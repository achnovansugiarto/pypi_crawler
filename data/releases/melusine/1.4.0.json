{
  "info": {
    "author": "Sacha Samama, Tom Stringer, Antoine Simoulin",
    "author_email": "ssamama@quantmetry.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 2 - Pre-Alpha",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: Apache Software License",
      "Natural Language :: English",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7"
    ],
    "description": "# Melusine\n\n<!-- <img src=`docs/_static/melusine.png` width=`200`/> -->\n![](docs/_static/melusine.png)\n\n[![pypi badge](https://img.shields.io/pypi/v/melusine.svg)](https://pypi.python.org/pypi/melusine)\n[![](https://img.shields.io/travis/sachasamama/melusine.svg)](https://travis-ci.org/sachasamama/melusine)\n[![documentation badge](https://readthedocs.org/projects/melusine/badge/?version=latest)](https://readthedocs.org/projects/melusine/)\n\n- Free software: Apache Software License 2.0\n- Documentation: [https://melusine.readthedocs.io](https://melusine.readthedocs.io).\n\n# Overview\n\n**Melusine** is a high-level Scikit-Learn API for emails classification and feature extraction,\nwritten in Python and capable of running on top of Scikit-Learn, Keras or Tensorflow.\nIt was developed with a focus on emails written in french.\n\nUse **Melusine** if you need a library which :\n  * Supports both convolutional networks and recurrent networks, as well as combinations of the two.\n  * Runs seamlessly on CPU and GPU.\n\n**Melusine** is compatible with `Python >= 3.5`.\n\n\n## The Melusine package\n\nThis package is designed for the preprocessing, classification and automatic summarization of emails written in french.\n\n<!-- <img src=`docs/_static/schema_1.png` width=`600`/> -->\n![](docs/_static/schema_1.png =700x)\n\n**3 main subpackages are offered :**\n\n* ``prepare_email`` : to preprocess and clean the emails.\n* ``summarizer`` : to extract keywords from an email.\n* ``models`` : to classify e-mails according to categories pre-defined defined by the user.\n\n**2 other subpackages are offered as building blocks :**\n\n* ``nlp_tools`` : to provide classic NLP tools such as tokenizer, phraser and embeddings.\n* ``utils`` : to provide a *TransformerScheduler* class to build your own transformer and integrate it into a scikit-learn Pipeline.\n\n**An other subpackage is also provided** to manage, modify or add parameters such as : regular expressions, keywords, stopwords, etc.\n\n* ``config`` : contains *`ConfigJsonReader`* class to setup and handle a *conf.json* file. This JSON file is the core of this package since it's used by different submodules to preprocess the data.\n\n\n## Getting started: 30 seconds to Melusine\n\n### Installation\n\n```\npip install melusine\n```\n\nTo use Melusine in a project\n\n```python\nimport melusine\n```\n\n### Input data : Email DataFrame\n\nThe basic requirement to use Melusine is to have an input e-mail DataFrame with the following columns:\n\n- *body*   : Body of an email (single message or conversation historic)\n- *header* : Header/Subject of an email\n- *date*   : Reception date of an email\n- *from*   : Email address of the sender\n- *to*     : Email address of the recipient\n- *label* (optional): Label of the email for a classification task (examples: Business, Spam, Finance or Family)\n\n| body                       | header         | date                           | from                         | to                             | label   |\n|:---------------------------|:--------------:|:------------------------------:|:----------------------------:|:-------------------------------------:|:-------:|\n| Thank you.\\\\nBye,\\\\nJohn   | Re: Your order | jeudi 24 mai 2018 11 h 49 CEST | anonymous.sender@unknown.com | anonymous.recipient@unknown.fr | label_1Â |\n\n### Pre-processing pipeline\n\nA working pre-processing pipeline is given below::\n\n```python\nfrom sklearn.pipeline import Pipeline\nfrom melusine.utils.transformer_scheduler import TransformerScheduler\nfrom melusine.prepare_email.manage_transfer_reply import check_mail_begin_by_transfer\nfrom melusine.prepare_email.manage_transfer_reply import update_info_for_transfer_mail\nfrom melusine.prepare_email.manage_transfer_reply import add_boolean_answer\nfrom melusine.prepare_email.manage_transfer_reply import add_boolean_transfer\nfrom melusine.prepare_email.build_historic import build_historic\nfrom melusine.prepare_email.mail_segmenting import structure_email\nfrom melusine.prepare_email.body_header_extraction import extract_last_body\nfrom melusine.prepare_email.cleaning import clean_body\nfrom melusine.prepare_email.cleaning import clean_header\n\nManageTransferReply = TransformerScheduler(\nfunctions_scheduler=[\n    (check_mail_begin_by_transfer, None, ['is_begin_by_transfer']),\n    (update_info_for_transfer_mail, None, None),\n    (add_boolean_answer, None, ['is_answer']),\n    (add_boolean_transfer, None, ['is_transfer'])\n])\n\nEmailSegmenting = TransformerScheduler(\nfunctions_scheduler=[\n    (build_historic, None, ['structured_historic']),\n    (structure_email, None, ['structured_body'])\n])\n\nCleaning = TransformerScheduler(\nfunctions_scheduler=[\n    (extract_last_body, None, ['last_body']),\n    (clean_body, None, ['clean_body']),\n    (clean_header, None, ['clean_header'])\n])\n\nprepare_data_pipeline = Pipeline([\n  ('ManageTransferReply', ManageTransferReply),\n  ('EmailSegmenting', EmailSegmenting),\n  ('Cleaning', Cleaning),\n])\n\ndf_email = prepare_data_pipeline.fit_transform(df_email)\n```\n\nIn this example, the pre-processing functions applied are:\n\n- ``check_mail_begin_by_transfer`` : Email is a direct transfer (True/False)\n- ``update_info_for_transfer_mail`` : Update body, header, from, to, date if direct transfer\n- ``add_boolean_answer`` : Email is an answer (True/False)\n- ``add_boolean_transfer`` : Email is transferred (True/False)\n- ``build_historic`` : When email is a conversation, reconstructs the individual message historic\n- ``structure_email`` : Splits parts of each messages in historic and tags them (tags: Hello, Body, Greetings, etc)\n\n### Phraser and Tokenizer pipeline\n\nA pipeline to train and apply the phraser end tokenizer is given below::\n\n```python\nfrom melusine.nlp_tools.phraser import Phraser\nfrom melusine.nlp_tools.tokenizer import Tokenizer\n\nphraser = Phraser(columns='clean_body')\nphraser.train(df_email)\nphraser.save('./phraser.pkl')\nphraser = Phraser().load('./phraser.pkl')\n\nPhraserTransformer = TransformerScheduler(\nfunctions_scheduler=[\n    (phraser_on_body, (phraser,), ['clean_body']),\n    (phraser_on_header, (phraser,), ['clean_header'])\n])\n\nphraser_tokenizer_pipeline = Pipeline([\n  ('PhraserTransformer', PhraserTransformer),\n  ('Tokenizer', Tokenizer(columns=['clean_body', 'clean_header']))\n])\n\ndf_email = phraser_tokenizer_pipeline.fit_transform(df_email)\n```\n\n### Embeddings training\n\nAn example of embedding training is given below::\n\n```python\nfrom melusine.nlp_tools.embedding import Embedding\n\nembedding = Embedding(columns='clean_body')\nembedding.train(df_email)\nembedding.save('./embedding.pkl')\n```\n\n### Metadata pipeline\n\nA pipeline to prepare the metadata is given below:\n\n```python\nfrom melusine.prepare_email.metadata_engineering import MetaExtension\nfrom melusine.prepare_email.metadata_engineering import MetaDate\nfrom melusine.prepare_email.metadata_engineering import Dummifier\n\nmetadata_pipeline = Pipeline([\n  ('MetaExtension', MetaExtension()),\n  ('MetaDate', MetaDate()),\n  ('Dummifier', Dummifier(columns_to_dummify=['extension', 'dayofweek', 'hour']))\n])\n\ndf_meta = metadata_pipeline.fit_transform(df_email)\n```\n\n### Keywords extraction\n\nAn example of keywords extraction is given below::\n\n```python\nfrom melusine.summarizer.keywords_generator import KeywordsGenerator\n\nkeywords_generator = KeywordsGenerator()\ndf_email = phraser_tokenizer_pipeline.fit_transform(df_email)\n```\n\n### Classification\n\nAn example of classification is given below::\n```python\nfrom sklearn.preprocessing import LabelEncoder\nfrom melusine.nlp_tools.embedding import Embedding\nfrom melusine.models.neural_architectures import cnn_model\nfrom melusine.models.train import NeuralModel\n\nX = df_email.drop(['label'], axis=1)\ny = df_email.label\n\nle = LabelEncoder()\ny = le.fit_transform(y)\n\npretrained_embedding = Embedding().load(./embedding.pkl)\n\nnn_model = NeuralModel(neural_architecture_function=cnn_model,\n                       pretrained_embedding=pretrained_embedding)\nnn_model.fit(X, y)\ny_res = nn_model.transform(X_test)\n```\n\n## Glossary\n\n### Pandas dataframes columns\n\nBecause Melusine manipulates pandas dataframes, the naming of the columns is imposed.\nHere is a basic glossary to provide an understanding of each columns manipulated.\nInitial columns of the dataframe:\n\n* **body :** the body of the email. It can be composed of a unique message, a historic of messages, a transfer of messages or a combination of historics and transfers.\n* **header :** the subject of the email.\n* **date :** the date the email has been sent. It corresponds to the date of the last message of the email has been written.\n* **from :** the email address of the author of the last message of the email.\n* **to :** the email address of the recipient of the last message.\n\nColumns added by Melusine:\n\n* **is_begin_by_transfer :** boolean, indicates if the email is a direct transfer. In that case it is recommended to update the value of the initial columns with the informations of the message transferred.\n* **is_answer :** boolean, indicates if the email contains a historic of messages\n* **is_transfer :** boolean, indicates if the email is a transfer (in that case it does not have to be a direct transfer).\n* **structured_historic :** list of dictionaries, each dictionary corresponds to a message of the email. The first dictionary corresponds to the last message (the one that has been written) while the last dictionary corresponds to the first message of the historic. Each dictionary has two keys :\n\n  - *meta :* to access the metadata of the message as a string.\n  - *text :* to access the message itself as a string.\n\n* **structured_body :** list of dictionaries, each dictionary corresponds to a message of the email. The first dictionary corresponds to the last message (the one that has been written) while the last dictionary corresponds to the first message of the historic. Each dictionary has two keys :\n\n  - *meta :* to access the metadata of the message as a dictionary. The dictionary has three keys:\n    + *date :* the date of the message.\n    + *from :* the email address of the author of the message.\n    + *to :* the email address of the recipient of the message.\n\n  - *text :* to access the message itself as a dictionary. The dictionary has two keys:\n    + *header :* the subject of the message.\n    + *structured_text :* the different parts of the message segmented and tagged as a list of dictionaries. Each dictionary has two keys:\n      - *part :* to access the part of the message as a string.\n      - *tags :* to access the tag of the part of the message.\n\n\n* **last_body :** string, corresponds to the part of the last message of the email that has been tagged as `BODY`.\n* **clean_body :** string, corresponds a cleaned last_body.\n* **clean_header :** string, corresponds to a cleaned header.\n* **clean_text :** string, concatenation of clean_header and clean_body.\n* **tokens :** list of strings, corresponds to a tokenized column, by default clean_text.\n* **keywords :** list of strings, corresponds to the keywords of extracted from the tokens column.\n\n### Tags\n\nEach messages of an email are segmented the in the **structured_body** columns and each parts are assigned a tag:\n\n* `RE/TR` : any metadata such as date, from, to etc.\n* `DISCLAIMER` : any disclaimer such as `L'Ã©metteur dÃ©cline toute responsabilitÃ©...`.\n* `GREETINGS` : any greetings such as `Salutations`.\n* `PJ` : any indication of an attached document such as `See attached file...`.\n* `FOOTER` : any footer such as `Provenance : Courrier pour Windows`.\n* `HELLO` : any salutations such as `Bonjour,`.\n* `THANKS` : any thanks such as `Avec mes remerciements`\n* `BODY` : the core of the the message which contains the valuable information.\n\n\n## Motivation & history\n\n\n### Origin of the project\n\n**MAIF**, being one of the leading mutual insurance companies in France, receives daily a large volume of emails from its clients\nand is under pressure to reply to their requests as efficiently as possible. As such an efficient routing system is of the\nupmost importance to assign each emails to its right entity.\nHowever the previously outdated routing system put the company under ever increasing difficulties to fulfill its pledge.\nIn order to face up to this challenge, MAIF in collaboration with **Quantmetry**, has implemented a new routing system\nbased on state-of-the-art NLP and Deep Learning techniques that would classify each email under the right label\naccording to its content and extract the relevant information to help the MAIF counsellors processing the emails.\n\n### Ambitions of the project\n\n**Melusine** is the first Open Source and free-of-use solution dedicated specifically to the qualification of e-mails written in french.\nThe ambition of this Python package is to become a reference, but also to live in the French NLP community by federating users and contributors.\nInitially developed to answer the problem of routing e-mails received by the MAIF, the solution was implemented using state-of-the-art techniques in Deep Learning and NLP.\nMelusine can be interfaced with Scikit-Learn: it offers the user the possibility to train his own classification and automatic summarization model according to the constraints of his problem.\n\n### The collaboration between Quantmetry and MAIF\n\nAfter collaborating for the implementation of its routing system with Quantmetry,\na pure player consulting firm in AI, MAIF pursued the partnership to develop the *Melusine* package.\n\n### Why Melusine ?\n\nFollowing MAIF's tradition to name its open source packages after deities, it was chosen to release this package\nunder the name of Melusine as an homage to a legend from the local folklore in the Poitou region in France\nwhere MAIF is historically based.\n\n\n## Credits\n\nThis package was created with [Cookiecutter](https://github.com/audreyr/cookiecutter) and the [audreyr/cookiecutter-pypackage](https://github.com/audreyr/cookiecutter-pypackage) project template.\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/MAIF/melusine",
    "keywords": "melusine",
    "license": "Apache Software License 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "melusine",
    "package_url": "https://pypi.org/project/melusine/",
    "platform": "",
    "project_url": "https://pypi.org/project/melusine/",
    "project_urls": {
      "Homepage": "https://github.com/MAIF/melusine"
    },
    "release_url": "https://pypi.org/project/melusine/1.4.0/",
    "requires_dist": [
      "pandas (>=0.22.0)",
      "scikit-learn (>=0.19.0)",
      "gensim (>=3.3.0)",
      "nltk (>=3.3)",
      "keras (>=2.2.0)",
      "tqdm (>=4.14)",
      "tensorflow (>=1.10.0)",
      "unidecode"
    ],
    "requires_python": "",
    "summary": "Melusine is a high-level package for french emails preprocessing, classification and feature extraction, written in Python.",
    "version": "1.4.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16074935,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "03030752c4bbef962ebbe9dabd1bdc0386621d3531844399ab80107554ff3521",
        "md5": "1fa36a667c9d6f617297bcae86e1e9a4",
        "sha256": "a63ec03e089747b342d5f9cd5b6ab99db7acc58e8a2aacae66dcbf6bf98bdba3"
      },
      "downloads": -1,
      "filename": "melusine-1.4.0-py2.py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "1fa36a667c9d6f617297bcae86e1e9a4",
      "packagetype": "bdist_wheel",
      "python_version": "py2.py3",
      "requires_python": null,
      "size": 41534,
      "upload_time": "2019-02-27T17:38:12",
      "upload_time_iso_8601": "2019-02-27T17:38:12.690443Z",
      "url": "https://files.pythonhosted.org/packages/03/03/0752c4bbef962ebbe9dabd1bdc0386621d3531844399ab80107554ff3521/melusine-1.4.0-py2.py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "1dd8150d5d1195888f683e983c4a301b119f7ac8342f2fd9e63aefea548d6c6d",
        "md5": "007dd1333dcd6119f25d5112b83f6f25",
        "sha256": "7e0ad956f2b219cab6837de42d5e535e060d3a99d7c1673f797afd8aa01103b0"
      },
      "downloads": -1,
      "filename": "melusine-1.4.0.tar.gz",
      "has_sig": false,
      "md5_digest": "007dd1333dcd6119f25d5112b83f6f25",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 607941,
      "upload_time": "2019-02-27T17:38:14",
      "upload_time_iso_8601": "2019-02-27T17:38:14.305611Z",
      "url": "https://files.pythonhosted.org/packages/1d/d8/150d5d1195888f683e983c4a301b119f7ac8342f2fd9e63aefea548d6c6d/melusine-1.4.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}