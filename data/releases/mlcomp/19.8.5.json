{
  "info": {
    "author": "Evgeny Semyonov",
    "author_email": "lightsanweb@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Developers",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: Implementation :: CPython",
      "Topic :: Scientific/Engineering :: Artificial Intelligence"
    ],
    "description": "\n# MLComp\n\n[![Build Status](https://travis-ci.org/lightforever/mlcomp.svg?branch=master)](https://travis-ci.org/lightforever/mlcomp) \n[![License](https://img.shields.io/github/license/lightforever/mlcomp.svg)](LICENSE)\n[![Pipi version](https://img.shields.io/pypi/v/mlcomp.svg)](https://pypi.org/project/mlcomp/)\n[![Docs](https://img.shields.io/badge/dynamic/json.svg?label=docs&url=https%3A%2F%2Fpypi.org%2Fpypi%2Fmlcomp%2Fjson&query=%24.info.version&colorB=brightgreen&prefix=v)](https://lightforever.github.io/mlcomp/index.html)\n\nMLComp is a distributed DAG (Directed acyclic graph) framework for machine learning with UI.\n\nThe goal of MLComp is to provide tools for training, inferencing, creating complex pipelines\n(especially for computer vision) in a rapid, well manageable way.\n\nMLComp is compatible with: Python 3.6+, Unix operation system.\n\n![MLComp logo](https://github.com/lightforever/mlcomp/raw/master/mlcomp/server/front/src/assets/img/mlcomp_logo.jpg)\n\n**Features**\n\n- Amazing UI\n- [Catalyst](https://github.com/catalyst-team/catalyst) support\n- Distributed training\n- Supervisor that controls computational resources\n- Synchronization of both code and data\n- Resource monitoring\n- Full functionality of the pause and continue on UI\n- Auto control of the requirements\n- Code dumping (with syntax highlight on UI)\n- [Kaggle](https://www.kaggle.com/) integration\n- Hierarchical logging\n- Grid search\n- Experiments comparison\n- Customizing layouts\n\n**Contents**\n\n- [Screenshots](#screenshots)\n\n- [Installation](#installation)\n\n- [UI](#ui)\n\n- [Usage](#usage)\n\n- [Docs and examples](#docs-and-examples)\n\n- [Environment variables](#environment-variables)\n\n# Screenshots\n\nDags\n\n![dags](docs/imgs/dags.png)\n\nComputers\n\n![computers](docs/imgs/computers.png)\n\nReports\n\n![reports](docs/imgs/reports.png)\n\nCode\n\n![code](docs/imgs/code.png)\n\nGraph\n\n![graph](docs/imgs/graph.png)\n\n[More screenshots](docs/screenshots.md)\n\n# Installation\n\n1. Install MLComp package\n\n    ```bash\n    pip install mlcomp\n    mlcomp init\n    ```\n\n2. Setup your environment. Please consider [Environment variables](#environment-variables) section\n\n3. Run db, redis, mlcomp-server, mlcomp-workers:\n\n    **Variant 1: minimal (if you have 1 computer)**\n\n    Run all necessary (mlcomp-server, mlcomp-workers, redis-server), it uses SQLITE:\n\n    ```bash\n    mlcomp-server start\n    ```\n\n    **Variant 2: full**\n\n    a. Change your [Environment variables](#environment-variables) to use PostgreSql\n\n    b. Install rsync on each work computer\n\n    ```.env\n    sudo apt-get install rsync\n    ```\n\n    Ensure that every computer is available by SSH protocol with IP/PORT you specified\n     in the [Environment variables](#environment-variables) file.\n\n     rsync will perform the following commands:\n\n     to upload\n     ```bash\n     rsync -vhru -e \"ssh -p {target.port} -o StrictHostKeyChecking=no\" \\\n     {folder}/ {target.user}@{target.ip}:{folder}/ --perms  --chmod=777\n     ```\n     to download\n\n     ```.env\n     rsync -vhru -e \"ssh -p {source.port} -o StrictHostKeyChecking=no\" \\\n     {source.user}@{source.ip}:{folder}/ {folder}/ --perms  --chmod=777\n     ```\n\n    c. Install [apex](https://github.com/NVIDIA/apex#quick-start) for distributed learning\n\n    d. To Run postgresql, redis-server, mlcomp-server, execute on your server-computer:\n\n     ```bash\n    cd ~/mlcomp/configs/\n    docker-compose -f server-compose.yml up -d\n    ```\n\n    e. Run on each worker-computer:\n\n    ```bash\n    mlcomp-worker start\n    ```\n\n # UI\n\nWeb site is available at http://{WEB_HOST}:{WEB_PORT}\n\nBy default, it is http://localhost:4201\n\nThe front is built with AngularJS.\n\nIn case you desire to change it, please consider [front's Readme page](mlcomp/server/front/README.md)\n\n # Usage\n\nRun\n ```bash\nmlcomp dag PATH_TO_CONFIG.yml\n```\n\nThis command copies files of the directory to the database.\n\nThen, the server schedules the DAG considering free resources. \n\nFor more information, please consider [Docs](https://lightforever.github.io/mlcomp/usage.html)\n\n# Docs and examples\n\nAPI documentation and an overview of the library can be\n found here [![Docs](https://img.shields.io/badge/dynamic/json.svg?label=docs&url=https%3A%2F%2Fpypi.org%2Fpypi%2Fmlcomp%2Fjson&query=%24.info.version&colorB=brightgreen&prefix=v)](https://lightforever.github.io/mlcomp/index.html)\n\nYou can find advanced tutorials and MLComp best practices in the [examples](examples/) folder of the repository.\n\n# Environment variables\n\nThe single file to setup your computer environment is located at ~/mlcomp/configs/.env\n\n- ROOT_FOLDER - folder to save MLComp files: configs, db, tasks, etc.\n- TOKEN - site security token. Please change it to any string\n- DB_TYPE. Either SQLITE or POSTGRESQL\n- POSTGRES_DB. PostgreSql db name\n- POSTGRES_USER. PostgreSql user\n- POSTGRES_PASSWORD. PostgreSql password\n- POSTGRES_HOST. PostgreSql host\n- PGDATA. PostgreSql db files location\n- REDIS_HOST. Redis host\n- REDIS_PORT. Redis port\n- REDIS_PASSWORD. Redis password\n- WEB_HOST. MLComp site host. 0.0.0.0 means it is available from everywhere\n- WEB_PORT. MLComp site port\n- CONSOLE_LOG_LEVEL. log level for output to the console\n- DB_LOG_LEVEL. log level for output to the database\n- IP. Ip of a work computer. The work computer must be accessible from other work computers by these IP/PORT\n- PORT. Port of a work computer. The work computer must be accessible from other work computers by these IP/PORT (SSH protocol)\n- MASTER_PORT_RANGE. distributed port range for a work computer. 29500-29510 means that if\nthis work computer is a master in a distributed learning, it will use the first free port\nfrom this range. Ranges of different work computers must not overlap.\n- NCCL_SOCKET_IFNAME. NCCL network interface. \nYou can see your network interfaces with `ifconfig` command.\n Please consider [nvidia doc](https://docs.nvidia.com/deeplearning/sdk/nccl-developer-guide/docs/env.html)\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/lightforever/mlcomp",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "mlcomp",
    "package_url": "https://pypi.org/project/mlcomp/",
    "platform": "",
    "project_url": "https://pypi.org/project/mlcomp/",
    "project_urls": {
      "Homepage": "https://github.com/lightforever/mlcomp"
    },
    "release_url": "https://pypi.org/project/mlcomp/19.8.5/",
    "requires_dist": [
      "catalyst (==19.8.5)",
      "redis",
      "PyYAML (>=5.1)",
      "setuptools (>=41.0.1)",
      "click (>=7.0)",
      "psutil (>=5.6.2)",
      "GPUtil (==1.4.0)",
      "pathspec (>=0.5.9)",
      "apscheduler (>=3.6.0)",
      "sqlalchemy (>=1.3.4)",
      "celery (>=4.3.0)",
      "kaggle (>=1.5.3)",
      "scipy (>=1.3.0)",
      "flask (>=1.0.2)",
      "requests",
      "flask-cors (>=3.0.6)",
      "sqlalchemy-serializer (==1.3.1)",
      "scikit-learn (>=0.21.2)",
      "psycopg2-binary (>=2.8.2)",
      "tiffile",
      "albumentations (>=0.2.3)",
      "sqlalchemy-migrate (>=0.12.0)",
      "cython",
      "pretrainedmodels (>=0.7.4)",
      "supervisor (>=4.0.4)",
      "pytest (>=5.0.1)",
      "pytest-xdist (>=1.29.0)"
    ],
    "requires_python": ">=3.6.0",
    "summary": "Machine learning pipelines. Especially, for competitions, like Kaggle",
    "version": "19.8.5",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 6821648,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "4ce2f7b76a977222b72ff95d845646a9e847122b1283f569d25a23a70ac295af",
        "md5": "7331aa1cb7540ca056a65eb8a735e1ef",
        "sha256": "cee4adf331ec8e1f00fbb899c10a931bf687d23c4f450f02ea6b57b906f18397"
      },
      "downloads": -1,
      "filename": "mlcomp-19.8.5-py2.py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "7331aa1cb7540ca056a65eb8a735e1ef",
      "packagetype": "bdist_wheel",
      "python_version": "py2.py3",
      "requires_python": ">=3.6.0",
      "size": 14021932,
      "upload_time": "2019-08-21T16:33:52",
      "upload_time_iso_8601": "2019-08-21T16:33:52.119327Z",
      "url": "https://files.pythonhosted.org/packages/4c/e2/f7b76a977222b72ff95d845646a9e847122b1283f569d25a23a70ac295af/mlcomp-19.8.5-py2.py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "c3e681267a4842d676fbaa90f0a0c60f145193a45278e5fb9ec50f518caa115b",
        "md5": "7a304a19e27b7e5125633f25aa705de5",
        "sha256": "aae7a5859f6dd44a0edab8a24ba702dbd3b64261590a3094f8c84fe624ecfa8c"
      },
      "downloads": -1,
      "filename": "mlcomp-19.8.5.tar.gz",
      "has_sig": false,
      "md5_digest": "7a304a19e27b7e5125633f25aa705de5",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6.0",
      "size": 6886184,
      "upload_time": "2019-08-21T16:33:56",
      "upload_time_iso_8601": "2019-08-21T16:33:56.960082Z",
      "url": "https://files.pythonhosted.org/packages/c3/e6/81267a4842d676fbaa90f0a0c60f145193a45278e5fb9ec50f518caa115b/mlcomp-19.8.5.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}