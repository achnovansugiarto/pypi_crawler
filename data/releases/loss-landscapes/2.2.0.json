{
  "info": {
    "author": "Marcello De Bernardi",
    "author_email": "marcello.debernardi@stcatz.ox.ac.uk",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Topic :: Scientific/Engineering :: Artificial Intelligence"
    ],
    "description": "# loss-landscapes\n\n`loss-landscapes` is a library for approximating neural network loss functions, and other related metrics, \nalong low-dimensional subspaces of the model parameter space. The library makes the production of visualizations\nsuch as those seen in [Visualizing the Loss Landscape of Neural Nets](https://arxiv.org/abs/1712.09913v3) much\neasier, aiding the analysis of the geometry of neural network loss landscapes.\n\nCurrently, `loss-landscapes` only supports PyTorch models, but support for other DL libraries (TensorFlow in particular)\nis planned for future releases.\n\n\n## 1. What is a Loss Landscape?\nLet `L : Parameters -> Real Numbers` be a loss function, which maps a point in the model parameter space to a \nreal number. For a neural network with `n` parameters, the loss function `L` takes an `n`-dimensional input. We\ncan define the loss landscape as the set of all `n+1`-dimensional points `(param, L(param))`, for all points\n`param` in the parameter space. For example, the image below, reproduced from the paper by Li et al (2018), link\nabove, provides a visual representation of what a loss function over a two-dimensional parameter space might look \nlike:\n\n<p align=\"center\"><img src=\"/img/loss-landscape.png\" width=\"60%\" align=\"middle\"/></p>\n\nOf course, real machine learning models have a number of parameters much greater than 2, so the parameter space of \nthe model is virtually never two-dimensional. Because we can't print visualizations in more than two dimensions, \nwe cannot hope to visualize the \"true\" shape of the loss landscape. Instead, a number of techniques\nexist for reducing the parameter space to one or two dimensions, ranging from dimensionality reduction techniques\nlike PCA, to restricting ourselves to a particular subspace of the overall parameter space. For more details,\nread Li et al's paper.\n\n\n## 2. Loss in Parameter Subspaces\nThis library facilitates the computation of a neural network model's loss landscape in low-dimensional subspaces\nof the parameter space. It does not provide plotting facilities, letting the user define how the data should be plotted,\nand is designed to support any deep learning library (in principle - currently only PyTorch is supported). As an \nexample, it allows a PyTorch user to produce data for a plot such as the one seen above by simply calling\n\n````python\nevaluator = LossEvaluator(loss_function, X, y)\nlandscape = random_plane(model, evaluator, normalize='filter')\n````\n\nThis would return a 2-dimensional array of loss values, which the user can plot in any desirable way. \nBelow are a contour plot and a surface plot made in `matplotlib`, drawn over the same loss landscape data, that \ndemonstrate what a loss landscape along a planar parameter subspace could look like.\nCheck the `examples` directory for `jupyter` notebooks with more in-depth examples of what is possible.\n\n<p align=\"center\"><img src=\"/img/loss-contour.png\" width=\"75%\" align=\"middle\"/></p>\n\n<p align=\"center\"><img src=\"/img/loss-contour-3d.png\" width=\"75%\" align=\"middle\"/></p>\n\n\n## 3. Evaluators and Custom Evaluators\nThe `loss-landscapes` library can compute any quantity of interest at a collection of points in a parameter subspace,\nnot just loss. This is accomplished using an `Evaluator`: a callable object which applies a pre-determined function,\nsuch as a cross entropy loss with a specific set of inputs and outputs, at every point. The `loss_landscapes.evaluators`\npackage contains a number of evaluators that cover common use cases, such as `LossEvaluator` (evaluates a loss\nfunction), `GradientEvaluator` (evaluates the gradient of the loss w.r.t. the model parameters), \n`PrincipalCurvatureEvaluator` (evaluates the principal curvatures of the loss function), and more.\n\nFurthermore, the user can add custom evaluators by subclassing `Evaluator`. As an example, consider the library\nimplementation of `LossEvaluator`, for `torch` models:\n\n````python\nclass LossEvaluator(SupervisedTorchEvaluator):\n    \"\"\" Computes a specified loss function over specified input-output pairs. \"\"\"\n    def __init__(self, supervised_loss_fn, inputs, target):\n        super().__init__(supervised_loss_fn, inputs, target)\n\n    def __call__(self, model) -> np.ndarray:\n        return self.loss_fn(model(self.inputs), self.target).clone().detach().numpy()\n````\n\nIn summary, the `Evaluator` abstraction adds a great degree of flexibility. An evaluator defines what quantity\ndependent on model parameters the user is interested in evaluating , and how to evaluate it. The user could define, \nfor example, an evaluator that computes an estimate of the expected return of a reinforcement learning agent.\n\n\n## 4. RL Agents and Other Complications\nIn the general case of a simple supervised learning model, as in the sections above, client code calls functions \nsuch as `loss_landscapes.linear_interpolation` and passes as argument a reference to a deep learning model. The \n`loss-landscapes` library detects the DL library to which the model belongs. This process is not visible to the\nuser and in most cases can safely be ignored.\n\nFor more complex cases, such as when the user wants to evaluate the loss landscape as a function of a subset of\nthe model parameters, or the expected return landscape for a RL model, the user must specify to the `loss-landscapes`\nlibrary how to interface with the model (or the agent, on a more general level). This is accomplished using a\n`AgentInterface` object. In the example below, the `AgentInterface` specifies the means by which the `random_plane`\nmethod will interface with a particular reinforcement learning agent, such that the agent object contains neural\nnetwork models.\n\n````python\n# agent.policy and agent.value_function are pytorch modules\ninterface = AgentInterface(library='torch', components=[agent.policy, agent.value_function], call_fn= lambda x: model.policy(x))\nlandscape = random_plane(agent, evaluator, normalize='filter')\n````\n\n\n\n## 5. WIP: Connecting Paths, Saddle Points, and Trajectory Tracking\nA number of features are currently under development, but as of yet incomplete.\n\nA number of papers in recent years have shown that loss landscapes of neural networks are dominated by a\nproliferation of saddle points, that good solutions are better described as large low-loss plateaus than as\n\"well-bottom\" points, and that for sufficiently high-dimensional networks, a low-loss path in parameter space can\nbe found between almost any arbitrary pair of minima. In the future, the `loss-landscapes` library will feature \nimplementations of algorithms for finding such low-loss connecting paths in the loss landscape, as well as tools to\nfacilitate the study of saddle points.\n\nSome sort of trajectory tracking features are also under consideration, though at the time it's unclear what this\nshould actually mean, as the optimization trajectory is implicitly tracked by the user's training loop. Any metric\nalong the optimization trajectory can be tracked with libraries such as [ignite](https://github.com/pytorch/ignite)\nfor PyTorch.\n\n\n## 7. Support for Other DL Libraries\nOnce the currently envisioned features are complete, the first priority will be adding support for TensorFlow.\n\n\n## 8. Installation and Use\nThe package is available on PyPI. Install using `pip install loss-landscapes`. To use the library, import as follows:\n\n````python\nimport loss_landscapes\nimport loss_landscapes.evaluators  # for the base Evaluator class\nimport loss_landscapes.evaluators.torch  # for the pre-defined PyTorch evaluators\n````\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/marcellodebernardi/loss-landscapes",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "loss-landscapes",
    "package_url": "https://pypi.org/project/loss-landscapes/",
    "platform": "",
    "project_url": "https://pypi.org/project/loss-landscapes/",
    "project_urls": {
      "Homepage": "https://github.com/marcellodebernardi/loss-landscapes"
    },
    "release_url": "https://pypi.org/project/loss-landscapes/2.2.0/",
    "requires_dist": [
      "numpy"
    ],
    "requires_python": ">=3.5",
    "summary": "A library for approximating loss landscapes in low-dimensional parameter subspaces",
    "version": "2.2.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 5761636,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "1a8549b21464c2fcac537f512cda5af32358ecafc99671edbaed76b235513a0b",
        "md5": "ad07a264f29be79cbf3d54785bf89ed5",
        "sha256": "5ab05ca3efa0eb569c385e983379b77eb9e148ef2132b929ff2d03fc1f639fb7"
      },
      "downloads": -1,
      "filename": "loss_landscapes-2.2.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "ad07a264f29be79cbf3d54785bf89ed5",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.5",
      "size": 56482,
      "upload_time": "2019-06-14T11:51:49",
      "upload_time_iso_8601": "2019-06-14T11:51:49.804802Z",
      "url": "https://files.pythonhosted.org/packages/1a/85/49b21464c2fcac537f512cda5af32358ecafc99671edbaed76b235513a0b/loss_landscapes-2.2.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "b00c2edb2335ef03743b630ee49e272b6ec6528cb1a491ed6e4a6dd5624d92fc",
        "md5": "fb876bdfae5a6845bff1ed2ef8dff3b3",
        "sha256": "e0faa1fc10b810c64f5db1cc56dac51587b49f7b48f0990b62dea0d722021224"
      },
      "downloads": -1,
      "filename": "loss_landscapes-2.2.0.tar.gz",
      "has_sig": false,
      "md5_digest": "fb876bdfae5a6845bff1ed2ef8dff3b3",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.5",
      "size": 19711,
      "upload_time": "2019-06-14T11:51:57",
      "upload_time_iso_8601": "2019-06-14T11:51:57.148637Z",
      "url": "https://files.pythonhosted.org/packages/b0/0c/2edb2335ef03743b630ee49e272b6ec6528cb1a491ed6e4a6dd5624d92fc/loss_landscapes-2.2.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}