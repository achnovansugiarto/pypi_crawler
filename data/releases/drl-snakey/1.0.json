{
  "info": {
    "author": "YANG Xuezhi",
    "author_email": "cstrikest@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Environment :: MacOS X",
      "License :: OSI Approved :: GNU General Public License v3 (GPLv3)",
      "Natural Language :: Chinese (Simplified)",
      "Programming Language :: Python :: 3.6",
      "Topic :: Scientific/Engineering :: Artificial Intelligence"
    ],
    "description": "# Deep Reinforcement Learning 深度强化学习贪吃蛇游戏 DRL_Snakey\n\n深度强化学习贪吃蛇AI与游戏环境。\n\n![Build](http://img.shields.io/travis/cstrikest/DRL_Snakey.svg)\n![PyPI - Downloads](https://img.shields.io/pypi/dm/DRL_Snakey.svg)\n\n![游戏开始界面](https://github.com/cstrikest/ML_Snakey/blob/master/images/gamestart_image.png?raw=true)\n\n## 环境\n\nPython版本: Python3.6或以上\n\n### 外部依赖\n\n* pygame\n* tensorflow / tensorflow-gpu\n* h5py\n* numpy\n* matplotlib\n\n## 游戏说明\n\n**演示文件: Snakey_play.py**\n\n此文件与DRL_Snakey包无关联，不含有任何AI部分，作为一个人类可以游玩的游戏进行演示。\n在使用包之前可以先运行该脚本查看游戏效果。\n\n![游戏面板](https://github.com/cstrikest/ML_Snakey/blob/master/images/game_image.png?raw=true)\n\n### 规则\n\n游戏素材图片比较简陋。人类玩家游玩时，游戏内容设有等级划分，随着获取食物的数量上升，蛇前进的速度会变快。\n\n同时每增加一个难度会多出现一个触碰到便会游戏结束的炸弹。\n\n游戏在一个200×200像素的平面中运行，每10×10个像素作为一个单元。 右侧有计分面板。\n\n游戏右侧是一个100×200像素的信息面板。主要用到的信息会在右侧给出。\n\n使用方向键控制移动方向，任何时候都可以使用Q键退出。\n\n游戏结束画面按R重新开始，按S则会跳出计分板。\n\n### AI部分说明\n\nAI没有游戏的速度区别与等级区分，暂时无视炸弹，并且在使用界面时默认使用最快的刷新速度。\n\n除单独存在的演示脚本外，AI部分主要由**物理引擎**，**图形引擎**，**决策逻辑**三部分组成，运行时可以根据需要选择是否加载图形引擎显示游戏界面。\n\n本项目内拥有数个AI逻辑脚本，详细见下文的各脚本说明。\n\n**游戏中按F键可切换可视化部分，P键暂停，N键在暂停时单步进行游戏。**\n\n### 使用方法\n\n首先import\n\n    import DRL_Snakey as Snakey\n\n创建游戏对象，此游戏类仅包含游戏规则(DRL_Snakey.Game)。\n\n    game = Snakey.Game(bomb = 0)\n\n游戏控制agent对象。这里以简单逻辑算法AI举例。\n\n    agent = Snakey.agent.Logic()\n\n游戏界面对象，通过pygame模块创建可视的游戏界面。\n\n    ui = Snakey.UI(fps = 60)\n\n通过UI类的show(game, agent)函数创建游戏窗口。\n\n    ui.show(game, agent)\n\n需要训练agent模型或其他等不需要游戏UI界面时，使用以下脚本控制游戏流程。\n\n    import DRL_Snakey as Snakey\n\n    game = Snakey.Game(bomb = 0)\n    agent = Snakey.agent.Logic()\n\n    while True:\n        game.next(agent.get_next_direction(game))\n        if game.deathflag:\n            print(\"Gameover. score:\", game.ate)\n            game.reset()\n\n## DRL_Snakey说明\n\nDRL_Snakey分为游戏环境`DRL_Snakey.core`，智能体`DRL_Snakey.agent`与`DRL_Snakey.utlis`组件三部分组成。\n\n其中`DRL_Snakey.core.Game`为贪吃蛇游戏的基本行动规则，死亡判定以及地图查看等功能。可以视为游戏的本体。\n`DRL_Snakey.core.UI`为游戏界面显示相关。通过pygame包来创建可视化的游戏界面。\n\n`DRL_Snakey.agent`为智能体部分。智能体会读取游戏中每步的状态，应用相对的决策方法（普通算法或神经网络等等）\n进行决策，并给出反应。\n\nAgent类:\n\n    class Agent(object):\n\tdef get_next_direction(self, Game):\n\t\t\"\"\"\n\t\t根据智能体对当前环境的判断选择下一步前进的方向。\n\t\t:return: 方向[\"W\", \"S\", \"A\", \"D\"]\n\t\t\"\"\"\n\t\tpass\n\n\tdef custom_function(self, Game):\n\t\t\"\"\"\n\t\t给不同的agnet预留的自定义函数，用来调试或数据可视化。\n\t\t\"\"\"\n\t\tpass\n\nps. 请多多编写自己的agent然后pull request\n\n### DRL_Snakey.Agent.Logic\n\n一个简单的演示用逻辑AI，完全无视炸弹，只吃食物。具有十分简单的自身躲避算法。\n\n通过计算蛇头位置与食物的水平竖直差，以之字形接近食物。并且在决策方向前，会通过`Logic.next()`预测\n下一步的位置，并调用`Logic.elude()`依次尝试各个方向来避免与自己相撞。但是因为只能预测下一步的危险情况，\n所以此AI并不具有很高智能，只是作为演示使用。\n\n此AI在20次尝试中最好成绩为68，平均值为49.6。\n\n![简易AI演示](https://github.com/cstrikest/ML_Snakey/blob/master/images/2.gif?raw=true)\n\n### DRL_Snakey.Agent.DP\n\nDP(Dynamic Programming)动态规划-马尔科夫决策法。\n\n每一步都通过迭代贝尔曼方程计算当前各点的价值，创建价值矩阵。并且朝周围价值最高的点前进。\n\n构造函数参数说明:\n\n    discount: 衰减率，贝尔曼方程中对于非即时回报的衰减率。\n\titeration: 推算价值矩阵的迭代次数。\n\twalk_reward: 每走一步的回报\n\teat_self_reward: 吃到自己的回报\n\tfood_reward: 吃到食物的回报\n\n按F打开可视化模式后，可观察每一步动作所基于的各点价值图像。\n\n实际操作中会发现，AI可以根据价值的判断避开自身，并且在食物环境恶劣的情况下选择在安全地带迂回等待。\n\n此AI在20次尝试中最好成绩为103，平均值为59.2。\n\n![DP演示](https://github.com/cstrikest/ML_Snakey/blob/master/images/DP_play.gif?raw=true)\n\n## 深度强化学习 DRL AI\n\n作为深度强化学习很好的一个例子，贪吃蛇游戏有着很明显的数据结构。Environment就是地图整体，Action是上下左右\n四种可以采取的行动，无需再通过卷积神经网络读取游戏画面。\n\n本项目提供了一个游戏环境，供他人自行编写新的agent或拓展游戏功能。\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/cstrikest/DRL_Snakey",
    "keywords": "",
    "license": "GPL",
    "maintainer": "",
    "maintainer_email": "",
    "name": "DRL-Snakey",
    "package_url": "https://pypi.org/project/DRL-Snakey/",
    "platform": "",
    "project_url": "https://pypi.org/project/DRL-Snakey/",
    "project_urls": {
      "Homepage": "https://github.com/cstrikest/DRL_Snakey"
    },
    "release_url": "https://pypi.org/project/DRL-Snakey/1.0/",
    "requires_dist": [
      "numpy",
      "h5py",
      "pygame",
      "tensorflow",
      "matplotlib"
    ],
    "requires_python": "",
    "summary": "A Deep Reinforcement Learning study package. With game environment.",
    "version": "1.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 5361716,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "69a2fd18eee02dacb4b1bcf282a25f7db4c6f5ab1af905f5d13ccf83fbf38bb6",
        "md5": "30f8fcc7231afe13a52eb31ea26bde5e",
        "sha256": "de776fc3a9c8bc425747489d59c3e70a9bfc0982bccb083a368880217ea41148"
      },
      "downloads": -1,
      "filename": "DRL_Snakey-1.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "30f8fcc7231afe13a52eb31ea26bde5e",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 25659,
      "upload_time": "2019-05-22T11:06:51",
      "upload_time_iso_8601": "2019-05-22T11:06:51.136601Z",
      "url": "https://files.pythonhosted.org/packages/69/a2/fd18eee02dacb4b1bcf282a25f7db4c6f5ab1af905f5d13ccf83fbf38bb6/DRL_Snakey-1.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "c855736779e4adfd0c1fe120a48ac4bf653fc7abde6d8af7f8b23a78d8b17801",
        "md5": "d23074ccded72808af7f75dabdc2aa73",
        "sha256": "13ff49448dcce242d70d740196926d2a67277cfc0e804db9103ed12eb163de13"
      },
      "downloads": -1,
      "filename": "DRL_Snakey-1.0.tar.gz",
      "has_sig": false,
      "md5_digest": "d23074ccded72808af7f75dabdc2aa73",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 13150,
      "upload_time": "2019-05-22T11:06:52",
      "upload_time_iso_8601": "2019-05-22T11:06:52.702353Z",
      "url": "https://files.pythonhosted.org/packages/c8/55/736779e4adfd0c1fe120a48ac4bf653fc7abde6d8af7f8b23a78d8b17801/DRL_Snakey-1.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}