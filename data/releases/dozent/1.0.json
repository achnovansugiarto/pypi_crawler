{
  "info": {
    "author": "Ali Abbas, Eric Burt, Keelin Becker-Wheeler",
    "author_email": "socialmediapublicanalysis@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3.9",
      "Topic :: Software Development :: Build Tools"
    ],
    "description": "# Dozent\n\nDozent is a powerful downloader that is used to collect large amounts of Twitter data from the internet archive.\n\nIt is built on top of [PySmartDL](https://pypi.org/project/pySmartDL/) and multithreading, similar to how traditional download accelerators like [axel](https://linux.die.net/man/1/axel), [aria2c](https://linux.die.net/man/1/aria2c) and [aws s3](https://docs.aws.amazon.com/cli/latest/userguide/cli-services-s3-commands.html) work, ensuring that the biggest bottlenecks are your network and your hardware.\n\nThe data that is downloaded is already heavily compressed to reduce download times and save local storage. When uncompressed, the data can easily add up to several terabytes depending on the timeframe of data being collected. Fortunately, you do not have to decompress the data to analyze it! We are working on a separate big data tool named [Murpheus](https://github.com/Social-Media-Public-Analysis/murpheus) that uses Dask to analyze the data without needing to decompress it.\n\nIf you have any ideas on how to improve Dozent, please open an issue [here](https://github.com/Twitter-Public-Analysis/Twitter-Public-Analysis/issues) and tell us how!\n\n## Installation\n\nBefore installing, ensure that the version of python that you're using is python>=3.6. We intend to support all of the latest releases of as they come out\n\n### Installing with pip\n\nInstalling with pip is as easy as:\n\n```bash\npip install dozent\n```\n\n### Installing with Docker\n\nIn keeping with our goal for keeping everything we distribute as lightweight as possible, we include a docker image that would ensure that this process is as painless as possible without having to worry about python versions and so on.\n\nWhile \"installing\" isn't something that we can do with docker, we felt it best to include a some helpful links to help new comers install docker. \n\nYou can find the link to the installation [here](https://docs.docker.com/get-docker/). If you chose to go this route, we suggest jumping down to the `Run Dozent as a Docker Container` section after installing docker. \n\n## Usage\n\n```bash\n$ python -m dozent --help\n\nusage: __main__.py [-h] -s START_DATE -e END_DATE [-t TIMEIT]\n                 [-o OUTPUT_DIRECTORY] [-q]\n\nA powerful downloader to get tweets from twitter for our compute. The first\nstep of many\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -s START_DATE, --start-date START_DATE\n                        The date from where we download. The format must be:\n                        YYYY-MM-DD\n  -e END_DATE, --end-date END_DATE\n                        The last day that we download. The format must be:\n                        YYYY-MM-DD\n  -t TIMEIT, --timeit TIMEIT\n                        Show total program runtime\n  -o OUTPUT_DIRECTORY, --output-directory OUTPUT_DIRECTORY\n                        Output Directory where the file will be stored.\n                        Defaults to the data/ directory\n  -q, --quiet           Turn off output (except for errors and warnings)\n\n```\n\n### Downloading with Dozent after installing with pip\n\nDownloading all tweets from 12th of May 2020 to 15th of May 2020\n\n```bash\n$ python -m dozent -s 2020-05-12 -e 2020-05-15\n\nQueueing tweets download for 05-2020\nQueueing tweets download for 05-2020\nQueueing tweets download for 05-2020\nQueueing tweets download for 05-2020\nhttps://archive.org/download/archiveteam-twitter-stream-2020-05/twitter_stream_2020_05_13.tar [downloading] 16 Mb / 2498 Mb @ 1.6 MB/s [------------------] [0%, 32 minutes, 31 seconds left]\n```\n\n### Downloading with Dozent after installing Docker\n\nPull the latest Dozent image from Docker Hub\n```bash\n$ docker pull socialmediapublicanalysis/dozent:latest\n```\n\nGet help\n```bash\n$ docker run -it socialmediapublicanalysis/dozent:latest\n```\nor\n```bash\n$ docker run -it socialmediapublicanalysis/dozent:latest -h\n```\n\nDownload all tweets from March 12th, 2020 to March 15th, 2020\n```bash\n$ docker run -it socialmediapublicanalysis/dozent:latest python -m dozent -s 2020-05-12 -e 2020-05-15\n```\n\n# About the Data\n\n- Only collects Tweets in the English language\n- Tweets are stored in JSON format\n- Each day is a compressed file roughly 2.5 GB large or ~ 32 GB uncompressed\n- Each tweet has accompanying metadata about the tweet and user\n\n# Sample Data\n\nInterested in seeing what the data that Dozent collects looks like?\n\nCheck it out!\n\nhttps://dozent-tests.s3.amazonaws.com/sample_data.json\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "https://github.com/Social-Media-Public-Analysis/dozent/releases/tag/v1.0",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/Social-Media-Public-Analysis/dozent",
    "keywords": "TWITTER,SCRAPER,TWEET",
    "license": "GNU-3",
    "maintainer": "",
    "maintainer_email": "",
    "name": "dozent",
    "package_url": "https://pypi.org/project/dozent/",
    "platform": "",
    "project_url": "https://pypi.org/project/dozent/",
    "project_urls": {
      "Download": "https://github.com/Social-Media-Public-Analysis/dozent/releases/tag/v1.0",
      "Homepage": "https://github.com/Social-Media-Public-Analysis/dozent"
    },
    "release_url": "https://pypi.org/project/dozent/1.0/",
    "requires_dist": [
      "pySmartDL",
      "aria2p",
      "pytest",
      "pyfiglet",
      "numpy",
      "humanize"
    ],
    "requires_python": "",
    "summary": "Dozent is a powerful downloader that is used to download a ton of twitter data from the internet archive.",
    "version": "1.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 9392533,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "8a031ed1aff11e1af63501d588462fed96275058bf38d5ef6c24883365a963c0",
        "md5": "2dfe81d2a9a312da44b90abd583295ba",
        "sha256": "9d6c7a3f00c28c5b8a05b10c3084792945f7b6568e475322ee4fd24dd20b6114"
      },
      "downloads": -1,
      "filename": "dozent-1.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "2dfe81d2a9a312da44b90abd583295ba",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 25775,
      "upload_time": "2021-02-06T19:54:05",
      "upload_time_iso_8601": "2021-02-06T19:54:05.550536Z",
      "url": "https://files.pythonhosted.org/packages/8a/03/1ed1aff11e1af63501d588462fed96275058bf38d5ef6c24883365a963c0/dozent-1.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "d8baaf932571b97205c28f872ce557812296c2f43a50031141f6756dc498d052",
        "md5": "292005f9d015db85638ee35298d1a525",
        "sha256": "4dc7feac556cf6c550f4b1133763883181a8f82ed14560352171233445634772"
      },
      "downloads": -1,
      "filename": "dozent-1.0.tar.gz",
      "has_sig": false,
      "md5_digest": "292005f9d015db85638ee35298d1a525",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 15407,
      "upload_time": "2021-02-06T19:54:06",
      "upload_time_iso_8601": "2021-02-06T19:54:06.837511Z",
      "url": "https://files.pythonhosted.org/packages/d8/ba/af932571b97205c28f872ce557812296c2f43a50031141f6756dc498d052/dozent-1.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}