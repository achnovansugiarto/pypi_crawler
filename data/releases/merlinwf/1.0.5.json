{
  "info": {
    "author": "",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9"
    ],
    "description": "![alt text][logo]\n\n[logo]: https://github.com/LLNL/merlin/blob/master/docs/images/merlin.png \"Merlin logo\"\n\nWelcome to the Merlin README, a condensed guide. For more in-depth Merlin\n information, try our [web docs here](https://merlin.readthedocs.io/).\n\nSee the [CHANGELOG](CHANGELOG.md) for up-to-date details about features,\n fixes, etc.\n\n# A brief introduction to Merlin\nMerlin is a tool for running machine learning based workflows. The goal of\nMerlin is to make it easy to build, run, and process the kinds of large\nscale HPC workflows needed for cognitive simulation.\n\nAt its heart, Merlin is a distributed task queueing system, designed to allow complex\nHPC workflows to scale to large numbers of simulations \n(we've done 100 Million on the Sierra Supercomputer).\n\nWhy would you want to run that many simulations?\nTo become your own Big Data generator.\n\nData sets of this size can be large enough to train deep neural networks\nthat can mimic your HPC application, to be used for such\nthings as design optimization, uncertainty quantification and statistical\nexperimental inference. Merlin's been used to study inertial confinement\nfusion, extreme ultraviolet light generation, structural mechanics and\natomic physics, to name a few.\n\nHow does it work?\n\nIn essence, Merlin coordinates complex workflows through a persistent\nexternal queue server that lives outside of your HPC systems, but that\ncan talk to nodes on your cluster(s). As jobs spin up across your ecosystem,\nworkers on those allocations pull work from a central server, which\ncoordinates the task dependencies for your workflow. Since this coordination\nis done via direct connections to the workers (i.e. not through a file\nsystem), your workflow can scale to very large numbers of workers,\nwhich means a very large number of simulations with very little overhead.\n\nFurthermore, since the workers pull their instructions from the central\nserver, you can do a lot of other neat things, like having multiple\nbatch allocations contribute to the same work (think surge computing), or\nspecialize workers to different machines (think CPU workers for your\napplication and GPU workers that train your neural network). Another\nneat feature is that these workers can add more work back to central\nserver, which enables a variety of dynamic workflows, such as may be\nnecessary for the intelligent sampling of design spaces or reinforcement\nlearning tasks.\n\nMerlin does all of this by leveraging some key HPC and cloud computing\ntechnologies, building off open source components. It uses\n[maestro]( https://github.com/LLNL/maestrowf) to\nprovide an interface for describing workflows, as well as for defining\nworkflow task dependencies. It translates those dependencies into concrete\ntasks via [celery](https://docs.celeryproject.org/), \nwhich can be configured for a variety of backend\ntechnologies ([rabbitmq](https://www.rabbitmq.com) and\n[redis](https://redis.io) are currently supported). Although not\na hard dependency, we encourage the use of\n[flux](http://flux-framework.org) for interfacing with\nHPC batch systems, since it can scale to a very large number of jobs.\n\nThe integrated system looks a little something like this:\n\n<img src=\"docs/images/merlin_arch.png\" alt=\"a typical Merlin workflow\">\n\nIn this example, here's how it all works:\n\n1. The scientist describes her HPC workflow as a maestro DAG (directed acyclic graph)\n\"spec\" file `workflow.yaml`\n2. She then sends it to the persistent server with  `merlin run workflow.yaml` .\nMerlin translates the file into tasks.\n3. The scientist submits a job request to her HPC center. These jobs ask for workers via\nthe command `merlin run-workers workflow.yaml`.\n4. Coffee break.\n5. As jobs stand up, they pull work from the queue, making calls to flux to get the \nnecessary HPC resources.\n5. Later, workers on a different allocation, with GPU resources connect to the \nserver and contribute to processing the workload.\n\nThe central queue server deals with task dependencies and keeps the workers fed.\n\nFor more details, check out the rest of the [documentation](https://merlin.readthedocs.io/).\n\nNeed help? <merlin@llnl.gov>\n\n# Quick Start\n\nNote: Merlin only supports Python 3.6+.\n\n\nTo install the project and set up its virtualenv with dependencies, run:\n\n    $ make all\n    $ source venv_merlin_$SYS_TYPE_py$(PYVERSION)/bin/activate  \n    # activate.csh for cshrc (venv_merlin_$SYS_TYPE_py$(PYVERSION)) $\n\nThat's it.\n\nTo update the project:\n\n    $ make update\n\nTo run something a little more like what you're interested in,\nnamely a demo workflow that has simulation and machine-learning:\n\n    (venv) $ merlin run workflows/feature_demo/feature_demo.yaml\n    (venv) $ merlin run-workers workflows/feature_demo/feature_demo.yaml\n\nMore documentation on the example workflows can be found under\n'Running the Examples'.\n\n# Code of Conduct\nPlease note that Merlin has a\n[**Code of Conduct**](.github/CODE_OF_CONDUCT.md). By participating in\nthe Merlin community, you agree to abide by its rules.\n\n# Running the Examples\nExample workflows can be found in the `workflows/` directory.\nThey can be run with the command line interface (CLI).\n\n    # This processes the workflow and creates tasks on the server\n    (venv) $ merlin run workflows/feature_demo/feature_demo.yaml\n    # This launches workers that can process those tasks\n    (venv) $ merlin run-workers workflows/feature_demo/feature_demo.yaml\n\n\n# Using the CLI\nA good way to use merlin is through the command line interface (CLI).\nThis allows you to both create tasks to be run, as well as stand up workers\nfor those tasks.\n\nFor more information see:\n\n    (venv) $ merlin --help\n    (venv) $ merlin run --help\n    (venv) $ merlin run-workers --help\n    (venv) $ merlin purge --help\n\nRun a workflow specified by the given file.\n\n`(venv) $ merlin run <my_workflow.yaml>`\n\nStand up celery workers with queues specified in the workflow file.\n\n`(venv) $ merlin run-workers <my_workflow.yaml> [--echo] [--worker-args \"celery args\"] [--steps step1 stepN]`\n\nA note on arguments:\n\n`[--echo]` Just process the file and print the appropriate command.\n\n`[--worker-args \"celery args\"]` Passes arguments to the workers\n\n`[--steps step1 ... stepN]` Just give workers for specific steps in the file.\n\n\nTo remove tasks from the task server, use the purge option:\n\n`(venv) $ merlin purge <my_workflow.yaml>`\n\nMore information can be obtained by running:\n\n    (venv) $ merlin purge --help\n\n    usage: merlin purge [-h] [-f] [--steps PURGE_STEPS [PURGE_STEPS ...]]\n                        specification\n\n    positional arguments:\n      specification         Path to a Merlin YAML spec file\n\n    optional arguments:`\n      -h, --help            Show this help message and exit\n      -f, --force           Purge the tasks without confirmation (default: False)\n      --steps PURGE_STEPS [PURGE_STEPS ...]\n                            The specific steps in the YAML file from which you\n                            want to purge the queues. The input is a space\n                            separated list. (default: None)\n\n## Some real-life examples:\n\nRun workers for the feature_demo.yaml file:\n\n    (venv) $ merlin run-workers workflows/feature_demo/feature_demo.yaml --worker-args \"--prefetch-multiplier 1\"\n    $ celery worker -A merlin --prefetch-multiplier 1 -Q merlin,hello_queue,post_process_queue\n\nJust run workers for the hello step in the file:\n\n    (venv) $ merlin run-workers workflows/feature_demo/feature_demo.yaml --steps hello\n    $ celery worker -A merlin -Q hello_queue\n\nAdding `--echo` to a command will just print out the command, so you can move this command into more complex workflows.\n\nFor instance, to put into a batch script, or run many workers you can do stuff like this:\n\n    $ srun -n 5 `merlin run-workers workflows/feature_demo/feature_demo.yaml --echo --steps hello`\n\nWhich is equivalent to\n\n    $ srun -n 5 celery worker -A merlin -Q hello_queue\n\nGenerate a template spec file.\n\n`(venv)` $ merlin template <path/for/spec>\n\nShow pip and python versions and locations. This is useful for troubleshooting.\n\n`(venv) $ merlin info`\n\nDisplay version number.\n\n`(venv) $ merlin -v` or `(venv) $ merlin --version`\n\nDisplay these CLI options in-console.\n\n`(venv) $ merlin -h` or `(venv) $ merlin --help`\n\n# Custom Setup\n\n##  Create and activate a Virtual Environment\n\n    $ python -m virtualenv venv\n    $ source venv/bin/activate  # Or activate.csh for cshrc.\n    (venv) $\n\n## Upgrade Pip\n\n    (venv) $ pip install -U pip\n\n## Add requirements to your environment\n\n    # This will install all package dependencies into the virtualenv.\n    (venv) $ pip install -r requirements.txt\n    (venv) $ pip install -e .\n\n## Adding MySQL packages\n\nIf using MySQL, then the following requirements should also be installed:\n\n    (venv) $ pip install -r requirements/mysql.txt\n\n## Celery\n\nCelery is a distributed task queue that helps spread work over threads and machines.\nBefore running a distributed job, use:\n\n    (venv) $ celery worker -A merlin -l INFO\n\nFor very small tests this may done on a login node, but otherwise celery workers should\nbe scheduled via the system's batch.\nSome useful flags are: `--concurrency N`, `-Ofair`, `--prefetch-multiplier M`.\nFor more details, see the batch scripts in `merlin/examples/` or type `celery -h` for help.\n\n# redis\n\nThe redis system is currently being used to implement the backend server on\nrabbit.llnl.gov. This same redis system can be used as the frontend broker\nand can also be run on the local allocation instead of a remote server. The\ninstructions below detail the method for implementing a local broker or\nbackend.\n\n## Build redis\n\nDownload the code from:\n    https://redis.io/download\n\nuntar the code\n\n    tar xvf redis-4.0.11.tar.gz\n\nType make in the top level redis code directory.\n\n    make\n\nThe executables will be in src.\n\n## Local redis server\n\nIn this example, the same redis server is used as the broker and\nbackend at port 6397 of localhost.\n\n### Start the server\n\nRun redis-server <file> on an allocation node using the default config.\n\n    redis-server redis.conf\n\n### Configure Merlin to use the local redis server\n\nEdit the app.yaml file and use these configurations\n\n    broker:\n        name: redis\n        server: localhost\n        port: 6379\n\n    results_backend:\n        name: redis\n        server: localhost\n        port: 6379\n\n## Local redis+socket\n\nThis configuration will use redis+socket for the broker and the same redis as the backend\nserver connection to port 6397 on the localhost.\n\nEdit the redis.conf file to turn on the socket interface, this method\nonly works on a single node:\n\n    unixsocket /<socket path>/redis.sock\n    unixsocketperm 700\n\n### Start the server\n\nRun redis-server <file> on an allocation node.\n\n    redis-server redis.conf\n\n### Configure Merlin to use the local redis server\n\nEdit the `app.yaml` file and use these configurations:\n\n    broker:\n        name: redis+socket\n        path: /<socket path>/redis.sock\n        socketname: redis.sock\n\n    results_backend:\n        name: redis\n        server: localhost\n        port: 6379\n\n# Testing\n## Unit tests\n* `(venv) $ make version-tests` or `(venv) $ tox` runs Merlin tests in different Python version environments. See `tox.ini` file for details on what this runs.\n* From the main directory, `(venv) $ py.tests merlin/` runs Merlin unit tests.\n## Style checks\n* `(venv) $ make check-style` or `(venv) $ pylint merlin/` checks for PEP8 infractions in our Python code. \nTo customize what is tested for, see `.pylintrc` and `tox.ini` files.\n\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/LLNL/merlin",
    "keywords": "machine learning workflow",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "merlinwf",
    "package_url": "https://pypi.org/project/merlinwf/",
    "platform": "",
    "project_url": "https://pypi.org/project/merlinwf/",
    "project_urls": {
      "Homepage": "https://github.com/LLNL/merlin"
    },
    "release_url": "https://pypi.org/project/merlinwf/1.0.5/",
    "requires_dist": [
      "cached-property",
      "celery[redis] (>=4.3.0)",
      "coloredlogs",
      "cryptography",
      "maestrowf (>=1.1.6)",
      "numpy",
      "parse",
      "psutil (>=5.1.0)",
      "pyyaml (>=5.1.2)",
      "tabulate",
      "importlib-resources ; python_version < \"3.7\"",
      "mysql-connector-python-rf ; extra == 'mysql'",
      "pymysql ; extra == 'mysql'"
    ],
    "requires_python": "",
    "summary": "The building blocks of workflows!",
    "version": "1.0.5",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 9730208,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "c339afcde7a1a07a228d3479e6e8dfcbe51a8b950433b042457a3a085be839f3",
        "md5": "82ca44cd91d962482843a6a0c41ab02d",
        "sha256": "9803a5aac146064c570f1257b3d414edf3bc8304011395917e2b92db9c0190e4"
      },
      "downloads": -1,
      "filename": "merlinwf-1.0.5-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "82ca44cd91d962482843a6a0c41ab02d",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 99679,
      "upload_time": "2019-12-06T18:16:30",
      "upload_time_iso_8601": "2019-12-06T18:16:30.252172Z",
      "url": "https://files.pythonhosted.org/packages/c3/39/afcde7a1a07a228d3479e6e8dfcbe51a8b950433b042457a3a085be839f3/merlinwf-1.0.5-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "201d5e9d05ee24cedfbd5f8d4f9aaed372072256151d08f6c12bf23bafe40640",
        "md5": "cbd09e693118065bdcf16fab3eba81b9",
        "sha256": "d66f50eac84ff9d7aa484f2d9655dc60f0352196d333284d81b6623a6f0aa180"
      },
      "downloads": -1,
      "filename": "merlinwf-1.0.5.tar.gz",
      "has_sig": false,
      "md5_digest": "cbd09e693118065bdcf16fab3eba81b9",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 61584,
      "upload_time": "2019-12-06T18:16:32",
      "upload_time_iso_8601": "2019-12-06T18:16:32.096023Z",
      "url": "https://files.pythonhosted.org/packages/20/1d/5e9d05ee24cedfbd5f8d4f9aaed372072256151d08f6c12bf23bafe40640/merlinwf-1.0.5.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}