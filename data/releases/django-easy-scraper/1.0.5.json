{
  "info": {
    "author": "dearopen",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Django Easy Scraper\n\nAn standalone django app that can be used/intigrated with both django and no-django application easily. the scraping mechanism is  on `Regular Expression` and `xpath` which is mean you can use what you are familiar with very easily.\n\nIt requires to install python `requests` modules\n\n\n## Install\n\n`pip install django-easy-scraper`\n\n## Basic Uses\n\nif you use regex:\n```\nfrom django_easy_scraper import scraper\n\nclass ScrapeExampleDotCom(scraper.Scraper):\n\n    regex_fields = {\n        'price': \"Write Your Regex pattern for price here\",\n        'title': \"Write your regex pattern for title here\",\n        # Like above way you can add as much fields/keys as you want\n    }\n\n```\n\nif you use xpath:\n\n```\nfrom django_easy_scraper import scraper\n\nclass ScrapeExampleDotCom(scraper.Scraper):\n\n    xpath_fields = {\n        'price': \"Write Your xpath pattern for price here\",\n        'title': \"Write your xpath pattern for title here\",\n        # Like above way you can add as much fields/keys as you want\n    }\n\n```\n\n\n### Scrape now\n```\nurl = 'www.example.com/bla-bla-details-page/\ndata = ScrapeExampleDotCom.regex_url_scraper(url)\n\nprint(data)\n```\nand the response should look like this if your regex pattern are correct:\n```\n{\n    'price': 4,\n    'title': 'an scraped title',\n}\n```\n\n`regex_url_scraper` method always gives you json response,\n\nSo if you add many regex pattern in `regex_fields`, it will give you response that number of dictionary key with result that you added in that dictionary.\n\n\n# Multiple Sites Scraping together\n\nYou don't need to call different method for different site all the time !! Just call once and scrape all, something fun, right?\n\n### Like you are gonna scrape three sites:\n> www.example.com\n\n> www.exampletwo.com\n\n> www.examplethree.com\n\n\n\nBut how will those site product scrape automatically, it scares you ? \n\n- Wirte Regex pattern for all above site with the fields that you want to scrape:\n\n\n```\nfrom django_easy_scraper import scraper\n\nclass ScrapeExampleDotCom(scraper.Scraper):\n    regex_fields = {\n        'price': \"Write Your Regex pattern for price here\",\n        'title': \"Write your regex pattern for title here\",\n        # Like above way you can add as much fields/keys as you want\n    }\n\nclass ScrapeExampleTwo(scraper.Scraper):\n    regex_fields = {\n        'price': \"Write Your Regex pattern for price here\",\n        'title': \"Write your regex pattern for title here\",\n        # Like above way you can add as much fields/keys as you want\n    }\n\nclass ScrapeExampleThree(scraper.Scraper):\n    regex_fields = {\n        'price': \"Write Your Regex pattern for price here\",\n        'title': \"Write your regex pattern for title here\",\n        # Like above way you can add as much fields/keys as you want\n    }\n\n\n```\n\n\nYou have written regular expression for you all the site you are gonna scrape,\n\nNow it's time use our `Switch` class that will route your script/class based on the site you are gonna scrape? Cool, right ? !!\n\nIt's where the magic really begins:\n\nJust place all your class in the dictionary `switcher`.\n\n\n> Important Note:\n\n`key` name should be domain name, pure domain name, no www or http or slash, dont add anything prefix/suffix\n`value` should be the class of that domain you have written for and place it's method `regex_url_scraper\n\n```\nfrom django_easy_scraper import switch\n\nclass Switch(switch.BaseSwitch):\n    switcher = {\n        'example.com': ScrapeExampleDotCom.regex_url_scraper,\n        'exampletwo.com': ScrapeExampleTwo.regex_url_scraper,\n        'examplethree.com': ScrapeExampleThree.regex_url_scraper,\n    }\n\n```\n\n> If you use xpath, you have pass `xpath_scraper` instead of `regex_url_scraper`\n\nSo you have done routing your script/class based on the url it gets.\n\n### Get response data as python dictionary like above site:\n\n```\nurl = 'Any of site you have written class for the site and added in switch class'\n\nresponse = Switch.get_data(url=url, raise_exception=False)\n\nprint(response) # Will give you an object of data that you trying to scrape\n\n```\n\nSwitch class is giving you facilities to route your scraping class automacally based whatever site link pass to it's `get_data` method.\n\n`get_data` method's `raise_exception` is it handle if you want to raise excepiton when your expected fields not found\n\n\n### Got an issue ?\nPlease open an issue on our github repo: https://github.com/dearopen/django-easy-scraper\n\nDon't forget to star to this project if you like this.\n\nHappy Scraping !!",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/dearopen/django-easy-scraper",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "django-easy-scraper",
    "package_url": "https://pypi.org/project/django-easy-scraper/",
    "platform": "",
    "project_url": "https://pypi.org/project/django-easy-scraper/",
    "project_urls": {
      "Homepage": "https://github.com/dearopen/django-easy-scraper"
    },
    "release_url": "https://pypi.org/project/django-easy-scraper/1.0.5/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "Dango app to scrape web page",
    "version": "1.0.5",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8730795,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "e11bf90f16ea4905c446e6c788382bb5509dda68aea305b1e0211f77f56f6f59",
        "md5": "74ce8264b875bc4b978282b83b4905a2",
        "sha256": "8a959c1c696e11b31acdb18f553ce757c17d87f28795e3f84942cfed1ab80f7c"
      },
      "downloads": -1,
      "filename": "django-easy-scraper-1.0.5.tar.gz",
      "has_sig": false,
      "md5_digest": "74ce8264b875bc4b978282b83b4905a2",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 4764,
      "upload_time": "2020-11-23T18:31:18",
      "upload_time_iso_8601": "2020-11-23T18:31:18.459259Z",
      "url": "https://files.pythonhosted.org/packages/e1/1b/f90f16ea4905c446e6c788382bb5509dda68aea305b1e0211f77f56f6f59/django-easy-scraper-1.0.5.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}