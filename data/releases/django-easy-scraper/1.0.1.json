{
  "info": {
    "author": "dearopen",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Django Easy Scraper\n\nAn standalone django app that can be used/intigrated with both django and no-django application easily. the scraping mechanism is fully based on `Regular Expression` but you can extends based on what you are familiar with very easily.\n\nIt requires to install python `requests` modules\n\n\n## Install\n\n`pip install django-easy-scraper`\n\n## Basic Uses\n\n```\nfrom django_easy_scraper import scraper\n\nclass ScrapeExampleDotCom(scraper.Scraper):\n\n    regex_fields = {\n        'price': \"Write Your Regex pattern for price here\",\n        'title': \"Write your regex pattern for title here\",\n        # Like above way you can add as much fields/keys as you want\n    }\n\n```\n\n### Scrape now\n```\nurl = 'www.example.com/bla-bla-details-page/\ndata = ScrapeExampleDotCom.regex_url_scraper(url)\n\nprint(data)\n```\nand the response should look like this if your regex pattern are correct:\n```\n{\n    'price': 4,\n    'title': 'an scraped title',\n}\n```\n\n`regex_url_scraper` method always gives you json response,\n\nSo if you add many regex pattern in `regex_fields`, it will give you response that number of dictionary key with result that you added in that dictionary.\n\n\n# Multiple Sites Scraping together\n\nYou don't need to call different method for different site all the time !! Just call once and scrape all, something fun, right?\n\n### Like you are gonna scrape three sites:\n> www.example.com\n\n> www.exampletwo.com\n\n> www.examplethree.com\n\n\n\nBut how will those site product scrape automatically, it scares you ? \n\n- Wirte Regex pattern for all above site with the fields that you want to scrape:\n\n\n```\nfrom django_easy_scraper import scraper\n\nclass ScrapeExampleDotCom(scraper.Scraper):\n    regex_fields = {\n        'price': \"Write Your Regex pattern for price here\",\n        'title': \"Write your regex pattern for title here\",\n        # Like above way you can add as much fields/keys as you want\n    }\n\nclass ScrapeExampleTwo(scraper.Scraper):\n    regex_fields = {\n        'price': \"Write Your Regex pattern for price here\",\n        'title': \"Write your regex pattern for title here\",\n        # Like above way you can add as much fields/keys as you want\n    }\n\nclass ScrapeExampleThree(scraper.Scraper):\n    regex_fields = {\n        'price': \"Write Your Regex pattern for price here\",\n        'title': \"Write your regex pattern for title here\",\n        # Like above way you can add as much fields/keys as you want\n    }\n\n\n```\n\n\nYou have written regular expression for you all the site you are gonna scrape,\n\nNow it's time use our `Switch` class that will route your script/class based on the site you are gonna scrape? Cool, right ? !!\n\nIt's where the magic really begins:\n\nJust place all your class in the dictionary `switcher`.\n\n\n> Important Note:\n\n`key` name should be domain name, pure domain name, no www or http or slash, dont add anything prefix/suffix\n`value` should be the class of that domain you have written for and place it's method `regex_url_scraper\n\n```\nfrom django_easy_scraper import switch\n\nclass Switch(switch.BaseSwitch):\n    switcher = {\n        'example.com': ScrapeExampleDotCom.regex_url_scraper,\n        'exampletwo.com': ScrapeExampleTwo.regex_url_scraper,\n        'examplethree.com': ScrapeExampleThree.regex_url_scraper,\n    }\n\n```\n\nSo you have done routing your script/class based on the url it gets.\n\n### Get response data as python dictionary like above site:\n\n```\nurl = 'Any of site you have written class for the site and added in switch class'\n\nresponse = Switch.get_data(url=url, raise_exception=False)\n\nprint(response) # Will give you an object of data that you trying to scrape\n\n```\n\nSwitch class is giving you facilities to route your scraping class automacally based whatever site link pass to it's `get_data` method.\n\n`get_data` method's `raise_exception` is it handle if you want to raise excepiton when your expected fields not found\n\n\n### Got an issue ?\nPlease open an issue on our github repo: https://github.com/dearopen/django-easy-scraper\n\nDon't forget to star to this project if you like this.\n\nHappy Scraping !!",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/dearopen/django-easy-scraper",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "django-easy-scraper",
    "package_url": "https://pypi.org/project/django-easy-scraper/",
    "platform": "",
    "project_url": "https://pypi.org/project/django-easy-scraper/",
    "project_urls": {
      "Homepage": "https://github.com/dearopen/django-easy-scraper"
    },
    "release_url": "https://pypi.org/project/django-easy-scraper/1.0.1/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "Dango app to scrape web page",
    "version": "1.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8730795,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "3cc45bed585ebd7b9ce0226e11d034c1abf813518d6632d345295914b0d85458",
        "md5": "e415165ff9929beed8c2b025bfa39b14",
        "sha256": "fb92520e35bea4e9ddb0e4872146b31ece5bc8d821b5f0d6b7e6cb427b6849a1"
      },
      "downloads": -1,
      "filename": "django-easy-scraper-1.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "e415165ff9929beed8c2b025bfa39b14",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 4556,
      "upload_time": "2020-11-22T11:57:37",
      "upload_time_iso_8601": "2020-11-22T11:57:37.342579Z",
      "url": "https://files.pythonhosted.org/packages/3c/c4/5bed585ebd7b9ce0226e11d034c1abf813518d6632d345295914b0d85458/django-easy-scraper-1.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}