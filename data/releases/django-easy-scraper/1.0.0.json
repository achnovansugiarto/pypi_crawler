{
  "info": {
    "author": "dearopen",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Django Easy Scraper\n\nAn standalone django app that can be used/intigrated with both django and no-django application easily. the scraping mechanism is fully based on `Regular Expression` but you can extends based on what you are familiar with very easily.\n\nIt requires to install python `requests` modules\n\n\n## Install\n\n`pip install django-easy-scraper`\n\n## Basic Uses\n\n```\nfrom django_easy_scraper import scraper\n\nclass ScrapeExampleDotCom(scraper.Scraper):\n\n    regex_fields = {\n        'price': \"Write Your Regex pattern for price here\",\n        'title': \"Write your regex pattern for title here\",\n        # Like above way you can add as much fields/keys as you want\n    }\n\n```\n\n### Scrape now\n```\nurl = 'www.example.com/bla-bla-details-page/\ndata = ScrapeExampleDotCom.regex_url_scraper(url)\n\nprint(data)\n```\nand the response should look like this if your regex pattern are correct:\n```\n{\n    'price': 4,\n    'title': 'an scraped title',\n}\n```\n\n`regex_url_scraper` method always gives you json response,\n\nSo if you add many regex pattern in `regex_fields`, it will give you response that number of json key with result that you added in that fields.\n\n\n# Multiple Sites Scraping together\n\nYou don't need to call different method for different site all the time !! Just call once and scrape all, something fun, right?\n\n### Like you are gonna scrape four sites:\n> www.example.com\n\n> www.amazonxsite.com\n\n> www.newyorktimesnoexist.com\n\n> www.walmaaaart.com\n\nBut how will those site product scrape automatically, curious ? \n\n- Wirte Regex patter for all above site and fields/data you want:\n\n\n```\nfrom django_easy_scraper import scraper\n\nclass ScrapeExampleDotCom(scraper.Scraper):\n    regex_fields = {\n        'price': \"Write Your Regex pattern for price here\",\n        'title': \"Write your regex pattern for title here\",\n        # Like above way you can add as much fields/keys as you want\n    }\n\nclass ScrapeAmazonxSite(scraper.Scraper):\n    regex_fields = {\n        'price': \"Write Your Regex pattern for price here\",\n        'title': \"Write your regex pattern for title here\",\n        # Like above way you can add as much fields/keys as you want\n    }\n\nclass ScrapeNewYorkTimeNoExist(scraper.Scraper):\n    regex_fields = {\n        'price': \"Write Your Regex pattern for price here\",\n        'title': \"Write your regex pattern for title here\",\n        # Like above way you can add as much fields/keys as you want\n    }\n\nclass ScrapeWalmaaartDotCom(scraper.Scraper):\n    regex_fields = {\n        'price': \"Write Your Regex pattern for price here\",\n        'title': \"Write your regex pattern for title here\",\n        # Like above way you can add as much fields/keys as you want\n    }\n\n```\n\n\nYou have written regular expression for you all the site you are gonna scrape,\n\nNow it's time use your `Switch` class that will route your script/class based on the site you are gonna scrape? It's complex? No !!\n\nHere where the magic begins:\n\nJust place all your class in the dict.\n\n\n> Important Note:\n\n`key` name should be domain name, pure domain name, no www or http or slash, dont add anything prefix/suffix\n`value` should be the class of that domain you have written for and place it's method `regex_url_scraper\n\n```\nfrom django_easy_scraper import switch\n\nclass Switch(switch.BaseSwitch):\n    switcher = {\n        'amazonxsite.com': ScrapeElgiganten.regex_url_scraper,\n        'amazonxsite.com': ScrapeAmazonxSite.regex_url_scraper,\n        'newyorktimesnoexist.com': ScrapeNewYorkTimeNoExist.regex_url_scraper,\n        'walmaaaart.com': ScrapeWalmaaartDotCom.regex_url_scraper,\n    }\n\n```\n\nSo you have done routing your script/class based on the url it gets.\n\n### Get response data as json like above site:\n\n```\nurl = 'Any of site you have written class for the site and added in switch class'\n\nresponse = Switch.get_data(url=url, raise_exception=False)\n\nprint(response) # Will give you an object of data that you trying to scrape\n\n```\n\nSwitch class is giving you facilities to route your scraping class automacally based whatever site link pass to it's method.\n\n\n### Got an issue ?\nPlease open an issue on our github repo: https://github.com/dearopen/django-easy-scraper\n\nDon't forget to star to this project if you like this.\n\nHappy Scraping !!",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/dearopen/django-easy-scraper",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "django-easy-scraper",
    "package_url": "https://pypi.org/project/django-easy-scraper/",
    "platform": "",
    "project_url": "https://pypi.org/project/django-easy-scraper/",
    "project_urls": {
      "Homepage": "https://github.com/dearopen/django-easy-scraper"
    },
    "release_url": "https://pypi.org/project/django-easy-scraper/1.0.0/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "Dango app to scrape web page",
    "version": "1.0.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8730795,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "14d0d5975871f312aa7d0c14ecfc23e6d1be26ea8867c3d017d57d54785e9db5",
        "md5": "68feb91feff3afcd528c2b915f1669eb",
        "sha256": "6c796ffcdfb6fee775480a76c4fef5e2524ad44971d7f78ef1c56251b4c152c2"
      },
      "downloads": -1,
      "filename": "django-easy-scraper-1.0.0.tar.gz",
      "has_sig": false,
      "md5_digest": "68feb91feff3afcd528c2b915f1669eb",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 4560,
      "upload_time": "2020-11-21T21:59:12",
      "upload_time_iso_8601": "2020-11-21T21:59:12.037593Z",
      "url": "https://files.pythonhosted.org/packages/14/d0/d5975871f312aa7d0c14ecfc23e6d1be26ea8867c3d017d57d54785e9db5/django-easy-scraper-1.0.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}