{
  "info": {
    "author": "Wei OUYANG",
    "author_email": "wei.ouyang@cri-paris.org",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Intended Audience :: Developers",
      "Intended Audience :: Information Technology",
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Cython",
      "Programming Language :: Other Scripting Engines",
      "Programming Language :: Python :: 2",
      "Programming Language :: Python :: 2.6",
      "Programming Language :: Python :: 2.7",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.2",
      "Programming Language :: Python :: 3.3",
      "Programming Language :: Python :: 3.4",
      "Programming Language :: Python :: 3.5",
      "Topic :: Software Development"
    ],
    "description": "# Lutorpy\n\nLutorpy is a libray built for deep learning with torch in python,  by a two-way bridge between Python/Numpy and Lua/Torch, you can use any Torch modules(nn, rnn etc.) in python, and easily convert variables(array and tensor) between torch and numpy.\n\n# Features\n\n* import any lua/torch module to python and use it like python moduels\n* use lua objects directly in python, conversion are done automatically\n* create torch tensor from numpy array with `torch.fromNumpyArray(arr)`\n* use `tensor.asNumpyarray()` to convert a torch tensor to a numpy array with memory sharing\n* support zero-base indexing (lua uses 1-based indexing)\n* automatic prepending self to function by `\"._\"` syntax, easily convert `\":\"` operator in lua to python\n\n\n#### * Interested in Lutorpy project? Please let us know by giving a star.\n\n# Convert from Lua to Python/Lutorpy\n```lua\n-- lua code                             # python code (with lutorpy)\n--                                      import lutorpy as lua\nrequire \"nn\"                    ===>    require(\"nn\")\nmodel = nn.Sequential()         ===>    model = nn.Sequential()\n-- use \":\" to access add        ===>    # use \"._\" to access add\nmodel:add(nn.Linear(10, 3))     ===>    model._add(nn.Linear(10, 3))\n--                                      import numpy as np\nx = torch.Tensor(10):zero()     ===>    arr = np.zeros(10)\n-- torch style(painful?)        ===>    # numpy style(elegent?) \nx:narrow(1, 2, 6):fill(1)       ===>    arr[1:7] = 1\n--                                      # convert numpy array to a torch tensor\n--                                      x = torch.fromNumpyArray(arr)\n--                                      # or you can still use torch style\nx:narrow(1, 7, 2):fill(2)       ===>    x._narrow(1, 7, 2)._fill(2)\n-- 1-based index                ===>    # 0-based index\nx[10] = 3                       ===>    x[9] = 3\ny = model:forward(x)            ===>    y = model._forward(x)\n--                                      # you can convert y to a numpy array\n--                                      yArr = y.asNumpyArray()\n```\n\n# Quick Start\n\n## basic usage\n``` python\nimport lutorpy as lua\nimport numpy as np\n\n## use require(\"MODULE\") to import lua modules\nrequire(\"nn\")\n\n## run lua code in python with minimal modification:  replace \":\" to \"._\"\nt = torch.DoubleTensor(10,3)\nprint(t._size()) # the corresponding lua version is t:size()\n\n## or, you can use numpy array\nxn = np.random.randn(100)\n## convert the numpy array into torch tensor\nxt = torch.fromNumpyArray(xn)\n\n## convert torch tensor to numpy array\n### Note: the underlying object are sharing the same memory, so the conversion is instant\narr = xt.asNumpyArray()\nprint(arr.shape)\n```\n## example 1: multi-layer perception\n``` python\n## minimal example of multi-layer perception(without training code)\nmlp = nn.Sequential()\nmlp._add(nn.Linear(100, 30))\nmlp._add(nn.Tanh())\nmlp._add(nn.Linear(30, 10))\n\n## generate a numpy array and convert it to torch tensor\nxn = np.random.randn(100)\nxt = torch.fromNumpyArray(xn)\n## process with the neural network\nyt = mlp._forward(xt)\nprint(yt)\n\n## or for example, you can plot your result with matplotlib\nyn = yt.asNumpyArray()\nimport matplotlib.pyplot as plt\nplt.plot(yn)\n```\n## example 2: load pre-trained model with torch and apply it\n```python\nimport numpy as np\nimport lutorpy as lua\n\nmodel = torch.load('PATH TO YOUR MODEL FILE')\n\n# generate your input data with numpy\narr = np.random.randn(100)\n\n# convert your numpy array into torch tensor\nx = torch.fromNumpyArray(arr)\n\n# apply model forward method with \"._\" syntax(which is equivalent to \":\" in lua)\ny = model._forward(x)\n```\n\nYou can also have a look at the step-by-step tutorial and more complete example.\n\n# Installation\nYou need to install torch before you start\n``` bash\n# in a terminal, run the commands WITHOUT sudo\ngit clone https://github.com/torch/distro.git ~/torch --recursive\ncd ~/torch; bash install-deps;\n./install.sh\n```\nThen, you can use luarocks to install torch/lua modules\n``` bash\nluarocks install nn\n```\nIf you don't have numpy installed, install it by pip\n``` bash\npip install numpy\n```\nNow, we are ready to install lutorpy\n``` bash\ngit clone https://github.com/imodpasteur/lutorpy.git\ncd lutorpy\nsudo python setup.py install\n```\n#### note that it has been tested on ubuntu, please report issue if you encountered error.\n\n\n# Step-by-step tutorial\n\n## import lutorpy\n\n``` python\nimport lutorpy as lua\n# setup runtime and use zero-based index(optional, enabled by default)\nlua.LuaRuntime(zero_based_index=True)\n\n### note: zero-based index will only work getter operator such as \"t[0]\", for torch function like narrow, you still need 1-based indexing.\n```\n## hello world\n\n``` python\nlua.execute(' greeting = \"hello world\" ')\nprint(greeting)\n```\n\n###  Alternatively you could also switch back to one-based indexing\n\nNote that if you do this, all the following code should change acorrdingly.\n\n```\nlua.LuaRuntime(zero_based_index=False)\n```\n\n## execute lua code\n\n``` python\na = lua.eval(' {11, 22} ') # define a lua table with two elements\nprint(a[0])\n\n```\n\n## use torch\n``` python\nrequire(\"torch\")\nz = torch.Tensor(4,5,6,2)\nprint(torch.isTensor(z))\ns = torch.LongStorage(6)\nprint(torch.type(s))\n```\n\n## convert torch tensor to numpy array\n\n\n``` python\nrequire('torch')\nt = torch.randn(10,10)\nprint(t)\narr = t.asNumpyArray()\nprint(arr)\n\n```\n                                \n## convert numpy array to torch tensor\n\nNote: both torch tensor and cuda tensor are supported.\n\n``` python\narr = np.random.randn(100)\nprint(arr)\nt = torch.fromNumpyArray(arr)\nprint(t)\n\n```\n\n## convert to/from cudaTensor\n``` python\nrequire('cutorch')\ncudat = torch.CudaTensor(10,10)\n#convert cudaTensor to numpy array\narr = cudat.asNumpyArray()\nprint(arr)\n\narr = np.random.randn(100)\nprint(arr)\nt = torch.fromNumpyArray(arr)\ncudat = t._cuda()\nprint(cudat)\n```\n\n## load image and use nn module\n``` python\nrequire(\"image\")\nimg_rgb = image.lena()\nprint(img_rgb.size(img_rgb))\nimg = image.rgb2y(img_rgb)\nprint(img.size(img))\n\n# use SpatialConvolution from nn to process the image\nrequire(\"nn\")\nn = nn.SpatialConvolution(1,16,12,12)\nres = n.forward(n, img)\nprint(res.size(res))\n\n```\n\n## build a simple model\n\n``` python\nmlp = nn.Sequential()\nmodule = nn.Linear(10, 5)\nmlp.add(mlp, module)\nprint(module.weight)\nprint(module.bias)\nprint(module.gradWeight)\nprint(module.gradBias)\nx = torch.Tensor(10) #10 inputs\n# pass self to the function\ny = mlp.forward(mlp, x)\nprint(y)\n```\n\n## prepending 'self' as the first argument automatically\nIn lua, we use syntax like 'mlp:add(module)' to use a function without pass self to the function. But in python, it's done by default, there are two ways to prepend 'self' to a lua function in lutorpy.\n\nThe first way is inline prepending by add '_' to before any function name, then it will try to return a prepended version of the function:\n``` python\nmlp = nn.Sequential()\nmodule = nn.Linear(10, 5)\n\n# lua style\nmlp.add(mlp, module)\n\n# inline prepending\nmlp._add(module) # equaliant to mlp:add(module) in lua\n```\n\n## build another model and training it\n\nTrain a model to perform XOR operation (see [this torch tutorial](https://github.com/torch/nn/blob/master/doc/training.md)).\n\n``` python\nrequire(\"nn\")\nmlp = nn.Sequential()\nmlp._add(nn.Linear(2, 20)) # 2 input nodes, 20 hidden nodes\nmlp._add(nn.Tanh())\nmlp._add(nn.Linear(20, 1)) # 1 output nodes\ncriterion = nn.MSECriterion() \nfor i in range(2500):\n    # random sample\n    input= torch.randn(2)    # normally distributed example in 2d\n    output= torch.Tensor(1)\n    if input[0]*input[1] > 0:  # calculate label for XOR function\n        output[0] = -1 # output[0] = -1\n    else:\n        output[0] = 1 # output[0] = 1\n    # feed it to the neural network and the criterion\n    criterion._forward(mlp._forward(input), output)\n    # train over this example in 3 steps\n    # (1) zero the accumulation of the gradients\n    mlp._zeroGradParameters()\n    # (2) accumulate gradients\n    mlp._backward(input, criterion.backward(criterion, mlp.output, output))\n    # (3) update parameters with a 0.01 learning rate\n    mlp._updateParameters(0.01)\n\n```\n## test the model\n\n``` python\n\nx = torch.Tensor(2)\nx[0] =  0.5; x[1] =  0.5; print(mlp._forward(x))\nx[0] =  0.5; x[1] = -0.5; print(mlp._forward(x))\nx[0] = -0.5; x[1] =  0.5; print(mlp._forward(x))\nx[0] = -0.5; x[1] = -0.5; print(mlp._forward(x))\n\n```\n\n# Details of implementation\n\n * For applying tensor.asNumpyArray() method to a torch tensor, if the tensor is contiguous, the memory will be shared between numpy array and torch tensor, if the tensor is not contiguous, a contiguous clone of the tensor will be used, so the created numpy array won't share memory with the old tensor.\n \n * For torch.fromNumpyArray(), there will be no memory sharing between the numpy array and the tenosr created.\n\n\n# More details about using lua in python\nLutorpy is built upon [lupa](https://github.com/scoder/lupa), there are more features provided by lupa could be also useful, please check it out.\n\n# Bug tracker\n\nHave a bug? Please create an issue here on GitHub at https://github.com/imodpasteur/lutorpy/issues.\n\n# Support lutorpy project\nLike lutorpy project? It solved your problem? Let us know by giving lutorpy project a star, so we know how many people are intereted, thank you.\n\n# Acknowledge\n\nThis is a project inspired by [lunatic-python](https://github.com/bastibe/lunatic-python) and [lupa](https://github.com/scoder/lupa), and it's based on lupa.",
    "description_content_type": null,
    "docs_url": null,
    "download_url": "UNKNOWN",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/oeway/lutorpy",
    "keywords": null,
    "license": "MIT style",
    "maintainer": null,
    "maintainer_email": null,
    "name": "lutorpy",
    "package_url": "https://pypi.org/project/lutorpy/",
    "platform": "UNKNOWN",
    "project_url": "https://pypi.org/project/lutorpy/",
    "project_urls": {
      "Download": "UNKNOWN",
      "Homepage": "https://github.com/oeway/lutorpy"
    },
    "release_url": "https://pypi.org/project/lutorpy/1.3.2/",
    "requires_dist": null,
    "requires_python": null,
    "summary": "Python wrapper for torch and Lua/LuaJIT",
    "version": "1.3.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 2418528,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "09416ebee698e2221779a79dcb9fe5f4ce42bbdd880b49cc8a521fccfb9504d5",
        "md5": "e5963ff7ce81d719808dde6a28e0228f",
        "sha256": "74dc959465741f67ca129febc2cd852dd661ea707c8acdb56fea24f104e421c8"
      },
      "downloads": -1,
      "filename": "lutorpy-1.3.2.tar.gz",
      "has_sig": false,
      "md5_digest": "e5963ff7ce81d719808dde6a28e0228f",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 216491,
      "upload_time": "2016-07-25T16:20:48",
      "upload_time_iso_8601": "2016-07-25T16:20:48.701857Z",
      "url": "https://files.pythonhosted.org/packages/09/41/6ebee698e2221779a79dcb9fe5f4ce42bbdd880b49cc8a521fccfb9504d5/lutorpy-1.3.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}