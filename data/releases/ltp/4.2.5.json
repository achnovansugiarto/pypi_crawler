{
  "info": {
    "author": "Yunlong Feng",
    "author_email": "ylfeng@ir.hit.edu.cn",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 1 - Planning",
      "Intended Audience :: Developers",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Topic :: Software Development :: Libraries"
    ],
    "description": "[![LTP](https://img.shields.io/pypi/v/ltp?label=LTP4%20ALPHA)](https://pypi.org/project/ltp/)\n![VERSION](https://img.shields.io/pypi/pyversions/ltp)\n[![Documentation Status](https://readthedocs.org/projects/ltp/badge/?version=latest)](https://ltp.readthedocs.io/zh_CN/latest/?badge=latest)\n[![PyPI Downloads](https://img.shields.io/pypi/dm/ltp)](https://pypi.python.org/pypi/ltp)\n![CODE SIZE](https://img.shields.io/github/languages/code-size/HIT-SCIR/ltp)\n![CONTRIBUTORS](https://img.shields.io/github/contributors/HIT-SCIR/ltp)\n![LAST COMMIT](https://img.shields.io/github/last-commit/HIT-SCIR/ltp)\n\n| Language                             | version                                                                                                                                                                                                                                                                                                                   |\n| ------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| [Python](python/interface/README.md) | [![LTP](https://img.shields.io/pypi/v/ltp?label=LTP)](https://pypi.org/project/ltp) [![LTP-Core](https://img.shields.io/pypi/v/ltp-core?label=LTP-Core)](https://pypi.org/project/ltp-core)   [![LTP-Extension](https://img.shields.io/pypi/v/ltp-extension?label=LTP-Extension)](https://pypi.org/project/ltp-extension) |\n| [Rust](rust/ltp/README.md)           | [![LTP](https://img.shields.io/crates/v/ltp?label=LTP)](https://crates.io/crates/ltp)                                                                                                                                                                                                                                     |\n\n# LTP 4\n\nLTP（Language Technology Platform） 提供了一系列中文自然语言处理工具，用户可以使用这些工具对于中文文本进行分词、词性标注、句法分析等等工作。\n\n## 引用\n\n如果您在工作中使用了 LTP，您可以引用这篇论文\n\n```bibtex\n@article{che2020n,\n  title={N-LTP: A Open-source Neural Chinese Language Technology Platform with Pretrained Models},\n  author={Che, Wanxiang and Feng, Yunlong and Qin, Libo and Liu, Ting},\n  journal={arXiv preprint arXiv:2009.11616},\n  year={2020}\n}\n```\n\n**参考书：**\n由哈工大社会计算与信息检索研究中心（HIT-SCIR）的多位学者共同编著的《[自然语言处理：基于预训练模型的方法](https://item.jd.com/13344628.html)\n》（作者：车万翔、郭江、崔一鸣；主审：刘挺）一书现已正式出版，该书重点介绍了新的基于预训练模型的自然语言处理技术，包括基础知识、预训练词向量和预训练模型三大部分，可供广大LTP用户学习参考。\n\n### 更新说明\n\n- 4.2.0\n  - \\[结构性变化\\] 将 LTP 拆分成 2 个部分，维护和训练更方便，结构更清晰\n    - \\[Legacy 模型\\] 针对广大用户对于**推理速度**的需求，使用 Rust 重写了基于感知机的算法，准确率与 LTP3 版本相当，速度则是 LTP v3 的 **3.55** 倍，开启多线程更可获得 **17.17** 倍的速度提升，但目前仅支持分词、词性、命名实体三大任务\n    - \\[深度学习模型\\] 即基于 PyTorch 实现的深度学习模型，支持全部的6大任务（分词/词性/命名实体/语义角色/依存句法/语义依存）\n  - \\[其他改进\\] 改进了模型训练方法\n    - \\[共同\\] 提供了训练脚本和训练样例，使得用户能够更方便地使用私有的数据，自行训练个性化的模型\n    - \\[深度学习模型\\] 采用 hydra 对训练过程进行配置，方便广大用户修改模型训练参数以及对 LTP 进行扩展（比如使用其他包中的 Module）\n  - \\[其他变化\\] 分词、依存句法分析 (Eisner) 和 语义依存分析 (Eisner) 任务的解码算法使用 Rust 实现，速度更快\n  - \\[新特性\\] 模型上传至 [Huggingface Hub](https://huggingface.co/LTP)，支持自动下载，下载速度更快，并且支持用户自行上传自己训练的模型供LTP进行推理使用\n  - \\[破坏性变更\\] 改用 Pipeline API 进行推理，方便后续进行更深入的性能优化（如SDP和SDPG很大一部分是重叠的，重用可以加快推理速度），使用说明参见[Github快速使用部分](https://github.com/hit-scir/ltp)\n- 4.1.0\n  - 提供了自定义分词等功能\n  - 修复了一些bug\n- 4.0.0\n  - 基于Pytorch 开发，原生 Python 接口\n  - 可根据需要自由选择不同速度和指标的模型\n  - 分词、词性、命名实体、依存句法、语义角色、语义依存6大任务\n\n## 快速使用\n\n### [Python](python/interface/README.md)\n\n```bash\npip install ltp # 安装 ltp\n```\n\n```python\nfrom ltp import LTP\n\nltp = LTP(\"LTP/small\")  # 默认加载 Small 模型\noutput = ltp.pipeline([\"他叫汤姆去拿外衣。\"], tasks=[\"cws\", \"pos\", \"ner\", \"srl\", \"dep\", \"sdp\"])\n# 使用字典格式作为返回结果\nprint(output.cws) # print(output[0]) / print(output['cws']) # 也可以使用下标访问\nprint(output.pos)\nprint(output.sdp)\n\n# 使用感知机算法实现的分词、词性和命名实体识别，速度比较快，但是精度略低\nltp = LTP(\"LTP/legacy\")\n# cws, pos, ner = ltp.pipeline([\"他叫汤姆去拿外衣。\"], tasks=[\"cws\", \"ner\"]).to_tuple() # error: NER 需要 词性标注任务的结果\ncws, pos, ner = ltp.pipeline([\"他叫汤姆去拿外衣。\"], tasks=[\"cws\", \"pos\", \"ner\"]).to_tuple() # to tuple 可以自动转换为元组格式\n# 使用元组格式作为返回结果\nprint(cws, pos, ner)\n```\n\n**[详细说明](python/interface/docs/quickstart.rst)**\n\n### [Rust](rust/ltp/README.md)\n\n```rust\nuse std::fs::File;\nuse apache_avro::Codec;\nuse itertools::multizip;\nuse ltp::{CWSModel, POSModel, NERModel, ModelSerde, Format};\n\nfn main() -> Result<(), Box<dyn std::error::Error>> {\n    let file = File::open(\"data/legacy-models/cws_model.bin\")?;\n    let cws: CWSModel = ModelSerde::load(file, Format::AVRO(Codec::Deflate))?;\n    let file = File::open(\"data/legacy-models/pos_model.bin\")?;\n    let pos: POSModel = ModelSerde::load(file, Format::AVRO(Codec::Deflate))?;\n    let file = File::open(\"data/legacy-models/ner_model.bin\")?;\n    let ner: NERModel = ModelSerde::load(file, Format::AVRO(Codec::Deflate))?;\n\n    let words = cws.predict(\"他叫汤姆去拿外衣。\");\n    let pos = pos.predict(&words);\n    let ner = ner.predict((&words, &pos));\n\n    for (w, p, n) in multizip((words, pos, ner)) {\n        println!(\"{}/{}/{}\", w, p, n);\n    }\n\n    Ok(())\n}\n```\n\n## 模型性能以及下载地址\n\n|                  深度学习模型                   |  分词   |  词性   | 命名实体  | 语义角色  | 依存句法  | 语义依存  | 速度(句/S) |\n| :---------------------------------------: | :---: | :---: | :---: | :---: | :---: | :---: | :-----: |\n|  [Base](https://huggingface.co/LTP/base)  | 98.7  | 98.5  | 95.4  | 80.6  | 89.5  | 75.2  |  39.12  |\n| [Base1](https://huggingface.co/LTP/base1) | 99.22 | 98.73 | 96.39 | 79.28 | 89.57 | 76.57 |  --.--  |\n| [Base2](https://huggingface.co/LTP/base2) | 99.18 | 98.69 | 95.97 | 79.49 | 90.19 | 76.62 |  --.--  |\n| [Small](https://huggingface.co/LTP/small) | 98.4  | 98.2  | 94.3  | 78.4  | 88.3  | 74.7  |  43.13  |\n|  [Tiny](https://huggingface.co/LTP/tiny)  | 96.8  | 97.1  | 91.6  | 70.9  | 83.8  | 70.1  |  53.22  |\n\n|                    感知机算法                    |  分词   |  词性   | 命名实体  | 速度(句/s)  |             备注             |\n| :-----------------------------------------: | :---: | :---: | :---: | :------: | :------------------------: |\n| [Legacy](https://huggingface.co/LTP/legacy) | 97.93 | 98.41 | 94.28 | 21581.48 | [性能详情](rust/ltp/README.md) |\n\n**注：感知机算法速度为开启16线程速度**\n\n## 构建 Wheel 包\n\n```shell script\nmake bdist\n```\n\n## 模型算法\n\n- 分词: Electra <sup>[1](#RELTRANS)</sup> + Linear\n- 词性: Electra + Linear\n- 命名实体: Electra + Relative Transformer<sup>[2](#RELTRANS)</sup> + Linear\n- 依存句法: Electra + BiAffine + Eisner<sup>[3](#Eisner)</sup>\n- 语义依存: Electra + BiAffine\n- 语义角色: Electra + BiAffine + CRF\n\n## 其他语言绑定\n\n**感知机算法**\n\n- [Rust](rust/ltp)\n- [C/C++](rust/ltp-cffi)\n\n**深度学习算法**\n\n- [Rust](https://github.com/HIT-SCIR/libltp/tree/master/ltp-rs)\n- [C++](https://github.com/HIT-SCIR/libltp/tree/master/ltp-cpp)\n- [Java](https://github.com/HIT-SCIR/libltp/tree/master/ltp-java)\n\n## 作者信息\n\n- 冯云龙 \\<\\<[ylfeng@ir.hit.edu.cn](mailto:ylfeng@ir.hit.edu.cn)>>\n\n## 开源协议\n\n1. 语言技术平台面向国内外大学、中科院各研究所以及个人研究者免费开放源代码，但如上述机构和个人将该平台用于商业目的（如企业合作项目等）则需要付费。\n2. 除上述机构以外的企事业单位，如申请使用该平台，需付费。\n3. 凡涉及付费问题，请发邮件到 car@ir.hit.edu.cn 洽商。\n4. 如果您在 LTP 基础上发表论文或取得科研成果，请您在发表论文和申报成果时声明“使用了哈工大社会计算与信息检索研究中心研制的语言技术平台（LTP）”.\n   同时，发信给car@ir.hit.edu.cn，说明发表论文或申报成果的题目、出处等。\n\n## 脚注\n\n- <a name=\"RELTRANS\">1</a>:: [Chinese-ELECTRA](https://github.com/ymcui/Chinese-ELECTRA)\n- <a name=\"RELTRANS\">2</a>:: [TENER: Adapting Transformer Encoder for Named Entity Recognition](https://arxiv.org/abs/1911.04474)\n- <a name=\"Eisner\">3</a>:: [A PyTorch implementation of \"Deep Biaffine Attention for Neural Dependency Parsing\"](https://github.com/yzhangcs/parser)\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/HIT-SCIR/ltp",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "ltp",
    "package_url": "https://pypi.org/project/ltp/",
    "platform": null,
    "project_url": "https://pypi.org/project/ltp/",
    "project_urls": {
      "Homepage": "https://github.com/HIT-SCIR/ltp"
    },
    "release_url": "https://pypi.org/project/ltp/4.2.5/",
    "requires_dist": [
      "ltp-core (>=0.1.0)",
      "ltp-extension (>=0.1.0)",
      "huggingface-hub (>=0.8.0)"
    ],
    "requires_python": ">=3.6.*, <4",
    "summary": "Language Technology Platform",
    "version": "4.2.5",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16255791,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "f026c801a33c482c2c903d34e975837eddbd36b0b40825de957ebc8a887ecaa8",
        "md5": "3f9b4705f1dc5c1764a348bca1893403",
        "sha256": "0bfd07b74d56265df05c254b5d04012a7209e44e4861346b3546bd74440f5223"
      },
      "downloads": -1,
      "filename": "ltp-4.2.5-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "3f9b4705f1dc5c1764a348bca1893403",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6.*, <4",
      "size": 19449,
      "upload_time": "2022-08-22T07:46:35",
      "upload_time_iso_8601": "2022-08-22T07:46:35.844949Z",
      "url": "https://files.pythonhosted.org/packages/f0/26/c801a33c482c2c903d34e975837eddbd36b0b40825de957ebc8a887ecaa8/ltp-4.2.5-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}