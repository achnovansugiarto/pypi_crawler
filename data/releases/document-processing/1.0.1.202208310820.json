{
  "info": {
    "author": "Guillaume Bernard",
    "author_email": "contact@guillaume-bernard.fr",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: GNU General Public License v3 (GPLv3)",
      "Operating System :: POSIX :: Linux",
      "Programming Language :: Python :: 3.9",
      "Topic :: Scientific/Engineering :: Artificial Intelligence"
    ],
    "description": "# `document_processing`\n\n## Install\n\n```bash\npip install document_processing\n```\n\nThis package provides functions to pre-process text for various NLP tasks. It uses [`spaCy`](https://spacy.io/) and its models to analyse the text.\n\n## Behaviour\n\nThe entry point of this package is `process_dcouments` in which you put the `Series` of documents to process and the `spaCy` model name that will be loaded to transform the texts.\n\nFrom a document, you can extract tokens, lemmas and entities with the `get_tokens_lemmas_entities_from_document` function, giving it the document returned by the previous function, and the preprocessing function, as described below.\n\n### Pre-processing functions\n\n- `preprocess_list_of_texts`: process tokens, remove stopwords, non-standard characters, etc.\n- `preprocess_list_of_tweets`: same as above, and remove all token that seem to be HTTP links, which are often present in Tweets.\n\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://gitlab.univ-lr.fr/cross-lingual-event-tracking/developpement/from-documents-to-events/document_processing",
    "keywords": "",
    "license": "GPLv3",
    "maintainer": "",
    "maintainer_email": "",
    "name": "document-processing",
    "package_url": "https://pypi.org/project/document-processing/",
    "platform": null,
    "project_url": "https://pypi.org/project/document-processing/",
    "project_urls": {
      "Bug Tracker": "https://gitlab.univ-lr.fr/cross-lingual-event-tracking/developpement/from-documents-to-events/document_processing/-/issues",
      "Homepage": "https://gitlab.univ-lr.fr/cross-lingual-event-tracking/developpement/from-documents-to-events/document_processing"
    },
    "release_url": "https://pypi.org/project/document-processing/1.0.1.202208310820/",
    "requires_dist": [
      "pandas (~=1.3.5)",
      "setuptools (~=53.0.0)",
      "spacy (~=3.2.1)"
    ],
    "requires_python": ">=3.9",
    "summary": "Pre-process documents for Natural Language Processing using spaCy models",
    "version": "1.0.1.202208310820",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14946273,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "95116c71405e9dac3995db4902e8c999b169e16e39ab35c3e58b000d0de49ebf",
        "md5": "a46e20ca0ea7ada2713e75e8964eab17",
        "sha256": "dd38610f57e25a78e4dc722d4bf9777b43011b95861d9b03e818c0813c654146"
      },
      "downloads": -1,
      "filename": "document_processing-1.0.1.202208310820-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "a46e20ca0ea7ada2713e75e8964eab17",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.9",
      "size": 16307,
      "upload_time": "2022-08-31T08:20:23",
      "upload_time_iso_8601": "2022-08-31T08:20:23.671301Z",
      "url": "https://files.pythonhosted.org/packages/95/11/6c71405e9dac3995db4902e8c999b169e16e39ab35c3e58b000d0de49ebf/document_processing-1.0.1.202208310820-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}