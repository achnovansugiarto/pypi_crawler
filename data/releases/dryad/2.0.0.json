{
  "info": {
    "author": "Kelsey Florek",
    "author_email": "kelsey.florek@slh.wisc.edu",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: GNU General Public License v3 (GPLv3)",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "![Dryad](dryad_app/assets/dryad_logo_250.png)\n\n![Latest Release](https://img.shields.io/github/v/release/k-florek/dryad)  \n[![Build Status](https://travis-ci.org/k-florek/dryad.svg?branch=master)](https://travis-ci.org/k-florek/dryad)\n\nDryad is a pipeline to construct reference free core-genome or SNP phylogenetic trees for examining prokaryote relatedness in outbreaks. Dryad accomplishes this using [NextFlow](https://www.nextflow.io/) allowing the pipeline to be run in numerous environments using [docker](https://www.docker.com/) or [singularity](https://sylabs.io/) either locally or in an HPC or cloud environment. Dryad will perform both a reference free core-genome analysis based off of the approach outlined by [Oakeson et. al](https://www.ncbi.nlm.nih.gov/pubmed/30158193) and/or a SNP analysis using the [CFSAN-SNP](https://snp-pipeline.readthedocs.io/en/latest/readme.html) pipeline.\n\n### Table of Contents:\n[Installation](#installing-dryad)  \n[Usage](#using-the-pipeline)  \n[Workflow outline](#workflow-outline)\n[Core-genome](#core-Genome-phylogenetic-tree-construction)  \n[SNP](#snp-phylogenetic-tree-construction)  \n[Quality assessment](#quality-assessment)  \n[Genome cluster report](#genome-cluster-report)  \n[Output](#output-files)  \n[Dependencies](#dependencies)  \n\n### Installing Dryad\nDryad uses a combination of nextflow and containers to function and is dependent on either [Docker](https://docs.docker.com/get-docker/) or [Singularity](https://sylabs.io/guides/3.5/user-guide/quick_start.html#quick-installation-steps).\n\nInstalling dryad can be done with pip using `pip install dryad`. If you are running Dryad from the git repository, a python dependency needs to be installed via pip using `pip install -r requirements.txt`.\n\n### Using the pipeline\nThe pipeline is designed to start from raw Illumina short reads. All reads must be in the same directory. Then start the pipeline using `dryad` and follow the options for selecting and running the appropriate pipeline.\n```\nusage: dryad [-h] [--output <output_path>] [--core-genome] [--snp] [-r <path>]\n             [-ar] [--sep sep_chars] [--profile {docker,singularity}]\n             [--config CONFIG] [--get_config] [--resume] [--report]\n             [reads_path]\n\nA comprehensive tree building program.\n\npositional arguments:\n  reads_path            path to the directory of raw reads in the fastq format\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --output <output_path>, -o <output_path>\n                        path to ouput directory, default \"dryad_results\"\n  --core-genome, -cg    construct a core-genome tree\n  --snp, -s             construct a SNP tree, requires a reference sequence in\n                        fasta format (-r)\n  -r <path>             reference sequence for SNP pipeline\n  -ar                   detect AR mechanisms\n  --sep sep_chars       dryad identifies sample names from the name of the\n                        read file by splitting the name on the specified\n                        separating characters, default \"_\"\n  --profile {docker,singularity}\n                        specify nextflow profile, dryad will try to use docker\n                        first, then singularity\n  --config CONFIG, -c CONFIG\n                        Nextflow custom configureation\n  --get_config          get a Nextflow configuration template for dryad\n  --resume              resume a previous run\n  --report <path>       RMarkdown file for report.\n```\n\nBoth pipelines begin with a quality trimming step to trim the reads of low quality bases at the end of the read using [Trimmomatic v0.39](http://www.usadellab.org/cms/?page=trimmomatic), the removal of PhiX contamination using [BBtools v38.76](https://jgi.doe.gov/data-and-tools/bbtools/), and the assessment of read quality using [FastQC v0.11.8](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/). After processing, the reads are used by each pipeline as needed.  \n*Note: Both pipelines can be run automatically in succession using the -cg and -s parameters simultaneously.*\n\n##### Additional workflow parameters\nIn order to tweak the versions of software used or specific workflow parameters. You can obtain the configuration file using `--get_config`. Then use the custom configuration with the `--profile` flag when running dryad.\n\n### Workflow outline\n\n![Workflow](dryad_workflow_2.0.0.png)\n\n### Core Genome phylogenetic tree construction\nThe core genome pipeline takes the trimmed and cleaned reads and infers a phylogenetic tree that can be used for inferring outbreak relatedness. This pipeline is based loosely off of the pipeline described here by [Oakeson et. al](https://www.ncbi.nlm.nih.gov/pubmed/30158193).\n\nSpecies and MLST type are predicted from the assemblies generated during the core genome pipeline, and assembly quality is evaluated.\n\nAdditionally, the core genome pipeline can be run with `-ar` to predict antibiotic resistance genes.\n\nThe core genome pipeline uses the following applications and pipelines:\n\n[Shovill v1.0.4](https://github.com/tseemann/shovill)\nShovill is a pipeline centered around SPAdes but alters some of the steps to get similar results in less time.\n\n[Prokka v1.14.5](https://github.com/tseemann/prokka)\nProkka is a whole genome annotation tool that is used to annotate the coding regions of the assembly.\n\n[Roary v3.12.0](https://github.com/sanger-pathogens/Roary)\nRoary takes the annotated genomes and constructs a core gene alignment.\n\n[IQ-Tree v1.6.7](http://www.iqtree.org/)\nIQ-Tree uses the core gene alignment and creates a maximum likelihood phylogenetic tree bootstraped 1000 times.\n\n[Mash v2.1](https://github.com/marbl/Mash)\nMash performs fast genome and metagenome distance estimation using MinHash.\n\n[MLST v2.17.6](https://github.com/tseemann/mlst)\nMLST scans contig files against PubMLST typing schemes.\n\n[QUAST v5.0.2](http://bioinf.spbau.ru/quast)\nQUAST evaluates genome assemblies.\n\n[AMRFinderPlus v3.1.1](https://github.com/ncbi/amr)\nAMRFinderPlus identifies acquired antimicrobial resistance genes.\n\n### SNP phylogenetic tree construction\nThe SNP pipeline takes the trimmed and cleaned reads and infers a phylogenetic tree that can be used for inferring outbreak relatedness. The pipeline requires the path to the raw reads (mentioned above) and a reference genome in fasta file format.\n\nThe SNP pipeline uses the following applications and pipelines:\n\n[CFSAN SNP Pipeline v2.0.2](https://github.com/CFSAN-Biostatistics/snp-pipeline)\n\n[IQ-Tree v1.6.7](http://www.iqtree.org/)\nIQ-Tree uses an alignment of the SNP sites to create a maximum likelihood phylogenetic tree bootstrapped 1000 times.\n\n### Quality Assessment\nThe results of quality checks from each pipeline are summarized using [MultiQC v1.8](https://multiqc.info/)\n\n### Genome cluster report\nDryad can generate an easily attributable analysis report. This uses RMarkdown and the results from the SNP and core genome pipelines to generate the genome cluster report. This option can be run using `--report`. The plotting defaults of the RMarkdown file (/report/report.Rmd) can be modified as necessary and rebuilt using `dryad_report`.\n\n### Output files\n\n```\ndryad_results\n├── logs\n│   ├── cleanedreads\n│   ├── dryad_execution_report.html\n│   ├── dryad_trace.txt\n│   ├── fastqc\n│   ├── quast\n│   └── work\n└── results\n    ├── amrfinder\n    ├── annotated\n    ├── ar_predictions_binary.tsv\n    ├── ar_predictions.tsv\n    ├── assembled\n    ├── cluster_report.pdf\n    ├── core_gene_alignment.aln\n    ├── core_genome_statistics.txt\n    ├── core_genome.tree\n    ├── mash\n    ├── mlst.tsv\n    ├── multiqc_data\n    ├── multiqc_report.html\n    ├── report_template.Rmd\n    ├── snp_distance_matrix.tsv\n    ├── snpma.fasta\n    └── snp.tree\n```\n**ar_predictions_binary.tsv** - Presence/absence matrix of antibiotic resistance genes.  \n**ar_predictions.tsv** - Antibiotic tesistance genes detected.  \n**cluster_report.pdf** - Genome cluster report.  \n**core_gene_alignment.aln** - Alignment of the core set of genes.  \n**core_gene_statistics.txt** - Information about the number of core genes.  \n**core_genome_tree.tree** - The core-genome phylogenetic tree created by the core-genome pipeline.  \n**mash/{sample}.mash.txt** - Species prediction for each sample.  \n**mlst.tsv** - MLST scheme predictions.  \n**multiqc_report.html** - QC report.  \n**report_template.Rmd** - R Markdown template for generating the cluster_report.pdf  \n**snp_distance_matrix.tsv** - The SNP distances generated by the SNP pipeline.  \n**snp.tree** - The SNP tree created by the SNP pipeline.  \n**snpma.fasta** - The SNP alignment.  \n\n### Authors\n[Kelsey Florek](https://github.com/k-florek), WSLH Bioinformatics Scientist  \n[Abigail Shockey](https://github.com/AbigailShockey), WSLH Bioinformatics Fellow\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/k-florek/dryad",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "dryad",
    "package_url": "https://pypi.org/project/dryad/",
    "platform": "",
    "project_url": "https://pypi.org/project/dryad/",
    "project_urls": {
      "Homepage": "https://github.com/k-florek/dryad"
    },
    "release_url": "https://pypi.org/project/dryad/2.0.0/",
    "requires_dist": [
      "pexpect (>=4.8)"
    ],
    "requires_python": ">=3.6",
    "summary": "A pipeline to construct reference free core-genome or SNP phylogenetic trees for examining prokaryote relatedness in outbreaks.",
    "version": "2.0.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8633414,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "7ecf32ce12526ac2ef03f8d28d9e1424dddad746bbcd54f1704e86e4bb500c2c",
        "md5": "b74c3a22a691740188fe4bf1c0977ec4",
        "sha256": "0c5fdf651468344d2e794ae0deeaf3e6ae928a21aece2bc3cc31409d9ae21d53"
      },
      "downloads": -1,
      "filename": "dryad-2.0.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "b74c3a22a691740188fe4bf1c0977ec4",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 64912,
      "upload_time": "2020-05-09T01:44:35",
      "upload_time_iso_8601": "2020-05-09T01:44:35.654965Z",
      "url": "https://files.pythonhosted.org/packages/7e/cf/32ce12526ac2ef03f8d28d9e1424dddad746bbcd54f1704e86e4bb500c2c/dryad-2.0.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "8641c7286e11a7054708c6606eea85f9bb680e53a422c774e247fe6cfdb22637",
        "md5": "67732713f81bd539f434be599ff78cbc",
        "sha256": "c5995ddb608405e515011e3db0a8416a3d663a356ddcf7236b96ff050f72dc1a"
      },
      "downloads": -1,
      "filename": "dryad-2.0.0.tar.gz",
      "has_sig": false,
      "md5_digest": "67732713f81bd539f434be599ff78cbc",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 47878,
      "upload_time": "2020-05-09T01:44:37",
      "upload_time_iso_8601": "2020-05-09T01:44:37.809280Z",
      "url": "https://files.pythonhosted.org/packages/86/41/c7286e11a7054708c6606eea85f9bb680e53a422c774e247fe6cfdb22637/dryad-2.0.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}