{
  "info": {
    "author": "huseinzol05",
    "author_email": "husein.zol05@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3.6"
    ],
    "description": "**Malaya-Speech** is a Speech-Toolkit library for bahasa Malaysia, powered by Deep Learning Tensorflow.\n\nDocumentation\n--------------\n\nProper documentation is available at https://malaya-speech.readthedocs.io/\n\nInstalling from the PyPI\n----------------------------------\n\nCPU version\n::\n\n    $ pip install malaya-speech\n\nGPU version\n::\n\n    $ pip install malaya-speech[gpu]\n\nOnly **Python 3.6.0 and above** and **Tensorflow 1.15.0 and above** are supported.\n\nWe recommend to use **virtualenv** for development. All examples tested on Tensorflow version 1.15.4, 1.15.5, 2.4.1 and 2.5.\n\nFeatures\n--------\n\n-  **Age Detection**, detect age in speech using Finetuned Speaker Vector.\n-  **Speaker Diarization**, diarizing speakers using Pretrained Speaker Vector.\n-  **Emotion Detection**, detect emotions in speech using Finetuned Speaker Vector.\n-  **Force Alignment**, generate a time-aligned transcription of an audio file using RNNT and CTC.\n-  **Gender Detection**, detect genders in speech using Finetuned Speaker Vector.\n-  **Language Detection**, detect hyperlocal languages in speech using Finetuned Speaker Vector.\n-  **Multispeaker Separation**, Multispeaker separation using FastSep on 8k Wav.\n-  **Noise Reduction**, reduce multilevel noises using STFT UNET.\n-  **Speaker Change**, detect changing speakers using Finetuned Speaker Vector.\n-  **Speaker overlap**, detect overlap speakers using Finetuned Speaker Vector.\n-  **Speaker Vector**, calculate similarity between speakers using Pretrained Speaker Vector.\n-  **Speech Enhancement**, enhance voice activities using Waveform UNET.\n-  **SpeechSplit Conversion**, detailed speaking style conversion by disentangling speech into content, timbre, rhythm and pitch using PyWorld and PySPTK.\n-  **Speech-to-Text**, End-to-End Speech to Text for Malay, Mixed (Malay, Singlish and Mandarin) and Singlish using RNNT, Wav2Vec2, HuBERT and BEST-RQ CTC.\n-  **Super Resolution**, Super Resolution 4x for Waveform.\n-  **Text-to-Speech**, Text to Speech for Malay and Singlish using Tacotron2, FastSpeech2 and FastPitch.\n-  **Vocoder**, convert Mel to Waveform using MelGAN, Multiband MelGAN and Universal MelGAN Vocoder.\n-  **Voice Activity Detection**, detect voice activities using Finetuned Speaker Vector.\n-  **Voice Conversion**, Many-to-One, One-to-Many, Many-to-Many, and Zero-shot Voice Conversion.\n-  **Hybrid 8-bit Quantization**, provide hybrid 8-bit quantization for all models to reduce inference time up to 2x and model size up to 4x.\n\nPretrained Models\n------------------\n\nMalaya-Speech also released pretrained models, simply check at `malaya-speech/pretrained-model <https://github.com/huseinzol05/malaya-speech/tree/master/pretrained-model>`_\n\n-  **Wave UNET**,  Multi-Scale Neural Network for End-to-End Audio Source Separation, https://arxiv.org/abs/1806.03185\n-  **Wave ResNet UNET**, added ResNet style into Wave UNET, no paper produced.\n-  **Wave ResNext UNET**, added ResNext style into Wave UNET, no paper produced.\n-  **Deep Speaker**, An End-to-End Neural Speaker Embedding System, https://arxiv.org/pdf/1705.02304.pdf\n-  **SpeakerNet**, 1D Depth-wise Separable Convolutional Network for Text-Independent Speaker Recognition and Verification, https://arxiv.org/abs/2010.12653\n-  **VGGVox**, a large-scale speaker identification dataset, https://arxiv.org/pdf/1706.08612.pdf\n-  **GhostVLAD**, Utterance-level Aggregation For Speaker Recognition In The Wild, https://arxiv.org/abs/1902.10107\n-  **Conformer**, Convolution-augmented Transformer for Speech Recognition, https://arxiv.org/abs/2005.08100\n-  **ALConformer**, A lite Conformer, no paper produced.\n-  **Jasper**, An End-to-End Convolutional Neural Acoustic Model, https://arxiv.org/abs/1904.03288\n-  **Tacotron2**, Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions, https://arxiv.org/abs/1712.05884\n-  **FastSpeech2**, Fast and High-Quality End-to-End Text to Speech, https://arxiv.org/abs/2006.04558\n-  **MelGAN**, Generative Adversarial Networks for Conditional Waveform Synthesis, https://arxiv.org/abs/1910.06711\n-  **Multi-band MelGAN**, Faster Waveform Generation for High-Quality Text-to-Speech, https://arxiv.org/abs/2005.05106\n-  **SRGAN**, Modified version of SRGAN to do 1D Convolution, Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network, https://arxiv.org/abs/1609.04802\n-  **Speech Enhancement UNET**, https://github.com/haoxiangsnr/Wave-U-Net-for-Speech-Enhancement\n-  **Speech Enhancement ResNet UNET**, Added ResNet style into Speech Enhancement UNET, no paper produced.\n-  **Speech Enhancement ResNext UNET**, Added ResNext style into Speech Enhancement UNET, no paper produced.\n-  **Universal MelGAN**, Universal MelGAN: A Robust Neural Vocoder for High-Fidelity Waveform Generation in Multiple Domains, https://arxiv.org/abs/2011.09631\n-  **FastVC**, Faster and Accurate Voice Conversion using Transformer, no paper produced.\n-  **FastSep**, Faster and Accurate Speech Separation using Transformer, no paper produced.\n-  **wav2vec 2.0**, A Framework for Self-Supervised Learning of Speech Representations, https://arxiv.org/abs/2006.11477\n-  **FastSpeechSplit**, Unsupervised Speech Decomposition Via Triple Information Bottleneck using Transformer, no paper produced.\n-  **Sepformer**, Attention is All You Need in Speech Separation, https://arxiv.org/abs/2010.13154\n-  **FastSpeechSplit**, Faster and Accurate Speech Split Conversion using Transformer, no paper produced.\n-  **HuBERT**, Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units, https://arxiv.org/pdf/2106.07447v1.pdf\n-  **FastPitch**, Parallel Text-to-speech with Pitch Prediction, https://arxiv.org/abs/2006.06873\n-  **GlowTTS**, A Generative Flow for Text-to-Speech via Monotonic Alignment Search, https://arxiv.org/abs/2005.11129\n-  **BEST-RQ**, Self-supervised learning with random-projection quantizer for speech recognition, https://arxiv.org/pdf/2202.01855.pdf\n-  **LightSpeech**, Lightweight and Fast Text to Speech with Neural Architecture Search, https://arxiv.org/abs/2102.04040\n-  **VITS**, Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech, https://arxiv.org/pdf/2106.06103.pdf \n-  **UnivNet**, A Neural Vocoder with Multi-Resolution Spectrogram Discriminators for High-Fidelity Waveform Generation, https://arxiv.org/abs/2106.07889\n\nReferences\n-----------\n\nIf you use our software for research, please cite:\n\n::\n\n  @misc{Malaya, Speech-Toolkit library for bahasa Malaysia, powered by Deep Learning Tensorflow,\n    author = {Husein, Zolkepli},\n    title = {Malaya-Speech},\n    year = {2020},\n    publisher = {GitHub},\n    journal = {GitHub repository},\n    howpublished = {\\url{https://github.com/huseinzol05/malaya-speech}}\n  }\n\nAcknowledgement\n----------------\n\nThanks to `KeyReply <https://www.keyreply.com/>`_ for sponsoring private cloud to train Malaya-Speech models, without it, this library will collapse entirely.  \n\n",
    "description_content_type": "",
    "docs_url": null,
    "download_url": "https://github.com/huseinzol05/malaya-speech/archive/master.zip",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/huseinzol05/malaya-speech",
    "keywords": "nlp,bm",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "malaya-speech",
    "package_url": "https://pypi.org/project/malaya-speech/",
    "platform": null,
    "project_url": "https://pypi.org/project/malaya-speech/",
    "project_urls": {
      "Download": "https://github.com/huseinzol05/malaya-speech/archive/master.zip",
      "Homepage": "https://github.com/huseinzol05/malaya-speech"
    },
    "release_url": "https://pypi.org/project/malaya-speech/1.2.6/",
    "requires_dist": [
      "numpy",
      "unidecode",
      "librosa",
      "soundfile",
      "herpetologist",
      "dataclasses",
      "python-speech-features",
      "tqdm",
      "tornado",
      "scipy (>=1.5.4)",
      "malaya-boilerplate (>=0.0.19)",
      "tensorflow (>=1.15)",
      "tensorflow (>=1.15) ; extra == 'cpu'",
      "tensorflow-gpu (>=1.15) ; extra == 'gpu'"
    ],
    "requires_python": ">=3.6.*",
    "summary": "Speech-Toolkit for bahasa Malaysia, powered by Deep Learning Tensorflow.",
    "version": "1.2.6",
    "yanked": true,
    "yanked_reason": "bugs"
  },
  "last_serial": 17443003,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "c3fe3c5f9fd24de98e7a482a05d899b25420a505d7af23a9711b2832e5c8f48c",
        "md5": "8dc4da76c49737ada5fa6fea5206881a",
        "sha256": "277a56830b65b1574c47012d8acc04d077d301f72ad01b7f58397ded150155e9"
      },
      "downloads": -1,
      "filename": "malaya_speech-1.2.6-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "8dc4da76c49737ada5fa6fea5206881a",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6.*",
      "size": 1069582,
      "upload_time": "2022-05-06T16:51:38",
      "upload_time_iso_8601": "2022-05-06T16:51:38.937273Z",
      "url": "https://files.pythonhosted.org/packages/c3/fe/3c5f9fd24de98e7a482a05d899b25420a505d7af23a9711b2832e5c8f48c/malaya_speech-1.2.6-py3-none-any.whl",
      "yanked": true,
      "yanked_reason": "bugs"
    }
  ],
  "vulnerabilities": []
}