{
  "info": {
    "author": "Mathew Rowe @ Oracle",
    "author_email": "matthew.r.rowe@oracle.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# MACEst (Model Agnostic Confidence Estimator)\n## What is MACEst?\nMACEst is a confidence estimator that can be used alongside any model (regression or \nclassification) which uses previously seen data (i.e. any supervised learning model) to produce a \npoint prediction.\n\nIn the regression case, MACEst produces a _confidence interval_ about the point prediction, e.g. \n\"the point prediction is 10 and I am 90% confident that the prediction lies between 8 and 12.\"\n\nIn Classification MACEst produces a _confidence score_ for the point prediction. e.g. the point \nprediction is class 0 and I am 90% sure that the prediction is correct.\n\nMACEst produces well-calibrated confidence estimates, i.e. 90% confidence means that you will on \naverage be correct 90% of the time. \nIt is also aware of the model limitations i.e. when a model is being asked to predict a point which \nit does not have the necessary knowledge (data) to predict confidently. \nIn these cases MACEst is able to incorporate the (epistemic) uncertainty due to this and return a \nvery low confidence prediction (in regression this means a large prediction interval).\n\n## Why use MACEst ?\nMachine learning has become an integral part of many of the tools that are used every day. \nThere has been a huge amount of progress on improving the global accuracy of machine learning \nmodels but calculating how likely a single prediction is to be correct has seen considerably less \nprogress.\n\nMost algorithms will still produce a prediction, even if this is in a part of the feature space the \nalgorithm has no information about. \nThis could be because the feature vector is unlike anything seen during training, or because the \nfeature vector falls in a part of the feature space where there is a large amount of uncertainty \nsuch as if the border between two classes overlaps.\nIn cases like this the prediction may well be meaningless. \nIn most models, it is impossible to distinguish this sort of meaningless prediction from a sensible \nprediction. \nMACEst addresses this situation by providing an additional confidence estimate.\n\nIn some areas such as Finance, Infrastructure, or Healthcare, making a single bad prediction can \nhave major consequences.\nIt is important in these situations that a model is able to understand how likely any prediction it \nmakes is to be correct before acting upon it. \nIt is often even more important in these situations that any model *knows what it doesn't know* so \nthat it will not blindly make bad predictions.\n\n## Summary of the Methodology\n### TL;DR\nMACEst produces confidence estimates for a given point x by considering two factors:\n1. How accurate is the model when predicting previously seen points that are **similar** to x? \nLess confident if the model is less accurate in the region close to x.\n2. How **similar** is x to the points that we have seen previously? \nLess confident if x is not **similar** to the data used to train the model.\n\n### Longer Explanation\nMACEst seeks to provide reliable confidence estimates for both regression and classification. \nIt draws from ideas present in trust scores, conformal learning, Gaussian processes, and Bayesian \nmodelling.\n\nThe general idea is that confidence is a local quantity. \nEven when the model is accurate globally, there are likely still some predictions about which it \nshould not be very confident. \nSimilarly, if the model is not accurate globally, there may still be some predictions for which the \nmodel can be very confident about.\n\nTo model this local confidence for a given prediction on a point x, we define the local \nneighbourhood by finding the k nearest neighbours to x. \nWe then attempt to directly model the two causes of uncertainty, these are:\n1. _Aleatoric Uncertainty_: Even with lots of (possibly infinite) data there will be some \nvariance/noise in the predictions.\nOur local approximation to this will be to define a local accuracy estimate. i.e. for the k nearest \nneighbours how accurate were the predictions?\n2. _Epistemic Uncertainty_: The model can only know relationships learnt from the training data. \nIf the model has not seen any data point similar to x then it does not have as much knowledge about \npoints like x, therefore the confidence estimate should be lower. \nMACEst estimates this by calculating how **similar** x is to the k nearest (most similar) points \nthat it has previously seen.\n\nWe define a simple parametric function of these two quantities and calibrate this function so that \nour confidence estimates approximate the empirical accuracy, i.e. 90% confident -> 90% correct on \naverage. \nBy directly modelling these two effects, MACEst estimates are able to encapsulate the local \nvariance accurately whilst also being aware of when the model is being asked to predict a point \nthat is very different to what it has been trained on. \nThis will make it robust to problems such as overconfident extrapolations and out of sample \npredictions.\n\n### Example\nIf a model has been trained to classify images of cats and dogs, and we want to predict an image of \na poodle, we find the k most poodle-like cats and the k most poodle-like dogs. \nWe then calculate how accurate the model was on these sets of images, and how similar the poodle is \nto each of these k cats and k dogs. We combine these two to produce a confidence estimate for each \nclass.\n\nAs the poodle-like cats will likely be strange cats, they will be harder to classify and the \naccuracy will be lower for these than the poodle-like dogs this combined with the fact that image \nwill be considerably more similar to poodle-like dogs the confidence of the dog prediction will be \nhigh.\n\nIf we now try to classify an image of a horse, we find that the new image is very **dissimilar** to \nboth cats and dogs, so the similarity term dominates and the model will return an approximately \nuniform distribution, this can be interpreted as MACEst saying \"I don't know what this is because \nI've never seen an image of a horse!\".\n\n## Getting Started\nTo install MACEst run the following cmd:\n```shell script\npip install macest\n```\n\nOr add `macest` to your project's `requirements.txt` file as a dependency. \n\n### Software Prerequisites\nTo import and use MACEst we recommend Python version >= `3.6.8`. \n\n## Basic Usage\nBelow shows examples of using MACEst for classification and regression.\nFor more examples, and advanced usage, please see the example [notebooks](./notebooks).\n\n### Classification \nTo use MACEst for a classification task, the following example can be used:\n``` python\n\n   import numpy as np\n   from macest.classification import models as cl_mod\n   from sklearn.ensemble import RandomForestClassifier\n   from sklearn import datasets\n   from sklearn.model_selection import train_test_split\n\n   X,y = datasets.make_circles(n_samples= 2 * 10**4, noise = 0.4, factor =0.001)\n\n   X_pp_train, X_conf_train, y_pp_train, y_conf_train  = train_test_split(X,\n                                                                          y,\n                                                                          test_size=0.66,\n                                                                          random_state=10)\n\n   X_conf_train, X_cal, y_conf_train, y_cal = train_test_split(X_conf_train,\n                                                               y_conf_train,\n                                                               test_size=0.5,\n                                                               random_state=0)\n\n   X_cal, X_test, y_cal,  y_test, = train_test_split(X_cal,\n                                                     y_cal,\n                                                     test_size=0.5,\n                                                     random_state=0)\n\n   point_pred_model = RandomForestClassifier(random_state =0,\n                                             n_estimators =800,\n                                             n_jobs =-1)\n\n   point_pred_model.fit(X_pp_train,\n                        y_pp_train)\n\n   macest_model = cl_mod.ModelWithConfidence(point_pred_model,\n                                          X_conf_train,\n                                          y_conf_train)\n\n   macest_model.fit(X_cal, y_cal)\n\n   conf_preds = macest_model.predict_confidence_of_point_prediction(X_test)\n``` \n\n### Regression\nTo use MACEst for a regression task, the following example can be used:\n``` python\n   import numpy as np\n   from macest.regression import models as reg_mod\n   from sklearn.linear_model import LinearRegression\n   from sklearn.model_selection import train_test_split\n\n   X = np.linspace(0,1,10**3)\n   y = np.zeros(10**3)\n   y = 2*X*np.sin(2 *X)**2 + np.random.normal(0 , 1 , len(X))\n\n   X_pp_train, X_conf_train, y_pp_train, y_conf_train  = train_test_split(X,\n                                                                          y,\n                                                                          test_size=0.66,\n                                                                          random_state=0)\n\n   X_conf_train, X_cal, y_conf_train, y_cal = train_test_split(X_conf_train, y_conf_train,\n                                                            test_size=0.5, random_state=1)\n\n   X_cal, X_test, y_cal,  y_test, =  train_test_split(X_cal,\n                                                      y_cal,\n                                                      test_size=0.5,\n                                                      random_state=1)\n\n   point_pred_model = LinearRegression()\n   point_pred_model.fit(X_pp_train[:,None], y_pp_train)\n\n   preds = point_pred_model.predict(X_conf_train[:,None])\n   test_error = abs(preds - y_conf_train)\n   y_conf_train_var = np.var(train_error)\n\n   macest_model = reg_mod.ModelWithPredictionInterval(point_pred_model,\n                                                    X_conf_train[:,None],\n                                                    test_error)\n\n   macest_model.fit(X_cal[:,None], y_cal)\n   conf_preds = confidence_model.predict_interval(X_test, conf_level=90)\n ```\n\n### MACEst with sparse data (see notebooks for more details)\n```python\nimport scipy\nfrom scipy.sparse import csr_matrix \nfrom scipy.sparse import random as sp_rand\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom macest.classification import models as clmod\nimport nmslib \n\nn_rows = 10**3\nn_cols = 5 * 10**3\nX = csr_matrix(sp_rand(n_rows, n_cols))\ny = np.random.randint(0, 2, n_rows)\n\nX_pp_train, X_conf_train, y_pp_train, y_conf_train = train_test_split(X, y, test_size=0.66, random_state=10)\nX_conf_train, X_cal, y_conf_train, y_cal = train_test_split(X_conf_train, y_conf_train,\n                                                            test_size=0.5, random_state=0)\nX_cal, X_test, y_cal,  y_test, = train_test_split(X_cal, y_cal, test_size=0.5, random_state=0)\n\nmodel = RandomForestClassifier(random_state=0,\n                               n_estimators=800,\n                               n_jobs=-1)\n\nmodel.fit(csr_matrix(X_pp_train), y_pp_train)\n\nparam_bounds = clmod.SearchBounds(alpha_bounds=(0, 500), k_bounds=(5, 15))\nneighbour_search_params = clmod.HnswGraphArgs(query_args=dict(ef=1100),\n                                              init_args=dict(method=\"hnsw\",\n                                                             space=\"cosinesimil_sparse\",\n                                                             data_type=nmslib.DataType.SPARSE_VECTOR))\nmacest_model = clmod.ModelWithConfidence(model,\n                                       X_conf_train,\n                                       y_conf_train,\n                                       search_method_args=neighbour_search_params)\n\nmacest_model.fit(X_cal, y_cal)\n\nmacest_point_prediction_conf = macest_model.predict_confidence_of_point_prediction(X_test)\n\n```\n\n## Contributing\nSee the [`CONTRIBUTING.md`](./CONTRIBUTING.md) file for information about contributing to MACEst.\n\n\n## License\nCopyright (c) 2021, Oracle and/or its affiliates. All rights reserved.\n\nThis library is licensed under Universal Permissive License (UPL) 1.0 as shown at \nhttps://oss.oracle.com/licenses/upl\n\nSee [LICENSE.txt](./LICENSE.txt) for more details.\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/oracle/macest",
    "keywords": "",
    "license": "??",
    "maintainer": "",
    "maintainer_email": "",
    "name": "macest",
    "package_url": "https://pypi.org/project/macest/",
    "platform": "",
    "project_url": "https://pypi.org/project/macest/",
    "project_urls": {
      "Homepage": "https://github.com/oracle/macest"
    },
    "release_url": "https://pypi.org/project/macest/1.0.0/",
    "requires_dist": [
      "matplotlib (==3.1.1)",
      "numpy (==1.19.0)",
      "pandas (==1.0.3)",
      "scikit-learn (==0.22.1)",
      "scipy (==1.4.1)",
      "seaborn (==0.11.0)",
      "nmslib (==2.0.6)",
      "typing-extensions (==3.7.4.3)"
    ],
    "requires_python": "",
    "summary": "",
    "version": "1.0.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 11197937,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "5c39df1d4ae6bce240a5fbb6a5532a170d546aa09d29cd509674133bbdf3025e",
        "md5": "c32f8062f98ae1204aaa2dfbf7d67112",
        "sha256": "7017507fd16bda173522666f4c9420a2f79e0e0ff1b3fb2ac2d5850274a5c2ab"
      },
      "downloads": -1,
      "filename": "macest-1.0.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "c32f8062f98ae1204aaa2dfbf7d67112",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 31268,
      "upload_time": "2021-08-17T08:24:44",
      "upload_time_iso_8601": "2021-08-17T08:24:44.326782Z",
      "url": "https://files.pythonhosted.org/packages/5c/39/df1d4ae6bce240a5fbb6a5532a170d546aa09d29cd509674133bbdf3025e/macest-1.0.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "b18fa06918f4a2b56e0c589887a4967dcf2a3b1edd87077f9709ffe9482a96ca",
        "md5": "77958b88c2404a83a1e2219cb779aa01",
        "sha256": "f3aba0d8ab25525d484b9c9c8839cdc0febd716beb6500a232d9ec0c6ec679c1"
      },
      "downloads": -1,
      "filename": "macest-1.0.0.tar.gz",
      "has_sig": false,
      "md5_digest": "77958b88c2404a83a1e2219cb779aa01",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 28867,
      "upload_time": "2021-08-17T08:24:46",
      "upload_time_iso_8601": "2021-08-17T08:24:46.422631Z",
      "url": "https://files.pythonhosted.org/packages/b1/8f/a06918f4a2b56e0c589887a4967dcf2a3b1edd87077f9709ffe9482a96ca/macest-1.0.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}