{
  "info": {
    "author": "ltshb",
    "author_email": "brice.schaffner@swisstopo.ch",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: BSD License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3 :: Only",
      "Topic :: System :: Logging",
      "Topic :: Utilities"
    ],
    "description": "# Python logging utilities\n\n[![Build Status](https://travis-ci.org/geoadmin/lib-py-logging-utilities.svg?branch=master)](https://travis-ci.org/geoadmin/lib-py-logging-utilities)\n\nThis package implements some usefull logging utilities. Here below are the main features of the package:\n\n- JSON formatter\n- Flask request context record attributes\n- ISO Time in format `YYYY-MM-DDThh:mm:ss.sss±hh:mm`\n- Add constant record attributes\n- Logger Level Filter\n\nAll features can be fully configured from the configuration file.\n\n**NOTE:** only python 3 is supported\n\n## Table of content\n\n- [Installation](#installation)\n- [Contribution](#contribution)\n- [JSON Formatter](#json-formatter)\n- [Flask Request Context](#flask-request-context)\n- [ISO Time with Timezone](#iso-time-with-timezone)\n- [Constant Record Attribute](#constant-record-attribute)\n- [Logger Level Filter](#logger-level-filter)\n- [Basic Usage](#basic-usage)\n  - [Case 1. Simple JSON Output](#case-1-simple-json-output)\n  - [Case 2. JSON Output Configured within Python Code](#case-2-json-output-configured-within-python-code)\n  - [Case 3. JSON Output Configured with a YAML File](#case-3-json-output-configured-with-a-yaml-file)\n  - [Case 4. Add Flask Request Context Attributes to JSON Output](#case-4-add-flask-request-context-attributes-to-json-output)\n- [Credits](#credits)\n\n## Installation\n\n__logging_utilities__ is available on PyPI.\n\nUse pip to install:\n\n```shell\npip install logging-utilities\n```\n\n## Contribution\n\nEvery contribution to this library is welcome ! So if you find a bug or want to add a new feature everyone is welcome to open an [issue](https://github.com/geoadmin/lib-py-logging-utilities/issues) or created a [Pull Request](https://github.com/geoadmin/lib-py-logging-utilities/pulls).\n\n### Developper\n\nYou can quickly setup your environment with the makefile:\n\n```bash\nmake setup\n```\n\nThis will create a virtual python environment with all packages required for the develpment.\n\nNote that for pull request, the code **MUST BE** with `yapf` formatted and it also **MUST PASS** the linter. For this you can use the make targets:\n\n```bash\nmake format\nmake lint\n#or\nmake format-lint\n```\n\nAny new feature should have its unittest class in order to be tested.\n\n## JSON Formatter\n\n**JsonFormatter** is a python logging formatter that transform the log output into a json object.\n\nJSON log format is quite usefull especially when the logs are sent to **LogStash**.\n\nThis formatter supports embedded object as well as array.\n\n### Configure JSON Format\n\nThe format can be configured either using the `format` config parameter or the `fmt` constructor parameter. This parameter should be a dictionary (for Python version below 3.7, it is better to use `OrderedDict` to keep the attribute order). Each _key_ is taken as such as _key_ for the output JSON object, while each value is transformed as follow in the output:\n\n| Value        | Type   | Transformation        | Example        |\n---------------|--------|-----------------------|----------------|\n| attribute    | string | The string is a _LogRecord_ attribute name,<br/>then the value of this attribute is used as output. | `\"message\"` |\n| str format   | string | The string contains named string format,<br/>each named format are replaced by the corresponding <br/>_LogRecord_ attribute value. | `\"%(asctime)s.%(msecs)s\"` |\n| object | dict | The object is embedded in the output with its value<br/>following the same rules as defined in this table. | `{\"lineno\": \"lineno\", \"file\": \"filename\"}` |\n| array | list | The list is embedded as an _array_ in the output.<br>Each value is processed using the rules from this table | `[\"created\", \"asctime\"]` |\n\nYou can find the _LogRecord_ attributes list in [Python Doc](https://docs.python.org/3.7/library/logging.html#logrecord-attributes)\n\n### JSON Formatter Options\n\nYou can change some behavior using the `JsonFormatter` constructor:\n\n| Parameter | Type | Default | Description                                       |\n|-----------|------|---------|---------------------------------------------------|\n| fmt       | dict | `None`  | Define the output format, see [Configure JSON Format](#configure-json-format) |\n| datefmt   | string | `None`  | Date format for `asctime`, see [time.strftime()](https://docs.python.org/3.7/library/time.html#time.strftime) |\n| style     | string | `%`     | String formatting style, see [logging.Formatter](https://docs.python.org/3.7/library/logging.html#logging.Formatter) |\n| add_always_extra | bool |`False` | When `True`, logging extra (`logging.log('message', extra={'my-extra': 'some value'})`) are always added to the output. Otherwise they are only added if present in `fmt`. |\n| filter_attributes | list | `None` | When the formatter is used with a _Logging.Filter_ that adds _LogRecord_ attributes, they can be listed here to avoid to be treated as logging _extra_. |\n| remove_empty | bool | `False` | When `True`, empty values (empty list, dict, None or empty string) are removed from output. |\n\nThe constructor parameters can be also be specified in the log configuration file using the `()` class specifier instead of `class`:\n\n```yaml\nformatters:\n  json:\n    (): logging_utilities.formatters.json_formatter.JsonFormatter\n    add_always_extra: True\n    fmt:\n      time: asctime\n      level: levelname\n      logger: name\n      module: module\n      message: message\n```\n\n## Flask Request Context\n\nWhen using logging within a [Flask](https://flask.palletsprojects.com/en/1.1.x/) application, you can use this _Filter_ to add some context attributes to all _LogRecord_.\n\nAll _Flask Request_ attributes are supported and they are added as _LogRecord_ with the `flask_request_` prefix.\n\n### Flask Request Context Filter Constructor\n\n| Parameter  | Type | Default | Description                                    |\n|------------|------|---------|------------------------------------------------|\n| attributes | list | None    | List of Flask Request attributes name to add to the _LogRecord_ |\n\n### Flask Request Context Config Example\n\n```yaml\nfilters:\n  flask:\n    (): logging_utilities.filters.flask_attribute.FlaskRequestAttribute\n    attributes:\n      - url\n      - method\n      - headers\n      - remote_addr\n      - json\n```\n\n**NOTE**: `FlaskRequestAttribute` only support the special key `'()'` factory in the configuration file (it doesn't work with the normal `'class'` key).\n\n## ISO Time with Timezone\n\nThe standard logging doesn't support the time as ISO with timezone; `YYYY-MM-DDThh:mm:ss.sss±hh:mm`. By default `asctime` uses a ISO like format; `YYYY-MM-DD hh:mm:ss.sss`, but without `T` separator (although this one could be configured by overriding a global variable, this can't be done by config file). You can use the `datefmt` option to specify another date format, however this one don't supports milliseconds, so you could achieve this format: `YYYY-MM-DDThh:mm:ss±hh:mm`.\n\nThis Filter can be used to achieve the full ISO 8601 Time format including timezone and milliseconds.\n\n### ISO Time Filter Constructor\n\n| Parameter   | Type | Default | Description                                    |\n|-------------|------|---------|------------------------------------------------|\n| isotime     | bool | True    | Add log local time as `isotime` attribute to _LogRecord_ with the `YYYY-MM-DDThh:mm:ss.sss±hh:mm` format. |\n| utc_isotime | bool | False   | Add log UTC time as `utc_isotime` attribute to _LogRecord_ with the `YYYY-MM-DDThh:mm:ss.sss±hh:mm` format. |\n\n### ISO Time Config Example\n\n```yaml\nfilters:\n  isotime:\n    (): logging_utilities.filters.TimeAttribute\n    utc_isotime: True\n    isotime: False\n```\n\n**NOTE**: `TimeAttribute` only support the special key `'()'` factory in the configuration file (it doesn't work with the normal `'class'` key).\n\n## Constant Record Attribute\n\nSimple logging _Filter_ to add constant attribute to every _LogRecord_\n\n### Constant Record Attribute Config Example\n\n```yaml\nfilters:\n  application:\n    (): logging_utilities.filters.ConstAttribute\n    application: my-application\n```\n\n**NOTE**: `ConstAttribute` only support the special key `'()'` factory in the configuration file (it doesn't work with the normal `'class'` key).\n\n## Logger Level Filter\n\nSometimes you might want to have different log Level based on the logger and handler. The standard logging library allow to set a logger level or a handler level but not based on both. Let say you have a config with two loggers logging to two handlers, on the first handler you want all messages of both loggers and on the second handler you want all messages of the first logger but only the WARNING messages of the second logger. This is here were this filter come into play.\n\n### Logger Level Filter Constructor\n\n| Parameter   | Type | Default | Description                                    |\n|-------------|------|---------|------------------------------------------------|\n| level       | int \\| string | `'DEBUG'` | All messages with a lower level than this one will be filtered out. |\n| logger | string | `''` | When non empty, only message from this logger will be fitlered out based on their level. |\n\n### Logger Level Filter Config Example\n\n```yaml\nroot:\n  handlers:\n    - \"console\"\n    - \"file\"\n  level: \"DEBUG\"\n  propagate: \"True\"\n\nfilters:\n  B_filter:\n    (): logging_utilities.filters.LevelFilter\n    level: \"WARNING\"\n    logger: 'B'\n\nloggers:\n  A:\n    level: \"DEBUG\"\n  B:\n    level: \"DEBUG\"\n\nhandlers:\n  console:\n    class: \"logging.StreamHandler\"\n\n  file:\n    class: \"logging.handlers.RotatingFileHandler\"\n    filters:\n      - \"B_filter\"\n```\n\n**NOTE**: `LevelFilter` only support the special key `'()'` factory in the configuration file (it doesn't work with the normal `'class'` key).\n\n## Basic Usage\n\n### Case 1. Simple JSON Output\n\n```python\nimport logging\n\nfrom logging_utilites.formatters.json_formatter import basic_config\n\n# default keyword parameter `format`: \"\"\"{\"levelname\": \"levelname\", \"name\": \"name\", \"message\": \"message\"}\"\"\"\nbasic_config(level=logging.INFO)\nlogging.info('hello, json_formatter')\n```\n\noutput:\n\n```shell\n{\"levelname\": \"INFO\", \"name\": \"root\", \"message\": \"hello, json_formatter\"}\n```\n\n### Case 2. JSON Output Configured within Python Code\n\n```python\nimport logging\n\nfrom logging_utilites.formatters.json_formatter import JsonFormatter\n\n# `FORMAT` can be `json`, `OrderedDict` or `dict`.\n# If `FORMAT` is `dict` and python version < 3.7.0, the output order is sorted by keys, otherwise it will be the same\n# as the defined order.\n#\n# KEY := string, can be whatever you like.\n# VALUE := `LogRecord` attribute name, string, formatted string (e.g. \"%(asctime)s.%(msecs)s\"), list or dict\nFORMAT = {\n    \"Name\":            \"name\",\n    \"Levelno\":         \"levelno\",\n    \"Levelname\":       \"levelname\",\n    \"Pathname\":        \"pathname\",\n    \"Filename\":        \"filename\",\n    \"Module\":          \"module\",\n    \"Lineno\":          \"lineno\",\n    \"FuncName\":        \"funcName\",\n    \"Created\":         \"created\",\n    \"Asctime\":         \"asctime\",\n    \"Msecs\":           \"msecs\",\n    \"RelativeCreated\": \"relativeCreated\",\n    \"Thread\":          \"thread\",\n    \"ThreadName\":      \"threadName\",\n    \"Process\":         \"process\",\n    \"Message\":         \"message\"\n}\n\nroot = logging.getLogger()\nroot.setLevel(logging.INFO)\n\nformatter = JsonFormatter(FORMAT)\n\nsh = logging.StreamHandler()\nsh.setFormatter(formatter)\nsh.setLevel(logging.INFO)\n\nroot.addHandler(sh)\n\ndef test():\n  root.info(\"test %s format\", 'string')\n\ntest()\n```\n\noutput:\n\n```shell\n{\"Name\": \"root\", \"Levelno\": 20, \"Levelname\": \"INFO\", \"Pathname\": \"test.py\", \"Filename\": \"test.py\", \"Module\": \"test\", \"Lineno\": 75, \"FuncName\": \"test\", \"Created\": 1588185267.3198836, \"Asctime\": \"2020-04-30 02:34:27,319\", \"Msecs\": 319.8835849761963, \"RelativeCreated\": 88.2880687713623, \"Thread\": 16468, \"ThreadName\": \"MainThread\", \"Process\": 16828, \"Message\": \"test string format\"}\n```\n\n### Case 3. JSON Output Configured with a YAML File\n\nconfig.yaml:\n\n```yaml\nversion: 1\n\nroot:\n  handlers:\n    - console\n  level: DEBUG\n  propagate: True\n\nformatters:\n  json:\n    class: logging_utilities.formatters.json_formatter.JsonFormatter\n    format:\n      time: asctime\n      level: levelname\n      logger: name\n      module: module\n      function: funcName\n      process: process\n      thread: thread\n      message: message\n\nhandlers:\n  console:\n    class: logging.StreamHandler\n    formatter: json\n    stream: ext://sys.stdout\n```\n\nThen in your python code use it as follow:\n\n```python\nimport logging\nimport logging.config\n\nimport yaml\n\n\nconfig = {}\nwith open('example-config.yaml', 'r') as fd:\n    config = yaml.safe_load(fd.read())\n\nlogging.config.dictConfig(config)\n\nroot = logging.getLogger()\nroot.info('Test file config')\n```\n\noutput:\n\n```shell\n{\"function\": \"<module>\", \"level\": \"INFO\", \"logger\": \"root\", \"message\": \"Test file config\", \"module\": \"<stdin>\", \"process\": 12264, \"thread\": 139815989413696, \"time\": \"asctime\"}\n```\n\n### Case 4. Add Flask Request Context Attributes to JSON Output\n\nconfig.yaml\n\n```yaml\nversion: 1\n\nroot:\n  handlers:\n    - console\n  level: DEBUG\n  propagate: True\n\nfilters:\n  isotime:\n    (): logging_utilities.filters.TimeAttribute\n  flask:\n    (): logging_utilities.filters.flask_attribute.FlaskRequestAttribute\n    attributes:\n      - url\n      - method\n      - headers\n      - remote_addr\n      - json\n\nformatters:\n  json:\n    class: logging_utilities.formatters.json_formatter.JsonFormatter\n    format:\n      time: isotime\n      level: levelname\n      logger: name\n      module: module\n      function: funcName\n      process: process\n      thread: thread\n      request:\n        url: flask_request_url\n        method: flask_request_method\n        headers: flask_request_headers\n        data: flask_request_json\n        remote: flask_request_remote_addr\n      message: message\n\nhandlers:\n  console:\n    class: logging.StreamHandler\n    formatter: json\n    stream: ext://sys.stdout\n    filters:\n      - isotime\n      - flask\n```\n\n**NOTE:** This require to have `flask` package installed otherwise it raises `ImportError`\n\nThen in your python code use it as follow:\n\n```python\nimport logging\nimport logging.config\n\nimport yaml\n\n\nconfig = {}\nwith open('example-config.yaml', 'r') as fd:\n    config = yaml.safe_load(fd.read())\n\nlogging.config.dictConfig(config)\n\nroot = logging.getLogger()\nroot.info('Test file config')\n```\n\noutput:\n\n```shell\n{\"function\": \"<module>\", \"level\": \"INFO\", \"logger\": \"root\", \"message\": \"Test file config\", \"module\": \"<stdin>\", \"process\": 24190, \"request\": {\"url\": \"\", \"method\": \"\", \"headers\": \"\", \"data\": \"\", \"remote\": \"\"}, \"thread\": 140163374577472, \"time\": \"isotime\"}\n```\n\n## Credits\n\nThe JSON Formatter implementation has been inspired by [MyColorfulDays/jsonformatter](https://github.com/MyColorfulDays/jsonformatter)\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/geoadmin/lib-py-logging-utilities",
    "keywords": "",
    "license": "BSD 3-Clause License",
    "maintainer": "",
    "maintainer_email": "",
    "name": "logging-utilities",
    "package_url": "https://pypi.org/project/logging-utilities/",
    "platform": "all",
    "project_url": "https://pypi.org/project/logging-utilities/",
    "project_urls": {
      "Homepage": "https://github.com/geoadmin/lib-py-logging-utilities"
    },
    "release_url": "https://pypi.org/project/logging-utilities/1.0.0/",
    "requires_dist": null,
    "requires_python": ">=3.0",
    "summary": "Python logging utilities",
    "version": "1.0.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16548657,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "cbf7593807d2efa3c6bc75c9baeb192bca0cd346245c72da500ef3ba7d0c7e91",
        "md5": "0708e9c6a200c9c55e8639427a1925f7",
        "sha256": "3676bd404f7e171e37748d8080d2af3b8e901caac24e1c3ddef0ee1a2beaa383"
      },
      "downloads": -1,
      "filename": "logging_utilities-1.0.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "0708e9c6a200c9c55e8639427a1925f7",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.0",
      "size": 15902,
      "upload_time": "2020-09-10T12:52:56",
      "upload_time_iso_8601": "2020-09-10T12:52:56.258328Z",
      "url": "https://files.pythonhosted.org/packages/cb/f7/593807d2efa3c6bc75c9baeb192bca0cd346245c72da500ef3ba7d0c7e91/logging_utilities-1.0.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "2a59c0bcba6dd9c4a71acd94c870f4818f121f4d3c1454cb7eff82122a4bd144",
        "md5": "dce20c5ca97ecc480d2cb469c65124d7",
        "sha256": "5319cef46943dbdf3921f3638725552af8850fbde47a39c13812111ed9d34901"
      },
      "downloads": -1,
      "filename": "logging-utilities-1.0.0.tar.gz",
      "has_sig": false,
      "md5_digest": "dce20c5ca97ecc480d2cb469c65124d7",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.0",
      "size": 20493,
      "upload_time": "2020-09-10T12:52:57",
      "upload_time_iso_8601": "2020-09-10T12:52:57.723196Z",
      "url": "https://files.pythonhosted.org/packages/2a/59/c0bcba6dd9c4a71acd94c870f4818f121f4d3c1454cb7eff82122a4bd144/logging-utilities-1.0.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}