{
  "info": {
    "author": "ltshb",
    "author_email": "brice.schaffner@swisstopo.ch",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Framework :: Django",
      "Framework :: Flask",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: BSD License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3 :: Only",
      "Topic :: Software Development :: Libraries",
      "Topic :: Software Development :: Libraries :: Python Modules",
      "Topic :: System :: Logging",
      "Topic :: Utilities"
    ],
    "description": "# Python logging utilities\n\n![Build Status](https://codebuild.eu-central-1.amazonaws.com/badges?uuid=eyJlbmNyeXB0ZWREYXRhIjoiTGJzNVpFWUdESWd3c2VWUyt0M1NoYmY4MzVBTEtLZkFKa0FxRFhFa2lwS2JobEhkamR4T2E0ZlZ0OG1hekZrQjlhOWd4QmtydXZ4eHBmblJ3VDBKd3F3PSIsIml2UGFyYW1ldGVyU3BlYyI6ImZEQzE0Rzd6andXYUEyQy8iLCJtYXRlcmlhbFNldFNlcmlhbCI6MX0%3D&branch=master)\n[![PyPI version](https://badge.fury.io/py/logging-utilities.svg)](https://badge.fury.io/py/logging-utilities)\n\nThis package implements some useful logging utilities. Here below are the main features of the package:\n\n- JSON formatter\n- Text formatter with `extra`\n- Flask request context record attributes\n- Jsonify Django request record attribute\n- ISO Time in format `YYYY-MM-DDThh:mm:ss.sss±hh:mm`\n- Add constant record attributes\n- Logger Level Filter\n\nAll features can be fully configured from the configuration file.\n\n**NOTE:** only python 3 is supported\n\n:warning: **Version 3.x.x BREAKING CHANGES** see [Breaking Changes](#version-3xx-breaking-changes)\n\n## Table of content\n\n- [Table of content](#table-of-content)\n- [Installation](#installation)\n- [Release and Publish](#release-and-publish)\n- [Contribution](#contribution)\n  - [Developer](#developer)\n- [Ignore missing log record attribute in formatter](#ignore-missing-log-record-attribute-in-formatter)\n  - [LogRecordIgnoreMissing](#logrecordignoremissing)\n- [JSON Formatter](#json-formatter)\n  - [Configure JSON Format](#configure-json-format)\n  - [JSON Formatter Options](#json-formatter-options)\n  - [JSON Output - Type Consistency](#json-output---type-consistency)\n- [Extra Formatter](#extra-formatter)\n  - [Extra Formatter Constructor](#extra-formatter-constructor)\n  - [Extra Formatter Config Example](#extra-formatter-config-example)\n- [Flask Request Context](#flask-request-context)\n  - [Flask Request Context Filter Constructor](#flask-request-context-filter-constructor)\n  - [Flask Request Context Config Example](#flask-request-context-config-example)\n- [Jsonify Django Request](#jsonify-django-request)\n  - [Usage](#usage)\n  - [Django Request Filter Constructor](#django-request-filter-constructor)\n  - [Django Request Config Example](#django-request-config-example)\n- [ISO Time with Timezone](#iso-time-with-timezone)\n  - [ISO Time Filter Constructor](#iso-time-filter-constructor)\n  - [ISO Time Config Example](#iso-time-config-example)\n- [Constant Record Attribute](#constant-record-attribute)\n  - [Constant Record Attribute Config Example](#constant-record-attribute-config-example)\n- [Logger Level Filter](#logger-level-filter)\n  - [Logger Level Filter Constructor](#logger-level-filter-constructor)\n  - [Logger Level Filter Config Example](#logger-level-filter-config-example)\n- [Basic Usage](#basic-usage)\n  - [Case 1. Simple JSON Output](#case-1-simple-json-output)\n  - [Case 2. JSON Output Configured within Python Code](#case-2-json-output-configured-within-python-code)\n  - [Case 3. JSON Output Configured with a YAML File](#case-3-json-output-configured-with-a-yaml-file)\n  - [Case 4. Add Flask Request Context Attributes to JSON Output](#case-4-add-flask-request-context-attributes-to-json-output)\n  - [Case 5. Add Django Request to JSON Output](#case-5-add-django-request-to-json-output)\n  - [Case 6. Add parts of Django Request to JSON Output](#case-6-add-parts-of-django-request-to-json-output)\n  - [Case 7. Add all Log Extra as Dictionary to the Standard Formatter (including Django log extra)](#case-7-add-all-log-extra-as-dictionary-to-the-standard-formatter-including-django-log-extra)\n  - [Case 8. Add Specific Log Extra to the Standard Formatter](#case-8-add-specific-log-extra-to-the-standard-formatter)\n- [Breaking Changes](#breaking-changes)\n  - [Version 3.x.x Breaking Changes](#version-3xx-breaking-changes)\n  - [Version 2.x.x Breaking Changes](#version-2xx-breaking-changes)\n- [Credits](#credits)\n\n## Installation\n\n**logging_utilities** is available on PyPI.\n\nUse pip to install:\n\n```shell\npip install logging-utilities\n```\n\n## Release and Publish\n\nOnly owners are allowed to publish a new version to PyPI. To publish a new version follow the procedure below:\n\n1. Increase the `VERSION` in `logging_utilities/__init__.py`\n    - Major version for outbreak changes in the user interface (no backward compatibility)\n    - Minor version for new features\n    - Patch version for bug fixes\n    - For alpha version append `alpha1` to `VERSION`\n1. Commit and push the changes to `develop` branch\n1. Merge `develop` to  `master`\n1. From `master` branch enter\n\n    ```shell\n    summon -p gopass --up make publish\n    ```\n\n**NOTE**: this requires to have `summon`, `gopass` and the correct `secrets.yml` file in a parent folder.\n\n## Contribution\n\nEvery contribution to this library is welcome ! So if you find a bug or want to add a new feature everyone is welcome to open an [issue](https://github.com/geoadmin/lib-py-logging-utilities/issues) or created a [Pull Request](https://github.com/geoadmin/lib-py-logging-utilities/pulls).\n\nAny contribution must follow the [git-flow](https://nvie.com/posts/a-successful-git-branching-model/#the-main-branches).\n\n### Developer\n\nYou can quickly setup your environment with the makefile:\n\n```bash\nmake setup\n```\n\nThis will create a virtual python environment with all packages required for the development.\n\nNote that for pull request, the code **MUST BE** with `yapf` formatted and it also **MUST PASS** the linter. For this you can use the make targets:\n\n```bash\nmake format\nmake lint\n#or\nmake format-lint\n```\n\nAny new feature should have its unittest class in order to be tested.\n\n## Ignore missing log record attribute in formatter\n\nWhen configuring a log formatter you can provide via print style any log record attribute including extra attributes. However when using extra attribute, if this attribute is then missing (e.g. because the logger did not add that extra)\nthen the logging would raise a `ValueError: Formatting field not found in record: ...`.\n\nFor the standard Formatter you could use the [Extra Formatter](#extra-formatter), but if you have any other Formatter you\ncan use the global `logging_utilities.log_record.set_log_record_ignore_missing_factory()` method.\n\n### LogRecordIgnoreMissing\n\nThe `LogRecordIgnoreMissing` factory can be used to avoid `ValueError` exception when formatting a log message from\na log record that don't have the extra required by the formatter.\n\nFor example:\n\n```python\nimport logging\n\nlogging.basicConfig(format=\"%(message)s - %(extra_param)s\", level=logging.INFO, force=True)\n\nlogger = logging.getLogger('my-logger')\n\nlogger.info('My message', extra={'extra_param': 20})\nMy message - 20\n\nlogger.info('My second message')\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/usr/lib/python3.8/logging/__init__.py\", line 440, in format\n    return self._format(record)\n  File \"/usr/lib/python3.8/logging/__init__.py\", line 436, in _format\n    return self._fmt % record.__dict__\nKeyError: 'extra_param'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.8/logging/__init__.py\", line 1085, in emit\n    msg = self.format(record)\n  File \"/usr/lib/python3.8/logging/__init__.py\", line 929, in format\n    return fmt.format(record)\n  File \"/usr/lib/python3.8/logging/__init__.py\", line 671, in format\n    s = self.formatMessage(record)\n  File \"/usr/lib/python3.8/logging/__init__.py\", line 640, in formatMessage\n    return self._style.format(record)\n  File \"/usr/lib/python3.8/logging/__init__.py\", line 442, in format\n    raise ValueError('Formatting field not found in record: %s' % e)\nValueError: Formatting field not found in record: 'extra_param'\n...\n```\n\nTo avoid such crash you can use `LogRecordIgnoreMissing` that will replace missing extra attributes by an empty string in the message.\n\n```python\nimport logging\nfrom logging_utilities.log_record import LogRecordIgnoreMissing\n\nlogging.setLogRecordFactory(LogRecordIgnoreMissing)\n\nlogging.basicConfig(format=\"%(message)s - %(extra_param)s\", level=logging.INFO, force=True)\n\nlogger = logging.getLogger('my-logger')\n\nlogger.info('My message', extra={'extra_param': 20})\nMy message - 20\n\nlogger.info('My second message')\nMy second message -\n```\n\nYou can also change the default value by using the helper `set_log_record_ignore_missing_factory()`\n\n```python\nimport logging\nfrom logging_utilities.log_record import set_log_record_ignore_missing_factory\n\nset_log_record_ignore_missing_factory('my-default')\n\nlogging.basicConfig(format=\"%(message)s - %(extra_param)s\", level=logging.INFO, force=True)\n\nlogger = logging.getLogger('my-logger')\n\nlogger.info('My message', extra={'extra_param': 20})\nMy message - 20\n\nlogger.info('My second message')\nMy second message - my-default\n```\n\n:warning: **NOTE that setting the log record factory is a global action that affects every logger and formatter**\n\n## JSON Formatter\n\n**JsonFormatter** is a python logging formatter that transform the log output into a json object.\n\nJSON log format is quite useful especially when the logs are sent to **LogStash**.\n\nThis formatter supports embedded object as well as array.\n\n### Configure JSON Format\n\nThe format can be configured either using the `format` config parameter or the `fmt` constructor parameter. This parameter should be a dictionary (for Python version below 3.7, it is better to use `OrderedDict` to keep the attribute order). Each _key_ is taken as such as _key_ for the output JSON object, while each value is transformed as follow in the output:\n\n| Value        | Type   | Transformation        | Example        |\n---------------|--------|-----------------------|----------------|\n| `LogRecord` attribute  | string | The string is a `LogRecord` attribute name,<br/>then the value of this attribute is used as output. See also [Type Consistency](#json-output---type-consistency). | `\"message\"` |\n| `LogRecord` attribute dotted key | string | The string is a dotted key to access a sub key of a `LogRecord` dictionary attribute.<br/>For example if the `LogRecord` contains a dictionary attribute added via an `extra`, you can use the dotted notation to access only a sub object/value of this dictionary. Note if the dotted key attribute doesn't exists it will raise a `ValueError` unless you set `ignore_missing=True` in the Formatter config. In the latest case missing attribute will be replaced by `''` unless the dotted key has a trailing `.` then the default value will be `{}` instead of `''`.<br/>See also [Type Consistency](#json-output---type-consistency). | `\"request.path\"` |\n| Named string format   | string | The string contains named string format,<br/>each named format are replaced by the corresponding <br/>_LogRecord_ attribute value.<br/>When using the `%` string formatting style, you can also used dotted notation to access dictionary sub-key; `%(request.headers)s`. NOTE that in string format the dictionary key must be a valid python attribute name (cannot contain spaces or special characters). | `\"%(asctime)s.%(msecs)s\"` |\n| Object | dict | The object is embedded in the output with its value<br/>following the same rules as defined in this table. | `{\"lineno\": \"lineno\", \"file\": \"filename\", \"id\": \"%(process)x/%(thread)x\", \"message\": \"message\"}` |\n| Array | list | The list is embedded as an _array_ in the output.<br>Each value is processed using the rules from this table | `[\"created\", \"asctime\", \"message\", \"%(process)x/%(thread)x\"]` |\n\n:warning: **If the value doesn't match any of the table above it will raise a `ValueError` unless you specify `ignore_missing=True` in the configuration**\n\nYou can find the _LogRecord_ attributes list in [Python Doc](https://docs.python.org/3.7/library/logging.html#logrecord-attributes)\n\nSee below the [Basic Usage](#basic-usage) for more examples.\n\n### JSON Formatter Options\n\nYou can change some behavior using the `JsonFormatter` constructor:\n\n| Parameter | Type | Default | Description                                       |\n|-----------|------|---------|---------------------------------------------------|\n| `fmt`       | dict | `{'levelname': 'levelname', 'name': 'name', 'message': 'message'}`  | Define the output format, see [Configure JSON Format](#configure-json-format) |\n| `datefmt`   | string | `None`  | Date format for `asctime`, see [time.strftime()](https://docs.python.org/3.7/library/time.html#time.strftime) |\n| `style`     | string | `%`     | String formatting style, see [logging.Formatter](https://docs.python.org/3.7/library/logging.html#logging.Formatter) |\n| `add_always_extra` | bool |`False` | When `True`, logging extra (`logging.log('message', extra={'my-extra': 'some value'})`) are always added to the output. Otherwise they are only added if present in `fmt`. |\n| `filter_attributes` | list | `None` | When the formatter is used with a _Logging.Filter_ that adds _LogRecord_ attributes, they can be listed here to avoid to be treated as logging _extra_. |\n| `remove_empty` | bool | `False` | When `True`, empty values (empty list, dict, None or empty string) are removed from output. |\n| `ignore_missing` | bool | `False` | If `True`, then all extra attributes from the log record that are missing (accessed by the `fmt` parameter) will be replaced by an empty string instead of raising a ValueError exception. **NOTE:** This has an impact on all formater not only on this one, see [LogRecordIgnoreMissing](#logrecordignoremissing). |\n\nThe constructor parameters can be also be specified in the log configuration file using the `()` class specifier instead of `class`:\n\n```yaml\nformatters:\n  json:\n    (): logging_utilities.formatters.json_formatter.JsonFormatter\n    add_always_extra: True\n    fmt:\n      time: asctime\n      level: levelname\n      logger: name\n      module: module\n      message: message\n```\n\n**:warning: When using the INI file format like documented [here](https://docs.python.org/3.9/library/logging.config.html#logging-config-fileformat), you cannot use the JSON formatter options describe above and have to use the formatter using the `class`, `format`, `datefmt` and `style` attributes like below**\n\n```ini\n[formatters]\nkeys = my_json\n\n[formatter_my_json]\nclass = logging_utilities.formatters.json_formatter.JsonFormatter\nformat: {\n        \"time\": \"asctime\",\n        \"level\": \"levelname\",\n        \"logger\": \"name\",\n        \"module\": \"module\",\n        \"function\": \"funcName\",\n        \"pid_tid\": \"%(process)x/%(thread)x\",\n        \"message\": \"message\",\n        \"exc_info\": \"exc_info\"\n    } # OPTIONAL\ndatefmt = %Y-%m-%d %H:%M # OPTIONAL\nstyle = % # OPTIONAL\n```\n\n### JSON Output - Type Consistency\n\nWhen you use `ignore_missing=True`, all missing attributes from the log record will be replaced by an empty string. This can be an issue if you require type consistency accross JSON logs. To avoid this, you can use the trailing dot notation.\n\n||||\n|---|---|---|\n| Single trailing dot | `attribute_name.`  | Default to `{}` when `attribute_name` is missing from log record |\n| Double trailing dot | `attribute_name..` | Default to `[]` when `attribute_name` is missing from log record |\n\nThis is quite usefull if you want to add a list or an object in your JSON from a LogRecord that might be missing. For example when using the [Flask Request Context](#flask-request-context) and you want to add the headers dictionary as object, you can do as follow:\n\n```python\nfmt={\"message\": \"message\", \"request\": {\"headers\": \"flask_request_headers.\"}}\n```\n\nThis way if the log record is outside a Flask request, your log output would be\n\n`{\"message\": \"this is the message\", \"request\": {\"headers\": {}}}`\n\ninstead of\n\n`{\"message\": \"this is the message\", \"request\": {\"headers\": \"\"}}`\n\nand when the record is within a Flask context you will have\n\n`{\"message\": \"this is the message\", \"request\": {\"headers\": {\"Host\": \"www.example.com\", ...}}}`\n\n## Extra Formatter\n\nThis formatter enhance the python standard formatter to allow working with the log `extra`.\nWhen adding an `extra` keyword in the format, the python standard formatter raises a `ValueError()`\nwhen this keyword is missing from log record. This means that if you want to display a log\n`extra`, you have to make sure that every log message contains this `extra`.\n\nThis formatter allow you to provide an `extra_fmt` parameter that will add record `extra` to the\nlog message when available. You can either add the entire extra dictionary: `extra_fmt='%s'` or\nonly some extras: `extra_fmt='%(extra1)s:%(extra2)s'`. In the latest case, when a key is missing\nin extra, the value is replaced by `extra_default`.\n\nWhen using the whole `extra` dictionary, you can use `extra_pretty_print` to improve the\nformatting, note that in this case the log might be on multiline (this use `pprint.pformat`).\n\nSee [logging.Logger.debug](https://docs.python.org/3.8/library/logging.html#logging.Logger.debug) for more infos on the logging `extra`\n\n### Extra Formatter Constructor\n\nSupport the same arguments as the [logging.Formatter](https://docs.python.org/3.5/library/logging.html#logging.Formatter)\nplus the followings:\n\n| Parameter  | Type     | Default | Description                                    |\n|------------|----------|---------|------------------------------------------------|\n| extra_fmt  | None\\|str | None    | When not `None`, adds the `extra` at the end of the log message. Either uses named placeholder with the extra keywords or add the whole `extra` directory using `%s`. |\n| extra_default | None\\|str | '' | When `extra_fmt` contains named placeholders and one or more of these placeholders are not found in the log record, then the formatter uses this default value instead. |\n| extra_default | any | '' | When using `extra_fmt` with named placeholders and a keyword is missing in the log record, it is then replaced by this value. |\n| extra_pretty_print | boolean | False | When `extra_fmt='%s'` you can set this flag to `True` to use `pprint.pformat` on the dictionary. |\n| pretty_print_kwargs | None\\|dict | None | kwargs as dictionary to pass to [pprint.pformat](https://docs.python.org/3.6/library/pprint.html#pprint.pformat) |\n\n### Extra Formatter Config Example\n\n```yaml\nformatters:\n  standard:\n    (): logging_utilities.formatters.extra_formatter.ExtraFormatter\n    format: \"%(levelname)s - %(name)s - %(message)s\"\n    extra_fmt: \" - extra:\\n%s\"\n    extra_pretty_print: True\n```\n\n**NOTE**: `ExtraFormatter` only support the special key `'()'` factory in the configuration file (it doesn't work with the normal `'class'` key).\n\n## Flask Request Context\n\nWhen using logging within a [Flask](https://flask.palletsprojects.com/en/2.1.x/) application, you can use this _Filter_ to add some context attributes to all _LogRecord_.\n\nAll _Flask Request_ attributes are supported and they are added as _LogRecord_ with the `flask_request_` prefix. See [Flask Request](https://flask.palletsprojects.com/en/2.1.x/api/#flask.Request) for more details on available attributes.\n\n### Flask Request Context Filter Constructor\n\n| Parameter  | Type | Default | Description                                    |\n|------------|------|---------|------------------------------------------------|\n| attributes | list | None    | List of Flask Request attributes name to add to the _LogRecord_ |\n\n### Flask Request Context Config Example\n\n```yaml\nversion: 1\n\nroot:\n  handlers:\n    - console\n  level: DEBUG\n  propagate: True\n\nfilters:\n  flask:\n    (): logging_utilities.filters.flask_attribute.FlaskRequestAttribute\n    attributes:\n      - url\n      - method\n      - headers\n      - json\n\nformatters:\n  console:\n    format: \"%(asctime)s - %(message)s - %(flask_request_url)s %(flask_request_method)s %(flask_request_headers)s: %(flask_request_json)s\"\n\nhandlers:\n  console:\n    class: logging.StreamHandler\n    formatter: console\n    stream: ext://sys.stdout\n    filters:\n      - flask\n```\n\n**NOTE**: `FlaskRequestAttribute` only support the special key `'()'` factory in the configuration file (it doesn't work with the normal `'class'` key).\n\n## Jsonify Django Request\n\nIf you want to log the [Django](https://www.djangoproject.com/) [HttpRequest](https://docs.djangoproject.com/en/3.1/ref/request-response/#httprequest-objects) object using the [JSON Formatter](#json-formatter), this filter is for made for you. It converts the `record.request` attribute to a valid json object or a string if the attribute is not an `HttpRequest` instance. It is also useful when using Django with the JSON Formatter because Django adds in some of its logs either an HttpRequest object to the log extra or a socket object.\n\nThe `HttpRequest` attributes that are converted can be configured using the `include_keys` and/or `exclude_keys` filter parameters. This can be useful if you want to limit the log data, for example if you don't want to log Authentication headers.\n\n### Usage\n\nAdd the filter to the log handler and then add simply the `HttpRequest` to the log extra as follow:\n\n```python\nlogger.info('My message', extra={'request': request})\n```\n\n### Django Request Filter Constructor\n\n| Parameter      | Type | Default | Description                                    |\n|----------------|------|---------|------------------------------------------------|\n| `include_keys` | list | None    | All request attributes that match any of the dotted keys of the list will be jsonify in the `record.request`. When `None` then all attributes are added (default behavior). |\n| `exclude_keys` | list | None    | All request attributes that match any of the dotted keys of the list will not be added to the jsonify of the `record.request`. **NOTE** this has precedence to `include_keys` which means that if a key is in both list, then it is not added. |\n\n### Django Request Config Example\n\n```yaml\nfilters:\n  django:\n    (): logging_utilities.filters.django_request.JsonDjangoRequest\n    include_keys:\n      - request.META.REQUEST_METHOD\n      - request.META.SERVER_NAME\n      - request.environ\n    exclude_keys:\n      - request.META.SERVER_NAME\n      - request.environ.wsgi\n```\n\n**NOTE**: `JsonDjangoRequest` only support the special key `'()'` factory in the configuration file (it doesn't work with the normal `'class'` key).\n\n## ISO Time with Timezone\n\nThe standard logging doesn't support the time as ISO with timezone; `YYYY-MM-DDThh:mm:ss.sss±hh:mm`. By default `asctime` uses a ISO like format; `YYYY-MM-DD hh:mm:ss.sss`, but without `T` separator (although this one could be configured by overriding a global variable, this can't be done by config file). You can use the `datefmt` option to specify another date format, however this one don't supports milliseconds, so you could achieve this format: `YYYY-MM-DDThh:mm:ss±hh:mm`.\n\nThis Filter can be used to achieve the full ISO 8601 Time format including timezone and milliseconds.\n\n### ISO Time Filter Constructor\n\n| Parameter   | Type | Default | Description                                    |\n|-------------|------|---------|------------------------------------------------|\n| `isotime`     | bool | True    | Add log local time as `isotime` attribute to _LogRecord_ with the `YYYY-MM-DDThh:mm:ss.sss±hh:mm` format. |\n| `utc_isotime` | bool | False   | Add log UTC time as `utc_isotime` attribute to _LogRecord_ with the `YYYY-MM-DDThh:mm:ss.sss±hh:mm` format. |\n\n### ISO Time Config Example\n\n```yaml\nfilters:\n  isotime:\n    (): logging_utilities.filters.TimeAttribute\n    utc_isotime: True\n    isotime: False\n```\n\n**NOTE**: `TimeAttribute` only support the special key `'()'` factory in the configuration file (it doesn't work with the normal `'class'` key).\n\n## Constant Record Attribute\n\nSimple logging _Filter_ to add constant attribute to every _LogRecord_\n\n### Constant Record Attribute Config Example\n\n```yaml\nfilters:\n  application:\n    (): logging_utilities.filters.ConstAttribute\n    application: my-application\n```\n\n**NOTE**: `ConstAttribute` only support the special key `'()'` factory in the configuration file (it doesn't work with the normal `'class'` key).\n\n## Logger Level Filter\n\nSometimes you might want to have different log Level based on the logger and handler. The standard logging library allow to set a logger level or a handler level but not based on both. Let say you have a config with two loggers logging to two handlers, on the first handler you want all messages of both loggers and on the second handler you want all messages of the first logger but only the WARNING messages of the second logger. This is here were this filter come into play.\n\n### Logger Level Filter Constructor\n\n| Parameter   | Type | Default | Description                                    |\n|-------------|------|---------|------------------------------------------------|\n| level       | int \\| string | `'DEBUG'` | All messages with a lower level than this one will be filtered out. |\n| logger | string | `''` | When non empty, only message from this logger will be filtered out based on their level. |\n\n### Logger Level Filter Config Example\n\n```yaml\nroot:\n  handlers:\n    - \"console\"\n    - \"file\"\n  level: \"DEBUG\"\n  propagate: \"True\"\n\nfilters:\n  B_filter:\n    (): logging_utilities.filters.LevelFilter\n    level: \"WARNING\"\n    logger: 'B'\n\nloggers:\n  A:\n    level: \"DEBUG\"\n  B:\n    level: \"DEBUG\"\n\nhandlers:\n  console:\n    class: \"logging.StreamHandler\"\n\n  file:\n    class: \"logging.handlers.RotatingFileHandler\"\n    filters:\n      - \"B_filter\"\n```\n\n**NOTE**: `LevelFilter` only support the special key `'()'` factory in the configuration file (it doesn't work with the normal `'class'` key).\n\n## Basic Usage\n\n### Case 1. Simple JSON Output\n\n```python\nimport logging\n\nfrom logging_utilities.formatters.json_formatter import basic_config\n\n# default keyword parameter `format`: \"\"\"{\"levelname\": \"levelname\", \"name\": \"name\", \"message\": \"message\"}\"\"\"\nbasic_config(level=logging.INFO)\nlogging.info('hello, json_formatter')\n```\n\noutput:\n\n```shell\n{\"levelname\": \"INFO\", \"name\": \"root\", \"message\": \"hello, json_formatter\"}\n```\n\n### Case 2. JSON Output Configured within Python Code\n\n```python\nimport logging\n\nfrom logging_utilities.formatters.json_formatter import JsonFormatter\n\n# `FORMAT` can be `json`, `OrderedDict` or `dict`.\n# If `FORMAT` is `dict` and python version < 3.7.0, the output order is sorted by keys, otherwise it will be the same\n# as the defined order.\n#\n# KEY := string, can be whatever you like.\n# VALUE := `LogRecord` attribute name, string, formatted string (e.g. \"%(asctime)s.%(msecs)s\"), list or dict\nFORMAT = {\n    \"Name\":            \"name\",\n    \"Levelno\":         \"levelno\",\n    \"Levelname\":       \"levelname\",\n    \"Pathname\":        \"pathname\",\n    \"Filename\":        \"filename\",\n    \"Module\":          \"module\",\n    \"Lineno\":          \"lineno\",\n    \"FuncName\":        \"funcName\",\n    \"Created\":         \"created\",\n    \"Asctime\":         \"asctime\",\n    \"Msecs\":           \"msecs\",\n    \"RelativeCreated\": \"relativeCreated\",\n    \"Thread\":          \"thread\",\n    \"ThreadName\":      \"threadName\",\n    \"Process\":         \"process\",\n    \"Message\":         \"message\"\n}\n\nroot = logging.getLogger()\nroot.setLevel(logging.INFO)\n\nformatter = JsonFormatter(FORMAT)\n\nsh = logging.StreamHandler()\nsh.setFormatter(formatter)\nsh.setLevel(logging.INFO)\n\nroot.addHandler(sh)\n\ndef test():\n  root.info(\"test %s format\", 'string')\n\ntest()\n```\n\noutput:\n\n```shell\n{\n  \"Name\": \"root\", \n  \"Levelno\": 20, \n  \"Levelname\": \"INFO\", \n  \"Pathname\": \"test.py\", \n  \"Filename\": \"test.py\", \n  \"Module\": \"test\", \n  \"Lineno\": 75, \n  \"FuncName\": \"test\", \n  \"Created\": 1588185267.3198836, \n  \"Asctime\": \"2020-04-30 02:34:27,319\", \n  \"Msecs\": 319.8835849761963, \n  \"RelativeCreated\": 88.2880687713623, \n  \"Thread\": 16468, \n  \"ThreadName\": \"MainThread\", \n  \"Process\": 16828, \n  \"Message\": \"test string format\"\n}\n```\n\n### Case 3. JSON Output Configured with a YAML File\n\nconfig.yaml:\n\n```yaml\nversion: 1\n\nroot:\n  handlers:\n    - console\n  level: DEBUG\n  propagate: True\n\nformatters:\n  json:\n    class: logging_utilities.formatters.json_formatter.JsonFormatter\n    format:\n      time: asctime\n      level: levelname\n      logger: name\n      module: module\n      function: funcName\n      process: process\n      thread: thread\n      message: message\n\nhandlers:\n  console:\n    class: logging.StreamHandler\n    formatter: json\n    stream: ext://sys.stdout\n```\n\nThen in your python code use it as follow:\n\n```python\nimport logging\nimport logging.config\n\nimport yaml\n\n\nconfig = {}\nwith open('example-config.yaml', 'r') as fd:\n    config = yaml.safe_load(fd.read())\n\nlogging.config.dictConfig(config)\n\nroot = logging.getLogger()\nroot.info('Test file config')\n```\n\noutput:\n\n```shell\n{\n  \"function\": \"<module>\", \n  \"level\": \"INFO\", \n  \"logger\": \"root\", \n  \"message\": \"Test file config\", \n  \"module\": \"<stdin>\", \n  \"process\": 12264, \n  \"thread\": 139815989413696, \n  \"time\": \"asctime\"\n}\n```\n\n### Case 4. Add Flask Request Context Attributes to JSON Output\n\nconfig.yaml\n\n```yaml\nversion: 1\n\nroot:\n  handlers:\n    - console\n  level: DEBUG\n  propagate: True\n\nfilters:\n  isotime:\n    (): logging_utilities.filters.TimeAttribute\n  flask:\n    (): logging_utilities.filters.flask_attribute.FlaskRequestAttribute\n    attributes:\n      - url\n      - method\n      - headers\n      - remote_addr\n      - json\n\nformatters:\n  json:\n    class: logging_utilities.formatters.json_formatter.JsonFormatter\n    format:\n      time: isotime\n      level: levelname\n      logger: name\n      module: module\n      function: funcName\n      process: process\n      thread: thread\n      request:\n        # We use the \"%()s\" notation here to ensure a string output and also if the LogRecord has\n        # no flask context, meaning no `flask_request_url` attribute, the \"%()s\" notation ensure\n        # to have an empty string instead of treating `flask_request_url` as a string constant.\n        url: \"%(flask_request_url)s\"\n        method: \"%(flask_request_method)s\"\n        # We use a trailing dot here to ensure to have a dictionary output even if the LogRecord \n        # doesn't have a flask_request_headers attribute.\n        headers: flask_request_headers.\n        data: flask_request_json.\n        remote: \"%(flask_request_remote_addr)s\"\n      message: message\n\nhandlers:\n  console:\n    class: logging.StreamHandler\n    formatter: json\n    stream: ext://sys.stdout\n    filters:\n      - isotime\n      - flask\n```\n\n**NOTE:** This require to have `flask` package installed otherwise it raises `ImportError`\n\nThen in your python code use it as follow:\n\n```python\nimport logging\nimport logging.config\n\nimport yaml\nfrom flask import Flask\n\n\nconfig = {}\nwith open('example-config.yaml', 'r') as fd:\n    config = yaml.safe_load(fd.read())\n\nlogging.config.dictConfig(config)\n\napp = Flask('test')\n\nroot = logging.getLogger()\n\nwith app.test_request_context(\"path/test\", method='GET', headers={\"Accept\": \"*/*\"}):\n  root.info('Test file config')\n```\n\noutput:\n\n```shell\n{\n  \"time\": \"2022-07-20T10:09:10.765237+02:00\", \n  \"level\": \"INFO\",\n  \"logger\": \"root\", \n  \"module\": \"<stdin>\", \n  \"function\": \"<module>\", \n  \"process\": 58043, \n  \"thread\": 139717802334016, \n  \"request\": {\n    \"url\": \"http://localhost/path/test\", \n    \"method\": \"GET\", \n    \"headers\": {\n      \"Host\": \"localhost\", \n      \"Accept\": \"*/*\"\n    }, \n    \"data\": null, \n    \"remote\": null\n  }, \n  \"message\": \"Test file config\"\n}\n```\n\n### Case 5. Add Django Request to JSON Output\n\nconfig.yaml\n\n```yaml\nversion: 1\n\nroot:\n  handlers:\n    - console\n  level: DEBUG\n  propagate: True\n\nfilters:\n  isotime:\n    (): logging_utilities.filters.TimeAttribute\n  django:\n    (): logging_utilities.filters.django_request.JsonDjangoRequest\n    include_keys:\n      - request.path\n      - request.method\n      - request.headers\n    exclude_keys:\n      - request.headers.Authorization\n      - request.headers.Proxy-Authorization\n\nformatters:\n  json:\n    class: logging_utilities.formatters.json_formatter.JsonFormatter\n    format:\n      time: isotime\n      level: levelname\n      logger: name\n      module: module\n      function: funcName\n      process: process\n      thread: thread\n      request: request\n      response: response\n      message: message\n\nhandlers:\n  console:\n    class: logging.StreamHandler\n    formatter: json\n    stream: ext://sys.stdout\n    filters:\n      - isotime\n      - django\n```\n\n**NOTE:** This require to have `django` package installed otherwise it raises `ImportError`\n\nThen in your python code use it as follow:\n\n```python\nimport logging\nimport logging.config\n\nimport yaml\n\nfrom django.http import JsonResponse\nfrom django.conf import settings\nfrom django.test import RequestFactory\n\n\nconfig = {}\nwith open('example-config.yaml', 'r') as fd:\n    config = yaml.safe_load(fd.read())\n\nlogging.config.dictConfig(config)\n\nlogger = logging.getLogger('your_logger')\n\ndef my_page(request):\n    answer = {'success': True}\n    logger.info('My page requested', extra={'request': request, 'response': answer})\n    return JsonResponse(answer)\n\nsettings.configure()\nfactory = RequestFactory()\n\nmy_page(factory.get('/my_page?test=true'))\n```\n\noutput:\n\n```shell\n{\n  \"function\": \"my_page\", \n  \"level\": \"INFO\", \n  \"logger\": \"your_logger\", \n  \"message\": \"My page requested\", \n  \"module\": \"<stdin>\", \n  \"process\": 20421, \n  \"request\": {\n    \"method\": \"GET\", \n    \"path\": \"/my_page\", \n    \"headers\": {\n      \"Cookie\": \"\"\n    }\n  }, \n  \"response\": {\n    \"success\": true\n  }, \n  \"thread\": 140433370822464, \n  \"time\": \"2020-10-12T16:44:45.374508+02:00\"\n}\n```\n\n### Case 6. Add parts of Django Request to JSON Output\n\nconfig.yaml\n\n```yaml\nversion: 1\n\nroot:\n  handlers:\n    - console\n  level: DEBUG\n  propagate: True\n\nfilters:\n  isotime:\n    (): logging_utilities.filters.TimeAttribute\n  django:\n    (): logging_utilities.filters.django_request.JsonDjangoRequest\n    include_keys:\n      - request.path\n      - request.method\n      - request.headers\n\nformatters:\n  json:\n    class: logging_utilities.formatters.json_formatter.JsonFormatter\n    format:\n      time: isotime\n      level: levelname\n      logger: name\n      module: module\n      function: funcName\n      process: process\n      thread: thread\n      request_path: request.path\n      request_method: request.method\n      request:\n        # NOTE: django headers name are case sensitive\n        header.accept: request.headers.Accept\n        header.accept-encoding: request.headers.Accept-Encoding \n        header.accept_language: request.headers.Accept-Language \n      message: message\n\nhandlers:\n  console:\n    class: logging.StreamHandler\n    formatter: json\n    stream: ext://sys.stdout\n    filters:\n      - isotime\n      - django\n```\n\n**NOTE:** This require to have `django` package installed otherwise it raises `ImportError`\n\nThen in your python code use it as follow:\n\n```python\nimport logging\nimport logging.config\n\nimport yaml\n\nfrom django.http import JsonResponse\nfrom django.conf import settings\nfrom django.test import RequestFactory\n\n\nconfig = {}\nwith open('example-config.yaml', 'r') as fd:\n    config = yaml.safe_load(fd.read())\n\nlogging.config.dictConfig(config)\n\nlogger = logging.getLogger('your_logger')\n\ndef my_page(request):\n    answer = {'success': True}\n    logger.info('My page requested', extra={'request': request})\n    return JsonResponse(answer)\n\nsettings.configure()\nfactory = RequestFactory()\n\nmy_page(factory.get(\n    '/my_page?test=true', \n    HTTP_ACCEPT='*/*', \n    HTTP_ACCEPT_ENCODING='gzip', \n    HTTP_ACCEPT_LANGUAGE='en')\n)\n```\n\noutput:\n\n```shell\n{\n  \"time\": \"2022-07-20T12:29:19.536922+02:00\",\n  \"level\": \"INFO\",\n  \"logger\": \"your_logger\",\n  \"module\": \"<stdin>\",\n  \"function\": \"my_page\",\n  \"process\": 78479,\n  \"thread\": 139751209555776,\n  \"request_path\": \"/my_page\",\n  \"request_method\": \"GET\",\n  \"request\": {\n    \"header.accept\": \"*/*\",\n    \"header.accept-encoding\": \"gzip\",\n    \"header.accept_language\": \"en\"\n  },\n  \"message\": \"My page requested\"\n}\n```\n\n### Case 7. Add all Log Extra as Dictionary to the Standard Formatter (including Django log extra)\n\nconfig.yaml\n\n```yaml\nversion: 1\n\nroot:\n  handlers:\n    - console\n  level: DEBUG\n  propagate: True\n\nfilters:\n  isotime:\n    (): logging_utilities.filters.TimeAttribute\n  django:\n    (): logging_utilities.filters.django_request.JsonDjangoRequest\n    include_keys:\n      - request.path\n      - request.method\n      - request.headers\n    exclude_keys:\n      - request.headers.Authorization\n      - request.headers.Proxy-Authorization\n\nformatters:\n  standard_extra:\n    (): logging_utilities.formatters.extra_formatter.ExtraFormatter\n    # NOTE also in the constructor the parameter is `fmt` we need to use `format` here\n    format: \"%(isotime)s - %(levelname)s - %(name)s - %(message)s\"\n    extra_fmt: \" - extra:\\n%s\"\n    extra_pretty_print: True\n    pretty_print_kwargs:\n      indent: 2\n      width: 60\n\nhandlers:\n  console:\n    class: logging.StreamHandler\n    formatter: standard_extra\n    stream: ext://sys.stdout\n    filters:\n      - isotime\n      - django\n```\n\n**NOTE:** This require to have `django` package installed otherwise it raises `ImportError`\n\nThen in your python code use it as follow:\n\n```python\n#!.venv/bin/python3\nimport logging\nimport logging.config\n\nimport yaml\n\nfrom django.http import JsonResponse\nfrom django.conf import settings\nfrom django.test import RequestFactory\n\n\nconfig = {}\nwith open('example-config.yaml', 'r') as fd:\n    config = yaml.safe_load(fd.read())\n\nlogging.config.dictConfig(config)\n\nlogger = logging.getLogger('your_logger')\n\ndef my_page(request):\n    answer = {'success': True}\n    logger.info('My page requested', extra={'request': request, 'response': answer})\n    return JsonResponse(answer)\n\nsettings.configure()\nfactory = RequestFactory()\n\nmy_page(factory.get('/my_page?test=true'))\n```\n\noutput:\n\n```shell\n2020-11-19T13:32:58.942568+01:00 - INFO - your_logger - My page requested - extra:\n{ 'request': { 'headers': {'Cookie': ''},\n               'method': 'GET',\n               'path': '/my_page'},\n  'response': {'success': True}}\n```\n\n### Case 8. Add Specific Log Extra to the Standard Formatter\n\nconfig.yaml\n\n```yaml\nversion: 1\n\nroot:\n  handlers:\n    - console\n  level: DEBUG\n  propagate: True\n\nformatters:\n  standard_extra:\n    (): logging_utilities.formatters.extra_formatter.ExtraFormatter\n    # NOTE also in the constructor the parameter is `fmt` we need to use `format` here\n    format: \"%(asctime)s - %(levelname)s - %(name)s - %(message)s\"\n    extra_fmt: \" - extra1=%(extra1)s\"\n\nhandlers:\n  console:\n    class: logging.StreamHandler\n    formatter: standard_extra\n    stream: ext://sys.stdout\n```\n\nThen in your python code use it as follow:\n\n```python\n#!.venv/bin/python3\nimport logging\nimport logging.config\n\nimport yaml\n\nconfig = {}\nwith open('example-config.yaml', 'r') as fd:\n    config = yaml.safe_load(fd.read())\n\nlogging.config.dictConfig(config)\n\nlogger = logging.getLogger('your_logger')\n\nlogger.debug('My log with extras', extra={'extra1': 23, 'extra2': \"don't add this\"})\n```\n\noutput:\n\n```shell\n2020-11-19 13:42:29,424 - DEBUG - your_logger - My log with extras - extra1=23\n```\n\n## Breaking Changes\n\n### Version 3.x.x Breaking Changes\n\nFrom version 2.x.x to version 3.x.x there is the following breaking change:\n\n- JSON Formatter doesn't support anymore string constant in the `fmt` parameter. Now if you want to have a string constant in all of you JSON logs output, you need to use the [Constant Record Attribute Filter](#constant-record-attribute).\n\n### Version 2.x.x Breaking Changes\n\nFrom version 1.x.x to version 2.x.x there is the following breaking change:\n\n- Flask Attribute filter do not set anymore missing Flask attribute to empty string ! So if you configure the Flask attribute you must make sure that all attribute specified in the attribute list, exists. Also if you use the filter on a logger outside of a Flask Request context, the logger will raise a `ValueError` exception due to the missing Flask Request attribute. To avoid this you can use the new [LogRecordIgnoreMissing](#logrecordignoremissing).\n\n## Credits\n\nThe JSON Formatter implementation has been inspired by [MyColorfulDays/jsonformatter](https://github.com/MyColorfulDays/jsonformatter)\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/geoadmin/lib-py-logging-utilities",
    "keywords": "",
    "license": "BSD 3-Clause License",
    "maintainer": "",
    "maintainer_email": "",
    "name": "logging-utilities",
    "package_url": "https://pypi.org/project/logging-utilities/",
    "platform": "all",
    "project_url": "https://pypi.org/project/logging-utilities/",
    "project_urls": {
      "Homepage": "https://github.com/geoadmin/lib-py-logging-utilities"
    },
    "release_url": "https://pypi.org/project/logging-utilities/3.0.0/",
    "requires_dist": null,
    "requires_python": ">=3.0",
    "summary": "A collection of useful logging formatters and filters. JSON Formatter, Extra Formatter, ISO Time Filter, Flask Filter, Django Filter, ...",
    "version": "3.0.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16548657,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "26384accf68ef305eee3c3022a66ed03a820ea9ca42e2e34d35e87cc89dd7cfa",
        "md5": "e4db440de50c75affe9d0b7d19456dfc",
        "sha256": "41df287a05968e37bdc68d593a9ec77046f75906c56bd8f83e51fb5ed12fb3b3"
      },
      "downloads": -1,
      "filename": "logging_utilities-3.0.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "e4db440de50c75affe9d0b7d19456dfc",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.0",
      "size": 37842,
      "upload_time": "2022-08-29T04:46:15",
      "upload_time_iso_8601": "2022-08-29T04:46:15.406579Z",
      "url": "https://files.pythonhosted.org/packages/26/38/4accf68ef305eee3c3022a66ed03a820ea9ca42e2e34d35e87cc89dd7cfa/logging_utilities-3.0.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "7e85749dd8e443b0cd9cac41083b1daca5db2e2774aa5a1f72a5f77ef46bba99",
        "md5": "15da176c72028f2315287b0d969f8781",
        "sha256": "ecc50c8b4eea8c9ffe856945f3ab619d1d28cbd21078a994264418d0a2db0697"
      },
      "downloads": -1,
      "filename": "logging-utilities-3.0.0.tar.gz",
      "has_sig": false,
      "md5_digest": "15da176c72028f2315287b0d969f8781",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.0",
      "size": 50469,
      "upload_time": "2022-08-29T04:46:18",
      "upload_time_iso_8601": "2022-08-29T04:46:18.425472Z",
      "url": "https://files.pythonhosted.org/packages/7e/85/749dd8e443b0cd9cac41083b1daca5db2e2774aa5a1f72a5f77ef46bba99/logging-utilities-3.0.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}