{
  "info": {
    "author": "Marek Robak",
    "author_email": "maro.robak@gmail.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "This package contains OpenAI Gym environment designed for training RL agents to balance double CartPole. The environment is automatically registered under id: double-cartpole-custom-v0, so it can be easily used by RL agent training libraries, such as StableBaselines3.<br /><br />At the https://github.com/mareo1208/Double-cartpole-custom-gym-env-for-reinforcement-learning.git you can find a detailed description of the environment, along with a description of the package installation and sample code made to train and evaluate agents in this environment.<br /><br />This environment was created for the needs of my bachelor's thesis, available at https://www.ap.uj.edu.pl/diplomas/151837/ site.\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "https://pypi.org/project/double-cartpole-custom-gym-env/",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/mareo1208/Double-cartpole-custom-gym-env-for-reinforcement-learning.git",
    "keywords": "reinforcement learning,gym environment,StableBaselines3,OpenAI Gym",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "double-cartpole-custom-gym-env",
    "package_url": "https://pypi.org/project/double-cartpole-custom-gym-env/",
    "platform": null,
    "project_url": "https://pypi.org/project/double-cartpole-custom-gym-env/",
    "project_urls": {
      "Download": "https://pypi.org/project/double-cartpole-custom-gym-env/",
      "Homepage": "https://github.com/mareo1208/Double-cartpole-custom-gym-env-for-reinforcement-learning.git"
    },
    "release_url": "https://pypi.org/project/double-cartpole-custom-gym-env/1.1.2/",
    "requires_dist": [
      "gym",
      "pygame",
      "pymunk",
      "numpy",
      "stable-baselines3[extra]"
    ],
    "requires_python": "",
    "summary": "OpenAI Gym environment designed for training RL agents to balance double CartPole.",
    "version": "1.1.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 13700534,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "1dd28e75d277191ad7dfdf804bd153a3f5768cb5a49f2df355e2e1b37030054e",
        "md5": "5814a2ff44570bce6e0157af7df0c452",
        "sha256": "a41c87898897a696e93cc55ba165c7b7b21e6b33a56b4fb2575f2ca82146b30f"
      },
      "downloads": -1,
      "filename": "double_cartpole_custom_gym_env-1.1.2-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "5814a2ff44570bce6e0157af7df0c452",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 8769,
      "upload_time": "2022-04-23T20:29:06",
      "upload_time_iso_8601": "2022-04-23T20:29:06.773908Z",
      "url": "https://files.pythonhosted.org/packages/1d/d2/8e75d277191ad7dfdf804bd153a3f5768cb5a49f2df355e2e1b37030054e/double_cartpole_custom_gym_env-1.1.2-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "f6e55684fbae6fec3629d1a5fb6fa2f390ecee8e8ef116641dff56409332e26f",
        "md5": "7affd691fa3bbd69b19b69a2813c2f8b",
        "sha256": "a4c6854d37f02063decf4155aedfdbfa433e4212f6dca6727c1c891ba10cce94"
      },
      "downloads": -1,
      "filename": "double_cartpole_custom_gym_env-1.1.2.tar.gz",
      "has_sig": false,
      "md5_digest": "7affd691fa3bbd69b19b69a2813c2f8b",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 8529,
      "upload_time": "2022-04-23T20:29:08",
      "upload_time_iso_8601": "2022-04-23T20:29:08.495156Z",
      "url": "https://files.pythonhosted.org/packages/f6/e5/5684fbae6fec3629d1a5fb6fa2f390ecee8e8ef116641dff56409332e26f/double_cartpole_custom_gym_env-1.1.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}