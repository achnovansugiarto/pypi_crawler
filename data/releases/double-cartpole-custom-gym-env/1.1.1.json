{
  "info": {
    "author": "Marek Robak",
    "author_email": "maro.robak@gmail.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "This package contains OpenAI Gym environment designed for training RL agents to balance double CartPole. The environment is automatically registered under id: double-cartpole-custom-v0, so it can be easily used by RL agent training libraries, such as StableBaselines3.<br /><br />At the https://github.com/mareo1208/Double-cartpole-custom-gym-env-for-reinforcement-learning.git you can find a detailed description of the environment, along with a description of the package installation and sample code made to train and evaluate agents in this environment.<br /><br />This environment was created for the needs of my bachelor's thesis, available at https://www.ap.uj.edu.pl/diplomas/151837/ site.\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "https://pypi.org/project/double-cartpole-custom-gym-env/",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/mareo1208/Double-cartpole-custom-gym-env-for-reinforcement-learning.git",
    "keywords": "reinforcement learning,gym environment,StableBaselines3,OpenAI Gym",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "double-cartpole-custom-gym-env",
    "package_url": "https://pypi.org/project/double-cartpole-custom-gym-env/",
    "platform": null,
    "project_url": "https://pypi.org/project/double-cartpole-custom-gym-env/",
    "project_urls": {
      "Download": "https://pypi.org/project/double-cartpole-custom-gym-env/",
      "Homepage": "https://github.com/mareo1208/Double-cartpole-custom-gym-env-for-reinforcement-learning.git"
    },
    "release_url": "https://pypi.org/project/double-cartpole-custom-gym-env/1.1.1/",
    "requires_dist": [
      "gym",
      "pygame",
      "pymunk",
      "numpy",
      "stable-baselines3[extra]"
    ],
    "requires_python": "",
    "summary": "OpenAI Gym environment designed for training RL agents to balance double CartPole.",
    "version": "1.1.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 13700534,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "6db49b171dd1619069c78f5062aa9c8b3557150a017361212daa54b38b8fdae4",
        "md5": "f990390ab92e19973ae341e6a3da975e",
        "sha256": "b6375fcf0800e3e5c0317d886910d496203e15a366739519909e44df2dc5d28c"
      },
      "downloads": -1,
      "filename": "double_cartpole_custom_gym_env-1.1.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "f990390ab92e19973ae341e6a3da975e",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 8761,
      "upload_time": "2022-04-23T17:46:36",
      "upload_time_iso_8601": "2022-04-23T17:46:36.092155Z",
      "url": "https://files.pythonhosted.org/packages/6d/b4/9b171dd1619069c78f5062aa9c8b3557150a017361212daa54b38b8fdae4/double_cartpole_custom_gym_env-1.1.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "975ff05dd6953e1226257404cce87ac3fd73fd21e5967f91b22e4c806ec21b2e",
        "md5": "b9c58429ad21c99de333c6a89f65bcd2",
        "sha256": "34dc8b82d6cd5c922aaca29b7df6d9ffff608162152be5eb3e16782daac44f84"
      },
      "downloads": -1,
      "filename": "double_cartpole_custom_gym_env-1.1.1.tar.gz",
      "has_sig": false,
      "md5_digest": "b9c58429ad21c99de333c6a89f65bcd2",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 8549,
      "upload_time": "2022-04-23T17:46:37",
      "upload_time_iso_8601": "2022-04-23T17:46:37.752939Z",
      "url": "https://files.pythonhosted.org/packages/97/5f/f05dd6953e1226257404cce87ac3fd73fd21e5967f91b22e4c806ec21b2e/double_cartpole_custom_gym_env-1.1.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}