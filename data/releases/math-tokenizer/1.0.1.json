{
  "info": {
    "author": "Florian Dahlitz",
    "author_email": "f2dahlitz@freenet.de",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3.4",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6"
    ],
    "description": "Math-tokenizer\n==============\n\n|Build Status|\n\nDescription\n-----------\n\nThis is a simple and lightweighted tokenizer for mathematical functions\nwritten in pure Python. It was tested with Python >= 3.4.\n\nversion 1.0.1\n\nFeatures\n--------\n\n-  tokenize mathematical function\n\nFuture features\n---------------\n\n-  create own rules\n\nInstallation\n------------\n\nThe package is available via ``pip``\n\n.. code:: bash\n\n    pip install math-tokenizer\n\nUpdate\n------\n\nYou can also update on the latest version via ``pip`` \\`\\`\\`bash pip\ninstall math-tokenizer â€“upgrade\n\n.. |Build Status| image:: https://travis-ci.org/DahlitzFlorian/math-tokenizer.svg?branch=master\n   :target: https://travis-ci.org/DahlitzFlorian/math-tokenizer\n\n",
    "description_content_type": null,
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/DahlitzFlorian/math-tokenizer",
    "keywords": "tokenizer math math-functions token analysis",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "math-tokenizer",
    "package_url": "https://pypi.org/project/math-tokenizer/",
    "platform": "",
    "project_url": "https://pypi.org/project/math-tokenizer/",
    "project_urls": {
      "Homepage": "https://github.com/DahlitzFlorian/math-tokenizer"
    },
    "release_url": "https://pypi.org/project/math-tokenizer/1.0.1/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "Simple and lightweighted tokenizer for mathematical functions",
    "version": "1.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 2823642,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "cb618b2394d14376585179724603154d353e3b1720b59f42151a2114832109cb",
        "md5": "a26189ae4281187b4b78581b11bcb0b8",
        "sha256": "4c31037db4f0173b28d7df3cb0d5f7d7399062f52310fe1527b45fb8a865ac70"
      },
      "downloads": -1,
      "filename": "math_tokenizer-1.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "a26189ae4281187b4b78581b11bcb0b8",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 3758,
      "upload_time": "2017-04-23T16:21:12",
      "upload_time_iso_8601": "2017-04-23T16:21:12.124222Z",
      "url": "https://files.pythonhosted.org/packages/cb/61/8b2394d14376585179724603154d353e3b1720b59f42151a2114832109cb/math_tokenizer-1.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "7c70404724435619faafa141e800cd870f5365334e36b74da0605b89e7b80257",
        "md5": "5529ba31ff447c1aa7b86a85aead1b21",
        "sha256": "6141000c5faefb109eb4eed07c3c066228c993bd9880ade6a9b4ab9e16883f58"
      },
      "downloads": -1,
      "filename": "math-tokenizer-1.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "5529ba31ff447c1aa7b86a85aead1b21",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 2517,
      "upload_time": "2017-04-23T16:21:13",
      "upload_time_iso_8601": "2017-04-23T16:21:13.308353Z",
      "url": "https://files.pythonhosted.org/packages/7c/70/404724435619faafa141e800cd870f5365334e36b74da0605b89e7b80257/math-tokenizer-1.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}