{
  "info": {
    "author": "yeyupiaoling",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Developers",
      "License :: OSI Approved :: Apache Software License",
      "Natural Language :: Chinese (Simplified)",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Topic :: Utilities"
    ],
    "description": "![python version](https://img.shields.io/badge/python-3.8+-orange.svg)\n![GitHub forks](https://img.shields.io/github/forks/yeyupiaoling/MASR)\n![GitHub Repo stars](https://img.shields.io/github/stars/yeyupiaoling/MASR)\n![GitHub](https://img.shields.io/github/license/yeyupiaoling/MASR)\n![支持系统](https://img.shields.io/badge/支持系统-Win/Linux/MAC-9cf)\n\n# MASR流式与非流式语音识别项目\n\nMASR是一款基于Pytorch实现的自动语音识别框架，MASR全称是神奇的自动语音识别框架（Magical Automatic Speech Recognition），MASR致力于简单，实用的语音识别项目。可部署在服务器，Nvidia Jetson设备，未来还计划支持Android等移动设备。\n\n**如果熟悉PaddlePaddle，请优先使用：[PPASR](https://github.com/yeyupiaoling/PPASR)**\n\n**欢迎大家扫码入QQ群讨论**，或者直接搜索QQ群号`1169600237`，问题答案为博主Github的ID`yeyupiaoling`。\n\n<div align=\"center\">\n  <img src=\"docs/images/qq.png\"/>\n</div>\n\n\n本项目使用的环境：\n - Anaconda 3\n - Python 3.8\n - Pytorch 1.12.1\n - Windows 10 or Ubuntu 18.04\n\n<!--\n## 在线使用\n\n - [在线使用Dome](https://masr.yeyupiaoling.cn)\n-->\n\n## 项目快速了解\n\n 1. 本项目支持流式识别模型`deepspeech2`、`deepspeech2_big`，非流式模型`deepspeech2_no_stream`、`deepspeech2_big_no_stream`。\n 2. 本项目支持两种解码器，分别是集束搜索解码器`ctc_beam_search`和贪心解码器`ctc_greedy`，集束搜索解码器`ctc_beam_search`准确率更高，但不支持Windows。\n\n\n## 更新记录\n\n - 2022.10.01: 调整数据预处理，此前下载的模型，需要重新下载。\n - 2022.09.18: 支持使用WebSocket调用流式识别。\n - 2022.08.27: 修改使用kaldi实现`fbank`和`mfcc`预处理方法。\n - 2022.08.22: 增加非流式模型`deepspeech2_no_stream`和`deepspeech2_big_no_stream`。\n - 2022.08.04: 发布1.0版本，优化实时识别流程。\n - 2022.07.12: 完成GUI界面的录音实时识别。\n - 2022.06.14: 支持`deepspeech2_big`模型，适合WenetSpeech大数据集训练模型。\n - 2022.01.16: 支持多种预处理方法。\n - 2022.01.15: 支持英文语音识别。\n - 2022.01.13: 支持给识别结果加标点符号\n - 2021.12.26: 支持pip方式安装。\n - 2021.12.25: 初步完成基本程序。\n\n\n## 视频讲解\n\n这个是PPSAR的视频教程，项目是通用的，可以参考使用。\n\n - [知识点讲解（哔哩哔哩）](https://www.bilibili.com/video/BV1Rr4y1D7iZ)\n - [流式识别的使用讲解（哔哩哔哩）](https://www.bilibili.com/video/BV1Te4y1h7KK)\n\n\n## 模型下载\n\n本项目支持流式识别模型`deepspeech2`、`deepspeech2_big`，非流式模型`deepspeech2_no_stream`、`deepspeech2_big_no_stream`。\n\n|         使用模型          |                                  数据集                                  | 预处理方式 | 参数大小（M）`*` | 语言  |     测试集字错率（词错率）      |                               下载地址                               |\n|:---------------------:|:---------------------------------------------------------------------:|:-----:|:----------:|:---:|:--------------------:|:----------------------------------------------------------------:|\n|    deepspeech2_big    |            [WenetSpeech](./docs/wenetspeech.md) (10000小时)             | fbank |    167     | 中文  | 0.08944(AIShell的测试集) | [点击下载](https://pan.baidu.com/s/1tGlHCBHF7vIWfU2N_7FE7A?pwd=j8hi) |\n|      deepspeech2      |   [aishell](https://openslr.magicdatatech.com/resources/33) (179小时)   | fbank |     35     | 中文  |       0.08279        | [点击下载](https://pan.baidu.com/s/1TuN6AmTk2EzEvwdf7cMZdg?pwd=quez) |\n|    deepspeech2_big    |   [aishell](https://openslr.magicdatatech.com/resources/33) (179小时)   | fbank |    167     | 中文  |       0.05912        | [点击下载](https://pan.baidu.com/s/1TuN6AmTk2EzEvwdf7cMZdg?pwd=quez) |\n| deepspeech2_no_stream |   [aishell](https://openslr.magicdatatech.com/resources/33) (179小时)   | fbank |     98     | 中文  |       0.06982        | [点击下载](https://pan.baidu.com/s/1TuN6AmTk2EzEvwdf7cMZdg?pwd=quez) |\n|      deepspeech2      | [Librispeech](https://openslr.magicdatatech.com/resources/12) (960小时) | fbank |     35     | 英文  |       0.17901        | [点击下载](https://pan.baidu.com/s/1c57J718blFgUAGqDO-dbJA?pwd=lcjw) | \n|    deepspeech2_big    | [Librispeech](https://openslr.magicdatatech.com/resources/12) (960小时) | fbank |    167     | 英文  |       0.15533        | [点击下载](https://pan.baidu.com/s/1c57J718blFgUAGqDO-dbJA?pwd=lcjw) | \n| deepspeech2_no_stream | [Librispeech](https://openslr.magicdatatech.com/resources/12) (960小时) | fbank |     98     | 英文  |       0.09705        | [点击下载](https://pan.baidu.com/s/1c57J718blFgUAGqDO-dbJA?pwd=lcjw) | \n\n**说明：** \n1. 这里字错率或者词错率是使用`eval.py`程序并使用集束搜索解码`ctc_beam_search`方法计算得到的。\n2. 把全部文件复制到项目根目录下。\n3. 模型名称包含`no_stream`为非流式模型，不能用于流式识别。\n4. 由于算力不足，大部分的模型都没有训练足够轮数，有算力的同学，欢迎提供模型。\n5. 由于音频的长度不一，所以参数大小也有所变化，以上参数大小为同一音频长度下的结果，仅供对比使用。\n\n>有问题欢迎提 [issue](https://github.com/yeyupiaoling/MASR/issues) 交流\n\n\n## 文档教程\n\n- [快速安装](./docs/install.md)\n- [数据准备](./docs/dataset.md)\n- [WenetSpeech数据集](./docs/wenetspeech.md)\n- [合成语音数据](./docs/generate_audio.md)\n- [数据增强](./docs/augment.md)\n- [训练模型](./docs/train.md)\n- [集束搜索解码](./docs/beam_search.md)\n- [执行评估](./docs/eval.md)\n- [导出模型](./docs/export_model.md)\n- [使用标点符号模型](./docs/punctuation.md)\n- 预测\n   - [本地预测](./docs/infer.md)\n   - [长语音预测](./docs/infer.md)\n   - [Web部署模型](./docs/infer.md)\n   - [GUI界面预测](./docs/infer.md)\n\n\n## 快速预测\n\n - 下载作者提供的模型或者训练模型，然后执行[导出模型](./docs/export_model.md)，使用`infer_path.py`预测音频，通过参数`--wav_path`指定需要预测的音频路径，完成语音识别，详情请查看[模型部署](./docs/infer.md)。\n```shell script\npython infer_path.py --wav_path=./dataset/test.wav\n```\n\n输出结果：\n```\n----------- 额外配置参数 -----------\nconfigs: configs/config_zh.yml\nis_long_audio: False\nmodel_dir: models/{}_{}/infer/\npun_model_dir: models/pun_models/\nreal_time_demo: False\nto_an: False\nuse_gpu: True\nuse_pun: False\nwav_path: dataset/test.wav\n------------------------------------------------\n----------- 配置文件参数 -----------\nctc_beam_search_decoder: {'alpha': 2.2, 'beta': 4.3, 'beam_size': 300, 'num_processes': 10, 'cutoff_prob': 0.99, 'cutoff_top_n': 40, 'language_model_path': 'lm/zh_giga.no_cna_cmn.prune01244.klm'}\ndataset: {'batch_size': 32, 'num_workers': 4, 'min_duration': 0.5, 'max_duration': 20, 'train_manifest': 'dataset/manifest.train', 'test_manifest': 'dataset/manifest.test', 'dataset_vocab': 'dataset/vocabulary.txt', 'mean_std_path': 'dataset/mean_std.json', 'noise_manifest_path': 'dataset/manifest.noise'}\ndecoder: ctc_beam_search\nmetrics_type: cer\nnum_epoch: 65\noptimizer: {'learning_rate': '5e-5', 'gamma': 0.93, 'clip_norm': 3.0, 'weight_decay': '1e-6'}\npreprocess: {'feature_method': 'fbank', 'n_mels': 80, 'n_mfcc': 40, 'sample_rate': 16000, 'use_dB_normalization': True, 'target_dB': -20}\nuse_model: deepspeech2\n------------------------------------------------\n\n消耗时间：132, 识别结果: 近几年不但我用书给女儿儿压岁也劝说亲朋不要给女儿压岁钱而改送压岁书, 得分: 94\n```\n\n\n - 长语音预测\n\n```shell script\npython infer_path.py --wav_path=./dataset/test_vad.wav --is_long_audio=True\n```\n\n\n - Web部署\n\n![录音测试页面](./docs/images/infer_server.jpg)\n\n\n - GUI界面部署\n\n![GUI界面](./docs/images/infer_gui.jpg)\n\n\n## 相关项目\n - 基于Pytorch实现的声纹识别：[VoiceprintRecognition-Pytorch](https://github.com/yeyupiaoling/VoiceprintRecognition-Pytorch)\n - 基于Pytorch实现的分类：[AudioClassification-Pytorch](https://github.com/yeyupiaoling/AudioClassification-Pytorch)\n - 基于PaddlePaddle实现的语音识别：[PPASR](https://github.com/yeyupiaoling/PPASR)\n\n\n## 参考资料\n - https://github.com/yeyupiaoling/PPASR\n - https://github.com/jiwidi/DeepSpeech-pytorch\n - https://github.com/wenet-e2e/WenetSpeech\n - https://github.com/SeanNaren/deepspeech.pytorch\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "https://github.com/yeyupiaoling/MASR.git",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/yeyupiaoling/MASR",
    "keywords": "asr,pytorch",
    "license": "Apache License 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "masr",
    "package_url": "https://pypi.org/project/masr/",
    "platform": null,
    "project_url": "https://pypi.org/project/masr/",
    "project_urls": {
      "Download": "https://github.com/yeyupiaoling/MASR.git",
      "Homepage": "https://github.com/yeyupiaoling/MASR"
    },
    "release_url": "https://pypi.org/project/masr/1.1.8/",
    "requires_dist": [
      "numpy (>=1.19.2)",
      "scipy (>=1.6.3)",
      "tqdm (>=4.59.0)",
      "librosa (~=0.9.2)",
      "python-Levenshtein (==0.12.2)",
      "visualdl (>=2.1.1)",
      "SoundFile (~=0.10)",
      "resampy (==0.2.2)",
      "numba (>=0.53.0)",
      "zhconv (>=1.4.2)",
      "ijson (~=3.1.4)",
      "webrtcvad (~=2.0.10)",
      "pydub (~=0.25.1)",
      "WeTextProcessing (>=0.0.4)",
      "audioread (~=2.1.9)",
      "pyyaml (~=5.4.1)",
      "flask (~=2.1.2)",
      "flask-cors (~=3.0.10)",
      "termcolor (~=1.1.0)",
      "requests (~=2.25.1)",
      "websockets (~=10.3)",
      "ffmpeg-python (>=0.2.0)"
    ],
    "requires_python": "",
    "summary": "Automatic speech recognition toolkit on Pytorch",
    "version": "1.1.8",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17396813,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "766795efcb77490ab7a9de4df13f9865233935961e7d8cd87eccd4534403e429",
        "md5": "4329d825c82780f0acd6f1da14f94422",
        "sha256": "7c0e903e6b6a6fc8a426a39dfcede4f9c5d8e71375c57fefbcd7098c0d14c90d"
      },
      "downloads": -1,
      "filename": "masr-1.1.8-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "4329d825c82780f0acd6f1da14f94422",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 66929,
      "upload_time": "2022-10-11T13:15:23",
      "upload_time_iso_8601": "2022-10-11T13:15:23.057133Z",
      "url": "https://files.pythonhosted.org/packages/76/67/95efcb77490ab7a9de4df13f9865233935961e7d8cd87eccd4534403e429/masr-1.1.8-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}