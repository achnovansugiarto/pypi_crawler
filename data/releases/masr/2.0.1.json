{
  "info": {
    "author": "yeyupiaoling",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Developers",
      "License :: OSI Approved :: Apache Software License",
      "Natural Language :: Chinese (Simplified)",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Topic :: Utilities"
    ],
    "description": "![python version](https://img.shields.io/badge/python-3.8+-orange.svg)\n![GitHub forks](https://img.shields.io/github/forks/yeyupiaoling/MASR)\n![GitHub Repo stars](https://img.shields.io/github/stars/yeyupiaoling/MASR)\n![GitHub](https://img.shields.io/github/license/yeyupiaoling/MASR)\n![支持系统](https://img.shields.io/badge/支持系统-Win/Linux/MAC-9cf)\n\n# MASR流式与非流式语音识别项目 (此分支未完成，请勿使用)\n\nMASR是一款基于Pytorch实现的自动语音识别框架，MASR全称是神奇的自动语音识别框架（Magical Automatic Speech Recognition），当前为V2版本，如果想使用V1版本，请在这个分支[r1.x](https://github.com/yeyupiaoling/MASR/tree/r1.x)。MASR致力于简单，实用的语音识别项目。可部署在服务器，Nvidia Jetson设备，未来还计划支持Android等移动设备。\n\n**如果熟悉PaddlePaddle，请优先使用：[PPASR](https://github.com/yeyupiaoling/PPASR)**\n\n**欢迎大家扫码入QQ群讨论**，或者直接搜索QQ群号`1169600237`，问题答案为博主Github的ID`yeyupiaoling`。\n\n<div align=\"center\">\n  <img src=\"docs/images/qq.png\"/>\n</div>\n\n\n本项目使用的环境：\n - Anaconda 3\n - Python 3.8\n - Pytorch 1.12.1\n - Windows 10 or Ubuntu 18.04\n\n\n## 项目快速了解\n\n 1. 本项目支持流式识别模型`deepspeech2`、`conformer`，每个模型又分online(在线)和offline(离线)，对应的是流式识别和非流式识别。\n 2. 本项目支持两种解码器，分别是集束搜索解码器`ctc_beam_search`和贪心解码器`ctc_greedy`，集束搜索解码器`ctc_beam_search`准确率更高，但不支持Windows。\n 3. 下面提供了一系列预训练模型的下载，下载预训练模型之后，需要把全部文件复制到项目根目录，并执行导出模型才可以使用语音识别。\n\n\n## 更新记录\n\n - 2022.11: 正式发布最终级的V2版本。\n\n\n## 视频讲解\n\n这个是PPSAR的视频教程，项目是通用的，可以参考使用。\n\n - [知识点讲解（哔哩哔哩）](https://www.bilibili.com/video/BV1Rr4y1D7iZ)\n - [流式识别的使用讲解（哔哩哔哩）](https://www.bilibili.com/video/BV1Te4y1h7KK)\n\n\n## 模型下载\n\n\n1. `conformer`预训练模型列表：\n\n|       使用模型        |                                  数据集                                  | 预处理方式 | 语言  | 测试集字错率（词错率） | 下载地址 |\n|:-----------------:|:---------------------------------------------------------------------:|:-----:|:---:|:-----------:|:----:|\n| conformer_online  |            [WenetSpeech](./docs/wenetspeech.md) (10000小时)             | fbank | 中文  |             |      |\n| conformer_online  |   [aishell](https://openslr.magicdatatech.com/resources/33) (179小时)   | fbank | 中文  |             |      |\n| conformer_offline |   [aishell](https://openslr.magicdatatech.com/resources/33) (179小时)   | fbank | 中文  |             |      |\n| conformer_online  | [Librispeech](https://openslr.magicdatatech.com/resources/12) (960小时) | fbank | 英文  |             |      | \n| conformer_offline | [Librispeech](https://openslr.magicdatatech.com/resources/12) (960小时) | fbank | 英文  |             |      | \n\n\n2. `deepspeech2`预训练模型列表：\n\n|        使用模型         |                                  数据集                                  | 预处理方式 | 语言  | 测试集字错率（词错率） | 下载地址 |\n|:-------------------:|:---------------------------------------------------------------------:|:-----:|:---:|:-----------:|:----:|\n| deepspeech2_online  |            [WenetSpeech](./docs/wenetspeech.md) (10000小时)             | fbank | 中文  |             |      |\n| deepspeech2_online  |   [aishell](https://openslr.magicdatatech.com/resources/33) (179小时)   | fbank | 中文  |             |      |\n| deepspeech2_offline |   [aishell](https://openslr.magicdatatech.com/resources/33) (179小时)   | fbank | 中文  |             |      |\n| deepspeech2_online  | [Librispeech](https://openslr.magicdatatech.com/resources/12) (960小时) | fbank | 英文  |             |      | \n| deepspeech2_offline | [Librispeech](https://openslr.magicdatatech.com/resources/12) (960小时) | fbank | 英文  |             |      | \n\n\n**说明：** \n1. 这里字错率或者词错率是使用`eval.py`程序并使用集束搜索解码`ctc_beam_search`方法计算得到的。\n2. 没有提供预测模型，需要把全部文件复制到项目的根目录下，执行`export_model.py`导出预测模型。\n\n>有问题欢迎提 [issue](https://github.com/yeyupiaoling/MASR/issues) 交流\n\n# 语言模型\n\n|                                          语言模型                                          |                                                      训练数据                                                       |  数据量  |  文件大小   |                 说明                  |\n|:--------------------------------------------------------------------------------------:|:---------------------------------------------------------------------------------------------------------------:|:-----:|:-------:|:-----------------------------------:|\n|         [自定义中文语言模型](https://pan.baidu.com/s/1vdQsqnoKHO9jdFU_1If49g?pwd=ea09)          |                       [自定义中文语料](https://download.csdn.net/download/qq_33200967/87002687)                        | 约2千万  | 572 MB  |           训练参数`-o 5`，无剪枝            |\n|  [英文语言模型](https://deepspeech.bj.bcebos.com/en_lm/common_crawl_00.prune01111.trie.klm)  | [CommonCrawl](http://web-language-models.s3-website-us-east-1.amazonaws.com/ngrams/en/deduped/en.00.deduped.xz) | 18.5亿 | 8.3 GB  | 训练参数`-o 5`，剪枝参数`'--prune 0 1 1 1 1` |\n| [中文语言模型（剪枝）](https://deepspeech.bj.bcebos.com/zh_lm/zh_giga.no_cna_cmn.prune01244.klm) |                                                     百度内部语料库                                                     | 1.3亿  | 2.8 GB  | 训练参数`-o 5`，剪枝参数`'--prune 0 1 1 1 1` |                                     |\n|            [中文语言模型](https://deepspeech.bj.bcebos.com/zh_lm/zhidao_giga.klm)            |                                                     百度内部语料库                                                     |  37亿  | 70.4 GB |           训练参数`-o 5`，无剪枝            |                                     \n\n\n## 文档教程\n\n- [快速安装](./docs/install.md)\n- [快速使用](./docs/GETTING_STARTED.md)\n- [数据准备](./docs/dataset.md)\n- [WenetSpeech数据集](./docs/wenetspeech.md)\n- [合成语音数据](./docs/generate_audio.md)\n- [数据增强](./docs/augment.md)\n- [训练模型](./docs/train.md)\n- [集束搜索解码](./docs/beam_search.md)\n- [执行评估](./docs/eval.md)\n- [导出模型](./docs/export_model.md)\n- [使用标点符号模型](./docs/punctuation.md)\n- [使用语音活动检测（VAD）](./docs/vad.md)\n- 预测\n   - [本地预测](./docs/infer.md)\n   - [长语音预测](./docs/infer.md)\n   - [Web部署模型](./docs/infer.md)\n   - [GUI界面预测](./docs/infer.md)\n\n\n## 快速预测\n\n - 下载作者提供的模型或者训练模型，然后执行[导出模型](./docs/export_model.md)，使用`infer_path.py`预测音频，通过参数`--wav_path`指定需要预测的音频路径，完成语音识别，详情请查看[模型部署](./docs/infer.md)。\n```shell script\npython infer_path.py --wav_path=./dataset/test.wav\n```\n\n输出结果：\n```\n消耗时间：132, 识别结果: 近几年不但我用书给女儿儿压岁也劝说亲朋不要给女儿压岁钱而改送压岁书, 得分: 94\n```\n\n\n - 长语音预测\n\n```shell script\npython infer_path.py --wav_path=./dataset/test_vad.wav --is_long_audio=True\n```\n\n\n - Web部署\n\n![录音测试页面](./docs/images/infer_server.jpg)\n\n\n - GUI界面部署\n\n![GUI界面](./docs/images/infer_gui.jpg)\n\n\n## 相关项目\n - 基于Pytorch实现的声纹识别：[VoiceprintRecognition-Pytorch](https://github.com/yeyupiaoling/VoiceprintRecognition-Pytorch)\n - 基于Pytorch实现的分类：[AudioClassification-Pytorch](https://github.com/yeyupiaoling/AudioClassification-Pytorch)\n - 基于PaddlePaddle实现的语音识别：[PPASR](https://github.com/yeyupiaoling/PPASR)\n\n\n## 参考资料\n - https://github.com/yeyupiaoling/PPASR\n - https://github.com/jiwidi/DeepSpeech-pytorch\n - https://github.com/wenet-e2e/WenetSpeech\n - https://github.com/SeanNaren/deepspeech.pytorch\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "https://github.com/yeyupiaoling/MASR.git",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/yeyupiaoling/MASR",
    "keywords": "asr,pytorch",
    "license": "Apache License 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "masr",
    "package_url": "https://pypi.org/project/masr/",
    "platform": null,
    "project_url": "https://pypi.org/project/masr/",
    "project_urls": {
      "Download": "https://github.com/yeyupiaoling/MASR.git",
      "Homepage": "https://github.com/yeyupiaoling/MASR"
    },
    "release_url": "https://pypi.org/project/masr/2.0.1/",
    "requires_dist": [
      "numpy (>=1.19.2)",
      "scipy (>=1.6.3)",
      "tqdm",
      "python-Levenshtein (==0.12.2)",
      "visualdl (>=2.1.1)",
      "SoundFile (>=0.11.0)",
      "resampy (>=0.2.2)",
      "zhconv (>=1.4.2)",
      "ijson (~=3.1.4)",
      "pydub (~=0.25.1)",
      "pyyaml (~=5.4.1)",
      "flask (~=2.1.2)",
      "flask-cors (~=3.0.10)",
      "termcolor (~=1.1.0)",
      "scikit-learn (>=1.1.0)",
      "requests (>=2.28.1)",
      "websockets (~=10.3)",
      "ffmpeg-python (>=0.2.0)",
      "typeguard (>=2.13.3)",
      "cn2an (>=0.5.17)",
      "onnxruntime (>=1.11.1)"
    ],
    "requires_python": "",
    "summary": "Automatic speech recognition toolkit on Pytorch",
    "version": "2.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17396813,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "c4627a579748c02b98b7dee9f0648b0755975597dcc4def6b391af6961831e45",
        "md5": "f339965985f3e37800d82c8906814a6d",
        "sha256": "d42ecb05414ced7f3daf0e39c8f87424ca89a6564d9af9e2787a84fbd27d3d2e"
      },
      "downloads": -1,
      "filename": "masr-2.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "f339965985f3e37800d82c8906814a6d",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 1622248,
      "upload_time": "2022-12-03T08:46:42",
      "upload_time_iso_8601": "2022-12-03T08:46:42.982298Z",
      "url": "https://files.pythonhosted.org/packages/c4/62/7a579748c02b98b7dee9f0648b0755975597dcc4def6b391af6961831e45/masr-2.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}