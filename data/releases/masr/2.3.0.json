{
  "info": {
    "author": "yeyupiaoling",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Developers",
      "License :: OSI Approved :: Apache Software License",
      "Natural Language :: Chinese (Simplified)",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Topic :: Utilities"
    ],
    "description": "![python version](https://img.shields.io/badge/python-3.8+-orange.svg)\n![GitHub forks](https://img.shields.io/github/forks/yeyupiaoling/MASR)\n![GitHub Repo stars](https://img.shields.io/github/stars/yeyupiaoling/MASR)\n![GitHub](https://img.shields.io/github/license/yeyupiaoling/MASR)\n![支持系统](https://img.shields.io/badge/支持系统-Win/Linux/MAC-9cf)\n\n# MASR流式与非流式语音识别项目\n\nMASR是一款基于Pytorch实现的自动语音识别框架，MASR全称是神奇的自动语音识别框架（Magical Automatic Speech Recognition），当前为V2版本，如果想使用V1版本，请在这个分支[r1.x](https://github.com/yeyupiaoling/MASR/tree/r1.x)。MASR致力于简单，实用的语音识别项目。可部署在服务器，Nvidia Jetson设备，未来还计划支持Android等移动设备。\n\n**如果熟悉PaddlePaddle，请优先使用：[PPASR](https://github.com/yeyupiaoling/PPASR)**\n\n**欢迎大家扫码入QQ群讨论**，或者直接搜索QQ群号`1169600237`，问题答案为博主Github的ID`yeyupiaoling`。\n\n<div align=\"center\">\n  <img src=\"docs/images/qq.png\"/>\n</div>\n\n\n本项目使用的环境：\n - Anaconda 3\n - Python 3.8\n - Pytorch 1.12.1\n - Windows 10 or Ubuntu 18.04\n\n\n## 项目快速了解\n\n 1. 本项目支持流式识别模型`deepspeech2`、`conformer`、`squeezeformer`，`efficient_conformer`，每个模型都支持流式识别和非流式识别，在配置文件中`streaming`参数设置。\n 2. 本项目支持两种解码器，分别是集束搜索解码器`ctc_beam_search`和贪心解码器`ctc_greedy`，集束搜索解码器`ctc_beam_search`准确率更高，但不支持Windows。\n 3. 下面提供了一系列预训练模型的下载，下载预训练模型之后，需要把全部文件复制到项目根目录，并执行导出模型才可以使用语音识别。\n\n\n## 更新记录\n\n - 2023.01.28: 调整配置文件结构，支持efficient_conformer模型。\n - 2022.11: 正式发布最终级的V2版本。\n\n\n## 视频讲解\n\n这个是PPSAR的视频教程，项目是通用的，可以参考使用。\n\n - [知识点讲解（哔哩哔哩）](https://www.bilibili.com/video/BV1Rr4y1D7iZ)\n - [流式识别的使用讲解（哔哩哔哩）](https://www.bilibili.com/video/BV1Te4y1h7KK)\n\n\n# 快速使用\n\n这里介绍如何使用MASR快速进行语音识别，前提是要安装MASR，文档请看[快速安装](./docs/install.md)。执行过程不需要手动下载模型，全部自动完成。\n\n1. 短语音识别\n```python\nfrom masr.predict import MASRPredictor\n\npredictor = MASRPredictor(model_tag='conformer_streaming_fbank_aishell')\n\nwav_path = 'dataset/test.wav'\nresult = predictor.predict(audio_data=wav_path, use_pun=False)\nscore, text = result['score'], result['text']\nprint(f\"识别结果: {text}, 得分: {int(score)}\")\n```\n\n2. 长语音识别\n```python\nfrom masr.predict import MASRPredictor\n\npredictor = MASRPredictor(model_tag='conformer_streaming_fbank_aishell')\n\nwav_path = 'dataset/test_long.wav'\nresult = predictor.predict_long(audio_data=wav_path, use_pun=False)\nscore, text = result['score'], result['text']\nprint(f\"识别结果: {text}, 得分: {score}\")\n```\n\n3. 模拟流式识别\n```python\nimport time\nimport wave\n\nfrom masr.predict import MASRPredictor\n\npredictor = MASRPredictor(model_tag='conformer_streaming_fbank_aishell')\n\n# 识别间隔时间\ninterval_time = 0.5\nCHUNK = int(16000 * interval_time)\n# 读取数据\nwav_path = 'dataset/test.wav'\nwf = wave.open(wav_path, 'rb')\ndata = wf.readframes(CHUNK)\n# 播放\nwhile data != b'':\n    start = time.time()\n    d = wf.readframes(CHUNK)\n    result = predictor.predict_stream(audio_data=data, use_pun=False, is_end=d == b'')\n    data = d\n    if result is None: continue\n    score, text = result['score'], result['text']\n    print(f\"【实时结果】：消耗时间：{int((time.time() - start) * 1000)}ms, 识别结果: {text}, 得分: {int(score)}\")\n# 重置流式识别\npredictor.reset_stream()\n```\n\n\n## 模型下载\n\n\n1. [WenetSpeech](./docs/wenetspeech.md) (10000小时) 的预训练模型列表：\n\n|       使用模型        | 是否为流式 | 预处理方式 | 语言  | 测试集字错率（词错率） | 下载地址 |\n|:-----------------:|:-----:|:-----:|:---:|:-----------:|:----:|\n| conformer_online  | True  | fbank | 普通话 |             |      |\n\n\n2.  [WenetSpeech](./docs/wenetspeech.md) (10000小时)+[中文语音数据集](https://download.csdn.net/download/qq_33200967/87003964) (3000+小时) 的预训练模型列表：\n\n|       使用模型       | 是否为流式 | 预处理方式 | 语言  | 测试集字错率（词错率） | 下载地址 |\n|:----------------:|:-----:|:-----:|:---:|:-----------:|:----:|\n| conformer_online | True  | fbank | 普通话 |             |      |\n\n\n3. [AIShell](https://openslr.magicdatatech.com/resources/33) (179小时) 的预训练模型列表：\n\n|        使用模型         | 是否为流式 | 预处理方式 | 语言  | 测试集字错率（词错率） |                               下载地址                               |\n|:-------------------:|:-----:|:-----:|:---:|:-----------:|:----------------------------------------------------------------:|\n|    squeezeformer    | True  | fbank | 普通话 |   0.04137   | [点击下载](https://pan.baidu.com/s/10fxH3-UZBEWUmqAUcQcXFg?pwd=d4u2) |\n|      conformer      | True  | fbank | 普通话 |   0.04491   | [点击下载](https://pan.baidu.com/s/10fxH3-UZBEWUmqAUcQcXFg?pwd=d4u2) |\n| efficient_conformer | True  | fbank | 普通话 |             | [点击下载](https://pan.baidu.com/s/10fxH3-UZBEWUmqAUcQcXFg?pwd=d4u2) |\n|     deepspeech2     | True  | fbank | 普通话 |   0.06907   | [点击下载](https://pan.baidu.com/s/10fxH3-UZBEWUmqAUcQcXFg?pwd=d4u2) |\n\n\n4. [Librispeech](https://openslr.magicdatatech.com/resources/12) (960小时) 的预训练模型列表：\n\n|        使用模型         | 是否为流式 | 预处理方式 | 语言  | 测试集字错率（词错率） |                               下载地址                               |\n|:-------------------:|:-----:|:-----:|:---:|:-----------:|:----------------------------------------------------------------:|\n|    squeezeformer    | True  | fbank | 英文  |             | [点击下载](https://pan.baidu.com/s/111PY9PEOUBEjE8vx79ythg?pwd=sypb) | \n|      conformer      | True  | fbank | 英文  |             | [点击下载](https://pan.baidu.com/s/111PY9PEOUBEjE8vx79ythg?pwd=sypb) | \n| efficient_conformer | True  | fbank | 英文  |             | [点击下载](https://pan.baidu.com/s/111PY9PEOUBEjE8vx79ythg?pwd=sypb) | \n|     deepspeech2     | True  | fbank | 英文  |             | [点击下载](https://pan.baidu.com/s/111PY9PEOUBEjE8vx79ythg?pwd=sypb) | \n\n\n**说明：** \n1. 这里字错率或者词错率是使用`eval.py`程序并使用集束搜索解码`ctc_beam_search`方法计算得到的。\n2. 没有提供预测模型，需要把全部文件复制到项目的根目录下，执行`export_model.py`导出预测模型。\n3. 由于算力不足，这里只提供了流式模型，但全部模型都支持流式和非流式的，在配置文件中`streaming`参数设置。\n\n>有问题欢迎提 [issue](https://github.com/yeyupiaoling/MASR/issues) 交流\n\n\n## 文档教程\n\n- [快速安装](./docs/install.md)\n- [快速使用](./docs/GETTING_STARTED.md)\n- [数据准备](./docs/dataset.md)\n- [WenetSpeech数据集](./docs/wenetspeech.md)\n- [合成语音数据](./docs/generate_audio.md)\n- [数据增强](./docs/augment.md)\n- [训练模型](./docs/train.md)\n- [集束搜索解码](./docs/beam_search.md)\n- [执行评估](./docs/eval.md)\n- [导出模型](./docs/export_model.md)\n- [使用标点符号模型](./docs/punctuation.md)\n- [使用语音活动检测（VAD）](./docs/vad.md)\n- 预测\n   - [本地预测](./docs/infer.md)\n   - [长语音预测](./docs/infer.md)\n   - [Web部署模型](./docs/infer.md)\n   - [GUI界面预测](./docs/infer.md)\n\n\n## 相关项目\n - 基于Pytorch实现的声纹识别：[VoiceprintRecognition-Pytorch](https://github.com/yeyupiaoling/VoiceprintRecognition-Pytorch)\n - 基于Pytorch实现的分类：[AudioClassification-Pytorch](https://github.com/yeyupiaoling/AudioClassification-Pytorch)\n - 基于PaddlePaddle实现的语音识别：[PPASR](https://github.com/yeyupiaoling/PPASR)\n\n\n## 参考资料\n - https://github.com/yeyupiaoling/PPASR\n - https://github.com/jiwidi/DeepSpeech-pytorch\n - https://github.com/wenet-e2e/WenetSpeech\n - https://github.com/SeanNaren/deepspeech.pytorch\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "https://github.com/yeyupiaoling/MASR.git",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/yeyupiaoling/MASR",
    "keywords": "asr,pytorch",
    "license": "Apache License 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "masr",
    "package_url": "https://pypi.org/project/masr/",
    "platform": null,
    "project_url": "https://pypi.org/project/masr/",
    "project_urls": {
      "Download": "https://github.com/yeyupiaoling/MASR.git",
      "Homepage": "https://github.com/yeyupiaoling/MASR"
    },
    "release_url": "https://pypi.org/project/masr/2.3.0/",
    "requires_dist": [
      "numpy (>=1.19.2)",
      "scipy (>=1.6.3)",
      "tqdm",
      "python-Levenshtein (==0.12.2)",
      "visualdl (>=2.1.1)",
      "SoundFile (>=0.11.0)",
      "resampy (>=0.2.2)",
      "zhconv (>=1.4.2)",
      "ijson (~=3.1.4)",
      "pydub (~=0.25.1)",
      "pyyaml (~=5.4.1)",
      "flask (~=2.1.2)",
      "flask-cors (~=3.0.10)",
      "termcolor (~=1.1.0)",
      "scikit-learn (>=1.0.2)",
      "requests (>=2.28.1)",
      "websockets (~=10.3)",
      "ffmpeg-python (>=0.2.0)",
      "typeguard (>=2.13.3)",
      "cn2an (>=0.5.17)",
      "onnxruntime (>=1.11.1)"
    ],
    "requires_python": "",
    "summary": "Automatic speech recognition toolkit on Pytorch",
    "version": "2.3.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17396813,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "617aaf3ca485476fe7706553cd63bce038b34c918e53a8ca70c818c144827a4c",
        "md5": "52a5fd9e21e867672c80daefd998ff2d",
        "sha256": "9a504020cc03b57d8776fb2c14b41d21e745f3abbe1c83e8bc7fd4916b672a13"
      },
      "downloads": -1,
      "filename": "masr-2.3.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "52a5fd9e21e867672c80daefd998ff2d",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 1640266,
      "upload_time": "2023-01-28T11:31:27",
      "upload_time_iso_8601": "2023-01-28T11:31:27.622131Z",
      "url": "https://files.pythonhosted.org/packages/61/7a/af3ca485476fe7706553cd63bce038b34c918e53a8ca70c818c144827a4c/masr-2.3.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}