{
  "info": {
    "author": "yeyupiaoling",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Developers",
      "License :: OSI Approved :: Apache Software License",
      "Natural Language :: Chinese (Simplified)",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Topic :: Utilities"
    ],
    "description": "# MASR流式与非流式语音识别\n\n![python version](https://img.shields.io/badge/python-3.7+-orange.svg)\n![GitHub forks](https://img.shields.io/github/forks/yeyupiaoling/MASR)\n![GitHub Repo stars](https://img.shields.io/github/stars/yeyupiaoling/MASR)\n![GitHub](https://img.shields.io/github/license/yeyupiaoling/MASR)\n![支持系统](https://img.shields.io/badge/支持系统-Win/Linux/MAC-9cf)\n\nMASR是一款基于Pytorch实现的自动语音识别框架，MASR全称是神奇的自动语音识别框架（Magical Automatic Speech Recognition），MASR致力于简单，实用的语音识别项目。可部署在服务器，Nvidia Jetson设备，未来还计划支持Android等移动设备。\n\n本项目使用的环境：\n - Anaconda 3\n - Python 3.7\n - Pytorch 1.10.0\n - Windows 10 or Ubuntu 18.04\n\n<!--\n## 在线使用\n\n - [在线使用Dome](https://masr.yeyupiaoling.cn)\n-->\n\n## 更新记录\n\n - 2022.08.04: 发布1.0版本，优化实时识别流程。\n - 2022.07.12: 完成GUI界面的录音实时识别。\n - 2022.06.14: 支持`deepspeech2_big`模型，适合WenetSpeech大数据集训练模型。\n - 2022.01.16: 支持多种预处理方法。\n - 2022.01.15: 支持英文语音识别。\n - 2022.01.13: 支持给识别结果加标点符号\n - 2021.12.26: 支持pip方式安装。\n - 2021.12.25: 初步完成基本程序。\n\n## 模型下载\n|                                            数据集                                            |      使用模型       | 预处理方式  |   语言   | 测试集字错率（词错率） |                              下载地址                               |\n|:-----------------------------------------------------------------------------------------:|:---------------:|:------:|:------:|:-----------:|:---------------------------------------------------------------:|\n|             [aishell](https://openslr.magicdatatech.com/resources/33) (179小时)             |   deepspeech2   | linear |   中文   |   0.06346   | [点击下载](https://download.csdn.net/download/qq_33200967/71141450) |\n| [free_st_chinese_mandarin_corpus](https://openslr.magicdatatech.com/resources/38) (109小时) |   deepspeech2   | linear |   中文   |   0.13941   | [点击下载](https://download.csdn.net/download/qq_33200967/71495689) |\n|             [thchs_30](https://openslr.magicdatatech.com/resources/18) (34小时)             |   deepspeech2   | linear |   中文   |   0.06751   | [点击下载](https://download.csdn.net/download/qq_33200967/71142778) |\n|                             超大数据集(1600多小时真实数据)+(1300多小时合成数据)                              |   deepspeech2   | linear |   中文   |   0.06215   | [点击下载](https://download.csdn.net/download/qq_33200967/75138230) |\n|                             超大数据集(1600多小时真实数据)+(1300多小时合成数据)                              | deepspeech2_big | linear |   中文   |   0.05517   |                                                                 |\n|           [Librispeech](https://openslr.magicdatatech.com/resources/12) (960小时)           |   deepspeech2   |   英文   | linear |   0.12842   | [点击下载](https://download.csdn.net/download/qq_33200967/85016728) | \n\n\n**说明：** \n1. 这里字错率是使用`eval.py`程序并使用集束搜索解码`ctc_beam_search`方法计算得到的。\n2. 中文解码参数为：`alpha=2.2，beta=4.3，beam_size=300，cutoff_prob=0.99，cutoff_top_n=40`。\n3. 英文解码参数为：`alpha=1.9，beta=0.3，beam_size=500，cutoff_prob=1.0，cutoff_top_n=40`。\n4. 除了aishell数据集按照数据集本身划分的训练数据和测试数据，其他的都是按照项目设置的固定比例划分训练数据和测试数据。\n5. 下载的压缩文件已经包含了`mean_std.npz`和`vocabulary.txt`，需要把解压得到的全部文件复制到项目根目录下。\n\n>有问题欢迎提 [issue](https://github.com/yeyupiaoling/MASR/issues) 交流\n\n\n## 文档教程\n\n- [快速安装](./docs/install.md)\n- [数据准备](./docs/dataset.md)\n- [WenetSpeech数据集](./docs/wenetspeech.md)\n- [合成语音数据](./docs/generate_audio.md)\n- [数据增强](./docs/augment.md)\n- [训练模型](./docs/train.md)\n- [集束搜索解码](./docs/beam_search.md)\n- [执行评估](./docs/eval.md)\n- [导出模型](./docs/export_model.md)\n- [使用标点符号模型](./docs/punctuation.md)\n- 预测\n   - [本地预测](./docs/infer.md)\n   - [长语音预测](./docs/infer.md)\n   - [Web部署模型](./docs/infer.md)\n   - [GUI界面预测](./docs/infer.md)\n\n\n## 快速预测\n\n - 下载作者提供的模型或者训练模型，然后执行[导出模型](./docs/export_model.md)，使用`infer_path.py`预测音频，通过参数`--wav_path`指定需要预测的音频路径，完成语音识别，详情请查看[模型部署](./docs/infer.md)。\n```shell script\npython infer_path.py --wav_path=./dataset/test.wav\n```\n\n输出结果：\n```\n-----------  Configuration Arguments -----------\nalpha: 1.2\nbeam_size: 10\nbeta: 0.35\ncutoff_prob: 1.0\ncutoff_top_n: 40\ndecoding_method: ctc_greedy\nenable_mkldnn: False\nis_long_audio: False\nlang_model_path: ./lm/zh_giga.no_cna_cmn.prune01244.klm\nmean_std_path: ./dataset/mean_std.npz\nmodel_dir: ./models/infer/\nto_an: True\nuse_gpu: True\nuse_tensorrt: False\nvocab_path: ./dataset/zh_vocab.txt\nwav_path: ./dataset/test.wav\n------------------------------------------------\n消耗时间：132, 识别结果: 近几年不但我用书给女儿儿压岁也劝说亲朋不要给女儿压岁钱而改送压岁书, 得分: 94\n```\n\n\n - 长语音预测\n\n```shell script\npython infer_path.py --wav_path=./dataset/test_vad.wav --is_long_audio=True\n```\n\n\n - Web部署\n\n![录音测试页面](./docs/images/infer_server.jpg)\n\n\n - GUI界面部署\n\n![GUI界面](./docs/images/infer_gui.jpg)\n\n\n## 相关项目\n - 基于Pytorch实现的声纹识别：[VoiceprintRecognition-Pytorch](https://github.com/yeyupiaoling/VoiceprintRecognition-Pytorch)\n - 基于Pytorch实现的分类：[AudioClassification-Pytorch](https://github.com/yeyupiaoling/AudioClassification-Pytorch)\n - 基于PaddlePaddle实现的语音识别：[PPASR](https://github.com/yeyupiaoling/PPASR)\n\n\n## 参考资料\n - https://github.com/yeyupiaoling/PPASR\n - https://github.com/jiwidi/DeepSpeech-pytorch\n - https://github.com/wenet-e2e/WenetSpeech\n - https://github.com/SeanNaren/deepspeech.pytorch\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "https://github.com/yeyupiaoling/MASR.git",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/yeyupiaoling/MASR",
    "keywords": "asr,pytorch",
    "license": "Apache License 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "masr",
    "package_url": "https://pypi.org/project/masr/",
    "platform": null,
    "project_url": "https://pypi.org/project/masr/",
    "project_urls": {
      "Download": "https://github.com/yeyupiaoling/MASR.git",
      "Homepage": "https://github.com/yeyupiaoling/MASR"
    },
    "release_url": "https://pypi.org/project/masr/1.0.0/",
    "requires_dist": [
      "numpy (>=1.19.2)",
      "scipy (>=1.6.1)",
      "tqdm (~=4.49.0)",
      "librosa (~=0.9.2)",
      "python-Levenshtein (==0.12.2)",
      "visualdl (>=2.1.1)",
      "SoundFile (~=0.10)",
      "resampy (==0.2.2)",
      "numba (>=0.53.0)",
      "zhconv (>=1.4.2)",
      "paddlespeech-feat",
      "ijson (~=3.1.4)",
      "webrtcvad (~=2.0.10)",
      "pydub (~=0.25.1)",
      "cn2an (~=0.5.14)",
      "paddlenlp (~=2.2.3)",
      "audioread (~=2.1.9)",
      "pyyaml (~=5.4.1)",
      "flask (~=2.1.2)"
    ],
    "requires_python": "",
    "summary": "Automatic speech recognition toolkit on Pytorch",
    "version": "1.0.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17396813,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "27b35f4957cbaafeb1b7440d9c7f9b8a0976ce622049b42e84cbf95a1dc2f169",
        "md5": "b01b390ec217246630027154bfbc0089",
        "sha256": "da6e4123d0889f9d9ae087b845058e6e563a2b2841099861857a4badd77db62c"
      },
      "downloads": -1,
      "filename": "masr-1.0.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "b01b390ec217246630027154bfbc0089",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 63414,
      "upload_time": "2022-08-04T09:46:37",
      "upload_time_iso_8601": "2022-08-04T09:46:37.140510Z",
      "url": "https://files.pythonhosted.org/packages/27/b3/5f4957cbaafeb1b7440d9c7f9b8a0976ce622049b42e84cbf95a1dc2f169/masr-1.0.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}