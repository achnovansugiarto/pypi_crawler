{
  "info": {
    "author": "Oliver Tosky",
    "author_email": "olivertosky@gmail.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# Medium Stats Scraper\n\nA command-line tool and Python package to fetch your Medium profile statistics \nand save the data as JSON.\n\n*Executes the same API and Graphql requests as the Medium front-end does, providing \nyou with the data as it is, pre-rendered.*\n\n## Install\n\n```bash\n$ pip install medium-stats\n```\n\n## Setup\n\n### Step 1\n\nTo make authenticated requests to Medium for your stats, the CLI tool \nneeds **two** cookies from a signed-in Medium session - \"sid\" and \"uid\".\n\n*If you want to manually find and store your cookies:*\n\n- Sign in to Medium\n- Get to your browser's developer tools and find the tab that holds cookies:\n  - *Application* for Chrome \n  - *Storage* for Firefox\n- Scroll through the cookies for medium.com until you find 'sid' and 'uid'\n\n\n![](readme_extras/cookie_howto.gif)\n\nCreate a `.medium_creds.ini` file to hold these cookie values:\n\n```bash\ncat > path_to_directory/.medium_creds.ini << EOF\n[your_medium_handle_here]\nsid=insert_sid_value_here\nuid=insert_uid_value_here\nEOF\n\n#Note: the default behavior of the package will search your home directory for \n#this file, but you are welcome to set it to whatever directory you like and \n#pass that path as an argument to the CLI tool.\n\n#Note: your Medium \"handle\" is your Medium username without the \"@\" prefix,\n#e.g. \"olivertosky\" from https://medium.com/@olivertosky\n```\n\n***\n\n*If you want to automatically find and store your cookies:*\n\n```bash\n$ pip install medium-stats[selenium]\n```\n\nThis installs some extra dependencies allowing a webscraper to authenticate to Medium\non your behalf and grab your \"sid\" and \"uid\" cookies.  *Note: You must already have \nChrome installed.*\n\nCurrently only valid for Gmail OAuth:\n\n```bash\n$ medium-stats fetch_cookies -u [HANDLE] --email [EMAIL] --pwd [PASSWORD]\n\n# Or specify that your password should be pulled from an environment variable:\n$ export MEDIUM_AUTH_PWD='[PASSWORD]'\n$ medium-stats fetch_cookies -u [HANDLE] --email [EMAIL] --pwd-in-env\n```\n\n### Step 2 - *Optional*:\n\nCreate a directory for your stats exports; the CLI tool will run \nunder the working directory by default.\n\n```bash\n$ mkdir path_to_target_stats_directory\n```\n\nOnce executed the CLI tool will create the following directory structure:\n```\ntarget_stats_directory/\n    stats_exports/\n        [HANDLE]/\n            agg_stats/ \n            agg_events/ \n            post_events/\n            post_referrers/\n```\n\n## Usage\n### Command-Line\n\nSimple Use: \n\n```bash\n$ medium-stats scrape_user -u [USERNAME] --all\n```\n\n> This will get all Medium stats for a user until now. \n\n\nFor a publication:\n```bash\n$ medium-stats scrape_publication -u [URL] --all\n\n# Valid example urls: \n# 'https://medium.com/test-publication', 'medium.com/test-publication', \n# 'https://custom.subdomain.com', 'custom.subdomain.com'\n```\n\nGeneral Use pattern:\n```bash\nmedium-stats (scrape_user | scrape_publication) -u USERNAME/URL [--output_dir DIR] \\\n(--creds PATH | (--sid SID --uid UID)) \\\n(--all | [--start PERIOD_START] [--end PERIOD END]) [--is-utc] \\\n[--mode {summary, events, articles, referrers, story_overview}]\n```\nFLAGS:\n\n| flag         |                      function                     |                        default |\n|--------------|:-------------------------------------------------:|---------------------------------------------:|\n| --all        | gets all stats until now |                        |\n| --end        |    end of period for stats fetched [exclusive]    | now (UTC) |\n| --start      | beginning of period for stats fetched [inclusive] | --end minus 1 day @midnight |\n| --is-utc     | whether start/stop are already in UTC time        | False |\n| --output-dir |          directory to hold stats exports          | current working directory |\n| --creds      |              path to credentials file             | ~/.medium_stats.ini |\n| --sid        |          your Medium session id from cookie       |\n| --uid        |          your Medium user id from cookie          |\n| --mode       |       limits retrieval to particular statistics   | ['summary', 'events', 'articles', 'referrers'] for scrape_user|\n|              |                  | ['events', 'story_overview', 'articles', 'referrers'] for scrape_publication\n\n### Python\n\nBasic Usage:\n```python\n#### SETUP ####\nfrom datetime import datetime\n\nstart = datetime(year=2020, month=1, day=1)\nstop = datetime(year=2020, month=4, day=1)\n```\n\n```python\n#### FOR A USER ####\nfrom medium_stats.scraper import StatGrabberUser\n\n# get aggregated summary statistics; note: start/stop will be converted to UTC\nme = StatGrabberUser('username', sid='sid', uid='uid', start=start, stop=stop)\ndata = me.get_summary_stats()\n\n# get the unattributed event logs for all your stories:\ndata_events = me.get_summary_stats(events=True)\n\n# get individual article statistics\narticles = me.get_article_ids(data) # returns a list of article_ids\n\narticle_events = me.get_all_story_stats(articles) # daily event logs\nreferrers = me.get_all_story_stats(articles, type_='referrer') # all-time referral sources\n```\n\n```python\n#### FOR A PUBLICATION ####\nfrom medium_stats.scraper import StatGrabberPublication\n\n# url should be consistent with publication landing page\npub = StatGrabberPublication('medium.com/test-publication', 'sid', 'uid', start, stop)\n\n# get publication views & visitors (like the stats landing page)\nviews = pub.get_events(type_='views')\nvisitors = pub.get_events(type_='visitors')\n\n# get summary stats for all publication articles\nstory_stats = pub.get_all_story_overview()\n\n# get individual article statistics\narticles = pub.get_article_ids(story_stats)\n\narticle_events = pub.get_all_story_stats(articles)\nreferrers = pub.get_all_story_stats(articles, type_='referrer')\n\n# Note: if you want to specify naive-UTC datetimes, set already_utc=True in the class instantiation to\n# avoid offset being applied.  Better practice is to just input tz-aware datetimes to \"start\" & \"stop\"\n# params in the first place...\n```\n\nNote: \"summary_stats\" and \"referrer\" data pre-aggregates to your full history, \ni.e. they don't take into account \"start\" & \"stop\" parameters.\n\n#### Example output:\n`data` (summary):\n```\n[   {   'claps': 3,\n        'collectionId': '',\n        'createdAt': 1570229100438,\n        'creatorId': 'UID',\n        'firstPublishedAt': 1583526956495,\n        'friendsLinkViews': 46,\n        'internalReferrerViews': 17,\n        'isSeries': False,\n        'postId': 'ARTICLE_ID',\n        'previewImage': {   'id': 'longstring.png',\n                            'isFeatured': True,\n                            'originalHeight': 311,\n                            'originalWidth': 627},\n        'readingTime': 7,\n        'reads': 67,\n        'slug': 'this-will-be-a-title',\n        'syndicatedViews': 0,\n        'title': 'This Will Be A Title',\n        'type': 'PostStat',\n        'updateNotificationSubscribers': 0,\n        'upvotes': 3,\n        'views': 394,\n        'visibility': 0},\n        ...\n```\n\n`data_events`:\n```\n[{  'claps': 0,\n    'flaggedSpam': 0,\n    'reads': 0,\n    'timestampMs': 1585695600000,\n    'updateNotificationSubscribers': 0,\n    'upvotes': 0,\n    'userId': 'UID',\n    'views': 1},\n        ...\n```\n\n`article_events`:\n```\n{'data': {\n    'post': [{\n        '__typename': 'Post',\n        'dailyStats': [\n            {   '__typename': 'DailyPostStat',\n                'internalReferrerViews': 1,\n                'memberTtr': 119,\n                'periodStartedAt': 1583452800000,\n                'views': 8},\n            ... \n            {   '__typename': 'DailyPostStat',\n                'internalReferrerViews': 5,\n                'memberTtr': 375,\n                'periodStartedAt': 1583539200000,\n                'views': 40}],\n        'earnings': {\n            '__typename': 'PostEarnings',\n            'dailyEarnings': [],\n            'lastCommittedPeriodStartedAt': 1585526400000},\n        'id': 'ARTICLE_ID'},\n        ...\n    ]}\n}\n```\n\n`referrers`:\n```\n{'data': {'post': [{'__typename': 'Post',\n                    'id': 'POST_ID',\n                    'referrers': [{'__typename': 'Referrer',\n                                   'internal': None,\n                                   'platform': None,\n                                   'postId': 'POST_ID',\n                                   'search': None,\n                                   'site': None,\n                                   'sourceIdentifier': 'direct',\n                                   'totalCount': 222,\n                                   'type': 'DIRECT'},\n                                  ...\n                                  {'__typename': 'Referrer',\n                                   'internal': None,\n                                   'platform': None,\n                                   'postId': 'POST_ID',\n                                   'search': None,\n                                   'site': {'__typename': 'SiteReferrer',\n                                            'href': 'https://www.inoreader.com/',\n                                            'title': None},\n                                   'sourceIdentifier': 'inoreader.com',\n                                   'totalCount': 1,\n                                   'type': 'SITE'}],\n                    'title': 'TITLE_HERE',\n                    'totalStats': {'__typename': 'SummaryPostStat',\n                                   'views': 395}},\n                    ...\n                   ]\n            }\n}\n```\n\n> If you set up your credentials file already, there is a helper class `MediumConfigHelper`,\nthat wraps the standard `configparser`:\n```python\nimport os\nfrom medium_stats.cli import MediumConfigHelper\n\ndefault_creds = os.path.join(os.path.expanduser('~'), '.medium_creds.ini')\n\ncookies = MediumConfigHelper(config_path=default_creds, account_name='your_handle')\nsid = cookies.sid\nuid = cookies.uid\n```\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/otosky/medium_stats",
    "keywords": "Medium blog scraper analytics",
    "license": "GNU GPLv3",
    "maintainer": "",
    "maintainer_email": "",
    "name": "medium-stats",
    "package_url": "https://pypi.org/project/medium-stats/",
    "platform": "",
    "project_url": "https://pypi.org/project/medium-stats/",
    "project_urls": {
      "Homepage": "https://github.com/otosky/medium_stats"
    },
    "release_url": "https://pypi.org/project/medium-stats/2.0.0/",
    "requires_dist": [
      "requests",
      "lxml",
      "selenium ; extra == 'selenium'",
      "webdriver-manager ; extra == 'selenium'"
    ],
    "requires_python": "",
    "summary": "CLI tool to fetch your Medium stats",
    "version": "2.0.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 13020871,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "4eabeb111f41ea44ab3a84450bd79b4d8c74d42777f69c4723ec94c36bd4542f",
        "md5": "6545c361463b09c2506942da94d06bfb",
        "sha256": "94d152a515f7a078a6c183ff744d75ec7423a3ff8137c99dc4a5588bd7f646fd"
      },
      "downloads": -1,
      "filename": "medium_stats-2.0.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "6545c361463b09c2506942da94d06bfb",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 27348,
      "upload_time": "2020-04-08T23:46:37",
      "upload_time_iso_8601": "2020-04-08T23:46:37.817787Z",
      "url": "https://files.pythonhosted.org/packages/4e/ab/eb111f41ea44ab3a84450bd79b4d8c74d42777f69c4723ec94c36bd4542f/medium_stats-2.0.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "f0652262fdb0562c9244106467630aa87ceb56ddd773fefd5ab94b0a9525146c",
        "md5": "889976f941bf8e423bc136d582deea84",
        "sha256": "1e51269067d94885e12b4855624edad12acf82a4439125727ef762dae76dbd9b"
      },
      "downloads": -1,
      "filename": "medium-stats-2.0.0.tar.gz",
      "has_sig": false,
      "md5_digest": "889976f941bf8e423bc136d582deea84",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 28936,
      "upload_time": "2020-04-08T23:46:40",
      "upload_time_iso_8601": "2020-04-08T23:46:40.128339Z",
      "url": "https://files.pythonhosted.org/packages/f0/65/2262fdb0562c9244106467630aa87ceb56ddd773fefd5ab94b0a9525146c/medium-stats-2.0.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}