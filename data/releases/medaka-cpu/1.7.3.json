{
  "info": {
    "author": "ont-research",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "\n![Oxford Nanopore Technologies logo](https://github.com/nanoporetech/medaka/raw/master/images/ONT_logo_590x106.png)\n\n\nMedaka\n======\n\n[![](https://img.shields.io/pypi/v/medaka.svg)](https://pypi.org/project/medaka/)\n[![](https://img.shields.io/pypi/wheel/medaka.svg)](https://pypi.org/project/medaka/)\n[![install with bioconda](https://img.shields.io/badge/install%20with-bioconda-brightgreen.svg?style=flat)](https://anaconda.org/bioconda/medaka)\n[![](https://img.shields.io/conda/pn/bioconda/medaka.svg)](https://anaconda.org/bioconda/medaka)\n\n\n`medaka` is a tool to create consensus sequences and variant calls from\nnanopore sequencing data. This task is performed using neural networks applied\na pileup of individual sequencing reads against a draft assembly. It provides\nstate-of-the-art results outperforming sequence-graph based methods and\nsignal-based methods, whilst also being faster.\n\n© 2018- Oxford Nanopore Technologies Ltd.\n\nFeatures\n--------\n\n  * Requires only basecalled data. (`.fasta` or `.fastq`)\n  * Improved accuracy over graph-based methods (e.g. Racon).\n  * 50X faster than Nanopolish (and can run on GPUs).\n  * Includes extras for implementing and training bespoke correction\n    networks.\n  * Works on Linux and MacOS.\n  * Open source (Mozilla Public License 2.0).\n\nFor creating draft assemblies we recommend [Flye](https://github.com/fenderglass/Flye).\n\nInstallation\n------------\n\nMedaka can be installed in one of several ways.\n\n**Installation with conda**\n\nPerhaps the simplest way to start using medaka is\nthrough conda; medaka is available via the\n[bioconda](https://anaconda.org/bioconda/medaka) channel:\n\n    conda create -n medaka -c conda-forge -c bioconda medaka\n\nOccasionally the conda releases lag behind the source code and\n[PyPI](https://pypi.org/project/medaka/) releases.\n\n**Installation with pip**\n\nFor those who prefer Python's native pacakage manager, medaka is also available\non pypi and can be installed using pip:\n\n    pip install medaka\n\nOn Linux platforms this will install a precompiled binary, on MacOS (and other)\nplatforms this will fetch and compile a source distribution.\n\nWe recommend using medaka within a virtual environment, viz.:\n\n    virtualenv medaka --python=python3 --prompt \"(medaka) \"\n    . medaka/bin/activate\n    pip install medaka\n\nUsing this method requires the user to provide several binaries:\n\n * [samtools](https://github.com/samtools/samtools),\n * [minimap2](https://github.com/lh3/minimap2),\n * [tabix](https://github.com/samtools/htslib), and\n * [bgzip](https://github.com/samtools/htslib)\n\nand place these within the `PATH`. `samtools/bgzip/tabix` version 1.14 and\n`minimap2` version 2.17 are recommended as these are those used in development\nof medaka.\n\n**Installation from source**\n\n> This method is useful for macOS M1 devices as it will assist in building\n> dependencies which will fail with the other methods above.\n\nMedaka can be installed from its source quite easily on most systems.\n\n Before installing medaka it may be required to install some\n prerequisite libraries, best installed by a package manager. On Ubuntu\n theses are:\n >     bzip2 g++ zlib1g-dev libbz2-dev liblzma-dev libffi-dev libncurses5-dev\n >     libcurl4-gnutls-dev libssl-dev curl make cmake wget python3-all-dev\n >     python-virtualenv\n In addition it is required to install and set up git LFS before cloning\n the repository.\n\nA Makefile is provided to fetch, compile and install all direct dependencies\ninto a python virtual environment. To set-up the environment run:\n\n    # Note: certain files are stored in git-lfs, https://git-lfs.github.com/,\n    #       which must therefore be installed first.\n    git clone https://github.com/nanoporetech/medaka.git\n    cd medaka\n    make install\n    . ./venv/bin/activate\n\nUsing this method both `samtools` and `minimap2` are built from source and need\nnot be provided by the user.\n\n\n**Using a GPU**\n\nSince version 1.1.0 `medaka` uses Tensorflow 2.2, prior versions used Tensorflow 1.4.\nFor `medaka` 1.1.0 and higher installation from source or using `pip` can make\nimmediate use of GPUs. However, note that the `tensorflow` package is compiled against\nspecific versions of the NVIDIA CUDA and cuDNN libraries; users are directed to the\n[tensorflow installation](https://www.tensorflow.org/install/source#gpu) pages\nfor further information. cuDNN can be obtained from the\n[cuDNN Archive](https://developer.nvidia.com/rdp/cudnn-archive), whilst CUDA\nfrom the [CUDA Toolkit Archive](https://developer.nvidia.com/cuda-toolkit-archive).\n\nFor `medaka` prior to version 1.1.0, to enable the use of GPU resource it is\nnecessary to install the `tensorflow-gpu` package. Using the source code from github\na working GPU-powered `medaka` can be configured with:\n\n    # Note: certain files are stored in git-lfs, https://git-lfs.github.com/,\n    #       which must therefore be installed first.\n    git clone https://github.com/nanoporetech/medaka.git\n    cd medaka\n    sed -i 's/tensorflow/tensorflow-gpu/' requirements.txt\n    make install\n    \n*GPU Usage notes*\n\nDepending on your GPU, `medaka` may show out of memory errors when running.\nTo avoid these the inference batch size can be reduced from the default\nvalue by setting the `-b` option when running `medaka_consensus`. A value\n`-b 100` is suitable for 11Gb GPUs.\n\nFor users with RTX series GPUs it may be required to additionally set an\nenvironment variable to have `medaka` run without failure:\n\n    export TF_FORCE_GPU_ALLOW_GROWTH=true\n\nIn this situation a further reduction in batch size may be required.\n\n\n**Using Docker**\n\nThe source code repository contains a `Dockerfile` which can be used to create\na GPU compatible Docker container image with the appropriate CUDA and cuDNN\nlibrary versions for running medaka. The image is built on top of images\n[provided by NVIDIA](https://hub.docker.com/r/nvidia/cuda) designed to run with the [NVIDIA Container\nToolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html).\nWith the toolkit setup on your host computer the following command can be used\nto run the latest version of medaka:\n\n    docker run --rm --gpus 0 ontresearch/medaka:latest medaka --help\n\n(The `--gpus` option can be amended as appropriate for your environment). Versioned\ntags are also available.\n\n\nUsage\n-----\n\n`medaka` can be run using its default settings through the `medaka_consensus`\nprogram. An assembly in `.fasta` format and basecalls in `.fasta` or `.fastq`\nformats are required. The program uses both `samtools` and `minimap2`. If\nmedaka has been installed using the from-source method these will be present\nwithin the medaka environment, otherwise they will need to be provided by\nthe user.\n\n    source ${MEDAKA}  # i.e. medaka/venv/bin/activate\n    NPROC=$(nproc)\n    BASECALLS=basecalls.fa\n    DRAFT=draft_assm/assm_final.fa\n    OUTDIR=medaka_consensus\n    medaka_consensus -i ${BASECALLS} -d ${DRAFT} -o ${OUTDIR} -t ${NPROC} -m r941_min_high_g303\n\nThe variables `BASECALLS`, `DRAFT`, and `OUTDIR` in the above should be set\nappropriately. For the selection of the model (`-m r941_min_high_g303` in the\nexample above) see the Model section following.\n\nWhen `medaka_consensus` has finished running, the consensus will be saved to\n`${OUTDIR}/consensus.fasta`.\n\n\n**Bacterial (ploidy-1) variant calling**\n\nVariant calling for monoploid samples is enabled through the `medaka_haploid_variant`\nworkflow:\n\n    medaka_haploid_variant -i <reads.fastq> -r <ref.fasta>\n    \nwhich requires the reads as a `.fasta` or `.fastq` and a reference sequence as a\n`.fasta` file.\n\n\n**Diploid variant calling**\n\nThe diploid variant calling workflow `medaka_variant` that was historically implemented\nwithin the medaka package has been surpassed in accuracy and compute performance by\nother methods, it has therefore been deprecated. Our current recommendation for\nperforming this task is to use [Clair3](https://github.com/HKU-BAL/Clair3) either directly\nor through the Oxford Nanopore Technologies provided Nextflow implementation available\nthrough [EPI2ME Labs](https://labs.epi2me.io/wfindex#variant-calling).\n\n\nModels\n------\n\nFor best results it is important to specify the correct model, `-m` in the\nabove, according to the basecaller used. Allowed values can be found by\nrunning `medaka tools list\\_models`.\n\nMedaka models are named to indicate i) the pore type, ii) the sequencing\ndevice (MinION or PromethION), iii) the basecaller variant, and iv) the\nbasecaller version, with the format:\n\n    {pore}_{device}_{caller variant}_{caller version}\n\nFor example the model named `r941_min_fast_g303` should be used with data from\nMinION (or GridION) R9.4.1 flowcells using the fast Guppy basecaller version\n3.0.3. By contrast the model `r941_prom_hac_g303` should be used with PromethION\ndata and the high accuracy basecaller (termed \"hac\" in Guppy configuration\nfiles). Where a version of Guppy has been used without an exactly corresponding\nmedaka model, the medaka model with the highest version equal to or less than\nthe guppy version should be selected.\n\n\nImproving parallelism\n---------------------\n\nThe `medaka_consensus` program is good for simple datasets but perhaps not\noptimal for running large datasets at scale. A higher level of parallelism\ncan be achieved by running independently the component steps of\n`medaka_consensus`. The program performs three tasks:\n\n1. alignment of reads to input assembly (via `mini_align` which is a thin\n   veil over `minimap2`)\n2. running of consensus algorithm across assembly regions\n   (`medaka consensus`, note no underscore!)\n3. aggregation of the results of 2. to create consensus sequences\n   (`medaka stitch`)\n\nThe three steps are discrete, and can be split apart and run independently. In\nmost cases, Step 2. is the bottleneck and can be trivially parallelized. The\n`medaka consensus` program can be supplied a `--regions`\nargument which will restrict its action to particular assembly sequences from\nthe `.bam` file output in Step 1. Therefore individual jobs can be run for batches\nof assembly sequences simultaneously. In the final step, `medaka stitch`\ncan take as input one or more of the `.hdf` files output by Step 2.\n\nSo in summary something like this is possible:\n\n.. code-block:: bash\n\n    # align reads to assembly\n    mini_align -i basecalls.fasta -r assembly.fasta -P -m \\\n        -p calls_to_draft.bam -t <threads>\n    # run lots of jobs like this, change model as appropriate\n    mkdir results\n    medaka consensus calls_to_draft.bam results/contigs1-4.hdf \\\n        --model r941_min_fast_g303 --batch 200 --threads 8 \\\n        --region contig1 contig2 contig3 contig4\n    ...\n    # wait for jobs, then collate results\n    medaka stitch results/*.hdf polished.assembly.fasta\n\nIt is not recommended to specify a value of `--threads` greater than 2 for\n`medaka consensus` since the compute scaling efficiency is poor beyond this.\nNote also that `medaka consensus` may been seen to use resources equivalent to\n`<threads> + 4` as an additional 4 threads are used for reading and preparing\ninput data.\n\n\nOrigin of the draft sequence\n----------------------------\n\nMedaka has been trained to correct draft sequences output from the\n[Flye](https://github.com/fenderglass/Flye) assembler.\n\nProcessing a draft sequence from alternative sources (e.g. the output of\n[canu](https://github.com/marbl/canu) or\n[wtdbg2](https://github.com/ruanjue/wtdbg2)) may lead to different results.\n\n> Historical correction\n> models in medaka were trained to correct draft sequences output from the canu\n> assembler with [racon](https://github.com/lbcb-sci/racon) applied either once,\n> or four times iteratively. For contemporary models this is not the case and\n> medaka should be used directly on the output of Flye.\n\n\n\nAcknowledgements\n----------------\n\nWe thank [Joanna Pineda](https://github.com/jopineda) and\n[Jared Simpson](https://github.com/jts) for providing htslib code samples which aided\ngreatly development of the optimised feature generation code, and for testing the\nversion 0.4 release candidates.\n\nWe thank [Devin Drown](https://github.com/devindrown) for\n[working through](https://github.com/nanoporetech/medaka/issues/70)\nuse of `medaka` with his RTX 2080 GPU.\n\nHelp\n----\n\n**Licence and Copyright**\n\n© 2018- Oxford Nanopore Technologies Ltd.\n\n`medaka` is distributed under the terms of the Mozilla Public License 2.0.\n\n**Research Release**\n\nResearch releases are provided as technology demonstrators to provide early\naccess to features or stimulate Community development of tools. Support for\nthis software will be minimal and is only provided directly by the developers.\nFeature requests, improvements, and discussions are welcome and can be\nimplemented by forking and pull requests. However much as we would\nlike to rectify every issue and piece of feedback users may have, the\ndevelopers may have limited resource for support of this software. Research\nreleases may be unstable and subject to rapid iteration by Oxford Nanopore\nTechnologies.\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/nanoporetech/medaka",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "medaka-cpu",
    "package_url": "https://pypi.org/project/medaka-cpu/",
    "platform": null,
    "project_url": "https://pypi.org/project/medaka-cpu/",
    "project_urls": {
      "Homepage": "https://github.com/nanoporetech/medaka"
    },
    "release_url": "https://pypi.org/project/medaka-cpu/1.7.3/",
    "requires_dist": [
      "cffi (==1.15.0)",
      "edlib",
      "grpcio",
      "h5py",
      "intervaltree",
      "tensorflow-cpu (~=2.8.0)",
      "numpy (>=1.21.6)",
      "mappy",
      "ont-fast5-api",
      "parasail",
      "pysam (>=0.16.0.1)",
      "pyspoa (>=0.0.3)",
      "requests"
    ],
    "requires_python": ">=3.7,<3.11",
    "summary": "Neural network sequence error correction.",
    "version": "1.7.3",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16841334,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "f743e8f0e0345603b12c54a5d0e2610e61de44e44b5fb7f69f458787731353bb",
        "md5": "8ef90517dd6f3928356af75d2d208d4c",
        "sha256": "350db6e4c7afd8629acca37f9d87aa357b888ad7fbd6b6ca7d1638fde8a5b010"
      },
      "downloads": -1,
      "filename": "medaka_cpu-1.7.3-cp310-cp310-manylinux_2_24_x86_64.whl",
      "has_sig": false,
      "md5_digest": "8ef90517dd6f3928356af75d2d208d4c",
      "packagetype": "bdist_wheel",
      "python_version": "cp310",
      "requires_python": ">=3.7,<3.11",
      "size": 42552989,
      "upload_time": "2023-02-13T16:37:55",
      "upload_time_iso_8601": "2023-02-13T16:37:55.181455Z",
      "url": "https://files.pythonhosted.org/packages/f7/43/e8f0e0345603b12c54a5d0e2610e61de44e44b5fb7f69f458787731353bb/medaka_cpu-1.7.3-cp310-cp310-manylinux_2_24_x86_64.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "55910182850e5cf6c781ce056b62bbe42ae8cfddaefa73538092f4f19f197b69",
        "md5": "5661320ef8d17a4ccd5d2681acaeee65",
        "sha256": "04d618e0be19b4ab3519506113cb2b610f85e59e04d069891c269b340f0d2a1d"
      },
      "downloads": -1,
      "filename": "medaka_cpu-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl",
      "has_sig": false,
      "md5_digest": "5661320ef8d17a4ccd5d2681acaeee65",
      "packagetype": "bdist_wheel",
      "python_version": "cp37",
      "requires_python": ">=3.7,<3.11",
      "size": 40781314,
      "upload_time": "2023-02-13T16:38:17",
      "upload_time_iso_8601": "2023-02-13T16:38:17.202258Z",
      "url": "https://files.pythonhosted.org/packages/55/91/0182850e5cf6c781ce056b62bbe42ae8cfddaefa73538092f4f19f197b69/medaka_cpu-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "82e5f9ed36747c68f643df216a671b68b58f105ea14d5960d8ebc5fe4b594a0f",
        "md5": "b3529cbf41f8ca465963f683f4637a1e",
        "sha256": "1820310553b88bbd7edac040ca148de3ccc22fd896039799f71abceaf6045fd4"
      },
      "downloads": -1,
      "filename": "medaka_cpu-1.7.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl",
      "has_sig": false,
      "md5_digest": "b3529cbf41f8ca465963f683f4637a1e",
      "packagetype": "bdist_wheel",
      "python_version": "cp37",
      "requires_python": ">=3.7,<3.11",
      "size": 41478879,
      "upload_time": "2023-02-13T16:38:36",
      "upload_time_iso_8601": "2023-02-13T16:38:36.962233Z",
      "url": "https://files.pythonhosted.org/packages/82/e5/f9ed36747c68f643df216a671b68b58f105ea14d5960d8ebc5fe4b594a0f/medaka_cpu-1.7.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "8e92ec66d2b071636c6f45f76c46c74bdb6bb53f336f2a0549fc37b268ca4fc4",
        "md5": "6f4f6d70d1f4a5cc3e60e292e883c7dc",
        "sha256": "7db18a57864150574f4e03fc3864974facf50f0a3faccf60611fe496cc63df7e"
      },
      "downloads": -1,
      "filename": "medaka_cpu-1.7.3-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl",
      "has_sig": false,
      "md5_digest": "6f4f6d70d1f4a5cc3e60e292e883c7dc",
      "packagetype": "bdist_wheel",
      "python_version": "cp38",
      "requires_python": ">=3.7,<3.11",
      "size": 40782014,
      "upload_time": "2023-02-13T16:38:56",
      "upload_time_iso_8601": "2023-02-13T16:38:56.582776Z",
      "url": "https://files.pythonhosted.org/packages/8e/92/ec66d2b071636c6f45f76c46c74bdb6bb53f336f2a0549fc37b268ca4fc4/medaka_cpu-1.7.3-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "b363647a8a576a4c229e6444d2634c032b791ee518080493da023abc6ebc5712",
        "md5": "3d2f2f17497c63c61931fc969766b3bb",
        "sha256": "44e0cae6d05f630f39ad3946d897bb7b3bbc34cc58c8c38826b3c922b775b6fa"
      },
      "downloads": -1,
      "filename": "medaka_cpu-1.7.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl",
      "has_sig": false,
      "md5_digest": "3d2f2f17497c63c61931fc969766b3bb",
      "packagetype": "bdist_wheel",
      "python_version": "cp38",
      "requires_python": ">=3.7,<3.11",
      "size": 41479284,
      "upload_time": "2023-02-13T16:39:20",
      "upload_time_iso_8601": "2023-02-13T16:39:20.976181Z",
      "url": "https://files.pythonhosted.org/packages/b3/63/647a8a576a4c229e6444d2634c032b791ee518080493da023abc6ebc5712/medaka_cpu-1.7.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "d92400b913ff5ec127aed94c15550c7cfa6b04fe576fc4f163c20a8d235cf4aa",
        "md5": "933a3c4014c6efb95983d527684a6e6c",
        "sha256": "953a39499e705a28cdf6ee53ba0f350a3316aab2051a368bda9c585c8e50ef58"
      },
      "downloads": -1,
      "filename": "medaka_cpu-1.7.3-cp38-cp38-manylinux_2_24_x86_64.whl",
      "has_sig": false,
      "md5_digest": "933a3c4014c6efb95983d527684a6e6c",
      "packagetype": "bdist_wheel",
      "python_version": "cp38",
      "requires_python": ">=3.7,<3.11",
      "size": 42553365,
      "upload_time": "2023-02-13T16:39:42",
      "upload_time_iso_8601": "2023-02-13T16:39:42.779159Z",
      "url": "https://files.pythonhosted.org/packages/d9/24/00b913ff5ec127aed94c15550c7cfa6b04fe576fc4f163c20a8d235cf4aa/medaka_cpu-1.7.3-cp38-cp38-manylinux_2_24_x86_64.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "3c06644e1b17e5cafe6743ba3ab06aa79e5b10e065f4e25fb8e0de181a670620",
        "md5": "24d8f9ee948ee2c046086f8a677f3afc",
        "sha256": "db7eab859d1e203f3151048b27b0e069e71c596c2dd60fdf0519b907a75271df"
      },
      "downloads": -1,
      "filename": "medaka_cpu-1.7.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl",
      "has_sig": false,
      "md5_digest": "24d8f9ee948ee2c046086f8a677f3afc",
      "packagetype": "bdist_wheel",
      "python_version": "cp39",
      "requires_python": ">=3.7,<3.11",
      "size": 41479147,
      "upload_time": "2023-02-13T16:40:01",
      "upload_time_iso_8601": "2023-02-13T16:40:01.226377Z",
      "url": "https://files.pythonhosted.org/packages/3c/06/644e1b17e5cafe6743ba3ab06aa79e5b10e065f4e25fb8e0de181a670620/medaka_cpu-1.7.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "08c9bce6ac27749b5e3b8166babaa173297156763f74b37fb7eab3b8b0013bc3",
        "md5": "d88ef96cb07d392f1a263d56224fc6f5",
        "sha256": "1089d3e79f61697c49b1e9f1ef5bcf8087a6c08f805a5a96075eb8f53604a47c"
      },
      "downloads": -1,
      "filename": "medaka_cpu-1.7.3-cp39-cp39-manylinux_2_24_x86_64.whl",
      "has_sig": false,
      "md5_digest": "d88ef96cb07d392f1a263d56224fc6f5",
      "packagetype": "bdist_wheel",
      "python_version": "cp39",
      "requires_python": ">=3.7,<3.11",
      "size": 42552938,
      "upload_time": "2023-02-13T16:40:17",
      "upload_time_iso_8601": "2023-02-13T16:40:17.831739Z",
      "url": "https://files.pythonhosted.org/packages/08/c9/bce6ac27749b5e3b8166babaa173297156763f74b37fb7eab3b8b0013bc3/medaka_cpu-1.7.3-cp39-cp39-manylinux_2_24_x86_64.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}