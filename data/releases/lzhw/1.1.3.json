{
  "info": {
    "author": "Muhammad N. Fawi",
    "author_email": "m.noor.fawi@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.7"
    ],
    "description": "# lzhw\n\n[![](https://img.shields.io/badge/docs-latest-blue.svg)](https://mnoorfawi.github.io/lzhw/) \n[![Build Status](https://travis-ci.com/MNoorFawi/lzhw.svg?branch=master)](https://travis-ci.com/MNoorFawi/lzhw)\n\n**Compression** library to compress big lists and/or pandas dataframes using an **optimized algorithm (lzhw)** developed from Lempel-Ziv, Huffman and LZ-Welch techniques.\n\n## How lzhw Works\nThe library's main goal is to compress data frames, excel and csv files so that they consume less space to overcome memory errors.\nAlso to enable dealing with large files that can cause memory errors when reading them in python or that cause slow operations.\nWith **lzhw**, we can read compressed files and do operations **column by column** only on columns that we are interesred in. \n\nThe algorithm is a mix of the famous **lempel-ziv and huffman coding** algorithm with some use of **lempel-ziv-welch** algorithm.\nThe algorithm starts with an input stream for example this one:\n```python\nexample = [\"to\", \"be\", \"or\", \"not\", \"to\", \"be\", \"or\", \"to\", \"be\", \"or\", \"not\"] * 2\nprint(\"\".join(example))\n# tobeornottobeortobeornottobeornottobeortobeornot\n```\n**lzhw** uses **lz78** to discover repeated sequences in the stream and construct a dictionary, but instead of returning their codes from the dictionary, it glues the sequence together in one cell.\nThen we will have a shorter list with repeated sequences glued together, where **Huffman Coding** can come to the game encoding them.\n\nThe function that performs lempel-ziv and returning a shorter list without the codes I named it **lz20** :D.\n```python\nlz20_ex = lzhw.lz20(example)\nprint(lz20_ex)\n# ['to', 'be', 'or', 'not', 'to', 'be', 'or', 'to', 'be', 'or', \n#  'not', 'to', 'be or', 'not', 'to be', 'or', 'to be or', 'not']\n```\nNow huffman coding will give us:\n```python\nhuff20 = lzhw.huffman_coding(Counter(lz20_ex))\nprint(huff20)\n# {'to': '10', 'be': '110', 'or': '01', 'not': '00', \n#  'be or': '11110', 'to be': '11111', 'to be or': '1110'}\n```\nThis will give us:\n```python\n\"\".join([huff20.get(i) for i in lz20_ex])\n# 10110010010110011011001001011110001111101111000\n```\nWhich has a length of 47 bits.\n\nThen it uses **lempel-ziv-welch (lzw)** to compress the keys of the dictionaries so that no need to store them as strings, i.e. extra space saving.\n```python\nfrom sys import getsizeof\nsome_key = \"to be or\"\nprint(getsizeof(some_key))\n# 57\n\nlzw_key = lzhw.lzw_compress(some_key)\nprint(lzw_key)\n# 5794278370027331706482\n\nprint(getsizeof(lzw_key))\n# 36\n```\nLet's see if we store the keys of the dictionary as string how much size they will have in comparison of the integer type.\n```python\nkeys = list(huff20.keys())\nprint(getsizeof(keys))\n# 144\n\ncomp_keys = [lzhw.lzw_compress(k) for k in keys]\nprint(getsizeof(comp_keys))\n# 128\n```\n\nAll of the steps can be done at once using **LZHW** class as follows and as shown in the Quick Start section:\n```python\nlzhw_comp = lzhw.LZHW(example)\nprint(lzhw_comp)\n# 110110010010110011011001001011110001111101111000 \n# the first 1 is a to save the preceeding 0s as compressed data is stored as an integer\nprint(lzhw_comp.compressed)\n# 238786645532536\n\nprint(lzhw_comp.sequences) # dictionary's keys and values are stored as integers as well\n# {6: 321647, 14: 312421, 5: 319090, 4: 163110516, 62: 41932445245042,\n#  63: 43170737996901, 30: 5794278370027331706482}\n```\n\n## Quick Start\n\n```bash\npip install lzhw\n```\n\n```python\nimport lzhw\n\nsample_data = [\"Sunny\", \"Sunny\", \"Overcast\", \"Rain\", \"Rain\", \"Rain\", \"Overcast\", \n               \"Sunny\", \"Sunny\", \"Rain\", \"Sunny\", \"Overcast\", \"Overcast\", \"Rain\", \n               \"Rain\", \"Rain\", \"Sunny\", \"Sunny\", \"Overcaste\"]\n\ncompressed = lzhw.LZHW(sample_data)\n## let's see how the compressed object looks like:\nprint(compressed)\n# 1111101101010011111101101010011100000010\n\n## its size\nprint(compressed.size())\n# 32\n\n## size of original\nfrom sys import getsizeof\nprint(getsizeof(sample_data))\n# 216\n\nprint(compressed.space_saving())\n# space saving from original to compressed is 85%\n\n## Let's decompress and check whether there is any information loss\ndecomp = compressed.decompress()\nprint(decomp == sample_data)\n# True\n```\n\nAs we saw, the LZHW class has saved 85% of the space used to store the original list without any loss.\nThe class has also some useful helper methods as **space_saving**, **size**, and **decompress()** to revert back to original.\n\nAnother example with numeric data.\n\n```python\nfrom random import sample, choices\n\nnumbers = choices(sample(range(0, 5), 5), k = 20)\ncomp_num = lzhw.LZHW(numbers)\n\nprint(getsizeof(numbers) > comp_num.size())\n# True\n\nprint(numbers == list(map(int, comp_num.decompress()))) ## make it int again\n# True\n\nprint(comp_num.space_saving())\n# space saving from original to compressed is 88%\n```\n\nLet's look at how the compressed object is stored and how it looks like when printed:\nLZHW class has an attribute called **compressed** which is the integer of the encoded bitstring\n\n```python\nprint(comp_num.compressed) # how the compressed is saved (as integer of the bit string)\n# 103596881534874\n\nprint(comp_num)\n# 10111100011100010000111010100101101111110011010\n```\n\nWe can also write the compressed data to files using **save_to_file** method, \nand read it back and decompress it using **decompress_from_file** function.\n\n```python\nstatus = [\"Good\", \"Bad\", \"Bad\", \"Bad\", \"Good\", \"Good\", \"Average\", \"Average\", \"Good\",\n          \"Average\", \"Average\", \"Bad\", \"Average\", \"Good\", \"Bad\", \"Bad\", \"Good\"]\ncomp_status = lzhw.LZHW(status)\ncomp_status.save_to_file(\"status.txt\")\ndecomp_status = lzhw.decompress_from_file(\"status.txt\")\nprint(status == decomp_status)\n# True\n```\n\n## Compressing DataFrames\n\nlzhw doesn't work only on lists, it also compress pandas dataframes and save it into compressed files to decompress them later.\n\n```python\nimport pandas as pd\n\ndf = pd.DataFrame({\"a\": [1, 1, 2, 2, 1, 3, 4, 4],\n                   \"b\": [\"A\", \"A\", \"B\", \"B\", \"A\", \"C\", \"D\", \"D\"]})\ncomp_df = lzhw.CompressedDF(df)\n# 100%|██████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 2003.97it/s]\n```\n\nLet's check space saved by compression\n```python\ncomp_space = 0\nfor i in range(len(comp_df.compressed)):\n\tcomp_space += comp_df.compressed[i].size()\n\nprint(comp_space, getsizeof(df))\n# 56 712\n\n## Test information loss\nprint(comp_df.compressed[0].decompress() == list(map(str, df.a)))\n# True\n```\n\n#### Saving and Loading Compressed DataFrames\n\nWith lzhw we can save a data frame into a compressed file and then read it again \nusing **save_to_file** method and **decompress_df_from_file** function.\n\n```python\n## Save to file\ncomp_df.save_to_file(\"comp_df.txt\")\n\n## Load the file\noriginal = lzhw.decompress_df_from_file(\"comp_df.txt\")\n# 100%|██████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 2004.93it/s]\n\nprint(original)\n#   a  b\n#0  1  A\n#1  1  A\n#2  2  B\n#3  2  B\n#4  1  A\n#5  3  C\n#6  4  D\n#7  4  D\n```\n\n#### Compressing Bigger DataFrames\n\nLet's try to compress a real-world dataframe **german_credit.xlsx** file.\nOriginal txt file is **219 KB** on desk.\n\n```python\ngc_original = pd.read_excel(\"examples/german_credit.xlsx\")\ncomp_gc = lzhw.CompressedDF(gc_original)\n# 100%|█████████████████████████████████████████████████████████████████████████████████| 62/62 [00:00<00:00, 257.95it/s]\n\n## Compare sizes in Python:\ncomp_space = 0\nfor i in range(len(comp_gc.compressed)):\n\tcomp_space += comp_gc.compressed[i].size()\n\nprint(comp_space, getsizeof(gc_original))\n# 12932 548852\n\nprint(comp_gc.compressed[0].decompress() == list(map(str, gc_original.iloc[:, 0])))\n# True\n```\n\n**Huge space saving, 97%, with no information loss!**\n\nLet's now write the compressed dataframe into a file and compare the sizes of the files.\n\n```python\ncomp_gc.save_to_file(\"gc_compressed.txt\")\n``` \n\nChecking the size of the compressed file, it is **87 KB**. Meaning that in total we saved around **60%**.\nFuture versions will be optimized to save more space.\n\nLet's now check when we reload the file, will we lose any information or not.\n\n```python\n## Load the file\ngc_original2 = lzhw.decompress_df_from_file(\"gc_compressed.txt\")\n# 100%|█████████████████████████████████████████████████████████████████████████████████| 62/62 [00:00<00:00, 259.46it/s]\n\nprint(list(gc_original2.iloc[:, 13]) == list(map(str, gc_original.iloc[:, 13])))\n# True\n\nprint(gc_original.shape == gc_original2.shape)\n# True\n```\n\nPerfect! There is no information loss at all.\n\n## (De)Compressing specific columns from a dataframe\n\nWith **lzhw** you can choose what columns you are interested in compressing from a data frame.\n**CompressedDF** class has an argument **selected_cols**.\n```python\ngc_original = pd.read_excel(\"examples/german_credit.xlsx\")\ncomp_gc = lzhw.CompressedDF(gc_original, selected_cols = [0, 3, 4, 7])\n# 100%|███████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 401.11it/s]\n``` \nAlso when you have a compressed file that you want to decompress, you don't have to decompress it all, you can choose only specific columns to decompress.\nBy this you can deal with large compressed files and do operations **column by column** quickly and **avoid memory errors**\n**decompress_df_from_file** function has the same argument **selected_cols**.\n```python\ngc_original2 = lzhw.decompress_df_from_file(\"gc_compressed.txt\", selected_cols = [0, 4])\n# 100%|████████████████████████████████████████████████████████████████████████████████| 62/62 [00:00<00:00, 3348.53it/s]\n\ngc_original2.head()\n#\tDuration\tAge\n#0\t       6\t67\n#1\t      48\t22\n#2\t      12\t49\n#3\t      42\t45\n#4\t      24\t53\n```\nLet's compare this subset with the original df.\n```python\ngc_original.iloc[:, [0, 4]].head()\n#\tDuration\tAge\n#0\t       6\t67\n#1\t      48\t22\n#2\t      12\t49\n#3\t      42\t45\n#4\t      24\t53\n```\nPerfect!\n\n*selected_cols* has \"all\" as its default value.\n\n## Using the lzhw Command Line Interface\n\nIn **lzhw_cli** folder, there is a python script that can work on command line to compress and decompress files.\n\nHere is the file:\n```bash\n$python lzhw_cli.py\n\nusage: lzhw_cli.py [-h] [-d] -f INPUT -o OUTPUT\nlzhw_cli.py: error: the following arguments are required: -f/--input, -o/--output\n```\n\nGetting help to see what it does and its arguments:\n```bash\n$python lzhw_cli.py -h\n\nusage: lzhw_cli.py [-h] [-d] -f INPUT -o OUTPUT\n\nData Frame Compressor\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -d, --decompress      decompress input into output\n  -f INPUT, --input INPUT\n                        input file to be (de)compressed\n  -o OUTPUT, --output OUTPUT\n                        output where to save result\n```\n\nHow to compress:\n```bash\n$python lzhw_cli.py -f \"file_to_compress\" -o \"output\"\n\ncompressed successfully\n```\n\nHow to decompress:\n```bash\n$python lzhw_cli.py -d -f \"file_to_decompress\" -o \"output\"\n\ndecompressed successfully\n```\n## Helper Functions\n\nAside from the functions and classes discussed, the library also has some more compression functions that can be used as standalone.\n\n#### lz78()\n\n**lz78** which performs the famous **lempel-ziv78** algorithm:\n```python\nimport random\nrandom.seed(1311)\nexample = random.choices([\"A\", \"B\", \"C\"], k = 20)\nprint(example)\n['A', 'A', 'C', 'C', 'A', 'A', 'C', 'C', 'C', 'B', 'B', 'A', 'B', 'B', 'C', 'C', 'B', 'C', 'C', 'B']\n\nlz78_comp, symb_dict = lzhw.lz78(example)\nprint(lz78_comp)\n# ['1', '1', 'C', '3', '1', 'A', '3', 'C', '3', 'B', \n#  '7', '1', 'B', '7', 'C', '6', 'C', 'C B']\n\nprint(symb_dict)\n# {'A': '1', 'A C': '2', 'C': '3', 'A A': '4', 'C C': '5', \n   'C B': '6', 'B': '7', 'A B': '8', 'B C': '9', 'C B C': '10'}\n```\n\n#### huffman_coding()\n\nHuffman Coding function which takes a Counter object and encodes each symbol accordingly.\n```python\nfrom collections import Counter\nhuffs = lzhw.huffman_coding(Counter(example))\nprint(huffs)\n# {'A': '10', 'C': '0', 'B': '11'}\n```\n\n#### lzw_compress() and lzw_decompress()\n\nThey perform **lempel-ziv-welch** compressing and decompressing\n```python\nprint(lzhw.lzw_compress(\"Hello World\"))\n# 723201696971929295664359987300\n\nprint(lzhw.lzw_decompress(lzw.lzw_compress(\"Hello World\")))\n# Hello World\n```\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/MNoorFawi/lzhw",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "lzhw",
    "package_url": "https://pypi.org/project/lzhw/",
    "platform": "",
    "project_url": "https://pypi.org/project/lzhw/",
    "project_urls": {
      "Homepage": "https://github.com/MNoorFawi/lzhw"
    },
    "release_url": "https://pypi.org/project/lzhw/1.1.3/",
    "requires_dist": [
      "pandas",
      "tqdm"
    ],
    "requires_python": "",
    "summary": "Compression using an optimized algorithm (lzhw) developed from Lempel-Ziv, Huffman and LZ-Welch techniques",
    "version": "1.1.3",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 7625775,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "08fa79400e3bf4fa5f8d35dd2e82842dcf221713b0e2b85ca17364824d86a1f5",
        "md5": "164042b0e37e0332d25d219f369b31d9",
        "sha256": "5f60d5801bb4bfa7a7f06bc972d34be37b10f9e7e685508e612989609e9c168d"
      },
      "downloads": -1,
      "filename": "lzhw-1.1.3-cp37-cp37m-win_amd64.whl",
      "has_sig": false,
      "md5_digest": "164042b0e37e0332d25d219f369b31d9",
      "packagetype": "bdist_wheel",
      "python_version": "cp37",
      "requires_python": null,
      "size": 114433,
      "upload_time": "2020-06-03T16:41:07",
      "upload_time_iso_8601": "2020-06-03T16:41:07.526728Z",
      "url": "https://files.pythonhosted.org/packages/08/fa/79400e3bf4fa5f8d35dd2e82842dcf221713b0e2b85ca17364824d86a1f5/lzhw-1.1.3-cp37-cp37m-win_amd64.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "99448a1497ad601cc52a985305868415fc4e7649f4640adf03acd0654fd14749",
        "md5": "4c2da36ea04a90395561a12895f6ba11",
        "sha256": "c9a5e3916a1df423dd995e9132d8ec8fe5e6b4d4eeac37c6bf3a70a13b4fe3fe"
      },
      "downloads": -1,
      "filename": "lzhw-1.1.3.tar.gz",
      "has_sig": false,
      "md5_digest": "4c2da36ea04a90395561a12895f6ba11",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 243241,
      "upload_time": "2020-06-03T16:41:09",
      "upload_time_iso_8601": "2020-06-03T16:41:09.102796Z",
      "url": "https://files.pythonhosted.org/packages/99/44/8a1497ad601cc52a985305868415fc4e7649f4640adf03acd0654fd14749/lzhw-1.1.3.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}