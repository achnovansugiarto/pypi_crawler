{
  "info": {
    "author": "Sebastian Maurice",
    "author_email": "sebastian.maurice@otics.ca",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "**Multi-Agent Accelerator for Data Science Using Transactional Machine Learning (MAADSTML)**\n\n*Revolutionizing Data Stream Science with Transactional Machine Learning*\n\n**Overview**\n\n*MAADSTML combines Artificial Intelligence, Auto Machine Learning with Data Streams Integrated with Apache Kafka to create frictionless and elastic machine learning solutions.*  \n\nThis library allows users to harness the power of agent-based computing using hundreds of advanced linear and non-linear algorithms. Users can easily integrate Predictive Analytics, Prescriptive Analytics and Optimization in any data stream solution by wrapping additional code around the functions below. It connects with **Apache KAFKA brokers** for cloud based computing using Kafka as the data backbone. \n\nIt uses VIPER as a **KAFKA connector and seamlessly combines Auto Machine Learning, with Real-Time Machine Learning, Real-Time Optimization and Real-Time Predictions** while publishing these insights in to a Kafka cluster in real-time at scale, while allowing users to consume these insights from anywhere, anytime and in any format.  We also provide management of algorithms and insights using our AiMS product integrated with VIPER and Kafka, to **help businesses reduce cloud compute and storage costs by tracking and controlling what algorithms are producing, and who is consuming these insights.**  If no one is consuming these insights, AiMS can **automatically deactivate** these algorithms thus STOPPING its use of storage and compute, saving organizations upto 20% in cloud costs. \n\nIt also HPDE as the AutoML technology for TML.  Linux/Windows/Mac versions can be downloaded from [Github](https://github.com/smaurice101/transactionalmachinelearning)\n\nIt uses VIPERviz to visualize streaming insights over HTTP(S). Linux/Windows/Mac versions can be downloaded from [Github](https://github.com/smaurice101/transactionalmachinelearning)\n\nMAADSTML details can be found in the forthcoming book: [Transactional Machine Learning with Data Streams and AutoML](https://github.com/smaurice101/transactionalmachinelearning_Book)\n\n\nTo install this library a request should be made to **support@otics.ca** for a username and a MAADSTOKEN.  Once you have these credentials then install this Python library.\n\n**Compatibility**\n    - Python 3.5 or greater\n    - Minimal Python skills needed\n\n**Copyright**\n   - Author: Sebastian Maurice, PhD\n\n**Installation**\n   - At the command prompt write:\n     **pip install maadstml**\n     - This assumes you have [Downloaded Python](https://www.python.org/downloads/) and installed it on your computer.  \n\n\n**MAADS-VIPER Connector to Manage Apache KAFKA:** \n  - MAADS-VIPER python library connects to VIPER instances on any servers; VIPER manages Apache Kafka.  VIPER is REST based and cross-platform that can run on windows, linux, MAC, etc.. It also fully supports SSL/TLS encryption in Kafka brokers for producing and consuming.\n\n- **viperlisttopics** \n  - List all topics in Kafka brokers\n\n- **viperdeactivatetopic**\n  - Deactivate topics in kafka brokers and prevent unused algorithms from consuming storage and computing resources that cost money \n\n- **viperactivatetopic**\n  - Activate topics in Kafka brokers \n\n- **vipercreatetopic**\n  - Create topics in Kafka brokers \n\n- **viperstats**\n  - List all stats from Kafka brokers allowing VIPER and KAFKA admins with a end-end view of who is producing data to algorithms, and who is consuming the insights from the algorithms including date/time stamp on the last reads/writes to topics, and how many bytes were read and written to topics and a lot more\n\n- **vipersubscribeconsumer**\n  - Admins can subscribe consumers to topics and consumers will immediately receive insights from topics.  This also gives admins more control of who is consuming the insights and allows them to ensures any issues are resolved quickly in case something happens to the algorithms.\n\n- **viperunsubscribeconsumer**\n  - Admins can unsubscribe consumers from receiving insights, this is important to ensure storage and compute resources are always used for active users.  For example, if a business user leaves your company or no longer needs the insights, by unsubscribing the consumer, the algorithm will STOP producing the insights.\n\n- **viperhpdetraining**\n  - Users can do real-time machine learning (RTML) on the data in Kafka topics. This is very powerful and useful for \"transactional learnings\" on the fly using our HPDE technology.  HPDE will find the optimal algorithm for the data in less than 60 seconds.  \n\n- **viperhpdepredict**\n  - Using the optimal algorithm - users can do real-time predictions from streaming data into Kafka Topics.\n\n- **viperhpdeoptimize**\n  -  Users can even do optimization to MINIMIZE or MAXIMIZE the optimal algorithm to find the BEST values for the independent variables that will minimize or maximize the dependent variable.\n\n- **viperproducetotopic**\n  - Users can produce to any topics by injesting from any data sources.\n\n- **viperproducetotopicbulk**\n  - Users can produce to any topics by injesting from any data sources.  Use this function to write bulk transactions at high speeds.  With the right architecture and\n  network you can stream 1 million transactions per second (or more).\n\n- **viperconsumefromtopic**\n  - Users can consume from any topic and graph the data. \n\n- **viperconsumefromstreamtopic**\n  - Users can consume from a multiple stream of topics at once\n\n- **vipercreateconsumergroup**\n  - Admins can create a consumer group made up of any number of consumers.  You can add as many partitions for the group in the Kafka broker as well as specify the replication factor to ensure high availaibility and no disruption to users who consume insights from the topics.\n\n- **viperconsumergroupconsumefromtopic**\n  - Users who are part of the consumer group can consume from the group topic.\n\n- **viperproducetotopicstream**\n  - Users can join multiple topic streams and produce the combined results to another topic.\n\n- **viperpreprocessproducetotopicstream**\n  - Users can pre-process data streams using the following functions: MAX, MIN, SUM, AVG, COUNT, DIFF.  This is very useful if you want\n  to extract aggregate values that you can then use to build TML models.\n\n- **vipercreatejointopicstreams**\n  - Users can join multiple topic streams\n\n- **vipercreatetrainingdata**\n  - Users can create a training data set from the topic streams for Real-Time Machine Learning (RTML) on the fly.\n\n- **vipermodifyconsumerdetails**\n  - Users can modify consumer details on the topic.  When topics are created an admin must indicate name, email, location and description of the topic.  This helps to better manage the topic and if there are issues, the admin can contact the individual consuming from the topic.\n\n- **vipermodifytopicdetails**\n  - Users can modify details on the topic.  When topics are created an admin must indicate name, email, location and description of the topic.  This helps to better manage the topic and if there are issues, the admin can contact the developer of the algorithm and resolve issue quickly to ensure disruption to consumers is minimal.\n\n- **vipergroupdeactivate**\n  - Admins can deactive a consumer group, which will stop all insights being delivered to consumers in the group.\n\n- **vipergroupactivate**\n  - Admins can activate a group to re-start the insights.\n\n- **viperdeletetopics**\n  - Admins can delete topics in VIPER database and Kafka clusters.\n\n- **viperanomalytrain**\n  - Perform anomaly/peer group analysis on text or numeric data stream using advanced unsupervised learning. VIPER automatically joins \n    streams, and determines the peer group of \"usual\" behaviours using proprietary algorithms, which are then used to predict anomalies with \n\t*viperanomalypredict* in real-time.  Users can use several parameters to fine tune the peer groups.  \n\n\t*VIPER is one of the very few, if not only, technology to do anomaly/peer group analysis using unsupervised learning on data streams \n\twith Apache Kafka.*\n\n- **viperanomalypredict**\n  - Predicts anomalies for text or numeric data using the peer groups found with *viperanomalytrain*.  VIPER automatically joins streams\n  and compares each value with the peer groups and determines if a value is anomalous in real-time.  Users can use several parameters to fine tune\n  the analysis. \n\n  *VIPER is one of the very few, if not only, technology to do anomaly detection/predictions using unsupervised learning on data streams\n  with Apache Kafka.*\n\n\n**First import the Python library.**\n\n**import maadstml**\n\n\n**1. maadstml.viperstats(vipertoken,host,port=-999,brokerhost='',brokerport=-999,microserviceid='')**\n\n**Parameters:**\t\n\n*VIPERTOKEN* : string, required\n\n- A token given to you by VIPER administrator.\n\n*host* : string, required\n\n- Indicates the url where the VIPER instance is located and listening.\n\n*port* : int, required\n\n- Port on which VIPER is listenting.\n\n\n*brokerhost* : string, optional\n\n- Address where Kafka broker is running - if none is specified, the Kafka broker address in the VIPER.ENV file will be used.\n\n\n*brokerport* : int, optional\n\n- Port on which Kafka is listenting.\n\n*microserviceid* : string, optional\n\n- If you are routing connections to VIPER through a microservice then indicate it here.\n\nRETURNS: A JSON formatted object of all the Kafka broker information.\n\n**21. maadstml.viperlisttopics(vipertoken,host,port=-999,brokerhost='', brokerport=-999,microserviceid='')**\n\n**Parameters:**\t\n\n*VIPERTOKEN* : string, required\n\n- A token given to you by VIPER administrator.\n\n*host* : string, required\n\n- Indicates the url where the VIPER instance is located and listening.\n\n*port* : int, required\n\n- Port on which VIPER is listenting.\n\n\n*brokerhost* : string, optional\n\n- Address where Kafka broker is running - if none is specified, the Kafka broker address in the VIPER.ENV file will be used.\n\n\n*brokerport* : int, optional\n\n- Port on which Kafka is listenting.\n\n*microserviceid* : string, optional\n\n- If you are routing connections to VIPER through a microservice then indicate it here.\n\nRETURNS: A JSON formatted object of all the topics in the Kafka broker.\n\n\n**2. maadstml.vipersubscribeconsumer(vipertoken,host,port,topic,companyname,contactname,contactemail,\n\t\tlocation,description,brokerhost='',brokerport=-999,groupid='',microserviceid='')**\n\n**Parameters:**\t\n\n*VIPERTOKEN* : string, required\n\n- A token given to you by VIPER administrator.\n\n*host* : string, required\n\n- Indicates the url where the VIPER instance is located and listening.\n\n*port* : int, required\n\n- Port on which VIPER is listenting.\n\n*topic* : string, required\n\n- Topic to subscribe to in Kafka broker\n\n*companyname* : string, required\n\n- Company name of consumer\n\n*contactname* : string, required\n\n- Contact name of consumer\n\n*contactemail* : string, required\n\n- Contact email of consumer\n\n*location* : string, required\n\n- Location of consumer\n\n*description* : string, required\n\n- Description of why consumer wants to subscribe to topic\n\n*brokerhost* : string, optional\n\n- Address of Kafka broker - if none is specified it will use broker address in VIPER.ENV file\n\n*brokerport* : int, optional\n\n- Port Kafka is listening on - if none is specified it will use port in the VIPER.ENV file\n\n*groupid* : string, optional\n\n- Subscribe consumer to group\n\n*microserviceid* : string, optional\n\n- If you are routing connections to VIPER through a microservice then indicate it here.\n\nRETURNS: Consumer ID that the user must use to receive insights from topic.\n\n\n**3. maadstml.viperunsubscribeconsumer(vipertoken,host,port,consumerid,brokerhost='',brokerport=-999,\n\tmicroserviceid='')**\n\n**Parameters:**\t\n\n*VIPERTOKEN* : string, required\n\n- A token given to you by VIPER administrator.\n\n*host* : string, required\n\n- Indicates the url where the VIPER instance is located and listening.\n\n*port* : int, required\n\n- Port on which VIPER is listenting.\n\n*consumerid* : string, required\n\n- Consumer id to unsubscribe\n\n*brokerhost* : string, optional\n\n- Address of Kafka broker - if none is specified it will use broker address in VIPER.ENV file\n\n*brokerport* : int, optional\n\n- Port Kafka is listening on - if none is specified it will use port in the VIPER.ENV file\n\nRETURNS: Success/failure \n\n**4. maadstml.viperproducetotopic(vipertoken,host,port,topic,producerid,enabletls=0,delay=100,inputdata='',maadsalgokey='',\n\tmaadstoken='',getoptimal=0,externalprediction='',subtopics='',topicid=-999,identifier='',brokerhost='',brokerport=-999,microserviceid='')**\n\n**Parameters:**\t\n\n*VIPERTOKEN* : string, required\n\n- A token given to you by VIPER administrator.\n\n*host* : string, required\n\n- Indicates the url where the VIPER instance is located and listening.\n\n*port* : int, required\n\n- Port on which VIPER is listenting.\n\n*topic* : string, required\n\n- Topic or Topics to produce to.  You can separate multiple topics by a comma.  If using multiple topics, you must \n  have the same number of producer ids (separated by commas), and same number of externalprediction (separated by\n  commas).  Producing to multiple topics at once is convenient for synchronizing the timing of \n  streams for machine learning.\n\n*subtopic* : string, optional\n\n- Enter sub-topic streams.  This is useful if you want to reduce the number of topics/partitions in Kafka by adding\n  sub-topics in the main topic.  \n\n*topicid* : int, optional\n\n- Topicid represents an id for some entity.  For example, if you have 1000 IoT devices, with 10 subtopic streams \n  you can assign a Topicid to each IoT device and each of the 10 subtopics will be associated to each IoT device.\n  This way, you do not create 10,000 streams, but just 1 Main Topic stream, and VIPER will add the 10,000 streams\n  in the one topic.  This will also drastically reduce the partition costs.  You can also create custom machine \n  learning models, predictions, and optimization for each 1000 IoT devices quickly: **It is very powerful.**\n\n*identifier* : string, optional\n\n- You can add any string identifier for the device.  For examaple, DSN ID, IoT device id etc.. \n\n*producerid* : string, required\n\n- Producer ID of topic to produce to in the Kafka broker\n\n*enabletls* : int, optional\n\n- Set to 1 if Kafka broker is enabled with SSL/TLS encryption, otherwise 0 for plaintext.\n\n*delay*: int, optional\n\n- Time in milliseconds from VIPER backsout from writing messages\n\n*inputdata* : string, optional\n\n- This is the inputdata for the optimal algorithm found by MAADS or HPDE\n\n*maadsalgokey* : string, optional\n\n- This should be the optimal algorithm key returned by maadstml.dotraining function.\n\n*maadstoken* : string, optional\n- If the topic is the name of the algorithm from MAADS, then a MAADSTOKEN must be specified to access the algorithm in the MAADS server\n\n*getoptimal*: int, optional\n- If you used the maadstml.OPTIMIZE function to optimize a MAADS algorithm, then if this is 1 it will only retrieve the optimal results in JSON format.\n\n*externalprediction* : string, optional\n- If you are using your own custom algorithms, then the output of your algorithm can be still used and fed into the Kafka topic.\n\n*brokerhost* : string, optional\n\n- Address of Kafka broker - if none is specified it will use broker address in VIPER.ENV file\n\n*brokerport* : int, optional\n\n- Port Kafka is listening on - if none is specified it will use port in the VIPER.ENV file\n\n*microserviceid* : string, optional\n\n- If you are routing connections to VIPER through a microservice then indicate it here.\n\nRETURNS: Returns the value produced or results retrieved from the optimization.\n\n**4.1. maadstml.viperproducetotopicbulk(vipertoken,host,port,topic,producerid,inputdata,partitionsize=100,enabletls=1,delay=100,\n        brokerhost='',brokerport=-999,microserviceid='')**\n\n**Parameters:**\t\n\n*VIPERTOKEN* : string, required\n\n- A token given to you by VIPER administrator.\n\n*host* : string, required\n\n- Indicates the url where the VIPER instance is located and listening.\n\n*port* : int, required\n\n- Port on which VIPER is listenting.\n\n*topic* : string, required\n\n- Topic or Topics to produce to.  You can separate multiple topics by a comma.  If using multiple topics, you must \n  have the same number of producer ids (separated by commas), and same number of externalprediction (separated by\n  commas).  Producing to multiple topics at once is convenient for synchronizing the timing of \n  streams for machine learning.\n\n*producerid* : string, required\n\n- Producer ID of topic to produce to in the Kafka broker.  Separate multiple producer ids with comma.\n\n*inputdata* : string, required\n\n- You can write multiple transactions to each topic.  Each group of transactions must be separated by a tilde.  \n  Each transaction in the group must be separate by a comma.  The number of groups must match the producerids and \n  topics.  For example, if you are writing to two topics: topic1,topic2, then the inputdata should be:\n  trans1,transn2,...,transnN~trans1,transn2,...,transnN.  The number of transactions and topics can be any number.\n  This function can be very powerful if you need to analyse millions or billions of transactions very quickly.\n\n*partitionsize* : int, optional\n\n- This is the number of partitions of the inputdata.  For example, if your transactions=10000, then VIPER will \n  create partitions of size 100 (if partitionsize=100) resulting in 100 threads for concurrency.  The higher\n  the partitionsize, the lower the number of threads.  If you want to streams lots of data fast, then a \n  partitionzie of 1 is the fastest but will come with overhead because more RAM and CPU will be consumed.\n\n*enabletls* : int, optional\n\n- Set to 1 if Kafka broker is enabled with SSL/TLS encryption, otherwise 0 for plaintext.\n\n*delay*: int, optional\n\n- Time in milliseconds from VIPER backsout from writing messages\n\n*brokerhost* : string, optional\n\n- Address of Kafka broker - if none is specified it will use broker address in VIPER.ENV file\n\n*brokerport* : int, optional\n\n- Port Kafka is listening on - if none is specified it will use port in the VIPER.ENV file\n\n*microserviceid* : string, optional\n\n- If you are routing connections to VIPER through a microservice then indicate it here.\n\nRETURNS: None\n\n**5. maadstml.viperconsumefromtopic(vipertoken,host,port,topic,consumerid,companyname,partition=-1,enabletls=0,delay=100,offset=0,\n\tbrokerhost='',brokerport=-999,microserviceid='',topicid=-999,rollbackoffsets=0)**\n\n**Parameters:**\t\n\n*VIPERTOKEN* : string, required\n\n- A token given to you by VIPER administrator.\n\n*host* : string, required\n\n- Indicates the url where the VIPER instance is located and listening.\n\n*port* : int, required\n\n- Port on which VIPER is listenting.\n\n*topic* : string, required\n\n- Topic to consume from in the Kafka broker\n\n*topicid* : int, optional\n\n- Topicid represents an id for some entity.  For example, if you have 1000 IoT devices, you can consume on a per device by entering\n  its topicid  that you gave when you produced the topic stream.\n\n*rollbackoffsets* : int, optional, enter value between 0 and 100\n\n- This will rollback the streams by this percentage.  For example, if using topicid, the main stream is rolled back by this\n  percentage amount.\n\n*consumerid* : string, required\n\n- Consumer id associated with the topic\n\n*companyname* : string, required\n\n- Your company name\n\n*partition* : int, optional\n\n- set to Kafka partition number or -1 to autodect\n\n*enabletls*: int, optional\n\n- Set to 1 if Kafka broker is SSL/TLS enabled for encrypted traffic, otherwise set to 0 for plaintext.\n\n*delay*: int, optional\n\n- Time in milliseconds before VIPER backsout from reading messages\n\n*offset*: int, optional\n\n- Offset to start the reading from..if 0 then reading will start from the beginning of the topic. If -1, VIPER will automatically \n  go to the last offset.  Or, you can extract the LastOffet from the returned JSON and use this offset for your next call.  \n\n*brokerhost* : string, optional\n\n- Address of Kafka broker - if none is specified it will use broker address in VIPER.ENV file\n\n*brokerport* : int, optional\n\n- Port Kafka is listening on - if none is specified it will use port in the VIPER.ENV file\n\n*microserviceid* : string, optional\n\n- If you are routing connections to VIPER through a microservice then indicate it here.\n\nRETURNS: Returns a JSON object of the contents read from the topic.\n\n\n**6. maadstml.viperhpdepredict(vipertoken,host,port,consumefrom,produceto,companyname,consumerid,producerid,\n\t\thpdehost,inputdata,maxrows=0,algokey='',partition=-1,offset=-1,enabletls=1,delay=1000,hpdeport=-999,brokerhost='',\n\t\tbrokerport=-999,timeout=120,usedeploy=0,microserviceid='',topicid=-999, maintopic='', streamstojoin='')**\n\n**Parameters:**\t\n\n*VIPERTOKEN* : string, required\n\n- A token given to you by VIPER administrator.\n\n*host* : string, required\n\n- Indicates the url where the VIPER instance is located and listening.\n\n*port* : int, required\n\n- Port on which VIPER is listenting.\n\n*topicid* : int, optional\n\n- Topicid represents an id for some entity.  For example, if you have 1000 IoT devices, with 10 subtopic streams \n  you can assign a Topicid to each IoT device and each of the 10 subtopics will be associated to each IoT device.\n  This way, you can do predictions for each IoT using its own custom ML model.\n\n*maintopic* : string, optional\n\n-  This is the name of the topic that contains the sub-topic streams.\n\n*streamstojoin* : string, optional\n\n- These are the sub-topics you are streaming into maintopic.  To do predictions, VIPER will automatically join \n  these streams to create the input data for predictions for each Topicid.\n\n*consumefrom* : string, required\n\n- Topic to consume from in the Kafka broker\n\n*produceto* : string, required\n\n- Topic to produce results of the prediction to\n\n*companyname* : string, required\n\n- Your company name\n\n*consumerid*: string, required\n\n- Consumerid associated with the topic to consume from\n\n*producerid*: string, required\n\n- Producerid associated with the topic to produce to\n\n*inputdata*: string, required\n\n- This is a comma separated list of values that represent the independent variables in your algorithm. \n  The order must match the order of the independent variables in your algorithm. OR, you can enter a \n  data stream that contains the joined topics from *vipercreatejointopicstreams*.\n\n*maxrows*: int, optional\n\n- Use this to rollback the stream by maxrows offsets.  For example, if you want to make 1000 predictions\n  then set maxrows=1000, and make 1000 predictions from the current offset of the independent variables.\n\n*algokey*: string, optional\n\n- If you know the algorithm key that was returned by VIPERHPDETRAIING then you can specify it here.\n  Specifying the algokey can drastically speed up the predictions.\n\n*partition* : int, optional\n\n- If you know the kafka partition used to store data then specify it here.\n  Most cases Kafka will dynamically store data in partitions, so you should\n  use the default of -1 to let VIPER find it.\n\n*offset* : int, optional\n\n- Offset to start consuming data.  Usually you can use -1, and VIPER\n  will get the last offset.\n\n*hpdehost*: string, required\n\n- Address of HPDE \n\n*enabletls*: int, optional\n\n- Set to 1 if Kafka broker is SSL/TLS enabled for encryted traffic, otherwise 0 for plaintext.\n\n*delay*: int, optional\n\n- Time in milliseconds before VIPER backsout from reading messages\n\n*hpdeport*: int, required\n\n- Port number HPDE is listening on \n\n*brokerhost* : string, optional\n\n- Address of Kafka broker - if none is specified it will use broker address in VIPER.ENV file\n\n*brokerport* : int, optional\n\n- Port Kafka is listening on - if none is specified it will use port in the VIPER.ENV file\n\n*timeout* : int, optional\n\n - Number of seconds that VIPER waits when trying to make a connection to HPDE.\n\n*usedeploy* : int, optional\n\n - If 0 will use algorithm in test, else if 1 use in production algorithm. \n\n*microserviceid* : string, optional\n\n- If you are routing connections to VIPER through a microservice then indicate it here.\n\nRETURNS: Returns a JSON object of the prediction.\n\n\n**7. maadstml.viperhpdeoptimize(vipertoken,host,port,consumefrom,produceto,companyname,consumerid,producerid,\n\t\thpdehost,partition=-1,offset=-1,enabletls=0,delay=100,hpdeport=-999,usedeploy=0,ismin=1,constraints='best',\n\t\tstretchbounds=20,constrainttype=1,epsilon=10,brokerhost='',brokerport=-999,timeout=120,microserviceid='',topicid=-999)**\n\n**Parameters:**\t\n\n*VIPERTOKEN* : string, required\n\n- A token given to you by VIPER administrator.\n\n*host* : string, required\n\n- Indicates the url where the VIPER instance is located and listening.\n\n*port* : int, required\n\n- Port on which VIPER is listenting.\n\n*consumefrom* : string, required\n\n- Topic to consume from in the Kafka broker\n\n*topicid* : int, optional\n\n- Topicid represents an id for some entity.  For example, if you have 1000 IoT devices, you can perform\n  mathematical optimization for each of the 1000 IoT devices using their specific algorithm.\n\n*produceto* : string, required\n\n- Topic to produce results of the prediction to\n\n*companyname* : string, required\n\n- Your company name\n\n*consumerid*: string, required\n\n- Consumerid associated with the topic to consume from\n\n*producerid*: string, required\n\n- Producerid associated with the topic to produce to\n\n*hpdehost*: string, required\n\n- Address of HPDE \n\n*partition* : int, optional\n\n- If you know the kafka partition used to store data then specify it here.\n  Most cases Kafka will dynamically store data in partitions, so you should\n  use the default of -1 to let VIPER find it.\n\n*offset* : int, optional\n\n- Offset to start consuming data.  Usually you can use -1, and VIPER\n  will get the last offset.\n\n*enabletls*: int, optional\n\n- Set to 1 if Kafka broker is SSL/TLS enabled for encrypted traffic, otherwise set to 0 for plaintext.\n\n*delay*: int, optional\n\n- Time in milliseconds before VIPER backsout from reading messages\n\n*hpdeport*: int, required\n\n- Port number HPDE is listening on \n\n*usedeploy* : int, optional\n - If 0 will use algorithm in test, else if 1 use in production algorithm. \n\n*ismin* : int, optional\n- If 1 then function is minimized, else if 0 the function is maximized\n\n*constraints*: string, optional\n\n- If \"best\" then HPDE will choose the best values of the independent variables to minmize or maximize the dependent variable.  \n  Users can also specify their own constraints for each variable and must be in the following format: varname1:min:max,varname2:min:max,...\n\n*stretchbounds*: int, optional\n\n- A number between 0 and 100, this is the percentage to stretch the bounds on the constraints.\n\n*constrainttype*: int, optional\n\n- If 1 then HPDE uses the min/max of each variable for the bounds, if 2 HPDE will adjust the min/max by their standard deviation, \n  if 3 then HPDE uses stretchbounds to adjust the min/max for each variable.  \n\n*epsilon*: int, optional\n\n- Once HPDE finds a good local minima/maxima, it then uses this epsilon value to find the Global minima/maxima to ensure \n  you have the best values of the independent variables that minimize or maximize the dependent variable.\n\n*brokerhost* : string, optional\n\n- Address of Kafka broker - if none is specified it will use broker address in VIPER.ENV file\n\n*brokerport* : int, optional\n\n- Port Kafka is listening on - if none is specified it will use port in the VIPER.ENV file\n\n*timeout* : int, optional\n\n - Number of seconds that VIPER waits when trying to make a connection to HPDE.\n\n\n*microserviceid* : string, optional\n\n- If you are routing connections to VIPER through a microservice then indicate it here.\n\nRETURNS: Returns a JSON object of the optimization details and optimal values.\n\n\n**8. maadstml.viperhpdetraining(vipertoken,host,port,consumefrom,produceto,companyname,consumerid,producerid,\n                 hpdehost,viperconfigfile,enabletls=1,partition=-1,deploy=0,modelruns=50,modelsearchtuner=80,hpdeport=-999,\n\t\t\t\t offset=-1,islogistic=0,brokerhost='', brokerport=-999,timeout=120,microserviceid='',topicid=-999,maintopic='',\n                 independentvariables='',dependentvariable='',rollbackoffsets=0,fullpathtotrainingdata='',processlogic='',identifier='')**\n\n**Parameters:**\t\n\n*VIPERTOKEN* : string, required\n\n- A token given to you by VIPER administrator.\n\n*host* : string, required\n\n- Indicates the url where the VIPER instance is located and listening.\n\n*port* : int, required\n\n- Port on which VIPER is listenting.\n\n*topicid* : int, optional\n\n- Topicid represents an id for some entity.  For example, if you have 1000 IoT devices, you can create individual \n  Machine Learning models for each IoT device in real-time.  This is a core functionality of TML solutions.\n\n*maintopic* : string, optional\n\n- This is the maintopic that contains the sub-topc streams.\n\n*independentvariables* : string, optional\n\n- These are the independent variables that are the subtopics.  \n\n*dependentvariable* : string, optional\n\n- This is the dependent variable in the subtopic streams.  \n\n*rollbackoffsets*: int, optional\n\n- This is the rollback percentage to create the training dataset.  VIPER will automatically create a training dataset\n  using the independent and dependent variable streams.  \n\n*fullpathtotrainingdata*: string, optional\n\n- This is the FULL path where you want to store the training dataset.  VIPER will write file to disk. Make sure proper\n  permissions are granted to VIPER.   For example, **c:/myfolder/mypath**\n\n*processlogic* : string, optional\n\n- You can dynamically build a classification model by specifying how you want to classify the dependent variable by\n  indicating your conditions in the processlogic variable (this will take effect if islogistic=1). For example: \n\n  **processlogic='classification_name=my_prob:temperature=20.5,30:humidity=50,55'**, means the following:\n\n   1. The name of the dependent variable is specified by **classification_name**\n   2. Then you can specify the conditions on the streams. If your stream is Temperature and humidity,\n      if Temperature is between 20.5 and 30, then my_prob=1, otherwise my_prob=0, and\n\t  if Humidity is between 50 and 55, then my_prob=1, otherwise my_prob=0\n   3.  If you want to specify no upperbound you can use *n*, or *-n* for no lowerbound.\n       For example, if **temperature=20.5,n**, means temperature >=20.5 then my_prob=1\n\t   If **humidity=-n,55**, means humidity<=55 then my_prob=1 \n\n- This allows you to classify the dependent with any number of variables all in real-time!\n\n*consumefrom* : string, required\n\n- Topic to consume from in the Kafka broker\n\n*produceto* : string, required\n\n- Topic to produce results of the prediction to\n\n*companyname* : string, required\n\n- Your company name\n\n*consumerid*: string, required\n\n*identifier*: string, optional\n\n- You can add any name or identifier like DSN ID\n\n- Consumerid associated with the topic to consume from\n\n*producerid*: string, required\n\n- Producerid associated with the topic to produce to\n\n*hpdehost*: string, required\n\n- Address of HPDE \n\n*viperconfigfile* : string, required\n\n- Full path to VIPER.ENV configuration file on server.\n\n*enabletls*: int, optional\n\n- Set to 1 if Kafka broker is SSL/TLS enabled for encrypted traffic, otherwise set to 0 for plaintext.\n\n*partition*: int, optional\n\n- Partition used by kafka to store data. NOTE: Kafka will dynamically store data in partitions.\n  Unless you know for sure the partition, you should use the default of -1 to let VIPER\n  determine where your data is.\n\n*deploy*: int, optional\n\n- If deploy=1, this will deploy the algorithm to the Deploy folder.  This is useful if you do not\n  want to use this algorithm in production, and just testing it.  If just testing, then set deploy=0 (default).  \n\n*modelruns*: int, optional\n\n- Number of iterations for model training\n\n*modelsearchtuner*: int, optional\n\n- An integer between 0-100, this variable will attempt to fine tune the model search space.  A number close to 0 means you will \n  have lots of models but their quality may be low, a number close to 100 (default=80) means you will have fewer models but their \n  quality will be higher\n\n*hpdeport*: int, required\n\n- Port number HPDE is listening on \n\n*offset* : int, optional\n\n - If 0 will use the training data from the beginning of the topic\n\n*islogistic*: int, optional\n\n- If is 1, the HPDE will switch to logistic modeling, else continous.\n\n*brokerhost* : string, optional\n\n- Address of Kafka broker - if none is specified it will use broker address in VIPER.ENV file\n\n*brokerport* : int, optional\n\n- Port Kafka is listening on - if none is specified it will use port in the VIPER.ENV file\n\n*timeout* : int, optional\n\n - Number of seconds that VIPER waits when trying to make a connection to HPDE.\n\n*microserviceid* : string, optional\n\n- If you are routing connections to VIPER through a microservice then indicate it here.\n\nRETURNS: Returns a JSON object of the optimal algorithm that best fits your data.\n\n**9. maadstml.viperproducetotopicstream(vipertoken,host,port,topic,producerid,offset,maxrows=0,enabletls=0,delay=100,\n\tbrokerhost='',brokerport=-999,microserviceid='',topicid=-999,mainstreamtopic='',streamstojoin='')**\n\n**Parameters:**\t\n\n*VIPERTOKEN* : string, required\n\n- A token given to you by VIPER administrator.\n\n*host* : string, required\n\n- Indicates the url where the VIPER instance is located and listening.\n\n*port* : int, required\n\n- Port on which VIPER is listenting.\n\n*topic* : string, required\n\n- Topics to produce to in the Kafka broker - this is a topic that contains multiple topics, VIPER will consume from each topic and \n  write results to the produceto topic\n\n*topicid* : int, optional\n\n- Topicid represents an id for some entity.  For example, if you have 1000 IoT devices, you can join these streams\n  and produce it to one stream,\n\n*mainstreamtopic*: string, optional\n\n- This is the main stream topic that contain the subtopic streams.\n\n*streamstojoin*: string, optional\n\n- These are the streams you want to join and produce to mainstreamtopic.\n\n*producerid* : string, required\n\n- Producerid of the topic producing to  \n\n*offset* : int\n\n - If 0 will use the stream data from the beginning of the topics, -1 will automatically go to last offset\n\n*maxrows* : int, optional\n\n - If offset=-1, this number will rollback the streams by maxrows amount i.e. rollback=lastoffset-maxrows\n\n*enabletls*: int, optional\n\n- Set to 1 if Kafka broker is SSL/TLS enabled for encrypted traffic, otherwise 0 for plaintext\n\n*delay*: int, optional\n\n- Time in milliseconds before VIPER backsout from reading messages\n\n*brokerhost* : string, optional\n\n- Address of Kafka broker - if none is specified it will use broker address in VIPER.ENV file\n\n*brokerport* : int, optional\n\n- Port Kafka is listening on - if none is specified it will use port in the VIPER.ENV file\n\n*microserviceid* : string, optional\n\n- If you are routing connections to VIPER through a microservice then indicate it here.\n\nRETURNS: Returns a JSON object of the optimal algorithm that best fits your data.\n\n**10. maadstml.vipercreatetrainingdata(vipertoken,host,port,consumefrom,produceto,dependentvariable,\n\t\tindependentvariables,consumerid,producerid,companyname,partition=-1,enabletls=0,delay=100,\n\t\tbrokerhost='',brokerport=-999,microserviceid='',topicid=-999)**\n\n**Parameters:**\t\n\n*VIPERTOKEN* : string, required\n\n- A token given to you by VIPER administrator.\n\n*host* : string, required\n\n- Indicates the url where the VIPER instance is located and listening.\n\n*port* : int, required\n\n- Port on which VIPER is listenting.\n\n*consumefrom* : string, required\n\n- Topic to consume from \n\n*topicid* : int, optional\n\n- Topicid represents an id for some entity.  For example, if you have 1000 IoT devices, with 10 subtopic streams \n  you can assign a Topicid to each IoT device and each of the 10 subtopics will be associated to each IoT device.\n  You can create training dataset for each device.\n\n*produceto* : string, required\n\n- Topic to produce to \n\n*dependentvariable* : string, required\n\n- Topic name of the dependentvariable \n\n*independentvariables* : string, required\n\n- Topic names of the independentvariables - VIPER will automatically read the data streams.  \n  Separate multiple variables by comma. \n\n*consumerid* : string, required\n\n- Consumerid of the topic to consume to  \n\n*producerid* : string, required\n\n- Producerid of the topic producing to  \n\n*partition* : int, optional\n\n- This is the partition that Kafka stored the stream data.  Specifically, the streams you joined \n  from function *viperproducetotopicstream* will be stored in a partition by Kafka, if you \n  want to create a training dataset from these data, then you should use this partition.  This\n  ensures you are using the right data to create a training dataset.\n\n*companyname* : string, required\n\n- Your company name  \n\n*enabletls*: int, optional\n\n- Set to 1 if Kafka broker is enabled for SSL/TLS encrypted traffic, otherwise set to 0 for plaintext.\n\n*delay*: int, optional\n\n- Time in milliseconds before VIPER backout from reading messages\n\n*brokerhost* : string, optional\n\n- Address of Kafka broker - if none is specified it will use broker address in VIPER.ENV file\n\n*brokerport* : int, optional\n\n- Port Kafka is listening on - if none is specified it will use port in the VIPER.ENV file\n\n*microserviceid* : string, optional\n\n- If you are routing connections to VIPER through a microservice then indicate it here.\n\nRETURNS: Returns a JSON object of the training data set.\n\n**11. maadstml.vipercreatetopic(vipertoken,host,port,topic,companyname,contactname,contactemail,location,\ndescription,enabletls=0,brokerhost='',brokerport=-999,numpartitions=1,replication=1,microserviceid='')**\n\n**Parameters:**\t\n\n*VIPERTOKEN* : string, required\n\n- A token given to you by VIPER administrator.\n\n*host* : string, required\n\n- Indicates the url where the VIPER instance is located and listening.\n\n*port* : int, required\n\n- Port on which VIPER is listenting.\n\n*topic* : string, required\n\n- Topic to create \n\n*companyname* : string, required\n\n- Company name of consumer\n\n*contactname* : string, required\n\n- Contact name of consumer\n\n*contactemail* : string, required\n\n- Contact email of consumer\n\n*location* : string, required\n\n- Location of consumer\n\n*description* : string, required\n\n- Description of why consumer wants to subscribe to topic\n\n*enabletls* : int, optional\n\n- Set to 1 if Kafka is SSL/TLS enabled for encrypted traffic, otherwise 0 for no encryption (plain text)\n\n*brokerhost* : string, optional\n\n- Address of Kafka broker - if none is specified it will use broker address in VIPER.ENV file\n\n*brokerport* : int, optional\n\n- Port Kafka is listening on - if none is specified it will use port in the VIPER.ENV file\n\n*numpartitions*: int, optional\n\n- Number of the parititons to create in the Kafka broker - more parititons the faster Kafka will produce results.\n\n*replication*: int, optional\n\n- Specificies the number of brokers to replicate to - this is important for failover\n\n*microserviceid* : string, optional\n\n- If you are routing connections to VIPER through a microservice then indicate it here.\n\nRETURNS: Returns a JSON object of the producer id for the topic.\n\n**12. maadstml.viperconsumefromstreamtopic(vipertoken,host,port,topic,consumerid,companyname,partition=-1,\n        enabletls=0,delay=100,offset=0,brokerhost='',brokerport=-999,microserviceid='',topicid=-999)**\n\n**Parameters:**\t\n\n*VIPERTOKEN* : string, required\n\n- A token given to you by VIPER administrator.\n\n*host* : string, required\n\n- Indicates the url where the VIPER instance is located and listening.\n\n*port* : int, required\n\n- Port on which VIPER is listenting.\n\n*topic* : string, required\n\n- Topic to consume from \n\n*topicid* : int, optional\n\n- Topicid represents an id for some entity.  For example, if you have 1000 IoT devices, you can consume \n  for each device.\n\n*consumerid* : string, required\n\n- Consumerid associated with topic\n\n*companyname* : string, required\n\n- Your company name\n\n*partition*: int, optional\n\n- Set to a kafka partition number, or -1 to autodetect partition.\n\n*enabletls*: int, optional\n\n- Set to 1 if Kafka broker is SSL/TLS enabled for encrypted traffic, otherwise set to 0 for plaintext.\n\n*delay*: int, optional\n\n- Time in milliseconds before VIPER backsout from reading messages\n\n*offset* : int, optional\n\n- Offset to start reading from ..if 0 VIPER will read from the beginning\n\n*brokerhost* : string, optional\n\n- Address of Kafka broker - if none is specified it will use broker address in VIPER.ENV file\n\n*brokerport* : int, optional\n\n- Port Kafka is listening on - if none is specified it will use port in the VIPER.ENV file\n\n*microserviceid* : string, optional\n\n- If you are routing connections to VIPER through a microservice then indicate it here.\n\nRETURNS: Returns a JSON object of the contents of all the topics read\n\n\n**13. maadstml.vipercreatejointopicstreams(vipertoken,host,port,topic,topicstojoin,companyname,contactname,contactemail,\n\t\tdescription,location,enabletls=0,brokerhost='',brokerport=-999,replication=1,numpartitions=1,microserviceid='',\n\t\ttopicid=-999)**\n\n**Parameters:**\t\n\n*VIPERTOKEN* : string, required\n\n- A token given to you by VIPER administrator.\n\n*host* : string, required\n\n- Indicates the url where the VIPER instance is located and listening.\n\n*port* : int, required\n\n- Port on which VIPER is listenting.\n\n*topic* : string, required\n\n- Topic to consume from \n\n*topicid* : int, optional\n\n- Topicid represents an id for some entity.  Create a joined topic stream per topicid.\n\n*topicstojoin* : string, required\n\n- Enter two or more topics separated by a comma and VIPER will join them into one topic\n\n*companyname* : string, required\n\n- Company name of consumer\n\n*contactname* : string, required\n\n- Contact name of consumer\n\n*contactemail* : string, required\n\n- Contact email of consumer\n\n*location* : string, required\n\n- Location of consumer\n\n*description* : string, required\n\n- Description of why consumer wants to subscribe to topic\n\n*enabletls*: int, optional\n\n- Set to 1 if Kafka broker is SSL/TLS enabled, otherwise set to 0 for plaintext.\n\n*brokerhost* : string, optional\n\n- Address of Kafka broker - if none is specified it will use broker address in VIPER.ENV file\n\n*brokerport* : int, optional\n\n- Port Kafka is listening on - if none is specified it will use port in the VIPER.ENV file\n\n*numpartitions* : int, optional\n\n- Number of partitions\n\n*replication* : int, optional\n\n- Replication factor\n\n*microserviceid* : string, optional\n\n- If you are routing connections to VIPER through a microservice then indicate it here.\n\nRETURNS: Returns a JSON object of the producerid of the joined streams\n\n**14. maadstml.vipercreateconsumergroup(vipertoken,host,port,topic,groupname,companyname,contactname,contactemail,\n\t\tdescription,location,enabletls=1,brokerhost='',brokerport=-999,microserviceid='')**\n\n**Parameters:**\t\n\n*VIPERTOKEN* : string, required\n\n- A token given to you by VIPER administrator.\n\n*host* : string, required\n\n- Indicates the url where the VIPER instance is located and listening.\n\n*port* : int, required\n\n- Port on which VIPER is listenting.\n\n*topic* : string, required\n\n- Topic to dd to the group, multiple (active) topics can be separated by comma \n\n*groupname* : string, required\n\n- Enter the name of the group\n\n*companyname* : string, required\n\n- Company name of consumer\n\n*contactname* : string, required\n\n- Contact name of consumer\n\n*contactemail* : string, required\n\n- Contact email of consumer\n\n*location* : string, required\n\n- Location of consumer\n\n*enabletls*: int, optional\n\n- Set to 1 if Kafka broker is SSL/TLS enabled, otherwise set to 0 for plaintext.\n\n*description* : string, required\n\n- Description of why consumer wants to subscribe to topic\n\n*brokerhost* : string, optional\n\n- Address of Kafka broker - if none is specified it will use broker address in VIPER.ENV file\n\n*brokerport* : int, optional\n\n- Port Kafka is listening on - if none is specified it will use port in the VIPER.ENV file\n\n*microserviceid* : string, optional\n\n- If you are routing connections to VIPER through a microservice then indicate it here.\n\nRETURNS: Returns a JSON object of the groupid of the group.\n\n**15. maadstml.viperconsumergroupconsumefromtopic(vipertoken,host,port,topic,consumerid,groupid,companyname,\n\t\tpartition=-1,enabletls=0,delay=100,offset=0,rollbackoffset=0,brokerhost='',brokerport=-999,microserviceid='')**\n\n**Parameters:**\t\n\n*VIPERTOKEN* : string, required\n\n- A token given to you by VIPER administrator.\n\n*host* : string, required\n\n- Indicates the url where the VIPER instance is located and listening.\n\n*port* : int, required\n\n- Port on which VIPER is listenting.\n\n*topic* : string, required\n\n- Topic to dd to the group, multiple (active) topics can be separated by comma \n\n*consumerid* : string, required\n\n- Enter the consumerid associated with the topic\n\n*groupid* : string, required\n\n- Enter the groups id\n\n*companyname* : string, required\n\n- Enter the company name\n\n*partition*: int, optional\n\n- set to Kakfa partition number or -1 to autodetect\n\n*enabletls*: int, optional\n\n- Set to 1 if Kafka broker is SSL/TLS enabled, otherwise set to 0 for plaintext.\n\n*delay*: int, optional\n\n- Time in milliseconds before VIPER backsout from reading messages\n\n*offset* : int, optional\n\n- Offset to start reading from.  If 0, will read from the beginning of topic, or -1 to automatically go to end of topic.\n\n*rollbackoffset* : int, optional\n\n- The number of offsets to rollback the data stream.\n\n*brokerhost* : string, optional\n\n- Address of Kafka broker - if none is specified it will use broker address in VIPER.ENV file\n\n*brokerport* : int, optional\n\n- Port Kafka is listening on - if none is specified it will use port in the VIPER.ENV file\n\n*microserviceid* : string, optional\n\n- If you are routing connections to VIPER through a microservice then indicate it here.\n\nRETURNS: Returns a JSON object of the contents of the group.\n\n**16. maadstml.vipermodifyconsumerdetails(vipertoken,host,port,topic,companyname,consumerid,contactname='',\ncontactemail='',location='',brokerhost='',brokerport=9092,microserviceid='')**\n\n**Parameters:**\t\n\n*VIPERTOKEN* : string, required\n\n- A token given to you by VIPER administrator.\n\n*host* : string, required\n\n- Indicates the url where the VIPER instance is located and listening.\n\n*port* : int, required\n\n- Port on which VIPER is listenting.\n\n*topic* : string, required\n\n- Topic to dd to the group, multiple (active) topics can be separated by comma \n\n*consumerid* : string, required\n\n- Enter the consumerid associated with the topic\n\n*companyname* : string, required\n\n- Enter the company name\n\n*contactname* : string, optional\n\n- Enter the contact name \n\n*contactemail* : string, optional\n- Enter the contact email\n\n*location* : string, optional\n\n- Enter the location\n\n*brokerhost* : string, optional\n\n- Address of Kafka broker - if none is specified it will use broker address in VIPER.ENV file\n\n*brokerport* : int, optional\n\n- Port Kafka is listening on - if none is specified it will use port in the VIPER.ENV file\n\n*microserviceid* : string, optional\n\n- If you are routing connections to VIPER through a microservice then indicate it here.\n\nRETURNS: Returns success/failure\n\n**17. maadstml.vipermodifytopicdetails(vipertoken,host,port,topic,companyname,partition=0,enabletls=1,\n          isgroup=0,contactname='',contactemail='',location='',brokerhost='',brokerport=9092,microserviceid='')**\n\n**Parameters:**\t\n\n*VIPERTOKEN* : string, required\n\n- A token given to you by VIPER administrator.\n\n*host* : string, required\n\n- Indicates the url where the VIPER instance is located and listening.\n\n*port* : int, required\n\n- Port on which VIPER is listenting.\n\n*topic* : string, required\n\n- Topic to dd to the group, multiple (active) topics can be separated by comma \n\n*companyname* : string, required\n\n- Enter the company name\n\n*partition* : int, optional\n\n- You can change the partition in the Kafka topic.\n\n*enabletls* : int, optional\n\n- If enabletls=1, then SSL/TLS is enables in Kafka, otherwise if enabletls=0 it is not.\n\n*isgroup* : int, optional\n\n- This tells VIPER whether this is a group topic if isgroup=1, or a normal topic if isgroup=0\n\n*contactname* : string, optional\n\n- Enter the contact name \n\n*contactemail* : string, optional\n- Enter the contact email\n\n*location* : string, optional\n\n- Enter the location\n\n*brokerhost* : string, optional\n\n- Address of Kafka broker - if none is specified it will use broker address in VIPER.ENV file\n\n*brokerport* : int, optional\n\n- Port Kafka is listening on - if none is specified it will use port in the VIPER.ENV file\n\n*microserviceid* : string, optional\n\n- If you are routing connections to VIPER through a microservice then indicate it here.\n\nRETURNS: Returns success/failure\n\n**18. maadstml.viperactivatetopic(vipertoken,host,port,topic,microserviceid='')**\n\n**Parameters:**\t\n\n*VIPERTOKEN* : string, required\n\n- A token given to you by VIPER administrator.\n\n*host* : string, required\n\n- Indicates the url where the VIPER instance is located and listening.\n\n*port* : int, required\n\n- Port on which VIPER is listenting.\n\n*topic* : string, required\n\n- Topic to activate\n\n*microserviceid* : string, optional\n\n- If you are routing connections to VIPER through a microservice then indicate it here.\n\nRETURNS: Returns success/failure\n\n**19. maadstml.viperdeactivatetopic(vipertoken,host,port,topic,microserviceid='')**\n\n**Parameters:**\t\n\n*VIPERTOKEN* : string, required\n\n- A token given to you by VIPER administrator.\n\n*host* : string, required\n\n- Indicates the url where the VIPER instance is located and listening.\n\n*port* : int, required\n\n- Port on which VIPER is listenting.\n\n*topic* : string, required\n\n- Topic to deactivate\n\n*microserviceid* : string, optional\n\n- If you are routing connections to VIPER through a microservice then indicate it here.\n\nRETURNS: Returns success/failure\n\n**20. maadstml.vipergroupactivate(vipertoken,host,port,groupname,groupid,microserviceid='')**\n\n**Parameters:**\t\n\n*VIPERTOKEN* : string, required\n\n- A token given to you by VIPER administrator.\n\n*host* : string, required\n\n- Indicates the url where the VIPER instance is located and listening.\n\n*port* : int, required\n\n- Port on which VIPER is listenting.\n\n*groupname* : string, required\n\n- Name of the group\n\n*groupid* : string, required\n\n- ID of the group\n\n*microserviceid* : string, optional\n\n- If you are routing connections to VIPER through a microservice then indicate it here.\n\nRETURNS: Returns success/failure\n\n**21.  maadstml.vipergroupdeactivate(vipertoken,host,port,groupname,groupid,microserviceid='')**\n\n**Parameters:**\t\n\n*VIPERTOKEN* : string, required\n\n- A token given to you by VIPER administrator.\n\n*host* : string, required\n\n- Indicates the url where the VIPER instance is located and listening.\n\n*port* : int, required\n\n- Port on which VIPER is listenting.\n\n*groupname* : string, required\n\n- Name of the group\n\n*groupid* : string, required\n\n- ID of the group\n\n*microserviceid* : string, optional\n\n- If you are routing connections to VIPER through a microservice then indicate it here.\n\nRETURNS: Returns success/failure\n\n**22. maadstml.viperdeletetopics(vipertoken,host,port,topic,enabletls=1,brokerhost='',brokerport=9092,microserviceid='')**\n\n**Parameters:**\t\n\n*VIPERTOKEN* : string, required\n\n- A token given to you by VIPER administrator.\n\n*host* : string, required\n\n- Indicates the url where the VIPER instance is located and listening.\n\n*port* : int, required\n\n- Port on which VIPER is listenting.\n\n*topic* : string, required\n\n- Topic to delete.  Separate multiple topics by a comma.\n\n*enabletls* : int, optional\n\n- If enabletls=1, then SSL/TLS is enable on Kafka, otherwise if enabletls=0, it is not.\n\n*brokerhost* : string, optional\n\n- Address of Kafka broker - if none is specified it will use broker address in VIPER.ENV file\n\n*brokerport* : int, optional\n\n- Port Kafka is listening on - if none is specified it will use port in the VIPER.ENV file\n\n*microserviceid* : string, optional\n\n- microservice to access viper\n\n**23.  maadstml.balancebigdata(localcsvfile,numberofbins,maxrows,outputfile,bincutoff,distcutoff,startcolumn=0)**\n\n**Parameters:**\t\n\n*localcsvfile* : string, required\n\n- Local file, must be CSV formatted.\n\n*numberofbins* : int, required\n\n- The number of bins for the histogram. You can set to any value but 10 is usually fine.\n\n*maxrows* :  int, required\n\n- The number of rows to return, which will be a subset of your original data.\n\n*outputfile* : string, required\n\n- Your new data will be writted as CSV to this file.\n\n*bincutoff* : float, required. \n\n-  This is the threshold percentage for the bins. Specifically, the data in each variable is allocated to bins, but many \n   times it will not fall in ALL of the bins.  By setting this percentage between 0 and 1, MAADS will choose variables that\n   exceed this threshold to determine which variables have data that are well distributed across bins.  The variables\n   with the most distributed values in the bins will drive the selection of the rows in your dataset that give the best\n   distribution - this will be very important for MAADS training.  Usually 0.7 is good.\n\n*distcutoff* : float, required. \n\n-  This is the threshold percentage for the distribution. Specifically, MAADS uses a Lilliefors statistic to determine whether \n   the data are well distributed.  The lower the number the better.  Usually 0.45 is good.\n\n*startcolumn* : int, optional\n\n- This tells MAADS which column to start from.  If you have DATE in the first column, you can tell MAADS to start from 1 (columns are zero-based)\n\nRETURNS: Returns a detailed JSON object and new balaced dataset written to outputfile.\n\n**24. maadstml.viperanomalytrain(vipertoken,host,port,consumefrom,produceto,producepeergroupto,produceridpeergroup,consumeridproduceto,\n                      streamstoanalyse,companyname,consumerid,producerid,flags,hpdehost,viperconfigfile,\n                      enabletls=1,partition=-1,hpdeport=-999,topicid=-999,maintopic='',rollbackoffsets=0,fullpathtotrainingdata='',\n\t\t\t\t\t  brokerhost='',brokerport=9092,delay=1000,timeout=120,microserviceid='')**\n\n**Parameters:**\t\n\n*VIPERTOKEN* : string, required\n\n- A token given to you by VIPER administrator.\n\n*host* : string, required\n\n- Indicates the url where the VIPER instance is located and listening.\n\n*port* : int, required\n\n- Port on which VIPER is listenting.\n\n*consumefrom* : string, required\n\n- Topic to consume from in the Kafka broker\n\n*produceto* : string, required\n\n- Topic to produce results of the prediction to\n\n*topicid* : int, optional\n\n- Topicid represents an id for some entity.  For example, if you have 1000 IoT devices, you can perform anomaly detection/predictions\n  for each device.\n\n*maintopic* : string, optional\n\n- This is the maintopic that contains the subtopic streams.\n\n*rollbackoffsets*: int, optional\n\n- This is the percentage to rollback the streams that you are analysing: streamstoanalyse\n\n*fullpathtotrainingdata*: string, optional\n\n- This is the full path to the training dataset to use to find peer groups.\n\n*producepeergroupto* : string, required\n\n- Topic to produce the peer group for anomaly comparisons \n\n*produceridpeergroup* : string, required\n\n- Producerid for the peer group topic\n\n*consumeridproduceto* : string, required\n\n- Consumer id for the Produceto topic \n\n*streamstoanalyse* : string, required\n\n- Comma separated list of streams to analyse for anomalies\n\n*flags* : string, required\n\n- These are flags that will be used to select the peer group for each stream.  The flags must have the following format:\n  *topic=[topic name],topictype=[numeric or string],threshnumber=[a number between 0 and 10000, i.e. 200],\n  lag=[a number between 1 and 20, i.e. 5],zthresh=[a number between 1 and 5, i.e. 2.5],influence=[a number between 0 and 1 i.e. 0.5]*\n\n  *threshnumber*: decimal number to determine usual behaviour - only for numeric streams, numbers are compared to the centroid number, \n  a standardized distance is taken and all numbers below the thresholdnumeric are deemed as usual i.e. thresholdnumber=200, any value \n  below is close to the centroid  - you need to experiment with this number.\n\n  *lag*: number of lags for the moving mean window, works to smooth the function i.e. lag=5\n\n  *zthresh*: number of standard deviations from moving mean i.e. 3.5\n\n  *influence*: strength in identifying outliers for both stationary and non-stationary data, i.e. influence=0 ignores outliers \n  when recalculating the new threshold, influence=1 is least robust.  Influence should be between (0,1), i.e. influence=0.5\n\n  Flags must be provided for each topic.  Separate multiple flags by ~\n\n*companyname* : string, required\n\n- Your company name\n\n*consumerid*: string, required\n\n- Consumerid associated with the topic to consume from\n\n*producerid*: string, required\n\n- Producerid associated with the topic to produce to\n\n*hpdehost*: string, required\n\n- Address of HPDE \n\n*viperconfigfile* : string, required\n\n- Full path to VIPER.ENV configuration file on server.\n\n*enabletls*: int, optional\n\n- Set to 1 if Kafka broker is SSL/TLS enabled for encrypted traffic, otherwise set to 0 for plaintext.\n\n*partition*: int, optional\n\n- Partition used by kafka to store data. NOTE: Kafka will dynamically store data in partitions.\n  Unless you know for sure the partition, you should use the default of -1 to let VIPER\n  determine where your data is.\n\n*hpdeport*: int, required\n\n- Port number HPDE is listening on \n\n*brokerhost* : string, optional\n\n- Address of Kafka broker - if none is specified it will use broker address in VIPER.ENV file\n\n*brokerport* : int, optional\n\n- Port Kafka is listening on - if none is specified it will use port in the VIPER.ENV file\n\n*delay* : int, optional\n\n- delay parameter to wait for Kafka to respond - in milliseconds.\n\n*timeout* : int, optional\n\n - Number of seconds that VIPER waits when trying to make a connection to HPDE.\n\n*microserviceid* : string, optional\n\n- If you are routing connections to VIPER through a microservice then indicate it here.\n\nRETURNS: Returns a JSON object of the peer groups for all the streams.\n\n\n**25. maadstml.viperanomalypredict(vipertoken,host,port,consumefrom,produceto,consumeinputstream,produceinputstreamtest,produceridinputstreamtest,\n                      streamstoanalyse,consumeridinputstream,companyname,consumerid,producerid,flags,hpdehost,viperconfigfile,\n                      enabletls=1,partition=-1,hpdeport=-999,topicid=-999,maintopic='',rollbackoffsets=0,fullpathtopeergroupdata='',\n\t\t\t\t\t  brokerhost='',brokerport=9092,delay=1000,timeout=120,microserviceid='')**\n\n**Parameters:**\t\n\n*VIPERTOKEN* : string, required\n\n- A token given to you by VIPER administrator.\n\n*host* : string, required\n\n- Indicates the url where the VIPER instance is located and listening.\n\n*port* : int, required\n\n- Port on which VIPER is listenting.\n\n*consumefrom* : string, required\n\n- Topic to consume from in the Kafka broker\n\n*produceto* : string, required\n\n- Topic to produce results of the prediction to\n\n*consumeinputstream* : string, required\n\n- Topic of the input stream to test for anomalies\n\n*produceinputstreamtest* : string, required\n\n- Topic to store the input stream data for analysis\n\n*produceridinputstreamtest* : string, required\n\n- Producer id for the produceinputstreamtest topic \n\n*streamstoanalyse* : string, required\n\n- Comma separated list of streams to analyse for anomalies\n\n*flags* : string, required\n\n- These are flags that will be used to select the peer group for each stream.  The flags must have the following format:\n  *riskscore=[a number between 0 and 1]~complete=[and, or, pvalue i.e. p50 means streams over 50% that have an anomaly]~type=[and,or this will \n  determine what logic to apply to v and sc],topic=[topic name],topictype=[numeric or string],v=[v>some value, v<some value, or valueany],\n  sc=[sc>some number, sc<some number - this is the score for the anomaly test]\n\n  if using strings, the specify flags: type=[and,or],topic=[topic name],topictype=string,stringcontains=[0 or 1 - 1 will do a substring test, \n  0 will equate the strings],v2=[any text you want to test - use | for OR or ^ for AND],sc=[score value, sc<some value, sc>some value]\n\n  *riskscore*: this the riskscore threshold.  A decimal number between 0 and 1, use this as a threshold to flag anomalies.\n\n  *complete* : If using multiple streams, this will test each stream to see if the computed riskscore and perform an AND or OR on each risk value\n  and take an average of the risk scores if using AND.  Otherwise if at least one stream exceeds the riskscore it will return.\n\n  *type*: AND or OR - if using v or sc, this is used to apply the appropriate logic between v and sc.  For example, if type=or, then VIPER \n  will see if a test value is less than or greater than V, OR, standarzided value is less than or greater than sc.  \n\n  *sc*: is a standarized variavice between the peer group value and test value.\n\n  *v1*: is a user chosen value which can be used to test for a particular value.  For example, if you want to flag values less then 0, \n  then choose v<0 and VIPER will flag them as anomolous.\n\n  *v2*: if analysing string streams, v2 can be strings you want to check for. For example, if I want to check for two\n  strings: Failed and Attempt Failed, then set v2=Failed^Attempt Failed, where ^ tells VIPER to perform an AND operation.  \n  If I want either to exist, 2=Failed|Attempt Failed, where | tells VIPER to perform an OR operation.\n\n  *stringcontains* : if using string streams, and you want to see if a particular text value exists and flag it - then \n  if stringcontains=1, VIPER will test for substrings, otherwise it will equate the strings. \n\n\n  Flags must be provided for each topic.  Separate multiple flags by ~\n\n*consumeridinputstream* : string, required\n\n- Consumer id of the input stream topic: consumeinputstream\n\n*companyname* : string, required\n\n- Your company name\n\n*consumerid*: string, required\n\n- Consumerid associated with the topic to consume from\n\n*producerid*: string, required\n\n- Producerid associated with the topic to produce to\n\n*hpdehost*: string, required\n\n- Address of HPDE \n\n*viperconfigfile* : string, required\n\n- Full path to VIPER.ENV configuration file on server.\n\n*enabletls*: int, optional\n\n- Set to 1 if Kafka broker is SSL/TLS enabled for encrypted traffic, otherwise set to 0 for plaintext.\n\n*partition*: int, optional\n\n- Partition used by kafka to store data. NOTE: Kafka will dynamically store data in partitions.\n  Unless you know for sure the partition, you should use the default of -1 to let VIPER\n  determine where your data is.\n\n*hpdeport*: int, required\n\n- Port number HPDE is listening on \n\n*topicid* : int, optional\n\n- Topicid represents an id for some entity.  For example, if you have 1000 IoT devices, you can perform anomaly \n  prediction for each device.\n\n*maintopic* : string, optional\n\n- This is the maintopic that contains the subtopic streams.\n\n*rollbackoffsets*: int, optional\n\n- This is the percentage to rollback the streams that you are analysing: streamstoanalyse\n\n*fullpathtopeergroupdata*: string, optional\n\n- This is the full path to the peer group you found in viperanomalytrain; this will be used for anomaly detection.\n\n*brokerhost* : string, optional\n\n- Address of Kafka broker - if none is specified it will use broker address in VIPER.ENV file\n\n*brokerport* : int, optional\n\n- Port Kafka is listening on - if none is specified it will use port in the VIPER.ENV file\n\n*delay* : int, optional\n\n- delay parameter to wait for Kafka to respond - in milliseconds.\n\n*timeout* : int, optional\n\n - Number of seconds that VIPER waits when trying to make a connection to HPDE.\n\n*microserviceid* : string, optional\n\n- If you are routing connections to VIPER through a microservice then indicate it here.\n\nRETURNS: Returns a JSON object of the peer groups for all the streams.\n\n**26. maads.viperpreprocessproducetotopicstream(VIPERTOKEN,host,port,topic,producerid,offset,maxrows=0,enabletls=0,delay=100,\n                brokerhost='',brokerport=-999,microserviceid='',topicid=-999,streamstojoin='',preprocesslogic='')**\n\n**Parameters:**\t\n\n*VIPERTOKEN* : string, required\n\n- A token given to you by VIPER administrator.\n\n*host* : string, required\n\n- Indicates the url where the VIPER instance is located and listening.\n\n*port* : int, required\n\n- Port on which VIPER is listenting.\n\n*topic* : string, required\n\n- Topics to produce to in the Kafka broker - this is a topic that contains multiple topics, VIPER will consume from each \n   topic and write the aggregated results back to this stream.\n\n*producerid* : string, required\n\n- Producerid of the topic producing to  \n\n*offset* : int\n\n - If 0 will use the stream data from the beginning of the topics, -1 will automatically go to last offset\n\n*maxrows* : int, optional\n\n - If offset=-1, this number will rollback the streams by maxrows amount i.e. rollback=lastoffset-maxrows\n\n*enabletls*: int, optional\n\n- Set to 1 if Kafka broker is SSL/TLS enabled for encrypted traffic, otherwise 0 for plaintext\n\n*delay*: int, optional\n\n- Time in milliseconds before VIPER backsout from reading messages\n\n*brokerhost* : string, optional\n\n- Address of Kafka broker - if none is specified it will use broker address in VIPER.ENV file\n\n*brokerport* : int, optional\n\n- Port Kafka is listening on - if none is specified it will use port in the VIPER.ENV file\n\n*microserviceid* : string, optional\n\n- If you are routing connections to VIPER through a microservice then indicate it here.\n\n*topicid* : int, optional\n\n- This represents the IoT device number or any entity\n\n*streamstojoin* : string, optional\n\n- If you entered topicid, you need to enter the streams you want to pre-process\n\n*preprocesslogic* : string, optional\n\n- Here you need to specify how you want to pre-process the streams.  You can perform the following operations:\n  MAX, MIN, AVG, COUNT, SUM, DIFF.  The order of the operation must match the order of the stream.  If you \n  specified topicid, you can perform TML on the new preprocessed stream append appending: _preprocessed_processlogic\n  For example, if streamstojoin=\"stream1,stream2,streams3\", and preprocesslogic=\"min,max,diff\", the new streams will be:\n  stream1_preprocessed_Min, stream2_preprocessed_Max, stream3_preprocessed_Diff.\n\nRETURNS: Returns preprocessed JSON.\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/smaurice101/transactionalmachinelearning",
    "keywords": "multi-agent, transactional machine learning, data streams, data science, optimization, prescriptive analytics, machine learning, automl,auto-ml,artificial intelligence,predictive analytics,advanced analytics",
    "license": "MIT License",
    "maintainer": "",
    "maintainer_email": "",
    "name": "maadstml",
    "package_url": "https://pypi.org/project/maadstml/",
    "platform": "",
    "project_url": "https://pypi.org/project/maadstml/",
    "project_urls": {
      "Homepage": "https://github.com/smaurice101/transactionalmachinelearning"
    },
    "release_url": "https://pypi.org/project/maadstml/2.31/",
    "requires_dist": [
      "aiohttp (>=3.6.2)",
      "requests (>=2.22.0)",
      "validators (>=0.14.2)",
      "wheel (>=0.33.6)",
      "numpy (>=1.18.1)",
      "pandas (>=0.25.3)",
      "numpy-indexed (>=0.3.5)"
    ],
    "requires_python": "",
    "summary": "Multi-Agent Accelerator for Data Science (MAADS): Transactional Machine Learning",
    "version": "2.31",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17099448,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "99fac5a5c116cd4077423d199937aa2e46301baea22c7c499f6980edc28c0fdd",
        "md5": "5dac91b67e89de77cf9c1b6f52bcbb06",
        "sha256": "7d112f313f4e8618ee52471cedb601d8f1b1cfd0f5f77ef334570f853e90129c"
      },
      "downloads": -1,
      "filename": "maadstml-2.31-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "5dac91b67e89de77cf9c1b6f52bcbb06",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 27216,
      "upload_time": "2022-02-02T01:44:42",
      "upload_time_iso_8601": "2022-02-02T01:44:42.754978Z",
      "url": "https://files.pythonhosted.org/packages/99/fa/c5a5c116cd4077423d199937aa2e46301baea22c7c499f6980edc28c0fdd/maadstml-2.31-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "ed2c9fc71aa5214881e053de8ada31da4e8f56431ce55e717fe6b830619fbe2e",
        "md5": "9836c371ef3386eca16eb4fb37233e12",
        "sha256": "7e40d3cfa4a62494ef63e480e618cf9efec574039f89a44538c7838a0c8382d8"
      },
      "downloads": -1,
      "filename": "maadstml-2.31.tar.gz",
      "has_sig": false,
      "md5_digest": "9836c371ef3386eca16eb4fb37233e12",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 44811,
      "upload_time": "2022-02-02T01:44:44",
      "upload_time_iso_8601": "2022-02-02T01:44:44.797069Z",
      "url": "https://files.pythonhosted.org/packages/ed/2c/9fc71aa5214881e053de8ada31da4e8f56431ce55e717fe6b830619fbe2e/maadstml-2.31.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}