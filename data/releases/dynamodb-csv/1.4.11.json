{
  "info": {
    "author": "danishi",
    "author_email": "dns2developer@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.11",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Topic :: Utilities"
    ],
    "description": "# DynamoDB CSV utility\n\n[![ci](https://github.com/danishi/DynamoDB-CSV/actions/workflows/ci.yaml/badge.svg?branch=master)](https://github.com/danishi/DynamoDBImportCSV/actions/workflows/ci.yaml)\n[![codecov](https://codecov.io/gh/danishi/dynamodb-csv/branch/master/graph/badge.svg?token=KRA27MJN42)](https://codecov.io/gh/danishi/dynamodb-csv)\n![MIT](https://img.shields.io/github/license/danishi/DynamoDB-CSV)\n![Supported Python versions](https://img.shields.io/pypi/pyversions/dynamodb-csv.svg?color=%2334D058)\n[![Linux](https://svgshare.com/i/Zhy.svg)](https://svgshare.com/i/Zhy.svg)\n[![macOS](https://svgshare.com/i/ZjP.svg)](https://svgshare.com/i/ZjP.svg)\n[![Windows](https://svgshare.com/i/ZhY.svg)](https://svgshare.com/i/ZhY.svg)\n[![PyPI](https://badge.fury.io/py/dynamodb-csv.svg)](https://badge.fury.io/py/dynamodb-csv)\n[![Downloads](https://pepy.tech/badge/dynamodb-csv)](https://pepy.tech/project/dynamodb-csv)\n[![Downloads week](https://pepy.tech/badge/dynamodb-csv/week)](https://pepy.tech/project/dynamodb-csv)\n[![Downloads month](https://pepy.tech/badge/dynamodb-csv/month)](https://pepy.tech/project/dynamodb-csv)\n[![Docker Pulls](https://img.shields.io/docker/pulls/danishi/dynamodb-csv)](https://hub.docker.com/r/danishi/dynamodb-csv)\n\n[![\"Buy Me A Coffee\"](https://www.buymeacoffee.com/assets/img/custom_images/orange_img.png)](https://www.buymeacoffee.com/danishi)\n\n![DynamoDBCSV](https://user-images.githubusercontent.com/56535085/159007555-e72d1c26-eb44-46ca-bc38-c752164995bf.png)\n\nA utility that allows CSV import / export to DynamoDB on the command line\n\nGive a ‚≠êÔ∏è if you like this tool!\n\n## Introduction\n\nI made this command because I didn't have any tools to satisfy my modest desire to make it easy to import CSV files into DynamoDB.\nWritten in a simple Python script, it's easy to parse and modify.\n\nIt works for me.\n\n## Getting started üöÄ\n\n### Install\n\n```shell\n$ python -m venv venv\n$ . venv/bin/activate\n$ pip install dynamodb-csv\n$ dynamodb-csv -h\nusage: dynamodb-csv [-h] [-v] [-i] [-e] [--truncate] -t TABLE [-idx INDEX] [-f FILE] [-o OUTPUT] [--ignore] [--profile PROFILE]\n\nImport CSV file into DynamoDB table utilities\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -v, --version         show version\n  -i, --imp             mode import\n  -e, --exp             mode export\n  --truncate            mode truncate\n  -t TABLE, --table TABLE\n                        DynamoDB table name\n  -idx INDEX, --index INDEX\n                        DynamoDB index name\n  -f FILE, --file FILE  UTF-8 CSV file path required import mode\n  -o OUTPUT, --output OUTPUT\n                        output file path required export mode\n  --ignore              ignore import error\n  --profile PROFILE     using AWS profile\n```\n\n### Install for developer\n\n```shell\n$ python -m venv venv\n$ . venv/bin/activate\n$ python setup.py install\n$ dynamodb-csv -h\n```\n\nOr\n\n```shell\n$ python -m venv venv\n$ . venv/bin/activate\n$ pip install -r requirements-dev.txt\n$ export PYTHONPATH=`pwd`\n$ python app/main.py -h\n```\n\nFor Windows\n\n```shell\n> python -m venv venv\n> venv\\Scripts\\activate\n> pip install -r requirements-dev.txt\n> set PYTHONPATH=%cd%\n> python app/main.py -h\n```\n\nOr you can use devcontainer.\n\n### [Use Docker image](https://hub.docker.com/r/danishi/dynamodb-csv)\n\n```shell\n$ docker run --rm -v ${PWD}/:/local danishi/dynamodb-csv:tagname -i -t my_table -f sample.csv\n```\n\nFor Windows\n\n```shell\n> docker run --rm -v %cd%/:/local danishi/dynamodb-csv:tagname -i -t my_table -f sample.csv\n```\n\nOr [GitHub Packages](https://github.com/danishi/dynamodb-csv/pkgs/container/dynamodb-csv)\n\n### Create your config.ini file on current directory\n\n```ini\n[AWS]\nAWS_ACCESS_KEY_ID=your_access_key\nAWS_SECRET_ACCESS_KEY=your_secret_key\nREGION=your_dynamodb_table_region\n# Option\n#ENDPOINT_URL=http://dynamodb-local:8000\n```\n\nNot required if AWS profile is specified as a parameter.\n\n### Create your CSV and CSV spec file\n\nPrepare a UTF-8 CSV file of the format you want to import into your DynamoDB table and a file that defines that format.\n\n#### For example\n\nPlease refer to this writing method.\n\n[sample.csv](sample.csv)\n\n```csv\nStringPK,NumberSK,DecimalValue,BooleanValue,NullValue,JsonValue,StringListValues,DecimalListValues\nfoo,1,1.23,TRUE,,\"[{\"\"string\"\" : \"\"value\"\"},{\"\"number\"\" : 100}]\",foo bar baz,10 10.1 20\nfoo,2,0.001,,,\"[{\"\"boolean\"\" : true}]\",„É™„É≥„Ç¥ „Éê„Éä„Éä „Çπ„Ç§„Ç´,10 10.1 20\nfoo,3,1,,,\"[{\"\"boolean\"\" : false}]\",,\n```\n\n[sample.csv.spec](sample.csv.spec)\n\n```ini\n# sample.csv data format specification\n\n# String : S\n# Integer : I\n# Decimal : D\n# Boolean : B (blank false)\n# Json : J\n# StringList : SL\n# StringSet : SS\n# DecimalList : DL\n# DecimalSet : DS\n\n[CSV_SPEC]\nStringPK=S\nNumberSK=I\nDecimalValue=D\nBooleanValue=B\nNullValue=S\nJsonValue=J\nStringListValues=SL\nStringSetValues=SS\nDecimalListValues=DL\nDecimalSetValues=DS\n```\n\n### Create DynamoDB table\n\nYou need to have created a DynamoDB table that meets your specifications.\n\n```shell\n$ aws dynamodb create-table --cli-input-json file://my_table.json --region ap-northeast-1\n$ aws dynamodb describe-table --table-name my_table\n{\n    \"Table\": {\n        \"AttributeDefinitions\": [\n            {\n                \"AttributeName\": \"NumberSK\",\n                \"AttributeType\": \"N\"\n            },\n            {\n                \"AttributeName\": \"StringPK\",\n                \"AttributeType\": \"S\"\n            }\n        ],\n        \"TableName\": \"my_table\",\n        \"KeySchema\": [\n            {\n                \"AttributeName\": \"StringPK\",\n                \"KeyType\": \"HASH\"\n            },\n            {\n                \"AttributeName\": \"NumberSK\",\n                \"KeyType\": \"RANGE\"\n            }\n        ],\n        \"TableStatus\": \"ACTIVE\",\n        \"CreationDateTime\": \"2022-06-26T21:19:21.767000+09:00\",\n        \"ProvisionedThroughput\": {\n            \"NumberOfDecreasesToday\": 0,\n            \"ReadCapacityUnits\": 5,\n            \"WriteCapacityUnits\": 5\n        },\n        \"TableSizeBytes\": 0,\n        \"ItemCount\": 0,\n        \"TableArn\": \"arn:aws:dynamodb:ap-northeast-1:XXXXXXXXXXX:table/my_table\",\n        \"TableId\": \"XXXXXXXX-925b-4cb1-8e3a-604158118c3f\",\n        \"GlobalSecondaryIndexes\": [\n            {\n                \"IndexName\": \"NumberSK-index\",\n                \"KeySchema\": [\n                    {\n                        \"AttributeName\": \"NumberSK\",\n                        \"KeyType\": \"HASH\"\n                    }\n                ],\n                \"Projection\": {\n                    \"ProjectionType\": \"INCLUDE\",\n                    \"NonKeyAttributes\": [\n                        \"DecimalValue\",\n                        \"JsonValue\"\n                    ]\n                },\n                \"IndexStatus\": \"ACTIVE\",\n                \"ProvisionedThroughput\": {\n                    \"NumberOfDecreasesToday\": 0,\n                    \"ReadCapacityUnits\": 5,\n                    \"WriteCapacityUnits\": 5\n                },\n                \"IndexSizeBytes\": 0,\n                \"ItemCount\": 0,\n                \"IndexArn\": \"arn:aws:dynamodb:ap-northeast-1:XXXXXXXXXXX:table/my_table/index/NumberSK-index\"\n            }\n        ]\n    }\n}\n```\n\n### CSV import into Table\n\nThis command requires a CSV spec file in the same directory.\n\n```shell\n$ dynamodb-csv -i -t my_table -f sample.csv\nplease wait my_table importing sample.csv\n300it [00:00, 19983.03it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:07<00:00, 40.97it/s]\nmy_table csv imported 300 items\n```\n\nIt is processed at high speed by batch write.\n\n#### Ignore option\n\nIf there is an error such as a key schema mismatch, you can give the option to ignore the CSV record.\n\n```shell\n$ dynamodb-csv -i -t my_table -f sample.csv --ignore\nplease wait my_table importing sample.csv\n300it [00:00, 19983.03it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:07<00:00, 40.97it/s]\nmy_table csv imported 299 items and 1 error items\n```\n\nNo batch write is done when this option is used.\n\n#### Import options\nBy default, if CSV has an empty value, it will be set to empty.  \nThere are options to convert this to Null or not to set the attribute itself.\n\n```ini\n[IMPORT_OPTION]\nConvertBlankToNullAttrs=NullValue,JsonValue\nConvertBlankToDropAttrs=DecimalValue\n```\n\n### Export table to CSV\n\nYou will also need to expand the same data to multiple tables.  \nTherefore, data can be exported.  \nAs with import, you need a CSV spec file.\n\n```shell\n$ dynamodb-csv -e -t my_table -o sample_exp.csv\nplease wait my_table exporting sample_exp.csv\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 16666.77it/s]\nmy_table csv exported 300 items\n```\n\n#### Use index\n```shell\n$ dynamodb-csv -e -t my_table -idx NumberSK-index -o sample_gsi_exp.csv\n```\n\n#### Use Query\n```shell\n$ dynamodb-csv -e -t my_table -idx NumberSK-index -o sample_query_exp.csv\n```\n\n```ini\n# sample_query_exp.csv data format specification\n\n# Integer : I\n# String : S\n# Decimal : D\n# Json : J\n\n[QUERY_OPTION]\nPKAttribute=NumberSK\nPKAttributeValue=1\nPKAttributeType=I\n\n[CSV_SPEC]\nNumberSK=I\nStringPK=S\nDecimalValue=D\nJsonValue=J\n```\n\n##### Query options\n* `PKAttribute` : Partition key attribute name\n* `PKAttributeValue` : Partition key attribute query value\n* `PKAttributeType` : Partition key attribute data type\n* `SKAttribute` : Sort key attribute name\n* `SKAttributeValues` : Sort key attribute query value or values\n  * ex. `foo` or `foo,bar`\n* `SKAttributeType` : Sort key attribute data type\n* `SKAttributeExpression` : Sort key attribute query expression [ex.](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/customizations/dynamodb.html#dynamodb-conditions)\n  * `begins_with` `between` `eq` `gt` `gte` `lt` `lte`\n\n```shell\n$ dynamodb-csv -e -t my_table -o sample_query_exp2.csv\n```\n\n```ini\n[QUERY_OPTION]\nPKAttribute=StringPK\nPKAttributeValue=bar\nPKAttributeType=S\nSKAttribute=NumberSK\nSKAttributeValues=50,100\nSKAttributeType=I\nSKAttributeExpression=between\n```\n\n### Table truncate\n\nAlso, since you may want to erase unnecessary data during the import experiment, we have prepared a command to discard it.\n\n```shell\n$ dynamodb-csv --truncate -t my_table\nmy_table scan 300 items\nplease wait my_table truncating\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:07<00:00, 40.95it/s]\nmy_table truncated\n```\n\n## License\n\nSee [LICENSE](LICENSE)\n\n## Special Thanks\n\n### Code contributors ü§ù\n\n<a href=\"https://github.com/danishi/dynamodb-csv/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=danishi/dynamodb-csv\" />\n</a>\n\n## Appendix\n\n### User guide\n- [User guide (for japanese)](https://danishi.github.io/dynamodb-csv/)\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/danishi/dynamodb-csv",
    "keywords": "AWS,DynamoDB,CSV",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "dynamodb-csv",
    "package_url": "https://pypi.org/project/dynamodb-csv/",
    "platform": null,
    "project_url": "https://pypi.org/project/dynamodb-csv/",
    "project_urls": {
      "Homepage": "https://github.com/danishi/dynamodb-csv"
    },
    "release_url": "https://pypi.org/project/dynamodb-csv/1.4.11/",
    "requires_dist": [
      "boto3",
      "configparser",
      "tqdm"
    ],
    "requires_python": ">=3.7",
    "summary": "A utility that allows CSV import / export to DynamoDB on the command line",
    "version": "1.4.11",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16944174,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "0313e703859decf76e314456dc36328aebcd77142d7161471375906b0c07cae9",
        "md5": "9b563bd79b5bedbdf2fb670c22f41384",
        "sha256": "b13cd08731b7d0776a168bfff18f429d0a9cac91ff1d6e30a7d95c96d1fd47d0"
      },
      "downloads": -1,
      "filename": "dynamodb_csv-1.4.11-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "9b563bd79b5bedbdf2fb670c22f41384",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 12045,
      "upload_time": "2023-02-07T00:41:18",
      "upload_time_iso_8601": "2023-02-07T00:41:18.710765Z",
      "url": "https://files.pythonhosted.org/packages/03/13/e703859decf76e314456dc36328aebcd77142d7161471375906b0c07cae9/dynamodb_csv-1.4.11-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "1a251e404c07c1f8e843facd8f997e66f14b69a86ec54ac508e7ff88bfb2fae7",
        "md5": "8d30b877ae494bae8bda9dfaf17c0bc4",
        "sha256": "7038cb57443854af5b43c431ab439f11df992abda5e8b15e81069c2bc47bcc94"
      },
      "downloads": -1,
      "filename": "dynamodb-csv-1.4.11.tar.gz",
      "has_sig": false,
      "md5_digest": "8d30b877ae494bae8bda9dfaf17c0bc4",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 13484,
      "upload_time": "2023-02-07T00:41:20",
      "upload_time_iso_8601": "2023-02-07T00:41:20.972171Z",
      "url": "https://files.pythonhosted.org/packages/1a/25/1e404c07c1f8e843facd8f997e66f14b69a86ec54ac508e7ff88bfb2fae7/dynamodb-csv-1.4.11.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}