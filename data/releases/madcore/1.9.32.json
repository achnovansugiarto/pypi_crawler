{
  "info": {
    "author": "Peter Styk",
    "author_email": "humans@madcore.ai",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Environment :: Console",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 2.7"
    ],
    "description": "================\nMadcore CLI\n================\n**************************************************************\nDeep Learning & Machine Intelligence Infrastructure Controller\n**************************************************************\n\n.. image:: https://travis-ci.org/madcore-ai/cli.svg?branch=master\n\nWhat is Madcore?\n------------------\n\nMadcore is a CLI tool for deployment and auto-configuration of data mining and analytics microservices. It is a Kubernetes-based unmodified KOPS/Minikube installation manager. However, single point of truth is preserved as a unified yaml file called \"clusterfile\". Clusterfile controls generic aspects of provisioning, deployment, scale and configuration. All KOPS and Kubernetes templates are then populated from input clusterfile.\n\n\nInstall\n-------\n\nMac & Linux install form terminal.\n\n.. code-block:: bash\n\n   pip install madcore\n\n\nDevelopment Install\n-------------------\n\nIf you want to contribute to MadcoreCLI, add new k8s modules or create your own clusterfiles you should clone the repo, create python virtual environment (make sure package is installed) to isolate installations from the rest of the system, activate the virtual env, perform requirements install, and create a symlink so you can call MadcoreCLI from any folder on the system. For below example we assume both cloned repo and new virtual environment will end up in ~/git folder in your user space and full path is /Users/peter/git  Obviously you can adjust this to match your system.\n\n.. code-block:: bash\n\n   mkdir ~/git && cd ~/git\n   virtualenv venv_cli && source venv_cli/bin/activate\n   git clone git@github.com:madcore-ai/cli.git\n   pip install -r ~git/cli/requirements.txt\n   ln -s /Users/peter/git/cli/bin/madcore.sh /usr/local/bin/madcore\n\n\n\nMinikube Environment Prerequisites\n----------------------------------\n\n * Virtual Box\n * Minikube 1.9\n * Local PC 16GB of Ram (minikube is set at 8GB by default)\n\nAWS Environment Prerequisites\n-----------------------------\n\n * VPC in AWS (you will need id)\n * Internet Gateway attached to VPC\n * S3 Storage bucket for KOPS settings\n\n\nProvision Locally on Minikube\n-----------------------------\n\nMinikube is great but obviously limited by specs of your local machine. You can comment out elements of minikube.yaml to suit your needs. Then when you're ready start provisioning. When you're done, run second command to map *minikube.local* hostname to your new setup.\n\n.. code-block:: bash\n\n   madcore --provision minikube.yaml\n   madcore --mini-hostname\n\n\nProvision in AWS\n----------------\n\nCurrently Madcore is tested on Mac and Linux only. We are working on exposing clusterfiles and templates in a better way. By default they install with the python project files location similar to this `lib/python2.7/site-packages/madcore`\n\n.. code-block:: bash\n\n   madcore --provision demo.yaml\n\n**AWS POST-INSTALL:**\n\n- Create <yourdomain.com> A record and point it to ingress IP (ingress horizontal scaling above 500MB/s is described in another doc)\n- Create wildcard CNAME *.<yourdomain.com> and point it to your above hostname (will automate this eventually)\n- Create Security Group in your VPC and whitelist your access IP's, attach it to ingress node (will automate this eventually)\n\n\nMadcore Data Mining & Deep Learning Ecosystem\n---------------------------------------------\n\nFunctionality is grouped into instance groups (physically) and into namespaces (logically). Each software deployed here belongs to their respective owners. We do not interfere in containers but make sure that we find best containers for deployment in Kubernetes.\n\nGoal of Madcore is to abstract deployment and configuration of data processing elements and have it available in working state out-of-the-box. This way anyone can start work on their actual problem and not spend time on deployment and configuration of common toolsets.\n\n.. code-block:: text\n\n   usage: ./madcore.py [-h]\n                       [-p CLUSTERFILE | -c CLUSTERFILE | --destroy | --kops-update | --kops-validate | --kubectl-use-context | --mini-hostname | --get-attr ATTR | --install-core | --install-elk | --install-neo4j | --install-kafka | --install-flink]\n\n   Madcore CLI 1.9.15 - (c) 2016-2018 Madcore Ltd <https://madcore.ai>\n\n   optional arguments:\n     -h, --help            show this help message and exit\n     -p CLUSTERFILE, --provision CLUSTERFILE\n                           provision based on <cllusterfile>\n     -c CLUSTERFILE, --clusterfile CLUSTERFILE\n                           set default clusterfile to input <clusterfile>\n     --destroy             destroy infrastructure\n     --kops-update         kops update\n     --kops-validate       kopds validate\n     --kubectl-use-context\n                           kubectl use context\n     --mini-hostname       set minikube hostname (will sudo)\n     --get-attr ATTR       get atribute\n     --install-core        install core of Madcore\n     --install-elk         install elk\n     --install-neo4j       install neo4j\n     --install-kafka       install apache kafka\n     --install-flink       install apache flink\n\n\nDeploy Core\n-----------\n\nInstallation of core elements is a single command. Filenames in range of 100-200. You can comment out any of those installs. By commenting corresponding lines in your aws clusterfile. Registry and metrics elements are optional. You probably want to leave dashboard and ingress setup as everything else maps to it.\n\n.. code-block:: bash\n\n   madcore --install-core\n\n\n.. image:: https://asciinema.org/a/179330.png\n   :target: https://asciinema.org/a/179330\n\n\n================  =====\nCore Stack        Description\n================  =====\ndashboard         Kubernetes Dashboard\nnfs               NFS 4.1 for utilized for Kubernetes persistent volume claims (StatefulSets)\nregistry2         (optional) docker registry v2\ninfluxdb          InfluxDB for Heapster data\nheapster          Kubernetes metrics collector\ngrafana           Grafana Dashboard pointed at InfluxDB for kube metrics\nhaproxy-ingress   HAProxy ingress (route external traffic and map to kube services)\ningress-default   default container reporting 404 when hitting anything but mapped endpoints\ningress echo      echo container to test ingress alive\n================  =====\n\n* DASHBOARD - https://api.<yourdomain.com>/api/v1/namespaces/kube-system/services/kubernetes-dashboard/proxy/ or type *minikube dahsboard*\n* GRAFANA - http://grafana.<yourdomain.com> or http://grafana.minikube.local\n\nDeploy neo4j\n------------\n\nNeo4j and Dashboard is in the template file space of 9220-9229. Deploy using command below. Few second later you will have a working dashboard and single pod engine configuration ready to start your tests. Thi deployment is installed onto standard `nodes` instancegroup. This deployment lives its own `neo4j` namespace. It's easy to remove it when you don't require it anymore. It using standard `neo4j:3.1.4-enterprise` containers from docker hub maintainer by neo4j team. It is exposed through ingress and mapped through its own subodmain `neo4j.<yourdomain.com>`\n\n.. code-block:: bash\n\n   madcore --install-neo4j\n\n================  =====\nNeo4J Stack       Description\n================  =====\nengine            Enterprise: neo4j:3.1.4-enterprise (subject to EULA)\nui                Dashboard\n================  =====\n\n* Neo4j Browser - http://neo4j.<yourdomain.com> or http://neo4j.minikube.local\n\n\nDeploy kafka\n------------\n\nKafka and Dashboard is in the template file space of 9240-9249. Deploy using command below. Few second later you will have a working dashboard and single pod engine configuration ready to start your tests. Thi deployment is installed onto standard `nodes` instancegroup. This deployment lives its own `kafka` namespace. It's easy to remove it when you don't require it anymore. It is exposed through ingress and mapped through its own subodmain `kafka.<yourdomain.com>` for Yahoo kafka dashboard and `kafka.<yourdomain.com>/rest` for Mailgun Pixy rest ui (grpc is listening internally but not exposed outside)\n\n.. code-block:: bash\n\n   madcore --install-kafka\n\n\n================  =====\nKafka Stack       Containers\n================  =====\nzookeeper         solsson/kafka:1.0.1\nkafka             solsson/kafka:1.0.1\nkafka-manager     solsson/kafka-manager\nkafka-pixy        mailgun/kafka-pixy\n================  =====\n\n* Kafka Manager - http://kafka.<yourdomain.com> or http://kafka.minikube.local\n* Kafka Rest Proxy - http://rest.kafka.<yourdomain.com> or http://rest.kafka.minikube.local\n\n\nDeploy Elasticsearch / FluentD / Kibana\n---------------------------------------\n\nFamous trio optimized for Kubernetes. Elasticsearch exposed through ingress as well as Kibana. Internally FluentD DaemonSets are deployed to ALL nodes and collect all logs from pods stdout along with kubernetes logs and aggregate in ElasticSearch. Deploy this when you have a need. There is a dedicated instance group for ELK so it doesn't collide with any of your other applications.\n\n.. code-block:: bash\n\n   madcore --install-elk\n\n================  =====\nKafka Stack       Containers\n================  =====\nelasticsearch     docker.elastic.co/elasticsearch/elasticsearch-oss:6.0.0\nfluentd           fluent/fluentd-kubernetes-daemonset:v0.12.33-elasticsearch\nkibana            docker.elastic.co/kibana/kibana-oss:6.0.0\n================  =====\n\n* Elasticsearch - http://elasticsearch.<yourdomain.com> or http://elasticsearch.minikube.local\n* Kibana - http://kibana.<yourdomain.com> or http://kibana.minikube.local\n\n\nDeploy Apache Flink Cluster\n---------------------------\n\nApache Flink is an open source stream processing framework developed by the Apache Software Foundation. The core of Apache Flink is a distributed streaming dataflow engine written in Java and Scala\n\n.. code-block:: bash\n\n   madcore --install-flink\n\n================  =====\nFlink Stack       Description\n================  =====\njobmanager        Flink Job Manager\njobmanager-ui     Flink Web Ui\ntaskmanager       Flink Task Manager (Horizontally Scaling)\n================  =====\n\n* Flink UI - http://flink.<yourdomain.com> or http://fink.minikube.local\n\nChat with us on Gitter\n----------------------\n\nIf you want to try Madcore, make sure you join us on Gitter. We are now focused on building Machine Learning and Ai plugins as well as building Ingress listeners for social media and queueing mechanisms in Spark and Kafka.  All based on Kubernetes. Chat with us now: https://gitter.im/madcore-ai/core\n\nMailing List\n------------\n\nVisit https://madcore.ai to sign up for weekly newsletter on Machine Learning and AI simulations that are now possible with Madcore\n\nCredits\n-------\n\nWe will be adding a formal Credits file into this project. For now just want to make clear that all registered brands/products remain property of their respective owners.\n\nLicense\n-------\n\nMadcore Project is distributed on MIT License (c) 2016-2017 Madcore Ltd (London, UK) https://madcore.ai\n",
    "description_content_type": "",
    "docs_url": null,
    "download_url": "https://github.com/madcore-ai/cli/tarball/master",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/madcore-ai/cli",
    "keywords": "aws",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "madcore",
    "package_url": "https://pypi.org/project/madcore/",
    "platform": "Any",
    "project_url": "https://pypi.org/project/madcore/",
    "project_urls": {
      "Download": "https://github.com/madcore-ai/cli/tarball/master",
      "Homepage": "https://github.com/madcore-ai/cli"
    },
    "release_url": "https://pypi.org/project/madcore/1.9.32/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "Madcore Core CLI - Deep Learning & Machine Intelligence Infrastructure Controller",
    "version": "1.9.32",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 4208916,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "4c2823bf8ead03e554f4b847f949751702c4aae0438e49fb31e10efeaf760d7e",
        "md5": "293e1b5561746251bea155cfdaa9d0df",
        "sha256": "4ddb89c1b822752315a851eba471f50f026b44e8a1ff57f3b7c94ca33a427ed2"
      },
      "downloads": -1,
      "filename": "madcore-1.9.32-py2.py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "293e1b5561746251bea155cfdaa9d0df",
      "packagetype": "bdist_wheel",
      "python_version": "2.7",
      "requires_python": null,
      "size": 70769,
      "upload_time": "2018-05-09T03:29:13",
      "upload_time_iso_8601": "2018-05-09T03:29:13.308460Z",
      "url": "https://files.pythonhosted.org/packages/4c/28/23bf8ead03e554f4b847f949751702c4aae0438e49fb31e10efeaf760d7e/madcore-1.9.32-py2.py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}