{
  "info": {
    "author": "Mario Orlandi",
    "author_email": "morlandi@brainstorm.it",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Framework :: Django",
      "Framework :: Django :: 1.10",
      "Framework :: Django :: 2.0",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: BSD License",
      "Natural Language :: English",
      "Operating System :: OS Independent",
      "Programming Language :: Python",
      "Programming Language :: Python :: 2",
      "Programming Language :: Python :: 2.7",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7"
    ],
    "description": "=============================\nDjango Task\n=============================\n\n.. image:: https://badge.fury.io/py/django-task.svg\n    :target: https://badge.fury.io/py/django-task\n\n.. image:: https://travis-ci.org/morlandi/django-task.svg?branch=master\n    :target: https://travis-ci.org/morlandi/django-task\n\n.. image:: https://codecov.io/gh/morlandi/django-task/branch/master/graph/badge.svg\n    :target: https://codecov.io/gh/morlandi/django-task\n\nA Django app to run new background tasks from either admin or cron, and inspect task history from admin; based on django-rq\n\nQuickstart\n----------\n\nInstall Django Task::\n\n    pip install django-task\n\nAdd it to your `INSTALLED_APPS`:\n\n.. code-block:: python\n\n    INSTALLED_APPS = (\n        ...\n        'django_rq',\n        'django_task',\n        ...\n    )\n\nAdd Django Task's URL patterns:\n\n.. code-block:: python\n\n    urlpatterns = [\n        ...\n        url(r'^django_task/', include('django_task.urls', namespace='django_task')),\n        ...\n    ]\n\nFeatures\n--------\n\n**Purposes**\n\n- create async tasks either programmatically or from admin\n- monitor async tasks from admin\n- log all tasks in the database for later inspection\n- optionally save task-specific logs in a TextField and/or in a FileField\n\n**Details**\n\n1. each specific job is described my a Model derived from models.Task, which\n   is responsible for:\n\n    - selecting the name for the consumer queue among available queues\n    - collecting and saving all parameters required by the associated job\n    - running the specific job asyncronously\n\n2. a new job can be run either:\n\n    - creating a Task from the Django admin\n    - creating a Task from code, then calling Task.run()\n\n3. job execution workflow:\n\n    - job execution is triggered by task.run(is_async)\n    - job will receive the task.id, and retrieve paramerts from it (task.retrieve_params_as_dict())\n    - on start, job will update task status to 'STARTED' and save job.id for reference\n    - during execution, the job can update the progress indicator\n    - on completion, task status is finally updated to either 'SUCCESS' or 'FAILURE'\n    - See example.jobs.count_beans for an example\n\n\nSupport Job class\n-----------------\n\nStarting from version 0.3.0, some conveniences have been added:\n\n- The @job decorator for job functions is no more required, as Task.run() now\n  uses queue.enqueue() instead of jobfunc.delay(), and retrieves the queue\n  name directly from the Task itself\n\n- each Task can set it's own TASK_TIMEOUT value (expressed in seconds),\n  that when provided overrides the default queue timeout\n\n- a new Job class has been provided to share suggested common logic before and\n  after jobfunc execution\n\n.. code :: python\n\n    class Job(object):\n\n        @classmethod\n        def run(job_class, task_class, task_id):\n            job_trace('job.run() enter')\n            task = None\n            result = 'SUCCESS'\n            failure_reason = ''\n\n            try:\n\n                # this raises a \"Could not resolve a Redis connection\" exception in sync mode\n                #job = get_current_job()\n                job = get_current_job(connection=redis.Redis.from_url(REDIS_URL))\n\n                # Retrieve task obj and set as Started\n                task = task_class.get_task_from_id(task_id)\n                task.set_status(status='STARTED', job_id=job.get_id())\n\n                # Execute job passing by task\n                job_class.execute(job, task)\n\n            except Exception as e:\n                job_trace('ERROR: %s' % str(e))\n                job_trace(traceback.format_exc())\n\n                if task:\n                    task.log(logging.ERROR, str(e))\n                    task.log(logging.ERROR, traceback.format_exc())\n                result = 'FAILURE'\n                failure_reason = str(e)\n\n            finally:\n                if task:\n                    task.set_status(status=result, failure_reason=failure_reason)\n                try:\n                    job_class.on_complete(job, task)\n                except Exception as e:\n                    job_trace('NESTED ERROR: Job.on_completed() raises error \"%s\"' % str(e))\n                    job_trace(traceback.format_exc())\n            job_trace('job.run() leave')\n\n        @staticmethod\n        def on_complete(job, task):\n            pass\n\n        @staticmethod\n        def execute(job, task):\n            pass\n\nso you can now replace the jobfunc with a simplyfied Job-derived class;\nfor example:\n\n.. code :: python\n\n    class CountBeansJob(Job):\n\n        @staticmethod\n        def execute(job, task):\n            params = task.retrieve_params_as_dict()\n            num_beans = params['num_beans']\n            for i in range(0, num_beans):\n                time.sleep(0.01)\n                task.set_progress((i + 1) * 100 / num_beans, step=10)\n\nYou might also override `on_complete()` to execute cleanup actions after job completion.\n\n\n**Execute**\n\nRun consumer:\n\n.. code:: bash\n\n    python manage.py runserver\n\n\nRun worker(s):\n\n.. code:: bash\n\n    python manage.py rqworker low high default\n    python manage.py rqworker low high default\n    ...\n\n**Sample Task**\n\n.. code:: python\n\n    from django.db import models\n    from django.conf import settings\n    from django_task.models import Task\n\n\n    class SendEmailTask(Task):\n\n        sender = models.CharField(max_length=256, null=False, blank=False)\n        recipients = models.TextField(null=False, blank=False,\n            help_text='put addresses in separate rows')\n        subject = models.CharField(max_length=256, null=False, blank=False)\n        message = models.TextField(null=False, blank=True)\n\n        TASK_QUEUE = settings.QUEUE_LOW\n        TASK_TIMEOUT = 60\n        DEFAULT_VERBOSITY = 2\n\n        @staticmethod\n        def get_jobfunc():\n            #from .jobs import send_email\n            #return send_email\n            from .jobs import SendEmailJob\n            return SendEmailJob\n\nYou can change the `verbosity` dinamically by overridding the verbosity property:\n\n.. code:: python\n\n    class SendEmailTask(Task):\n\n        @property\n        def verbosity(self):\n            #return self.DEFAULT_VERBOSITY\n            return 1  # either 0, 1 or 2\n\n**Sample Job**\n\n.. code:: python\n\n    from __future__ import print_function\n    import redis\n    import logging\n    import traceback\n    from django.conf import settings\n    from .models import SendEmailTask\n    from django_task.job import Job\n\n\n    class SendEmailJob(Job):\n\n        @staticmethod\n        def execute(job, task):\n            params = task.retrieve_params_as_dict()\n            recipient_list = params['recipients'].split()\n            sender = params['sender'].strip()\n            subject = params['subject'].strip()\n            message = params['message']\n            from django.core.mail import send_mail\n            send_mail(subject, message, sender, recipient_list)\n\n\n    # from __future__ import print_function\n    # import redis\n    # import logging\n    # import traceback\n    # from django.conf import settings\n    # from .models import SendEmailTask\n    # from rq import get_current_job\n    # from django_rq import job\n\n    # @job(SendEmailTask.TASK_QUEUE)\n    # def send_email(task_id):\n\n    #     task = None\n    #     result = 'SUCCESS'\n    #     failure_reason = ''\n\n    #     try:\n\n    #         # this raises a \"Could not resolve a Redis connection\" exception in sync mode\n    #         #job = get_current_job()\n    #         job = get_current_job(connection=redis.Redis.from_url(settings.REDIS_URL))\n\n    #         #task = SendEmailTask.objects.get(id=task_id)\n    #         task = SendEmailTask.get_task_from_id(task_id)\n    #         task.set_status(status='STARTED', job_id=job.get_id())\n\n    #         params = task.retrieve_params_as_dict()\n\n    #         recipient_list = params['recipients'].split()\n    #         sender = params['sender'].strip()\n    #         subject = params['subject'].strip()\n    #         message = params['message']\n\n    #         from django.core.mail import send_mail\n    #         send_mail(subject, message, sender, recipient_list)\n\n    #     except Exception as e:\n    #         if task:\n    #             task.log(logging.ERROR, str(e))\n    #             task.log(logging.ERROR, traceback.format_exc())\n    #         result = 'FAILURE'\n    #         failure_reason = str(e)\n\n    #     finally:\n    #         if task:\n    #             task.set_status(status=result, failure_reason=failure_reason)\n\n**Sample management command**\n\n.. code:: python\n\n    from django_task.task_command import TaskCommand\n\n    class Command(TaskCommand):\n\n        def add_arguments(self, parser):\n            super(Command, self).add_arguments(parser)\n            parser.add_argument('sender')\n            parser.add_argument('subject')\n            parser.add_argument('message')\n            parser.add_argument('-r', '--recipients', nargs='*')\n\n        def handle(self, *args, **options):\n            from tasks.models import SendEmailTask\n\n            # transform the list of recipents into text\n            # (one line for each recipient)\n            options['recipients'] = '\\n'.join(options['recipients']) if options['recipients'] is not None else ''\n\n            # format multiline message\n            options['message'] = options['message'].replace('\\\\n', '\\n')\n\n            self.run_task(SendEmailTask, **options)\n\n**Deferred Task retrieval to avoid job vs. Task race condition**\n\nAn helper Task.get_task_from_id() classmethod is supplied to retrieve Task object\nfrom task_id safely.\n\n*Task queues create a new type of race condition. Why ?\nBecause message queues are fast !\nHow fast ?\nFaster than databases.*\n\nSee:\n\nhttps://speakerdeck.com/siloraptor/django-tasty-salad-dos-and-donts-using-celery\n\nA similar generic helper is available for Job-derived needs::\n\n    django_task.utils.get_model_from_id(model_cls, id, timeout=1000, retry_count=10)\n\n\n**Howto separate jobs for different instances on the same machine**\n\nTo sepatare jobs for different instances on the same machine (or more precisely\nfor the same redis connection), override queues names for each instance;\n\nfor example:\n\n.. code:: python\n\n    # file \"settings.py\"\n\n    REDIS_URL = 'redis://localhost:6379/0'\n    ...\n\n    #\n    # RQ config\n    #\n\n    RQ_PREFIX = \"myproject_\"\n    QUEUE_DEFAULT = RQ_PREFIX + 'default'\n    QUEUE_HIGH = RQ_PREFIX + 'high'\n    QUEUE_LOW = RQ_PREFIX + 'low'\n\n    RQ_QUEUES = {\n        QUEUE_DEFAULT: {\n            'URL': REDIS_URL,\n            #'PASSWORD': 'some-password',\n            'DEFAULT_TIMEOUT': 360,\n        },\n        QUEUE_HIGH: {\n            'URL': REDIS_URL,\n            'DEFAULT_TIMEOUT': 500,\n        },\n        QUEUE_LOW: {\n            'URL': REDIS_URL,\n            #'ASYNC': False,\n        },\n    }\n\n    RQ_SHOW_ADMIN_LINK = False\n    DJANGOTASK_LOG_ROOT = os.path.abspath(os.path.join(BASE_DIR, '..', 'protected', 'tasklog'))\n    DJANGOTASK_ALWAYS_EAGER = False\n\nthen run worker as follows:\n\n.. code:: python\n\n    python manage.py rqworker myproject_default\n\n**Howto schedule jobs with cron**\n\nCall management command 'count_beans', which in turn executes the required job.\n\nFor example::\n\n    SHELL=/bin/bash\n    PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin\n\n    0 * * * *  {{username}}    timeout 55m {{django.pythonpath}}/python {{django.website_home}}/manage.py count_beans 1000 >> {{django.logto}}/cron.log 2>&1\n\nA base class TaskCommand has been provided to simplify the creation of any specific\ntask-related management commad;\n\na derived management command is only responsible for:\n\n- defining suitable command-line parameters\n- selecting the specific Task class and job function\n\nfor example:\n\n.. code:: python\n\n    from django_task.task_command import TaskCommand\n\n\n    class Command(TaskCommand):\n\n        def add_arguments(self, parser):\n            super(Command, self).add_arguments(parser)\n            parser.add_argument('num_beans', type=int)\n\n        def handle(self, *args, **options):\n            from tasks.models import CountBeansTask\n            self.run_task(CountBeansTask, **options)\n\nScreenshots\n-----------\n\n.. image:: example/etc/screenshot_001.png\n\n.. image:: example/etc/screenshot_002.png\n\n\nApp settings\n------------\n\nDJANGOTASK_LOG_ROOT\n    Path for log files.\n\n    Default: None\n\n    Example: os.path.abspath(os.path.join(BASE_DIR, '..', 'protected', 'tasklog'))\n\nDJANGOTASK_ALWAYS_EAGER\n    When True, all task are execute syncronously (useful for debugging and unit testing).\n\n    Default: False\n\nDJANGOTASK_JOB_TRACE_ENABLED\n    Enables low level tracing in Job.run() - for debugging challenging race conditions\n\n    Default: False\n\nDJANGOTASK_REJECT_IF_NO_WORKER_ACTIVE_FOR_QUEUE\n    Rejects task if not active worker is available for the specific task queue\n    when task.run() is called\n\n    Default: False\n\nREDIS_URL\n\n    Redis server to connect to\n\n    Default: 'redis://localhost:6379/0'\n\nRunning Tests\n-------------\n\nDoes the code actually work?\n\n::\n\n    source <YOURVIRTUALENV>/bin/activate\n    (myenv) $ pip install tox\n    (myenv) $ tox\n\nCredits\n-------\n\nReferences:\n\n- `A simple app that provides django integration for RQ (Redis Queue) <https://github.com/ui/django-rq>`_\n- `Asynchronous tasks in django with django-rq <https://spapas.github.io/2015/01/27/async-tasks-with-django-rq/>`_\n- `django-rq redux: advanced techniques and tools <https://spapas.github.io/2015/09/01/django-rq-redux/>`_\n- `Benchmark: Shared vs. Dedicated Redis Instances <https://redislabs.com/blog/benchmark-shared-vs-dedicated-redis-instances/>`_\n- `Django tasty salad - DOs and DON'Ts using Celery by Roberto Rosario <https://speakerdeck.com/siloraptor/django-tasty-salad-dos-and-donts-using-celery>`_\n\nTools used in rendering this package:\n\n*  Cookiecutter_\n*  `cookiecutter-djangopackage`_\n\n.. _Cookiecutter: https://github.com/audreyr/cookiecutter\n.. _`cookiecutter-djangopackage`: https://github.com/pydanny/cookiecutter-djangopackage\n\n\n\n\nHistory\n=======\n\nv1.2.5\n------\n* Tested with Django 2.0 and Python 3.7\n* Rename `async` to `is_async` to support Python 3.7\n* DJANGOTASK_REJECT_IF_NO_WORKER_ACTIVE_FOR_QUEUE app setting added\n* example cleanup\n\nv1.2.4\n------\n* API to create and run task via ajax\n\nv1.2.3\n------\n* TaskAdmin: postpone autorun to response_add() to have M2M task parameters (if any) ready\n* Task.clone() supports M2M parameters\n\nv1.2.2\n------\n* property to change verbosity dinamically\n\nv1.2.1\n------\n* util revoke_pending_tasks() added\n\nv1.2.0\n------\n* DJANGOTASK_JOB_TRACE_ENABLED setting added to enable low level tracing in Job.run()\n* Added missing import in utils.py\n\nv1.1.3\n------\n* cleanup: remove get_child() method being Task an abstract class\n* fix: skip Task model (being abstract) in dump_all_tasks and delete_all_tasks management commands\n* generic get_model_from_id() helper\n* Job.on_complete() callback\n\nv1.1.2\n------\n* provide list of pending and completed task status\n\nv1.1.0\n------\n* INCOMPATIBLE CHANGE: Make model Task abstract for better listing performances\n* redundant migrations removed\n* convert request.body to string for Python3\n* pretty print task params in log when task completes\n\nv0.3.8\n------\n* return verbose name as description\n\nv0.3.7\n------\n* description added to Task model\n\nv0.3.6\n------\n* More fixes\n\nv0.3.5\n------\n* log to field fix\n\nv0.3.4\n------\n* log quickview + view\n\nv0.3.3\n------\n* Optionally log to either file or text field\n* Management commands to dump and delete all tasks\n\nv0.3.2\n------\n* search by task.id and task.job_id\n\nv0.3.1\n------\n* Keep track of task mode (sync or async)\n\nv0.3.0\n------\n* new class Job provided to share task-related logic among job funcs\n\nv0.2.0\n------\n* fixes for django 2.x\n\nv0.1.15\n-------\n* hack for  prepopulated_fields\n\nv0.1.14\n-------\n* css fix\n\nv0.1.13\n-------\n* minor fixes\n\nv0.1.12\n------\n* Deferred Task retrieval to avoid job vs. Task race condition\n* Improved Readme\n\nv0.1.11\n-------\n* superuser can view all tasks, while other users have access to their own tasks only\n* js fix\n\nv0.1.10\n-------\n* prevent task.failure_reason overflow\n\nv0.1.9\n------\n* app settings\n\nv0.1.8\n------\n* always start job from task.run() to prevent any possible race condition\n* task.run(async) can now accept async=False\n\nv0.1.7\n------\n* javascript: use POST to retrieve tasks state for UI update to prevent URL length limit exceed\n\nv0.1.6\n------\n* Improved ui for TaskAdmin\n* Fix unicode literals for Python3\n\nv0.1.5\n------\n* fixes for Django 1.10\n* send_email management command example added\n\nv0.1.4\n------\n* Fix OneToOneRel import for Django < 1.9\n\nv0.1.3\n------\n* Polymorphic behaviour or Task.get_child() restored\n\nv0.1.2\n------\n* TaskCommand.run_task() renamed as TaskCommand.run_job()\n* New TaskCommand.run_task() creates a Task, then runs it;\n  this guarantees that something is traced even when background job will fail\n\n\n",
    "description_content_type": "",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/morlandi/django-task",
    "keywords": "django-task",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "django-task",
    "package_url": "https://pypi.org/project/django-task/",
    "platform": "",
    "project_url": "https://pypi.org/project/django-task/",
    "project_urls": {
      "Homepage": "https://github.com/morlandi/django-task"
    },
    "release_url": "https://pypi.org/project/django-task/1.3.1/",
    "requires_dist": [
      "django (>=1.10.0)",
      "django-rq (>=1.2.0)"
    ],
    "requires_python": "",
    "summary": "A Django app to run new background tasks from either admin or cron, and inspect task history from admin; based on django-rq",
    "version": "1.3.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16905658,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "46415c35f0eaf9d5e12271c37f4746834d9a86d9f280b2b3087fa57fa037fa45",
        "md5": "dedc8c257d4bfb6601361f13c3d8e773",
        "sha256": "a00af38ff30dfe47096601934ba909dbd974bf302c7e1fac0f4131a1dc48fdda"
      },
      "downloads": -1,
      "filename": "django_task-1.3.1-py2.py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "dedc8c257d4bfb6601361f13c3d8e773",
      "packagetype": "bdist_wheel",
      "python_version": "py2.py3",
      "requires_python": null,
      "size": 37067,
      "upload_time": "2018-07-29T19:11:35",
      "upload_time_iso_8601": "2018-07-29T19:11:35.803264Z",
      "url": "https://files.pythonhosted.org/packages/46/41/5c35f0eaf9d5e12271c37f4746834d9a86d9f280b2b3087fa57fa037fa45/django_task-1.3.1-py2.py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}