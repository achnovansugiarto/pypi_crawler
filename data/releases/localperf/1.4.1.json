{
  "info": {
    "author": "Timoth√© Boulet",
    "author_email": "timothe.boulet0@gmail.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# Local Python performance measurement\r\n\r\nThis project aims to create an easy-to-use package for measuring the performance of python in any machine, in terms of CPU, multiprocessing and GPU (pytorch with CUDA), and also verify that the GPU is used.\r\n\r\n# Installation\r\n\r\nInstall the requirements in requirements.txt, then install the package:\r\n\r\n```bash\r\npip install -r requirements.txt\r\npip install localperf\r\n```\r\n\r\n\r\n# Usage\r\n\r\nYou can measure the performance of your machine in terms of CPU, multiprocessing and GPU (pytorch only for now) by running the commands below.\r\n\r\nRelevant arguments for visualization are:\r\n- `--plot` : plot the results (default False)\r\n- `--log_dir` [log directory] : directory where to save the results (default no logging)\r\n- `--image_dir` [image directory]: directory where to save the images (default no image saving)\r\n- `--no-progess` : do not show progress bar (default behavior is to show)\r\n\r\n# CPU\r\n\r\n<p align=\"center\">\r\n  <img src=\"assets/cpu.png\" alt=\"CPU performances\" width=\"60%\"/>\r\n</p>\r\n\r\nTo measure the performance of your machine in terms of CPU, run the following command:\r\n```bash\r\npython -m localperf.cpu\r\n```\r\n\r\nRelevant arguments for the benchmark are:\r\n- `log_n_data` [log n data] : maximum number of data to do the benchmark (in log10 scale). The treatment of 1 data is defined as the sum of integers from 1 to 1000 (with a for loop), it is used as a base unit of computation.\r\n- `n_measures` [n measures] : number of measures to do for each data size\r\n\r\n# Parallelization\r\n\r\n<p align=\"center\">\r\n  <img src=\"assets/multiprocessing.png\" alt=\"Parallelization performances\" width=\"60%\"/>\r\n</p>\r\n\r\nTo measure the performance of your machine in terms of parallelization, run the following command:\r\n```bash\r\npython -m localperf.parallel\r\n```\r\n\r\nRelevant arguments for the benchmark are:\r\n- `log_n_data` [log n data] : maximum number of data to do the benchmark (in log10 scale)\r\n- `log2_n_process` [log2 n process] : maximum number of processes to do the benchmark (in log2 scale)\r\n- `n_measures` [n measures] : number of measures to do for each data size\r\n- `lib` [lib] : library to use for parallelization. Default is joblib. Currently supported libraries are multiprocessing (`mp`), joblib (`joblib`) and ray (`ray`). For ray you will need to install it with pip before running the benchmark.\r\n\r\n## Compare parallelization libraries\r\n\r\nTo compare the performances of the different libraries, run the following command:\r\n```bash\r\npython -m localperf.parallel_benchmark\r\n```\r\nThis will compare the performances of multiprocessing, joblib and ray. Relevant arguments are:\r\n- `log_n_data` [log n data] : maximum number of data to do the benchmark (in log10 scale)\r\n- `n_process` [n process] : number of processes to do the benchmark. Default behavior is to use your number of CPUs, given by `multiprocessing.cpu_count()`\r\n- `n_measures` [n measures] : number of measures to do for each data size\r\n\r\n\r\n# GPU (pytorch)\r\n\r\n## Install CUDA for pytorch\r\n\r\n<p align=\"center\">\r\n  <img src=\"assets/gpu_torch.png\" alt=\"GPU with torch performances\" width=\"60%\"/>\r\n</p>\r\n\r\nFirst, install pytorch with CUDA following the instructions on the [pytorch website](https://pytorch.org/get-started/locally/). \r\nIf this code returns `True`, it means pytorch and CUDA are installed and its a good sign your GPU is used but this is not a guarantee:\r\n```python\r\nimport torch\r\nprint(torch.cuda.is_available())\r\n```\r\nYou may use the command `nvidia-smi` to check if your GPU is recognized by the system.\r\n\r\n    nvidia-smi\r\n<p align=\"center\">\r\n  <img src=\"assets/nvidia_smi.png\" alt=\"nvidia-smi sceenshot\" width=\"60%\"/>\r\n</p>\r\nThis give you information about each GPU recognized by the system : the name, the VRAM used. You can run this command in a separate terminal to see the GPU usage during your code :\r\n\r\n    watch -n 0.1 nvidia-smi\r\n\r\n## Measure performance\r\n\r\nTo measure the performance of your machine in terms of GPU, run the following command:\r\n```bash\r\npython -m localperf.gpu_torch\r\n```\r\nRelevant arguments for the benchmark are:\r\n- `log_n_data` [log n data] : maximum number of data to do the benchmark (in log10 scale)\r\n- `n_measures` [n measures] : number of measures to do for each data size\r\n- `n_measures_gpu` [n measures gpu] : number of measures to do for each data size, on the GPU. If not specified, the same number of measures as on the CPU is done.\r\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/tboulet/Local-Python-Performance",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "localperf",
    "package_url": "https://pypi.org/project/localperf/",
    "platform": null,
    "project_url": "https://pypi.org/project/localperf/",
    "project_urls": {
      "Homepage": "https://github.com/tboulet/Local-Python-Performance"
    },
    "release_url": "https://pypi.org/project/localperf/1.4.1/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "Measure of python performance in local.",
    "version": "1.4.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17059439,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "42448cb9448db02442555e78a2a1645715c39244e88e9ba1e4ba0efc2e2340ef",
        "md5": "4c600fa25f9b9c78416d54ee12aef7c0",
        "sha256": "8327d13e23c95011f5d080961c762fd458d657690a2ec47cc1a0611f9147aab1"
      },
      "downloads": -1,
      "filename": "localperf-1.4.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "4c600fa25f9b9c78416d54ee12aef7c0",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 13788,
      "upload_time": "2023-02-27T04:21:34",
      "upload_time_iso_8601": "2023-02-27T04:21:34.143443Z",
      "url": "https://files.pythonhosted.org/packages/42/44/8cb9448db02442555e78a2a1645715c39244e88e9ba1e4ba0efc2e2340ef/localperf-1.4.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "e49dc3a961760710a45fe1a59aaa55832f36e3ff15c1974f4db4b8c0a4e98ce3",
        "md5": "8bbe35ef97be2bbd4b268b783d0882cc",
        "sha256": "ccaafc4576edb91c1fd65245b432ba5187353575f0b7b2e0c65101797bc85bc3"
      },
      "downloads": -1,
      "filename": "localperf-1.4.1.tar.gz",
      "has_sig": false,
      "md5_digest": "8bbe35ef97be2bbd4b268b783d0882cc",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 9907,
      "upload_time": "2023-02-27T04:21:38",
      "upload_time_iso_8601": "2023-02-27T04:21:38.541357Z",
      "url": "https://files.pythonhosted.org/packages/e4/9d/c3a961760710a45fe1a59aaa55832f36e3ff15c1974f4db4b8c0a4e98ce3/localperf-1.4.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}