{
  "info": {
    "author": "Jurgis Pasukonis",
    "author_email": "jurgisp@gmail.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "**Status:** Stable release\n\n[![PyPI](https://img.shields.io/pypi/v/memory-maze.svg)](https://pypi.python.org/pypi/memory-maze/#history)\n\n# Memory Maze\n\nMemory Maze is a 3D domain of randomized mazes designed for evaluating the long-term memory abilities of RL agents. Memory Maze isolates long-term memory from confounding challenges, such as exploration, and requires remembering several pieces of information: the positions of objects, the wall layout, and keeping track of agentâ€™s own position.\n\n| Memory 9x9 | Memory 11x11 | Memory 13x13 | Memory 15x15 |\n|------------|--------------|--------------|--------------|\n| ![map-9x9](https://user-images.githubusercontent.com/3135115/177040204-fbf3b558-d063-49d3-9973-ae113137782f.png) | ![map-11x11](https://user-images.githubusercontent.com/3135115/177040184-16ccb614-b897-44db-ab2c-7ae66e14c007.png) | ![map-13x13](https://user-images.githubusercontent.com/3135115/177040164-d3edb11f-de6a-4c17-bce2-38e539639f40.png) | ![map-15x15](https://user-images.githubusercontent.com/3135115/177040126-b9a0f861-b15b-492c-9216-89502e8f8ae9.png) |\n\nKey features:\n- Online RL memory tasks (with baselines)\n- Offline dataset for representation learning (with baselines)\n- Verified that memory is the key challenge\n- Challenging but solvable by human baseline\n- Easy installation via a simple pip command\n- Available `gym` and `dm_env` interfaces\n- Supports headless and hardware rendering\n- Interactive GUI for human players\n- Hidden state information for probe evaluation\n\nAlso see the accompanying research paper: [Evaluating Long-Term Memory in 3D Mazes](https://arxiv.org/abs/2210.13383)\n\n```\n@article{pasukonis2022memmaze,\n  title={Evaluating Long-Term Memory in 3D Mazes},\n  author={Pasukonis, Jurgis and Lillicrap, Timothy and Hafner, Danijar},\n  journal={arXiv preprint arXiv:2210.13383},\n  year={2022}\n}\n```\n\n## Installation\n\nMemory Maze builds on the [`dm_control`](https://github.com/deepmind/dm_control) and [`mujoco`](https://github.com/deepmind/mujoco) packages, which are automatically installed as dependencies:\n\n```sh\npip install memory-maze\n```\n\n## Play Yourself\n\nMemory Maze allows you to play the levels in human mode. We used this mode for recording the human baseline scores. These are the instructions for launching the GUI:\n\n```sh\n# GUI dependencies\npip install gym pygame pillow imageio\n\n# Launch with standard 64x64 resolution\npython gui/run_gui.py\n\n# Launch with higher 256x256 resolution\npython gui/run_gui.py --env \"memory_maze:MemoryMaze-9x9-HD-v0\"\n```\n\n## Task Description\n\nThe task is based on a game known as scavenger hunt or treasure hunt:\n- The agent starts in a randomly generated maze, which contains several objects of different colors.\n- The agent is prompted to find the target object of a specific color, indicated by the border color in the observation image.\n- Once the agent successfully finds and touches the correct object, it gets a +1 reward and the next random object is chosen as a target.\n- If the agent touches an object of the wrong color, there is no effect.\n- Throughout the episode, the maze layout and the locations of the objects do not change.\n- The episode continues for a fixed amount of time, so the total episode reward equals the number of reached targets.\n\n<p align=\"center\"><img width=\"256\" src=\"https://user-images.githubusercontent.com/3135115/177040240-847f0f0d-b20b-4652-83c3-a486f6f22c22.gif\"></p>\n\nAn agent with long-term memory only has to explore each maze once (which is possible in a time much shorter than the length of an episode) and can afterwards follow the shortest path to each requested target, whereas an agent with no memory has to randomly wander through the maze to find each target.\n\nThere are 4 size variations of the maze. The largest maze 15x15 is designed to be challenging but solvable for humans (see benchmark results below), but out of reach for the state-of-the-art RL methods. The smaller sizes are provided as stepping stones, with 9x9 being solvable with current RL methods.\n\n| Size | env_id | Objects | Episode steps | Mean human score | Mean max score |\n|:---------:|-----------------------|:---:|:-----:|:----:|:----:|\n| **9x9**   | `MemoryMaze-9x9-v0`   |  3  | 1000  | 26.4 | 34.8 |\n| **11x11** | `MemoryMaze-11x11-v0` |  4  | 2000  | 44.3 | 58.0 |\n| **13x13** | `MemoryMaze-13x13-v0` |  5  | 3000  | 55.5 | 74.5 |\n| **15x15** | `MemoryMaze-15x15-v0` |  6  | 4000  | 67.7 | 87.7 |\n\nThe mazes are generated with [labmaze](https://github.com/deepmind/labmaze), the same algorithm as used by [DmLab-30](https://github.com/deepmind/lab/tree/master/game_scripts/levels/contributed/dmlab30). The 9x9 corresponds to the [small](https://github.com/deepmind/lab/tree/master/game_scripts/levels/contributed/dmlab30#goal-locations-small) variant and 15x15 corresponds to the [large](https://github.com/deepmind/lab/tree/master/game_scripts/levels/contributed/dmlab30#goal-locations-large) variant.\n\n## Gym Interface\n\nYou can create the environment using the [Gym](https://github.com/openai/gym) interface:\n\n```python\n!pip install gym\nimport gym\n\nenv = gym.make('memory_maze:MemoryMaze-9x9-v0')\nenv = gym.make('memory_maze:MemoryMaze-11x11-v0')\nenv = gym.make('memory_maze:MemoryMaze-13x13-v0')\nenv = gym.make('memory_maze:MemoryMaze-15x15-v0')\n```\n\nThe default environment has 64x64 image observations:\n\n```python\n>>> env.observation_space\nBox(0, 255, (64, 64, 3), uint8)\n```\n\nThere are 6 discrete actions:\n\n```python\n>>> env.action_space\nDiscrete(6)  # (noop, forward, left, right, forward_left, forward_right)\n```\n\nTo create an environment with extra observations for debugging and probe analysis, append `ExtraObs` to the names:\n\n```python\n>>> env = gym.make('memory_maze:MemoryMaze-9x9-ExtraObs-v0')\n>>> env.observation_space\nDict(\n    agent_dir: Box(-inf, inf, (2,), float64), \n    agent_pos: Box(-inf, inf, (2,), float64),\n    image: Box(0, 255, (64, 64, 3), uint8),\n    maze_layout: Box(0, 1, (9, 9), uint8),\n    target_color: Box(-inf, inf, (3,), float64),\n    target_pos: Box(-inf, inf, (2,), float64),\n    target_vec: Box(-inf, inf, (2,), float64),\n    targets_pos: Box(-inf, inf, (3, 2), float64),\n    targets_vec: Box(-inf, inf, (3, 2), float64)\n)\n```\n\nWe also register [additional variants](memory_maze/__init__.py) of the environment that can be useful in certain scenarios.\n\n## DeepMind Interface\n\nYou can create the environment using the [dm_env](https://github.com/deepmind/dm_env) interface:\n\n```python\nfrom memory_maze import tasks\n\nenv = tasks.memory_maze_9x9()\nenv = tasks.memory_maze_11x11()\nenv = tasks.memory_maze_13x13()\nenv = tasks.memory_maze_15x15()\n```\n\nEach observation is a dictionary that includes `image` key:\n\n```python\n>>> env.observation_spec()\n{\n  'image': BoundedArray(shape=(64, 64, 3), ...)\n}\n```\n\nThe constructor accepts a number of arguments, which can be used to tweak the environment:\n\n```python\nenv = tasks.memory_maze_9x9(\n    global_observables=True,\n    image_only_obs=False,\n    top_camera=False,\n    camera_resolution=64,\n    control_freq=4.0,\n    discrete_actions=True,\n)\n```\n\n## Offline Dataset\n\n[**Dataset download here** (~100GB per dataset)](https://www.dropbox.com/sh/c38sc5h7ltgyyzc/AAARVeKgnyaoBLGdYYVABh_Ja)\n\nWe provide two datasets of experience collected from the Memory Maze environment: Memory Maze 9x9 (30M) and Memory Maze 15x15 (30M). Each dataset contains 30 thousand trajectories from Memory Maze 9x9 and 15x15 environments respectively, split into 29k trajectories for training and 1k for evaluation. All trajectories are 1000 steps long, so each dataset has 30M steps total.\n\nThe data is generated with a scripted policy that navigates to randomly chosen points in the maze under action noise. This choice of policy was made to generate diverse trajectories that explore the maze effectively and that form spatial loops, which can be important for learning long-term memory. We intentionally avoid recording data with a trained agent to ensure a diverse data distribution and to avoid dataset bias that could favor some methods over others. Because of this, the rewards are quite sparse in the data, occurring on average 1-2 times per trajectory.\n\nEach trajectory is saved as an NPZ file with the following entries available:\n\n| Key            | Shape              | Type   | Description                                   |\n|----------------|--------------------|--------|-----------------------------------------------|\n| `image`        | (64, 64, 3)        | uint8  | First-person view observation                 |\n| `action`       | (6)                | binary | Last action, one-hot encoded                  |\n| `reward`       | ()                 | float  | Last reward                                   |\n| `maze_layout`  | (9, 9) or (15, 15) | binary | Maze layout (wall / no wall)                  |\n| `agent_pos`    | (2)                | float  | Agent position in global coordinates          |\n| `agent_dir`    | (2)                | float  | Agent orientation as a unit vector            |\n| `targets_pos`  | (3, 2) or (6, 2)   | float  | Object locations in global coordinates        |\n| `targets_vec`  | (3, 2) or (6, 2)   | float  | Object locations in agent-centric coordinates |\n| `target_pos`   | (2)                | float  | Current target object location, global        |\n| `target_vec`   | (2)                | float  | Current target object location, agent-centric |\n| `target_color` | (3)                | float  | Current target object color RGB               |\n\nYou can load a trajectory using [`np.load()`](https://numpy.org/doc/stable/reference/generated/numpy.load.html) to obtain a dictionary of Numpy arrays as follows:\n\n```python\nepisode = np.load('trajectory.npz')\nepisode = {key: episode[key] for key in episode.keys()}\n\nassert episode['image'].shape == (1001, 64, 64, 3)\nassert episode['image'].dtype == np.uint8\n```\n\nAll tensors have a leading time dimension, e.g. `image` tensor has shape (1001, 64, 64, 3). The tensor length is 1001 because there are 1000 steps (actions) in a trajectory, `image[0]` is the observation *before* the first action, and `image[-1]` is the observation *after* the last action.\n\n## Online RL Baselines\n\nIn our [research paper](https://arxiv.org/abs/2210.13383), we evaluate the model-free [IMPALA](https://github.com/google-research/seed_rl/tree/master/agents/vtrace) agent and the model-based [Dreamer](https://github.com/jurgisp/pydreamer) agent as baselines.\n\n<p align=\"center\">\n  <img width=\"650\" alt=\"baselines\" src=\"https://user-images.githubusercontent.com/3135115/197349778-74073613-bf6c-449b-b5c2-07adf21030ff.png\">\n  <br/>\n  <img width=\"650\" alt=\"training\" src=\"https://user-images.githubusercontent.com/3135115/197485498-60560934-2629-47b0-ada8-0484398800d0.png\">\n</p>\n\nHere are videos of the learned behaviors:\n\n**Memory 9x9 - Dreamer (TBTT)**\n\nhttps://user-images.githubusercontent.com/3135115/197378287-4e413440-7097-4d11-8627-3d7fac0845f1.mp4\n\n**Memory 9x9 - IMPALA (400M)**\n\nhttps://user-images.githubusercontent.com/3135115/197378929-7fe3f374-c11c-409a-8a95-03feeb489330.mp4\n\n**Memory 15x15 - Dreamer (TBTT)**\n\nhttps://user-images.githubusercontent.com/3135115/197378324-fb99b496-dba8-4b00-ad80-2d6e19ba8acd.mp4\n\n**Memory 15x15 - IMPALA (400M)**\n\nhttps://user-images.githubusercontent.com/3135115/197378936-939e7615-9dad-4765-b0ef-a49c5a38fe28.mp4\n\n## Offline Probing Baselines\n\nHere we visualize probe predictions alongside trajectories of the offline dataset, as explained in [the paper](https://arxiv.org/abs/2210.13383). These trajectories are from the offline dataset, where the agent just navigates to random points in the maze, it does *not* try to collect rewards.\n\nBottom-left: Object location predictions (x) versus the actual locations (o).\n\nBottom-right: Wall layout predictions (dark green = true positive, light green = true negative, light red = false positive, dark red = false negative).\n\n**Memory 9x9 Walls Objects - RSSM (TBTT)**\n\nhttps://user-images.githubusercontent.com/3135115/197379227-775ec5bc-0780-4dcc-b7f1-660bc7cf95f1.mp4\n\n**Memory 9x9 Walls Objects - Supervised oracle**\n\nhttps://user-images.githubusercontent.com/3135115/197379235-a5ea0388-2718-4035-8bbc-064ecc9ea444.mp4\n\n**Memory 15x15 Walls Objects - RSSM (TBTT)**\n\nhttps://user-images.githubusercontent.com/3135115/197379245-fb96bd12-6ef5-481e-adc6-f119a39e8e43.mp4\n\n**Memory 15x15 Walls Objects - Supervised oracle**\n\nhttps://user-images.githubusercontent.com/3135115/197379248-26a8093e-8b54-443c-b154-e33e0383b5e4.mp4\n\n## Questions\n\nPlease [open an issue][issues] on Github.\n\n[issues]: https://github.com/jurgisp/memory-maze/issues\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/jurgisp/memory-maze",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "memory-maze",
    "package_url": "https://pypi.org/project/memory-maze/",
    "platform": null,
    "project_url": "https://pypi.org/project/memory-maze/",
    "project_urls": {
      "Homepage": "https://github.com/jurgisp/memory-maze"
    },
    "release_url": "https://pypi.org/project/memory-maze/1.0.1/",
    "requires_dist": [
      "dm-control"
    ],
    "requires_python": ">=3",
    "summary": "Memory Maze is an environment to benchmark memory abilities of RL agents",
    "version": "1.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 15539984,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "42ec03f8f6f6a0817d46593a4ba664a7f90c4965ca5aaa75c04eb2ea0193d52a",
        "md5": "04521f0be719027456dc90c395487aae",
        "sha256": "175e58430a9183169d6ca73237e711c1047f850e854f73f3557008b26cc63936"
      },
      "downloads": -1,
      "filename": "memory_maze-1.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "04521f0be719027456dc90c395487aae",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3",
      "size": 17973,
      "upload_time": "2022-10-26T14:01:50",
      "upload_time_iso_8601": "2022-10-26T14:01:50.722743Z",
      "url": "https://files.pythonhosted.org/packages/42/ec/03f8f6f6a0817d46593a4ba664a7f90c4965ca5aaa75c04eb2ea0193d52a/memory_maze-1.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "623f6ade0820bc4868042a37ec0e20f815b185ba851f4a5f405306c2e4894cb4",
        "md5": "57c071b9a23d7fa90300b16a2ffc2c05",
        "sha256": "4edb42e11fafc052d12cf3dbd1f4151fa8edab46217c026f9070a80d81973add"
      },
      "downloads": -1,
      "filename": "memory-maze-1.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "57c071b9a23d7fa90300b16a2ffc2c05",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3",
      "size": 20566,
      "upload_time": "2022-10-26T14:01:52",
      "upload_time_iso_8601": "2022-10-26T14:01:52.513427Z",
      "url": "https://files.pythonhosted.org/packages/62/3f/6ade0820bc4868042a37ec0e20f815b185ba851f4a5f405306c2e4894cb4/memory-maze-1.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}