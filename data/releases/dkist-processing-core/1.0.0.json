{
  "info": {
    "author": "NSO / AURA",
    "author_email": "\"dkistdc@nso.edu\"",
    "bugtrack_url": null,
    "classifiers": [
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.9"
    ],
    "description": "dkist-processing-core\n=====================\n\nOverview\n--------\nThe dkist-processing-core package provides an abstraction layer between the dkist data processing code, the workflow\nengine that supports it (airflow), and the logging infrastructure. By providing the abstraction layer to airflow\nspecifically a versioning system is implemented.\n\n.. image:: https://bitbucket.org/dkistdc/dkist-processing-core/raw/faf0c57f2155d03889fcd54bc1676a8a219f6ee3/docs/auto_proc_brick.png\n  :width: 600\n  :alt: Core, Common, and Instrument Brick Diagram\n\nThere are 3 main entities which implement the abstraction:\n\n*Task* : The Task provides a definition of the dkist data processing task interface.\nIt additionally implements some methods that should be global for all dkist processing tasks.  It also provides an api\nto the application performance monitoring infrastructure.\n\n*Workflow* : The Workflow defines an api independent of the workflow engine it abstracts.  It also implements the translation to\nengine specific workflow definitions.  In the case of airflow this is a DAG.\n\n*Node* : The Node is used by the Workflow to translate a Task to the engine specific implementation of the Task which runs inside of a python virtual environment.\nThe virtual environment enables the loading of only that tasks dependencies.\n\nAdditional support functions are provided in build_utils.\n\nUsage\n-----\nThe Workflow and Task are the primary objects used by client libraries.\nThe Task is used as a base class and the subclass must at a minimum implement run.\nA Workflow is used to give the tasks an order of execution and a name for the flow.\n\n.. code-block:: python\n\n    from dkist_processing_core import TaskBase\n    from dkist_processing_core import Workflow\n\n    # Task definitions\n    class MyTask1(TaskBase):\n        def run(self):\n            print(\"Running MyTask1\")\n\n\n    class MyTask2(TaskBase):\n        def run(self):\n            print(\"Running MyTask2\")\n\n    # Workflow definition\n    # MyTask1 -> MyTask2\n    w = Workflow(process_category=\"My\", process_name=\"Workflow\", workflow_package=__package__, workflow_version=\"dev\")\n    w.add_node(MyTask1, upstreams=None)\n    w.add_node(MyTask2, upstreams=MyTask1)\n\n\nUsing dkist-processing-core for data processing with airflow involves a project structure and\nbuild process that results in code artifacts deployed to `PyPI <https://pypi.org/project/dkist-processing-core/>`_ and a\nzip of workflow artifacts deployed to artifactory.\n\n.. image:: https://bitbucket.org/dkistdc/dkist-processing-core/raw/faf0c57f2155d03889fcd54bc1676a8a219f6ee3/docs/auto-proc-concept-model.png\n  :width: 600\n  :alt: Build Artifacts Diagram\n\nThe client dkist data processing libraries should implement a structure and build pipeline using `dkist-processing-test <https://bitbucket.org/dkistdc/dkist-processing-test/src/main/>`_\nas an example.  The build pipelines for a client repo can leverage the `build_utils <dkist_processing_core/build_utils.py>`_ for test and export.\n\nSpecifically for airflow, the resulting deployment has the versioned workflow artifacts all available to the scheduler\nand the versioned code artifacts available to workers for task execution\n\n.. image:: https://bitbucket.org/dkistdc/dkist-processing-core/raw/faf0c57f2155d03889fcd54bc1676a8a219f6ee3/docs/automated-processing-deployed.png\n  :width: 800\n  :alt: Airflow Deployment Diagram\n\nBuild\n-----\ndkist-processing-core is built using `bitbucket-pipelines <bitbucket-pipelines.yml>`_\n\nDeployment\n----------\ndkist-processing-core is deployed to `PyPI <https://pypi.org/project/dkist-processing-core/>`_\n\nEnvironment Variables\n---------------------\n\n.. list-table::\n   :widths: 10 70 10 10\n   :header-rows: 1\n\n   * - Variable\n     - Description\n     - Type\n     - Default\n   * - BUILD_VERSION\n     - Build/Export pipelines only.  This is the value that will be appended to all artifacts and represents their unique version\n     - STR\n     - dev\n   * - MESH_CONFIG\n     - Provides the dkistdc cloud mesh configuration.  Specifically the location of the message broker\n     - JSON\n     -\n   * - ISB_USERNAME\n     - Message broker user name\n     - STR\n     -\n   * - ISB_PASSWORD\n     - Message broker password\n     - STR\n     -\n\nDevelopment\n-----------\n.. code-block:: bash\n\n    git clone git@bitbucket.org:dkistdc/dkist-processing-core.git\n    cd dkist-processing-core\n    pre-commit install\n    pip install -e .[test]\n    pytest -v --cov dkist_processing_core\n\nChangelog\n#########\n\nWhen you make **any** change to this repository it **MUST** be accompanied by a changelog file.\nThe changelog for this repository uses the `towncrier <https://github.com/twisted/towncrier>`__ package.\nEntries in the changelog for the next release are added as individual files (one per change) to the ``changelog/`` directory.\n\nWriting a Changelog Entry\n^^^^^^^^^^^^^^^^^^^^^^^^^\n\nA changelog entry accompanying a change should be added to the ``changelog/`` directory.\nThe name of a file in this directory follows a specific template::\n\n  <PULL REQUEST NUMBER>.<TYPE>[.<COUNTER>].rst\n\nThe fields have the following meanings:\n\n* ``<PULL REQUEST NUMBER>``: This is the number of the pull request, so people can jump from the changelog entry to the diff on BitBucket.\n* ``<TYPE>``: This is the type of the change and must be one of the values described below.\n* ``<COUNTER>``: This is an optional field, if you make more than one change of the same type you can append a counter to the subsequent changes, i.e. ``100.bugfix.rst`` and ``100.bugfix.1.rst`` for two bugfix changes in the same PR.\n\nThe list of possible types is defined the the towncrier section of ``pyproject.toml``, the types are:\n\n* ``feature``: This change is a new code feature.\n* ``bugfix``: This is a change which fixes a bug.\n* ``doc``: A documentation change.\n* ``removal``: A deprecation or removal of public API.\n* ``misc``: Any small change which doesn't fit anywhere else, such as a change to the package infrastructure.\n\n\nRendering the Changelog at Release Time\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nWhen you are about to tag a release first you must run ``towncrier`` to render the changelog.\nThe steps for this are as follows:\n\n* Run `towncrier build --version vx.y.z` using the version number you want to tag.\n* Agree to have towncrier remove the fragments.\n* Add and commit your changes.\n* Tag the release.\n\n**NOTE:** If you forget to add a Changelog entry to a tagged release (either manually or automatically with ``towncrier``)\nthen the Bitbucket pipeline will fail. To be able to use the same tag you must delete it locally and on the remote branch:\n\n.. code-block:: bash\n\n    # First, actually update the CHANGELOG and commit the update\n    git commit\n\n    # Delete tags\n    git tag -d vWHATEVER.THE.VERSION\n    git push --delete origin vWHATEVER.THE.VERSION\n\n    # Re-tag with the same version\n    git tag vWHATEVER.THE.VERSION\n    git push --tags origin main\n\n\n",
    "description_content_type": "",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://bitbucket.org/dkistdc/dkist-processing-core/src/main/",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "dkist-processing-core",
    "package_url": "https://pypi.org/project/dkist-processing-core/",
    "platform": null,
    "project_url": "https://pypi.org/project/dkist-processing-core/",
    "project_urls": {
      "Documentation": "https://docs.dkist.nso.edu/projects/core",
      "Homepage": "https://bitbucket.org/dkistdc/dkist-processing-core/src/main/"
    },
    "release_url": "https://pypi.org/project/dkist-processing-core/1.0.0/",
    "requires_dist": null,
    "requires_python": ">=3.9",
    "summary": "Abstraction layer that is used by the DKIST Science Data Processing pipelines to process DKIST data using Apache Airflow.",
    "version": "1.0.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16905972,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "ac541cee326be613d8fb385e75b8ab397f8d0b8f4758bb69900ac8605c324dbb",
        "md5": "5804b66a31de0a614d20869ac28b7e1e",
        "sha256": "ff67c4535897c11fab5dca08e008c3d3320bf94b2334ad617b5dc588f04cbcc6"
      },
      "downloads": -1,
      "filename": "dkist-processing-core-1.0.0.tar.gz",
      "has_sig": false,
      "md5_digest": "5804b66a31de0a614d20869ac28b7e1e",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.9",
      "size": 379716,
      "upload_time": "2022-08-08T22:04:13",
      "upload_time_iso_8601": "2022-08-08T22:04:13.950195Z",
      "url": "https://files.pythonhosted.org/packages/ac/54/1cee326be613d8fb385e75b8ab397f8d0b8f4758bb69900ac8605c324dbb/dkist-processing-core-1.0.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}