{
  "info": {
    "author": "Andy Wong",
    "author_email": "wangyucheng@iie.ac.cn",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: Implementation :: CPython",
      "Programming Language :: Python :: Implementation :: PyPy"
    ],
    "description": "\n\n# Doraemon\n**Doraemon is a tool kit.**\n\n***\n1. Google Knowledge Graph [Deprecated]\n2. Google Translator\n3. Dianping [Deprecated] # 大众点评 \n4. QQ music lyrics\n5. whois\n6. NetEase music comments\n7. Parse domain name to IP (in batch)\n***\n\n## Tools\n### 1. Robust Requests\n```python\nfrom Doraemon import requests_dora\nurl = \"https://www.baidu.com\"\n\nheaders = requests_dora.get_default_headers()\nheaders[\"User-Agent\"] = requests_dora.get_random_user_agent()\n\ndef get_proxies():\n    proxy_str = \"127.0.0.1:1080\"\n    proxies = {\"http\": \"http://%s\" % proxy_str,\n               \"https\": \"http://%s\" % proxy_str, }\n    return proxies\n\n# max_times, get_proxies_fun, and invoked_by are optional parameters, others are the same as the requests.get() and requests.post()\nres1 = requests_dora.try_best_2_get(url, max_times=5, get_proxies_fun=get_proxies, invoked_by=\"parent_fun_name\") \nres2 = requests_dora.try_best_2_post(url, max_times=5, get_proxies_fun=get_proxies)\nprint(res1.status_code)\nprint(res2.status_code)\n```\n### 2. Proxy Kit\n```python\nfrom Doraemon import proxies_dora\nproxies1 = proxies_dora.get_proxies(\"127.0.0.1:223\") # get a self-defined proxies dict\nproxies2 = proxies_dora.get_data5u_proxies(\"your data5u api key\") # input api key for crawling, get a proxies dict\n\npool = [\n\"127.0.0.1:233\",\n\"123.123.123.123:123\",\n\"...\",\n]\n\nproxies_dora.set_pool(pool) # set a self-defined proxy pool\nproxies3 = proxies_dora.get_proxies_fr_pool() # get a proxies dict from the pool\n\nloc_info1 = proxies_dora.loc_proxy_ipv4(proxies1) # get location info of a given proxy, ipv4 only\nloc_info2 = proxies_dora.loc_proxy(proxies2) # get location info of a given proxy, for both ipv4 and ipv6\n\n```\n### 3. User-friendly Chrome\n```python\nfrom Doraemon import chrome_dora\n\nproxy = \"127.0.0.1:1080\"\nbaidu_url = \"https://www.baidu.com\"\n# no_images: do not load images(response more quickly)\n# headless: make the chrome invisible\n# proxy: set if you need\n# they are all optional\nchrome = chrome_dora.MyChrome(headless=False, proxy=\"127.0.0.1:1080\", no_images=True) \nchrome.get(baidu_url)\nprint(chrome.page_source)\n```\n\n## Crawlers\n### 1. Google Knowledge Graph [Deprecated]\n```python\nfrom Doraemon import google_KG\n\ndef get_proxies():\n    proxy_str = \"127.0.0.1:1080\"\n    proxies = {\"http\": \"http://%s\" % proxy_str,\n               \"https\": \"http://%s\" % proxy_str, }\n    return proxies\n\nres = google_KG.get_entity(\"alibaba\", get_proxies_fun=get_proxies)\nprint(res)\n```\n\n### 2. Google Translator\n```python\nfrom Doraemon import google_translator, proxies_dora\n\ndef get_proxies():\n    proxy_str = \"127.0.0.1:1080\"\n    proxies = {\"http\": \"http://%s\" % proxy_str,\n               \"https\": \"http://%s\" % proxy_str, }\n    return proxies\n\nori_text = \"中华民国\"\n# sl, tl and get_proxies_fun are optional, the default values are \"auto\", \"en\", None\nres1 = google_translator.trans(ori_text,sl=\"auto\", tl=\"zh-TW\", get_proxies_fun=get_proxies) \n# replace the function get_proxies with proxies_dora.get_proxies(\"127.0.0.1:1080\")\nres2 = google_translator.trans(ori_text,sl=\"auto\", tl=\"zh-TW\", get_proxies_fun=lambda: proxies_dora.get_proxies(\"127.0.0.1:1080\")) \n\nlong_text = ori_text * 2500 # 10000 characters\nres3 = google_translator.trans_long(long_text)# if len(text) > 5000\n\nprint(res1)\nprint(res2)\n```\n\n**Language Code:**\n```angular2html\n检测语言: auto\n阿尔巴尼亚语: sq\n阿拉伯语: ar\n阿姆哈拉语: am\n阿塞拜疆语: az\n爱尔兰语: ga\n爱沙尼亚语: et\n巴斯克语: eu\n白俄罗斯语: be\n保加利亚语: bg\n冰岛语: is\n波兰语: pl\n波斯尼亚语: bs\n波斯语: fa\n布尔语(南非荷兰语): af\n丹麦语: da\n德语: de\n俄语: ru\n法语: fr\n菲律宾语: tl\n芬兰语: fi\n弗里西语: fy\n高棉语: km\n格鲁吉亚语: ka\n古吉拉特语: gu\n哈萨克语: kk\n海地克里奥尔语: ht\n韩语: ko\n豪萨语: ha\n荷兰语: nl\n吉尔吉斯语: ky\n加利西亚语: gl\n加泰罗尼亚语: ca\n捷克语: cs\n卡纳达语: kn\n科西嘉语: co\n克罗地亚语: hr\n库尔德语: ku\n拉丁语: la\n拉脱维亚语: lv\n老挝语: lo\n立陶宛语: lt\n卢森堡语: lb\n罗马尼亚语: ro\n马尔加什语: mg\n马耳他语: mt\n马拉地语: mr\n马拉雅拉姆语: ml\n马来语: ms\n马其顿语: mk\n毛利语: mi\n蒙古语: mn\n孟加拉语: bn\n缅甸语: my\n苗语: hmn\n南非科萨语: xh\n南非祖鲁语: zu\n尼泊尔语: ne\n挪威语: no\n旁遮普语: pa\n葡萄牙语: pt\n普什图语: ps\n齐切瓦语: ny\n日语: ja\n瑞典语: sv\n萨摩亚语: sm\n塞尔维亚语: sr\n塞索托语: st\n僧伽罗语: si\n世界语: eo\n斯洛伐克语: sk\n斯洛文尼亚语: sl\n斯瓦希里语: sw\n苏格兰盖尔语: gd\n宿务语: ceb\n索马里语: so\n塔吉克语: tg\n泰卢固语: te\n泰米尔语: ta\n泰语: th\n土耳其语: tr\n威尔士语: cy\n乌尔都语: ur\n乌克兰语: uk\n乌兹别克语: uz\n西班牙语: es\n希伯来语: iw\n希腊语: el\n夏威夷语: haw\n信德语: sd\n匈牙利语: hu\n修纳语: sn\n亚美尼亚语: hy\n伊博语: ig\n意大利语: it\n意第绪语: yi\n印地语: hi\n印尼巽他语: su\n印尼语: id\n印尼爪哇语: jw\n英语: en\n约鲁巴语: yo\n越南语: vi\n中文(繁体): zh-TW\n中文(简体): zh-CN\n```\n### 3. Dianping [Deprecated: character decoding]\n```python\nfrom Doraemon import dianping, proxies_dora\nimport json\n\n# get_proxies_fun is optional, set if you want to use a proxy\nshop_list = dianping.search_shops(\"2\", \"4s店\", 1, get_proxies_fun=lambda: proxies_dora.get_proxies(\"127.0.0.1:1080\")) # args: city id, keyword, page index\nprint(json.dumps(shop_list, indent=2, ensure_ascii=False))\n# [{\"name\": \"shopname1\", \"shop_id\": \"1245587}, ...]\n\n# get_proxies_fun is optional, set if you want to use a proxy, this example use data5u proxy, \n# the website is :http://www.data5u.com/api/doc-dynamic.html \nshop_list_around = dianping.get_around(\"2\", \"5724615\", 2000, 1, get_proxies_fun=lambda: proxies_dora.get_data5u_proxies(\"your data5u api key\")) # args: city id, shop id, max distance, page index\nprint(json.dumps(shop_list_around, indent=2, ensure_ascii=False))\n'''\nshop_list_around is like this:\n    [\n      {\n        \"img_src\": \"https://img.meituan.net/msmerchant/2e5787325ba4579ec2e2e3f45038ade1149446.jpg%40340w_255h_1e_1c_1l%7Cwatermark%3D1%26%26r%3D1%26p%3D9%26x%3D2%26y%3D2%26relative%3D1%26o%3D20\",\n        \"title\": \"速度披萨(华贸城店)\",\n        \"star_level\": 4.5,\n        \"review_num\": 30,\n        \"mean_price\": 89,\n        \"cat\": \"西餐\",\n        \"region\": \"北苑家园\",\n        \"addr\": \"清苑路13号\",\n        \"rec_dish\": [\n          \"黑芝麻沙拉\",\n          \"蟹肉意面\",\n          \"火腿榴莲披萨双拼\"\n        ],\n        \"score\": {\n          \"taste\": 8.5,\n          \"env\": 8.4,\n          \"service\": 8.4\n        }\n      },\n    ]\n'''\n```\n\n### 4. QQ music lyrics\n```python\nimport os\nfrom Doraemon import qq_music_crawler_by_album as qm_album, qq_music_crawler_by_area as qm_area\n# crawl lyrics of songs in specific areas\narea_list = [\"港台\", \"内地\"] # {'全部': -100, '内地': 200, '港台': 2, '欧美': 5, '日本': 4, '韩国': 3, '其他': 6}\nsave_path = \"./qq_music_songs_by_area\"\nif not os.path.exists(save_path):\n    os.makedirs(save_path)\nqm_area.crawl_songs(area_list, save_path)\n\n# crawl lyrics by albums\nimport json\nfrom tqdm import tqdm\n\nsave_path = \"./qq_music_songs_by_album\"\nif not os.path.exists(save_path):\n    os.makedirs(save_path)\n\nfor sin in range(0, 7050, 30):\n    ein = sin + 29\n    album_list = qm_album.get_album_list(sin, ein) # get 30 albums\n\n    for album in album_list:\n        dissname = album[\"dissname\"]\n        song_list = qm_album.get_song_list(album[\"dissid\"])\n        chunk = []\n        for song in tqdm(song_list, desc = \"getting songs in {}\".format(dissname)):\n            contributors, lyric = qm_album.get_lyric(song)\n            song[\"lyric\"] = lyric\n            chunk.append(song)\n\n        json.dump(chunk, open(\"{}/lyric_{}.json\".format(save_path, dissname), \"w\", encoding = \"utf-8\"), ensure_ascii = False)\n```\n\n### 5. whois\n```python\nfrom Doraemon import whois\nip_list = [\"154.17.24.36\", \"154.17.24.37\", \"154.17.24.39\", \"154.17.21.36\"] * 100\n# # friendly\n# res = whois.extract_org_names_friendly(ip_list, block_size = 100, sleep = 2)\n\n# no limited\nres = whois.extract_org_names_no_limited(ip_list)\nprint(res)\n```\n\n### 6. NetEase music comments \nrun under `netease_music`\n```bash\nscrapy crawl comments\n```\n\n### 7. domain2ip\n```python\nfrom Doraemon import domain2ip\nthreads = 100\nmax_fail_num = 0\ndomain_name2ip = {} # results\nurl_list = [\"https://www.baidu.com\", \"https://www.qq.com\"]\ndomain2ip.gethostbyname_fast(url_list, domain_name2ip, threads, max_fail_num)\n```\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/131250208/Doraemon",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "Doraemon",
    "package_url": "https://pypi.org/project/Doraemon/",
    "platform": "",
    "project_url": "https://pypi.org/project/Doraemon/",
    "project_urls": {
      "Homepage": "https://github.com/131250208/Doraemon"
    },
    "release_url": "https://pypi.org/project/Doraemon/4.2/",
    "requires_dist": [
      "selenium",
      "requests",
      "bs4",
      "chardet (<4.0,>=2.0)",
      "aiohttp",
      "tqdm",
      "rsa",
      "webdriver-manager",
      "PyExecJS",
      "nest-asyncio"
    ],
    "requires_python": ">=3.5.0",
    "summary": "The pocket of Doraemon: many tools",
    "version": "4.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8966841,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "ee20ceb70ff73ed872f02045360b66f93aab0ee135a474c601f7429afb7aa65b",
        "md5": "21e6c4e381a33c5e68b452bafb2def6a",
        "sha256": "c34e5cf70c8628f03417b908045d8db910039da494150b6a11dae36d4d7f1430"
      },
      "downloads": -1,
      "filename": "Doraemon-4.2-py2.py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "21e6c4e381a33c5e68b452bafb2def6a",
      "packagetype": "bdist_wheel",
      "python_version": "py2.py3",
      "requires_python": ">=3.5.0",
      "size": 60241,
      "upload_time": "2020-12-22T16:04:27",
      "upload_time_iso_8601": "2020-12-22T16:04:27.933573Z",
      "url": "https://files.pythonhosted.org/packages/ee/20/ceb70ff73ed872f02045360b66f93aab0ee135a474c601f7429afb7aa65b/Doraemon-4.2-py2.py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "9aeaaeca9c1af3446957513599114d9b85eeab825f2d092f34ad0f524299378e",
        "md5": "a9b18a5d2bf589f8fa92d283cdad8bac",
        "sha256": "dac4f1e257232fbcfd49bc67b7c26bb213c4da8d28039d75fd211041b65a6693"
      },
      "downloads": -1,
      "filename": "Doraemon-4.2.tar.gz",
      "has_sig": false,
      "md5_digest": "a9b18a5d2bf589f8fa92d283cdad8bac",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.5.0",
      "size": 34282,
      "upload_time": "2020-12-22T16:04:30",
      "upload_time_iso_8601": "2020-12-22T16:04:30.329216Z",
      "url": "https://files.pythonhosted.org/packages/9a/ea/aeca9c1af3446957513599114d9b85eeab825f2d092f34ad0f524299378e/Doraemon-4.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}