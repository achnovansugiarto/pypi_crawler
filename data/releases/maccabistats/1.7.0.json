{
  "info": {
    "author": "",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# Description \n\nSimple package which allow to figure out more about maccabi tel-aviv football team while manipulating statistics.\nAtm all the data parsed from maccabi-tlv site.\n\n# Manipulating Statistics - Examples\n\nLoading all the games:\n```\nfrom maccabistats.stats.serialized_games import get_maccabi_stats\ngames = get_maccabi_stats()\n```\nor shorter\n\n```\nfrom maccabistats import get_maccabi_stats\ngames = get_maccabi_stats()\n```\n\nTrying to get only old home wins:\n```\nold_games = games.played_before(\"1.1.2000\")\nold_home_games = old_games.home_games\nold_home_wins = old_home_games.maccabi_wins\n```\n\nor just:\n```\ngames.played_before(\"1.1.2000\").home_games.maccabi_wins\n```\n\n\n\nShow best scorers of 'games':\n```\ngames.best_scorers\n```\n\nOr the same for old home wins:\n```\nold_home_wins.best_scorers\n```\n\n# Crawling maccabi games\n\nWhen crawling each page will be saved on your disk to allow optimization for the next time.\nif you just want to get the stats, You can run:\n```\nfrom maccabistats import serialize_maccabi_games\nserialize_maccabi_games(file_name)\n```\ndefault file_name will be saved to maccabistats package.\n\nYou can 'use_multi-process-crawl' from settings to allow multi-processing,\nBUT atm logging does not support multi-processing, so dont use that if you need to debug anything.\n\n\n# Manual fixes\n\nAfter crawling data from maccabi site there are some manual fixes to be done.\nyou can run them manually by:\n```\nfrom maccabistats import get_maccabi_stats\ngames = get_maccabi_stats()\n\nfrom maccabistats.data_improvement.manual_fixes import run_manual_fixes\nnew_games = run_manual_fixes(games)\n```\n\nTo debug manual fixes, just import any class under data_improvement:\n```\nfrom maccabistats.data_improvement.naming_fixes import NamingErrorsFinder\nn = NamingErrorsFinder(g)  # g = get_maccabi_stats()\nn.show_naming_similarities()\n```\n\n\n# Logging\n\nAll of the log files will be saved at 'maccabistats-logs' folder under the user home folder (pathlib.Path.home())\nThere are several log files, each one has this pattern - maccabistats-{suffix}.log (at the mentioned folder): \n\n* all - save all log levels\n* info - save just the info log level\n* warning - save just the warn log level\n* exception - save just exceptions (log.exception)\n* stdout - not a file but log handler that print to stdout (info level +) \n\n\n# Known issues\n\n* Players which opened as (captain or had different shirt number between games) will be counted as different players.\n* Ignoring events after 120 min (in game_events_parser -> fully_game_time_without_penalties)\n* Logging with multi-process crawling mode isn't working.\n\n\n# Optimization \n* You can use 'use-disk-to-crawl-when-available' to crawl from disk when available, each page that will be crawled from internet wil be save on disk. \n* You can get some of the html files from: https://mega.nz/#F!szxTUDRQ ( key will be available at forum.12p.co.il)\n* You can reduce logging when crawling by use :\n```\nfrom maccabistats import faster_logging\nfaster_logging() will disable the stdout & debug handlers.\n```\n\n\n# Versioning\nATM minor version change 0.X.0 may indicate API CHANGES.\n\n\n",
    "description_content_type": "",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "maccabistats",
    "package_url": "https://pypi.org/project/maccabistats/",
    "platform": "",
    "project_url": "https://pypi.org/project/maccabistats/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/maccabistats/1.7.0/",
    "requires_dist": [
      "setuptools (==28.8.0)",
      "requests (==2.18.4)",
      "beautifulsoup4 (==4.6.0)"
    ],
    "requires_python": ">=3",
    "summary": "Maccabi tel-aviv football team statistics manipulation.",
    "version": "1.7.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16331800,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "141a1f3023d641643af56980655973923c0ceae51847b34821a430451fa3fe2b",
        "md5": "59a5f51fb30a7f253077c4abcca45502",
        "sha256": "42597ced39c2a8f7f9c0b02049d8e1a9762b0a5ae3d961a9a9ec5befb2f4ab17"
      },
      "downloads": -1,
      "filename": "maccabistats-1.7.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "59a5f51fb30a7f253077c4abcca45502",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3",
      "size": 35885,
      "upload_time": "2018-04-02T11:12:45",
      "upload_time_iso_8601": "2018-04-02T11:12:45.131222Z",
      "url": "https://files.pythonhosted.org/packages/14/1a/1f3023d641643af56980655973923c0ceae51847b34821a430451fa3fe2b/maccabistats-1.7.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}