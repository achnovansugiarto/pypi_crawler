{
  "info": {
    "author": "Xunmo Yang, Dennis Sun, Taylor Pospisil",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Framework :: IPython",
      "Framework :: Jupyter",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: Apache Software License",
      "Programming Language :: Python",
      "Programming Language :: Python :: 2",
      "Programming Language :: Python :: 3",
      "Programming Language :: SQL"
    ],
    "description": "# Meterstick Documentation\n\nThe meterstick package provides a concise syntax to describe and execute\nroutine data analysis tasks. Please see meterstick_demo.ipynb for examples.\n\n## Disclaimer\n\nThis is not an officially supported Google product.\n\n\n## tl;dr\n\nModify the demo colab [notebook](https://colab.research.google.com/github/google/meterstick/blob/master/meterstick_demo.ipynb) and adapt it to your needs.\n\n## Building up an analysis\n\nEvery analysis starts with a `Metric` or a `MetricList`. A full list of Metrics\ncan be found below.\n\nA `Metric` may be modified by one or more `Operation`s. For example, we might\nwant to calculate a confidence interval for the metric, a treatment-control\ncomparison, or both.\n\nOnce we have specified the analysis, we pass in the data to compute the\nanalysis on, as well as variables to slice by.\n\nHere is an example of a full analysis:\n\n```python\n# define metrics\ncvr = Ratio(\"Conversions\", \"Visits\")\nbounce_rate = Ratio(\"Bounces\", \"Visits\")\n\n(MetricList((cvr, bounce_rate))\n | PercentChange(\"Experiment\", \"Control\")\n | Jackknife(\"Cookie\", confidence=.95)\n | compute_on(data, [\"Country\", \"Device\"]))\n```\n\nThis calculates the percent change in conversion rate and bounce rate,\nrelative to the control arm, for each country and device, together with\n95% confidence intervals based on jackknife standard errors.\n\n\n## Building Blocks of an Analysis Object\n\n### Metrics\n\nA Meterstick analysis begins with one or more metrics.\n\nCurrently built-in metrics include:\n\n+   `Count(variable)`: calculates the number of (non-null) entries of `variable`\n+   `Sum(variable)` : calculates the sum of `variable`\n+   `Mean(variable)`: calculates the mean of `variable`\n+   `Max(variable)`: calculates the max of `variable`\n+   `Min(variable)`: calculates the min of `variable`\n+   `Ratio(numerator, denominator)` : calculates `Sum(numerator) /\n    Sum(denominator)`.\n+   `Quantile(variable, quantile(s))`: calculates the `quantile(s)` quantile for\n    `variable`.\n+   `Variance(variable, unbiased=True)`: calculates the variance of `variable`;\n    `unbiased` determines whether the unbiased (sample) or population estimate\n    is used.\n+   `StandardDeviation(variable, unbiased=True)`: calculates the standard\n    deviations of `variable`; `unbiased` determines whether the unbiased or MLE\n    estimate is used.\n+   `CV(variable, unbiased=True)`: calculates the coefficient of variation of\n    `variable`; `unbiased` determines whether the unbiased or MLE estimate of\n    the standard deviation is used.\n+   `Correlation(variable1, variable2)`: calculates the Pearson correlation\n    between `variable1` and `variable2`.\n+   `Cov(variable1, variable2)`: calculates the covariance between `variable1`\n    and `variable2`.\n\nAll metrics have an optional `name` argument which determines the column name\nin the output. If not specified, a default name will be provided. For instance,\nthe metric `Sum(\"Clicks\")` will have the default name `sum(Clicks)`.\n\nMetrics such as `Mean` and `Quantile` have an optional `weight` argument that\nspecifies a weighting column. The resulting metric is a weighted mean or\nweighted quantile.\n\nTo calculate multiple metrics at once, create a `MetricList` of the individual\n`Metric`s. For example, to calculate both total visits and conversion rate,\nwe would write:\n\n```python\nsum_visits = Sum(\"Visits\")\nMetricList([sum_visits, Sum(\"Conversions\") / sum_visits])\n```\n\nWhen computing analyses involving multiple metrics, Meterstick will try to\ncache redundant computations. For example, both metrics above require\ncalculating `Sum(\"Visits\")`; Meterstick will only calculate this once.\n\nYou can also define custom metrics. See section `Custom Metric` below for\ninstructions.\n\n#### Composite Metrics\n\nMetrics are also **composable**. For example, you can:\n\n+ Add metrics: `Sum(\"X\") + Sum(\"Y\")` or `Sum(\"X\") + 1`.\n+ Subtract metrics: `Sum(\"X\") - Sum(\"Y\")` or `Sum(\"X\") - 1`.\n+ Multiply metrics: `Sum(\"X\") * Sum(\"Y\")` or `100 * Sum(\"X\")`.\n+ Divide metrics: `Sum(\"X\") / Sum(\"Y\")` or `Sum(\"X\") / 2`.\n  (Note that the first is equivalent to `Ratio(\"X\", \"Y\")`.)\n+ Raise metrics to a power: `Sum(\"X\") ** 2` or `2 ** Sum(\"X\")` or\n  `Sum(\"X\") ** Sum(\"Y\")`.\n+ ...or any combination of these: `100 * (Sum(\"X\") / Sum(\"Y\") - 1)`.\n\nCommon metrics can be implemented as follows:\n\n+   Click-through rate: `Ratio('Clicks', 'Impressions', 'CTR')`\n+   Conversion rate: `Ratio('Conversions', 'Visits', 'CvR')`\n+   Bounce rate: `Ratio('Bounce', 'Visits', 'BounceRate')`\n+   Cost per click (CPC): `Ratio('Cost', 'Clicks', 'CPC')`\n\n### Operations\n\nOperations are defined on top of metrics. Operations include comparisons,\nstandard errors, and distributions.\n\n#### Comparisons\n\nA **comparison** operation calculates the change in a metric between various\nconditions and a baseline. In A/B testing, the \"condition\" is\ntypically a treatment and the \"baseline\" a control.\n\nBuilt-in comparisons include:\n\n+   `PercentChange(condition_column, baseline)` : Computes the percent change\n    (other - baseline) / baseline.\n+   `AbsoluteChange(condition_column, baseline)` : Computes the absolute change\n    (other - baseline).\n+   `MH(condition_column, baseline, stratified_by)` : Computes the\n    [Mantel-Haenszel estimator](https://en.wikipedia.org/wiki/Cochran%E2%80%93Mantel%E2%80%93Haenszel_statistics).\n    The metric being computed must be a `Ratio` or a `MetricList` of `Ratio`s.\n    The `stratified_by` argument specifies the strata over which the MH\n    estimator is computed.\n\nExample Usage: `... | PercentChange(\"Experiment\", \"Control\")`\n\nNote that `condition_column` can be a list of columns, in which case `baseline`\nshould be a tuple of baselines, one for each condition variable.\n\n#### Standard Errors\n\nA **standard error** operation adds the standard error of the metric\n(or confidence interval) to the point estimate.\n\nBuilt-in standard errors include:\n\n+   `Jackknife(unit, confidence)` : Computes a leave-one-out jackknife estimate\n    of the standard error of the child Metric.\n\n    `unit` is a string for the variable whose unique values will be resampled.\n\n    `confidence` in (0,1) represents the level of the conidence interval;\n    optional\n\n+   `Bootstrap(unit, num_replicates, confidence)` : Computes a bootstrap\n    estimate of the standard error.\n\n    `num_replicates` is the number of bootstrap replicates, default is 10000.\n\n    `unit` is a string for the variable whose unique values will be resampled;\n    if `unit` is not supplied the rows will be the unit.\n\n    `confidence` in (0,1) represents the level of the conidence interval;\n    optional\n\nExample Usage: `... | Jackknife('CookieBucket', confidence=.95)`\n\n#### Distributions\n\nA **distribution** operation produces the distribution of the metric over\na variable.\n\n+   `Distribution(over)`: calculates the distribution of the metric over the\n    variables in `over`; the values are normalized so that they sum to 1. It has\n    an alias `Normalize`.\n+   `CumulativeDistribution(over, order=None, ascending=True)`: calculates the\n    cumulative distribution of the metric over the variables in `over`. The\n    `over` column will be sorted. You can pass in a list of values as a custom\n    `order`. `ascending` determines whether the variables in `over` should be\n    sorted in ascending or descending order.\n\nExample Usage: `Sum(\"Queries\") | Distribution(\"Device\")` calculates the\nproportion of queries that come from each device.\n\n### Data and Slicing\n\nOnce we have specified the metric(s) and operation(s), it is time to\ncompute the analysis on some data. The final step is to pass in the data,\nalong with any variables we want to slice by. The analysis will be carried out\nfor each slice separately.\n\nThe data can be supplied in two forms:\n\n+  a pandas `DataFrame`\n+  a string representing a SQL table or subquery.\n\nExample Usage: `compute_on(df, [\"Country\", \"Device\"])`\n\nExample Usage:\n\n`compute_on_sql(\"SELECT * FROM table WHERE date = '20200101'\", \"Country\")`\n\n#### Customizing the Output Format\n\nWhen calculating multiple metrics, Meterstick will store each metric as a\nseparate column by default. However, it is sometimes more convenient to store\nthe data in a different shape: with one column storing the metric values and\nanother column storing the metric names. This makes it easier to facet by metric\nin packages like `ggplot2` and `altair`. This is known as the \"melted\"\nrepresentation of the data. To return the output in melted form, simply add the\nargument `melted=True` in compute_on() or compute_on_sql().\n\n#### Visualization\n\nIf the last operation applied to the metric is [Jackknife](https://colab.research.google.com/github/google/meterstick/blob/master/meterstick_demo.ipynb#scrollTo=53NI01DoqyDe) or [Bootstrap](https://colab.research.google.com/github/google/meterstick/blob/master/meterstick_demo.ipynb#scrollTo=uKBRJlBBqskw) with\nconfidence, the output can be displayed in a way that highlights significant changes by calling\n`.display()`.\n\n![Rasta-style display of Meterstick result](http://services.google.com/fh/files/misc/confidence_interval_display.png)\n\nYou can customize the `display`. It takes the same arguments as the underlying\nvisualization\n[library](https://colab.research.google.com/github/google/meterstick/blob/master/confidence_interval_display_demo.ipynb).\n\n## SQL\n\nYou can get the SQL query for all built-in Metrics and Operations (except\nweighted Quantile/CV/Correlation/Cov) by calling `to_sql(sql_data_source,\nsplit_by)` on the Metric. `sql_data_source` could be a table or a subquery. The\ndialect it uses is the [standard SQL](https://cloud.google.com/bigquery/docs/reference/standard-sql)\nin Google Cloud's BigQuery. For example,\n\n```python\nMetricList((Sum('X', where='Y > 0'), Sum('X'))).to_sql('table', 'grp')\n```\n\ngives\n\n```sql\nSELECT\n  grp,\n  SUM(IF(Y > 0, X, NULL)) AS `sum(X)`,\n  SUM(X) AS `sum(X)_1`\nFROM table\nGROUP BY grp\n```\n\nVery often what you need is the execution of the SQL query, then you can call\n\n```\ncompute_on_sql(sql_data_source, split_by=None, execute=None, melted=False)\n```\n\ndirectly, which will give you a output similar to `compute_on()`. `execute` is a\nfunction that can execute SQL query.\n\n## Custom Metric\n\nYou can write your own Metric and Operartion. Below is a Metric taken from the demo [colab](https://colab.sandbox.google.com/github/google/meterstick/blob/master/meterstick_demo.ipynb#scrollTo=QFjhj96EdK-r).\nThe Metric fits a LOWESS model.\n\n```python\nimport statsmodels.api as sm\nlowess = sm.nonparametric.lowess\n\nclass Lowess(Metric):\n def __init__(self, x, y, name=None, where=None):\n   self.x = x\n   self.y = y\n   name = name or 'LOWESS(%s ~ %s)' % (y, x)\n   super(Lowess, self).__init__(name, where=where)\n\n def compute(self, data):\n   lowess_fit = pd.DataFrame(\n       lowess(data[self.y], data[self.x]), columns=[self.x, self.y])\n   return lowess_fit.drop_duplicates().reset_index(drop=True)\n```\n\nAs long as the Metric obeys some [rules](https://colab.research.google.com/github/google/meterstick/blob/master/meterstick_demo.ipynb#scrollTo=AQjJAr3YcQB2), it\nwill work with all built-in Metrics and Operations. For example, we can pass it\nto `Jackknife` to get a confidence interval.\n\n```python\njk = Lowess('x', 'y') | Jackknife('cookie', confidence=0.9) | compute_on(df)\npoint_est = jk[('y', 'Value')]\nci_lower = jk[('y', 'Jackknife CI-lower')]\nci_upper = jk[('y', 'Jackknife CI-upper')]\n\nplt.scatter(df.x, df.y)\nplt.plot(x, point_est, c='g')\nplt.fill_between(x, ci_lower, ci_upper, color='g', alpha=0.5)\nplt.show()\n```\n![LOWESS with jackknife](http://services.google.com/fh/files/misc/lowess.png)\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "Apache License 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "meterstick",
    "package_url": "https://pypi.org/project/meterstick/",
    "platform": "",
    "project_url": "https://pypi.org/project/meterstick/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/meterstick/1.1.0/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "A grammar of data analysis",
    "version": "1.1.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 13328987,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "0117a6a111c42b0491e443c4342e9109c91241d806cc93f0a1ca5e875ae391ae",
        "md5": "7c4f95db3dca83376d62beb5d6d67d96",
        "sha256": "b2c5eff5f7c378beeed06478d91b638addf771459fd0001723c15221a2b4438b"
      },
      "downloads": -1,
      "filename": "meterstick-1.1.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "7c4f95db3dca83376d62beb5d6d67d96",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 62938,
      "upload_time": "2021-01-09T10:00:09",
      "upload_time_iso_8601": "2021-01-09T10:00:09.032247Z",
      "url": "https://files.pythonhosted.org/packages/01/17/a6a111c42b0491e443c4342e9109c91241d806cc93f0a1ca5e875ae391ae/meterstick-1.1.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "1d3e54e54cb9ff0471bb9f329f5ca9c6c514b242e15f1022ce395efd3e5913d6",
        "md5": "219ca3853418756edcdbbc594a9f65cb",
        "sha256": "4e357f67116b7e0edd1cf896db9c74e54bc2af557d29f0eec5097ac64c927822"
      },
      "downloads": -1,
      "filename": "meterstick-1.1.0.tar.gz",
      "has_sig": false,
      "md5_digest": "219ca3853418756edcdbbc594a9f65cb",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 61568,
      "upload_time": "2021-01-09T10:00:10",
      "upload_time_iso_8601": "2021-01-09T10:00:10.579012Z",
      "url": "https://files.pythonhosted.org/packages/1d/3e/54e54cb9ff0471bb9f329f5ca9c6c514b242e15f1022ce395efd3e5913d6/meterstick-1.1.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}