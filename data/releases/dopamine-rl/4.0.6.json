{
  "info": {
    "author": "The Dopamine Team",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Intended Audience :: Developers",
      "Intended Audience :: Education",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: Apache Software License",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3 :: Only",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Topic :: Scientific/Engineering",
      "Topic :: Scientific/Engineering :: Artificial Intelligence",
      "Topic :: Scientific/Engineering :: Mathematics",
      "Topic :: Software Development",
      "Topic :: Software Development :: Libraries",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "# Dopamine\n[Getting Started](#getting-started) |\n[Docs][docs] |\n[Baseline Results][baselines] |\n[Changelist](https://google.github.io/dopamine/docs/changelist)\n\n<div align=\"center\">\n  <img src=\"https://google.github.io/dopamine/images/dopamine_logo.png\"><br><br>\n</div>\n\nDopamine is a research framework for fast prototyping of reinforcement learning\nalgorithms. It aims to fill the need for a small, easily grokked codebase in\nwhich users can freely experiment with wild ideas (speculative research).\n\nOur design principles are:\n\n* _Easy experimentation_: Make it easy for new users to run benchmark\n                          experiments.\n* _Flexible development_: Make it easy for new users to try out research ideas.\n* _Compact and reliable_: Provide implementations for a few, battle-tested\n                          algorithms.\n* _Reproducible_: Facilitate reproducibility in results. In particular, our\n                  setup follows the recommendations given by\n                  [Machado et al. (2018)][machado].\n\nDopamine supports the following agents, implemented with jax:\n\n* DQN ([Mnih et al., 2015][dqn])\n* C51 ([Bellemare et al., 2017][c51])\n* Rainbow ([Hessel et al., 2018][rainbow])\n* IQN ([Dabney et al., 2018][iqn])\n* SAC ([Haarnoja et al., 2018][sac])\n\nFor more information on the available agents, see the [docs](https://google.github.io/dopamine/docs).\n\nMany of these agents also have a tensorflow (legacy) implementation, though\nnewly added agents are likely to be jax-only.\n\nThis is not an official Google product.\n\n## Getting Started\n\n\nWe provide docker containers for using Dopamine.\nInstructions can be found [here](https://google.github.io/dopamine/docker/).\n\nAlternatively, Dopamine can be installed from source (preferred) or installed\nwith pip. For either of these methods, continue reading at prerequisites.\n\n### Prerequisites\n\nDopamine supports Atari environments and Mujoco environments. Install the\nenvironments you intend to use before you install Dopamine:\n\n**Atari**\n\n1. Install the atari roms following the instructions from\n[atari-py](https://github.com/openai/atari-py#roms).\n2. `pip install ale-py` (we recommend using a [virtual environment](virtualenv)):\n3. `unzip $ROM_DIR/ROMS.zip -d $ROM_DIR && ale-import-roms $ROM_DIR/ROMS`\n(replace $ROM_DIR with the directory you extracted the ROMs to).\n\n**Mujoco**\n\n1. Install Mujoco and get a license\n[here](https://github.com/openai/mujoco-py#install-mujoco).\n2. Run `pip install mujoco-py` (we recommend using a\n[virtual environment](virtualenv)).\n\n### Installing from Source\n\n\nThe most common way to use Dopamine is to install it from source and modify\nthe source code directly:\n\n```\ngit clone https://github.com/google/dopamine\n```\n\nAfter cloning, install dependencies:\n\n```\npip install -r dopamine/requirements.txt\n```\n\nDopamine supports tensorflow (legacy) and jax (actively maintained) agents.\nView the [Tensorflow documentation](https://www.tensorflow.org/install) for\nmore information on installing tensorflow.\n\nNote: We recommend using a [virtual environment](virtualenv) when working with Dopamine.\n\n### Installing with Pip\n\nNote: We strongly recommend installing from source for most users.\n\nInstalling with pip is simple, but Dopamine is designed to be modified\ndirectly. We recommend installing from source for writing your own experiments.\n\n```\npip install dopamine-rl\n```\n\n### Running tests\n\nYou can test whether the installation was successful by running the following\nfrom the dopamine root directory.\n\n```\nexport PYTHONPATH=$PYTHONPATH:$PWD\npython -m tests.dopamine.atari_init_test\n```\n\n## Next Steps\n\nView the [docs][docs] for more information on training agents.\n\nWe supply [baselines][baselines] for each Dopamine agent.\n\nWe also provide a set of [Colaboratory notebooks](https://github.com/google/dopamine/tree/master/dopamine/colab)\nwhich demonstrate how to use Dopamine.\n\n## References\n\n[Bellemare et al., *The Arcade Learning Environment: An evaluation platform for\ngeneral agents*. Journal of Artificial Intelligence Research, 2013.][ale]\n\n[Machado et al., *Revisiting the Arcade Learning Environment: Evaluation\nProtocols and Open Problems for General Agents*, Journal of Artificial\nIntelligence Research, 2018.][machado]\n\n[Hessel et al., *Rainbow: Combining Improvements in Deep Reinforcement Learning*.\nProceedings of the AAAI Conference on Artificial Intelligence, 2018.][rainbow]\n\n[Mnih et al., *Human-level Control through Deep Reinforcement Learning*. Nature,\n2015.][dqn]\n\n[Schaul et al., *Prioritized Experience Replay*. Proceedings of the International\nConference on Learning Representations, 2016.][prioritized_replay]\n\n[Haarnoja et al., *Soft Actor-Critic Algorithms and Applications*,\narXiv preprint arXiv:1812.05905, 2018.][sac]\n\n## Giving credit\n\nIf you use Dopamine in your work, we ask that you cite our\n[white paper][dopamine_paper]. Here is an example BibTeX entry:\n\n```\n@article{castro18dopamine,\n  author    = {Pablo Samuel Castro and\n               Subhodeep Moitra and\n               Carles Gelada and\n               Saurabh Kumar and\n               Marc G. Bellemare},\n  title     = {Dopamine: {A} {R}esearch {F}ramework for {D}eep {R}einforcement {L}earning},\n  year      = {2018},\n  url       = {http://arxiv.org/abs/1812.06110},\n  archivePrefix = {arXiv}\n}\n```\n\n\n\n[docs]: https://google.github.io/dopamine/docs/\n[baselines]: https://google.github.io/dopamine/baselines\n[machado]: https://jair.org/index.php/jair/article/view/11182\n[ale]: https://jair.org/index.php/jair/article/view/10819\n[dqn]: https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf\n[a3c]: http://proceedings.mlr.press/v48/mniha16.html\n[prioritized_replay]: https://arxiv.org/abs/1511.05952\n[c51]: http://proceedings.mlr.press/v70/bellemare17a.html\n[rainbow]: https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/download/17204/16680\n[iqn]: https://arxiv.org/abs/1806.06923\n[sac]: https://arxiv.org/abs/1812.05905\n[dopamine_paper]: https://arxiv.org/abs/1812.06110\n[vitualenv]: https://docs.python.org/3/library/venv.html#creating-virtual-environments\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/google/dopamine",
    "keywords": "dopamine,reinforcement,machine,learning,research",
    "license": "Apache 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "dopamine-rl",
    "package_url": "https://pypi.org/project/dopamine-rl/",
    "platform": null,
    "project_url": "https://pypi.org/project/dopamine-rl/",
    "project_urls": {
      "Bug Reports": "https://github.com/google/dopamine/issues",
      "Documentation": "https://github.com/google/dopamine",
      "Homepage": "https://github.com/google/dopamine",
      "Source": "https://github.com/google/dopamine"
    },
    "release_url": "https://pypi.org/project/dopamine-rl/4.0.6/",
    "requires_dist": [
      "tensorflow (>=2.2.0)",
      "gin-config (>=0.3.0)",
      "absl-py (>=0.9.0)",
      "opencv-python (>=3.4.8.29)",
      "gym (<=0.25.2)",
      "flax (>=0.2.0)",
      "jax (>=0.1.72)",
      "jaxlib (>=0.1.51)",
      "Pillow (>=7.0.0)",
      "numpy (>=1.16.4)",
      "pygame (>=1.9.2)",
      "pandas (>=0.24.2)",
      "tf-slim (>=1.0)",
      "tensorflow-probability (>=0.13.0)"
    ],
    "requires_python": ">=3.5,<4",
    "summary": "Dopamine: A framework for flexible Reinforcement Learning research",
    "version": "4.0.6",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 15170036,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "c360ffbde96530f0565209199ff40b5c5dc4464a3f55e32f88fa0514f9b2533a",
        "md5": "bf54a6a6cd1f77af67c6f7ceaaab132f",
        "sha256": "1ad057a8c734dc8fe089ce7105bcabc0249a547ed16637553488911327e76123"
      },
      "downloads": -1,
      "filename": "dopamine_rl-4.0.6-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "bf54a6a6cd1f77af67c6f7ceaaab132f",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.5,<4",
      "size": 179563,
      "upload_time": "2022-09-21T20:19:16",
      "upload_time_iso_8601": "2022-09-21T20:19:16.809763Z",
      "url": "https://files.pythonhosted.org/packages/c3/60/ffbde96530f0565209199ff40b5c5dc4464a3f55e32f88fa0514f9b2533a/dopamine_rl-4.0.6-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "ececab07ca64802f209f7dc23a653c91015fb7459fba60866279684ded589725",
        "md5": "358f021fdfedb26f47f313ab2de9a71b",
        "sha256": "eaed747238e7793111b0d5c0e9550e5ebab65ab863370787da67cf5895bd9957"
      },
      "downloads": -1,
      "filename": "dopamine_rl-4.0.6.tar.gz",
      "has_sig": false,
      "md5_digest": "358f021fdfedb26f47f313ab2de9a71b",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.5,<4",
      "size": 118290,
      "upload_time": "2022-09-21T20:19:18",
      "upload_time_iso_8601": "2022-09-21T20:19:18.976964Z",
      "url": "https://files.pythonhosted.org/packages/ec/ec/ab07ca64802f209f7dc23a653c91015fb7459fba60866279684ded589725/dopamine_rl-4.0.6.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}