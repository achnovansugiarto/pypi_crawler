{
  "info": {
    "author": "ParallelM",
    "author_email": "info@parallelm.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: MacOS",
      "Operating System :: POSIX",
      "Operating System :: Unix",
      "Programming Language :: Python :: 2",
      "Programming Language :: Python :: 3"
    ],
    "description": "# README\n\nThe `mlcomp` module is designed to process and run complex PySpark pipelines, which contain\nmultiple PySpark components. These components can be uploaded by the user.\n\n## How to build and upload a component\n\n#### Steps\n\n- Create a folder, whose name corresponds to the component's name (.e.g pi_calc)\n\n- Create a `component.json` file (json format) inside this folder and make sure to fill in all the following\n  fields:\n\n        {\n            \"engineType\": \"PySpark\",\n            \"language\": \"Python\",\n            \"userStandalone\": false,\n            \"name\": \"<Component name (.e.g pi_calc)>\",\n            \"label\": \"<A lable that is displayed in the UI>\",\n            \"version\": \"<Component's version (e.g. 1.0.0)>\",\n            \"group\": \"<One of the valid groups (.e.g \"Algorithms\")>,\n            \"program\": \"<The Python component main script (.e.g pi_calc.py)>\",\n            \"componentClass\": \"<The component class name (.e.g PiCalc)>\",\n            \"useMLStats\": <true|false - whether the components uses mlstats>,\n            \"inputInfo\": [\n                {\n                 \"description\": \"<Description>\",\n                 \"label\": \"<Lable name>\",\n                 \"defaultComponent\": \"\",\n                 \"type\": \"<A type used to verify matching connected legs (e.g 'org.apache.spark.rdd.RDD[int]')>,\n                 \"group\": \"<data|model|prediction|statistics|other>\"\n                },\n                {...}\n            ],\n            \"outputInfo\": [\n                <Same as inputInfo above>\n            ],\n            \"arguments\": [\n                {\n                    \"key\": \"<Unique argument key name>\",\n                    \"type\": \"int|long|float|str|bool\",\n                    \"label\": \"<A lable that is displayed in the UI>\",\n                    \"description\": \"<Description>\",\n                    \"optional\": <true|false>\n                }\n            ]\n        }\n\n- Create the main component script, which contains the component's class name. This class\n  should inherit from a 'Component' base class, which is taken from `parallelm.components.component`.\n  The class must implement the `materialize` function, with this prototype:\n  `def materialize(self, sc, parents_rdds)`. Here is a complete self contained example:\n\n        import numpy as np\n        from parallelm.components.component import Component\n\n\n        class NumGen(Component):\n            num_samples = 0\n\n            def __init__(self):\n                super(self.__class__, self).__init__()\n\n            def materialize(self, sc, parents_rdds):\n                num_samples = self._params['num_samples']\n                self._logger.info(\"Num samples: {}\".format(num_samples))\n\n                rdd = sc.parallelize([0] * num_samples).map(NumGen._rand_num)\n                return [rdd]\n\n            @staticmethod\n            def _rand_num(x):\n                return (np.random.random(), np.random.random())\n\n  Notes:\n    - `num_samples` is an argument to the given component and thus can be read from `self._params`.\n    - A component can use `self._logger` object to print logs. It is defined in the base `Component` class.\n    - In this case the component uses the `numpy` module.\n    - A static function can be used in the `map` api of an `RDD` (.e.g `NumGen._rand_num`).\n\n- Place the components main program (*.py) inside that folder along with any other\n  desired files.\n\n- Pack the folder, using the `tar` tool. The extension should be `.tar`:\n\n        > tar cf pi_calc.tar ./pi_calc\n\n- Use the MLOps center UI to upload the component.\n\n\n**Note:** Complete example components can be found under `./test/comp-to-upload/parallelm/uploaded_components/`\n\n\n## Tools\n\nHandy tools are located under `./bin` folder. These tools are used by the build system\nas well as the testing tools.\n\n\n### create-egg.sh\n\nBuilds and generates new `egg` distribution. The result is placed under `./dist` folder.\n\n\n### cleanup.sh\n\nCleanups all generated products created by the `create-egg.sh`\n\n\n## Testing\n\nThe whole module can be tested by running the `./test/run-test.sh` tool. This tool\ncan be run in either local or external (default) modes.\n\n* Local mode (`--run-locally`) - Run Spark locally with as many worker threads as logical cores on your machine.\n  The local mode means that the Spark is embedded withing the driver itself and does not\n  require an external standalone Spark cluster.\n* External mode (**default**) - Submit the application to a standalone cluster that run on the same\n  machine. It is required to run the spark cluster on the `localhost` interface (It can be\n  achieved by setting an env variable as follows: `SPARK_MASTER_HOST=localhost`).\n  <b>Note: You may also run `<reflex-root>/tools/local-dev/start-externals.sh`, which runs\n  the Spark cluster as necessary.\n\n\n### Example Components\n\nExample components are located under: `./test/comp-to-upload/parallelm/uploaded_components`.\n\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/mlpiper/mlpiper/tree/master/reflex-algos/src/main/python/mlcomp",
    "keywords": "",
    "license": "Apache License 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "ml-comp",
    "package_url": "https://pypi.org/project/ml-comp/",
    "platform": "",
    "project_url": "https://pypi.org/project/ml-comp/",
    "project_urls": {
      "Homepage": "https://github.com/mlpiper/mlpiper/tree/master/reflex-algos/src/main/python/mlcomp"
    },
    "release_url": "https://pypi.org/project/ml-comp/1.0.2/",
    "requires_dist": [
      "ml-ops",
      "termcolor",
      "flask",
      "psutil",
      "py4j",
      "enum"
    ],
    "requires_python": ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*",
    "summary": "An engine for running component based ML pipelines",
    "version": "1.0.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 6199504,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "a5173811c15c97d35551c703b586ba795a5f5fbaaf93559372ea8d059eb93c91",
        "md5": "cac7c8c3b22845c3de5667883b65e6cd",
        "sha256": "363c835d052b7efb72905427b6df788b5f2e06277350c94718b651278848d987"
      },
      "downloads": -1,
      "filename": "ml_comp-1.0.2-py2-none-any.whl",
      "has_sig": false,
      "md5_digest": "cac7c8c3b22845c3de5667883b65e6cd",
      "packagetype": "bdist_wheel",
      "python_version": "py2",
      "requires_python": ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*",
      "size": 79358,
      "upload_time": "2019-02-14T13:10:36",
      "upload_time_iso_8601": "2019-02-14T13:10:36.081742Z",
      "url": "https://files.pythonhosted.org/packages/a5/17/3811c15c97d35551c703b586ba795a5f5fbaaf93559372ea8d059eb93c91/ml_comp-1.0.2-py2-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "ff2ee33e82b11d5d041ba5593d2c078effc9d525ee0317ad53aa4bcd9ea7ea20",
        "md5": "9af4eab0bc6dad5eb90d78a290592694",
        "sha256": "2654f841bcd350813db1d5a8fed6a5ba7e0d81a31d8d580dd0a66a1488db73ba"
      },
      "downloads": -1,
      "filename": "ml_comp-1.0.2-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "9af4eab0bc6dad5eb90d78a290592694",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*",
      "size": 79351,
      "upload_time": "2019-02-14T13:10:38",
      "upload_time_iso_8601": "2019-02-14T13:10:38.256630Z",
      "url": "https://files.pythonhosted.org/packages/ff/2e/e33e82b11d5d041ba5593d2c078effc9d525ee0317ad53aa4bcd9ea7ea20/ml_comp-1.0.2-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "8f63b48b0b827862166af7985616d77342ec7267bcf729bdc50d8fdb3c3efc4e",
        "md5": "e882c5c9760386b2d07c8926c1600ac3",
        "sha256": "1cc4b04c08a188eec62e1431f25817aeda2a8228f66ab8af6e3766e2b5e407b0"
      },
      "downloads": -1,
      "filename": "ml-comp-1.0.2.tar.gz",
      "has_sig": false,
      "md5_digest": "e882c5c9760386b2d07c8926c1600ac3",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*",
      "size": 46458,
      "upload_time": "2019-02-14T13:10:39",
      "upload_time_iso_8601": "2019-02-14T13:10:39.824187Z",
      "url": "https://files.pythonhosted.org/packages/8f/63/b48b0b827862166af7985616d77342ec7267bcf729bdc50d8fdb3c3efc4e/ml-comp-1.0.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}