{
  "info": {
    "author": "TB",
    "author_email": "tim.bleimehl@helmholtz-muenchen.de",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# DZDutils\n\n## About\n\n**Maintainer**: tim.bleimehl@dzd-ev.de\n\n**Licence**: MIT\n\n**Purpose**: Collection of homemade Python tools of the German Center for Diabetes Research\n\n[[_TOC_]]\n\n\n## Install\n\n`pip3 install DZDutils`\n\nor if you need the current dev version:\n\n`pip3 install git+https://git.connect.dzd-ev.de/dzdpythonmodules/dzdutils.git`\n\n\n## Modules\n\n### DZDutils.inspect\n\n#### object2html\n\n[code](https://git.connect.dzd-ev.de/dzdpythonmodules/dzdutils/-/blob/master/DZDutils/inspect/object2html.py#L58)\n\nOpens the webbrowser and let you inspect any object / dict with jquery jsonviewer\n\n```python\nfrom DZDutils.inspect import object2html\nmy_ultra_complex_dict = {\"key\":\"val\"}\nobject2html(my_ultra_complex_dict)\n``` \n\n### DZDutils.list\n\n#### chunks\n\n[code](https://git.connect.dzd-ev.de/dzdpythonmodules/dzdutils/-/blob/master/DZDutils/list.py#L5)\n\nBreaks up a list in shorter lists of given length\n\n```python\nfrom DZDutils.list import chunks\nmy_ultra_long_list = [1,2,3,4,5,6,7,8,9,10]\nfor chunk in chunks(my_ultra_long_list, 3)\n    print(chunk)\n```\n\nOutput:\n\n```python\n[1, 2, 3]\n[4, 5, 6]\n[7, 8, 9]\n[10]\n``` \n\n\n#### divide\n\n[code](https://git.connect.dzd-ev.de/dzdpythonmodules/dzdutils/-/blob/master/DZDutils/list.py#L12)\n\nBreaks up a list in a given amount of shorter lists\n\n```python\nfrom DZDutils.list import divide\nmy_ultra_long_list = [1,2,3,4,5,6,7,8,9,10]\nfor chunk in divide(my_ultra_long_list, 3)\n    print(chunk)\n```\n\nOutput:\n\n```python\n[1, 2, 3, 4]\n[5, 6, 7]\n[8, 9, 10]\n``` \n\n### DZDutils.neo4j\n\n\n#### wait_for_db_boot\n\n[code](https://git.connect.dzd-ev.de/dzdpythonmodules/dzdutils/-/blob/master/DZDutils/neo4j/tools/wait_for_db_boot.py)\n\nWait for a neo4j to boot up. If timeout is expired it will raise the last error of the connection expception for debuging.\nThe argument `neo4j` must be a dict of py2neo.Graph() arguments -> https://py2neo.org/2021.1/profiles.html#individual-settings\n\n```python\nfrom DZDutils.neo4j import wait_for_db_boot\nwait_for_db_boot(neo4j={\"host\": \"localhost\"}, timeout_sec=120)\n```\n\n#### wait_for_index_build_up\n\n[code](https://git.connect.dzd-ev.de/dzdpythonmodules/dzdutils/-/blob/master/DZDutils/neo4j/tools/wait_for_index_build_up.py)\n\nProvide a list of index names and wait for them to be online\n\n```python\nimport py2neo\nfrom DZDutils.neo4j import wait_for_index_build_up\n\ng = py2neo.Graph()\n\ng.run(\"CREATE FULLTEXT INDEX FTI_1 IF NOT EXISTS FOR (n:MyNode) ON EACH [n.my_property]\")\ng.run(\"CREATE INDEX INDEX_2 IF NOT EXISTS FOR (n:MyNode) ON EACH [n.my_property]\")\ng.run(\"CREATE FULLTEXT INDEX FTI_3 IF NOT EXISTS FOR (n:MyNode) ON EACH [n.my_property]\")\n\nwait_for_fulltextindex_build_up(graph=g,index_names=[\"FTI_1\",\"INDEX_2\",\"FTI_3\"])\n\nprint(\"Indexes are usable now\")\n\n```\n\n#### nodes_to_buckets_distributor\n\n[code](https://git.connect.dzd-ev.de/dzdpythonmodules/dzdutils/-/blob/master/DZDutils/neo4j/tools/nodes_to_buckets_distributor.py)\n\nDivide a bunch of nodes into multiple buckets (labels with a prefix and sequential numbering e.b. \"BucketLabel1, BucketLabel2, ...\")\n\nSupply a query return nodes. Get a list of str containg the buckets label names\n\n\n```python\nimport py2neo\nfrom DZDutils.neo4j import nodes_to_buckets_distributor\n\ng = py2neo.Graph()\n\n# Create some testnodes\n\ng.run(f\"UNWIND range(1,10) as i CREATE (:MyNodeLabel)\")\n\nlabels = nodes_to_buckets_distributor(\n            g,\n            query=f\"MATCH (n:MyNodeLabel) return n\",\n            bucket_count=3,\n            bucket_label_prefix=\"Bucket\",\n        )\n\nprint(labels)\n```\nOutput:\n\n`['Bucket0','Bucket1','Bucket2']`\n\nEach of our `:MyNodeLabel`-Nodes has now applied one of the bucket labels\n\n\n#### run_periodic_iterate\n\n[code](https://git.connect.dzd-ev.de/dzdpythonmodules/dzdutils/-/blob/master/DZDutils/neo4j/tools/run_periodic_iterate.py)\n\nAbstraction function for [`apoc.periodic.iterate`](https://neo4j.com/labs/apoc/4.1/overview/apoc.periodic/apoc.periodic.iterate/) with proper error handling and less of the string fumbling\n\n```python\nimport py2neo\nfrom DZDutils.neo4j import run_periodic_iterate\n\ng = py2neo.Graph()\n\n# Create some node per iterate\nrun_periodic_iterate(\n        g,\n        cypherIterate=\"UNWIND range(1,100) as i return i\",\n        cypherAction=\"CREATE (n:_TestNode) SET n.index = i\",\n        parallel=True,\n    )\n\n# set some props per iterate\nrun_periodic_iterate(\n        g,\n        cypherIterate=\"MATCH (n:_TestNode) return n\",\n        cypherAction=\"SET n.prop = 'MyVal'\",\n        parallel=True,\n    )\n```\n\n##### Error Handling\n\nWhen using `apoc.periodic.iterate` manual you have to parse the result table for errors and interpret the result if and how a query failed.\n\n\nWith `run_periodic_iterate` you dont have to anymore.\n\nLets have an example and write some faulty query\n\n```python\nimport py2neo\nfrom DZDutils.neo4j import run_periodic_iterate\n\ng = py2neo.Graph()\n\n# Create some node per iterate\nrun_periodic_iterate(\n        g,\n        cypherIterate=\"UNWIND range(1,100) as i return i\",\n        cypherAction=\"f*** ohnooo i cant write proper cypher\",\n        parallel=True,\n    )\n```\n\nThis will result in an exception: \n\n```\nDZDutils.neo4j.Neo4jPeriodicIterateError: Error on 100 of 100 operations. ErrorMessages:\n\n Invalid input 'f': expected\n  \",\"\n  \"CALL\"\n  \"CREATE\"\n[...]\n  \"WITH\"\n  <EOF> (line 1, column 46 (offset: 45))\n\"UNWIND $_batch AS _batch WITH _batch.i AS i  f*** ohnooo i cant write proper cypher\"\n```\n\nAs wee see we get immediately feedback if and how the query failed\n\n#### LuceneTextCleanerTools\n\n[code](https://git.connect.dzd-ev.de/dzdpythonmodules/dzdutils/-/blob/master/DZDutils/neo4j/LuceneTextCleanerTools.py)\n\n`LuceneTextCleanerTools` is a class with some functions/tools to prepare node properties to be used as input for a lucene fulltext search. \n\ne.g. You want to search for `(:Actor).name` in any `(:Movie).description`. In real word data you will mostly have some noise in the Actor names: \n\n* Some Lucene operators like \"-\" or \"OR\"\n* Or maybe some generic words like \"the\" which will drown any meaningful results\n\nLuceneTextCleanerTools will help you to sanitize your data.\n\nLets get started with a small example\n\n```python\nimport py2neo\nimport graphio\nfrom DZDutils.neo4j import LuceneTextCleanerTools\n\ng = py2neo.Graph()\n\n# lets create some testdata\n\nactorset = graphio.NodeSet([\"Actor\"], [\"name\"])\n# lets assume our actor names came from a messy source;\nfor actor in [\n    \"The\",\n    \"The.Rock\",\n    \"Catherine Zeta-Jones\",\n    \"Keith OR Kevin Schultz\",\n    \"32567221\",\n]:\n    actorset.add_node({\"name\": actor})\nmovieset = graphio.NodeSet([\"Movie\"], [\"name\"])\nfor movie_name, movie_desc in [\n    (\n        \"Hercules\",\n        \"A movie with The Rock and other people. maybe someone is named Keith\",\n    ),\n    (\n        \"The Iron Horse\",\n        \"An old movie with the twin actors Keith and Kevin Schultz. Never seen it; 5 stars nevertheless. its old and the title is cool\",\n    ),\n    (\n        \"Titanic\",\n        \"A movie with The ship titanic and Catherine Zeta-Jones and maybe someone who is named Keith\",\n    ),\n]:\n    movieset.add_node({\"name\": movie_name, \"desc\": movie_desc})\n\nactorset.create_index(g)\nactorset.merge(g)\nmovieset.create_index(g)\nmovieset.merge(g)\n\n# We have our test data. lets start...\n\n# If we now would do create a fulltext index on `(:Movie).desc` and do a search by every actor name and create a relationship on every actor appearing in the description our result would be all over the place\n# e.g.\n#   * `Keith OR Kevin Schultz` would be connected to every movie because Keith comes up in every description. But actually we wanted to match  `Keith OR Kevin Schultz` but `OR` is an lucene operator\n#   * `Catherine Zeta-Jones` would appear in no description because the Hyphen expludes anything with `Jones`\n#   * `The.Rock` would appeat in no description because the data is dirty and there is a dot in his name\n\n# lets sanitize our actor names with LuceneTextCleanerTools\ntxt = LuceneTextCleanerTools(g)\ntxt.create_sanitized_property_for_lucene_index(\n    labels=[\"Actor\"],\n    property=\"name\",\n    target_property=\"name_clean\",\n    min_word_length=2,\n    exlude_num_only=False,\n    to_be_escape_chars=[\"-\"],\n)\n# this will cast our actor names to:\n# * \"The.Rock\" -> \"The Rock\"\n# * \"Catherine Zeta-Jones\" -> \"Catherine Zeta\\-Jones\"\n# * \"Keith OR Kevin Schultz\" -> \"Keith Kevin Schultz\"\n\n#  The new value will be writen into a new property `name_clean`. No information is lost\n\n# optionaly, depending on what we want to do, we also can import common words in many languages\n\ntxt.import_common_words(\n    top_n_words_per_language=4000, min_word_length=2, max_word_length=6\n)\n\n# we can now tag actor names that are not suitable for full text matching\ntxt.find_sanitized_properties_unsuitable_for_lucene_index(\n    match_labels=[\"Actor\"],\n    check_property=\"name_clean\",\n    tag_with_labels=[\"_OmitFullTextMatch\"],\n    match_properties_equal_to_common_word=True,\n)\n\n# this would tag the Actors `32567221` and `the` as unsuitable. these values are obviously garbage or to common to match anything meaningful\n\n# Now we can do our lucene full test matching on clean data :)\n```\n\nFor further actions have a look at `TextIndexBucketProcessor`\n\n#### TextIndexBucketProcessor\n\n[code](https://git.connect.dzd-ev.de/dzdpythonmodules/dzdutils/-/blob/master/DZDutils/neo4j/TextIndexBucketProcessor.py)\n\nRunning a [`db.index.fulltext.queryNodes`](https://neo4j.com/docs/operations-manual/current/reference/procedures/#procedure_db_index_fulltext_querynodes) is a very powerful but also expensiv query.\n\nWhen running `db.index.fulltext.queryNodes` often against a lot of data it wont scale well. \n\nFor example, in our case, finding thousand of genes (and their synonyms) in million of scientific papers will take a very long time.\n\nThe proper solution would be to run multiple queries at a time. But what if you want to generate Nodes and new Relations based on the query result?\n\nYou would end up in node locking situations and wont gain much perfomance or even run in timeouts/deadlocks (depending on your actions and/or setup)\n\nHere is where `TextIndexBucketProcessor` can help you:\n\n`TextIndexBucketProcessor` will seperate you data into multiple \"Buckets\" and do your queries and transforming-actions isolated in these buckets. \n\nYou can now run multiple actions at a time where you usally would end up in Lock situations.\n\nLets have an example:\n(The demodata generator source is [here](https://git.connect.dzd-ev.de/dzdpythonmodules/dzdutils/-/blob/master/DZDutils/neo4j/TextIndexBucketProcessor.py#L190))\n\n```python\nimport py2neo\nfrom DZDutils.neo4j import TextIndexBucketProcessor, create_demo_data\n\n\ng = py2neo.Graph()\n# lets create some testdata first.\n# * We create some nodes `(:AbstractText)` nodes with long texts in the property `text`\n# * We create some nodes `(:Gene)` nodes with gene IDs in the property `sid`\ncreate_demo_data(g)\n# Our goal is now to connect `(:Gene)` nodes to `(:AbstractText)` nodes when the gene sid appears in the abstracts text\n\n# First we create an instance of TextIndexBucketProcessor with a conneciton to our database.\n# `buckets_count_per_collection` defines how many isolated buckets we want to run at one time. In other words: The CPU core count we have on our database available\nti_proc = TextIndexBucketProcessor(graph=g, buckets_count_per_collection=6)\n\n# We add a query which contains the nodes with the words we want to search for\nti_proc.set_iterate_node_collection(\n    name=\"gene\", query=\"MATCH (n:Gene) WHERE NOT n:_OmitMatch return n\"\n)\n\n# Next we add a query which contains the nodes and property name we want to scan.\n# You also replace `fulltext_index_properties` with `text_index_property` to use a CONTAINS query instead of fulltext index\nti_proc.set_text_node_collection(\n    name=\"abstract\",\n    query=\"MATCH (n:AbstractText) return n\",\n    fulltext_index_properties=[\"text\"],\n)\n\n# Now we define the action we want to apply on positive search results, set the property we search for and start our full text index search\n# Mind the names of the nodes: its the name we defined in `add_iterate_node_collection` and `add_fulltext_node_collection`\nti_proc.run_text_index(\n    iterate_property=\"sid\", cypher_action=\"MERGE (abstract)-[r:MENTIONS]->(gene)\"\n)\n\n# At the end we clean up our bucket labels\nti_proc.clean_up()\n```\n\nWe now have connected genes that appear in abstracts and did that process with the use of multiple CPU cores and avoided any nodelocking.\n\nThis was 4-times faster (because of `buckets_count_per_collection=4`) as just loop throug all genes and send them one by one to `db.index.fulltext.queryNodes`\n\n\n> :warning: This is a prove of concept with a very narrow scope. You can not modify the `db.index.fulltext.queryNodes`-call which makes this tool rather unflexibel atm. Expect improvements in future versions :) \n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://git.connect.dzd-ev.de/dzdpythonmodules/dzdutils",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "DZDutils",
    "package_url": "https://pypi.org/project/DZDutils/",
    "platform": null,
    "project_url": "https://pypi.org/project/DZDutils/",
    "project_urls": {
      "Homepage": "https://git.connect.dzd-ev.de/dzdpythonmodules/dzdutils"
    },
    "release_url": "https://pypi.org/project/DZDutils/1.7.0/",
    "requires_dist": [
      "py2neo",
      "numpy",
      "linetimer",
      "graphio",
      "pandas"
    ],
    "requires_python": ">=3.6",
    "summary": "Tool collection from the DZD Devs",
    "version": "1.7.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14973119,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "0353a6b70e6e33e5f522b25eb2e2de7ce0b0dc23b1f9e43ba3857504f51aa0e6",
        "md5": "6021ee45d565c0b4305de769037383e3",
        "sha256": "0e5471a86ae544419514e26eae7b402bffa7dc1ab817cd9ab782fe5f8a5e6665"
      },
      "downloads": -1,
      "filename": "DZDutils-1.7.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "6021ee45d565c0b4305de769037383e3",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 57976,
      "upload_time": "2022-09-01T13:35:03",
      "upload_time_iso_8601": "2022-09-01T13:35:03.633143Z",
      "url": "https://files.pythonhosted.org/packages/03/53/a6b70e6e33e5f522b25eb2e2de7ce0b0dc23b1f9e43ba3857504f51aa0e6/DZDutils-1.7.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "a098268edace14fefd65c8bc3f312e79baf03fca0b925723b132c835f345db7c",
        "md5": "c1e50439382c776a3f275426a614585d",
        "sha256": "c1e32c1ef34f0414205ed2c50ed7253917c4e0999e3db9c7bd6f0cbda507a4cc"
      },
      "downloads": -1,
      "filename": "DZDutils-1.7.0.tar.gz",
      "has_sig": false,
      "md5_digest": "c1e50439382c776a3f275426a614585d",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 56030,
      "upload_time": "2022-09-01T13:35:05",
      "upload_time_iso_8601": "2022-09-01T13:35:05.324883Z",
      "url": "https://files.pythonhosted.org/packages/a0/98/268edace14fefd65c8bc3f312e79baf03fca0b925723b132c835f345db7c/DZDutils-1.7.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}