{
  "info": {
    "author": "MDP Developers",
    "author_email": "mdp-toolkit-devel@lists.sourceforge.net",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Intended Audience :: Developers",
      "Intended Audience :: Education",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: BSD License",
      "Operating System :: OS Independent",
      "Programming Language :: Python",
      "Programming Language :: Python :: 2",
      "Programming Language :: Python :: 3",
      "Topic :: Scientific/Engineering :: Information Analysis",
      "Topic :: Scientific/Engineering :: Mathematics"
    ],
    "description": "**The Modular toolkit for Data Processing (MDP)** package is a library\r\nof widely used data processing algorithms, and the possibility to\r\ncombine them together to form pipelines for building more complex\r\ndata processing software.\r\n\r\nMDP has been designed to be used as-is and as a framework for\r\nscientific data processing development.\r\n\r\nFrom the user's perspective, MDP consists of a collection of *units*,\r\nwhich process data. For example, these include algorithms for\r\nsupervised and unsupervised learning, principal and independent\r\ncomponents analysis and classification.\r\n\r\nThese units can be chained into data processing flows, to create\r\npipelines as well as more complex feed-forward network\r\narchitectures. Given a set of input data, MDP takes care of training\r\nand executing all nodes in the network in the correct order and\r\npassing intermediate data between the nodes. This allows the user to\r\nspecify complex algorithms as a series of simpler data processing\r\nsteps.\r\n\r\nThe number of available algorithms is steadily increasing and includes\r\nsignal processing methods (Principal Component Analysis, Independent\r\nComponent Analysis, Slow Feature Analysis), manifold learning methods\r\n([Hessian] Locally Linear Embedding), several classifiers,\r\nprobabilistic methods (Factor Analysis, RBM), data pre-processing\r\nmethods, and many others.\r\n\r\nParticular care has been taken to make computations efficient in terms\r\nof speed and memory. To reduce the memory footprint, it is possible to\r\nperform learning using batches of data. For large data-sets, it is\r\nalso possible to specify that MDP should use single precision floating\r\npoint numbers rather than double precision ones. Finally, calculations\r\ncan be parallelised using the ``parallel`` subpackage, which offers a\r\nparallel implementation of the basic nodes and flows.\r\n\r\nFrom the developer's perspective, MDP is a framework that makes the\r\nimplementation of new supervised and unsupervised learning algorithms\r\neasy and straightforward. The basic class, ``Node``, takes care of tedious\r\ntasks like numerical type and dimensionality checking, leaving the\r\ndeveloper free to concentrate on the implementation of the learning\r\nand execution phases. Because of the common interface, the node then\r\nautomatically integrates with the rest of the library and can be used\r\nin a network together with other nodes.\r\n\r\nA node can have multiple training phases and even an undetermined\r\nnumber of phases. Multiple training phases mean that the training data\r\nis presented multiple times to the same node. This allows the\r\nimplementation of algorithms that need to collect some statistics on\r\nthe whole input before proceeding with the actual training, and others\r\nthat need to iterate over a training phase until a convergence\r\ncriterion is satisfied. It is possible to train each phase using\r\nchunks of input data if the chunks are given as an iterable. Moreover,\r\ncrash recovery can be optionally enabled, which will save the state of\r\nthe flow in case of a failure for later inspection.\r\n\r\nMDP is distributed under the open source BSD license. It has been\r\nwritten in the context of theoretical research in neuroscience, but it\r\nhas been designed to be helpful in any context where trainable data\r\nprocessing algorithms are used. Its simplicity on the user's side, the\r\nvariety of readily available algorithms, and the reusability of the\r\nimplemented nodes also make it a useful educational tool.\r\n\r\nhttp://mdp-toolkit.sourceforge.net",
    "description_content_type": null,
    "docs_url": null,
    "download_url": "http://sourceforge.net/projects/mdp-toolkit/files/mdp-toolkit/3.0/MDP-3.0.tar.gz/download",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "http://mdp-toolkit.sourceforge.net",
    "keywords": "",
    "license": "http://mdp-toolkit.sourceforge.net/license.html",
    "maintainer": "",
    "maintainer_email": "",
    "name": "MDP",
    "package_url": "https://pypi.org/project/MDP/",
    "platform": "Any",
    "project_url": "https://pypi.org/project/MDP/",
    "project_urls": {
      "Download": "http://sourceforge.net/projects/mdp-toolkit/files/mdp-toolkit/3.0/MDP-3.0.tar.gz/download",
      "Homepage": "http://mdp-toolkit.sourceforge.net"
    },
    "release_url": "https://pypi.org/project/MDP/3.0/",
    "requires_dist": null,
    "requires_python": null,
    "summary": "MDP is a Python library of widely used data processing algorithms that can be combined according to a pipeline analogy to build more complex data processing software. The base of available algorithms includes signal processing methods (Principal Component Analysis, Independent Component Analysis, Slow Feature Analysis), manifold learning methods ([Hessian] Locally Linear Embedding), several classifiers, probabilistic methods (Factor Analysis, RBM), data pre-processing methods, and many others.",
    "version": "3.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 7096179,
  "urls": [],
  "vulnerabilities": []
}