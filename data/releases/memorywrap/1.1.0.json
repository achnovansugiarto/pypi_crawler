{
  "info": {
    "author": "La Rosa Biagio",
    "author_email": "larosa@diag.uniroma1.it",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Description\nMemory Wrap is an extension to image classification models that improves both data-efficiency and model interpretability, adopting a sparse content-attention mechanism between the input and some memories of past training samples.\n\n# Installation\nThis is a PyTorch implementation of Memory Wrap. To install Memory Wrap run the following command:\n```\npip install memorywrap\n```\n\nThe library contains two main classes:\n- *MemoryWrapLayer*: it is the Memory Wrap variant described in the paper that uses both the input encoding and the memory encoding to compute the output;\n- *BaselineMemory*: it is the baseline that uses only the memory encoding to compute the output.\n\n# Usage\n## Instantiate the layer\n```python\nmemorywrap = MemoryWrapLayer(encoder_output_dim, output_dim, head=None, classifier=None, distance='cosine')\n```\nor, for the baseline that uses only the memory to output the prediction:\n```python\nmemorywrap = BaselineMemory(encoder_output_dim, output_dim, head=None, classifier=None, distance='cosine')\n```\nwhere\n- *encoder_output_dim* (int) is the output dimension of the last layer of the encoder \n- *output_dim* (int) is the desired output dimensione. In the case of the paper *output_dim* is equal to the **number of classes**;\n- *head* (torch.nn.Module): Read head used to project the key and query. It can be a linear or non-linear layer. Input dimensions must be equal to encoder_output_dim (in this case 1280). If None, it is fixed as a linear layer with input and output dimension equal to the input dimension of MemoryWrap(encoder_output_dim). (See https://www.nature.com/articles/nature20101 for further information)\n- classifier (torch.nn.Module): Classifier on top of MemoryWrap. Inputs dimensions must be equal at encoder_output_dim*2 for MemoryWrapLayer and encoder_output_dim for BaselineMemory. By default is an MLP as described in the paper. An alternative is to use a linear layer. (e.g. torch.nn.Linear(encoder_output_dim*2, output_dim)\n- distance (str): Distance to use to compute the similarity between input and memory set. Allowed values are: cosine, l2 and dot for respectively cosine similarity, l2 distance and dot product distance. Default=cosine\n## Forward call\nAdd the forward call to your forward function.\n```python\noutput_memorywrap = memorywrap(input_encoding, memory_encoding, return_weights=False)\n```\nwhere *input_encoding* and *memory_encoding* are the outputs of the the encoder of rispectively the current input and the memory set. <br>\nThe last argument of the Memory Wrap's call function is a boolean flag controlling the number of outputs returned. If the flag is True, then the layer returns both the output and the sparse attention weight associated to each memory sample; if the flag is False, then the layer return only the output.\n\n# Additional information\nHere you can find link to additional source of information about Memory Wrap:\n- <a href=\"https://arxiv.org/abs/2106.01440\">Paper</a>\n- <a href=\"https://github.com/KRLGroup/memory-wrap\">GitHub repo</a>\n- <a href=\"https://colab.research.google.com/drive/1OPjcpTH7X8EV1ev361iuhVzd2Jfp9kFA\">Jupyter notebook</a>\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "memorywrap",
    "package_url": "https://pypi.org/project/memorywrap/",
    "platform": "",
    "project_url": "https://pypi.org/project/memorywrap/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/memorywrap/1.1.0/",
    "requires_dist": [
      "entmax",
      "torch (>1.5)"
    ],
    "requires_python": "",
    "summary": "Memory Wrap: an extension for image classification models",
    "version": "1.1.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14666407,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "c6a6ebc8f3a0a3e8004e44fe5b9aef7ac8e20c95e1959456367b4e92dc4d2607",
        "md5": "d18b0a566de52c0c55841e74f1e2b6f8",
        "sha256": "3c33c784a36d7f967f01bb5815318688bc695212ccc1bd1af5d946c5bcd44986"
      },
      "downloads": -1,
      "filename": "memorywrap-1.1.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "d18b0a566de52c0c55841e74f1e2b6f8",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 4656,
      "upload_time": "2021-09-10T16:20:38",
      "upload_time_iso_8601": "2021-09-10T16:20:38.018614Z",
      "url": "https://files.pythonhosted.org/packages/c6/a6/ebc8f3a0a3e8004e44fe5b9aef7ac8e20c95e1959456367b4e92dc4d2607/memorywrap-1.1.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "8c1de46f150987368049f6c850c544ae490767dbd1b0ecaae7bc212a6cdb2c18",
        "md5": "387ae7f61f2bc83a6f1df35234385efa",
        "sha256": "586d7b4a873682b67b440e6a2edaf2fe7ce5265478a9ac16e2546a1147067d34"
      },
      "downloads": -1,
      "filename": "memorywrap-1.1.0.tar.gz",
      "has_sig": false,
      "md5_digest": "387ae7f61f2bc83a6f1df35234385efa",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 4404,
      "upload_time": "2021-09-10T16:20:39",
      "upload_time_iso_8601": "2021-09-10T16:20:39.559651Z",
      "url": "https://files.pythonhosted.org/packages/8c/1d/e46f150987368049f6c850c544ae490767dbd1b0ecaae7bc212a6cdb2c18/memorywrap-1.1.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}