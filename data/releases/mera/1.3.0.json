{
  "info": {
    "author": "EdgeCortix Inc.",
    "author_email": "mera-compiler@edgecortix.com",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.8",
      "Topic :: Scientific/Engineering :: Artificial Intelligence",
      "Topic :: Software Development :: Compilers"
    ],
    "description": "# EdgeCortix&reg; MERA&trade; - A heterogeneous deep learning compiler framework\n\nThis repository contains the source code for the frontend stack of EdgeCortix&reg; MERA™ compiler framework, developed by [EdgeCortix Inc.](https://www.edgecortix.com/). If you are interested in the latest (bleeding edge) capabilities of MERA™ framework and the different Dynamic Neural Accelerator&reg; architecture configurations, contact [EdgeCortix AI Accelerator Team](mailto:dna-ip@edgecortix.com).\n\n![MERA software stack description](https://github.com/Edgecortix-Inc/mera/raw/main/docs/images/MERA_framework.png \"MERA™ software stack\")\n\nThe current release of EdgeCortix&reg; MERA™ supports the following Dynamic Neural Accelerator architectures for FPGAs and ASICs:\n\n| Platform Identifiers | Platform | TOPS |\n|:---------------------:|:------:|:----:|\n|      DNAA800L0001     |  ASIC  |  78 <sub>1</sub>   |\n|      DNAA600L0002     |  ASIC  |  40  |\n|      DNAA400L0001     |  ASIC  | 26.2 |\n|      DNAF132S0001     |  FPGA  |  0.6 |\n|      DNAF232S0002     |  FPGA  |  1.2 |\n|      DNAF100L0003     |  FPGA  |  2.4 |\n|      DNAF632L0003     |  FPGA  |  3.6 |\n|      DNAF200L0003     |  FPGA  |  4.9 |\n\n*Note<sub>1</sub> Recommended frequency for this platform is 1.2GHz*\n\nWhen using a platform identifier corresponding to the ASIC platforms, the recommended minimum frequency setting is 800 MHz. In the case of FPGA platforms, the minimum recommended frequency is 300 MHz. In the above table, the TOPS corresponds to these minimum frequency specifications.\n\n## Installation Guide\n\nThis document describes the steps needed to install MERA in your system.\n\n### Quick installation of MERA on Ubuntu 18.04 LTS\n\nTo install MERA for Python 3.6 and all its dependencies source the provided script:\n\n```bash\nsource install/install-mera-py36.sh\n```\n### Quick installation of MERA on Ubuntu 20.04 LTS\n\nTo install MERA for Python 3.8 and all its dependencies source the provided script:\n\n```bash\nsource install/install-mera-py38.sh\n```\n\n### Manual Installation\n\nIf the `install-mera.sh` script is not enough for your environment, the following section describes how to install\nall the dependencies manually in your system.\n\n#### System Requirements\n\nFor an *x86* architecture, you will need `Ubuntu 18.04` or `Ubuntu 20.04` as your OS, whereas for *aarch64* you will need `Ubuntu 20.04`.\nThe following software packages will also need to be installed:\n\n```bash\nsudo apt update && sudo apt install python3.6 llvm-10 libgomp1 ocl-icd-libopencl1 software-properties-common \\\n    libgoogle-glog0v5 libboost-graph-dev virtualenv wget build-essential\nsudo add-apt-repository ppa:ubuntu-toolchain-r/test\nsudo apt update\nsudo apt install libstdc++6\n```\n\n#### MERA Installation\n\nThe MERA environment provides 3 different modes depending on the target usage:\n\n* `host-only`: Meant for performing deployments only targetting simulation running on the host.\n* `runtime`: Meant for running inference in HW accelerators using the DNA IP, requires extra system dependencies depending on the HW device.\n* `full`: Meant for users who want the functionality of both `host-only` and `runtime` models\n\nMERA pip packages are available for both Python3.6 and Python3.8 variants. Later python versions allow the usage of more up-to-date\nPyTorch and Tensorflow to use for deployments.\n\nAfter choosing the desired mode, you can install MERA with the following command:\n\n```bash\n# Create virtual environment with Python 3.6\nMERA_VENV=mera-env\nvirtualenv -p python3.6 $MERA_VENV\nsource $MERA_VENV/bin/activate\n\n# Install MERA host-only version\npip install --upgrade pip\npip install mera[host-only]\n\n# Install extra dependencies. These are needed to run our tutorials and demos\npip install tqdm easydict wget notebook pandas matplotlib opencv-python gdown seaborn tensorflow_datasets\n\n\n# Test the installation\n$ python -c \"mera --version\"\n>>> Mera Environment Versions:\n      * mera version x.y released on dd/mm/yyyy\n      * mera-tvm version x.y\n      * mera-dna version vx.y+git=<hash>\n```\n\n`mera` provides packages for installing in both *x86* and *aarch64* architectures.\nThe pip command will also install all the necessary dependencies to perform deployments with MERA. Note that some of the tutorials require some extra\ndependencies to be installed. Please check the tutorial's `README.md` file to check which other packages might be needed.\n\n## MERA Documentation\n\nPlease follow the instructions in [docs](docs/) on how to generate the HTML documentation for the MERA framework.\n\n## Introduction to the MERA Software Stack\n\nThe **MERA Software Stack** provides a full end-to-end deployment framework for EdgeCortix DNA platforms. It provides:\n\n * Import models in **PyTorch**, **TensorFlow/TFLite** and **ONNX** formats.\n * Support for **INT8 precision** models quantized with the official built-in quantization tools of PyTorch and TensorFlow.\n * Support for **EdgeCortix custom quantization**: quantize FP32 models from PyTorch, TensorFlow and ONNX using only MERA Quantizer tools.\n * **Multi-network support** allows to fuse several models together into a single workload to maximize hardware utilization. Several models can be compiled and optimized together into a single deployment binary artifact.\n * Several targets to validate models on increasing level optimizations:\n  * **Interpreters** to emulate the DNA platform internal math with minimal amount of optimizations.\n  * **Software simulators** to perform functional and cycle accurate simulations of the MERA DNA platforms on x86 hardware.\n  * Targets to generate binary deployments for **FPGA** and **ASIC**.\n * Different user configurable levels of optimization for fast development, validation and testing.\n * Separate PIP packages for different scenarios. Separate packages for model compilation and inference runtime.\n\n### MERA compiler framework targets\n\nSeveral targets are supported by the MERA Software Stack:\n\n* InterpreterHw: simplest node by node execution of the computational graph with minimal graph fusion and model parameters processing. This target only emulates the way the accelerator IP does the math operations in fixed-point precision.\n\n* Simulator: for this target more passes are enabled and several local and global optimizations are applied to the computational graph. Further lowering into accelerator instructions together with scheduling, allocation, synchronization and instruction encoding produce assembly programs that can be run with the C++ simulator which provides a functional simulation of the selected accelerator IP.\n\n* IP: further encoding into binary instructions and binary artifacts that can be consumed by real hardware. This target is suitable for both FPGA and ASIC IPs. The differences between both are determined in the compiler thanks to the mera.Platform code names that can be specified during compilation as, for example, mera.Platform.DNAF200L0003 for an FPGA IP case or mera.Platform.DNAA600L0002 for an ASIC IP.\n\n* VerilatorSimulator: this target generates binary encoding of the instructions and executes the generated program on a RTL Verilator based cycle accurate library.\n\n### Deploying models with MERA\n\nFor futher details on how to deploy models with MERA software stack please refer to the [tutorials](tutorials/) and the [API reference](QUICK_API_REFERENCE.md).\n\n### Improving inference time\n\nThere are extra compilation options available that can improve the final inference time.\nDuring deployment, it is possible to specify these options as part of the compiler configuration.\nUsually the compilation options provide the IP model for either ASIC or FPGA:\n\n```python\n#\n# Compilation options example for ASIC IP\n#\nwith mera.TVMDeployer(output_dir, overwrite=True) as deployer:\n    model = ...\n    deploy_ip = deployer.deploy(\n        model,\n        mera_platform=Platform.DNAA600L0002,\n        target=Target.IP,\n        host_arch=\"x86)\n\n#\n# Compilation options example for FPGA IP\n#\nwith mera.TVMDeployer(output_dir, overwrite=True) as deployer:\n    model = ...\n    deploy_ip = deployer.deploy(\n        model,\n        mera_platform=Platform.DNAF200L0003,\n        target=Target.IP,\n        host_arch=\"x86)\n```\n\nThese examples assume some default compiler options, in particular, the Fast scheduling mode,\nwhich provides fast compilation times but not the best inference times.\n\n> **_NOTE:_**  To facilitate testing of the MERA software stack all the tutorials and scripts use the fast scheduling mode. To get the best latency for production environments please use the high effort scheduling mode instead.\n\nIn order to improve the performance of our deployments we can specify extra scheduler and memory allocator options, this is known as the Slow scheduler mode. This mode increases the effort made by the scheduler and allocation algorithms to get a better utilization of the DNA IPs by searching better instruction schedules and reducing memory bank conflicts during memory allocation.\n\nExamples of better compiler configuration are:\n\n```python\n#\n# Better compilation options\n#\nbuild_config = {\n  \"compiler_workers\": 4,\n  \"scheduler_config\": {\n    \"mode\": \"Slow\",\n  }\n}\nwith mera.TVMDeployer(output_dir, overwrite=True) as deployer:\n    model = ...\n    deploy_ip = deployer.deploy(\n        model,\n        mera_platform=Platform.DNAA600L0002,\n        target=Target.IP,\n        host_arch=\"x86,\n        build_config=build_config)  # new option\n```\n\nThese options provide a trade off between compilation time and inference time but in general higher compilation time should improve the performance of the model being deployed.\n\n> **_NOTE:_**  There are no changes in neither model accuracy or model outputs while using the different scheduling modes. It is guaranteed that the outputs of a model that has been compiled in two different scheduling modes will be exactly the same.\n\nDepending on the nature of the model there will be different rooms for improvement.\n\n> **_NOTE:_**  During development and early deployment of a model it is recommended to use the fast scheduler mode as this mode will provide the best compilation times. Once the deployment scripts has been validated, switch to the Slow scheduler mode is a trivial change that will only reduce the latency of the model while giving exactly the same model outputs than the fast scheduling mode.\n\n\n### RTL based cycle accurate ASIC simulations\n\nThe C++ IP simulator target (Simulator target) is not cycle accurate. We provide a way to perform a fully cycle accurate ASIC IP simulation through a the target named VerilatorSimulator. Please note that these libraries are not publicly available. Please contact the [EdgeCortix AI Accelerator Team](mailto:dna-ip@edgecortix.com).\n\nIn order to do a cycle accurate simulation it is only necessary to change the target during compilation. We usually choose the Simulator or IP targets:\n\n```python\n#\n# Compile for FPGA IP hardware\n#\nwith mera.TVMDeployer(output_dir, overwrite=True) as deployer:\n    model = ...\n    deploy_ip = deployer.deploy(\n        model,\n        mera_platform=Platform.DNAF200L0003,\n        target=Target.IP,\n        host_arch=\"x86)\n\n#\n# Compile for FPGA IP C++ simulator\n#\nwith mera.TVMDeployer(output_dir, overwrite=True) as deployer:\n    model = ...\n    deploy_ip = deployer.deploy(\n        model,\n        mera_platform=Platform.DNAF200L0003,\n        target=Target.Simulator,\n        host_arch=\"x86)\n```\n\nIn order to compile a model and do a cycle accurate simulation we should choose the following target:\n\n```python\n#\n# Compile for verilator simulator using the DNAA600L0002 ASIC architecture (40 TOPs)\n#\nwith mera.TVMDeployer(output_dir, overwrite=True) as deployer:\n    model = ...\n    deploy_ip = deployer.deploy(\n        model,\n        mera_platform=Platform.DNAA600L0002,\n        target=Target.VerilatorSimulator,\n        host_arch=\"x86)\n```\n\nNote that choosing this target is independent on the scheduler Slow or Fast modes, both can be used for this target but it is recommended to use the Slow (high effort) scheduling mode for the final compilation that will be used to benchmark a model.\n\nIn summary, the required configuration to perform a cycle accurate ASIC IP simulation for the DNAA600L0002 architecture, with high effort scheduling mode, are the following changes:\n\n```python\n#\n# Compile for verilator simulator using the DNAA600L0002 ASIC architecture (40 TOPs)\n# With high effort compilation mode (slow scheduling mode)\n#\nbuild_config = {\n  \"compiler_workers\": 4,\n  \"scheduler_config\": {\n    \"mode\": \"Slow\",\n  }\n}\nwith mera.TVMDeployer(output_dir, overwrite=True) as deployer:\n    model = ...\n    deploy_ip = deployer.deploy(\n        model,\n        mera_platform=Platform.DNAA600L0002,\n        target=Target.VerilatorSimulator,\n        host_arch=\"x86,\n        build_config=build_config)\n```\n\nThe inference times are now more accurate. We observe that in general the Simulator target takes less time to finish a simulation but it will not give us very accurate inference times. While the RTL based simulation will take much longer to complete but will return more accurate inference times. When possible, RTL based simulations in high effort scheduling mode are recommended for model benchmarking.\n\n## MERA Tutorials\nThe [tutorials](tutorials/) folder contains a list of tutorials on how to use the MERA Software Stack to deploy and run inference on typical deep neural network models using both PyTorch and TFLite frameworks. Check the corresponding docs for information about the tutorial contents.\n\n### Tutorial List\n\n- **PyTorch Resnet50 on Simulator** (`pytorch/resnet50_simulator.py`):\n\nContains an example on how to deploy and run a traced `resnet50` model in x86 host simulation.\nCan be executed with the following command:\n\n```\ncd tutorials/pytorch\npython3 resnet50_simulator.py\n```\n\n- **PyTorch Resnet50 on IP** (`pytorch/resnet50_ip.py`):\n\nContains an example on how to deploy and run a traced `resnet50` model in FPGA environment.\nNeeds to have FPGA runtime setup before running.\nCan be executed with the following command:\n\n```\ncd tutorials/pytorch\n# Needs to enable RUN_IP env in order to actually run the tutorial in HW\nRUN_IP=1 python3 resnet50_ip.py\n```\n\n- **TFLite EfficientNet on Simulator** (`tflite/efficientnet_simulator.py`):\n\nContains an example on how to deploy and run a quantized `efficientnet-lite1` and `efficientnet-lite4` model in x86 host simulation and run an example object classification.\nCan be executed with the following command:\n\n```\ncd tutorials/tflite\npython3 efficientnet_simulator.py\n```\n\n- **TFLite EfficientNet on IP** (`tflite/efficientnet_ip.py`):\n\nContains an example on how to deploy and run a quantized `efficientnet-lite1` and `efficientnet-lite4` model in\nFPGA environment and run an example object classification. Needs to have FPGA runtime setup before running.\nCan be executed with the following command:\n\n```\ncd tutorials/tflite\n# Needs to enable RUN_IP env in order to actually run the tutorial in HW\nRUN_IP=1 python3 efficientnet_ip.py\n```\n\n- **Multi-Model Deployment via Simulator** (`multi_models/fused_resnet_mobilenet_simulator.py`):\n\nContains an example on how to fuse two quantized PyTorch models (i.e., `resnet18` and `mobilenet_v2`) and then deploy the fused model in x86 host simulation.\nCan be executed with the following command:\n\n```\ncd tutorials/multi_models\npython3 fused_resnet_mobilenet_simulator.py\n```\n\n## License\n\nThis library is licensed under the Apache License Version 2.0.\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/Edgecortix-Inc/mera",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "mera",
    "package_url": "https://pypi.org/project/mera/",
    "platform": null,
    "project_url": "https://pypi.org/project/mera/",
    "project_urls": {
      "Bug Tracker": "https://github.com/Edgecortix-Inc/mera/issues",
      "Homepage": "https://github.com/Edgecortix-Inc/mera",
      "Web Page": "https://www.edgecortix.com"
    },
    "release_url": "https://pypi.org/project/mera/1.3.0/",
    "requires_dist": [
      "PyYAML",
      "matplotlib",
      "pytest",
      "seaborn",
      "tqdm",
      "mera-tvm-runtime ; extra == 'runtime'"
    ],
    "requires_python": ">=3.6",
    "summary": "An heterogeneous deep learning compiler framework.",
    "version": "1.3.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17079561,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "279b85673285917fefc29dd7cf32ed3f791fe1d93a42d90eb0be2f871b4b7a0a",
        "md5": "503ddc6f549dec6d9ab6f6b86f0ff174",
        "sha256": "08b8762a6149019db4f58953a3f0896b0896269cf689424f4d62a1062cffc6f0"
      },
      "downloads": -1,
      "filename": "mera-1.3.0-py3-none-manylinux_2_27_aarch64.whl",
      "has_sig": false,
      "md5_digest": "503ddc6f549dec6d9ab6f6b86f0ff174",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 34125,
      "upload_time": "2023-01-23T13:24:03",
      "upload_time_iso_8601": "2023-01-23T13:24:03.449282Z",
      "url": "https://files.pythonhosted.org/packages/27/9b/85673285917fefc29dd7cf32ed3f791fe1d93a42d90eb0be2f871b4b7a0a/mera-1.3.0-py3-none-manylinux_2_27_aarch64.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "abe63871d491489939f6499a477ad9a184ddfa952c73055835784125f92cae3a",
        "md5": "061332dd79ff7d6b227de4db6900717e",
        "sha256": "13f2a3453ccfda92f839faf61ad7aba46856c12c8cdf56f095c2653af425e630"
      },
      "downloads": -1,
      "filename": "mera-1.3.0-py3-none-manylinux_2_27_x86_64.whl",
      "has_sig": false,
      "md5_digest": "061332dd79ff7d6b227de4db6900717e",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 34256,
      "upload_time": "2023-01-23T13:24:05",
      "upload_time_iso_8601": "2023-01-23T13:24:05.097759Z",
      "url": "https://files.pythonhosted.org/packages/ab/e6/3871d491489939f6499a477ad9a184ddfa952c73055835784125f92cae3a/mera-1.3.0-py3-none-manylinux_2_27_x86_64.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}