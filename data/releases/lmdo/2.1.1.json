{
  "info": {
    "author": "Roger Liang",
    "author_email": "pinguroger@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Developers",
      "License :: OSI Approved :: Apache Software License",
      "Natural Language :: English",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 2",
      "Programming Language :: Python :: 2.6",
      "Programming Language :: Python :: 2.7",
      "Topic :: Utilities"
    ],
    "description": "lmdo\n====\nA CD/CI tool for developing micro-services components using AWS Lambda function (python2.7) and managing other AWS resources.\n\nInspirations\n------------\n[Apex](https://github.com/apex/apex),  [Serverless](https://github.com/serverless/serverless),\n[Zappa](https://github.com/Miserlou/Zappa),\n[sceptre](https://github.com/cloudreach/sceptre)\n\nWhy\n---\nMost of the open-source apps are very much opinionated and the model they employ doesn't always fit for the actual individual use case. In fact, there aren't a lot of flexibility provided. In addition, abstraction makes it hard to diagnose issues.\n\nThe tool I have in mind should allow raw inputs, be atomic, has important functionalities like the others and easy to use to a certain degree (You need to know what you are doing. E.g. I don't expect you to use it for creating stack if you don't know how to write a raw CloudFormation). Hence born lmdo.   \n\nFeatures\n--------\n- Initialize project via Github boiler plate\n- Use of CloudFormation templates in either json or yaml format\n- Use of CloudFormation paramter files in either json or yaml format\n- Manage one or more CloudFormation stacks\n- Use of swagger template for API Gateway\n- Manage API Gateway resources like deployments and stages\n- Automatically generate API Gateway for Lambda functions\n- Manage life cycles of AWS Lambda functions\n- Offer two type of managed Lambda functions: Django wsgi wrapper and CloudWatch Event scheduler dispatcher\n- Maintain Lambda function heart beat\n- CloudWatch log output on CL\n- Upload any files to S3 bucket\n\nContents:\n---------\n1. [Installation](#installation)\n2. [Project initiation](#project-initiation)\n3. [Basic configuration](#basic-configuration)\n4. [One step deployment](#one-step-deployment)\n5. [CloudFormation](#cloudformation)\n4. [Lambda function](#lambda-function)\n5. [API Gateway](#api-gateway)\n6. [CloudWatch events](#cloudwatch-events)\n7. [CloudWatch logs](#cloudwatch-logs)\n8. [S3 Upload](#s3-upload)\n\nInstallation\n------------\nInstalling via pypi:\n\n    $ sudo pip install lmdo\n\nInstalling via code (Recommended, as lmdo is under active development at the moment):\n\n    $ git pull https://github.com/MerlinTechnology/lmdo.git\n    $ cd lmdo\n    $ sudo pip install -U ./\n\n**Note**: All lmdo commands need to be run at the same directory of the `lmdo.yaml` file\n\nProject Initiation\n------------------\nTo initiate your project, run:\n\n    $ lmdo init <project_name>\n\nThis will create you named project folder and the sample lmdo configuration file `lmdo.yaml`.\n\nIf you already have an existing project, you can run:\n\n    $ lmdo init config\n\nThe configuration file `lmdo.yaml` will be copied to your current directory. If there is already one, the new configuration file will be renamed to `lmdo.yaml.copy`\n\nTo start a project by using a github boiler plate, run:\n\n    $ lmdo bp fetch <url>\n\nThe repo will then be copied from github to your current project folder without all the git folders or files\n\n\nBasic Configuration\n-------------------\n1. AWS credentials\n\n    You can either use session (`Profile`) or configure AWS key and secret (`Region, AWSKey, AWSSecret`) in `lmdo.yaml`\n\n    When using session, you will need to create two files:\n\n        ~/.aws/config and ~/.aws/credentials\n\n    Details please ref to [AWS CLI](http://docs.aws.amazon.com/cli/latest/userguide/cli-chap-getting-started.html)\n\n    **Note**: If explicitly using config options `Region, AWSKey, AWSSecret`, it's recommended to define them in the environment. Using syntax like `$env|YOUR_ENV_VAR` lmdo will replace them with the actual environment value.\n\n2. Other mandatory configuration Options\n\n    `Service`: The name of your service/project\n\n    `User`: The user that deploys the service/project\n\n    `Stage`: The deployment stage\n\n\nOne Step Deployment\n-------------------\nTo deploy your entire service, run:\n\n    $ lmdo deploy\n\nTo delete, run:\n\n    $ lmdo destroy\n\n\nCloudFormation\n--------------\n### Available reserved utility variables (`WARNING`, see Note)\nThey will be replaced with correct value during deployment\n\n`$env|ENV_VAR_NAME`: Environment variables, can be used both in parameters and templates.\n\n`$template|template-file-name`: Nested stack template to be used to construct proper S3 bucket url for stack resource `TemplateURL`, mostly used in templates.\n\n`$stack|stack-name::output-key`: The value of an existing stack's output based on key name. Can be used both in parameters and templates.\n\n**Note**: \n\n- the stack referring to must exist before deployment. \n- Recommand to avoid use those variable in the template so to keep the template complying to AWS. Instead, use those variables in the parameter file to pass in as parameters\n\n### Configuration examples:\n\n1. Single CloudFormation template without parameters\n\n    ```    \n    CloudFormation:\n        Stacks:\n            - Name: your-stack-name\n              TemplatePath: relative/path/to/template            \n    ```        \n\n2. Single CloudFormation template with parameters. You can either provide a single file or a directory that contains all the parameter files. If a directory is provided, lmdo will combine all files into one during deployment.\n\n    ```\n    CloudFormation:\n        Stacks:\n            - Name: your-stack-name\n              TemplatePath: relative/path/to/template  \n              ParamsPath: relative/path/to/params/file/or/directory\n    ```\n\n3. CloudFormation using S3 bucket\n\n    ```\n    CloudFormation:\n        S3Bucket: your.bucket.url\n        Stacks:\n            - Name: your-stack-name\n              TemplatePath: relative/path/to/template  \n              ParamsPath: relative/path/to/params/file/or/directory\n    ```  \n\n4. Single CloudFormation template with nested stacks\n\n    ```\n    CloudFormation:\n        S3Bucket: your.bucket.url\n        TemplateRepoPath: relative/path/to/nested/stack/template/directory\n        Stacks:\n            - Name: your-stack-name\n              TemplatePath: relative/path/to/template  \n              ParamsPath: relative/path/to/params/file/or/directory\n    ```       \n\n    **Note**:\n\n    a. You must provide `S3Bucket` for nested stacks as it'll be used for uploading all the templates to.\n\n    b. All nested stack templates must reside in `TemplateRepoPath`. If not given, lmdo will look for nested stack template (see point **c** below) from the project folder by default.\n\n    c. Using syntax like `TemplateURL: $template|your-nested-stack-template-file-name` in your master template stack resource, lmdo will replace the syntax to appropriate S3 url.\n    \n    d. You can use `DisablePrefix` option to create stack with exact name you give\n\n5. Multiple CloudFormation Stacks\n\n    ```\n    CloudFormation:\n        S3Bucket: your.bucket.url\n        TemplateRepoPath: relative/path/to/nested/stack/template/directory\n        Stacks:\n            - Name: your-stack-name-1\n              TemplatePath: relative/path/to/template-1  \n              ParamsPath: relative/path/to/params/file-1/or/directory-1\n            - Name: your-stack-name-2\n              TemplatePath: relative/path/to/template-2  \n              ParamsPath: relative/path/to/params/file-2/or/directory-2            \n    ```\n\n### Parameter file\nParameter file can be in either `.json` or `.yaml` format.\n\nFor json file, you can use two types of syntax:\n\n1. Standard AWS stack parameter format\n\n    ```\n    [\n        {\n            \"ParameterKey\": \"your-parameter-key-1\",\n            \"ParameterValue\": \"your-parameter-value-1\"\n        },\n        {\n            \"ParameterKey\": \"your-parameter-key-2\",\n            \"ParameterValue\": \"your-parameter-value-2\"\n        }            \n    ]\n    ```\n\n2. lmdo json format\n\n    ```\n    {\n        \"your-parameter-key-1\": \"your-parameter-value-1\",\n        \"your-parameter-key-2\": \"your-parameter-value-2\"\n    }\n    ```\n\n3. For yaml file, the format as follow:\n    \n    ```\n    your-parameter-key-1: your-parameter-value-1\n    your-parameter-key-2: your-parameter-value-2\n    ```\n\n4. Available reserved utility variables\n\n    They will be replaced with correct value during deployment\n\n    `$env|ENV_VAR_NAME`: Environment variables, can be used both in parameters and templates.\n\n    `$stack|stack-name::output-key`: The value of an existing stack's output based on key name. Can be used both in parameters and templates.\n    \n    `$template|template-file-name`: Nested stack template to be used to construct proper S3 bucket url for stack resource   `TemplateURL`, mostly used in templates.\n\n    **Note**: \n  \n    The stack referring to must exist before deployment.\n  \n    For `CommaDelimitedList` type, you can do `\"$env|ENV_VAR_NAME1, $env|ENV_VAR_NAME2\"`. Same to `$stack|*`.\n   \n### Commands\n\nTo create your CloudFormation, run:\n\n    $ lmdo cf create\n\nTo update or delete, run the similar command using `update` or `delete` keyword\n\nTo use change-set instead of directly update stack, use `-c` or `--change_set` option:\n\n    $ lmdo cf create -c\n\nStack event will be output by default, if you want to hide it,  use `-he` or `--hide-event` option:\n\n    $ lmdo cf create -he\n\nFor only change one specific stack, use option `--stack=`\n\n\nLambda Function\n---------------\nlmdo facilitates packaging, uploading and managing your lambda function. Out of box, it also provides support for two types of lambda function wrapper: wsgi and event dispatcher apart from the standard Lambda function.\n\n### Basic configuration structure\n\n\n    VirtualEnv: False\n    Lambda:\n        - function-1 configuration\n        - function-2 configuration\n        ...\n\n**Note**:\n- If you are using virtualenv, please set `VirtualEnv` to `True`\n- The actual deployed function name created by lmdo will be using `<user>-<stage>-<service-name>-<FunctionName>`\n\n### Optional configurations and their default values available for all function types\n\n`Type`: default `default`. Other availabe types are `wsgi` and `cron_dispatcher`\n\n`MemorySize`: default `128`\n\n`Runtime`: default `python2.7` (Note: lmdo only support python at the moment)\n\n`Timeout`: default `180`\n\n`HeatUp`: default `False`. Provide CPR for lambda function to keep container alive. Only avaiable for `wsgi` and `default` functions.\n\n`HeatRate`: default `rate(4 minutes)` before container becomes inactive. Only avaiable for `wsgi` and `default` functions.\n\nVPC configuration:\n\n    VpcConfig:                          \n        SecurityGroupIds:\n            - security-group-id-1\n            - security-group-id-2\n        SubnetIds:\n            - subnet-id-1\n            - subnet-id-2\n\nRuntime environment variables\n\n    EnvironmentVariables:          \n        MYSQL_HOST: host-url\n        MYSQL_PASSWORD: password\n        MYSQL_USERNAME: username\n        MYSQL_DATABASE: dbname\n\nRole and policies:\n\n    RoleArn: your-role-arn\n\nor\n\n    RolePolicy:                         \n        AssumeRoles:                    \n            - sns.amazonaws.com         \n        PolicyDocument: file/path/to/your/policy\n        ManagedPolicyArns:             \n            - your-managed-policy-arn      \n\n**Note**:\n- `$region` and `$accountId` are available to use in your `PolicyDocument` so you don't need to hard-code them\n- Only one of `RoleArn` and `RolePolicy` required.\n- If both provided, `RolePolicy` takes over.\n- If none provided, lmdo will create a default role with default policy\n- the default role will assume role of apigateway, lambda, events, ec2.\n- the default policy will allow `lambda:InvokeFunction`, `lambda:AddPermission`, `lambda:RemovePermission` on the lambda function, `log:CreateLogGroup`, `logs:CreateLogStream`, `logs:PutLogEvents`, `ec2:DescribeNetworkInterfaces`, `ec2:CreateNetworkInterface` and `ec2:DeleteNetworkInterface` actions    \n- Only extra assume roles and policies need to be configured other than the default\n\n### Examples\n1. Standard lambda function\n\n    Requirements:\n\n    The invokable lambda function files need to be placed on the top level of the project folder.\n\n    Put all your dependent packages in `requirements.txt`\n\n    Configuration:\n\n    ```\n    Lambda:\n        - S3Bucket: lambda.bucket.name\n          FunctionName: your-function-name\n          Handler: handler.fly                \n    ```\n\n2. Django wsgi lambda function\n\n    It wraps up Django and bridge between API gateway and your Django\n\n    Requirements:\n\n    Put all your dependent packages in `requirements.txt`\n\n    Optional configuration:\n\n    `CognitoUserPoolId`: It will set the API gateway authentication if provided. You can only have one per `ApiBasePath`\n\n    Configuration:\n\n    ```\n    Lambda:\n        - S3Bucket: lambda.bucket.name       \n          Type: wsgi                       \n          DisableApiGateway: False            \n          ApiBasePath: /path                  \n          FunctionName: your-function-name         \n          EnvironmentVariables:              \n              DJANGO_SETTINGS_MODULE: mysite.settings\n    ```\n\n    **Note**:\n\n    By default, `DisableApiGateway` is set to `False`. You must set your `ApiBasePath` when it's `False`\n\n    `DJANGO_SETTINGS_MODULE` environment variable is a must for it to work\n\n3. Cron dispatcher\n\n    Cron dispatcher function allows you to create multiple event schedulers on different functions via a single dispatcher.\n    **Note**: lmdo will construct rule name based on `<user>-<stage>-<service-name>-<FunctionName>--<handler>`. CloudWatch events rule name can only be within 64 characters, so mind your names.\n\n    Configuration:\n\n    ```\n    Lambda:\n        - S3Bucket: lambda.bucket.name      \n          Type: cron_dispatcher                     \n          FunctionName: your-dispatcher-name            \n          RuleHandlers:\n              - Handler: your.module.handler\n                Rate: your cron string e.g. Rate(1 minutes)\n    ```\n\n### Available reserved utility variables\n\nThey will be replaced with correct value during deployment\n\n`$stack|stack-name::output-key`: The value of an existing stack's output based on key name. Can be used both in parameters and templates.\n\n**Note**: \n  \nThe stack referring to MUST exist before deployment.\n  \nFor `CommaDelimitedList` type, you can do `\"$stack|stack-name::key1, $stack|stack-name::key2\"`.\n\n### Commands\n\nTo create all functions, run (update/delete similar):\n\n    $ lmdo lm create\n\nOptions:\n`--function-name`: Only action on a particular function\n\nTo package the function only:\n\n    $ lmdo package --function-name=your-function-name\n \nAPI Gateway\n---------------\nSwagger template is used to create API Gateway\n\n### Requirments\n\n* A folder named 'swagger' under your project folder\n* Name your swagger template as `apigateway.json`\n\n### Configuration\n\n    ApiGatewayName: Your unique Apigateway name\n\nOptionally, you can use `ApiVarMapToFile` to map your custom key to a file for replacement\n\n    ApiVarMapToFile:                   \n        $mappingKey: file/path/name               \n\nYou can also use `ApiVarMapToVar` to map any string values to your defined key. For this mapping, you can also use `$stack` and `$lambda-arn` utitlity variable for the value.\n\n    ApiVarMapToVar:\n        $mappingKey1: value\n        $mappingKey2: $stack|stack-name::key1\n        $mappingKey3: $lambda-arn|lambda-name\n\n\n**NOTE:** Please name your version as `$version` and your title as `$title` so that Lmdo can update it during creation using the value of `ApiGatewayName` in your lmdo.yaml\n\n### Commands\n\nTo manage your APIGateway resource, run(update/delete similar):\n\n    $ lmdo api create\n\nYou can create or delete a stage by running:\n\n    $ lmdo api create-stage <from_stage> <to_stage>\n\nor\n\n    $ lmdo api delete-stage <from_stage>\n\nCloudWatch events\n-----------------\n\n### Configuration\n\n    CloudWatchEvent:\n        - Name: rule_name                          \n          ScheduleExpression: [schedule-expression]  \n          EventPatternFile: [path/to/pattern/file] \n          Targets:                                  \n              - Type: default                        \n                Arn: aws-resource-arn\n              - Type: local                          \n                FunctionName: local-function-name\n                \n`[schedule-expression]`: http://docs.aws.amazon.com/AmazonCloudWatch/latest/events/ScheduledEvents.html\n`[path/to/pattern/file]`: http://docs.aws.amazon.com/AmazonCloudWatch/latest/events/CloudWatchEventsandEventPatterns.html\n\nOptions:\n\n`Description`: description of your rule\n\n`DisablePrefix`: default to `False`. If `True`, lmdo will use your rule name instead of using `<user>-<stage>-<service-name>-<rule_name>`\n\n`RoleArn`: default lmdo will create lambda invokable role\n\n**Note**\n\nWhen target type is `local`, lmdo will replace it with your function ARN\n\n\nCloudWatch Logs\n-------------------\n\n### Commands\n\nYou can tail any AWS cloudwatch group logs by running:\n\n    $ lmdo logs tail your_log_group_name\n\n`--day`: defines how many days ago the logs need to be retrieved\n\n`--start-date` or `--end-date`: specify a start date and/or end date for the log entries using format `YYYY-MM-DD`\n\nYou can also tail logs of your lambda function in your project by running:\n\n    $ lmdo logs tail function your-function-name\n\n`your-function-name` is the function name you configure in your lmdo.yaml\n\nS3 Upload\n------\n\nlmdo offers a simple command line to upload your local static asset into a S3 bucket.\n\n### Configuration\n\n    AssetS3Bucket: your.bucket.url\n    AssetDirectory: directory/where/your/assets/in\n\n### Commands\n\nTo upload (Note: it doesn't delete files):\n\n    $ lmdo s3 sync",
    "description_content_type": null,
    "docs_url": null,
    "download_url": "UNKNOWN",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/liangrog/lmdo",
    "keywords": "cli",
    "license": "MIT",
    "maintainer": null,
    "maintainer_email": null,
    "name": "lmdo",
    "package_url": "https://pypi.org/project/lmdo/",
    "platform": "UNKNOWN",
    "project_url": "https://pypi.org/project/lmdo/",
    "project_urls": {
      "Download": "UNKNOWN",
      "Homepage": "https://github.com/liangrog/lmdo"
    },
    "release_url": "https://pypi.org/project/lmdo/2.1.1/",
    "requires_dist": null,
    "requires_python": null,
    "summary": "CLI tools for microservices automation using AWS Lambda function",
    "version": "2.1.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 4096566,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "2d107dd8fd011f2de81314ccbf82cc811153a88203822d2cdab549d36ba3539b",
        "md5": "b8b51bd34ecebe79fc3fceb2689ec605",
        "sha256": "5f0afc3c0e57010797577aed07b80e20e204fa740290d1e95641f421a7d82e35"
      },
      "downloads": -1,
      "filename": "lmdo-2.1.1.tar.gz",
      "has_sig": false,
      "md5_digest": "b8b51bd34ecebe79fc3fceb2689ec605",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 54913,
      "upload_time": "2017-04-19T05:29:50",
      "upload_time_iso_8601": "2017-04-19T05:29:50.810646Z",
      "url": "https://files.pythonhosted.org/packages/2d/10/7dd8fd011f2de81314ccbf82cc811153a88203822d2cdab549d36ba3539b/lmdo-2.1.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}