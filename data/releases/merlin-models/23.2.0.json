{
  "info": {
    "author": "NVIDIA Corporation",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: Apache Software License",
      "Programming Language :: Python :: 3",
      "Topic :: Scientific/Engineering",
      "Topic :: Software Development :: Libraries"
    ],
    "description": "## Merlin Models\n\n[![PyPI version shields.io](https://img.shields.io/pypi/v/merlin-models.svg)](https://pypi.python.org/pypi/merlin-models/)\n![GitHub License](https://img.shields.io/github/license/NVIDIA-Merlin/models)\n[![Documentation](https://img.shields.io/badge/documentation-blue.svg)](https://nvidia-merlin.github.io/models/main/)\n\nThe Merlin Models library provides standard models for recommender systems with an aim for high-quality implementations\nthat range from classic machine learning models to highly-advanced deep learning models.\n\nThe goal of this library is to make it easy for users in the industry to train and deploy recommender models with the best\npractices that are already baked into the library. The library simplifies how users in the industry can train standard models against their dataset and put high-performance, GPU-accelerated models into production. The library also enables researchers to build custom\nmodels by incorporating standard components of deep learning recommender models and then researchers can benchmark the new models on\nexample offline\ndatasets.\n\nIn our initial releases, Merlin Models features a TensorFlow API. The PyTorch API is initiated, but incomplete. We have PyTorch support for transformer-based, session-based recommender systems in the [Transformer4Rec](https://github.com/NVIDIA-Merlin/Transformers4Rec/) library.\n\n### Benefits of Merlin Models\n\n**[RecSys model implementations](https://nvidia-merlin.github.io/models/main/models_overview.html)** - The library provides a high-level API for classic and state-of-the-art deep learning architectures for recommender models.\nThese models include both retrieval (e.g. Matrix Factorization, Two tower, YouTube DNN, ..) and ranking (e.g. DLRM, DCN-v2, DeepFM, ...) models.\n\n**Building blocks** - Within Merlin Models, recommender models are built on reusable building blocks.\nThe design makes it easy to combine the blocks to define new architectures.\nThe library provides model definition blocks (MLP layers, factorization layers, input blocks, negative samplers, loss functions), training models (data loaders from Parquet files), and evaluation (e.g. ranking metrics).\n\n**Integration with Merlin platform** - Merlin Models is deeply integrated with the other Merlin components.\nFor example, models depend on NVTabular for pre-processing and integrate easily with Merlin Systems for inference.\nThe thoughtfully-designed integration makes it straightforward to build performant end-to-end RecSys pipelines.\n\n**[Merlin Models DataLoaders](https://nvidia-merlin.github.io/models/main/api.html#loader-utility-functions)** - Merlin provides seamless integration with common deep learning frameworks, such as TensorFlow, PyTorch, and HugeCTR.\nWhen training deep learning recommender system models, data loading can be a bottleneck.\nTo address the challenge, Merlin has custom, highly-optimized dataloaders to accelerate existing TensorFlow and PyTorch training pipelines.\nThe Merlin dataloaders can lead to a speedup that is nine times faster than the same training pipeline used with the GPU.\n\nWith the Merlin dataloaders, you can:\n\n- Remove bottlenecks from data loading by processing large chunks of data at a time instead of item by item.\n- Process datasets that don't fit within the GPU or CPU memory by streaming from the disk.\n- Prepare batches asynchronously into the GPU to avoid CPU-to-GPU communication.\n- Integrate easily into existing TensorFlow or PyTorch training pipelines by using a similar API.\n\nTo learn about the core features of Merlin Models, see the [Models Overview](https://nvidia-merlin.github.io/models/main/models_overview.html) page.\n\n### Installation\n\n#### Installing Merlin Models Using Pip\n\nMerlin Models can be installed with `pip` by running the following command:\n\n```shell\npip install merlin-models\n```\n\n> Installing Merlin Models with `pip` does not install some additional GPU dependencies, such as the CUDA Toolkit.\n> When you run Merlin Models in one of our Docker containers, the dependencies are already installed.\n\n#### Docker Containers that include Merlin Models\n\nMerlin Models is included in the Merlin Containers.\n\nRefer to the [Merlin Containers](https://nvidia-merlin.github.io/Merlin/main/containers.html) documentation page for information about the Merlin container names, URLs to the container images on the NVIDIA GPU Cloud catalog, and key Merlin components.\n\n#### Installing Merlin Models from Source\n\nMerlin Models can be installed from source by running the following commands:\n\n```shell\ngit clone https://github.com/NVIDIA-Merlin/models\ncd models && pip install -e .\n```\n\n### Getting Started\n\nMerlin Models makes it straightforward to define architectures that adapt to different input features.\nThis adaptability is provided by building on a core feature of the NVTabular library.\nWhen you use NVTabular for feature engineering, NVTabular creates a schema that identifies the input features.\nYou can see the `Schema` object in action by looking at the [From ETL to Training RecSys models - NVTabular and Merlin Models integrated example](https://nvidia-merlin.github.io/models/main/examples/02-Merlin-Models-and-NVTabular-integration.html) example notebook.\n\nYou can easily build popular RecSys architectures like [DLRM](http://arxiv.org/abs/1906.00091), as shown in the following code sample.\nAfter you define the model, you can train and evaluate it with a typical Keras model.\n\n```python\nimport merlin.models.tf as mm\nfrom merlin.io.dataset import Dataset\n\ntrain = Dataset(PATH_TO_TRAIN_DATA)\nvalid = Dataset(PATH_TO_VALID_DATA)\n\nmodel = mm.DLRMModel(\n    train.schema,                                                   # 1\n    embedding_dim=64,\n    bottom_block=mm.MLPBlock([128, 64]),                            # 2\n    top_block=mm.MLPBlock([128, 64, 32]),\n    prediction_tasks=mm.BinaryClassificationTask(train.schema)      # 3\n)\n\nmodel.compile(optimizer=\"adagrad\", run_eagerly=False)\nmodel.fit(train, validation_data=valid, batch_size=1024)\neval_metrics = model.evaluate(valid, batch_size=1024, return_dict=True)\n```\n\n1.  To build the internal input layer, the model identifies them from the schema object.\n    The schema identifies the continuous features and categorical features, for which embedding tables are created.\n2.  To define the body of the architecture, MLP layers are used with configurable dimensions.\n3.  The head of the architecture is created from the chosen task, `BinaryClassificationTask` in this example.\n    The target binary feature is also inferred from the schema (i.e., tagged as 'TARGET').\n\nYou can find more details and information about a low-level API in our overview of the\n[Deep Learning Recommender Model](https://nvidia-merlin.github.io/models/main/models_overview.html#deep-learning-recommender-model).\n\n### Notebook Examples and Tutorials\n\nView the example notebooks in the [documentation](https://nvidia-merlin.github.io/models/main/examples/README.html) to help you become familiar with Merlin Models.\n\nThe same notebooks are available in the `examples` directory from the [Merlin Models](https://github.com/NVIDIA-Merlin/models) GitHub repostory.\n\n### Feedback and Support\n\nIf you'd like to contribute to the library directly, see the [CONTRIBUTING.md](CONTRIBUTING.md) file.\nWe're particularly interested in contributions or feature requests for our feature engineering and preprocessing operations.\nTo further advance our Merlin Roadmap, we encourage you to share all the details regarding your recommender system pipeline in this [survey](https://developer.nvidia.com/merlin-devzone-survey).",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/NVIDIA-Merlin/models",
    "keywords": "",
    "license": "Apache 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "merlin-models",
    "package_url": "https://pypi.org/project/merlin-models/",
    "platform": null,
    "project_url": "https://pypi.org/project/merlin-models/",
    "project_urls": {
      "Homepage": "https://github.com/NVIDIA-Merlin/models"
    },
    "release_url": "https://pypi.org/project/merlin-models/23.2.0/",
    "requires_dist": null,
    "requires_python": ">=3.8",
    "summary": "Merlin recommender system models",
    "version": "23.2.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17210159,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "916448c628ad667d8e66d0e7f1093407e658e82ee5e0ce8d7751e7a62b5331eb",
        "md5": "9c8e5de3b43c49a343ce92c3b5290309",
        "sha256": "4a7e55576e019fe2b9f8ee1627e421194c477d43406c932f938c1ffc99981eb9"
      },
      "downloads": -1,
      "filename": "merlin-models-23.2.0.tar.gz",
      "has_sig": false,
      "md5_digest": "9c8e5de3b43c49a343ce92c3b5290309",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.8",
      "size": 392119,
      "upload_time": "2023-03-08T17:24:57",
      "upload_time_iso_8601": "2023-03-08T17:24:57.003479Z",
      "url": "https://files.pythonhosted.org/packages/91/64/48c628ad667d8e66d0e7f1093407e658e82ee5e0ce8d7751e7a62b5331eb/merlin-models-23.2.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}