{
  "info": {
    "author": "Atif Hassan",
    "author_email": "atif.hit.hassan@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: GNU Lesser General Public License v2 or later (LGPLv2+)",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7"
    ],
    "description": "[![forthebadge made-with-python](http://ForTheBadge.com/images/badges/made-with-python.svg)](https://www.python.org/)\n[![ForTheBadge built-with-love](http://ForTheBadge.com/images/badges/built-with-love.svg)](https://github.com/atif-hassan/)\n\n[![PyPI version shields.io](https://img.shields.io/pypi/v/manual-spellchecker.svg)](https://pypi.python.org/pypi/manual-spellchecker/)\n[![Downloads](https://pepy.tech/badge/manual-spellchecker)](https://pepy.tech/project/manual-spellchecker)\n[![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](https://github.com/atif-hassan/manual_spellchecker/commits/master)\n# Manual Spell Checker\nA manual spell checker **built on _pyenchant_** that allows you to swiftly correct misspelled words.\n\n## Why does this exist?\nWhile I was working on a text based multi-class classification competition, I noticed that the data contained a lot of misspelled words, errors which automated spell check packages out there couldn't fix. This was because the data had been compiled based on a survey of people who weren't native English speakers. As the there weren't many samples in the dataset (~1000), I decided to write some code for automated detection of spelling errors which I could then fix manually, and thus, this package was born.\n\n## How to install?\n```pip install manual_spellchecker```\n\n## Features\n- All features as provided by [pyenchant](https://github.com/pyenchant/pyenchant)\n- Quickly analyze and get a list of all misspelled words\n- Can replace, skip and delete misspelled words\n- Use your favourite tokenizer for splitting words\n- Replaced misspelled words via provided suggestions by simply typing in their indices\n- Can checkpoint current set of corrections\n- Contexualized pretty printing for easy visual correction (works on both command line and notebook)\n\n## Functions and Parameters\n```python\n# Initialize the spell checking object\n__init__(dataframe, column_names, tokenizer=None, num_n_words_dis=5, save_path=None)\n```\n- **dataframe** - Takes a pandas dataframe as input\n- **column_names** - Pass the column name(s) upon which you want to perform spelling correction\n- **tokenizer=None** - Pass your favourite tokenizer like nltk or spacy, etc. (Default: splits on space)\n- **num_n_words_dis=5** - This decides how many neighbouring words to display on either side of the error\n- **save_path=None** - If a save path is provided, the final corrected dataframe is saved as a csv. (Default: the dataframe is not saved but returned)\n\n```python\n# For quick analysis of all the misspelled words\nspell_check()\n```\n\n```python\n# Returns a list of all the misspelled words\nget_all_errors()\n```\n\n```python\n# Starts the process of correcting erroneous words\ncorrect_words()\n```\n\n **Important Note:**\n - Type -999 into the input box to stop the error correction and save the current progress (if save_path is provided)\n - Simply press enter if you want to skip the current word\n - Type in \"\" or '' in the input box to delete a misspelled word\n\n## Usage\n### How to import?\n```python\nfrom manual_spellchecker import spell_checker\n```\n\n### Quick analysis of the total number of errors\n```python\n# Read the data\ndf = pd.read_csv(\"Train.csv\")\n# Initialize the model\nob = spell_checker(df, \"text\")\n# Quick analysis\nob.spell_check()\n```\n![](resources/manual_spellchecker_quick_analysis.gif)\n\n### Multiple columns can be passed for spelling correction\n```python\n# Read the data\ndf = pd.read_csv(\"Train.csv\")\n# Initialize the model\nob = spell_checker(df, [\"text\", \"label\"])\n# Quick analysis\nob.spell_check()\n```\n\n### You can pass your own tokenizers\n```python\n# Import nltk's word tokenizer\nfrom nltk import word_tokenize\n# Read the data\ndf = pd.read_csv(\"Train.csv\")\n# Initialize the model\nob = spell_checker(df, \"text\", word_tokenize)\n# Quick analysis\nob.spell_check()\n```\n\n### Get a list of all the errors\n```python\n# Read the data\ndf = pd.read_csv(\"Train.csv\")\n# Initialize the model\nob = spell_checker(df, \"text\")\n# Quick analysis. This needs to be performed before getting all errors\nob.spell_check()\n# Returns a list of all errors\nob.get_all_errors()\n```\n\n### Make corrections\n```python\n# Read the data\ndf = pd.read_csv(\"Train.csv\")\n# Initialize the model\nob = spell_checker(df, \"text\")\n# Start corrections\nob.correct_words()\n```\n![](resources/manual_spellchecker_corrections.gif)\n\n### To save\n```python\ndf = pd.read_csv(\"Train.csv\")\n# Initialize the model\nob = spell_checker(df, \"text\", save_path=\"correct_train_data.csv\")\n```\n\n## Future Ideas\n- Will be adding automated, contextual error corrections\n\n## Feature Request\nDrop me an email at **atif.hit.hassan@gmail.com** if you want any particular feature\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/atif-hassan/manual_spellchecker",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "manual-spellchecker",
    "package_url": "https://pypi.org/project/manual-spellchecker/",
    "platform": "",
    "project_url": "https://pypi.org/project/manual-spellchecker/",
    "project_urls": {
      "Homepage": "https://github.com/atif-hassan/manual_spellchecker"
    },
    "release_url": "https://pypi.org/project/manual-spellchecker/1.1/",
    "requires_dist": [
      "tqdm",
      "pyenchant",
      "numpy"
    ],
    "requires_python": "",
    "summary": "A manual spell checker built on pyenchant that allows you to swiftly correct misspelled words.",
    "version": "1.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 7487862,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "24370811d905f260950aba4e5056ff56cd265dcb6a7739841c93f435fe6f6bbe",
        "md5": "9ef8a779f6e444d4c32414c2ee4e19f4",
        "sha256": "e5f4d294df604f5360d9bfbc379693ba417c8a844befa1e12c9ae5abf8899fd7"
      },
      "downloads": -1,
      "filename": "manual_spellchecker-1.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "9ef8a779f6e444d4c32414c2ee4e19f4",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 14317,
      "upload_time": "2020-06-16T11:55:16",
      "upload_time_iso_8601": "2020-06-16T11:55:16.691677Z",
      "url": "https://files.pythonhosted.org/packages/24/37/0811d905f260950aba4e5056ff56cd265dcb6a7739841c93f435fe6f6bbe/manual_spellchecker-1.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "cb59e0d7cd24c0eabc880f7b5a018b0940d700572082388c1d33488b6ef32f78",
        "md5": "de423e23bbdaaeb06b45b6c64ad7baee",
        "sha256": "c91f66e15ba1fe71c30c1c0f37fa47e38b946647a90d038f30badeb2717c12ce"
      },
      "downloads": -1,
      "filename": "manual_spellchecker-1.1.tar.gz",
      "has_sig": false,
      "md5_digest": "de423e23bbdaaeb06b45b6c64ad7baee",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 14080,
      "upload_time": "2020-06-16T11:55:18",
      "upload_time_iso_8601": "2020-06-16T11:55:18.206904Z",
      "url": "https://files.pythonhosted.org/packages/cb/59/e0d7cd24c0eabc880f7b5a018b0940d700572082388c1d33488b6ef32f78/manual_spellchecker-1.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}