{
  "info": {
    "author": "Atif Hassan",
    "author_email": "atif.hit.hassan@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: GNU Lesser General Public License v2 or later (LGPLv2+)",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7"
    ],
    "description": "[![forthebadge made-with-python](http://ForTheBadge.com/images/badges/made-with-python.svg)](https://www.python.org/)\n[![ForTheBadge built-with-love](http://ForTheBadge.com/images/badges/built-with-love.svg)](https://github.com/atif-hassan/)\n\n[![PyPI version shields.io](https://img.shields.io/pypi/v/manual-spellchecker.svg)](https://pypi.python.org/pypi/manual-spellchecker/)\n[![Downloads](https://pepy.tech/badge/manual-spellchecker)](https://pepy.tech/project/manual-spellchecker)\n[![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](https://github.com/atif-hassan/manual_spellchecker/commits/master)\n# Manual Spell Checker\nA manual spell checker **built on _pyenchant_** that allows you to swiftly correct misspelled words.\n\n## Why does this exist?\nWhile I was working on a text based multi-class classification competition, I noticed that the data contained a lot of misspelled words, errors which automated spell check packages out there couldn't fix. This was because the data had been compiled based on a survey of people who weren't native English speakers. As the there weren't many samples in the dataset (~1000), I decided to write some code for automated detection of spelling errors which I could then fix manually, and thus, this package was born.\n\n## How to install?\n```pip install manual_spellchecker```\n\n## Features\n- All features as provided by [pyenchant](https://github.com/pyenchant/pyenchant)\n- Quickly analyze and get a list of all misspelled words\n- Can replace, skip and delete misspelled words\n- Use your favourite tokenizer for splitting words\n- Replaced misspelled words via provided suggestions by simply typing in their indices\n- Can checkpoint current set of corrections\n- Contexualized pretty printing for easy visual correction (works on both command line and notebook)\n\n## Functions and Parameters\n```python\n# Initialize the spell checking object\n__init__(dataframe, column_names, tokenizer=None, num_n_words_dis=5, save_path=None)\n```\n- **dataframe** - Takes a pandas dataframe as input\n- **column_names** - Pass the column name(s) upon which you want to perform spelling correction\n- **tokenizer=None** - Pass your favourite tokenizer like nltk or spacy, etc. (Default: splits on space)\n- **num_n_words_dis=5** - This decides how many neighbouring words to display on either side of the error\n- **save_path=None** - If a save path is provided, the final corrected dataframe is saved as a csv. (Default: the dataframe is not saved but returned)\n\n```python\n# For quick analysis of all the misspelled words\nspell_check()\n```\n\n```python\n# Returns a list of all the misspelled words\nget_all_errors()\n```\n\n```python\n# Starts the process of correcting erroneous words\ncorrect_words()\n```\n\n **Important Note:**\n - Type -999 into the input box to stop the error correction and save the current progress (if save_path is provided)\n - Simply press enter if you want to skip the current word\n - Type in \"\" or '' in the input box to delete a misspelled word\n\n## Usage\n### How to import?\n```python\nfrom manual_spellchecker import spell_checker\n```\n\n### Quick analysis of the total number of errors\n```python\n# Read the data\ndf = pd.read_csv(\"Train.csv\")\n# Initialize the model\nob = spell_checker(df, \"text\")\n# Quick analysis\nob.spell_check()\n```\n![](resources/manual_spellchecker_quick_analysis.gif)\n\n### Multiple columns can be passed for spelling correction\n```python\n# Read the data\ndf = pd.read_csv(\"Train.csv\")\n# Initialize the model\nob = spell_checker(df, [\"text\", \"label\"])\n# Quick analysis\nob.spell_check()\n```\n\n### You can pass your own tokenizers\n```python\n# Import nltk's word tokenizer\nfrom nltk import word_tokenize\n# Read the data\ndf = pd.read_csv(\"Train.csv\")\n# Initialize the model\nob = spell_checker(df, \"text\", word_tokenize)\n# Quick analysis\nob.spell_check()\n```\n\n### Get a list of all the errors\n```python\n# Read the data\ndf = pd.read_csv(\"Train.csv\")\n# Initialize the model\nob = spell_checker(df, \"text\")\n# Quick analysis. This needs to be performed before getting all errors\nob.spell_check()\n# Returns a list of all errors\nob.get_all_errors()\n```\n\n### Make corrections\n```python\n# Read the data\ndf = pd.read_csv(\"Train.csv\")\n# Initialize the model\nob = spell_checker(df, \"text\")\n# Start corrections\nob.correct_words()\n```\n![](resources/manual_spellchecker_corrections.gif)\n\n### To save\n```python\ndf = pd.read_csv(\"Train.csv\")\n# Initialize the model\nob = spell_checker(df, \"text\", save_path=\"correct_train_data.csv\")\n```\n\n## Future Ideas\n- Will be adding automated, contextual error corrections\n\n## Feature Request\nDrop me an email at **atif.hit.hassan@gmail.com** if you want any particular feature\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/atif-hassan/manual_spellchecker",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "manual-spellchecker",
    "package_url": "https://pypi.org/project/manual-spellchecker/",
    "platform": "",
    "project_url": "https://pypi.org/project/manual-spellchecker/",
    "project_urls": {
      "Homepage": "https://github.com/atif-hassan/manual_spellchecker"
    },
    "release_url": "https://pypi.org/project/manual-spellchecker/1.2/",
    "requires_dist": [
      "tqdm",
      "pyenchant",
      "numpy"
    ],
    "requires_python": "",
    "summary": "A manual spell checker built on pyenchant that allows you to swiftly correct misspelled words.",
    "version": "1.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 7487862,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "be0e25f455176ff6f26bcd4379530143c7d6f9f621767d9d543972e7d404324a",
        "md5": "ac5cda2ee8dece5f0b28acea1adb490c",
        "sha256": "c3dde9011e5f657b4a72d4f8dbff87220aae85fb6f75294cfea2501feceac7b9"
      },
      "downloads": -1,
      "filename": "manual_spellchecker-1.2-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "ac5cda2ee8dece5f0b28acea1adb490c",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 14325,
      "upload_time": "2020-06-16T12:14:10",
      "upload_time_iso_8601": "2020-06-16T12:14:10.638060Z",
      "url": "https://files.pythonhosted.org/packages/be/0e/25f455176ff6f26bcd4379530143c7d6f9f621767d9d543972e7d404324a/manual_spellchecker-1.2-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "6934ab82f6526bdc1b45953751b9d8f82521aaef36146c9086724fa83459a375",
        "md5": "3e031733d503a08a85ccdb1171560bda",
        "sha256": "5b24731b9f905b2ea29c0d15a21c5a6162e22a8db3a357afb50175ab08e939b1"
      },
      "downloads": -1,
      "filename": "manual_spellchecker-1.2.tar.gz",
      "has_sig": false,
      "md5_digest": "3e031733d503a08a85ccdb1171560bda",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 14089,
      "upload_time": "2020-06-16T12:14:12",
      "upload_time_iso_8601": "2020-06-16T12:14:12.167905Z",
      "url": "https://files.pythonhosted.org/packages/69/34/ab82f6526bdc1b45953751b9d8f82521aaef36146c9086724fa83459a375/manual_spellchecker-1.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}