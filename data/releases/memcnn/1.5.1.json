{
  "info": {
    "author": "S.C. van de Leemput",
    "author_email": "silvandeleemput@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Topic :: Scientific/Engineering",
      "Topic :: Scientific/Engineering :: Information Analysis",
      "Topic :: Scientific/Engineering :: Medical Science Apps.",
      "Topic :: Software Development :: Libraries"
    ],
    "description": "======\nMemCNN\n======\n\n.. image:: https://img.shields.io/circleci/build/github/silvandeleemput/memcnn/master.svg        \n        :alt: CircleCI - Status master branch\n        :target: https://circleci.com/gh/silvandeleemput/memcnn/tree/master\n\n.. image:: https://img.shields.io/docker/cloud/build/silvandeleemput/memcnn.svg\n        :alt: Docker - Status\n        :target: https://hub.docker.com/r/silvandeleemput/memcnn\n\n.. image:: https://readthedocs.org/projects/memcnn/badge/?version=latest        \n        :alt: Documentation - Status master branch\n        :target: https://memcnn.readthedocs.io/en/latest/?badge=latest\n\n.. image:: https://img.shields.io/codacy/grade/95de32e0d7c54d038611da47e9f0948b/master.svg\n        :alt: Codacy - Branch grade\n        :target: https://app.codacy.com/project/silvandeleemput/memcnn/dashboardgit\n\n.. image:: https://img.shields.io/codecov/c/gh/silvandeleemput/memcnn/master.svg   \n        :alt: Codecov - Status master branch\n        :target: https://codecov.io/gh/silvandeleemput/memcnn\n\n.. image:: https://img.shields.io/pypi/v/memcnn.svg\n        :alt: PyPI - Latest release\n        :target: https://pypi.python.org/pypi/memcnn\n\n.. image:: https://img.shields.io/conda/vn/silvandeleemput/memcnn?label=anaconda\n        :alt: Conda - Latest release\n        :target: https://anaconda.org/silvandeleemput/memcnn\n\n.. image:: https://img.shields.io/pypi/implementation/memcnn.svg        \n        :alt: PyPI - Implementation\n        :target: https://pypi.python.org/pypi/memcnn\n\n.. image:: https://img.shields.io/pypi/pyversions/memcnn.svg        \n        :alt: PyPI - Python version\n        :target: https://pypi.python.org/pypi/memcnn\n\n.. image:: https://img.shields.io/github/license/silvandeleemput/memcnn.svg        \n        :alt: GitHub - Repository license\n        :target: https://github.com/silvandeleemput/memcnn/blob/master/LICENSE.txt\n\n.. image:: http://joss.theoj.org/papers/10.21105/joss.01576/status.svg\n        :alt: JOSS - DOI\n        :target: https://doi.org/10.21105/joss.01576\n\nA `PyTorch <http://pytorch.org/>`__ framework for developing memory-efficient invertible neural networks.\n\n* Free software: `MIT license <https://github.com/silvandeleemput/memcnn/blob/master/LICENSE.txt>`__ (please cite our work if you use it)\n* Documentation: https://memcnn.readthedocs.io.\n* Installation: https://memcnn.readthedocs.io/en/latest/installation.html\n\nFeatures\n--------\n\n* Enable memory savings during training by wrapping arbitrary invertible PyTorch functions with the `InvertibleModuleWrapper` class.\n* Simple toggling of memory saving by setting the `keep_input` property of the `InvertibleModuleWrapper`.\n* Turn arbitrary non-linear PyTorch functions into invertible versions using the `AdditiveCoupling` or the `AffineCoupling` classes.\n* Training and evaluation code for reproducing RevNet experiments using MemCNN.\n* CI tests for Python v3.7 and torch v1.0, v1.1, v1.4 and v1.7 with good code coverage.\n\nExamples\n--------\n\nCreating an AdditiveCoupling with memory savings\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n.. code:: python\n\n    import torch\n    import torch.nn as nn\n    import memcnn\n\n\n    # define a new torch Module with a sequence of operations: Relu o BatchNorm2d o Conv2d\n    class ExampleOperation(nn.Module):\n        def __init__(self, channels):\n            super(ExampleOperation, self).__init__()\n            self.seq = nn.Sequential(\n                                        nn.Conv2d(in_channels=channels, out_channels=channels,\n                                                  kernel_size=(3, 3), padding=1),\n                                        nn.BatchNorm2d(num_features=channels),\n                                        nn.ReLU(inplace=True)\n                                    )\n\n        def forward(self, x):\n            return self.seq(x)\n\n\n    # generate some random input data (batch_size, num_channels, y_elements, x_elements)\n    X = torch.rand(2, 10, 8, 8)\n\n    # application of the operation(s) the normal way\n    model_normal = ExampleOperation(channels=10)\n    model_normal.eval()\n\n    Y = model_normal(X)\n\n    # turn the ExampleOperation invertible using an additive coupling\n    invertible_module = memcnn.AdditiveCoupling(\n        Fm=ExampleOperation(channels=10 // 2),\n        Gm=ExampleOperation(channels=10 // 2)\n    )\n\n    # test that it is actually a valid invertible module (has a valid inverse method)\n    assert memcnn.is_invertible_module(invertible_module, test_input_shape=X.shape)\n\n    # wrap our invertible_module using the InvertibleModuleWrapper and benefit from memory savings during training\n    invertible_module_wrapper = memcnn.InvertibleModuleWrapper(fn=invertible_module, keep_input=True, keep_input_inverse=True)\n\n    # by default the module is set to training, the following sets this to evaluation\n    # note that this is required to pass input tensors to the model with requires_grad=False (inference only)\n    invertible_module_wrapper.eval()\n\n    # test that the wrapped module is also a valid invertible module\n    assert memcnn.is_invertible_module(invertible_module_wrapper, test_input_shape=X.shape)\n\n    # compute the forward pass using the wrapper\n    Y2 = invertible_module_wrapper.forward(X)\n\n    # the input (X) can be approximated (X2) by applying the inverse method of the wrapper on Y2\n    X2 = invertible_module_wrapper.inverse(Y2)\n\n    # test that the input and approximation are similar\n    assert torch.allclose(X, X2, atol=1e-06)\n\nRun PyTorch Experiments\n-----------------------\n\nAfter installing MemCNN run:\n\n.. code:: bash\n\n    python -m memcnn.train [MODEL] [DATASET] [--fresh] [--no-cuda]\n\n* Available values for ``DATASET`` are ``cifar10`` and ``cifar100``.\n* Available values for ``MODEL`` are ``resnet32``, ``resnet110``, ``resnet164``, ``revnet38``, ``revnet110``, ``revnet164``\n* Use the ``--fresh`` flag to remove earlier experiment results.\n* Use the ``--no-cuda`` flag to train on the CPU rather than the GPU through CUDA.\n\nDatasets are automatically downloaded if they are not available.\n\nWhen using Python 3.* replace the ``python`` directive with the appropriate Python 3 directive. For example when using the MemCNN docker image use ``python3.6``.\n\nWhen MemCNN was installed using `pip` or from sources you might need to setup a configuration file before running this command.\nRead the corresponding section about how to do this here: https://memcnn.readthedocs.io/en/latest/installation.html\n\n\n\n",
    "description_content_type": "text/x-rst",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "http://pypi.python.org/pypi/memcnn/",
    "keywords": "memcnn invertible PyTorch",
    "license": "LICENSE.txt",
    "maintainer": "",
    "maintainer_email": "",
    "name": "memcnn",
    "package_url": "https://pypi.org/project/memcnn/",
    "platform": "",
    "project_url": "https://pypi.org/project/memcnn/",
    "project_urls": {
      "Homepage": "http://pypi.python.org/pypi/memcnn/"
    },
    "release_url": "https://pypi.org/project/memcnn/1.5.1/",
    "requires_dist": [
      "numpy",
      "SimpleITK",
      "torch (>=1.0.0)",
      "torchvision",
      "tqdm",
      "pathlib2"
    ],
    "requires_python": "",
    "summary": "A PyTorch framework for developing memory efficient deep invertible networks.",
    "version": "1.5.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 11151326,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "af4b648bf4aafada78f0db24520a871d0a30c4ee897b915df4bd31679e933034",
        "md5": "02704572084cd1089677f009e666f465",
        "sha256": "1f3240ad42e63d9dce856ce301682a18d30d22bfac8ffe84b52d8d3dfee9ebac"
      },
      "downloads": -1,
      "filename": "memcnn-1.5.1-py2.py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "02704572084cd1089677f009e666f465",
      "packagetype": "bdist_wheel",
      "python_version": "py2.py3",
      "requires_python": null,
      "size": 50203,
      "upload_time": "2021-08-11T15:16:08",
      "upload_time_iso_8601": "2021-08-11T15:16:08.265859Z",
      "url": "https://files.pythonhosted.org/packages/af/4b/648bf4aafada78f0db24520a871d0a30c4ee897b915df4bd31679e933034/memcnn-1.5.1-py2.py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "ce9a88475f2b5641ae3f00d418d4cc814768a9adf6cb73698ad286ae38740d78",
        "md5": "4de9c9511fd626a674b59970190a641e",
        "sha256": "7dd2b04ccf9dd9bc82644fe0d197d64164be72c24174c69acd4ce5de73002344"
      },
      "downloads": -1,
      "filename": "memcnn-1.5.1.tar.gz",
      "has_sig": false,
      "md5_digest": "4de9c9511fd626a674b59970190a641e",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 47720,
      "upload_time": "2021-08-11T15:16:09",
      "upload_time_iso_8601": "2021-08-11T15:16:09.662146Z",
      "url": "https://files.pythonhosted.org/packages/ce/9a/88475f2b5641ae3f00d418d4cc814768a9adf6cb73698ad286ae38740d78/memcnn-1.5.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}