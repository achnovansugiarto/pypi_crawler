{
  "info": {
    "author": "Andre Mesarovic",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Developers",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3.7"
    ],
    "description": "# MLflow Export Import\n\nThis package provides tools to export and import MLflow objects (runs, experiments or registered models) from one MLflow tracking server (Databricks workspace) to another.\n\nFor more details on MLflow objects (Databricks MLflow) see the [Databricks MLflow Object Relationships](https://github.com/amesar/mlflow-resources/blob/master/slides/Databricks_MLflow_Object_Relationships.pdf) slide deck.\n\n## Architecture\n\n<img src=\"architecture.png\" height=\"330\" />\n\n## Overview\n\n### Why use MLflow Export Import?\n  * Share and collaborate with other data scientists in the same or another tracking server.\n    * For example, clone a favorite experiment from another user in your own workspace.\n  * Migrate experiments to another tracking server.\n    * For example, promote a registered model version (and its associated run) from the development to the test tracking server and then to the production tracking server.\n  * Backup your MLflow objects.\n  * Disaster recovery.\n\n### MLflow Export Import scenarios\n\n|Source tracking server | Destination tracking server | Note |\n|-------|------------|---|\n| Open source | Open source | common |\n| Open source | Databricks | less common |\n| Databricks | Databricks |common |\n| Databricks | Open source | rare |\n\n### Two sets of tools\n\n* Open source MLflow Python scripts.\n* [Databricks notebooks](databricks_notebooks/README.md) that invoke the Python scripts.\n\n## Tools Overview\n\n###  Python Scripts\n\nThere are two sets of Python scripts:\n\n* [Individual tools](README_individual.md). Use these tools to export and import individual MLflow objects between tracking servers. \nThey allow you to specify a different destination object name.\nFor example, if you want to clone the experiment `/Mary/Experiments/Iris` under a new name, you can specify the target experiment name as `/John/Experiments/Iris`.\n\n* [Collection tools](README_collection.md). High-level tools to copy an entire tracking server or a collection of MLflow objects (runs and experiments).\nFull object referential integrity is maintained as well as the original MLflow object names.\n\n### Databricks notebooks\n\nDatabricks notebooks simply invoke their corresponding Python scripts.\nNote that only `Individual` notebooks are currently available.\n\nSee [README](databricks_notebooks/README.md).\n\n### Other\n* [Miscellanous tools](README_tools.md) \n\n## Limitations\n\n### General Limitations\n\n* Nested runs are only supported when you import an experiment. For a run, it is still a TODO.\n* If the run linked to a registered model version does not exist (has been deleted) the version is not exported \n  since when importing [MLflowClient.create_model_version](https://mlflow.org/docs/latest/python_api/mlflow.tracking.html#mlflow.tracking.MlflowClient.create_model_version) requires a run ID.\n\n### Databricks Limitations\n\n#### Exporting Notebook Revisions\n* The notebook revision associated with the run can be exported. It is stored as an an artifact in the run's `notebooks` artifact directory.\n*  You can save the notebook in the suppported SOURCE, HTML, JUPYTER and DBC formats. \n*  Examples: `notebooks/notebook.dbc` or `notebooks/notebook.source`.\n\n#### Importing Notebooks\n\n* Partial functionality due to Databricks REST API limitations.\n* The Databricks REST API does not support:\n  * Importing a notebook with its revision history.\n  * Linking an imported run with the imported notebook.\n* When you import a run, the link to its source notebook revision ID will be a dead link and you cannot access the notebook from the MLflow UI.\n* As a convenience, the import tools allows you to import the exported notebook into Databricks. For more details, see:\n  *  [README_individual - Import run](README_individual.md#Import-run)\n  *  [README_individual - Import experiment](README_individual.md#Import-experiment)\n* You must export a notebook in the SOURCE format for the notebook to be imported.\n\n\n#### Used ID\n* When importing a run or experiment, for open source MLflow you can specify the user owner. \n* OSS MLflow - the destination run `mlflow.user` tag can be the same as the source `mlflow.user` tag since OSS MLflow allows you to set this tag.\n* Databricks MLflow - you cannot set the `mlflow.user` tag.  The `mlflow.user` will be based on the personal access token (PAT) of the importing user.\n\n## Common options details \n\n`notebook-formats` - If exporting a Databricks run, the run's notebook revision can be saved in the specified formats (comma-delimited argument). Each format is saved in the notebooks folder of the run's artifact root directory as `notebook.{format}`. Supported formats are  SOURCE, HTML, JUPYTER and DBC. See Databricks [Export Format](https://docs.databricks.com/dev-tools/api/latest/workspace.html#notebookexportformat) documentation.\n\n`use-src-user-id` -  Set the destination user ID to the source user ID. Source user ID is ignored when importing into Databricks since the user is automatically picked up from your Databricks access token.\n\n`export-source-tags` - Exports source information under the `mlflow_export_import` tag prefix. See section below for details.\n\n### MLflow Export Import Source Run Tags - `mlflow_export_import`\n\nFor governance purposes, original source run information is saved under the `mlflow_export_import` tag prefix. When you import a run, the values of `RunInfo` are auto-generated for you as well as some tags. \n\nThis is useful for governance, provenance and auditing purposes for regulated industries such as finance and HLS (health case and life science) industries.\n\nIf the `export-source-tags` option is set on an export tool, three sets of source run tags will be saved under the `mlflow_export_import` prefix.\n\n* **MLflow system tags.** Prefix: `mlflow_export_import.mlflow`. Saves all source MLflow system tags starting with `mlflow.` \n  * For example, the source tag `mlflow.source.type` is saved as the destination tag `mlflow_export_import.mlflow.source.type`.\n\n* **RunInfo field tags.** Prefix: `mlflow_export_import.run_info`. Saves all source [RunInfo](https://mlflow.org/docs/latest/python_api/mlflow.entities.html#mlflow.entities.RunInfo) fields.\n  * For example RunInfo.run_id is stored as `mlflow_export_import.run_info.run_id`.\n  * Note that since MLflow tag values must be a string, non-string `RunInfo` fields (int) are cast to a string such as `start_time`.\n\n* **Metadata tags.** Prefix: `mlflow_export_import.metadata`.  Tags indicating source export metadata information \n  * Example: `mlflow_export_import.metadata.tracking_uri`.\n\n#### Open Source Mlflow Export Import Tags\n\nSee [sample run tags](samples/oss_mlflow/experiments/sklearn_wine/eb66c160957d4a28b11d3f1b968df9cd/run.json).\n\n##### MLflow system tags\n\n|Tag | Value |\n|----|-------|\n| mlflow_export_import.mlflow.log-model.history | [{\\run_id\\: \\eb66c160957d4a28b11d3f1b968df9cd\\ | \\artifact_path\\: \\model\\, \\utc_time_created\\: \\2022-06-12 03:34:39.289551\\, \\flavors\\: {\\python_function\\: {\\model_path\\: \\model.pkl\\, \\loader_module\\: \\mlflow.sklearn\\, \\python_version\\: \\3.7.6\\, \\env\\: \\conda.yaml\\}, \\sklearn\\: {\\pickled_model\\: \\model.pkl\\, \\sklearn_version\\: \\1.0.2\\, \\serialization_format\\: \\cloudpickle\\, \\code\\: null}}, \\model_uuid\\: \\38c43fc59c734b0a80704ac3214ea2c3\\, \\mlflow_version\\: \\1.26.1\\}, {\\run_id\\: \\eb66c160957d4a28b11d3f1b968df9cd\\, \\artifact_path\\: \\onnx-model\\, \\utc_time_created\\: \\2022-06-12 03:34:42.110784\\, \\flavors\\: {\\python_function\\: {\\loader_module\\: \\mlflow.onnx\\, \\python_version\\: \\3.7.6\\, \\data\\: \\model.onnx\\, \\env\\: \\conda.yaml\\}, \\onnx\\: {\\onnx_version\\: \\1.10.2\\, \\data\\: \\model.onnx\\, \\providers\\: [\\CUDAExecutionProvider\\, \\CPUExecutionProvider\\], \\code\\: null}}, \\model_uuid\\: \\ddf79625e4d241b7813e601f31b1222f\\, \\mlflow_version\\: \\1.26.1\\}],\n| mlflow_export_import.mlflow.runName | train.sh |\n| mlflow_export_import.mlflow.source.git.commit | 67fb8f823ec794902cdbb67be653a6155a0b5172 |\n| mlflow_export_import.mlflow.source.name | /Users/andre/git/mlflow-examples/python/sklearn/wine_quality/train.py |\n| mlflow_export_import.mlflow.source.type | LOCAL |\n| mlflow_export_import.mlflow.user | andre |\n\n##### MLflow RunInfo tags\n\n|Tag | Value |\n|----|-------|\n| mlflow_export_import.run_info.artifact_uri | /opt/mlflow/server/mlruns/2/eb66c160957d4a28b11d3f1b968df9cd/artifacts |\n| mlflow_export_import.run_info.end_time | 1655004883611 |\n| mlflow_export_import.run_info.experiment_id | 2 |\n| mlflow_export_import.run_info.lifecycle_stage | active |\n| mlflow_export_import.run_info.run_id | eb66c160957d4a28b11d3f1b968df9cd |\n| mlflow_export_import.run_info.start_time | 1655004878844 |\n| mlflow_export_import.run_info.status | FINISHED |\n| mlflow_export_import.run_info.user_id | andre |\n\n##### Metadata tags\n\n|Tag | Value | Description |\n|----|-------|-------------|\n| mlflow_export_import.metadata.mlflow_version | 1.26.1 | MLflow version |\n| mlflow_export_import.metadata.tracking_uri | http://127.0.0.1:5020 | Source tracking server URI |\n| mlflow_export_import.metadata.experiment_name | sklearn_wine | Name of experiment |\n| mlflow_export_import.metadata.timestamp | 1655007510 | Time when run was exported |\n| mlflow_export_import.metadata.timestamp_nice | 2022-06-12 04:18:30 | ibid |\n\n### Databricks MLflow source tags\n\nSee [sample run tags](samples/databricks/experiments/sklearn_wine/eb66c160957d4a28b11d3f1b968df9cd/run.json).\n\n##### MLflow system tags \n\n|Tag | Value | \n|----|-------|\n| mlflow_export_import.mlflow.databricks.cluster.id         | 0318-151752-abed99                                                                                             |\n| mlflow_export_import.mlflow.databricks.cluster.info       | {\"cluster_name\":\"Shared Autoscaling Americas\",\"spark_version\":\"10.2.x-cpu-ml-scala2.12\",\"node_type_id\":\"i3.2xl |\n| mlflow_export_import.mlflow.databricks.cluster.libraries  | {\"installable\":[],\"redacted\":[]}                                                                               |\n| mlflow_export_import.mlflow.databricks.notebook.commandID | 6101304639030907941_7207589773925520000_e458c0ed7c5c4e52b020b1b92d39b308                                       |\n| mlflow_export_import.mlflow.databricks.notebookID         | 3532228                                                                                                        |\n| mlflow_export_import.mlflow.databricks.notebookPath       | /Users/andre@mycompany.com/mlflow/02a_Sklearn_Train_Predict    |\n| mlflow_export_import.mlflow.databricks.notebookRevisionID | 1647395473565                                                                                                  |\n| mlflow_export_import.mlflow.databricks.webappURL          | https://demo.cloud.databricks.com                                                                              |\n| mlflow_export_import.mlflow.log-model.history             | [{\"artifact_path\":\"sklearn-model\",\"signature\":{\"inputs\":\"[{\\\"name\\\": \\\"fixed acidity\\\", \\\"type\\\": \\\"double\\\"}, |\n| mlflow_export_import.mlflow.runName                       | sklearn                                                                                                        |\n| mlflow_export_import.mlflow.source.name                   | /Users/andre@mycompany.com/mlflow/02a_Sklearn_Train_Predict    |\n| mlflow_export_import.mlflow.source.type                   | NOTEBOOK                                                                                                       |\n| mlflow_export_import.mlflow.user                          | andre@mycompany.com                                                                                 |\n\n\n##### MLflow RunInfo tags\n\n|Tag | Value | \n|----|-------|\n| mlflow_export_import.run_info.artifact_uri                | dbfs:/databricks/mlflow/3532228/826a19c33d8c461ebf91aa90c25a5dd8/artifacts |\n| mlflow_export_import.run_info.end_time                    | 1647395473410                                                              |\n| mlflow_export_import.run_info.experiment_id               | 3532228                                                                    |\n| mlflow_export_import.run_info.lifecycle_stage             | active                                                                     |\n| mlflow_export_import.run_info.run_id                      | 826a19c33d8c461ebf91aa90c25a5dd8                                           |\n| mlflow_export_import.run_info.run_uuid                    | 826a19c33d8c461ebf91aa90c25a5dd8                                           |\n| mlflow_export_import.run_info.start_time                  | 1647395462575                                                              |\n| mlflow_export_import.run_info.status                      | FINISHED                                                                   |\n| mlflow_export_import.run_info.user_id                     |                                                                            |\n\n##### Metadata tags\n|Tag | Value | \n|----|-------|\n| mlflow_export_import.metadata.mlflow_version | 1.26.1 | \n| mlflow_export_import.metadata.tracking_uri                | databricks |\n| mlflow_export_import.metadata.experiment_name             | /Users/andre@mycompany.com/mlflow/02a_Sklearn_Train_Predict    |\n| mlflow_export_import.metadata.timestamp                   | 1655148303 |\n| mlflow_export_import.metadata.timestamp_nice              | 2022-06-13 19:25:03 |\n\n## Setup\n\nSupports python 3.7.6 or above.\n\n\n### Local setup\n\nFirst create a virtual environment.\n```\npython -m venv mlflow-export-import\nsource mlflow-export-import/bin/activate\n```\n\nThere are two different ways to install the package.\n\n#### 1. Install from github directly\n\n```\npip install git+https:///github.com/mlflow/mlflow-export-import/#egg=mlflow-export-import\n```\n\n#### 2. Install from github clone\n```\ngit clone https://github.com/mlflow/mlflow-export-import\ncd mlflow-export-import\npip install -e .\n```\n\n### Databricks setup\n\nThere are two different ways to install the package.\n\n#### 1. Install package in notebook\n\n[Install notebook-scoped libraries with %pip](https://docs.databricks.com/libraries/notebooks-python-libraries.html#install-notebook-scoped-libraries-with-pip).\n\n\n```\npip install git+https:///github.com/mlflow/mlflow-export-import/#egg=mlflow-export-import\n```\n\n#### 2. Install package as a wheel on cluster\n\nBuild the wheel artifact, upload it to DBFS and then [install it on your cluster](https://docs.databricks.com/libraries/cluster-libraries.html).\n\n```\npython setup.py bdist_wheel\ndatabricks fs cp dist/mlflow_export_import-1.0.0-py3-none-any.whl {MY_DBFS_PATH}\n```\n\n### Databricks MLflow usage\n\nTo run the tools externally (from your laptop) against a Databricks tracking server (workspace) set the following environment variables.\n```\nexport MLFLOW_TRACKING_URI=databricks\nexport DATABRICKS_HOST=https://mycompany.cloud.databricks.com\nexport DATABRICKS_TOKEN=MY_TOKEN\n```\nFor full details see [Access the MLflow tracking server from outside Databricks](https://docs.databricks.com/applications/mlflow/access-hosted-tracking-server.html).\n\n\n## Running tools\n\nThe main tool scripts can be executed either as a standard Python script or console script.\n\nPython [console scripts](https://python-packaging.readthedocs.io/en/latest/command-line-scripts.html#the-console-scripts-entry-point)  (such as export-run, import-run, etc.) are provided as a convenience. For a list of scripts see [setup.py](setup.py).\n\nThis allows you to use:\n```\nexport-experiment --help\n```\ninstead of:\n```\npython -u -m mlflow_export_import.experiment.export_experiment --help\n```\n\n## Testing\n\nTwo types of tests exist: open source and Databricks tests.\nSee [tests/README](tests/README.md).\n\n### Workflow API\n\n* [README.md](mlflow_export_import/workflow_api/README.md)\n* The WorkflowApiClient is a Python wrapper around the Databricks REST API to execute job runs in a synchronous polling manner.\n* Although a generic tool, in terms of mlflow-export-import it used for testing Databricks notebook jobs.\n\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/mlflow/mlflow-export-import",
    "keywords": "mlflow ml ai",
    "license": "Apache License 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "mlflow-export-import",
    "package_url": "https://pypi.org/project/mlflow-export-import/",
    "platform": null,
    "project_url": "https://pypi.org/project/mlflow-export-import/",
    "project_urls": {
      "Bug Tracker": "https://github.com/mlflow/mlflow-export-import/issues",
      "Documentation": "https://github.com/mlflow/mlflow-export-import/blob/master/README.md",
      "Homepage": "https://github.com/mlflow/mlflow-export-import",
      "Source Code": "https://github.com/mlflow/mlflow-export-import/"
    },
    "release_url": "https://pypi.org/project/mlflow-export-import/1.0.1/",
    "requires_dist": [
      "mlflow (>=1.26.0)",
      "wheel"
    ],
    "requires_python": ">=3.7",
    "summary": "Copy MLflow objects (experiments, runs or registered models) to another tracking server",
    "version": "1.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16891767,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "50301531b26115ea656dd16f029b63bee69b9585a6fa0e618e52b155ffa92699",
        "md5": "1fdb0bdb9068facd9ac488bc87ed9ba2",
        "sha256": "ed036a604d570b12ed50eebcdef42bed0447a2fe3f345a01daad51d03a3ef7f9"
      },
      "downloads": -1,
      "filename": "mlflow_export_import-1.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "1fdb0bdb9068facd9ac488bc87ed9ba2",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 48898,
      "upload_time": "2022-07-06T02:18:55",
      "upload_time_iso_8601": "2022-07-06T02:18:55.882553Z",
      "url": "https://files.pythonhosted.org/packages/50/30/1531b26115ea656dd16f029b63bee69b9585a6fa0e618e52b155ffa92699/mlflow_export_import-1.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}