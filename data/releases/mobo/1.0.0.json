{
  "info": {
    "author": "Seaton Ullberg",
    "author_email": "sullberg@ufl.edu",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# mobo\n\n## Introduction\n\n`mobo` is an algorithm to solve multi-objective problems without imposing the bias of weights. Rather than converging to a single 'optimal' solution, `mobo` produces an ensamble of rational solutions which may then be further downselected according to the constraints of a particular application.\n\n## Installation\n\n`mobo` can be installed simply with pip.\n\n```bash\n$ python3 -m pip install mobo\n```\n\nFor testing or development you will need to clone the repo.\n\n```bash\n$ git clone https://github.com/seatonullberg/mobo.git\n```\n\n## Example\n\nAn introductory example, fitting a polynomial, is available in the [examples directory](./examples). Snippets of that example will be shown here. The first step in preparing an optimizer is to define the parameters which are being optimized.\n\n```python\nparameters = [\n        Parameter(\"a\", -1.0, 1.0),\n        Parameter(\"b\", -2.0, 0.0),\n        Parameter(\"c\", 0.0, 1.0)\n]\n```\n\nEach parameter has a name, a lower bound, and an upper bound. Next, it is necessary to define the quantities of interest which will be evaluated with the fitted parameters.\n\n```python\nqois = [\n        QoI(\"pt0\", evaluate_pt0, -0.062),\n        QoI(\"pt1\", evaluate_pt1, 0.05),\n        QoI(\"pt2\", evaluate_pt2, -1.4),\n        QoI(\"pt3\", evaluate_pt3, 2.0)\n]\n```\n\nEach quantity of interest has a name, an associated evaluation function, and a target value. The evaluation function should take only a dict mapping parameter names to their values as its argument and return a float.\n\n```python\n# target coefficients: 0.3, -1.2, 0.5\npolynomial = lambda a, b, c, x: a*x**3 + b*x**2 + c*x\n\n# target: -0.062\ndef evaluate_pt0(params):\n    x = -0.1\n    return polynomial(params[\"a\"], params[\"b\"], params[\"c\"], x)\n```\n\nAfter these fundamental components are defined, the mobo-centric components should be chosen.\n\n```python\nclusterer = KmeansClusterer(n_clusters=2)\nerror_calculator = SquaredErrorCalculator()\nfilters = [ParetoFilter(), PercentileFilter()]\nprojector = PCAProjector()\n```\n\nA clusterer is required to partition the parameter space, an error calculator is required to determine a cost, filters are used to purge poor parameterizations, and a projector is used to project a high dimensional parameter space down to 2D for more effective clustering. Since this algorithm is iterative, each iteration requires a 'local' configuration which is passed into a 'global' configuration before finally constructing the optimizer.\n\n```python\nlocal_config = LocalConfiguration(\n    n_samples, clusterer, error_calculator, filters, projector\n)\nlocal_configurations = [local_config for _ in range(n_iterations)]\nglobal_config = GlobalConfiguration(\n    n_samples, local_configurations, parameters, qois\n)\n```\n\nOnce the global configuration has been constructed, execution of the optimizer is trivial.\n\n```python\noptimizer = Optimizer(global_config)\noptimizer()\n```\n\nAs an aside, you may notice that this optimizer is a callable object. I use this theme in many objects which only expose publicly a single method. After optimization you will be left with some data files representing the results of each iteration. If you were to visualize the final results, you should see something like this.\n\n![polynomial fit results](./figures/polynomial_predictions.png)\n\nThe black line is the target polynomial, the black dots are the points used as quantities of interest, the blue lines are the predictions from cluster 0 and the red lines are predictions from cluster 1. As you can see, the fit is quite close. Other choices of points to evaluate should yield similar results so long as they are near the local extrema. The following plot attempts to illustrate some of the internal mechanics.\n\n![polynomial cluster results](./figures/polynomial_clusters.png)\n\nThe points are parameters projected down onto their primary PCA vectors. Blue points correspond to parameterizations from cluster 0 and red from cluster 1. This view is essentially what the KDE sampler \"sees\" when it is selecting new parameterizations. This view helps to show why the parameters in different clusters are producing distinct predictions.\n\n## Algorithm Description\n\nTODO\n\n## Acknowledgements\n\nThe implementation of this algorithm is based upon work I contributed to in [pypospack](https://github.com/eragasa/pypospack). The `pypospack` project is the focus of [this dissertation](http://phillpot.mse.ufl.edu/wp-content/uploads/2019/08/2019_Ragasa_Dissertation.pdf) which you may be interested in reading for a more in-depth description of the mathematics involved or alternative applications of the algorithm.\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/seatonullberg/mobo",
    "keywords": "",
    "license": "BSD 2-Clause License",
    "maintainer": "",
    "maintainer_email": "",
    "name": "mobo",
    "package_url": "https://pypi.org/project/mobo/",
    "platform": "",
    "project_url": "https://pypi.org/project/mobo/",
    "project_urls": {
      "Homepage": "https://github.com/seatonullberg/mobo"
    },
    "release_url": "https://pypi.org/project/mobo/1.0.0/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "A rational and extensible algorithm for solving multi-objective optimization problems",
    "version": "1.0.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 6152417,
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "8a5989c61e4c1954e11c78e472decf45180509e0d5c1a6296788150a763cee29",
        "md5": "dd16073ba5c33bed73d721759d490190",
        "sha256": "b7a91d8e6620696c2fc460e97e55d64eef20d3e3e28430a3615b5af91603b687"
      },
      "downloads": -1,
      "filename": "mobo-1.0.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "dd16073ba5c33bed73d721759d490190",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 13640,
      "upload_time": "2019-11-18T00:28:05",
      "upload_time_iso_8601": "2019-11-18T00:28:05.550788Z",
      "url": "https://files.pythonhosted.org/packages/8a/59/89c61e4c1954e11c78e472decf45180509e0d5c1a6296788150a763cee29/mobo-1.0.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "557759cae7ffa7c83b4e9bd381248061e0454b3cc0d992fbb9c029cc1c9bb1f3",
        "md5": "1b5921cdfd5e6a40a9cca5c7dec9fe6b",
        "sha256": "89e2e7ea617825b55750ecafe37502d3da650abbbc80c8bc41708ff4731e21c1"
      },
      "downloads": -1,
      "filename": "mobo-1.0.0.tar.gz",
      "has_sig": false,
      "md5_digest": "1b5921cdfd5e6a40a9cca5c7dec9fe6b",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 11015,
      "upload_time": "2019-11-18T00:28:07",
      "upload_time_iso_8601": "2019-11-18T00:28:07.326532Z",
      "url": "https://files.pythonhosted.org/packages/55/77/59cae7ffa7c83b4e9bd381248061e0454b3cc0d992fbb9c029cc1c9bb1f3/mobo-1.0.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}