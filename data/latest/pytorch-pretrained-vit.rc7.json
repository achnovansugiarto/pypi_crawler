{
  "info": {
    "author": "Luke",
    "author_email": "luke.melas@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: Apache Software License",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.6"
    ],
    "description": "# ViT PyTorch\n\n### Quickstart\n\nInstall with `pip install pytorch_pretrained_vit` and load a pretrained ViT with:\n```python\nfrom pytorch_pretrained_vit import ViT\nmodel = ViT('B_16_imagenet1k', pretrained=True)\n```\n\nOr find a Google Colab example [here](https://colab.research.google.com/drive/1muZ4QFgVfwALgqmrfOkp7trAvqDemckO?usp=sharing).  \n\n### Overview\nThis repository contains an op-for-op PyTorch reimplementation of the [Visual Transformer](https://openreview.net/forum?id=YicbFdNTTy) architecture from [Google](https://github.com/google-research/vision_transformer), along with pre-trained models and examples.\n\nThe goal of this implementation is to be simple, highly extensible, and easy to integrate into your own projects. \n\nAt the moment, you can easily:\n * Load pretrained ViT models\n * Evaluate on ImageNet or your own data\n * Finetune ViT on your own dataset\n\n_(Upcoming features)_ Coming soon: \n * Train ViT from scratch on ImageNet (1K)\n * Export to ONNX for efficient inference\n\n### Table of contents\n1. [About ViT](#about-vit)\n2. [About ViT-PyTorch](#about-vit-pytorch)\n3. [Installation](#installation)\n4. [Usage](#usage)\n    * [Load pretrained models](#loading-pretrained-models)\n    * [Example: Classify](#example-classification)\n    <!-- * [Example: Extract features](#example-feature-extraction) -->\n    <!-- * [Example: Export to ONNX](#example-export) -->\n6. [Contributing](#contributing)\n\n### About ViT\n\nVisual Transformers (ViT) are a straightforward application of the [transformer architecture](https://arxiv.org/abs/1706.03762) to image classification. Even in computer vision, it seems, attention is all you need. \n\nThe ViT architecture works as follows: (1) it considers an image as a 1-dimensional sequence of patches, (2) it prepends a classification token to the sequence, (3) it passes these patches through a transformer encoder (like [BERT](https://arxiv.org/abs/1810.04805)), (4) it passes the first token of the output of the transformer through a small MLP to obtain the classification logits. \nViT is trained on a large-scale dataset (ImageNet-21k) with a huge amount of compute. \n\n<div style=\"text-align: center; padding: 10px\">\n    <img src=\"https://raw.githubusercontent.com/google-research/vision_transformer/master/figure1.png\" width=\"100%\" style=\"max-width: 300px; margin: auto\"/>\n</div>\n\n\n### About ViT-PyTorch\n\nViT-PyTorch is a PyTorch re-implementation of ViT. It is consistent with the [original Jax implementation](https://github.com/google-research/vision_transformer), so that it's easy to load Jax-pretrained weights.\n\nAt the same time, we aim to make our PyTorch implementation as simple, flexible, and extensible as possible.\n\n### Installation\n\nInstall with pip:\n```bash\npip install pytorch_pretrained_vit\n```\n\nOr from source:\n```bash\ngit clone https://github.com/lukemelas/ViT-PyTorch\ncd ViT-Pytorch\npip install -e .\n```\n\n### Usage\n\n#### Loading pretrained models\n\nLoading a pretrained model is easy:\n```python\nfrom pytorch_pretrained_vit import ViT\nmodel = ViT('B_16_imagenet1k', pretrained=True)\n```\n\nDetails about the models are below:\n\n|    *Name*         |* Pretrained on *|*Finetuned on*|*Available? *|\n|:-----------------:|:---------------:|:------------:|:-----------:|\n| `B_16`            |  ImageNet-21k   | -            |      ✓      |\n| `B_32`            |  ImageNet-21k   | -            |      ✓      |\n| `L_16`            |  ImageNet-21k   | -            |      -      |\n| `L_32`            |  ImageNet-21k   | -            |      ✓      |\n| `B_16_imagenet1k` |  ImageNet-21k   | ImageNet-1k  |      ✓      |\n| `B_32_imagenet1k` |  ImageNet-21k   | ImageNet-1k  |      ✓      |\n| `L_16_imagenet1k` |  ImageNet-21k   | ImageNet-1k  |      ✓      |\n| `L_32_imagenet1k` |  ImageNet-21k   | ImageNet-1k  |      ✓      |\n\n#### Custom ViT\n\nLoading custom configurations is just as easy: \n```python\nfrom pytorch_pretrained_vit import ViT\n# The following is equivalent to ViT('B_16')\nconfig = dict(hidden_size=512, num_heads=8, num_layers=6)\nmodel = ViT.from_config(config)\n```\n\n#### Example: Classification\n\nBelow is a simple, complete example. It may also be found as a Jupyter notebook in `examples/simple` or as a [Colab Notebook]().  \n<!-- TODO: new Colab -->\n\n```python\nimport json\nfrom PIL import Image\nimport torch\nfrom torchvision import transforms\n\n# Load ViT\nfrom pytorch_pretrained_vit import ViT\nmodel = ViT('B_16_imagenet1k', pretrained=True)\nmodel.eval()\n\n# Load image\n# NOTE: Assumes an image `img.jpg` exists in the current directory\nimg = transforms.Compose([\n    transforms.Resize((384, 384)), \n    transforms.ToTensor(),\n    transforms.Normalize(0.5, 0.5),\n])(Image.open('img.jpg')).unsqueeze(0)\nprint(img.shape) # torch.Size([1, 3, 384, 384])\n\n# Classify\nwith torch.no_grad():\n    outputs = model(img)\nprint(outputs.shape)  # (1, 1000)\n```\n\n<!-- #### Example: Feature Extraction\n\nYou can easily extract features with `model.extract_features`:\n```python\nfrom efficientnet_pytorch import EfficientNet\nmodel = EfficientNet.from_pretrained('efficientnet-b0')\n\n# ... image preprocessing as in the classification example ...\nprint(img.shape) # torch.Size([1, 3, 384, 384])\n\nfeatures = model.extract_features(img)\nprint(features.shape) # torch.Size([1, 1280, 7, 7])\n``` -->\n\n<!-- #### Example: Export to ONNX\n\nExporting to ONNX for deploying to production is now simple:\n```python\nimport torch\nfrom efficientnet_pytorch import EfficientNet\n\nmodel = EfficientNet.from_pretrained('efficientnet-b1')\ndummy_input = torch.randn(10, 3, 240, 240)\n\nmodel.set_swish(memory_efficient=False)\ntorch.onnx.export(model, dummy_input, \"test-b1.onnx\", verbose=True)\n```\n\n[Here](https://colab.research.google.com/drive/1rOAEXeXHaA8uo3aG2YcFDHItlRJMV0VP) is a Colab example. -->\n\n\n#### ImageNet\n\nSee `examples/imagenet` for details about evaluating on ImageNet.\n\n#### Credit\n\nOther great repositories with this model include: \n - [Ross Wightman's repo](https://github.com/rwightman/pytorch-image-models)\n - [Phil Wang's repo](https://github.com/lucidrains/vit-pytorch)\n\n### Contributing\n\nIf you find a bug, create a GitHub issue, or even better, submit a pull request. Similarly, if you have questions, simply post them as GitHub issues.\n\nI look forward to seeing what the community does with these models!",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/lukemelas/ViT-PyTorch",
    "keywords": "",
    "license": "Apache",
    "maintainer": "",
    "maintainer_email": "",
    "name": "pytorch-pretrained-vit",
    "package_url": "https://pypi.org/project/pytorch-pretrained-vit/",
    "platform": "",
    "project_url": "https://pypi.org/project/pytorch-pretrained-vit/",
    "project_urls": {
      "Homepage": "https://github.com/lukemelas/ViT-PyTorch"
    },
    "release_url": "https://pypi.org/project/pytorch-pretrained-vit/0.0.7/",
    "requires_dist": null,
    "requires_python": ">=3.5.0",
    "summary": "Visual Transformers (ViT) in PyTorch.",
    "version": "0.0.7",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8609892,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5dbadf75d0cb9db876f00e7fdb0770916fa836afb2505697638205b1a392f437",
          "md5": "da4c5fcc700ab4776fc819124e49bc24",
          "sha256": "f4d9d1b0d2e02b419e192d14820dd1597381bec270c728320bec46400089006b"
        },
        "downloads": -1,
        "filename": "pytorch-pretrained-vit-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "da4c5fcc700ab4776fc819124e49bc24",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5.0",
        "size": 9967,
        "upload_time": "2020-10-30T15:50:57",
        "upload_time_iso_8601": "2020-10-30T15:50:57.315268Z",
        "url": "https://files.pythonhosted.org/packages/5d/ba/df75d0cb9db876f00e7fdb0770916fa836afb2505697638205b1a392f437/pytorch-pretrained-vit-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1824ed791c8b35ba41e80334b126d6fdf8fd0335764e761773dfabaebe5b348b",
          "md5": "9ef39c0027e040657e6670957945b664",
          "sha256": "a3a27c1f5dd00eafa6e9d4e41f158e428930c451cca9eeeace4e6b6bc12da2d2"
        },
        "downloads": -1,
        "filename": "pytorch-pretrained-vit-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "9ef39c0027e040657e6670957945b664",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5.0",
        "size": 12390,
        "upload_time": "2020-10-30T15:56:09",
        "upload_time_iso_8601": "2020-10-30T15:56:09.507047Z",
        "url": "https://files.pythonhosted.org/packages/18/24/ed791c8b35ba41e80334b126d6fdf8fd0335764e761773dfabaebe5b348b/pytorch-pretrained-vit-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "55e25694d46c2bd74ea598558d9608b8454b40c62d4614061a39a58673353f2b",
          "md5": "3c6cb3fd494c201a7ac6ad5e09ffb57c",
          "sha256": "2fbca1270c3496f91530545ce8d31542b8cad19661dabc3b1a116787a27b5884"
        },
        "downloads": -1,
        "filename": "pytorch-pretrained-vit-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "3c6cb3fd494c201a7ac6ad5e09ffb57c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5.0",
        "size": 12435,
        "upload_time": "2020-11-03T22:58:58",
        "upload_time_iso_8601": "2020-11-03T22:58:58.586263Z",
        "url": "https://files.pythonhosted.org/packages/55/e2/5694d46c2bd74ea598558d9608b8454b40c62d4614061a39a58673353f2b/pytorch-pretrained-vit-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "13da1378a895be5c4632a017e686eaca96b72e7ddfb82d471f238c0d8363b00b",
          "md5": "6545b04b320bba141fb71f46afea4072",
          "sha256": "4765aec6082ff084dea04d87eec5dad2861a84ab665e5f59b7656e4f98fcaeac"
        },
        "downloads": -1,
        "filename": "pytorch-pretrained-vit-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "6545b04b320bba141fb71f46afea4072",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5.0",
        "size": 12462,
        "upload_time": "2020-11-03T23:09:00",
        "upload_time_iso_8601": "2020-11-03T23:09:00.208586Z",
        "url": "https://files.pythonhosted.org/packages/13/da/1378a895be5c4632a017e686eaca96b72e7ddfb82d471f238c0d8363b00b/pytorch-pretrained-vit-0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "29796ee37268dd4448d3a06b03c47de3df120b61a0fe58ba470ff208483e72b4",
          "md5": "165081a9bc392080debee2535b169100",
          "sha256": "1336db5300d263d63433e8211345eca15ca37ed4033ed20efacee5d5a8478c70"
        },
        "downloads": -1,
        "filename": "pytorch-pretrained-vit-0.0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "165081a9bc392080debee2535b169100",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5.0",
        "size": 12521,
        "upload_time": "2020-11-03T23:15:10",
        "upload_time_iso_8601": "2020-11-03T23:15:10.831319Z",
        "url": "https://files.pythonhosted.org/packages/29/79/6ee37268dd4448d3a06b03c47de3df120b61a0fe58ba470ff208483e72b4/pytorch-pretrained-vit-0.0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3632d5744e26589969dde2ad95a70e9c6f2fa06af21626b9d486093602063f54",
          "md5": "cd132ef38df1b30650276605e7ad7dcc",
          "sha256": "3f8760d7d323b55a2afedc3ac8868bdfd0d92a26fc8903b6dfce4481db24abc5"
        },
        "downloads": -1,
        "filename": "pytorch-pretrained-vit-0.0.6.tar.gz",
        "has_sig": false,
        "md5_digest": "cd132ef38df1b30650276605e7ad7dcc",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5.0",
        "size": 12506,
        "upload_time": "2020-11-03T23:25:12",
        "upload_time_iso_8601": "2020-11-03T23:25:12.665969Z",
        "url": "https://files.pythonhosted.org/packages/36/32/d5744e26589969dde2ad95a70e9c6f2fa06af21626b9d486093602063f54/pytorch-pretrained-vit-0.0.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "028db404fe410a984ce2bc95a8ce02d397e3b8b12d6dd3118db6ac9b8edaa370",
          "md5": "f868742c7a9a78993493e1fdfaf128bf",
          "sha256": "2c74057c5898c63c0076ac518645bcea0f380b8b1aa73dbb8fedbedec757e6ec"
        },
        "downloads": -1,
        "filename": "pytorch-pretrained-vit-0.0.7.tar.gz",
        "has_sig": false,
        "md5_digest": "f868742c7a9a78993493e1fdfaf128bf",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5.0",
        "size": 13060,
        "upload_time": "2020-11-08T22:52:57",
        "upload_time_iso_8601": "2020-11-08T22:52:57.577422Z",
        "url": "https://files.pythonhosted.org/packages/02/8d/b404fe410a984ce2bc95a8ce02d397e3b8b12d6dd3118db6ac9b8edaa370/pytorch-pretrained-vit-0.0.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "028db404fe410a984ce2bc95a8ce02d397e3b8b12d6dd3118db6ac9b8edaa370",
        "md5": "f868742c7a9a78993493e1fdfaf128bf",
        "sha256": "2c74057c5898c63c0076ac518645bcea0f380b8b1aa73dbb8fedbedec757e6ec"
      },
      "downloads": -1,
      "filename": "pytorch-pretrained-vit-0.0.7.tar.gz",
      "has_sig": false,
      "md5_digest": "f868742c7a9a78993493e1fdfaf128bf",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.5.0",
      "size": 13060,
      "upload_time": "2020-11-08T22:52:57",
      "upload_time_iso_8601": "2020-11-08T22:52:57.577422Z",
      "url": "https://files.pythonhosted.org/packages/02/8d/b404fe410a984ce2bc95a8ce02d397e3b8b12d6dd3118db6ac9b8edaa370/pytorch-pretrained-vit-0.0.7.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}