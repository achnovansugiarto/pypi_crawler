{
  "info": {
    "author": "Roy Lam",
    "author_email": "13032765d@connect.polyu.hk",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# similarweb_scraper\n\nsimilarweb_scraperis is a python library for scraping similarweb with proxycrawl api and it can bypass the distil projection so far. It also provides some functionality for transforming scraped data into pd dataframe.\n\n## Installation\n\nUse the package manager [pip](https://pip.pypa.io/en/stable/) to install foobar.\n\n```bash\npip install similarweb-scraper\n\n## Usage\n\nfrom similarweb_scraper import scraper\n\n### get the website html\nweb_scrape = scraper()\nweb_scrape.login(#api key from proxycrawl.com)\nweb_scrape.webpage_scrape(#websit e.g: hk.yahoo.com)\n\n### get the html code\nsoup = web_scrape.og_soup\n### get the html code as json format\nweb_json = web_scrape.json_storage\n\n### get data into json format\ndf = web_scrape.metrics_to_df(#str(metrics_type))\n##metrics_type name :\n#'country_share',\n#'traffic_share',\n# engagement',\n#'monthly_traffic_data'\n# more function will be available soon\n```\n\n## Contributing\nPull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.\n\nPlease make sure to update tests as appropriate.\n\n## License\n[MIT](https://choosealicense.com/licenses/mit/)\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/wchan757/similarweb_scraper",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "similarweb-scraper",
    "package_url": "https://pypi.org/project/similarweb-scraper/",
    "platform": "",
    "project_url": "https://pypi.org/project/similarweb-scraper/",
    "project_urls": {
      "Homepage": "https://github.com/wchan757/similarweb_scraper"
    },
    "release_url": "https://pypi.org/project/similarweb-scraper/0.0.3/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "Using proxycrawl api to scrape similarweb data",
    "version": "0.0.3",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 5999545,
  "releases": {
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "da4ee61f460dd477ecf708e24712412c6dd6f4ea6c7511adebf3709de2946867",
          "md5": "6e9c35b4a41c54bacc9eb7670f52f05b",
          "sha256": "53b97147230b96a5c684a718afd96120b1fc1cf2de27211cdcb11cc95c149a01"
        },
        "downloads": -1,
        "filename": "similarweb_scraper-0.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "6e9c35b4a41c54bacc9eb7670f52f05b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 5519,
        "upload_time": "2019-10-19T11:01:10",
        "upload_time_iso_8601": "2019-10-19T11:01:10.236721Z",
        "url": "https://files.pythonhosted.org/packages/da/4e/e61f460dd477ecf708e24712412c6dd6f4ea6c7511adebf3709de2946867/similarweb_scraper-0.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1a5449810b1d07df0451749235afba64f541c2b5481febc7cd8a95ade2f9fac7",
          "md5": "ffc3204289dc78199c8a4fedd5728e68",
          "sha256": "3e9d46c8e16f5f71eb872df997eb9e9687c95dd4aa4bcf731ebefb15286302f3"
        },
        "downloads": -1,
        "filename": "similarweb_scraper-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "ffc3204289dc78199c8a4fedd5728e68",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 3923,
        "upload_time": "2019-10-19T11:01:12",
        "upload_time_iso_8601": "2019-10-19T11:01:12.125308Z",
        "url": "https://files.pythonhosted.org/packages/1a/54/49810b1d07df0451749235afba64f541c2b5481febc7cd8a95ade2f9fac7/similarweb_scraper-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "da4ee61f460dd477ecf708e24712412c6dd6f4ea6c7511adebf3709de2946867",
        "md5": "6e9c35b4a41c54bacc9eb7670f52f05b",
        "sha256": "53b97147230b96a5c684a718afd96120b1fc1cf2de27211cdcb11cc95c149a01"
      },
      "downloads": -1,
      "filename": "similarweb_scraper-0.0.3-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "6e9c35b4a41c54bacc9eb7670f52f05b",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 5519,
      "upload_time": "2019-10-19T11:01:10",
      "upload_time_iso_8601": "2019-10-19T11:01:10.236721Z",
      "url": "https://files.pythonhosted.org/packages/da/4e/e61f460dd477ecf708e24712412c6dd6f4ea6c7511adebf3709de2946867/similarweb_scraper-0.0.3-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "1a5449810b1d07df0451749235afba64f541c2b5481febc7cd8a95ade2f9fac7",
        "md5": "ffc3204289dc78199c8a4fedd5728e68",
        "sha256": "3e9d46c8e16f5f71eb872df997eb9e9687c95dd4aa4bcf731ebefb15286302f3"
      },
      "downloads": -1,
      "filename": "similarweb_scraper-0.0.3.tar.gz",
      "has_sig": false,
      "md5_digest": "ffc3204289dc78199c8a4fedd5728e68",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 3923,
      "upload_time": "2019-10-19T11:01:12",
      "upload_time_iso_8601": "2019-10-19T11:01:12.125308Z",
      "url": "https://files.pythonhosted.org/packages/1a/54/49810b1d07df0451749235afba64f541c2b5481febc7cd8a95ade2f9fac7/similarweb_scraper-0.0.3.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}