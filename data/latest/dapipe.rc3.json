{
  "info": {
    "author": "Ariel Iporre",
    "author_email": "ariel.iporre.rivas@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: Apache Software License",
      "Programming Language :: Python :: 3.7",
      "Topic :: Software Development :: Build Tools"
    ],
    "description": "<h1 align=\"center\"> DPIPE</h1>\n\n<p align=\"center\">\n  <img src=\"images/pipeguy.png\" data-canonical-src=\"https://gyazo.com/eb5c5741b6a9a16c692170a41a49c858.png\" width=\"200\" />\n</p>\n\n[![Documentation](http://inch-ci.org/github/dwyl/hapi-auth-jwt2.svg?branch=master)](https://multidataloader.readthedocs.io/en/latest/) \n\nWith dpipe you can create ready to use datasets from paths or list of files. You should \nspecify the type and the location of the input and target. The labels are assumed to be the name of the folder containing the file,\nif you need a dataset for classification. \n\nThe inputs and targets can be a list of paths, a path to be explored containing images or videos. For example:\n````shell script\n./dataset\n  |\n  |--cat/img1.png|\n  |--cat/img2.png\n  |--dog/img1.png\n  |--dog/img2.png\n````\nThe function `make_dataset` outputs a `dpipe.dataset_builder` object that has the method to predefined multiprocessing setups based on the recomendation of tensorflow.\n\n| method        | action          \n| ------------- |:-------------:| \n| `dataset_builder.prefetch()`      | Preloads samples on memory |\n| `dataset_builder.batch()`      | Creates a batch dataset |\n| `dataset_builder.enumerate()`      | Creates a appends an index to the output |\n| `dataset_builder.filter()`      | Applies a filter concurrently |\n| `dataset_builder.map()`      | Applies a function to each element concurrently |\n| `dataset_builder.repeat()`      | Creates a repeated dataset |\n| `dataset_builder.shuffle()`      | Shuffles the dataset after a complete run |\n \n\nThe dataset can be specified as:\n````python\nfrom dpipe import make_dataset\ndataset = make_dataset('image','label',x_path='./dataset',x_size=(128,128)).build()\n````\n## Creating dataset (more options)\nAdditionally, we defined the dataset from functions or objects. Two use cases are presented here. A dataset can be created from a function and a list of element to parse, for example a list of files and a reading function. \nFor example, if we need are training a denoising autoencoder, we need image noisy and clean image pairs; this can be handled with the function `dpipe.from_function`:\n```python\nimport glob # to find the files\nimport matplotlib.image as mpimg # to read the images (you need to install it.)\nimport numpy as np\nfrom dpipe import from_function\n\nfilelist = glob.glob('./dataset','*.png')\ndef read_file(filename):\n    target = mpimg.imread(filename) # read the image\n    noisy_image = np.random.randn(target.shape)\n    return noisy_image, target\n# undetermined shape is used to define dimentions that vary across shamples, in this case the height and the width of the images\ndataset = from_function(read_file, filelist, undetermined_shape=((1,2),(1,2))).build()\n```\nIf you are accessing your data in an object oriented way, you can use `dpipe.from_object`. In the next example lets consider you want use consume a list of files with records on it via generator function, this can also be handled with `dpipe.from_function` though. The code should look like this\n```python\nimport os\nimport pandas as pd\nfrom dpipe import from_object\n\nclass Reader():\n    def __init__(self,datapath='./dataset'):\n        self.filelist = os.listdir(datapath)\n    def __len__(self):\n        return len(self.filelist)\n    def my_reading_function(self,filename):\n        df = pd.read_csv(filename)\n        for v, t in zip(df.values, df.targets):\n            yield v, t\nreader = Reader()\ndataset = from_object(reader, 'my_reading_function','filelist').build()\n```\nThe `build()` function that creates a dataset with arguments ready to use with the `fit()` method of and `tf.model` object. This is used like this:\n```python\ntraining_ds = from_object(reader_training, 'my_reading_function').shuffle(len(reader_training), reshuffle_each_iteration=True).batch(32).repeat().build()\nvalidation_ds = from_object(reader_validation, 'my_reading_function',training=False).batch(32).build()\nmodel.fit(x=training_ds,validation_data=validation_ds, epochs=10,**training_ds.built_args,**validation_ds_ds.built_args)\n```\n# Installation\n````shell script\npip install dapipe\n````\nIt requires to install FFMPEG ([here](https://www.ffmpeg.org)) to work with video formats.",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "https://github.com/aiporre/multidataloader/archive/v0.2.1.tar.gz",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/aiporre/multidataloader.git",
    "keywords": "",
    "license": "Apache License Version 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "dapipe",
    "package_url": "https://pypi.org/project/dapipe/",
    "platform": "",
    "project_url": "https://pypi.org/project/dapipe/",
    "project_urls": {
      "Download": "https://github.com/aiporre/multidataloader/archive/v0.2.1.tar.gz",
      "Homepage": "https://github.com/aiporre/multidataloader.git"
    },
    "release_url": "https://pypi.org/project/dapipe/0.2.1/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "Creates dataset builder objects",
    "version": "0.2.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8894407,
  "releases": {
    "0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8dbeb9bab26265b3e92ea45179a3e74d9b2e462e35cfcdb7bde99bb6e2096086",
          "md5": "247a6741fb7be296c1d634637d4b22dc",
          "sha256": "a0df72befe0ecc0e986988ec5cb525de1b4525ebd0c2604e91524f0f24955a5e"
        },
        "downloads": -1,
        "filename": "dapipe-0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "247a6741fb7be296c1d634637d4b22dc",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 12388,
        "upload_time": "2020-02-24T12:20:43",
        "upload_time_iso_8601": "2020-02-24T12:20:43.175089Z",
        "url": "https://files.pythonhosted.org/packages/8d/be/b9bab26265b3e92ea45179a3e74d9b2e462e35cfcdb7bde99bb6e2096086/dapipe-0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "27b302936d264075f27f256ca721d1a4037de48697128821ab1a382f52d08901",
          "md5": "8c15c287acaf2fd87f0943dce0efc724",
          "sha256": "39a486a4aa32dcb6cc0df342184498abd6a4f0460f500ca2e8530772fe052c57"
        },
        "downloads": -1,
        "filename": "dapipe-0.2.1-py3.7.egg",
        "has_sig": false,
        "md5_digest": "8c15c287acaf2fd87f0943dce0efc724",
        "packagetype": "bdist_egg",
        "python_version": "3.7",
        "requires_python": null,
        "size": 39774,
        "upload_time": "2020-12-14T10:15:25",
        "upload_time_iso_8601": "2020-12-14T10:15:25.294541Z",
        "url": "https://files.pythonhosted.org/packages/27/b3/02936d264075f27f256ca721d1a4037de48697128821ab1a382f52d08901/dapipe-0.2.1-py3.7.egg",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fa131b6b7acc8a69fe4e2d863b65373efc6414965af323bcea70f2b519149c2a",
          "md5": "40431e570e28fe4d1210ce19018f8ff2",
          "sha256": "370d9342b33caccda881e6cc290d898753c5ddce14c0c01986803d6e9fb6d97a"
        },
        "downloads": -1,
        "filename": "dapipe-0.2.1.tar.gz",
        "has_sig": false,
        "md5_digest": "40431e570e28fe4d1210ce19018f8ff2",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 15602,
        "upload_time": "2020-12-14T10:15:26",
        "upload_time_iso_8601": "2020-12-14T10:15:26.793209Z",
        "url": "https://files.pythonhosted.org/packages/fa/13/1b6b7acc8a69fe4e2d863b65373efc6414965af323bcea70f2b519149c2a/dapipe-0.2.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "45e4b15fc2aa0112e4790c9b30cd2ac1c23995f70bf925a3b70d64e62d74f290",
          "md5": "e93fff64b1087960dee45f50088c0737",
          "sha256": "aa994e2b9cafa53610f9bbab98ba5a6302d5625685b9a9df677256fe37224cc0"
        },
        "downloads": -1,
        "filename": "dapipe-0.3-py3.7.egg",
        "has_sig": false,
        "md5_digest": "e93fff64b1087960dee45f50088c0737",
        "packagetype": "bdist_egg",
        "python_version": "3.7",
        "requires_python": null,
        "size": 39773,
        "upload_time": "2020-12-14T10:15:28",
        "upload_time_iso_8601": "2020-12-14T10:15:28.336874Z",
        "url": "https://files.pythonhosted.org/packages/45/e4/b15fc2aa0112e4790c9b30cd2ac1c23995f70bf925a3b70d64e62d74f290/dapipe-0.3-py3.7.egg",
        "yanked": true,
        "yanked_reason": "version 0.3 will wait tensorflow 2.4 official release"
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c253b812c154b8e75ead103e0bc89e928e805019ff9ce725d138473e1ced5b02",
          "md5": "9b6128a18061fa9df808db2c35607dc3",
          "sha256": "147f393a510ba1c753b0f90fd9e3f00bf072b8daebe243306c8ac2729d332d81"
        },
        "downloads": -1,
        "filename": "dapipe-0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "9b6128a18061fa9df808db2c35607dc3",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 15548,
        "upload_time": "2020-12-14T10:15:29",
        "upload_time_iso_8601": "2020-12-14T10:15:29.492807Z",
        "url": "https://files.pythonhosted.org/packages/c2/53/b812c154b8e75ead103e0bc89e928e805019ff9ce725d138473e1ced5b02/dapipe-0.3.tar.gz",
        "yanked": true,
        "yanked_reason": "version 0.3 will wait tensorflow 2.4 official release"
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "27b302936d264075f27f256ca721d1a4037de48697128821ab1a382f52d08901",
        "md5": "8c15c287acaf2fd87f0943dce0efc724",
        "sha256": "39a486a4aa32dcb6cc0df342184498abd6a4f0460f500ca2e8530772fe052c57"
      },
      "downloads": -1,
      "filename": "dapipe-0.2.1-py3.7.egg",
      "has_sig": false,
      "md5_digest": "8c15c287acaf2fd87f0943dce0efc724",
      "packagetype": "bdist_egg",
      "python_version": "3.7",
      "requires_python": null,
      "size": 39774,
      "upload_time": "2020-12-14T10:15:25",
      "upload_time_iso_8601": "2020-12-14T10:15:25.294541Z",
      "url": "https://files.pythonhosted.org/packages/27/b3/02936d264075f27f256ca721d1a4037de48697128821ab1a382f52d08901/dapipe-0.2.1-py3.7.egg",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "fa131b6b7acc8a69fe4e2d863b65373efc6414965af323bcea70f2b519149c2a",
        "md5": "40431e570e28fe4d1210ce19018f8ff2",
        "sha256": "370d9342b33caccda881e6cc290d898753c5ddce14c0c01986803d6e9fb6d97a"
      },
      "downloads": -1,
      "filename": "dapipe-0.2.1.tar.gz",
      "has_sig": false,
      "md5_digest": "40431e570e28fe4d1210ce19018f8ff2",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 15602,
      "upload_time": "2020-12-14T10:15:26",
      "upload_time_iso_8601": "2020-12-14T10:15:26.793209Z",
      "url": "https://files.pythonhosted.org/packages/fa/13/1b6b7acc8a69fe4e2d863b65373efc6414965af323bcea70f2b519149c2a/dapipe-0.2.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}