{
  "info": {
    "author": "Antonio Di Mariano",
    "author_email": "antonio.dimariano@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "\n## Description:\n\nThis module provides a wrapper around the [confluent-kafka-python](https://github.com/confluentinc/confluent-kafka-python) \nto simplify the creation and usage of producers by hiding the configuration details. \nIn particular, when it comes to using a schema registry, it provides a caching system that optimizes the number of requests sent to retrieve the schemas for topics. \nWe do not apply changes to our schemas very often, so loading the schemas from the internal caching system improves the overall performances, avoiding networking delays and errors that might occur querying the Schema Registry multi times.\nMoreover, to guarantee the cached information's consistency, if a schema validation error occurs, the cached schema is deleted so the new version of the schema can be retrieved from the Schema Registry and cached again.\nThis module comes handy with scenarios where we need to produce messages as fire-and-forget, even to different topics each time. \nFor example, we might have a static method that we only call when we need to produce a message to a given Avro topic, passing just the topic and the message as parameters. In the static method, an instance of AvroProducer is created, and it will last just for the time needed to produce the message. Thanks to the internal caching system, every time we use our static method with the same topic, the schemas needed to initialize the AvroProducer will be loaded from a file instead of being requested from the Schema Registry. \n\n## How to use it:\n\n### How to set the Environment variables\n\n#### Plain-text Brokers\n\nthe bare minimum is \n\n```\nbrokers=mybroker:9090 mandatory\n```\n\n#### Schema Registry\n\nIf you brokers use a schema registry, then you have to specify this environment variable,\n\n```\nschema_registry= https://myschemaregistry:8081`\n```\n\n#### SSL identification\n\nMore information https://docs.confluent.io/3.0.0/kafka/ssl.html\n\nIf you broker uses SSL, like Aiven, you need to download these certificates files and copy them to a folder: \n\n* Access key \n* Access Certificate\n* CA Certificate\n\nThen, specify these environ variables\n\n\n\n\n\n| ENV variable name        |                       value                      |\n|--------------------------|:------------------------------------------------:|\n| security_protocol         | SSL                                              |\n| ssl\\_ca_location          | the relative path to the CA certificate file     |\n| ssl\\_certificate_location | the relative path to the Access Certificate file |\n| ssl\\_key_location         | the relative path to the Access Key file         |\n\n\n\n#### SASL Identification\n\nMore information https://docs.confluent.io/3.0.0/kafka/sasl.html\nIf your broker requires SASL authentication, like Confluent Cloud,  these are the ENVironment variables to include\n\n\n| ENV variable name                                 |        value       |\n|---------------------------------------------------|:------------------:|\n| sasl_username                                     | YOUR USERNAME HERE |\n| sasl_password                                     | YOUR PASSWORD HERE |\n| schema\\_registry\\_basic\\_auth\\_user_info          | AUTH HERE          |\n| schema\\_registry\\_basic\\_auth\\_credentials_source | USER_INFO          |\n| sasl_mechanisms                                   | PLAIN              |\n| security_protocol                                 | SASL_SSL           |\n\n\n\n\n### Create producers\n\nThe only mandatory parameter to pass is the **topic**. Under the hood, the module will process the environ variables and configure the producer according. \nOther optional parameters are \n\n* brokers_configuration = a dictionary like \n\n```\n{\n    'brokers_uri': os.environ.get('brokers'),\n    'schema_registry_url': os.environ.get('schema_registry'),\n    'topic': 'tc-lab-data-sent-to-marketo',\n    'security_protocol': os.environ.get('security_protocol'),\n    'ssl_ca_location': os.environ.get('ssl_ca_location'),\n    'ssl_certificate_location': os.environ.get('ssl_certificate_location'),\n    'ssl_key_location': os.environ.get('ssl_key_location'),\n    'basic_auth_credentials_source': os.environ.get('basic_auth_credentials_source'),\n    'sasl_mechanisms': os.environ.get('sasl_mechanisms'),\n    'debug': os.environ.get('debug'),\n    'api_version_request': os.environ.get('api_version_request')\n\n}\n```\n* store\\_and_load\\_schema = boolean. \n\nBy default, the schemas are stored internally and loaded each time the same topic is passed as parameter. You can disable this behaviour by setting `store_and_load_schema=0`\n\n\n#### Produce a message to an Avro topic\n\n\n```\n# Produce a  message to an Avro topic\nfrom confluent_kafka_producers_wrapper.producer import Producer\nproducer = Producer(topic='mytopic')\nmessage_to_send = {    \n                       'timestamp': '2021-01-27T09:17:02+00:00',\n                       'field1': 'test',\n                       'customer_email': 'peterparker@spiderman.com',\n                       'token': 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUz4'\n                    }\n\nproducer.produce_message(value=message_to_send, key={\"my_key\": 'my_key'})\n\n\n```\n\n\n```\n#Example with a static method \n\ndef my_fire_and_forget_producer(topic,message_value_payload, message_key_payload)\n    producer = Producer(topic=topic)\n    return producer.produce_message(value=message_value_payload,key= message_key_payload)\n\n```\n\nEvery time I call the `my_fire_and_forget_producer` method with the same topic schemas will be loaded from the internal cache instead of being retrived from the Schema Registry.\n\n#### Produce a  message to a Kafka topic:\n\n```\n# Produce a message to a Kafka topic\nfrom confluent_kafka_producers_wrapper.producer import Producer\nproducer = Producer(topic='mytopic')\nmessage_to_send = {    \n                       'timestamp': '2021-01-27T09:17:02+00:00',\n                       'field1': 'test',\n                       'customer_email': 'peterparker@spiderman.com',\n                       'token': 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUz4'\n                    }\n\nproducer.produce_message(value=message_to_send)\n\n\n```\n\n\n\n\n## Background consideration:\n\nAssume to create an instance of a producer using the `confluent_kafka.avro` AvroProducer package from the confluent-kafka-python\n\nAs required, to create a producer, we need to provide schemas. \nSchemas can either be stored as .avsc files and load using the  `avro.load` method, \n\n```\nfrom confluent_kafka import avro \nfrom confluent_kafka.avro import AvroProducer\n\nvalue_schema = avro.load('ValueSchema.avsc')\nkey_schema = avro.load('KeySchema.avsc')\nvalue = {\"name\": \"Value\"}\nkey = {\"name\": \"Key\"}\n\navroProducer = AvroProducer({'bootstrap.servers': 'mybroker,mybroker2', 'schema.registry.url': 'http://schem_registry_host:port'}, default_key_schema=key_schema, default_value_schema=value_schema)\navroProducer.produce(topic='my_topic', value=value, key=key)\n```\n\nor can be retrieved querying the Schema registry. In the latter, a few requests to the Schema Registry are needed to get the latest version of the topic's value and key schemas and then to retrieve their payload.\n\nAnyhow, the `default_key_schema` and the `default_value_schema` values are mandatory fields for the AvroProducer class.\n\n```\nproducer = AvroProducer(producer_conf, default_key_schema=topic_schema.get('topic_key_schema'),\n                    default_value_schema=topic_schema.get('topic_value_schema'))\n```\n\nWhen an instance of AvroProducer is initialized, the Confluent Schema Registry component will retrieve and store the given topic's schemas in a local cache. The producer instance will keep using the local version of the schema for all its life unless a change will be applied to the schema that generates a validation error. \nSuppose another new instance of AvroProducer is created. In that case, the Schema Registry will be queried again to get the topic schemas, no matter if a previous instance has been created with the same topic.\nThere might be scenarios where we need to produce messages as a result of given actions on our service and to different topics. We want to have a  fire-and-forget behaviour and not keeping producing data. \nFor example, we might have a static method that we only call when we need to produce a message to a given Avro topic, passing the topic and the message as parameters. In our static method, we create an instance of AvroProducer that will last for the time needed to produce the message. In this case, every time we create a new instance of AvroProducer, we need to retrieve from the Schema Registry the schemas for our topic. \nMost of the time, we do not apply changes to schemas very often. We could store the schemas instead of query for them, but we should do it for all the topics we want to use and update them if we apply schemas changes. \n\nThis module provides a caching system to avoid sending multiple requests to the Schema Registry to retrieve the same schemas and use cached versions. It also provides a way to remove the cached version if a schema validation error occurs so the new version of the schema can be retrieved from the Schema Registry and cached.\n\n\n## How the module works: \n\n![](kafka_producer_init.png)\n\n\n\n\n\n\n\n\n\n\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/antoniodimariano/confluent_kafka_producers_wrapper",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "confluent-kafka-producers-wrapper",
    "package_url": "https://pypi.org/project/confluent-kafka-producers-wrapper/",
    "platform": "",
    "project_url": "https://pypi.org/project/confluent-kafka-producers-wrapper/",
    "project_urls": {
      "Homepage": "https://github.com/antoniodimariano/confluent_kafka_producers_wrapper"
    },
    "release_url": "https://pypi.org/project/confluent-kafka-producers-wrapper/0.0.6/",
    "requires_dist": [
      "avro-python3",
      "requests",
      "confluent-kafka",
      "fastavro"
    ],
    "requires_python": "~=3.7",
    "summary": "Wrapper for producing messages using the confluent-kafka package.",
    "version": "0.0.6",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 9819535,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e10c4dd87b447947c00448e08f7ff6ffcc6a519c2ccaf83dc7c8b23af7c11a8e",
          "md5": "b30628d1974c649a38018c6bb2faace5",
          "sha256": "bee724dfede1e54f783ba58f21c0bfb951c80a9aa2334496a430d7f35bbcf607"
        },
        "downloads": -1,
        "filename": "confluent_kafka_producers_wrapper-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "b30628d1974c649a38018c6bb2faace5",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": "~=3.6",
        "size": 12232,
        "upload_time": "2021-02-02T15:15:57",
        "upload_time_iso_8601": "2021-02-02T15:15:57.240051Z",
        "url": "https://files.pythonhosted.org/packages/e1/0c/4dd87b447947c00448e08f7ff6ffcc6a519c2ccaf83dc7c8b23af7c11a8e/confluent_kafka_producers_wrapper-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "28bc2c90d5c0ea588b5995a5d4987fd0bc6a376cb3a7065f053db2f676cb369a",
          "md5": "ab127c987eea36459a12c597592e532d",
          "sha256": "32e18e2f2981ef1cdf8cedb9b82932cfe6af357340ea890034a6bdddb5ad3d1d"
        },
        "downloads": -1,
        "filename": "confluent_kafka_producers_wrapper-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "ab127c987eea36459a12c597592e532d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": "~=3.6",
        "size": 8199,
        "upload_time": "2021-02-02T15:15:58",
        "upload_time_iso_8601": "2021-02-02T15:15:58.375015Z",
        "url": "https://files.pythonhosted.org/packages/28/bc/2c90d5c0ea588b5995a5d4987fd0bc6a376cb3a7065f053db2f676cb369a/confluent_kafka_producers_wrapper-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b6943e48a5ceb5970506eda5afe5b5f1988be1dedaf646d11b964f511242eb07",
          "md5": "895450a81f178bff6b8182be6b6f95f3",
          "sha256": "5a368cdb913b25de302e2e8fd3ce0d1923f858af5f9827e814ca25a2b2a0443d"
        },
        "downloads": -1,
        "filename": "confluent_kafka_producers_wrapper-0.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "895450a81f178bff6b8182be6b6f95f3",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": "~=3.6",
        "size": 12425,
        "upload_time": "2021-02-02T16:53:07",
        "upload_time_iso_8601": "2021-02-02T16:53:07.597509Z",
        "url": "https://files.pythonhosted.org/packages/b6/94/3e48a5ceb5970506eda5afe5b5f1988be1dedaf646d11b964f511242eb07/confluent_kafka_producers_wrapper-0.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f22c7808cb6cde8c5dc4c2184c216f33b8e54eaf09ad3670db4f6f11fdbe8f1f",
          "md5": "5dc210bb250a8874987eb07c9799c529",
          "sha256": "844352c51dae78d6e094b4d304fc946eea504ced5049544b83ac773f02e41508"
        },
        "downloads": -1,
        "filename": "confluent_kafka_producers_wrapper-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "5dc210bb250a8874987eb07c9799c529",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": "~=3.6",
        "size": 8426,
        "upload_time": "2021-02-02T16:53:08",
        "upload_time_iso_8601": "2021-02-02T16:53:08.826984Z",
        "url": "https://files.pythonhosted.org/packages/f2/2c/7808cb6cde8c5dc4c2184c216f33b8e54eaf09ad3670db4f6f11fdbe8f1f/confluent_kafka_producers_wrapper-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e3aead0122fb4c8da05d23fedf23a0f5374bf5fb04cc582d54baebb4ca50940d",
          "md5": "cbbff78760d17d07cf8b72683dc17293",
          "sha256": "d17a856e4e8abe45dd693b619dafba58322a127a34a1781829b26ff0c52a98d8"
        },
        "downloads": -1,
        "filename": "confluent_kafka_producers_wrapper-0.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "cbbff78760d17d07cf8b72683dc17293",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": "~=3.7",
        "size": 14921,
        "upload_time": "2021-02-05T11:14:28",
        "upload_time_iso_8601": "2021-02-05T11:14:28.442021Z",
        "url": "https://files.pythonhosted.org/packages/e3/ae/ad0122fb4c8da05d23fedf23a0f5374bf5fb04cc582d54baebb4ca50940d/confluent_kafka_producers_wrapper-0.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "36cc7a5b48aa9ecc1b8dd4daee12999a5acbfbfb122797f62ce16a49906ab6e6",
          "md5": "cd6355c09946252936acfb81a7971aab",
          "sha256": "6b91714f2c528501e85a0daa89c76a26ca83a694548ba588cdb609e26f0e3b95"
        },
        "downloads": -1,
        "filename": "confluent_kafka_producers_wrapper-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "cd6355c09946252936acfb81a7971aab",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": "~=3.7",
        "size": 14325,
        "upload_time": "2021-02-05T11:14:29",
        "upload_time_iso_8601": "2021-02-05T11:14:29.903560Z",
        "url": "https://files.pythonhosted.org/packages/36/cc/7a5b48aa9ecc1b8dd4daee12999a5acbfbfb122797f62ce16a49906ab6e6/confluent_kafka_producers_wrapper-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "44cb15524c5c4f9d9533e6b0f6d0502127d449c190fafd35001a83a9d17109a2",
          "md5": "f698717471ae5330581a3f3391c65b35",
          "sha256": "547f9f6eca436104a701c84e5f71794fd76a6b0a6aed147ebde0163962cd2a7e"
        },
        "downloads": -1,
        "filename": "confluent_kafka_producers_wrapper-0.0.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f698717471ae5330581a3f3391c65b35",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": "~=3.7",
        "size": 14855,
        "upload_time": "2021-02-12T09:11:00",
        "upload_time_iso_8601": "2021-02-12T09:11:00.557184Z",
        "url": "https://files.pythonhosted.org/packages/44/cb/15524c5c4f9d9533e6b0f6d0502127d449c190fafd35001a83a9d17109a2/confluent_kafka_producers_wrapper-0.0.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c8a12113b04ae004bfde297281fbcf799194b478c44751877947b167c449bf83",
          "md5": "8c7783fb9d404c43b9cb33e4150569c6",
          "sha256": "216398e0aced49730d46984d6e020aa5eaacbf9ad4d16bb5709030867474d038"
        },
        "downloads": -1,
        "filename": "confluent_kafka_producers_wrapper-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "8c7783fb9d404c43b9cb33e4150569c6",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": "~=3.7",
        "size": 14220,
        "upload_time": "2021-02-12T09:11:02",
        "upload_time_iso_8601": "2021-02-12T09:11:02.106832Z",
        "url": "https://files.pythonhosted.org/packages/c8/a1/2113b04ae004bfde297281fbcf799194b478c44751877947b167c449bf83/confluent_kafka_producers_wrapper-0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "eb5bd1f10aa630be60df0eca03a952b6998f402bdafcc1b2e1205dae0adeba43",
          "md5": "56b28247a62d03d8dec7c0c384e75444",
          "sha256": "e8425970bb53adc2994eb0ea85c2841846fd90149d2a5025f9f6616734595fe5"
        },
        "downloads": -1,
        "filename": "confluent_kafka_producers_wrapper-0.0.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "56b28247a62d03d8dec7c0c384e75444",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": "~=3.7",
        "size": 15050,
        "upload_time": "2021-03-11T12:00:42",
        "upload_time_iso_8601": "2021-03-11T12:00:42.285610Z",
        "url": "https://files.pythonhosted.org/packages/eb/5b/d1f10aa630be60df0eca03a952b6998f402bdafcc1b2e1205dae0adeba43/confluent_kafka_producers_wrapper-0.0.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3b8d6a3f800aa9849219022a026976a47e3a1f7c020146f2279fcd49301b1594",
          "md5": "61b11377545b87270ac440406c966995",
          "sha256": "d90f2e0dcd027d8fac85beeac14c6cc570db1acffefe122a77f3743719d10373"
        },
        "downloads": -1,
        "filename": "confluent_kafka_producers_wrapper-0.0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "61b11377545b87270ac440406c966995",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": "~=3.7",
        "size": 14314,
        "upload_time": "2021-03-11T12:00:43",
        "upload_time_iso_8601": "2021-03-11T12:00:43.525562Z",
        "url": "https://files.pythonhosted.org/packages/3b/8d/6a3f800aa9849219022a026976a47e3a1f7c020146f2279fcd49301b1594/confluent_kafka_producers_wrapper-0.0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "55ccdef8800d34623bd0e6bb0af5c7589195a3119cdf6e60cf06cc006a5411ed",
          "md5": "d7d25f548712d7d4af744436b8d0b4fb",
          "sha256": "5ac38e03ca00d3d891d1a7ae5b31eaead60cbcc2cd559203b7dbffa0714fe6f9"
        },
        "downloads": -1,
        "filename": "confluent_kafka_producers_wrapper-0.0.6-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d7d25f548712d7d4af744436b8d0b4fb",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": "~=3.7",
        "size": 15055,
        "upload_time": "2021-03-16T11:35:56",
        "upload_time_iso_8601": "2021-03-16T11:35:56.666150Z",
        "url": "https://files.pythonhosted.org/packages/55/cc/def8800d34623bd0e6bb0af5c7589195a3119cdf6e60cf06cc006a5411ed/confluent_kafka_producers_wrapper-0.0.6-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5c7f51918fb9f27d342dfb01cac22766dbad8994243383009dd569378a720cbc",
          "md5": "8b39ad687bd9c9ef27e35a2ec6baaea3",
          "sha256": "99407df1afa3f0b9c38cdf5201c3d956e0034394210bb4b309149dbc382345d4"
        },
        "downloads": -1,
        "filename": "confluent_kafka_producers_wrapper-0.0.6.tar.gz",
        "has_sig": false,
        "md5_digest": "8b39ad687bd9c9ef27e35a2ec6baaea3",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": "~=3.7",
        "size": 14314,
        "upload_time": "2021-03-16T11:35:58",
        "upload_time_iso_8601": "2021-03-16T11:35:58.193850Z",
        "url": "https://files.pythonhosted.org/packages/5c/7f/51918fb9f27d342dfb01cac22766dbad8994243383009dd569378a720cbc/confluent_kafka_producers_wrapper-0.0.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "55ccdef8800d34623bd0e6bb0af5c7589195a3119cdf6e60cf06cc006a5411ed",
        "md5": "d7d25f548712d7d4af744436b8d0b4fb",
        "sha256": "5ac38e03ca00d3d891d1a7ae5b31eaead60cbcc2cd559203b7dbffa0714fe6f9"
      },
      "downloads": -1,
      "filename": "confluent_kafka_producers_wrapper-0.0.6-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "d7d25f548712d7d4af744436b8d0b4fb",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": "~=3.7",
      "size": 15055,
      "upload_time": "2021-03-16T11:35:56",
      "upload_time_iso_8601": "2021-03-16T11:35:56.666150Z",
      "url": "https://files.pythonhosted.org/packages/55/cc/def8800d34623bd0e6bb0af5c7589195a3119cdf6e60cf06cc006a5411ed/confluent_kafka_producers_wrapper-0.0.6-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "5c7f51918fb9f27d342dfb01cac22766dbad8994243383009dd569378a720cbc",
        "md5": "8b39ad687bd9c9ef27e35a2ec6baaea3",
        "sha256": "99407df1afa3f0b9c38cdf5201c3d956e0034394210bb4b309149dbc382345d4"
      },
      "downloads": -1,
      "filename": "confluent_kafka_producers_wrapper-0.0.6.tar.gz",
      "has_sig": false,
      "md5_digest": "8b39ad687bd9c9ef27e35a2ec6baaea3",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": "~=3.7",
      "size": 14314,
      "upload_time": "2021-03-16T11:35:58",
      "upload_time_iso_8601": "2021-03-16T11:35:58.193850Z",
      "url": "https://files.pythonhosted.org/packages/5c/7f/51918fb9f27d342dfb01cac22766dbad8994243383009dd569378a720cbc/confluent_kafka_producers_wrapper-0.0.6.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}