{
  "info": {
    "author": "Andres Prados Torreblanca",
    "author_email": "andresprator@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Environment :: Console",
      "Environment :: GPU",
      "Intended Audience :: Developers",
      "Intended Audience :: Education",
      "Intended Audience :: Science/Research",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Topic :: Scientific/Engineering :: Artificial Intelligence",
      "Topic :: Scientific/Engineering :: Image Processing",
      "Topic :: Software Development :: Libraries",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "# SPIGA: Shape Preserving Facial Landmarks with Graph Attention Networks.\n\n[![Project Page](https://badgen.net/badge/color/Project%20Page/purple?icon=atom&label)](https://bmvc2022.mpi-inf.mpg.de/155/)\n[![arXiv](https://img.shields.io/badge/arXiv-2210.07233-b31b1b.svg)](https://arxiv.org/abs/2210.07233)\n[![License](https://img.shields.io/badge/License-BSD%203--Clause-blue.svg)](LICENSE)\n[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/andresprados/SPIGA/blob/main/colab_tutorials/video_demo.ipynb)\n\n[//]: # ([![PyPI version]&#40;https://badge.fury.io/py/spiga.svg&#41;]&#40;https://badge.fury.io/py/spiga&#41;)\n\nThis repository contains the source code of **SPIGA, a face alignment and headpose estimator** that takes advantage of the complementary benefits from CNN and GNN architectures producing plausible face shapes in presence of strong appearance changes. \n\n<p align=\"center\">\n    <img src=\"https://raw.githubusercontent.com/andresprados/SPIGA/main/assets/spiga_scheme.png\" width=\"80%\">\n</p>\n\n**It achieves top-performing results in:**\n\n[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/shape-preserving-facial-landmarks-with-graph/pose-estimation-on-300w-full)](https://paperswithcode.com/sota/pose-estimation-on-300w-full?p=shape-preserving-facial-landmarks-with-graph)\n[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/shape-preserving-facial-landmarks-with-graph/head-pose-estimation-on-wflw)](https://paperswithcode.com/sota/head-pose-estimation-on-wflw?p=shape-preserving-facial-landmarks-with-graph)\n[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/shape-preserving-facial-landmarks-with-graph/pose-estimation-on-merl-rav)](https://paperswithcode.com/sota/pose-estimation-on-merl-rav?p=shape-preserving-facial-landmarks-with-graph)\n[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/shape-preserving-facial-landmarks-with-graph/face-alignment-on-merl-rav)](https://paperswithcode.com/sota/face-alignment-on-merl-rav?p=shape-preserving-facial-landmarks-with-graph)\n[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/shape-preserving-facial-landmarks-with-graph/face-alignment-on-wflw)](https://paperswithcode.com/sota/face-alignment-on-wflw?p=shape-preserving-facial-landmarks-with-graph)\n[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/shape-preserving-facial-landmarks-with-graph/face-alignment-on-300w-split-2)](https://paperswithcode.com/sota/face-alignment-on-300w-split-2?p=shape-preserving-facial-landmarks-with-graph)\n[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/shape-preserving-facial-landmarks-with-graph/face-alignment-on-cofw-68)](https://paperswithcode.com/sota/face-alignment-on-cofw-68?p=shape-preserving-facial-landmarks-with-graph)\n[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/shape-preserving-facial-landmarks-with-graph/face-alignment-on-300w)](https://paperswithcode.com/sota/face-alignment-on-300w?p=shape-preserving-facial-landmarks-with-graph)\n\n\n## Setup\nThe repository has been tested on Ubuntu 20.04 with CUDA 11.4, the latest version of cuDNN, Python 3.8 and Pytorch 1.12.1.\nTo run the video analyzer demo or evaluate the algorithm, install the repository from the source code:\n\n```\n# Best practices: \n#  1. Create a virtual environment.\n#  2. Install Pytorch according to your CUDA version.\n#  3. Install SPIGA from source code:\n\ngit clone https://github.com/andresprados/SPIGA.git\ncd spiga\npip install -e .  \n\n# To run the video analyzer demo install the extra requirements.\npip install -e .[demo]\n```\n**Models:** By default, model weights are automatically downloaded on demand and stored at ```./spiga/models/weights/```.\nYou can also download them from [Google Drive](https://drive.google.com/drive/folders/1olrkoiDNK_NUCscaG9BbO3qsussbDi7I?usp=sharing). \n\n***Note:*** All the callable files provide a detailed parser that describes the behaviour of the program and their inputs. Please, check the operational modes by using the extension ```--help```.\n\n## Inference and Demo\nWe provide an inference framework for SPIGA available at ```./spiga/inference```. The models can be easily deployed \nin third-party projects by adding a few lines of code. Check out our inference and application tutorials\nfor more information: \n\n<div align=\"center\">\n\nTutorials | Notebook |\n:---: | :---: |\nImage Inference Example | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/andresprados/SPIGA/blob/main/colab_tutorials/image_demo.ipynb) |\nFace Video Analyzer Demo | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/andresprados/SPIGA/blob/main/colab_tutorials/video_demo.ipynb) |\n\n</div>\n\n### Face Video Analyzer Demo:\nThe demo application provides a general framework for tracking, detecting and extracting features of human faces in images or videos.\nYou can use the following commands to run the demo:\n\n```\npython ./spiga/demo/app.py \\\n            [--input] \\      # Webcam ID or Video Path. Dft: Webcam '0'.\n            [--dataset] \\    # SPIGA pretrained weights per dataset. Dft: 'wflw'.\n            [--tracker] \\    # Tracker name. Dft: 'RetinaSort'.\n            [--show] \\       # Select the attributes of the face to be displayed. Dft: ['fps', 'face_id', 'landmarks', 'headpose']\n            [--save] \\       # Save record.\n            [--noview] \\     # Do not visualize window.\n            [--outpath] \\    # Recorded output directory. Dft: './spiga/demo/outputs'\n            [--fps] \\        # Frames per second.\n            [--shape] \\      # Visualizer shape (W,H).\n```\n\n\n[//]: # (<p align=\"center\">)\n\n[//]: # ()\n[//]: # (<img src=\"https://raw.githubusercontent.com/andresprados/SPIGA/main/assets/results/demo_10MB.gif\" width=300px height=250px>    )\n\n[//]: # (&nbsp;&nbsp;&nbsp;)\n\n[//]: # (<img src=\"https://raw.githubusercontent.com/andresprados/SPIGA/main/assets/results/carnaval_10MB.gif\" width=350px height=250px>)\n\n[//]: # (&nbsp;&nbsp;&nbsp;)\n\n[//]: # (<img src=\"https://raw.githubusercontent.com/andresprados/SPIGA/main/assets/results/football_10MB.gif\" width=300px height=250px>)\n\n[//]: # ()\n[//]: # (</p>)\n\n***Note:*** For more information check the [Demo Readme](spiga/demo/readme.md) or call the app parser ```--help```.\n\n\n## Dataloaders and Benchmarks\nThis repository provides general-use tools for the task of face alignment and headpose estimation:\n\n* **Dataloaders:** Training and inference dataloaders are available at ```./spiga/data```.\nIncluding the data augmentation tools used for training SPIGA and data-visualizer to analyze the dataset images and features.\nFor more information check the [Data Readme](spiga/data/readme.md) .\n\n* **Benchmark:** A common benchmark framework to test any algorithm in the task of face alignment and headpose estimation\nis available at ```./spiga/eval/benchmark```. For more information check the following Evaluation Section and the [Benchmark Readme](spiga/eval/benchmark/readme.md).\n\n**Datasets:** To run the data visualizers or the evaluation benchmark please download the dataset images from the official websites \n([300W](https://ibug.doc.ic.ac.uk/resources/facial-point-annotations/), \n[AFLW](https://www.tugraz.at/institute/icg/research/team-bischof/lrs/downloads/aflw/), \n[WFLW](https://wywu.github.io/projects/LAB/WFLW.html), [COFW](http://www.vision.caltech.edu/xpburgos/ICCV13/)). \nBy default they should be saved following the next folder structure:\n```\n./spiga/data/databases/   # Default path can be updated by modifying 'db_img_path' in ./spiga/data/loaders/dl_config.py\n|\n└───/300w               \n│   └─── /images           \n│        | /private     \n│        | /test                   \n|        └ /train             \n|\n└───/cofw                   \n│   └─── /images\n|  \n└───/aflw                   \n│   └─── /data\n|        └ /flickr\n|  \n└───/wflw\n    └─── /images\n```\n**Annotations:** We have stored for simplicity the datasets annotations directly in ```./spiga/data/annotations```. We strongly recommend to move them out of the repository if you plan to use it as a git directory.\n\n**Results:** Similar to the annotations problem, we have stored the SPIGA results in ```./spiga/eval/results/<dataset_name>```. Remove them if need it.\n\n## Evaluation\nThe models evaluation is divided in two scripts:\n\n**Results generation**: The script extracts the data alignments and headpose estimation from the desired ``` <dataset_name>``` trained network. Generating a ```./spiga/eval/results/results_<dataset_name>_test.json``` file which follows the same data structure defined by the dataset annotations.\n\n```\npython ./spiga/eval/results_gen.py <dataset_name>\n``` \n \n**Benchmark metrics**: The script generates the desired landmark or headpose estimation metrics. We have implemented an useful benchmark which allows you to test any model using a results file as input. \n\n```\npython ./spiga/eval/benchmark/evaluator.py /path/to/<results_file.json> --eval lnd pose -s\n``` \n\n***Note:*** You will have to interactively select the NME_norm and other parameters in the terminal window.\n\n### Results Sum-up\n<details>\n  <summary> WFLW Dataset </summary>\n\n|[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/shape-preserving-facial-landmarks-with-graph/face-alignment-on-wflw)](https://paperswithcode.com/sota/face-alignment-on-wflw?p=shape-preserving-facial-landmarks-with-graph)|NME_ioc|AUC_10|FR_10|NME_P90|NME_P95|NME_P99|\n|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n|full|4.060|60.558|2.080|6.766|8.199|13.071|\n|pose|7.141|35.312|11.656|10.684|13.334|26.890|\n|expression|4.457|57.968|2.229|7.023|8.148|22.388|\n|illumination|4.004|61.311|1.576|6.528|7.919|11.090|\n|makeup|3.809|62.237|1.456|6.320|8.289|11.564|\n|occlusion|4.952|53.310|4.484|8.091|9.929|16.439|\n|blur|4.650|55.310|2.199|7.311|8.693|14.421|\n</details>\n    \n<details>\n  <summary> MERLRAV Dataset </summary>\n    \n|[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/shape-preserving-facial-landmarks-with-graph/face-alignment-on-merl-rav)](https://paperswithcode.com/sota/face-alignment-on-merl-rav?p=shape-preserving-facial-landmarks-with-graph)|NME_bbox|AUC_7|FR_7|NME_P90|NME_P95|NME_P99|\n|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n|full|1.509|78.474|0.052|2.163|2.468|3.456|\n|frontal|1.616|76.964|0.091|2.246|2.572|3.621|\n|half_profile|1.683|75.966|0.000|2.274|2.547|3.397|\n|profile|1.191|82.990|0.000|1.735|2.042|2.878|\n</details>\n\n<details>\n  <summary> 300W Private Dataset </summary>\n    \n|[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/shape-preserving-facial-landmarks-with-graph/face-alignment-on-300w-split-2)](https://paperswithcode.com/sota/face-alignment-on-300w-split-2?p=shape-preserving-facial-landmarks-with-graph)|NME_bbox|AUC_7|FR_7|NME_P90|NME_P95|NME_P99|\n|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n|full|2.031|71.011|0.167|2.788|3.078|3.838|\n|indoor|2.035|70.959|0.333|2.726|3.007|3.712|\n|outdoor|2.027|37.174|0.000|2.824|3.217|3.838|\n</details>\n\n<details>\n  <summary> COFW68 Dataset </summary>\n\n|[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/shape-preserving-facial-landmarks-with-graph/face-alignment-on-cofw-68)](https://paperswithcode.com/sota/face-alignment-on-cofw-68?p=shape-preserving-facial-landmarks-with-graph)|NME_bbox|AUC_7|FR_7|NME_P90|NME_P95|NME_P99|\n|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n|full|2.517|64.050|0.000|3.439|4.066|5.558|\n</details>\n\n<details>\n  <summary> 300W Public Dataset </summary>\n\n|[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/shape-preserving-facial-landmarks-with-graph/face-alignment-on-300w)](https://paperswithcode.com/sota/face-alignment-on-300w?p=shape-preserving-facial-landmarks-with-graph)|NME_ioc|AUC_8|FR_8|NME_P90|NME_P95|NME_P99|\n|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n|full|2.994|62.726|0.726|4.667|5.436|7.320|\n|common|2.587|44.201|0.000|3.710|4.083|5.215|\n|challenge|4.662|42.449|3.704|6.626|7.390|10.095|\n\n</details>\n\n## BibTeX Citation\n```\n@inproceedings{Prados-Torreblanca_2022_BMVC,\n  author    = {Andrés  Prados-Torreblanca and José M Buenaposada and Luis Baumela},\n  title     = {Shape Preserving Facial Landmarks with Graph Attention Networks},\n  booktitle = {33rd British Machine Vision Conference 2022, {BMVC} 2022, London, UK, November 21-24, 2022},\n  publisher = {{BMVA} Press},\n  year      = {2022},\n  url       = {https://bmvc2022.mpi-inf.mpg.de/0155.pdf}\n}\n```\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/andresprados/SPIGA",
    "keywords": "Computer Vision,Face Alignment,Head Pose Estimation,Pytorch,CNN,GNN,BMVC2022,WFLW,300W,Merlrav,COFW",
    "license": "BSD-3-Clause",
    "maintainer": "",
    "maintainer_email": "",
    "name": "spiga",
    "package_url": "https://pypi.org/project/spiga/",
    "platform": null,
    "project_url": "https://pypi.org/project/spiga/",
    "project_urls": {
      "Bug Tracker": "https://github.com/andresprados/SPIGA/issues",
      "Homepage": "https://bmvc2022.mpi-inf.mpg.de/155/",
      "SPIGA Paper": "https://bmvc2022.mpi-inf.mpg.de/0155.pdf"
    },
    "release_url": "https://pypi.org/project/spiga/0.0.6/",
    "requires_dist": [
      "matplotlib (>=3.2.1)",
      "numpy (>=1.18.2)",
      "opencv-python (>=4.2.0.32)",
      "Pillow (>=7.0.0)",
      "torch (>=1.4.0)",
      "torchvision (>=0.5.0)",
      "torchaudio",
      "scipy",
      "scikit-learn",
      "retinaface-py (>=0.0.2) ; extra == 'demo'",
      "sort-tracker-py (>=1.0.2) ; extra == 'demo'"
    ],
    "requires_python": ">=3.6",
    "summary": "SPIGA: Shape Preserving Facial Landmarks with Graph Attention Networks",
    "version": "0.0.6",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16949225,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9512a1b3379b9df79232f8c1be8c0ad4a7850feac3fdb54b2864f0d5e0d69f41",
          "md5": "04dc7ba7b64419b4df80a35289f629e4",
          "sha256": "45bb3f1f642f3bb0ee32393bb2e4894b01fed156f4d55b2ca281ece3d75a73f0"
        },
        "downloads": -1,
        "filename": "spiga-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "04dc7ba7b64419b4df80a35289f629e4",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 75592,
        "upload_time": "2023-02-14T19:11:32",
        "upload_time_iso_8601": "2023-02-14T19:11:32.027171Z",
        "url": "https://files.pythonhosted.org/packages/95/12/a1b3379b9df79232f8c1be8c0ad4a7850feac3fdb54b2864f0d5e0d69f41/spiga-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "59ee18e500ae6c32005c87076fd58338950f472e2cb7f6c7337d8e00b376331c",
          "md5": "a1ba2a060ac1a66c0169e56e5fee94d2",
          "sha256": "94d695ff8b60e4ffadcd881ccc4bd407fc8642ade14aa655ee58590b6edf63a9"
        },
        "downloads": -1,
        "filename": "spiga-0.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "a1ba2a060ac1a66c0169e56e5fee94d2",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 75609,
        "upload_time": "2023-02-14T19:39:50",
        "upload_time_iso_8601": "2023-02-14T19:39:50.489299Z",
        "url": "https://files.pythonhosted.org/packages/59/ee/18e500ae6c32005c87076fd58338950f472e2cb7f6c7337d8e00b376331c/spiga-0.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1681d2d56467d42c2887b91e409239f401fa7406298bd97be6416fe7df133027",
          "md5": "31d3fc6c640f6ec900e1a360737b03bc",
          "sha256": "dba5e31a430aa79323dd615b211f0a370d7e55103db910d7e880624983c98770"
        },
        "downloads": -1,
        "filename": "spiga-0.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "31d3fc6c640f6ec900e1a360737b03bc",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 77876,
        "upload_time": "2023-02-15T10:31:15",
        "upload_time_iso_8601": "2023-02-15T10:31:15.988101Z",
        "url": "https://files.pythonhosted.org/packages/16/81/d2d56467d42c2887b91e409239f401fa7406298bd97be6416fe7df133027/spiga-0.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "236955c577a595ace210d71572017206250a208aa61bc2f9dd2f687e6498c1fe",
          "md5": "17c52134371bf3e3b7c5d6677af95ed6",
          "sha256": "97c90a2b387e0177661bffdc2002c36ac3e097ecbd8c1dfba512fb8d745a8ca3"
        },
        "downloads": -1,
        "filename": "spiga-0.0.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "17c52134371bf3e3b7c5d6677af95ed6",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 95056,
        "upload_time": "2023-02-17T00:56:40",
        "upload_time_iso_8601": "2023-02-17T00:56:40.211197Z",
        "url": "https://files.pythonhosted.org/packages/23/69/55c577a595ace210d71572017206250a208aa61bc2f9dd2f687e6498c1fe/spiga-0.0.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6761ab6e9d0a49f57c33c512a448892d92344471fbbf7eb5b5d48f23eadadf89",
          "md5": "0db1a1ff6eb5cf8a6c24f646c76fd966",
          "sha256": "b2882ee64261b7efe15de2bda35fcc3790420e09b4b3774327e942383a5538b3"
        },
        "downloads": -1,
        "filename": "spiga-0.0.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0db1a1ff6eb5cf8a6c24f646c76fd966",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 95187,
        "upload_time": "2023-02-20T20:01:05",
        "upload_time_iso_8601": "2023-02-20T20:01:05.198208Z",
        "url": "https://files.pythonhosted.org/packages/67/61/ab6e9d0a49f57c33c512a448892d92344471fbbf7eb5b5d48f23eadadf89/spiga-0.0.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a702a52d7238690c6b28e0ba85b94fa6d456e6bbe3d30e22a37504f5d7fcc81f",
          "md5": "9065d7604d3f7ed15d83d9e1b4f2300a",
          "sha256": "d098fc4097bc353ad514f5686bc87d8b01f83e6edbe36f9a2a0505afc994304e"
        },
        "downloads": -1,
        "filename": "spiga-0.0.6-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "9065d7604d3f7ed15d83d9e1b4f2300a",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 95167,
        "upload_time": "2023-02-20T20:06:37",
        "upload_time_iso_8601": "2023-02-20T20:06:37.006491Z",
        "url": "https://files.pythonhosted.org/packages/a7/02/a52d7238690c6b28e0ba85b94fa6d456e6bbe3d30e22a37504f5d7fcc81f/spiga-0.0.6-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "a702a52d7238690c6b28e0ba85b94fa6d456e6bbe3d30e22a37504f5d7fcc81f",
        "md5": "9065d7604d3f7ed15d83d9e1b4f2300a",
        "sha256": "d098fc4097bc353ad514f5686bc87d8b01f83e6edbe36f9a2a0505afc994304e"
      },
      "downloads": -1,
      "filename": "spiga-0.0.6-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "9065d7604d3f7ed15d83d9e1b4f2300a",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 95167,
      "upload_time": "2023-02-20T20:06:37",
      "upload_time_iso_8601": "2023-02-20T20:06:37.006491Z",
      "url": "https://files.pythonhosted.org/packages/a7/02/a52d7238690c6b28e0ba85b94fa6d456e6bbe3d30e22a37504f5d7fcc81f/spiga-0.0.6-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}