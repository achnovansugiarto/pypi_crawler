{
  "info": {
    "author": "Alejandro Pérez-Sanjuán",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "\n<p align=\"center\">\n  <img src=\"assets/logo.png\" width=\"650\">\n</p>\n\n![GitHub tag (latest by date)](https://img.shields.io/github/v/tag/Xylambda/torchfitter?label=VERSION&style=badge)\n![GitHub code size in bytes](https://img.shields.io/github/languages/code-size/Xylambda/torchfitter?style=badge)\n![GitHub issues](https://img.shields.io/github/issues/Xylambda/torchfitter?style=badge)\n![workflow](https://github.com/Xylambda/torchfitter/actions/workflows/cicd.yml/badge.svg)\n[![doc](https://img.shields.io/badge/DOCS-documentation-blue.svg?style=badge)](https://xylambda.github.io/torchfitter/)\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg?style=badge)](https://github.com/psf/black)\n\n`torchfitter` is a simple library to ease the training of PyTorch models. It \nfeatures a class called `Trainer` that includes the basic functionality to fit \nmodels in a Keras-like style.\n\nInternally, `torchfitter` leverages the power of [accelerate](https://huggingface.co/docs/accelerate/)\nto handle the device management.\n\nThe library also provides a callbacks API that can be used to interact with\nthe model during the training process, as well as a set of basic regularization\nprocedures.\n\n## Installation\n**Normal user**\n```bash\npip install torchfitter\n```\n\nThis library does not ship CUDA nor XLA. Follow the \n[official PyTorch documentation](https://pytorch.org/get-started/locally/) for\nmore information about how to install CUDA binaries.\n\n**Developer**\n```bash\ngit clone https://github.com/Xylambda/torchfitter.git\npip install -e torchfitter/. -r torchfitter/requirements-dev.txt\n```\n\n## Tests\nTo run the tests you must install the library as a `developer`.\n```bash\ncd torchfitter/\npytest -v tests/\n```\n\n## Features\n\n|                          | Supported | Not supported | Planned |\n|--------------------------|-----------|---------------|---------|\n|      Basic training loop |     x     |               |         |\n|        Gradient Clipping |     x     |               |         |\n|    Gradient Accumulation |     x     |               |         |\n|     Multi-device support |     x     |               |         |\n|           Regularization |     x     |               |         |\n|  In-loop metrics support |     x     |               |         |\n| Mixed precision training |     x     |               |         |\n|         Callbacks System |     x     |               |         |\n|    Hyperparameter search |           |       x       |         |\n|            Warm Training |           |       x       |    x    |\n\n## Usage\nAssume we already have `DataLoaders` for the train and validation sets. \n```python\nfrom torch.utils.data import DataLoader\n\n\ntrain_loader = DataLoader(...)\nval_loader = DataLoader(...)\n```\n\nThen, create the optimizer and the loss criterion as usual. Pass them to the\ntrainer along the PyTorch model. You can also add a regularization procedure if \nyou need/want to do it. The same goes for callbacks: create the desired\ncallbacks and pass them to the trainer as a list.\n```python\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchfitter.trainer import Trainer\nfrom torchfitter.regularization import L1Regularization\nfrom torchfitter.callbacks import (\n    LoggerCallback,\n    EarlyStopping,\n    LearningRateScheduler\n)\n\nmodel = nn.Linear(in_features=1, out_features=1)\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(model.parameters())\nregularizer = L1Regularization(regularization_rate=0.01, biases=False)\n\n# callbacks\nlogger = LoggerCallback(update_step=50)\nearly_stopping = EarlyStopping(patience=50, load_best=True, path='checkpoint.pt')\nscheduler = LearningRateScheduler(\n    scheduler=optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.9)\n)\n\ntrainer = Trainer(\n    model=model, \n    criterion=criterion,\n    optimizer=optimizer, \n    regularizer=regularizer,\n    mixed_precision=True,\n    accumulate_iter=4, # accumulate gradient every 4 iterations,\n    gradient_clipping='norm',\n    gradient_clipping_kwrgs={'max_norm': 1.0, 'norm_type': 2.0},\n    callbacks=[logger, early_stopping, scheduler]\n)\n\nhistory = trainer.fit(train_loader, val_loader, epochs=1000)\n```\n\nSince `torchfitter` leverages the power of `accelerate`, the device management\nwill rely on the latter. You can pass your own `accelerate.Accelerator` \nobject to fine tune its parameters:\n\n```python\nfrom accelerate import Accelerator\nfrom torchfitter.trainer import Trainer\n\n\naccelerator = Accelerator(...)\ntrainer = Trainer(\n    accelerator=accelerator,\n    **kwargs\n)\n```\n\n## Callbacks\nCallbacks allow you to interact with the model during the fitting process. They\nprovide with different methods that are called at different stages. To create a \ncallback simply extend the base class and fill the desired methods.\n\n```python\nimport torch\nfrom torchfitter.conventions import ParamsDict\nfrom torchfitter.callbacks.base import Callback\n\n\nclass ModelCheckpoint(Callback):\n    def __init__(self, path):\n        super(ModelCheckpoint, self).__init__()\n\n        self.path = path\n\n    def __repr__(self) -> str:\n        return \"ModelCheckpoint()\"\n\n    def on_epoch_end(self, params_dict):\n        # get params\n        accelerator = params_dict[ParamsDict.ACCELERATOR]\n        epoch = params_dict[ParamsDict.EPOCH_NUMBER]\n\n        # ensure model is safe to save\n        _model = params_dict[ParamsDict.MODEL]\n        accelerator.wait_for_everyone()\n        unwrapped_model = accelerator.unwrap_model(_model)\n\n        # actual saving\n        fname = self.path / f'model_epoch_{epoch}.pt'\n        accelerator.save(unwrapped_model.state_dict(), fname)\n```\n\nEach method receives `params_dict`, which is a dictionary object containing the\ninternal training parameters. You can see the pair key value of each parameter\nof the conventions:\n\n```python\n>>> from torchfitter.conventions import ParamsDict\n>>> [(x, getattr(ParamsDict, x)) for x in ParamsDict.__dict__ if not x.startswith('__')]\n```\n\nAnd you can also check the doc to understand the meaning of each one of the \nparameters:\n```python\n>>> from torchfitter.conventions import ParamsDict\n>>> print(ParamsDict.__doc__)\n```\n\n`NOTE:` the callbacks design can be considered as a port from Keras design. \n`I AM NOT` the author of this callback sysem design despite the fact that I \nmade some minor design changes. Find more in the `Credits` section.\n\n\n## FAQ\n* **Do you know Pytorch-Lightning/FastAI?**\n\nI know them and I think **they are awesome**. This is a personal project though\nI must say the trainer is reasonably well-equiped.\n\n* **Why is the `validation loader` not optional?**\n\nBecause I think it enforces good ML practices that way.\n\n* **Why didn't you implement the optimization steps in the model object?**\n\nIt is certainly another approach you may take when building an optimization \nloop (PyTorch-Lightning works this way), but I don't like my abstract data \ntypes to track way too many things in addition to being torch.nn.Module types. \nFunctionality should be **clear and atomic**: the model tracks gradients and \nthe trainer cares about the optimization process.\n\n* **I have a suggestion/question**\n\nThank you! Do not hesitate to open an issue and I'll do my best to answer you.\n\n## CREDITS\n\n* [Keras API](https://keras.io/api/).\n\n* [torchmetrics](https://torchmetrics.readthedocs.io/en/latest/)\n\n* [fastai](https://docs.fast.ai/)\n\n\n## Cite\nIf you've used this library for your projects please cite it:\n\n```latex\n@misc{alejandro2019torchfitter,\n  title={torchfitter - Simple Trainer to Optimize PyTorch Models},\n  author={Alejandro Pérez-Sanjuán},\n  year={2020},\n  howpublished={\\url{https://github.com/Xylambda/torchfitter}},\n}\n```\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "torchfitter",
    "package_url": "https://pypi.org/project/torchfitter/",
    "platform": null,
    "project_url": "https://pypi.org/project/torchfitter/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/torchfitter/4.2.1/",
    "requires_dist": [
      "rich",
      "numpy (>=1.20.0)",
      "accelerate (>=0.11.0)",
      "scikit-learn",
      "torchmetrics",
      "torch (>=1.1.0)"
    ],
    "requires_python": ">=3.7,",
    "summary": "Trainer to optimize PyTorch models",
    "version": "4.2.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 15052461,
  "releases": {
    "4.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9177fba8ae057bf0ef71420b2ee409c5aa758117a0b7ab2393c10d29624a36b1",
          "md5": "1c275d7ddd1f38c218bab0521dcb84f3",
          "sha256": "337455868c90da4a91173c3896e5e4eb87e05309eec95eedcd9a0f377ec681fe"
        },
        "downloads": -1,
        "filename": "torchfitter-4.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "1c275d7ddd1f38c218bab0521dcb84f3",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7,",
        "size": 41418,
        "upload_time": "2021-12-16T20:56:21",
        "upload_time_iso_8601": "2021-12-16T20:56:21.698866Z",
        "url": "https://files.pythonhosted.org/packages/91/77/fba8ae057bf0ef71420b2ee409c5aa758117a0b7ab2393c10d29624a36b1/torchfitter-4.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "4.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d72105991847679a1530012792d5eff69215c8e743ebbe6c446eec62da304ba3",
          "md5": "63d19802a2277221545d0edae3302f7f",
          "sha256": "59858b50068de76f7419a5f488c3389d7e68dc52aa4fe7f7b5e91d2d60b59c48"
        },
        "downloads": -1,
        "filename": "torchfitter-4.1.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "63d19802a2277221545d0edae3302f7f",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7,",
        "size": 29698,
        "upload_time": "2021-12-24T19:01:54",
        "upload_time_iso_8601": "2021-12-24T19:01:54.459963Z",
        "url": "https://files.pythonhosted.org/packages/d7/21/05991847679a1530012792d5eff69215c8e743ebbe6c446eec62da304ba3/torchfitter-4.1.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b629f871f332784c93089e510901b7fe5c531a41e87e5905b3170f91c2fc68c0",
          "md5": "c4f00650fcc743af6547be1a8a6e8346",
          "sha256": "59f1bfa234359a8ab527796684ee48c6f6c8cbad72ce46a19bcb2e184c20b1c2"
        },
        "downloads": -1,
        "filename": "torchfitter-4.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "c4f00650fcc743af6547be1a8a6e8346",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7,",
        "size": 43590,
        "upload_time": "2021-12-24T19:01:56",
        "upload_time_iso_8601": "2021-12-24T19:01:56.208886Z",
        "url": "https://files.pythonhosted.org/packages/b6/29/f871f332784c93089e510901b7fe5c531a41e87e5905b3170f91c2fc68c0/torchfitter-4.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "4.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "72aaaa4af88d8d47a26db1c059e88704d9bef8a7bef7d75c3a8935879774f401",
          "md5": "6684868a364f956051eeb8d353bf6a33",
          "sha256": "b76169d034980e1a84ee91e4629253970557990ecd763a21854eb7bec6e3c12a"
        },
        "downloads": -1,
        "filename": "torchfitter-4.2.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "6684868a364f956051eeb8d353bf6a33",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7,",
        "size": 30727,
        "upload_time": "2022-08-08T19:05:16",
        "upload_time_iso_8601": "2022-08-08T19:05:16.721916Z",
        "url": "https://files.pythonhosted.org/packages/72/aa/aa4af88d8d47a26db1c059e88704d9bef8a7bef7d75c3a8935879774f401/torchfitter-4.2.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b07873d7ffd3b22086511c8110807b1ac336378aa415b50012799e295f6c03b5",
          "md5": "10def59fa36f08295428650fdd78d51c",
          "sha256": "b6a017027e590288e21d47ef344985efa4079b8cdbdc1b60d7a29aa9fabfdc6a"
        },
        "downloads": -1,
        "filename": "torchfitter-4.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "10def59fa36f08295428650fdd78d51c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7,",
        "size": 44866,
        "upload_time": "2022-08-08T19:05:18",
        "upload_time_iso_8601": "2022-08-08T19:05:18.777601Z",
        "url": "https://files.pythonhosted.org/packages/b0/78/73d7ffd3b22086511c8110807b1ac336378aa415b50012799e295f6c03b5/torchfitter-4.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "4.2.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4f7e8e338757e7d5ece83035f415a6bdd3106bbbc59f139ce6a56eb35d879625",
          "md5": "fabc5aac2825d823fdcb77dbd4d54625",
          "sha256": "103e12b4e276783433d55314c6850752abf4787c4f27eff3fe6feba6ff4c422f"
        },
        "downloads": -1,
        "filename": "torchfitter-4.2.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "fabc5aac2825d823fdcb77dbd4d54625",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7,",
        "size": 30696,
        "upload_time": "2022-09-10T15:40:31",
        "upload_time_iso_8601": "2022-09-10T15:40:31.303155Z",
        "url": "https://files.pythonhosted.org/packages/4f/7e/8e338757e7d5ece83035f415a6bdd3106bbbc59f139ce6a56eb35d879625/torchfitter-4.2.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "00f67d14adda07b8222b17aceac95c905abd62dbb4d46dd32c1c1fef5728024b",
          "md5": "97e8402c278ce6e26f88ba4fa2b693c9",
          "sha256": "aed6388481b1a0c6a3ba0cb0103d2f3b674c4b8fc0e20c8a3f873adc432df69a"
        },
        "downloads": -1,
        "filename": "torchfitter-4.2.1.tar.gz",
        "has_sig": false,
        "md5_digest": "97e8402c278ce6e26f88ba4fa2b693c9",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7,",
        "size": 44804,
        "upload_time": "2022-09-10T15:40:33",
        "upload_time_iso_8601": "2022-09-10T15:40:33.183174Z",
        "url": "https://files.pythonhosted.org/packages/00/f6/7d14adda07b8222b17aceac95c905abd62dbb4d46dd32c1c1fef5728024b/torchfitter-4.2.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "4f7e8e338757e7d5ece83035f415a6bdd3106bbbc59f139ce6a56eb35d879625",
        "md5": "fabc5aac2825d823fdcb77dbd4d54625",
        "sha256": "103e12b4e276783433d55314c6850752abf4787c4f27eff3fe6feba6ff4c422f"
      },
      "downloads": -1,
      "filename": "torchfitter-4.2.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "fabc5aac2825d823fdcb77dbd4d54625",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7,",
      "size": 30696,
      "upload_time": "2022-09-10T15:40:31",
      "upload_time_iso_8601": "2022-09-10T15:40:31.303155Z",
      "url": "https://files.pythonhosted.org/packages/4f/7e/8e338757e7d5ece83035f415a6bdd3106bbbc59f139ce6a56eb35d879625/torchfitter-4.2.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "00f67d14adda07b8222b17aceac95c905abd62dbb4d46dd32c1c1fef5728024b",
        "md5": "97e8402c278ce6e26f88ba4fa2b693c9",
        "sha256": "aed6388481b1a0c6a3ba0cb0103d2f3b674c4b8fc0e20c8a3f873adc432df69a"
      },
      "downloads": -1,
      "filename": "torchfitter-4.2.1.tar.gz",
      "has_sig": false,
      "md5_digest": "97e8402c278ce6e26f88ba4fa2b693c9",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7,",
      "size": 44804,
      "upload_time": "2022-09-10T15:40:33",
      "upload_time_iso_8601": "2022-09-10T15:40:33.183174Z",
      "url": "https://files.pythonhosted.org/packages/00/f6/7d14adda07b8222b17aceac95c905abd62dbb4d46dd32c1c1fef5728024b/torchfitter-4.2.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}