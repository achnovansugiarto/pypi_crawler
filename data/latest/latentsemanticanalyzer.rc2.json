{
  "info": {
    "author": "Anton Antonov",
    "author_email": "antononcube@posteo.net",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: GNU General Public License v3 (GPLv3)",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Latent Semantic Analysis (LSA) Python package \n\n## In brief\n\nThis Python package, `LatentSemanticAnalyzer`, has different functions for computations of \nLatent Semantic Analysis (LSA) workflows\n(using Sparse matrix Linear Algebra.) The package mirrors\nthe Mathematica implementation [AAp1]. \n(There is also a corresponding implementation in R; see [AAp2].) \n\nThe package provides: \n- Class `LatentSemanticAnalyzer`\n- Functions for applying Latent Semantic Indexing (LSI) functions on matrix entries\n- \"Data loader\" function for obtaining a `pandas` data frame ~580 abstracts of conference presentations\n\n------\n\n## Installation\n\nTo install from GitHub use the shell command:\n\n```shell\npython -m pip install git+https://github.com/antononcube/Python-packages.git#egg=LatentSemanticAnalyzer\\&subdirectory=LatentSemanticAnalyzer\n```\n\nTo install from PyPI:\n\n```shell\npython -m pip install LatentSemanticAnalyzer\n```\n\n----- \n\n## LSA workflows\n\nThe scope of the package is to facilitate the creation and execution of the workflows encompassed in this\nflow chart:\n\n![LSA-workflows](https://raw.githubusercontent.com/antononcube/MathematicaForPrediction/master/MarkdownDocuments/Diagrams/A-monad-for-Latent-Semantic-Analysis-workflows/LSA-workflows.jpg)\n\nFor more details see the article \n[\"A monad for Latent Semantic Analysis workflows\"](https://mathematicaforprediction.wordpress.com/2019/09/13/a-monad-for-latent-semantic-analysis-workflows/),\n[AA1].\n\n------\n\n## Usage example\n\nHere is an example of a LSA pipeline that:\n1. Ingests a collection of texts\n2. Makes the corresponding document-term matrix using stemming and removing stop words\n3. Extracts 40 topics\n4. Shows a table with the extracted topics\n5. Shows a table with statistical thesaurus entries for selected words  \n\n```\nimport random\nfrom LatentSemanticAnalyzer.LatentSemanticAnalyzer import *\nfrom LatentSemanticAnalyzer.DataLoaders import *\nimport snowballstemmer\n\n# Collection of texts\ndfAbstracts = load_abstracts_data_frame()\ndocs = dict(zip(dfAbstracts.ID, dfAbstracts.Abstract))\n\n# Stemmer object (to preprocess words in the pipeline below)\nstemmerObj = snowballstemmer.stemmer(\"english\")\n\n# Words to show statistical thesaurus entries for\nwords = [\"notebook\", \"computational\", \"function\", \"neural\", \"talk\", \"programming\"]\n\n# Reproducible results\nrandom.seed(12)\n\n# LSA pipeline\nlsaObj = (LatentSemanticAnalyzer()\n          .make_document_term_matrix(docs=docs,\n                                     stop_words=True,\n                                     stemming_rules=True,\n                                     min_length=3)\n          .apply_term_weight_functions(global_weight_func=\"IDF\",\n                                       local_weight_func=\"None\",\n                                       normalizer_func=\"Cosine\")\n          .extract_topics(number_of_topics=40, min_number_of_documents_per_term=10, method=\"NNMF\")\n          .echo_topics_interpretation(number_of_terms=12, wide_form=True)\n          .echo_statistical_thesaurus(terms=stemmerObj.stemWords(words),\n                                      wide_form=True,\n                                      number_of_nearest_neighbors=12,\n                                      method=\"cosine\",\n                                      echo_function=lambda x: print(x.to_string())))\n```\n\n------\n\n## Related Python packages\n\nThis package is based on the Python package \n[`SSparseMatrix`](../SSparseMatrix/README.md), [AAp3]\n\n*TBF...*\n\n------\n\n## Related Mathematica and R packages\n\n### Mathematica\n\nThe Python pipeline above corresponds to the following pipeline for the Mathematica package\n[AAp1]:\n\n```mathematica\nlsaObj =\n  LSAMonUnit[aAbstracts]⟹\n   LSAMonMakeDocumentTermMatrix[\"StemmingRules\" -> Automatic, \"StopWords\" -> Automatic]⟹\n   LSAMonEchoDocumentTermMatrixStatistics[\"LogBase\" -> 10]⟹\n   LSAMonApplyTermWeightFunctions[\"IDF\", \"None\", \"Cosine\"]⟹\n   LSAMonExtractTopics[\"NumberOfTopics\" -> 20, Method -> \"NNMF\", \"MaxSteps\" -> 16, \"MinNumberOfDocumentsPerTerm\" -> 20]⟹\n   LSAMonEchoTopicsTable[\"NumberOfTerms\" -> 10]⟹\n   LSAMonEchoStatisticalThesaurus[\"Words\" -> Map[WordData[#, \"PorterStem\"]&, {\"notebook\", \"computational\", \"function\", \"neural\", \"talk\", \"programming\"}]];\n```\n\n### R \n\nThe package \n[`LSAMon-R`](https://github.com/antononcube/R-packages/tree/master/LSAMon-R), \n[AAp2], implements a software monad for LSA workflows. \n\n------\n\n## References\n\n### Articles\n\n[AA1] Anton Antonov,\n[\"A monad for Latent Semantic Analysis workflows\"](https://mathematicaforprediction.wordpress.com/2019/09/13/a-monad-for-latent-semantic-analysis-workflows/),\n(2019),\n[MathematicaForPrediction at WordPress](https://mathematicaforprediction.wordpress.com).\n\n### Mathematica and R Packages \n\n[AAp1] Anton Antonov, \n[Monadic Latent Semantic Analysis Mathematica package](https://github.com/antononcube/MathematicaForPrediction/blob/master/MonadicProgramming/MonadicLatentSemanticAnalysis.m),\n(2017),\n[MathematicaForPrediction at GitHub](https://github.com/antononcube/MathematicaForPrediction).\n\n[AAp2] Anton Antonov,\n[Latent Semantic Analysis Monad in R](https://github.com/antononcube/R-packages/tree/master/LSAMon-R)\n(2019),\n[R-packages at GitHub/antononcube](https://github.com/antononcube/R-packages).\n\n### Python packages\n\n[AAp3] Anton Antonov,\n[SSparseMatrix Python package](https://pypi.org/project/SSparseMatrix),\n(2021),\n[PyPI](https://pypi.org).\n\n[AAp4] Anton Antonov,\n[SparseMatrixRecommender Python package](https://pypi.org/project/SparseMatrixRecommender),\n(2021),\n[PyPI](https://pypi.org).\n\n[AAp5] Anton Antonov,\n[RandomDataGenerators Python package](https://pypi.org/project/RandomDataGenerators),\n(2021),\n[PyPI](https://pypi.org).\n\n[AAp6] Anton Antonov,\n[RandomMandala Python package](https://pypi.org/project/RandomMandala),\n(2021),\n[PyPI](https://pypi.org).\n\n[MZp1] Marinka Zitnik and Blaz Zupan,\n[Nimfa: A Python Library for Nonnegative Matrix Factorization](https://pypi.org/project/nimfa/),\n(2013-2019),\n[PyPI](https://pypi.org).\n\n[SDp1] Snowball Developers,\n[SnowballStemmer Python package](https://pypi.org/project/snowballstemmer/),\n(2013-2021),\n[PyPI](https://pypi.org).\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/antononcube/Python-packages/tree/main/LatentSemanticAnalyzer",
    "keywords": "sparse,matrix,sparse matrix,linear algebra,linear,algebra,lsi,latent semantic indexing,dimension,reduction,dimension reduction,svd,singular value decomposition,nnmf,nmf,non-negative matrix factorization",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "LatentSemanticAnalyzer",
    "package_url": "https://pypi.org/project/LatentSemanticAnalyzer/",
    "platform": null,
    "project_url": "https://pypi.org/project/LatentSemanticAnalyzer/",
    "project_urls": {
      "Homepage": "https://github.com/antononcube/Python-packages/tree/main/LatentSemanticAnalyzer"
    },
    "release_url": "https://pypi.org/project/LatentSemanticAnalyzer/0.1.1/",
    "requires_dist": [
      "numpy",
      "scipy",
      "pandas",
      "stop-words",
      "snowballstemmer",
      "nimfa",
      "SSparseMatrix",
      "SparseMatrixRecommender"
    ],
    "requires_python": ">=3.7",
    "summary": "Latent Semantic Analysis package based on \"the standard\" Latent Semantic Indexing theory.",
    "version": "0.1.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 13417325,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "002b9616d402053c2cf8392bd958fb558fd27847992460f6b57712591ff6e476",
          "md5": "f829b8c80c4d30458deb09d80882e307",
          "sha256": "949669f11aa0f69f7cd38e0b9e420c72afe16fc26d2f6296a1da0b8caf4a853c"
        },
        "downloads": -1,
        "filename": "LatentSemanticAnalyzer-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f829b8c80c4d30458deb09d80882e307",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 186898,
        "upload_time": "2021-12-05T14:39:15",
        "upload_time_iso_8601": "2021-12-05T14:39:15.922195Z",
        "url": "https://files.pythonhosted.org/packages/00/2b/9616d402053c2cf8392bd958fb558fd27847992460f6b57712591ff6e476/LatentSemanticAnalyzer-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "49798e7f29ab3140608d6e8dd0a8b19f0db4f89558947c462c5de122133fca37",
          "md5": "0b53b65d4e6adc46e6e11ea94df0c6de",
          "sha256": "9163544302dbf4f1302f00bb386cc853eab23c5e9b9feaa405b02662cf429431"
        },
        "downloads": -1,
        "filename": "LatentSemanticAnalyzer-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "0b53b65d4e6adc46e6e11ea94df0c6de",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 188062,
        "upload_time": "2021-12-05T14:39:18",
        "upload_time_iso_8601": "2021-12-05T14:39:18.163396Z",
        "url": "https://files.pythonhosted.org/packages/49/79/8e7f29ab3140608d6e8dd0a8b19f0db4f89558947c462c5de122133fca37/LatentSemanticAnalyzer-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5e9194042d60f1fce6b4677eb5b780ff7535f559c313772f809a534d5bd4438e",
          "md5": "65e39e213da8a58aae53a5b806aa3b9f",
          "sha256": "a35254c40c3b9e9c72c9872a646af7f7982a4943c5f1446db6334fdf31bb4910"
        },
        "downloads": -1,
        "filename": "LatentSemanticAnalyzer-0.1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "65e39e213da8a58aae53a5b806aa3b9f",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 187335,
        "upload_time": "2022-04-05T16:21:18",
        "upload_time_iso_8601": "2022-04-05T16:21:18.326762Z",
        "url": "https://files.pythonhosted.org/packages/5e/91/94042d60f1fce6b4677eb5b780ff7535f559c313772f809a534d5bd4438e/LatentSemanticAnalyzer-0.1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4521ba601c2373b83256ea28f5ceca10b3f6fd00df9a42527b6075f13bed1633",
          "md5": "67b093bcb61eae1d7e084c75ca0f7c81",
          "sha256": "aadafb1405ca35849924232b54298756ef65129e3e306506c2ab621252e38684"
        },
        "downloads": -1,
        "filename": "LatentSemanticAnalyzer-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "67b093bcb61eae1d7e084c75ca0f7c81",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 188434,
        "upload_time": "2022-04-05T16:21:19",
        "upload_time_iso_8601": "2022-04-05T16:21:19.950248Z",
        "url": "https://files.pythonhosted.org/packages/45/21/ba601c2373b83256ea28f5ceca10b3f6fd00df9a42527b6075f13bed1633/LatentSemanticAnalyzer-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "5e9194042d60f1fce6b4677eb5b780ff7535f559c313772f809a534d5bd4438e",
        "md5": "65e39e213da8a58aae53a5b806aa3b9f",
        "sha256": "a35254c40c3b9e9c72c9872a646af7f7982a4943c5f1446db6334fdf31bb4910"
      },
      "downloads": -1,
      "filename": "LatentSemanticAnalyzer-0.1.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "65e39e213da8a58aae53a5b806aa3b9f",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 187335,
      "upload_time": "2022-04-05T16:21:18",
      "upload_time_iso_8601": "2022-04-05T16:21:18.326762Z",
      "url": "https://files.pythonhosted.org/packages/5e/91/94042d60f1fce6b4677eb5b780ff7535f559c313772f809a534d5bd4438e/LatentSemanticAnalyzer-0.1.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "4521ba601c2373b83256ea28f5ceca10b3f6fd00df9a42527b6075f13bed1633",
        "md5": "67b093bcb61eae1d7e084c75ca0f7c81",
        "sha256": "aadafb1405ca35849924232b54298756ef65129e3e306506c2ab621252e38684"
      },
      "downloads": -1,
      "filename": "LatentSemanticAnalyzer-0.1.1.tar.gz",
      "has_sig": false,
      "md5_digest": "67b093bcb61eae1d7e084c75ca0f7c81",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 188434,
      "upload_time": "2022-04-05T16:21:19",
      "upload_time_iso_8601": "2022-04-05T16:21:19.950248Z",
      "url": "https://files.pythonhosted.org/packages/45/21/ba601c2373b83256ea28f5ceca10b3f6fd00df9a42527b6075f13bed1633/LatentSemanticAnalyzer-0.1.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}