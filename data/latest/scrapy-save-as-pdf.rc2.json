{
  "info": {
    "author": "etng",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Framework :: Scrapy",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: BSD License",
      "Operating System :: OS Independent",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.4",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Topic :: Internet :: WWW/HTTP",
      "Topic :: Software Development :: Libraries :: Application Frameworks",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "# Pipeline to Download PDF or Save page as PDF for scrapy item\n\n\n## Installation\n\nInstall `scrapy-save-as-pdf` using `pip`:\n\n```\npip install scrapy-save-as-pdf\n```\n\n## Configuration\n0. _(Optionally)_ if you want to use `WEBDRIVER_HUB_URL`, you can use `docker` to setup one like this:\n\n```shell script\ndocker run -d -p 4444:4444 -v /dev/shm:/dev/shm selenium/standalone-chrome:4.0.0-alpha-7-20201119\n```\nthen `WEBDRIVER_HUB_URL` value is `http://docker_host_ip:4444/wd/hub`\nand we often debug on local host, so we use `http://127.0.0.1:4444/wd/hub`\n\n1. Add the  ``settings.py`` of your Scrapy project like this:\n\n```python\nPROXY = \"\"\nCHROME_DRIVER_PATH ='/snap/bin/chromium.chromedriver'\nPDF_SAVE_PATH = \"./pdfs\"\nPDF_SAVE_AS_PDF = False\nPDF_DOWNLOAD_TIMEOUT = 60\nPDF_PRINT_OPTIONS = {\n    'landscape': False,\n    'displayHeaderFooter': False,\n    'printBackground': True,\n    'preferCSSPageSize': True,\n}\nWEBDRIVER_HUB_URL = 'http://127.0.0.1:4444/wd/hub'\n```\n\nIf both `WEBDRIVER_HUB_URL` and `CHROME_DRIVER_PATH` are set, we use `WEBDRIVER_HUB_URL`.\n\n2. Enable the pipeline by adding it to ``ITEM_PIPELINES`` in your ``settings.py`` file and changing priority:\n\n```python\nITEM_PIPELINES = {\n    'scrapy_save_as_pdf.pipelines.SaveAsPdfPipeline': -1,\n}\n```\nThe order should before your persist pipeline such as save to database and after your preprocess pipeline.\n\nIn the demo scrapy project, I put the `SaveToQiniuPipeline` after this plugin to persist pdf to the cloud.\n\n## Usage\n\nset the `pdf_url` and/or `url` field in your yielded item\n```python\nimport scrapy\n\nclass MySpider(scrapy.Spider):\n    start_urls = [\n        \"http://example.com\",\n    ]\n\n    def start_requests(self):\n        for url in self.start_urls:\n            yield scrapy.Request(url, self.parse)\n\n    def parse(self, response):\n        yield {\n            \"url\": \"http://example.com/cate1/page1.html\",\n            \"pdf_url\": \"http://example.com/cate1/page1.pdf\",\n        }\n        yield {\n            \"url\": \"http://example.com/cate1/page2.html\",\n            \"pdf_url\": \"http://example.com/cate1/page2.pdf\",\n        }\n```\nthe `pdf_url` field will be populated with the downloaded pdf file location, if `pdf_url` field has old value then move it to `origin_pdf_url` field, you can handle them in your next pipeline.\n\n## Getting help\n\nPlease use github issue\n\n## Contributing\n\nPRs are always welcomed.\n\n## Changes\n\n### 0.1.0 (2020-12-25)\n\nInitial release\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/etng/scrapy-save-as-pdf",
    "keywords": "",
    "license": "BSD",
    "maintainer": "etng",
    "maintainer_email": "etng2004@gmail.com",
    "name": "scrapy-save-as-pdf",
    "package_url": "https://pypi.org/project/scrapy-save-as-pdf/",
    "platform": "",
    "project_url": "https://pypi.org/project/scrapy-save-as-pdf/",
    "project_urls": {
      "Homepage": "https://github.com/etng/scrapy-save-as-pdf"
    },
    "release_url": "https://pypi.org/project/scrapy-save-as-pdf/0.2.1/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "Pipeline to Download PDF or Save page as PDF for scrapy item",
    "version": "0.2.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 9229955,
  "releases": {
    "0.1.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "786abda67bd2c85a09732fadc267363a10450b2a7a0f7f50b8aea0e023371711",
          "md5": "28239ff2cf763315aa139b6bb4293bdd",
          "sha256": "e701c6f1a63312b58a2fe24b9e32ddc4d79a8acb35ee7ba753bee19a0950d9d1"
        },
        "downloads": -1,
        "filename": "scrapy_save_as_pdf-0.1.3-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "28239ff2cf763315aa139b6bb4293bdd",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 3764,
        "upload_time": "2020-11-25T10:49:16",
        "upload_time_iso_8601": "2020-11-25T10:49:16.476919Z",
        "url": "https://files.pythonhosted.org/packages/78/6a/bda67bd2c85a09732fadc267363a10450b2a7a0f7f50b8aea0e023371711/scrapy_save_as_pdf-0.1.3-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3cd9db798c93725c35d8775ca5f749a575f554d7e461fe9ac6eef8843e356f43",
          "md5": "c214fda131f69daf86263db87bf7f74c",
          "sha256": "c62c94c3e2f40e7603f2d760a50341c1fe0057f2b6aba659380058f62eec05dc"
        },
        "downloads": -1,
        "filename": "scrapy-save-as-pdf-0.1.3.tar.gz",
        "has_sig": false,
        "md5_digest": "c214fda131f69daf86263db87bf7f74c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 3576,
        "upload_time": "2020-11-25T10:49:18",
        "upload_time_iso_8601": "2020-11-25T10:49:18.242419Z",
        "url": "https://files.pythonhosted.org/packages/3c/d9/db798c93725c35d8775ca5f749a575f554d7e461fe9ac6eef8843e356f43/scrapy-save-as-pdf-0.1.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "46f2f22008a74342410ffb71075ae7260020a84b27626f659f9e29b7c77e2d14",
          "md5": "f4bf9a22ac292e1503eb46bb701f48ff",
          "sha256": "520bf291d0fb2d7f5a874ec78c91ad40b766ca88b14c57d503eb290744cc7655"
        },
        "downloads": -1,
        "filename": "scrapy_save_as_pdf-0.2.1-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f4bf9a22ac292e1503eb46bb701f48ff",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 4356,
        "upload_time": "2021-01-26T03:34:55",
        "upload_time_iso_8601": "2021-01-26T03:34:55.690239Z",
        "url": "https://files.pythonhosted.org/packages/46/f2/f22008a74342410ffb71075ae7260020a84b27626f659f9e29b7c77e2d14/scrapy_save_as_pdf-0.2.1-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2efd50076cee9f90dadad9a1394039ddcfb01f33fdcd375c88ba06922439ba80",
          "md5": "2d5d4d8d232674210f710f84e1ad5f81",
          "sha256": "f82b5749638847854744334d2e2458f8906a0f55411d03295208dfbaa0e45b82"
        },
        "downloads": -1,
        "filename": "scrapy-save-as-pdf-0.2.1.tar.gz",
        "has_sig": false,
        "md5_digest": "2d5d4d8d232674210f710f84e1ad5f81",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 4258,
        "upload_time": "2021-01-26T03:34:57",
        "upload_time_iso_8601": "2021-01-26T03:34:57.121472Z",
        "url": "https://files.pythonhosted.org/packages/2e/fd/50076cee9f90dadad9a1394039ddcfb01f33fdcd375c88ba06922439ba80/scrapy-save-as-pdf-0.2.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "46f2f22008a74342410ffb71075ae7260020a84b27626f659f9e29b7c77e2d14",
        "md5": "f4bf9a22ac292e1503eb46bb701f48ff",
        "sha256": "520bf291d0fb2d7f5a874ec78c91ad40b766ca88b14c57d503eb290744cc7655"
      },
      "downloads": -1,
      "filename": "scrapy_save_as_pdf-0.2.1-py2.py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "f4bf9a22ac292e1503eb46bb701f48ff",
      "packagetype": "bdist_wheel",
      "python_version": "py2.py3",
      "requires_python": null,
      "size": 4356,
      "upload_time": "2021-01-26T03:34:55",
      "upload_time_iso_8601": "2021-01-26T03:34:55.690239Z",
      "url": "https://files.pythonhosted.org/packages/46/f2/f22008a74342410ffb71075ae7260020a84b27626f659f9e29b7c77e2d14/scrapy_save_as_pdf-0.2.1-py2.py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "2efd50076cee9f90dadad9a1394039ddcfb01f33fdcd375c88ba06922439ba80",
        "md5": "2d5d4d8d232674210f710f84e1ad5f81",
        "sha256": "f82b5749638847854744334d2e2458f8906a0f55411d03295208dfbaa0e45b82"
      },
      "downloads": -1,
      "filename": "scrapy-save-as-pdf-0.2.1.tar.gz",
      "has_sig": false,
      "md5_digest": "2d5d4d8d232674210f710f84e1ad5f81",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 4258,
      "upload_time": "2021-01-26T03:34:57",
      "upload_time_iso_8601": "2021-01-26T03:34:57.121472Z",
      "url": "https://files.pythonhosted.org/packages/2e/fd/50076cee9f90dadad9a1394039ddcfb01f33fdcd375c88ba06922439ba80/scrapy-save-as-pdf-0.2.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}