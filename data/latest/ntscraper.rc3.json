{
  "info": {
    "author": "Lorenzo Bocchi",
    "author_email": "lorenzobocchi99@yahoo.com",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.9"
    ],
    "description": "# Unofficial Nitter scraper\r\n\r\nThis is a simple library to scrape Nitter instances for tweets. It can:\r\n\r\n- search and scrape tweets with a certain term\r\n\r\n- search and scrape tweets with a certain hashtag\r\n\r\n- scrape tweets from a user profile\r\n\r\n- get profile information of a user, such as display name, username, number of tweets, profile picture ...\r\n\r\nIf the instance to use is not provided to the scraper, it will use a random instance among those listed in https://github.com/zedeus/nitter/wiki/Instances.\r\n\r\n---\r\n\r\n## Installation\r\n\r\n```\r\npip install ntscraper\r\n```\r\n\r\n## How to use\r\n\r\nFirst, initialize the library:\r\n\r\n```\r\nfrom ntscraper import Nitter\r\n\r\nscraper = Nitter(log_level=None)\r\n```\r\nThe valid logging levels are:\r\n- None = no logs\r\n- 1 = informational logs (default)\r\n- 2 = informational, warning and error logs\r\n\r\nThen, choose the proper function for what you want to do from the following.\r\n\r\n### Scrape tweets\r\n\r\n```\r\ngithub_hash_tweets = scraper.get_tweets(\"github\", mode='hashtag')\r\n\r\nbezos_tweets = scraper.get_tweets(\"JeffBezos\", mode='user')\r\n```\r\n\r\nParameters:\r\n- term: search term\r\n- mode: modality to scrape the tweets. Default is 'term' which will look for tweets containing the search term. Other modes are 'hashtag' to search for a hashtag and 'user' to scrape tweets from a user profile\r\n- number: number of tweets to scrape. Default is 5. If 'since' is specified, this is bypassed.\r\n- since: date to start scraping from, formatted as YYYY-MM-DD. Default is None\r\n- until: date to stop scraping at, formatted as YYYY-MM-DD. Default is None\r\n- max_retries: max retries to scrape a page. Default is 5\r\n- instance: Nitter instance to use. Default is None and will be chosen at random\r\n\r\nReturns a dictionary with tweets and threads for the term.\r\n\r\n### Get profile information\r\n\r\n```\r\nbezos_information = scraper.get_profile_info(\"JeffBezos\")\r\n```\r\n\r\nParameters:\r\n- username: username of the page to scrape\r\n- max_retries: max retries to scrape a page. Default is 5\r\n- instance: Nitter instance to use. Default is None\r\n\r\nReturns a dictionary of the profile's information.\r\n\r\n### Get random Nitter instance\r\n\r\n```\r\nrandom_instance = scraper.get_random_instance()\r\n```\r\n\r\nReturns a random Nitter instance.\r\n\r\n## To do list\r\n\r\n- [ ] Add scraping of posts and comments\r\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "twitter,nitter,scraping",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "ntscraper",
    "package_url": "https://pypi.org/project/ntscraper/",
    "platform": null,
    "project_url": "https://pypi.org/project/ntscraper/",
    "project_urls": {
      "Documentation": "https://github.com/bocchilorenzo/ntscraper",
      "Homepage": "https://github.com/bocchilorenzo/ntscraper",
      "Source": "https://github.com/bocchilorenzo/ntscraper"
    },
    "release_url": "https://pypi.org/project/ntscraper/0.1.2/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "Unofficial library to scrape Twitter profiles and posts from Nitter instances",
    "version": "0.1.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16655920,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cb5caeb0f1104f218113e0cba117539b1d3c71f6acf49012e98542012fbd5d90",
          "md5": "75954a951045ae8cb48d9dbb1e9f7eb4",
          "sha256": "169611a2908d3673a93272c293b54f90b91332ffca8cc60b59d9a55962ddeee6"
        },
        "downloads": -1,
        "filename": "ntscraper-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "75954a951045ae8cb48d9dbb1e9f7eb4",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 7683,
        "upload_time": "2023-01-22T17:38:40",
        "upload_time_iso_8601": "2023-01-22T17:38:40.846489Z",
        "url": "https://files.pythonhosted.org/packages/cb/5c/aeb0f1104f218113e0cba117539b1d3c71f6acf49012e98542012fbd5d90/ntscraper-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8fe8afa3f133c6f15eaa48a4e08313f94e376ec4c111a3d965be1b510caefa4b",
          "md5": "b48e57c1c5fb8657fde0250c3a59ab34",
          "sha256": "023416179de1e0521d9699d014827ac748c0fb9ccb474fb92c8dc2ccd8858e76"
        },
        "downloads": -1,
        "filename": "ntscraper-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "b48e57c1c5fb8657fde0250c3a59ab34",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 7684,
        "upload_time": "2023-01-31T13:59:19",
        "upload_time_iso_8601": "2023-01-31T13:59:19.603962Z",
        "url": "https://files.pythonhosted.org/packages/8f/e8/afa3f133c6f15eaa48a4e08313f94e376ec4c111a3d965be1b510caefa4b/ntscraper-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9618b1de1b86c99b8e63a9df06db998bc1ca33cf7a55dc2825cabc42cc8a5483",
          "md5": "5225fc88eec318b9eceeb5e8ba13e663",
          "sha256": "d8bad3463f6f4a1def7eb8fad195f948b65d5e991bdc3b98fda175b412b09a79"
        },
        "downloads": -1,
        "filename": "ntscraper-0.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "5225fc88eec318b9eceeb5e8ba13e663",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 8537,
        "upload_time": "2023-02-01T20:52:27",
        "upload_time_iso_8601": "2023-02-01T20:52:27.592120Z",
        "url": "https://files.pythonhosted.org/packages/96/18/b1de1b86c99b8e63a9df06db998bc1ca33cf7a55dc2825cabc42cc8a5483/ntscraper-0.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "9618b1de1b86c99b8e63a9df06db998bc1ca33cf7a55dc2825cabc42cc8a5483",
        "md5": "5225fc88eec318b9eceeb5e8ba13e663",
        "sha256": "d8bad3463f6f4a1def7eb8fad195f948b65d5e991bdc3b98fda175b412b09a79"
      },
      "downloads": -1,
      "filename": "ntscraper-0.1.2.tar.gz",
      "has_sig": false,
      "md5_digest": "5225fc88eec318b9eceeb5e8ba13e663",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 8537,
      "upload_time": "2023-02-01T20:52:27",
      "upload_time_iso_8601": "2023-02-01T20:52:27.592120Z",
      "url": "https://files.pythonhosted.org/packages/96/18/b1de1b86c99b8e63a9df06db998bc1ca33cf7a55dc2825cabc42cc8a5483/ntscraper-0.1.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}