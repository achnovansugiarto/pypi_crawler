{
  "info": {
    "author": "Artiom",
    "author_email": "art.israel.mail@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Framework :: AsyncIO",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.11",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Topic :: System :: Distributed Computing",
      "Topic :: System :: Networking"
    ],
    "description": "aiokafka-commit\n===============\n.. image:: https://github.com/aio-libs/aiokafka/actions/workflows/tests.yml/badge.svg?branch=master\n    :target: https://github.com/aio-libs/aiokafka/actions/workflows/tests.yml?query=branch%3Amaster\n    :alt: |Build status|\n.. image:: https://codecov.io/github/aio-libs/aiokafka/coverage.svg?branch=master\n    :target: https://codecov.io/gh/aio-libs/aiokafka/branch/master\n    :alt: |Coverage|\n.. image:: https://badges.gitter.im/Join%20Chat.svg\n    :target: https://gitter.im/aio-libs/Lobby\n    :alt: |Chat on Gitter|\n\nasyncio client for Kafka forked from aio-libs/aiokafka\nThis project will be removed in the future when aio-libs/aiokafka will fix commit issue\n\nAIOKafkaProducer\n****************\n\nAIOKafkaProducer is a high-level, asynchronous message producer.\n\nExample of AIOKafkaProducer usage:\n\n.. code-block:: python\n\n    from aiokafka import AIOKafkaProducer\n    import asyncio\n\n    async def send_one():\n        producer = AIOKafkaProducer(bootstrap_servers='localhost:9092')\n        # Get cluster layout and initial topic/partition leadership information\n        await producer.start()\n        try:\n            # Produce message\n            await producer.send_and_wait(\"my_topic\", b\"Super message\")\n        finally:\n            # Wait for all pending messages to be delivered or expire.\n            await producer.stop()\n\n    asyncio.run(send_one())\n\n\nAIOKafkaConsumer\n****************\n\nAIOKafkaConsumer is a high-level, asynchronous message consumer.\nIt interacts with the assigned Kafka Group Coordinator node to allow multiple\nconsumers to load balance consumption of topics (requires kafka >= 0.9.0.0).\n\nExample of AIOKafkaConsumer usage:\n\n.. code-block:: python\n\n    from aiokafka import AIOKafkaConsumer\n    import asyncio\n\n    async def consume():\n        consumer = AIOKafkaConsumer(\n            'my_topic', 'my_other_topic',\n            bootstrap_servers='localhost:9092',\n            group_id=\"my-group\")\n        # Get cluster layout and join group `my-group`\n        await consumer.start()\n        try:\n            # Consume messages\n            async for msg in consumer:\n                print(\"consumed: \", msg.topic, msg.partition, msg.offset,\n                      msg.key, msg.value, msg.timestamp)\n        finally:\n            # Will leave consumer group; perform autocommit if enabled.\n            await consumer.stop()\n\n    asyncio.run(consume())\n\nRunning tests\n-------------\n\nDocker is required to run tests. See https://docs.docker.com/engine/installation for installation notes. Also note, that `lz4` compression libraries for python will require `python-dev` package,\nor python source header files for compilation on Linux.\nNOTE: You will also need a valid java installation. It's required for the ``keytool`` utility, used to\ngenerate ssh keys for some tests.\n\nSetting up tests requirements (assuming you're within virtualenv on ubuntu 14.04+)::\n\n    sudo apt-get install -y libsnappy-dev libzstd-dev\n    make setup\n\nRunning tests with coverage::\n\n    make cov\n\nTo run tests with a specific version of Kafka (default one is 1.0.2) use KAFKA_VERSION variable::\n\n    make cov KAFKA_VERSION=0.10.2.1\n\nTest running cheatsheat:\n\n * ``make test FLAGS=\"-l -x --ff\"`` - run until 1 failure, rerun failed tests first. Great for cleaning up a lot of errors, say after a big refactor.\n * ``make test FLAGS=\"-k consumer\"`` - run only the consumer tests.\n * ``make test FLAGS=\"-m 'not ssl'\"`` - run tests excluding ssl.\n * ``make test FLAGS=\"--no-pull\"`` - do not try to pull new docker image before test run.\n\n=========\nChangelog\n=========\n\n\n0.7.2 (2021-09-02)\n==================\n\nBugfixes:\n\n* Fix `CancelledError` handling in sender (issue #710)\n* Fix exception for weakref use after object deletion (issue #755)\n* Fix consumer's `start()` method hanging after being idle for more than\n  `max_poll_interval_ms` (issue #764)\n\n\nImproved Documentation:\n\n* Add `SASL_PLAINTEXT` and `SASL_SSL` to valid values of security protocol\n  attribute (pr #768 by @pawelrubin)\n\n\n0.7.1 (2021-06-04)\n==================\n\nBugfixes:\n\n* Allow group coordinator to close when all brokers are unavailable (issue #659\n  and pr #660 by @dkilgore90)\n* Exclude `.so` from source distribution to fix usage of sdist tarball\n  (issue #681 and pr #684 by ods)\n* Add `dataclasses` backport package to dependencies for Python 3.6\n  (pr #690 by @ods)\n* Fix initialization without running loop (issue #689 and pr #690 by @ods)\n* Fix consumer fetcher for python3.9 (pr #672 by @dutradda)\n* Make sure generation and member id are correct after (re)joining group.\n  (issue #727 and pr #747 by @vangheem)\n\n\nDeprecation:\n\n* Add deprecation warning when loop argument to AIOKafkaConsumer and\n  AIOKafkaProducer is passed.  It's scheduled for removal in 0.8.0 as a\n  preparation step towards upcoming Python 3.10 (pr #699 by @ods)\n\n\nImproved Documentation:\n\n* Update docs and examples to not use deprecated practices like passing loop\n  explicitly (pr #693 by @ods)\n* Add docstring for Kafka header support in `Producer.send()` (issue #566 and\n  pr #650 by @andreportela)\n\n\n0.7.0 (2020-10-28)\n==================\n\nNew features:\n\n* Add support for Python 3.8 and 3.9. (issue #569, pr #669 and #676 by @ods)\n* Drop support for Python 3.5. (pr #667 by @ods)\n* Add `OAUTHBEARER` as a new `sasl_mechanism`. (issue #618 and pr #630 by @oulydna)\n\n\nBugfixes:\n\n* Fix memory leak in kafka consumer when consumer is in idle state not consuming any message.\n  (issue #628 and pr #629 by @iamsinghrajat)\n\n\n0.6.0 (2020-05-15)\n==================\n\nNew features:\n\n* Add async context manager support for both Producer and Consumer. (pr #613 and #494 by @nimish)\n* Upgrade to kafka-python version 2.0.0 and set it as non-strict\n  parameter. (issue #590 by @yumendy and #558 by @originalgremlin)\n* Make loop argument optional (issue #544)\n* SCRAM-SHA-256 and SCRAM-SHA-512 support for SASL authentication (issue #571 and pr #588 by @SukiCZ)\n* Added headers param to AIOKafkaProducer.send_and_wait (pr #553 by @megabotan)\n* Add `consumer.last_poll_timestamp(partition)` which gives the ms timestamp of the last\n  update of `highwater` and `lso`. (issue #523 and pr #526 by @aure-olli)\n* Change all code base to async-await (pr #522)\n* Minor: added PR and ISSUE templates to GitHub\n\n\nBugfixes:\n\n* Ignore debug package generation on bdist_rpm command. (issue #599 by @gabriel-tincu)\n* UnknownMemberId was raised to the user instead of retrying on auto commit. (issue #611)\n* Fix issue with messages not being read after subscriptions change with group_id=None. (issue #536)\n* Handle `RequestTimedOutError` in `coordinator._do_commit_offsets()` method to explicitly mark\n  coordinator as dead. (issue #584 and pr #585 by @FedirAlifirenko)\n* Added handling `asyncio.TimeoutError` on metadata request to broker and metadata update.\n  (issue #576 and pr #577 by @MichalMazurek)\n* Too many reqs on kafka not available (issue #496 by @lud4ik)\n* Consumer.seek_to_committed now returns mapping of committed offsets (pr #531 by @ask)\n* Message Accumulator: add_message being recursive eventually overflows (pr #530 by @ask)\n\n\nImproved Documentation:\n\n* Clarify auto_offset_reset usage. (pr 601 by @dargor)\n* Fix spelling errors in comments and documentation using codespell (pr #567 by mauritsvdvijgh)\n* Delete old benchmark file (issue #546 by @jeffwidman)\n* Fix a few typos in docs (pr #573 and pr #563 by @ultrabug)\n* Fix typos, spelling, grammar, etc (pr #545 and pr #547 by @jeffwidman)\n* Fix typo in docs (pr #541 by @pablogamboa)\n* Fix documentation for benchmark (pr #537 by @abhishekray07)\n* Better logging for bad CRC (pr #529 by @ask)\n\n\n0.5.2 (2019-03-10)\n==================\n\nBugfixes:\n\n* Fix ConnectionError breaking metadata sync background task (issue #517 and #512)\n* Fix event_waiter reference before assignment (pr #504 by @romantolkachyov)\n* Bump version of kafka-python\n\n\n0.5.1 (2019-03-10)\n==================\n\nNew features:\n\n* Add SASL support with both SASL plain and SASL GGSAPI. Support also includes\n  Broker v0.9.0, but you will need to explicitly pass ``api_version=\"0.9\"``.\n  (Big thanks to @cyrbil and @jsurloppe for working on this)\n* Added support for max_poll_interval_ms and rebalance_timeout_ms settings (\n  issue #67)\n* Added pause/resume API for AIOKafkaConsumer. (issue #304)\n* Added header support to both AIOKafkaConsumer and AIOKafkaProducer for\n  brokers v0.11 and above. (issue #462)\n\nBugfixes:\n\n* Made sure to not request metadata for all topics if broker version is passed\n  explicitly and is 0.10 and above. (issue #440, thanks to @ulrikjohansson)\n* Make sure heartbeat task will close if group is reset. (issue #372)\n\n\n0.5.0 (2018-12-28)\n==================\n\nNew features:\n\n* Add full support for V2 format messages with a Cython extension. Those are\n  used for Kafka >= 0.11.0.0\n* Added support for transactional producing (issue #182)\n* Added support for idempotent producing with `enable_idempotence` parameter\n* Added support for `fetch_max_bytes` in AIOKafkaConsumer. This can help limit\n  the amount of data transferred in a single roundtrip to broker, which is\n  essential for consumers with large amount of partitions\n\nBugfixes:\n\n* Fix issue with connections not propagating serialization errors\n* Fix issue with `group=None` resetting offsets on every metadata update\n  (issue #441)\n* Fix issue with messages not delivered in order when Leader changes (issue\n  #228)\n* Fixed version parsing of `api_version` parameter. Before it ignored the\n  parameter\n\n\n0.4.3 (2018-11-01)\n==================\n\nBugfix:\n\n* Fixed memory issue introduced as a result of a bug in `asyncio.shield` and\n  not cancelling coroutine after usage. (see issue #444 and #436)\n\n\n0.4.2 (2018-09-12)\n==================\n\nBugfix:\n\n* Added error propagation from coordinator to main consumer. Before consumer\n  just stopped with error logged. (issue #294)\n* Fix manual partition assignment, broken in 0.4.0 (issue #394)\n* Fixed RecursionError in MessageAccumulator.add_message (issue #409)\n* Update kafka-python to latest 1.4.3 and added support for Python3.7\n* Dropped support for Python3.3 and Python3.4\n\nInfrastructure:\n\n* Added Kafka 1.0.2 broker for CI test runner\n* Refactored travis CI build pipeline\n\n0.4.1 (2018-05-13)\n==================\n\n* Fix issue when offset commit error reports wrong partition in log (issue #353)\n* Add ResourceWarning when Producer, Consumer or Connections are not closed\n  properly (issue #295)\n* Fix Subscription None in GroupCoordinator._do_group_rejoin (issue #306)\n\n\n0.4.0 (2018-01-30)\n==================\n\nMajor changes:\n\n* Full refactor of the internals of AIOKafkaConsumer. Needed to avoid several\n  race conditions in code (PR #286, fixes #258, #264 and #261)\n* Rewrote Records parsing protocol to allow implementation of newer protocol\n  versions later\n* Added C extension for Records parsing protocol, boosting the speed of\n  produce/consume routines significantly\n* Added an experimental batch producer API for unique cases, where user wants\n  to control batching himself (by @shargan)\n\n\nMinor changes:\n\n* Add `timestamp` field to produced message's metadata. This is needed to find\n  LOG_APPEND_TIME configured timestamps.\n* `Consumer.seek()` and similar API's now raise proper ``ValueError``'s on\n  validation failure instead of ``AssertionError``.\n\n\nBug fixes:\n\n* Fix ``connections_max_idle_ms`` option, as earlier it was only applied to\n  bootstrap socket. (PR #299)\n* Fix ``consumer.stop()`` side effect of logging an exception\n  ConsumerStoppedError (issue #263)\n* Problem with Producer not able to recover from broker failure (issue #267)\n* Traceback containing duplicate entries due to exception sharing (PR #247\n  by @Artimi)\n* Concurrent record consumption rasing `InvalidStateError('Exception is not\n  set.')` (PR #249 by @aerkert)\n* Don't fail ``GroupCoordinator._on_join_prepare()`` if ``commit_offset()``\n  throws exception (PR #230 by @shargan)\n* Send session_timeout_ms to GroupCoordinator constructor (PR #229 by @shargan)\n\nBig thanks to:\n\n* @shargan for Producer speed enhancements and the batch produce API\n  proposal/implementation.\n* @vineet-rh and other contributors for constant feedback on Consumer\n  problems, leading to the refactor mentioned above.\n\n\n0.3.1 (2017-09-19)\n==================\n\n* Added `AIOKafkaProducer.flush()` method. (PR #209 by @vineet-rh)\n* Fixed a bug with uvloop involving `float(\"inf\")` for timeout. (PR #210 by\n   dmitry-moroz)\n* Changed test runner to allow running tests on OSX. (PR #213 by @shargan)\n\n\n0.3.0 (2017-08-17)\n==================\n\n* Moved all public structures and errors to `aiokafka` namespace. You will no\n  longer need to import from `kafka` namespace.\n* Changed ConsumerRebalanceListener to support either function or coroutine\n  for `on_partitions_assigned` and `on_partitions_revoked` callbacks. (PR #190\n  by @ask)\n* Added support for `offsets_for_times`, `beginning_offsets`, `end_offsets`\n  API's. (issue #164)\n* Coordinator requests are now sent using a separate socket. Fixes slow commit\n  issue. (issuer #137, issue #128)\n* Added `seek_to_end`, `seek_to_beginning` API's. (issue #154)\n* Updated documentation to provide more useful usage guide on both Consumer and\n  Producer interface.\n\n0.2.3 (2017-07-23)\n==================\n\n* Fixed retry problem in Producer, when buffer is not reset to 0 offset.\n  Thanks to @ngavrysh for the fix in Tubular/aiokafka fork. (issue #184)\n* Fixed how Producer handles retries on Leader node failure. It just did not\n  work before... Thanks to @blugowski for the help in locating the problem.\n  (issue #176, issue #173)\n* Fixed degrade in v0.2.2 on Consumer with no group_id. (issue #166)\n\n\n0.2.2 (2017-04-17)\n==================\n\n* Reconnect after KafkaTimeoutException. (PR #149 by @Artimi)\n* Fixed compacted topic handling. It could skip messages if those were\n  compacted (issue #71)\n* Fixed old issue with new topics not adding to subscription on pattern\n  (issue #46)\n* Another fix for Consumer race condition on JoinGroup. This forces Leader to\n  wait for new metadata before assigning partitions. (issue #118)\n* Changed metadata listener in Coordinator to avoid 2 rejoins in a rare\n  condition (issue #108)\n* `getmany` will not return 0 results until we hit timeout. (issue #117)\n\nBig thanks to @Artimi for pointing out several of those issues.\n\n\n0.2.1 (2017-02-19)\n==================\n\n* Add a check to wait topic autocreation in Consumer, instead of raising\n  UnknownTopicOrPartitionError (PR #92 by fabregas)\n* Consumer now stops consumption after `consumer.stop()` call. Any new `get*` calls\n  will result in ConsumerStoppedError (PR #81)\n* Added `exclude_internal_topics` option for Consumer (PR #111)\n* Better support for pattern subscription when used with `group_id` (part of PR #111)\n* Fix for Consumer `subscribe` and JoinGroup race condition (issue #88). Coordinator will now notice subscription changes during rebalance and will join group again. (PR #106)\n* Changed logging messages according to KAFKA-3318. Now INFO level should be less messy and more informative. (PR #110)\n* Add support for connections_max_idle_ms config (PR #113)\n\n\n0.2.0 (2016-12-18)\n==================\n\n* Added SSL support. (PR #81 by Drizzt1991)\n* Fixed UnknownTopicOrPartitionError error on first message for autocreated topic (PR #96 by fabregas)\n* Fixed `next_record` recursion (PR #94 by fabregas)\n* Fixed Heartbeat fail if no consumers (PR #92 by fabregas)\n* Added docs addressing kafka-python and aiokafka differences (PR #70 by Drizzt1991)\n* Added `max_poll_records` option for Consumer (PR #72 by Drizzt1991)\n* Fix kafka-python typos in docs (PR #69 by jeffwidman)\n* Topics and partitions are now randomized on each Fetch request (PR #66 by Drizzt1991)\n\n\n0.1.4 (2016-11-07)\n==================\n\n* Bumped kafka-python version to 1.3.1 and Kafka to 0.10.1.0.\n* Fixed auto version detection, to correctly handle 0.10.0.0 version\n* Updated Fetch and Produce requests to use v2 with v0.10.0 message format on brokers.\n  This allows a ``timestamp`` to be associated with messages.\n* Changed lz4 compression framing, as it was changed due to KIP-57 in new message format.\n* Minor refactorings\n\nBig thanks to @fabregas for the hard work on this release (PR #60)\n\n\n0.1.3 (2016-10-18)\n==================\n\n* Fixed bug with infinite loop on heartbeats with autocommit=True. #44\n* Bumped kafka-python to version 1.1.1\n* Fixed docker test runner with multiple interfaces\n* Minor documentation fixes\n\n\n0.1.2 (2016-04-30)\n==================\n\n* Added Python3.5 usage example to docs\n* Don't raise retriable exceptions in 3.5's async for iterator\n* Fix Cancellation issue with producer's `send_and_wait` method\n\n\n0.1.1 (2016-04-15)\n==================\n\n* Fix packaging issues. Removed unneeded files from package.\n\n0.1.0 (2016-04-15)\n==================\n\nInitial release\n\nAdded full support for Kafka 9.0. Older Kafka versions are not tested.\n\n",
    "description_content_type": "",
    "docs_url": null,
    "download_url": "https://github.com/Arti0m/aiokafka",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "http://aiokafka.readthedocs.org",
    "keywords": "",
    "license": "Apache 2",
    "maintainer": "",
    "maintainer_email": "",
    "name": "aiokafka-commit",
    "package_url": "https://pypi.org/project/aiokafka-commit/",
    "platform": "POSIX",
    "project_url": "https://pypi.org/project/aiokafka-commit/",
    "project_urls": {
      "Download": "https://github.com/Arti0m/aiokafka",
      "Homepage": "http://aiokafka.readthedocs.org",
      "Source": "https://github.com/Arti0m/aiokafka"
    },
    "release_url": "https://pypi.org/project/aiokafka-commit/0.0.7/",
    "requires_dist": null,
    "requires_python": ">=3.7",
    "summary": "Kafka integration with asyncio.",
    "version": "0.0.7",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 15710769,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "54df9c1057ffe181bb020a73246497c54e4aab830f3d2be6f8bef5da1312d171",
          "md5": "f93a3aa1c8b343412d62ebcc529228d2",
          "sha256": "a673c03a902d1869e20e47f7e1140cb93280a3892d54d83c200dc1be08ef53c0"
        },
        "downloads": -1,
        "filename": "aiokafka-commit-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "f93a3aa1c8b343412d62ebcc529228d2",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.10",
        "size": 144653,
        "upload_time": "2022-11-08T15:18:12",
        "upload_time_iso_8601": "2022-11-08T15:18:12.506845Z",
        "url": "https://files.pythonhosted.org/packages/54/df/9c1057ffe181bb020a73246497c54e4aab830f3d2be6f8bef5da1312d171/aiokafka-commit-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "08208fcd56c7cb32c6c1688f25d8b6240fdc7c02b8c7fbb250e13c241ca269ea",
          "md5": "0ca163f8bf8e80c66d3e520d98572dc5",
          "sha256": "00ff0a4c29a939bdc33a91b4bbecccf809736fe283ed5f69ef450369c5858802"
        },
        "downloads": -1,
        "filename": "aiokafka-commit-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "0ca163f8bf8e80c66d3e520d98572dc5",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.10",
        "size": 144695,
        "upload_time": "2022-11-08T15:22:23",
        "upload_time_iso_8601": "2022-11-08T15:22:23.563997Z",
        "url": "https://files.pythonhosted.org/packages/08/20/8fcd56c7cb32c6c1688f25d8b6240fdc7c02b8c7fbb250e13c241ca269ea/aiokafka-commit-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "992651215f2c6f60067926473576f99b7aa2108beec9b0685e64042688eb3d0f",
          "md5": "55a5401be4c81bb759611ca418e3b245",
          "sha256": "80ab433197c8fd0c0294712ca9f6a76bfcce3f3e1f5409b85a7724f5b3988f15"
        },
        "downloads": -1,
        "filename": "aiokafka_commit-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "55a5401be4c81bb759611ca418e3b245",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.10",
        "size": 57319,
        "upload_time": "2022-11-08T15:40:03",
        "upload_time_iso_8601": "2022-11-08T15:40:03.970223Z",
        "url": "https://files.pythonhosted.org/packages/99/26/51215f2c6f60067926473576f99b7aa2108beec9b0685e64042688eb3d0f/aiokafka_commit-0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "db87130231720aa9ee0a781acb3a93fc2153c309217a1f9371e80c5a2ea34d3d",
          "md5": "0bbcb5d60c2cbc0dd460adfad4f5b086",
          "sha256": "2dbfcae635999a2d0f8ab52b97559c4743214a9cade456e43d3ccfd979f7904f"
        },
        "downloads": -1,
        "filename": "aiokafka_commit-0.0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "0bbcb5d60c2cbc0dd460adfad4f5b086",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 57310,
        "upload_time": "2022-11-09T11:04:56",
        "upload_time_iso_8601": "2022-11-09T11:04:56.530613Z",
        "url": "https://files.pythonhosted.org/packages/db/87/130231720aa9ee0a781acb3a93fc2153c309217a1f9371e80c5a2ea34d3d/aiokafka_commit-0.0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a6f22b677b8fdf5ce4ac8d994ac6221bbe5736983ef90f11ba0fca241dc2e655",
          "md5": "aa52494b63cb89e9a9d216cefaf2cc24",
          "sha256": "a4b3cf91996a07b43c2c763e3985c7a5056a83a45607e1f1560db09d93fefcc2"
        },
        "downloads": -1,
        "filename": "aiokafka-commit-0.0.6.tar.gz",
        "has_sig": false,
        "md5_digest": "aa52494b63cb89e9a9d216cefaf2cc24",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.10",
        "size": 144692,
        "upload_time": "2022-11-09T11:33:47",
        "upload_time_iso_8601": "2022-11-09T11:33:47.530336Z",
        "url": "https://files.pythonhosted.org/packages/a6/f2/2b677b8fdf5ce4ac8d994ac6221bbe5736983ef90f11ba0fca241dc2e655/aiokafka-commit-0.0.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c904a437ed8d0efcba103f68867b4a2f2c87b6fa38fa1fd472c62bf901610394",
          "md5": "07ee2f18d2b5e07619139d0cf3d4b3f3",
          "sha256": "48cc09a048aaf09ecc6a527e8461ee0ee6e0d957984d4faab49d9ce98601a237"
        },
        "downloads": -1,
        "filename": "aiokafka-commit-0.0.7.tar.gz",
        "has_sig": false,
        "md5_digest": "07ee2f18d2b5e07619139d0cf3d4b3f3",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 144689,
        "upload_time": "2022-11-09T11:39:30",
        "upload_time_iso_8601": "2022-11-09T11:39:30.168363Z",
        "url": "https://files.pythonhosted.org/packages/c9/04/a437ed8d0efcba103f68867b4a2f2c87b6fa38fa1fd472c62bf901610394/aiokafka-commit-0.0.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "c904a437ed8d0efcba103f68867b4a2f2c87b6fa38fa1fd472c62bf901610394",
        "md5": "07ee2f18d2b5e07619139d0cf3d4b3f3",
        "sha256": "48cc09a048aaf09ecc6a527e8461ee0ee6e0d957984d4faab49d9ce98601a237"
      },
      "downloads": -1,
      "filename": "aiokafka-commit-0.0.7.tar.gz",
      "has_sig": false,
      "md5_digest": "07ee2f18d2b5e07619139d0cf3d4b3f3",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 144689,
      "upload_time": "2022-11-09T11:39:30",
      "upload_time_iso_8601": "2022-11-09T11:39:30.168363Z",
      "url": "https://files.pythonhosted.org/packages/c9/04/a437ed8d0efcba103f68867b4a2f2c87b6fa38fa1fd472c62bf901610394/aiokafka-commit-0.0.7.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}