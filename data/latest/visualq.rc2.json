{
  "info": {
    "author": "TuringQ",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "Environment :: Web Environment",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Operating System :: Microsoft",
      "Operating System :: Unix",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "# DeepQuantum \r\n---\r\n\r\n## 编写目的\r\n本文档介绍了DeepQuantum量子计算软件库的使用方法，包括对量子计算的一般性知识进行介绍以及软件库的功能函数的介绍，指导用户自行搭建模拟的通用型量子逻辑门线路以及已定义的量子神经网络层。\r\n\r\n---\r\n## 运行环境\r\n| 硬件环境 |               |  软件环境  |                   |\r\n| :--: | :-----------: | :----: | :---------------: |\r\n|  名称  |      型号       |   名称   |        版本         |\r\n| CPU  | Intel/AMD/ARM |  操作系统  | Windows/Linux/MAC |\r\n|  内存  |      2GB      | 深度学习框架 |   Pytorch 1.10    |\r\n|  硬盘  |      8GB      |   语言   |   Python 3.6及以上   |\r\n\r\n***\r\n## 目录\r\n* [使用说明](#1)\r\n    - [依赖库安装](#1.1)\r\n    - [运行步骤](#1.2)\r\n* [子程序作用举例](#2)\r\n    - [Circuit类的作用](#2)\r\n    - [类外调用函数](#2.2)\r\n    - [基于DeepQuantum的量子线路](#2.3)\r\n* [量子神经网络](#3)\r\n    - [ QuConv](#3.1)\r\n    - [DeQuConv](#3.2)\r\n    - [QuPool](#3.3)\r\n    - [DeQuPool](#3.4)\r\n    - [QuLinear](#3.5)\r\n    - [QuAE](#3.6)\r\n    - [QuGRU](#3.7)\r\n    - [QuSAAE](#3.8)\r\n    - [QuML](#3.9)\r\n    - [QuAttention](#3.10)\r\n* [TorchScript IR](#4)\r\n    - [TorchScript简介](#4)\r\n    - [DeepQuantum](#4.2)\r\n* [组织交流方式](#5)\r\n* [贡献者](#6)\r\n* [鸣谢](#7)\r\n* [许可证](#8)\r\n* [To-List](#9)\r\n\r\n<span id=\"1\"></span>\r\n***\r\n## 使用说明\r\n\r\n<span id=\"1.1\"></span>\r\n### 依赖库安装\r\n* Pytorch 1.10版本以上\r\n* Numpy\r\n* Scipy\r\n* typing\r\n\r\n### 安装命令\r\n以deepquantum 0.0.2版本为例：\r\n`pip install deepquantum==0.02`\r\n上述的依赖包在安装DeepQuantum时，会附带安装，无须另外安装。\r\n\r\n<span id=\"1.2\"></span>\r\n### 运行步骤\r\n运行代码库代码后，首先可以实例化一个量子线路Circuit，参数为线路的比特数，随后可以选择添加门，例如添加一个rx旋转门，参数中第一位为目标\t比特位置，第二位为旋转角度；\r\n\r\n```python\r\ncir=Circuit(2)\r\ncir.rx(1,torch.tensor(0.2))\r\n```\r\n添加量子逻辑门完毕后，可以查看已经添加的门的酉矩阵；\r\n```python\r\ncir.U\r\ntensor([[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\r\n        [0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j],\r\n        [0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j],\r\n        [0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j]])\r\n```\r\n随后选择再添加一个受控非门，其控制比特位是0，受控比特位是1，再次打印已添加的门的酉矩阵；\r\n```python\r\ncir.cnot(0,1)\r\ncir.U\r\ntensor([[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\r\n        [0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j],\r\n        [0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j],\r\n        [0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j]])\r\n\r\n```\r\n最后，可以通过get()函数得到整个量子线路上所有逻辑门的整体酉矩阵。\r\n```python\r\ncir.get()\r\ntensor([[0.9950+0.0000j, 0.0000-0.0998j, 0.0000+0.0000j, 0.0000+0.0000j],\r\n        [0.0000-0.0998j, 0.9950+0.0000j, 0.0000+0.0000j, 0.0000+0.0000j],\r\n        [0.0000+0.0000j, 0.0000+0.0000j, 0.0000-0.0998j, 0.9950+0.0000j],\r\n        [0.0000+0.0000j, 0.0000+0.0000j, 0.9950+0.0000j, 0.0000-0.0998j]])\r\n```\r\n\r\n<span id=\"2\"></span>\r\n***\r\n## 子程序作用举例\r\n### Circuit类的作用\t\r\nCircuit类定义了量子线路包含的信息，通过实例化Circuit类可以模拟搭建量子线路。Circuit类的初始化函数中包含三个空列表，分别用于保存放置门的资源信息、放置门的酉矩阵以及用于测量的酉矩阵，还提供一个初始化的|00...0>态。\r\n```python\r\nclass Circuit(object):\r\n    def __init__(self, n:int):\r\n        self.n_qubits = n  # 总QuBit的个数\r\n        self.U = torch.eye(int(2**self.n_qubits)) + 0j\r\n        self.u = []    # 顺序保存酉矩阵\r\n\r\n        #线路的初始态，默认全为|0>态\r\n        self.state_init = torch.zeros(int(2**self.n_qubits))\r\n        self.state_init[0] = 1\r\n        self.state_init = self.state_init + 0j\r\n```\r\nCircuit的函数包括rx、rxx、x_gate、cnot等添加门的函数，\r\n```python\r\n    def cnot(self, control_qubit: int, target_qubit: int):\r\n        assert isinstance(target_qubit, int), \\\r\n            \"target qubit is not integer\"\r\n        assert isinstance(control_qubit, int), \\\r\n            \"control qubit is not integer\"\r\n        assert control_qubit <= self.n_qubits\r\n        assert 0 <= target_qubit < self.n_qubits, \\\r\n            \"target qubit is not available\"\r\n        self._add_u(two_qubit_control_gate(x_gate(), self.n_qubits, control_qubit, target_qubit))\r\n\r\n    def x_gate(self, target_qubit:int):\r\n        assert isinstance(target_qubit, int), \\\r\n            \"target qubit is not integer\"\r\n        assert 0 <= target_qubit < self.n_qubits, \\\r\n            \"target qubit is not available\"\r\n        self._add_u(gate_expand_1toN(x_gate(), self.n_qubits, target_qubit))\r\n```\r\n还包括用于计算整体线路酉矩阵的get函数，\r\n```python\r\n    def get(self):\r\n        self.U = gate_sequence_product(self.u, self.n_qubits)\r\n        return self.U\r\n```\r\n以及重置线路的clear函数。\r\n```python\r\n    def clear(self):\r\n        # 清空\r\n        self.u = []\r\n        self.U = torch.eye(int(2**self.n_qubits)) + 0j\r\n```\r\n\r\n<span id=\"2.2\"></span>\r\n### 类外调用函数\r\n|           函数名称            |                    功能                    |\r\n| :-----------------------: | :--------------------------------------: |\r\n|       multi_kron 函数       | 此函数用于对多个酉矩阵进行求克罗内克积的操作。数学上，克罗内克积是两个任意大小的矩阵间的运算。克罗内克积是张量积的特殊形式 |\r\n|        rx、ry、rz函数         | 此类函数用于初始化一个单比特的旋转门酉矩阵。配和gate_expand_1toN函数，可以将单比特酉矩阵扩张成在整个线路上的酉矩阵 |\r\n|          cont函数           | 此函数用于初始化一个两比特的受控非门。配和two_qubit_control_gate函数，可以将两比特酉矩阵扩张成在整个线路上的酉矩阵 |\r\n|  x_gate、y_gate、z_gate函数   |             此类函数用于初始化一个泡利矩阵              |\r\n|     gate_expand_1toN      |        此函数用于将一个单比特门的酉矩阵扩张成n比特酉矩阵         |\r\n| two_qubit_control_gate函数  |        此函数用于将两比特受控门的酉矩阵扩张成n比特酉矩阵         |\r\n| two_qubit_rotation_gate函数 |        此函数用于将两比特旋转门的酉矩阵扩张成n比特酉矩阵         |\r\n|   multi_control_gate 函数   |        此函数用于将多比特控制门的酉矩阵扩张成n比特酉矩阵         |\r\n| gate_sequence_product 函数  |   此函数被Circuit类内部get函数调用，用于计算整个线路的整体酉矩阵   |\r\n|           dag函数           |            此函数用于求某个酉矩阵的共轭转置矩阵            |\r\n|         ptrace 函数         | 此函数用于对某个密度矩阵做偏迹测量，定义与克罗内克积运算相反的运算叫做偏迹运算  |\r\n|         measure函数         | 此函数使用泡利z矩阵作为测量算子，对某个密度矩阵测量求期望，获得n比特个测量结果 |\r\n|            I函数            |               此函数用于生成单位矩阵                |\r\n|        Hadamard函数         |             此函数用于生成一个单比特哈达玛门             |\r\n|        encoding函数         |               此函数用于编码密度矩阵                |\r\n|        IsUnitary函数        |             此函数用于判断矩阵是否为酉矩阵              |\r\n|      IsNormalized函数       |             此函数用于判断一个矢量是否归一              |\r\n|       IsHermitian函数       |             此函数用于判断矩阵是否是厄密矩阵             |\r\n|      get_fidelity函数       |                此函数用于保真度计算                |\r\n|   get_trace_distance函数    |                此函数用于计算迹距离                |\r\n\r\n<span id=\"2.3\"></span>\r\n### 基于DeepQuantum的量子线路\r\n量子线路是由量子线互连的量子门的集合。在基于DeepQuantum的量子计算中，线路的实际结构、门的数量和类型以及互连方案由所要执行的幺正变换U决定。\r\n\r\n#### 酉矩阵维度\r\n以3比特线路为例：\r\n1. 量子比特是二维复向量空间中的向量\r\n2. 若考虑一个由n个量子比特组成的系统，则其空间是一个$2^n$维的希伯特复空间，即$2^3=8$\r\n\r\n##### 酉矩阵\r\n1. 量子比特的演化是线性的，所以量子门可以用矩阵进行表示（酉矩阵）\r\n2. 量子门矩阵的条件：经过量子门作用后得到的状态也要满足基态系数平方和为1\r\n3. 单量子比特门的相应矩阵U（酉矩阵）要满足的条件是“酉性”，即 $U^\\dagger U=I$, 其中$U^\\dagger$是U的共轭转置，I是单位矩阵。\r\n  酉性限制是对量子门的唯一限制，每个酉矩阵都定义一个有效的量子门\r\n\r\n#### 纠缠态\r\n对于一个量子系统，处于纠缠状态的子系统之间会相互影响，对一个子系统的测量行为会改变另外一个子系统的状态\r\n\r\n#### CNOT门（受控非门）\r\n将控制量子比特和目标量子比特作异或运算，并将结果储存在目标量子比特中\r\n\r\n#### Toffoli门\r\n1. Toffoli接受三个比特作为输入，其中两个控制比特（不受门的影响），一个目标比特；当两个控制比特都为1时，对目标比特进行翻转，否则目标比特保持不变。\r\n2. 若连续进行两次Toffoli门操作，结果不发生变化，因此Toffoli门是可逆门，逆是它本身\r\n\r\n#### 泡利X门\r\n单比特量子门，相当于逻辑门中的非门，量子非门的作用是线性的。\r\n$$\r\nX=\\begin{bmatrix}\r\n   0 & 1 \\\\\r\n   1 & 0\r\n\\end{bmatrix}\r\n$$\r\n$$\\alpha \\lvert{0}\\rangle+\\beta \\lvert{1}\\rangle \\xrightarrow{X} \\alpha \\lvert{1}\\rangle+\\beta \\lvert{0}\\rangle​$$\r\n\r\n#### 泡利Y门\r\n单比特量子门\r\n\r\n\r\n$$\r\nY=\\begin{bmatrix}\r\n   0 & -i \\\\\r\n   i & 0\r\n\\end{bmatrix}\r\n$$\r\n\r\n\r\n#### 泡利Z门\r\n单比特量子门，它保持$\\lvert{0}\\rangle$不变，翻转$\\lvert{1}\\rangle$的符号变为$-\\lvert{1}\\rangle$\r\n\r\n$$\r\nZ=\\begin{bmatrix}\r\n   1 & 0 \\\\\r\n   0 & -1\r\n\\end{bmatrix}\r\n$$\r\n\r\n$$\\alpha \\lvert{0}\\rangle+\\beta \\lvert{1}\\rangle \\xrightarrow{Z} \\alpha \\lvert{0}\\rangle-\\beta \\lvert{1}\\rangle$$\r\n\r\n\r\n#### 交换门\r\n$$\r\nSWAP=\\begin{bmatrix}\r\n   1 & 0 & 0 & 0 \\\\\r\n   0 & 0 & 1 & 0 \\\\\r\n   0 & 1 & 0 & 0 \\\\\r\n   0 & 0 & 0 & 1 \\\\\r\n\\end{bmatrix}\r\n$$\r\n\r\n\r\n\r\n#### 哈达玛门\r\n$$\r\nH=\\frac{1}{\\sqrt{2}}\\begin{bmatrix}\r\n   1 & 1 \\\\\r\n   1 & -1\r\n\\end{bmatrix}\r\n$$\r\n\r\n\r\n哈达玛门可以将$\\lvert{0}\\rangle$变为$(\\lvert{0}\\rangle+\\lvert{1}\\rangle)/\\sqrt{2}$，把$\\lvert{1}\\rangle$变到同样的$(\\lvert{0}\\rangle-\\lvert{1}\\rangle)/\\sqrt{2}$（连续两次应用哈达玛门等于什么也没做）\r\n\r\n#### 张量积\r\n\r\n$$\r\n\\begin{bmatrix}\r\n\r\n\r\n1 & 0 \\\\\r\n0 & 1 \\\\\r\n\r\n\r\n\\end{bmatrix} \r\n\r\n\r\n\\bigotimes \r\n\r\n\r\n  \\begin{bmatrix} \r\n\r\n\r\n2 & 3 \\\\ \r\n4 & 5 \\\\ \r\n\r\n\r\n\\end{bmatrix} = \\begin{bmatrix}\r\n   1\\times2 & 1\\times3 & 0\\times2 & 0\\times3 \\\\\r\n   1\\times4 & 1\\times5 & 0\\times4 & 0\\times5 \\\\\r\n   0\\times2 & 0\\times3 & 1\\times2 & 1\\times3 \\\\\r\n   0\\times4 & 0\\times5 & 1\\times4 & 1\\times5 \\\\\r\n\\end{bmatrix}\r\n$$\r\n\r\n\r\n##### 示例\r\n```python\r\nfrom deepquantum.utils import multi_kron\r\n\r\na = torch.tensor([[1, 0], [0, 1]])\r\nb = torch.tensor([[1, 0], [0, 1]])\r\n\r\nresult = multi_kron([a, b])\r\n```\r\n\r\n#### 共轭转置矩阵\r\n- 共轭复数：实部相同，虚部互为相反数的复数互为共轭复数\r\n- 共轭转置：先进行共轭操作，然后对矩阵进行转置\r\n##### 示例\r\n```python\r\nfrom deepquantum.utils import dag\r\n\r\na = torch.randint(0,4,(2,2)) + 0j\r\na_dag = dag(a)\r\n```\r\n\r\n#### 密度矩阵\r\n当量子系统处于纯态时，系统的状态通常用波函数或态矢量表示；当系统处于混合态时，系统的状态用密度矩阵表示。\r\n##### 密度矩阵计算\r\n1. 纯态：$\\rho = \\lvert{\\psi}\\rangle\\langle{\\psi}\\lvert$\r\n2. 混态：$\\rho_{mix} = \\sum_{i} p_{i} \\lvert{\\psi}\\rangle\\langle{\\psi}\\lvert$\r\n##### 示例\r\n```python\r\nfrom deepquantum.utils import encoding\r\n\r\na = torch.randint(0,4,(2,2))\r\na_enc = encoding(a)\r\n```\r\n\r\n\r\n#### 偏迹\r\n对于一个包含多个子系统的量子系统，应用偏迹运算可以求解不同子系统的约化密度矩阵\r\n##### 示例\r\n```python\r\nimport torch\r\nfrom deepquantum.utils import ptrace, encoding\r\n    \r\na = torch.ones(8,8)\r\na_enc = encoding(a)\r\n\r\na_ptr = ptrace(a_enc,1,2)\r\n```\r\n\r\n#### 测量\r\n使用DeepQuantum中的measure()函数对某个子系统进行测量求期望\r\n##### 示例\r\n```python\r\nfrom deepquantum.utils import expecval_ZI, measure, encoding\r\n\r\na = torch.rand(8,8)   # 3个量子比特\r\na_enc = encoding(a)   # 计算密度矩阵\r\na_exp = expecval_ZI(a_enc, 3, 0)\r\na_measure = measure(a_enc, 3)\r\n```\r\n\r\n#### 保真度\r\n表示信息在传输和处理过程中保持原来状态的程度，这里用来衡量输入输出量子态之间的相似程度。\r\n##### 示例\r\n```python\r\nfrom deepquantum.utils import get_fidelity,encoding\r\n\r\na = torch.rand(8,8)\r\nb = torch.rand(8,8)\r\na = encoding(a)\r\nb = encoding(b)\r\n\r\nfidelity = get_fidelity(a,b)\r\n```\r\n\r\n<span id=\"3\"></span>\r\n***\r\n## 量子神经网络\r\n\r\n<span id=\"3.1\"></span>\r\n### QuConv\r\nDeepQuantum为方便用户使用提供了量子卷积核，量子卷积之后可以是量子层或经典层。与经典卷积的主要区别在于，量子电路可以生成高度复杂的内核，其计算至少在原则上是经典上难以处理的。\r\n\r\n#### QuConv提供的接口\r\n* QuConvXYZ：在量子线路上放置了单比特泡利旋转门以及双比特旋转门，如$R_x(\\theta_1)$、$R_y(\\theta_3)$、$R_z(\\theta_5)$以及$R_{xx}(\\theta_6)$等，该量子卷积核有14个参数\r\n* QuConvSXZ：组成和QuConvXYZ相同，但是所包含的参数较少，线路较简单\r\n\r\n#### QuConv使用方法\r\n以QuConvXYZ为例，首先输入一个数据实例化量子卷积核，这里注意实例化数据必须为2的倍数\r\n```python\r\nQuConv=QuConvXYZ(4)  #定义了4比特量子线路\r\n```\r\n接下来将输入数据编码成量子态，并输入到定义的卷积核中\r\n```python\r\nX=torch.rand(16,16)  #随机生成一个符合输入维度的矩阵\r\nX=encoding(X)      #将经典数据编码成量子态密度矩阵\r\n\r\nout=QuConv(X)\r\n```\r\nQuConvSXZ的使用方法与QuConvXYZ方法类似\r\n\r\n#### 示例\r\n```python\r\nimport torch\r\nimport torch.nn as nn\r\nimport deepquantum.nn as Qnn\r\nfrom deepquantum.utils import encoding\r\n\r\nclass My_QuConv(nn.Module):\r\n    def __init__(self,n_qubits):\r\n        super(My_QuConv, self).__init__()\r\n        self.n_qubits = n_qubits\r\n        self.linear = nn.Linear(250,2**self.n_qubits)\r\n        self.QuConvX = Qnn.QuConvXYZ(self.n_qubits)\r\n        self.QuConvS = Qnn.QuConvSXZ(self.n_qubits)\r\n        \r\n    def forward(self,x):\r\n        x = self.linear(x)\r\n        x = Gram(x)      #将向量x输入到Gram函数中编码为对应的量子态密度矩阵\r\n        x = self.QuConvX(x)\r\n        out = self.QuConvS(x)\r\n        return out\r\n    \r\n#初始化模型时输入需要是2的倍数    \r\nmodule = My_QuConv(4)\r\nx = torch.rand(1,250)\r\nresult = module(x)\r\n```\r\n\r\n<span id=\"3.2\"></span>\r\n### DeQuConv\r\nDeepQuantum提供了DeQuConv是上述QuConv的$U^\\dagger$，在量子计算过程中相当于数据在QuConv的量子线路中逆演化。\r\n\r\n#### DeQuConv提供的接口\r\n* DeQuConvXYZ：在量子线路上放置了单比特泡利旋转门以及双比特旋转门同QuConv，然后使用dag()操作得到$U$的共轭转置矩阵$U^\\dagger$\r\n* DeQuConvSXZ：与上述类似\r\n\r\n#### DeQuConv使用方法\r\nDeQuConv使用方法与QuConv相同，请参照QuConv的使用方法。\r\n\r\n#### 示例\r\n```python\r\nimport torch\r\nimport torch.nn as nn\r\nimport deepquantum.nn as Qnn\r\nfrom deepquantum.utils import Gram\r\n\r\nclass My_DeQuConv(nn.Module):\r\n    def __init__(self,n_qubits):\r\n        super(My_DeQuConv, self).__init__()\r\n        self.n_qubits = n_qubits\r\n        self.linear = nn.Linear(250,2**self.n_qubits)\r\n        self.DeQuConvX = Qnn.DeQuConvXYZ(self.n_qubits)\r\n        \r\n    def forward(self,x):\r\n        x = self.linear(x)\r\n        x = Gram(x)\r\n        out = self.DeQuConvX(x)\r\n        return out\r\n\r\nmodule = My_DeQuConv(4)\r\nx = torch.rand(1,250)\r\nresult = module(x)\r\n```\r\n\r\n<span id=\"3.3\"></span>\r\n### QuPool\r\nDeepQuantum提供了量子池化核方便用户直接使用，引入受控门将相邻线路的量子态纠缠起来，模拟经典池化提取数据更深层次特征的作用。\r\n\r\n#### QuPool提供的接口\r\n* QuPoolXYZ：在量子线路上放置了单比特泡利旋转门以及受控门cnot()，其中单比特泡利旋转门如$R_x(\\theta_1)$、$R_y(\\theta_3)$、$R_z(\\theta_5)$\r\n* QuPoolSX：只包含了单比特x泡利旋转门和受控门cnot()\r\n\r\n#### QuPool使用方法\r\n以QuPoolXYZ为例，首先输入一个数据实例化量子池化核，这里注意示例化时的数必须为2的倍数\r\n```python\r\nQuPool=QuPoolXYZ(4)  #定义了4比特量子线路\r\n```\r\n接下来将输入数据编码成量子态，并输入到定义的卷积核中\r\n```python\r\nX=torch.rand(16,16)  #随机生成一个符合输入维度的矩阵\r\nX=encoding(X)      #将经典数据编码成量子态密度矩阵\r\n\r\nout=QuPool(X)\r\n```\r\nQuPoolSX的使用方法与QuPoolXYZ方法类似\r\n\r\n#### 示例\r\n```python\r\nimport torch\r\nimport torch.nn as nn\r\nimport deepquantum.nn as Qnn\r\nfrom deepquantum.utils import Gram\r\n\r\nclass My_QuPool(nn.Module):\r\n    def __init__(self,n_qubits):\r\n        super(My_QuPool, self).__init__()\r\n        self.n_qubits = n_qubits\r\n        self.linear = nn.Linear(250,2**self.n_qubits)\r\n        self.QuConvX = Qnn.QuConvXYZ(self.n_qubits)\r\n        self.QuPoolX = Qnn.QuPoolXYZ(self.n_qubits)\r\n        self.QuPoolS = Qnn.QuPoolSX(self.n_qubits)\r\n        \r\n    def forward(self,x):\r\n        x = self.linear(x)\r\n        x = Gram(x)\r\n        x = self.QuConvX(x)\r\n        x = self.QuPoolX(x)\r\n        out = self.QuPoolS(x)\r\n        return out\r\n\r\nmodule = My_QuPool(4)\r\nx = torch.rand(1,250)\r\nresult = module(x)\r\n```\r\n\r\n<span id=\"3.4\"></span>\r\n### DeQuPool\r\n同理DeQuPool是上述QuPool量子线路$U$酉矩阵矩阵的$U^\\dagger$。\r\n\r\n#### DeQuPool提供的接口\r\n* DeQuPoolXYZ：在量子线路上放置了单比特泡利旋转门以及受控门同QuPool，然后使用dag()得到$U$酉矩阵的$U^\\dagger$\r\n* DeQuPoolSX：与上述类似\r\n\r\n#### DeQuPool使用方法\r\nDeQuPool使用方法与QuPool相同，请参照QuPool的使用方法。\r\n\r\n#### 示例\r\n```python\r\nimport torch\r\nimport torch.nn as nn\r\nimport deepquantum.nn as Qnn\r\nfrom deepquantum.utils import Gram\r\n\r\nclass My_DeQuPool(nn.Module):\r\n    def __init__(self,n_qubits):\r\n        super(My_DeQuPool, self).__init__()\r\n        self.n_qubits = n_qubits\r\n        self.linear = nn.Linear(250,2**self.n_qubits)\r\n        self.QuConvX = Qnn.QuConvXYZ(self.n_qubits)\r\n        self.QuPoolX = Qnn.QuPoolXYZ(self.n_qubits)\r\n        self.DeQuPoolX = Qnn.DeQuPoolXYZ(self.n_qubits)\r\n        self.DeQuPoolS = Qnn.DeQuPoolSX(self.n_qubits)\r\n        \r\n    def forward(self,x):\r\n        x = self.linear(x)\r\n        x = Gram(x)\r\n        x = self.QuConvX(x)\r\n        x = self.QuPoolX(x)\r\n        x = self.DeQuPoolX(x)\r\n        out = self.DeQuPoolS(x)\r\n        return out\r\n    \r\nmodule = My_DeQuPool(4)\r\nx = torch.rand(1,250)\r\nresult = module(x)\r\n```\r\n\r\n<span id=\"3.5\"></span>\r\n### QuLinear\r\nDeepQuantum中的QuLinear是量子神经网络中被用来替代PyTorch中的nn.Linear,增强量子神经网络的表达能力的。\r\n\r\n#### QuLinear提供的接口\r\n* QuLinear:先定义量子线形成的输入和输出维度，然后将数据输入到QuLinear中得到输出结果\r\n\r\n#### QuLinear使用方法\r\n首先定义输入特征和输出特征维度，这里需要注意输出维度out_features需要满足$2^1\\leq2^i\\leq2^{in-features}$\r\n```python\r\nQL=QuLinear(6,32)  #定义了输入和输出特征\r\n```\r\n接下来生成输入数据，用户这里应该使用自己的数据，上一步的定义也需要根据需要自行定义\r\n```python\r\nX=torch.rand(64,1)  #随机生成一个符合输入维度的矩阵\r\n\r\nout=QL(X)\r\nprint('结果：',out)\r\n\r\n#输出结果\r\n结果： tensor([[0.0834, 0.0257, 0.0419, 0.0088, 0.0652, 0.0187, 0.0434, 0.0105, 0.1252,\r\n         0.0317, 0.0511, 0.0113, 0.0973, 0.0239, 0.0466, 0.0113, 0.0141, 0.0157,\r\n         0.0067, 0.0228, 0.0223, 0.0134, 0.0236, 0.0210, 0.0284, 0.0137, 0.0218,\r\n         0.0143, 0.0145, 0.0254, 0.0122, 0.0339]],\r\n       grad_fn=<UnsqueezeBackward0>)\r\n```\r\n这里输入的数据X是用户需要做线性激活的经典数据，输入QuLinear后会自动将其编码为量子态，经过演化后对其进行测量并输出结果\r\n\r\n#### 示例\r\n```python\r\nimport torch\r\nimport torch.nn as nn\r\nimport deepquantum.nn as Qnn\r\n\r\nclass My_QuLinear(nn.Module):\r\n    def __init__(self,n_qubits,out_qubits):\r\n        super(My_QuLinear, self).__init__()\r\n        self.n_qubits = n_qubits\r\n        self.out_features = 2**out_qubits\r\n        self.linear = nn.Linear(250,self.n_qubits)\r\n        self.Qulinear = Qnn.QuLinear(self.n_qubits,self.out_features)\r\n        \r\n    def forward(self,x):\r\n        x = self.linear(x)\r\n        out = self.Qulinear(x)\r\n        return out\r\n    \r\nmodule = My_QuLinear(6,5)\r\nx=torch.rand(1,250)\r\nresult = module(x)\r\nprint('结果：',result)\r\n\r\n#结果如下\r\n结果： tensor([[0.0298, 0.0751, 0.0795, 0.0231, 0.0986, 0.0326, 0.0480, 0.0834, 0.0207,\r\n         0.0434, 0.0542, 0.0129, 0.0597, 0.0230, 0.0282, 0.0551, 0.0113, 0.0191,\r\n         0.0258, 0.0065, 0.0273, 0.0128, 0.0130, 0.0264, 0.0053, 0.0163, 0.0125,\r\n         0.0058, 0.0198, 0.0059, 0.0105, 0.0143]],\r\n       grad_fn=<UnsqueezeBackward0>)\r\n```\r\n\r\n<span id=\"3.6\"></span>\r\n### QuAE\r\n量子自编码网络来压缩和重构输入量子态，为此需要用量子线路实现编码器encoder网络和解码器decode网络。DeepQuantumy提供已定义好的AE网络只需将数据输入即可重构出量子态。\r\n\r\n#### QuAE 提供的接口\r\n* Qu_AEnet：实例化量子神经网络层后，输入压缩数据X,单位矩阵I，编码后保留的比特数N和丢弃的比特数N_Trash\r\n\r\n#### QuAE使用方法\r\n首先实例化量子自编码网络的比特数\r\n```python\r\nQuAE=Qu_AEnet(8) #实例化一个8比特的量子自编码网络\r\n```\r\n这里对应的输入数据应为$2^8\\times2^8$的数据，假如保留7比特的数据那么单位矩阵为$2^{8-7}\\times2^{8-7}$\r\n```python\r\nx=torch.rand(256,256)  #随机生成一个符合输入维度的矩阵\r\nX=encoding(x)       #将经典数据编码为量子态密度矩阵\r\nI=torch.eye(2)      #生成符合要求的单位矩阵I\r\n```\r\n将数据输入到量子自编码网络中\r\n```python\r\nout=QuAE(X,I,7,1)\r\nprint('结果',out)\r\n\r\n#输出结果\r\n结果 tensor([[ 1.4972e-01+1.4203e-08j,  2.3368e-03+6.4389e-02j,\r\n         -6.2205e-02+1.0121e-02j,  ...,\r\n          1.7100e-03+1.3212e-03j, -1.2927e-03+2.9093e-03j,\r\n          3.4853e-04+3.0846e-03j],\r\n        [ 2.3368e-03-6.4389e-02j,  1.2847e-01+6.9849e-09j,\r\n         -7.1227e-02+1.1383e-02j,  ...,\r\n          2.5565e-03-3.5899e-03j, -2.1651e-03+2.4778e-03j,\r\n         -1.0873e-03-2.9004e-03j],\r\n        [-6.2205e-02-1.0121e-02j, -7.1227e-02-1.1383e-02j,\r\n          1.3469e-01-6.2864e-09j,  ...,\r\n         -1.5109e-03+1.5907e-03j,  1.0315e-03-2.6573e-03j,\r\n          2.4558e-03+1.2072e-04j],\r\n        ...,\r\n        [ 1.7100e-03-1.3212e-03j,  2.5565e-03+3.5899e-03j,\r\n         -1.5109e-03-1.5907e-03j,  ...,\r\n          1.6151e-04+5.8208e-10j, -1.2107e-04-1.3201e-05j,\r\n          9.0529e-05-6.1642e-05j],\r\n        [-1.2927e-03-2.9093e-03j, -2.1651e-03-2.4778e-03j,\r\n          1.0315e-03+2.6573e-03j,  ...,\r\n         -1.2107e-04+1.3195e-05j,  3.0566e-04+9.3714e-09j,\r\n          8.7468e-05+7.1358e-05j],\r\n        [ 3.4853e-04-3.0846e-03j, -1.0873e-03+2.9004e-03j,\r\n          2.4558e-03-1.2071e-04j,  ...,\r\n          9.0531e-05+6.1647e-05j,  8.7472e-05-7.1363e-05j,\r\n          3.6828e-04+3.1723e-09j]], grad_fn=<MmBackward0>)\r\n```\r\n用户可以参照以上方法，根据自己的数据定义量子线路数量以及保留比特数N等\r\n\r\n#### 示例\r\n```python\r\nimport torch\r\nimport torch.nn as nn\r\nimport deepquantum.nn as Qnn\r\nfrom deepquantum.utils import Gram\r\n\r\nclass My_QuAE(nn.Module):\r\n    def __init__(self,n_qubits,n_retain):\r\n        super(My_QuAE, self).__init__()\r\n        self.n_qubits = n_qubits\r\n        self.n_retain = n_retain\r\n        self.n_trash = self.n_qubits-self.n_retain\r\n        self.QuAE = Qnn.Qu_AEnet(self.n_qubits)\r\n        self.I = torch.eye(2**self.n_trash)\r\n        \r\n    def forward(self,x):\r\n        x = Gram(x)\r\n        out = self.QuAE(x, self.I, self.n_retain, self.n_trash)\r\n        return out\r\n \r\nmodule = My_QuAE(8,7)\r\nx = torch.rand(1,256)\r\nresult = module(x)\r\n\r\n```\r\n注意初始化时需要满足$0\\leq{n retain}\\leq{n qubits}$\r\n\r\n<span id=\"3.7\"></span>\r\n### QuGRU\r\nGRU(Gate Recurrent Unit)是循环神经网络的一种，是为了解决长期记忆和反向传播中的梯度等问题而提出来的。QuGRU原理在经典GRU上做了逻辑上的映射。\r\n\r\n#### QuGRU提供的接口\r\n* QuGRU：实例化的时候需要输入三个数，分别是输入维度、隐藏维度和输出维度，然后将数据x输入模型，得到QuGRU计算后结果\r\n\r\n#### QuGRU使用方法\r\n首先定义输入维度、隐藏维度和输出维度，这里需要注意隐藏维度$2^1\\leq2^i\\leq2^{input-dim}$\r\n```python\r\nQG=QuGRU(3,8,3)  #定义了输入、隐藏以及输出维度\r\n```\r\n接下来生成输入数据，用户这里应该使用自己的数据，上一步的定义也需要根据需要自行定义。注意这里张量输入维度为(batch_size, seq_length, input_dim)\r\n```python\r\nX=torch.rand(1,8,3)  #随机生成一个符合输入维度的矩阵\r\n\r\nout=QG(X)\r\nprint('结果',out)\r\n\r\n#输出结果\r\n结果 tensor([[-0.0015, -0.0575,  0.1222]], grad_fn=<AddmmBackward0>)\r\n```\r\n这里输入数据x是用户需要输入QuGRU的经典数据，输入QuGRU后会自动将其编码为量子态数据经过演化后输入符合要求的结果\r\n\r\n#### 示例\r\n```python\r\nimport torch\r\nimport torch.nn as nn\r\nimport deepquantum.nn as Qnn\r\n\r\nclass My_QuGRU(nn.Module):\r\n    def __init__(self,input_dim, hidden_dim, Quoutput_dim):\r\n        super(My_QuGRU, self).__init__()\r\n        self.n_qubits = input_dim\r\n        self.hidden_dim = hidden_dim\r\n        self.output_dim = Quoutput_dim\r\n        self.QuGRU = Qnn.QuGRU(self.n_qubits,self.hidden_dim, self.output_dim)\r\n        self.linear = nn.Linear(self.output_dim,4)\r\n        \r\n    def forward(self,x):\r\n        x = self.QuGRU(x)\r\n        out = self.linear(x)\r\n        return out\r\n    \r\nmodule = My_QuGRU(3,8,3)\r\nx=torch.rand(1,8,3)\r\nresult = module(x)\r\nprint('结果：',result)\r\n\r\n#输出结果\r\n结果： tensor([[-0.0485,  0.3078,  0.5784, -0.1791]], grad_fn=<AddmmBackward0>)\r\n```\r\n\r\n<span id=\"3.8\"></span>\r\n### QuSAAE\r\n在量子对抗自编码网络中，编码器对输入数据X进行压缩，主要保留与标签数据Y无关的数据$Z_x$。解码器输入$Z_x$和Y的混合数据，重构输入数据$R_x$。判别器输入$Z_x$及其正态分布数据用于后续的训练和优化。\r\n\r\n#### QuSAAE 算法逻辑图\r\n\r\n<img src=\"./deepquantum/pictures/SAAE.png\" style=\"zoom:45%\">\r\n\r\n#### QuSAAE提供接口\r\n* Q_Encoder：先实例化量子编码器后，输入数据和保留比特数\r\n\r\n* Q_Decoder：先实例化后，输入$Z_x$和Y\r\n\r\n* Q_Discriminator：根据$Z_x$实例化，然后输入判别数据\r\n\r\n#### QuSAAE使用方法\r\n调用DeepQuantum 0.0.2版本及以上中的量子编码器\r\n```python\r\nQE=Q_Encoder(6)    #实例化一个6比特的量子编码器\r\n```\r\n这里使用6比特实例化量子编码器，对应的输入数据X的维度应为$2^6\\times2^6$\r\n```python\r\nX=torch.rand(64,64) #随机生成一个符合输入维度的矩阵\r\nX=encoding(X)      #将经典数据编码成量子态密度矩阵\r\nZx=QE(X,4)        #输入量子判别器中并输入保留的比特数\r\n\r\n```\r\n将数据X输入到实例化的量子编码器中，并编码压缩得到$Z_x$维度为$2^4\\times2^4$,解码器和判别器的使用方法类似，均可根据输入数据维度对量子编码器，量子解码器、量子判别器的线路数进行定义。\r\n```python\r\nY=torch.rand(64,64) #随机生成一个标签数据\r\nY=encoding(Y)     #将经典数据编码成量子态密度矩阵\r\nQD=Q_Decoder(10)   #实例化一个10比特的量子解码器\r\nRx=QD(Zx,Y,6)     #将编码得到的Zx和Y输入，解码重建得到2^6*2^6的Rx\r\nQDis=Q_Discriminator(4) #根据Zx定义量子判别器\r\nQDisS=QDis(Zx)  #量子判别器示例输入\r\n```\r\n\r\n#### 示例\r\n```python\r\nimport torch\r\nimport torch.nn as nn\r\nimport deepquantum.nn as Qnn\r\nfrom deepquantum.utils import Gram\r\n\r\nclass My_QuSAAE(nn.Module):\r\n    def __init__(self,n_qubits, n_retain, ):\r\n        super(My_QuSAAE, self).__init__()\r\n        self.n_qubits = n_qubits\r\n        self.n_retain = n_retain\r\n        self.linearE = nn.Linear(250, 2**self.n_qubits)\r\n        self.QuEncoder = Qnn.Q_Encoder(self.n_qubits)\r\n        self.linearD = nn.Linear(33,2**self.n_qubits)\r\n        self.QuDecoder = Qnn.Q_Decoder(self.n_qubits+self.n_retain)\r\n        self.QuDiscriminator = Qnn.Q_Discriminator(self.n_retain)\r\n        \r\n    def forward(self, x, y):\r\n        x = self.linearE(x)\r\n        x = Gram(x)\r\n        x = self.QuEncoder(x, self.n_retain)\r\n        y = self.linearD(y)\r\n        y = Gram(y)\r\n        rx = self.QuDecoder(x,y,self.n_qubits)\r\n        out = self.QuDiscriminator(x)\r\n        return rx,out\r\n    \r\nmodule = My_QuSAAE(6,4)\r\nx = torch.rand(1,250)\r\ny = torch.rand(1,33)\r\nRx,result = module(x, y)\r\nprint('重建数据',Rx)\r\nprint('量子判别器结果：',result)\r\n\r\n#输出结果\r\n重建数据 tensor([[ 0.0089+3.8299e-09j,  0.0014+4.3687e-03j,  0.0005+4.3297e-03j,\r\n          ..., -0.0031+1.5534e-03j, -0.0011-1.4202e-03j,\r\n         -0.0010-5.6579e-04j],\r\n        [ 0.0014-4.3687e-03j,  0.0109+5.4006e-09j,  0.0031+5.9140e-04j,\r\n          ...,  0.0014+8.9393e-03j,  0.0006-7.0626e-04j,\r\n         -0.0008-2.0498e-03j],\r\n        [ 0.0005-4.3297e-03j,  0.0031-5.9140e-04j,  0.0076-8.1491e-10j,\r\n          ...,  0.0007+1.7250e-03j,  0.0006+4.0059e-03j,\r\n          0.0010+1.1066e-03j],\r\n        ...,\r\n        [-0.0031-1.5534e-03j,  0.0014-8.9393e-03j,  0.0007-1.7250e-03j,\r\n          ...,  0.0160-2.7931e-09j,  0.0009-1.2880e-03j,\r\n         -0.0046-1.0336e-03j],\r\n        [-0.0011+1.4202e-03j,  0.0006+7.0627e-04j,  0.0006-4.0059e-03j,\r\n          ...,  0.0009+1.2880e-03j,  0.0156+7.2760e-12j,\r\n          0.0029-4.8818e-03j],\r\n        [-0.0010+5.6579e-04j, -0.0008+2.0498e-03j,  0.0010-1.1066e-03j,\r\n          ..., -0.0046+1.0336e-03j,  0.0029+4.8818e-03j,\r\n          0.0188-1.9008e-10j]], grad_fn=<AddBackward0>)\r\n量子判别器结果： tensor([[0.6479],\r\n        [0.3726],\r\n        [0.4541],\r\n        [0.4984]])\r\n```\r\n注意这里中间引入的数据Y用户可以根据自己的需求自行修改\r\n\r\n<span id=\"3.9\"></span>\r\n### QuML(Mutual Learning)\r\n主要思想是中间使用一个量子互信息的过程，交互后的信息各自都包含着自己和对方的特征，再分别将各自量子互信息后的信息与经典卷积得到的信息拼接，再进行后面的卷积及全连接过程，最后得到包含双方信息的结构。\r\n\r\n\r\n#### QuML结构图\r\n<img src=\"./deepquantum/pictures/QuML.png\" style=\"zoom:70%\">\r\n\r\n#### QuML提供的接口\r\n* Qu_conv_mutual：先实例化模型，然后将需要得到互信息的两个输入输入到模型中即可得到两者间的特征结果\r\n\r\n#### QuML使用方法\r\n调用DeepQuantum 0.0.2版本中的Qu_conv_mutual模型\r\n```python\r\nQuCM=Qu_conv_mutual(64,25)    #实例化互信息模型\r\n```\r\n实例化后将需要进行互学习的数据输入到模型中，注意这里可直接输入原始数据不需要编码为量子态数据\r\n```python\r\nX=torch.linspace(1,10,steps=150,dtype=int)  #将1~10数据平均分成150个数据，组成1*150的一维向量\r\nY=torch.linspace(1,10,steps=1000,dtype=int)  #将1~10数据平均分成1000个数据，组成1*1000的一维向量\r\n```\r\n将数据X和Y输入到QuCM中即可得到互学习后的结果\r\n```python\r\nout=QuCM(x,y)  #将需要互学习的结果输入到模型中\r\nprint('结果：',out)  #打印结果\r\n\r\n#输出结果\r\n结果： tensor([-298.0587], grad_fn=<ViewBackward0>)\r\n```\r\n用户可根据自己的需要定义输入数据并定义训练过程\r\n\r\n#### 示例\r\n```python\r\nimport torch\r\nimport torch.nn as nn\r\nimport deepquantum.nn as Qnn\r\n\r\nclass My_QuML(nn.Module):\r\n    def __init__(self,embedding_num_x, embedding_num_y):\r\n        super(My_QuML, self).__init__()\r\n        self.embedx = embedding_num_x\r\n        self.embedy = embedding_num_y\r\n        self.QuML = Qnn.Qu_conv_mutual(self.embedx,self.embedy)\r\n        self.linearx = nn.Linear(250, 150)\r\n        self.lineary = nn.Linear(33,1000)\r\n        \r\n    def forward(self, x, y):\r\n        x = self.linearx(x).int()\r\n        x = abs(x)\r\n        y = self.lineary(y).int()\r\n        y = abs(y)\r\n        out = self.QuML(x,y)\r\n        return out\r\n    \r\nmodule = My_QuML(64,25)\r\nx = torch.linspace(1,10,steps=250)\r\ny = torch.linspace(1,10,steps=33)\r\nresult = module(x, y)\r\nprint('结果：',result)\r\n\r\n#输出结果\r\n结果： tensor([-653.8476], grad_fn=<ViewBackward0>)\r\n```\r\n注意输入到模型中的数据集需要为正整数组成的向量\r\n\r\n<span id=\"3.10\"></span>\r\n### QuAttention\r\n量子注意力机制是经典注意力机制的量子版本，用量子比特的方式进行编码和信息处理。量子线路的是对量子信息的操作方法，通过量子线路，我们可以对含有量子信息的量子比特进行旋转，演化等操作。\r\n\r\n#### QuAttention提供的接口\r\n* QuAttention：先初始化量子注意力机制比特数n，然后将输入数据按定义的比特数分割成数份,每份的维度为$1\\times2^n$，将其编码为量子态密度矩阵并添加到同一列表中，最后将整个列表输入到模型中得到结果\r\n\r\n#### QuAtttention使用方法\r\n首先实例化模型\r\n```python\r\nqubits = 2 # 设定比特数\r\nquattention = QuAttention(qubits)\r\n```\r\n注意这里使用的是2比特线路的注意力机制模型，这里的输入数据需要为$2^2$的整数倍，并将数据切成数份长度为$2^2$的向量放入列表中\r\n```python\r\ntemp = torch.rand(200)\r\ndata = temp.reshape(1,-1) # 输入数据拉长为一维向量\r\nk = int(2**qubits) # 设定切片维度\r\nstate_list = []\r\nfor i in range(0,data.shape[1],k):\r\n    state = data[0,i:i+k].reshape(1,-1)\r\n    x = Gram(state)\r\n    state_list.append(x)\r\n```\r\n最后将得到的列表输入到模型中得到最后的结果\r\n```python\r\noutput = quattention(state_list)\r\n```\r\n\r\n#### 示例\r\n```python\r\nimport torch\r\nimport torch.nn as nn\r\nimport deepquantum.nn as Qnn\r\nfrom deepquantum.utils import Gram\r\n\r\nclass My_QuAttention(nn.Module):\r\n    def __init__(self, n_qubits, slice_n):\r\n        super(My_QuAttention, self).__init__()\r\n        self.n_qubits = n_qubits\r\n        self.slice_n = slice_n\r\n        self.linear = nn.Linear(100,2**self.n_qubits*self.slice_n )\r\n        self.QuAttn = Qnn.QuAttention(self.n_qubits)\r\n        \r\n        \r\n    def forward(self,x):\r\n        x = self.linear(x)\r\n        state_list = []\r\n        k = 2**self.n_qubits\r\n        for i in range(0,k*self.slice_n, k):\r\n            state = x[0, i:i+k].reshape(1,-1)\r\n            data = Gram(state)\r\n            state_list.append(data)\r\n        out = self.QuAttn(state_list)\r\n        return out\r\n    \r\nmodule = My_QuAttention(2,10)\r\nx = torch.rand(1,100)\r\nresult = module(x)\r\n```\r\n\r\n\r\n<span id=\"4\"></span>\r\n***\r\n## TorchScript IR\r\n### TorchScript简介\r\n<p>  PyTorch框架提供了一种即时（just-in-time, JIT）编译内联加载方式，即在一个Python文件中，将C++代码作为字符串传递给PyTorch中负责内联编译的函数。在运行Python文件时，即时编译出动态链接文件，并导入函数进行后续运算。torch.jit.torchscript是PyTorch提供的即时编译模块，它是Python语言的一个静态类型子集，并且支持Python语法同时也从Python中分离出来，只专注于Python中用于在Pytorch中表示神经网络模型所需的特性。</p>\r\n\r\n<span id=\"4.2\"></span>\r\n### DeepQuantum\r\nDeepQuantum是基于PyTorch框架开发的，量子经典混合神经网络的训练和部署是基于同一有向无环图(DAG)进行的，DeepQuantum 0.0版本是支持TorchScript进行跟踪和编译的，可使用该版本的对量子神经网络层算子进行定义和梯度计算，并对计算过程重写编译器做到将量子神经网络的DAG结构储存在CPU中，而推导过程在QPU或模拟QPU上进行计算提升运算效率。\r\n\r\n<span id=\"5\"></span>\r\n***\r\n## 组织交流方式\r\n<img src=\"./deepquantum/pictures/DeepQuantum交流群.png\" style=\"zoom:100%\">\r\n\r\n**QQ群：727013373**\r\n\r\n**交流邮箱：Algorithms-Applications@turingq.com**\r\n\r\n<span id=\"6\"></span>\r\n***\r\n ## 贡献者\r\n **图灵量子 算法应用部门**\r\n\r\n<span id=\"7\"></span>\r\n***\r\n## 鸣谢\r\n### 参考资料\r\n[1] M. A. Nielsen and I. L. Chuang, Quantum Computation and Quantum Information: 10th Anniversary Edition, 10th ed. (Cambridge University Press, New York, NY, USA, 2011).</br>\r\n\r\n[2]Alireza Makhzani,Jonathon Shlens,Navdeep Jaitly,Ian J. Goodfellow. Adversarial Autoencoders.[J]. CoRR,2015,abs/1511.05644:\r\n\r\n[3]Shayakhmetov Rim,Kuznetsov Maksim,Zhebrak Alexander,Kadurin Artur,Nikolenko Sergey,Aliper Alexander,Polykovskiy Daniil. Erratum: Addendum: Molecular Generation for Desired Transcriptome Changes With Adversarial Autoencoders.[J]. Frontiers in pharmacology,2020,11:\r\n\r\n[4]Maxwell Henderson, Samriddhi Shakya, Shashindra Pradhan, Tristan Cook. “Quanvolutional Neural Networks: Powering Image Recognition with Quantum Circuits.”arXiv:1904.04767, 2019.\r\n\r\n[5] PyTorch官方文档：[https://pytorch.org/docs/stable/index.html](https://pytorch.org/docs/stable/index.html)\r\n\r\n<span id=\"8\"></span>\r\n***\r\n## 许可证\r\nCopyright 2021 TuringQ\r\n\r\nLicensed under the Apache License, Version 2.0 (the \"License\");\r\nyou may not use this file except in compliance with the License.\r\nYou may obtain a copy of the License at\r\n\r\n[http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0)\r\n\r\nUnless required by applicable law or agreed to in writing, software\r\ndistributed under the License is distributed on an \"AS IS\" BASIS,\r\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\nSee the License for the specific language governing permissions and\r\nlimitations under the License.\r\n\r\n<span id=\"9\"></span>\r\n***\r\n## To-do List\r\n\r\n- [x] QuConv\r\n- [x] DeQuConv\r\n- [x] QuPool\r\n- [x] DeQuPool\r\n- [x] QuLinear\r\n- [x] QuAE\r\n- [x] QuGRU\r\n- [x] QuSAAE\r\n- [x] QuQML\r\n- [x] QuAttention\r\n- [ ] GAT \r\n- [ ] QuBiAAE\r\n- [ ] QuReinforce\r\n- [ ] Qustyle-GAN\r\n\r\n\r\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "VisualQ",
    "package_url": "https://pypi.org/project/VisualQ/",
    "platform": "",
    "project_url": "https://pypi.org/project/VisualQ/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/VisualQ/0.0.2/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "Simplified version deepquantum for visualization.",
    "version": "0.0.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12482140,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8b235bf5a75e86d760c6b10b5396a9648c4309998d5f19b7b1f72f81f3bb5ddc",
          "md5": "424be3d0af576551ca66cd5a17c0c488",
          "sha256": "05196378c98c3f8e7edbf6cecb4f27e06085620161201f98b21def1d1905b221"
        },
        "downloads": -1,
        "filename": "VisualQ-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "424be3d0af576551ca66cd5a17c0c488",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 5608,
        "upload_time": "2021-11-05T03:16:40",
        "upload_time_iso_8601": "2021-11-05T03:16:40.032711Z",
        "url": "https://files.pythonhosted.org/packages/8b/23/5bf5a75e86d760c6b10b5396a9648c4309998d5f19b7b1f72f81f3bb5ddc/VisualQ-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1843bedc524398ddcf1ac61d099214029d6e3ceac61b7af4743145b2302e71d0",
          "md5": "58c8280f745731725ae9cfd61268f086",
          "sha256": "317a1bd5fe422e50f6f833c9473371e049ee885da52e5a095161eeb397557787"
        },
        "downloads": -1,
        "filename": "VisualQ-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "58c8280f745731725ae9cfd61268f086",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 54039,
        "upload_time": "2022-01-05T08:58:07",
        "upload_time_iso_8601": "2022-01-05T08:58:07.071357Z",
        "url": "https://files.pythonhosted.org/packages/18/43/bedc524398ddcf1ac61d099214029d6e3ceac61b7af4743145b2302e71d0/VisualQ-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "1843bedc524398ddcf1ac61d099214029d6e3ceac61b7af4743145b2302e71d0",
        "md5": "58c8280f745731725ae9cfd61268f086",
        "sha256": "317a1bd5fe422e50f6f833c9473371e049ee885da52e5a095161eeb397557787"
      },
      "downloads": -1,
      "filename": "VisualQ-0.0.2.tar.gz",
      "has_sig": false,
      "md5_digest": "58c8280f745731725ae9cfd61268f086",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 54039,
      "upload_time": "2022-01-05T08:58:07",
      "upload_time_iso_8601": "2022-01-05T08:58:07.071357Z",
      "url": "https://files.pythonhosted.org/packages/18/43/bedc524398ddcf1ac61d099214029d6e3ceac61b7af4743145b2302e71d0/VisualQ-0.0.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}