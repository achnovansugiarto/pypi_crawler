{
  "info": {
    "author": "Leo Gao",
    "author_email": "lg@eleuther.ai",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Language Model Evaluation Harness\n\n![](https://github.com/EleutherAI/lm-evaluation-harness/workflows/Build/badge.svg)\n[![codecov](https://codecov.io/gh/EleutherAI/lm-evaluation-harness/branch/master/graph/badge.svg?token=JSG3O2427J)](https://codecov.io/gh/EleutherAI/lm-evaluation-harness)\n\n## Overview\n\nThis project provides a unified framework to test autoregressive language models (GPT-2, GPT-3, GPTNeo, etc) on a large number of different evaluation tasks.\n\nFeatures:\n\n- 200+ tasks implemented. See the [task-table](./docs/task_table.md) for a complete list.\n- Support for GPT-2, GPT-3, GPT-Neo, GPT-NeoX, and GPT-J, with flexible tokenization-agnostic interface.\n- Task versioning to ensure reproducibility.\n\n## Install\n\n```bash\npip install lm-eval\n```\n\nTo install additional multlingual tokenization and text segmenation packages, you must install the package with the `multilingual` extra:\n\n```bash\npip install \"lm-eval[multilingual]\"\n```\n\n## Basic Usage\n\n> **Note**: When reporting results from eval harness, please include the task versions (shown in `results[\"versions\"]`) for reproducibility. This allows bug fixes to tasks while also ensuring that previously reported scores are reproducible. See the [Task Versioning](#task-versioning) section for more info.\n\nTo evaluate a model (e.g. GPT-2) on NLP tasks such as SuperGLUE WiC, you can run the following command:\n\n\n```bash\npython main.py \\\n    --model gpt2 \\\n    --tasks lambada_openai,hellaswag \\\n    --device 0\n```\n\nThis example uses gpt2-117M by default as per HF defaults.\n\nAdditional arguments can be provided to the model constructor using the `--model_args` flag. Most importantly, the `gpt2` model can be used to load an arbitrary HuggingFace CausalLM. For example, to run GPTNeo use the following:\n\n```bash\npython main.py \\\n    --model gpt2 \\\n    --model_args pretrained=EleutherAI/gpt-neo-2.7B \\\n    --tasks lambada_openai,hellaswag \\\n    --device 0\n```\n\nIf you have access to the OpenAI API, you can also evaluate GPT-3:\n\n```bash\nexport OPENAI_API_SECRET_KEY=YOUR_KEY_HERE\npython main.py \\\n    --model gpt3 \\\n    --model_args engine=davinci \\\n    --tasks lambada_openai,hellaswag\n```\n\nAnd if you want to verify the data integrity of the tasks you're performing in addition to running the tasks themselves, you can use the `--check_integrity` flag:\n\n```bash\npython main.py \\\n    --model gpt3 \\\n    --model_args engine=davinci \\\n    --tasks lambada_openai,hellaswag \\\n    --check_integrity\n```\n\nTo evaluate mesh-transformer-jax models that are not available on HF, please invoke eval harness through [this script](https://github.com/kingoflolz/mesh-transformer-jax/blob/master/eval_harness.py).\n\nðŸ’¡ **Tip**: You can inspect what the LM inputs look like by running the following command:\n\n```bash\npython write_out.py \\\n    --tasks all_tasks \\\n    --num_fewshot 5 \\\n    --num_examples 10 \\\n    --output_base_path /path/to/output/folder\n```\n\nThis will write out one text file for each task.\n\n## Implementing new tasks\n\nTo implement a new task in the eval harness, see [this guide](./docs/task_guide.md).\n\n## Task Versioning\n\nTo help improve reproducibility, all tasks have a `VERSION` field. When run from the command line, this is reported in a column in the table, or in the \"version\" field in the evaluator return dict. The purpose of the version is so that if the task definition changes (i.e to fix a bug), then we can know exactly which metrics were computed using the old buggy implementation to avoid unfair comparisons. To enforce this, there are unit tests that make sure the behavior of all tests remains the same as when they were first implemented. Task versions start at 0, and each time a breaking change is made, the version is incremented by one.\n\nWhen reporting eval harness results, please also report the version of each task. This can be done either with a separate column in the table, or by reporting the task name with the version appended as such: taskname-v0.\n\n## Test Set Decontamination\n\nFor details on text decontamination, see the [decontamination guide](./docs/decontamination.md).\n\nNote that the directory provided to the `--decontamination_ngrams_path` argument should contain the ngram files and info.json. See the above guide for ngram generation for the pile, this could be adapted for other training sets.\n\n```bash\npython main.py \\\n    --model gpt2 \\\n    --tasks sciq \\\n    --decontamination_ngrams_path path/containing/training/set/ngrams \\\n    --device 0\n```\n\n## Cite as\n\n```\n@software{eval-harness,\n  author       = {Gao, Leo and\n                  Tow, Jonathan and\n                  Biderman, Stella and\n                  Black, Sid and\n                  DiPofi, Anthony and\n                  Foster, Charles and\n                  Golding, Laurence and\n                  Hsu, Jeffrey and\n                  McDonell, Kyle and\n                  Muennighoff, Niklas and\n                  Phang, Jason and\n                  Reynolds, Laria and\n                  Tang, Eric and\n                  Thite, Anish and\n                  Wang, Ben and\n                  Wang, Kevin and\n                  Zou, Andy},\n  title        = {A framework for few-shot language model evaluation},\n  month        = sep,\n  year         = 2021,\n  publisher    = {Zenodo},\n  version      = {v0.0.1},\n  doi          = {10.5281/zenodo.5371628},\n  url          = {https://doi.org/10.5281/zenodo.5371628}\n}\n```\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/EleutherAI/lm-evaluation-harness",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "lm-eval",
    "package_url": "https://pypi.org/project/lm-eval/",
    "platform": null,
    "project_url": "https://pypi.org/project/lm-eval/",
    "project_urls": {
      "Homepage": "https://github.com/EleutherAI/lm-evaluation-harness"
    },
    "release_url": "https://pypi.org/project/lm-eval/0.3.0/",
    "requires_dist": [
      "datasets (>=2.0.0)",
      "jsonlines",
      "numexpr",
      "openai (>=0.6.4)",
      "pybind11 (>=2.6.2)",
      "pycountry",
      "pytablewriter",
      "rouge-score (>=0.0.4)",
      "sacrebleu (==1.5.0)",
      "scikit-learn (>=0.24.1)",
      "sqlitedict",
      "torch (>=1.7)",
      "tqdm-multiprocess",
      "transformers (>=4.1)",
      "zstandard",
      "black ; extra == 'dev'",
      "flake8 ; extra == 'dev'",
      "pre-commit ; extra == 'dev'",
      "pytest ; extra == 'dev'",
      "pytest-cov ; extra == 'dev'",
      "nagisa (>=0.2.7) ; extra == 'multilingual'",
      "jieba (>=0.42.1) ; extra == 'multilingual'"
    ],
    "requires_python": ">=3.6",
    "summary": "A framework for evaluating autoregressive language models",
    "version": "0.3.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16030704,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1b5f7841febb99c12ffb453d33a67b9841e89dba18c388b644bf22b81d137fc4",
          "md5": "68ea867c38b60cf153b5c6c8ec2a1a07",
          "sha256": "bdaced3e4b56313c1e70d1207a788e42615bb29010687abf775d312dbd4ce7e2"
        },
        "downloads": -1,
        "filename": "lm_eval-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "68ea867c38b60cf153b5c6c8ec2a1a07",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 102867,
        "upload_time": "2021-09-02T02:28:24",
        "upload_time_iso_8601": "2021-09-02T02:28:24.540829Z",
        "url": "https://files.pythonhosted.org/packages/1b/5f/7841febb99c12ffb453d33a67b9841e89dba18c388b644bf22b81d137fc4/lm_eval-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "215afeb5ff3a1591ca963c54873d39116b0e6a4f80e493e961ac08569709c5d7",
          "md5": "ffbb8b78045d7bfd0808ae6f93d3c941",
          "sha256": "d6d2356c206065d80489bd89802c0b23534c56906bae07e2dbe367261f3fc35f"
        },
        "downloads": -1,
        "filename": "lm_eval-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "ffbb8b78045d7bfd0808ae6f93d3c941",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 84153,
        "upload_time": "2021-09-02T02:28:26",
        "upload_time_iso_8601": "2021-09-02T02:28:26.565687Z",
        "url": "https://files.pythonhosted.org/packages/21/5a/feb5ff3a1591ca963c54873d39116b0e6a4f80e493e961ac08569709c5d7/lm_eval-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f3a763cbce8b51de25fabb1c49f3a3fd1704faaacadb5ed816401f800e4d2dbd",
          "md5": "75147dbf11c1eb5b04b18216c6406f3e",
          "sha256": "dcb16a78a6c99e0fe2d2c72dd348d3e43ba965b587762f4233abc0b0742083e2"
        },
        "downloads": -1,
        "filename": "lm_eval-0.2.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "75147dbf11c1eb5b04b18216c6406f3e",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 143108,
        "upload_time": "2022-03-07T02:02:44",
        "upload_time_iso_8601": "2022-03-07T02:02:44.301588Z",
        "url": "https://files.pythonhosted.org/packages/f3/a7/63cbce8b51de25fabb1c49f3a3fd1704faaacadb5ed816401f800e4d2dbd/lm_eval-0.2.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c5fdedd21b0f258b4ec0260f99f5b2ac3864f7cddc8fb7c83bbb2379a6aab975",
          "md5": "9fbfd340cfaf0f60e7d99b70debec327",
          "sha256": "b557c2a6853dc2ec01f4dc090e9c72c722521e4707758898114aa3a7e9bfb3fd"
        },
        "downloads": -1,
        "filename": "lm_eval-0.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "9fbfd340cfaf0f60e7d99b70debec327",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 121336,
        "upload_time": "2022-03-07T02:02:46",
        "upload_time_iso_8601": "2022-03-07T02:02:46.063837Z",
        "url": "https://files.pythonhosted.org/packages/c5/fd/edd21b0f258b4ec0260f99f5b2ac3864f7cddc8fb7c83bbb2379a6aab975/lm_eval-0.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "61c5bff92e6b61fc2b0c1b7ac769633731910152e5176a404912ce7c07329ba0",
          "md5": "ae1830db4e0f5ec746b9cacb14c57709",
          "sha256": "a1b3cc6c3f1291717cac79a995dc2204547fe086ecfdec0e440ff1cea20b2ac2"
        },
        "downloads": -1,
        "filename": "lm_eval-0.3.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ae1830db4e0f5ec746b9cacb14c57709",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 178673,
        "upload_time": "2022-12-08T08:11:11",
        "upload_time_iso_8601": "2022-12-08T08:11:11.575578Z",
        "url": "https://files.pythonhosted.org/packages/61/c5/bff92e6b61fc2b0c1b7ac769633731910152e5176a404912ce7c07329ba0/lm_eval-0.3.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c4f858abc65390a758c8c2e5f1d8bb9b58d7885d02535d5f48de27006453d07e",
          "md5": "8a1d2fa73ae48c3e938b47a1d8617d0e",
          "sha256": "643b12bf9374f4d7c78ce55471b6ad82c130ab1aa0577d97fdfa48875dbc598b"
        },
        "downloads": -1,
        "filename": "lm_eval-0.3.0.tar.gz",
        "has_sig": false,
        "md5_digest": "8a1d2fa73ae48c3e938b47a1d8617d0e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 120598,
        "upload_time": "2022-12-08T08:11:14",
        "upload_time_iso_8601": "2022-12-08T08:11:14.586656Z",
        "url": "https://files.pythonhosted.org/packages/c4/f8/58abc65390a758c8c2e5f1d8bb9b58d7885d02535d5f48de27006453d07e/lm_eval-0.3.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "61c5bff92e6b61fc2b0c1b7ac769633731910152e5176a404912ce7c07329ba0",
        "md5": "ae1830db4e0f5ec746b9cacb14c57709",
        "sha256": "a1b3cc6c3f1291717cac79a995dc2204547fe086ecfdec0e440ff1cea20b2ac2"
      },
      "downloads": -1,
      "filename": "lm_eval-0.3.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "ae1830db4e0f5ec746b9cacb14c57709",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 178673,
      "upload_time": "2022-12-08T08:11:11",
      "upload_time_iso_8601": "2022-12-08T08:11:11.575578Z",
      "url": "https://files.pythonhosted.org/packages/61/c5/bff92e6b61fc2b0c1b7ac769633731910152e5176a404912ce7c07329ba0/lm_eval-0.3.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "c4f858abc65390a758c8c2e5f1d8bb9b58d7885d02535d5f48de27006453d07e",
        "md5": "8a1d2fa73ae48c3e938b47a1d8617d0e",
        "sha256": "643b12bf9374f4d7c78ce55471b6ad82c130ab1aa0577d97fdfa48875dbc598b"
      },
      "downloads": -1,
      "filename": "lm_eval-0.3.0.tar.gz",
      "has_sig": false,
      "md5_digest": "8a1d2fa73ae48c3e938b47a1d8617d0e",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 120598,
      "upload_time": "2022-12-08T08:11:14",
      "upload_time_iso_8601": "2022-12-08T08:11:14.586656Z",
      "url": "https://files.pythonhosted.org/packages/c4/f8/58abc65390a758c8c2e5f1d8bb9b58d7885d02535d5f48de27006453d07e/lm_eval-0.3.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}