{
  "info": {
    "author": "Michael Fatemi",
    "author_email": "myfatemi04@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# webparsa\nThis project uses XML templates to extract data from websites for you, with almost no code.\n\nXML templates are used to mimic the structure of the HTML itself, allowing you to make intuitive selectors.\nYou could literally copy and paste website code, and specify which attributes are the variables you want, and it would\nwork.\n\n### Storing single values\n*Note: for images, use the `<p_img>` tag, because img tags can't have children in HTML.*\nTo extract a certain value from a part of the element, use the `<value>` tag.\nValue tags need two things:\n- name: the name of the variable to store under\n- (inner text): the attribute to store.\n\n### Storing lists of values\nTo import a list of similar divs as a python list, wrap the single div that encloses the tags with `<list>` tags.\nList tags need only one attribute:\n- name: the name of the variable to store under\nDoesn't have to be the direct parent of a value!\n\n### Storing dicts of values\nTo group some values together as a dict, wrap the values in a `<dict>` tag.\nRequires a name attribute, like `<list>` and `<value>`.\nDoesn't have to be the direct parent of a value!\n\n### Possible attributes:\n- self.attrs.(any attribute): attributes from the HTML tag\n- self.text: inner text\n- self.element: BeautifulSoup element\n\n### Filtering\nTo select an element with HTML, just write the HTML element.\n\nFor example, writing `<div class='foo'>` will select any `div`s with class `foo`. \n\nTo filter any attribute, use \"filter.*\" as an attribute in the element.\n- filter.index=N: this element must be at select(element)\\[N\\]\n- filter.regex.*=REGEX: this attribute must match a certain regex. Examples: filter.regex.text=.+, filter.regex.attrs.data=\\\\d+.\n- filter.function=*: you define a function for us, passed as a keyword argument during the constructor. Then, we pass a dict containing attributes ('text', 'element', 'index', and another dictionary called 'attrs'), and your function returns False if the node should be rejected.\n\n### Post processing\nIn any tag, you can add the attribute \"after\" to run on any `<list>, <dict>, or <value>`'s value.\n\nFor example,\n~~~\n<div id=number>\n    <value name=number after=int>self.text</value>\n</div>\n~~~\n\nWill call the user-defined function `int` on the value returned from self.text.\nThis applies to any node in the XML tree, including HTML elements.\nYou can also call this `after` in `<list>` and `<value>` tags.\n\n**NOTE: in lists, this function will be called on the entire list, NOT on individual elements!**\n\nTo define the 'int' function, pass it in the constructor as Parsa((structure), int=function)\n\nSomething that might be useful would be to have a function called `df`, that makes a pandas dataframe from a list element.\n\nDefault postprocessing functions:\n - (User-defined functions)\n - .<...>: runs type(value).<...>(value). Essentially value.<...>(). Example: \".strip\" -> x.strip()\n - Built-in functions like int, float, str, list, dict, etc. Any attribute of the module builtins.\n\nOther postprocessing functions:\n - remove_commas: x.replace(\",\", \"\")\n - split_commas: x.split(\",\")\n - split: x.split(\" \")\n\nYou can use function composition by adding a \"+\" between function names.\nFor example:\nremove_commas+int: \"1,000,000\" -> \"1000000\" -> 1000000.\n\nIf you want to use more than one argument, I suggest writing a wrapper function or making a `partial` with `functools.partial`.\n\n### Required content\nBy default, all selectors must exist for a datapoint to be stored.\nHowever, if you want a datapoint to be optional, wrap the selector in `<unrequired>`.\n\n## Example\n### washington-post.xml\nHopefully this explains enough about how it works!\nTHIS GETS WASHINGTON POST HEADLINES\n\n~~~\n<list name=headlines> // stores children as dicts in a list called 'headlines'\n    <div filter.level=\"any\"> // filter.level=\"any\" means they don't have to be direct children\n        <div class=\"headline\" filter.level=\"any\"> // finds divs with class headline\n            <a> // finds a link\n                <value name=link>self.attrs.href</value> // stores the link's href attribute to 'link'\n                <value name=headline>self.text</value> // stores the link's text to 'text'. other possibility is 'element', which stores the BS4 node.\n            </a>\n        </div>\n        <span class=\"author\" filter.level=\"any\"> // finds spans with class author\n            <a filter.level=\"any\"> // finds any link\n                <value name=author>self.text</value> // stores the text to 'author'\n            </a>\n        </span>\n        <div class=\"art\" filter.level=\"any\"> // finds divs with class art\n            <p_img filter.level=\"any\"> // img doesn't let you put stuff inside, so it's called p_img\n                <value name=image_url>self.attrs.data-hi-res-src</value> // stores an attribute to 'image_url'\n            </p_img>\n        </div>\n    </div>\n</list>\n~~~\n\n### washington-post.py\n\n~~~\nimport webparsa\nimport requests\n\nparser = webparsa.Parsa(washington-post-xml-text)\n\nwebsite_content = requests.get(\"http://washingtonpost.com\")\n\nfor headline in parser.parse(website_content)['headlines']:\n    print(headline['headline'], headline['author'], headline['image_url'])\n~~~\n\n## License\n\nStandard MIT license.\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/myfatemi04/webparsa",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "webparsa",
    "package_url": "https://pypi.org/project/webparsa/",
    "platform": "",
    "project_url": "https://pypi.org/project/webparsa/",
    "project_urls": {
      "Homepage": "https://github.com/myfatemi04/webparsa"
    },
    "release_url": "https://pypi.org/project/webparsa/0.0.2/",
    "requires_dist": [
      "beautifulsoup4",
      "lxml (>=4.5)"
    ],
    "requires_python": ">=3.6",
    "summary": "This project uses XML templates to extract data from websites for you, with almost no code",
    "version": "0.0.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 7356472,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f96a013eb0d7554880a9f3c18a016fe2c62312f245c97cc0374d7859b6e16f21",
          "md5": "d8bcc1f559b9eb5b1cd0c70a4511e8f7",
          "sha256": "fc13e8fb3dcd560f3834702341f4343be315ce757bd13fe336dd6c919887d252"
        },
        "downloads": -1,
        "filename": "webparsa-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d8bcc1f559b9eb5b1cd0c70a4511e8f7",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 8265,
        "upload_time": "2020-05-30T00:35:32",
        "upload_time_iso_8601": "2020-05-30T00:35:32.966620Z",
        "url": "https://files.pythonhosted.org/packages/f9/6a/013eb0d7554880a9f3c18a016fe2c62312f245c97cc0374d7859b6e16f21/webparsa-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "24579b548b18f4f5a59977e46fe9743613d89c906103bf9d2d6c4a854e18f462",
          "md5": "6521eb436e819ffb8ce384dded066f25",
          "sha256": "c99dd76548b7c76f288bd81e29f770f89dbc564eec96f48ff037da7d8d86447e"
        },
        "downloads": -1,
        "filename": "webparsa-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "6521eb436e819ffb8ce384dded066f25",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 6127,
        "upload_time": "2020-05-30T00:35:34",
        "upload_time_iso_8601": "2020-05-30T00:35:34.946394Z",
        "url": "https://files.pythonhosted.org/packages/24/57/9b548b18f4f5a59977e46fe9743613d89c906103bf9d2d6c4a854e18f462/webparsa-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fd8123fad26acd702704bc157c611680156c1d0b0366417fc514f9eb125ec507",
          "md5": "0c440adabe9e472ed642e7218ff44a89",
          "sha256": "fe0101cef0c1ff2d1c37e1e318a4989f2d7737f611bbc66f963b2f73407737b6"
        },
        "downloads": -1,
        "filename": "webparsa-0.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0c440adabe9e472ed642e7218ff44a89",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 8291,
        "upload_time": "2020-05-30T00:44:40",
        "upload_time_iso_8601": "2020-05-30T00:44:40.851531Z",
        "url": "https://files.pythonhosted.org/packages/fd/81/23fad26acd702704bc157c611680156c1d0b0366417fc514f9eb125ec507/webparsa-0.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a45b6b2c0e356f748c0cf8108509b1f94da83ab87e4fffe635cea104c4f0eb7f",
          "md5": "a60aac886c24b404d735fcc9e145dfe2",
          "sha256": "c69dac9739d2c3b2126271e564f6308e13aa87aad9f9377c4de888cfafdcb1bc"
        },
        "downloads": -1,
        "filename": "webparsa-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "a60aac886c24b404d735fcc9e145dfe2",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 6821,
        "upload_time": "2020-05-30T00:44:42",
        "upload_time_iso_8601": "2020-05-30T00:44:42.053723Z",
        "url": "https://files.pythonhosted.org/packages/a4/5b/6b2c0e356f748c0cf8108509b1f94da83ab87e4fffe635cea104c4f0eb7f/webparsa-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "fd8123fad26acd702704bc157c611680156c1d0b0366417fc514f9eb125ec507",
        "md5": "0c440adabe9e472ed642e7218ff44a89",
        "sha256": "fe0101cef0c1ff2d1c37e1e318a4989f2d7737f611bbc66f963b2f73407737b6"
      },
      "downloads": -1,
      "filename": "webparsa-0.0.2-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "0c440adabe9e472ed642e7218ff44a89",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 8291,
      "upload_time": "2020-05-30T00:44:40",
      "upload_time_iso_8601": "2020-05-30T00:44:40.851531Z",
      "url": "https://files.pythonhosted.org/packages/fd/81/23fad26acd702704bc157c611680156c1d0b0366417fc514f9eb125ec507/webparsa-0.0.2-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "a45b6b2c0e356f748c0cf8108509b1f94da83ab87e4fffe635cea104c4f0eb7f",
        "md5": "a60aac886c24b404d735fcc9e145dfe2",
        "sha256": "c69dac9739d2c3b2126271e564f6308e13aa87aad9f9377c4de888cfafdcb1bc"
      },
      "downloads": -1,
      "filename": "webparsa-0.0.2.tar.gz",
      "has_sig": false,
      "md5_digest": "a60aac886c24b404d735fcc9e145dfe2",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 6821,
      "upload_time": "2020-05-30T00:44:42",
      "upload_time_iso_8601": "2020-05-30T00:44:42.053723Z",
      "url": "https://files.pythonhosted.org/packages/a4/5b/6b2c0e356f748c0cf8108509b1f94da83ab87e4fffe635cea104c4f0eb7f/webparsa-0.0.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}