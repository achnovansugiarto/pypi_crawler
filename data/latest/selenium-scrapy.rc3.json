{
  "info": {
    "author": "",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# Scrapy with selenium\nScrapy middleware to handle javascript pages using selenium==4.3.0.\n\n_This was originally a fork of [scrapy-selenium](https://github.com/clemfromspace/scrapy-selenium) but I couldn't use the below command on it._\n_Therefore this is actually a rip-off of said repo._\n## Installation\n```\n$ pip install git+https://github.com/mrafee113/selenium_scrapy.git@v0.1.0\n```\nYou should use **python>=3.9**. \nYou will also need one of the Selenium [compatible browsers](http://www.seleniumhq.org/about/platforms.jsp).\n\n## Configuration\n1. Add the browser to use, the path to the driver executable, and the arguments to pass to the executable to the scrapy settings:\n    ```python\n    from shutil import which\n\n    SELENIUM_DRIVER_NAME = 'firefox'\n    SELENIUM_DRIVER_EXECUTABLE_PATH = which('geckodriver')\n    SELENIUM_DRIVER_ARGUMENTS=['-headless']  # '--headless' if using chrome instead of firefox\n    SELENIUM_DRIVER_PREFERENCES = {\n        # (for firefox) to allow browser data to be cached among sessions.\n        \"browser.cahce.disk.parent_directory\": '/tmp/firefox-data-directory',\n   \n        # template firefox preferences to customize downloading files.\n        \"browser.download.folderList\": 2,\n        \"browser.download.manager.showWhenStarting\": False,\n        \"browser.download.dir\": '/tmp/firefox-download-directory',\n        \"browser.helperApps.neverAsk.saveToDisk\": \"application/x-gzip\"\n   }\n   # WARNING: To support localstorage the github project pyselenium_localstorage was used.\n   #  This project has its obvious limitations (read its code).\n   #  So be careful for type conversion when setting and getting values.\n   SELENIUM_DRIVER_LOCALSTORAGE_DATA = [\n        (\"https://python.org\", {\"key1\": \"value1\"}),\n        (\"https://google.com\", {\"data\": \"information\"})\n   ]\n   # or alternatively\n   SELENIUM_DRIVER_LOCALSTORAGE_DATA = (\"https://github.ccm\", {\"username\": \"code\"})\n    ```\n\nOptionally, set the path to the browser executable:\n    ```python\n    SELENIUM_BROWSER_EXECUTABLE_PATH = which('firefox')\n    ```\n\nIn order to use a remote Selenium driver, specify `SELENIUM_COMMAND_EXECUTOR` instead of `SELENIUM_DRIVER_EXECUTABLE_PATH`:\n    ```python\n    SELENIUM_COMMAND_EXECUTOR = 'http://localhost:4444/wd/hub'\n    ```\n\n2. Add the `SeleniumMiddleware` to the downloader middlewares:\n    ```python\n    DOWNLOADER_MIDDLEWARES = {\n        'scrapy_selenium.SeleniumMiddleware': 800\n    }\n    ```\n## Usage\nUse the `scrapy_selenium.SeleniumRequest` instead of the scrapy built-in `Request` like below:\n```python\nfrom scrapy_selenium import SeleniumRequest\n\nyield SeleniumRequest(url=url, callback=self.parse_result)\n```\nThe request will be handled by selenium, and the request will have an additional `meta` key, named `driver` containing the selenium driver with the request processed.\n```python\ndef parse_result(self, response):\n    print(response.request.meta['driver'].title)\n```\nFor more information about the available driver methods and attributes, refer to the [selenium python documentation](http://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.remote.webdriver)\n\nThe `selector` response attribute work as usual (but contains the html processed by the selenium driver).\n```python\ndef parse_result(self, response):\n    print(response.selector.xpath('//title/@text'))\n```\n\n### Additional arguments\nThe `scrapy_selenium.SeleniumRequest` accept 4 additional arguments:\n\n#### `wait_time` / `wait_until`\n\nWhen used, selenium will perform an [Explicit wait](http://selenium-python.readthedocs.io/waits.html#explicit-waits) before returning the response to the spider.\n```python\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support import expected_conditions as EC\n\nyield SeleniumRequest(\n    url=url,\n    callback=self.parse_result,\n    wait_time=10,\n    wait_until=EC.element_to_be_clickable((By.ID, 'someid'))\n)\n```\n\n#### `screenshot`\nWhen used, selenium will take a screenshot of the page and the binary data of the .png captured will be added to the response `meta`:\n```python\nyield SeleniumRequest(\n    url=url,\n    callback=self.parse_result,\n    screenshot=True\n)\n\ndef parse_result(self, response):\n    with open('image.png', 'wb') as image_file:\n        image_file.write(response.meta['screenshot'])\n```\n\n#### `script`\nWhen used, selenium will execute custom JavaScript code.\n```python\nyield SeleniumRequest(\n    url=url,\n    callback=self.parse_result,\n    script='window.scrollTo(0, document.body.scrollHeight);',\n)\n```\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/mrafee113/selenium_scrapy",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "selenium-scrapy",
    "package_url": "https://pypi.org/project/selenium-scrapy/",
    "platform": null,
    "project_url": "https://pypi.org/project/selenium-scrapy/",
    "project_urls": {
      "Homepage": "https://github.com/mrafee113/selenium_scrapy"
    },
    "release_url": "https://pypi.org/project/selenium-scrapy/0.1.4/",
    "requires_dist": [
      "Scrapy (==2.6.1)",
      "pyselenium-localstorage (==0.1.1)"
    ],
    "requires_python": "",
    "summary": "Scrapy with selenium==4.3",
    "version": "0.1.4",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14461318,
  "releases": {
    "0.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "528aca141cd10d076b3b717f8622822cee25235d4d3a146727d87c7094e97129",
          "md5": "537a7e39976981411d3ea5bb12950a47",
          "sha256": "7b51c4852e99bb01d9334b3bc35ef90fa0ab65956448cb46dfa08001d6b4b833"
        },
        "downloads": -1,
        "filename": "selenium_scrapy-0.1.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "537a7e39976981411d3ea5bb12950a47",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 6017,
        "upload_time": "2022-07-17T10:46:28",
        "upload_time_iso_8601": "2022-07-17T10:46:28.645914Z",
        "url": "https://files.pythonhosted.org/packages/52/8a/ca141cd10d076b3b717f8622822cee25235d4d3a146727d87c7094e97129/selenium_scrapy-0.1.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "78e9f959a261792a87cdcc778fc529aa392a51e2942b3ecb45ed964f7164d4f8",
          "md5": "01b0c729d0ff7cc0bca7becad06683b7",
          "sha256": "dc6e960804b6d69a5e78e695764ee4d5d956480f72515869a23bb0b337d12611"
        },
        "downloads": -1,
        "filename": "selenium-scrapy-0.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "01b0c729d0ff7cc0bca7becad06683b7",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 5122,
        "upload_time": "2022-07-17T10:46:30",
        "upload_time_iso_8601": "2022-07-17T10:46:30.059698Z",
        "url": "https://files.pythonhosted.org/packages/78/e9/f959a261792a87cdcc778fc529aa392a51e2942b3ecb45ed964f7164d4f8/selenium-scrapy-0.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4c6dc1152e3ace46813f9ba5df39283244eb4d872d589ecf03aa2527b3ab5b0d",
          "md5": "2683b62304fe18949ce438e63ca3d5c1",
          "sha256": "f0ed909d5d1289a7916fd12cb886e0b5cde2859086b7bcc167dc32426173b752"
        },
        "downloads": -1,
        "filename": "selenium_scrapy-0.1.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "2683b62304fe18949ce438e63ca3d5c1",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 6010,
        "upload_time": "2022-07-17T14:45:03",
        "upload_time_iso_8601": "2022-07-17T14:45:03.003038Z",
        "url": "https://files.pythonhosted.org/packages/4c/6d/c1152e3ace46813f9ba5df39283244eb4d872d589ecf03aa2527b3ab5b0d/selenium_scrapy-0.1.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "eb5959902be93255f82c8a18f1610a3ffb591e3d03c1424bf95c9a3e5a8b8783",
          "md5": "ed7e30f16545a963853ebe039bf013a8",
          "sha256": "5835691f1fa123e91ce25849dc59eef15148c6ba81a82b1aaf41e1a8c6c5ad35"
        },
        "downloads": -1,
        "filename": "selenium-scrapy-0.1.3.tar.gz",
        "has_sig": false,
        "md5_digest": "ed7e30f16545a963853ebe039bf013a8",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 5114,
        "upload_time": "2022-07-17T14:45:04",
        "upload_time_iso_8601": "2022-07-17T14:45:04.720459Z",
        "url": "https://files.pythonhosted.org/packages/eb/59/59902be93255f82c8a18f1610a3ffb591e3d03c1424bf95c9a3e5a8b8783/selenium-scrapy-0.1.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "90dc864b7df8c41c1b26558cc6807b7a65cd7721f926a3a826d6f31f2d914d75",
          "md5": "d6c41268d585541390f2a1e3530346d0",
          "sha256": "d67bbda2797dc1a6129b60c1db57f563b087e85b850ecce8459a3737644ad495"
        },
        "downloads": -1,
        "filename": "selenium_scrapy-0.1.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d6c41268d585541390f2a1e3530346d0",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 5875,
        "upload_time": "2022-07-17T16:07:06",
        "upload_time_iso_8601": "2022-07-17T16:07:06.535858Z",
        "url": "https://files.pythonhosted.org/packages/90/dc/864b7df8c41c1b26558cc6807b7a65cd7721f926a3a826d6f31f2d914d75/selenium_scrapy-0.1.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "de9043a83293047b9719cd91ae94a99a391c1aed3b96b245ff7e47d2ea5a3d45",
          "md5": "c5bc7bc2106a3615dc3e27b1cb37a38f",
          "sha256": "9077f357357b821c99c04b2b474a0944b2c01d7ddfb2d8e449c603661967e6ec"
        },
        "downloads": -1,
        "filename": "selenium-scrapy-0.1.4.tar.gz",
        "has_sig": false,
        "md5_digest": "c5bc7bc2106a3615dc3e27b1cb37a38f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 4983,
        "upload_time": "2022-07-17T16:07:07",
        "upload_time_iso_8601": "2022-07-17T16:07:07.842646Z",
        "url": "https://files.pythonhosted.org/packages/de/90/43a83293047b9719cd91ae94a99a391c1aed3b96b245ff7e47d2ea5a3d45/selenium-scrapy-0.1.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "90dc864b7df8c41c1b26558cc6807b7a65cd7721f926a3a826d6f31f2d914d75",
        "md5": "d6c41268d585541390f2a1e3530346d0",
        "sha256": "d67bbda2797dc1a6129b60c1db57f563b087e85b850ecce8459a3737644ad495"
      },
      "downloads": -1,
      "filename": "selenium_scrapy-0.1.4-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "d6c41268d585541390f2a1e3530346d0",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 5875,
      "upload_time": "2022-07-17T16:07:06",
      "upload_time_iso_8601": "2022-07-17T16:07:06.535858Z",
      "url": "https://files.pythonhosted.org/packages/90/dc/864b7df8c41c1b26558cc6807b7a65cd7721f926a3a826d6f31f2d914d75/selenium_scrapy-0.1.4-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "de9043a83293047b9719cd91ae94a99a391c1aed3b96b245ff7e47d2ea5a3d45",
        "md5": "c5bc7bc2106a3615dc3e27b1cb37a38f",
        "sha256": "9077f357357b821c99c04b2b474a0944b2c01d7ddfb2d8e449c603661967e6ec"
      },
      "downloads": -1,
      "filename": "selenium-scrapy-0.1.4.tar.gz",
      "has_sig": false,
      "md5_digest": "c5bc7bc2106a3615dc3e27b1cb37a38f",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 4983,
      "upload_time": "2022-07-17T16:07:07",
      "upload_time_iso_8601": "2022-07-17T16:07:07.842646Z",
      "url": "https://files.pythonhosted.org/packages/de/90/43a83293047b9719cd91ae94a99a391c1aed3b96b245ff7e47d2ea5a3d45/selenium-scrapy-0.1.4.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}