{
  "info": {
    "author": "Jisk Attema",
    "author_email": "j.attema@esciencecenter.nl",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Environment :: Console",
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Graph based Semantic Role Labeller\n\nThis is a semantic role laballer based on a graph convolutional network.\nThe goal is to make something reasonably state-of-the-art for the Dutch language.\n\nThis is work in progress.\n\n# Quick start\n\n## Run it on Conll files\n\n```\npython -m stroll.srl --dataset example.conll\n```\n\n## Use it in a Stanza Pipeline directly from python\n\nYou can add Stroll to a Stanza pipeline by importing ```stroll.stanza``` and\nadding ```srl``` to the Stanza processors.\nThis will add an *srl* and *frame* attribute to words.\n(Note that these are not printed when printing the Stanza Document, Sentence, or Word objects.)\n\n```\nimport stanza\nimport stroll.stanza\n\nnlp = stanza.Pipeline(lang='nl', processors='tokenize,lemma,pos,depparse,srl')\ndoc = nlp('Stroll annoteert semantic roles.')\n\nfor s in doc.sentences:\n    for w in s.words:\n        print(w.lemma, w.srl, w.frame)\n\nStroll Arg0 _\nannoteren _ rel\nsemantic Arg1 _\nroles _ _\n. _ _\n```\n\n## Training data\n\n[SoNaR](http://lands.let.ru.nl/projects/SoNaR/) contains a annotated dataset of 500K words.\nThe annotation of the frames is quite basic:\n * the semantic annotations were made on top of a syntactic dependency tree\n * only (some) verbs are marked\n * no linking to FrameNet or any frame identification is made\n\nThe original annotations were made on AlpinoXML; the files are converted to conllu using a script from Groningen.\nConversion scripts from Alpino and Lassy to the UD format [available here](https://github.com/gossebouma/lassy2ud).\n\nI am planning to use universal dependencies schema for the syntax, and assume input files are in conllu format.\nThis way the labeller can be used as part of the Newsreader annotation pipeline.\n\n## Approach\n\nThe training set was made as annotations on top of a syntactic tree.\nWe'll use the same tree, as given by the `HEAD` and `DEPREL` fields from the conll files.\nWords form the nodes, and we add three kinds of edges:\n * from dependent to head (weighted by the number of dependents)\n * from the head to the dependent\n * from the node to itself\n\nAt each node, we add a `GRU` cell.\nThe initial state is made using one-hot encoding of a number of features.\nThe output of the cell is then passed to two classifiers\nOne to indicate if this word is a frame, and one to indicate if the word is the head of an arguments (and which argument).\n\nAs node features we can use the information in the conllu file.\nWe also added pre-trained word vectors form either fasttext, or BERTje.\nFinally, we add a positional encoding (ie. 'first descendant').\n\n# Installation\n\nSetup a virtual env with python3, and install dependencies:\n```bash\npython3 -m venv env\n. env/bin/activate\npip install -r requirements.txt\n```\n\n# Best model until now\n\n## Model layers\n\n```\nNet(\n  (embedding): Sequential(\n    (0): Linear(in_features=189, out_features=100, bias=True)\n    (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n  )\n  (gru): RGRUGCN(\n    in_feats=100, out_feats=100\n    (gru): GRU(100, 100)\n    (batchnorm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (task_a): MLP(\n    (fc): Sequential(\n      (0): Linear(in_features=100, out_features=100, bias=True)\n      (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Linear(in_features=100, out_features=2, bias=True)\n    )\n  )\n  (task_b): MLP(\n    (fc): Sequential(\n      (0): Linear(in_features=100, out_features=100, bias=True)\n      (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Linear(in_features=100, out_features=21, bias=True)\n    )\n  )\n)\n```\n\n## Training settings\n\n * Features used UPOS, DEPREL, FEATS, RID,  FastText100\n * Size of hidden state 100\n * Number of GRU iterations 4\n * Activation functions relu\n * Batch size 50 sentences\n * Adam optimizer ADAM\n * Initial learning rate 1e-02\n * Learning rate scheduler StepLR, gamma=0.9\n * Focal Loss, gamma=5.\n * The two loss functions were added, both with weight 1\n\n## Results\n\n2 classes are so rare, they are not in our 10% evaluation set, and were not predicted by the model. (`Arg5` and `ArgM-STR`).\n\nThe confustion matrix and statistics (`classification_report`) were made with `scikit-learn`.\n\nThe best model was after 6628920 words, or 15 epochs.\n\n### Frames\n\n|   |   _   |  rel |\n|---|------:|-----:|\n| _ | 45602 |  152 |\n|rel|  164  | 3561 |\n\n\n|             | precision   | recall  |f1-score   |support|\n|-------------|------------:|--------:|----------:|------:|\n|           _ |      1.00   |   1.00  |    1.00   |  45754|\n|         rel |      0.96   |   0.96  |    0.96   |   3725|\n|             |             |         |           |       |\n|    accuracy |             |         |    0.99   |  49479|\n|   macro avg |      0.98   |   0.98  |    0.98   |  49479|\n|weighted avg |      0.99   |   0.99  |    0.99   |  49479|\n\n\n### Roles\n\n|         | Arg0|   Arg1|  Arg2| Arg3 | Arg4  |ArgM-ADV | ArgM-CAU  | ArgM-DIR | ArgM-DIS | ArgM-EXT | ArgM-LOC | ArgM-MNR | ArgM-MOD | ArgM-NEG | ArgM-PNC | ArgM-PRD | ArgM-REC | ArgM-TMP  |  _   |\n|---------|----:|------:|-----:|-----:|------:|--------:|----------:|---------:|---------:|---------:|---------:|---------:|---------:|---------:|---------:|---------:|---------:|----------:|-----:|\n|     Arg0| 1650|   113 |    9 |    0 |    0  |       2 |         2 |        1 |       0  |       0  |        3 |         0|       0  |        0 |        2 |        0 |        0 |          0|    32|\n|     Arg1|  232|  2596 |  111 |    0 |    6  |       4 |         3 |        3 |       0  |       5  |       41 |        17|       1  |        6 |        7 |        2 |        2 |          2|   100|\n|     Arg2|   16|   154 |  346 |    2 |    8  |       1 |         0 |       10 |       0  |       3  |       91 |        27|       0  |        1 |       16 |        6 |        2 |          6|    18|\n|     Arg3|    0|     9 |   26 |    5 |    0  |       0 |         0 |        1 |       0  |       0  |        7 |         3|       0  |        0 |        8 |        1 |        0 |          4|     1|\n|     Arg4|    0|     5 |   11 |    0 |   28  |       0 |         0 |        3 |       0  |       0  |        7 |         0|       0  |        0 |        0 |        0 |        0 |          1|     0|\n| ArgM-ADV|    0|     8 |   13 |    0 |    0  |     312 |        10 |        2 |      27  |       5  |       20 |        32|       0  |        0 |        4 |        6 |        0 |         45|    44|\n| ArgM-CAU|    9|     5 |    5 |    0 |    0  |      13 |        96 |        1 |       1  |       0  |        0 |        20|       0  |        0 |        1 |        0 |        0 |          7|    12|\n| ArgM-DIR|    0|     0 |   10 |    0 |    4  |       0 |         0 |       30 |       0  |       0  |        4 |         5|       0  |        0 |        0 |        1 |        0 |          2|     2|\n| ArgM-DIS|    0|     0 |    0 |    0 |    0  |      27 |         3 |        0 |     322  |       2  |        5 |        13|       0  |        0 |        0 |        0 |        0 |         14|   157|\n| ArgM-EXT|    0|     4 |    4 |    1 |    0  |       6 |         0 |        0 |       0  |      47  |        2 |         8|       0  |        1 |        0 |        0 |        0 |          9|     5|\n| ArgM-LOC|    0|    12 |   49 |    0 |    3  |       8 |         1 |        7 |       0  |       1  |      519 |         6|       0  |        1 |        4 |        2 |        1 |         26|    36|\n| ArgM-MNR|    3|    25 |   35 |    0 |    0  |      38 |         6 |        8 |       4  |      13  |       18 |       313|       1  |        1 |        0 |       10 |        0 |         14|    27|\n| ArgM-MOD|    0|     2 |    0 |    0 |    0  |       1 |         0 |        0 |       0  |       0  |        0 |         1|       598|        0 |        0 |        0 |        0 |          0|    54|\n| ArgM-NEG|    1|     2 |    1 |    0 |    0  |       2 |         0 |        0 |       0  |       0  |        0 |         2|       1  |      266 |        0 |        0 |        0 |          3|    13|\n| ArgM-PNC|    0|     9 |   20 |    0 |    0  |       2 |         7 |        0 |       0  |       0  |        4 |         4|       0  |        0 |      119 |        0 |        0 |          5|    11|\n| ArgM-PRD|    0|     9 |    7 |    0 |    0  |       9 |         0 |        0 |       0  |       2  |        3 |        13|       0  |        0 |        2 |       74 |        2 |          1|    12|\n| ArgM-REC|    0|     0 |    1 |    0 |    0  |       0 |         0 |        0 |       0  |       0  |        1 |         0|       0  |        0 |        1 |        1 |      105 |          0|     0|\n| ArgM-TMP|    0|     4 |   13 |    1 |    1  |      45 |         7 |        0 |       3  |      13  |       31 |        24|       1  |        3 |        4 |        0 |        0 |        862|    32|\n|       _ |   81|   138 |   24 |    0 |    1  |      37 |         9 |        2 |      13  |       3  |       27 |        28|       50 |        15|         8|         7|         0|         30| 38234|\n\n\n|             | precision  |  recall  |f1-score   |support|\n|-------------|-----------:|---------:|----------:|------:|\n|        Arg0 |      0.83  |    0.91  |    0.87   |   1814|\n|        Arg1 |      0.84  |    0.83  |    0.83   |   3138|\n|        Arg2 |      0.51  |    0.49  |    0.50   |    707|\n|        Arg3 |      0.56  |    0.08  |    0.14   |     65|\n|        Arg4 |      0.55  |    0.51  |    0.53   |     55|\n|    ArgM-ADV |      0.62  |    0.59  |    0.60   |    528|\n|    ArgM-CAU |      0.67  |    0.56  |    0.61   |    170|\n|    ArgM-DIR |      0.44  |    0.52  |    0.48   |     58|\n|    ArgM-DIS |      0.87  |    0.59  |    0.71   |    543|\n|    ArgM-EXT |      0.50  |    0.54  |    0.52   |     87|\n|    ArgM-LOC |      0.66  |    0.77  |    0.71   |    676|\n|    ArgM-MNR |      0.61  |    0.61  |    0.61   |    516|\n|    ArgM-MOD |      0.92  |    0.91  |    0.91   |    656|\n|    ArgM-NEG |      0.90  |    0.91  |    0.91   |    291|\n|    ArgM-PNC |      0.68  |    0.66  |    0.67   |    181|\n|    ArgM-PRD |      0.67  |    0.55  |    0.61   |    134|\n|    ArgM-REC |      0.94  |    0.96  |    0.95   |    109|\n|    ArgM-TMP |      0.84  |    0.83  |    0.83   |   1044|\n|           _ |      0.99  |    0.99  |    0.99   |  38707|\n|             |            |          |           |       |\n|    accuracy |            |          |    0.94   |  49479|\n|   macro avg |      0.71  |    0.67  |    0.68   |  49479|\n|weighted avg |      0.94  |    0.94  |    0.94   |  49479|\n\n\n# References\n\n1. [Encoding Sentences with Graph Convolutional Networks for Semantic Role Labeling](https://arxiv.org/abs/1703.04826)\n2. [Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics](https://arxiv.org/pdf/1705.07115.pdf)\n3. [Focal Loss for Dense Object Detection](https://arxiv.org/abs/1708.02002)\n4. [GaAN: Gated Attention Networks for Learning on Large and Spatiotemporal Graphs](https://arxiv.org/abs/1803.07294)\n5. [Look Again at the Syntax: Relational Graph Convolutional Network for Gendered Ambiguous Pronoun Resolution](https://arxiv.org/abs/1905.08868) [code](https://github.com/ianycxu/RGCN-with-BERT)\n6. [Deep Graph Library](https://www.dgl.ai)\n7. [The CoNLL-2009 shared task: syntactic and semantic dependencies in multiple languages](https://dl.acm.org/doi/10.5555/1596409.1596411)\n8. [2009 Shared task evaluation script](https://ufal.mff.cuni.cz/conll2009-st/scorer.html)\n9. [Super-Convergence: Very Fast Training of NeuralNetworks Using Large Learning Rates](https://arxiv.org/abs/1708.07120)\n10. [Label Distribution Learning](https://arxiv.org/abs/1408.6027)\n11. [On Loss Functions for Deep Neural Networks in Classification](https://arxiv.org/abs/1702.05659)\n12. [Training Products of Experts by Minimizing Contrastive Divergence](https://www.mitpressjournals.org/doi/10.1162/089976602760128018)\n13. [Selecting weighting factors in logarithmic opinion pools.pdf](https://dl.acm.org/doi/10.5555/3008904.3008942)\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/Filter-Bubble/stroll",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "stroll-srl",
    "package_url": "https://pypi.org/project/stroll-srl/",
    "platform": "",
    "project_url": "https://pypi.org/project/stroll-srl/",
    "project_urls": {
      "Homepage": "https://github.com/Filter-Bubble/stroll"
    },
    "release_url": "https://pypi.org/project/stroll-srl/0.5.1/",
    "requires_dist": [
      "torch",
      "dgl",
      "matplotlib",
      "numpy",
      "sklearn",
      "progress",
      "argparse",
      "fasttext",
      "seaborn",
      "stanza",
      "KafNafParserPy"
    ],
    "requires_python": ">=3.6",
    "summary": "Graph based semantic role labeler",
    "version": "0.5.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 9522165,
  "releases": {
    "0.5.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5c2d26e3d7951e64ede931e1ef8235aeaa69248d08bb313a8b81f650dbb85e2e",
          "md5": "c92f8798b2228ca438ef5951279d22a5",
          "sha256": "da011726ce081c847da319027571563b73ed6165d96229e3223da02a53f0e383"
        },
        "downloads": -1,
        "filename": "stroll_srl-0.5.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "c92f8798b2228ca438ef5951279d22a5",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 27472,
        "upload_time": "2021-02-25T13:25:07",
        "upload_time_iso_8601": "2021-02-25T13:25:07.262978Z",
        "url": "https://files.pythonhosted.org/packages/5c/2d/26e3d7951e64ede931e1ef8235aeaa69248d08bb313a8b81f650dbb85e2e/stroll_srl-0.5.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "16af5536852299418a4cf7cd280d25d9eaea4eae3a002087ec4807adfe04e618",
          "md5": "78a9c7e788496f70deb54c1b5782808e",
          "sha256": "e7fe1aa705561d9b77f4e65ed83a997aae7d0c07fff1be8fd0e621321d46571b"
        },
        "downloads": -1,
        "filename": "stroll-srl-0.5.1.tar.gz",
        "has_sig": false,
        "md5_digest": "78a9c7e788496f70deb54c1b5782808e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 25343,
        "upload_time": "2021-02-25T13:25:08",
        "upload_time_iso_8601": "2021-02-25T13:25:08.917753Z",
        "url": "https://files.pythonhosted.org/packages/16/af/5536852299418a4cf7cd280d25d9eaea4eae3a002087ec4807adfe04e618/stroll-srl-0.5.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "5c2d26e3d7951e64ede931e1ef8235aeaa69248d08bb313a8b81f650dbb85e2e",
        "md5": "c92f8798b2228ca438ef5951279d22a5",
        "sha256": "da011726ce081c847da319027571563b73ed6165d96229e3223da02a53f0e383"
      },
      "downloads": -1,
      "filename": "stroll_srl-0.5.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "c92f8798b2228ca438ef5951279d22a5",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 27472,
      "upload_time": "2021-02-25T13:25:07",
      "upload_time_iso_8601": "2021-02-25T13:25:07.262978Z",
      "url": "https://files.pythonhosted.org/packages/5c/2d/26e3d7951e64ede931e1ef8235aeaa69248d08bb313a8b81f650dbb85e2e/stroll_srl-0.5.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "16af5536852299418a4cf7cd280d25d9eaea4eae3a002087ec4807adfe04e618",
        "md5": "78a9c7e788496f70deb54c1b5782808e",
        "sha256": "e7fe1aa705561d9b77f4e65ed83a997aae7d0c07fff1be8fd0e621321d46571b"
      },
      "downloads": -1,
      "filename": "stroll-srl-0.5.1.tar.gz",
      "has_sig": false,
      "md5_digest": "78a9c7e788496f70deb54c1b5782808e",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 25343,
      "upload_time": "2021-02-25T13:25:08",
      "upload_time_iso_8601": "2021-02-25T13:25:08.917753Z",
      "url": "https://files.pythonhosted.org/packages/16/af/5536852299418a4cf7cd280d25d9eaea4eae3a002087ec4807adfe04e618/stroll-srl-0.5.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}