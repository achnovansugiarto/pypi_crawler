{
  "info": {
    "author": "",
    "author_email": "FARHAN AHMED <contact@farhyn.com>",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# scrapeTiger\n\nscrapeTiger is an python package for web scraping. \n\n* `requires-python = \">=3.7\"`\n\n# example of scraping multiple page\n```\nfrom scrapeTiger import multi_page,details_page\n\nmulti_page(url=\"https://quotes.toscrape.com/page/\",start_page=1,end_page=3,css_selector= \".quote span a\")\n\ndetails_page(field_one_css='.author-title')\n```\n\nLet explain how this two function working. First we are scraping link of each items from page 1 to page 2 with the help of multi_page function then we are scraping author name from datils page of each item with the help of details_page function.  \n\n# example of scraping single page\n```\nfrom scrapeTiger import single_page,details_page\n\nsingle_page(url=\"https://quotes.toscrape.com/\",css_selector= \".quote span a\")\n\ndetails_page(field_one_css='.author-title')\n```\n\n# How to install\n\n`pip install scrapeTiger`\n\n# dependency packages\ninstall selenium and webdriver-manager for run this package properly.\n\n* `pip install selenium`\n* `pip install webdriver-manager`\n\n# Output Result\n___\n\nIt will generate csv file after scraping.\n\n# multi_page \n\n`multi_page(url,start_page,end_page,css_selector,wait_second=2)`\n* url (string, required)\n* start_page(integer, required) \n* end_page(integer, required)\n* css_selector(string, required)\n* wait_second(integer, optional)  \ndefult 2 second\n\n\n# single_page\n `single_page(url,css_selector,wait_second=2)`\n\n* url (string, required)\n* css_selector(string, required)\n* wait_second(integer, optional)\n\n\n# details_page\n___\n `\n details_page(wait_second=2,field_one_css=None,field_one_html=False,main_image_css=None,img_attribute='src',gallary_image_css=None,gallary_image_attribute='src',header_added=False)\n `\n\n * wait_second(integer, optional)  \n defult 2 second\n  \n * field_one_css(string, optional)\n * field_one_html(boolean, optional)\n  \n   defult flase. If you want to get html then make it true otherwise you will get text value.\n* You can aslo use field_two_css,field_three_css,field_four_css same like field_one_css.\n\n* You can aslo use field_two_html, field_three_html,field_four_html same like field_one_html.\n\n* maximum four fields \n\n* main_image_css(string, optional)\n\n* img_attribute(string, optional)\n  \n  defult img_attribute is `src` for main_image_css. \n\n* gallary_image_css(string, optional)\n\n* gallary_image_attribute(string, optional)\n\n   defult img_attribute is `src` for gallary_image_css. \n\n* header_added(boolean, optional)\n\n  defult flase. If you don't want to write csv header then make to true.\n\n* details_page() function support maximum four fields.\n example: `details_page(field_one_css=None,field_one_html=False,field_two_css=None,field_two_html=False,field_three_css=None,field_three_html=False,field_four_css=None,field_four_html=False,)`\n\n\n\n\n\n[Github link](https://github.com/MDFARHYN/scrapeTiger)\n\n[report issue](https://github.com/MDFARHYN/scrapeTiger/issues)\n\n\n\n\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "web scraping,data mining,scraping tools,scraping tiger,farhyn.com",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "scrapeTiger",
    "package_url": "https://pypi.org/project/scrapeTiger/",
    "platform": null,
    "project_url": "https://pypi.org/project/scrapeTiger/",
    "project_urls": {
      "Bug Tracker": "https://github.com/MDFARHYN/scrapeLion/scrapeTiger",
      "Homepage": "https://github.com/MDFARHYN/scrapeTiger"
    },
    "release_url": "https://pypi.org/project/scrapeTiger/1.0.4/",
    "requires_dist": [
      "selenium",
      "webdriver-manager"
    ],
    "requires_python": ">=3.7",
    "summary": "scrapeTiger is an python package for web scraping.",
    "version": "1.0.4",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 15012562,
  "releases": {
    "1.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7eee2da78e96f8d5f6c47b5eee4ce991a304c7446f28343c1f9035631ca0501c",
          "md5": "0fab500c4bd18778e67272bba8c7ef77",
          "sha256": "e8bb04bf0e697d6bf7dc9c858c64e7fc1b767fce29e8f5f2c91b304afd68313b"
        },
        "downloads": -1,
        "filename": "scrapeTiger-1.0.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0fab500c4bd18778e67272bba8c7ef77",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 4452,
        "upload_time": "2022-09-06T22:55:34",
        "upload_time_iso_8601": "2022-09-06T22:55:34.310347Z",
        "url": "https://files.pythonhosted.org/packages/7e/ee/2da78e96f8d5f6c47b5eee4ce991a304c7446f28343c1f9035631ca0501c/scrapeTiger-1.0.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d7366a2ac2a7d3af4cf0e2236204d7eb68d42e8fd33d21a92b169355b83cf96a",
          "md5": "1df6f089232eec62ef38185f09198343",
          "sha256": "07052678a9bcb92545d192974930f898e92030e6e4c819fb7065e1f4bdbff9de"
        },
        "downloads": -1,
        "filename": "scrapeTiger-1.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "1df6f089232eec62ef38185f09198343",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 4137,
        "upload_time": "2022-09-06T22:55:36",
        "upload_time_iso_8601": "2022-09-06T22:55:36.661399Z",
        "url": "https://files.pythonhosted.org/packages/d7/36/6a2ac2a7d3af4cf0e2236204d7eb68d42e8fd33d21a92b169355b83cf96a/scrapeTiger-1.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "7eee2da78e96f8d5f6c47b5eee4ce991a304c7446f28343c1f9035631ca0501c",
        "md5": "0fab500c4bd18778e67272bba8c7ef77",
        "sha256": "e8bb04bf0e697d6bf7dc9c858c64e7fc1b767fce29e8f5f2c91b304afd68313b"
      },
      "downloads": -1,
      "filename": "scrapeTiger-1.0.4-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "0fab500c4bd18778e67272bba8c7ef77",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 4452,
      "upload_time": "2022-09-06T22:55:34",
      "upload_time_iso_8601": "2022-09-06T22:55:34.310347Z",
      "url": "https://files.pythonhosted.org/packages/7e/ee/2da78e96f8d5f6c47b5eee4ce991a304c7446f28343c1f9035631ca0501c/scrapeTiger-1.0.4-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "d7366a2ac2a7d3af4cf0e2236204d7eb68d42e8fd33d21a92b169355b83cf96a",
        "md5": "1df6f089232eec62ef38185f09198343",
        "sha256": "07052678a9bcb92545d192974930f898e92030e6e4c819fb7065e1f4bdbff9de"
      },
      "downloads": -1,
      "filename": "scrapeTiger-1.0.4.tar.gz",
      "has_sig": false,
      "md5_digest": "1df6f089232eec62ef38185f09198343",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 4137,
      "upload_time": "2022-09-06T22:55:36",
      "upload_time_iso_8601": "2022-09-06T22:55:36.661399Z",
      "url": "https://files.pythonhosted.org/packages/d7/36/6a2ac2a7d3af4cf0e2236204d7eb68d42e8fd33d21a92b169355b83cf96a/scrapeTiger-1.0.4.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}