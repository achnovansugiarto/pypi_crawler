{
  "info": {
    "author": "",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "Operating System :: POSIX :: Linux",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9"
    ],
    "description": "![Python CI](https://github.com/nebulastream/nebulastream-python-client/workflows/Python%20CI/badge.svg)\n[![Version](https://img.shields.io/pypi/v/nespy.svg)](https://img.shields.io/pypi/v/nespy.svg)\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n# NebulaStream Python Client \n\nNebulaStream's python client is the first data science environment for NebulaStream.\nIt allows users to...\n* use operators to execute queries in NebulaStream efficiently\n* perform data preparation tasks on data streams \n* train machine learning models with ease \n* integrate any python library\n\n## Example\nAs an example, we want to perform a data exploration task. \nFirst, we need to connect with NebulaStream and select the data stream \"vehicles\". This data stream contains data from all by NebulaStream registered vehicles in the berlin, including their current position, their speed, the total driven route, and vehicle type.\n\n```python\n>>> import nespy as nes\n\n>>> c = nes.Connection('127.0.0.1', 8081)\n>>> vehicles = c.get_logical_stream(\"vehicles\")\n>>> vehicles\n```\n| type | id  | lat      | lon       | timestamp | speed in km/h | route (in meters) |\n| ---- | --- | -------- | --------- | --------- | ------------- | ----------------- |\n| 6    | 1   |52.513126 | 13.328347 | 1         | 51            | 27.000            |\n| 4    | 2   |52.513109 | 13.326388 | 1         | 25            | 5.35              |\n| 6    | 3   |52.512763 | 13.325291 | 1         | 62            | 10.000            |\n| 9    | 4   |52.512677 | 13.325964 | 1         | 51            | 10.000            |\n| 3    | 5   |52.512259 | 13.322778 | 1         | 29            | 1.89              |\n\nWhat we want to do now is to find out the average speed over the last five minutes of all cars in berlin. \nTherefore, we only filter cars (type = 6) and apply a sliding window on these cars. We are going to set the window size on five minutes and the sliding size on every second. This means that we are computing the average speed over the last five minutes every second. \n```python\n>>> vehicles = vehicles[vehicles[\"type\"] == 6] \n>>> vehicles.sliding(size=5, size_unit=\"min\", slide=1, slide_unit=\"sec\").avg(on=\"value\", name=\"avg_speed\")\n```\n| start | end | avg_speed |\n| ----- | --- | --------- |\n| 0     | 5   | 24        |\n| 5     | 10  | 26        |\n| 10    | 15  | 25        |\n\nIf we anaylize this data stream for an entire day we can find out how the speed changes throughout the day. \nWe can also filter other vehicle types, e.g., underground, bus, trucks, and compare them to each other.\n\nAdditionally we can apply for example DBSCAN before using the window on each cluster. \nThis way we find out which areas are prone to traffic jams at a specific time of day. \nWe can write the DBSCAN algorithm by integrating other libaries. For this, we have to write a function like the following :\n```python\n>>> def my_dbscan_function(current_tuple):\n    # here comes the code for dbscan\n\n```\n**Note:** \n\nCurrently this function is the last function to be processed in the python pipeline. For this reason, we have to add the window functionality by hand right here too. Furthermore, we have to keep in mind that this function can only process one tuple at a time.\n\nWe use `.process(my_dbscan_function)` to apply dbscan and the window on our data stream:\n```python\n>>> vehicles.process(my_dbscan_function)\n```\n| cluster | start | stop | avg_speed |\n| ------- | ----- | ---- | --------- |\n| 1       | 0     | 5    | 52        | \n| 2       | 0     | 5    | 25        | \n| 2       | 0     | 5    | 17        | \n\n## Requirements\nOS: Ubuntu 20.04+ \\\nJupyter Notebook \\\nPython 3+ \n\n## Installation\n\n1. Install the python client with:\n```\npip install nespy\n```\n\n2. Run NebulaStream. There are two options: a) you start NebulaStream locally in CLion or b) you use docker.\n  #### a) Run NebulaStream with CLion\n\n  1. Build NebulaStream. To build NebulaStream please follow [this instruction](http://iotdb.dfki.de/doku.php?id=how_to_build_nes).\n  2. Start the Coordinator. If no parameters are configured the Coordinator starts with the default values. To configure the Coordinator please take a look [here](http://iotdb.dfki.de/doku.php?id=coordinator-configurations).\n  3. Start the Worker. Just like the Coordinator the Worker starts with default values unless the parameters are configured. To configure the Worker please take a look [here](http://iotdb.dfki.de/doku.php?id=worker-configurations) and to configure the sources take a look [here](http://iotdb.dfki.de/doku.php?id=sources-configurations).\n\n  #### b) Run the NebulaStream docker image\n  1. Install docker (https://docs.docker.com/get-docker/)\n  2. Pull the latest docker image with: \n  ```\n  docker pull nebulastream/nes-executable-image:latest\n  ```\t\n\n  or a specific version with: \n\n  ```\n  docker pull nebulastream/nes-executable-image:<version_number>\n  ```\n\n  3. Run the latest docker image with:\n\n  ```\n  docker run --network host --name nes nebulastream/nes-executable-image:latest\n  ``` \n\n  or \n\n  ```\n  docker run --network host --name nes nebulastream/nes-executable-image:<version_number> \n  ```\n\n  The following additional parameters are optional ([source](http://iotdb.dfki.de/doku.php?id=deployment)):\n\n  ##### Coordinator\t\n  | parameters       | default value          | description                                             |\n  | ---------------- | ---------------------- | ------------------------------------------------------- |\n  | -serverIp        | 127.0.0.1 |            | Set the IP address of the Coordinator  \t        |\n  | -coordinatorPort | 4000                   | Set the RPC Server port of the Coordinator           |\n  | -restPort \t     | 8081                   | Set the port exposed for REST endpoints                 |\n  | –numberOfSlots   | #processor in the host | Set the number of computing slots in the Coordinator |\n  | –help            |                        | Display help message                                    |\n\n\n  ##### Worker\n  | parameters     \t\t    | default value          | description                                           \t\t\t       |\n  | ------------------------------- | ---------------------- | ------------------------------------------------------------------------------- |\n  | –coordinatorIp   \t \t    | 127.0.0.1              | Set the server IP of the Coordinator to which the Worker should connect  |\n  | –coordinatorPort\t\t    | 0\t\t\t     | Set the RPC server Port of the Coordinator to which the Worker connected |\n  | –rpcPort \t\t            | 0\t\t\t     | Set the RPC server of the Worker \t\t                               |\n  | –dataPort \t  \t\t    | 0 \t             | Set the data port of the Worker                                              |\n  | –sourceType \t  \t    | \t\t\t     | Set the type of the Source (must be either CSVSource or DefaultSource)          |\n  | –sourceConfig   \t\t    |\t\t\t     | Set the configuration of the source (e.g., path to the CSV file)\t\t       |\n  | –sourceFrequency  \t\t    |                        | Set the sampling frequency of the source\t\t\t\t               |\n  | –physicalStreamName \t    | \t\t\t     | Set the physical name of the stream\t                                       |\n  | –numberOfBuffersToProduce       | \t                     | Set the number of buffers to produce\t\t\t\t\t       |\n  | –logicalStreamName \t\t    |\t\t\t     | Set the logical stream name where this stream is added to                       |\n  | –parentId\t\t\t    |\t\t\t     | Set the parentId of the Worker node\t   \t\t\t\t       |\n  | –localWorkerIp \t\t    | 127.0.0.1\t\t     | Set worker ip \t\t\t\t\t\t\t\t       |\n  | –numberOfSlots \t\t    | #processor in the host | Set the number of computing slots in the Worker \t\t\t       |\n  | –help \t\t\t    |\t\t             | Display help message\t\t\t\t\t\t\t       |\n\n  3. Open Jupyter Notebook, import the python client with \"import nespy as nes\", and get started \n\n## License\n[Apache License 2.0](https://github.com/nebulastream/darkNES/blob/main/LICENSE)\n## Documentation\n\n[1. Connect with NebulaStream](#connection)\n\n[2. Manage Data Streams ](#streamManagement)\n  * [Retrieving all Registered Logical Streams](#get_all_logical_streams)\n  * [Retrieving all Physical Streams for a Logical Stream](#get_all_physical_streams)\n  * [Selecting a Specific Logical Stream](#get_logical_stream)\n  * [Add Logical Stream](#add_logical_stream)\n  * [Update Logical Stream](#update_logical_stream)\n  * [Delete Logical Stream](#delete_logical_stream)\n\n[3. Process Data Streams](#streamProcessing)\n\n  * [Filter](#filter)\n  * [Map](#map)\n  * [Select/Projection](#select)\n  * [Rename](#rename)\n  * [Windows](#windows)\n    * [Keyed Window vs. Global Window](#keyed_vs_global)\n    * [Tumbling Windows](#tumbling)\n    * [Sliding Windows](#sliding)\n  * [Include other Python libraries](#include_other_libs)\n    * [Stream Processing](#process)\n    * [Batch processing with DataFrames](#batch) \n  * [Union](#union)\n  * [Join](#join)\n  * [Sinks](#sinks)\n\n[4. Plotting Data Streams with Nespy](#plotting)\n\n[5. Manage Queries](#queryManagement)\n  * [Stop a Running Query](#stop_query)\n  * [Retrieving All Registered Queries](#get_all_queries)\n  * [Retrieving All Queries with a Status](#get_queries_with_status)\n  * [Retrieve a Specific Query with a Status](#get_queries_with_status_at_pos)\n  * [Retrieving Execution Plan](#get_query_execution_plan)\n  * [Retrieving Query Plan](#get_query_plan)\n  * [Retrieve Topology](#get_nes_topology)\n\n<a name=\"connection\"></a>\n### 1.Connect with NebulaStream \n\nConnection is a class that manages the overall connection to NebulaStream.\n\n```python\nConnection(host, port)\n```\n\nExample: \n```python\n>>> c = ds.Connection('127.0.0.1', 8081)\n```\n\n<a name=\"streamManagement\"></a>\n### 2. Managing Data Streams\n\nAfter setting up the connection with NebulaStream the user can call different functions to gather information about the data stream itself and manage data streams.\n\n<a name=\"get_all_logical_streams\"></a>\n#### Retrieving all Registered Logical Streams\n```python\nConnection.get_all_logical_streams()\n```\n\nExample:\n```python\n>>> c.get.all_logical_streams()\n```\n<a name=\"get_all_physical_streams\"></a>\n#### Retrieving all Physical Streams for a Logical Stream\n```python\nConnection.get_all_physical_streams(logical_stream_name)\n```\nExample:\n```python\n>>> c.get_all_physical_streams(\"default_logical\")\n```\n\n<a name=\"get_logical_stream\"></a>\n#### Selecting a Specific Logical Stream\n```python\nConnection.get_logical_stream(position_or_name)\n```\n\nExample:\n```python\n>>> data_stream = c.get_logical_stream(0)\n```\nor\n```python\n>>> data_stream = c.get_logical_stream(\"default_logical\")\n>>> data_stream\n``` \n| id | value |\n| --- | ---  |\n| 0 | 1      |\n| 1 | 1      |\n| 2 | 1      |\n\n<a name=\"add_logical_stream\"></a>\n#### Add Logical Stream\n```python\nConnection.add_logical_stream(logical_stream_name, schema)\n```\n\nExample:\n```python\n>>> schema = \"Schema::create()->addField(\\\"test\\\",INT32);\"\n>>> c.add_logical_stream(\"new_logical_stream\", schema)\n{Success: True}\n```\n\n<a name=\"update_logical_stream\"></a>\n#### Update Logical Stream\n```python\nConnection.update_logical_stream(logical_stream_name, schema)\n```\n\nExample:\n```python\n>>> schema = \"Schema::create()->addField(\\\"test\\\",INT32);\"\n>>> c.update_logical_stream(\"default_logical\", schema):\n{Success: True}\n```\n\n<a name=\"delete_logical_stream\"></a>\n#### Delete Logical Stream\n```python\nConnection.delete_logical_stream(logical_stream_name)\n```\n\nExample:\n```python\n>>> c.delete_logical_stream(\"default_logical\")\n{Success: True}\n```\n\n<a name=\"streamProcessing\"></a>\n### 3. Process Data Streams\n\n<a name=\"filter\"></a>\n#### Filter\n```python\ndata_stream[filter_predicate]\n```\n\nExamples:\n```python\n>>> sensor[sensor[\"temperature\"] > 3]\n>>> sensor[sensor[\"temperature\"] < 3]\n>>> sensor[sensor[\"temperature\"] <= 3]\n>>> sensor[sensor[\"temperature\"] >= 3]\n>>> sensor[sensor[\"temperature\"] == 3]\n>>> sensor[sensor[\"temperature\"] != 3]\n>>> sensor[sensor[\"temperature\"] > sensor[\"humidity\"]\n>>> sensor[(sensor[\"temperature\"] > 3) & (sensor[\"temperature\"] < 15)]\n>>> sensor[(sensor[\"temperature\"] < 3) | (sensor[\"temperature\"] == 10)]\n```\n\n<a name=\"map\"></a>\n#### Map\n```python\ndata_stream[attribute_name] = new_value_for_this_attribute\n```\n\nExample:\n```python\n>>> sensor[\"temperature\"] = sensor[\"temperature\"] + 0.01\n>>> sensor[\"temperature\"] = sensor[\"temperature\"] - 0.01\n>>> sensor[\"temperature\"] = sensor[\"temperature\"] * 0.01\n>>> sensor[\"temperature\"] = sensor[\"temperature\"] / 0.01\n>>> sensor[\"temperature\"] = (sensor[\"sensor_a\"] + sensor[\"sensor_b\"]) / 2\n>>> sensor[\"temperature\"] = 0.01 * sensor[\"temperature\"]\n```\n\n<a name=\"select\"></a>\n#### Select (in SQL)/Projection (in relational algebra)\nFor a single selection you only have to write the name of the desired attribute as a string into the brackets. \nFor a multiple selection you write a list of attribute names as a string that you want to project.\n```python\ndata_stream[data_stream[attribute_name]]\ndata_stream[[attribute_name1, attribute_name2, attribute_name3]]\n```\n\nExample:\n```python\n>>> cars[cars[\"car_id\"]]\n>>> cars[[\"car_id\"]]\n>>> cars[[\"car_id\", \"speed\", \"lat\", \"lon\"]]\n```\n\n<a name=\"rename\"></a>\n#### Rename\nRename only works if the operator before rename was a projection. \nIt gives a temporary (not persisted!) name for the attribute.\n```python\ndata_stream.as({\"old_name\":\"new_name\"})\n```\n\nExample:\n```python\n>>> cars[[\"car_id\"]]\n>>> cars.rename({car_id\": \"id\"})\n```\n\n<a name=\"windows\"></a>\n#### Windows\nWindows allow to break a infinite data stream into finite data sets. As a result, we are then able to compute aggregations over these finite data sets.\nThe following aggregation functions are supported:\n  * sum(on, name)\n  * count(on, name)\n  * min(on, name)\n  * max(on, name)\n\n**Warning** : Do not try to rename the columns yet. This functionality isn't supported by NebulaStream yet!\nThe avg function is supported by NebulaStream soon! Please be patient :)\n\n| parameter |          | description                                   | default                                |\n| ----------| -------- | --------------------------------------------- | -------------------------------------- |\n| on        | required | declares on which attribute to aggregate over | -                                      |\n| name      | optional | name of the new column (not supported yet!)   | aggregation_attribute, e.g,  sum_value | \n\nIn this section, we will explain how to use keyed and non-keyed windows in our python client.\n\n<a name=\"keyed_vs_global\"></a>\n##### Keyed Windows vs. Global Windows\n\n###### Keyed Windows\nA key for a window can be any attribute of your data stream. \nWith keyed windows we can run multiple different windows and window aggregatins on one data stream. \nTherefore, a keyed window splits up a single data stream into multiple data streams to enable parallel computation. \n\n###### Global Windows\nGlobal windows are non-keyed windows. These window do not split a data stream into multiple data streams and therefore, they cannot compute multiple different aggregation function in parallel. \n\n<a name=\"tumbling\"></a>\n##### Tumbling Windows\n```python\nDataStream.tumbling(on, event, event_unit, size, size_unit, lateness, lateness_unit)\n```\n| parameter     |          | description                                                             | default value         |\n| ------------- | -------- | ----------------------------------------------------------------------- | --------------------- |\n| on            | required | key for the window, can be any attribute of the data stream, if not set this window is a global window | None |\n| event         | required | value decides on which attribute in the data stream is the event time   | 'timestamp'           |\n| event_unit    | optional | unit for the event, can only be 'min', 'sec', 'ms', and 'count'         | 'sec'                 |\n| size          | required | size of the window                                                      | 0 (meaning no window) |\n| size_unit     | required | unit of the parameter size, can only be 'min', 'sec', 'ms', and 'count' | 'sec'                 |\n| lateness      | optional | the allowed lateness of a tuple                                         | 0                     |\n| lateness_unit | optional | unit of the lateness, can only be 'min', 'sec', 'ms', and 'count'       | 'sec'                 |\n\n\nExample:\n```python\n>>> # keyed window\n>>> shop.tumbling(on=\"value\", size=10, size_unit=\"sec\").sum(on=\"sales\")\n\n>>> # global window\n>>> shop.tumbling(size=10, size_unit=\"sec\").sum(on=\"sales\")\n```\n<a name=\"sliding\"></a>\n##### Sliding Windows\n```python\nDataStream.sliding(on, event, event_unit, size=0, size_unit, slide, slide_unit, lateness, lateness_unit)\n```\n| parameter     |          | description                                                             | default value         |\n| ------------- | -------- | ----------------------------------------------------------------------- | --------------------- |\n| on            | optional | key for the window, can be any attribute of the data stream, if not set this window is a global window  | None |\n| event         | required | value decides on which attribute in the data stream is the event time   | 'timestamp'           |\n| event_unit    | optional | unit for the event, can only be 'min', 'sec', 'ms', and 'count'         | 'sec'                 |\n| size          | required | size of the window                                                      | 0 (meaning no window) |\n| size_unit     | required | unit of the parameter size, can only be 'min', 'sec', 'ms', and 'count' | 'sec'                 |\n| slide         | required | the slide value or the update rate of the window                        | 0 (meaning no slide)  |\n| slide_unit    | required | the unit of the slide value, can only be 'min', 'sec', 'ms', and 'count'| 'sec'                 |\n| lateness      | optional | the allowed lateness of a tuple                                         | 0                     |\n| lateness_unit | optional | unit of the lateness, can only be 'min', 'sec', 'ms', and 'count'       | 'sec'                 |\n\nExample:\n```python\n>>> # keyed window\n>>> shop.sliding(on=\"sales\", size=10, size_unit=\"sec\", slide=5, slide_unit=\"sec\").sum(on=\"sales\")\n\n>>> # global window\n>>> shop.sliding(size=10, size_unit=\"sec\", slide=5, slide_unit=\"sec\").sum(on=\"sales\")\n```\n\n<a name=\"include_other_libs\"></a>\n#### Include other Python libraries \n\n<a name=\"process\"></a>\n##### Stream Processing\n```python\n>>> def my_function(data):\n>>>     #do something with a single tuple\n>>>     return data\n>>> data_stream.process(my_function)\n```\n\n<a name=\"batch\"></a>\n##### Batch Processing with DataFrames\nThis function enables user to compute in batches over DataFrames. If on_time_over is set to True the batch function is triggered every time a tuple is added to the batch. Otherwise, we only trigger the batch function when the timeframe has reached it's time.\nCurrently, we only support 'sec', 'min', and 'h' as the timeframe_unit.\n```python\n>>> def my_function(data):\n>>>     #do something with a DataFrame\n>>>     return data\n>>>     \n>>> # We set the size of the buffer to 1 hour and only call the batch function my_function once after every hour.\n>>> data_stream.batch(my_function, timeframe=1, timeframe_unit='h, on_time_over=True) \n>>> data_stream.batch(my_function, timeframe=1, timeframe_unit='h, on_time_over=False) \n```\n\n\n<a name=\"union\"></a>\n#### Union\nUnion is the same as in relational algrebra and SQL. The schema of both data streams have to be the same.\n```python\nDataStream.union(other_stream)\n```\n\nExample:\n```python\n>>> bus = c.get_logical_stream(\"bus\")\n>>> cars = c.get_logical_stream(\"car\")\n>>> bus.union(car)\n```\n\n<a name=\"join\"></a>\n#### Join\nJoin works just like JOIN in SQL or the theta join in relational algebra.\nIf both of the data streams have an attribute with the same name, we can set the parameter \"on\".\nOtherwise, we have to set the parameter \"left_on\" and \"right_on\". \n```python\nDataStream.join(other_stream, on, left_on, right_on)\n```\n\nExample:\n```python\n>>> position = get_logical_stream(\"car_position\")\n>>> details = get_logical_stream(\"car_details\")\n>>> position.join(details, left_on=\"id\", right_on=\"car_id\")\n\n```\n\n<a name=\"sinks\"></a>\n#### Sinks\n\nNespy offers different types of sources:\n* ZMQ Sink\n* Kafka Sink\n* File Sink\n* Print Sink\n\nThe default source is using ZMQ. \n\nTo select other sink use:\n```python\nDataStream.set_sink(set_sink(sink, host, port, topic, brokers, timeout, path)\n```\n| parameter     |          | description                                                             | \n| ------------- | -------- | ----------------------------------------------------------------------- | \n| sink          | required | can only be \"zmq\", \"kafka\", \"file\" or \"print\" | \n| host         | required for ZMQ Sink | Host for ZMQ Sink | \n| port    | required for ZMQ Sink | Port for ZMQ Sink  | \n| topic          | required for Kafka Sink | Topic for Kafka Sink                                                | \n| brokers     | required for Kafka Sink | Brokers for Kafka Sink | \n| timout         | required for Kafka Sink | Timout for Kafka Sink        | \n| path    | required for File Sink | Path to where the result should be saved | \n\n<a name=\"plotting\"></a>\n### 4. Plotting Data Streams with Nespy\n\nTBD\n\n<a name=\"queryManagement\"></a>\n### 5. Manage Queries\n\n<a name=\"stop_query\"></a>\n#### Stop a Running Query\n```python\nDataStream.stop_query()\n```\n\nExample:\n```python\n>>> data_stream.stop_query()\n```\n#### Reset All Operators of a Query\nThis function resets all operators saved for this variable and also stops the running query. Therefore, the user can reuse this variable for another query.\n```python\nDataStream.reset_operators()\n```\n\nExample:\n```python\n>>> data_stream_reset_operators()\n```\n\n<a name=\"get_all_queries\"></a>\n#### Retrieving All Registered Queries\n```python\nConnection.get_all_queries()\n```\n\nExample:\n```python\n>>> c.get_all_queries()\n{\n            \"edges\": [\n                {\n                    \"source\": \"UNDEFINED(OP-2)\",\n                    \"target\": \"SINK(OP-3)\"\n                },\n                {\n                    \"source\": \"SOURCE(OP-1)\",\n                    \"target\": \"UNDEFINED(OP-2)\"\n                }\n            ],\n            \"nodes\": [\n                {\n                    \"id\": \"3\",\n                    \"name\": \"SINK(OP-3)\",\n                    \"nodeType\": \"SINK\"\n                },\n                {\n                    \"id\": \"2\",\n                    \"name\": \"UNDEFINED(OP-2)\",\n                    \"nodeType\": \"UNDEFINED\"\n                },\n                {\n                    \"id\": \"1\",\n                    \"name\": \"SOURCE(OP-1)\",\n                    \"nodeType\": \"SOURCE\"\n                }\n            ]\n        }\n```\n\n<a name=\"get_queries_with_status\"></a>\n#### Retrieving All Queries with a Status\n```python\nConnection.get_queries_with_status(status)\n```\n\nExample:\n```python\n>>> registered = c.get_queries_with_status(\"Registered\")\n>>> scheduling = c.get_queries_with_status(\"Scheduling\")\n>>> running = c.get_queries_with_status(\"Running\")\n>>> marked_for_stopped = c.get_queries_with_status(\"MarkedForStop\")\n>>> stopped = c.get_queries_with_status(\"Stopped\")\n>>> failed = c.get_queries_with_status(\"Failed\")\n>>> running\n[null, \"Query::from(\\\"default_logical\\\").project(Attribute(\\\"id\\\")).sink(PrintSinkDescriptor::create());\"\n```\n\n<a name=\"get_queries_with_status_at_pos\"></a>\n#### Retrieve a Specific Query with a Status\n```python\nConnection.get_queries_with_status_at_pos(status, pos)\n```\n\nExample:\n```python\n>>> c.get_queries_with_status_at_pos(\"Running\", 1)\nQuery::from(\"default_logical\").project(Attribute(\"id\")).sink(PrintSinkDescriptor::create());\n```\n\n<a name=\"get_query_execution_plan\"></a>\n#### Retrieving Execution Plan\n```python\nConnection.get_query_execution_plan(queryId)\n```\n\nExample:\n```python\n>>> data_stream = c.get_logical_stream(\"default_logical\")\n>>> data_stream[\"id\"] \n```\n| id | \n| --- | \n| 0 | \n| 1 | \n| 2 | \n\n```python\n>>> data_stream.get_query_execution_plan()\n{\n            \"executionNodes\": [\n                {\n                    \"ScheduledQueries\": [\n                        {\n                            \"queryId\": 1,\n                            \"querySubPlans\": [\n                                {\n                                    \"operator\": \"SINK(5)\\n  PROJECTION(2, schema=default_logical$id:INTEGER )\\n    \"\n                                                \"SOURCE(1,default_logical)\\n\",\n                                    \"querySubPlanId\": 1\n                                }\n                            ]\n                        }\n                    ],\n                    \"executionNodeId\": 2,\n                    \"topologyNodeId\": 2,\n                    \"topologyNodeIpAddress\": \"127.0.0.1\"\n                },\n                {\n                    \"ScheduledQueries\": [\n                        {\n                            \"queryId\": 1,\n                            \"querySubPlans\": [\n                                {\n                                    \"operator\": \"SINK(3)\\n  SOURCE(4,)\\n\",\n                                    \"querySubPlanId\": 2\n                                }\n                            ]\n                        }\n                    ],\n                    \"executionNodeId\": 1,\n                    \"topologyNodeId\": 1,\n                    \"topologyNodeIpAddress\": \"127.0.0.1\"\n                }\n            ]\n        }\n```\n\n\n<a name=\"get_query_plan\"></a>\n#### Retrieving Query Plan\n```python\nConnection.get_query_plan(queryId)\n```\n\nExample:\n```python\n>>> data_stream = c.get_logical_stream(\"default_logical\")\n>>> data_stream[\"id\"] \n```\n| id | \n| --- | \n| 0 | \n| 1 | \n| 2 | \n\n```python\n>>> data_stream.get_query_plan(queryId)\n{\n            \"edges\": [\n                {\n                    \"source\": \"UNDEFINED(OP-2)\",\n                    \"target\": \"SINK(OP-3)\"\n                },\n                {\n                    \"source\": \"SOURCE(OP-1)\",\n                    \"target\": \"UNDEFINED(OP-2)\"\n                }\n            ],\n            \"nodes\": [\n                {\n                    \"id\": \"3\",\n                    \"name\": \"SINK(OP-3)\",\n                    \"nodeType\": \"SINK\"\n                },\n                {\n                    \"id\": \"2\",\n                    \"name\": \"UNDEFINED(OP-2)\",\n                    \"nodeType\": \"UNDEFINED\"\n                },\n                {\n                    \"id\": \"1\",\n                    \"name\": \"SOURCE(OP-1)\",\n                    \"nodeType\": \"SOURCE\"\n                }\n            ]\n        }\n```\n\n<a name=\"get_nes_topology\"></a>\n#### Retrieve Topology\n```python\nConnection.get_nes_topology()\n```\n\nExample:\n```python\n>>> c.get_nes_topology()\n{\n    \"edges\": [\n        {\n            \"source\": 2,\n            \"target\": 1\n        }\n    ],\n    \"nodes\": [\n        {\n            \"available_resources\": 65535,\n            \"id\": 1,\n            \"ip_address\": \"127.0.0.1\"\n        },\n        {\n            \"available_resources\": 8,\n            \"id\": 2,\n            \"ip_address\": \"127.0.0.1\"\n        }\n    ]\n}\n```\n\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://www.nebula.stream/",
    "keywords": "NebulaStream,NES,nespy,nebulastream-python-client,data science,IoT,data streams,data stream management",
    "license": "Apache License 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "nespy",
    "package_url": "https://pypi.org/project/nespy/",
    "platform": "",
    "project_url": "https://pypi.org/project/nespy/",
    "project_urls": {
      "Homepage": "https://www.nebula.stream/",
      "Source Code": "https://github.com/nebulastream/nebulastream-python-client"
    },
    "release_url": "https://pypi.org/project/nespy/0.0.6/",
    "requires_dist": [
      "requests (>=2.25)",
      "pyzmq (>=22)",
      "pandas (>=1)",
      "ipython (>=6)",
      "google (>=3)",
      "protobuf (>=3)"
    ],
    "requires_python": ">=3.6",
    "summary": "Python Client for NebulaStream",
    "version": "0.0.6",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12021969,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bed6454f084806daa845f5e3cfc024044ee39e56fe71067981c941acd14510d8",
          "md5": "2ff877ec9066faf44ab1ef0f755588d4",
          "sha256": "ae56c92652025f621ce23df6a6461b02dfb8d92bc83e6abe598ed1ec655be4da"
        },
        "downloads": -1,
        "filename": "nespy-0.0.1-py3.8.egg",
        "has_sig": false,
        "md5_digest": "2ff877ec9066faf44ab1ef0f755588d4",
        "packagetype": "bdist_egg",
        "python_version": "0.0.1",
        "requires_python": ">=3.6",
        "size": 84817,
        "upload_time": "2021-04-26T20:47:31",
        "upload_time_iso_8601": "2021-04-26T20:47:31.344978Z",
        "url": "https://files.pythonhosted.org/packages/be/d6/454f084806daa845f5e3cfc024044ee39e56fe71067981c941acd14510d8/nespy-0.0.1-py3.8.egg",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6828355017e1c9de636cc91727a11c9a4fc4264f1a1a7a3e2e4ab35b2abc39b8",
          "md5": "fae0260aeb5260dd488d1f95d0830b00",
          "sha256": "fe24b34012ad07b5a8361ba56c8e26a8e5ea88d031ebf81e90534e85785cbd06"
        },
        "downloads": -1,
        "filename": "nespy-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "fae0260aeb5260dd488d1f95d0830b00",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 53658,
        "upload_time": "2021-04-26T20:47:34",
        "upload_time_iso_8601": "2021-04-26T20:47:34.943794Z",
        "url": "https://files.pythonhosted.org/packages/68/28/355017e1c9de636cc91727a11c9a4fc4264f1a1a7a3e2e4ab35b2abc39b8/nespy-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d9566ff3d369c166fc5d8bf915a1d49a40a480b516726091985103e6ff1113bf",
          "md5": "093e406c26e900775e2c3981e24235a6",
          "sha256": "47c3343c06d3ea3c82af3da9e2edd6db3c48b8f8cb34dd611fd53051d3d02802"
        },
        "downloads": -1,
        "filename": "nespy-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "093e406c26e900775e2c3981e24235a6",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 53703,
        "upload_time": "2021-04-26T21:02:45",
        "upload_time_iso_8601": "2021-04-26T21:02:45.266802Z",
        "url": "https://files.pythonhosted.org/packages/d9/56/6ff3d369c166fc5d8bf915a1d49a40a480b516726091985103e6ff1113bf/nespy-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "62be18e0435005dd6214d3fdb7e38087a55b7e44e31b9c3bb353702653bd7f32",
          "md5": "f31e8cd43cac8d1e1935213ce90c8be6",
          "sha256": "16416ed651d6aba65bd15efc349fa5019fb038605edc78e9c9bdd4e9ea014877"
        },
        "downloads": -1,
        "filename": "nespy-0.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f31e8cd43cac8d1e1935213ce90c8be6",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 49860,
        "upload_time": "2021-05-07T15:57:24",
        "upload_time_iso_8601": "2021-05-07T15:57:24.004349Z",
        "url": "https://files.pythonhosted.org/packages/62/be/18e0435005dd6214d3fdb7e38087a55b7e44e31b9c3bb353702653bd7f32/nespy-0.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fd02395c57674cb0bcdbaacc6c73e125b050778160d7468968d17021a4238b76",
          "md5": "2f468d3f2b151108f1f5aa41829f2e57",
          "sha256": "d61289cea295b3396c7ed34a1e2851f1908e67d42e7bb269e7783d65da8e7131"
        },
        "downloads": -1,
        "filename": "nespy-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "2f468d3f2b151108f1f5aa41829f2e57",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 53761,
        "upload_time": "2021-05-07T15:57:29",
        "upload_time_iso_8601": "2021-05-07T15:57:29.706846Z",
        "url": "https://files.pythonhosted.org/packages/fd/02/395c57674cb0bcdbaacc6c73e125b050778160d7468968d17021a4238b76/nespy-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "19e6cbdd6626e73e632cd9d951eadf890b38a8758b4e746868a8e69dc5834685",
          "md5": "712c59965049a58f82a4372b7a831cf1",
          "sha256": "d132ff8e695583ec4bfc08e273894d53f988ab84b0a2bf9c5554673ce1b10d10"
        },
        "downloads": -1,
        "filename": "nespy-0.0.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "712c59965049a58f82a4372b7a831cf1",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 49861,
        "upload_time": "2021-05-18T13:30:19",
        "upload_time_iso_8601": "2021-05-18T13:30:19.517496Z",
        "url": "https://files.pythonhosted.org/packages/19/e6/cbdd6626e73e632cd9d951eadf890b38a8758b4e746868a8e69dc5834685/nespy-0.0.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e1b0519f1792d783a75a7497e4c8bfcbcade1dcd3361b73de07cf643f4fd9f72",
          "md5": "7174dfe20bb09014ddc9dab4ea7505da",
          "sha256": "fe496b030735a53d200677dfcad08c190eb644086f236865864bf4e965695e4c"
        },
        "downloads": -1,
        "filename": "nespy-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "7174dfe20bb09014ddc9dab4ea7505da",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 53644,
        "upload_time": "2021-05-18T13:30:27",
        "upload_time_iso_8601": "2021-05-18T13:30:27.022953Z",
        "url": "https://files.pythonhosted.org/packages/e1/b0/519f1792d783a75a7497e4c8bfcbcade1dcd3361b73de07cf643f4fd9f72/nespy-0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7f67e3f5f049af6a69204ab856767eac650e7f47430ecf1bf7a2235f8da25db0",
          "md5": "e6d380215188c72d8d8b4bc54f1099e7",
          "sha256": "974419f1f5674917eaf13354d3509768c6bd950e55a60b4c060e741d090d8bbf"
        },
        "downloads": -1,
        "filename": "nespy-0.0.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "e6d380215188c72d8d8b4bc54f1099e7",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 50062,
        "upload_time": "2021-05-18T13:50:13",
        "upload_time_iso_8601": "2021-05-18T13:50:13.022253Z",
        "url": "https://files.pythonhosted.org/packages/7f/67/e3f5f049af6a69204ab856767eac650e7f47430ecf1bf7a2235f8da25db0/nespy-0.0.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ec947721013cc94597d781935075940b0448edc9da9b757a94f5e6d9aef499d5",
          "md5": "d2ecfe291de5f81c8ec5cb929c3c7367",
          "sha256": "dc23aea6232e79ad5c112fd0abd687f358ce54ab8a5d51b9116b20a565682991"
        },
        "downloads": -1,
        "filename": "nespy-0.0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "d2ecfe291de5f81c8ec5cb929c3c7367",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 54504,
        "upload_time": "2021-05-18T13:50:21",
        "upload_time_iso_8601": "2021-05-18T13:50:21.958164Z",
        "url": "https://files.pythonhosted.org/packages/ec/94/7721013cc94597d781935075940b0448edc9da9b757a94f5e6d9aef499d5/nespy-0.0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "eb877413c88805346aedec1c9c991ad1759b6bceb54112d228ad5752e661178f",
          "md5": "2ad6a7abeed6687130da9d2c260c2464",
          "sha256": "25ba0d4cf8b1649d4fcb252c7f31970b9e1b61da1e7ba6f83c3884d6598540b4"
        },
        "downloads": -1,
        "filename": "nespy-0.0.6-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "2ad6a7abeed6687130da9d2c260c2464",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 53461,
        "upload_time": "2021-11-15T00:28:11",
        "upload_time_iso_8601": "2021-11-15T00:28:11.477499Z",
        "url": "https://files.pythonhosted.org/packages/eb/87/7413c88805346aedec1c9c991ad1759b6bceb54112d228ad5752e661178f/nespy-0.0.6-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c03a2851ac83d087372ae548fdc855ef8f87305121217f0a595bd2efe6cd65a6",
          "md5": "090391758c9757609ea8874e1bfaa2ea",
          "sha256": "0af43e26e2db5abb54fa99f2bcbf7c15f4e0da2490c98c2715eb85ae30b71f1e"
        },
        "downloads": -1,
        "filename": "nespy-0.0.6.tar.gz",
        "has_sig": false,
        "md5_digest": "090391758c9757609ea8874e1bfaa2ea",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 59152,
        "upload_time": "2021-11-15T00:28:24",
        "upload_time_iso_8601": "2021-11-15T00:28:24.377384Z",
        "url": "https://files.pythonhosted.org/packages/c0/3a/2851ac83d087372ae548fdc855ef8f87305121217f0a595bd2efe6cd65a6/nespy-0.0.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "eb877413c88805346aedec1c9c991ad1759b6bceb54112d228ad5752e661178f",
        "md5": "2ad6a7abeed6687130da9d2c260c2464",
        "sha256": "25ba0d4cf8b1649d4fcb252c7f31970b9e1b61da1e7ba6f83c3884d6598540b4"
      },
      "downloads": -1,
      "filename": "nespy-0.0.6-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "2ad6a7abeed6687130da9d2c260c2464",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 53461,
      "upload_time": "2021-11-15T00:28:11",
      "upload_time_iso_8601": "2021-11-15T00:28:11.477499Z",
      "url": "https://files.pythonhosted.org/packages/eb/87/7413c88805346aedec1c9c991ad1759b6bceb54112d228ad5752e661178f/nespy-0.0.6-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "c03a2851ac83d087372ae548fdc855ef8f87305121217f0a595bd2efe6cd65a6",
        "md5": "090391758c9757609ea8874e1bfaa2ea",
        "sha256": "0af43e26e2db5abb54fa99f2bcbf7c15f4e0da2490c98c2715eb85ae30b71f1e"
      },
      "downloads": -1,
      "filename": "nespy-0.0.6.tar.gz",
      "has_sig": false,
      "md5_digest": "090391758c9757609ea8874e1bfaa2ea",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 59152,
      "upload_time": "2021-11-15T00:28:24",
      "upload_time_iso_8601": "2021-11-15T00:28:24.377384Z",
      "url": "https://files.pythonhosted.org/packages/c0/3a/2851ac83d087372ae548fdc855ef8f87305121217f0a595bd2efe6cd65a6/nespy-0.0.6.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}