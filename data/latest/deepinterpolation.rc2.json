{
  "info": {
    "author": "Jerome Lecoq",
    "author_email": "jeromel@alleninstitute.org",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "license plus clause a third clause that prohibits redistribution and use for \ncommercial purposes without further permission. \n\nCopyright © 2019. Allen Institute.  All rights reserved.\n\nRedistribution and use in source and binary forms, with or without \nmodification, are permitted provided that the following conditions are met:\n\n1. Redistributions of source code must retain the above copyright notice, this \nlist of conditions and the following disclaimer.\n\n2. Redistributions in binary form must reproduce the above copyright notice, \nthis list of conditions and the following disclaimer in the documentation \nand/or other materials provided with the distribution.\n\n3. Redistributions and use for commercial purposes are not permitted without \nthe Allen Institute’s written permission. For purposes of this license, \ncommercial purposes are the incorporation of the Allen Institute's software \ninto anything for which you will charge fees or other compensation or use of \nthe software to perform a commercial service for a third party. Contact \nterms@alleninstitute.org for commercial licensing opportunities.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND \nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED \nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE \nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE \nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL \nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR \nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER \nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, \nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE \nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nDescription: .. image:: https://circleci.com/gh/AllenInstitute/deepinterpolation.svg?style=svg\n            :target: https://circleci.com/gh/AllenInstitute/deepinterpolation\n        \n        \n        # Deep Interpolation\n        \n        \n        *deepinterpolation* is a Python library to denoise data by removing independent noise. Importantly training does **NOT** require ground truth. This repository is currently meant to support the bioRxiv publication results : https://www.biorxiv.org/content/10.1101/2020.10.15.341602v1\n        \n        \n        # Principle of Deep Interpolation\n        \n        \n        .. image:: /docs/principle.png\n            :alt: principle of deep interpolation\n            :width: 100 px\n        \t\n        **Figure 1** - Schematic introducing the principles of deep interpolation.  **A**. An interpolation model is trained to predict a noisy block from other blocks with independent noise. The loss is the difference between the predicted data and a new noisy block. **B**. The interpolation model is used to create a noiseless version of the input data. \n        \n        For more information, consult the associated bioRxiv publication : https://www.biorxiv.org/content/10.1101/2020.10.15.341602v1\n        \n        \n        # Support\n        \n        \n        For bug and issues, please submit issue tickets on this repository. \n        For installation and running support, join the slack channel (if invitation has expired: email to Jerome): https://join.slack.com/t/deepinterpolation/shared_invite/zt-rkmcw7h1-v8y0Grwe3fZg4m~DiAQVMg\n        \n        \n        # Installation\n        \n        \n        The following outlines how to install on your local machine. This should take no more than a few minutes. This was tested on a macOS Catalina but should be adapted depending on your final environment (institution cluster, AWS EC2 instance, ...). Tensorflow made a lot of progress lately to install GPU dependencies. However, you might have to consult tensorflow documentation to enable your GPU. The small training example below works on both CPU and GPU architecture (ie. even a small macbook). If you are not familiar with using deep learning, we recommend to play with smaller datasets first, such as the example Neuropixels data provided. \n        \n        1. Clone the repository locally on a directory 'local_dir'\n        git clone https://github.com/AllenInstitute/deepinterpolation.git\n        \n        2. Go to that directory::\n        \n            cd 'local_dir'\n        \n        3. Create new conda environment called 'local_env'::\n            conda create -n local_env python=3.8\n        \n        4. activate environment::\n        \n        \tconda activate local_env\n        \n        5. install necessary packages::\n        \n        \tmake init\n        \n        6. install deepinterpolation package::\n        \n        \tpython setup.py install\n        \n        \n        # General code description\n        \n        \n        The files in the deepinterpolation folder contains the core classes for training, inferrence, loss calculation and network generations. Those are called 'Collection'. Each collection is essentially a local list of functions that are used to create different type of objects and can be extended on one another. \n        For instance, the network_collection.py contains a list of networks that can be generated for training. This allows for quick iteration and modification of an architecture while keeping the code organized. \n        \n        \n        # FAQ\n        \n        \n        See here : https://github.com/AllenInstitute/deepinterpolation/tree/master/faq\n        \n        \n        # Training\n        \n        To adapt DeepInterpolation to a new dataset, you will need to use or recreate a generator in 'generator_collection.py'. Those are all constructed from a core class called 'DeepGenerator'. The 'CollectorGenerator' class allows to group generators if your dataset is distributed across many files/folder/sources. \n        This system was designed to allow to train very large DeepInterpolation models from TB of data distributed on a network infrastructure. \n        \n        To try out training your own DeepInterpolation network, we recommend to start with this file: https://github.com/AllenInstitute/deepinterpolation/blob/master/examples/example_tiny_ephys_training.py\n        \n        In this file, you will need to edit the jobdir variable, in particular change \"/Users/jeromel/test\" to a local folder appropriate to save your models. \n        \n        Then, activate your conda env called 'local_env'::\n        \n        \tconda activate local_env\n        \t\n        then run::\n        \n        \tpython example_tiny_ephys_training.py\n        \n        If everything runs correctly, you should see the following in just a few minutes : ::\n        \n        \t2020-10-19 18:01:03.735098: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n        \tTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n        \tsh: sysctl: command not found\n        \t2020-10-19 18:01:03.749184: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9b1f115860 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n        \t2020-10-19 18:01:03.749202: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n        \tWARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n        \tEpoch 1/5\n        \t10/10 [==============================] - 19s 2s/step - loss: 0.4597 - val_loss: 0.3987\n        \tEpoch 2/5\n        \t10/10 [==============================] - 20s 2s/step - loss: 0.3796 - val_loss: 0.3785\n        \tEpoch 3/5\n        \t10/10 [==============================] - 22s 2s/step - loss: 0.3646 - val_loss: 0.3709\n        \tEpoch 4/5\n        \t10/10 [==============================] - 21s 2s/step - loss: 0.3797 - val_loss: 0.3698\n        \tEpoch 5/5\n        \t10/10 [==============================] - 21s 2s/step - loss: 0.3835 - val_loss: 0.3675\n        \tSaved model to disk\n        \n        This is a toy example but you can increase the number of training frames to increase the quality of the model. \n        All parameters are commented in the file. To adjust to a larger dataset, change the train_path parameters, the start_frame and end_frame parameters. \n        \n        \n        # Inference\n        \n        \n        Raw pre-trained models are available either as part of Tensorflow ModelServer in an AWS docker environment or as a separate h5 file on Dropbox. \n        \n        The following models are currently available : \n        \n        **Two-photon Ai93 excitatory line DeepInterpolation network:**\n        \n        Key recording parameters: \n        \n        - 30Hz sampling rate, 400x400 μm2 field of view, 512x512 pixels.\n        - 0.8 NA objective.\n        - 910 nm excitation wavelength.\n        - Gcamp6f calcium indicator.\n        - Ai93 reporter line expressed in excitatory neurons.\n        - Docker hub id : 245412653747/deep_interpolation:allen_400um_512pix_30hz_ai93\n        - Dropbox link : https://www.dropbox.com/sh/vwxf1uq2j60uj9o/AAC9BQI1bdfmAL3OFO0lmVb1a?dl=0\n        - Training data : https://github.com/AllenInstitute/deepinterpolation/blob/master/examples/paper_generation_code/json_data/2019-09-05-train-very-large-single-plane-Ai93-norm.json\n        \n        **Two-photon Ai148 excitatory line DeepInterpolation network:**\n        \n        Key recording parameters: \n        \n        - 30 Hz sampling rate, 400x400 μm2 field of view, 512x512 pixels.\n        - 0.8 NA objective.\n        - 910 nm excitation wavelength.\n        - Gcamp6f calcium indicator.\n        - Ai148 reporter line expressed in excitatory neurons.\n        - Pre-processing: Individual movies were motion corrected. Each movie recording was mean-centered and normalized with a single pair of value for all pixels \n        - Docker hub id : 245412653747/deep_interpolation:allen_400um_512pix_30hz_ai148\n        - Dropxbox link : https://www.dropbox.com/sh/u9h9mhppkmku5bs/AAD9UoomhB3D4JfLV7zT9Y_Ca?dl=0\n        - Training data : https://github.com/AllenInstitute/deepinterpolation/blob/master/examples/paper_generation_code/json_data/2019-09-05-train-very-large-single-plane-Ai148-norm.json\n        \n        **Neuropixel DeepInterpolation network:**\n        \n        Key recording parameters: \n        \n        - Neuropixels Phase 3a probes\n        - 374 simultaneous recording sites across 3.84 mm, 10 reference channels\n        - Four-column checkerboard site layout with 20 µm spacing between rows\n        - 30 kHz sampling rate\n        - 500x hardware gain setting\n        - 500 Hz high pass filter in hardware, 150 Hz high-pass filter applied offline. \n        - Pre-processing: Median subtraction was applied to individual probes to remove signals that were common across all recording sites. Each probe recording was mean-centered and normalized with a single pair of value for all nodes on the probe. \n        - Docker hub id : 245412653747/deep_interpolation:allen_neuropixel\n        - Dropxbox link : https://www.dropbox.com/sh/tm3epzil44ybalq/AACyKxfvvA2T_Lq_rnpHnhFma?dl=0\n        \n        **fMRI DeepInterpolation network:**\n        \n        Key recording parameters: \n        \n        - TR, 3000 ms; TE, 30 ms; flip angle, 80°; voxel size, 3 × 3 × 3 mm; FOV, 192 × 192 mm; number of slices, 50, slice gap, 0 mm\n        - Pre-processing: N/A\n        - Docker hub id : 245412653747/deep_interpolation:allen_3_3_3_tr_3000_fmri\n        - Dropxbox link : https://www.dropbox.com/sh/ngx5plndmd4jsca/AAAkR-_4_E7VyL8WzEC7twuza?dl=0\n        \n        To start inference, we recommend to start with this file: https://github.com/AllenInstitute/deepinterpolation/blob/master/examples/example_tiny_ephys_inference.py\n        \n        In this file, you will need to edit the train_path, model_path and output_file variable to fit your local paths. \n        \n        Then, activate your conda env called 'local_env'::\n        \n        \tconda activate local_env\n        \t\n        then run ::\n        \n        \tpython example_tiny_ephys_inference.py\n        \n        If everything runs correctly, you should see the following in just a few minutes : ::\n        \n        \t2020-10-20 14:10:37.549061: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n        \tTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n        \tsh: sysctl: command not found\n        \t2020-10-20 14:10:37.564133: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f82ada8a520 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n        \t2020-10-20 14:10:37.564156: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n        \n        This is a toy example but you can increase the start_frame and end_frame variable for larger data. \n        It is important to keep in mind that this process is easily parallelizable. In practice, we wrapped this code with additional routines to leverage 20 to 100 cluster CPU nodes to accelerate this process. You could also use GPU nodes as well, we just had access to a much larger number of CPU machines quickly.  \n        \n        More on using the Tensorflow ModelServer soon. Those are usefull to deploy to AWS and/or avoid installing GPUs related packages. \n        \n        \n        # License\n        \n        \n        Allen Institute Software License – This software license is the 2-clause BSD \n        license plus clause a third clause that prohibits redistribution and use for \n        commercial purposes without further permission. \n        \n        Copyright © 2019. Allen Institute.  All rights reserved.\n        \n        Redistribution and use in source and binary forms, with or without \n        modification, are permitted provided that the following conditions are met:\n        \n        1. Redistributions of source code must retain the above copyright notice, this \n        list of conditions and the following disclaimer.\n        \n        2. Redistributions in binary form must reproduce the above copyright notice, \n        this list of conditions and the following disclaimer in the documentation \n        and/or other materials provided with the distribution.\n        \n        3. Redistributions and use for commercial purposes are not permitted without \n        the Allen Institute’s written permission. For purposes of this license, \n        commercial purposes are the incorporation of the Allen Institute's software \n        into anything for which you will charge fees or other compensation or use of \n        the software to perform a commercial service for a third party. Contact \n        terms@alleninstitute.org for commercial licensing opportunities.\n        \n        THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND \n        ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED \n        WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE \n        DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE \n        FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL \n        DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR \n        SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER \n        CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, \n        OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE \n        OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n        \nPlatform: UNKNOWN\nDescription-Content-Type: text/x-rst\n",
    "description_content_type": "",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/AllenInstitute/deepinterpolation",
    "keywords": "",
    "license": "Allen Institute Software License – This software license is the 2-clause BSD",
    "maintainer": "",
    "maintainer_email": "",
    "name": "deepinterpolation",
    "package_url": "https://pypi.org/project/deepinterpolation/",
    "platform": "",
    "project_url": "https://pypi.org/project/deepinterpolation/",
    "project_urls": {
      "Homepage": "https://github.com/AllenInstitute/deepinterpolation"
    },
    "release_url": "https://pypi.org/project/deepinterpolation/0.1.4/",
    "requires_dist": [
      "tensorflow (==2.4.4)",
      "nibabel",
      "h5py (==2.10.0)",
      "matplotlib",
      "numpy",
      "python-dateutil",
      "scipy",
      "tifffile",
      "s3fs",
      "argschema (==2.0.2)",
      "mlflow (==1.14.1)"
    ],
    "requires_python": "",
    "summary": "Implemenent DeepInterpolation to denoise data by removing independent noise",
    "version": "0.1.4",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12096013,
  "releases": {
    "0.1.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f4000b18c214ccd26027615cffcb69970ecd2e0091ce19d99e1992d801cebc97",
          "md5": "5dbe86ec878ca9753e9ff7e46dfc7a17",
          "sha256": "6acb5bf9ea3fef6d092668805df6ee4ce6d93d76e620737aa510a03aa5be6d51"
        },
        "downloads": -1,
        "filename": "deepinterpolation-0.1.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "5dbe86ec878ca9753e9ff7e46dfc7a17",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 33542,
        "upload_time": "2021-11-22T21:26:39",
        "upload_time_iso_8601": "2021-11-22T21:26:39.777290Z",
        "url": "https://files.pythonhosted.org/packages/f4/00/0b18c214ccd26027615cffcb69970ecd2e0091ce19d99e1992d801cebc97/deepinterpolation-0.1.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9ba7199b6d6f2030f1f67ebf7869e8f2cfe9c7c8cc6e0eca468a124c32608365",
          "md5": "0f7564e79724f76813d15ecf1c004c65",
          "sha256": "478a4d24f7518d6bf7edbde7e64273814c9af2a27d6115fab30d6641671e91a4"
        },
        "downloads": -1,
        "filename": "deepinterpolation-0.1.3.tar.gz",
        "has_sig": false,
        "md5_digest": "0f7564e79724f76813d15ecf1c004c65",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 33978,
        "upload_time": "2021-11-22T21:26:43",
        "upload_time_iso_8601": "2021-11-22T21:26:43.410577Z",
        "url": "https://files.pythonhosted.org/packages/9b/a7/199b6d6f2030f1f67ebf7869e8f2cfe9c7c8cc6e0eca468a124c32608365/deepinterpolation-0.1.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "dd716317fe363f7c47d833fd4260278a449dad5a5efeab4e450a71816bf494ea",
          "md5": "45c94c091dea21e37c1d2f07821a8bad",
          "sha256": "6f04c1a576f8eb49a9a501e926fb08b00133430d415ca332aeea0e496317220d"
        },
        "downloads": -1,
        "filename": "deepinterpolation-0.1.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "45c94c091dea21e37c1d2f07821a8bad",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 33578,
        "upload_time": "2021-11-22T21:26:41",
        "upload_time_iso_8601": "2021-11-22T21:26:41.378015Z",
        "url": "https://files.pythonhosted.org/packages/dd/71/6317fe363f7c47d833fd4260278a449dad5a5efeab4e450a71816bf494ea/deepinterpolation-0.1.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e68a3f414e2387f5fdb1fbba08a4d99fe2ce1c643bff602634d565a139142986",
          "md5": "4a5b81faddbe00f375174770e7ae7d59",
          "sha256": "3bf46dfdc8449f86cd94ec2648d80324f726404dcdda46a448186e869beeb720"
        },
        "downloads": -1,
        "filename": "deepinterpolation-0.1.4.tar.gz",
        "has_sig": false,
        "md5_digest": "4a5b81faddbe00f375174770e7ae7d59",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 33893,
        "upload_time": "2021-11-22T21:26:45",
        "upload_time_iso_8601": "2021-11-22T21:26:45.399233Z",
        "url": "https://files.pythonhosted.org/packages/e6/8a/3f414e2387f5fdb1fbba08a4d99fe2ce1c643bff602634d565a139142986/deepinterpolation-0.1.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "dd716317fe363f7c47d833fd4260278a449dad5a5efeab4e450a71816bf494ea",
        "md5": "45c94c091dea21e37c1d2f07821a8bad",
        "sha256": "6f04c1a576f8eb49a9a501e926fb08b00133430d415ca332aeea0e496317220d"
      },
      "downloads": -1,
      "filename": "deepinterpolation-0.1.4-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "45c94c091dea21e37c1d2f07821a8bad",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 33578,
      "upload_time": "2021-11-22T21:26:41",
      "upload_time_iso_8601": "2021-11-22T21:26:41.378015Z",
      "url": "https://files.pythonhosted.org/packages/dd/71/6317fe363f7c47d833fd4260278a449dad5a5efeab4e450a71816bf494ea/deepinterpolation-0.1.4-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "e68a3f414e2387f5fdb1fbba08a4d99fe2ce1c643bff602634d565a139142986",
        "md5": "4a5b81faddbe00f375174770e7ae7d59",
        "sha256": "3bf46dfdc8449f86cd94ec2648d80324f726404dcdda46a448186e869beeb720"
      },
      "downloads": -1,
      "filename": "deepinterpolation-0.1.4.tar.gz",
      "has_sig": false,
      "md5_digest": "4a5b81faddbe00f375174770e7ae7d59",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 33893,
      "upload_time": "2021-11-22T21:26:45",
      "upload_time_iso_8601": "2021-11-22T21:26:45.399233Z",
      "url": "https://files.pythonhosted.org/packages/e6/8a/3f414e2387f5fdb1fbba08a4d99fe2ce1c643bff602634d565a139142986/deepinterpolation-0.1.4.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}