{
  "info": {
    "author": "Matteo Senardi",
    "author_email": "pualien@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Natural Language :: English",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Topic :: Utilities"
    ],
    "description": "# Google Search Results Async in Python\n\n[![Package](https://badge.fury.io/py/google-search-results.svg)](https://badge.fury.io/py/google-search-results)\n[![Build](https://github.com/serpapi/google-search-results-python/actions/workflows/python-package.yml/badge.svg)](https://github.com/serpapi/google-search-results-python/actions/workflows/python-package.yml)\n\nThis Python package is meant to scrape and parse search results from Google, Bing, Baidu, Yandex, Yahoo, Home depot, Ebay and more.. using [SerpApi](https://serpapi.com). \n\nThe following services are provided:\n- [Search API](https://serpapi.com/search-api)\n- [Search Archive API](https://serpapi.com/search-archive-api)\n- [Account API](https://serpapi.com/account-api)\n- [Location API](https://serpapi.com/locations-api) (Google Only)\n\nSerpApi provides a [script builder](https://serpapi.com/demo) to get you started quickly.\n\n## Installation\n\nPython 3.7+\n```bash\npip install google-search-results\n```\n\n[Link to the python package page](https://pypi.org/project/google-search-results/)\n\n## Quick start\n\n```python\nfrom serpapi import GoogleSearch\nsearch = GoogleSearch({\n    \"q\": \"coffee\", \n    \"location\": \"Austin,Texas\",\n    \"api_key\": \"<your secret api key>\"\n  })\nresult = search.get_dict()\n```\n\nThis example runs a search about \"coffee\" using your secret api key.\n\nThe SerpApi service (backend)\n- searches on Google using the search: q = \"coffee\"\n- parses the messy HTML responses\n- return a standardizes JSON response\nThe GoogleSearch class\n- Format the request\n- Execute GET http request against SerpApi service\n- Parse JSON response into a dictionary\nEt voila..\n\nAlternatively, you can search:\n- Bing using BingSearch class\n- Baidu using BaiduSearch class\n- Yahoo using YahooSearch class\n- duckduckgo using DuckDuckGoSearch class\n- Ebay using EbaySearch class\n- Yandex using YandexSearch class\n- HomeDepot using HomeDepotSearch class\n- GoogleScholar using GoogleScholarSearch class\n- Youtube using YoutubeSearch class\n- Walmart using WalmartSearch\n- Apple App Store using AppleAppStoreSearch class\n- Naver using NaverSearch class\n\n\nSee the [playground to generate your code.](https://serpapi.com/playground)\n\n## Summary\n- [Google Search Results in Python](#google-search-results-in-python)\n  - [Installation](#installation)\n  - [Quick start](#quick-start)\n  - [Summary](#summary)\n    - [Google Search API capability](#google-search-api-capability)\n    - [How to set SERP API key](#how-to-set-serp-api-key)\n    - [Example by specification](#example-by-specification)\n    - [Location API](#location-api)\n    - [Search Archive API](#search-archive-api)\n    - [Account API](#account-api)\n    - [Search Bing](#search-bing)\n    - [Search Baidu](#search-baidu)\n    - [Search Yandex](#search-yandex)\n    - [Search Yahoo](#search-yahoo)\n    - [Search Ebay](#search-ebay)\n    - [Search Home depot](#search-home-depot)\n    - [Search Youtube](#search-youtube)\n    - [Search Google Scholar](#search-google-scholar)\n    - [Generic search with SerpApiClient](#generic-search-with-serpapiclient)\n    - [Search Google Images](#search-google-images)\n    - [Search Google News](#search-google-news)\n    - [Search Google Shopping](#search-google-shopping)\n    - [Google Search By Location](#google-search-by-location)\n    - [Batch Asynchronous Searches](#batch-asynchronous-searches)\n    - [Python object as a result](#python-object-as-a-result)\n    - [Python paginate using iterator](#pagination-using-iterator)\n    - [Error management](#error-management)\n  - [Change log](#change-log)\n  - [Conclusion](#conclusion)\n\n### Google Search API capability\nSource code.\n```python\nparams = {\n  \"q\": \"coffee\",\n  \"location\": \"Location Requested\", \n  \"device\": \"desktop|mobile|tablet\",\n  \"hl\": \"Google UI Language\",\n  \"gl\": \"Google Country\",\n  \"safe\": \"Safe Search Flag\",\n  \"num\": \"Number of Results\",\n  \"start\": \"Pagination Offset\",\n  \"api_key\": \"Your SERP API Key\", \n  # To be match\n  \"tbm\": \"nws|isch|shop\", \n  # To be search\n  \"tbs\": \"custom to be search criteria\",\n  # allow async request\n  \"async\": \"true|false\",\n  # output format\n  \"output\": \"json|html\"\n}\n\n# define the search search\nsearch = GoogleSearch(params)\n# override an existing parameter\nsearch.params_dict[\"location\"] = \"Portland\"\n# search format return as raw html\nhtml_results = search.get_html()\n# parse results\n#  as python Dictionary\ndict_results = search.get_dict()\n#  as JSON using json package\njson_results = search.get_json()\n#  as dynamic Python object\nobject_result = search.get_object()\n```\n[Link to the full documentation](https://serpapi.com/search-api)\n\nsee below for more hands on examples.\n\n### How to set SERP API key\n\nYou can get an API key here if you don't already have one: https://serpapi.com/users/sign_up\n\nThe SerpApi `api_key` can be set globally:\n```python\nGoogleSearch.SERP_API_KEY = \"Your Private Key\"\n```\nThe SerpApi `api_key` can be provided for each search:\n```python\nquery = GoogleSearch({\"q\": \"coffee\", \"serp_api_key\": \"Your Private Key\"})\n```\n\n### Example by specification\n\nWe love true open source, continuous integration and Test Drive Development (TDD). \n We are using RSpec to test [our infrastructure around the clock](https://travis-ci.org/serpapi/google-search-results-python) to achieve the best QoS (Quality Of Service).\n \nThe directory test/ includes specification/examples.\n\nSet your api key.\n```bash\nexport API_KEY=\"your secret key\"\n```\n\nRun test\n```python\nmake test\n```\n\n### Location API\n\n```python\nfrom serpapi import GoogleSearch\nsearch = GoogleSearch({})\nlocation_list = search.get_location(\"Austin\", 3)\nprint(location_list)\n```\n\nit prints the first 3 location matching Austin (Texas, Texas, Rochester)\n```python\n[   {   'canonical_name': 'Austin,TX,Texas,United States',\n        'country_code': 'US',\n        'google_id': 200635,\n        'google_parent_id': 21176,\n        'gps': [-97.7430608, 30.267153],\n        'id': '585069bdee19ad271e9bc072',\n        'keys': ['austin', 'tx', 'texas', 'united', 'states'],\n        'name': 'Austin, TX',\n        'reach': 5560000,\n        'target_type': 'DMA Region'},\n        ...]\n```\n\n### Search Archive API\n\nThe search result are stored in temporary cached.\nThe previous search can be retrieve from the the cache for free.\n\n```python\nfrom serpapi import GoogleSearch\nsearch = GoogleSearch({\"q\": \"Coffee\", \"location\": \"Austin,Texas\"})\nsearch_result = search.get_dictionary()\nassert search_result.get(\"error\") == None\nsearch_id = search_result.get(\"search_metadata\").get(\"id\")\nprint(search_id)\n```\n\nNow let retrieve the previous search from the archive.\n\n```python\narchived_search_result = GoogleSearch({}).get_search_archive(search_id, 'json')\nprint(archived_search_result.get(\"search_metadata\").get(\"id\"))\n```\nit prints the search result from the archive.\n\n### Account API\n```python\nfrom serpapi import GoogleSearch\nsearch = GoogleSearch({})\naccount = search.get_account()\n```\nit prints your account information.\n\n### Search Bing\n```python\nfrom serpapi import BingSearch\nsearch = BingSearch({\"q\": \"Coffee\", \"location\": \"Austin,Texas\"})\ndata = search.get_dict()\n```\nthis code prints baidu search results for coffee as a Dictionary. \n\nhttps://serpapi.com/bing-search-api\n\n### Search Baidu\n```python\nfrom serpapi import BaiduSearch\nsearch = BaiduSearch({\"q\": \"Coffee\"})\ndata = search.get_dict()\n```\nthis code prints baidu search results for coffee as a Dictionary. \nhttps://serpapi.com/baidu-search-api\n\n### Search Yandex\n```python\nfrom serpapi import YandexSearch\nsearch = YandexSearch({\"text\": \"Coffee\"})\ndata = search.get_dict()\n```\nthis code prints yandex search results for coffee as a Dictionary. \n\nhttps://serpapi.com/yandex-search-api\n\n### Search Yahoo\n```python\nfrom serpapi import YahooSearch\nsearch = YahooSearch({\"p\": \"Coffee\"})\ndata = search.get_dict()\n```\nthis code prints yahoo search results for coffee as a Dictionary. \n\nhttps://serpapi.com/yahoo-search-api\n\n\n### Search Ebay\n```python\nfrom serpapi import EbaySearch\nsearch = EbaySearch({\"_nkw\": \"Coffee\"})\ndata = search.get_dict()\n```\nthis code prints ebay search results for coffee as a Dictionary. \n\nhttps://serpapi.com/ebay-search-api\n\n### Search Home depot\n```python\nfrom serpapi import HomeDepotSearch\nsearch = HomeDepotSearch({\"q\": \"chair\"})\ndata = search.get_dict()\n```\nthis code prints home depot search results for chair as Dictionary. \n\nhttps://serpapi.com/home-depot-search-api\n\n### Search Youtube\n```python\nfrom serpapi import HomeDepotSearch\nsearch = YoutubeSearch({\"q\": \"chair\"})\ndata = search.get_dict()\n```\nthis code prints youtube search results for chair as Dictionary. \n\nhttps://serpapi.com/youtube-search-api\n\n### Search Google Scholar\n```python\nfrom serpapi import GoogleScholarSearch\nsearch = GoogleScholarSearch({\"q\": \"Coffee\"})\ndata = search.get_dict()\n```\nthis code prints Google Scholar search results.\n\n### Search Walmart\n```python\nfrom serpapi import WalmartSearch\nsearch = WalmartSearch({\"query\": \"chair\"})\ndata = search.get_dict()\n```\nthis code prints Google Scholar search results.\n\n### Search Youtube\n```python\nfrom serpapi import YoutubeSearch\nsearch = YoutubeSearch({\"search_query\": \"chair\"})\ndata = search.get_dict()\n```\nthis code prints Google Scholar search results.\n\n### Search Apple Store\n```python\nfrom serpapi import AppleAppStoreSearch\nsearch = AppleAppStoreSearch({\"term\": \"Coffee\"})\ndata = search.get_dict()\n```\nthis code prints Google Scholar search results.\n\n### Search Naver\n```python\nfrom serpapi import NaverSearch\nsearch = NaverSearch({\"query\": \"chair\"})\ndata = search.get_dict()\n```\nthis code prints Google Scholar search results.\n\n### Generic search with SerpApiClient\n```python\nfrom serpapi import SerpApiClient\nquery = {\"q\": \"Coffee\", \"location\": \"Austin,Texas\", \"engine\": \"google\"}\nsearch = SerpApiClient(query)\ndata = search.get_dict()\n```\nThis class enables to interact with any search engine supported by SerpApi.com \n\n### Search Google Images\n\n```python\nfrom serpapi import GoogleSearch\nsearch = GoogleSearch({\"q\": \"coffe\", \"tbm\": \"isch\"})\nfor image_result in search.get_dict()['images_results']:\n    link = image_result[\"original\"]\n    try:\n        print(\"link: \" + link)\n        # wget.download(link, '.')\n    except:\n        pass\n```\n\nthis code prints all the images links, \n and download image if you un-comment the line with wget (linux/osx tool to download image).\n\nThis tutorial covers more ground on this topic.\nhttps://github.com/serpapi/showcase-serpapi-tensorflow-keras-image-training\n\n### Search Google News\n\n```python\nfrom serpapi import GoogleSearch\nsearch = GoogleSearch({\n    \"q\": \"coffe\",   # search search\n    \"tbm\": \"nws\",  # news\n    \"tbs\": \"qdr:d\", # last 24h\n    \"num\": 10\n})\nfor offset in [0,1,2]:\n    search.params_dict[\"start\"] = offset * 10\n    data = search.get_dict()\n    for news_result in data['news_results']:\n        print(str(news_result['position'] + offset * 10) + \" - \" + news_result['title'])\n```\n\nthis script prints the first 3 pages of the news title for the last 24h.\n\n### Search Google Shopping\n\n```python\nfrom serpapi import GoogleSearch\nsearch = GoogleSearch({\n    \"q\": \"coffe\",   # search search\n    \"tbm\": \"shop\",  # news\n    \"tbs\": \"p_ord:rv\", # last 24h\n    \"num\": 100\n})\ndata = search.get_dict()\nfor shopping_result in data['shopping_results']:\n    print(shopping_result['position']) + \" - \" + shopping_result['title'])\n\n```\n\nthis script prints all the shopping results order by review order.\n\n### Google Search By Location\n\nWith SerpApi, we can build Google search from anywhere in the world.\nThis code is looking for the best coffee shop per city.\n\n```python\nfrom serpapi import GoogleSearch\nfor city in [\"new york\", \"paris\", \"berlin\"]:\n  location = GoogleSearch({}).get_location(city, 1)[0][\"canonical_name\"]\n  search = GoogleSearch({\n      \"q\": \"best coffee shop\",   # search search\n      \"location\": location,\n      \"num\": 1,\n      \"start\": 0\n  })\n  data = search.get_dict()\n  top_result = data[\"organic_results\"][0][\"title\"]\n```\n\n### Batch Asynchronous Searches\n\nWe do offer two ways to boost your searches thanks to `async` parameter.\n - Blocking - async=false - it's more compute intensive because the search would need to hold many connections. (default) \n- Non-blocking - async=true - it's way to go for large amount of query submitted by batch  (recommended)\n\n```python\n# Operating system\nimport os\n\n# regular expression library\nimport re\n\n# safe queue (named Queue in python2)\nfrom queue import Queue\n\n# Time utility\nimport time\n\n# SerpApi search\nfrom serpapi import GoogleSearch\n\n# store searches\nsearch_queue = Queue()\n\n# SerpApi search\nsearch = GoogleSearch({\n    \"location\": \"Austin,Texas\",\n    \"async\": True,\n    \"api_key\": os.getenv(\"API_KEY\")\n})\n\n# loop through a list of companies\nfor company in ['amd', 'nvidia', 'intel']:\n    print(\"execute async search: q = \" + company)\n    search.params_dict[\"q\"] = company\n    result = search.get_dict()\n    if \"error\" in result:\n        print(\"oops error: \", result[\"error\"])\n        continue\n    print(\"add search to the queue where id: \", result['search_metadata'])\n    # add search to the search_queue\n    search_queue.put(result)\n\nprint(\"wait until all search statuses are cached or success\")\n\n# Create regular search\nwhile not search_queue.empty():\n    result = search_queue.get()\n    search_id = result['search_metadata']['id']\n\n    # retrieve search from the archive - blocker\n    print(search_id + \": get search from archive\")\n    search_archived = search.get_search_archive(search_id)\n    print(search_id + \": status = \" +\n          search_archived['search_metadata']['status'])\n\n    # check status\n    if re.search('Cached|Success',\n                 search_archived['search_metadata']['status']):\n        print(search_id + \": search done with q = \" +\n              search_archived['search_parameters']['q'])\n    else:\n        # requeue search_queue\n        print(search_id + \": requeue search\")\n        search_queue.put(result)\n\n        # wait 1s\n        time.sleep(1)\n\nprint('all searches completed')\n```\n\nThis code shows how to run searches asynchronously.\nThe search parameters must have {async: True}. This indicates that the client shouldn't wait for the search to be completed.\nThe current thread that executes the search is now non-blocking which allows to execute thousand of searches in seconds. The SerpApi backend will do the processing work.\nThe actual search result is defer to a later call from the search archive using get_search_archive(search_id).\nIn this example the non-blocking searches are persisted in a queue: search_queue.\nA loop through the search_queue allows to fetch individual search result.\nThis process can be easily multithreaded to allow a large number of concurrent search requests.\nTo keep thing simple, this example does only explore search result one at a time (single threaded).\n\n[See example.](https://github.com/serpapi/google-search-results-python/blob/master/tests/test_example.py)\n\n### Python object as a result\n\nThe search results can be automatically wrapped in dynamically generated Python object.\nThis solution offers a more dynamic solution fully Oriented Object Programming approach over the regular Dictionary / JSON data structure.\n\n```python\nfrom serpapi import GoogleSearch\nsearch = GoogleSearch({\"q\": \"Coffee\", \"location\": \"Austin,Texas\"})\nr = search.get_object()\nassert type(r.organic_results), list\nassert r.organic_results[0].title\nassert r.search_metadata.id\nassert r.search_metadata.google_url\nassert r.search_parameters.q, \"Coffee\"\nassert r.search_parameters.engine, \"google\"\n```\n\n### Pagination using iterator\nLet's collect links accross multiple search result pages.\n```python\n# to get 2 pages\nstart = 0\nend = 40\npage_size = 10\n\n# basic search parameters\nparameter = {\n  \"q\": \"coca cola\",\n  \"tbm\": \"nws\",\n  \"api_key\": os.getenv(\"API_KEY\"),\n  # optional pagination parameter\n  #  the pagination method can take argument directly\n  \"start\": start,\n  \"end\": end,\n  \"num\": page_size\n}\n\n# as proof of concept \n# urls collects\nurls = []\n\n# initialize a search\nsearch = GoogleSearch(parameter)\n\n# create a python generator using parameter\npages = search.pagination()\n# or set custom parameter\npages = search.pagination(start, end, page_size)\n\n# fetch one search result per iteration \n# using a basic python for loop \n# which invokes python iterator under the hood.\nfor page in pages:\n  print(f\"Current page: {page['serpapi_pagination']['current']}\")\n  for news_result in page[\"news_results\"]:\n    print(f\"Title: {news_result['title']}\\nLink: {news_result['link']}\\n\")\n    urls.append(news_result['link'])\n  \n# check if the total number pages is as expected\n# note: the exact number if variable depending on the search engine backend\nif len(urls) == (end - start):\n  print(\"all search results count match!\")\nif len(urls) == len(set(urls)):\n  print(\"all search results are unique!\")\n```\n\nExamples to fetch links with pagination: [test file](https://github.com/serpapi/google-search-results-python/blob/master/tests/test_example_paginate.py), [online IDE](https://replit.com/@DimitryZub1/Scrape-Google-News-with-Pagination-python-serpapi)\n\n### Error management\n\nSerpAPI keeps error mangement very basic.\n - backend service error or search fail\n - client error\n\nIf it's a backend error, a simple message error is returned as string in the server response.\n```python\nfrom serpapi import GoogleSearch\nsearch = GoogleSearch({\"q\": \"Coffee\", \"location\": \"Austin,Texas\", \"api_key\": \"<secret_key>\"})\ndata = search.get_json()\nassert data[\"error\"] == None\n```\nIn some case, there is more details availabel in the data object.\n\nIf it's client error, then a SerpApiClientException is raised.\n\n## Change log\n2021-12-22 @ 2.4.1\n - add more search engine \n   - youtube\n   - walmart\n   - apple_app_store\n   - naver \n - raise SerpApiClientException instead of raw string in order to follow Python guideline 3.5+\n - add more unit error tests for serp_api_client\n\n2021-07-26 @ 2.4.0\n - add page size support using num parameter\n - add youtube search engine\n\n2021-06-05 @ 2.3.0\n - add pagination support\n\n2021-04-28 @ 2.2.0\n - add get_response method to provide raw requests.Response object\n\n2021-04-04 @ 2.1.0\n - Add home depot search engine\n - get_object() returns dynamic Python object\n \n2020-10-26 @ 2.0.0\n - Reduce class name to <engine>Search\n - Add get_raw_json\n\n2020-06-30 @ 1.8.3\n - simplify import\n - improve package for python 3.5+\n - add support for python 3.5 and 3.6\n\n2020-03-25 @ 1.8\n - add support for Yandex, Yahoo, Ebay\n - clean-up test\n\n2019-11-10 @ 1.7.1\n - increase engine parameter priority over engine value set in the class\n\n2019-09-12 @ 1.7\n - Change  namespace \"from lib.\" instead: \"from serpapi import GoogleSearch\"\n - Support for Bing and Baidu\n\n2019-06-25 @ 1.6\n - New search engine supported: Baidu and Bing\n\n## Conclusion\nSerpApi supports all the major search engines. Google has the more advance support with all the major services available: Images, News, Shopping and more..\nTo enable a type of search, the field tbm (to be matched) must be set to:\n\n * isch: Google Images API.\n * nws: Google News API.\n * shop: Google Shopping API.\n * any other Google service should work out of the box.\n * (no tbm parameter): regular Google search.\n\nThe field `tbs` allows to customize the search even more.\n\n[The full documentation is available here.](https://serpapi.com/search-api)\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/serpapi/google-search-results-python",
    "keywords": "scrape,serp,api,json,search,localized,rank,google,bing,baidu,yandex,yahoo,ebay,scale,datamining,training,machine,ml,youtube,naver,walmart,apple,store,app",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "google-search-results-async",
    "package_url": "https://pypi.org/project/google-search-results-async/",
    "platform": null,
    "project_url": "https://pypi.org/project/google-search-results-async/",
    "project_urls": {
      "Homepage": "https://github.com/serpapi/google-search-results-python"
    },
    "release_url": "https://pypi.org/project/google-search-results-async/2.4.2/",
    "requires_dist": [
      "requests (==2.25.1)",
      "Brotli (==1.0.9)",
      "aiodns (==3.0.0)",
      "aiohttp (==3.8.1)",
      "cchardet (==2.1.7)"
    ],
    "requires_python": ">=3.5",
    "summary": "Scrape and search localized results from Google, Bing, Baidu, Yahoo, Yandex, Ebay, Homedepot, youtube at scale using SerpApi.com",
    "version": "2.4.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 13131202,
  "releases": {
    "2.4.1b0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fceb7662582f9a39d475540146ffd3c3bc7d809d47e4dc43b18c1046e1247aa8",
          "md5": "ff43913c529f5ff23ca1c667a6b483ed",
          "sha256": "2e0221f074e1aaa9656c9984779dc3ffd68be9eacd4671147294556b2e5d3c0f"
        },
        "downloads": -1,
        "filename": "google_search_results_async-2.4.1b0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ff43913c529f5ff23ca1c667a6b483ed",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.5",
        "size": 21162,
        "upload_time": "2022-03-09T20:28:00",
        "upload_time_iso_8601": "2022-03-09T20:28:00.143489Z",
        "url": "https://files.pythonhosted.org/packages/fc/eb/7662582f9a39d475540146ffd3c3bc7d809d47e4dc43b18c1046e1247aa8/google_search_results_async-2.4.1b0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5ce31b81cb1701628047884b0ff0561d83c5bcbda4bde70bc49a03f80e899460",
          "md5": "05cf68971d4b267c0bc759a6f1fdd052",
          "sha256": "e3de59ca9931af59ffc6becce7c8448b7af86a29507f4405b8d8b22a01cd9a7e"
        },
        "downloads": -1,
        "filename": "google_search_results_async-2.4.1b0.tar.gz",
        "has_sig": false,
        "md5_digest": "05cf68971d4b267c0bc759a6f1fdd052",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 13407,
        "upload_time": "2022-03-09T20:28:01",
        "upload_time_iso_8601": "2022-03-09T20:28:01.653228Z",
        "url": "https://files.pythonhosted.org/packages/5c/e3/1b81cb1701628047884b0ff0561d83c5bcbda4bde70bc49a03f80e899460/google_search_results_async-2.4.1b0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "2.4.1b1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "345206b6ace0567b913eba4f2b351845d8e6bb0cdfe0fc4a119b9a49a28a69b5",
          "md5": "0bf987d4e6f6777a18e902d25e55f898",
          "sha256": "e08043824edcbdfbbf3d117252af21ce469a2463963d5dafaa6f2415a5a9b64f"
        },
        "downloads": -1,
        "filename": "google_search_results_async-2.4.1b1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0bf987d4e6f6777a18e902d25e55f898",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.5",
        "size": 21196,
        "upload_time": "2022-03-09T20:39:01",
        "upload_time_iso_8601": "2022-03-09T20:39:01.969389Z",
        "url": "https://files.pythonhosted.org/packages/34/52/06b6ace0567b913eba4f2b351845d8e6bb0cdfe0fc4a119b9a49a28a69b5/google_search_results_async-2.4.1b1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "719ef6c343c23c7cd9b8119186cf30dc2da05d3ff9c21f38c4e8046a498c7091",
          "md5": "6a8bbc0b70cd14fc576a4ca4afcb9c18",
          "sha256": "a47c26b193faaf2769a9c860615fe0d380b721068275ab3897495e3bbc576463"
        },
        "downloads": -1,
        "filename": "google_search_results_async-2.4.1b1.tar.gz",
        "has_sig": false,
        "md5_digest": "6a8bbc0b70cd14fc576a4ca4afcb9c18",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 13434,
        "upload_time": "2022-03-09T20:39:03",
        "upload_time_iso_8601": "2022-03-09T20:39:03.606140Z",
        "url": "https://files.pythonhosted.org/packages/71/9e/f6c343c23c7cd9b8119186cf30dc2da05d3ff9c21f38c4e8046a498c7091/google_search_results_async-2.4.1b1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "2.4.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ed6985d38fc5c594b51646e90974618159e53eeeb18275f2767a611dfbc0e5f7",
          "md5": "7dbdc8a86bb0937eb1ebcd8039a4e29d",
          "sha256": "67aa9ae71db08b21c2121907b218f782760cb7b50349e8897cc652e91bf15446"
        },
        "downloads": -1,
        "filename": "google_search_results_async-2.4.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "7dbdc8a86bb0937eb1ebcd8039a4e29d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.5",
        "size": 21496,
        "upload_time": "2022-03-09T23:56:51",
        "upload_time_iso_8601": "2022-03-09T23:56:51.957344Z",
        "url": "https://files.pythonhosted.org/packages/ed/69/85d38fc5c594b51646e90974618159e53eeeb18275f2767a611dfbc0e5f7/google_search_results_async-2.4.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "40de8e5224a9e3d1f2c9901c640e2a34861ac7b5e734e100385c93faaf177bab",
          "md5": "df0c1970a6f52f277d360558ac026510",
          "sha256": "b267bdae42adbb2bdca47539da1644e5c164786f8ff164dd06e63a946be127f0"
        },
        "downloads": -1,
        "filename": "google_search_results_async-2.4.2.tar.gz",
        "has_sig": false,
        "md5_digest": "df0c1970a6f52f277d360558ac026510",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 13428,
        "upload_time": "2022-03-09T23:56:54",
        "upload_time_iso_8601": "2022-03-09T23:56:54.153211Z",
        "url": "https://files.pythonhosted.org/packages/40/de/8e5224a9e3d1f2c9901c640e2a34861ac7b5e734e100385c93faaf177bab/google_search_results_async-2.4.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "ed6985d38fc5c594b51646e90974618159e53eeeb18275f2767a611dfbc0e5f7",
        "md5": "7dbdc8a86bb0937eb1ebcd8039a4e29d",
        "sha256": "67aa9ae71db08b21c2121907b218f782760cb7b50349e8897cc652e91bf15446"
      },
      "downloads": -1,
      "filename": "google_search_results_async-2.4.2-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "7dbdc8a86bb0937eb1ebcd8039a4e29d",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.5",
      "size": 21496,
      "upload_time": "2022-03-09T23:56:51",
      "upload_time_iso_8601": "2022-03-09T23:56:51.957344Z",
      "url": "https://files.pythonhosted.org/packages/ed/69/85d38fc5c594b51646e90974618159e53eeeb18275f2767a611dfbc0e5f7/google_search_results_async-2.4.2-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "40de8e5224a9e3d1f2c9901c640e2a34861ac7b5e734e100385c93faaf177bab",
        "md5": "df0c1970a6f52f277d360558ac026510",
        "sha256": "b267bdae42adbb2bdca47539da1644e5c164786f8ff164dd06e63a946be127f0"
      },
      "downloads": -1,
      "filename": "google_search_results_async-2.4.2.tar.gz",
      "has_sig": false,
      "md5_digest": "df0c1970a6f52f277d360558ac026510",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.5",
      "size": 13428,
      "upload_time": "2022-03-09T23:56:54",
      "upload_time_iso_8601": "2022-03-09T23:56:54.153211Z",
      "url": "https://files.pythonhosted.org/packages/40/de/8e5224a9e3d1f2c9901c640e2a34861ac7b5e734e100385c93faaf177bab/google_search_results_async-2.4.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}