{
  "info": {
    "author": "Miles Cranmer",
    "author_email": "miles.cranmer@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# PySR.jl\n\n**Symbolic regression built on Julia, and interfaced by Python.\nUses regularized evolution and simulated annealing.**\n\nBackstory: we used the original\n[eureqa](https://www.creativemachineslab.com/eureqa.html)\nin our [paper](https://arxiv.org/abs/2006.11287) to\nconvert a graph neural network into\nan analytic equation describing dark matter overdensity. However,\neureqa is GUI-only, doesn't allow for user-defined\noperators, has no distributed capabilities,\nand has become proprietary. Thus, the goal\nof this package is to have an open-source symbolic regression tool\nas efficient as eureqa, while also exposing a configurable\npython interface.\n\nThe algorithms here implement regularized evolution, as in\n[AutoML-Zero](https://arxiv.org/abs/2003.03384),\nbut with additional algorithmic changes such as simulated\nannealing, and classical optimization of constants.\n\n\n## Installation\n\nInstall [Julia](https://julialang.org/downloads/). Then, at the command line,\ninstall the `Optim` package via: `julia -e 'import Pkg; Pkg.add(\"Optim\")'`.\nFor python, you need to have Python 3, numpy, and pandas installed.\n\n## Running:\n\n### Quickstart\n\n```python\nimport numpy as np\nfrom pysr import pysr\n\n# Dataset\nX = 2*np.random.randn(100, 5)\ny = 2*np.cos(X[:, 3]) + X[:, 0]**2 - 2\n\n# Learn equations\nequations = pysr(X, y, niterations=5)\n\n...\n\nprint(equations)\n```\n\nwhich gives:\n\n```\n   Complexity       MSE                                                Equation\n0           5  1.947431                          plus(-1.7420927, mult(x0, x0))\n1           8  0.486858           plus(-1.8710494, plus(cos(x3), mult(x0, x0)))\n2          11  0.000000  plus(plus(mult(x0, x0), cos(x3)), plus(-2.0, cos(x3)))\n```\n\n### API\n\nWhat follows is the API reference for running the numpy interface.\nYou likely don't need to tune the hyperparameters yourself,\nbut if you would like, you can use `hyperopt.py` as an example.\nHowever, you should adjust `threads`, `niterations`,\n`binary_operators`, `unary_operators`, and `maxsize`\nto your requirements.\n\nThe program will output a pandas DataFrame containing the equations,\nmean square error, and complexity. It will also dump to a csv\nat the end of every iteration,\nwhich is `hall_of_fame.csv` by default. It also prints the\nequations to stdout.\n\nYou can add more operators in `operators.jl`, or use default\nJulia ones. Make sure all operators are defined for scalar `Float32`.\nThen just specify the operator names in your call, as above.\nYou can also change the dataset learned on by passing in `X` and `y` as\nnumpy arrays to `pysr(...)`.\n\n```python\npysr(X=None, y=None, threads=4, niterations=20,\n   ncyclesperiteration=int(default_ncyclesperiteration),\n   binary_operators=[\"plus\", \"mult\"], unary_operators=[\"cos\", \"exp\", \"sin\"],\n   alpha=default_alpha, annealing=True, fractionReplaced=default_fractionReplaced,\n   fractionReplacedHof=default_fractionReplacedHof, npop=int(default_npop),\n   parsimony=default_parsimony, migration=True, hofMigration=True\n   shouldOptimizeConstants=True, topn=int(default_topn),\n   weightAddNode=default_weightAddNode, weightDeleteNode=default_weightDeleteNode,\n   weightDoNothing=default_weightDoNothing,\n   weightMutateConstant=default_weightMutateConstant,\n   weightMutateOperator=default_weightMutateOperator,\n   weightRandomize=default_weightRandomize, weightSimplify=default_weightSimplify,\n   timeout=None, equation_file='hall_of_fame.csv', test='simple1', maxsize=20)\n```\n\nRun symbolic regression to fit f(X[i, :]) ~ y[i] for all i.\n\n**Arguments**:\n\n- `X`: np.ndarray, 2D array. Rows are examples, columns are features.\n- `y`: np.ndarray, 1D array. Rows are examples.\n- `threads`: int, Number of threads (=number of populations running).\nYou can have more threads than cores - it actually makes it more\nefficient.\n- `niterations`: int, Number of iterations of the algorithm to run. The best\nequations are printed, and migrate between populations, at the\nend of each.\n- `ncyclesperiteration`: int, Number of total mutations to run, per 10\nsamples of the population, per iteration.\n- `binary_operators`: list, List of strings giving the binary operators\nin Julia's Base, or in `operator.jl`.\n- `unary_operators`: list, Same but for operators taking a single `Float32`.\n- `alpha`: float, Initial temperature.\n- `annealing`: bool, Whether to use annealing. You should (and it is default).\n- `fractionReplaced`: float, How much of population to replace with migrating\nequations from other populations.\n- `fractionReplacedHof`: float, How much of population to replace with migrating\nequations from hall of fame.\n- `npop`: int, Number of individuals in each population\n- `parsimony`: float, Multiplicative factor for how much to punish complexity.\n- `migration`: bool, Whether to migrate.\n- `hofMigration`: bool, Whether to have the hall of fame migrate.\n- `shouldOptimizeConstants`: bool, Whether to numerically optimize\nconstants (Nelder-Mead/Newton) at the end of each iteration.\n- `topn`: int, How many top individuals migrate from each population.\n- `weightAddNode`: float, Relative likelihood for mutation to add a node\n- `weightDeleteNode`: float, Relative likelihood for mutation to delete a node\n- `weightDoNothing`: float, Relative likelihood for mutation to leave the individual\n- `weightMutateConstant`: float, Relative likelihood for mutation to change\nthe constant slightly in a random direction.\n- `weightMutateOperator`: float, Relative likelihood for mutation to swap\nan operator.\n- `weightRandomize`: float, Relative likelihood for mutation to completely\ndelete and then randomly generate the equation\n- `weightSimplify`: float, Relative likelihood for mutation to simplify\nconstant parts by evaluation\n- `timeout`: float, Time in seconds to timeout search\n- `equation_file`: str, Where to save the files (.csv separated by |)\n- `test`: str, What test to run, if X,y not passed.\n- `maxsize`: int, Max size of an equation.\n\n**Returns**:\n\npd.DataFrame, Results dataframe, giving complexity, MSE, and equations\n(as strings).\n\n\n# TODO\n\n- [ ] Rename package to avoid trademark issues\n    - PySR?\n- [ ] Calculate feature importances of future mutations, by looking at correlation between residual of model, and the features.\n    - Store feature importances of future, and periodically update it.\n- [ ] Implement more parts of the original Eureqa algorithms: https://www.creativemachineslab.com/eureqa.html\n- [ ] Sympy printing\n- [ ] Consider adding mutation for constant<->variable\n- [ ] Hierarchical model, so can re-use functional forms. Output of one equation goes into second equation?\n- [ ] Use NN to generate weights over all probability distribution conditional on error and existing equation, and train on some randomly-generated equations\n- [ ] Performance:\n    - [ ] Use an enum for functions instead of storing them?\n    - Current most expensive operations:\n        - [ ] Calculating the loss function - there is duplicate calculations happening.\n        - [x] Declaration of the weights array every iteration\n- [x] Make scaling of changes to constant a hyperparameter\n- [x] Make deletion op join deleted subtree to parent\n- [x] Update hall of fame every iteration?\n    - Seems to overfit early if we do this.\n- [x] Consider adding mutation to pass an operator in through a new binary operator (e.g., exp(x3)->plus(exp(x3), ...))\n    - (Added full insertion operator\n- [x] Add a node at the top of a tree\n- [x] Insert a node at the top of a subtree\n- [x] Record very best individual in each population, and return at end.\n- [x] Write our own tree copy operation; deepcopy() is the slowest operation by far.\n- [x] Hyperparameter tune\n- [x] Create a benchmark for accuracy\n- [x] Add interface for either defining an operation to learn, or loading in arbitrary dataset.\n    - Could just write out the dataset in julia, or load it.\n- [x] Create a Python interface\n- [x] Explicit constant optimization on hall-of-fame\n    - Create method to find and return all constants, from left to right\n    - Create method to find and set all constants, in same order\n    - Pull up some optimization algorithm and add it. Keep the package small!\n- [x] Create a benchmark for speed\n- [x] Simplify subtrees with only constants beneath them. Or should I? Maybe randomly simplify sometimes?\n- [x] Record hall of fame\n- [x] Optionally (with hyperparameter) migrate the hall of fame, rather than current bests\n- [x] Test performance of reduced precision integers\n    - No effect\n- [x] Create struct to pass through all hyperparameters, instead of treating as constants\n    - Make sure doesn't affect performance\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/MilesCranmer/pysr",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "pysr-mcranmer",
    "package_url": "https://pypi.org/project/pysr-mcranmer/",
    "platform": "",
    "project_url": "https://pypi.org/project/pysr-mcranmer/",
    "project_urls": {
      "Homepage": "https://github.com/MilesCranmer/pysr"
    },
    "release_url": "https://pypi.org/project/pysr-mcranmer/0.0.1/",
    "requires_dist": null,
    "requires_python": ">=3.3",
    "summary": "Simple and efficient symbolic regression",
    "version": "0.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8224822,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d171f5246dc16d6ec8ed5edc7ec5c13fa17000de01d8fd95012ba067cf9e0751",
          "md5": "98bacded5fde163e9b92670ac02609ed",
          "sha256": "1c0bb8fc6410cfa21117aa89ed96ca1ae495bb63cf5da5964c4f75b2fda458fb"
        },
        "downloads": -1,
        "filename": "pysr_mcranmer-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "98bacded5fde163e9b92670ac02609ed",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.3",
        "size": 12425,
        "upload_time": "2020-09-19T17:30:57",
        "upload_time_iso_8601": "2020-09-19T17:30:57.687131Z",
        "url": "https://files.pythonhosted.org/packages/d1/71/f5246dc16d6ec8ed5edc7ec5c13fa17000de01d8fd95012ba067cf9e0751/pysr_mcranmer-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c737f83b3b4f56e03a374f27f7c7ccff9936a9afbbc6eae77a13128426df9a15",
          "md5": "5c98a5eb066ad6bd74c329d6184cd63d",
          "sha256": "f11f632fc2d25611967dde4eae99fe163ad0264593b0dadd07a2312eeef429aa"
        },
        "downloads": -1,
        "filename": "pysr-mcranmer-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "5c98a5eb066ad6bd74c329d6184cd63d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.3",
        "size": 7637,
        "upload_time": "2020-09-19T17:30:59",
        "upload_time_iso_8601": "2020-09-19T17:30:59.927239Z",
        "url": "https://files.pythonhosted.org/packages/c7/37/f83b3b4f56e03a374f27f7c7ccff9936a9afbbc6eae77a13128426df9a15/pysr-mcranmer-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "d171f5246dc16d6ec8ed5edc7ec5c13fa17000de01d8fd95012ba067cf9e0751",
        "md5": "98bacded5fde163e9b92670ac02609ed",
        "sha256": "1c0bb8fc6410cfa21117aa89ed96ca1ae495bb63cf5da5964c4f75b2fda458fb"
      },
      "downloads": -1,
      "filename": "pysr_mcranmer-0.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "98bacded5fde163e9b92670ac02609ed",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.3",
      "size": 12425,
      "upload_time": "2020-09-19T17:30:57",
      "upload_time_iso_8601": "2020-09-19T17:30:57.687131Z",
      "url": "https://files.pythonhosted.org/packages/d1/71/f5246dc16d6ec8ed5edc7ec5c13fa17000de01d8fd95012ba067cf9e0751/pysr_mcranmer-0.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "c737f83b3b4f56e03a374f27f7c7ccff9936a9afbbc6eae77a13128426df9a15",
        "md5": "5c98a5eb066ad6bd74c329d6184cd63d",
        "sha256": "f11f632fc2d25611967dde4eae99fe163ad0264593b0dadd07a2312eeef429aa"
      },
      "downloads": -1,
      "filename": "pysr-mcranmer-0.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "5c98a5eb066ad6bd74c329d6184cd63d",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.3",
      "size": 7637,
      "upload_time": "2020-09-19T17:30:59",
      "upload_time_iso_8601": "2020-09-19T17:30:59.927239Z",
      "url": "https://files.pythonhosted.org/packages/c7/37/f83b3b4f56e03a374f27f7c7ccff9936a9afbbc6eae77a13128426df9a15/pysr-mcranmer-0.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}