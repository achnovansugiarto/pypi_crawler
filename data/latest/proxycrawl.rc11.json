{
  "info": {
    "author": "ProxyCrawl",
    "author_email": "info@proxycrawl.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 2",
      "Programming Language :: Python :: 2.7",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.9",
      "Topic :: Utilities"
    ],
    "description": "# ProxyCrawl API Python class\n\nA lightweight, dependency free Python class that acts as wrapper for ProxyCrawl API.\n\n## Installing\n\nChoose a way of installing:\n\n- Download the python class from Github.\n- Or use [PyPi](https://pypi.org/project/proxycrawl/) Python package manager. `pip install proxycrawl`\n\nThen import the CrawlingAPI, ScraperAPI, etc as needed.\n\n```python\nfrom proxycrawl import CrawlingAPI, ScraperAPI, LeadsAPI, ScreenshotsAPI, StorageAPI\n```\n\n### Upgrading to version 3\n\nVersion 3 deprecates the usage of ProxyCrawlAPI in favour of CrawlingAPI (although is still usable). Please test the upgrade before deploying to production.\n\n## Crawling API\n\nFirst initialize the CrawlingAPI class.\n\n```python\napi = CrawlingAPI({ 'token': 'YOUR_PROXYCRAWL_TOKEN' })\n```\n\n### GET requests\n\nPass the url that you want to scrape plus any options from the ones available in the [API documentation](https://proxycrawl.com/docs).\n\n```python\napi.get(url, options = {})\n```\n\nExample:\n\n```python\nresponse = api.get('https://www.facebook.com/britneyspears')\nif response['status_code'] == 200:\n    print(response['body'])\n```\n\nYou can pass any options from ProxyCrawl API.\n\nExample:\n\n```python\nresponse = api.get('https://www.reddit.com/r/pics/comments/5bx4bx/thanks_obama/', {\n    'user_agent': 'Mozilla/5.0 (Windows NT 6.2; rv:20.0) Gecko/20121202 Firefox/30.0',\n    'format': 'json'\n})\nif response['status_code'] == 200:\n    print(response['body'])\n```\n\n### POST requests\n\nPass the url that you want to scrape, the data that you want to send which can be either a json or a string, plus any options from the ones available in the [API documentation](https://proxycrawl.com/docs).\n\n```python\napi.post(url, dictionary or string data, options = {})\n```\n\nExample:\n\n```python\nresponse = api.post('https://producthunt.com/search', { 'text': 'example search' })\nif response['status_code'] == 200:\n    print(response['body'])\n```\n\nYou can send the data as `application/json` instead of `x-www-form-urlencoded` by setting option `post_content_type` as json.\n\n```python\nimport json\nresponse = api.post('https://httpbin.org/post', json.dumps({ 'some_json': 'with some value' }), { 'post_content_type': 'json' })\nif response['status_code'] == 200:\n    print(response['body'])\n```\n\n### Javascript requests\n\nIf you need to scrape any website built with Javascript like React, Angular, Vue, etc. You just need to pass your javascript token and use the same calls. Note that only `.get` is available for javascript and not `.post`.\n\n```python\napi = CrawlingAPI({ 'token': 'YOUR_JAVASCRIPT_TOKEN' })\n```\n\n```python\nresponse = api.get('https://www.nfl.com')\nif response['status_code'] == 200:\n    print(response['body'])\n```\n\nSame way you can pass javascript additional options.\n\n```python\nresponse = api.get('https://www.freelancer.com', { 'page_wait': 5000 })\nif response['status_code'] == 200:\n    print(response['body'])\n```\n\n## Original status\n\nYou can always get the original status and proxycrawl status from the response. Read the [ProxyCrawl documentation](https://proxycrawl.com/docs) to learn more about those status.\n\n```python\nresponse = api.get('https://craiglist.com')\nprint(response['headers']['original_status'])\nprint(response['headers']['pc_status'])\n```\n\nIf you have questions or need help using the library, please open an issue or [contact us](https://proxycrawl.com/contact).\n\n## Scraper API\n\nThe usage of the Scraper API is very similar, just change the class name to initialize.\n\n```python\nscraper_api = ScraperAPI({ 'token': 'YOUR_NORMAL_TOKEN' })\n\nresponse = scraper_api.get('https://www.amazon.com/DualSense-Wireless-Controller-PlayStation-5/dp/B08FC6C75Y/')\nif response['status_code'] == 200:\n    print(response['json']['name']) # Will print the name of the Amazon product\n```\n\n## Leads API\n\nTo find email leads you can use the leads API, you can check the full [API documentation](https://proxycrawl.com/docs/leads-api/) if needed.\n\n```python\nleads_api = LeadsAPI({ 'token': 'YOUR_NORMAL_TOKEN' })\n\nresponse = leads_api.get_from_domain('microsoft.com')\n\nif response['status_code'] == 200:\n    print(response['json']['leads'])\n```\n\n## Screenshots API\n\nInitialize with your Screenshots API token and call the `get` method.\n\n```python\nscreenshots_api = ScreenshotsAPI({ 'token': 'YOUR_NORMAL_TOKEN' })\nresponse = screenshots_api.get('https://www.apple.com')\nif response['status_code'] == 200:\n    print(response['headers']['success'])\n    print(response['headers']['url'])\n    print(response['headers']['remaining_requests'])\n    print(response['file'])\n```\n\nor specifying a file path\n\n```python\nscreenshots_api = ScreenshotsAPI({ 'token': 'YOUR_NORMAL_TOKEN' })\nresponse = screenshots_api.get('https://www.apple.com', { 'save_to_path': 'apple.jpg' })\nif response['status_code'] == 200:\n    print(response['headers']['success'])\n    print(response['headers']['url'])\n    print(response['headers']['remaining_requests'])\n    print(response['file'])\n```\n\nor if you set `store=true` then `screenshot_url` is set in the returned headers \n\n```python\nscreenshots_api = ScreenshotsAPI({ 'token': 'YOUR_NORMAL_TOKEN' })\nresponse = screenshots_api.get('https://www.apple.com', { 'store': 'true' })\nif response['status_code'] == 200:\n    print(response['headers']['success'])\n    print(response['headers']['url'])\n    print(response['headers']['remaining_requests'])\n    print(response['file'])\n    print(response['headers']['screenshot_url'])\n```\n\nNote that `screenshots_api.get(url, options)` method accepts an [options](https://proxycrawl.com/docs/screenshots-api/parameters)\n\n## Storage API\n\nInitialize the Storage API using your private token.\n\n```python\nstorage_api = StorageAPI({ 'token': 'YOUR_NORMAL_TOKEN' })\n```\n\nPass the [url](https://proxycrawl.com/docs/storage-api/parameters/#url) that you want to get from [Proxycrawl Storage](https://proxycrawl.com/dashboard/storage).\n\n```python\nresponse = storage_api.get('https://www.apple.com')\nif response['status_code'] == 200:\n    print(response['headers']['original_status'])\n    print(response['headers']['pc_status'])\n    print(response['headers']['url'])\n    print(response['headers']['rid'])\n    print(response['headers']['stored_at'])\n    print(response['body'])\n```\n\nor you can use the [RID](https://proxycrawl.com/docs/storage-api/parameters/#rid)\n\n```python\nresponse = storage_api.get('RID_REPLACE')\nif response['status_code'] == 200:\n    print(response['headers']['original_status'])\n    print(response['headers']['pc_status'])\n    print(response['headers']['url'])\n    print(response['headers']['rid'])\n    print(response['headers']['stored_at'])\n    print(response['body'])\n```\n\nNote: One of the two RID or URL must be sent. So both are optional but it's mandatory to send one of the two.\n\n### [Delete](https://proxycrawl.com/docs/storage-api/delete/) request\n\nTo delete a storage item from your storage area, use the correct RID\n\n```python\nif storage_api.delete('RID_REPLACE'):\n  print('delete success')\nelse:\n  print('Unable to delete')\n```\n\n### [Bulk](https://proxycrawl.com/docs/storage-api/bulk/) request\n\nTo do a bulk request with a list of RIDs, please send the list of rids as an array\n\n```python\nresponse = storage_api.bulk(['RID1', 'RID2', 'RID3', ...])\nif response['status_code'] == 200:\n    for item in response['json']:\n        print(item['original_status'])\n        print(item['pc_status'])\n        print(item['url'])\n        print(item['rid'])\n        print(item['stored_at'])\n        print(item['body'])\n```\n\n### [RIDs](https://proxycrawl.com/docs/storage-api/rids) request\n\nTo request a bulk list of RIDs from your storage area\n\n```python\nrids = storage_api.rids()\nprint(rids)\n```\n\nYou can also specify a limit as a parameter\n\n```python\nstorage_api.rids(100)\n```\n\n### [Total Count](https://proxycrawl.com/docs/storage-api/total_count)\n\nTo get the total number of documents in your storage area\n\n```python\ntotal_count = storage_api.totalCount()\nprint(total_count)\n```\n\n## Custom timeout\n\nIf you need to use a custom timeout, you can pass it to the class instance creation like the following:\n\n```python\napi = CrawlingAPI({ 'token': 'TOKEN', 'timeout': 120 })\n```\n\nTimeout is in seconds.\n\n---\n\nCopyright 2021 ProxyCrawl\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/proxycrawl/proxycrawl-python",
    "keywords": "scraping scraper crawler crawling proxycrawl api",
    "license": "Apache-2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "proxycrawl",
    "package_url": "https://pypi.org/project/proxycrawl/",
    "platform": "",
    "project_url": "https://pypi.org/project/proxycrawl/",
    "project_urls": {
      "Homepage": "https://github.com/proxycrawl/proxycrawl-python"
    },
    "release_url": "https://pypi.org/project/proxycrawl/3.2.1/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "A Python class that acts as wrapper for ProxyCrawl scraping and crawling API",
    "version": "3.2.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 11447638,
  "releases": {
    "1.0.0": [],
    "1.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "db976e5b5b5e0193ef70acf623fd183bd5ba72b8c49e9414898a4a33da469bfe",
          "md5": "fc4106271e1c3d62cafb873e32eca497",
          "sha256": "cc856fa8535e83fd210469ad8662c1bdafe28d7529859e57ab7d11850591cb57"
        },
        "downloads": -1,
        "filename": "proxycrawl-1.0.1-py2-none-any.whl",
        "has_sig": false,
        "md5_digest": "fc4106271e1c3d62cafb873e32eca497",
        "packagetype": "bdist_wheel",
        "python_version": "py2",
        "requires_python": null,
        "size": 3641,
        "upload_time": "2018-05-31T12:25:27",
        "upload_time_iso_8601": "2018-05-31T12:25:27.166431Z",
        "url": "https://files.pythonhosted.org/packages/db/97/6e5b5b5e0193ef70acf623fd183bd5ba72b8c49e9414898a4a33da469bfe/proxycrawl-1.0.1-py2-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2ea9988421ef028df1902918d4c5ce2454b94bddebcb08f3586470ef3f2d9422",
          "md5": "b05cd3109b39f6b75477f5d2b56bb08d",
          "sha256": "864a9f639313dd980a982aab90b6aa546864db9ccd14780ebb6ff1c8ab0af633"
        },
        "downloads": -1,
        "filename": "proxycrawl-1.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "b05cd3109b39f6b75477f5d2b56bb08d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 3641,
        "upload_time": "2018-05-31T12:25:28",
        "upload_time_iso_8601": "2018-05-31T12:25:28.119445Z",
        "url": "https://files.pythonhosted.org/packages/2e/a9/988421ef028df1902918d4c5ce2454b94bddebcb08f3586470ef3f2d9422/proxycrawl-1.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d5c4b79a09ea0a1dbb8e35deb83da9e52fe8f80ab8280939e1acde14df00e6f7",
          "md5": "086ae4a10aada7a8ccd328162ac955f0",
          "sha256": "bd241f3feb7603b778d18d70e64508e6c14c3bbf802cd25490ebc09866b9c4d6"
        },
        "downloads": -1,
        "filename": "proxycrawl-1.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "086ae4a10aada7a8ccd328162ac955f0",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 3329,
        "upload_time": "2018-05-31T12:25:29",
        "upload_time_iso_8601": "2018-05-31T12:25:29.388940Z",
        "url": "https://files.pythonhosted.org/packages/d5/c4/b79a09ea0a1dbb8e35deb83da9e52fe8f80ab8280939e1acde14df00e6f7/proxycrawl-1.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1b055340eaabd2c71892672b5b8755d2e6e89166c36688b046960cc018575e06",
          "md5": "19251a9669e3a621769dfe0b07b6ace9",
          "sha256": "dd59831a17f75708b4ce96f8ecde4e9aa26db6da9e3b40c5befb33eb860aae3f"
        },
        "downloads": -1,
        "filename": "proxycrawl-1.1.0-py2-none-any.whl",
        "has_sig": false,
        "md5_digest": "19251a9669e3a621769dfe0b07b6ace9",
        "packagetype": "bdist_wheel",
        "python_version": "py2",
        "requires_python": null,
        "size": 3636,
        "upload_time": "2018-06-07T09:38:24",
        "upload_time_iso_8601": "2018-06-07T09:38:24.443255Z",
        "url": "https://files.pythonhosted.org/packages/1b/05/5340eaabd2c71892672b5b8755d2e6e89166c36688b046960cc018575e06/proxycrawl-1.1.0-py2-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "37492904d0b2d078f293e3cb35c7262e1be7f86ee9b97406a11c1146025c88de",
          "md5": "c2ce9139746c0c94d3ae3af3d978cd7a",
          "sha256": "00e9d11681277a15869da6fbde154e4368af28ba28f1583e27840166fc6a1dbd"
        },
        "downloads": -1,
        "filename": "proxycrawl-1.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "c2ce9139746c0c94d3ae3af3d978cd7a",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 3637,
        "upload_time": "2018-06-07T09:38:25",
        "upload_time_iso_8601": "2018-06-07T09:38:25.701328Z",
        "url": "https://files.pythonhosted.org/packages/37/49/2904d0b2d078f293e3cb35c7262e1be7f86ee9b97406a11c1146025c88de/proxycrawl-1.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "810eb89ee41dcddec38219563055270f4fe3977831fc035ef07b2209b052d166",
          "md5": "48221f8a3a193f20136d0ef4ecbc5a16",
          "sha256": "d16ff3097c3317f588c6af057f4a88deae089b515ab3a45cd5ee906086e013a0"
        },
        "downloads": -1,
        "filename": "proxycrawl-1.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "48221f8a3a193f20136d0ef4ecbc5a16",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 3324,
        "upload_time": "2018-06-07T09:38:27",
        "upload_time_iso_8601": "2018-06-07T09:38:27.151646Z",
        "url": "https://files.pythonhosted.org/packages/81/0e/b89ee41dcddec38219563055270f4fe3977831fc035ef07b2209b052d166/proxycrawl-1.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7193cc15ab0aeed96c95c6dc45f48995099562f0e820cd59f5634e7a4cb7ac0f",
          "md5": "7b882d5433ba710d26f14e01e1c4c975",
          "sha256": "61dcec13fcb27acccb68e4af290b224a4d97ed5dcac243becd7c8749cabf5e0b"
        },
        "downloads": -1,
        "filename": "proxycrawl-1.1.1-py2-none-any.whl",
        "has_sig": false,
        "md5_digest": "7b882d5433ba710d26f14e01e1c4c975",
        "packagetype": "bdist_wheel",
        "python_version": "py2",
        "requires_python": null,
        "size": 3712,
        "upload_time": "2018-06-28T11:51:51",
        "upload_time_iso_8601": "2018-06-28T11:51:51.988016Z",
        "url": "https://files.pythonhosted.org/packages/71/93/cc15ab0aeed96c95c6dc45f48995099562f0e820cd59f5634e7a4cb7ac0f/proxycrawl-1.1.1-py2-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "411c5170fc9ea41d026b6c60f988a61d3f4cdb766351724d1805f105ab898fc7",
          "md5": "d163ccd027bf378e74a08cd3e6c06a5c",
          "sha256": "b2b8c85954292cc505b004bed8f1ffcfa495f64eaed04ba112dffa451392249e"
        },
        "downloads": -1,
        "filename": "proxycrawl-1.1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d163ccd027bf378e74a08cd3e6c06a5c",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 3711,
        "upload_time": "2018-06-28T11:51:53",
        "upload_time_iso_8601": "2018-06-28T11:51:53.205609Z",
        "url": "https://files.pythonhosted.org/packages/41/1c/5170fc9ea41d026b6c60f988a61d3f4cdb766351724d1805f105ab898fc7/proxycrawl-1.1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7333c1e464505f8fe23a4cbf4d99c1e2c310c94eea3d3e4e0b478c20709230b2",
          "md5": "bf4b41ef91fdb6c2ecb2f7e95e6099be",
          "sha256": "9a037eee9bdd9206a98907004197e3d52e42b7560b1f3e286f27fe1476003265"
        },
        "downloads": -1,
        "filename": "proxycrawl-1.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "bf4b41ef91fdb6c2ecb2f7e95e6099be",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 3376,
        "upload_time": "2018-06-28T11:51:55",
        "upload_time_iso_8601": "2018-06-28T11:51:55.382974Z",
        "url": "https://files.pythonhosted.org/packages/73/33/c1e464505f8fe23a4cbf4d99c1e2c310c94eea3d3e4e0b478c20709230b2/proxycrawl-1.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "2.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "61c3bcd29ff03377e6a466ddb22a45b7b5c1ecb9cec57dc46b8d997570950689",
          "md5": "9d3eb32aba73ec56fc833863e8cbe492",
          "sha256": "78b64ff6f18270f5b2609d0e3c81887248841b664f66d1da7737f5768033dd2a"
        },
        "downloads": -1,
        "filename": "proxycrawl-2.0.0-py2-none-any.whl",
        "has_sig": false,
        "md5_digest": "9d3eb32aba73ec56fc833863e8cbe492",
        "packagetype": "bdist_wheel",
        "python_version": "py2",
        "requires_python": null,
        "size": 8095,
        "upload_time": "2019-05-30T07:51:53",
        "upload_time_iso_8601": "2019-05-30T07:51:53.432768Z",
        "url": "https://files.pythonhosted.org/packages/61/c3/bcd29ff03377e6a466ddb22a45b7b5c1ecb9cec57dc46b8d997570950689/proxycrawl-2.0.0-py2-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "147fcc3fbe6b458ce0dfc6aca67962547547a8a3d8a5526a8c0e2f84e0f454e5",
          "md5": "5796b7e7ffeaca5642b449ba63cd3791",
          "sha256": "52b8db25c8133a6723e2f827fc4065be3c4eddf3ea3e4ee3f551f058b717532d"
        },
        "downloads": -1,
        "filename": "proxycrawl-2.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "5796b7e7ffeaca5642b449ba63cd3791",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 8096,
        "upload_time": "2019-05-30T07:51:55",
        "upload_time_iso_8601": "2019-05-30T07:51:55.203428Z",
        "url": "https://files.pythonhosted.org/packages/14/7f/cc3fbe6b458ce0dfc6aca67962547547a8a3d8a5526a8c0e2f84e0f454e5/proxycrawl-2.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e40bf731ed62d984fb458bb303d362494a4df1a568d636ec40dedf0d78278c79",
          "md5": "eb760018b0d7a8d52982d5fa683dcfc9",
          "sha256": "00c1d914c5299fb126a12a0a8963f5a6d2b28148b9029932c64d932bdc1294a3"
        },
        "downloads": -1,
        "filename": "proxycrawl-2.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "eb760018b0d7a8d52982d5fa683dcfc9",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 3618,
        "upload_time": "2019-05-30T07:51:56",
        "upload_time_iso_8601": "2019-05-30T07:51:56.828044Z",
        "url": "https://files.pythonhosted.org/packages/e4/0b/f731ed62d984fb458bb303d362494a4df1a568d636ec40dedf0d78278c79/proxycrawl-2.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "2.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "38132986d14d17a13008f08ab4fd4c18dad714606e07130c174868bd20f6c7c9",
          "md5": "def3bc4dfcf068720b1e10f17a5f7c84",
          "sha256": "bbf4c819c8c3c40cefa59da2d1a97e79841c4f4856077f53ca6a6877f5577a3b"
        },
        "downloads": -1,
        "filename": "proxycrawl-2.0.1-py2-none-any.whl",
        "has_sig": false,
        "md5_digest": "def3bc4dfcf068720b1e10f17a5f7c84",
        "packagetype": "bdist_wheel",
        "python_version": "py2",
        "requires_python": null,
        "size": 8096,
        "upload_time": "2019-08-06T08:24:52",
        "upload_time_iso_8601": "2019-08-06T08:24:52.422978Z",
        "url": "https://files.pythonhosted.org/packages/38/13/2986d14d17a13008f08ab4fd4c18dad714606e07130c174868bd20f6c7c9/proxycrawl-2.0.1-py2-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "493ab10a4c43ce4bebc1ec1ab716bec69a9175f4440f215647ac3102149916b6",
          "md5": "ee7eb7d5d1ce06f181a79faad9fad160",
          "sha256": "b154117cd9f94449b618f7d590b2357cb8841bcc1a9f14607a70d730acb91720"
        },
        "downloads": -1,
        "filename": "proxycrawl-2.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ee7eb7d5d1ce06f181a79faad9fad160",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 8093,
        "upload_time": "2019-08-06T08:24:54",
        "upload_time_iso_8601": "2019-08-06T08:24:54.196482Z",
        "url": "https://files.pythonhosted.org/packages/49/3a/b10a4c43ce4bebc1ec1ab716bec69a9175f4440f215647ac3102149916b6/proxycrawl-2.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bdf267918850f8bf968f53be76dfaadd313e1525edfe121cd2ac57958f4487c9",
          "md5": "f94936a661918109f7d32236ba139b91",
          "sha256": "03c97e44f7a24f3c561b53053f3685a5ee58f348cb441105dacb19ba0591f4c6"
        },
        "downloads": -1,
        "filename": "proxycrawl-2.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "f94936a661918109f7d32236ba139b91",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 3617,
        "upload_time": "2019-08-06T08:24:57",
        "upload_time_iso_8601": "2019-08-06T08:24:57.165660Z",
        "url": "https://files.pythonhosted.org/packages/bd/f2/67918850f8bf968f53be76dfaadd313e1525edfe121cd2ac57958f4487c9/proxycrawl-2.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "2.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a61dee4e6376d208e3763c66fc6df76acf8547d0876cf85b369d25626637e333",
          "md5": "3559edef5961c2e9abcdfaeed998e5e8",
          "sha256": "740aa02507e02af3886150b40491bc049bfca7d90ad35958158ee1b0727487ef"
        },
        "downloads": -1,
        "filename": "proxycrawl-2.0.3-py2-none-any.whl",
        "has_sig": false,
        "md5_digest": "3559edef5961c2e9abcdfaeed998e5e8",
        "packagetype": "bdist_wheel",
        "python_version": "py2",
        "requires_python": null,
        "size": 8155,
        "upload_time": "2019-10-24T04:02:43",
        "upload_time_iso_8601": "2019-10-24T04:02:43.291876Z",
        "url": "https://files.pythonhosted.org/packages/a6/1d/ee4e6376d208e3763c66fc6df76acf8547d0876cf85b369d25626637e333/proxycrawl-2.0.3-py2-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8297fe0e82de4e7470ff8e100e58e6ef4c5811988a2bca0ae9554cd5980f9ab3",
          "md5": "13b9dc438ce4484cd52f6a10c6f1746a",
          "sha256": "d9a368eb5df961f7d7b5b4fad8723d62b1f87dba53ab8ef1f630309dbf33fef3"
        },
        "downloads": -1,
        "filename": "proxycrawl-2.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "13b9dc438ce4484cd52f6a10c6f1746a",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 8157,
        "upload_time": "2019-10-24T04:02:45",
        "upload_time_iso_8601": "2019-10-24T04:02:45.442023Z",
        "url": "https://files.pythonhosted.org/packages/82/97/fe0e82de4e7470ff8e100e58e6ef4c5811988a2bca0ae9554cd5980f9ab3/proxycrawl-2.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c0d5d6747020d74697c646775b22bc700ae334587fa7a9fa55f3cb9013b7e9f8",
          "md5": "6fbabc9c38e62ef271f7a1e80b8cd8e3",
          "sha256": "c20528c470100fc792bad623a107a91e90a2d34057c8dfaec272498e7a98748b"
        },
        "downloads": -1,
        "filename": "proxycrawl-2.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "6fbabc9c38e62ef271f7a1e80b8cd8e3",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 3704,
        "upload_time": "2019-10-24T04:02:47",
        "upload_time_iso_8601": "2019-10-24T04:02:47.386778Z",
        "url": "https://files.pythonhosted.org/packages/c0/d5/d6747020d74697c646775b22bc700ae334587fa7a9fa55f3cb9013b7e9f8/proxycrawl-2.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "2.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "765948c9c4e82199aeb88d0483918213582df5b3c8f8c047ca3c43e53ec45b56",
          "md5": "f99c6fa7d273446bf4b36c51089e1e62",
          "sha256": "ac5ea70886027f44b6c63984fa8afb2f404613e0637558b0b4440be30d0a69f3"
        },
        "downloads": -1,
        "filename": "proxycrawl-2.1.0-py2-none-any.whl",
        "has_sig": false,
        "md5_digest": "f99c6fa7d273446bf4b36c51089e1e62",
        "packagetype": "bdist_wheel",
        "python_version": "py2",
        "requires_python": null,
        "size": 8248,
        "upload_time": "2020-02-05T17:18:41",
        "upload_time_iso_8601": "2020-02-05T17:18:41.033757Z",
        "url": "https://files.pythonhosted.org/packages/76/59/48c9c4e82199aeb88d0483918213582df5b3c8f8c047ca3c43e53ec45b56/proxycrawl-2.1.0-py2-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4d852f3fa1c4ba3e8f3ce853ef33827dc7325405e714b55000136f4b3155f7be",
          "md5": "8863cf99e8a02256f1667b1f3239aeb2",
          "sha256": "f24b15337d3f6081dfe00a228a2f26eda8db5b647db6a0a4077881883451b470"
        },
        "downloads": -1,
        "filename": "proxycrawl-2.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "8863cf99e8a02256f1667b1f3239aeb2",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 8248,
        "upload_time": "2020-02-05T17:18:43",
        "upload_time_iso_8601": "2020-02-05T17:18:43.718779Z",
        "url": "https://files.pythonhosted.org/packages/4d/85/2f3fa1c4ba3e8f3ce853ef33827dc7325405e714b55000136f4b3155f7be/proxycrawl-2.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7dbe87b90283d2e1eed8ae496ed03ac1dff38a1202b2c6efbe250056f7641e85",
          "md5": "297eea115d8a248b6e639731b0836004",
          "sha256": "a7b34ef172f32f1b5ff4539288c16ee75662fcd587e65810e9e8041df6e53080"
        },
        "downloads": -1,
        "filename": "proxycrawl-2.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "297eea115d8a248b6e639731b0836004",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 3793,
        "upload_time": "2020-02-05T17:18:48",
        "upload_time_iso_8601": "2020-02-05T17:18:48.430980Z",
        "url": "https://files.pythonhosted.org/packages/7d/be/87b90283d2e1eed8ae496ed03ac1dff38a1202b2c6efbe250056f7641e85/proxycrawl-2.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "3.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "71bc054994ace4dc26fb97e835779ddd5c4dd0fd83ced5ec238fca5d0614dca7",
          "md5": "cc1889c0e13d07cac7ff6a0e957d34ef",
          "sha256": "cc5116fcbd98fb14fe6d58d372f0c89bf582315123b8f3225de2e1d0d0272ff2"
        },
        "downloads": -1,
        "filename": "proxycrawl-3.1.0-py2-none-any.whl",
        "has_sig": false,
        "md5_digest": "cc1889c0e13d07cac7ff6a0e957d34ef",
        "packagetype": "bdist_wheel",
        "python_version": "py2",
        "requires_python": null,
        "size": 10341,
        "upload_time": "2020-12-20T03:38:25",
        "upload_time_iso_8601": "2020-12-20T03:38:25.386710Z",
        "url": "https://files.pythonhosted.org/packages/71/bc/054994ace4dc26fb97e835779ddd5c4dd0fd83ced5ec238fca5d0614dca7/proxycrawl-3.1.0-py2-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4da66f8af2a99f14996b2ee0a89bc910a84b703b79dc4748cf8b2f27d5426863",
          "md5": "4e04bf81e6a34fce874ed5f2b49c3872",
          "sha256": "c771f0c8ef4b77dc696a5beba922c4c0f4c987a3f4208b1fabe89643cc0a5c76"
        },
        "downloads": -1,
        "filename": "proxycrawl-3.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "4e04bf81e6a34fce874ed5f2b49c3872",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 10341,
        "upload_time": "2020-12-20T03:38:26",
        "upload_time_iso_8601": "2020-12-20T03:38:26.869910Z",
        "url": "https://files.pythonhosted.org/packages/4d/a6/6f8af2a99f14996b2ee0a89bc910a84b703b79dc4748cf8b2f27d5426863/proxycrawl-3.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9f16d85e83b0db80512985ab5de21f504f88f8160a43c4bfbb2be6027a439ef2",
          "md5": "712a68f71cdf8e249d4a2d108de52506",
          "sha256": "aae95c90a4ae4b6fd823007f44a1c620e535532f0346d3c8693358f0d0da07f0"
        },
        "downloads": -1,
        "filename": "proxycrawl-3.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "712a68f71cdf8e249d4a2d108de52506",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 4641,
        "upload_time": "2020-12-20T03:38:30",
        "upload_time_iso_8601": "2020-12-20T03:38:30.156777Z",
        "url": "https://files.pythonhosted.org/packages/9f/16/d85e83b0db80512985ab5de21f504f88f8160a43c4bfbb2be6027a439ef2/proxycrawl-3.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "3.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2ab59d151510b73b7a96cc8013439b4649c89399594ac3d14ee94b33340d7df9",
          "md5": "bee06ee0b040efacbb40d0e4588e9117",
          "sha256": "cf5978ad9a2774f70357bf1815be6a0d9dc180e7c68803d2d9cc14e6afd3f361"
        },
        "downloads": -1,
        "filename": "proxycrawl-3.2.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "bee06ee0b040efacbb40d0e4588e9117",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 13253,
        "upload_time": "2021-09-10T14:54:05",
        "upload_time_iso_8601": "2021-09-10T14:54:05.437292Z",
        "url": "https://files.pythonhosted.org/packages/2a/b5/9d151510b73b7a96cc8013439b4649c89399594ac3d14ee94b33340d7df9/proxycrawl-3.2.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "846d965acd9137f48bb047dfa3fea75f6ab20a016d1eb74e2a50335cb288b732",
          "md5": "07ea9bc896b14e5562655e3cf86c48c5",
          "sha256": "45e4ffa809ee125b529b4d7e9c540e8cf070695791197a630b99091b458222f3"
        },
        "downloads": -1,
        "filename": "proxycrawl-3.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "07ea9bc896b14e5562655e3cf86c48c5",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 12920,
        "upload_time": "2021-09-10T14:54:09",
        "upload_time_iso_8601": "2021-09-10T14:54:09.246352Z",
        "url": "https://files.pythonhosted.org/packages/84/6d/965acd9137f48bb047dfa3fea75f6ab20a016d1eb74e2a50335cb288b732/proxycrawl-3.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "3.2.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b9dd4e8841cae3fd4d3299583fd6d1ebb5c0231529dd7c0319a2993567d31691",
          "md5": "52553d0aa6d2f10524aa7f78555141e2",
          "sha256": "b20e9e28457adb3c2b34050210f57f7bedee2feec8ee15a12edbf396ccd22ff8"
        },
        "downloads": -1,
        "filename": "proxycrawl-3.2.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "52553d0aa6d2f10524aa7f78555141e2",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 13260,
        "upload_time": "2021-09-14T13:40:08",
        "upload_time_iso_8601": "2021-09-14T13:40:08.442679Z",
        "url": "https://files.pythonhosted.org/packages/b9/dd/4e8841cae3fd4d3299583fd6d1ebb5c0231529dd7c0319a2993567d31691/proxycrawl-3.2.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "95e5371f42767290261a8c7697d49af1b74a147ac54b9cb111b04f160ba4b867",
          "md5": "f46beab43eff9215bda529883598d9d4",
          "sha256": "513f1a12d083c75415a32c495fd9ba3da2290ce6ddea3e13e531b4913e4063b7"
        },
        "downloads": -1,
        "filename": "proxycrawl-3.2.1.tar.gz",
        "has_sig": false,
        "md5_digest": "f46beab43eff9215bda529883598d9d4",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 12940,
        "upload_time": "2021-09-14T13:40:13",
        "upload_time_iso_8601": "2021-09-14T13:40:13.087064Z",
        "url": "https://files.pythonhosted.org/packages/95/e5/371f42767290261a8c7697d49af1b74a147ac54b9cb111b04f160ba4b867/proxycrawl-3.2.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "b9dd4e8841cae3fd4d3299583fd6d1ebb5c0231529dd7c0319a2993567d31691",
        "md5": "52553d0aa6d2f10524aa7f78555141e2",
        "sha256": "b20e9e28457adb3c2b34050210f57f7bedee2feec8ee15a12edbf396ccd22ff8"
      },
      "downloads": -1,
      "filename": "proxycrawl-3.2.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "52553d0aa6d2f10524aa7f78555141e2",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 13260,
      "upload_time": "2021-09-14T13:40:08",
      "upload_time_iso_8601": "2021-09-14T13:40:08.442679Z",
      "url": "https://files.pythonhosted.org/packages/b9/dd/4e8841cae3fd4d3299583fd6d1ebb5c0231529dd7c0319a2993567d31691/proxycrawl-3.2.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "95e5371f42767290261a8c7697d49af1b74a147ac54b9cb111b04f160ba4b867",
        "md5": "f46beab43eff9215bda529883598d9d4",
        "sha256": "513f1a12d083c75415a32c495fd9ba3da2290ce6ddea3e13e531b4913e4063b7"
      },
      "downloads": -1,
      "filename": "proxycrawl-3.2.1.tar.gz",
      "has_sig": false,
      "md5_digest": "f46beab43eff9215bda529883598d9d4",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 12940,
      "upload_time": "2021-09-14T13:40:13",
      "upload_time_iso_8601": "2021-09-14T13:40:13.087064Z",
      "url": "https://files.pythonhosted.org/packages/95/e5/371f42767290261a8c7697d49af1b74a147ac54b9cb111b04f160ba4b867/proxycrawl-3.2.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}