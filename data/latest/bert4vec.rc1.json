{
  "info": {
    "author": "wangzejun",
    "author_email": "wangzejunscut@126.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "bert4vec：一个基于预训练的句向量生成工具\n----------------------------------------\n\n环境\n~~~~\n\n-  transformers>=4.6.0,<5.0.0\n-  torch>=1.6.0\n-  numpy\n-  huggingface-hub\n-  faiss (optional)\n\n安装\n~~~~\n\n方式一\n^^^^^^\n\n.. code:: shell\n\n   pip install bert4vec\n\n方式二\n^^^^^^\n\n.. code:: shell\n\n   git clone https://github.com/zejunwang1/bert4vec\n   cd bert4vec/\n   python setup.py install\n\n功能介绍\n~~~~~~~~\n\n目前支持加载的句向量预训练模型包括 SimBERT、RoFormer-Sim（small 版本或\nbase 版本）和 paraphrase-multilingual-MiniLM-L12-v2，其中 SimBERT 与\nRoFormer-Sim\n为苏剑林老师开源的中文句向量表示模型，paraphrase-multilingual-MiniLM-L12-v2\n为 sentence-transformers 开放的多语言预训练模型，支持中文句向量生成。\n\n句向量生成\n^^^^^^^^^^\n\n.. code:: python\n\n   from bert4vec import Bert4Vec\n\n   # 支持四种模式：simbert-base/roformer-sim-base/roformer-sim-small/paraphrase-multilingual-minilm\n   model = Bert4Vec(mode='simbert-base')    \n   sentences = ['喜欢打篮球的男生喜欢什么样的女生', '西安下雪了？是不是很冷啊?', '第一次去见女朋友父母该如何表现？', '小蝌蚪找妈妈怎么样', \n                '给我推荐一款红色的车', '我喜欢北京']\n\n   vecs = model.encode(sentences, convert_to_numpy=True, normalize_to_unit=False)\n   # encode函数支持的默认输入参数有：batch_size=64, convert_to_numpy=False, normalize_to_unit=False\n\n   print(vecs.shape)\n   print(vecs)\n\n结果如下：\n\n.. figure:: https://github.com/zejunwang1/bert4vec/blob/main/images/fig1.png\n   :alt: image\n\n   image\n\n当 mode 参数缺失时，默认使用 roformer-sim-small 模型生成 384\n维度的句向量。当需要计算英文句子的稠密向量时，需要设置\nmode=‘paraphrase-multilingual-minilm’。\n\n相似度计算\n^^^^^^^^^^\n\n.. code:: python\n\n   from bert4vec import Bert4Vec\n\n   model = Bert4Vec(mode='paraphrase-multilingual-minilm')    \n   sent1 = ['喜欢打篮球的男生喜欢什么样的女生', '西安下雪了？是不是很冷啊?', '第一次去见女朋友父母该如何表现？', '小蝌蚪找妈妈怎么样', \n            '给我推荐一款红色的车', '我喜欢北京', 'That is a happy person']\n   sent2 = ['爱打篮球的男生喜欢什么样的女生', '西安的天气怎么样啊？还在下雪吗？', '第一次去见家长该怎么做', '小蝌蚪找妈妈是谁画的', \n            '给我推荐一款黑色的车', '我不喜欢北京', 'That is a happy dog']\n\n   similarity = model.similarity(sent1, sent2, return_matrix=False)\n   # similarity函数支持的默认输入参数有：batch_size=64, return_matrix=False\n   print(similarity)\n\n结果如下：\n\n.. figure:: https://github.com/zejunwang1/bert4vec/blob/main/images/fig2.png\n   :alt: image\n\n   image\n\n假设 ``sent1`` 包含 M 个句子，\\ ``sent2`` 包含 N 个句子，当 similarity\n函数的 return_matrix 参数设置为 False 时，函数返回 ``sent1`` 和\n``sent2`` 中同一行两个句子之间的余弦相似度，此时要求 M=N，否则会报错。\n\n当 similarity 函数的 return_matrix 参数设置为 True 时，函数返回一个 M*N\n相似度矩阵，矩阵的第 i 行第 j 列元素表示 ``sent1`` 的第 i 个句子和\n``sent2`` 的第 j 个句子之间的余弦相似度。\n\n.. code:: python\n\n   similarity = model.similarity(sent1, sent2, return_matrix=True)\n   print(similarity)\n\n结果如下：\n\n.. figure:: https://github.com/zejunwang1/bert4vec/blob/main/images/fig3.png\n   :alt: image\n\n   image\n\n语义检索\n^^^^^^^^\n\nbert4vec 支持使用 faiss 构建 cpu/gpu 句向量索引，Bert4Vec 类的\nbuild_index 函数参数列表如下：\n\n.. code:: python\n\n   def build_index(\n       self,\n       sentences_or_file_path: Union[str, List[str]],\n       ann_search: bool = False,\n       gpu_index: bool = False,\n       gpu_memory: int = 16,\n       n_search: int = 64,\n       batch_size: int = 64\n   )\n\n-  sentences_or_file_path：要进行索引构建的句子文件路径或句子列表。\n-  ann_search：是否进行近似最近邻查找。若为\n   False，则查找时进行暴力搜索计算，返回精确结果。\n-  gpu_index：是否构建 gpu 索引。\n-  gpu_memory：构建 gpu 索引时分配的显存，默认为 16G。\n-  n_search：近似最近邻查找时的搜索类别数量，该参数越大，查找结果越准确。\n-  batch_size：句向量计算时的批量大小。\n\n使用 Chinese-STS-B 验证集 (https://github.com/zejunwang1/CSTS)\n中去重后的所有句子构建索引，进行近似最近邻查找的示例代码如下：\n\n.. code:: python\n\n   from bert4vec import Bert4Vec\n\n   model = Bert4Vec(mode='roformer-sim-small')\n\n   sentences_path = \"./sentences.txt\"  # examples文件夹下\n   model.build_index(sentences_path, ann_search=True, gpu_index=False, n_search=32)\n\n   results = model.search(queries=['一个男人在弹吉他。', '一个女人在做饭'], threshold=0.6, top_k=5)\n   # threshold为最低相似度阈值，top_k为查找的近邻个数\n   print(results)\n\n结果如下：\n\n.. figure:: https://github.com/zejunwang1/bert4vec/blob/main/images/fig4.png\n   :alt: image\n\n   image\n\nBert4Vec 类支持使用如下函数保存和加载句向量索引文件：\n\n.. code:: python\n\n   def write_index(self, index_path: str)\n   def read_index(self, sentences_path: str, index_path: str, is_faiss_index: bool = True)\n\nsentences_path 为构建句向量索引的句子文件路径，index_path\n为句向量索引存储路径。\n\n模型下载\n~~~~~~~~\n\n笔者将原始的 SimBERT 和 RoFormer-Sim 模型权重转换为支持使用 Huggingface\nTransformers进行加载的模型格式：https://huggingface.co/WangZeJun\n\n.. code:: python\n\n   from bert4vec import Bert4Vec\n\n   model = Bert4Vec(mode='simbert-base', model_name_or_path='WangZeJun/simbert-base-chinese')\n   model = Bert4Vec(mode='roformer-sim-base', model_name_or_path='WangZeJun/roformer-sim-base-chinese')\n   model = Bert4Vec(mode='roformer-sim-small', model_name_or_path='WangZeJun/roformer-sim-small-chinese')\n   model = Bert4Vec(mode='paraphrase-multilingual-minilm', model_name_or_path='sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n\nmode 与 model_name_or_path 的对应关系如下：\n\n+-----------------------+----------------------------------------------+\n| mode                  | model_name_or_path                           |\n+=======================+==============================================+\n| simbert-base          | WangZeJun/simbert-base-chinese               |\n+-----------------------+----------------------------------------------+\n| roformer-sim-base     | WangZeJun/roformer-sim-base-chinese          |\n+-----------------------+----------------------------------------------+\n| roformer-sim-small    | WangZeJun/roformer-sim-small-chinese         |\n+-----------------------+----------------------------------------------+\n| paraphrase-multilingu | sentence-transformers/paraphrase-multilingua |\n| al-minilm             | l-MiniLM-L12-v2                              |\n+-----------------------+----------------------------------------------+\n\n当 mode 设置完成后，无需设置 model_name_or_path，代码会从\nhttps://huggingface.co/ 上自动下载相应的预训练模型权重并加载。\n\nContact\n~~~~~~~\n\n邮箱： wangzejunscut@126.com\n\n微信：autonlp\n\n链接\n~~~~\n\n-  https://huggingface.co/WangZeJun\n-  https://github.com/ZhuiyiTechnology/simbert\n-  https://github.com/ZhuiyiTechnology/roformer-sim\n-  https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
    "description_content_type": "",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/zejunwang1/bert4vec",
    "keywords": "",
    "license": "Apache License 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "bert4vec",
    "package_url": "https://pypi.org/project/bert4vec/",
    "platform": null,
    "project_url": "https://pypi.org/project/bert4vec/",
    "project_urls": {
      "Homepage": "https://github.com/zejunwang1/bert4vec"
    },
    "release_url": "https://pypi.org/project/bert4vec/0.3.0/",
    "requires_dist": [
      "transformers (<5.0.0,>=4.6.0)",
      "torch (>=1.6.0)",
      "numpy",
      "huggingface-hub"
    ],
    "requires_python": "",
    "summary": "Chinese Sentence Embeddings using SimBERT / RoFormer-Sim / Paraphrase-Multilingual-MiniLM",
    "version": "0.3.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17506022,
  "releases": {
    "0.3.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "844cf1be411efc060ddb791a9c5220b7b154b438e26ef40ab7ff6f6e9f59da2a",
          "md5": "b1413a12a694ee9025b71c55d496c8c0",
          "sha256": "f48efcf250b46f215a0d55ec7c857d08830b565e9cea69b054c1a5929a28eaf0"
        },
        "downloads": -1,
        "filename": "bert4vec-0.3.0.tar.gz",
        "has_sig": false,
        "md5_digest": "b1413a12a694ee9025b71c55d496c8c0",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 14513,
        "upload_time": "2023-03-30T07:15:53",
        "upload_time_iso_8601": "2023-03-30T07:15:53.886556Z",
        "url": "https://files.pythonhosted.org/packages/84/4c/f1be411efc060ddb791a9c5220b7b154b438e26ef40ab7ff6f6e9f59da2a/bert4vec-0.3.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "844cf1be411efc060ddb791a9c5220b7b154b438e26ef40ab7ff6f6e9f59da2a",
        "md5": "b1413a12a694ee9025b71c55d496c8c0",
        "sha256": "f48efcf250b46f215a0d55ec7c857d08830b565e9cea69b054c1a5929a28eaf0"
      },
      "downloads": -1,
      "filename": "bert4vec-0.3.0.tar.gz",
      "has_sig": false,
      "md5_digest": "b1413a12a694ee9025b71c55d496c8c0",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 14513,
      "upload_time": "2023-03-30T07:15:53",
      "upload_time_iso_8601": "2023-03-30T07:15:53.886556Z",
      "url": "https://files.pythonhosted.org/packages/84/4c/f1be411efc060ddb791a9c5220b7b154b438e26ef40ab7ff6f6e9f59da2a/bert4vec-0.3.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}