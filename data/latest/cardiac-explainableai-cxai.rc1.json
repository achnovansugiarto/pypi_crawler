{
  "info": {
    "author": "Alessa Stria",
    "author_email": "alessa.stria@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Introduction\nCurrently the cardiac explainable AI framework consists of these main components:\n- Config\n- Dataloader\n- Model training\n- Evaluation\n- CAM module will be provided later\n\nThe idea is to setup the config to the needs of different experiments and run it to produce results.\nThe config class has many different parameters which are explained in detail in the following table.\n\n| Supclass     | Variable Name         | Despriction                                                                                                                                                       | Default                                                                                 |\n|--------------|-----------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------|\n| File         | training_path         | Directory path to ACDC training data                                                                                                                              | E:/MasterThesis/MA_data/ACDC/training/training/                                         |\n|              | output_dir            | Directory where all results will be saved. Results = Processed datasets, logs, models, config JSON, datasplits, performance metrics CSV, confusion matrix, ROCAUC | ../Results/Test/                                                                        |\n|              | time                  | Time of creation in format: %Y%m%d-%H%M%S                                                                                                                         | datetime.datetime.now()                                                                 |\n|              | filename_h5           | Filename of created dataset HDF5 file                                                                                                                             | acdc_ds_\"+str(model.modeltype)+\".hdf5                                                   |\n|              | h5_path               | Filepath of dataset HDF5 file                                                                                                                                     | os.path.join(self.output_dir, self.filename_h5)                                         |\n|              | csv_name              | Filename of CSV dataset file                                                                                                                                      | \"acdc_ds_\"+str(model.modeltype)+\".csv\"                                                  |\n|              | csv_path              | Filepath of dataset CSV file                                                                                                                                      | os.path.join(self.output_dir,self.csv_name)                                             |\n|              | logdir                | Directory to save log training data                                                                                                                               | os.path.join(self.output_dir,'logs')                                                    |\n|              | experimentfolder      | Supfolder of experiments (e.g.: for specific task/modeltype)                                                                                                      | _'.join([model.task,model.modeltype])                                                   |\n|              | experimentname        | Name of current run                                                                                                                                               | _'.join([model.method,self.time])                                                       |\n|              | modeldir              | Directory to store model data (= models, config JSON, datasplits, performance metrics CSV, confusion matrix, ROCAUC)                                              | os.path.join(os.path.join(self.output_dir, self.experimentfolder), self.experimentname) |\n| Data         | img_height            | Image height for all slices                                                                                                                                       | 224                                                                                     |\n|              | img_width             | Image width for all slices                                                                                                                                        | 224                                                                                     |\n|              | as_stack              | If single slices are fake as RGB (staked 3 times) = True. Or saved as greyscale (only 1 dim) = False                                                              | TRUE                                                                                    |\n|              | nsplits               | Number of cross-validation splits                                                                                                                                 | 5                                                                                       |\n|              | randomstate           | Seed for data                                                                                                                                                     | 1337                                                                                    |\n|              | withmask              | If mask is included = True. Or if the segmentaiton masks are not used = False. (e.g. Not used if only classification is performed)                                | FALSE                                                                                   |\n|              | diagnosis_dict        | Dictionary of the different classes                                                                                                                               | {'NOR': 0, 'MINF': 1, 'DCM': 2, 'HCM': 3, 'RV': 4}                                      |\n|              | n_classes             | Number of classes. Here 5 different diagnosis, therefore 5 classes                                                                                                | 5                                                                                       |\n|              | img_shape             | Shape of one processed MR slice. (img_height, img_width, number of stacks)                                                                                        | (self.img_height, self.img_width,3)                                                     |\n| Model        | modeltype             | Type of NN model                                                                                                                                                  | vgg16                                                                                   |\n|              | task                  | Task of the NN, either segmentation or classification                                                                                                             | classification                                                                          |\n|              | weights               | Option for predefined weights                                                                                                                                     | None                                                                                    |\n|              | batch_size            | Batch size                                                                                                                                                        | 8                                                                                       |\n|              | shuffle_buffer_size   | Shuffle buffer size used for fitting the model to the data                                                                                                        | 2000                                                                                    |\n|              | seed                  | Seed for model training                                                                                                                                           | 3574                                                                                    |\n|              | base_learning_rate    | Starting learning rate                                                                                                                                            | 1,00E-02                                                                                |\n|              | dense                 | Number dense                                                                                                                                                      | 1024                                                                                    |\n|              | dropout               | Number of dropout                                                                                                                                                 | 0.2                                                                                     |\n|              | method                | Method used for training                                                                                                                                          | training_from_scratch                                                                   |\n|              | experiment_assignment | States which experiment this Model is assignet to                                                                                                                 | ex03_gradCAM                                                                            |\n|              | loss_function         | Loss function                                                                                                                                                     | categorical_crossentropy                                                                |\n| Augmentation | augmentation_type     | Type of augmentation. None, 'with_aug', and 'with_small_aug' to use predefined setting                                                                            | None                                                                                    |\n|              | rotation_range        | Range of rotation                                                                                                                                                 | None                                                                                    |\n|              | width_shift_range     | Range of width shift                                                                                                                                              | None                                                                                    |\n|              | height_shift_range    | Range of height shift                                                                                                                                             | None                                                                                    |\n|              | shear_range           | Range of shear                                                                                                                                                    | None                                                                                    |\n|              | zoom_range            | Range of zoom                                                                                                                                                     | None                                                                                    |\n|              | horizontal_flip       | If horizontal flip will be applied                                                                                                                                | FALSE                                                                                   |\n|              | vertical_flip         | If vertical flip will be applied                                                                                                                                  | FALSE                                                                                   |\n\nTo generate results multiple steps have to be followed:\n1. Processsed Dataset of ACDC\n2. Training/Validation/Testing split of data\n3. Training the model\n\n## 1. Processsed Dataset of ACDC\nTo create a processed Dataset the dataloader needs to be used. However, first a config object needs to be created. The parameters for the config class at initiation have to be given as a dictionary. The only path that has to be set for preproccessing the data is the file.training_path which should lead to the directory of the ACDC data (currently saved in my GoogleDrive: https://drive.google.com/file/d/1WlhhPj6CagTHFbDqEuz5jjCEVPRqrL2e/view?usp=sharing)\n#### ACDC Data \ninitially downloaded from: https://acdc.creatis.insa-lyon.fr/\n##### Reference\nO. Bernard, A. Lalande, C. Zotti, F. Cervenansky, et al. \"Deep Learning Techniques for Automatic MRI Cardiac Multi-structures Segmentation and Diagnosis: Is the Problem Solved ?\" in IEEE Transactions on Medical Imaging, vol. 37, no. 11, pp. 2514-2525, Nov. 2018 doi: 10.1109/TMI.2018.2837502\n\n### 1.1 Configuration class\nThe parameters of the config class can be set as dict for the initialization. Furthermore, an already existing config can be loaded. The parameters/variables need to be changed if other values instead of the default values should be used.\n#### Example code\n```python\nimport CXAI_config as CXAI\n\nds_params = {\n    \"data\": {\n            \"as_stack\": False,\n            \"diagnosis_dict\": {\n                \"DCM\": 2,\n                \"HCM\": 3,\n                \"MINF\": 1,\n                \"NOR\": 0,\n                \"RV\": 4\n            },\n            \"img_height\": 224,\n            \"img_width\": 224,\n            },\n    \"file\": {\n            \"training_path\": \"E:/MasterThesis/MA_data/ACDC/training/training/\",\n            \"experimentname\": 'testnr1',\n            },\n    \"model\": {\n            \"modeltype\": \"own\",\n            \"task\": \"classification\"\n            }\n}\n\ntestclass = CXAI.Experiment_config(ds_params)\n``` \n\n### 1.2 Dataloader Dataset creation\nThe dataloader consists of two parts. First the dataset_generator which prepares the ACDC dataset as HDF5 file and extract dataset information as CSV. The HDF5 file as well as the CSV s neccessary for the next steps.\n\n#### Example code\n```python\nimport CXAI_dataloader\n\ndataloaderobj = CXAI_dataloader.dataset_generator(_config = testclass)\n```\n## 2. Dataloader Datasplit\nTo create datasplits and cross-validation the cv_dataloader class needs to be called. The patient selection as well as the train/test/validation split for each fold are ssaved into the defined output_dir. \n#### Example code\n```python\ncv_dataloaderobj = CXAI_dataloader.cv_dataloader(testclass)\n```\n\n## 3. Training the model\nTo train the model the a model_training object needs to be initialized before calling the train_model function. Almost all training parameters as well as model design are defined by the configuration class. In the train_model function at the end of each split the evaluation will be automatically done.\n#### Example code\n```python\nimport CXAI_model_training\nmodel1 = CXAI_model_training.model_training(_config = testclass, _dataloader = cv_dataloaderobj).train_model()\n```\n\n\n### Example code to run framework\nTo create the first run through of the framework, this code could be used.\n\n```python\nimport CXAI_config as CXAI\nimport CXAI_dataloader\nimport CXAI_model_training\n\nds_params = {\n    \"file\": {\n            \"training_path\": \"E:/MasterThesis/MA_data/ACDC/training/training/\"\n            }\n}\n\ntestclass = CXAI.Experiment_config(ds_params)\ndataloaderobj = CXAI_dataloader.dataset_generator(_config = testclass)\ncv_dataloaderobj = CXAI_dataloader.cv_dataloader(testclass)\nmodel1 = CXAI_model_training.model_training(_config = testclass, _dataloader = cv_dataloaderobj).train_model()\n```\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://gitlab.com/plumdeq/alessa-master-thesis-mura",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "Cardiac-eXplainableAI-CXAI",
    "package_url": "https://pypi.org/project/Cardiac-eXplainableAI-CXAI/",
    "platform": "",
    "project_url": "https://pypi.org/project/Cardiac-eXplainableAI-CXAI/",
    "project_urls": {
      "Bug Tracker": "https://gitlab.com/plumdeq/alessa-master-thesis-mura/-/issues",
      "Homepage": "https://gitlab.com/plumdeq/alessa-master-thesis-mura"
    },
    "release_url": "https://pypi.org/project/Cardiac-eXplainableAI-CXAI/0.0.3/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "This package provides a framework that uses the ACDC data to train multiple CNN models and create GradCAMs of the resulting data.",
    "version": "0.0.3",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12148416,
  "releases": {
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1ccc73eee4cc3dba542f97a33fd89937b443b40cf8151f4878a342afb7f723e7",
          "md5": "6811aed243691c6ad3634f91621726ef",
          "sha256": "3175f3ad56761f069a7e8ea77ef673a593a99516cb9f9bdd9dc66f98ada427a2"
        },
        "downloads": -1,
        "filename": "Cardiac_eXplainableAI_CXAI-0.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "6811aed243691c6ad3634f91621726ef",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 28313,
        "upload_time": "2021-11-28T21:27:12",
        "upload_time_iso_8601": "2021-11-28T21:27:12.674123Z",
        "url": "https://files.pythonhosted.org/packages/1c/cc/73eee4cc3dba542f97a33fd89937b443b40cf8151f4878a342afb7f723e7/Cardiac_eXplainableAI_CXAI-0.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "49803270b48d1b6e2787fe2743303a35badccfb4dedf2d5eb5322bbc2f3ad5c9",
          "md5": "43da6614b4afa3e151c08a72afc10321",
          "sha256": "d3d351502ebc10cc388489ad5f18f34c43216527d6898ae313b9ce5d79c45984"
        },
        "downloads": -1,
        "filename": "Cardiac_eXplainableAI-CXAI-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "43da6614b4afa3e151c08a72afc10321",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 29613,
        "upload_time": "2021-11-28T21:27:14",
        "upload_time_iso_8601": "2021-11-28T21:27:14.084910Z",
        "url": "https://files.pythonhosted.org/packages/49/80/3270b48d1b6e2787fe2743303a35badccfb4dedf2d5eb5322bbc2f3ad5c9/Cardiac_eXplainableAI-CXAI-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "1ccc73eee4cc3dba542f97a33fd89937b443b40cf8151f4878a342afb7f723e7",
        "md5": "6811aed243691c6ad3634f91621726ef",
        "sha256": "3175f3ad56761f069a7e8ea77ef673a593a99516cb9f9bdd9dc66f98ada427a2"
      },
      "downloads": -1,
      "filename": "Cardiac_eXplainableAI_CXAI-0.0.3-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "6811aed243691c6ad3634f91621726ef",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 28313,
      "upload_time": "2021-11-28T21:27:12",
      "upload_time_iso_8601": "2021-11-28T21:27:12.674123Z",
      "url": "https://files.pythonhosted.org/packages/1c/cc/73eee4cc3dba542f97a33fd89937b443b40cf8151f4878a342afb7f723e7/Cardiac_eXplainableAI_CXAI-0.0.3-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "49803270b48d1b6e2787fe2743303a35badccfb4dedf2d5eb5322bbc2f3ad5c9",
        "md5": "43da6614b4afa3e151c08a72afc10321",
        "sha256": "d3d351502ebc10cc388489ad5f18f34c43216527d6898ae313b9ce5d79c45984"
      },
      "downloads": -1,
      "filename": "Cardiac_eXplainableAI-CXAI-0.0.3.tar.gz",
      "has_sig": false,
      "md5_digest": "43da6614b4afa3e151c08a72afc10321",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 29613,
      "upload_time": "2021-11-28T21:27:14",
      "upload_time_iso_8601": "2021-11-28T21:27:14.084910Z",
      "url": "https://files.pythonhosted.org/packages/49/80/3270b48d1b6e2787fe2743303a35badccfb4dedf2d5eb5322bbc2f3ad5c9/Cardiac_eXplainableAI-CXAI-0.0.3.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}