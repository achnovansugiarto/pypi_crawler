{
  "info": {
    "author": "DataKund",
    "author_email": "datakund@gmail.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "Wikipedia scraper is a python library to scrape for a Wikipedia. using browser automation. \r\nIt currently runs only on windows.\r\n\r\n## Scrape Wikipedia Current events\r\n In this, we first import library.\r\n\r\n\r\n```sh\r\nfrom wikipedia_scraper_in import *\r\nresponse = wikipedia.current_events()\r\n```\r\n\r\n### Response Data\r\n```sh\r\n        \"title\": \"An apartment fire\",\r\n        \"description\": \"An apartment fire in the Bronx, New York City, kills 17 people.\",\r\n        \"link\": \"/wiki/2022_Bronx_apartment_fire\"\r\n```\r\n\r\n## Scrape GDP per Capita\r\n In this, we first import library.\r\n\r\n\r\n```sh\r\nfrom wikipedia_scraper_in import *\r\nresponse = wikipedia.gdp_per_capita()\r\n```\r\n\r\n### Response Data\r\n```sh\r\n        \"country\": \"Monaco\\u202f*\",\r\n        \"region\": \"Europe\",\r\n        \"imf_estimate\": \"N/A\",\r\n        \"Imf_year\": \"190,532\",\r\n        \"un_estimate\": \"2019\",\r\n        \"un_year\": \"2019\"\r\n```\r\n \r\n \r\n### Bot Studio\r\n[Bot_Studio](https://pypi.org/project/bot_studio/) is needed for browser automation. When this library is imported in code, an automated browser will automatically open up in which it opens Wikipedia page and scrapes data from the page.\r\n\r\n### Installation\r\n```sh\r\npip install wikipedia-scraper-in\r\n```\r\n\r\n### Import\r\n```sh\r\nfrom wikipedia_scraper_in import *\r\n```\r\n\r\n### Get Current Events \r\n```sh\r\nresponse = wikipedia.current_events()\r\n\r\n```\r\n\r\n### Get GDP per Capita\r\n```sh\r\nresponse = wikipedia.gdp_per_capita()\r\n\r\n```\r\n### Run bot on cloud\r\n* Current Events - You can run bot on [Cloud](https://datakund.com/products/wikipedia-current-events?_pos=1&_sid=14f41b6c0&_ss=r).\r\n* GDP per Capita -  You can run bot on [Cloud](https://datakund.com/products/wikipedia-gdp-per-capita?_pos=1&_sid=e6747578c&_ss=r).\r\n\r\n### Send Feedback to Developers\r\n```sh\r\nbot_studio.send_feedback(feedback=\"Need help with this ......\")\r\n```\r\n\r\n### Contact Us\r\n* [Telegram](https://t.me/datakund)\r\n* [Website](https://datakund.com)\r\n\r\n\r\n\r\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "wikipedia python bot_studio automation product scraper city service",
    "license": "Apache License 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "wikipedia-scraper-in",
    "package_url": "https://pypi.org/project/wikipedia-scraper-in/",
    "platform": "",
    "project_url": "https://pypi.org/project/wikipedia-scraper-in/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/wikipedia-scraper-in/1.0.1/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "A python library to Scrape Wikipedia.",
    "version": "1.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12602648,
  "releases": {
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ded86c920a2c284e27712feeaf32b61349ee1652bb1f9271efde869cf1ed2d6b",
          "md5": "93cdb94f3559d7fcb078eaf288b3a6e8",
          "sha256": "6e1eacc71bad8b6654399d74ae0600dc25d355cf171a577fff893ea045b81c92"
        },
        "downloads": -1,
        "filename": "wikipedia_scraper_in-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "93cdb94f3559d7fcb078eaf288b3a6e8",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 2699,
        "upload_time": "2022-01-17T16:58:19",
        "upload_time_iso_8601": "2022-01-17T16:58:19.654000Z",
        "url": "https://files.pythonhosted.org/packages/de/d8/6c920a2c284e27712feeaf32b61349ee1652bb1f9271efde869cf1ed2d6b/wikipedia_scraper_in-1.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "805092115e7638b5eaa5ab406f1ee942c4d0ad285a13b38b0a1ef5205b9a565e",
          "md5": "632bce22b08a5caf79575833bcffe6ee",
          "sha256": "9748e8ec887d769993531df691f3f70a03ba36444281c0e9aebc37dbe6427420"
        },
        "downloads": -1,
        "filename": "wikipedia_scraper_in-1.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "632bce22b08a5caf79575833bcffe6ee",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 2832,
        "upload_time": "2022-01-18T01:35:50",
        "upload_time_iso_8601": "2022-01-18T01:35:50.880709Z",
        "url": "https://files.pythonhosted.org/packages/80/50/92115e7638b5eaa5ab406f1ee942c4d0ad285a13b38b0a1ef5205b9a565e/wikipedia_scraper_in-1.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "805092115e7638b5eaa5ab406f1ee942c4d0ad285a13b38b0a1ef5205b9a565e",
        "md5": "632bce22b08a5caf79575833bcffe6ee",
        "sha256": "9748e8ec887d769993531df691f3f70a03ba36444281c0e9aebc37dbe6427420"
      },
      "downloads": -1,
      "filename": "wikipedia_scraper_in-1.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "632bce22b08a5caf79575833bcffe6ee",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 2832,
      "upload_time": "2022-01-18T01:35:50",
      "upload_time_iso_8601": "2022-01-18T01:35:50.880709Z",
      "url": "https://files.pythonhosted.org/packages/80/50/92115e7638b5eaa5ab406f1ee942c4d0ad285a13b38b0a1ef5205b9a565e/wikipedia_scraper_in-1.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}