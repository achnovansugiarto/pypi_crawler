{
  "info": {
    "author": "Brunoais",
    "author_email": "brunoaiss@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7"
    ],
    "description": "# apispec-decorated-crawler\n\nPlugin for apispec which helps reusing the documentation by using a decorated function stack.\n\n## Extended Example\nWith this setup:\n```python\nfrom apispec import APISpec\nfrom flask import Flask\nfrom marshmallow import Schema, fields\n\nfrom brunoais.apispec.ext.decorated_crawler import docd_wraps\n\napp = Flask(__name__)\n\n# Create an APISpec\nspec = APISpec(\n    title='A safe Random swagger Petstore',\n    version='1.0.0',\n    plugins=[\n        'apispec.ext.flask',\n        'apispec.ext.marshmallow',\n        'brunoais.apispec.ext.decorated_crawler',\n    ],\n)\n\n\ndef decorates(func):\n    @docd_wraps(func)\n    def calling(*args, **kwargs):\n        \"\"\"\n            ---\n            get:\n                consumes:\n                  - application/xml+dec1\n                security:\n                    - AlmostBasicAuth: []\n                      BasicAuth: []\n                    - ApiKeyAuth: []\n                tags:\n                    - down1\n                    - up1\n                responses:\n                    400:\n                        description: he may fail {f[x-400-suffix]}\n                        schema: PetSchema\n            _:\n                responses:\n                    400:\n                        description: Global fail\n                        schema: PetSchema\n        \"\"\"\n        return func(*args, **kwargs)\n\n    return calling\n\n\ndef decorates2(func):\n    @docd_wraps(func)\n    def calling(*args, **kwargs):\n        \"\"\"\n        ---\n        get:\n            tags:\n                - get2\n                - up1\n            security:\n                - OAuth2: [scope1, scope2]\n            responses:\n                402:\n                    description: mefail\n                    schema: PetSchema\n        \"\"\"\n\n        return func(*args, **kwargs)\n\n    return calling\n\n\n```\nPassing a view function:\n```python\n\n@app.route('/random/<kind>')\n@decorates\n@decorates2\ndef random_pet(kind):\n    \"\"\"\n\n    A cute furry animal endpoint.\n    ---\n\n    post:\n        description: POST a pet\n    get:\n        description: Get a pet\n        security:\n            - ApiKeyAuth: []\n        consumes:\n          - application/json\n          - application/xml\n        produces:\n          - application/json\n          - application/xml\n        parameters:\n            - in: path\n              name: kind\n              required: true\n              type: string\n              description: Path Parameter description in Markdown.\n            - in: query\n              name: offset\n              type: string\n              description: Query Parameter description in Markdown.\n        responses:\n            200:\n                description: A pet to be returned\n                schema: PetSchema\n            400:\n                x-400-suffix: yeah yeah....\n    \"\"\"\n    pet = {\n        \"category\": [{\n            \"id\": 1,\n            \"name\": \"Named\"\n        }],\n        \"name\": \"woof\"\n    }\n    return jsonify(PetSchema().dump(pet).data)\n\n# Optional marshmallow support\nclass CategorySchema(Schema):\n    id = fields.Int()\n    name = fields.Str(required=True)\n\nclass PetSchema(Schema):\n    category = fields.Nested(CategorySchema, many=True)\n    name = fields.Str()\n\nspec.definition('Category', schema=CategorySchema)\nspec.definition('Pet', schema=PetSchema)\n\nwith app.test_request_context():\n    spec.add_path(view=random_pet)\n\n```\nThe result becomes\n```python\nprint(spec.to_yaml())\n```\n```yaml\ndefinitions:\n# ...\ninfo: {title: A safe Random swagger Petstore, version: 1.0.0}\npaths:\n  /random/{kind}:\n    post:\n      description: POST a pet\n      responses:\n        400: {description: Global fail, schema: PetSchema}\n    get:\n      consumes: [application/json, application/xml, application/xml+dec1]\n      description: Get a pet\n      parameters:\n      - {description: Path Parameter description in Markdown., in: path, name: kind,\n        required: true, type: string}\n      - {description: Query Parameter description in Markdown., in: query, name: offset,\n        type: string}\n      produces: [application/json, application/xml]\n      responses:\n        200:\n          description: A pet to be returned\n          schema: {$ref: '#/definitions/Pet'}\n        400: {description: he may fail yeah yeah...., schema: PetSchema, x-400-suffix: yeah\n            yeah....}\n        402: {description: mefail, schema: PetSchema}\n      security:\n      - ApiKeyAuth: []\n      - AlmostBasicAuth: []\n        BasicAuth: []\n      - OAuth2: [scope1, scope2]\n      tags: [down1, up1, get2]\nswagger: '2.0'\ntags: []\n\n```\n\n## Details\n\nThis is an operations helper that allows you to pass a decorated view and get the combined documentation of all decorator functions.\nIt required the view passed to `add_path`. Inspects view docstrings and its docd_wraps decorator functions and merges all the\ndocumentation into a single document.\nUseful if you use decorators to manage authentication or even if you have shared error pages and you do not\nwant to document common error states (status 400, status 500, etc...) individually on all views.\n\nAll documentation is merged from bottom-up, starting on the view function and ending on the topmost decorator.\nDecorators can declare a \"special\" HTTP method called _ (underscore). That one is applied last for all methods,\nalso from bottom up, in a subsequent pass.\n\n\n## Installation\n\n    pip install apispec-decorated-crawler\n\n## License\n\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/brunoais/apispec-decorated-crawler",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "apispec-decorated-crawler",
    "package_url": "https://pypi.org/project/apispec-decorated-crawler/",
    "platform": "",
    "project_url": "https://pypi.org/project/apispec-decorated-crawler/",
    "project_urls": {
      "Homepage": "https://github.com/brunoais/apispec-decorated-crawler"
    },
    "release_url": "https://pypi.org/project/apispec-decorated-crawler/2.0.0/",
    "requires_dist": [
      "apispec (~=1.0)"
    ],
    "requires_python": "",
    "summary": "Plugin for apispec which helps reusing the documentation by using a decorated function stack.",
    "version": "2.0.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 4836381,
  "releases": {
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "31bbf16671db10c3d76328e637d823652186383d9cd98699e32eb1f5ad049b64",
          "md5": "1cc71b4ec56b91534d7e35564f53a313",
          "sha256": "a7b640a1001a370d735979f5844035889a803b0e359afa4bdaf7c5ea630c1d02"
        },
        "downloads": -1,
        "filename": "apispec_decorated_crawler-1.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "1cc71b4ec56b91534d7e35564f53a313",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 6923,
        "upload_time": "2018-06-24T21:16:43",
        "upload_time_iso_8601": "2018-06-24T21:16:43.417779Z",
        "url": "https://files.pythonhosted.org/packages/31/bb/f16671db10c3d76328e637d823652186383d9cd98699e32eb1f5ad049b64/apispec_decorated_crawler-1.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "66ca919e0e45e46cd784399a7ed8c0a4cf1bcc9abda882e864343dd98c043c8a",
          "md5": "c5e9b83e71712fa77dbe021b900f79ef",
          "sha256": "c527dc2eabe541e92880aa12c2d2197a8243659e3ef60f74352cc655f71b11d3"
        },
        "downloads": -1,
        "filename": "apispec-decorated-crawler-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "c5e9b83e71712fa77dbe021b900f79ef",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 6381,
        "upload_time": "2018-06-24T21:16:44",
        "upload_time_iso_8601": "2018-06-24T21:16:44.524177Z",
        "url": "https://files.pythonhosted.org/packages/66/ca/919e0e45e46cd784399a7ed8c0a4cf1bcc9abda882e864343dd98c043c8a/apispec-decorated-crawler-1.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fdf6c06823e87c2b378da5882d68d54ca657c586b5f3f4a9979a6390656ce43f",
          "md5": "1ebcde77c8fc8f9a0a8cc52410472cfe",
          "sha256": "be17f1d22845faf23c196073a1e76a145947ab63c3ed3a3867cd4c83bfddc46b"
        },
        "downloads": -1,
        "filename": "apispec_decorated_crawler-1.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "1ebcde77c8fc8f9a0a8cc52410472cfe",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 6912,
        "upload_time": "2018-07-07T17:27:28",
        "upload_time_iso_8601": "2018-07-07T17:27:28.595094Z",
        "url": "https://files.pythonhosted.org/packages/fd/f6/c06823e87c2b378da5882d68d54ca657c586b5f3f4a9979a6390656ce43f/apispec_decorated_crawler-1.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "be2011bf2f8549489eabac2b45d07cc505b637ef51464814133fc9c2833fe40b",
          "md5": "7b1f9fbe89f1f959f0aac299d5c7f67f",
          "sha256": "97579cabfe8cc6ae9512ac17bdb0dbdbfd5761e6623ef7d2ffccc92c9edf790b"
        },
        "downloads": -1,
        "filename": "apispec-decorated-crawler-1.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "7b1f9fbe89f1f959f0aac299d5c7f67f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 6374,
        "upload_time": "2018-07-07T17:27:30",
        "upload_time_iso_8601": "2018-07-07T17:27:30.519280Z",
        "url": "https://files.pythonhosted.org/packages/be/20/11bf2f8549489eabac2b45d07cc505b637ef51464814133fc9c2833fe40b/apispec-decorated-crawler-1.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "2.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "466208e3de53e07f0ae3598138d09733de253f6717851516a8f7a3f58a461c8d",
          "md5": "961bbb614e8fa6229e7dec8f0969e9db",
          "sha256": "6f311b800f827e6dc4cc6b6485932c82b25eb2161c2810100e6da96eeb49b532"
        },
        "downloads": -1,
        "filename": "apispec_decorated_crawler-2.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "961bbb614e8fa6229e7dec8f0969e9db",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 7756,
        "upload_time": "2019-02-18T18:22:06",
        "upload_time_iso_8601": "2019-02-18T18:22:06.905178Z",
        "url": "https://files.pythonhosted.org/packages/46/62/08e3de53e07f0ae3598138d09733de253f6717851516a8f7a3f58a461c8d/apispec_decorated_crawler-2.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "62fd89c7d0ba6b5b17769c6c184e2bf5840e0ff0e962f2d9221a93179d02239d",
          "md5": "a704d98fd9d1770c380fa397280e3ce5",
          "sha256": "d43336a69c2d8e3b16560434c85a56cd4ae4521a6bfccbc13f6937675e6a3ff5"
        },
        "downloads": -1,
        "filename": "apispec-decorated-crawler-2.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "a704d98fd9d1770c380fa397280e3ce5",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 7099,
        "upload_time": "2019-02-18T18:22:08",
        "upload_time_iso_8601": "2019-02-18T18:22:08.582798Z",
        "url": "https://files.pythonhosted.org/packages/62/fd/89c7d0ba6b5b17769c6c184e2bf5840e0ff0e962f2d9221a93179d02239d/apispec-decorated-crawler-2.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "466208e3de53e07f0ae3598138d09733de253f6717851516a8f7a3f58a461c8d",
        "md5": "961bbb614e8fa6229e7dec8f0969e9db",
        "sha256": "6f311b800f827e6dc4cc6b6485932c82b25eb2161c2810100e6da96eeb49b532"
      },
      "downloads": -1,
      "filename": "apispec_decorated_crawler-2.0.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "961bbb614e8fa6229e7dec8f0969e9db",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 7756,
      "upload_time": "2019-02-18T18:22:06",
      "upload_time_iso_8601": "2019-02-18T18:22:06.905178Z",
      "url": "https://files.pythonhosted.org/packages/46/62/08e3de53e07f0ae3598138d09733de253f6717851516a8f7a3f58a461c8d/apispec_decorated_crawler-2.0.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "62fd89c7d0ba6b5b17769c6c184e2bf5840e0ff0e962f2d9221a93179d02239d",
        "md5": "a704d98fd9d1770c380fa397280e3ce5",
        "sha256": "d43336a69c2d8e3b16560434c85a56cd4ae4521a6bfccbc13f6937675e6a3ff5"
      },
      "downloads": -1,
      "filename": "apispec-decorated-crawler-2.0.0.tar.gz",
      "has_sig": false,
      "md5_digest": "a704d98fd9d1770c380fa397280e3ce5",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 7099,
      "upload_time": "2019-02-18T18:22:08",
      "upload_time_iso_8601": "2019-02-18T18:22:08.582798Z",
      "url": "https://files.pythonhosted.org/packages/62/fd/89c7d0ba6b5b17769c6c184e2bf5840e0ff0e962f2d9221a93179d02239d/apispec-decorated-crawler-2.0.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}