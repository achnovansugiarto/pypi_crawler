{
  "info": {
    "author": "Femtosense",
    "author_email": "info@femtosense.ai",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Developers",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3 :: Only",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8"
    ],
    "description": "![Build Status](https://codebuild.us-west-2.amazonaws.com/badges?uuid=eyJlbmNyeXB0ZWREYXRhIjoiRGpDOFpEOXF1M0prSy9OOVNkZ3F2NkRKM0NNMG8xbmpZU0hZdUp1ejhHOEswdDRhOEZOakMrdWZyaHp1WGVtQ1lVTStzRUpXaFlYeFZPSEJFd21NdjF3PSIsIml2UGFyYW1ldGVyU3BlYyI6InJZYzhuZ3d3a1FUUzBzM0kiLCJtYXRlcmlhbFNldFNlcmlhbCI6MX0%3D&branch=master)\n\n# fmot\nThe Femtosense Model Optimization Toolkit (fmot) quantizes neural network models for deployment on Femtosense hardware.\n\n## Installation\n```\ngit clone https://github.com/femtosense/fmot.git\ncd fmot\npip install -e .\n```\n\n## Quantizing Models\nYou get to define your pytorch models however you want. Once your model has been trained, it can be converted to the `fmot.qat` format by calling `fmot.convert.convert_torch_to_qat`. This resulting `qat` model will initially not be quantized. To quantize it, provide your model, along with an iteratable of sample inputs, to `fmot.qat.control.quantize`. These test inputs will help the `qat` model to find an optimal quantization configuration. The resulting quantized model will now simulate the fixed-point integer arithmetic, exactly how it will be performed on Femtosense hardware.\n```python\nimport torch\nimport fmot\n\nclass MyModel(torch.nn.Module):\n    def __init__(self, din, dout):\n        super().__init__()\n        weights = torch.rand(din, dout)\n        self.weight = torch.nn.Parameter(weights)\n        self.linear = torch.nn.Linear(dout, dout)\n\n    def forward(self, x):\n        x = torch.matmul(x, self.weight)\n        x = x.relu()\n        x = self.linear(x)\n        x = torch.sigmoid(x)\n        return x\n\nmodel = MyModel(128, 256)\n\n### TRAINING GOES HERE\n\n# Convert the trained model to qat format\nquant_model = fmot.convert.convert_torch_to_qat(model)\n# Provide a set of sample inputs to choose an optimal quantization scheme\nquant_model = fmot.qat.control.quantize(quant_model, [torch.randn(16, 128) for __ in range(20)])\n```\n**NOTE: THE ABOVE API NEEDS A TOP-LEVEL SHORTCUT**\n\n## Fine-Tuning Quantized Models\n\n## Setting Custom Bitwidths\n\n## Emitting FQIR\nOnce your model has been quantized, \n\n## Building and Viewing Sphinx Documentation\nFirst, let's install sphinx. On macOs:\n```\nbrew install sphinx-doc\n```\nOn [other platforms](https://www.sphinx-doc.org/en/1.8/usage/installation.html).\n\nNow, let's install some dependencies with pip:\n```\ncd docs\npip install -r requirements.txt\n```\n\nYou can now build the documentation by running\n```\nmake html\n```\n\nThis documentation can be viewed in your browser with `Open File` (âŒ˜O). Navigate to\n```\n{fmot_base}/docs/_build/html/index.html\n```\n\n## Running Tests\n\n## Pruning Weight Matrices\n\n## Sparsifying Activations\n\n## Using Custom Layers\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/femtosense/fmot",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "fmot",
    "package_url": "https://pypi.org/project/fmot/",
    "platform": null,
    "project_url": "https://pypi.org/project/fmot/",
    "project_urls": {
      "Homepage": "https://github.com/femtosense/fmot",
      "Source": "https://github.com/femtosense/fmot"
    },
    "release_url": "https://pypi.org/project/fmot/1.3.4/",
    "requires_dist": [
      "Cython",
      "torch (>=1.12.1)",
      "numpy (>=1.18.0)",
      "scipy",
      "python-speech-features",
      "tqdm",
      "networkx",
      "deprecation",
      "tabulate",
      "datashader",
      "colorcet",
      "matplotlib"
    ],
    "requires_python": ">=3.6",
    "summary": "Femtosense Model Optimization Toolkit",
    "version": "1.3.4",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17257178,
  "releases": {
    "1.3.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7ce1e00306e4afe661961f95369b015f78cd078a50b9468bed24d4c05cc83c81",
          "md5": "05154a39b3045bd8e288364c87b51c09",
          "sha256": "6c7f469334a84722d95b8deb2c1efe07c1d154008a60dccc03f1d0c93921f75c"
        },
        "downloads": -1,
        "filename": "fmot-1.3.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "05154a39b3045bd8e288364c87b51c09",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 208658,
        "upload_time": "2023-03-12T01:50:17",
        "upload_time_iso_8601": "2023-03-12T01:50:17.267156Z",
        "url": "https://files.pythonhosted.org/packages/7c/e1/e00306e4afe661961f95369b015f78cd078a50b9468bed24d4c05cc83c81/fmot-1.3.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "7ce1e00306e4afe661961f95369b015f78cd078a50b9468bed24d4c05cc83c81",
        "md5": "05154a39b3045bd8e288364c87b51c09",
        "sha256": "6c7f469334a84722d95b8deb2c1efe07c1d154008a60dccc03f1d0c93921f75c"
      },
      "downloads": -1,
      "filename": "fmot-1.3.4-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "05154a39b3045bd8e288364c87b51c09",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 208658,
      "upload_time": "2023-03-12T01:50:17",
      "upload_time_iso_8601": "2023-03-12T01:50:17.267156Z",
      "url": "https://files.pythonhosted.org/packages/7c/e1/e00306e4afe661961f95369b015f78cd078a50b9468bed24d4c05cc83c81/fmot-1.3.4-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}