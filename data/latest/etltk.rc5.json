{
  "info": {
    "author": "Robel Equbasilassie",
    "author_email": "robiki4life@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Ethiopian Language Toolkit (etltk)\n\n- The Ethiopian Natural Language Toolkit (ETLTK) project aimed to develop a suite of open source Natural Language Processing modules for the Ethiopian languages.\n- The Ethiopian Language Toolkit (ETLTK) is built using python language and takes inspiration from `spacy` and `nltk` libraries.\n\n## Installation\n\n### pip\n\n- **etltk** supports Python 3.6 or later. We recommend that you install etltk via `pip`, the Python package manager. To install, simply run:\n\n  ```python\n    pip install etltk\n  ```\n\n### From Source\n\n- Alternatively, you can also install from source via ethiopian_language_toolkitРђЎs git repository, which will give you more flexibility in developing on top of etltk. For this option, run\n\n  ```python\n    git clone https://github.com/robikieq/ethiopian_language_toolkit.git\n    \n    cd ethiopian_language_toolkit\n    \n    pip install -e .\n  ```\n\n## Documentation\n\nhttps://etltk.netlify.app/\n\n## Usage\n\n1. Amharic text preprocessing with Amharic document\n    - Preprocessing amharic text is very simple: you can simply pass the text to the `Amharic` document and access all annotations from the returned Amharic document object:\n\n    ```python\n      from etltk import Amharic\n\n      sample_text = \"\"\"\n        рѕџрІФрІЮрІФ 14рЇБ 2014 рІЊ.рѕЮ ­ЪцЌ рЅаріарїѕрѕГ рІ░рѕерїЃ рІерѕ░рІЇ рѕ░рѕФрѕй ріарѕхрЅ░рІЇрѕјрЅх /Artificial Intelligence/ ріарѕЂріЋ ріФрѕѕрЅарЅх рІЮрЅЁрЅ░ріЏ рІ░рѕерїЃ рІѕрІ░ рѕІрЅђ рІ░рѕерїЃ рѕѕрѕЏрІхрѕерѕхрЇБ рѕЃрїѕрѕГріЏ рЅІріЋрЅІрІјрЅйріЋ рѕѕрІЊрѕѕрѕЮ рЅ░рІ░рѕФрѕй рѕѕрѕЏрІхрѕерїЇрЇБ ріарїѕрѕФрІі ріарЅЁрѕЮріЋ рѕѕрѕЏрѕ│рІ░рїЇ ріЦріЊ рЅ░рїарЅЃрѕџ рѕѕрѕўрѕєріЋ рЅарїІрѕФ ріарЅЦрѕ« рѕўрѕхрѕФрЅ▒ ріЦрїЁрїЇ рїарЅЃрѕџ ріљрІЇрЇАрЇА\n\n        рЅарѕЏрѕйріЋ рІЊрѕхрЅ░рѕЮрѕ« (Machine Learning) ріарѕЏріФріЮріљрЅх рІерїйрѕЂрЇЇ ріЊрѕЎріЊрІјрЅй рЅаріарѕГрЅ▓рЇірѕ╗рѕЇ рібріЋрЅ░рѕѕрїђріЋрѕх рѕЦрѕГрІЊрЅх рѕѕрѕЏрѕ░рѕЇрїаріЋрЇБ рІерїйрѕЂрЇЇ рІ│рЅ│ріЋ рѕўрѕ░рЅЦрѕ░рЅЦ ріЦріЊ рѕЏрІ░рѕФрїђрЅхрЇц рІеріЊрЅ╣рѕФрѕЇ рѕІріЋрїЅрІїрїЁ рЇЋрѕ«рѕ░рѕ▓ріЋрїЇ рЅ▒рѕјрЅйріЋ /Natural Language Processing Tools/ рЅарѕўрїарЅђрѕЮ рІерїйрѕЂрЇЇ рІ│рЅ│ріЋ рЇЋрѕ«рѕ░рѕх рѕЏрІхрѕерїЇ рЅ░рЅђрІ│рѕџ ріЦріЊ рѕўрѕ░рѕерЅ│рІі рїЅрІ│рІГ ріљрІЇрЇб\n      \"\"\"\n  \n      # Annotating Amharic document\n      doc = Amharic(sample_text)\n\n      # print the `clean` text:\n      print(doc)\n      \n      # output: Amharic(\"рѕџрІФрІЮрІФ рІЊрѕўрЅ░ рѕЮрѕЁрѕерЅх рЅаріарїѕрѕГ рІ░рѕерїЃ рІерѕ░рІЇ рѕ░рѕФрѕй ріарѕхрЅ░рІЇрѕјрЅх ріарѕЂріЋ ріФрѕѕрЅарЅх рІЮрЅЁрЅ░ріЏ рІ░рѕерїЃ рІѕрІ░ рѕІрЅђ рІ░рѕерїЃ рѕѕрѕЏрІхрѕерѕх рѕђрїѕрѕГріЏ рЅІріЋрЅІрІјрЅйріЋ рѕѕріарѕѕрѕЮ рЅ░рІ░рѕФрѕй рѕѕрѕЏрІхрѕерїЇ ріарїѕрѕФрІі ріарЅЁрѕЮріЋ рѕѕрѕЏрѕ│рІ░рїЇ ріЦріЊ рЅ░рїарЅЃрѕџ рѕѕрѕўрѕєріЋ рЅарїІрѕФ ріарЅЦрѕ« рѕўрѕхрѕФрЅ▒ ріЦрїЁрїЇ рїарЅЃрѕџ ріљрІЇ рЅарѕЏрѕйріЋ ріарѕхрЅ░рѕЮрѕ« ріарѕЏріФріЮріљрЅх рІерЇЁрѕЂрЇЇ ріЊрѕЎріЊрІјрЅй рЅаріарѕГрЅ▓рЇірѕ╗рѕЇ рібріЋрЅ░рѕѕрїђріЋрѕх рѕхрѕГріарЅх рѕѕрѕЏрѕ░рѕЇрїаріЋ рІерЇЁрѕЂрЇЇ рІ│рЅ│ріЋ рѕўрѕ░рЅЦрѕ░рЅЦ ріЦріЊ рѕЏрІ░рѕФрїђрЅх рІеріЊрЅ╣рѕФрѕЇ рѕІріЋрїЅрІїрїЁ рЇЋрѕ«рѕ░рѕ▓ріЋрїЇ рЅ▒рѕјрЅйріЋ рЅарѕўрїарЅђрѕЮ рІерЇЁрѕЂрЇЇ рІ│рЅ│ріЋ рЇЋрѕ«рѕ░рѕх рѕЏрІхрѕерїЇ рЅ░рЅђрІ│рѕџ ріЦріЊ рѕўрѕ░рѕерЅ│рІі рїЅрІ│рІГ ріљрІЇ\")\n    ```\n\n     - Here is a another example of performing text cleaning on a piece of plaintext using `clean_amharic` function:\n\n    ```python\n    from etltk.lang.am import (\n      preprocessing,\n      clean_amharic\n    )\n\n    sample_text = \"\"\"\n      рѕџрІФрІЮрІФ 14рЇБ 2014 рІЊ.рѕЮ ­ЪцЌ рЅаріарїѕрѕГ рІ░рѕерїЃ рІерѕ░рІЇ рѕ░рѕФрѕй ріарѕхрЅ░рІЇрѕјрЅх /Artificial Intelligence/ ріарѕЂріЋ ріФрѕѕрЅарЅх рІЮрЅЁрЅ░ріЏ рІ░рѕерїЃ рІѕрІ░ рѕІрЅђ рІ░рѕерїЃ рѕѕрѕЏрІхрѕерѕхрЇБ рѕЃрїѕрѕГріЏ рЅІріЋрЅІрІјрЅйріЋ рѕѕрІЊрѕѕрѕЮ рЅ░рІ░рѕФрѕй рѕѕрѕЏрІхрѕерїЇрЇБ ріарїѕрѕФрІі ріарЅЁрѕЮріЋ рѕѕрѕЏрѕ│рІ░рїЇ ріЦріЊ рЅ░рїарЅЃрѕџ рѕѕрѕўрѕєріЋ рЅарїІрѕФ ріарЅЦрѕ« рѕўрѕхрѕФрЅ▒ ріЦрїЁрїЇ рїарЅЃрѕџ ріљрІЇрЇАрЇА\n\n      рЅарѕЏрѕйріЋ рІЊрѕхрЅ░рѕЮрѕ« (Machine Learning) ріарѕЏріФріЮріљрЅх рІерїйрѕЂрЇЇ ріЊрѕЎріЊрІјрЅй рЅаріарѕГрЅ▓рЇірѕ╗рѕЇ рібріЋрЅ░рѕѕрїђріЋрѕх рѕЦрѕГрІЊрЅх рѕѕрѕЏрѕ░рѕЇрїаріЋрЇБ рІерїйрѕЂрЇЇ рІ│рЅ│ріЋ рѕўрѕ░рЅЦрѕ░рЅЦ ріЦріЊ рѕЏрІ░рѕФрїђрЅхрЇц рІеріЊрЅ╣рѕФрѕЇ рѕІріЋрїЅрІїрїЁ рЇЋрѕ«рѕ░рѕ▓ріЋрїЇ рЅ▒рѕјрЅйріЋ /Natural Language Processing Tools/ рЅарѕўрїарЅђрѕЮ рІерїйрѕЂрЇЇ рІ│рЅ│ріЋ рЇЋрѕ«рѕ░рѕх рѕЏрІхрѕерїЇ рЅ░рЅђрІ│рѕџ ріЦріЊ рѕўрѕ░рѕерЅ│рІі рїЅрІ│рІГ ріљрІЇрЇб\n    \"\"\"\n\n    # Define a custom preprocessor pipeline\n    custom_pipeline = [\n      preprocessing.remove_emojis, \n      preprocessing.remove_digits,\n      preprocessing.remove_ethiopic_punct,\n      preprocessing.remove_english_chars, \n      preprocessing.remove_punct\n    ]\n    \n    # `clean_amharic` function takes a custom pipeline, if not uses the default pipeline\n    cleaned = clean_amharic(input_text, abbrev=False, pipeline=custom_pipeline)\n\n    # print the `clean` text:\n    print(cleaned)\n    # output: рѕџрІФрІЮрІФ рІЊрѕўрЅ░ рѕЮрѕЁрѕерЅх рЅаріарїѕрѕГ рІ░рѕерїЃ рІерѕ░рІЇ рѕ░рѕФрѕй ріарѕхрЅ░рІЇрѕјрЅх ріарѕЂріЋ ріФрѕѕрЅарЅх рІЮрЅЁрЅ░ріЏ рІ░рѕерїЃ рІѕрІ░ рѕІрЅђ рІ░рѕерїЃ рѕѕрѕЏрІхрѕерѕх рѕђрїѕрѕГріЏ рЅІріЋрЅІрІјрЅйріЋ рѕѕріарѕѕрѕЮ рЅ░рІ░рѕФрѕй рѕѕрѕЏрІхрѕерїЇ ріарїѕрѕФрІі ріарЅЁрѕЮріЋ рѕѕрѕЏрѕ│рІ░рїЇ ріЦріЊ рЅ░рїарЅЃрѕџ рѕѕрѕўрѕєріЋ рЅарїІрѕФ ріарЅЦрѕ« рѕўрѕхрѕФрЅ▒ ріЦрїЁрїЇ рїарЅЃрѕџ ріљрІЇ рЅарѕЏрѕйріЋ ріарѕхрЅ░рѕЮрѕ« ріарѕЏріФріЮріљрЅх рІерЇЁрѕЂрЇЇ ріЊрѕЎріЊрІјрЅй рЅаріарѕГрЅ▓рЇірѕ╗рѕЇ рібріЋрЅ░рѕѕрїђріЋрѕх рѕхрѕГріарЅх рѕѕрѕЏрѕ░рѕЇрїаріЋ рІерЇЁрѕЂрЇЇ рІ│рЅ│ріЋ рѕўрѕ░рЅЦрѕ░рЅЦ ріЦріЊ рѕЏрІ░рѕФрїђрЅх рІеріЊрЅ╣рѕФрѕЇ рѕІріЋрїЅрІїрїЁ рЇЋрѕ«рѕ░рѕ▓ріЋрїЇ рЅ▒рѕјрЅйріЋ рЅарѕўрїарЅђрѕЮ рІерЇЁрѕЂрЇЇ рІ│рЅ│ріЋ рЇЋрѕ«рѕ░рѕх рѕЏрІхрѕерїЇ рЅ░рЅђрІ│рѕџ ріЦріЊ рѕўрѕ░рѕерЅ│рІі рїЅрІ│рІГ ріљрІЇ\n    ```\n\n2. Tokenization - Sentence\n    - Here is a simple example of performing sentence tokenization on a piece of plaintext using Amharic document:\n    - Within Amharic document, annotations are further stored in `Sentences`\n\n    ```python\n    from etltk import Amharic\n\n    sample_text = \"\"\"\n      рІерѕЏрѕйріЋ рѕѕрѕГріњріЋрїЇ рѕхрѕЇрЅ░-рЅђрѕўрѕ«рЅй  (Algorithms) рЅарѕўрїарЅђрѕЮ рЅІріЋрЅІрІјрЅйріЋ рѕўрѕѕрІерЅх ріЦріЊ рѕўрѕерІ│рЅхрЇБ рІерїйрѕЂрЇЇ рІГрІўрЅХрЅйріЋ рѕўрѕѕрІерЅхрЇБ рІерЅІріЋрЅІріЋ рѕўрІІрЅЁрѕГ рѕўрЅ░ріЋрЅ░ріЋ рІерѕџрІФрѕхрЅйрѕЅ рІерѕЃрїѕрѕфріЏ ріЊрЅ╣рѕФрѕЇ рѕІріЋрїЅрІїрїЁ рЇЋрѕ«рѕ░рѕ▓ріЋрїЇ рЅ▒рѕјрЅй (NLP tools) рЇБ рѕхрѕЇрЅ░-рЅђрѕўрѕ«рЅй ріЦріЊ рѕърІ┤рѕјрЅйріЋ рѕЏрІўрїІрїђрЅх рЅ░рїѕрЅб ріљрІЇрЇб рЅарІџрѕЁрѕЮ рѕўрѕ░рѕерЅх ріарѕЏрѕГріЏрЇБ ріарЇІріЋ рідрѕ«рѕърЇБ рѕХрѕЏрѕіріЏ ріЦріЊ рЅхрїЇрѕГріЏ рЅІріЋрЅІрІјрЅйріЋ рѕѕрѕЏрѕйріЋ рІерѕЏрѕхрЅ░рѕЏрѕГ рѕѓрІ░рЅхріЋ рЅђрѕІрѕЇріЊ рІерЅ░рЅђрѕІрЅ░рЇЇ ріЦріЋрІ▓рѕєріЋ рІФрѕхрЅйрѕІрѕЇрЇАрЇА\n    \"\"\"\n\n    # Annotating Amharic Text\n    doc = Amharic(sample_text)\n\n    # print all list of `Sentence` in a document:\n    print(doc.sentences)\n    # output: [Sentence(\"рІерѕЏрѕйріЋ рѕѕрѕГріњріЋрїЇ рѕхрѕЇрЅ░рЅђрѕўрѕ«рЅй рЅарѕўрїарЅђрѕЮ рЅІріЋрЅІрІјрЅйріЋ рѕўрѕѕрІерЅх ріЦріЊ рѕўрѕерІ│рЅх рІерЇЁрѕЂрЇЇ рІГрІўрЅХрЅйріЋ рѕўрѕѕрІерЅх рІерЅІріЋрЅІріЋ рѕўрІІрЅЁрѕГ рѕўрЅ░ріЋрЅ░ріЋ рІерѕџрІФрѕхрЅйрѕЅ рІерѕђрїѕрѕфріЏ ріЊрЅ╣рѕФрѕЇ рѕІріЋрїЅрІїрїЁ рЇЋрѕ«рѕ░рѕ▓ріЋрїЇ рЅ▒рѕјрЅй рѕхрѕЇрЅ░рЅђрѕўрѕ«рЅй ріЦріЊ рѕърІ┤рѕјрЅйріЋ рѕЏрІўрїІрїђрЅх рЅ░рїѕрЅб ріљрІЇ\"), Sentence(\"рЅарІџрѕЁрѕЮ рѕўрѕ░рѕерЅх ріарѕЏрѕГріЏ ріарЇІріЋ рідрѕ«рѕъ рѕХрѕЏрѕіріЏ ріЦріЊ рЅхрїЇрѕГріЏ рЅІріЋрЅІрІјрЅйріЋ рѕѕрѕЏрѕйріЋ рІерѕЏрѕхрЅ░рѕЏрѕГ рѕѓрІ░рЅхріЋ рЅђрѕІрѕЇріЊ рІерЅ░рЅђрѕІрЅ░рЇЇ ріЦріЋрІ▓рѕєріЋ рІФрѕхрЅйрѕІрѕЇ\")]\n    ```\n\n    - Here is another example of performing sentence tokenization on a piece of plaintext using `sentence_tokenize` function:\n\n    ```python\n    from etltk.tokenize.am import sent_tokenize\n\n    sample_text = \"\"\"\n      рІерѕЏрѕйріЋ рѕѕрѕГріњріЋрїЇ рѕхрѕЇрЅ░-рЅђрѕўрѕ«рЅй  (Algorithms) рЅарѕўрїарЅђрѕЮ рЅІріЋрЅІрІјрЅйріЋ рѕўрѕѕрІерЅх ріЦріЊ рѕўрѕерІ│рЅхрЇБ рІерїйрѕЂрЇЇ рІГрІўрЅХрЅйріЋ рѕўрѕѕрІерЅхрЇБ рІерЅІріЋрЅІріЋ рѕўрІІрЅЁрѕГ рѕўрЅ░ріЋрЅ░ріЋ рІерѕџрІФрѕхрЅйрѕЅ рІерѕЃрїѕрѕфріЏ ріЊрЅ╣рѕФрѕЇ рѕІріЋрїЅрІїрїЁ рЇЋрѕ«рѕ░рѕ▓ріЋрїЇ рЅ▒рѕјрЅй (NLP tools) рЇБ рѕхрѕЇрЅ░-рЅђрѕўрѕ«рЅй ріЦріЊ рѕърІ┤рѕјрЅйріЋ рѕЏрІўрїІрїђрЅх рЅ░рїѕрЅб ріљрІЇрЇб рЅарІџрѕЁрѕЮ рѕўрѕ░рѕерЅх ріарѕЏрѕГріЏрЇБ ріарЇІріЋ рідрѕ«рѕърЇБ рѕХрѕЏрѕіріЏ ріЦріЊ рЅхрїЇрѕГріЏ рЅІріЋрЅІрІјрЅйріЋ рѕѕрѕЏрѕйріЋ рІерѕЏрѕхрЅ░рѕЏрѕГ рѕѓрІ░рЅхріЋ рЅђрѕІрѕЇріЊ рІерЅ░рЅђрѕІрЅ░рЇЇ ріЦріЋрІ▓рѕєріЋ рІФрѕхрЅйрѕІрѕЇрЇАрЇА\n    \"\"\"\n\n    # Annotating a Document\n    sentences = sent_tokenize(sample_text)\n\n    # print all list of sentence:\n    print(sentences)\n    # output: ['рІерѕЏрѕйріЋ рѕѕрѕГріњріЋрїЇ рѕхрѕЇрЅ░рЅђрѕўрѕ«рЅй рЅарѕўрїарЅђрѕЮ рЅІріЋрЅІрІјрЅйріЋ рѕўрѕѕрІерЅх ріЦріЊ рѕўрѕерІ│рЅх рІерЇЁрѕЂрЇЇ рІГрІўрЅХрЅйріЋ рѕўрѕѕрІерЅх рІерЅІріЋрЅІріЋ рѕўрІІрЅЁрѕГ рѕўрЅ░ріЋрЅ░ріЋ рІерѕџрІФрѕхрЅйрѕЅ рІерѕђрїѕрѕфріЏ ріЊрЅ╣рѕФрѕЇ рѕІріЋрїЅрІїрїЁ рЇЋрѕ«рѕ░рѕ▓ріЋрїЇ рЅ▒рѕјрЅй рѕхрѕЇрЅ░рЅђрѕўрѕ«рЅй ріЦріЊ рѕърІ┤рѕјрЅйріЋ рѕЏрІўрїІрїђрЅх рЅ░рїѕрЅб ріљрІЇ', 'рЅарІџрѕЁрѕЮ рѕўрѕ░рѕерЅх ріарѕЏрѕГріЏ ріарЇІріЋ рідрѕ«рѕъ рѕХрѕЏрѕіріЏ ріЦріЊ рЅхрїЇрѕГріЏ рЅІріЋрЅІрІјрЅйріЋ рѕѕрѕЏрѕйріЋ рІерѕЏрѕхрЅ░рѕЏрѕГ рѕѓрІ░рЅхріЋ рЅђрѕІрѕЇріЊ рІерЅ░рЅђрѕІрЅ░рЇЇ ріЦріЋрІ▓рѕєріЋ рІФрѕхрЅйрѕІрѕЇ']\n\n3. Tokenization - Word\n    - Here is a simple example of performing word tokenization on a piece of plaintext using AmharicDocument:\n    - Within Amharic focument, annotations are further stored in `Words`.\n\n    ```python\n    from etltk import AmharicDocument\n\n    sample_text = \"\"\"\n      РђюрЅ░рѕеріЏрЇБ рЅ░рѕеріЏ!РђЮ ріарѕѕ ріљрѕГрѕ▒рЇб рІѕрІГрІўрѕ«\n      рЅ│рѕфрі│рЇБ РђюріарЅцрЅх!РђЮ рЅЦрѕѕрІЇ рІерѕЂрѕѕрЅх\n      рІЊрѕўрЅх рѕЇрїЃрЅИрІЇріЋ рІГрІўрІЇ рїѕрЅАрЇб\n      РђюрѕЮріЉріЋ ріљрІЇ рІФрѕўрѕўрІЇ?РђЮ рІХріГрЅ░рѕ»\n      рїарІерЅЂрЇб РђюріарІФрІЕрЅхрѕЮ! рЇђрїЅрѕЕ рѕ│рѕхрЅирѕЇрЇц\n      рѕєрІ▒ рЅ░ріљрЇЇрЅирѕЇрЇц рІхрІ▒рѕЮ рІГрІ░рѕЏрѕЇРђЮ\n      ріарѕЅ рІѕрІГрІўрѕ« рЅ│рѕфрі│рЇб рІХріГрЅ░рѕ»рѕЮрЇБ\n      РђюрЅарїБрѕЮ рІФрѕ│рІЮріЊрѕЇрЇц ріЦріЋрІ░рІџрѕЁ\n      рІФрІ░рѕерїѕрІЇ рІерЅ░рѕўрїБрїаріљ рѕЮрїЇрЅЦ ріарѕѕрѕЏрїЇріўрЅ▒ ріљрІЇрЇб ріарѕЂріЋрѕЮ рІѕрЅ░рЅхрЇБ\n      ріЦріЋрЅЂрѕІрѕЇрЇБ рѕЏрѕГрЇБ ріарЅхріГрѕЇрЅхріЊ рЇЇрѕФрЇЇрѕг рІГрѕўрїЇрЅАрЅхрЇц рЅХрѕј рІГрѕ╗рѕѕрІІрѕЇрЇц\n      рѕѕріарѕЂріЉ рїЇріЋ рѕўрІхріЃріњрЅх ріарІЮрѕѕрЅ│рѕѕрѕЂРђЮ рЅарѕЏрѕѕрЅх ріарѕхрѕерІирЅИрІЇрЇб рІѕрІГрІўрѕ«\n      рЅ│рѕфрі│рѕЮ РђюрІѕрІГ ріарѕѕрѕЏрІѕрЅЁ! рѕЇрїёріЋ рЅарѕЮрїЇрЅЦ ріЦрїЦрѕерЅх рїѕрІхрІгрІЇ ріљрЅарѕГ\"\n      рЅарѕЏрѕѕрЅх ріарѕѕрЅђрѕ▒рЇб\n\n      \"\"\"\n    \n    # Annotating Amharic Text\n    doc = Amharic(sample_text)\n\n    # print all list of `AmharicWord` in a document:\n    print(doc.words)\n    # output: ['рЅ░рѕеріЏ', 'рЅ░рѕеріЏ', 'ріарѕѕ', 'ріљрѕГрѕ▒', 'рІѕрІГрІўрѕ«', 'рЅ│рѕфрі│', 'ріарЅцрЅх', 'рЅЦрѕѕрІЇ', 'рІерѕЂрѕѕрЅх', 'ріарѕўрЅх', 'рѕЇрїЃрЅИрІЇріЋ', 'рІГрІўрІЇ', 'рїѕрЅА', 'рѕЮріЉріЋ', 'ріљрІЇ', 'рІФрѕўрѕўрІЇ', 'рІХріГрЅ░рѕ»', 'рїарІерЅЂ', 'ріарІФрІЕрЅхрѕЮ', 'рЇђрїЅрѕЕ', 'рѕ│рѕхрЅирѕЇ', 'рѕєрІ▒', 'рЅ░ріљрЇЇрЅирѕЇ', 'рІхрІ▒рѕЮ', 'рІГрІ░рѕЏрѕЇ', 'ріарѕЅ', 'рІѕрІГрІўрѕ«', 'рЅ│рѕфрі│', 'рІХріГрЅ░рѕ»рѕЮ', 'рЅарїБрѕЮ', 'рІФрѕ│рІЮріЊрѕЇ', 'ріЦріЋрІ░рІџрѕЁ', 'рІФрІ░рѕерїѕрІЇ', 'рІерЅ░рѕўрїБрїаріљ', 'рѕЮрїЇрЅЦ', 'ріарѕѕрѕЏрїЇріўрЅ▒', 'ріљрІЇ', 'ріарѕЂріЋрѕЮ', 'рІѕрЅ░рЅх', 'ріЦріЋрЅЂрѕІрѕЇ', 'рѕЏрѕГ', 'ріарЅхріГрѕЇрЅхріЊ', 'рЇЇрѕФрЇЇрѕг', 'рІГрѕўрїЇрЅАрЅх', 'рЅХрѕј', 'рІГрѕ╗рѕѕрІІрѕЇ', 'рѕѕріарѕЂріЉ', 'рїЇріЋ', 'рѕўрІхрѕђріњрЅх', 'ріарІЮрѕѕрЅ│рѕѕрѕЂ', 'рЅарѕЏрѕѕрЅх', 'ріарѕхрѕерІирЅИрІЇ', 'рІѕрІГрІўрѕ«', 'рЅ│рѕфрі│рѕЮ', 'рІѕрІГ', 'ріарѕѕрѕЏрІѕрЅЁ', 'рѕЇрїёріЋ', 'рЅарѕЮрїЇрЅЦ', 'ріЦрїЦрѕерЅх', 'рїѕрІхрІгрІЇ', 'ріљрЅарѕГ', 'рЅарѕЏрѕѕрЅх', 'ріарѕѕрЅђрѕ▒']\n    ```\n\n    - Here is another example of performing word tokenization on a piece of plaintext using `word_tokenize` function:\n\n    ```python\n    from etltk.tokenize.am import word_tokenize\n\n    sample_text = \"\"\"\n      РђюрЅ░рѕеріЏрЇБ рЅ░рѕеріЏ!РђЮ ріарѕѕ ріљрѕГрѕ▒рЇб рІѕрІГрІўрѕ«\n      рЅ│рѕфрі│рЇБ РђюріарЅцрЅх!РђЮ рЅЦрѕѕрІЇ рІерѕЂрѕѕрЅх\n      рІЊрѕўрЅх рѕЇрїЃрЅИрІЇріЋ рІГрІўрІЇ рїѕрЅАрЇб\n      РђюрѕЮріЉріЋ ріљрІЇ рІФрѕўрѕўрІЇ?РђЮ рІХріГрЅ░рѕ»\n      рїарІерЅЂрЇб РђюріарІФрІЕрЅхрѕЮ! рЇђрїЅрѕЕ рѕ│рѕхрЅирѕЇрЇц\n      рѕєрІ▒ рЅ░ріљрЇЇрЅирѕЇрЇц рІхрІ▒рѕЮ рІГрІ░рѕЏрѕЇРђЮ\n      ріарѕЅ рІѕрІГрІўрѕ« рЅ│рѕфрі│рЇб рІХріГрЅ░рѕ»рѕЮрЇБ\n      РђюрЅарїБрѕЮ рІФрѕ│рІЮріЊрѕЇрЇц ріЦріЋрІ░рІџрѕЁ\n      рІФрІ░рѕерїѕрІЇ рІерЅ░рѕўрїБрїаріљ рѕЮрїЇрЅЦ ріарѕѕрѕЏрїЇріўрЅ▒ ріљрІЇрЇб ріарѕЂріЋрѕЮ рІѕрЅ░рЅхрЇБ\n      ріЦріЋрЅЂрѕІрѕЇрЇБ рѕЏрѕГрЇБ ріарЅхріГрѕЇрЅхріЊ рЇЇрѕФрЇЇрѕг рІГрѕўрїЇрЅАрЅхрЇц рЅХрѕј рІГрѕ╗рѕѕрІІрѕЇрЇц\n      рѕѕріарѕЂріЉ рїЇріЋ рѕўрІхріЃріњрЅх ріарІЮрѕѕрЅ│рѕѕрѕЂРђЮ рЅарѕЏрѕѕрЅх ріарѕхрѕерІирЅИрІЇрЇб рІѕрІГрІўрѕ«\n      рЅ│рѕфрі│рѕЮ РђюрІѕрІГ ріарѕѕрѕЏрІѕрЅЁ! рѕЇрїёріЋ рЅарѕЮрїЇрЅЦ ріЦрїЦрѕерЅх рїѕрІхрІгрІЇ ріљрЅарѕГ\"\n      рЅарѕЏрѕѕрЅх ріарѕѕрЅђрѕ▒рЇб\n\n    \"\"\"\n      \n    # word tokenization\n    words = word_tokenize(sample_text)\n\n    # print all list of word:\n    print(words)\n    # output: ['рЅ░рѕеріЏ', 'рЅ░рѕеріЏ', 'ріарѕѕ', 'ріљрѕГрѕ▒', 'рІѕрІГрІўрѕ«', 'рЅ│рѕфрі│', 'ріарЅцрЅх', 'рЅЦрѕѕрІЇ', 'рІерѕЂрѕѕрЅх', 'ріарѕўрЅх', 'рѕЇрїЃрЅИрІЇріЋ', 'рІГрІўрІЇ', 'рїѕрЅА', 'рѕЮріЉріЋ', 'ріљрІЇ', 'рІФрѕўрѕўрІЇ', 'рІХріГрЅ░рѕ»', 'рїарІерЅЂ', 'ріарІФрІЕрЅхрѕЮ', 'рЇђрїЅрѕЕ', 'рѕ│рѕхрЅирѕЇ', 'рѕєрІ▒', 'рЅ░ріљрЇЇрЅирѕЇ', 'рІхрІ▒рѕЮ', 'рІГрІ░рѕЏрѕЇ', 'ріарѕЅ', 'рІѕрІГрІўрѕ«', 'рЅ│рѕфрі│', 'рІХріГрЅ░рѕ»рѕЮ', 'рЅарїБрѕЮ', 'рІФрѕ│рІЮріЊрѕЇ', 'ріЦріЋрІ░рІџрѕЁ', 'рІФрІ░рѕерїѕрІЇ', 'рІерЅ░рѕўрїБрїаріљ', 'рѕЮрїЇрЅЦ', 'ріарѕѕрѕЏрїЇріўрЅ▒', 'ріљрІЇ', 'ріарѕЂріЋрѕЮ', 'рІѕрЅ░рЅх', 'ріЦріЋрЅЂрѕІрѕЇ', 'рѕЏрѕГ', 'ріарЅхріГрѕЇрЅхріЊ', 'рЇЇрѕФрЇЇрѕг', 'рІГрѕўрїЇрЅАрЅх', 'рЅХрѕј', 'рІГрѕ╗рѕѕрІІрѕЇ', 'рѕѕріарѕЂріЉ', 'рїЇріЋ', 'рѕўрІхрѕђріњрЅх', 'ріарІЮрѕѕрЅ│рѕѕрѕЂ', 'рЅарѕЏрѕѕрЅх', 'ріарѕхрѕерІирЅИрІЇ', 'рІѕрІГрІўрѕ«', 'рЅ│рѕфрі│рѕЮ', 'рІѕрІГ', 'ріарѕѕрѕЏрІѕрЅЁ', 'рѕЇрїёріЋ', 'рЅарѕЮрїЇрЅЦ', 'ріЦрїЦрѕерЅх', 'рїѕрІхрІгрІЇ', 'ріљрЅарѕГ', 'рЅарѕЏрѕѕрЅх', 'ріарѕѕрЅђрѕ▒']\n\n4. Normalization\n    1. Character Level Normalization such as \"`рїИ`рѕђрІГ\" and \"`рЇђ`рѕљрІГ\"\n    2. Labialized Character Normalzation such as \"рѕърѕЇ`рЅ▒рІІ`рѕЇ\" to \"рѕърѕЇ`рЅи`рѕЇ\"\n    3. Short Form Expansion such as \"`ріа.ріа`\" to \"`ріарІ▓рѕх ріарЅарЅБ`\"\n    4. Punctuation Normalization such as `::` to `рЇб`\n\n    - Here is a simple example of performing normalization on a piece of plaintext using `normalize` function:\n\n    ```python\n    from etltk.lang.am import normalize\n\n    sample_text = \"\"\"\n      рѕџрІФрІЮрІФ 14рЇБ 2014 рІЊ.рѕЮ рЅарІЊрїѕрѕГ рІ░рѕерїЃ рІерѕ░рІЇ рѕ░рѕФрѕй ріарѕхрЅ░рІЇрѕјрЅх рІерІЇрІГрІГрЅх рѕўрІхрѕеріГ рѕІрІГ\n      рІерѕЃрїѕрѕГріЏ рЅІріЋрЅІрІјрЅй рЅхрѕГрїЅрѕЮ ріарїѕрѕЇрїЇрѕјрЅхрЇБ \n      рЅ╗рЅхрЅдрЅх (рІерІЇрІГрІГрЅх рѕўрѕѕрІІрІѕрїФ рѕ«рЅдрЅх): \n      рІерЇЁрѕЂрЇЇ рѕ░ріљрІХрЅй рѕѕрѕўрѕѕрІерЅхрЇБ рІерЅЃрѕІрЅх рЅхріГріГрѕѕріЏріљрЅхріЋ рѕѕрѕЏрѕерїІрїѕрїЦрЇБ \n      рЅарЅІріЋрЅІріЋ рѕЋрїЇрїІрЅх рѕўрѕарѕерЅх рїйрѕЉрЇјрЅйріЋ рѕѕрѕЏрІІрЅђрѕГ ріЦріЊ рѕѕрѕўрѕўрѕхрѕерЅхрЇБ \n      рѕерїЁрѕЮ рїйрѕЂрЇјрЅйріЋ рѕѕрѕЏрѕ│рїарѕГрЇБ ріаріЋрі│рѕГ рїЅрІ│рІ«рЅйріЋ рѕўрѕѕрІерЅх рІѕрІГрѕЮ рїЦрЅЁрѕЇ рѕЃрѕ│рЅЦ рѕѕрѕЏрІЇрїБрЅхрЇБ \n      ріЋрїЇрїЇрѕГріЋ рІѕрІ░ рїйрѕЂрЇЇ рѕѕрѕўрЅђрІерѕГ рІерѕџрІФрѕхрЅйрѕЅ рѕўрЅ░рїЇрЅарѕфрІФрІјрЅйріЋ рѕЏрѕЇрѕЏрЅх ріарѕхрѕерѕІрїіріљрЅ▒ рЅ░рїѕрѕЇрї╣рІІрѕЇ::\n    \"\"\"\n\n    # normalization\n    normalized_text = normalize(sample_text)\n\n    # The following example shows how to print all normalized in a document:\n    print(normalized_text)\n    # output: рѕџрІФрІЮрІФ 14рЇБ 2014 ріарѕўрЅ░ рѕЮрѕЁрѕерЅх рЅаріарїѕрѕГ рІ░рѕерїЃ рІерѕ░рІЇ рѕ░рѕФрѕй ріарѕхрЅ░рІЇрѕјрЅх рІерІЇрІГрІГрЅх рѕўрІхрѕеріГ рѕІрІГ\n    # рІерѕђрїѕрѕГріЏ рЅІріЋрЅІрІјрЅй рЅхрѕГрїЅрѕЮ ріарїѕрѕЇрїЇрѕјрЅхрЇБ \n    # рЅ╗рЅхрЅдрЅх (рІерІЇрІГрІГрЅх рѕўрѕѕрІІрІѕрїФ рѕ«рЅдрЅх)рЇА \n    # рІерЇЁрѕЂрЇЇ рѕ░ріљрІХрЅй рѕѕрѕўрѕѕрІерЅхрЇБ рІерЅЃрѕІрЅх рЅхріГріГрѕѕріЏріљрЅхріЋ рѕѕрѕЏрѕерїІрїѕрїЦрЇБ \n    # рЅарЅІріЋрЅІріЋ рѕЁрїЇрїІрЅх рѕўрѕ░рѕерЅх рЇЁрѕЂрЇјрЅйріЋ рѕѕрѕЏрІІрЅђрѕГ ріЦріЊ рѕѕрѕўрѕўрѕхрѕерЅхрЇБ \n    # рѕерїЁрѕЮ рЇЁрѕЂрЇјрЅйріЋ рѕѕрѕЏрѕ│рїарѕГрЇБ ріаріЋрі│рѕГ рїЅрІ│рІ«рЅйріЋ рѕўрѕѕрІерЅх рІѕрІГрѕЮ рїЦрЅЁрѕЇ рѕђрѕ│рЅЦ рѕѕрѕЏрІЇрїБрЅхрЇБ \n    # ріЋрїЇрїЇрѕГріЋ рІѕрІ░ рЇЁрѕЂрЇЇ рѕѕрѕўрЅђрІерѕГ рІерѕџрІФрѕхрЅйрѕЅ рѕўрЅ░рїЇрЅарѕфрІФрІјрЅйріЋ рѕЏрѕЇрѕЏрЅх ріарѕхрѕерѕІрїіріљрЅ▒ рЅ░рїѕрѕЇрї┐рѕЇрЇб \"\"\"\n    ```\n\n    - Here is another example of performing normalization on a piece of plaintext using `normalize_char`, `normalize_punct`, `normalize_labialized`, `normalize_shortened` function:\n\n    ```python\n    from etltk.lang.am.normalizer import ( \n      normalize_labialized, \n      normalize_shortened,\n      normalize_punct,\n      normalize_char\n    )\n\n    # normalize labialized \n    normalized_text = normalize_labialized(\"ріЋрїЇрїЇрѕГріЋ рІѕрІ░ рїйрѕЂрЇЇ рѕѕрѕўрЅђрІерѕГ рІерѕџрІФрѕхрЅйрѕЅ рѕўрЅ░рїЇрЅарѕфрІФрІјрЅйріЋ рѕЏрѕЇрѕЏрЅх ріарѕхрѕерѕІрїіріљрЅ▒ рЅ░рїѕрѕЇрї╣рІІрѕЇ\")\n    print(normalized_text)\n    # output: ріЋрїЇрїЇрѕГріЋ рІѕрІ░ рЇЁрѕЂрЇЇ рѕѕрѕўрЅђрІерѕГ рІерѕџрІФрѕхрЅйрѕЅ рѕўрЅ░рїЇрЅарѕфрІФрІјрЅйріЋ рѕЏрѕЇрѕЏрЅх ріарѕхрѕерѕІрїіріљрЅ▒ рЅ░рїѕрѕЇрї┐рѕЇ\n\n    # normalize short forms\n    normalized_text = normalize_shortened(\"рѕџрІФрІЮрІФ 14рЇБ 2014 рІЊ.рѕЮ рЅарІЊрїѕрѕГ рІ░рѕерїЃ рІерѕ░рІЇ рѕ░рѕФрѕй ріарѕхрЅ░рІЇрѕјрЅх рІерІЇрІГрІГрЅх рѕўрІхрѕеріГ\")\n    print(normalized_text)\n    # output: рѕџрІФрІЮрІФ 14рЇБ 2014 рІЊрѕўрЅ░ рѕЮрѕЁрѕерЅх рЅаріарїѕрѕГ рІ░рѕерїЃ рІерѕ░рІЇ рѕ░рѕФрѕй ріарѕхрЅ░рІЇрѕјрЅх рІерІЇрІГрІГрЅх рѕўрІхрѕеріГ\n\n    # normalize punctuation\n    normalized_text = normalize_punct(\"рѕўрЅ░рїЇрЅарѕфрІФрІјрЅйріЋ рѕЏрѕЇрѕЏрЅх ріарѕхрѕерѕІрїіріљрЅ▒ рЅ░рїѕрѕЇрї╣рІІрѕЇ::\")\n    print(normalized_text)\n    # output: рѕўрЅ░рїЇрЅарѕфрІФрІјрЅйріЋ рѕЏрѕЇрѕЏрЅх ріарѕхрѕерѕІрїіріљрЅ▒ рЅ░рїѕрѕЇрї┐рѕЇрЇб\n\n    # normalize characters\n    normalized_text = normalize_char(\"рЅарЅІріЋрЅІрІЅ рѕЋрїЇрїІрЅх рѕўрѕарѕерЅх рїйрѕЉрЇјрЅйріЋ рѕЏрІІрЅђрѕГ ріЦріЊ рѕўрѕўрѕЦрѕерЅх\")\n    print(normalized_text)\n    # output: рЅарЅІріЋрЅІрІЅ рѕЁрїЇрїІрЅх рѕўрѕ░рѕерЅх рЇЁрѕЂрЇјрЅйріЋ рѕЏрІІрЅђрѕГ ріЦріЊ рѕўрѕўрѕхрѕерЅх\n\n## Features\n\n- Text preprocessing functions.\n\n    ``` python\n    from etltk.lang.am import preprocessing\n    ```\n\n    | Function | Description |\n    -----------|-------------|\n    | remove_whitespaces | Remove extra spaces, tabs, and new lines from a text string\n    | remove_links | Remove URLs from a text string\n    | remove_tags | Remove HTML tags from a text string\n    | remove_emojis | Remove emojis from a text string\n    | remove_email | Remove email adresses from a text string\n    | remove_digits | Remove all digits from a text string\n    | remove_english_chars | Remove ascii characters from a text string\n    | remove_arabic_chars | Remove arabic characters and numerals from a text string\n    | remove_chinese_chars | Remove chinese characters from a text string\n    | remove_ethiopic_digits | Remove all ethiopic digits from a text string\n    | remove_ethiopic_punct | Remove ethiopic punctuations from a text string\n    | remove_non_ethiopic | Remove non ethioipc characters from a text string\n    | remove_stopwords | Remove stop words\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/robikieq/ethiopian_language_toolkit.git",
    "keywords": "['nlp','ethiopic','amharic','tokenizing','preprocessing','text-analytics']",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "etltk",
    "package_url": "https://pypi.org/project/etltk/",
    "platform": null,
    "project_url": "https://pypi.org/project/etltk/",
    "project_urls": {
      "Homepage": "https://github.com/robikieq/ethiopian_language_toolkit.git"
    },
    "release_url": "https://pypi.org/project/etltk/0.0.22/",
    "requires_dist": [
      "textsearch (>=0.0.21)",
      "emoji (>=1.7.0)"
    ],
    "requires_python": ">=3.6",
    "summary": "Ethiopian Language NLP Toolkit",
    "version": "0.0.22",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 13829097,
  "releases": {
    "0.0.12": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ab65a356d1705405a4e932b3dc5b1121342f7278b4462154cb82676ee1b4fc76",
          "md5": "7035635243bad7748c5edc250fa00e1a",
          "sha256": "bff40842ad0aac3e4798f166587d666323848612cc6894170c0d8875853fba67"
        },
        "downloads": -1,
        "filename": "etltk-0.0.12-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "7035635243bad7748c5edc250fa00e1a",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 19603,
        "upload_time": "2022-04-22T17:11:20",
        "upload_time_iso_8601": "2022-04-22T17:11:20.864693Z",
        "url": "https://files.pythonhosted.org/packages/ab/65/a356d1705405a4e932b3dc5b1121342f7278b4462154cb82676ee1b4fc76/etltk-0.0.12-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "dc76a3410ca4b7a00acd6061b1d3aea6d67c27630a56ded998e0b13f1edfa179",
          "md5": "4649ee0fd69aa2f8dee303e3b2c88af8",
          "sha256": "7d4aaa6fa563ea020723b74d0436a2ae18693757ec86247e4297a5f8bb6cc9e3"
        },
        "downloads": -1,
        "filename": "etltk-0.0.12.tar.gz",
        "has_sig": false,
        "md5_digest": "4649ee0fd69aa2f8dee303e3b2c88af8",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 19830,
        "upload_time": "2022-04-22T17:11:22",
        "upload_time_iso_8601": "2022-04-22T17:11:22.636895Z",
        "url": "https://files.pythonhosted.org/packages/dc/76/a3410ca4b7a00acd6061b1d3aea6d67c27630a56ded998e0b13f1edfa179/etltk-0.0.12.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.14": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7dca06809a1050af363588416beed3beebcbff0dd5656392324d576f265fea0f",
          "md5": "8e1934c9b16bed4fd244964c6b900d45",
          "sha256": "cbfe3f541c0369666a4c6a4b0c8428591f4ba18515cc3ad9dc43b2e88d66e466"
        },
        "downloads": -1,
        "filename": "etltk-0.0.14-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "8e1934c9b16bed4fd244964c6b900d45",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 19621,
        "upload_time": "2022-04-23T12:20:48",
        "upload_time_iso_8601": "2022-04-23T12:20:48.723708Z",
        "url": "https://files.pythonhosted.org/packages/7d/ca/06809a1050af363588416beed3beebcbff0dd5656392324d576f265fea0f/etltk-0.0.14-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5d898adfd716d8aeca90d999405204b0fb5203442ad07d5378ec697d9b22ee17",
          "md5": "5ba197c2d63d4efd4d4fc2d04437bd83",
          "sha256": "fcbfa241c14bb6cef0549f397d0e016304ac17251ff8fa0beaf9725d72e769cb"
        },
        "downloads": -1,
        "filename": "etltk-0.0.14.tar.gz",
        "has_sig": false,
        "md5_digest": "5ba197c2d63d4efd4d4fc2d04437bd83",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 19477,
        "upload_time": "2022-04-23T12:20:51",
        "upload_time_iso_8601": "2022-04-23T12:20:51.536263Z",
        "url": "https://files.pythonhosted.org/packages/5d/89/8adfd716d8aeca90d999405204b0fb5203442ad07d5378ec697d9b22ee17/etltk-0.0.14.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.18": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3930f0dcbdce731250c24f4977b8b2f14bdca0e6bbde93ba547dd96320a1574a",
          "md5": "723253a551dbbdd60f0b3e04e4393971",
          "sha256": "5ab1949eab98eeeb38167504e83255014c9823a5f6b16be7bf542d87329c9b26"
        },
        "downloads": -1,
        "filename": "etltk-0.0.18-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "723253a551dbbdd60f0b3e04e4393971",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 19583,
        "upload_time": "2022-04-25T10:49:59",
        "upload_time_iso_8601": "2022-04-25T10:49:59.543032Z",
        "url": "https://files.pythonhosted.org/packages/39/30/f0dcbdce731250c24f4977b8b2f14bdca0e6bbde93ba547dd96320a1574a/etltk-0.0.18-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "94fcccb48fedecd1fa0ad86b87bc06f73dad1be58c2a916d1a7031ed7fa02bf7",
          "md5": "21f9227848c727d9d25c91f3a7d06f3d",
          "sha256": "4682da5507d5852cac3c1a061c0c110879b00a628f8f3514d7f79404c03a5f6a"
        },
        "downloads": -1,
        "filename": "etltk-0.0.18.tar.gz",
        "has_sig": false,
        "md5_digest": "21f9227848c727d9d25c91f3a7d06f3d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 19449,
        "upload_time": "2022-04-25T10:50:03",
        "upload_time_iso_8601": "2022-04-25T10:50:03.376881Z",
        "url": "https://files.pythonhosted.org/packages/94/fc/ccb48fedecd1fa0ad86b87bc06f73dad1be58c2a916d1a7031ed7fa02bf7/etltk-0.0.18.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.20": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "87b4989a42f0af525257c28d1f1a5bebec3623a8291437152904822f6a342f95",
          "md5": "2f34873b01c1bcfcb5dd4fe68291d578",
          "sha256": "e431195a3bef69702b87dd1adef92d999d13ef07ec2a7162a1882523dbde67c1"
        },
        "downloads": -1,
        "filename": "etltk-0.0.20-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "2f34873b01c1bcfcb5dd4fe68291d578",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 19695,
        "upload_time": "2022-04-27T08:10:22",
        "upload_time_iso_8601": "2022-04-27T08:10:22.487051Z",
        "url": "https://files.pythonhosted.org/packages/87/b4/989a42f0af525257c28d1f1a5bebec3623a8291437152904822f6a342f95/etltk-0.0.20-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8fdbb2fdb600efc69886d5bea7a6199760bcac3b33630edd99e648f5a5cf05e2",
          "md5": "4a9b38f7106035a215b8800479f88eae",
          "sha256": "ed29371e25fe9eaf04799394e139205138a7fa8d9b519bdb9a03d090a6f75cc9"
        },
        "downloads": -1,
        "filename": "etltk-0.0.20.tar.gz",
        "has_sig": false,
        "md5_digest": "4a9b38f7106035a215b8800479f88eae",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 19556,
        "upload_time": "2022-04-27T08:10:28",
        "upload_time_iso_8601": "2022-04-27T08:10:28.107525Z",
        "url": "https://files.pythonhosted.org/packages/8f/db/b2fdb600efc69886d5bea7a6199760bcac3b33630edd99e648f5a5cf05e2/etltk-0.0.20.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.22": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9fa66977be39cc33c57de7d5240b7070513677048fb3f204694c42f4e6c8cbd8",
          "md5": "d16683b9e49641986e2373ded82d2c6a",
          "sha256": "f5b992a01df2259daa7e1785b85d0b62ba831a52db8da8c91594d8569b0a2f37"
        },
        "downloads": -1,
        "filename": "etltk-0.0.22-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d16683b9e49641986e2373ded82d2c6a",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 20570,
        "upload_time": "2022-05-16T11:59:28",
        "upload_time_iso_8601": "2022-05-16T11:59:28.788842Z",
        "url": "https://files.pythonhosted.org/packages/9f/a6/6977be39cc33c57de7d5240b7070513677048fb3f204694c42f4e6c8cbd8/etltk-0.0.22-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f47ee7bb001647397f49fbffe01a0638db011542447fb8d85917c9d7af3163d4",
          "md5": "c76905439832e4131d244bf34549074e",
          "sha256": "3e1992b8fa42ba50e457b601e973126a723327d36f4730da98c132409bee966e"
        },
        "downloads": -1,
        "filename": "etltk-0.0.22.tar.gz",
        "has_sig": false,
        "md5_digest": "c76905439832e4131d244bf34549074e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 20618,
        "upload_time": "2022-05-16T11:59:34",
        "upload_time_iso_8601": "2022-05-16T11:59:34.390018Z",
        "url": "https://files.pythonhosted.org/packages/f4/7e/e7bb001647397f49fbffe01a0638db011542447fb8d85917c9d7af3163d4/etltk-0.0.22.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "9fa66977be39cc33c57de7d5240b7070513677048fb3f204694c42f4e6c8cbd8",
        "md5": "d16683b9e49641986e2373ded82d2c6a",
        "sha256": "f5b992a01df2259daa7e1785b85d0b62ba831a52db8da8c91594d8569b0a2f37"
      },
      "downloads": -1,
      "filename": "etltk-0.0.22-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "d16683b9e49641986e2373ded82d2c6a",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 20570,
      "upload_time": "2022-05-16T11:59:28",
      "upload_time_iso_8601": "2022-05-16T11:59:28.788842Z",
      "url": "https://files.pythonhosted.org/packages/9f/a6/6977be39cc33c57de7d5240b7070513677048fb3f204694c42f4e6c8cbd8/etltk-0.0.22-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "f47ee7bb001647397f49fbffe01a0638db011542447fb8d85917c9d7af3163d4",
        "md5": "c76905439832e4131d244bf34549074e",
        "sha256": "3e1992b8fa42ba50e457b601e973126a723327d36f4730da98c132409bee966e"
      },
      "downloads": -1,
      "filename": "etltk-0.0.22.tar.gz",
      "has_sig": false,
      "md5_digest": "c76905439832e4131d244bf34549074e",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 20618,
      "upload_time": "2022-05-16T11:59:34",
      "upload_time_iso_8601": "2022-05-16T11:59:34.390018Z",
      "url": "https://files.pythonhosted.org/packages/f4/7e/e7bb001647397f49fbffe01a0638db011542447fb8d85917c9d7af3163d4/etltk-0.0.22.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}