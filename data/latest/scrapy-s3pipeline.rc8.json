{
  "info": {
    "author": "orangain",
    "author_email": "orangain@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Framework :: Scrapy",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9"
    ],
    "description": "# Scrapy S3 Pipeline\n\n[![PyPI version](https://badge.fury.io/py/scrapy-s3pipeline.svg)](https://badge.fury.io/py/scrapy-s3pipeline) ![CI](https://github.com/orangain/scrapy-s3pipeline/workflows/CI/badge.svg)\n\nScrapy pipeline to store items into [Amazon S3](https://aws.amazon.com/s3/) or [Google Cloud Storage (GCS)](https://cloud.google.com/storage) bucket. Unlike built-in [FeedExporter](https://docs.scrapy.org/en/latest/topics/feed-exports.html#s3), the pipeline has the following features:\n\n* The pipeline upload items to S3/GCS by chunk while crawler is running.\n  * From Scrapy 2.3, built-in [FEED_EXPORT_BATCH_ITEM_COUNT](https://docs.scrapy.org/en/latest/topics/feed-exports.html#std-setting-FEED_EXPORT_BATCH_ITEM_COUNT) does almost the same thing.\n* Support GZip compression.\n\nThe pipeline aims to run crawler and scraper in different processes, e.g. run crawler process with Scrapy in AWS Fargate and run scraper process with lxml in AWS Lambda.\n\n## Requirements\n\n* Python 3.6+ (Tested in 3.9)\n* Scrapy 1.1+ (Tested in 2.4)\n* boto3 or google-cloud-storage\n\n## Install\n\n**For S3 users:**\n\n```shell-session\n$ pip3 install scrapy-s3pipeline[s3]\n```\n\n**For GCS users:**\n\n```shell-session\n$ pip3 install scrapy-s3pipeline[gcs]\n```\n\n## Getting started\n\n1. Install Scrapy S3 Pipeline with pip.\n\n    ```shell-session\n    $ pip3 install scrapy-s3pipeline[s3]\n    ```\n\n    or\n\n    ```shell-session\n    $ pip3 install scrapy-s3pipeline[gcs]\n    ```\n\n2.  Add `'s3pipeline.S3Pipeline'` to `ITEM_PIPELINES` setting in your Scrapy project.\n\n    ```py\n    ITEM_PIPELINES = {\n        's3pipeline.S3Pipeline': 100,  # Add this line.\n    }\n    ```\n\n3. Add `S3PIPELINE_URL` setting. You need to change `my-bucket` to your bucket name.\n\n    ```py\n    # For S3 users\n    S3PIPELINE_URL = 's3://my-bucket/{name}/{time}/items.{chunk:07d}.jl.gz'\n\n    # For GCS users\n    S3PIPELINE_URL = 'gs://my-bucket/{name}/{time}/items.{chunk:07d}.jl.gz'\n    GCS_PROJECT_ID = 'my-project' # Change to your project id\n    ```\n\n4. Setup AWS/GCP credentials.\n\n    **For S3 users:**\n\n    Setup AWS credentials via `aws configure` command or [environment variables](https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-envvars.html). Alternatively, use Scrapy's settings [AWS_ACCESS_KEY_ID](https://docs.scrapy.org/en/latest/topics/settings.html#aws-access-key-id) and [AWS_SECRET_ACCESS_KEY](https://docs.scrapy.org/en/latest/topics/settings.html#aws-secret-access-key).\n\n    **For GCS users:**\n\n    Setup GCP credentials via `gcloud auth application-default login` command or environment variable [GOOGLE_APPLICATION_CREDENTIALS](https://cloud.google.com/docs/authentication/getting-started). Alternatively, you can set json string of service account's key file to `GOOGLE_APPLICATION_CREDENTIALS_JSON` settings.\n\n5. Run your spider. You will see items in your bucket after 100 items are crawled or the spider is closed.\n\n## Settings\n\n### S3PIPELINE_URL (Required)\n\nS3/GCS Bucket URL to store items.\n\ne.g.:\n\n* S3: `s3://my-bucket/{name}/{time}/items.{chunk:07d}.jl.gz`\n* GCS: `gs://my-bucket/{name}/{time}/items.{chunk:07d}.jl.gz`\n\nThe following replacement fields are supported in `S3PIPELINE_URL`.\n\n* `{chunk}` - gets replaced by a start index of items in current chunk, e.g. '0', '100', '200',....\n* `{time}` - gets replaced by a timestamp when the spider is started.\n\nYou can also use other spider fields, e.g. `{name}`. You can use [format string syntax](https://docs.python.org/3/library/string.html#formatstrings) here, e.g. `{chunk:07d}`.\n\nFile format is determined by a file extension in the URL. For example, if `S3PIPELINE_URL` ends with `.json` or `.json.gz`, JSON format is used. See Scrapy's built-in [FEED_EXPORTERS](https://docs.scrapy.org/en/latest/topics/feed-exports.html#std-setting-FEED_EXPORTERS) settings for supported formats. If the file extension is not available in `FEED_EXPORTERS`, JSONLines format is used by default.\n\n### S3PIPELINE_MAX_CHUNK_SIZE (Optional)\n\nDefault: `100`\n\nMax count of items in a single chunk.\n\n### S3PIPELINE_MAX_WAIT_UPLOAD_TIME (Optional)\n\nDefault: `30.0`\n\nWhen no new item is processed in more than `S3PIPELINE_MAX_WAIT_UPLOAD_TIME` seconds, it will be forced to upload a chunk.\n\n### S3PIPELINE_GZIP (Optional)\n\nDefault: `True` if `S3PIPELINE_URL` ends with `.gz`; otherwise `False`.\n\nIf `True`, uploaded files will be compressed with Gzip.\n\n## Page item\n\nFor convinience, Scrapy S3 Pipeline provides `s3pipeline.Page` item class to store entire HTTP body. It has `url`, `body` and `crawled_at` fields.\n\nThis make it easy to store entire HTTP body and run scraper in other process. It's friendly to server-less architecture which run scraper in AWS Lambda.\n\nExample usage of Page:\n\n```py\nfrom datetime import datetime, timezone\n\nimport scrapy\nfrom s3pipeline import Page\n\n# ...\n\nclass YourSpider(scrapy.Spider):\n\n    # ...\n\n    def parse(self, response):\n        # You can create Page instance just one line.\n        yield Page.from_response(response)\n\n        # Or, you can fill item fields manually.\n        item = Page()\n        item['url'] = response.url\n        item['body'] = response.text\n        item['crawled_at'] = datetime.now(timezone.utc).replace(microsecond=0).isoformat()\n        yield item\n```\n\nNote: Page's body is omitted when printed to logs to improve readbility of logs.\n\n## Development\n\n### Test\n\n```\n$ python3 setup.py test\n```\n\n### Release\n\n```\n$ pip install twine wheel\n```\n\n```\n$ python3 setup.py bdist_wheel sdist\n$ twine upload dist/*\n```\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/orangain/scrapy-s3pipeline",
    "keywords": "scrapy pipeline aws s3 gcs serverless",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "scrapy-s3pipeline",
    "package_url": "https://pypi.org/project/scrapy-s3pipeline/",
    "platform": "",
    "project_url": "https://pypi.org/project/scrapy-s3pipeline/",
    "project_urls": {
      "Homepage": "https://github.com/orangain/scrapy-s3pipeline"
    },
    "release_url": "https://pypi.org/project/scrapy-s3pipeline/0.7.0/",
    "requires_dist": [
      "Scrapy (>=1.1)",
      "google-cloud-storage ; extra == 'gcs'",
      "boto3 ; extra == 's3'"
    ],
    "requires_python": "",
    "summary": "Scrapy pipeline to store chunked items into Amazon S3 or Google Clous Storage bucket",
    "version": "0.7.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 9277012,
  "releases": {
    "0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f21136d4702decd2c2ace734080da0ee98b71c5bf8f3074ba5f74bf95773b7dc",
          "md5": "369b49e9a1de10f369ac7eb9d7e3b629",
          "sha256": "ce56be19555a59c01c2ac839a20a82aa39519d8fd7ad994e8b4af82a9bedeed7"
        },
        "downloads": -1,
        "filename": "scrapy_s3pipeline-0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "369b49e9a1de10f369ac7eb9d7e3b629",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 4353,
        "upload_time": "2017-12-03T06:10:19",
        "upload_time_iso_8601": "2017-12-03T06:10:19.615221Z",
        "url": "https://files.pythonhosted.org/packages/f2/11/36d4702decd2c2ace734080da0ee98b71c5bf8f3074ba5f74bf95773b7dc/scrapy_s3pipeline-0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e858c37dda4f500a9eed6f1dd635149551bf122796f8a4f10b4d891d00399dd0",
          "md5": "7ca6a2b75dbbd2877309f609806f8bd9",
          "sha256": "0c9e72dee1103229d1b0d424fe5829655edfd73e42c88a1e1940fe93bad8c418"
        },
        "downloads": -1,
        "filename": "scrapy-s3pipeline-0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "7ca6a2b75dbbd2877309f609806f8bd9",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 2681,
        "upload_time": "2017-12-03T06:10:20",
        "upload_time_iso_8601": "2017-12-03T06:10:20.755395Z",
        "url": "https://files.pythonhosted.org/packages/e8/58/c37dda4f500a9eed6f1dd635149551bf122796f8a4f10b4d891d00399dd0/scrapy-s3pipeline-0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8aa297e22056b68f89c12d18269ae492dd83b91e06eb5a8478491b68c0a7dd8c",
          "md5": "1636fd39cf8ed42a1f470dda16e0594a",
          "sha256": "b5aacf02e41fb4cced0511c9471c1b70a7bb8dd994bc5757e93a521d7ed4e105"
        },
        "downloads": -1,
        "filename": "scrapy_s3pipeline-0.1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "1636fd39cf8ed42a1f470dda16e0594a",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 4469,
        "upload_time": "2017-12-03T13:53:52",
        "upload_time_iso_8601": "2017-12-03T13:53:52.431995Z",
        "url": "https://files.pythonhosted.org/packages/8a/a2/97e22056b68f89c12d18269ae492dd83b91e06eb5a8478491b68c0a7dd8c/scrapy_s3pipeline-0.1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "58e5487492036772c1046c8f10ca9c21eb1c81857f0e9d994be2ac8c5f195ceb",
          "md5": "805e02e35f7e9af7d142b1fa3e83a580",
          "sha256": "c29bfddf58892348a763f7fa83d05d5ad63e0c9022d1b3245c9081227b59975c"
        },
        "downloads": -1,
        "filename": "scrapy-s3pipeline-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "805e02e35f7e9af7d142b1fa3e83a580",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 2742,
        "upload_time": "2017-12-03T13:53:54",
        "upload_time_iso_8601": "2017-12-03T13:53:54.924351Z",
        "url": "https://files.pythonhosted.org/packages/58/e5/487492036772c1046c8f10ca9c21eb1c81857f0e9d994be2ac8c5f195ceb/scrapy-s3pipeline-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "847e822b18ef71748128d9917fd7290064b76d5e1057606793a356202db25eb4",
          "md5": "4e5b83557879c41eb9651d7d54efe050",
          "sha256": "0cca2aae19f8372bde92a4a362a726f76c0bc86c4e2c1fcfd8c04d25c6aa8a07"
        },
        "downloads": -1,
        "filename": "scrapy_s3pipeline-0.2.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "4e5b83557879c41eb9651d7d54efe050",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 4465,
        "upload_time": "2017-12-05T15:05:22",
        "upload_time_iso_8601": "2017-12-05T15:05:22.873457Z",
        "url": "https://files.pythonhosted.org/packages/84/7e/822b18ef71748128d9917fd7290064b76d5e1057606793a356202db25eb4/scrapy_s3pipeline-0.2.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b3803cfa7e56865359ec7f6be62c98ee77c2c763fa44356a1130f3cbb53258be",
          "md5": "a525690c2016a96e7b9227796017bd6f",
          "sha256": "75a62c5739978b68db117787030b429a525c86741cb14518a718096cb4a9b95b"
        },
        "downloads": -1,
        "filename": "scrapy-s3pipeline-0.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "a525690c2016a96e7b9227796017bd6f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 2744,
        "upload_time": "2017-12-05T15:05:27",
        "upload_time_iso_8601": "2017-12-05T15:05:27.869526Z",
        "url": "https://files.pythonhosted.org/packages/b3/80/3cfa7e56865359ec7f6be62c98ee77c2c763fa44356a1130f3cbb53258be/scrapy-s3pipeline-0.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f944f35bb31fd761ad011c29b8e2064586c0b8e59a7208924478c41a6c1315a0",
          "md5": "a1b786b5a8c3dcb2cb1d30b4f7ac1df1",
          "sha256": "1b6edf080a57f7f63cd364be281a22c156f6779a3c6b0dcf6bb100eaeb0298bb"
        },
        "downloads": -1,
        "filename": "scrapy_s3pipeline-0.3.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "a1b786b5a8c3dcb2cb1d30b4f7ac1df1",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 6028,
        "upload_time": "2019-04-20T05:28:07",
        "upload_time_iso_8601": "2019-04-20T05:28:07.463793Z",
        "url": "https://files.pythonhosted.org/packages/f9/44/f35bb31fd761ad011c29b8e2064586c0b8e59a7208924478c41a6c1315a0/scrapy_s3pipeline-0.3.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "64730f731c30a891ff63ce922c0ccbcf1e0a433c6319eb84cbceecb710754867",
          "md5": "55535539c0e2466b4f6d23a5ad8c1259",
          "sha256": "6b505538ef922dd8848c7ab5b2f2161795deb998e1c21e068e6c0dc81887e23e"
        },
        "downloads": -1,
        "filename": "scrapy-s3pipeline-0.3.0.tar.gz",
        "has_sig": false,
        "md5_digest": "55535539c0e2466b4f6d23a5ad8c1259",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 4656,
        "upload_time": "2019-04-20T05:28:09",
        "upload_time_iso_8601": "2019-04-20T05:28:09.062784Z",
        "url": "https://files.pythonhosted.org/packages/64/73/0f731c30a891ff63ce922c0ccbcf1e0a433c6319eb84cbceecb710754867/scrapy-s3pipeline-0.3.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fa6e79c9e0942c795931d724f7c630c00a937001add052ecf7a5c0ffcc85e96d",
          "md5": "a609188b178a6b7a7d7250ec8809bca4",
          "sha256": "6080f99be8bdf015b8ff9e20cde3ae90fe5b68ce4b498dc339f1dbf985f3a8c5"
        },
        "downloads": -1,
        "filename": "scrapy_s3pipeline-0.4.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "a609188b178a6b7a7d7250ec8809bca4",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 6256,
        "upload_time": "2020-11-05T14:30:03",
        "upload_time_iso_8601": "2020-11-05T14:30:03.722779Z",
        "url": "https://files.pythonhosted.org/packages/fa/6e/79c9e0942c795931d724f7c630c00a937001add052ecf7a5c0ffcc85e96d/scrapy_s3pipeline-0.4.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "345a40f5d6e3eae9e8e11874af3fd85a06c47017d43b73a703dfc55b391658f8",
          "md5": "978125c073930daab1ac055faa7eebe2",
          "sha256": "3524d3fba495f257c692935f1a6a1a2bfd52b03792f78afd5b28ed707939c6e0"
        },
        "downloads": -1,
        "filename": "scrapy-s3pipeline-0.4.0.tar.gz",
        "has_sig": false,
        "md5_digest": "978125c073930daab1ac055faa7eebe2",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 5163,
        "upload_time": "2020-11-05T14:30:06",
        "upload_time_iso_8601": "2020-11-05T14:30:06.030778Z",
        "url": "https://files.pythonhosted.org/packages/34/5a/40f5d6e3eae9e8e11874af3fd85a06c47017d43b73a703dfc55b391658f8/scrapy-s3pipeline-0.4.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.5.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d2701b28a0fdc246c381aca4afce0ec943752fe4b0601257550dc67de3eca0ae",
          "md5": "33fbb1da04449e89eabb1d14fcfc59fb",
          "sha256": "be0c27d1822ab6c556a68eda1e1f13aace59936e508b4cbc6c10f437f1c2ff31"
        },
        "downloads": -1,
        "filename": "scrapy_s3pipeline-0.5.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "33fbb1da04449e89eabb1d14fcfc59fb",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 6285,
        "upload_time": "2020-11-30T12:52:20",
        "upload_time_iso_8601": "2020-11-30T12:52:20.569072Z",
        "url": "https://files.pythonhosted.org/packages/d2/70/1b28a0fdc246c381aca4afce0ec943752fe4b0601257550dc67de3eca0ae/scrapy_s3pipeline-0.5.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ca1e0edc33b6288622420fbb46f64d90d14b52da0daebdf6197ec2e0533b6420",
          "md5": "d91ca8578f9584b2ed6c489a2668ce99",
          "sha256": "86deb5098816587c6f222041ecd6863fbb4d187e120ea994f78542c70b277ca0"
        },
        "downloads": -1,
        "filename": "scrapy-s3pipeline-0.5.0.tar.gz",
        "has_sig": false,
        "md5_digest": "d91ca8578f9584b2ed6c489a2668ce99",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 5206,
        "upload_time": "2020-11-30T12:52:22",
        "upload_time_iso_8601": "2020-11-30T12:52:22.113421Z",
        "url": "https://files.pythonhosted.org/packages/ca/1e/0edc33b6288622420fbb46f64d90d14b52da0daebdf6197ec2e0533b6420/scrapy-s3pipeline-0.5.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.6.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e3fcbe28fc8a57bf81919ef3864b8a4c4b18f8e194a3bdc53d1b83d0bf5cd8d1",
          "md5": "64cf427150eaba72aee3a68c3fab304a",
          "sha256": "5917a001ba1243e47eeb12f75ec84c3519f2438363c3b36645245e588359ae87"
        },
        "downloads": -1,
        "filename": "scrapy_s3pipeline-0.6.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "64cf427150eaba72aee3a68c3fab304a",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 8200,
        "upload_time": "2020-12-30T05:51:06",
        "upload_time_iso_8601": "2020-12-30T05:51:06.214451Z",
        "url": "https://files.pythonhosted.org/packages/e3/fc/be28fc8a57bf81919ef3864b8a4c4b18f8e194a3bdc53d1b83d0bf5cd8d1/scrapy_s3pipeline-0.6.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6477885eb1b4ae4af8335dd896afa365b6322dad1cf8136ff9f88831b207cee5",
          "md5": "54afcf3dabceb1f3afd3d328d3fedbf0",
          "sha256": "7b7e6d1487606d40803336af8e7c59087a305dcdb0d106c34a85792c32a82915"
        },
        "downloads": -1,
        "filename": "scrapy-s3pipeline-0.6.0.tar.gz",
        "has_sig": false,
        "md5_digest": "54afcf3dabceb1f3afd3d328d3fedbf0",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 7031,
        "upload_time": "2020-12-30T05:51:07",
        "upload_time_iso_8601": "2020-12-30T05:51:07.779823Z",
        "url": "https://files.pythonhosted.org/packages/64/77/885eb1b4ae4af8335dd896afa365b6322dad1cf8136ff9f88831b207cee5/scrapy-s3pipeline-0.6.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.7.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9822eedb0f82bd289286b50795ca1a0291981e8bbedb10b16bf89a2264bd64a4",
          "md5": "1bea3b4f6767c9fb2e93fd6a069d5460",
          "sha256": "17edc26602730eb37272e1ffd1fb98e4a812e81362497aee8e54d2e87a7ac921"
        },
        "downloads": -1,
        "filename": "scrapy_s3pipeline-0.7.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "1bea3b4f6767c9fb2e93fd6a069d5460",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 8507,
        "upload_time": "2021-01-31T08:17:34",
        "upload_time_iso_8601": "2021-01-31T08:17:34.395786Z",
        "url": "https://files.pythonhosted.org/packages/98/22/eedb0f82bd289286b50795ca1a0291981e8bbedb10b16bf89a2264bd64a4/scrapy_s3pipeline-0.7.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8c1079d32e6873b4fa997932744744c8b91cf09a68ddfb3f2924ff2ef60eda5d",
          "md5": "c14a432170d6f1c2b6808093fc7e8db2",
          "sha256": "41af49ffd7ec7b33b0a12a74225802634160f1744a1d7efd8abf5d902570e223"
        },
        "downloads": -1,
        "filename": "scrapy-s3pipeline-0.7.0.tar.gz",
        "has_sig": false,
        "md5_digest": "c14a432170d6f1c2b6808093fc7e8db2",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 8236,
        "upload_time": "2021-01-31T08:17:35",
        "upload_time_iso_8601": "2021-01-31T08:17:35.613293Z",
        "url": "https://files.pythonhosted.org/packages/8c/10/79d32e6873b4fa997932744744c8b91cf09a68ddfb3f2924ff2ef60eda5d/scrapy-s3pipeline-0.7.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "9822eedb0f82bd289286b50795ca1a0291981e8bbedb10b16bf89a2264bd64a4",
        "md5": "1bea3b4f6767c9fb2e93fd6a069d5460",
        "sha256": "17edc26602730eb37272e1ffd1fb98e4a812e81362497aee8e54d2e87a7ac921"
      },
      "downloads": -1,
      "filename": "scrapy_s3pipeline-0.7.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "1bea3b4f6767c9fb2e93fd6a069d5460",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 8507,
      "upload_time": "2021-01-31T08:17:34",
      "upload_time_iso_8601": "2021-01-31T08:17:34.395786Z",
      "url": "https://files.pythonhosted.org/packages/98/22/eedb0f82bd289286b50795ca1a0291981e8bbedb10b16bf89a2264bd64a4/scrapy_s3pipeline-0.7.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "8c1079d32e6873b4fa997932744744c8b91cf09a68ddfb3f2924ff2ef60eda5d",
        "md5": "c14a432170d6f1c2b6808093fc7e8db2",
        "sha256": "41af49ffd7ec7b33b0a12a74225802634160f1744a1d7efd8abf5d902570e223"
      },
      "downloads": -1,
      "filename": "scrapy-s3pipeline-0.7.0.tar.gz",
      "has_sig": false,
      "md5_digest": "c14a432170d6f1c2b6808093fc7e8db2",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 8236,
      "upload_time": "2021-01-31T08:17:35",
      "upload_time_iso_8601": "2021-01-31T08:17:35.613293Z",
      "url": "https://files.pythonhosted.org/packages/8c/10/79d32e6873b4fa997932744744c8b91cf09a68ddfb3f2924ff2ef60eda5d/scrapy-s3pipeline-0.7.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}