{
  "info": {
    "author": "Henrik Bostr√∂m",
    "author_email": "bostromh@kth.se",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: BSD License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# `crepes`: Conformal Regressors and Predictive Systems\n\n`crepes` is a Python package for generating *conformal regressors*, which transform point predictions of any underlying regression model into prediction intervals for specified levels of confidence. The package also implements *conformal predictive systems*, which transform the point predictions into cumulative distribution functions.\n\nThe `crepes` package implements standard, normalized and Mondrian conformal regressors and predictive systems. While the package allows you to use your own difficulty estimates and Mondrian categories, there is also a separate module, called `crepes.fillings`, which provides some standard options for these.\n\n## Installation\n\nInstall with: `pip install crepes`\n\n## Quick start\n\n### Conformal regressors\n\nWe first import the main class and two helper functions:\n\n```python\nfrom crepes import ConformalRegressor\nfrom crepes.fillings import sigma_knn, binning\n```\n\nWe will illustrate the above using a dataset from www.openml.org and a `RandomForestRegressor` from `sklearn`:\n\n```python\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\n\ndataset = fetch_openml(name=\"house_sales\", version=3)\nX = dataset.data.values.astype(float)\ny = dataset.target.values.astype(float)\n```\n\nWe now first split the dataset into a training and a test set, and then further split the training set into a proper training set and a calibration set. Finally, we fit a random forest to the proper training set and apply it to obtain point predictions for the test set (nothing new here).\n\n```python\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\nX_prop_train, X_cal, y_prop_train, y_cal = train_test_split(X_train, y_train,\n                                                            test_size=0.25)\n\nlearner = RandomForestRegressor() \nlearner.fit(X_prop_train, y_prop_train)\ny_hat_test = learner.predict(X_test)\n```\n\nNow, we will make use of the calibration set. We apply the model also to the calibration objects and calculate the residuals.\n```python\ny_hat_cal = learner.predict(X_cal)\nresiduals_cal = y_cal - y_hat_cal\n```\n\nThe latter is just what we need to fit a standard conformal regressor:\n```python\ncr_std = ConformalRegressor()\ncr_std.fit(residuals=residuals_cal)\n```\n\nWe can now apply the conformal regressor to get prediction intervals for the test objects, using the point predictions as input, where the probability of not including the correct target in an interval is 1-confidence:\n```python\nstd_intervals = cr_std.predict(y_hat=y_hat_test, confidence=0.99)\n```\n\nThe output is a NumPy array, specifying the lower and upper bound of each interval:\n\n```numpy\narray([[-353379.  ,  939231.  ],\n       [-251874.3 , 1040735.7 ],\n       [-138329.5 , 1154280.5 ],\n       ...,\n       [-389128.68,  903481.32],\n       [-313003.  ,  979607.  ],\n       [ -90551.53, 1202058.47]])\n```\n\nWe may request that the intervals are cut to exclude impossible values, in this case below 0, and if we also rely on the default confidence level (0.95), the output intervals will be a bit tighter:\n\n```python\nintervals_std = cr_std.predict(y_hat=y_hat_test, y_min=0)\n```\n\n```numpy\narray([[  7576.18, 578275.82],\n       [109080.88, 679780.52],\n       [222625.68, 793325.32],\n       ...,\n       [     0.  , 542526.14],\n       [ 47952.18, 618651.82],\n       [270403.65, 841103.29]])\n```\n\nThe above intervals are not normalized, i.e., they are all of the same size (at least before they are cut). We could make the intervals more informative through normalization using difficulty estimates; more difficult instances will be assigned wider intervals.\n\nWe will here use the helper function `sigma_knn` for this purpose. It estimates the difficulty by the mean absolute errors of the k (default `k=5`) nearest neighbors to each instance in the calibration set. A small value (beta) is added to the estimates, which may be given through a (named) argument to the function; below we just use the default, i.e., `beta=0.01`.\n\n```python\nsigmas_cal = sigma_knn(X=X_cal, residuals=residuals_cal)\n```\n\nThe difficulty estimates and residuals of the calibration examples can now be used to form a normalized conformal regressor:\n\n```python\ncr_norm = ConformalRegressor()\ncr_norm.fit(residuals=residuals_cal, sigmas=sigmas_cal)\n```\n\nTo generate prediction intervals for the test set using the normalized conformal regressor, we need difficulty estimates for the test set too, which we get using the calibration objects and residuals. \n\n```python\nsigmas_test = sigma_knn(X=X_cal, residuals=residuals_cal, X_test=X_test)\n```\n\nNow we can obtain the prediction intervals, using the point predictions and difficulty estimates for the test set:\n\n```python\nintervals_norm = cr_norm.predict(y_hat=y_hat_test, sigmas=sigmas_test, \n                                 y_min=0)\n```\n\n```numpy\narray([[     0.        , 645527.3140099 ],\n       [100552.5573358 , 688308.8426642 ],\n       [206605.7263972 , 809345.2736028 ],\n       ...,\n       [ 55388.60029434, 458964.03970566],\n       [252094.62400964, 414509.37599036],\n       [305546.225071  , 805960.714929  ]])\n```\n\nDepending on the employed difficulty estimator, the normalized intervals may sometimes be unreasonably large, in the sense that they may be several times larger than any previously observed error. Moreover, if the difficulty estimator is not very informative, e.g., completely random, the varying interval sizes may give a false impression of that we can expect lower prediction errors for instances with tighter intervals. Ideally, a difficulty estimator providing little or no informatoion on the expected error should instead lead to more uniformly distributed interval sizes.\n\nA Mondrian conformal regressor can be used to address these problems, by dividing the object space into non-overlapping so-called Mondrian categories, and forming a (standard) conformal regressor for each category. The category membership of the objects can be provided as an additional argument, named `bins`, for the `fit` method.\n\nHere we will use the helper function `binning` to form Mondrian categories by equal-sized binning of the difficulty estimates; the function will return labels for the calibration objects as well as thresholds for the bins, which are later to be used when binning the test objects:\n\n```python\nbins_cal, bin_thresholds = binning(values=sigmas_cal, bins=20)\n```\n\nA Mondrian conformal regressor is obtained from the residuals and Mondrian category labels:\n\n```python\ncr_mond = ConformalRegressor()\ncr_mond.fit(residuals=residuals_cal, bins=bins_cal)\n```\n\nIn order to use the Mondrian conformal regressor on the test objects, we need to get the labels of the Mondrian categories for these:\n\n```python\nbins_test = binning(values=sigmas_test, bins=bin_thresholds)\n```\n\nNow we have everything we need to get the prediction intervals:\n\n```python\nintervals_mond = cr_mond.predict(y_hat=y_hat_test, bins=bins_test, y_min=0)\n```\n\n```numpy\narray([[     0.  , 592782.5 ],\n       [146648.15, 642213.25],\n       [260192.95, 755758.05],\n       ...,\n       [ 38332.66, 476019.98],\n       [198148.5 , 468455.5 ],\n       [329931.17, 781575.77]])\n```\n\n### Conformal predictive systems\n\nThe interface to a `ConformalPredictiveSystem` is very similar to that of a conformal regressor; by providing just the residuals, we get a standard conformal predictive system, by providing also difficulty estimates, we get a normalized conformal predictive system and by providing labels for Mondrian categories (bins), we get a Mondrian conformal predictive system.\n\nThe main difference to conformal regressors concerns the output; instead of prediction intervals, conformal predictive systems produce complete cumulative distribution functions (conformal predictive distributions). From these we can generate prediction intervals, but we can also obtain calibrated point predictions, as well as p values for given target values.\n\nLet us fit a Mondrian normalized conformal predictive system, using the above residuals and difficulty estimates (sigmas), and where the Mondrian categories (bins) are formed using the point predictions for the calibration set:\n\n```python\nfrom crepes import ConformalPredictiveSystem\n\nbins_cal, bin_thresholds = binning(values=y_hat_cal, bins=5)\n\ncps_mond_norm = ConformalPredictiveSystem().fit(residuals=residuals_cal,\n                                                sigmas=sigmas_cal,\n                                                bins=bins_cal)\n```\n\nWe already have the point predictions and the difficulty estimates for the test objects, so we just need the category labels according to the new bin thresholds:\n\n```python\nbins_test = binning(values=y_hat_test, bins=bin_thresholds)\n```\n\nWe can now extract prediction intervals from the conformal predictive distributions for the test objects: \n\n```python\nintervals = cps_mond_norm.predict(y_hat=y_hat_test,\n                                  sigmas=sigmas_test,\n                                  bins=bins_test,\n                                  lower_percentiles=2.5,\n                                  higher_percentiles=97.5,\n                                  y_min=0)\n```\n\n```numpy\narray([[     0.        , 537757.93618585],\n       [177348.62535049, 655015.98985999],\n       [253618.31669927, 783707.98804461],\n       ...,\n       [ 73466.09003216, 397289.46238233],\n       [273315.68901744, 405309.55870912],\n       [274035.55188125, 789701.43635318]])\n```\n\nWe can also get the p values for the true target values; they should be uniformly distributed, if the test objects are drawn from the same underlying distribution as the calibration examples.\n\n```python\np_values = cps_mond_norm.predict(y_hat=y_hat_test,\n                                 sigmas=sigmas_test,\n                                 bins=bins_test,\n                                 y=y_test)\n```\n\n```numpy\narray([[0.3262945 ],\n       [0.12184386],\n       [0.82948135],\n       ...,\n       [0.75042278],\n       [0.61815831],\n       [0.70252814]])\n```\n\nWe may request that the predict method returns the full conformal predictive distribution (CPD) for each test instance, as defined by the threshold values, by setting `return_cpds=True`. The format of the distributions vary with the type of conformal predictive system; for a standard and normalized CPS, the output is an array with a row for each test instance and a column for each calibration instance (residual), while for a Mondrian CPS, the default output is a vector containing one CPD per test instance, since the number of values may vary between categories.\n\n```python\ncpds = cps_mond_norm.predict(y_hat=y_hat_test,\n                             sigmas=sigmas_test,\n                             bins=bins_test,\n                             return_cpds=True)\n```\n\nThe resulting vector of arrays is not displayed here, but we instead provide a plot for the CPD of a random test instance:\n\n![cpd](https://user-images.githubusercontent.com/7838741/176182669-1cb739dc-dc38-4c30-80b1-624c2f6b4b83.png)\n\n## Examples\n\nFor additional examples of how to use the package and module, including how to use out-of-bag predictions rather than having to rely on dividing the training set into a proper training and calibration set, see [this Jupyter notebook](https://github.com/henrikbostrom/crepes/blob/main/crepes.ipynb).\n\n## Documentation\n\nFor documentation of the `crepes` package, see [here](http://htmlpreview.github.io/?https://github.com/henrikbostrom/crepes/blob/main/docs/crepes.html).\n\nFor documentation of the `crepes.fillings` module, see [here](http://htmlpreview.github.io/?https://github.com/henrikbostrom/crepes/blob/main/docs/crepes.fillings.html).\n\n## Citing crepes\n\nIf you use `crepes` for a scientific publication, you may cite the following paper:\n\nBostr√∂m, H., 2022. crepes: a Python Package for Generating Conformal Regressors and Predictive Systems. In Conformal and Probabilistic Prediction and Applications. PMLR, 179.\n\nBibtex entry:\n\n```bibtex\n@InProceedings{crepes,\n  title = \t {crepes: a Python Package for Generating Conformal Regressors and Predictive Systems},\n  author =       {Bostr\\\"om, Henrik},\n  booktitle = \t {Proceedings of the Eleventh Symposium on Conformal and Probabilistic Prediction and Applications},\n  year = \t {2022},\n  editor = \t {Johansson, Ulf and Bostr√∂m, Henrik and An Nguyen, Khuong and Luo, Zhiyuan and Carlsson, Lars},\n  volume = \t {179},\n  series = \t {Proceedings of Machine Learning Research},\n  publisher =    {PMLR}\n}\n```\n\n## References\n\n<a id=\"1\">[1]</a> Vovk, V., Gammerman, A. and Shafer, G., 2005. Algorithmic learning in a random world. Springer [Link](https://link.springer.com/book/10.1007/b106715)\n\n<a id=\"2\">[2]</a> Papadopoulos, H., Proedrou, K., Vovk, V. and Gammerman, A., 2002. Inductive confidence machines for regression. European Conference on Machine Learning, pp. 345-356. [Link](https://link.springer.com/chapter/10.1007/3-540-36755-1_29)\n\n<a id=\"3\">[3]</a> Johansson, U., Bostr√∂m, H., L√∂fstr√∂m, T. and Linusson, H., 2014. Regression conformal prediction with random forests. Machine learning, 97(1-2), pp. 155-176. [Link](https://link.springer.com/article/10.1007/s10994-014-5453-0)\n\n<a id=\"4\">[4]</a> Bostr√∂m, H., Linusson, H., L√∂fstr√∂m, T. and Johansson, U., 2017. Accelerating difficulty estimation for conformal regression forests. Annals of Mathematics and Artificial Intelligence, 81(1-2), pp.125-144. [Link](https://link.springer.com/article/10.1007/s10472-017-9539-9)\n\n<a id=\"5\">[5]</a> Bostr√∂m, H. and Johansson, U., 2020. Mondrian conformal regressors. In Conformal and Probabilistic Prediction and Applications. PMLR, 128, pp. 114-133. [Link](https://proceedings.mlr.press/v128/bostrom20a.html)\n\n<a id=\"6\">[6]</a> Vovk, V., Petej, I., Nouretdinov, I., Manokhin, V. and Gammerman, A., 2020. Computationally efficient versions of conformal predictive distributions. Neurocomputing, 397, pp.292-308. [Link](https://www.aminer.org/pub/5e09aac9df1a9c0c416c9b70/computationally-efficient-versions-of-conformal-predictive-distributions)\n\n<a id=\"7\">[7]</a> Bostr√∂m, H., Johansson, U. and L√∂fstr√∂m, T., 2021. Mondrian conformal predictive distributions. In Conformal and Probabilistic Prediction and Applications. PMLR, 152, pp. 24-38. [Link](https://proceedings.mlr.press/v152/bostrom21a.html)\n\n- - -\n\nAuthor: Henrik Bostr√∂m (bostromh@kth.se)\nCopyright 2022 Henrik Bostr√∂m\nLicense: BSD 3 clause\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/henrikbostrom/crepes",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "crepes",
    "package_url": "https://pypi.org/project/crepes/",
    "platform": null,
    "project_url": "https://pypi.org/project/crepes/",
    "project_urls": {
      "Bug Tracker": "https://github.com//henrikbostrom/crepes/issues",
      "Homepage": "https://github.com/henrikbostrom/crepes"
    },
    "release_url": "https://pypi.org/project/crepes/0.1.0/",
    "requires_dist": [
      "numpy",
      "pandas"
    ],
    "requires_python": ">=3.8",
    "summary": "Conformal regressors and predictive systems (crepes)",
    "version": "0.1.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14273704,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "129a77e61d660ef058308cc10f35c32bf7a63c978057720dd34d813d75b0aba9",
          "md5": "6c80303cfd833e4abcfbec59e77c7804",
          "sha256": "f758bbc11fcfee22bd02fbcc4342e7bf507c001a47a04d0cfd5b0ef61f48633b"
        },
        "downloads": -1,
        "filename": "crepes-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "6c80303cfd833e4abcfbec59e77c7804",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 7612,
        "upload_time": "2021-11-17T12:52:34",
        "upload_time_iso_8601": "2021-11-17T12:52:34.820938Z",
        "url": "https://files.pythonhosted.org/packages/12/9a/77e61d660ef058308cc10f35c32bf7a63c978057720dd34d813d75b0aba9/crepes-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "92f680e86b5c3ea59e4a7ab51b832b44bd38351b5ed370fc78d34efeeecf2ae9",
          "md5": "04638645bdf6615218f14b1cea010364",
          "sha256": "cf46ec4e667a379ca615d75b81eaf5944133e3c50e922ebc11477dccec2314fc"
        },
        "downloads": -1,
        "filename": "crepes-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "04638645bdf6615218f14b1cea010364",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 7270,
        "upload_time": "2021-11-17T12:52:36",
        "upload_time_iso_8601": "2021-11-17T12:52:36.762057Z",
        "url": "https://files.pythonhosted.org/packages/92/f6/80e86b5c3ea59e4a7ab51b832b44bd38351b5ed370fc78d34efeeecf2ae9/crepes-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ca75f1eba223daebaa687e1fe887296fdce0fb00008fbaae0de56992a4cca28b",
          "md5": "052fa559705344bfd08422d8224b3d82",
          "sha256": "2597c61718dab1feade9ddcdd7700f9a47eda0c23e6573caebcfe1468d6ad242"
        },
        "downloads": -1,
        "filename": "crepes-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "052fa559705344bfd08422d8224b3d82",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 13812,
        "upload_time": "2022-06-28T14:15:12",
        "upload_time_iso_8601": "2022-06-28T14:15:12.120208Z",
        "url": "https://files.pythonhosted.org/packages/ca/75/f1eba223daebaa687e1fe887296fdce0fb00008fbaae0de56992a4cca28b/crepes-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "603212363997ca9b9c02e3840a550b35aa19b1faf0c691877bda87706696f7f4",
          "md5": "5866187737dc8ecf61d854957dd00d42",
          "sha256": "b9a6acfcb0dfb56cfd20aeb54c2b4f88ffedf1bfef70df7397e506c6a3e1223a"
        },
        "downloads": -1,
        "filename": "crepes-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "5866187737dc8ecf61d854957dd00d42",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 17970,
        "upload_time": "2022-06-28T14:15:13",
        "upload_time_iso_8601": "2022-06-28T14:15:13.977570Z",
        "url": "https://files.pythonhosted.org/packages/60/32/12363997ca9b9c02e3840a550b35aa19b1faf0c691877bda87706696f7f4/crepes-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "ca75f1eba223daebaa687e1fe887296fdce0fb00008fbaae0de56992a4cca28b",
        "md5": "052fa559705344bfd08422d8224b3d82",
        "sha256": "2597c61718dab1feade9ddcdd7700f9a47eda0c23e6573caebcfe1468d6ad242"
      },
      "downloads": -1,
      "filename": "crepes-0.1.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "052fa559705344bfd08422d8224b3d82",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.8",
      "size": 13812,
      "upload_time": "2022-06-28T14:15:12",
      "upload_time_iso_8601": "2022-06-28T14:15:12.120208Z",
      "url": "https://files.pythonhosted.org/packages/ca/75/f1eba223daebaa687e1fe887296fdce0fb00008fbaae0de56992a4cca28b/crepes-0.1.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "603212363997ca9b9c02e3840a550b35aa19b1faf0c691877bda87706696f7f4",
        "md5": "5866187737dc8ecf61d854957dd00d42",
        "sha256": "b9a6acfcb0dfb56cfd20aeb54c2b4f88ffedf1bfef70df7397e506c6a3e1223a"
      },
      "downloads": -1,
      "filename": "crepes-0.1.0.tar.gz",
      "has_sig": false,
      "md5_digest": "5866187737dc8ecf61d854957dd00d42",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.8",
      "size": 17970,
      "upload_time": "2022-06-28T14:15:13",
      "upload_time_iso_8601": "2022-06-28T14:15:13.977570Z",
      "url": "https://files.pythonhosted.org/packages/60/32/12363997ca9b9c02e3840a550b35aa19b1faf0c691877bda87706696f7f4/crepes-0.1.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}