{
  "info": {
    "author": "",
    "author_email": "Bitte Development Team <pythonmodule@bitteapi.com>",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Bitte\r\nPlease, somebody get me a beer instead of another 4 hours preprocessing NLP!\r\n\r\nThis module speeds you up so you can get to the exciting tasks.\r\n\r\nIt is a quirky collection of the makeshift-tasks most NLP tools run into, but are either too recently relevant,\r\ntoo small, or too monolingual to have made it to the common NLP modules like spacy, nltk, huggingface transformers, spark etc.\r\n\r\n\r\n# You hit walls processing data with NLP\r\nThis module helps you overcome annoying wastes of time. Now you can glue together the jagged OCR output from some strange .epub file\r\nthat once had a life as a .pdf file exported frrom .pptx, into your pristine and beautiful BERT acronym\r\nrecognition model which ONLY WORKS WITH FULL SENTENCES AND NORMAL GRAMMAR[*1]\r\n\r\n\r\n# Quick starts\r\n## Repunctuate\r\n```\r\nrepunctuated = bitte.repunctuate([list])\r\n```\r\n- Combined functionality of modules like rpunct, NNSplitter(sentence splitting) and transformer models performing CoLA\r\ntask. Runs quickly, you don't have to deal with the hassle of rpunct difficulties on windows or fast execution of a quantized DistilBERT model: It'll just work.\r\n\r\nThis tool has 0 reliance on external APIs. It does not use a large language model API under the hood. That's why it's fast and cheap.\r\n\r\n## Semantic Chunk Text\r\n```\r\nchunks: List[List[str]] = bitte.chunk_semantically(input_string)\r\n```\r\nSemantic search is amazing. There's so much. But the second or third time you run it, you'll get some weird disappointing half sentence returned as a result.\r\nOh no, you realise. The real world isn't like Wikipedia. We aren't in Kansas. The OCR parser is in Kan sa5.\r\n\r\nYou're going to need the big guns. Semantic Chunk Text can deal with any string of text and make it reasonably semantically chunked together,\r\nideal for retrieval tasks for semantic search and for embedding tasks.\r\n\r\nThis API functions similarly to the Autochapter API of Audacity, but it works for text and does not use transcript timing information.\r\n\r\nThis API isn't super fast as it runs transformer models often multiple times. It is cheap and quality.\r\n\r\n## Wholesome\r\n```\r\nsentence_classifications = bitte.are_full_sentences(sentences)\r\n# Filter for full sentenecs only:\r\nfull_sentences = [sentence for ind, sentence in enumerate(sentences) if sentence_classifications[ind]]\r\n```\r\nHave you ever felt your sentence was incompl\r\n\r\nNow, you can check if an english sentence is complete. This is useful for grammar merging decisions, detecting conversational interupts,\r\nand deciding whether to display questionable quality content to users or not.\r\n\r\nThis API isn't super fast, as it needs a transformer model too. It is cheap and quality.\r\n\r\n# Why now?\r\nIt's a fact that lots of NLP right now works better for english. Large language models; medium ones like BERT;\r\nOCR trained on english datasets... you get the point. If you speak english, you'll be tempted to take advantage\r\nof this somewhere in your pipeline. These tools are for you.\r\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "bitte",
    "package_url": "https://pypi.org/project/bitte/",
    "platform": null,
    "project_url": "https://pypi.org/project/bitte/",
    "project_urls": {
      "Bug Tracker": "https://github.com/bitteauthor/bitteapi/issues",
      "Homepage": "https://github.com/bitteauthor/bitteapi"
    },
    "release_url": "https://pypi.org/project/bitte/0.0.1/",
    "requires_dist": null,
    "requires_python": ">=3.7",
    "summary": "A way to quickly preprocess common NLP tasks. Specialised for english tasks requiring lightweight compute that you just want done",
    "version": "0.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16418682,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "26a4579affa5988d3343eb1d2bb44765420b36f4241f881ca59db6eb5c496e2c",
          "md5": "57d0e7cf15029329a427daf9b3aa3ab2",
          "sha256": "60ecf12e832ff0889b55980ec3954b10e351b0d1beb0dfb4f83ba706178945a1"
        },
        "downloads": -1,
        "filename": "bitte-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "57d0e7cf15029329a427daf9b3aa3ab2",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 3225,
        "upload_time": "2023-01-13T15:06:08",
        "upload_time_iso_8601": "2023-01-13T15:06:08.392992Z",
        "url": "https://files.pythonhosted.org/packages/26/a4/579affa5988d3343eb1d2bb44765420b36f4241f881ca59db6eb5c496e2c/bitte-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "742e972d2aab700ee79f954f543472b9c499b3c22695aa37fe9efd145443ae87",
          "md5": "7eb89f91ac6be8f64d880b74bc59c360",
          "sha256": "8fa8e0affda6ba9eec037dd0ea8d5c651079ba474fd1592f0da0d6d1de1ae8e4"
        },
        "downloads": -1,
        "filename": "bitte-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "7eb89f91ac6be8f64d880b74bc59c360",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 2869,
        "upload_time": "2023-01-13T15:06:09",
        "upload_time_iso_8601": "2023-01-13T15:06:09.797503Z",
        "url": "https://files.pythonhosted.org/packages/74/2e/972d2aab700ee79f954f543472b9c499b3c22695aa37fe9efd145443ae87/bitte-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "26a4579affa5988d3343eb1d2bb44765420b36f4241f881ca59db6eb5c496e2c",
        "md5": "57d0e7cf15029329a427daf9b3aa3ab2",
        "sha256": "60ecf12e832ff0889b55980ec3954b10e351b0d1beb0dfb4f83ba706178945a1"
      },
      "downloads": -1,
      "filename": "bitte-0.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "57d0e7cf15029329a427daf9b3aa3ab2",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 3225,
      "upload_time": "2023-01-13T15:06:08",
      "upload_time_iso_8601": "2023-01-13T15:06:08.392992Z",
      "url": "https://files.pythonhosted.org/packages/26/a4/579affa5988d3343eb1d2bb44765420b36f4241f881ca59db6eb5c496e2c/bitte-0.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "742e972d2aab700ee79f954f543472b9c499b3c22695aa37fe9efd145443ae87",
        "md5": "7eb89f91ac6be8f64d880b74bc59c360",
        "sha256": "8fa8e0affda6ba9eec037dd0ea8d5c651079ba474fd1592f0da0d6d1de1ae8e4"
      },
      "downloads": -1,
      "filename": "bitte-0.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "7eb89f91ac6be8f64d880b74bc59c360",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 2869,
      "upload_time": "2023-01-13T15:06:09",
      "upload_time_iso_8601": "2023-01-13T15:06:09.797503Z",
      "url": "https://files.pythonhosted.org/packages/74/2e/972d2aab700ee79f954f543472b9c499b3c22695aa37fe9efd145443ae87/bitte-0.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}