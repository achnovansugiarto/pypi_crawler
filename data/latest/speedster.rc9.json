{
  "info": {
    "author": "",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# 💥 Speedster\n\n`Speedster` is an open-source module designed to speed up AI inference in just a few lines of code. The library automatically applies the best set of SOTA optimization techniques to achieve the maximum inference speed-up (latency, throughput, model size) physically possible on your hardware (single machine).\n\n`Speedster` makes it easy to combine optimization techniques across the whole software-to-hardware stack, delivering best-in-class speed-ups. If you like the idea, give us a star to support the project ⭐\n\n![speedster](https://user-images.githubusercontent.com/53374883/225599469-f1a626f0-c001-42bd-bc8b-ec0e966ddad6.png)\n\nThe core `Speedster` workflow consists of 3 steps:\n\n\n- [x]  **Select**: input your model in your preferred DL framework and express your preferences regarding:\n    - Accuracy loss: do you want to trade off a little accuracy for much higher performance?\n    - Optimization time: stellar accelerations can be time-consuming. Can you wait, or do you need an instant answer?\n- [x]  **Search**: the library automatically tests every combination of optimization techniques across the software-to-hardware stack (sparsity, quantization, compilers, etc.) that is compatible with your needs and local hardware.\n- [x]  **Serve**: finally, `Speedster` chooses the best configuration of optimization techniques and returns an accelerated version of your model in the DL framework of your choice (just on steroids 🚀).\n\n\n# Installation\n\nInstall `Speedster` and its base requirements:\n```\npip install speedster\n```\n\nThen make sure to install all the available deep learning compilers.\n```\npython -m nebullvm.installers.auto_installer --compilers all\n```\n> :warning: For **MacOS** with **ARM processors**, please use a conda environment.\n> Moreover, if you want to optimize a **PyTorch model**, PyTorch must be pre-installed \n> on your environment before proceeding to the next step, please install it from this \n> [link](https://pytorch.org/get-started/locally/).\n\nFor more details on how to install Speedster, please visit our [Installation](https://docs.nebuly.com/Speedster/installation/) guide.\n\n# Quick start\n\nOnly one line of code - that’s what you need to accelerate your model! Find below your getting started guide for 5 different input model frameworks:\n\n<details>\n<summary>🔥 PyTorch </summary>\n    \nIn this section, we will learn about the 4 main steps needed to optimize PyTorch models:\n\n1) Input your model and data\n2) Run the optimization\n3) Save your optimized model \n4) Load and run your optimized model in production\n\n```python\nimport torch\nimport torchvision.models as models\nfrom speedster import optimize_model, save_model\n\n#1 Provide input model and data (we support PyTorch Dataloaders and custom input, see the docs to learn more)\nmodel = models.resnet50()  \ninput_data = [((torch.randn(1, 3, 256, 256), ), torch.tensor([0])) for _ in range(100)]\n\n#2 Run Speedster optimization\noptimized_model = optimize_model(\n    model, \n    input_data=input_data, \n    optimization_time=\"constrained\",\n    metric_drop_ths=0.05\n)\n\n#3 Save the optimized model\nsave_model(optimized_model, \"model_save_path\")\n```\n\nOnce the optimization is completed, start using the accelerated model (on steroids 🚀) in your DL framework of choice.\n\n```python\n#4 Load and run your PyTorch accelerated model in production\nfrom speedster import load_model\n\noptimized_model = load_model(\"model_save_path\")\n\noutput = optimized_model(input_sample)\n```\nFor more details, please visit [Getting Started with PyTorch Optimization](https://docs.nebuly.com/Speedster/getting_started/pytorch_getting_started/).\n    \n</details>\n<details>\n<summary>🤗 Hugging Face Transformers </summary>\n    \nIn this section, we will learn about the 4 main steps needed to optimize 🤗 Hugging Face Transformer models:\n\n1) Input your model and data\n2) Run the optimization\n3) Save your optimized model \n4) Load and run your optimized model in production\n\n* <details><summary><b>✅ For Decoder-only or Encoder-only architectures (Bert, GPT, etc)</b></summary>\n\n    ```python\n    from transformers import AlbertModel, AlbertTokenizer\n    from speedster import optimize_model, save_model\n\n    #1a. Provide input model: Load Albert as an example\n    model = AlbertModel.from_pretrained(\"albert-base-v1\")\n    tokenizer = AlbertTokenizer.from_pretrained(\"albert-base-v1\")\n\n    #1b. Dictionary input format (also string format is accepted, see the docs to learn more)\n    text = \"This is an example text for the huggingface model.\"\n    input_dict = tokenizer(text, return_tensors=\"pt\")\n    input_data = [input_dict for _ in range(100)]\n\n    #2 Run Speedster optimization (if input data is in string format, also the tokenizer \n    # should be given as input argument, see the docs to learn more)\n    optimized_model = optimize_model(\n        model, \n        input_data=input_data, \n        optimization_time=\"constrained\",\n        metric_drop_ths=0.05\n    )\n\n    #3 Save the optimized model\n    save_model(optimized_model, \"model_save_path\")\n    ```\n\n    Once the optimization is completed, start using the accelerated model (on steroids 🚀) in your DL framework of choice.\n\n    ```python\n    #4 Load and run your Huggingface accelerated model in production\n    from speedster import load_model\n\n    optimized_model = load_model(\"model_save_path\")\n\n    output = optimized_model(**input_sample)\n    ```\n    For more details, please visit [Getting Started with HuggingFace optimization](https://docs.nebuly.com/Speedster/getting_started/hf_getting_started/).\n\n    </details>\n\n* <details><summary><b>✅ For Encoder-Decoder architectures (T5 etc)</b></summary>\n\n\n    ```python\n    from transformers import T5Tokenizer, T5ForConditionalGeneration\n    from speedster import optimize_model, save_model\n\n    #1a. Provide input model: Load T5 as an example\n    model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n    tokenizer = T5Tokenizer.from_pretrained(\"t5-small\") \n\n    #1b. Dictionary input format\n    question = \"What's the meaning of life?\"\n    answer = \"The answer is:\"\n    input_dict = tokenizer(question, return_tensors=\"pt\")\n    input_dict[\"decoder_input_ids\"] = tokenizer(answer, return_tensors=\"pt\").input_ids\n    input_data = [input_dict for _ in range(100)]\n\n    #2 Run Speedster optimization (if input data is in string format, also the tokenizer \n    # should be given as input argument, see the docs to learn more)\n    optimized_model = optimize_model(\n        model, \n        input_data=input_data, \n        optimization_time=\"constrained\",\n        metric_drop_ths=0.05\n    )\n\n    #3 Save the optimized model\n    save_model(optimized_model, \"model_save_path\")\n    ```\n\n    Once the optimization is completed, start using the accelerated model (on steroids 🚀) in your DL framework of choice.\n\n    ```python\n    #4 Load and run your Huggingface accelerated model in production\n    from speedster import load_model\n\n    optimized_model = load_model(\"model_save_path\")\n\n    output = optimized_model(**input_sample)\n    ```\n    For more details, please visit [Getting Started with HuggingFace optimization](https://docs.nebuly.com/Speedster/getting_started/hf_getting_started/).\n\n    </details>\n    \n</details>\n\n<details>\n<summary>🧨 Hugging Face Diffusers </summary>\n\n> :warning: In order to work properly, the diffusers optimization requires `CUDA>=12.0` and `tensorrt>=8.6.0`. For additional details, please look the docs [here](https://docs.nebuly.com/Speedster/getting_started/diffusers_getting_started/).\n\nIn this section, we will learn about the 4 main steps needed to optimize Stable Diffusion models from the Diffusers library:\n\n1) Input your model and data\n2) Run the optimization\n3) Save your optimized model \n4) Load and run your optimized model in production\n\n```python\nimport torch\nfrom diffusers import StableDiffusionPipeline\nfrom speedster import optimize_model, save_model\n\n#1 Provide input model and data\nmodel_id = \"CompVis/stable-diffusion-v1-4\"\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nif device == \"cuda\":\n    # On GPU we load by default the model in half precision, because it's faster and lighter.\n    pipe = StableDiffusionPipeline.from_pretrained(model_id, revision='fp16', torch_dtype=torch.float16)\nelse:\n    pipe = StableDiffusionPipeline.from_pretrained(model_id)\n\n# Create some example input data\ninput_data = [\n    \"a photo of an astronaut riding a horse on mars\",\n    \"a monkey eating a banana in a forest\",\n    \"white car on a road surrounded by palm trees\",\n    \"a fridge full of bottles of beer\",\n    \"madara uchiha throwing asteroids against people\"\n]\n\n#2 Run Speedster optimization\noptimized_model = optimize_model(\n    model=pipe,\n    input_data=input_data,\n    optimization_time=\"unconstrained\",\n    ignore_compilers=[\"torch_tensor_rt\", \"tvm\"],\n    metric_drop_ths=0.1,\n)\n\n#3 Save the optimized model\nsave_model(optimized_model, \"model_save_path\")\n```\n\nOnce the optimization is completed, start using the accelerated model (on steroids 🚀).\n\n```python\n#4 Load and run your PyTorch accelerated model in production\nfrom speedster import load_model\n\noptimized_model = load_model(\"model_save_path\", pipe=pipe)\n\ntest_prompt = \"futuristic llama with a cyberpunk city on the background\"\noutput = optimized_model(test_prompt).images[0]\n```\nFor more details, please visit [Getting Started with Stable Diffusion optimization](https://docs.nebuly.com/Speedster/getting_started/diffusers_getting_started/).\n    \n</details>\n\n<details>\n<summary>🌊 TensorFlow/Keras </summary>\n    \nIn this section, we will learn about the 4 main steps needed to optimize TensorFlow/Keras models:\n\n1) Input your model and data\n2) Run the optimization\n3) Save your optimized model \n4) Load and run your optimized model in production\n\n```python\nimport tensorflow as tf\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom speedster import optimize_model, save_model\n\n#1 Provide input model and data (we support Keras dataset and custom input, see the docs to learn more)\nmodel = ResNet50() \ninput_data = [((tf.random.normal([1, 224, 224, 3]),), tf.constant([0])) for _ in range(100)]\n\n#2 Run Speedster optimization\noptimized_model = optimize_model(\n    model, \n    input_data=input_data, \n    optimization_time=\"constrained\",\n    metric_drop_ths=0.05\n)\n\n#3 Save the optimized model\nsave_model(optimized_model, \"model_save_path\")\n```\n\nOnce the optimization is completed, start using the accelerated model (on steroids 🚀) in your DL framework of choice.\n\n```python\n#4 Load and run your TensorFlow accelerated model in production\nfrom speedster import load_model\n\noptimized_model = load_model(\"model_save_path\")\n\noutput = optimized_model(input_sample)\n```\nFor more details, please visit [Getting Started with TensorFlow optimization](https://docs.nebuly.com/Speedster/getting_started/tf_getting_started/).\n\n</details>\n<details>\n    \n<summary> ⚡ ONNX </summary>\n\nIn this section, we will learn about the 4 main steps needed to optimize ONNX models:\n\n1) Input your model and data\n2) Run the optimization\n3) Save your optimized model \n4) Load and run your optimized model in production\n\n```python\nimport numpy as np\nfrom speedster import optimize_model, save_model\n\n#1 Provide input model and data\n# Model was downloaded from here: \n# https://github.com/onnx/models/tree/main/vision/classification/resnet\nmodel = \"resnet50-v1-12.onnx\" \ninput_data = [((np.random.randn(1, 3, 224, 224).astype(np.float32), ), np.array([0])) for _ in range(100)]\n\n#2 Run Speedster optimization\noptimized_model = optimize_model(\n    model, \n    input_data=input_data, \n    optimization_time=\"constrained\",\n    metric_drop_ths=0.05\n)\n\n#3 Save the optimized model\nsave_model(optimized_model, \"model_save_path\")\n```\n\nOnce the optimization is completed, start using the accelerated model (on steroids 🚀) in your DL framework of choice.\n\n```python\n#4 Load and run your ONNX accelerated model in production\nfrom speedster import load_model\n\noptimized_model = load_model(\"model_save_path\")\n\noutput = optimized_model(input_sample)\n```\nFor more details, please visit [Getting Started with ONNX optimization](https://docs.nebuly.com/Speedster/getting_started/onnx_getting_started/).\n    \n</details>\n\n# **Documentation**\n\n- [Installation](https://docs.nebuly.com/Speedster/installation/)\n- [Getting started with PyTorch optimization](https://docs.nebuly.com/Speedster/getting_started/pytorch_getting_started/)\n- [Getting started with Hugging Face optimization](https://docs.nebuly.com/Speedster/getting_started/hf_getting_started/)\n- [Getting started with Stable Diffusion optimization](https://docs.nebuly.com/Speedster/getting_started/diffusers_getting_started/)\n- [Getting started with TensorFlow optimization](https://docs.nebuly.com/Speedster/getting_started/tf_getting_started/)\n- [Getting started with ONNX optimization](https://docs.nebuly.com/Speedster/getting_started/onnx_getting_started/)\n- [Key concepts](https://docs.nebuly.com/Speedster/key_concepts/)\n- [Notebooks](https://github.com/nebuly-ai/nebullvm/tree/main/notebooks/speedster)\n- [Advanced options](https://docs.nebuly.com/Speedster/advanced_options/)\n- [Benchmarks](https://docs.nebuly.com/Speedster/benchmarks/)\n\n\n# **Key concepts**\n\n`Speedster`'s design reflects our mission to automatically master each and every existing AI acceleration technique to deliver the **fastest AI ever**. As a result, `Speedster` leverages available enterprise-grade open-source optimization tools. If these tools and  communities already exist, and are distributed under a permissive license (Apache, MIT, etc), we integrate them and happily contribute to their communities. However, many tools do not exist yet, in which case we implement them and open-source the code so that our community can benefit from it.\n\n`Speedster` is shaped around **4 building blocks** and leverages a modular design to foster scalability and integration of new acceleration components across the software to hardware stack.\n\n- [x]  **Converter:** converts the input model from its original framework to the framework backends supported by `Speedster`, namely PyTorch, ONNX and TensorFlow. This allows the Compressor and Compiler modules to apply any optimization technique to the model.\n- [x]  **Compressor:** applies various compression techniques to the model, such as pruning, knowledge distillation, or quantization-aware training.\n- [x]  **Compiler:** converts the compressed models to the intermediate representation (IR) of the supported deep learning compilers. The compilers apply both post-training quantization techniques and graph optimizations, to produce compiled binary files.\n- [x]  **Inference Learner:** takes the best performing compiled model and converts it back into the same interface as the original input model.\n\n![speedster_blocks](https://user-images.githubusercontent.com/42771598/213177175-a76908a2-5eef-4e82-9d54-0fc812131463.png)\n\nThe **compressor** stage leverages the following open-source projects:\n\n- [Intel/neural-compressor](https://github.com/intel/neural-compressor): targeting to provide unified APIs for network compression technologies, such as low precision quantization, sparsity, pruning, knowledge distillation, across different deep learning frameworks to pursue optimal inference performance.\n- [SparseML](https://github.com/neuralmagic/sparseml): libraries for applying sparsification recipes to neural networks with a few lines of code, enabling faster and smaller models.\n\nThe **compiler stage** leverages the following open-source projects:\n\n- [Apache TVM](https://github.com/apache/tvm): open deep learning compiler stack for cpu, gpu and specialized accelerators.\n- [BladeDISC](https://github.com/alibaba/BladeDISC): end-to-end Dynamic Shape Compiler project for machine learning workloads.\n- [DeepSparse](https://github.com/neuralmagic/deepsparse): neural network inference engine that delivers GPU-class performance for sparsified models on CPUs.\n- [OpenVINO](https://github.com/openvinotoolkit/openvino): open-source toolkit for optimizing and deploying AI inference.\n- [ONNX Runtime](https://github.com/microsoft/onnxruntime): cross-platform, high performance ML inferencing and training accelerator\n- [TensorRT](https://github.com/NVIDIA/TensorRT): C++ library for high performance inference on NVIDIA GPUs and deep learning accelerators.\n- [TFlite](https://github.com/tensorflow/tflite-micro) and [XLA](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/compiler/xla): open-source libraries to accelerate TensorFlow models.\n\n\n\n# **Community**\nWe’re developing `Speedster` for and together with our community, so please get in touch on GitHub or Discord. \n\n• **[GitHub issues](https://github.com/nebuly-ai/nebullvm/issues)**: suggest new acceleration components, request new features, and report bugs and improvements.\n\n• **[Discord](https://discord.gg/RbeQMu886J)**: learn about AI acceleration, share exciting projects and hang out with our global community.\n\nThe best way to get started is to pick a good-first issue. Please read our [contribution guidelines](https://docs.nebuly.com/contributions/) for a deep dive into how to best contribute to our project!\n\nDon't forget to leave a star ⭐ to support the project and happy acceleration 🚀\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "speedster",
    "package_url": "https://pypi.org/project/speedster/",
    "platform": null,
    "project_url": "https://pypi.org/project/speedster/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/speedster/0.3.0/",
    "requires_dist": [
      "nebullvm (>=0.9.0)",
      "tabulate (>=0.8.0)"
    ],
    "requires_python": "",
    "summary": "",
    "version": "0.3.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17379175,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8fc42ef970d86d7a32b114158c63bdbf97bb29b36bcca50f704eb66033165102",
          "md5": "cd4a46c574f73684c6825c5bd3d7c8f2",
          "sha256": "1459385cac32ad35b17e993d4396d85f6042b9574ad9a6632628708a079b66cd"
        },
        "downloads": -1,
        "filename": "speedster-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "cd4a46c574f73684c6825c5bd3d7c8f2",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 16905,
        "upload_time": "2022-12-16T18:52:33",
        "upload_time_iso_8601": "2022-12-16T18:52:33.133412Z",
        "url": "https://files.pythonhosted.org/packages/8f/c4/2ef970d86d7a32b114158c63bdbf97bb29b36bcca50f704eb66033165102/speedster-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "268b391dea54bd77df107a65a8ddfe1a00f7a31866a9e3284e7ce4f2ac3c1c33",
          "md5": "4a04caf9aea66f169474a6fa32c73f7f",
          "sha256": "ac29cd6cff891c397b6fd3e0c0dcbd4ad433e5ef892cf54fd36735ca45cea33c"
        },
        "downloads": -1,
        "filename": "speedster-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "4a04caf9aea66f169474a6fa32c73f7f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 16571,
        "upload_time": "2022-12-16T18:52:34",
        "upload_time_iso_8601": "2022-12-16T18:52:34.768474Z",
        "url": "https://files.pythonhosted.org/packages/26/8b/391dea54bd77df107a65a8ddfe1a00f7a31866a9e3284e7ce4f2ac3c1c33/speedster-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d7143c44585a6adc98a9db0dfdb69157657f2925fa93648accaa2f75ee31d3a3",
          "md5": "35fafaf068500b3fd6f51bbe6979e862",
          "sha256": "48fc33c4e909e9f128db37b093c72fbfee1451807bb9edd6b09f12aa4d047c3e"
        },
        "downloads": -1,
        "filename": "speedster-0.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "35fafaf068500b3fd6f51bbe6979e862",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 22233,
        "upload_time": "2023-01-01T22:33:49",
        "upload_time_iso_8601": "2023-01-01T22:33:49.505524Z",
        "url": "https://files.pythonhosted.org/packages/d7/14/3c44585a6adc98a9db0dfdb69157657f2925fa93648accaa2f75ee31d3a3/speedster-0.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6e88ee72d3fccfe8233187c4d517ab2451597a7964831c7a027566d76b2f419e",
          "md5": "39af1090ebc1a55e1a51be669dd79f13",
          "sha256": "d4ed4e5ae1718d1416e29d8bc2b4957fcf5d920da4c2e8af552a0c998a5d9f64"
        },
        "downloads": -1,
        "filename": "speedster-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "39af1090ebc1a55e1a51be669dd79f13",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 21303,
        "upload_time": "2023-01-01T22:33:50",
        "upload_time_iso_8601": "2023-01-01T22:33:50.824146Z",
        "url": "https://files.pythonhosted.org/packages/6e/88/ee72d3fccfe8233187c4d517ab2451597a7964831c7a027566d76b2f419e/speedster-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "748b9e3728c288cd70cc2e3c96816d5aee0c4c9d5a9fcd052b38d077e8145205",
          "md5": "26f3f12ef86c2695e26f87b63299a27e",
          "sha256": "76256a7fd99563b1f42bcf8b7eddf371fca35331c7ed909beb1a4653cc448d48"
        },
        "downloads": -1,
        "filename": "speedster-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "26f3f12ef86c2695e26f87b63299a27e",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 18313,
        "upload_time": "2023-01-09T17:09:27",
        "upload_time_iso_8601": "2023-01-09T17:09:27.860548Z",
        "url": "https://files.pythonhosted.org/packages/74/8b/9e3728c288cd70cc2e3c96816d5aee0c4c9d5a9fcd052b38d077e8145205/speedster-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "caa125187ee02b4c05006f90565b15a337e34b19adb56c16a49b68636ae916b3",
          "md5": "003407c4869fe9a85021c4ca7225e77e",
          "sha256": "7a00dc5edf156f408ef0676d3d5fb4620efbcd1b383bda79ce3bb1c91e6535fc"
        },
        "downloads": -1,
        "filename": "speedster-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "003407c4869fe9a85021c4ca7225e77e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 17641,
        "upload_time": "2023-01-09T17:09:29",
        "upload_time_iso_8601": "2023-01-09T17:09:29.156015Z",
        "url": "https://files.pythonhosted.org/packages/ca/a1/25187ee02b4c05006f90565b15a337e34b19adb56c16a49b68636ae916b3/speedster-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bffc10e75a20468b627cc8fca8baf57be11564c5e6cde96861a28a681820bf7f",
          "md5": "d7b18cf32d68010469892ecc86c17384",
          "sha256": "6e4866ead7021d71bc8c308d8cd0a2ef25a5c430e563215acc6764b8a0495ad4"
        },
        "downloads": -1,
        "filename": "speedster-0.1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d7b18cf32d68010469892ecc86c17384",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 18751,
        "upload_time": "2023-01-12T08:37:30",
        "upload_time_iso_8601": "2023-01-12T08:37:30.998767Z",
        "url": "https://files.pythonhosted.org/packages/bf/fc/10e75a20468b627cc8fca8baf57be11564c5e6cde96861a28a681820bf7f/speedster-0.1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "64c12a45a0a7649d31f50f137f1016b4e001b44415f883144b1dfb4ba15ead85",
          "md5": "fcf03c73c5f1d5717b5053fa27536c59",
          "sha256": "04e3c3b659b999e19a801279cbda4a6de506a0ba7e7a59e067f7cbe8a36a4d99"
        },
        "downloads": -1,
        "filename": "speedster-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "fcf03c73c5f1d5717b5053fa27536c59",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 18027,
        "upload_time": "2023-01-12T08:37:32",
        "upload_time_iso_8601": "2023-01-12T08:37:32.771461Z",
        "url": "https://files.pythonhosted.org/packages/64/c1/2a45a0a7649d31f50f137f1016b4e001b44415f883144b1dfb4ba15ead85/speedster-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6d62ec10a2dcb61a23540cee017eec99b31ff9f2f8adeddf16a73cbfc4c8ef37",
          "md5": "f555958cd81b7cb9abb9f50cae36fa3b",
          "sha256": "2d50624fe64d86d01defa4d13b8ee4df7231d50114a83f83e5f54f96bdfe66e3"
        },
        "downloads": -1,
        "filename": "speedster-0.1.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f555958cd81b7cb9abb9f50cae36fa3b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 19186,
        "upload_time": "2023-01-12T23:54:56",
        "upload_time_iso_8601": "2023-01-12T23:54:56.790787Z",
        "url": "https://files.pythonhosted.org/packages/6d/62/ec10a2dcb61a23540cee017eec99b31ff9f2f8adeddf16a73cbfc4c8ef37/speedster-0.1.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "413e1542d6c49f6eb50601de4876c6ce00fb44c5e97533d1b5469a2929b899b0",
          "md5": "1ddda4e2619fe4550a1e2a8bf09ba2f4",
          "sha256": "700b6e8546d1ce411091964427f12c32a2bca4ac12274a4540e99fb558262806"
        },
        "downloads": -1,
        "filename": "speedster-0.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "1ddda4e2619fe4550a1e2a8bf09ba2f4",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 18390,
        "upload_time": "2023-01-12T23:54:58",
        "upload_time_iso_8601": "2023-01-12T23:54:58.088408Z",
        "url": "https://files.pythonhosted.org/packages/41/3e/1542d6c49f6eb50601de4876c6ce00fb44c5e97533d1b5469a2929b899b0/speedster-0.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "979a05945ad94c042b4b1ef8b041db8f94cd3f82e45209621b64a12a575d7e1f",
          "md5": "41e1065c0114e0e7445efb7079abb4d8",
          "sha256": "9479ae1c38359ccb289e12dd17788b166244db55ead4beb45d1c8a3442106296"
        },
        "downloads": -1,
        "filename": "speedster-0.1.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "41e1065c0114e0e7445efb7079abb4d8",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 19192,
        "upload_time": "2023-01-13T10:03:13",
        "upload_time_iso_8601": "2023-01-13T10:03:13.218860Z",
        "url": "https://files.pythonhosted.org/packages/97/9a/05945ad94c042b4b1ef8b041db8f94cd3f82e45209621b64a12a575d7e1f/speedster-0.1.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "37bc18581cb033aecb8aa30ba53419cbb51d8cfd007d9183fb362013f561ac35",
          "md5": "5b3a3fbf5446c1acab3dce43eb6b47ad",
          "sha256": "83e0e88c418236e002a1df8ff0d960e5303e6d3710192dbba054b62df132a89a"
        },
        "downloads": -1,
        "filename": "speedster-0.1.3.tar.gz",
        "has_sig": false,
        "md5_digest": "5b3a3fbf5446c1acab3dce43eb6b47ad",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 18404,
        "upload_time": "2023-01-13T10:03:15",
        "upload_time_iso_8601": "2023-01-13T10:03:15.328579Z",
        "url": "https://files.pythonhosted.org/packages/37/bc/18581cb033aecb8aa30ba53419cbb51d8cfd007d9183fb362013f561ac35/speedster-0.1.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f3eed0cb54e7d1d6c47a9dce9c875aadb34232e3e972e4d80d7efbf4db0e5ad8",
          "md5": "2462c57313edaf506bb6137ce581dee4",
          "sha256": "fdfc8ed4ac302f54dee2a5c715412f03f96e413777f1dba4f409432e8b5a127c"
        },
        "downloads": -1,
        "filename": "speedster-0.2.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "2462c57313edaf506bb6137ce581dee4",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 20160,
        "upload_time": "2023-01-23T23:02:37",
        "upload_time_iso_8601": "2023-01-23T23:02:37.234920Z",
        "url": "https://files.pythonhosted.org/packages/f3/ee/d0cb54e7d1d6c47a9dce9c875aadb34232e3e972e4d80d7efbf4db0e5ad8/speedster-0.2.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6231ed5e446524c3faa8fb958da4fbeafa13235c6fafc6896896c23d8253d39e",
          "md5": "926ee8f05accd8050039b7ba42b1a719",
          "sha256": "bf256fe577bd697aa34a3fdef9bd5df430e575afe4c5bf638e5b27e034e9d20f"
        },
        "downloads": -1,
        "filename": "speedster-0.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "926ee8f05accd8050039b7ba42b1a719",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 20190,
        "upload_time": "2023-01-23T23:02:38",
        "upload_time_iso_8601": "2023-01-23T23:02:38.681411Z",
        "url": "https://files.pythonhosted.org/packages/62/31/ed5e446524c3faa8fb958da4fbeafa13235c6fafc6896896c23d8253d39e/speedster-0.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8be19adbc2fdf67f7f57ece5c078c004f4000b128dde57f97cfad96a26bcf3f7",
          "md5": "3f24847a93b9cee5314cc82c49c83e28",
          "sha256": "68032dac9572d1d9dd5a357550e9b92dc7a79991d4d6f140616aad94372ae7ab"
        },
        "downloads": -1,
        "filename": "speedster-0.2.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "3f24847a93b9cee5314cc82c49c83e28",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 20368,
        "upload_time": "2023-02-15T13:00:32",
        "upload_time_iso_8601": "2023-02-15T13:00:32.729127Z",
        "url": "https://files.pythonhosted.org/packages/8b/e1/9adbc2fdf67f7f57ece5c078c004f4000b128dde57f97cfad96a26bcf3f7/speedster-0.2.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "aad5f6dff1d7f446d79c6672a5f0073689bcf8ee9481dc4098251d7dc3420a07",
          "md5": "d7bc026a7f9667e513fd622daeeaeac7",
          "sha256": "843a4091d6881e46e61debc932c14b6357aede2bf48a154cc48d8778a9e4f372"
        },
        "downloads": -1,
        "filename": "speedster-0.2.1.tar.gz",
        "has_sig": false,
        "md5_digest": "d7bc026a7f9667e513fd622daeeaeac7",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 20403,
        "upload_time": "2023-02-15T13:00:34",
        "upload_time_iso_8601": "2023-02-15T13:00:34.516215Z",
        "url": "https://files.pythonhosted.org/packages/aa/d5/f6dff1d7f446d79c6672a5f0073689bcf8ee9481dc4098251d7dc3420a07/speedster-0.2.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fafa180a6373f831ae8fd529502ac5f3bf43d18fab206a69c19a27e61359219d",
          "md5": "e2b50cfa0672f256406f531062a4af42",
          "sha256": "7f4dea86dd1fcd04653b77645a2c887d007f7175f1177f84e35b69dec00401f1"
        },
        "downloads": -1,
        "filename": "speedster-0.3.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "e2b50cfa0672f256406f531062a4af42",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 21637,
        "upload_time": "2023-03-21T13:04:45",
        "upload_time_iso_8601": "2023-03-21T13:04:45.483219Z",
        "url": "https://files.pythonhosted.org/packages/fa/fa/180a6373f831ae8fd529502ac5f3bf43d18fab206a69c19a27e61359219d/speedster-0.3.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ead579a782006b8f8667ba0f846e981f95b3cd9fa0bcf4c11f72f9e6c637f140",
          "md5": "2c6ddd6e60936be812895602c7c695d4",
          "sha256": "2b82b4814273038a9e4d31ab065c6041c219f13d40737bd253c6876c2b7a55f5"
        },
        "downloads": -1,
        "filename": "speedster-0.3.0.tar.gz",
        "has_sig": false,
        "md5_digest": "2c6ddd6e60936be812895602c7c695d4",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 22298,
        "upload_time": "2023-03-21T13:04:47",
        "upload_time_iso_8601": "2023-03-21T13:04:47.682639Z",
        "url": "https://files.pythonhosted.org/packages/ea/d5/79a782006b8f8667ba0f846e981f95b3cd9fa0bcf4c11f72f9e6c637f140/speedster-0.3.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "fafa180a6373f831ae8fd529502ac5f3bf43d18fab206a69c19a27e61359219d",
        "md5": "e2b50cfa0672f256406f531062a4af42",
        "sha256": "7f4dea86dd1fcd04653b77645a2c887d007f7175f1177f84e35b69dec00401f1"
      },
      "downloads": -1,
      "filename": "speedster-0.3.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "e2b50cfa0672f256406f531062a4af42",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 21637,
      "upload_time": "2023-03-21T13:04:45",
      "upload_time_iso_8601": "2023-03-21T13:04:45.483219Z",
      "url": "https://files.pythonhosted.org/packages/fa/fa/180a6373f831ae8fd529502ac5f3bf43d18fab206a69c19a27e61359219d/speedster-0.3.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "ead579a782006b8f8667ba0f846e981f95b3cd9fa0bcf4c11f72f9e6c637f140",
        "md5": "2c6ddd6e60936be812895602c7c695d4",
        "sha256": "2b82b4814273038a9e4d31ab065c6041c219f13d40737bd253c6876c2b7a55f5"
      },
      "downloads": -1,
      "filename": "speedster-0.3.0.tar.gz",
      "has_sig": false,
      "md5_digest": "2c6ddd6e60936be812895602c7c695d4",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 22298,
      "upload_time": "2023-03-21T13:04:47",
      "upload_time_iso_8601": "2023-03-21T13:04:47.682639Z",
      "url": "https://files.pythonhosted.org/packages/ea/d5/79a782006b8f8667ba0f846e981f95b3cd9fa0bcf4c11f72f9e6c637f140/speedster-0.3.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}