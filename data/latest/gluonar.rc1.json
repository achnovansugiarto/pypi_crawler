{
  "info": {
    "author": "haoxintong",
    "author_email": "haoxintongpku@gmail.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "Gluon Audio Toolkit\n===================\n\nGluon Audio is a toolkit providing deep learning based audio recognition\nalgorithm. The project is still under development, and only Chinese\nintroduction will be provided.\n\nGluonAR Introduction:\n---------------------\n\nGluonAR is based on MXnet-Gluon, if you are new to it, please check out\n`dmlc 60-minute crash course <http://gluon-crash-course.mxnet.io/>`__.\n\n虽然名字叫GluonAR, 但是目前以及可以预见的时间内只有Text-Independent\nSpeaker Recognition的内容.\n\n已经实现的feature: - 使用ffmpeg的pythonic binding\n``av``\\ 和\\ ``librosa``\\ 做audio数据读取 - 模块支持\\ ``Hybridize()``.\nforward阶段不使用pysound, librosa, scipy, 效率更高,\n提供快速训练和end-to-end部署的能力, 包括: -\n基于\\ ``nd.contrib.fft``\\ 的短时傅里叶变换(\\ ``STFTBlock``)和z-score\nblock, 相比使用numpy和scipy预处理后载入GPU训练效率提高12%. -\n``MelSpectrogram``, ``DCT1D``, ``MFCC``, ``PowerToDB`` -\n`1808.00158 <https://arxiv.org/abs/1808.00158>`__\\ 中提出的\\ ``SincBlock``\n- gluon风格的VOX数据集载入 - 类似人脸验证的Speaker Verification -\n使用频谱图训练声纹特征的例子, 在VOX1上的1:1验证acc: 0.941152+-0.004926\n\nexample:\n\n.. code:: python\n\n    import numpy as np\n    import mxnet as mx\n    import librosa as rosa\n    from gluonar.utils.viz import view_spec\n    from gluonar.nn.basic_blocks import STFTBlock\n\n    data = rosa.load(r\"resources/speaker_recognition/speaker0_0.m4a\", sr=16000)[0][:35840]\n    nd_data = mx.nd.array([data], ctx=mx.gpu())\n\n    stft = STFTBlock(35840, hop_length=160, win_length=400)\n    stft.initialize(ctx=mx.gpu())\n\n    # stft block forward\n    ret = stft(nd_data).asnumpy()[0][0]\n    spec = np.transpose(ret, (1, 0)) ** 2\n    view_spec(spec)\n\n    # stft in librosa \n    spec = rosa.stft(data, hop_length=160, win_length=400, window=\"hamming\")\n    spec = np.abs(spec) ** 2\n    view_spec(spec)\n\n输出:\n\n+-------------+-------------------+\n| STFTBlock   | STFT in librosa   |\n+=============+===================+\n+-------------+-------------------+\n\n更多的例子请参考\\ ``examples/``.\n\nRequirements\n------------\n\nmxnet-1.5.0+, gluonfr, av, librosa, ...\n\n音频库的选择主要考虑数据读取速度,\n训练过程中音频的解码相比图像解码会消耗更多时间,\n实际测试librosa从磁盘加载一个aac编码的短音频 耗时是pyav的8倍左右.\n\n-  librosa\n   ``pip install librosa``\n-  ffmpeg\n\n   ::\n\n       # 下载ffmpeg源码, 进入根目录\n       ./configure --extra-cflags=-fPIC --enable-shared\n       make -j\n       sudo make install\n\n-  pyav, 需要先安装ffmpeg\n   ``pip install av``\n-  | gluonfr\n   | ``pip install git+https://github.com/THUFutureLab/gluon-face.git@master``\n\nDatasets\n--------\n\nTIMIT\n~~~~~\n\nThe DARPA TIMIT Acoustic-Phonetic Continuous Speech Corpus (TIMIT)\nTraining and Test Data. Before using this dataset please follow the\ninstruction on `link <https://catalog.ldc.upenn.edu/LDC93S1>`__.\n\nA copy of this was uploaded to `Google Drive <https://goo.gl/l0sPwz>`__\nby @philipperemy `here <https://github.com/philipperemy/timit>`__.\n\nVoxCeleb\n~~~~~~~~\n\nVoxCeleb is an audio-visual dataset consisting of short clips of human\nspeech, extracted from interview videos uploaded to YouTube.\n\nFor more information, checkout this\n`page <http://www.robots.ox.ac.uk/~vgg/data/voxceleb/>`__.\n\nPretrained Models\n-----------------\n\nSpeaker Recognition\n~~~~~~~~~~~~~~~~~~~\n\nResNet18 training with VoxCeleb\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nDownload: `Baidu <https://pan.baidu.com/s/1Gkhi67oJSiSyAiYNTdPlTw>`__,\n`Google\nDrive <https://drive.google.com/open?id=1oEvSQrnNwYL4pRyQ8t87hRP3m22wuePz>`__\n\nI followed the ideas in paper **VoxCeleb2**\n`1806.05622 <https://arxiv.org/abs/1806.05622>`__ to train this model,\nthe differences between them:\n\n+-------+--------+--------+\n| -     | Res18  | Res34  |\n|       | in     | in     |\n|       | this   | paper  |\n|       | repo   |        |\n+=======+========+========+\n| Train | VoxCel | VoxCel |\n| ed    | eb2    | eb2    |\n| on    |        |        |\n+-------+--------+--------+\n| Input | 224x22 | 512x30 |\n| spec  | 4      | 0      |\n| size  |        |        |\n+-------+--------+--------+\n| Eval  | Random | Origin |\n| on    | 9500+  | al     |\n|       | pair   | VoxCel |\n|       | sample | eb1    |\n|       | s      | test   |\n|       | from   | set    |\n|       | VoxCel |        |\n|       | eb1    |        |\n|       | train  |        |\n|       | and    |        |\n|       | test   |        |\n|       | set    |        |\n+-------+--------+--------+\n| Metri | Accura | EER:   |\n| c     | cy:0.9 | 0.0504 |\n|       | 32656+ |        |\n|       | -0.005 |        |\n|       | 187    |        |\n+-------+--------+--------+\n| Frame | Mxnet  | Matcon |\n| work  | Gluon  | vnet   |\n+-------+--------+--------+\n| ROC   |        | -      |\n+-------+--------+--------+\n\nTODO\n----\n\n接下来会慢慢补全使用mxnet gluon训练说话人识别的工具链, 预计会花超长时间.\n\nDocs\n----\n\nGluonAR documentation is not available now.\n\nAuthors\n-------\n\n{ `haoxintong <https://github.com/haoxintong>`__ }\n\nDiscussion\n----------\n\nAny suggestions, please open an issue.\n\nContributes\n-----------\n\nThe final goal of this project is providing an easy using deep learning\nbased audio algorithm library like\n`pytorch-kaldi <https://github.com/mravanelli/pytorch-kaldi>`__.\n\nContribution is welcomed.\n\nReferences\n----------\n\n1. MXNet Documentation and Tutorials\n   https://zh.diveintodeeplearning.org/\n",
    "description_content_type": "",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/haoxintong/gluon-audio",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "gluonar",
    "package_url": "https://pypi.org/project/gluonar/",
    "platform": "",
    "project_url": "https://pypi.org/project/gluonar/",
    "project_urls": {
      "Homepage": "https://github.com/haoxintong/gluon-audio"
    },
    "release_url": "https://pypi.org/project/gluonar/0.1.0/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "Gluon Audio Toolkit",
    "version": "0.1.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 5385310,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e2a133e1a0221c11e85382979dfd6d227f768c97ac25facc72efafa08328b089",
          "md5": "d8dd0a44fa65e46068a6d97ae497713d",
          "sha256": "0e38622857699094e231ecc9a680d1e20175d98ec63cfb3e63b02158a812a194"
        },
        "downloads": -1,
        "filename": "gluonar-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "d8dd0a44fa65e46068a6d97ae497713d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 15000,
        "upload_time": "2019-06-11T08:15:00",
        "upload_time_iso_8601": "2019-06-11T08:15:00.773540Z",
        "url": "https://files.pythonhosted.org/packages/e2/a1/33e1a0221c11e85382979dfd6d227f768c97ac25facc72efafa08328b089/gluonar-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "e2a133e1a0221c11e85382979dfd6d227f768c97ac25facc72efafa08328b089",
        "md5": "d8dd0a44fa65e46068a6d97ae497713d",
        "sha256": "0e38622857699094e231ecc9a680d1e20175d98ec63cfb3e63b02158a812a194"
      },
      "downloads": -1,
      "filename": "gluonar-0.1.0.tar.gz",
      "has_sig": false,
      "md5_digest": "d8dd0a44fa65e46068a6d97ae497713d",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 15000,
      "upload_time": "2019-06-11T08:15:00",
      "upload_time_iso_8601": "2019-06-11T08:15:00.773540Z",
      "url": "https://files.pythonhosted.org/packages/e2/a1/33e1a0221c11e85382979dfd6d227f768c97ac25facc72efafa08328b089/gluonar-0.1.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}