{
  "info": {
    "author": "Vitaly Bondar",
    "author_email": "johngull@gmail.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# PyTorch implementation of the GradInit\n\nPytorch-based library to initialize any neural network with the gradient descent and your dataset.\nThis implementation is the simple way to use the method described in the paper [Chen Zhu et al. GradInit: Learning to Initialize Neural Networks for Stable and Efficient Training](https://arxiv.org/abs/2102.08098)\n\nGradinit may be used as the alternative to the warmup mechanism.\nIt is more useful for deep or unusual architectures.\n\n## Installation\n\n    pip install gradinit\n\nor\n\n    pip install --upgrade git+https://github.com/johngull/gradinit.git\n\n## Differences from the original paper\n\nThis implementation uses simplified loss in the case of the small gradients.\nin this case, `gradinit` uses the user's loss instead of the complex 2-stage procedure described in the paper.\n\n## Usage\n\nTo make gradinit you need to wrap your model with the `GradInitWrapper` \nand then you can use the usual training loop with some differences:\n- recalculate loss with the `GradInitWrapper.grad_loss` function\n- clip scales with the `GradInitWrapper.clamp_scales` function\n\nHere is a simplified example of the full gradinit process:\n```python\nmodel: torch.nn.Module = ...\n\nwith GradInitWrapper(model) as ginit:\n    #it is important to create optimizer after wraping your model\n    optimizer = torch.optim.Adam(model.parameters())  \n    norm = 1    # use 2 for the SGD optimizer\n\n    model.train()\n    for x, y in data_loader:\n        pred = model(x)\n        loss = criterion(pred, y)\n    \n        # recalculate gradinit loss based on your loss\n        loss = ginit.grad_loss(loss, norm)\n    \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    \n        # clip minimum values for the init scales\n        ginit.clamp_scales()\n    \n# on exit of with statement model is recovered to its normal way\n# here you should create your main optimizer and start training\noptimizer = torch.optim.Adam(model.parameters())\n...\n\n```\n\nAlternatively to the `with`-notation \nyou may use `detach` or delete the wrapper object after finishing the initialization process.\n```python\nginit = GradInitWrapper(model)\n# full gradinit loop\n...\nginit.detach() # or del ginit\n\n# here you should create your main optimizer and start training\noptimizer = torch.optim.Adam(model.parameters())\n...\n\n```\n\nFrom our experience gradinit works worse in the mixed-precision mode. \nAnd we recommend running gradinit in the full-precision mode and then starting the main training loop in mixed-precision.\n\nBut if you really want to try, gradinit supports torch mixed-precision.\nIn such a case gradinit need to use your scaler object.\nHere is an example of how to use gradinit with the torch amp.\n```python\nimport torch.cuda.amp\n\nmodel: torch.nn.Module = ...\nscaler: torch.cuda.amp.GradScaler = ...\n\nwith GradInitWrapper(model) as ginit:\n    # it is important to create optimizer after wraping your model\n    optimizer = torch.optim.Adam(model.parameters())\n    norm = 1  # use 2 for the SGD optimizer\n\n    model.train()\n    for x, y in data_loader:\n        with autocast():\n            pred = model(x)\n            loss = criterion(pred, y)\n\n        # recalculate gradinit loss based on your loss\n        loss = ginit.grad_loss(loss, norm, scaler=scaler)\n\n        optimizer.zero_grad()\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        # clip minimum values for the init scales\n        ginit.clamp_scales()\n\n# on exit of with statement model is recovered to its normal way\n# here you should create your main optimizer and start training\noptimizer = torch.optim.Adam(model.parameters())\n...\n\n```\n\n## Experiments\n\nFor the experiment results see [this page](https://github.com/johngull/gradinit/tree/main/experiments)\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/johngull/gradinit",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "gradinit",
    "package_url": "https://pypi.org/project/gradinit/",
    "platform": "",
    "project_url": "https://pypi.org/project/gradinit/",
    "project_urls": {
      "Homepage": "https://github.com/johngull/gradinit"
    },
    "release_url": "https://pypi.org/project/gradinit/0.1.1/",
    "requires_dist": [
      "torch"
    ],
    "requires_python": "",
    "summary": "Pytorch implementation of the gradient-based initialization",
    "version": "0.1.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12786533,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bfc7a25a8d73b25aa84cb9e9209d5f6bc95a5bd8fd38869070978edcb2b197cd",
          "md5": "165d6417c891844e8e9a823b6e2d1320",
          "sha256": "8dc59713447fca1758e7e2bb700c9fd0797d68b1e896af617a518b0620b37ab3"
        },
        "downloads": -1,
        "filename": "gradinit-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "165d6417c891844e8e9a823b6e2d1320",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 5993,
        "upload_time": "2022-01-31T19:04:24",
        "upload_time_iso_8601": "2022-01-31T19:04:24.212243Z",
        "url": "https://files.pythonhosted.org/packages/bf/c7/a25a8d73b25aa84cb9e9209d5f6bc95a5bd8fd38869070978edcb2b197cd/gradinit-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e2f5c3f59e02e601abcac07545139f54ede63b7360b0a8565da031d309ecb1bc",
          "md5": "fe7105c85a71e9b06fd7770df2ee6e74",
          "sha256": "dacd17d081f27fafbdf4c31e664e27605633ee182edd65cf979fdacbb7d278b9"
        },
        "downloads": -1,
        "filename": "gradinit-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "fe7105c85a71e9b06fd7770df2ee6e74",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 4970,
        "upload_time": "2022-01-31T19:04:25",
        "upload_time_iso_8601": "2022-01-31T19:04:25.629308Z",
        "url": "https://files.pythonhosted.org/packages/e2/f5/c3f59e02e601abcac07545139f54ede63b7360b0a8565da031d309ecb1bc/gradinit-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d8ef1446ebba0a420ebd489482d880bdc78cdeba4748c956b0eadf1e7e3b61de",
          "md5": "5049425cd8ad62c32e6cbc70c11a8592",
          "sha256": "edc9f40bbf5141bb332e319d884f896f8990746657aac67bdf087406917f65e4"
        },
        "downloads": -1,
        "filename": "gradinit-0.1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "5049425cd8ad62c32e6cbc70c11a8592",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 6008,
        "upload_time": "2022-02-04T11:23:11",
        "upload_time_iso_8601": "2022-02-04T11:23:11.448269Z",
        "url": "https://files.pythonhosted.org/packages/d8/ef/1446ebba0a420ebd489482d880bdc78cdeba4748c956b0eadf1e7e3b61de/gradinit-0.1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "eb175ee76f751c84f46c64f11547870e653d0f2f183afa6ea301af198facbcb4",
          "md5": "26593bbe2c95ddc96cfe9b41c07cdad3",
          "sha256": "8d48509f01c0a253dda478fbc87a1325170809c237c7d2e32e611b4ecb4c7c61"
        },
        "downloads": -1,
        "filename": "gradinit-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "26593bbe2c95ddc96cfe9b41c07cdad3",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 4982,
        "upload_time": "2022-02-04T11:23:13",
        "upload_time_iso_8601": "2022-02-04T11:23:13.176872Z",
        "url": "https://files.pythonhosted.org/packages/eb/17/5ee76f751c84f46c64f11547870e653d0f2f183afa6ea301af198facbcb4/gradinit-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "d8ef1446ebba0a420ebd489482d880bdc78cdeba4748c956b0eadf1e7e3b61de",
        "md5": "5049425cd8ad62c32e6cbc70c11a8592",
        "sha256": "edc9f40bbf5141bb332e319d884f896f8990746657aac67bdf087406917f65e4"
      },
      "downloads": -1,
      "filename": "gradinit-0.1.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "5049425cd8ad62c32e6cbc70c11a8592",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 6008,
      "upload_time": "2022-02-04T11:23:11",
      "upload_time_iso_8601": "2022-02-04T11:23:11.448269Z",
      "url": "https://files.pythonhosted.org/packages/d8/ef/1446ebba0a420ebd489482d880bdc78cdeba4748c956b0eadf1e7e3b61de/gradinit-0.1.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "eb175ee76f751c84f46c64f11547870e653d0f2f183afa6ea301af198facbcb4",
        "md5": "26593bbe2c95ddc96cfe9b41c07cdad3",
        "sha256": "8d48509f01c0a253dda478fbc87a1325170809c237c7d2e32e611b4ecb4c7c61"
      },
      "downloads": -1,
      "filename": "gradinit-0.1.1.tar.gz",
      "has_sig": false,
      "md5_digest": "26593bbe2c95ddc96cfe9b41c07cdad3",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 4982,
      "upload_time": "2022-02-04T11:23:13",
      "upload_time_iso_8601": "2022-02-04T11:23:13.176872Z",
      "url": "https://files.pythonhosted.org/packages/eb/17/5ee76f751c84f46c64f11547870e653d0f2f183afa6ea301af198facbcb4/gradinit-0.1.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}