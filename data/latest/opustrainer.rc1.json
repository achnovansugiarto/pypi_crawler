{
  "info": {
    "author": "",
    "author_email": "Jelmer van der Linde <jelmer.vanderlinde@ed.ac.uk>",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Trainer\nThe purpose of the trainer is to provide the user with a flexible way of scheduling various sources of input data, as well as augment the training data with tittle casing, all caps, etc. This is particularly useful when you have multiple data sources and you want to pretrain the model first on backtranslated data, gradually add other sources of data, and finally fine tune, all in one go.\n\nAlternatively, this tool is particularly suited to training multilingual models, as it provides an easy way to define the desired mixture of datasets from different language sources.\n\n## Configuration file\nDefine your training process via a configuration file. You define the datasets on top, the stages and then for each stage a mixing criteria and a stage termination criteria. An example configuration file is provided below. The path to the `trainer` is a path to any neural network trainer that supports having stdin as training input format.\n```yml\n# Datasets are already TSV files\ndatasets:\n  clean: test/data/clean\n  medium: test/data/medium\n  dirty: test/data/dirty\n\nstages:\n  - start\n  - mid\n  - end\n\nstart:\n  - clean 0.8\n  - medium 0.2\n  - dirty 0\n  - until clean 2 # Until two epochs of clean\n\nmid:\n  - clean 0.6\n  - medium 0.3\n  - dirty 0.1\n  - until medium 1\n\nend:\n  - clean 0.4\n  - medium 0.3\n  - dirty 0.3\n  - until dirty 5 # use `inf` to mean until forever\n\nmodifiers:\n- uppercase 0.05 # Apply uppercase randomly to 0.05% of sentences. Use 0 to disable\n- titlecase 0.05 # Apply titlecase randomly to 0.05% of sentences. Use 0 to disable\n\nseed: 1111\ntrainer: /path/to/trainer/run.py\n```\n\n## Usage\n```bash\n% ./trainer.py --help\nusage: trainer.py [-h] --config CONFIG [--temporary-directory TEMPORARY_DIR] [--state STATE_FILE] [--do-not-resume] [--sync] [trainer-command [arguments]]\n\nFeeds marian tsv data for training.\n\noptions:\n  -h, --help            show this help message and exit\n  --config CONFIG, -c CONFIG\n                        YML configuration input.\n  --temporary-directory TEMPORARY_DIR, -t TEMPORARY_DIR\n                        Temporary dir, used for shuffling and tracking state\n  --state STATE_FILE    Path to trainer state file which stores how much of\n                        each dataset has been read. Defaults to ${CONFIG}.state\n  --sync                Do not shuffle in the background\n  --do-not-resume, -d   Do not resume from the previous training state\n```\nOnce you fix the paths in the configuration file, `train_config.yml` you can run a test case by doing:\n```bash\n./trainer.py -c train_config.yml\n```\nYou can check resulting mixed file in `/tmp/test`. If your neural network trainer doesn't support training from `stdin`, you can use this tool to generate a training dataset and then disable data reordering or shuffling at your trainer implementation, as your training input should be balanced.\n\nAt the start of the training all datasets are shuffled. Each time a dataset's end is reached, it is re-shuffled. Shuffling [in the system temp directory](https://docs.python.org/3.11/library/tempfile.html#tempfile.gettempdir) but can be repositioned using `--temporary-directory` or the `TMPDIR` environment variable. By default, the training state is kept in the same place as the configuration file. If training is interrupted, re-running the trainer should resume from where it was (depending on how much your neural network trainer has buffered, that part will be skipped).\n\n## Generating vocabulary and placeholders before training\nTo use the placeholder code augment your training data with placeholders before training, look at this example script:\n```bash\n#!/usr/bin/env bash\n# Get the placeholders\n../placeholders/placeholders.py -c train_config_bgen.yml --dump_placeholders > my_placeholders\n# train vocabulary\nspm_train --bos_id=-1 --eos_id=0 --unk_id=1 --user_defined_symbols_file my_placeholders \\\n  --model_prefix=\"test/vocab.bgen\" --vocab_size=12000 \\\n  --input=\"/home/dheart/uni_stuff/postdoc/empty-train/trainer/test/data/clean.bgen\" \\\n  --shuffle_input_sentence=true --character_coverage 1\n\n# Move vocabulary to the new location\nmv test/vocab.bgen.model test/vocab.bgen.spm\n\n# Make all datasets placeholded\nfor myfile in test/data/*.bgen; do\n\t../placeholders/placeholders.py -n --strict --encode -c train_config_bgen.yml < ${myfile} > ${myfile}.pls\ndone\n```\nYou need to augment the training configuration with additional placeholder configuration setting:\n```yml\nvocab: /home/dheart/uni_stuff/postdoc/empty-train/trainer/test/vocab.bgen.spm\nplaceholder-symbol: \"<PLACEHOLDER>\"\nnum-placeholders: 4\nregexes:\n    - (https?:\\/\\/www\\.\\w{1,63}\\.\\w{1,63}(?:\\/\\w{0,63}){0,})\n    - (www\\.\\w{1,63}\\.\\w{1,63}(?:\\/\\w{0,63}){0,})\n    - ([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+)\n```\nAfter vocabulary is trained and data is preprocessed, proceed with a normal training run.\n## Future work\n\n- Terminology support (using a dictionary). We should augment the training data with terminology (possibly stemmed on the source side) so that we can use it real world models\n- A one click run training\n\n# Acknowledgements\n\nThis project has received funding from the European Union’s Horizon Europe research and innovation programme under grant agreement No 101070350 and from UK Research and Innovation (UKRI) under the UK government’s Horizon Europe funding guarantee [grant number 10052546]\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "opustrainer",
    "package_url": "https://pypi.org/project/opustrainer/",
    "platform": null,
    "project_url": "https://pypi.org/project/opustrainer/",
    "project_urls": {
      "Bug Tracker": "https://github.com/hplt-project/OpusTrainer/issues",
      "Homepage": "https://github.com/hplt-project/OpusTrainer"
    },
    "release_url": "https://pypi.org/project/opustrainer/0.1/",
    "requires_dist": [
      "PyYAML (==6.0)"
    ],
    "requires_python": ">=3.7",
    "summary": "Scheduled training for machine translation systems",
    "version": "0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17147507,
  "releases": {
    "0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4260840a0884ec3ea6269eef01a48ba1e261a056eb01c544fdd8be774e6282fe",
          "md5": "db8582786bbf9b0ab04b12e52e68bed5",
          "sha256": "a7b86657003ea4ca591f126a492c7ba75d9bd14f78f710aefaf5200d6bc7447f"
        },
        "downloads": -1,
        "filename": "opustrainer-0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "db8582786bbf9b0ab04b12e52e68bed5",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 14339,
        "upload_time": "2023-03-03T17:48:23",
        "upload_time_iso_8601": "2023-03-03T17:48:23.270044Z",
        "url": "https://files.pythonhosted.org/packages/42/60/840a0884ec3ea6269eef01a48ba1e261a056eb01c544fdd8be774e6282fe/opustrainer-0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "4260840a0884ec3ea6269eef01a48ba1e261a056eb01c544fdd8be774e6282fe",
        "md5": "db8582786bbf9b0ab04b12e52e68bed5",
        "sha256": "a7b86657003ea4ca591f126a492c7ba75d9bd14f78f710aefaf5200d6bc7447f"
      },
      "downloads": -1,
      "filename": "opustrainer-0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "db8582786bbf9b0ab04b12e52e68bed5",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 14339,
      "upload_time": "2023-03-03T17:48:23",
      "upload_time_iso_8601": "2023-03-03T17:48:23.270044Z",
      "url": "https://files.pythonhosted.org/packages/42/60/840a0884ec3ea6269eef01a48ba1e261a056eb01c544fdd8be774e6282fe/opustrainer-0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}