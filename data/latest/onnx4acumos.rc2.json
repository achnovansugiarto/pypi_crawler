{
  "info": {
    "author": "Bruno Lozach",
    "author_email": "bruno.lozach@orange.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Intended Audience :: Developers",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: Apache Software License",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8"
    ],
    "description": ".. ===============LICENSE_START=======================================================\n.. Acumos CC-BY-4.0\n.. ===================================================================================\n.. Copyright (C) 2020 Orange Intellectual Property. All rights reserved.\n.. ===================================================================================\n.. This Acumos documentation file is distributed by Orange\n.. under the Creative Commons Attribution 4.0 International License (the \"License\")\n.. you may not use this file except in compliance with the License.\n.. You may obtain a copy of the License at\n..\n..      http://creativecommons.org/licenses/by/4.0\n..\n.. This file is distributed on an \"AS IS\" BASIS,\n.. WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n.. See the License for the specific language governing permissions and\n.. limitations under the License.\n.. ===============LICENSE_END=========================================================\n\n===========\nonnx4acumos\n===========\n\n|Build Status|\n\n``onnx4acumos`` is a client library that allows modelers to on-board their onnx models\non an Acumos platform and also to test and run their onnx models.\n\nFor more informations on Acumos see :\n`Acumos AI Linux Fondation project  <https://www.acumos.org/>`__ , his  `Acumos AI Wiki <https://wiki.acumos.org/>`_\nand his `Documentation <https://docs.acumos.org/en/latest/>`_.\n\nBased on the ``acumos`` python client, we built ``onnx4acumos`` client able to create the onnx model bundle with all the\nrequired files needed by Acumos platform.\nWhen you used ``onnx4acumos``, you can choose to on-board your onnx model directly in Acumos with or whithout micro-service\ncreation (CLI on-boarding). Or you can choose to save your Acumos model bundle locally for later manual on-boarding (Web-onboarding).\nIt that case ``onnx4acumos`` will create a ModelName Directory in which you will find the Acumos model bundle and all the\nnecessary files to test and run the Acumos onnx model bundle locally.\n\nMicro-service generation in Acumos will transform your onnx model as a serving model, based on docker, ready to be deployed.\n\nInstallation\n============\n\nThe main requirements to install ``onnx4acumos`` is to install first the following dependancies :\n\nonnx, zipp, acumos, acumos-model-runner, numpy, requests, protobuf, dill, appdirs, filelock, typing-inspect, grpcio, onnxruntime\n\nOnce it is done, you can install ``onnx4acumos`` with pip:\n\n.. code:: bash\n\n    pip install onnx4acumos\n\nremark : if you used Acumos CLIO you must used python3.6 with acumos 0.8.0 and acumos_model_runner 0.2.3\n\n.. |Build Status| image:: https://jenkins.acumos.org/buildStatus/icon?job=acumos-onnx-client-tox-verify-master\n   :target: https://jenkins.acumos.org/job/acumos-onnx-client-tox-verify-master/\n\n.. ===============LICENSE_START=======================================================\n.. Acumos CC-BY-4.0\n.. ===================================================================================\n.. Copyright (C) 2020 Orange Intellectual Property. All rights reserved.\n.. ===================================================================================\n.. This Acumos documentation file is distributed by Orange\n.. under the Creative Commons Attribution 4.0 International License (the \"License\");\n.. you may not use this file except in compliance with the License.\n.. You may obtain a copy of the License at\n..\n..      http://creativecommons.org/licenses/by/4.0\n..\n.. This file is distributed on an \"AS IS\" BASIS,\n.. WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n.. See the License for the specific language governing permissions and\n.. limitations under the License.\n.. ===============LICENSE_END=========================================================\n\n====================\nonnx4acumos Tutorial\n====================\n\nThis tutorial explains how to on-board an onnx model in an Acumos platform with microservice creation.\nIt's meant to be followed linearly, and some code snippets depend on earlier imports and objects.\nFull onnx python client examples are available in the **/acumos-onnx-client/acumos-package/onnx4acumos** \ndirectory of the `Acumos onnx client repository <https://gerrit.acumos.org/r/gitweb?p=acumos-onnx-client.git;a=tree>`__.\n\nWe assume that you have already installed ``onnx4acumos`` package.\n\n#.  `On-boarding Onnx Model on Acumos Platform`_\n#.  `How to test & run your ONNX model`_\n#.  `More Examples`_\n\nOn-boarding Onnx Model on Acumos Platform\n=========================================\n\nClone the acumos-onnx-client from gerrit\n\n.. code:: bash\n\n     git clone \"ssh://your_gerrit_login@gerrit.acumos.org:29418/acumos-onnx-client\" && scp -p -P 29418 your_gerrit_login@gerrit.acumos.org:hooks/commit-msg \"acumos-onnx-client/.git/hooks/\"\n     or\n     git clone \"ssh://your_gerrit_login@gerrit.acumos.org:29418/acumos-onnx-client\"\n\nor from `Github <https://github.com/acumos/acumos-onnx-client>`_\n\nYou will need the two following files for this tutorial :\n\n- The model located at **/acumos-onnx-client/acumos-package/onnx4acumos/OnnxModels/super_resolution_zoo.onnx**\n- A configuration file located at **/acumos-onnx-client/acumos-package/onnx4acumos/Templates/onnx4acumos.ini**\n\nThis configuration file is mandatory if you want to push your model in Acumos by CLI (CLI on-boarding). You must copy\nthis file locally if you want to onboard your own models (sometimes onnx4acumos folder name can be confused with onnx4acumos command).\n\nonnx4acumos.ini looks like :\n\n.. code:: bash\n\n        [certificates]\n        CURL_CA_BUNDLE: /etc/ssl/certs/ca-certificates.crt\n\n        [proxy]\n        https_proxy: socks5h://127.0.0.1:8886/\n        http_proxy:  socks5h://127.0.0.1:8886/\n\n        [session]\n        push_api: https://acumos/onboarding-app/v2/models\n\n**certificates :** location of acumos certificates generated during the installation,\nyou can also let this parameter empty (CURL_CA_BUNDLE:), in that case you will just\nreceive a warning.\n\n**proxy** : The proxy you used to reach your acumos platform. If you don't use proxy, you can also let this\nparameter empty (https:proxy:).\n\n**session** : The on-boarding model push API URL, available in Acumos GUI in the ON-BOARDING MODEL page.\n\nTo on-board, by CLI, the super_resolution_zoo model in Acumos platform with micro-service activation, use the following\ncommand line :\n\n\n.. code:: bash\n\n     onnx4acumos super_resolution_zoo.onnx onnx4acumos.ini -push -ms -li \"path to your license file\" -deploy\n\nIn this command line the -push parameter is used to on-board the onnx model directly\nin Acumos (CLI on-boarding). You will be prompted to enter your on-boarding token\n: onboarding token = \"your Acumos login\":\"authentication token\" (example : acumos_user:a2a6a9e8f4gbg3c147eq9g3h).\nThe \"authentication token\" can be retrieved in the ACUMOS GUI in your personal settings.\n\nThe -ms parameter is used to launch the micro-service creation in Acumos right after the on-boarding.\nIf -ms is omitted, the model will be on-boarded whithout micro-service generation.\n(don't worry, you can create the micro-service later in Acumos)).\n\nThe -li parameter is used to onboard a license file alongside your model in Acumos in order to protect the model's copyright.\nThis parameter is optional. Please refers to the licence management project in the Acumos wiki. You can find a license\ntemplate in the doc folder of the acumos4onnx repo in github.\n\nThe -deploy parameter is used to deploy the model automatically after the microservice generation (based in Jenkins server\nconfiguration set up in Acumos/SITE ADMIN/model deployment automation), by default deploy=False, so if deploy is not mentionned\nin the command line the model will not be deployed. If -deploy is added in the comand line and -ms has been ommitted,\nthe microservice will be created and deployed.\n\nTo on-board by web the super_resolution_zoo model in Acumos platform, follow the next step :\n\nFirst you have to dump the super_resolution_zoo model locally :\n\n.. code:: bash\n\n     onnx4acumos super_resolution_zoo.onnx onnx4acumos.ini -dump -f input/cat.jpg\n\nThe onnx4acumos.ini configuration file is optionnal when you dump your model bundle localy for WEB on-boarding purpose, however\nit can be provided, in the command line, in order to copy it in \"ModelName\" directory for later use (push using ModelName/ModelName_OnnxModelOnBoarding.py).\n\nThanks to the command line above a \"ModelName\" directory (\"super_resolution_zoo\" directory in our case)\nis created and it contains all the files needed to test the onnx model locally, the -f parameter is optional and\nis used to add an input data file in the ModelName_OnnxClient folder.\n\nAn Acumos model bundle is also created locally and ready to be on-boarded in Acumos manually (Web onboarding).\nThe default parameter -dump (can be omitted) allows the bundle to be saved locally.\n\nYou can find the \"ModelName\" directory contents description below :\n\n.. image:: https://gerrit.acumos.org/r/gitweb?p=acumos-onnx-client.git;a=blob_plain;f=docs/images/Capture2.png\n\nIn this directory, you cand find :\n\n- ModelName_OnnxModelOnboarding.py : Python file used to onboard a model in Acumos by CLI and/or to dump the model bundle locally.\n- Dumped Model directory(model bundle) : Directory that contains all the required files nedded by an Acumos platform.\n- Zipped model bundle(ModelName.zip) : zip file (built from Dumped Model directory) ready to be onboarded in Acumos.\n- ModelName_OnnxClient directory : Directory that contains all the necessary files to create a client/server able to test & run your model.\n\nThen The last thing to do is to drag and drop the Zipped model bundle in the \"ON-BOARDING BY WEB\" page of Acumos or use the browse function to on-board your\nmodel.\n\nHow to test & run your ONNX model\n=================================\n\nThis on-boarding client can also be used to test and run your onnx model, regardless of whether you want to on-board it or not in Acumos.\nYou have to follow the two main steps, first Launch the model runner server and then fill the skeleton client file to create the onnx client.\n\nWe assume that:\n\n- You have installed `acumos_model_runner <https://pypi.org/project/acumos-model-runner/>`__ package.\n- You have dumped the model bundle locally as explained above.\n\nWe use a client-server architecture to test and run onnx models, first you have to launch your model runner locally to create the server,\nthen you have to use a python sript as an onnx client to interact with the server.\n\nLaunch model runner server\n==========================\n\nThe local server part can be started quite simply as follows :\n\n.. code:: bash\n\n    acumos_model_runner super_resolution_zoo/dumpedModel/super_resolution_zoo\n\nThe acumos model runner will also create a swagger interface available at localhost:3330.\n\nFill skeleton client file to create the ONNX client\n===================================================\n\nYou can find the python client skeleton file desciptions below :\n\n.. image:: https://gerrit.acumos.org/r/gitweb?p=acumos-onnx-client.git;a=blob_plain;f=docs/images/Capture4.png\n\nThis python client skeleton file is available in the following folder  **super_resolution_zoo/super_resolution_zoo_OnnxClient**\n\nAll steps, in order to fill this python client skeleton, are described below. You must filled the part between two lines of \"***********\"\nYou just have to copy/paste the following code snipsets below in the right place of your skeleton file.\n\nFirst import your own needed libraries:\n=======================================\n\n.. code:: python\n\n        # Import your own needed library below\n        \"**************************************\"\n        from numpy import clip\n        import PIL\n        # torch imports\n        import torchvision.transforms as transforms\n        \"**************************************\"\n\nSecond, define your own needed methods:\n=======================================\n\n.. code:: python\n\n        # Define your own needed method below\n        \"**************************************\"\n        def to_numpy(tensor):\n             return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n        \"**************************************\"\n\nThird, define Preprocessing method:\n===================================\n\n.. code:: python\n\n    # Import the management of the Onnx data preprocessing below.\n    # The \"preProcessingOutput\" variable must contain the preprocessing result with type found in run_xx_OnnxModel method signature below\n    \"*************************************************************************************************\"\n    global img_cb, img_cr\n    img = PIL.Image.open(preProcessingInput)\n    resize = transforms.Resize([224, 224])\n    img = resize(img)\n    img.show()\n    img_ycbcr = img.convert('YCbCr')\n    img_y, img_cb, img_cr = img_ycbcr.split()\n    to_tensor = transforms.ToTensor()\n    img_y = to_tensor(img_y)\n    img_y.unsqueeze_(0)\n    preprocessingResult = to_numpy(img_y)\n    \"**************************************************************************************************\"\n\n    # \"PreProcessingOutput\" variable affectation with the preprocessing result\n\nFourth, define Postprocessing method:\n=====================================\n\n.. code:: python\n\n    # Import the management of the Onnx data postprocessing below.\n    # The \"postProcessingInput\" variable must contain the data of the Onnx model result with type found in method signature below\n    \"*************************************************************************************************\"\n    global img_cb, img_cr\n    img_out_y = output[0]\n    img_out_y = np.array((img_out_y[0] * 255.0))\n    img_out_y = clip(img_out_y,0, 255)\n    img_out_y = PIL.Image.fromarray(np.uint8(img_out_y), mode='L')\n    final_img = PIL.Image.merge(\n        \"YCbCr\", [\n        img_out_y,\n        img_cb.resize(img_out_y.size, PIL.Image.BICUBIC),\n        img_cr.resize(img_out_y.size, PIL.Image.BICUBIC),\n      ]).convert(\"RGB\")\n    f=io.BytesIO()\n    final_img.save(f,format='jpeg')\n    imageOutputData = f.getvalue()\n    final_img.show()\n    postProcessingResult = imageOutputData\n    \"*************************************************************************************************\"\n\nAnd finally :\n=============\n\nRedefine the REST URL if necessary (by default, localhost on port 3330):\n\n\n.. code:: python\n\n        restURL = \"http://localhost:3330/model/methods/run_super_resolution_zoo_OnnxModel\"\n\nThe final name of the filled skeleton ModelName_OnnxClientSkeleton.py could be  ModelName_OnnxClient.py\n(the same name without Skeleton, super_resolution_zoo_OnnxClient.py for our example).\n\nThe filled python client skeleton file can be retrieved in the acumos-onnx-client folder :\nacumos-onnx-client/acumos-package/onnx4acumos/FilledClientSkeletonsExamples/super_resolution_zoo_OnnxClient.py.\n\nRemark : To test super_resolution_zoo you must have a server X running on your local system.\n\nCommand lines\n=============\n\nYou can find all command lines to test and run onnx model super_resolution_zoo below :\n\n.. code:: bash\n\n    onnx4acumos super_resolution_zoo.onnx onnx4acumos.ini -f InputData/cat.jpg\n    acumos_model_runner super_resolution_zoo/dumpedModel/super_resolution_zoo/ ## Launch the model runner server\n    python super_resolution_zoo_OnnxClient.py -f input/cat.jpg ## Launch client and send input data\n\nsuper_resolution_zoo_Model example\n==================================\n\n.. image:: https://gerrit.acumos.org/r/gitweb?p=acumos-onnx-client.git;a=blob_plain;f=docs/images/superResoZoo.png\n\nMore Examples\n=============\n\nBelow are some additional examples.\nPost and Pre-processing methods are available in the Github folder : `onnx/models <https://github.com/onnx/models>`__\n\nGoogLeNet\n=========\n\nYou can find all command lines for GoogleNetexample below :\n\n.. image:: https://gerrit.acumos.org/r/gitweb?p=acumos-onnx-client.git;a=blob_plain;f=docs/images/Commandes.png\n\n.. code:: bash\n\n    onnx4acumos OnnxModels/GoogleNet.onnx onnx4acumos.ini -f InputData/car4.jpg\n    acumos_model_runner GoogLeNet/dumpedModel/GoogleNet/ ## Lanch the model runner server\n    cd  GoogLeNet/GoogLeNet_OnnxClient\n    python GoogLeNet_OnnxClient.py -f input/car4.jpg ## Launch client and send input data\n\n.. image:: https://gerrit.acumos.org/r/gitweb?p=acumos-onnx-client.git;a=blob_plain;f=docs/images/bvlc.png\n\nIn our example above :\n\n.. code:: bash\n\n    python GoogLeNet_OnnxClient.py -f input/car4.jpg\n    python GoogLeNet_OnnxClient.py -f input/BM4.jpeg\n    python GoogLeNet_OnnxClient.py -f input/espresso.jpeg\n    python GoogLeNet_OnnxClient.py -f input/cat.jpg\n    python GoogLeNet_OnnxClient.py -f input/pesan3.jpg\n\nEmotion Ferplus Model example\n=============================\n\n.. image:: https://gerrit.acumos.org/r/gitweb?p=acumos-onnx-client.git;a=blob_plain;f=docs/images/emotionFerPlus.png\n\n.. code:: bash\n\n    python emotion_ferplus_model_OnnxClient.py -f input/angryMan.png\n    python emotion_ferplus_model_OnnxClient.py -f input/sadness.png\n    python emotion_ferplus_model_OnnxClient.py -f input/happy.jpg\n    python emotion_ferplus_model_OnnxClient.py -f input/joker.jpg\n\nThat's all  :-)\n===============\n\n.. ===============LICENSE_START=======================================================\n.. Acumos CC-BY-4.0\n.. ===================================================================================\n.. Copyright (C) 2020 Orange Intellectual Property. All rights reserved.\n.. ===================================================================================\n.. This Acumos documentation file is distributed by Orange\n.. under the Creative Commons Attribution 4.0 International License (the \"License\");\n.. you may not use this file except in compliance with the License.\n.. You may obtain a copy of the License at\n..\n..      http://creativecommons.org/licenses/by/4.0\n..\n.. This file is distributed on an \"AS IS\" BASIS,\n.. WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n.. See the License for the specific language governing permissions and\n.. limitations under the License.\n.. ===============LICENSE_END=========================================================\n\n================================\nAcumos ONNX Client Release Notes\n================================\n\nv1.0.5 30 June 2021\n===================\n\n* Minor documentation change `ACUMOS-4337 <https://jira.acumos.org/browse/ACUMOS-4337>`_\n\nv1.0.4 08 June 2021\n===================\n\n* Fix failed with onnx new version 1_9_0 `ACUMOS-4337 <https://jira.acumos.org/browse/ACUMOS-4337>`_\n\nv1.0.3, 27 April 2021\n=====================\n\n* Adding deploy management `ACUMOS-4308 <https://jira.acumos.org/browse/ACUMOS-4308>`_\n* Adding licence file management `ACUMOS-4319 <https://jira.acumos.org/browse/ACUMOS-4319>`_\n* Avoid the use of configuration file when model bundle is dumped `ACUMOS-4317 <https://jira.acumos.org/browse/ACUMOS-4317>`_\n* fix typo \"Exemples\" in folder `ACUMOS-4318 <https://jira.acumos.org/browse/ACUMOS-4318>`_\n* fix typo \"and/\" in index file `ACUMOS-4320 <https://jira.acumos.org/browse/ACUMOS-4320>`_\n\nv1.0.0, 22 January 2021\n=======================\n\n* Creation of onnx4acumos 'ACUMOS-3101 <https://jira.acumos.org/browse/ACUMOS-3101>'_\n\n========================\n\n.. ===============LICENSE_START=======================================================\n.. Acumos CC-BY-4.0\n.. ===================================================================================\n.. Copyright (C) 2020 Orange Intellectual Property. All rights reserved.\n.. ===================================================================================\n.. This Acumos documentation file is distributed by Orange\n.. under the Creative Commons Attribution 4.0 International License (the \"License\");\n.. you may not use this file except in compliance with the License.\n.. You may obtain a copy of the License at\n..\n..      http://creativecommons.org/licenses/by/4.0\n..\n.. This file is distributed on an \"AS IS\" BASIS,\n.. WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n.. See the License for the specific language governing permissions and\n.. limitations under the License.\n.. ===============LICENSE_END=========================================================\n\n==================================\nAcumos onnx Client Developer Guide\n==================================\n\nTesting\n=======\n\nWe use a combination of ``tox``, ``pytest``, and ``flake8`` to test\n``acumos_onnx_client``. Code which is not PEP8 compliant (aside from E501) will be\nconsidered a failing test. You can use tools like ``autopep8`` to\n“clean” your code as follows:\n\n.. code:: bash\n\n    $ pip install autopep8\n    $ cd acumos-onnx-client\n    $ autopep8 -r --in-place --ignore E501 acumos_onnx_client/ testing/ examples/\n\nRun tox directly:\n\n.. code:: bash\n\n    $ cd acumos-onnx-client\n    $ export WORKSPACE=$(pwd)  # env var normally provided by Jenkins\n    $ tox\n\nYou can also specify certain tox environments to test:\n\n.. code:: bash\n\n    $ tox -e py36  # only test against Python 3.6\n    $ tox -e flake8  # only lint code\n\nA set of integration test is also available in ``acumos-package/testing/integration_tests``.\nTo run those, use ``acumos-package/testing/tox-integration.ini`` as tox config (-c flag),\nonboarding tests will be ran with python 3.6 to 3.9.\nYou will need to set your user credentials and platform configuration in ``tox-integration.ini``.\n\n.. code:: bash\n\n    $ tox -c acumos-package/testing/integration_tests\n\n\nPackaging\n=========\n\nThe RST files in the docs/ directory are used to publish HTML pages to\nReadTheDocs.io and to build the package long description in setup.py.\nThe symlink from the subdirectory acumos-package to the docs/ directory\nis required for the Python packaging tools.  Those tools build a source\ndistribution from files in the package root, the directory acumos-package.\nThe MANIFEST.in file directs the tools to pull files from directory docs/,\nand the symlink makes it possible because the tools only look within the\npackage root.\n\n\n",
    "description_content_type": "text/x-rst",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://gerrit.acumos.org/r/gitweb?p=acumos-onnx-client.git",
    "keywords": "acumos machine learning model modeling artificial intelligence ml ai onnx",
    "license": "Apache License 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "onnx4acumos",
    "package_url": "https://pypi.org/project/onnx4acumos/",
    "platform": "",
    "project_url": "https://pypi.org/project/onnx4acumos/",
    "project_urls": {
      "Homepage": "https://gerrit.acumos.org/r/gitweb?p=acumos-onnx-client.git"
    },
    "release_url": "https://pypi.org/project/onnx4acumos/1.0.5/",
    "requires_dist": [
      "protobuf",
      "requests",
      "numpy",
      "configparser",
      "dill",
      "appdirs",
      "filelock",
      "grpcio",
      "zipp",
      "acumos",
      "acumos-model-runner",
      "onnx",
      "onnxruntime",
      "typing-inspect"
    ],
    "requires_python": ">=3.6, <3.9",
    "summary": "Acumos ONNX client library for pushing Onnx models in Acumos",
    "version": "1.0.5",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12039552,
  "releases": {
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "91ebe1a54c4cb4d76cd70deb1d8ed75d046b0ba6feed7198e023f558aa7684d8",
          "md5": "1ac7691674ad1674ec320412c6df9fc5",
          "sha256": "2d7c2ccb8a9fa09ef236376dc85c6c708a9438e67e30ed019a6de52298625de3"
        },
        "downloads": -1,
        "filename": "onnx4acumos-1.0.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "1ac7691674ad1674ec320412c6df9fc5",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": ">=3.6, <3.9",
        "size": 18095,
        "upload_time": "2021-01-26T20:45:34",
        "upload_time_iso_8601": "2021-01-26T20:45:34.192209Z",
        "url": "https://files.pythonhosted.org/packages/91/eb/e1a54c4cb4d76cd70deb1d8ed75d046b0ba6feed7198e023f558aa7684d8/onnx4acumos-1.0.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a2ccca0b7290ebe14ed15ed030810d822422bf904c4c12f558a1dfb1362c1c76",
          "md5": "d9738cdf40758ebd9a8e0051ac9e28aa",
          "sha256": "8afb8eab4610457e5628cd9bb267d6fbee4acdf8594f0af14160bfbda2294a65"
        },
        "downloads": -1,
        "filename": "onnx4acumos-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "d9738cdf40758ebd9a8e0051ac9e28aa",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6, <3.9",
        "size": 25029,
        "upload_time": "2021-01-26T20:45:35",
        "upload_time_iso_8601": "2021-01-26T20:45:35.489511Z",
        "url": "https://files.pythonhosted.org/packages/a2/cc/ca0b7290ebe14ed15ed030810d822422bf904c4c12f558a1dfb1362c1c76/onnx4acumos-1.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0954f916164e87973082700bc218f33bf942b0606a9f829787703e2fd7d4c0f7",
          "md5": "ebe31e3b84a343022ce9d677f609ee1d",
          "sha256": "d3b4fdd2fa339358fa392b9ef78554db034f0c0a55a843f54e1db1535aa211e8"
        },
        "downloads": -1,
        "filename": "onnx4acumos-1.0.5-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ebe31e3b84a343022ce9d677f609ee1d",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": ">=3.6, <3.9",
        "size": 19468,
        "upload_time": "2021-11-16T16:55:13",
        "upload_time_iso_8601": "2021-11-16T16:55:13.963839Z",
        "url": "https://files.pythonhosted.org/packages/09/54/f916164e87973082700bc218f33bf942b0606a9f829787703e2fd7d4c0f7/onnx4acumos-1.0.5-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fe031b906d6ca81ebb447bff6d7a5c791969c6dca30756481c55cb64de497115",
          "md5": "ef96db0c06ffbc61261c61571c7dbdf9",
          "sha256": "e1e986f98ae9dfcf613f45ef1186f7107c6e93752fc9df0f8045a9f04b99ab50"
        },
        "downloads": -1,
        "filename": "onnx4acumos-1.0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "ef96db0c06ffbc61261c61571c7dbdf9",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6, <3.9",
        "size": 27027,
        "upload_time": "2021-11-16T16:55:15",
        "upload_time_iso_8601": "2021-11-16T16:55:15.982319Z",
        "url": "https://files.pythonhosted.org/packages/fe/03/1b906d6ca81ebb447bff6d7a5c791969c6dca30756481c55cb64de497115/onnx4acumos-1.0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "0954f916164e87973082700bc218f33bf942b0606a9f829787703e2fd7d4c0f7",
        "md5": "ebe31e3b84a343022ce9d677f609ee1d",
        "sha256": "d3b4fdd2fa339358fa392b9ef78554db034f0c0a55a843f54e1db1535aa211e8"
      },
      "downloads": -1,
      "filename": "onnx4acumos-1.0.5-py2.py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "ebe31e3b84a343022ce9d677f609ee1d",
      "packagetype": "bdist_wheel",
      "python_version": "py2.py3",
      "requires_python": ">=3.6, <3.9",
      "size": 19468,
      "upload_time": "2021-11-16T16:55:13",
      "upload_time_iso_8601": "2021-11-16T16:55:13.963839Z",
      "url": "https://files.pythonhosted.org/packages/09/54/f916164e87973082700bc218f33bf942b0606a9f829787703e2fd7d4c0f7/onnx4acumos-1.0.5-py2.py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "fe031b906d6ca81ebb447bff6d7a5c791969c6dca30756481c55cb64de497115",
        "md5": "ef96db0c06ffbc61261c61571c7dbdf9",
        "sha256": "e1e986f98ae9dfcf613f45ef1186f7107c6e93752fc9df0f8045a9f04b99ab50"
      },
      "downloads": -1,
      "filename": "onnx4acumos-1.0.5.tar.gz",
      "has_sig": false,
      "md5_digest": "ef96db0c06ffbc61261c61571c7dbdf9",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6, <3.9",
      "size": 27027,
      "upload_time": "2021-11-16T16:55:15",
      "upload_time_iso_8601": "2021-11-16T16:55:15.982319Z",
      "url": "https://files.pythonhosted.org/packages/fe/03/1b906d6ca81ebb447bff6d7a5c791969c6dca30756481c55cb64de497115/onnx4acumos-1.0.5.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}