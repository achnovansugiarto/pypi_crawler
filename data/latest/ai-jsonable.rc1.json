{
  "info": {
    "author": "Duncan Blythe",
    "author_email": "duncanblythe@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Topic :: Scientific/Engineering",
      "Topic :: Scientific/Engineering :: Artificial Intelligence"
    ],
    "description": "# AI-JSONABLE\n\nParameter and settings tracking in Python3 for jsonable output.\n\n## Installation\n\n```Â \npip3 install aijson\n```\n\n## Philosophy\n\nSaving and serializing in Python3 is supported by, for instance, `pickle` and `dill`. However, we believe that logging parameters in a Pythonic and flexible way is undersupported. Once a model or experiment has been executed, it should be easy to inspect which parameters were used. If the experiment is to be rerun or modified, it should be possible to do this with some simple overrides.\n\n## Minimum working example\n\nA minimal example is in `example/config.py`, which requires PyTorch and imports from `example/themod.py`.\n\nTo install do:\n\n```\npip3 install torch\n```\n\n`example/themod.py`:\n\n```python\nfrom aijson.decorate import aijson\nimport torch\n\n\n@aijson\nclass MyPyTorchModel(torch.nn.Module):\n    def __init__(self, n_layers, n_hidden, n_input):\n        super().__init__()\n        self.rnn = torch.nn.GRU(n_hidden, n_hidden, n_layers)\n        self.embed = torch.nn.Embedding(n_input, n_hidden)\n\n\n@aijson\nclass MyCompose:\n    def __init__(self, functions):\n        self.functions = functions\n\n    def __call__(self, x):\n        for f in self.functions:\n            x = f(x)\n        return x\n\n```\n\n`example/config.py`:\n\n```python\nimport json\nfrom example.themod import MyPyTorchModel, MyCompose\nfrom aijson import aijson, logging_context\nfrom torch.nn import GRU\n\nwith logging_context() as lc:\n    m = MyPyTorchModel(n_layers=1, n_hidden=512, n_input=64)\n    rnn = aijson(GRU)(\n        input_size=2,\n        hidden_size=5,\n    )\n    n = MyCompose(functions=[m, m, 2, rnn])\n\n    with open('mymodel.ai.json', 'w') as f:\n        json.dump(lc, f)\n```\n\nIn `example/themod.py` you can see that classes (and functions) whose parameter settings should be tracked are decorated with `@aijson`. Predefined functions (as in `torch.nn.XXX`) are similarly wrapped with `aijson(...)`. To create a single JSON-able logging instance in a Python dictionary, one uses the `logging_context` context manager. Having wired the model together in Python, all parameters chosen are recursively saved in the dictionary `lc`.\n\nTo run do:\n\n```\npython3 -m example.config\n```\n\nThis should give output in `mymodel.ai.json`, which should look like this:\n\n```json\n{\n  \"var0\": {\n    \"module\": \"example.themod\",\n    \"caller\": \"MyPyTorchModel\",\n    \"kwargs\": {\n      \"n_layers\": 1,\n      \"n_hidden\": 512,\n      \"n_input\": 64\n    }\n  },\n  \"var1\": {\n    \"module\": \"torch.nn.modules.rnn\",\n    \"caller\": \"GRU\",\n    \"kwargs\": {\n      \"input_size\": 2,\n      \"hidden_size\": 5\n    }\n  },\n  \"var2\": {\n    \"module\": \"example.themod\",\n    \"caller\": \"MyCompose\",\n    \"kwargs\": {\n      \"functions\": [\n        \"$var0\",\n        \"$var0\",\n        2,\n        \"$var1\"\n      ]\n    }\n  }\n}\n```\n\nThe JSON output is a dictionary representation of the build tree/ graph. If a parameter is JSON-able, then it will be directly saved in the `kwargs` subdictionary. Otherwise, it will be defined recursively. Hence the underlying assumption is that all parameters are either JSON-able or are Python objects whose parameters are JSON-able or are Python objects..., and so on. The base/ trunk node is the variable with highest index.\n\nOnce this output has been produced, it's possible to rebuild the object using the same parameters in the following way:\n\n```python\nimport json\nfrom aijson import build\n\nwith open('mymodel.ai.json') as f:\n    cf = json.load(f)\n    \nrebuilt = build(cf)\n```\n\nThis means that one doesn't need the code in `example/config.py` but only the items imported there (i.e. whatever is in `example/themod.py` and `torch` etc.).\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/blythed/aijson",
    "keywords": "",
    "license": "MIT License",
    "maintainer": "",
    "maintainer_email": "",
    "name": "ai-jsonable",
    "package_url": "https://pypi.org/project/ai-jsonable/",
    "platform": null,
    "project_url": "https://pypi.org/project/ai-jsonable/",
    "project_urls": {
      "Homepage": "https://github.com/blythed/aijson"
    },
    "release_url": "https://pypi.org/project/ai-jsonable/0.0.1/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "Tracking model parameters and settings for AI using JSON.",
    "version": "0.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16018742,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4f38635bc62c80288d975adb2677dde46d9563fbb995b203bf68625cb17b443c",
          "md5": "c841f82c535be4ca58275d8c06c24a6b",
          "sha256": "5b60c3b57b0157eb57a632d98ef2d20d6072a3b7028dc6f0d7b8662f970e5f52"
        },
        "downloads": -1,
        "filename": "ai-jsonable-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "c841f82c535be4ca58275d8c06c24a6b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 6362,
        "upload_time": "2022-10-19T09:54:29",
        "upload_time_iso_8601": "2022-10-19T09:54:29.831518Z",
        "url": "https://files.pythonhosted.org/packages/4f/38/635bc62c80288d975adb2677dde46d9563fbb995b203bf68625cb17b443c/ai-jsonable-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "4f38635bc62c80288d975adb2677dde46d9563fbb995b203bf68625cb17b443c",
        "md5": "c841f82c535be4ca58275d8c06c24a6b",
        "sha256": "5b60c3b57b0157eb57a632d98ef2d20d6072a3b7028dc6f0d7b8662f970e5f52"
      },
      "downloads": -1,
      "filename": "ai-jsonable-0.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "c841f82c535be4ca58275d8c06c24a6b",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 6362,
      "upload_time": "2022-10-19T09:54:29",
      "upload_time_iso_8601": "2022-10-19T09:54:29.831518Z",
      "url": "https://files.pythonhosted.org/packages/4f/38/635bc62c80288d975adb2677dde46d9563fbb995b203bf68625cb17b443c/ai-jsonable-0.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}