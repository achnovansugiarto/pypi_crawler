{
  "info": {
    "author": "Hashmap, Inc",
    "author_email": "accelerators@hashmapinc.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "<!---\n# Modifications Â© 2020 Hashmap, Inc\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n-->\n# cloudy_sql\n\n## Snowflake Support\nThe cloudy_sql is an Ipython Magics library and pandas extension that currently supports: \n- a Magics function that allows users to easily execute SQL Queries in Snowflake\n- writing to an existing Snowflake table from a pandas dataframe\n- creating a new Snowflake table from a pandas dataframe\n## How To Use cloudy_sql\n\n**Installation**\n\n`pip install cloudy-sql`\n\n**Configuration** \n\nUpon installation, open a jupyter notebook and run the following cell.\n```python\n%load_ext cloudy_sql\n```\nAfter you run the cell, a configuration file will be created in your HOME directory.\nThe path to the configuration file is: `$HOME/.cloudy_sql/configuration_profiles.yml`\n\nFor Windows user: use $USERPROFILE instead of $HOME variable\n\nThe configuration file is a YAML file with the following format\n```yaml\nprofiles:\n  snowflake:\n    user: <your snowflake username>\n    pass: <your snowflake password>\n    acct: <your snowflake account>\n    role: <your snowflake role>\n    warehouse: <your snowflake warehouse>\n    database: <your snowflake database>\n    schema: <your snowflake schema>\n```\nThe user, pass, acct, database, schema, values all should be filled in with your desired Snowflake credentials and connection details. The variables in this\nfile serve as default arguments when calling a cloudy_sql method. Role and warehouse can be filled in as well, but they are optional arguments when connecting to Snowflake.\n\n\n## API\nThe intent has been to keep the API as simple as possible by minimally extending the pandas and IPython Magics APIs.\n\n### Optional Arguments\nThere are two methods for passing optional arguments into a method.\n1. The configuration file\n2. Directly pass in the arguments when calling the method\n\nThe variables saved in the configuration file serve as default arguments for the methods to use.\nHowever, you tell the method to use different credentials by passing in arguments directly. The method will use the passed in arguments \ninstead of the default arguments saved in `configuration_profiles.yml`. \n\nFor example, if I had the `database` variable saved in the `configuration_profiles.yml` as `database_1`, but passed in `database = database_2` directly into the method,\nthe method would use `database_2` instead of `database_1`. \n\nHowever, if I choose to not directly pass a `database` argument in, the method will use the \n`database_1` because it is the default. The passed in arguments take priority over the default variables saved in `configuration_profiles.yml`.\n### IPython Magics\n#### %%sql_to_snowflake\nIPython Cell Magic to seamlessly connect to Snowflake and run a query in Snowflake and return a pandas DataFrame as the result.\n```\n%%sql_to_snowflake [<destination_var>] [--username <snowflake_username>]\n                   [--password <snowflake_password>] [--account <snowflake_account>]\n                   [--role <snowflake_role>] [--warehouse <snowflake_warehouse>]\n<SQL query>\n```\n#### Parameters\n    * <destination_var> (Optional [IPython line argument]): \n        Variable to store the query results. If none is given, the magic will return\n        the first 10 rows of the pandas DataFrame if applicable.\n\n    * --params <params> (Optional [IPython line argument]):\n        Parameters to be used in the SQL Query. Params must be passed in as a \n        dictionary string in the format {\"param_name\": \"param_value\"} or reference a \n        dictionary string defined in a previous cell. The use of the parameter in the \n        query should be indicated with {{param_name}}.\n\n    * --username <username> (Optional [IPython line argument]):\n        If provided, the called method will connect to Snowflake with this username \n        instead of the default in the configuration file.\n    \n    * --password <password> (Optional [IPython line argument]):\n        If provided, the called method will connect to Snowflake with this password\n        instead of the default in the configuration file.\n\n    * --account <account> (Optional [IPython line argument]):\n        If provided, the called method will connect to Snowflake with this account \n        instead of the default in the configuration file.\n\n    * --role <role> (Optional [IPython line argument]):\n        If provided, the called method will connect to Snowflake with this role \n        instead of the default in the configuration file.\n\n    * --warehouse <warehouse> (Optional [IPython line argument]):\n        If provided, the called method will use this warehouse instead of the \n        default in the configuration file.\n\n### write_snowflake\n```python\npd.DataFrame.cloudy_sql.write_snowflake(table: str, \n                                        database: str = None, \n                                        schema: str = None, \n                                        overwrite: bool = False, \n                                        username: str = None,\n                                        password: str = None, \n                                        account: str = None, \n                                        role: str = None, \n                                        warehouse: str = None\n                                       )\n```\nThis method writes to a Snowflake table and informs you on success. This method works when writing to either an existing Snowflake table or a previously non-existing Snowflake table. \nIf the table that you provide does not exist, this method creates a new Snowflake table and writes to it. If the table already exists, the DataFrame data is \nappended to the existing table by default. If you would like to replace the table with the pandas DataFrame\nset `overwrite = True` when calling the method. You can configure your `database` and `schema` default values in the configuration file. You can also pass them in directly when calling the method.\nThe passed in values are used instead of the defaults in the configuration file.\n\nThe goal of this method is to be used in tandem with `%%sql_to_snowflake`. You use the magic function to run your SQL query\nthat returns a pandas DataFrame. Then, you can transform the DataFrame and write the DataFrame to a Snowflake using this method.\n\n\n## Examples\n\n__Using `%%sql_to_snowflake` magic and `write_snowflake` method__\n```\nIn [1]:  %load_ext cloudy_sql\n\nIn [2]:  %%sql_to_snowflake df \n         SELECT * from db.schema.table\n         \n         Query successfully ran and results were stored to the 'df' destination variable.\n\nIn [3]:  df.head()\nOut[3]:  \n         CUSTOMER_ID\tFIRST_NAME\tLAST_NAME\tFIRST_ORDER_DATE\tMOST_RECENT_ORDER_DATE\tNUMBER_OF_ORDERS\n     0   \t   1\t   Michael\t       P.\t      2018-01-01\t            2018-02-10\t               2\n     1   \t   2\t     Shawn\t       M.\t      2018-01-11\t            2018-01-11\t               1\n     2   \t   3\t  Kathleen\t       P.\t      2018-01-02\t            2018-03-11\t               3\n     3   \t   4\t     Jimmy\t       C.\t            None\t                  None\t               0\n     4   \t   5\t Katherine\t       R.\t            None\t                  None\t               0\n     \nIn [4]: df.cloudy_sql.write_snowflake(table=\"test_cloudy_sql\")\n\n        Successfully wrote to the test_cloudy_sql Snowflake table\n\nIn [5]: %%sql_to_snowflake\n        drop table if exists db.schema.test_cloudy_sql\n        \n        Successfully ran SQL Query in Snowflake\n        \nIn [6]: %close_connection\n```\nThe above example runs a SQL query with `%%sql_to_snowflake` and saves the results as a pandas DataFrame by passing\nin the destination variable `df`. The example then shows how to easily write that `df` to a Snowflake table `In [4]`. Also, the created table is dropped `In [5]`.\nThe connection is then closed by calling the `%close_connection` magic `In [6]`.\n\n__Using `%%sql_to_snowflake` magic with the `--params` inline argument__\n```\nIn [1]:  %load_ext cloudy_sql\n\nIn [2]:  parameters = {'firstname': 'Michael', 'orders': '2'}\n         \nIn [3]:  %%sql_to_snowflake --params $parameters\n         SELECT * from db.schema.table\n         WHERE FIRST_NAME = {{firstname}} and NUMBER_OF_ORDERS = {{orders}}\nOut[3]:  \n         CUSTOMER_ID\tFIRST_NAME\tLAST_NAME\tFIRST_ORDER_DATE\tMOST_RECENT_ORDER_DATE\tNUMBER_OF_ORDERS\n     0   \t   1\t   Michael\t       P.\t      2018-01-01\t            2018-02-10\t               2\n     \n```\nThe above example runs a SQL query with passed-in variables. The variables are used directly in the SQL query by placing each one inside `{{  }}`. A dictionary string `parameters` is passed in when the \nmagic is called by including a `--params` inline argument and placing a `$` to reference the dictionary string creating in the previous cell. There is no specified `destination variable`. Therefore, the magic prints out the resulting pandas dataframe.\n\n__Using `%%sql_to_snowflake` magic with the `--params` inline argument__\n```\nIn [1]:  %load_ext cloudy_sql\n         \nIn [2]:  %%sql_to_snowflake --params {'firstname': 'Michael', 'orders': '2'}\n         SELECT * from db.schema.table\n         WHERE FIRST_NAME = {{firstname}} and NUMBER_OF_ORDERS = {{orders}}\nOut[2]:  \n         CUSTOMER_ID\tFIRST_NAME\tLAST_NAME\tFIRST_ORDER_DATE\tMOST_RECENT_ORDER_DATE\tNUMBER_OF_ORDERS\n     0   \t   1\t   Michael\t       P.\t      2018-01-01\t            2018-02-10\t               2\n     \n```\nThis example directly passes in the dictionary string when calling the `--params` inline argument.",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/hashmapinc/sales-and-marketing/pocs/sam-kohlleffel-poc/pandas-cloudy-extension",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "cloudy-sql",
    "package_url": "https://pypi.org/project/cloudy-sql/",
    "platform": "",
    "project_url": "https://pypi.org/project/cloudy-sql/",
    "project_urls": {
      "Homepage": "https://github.com/hashmapinc/sales-and-marketing/pocs/sam-kohlleffel-poc/pandas-cloudy-extension"
    },
    "release_url": "https://pypi.org/project/cloudy-sql/0.0.0.4/",
    "requires_dist": null,
    "requires_python": ">=3.7",
    "summary": "A Jupyter magics extension designed for seamless interaction with Snowflake",
    "version": "0.0.0.4",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 9175145,
  "releases": {
    "0.0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e3b4835498228d5ff202c8cd8b5ca8890bd777b722a00826383f86283187ed13",
          "md5": "58bd48a05cee3f6f5d1edc8f23f9fd07",
          "sha256": "26ec2a8224a410a51b5aac71ada20bac2ae8e478f88e4c61ee7d348fa934c2af"
        },
        "downloads": -1,
        "filename": "cloudy_sql-0.0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "58bd48a05cee3f6f5d1edc8f23f9fd07",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 3485,
        "upload_time": "2021-01-08T15:10:38",
        "upload_time_iso_8601": "2021-01-08T15:10:38.127835Z",
        "url": "https://files.pythonhosted.org/packages/e3/b4/835498228d5ff202c8cd8b5ca8890bd777b722a00826383f86283187ed13/cloudy_sql-0.0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "338dc8566a2ac0b9606bbd78240cf96a3d0e2debd082dd89e05bf6e0d890273d",
          "md5": "48d431f8f7f2cf932a2c12dc3dbbac6b",
          "sha256": "e5aedac5ab085381e2ed2b30656da51fef466e61dcd2ef3f02753130266c1b54"
        },
        "downloads": -1,
        "filename": "cloudy_sql-0.0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "48d431f8f7f2cf932a2c12dc3dbbac6b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 11858,
        "upload_time": "2021-01-19T16:15:21",
        "upload_time_iso_8601": "2021-01-19T16:15:21.392258Z",
        "url": "https://files.pythonhosted.org/packages/33/8d/c8566a2ac0b9606bbd78240cf96a3d0e2debd082dd89e05bf6e0d890273d/cloudy_sql-0.0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3ff324c4de71d80ca1dfdeb3ce04fb7fddac92fe643df110df0915f0089fa84f",
          "md5": "8f1b7b81270bf6f745dfb8b4a5d0dab8",
          "sha256": "31ff045f454007d5f63df214a264a54ef816edc6aa5588475ece64ab4b690082"
        },
        "downloads": -1,
        "filename": "cloudy_sql-0.0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "8f1b7b81270bf6f745dfb8b4a5d0dab8",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 12059,
        "upload_time": "2021-01-19T19:53:25",
        "upload_time_iso_8601": "2021-01-19T19:53:25.423825Z",
        "url": "https://files.pythonhosted.org/packages/3f/f3/24c4de71d80ca1dfdeb3ce04fb7fddac92fe643df110df0915f0089fa84f/cloudy_sql-0.0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "3ff324c4de71d80ca1dfdeb3ce04fb7fddac92fe643df110df0915f0089fa84f",
        "md5": "8f1b7b81270bf6f745dfb8b4a5d0dab8",
        "sha256": "31ff045f454007d5f63df214a264a54ef816edc6aa5588475ece64ab4b690082"
      },
      "downloads": -1,
      "filename": "cloudy_sql-0.0.0.4.tar.gz",
      "has_sig": false,
      "md5_digest": "8f1b7b81270bf6f745dfb8b4a5d0dab8",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 12059,
      "upload_time": "2021-01-19T19:53:25",
      "upload_time_iso_8601": "2021-01-19T19:53:25.423825Z",
      "url": "https://files.pythonhosted.org/packages/3f/f3/24c4de71d80ca1dfdeb3ce04fb7fddac92fe643df110df0915f0089fa84f/cloudy_sql-0.0.0.4.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}