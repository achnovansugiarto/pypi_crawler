{
  "info": {
    "author": "",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Intended Audience :: Developers",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved",
      "Operating System :: MacOS",
      "Operating System :: Microsoft :: Windows",
      "Operating System :: POSIX",
      "Operating System :: Unix",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Programming Language :: Python :: Implementation :: CPython",
      "Topic :: Scientific/Engineering",
      "Topic :: Software Development"
    ],
    "description": "# sklearn-numba-dpex\n\nExperimental plugin for scikit-learn to be able to run (some estimators) on\nIntel GPUs via [numba-dpex](https://github.com/IntelPython/numba-dpex).\n\nDISCLAIMER: this is work in progres, do not expect this repo to be in a\nworkable state at the moment.\n\nThis requires working with the following branch of scikit-learn which is itself\nnot yet in a working state at the moment:\n\n- `wip-engines` branch on https://github.com/ogrisel/scikit-learn \n\n## Getting started:\n\n### Step 1: Installing a `numba_dpex` environment\n\nGetting started requires a working environment for using `numba_dpex`. Currently a [conda install](#using-a-conda-installation) or a [docker image](#using-the-docker-image) are available. The most stable and recommended environment at the moment is using the docker image.\n\n#### Using a conda installation\n\nTODO: update the instructions to install everything from non-dev conda packages\nonce available.\n\n##### A conda env with Intel Python libraries (1/2)\n\nLet's create a dedicated conda env with the development versions\nof the Intel Python libraries (from the `dppy/label/dev` channel).\n\n```\nconda create -n dppy-dev dpnp numba cython spirv-tools -c dppy/label/dev -c intel --override-channels\n```\n\nLet's activate it and introspect the available hardware:\n\n```\nconda activate dppy-dev\npython -c \"import dpctl; print(dpctl.get_devices())\"\n```\n\nIf you do not not see any CPU device, try again with the following after\nsetting the `SYCL_ENABLE_HOST_DEVICE=1` environment variable, for instance:\n\n```\nSYCL_ENABLE_HOST_DEVICE=1 python -c \"import dpctl; print(dpctl.get_devices())\"\n```\n\nIf you have an Intel GPU and it is not detected, check the\nfollowing steps:\n\n- Make sure you have installed the [latest GPU drivers](https://dgpu-docs.intel.com/installation-guides/index.html)\n\n- On Linux, check that the i915 driver is properly loaded:\n\n  ```\n  $ lspci -nnk | grep i915\n        Kernel driver in use: i915\n        Kernel modules: i915\n  ```\n\n- On Linux, check that the current user is in the `render` group, for instance:\n\n  ```\n  $ groups\n  myuser adm cdrom sudo dip plugdev render lpadmin lxd sambashare docker\n  ```\n\n  If not, add it with `sudo adduser $USER render`, logout and log back in, and check\n  again.\n\n- Install recent versions of the [runtime libraries](https://github.com/intel/compute-runtime/releases) (not yet available\n  as conda packages)\n\nFor more in-depth information, you can refer to the [guides for system configuration for Intel hardware and software](https://www.intel.com/content/www/us/en/developer/articles/system-requirements/intel-oneapi-dpcpp-system-requirements.html) and to the discussions in this github issue https://github.com/IntelPython/dpnp/issues/1149\n\n\nThe `dpctl.lsplatform()` can also list version informations on your SYCL\nruntime environment:\n\n```\npython -c \"import dpctl; dpctl.lsplatform()\"\n```\n\n##### Install numba-dpex from source (2/2)\n\nInstall and activate the Intel oneAPI DPC++ compiler shipped with the [Intel oneAPI base toolkit](https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit-download.html).\n\nFor instance, in Ubuntu, once the apt repo has been configured:\n\n```\nsudo apt update\nsudo apt install intel-basekit\nsource /opt/intel/oneapi/compiler/latest/env/vars.sh\n```\n\nEnsure that the `icx` command can be found in the PATH with the command:\n\n```\nwhich icx\n```\n\nInstall numba-dpex in the same conda env as previously:\n\n```\ngit clone https://github.com/IntelPython/numba-dpex/\ncd numba-dpex\npip install -e . --no-build-isolation\n```\n\nImportant: in order to use `numba-dpex`, the `llvm-spirv` compiler is required\nto be in the PATH. This can be achieved with:\n\n```\n$ export PATH=/opt/intel/oneapi/compiler/latest/linux/bin-llvm:$PATH\n```\n\n#### Using the docker image\n\nA docker image is available and provides an up-to-date, one-command install environment. You can either build it from the [Dockerfile](./docker/Dockerfile) :\n\n```\n$ cd docker\n$ docker build . -t my_tag\n```\n\nor pull the docker image from [this publicly available repository](https://hub.docker.com/repository/docker/jjerphan/numba_dpex_dev):\n\n```\n$ docker pull jjerphan/numba_dpex_dev:latest\n```\n\nRun the container in interactive mode with your favorite docker flags, for example:\n\n```\n$ docker run --name my_container_name -it -v /my/host/volume/:/mounted/volume --device=/dev/dri my_tag\n```\n\nwhere `my_tag` would be `jjerphan/numba_dpex_dev:latest` if you pulled from the repository.\n\nâš  The flag `--device=/dev/dri` is **mandatory** to enable the gpu within the container, also the user starting the `docker run` command must have access to the gpu, e.g. by being a member of the `render` group.\n\nUnless using the flag `--rm` when starting a container, you can restart it after it was exited, with the command:\n\n```\nsudo docker start -a -i my_container_name\n```\n\nOnce inside the container, you can check that the environment works: the command\n\n```\npython -c \"import dpctl; print(dpctl.get_devices())\"\n```\n\nwill introspect the available hardware, and should display working `opencl` cpu and gpu devices, and `level_zero` gpu devices.\n\n### Step 2: install the `wip-engines` branch of scikit-learn\n\nOnce you have loaded into a `numba_dpex` development environment, following one of the two previous guides, follow those instructions:\n\n```\ngit clone https://github.com/ogrisel/scikit-learn\ncd scikit-learn\ngit checkout wip-engines\npip install -e . --no-build-isolation\ncd ..\n```\n\n### Step 3: install this plugin\n\n```\ngit clone https://github.com/soda-inria/sklearn-numba-dpex\ncd sklearn-numba-dpex\npip install -e . --no-build-isolation\n```\n\n## Intended usage\n\nSee the `sklearn_numba_dpex/tests` folder for example usage.\n\nTODO: write some doc here instead.\n\n### Running the benchmarks\n\nRepeat the pip installation step exposed in [step 3](#step-3-install-this-plugin) with the following edit:\n\n```\npip install -e .[benchmark] --no-build-isolation\n```\n\n(i.e adding the _benchmark_ extra-require), followed by:\n\n```\ncd benckmark\npython ./kmeans.py\n```\n\nto run a benchmark for different k-means implementations and print a short summary of the performance.\n\nSome parameters in the `__main__` section of the file `./benchmark/kmeans.py` are exposed for quick edition (`n_clusters`, `max_iter`, `skip_slow`, ...).\n\n### Notes about the preferred floating point precision\n\nIn many machine learning applications, operations using single-precision (float32) floating point data require twice as less memory that double-precision (float64), are regarded as faster, accurate enough and more suitable for GPU compute. Besides, most GPUs used in machine learning projects are significantly faster with float32 than with double-precision (float64) floating point data.\n\nTo leverage the full potential of GPU execution, it's strongly advised to use a data loader that loads float32 data. By default, unless specified otherwise numpy array are created with type float64, so be especially careful to the type whenever the loader does not explicitly document the type nor expose a type option.\n\nAlthough it's less recommended to prevent avoidable data copies, it's also possible to transform float64 numpy arrays into float32 arrays using the [numpy.ndarray.astype](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.astype.html) type converter following this example:\n\n```\nX = my_data_loader()\nX_float32 = X.astype(float32)\nmy_gpu_compute(X_float32)\n```\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "BSD 3-Clause License Copyright (c) 2007-2021 The scikit-learn developers. All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.",
    "maintainer": "",
    "maintainer_email": "Olivier Grisel <olivier.grisel@ensta.org>",
    "name": "sklearn-numba-dpex",
    "package_url": "https://pypi.org/project/sklearn-numba-dpex/",
    "platform": null,
    "project_url": "https://pypi.org/project/sklearn-numba-dpex/",
    "project_urls": {
      "Homepage": "https://github.com/ogrisel/sklearn-numba-dpex"
    },
    "release_url": "https://pypi.org/project/sklearn-numba-dpex/0.1.0.dev0/",
    "requires_dist": [
      "scikit-learn",
      "numba-dpex",
      "dpctl",
      "pyopencl",
      "scikit-learn-intelex ; extra == 'benchmark'",
      "pandas ; extra == 'benchmark'"
    ],
    "requires_python": ">=3.8",
    "summary": "Computational Engine for scikit-learn based on numba-dpex",
    "version": "0.1.0.dev0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 15215845,
  "releases": {
    "0.1.0.dev0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ddf3fd16005ace3b15a34615950c9f1dc8faf85cf8c0728169f8c2bec3dc3c0e",
          "md5": "2aba61b0072a228dd7e2e0c9f09f7359",
          "sha256": "b7dac17d0e381e6b323cf30ff55bd141b7b95cfd85e5039019a7cdda85cd54b5"
        },
        "downloads": -1,
        "filename": "sklearn_numba_dpex-0.1.0.dev0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "2aba61b0072a228dd7e2e0c9f09f7359",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 6879,
        "upload_time": "2022-09-26T12:32:34",
        "upload_time_iso_8601": "2022-09-26T12:32:34.389047Z",
        "url": "https://files.pythonhosted.org/packages/dd/f3/fd16005ace3b15a34615950c9f1dc8faf85cf8c0728169f8c2bec3dc3c0e/sklearn_numba_dpex-0.1.0.dev0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "ddf3fd16005ace3b15a34615950c9f1dc8faf85cf8c0728169f8c2bec3dc3c0e",
        "md5": "2aba61b0072a228dd7e2e0c9f09f7359",
        "sha256": "b7dac17d0e381e6b323cf30ff55bd141b7b95cfd85e5039019a7cdda85cd54b5"
      },
      "downloads": -1,
      "filename": "sklearn_numba_dpex-0.1.0.dev0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "2aba61b0072a228dd7e2e0c9f09f7359",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.8",
      "size": 6879,
      "upload_time": "2022-09-26T12:32:34",
      "upload_time_iso_8601": "2022-09-26T12:32:34.389047Z",
      "url": "https://files.pythonhosted.org/packages/dd/f3/fd16005ace3b15a34615950c9f1dc8faf85cf8c0728169f8c2bec3dc3c0e/sklearn_numba_dpex-0.1.0.dev0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}