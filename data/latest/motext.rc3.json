{
  "info": {
    "author": "Constantine Lignos",
    "author_email": "lignos@brandeis.edu",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Topic :: Scientific/Engineering :: Artificial Intelligence"
    ],
    "description": "# Multilingual Open Text (MOT)\n\nThis is the repository for Multilingual Open Text (MOT), a project of the Broadening Linguistic Technologies (BLT) Lab at Brandeis University. MOT was created by Chester Palen-Michel, June Kim, and Constantine Lignos. This work was supported by a 2021 Brandeis University Provost Research Grant.\n\nIf you use the corpus please cite [our LREC 2022 paper](https://arxiv.org/abs/2201.05609):\n```\n@InProceedings{palenmichel-kim-lignos:2022:LREC,\n  author    = {Palen-Michel, Chester  and  Kim, June  and  Lignos, Constantine},\n  title     = {Multilingual Open Text Release 1: Public Domain News in 44 Languages},\n  booktitle      = {Proceedings of the Language Resources and Evaluation Conference},\n  month          = {June},\n  year           = {2022},\n  address        = {Marseille, France},\n  publisher      = {European Language Resources Association},\n  pages     = {2080--2089},\n  abstract  = {We present Multilingual Open Text (MOT), a new multilingual corpus containing text in 44 languages, many of which have limited existing text resources for natural language processing. The first release of the corpus contains over 2.8 million news articles and an additional 1 million short snippets (photo captions, video descriptions, etc.) published between 2001--2022 and collected from Voice of America's news websites. We describe our process for collecting, filtering, and processing the data. The source material is in the public domain, our collection is licensed using a creative commons license (CC BY 4.0), and all software used to create the corpus is released under the MIT License. The corpus will be regularly updated as additional documents are published.},\n  url       = {https://aclanthology.org/2022.lrec-1.224}\n}\n```\n\n# Releases\n\nThe latest version of the MOT data can always be found at\n[our latest GitHub release](https://github.com/bltlab/mot/releases/latest).\n\nThe current release contains 44 languages: Albanian (sqi), Amharic (amh), Armenian (hye), Azerbaijani (aze), Bambara (bam), Bangla (ben), Bosnian (bos), Burmese (mya), Cantonese (yue), Dari (prs), English (eng), French (fra), Georgian (kat), Greek (ell), Haitian Creole (hat), Hausa (hau), Indonesian (ind), Khmer (khm), Kinyarwanda (kin), Korean (kor), Kurdish (kur), Lao (lao), Lingala (lin), Macedonian (mkd), Mandarin (cmn), Northern (nde), Oromo (orm), Pashto (pus), Persian (fas), Portuguese (por), Russian (rus), Serbian (srp), Shona (sna), Somali (som), Spanish (spa), Swahili (swh), Thai (tha), Tibetan (bod), Tigrinya (tir), Turkish (tur), Ukranian (ukr), Urdu (urd), Uzbek (uzb), and Vietnamese (vie).\n\n\n## Release Layout\n\nThe data is released in one gzipped tar file per crawled site in the source data. Each site file is prefixed with an ISO 639-3 code denoting its language.\n\nThere are sometimes multiple sites per language. For example, in English (language code `eng`), there's the main news site at https://www.voanews.com/, the editorials site at https://editorials.voa.gov/, and a site for learning English at https://learningenglish.voanews.com/.\n\n## Downloading and Decompressing the Latest Release\n\nAll command-line instructions in this section require the `bash` shell and cloning/downloading this repository.\n\nWe have provided two scripts to help download and decompress all the data. Since they download all sites (currently 5.6GB compressed), they take a while to run. If you only want a handful of sites, it's probably easiest to download them manually.\n\nThe fastest way to download the data is to set up [the GitHub CLI](https://cli.github.com/), which allows for much faster release downloads. Once you have set it up, run `gh_download_latest_relase.sh`.\n\nIf you don't have the GitHub CLI available, run `download_latest_relase.sh` instead.\n\nBoth of the download scripts place compressed files (one per site) in the `release` directory. To decompress the downloaded files, run `decompress_latest_release.sh`.\n\n### Sentence Segmentation and Tokenization\n\nEach JSON document in the release has `paragraphs` and `n_paragraphs` fields. These contain the text of each website divided by paragraphs and the number of paragraphs, respectively.  For the languages where we provide sentence segmentation and  tokenization, the fields `sentences`, `n_sentences`, `tokens`, and `n_tokens` are also provided.\n\nWe are in the process of expanding the languages for which we provide sentence segmentation and tokenization. We currently provide both sentence segmentation and tokenization in the following languages (by ISO 639-3 code):\namh,\ncmn,\nell,\neng,\nfas,\nfra,\nhye,\nind,\nkhm,\nkor,\nlao,\nmya,\npor,\nprs,\nrus,\nspa,\nsrp,\ntha,\ntir,\ntur,\nukr,\nurd,\nvie, and\nyue.\n\nWe provide sentence segmentation but not tokenization for the following languages:\naze,\nbos,\nhat,\nhau,\nkin,\nlin,\nmkd,\nnde,\norm,\npus,\nsna,\nsom,\nsqi,\nswh, and\nuzb.\n\n# Working with the Data\n\n## Overview\n\nThe `motext` script contains two commands that assist in accessing data in the MOT corpus.\n\nTo install `motext`, run `pip install motext`. (If you are working with a clone of the repository and want to make changes to `motext`, you can run `pip install -e .` from the root of the clone.)\n\nCurrently, two subcommands are supported by this script: `search` and `extract`. For a description of these commands, run `motext --help`:\n\n```\nUsage: motext [OPTIONS] COMMAND [ARGS]...\n\nOptions:\n  --help  Show this message and exit.\n\nCommands:\n  extract  Extract json documents into text files in the output directory.\n  search   Search for json files with the keyword string in source.\n\n```\n\n### Extract\n\n#### Extracting given a source directory\n\nThe extract command takes in a folder and extracts information from the JSON files, converting into text files. a full call to this function may look like this:\n```\nmotext extract units source output_dir --num-files (int1) --max-per-file (int2) types article,video,photo,audio --include-title --include-authors\n```\n\nThis will produce a new directory `output_dir` containing subdirectories `output_dir\\article`, `output_dir\\video` etc. Extracted files will be sorted by content type in their respective directories.\n\nThe arguments are as follows:\n\n* `units`: choose from [sentences, tokens, paragraphs]. Extract will print one sentence/paragraph per line or a sentence of tokens per line.\n* `source`: this is the source directory from which data will be extracted (ex: swh_voaswahili)\n* `output_dir`: This is the folder to which you would like the data extracted. If output_dir does not exist, a new directory will be created.\n* `(optional) num-files`: The total number of files to extract from source.\n* `(optional) max-per-file`: The max number of units to extract per file (the first max-per-file units will be extracted)\n* `(optional) types`: The content types to extract from the source directory (ex: article,audio). By default will take all available. Input with commas and no spaces.\n* `(optional) include-title`: Whether to include the title at the top of each document on its own line\n* `(optional) include-authors`: Whether to include authors below the title, each on their own line. \n\nSay you would like to extract sentences from \"swh_voaswahili\" of all content types (this will include article, audio, video, and photo) to the directory \"output_folder\" including titles and authors. \n\nRun the following:\n\n```\nmotext extract sentences swh_voaswahili output_folder --include-title --include-authors\n```\n\nIf instead you want one paragraph per line, run:\n\n```\nmotext extract paragraphs swh_voaswahili output_folder --include-title --include-authors\n```\n\nIf you only want 6 files total, run:\n\n```\nmotext extract sentences swh_voaswahili output_folder --num-files 6 --include-title --include-authors\n```\n\nIf you want to constrain the number of lines per file to 7, run:\n\n```\nmotext extract sentences swh_voaswahili output_folder --max-per-file 7\n```\n\nIf you want all audio and photo content, run:\n\n```\nmotext extract sentences swh_voaswahili output_folder --types audio,photo\n```\n\nNote that content types are separated by a comma and no spaces.\n\n#### Extracting given a source text file\n\nThe `source` argument of `extract` can also be a text file containing paths directly to json files. Most efficiently, this will be a text file produced by the `search` function, outlined in the **Search** section below. To use `extract` in this way, it is the same syntax as if the text file were a directory. An example of this usage is as follows:\n\n```\nmotext extract sentences filter_text_file.txt output_folder\n```\n\n### Search\n\nThe `search` function allows the user to produce a text file of paths to json files that are tagged by a keyword. To call `search`, run:\n\n```\nmotext search source output_dir filename keyword\n```\n\nSay you would like a list of all articles in swh_voaswahili that are tagged with \"Afrika\". \n\nRun:\n\n```\nmotext search swh_voaswahili searches_dir afrika_search Afrika\n```\n\nThe list will be stored in `afrika_search.txt` in `searches_dir`. \n\nNow say you want to constrain the content types you are searching through to only audio and videos. \n\nRun:\n\n```\nmotext search swh_voaswahili searches_dir afrika_search Afrika --types audio,video\n```\n\n---\n\n# Scraping, Extraction, and Creating Releases\n\nThis repository contains all the code used to create version 1 of MOT. While we provide\nthis for transparency, replication, and in case it will be useful to others, we do not\nrecommend using it due to its complexity. However, documentation for our release creation\nprocess is below.\n\n## Setup\nWe recommend using a conda environment when working with the codebase.\nUse Python 3.8 or higher.\nInstall dependencies with `pip install -r requirements.txt`. \n\nYou will need to install MongoDB to store scraped documents.\n[mongo installation instructions](https://www.mongodb.com/docs/v4.0/tutorial/install-mongodb-on-os-x/).\nTo start the database: `mongod --dbpath voa-mongodb/ --wiredTigerCacheSizeGB 16 --port 27200`\nWe specify a specfic path to store the database and a specific port and limit the cache size.\n\nTo dump or restore the DB from a past archive:\n`mongodump --port 27200 --archive=dump-7.30.21.gz --gzip`\n`mongorestore --port 27200 --archive=dump-7.30.21.gz --gzip`\nUse `--bypassDocumentValidation` flag if the backedup db doesn't have all documents passing validation.\n\n## Running Scraping and Extraction\n\nRun downloadsitemaps.py to get fresh sitemaps of VOA.\nThis requires the `voa-domain.tsv` file with the different VOA domains.\n`python extraction/downloadsitemaps.py voa-domains.tsv sitemaps-10.27.21 filemap-10.27.21.tsv`\n(Sometimes this fails with 503 error, just run again if needed)\n\nThere are two ways to scrape. \nYou can scrape from scratch or you can scrape with only the new urls after \ncomparing with prior sitemaps.\n\n### Updating the scrape with only new urls\n\nDiff the new sitemap with whatever the most recent previous sitemap is.\n`python scripts/comparesitemaps.py filemap-8.16.21.tsv filemap-10.27.21.tsv --early-sitemap-dir sitemaps-8.16.21/ --late-sitemap-dir sitemaps-10.27.21/ --outdir sitemap-diff-10.27.21/`\n\nBack up the database if it hasn't been backed up lately:\n`mongodump --port 27200 --archive=dump-7.30.21.gz --gzip`\n\nScrape using the diffed sitemap urls:\n`python extraction/scraper.py update sitemap-diff-10.27.21/new_urls-filemap-10.27.21.tsv --port 27200 `\n\n### Scraping from scratch\n\nSkip `comparesitemaps.py` and use \n`python extraction/scraper.py scrape filemap-10.27.21.tsv sitemaps-10.27.21 --port 27200 `\n\nDump documents:\nThis step can be skipped if extracting from the mongo database directly.\nSkipping this saves a lot of wasted space writing to disk.\n`python extraction/dump_documents.py <outdir> <filemap> --n-processes 20`\nIf including the custom models download them from [custom-ersatz-models](https://github.com/cpalenmichel/custom-ersatz-models)\nor train your own models using [Ersatz](https://github.com/rewicks/ersatz) \nand use the flag `--custom-segmentation-dir <custom-models-dir-path>`. \n\nRun extraction script:\nIt is currently recommended without GPUs and just use a high number of cpus for extraction.\n`extracttext.py` can be run on dumped json documents from the database or \ncan be run from the database directly.\nUse `fromdb` to query the database directly and do extraction without writing intermediary files.\nUse `fromfiles` to run extract text from intermediate json files dumped from the db.\n\nSample call with parameters that seem ok on our dev machine.\n`time python extraction/extracttext.py fromdb ~/mot/extractions-03.02.22/ --port 27200 --n-extractors 50 --n-db-queriers 10 --batchsize 100 --filemap filemap-03.01.22.tsv --start-date 2001-01-01`\n\n\n## One-off Scripts \n\nThe directory `scripts` contains a number of one-off scripts that we used briefly\nbut are not part of the main extraction process. \n\n\n## Quality Checks\n\nThe directory `qualitychecks` contains some scripts for analysis of the corpus.\n\n## Making a new release \n\nInstall `gh` if it isn't already installed. `conda install gh --channel conda-forge`\nLogin with `gh auth login`. Follow the steps for logging in through a browser.\nCreate a release draft on github.\n`gh release upload <release number> <dir with the final extractions for release>/*.tgz`\nCheck everything is uploaded and publish the release on github.\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/bltlab/mot",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "motext",
    "package_url": "https://pypi.org/project/motext/",
    "platform": null,
    "project_url": "https://pypi.org/project/motext/",
    "project_urls": {
      "Homepage": "https://github.com/bltlab/mot"
    },
    "release_url": "https://pypi.org/project/motext/0.2.1/",
    "requires_dist": [
      "click"
    ],
    "requires_python": ">=3.8",
    "summary": "motext: The interface to the Multilingual Open Text (MOT) corpus",
    "version": "0.2.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14200596,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e83390412818a25e6306451cac574534ff9ab2100fa3257f2a1535cc0381d5bc",
          "md5": "7730743f54d604923eb2c1a573c58caf",
          "sha256": "712042e43f5a8288eb323b9cd2a0f57aa7d15a3baaed2ae1d3f031fd328a7ec4"
        },
        "downloads": -1,
        "filename": "motext-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "7730743f54d604923eb2c1a573c58caf",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 10978,
        "upload_time": "2022-06-20T07:25:51",
        "upload_time_iso_8601": "2022-06-20T07:25:51.300019Z",
        "url": "https://files.pythonhosted.org/packages/e8/33/90412818a25e6306451cac574534ff9ab2100fa3257f2a1535cc0381d5bc/motext-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "18c89ca034e475f286354b025741dda861c4f8ce604772147d3ae9b735629025",
          "md5": "cef40ba02539d85013f774e591e8d4f8",
          "sha256": "0c47d09029f7a50b931ea172b7e579b026b72ba851e9e3a6b7769a4843a8fe6f"
        },
        "downloads": -1,
        "filename": "motext-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "cef40ba02539d85013f774e591e8d4f8",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 15227,
        "upload_time": "2022-06-20T07:25:53",
        "upload_time_iso_8601": "2022-06-20T07:25:53.091361Z",
        "url": "https://files.pythonhosted.org/packages/18/c8/9ca034e475f286354b025741dda861c4f8ce604772147d3ae9b735629025/motext-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f691bdaac95e2876c8ea777a1b03266ddb880e282074329b332692f4a8303886",
          "md5": "0efa16f24736b29452185cfd09e8f099",
          "sha256": "c45f300c4b5a941194f60fe45bfa6f5202f749dd870725f524f78558f707cfaf"
        },
        "downloads": -1,
        "filename": "motext-0.2.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0efa16f24736b29452185cfd09e8f099",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 11499,
        "upload_time": "2022-06-21T15:22:54",
        "upload_time_iso_8601": "2022-06-21T15:22:54.420169Z",
        "url": "https://files.pythonhosted.org/packages/f6/91/bdaac95e2876c8ea777a1b03266ddb880e282074329b332692f4a8303886/motext-0.2.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e685d9946258b80d7f27c052fdc684e720fc2f7044748e6f41ace817fa7efa94",
          "md5": "3b164bc33b86987b530a901a3d75963b",
          "sha256": "b7dccb9017360e38d8dc6ee0d843638e15f00a38c23359067c3568c9e7507a14"
        },
        "downloads": -1,
        "filename": "motext-0.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "3b164bc33b86987b530a901a3d75963b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 16356,
        "upload_time": "2022-06-21T15:22:56",
        "upload_time_iso_8601": "2022-06-21T15:22:56.106560Z",
        "url": "https://files.pythonhosted.org/packages/e6/85/d9946258b80d7f27c052fdc684e720fc2f7044748e6f41ace817fa7efa94/motext-0.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3643365128e7189abb3820787a69bc86998f5c6c49ff83299682ec2c610bdd41",
          "md5": "75c5ee54fba21dbf0397f2313553a613",
          "sha256": "4c238c9138c9adbb8fa135c5f9c3220b75655047d1c0843b469cfa9684cf9827"
        },
        "downloads": -1,
        "filename": "motext-0.2.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "75c5ee54fba21dbf0397f2313553a613",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 11492,
        "upload_time": "2022-06-21T15:49:45",
        "upload_time_iso_8601": "2022-06-21T15:49:45.861052Z",
        "url": "https://files.pythonhosted.org/packages/36/43/365128e7189abb3820787a69bc86998f5c6c49ff83299682ec2c610bdd41/motext-0.2.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "005a4bfacee9b86d1a375d7b1d51b9f5594d0e98f1e0e1fa271ffde242420f04",
          "md5": "ef6dfb82f57adb5422b7a4df98c3becb",
          "sha256": "9205bc8e3337b098190e3981d7c1ccfaff1f48a3a245d14dc5422a43a8b07672"
        },
        "downloads": -1,
        "filename": "motext-0.2.1.tar.gz",
        "has_sig": false,
        "md5_digest": "ef6dfb82f57adb5422b7a4df98c3becb",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 16343,
        "upload_time": "2022-06-21T15:49:47",
        "upload_time_iso_8601": "2022-06-21T15:49:47.270442Z",
        "url": "https://files.pythonhosted.org/packages/00/5a/4bfacee9b86d1a375d7b1d51b9f5594d0e98f1e0e1fa271ffde242420f04/motext-0.2.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "3643365128e7189abb3820787a69bc86998f5c6c49ff83299682ec2c610bdd41",
        "md5": "75c5ee54fba21dbf0397f2313553a613",
        "sha256": "4c238c9138c9adbb8fa135c5f9c3220b75655047d1c0843b469cfa9684cf9827"
      },
      "downloads": -1,
      "filename": "motext-0.2.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "75c5ee54fba21dbf0397f2313553a613",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.8",
      "size": 11492,
      "upload_time": "2022-06-21T15:49:45",
      "upload_time_iso_8601": "2022-06-21T15:49:45.861052Z",
      "url": "https://files.pythonhosted.org/packages/36/43/365128e7189abb3820787a69bc86998f5c6c49ff83299682ec2c610bdd41/motext-0.2.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "005a4bfacee9b86d1a375d7b1d51b9f5594d0e98f1e0e1fa271ffde242420f04",
        "md5": "ef6dfb82f57adb5422b7a4df98c3becb",
        "sha256": "9205bc8e3337b098190e3981d7c1ccfaff1f48a3a245d14dc5422a43a8b07672"
      },
      "downloads": -1,
      "filename": "motext-0.2.1.tar.gz",
      "has_sig": false,
      "md5_digest": "ef6dfb82f57adb5422b7a4df98c3becb",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.8",
      "size": 16343,
      "upload_time": "2022-06-21T15:49:47",
      "upload_time_iso_8601": "2022-06-21T15:49:47.270442Z",
      "url": "https://files.pythonhosted.org/packages/00/5a/4bfacee9b86d1a375d7b1d51b9f5594d0e98f1e0e1fa271ffde242420f04/motext-0.2.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}