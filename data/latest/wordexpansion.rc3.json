{
  "info": {
    "author": "大邓",
    "author_email": "thunderhit@qq.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "> README.md为本人所写，代码底层完全为刘焕勇设计。\n>\n> 原项目(刘焕勇)地址\n\n\n# 一、项目意义\n\n情感分析大多是基于情感词典对文本数据进行分析，所以情感词典好坏、是否完备充足是文本分析的关键。\n\n目前常用的词典都是基于形容词，有\n\n- 知网HowNet\n- 大连理工大学情感本体库\n\n但是形容词类型的词典在某些情况下不适用，比如\n\n**华为手机外壳采用金属制作，更耐摔**\n\n由于句子中没有形容词，使用形容词情感词典计算得到的情感得分为0。但是**耐摔**这个动词具有**正面积极情绪**，这个句子的情感的分理应为**正**\n\n\n\n可见能够简单快速构建不同领域(手机、汽车等)的情感词典十分重要。但是人工构建太慢，如果让机器帮我们把最有可能带情感的候选词找出来，人工再去筛选构建词典，那该多好啊。 那么如何快速自动的新建或者扩充词表呢？\n\n\n\n<br>\n\n# 二、构建思路\n\n- 共现法，参考https://github.com/liuhuanyong/SentimentWordExpansion\n- 词向量，参考https://github.com/MS20190155/Measuring-Corporate-Culture-Using-Machine-Learning\n\n\n\n\n\n<br>\n\n## 2.1 共现法扩充词表\n\n计算机领域有一个算法叫做SO_PMI，互信息。简单的讲个体之间不是完全独立的，往往物以类聚，人以群分。如果我们一开始设定少量的\n\n- 初始正面种子词\n- 初始负面种子词\n\n程序会按照“物以类聚人以群分”的思路，\n\n- 根据**初始正面种子词**找到很多大概率为**正面情感的候选词**\n- 根据**初始负种子词**找到很多大概率为**负面情感的候选词**\n\n这个包原始作者刘焕勇，项目地址https://github.com/liuhuanyong/SentimentWordExpansion 我仅仅做了简单的封装\n\n\n\n\n\n## 2.2 词向量扩充词表\n\n共现法，词语之间的独立无相关性依然很强，依然认为词语与词语是不可以比较的。其实词语里潜藏着很多线索，例如中国传统文化中的金木水火土、性别(阴阳)等信息。例如\n\n- “铁”、“铜”、“钢”\n- “国王“、“王后“、“男人“、“女人“\n\n如果能抽取出每个词的特征，将每个词用同样长度的向量表示，例如100维。那么咱们中学阶段的cos余弦公式可以计算任意两个词的相似度。\n\n参照论文使用机器学习构建五类企业文化词典\n\n> Kai Li, Feng Mai, Rui Shen, Xinyan Yan, [**Measuring Corporate Culture Using Machine Learning**](https://academic.oup.com/rfs/advance-article-abstract/doi/10.1093/rfs/hhaa079/5869446?redirectedFrom=fulltext), *The Review of Financial Studies*, 2020\n>\n> 代码发布在github https://github.com/MS20190155/Measuring-Corporate-Culture-Using-Machine-Learning\n\n作者github的代码，我技术水平有限，很难直接拿来用，我修改了两处。\n\n- 原作者使用的stanfordnlp处理英文分词；wordexpansion改为jieba处理中文、nltk处理英文\n\n- 原作者在构建word2vec模型，考虑了Ngram；wordexpansion未考虑Ngram\n\n\n\n两处更改，降低了代码的复杂程度，方便自己封装成包，供大家使用。大家也可根据自己能力，直接使用作者提供的代码。\n\n\n\n\n\n<br>\n\n\n# 三、安装\n\n\n\n最简单的安装,现在由于国内外网络不稳定，可能需要尝试几次\n\n```\npip3 install wordexpansion\n```\n\n\n\n<br>\n\n# 四、test项目文件目录\n\n>**注意：**\n>所有的txt文件，不论输入的还是程序输出的结果，均采用utf-8编码。\n\n```\n|---test \n    |---共现法\n       |--find_newwords.py          #共现法测试代码\n       |--corpus1.txt               #语料（媒体报道）文本数据，5.5M\n       |--test_seed_words.txt       #情感种子词，需要手动构建\n       |--neg_candi.txt             #find_newwords.py运行后发现的负面候选词\n       |--pos_candi.txt             #find_newwords.py运行后发现的正面候选词\n\n    |---词向量法\n       |--run_w2v.py                #词向量法测试代码\n       |--corpus2.txt               #语料（企业文化）文本数据，34M\n       |--seeds                     #五种企业文化初始候选词(5个txt)\n       |--model                     #word2vec训练过程中的模型(运行时产生的副产品)\n       |--candidate_words           #五种企业文化词典（5个txt）\n\n\n```\n\n\n\n# 五、共现法代码\n\n### 5.1 准备构建种子词\n\n可能我们希望的情感词典几万个，但是种子词100个（正面词50个，负面词50个）说不定就可以。\n\n手动构建的种子词典**test_seed_words.txt**中\n\n- 每行一个词\n- 每个词用neg或pos标记\n- 词与标记用tab键间隔\n\n```\n休克\tneg\n如出一辙\tneg\n渴求\tneg\n扎堆\tneg\n休整\tneg\n关门\tneg\n阴晴不定\tneg\n喜忧参半\tneg\n起起伏伏\tneg\n一厢情愿\tneg\n松紧\tneg\n最全\tpos\n雄风\tpos\n稳健\tpos\n稳定\tpos\n拉平\tpos\n保供\tpos\n修正\tpos\n稳\tpos\n稳住\tpos\n保养\tpos\n...\n...\n```\n\n\n\n### 5.2 发现情感新词\n\n已经安装好了**wordexpansion**，现在我们新建一个名为**find_newwords.py**的测试代码\n\n代码中的\n\n```python\nfrom wordexpansion import ChineseSoPmi\n\nsopmier = ChineseSoPmi(inputtext_file='test_corpus.txt',\n                       seedword_txtfile='test_seed_words.txt',\n                       pos_candi_txt_file='pos_candi.txt',\n                       neg_candi_txtfile='neg_candi.txt')\nsopmier.sopmi()\n```\n\n\n\n我们的语料数据**test_corpus.txt** 文件5.5M，100个候选词，运行程序大概耗时60s\n\n\n\n### 5.3 输出的结果\n\n**find_newwords.py**运行结束后，会在**同文件夹内(find_newwords.py所在的文件夹)**发现有两个新的txt文件\n\n- pos_candi.txt\n- neg_candi.txt\n\n打开**pos_candi.txt**, 我们看到\n\n```\nword,sopmi,polarity,word_length,postag\n保持,87.28493062512524,pos,2,v\n风险,70.15627986116269,pos,2,n\n货币政策,66.28476448498694,pos,4,n\n发展,64.40272795986517,pos,2,vn\n不要,63.71800916752807,pos,2,df\n理念,61.2024367757337,pos,2,n\n整体,59.415315156715586,pos,2,n\n下,59.321140440512984,pos,1,f\n引导,58.5817208758171,pos,2,v\n投资,57.71720491331896,pos,2,vn\n加强,57.067969337267684,pos,2,v\n自己,53.25503772499689,pos,2,r\n提升,52.80686380719989,pos,2,v\n和,52.12334472663675,pos,1,c\n稳步,51.58193211655792,pos,2,d\n重要,51.095865548255034,pos,2,a\n...\n```\n\n打开**neg_candi.txt**, 我们看到\n\n```\nword,sopmi,polarity,word_length,postag\n心灵,33.17993872989303,neg,2,n\n期间,31.77900620939178,neg,2,f\n西溪,30.87839808390589,neg,2,ns\n人事,29.594976229171877,neg,2,n\n复杂,29.47870186147108,neg,2,a\n直到,27.86014637934966,neg,2,v\n宰客,27.27304813428452,neg,2,nr\n保险,26.433136238404746,neg,2,n\n迎来,25.83859896903048,neg,2,v\n至少,25.105021416064616,neg,2,d\n融资,25.09148586460598,neg,2,vn\n或,24.48343281812743,neg,1,c\n列,22.20695894382675,neg,1,v\n存在,22.041049266517774,neg,2,v\n...\n```\n\n\n\n从上面的结果看，正面候选词较好，负面候选词有点差强人意。虽然差点，但节约了很多很多时间。\n\n现在电脑已经帮我们找出候选词，我们人类最擅长找毛病，对neg_candi.txt和pos_candi.txt我们人类只需要一个个挑毛病，把不带正负情感的词剔除掉。这样经过一段时间的剔除工作，针对具体研究领域的专业情感词典就构建出来了。\n\n\n\n# 六、词向量法代码\n\n## 6.1 准备种子词\n\n词向量法程序会挖掘出原始数据中的所有词的词向量，这时候如果给词向量模型传入种子词，会根据向量的远近识别出多个近义词。例如在``Kai Li, Feng Mai, Rui Shen, Xinyan Yan, Measuring Corporate Culture Using Machine Learning, *The Review of Financial Studies*,2020``中, 人工构建了五大类企业文化词典，存放在txt中，即\n\n- innovation.txt\n- integrity.txt\n- quality.txt\n- respect.txt\n- teamwork.txt\n\n注意，在txt中，每行一个词语。\n\n\n\n### 6.2 发现情感新词\n\n已经安装好了**wordexpansion**，现在我们新建一个名为**run_w2v.py**的测试代码\n\n代码中的\n\n```python\nfrom wordexpansion import W2VModels\n\nfrom similarity import W2VModels\nimport pandas as pd\nimport os\n\n#初始化模型\nmodel = W2VModels(cwd=os.getcwd())\nmodel.train(documents=list(open('documents.txt').readlines()))\n\n#导入种子词\nintegrity = [w for w in open('seeds/integrity.txt').read().split('\\n') if w!='']\ninnovation = [w for w in open('seeds/innovation.txt').read().split('\\n') if w!='']\nquality = [w for w in open('seeds/quality.txt').read().split('\\n') if w!='']\nrespect = [w for w in open('seeds/respect.txt').read().split('\\n') if w!='']\nteamwork = [w for w in open('seeds/teamwork.txt').read().split('\\n') if w!='']\n\n#根据种子词，筛选出没类词最相近的前100个词\nmodel.find(seedwords=integrity, seedwordsname='integrity', topn=100)\nmodel.find(seedwords=innovation, seedwordsname='innovation', topn=100)\nmodel.find(seedwords=quality, seedwordsname='quality', topn=100)\nmodel.find(seedwords=respect, seedwordsname='respect', topn=100)\nmodel.find(seedwords=teamwork, seedwordsname='teamwork', topn=100)\n\n```\n\n\n\n我们的语料数据**run_w2v.txt** 文件30+M，50多个候选词，运行程序大概耗时30s\n\n<br>\n\n### 6.3 输出的结果\n\n**run_w2v.py**运行结束后，会在**candidate_words内**发现有5个新的txt文件\n\n- innovation.txt\n- integrity.txt\n- quality.txt\n- respect.txt\n- teamwork.txt\n\n打开**innovation.txt**, 我们看到\n\n```\ninnovation\ninnovate\ninnovative\ncreativity\ncreative\ncreate\npassion\npassionate\nefficiency\nefficient\nexcellence\npride\nenhance\nexpertise\noptimizing\nadapt\ncapability\nawareness\ncreating\nvalue-added\noptimize\nleveraging\nattract\ninnovative\nmanufacture\nefficient\nintegrate\nbetter-for-you\nenhanced\nefficiently\nconsolidate\nautomation\nresources\ninfrastructure\ninnovation\ntalent\nskills\ncommunicate\ndifferentiated\nnetwork\nsupporting\ndsd\ncapture\nefficiency\ncapabilities\nproductive\nspeed\norganized\nmanual\nmanage\ncost-effective\nsimpler\ntraining\ntechnology\nmerchandising\ninteract\ndrive\norganization\nreliability\nbackbone\nstrengthen\nattracting\nmaximizing\nfine-tune\nenable\nheadquarter\nplatform\ntightly\naligned\nflexible\nfulfillment\nrationalize\nback-office\nensure\nmanufacturing\nefficiencies\neffort\ntechnological\nretain\nproprietary\ndurable\ndiligent\nwap\ntalented\nexcitement\nlogistical\nutilize\nbandwidth\ninvest\ndiversify\nhigher-margin\npride\nselecting\nmanaging\ndepartments\nengaging\ncoordination\nmultinational\nefforts\nstore-within-store\nprocurement\nworkarounds\nnurture\nprovides\nbreadth\nviable\nsuperb\ndigital\nsmarter\nintroducing\nbeef\nproposition\n```\n\n打开**respec.txt**, 我们看到\n\n```\nrespectful\ntalent\ntalented\nemployee\ndignity\nempowerment\nempower\nskills\nbackbone\ntraining\ndatabase\ndesigners\nsdk\nrecruit\nengine\ndealers\nselecting\nresource\nonsite\ncomputer\nfunctions\nwholesalers\neducational\nexpertise\ncoordination\nvalue-added\ncreative\nindividuals\nmanagers\npride\ntechnological\nawareness\nsalespeople\norganized\nelectrical\nreputation\ntools\nweb-based\nfulfillment\nin-house\nstaff\nmotor\ncrm\ncommunications\nattracting\ndepartments\ndatabases\nwarsaw\noptimized\nfunctionality\nfaces\ntool\nsupported\ncommission-based\ntransportation\ncentralized\nsponsor\nknowledge\ntrain\nassigned\nphysician\nviability\nbrokerage\nnetworks\nculture\ninterior\nconnecting\nleveraging\nmwd\nsystems\nincentivized\nmission\naffiliated\nhigh-quality\necosystem\neradication\nprocesses\nsimplify\non-site\ncontinuously\nrecruiting\npractices\ndedicated\nadequately\nheadquarter\nvar\npractice\nairclic\npolice\narchitectural\npainlessly\nemploying\nnear-field\ncorporations\norganization\nonshore\nadjacencies\nsocial\nwell-known\ntrained\nsap\ncomplement\nodms\nresources\ngasification\nsalesforce\nthird-party\n\n```\n\n同理，在其他几类企业文化词典txt中产生了符合预期的词语。\n\n现在电脑已经帮我们找出5类企业文化候选词，我们人类最擅长找毛病，对5个txt文件，我们人类只需要一个个挑毛病，把不带正负情感的词剔除掉。这样经过一段时间的剔除工作，针对具体研究领域的专业情感词典就构建出来了。\n\n\n\n\n\n<br>\n\n# 七、注意：\n1. so_pmi算法效果受训练语料影响，语料规模越大，效果越好  \n\n2. so_pmi算法效率受训练语料影响，语料越大，训练越耗时。100个种子词，5M的数据，大约耗时62.679秒  \n\n3. 候选词的选择，可根据PMI值，词长，词性设定规则，进行筛选  \n\n4. **所有的txt文件，不论输入的还是程序输出的结果，均采用utf-8编码。**\n\n5. 词向量法没有考虑Ngram，如果采用了Ngram， 可能会挖掘出该场景下的词语组合。但是程序运行时间可能会更慢。\n\n6. 如果刚刚好也想使用**企业文化**这个具体场景，记得引用论文\n\n7. > Kai Li, Feng Mai, Rui Shen, Xinyan Yan, Measuring Corporate Culture Using Machine Learning, *The Review of Financial Studies*,2020\n\n\n\n<br>\n\n# 如果\n\n如果您是经管人文社科专业背景，编程小白，面临海量文本数据采集和处理分析艰巨任务，可以参看[《python网络爬虫与文本数据分析》](https://ke.qq.com/course/482241?tuin=163164df)视频课。作为文科生，一样也是从两眼一抹黑开始，这门课程是用五年时间凝缩出来的。自认为讲的很通俗易懂o(*￣︶￣*)o，\n\n- python入门\n- 网络爬虫\n- 数据读取\n- 文本分析入门\n- 机器学习与文本分析\n- 文本分析在经管研究中的应用\n\n感兴趣的童鞋不妨 戳一下[《python网络爬虫与文本数据分析》](https://ke.qq.com/course/482241?tuin=163164df)进来看看~\n\n[![](img/课程.png)](https://ke.qq.com/course/482241?tuin=163164df)\n\n\n\n# 更多\n\n- [B站:大邓和他的python](https://space.bilibili.com/122592901/channel/detail?cid=66008)\n\n- 公众号：大邓和他的python\n\n- [知乎专栏：数据科学家](https://zhuanlan.zhihu.com/dadeng)\n\n![](img/大邓和他的Python.png)\n<br>\n\n\n\n\n\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/hidadeng/wordexpansion",
    "keywords": "knowledge graph,text analysis,event extraction",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "wordexpansion",
    "package_url": "https://pypi.org/project/wordexpansion/",
    "platform": "",
    "project_url": "https://pypi.org/project/wordexpansion/",
    "project_urls": {
      "Homepage": "https://github.com/hidadeng/wordexpansion"
    },
    "release_url": "https://pypi.org/project/wordexpansion/1.1/",
    "requires_dist": null,
    "requires_python": ">=3.5",
    "summary": "",
    "version": "1.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 10943448,
  "releases": {
    "0.0.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "feb884cd34dd1f0defab42e95470ce5ab311e623b1bbe4e81bb282b18186b99c",
          "md5": "9ea3f4f633ba3eba2bc585cd215b1b2e",
          "sha256": "e538f5c2fa50a7940302e1e3d344d7c8b6c42fc8d4fc1c8117df51d6d15b4b28"
        },
        "downloads": -1,
        "filename": "wordexpansion-0.0.7.macosx-10.9-x86_64.tar.gz",
        "has_sig": false,
        "md5_digest": "9ea3f4f633ba3eba2bc585cd215b1b2e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 10256,
        "upload_time": "2020-03-26T05:49:02",
        "upload_time_iso_8601": "2020-03-26T05:49:02.446049Z",
        "url": "https://files.pythonhosted.org/packages/fe/b8/84cd34dd1f0defab42e95470ce5ab311e623b1bbe4e81bb282b18186b99c/wordexpansion-0.0.7.macosx-10.9-x86_64.tar.gz",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cefbe98f5077bab4fddeb58e5a168beb77f3045688e2b96453e8b37c409f2d46",
          "md5": "54b3bcf656cf418f81a5d9bbfa9a8bd2",
          "sha256": "97179d386a4f4b111ba84f3bf8313692d5436499cfdccaa26ebca6f1a61779f7"
        },
        "downloads": -1,
        "filename": "wordexpansion-0.0.7-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "54b3bcf656cf418f81a5d9bbfa9a8bd2",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.5",
        "size": 7201,
        "upload_time": "2020-03-26T05:49:00",
        "upload_time_iso_8601": "2020-03-26T05:49:00.805997Z",
        "url": "https://files.pythonhosted.org/packages/ce/fb/e98f5077bab4fddeb58e5a168beb77f3045688e2b96453e8b37c409f2d46/wordexpansion-0.0.7-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "08063123cd1114b8299a2df23a5bbe60f461fd06a26db9e7d0821cbaaafaa842",
          "md5": "2773caff5a7e4da644d9b7d140dbbac8",
          "sha256": "fd03d7e8722f6478a9228ed17b241d1ffc538443168bdb6aee6b80aaf13c1040"
        },
        "downloads": -1,
        "filename": "wordexpansion-1.0.macosx-10.9-x86_64.tar.gz",
        "has_sig": false,
        "md5_digest": "2773caff5a7e4da644d9b7d140dbbac8",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 10054,
        "upload_time": "2021-05-14T03:09:44",
        "upload_time_iso_8601": "2021-05-14T03:09:44.527911Z",
        "url": "https://files.pythonhosted.org/packages/08/06/3123cd1114b8299a2df23a5bbe60f461fd06a26db9e7d0821cbaaafaa842/wordexpansion-1.0.macosx-10.9-x86_64.tar.gz",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cb0388abe4ae65eee33ec37076d6c96dd145cbbc00f6454c3fd092dae2643838",
          "md5": "58f4853a14bdbe68b349a3f297a27a03",
          "sha256": "f6e290e1be5224003b1fc41b719af7f6517929f460e81c417155ed1eaf5aeb29"
        },
        "downloads": -1,
        "filename": "wordexpansion-1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "58f4853a14bdbe68b349a3f297a27a03",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.5",
        "size": 8076,
        "upload_time": "2021-05-14T03:09:41",
        "upload_time_iso_8601": "2021-05-14T03:09:41.617348Z",
        "url": "https://files.pythonhosted.org/packages/cb/03/88abe4ae65eee33ec37076d6c96dd145cbbc00f6454c3fd092dae2643838/wordexpansion-1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7e05b35f51d2cfe3b14a165dec32e8ede24a80f5b7c0690e983eeb2955e2a4f4",
          "md5": "ac807aea70641cc9eaea02c31b2feedb",
          "sha256": "7f58a77b541f0f17e0295640f8537d9fe19016230ef1e6076e7ca7419fb28e4f"
        },
        "downloads": -1,
        "filename": "wordexpansion-1.1.macosx-10.9-x86_64.tar.gz",
        "has_sig": false,
        "md5_digest": "ac807aea70641cc9eaea02c31b2feedb",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 16247,
        "upload_time": "2021-07-19T06:19:33",
        "upload_time_iso_8601": "2021-07-19T06:19:33.601786Z",
        "url": "https://files.pythonhosted.org/packages/7e/05/b35f51d2cfe3b14a165dec32e8ede24a80f5b7c0690e983eeb2955e2a4f4/wordexpansion-1.1.macosx-10.9-x86_64.tar.gz",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ec53ea6c9ea678ab8e51dcf07ce5b342efce54ae8dae354e5c4f7608753d37da",
          "md5": "aba5ac304fa5e50d884a29c388e31d41",
          "sha256": "9cbf874b8b3967f430b1a9042e793de6b0c1cd31e5b805b7b5ba4391cc450e51"
        },
        "downloads": -1,
        "filename": "wordexpansion-1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "aba5ac304fa5e50d884a29c388e31d41",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.5",
        "size": 12680,
        "upload_time": "2021-07-19T06:19:31",
        "upload_time_iso_8601": "2021-07-19T06:19:31.564363Z",
        "url": "https://files.pythonhosted.org/packages/ec/53/ea6c9ea678ab8e51dcf07ce5b342efce54ae8dae354e5c4f7608753d37da/wordexpansion-1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "7e05b35f51d2cfe3b14a165dec32e8ede24a80f5b7c0690e983eeb2955e2a4f4",
        "md5": "ac807aea70641cc9eaea02c31b2feedb",
        "sha256": "7f58a77b541f0f17e0295640f8537d9fe19016230ef1e6076e7ca7419fb28e4f"
      },
      "downloads": -1,
      "filename": "wordexpansion-1.1.macosx-10.9-x86_64.tar.gz",
      "has_sig": false,
      "md5_digest": "ac807aea70641cc9eaea02c31b2feedb",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.5",
      "size": 16247,
      "upload_time": "2021-07-19T06:19:33",
      "upload_time_iso_8601": "2021-07-19T06:19:33.601786Z",
      "url": "https://files.pythonhosted.org/packages/7e/05/b35f51d2cfe3b14a165dec32e8ede24a80f5b7c0690e983eeb2955e2a4f4/wordexpansion-1.1.macosx-10.9-x86_64.tar.gz",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "ec53ea6c9ea678ab8e51dcf07ce5b342efce54ae8dae354e5c4f7608753d37da",
        "md5": "aba5ac304fa5e50d884a29c388e31d41",
        "sha256": "9cbf874b8b3967f430b1a9042e793de6b0c1cd31e5b805b7b5ba4391cc450e51"
      },
      "downloads": -1,
      "filename": "wordexpansion-1.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "aba5ac304fa5e50d884a29c388e31d41",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.5",
      "size": 12680,
      "upload_time": "2021-07-19T06:19:31",
      "upload_time_iso_8601": "2021-07-19T06:19:31.564363Z",
      "url": "https://files.pythonhosted.org/packages/ec/53/ea6c9ea678ab8e51dcf07ce5b342efce54ae8dae354e5c4f7608753d37da/wordexpansion-1.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}