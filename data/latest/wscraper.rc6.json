{
  "info": {
    "author": "T.Furukawa",
    "author_email": "tfurukawa.mail@gmail.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# Wikipedia Scraper\n\nParsing, tokenizing text using a Wikipedia dump XML file.\n\n## Author\n\n- Name: T.Furukawa\n- Email: tfurukawa.mail@gmail.com\n\n## Installation\n\n```shell\npip install wscraper\n```\n\n## Support\n\n### language\n\n- japanese\n  - Japanese Wikipedia\n- english\n  - English Wikipedia\n\n## How to Work (Command)\n\n### Check Console Commands\n\nPlease run this command.\n\n```shell\nwscraper --help\n```\n\nExecutable commands to be listed.\n\n### Initialize\n\nFor start, you have to execute this command.  \nIt creates necessary directory and files.\n\n```shell\nwscraper initialize\n```\n\nwscraper root directory is created at `$HOME/.wscraper`.  \nIf you change this path, please set environment `WSCRAPER_ROOT`.\n\n### Set Global Parameters\n\n```shell\nwscraper root set --language japanese --page_chunk 1000\n```\n\n- `language`\n  - Default language. If you do not set the parameter `language` for each corpus, this default language is used.\n- `page_chunk`\n  - A Wikipedia dump XML file has large text data as many pages. For analysis, it is separated to several small files because of memory efficiency.\n\nSee `wscraper root set -h`\n\n### Import a Wikipedia XML File\n\nA file wikipedia.xml assumes like `(lang)wiki-(date)-pages-articles-multistream.xml`\n\n```shell\nwscraper import /path/to/sample.xml\nwscraper import /path/to/wikipedia.xml --name my_wp\n```\n\nSee `wscraper import -h`.\n\n### Check Wikipedia Resources\n\nIt can check Wikipedia corpus resources.\n\n```shell\nwscraper list\n```\n\noutput\n```text\nAvailable wikipedia:\n  - sample\n  - my_wp\n```\n\n### Switch Current Corpus\n\n```shell\nwscraper switch my_wp\n```\n\n### Check the Status of Current Corpus\n\n```shell\nwscraper status\n```\n\noutput\n```text\ncurrent: my_wp\n\nlanguage [default]: japanese\n```\n\n### Set Parameters for Current Corpus\n\nRequired parameters should be set for current corpus.\n\n```shell\nwscraper set --language english\n```\n\nparameters:\n- `language`\n\n### Unset Parameters\n\nYou can delete parameters by running following command.\n\n```shell\nwscraper unset --language\n```\n\n### Rename a Corpus Name\n\nYou can rename a corpus name from `$source` to `$target`.\n\n```shell\nwscraper rename $source $target\n```\n\n### Delete a Corpus\n\nWhen a corpus (example: `$target`) is unnecessary, it can be removed.\n\n```shell\nwscraper delete $target\n```\n\n## How to Work (Python)\n\nImporting iterator classes.\n\n```python\nfrom wscraper.analysis import *\n```\n\nYou can iterate pages of a corpus by writing this.\n\n```python\n# entry\nentry_iterator = EntryIterator()\n# You can specify corpus name and language.\n# If parameter is not given, current Wikipedia corpus is used.\n# >>> EntryIterator(name = \"sample\", language = \"japanese\")\nboth_iterator = BothIterator()\nredirection_iterator = RedirectionIterator()\n\nfor i, b in enumerate(both_iterator):\n    print(f\"both: {i}: {type(b)}\")\n\nfor i, e in enumerate(entry_iterator):\n    print(f\"entry {i}: {e.title} {len(e.mediawiki)}\")\n\nfor i, r in enumerate(redirection_iterator):\n    print(f\"redirection: {i}: {r.source} -> {r.target}\")\n```\n\nFor example, you can give iterator a ML model.\n\n```python\ndef to_words(x):\n    return x.split()\n\n# return word list for each iteration\niterator = ArticleIterator(tagger = to_words)\n# If you set `type = dict`, you can get records as dictionary\n# ex: { \"title\", \"ABC...\", \"article\": \"eval(to_words(article))\" }\n\n# Iterators:\n#   ArticleIterator\n#     - 1 page / record\n#     - dict keys: [\"title\", \"article\"]\n#   ParagraphIterator:\n#     - N page / record\n#     - Description like \"== A ==\" is delimiter of paragraphs.\n#     - dict keys: [\"page_title\", \"paragraph_title\", \"paragraph\"]\n\n# For example, gensim word2vec can interpret this iterator\n\n# from gensim.models.word2vec import Word2Vec\nWord2Vec(iterator)\n\n# You can concatenate iterators to train ML model using CombinedIterator.\nWord2Vec(CombinedIterator(iterator, another_iterator))\n```\n\n\n## License\n\nThe source code is licensed MIT.\n\nPlease check the file LICENSE.",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/tfull/wikipedia_scraper",
    "keywords": "Wikipedia",
    "license": "MIT License",
    "maintainer": "",
    "maintainer_email": "",
    "name": "wscraper",
    "package_url": "https://pypi.org/project/wscraper/",
    "platform": null,
    "project_url": "https://pypi.org/project/wscraper/",
    "project_urls": {
      "Homepage": "https://github.com/tfull/wikipedia_scraper"
    },
    "release_url": "https://pypi.org/project/wscraper/0.2.1/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "Scraping documents from a dump XML file of Wikipedia.",
    "version": "0.2.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14627559,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1fea71d6be7aba7dde6fb49922924b58ab4901a07cc0163238460ce29043f3eb",
          "md5": "f0a268fe0a6205b2a2e8e0214baa4cb2",
          "sha256": "5ce41a766f6ab4a518a9bbb98c517eb890b09f087cf8b85694300b390636ca5f"
        },
        "downloads": -1,
        "filename": "wscraper-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "f0a268fe0a6205b2a2e8e0214baa4cb2",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 14068,
        "upload_time": "2021-03-27T07:09:47",
        "upload_time_iso_8601": "2021-03-27T07:09:47.561779Z",
        "url": "https://files.pythonhosted.org/packages/1f/ea/71d6be7aba7dde6fb49922924b58ab4901a07cc0163238460ce29043f3eb/wscraper-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f3ed9f5378ee355093d8a0dfcd421be88ee94fdd7fb2c0e07fe097e880b76aa3",
          "md5": "07c2f159c795616bc4b35dc98e5f5265",
          "sha256": "656d1fd3abbe7596232d854b93d114b47d113b2b148ec45f180be9245b0bed07"
        },
        "downloads": -1,
        "filename": "wscraper-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "07c2f159c795616bc4b35dc98e5f5265",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 16750,
        "upload_time": "2021-04-06T12:45:52",
        "upload_time_iso_8601": "2021-04-06T12:45:52.972041Z",
        "url": "https://files.pythonhosted.org/packages/f3/ed/9f5378ee355093d8a0dfcd421be88ee94fdd7fb2c0e07fe097e880b76aa3/wscraper-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f3980ab215c4197763277fd56e4a9ba0f9dd25414adb1d204963acd8a4b2740a",
          "md5": "761e0fab5961d962a333ab06835b7cc8",
          "sha256": "62da482d02424dfb7dd1249d757e5bdc3304bd4cf2e4bddce51846a48e2f8047"
        },
        "downloads": -1,
        "filename": "wscraper-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "761e0fab5961d962a333ab06835b7cc8",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 19949,
        "upload_time": "2021-04-15T02:59:42",
        "upload_time_iso_8601": "2021-04-15T02:59:42.602743Z",
        "url": "https://files.pythonhosted.org/packages/f3/98/0ab215c4197763277fd56e4a9ba0f9dd25414adb1d204963acd8a4b2740a/wscraper-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8682207b7461e86a4a84a35f9718570137aa843ce19eb94efd52797fba576cce",
          "md5": "dfd75aece026a25e14f9f0d067bcaf9f",
          "sha256": "3e0549e2a37555307dd84d1f33b227d52ed22ad524ff5fe32679562e226a42eb"
        },
        "downloads": -1,
        "filename": "wscraper-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "dfd75aece026a25e14f9f0d067bcaf9f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 13269,
        "upload_time": "2021-10-25T13:20:29",
        "upload_time_iso_8601": "2021-10-25T13:20:29.096887Z",
        "url": "https://files.pythonhosted.org/packages/86/82/207b7461e86a4a84a35f9718570137aa843ce19eb94efd52797fba576cce/wscraper-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c6366bb0a7efcc971a18c4fb0e0c28c28416684f1c583a3a0b306b5ea2b49c08",
          "md5": "3c29ef7e91753d99a8228f67f6ea27f1",
          "sha256": "d34a725655ec16b8db5039d3fa678a2db2d5dd281b4255054deb377a0b4bc06e"
        },
        "downloads": -1,
        "filename": "wscraper-0.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "3c29ef7e91753d99a8228f67f6ea27f1",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 14606,
        "upload_time": "2021-11-06T17:14:31",
        "upload_time_iso_8601": "2021-11-06T17:14:31.120300Z",
        "url": "https://files.pythonhosted.org/packages/c6/36/6bb0a7efcc971a18c4fb0e0c28c28416684f1c583a3a0b306b5ea2b49c08/wscraper-0.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "05d08f361bd88a20bd742221bb319b7e8f8ce6383b31e502482f2a61b1b9e47c",
          "md5": "de29ba5631ce9c72719ab537422ca937",
          "sha256": "fb948a16e1d86691f85f930622368c0a625f8278aa620517830699811aba204b"
        },
        "downloads": -1,
        "filename": "wscraper-0.2.1.tar.gz",
        "has_sig": false,
        "md5_digest": "de29ba5631ce9c72719ab537422ca937",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 14605,
        "upload_time": "2022-08-02T13:50:36",
        "upload_time_iso_8601": "2022-08-02T13:50:36.088724Z",
        "url": "https://files.pythonhosted.org/packages/05/d0/8f361bd88a20bd742221bb319b7e8f8ce6383b31e502482f2a61b1b9e47c/wscraper-0.2.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "05d08f361bd88a20bd742221bb319b7e8f8ce6383b31e502482f2a61b1b9e47c",
        "md5": "de29ba5631ce9c72719ab537422ca937",
        "sha256": "fb948a16e1d86691f85f930622368c0a625f8278aa620517830699811aba204b"
      },
      "downloads": -1,
      "filename": "wscraper-0.2.1.tar.gz",
      "has_sig": false,
      "md5_digest": "de29ba5631ce9c72719ab537422ca937",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 14605,
      "upload_time": "2022-08-02T13:50:36",
      "upload_time_iso_8601": "2022-08-02T13:50:36.088724Z",
      "url": "https://files.pythonhosted.org/packages/05/d0/8f361bd88a20bd742221bb319b7e8f8ce6383b31e502482f2a61b1b9e47c/wscraper-0.2.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}