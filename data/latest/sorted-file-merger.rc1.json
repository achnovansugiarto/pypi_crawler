{
  "info": {
    "author": "Hakan Bogan",
    "author_email": "hb@hakanbogan.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# File Merger\r\n\r\n## How does it work?\r\nA command-line tool was developed for merging multiple sorted text files into a single, sorted output file. The tool supports three different strategies for merging files, depending on the size of the input files and the desired performance characteristics:\r\n\r\n**Basic strategy**: This strategy reads input files and lazily merge the input files, one element at a time and writes them to the output file. It is suitable for small inputs and performs all operations sequentially.\r\n\r\n**Async strategy**: This strategy splits the input files into chunks and processes each chunk in a separate coroutine using asyncio. This allows for concurrent execution of the file processing, but does not use multiple threads. The sorted results from each chunk are then written to intermediate files that are merged at the end. This approach can be more efficient than the basic strategy for larger inputs, and can help reduce memory usage compared to the parallel strategy.\r\n\r\n**Parallel strategy**: The parallel strategy uses multiprocessing to process each input file in a separate process. In this strategy, each input file is divided into chunks, and each chunk is processed by a separate subprocess in parallel. The results of the subprocesses are then combined at the end to create the final output file. The parallel strategy is suitable for very large inputs where the basic and async strategies may not be efficient due to the limitations of single-threaded or single-process approaches. By using parallel processing, this strategy can distribute the workload across multiple CPU cores, which can greatly improve the overall performance. The parallel strategy provides the best performance for very large inputs, while the async strategy offers a good compromise between performance and memory usage.\r\n\r\n### Merge Algorithm\r\n\r\n`heapq.merge` is a Python function that takes multiple sorted input iterables and merges them into a single sorted iterable. It works by creating a heap of the first item from each iterable, and repeatedly popping the smallest item from the heap and adding it to the output. When an iterable is exhausted, its next item is automatically pulled from the next iterable in the list. This process continues until all input iterables have been exhausted and the entire output is produced. The algorithm used by heapq.merge is a variation of the merge step in merge sort. It has a time complexity of O(n log k), where n is the total number of items in all input iterables and k is the number of input iterables. It does not hold all items in memory at once. It uses a heap data structure to merge the items from the input iterables one at a time, only keeping a small number of items in memory at any given time. This means that heapq.merge() is memory-efficient and can handle very large iterables without running out of memory. However, heapq.merge is a blocking operation that is run synchronously and cannot be run asynchronously.\r\n\r\n         Input Iterable 1               Input Iterable 2           Input Iterable 3\r\n          ┌───────────┐                 ┌─────────┐                ┌───────────┐\r\n          │     A     │                 │   C     │                │     F     │\r\n          ├───────────┤                 ├─────────┤                ├───────────┤\r\n          │     B     │                 │   D     │                │     H     │\r\n          ├───────────┤                 ├─────────┤                ├───────────┤\r\n          │     E     │                 │   G     │                │     J     │\r\n          └───────────┘                 └─────────┘                └───────────┘\r\n\r\n                                       heapq.merge()\r\n                                            │\r\n                                            ▼\r\n                                   ┌─────────────────┐\r\n                                   │ Output Iterable │\r\n                                   └─────────────────┘\r\n                                            │\r\n                                            ▼\r\n          Output Iterable:    A     B     C     D     E     F     G     H     J\r\n\r\nIn general, the solution should be efficient and scalable for most use cases. The basic strategy is suitable for small inputs, while the async and parallel strategies provide improved performance for larger inputs. The parallel strategy provides the best performance, but requires more memory and may not be suitable for extremely large inputs. The async strategy provides a good compromise between performance and memory usage, and should be suitable for most inputs. However, the performance of each strategy will depend on the specifics of the input data, so it is always a good idea to test different strategies with different inputs to find the best approach for a given situation.\r\n\r\n### Performance Comparison\r\n\r\n| Input File Size | Number of Files | Basic         | Async  | Parallel |\r\n| --------------- | --------------- | ------------- | ------ | -------- |\r\n| 16 KB           | 5               | 0.01s         | 0.01s  | 0.35s    |\r\n| 1.27 MB         | 500             | 0.4s          | 0.25s  | 0.59s    |\r\n| 11.4 MB         | 4000            | 1.89s         | 1.25s  | 0.81s    |\r\n| 39 MB           | 10000           | 10.51s        | 4.67s  | 3.12s    |\r\n| 195 MB          | 50000           | 73.96s        | 33.70s | 13.43s   |\r\n| 1 GB            | 250000          | 514.64s       | 150.29s| 79.70s   |\r\n\r\n*Default parameters are used in performance measurements. File and Line chunk sizes are 1024, number of processes is 4.*\r\n\r\n---\r\n## Instructions\r\n\r\nA directory containing hundreds of files is given. Each file contains a sorted list of hundreds of words, one word per line.\r\n\r\nA python command line tool that aims to find an efficient and scalable solution that combines the contents of all files into a single sorted file.\r\nAn example output:\r\n\r\n```\r\nfilemerger -i input_files_dir\r\n```\r\n\r\n1. word1\r\n2. word2\r\n......\r\n10. word10\r\n\r\n---\r\n\r\n## Package Installation\r\n\r\nThe application can be installed with the following command:\r\n\r\n```bash\r\npip install sorted-file-merger\r\n```\r\n\r\n*Note: Package installation is recommended. But it is not necessary to run the application*.\r\n\r\n---\r\n\r\n## Creating a Fake Dataset (optional)\r\nYou can create fake dataset for testing or development. The `faker` library is needed for this. If you have installed the `filemerger` package, it will come with faker.\r\n\r\nOtherwise you need to run following command first.\r\n```\r\npip install faker==17.0.0\r\n```\r\n\r\nExample fake dataset creation code is as follows.\r\n\r\n```\r\npython setup.py generate_fake_dataset --num-files 10 --min-words-per-file 100 --max-words-per-file 500 --output-dir dataset/small_dataset\r\n```\r\n\r\n\r\n---\r\n## Usage\r\n\r\n### With Installation\r\n\r\nOnce `filemerger` is installed, it can be run in one of two ways.\r\n\r\n```filemerger --help```\r\n\r\n## `filemerger` CLI\r\n\r\nCommand line tool has a help feature that shows all the operations that can be done.\r\n\r\n```\r\n$ filemerger --help\r\nusage: file_merger.py [-h] [-i INPUT_DIR] [-o OUTPUT_DIR] [-f FILENAME] [-p] [-np N_OF_PROCESS] [-cf CHUNK_FILE] [-cl CHUNK_LINE]\r\n\r\nA tool that merges all input files into a single sorted output file\r\n\r\noptions:\r\n  -h, --help            show this help message and exit\r\n  -i INPUT_DIR, --input-dir INPUT_DIR\r\n                        A directory of files to be merged.\r\n  -o OUTPUT_DIR, --output-dir OUTPUT_DIR\r\n                        A directory where the merged file will be saved. DEFAULT <current-directory>\r\n  -f FILENAME, --filename FILENAME\r\n                        A name of output file. DEFAULT output.txt\r\n  -p, --parallel        Use multiprocessing for merging operations. DEFAULT False\r\n  -np N_OF_PROCESS, --n_of_process N_OF_PROCESS\r\n                        Number of processes to use. DEFAULT 4\r\n  -cf CHUNK_FILE, --chunk-file CHUNK_FILE\r\n                        Number of files to process at once. DEFAULT 1024\r\n  -cl CHUNK_LINE, --chunk-line CHUNK_LINE\r\n                        Number of lines to process at once. DEFAULT 1024\r\n```\r\n\r\n---\r\n\r\n## Examples\r\n\r\n### Merge Multiple Files in Input Folder\r\nConsider the input files in the following structure.\r\n```\r\ninput_dir/\r\n    ├── file1.dat\r\n    ├── file2.dat\r\n    ├── file3.dat\r\n    ├── file4.dat\r\n    └── file5.dat\r\n```\r\nThe folder directory where the files are located is given as Input Directory.\r\n```\r\n$ filemerger -i input_dir\r\n\r\nOperation is successful. The output file has been saved here: /path/to/package/folder/output.txt\r\n```\r\n---\r\n### Merge Multiple Files in Compressed File\r\nCompressed file directory can be given as Input Directory. In this case, the files in the compressed file are extracted to the folder created in the same directory and the directory of that folder is given.\r\n```\r\n$ filemerger -i compressed_file_dir\r\n\r\nOperation is successful. The output file has been saved here: /path/to/package/folder/output.txt\r\n```\r\n\r\n---\r\n### Custom Output Path\r\nSpecify a custom directory.\r\n```\r\n$ filemerger -i input_dir -o output_dir\r\n\r\nOperation is successful. The output file has been saved here: /path/to/custom/folder/output.txt\r\n```\r\n---\r\n### Custom Output File Name\r\n\r\n```\r\n$ filemerger -i input_dir -o output_dir -f merged_file.txt\r\n\r\nOperation is successful. The output file has been saved here: /path/to/custom/folder/merged_file.txt\r\n```\r\n---\r\n### Use Multiprocessing\r\nUse multiple processes during the merge process\r\n```\r\n$ filemerger -i input_dir -p\r\n\r\nOperation is successful. The output file has been saved here: /path/to/package/folder/output.txt\r\n```\r\n---\r\n### Use Multiprocessing with Custom Number of Processes\r\nUse custom number of processes\r\n```\r\n$ filemerger -i input_dir -p -np 8\r\n\r\nOperation is successful. The output file has been saved here: /path/to/package/folder/output.txt\r\n```\r\n---\r\n### Custom File Chunk Size\r\nSet custom number of files to process at once\r\n```\r\n$ filemerger -i input_dir -cf 100\r\n\r\nOperation is successful. The output file has been saved here: /path/to/package/folder/output.txt\r\n```\r\n---\r\n### Custom Line Chunk Size\r\nSet custom number of lines to process at once\r\n```\r\n$ filemerger -i input_dir -cl 250\r\n\r\nOperation is successful. The output file has been saved here: /path/to/package/folder/output.txt\r\n```\r\n---\r\n### Attempting to Enter an Invalid Input Directory\r\nIf the user enters an invalid input directory, the following error will be raised.\r\n\r\n```\r\n$ filemerger -i invalid_dir\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\hboga\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\\filemerger-script.py\", line 33, in <module>\r\n    sys.exit(load_entry_point('filemerger==1.0.0', 'console_scripts', 'filemerger')())\r\n  File \"C:\\Users\\hboga\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\merge_files\\main.py\", line 64, in cli_main\r\n    merge(\r\n  File \"C:\\Users\\hboga\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\merge_files\\main.py\", line 12, in merge\r\n    input_dir = check_valid_path(input_dir)\r\n  File \"C:\\Users\\hboga\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\merge_files\\utils.py\", line 36, in check_valid_path\r\n    raise ValueError(f\"Please enter a valid path: {path}\")\r\nValueError: Please enter a valid path: invalid_dir\r\n```\r\n---\r\n### Attempting to Not Enter a Input Directory\r\nIf the user doesn't enter any input directory, the following error will be raised.\r\n```\r\n$ filemerger\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\hboga\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\\filemerger-script.py\", line 33, in <module>\r\n    sys.exit(load_entry_point('filemerger==1.0.0', 'console_scripts', 'filemerger')())\r\n  File \"C:\\Users\\hboga\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\merge_files\\main.py\", line 64, in cli_main\r\n    merge(\r\n  File \"C:\\Users\\hboga\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\merge_files\\main.py\", line 12, in merge\r\n    input_dir = check_valid_path(input_dir)\r\n  File \"C:\\Users\\hboga\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\merge_files\\utils.py\", line 10, in check_valid_path\r\n    raise ValueError(\r\nValueError: Path cannot be None. Please enter a valid path: None\r\n```\r\n---\r\n\r\n## Tests\r\n\r\nThe core functions of `filemerger` have tests.\r\n\r\n```\r\n$ python setup.py test\r\nrunning test\r\nrunning egg_info\r\nwriting filemerger.egg-info\\PKG-INFO\r\nwriting dependency_links to filemerger.egg-info\\dependency_links.txt\r\nwriting entry points to filemerger.egg-info\\entry_points.txt\r\nwriting top-level names to filemerger.egg-info\\top_level.txt\r\nreading manifest file 'filemerger.egg-info\\SOURCES.txt'\r\nwriting manifest file 'filemerger.egg-info\\SOURCES.txt'\r\nrunning build_ext\r\n(running tests...)\r\n\r\n----------------------------------------------------------------------\r\nRan 30 tests in 0.143s\r\n\r\nOK\r\n```\r\n\r\n---\r\n\r\n## Coverage Report\r\n\r\nYou can see how much of the written unit tests cover the project code.\r\n\r\nIf you have installed the `filemerger` package, it will come with coverage package.\r\n\r\nOtherwise you need to run following command first.\r\n```\r\npip install coverage==7.1.0\r\n```\r\n\r\nRun following command to generage coverage report.\r\n```\r\npython setup.py coverage\r\n```\r\n\r\nCurrent coverage rate is 92%\r\n\r\n| Module                          | statements | missing | excluded | coverage |\r\n|---------------------------------|------------|---------|----------|----------|\r\n| merge_files\\__init__.py         |          1 |       0 |        0 |     100% |\r\n| merge_files\\__main__.py         |          3 |       3 |        0 |       0% |\r\n| merge_files\\main.py             |         34 |      10 |        0 |      71% |\r\n| merge_files\\mergers\\async_.py   |         20 |       0 |        0 |     100% |\r\n| merge_files\\mergers\\base.py     |         50 |       0 |        0 |     100% |\r\n| merge_files\\mergers\\basic.py    |          4 |       0 |        0 |     100% |\r\n| merge_files\\mergers\\parallel.py |         31 |       0 |        0 |     100% |\r\n| merge_files\\utils.py            |         31 |       0 |        0 |     100% |\r\n| **Total**                       |    **174** |  **13** |    **0** |  **93%** |\r\n\r\n---\r\n\r\n## Improvements for the Future\r\n\r\n1. **Compression:** The ability to compress input files and decompress the merged output file can greatly reduce storage and transfer costs for large files.\r\n2. **User-friendly CLI:** The current command-line interface (CLI) is suitable for experienced users, but it can be improved for ease of use by novice users. Adding more descriptive error messages, help texts, and examples could make the tool more accessible to a wider range of users.\r\n3. **Progress monitoring:** Providing a progress bar or other status updates during processing can help users to better understand the progress of the tool and make it more user-friendly.\r\n4. **Integration with other tools:** Integrating the tool with other tools, such as a file transfer or backup tool, can provide a more complete solution for users.\r\n5. **Performance profiling and optimization:** Conducting performance profiling and optimization on the codebase can help identify and fix bottlenecks, and further improve the performance of the tool.\r\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "sorted-file-merger",
    "package_url": "https://pypi.org/project/sorted-file-merger/",
    "platform": null,
    "project_url": "https://pypi.org/project/sorted-file-merger/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/sorted-file-merger/0.1.0/",
    "requires_dist": [
      "faker (==17.0.0)",
      "coverage (==7.1.0)"
    ],
    "requires_python": ">=3.6",
    "summary": "A CLI tool to merge multiple sorted files into a single sorted output file.",
    "version": "0.1.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17130106,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8beb01a1ba792864feed1df881ee2cf990b2d7d2e23f736bb4754a98dc1569f4",
          "md5": "0f2d6b79fde8406bdacc927a08a29fb2",
          "sha256": "aec8b4322733029dcd7dac24cea121ee7a8f3bd4e28bef49f08b547327eb4126"
        },
        "downloads": -1,
        "filename": "sorted_file_merger-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0f2d6b79fde8406bdacc927a08a29fb2",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 12598,
        "upload_time": "2023-03-02T16:20:02",
        "upload_time_iso_8601": "2023-03-02T16:20:02.153489Z",
        "url": "https://files.pythonhosted.org/packages/8b/eb/01a1ba792864feed1df881ee2cf990b2d7d2e23f736bb4754a98dc1569f4/sorted_file_merger-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "823e693ad17bbe7eb74a172ecb4db89f423b6f632ce1893953ae7b929cae8c8f",
          "md5": "106c056b0a2e85afdeb09fd31d2c2959",
          "sha256": "b5c63da089139b532713decb91f3bff6cece7f6556b1309f506e3a7dcc5be22d"
        },
        "downloads": -1,
        "filename": "sorted-file-merger-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "106c056b0a2e85afdeb09fd31d2c2959",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 18969,
        "upload_time": "2023-03-02T16:20:04",
        "upload_time_iso_8601": "2023-03-02T16:20:04.508558Z",
        "url": "https://files.pythonhosted.org/packages/82/3e/693ad17bbe7eb74a172ecb4db89f423b6f632ce1893953ae7b929cae8c8f/sorted-file-merger-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "8beb01a1ba792864feed1df881ee2cf990b2d7d2e23f736bb4754a98dc1569f4",
        "md5": "0f2d6b79fde8406bdacc927a08a29fb2",
        "sha256": "aec8b4322733029dcd7dac24cea121ee7a8f3bd4e28bef49f08b547327eb4126"
      },
      "downloads": -1,
      "filename": "sorted_file_merger-0.1.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "0f2d6b79fde8406bdacc927a08a29fb2",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 12598,
      "upload_time": "2023-03-02T16:20:02",
      "upload_time_iso_8601": "2023-03-02T16:20:02.153489Z",
      "url": "https://files.pythonhosted.org/packages/8b/eb/01a1ba792864feed1df881ee2cf990b2d7d2e23f736bb4754a98dc1569f4/sorted_file_merger-0.1.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "823e693ad17bbe7eb74a172ecb4db89f423b6f632ce1893953ae7b929cae8c8f",
        "md5": "106c056b0a2e85afdeb09fd31d2c2959",
        "sha256": "b5c63da089139b532713decb91f3bff6cece7f6556b1309f506e3a7dcc5be22d"
      },
      "downloads": -1,
      "filename": "sorted-file-merger-0.1.0.tar.gz",
      "has_sig": false,
      "md5_digest": "106c056b0a2e85afdeb09fd31d2c2959",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 18969,
      "upload_time": "2023-03-02T16:20:04",
      "upload_time_iso_8601": "2023-03-02T16:20:04.508558Z",
      "url": "https://files.pythonhosted.org/packages/82/3e/693ad17bbe7eb74a172ecb4db89f423b6f632ce1893953ae7b929cae8c8f/sorted-file-merger-0.1.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}