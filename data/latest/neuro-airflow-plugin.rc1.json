{
  "info": {
    "author": "Neu.ro Team",
    "author_email": "team@neu.ro",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Environment :: Plugins",
      "Intended Audience :: Developers",
      "Intended Audience :: Information Technology",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: Apache Software License",
      "License :: Other/Proprietary License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Topic :: Scientific/Engineering :: Artificial Intelligence",
      "Topic :: Software Development",
      "Topic :: Utilities"
    ],
    "description": "# Neu.ro Airflow plugin\n\nThis package helps you execute your ML workloads on [neu.ro](https://neu.ro/) platform from Airflow environment.\n\nAlso, take a look at our [CLI reference](https://docs.neu.ro/references/cli-reference) and [Python API reference](https://neuromation-sdk.readthedocs.io/en/latest/).\n\n## Environment\n- Python 3.6+\n- apache-airflow >= 1.10.x\n- Neuromation >= 20.4.6\n\n## Installation\n\nThe plugin is written to automatically register with Airflow, so all you have to do is install it into your Python environment:\n\n```\npip install neuro-airflow-plugin\n```\n\n## Usage\n\nBefore start you need to get a Neuro token by using CLI command:\n\n```\nneuro config show-token\n```\n\nand set up a Neuro Connection (`neuro_default` by default) in Airflow:\n\n```\nairflow connections --add \\\n    --conn_id neuro_default2 \\\n    --conn_type \"neuro\" \\\n    --conn_extra '{\"token\": \"Put your Token here...\"}'\n```\n\nApart from `token` you can also provide those fields as part of extra json:\n\n* `cluster` - name of the cluster used for compute scheduling. Default cluster will be used if not provided.\n* `api_url` - entry URL for Neuro Platform. Only needed for custom clusters.\n\nYou can set up the connection from UI interface as well, just put the same JSON document\ninto `Extra` form field. Connection type does not matter, so you can pick any that the UI allows.\n\nFor more information on how to set up connections in Airflow see\n[Managing Connections](https://airflow.apache.org/docs/stable/howto/connection/index.html).\n\n### NeuroRunOperator\n\nRuns a Job in the Neuro Platform. Example usage:\n\n```python\nfrom airflow.operators.neuro import NeuroRunOperator\n\n\nrun = NeuroRunOperator(\n    task_id=\"small-deeds\",\n\n    job_command=\"echo 'Big things start from small deeds'\",\n    job_image=\"ubuntu:{{ var.value.ubuntu_tag }}\",\n    job_resources_preset=\"{% if var.value.use_large_cpu %}cpu-large{% else %}cpu-small{% endif %}\"\n)\n```\n\nFor more usage examples see `examples/dags` folder of the repository.\n\n**Operator arguments**\n\n* `job_command` **str** *Required* - Command to be executed in the Job. If you need to override the\n  entrypoint of an image, see `job_entrypoint` instead.\n* `job_image` **str** *Required* - Container image used for the Job. Name can be either a docker image\n  name hosted on an external public repository or a Neuro image specified by `image://` scheme.\n* `job_name` **str** - Optional job name. Note that creating 2 running jobs with the same name by the\n  same user is forbidden.\n* `job_volumes` **list** - List of strings describing a volume mount or `neuromation.Volume` objects.\n  String description consists of 3 parts separated by column: *storage URI*, *mount path*, *mount mode*.\n  For example: `storage:my-project:/var/storage:ro`.\n* `job_resources_preset` **str** - Predefined resource configuration (to see available values, run `neuro config show`)\n* `job_resources` **Resources** - Custom resource configuration. See\n  [Python API reference](https://neuromation-sdk.readthedocs.io/en/latest/jobs_reference.html#resources)\n  for details.\n* `job_is_preemptible` **bool** - Whether the Job may be run on a preemptible, or also known as Spot instance.\n  Is only used with custom resource configuration.\n* `job_extshm` **bool** - Request extended '/dev/shm' space. Defaults to `True` and is only used with\n  predefined resource configuration.\n* `job_tags` **list** - List of string tags to mark the Job with. Can later be used for filtering, etc.\n* `job_description` **str** - Optional job description in free format.\n* `job_lifespan` **float** - Optional job run-time limit in seconds. Is unlimited by default.\n* `job_environ` **dict** - Environment variables to run the Job with. Jinja template support is only provided for values,\n  not for keys, see more details below.\n* `job_entrypoint` **str** - Override ENTRYPOINT of the container image.\n* `job_http_port` **str** - Enable HTTP port forwarding to specified container port. If used you can access it from\n  a custom link definition on the Task panel in Airflow UI (see\n  [Airflow docs](https://airflow.apache.org/docs/stable/howto/define_extra_link.html?highlight=link)\n  for details on how it works). Disabled by default.\n* `job_http_auth` **bool** - Disable Neuro authentication on the exposed port in `job_http_port`.\n* `job_tty` **bool** - Allocate a TTY for the Container.\n* `job_detach` **bool** - Detach after starting the job. If detached Job logs will not be viewable in Airflow interface,\n  but the job will not consume Airflow worker slot. Defaults to `True`.\n* `raise_on_errno` **bool** - Raise an error if job returns a non-zero exit code. Ignored if `job_detach` is `True`. Default to `True`.\n* `neuro_conn_id` **bool** - Name of the connection to use for Neuro authentication. Defaults to `neuro_default`.\n\nSee also the `neuro run` reference in [CLI documentation](https://docs.neu.ro/references/cli-reference/job#run)\n\n**Jinja2 template fields**\n\nAirflow supports passing custom attributes and dynamic definitions using Jinja templating fields. This operator\nsupports templating on the following fields:\n\n* `job_command`\n* `job_image`\n* `job_volumes`\n* `job_name`\n* `job_resources_preset`\n* `job_tags`\n* `job_environ`\n* `job_entrypoint`\n* `job_description`\n* `job_http_port`\n* `neuro_conn_id`\n\n**XCom exports**\n\nThe operator exports 2 XCom values: `return_value` (default in Airflow for query) and `assigned_job`. Both are\nJSON documents with the following fields:\n\n* `id` **str** - Job ID assigned by Neuro on start.\n* `exit_code` **int** - Command return code if the Job already finished.\n* `status` *str* - One of job statuses: `pending`, `running`, `succeeded`, `failed` or `unknown`.\n* `http_url` *str* - URL of the exposed HTTP port if `job_http_port` is used.\n\n### NeuroJobStatusSensor\n\nWait for a Job to be completed or any other status transition to happen. Example usage:\n\n```python\nfrom airflow.sensors.neuro import NeuroJobStatusSensor\n\n\nwait = NeuroJobStatusSensor(\n    task_id=\"wait_close\",\n    job_id=\"{{ task_instance.xcom_pull(task_ids='small-deeds')['id'] }}\",  # noqa\n    poke_interval=5,\n    timeout=10 * 60,\n)\n```\n\n**Operator arguments**\n\n* `job_id` **str** - Job ID to query for status updates.\n* `job_statuses` **list** - List\n  [JobStatus](https://neuromation-sdk.readthedocs.io/en/latest/jobs_reference.html#jobstatus)\n  enum values to wait for.\n* `neuro_conn_id` **str** - Name of the connection to use for Neuro authentication. Defaults to `neuro_default`.\n\n**Jinja2 template fields**\n\n* `job_id`\n\n**XCom exports**\n\nDoes not export any XCom values.\n\n\n### NeuroHook\n\nIn some cases you may need to access other functionalities of the platform. This can be done using the NeuroHook.\nFor example:\n\n```python\nimport yarl\nfrom neuromation.api import ResourceNotFound\n\nfrom airflow.hooks.neuro import NeuroHook\nfrom airflow.operators.python_operator import BranchPythonOperator\n\n\ndef check_model(templates_dict, **kw):\n    hook = NeuroHook()\n    with hook:\n        try:\n            hook.run(\n                hook.client.storage.stat(\n                    yarl.URL(\"storage:\" + templates_dict[\"model_path\"])\n                )\n            )\n            return \"process_with_model\"\n        except ResourceNotFound:\n            return \"process_without_model\"\n\n\ncheck_model = BranchPythonOperator(\n    task_id=\"check_model_exists\",\n    python_callable=check_model,\n    provide_context=True,\n    templates_dict={\"model_path\": \"{{ var.value.project_home }}/model.pth\"},\n)\n```\n\nExplore the [Python SDK](https://neuromation-sdk.readthedocs.io/en/latest/) for more features of the Platform.\n\n\n",
    "description_content_type": "text/markdown; charset=UTF-8; variant=GFM",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/neuromation/platform-airflow-plugin",
    "keywords": "",
    "license": "Apache License, version 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "neuro-airflow-plugin",
    "package_url": "https://pypi.org/project/neuro-airflow-plugin/",
    "platform": "",
    "project_url": "https://pypi.org/project/neuro-airflow-plugin/",
    "project_urls": {
      "Homepage": "https://github.com/neuromation/platform-airflow-plugin"
    },
    "release_url": "https://pypi.org/project/neuro-airflow-plugin/0.0.1/",
    "requires_dist": [
      "apache-airflow (<2.0.0)",
      "neuromation (>=20.4.6)",
      "typing-extensions (>=3.7.4)"
    ],
    "requires_python": ">=3.7",
    "summary": "Neu.ro Airflow plugin",
    "version": "0.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 7374462,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "47040c7ea05ddc5ef694d72e80ea66b614830823365545482e9a14c2a04b9ff3",
          "md5": "61b09e9fc0a89d8ef1208f30fd3d2fa4",
          "sha256": "136af84892fadebe7f04b6cbf834f01419d05b040061611259def6bb5587949e"
        },
        "downloads": -1,
        "filename": "neuro_airflow_plugin-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "61b09e9fc0a89d8ef1208f30fd3d2fa4",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 17278,
        "upload_time": "2020-06-01T22:47:02",
        "upload_time_iso_8601": "2020-06-01T22:47:02.246263Z",
        "url": "https://files.pythonhosted.org/packages/47/04/0c7ea05ddc5ef694d72e80ea66b614830823365545482e9a14c2a04b9ff3/neuro_airflow_plugin-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4f268f6d1f88c54a917117c154ceb21b72b92e6bf8ab1a202755a9bf8ee5ac74",
          "md5": "5add455cbdce851de9656afbb668f589",
          "sha256": "2d6ddf716f0026ce043808ac1f43c3394f18ff54b6b5e9abb7f88cc39c84ed00"
        },
        "downloads": -1,
        "filename": "neuro-airflow-plugin-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "5add455cbdce851de9656afbb668f589",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 18874,
        "upload_time": "2020-06-01T22:47:04",
        "upload_time_iso_8601": "2020-06-01T22:47:04.902547Z",
        "url": "https://files.pythonhosted.org/packages/4f/26/8f6d1f88c54a917117c154ceb21b72b92e6bf8ab1a202755a9bf8ee5ac74/neuro-airflow-plugin-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "47040c7ea05ddc5ef694d72e80ea66b614830823365545482e9a14c2a04b9ff3",
        "md5": "61b09e9fc0a89d8ef1208f30fd3d2fa4",
        "sha256": "136af84892fadebe7f04b6cbf834f01419d05b040061611259def6bb5587949e"
      },
      "downloads": -1,
      "filename": "neuro_airflow_plugin-0.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "61b09e9fc0a89d8ef1208f30fd3d2fa4",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 17278,
      "upload_time": "2020-06-01T22:47:02",
      "upload_time_iso_8601": "2020-06-01T22:47:02.246263Z",
      "url": "https://files.pythonhosted.org/packages/47/04/0c7ea05ddc5ef694d72e80ea66b614830823365545482e9a14c2a04b9ff3/neuro_airflow_plugin-0.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "4f268f6d1f88c54a917117c154ceb21b72b92e6bf8ab1a202755a9bf8ee5ac74",
        "md5": "5add455cbdce851de9656afbb668f589",
        "sha256": "2d6ddf716f0026ce043808ac1f43c3394f18ff54b6b5e9abb7f88cc39c84ed00"
      },
      "downloads": -1,
      "filename": "neuro-airflow-plugin-0.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "5add455cbdce851de9656afbb668f589",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 18874,
      "upload_time": "2020-06-01T22:47:04",
      "upload_time_iso_8601": "2020-06-01T22:47:04.902547Z",
      "url": "https://files.pythonhosted.org/packages/4f/26/8f6d1f88c54a917117c154ceb21b72b92e6bf8ab1a202755a9bf8ee5ac74/neuro-airflow-plugin-0.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}