{
  "info": {
    "author": "Charlie Masters",
    "author_email": "cm2435@bath.ac.uk",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# CodeClarity- Code Embeddings Made Easy\n\n# About CodeClarity\n\nThis repository contains [CodeClarity] a lightweight app for creating contextual embeddings of source code in a format that is optimized and designed with code search and understanding.\nin mind. This repository is part of a larger application providing a free exploration into the documatic codesearch tools capabilities. \n\n## Installation\n\nWe recommend **Python 3.7** or higher, **[PyTorch 1.6.0](https://pytorch.org/get-started/locally/)** or higher and **[transformers v4.6.0](https://github.com/huggingface/transformers)** or higher. The code does **not** work with Python 2.\n**Install with pip (not currently live, coming soon.)**\n\nInstall the *codclarity* with `pip`:\n\n```\npip install -U sentence-transformers\n```\n\n**Install from sources**\n\nAlternatively, you can also clone the latest version from the [repository](https://github.com/DocumaticAI/CodeClarity) and install it directly from the source code:\n\n````\npip install -e .\n```` \n\n**PyTorch with CUDA**\n\nIf you want to use a GPU / CUDA, you must install PyTorch with the matching CUDA Version. Follow\n[PyTorch - Get Started](https://pytorch.org/get-started/locally/) for further details how to install PyTorch.\n\n\n## Getting Started\nFirst download a pretrained code model.\n\n````python\nfrom encoder import CodeEmbedder\nmodel = CodeEmbedder(base_model = \"microsoft/unixcoder-base\")\n````\n\nThen provide some code snippits to the model. These can be full functions that could \nbe parsed by an Abstract Syntax Tree, or small snippits.\n\n````python\ncode_snippits = ['def read_csvs(dir) : return [pd.read_csv(fp) for fp in os.listdir(dir)]',\n    \"def set_pytorch_device(): return torch.device('cuda') if torch.cuda.is_available() else 'cpu\", \n    'read file from disk into pandas dataframe']\ncode_embeddings = model.encode(code_snippits)\n````\n\nAnd that's it! We now have a list of returned embeddings of default type numpy array.\n\n````python\nfor code, embedding in zip(code_snippits, code_embeddings):\n    print(\"Sentence:\", code)\n    print(\"Embedding:\", embedding)\n    print(\"\")\n````\n\n# API Drop in \nThis project additionally impliments a docker container that serves a python REST api with the package running in it to serve a given model. to automatically build the container with any of the supported models for code search by running the following \n\n```\ngit clone https://github.com/DocumaticAI/code-embeddings-api.git \ncd api && bash ./setup.sh\n```\n\nEqually, to run the API outside the docker container, just clone the repository, navigate to the API folder and run the API file directly \n```\ngit clone https://github.com/DocumaticAI/code-embeddings-api.git \npip install -r requirements-dev.txt\ncd api\npython predictor.py\n```\n\n## Pre-Trained Models\n\nWe provide implimentations of a range of code embedding models that are currently the state of the art in various tasks, including code semantic search, code clustering, code program detection, synthesis and more.  Some models are general purpose models, while others produce embeddings for specific use cases. Pre-trained models can be loaded by just passing the model name: `CodeEmbedder('model_name')`.\n\n## Currently supported models\n- [CodeBERT (base model): A Pre-Trained Model for Programming and Natural Languages](https://huggingface.co/microsoft/codebert-base)\n- [CodeBERT (python finetuned on codesearchnet corpus): A Pre-Trained Model for Programming and Natural Languages](https://huggingface.co/documatic/codebert-python-finetuned)\n- [UniXcoder (base model): Unified Cross-Modal Pre-training for Code Representation](https://huggingface.co/microsoft/unixcoder-base)\n- [UniXcoder (9 language varient): Unified Cross-Modal Pre-training for Code Representation](https://huggingface.co/microsoft/unixcoder-base-nine)\n- [UniXcoder (unimodal varient): Unified Cross-Modal Pre-training for Code Representation](https://huggingface.co/microsoft/unixcoder-base-unimodal)\n- [InCoder 1B parameter model: A Generative Model for Code Infilling and Synthesis](https://huggingface.co/facebook/incoder-1B)\n- [InCoder 6B parameter model: A Generative Model for Code Infilling and Synthesis](https://huggingface.co/facebook/incoder-6B)\n\n\n## Internals of docker API\n\nCodeClarity is designed to be a simple, modular dockerized python application that can be used to optain dense vector representations of natrual language code queries, and source code jointly to empower semantic search of codebases. \n\nIt is comprised of a lightweight, async fastapi application running on a guicorn webserver. On startup, any of the supported models will be injected into the container, converted to an optimized serving format, and run on a REST API. \n\nCodeClarity automatically handles checking for supported languages for code models, dynamic batching of both code and natrual language snippits and conversions of code models to torchscript all in an asyncronous manner! \n\n\n## <a name=\"help\"></a>Publications\n\nThe following papers are implimented or used heavily in this repo and this project would not be possible without their work:\n\n- [CodeBERT: A Pre-Trained Model for Programming and Natural Languages](https://arxiv.org/abs/2002.08155)\n- [UniXcoder: Unified Cross-Modal Pre-training for Code Representation](https://arxiv.org/abs/2203.03850) (EMNLP 2020)\n- [InCoder: A Generative Model for Code Infilling and Synthesis](https://arxiv.org/abs/2204.05999)\n- [A Conversational Paradigm for Program Synthesis](https://arxiv.org/pdf/2203.13474.pdf)\n- [CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation](https://github.com/salesforce/CodeT5) (EMNLP 2021)\n\n\n# About Documatic\n\n[Documatic](https://www.documatic.com/) is the company that deliversa more efficient codebase in 5 minutes. While you focus on coding, Documatic handles, creates and deploys the documentation so it's always up to date.\n\n\n## <a name=\"help\"></a>Getting help\n\nIf you have any questions about, feedback for or a problem with Codeclarity:\n\n- Read [documatic website](https://www.documatic.com/).\n- Sign up for the [documatic Waitlist](https://documatic-website.vercel.app/waitlist).\n- [File an issue or request a feature](https://github.com/DocumaticAI/Roadmap).\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/DocumaticAI/CodeClarity",
    "keywords": "sentence,embedding,code,search,contrastive,nlp,deep_learning,semantic",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "codeclarity",
    "package_url": "https://pypi.org/project/codeclarity/",
    "platform": null,
    "project_url": "https://pypi.org/project/codeclarity/",
    "project_urls": {
      "Homepage": "https://github.com/DocumaticAI/CodeClarity"
    },
    "release_url": "https://pypi.org/project/codeclarity/0.1/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "An embedding tool for all state of the art code language models",
    "version": "0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14849649,
  "releases": {
    "0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5b4fd4118c2ca7fbdc807520cafb96f606d36c8452b743d5eaa8524ce775720b",
          "md5": "b693b6d8438154fa8f98af4293e35e3d",
          "sha256": "96ed569369ba2d5f9036dc90bd253553739060d3e938a6b8ff8498392f3e5ac6"
        },
        "downloads": -1,
        "filename": "codeclarity-0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "b693b6d8438154fa8f98af4293e35e3d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 3926,
        "upload_time": "2022-08-23T14:21:36",
        "upload_time_iso_8601": "2022-08-23T14:21:36.447663Z",
        "url": "https://files.pythonhosted.org/packages/5b/4f/d4118c2ca7fbdc807520cafb96f606d36c8452b743d5eaa8524ce775720b/codeclarity-0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "5b4fd4118c2ca7fbdc807520cafb96f606d36c8452b743d5eaa8524ce775720b",
        "md5": "b693b6d8438154fa8f98af4293e35e3d",
        "sha256": "96ed569369ba2d5f9036dc90bd253553739060d3e938a6b8ff8498392f3e5ac6"
      },
      "downloads": -1,
      "filename": "codeclarity-0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "b693b6d8438154fa8f98af4293e35e3d",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 3926,
      "upload_time": "2022-08-23T14:21:36",
      "upload_time_iso_8601": "2022-08-23T14:21:36.447663Z",
      "url": "https://files.pythonhosted.org/packages/5b/4f/d4118c2ca7fbdc807520cafb96f606d36c8452b743d5eaa8524ce775720b/codeclarity-0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}