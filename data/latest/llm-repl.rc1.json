{
  "info": {
    "author": "",
    "author_email": "Sebastiano Mariani <mariani.sebastiano@gmail.com>",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# LLM REPL\n\n## What is this?\n\nThe goal of this project is to create a simple, interactive **REPL** (Read-Eval-Print-Loop) that allows users to interact with a variety of Large Language Models (**LLMs**). The project is mainly built on top of two Python libraries: [langchain](https://github.com/hwchase17/langchain), which provides a convenient and flexible interface for working with LLMs, and [rich](https://github.com/Textualize/rich) which provides a user-friendly interface for the REPL.\n\nCurrently, the project is in development and only supports interaction with the ChatGPT but it has been structure to make it easy to extend it use any LLMs, including custom ones (by extending `BaseLLM` in `./src/llm_repl/llms/__init__.py`).\n\nChatGPT can be interacted by using the models `gpt-3.5-turbo` and `gpt4` (For users who got GPT-4 API beta).\n\n## Features\n\nThe REPL supports the following features:\n\n### Streaming Mode\n\nThe REPL won't wait for the model to finish generating the output, but it will start printing the output as soon as it is available.\n\n![Streaming Mode](./docs/gifs/streaming_mode.gif)\n\n### Conversation Memory\n\nThe REPL supports conversation memory. This means that the model will remember the previous conversation and will use it to generate the next response.\n\n![Memory](./docs/gifs/memory.gif)\n\n### Pretty Printing\n\nThe REPL supports Markdown rendering both of the input and the output.\n\nPS: In this initial version of the REPL, the full Markdown syntax is only when running the tool in `non-streaming` mode. In `streaming` mode only code sections will be pretty printed.\n\n![Pretty Printing](./docs/gifs/pretty_printing.gif)\n\n### Model Switching\n\nThe REPL supports the switching between different models. At the moment, the only supported LLMs are `chatgpt` and `chatgpt4`.\n\n**COMING SOON...**\n\n## Installation\n\n```bash\npip install llm-repl\n```\n\n## Usage\n\nFirst export your OpenAI API key as an environment variable:\n\n```bash\nexport OPENAI_API_KEY=<OPENAI_KEY>\n```\n\nThen run the REPL:\n\n```bash\nllm-repl\n```\n\nOr if you want to use a specific model:\n\n```bash\nllm-repl --llm chatgpt4\n```\n\n### Run inside Docker\n\n```bash\ndocker run -it --rm -e OPENAI_API_KEY=<OPENAI_KEY> phate/llm-repl\n```\n\nOr if you want to source the environment variables from a file, first create a file called `.env` with the following content:\n\n```bash\nOPENAI_API_KEY=<OPENAI_KEY>\n```\n\nAnd then run the following command:\n\n```bash\ndocker run -it --rm --env-file .env phate/llm-repl\n```\n\n## Development\n\nTo install the REPL in development mode\n\nThen install the package in development mode:\n\n```bash\npip install -e \".[DEV]\"\n```\n\nBefore contributing, please make sure to run the following commands:\n\n```bash\npre-commit install\n```\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "llm-repl",
    "package_url": "https://pypi.org/project/llm-repl/",
    "platform": null,
    "project_url": "https://pypi.org/project/llm-repl/",
    "project_urls": {
      "homepage": "https://github.com/Phat3/ChatGPT-REPL",
      "repository": "https://github.com/Phat3/ChatGPT-REPL.git"
    },
    "release_url": "https://pypi.org/project/llm-repl/0.0.1/",
    "requires_dist": [
      "prompt-toolkit",
      "rich",
      "langchain",
      "openai",
      "pylint ; extra == 'dev'",
      "ipdb ; extra == 'dev'",
      "black ; extra == 'dev'",
      "pytest ; extra == 'dev'",
      "mypy ; extra == 'dev'",
      "pre-commit ; extra == 'dev'"
    ],
    "requires_python": ">=3.10",
    "summary": "A REPL for ChatGPT",
    "version": "0.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17472373,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2d1d64e7449b9aaec2d265a75920fd7061241347ffeacdd0fd308f270f924c5f",
          "md5": "5d129504fa8e64deaaae4e777cbdda40",
          "sha256": "827953c85ff927fb547156bac438c45085dd47b5d23138745c03a7fe4acae0ab"
        },
        "downloads": -1,
        "filename": "llm_repl-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "5d129504fa8e64deaaae4e777cbdda40",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.10",
        "size": 10577,
        "upload_time": "2023-03-28T02:15:46",
        "upload_time_iso_8601": "2023-03-28T02:15:46.722101Z",
        "url": "https://files.pythonhosted.org/packages/2d/1d/64e7449b9aaec2d265a75920fd7061241347ffeacdd0fd308f270f924c5f/llm_repl-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "69e647f6fa1800f5d5845b00a725cbcd9e7d3ca909e3dce7ad5f5c5ed66e1dce",
          "md5": "a84057670690fea7792fb3bd23c761f9",
          "sha256": "78b2a0057fbb75ab7c35e2d7103a0f61a8204af1cb56b0d9049f6ee840934969"
        },
        "downloads": -1,
        "filename": "llm-repl-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "a84057670690fea7792fb3bd23c761f9",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.10",
        "size": 9076,
        "upload_time": "2023-03-28T02:15:48",
        "upload_time_iso_8601": "2023-03-28T02:15:48.966691Z",
        "url": "https://files.pythonhosted.org/packages/69/e6/47f6fa1800f5d5845b00a725cbcd9e7d3ca909e3dce7ad5f5c5ed66e1dce/llm-repl-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "2d1d64e7449b9aaec2d265a75920fd7061241347ffeacdd0fd308f270f924c5f",
        "md5": "5d129504fa8e64deaaae4e777cbdda40",
        "sha256": "827953c85ff927fb547156bac438c45085dd47b5d23138745c03a7fe4acae0ab"
      },
      "downloads": -1,
      "filename": "llm_repl-0.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "5d129504fa8e64deaaae4e777cbdda40",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.10",
      "size": 10577,
      "upload_time": "2023-03-28T02:15:46",
      "upload_time_iso_8601": "2023-03-28T02:15:46.722101Z",
      "url": "https://files.pythonhosted.org/packages/2d/1d/64e7449b9aaec2d265a75920fd7061241347ffeacdd0fd308f270f924c5f/llm_repl-0.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "69e647f6fa1800f5d5845b00a725cbcd9e7d3ca909e3dce7ad5f5c5ed66e1dce",
        "md5": "a84057670690fea7792fb3bd23c761f9",
        "sha256": "78b2a0057fbb75ab7c35e2d7103a0f61a8204af1cb56b0d9049f6ee840934969"
      },
      "downloads": -1,
      "filename": "llm-repl-0.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "a84057670690fea7792fb3bd23c761f9",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.10",
      "size": 9076,
      "upload_time": "2023-03-28T02:15:48",
      "upload_time_iso_8601": "2023-03-28T02:15:48.966691Z",
      "url": "https://files.pythonhosted.org/packages/69/e6/47f6fa1800f5d5845b00a725cbcd9e7d3ca909e3dce7ad5f5c5ed66e1dce/llm-repl-0.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}