{
  "info": {
    "author": "NeuML",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Topic :: Scientific/Engineering :: Artificial Intelligence",
      "Topic :: Software Development",
      "Topic :: Text Processing :: Indexing",
      "Topic :: Utilities"
    ],
    "description": "<p align=\"center\">\n    <img src=\"https://raw.githubusercontent.com/neuml/txtchat/master/logo.png\"/>\n</p>\n\n<h3 align=\"center\">\n    <p>Conversational search and workflows for all</p>\n</h3>\n\n-------------------------------------------------------------------------------------------------------------------------------------------------------\n\ntxtchat is a framework for building conversational search and workflows.\n\n![demo](https://raw.githubusercontent.com/neuml/txtchat/master/demo.gif)\n\nA set of intelligent agents are available to integrate with messaging platforms. These agents or personas are associated with an automated account and respond to messages with AI-powered responses. Workflows can use large language models (LLMs), small models or both.\n\ntxtchat is built with Python 3.7+ and [txtai](https://github.com/neuml/txtai).\n\n## Installation\n\nThe easiest way to install is via pip and PyPI\n\n    pip install txtchat\n\nYou can also install txtchat directly from GitHub. Using a Python Virtual Environment is recommended.\n\n    pip install git+https://github.com/neuml/txtchat\n\nPython 3.7+ is supported\n\nSee [this link](https://github.com/neuml/txtai#installation) to help resolve environment-specific install issues.\n\n## Messaging platforms\n\ntxtchat is designed to and will support a number of messaging platforms. Currently, [Rocket.Chat](https://github.com/RocketChat/Rocket.Chat) is the only supported platform given it's ability to be installed in a local environment along with being MIT-licensed. The easiest way to start a local Rocket.Chat instance is with Docker Compose. See these [instructions](https://docs.rocket.chat/deploy/prepare-for-your-deployment/rapid-deployment-methods/docker-and-docker-compose) for more.\n\nExtending txtchat to additional platforms only needs a new Agent subclass for that platform.\n\n## Architecture\n\n![architecture](https://raw.githubusercontent.com/neuml/txtchat/master/images/architecture.png#gh-light-mode-only)\n\nA persona is a combination of a chat agent and workflow that determines the type of responses. Each agent is tied to an account in the messaging platform. Persona workflows are messaging-platform agnostic. The [txtchat-persona](https://hf.co/neuml/txtchat-personas) repository has a list of standard persona workflows.\n\n- [Wikitalk](https://hf.co/neuml/txtchat-personas/blob/main/wikitalk.yml): Conversational search with Wikipedia\n- [Summary](https://hf.co/neuml/txtchat-personas/blob/main/summary.yml): Reads input URLs and summarizes the text\n- [Mr. French](https://hf.co/neuml/txtchat-personas/blob/main/mrfrench.yml): Translates input text into French\n\nThe following command shows how to start a txtchat persona.\n\n```\n# Set to server URL, this is default when running local\nexport AGENT_URL=ws://localhost:3000/websocket\nexport AGENT_USERNAME=<Rocket Chat User>\nexport AGENT_PASSWORD=<Rocket Chat User Password>\n\n# YAML is loaded from Hugging Face Hub, can also reference local path\npython -m txtchat.agent wikitalk.yml\n```\n\nWant to add a new persona? Simply create a txtai workflow and save it to a YAML file.\n\n## Examples\n\nThe following is a [list of YouTube videos](https://www.youtube.com/watch?v=ROyess8dLoA&list=PLaqn_lxC5d0C_HPe53GPk7jBH3xhBcgu-) that shows how txtchat works. These videos run a series of queries with the Wikitalk persona. Wikitalk is a combination of a Wikipedia embeddings index and a LLM prompt to answer questions.\n\nEvery answer shows an associated reference with where the data came from. Wikitalk will say \"I don't have data on that\" when it doesn't have an answer.\n\n### History\n\nConversation with Wikitalk about history.\n\n[![History](https://img.youtube.com/vi/ROyess8dLoA/maxresdefault.jpg)](https://youtube.com/watch?v=ROyess8dLoA)\n\n### Sports\n\nTalk about sports.\n\n[![Sports](https://img.youtube.com/vi/LXRB-iruKSc/maxresdefault.jpg)](https://youtube.com/watch?v=LXRB-iruKSc)\n\n### Culture\n\nArts and culture questions.\n\n[![Culture](https://img.youtube.com/vi/OkObkNhJIgk/maxresdefault.jpg)](https://youtube.com/watch?v=OkObkNhJIgk)\n\n### Science\n\nLet's quiz Wikitalk on science.\n\n[![Science](https://img.youtube.com/vi/-rsYDsZc9Wo/maxresdefault.jpg)](https://youtube.com/watch?v=-rsYDsZc9Wo)\n\n### Summary\n\nNot all workflows need a LLM. There are plenty of great small models available to perform a specific task. The Summary persona simply reads the input URL and summarizes the text.\n\n[![Summary](https://img.youtube.com/vi/PBJm9aDqkn0/maxresdefault.jpg)](https://youtube.com/watch?v=PBJm9aDqkn0)\n\n### Mr. French\n\nLike the summary persona, Mr. French is a simple persona that translates input text to French.\n\n[![French](https://img.youtube.com/vi/4x8pOIm4rbo/maxresdefault.jpg)](https://youtube.com/watch?v=4x8pOIm4rbo)\n\n## Connect your own data\n\nWant to connect txtchat to your own data? All that you need to do is create a txtai workflow. Let's run through an example of building a Hacker News indexing workflow and a txtchat persona.\n\nFirst, we'll define the indexing workflow and build the index. This is done with a workflow for convenience. Alternatively it could be a Python program that builds an embeddings index from your dataset. There are over [40 example notebooks](https://github.com/neuml/txtai#examples) covering a wide range of ways to get data into txtai. There are also example workflows that can be downloaded from in this [Hugging Face Space](https://huggingface.co/spaces/NeuML/txtai).\n\n```yaml\npath: /tmp/hn\nembeddings:\n  path: sentence-transformers/all-MiniLM-L6-v2\n  content: true\ntabular:\n  idcolumn: url\n  textcolumns:\n  - title\nworkflow:\n  index:\n    tasks:\n    - batch: false\n      extract:\n      - hits\n      method: get\n      params:\n        tags: null\n      task: service\n      url: https://hn.algolia.com/api/v1/search?hitsPerPage=50\n    - action: tabular\n    - action: index\nwritable: true\n```\n\nThis workflow parses the Hacker News front page feed and builds an embeddings index at the path `/tmp/hn`. \n\nRun the workflow with the following.\n\n```python\nfrom txtai.app import Application\n\napp = Application(\"index.yml\")\nlist(app.workflow(\"index\", [\"front_page\"]))\n```\n\nNow we'll define the chat workflow and run it as an agent.\n\n```yaml\npath: /tmp/hn\nwritable: false\n\nextractor:\n  path: google/flan-t5-xl\n  output: flatten\n\nworkflow:\n  search:\n    tasks:\n      - task: txtchat.task.Question\n        action: extractor\n```\n\n```\npython -m txtchat.agent query.yml\n```\n\nLet's talk to Hacker News!\n\n![hn](https://raw.githubusercontent.com/neuml/txtchat/master/images/custom.png)\n\nAs you can see, Hacker News is a highly opinionated data source!\n\nGetting answers is nice but being able to have answers with where they came from is nicer. Let's build a workflow that adds a reference link to each answer.\n\n```yaml\npath: /tmp/hn\nwritable: false\n\nextractor:\n  path: google/flan-t5-xl\n  output: reference\n\nworkflow:\n  search:\n    tasks:\n      - task: txtchat.task.Question\n        action: extractor\n      - task: txtchat.task.Answer\n```\n\n![hn-reference](https://raw.githubusercontent.com/neuml/txtchat/master/images/custom-reference.png)\n\n## Further Reading\n\n- [Introducing txtchat, next-generation conversational search and workflows for all](https://medium.com/neuml/introducing-txtchat-next-generation-conversational-search-and-workflows-for-all-97557009fb53)\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/neuml/txtchat",
    "keywords": "search embedding machine-learning nlp",
    "license": "Apache 2.0: http://www.apache.org/licenses/LICENSE-2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "txtchat",
    "package_url": "https://pypi.org/project/txtchat/",
    "platform": null,
    "project_url": "https://pypi.org/project/txtchat/",
    "project_urls": {
      "Documentation": "https://github.com/neuml/txtchat",
      "Homepage": "https://github.com/neuml/txtchat",
      "Issue Tracker": "https://github.com/neuml/txtchat/issues",
      "Source Code": "https://github.com/neuml/txtchat"
    },
    "release_url": "https://pypi.org/project/txtchat/0.1.0/",
    "requires_dist": [
      "datasets (>=2.8.0)",
      "nltk (>=3.5)",
      "pandas (>=1.3.5)",
      "pyyaml (>=5.3)",
      "rocketchat-async (>=1.0.1)",
      "tqdm (>=4.48.0)",
      "txtai (>=5.4.0)"
    ],
    "requires_python": ">=3.7",
    "summary": "Conversational search and workflows for all",
    "version": "0.1.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17177599,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "064f0462eda41780d79e25f8daf40cd3eb823c9ac43463407ae7fe5cb74abd1a",
          "md5": "85d801c6914a01733100a79ff6b811f9",
          "sha256": "9b319fed382edaa1a97ad49f593229d2fd233d46e31298753ba63a69a44464d3"
        },
        "downloads": -1,
        "filename": "txtchat-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "85d801c6914a01733100a79ff6b811f9",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 5460,
        "upload_time": "2023-02-11T15:13:22",
        "upload_time_iso_8601": "2023-02-11T15:13:22.651458Z",
        "url": "https://files.pythonhosted.org/packages/06/4f/0462eda41780d79e25f8daf40cd3eb823c9ac43463407ae7fe5cb74abd1a/txtchat-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8be099794808489f35bb1fe17082a7d1804aa950c534ec22a389b0ac6483344f",
          "md5": "f0e94a83421909d64768f9fb783c31dc",
          "sha256": "0c383287d2ef2040d2c89fdc4d6464c44d04223c17e9d675d5d1f5af8bab9971"
        },
        "downloads": -1,
        "filename": "txtchat-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "f0e94a83421909d64768f9fb783c31dc",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 1395,
        "upload_time": "2023-02-11T15:13:24",
        "upload_time_iso_8601": "2023-02-11T15:13:24.315472Z",
        "url": "https://files.pythonhosted.org/packages/8b/e0/99794808489f35bb1fe17082a7d1804aa950c534ec22a389b0ac6483344f/txtchat-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6b70c6b2d388f158f5abc3f05f82064b2cc79bd13c6c5e38760d9227bad1ebe0",
          "md5": "a96931c319b8b8dd3203dc32ff090298",
          "sha256": "4cfb8c3b0708ba29baabacb6c01386eb7b2d25bade21e98b83fabb8062233316"
        },
        "downloads": -1,
        "filename": "txtchat-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "a96931c319b8b8dd3203dc32ff090298",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 19301,
        "upload_time": "2023-03-06T16:22:02",
        "upload_time_iso_8601": "2023-03-06T16:22:02.486906Z",
        "url": "https://files.pythonhosted.org/packages/6b/70/c6b2d388f158f5abc3f05f82064b2cc79bd13c6c5e38760d9227bad1ebe0/txtchat-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9461dc91a4d86e489bf86f2ac5a5b4324a144b053ccb86e4ebf6ff98212244cb",
          "md5": "d79e44445c54e137650d59c2f588d1ae",
          "sha256": "a8d89cdbeec6a45e3bc101782ade4def53a6cf3a353069b8b74f7034e325732f"
        },
        "downloads": -1,
        "filename": "txtchat-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "d79e44445c54e137650d59c2f588d1ae",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 14924,
        "upload_time": "2023-03-06T16:22:04",
        "upload_time_iso_8601": "2023-03-06T16:22:04.513548Z",
        "url": "https://files.pythonhosted.org/packages/94/61/dc91a4d86e489bf86f2ac5a5b4324a144b053ccb86e4ebf6ff98212244cb/txtchat-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "6b70c6b2d388f158f5abc3f05f82064b2cc79bd13c6c5e38760d9227bad1ebe0",
        "md5": "a96931c319b8b8dd3203dc32ff090298",
        "sha256": "4cfb8c3b0708ba29baabacb6c01386eb7b2d25bade21e98b83fabb8062233316"
      },
      "downloads": -1,
      "filename": "txtchat-0.1.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "a96931c319b8b8dd3203dc32ff090298",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 19301,
      "upload_time": "2023-03-06T16:22:02",
      "upload_time_iso_8601": "2023-03-06T16:22:02.486906Z",
      "url": "https://files.pythonhosted.org/packages/6b/70/c6b2d388f158f5abc3f05f82064b2cc79bd13c6c5e38760d9227bad1ebe0/txtchat-0.1.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "9461dc91a4d86e489bf86f2ac5a5b4324a144b053ccb86e4ebf6ff98212244cb",
        "md5": "d79e44445c54e137650d59c2f588d1ae",
        "sha256": "a8d89cdbeec6a45e3bc101782ade4def53a6cf3a353069b8b74f7034e325732f"
      },
      "downloads": -1,
      "filename": "txtchat-0.1.0.tar.gz",
      "has_sig": false,
      "md5_digest": "d79e44445c54e137650d59c2f588d1ae",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 14924,
      "upload_time": "2023-03-06T16:22:04",
      "upload_time_iso_8601": "2023-03-06T16:22:04.513548Z",
      "url": "https://files.pythonhosted.org/packages/94/61/dc91a4d86e489bf86f2ac5a5b4324a144b053ccb86e4ebf6ff98212244cb/txtchat-0.1.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}