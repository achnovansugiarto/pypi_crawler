{
  "info": {
    "author": "79988",
    "author_email": "77957147@qq.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# TEXT_ANALYSIS_extracting_diseases_places_keywords\r\nThis repository contains code used gensim,en_core_web_sm and en_ner_bc5cdr_md to Generate pictures and word clouds of diseases, locations, key words in a paper.\r\n## Content\r\n1.a pipeline to detect chimeric reads from direct RNA-seq data  \r\n2.a custom script to verify insertion with raw sequencing data  \r\n3.codes to generate Figures\r\n## Prerequisites\r\nAll codes were run and tested on Linux\r\n\r\n* Python >=3.8  \r\n* scispacy \r\n* en-ner-bc5cdr-md\r\n* en-core-web-sm \r\n* beautifulsoup4\r\n* wordcloud\r\n* gensim \r\n* nltk\r\n## Workflow for direct diseases, locations, key words in a paper\r\n### Input:\r\n\"PMC\"+Complete number\r\n### Output:\r\n#### 1. The histogram and word clouds of top3 words about diseases : \r\nThe abscissa of the bar graph represents the word, and the ordinate represents the number of times the word appears in the text  \r\nThe size of the word in the word cloud depends on the frequency of the word in the text\r\n#### 2. The histogram and word clouds of top3 words about locations : \r\nThe abscissa of the bar graph represents the word, and the ordinate represents the number of times the word appears in the text  \r\nThe size of the word in the word cloud depends on the frequency of the word in the text\r\n#### 3. The histogram and word clouds of top3 words about key words : \r\nThe abscissa of the bar graph represents the word, and the ordinate represents weight(tf_idf) of the word,the weight=word_freq*log(the number of total text/Number of texts containing the word)\r\nThe size of the word in the word cloud depends on the weight(tf_idf) of the word in the text\r\n### Steps:\r\n* Step.1: Enter the PMC number you want to query.\r\n* Step.2: Use beautifulsoup to crawl the web page information of the paper, and then use xml etree. Elementtree package to transform web page information into XML for analysis.\r\n* Step.3: Extract thesis information from XML file\r\n>* Step.3.1: ABOUT KEY_WORD:  \r\n   > Extract the text information from the converted XML file: filter the text information of 'abstract', 'intro','methods','discuss','results','case','concl','abbr','fig','table' attributes in the XML file, because the keywords in the article mainly come from the 'Abstract','concl'parts in the XML file. In order to highlight the information of' Abstract','concl' parts and improve the weight of this part(Because of the tfidfmodel algorithm, all other articles that need to call the article library extract the words in the article for analysis.)\r\n>* Step.3.2: ABOUT DISEASE:   \r\n   >  Extract body information from the converted XML file: filter the text information of 'Abstract','intro','methods','exclude','results','case','concl','abbr','fig','table'attributes in the XML file\r\n>* Step.3.3: ABOUT LOCATION:  \r\n> Extract body information from the converted XML file: filter the text information of 'Abstract','intro','methods','exclude','results','case','concl','abbr','fig','table'attributes in the XML file\r\n* Step.4:Conduct preliminary text analysis\r\n>* Step.4.1: ABOUT KEY_WORD:  \r\n> Remove redundant spaces, line breaks, numbers and some punctuation in the text. Then morpheme all words in the text (convert all words into prototypes),In order to improve the efficiency of program analysis, the stopworld package of nltk library is loaded to remove useless high-frequency words.\r\n >* Step.4.2: ABOUT DISEASE:  \r\n> Remove redundant spaces, line breaks, numbers and some punctuation in the text. And reduce all words to lowercase,In order to improve the efficiency of program analysis, the stopworld package of nltk library is loaded to remove useless high-frequency words.\r\n>* Step.4.3: ABOUT LOCATION:   \r\n> Remove redundant spaces, line breaks, numbers and some punctuation in the text. And reduce all words to lowercase,In order to improve the efficiency of program analysis, the stopworld package of nltk library is loaded to remove useless high-frequency words.\r\n* Step.5: Text analysis\r\n>* Step.5.1: ABOUT KEY_WORD:  \r\n> Use trigram to enumerate all the possibilities and turn the individual words in the article into three word phrases,Tfidfmodel algorithm is used to allocate the weight of trigram.\r\n>* Step.5.2: ABOUT DISEASE:  \r\n> Use the en_ ner_ bc5cdr_ MD model of the scispacy  to find out the special medical words in the text, and then select the words with \"labs\" as DISEASE,and count the number of times words appear in the article.\r\n>* Step.5.3: ABOUT LOCATION:  \r\n> Use NLP to process documents and analyze the part of speech of all words in a sentence and find the word whose key value is ' GPE ',count the number of times words appear in the article.\r\n* Step.6: Generate histogram and word cloud.\r\n>* Step.6.1: ABOUT KEY_WORD:  \r\n> Generate histogram using Matplotlib, The abscissa of the bar graph represents the word, and the ordinate represents weight(tf_idf) of the word,the weight=word_freq*log(the number of total text/Number of texts containing the word)  \r\nGenerate word cloud using wordcloud, The size of the word in the word cloud depends on the weight(tf_idf) of the word in the text\r\n>* Step.6.2: ABOUT DISEASE:  \r\n> Generate histogram using Matplotlib, The abscissa of the bar graph represents the word, and the ordinate represents the number of times the word appears in the text  \r\nGenerate word cloud using wordcloud, The size of the word in the word cloud depends on the frequency of the word in the text\r\n>* Step.6.3: ABOUT LOCATION:\r\n> Generate histogram using Matplotlib, The abscissa of the bar graph represents the word, and the ordinate represents the number of times the word appears in the text  \r\nGenerate word cloud using wordcloud, The size of the word in the word cloud depends on the frequency of the word in the text\r\n## Usage\r\n```\r\nimport os\r\nimport nltk\r\nimport gensim\r\nimport re\r\nimport spacy\r\nfrom bs4 import BeautifulSoup \r\nimport re \r\nimport urllib.request, urllib.error\r\nimport scispacy\r\nimport en_ner_bc5cdr_md\r\nfrom MainWord import ForTheMainWord \r\n\r\nMainWord.To_Generate_Disease(6988269)\r\nMainWord.To_Generate_Location(6988269)\r\nMainWord.To_Generate_Key_Word(6988269)\r\n\r\n```\r\n## Citation\r\nBase the en-ner-bc5cdr-md,en-core-web-sm and gensim \r\n## Acknowledgements\r\nWe would like to thank *********** and *********** for their code on how to perform permutation tests and plot the results provided at TEXT_ANALYSIS which was adjusted and used in this project.\r\n\r\n\r\n\r\n\r\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/ReddishXia/TheMainword",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "TheMixed",
    "package_url": "https://pypi.org/project/TheMixed/",
    "platform": null,
    "project_url": "https://pypi.org/project/TheMixed/",
    "project_urls": {
      "Homepage": "https://github.com/ReddishXia/TheMainword"
    },
    "release_url": "https://pypi.org/project/TheMixed/6.0.0/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "Get the main word in the paper",
    "version": "6.0.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14717750,
  "releases": {
    "2.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c9fa71efd94f02b98b5851b8408b61daccb4af3b22fdbb093934b323f84c6f29",
          "md5": "d85456674c689676fd3b1f3075e4d42b",
          "sha256": "d9c0a2a2ee0bb999b8e5864ea6611c9f3491d78b89a21849c82c67ceb6ca5832"
        },
        "downloads": -1,
        "filename": "TheMixed-2.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "d85456674c689676fd3b1f3075e4d42b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 8170,
        "upload_time": "2022-07-27T01:34:36",
        "upload_time_iso_8601": "2022-07-27T01:34:36.731175Z",
        "url": "https://files.pythonhosted.org/packages/c9/fa/71efd94f02b98b5851b8408b61daccb4af3b22fdbb093934b323f84c6f29/TheMixed-2.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "3.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "612e036eceb61c53e73dda6f9cea221f63bbc367ae6593517f7b1def6900aa51",
          "md5": "b98143d02c8adebf1fb123ce207d6b21",
          "sha256": "4ff0abdbdb5c58571644d0cc9f0fb25c4210cadf636b07a118f83d1786e65a60"
        },
        "downloads": -1,
        "filename": "TheMixed-3.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "b98143d02c8adebf1fb123ce207d6b21",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 8195,
        "upload_time": "2022-07-29T09:48:44",
        "upload_time_iso_8601": "2022-07-29T09:48:44.406587Z",
        "url": "https://files.pythonhosted.org/packages/61/2e/036eceb61c53e73dda6f9cea221f63bbc367ae6593517f7b1def6900aa51/TheMixed-3.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "5.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "83ad54c327756c2a2869cfaa6fda5b4521f1cce90ec58a79dc96f5b75f5315a9",
          "md5": "65f0240e46f549922a423f87085719ba",
          "sha256": "dcc0905af2f25152e10a3beebb8cf3436136324005af7fb317d67d9444e0c9ba"
        },
        "downloads": -1,
        "filename": "TheMixed-5.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "65f0240e46f549922a423f87085719ba",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 1446333,
        "upload_time": "2022-08-04T05:35:26",
        "upload_time_iso_8601": "2022-08-04T05:35:26.038467Z",
        "url": "https://files.pythonhosted.org/packages/83/ad/54c327756c2a2869cfaa6fda5b4521f1cce90ec58a79dc96f5b75f5315a9/TheMixed-5.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "6.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0575fbbbcf7d0ba72ac5d1acd58c3af54dee71cac35b3f513bbdb6c15360c534",
          "md5": "ee9c2e5d63409d25b9a5bea544eeb65c",
          "sha256": "6336c2a42b96c347671aad1467fa269d205c0a41a832320ea03139ba82d166b0"
        },
        "downloads": -1,
        "filename": "TheMixed-6.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "ee9c2e5d63409d25b9a5bea544eeb65c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 1450151,
        "upload_time": "2022-08-10T14:02:53",
        "upload_time_iso_8601": "2022-08-10T14:02:53.226585Z",
        "url": "https://files.pythonhosted.org/packages/05/75/fbbbcf7d0ba72ac5d1acd58c3af54dee71cac35b3f513bbdb6c15360c534/TheMixed-6.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "0575fbbbcf7d0ba72ac5d1acd58c3af54dee71cac35b3f513bbdb6c15360c534",
        "md5": "ee9c2e5d63409d25b9a5bea544eeb65c",
        "sha256": "6336c2a42b96c347671aad1467fa269d205c0a41a832320ea03139ba82d166b0"
      },
      "downloads": -1,
      "filename": "TheMixed-6.0.0.tar.gz",
      "has_sig": false,
      "md5_digest": "ee9c2e5d63409d25b9a5bea544eeb65c",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 1450151,
      "upload_time": "2022-08-10T14:02:53",
      "upload_time_iso_8601": "2022-08-10T14:02:53.226585Z",
      "url": "https://files.pythonhosted.org/packages/05/75/fbbbcf7d0ba72ac5d1acd58c3af54dee71cac35b3f513bbdb6c15360c534/TheMixed-6.0.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}