{
  "info": {
    "author": "Martin Drawitsch",
    "author_email": "martin.drawitsch@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# `anonfaces`: Video anonymization by face detection\n\n`anonfaces` is a simple command-line tool for automatic anonymization of faces in videos or photos.\nIt works by first detecting all human faces in each video frame and then applying an anonymization filter (blurring or black boxes) on each detected face region.\nAll audio tracks are discarded as well.\n\n\nOriginal frame | `anonfaces` output (using default options)\n:--:|:--:\n![examples/city.jpg](examples/city.jpg) | ![$ anonfaces examples/city.jpg](examples/city_anonymized.jpg)\n\n\n## Installation\n\n`anonfaces` supports all commonly used operating systems (Linux, Windows, MacOS), but it requires using a command-line shell such as bash. There are currently no plans of creating a graphical user interface.\n\nThe recommended way of installing `anonfaces` is via the `pip` package manager. This requires that you have Python 3.6 or later installed on your system. It is recommended to set up and activate a new [virtual environment](https://realpython.com/python-virtual-environments-a-primer/) first. Then you can install the latest release of `anonfaces` and all necessary dependencies by running:\n\n    $ python3 -m pip install anonfaces\n\nAlternatively, if you want to use the latest (unreleased) revision directly from GitHub, you can run:\n\n    $ python3 -m pip install 'git+https://github.com/StealUrKill/anonfaces'\n\nThis will only install the dependencies that are strictly required for running the tool. If you want to speed up processing by enabling hardware acceleration, you will need to manually install additional packages, see [Hardware acceleration](#hardware-acceleration)\n\n\n## Usage\n\n### Quick start\n\nIf you want to try out anonymizing a video using the default settings, you just need to supply the path to it. For example, if the path to your test video is `myvideos/vid1.mp4`, run:\n\n    $ anonfaces myvideos/vid1.mp4\n\nThis will write the the output to the new video file `myvideos/vid1_anonymized.mp4`.\n\n### Live capture demo\n\nIf you have a camera (webcam) attached to your computer, you can run `anonfaces` on the live video input by calling it with the `cam` argument instead of an input path:\n\n    $ anonfaces cam\n\nThis is a shortcut for `$ anonfaces --preview '<video0>'`, where `'<video0>'` (literal) is a  camera device identifier. If you have multiple cameras installed, you can try `'<videoN>'`, where `N` is the index of the camera (see [imageio-ffmpeg docs](https://imageio.readthedocs.io/en/stable/format_ffmpeg.html)).\n\n### CLI usage and options summary\n\nTo get an overview of usage and available options, run:\n\n    $ anonfaces -h\n\nThe output may vary depending on your installed version, but it should look similar to this:\n\n```\nusage: anonfaces [--output O] [--thresh T] [--scale WxH] [--preview] [--boxes]\n              [--draw-scores] [--mask-scale M]\n              [--replacewith {blur,solid,none,img}] [--replaceimg REPLACEIMG]\n              [--ffmpeg-config FFMPEG_CONFIG] [--backend {auto,onnxrt,opencv}]\n              [--version] [--help]\n              [input ...]\n\nVideo anonymization by face detection\n\npositional arguments:\n  input                 File path(s) or camera device name. It is possible to\n                        pass multiple paths by separating them by spaces or by\n                        using shell expansion (e.g. `$ anonfaces vids/*.mp4`).\n                        Alternatively, you can pass a directory as an input,\n                        in which case all files in the directory will be used\n                        as inputs. If a camera is installed, a live webcam\n                        demo can be started by running `$ anonfaces cam` (which\n                        is a shortcut for `$ anonfaces -p '<video0>'`.\n\noptional arguments:\n  --output O, -o O      Output file name. Defaults to input path + postfix\n                        \"_anonymized\".\n  --thresh T, -t T      Detection threshold (tune this to trade off between\n                        false positive and false negative rate). Default: 0.2.\n  --scale WxH, -s WxH   Downscale images for network inference to this size\n                        (format: WxH, example: --scale 640x360).\n  --preview, -p         Enable live preview GUI (can decrease performance).\n  --boxes               Use boxes instead of ellipse masks.\n  --draw-scores         Draw detection scores onto outputs.\n  --mask-scale M        Scale factor for face masks, to make sure that masks\n                        cover the complete face. Default: 1.3.\n  --replacewith {blur,solid,none,img}\n                        Anonymization filter mode for face regions. \"blur\"\n                        applies a strong gaussian blurring, \"solid\" draws a\n                        solid black box, \"none\" does leaves the input\n                        unchanged and \"img\" replaces the face with a custom\n                        image. Default: \"blur\".\n  --replaceimg REPLACEIMG\n                        Anonymization image for face regions. Requires\n                        --replacewith img option.\n  --ffmpeg-config FFMPEG_CONFIG\n                        FFMPEG config arguments for encoding output videos.\n                        This argument is expected in JSON notation. For a list\n                        of possible options, refer to the ffmpeg-imageio docs.\n                        Default: '{\"codec\": \"libx264\"}'.\n  --backend {auto,onnxrt,opencv}\n                        Backend for ONNX model execution. Default: \"auto\"\n                        (prefer onnxrt if available).\n  --version             Print version number and exit.\n  --help, -h            Show this help message and exit.\n```\n\n## Usage examples\n\nIn most use cases the default configuration should be sufficient, but depending on individual requirements and type of media to be processed, some of the options might need to be adjusted. In this section, some common example scenarios that require option changes are presented. All of the examples use the photo [examples/city.jpg](examples/city.jpg), but they work the same on any video or photo file.\n\n### Drawing black boxes\n\nBy default, each detected face is anonymized by applying a blur filter to an ellipse region that covers the face. If you prefer to anonymize faces by drawing black boxes on top of them, you can achieve this through the `--boxes` and `--replacewith` options:\n\n    $ anonfaces examples/city.jpg --boxes --replacewith solid -o examples/city_anonymized_boxes.jpg\n\n<img src=\"examples/city_anonymized_boxes.jpg\" width=\"70%\" alt=\"$ anonfaces examples/city.jpg --enable-boxes --replacewith solid -o examples/city_anonymized_boxes.jpg\"/>\n\n\n### Tuning detection thresholds\n\nThe detection threshold (`--thresh`, `-t`) is used to define how confident the detector needs to be for classifying some region as a face. By default this is set to the value 0.2, which was found to work well on many test videos.\n\nIf you are experiencing too many false positives (i.e. anonymization filters applied at non-face regions) on your own video data, consider increasing the threshold.\nOn the other hand, if there are too many false negative errors (visible faces that are not anonymized), lowering the threshold is advisable.\n\nThe optimal value can depend on many factors such as video quality, lighting conditions and prevalence of partial occlusions. To optimize this value, you can set threshold to a very low value and then draw detection score overlays, as described in the [section below](#drawing-detection-score-overlays).\n\nTo demonstrate the effects of a threshold that is set too low or too high, see the examples outputs below:\n\n`--thresh 0.02` (notice the false positives, e.g. at hand regions) | `--thresh 0.7` (notice the false negatives, especially at partially occluded faces)\n:--:|:--:\n![examples/city_anonymized_thresh0.02.jpg](examples/city_anonymized_thresh0.02.jpg) | ![$ anonfaces examples/city_anonymized_thresh0.7.jpg](examples/city_anonymized_thresh0.7.jpg)\n\n\n### Drawing detection score overlays\n\nIf you are interested in seeing the faceness score (a score between 0 and 1 that roughly corresponds to the detector's confidence that something *is* a face) of each detected face in the input, you can enable the `--draw-scores` option to draw the score of each detection directly above its location.\n\n    $ anonfaces examples/city.jpg --draw-scores -o examples/city_anonymized_scores.jpg\n\n<img src=\"examples/city_anonymized_scores.jpg\" width=\"70%\" alt=\"$ anonfaces examples/city.jpg --draw-scores -o examples/city_anonymized_scores.jpg\"/>\n\nThis option can be useful to figure out an optimal value for the detection threshold that can then be set through the `--thresh` option.\n\n\n### High-resolution media and performance issues \n\nSince `anonfaces` tries to detect faces in the unscaled full-res version of input files by default, this can lead to performance issues on high-res inputs (>> 720p). In extreme cases, even detection accuracy can suffer because the detector neural network has not been trained on ultra-high-res images.\n\nTo counter these performance issues, `anonfaces` supports downsampling its inputs on-the-fly before detecting faces, and subsequently rescaling detection results to the original resolution. Downsampling only applies to the detection process, whereas the final output resolution remains the same as the input resolution.\n\nThis feature is controlled through the `--scale` option, which expects a value of the form `WxH`, where `W` and `H` are the desired width and height of downscaled input representations.\nIt is very important to make sure the aspect ratio of the inputs remains intact when using this option, because otherwise, distorted images are fed into the detector, resulting in decreased accuracy.\n\nFor example, if your inputs have the common aspect ratio 16:9, you can instruct the detector to run in 360p resolution by specifying `--scale 640x360`.\nIf the results at this fairly low resolution are not good enough, detection at 720p input resolution (`--scale 1280x720`) may work better.\n\n\n## Hardware acceleration\n\nDepending on your available hardware, you can often speed up neural network inference by enabling the optional [ONNX Runtime](https://microsoft.github.io/onnxruntime/) backend of `anonfaces`.\n\n### CUDA (on Nvidia GPUs)\n\nIf you have a CUDA-capable GPU, you can enable GPU acceleration by installing the relevant packages:\n\n    $ python3 -m pip install onnx onnxruntime-gpu\n\nIf the `onnxruntime-gpu` package is found and a GPU is available, the face detection network is automatically offloaded to the GPU.\nThis can significantly improve the overall processing speed.\n\n### Other platforms\n\nIf your machine doesn't have a CUDA-capable GPU but you want to accelerate computation on another hardware platform (e.g. Intel CPUs), you can look into the available options in the [ONNX Runtime build matrix](https://microsoft.github.io/onnxruntime/).\n\n\n## How it works\n\nThe included face detection system is based on CenterFace ([code](https://github.com/Star-Clouds/centerface), [paper](https://arxiv.org/abs/1911.03599)), a deep neural network optimized for fast but reliable detection of human faces in photos.\nThe network was trained on the [WIDER FACE](http://shuoyang1213.me/WIDERFACE/) dataset, which contains annotated photos showing faces in a wide variety of scales, poses and occlusions.\n\nAlthough the face detector is originally intended to be used for normal 2D images, `anonfaces` can also use it to detect faces in video data by analyzing each video frame independently.\nThe face bounding boxes predicted by the CenterFace detector are then used as masks to determine where to apply anonymization filters.\n\n\n## Credits\n\n- `centerface.onnx` (original) and `centerface.py` (modified) are based on https://github.com/Star-Clouds/centerface (revision [8c39a49](https://github.com/Star-Clouds/CenterFace/tree/8c39a497afb78fb2c064eb84bf010c273bb7d3ce)),\n  [released under MIT license](https://github.com/Star-Clouds/CenterFace/blob/36afed/LICENSE).\n- The original source of the example images in the `examples` directory can be found [here](https://www.pexels.com/de-de/foto/stadt-kreuzung-strasse-menschen-109919/) (released under the [Pexels photo license](https://www.pexels.com/photo-license/)).\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/StealUrKill/anonfaces",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "anonfaces",
    "package_url": "https://pypi.org/project/anonfaces/",
    "platform": null,
    "project_url": "https://pypi.org/project/anonfaces/",
    "project_urls": {
      "Homepage": "https://github.com/StealUrKill/anonfaces"
    },
    "release_url": "https://pypi.org/project/anonfaces/1.0.0/",
    "requires_dist": [
      "imageio",
      "imageio-ffmpeg",
      "numpy",
      "tqdm",
      "scikit-image",
      "opencv-python",
      "onnxruntime-gpu ; extra == 'gpu'"
    ],
    "requires_python": ">=3.6",
    "summary": "Video anonymization by face detection",
    "version": "1.0.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 13842820,
  "releases": {
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e7bee2fd6049762bdcfd3d70c6757c61d894376cb89b56150deafc183097f98d",
          "md5": "fbc785c89de9f37f55d2f3c034a40497",
          "sha256": "3ed11017d0b1e78f1ccbe34f6935d82ab4c45300d74d671d7d79dc4cc016443e"
        },
        "downloads": -1,
        "filename": "anonfaces-1.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "fbc785c89de9f37f55d2f3c034a40497",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 7010509,
        "upload_time": "2022-05-17T15:01:01",
        "upload_time_iso_8601": "2022-05-17T15:01:01.213572Z",
        "url": "https://files.pythonhosted.org/packages/e7/be/e2fd6049762bdcfd3d70c6757c61d894376cb89b56150deafc183097f98d/anonfaces-1.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "e7bee2fd6049762bdcfd3d70c6757c61d894376cb89b56150deafc183097f98d",
        "md5": "fbc785c89de9f37f55d2f3c034a40497",
        "sha256": "3ed11017d0b1e78f1ccbe34f6935d82ab4c45300d74d671d7d79dc4cc016443e"
      },
      "downloads": -1,
      "filename": "anonfaces-1.0.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "fbc785c89de9f37f55d2f3c034a40497",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 7010509,
      "upload_time": "2022-05-17T15:01:01",
      "upload_time_iso_8601": "2022-05-17T15:01:01.213572Z",
      "url": "https://files.pythonhosted.org/packages/e7/be/e2fd6049762bdcfd3d70c6757c61d894376cb89b56150deafc183097f98d/anonfaces-1.0.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}