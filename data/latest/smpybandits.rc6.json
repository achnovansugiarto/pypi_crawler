{
  "info": {
    "author": "Lilian Besson",
    "author_email": "naereen@crans.org",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Environment :: Console",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: MIT License",
      "Natural Language :: English",
      "Operating System :: Unix",
      "Programming Language :: Python :: 2.7",
      "Programming Language :: Python :: 3.4",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Topic :: Scientific/Engineering",
      "Topic :: Scientific/Engineering :: Mathematics"
    ],
    "description": "*SMPyBandits*\n=============\n\n**Open-Source Python package for Single- and Multi-Players multi-armed Bandits algorithms**.\n\nThis repository contains the code of `Lilian Besson’s <http://perso.crans.org/besson/>`__ numerical environment, written in `Python (2 or 3) <https://www.python.org/>`__, for numerical simulations on *single*-player and *multi*-players `Multi-Armed Bandits (MAB) <https://en.wikipedia.org/wiki/Multi-armed_bandit>`__ algorithms.\n\nA complete Sphinx-generated documentation is on `SMPyBandits.GitHub.io <https://smpybandits.github.io/>`__.\n\nQuick presentation\n------------------\n\n*SMPyBandits* contains the most complete collection of single-player (classical) bandit algorithms on the Internet (`over 65! <https://smpybandits.github.io/docs/Policies.html>`__), as well as implementation of all the state-of-the-art `multi-player algorithms <https://smpybandits.github.io/docs/PoliciesMultiPlayers.html>`__.\n\nI follow very actively the latest publications related to Multi-Armed Bandits (MAB) research, and usually implement quite quickly the new algorithms (see for instance, `Exp3++ <https://smpybandits.github.io/docs/Policies.Exp3PlusPlus.html>`__, `CORRAL <https://smpybandits.github.io/docs/Policies.CORRAL.html>`__ and `SparseUCB <https://smpybandits.github.io/docs/Policies.SparseUCB.html>`__ were each introduced by articles (`for Exp3++ <https://arxiv.org/pdf/1702.06103>`__, `for CORRAL <https://arxiv.org/abs/1612.06246v2>`__, `for SparseUCB <https://arxiv.org/abs/1706.01383>`__) presented at COLT in July 2017, `LearnExp <https://smpybandits.github.io/docs/Policies.LearnExp.html>`__ comes from a `NIPS 2017 paper <https://arxiv.org/abs/1702.04825>`__, and `kl-UCB++ <https://smpybandits.github.io/docs/Policies.klUCBPlusPlus.html>`__ from an `ALT 2017 paper <https://hal.inria.fr/hal-01475078>`__.).\n\n-  Classical MAB have a lot of applications, from clinical trials, A/B testing, game tree exploration, and online content recommendation (my framework does *not* implement contextual bandit - yet).\n-  `Multi-player MAB <MultiPlayers.md>`__ have applications in Cognitive Radio, and my framework implements `all the collision models <https://smpybandits.github.io/docs/Environment/CollisionModels.html>`__ found in the literature, as well as all the algorithms from the last 10 years or so (`rhoRand <https://smpybandits.github.io/docs/PoliciesMultiPlayers/rhoRand.html>`__ from 2009, `MEGA <https://smpybandits.github.io/docs/Policies/MEGA.html>`__ from 2015, `MusicalChair <https://smpybandits.github.io/docs/Policies/MusicalChair.html>`__, and our state-of-the-art algorithms `RandTopM <https://smpybandits.github.io/docs/PoliciesMultiPlayers/RandTopM.html>`__ and `MCTopM <https://smpybandits.github.io/docs/PoliciesMultiPlayers/MCTopM.html>`__).\n\nWith this numerical framework, simulations can run on a single CPU or a multi-core machine, and summary plots are automatically saved as high-quality PNG, PDF and EPS (ready for being used in research article). Making new simulations is very easy, one only needs to write a configuration script and basically no code! See `these examples <https://github.com/SMPyBandits/SMPyBandits/search?l=Python&q=configuration&type=&utf8=%E2%9C%93>`__ (files named ``configuration_...py``).\n\nA complete `Sphinx <http://sphinx-doc.org/>`__ documentation for each algorithms and every piece of code (included constants in the configurations!) is available here: `SMPyBandits.GitHub.io <https://smpybandits.github.io/>`__.\n\n|PyPI implementation| |PyPI pyversions| |Maintenance| |Ask Me Anything|\n\n\n.. note::\n\n    - `I (Lilian Besson) <http://perso.crans.org/besson/>`__ have `started my PhD <http://perso.crans.org/besson/phd/>`__ in October 2016, and this is a part of my **on going** research since December 2016.\n    - I launched the `documentation <https://smpybandits.github.io/>`__ on March 2017, I wrote my first research articles using this framework in 2017 and decided to (finally) open-source my project in February 2018.\n\n--------------\n\nHow to cite this work?\n----------------------\n\nIf you use this package for your own work, please consider citing it with `this piece of BibTeX <https://github.com/SMPyBandits/SMPyBandits/raw/master/SMPyBandits.bib>`__:\n\n.. code:: bibtex\n\n    @misc{SMPyBandits,\n        title =   {{SMPyBandits: an Open-Source Research Framework for Single and Multi-Players Multi-Arms Bandits (MAB) Algorithms in Python}},\n        author =  {Lilian Besson},\n        year =    {2018},\n        url =     {https://github.com/SMPyBandits/SMPyBandits/},\n        howpublished = {Online at: \\url{github.com/SMPyBandits/SMPyBandits}},\n        note =    {Code at https://github.com/SMPyBandits/SMPyBandits/, documentation at https://smpybandits.github.io/}\n    }\n\nI also wrote a small paper to present *SMPyBandits*, and I will send it to `JMLR MLOSS <http://jmlr.org/mloss/>`__. The paper can be consulted `here on my website <https://perso.crans.org/besson/articles/SMPyBandits.pdf>`__.\n\n--------------\n\nOther interesting things\n------------------------\n\n`Single-player Policies <https://smpybandits.github.io/docs/Policies.html>`__\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n-  More than 65 algorithms, including all known variants of the `UCB <https://smpybandits.github.io/docs/Policies/UCB.html>`__, `kl-UCB <https://smpybandits.github.io/docs/Policies/klUCB.html>`__, `MOSS <https://smpybandits.github.io/docs/Policies/MOSS.html>`__ and `Thompson Sampling <https://smpybandits.github.io/docs/Policies/Thompson.html>`__ algorithms, as well as other less known algorithms (`OCUCB <https://smpybandits.github.io/docs/Policies/OCUCB.html>`__, `BESA <https://smpybandits.github.io/docs/Policies/OCUCB.html>`__, `OSSB <https://smpybandits.github.io/docs/Policies/OSSB.html>`__ etc).\n-  `SparseWrapper <https://smpybandits.github.io/docs/Policies.SparseWrapper.html#module-Policies.SparseWrapper>`__ is a generalization of `the SparseUCB from this article <https://arxiv.org/pdf/1706.01383/>`__.\n-  Implementation of very recent Multi-Armed Bandits algorithms, e.g., `kl-UCB++ <https://smpybandits.github.io/docs/Policies.klUCBPlusPlus.html>`__ (from `this article <https://hal.inria.fr/hal-01475078>`__), `UCB-dagger <https://smpybandits.github.io/docs/Policies.UCBdagger.html>`__ (from `this article <https://arxiv.org/pdf/1507.07880>`__), or `MOSS-anytime <https://smpybandits.github.io/docs/Policies.MOSSAnytime.html>`__ (from `this article <http://proceedings.mlr.press/v48/degenne16.pdf>`__).\n-  Experimental policies: `BlackBoxOpt <https://smpybandits.github.io/docs/Policies.BlackBoxOpt.html>`__ or `UnsupervisedLearning <https://smpybandits.github.io/docs/Policies.UnsupervisedLearning.html>`__ (using Gaussian processes to learn the arms distributions).\n\nArms and problems\n~~~~~~~~~~~~~~~~~\n\n-  My framework mainly targets stochastic bandits, with arms following\n   `Bernoulli <https://smpybandits.github.io/docs/Arms/Bernoulli.html>`__, bounded\n   (SMPyBandits/truncated) or unbounded\n   `Gaussian <https://smpybandits.github.io/docs/Arms/Gaussian.html>`__,\n   `Exponential <https://smpybandits.github.io/docs/Arms/Exponential.html>`__,\n   `Gamma <https://smpybandits.github.io/docs/Arms/Gamma.html>`__ or\n   `Poisson <https://smpybandits.github.io/docs/Arms/Poisson.html>`__ distributions.\n-  The default configuration is to use a fixed problem for N repetitions (e.g. 1000 repetitions, use `MAB.MAB <https://smpybandits.github.io/docs/Environment/MAB.html>`__), but there is also a perfect support for \"Bayesian\" problems where the mean vector µ1,…,µK change *at every repetition* (see `MAB.DynamicMAB <https://smpybandits.github.io/docs/Environment/MAB.html>`__).\n-  There is also a good support for Markovian problems, see `MAB.MarkovianMAB <https://smpybandits.github.io/docs/Environment/MAB.html>`__, even though I didn’t implement any policies tailored for Markovian problems.\n\nOther remarks\n~~~~~~~~~~~~~\n\n-  Everything here is done in an imperative, object oriented style. The API of the Arms, Policy and MultiPlayersPolicy classes is documented `in this page <https://smpybandits.github.io/API.html>`__.\n-  The code is `clean <https://smpybandits.github.io/logs/main_pylint_log.txt>`__, valid for both `Python 2 <https://smpybandits.github.io/logs/main_pylint_log.txt>`__ and `Python 3 <https://smpybandits.github.io/logs/main_pylint3_log.txt>`__.\n-  Some piece of code come from the `pymaBandits <http://mloss.org/software/view/415/>`__ project, but most of them were refactored. Thanks to the initial project!\n-  `G.Varoquaux <http://gael-varoquaux.info/>`__\\ ’s `joblib <https://joblib.readthedocs.io/>`__ is used for the `Evaluator <https://smpybandits.github.io/docs/Environment/Evaluator.html>`__ and `EvaluatorMultiPlayers <https://smpybandits.github.io/docs/Environment/EvaluatorMultiPlayers.html>`__ classes, so the simulations are easily parallelized on multi-core machines. (Put ``n_jobs = -1`` or ``PARALLEL = True`` in the config file to use all your CPU cores, as it is by default).\n\n--------------\n\n`How to run the experiments ? <How_to_run_the_code.md>`__\n---------------------------------------------------------\n\n    See this document: `How_to_run_the_code.md <https://smpybandits.github.io/How_to_run_the_code.html>`__ for more details.\n\nTL;DR: this short bash snippet shows how to clone the code, install the requirements for Python 3 (in a `virtualenv <https://virtualenv.pypa.io/en/stable/>`__, and starts some simulation for N=100 repetitions of the default non-Bayesian Bernoulli-distributed problem, for K=9 arms, an horizon of T=10000 and on 4 CPUs (it should take about 20 minutes for each simulations):\n\n.. code:: bash\n\n    cd /tmp/\n    # just be sure you have the latest virtualenv from Python 3\n    sudo pip3 install --upgrade --force-reinstall virtualenv\n\n    # create and active the virtualenv\n    virtualenv venv\n    . venv/bin/activate\n    type pip  # check it is /tmp/venv/bin/pip\n    type python  # check it is /tmp/venv/bin/python\n\n    pip install SMPyBandits  # pulls latest version from https://pypi.org/project/SMPyBandits/\n    # or you can also\n    pip install git+https://github.com/SMPyBandits/SMPyBandits/#egg=SMPyBandits[full]  # pulls latest version from https://github.com/SMPyBandits/SMPyBandits/\n\n    # run a single-player simulation!\n    N=100 T=10000 K=9 N_JOBS=4 make single\n    # run a multi-player simulation!\n    N=100 T=10000 M=3 K=9 N_JOBS=4 make more\n\n..\n\n-  If speed matters to you and you want to use algorithms based on `kl-UCB <https://smpybandits.github.io/docs/Policies/klUCB.html>`__, you should take the time to build and install the fast C implementation of the utilities KL functions. Default is to use `kullback.py <https://smpybandits.github.io/docs/Policies/kullback.html>`__, but using `the C version from Policies/C/ <github.com/SMPyBandits/SMPyBandits/tree/master/SMPyBandits/Policies/C/>`__ really speeds up the computations. Just follow the instructions, it should work well (you need ``gcc`` to be installed).\n-  And if speed matters, be sure that you have a working version of `Numba <https://numba.pydata.org/>`__, it is used by many small functions to (try to automatically) speed up the computations.\n\n--------------\n\nWarning\n~~~~~~~\n\n-  This work is still **experimental**! It’s `active research <https://github.com/SMPyBandits/SMPyBandits/graphs/contributors>`__. It should be completely bug free and every single module/file should work perfectly(as `this pylint log <https://smpybandits.github.io/logs/main_pylint_log.txt>`__ and `this other one <https://smpybandits.github.io/logs/main_pylint3_log.txt>`__ says), but bugs are sometimes hard to spot so if you encounter any issue, `please fill a bug ticket <https://github.com/SMPyBandits/SMPyBandits/issues/new>`__.\n-  Whenever I add a new feature, I run experiments to check that nothing is broken. But *there is no unittest* (I don’t have time). You would have to trust me!\n-  This project is NOT meant to be a library that you can use elsewhere, but a research tool. In particular, I don’t take ensure that any of the Python modules can be imported from another directory than the main directory.\n\nContributing?\n-------------\n\nContributions (issues, questions, pull requests) are of course welcome, but this project is and will stay a personal environment designed for quick research experiments, and will never try to be an industry-ready module for applications of Multi-Armed Bandits algorithms.\n\nIf you want to contribute, please have a look to the `CONTRIBUTING <https://smpybandits.github.io/CONTRIBUTING.html>`__ page, and if you want to be more seriously involved, read the `CODE_OF_CONDUCT <https://smpybandits.github.io/CODE_OF_CONDUCT.html>`__ page.\n\n-  You are welcome to `submit an issue <https://github.com/SMPyBandits/SMPyBandits/issues/new>`__, if it was not previously answered,\n-  If you have interesting example of use of SMPyBandits, please share it! (`Jupyter Notebooks <https://www.jupyter.org/>`__ are preferred). And fill a pull request to `add it to the notebooks examples <https://smpybandits.github.io/notebooks/README.html>`__.\n\n--------------\n\nLicense ? |GitHub license|\n--------------------------\n\n`MIT Licensed <https://lbesson.mit-license.org/>`__ (file `LICENSE <https://smpybandits.github.io/LICENSE>`__).\n\n© 2016-2018 `Lilian Besson <https://GitHub.com/Naereen>`__.\n\n|Maintenance| |Ask Me Anything| |Analytics| |PyPI implementation|\n|PyPI pyversions| |Documentation Status| |ForTheBadge uses-badges| |ForTheBadge uses-git|\n\n|forthebadge made-with-python| |ForTheBadge built-with-science|\n\n.. |PyPI implementation| image:: https://img.shields.io/pypi/implementation/smpybandits.svg\n.. |PyPI pyversions| image:: https://img.shields.io/pypi/pyversions/smpybandits.svg\n.. |Maintenance| image:: https://img.shields.io/badge/Maintained%3F-yes-green.svg\n   :target: https://GitHub.com/SMPyBandits/SMPyBandits/graphs/commit-activity\n.. |Ask Me Anything| image:: https://img.shields.io/badge/Ask%20me-anything-1abc9c.svg\n   :target: https://GitHub.com/Naereen/ama\n.. |GitHub license| image:: https://img.shields.io/github/license/SMPyBandits/SMPyBandits.svg\n   :target: https://github.com/SMPyBandits/SMPyBandits/blob/master/LICENSE\n.. |Analytics| image:: https://ga-beacon.appspot.com/UA-38514290-17/github.com/SMPyBandits/SMPyBandits/README.md?pixel\n   :target: https://GitHub.com/SMPyBandits/SMPyBandits/\n.. |Documentation Status| image:: https://readthedocs.org/projects/smpybandits/badge/?version=latest\n   :target: https://smpybandits.readthedocs.io/en/latest/?badge=latest\n.. |ForTheBadge uses-badges| image:: http://ForTheBadge.com/images/badges/uses-badges.svg\n   :target: http://ForTheBadge.com\n.. |ForTheBadge uses-git| image:: http://ForTheBadge.com/images/badges/uses-git.svg\n   :target: https://GitHub.com/\n.. |forthebadge made-with-python| image:: http://ForTheBadge.com/images/badges/made-with-python.svg\n   :target: https://www.python.org/\n.. |ForTheBadge built-with-science| image:: http://ForTheBadge.com/images/badges/built-with-science.svg\n   :target: https://GitHub.com/Naereen/\n\n\n",
    "description_content_type": "",
    "docs_url": null,
    "download_url": "https://github.com/SMPyBandits/SMPyBandits/releases/",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/SMPyBandits/SMPyBandits/",
    "keywords": "multi-arm-bandits simulations learning-theory centralized-algorithms decentralized-algorithms cognitive-radio",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "SMPyBandits",
    "package_url": "https://pypi.org/project/SMPyBandits/",
    "platform": "GNU/Linux",
    "project_url": "https://pypi.org/project/SMPyBandits/",
    "project_urls": {
      "Bug Reports": "https://github.com/SMPyBandits/SMPyBandits/issues",
      "Documentation": "https://smpybandits.github.io/",
      "Download": "https://github.com/SMPyBandits/SMPyBandits/releases/",
      "Homepage": "https://github.com/SMPyBandits/SMPyBandits/",
      "Source": "https://github.com/SMPyBandits/SMPyBandits/tree/master/"
    },
    "release_url": "https://pypi.org/project/SMPyBandits/0.9.7/",
    "requires_dist": [
      "numpy",
      "scipy (>0.9)",
      "matplotlib (>=2)",
      "joblib",
      "seaborn",
      "scikit-learn",
      "scikit-optimize",
      "sphinx-rtd-theme ; extra == 'doc'",
      "recommonmark ; extra == 'doc'",
      "nbsphinx ; extra == 'doc'",
      "pyreverse ; extra == 'doc'",
      "tqdm ; extra == 'full'",
      "numba ; extra == 'full'",
      "docopt ; extra == 'full'",
      "ipython ; extra == 'full'"
    ],
    "requires_python": "",
    "summary": "SMPyBandits: Open-Source Python package for Single- and Multi-Players multi-armed Bandits algorithms.",
    "version": "0.9.7",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 6029551,
  "releases": {
    "0.9.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ef856be28df19f65354fa45fe12f139bf026249cf7f7dfd2e77aadc66ecc4a61",
          "md5": "5cec1af4001b13d38f1d2a4deb0613ce",
          "sha256": "b2c98e3555da59bc8a1ebc427e9a9e8a8604f6cd349ad0f9abf9fbddef668998"
        },
        "downloads": -1,
        "filename": "SMPyBandits-0.9.2-py2.py3-none-any.whl",
        "has_sig": true,
        "md5_digest": "5cec1af4001b13d38f1d2a4deb0613ce",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 401582,
        "upload_time": "2018-03-07T15:05:14",
        "upload_time_iso_8601": "2018-03-07T15:05:14.306921Z",
        "url": "https://files.pythonhosted.org/packages/ef/85/6be28df19f65354fa45fe12f139bf026249cf7f7dfd2e77aadc66ecc4a61/SMPyBandits-0.9.2-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.9.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "142d866590b59fba3c0792060effed3c52ba878c0c3242bdb7163a7108424e1b",
          "md5": "ec66bd64df90828ed3554a8ce889a673",
          "sha256": "52b0f9d3271f5734a2c0abd0f0df6204daac73e1ed6b56457752f5475fa28612"
        },
        "downloads": -1,
        "filename": "SMPyBandits-0.9.3-py2.py3-none-any.whl",
        "has_sig": true,
        "md5_digest": "ec66bd64df90828ed3554a8ce889a673",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 487977,
        "upload_time": "2018-11-09T21:26:13",
        "upload_time_iso_8601": "2018-11-09T21:26:13.477931Z",
        "url": "https://files.pythonhosted.org/packages/14/2d/866590b59fba3c0792060effed3c52ba878c0c3242bdb7163a7108424e1b/SMPyBandits-0.9.3-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.9.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0715440f090019e2f8552726957507370699092f76745ba24d871c65ab6860f8",
          "md5": "364fd733796edcb9aa544fce543fdc6e",
          "sha256": "407c62f3eb8f1e186d9b33263c72aea39f0242a2645da74a5e5b61b019a27edd"
        },
        "downloads": -1,
        "filename": "SMPyBandits-0.9.4-py2.py3-none-any.whl",
        "has_sig": true,
        "md5_digest": "364fd733796edcb9aa544fce543fdc6e",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 487986,
        "upload_time": "2018-11-09T21:48:13",
        "upload_time_iso_8601": "2018-11-09T21:48:13.161110Z",
        "url": "https://files.pythonhosted.org/packages/07/15/440f090019e2f8552726957507370699092f76745ba24d871c65ab6860f8/SMPyBandits-0.9.4-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.9.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e91e6abea2ff26a0978c879a17b133982c0d3025983b1213546411ebdc20cecd",
          "md5": "8c7326f5df34118cbae5fc362a7ff4a2",
          "sha256": "e7864755135123a06e0f9b514b69f9c9a8c5bc366a690cdab29dff0604550c0c"
        },
        "downloads": -1,
        "filename": "SMPyBandits-0.9.5-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "8c7326f5df34118cbae5fc362a7ff4a2",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 517066,
        "upload_time": "2019-01-17T09:23:24",
        "upload_time_iso_8601": "2019-01-17T09:23:24.599723Z",
        "url": "https://files.pythonhosted.org/packages/e9/1e/6abea2ff26a0978c879a17b133982c0d3025983b1213546411ebdc20cecd/SMPyBandits-0.9.5-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.9.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ce7fdc30ec12e1b3e5b6a03fa0865e3ddd4406a928d1ee720195e5e291b619a6",
          "md5": "43fe96884f2af42c3c2d241934823a1d",
          "sha256": "e3530ef364f4d178e18673046d9e00d02bb6df0b84a12ce7ce94c99ca8f95bfa"
        },
        "downloads": -1,
        "filename": "SMPyBandits-0.9.6-py2.py3-none-any.whl",
        "has_sig": true,
        "md5_digest": "43fe96884f2af42c3c2d241934823a1d",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 551957,
        "upload_time": "2019-07-12T09:52:59",
        "upload_time_iso_8601": "2019-07-12T09:52:59.910643Z",
        "url": "https://files.pythonhosted.org/packages/ce/7f/dc30ec12e1b3e5b6a03fa0865e3ddd4406a928d1ee720195e5e291b619a6/SMPyBandits-0.9.6-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.9.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "015f515fffa380f0e381740bca33dfadf1717b2c8a3dc85cae1526d82761e0dd",
          "md5": "7ac75a69c7e3933db1e46e5b5f76f204",
          "sha256": "441da15f005519c480ab60f27a73c1b06cfcb8b864d1051adbb9ecdefb17ea7f"
        },
        "downloads": -1,
        "filename": "SMPyBandits-0.9.7-py2.py3-none-any.whl",
        "has_sig": true,
        "md5_digest": "7ac75a69c7e3933db1e46e5b5f76f204",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 552532,
        "upload_time": "2019-10-25T13:20:44",
        "upload_time_iso_8601": "2019-10-25T13:20:44.435371Z",
        "url": "https://files.pythonhosted.org/packages/01/5f/515fffa380f0e381740bca33dfadf1717b2c8a3dc85cae1526d82761e0dd/SMPyBandits-0.9.7-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "015f515fffa380f0e381740bca33dfadf1717b2c8a3dc85cae1526d82761e0dd",
        "md5": "7ac75a69c7e3933db1e46e5b5f76f204",
        "sha256": "441da15f005519c480ab60f27a73c1b06cfcb8b864d1051adbb9ecdefb17ea7f"
      },
      "downloads": -1,
      "filename": "SMPyBandits-0.9.7-py2.py3-none-any.whl",
      "has_sig": true,
      "md5_digest": "7ac75a69c7e3933db1e46e5b5f76f204",
      "packagetype": "bdist_wheel",
      "python_version": "py2.py3",
      "requires_python": null,
      "size": 552532,
      "upload_time": "2019-10-25T13:20:44",
      "upload_time_iso_8601": "2019-10-25T13:20:44.435371Z",
      "url": "https://files.pythonhosted.org/packages/01/5f/515fffa380f0e381740bca33dfadf1717b2c8a3dc85cae1526d82761e0dd/SMPyBandits-0.9.7-py2.py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}