{
  "info": {
    "author": "Yann Bouteiller, Edouard Geze",
    "author_email": "yann.bouteiller@polymtl.ca, edouard.geze@hotmail.fr",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Intended Audience :: Developers",
      "Intended Audience :: Education",
      "Intended Audience :: Information Technology",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python",
      "Topic :: Games/Entertainment",
      "Topic :: Scientific/Engineering :: Artificial Intelligence"
    ],
    "description": "# TMRL\r\n\r\n[![PyPI version](https://badge.fury.io/py/tmrl.svg)](https://badge.fury.io/py/tmrl)\r\n[![PyPI - License](https://img.shields.io/pypi/l/tmrl?color=blue)](https://github.com/trackmania-rl/tmrl/blob/master/LICENSE)\r\n[![DOI](https://zenodo.org/badge/277973609.svg)](https://zenodo.org/badge/latestdoi/277973609)\r\n\r\n| **`API reference`**                                                                                                                         |\r\n|---------------------------------------------------------------------------------------------------------------------------------------------|\r\n| [![Documentation Status](https://readthedocs.org/projects/tmrl/badge/?version=latest)](https://tmrl.readthedocs.io/en/latest/?badge=latest) |\r\n\r\n\r\n`tmrl` is a fully-fledged distributed RL framework for robotics, designed to help you train Deep Reinforcement Learning AIs in real-time applications.\r\n\r\n`tmrl` comes with a readily implemented pipeline for the TrackMania 2020 video game.\r\n\r\n![example](https://github.com/trackmania-rl/tmrl/releases/download/v0.2.0/video_lidar.gif)\r\n\r\n\r\n **TL;DR:**\r\n\r\n- :red_car: **AI and TM enthusiasts:**\\\r\n`tmrl` enables you to train AIs in TrackMania with minimal effort. Tutorial for you guys [here](readme/get_started.md) and video of a pre-trained AI [here](https://www.youtube.com/watch?v=LN29DDlHp1U) (with a beginner introduction to the SAC algorithm).\r\n\r\n- :rocket: **ML developers / roboticists:**\\\r\n`tmrl` is a python library designed to facilitate the implementation of deep RL applications in real-time settings such as robots and video games. Full tutorial [here](readme/tuto_library.md) and documentation [here](https://tmrl.readthedocs.io/en/latest/).\r\n\r\n- :ok_hand: **ML developers who are TM enthusiasts with no interest in learning this huge thing:**\\\r\n`tmrl` provides a Gymnasium environment for TrackMania that is easy to use. Fast-track for you guys [here](#trackmania-gymnasium-environment).\r\n\r\n- :earth_americas: **Everyone:**\\\r\n`tmrl` hosts the [TrackMania Roborace League](readme/competition.md), a vision-based AI competition where participants design real-time self-racing AIs in the TrackMania video game.\r\n\r\n\r\n## Quick links\r\n- [The TMRL Project](#the-tmrl-project)\r\n  - [Introduction](#introduction)\r\n    - [User features](#user-features-trackmania)\r\n    - [Developer features](#developer-features-real-time-applications-in-python)\r\n    - [TMRL in the media](#tmrl-in-the-media)\r\n  - [Installation](readme/Install.md)\r\n  - [Getting started](readme/get_started.md)\r\n  - [TMRL python library for robot RL](readme/tuto_library.md)\r\n    - [API reference](https://tmrl.readthedocs.io/en/latest/)\r\n  - [Security (important)](#security)\r\n- [TrackMania applications](#autonomous-driving-in-trackmania)\r\n  - [TrackMania Roborace League](readme/competition.md)\r\n  - [TrackMania Gymnasium environment](#trackmania-gymnasium-environment)\r\n    - [LIDAR environment](#lidar-environment)\r\n    - [Full environment](#full-environment)\r\n  - [TrackMania training details](#trackmania-training-details)\r\n    - [RL basics](#reinforcement-learning-basics)\r\n    - [SAC](#soft-actor-critic)\r\n    - [REDQ](#randomized-ensembled-double-q-learning)\r\n    - [A clever reward](#a-clever-reward)\r\n    - [Available action spaces](#available-action-spaces)\r\n    - [Available observation spaces](#available-observation-spaces)\r\n    - [Results](#results)\r\n- [Framework details](#framework-details)\r\n    - [Real-time Gym framework](#real-time-gym-framework)\r\n      - [rtgym repo](https://github.com/yannbouteiller/rtgym)\r\n  - [Remote training architecture](#remote-training-architecture)\r\n- [Contribute](#authors)\r\n- [Sponsors](#sponsors)\r\n\r\n\r\n# The TMRL project\r\n\r\n## Introduction\r\n\r\n`tmrl` is a python framework designed to help you train Artificial Intelligences (AIs) through deep Reinforcement Learning (RL), for your own robots or real-time video games.\r\n\r\n_Note: In the context of RL, an AI is called a policy._\r\n\r\n### User features (TrackMania):\r\n* **Training algorithms:**\r\n`tmrl` lets you easily train policies in TrackMania with state-of-the-art Deep Reinforcement Learning algorithms such as [Soft Actor-Critic](https://www.youtube.com/watch?v=LN29DDlHp1U) (SAC) and [Randomized Ensembled Double Q-Learning](https://arxiv.org/abs/2101.05982) (REDQ).\r\nThese algorithms store collected samples in a large dataset, called a replay memory.\r\nIn parallel, this dataset is used to train an artificial neural network (policy) that maps observations (images, speed...) to relevant actions (gas, break, steering angle...).\r\n\r\n* **Analog control:**\r\n`tmrl` controls the game using a virtual gamepad, which enables analog input.\r\n\r\n* **Different types of observation:**\r\nThe AI can either use raw unprocessed snapshots, or a LIDAR (Light Detection and Ranging) computed from the snapshots in order to perceive its environment.\r\n\r\n* **Models:**\r\nTo process LIDAR measurements, `tmrl` uses a Multi-Layer Perceptron (MLP).\r\nTo process raw camera images (snapshots), it uses a Convolutional Neural Network (CNN).\r\nThese models learn the physics from histories or observations equally spaced in time.\r\n\r\n### Developer features (real-time applications in Python):\r\n* **Python library:**\r\n`tmrl` is a complete framework designed to help you successfully implement deep RL in your [real-time applications](#real-time-gym-framework) (e.g., robots...).\r\nA complete tutorial toward doing this is provided [here](readme/tuto_library.md).\r\n\r\n* **TrackMania Gymnasium environment:**\r\n`tmrl` comes with a real-time Gymnasium environment for the TrackMania2020 video game, based on [rtgym](https://pypi.org/project/rtgym/). Once `tmrl` is installed, it is easy to use this environment in your own training framework. More information [here](#trackmania-gymnasium-environment).\r\n\r\n* **Distributed training:**\r\n`tmrl` is based on a single-server / multiple-clients architecture.\r\nIt enables collecting samples locally on one or several computers and training remotely on a High Performance Computing cluster.\r\nFind out more [here](#remote-training-architecture).\r\n\r\n* **External libraries:**\r\nThis project gave birth to a few sub-projects of more general interest that were cut out and packaged as standalone python libraries.\r\nIn particular, [rtgym](https://github.com/yannbouteiller/rtgym) enables implementing Gymnasium environments in real-time applications,\r\n[vgamepad](https://github.com/yannbouteiller/vgamepad) enables emulating virtual game controllers,\r\nand [tlspyo](https://github.com/MISTLab/tls-python-object) enables transferring python object over the Internet in a secure fashion.\r\n\r\n### TMRL in the media:\r\n- In the french show [Underscore_ (2022-06-08)](https://www.youtube.com/watch?v=c1xq7iJ3f9E), we used a vision-based (LIDAR) policy to play against the TrackMania world champions. Spoiler: our policy lost by far (expectedly :smile:); the superhuman target was set to about 32s on the `tmrl-test` track, while the trained policy had a mean performance of about 45.5s. The Gymnasium environment that we used for the show is available [here](#lidar-with-track-progress).\r\n\r\n## Installation\r\n\r\nDetailed instructions for installation are provided at [this link](readme/Install.md).\r\n\r\n## Getting started\r\n\r\nFull guidance toward setting up an environment in TrackMania, testing pre-trained weights, as well as a beginner-friendly tutorial to train, test, and fine-tune your own models,\r\nare provided at [this link](readme/get_started.md).\r\n\r\n## TMRL python library\r\n\r\nAn advanced tutorial toward implementing your own ad-hoc optimized training pipelines for your own real-time tasks other than TrackMania (robots, other video games...) is provided [here](readme/tuto_library.md).\r\n\r\n## Security\r\n\r\n:warning: **IMPORTANT: READ AND UNDERSTAND THIS SECTION BEFORE YOU USE `tmrl` ON A PUBLIC NETWORK.**\r\n\r\nSecurity-wise, `tmrl` is based on [tlspyo](https://github.com/MISTLab/tls-python-object).\r\n\r\nBy default, `tmrl` transfers objects via non-encrypted TCP in order to work out-of-the-box.\r\nThis is fine as long as you use `tmrl` on your own private network.\r\n\r\nHOWEVER, THIS IS A SECURITY BREACH IF YOU START USING `tmrl` ON A PUBLIC NETWORK.\r\n\r\nTo use `tmrl` on a public network (for instance, on the Internet), we recommend that you enable Transport Layer Security (TLS).\r\nTo do so, follow these instructions on all your machines:\r\n\r\n- Open `config.json`;\r\n- Set the `\"TLS\"` entry to `true`;\r\n- Replace the `\"PASSWORD\"` entry with a strong password of your own (the same on all your machines);\r\n- On the machine hosting your `Server`, generate a TLS key and certificate (follow the [tlspyo instructions](https://github.com/MISTLab/tls-python-object#tls-setup));\r\n- Copy your generated certificate on all other machines (either in the default tlspyo credentials directory or in a directory of your choice);\r\n- If you used your own directory in the previous step, replace the `\"TLS_CREDENTIALS_DIRECTORY\"` entry with its path.\r\n\r\nIf for any reason you do not wish to use TLS (not recommended), you should still at least use a custom password in `config.json` when training over a public network.\r\nHOWEVER, DO NOT USE A PASSWORD THAT YOU USE FOR OTHER APPLICATIONS.\r\nThis is because, without TLS encryption, this password will be readable in the packets sent by your machines over the network.\r\n\r\n# Autonomous driving in TrackMania\r\n\r\n## TrackMania Roborace League\r\n\r\nWe host the [TrackMania Roborace League](readme/competition.md), a fun way of benchmarking self-racing approaches in the TrackMania2020 video game.\r\nFollow the link for information about the competition, including the current leaderboard and instructions to participate.\r\n\r\nRegardless of whether they want to compete or not, ML developers will find the [competition tutorial script](https://github.com/trackmania-rl/tmrl/blob/master/tmrl/tuto/competition/custom_actor_module.py) useful for creating advanced training pipelines in TrackMania.\r\n\r\n## TrackMania Gymnasium environment\r\nIn case you only wish to use the `tmrl` Real-Time Gym environment for TrackMania in your own training framework, this is made possible by the `get_environment()` method:\r\n\r\n_(NB: the game needs to be set up as described in the [getting started](readme/get_started.md) instructions)_\r\n```python\r\nfrom tmrl import get_environment\r\nfrom time import sleep\r\nimport numpy as np\r\n\r\n# default LIDAR observations are of shape: ((1,), (4, 19), (3,), (3,))\r\n# representing: (speed, 4 last LIDARs, 2 previous actions)\r\n# actions are [gas, break, steer], analog between -1.0 and +1.0\r\ndef model(obs):\r\n    \"\"\"\r\n    simplistic policy for LIDAR observations\r\n    \"\"\"\r\n    deviation = obs[1].mean(0)\r\n    deviation /= (deviation.sum() + 0.001)\r\n    steer = 0\r\n    for i in range(19):\r\n        steer += (i - 9) * deviation[i]\r\n    steer = - np.tanh(steer * 4)\r\n    steer = min(max(steer, -1.0), 1.0)\r\n    return np.array([1.0, 0.0, steer])\r\n\r\n# Let us retrieve the TMRL Gymnasium environment.\r\n# The environment you get from get_environment() depends on the content of config.json\r\nenv = get_environment()\r\n\r\nsleep(1.0)  # just so we have time to focus the TM20 window after starting the script\r\n\r\nobs, info = env.reset()  # reset environment\r\nfor _ in range(200):  # rtgym ensures this runs at 20Hz by default\r\n    act = model(obs)  # compute action\r\n    obs, rew, terminated, truncated, info = env.step(act)  # step (rtgym ensures healthy time-steps)\r\n    if terminated or truncated:\r\n        break\r\nenv.wait()  # rtgym-specific method to artificially 'pause' the environment when needed\r\n```\r\n\r\nThe environment flavor can be chosen and customized by changing the content of the `ENV` entry in `TmrlData\\config\\config.json`:\r\n\r\n_(NB: do not copy-paste the examples, comments are not supported in vanilla .json files)_\r\n\r\n### Full environment:\r\nThis version of the environment features full screenshots to be processed with, e.g., a CNN.\r\nIn addition, this version features the speed, gear and RPM.\r\nThis works on any track, using any (sensible) camera configuration.\r\n\r\n```json5\r\n{\r\n  \"ENV\": {\r\n    \"RTGYM_INTERFACE\": \"TM20FULL\",  // TrackMania 2020 with full screenshots\r\n    \"WINDOW_WIDTH\": 256,  // width of the game window (min: 256)\r\n    \"WINDOW_HEIGHT\": 128,  // height of the game window (min: 128)\r\n    \"SLEEP_TIME_AT_RESET\": 1.5,  // the environment sleeps for this amount of time after each reset\r\n    \"IMG_HIST_LEN\": 4,  // length of the history of images in observations (set to 1 for RNNs)\r\n    \"IMG_WIDTH\": 64,  // actual (resized) width of the images in observations\r\n    \"IMG_HEIGHT\": 64,  // actual (resized) height of the images in observations\r\n    \"IMG_GRAYSCALE\": true,  // true for grayscale images, false for color images\r\n    \"RTGYM_CONFIG\": {\r\n      \"time_step_duration\": 0.05,  // duration of a time step\r\n      \"start_obs_capture\": 0.04,  // duration before an observation is captured\r\n      \"time_step_timeout_factor\": 1.0,  // maximum elasticity of a time step\r\n      \"act_buf_len\": 2,  // length of the history of actions in observations (set to 1 for RNNs)\r\n      \"benchmark\": false,  // enables benchmarking your environment when true\r\n      \"wait_on_done\": true\r\n    }\r\n  }\r\n}\r\n```\r\nNote that human players can see or hear the features provided by this environment: we provide no \"cheat\" that would render the approach non-transferable to the real world.\r\nIn case you do wish to cheat, though, you can easily take inspiration from our [rtgym interfaces](https://github.com/trackmania-rl/tmrl/blob/master/tmrl/custom/custom_gym_interfaces.py) to build your own custom environment for TrackMania.\r\n\r\nThe `Full` environment is used in the official [TMRL competition](https://github.com/trackmania-rl/tmrl/blob/master/readme/competition.md), and custom environments are featured in the \"off\" competition :wink:\r\n\r\n### LIDAR environment:\r\nIn this version of the environment, screenshots are reduced to 19-beam LIDARs to be processed with, e.g., an MLP.\r\nIn addition, this version features the speed (that human players can see).\r\nThis works only on plain road with black borders, using the front camera with car hidden.\r\n```json5\r\n{\r\n  \"ENV\": {\r\n    \"RTGYM_INTERFACE\": \"TM20LIDAR\",  // TrackMania 2020 with LIDAR observations\r\n    \"WINDOW_WIDTH\": 958,  // width of the game window (min: 256)\r\n    \"WINDOW_HEIGHT\": 488,  // height of the game window (min: 128)\r\n    \"SLEEP_TIME_AT_RESET\": 1.5,  // the environment sleeps for this amount of time after each reset\r\n    \"IMG_HIST_LEN\": 4,  // length of the history of LIDAR measurements in observations (set to 1 for RNNs)\r\n    \"RTGYM_CONFIG\": {\r\n      \"time_step_duration\": 0.05,  // duration of a time step\r\n      \"start_obs_capture\": 0.04,  // duration before an observation is captured\r\n      \"time_step_timeout_factor\": 1.0,  // maximum elasticity of a time step\r\n      \"act_buf_len\": 2,  // length of the history of actions in observations (set to 1 for RNNs)\r\n      \"benchmark\": false,  // enables benchmarking your environment when true\r\n      \"wait_on_done\": true\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n### LIDAR with track progress\r\n\r\nIf you have watched the [2022-06-08 episode](https://www.youtube.com/watch?v=c1xq7iJ3f9E) of the Underscore_ talk show (french), note that the policy you have seen has been trained in a slightly augmented version of the LIDAR environment: on top of LIDAR and speed value, we have added a value representing the percentage of completion of the track, so that the model can know the turns in advance similarly to humans practicing a given track.\r\nThis environment will not be accepted in the competition, as it is de-facto less generalizable.\r\nHowever, if you wish to use this environment, e.g., to beat our results, you can use the following `config.json`:\r\n\r\n```json5\r\n{\r\n  \"ENV\": {\r\n    \"RTGYM_INTERFACE\": \"TM20LIDARPROGRESS\",  // TrackMania 2020 with LIDAR and percentage of completion\r\n    \"WINDOW_WIDTH\": 958,  // width of the game window (min: 256)\r\n    \"WINDOW_HEIGHT\": 488,  // height of the game window (min: 128)\r\n    \"SLEEP_TIME_AT_RESET\": 1.5,  // the environment sleeps for this amount of time after each reset\r\n    \"IMG_HIST_LEN\": 4,  // length of the history of LIDAR measurements in observations (set to 1 for RNNs)\r\n    \"RTGYM_CONFIG\": {\r\n      \"time_step_duration\": 0.05,  // duration of a time step\r\n      \"start_obs_capture\": 0.04,  // duration before an observation is captured\r\n      \"time_step_timeout_factor\": 1.0,  // maximum elasticity of a time step\r\n      \"act_buf_len\": 2,  // length of the history of actions in observations (set to 1 for RNNs)\r\n      \"benchmark\": false,  // enables benchmarking your environment when true\r\n      \"wait_on_done\": true\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n## TrackMania training details\r\n\r\nIn `tmrl`, model (AI) that knows absolutely nothing about driving or even about what a road is, is set at the starting point of a track.\r\nIts goal is to learn how to complete the track as fast as possible by exploring its own capacities and environment.\r\n\r\nThe car feeds observations such as images to an artificial neural network, which must output the best possible controls from these observations.\r\nThis implies that the AI must understand its environment in some way.\r\nTo achieve this understanding, the car explores the world for a few hours (up to a few days), slowly gaining an understanding of how to act efficiently.\r\nThis is accomplished through Deep Reinforcement Learning (RL).\r\n\r\n### Reinforcement Learning basics\r\n\r\nMost RL algorithms are based on a mathematical description of the environment called Markov Decision Process (MDP).\r\nA policy trained though RL interacts with an MDP as follows:\r\n\r\n![reward](readme/img/mrp.png)\r\n\r\nIn this illustration, the policy is represented as the stickman, and time is represented as time-steps of fixed duration.\r\nAt each time-step, the policy applies an action (float values for gas, brake, and steering) computed from an observation.\r\nThe action is applied to the environment, which yields a new observation at the end of the transition.\r\n\r\nFor the purpose of training this policy, the environment also provides another signal, called the \"reward\".\r\nIndeed, RL is derived from behaviorism, which relies on the fundamental idea that intelligence is the result of a history of positive and negative stimuli.\r\nThe reward received by the AI at each time-step is a measure of how well it performs.\r\n\r\nIn order to learn how to drive, the AI tries random actions in response to incoming observations, gets rewarded positively or negatively, and optimizes its policy so that its long-term reward is maximized.\r\n\r\n### Soft Actor-Critic\r\n\r\n([Introductory video](https://www.youtube.com/watch?v=LN29DDlHp1U))\r\n\r\n([Full paper](https://arxiv.org/abs/1801.01290))\r\n\r\nSoft Actor-Critic (SAC) is an algorithm that enables learning continuous stochastic controllers.\r\n\r\nMore specifically, SAC does this using two separate Artificial Neural Networks (NNs):\r\n\r\n- The first one, called the \"policy network\" (or, in the literature, the \"actor\"), is the NN the user is ultimately interested in : the controller of the car.\r\n  It takes observations as input and outputs actions.\r\n- The second called the \"value network\" (or, in the literature, the \"critic\"), is used to train the policy network.\r\n  It takes an observation ```x``` and an action ```a``` as input, to output a value.\r\n  This value is an estimate of the expected sum of future rewards if the AI observes ```x```, selects ```a```, and then uses the policy network forever (there is also a discount factor so that this sum is not infinite).\r\n\r\nBoth networks are trained in parallel using each other.\r\nThe reward signal is used to train the value network, and the value network is used to train the policy network.\r\n\r\nAdvantages of SAC over other existing methods are the following:\r\n- It is able to store transitions in a huge circular buffer called the \"replay memory\" and reuse these transitions several times during training.\r\n  This is an important property for applications such as `tmrl` where only a relatively small number of transitions can be collected due to the Real-Time nature of the setting.\r\n- It is able to output analog controls. We use this property with a virtual gamepad.\r\n- It maximizes the entropy of the learned policy.\r\n  This means that the policy will be as random as possible while maximizing the reward.\r\n  This property helps explore the environment and is known to produce policies that are robust to external perturbations, which is of central importance e.g. in real-world self-driving scenarios.\r\n\r\n### Randomized Ensembled Double Q-Learning\r\n\r\n([Full paper](https://arxiv.org/abs/2101.05982))\r\n\r\nREDQ is a more recent methodology that improves the performance of value-based algorithms such as SAC.\r\n\r\nThe improvement introduced by REDQ consists essentially of training an ensemble of parallel value networks from which a subset is randomly sampled to evaluate target values during training.\r\nThe authors show that this enables low-bias updates and a sample efficiency comparable to model-based algorithms, at a much lower computational cost.\r\n\r\nBy default, `tmrl` trains policies with vanilla SAC.\r\nTo use REDQ-SAC, edit `TmrlData\\config\\config.json` on the machine used for training, and replace the `\"SAC\"` value with `\"REDQSAC\"` in the `\"ALGORITHM\"` entry.\r\nYou also need values for the `\"REDQ_N\"`, `\"REDQ_M\"` and `\"REDQ_Q_UPDATES_PER_POLICY_UPDATE\"` entries, where `\"REDQ_N\"` is the number of parallel critics, `\"REDQ_M\"` is the size of the subset, and `\"REDQ_Q_UPDATES_PER_POLICY_UPDATE\"` is a number of critic updates happenning between each actor update.\r\n\r\nFor instance, a valid `\"ALG\"` entry using REDQ-SAC is:\r\n\r\n```json\r\n  \"ALG\": {\r\n    \"ALGORITHM\": \"REDQSAC\",\r\n    \"LEARN_ENTROPY_COEF\":false,\r\n    \"LR_ACTOR\":0.0003,\r\n    \"LR_CRITIC\":0.00005,\r\n    \"LR_ENTROPY\":0.0003,\r\n    \"GAMMA\":0.995,\r\n    \"POLYAK\":0.995,\r\n    \"TARGET_ENTROPY\":-7.0,\r\n    \"ALPHA\":0.37,\r\n    \"REDQ_N\":10,\r\n    \"REDQ_M\":2,\r\n    \"REDQ_Q_UPDATES_PER_POLICY_UPDATE\":20\r\n  },\r\n```\r\n\r\n### A clever reward\r\n\r\nAs mentioned before, a reward function is needed to evaluate how well the policy performs.\r\n\r\nThere are multiple reward functions that could be used.\r\nFor instance, one could directly use the raw speed of the car as a reward.\r\nThis makes some sense because the car slows down when it crashes and goes fast when it is performing well.\r\nWe use this as a reward in TrackMania Nations Forever.\r\n\r\nHowever, such approach is naive.\r\nIndeed, the actual goal of racing is not to move as fast as possible.\r\nRather, one wants to complete the largest portion of the track in the smallest possible amount of time.\r\nThis is not equivalent as one should consider the optimal trajectory, which may imply slowing down on sharp turns in order to take the apex of each curve.\r\n\r\nIn TrackMania 2020, we use a more advanced and conceptually more interesting reward function:\r\n\r\n![reward](readme/img/Reward.PNG)\r\n\r\nFor a given track, we record one single demonstration trajectory.\r\nThis does not have to be a good demonstration, but only to follow the track.\r\nOnce the demonstration trajectory is recorded, it is automatically divided into equally spaced points.\r\n\r\nDuring training, at each time-step, the reward is then the number of such points that the car has passed since the previous time-step.\r\nIn a nutshell, whereas the previous reward function was measuring how fast the car was, this new reward function measures how good it is at covering a big portion of the track in a given amount of time.\r\n\r\n### Available action spaces\r\n\r\nIn `tmrl`, the car can be controlled in two different ways:\r\n\r\n- The policy can output simple (binary) arrow presses.\r\n- On Windows, the policy controls the car with analog inputs by emulating an XBox360 controller thanks to the [vgamepad](https://pypi.org/project/vgamepad/) library.\r\n\r\n### Available observation spaces\r\n\r\nDifferent observation spaces are available in `tmrl`:\r\n\r\n- A history of raw screenshots (typically 4).\r\n- A history of LIDAR measurement computed from raw screenshots in tracks with black borders.\r\n\r\nIn addition, we provide the norm of the velocity as part of the observation space in all our experiments.\r\n\r\nExample of `tmrl` environment in TrackMania Nations Forever with a single LIDAR measurement:\r\n\r\n![reward](readme/img/lidar.png)\r\n\r\nIn TrackMania Nations Forever, we use to compute the raw speed from screenshots thanks to the 1-NN algorithm.\r\n\r\nIn TrackMania 2020, we now use the [OpenPlanet](https://openplanet.nl) API to retrieve the raw speed directly.\r\n\r\n### Results\r\n\r\nWe train policies in Real-Time with several observation spaces.\r\nWe show that our AIs are able to take advantage of the more complex types of observations in order to learn complex dynamics, leading to more clever policies:\r\n\r\nIn the following experiment, on top of the raw speed, the blue car is using a single LIDAR measurement whereas the red car is using a history of 4 LIDAR measurements.\r\nThe positions of both cars are captured at constant time intervals in this animation:\r\n\r\n![Turn](readme/img/turn_tm20.gif)\r\n\r\nThe blue car learned to drive at a constant speed, as it is the best it can do from its naive observation space.\r\nConversely, the red car is able to infer higher-order dynamics from the history of 4 LIDARs and successfully learned to break, take the apex of the curve, and accelerate again after this sharp turn, which is slightly better in this situation.\r\n\r\n\r\n# Framework details\r\n\r\n## Real-time Gym framework:\r\nThis project uses [Real-Time Gym](https://github.com/yannbouteiller/rtgym) (```rtgym```), a simple python framework that enables efficient real-time implementations of Delayed Markov Decision Processes in real-world applications.\r\n\r\n```rtgym``` constrains the times at which actions are sent and observations are retrieved as follows:\r\n\r\n![Real-Time Gym Framework](https://raw.githubusercontent.com/yannbouteiller/rtgym/main/figures/rt_gym_env.png \"Real-Time Gym Framework\")\r\n\r\nTime-steps are being elastically constrained to their nominal duration. When this elastic constraint cannot be satisfied, the previous time-step times out and the new time-step starts from the current timestamp.\r\n\r\nCustom `rtgym` interfaces for Trackmania used by `tmrl` are implemented in [custom_gym_interfaces.py](https://github.com/yannbouteiller/tmrl/blob/master/tmrl/custom/custom_gym_interfaces.py).\r\n\r\n## Remote training architecture:\r\n\r\n`tmrl` is built with [tlspyo](https://github.com/MISTLab/tls-python-object).\r\nIts client-server architecture is similar to [Ray RLlib](https://docs.ray.io/en/latest/rllib.html).\r\n`tmrl` is not meant to compete with Ray, but it is much simpler to adapt in order to implement ad-hoc pipelines, and works on both Windows and Linux.\r\n\r\n`tmrl` collects training samples from several rollout workers (typically several computers and/or robots).\r\nEach rollout worker stores its collected samples in a local buffer, and periodically sends this replay buffer to the central server.\r\nPeriodically, each rollout worker also receives new policy weights from the central server and updates its policy network.\r\n\r\nThe central server is located either on the localhost of one of the rollout worker computers, on another computer on the local network, or on another computer on the Internet.\r\nIt collects samples from all the connected rollout workers and stores these in a local buffer.\r\nThis buffer is periodically sent to the trainer interface.\r\nPeriodically, the central server receives updated policy weights from the trainer interface and broadcasts these to all connected rollout workers.\r\n\r\nThe trainer interface is typically located on a non-rollout worker computer of the local network, or on another computer on the Internet (like a GPU cluster).\r\nOf course, it is also possible to locate everything on localhost when needed.\r\nThe trainer interface periodically receives the samples gathered by the central server and appends these to a replay memory.\r\nPeriodically, it sends the new policy weights to the central server.\r\n\r\nThese mechanics can be summarized as follows:\r\n\r\n![Networking architecture](readme/img/network_interface.png \"Networking Architecture\")\r\n\r\n\r\n# Development roadmap:\r\nYou are welcome to contribute to the `tmrl` project.\r\nPlease consider the following:\r\n- Further profiling and code optimization.\r\n- Find the cleanest way to support sequences in `Memory` for RNN training.\r\n\r\nYou can discuss contribution projects in the [discussions section](https://github.com/trackmania-rl/tmrl/discussions)\r\n\r\n\r\n# Authors:\r\n\r\nWhen contributing, please submit a PR with your name in the contributors list with a short caption.\r\n\r\n## Maintainers:\r\n- Yann Bouteiller\r\n- Edouard Geze\r\n\r\n## Contributors:\r\n- Simon Ramstedt - initial code base\r\n- AndrejGobeX - optimization of screen capture\r\n\r\n# License\r\n\r\nMIT, Bouteiller and Geze 2021-2022.\r\n\r\n# Sponsors:\r\n\r\nMany thanks to our sponsors for their support!\r\n\r\n![mist](readme/img/mistlogo.png)\r\n[MISTlab - Polytechnique Montreal](https://mistlab.ca)\r\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "https://github.com/trackmania-rl/tmrl/archive/refs/tags/v0.5.1.tar.gz",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/trackmania-rl/tmrl",
    "keywords": "reinforcement learning,robot learning,trackmania,self driving,roborace",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "tmrl",
    "package_url": "https://pypi.org/project/tmrl/",
    "platform": null,
    "project_url": "https://pypi.org/project/tmrl/",
    "project_urls": {
      "Download": "https://github.com/trackmania-rl/tmrl/archive/refs/tags/v0.5.1.tar.gz",
      "Homepage": "https://github.com/trackmania-rl/tmrl"
    },
    "release_url": "https://pypi.org/project/tmrl/0.5.1/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "Network-based framework for real-time robot learning",
    "version": "0.5.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17427496,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7f9ff55a835f744a02912b03565929c53623a9a03b001004ac708990112cb785",
          "md5": "fcf312462f48c3eff4597e4b9acd9a14",
          "sha256": "5085e5ac7a92b2078888c6cd43b42979a99043b9bc964f5b8d682fd4587adc2c"
        },
        "downloads": -1,
        "filename": "tmrl-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "fcf312462f48c3eff4597e4b9acd9a14",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 13753069,
        "upload_time": "2021-12-01T21:48:34",
        "upload_time_iso_8601": "2021-12-01T21:48:34.269003Z",
        "url": "https://files.pythonhosted.org/packages/7f/9f/f55a835f744a02912b03565929c53623a9a03b001004ac708990112cb785/tmrl-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "81123c4553605ecdf59d164ed736939cc9519947f49286bfa015af39b5884354",
          "md5": "0df05830bdbc12535b90cd7d4adae59c",
          "sha256": "78cde27dada4c3ac1efedf8bff25e20fed922af58f83c6290c7d97cd55ff60e8"
        },
        "downloads": -1,
        "filename": "tmrl-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "0df05830bdbc12535b90cd7d4adae59c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 13753000,
        "upload_time": "2021-12-07T03:15:15",
        "upload_time_iso_8601": "2021-12-07T03:15:15.412178Z",
        "url": "https://files.pythonhosted.org/packages/81/12/3c4553605ecdf59d164ed736939cc9519947f49286bfa015af39b5884354/tmrl-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3ffa0d2b96ab952507bde0cc1d802f459fb22a69ea550f094d65f8b5836773f7",
          "md5": "491afccd37f5924370f41f60541171fe",
          "sha256": "bb52e0d1a1635766cd38b2021cd580329c78a7b1788a9be17f5ea9377fa2143c"
        },
        "downloads": -1,
        "filename": "tmrl-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "491afccd37f5924370f41f60541171fe",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 13789674,
        "upload_time": "2022-01-25T23:24:57",
        "upload_time_iso_8601": "2022-01-25T23:24:57.650255Z",
        "url": "https://files.pythonhosted.org/packages/3f/fa/0d2b96ab952507bde0cc1d802f459fb22a69ea550f094d65f8b5836773f7/tmrl-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "95a2f6eb17a64635e662e9d3f073d58b2fcdc5ddd51ef711f9bd882348323418",
          "md5": "5de96d99d606665a963aad3b9bbac9ba",
          "sha256": "4341f8ac4d63f5db9c8a8b028d9a7a3906f9294a58abd1d3ae14994c81dab37d"
        },
        "downloads": -1,
        "filename": "tmrl-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "5de96d99d606665a963aad3b9bbac9ba",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 119488,
        "upload_time": "2022-03-04T07:55:43",
        "upload_time_iso_8601": "2022-03-04T07:55:43.333542Z",
        "url": "https://files.pythonhosted.org/packages/95/a2/f6eb17a64635e662e9d3f073d58b2fcdc5ddd51ef711f9bd882348323418/tmrl-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5f0958dc367b3bfb4e388f21ef533e33eee8279f30393ec0f4c8ded7fbd5ad1d",
          "md5": "8cb3106c41eda53e8bb8ccbcacdbe79b",
          "sha256": "cc7f6a0d433c4425354934e23f4a9f43df75a4eaa1ba0a65f6c776a8e47a0bee"
        },
        "downloads": -1,
        "filename": "tmrl-0.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "8cb3106c41eda53e8bb8ccbcacdbe79b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 13796056,
        "upload_time": "2022-03-19T06:15:47",
        "upload_time_iso_8601": "2022-03-19T06:15:47.389403Z",
        "url": "https://files.pythonhosted.org/packages/5f/09/58dc367b3bfb4e388f21ef533e33eee8279f30393ec0f4c8ded7fbd5ad1d/tmrl-0.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "dfda922a3158a140e2d015b08727aed96566fe4fb6e5752ba4ae351c6cb7d2ab",
          "md5": "312e73dcf69c81b4f8a60e55b1db2b63",
          "sha256": "edff32adfc81122928f89255dafa717f9f91d63eb17629ac925bb3f2223d6d7f"
        },
        "downloads": -1,
        "filename": "tmrl-0.1.3.tar.gz",
        "has_sig": false,
        "md5_digest": "312e73dcf69c81b4f8a60e55b1db2b63",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 13796615,
        "upload_time": "2022-03-30T21:14:49",
        "upload_time_iso_8601": "2022-03-30T21:14:49.761700Z",
        "url": "https://files.pythonhosted.org/packages/df/da/922a3158a140e2d015b08727aed96566fe4fb6e5752ba4ae351c6cb7d2ab/tmrl-0.1.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cfd5d9fb2f6457d42ade5b82e92f65724b9025100447e9d80c13ab0ce12fb8cb",
          "md5": "ce896335c7d9bd9bfd55a013219e5b02",
          "sha256": "fb16aa66fafbdb02139c3b5498986a39f121e9eeed0eb5c152ec8dad4aabae6d"
        },
        "downloads": -1,
        "filename": "tmrl-0.1.4.tar.gz",
        "has_sig": false,
        "md5_digest": "ce896335c7d9bd9bfd55a013219e5b02",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 13789612,
        "upload_time": "2022-04-19T16:08:55",
        "upload_time_iso_8601": "2022-04-19T16:08:55.238223Z",
        "url": "https://files.pythonhosted.org/packages/cf/d5/d9fb2f6457d42ade5b82e92f65724b9025100447e9d80c13ab0ce12fb8cb/tmrl-0.1.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "94d3f5cfe0da3c8eb66713484fee9fd661b9dc561cf2d4dd1aa1b57d5d81c24b",
          "md5": "a321e6616c745f42765d049ce1ac83cf",
          "sha256": "35c3e67d8d9ee42ccd54a9d6269ecd5dbb8caf6886cea617525fd347024f949a"
        },
        "downloads": -1,
        "filename": "tmrl-0.1.6.tar.gz",
        "has_sig": false,
        "md5_digest": "a321e6616c745f42765d049ce1ac83cf",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 13246348,
        "upload_time": "2022-05-01T22:55:29",
        "upload_time_iso_8601": "2022-05-01T22:55:29.080614Z",
        "url": "https://files.pythonhosted.org/packages/94/d3/f5cfe0da3c8eb66713484fee9fd661b9dc561cf2d4dd1aa1b57d5d81c24b/tmrl-0.1.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bf8bbefb9ea7b104c3219b3bcf5b4a5ea4d8452ac9916ed229de4323f39a7027",
          "md5": "0c2c61127b570e293b05382e1f144fce",
          "sha256": "c00a09870e4c435612a9b17563b7302dd4c7c09740d36b1858356f977769899f"
        },
        "downloads": -1,
        "filename": "tmrl-0.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "0c2c61127b570e293b05382e1f144fce",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 13250218,
        "upload_time": "2022-06-04T15:58:27",
        "upload_time_iso_8601": "2022-06-04T15:58:27.053187Z",
        "url": "https://files.pythonhosted.org/packages/bf/8b/befb9ea7b104c3219b3bcf5b4a5ea4d8452ac9916ed229de4323f39a7027/tmrl-0.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9cb218554ad65778b4e6e7ccbc4e3f1db77d5e285f0e9966bdd3175b959c603c",
          "md5": "d8304c02d7159355f2c082dbb7bfc34b",
          "sha256": "ce90a62757368caca0da962c328a2b2f482e3a84cbc099c28298dec97ee89054"
        },
        "downloads": -1,
        "filename": "tmrl-0.3.0.tar.gz",
        "has_sig": false,
        "md5_digest": "d8304c02d7159355f2c082dbb7bfc34b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 82802,
        "upload_time": "2022-09-15T18:06:13",
        "upload_time_iso_8601": "2022-09-15T18:06:13.717761Z",
        "url": "https://files.pythonhosted.org/packages/9c/b2/18554ad65778b4e6e7ccbc4e3f1db77d5e285f0e9966bdd3175b959c603c/tmrl-0.3.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bf77d11342b04fb64a95ac220193ad51921b340c0d8db0df2549e1cd173654e2",
          "md5": "ebbfebe217afacc6ebd2c90bfdd69695",
          "sha256": "f24916afdc7ec6bd5b6e19cdd6d4a09280b5fb32d8ec890f7e198a5306f94eaa"
        },
        "downloads": -1,
        "filename": "tmrl-0.3.1.tar.gz",
        "has_sig": false,
        "md5_digest": "ebbfebe217afacc6ebd2c90bfdd69695",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 81731,
        "upload_time": "2022-09-16T02:50:12",
        "upload_time_iso_8601": "2022-09-16T02:50:12.906643Z",
        "url": "https://files.pythonhosted.org/packages/bf/77/d11342b04fb64a95ac220193ad51921b340c0d8db0df2549e1cd173654e2/tmrl-0.3.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f1c41a4eb0f599002165fb0b6e4a7062afd21d62df55c9e16cc8194b53391ada",
          "md5": "2e36264fea1723d02ee2563d2fdb27df",
          "sha256": "511a390088374b2611f59dadee9ebf2d590d3a37340a004757ddb2a5d09da888"
        },
        "downloads": -1,
        "filename": "tmrl-0.4.0.tar.gz",
        "has_sig": false,
        "md5_digest": "2e36264fea1723d02ee2563d2fdb27df",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 81503,
        "upload_time": "2023-01-12T18:03:44",
        "upload_time_iso_8601": "2023-01-12T18:03:44.766159Z",
        "url": "https://files.pythonhosted.org/packages/f1/c4/1a4eb0f599002165fb0b6e4a7062afd21d62df55c9e16cc8194b53391ada/tmrl-0.4.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e4d7f2c257600a08645aff591066a30d4a6094ca7555e2f9ce528dfcd4792dda",
          "md5": "9fee9203885e6f4bc9a304d0aae0176a",
          "sha256": "8afb38aa4fbd1fc0d7751a8b211558dacf160eeaad944763419dfd2d6239046d"
        },
        "downloads": -1,
        "filename": "tmrl-0.4.1.tar.gz",
        "has_sig": false,
        "md5_digest": "9fee9203885e6f4bc9a304d0aae0176a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 81351,
        "upload_time": "2023-02-05T00:18:05",
        "upload_time_iso_8601": "2023-02-05T00:18:05.850171Z",
        "url": "https://files.pythonhosted.org/packages/e4/d7/f2c257600a08645aff591066a30d4a6094ca7555e2f9ce528dfcd4792dda/tmrl-0.4.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7f5b1c3853154c7da8e8b46073af4f320d2a2cee23fe32a141fb7b2ebd95550a",
          "md5": "a4a591f681aa7ee1fd8d9dd8ba465d26",
          "sha256": "40afde0b4c3f66679a8e2d7ed4edb6f51809a87c10e319242e56b4e88c184c42"
        },
        "downloads": -1,
        "filename": "tmrl-0.4.2.tar.gz",
        "has_sig": false,
        "md5_digest": "a4a591f681aa7ee1fd8d9dd8ba465d26",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 81720,
        "upload_time": "2023-03-07T08:47:51",
        "upload_time_iso_8601": "2023-03-07T08:47:51.613888Z",
        "url": "https://files.pythonhosted.org/packages/7f/5b/1c3853154c7da8e8b46073af4f320d2a2cee23fe32a141fb7b2ebd95550a/tmrl-0.4.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.5.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a3c593b7f77ce10cdd46ca1beb3286384fb31928bda6628007a041f9bc1b8078",
          "md5": "fc04bdd57214c96faa85ec4780269705",
          "sha256": "f0761a5cf5355a0a06efa51a8c01a8c694d5cd18e3e9108ff2056a5a0837adc3"
        },
        "downloads": -1,
        "filename": "tmrl-0.5.0.tar.gz",
        "has_sig": false,
        "md5_digest": "fc04bdd57214c96faa85ec4780269705",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 82619,
        "upload_time": "2023-03-19T04:33:13",
        "upload_time_iso_8601": "2023-03-19T04:33:13.499124Z",
        "url": "https://files.pythonhosted.org/packages/a3/c5/93b7f77ce10cdd46ca1beb3286384fb31928bda6628007a041f9bc1b8078/tmrl-0.5.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.5.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "87401325f19f7f30f740ef9e33a6a1db6a28456a8457066c90415da886529b77",
          "md5": "33ec3b83f0be3c55763cbc389210f087",
          "sha256": "fb9ff7b15b52564f5aad0bfcbf0e6e78b74a246dece6ad41fde5bb2ef9cdd217"
        },
        "downloads": -1,
        "filename": "tmrl-0.5.1.tar.gz",
        "has_sig": false,
        "md5_digest": "33ec3b83f0be3c55763cbc389210f087",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 84892,
        "upload_time": "2023-03-24T06:53:21",
        "upload_time_iso_8601": "2023-03-24T06:53:21.259462Z",
        "url": "https://files.pythonhosted.org/packages/87/40/1325f19f7f30f740ef9e33a6a1db6a28456a8457066c90415da886529b77/tmrl-0.5.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "87401325f19f7f30f740ef9e33a6a1db6a28456a8457066c90415da886529b77",
        "md5": "33ec3b83f0be3c55763cbc389210f087",
        "sha256": "fb9ff7b15b52564f5aad0bfcbf0e6e78b74a246dece6ad41fde5bb2ef9cdd217"
      },
      "downloads": -1,
      "filename": "tmrl-0.5.1.tar.gz",
      "has_sig": false,
      "md5_digest": "33ec3b83f0be3c55763cbc389210f087",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 84892,
      "upload_time": "2023-03-24T06:53:21",
      "upload_time_iso_8601": "2023-03-24T06:53:21.259462Z",
      "url": "https://files.pythonhosted.org/packages/87/40/1325f19f7f30f740ef9e33a6a1db6a28456a8457066c90415da886529b77/tmrl-0.5.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}