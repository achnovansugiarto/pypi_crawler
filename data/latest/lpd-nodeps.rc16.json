{
  "info": {
    "author": "Roy Sadaka",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Intended Audience :: Developers",
      "Intended Audience :: Education",
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.9",
      "Topic :: Scientific/Engineering :: Artificial Intelligence",
      "Topic :: Utilities"
    ],
    "description": "![Logo](https://raw.githubusercontent.com/RoySadaka/ReposMedia/main/lpd/images/logo.png)\n\n# lpd\n\nA Fast, Flexible Trainer with Callbacks and Extensions for PyTorch\n\n``lpd`` derives from the Hebrew word *lapid* (לפיד) which means \"torch\".\n\n\n\n## For latest PyPI stable release \n[![PyPI version](https://badge.fury.io/py/lpd.svg)](https://badge.fury.io/py/lpd) \n[![Downloads](https://pepy.tech/badge/lpd)](https://pepy.tech/project/lpd)\n![License](https://img.shields.io/github/license/roysadaka/lpd)\n<!-- ![Follow](https://img.shields.io/twitter/follow/roysadaka?label=RoySadaka&style=social) -->\n\nThere are 2 types of ``lpd`` packages available \n* ``lpd`` which brings dependencies for pytorch, numpy and tensorboard\n```sh\n    pip install lpd\n```\n\n* ``lpd-nodeps`` which **you provide** your own dependencies for pytorch, numpy and tensorboard\n```sh\n    pip install lpd-nodeps\n```\n\n<b>[v0.4.12-beta](https://github.com/RoySadaka/lpd/releases) Release - contains the following:</b> \n\n* ``ThresholdChecker`` is updated to compute improvement according to last improved step and not to the best received metric\n* Some minor cosmetic changes\n\n\n\nPreviously on lpd:\n* ``Dense`` custom layer to support apply norm (configurable to before or after activation) \n* ``StatsPrint`` callback to support printing best confusion matrix when at least one of the metrics is of type ``MetricConfusionMatrixBase``\n* ``TransformerEncoderStack`` to support activation as input\n* ``PositionalEncoding`` to support more than 3 dimensions input\n* Updated Pipfile\n* Fixed confusion matrix cpu/gpu device error\n* Better handling on callbacks where apply_on_states=None (apply on all states)\n* Bug fix in case validation samples are empty\n\n\n## Usage\n\n``lpd`` intended to properly structure your PyTorch model training.  \nThe main usages are given below.\n\n### Training your model\n\n```python\n    from lpd.trainer import Trainer\n    from lpd.enums import Phase, State, MonitorType, MonitorMode, StatsType\n    from lpd.callbacks import LossOptimizerHandler, StatsPrint, ModelCheckPoint, Tensorboard, EarlyStopping, SchedulerStep, CallbackMonitor\n    from lpd.extensions.custom_schedulers import KerasDecay\n    from lpd.metrics import BinaryAccuracyWithLogits, FalsePositives\n    from lpd.utils.torch_utils import get_gpu_device_if_available\n    from lpd.utils.general_utils import seed_all\n    from lpd.utils.threshold_checker import AbsoluteThresholdChecker\n\n    seed_all(seed=42) # because its the answer to life and the universe\n\n    device = get_gpu_device_if_available() # with fallback to CPU if GPU not available\n    model = MyModel().to(device) # this is your model class, and its being sent to the relevant device\n    optimizer = torch.optim.SGD(params=model.parameters())\n    scheduler = KerasDecay(optimizer, decay=0.01, last_step=-1) # decay scheduler using keras formula \n    loss_func = torch.nn.BCEWithLogitsLoss().to(device) # this is your loss class, already sent to the relevant device\n    metrics = [BinaryAccuracyWithLogits(name='Accuracy'), FalsePositives(name='FP', num_class=2, threshold=0)] # define your metrics\n                           \n\n    # you can use some of the defined callbacks, or you can create your own\n    callbacks = [\n                LossOptimizerHandler(),\n                SchedulerStep(apply_on_phase=Phase.BATCH_END, apply_on_states=State.TRAIN),\n                ModelCheckPoint(checkpoint_dir, \n                                checkpoint_file_name, \n                                CallbackMonitor(monitor_type=MonitorType.LOSS, \n                                                stats_type=StatsType.VAL, \n                                                monitor_mode=MonitorMode.MIN),\n                                save_best_only=True), \n                Tensorboard(summary_writer_dir=summary_writer_dir),\n                EarlyStopping(CallbackMonitor(monitor_type=MonitorType.METRIC, \n                                              stats_type=StatsType.VAL, \n                                              monitor_mode=MonitorMode.MAX,\n                                              patience=10,\n                                              metric_name='Accuracy'),\n                                              threshold_checker=AbsoluteThresholdChecker(monitor_mode=MonitorMode.MAX, threshold=0.01)),\n                StatsPrint(train_metrics_monitors=[CallbackMonitor(monitor_type=MonitorType.METRIC,\n                                                                   stats_type=StatsType.TRAIN,\n                                                                   monitor_mode=MonitorMode.MAX,  # <-- notice MAX\n                                                                   metric_name='Accuracy'),\n                                                   CallbackMonitor(monitor_type=MonitorType.METRIC,\n                                                                   stats_type=StatsType.TRAIN,\n                                                                   monitor_mode=MonitorMode.MIN, # <-- notice MIN\n                                                                   metric_name='FP')],\n                           print_confusion_matrix=True) # since one of the metric (FalsePositives) is confusion matrix based, lets print the whole confusion matrix\n                ]\n\n    trainer = Trainer(model, \n                      device, \n                      loss_func, \n                      optimizer,\n                      scheduler,\n                      metrics, \n                      train_data_loader,  # DataLoader, Iterable or Generator\n                      val_data_loader,    # DataLoader, Iterable or Generator\n                      train_steps,\n                      val_steps,\n                      callbacks,\n                      name='Readme-Example')\n    \n    trainer.train(num_epochs)\n```\n\n### Evaluating your model\n``trainer.evaluate`` will return ``StatsResult`` that stores the loss and metrics results for the test set \n```python\n    evaluation_result = trainer.evaluate(test_data_loader, test_steps)\n```\n\n\n### Making predictions\n``Predictor`` class will generate output predictions from input samples.\n\n``Predictor`` class can be created from ``Trainer``\n```python\n    predictor_from_trainer = Predictor.from_trainer(trainer)\n    predictions = predictor_from_trainer.predict_batch(batch)\n```\n\n``Predictor`` class can also be created from saved checkpoint\n```python\n    predictor_from_checkpoint = Predictor.from_checkpoint(checkpoint_dir,\n                                                          checkpoint_file_name,\n                                                          model, # nn.Module, weights will be loaded from checkpoint\n                                                          device)\n    prediction = predictor_from_checkpoint.predict_sample(sample)\n```\nLastly, ``Predictor`` class can be initialized explicitly\n```python\n    predictor = Predictor(model,\n                          device,\n                          callbacks, # relevant only for prediction callbacks (see callbacks Phases and States)\n                          name='lpd predictor')\n    predictions = predictor.predict_data_loader(data_loader, steps)\n```\n\nJust to be fair, you can also predict directly from ``Trainer`` class \n```python\n    # On single sample:\n    prediction = trainer.predict_sample(sample)\n    # On batch:\n    predictions = trainer.predict_batch(batch)\n    # On Dataloader/Iterable/Generator:\n    predictions = trainer.predict_data_loader(data_loader, steps)\n```\n\n## TrainerStats\n``Trainer`` tracks stats for `train/validate/test` and you can access them in your custom callbacks\nor any other place that has access to your trainer.\n\nHere are some examples\n```python\n    train_loss = trainer.train_stats.get_loss()         # the mean of the last epoch's train losses\n    val_loss = trainer.val_stats.get_loss()             # the mean of the last epoch's validation losses\n    test_loss = trainer.test_stats.get_loss()           # the mean of the test losses (available only after calling evaluate)\n\n    train_metrics = trainer.train_stats.get_metrics()   # dict(metric_name, MetricMethod(values)) of the current epoch in train state\n    val_metrics = trainer.val_stats.get_metrics()       # dict(metric_name, MetricMethod(values)) of the current epoch in validation state\n    test_metrics = trainer.test_stats.get_metrics()     # dict(metric_name, MetricMethod(values)) of the test (available only after calling evaluate)\n```\n\n\n## Callbacks\nWill be used to perform actions at various stages.  \nSome common callbacks are available under ``lpd.callbacks``, and you can also create your own, more details below.  \nIn a callback, ``apply_on_phase`` (``lpd.enums.Phase``) will determine the execution phase,  \nand ``apply_on_states`` (``lpd.enums.State`` or ``list(lpd.enums.State)``) will determine the execution states  \nThese are the current available phases and states, more might be added in future releases\n\n### Training and Validation phases and states will behave as follow\n```python\n        State.EXTERNAL\n        Phase.TRAIN_BEGIN\n        # train loop:\n            Phase.EPOCH_BEGIN\n\n            State.TRAIN\n            # batches loop:\n                Phase.BATCH_BEGIN\n                # batch\n                Phase.BATCH_END\n            State.VAL\n            # batches loop:\n                Phase.BATCH_BEGIN\n                # batch\n                Phase.BATCH_END\n            State.EXTERNAL\n\n            Phase.EPOCH_END\n        Phase.TRAIN_END\n```\n\n### Evaluation phases and states will behave as follow\n```python\n        State.EXTERNAL\n        Phase.TEST_BEGIN\n        State.TEST\n        # batches loop:\n            Phase.BATCH_BEGIN\n            # batch\n            Phase.BATCH_END\n        State.EXTERNAL\n        Phase.TEST_END\n```\n\n\n### Predict phases and states will behave as follow\n```python\n        State.EXTERNAL\n        Phase.PREDICT_BEGIN\n        State.PREDICT\n        # batches loop:\n            Phase.BATCH_BEGIN\n            # batch\n            Phase.BATCH_END\n        State.EXTERNAL\n        Phase.PREDICT_END\n```\nCallbacks will be executed under the relevant phase and state, and by their order.  \nWith phases and states, you have full control over the timing of your callbacks.  \nLet's take a look at some of the callbacks ``lpd`` provides:\n\n### LossOptimizerHandler Callback\nDerives from ``LossOptimizerHandlerBase``, probably the most important callback during training 😎   \nUse ``LossOptimizerHandler`` to determine when to call: \n```python\n    loss.backward(...)\n    optimizer.step(...)\n    optimizer.zero_grad(...)\n```\nOr, you may choose to create your own ``AwesomeLossOptimizerHandler`` class by deriving from ``LossOptimizerHandlerBase``.  \n``Trainer.train(...)`` will validate that at least one ``LossOptimizerHandlerBase`` callback was provided.\n\n### LossOptimizerHandlerAccumulateBatches Callback\nAs well as ``LossOptimizerHandlerAccumulateSamples`` will call loss.backward() every batch, but invoke optimizer.step() and optimizer.zero_grad()  \nonly after the defined num of batches (or samples) were accumulated \n\n\n### StatsPrint Callback\n``StatsPrint`` callback prints informative summary of the trainer stats including loss and metrics.  \n* ``CallbackMonitor`` can add nicer look with ``IMPROVED`` indication on improved loss or metric, see output example below. \n* Loss (for all states) will be monitored as ``MonitorMode.MIN``\n* For train metrics, provide your own monitors via ``train_metrics_monitors`` argument\n* Validation metrics monitors will be added automatically according to ``train_metrics_monitors`` argument\n\n```python\n    from lpd.enums import Phase, State, MonitorType, StatsType, MonitorMode\n\n    StatsPrint(apply_on_phase=Phase.EPOCH_END, \n               apply_on_states=State.EXTERNAL, \n               train_metrics_monitors=CallbackMonitor(monitor_type=MonitorType.METRIC,\n                                                      stats_type=StatsType.TRAIN,\n                                                      monitor_mode=MonitorMode.MAX,\n                                                      metric_name='TruePositives'),\n               print_confusion_matrix_normalized=True) # in case you use one of the ConfusionMatrix metrics (e.g. TruePositives), you may also print the confusion matrix \n```\nOutput example: \n\n![EpochSummary](https://raw.githubusercontent.com/RoySadaka/ReposMedia/main/lpd/images/epoch_summary_0_4_11.png)\n\n\n\n### ModelCheckPoint Callback\nSaving a checkpoint when a monitored loss/metric has improved.  \nThe callback will save the model, optimizer, scheduler, and epoch number.  \nYou can also configure it to save Full Trainer.  \nFor example, ``ModelCheckPoint`` that will save a new *full trainer checkpoint* every time the validation metric_name ``my_metric``  \nis getting higher than the highest value so far.\n\n```python\n    ModelCheckPoint(Phase.EPOCH_END, \n                    State.EXTERNAL,\n                    checkpoint_dir, \n                    checkpoint_file_name,\n                    CallbackMonitor(monitor_type=MonitorType.METRIC,    # It's a Metric and not a Loss \n                                    stats_type=StatsType.VAL,           # check the value on the Validation set\n                                    monitor_mode=MonitorMode.MAX,       # MAX indicates higher is better\n                                    metric_name='my_metric'),           # since it's a Metric, mention its name\n                    save_best_only=False, \n                    save_full_trainer=True)\n```\n\n### EarlyStopping Callback\nStops the trainer when a monitored loss/metric has stopped improving.  \nFor example, EarlyStopping that will monitor at the end of every epoch, and stop the trainer if the validation loss didn't improve (decrease) for the last 10 epochs.\n```python\nEarlyStopping(Phase.EPOCH_END, \n              State.EXTERNAL,\n              CallbackMonitor(monitor_type=MonitorType.LOSS, \n                              stats_type=StatsType.VAL, \n                              monitor_mode=MonitorMode.MIN,\n                              patience=10))\n```\n\n### SchedulerStep Callback\n\nWill invoke ``step()`` on your scheduler in the desired phase and state.  \nFor example, SchedulerStep callback to invoke ``scheduler.step()`` at the end of every batch, in train state (as opposed to validation and test):\n```python\n    from lpd.callbacks import SchedulerStep\n    from lpd.enums import Phase, State\n    SchedulerStep(apply_on_phase=Phase.BATCH_END, apply_on_states=State.TRAIN)\n```\n\n\n### Tensorboard Callback\nWill export the loss and the metrics at a given phase and state, in a format that can be viewed on Tensorboard \n```python\n    from lpd.callbacks import Tensorboard\n    Tensorboard(apply_on_phase=Phase.EPOCH_END, \n                apply_on_states=State.EXTERNAL, \n                summary_writer_dir=dir_path)\n```\n\n\n### TensorboardImage Callback\nWill export images, in a format that can be viewed on Tensorboard.  \nFor example, a TensorboardImage callback that will output all the images generated in validation\n```python\n    from lpd.callbacks import TensorboardImage\n    TensorboardImage(apply_on_phase=Phase.BATCH_END, \n                     apply_on_states=State.VAL, \n                     summary_writer_dir=dir_path,\n                     description='Generated Images',\n                     outputs_parser=None)\n```\nLets pass outputs_parser that will change the range of the outputs from [-1,1] to [0,255]\n```python\n    from lpd.callbacks import TensorboardImage\n\n    def outputs_parser(input_output_label: InputOutputLabel):\n        outputs_scaled = (input_output_label.outputs + 1.0) / 2.0 * 255\n        outputs_scaled = torchvision.utils.make_grid(input_output_label.output)\n        return outputs_scaled\n\n    TensorboardImage(apply_on_phase=Phase.BATCH_END, \n                     apply_on_states=State.VAL, \n                     summary_writer_dir=dir_path,\n                     description='Generated Images',\n                     outputs_parser=outputs_parser)\n```\n\n\n### CollectOutputs Callback\nWill collect model's outputs for the defined states.  \nCollectOutputs is automatically used by ``Trainer`` to collect the predictions when calling one of the ``predict`` methods. \n```python\n    CollectOutputs(apply_on_phase=Phase.BATCH_END, apply_on_states=State.VAL)\n```\n\n### Create your custom callbacks\n\n```python\n    from lpd.enums import Phase, State\n    from lpd.callbacks import CallbackBase\n\n    class MyAwesomeCallback(CallbackBase):\n        def __init__(self, apply_on_phase=Phase.BATCH_END, apply_on_states=[State.TRAIN, State.VAL]):\n            # make sure to call init parent class\n            super(MyAwesomeCallback, self).__init__(apply_on_phase, apply_on_states)\n\n        def __call__(self, callback_context): # <=== implement this method!\n            # your implementation here\n            # using callback_context, you can access anything in your trainer\n            # below are some examples to get the hang of it\n            val_loss = callback_context.val_stats.get_loss()\n            train_loss = callback_context.train_stats.get_loss()\n            train_metrics = callback_context.train_stats.get_metrics()\n            val_metrics = callback_context.val_stats.get_metrics()\n            optimizer = callback_context.optimizer\n            scheduler = callback_context.scheduler\n            trainer = callback_context.trainer\n\n            if val_loss < 0.0001:\n                # you can also mark the trainer to STOP training by calling stop()\n                trainer.stop()\n```\n\nLets expand ``MyAwesomeCallback`` with ``CallbackMonitor`` to track if our validation loss is getting better\n```python\n    from lpd.callbacks import CallbackBase, CallbackMonitor # <== CallbackMonitor added\n    from lpd.enums import Phase, State, MonitorType, StatsType, MonitorMode # <== added few needed enums to configure CallbackMonitor\n\n    class MyAwesomeCallback(CallbackBase):\n        def __init__(self, apply_on_phase=Phase.BATCH_END, apply_on_states=[State.TRAIN, State.VAL]):\n            super(MyAwesomeCallback, self).__init__(apply_on_phase, apply_on_states)\n            \n            # adding CallbackMonitor to track VAL LOSS with regards to MIN (lower is better) and patience of 20 epochs\n            self.val_loss_monitor = CallbackMonitor(MonitorType.LOSS, StatsType.VAL, MonitorMode.MIN, patience=20)\n\n        def __call__(self, callback_context: CallbackContext): # <=== implement this method!\n            # same as before, using callback_context, you can access anything in your trainer\n            train_metrics = callback_context.train_stats.get_metrics()\n            val_metrics = callback_context.val_stats.get_metrics()\n\n            # invoke track() method on your monitor and pass callback_context as parameter\n            # since you configured your val_loss_monitor, it will get the relevant parameters from callback_context\n            monitor_result = self.val_loss_monitor.track(callback_context)\n\n            # monitor_result (lpd.callbacks.CallbackMonitorResult) contains informative properties\n            # for example lets check the status of the patience countdown\n\n            if monitor_result.has_patience():\n                print(f'[MyAwesomeCallback] - patience left: {monitor_result.patience_left}')\n\n            # Or, let's stop the trainer, by calling the trainer.stop()\n            # if our monitored value did not improve\n\n            if not monitor_result.has_improved():\n                print(f'[MyAwesomeCallback] - {monitor_result.description} has stopped improving')\n                callback_context.trainer.stop()\n```\n\n\n### CallbackMonitor, AbsoluteThresholdChecker and RelativeThresholdChecker\nWhen using callbacks such as ``EarlyStopping``, a ``CallbackMonitor`` is provided to track  \na certain metric and reset/trigger the stopping event (or any event in other callbacks).  \n  \n``CallbackMonitor`` will internally use ``ThresholdChecker`` when comparing new value to old value  \nfor the tracked metric, and ``AbsoluteThresholdChecker`` or ``RelativeThresholdChecker`` will be used  \nto check if the criteria was met.  \nThe following example creates a ``CallbackMonitor`` that will track if the metric 'accuracy'  \nhas increased with more then 1% using ``RelativeThresholdChecker``\n```python\n    from lpd.utils.threshold_checker import RelativeThresholdChecker\n    relative_threshold_checker_1_percent = RelativeThresholdChecker(monitor_mode=MonitorMode.MAX, threshold=0.01)\n\n    CallbackMonitor(monitor_type=MonitorType.METRIC,                        # It's a Metric and not a Loss \n                    stats_type=StatsType.VAL,                               # check the value on the Validation set\n                    monitor_mode=MonitorMode.MAX,                           # MAX indicates higher is better\n                    metric_name='accuracy',                                 # since it's a Metric, mention its name\n                    threshold_checker=relative_threshold_checker_1_percent) # track 1% increase from last highest value     \n```\n\n\n\n## Metrics\n``lpd.metrics`` provides metrics to check the accuracy of your model.  \nLet's create a custom metric using ``MetricBase`` and also show the use of ``BinaryAccuracyWithLogits`` in this example\n```python\n    from lpd.metrics import BinaryAccuracyWithLogits, MetricBase\n    from lpd.enums import MetricMethod\n\n    # our custom metric\n    class InaccuracyWithLogits(MetricBase):\n        def __init__(self):\n            super(InaccuracyWithLogits, self).__init__(MetricMethod.MEAN) # use mean over the batches\n            self.bawl = BinaryAccuracyWithLogits() # we exploit BinaryAccuracyWithLogits for the computation\n\n        def __call__(self, y_pred, y_true): # <=== implement this method!\n            # your implementation here\n            acc = self.bawl(y_pred, y_true)\n            return 1 - acc  # return the inaccuracy\n\n    # we can now define our metrics and pass them to the trainer\n    metrics = [BinaryAccuracyWithLogits(name='accuracy'), InaccuracyWithLogits(name='inaccuracy')]\n``` \n\nLet's do another example, a custom metric ``Truthfulness`` based on confusion matrix using ``MetricConfusionMatrixBase``\n```python\n    from lpd.metrics import MetricConfusionMatrixBase, TruePositives, TrueNegatives\n    from lpd.enums import ConfusionMatrixBasedMetric\n\n    # our custom metric\n    class Truthfulness(MetricConfusionMatrixBase):\n        def __init__(self, num_classes, labels=None, predictions_to_classes_convertor=None, threshold=0.5):\n            super(Truthfulness, self).__init__(num_classes, labels, predictions_to_classes_convertor, threshold)\n            self.tp = TruePositives(num_classes, labels, predictions_to_classes_convertor, threshold) # we exploit TruePositives for the computation\n            self.tn = TrueNegatives(num_classes, labels, predictions_to_classes_convertor, threshold) # we exploit TrueNegatives for the computation\n\n        def __call__(self, y_pred, y_true):  # <=== implement this method!\n            tp_per_class = self.tp(y_pred, y_true)\n            tn_per_class = self.tn(y_pred, y_true)\n\n            # you can also access more confusion matrix metrics such as\n            f1score = self.get_stats(ConfusionMatrixBasedMetric.F1SCORE)\n            precision = self.get_stats(ConfusionMatrixBasedMetric.PRECISION)\n            recall = self.get_stats(ConfusionMatrixBasedMetric.RECALL)\n            # see ConfusionMatrixBasedMetric enum for more             \n\n            return tp_per_class + tn_per_class\n``` \n\n\n## Save and Load full Trainer\nSometimes you just want to save everything so you can continue training where you left off.  \nTo do so, you may use ``ModelCheckPoint`` for saving full trainer by setting parameter\n```python\n    save_full_trainer=True\n``` \nOr, you can invoke it directly from your trainer\n```python\n    your_trainer.save_trainer(dir_path, file_name)\n``` \n\nLoading a trainer from checkpoint is as simple as:\n```python\n    loaded_trainer = Trainer.load_trainer(dir_path,             # the folder where the saved trainer file exists \n                                          trainer_file_name,    # the saved trainer file name \n                                          model,                # state_dict will be loaded\n                                          device,\n                                          loss_func,            # state_dict will be loaded\n                                          optimizer,            # state_dict will be loaded\n                                          scheduler,            # state_dict will be loaded\n                                          train_data_loader,    # provide new/previous data_loader\n                                          val_data_loader,      # provide new/previous data_loader\n                                          train_steps,\n                                          val_steps)\n``` \n\n### Utils\n``lpd.utils`` provides ``torch_utils``, ``file_utils`` and ``general_utils``  \nFor example, a good practice is to use ``seed_all`` as early as possible in your code, to make sure that results are reproducible:\n```python\n    import lpd.utils.general_utils as gu\n    gu.seed_all(seed=42)  # because its the answer to life and the universe\n```\n\n\n### Extensions\n``lpd.extensions`` provides some custom PyTorch layers, and schedulers, these are just some stuff we like using when we create our models, to gain better flexibility.  \nSo you can use them at your own will, more extensions are added from time to time.\n\n\n## Something is missing?! please share with us\nYou can open an issue, but also feel free to email us at torch.lpd@gmail.com\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/roysadaka/lpd",
    "keywords": "lpd-nodeps",
    "license": "MIT Licences",
    "maintainer": "lpd developers",
    "maintainer_email": "torch.lpd@gmail.com",
    "name": "lpd-nodeps",
    "package_url": "https://pypi.org/project/lpd-nodeps/",
    "platform": null,
    "project_url": "https://pypi.org/project/lpd-nodeps/",
    "project_urls": {
      "Homepage": "https://github.com/roysadaka/lpd"
    },
    "release_url": "https://pypi.org/project/lpd-nodeps/0.4.12/",
    "requires_dist": [
      "tqdm"
    ],
    "requires_python": ">=3.9",
    "summary": "A Fast, Flexible Trainer with Callbacks and Extensions for PyTorch",
    "version": "0.4.12",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17477308,
  "releases": {
    "0.3.6.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "974ddcd24db49ca9f3cce70f0dedf9a1f25025bd91179dc3bae072a3ff3e803a",
          "md5": "b65dfe96b6da4c357b9e9d0aaebbef9d",
          "sha256": "658f7a289b4a015e3689a28d884155686877bf9e97482e38bd7439afb1b8b1e8"
        },
        "downloads": -1,
        "filename": "lpd_nodeps-0.3.6.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "b65dfe96b6da4c357b9e9d0aaebbef9d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 43046,
        "upload_time": "2020-11-26T09:00:41",
        "upload_time_iso_8601": "2020-11-26T09:00:41.100385Z",
        "url": "https://files.pythonhosted.org/packages/97/4d/dcd24db49ca9f3cce70f0dedf9a1f25025bd91179dc3bae072a3ff3e803a/lpd_nodeps-0.3.6.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "415dfa774ec0822acdddae6aeaf0eec0c45e1f4d72ea931ab054456d29abf392",
          "md5": "9cf0a736943a01bfabd89637da36f744",
          "sha256": "cd9199796c56df4e5c46bb300865e1581bf9678aebeceefb0d1579b3b62fd5e9"
        },
        "downloads": -1,
        "filename": "lpd_nodeps-0.3.7-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "9cf0a736943a01bfabd89637da36f744",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 43053,
        "upload_time": "2020-11-27T06:54:00",
        "upload_time_iso_8601": "2020-11-27T06:54:00.078805Z",
        "url": "https://files.pythonhosted.org/packages/41/5d/fa774ec0822acdddae6aeaf0eec0c45e1f4d72ea931ab054456d29abf392/lpd_nodeps-0.3.7-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "468e0a2d7dacf617dab3ce7cc0e98035c7f67fb390aec96a1115c022bf2bc85d",
          "md5": "8ec63cf0a1828aa12150d05ddf0c9795",
          "sha256": "f468bdda07bbfb1ebb1c2e93a69129dbb2897b5eaf28202830b23b325251abb8"
        },
        "downloads": -1,
        "filename": "lpd_nodeps-0.3.8-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "8ec63cf0a1828aa12150d05ddf0c9795",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 44739,
        "upload_time": "2021-01-20T20:13:15",
        "upload_time_iso_8601": "2021-01-20T20:13:15.920967Z",
        "url": "https://files.pythonhosted.org/packages/46/8e/0a2d7dacf617dab3ce7cc0e98035c7f67fb390aec96a1115c022bf2bc85d/lpd_nodeps-0.3.8-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.9": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4744a66938b15790fe5d4c6ab2efedae5bf00c2f85636748586a1a9401e114aa",
          "md5": "71dc32b4ac9f01946c576daa738dabfe",
          "sha256": "11a6c4de34a5f4f2b1cfd75eb8bf2cddc019c5d0b5750604851a3038cae4d3ea"
        },
        "downloads": -1,
        "filename": "lpd_nodeps-0.3.9-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "71dc32b4ac9f01946c576daa738dabfe",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 46823,
        "upload_time": "2021-01-29T20:37:38",
        "upload_time_iso_8601": "2021-01-29T20:37:38.668473Z",
        "url": "https://files.pythonhosted.org/packages/47/44/a66938b15790fe5d4c6ab2efedae5bf00c2f85636748586a1a9401e114aa/lpd_nodeps-0.3.9-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9909b5fb32cdb687b3220a10646a786953477f74eb7166ff3bd558e8c2a899a8",
          "md5": "218978f7605bb70b480f61682c731a90",
          "sha256": "2047547731cd527f5414ff6969b644e0b5fa6db158430107bad5e3489479c0ce"
        },
        "downloads": -1,
        "filename": "lpd_nodeps-0.4.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "218978f7605bb70b480f61682c731a90",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 46708,
        "upload_time": "2021-04-05T07:35:21",
        "upload_time_iso_8601": "2021-04-05T07:35:21.815664Z",
        "url": "https://files.pythonhosted.org/packages/99/09/b5fb32cdb687b3220a10646a786953477f74eb7166ff3bd558e8c2a899a8/lpd_nodeps-0.4.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2e0424ae68a1b1f07c52bcb2bebfa97b20f38e609f6ebe529cb2ba94e43d1380",
          "md5": "e1a492cfb69f893ad37f5c5ee23bba3e",
          "sha256": "00f8434e98306f85a53a757f18692d6855a71a8e78e9e0ccaea1e90f02708efe"
        },
        "downloads": -1,
        "filename": "lpd_nodeps-0.4.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "e1a492cfb69f893ad37f5c5ee23bba3e",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 46747,
        "upload_time": "2021-07-27T08:08:32",
        "upload_time_iso_8601": "2021-07-27T08:08:32.468437Z",
        "url": "https://files.pythonhosted.org/packages/2e/04/24ae68a1b1f07c52bcb2bebfa97b20f38e609f6ebe529cb2ba94e43d1380/lpd_nodeps-0.4.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.10": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ec7a1101131471f370a0e7c837665874f0504c1c03d4a5157de5fee0cb7470c3",
          "md5": "d852810f35860134f06132a06f453d47",
          "sha256": "9117f55114eee6d4eb5148803a6d60fae0b8dea93fa78d78ba4ff277899aa9fa"
        },
        "downloads": -1,
        "filename": "lpd_nodeps-0.4.10-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d852810f35860134f06132a06f453d47",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.9",
        "size": 48038,
        "upload_time": "2023-02-04T06:43:48",
        "upload_time_iso_8601": "2023-02-04T06:43:48.132059Z",
        "url": "https://files.pythonhosted.org/packages/ec/7a/1101131471f370a0e7c837665874f0504c1c03d4a5157de5fee0cb7470c3/lpd_nodeps-0.4.10-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.11": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "491e708698cb8ee0bc79f68fd16ce8d3bda3797c5d08fef25102e78fe48c3968",
          "md5": "46c733722c1526793ae3fc094c6d6fdc",
          "sha256": "5a08dea15166e58bb69ca5b968644bac3a9cbe64ad85df1689f5a393132ef4aa"
        },
        "downloads": -1,
        "filename": "lpd_nodeps-0.4.11-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "46c733722c1526793ae3fc094c6d6fdc",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.9",
        "size": 49844,
        "upload_time": "2023-02-14T13:00:33",
        "upload_time_iso_8601": "2023-02-14T13:00:33.569376Z",
        "url": "https://files.pythonhosted.org/packages/49/1e/708698cb8ee0bc79f68fd16ce8d3bda3797c5d08fef25102e78fe48c3968/lpd_nodeps-0.4.11-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.12": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "356ac58e3e43abc04c8be6532f4969fc841c972b739d488588e329da3848de4f",
          "md5": "d449cde3681c45769c539c7e07015041",
          "sha256": "952e0d4a0392105717db3b4ccc230d0334e55a11ec88292c66dd3f0177122a32"
        },
        "downloads": -1,
        "filename": "lpd_nodeps-0.4.12-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d449cde3681c45769c539c7e07015041",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.9",
        "size": 50159,
        "upload_time": "2023-03-28T11:58:46",
        "upload_time_iso_8601": "2023-03-28T11:58:46.123150Z",
        "url": "https://files.pythonhosted.org/packages/35/6a/c58e3e43abc04c8be6532f4969fc841c972b739d488588e329da3848de4f/lpd_nodeps-0.4.12-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a3e127d81da3550d3860587142af596c2a345eb16162a881ec4947bc6068da7f",
          "md5": "f34e25632adaf179935d4223431d49e7",
          "sha256": "edcc521aab4f1bd0363ebfb576c50f32bfbb6c693a9f63b544a530df32fd2253"
        },
        "downloads": -1,
        "filename": "lpd_nodeps-0.4.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f34e25632adaf179935d4223431d49e7",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 46722,
        "upload_time": "2021-11-03T11:47:09",
        "upload_time_iso_8601": "2021-11-03T11:47:09.253903Z",
        "url": "https://files.pythonhosted.org/packages/a3/e1/27d81da3550d3860587142af596c2a345eb16162a881ec4947bc6068da7f/lpd_nodeps-0.4.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cc0cbfff727ee43d4bc06e2a97f6598098be82186f279c44955628c0f993bf91",
          "md5": "be0a6c43e8c22d8a345f2e53814610c7",
          "sha256": "0296d7a86af2031b3ebbf2dc51e1df957eda5acbe9059f8c9ff593fe5ba5267d"
        },
        "downloads": -1,
        "filename": "lpd_nodeps-0.4.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "be0a6c43e8c22d8a345f2e53814610c7",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 46732,
        "upload_time": "2022-03-17T20:16:10",
        "upload_time_iso_8601": "2022-03-17T20:16:10.981576Z",
        "url": "https://files.pythonhosted.org/packages/cc/0c/bfff727ee43d4bc06e2a97f6598098be82186f279c44955628c0f993bf91/lpd_nodeps-0.4.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "43db611c622b475661ce3ecffba65e5a72713a23f31ba0c720568cb53ae7a080",
          "md5": "401abaf43e8137e2cff17d412d305e46",
          "sha256": "dc60cdf39dc070b19da964378a3d27348e83119afe5ba827c7d46939a58af54f"
        },
        "downloads": -1,
        "filename": "lpd_nodeps-0.4.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "401abaf43e8137e2cff17d412d305e46",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 46748,
        "upload_time": "2022-04-24T07:41:02",
        "upload_time_iso_8601": "2022-04-24T07:41:02.359620Z",
        "url": "https://files.pythonhosted.org/packages/43/db/611c622b475661ce3ecffba65e5a72713a23f31ba0c720568cb53ae7a080/lpd_nodeps-0.4.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "32a1f18319d17eb7a91d5af839262e6815bc031733c16982aa9e05fbf5edf8d9",
          "md5": "46c5a70682aed2cb17e1048e87bec605",
          "sha256": "3d6c2c320ad9468f1233672b01446e18b1584d6a6b2982af64cc09a3f15784b1"
        },
        "downloads": -1,
        "filename": "lpd_nodeps-0.4.6-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "46c5a70682aed2cb17e1048e87bec605",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 46899,
        "upload_time": "2022-06-22T17:49:25",
        "upload_time_iso_8601": "2022-06-22T17:49:25.429893Z",
        "url": "https://files.pythonhosted.org/packages/32/a1/f18319d17eb7a91d5af839262e6815bc031733c16982aa9e05fbf5edf8d9/lpd_nodeps-0.4.6-py3-none-any.whl",
        "yanked": true,
        "yanked_reason": "Please use 0.4.7 for another fix"
      }
    ],
    "0.4.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6124fcb1e0665c1be54bfdcb5b3efbea26fd63361e376e5cda2644469c6a73a5",
          "md5": "ccbdcb511c07802f875c8e03c86dd448",
          "sha256": "ff4063fe4a052e5437602b50935a82887d43a3387be57f957c6d3694ce2a32a4"
        },
        "downloads": -1,
        "filename": "lpd_nodeps-0.4.7-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ccbdcb511c07802f875c8e03c86dd448",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 46903,
        "upload_time": "2022-06-27T17:18:28",
        "upload_time_iso_8601": "2022-06-27T17:18:28.200720Z",
        "url": "https://files.pythonhosted.org/packages/61/24/fcb1e0665c1be54bfdcb5b3efbea26fd63361e376e5cda2644469c6a73a5/lpd_nodeps-0.4.7-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c1130aeb1a22bbeebd62fb5a049a39cc73067b1c4994849a7fbaff2fa84a68a1",
          "md5": "47dfe421d8e7608c77d0a278ea2fc45b",
          "sha256": "39231c6cf6384d40fafb64cbdd48f43466d8031f6f95824458480fadebc7b239"
        },
        "downloads": -1,
        "filename": "lpd_nodeps-0.4.8-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "47dfe421d8e7608c77d0a278ea2fc45b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 48223,
        "upload_time": "2022-09-15T07:55:16",
        "upload_time_iso_8601": "2022-09-15T07:55:16.512668Z",
        "url": "https://files.pythonhosted.org/packages/c1/13/0aeb1a22bbeebd62fb5a049a39cc73067b1c4994849a7fbaff2fa84a68a1/lpd_nodeps-0.4.8-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.9": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8b308ea13c29d411a3a4f0eb2631b239a18873473673d389a2eb8aa62fdb9197",
          "md5": "91de62ba8d39e91f136fb1106391adb9",
          "sha256": "e5f46c31fcd9dd9001df491c64459eeb40c2753949010a41729bc2baf3cf503c"
        },
        "downloads": -1,
        "filename": "lpd_nodeps-0.4.9-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "91de62ba8d39e91f136fb1106391adb9",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.9",
        "size": 47886,
        "upload_time": "2023-01-22T10:11:35",
        "upload_time_iso_8601": "2023-01-22T10:11:35.651584Z",
        "url": "https://files.pythonhosted.org/packages/8b/30/8ea13c29d411a3a4f0eb2631b239a18873473673d389a2eb8aa62fdb9197/lpd_nodeps-0.4.9-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "356ac58e3e43abc04c8be6532f4969fc841c972b739d488588e329da3848de4f",
        "md5": "d449cde3681c45769c539c7e07015041",
        "sha256": "952e0d4a0392105717db3b4ccc230d0334e55a11ec88292c66dd3f0177122a32"
      },
      "downloads": -1,
      "filename": "lpd_nodeps-0.4.12-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "d449cde3681c45769c539c7e07015041",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.9",
      "size": 50159,
      "upload_time": "2023-03-28T11:58:46",
      "upload_time_iso_8601": "2023-03-28T11:58:46.123150Z",
      "url": "https://files.pythonhosted.org/packages/35/6a/c58e3e43abc04c8be6532f4969fc841c972b739d488588e329da3848de4f/lpd_nodeps-0.4.12-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}