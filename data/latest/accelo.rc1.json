{
  "info": {
    "author": "Acceldata",
    "author_email": "support@acceldata.io",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: BSD License",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.7"
    ],
    "description": "# Acceldata ML Observability SDK\n\nThe SDK helps Data organizations track their ML models, data that deliver business value. \n\n## Pre-requisites\n- Registering yourself with Acceldata Data Observability Cloud platform\n\nDriven through Acceldata Cloud Platform\n- Enabling ML Observability toolkit\n\nDriven through Acceldata Cloud Platform\n- Generating API keys\n\nDriven through Acceldata ML Observability UI\n- Setting up env vars\n```bash\nexport CLOUD_ACCESS_KEY=XXXX0000\nexport CLOUD_SECRET_KEY=XXXX0000\nexport ACCELO_API_ACCESS_KEY=XXXX0000\nexport ACCELO_API_SECRET_KEY=XXXX0000\nexport ACCELO_API_ENDPOINT=https://some_acceldata_endpoint\n```\n- Install the SDK\n```python\npip install accelo\n```\n\nSet Go!\n\n## Sample Usage Patterns\nBefore we delve into code, let's just see an example of a pattern in which you can use the SDK. \n\n### Project Creation\n#### Modes\n1. UI - Users will be able to create projects via the Catalog UI where they can either have a model view or a project view\n2. API - Users can create a project in their training pipeline. If a project already exists, API throws a custom error that can be used to avoid any failures in the training pipeline\n### Model Registration and Baseline logging (training pipeline)\n- User registers a model against a project\n- Model registration API expects the project id, model name and bunch of other metadata that can be used to track models on the catalog UI\n### Prediction logging (serving pipeline)\n- The serving pipeline can be used to log the predictions to Acceldata datastore\n- The API expects model id, model version, and predictions along with their id columns as mandatory params.\n### Actual logging (actuals pipeline)\nThe actuals for any features may arrive at a later point and the API provides 2 ways to log the actuals.\n- UUIDs: generated by the API during the serving pipeline stage; but the users are expected to keep track of them and map them to the appropriate actuals\n- ID COLUMNS: If users specify certain columns to considered as the ID’s, the API will be able to automatically log the actuals against the API’s and the backend services will be able to compare the actuals to predictions based on these ID COLUMNS\n\n**Note**: Please refer to the API documentation for more information. \n\n## Basic APIs\nFinally, let's see how you can annotate the SDK into your production code pipelines. Below are some examples of how a Data Scientist or ML Engineer can annotate the SDK into the \nexisting ML code and observe them using Acceldata ML Observability platform.\n\n### Import the library\n```python\nfrom accelo_mlops import AcceloClient\n``` \n\n### Creating a client with a workspace\nThe workspace is the top level name that you would want to associate your organization with. \nThis can also be thought of like a tenant name. \n```python\nclient = AcceloClient(workspace='your_organization_name')\n```\n\n### Creating a Project\nNow, when it comes to code, the atomic unit is a `Project`. The project name can be a team name, domain name within \na company or any other logical separation Data Science groups.\n\n```python\nclient.create_project(name='marketing-team', \n                      description='All models related to the marketing team reside here. '\n)\n```\n\n### Register a Model\nNow, assuming that you have developed a model that you want to observe using the Acceldata ML Observability platform.\nThe model object is called `classifier`.  \n```python\nmodel_metadata = {\n    'frequency': 'DAILY', \n    'model_type': 'binary_classification',\n    'performance_metric': 'f1_score', \n    'model_obj': classifier\n}\nadditional_params = {\n    'owner': 'research@preview.com',\n    'last_trained': '2021-08-01',\n    'training_job_name': 'click_prediction_ml_pipeline',\n    'label': 'flower_type',\n    'total_consumers': 2\n}\n\nclient.register_model(project_id=12, \n                      model_name='click_prediction_model', \n                      model_version='v1', \n                      model_metadata=model_metadata, \n                      **additional_params\n)\n```\n\nLet's see what above variables mean.\n- **classifier**: this is the model object\n- **model_meatadata**: this is a mandatory dictionary users have to pass to the register model call to make most use of the ML observability platform. \n- **additional_params**: this is a optional dictionary users can use to log any additional details about the model which might be useful when viewed in the ML Catalog.   \n\nNow, it's time to log the data that was used in model. \n### Log baseline data\n```python\nclient.log_baseline(\n    model_id=client.model_id,\n    model_version='v1',\n    baseline_data=X_train,\n    labels=y_train,\n    label_name='click',\n    id_cols=['campaign_id'],\n    publish_date='2021-08-02'\n)\n```\nThis API call logs your baseline data to Acceldata data store and will be further used for analysis that you sign up for. \n\n### Log predictions\n```python\nids = client.log_predictions(\n    model_id=client.model_id,\n    model_version='v1',\n    feature_data=feature_data,\n    predictions=preds,\n    publish_date='2021-06-02'\n)\n```\n\n**Note**: As of now, we support batch predictions only but soon enough, will be able to support logging online \npredictions. \n\n### Log actuals\nAt a later time, when actuals arrive, you'd be able to log them using below API.\n```python\nclient.log_actuals(\n    model_id=client.model_id,\n    model_version='v1',\n    id_cols_df=id_columns_frane,\n    actuals=y_test,\n    publish_date='2021-06-03'\n)\n```\n\nYou are now done logging both metadata and the data itself. \n\nDetailed activity logs can be viewed in the `ad-mlops.log` file in the directory where your code file exists, however, location of the log file is configurable.\n\n## What happens after you create a project and register a model?\n### Metadata\nThe model and the other metadata are now part of Acceldata ML Catalog and can be viewed on the UI. \n\n### Data\nThe `baseline, prediction, actual` data are logged into the Acceldata Store. This data will be used for further analysis. \n\n### Dashboard\nYou will be able to track model performance, data drifts, etc by visiting this dashboard. \n\n### Alerts\nYou can set alerts on charts, generate reports, etc using the dashboard or the catalog.\n\n## Contact Us\nPlease get in touch with us at `contact@acceldata.io` for access to Acceldata catalog, dashboard, and assistance with bringing ML Observability into your organization.   \n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://acceldata.io",
    "keywords": "accelo",
    "license": "BSD",
    "maintainer": "",
    "maintainer_email": "",
    "name": "accelo",
    "package_url": "https://pypi.org/project/accelo/",
    "platform": "",
    "project_url": "https://pypi.org/project/accelo/",
    "project_urls": {
      "Homepage": "https://acceldata.io"
    },
    "release_url": "https://pypi.org/project/accelo/0.0.1/",
    "requires_dist": [
      "pandas",
      "numpy",
      "requests",
      "dataclasses",
      "sqlalchemy",
      "joblib",
      "psycopg2-binary",
      "boto3 (>=1.17)",
      "pyarrow (>=3.0.0)",
      "fsspec (>=0.8.7)"
    ],
    "requires_python": "",
    "summary": "",
    "version": "0.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 11078874,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9c93fa644e945adc0da915f3ac86af0b099fbf5b1a7c4c2ccd2817ddc3bf8ed8",
          "md5": "29652a38af81306d1ee127334c09ab56",
          "sha256": "b29f28d808e695add6e6c0e49ec47cf254f51f3412b4107d52d1843a7a596e35"
        },
        "downloads": -1,
        "filename": "accelo-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "29652a38af81306d1ee127334c09ab56",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 29461,
        "upload_time": "2021-08-03T12:08:14",
        "upload_time_iso_8601": "2021-08-03T12:08:14.763572Z",
        "url": "https://files.pythonhosted.org/packages/9c/93/fa644e945adc0da915f3ac86af0b099fbf5b1a7c4c2ccd2817ddc3bf8ed8/accelo-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cc4d5ca971f2d711102077e47c198be91977c7a6011bf537be96af32ab747c0a",
          "md5": "a2578b83156e72f723757e813dbcd968",
          "sha256": "76d3e0d9eee830b1c814df325aba3e0c5d174b832926399a1e3e2db07c56d07d"
        },
        "downloads": -1,
        "filename": "accelo-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "a2578b83156e72f723757e813dbcd968",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 19021,
        "upload_time": "2021-08-03T12:08:16",
        "upload_time_iso_8601": "2021-08-03T12:08:16.666794Z",
        "url": "https://files.pythonhosted.org/packages/cc/4d/5ca971f2d711102077e47c198be91977c7a6011bf537be96af32ab747c0a/accelo-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "9c93fa644e945adc0da915f3ac86af0b099fbf5b1a7c4c2ccd2817ddc3bf8ed8",
        "md5": "29652a38af81306d1ee127334c09ab56",
        "sha256": "b29f28d808e695add6e6c0e49ec47cf254f51f3412b4107d52d1843a7a596e35"
      },
      "downloads": -1,
      "filename": "accelo-0.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "29652a38af81306d1ee127334c09ab56",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 29461,
      "upload_time": "2021-08-03T12:08:14",
      "upload_time_iso_8601": "2021-08-03T12:08:14.763572Z",
      "url": "https://files.pythonhosted.org/packages/9c/93/fa644e945adc0da915f3ac86af0b099fbf5b1a7c4c2ccd2817ddc3bf8ed8/accelo-0.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "cc4d5ca971f2d711102077e47c198be91977c7a6011bf537be96af32ab747c0a",
        "md5": "a2578b83156e72f723757e813dbcd968",
        "sha256": "76d3e0d9eee830b1c814df325aba3e0c5d174b832926399a1e3e2db07c56d07d"
      },
      "downloads": -1,
      "filename": "accelo-0.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "a2578b83156e72f723757e813dbcd968",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 19021,
      "upload_time": "2021-08-03T12:08:16",
      "upload_time_iso_8601": "2021-08-03T12:08:16.666794Z",
      "url": "https://files.pythonhosted.org/packages/cc/4d/5ca971f2d711102077e47c198be91977c7a6011bf537be96af32ab747c0a/accelo-0.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}