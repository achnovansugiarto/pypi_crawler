{
  "info": {
    "author": "Mayank khursija",
    "author_email": "mk6619@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# ScrapeData\nPython module to get table data from any webpage and converts it into either Json or Csv\n\n## Installation\nSupported python version is 3.0+\n```\npip3 install ScrapeData\n```\n\n## Usage\nThere are 4 functions exposed which will do all the work for you available in **TableParser**\n```\n1. toJsonByClass(URL, tagClass, orientation, tagId = \"table\")\n2. toJsonByIndex(URL, tagIndex, orientation, tagId = \"table\")\n3. toCsvByClass(URL, tagClass, fileName, tagId = \"table\")\n4. toCsvByIndex(URL, tagIndex, fileName, tagId = \"table\")\n```\n\n1. **URL** :- The url from where table needs to fetched\n2. **tagClass** :- if there is any class associated with tag\n3. **tagIndex** :- the occurance index of the table you want to fetch.\n4. **tagId** :- the html tag which is by default table (optional value)\n5. **orientation** :-\n```\n‘split’ : dict like {‘index’ -> [index], ‘columns’ -> [columns], ‘data’ -> [values]}\n‘records’ : list like [{column -> value}, … , {column -> value}]\n‘index’ : dict like {index -> {column -> value}}\n‘columns’ : dict like {column -> {index -> value}}\n‘values’ : just the values array\n‘table’ : dict like {‘schema’: {schema}, ‘data’: {data}} describing the data, and the data component is like orient='records'.\n```\nThere are other functions available in **Utils** if you want to customize the implementation.\n```\n1. getDataFromUrl(url)\n2. parseDataUsingHtmlParser(page)\n3. findTableByClass(soup, tagId, tagClass)\n4. findTableByIndex(soup, tagId, tagIndex)\n5. convertTableToList(table)\n6. convertListToJson(dataList, orientation = 'none')\n7. convertListToCsv(dataList, fileName)\n```\n\n## Example Code\n\n```\nfrom ScrapeData import TableParser as parser\nfrom ScrapeData import Utils\n\nURL = 'https://www.w3schools.com/python/module_requests.asp'\ntableClass = 'w3-table-all notranslate'\n\nprint(parser.toJsonByClass(URL, tableClass, 'records'))\nprint(parser.toJsonByIndex(URL, 0, 'records'))\nprint(parser.toCsvByIndex(URL, 0, 'records.csv'))\n```\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/mk6619/",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "ScrapeData",
    "package_url": "https://pypi.org/project/ScrapeData/",
    "platform": "",
    "project_url": "https://pypi.org/project/ScrapeData/",
    "project_urls": {
      "Homepage": "https://github.com/mk6619/"
    },
    "release_url": "https://pypi.org/project/ScrapeData/0.0.6/",
    "requires_dist": [
      "setuptools",
      "pandas",
      "requests",
      "beautifulsoup4"
    ],
    "requires_python": "",
    "summary": "Python module to get table data from any webpage and converts it into either Json or Csv",
    "version": "0.0.6",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 7854519,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e7e7a5e86becb655394a4a303f0f7b7d930b359fd13e2f56d86cbfe9496272db",
          "md5": "a85681589016347a0af496700efb819c",
          "sha256": "bfcdc7e1b81b8e6d2002a234029facce9d45cefa80eb862860d064b195fad80b"
        },
        "downloads": -1,
        "filename": "ScrapeData-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "a85681589016347a0af496700efb819c",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 2796,
        "upload_time": "2020-07-31T07:28:34",
        "upload_time_iso_8601": "2020-07-31T07:28:34.686784Z",
        "url": "https://files.pythonhosted.org/packages/e7/e7/a5e86becb655394a4a303f0f7b7d930b359fd13e2f56d86cbfe9496272db/ScrapeData-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2700a9a8e8f801eb67c32e1ca3ec246877303c2a0a2ba841752ec38f55fefc29",
          "md5": "381b1afcea4f4916be1b11b4937ac7dc",
          "sha256": "aa05226357f3b6403c0eaf4addaf377df7985ada70d7ab19873b2bfc2026d41a"
        },
        "downloads": -1,
        "filename": "ScrapeData-0.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "381b1afcea4f4916be1b11b4937ac7dc",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 2836,
        "upload_time": "2020-07-31T07:31:31",
        "upload_time_iso_8601": "2020-07-31T07:31:31.251614Z",
        "url": "https://files.pythonhosted.org/packages/27/00/a9a8e8f801eb67c32e1ca3ec246877303c2a0a2ba841752ec38f55fefc29/ScrapeData-0.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1b1dcbe92ca4f8f6284ac04424ea4874c1e76545ebfe62b9399c4aaf21a3ec1e",
          "md5": "954ff38d13cdcd893a83ddc58aacaab3",
          "sha256": "4bd6a0de4af905d7cfddf3a6b3c69e2734f2375c1412b999624dee4fe00d5218"
        },
        "downloads": -1,
        "filename": "ScrapeData-0.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "954ff38d13cdcd893a83ddc58aacaab3",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 4708,
        "upload_time": "2020-07-31T08:20:04",
        "upload_time_iso_8601": "2020-07-31T08:20:04.287033Z",
        "url": "https://files.pythonhosted.org/packages/1b/1d/cbe92ca4f8f6284ac04424ea4874c1e76545ebfe62b9399c4aaf21a3ec1e/ScrapeData-0.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8c8d5836a454b4a814551c7d76132b9c2b63d667796b74ce4add8702c5b07f46",
          "md5": "919b7eb497d810f281aac9e8c608192c",
          "sha256": "e4b2b68a78384cc02e6fa5afbae0daddb246fa23f83238c64f6c0d621d4c200b"
        },
        "downloads": -1,
        "filename": "ScrapeData-0.0.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "919b7eb497d810f281aac9e8c608192c",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 4718,
        "upload_time": "2020-07-31T09:14:49",
        "upload_time_iso_8601": "2020-07-31T09:14:49.202785Z",
        "url": "https://files.pythonhosted.org/packages/8c/8d/5836a454b4a814551c7d76132b9c2b63d667796b74ce4add8702c5b07f46/ScrapeData-0.0.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "17d3f2435ea5d995ec17f135dcbaa5c5dcfa71d954f78318ff70f1e5a0596726",
          "md5": "f7b5bc3e6f8a79b7aa0f8cbfbf4cfe38",
          "sha256": "40aa0fc31f581d4aa23d297a1d0b6a8823e83279f10696d5cac7555a6a8c9617"
        },
        "downloads": -1,
        "filename": "ScrapeData-0.0.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f7b5bc3e6f8a79b7aa0f8cbfbf4cfe38",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 4709,
        "upload_time": "2020-07-31T11:36:10",
        "upload_time_iso_8601": "2020-07-31T11:36:10.890780Z",
        "url": "https://files.pythonhosted.org/packages/17/d3/f2435ea5d995ec17f135dcbaa5c5dcfa71d954f78318ff70f1e5a0596726/ScrapeData-0.0.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e642213247f9909a36c4107dcb45c5a60400815e79d53b6da29fe0d80014cc65",
          "md5": "99fbbeb239b5ea3ef1f8154d9b07e5f6",
          "sha256": "2c53338ed21a3db5776cc5b4e2b41a3eadf846749a47afd67df42d0b3f00666a"
        },
        "downloads": -1,
        "filename": "ScrapeData-0.0.6-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "99fbbeb239b5ea3ef1f8154d9b07e5f6",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 4764,
        "upload_time": "2020-07-31T12:43:35",
        "upload_time_iso_8601": "2020-07-31T12:43:35.673387Z",
        "url": "https://files.pythonhosted.org/packages/e6/42/213247f9909a36c4107dcb45c5a60400815e79d53b6da29fe0d80014cc65/ScrapeData-0.0.6-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "e642213247f9909a36c4107dcb45c5a60400815e79d53b6da29fe0d80014cc65",
        "md5": "99fbbeb239b5ea3ef1f8154d9b07e5f6",
        "sha256": "2c53338ed21a3db5776cc5b4e2b41a3eadf846749a47afd67df42d0b3f00666a"
      },
      "downloads": -1,
      "filename": "ScrapeData-0.0.6-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "99fbbeb239b5ea3ef1f8154d9b07e5f6",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 4764,
      "upload_time": "2020-07-31T12:43:35",
      "upload_time_iso_8601": "2020-07-31T12:43:35.673387Z",
      "url": "https://files.pythonhosted.org/packages/e6/42/213247f9909a36c4107dcb45c5a60400815e79d53b6da29fe0d80014cc65/ScrapeData-0.0.6-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}