{
  "info": {
    "author": "Sai Muralidhar Jayanthi, Danish Pruthi, and Graham Neubig",
    "author_email": "jsaimurali001@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: MIT License",
      "Natural Language :: English",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Topic :: Scientific/Engineering :: Artificial Intelligence"
    ],
    "description": "<h1 align=\"center\">\n<p>NeuSpell: A Neural Spelling Correction Toolkit\n</h1>\n\n# Contents\n\n- [Installation & Quick Start](#Installation)\n- [Introduction](#Introduction)\n- [Pretrained models](#Pretrained-models)\n- [Demo Setup](#Demo-Setup)\n- [Datasets](#Datasets)\n- [Applications](#Potential-applications-for-practitioners)\n- [Additional Requirements](#Additional-requirements)\n\n# Updates\n\n- April 2021: `neuspell` is now available through pip. To install, simply do `pip install neuspell`.\n- March, 2021: Code-base reformatted. Addressed some bug fixes.\n- November, 2020: Neuspell's ```BERT``` pretrained model is now available as part of huggingface models\n  as ```murali1996/bert-base-cased-spell-correction```. We provide an example code snippet\n  at [./scripts/huggingface](./huggingface/huggingface-snippet-for-neuspell.py) for curious practitioners.\n- September, 2020: This work is accepted at EMNLP 2020 (system demonstrations)\n\n# Installation\n\n```bash\ngit clone https://github.com/neuspell/neuspell; cd neuspell\npip install -e .\n```\n\nTo install extra requirements,\n```bash\npip install -r extras-requirements.txt\n```\nor individually as (NOTE: For _zsh_, use \".[elmo]\" and \".[spacy]\")\n```bash\npip install -e .[elmo]\npip install -e .[spacy]\n```\n\nAdditionally, ```spacy models``` can be downloaded as:\n```bash\npython -m spacy download en_core_web_sm\n```\nFollow [Additional Requirements](#Additional-requirements) for installing non-neural spell checkers- ```Aspell``` and ```Jamspell```.\n\nThen, download pretrained models following [Pretrained models](#Pretrained-models)\n\nHere is a quick-start code snippet (command line usage). (See [```test.py```](test.py) for more usage\npatterns)\n\n```python\n\"\"\" select spell checkers \"\"\"\nfrom neuspell import BertChecker\n\n\"\"\" load spell checkers \"\"\"\nchecker = BertChecker()\nchecker.from_pretrained()\n\n\"\"\" spell correction \"\"\"\nchecker.correct(\"I luk foward to receving your reply\")\n# → \"I look forward to receiving your reply\"\nchecker.correct_strings([\"I luk foward to receving your reply\", ])\n# → [\"I look forward to receiving your reply\"]\nchecker.correct_from_file(src=\"noisy_texts.txt\")\n# → \"Found 450 mistakes in 322 lines, total_lines=350\"\n\n\"\"\" evaluation of models \"\"\"\nchecker.evaluate(clean_file=\"bea60k.txt\", corrupt_file=\"bea60k.noise.txt\")\n# → data size: 63044\n# → total inference time for this data is: 998.13 secs\n# → total token count: 1032061\n# → confusion table: corr2corr:940937, corr2incorr:21060,\n#                    incorr2corr:55889, incorr2incorr:14175\n# → accuracy is 96.58%\n# → word correction rate is 79.76%\n\n\"\"\" fine-tuning on domain specific dataset \"\"\"\nchecker.finetune(clean_file=\"sample_clean.txt\", corrupt_file=\"sample_corrupt.txt\")\n# Once the model is fine-tuned, you can use the saved model checkpoint path\n#   to load and infer by calling `checker.from_pretrained(...)` as above\n```\n\nAlternatively, once can also select and load a spell checker differently as follows:\n\n```python\nfrom neuspell import SclstmChecker\nchecker = SclstmChecker()\nchecker = checker.add_(\"elmo\", at=\"input\")  # elmo or bert, input or output\nchecker.from_pretrained()\nchecker.finetune(clean_file=\"./data/traintest/test.bea322\", corrupt_file=\"./data/traintest/test.bea322.noise\")\n```\n\n# Introduction\n\nNeuSpell is an open-source toolkit for context sensitive spelling correction in English. This toolkit comprises of 10\nspell checkers, with evaluations on naturally occurring mis-spellings from multiple (publicly available) sources. To\nmake neural models for spell checking context dependent, (i) we train neural models using spelling errors in context,\nsynthetically constructed by reverse engineering isolated mis-spellings; and  (ii) use richer representations of the\ncontext.This toolkit enables NLP practitioners to use our proposed and existing spelling correction systems, both via a\nsimple unified command line, as well as a web interface. Among many potential applications, we demonstrate the utility\nof our spell-checkers in combating adversarial misspellings.\n\n##### Demo available at <http://neuspell.github.io/>\n\n<p align=\"center\">\n    <br>\n    <img src=\"https://github.com/neuspell/neuspell/blob/master/images/ui.png?raw=true\" width=\"400\"/>\n    <br>\n<p>\n\n##### List of neural models in the toolkit:\n\n- [```CNN-LSTM```](https://drive.google.com/file/d/14XiDY4BJ144fVGE2cfWfwyjnMwBcwhNa/view?usp=sharing)\n- [```SC-LSTM```](https://drive.google.com/file/d/1OvbkdBXawnefQF1d-tUrd9lxiAH1ULtr/view?usp=sharing)\n- [```Nested-LSTM```](https://drive.google.com/file/d/19ZhWvBaZqrsP5cGqBJdFPtufdyBqQprI/view?usp=sharing)\n- [```BERT```](https://huggingface.co/transformers/bertology.html)\n- [```SC-LSTM plus ELMO (at input)```](https://drive.google.com/file/d/1mjLFuQ0vWOOpPqTVkFZ_MSHiuVUmgHSK/view?usp=sharing)\n- [```SC-LSTM plus ELMO (at output)```](https://drive.google.com/file/d/1P8vX9ByOBQpN9oeho_iOJmFJByv1ifI5/view?usp=sharing)\n- [```SC-LSTM plus BERT (at input)```](https://huggingface.co/transformers/bertology.html)\n- [```SC-LSTM plus BERT (at output)```](https://huggingface.co/transformers/bertology.html)\n\n<p align=\"center\">\n    <br>\n    <img src=\"https://github.com/neuspell/neuspell/blob/master/images/pipeline.jpeg?raw=true\" width=\"400\"/>\n    <br>\n    This pipeline corresponds to the `SC-LSTM plus ELMO (at input)` model.\n<p>\n\n##### Performances\n\n| Spell<br>Checker    | Word<br>Correction <br>Rate | Time per<br>sentence <br>(in milliseconds) |\n|----------|----------------------|--------------------------------------|\n| ```Aspell``` | 48.7 | 7.3* |\n|``` Jamspell``` | 68.9 | 2.6* |\n|```CNN-LSTM``` |75.8 |  4.2|\n|```SC-LSTM``` | 76.7| 2.8 |\n|```Nested-LSTM``` |77.3 | 6.4|\n|```BERT``` | 79.1| 7.1|\n|```SC-LSTM plus ELMO (at input)``` |<b> 79.8</b>|15.8 |\n|```SC-LSTM plus ELMO (at output)``` | 78.5| 16.3|\n|```SC-LSTM plus BERT (at input)``` | 77.0| 6.7|\n|```SC-LSTM plus BERT (at output)``` | 76.0| 7.2|\n\nPerformance of different correctors in the NeuSpell toolkit on the  ```BEA-60K```  dataset with real-world spelling\nmistakes. ∗ indicates evaluation on a CPU (for others we use a GeForce RTX 2080 Ti GPU).\n\n# Pretrained models\n\n##### Checkpoints\n\nRun the following to download checkpoints of all neural models\n\n```\ncd data/checkpoints\npython download_checkpoints.py \n```\n\nSee ```data/checkpoints/README.md``` for more details. You can alternatively choose to download only selected models'\ncheckpoints.\n\n# Demo Setup\n\nIn order to setup a demo, follow these steps:\n\n- Do [Installation](#Installation)\n- Download [checkpoints](#Pretrained-models)\n- Start a flask server at [neuspell/flask-server](./flask-server) by running `CUDA_VISIBLE_DEVICES=0 python app.py`\n  (on GPU) or `python app.py` (on CPU)\n\n# Datasets\n\n##### Download datasets\n\nRun the following to download datasets\n\n```\ncd data/traintest\npython download_datafiles.py \n```\n\nSee ```data/traintest/README.md``` for more details.\n\n##### Synthetic Training Dataset Creation\n\nThe toolkit offers 4 kinds of noising strategies to generate synthetic parallel training data to train neural models for\nspell correction.\n\n- ```RANDOM```\n- ```Word Replacement```\n- ```Probabilistic Replacement```\n- A combination of ```Word Replacement``` and ```Probabilistic Replacement```\n\nTrain files are dubbed with names ```.random```, ```.word```, ```.prob```, ```.probword``` respectively. For each\nstrategy, we noise ∼20% of the tokens in the clean corpus. We use 1.6 Million sentences from\nthe [```One billion word benchmark```](https://arxiv.org/abs/1312.3005) dataset as our clean corpus.\n\n# Potential applications for practitioners\n\n- Defenses against adversarial attacks in NLP\n    - example implementation available in folder ```./applications/Adversarial-Misspellings```\n- Improving OCR text correction systems\n- Improving grammatical error correction systems\n- Improving Intent/Domain classifiers in conversational AI\n- Spell Checking in Collaboration and Productivity tools\n\n# Additional requirement\n\nRequirements for ```Aspell``` checker:\n\n```\nwget https://files.pythonhosted.org/packages/53/30/d995126fe8c4800f7a9b31aa0e7e5b2896f5f84db4b7513df746b2a286da/aspell-python-py3-1.15.tar.bz2\ntar -C . -xvf aspell-python-py3-1.15.tar.bz2\ncd aspell-python-py3-1.15\npython setup.py install\n```\n\nRequirements for ```Jamspell``` checker:\n\n```\nsudo apt-get install -y swig3.0\nwget -P ./ https://github.com/bakwc/JamSpell-models/raw/master/en.tar.gz\ntar xf ./en.tar.gz --directory ./\n```\n\n# Citation\n\n```\n@inproceedings{jayanthi-etal-2020-neuspell,\n    title = \"{N}eu{S}pell: A Neural Spelling Correction Toolkit\",\n    author = \"Jayanthi, Sai Muralidhar  and\n      Pruthi, Danish  and\n      Neubig, Graham\",\n    booktitle = \"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations\",\n    month = oct,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.emnlp-demos.21\",\n    doi = \"10.18653/v1/2020.emnlp-demos.21\",\n    pages = \"158--164\",\n    abstract = \"We introduce NeuSpell, an open-source toolkit for spelling correction in English. Our toolkit comprises ten different models, and benchmarks them on naturally occurring misspellings from multiple sources. We find that many systems do not adequately leverage the context around the misspelt token. To remedy this, (i) we train neural models using spelling errors in context, synthetically constructed by reverse engineering isolated misspellings; and (ii) use richer representations of the context. By training on our synthetic examples, correction rates improve by 9{\\%} (absolute) compared to the case when models are trained on randomly sampled character perturbations. Using richer contextual representations boosts the correction rate by another 3{\\%}. Our toolkit enables practitioners to use our proposed and existing spelling correction systems, both via a simple unified command line, as well as a web interface. Among many potential applications, we demonstrate the utility of our spell-checkers in combating adversarial misspellings. The toolkit can be accessed at neuspell.github.io.\",\n}\n```\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/neuspell/neuspell",
    "keywords": "transformer networks neuspell neural spelling correction embedding PyTorch NLP deep learning",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "neuspell",
    "package_url": "https://pypi.org/project/neuspell/",
    "platform": "",
    "project_url": "https://pypi.org/project/neuspell/",
    "project_urls": {
      "Homepage": "https://github.com/neuspell/neuspell"
    },
    "release_url": "https://pypi.org/project/neuspell/1.0.0/",
    "requires_dist": [
      "transformers",
      "tqdm",
      "torch (>=1.6.0)",
      "numpy",
      "jsonlines",
      "sentencepiece",
      "pytorch-pretrained-bert",
      "allennlp (==1.5.0) ; extra == 'elmo'",
      "spacy ; extra == 'spacy'"
    ],
    "requires_python": ">3.5",
    "summary": "NeuSpell: A Neural Spelling Correction Toolkit",
    "version": "1.0.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 9964187,
  "releases": {
    "0.9.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9974b58f568c2a71f78ca8ff567de9711f83c2c8fa1cd7c33cae90a2cca5875b",
          "md5": "919021a59345cfe911a538262111e30f",
          "sha256": "0a96845972a73878b5c1d50320a403dea59a28cc5025df84ce04bb5309664f1a"
        },
        "downloads": -1,
        "filename": "neuspell-0.9.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "919021a59345cfe911a538262111e30f",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">3.5",
        "size": 184239,
        "upload_time": "2021-04-03T07:59:26",
        "upload_time_iso_8601": "2021-04-03T07:59:26.568116Z",
        "url": "https://files.pythonhosted.org/packages/99/74/b58f568c2a71f78ca8ff567de9711f83c2c8fa1cd7c33cae90a2cca5875b/neuspell-0.9.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e6364198312e987e617bf3e371418e2dae50fb5c03fbe9bc3b27fd6bd5670458",
          "md5": "1a72446b8a3c52df196ff80b9e9bcd4e",
          "sha256": "3082166a863140731f9ba9a9e021298f2f6f881caab06bf673c30dbbd3f1bae6"
        },
        "downloads": -1,
        "filename": "neuspell-0.9.0.tar.gz",
        "has_sig": false,
        "md5_digest": "1a72446b8a3c52df196ff80b9e9bcd4e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">3.5",
        "size": 143104,
        "upload_time": "2021-04-03T07:59:28",
        "upload_time_iso_8601": "2021-04-03T07:59:28.650789Z",
        "url": "https://files.pythonhosted.org/packages/e6/36/4198312e987e617bf3e371418e2dae50fb5c03fbe9bc3b27fd6bd5670458/neuspell-0.9.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "824edc440b25c326b701ddfe57bfe80fc7377880296c4ebb426109dcca0d62ba",
          "md5": "1d27e8d5f096b0f02e59b75eb43cfdcb",
          "sha256": "4afbba61cf9d2db5e32e4cc5a23f5cc12a516188ba09b09ddafbe07822353c3b"
        },
        "downloads": -1,
        "filename": "neuspell-1.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "1d27e8d5f096b0f02e59b75eb43cfdcb",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">3.5",
        "size": 184282,
        "upload_time": "2021-04-03T08:15:16",
        "upload_time_iso_8601": "2021-04-03T08:15:16.534353Z",
        "url": "https://files.pythonhosted.org/packages/82/4e/dc440b25c326b701ddfe57bfe80fc7377880296c4ebb426109dcca0d62ba/neuspell-1.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0c27397c5275ec55488a13f379f87b597ad7094b3eaa205da5e31dc5bba31b6a",
          "md5": "7a6730e26ab4b808ce2342c2ca5705b0",
          "sha256": "91c8918a132a21eb45e8c87cecdb9593ce2eb88379fe534745c7f6ffdab6a51e"
        },
        "downloads": -1,
        "filename": "neuspell-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "7a6730e26ab4b808ce2342c2ca5705b0",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">3.5",
        "size": 143192,
        "upload_time": "2021-04-03T08:15:18",
        "upload_time_iso_8601": "2021-04-03T08:15:18.145821Z",
        "url": "https://files.pythonhosted.org/packages/0c/27/397c5275ec55488a13f379f87b597ad7094b3eaa205da5e31dc5bba31b6a/neuspell-1.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "824edc440b25c326b701ddfe57bfe80fc7377880296c4ebb426109dcca0d62ba",
        "md5": "1d27e8d5f096b0f02e59b75eb43cfdcb",
        "sha256": "4afbba61cf9d2db5e32e4cc5a23f5cc12a516188ba09b09ddafbe07822353c3b"
      },
      "downloads": -1,
      "filename": "neuspell-1.0.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "1d27e8d5f096b0f02e59b75eb43cfdcb",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">3.5",
      "size": 184282,
      "upload_time": "2021-04-03T08:15:16",
      "upload_time_iso_8601": "2021-04-03T08:15:16.534353Z",
      "url": "https://files.pythonhosted.org/packages/82/4e/dc440b25c326b701ddfe57bfe80fc7377880296c4ebb426109dcca0d62ba/neuspell-1.0.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "0c27397c5275ec55488a13f379f87b597ad7094b3eaa205da5e31dc5bba31b6a",
        "md5": "7a6730e26ab4b808ce2342c2ca5705b0",
        "sha256": "91c8918a132a21eb45e8c87cecdb9593ce2eb88379fe534745c7f6ffdab6a51e"
      },
      "downloads": -1,
      "filename": "neuspell-1.0.0.tar.gz",
      "has_sig": false,
      "md5_digest": "7a6730e26ab4b808ce2342c2ca5705b0",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">3.5",
      "size": 143192,
      "upload_time": "2021-04-03T08:15:18",
      "upload_time_iso_8601": "2021-04-03T08:15:18.145821Z",
      "url": "https://files.pythonhosted.org/packages/0c/27/397c5275ec55488a13f379f87b597ad7094b3eaa205da5e31dc5bba31b6a/neuspell-1.0.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}