{
  "info": {
    "author": null,
    "author_email": "Astronomer <humans@astronomer.io>",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Framework :: Apache Airflow",
      "Framework :: Apache Airflow :: Provider",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: OS Independent",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9"
    ],
    "description": "<h1 align=\"center\">\n  Astro Databricks\n</h1>\n  <h3 align=\"center\">\n  Orchestrate your Databricks notebooks in Airflow and execute them as Databricks Workflows<br><br>\n</h3>\n\n[![Python versions](https://img.shields.io/pypi/pyversions/astro-provider-databricks.svg)](https://pypi.org/pypi/astro-provider-databricks)\n[![License](https://img.shields.io/pypi/l/astro-provider-databricks.svg)](https://pypi.org/pypi/astro-provider-databricks)\n[![Development Status](https://img.shields.io/pypi/status/astro-provider-databricks.svg)](https://pypi.org/pypi/astro-provider-databricks)\n[![PyPI downloads](https://img.shields.io/pypi/dm/astro-provider-databricks.svg)](https://pypistats.org/packages/astro-provider-databricks)\n[![Contributors](https://img.shields.io/github/contributors/astronomer/astro-provider-databricks)](https://github.com/astronomer/astro-provider-databricks)\n[![Commit activity](https://img.shields.io/github/commit-activity/m/astronomer/astro-provider-databricks)](https://github.com/astronomer/astro-provider-databricks)\n[![CI](https://github.com/astronomer/astro-provider-databricks/actions/workflows/ci.yml/badge.svg)](https://github.com/astronomer/astro-provider-databricks)\n[![codecov](https://codecov.io/gh/astronomer/astro-provider-databricks/branch/main/graph/badge.svg?token=MI4SSE50Q6)](https://codecov.io/gh/astronomer/astro-provider-databricks)\n\n\nThe **Astro Databricks Provider** is an [Apache Airflow](https://github.com/apache/airflow) provider created by [Astronomer](https://www.astronomer.io/) to run your Databricks notebooks as Databricks Workflows while maintaining Airflow as the authoring interface. When using the `DatabricksTaskGroup` and `DatabricksNotebookOperator`, notebooks run as a Databricks Workflow which can result in a [75% cost reduction](https://www.databricks.com/product/aws-pricing) ($0.40/DBU for all-purpose compute, $0.10/DBU for Jobs compute).\n\n## Prerequisites\n\n* Apache Airflow >= 2.2.4\n* Python >= 2.7\n* Databricks account\n* Previously created Databricks Notebooks\n\n## Install\n\n```shell\npip install astro-provider-databricks\n```\n\n## Quickstart\n\n1. Use pre-existing or create two simple [Databricks Notebooks](https://docs.databricks.com/notebooks/). Their identifiers will be used in step (5). The original example DAG uses: \n   * `Shared/Notebook_1`\n   * `Shared/Notebook_2`\n\n2. Generate a [Databricks Personal Token](https://docs.databricks.com/dev-tools/auth.html#databricks-personal-access-tokens). This will be used in step (6). \n\n3. Ensure that your Airflow environment is set up correctly by running the following commands:\n\n    ```shell\n    export AIRFLOW_HOME=`pwd`\n   \n    airflow db init\n    ```\n   \n4. [Create a Databricks connection in Airflow](https://airflow.apache.org/docs/apache-airflow/stable/howto/connection.html). This can be done by running the following command, replacing the login and password (with your access token):\n\n   ```shell\n   # If using Airflow 2.3 or higher:\n   airflow connections add 'databricks_conn' \\\n       --conn-json '{\n           \"conn_type\": \"databricks\",\n           \"login\": \"some.email@yourcompany.com\",\n           \"host\": \"https://dbc-c9390870-65ef.cloud.databricks.com/\",\n           \"password\": \"personal-access-token\"\n       }'\n   \n   # If using Airflow between 2.2.4 and less than 2.3:\n   airflow connections add 'databricks_conn' --conn-type 'databricks' --conn-login 'some.email@yourcompany.com' --conn-host 'https://dbc-9c390870-65ef.cloud.databricks.com/' --conn-password 'personal-access-token'\n   ```\n\n5. Copy the following workflow into a file named `example_databricks_workflow.py` and add it to the `dags` directory of your Airflow project:\n   \n   https://github.com/astronomer/astro-provider-databricks/blob/45897543a5e34d446c84b3fbc4f6f7a3ed16cdf7/example_dags/example_databricks_workflow.py#L48-L101\n\n   Alternatively, you can download `example_databricks_workflow.py`\n   ```shell\n   curl -O https://raw.githubusercontent.com/astronomer/astro-provider-databricks/main/example_dags/example_databricks_workflow.py\n   ```\n\n6. Run the example DAG:\n\n    ```shell\n    airflow dags test example_databricks_workflow `date -Iseconds`\n    ```\n   \n    Which will log, among other lines, the link to the Databricks Job Run URL:\n    ```shell\n    [2023-03-13 15:27:09,934] {notebook.py:158} INFO - Check the job run in Databricks: https://dbc-c9390870-65ef.cloud.databricks.com/?o=4256138892007661#job/950578808520081/run/14940832\n    ```\n   \n    This will create a Databricks Workflow with two Notebook jobs. This workflow may take two minutes to complete if the cluster is already up & running or approximately five minutes depending on your cluster initialisation time.\n \n\n## Available features\n\n* `DatabricksWorkflowTaskGroup`: Airflow [task group](https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/dags.html#taskgroups) that allows users to create a [Databricks Workflow](https://www.databricks.com/product/workflows).\n* `DatabricksNotebookOperator`: Airflow [operator](https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/operators.html) which abstracts a pre-existing [Databricks Notebook](https://docs.databricks.com/notebooks/). Can be used independently to run the Notebook, or within a Databricks Workflow Task Group.\n* `AstroDatabricksPlugin`: An Airflow [plugin](https://airflow.apache.org/docs/apache-airflow/stable/authoring-and-scheduling/plugins.html) which is installed by the default. It allows users, by using the UI, to view a Databricks job and retry running it in case of failure.\n\n## Documentation\n\nThe documentation is a work in progress--we aim to follow the [DiÃ¡taxis](https://diataxis.fr/) system:\n\n* [Reference Guide](https://astronomer.github.io/astro-provider-databricks/)\n\n## Changelog\n\nAstro Databricks follows [semantic versioning](https://semver.org/) for releases. Read [changelog](CHANGELOG.rst) to understand more about the changes introduced to each version.\n\n## Contribution guidelines\n\nAll contributions, bug reports, bug fixes, documentation improvements, enhancements, and ideas are welcome.\n\nRead the [Contribution Guidelines](docs/contributing.rst) for a detailed overview on how to contribute.\n\nContributors and maintainers should abide by the [Contributor Code of Conduct](CODE_OF_CONDUCT.md).\n\n## License\n\n[Apache Licence 2.0](LICENSE)\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": null,
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": null,
    "keywords": "airflow,apache-airflow,astronomer,dags",
    "license": null,
    "maintainer": null,
    "maintainer_email": null,
    "name": "astro-provider-databricks",
    "package_url": "https://pypi.org/project/astro-provider-databricks/",
    "platform": null,
    "project_url": "https://pypi.org/project/astro-provider-databricks/",
    "project_urls": {
      "Documentation": "https://github.com/astronomer/astro-provider-databricks/",
      "Homepage": "https://github.com/astronomer/astro-provider-databricks/"
    },
    "release_url": "https://pypi.org/project/astro-provider-databricks/0.1.1/",
    "requires_dist": [
      "apache-airflow-providers-databricks>=2.2.0",
      "apache-airflow>=2.2.4",
      "databricks-cli",
      "databricks-sql-connector>=2.0.4; python_version >= '3.10'",
      "mergedeep",
      "pydata-sphinx-theme; extra == 'docs'",
      "sphinx; extra == 'docs'",
      "sphinx-autobuild; extra == 'docs'",
      "sphinx-tabs; extra == 'docs'",
      "mypy; extra == 'tests'",
      "pytest-cov; extra == 'tests'",
      "pytest-describe; extra == 'tests'",
      "pytest-dotenv; extra == 'tests'",
      "pytest-split; extra == 'tests'",
      "pytest>=6.0; extra == 'tests'",
      "requests-mock; extra == 'tests'",
      "sqlalchemy-stubs; extra == 'tests'",
      "types-requests; extra == 'tests'"
    ],
    "requires_python": ">=3.7",
    "summary": "Affordable Databricks Workflows in Apache Airflow",
    "version": "0.1.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17364032,
  "releases": {
    "0.1.0": [
      {
        "comment_text": null,
        "digests": {
          "blake2b_256": "5768d079ce21cb3afb8034a1d8cb31b6a09e24ba3ed610d3aa67c5307f61f7a6",
          "md5": "ebc9f62c39696ed0ad0d18c8c1153601",
          "sha256": "c3fd957cc73e529ec7b51a1969f4575c6f03bc65e7bcaf2ab3f0d29c9dc04627"
        },
        "downloads": -1,
        "filename": "astro_provider_databricks-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ebc9f62c39696ed0ad0d18c8c1153601",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 20818,
        "upload_time": "2023-03-13T10:23:08",
        "upload_time_iso_8601": "2023-03-13T10:23:08.639372Z",
        "url": "https://files.pythonhosted.org/packages/57/68/d079ce21cb3afb8034a1d8cb31b6a09e24ba3ed610d3aa67c5307f61f7a6/astro_provider_databricks-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": null,
        "digests": {
          "blake2b_256": "8ecc43c5b3063a150db68f147d65b1edf3922880d3c2eb501daf53d6792b716f",
          "md5": "233fe8b3ec3488a3cd6e14c5218c30e1",
          "sha256": "3436f9b9b89ea96e1c20c03d49ff3ccb25681e34b56d975c3427e4010b8d0d21"
        },
        "downloads": -1,
        "filename": "astro_provider_databricks-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "233fe8b3ec3488a3cd6e14c5218c30e1",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 1735889,
        "upload_time": "2023-03-13T10:23:13",
        "upload_time_iso_8601": "2023-03-13T10:23:13.382849Z",
        "url": "https://files.pythonhosted.org/packages/8e/cc/43c5b3063a150db68f147d65b1edf3922880d3c2eb501daf53d6792b716f/astro_provider_databricks-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.1": [
      {
        "comment_text": null,
        "digests": {
          "blake2b_256": "93b84be8054533af948c75bf30b7ca8c5d6f32bcf0ed13a69c3b15fa68d6f602",
          "md5": "65c644a44f1d2759319e09baeaccc4a0",
          "sha256": "4612575e367b6cd60a460a3150e4d982e51d8b93011f8efa2c2aa26bc4caa8ad"
        },
        "downloads": -1,
        "filename": "astro_provider_databricks-0.1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "65c644a44f1d2759319e09baeaccc4a0",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 21640,
        "upload_time": "2023-03-13T17:59:02",
        "upload_time_iso_8601": "2023-03-13T17:59:02.395862Z",
        "url": "https://files.pythonhosted.org/packages/93/b8/4be8054533af948c75bf30b7ca8c5d6f32bcf0ed13a69c3b15fa68d6f602/astro_provider_databricks-0.1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": null,
        "digests": {
          "blake2b_256": "76b102c8c38d4269b3d4aaa059578f06d6e5eb324dc4bc5cd1bf8cee68f72d4d",
          "md5": "3faf938bbb47bfd3b6f42b435c75d767",
          "sha256": "1948dbad60e207fb2e1499303be9b896e1abaa9cb1811e7cdbf3599b85fb931c"
        },
        "downloads": -1,
        "filename": "astro_provider_databricks-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "3faf938bbb47bfd3b6f42b435c75d767",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 1791375,
        "upload_time": "2023-03-13T17:59:00",
        "upload_time_iso_8601": "2023-03-13T17:59:00.167371Z",
        "url": "https://files.pythonhosted.org/packages/76/b1/02c8c38d4269b3d4aaa059578f06d6e5eb324dc4bc5cd1bf8cee68f72d4d/astro_provider_databricks-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": null,
      "digests": {
        "blake2b_256": "93b84be8054533af948c75bf30b7ca8c5d6f32bcf0ed13a69c3b15fa68d6f602",
        "md5": "65c644a44f1d2759319e09baeaccc4a0",
        "sha256": "4612575e367b6cd60a460a3150e4d982e51d8b93011f8efa2c2aa26bc4caa8ad"
      },
      "downloads": -1,
      "filename": "astro_provider_databricks-0.1.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "65c644a44f1d2759319e09baeaccc4a0",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 21640,
      "upload_time": "2023-03-13T17:59:02",
      "upload_time_iso_8601": "2023-03-13T17:59:02.395862Z",
      "url": "https://files.pythonhosted.org/packages/93/b8/4be8054533af948c75bf30b7ca8c5d6f32bcf0ed13a69c3b15fa68d6f602/astro_provider_databricks-0.1.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": null,
      "digests": {
        "blake2b_256": "76b102c8c38d4269b3d4aaa059578f06d6e5eb324dc4bc5cd1bf8cee68f72d4d",
        "md5": "3faf938bbb47bfd3b6f42b435c75d767",
        "sha256": "1948dbad60e207fb2e1499303be9b896e1abaa9cb1811e7cdbf3599b85fb931c"
      },
      "downloads": -1,
      "filename": "astro_provider_databricks-0.1.1.tar.gz",
      "has_sig": false,
      "md5_digest": "3faf938bbb47bfd3b6f42b435c75d767",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 1791375,
      "upload_time": "2023-03-13T17:59:00",
      "upload_time_iso_8601": "2023-03-13T17:59:00.167371Z",
      "url": "https://files.pythonhosted.org/packages/76/b1/02c8c38d4269b3d4aaa059578f06d6e5eb324dc4bc5cd1bf8cee68f72d4d/astro_provider_databricks-0.1.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}