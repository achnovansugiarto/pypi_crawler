{
  "info": {
    "author": "Nath Prachayakul",
    "author_email": "nath.prachayakul@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3 :: Only",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Topic :: Software Development :: Build Tools"
    ],
    "description": "![TensorFlow](https://img.shields.io/badge/TensorFlow-%23FF6F00.svg?style=flat&logo=TensorFlow&logoColor=white) \n![Keras](https://img.shields.io/badge/Keras-%23D00000.svg?style=flat&logo=Keras&logoColor=white) \n[![Codacy Badge](https://app.codacy.com/project/badge/Grade/2480da2b4a684a198c75db6ed249edda)](https://www.codacy.com/gh/namirinz/KME-WordSegmentation/dashboard?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=namirinz/KME-WordSegmentation&amp;utm_campaign=Badge_Grade)\n# KME Word Segmentation\nAI for tokenize chemical IUPAC name using tensorflow and keras.\n\n## Prepare training dataset\n#### What to have\n1. CHAR_INDICES: dictionary with key is character [string], value is number [int] *(use to preprocess text to number)*\n\n2. Dict_cut: Input text with determined (by '|' ) where to be cut (use for create label)\n```\nCyclo|prop|ane| |Non|a|-|1|,|8|-|di|yne| \n|1|,|3|-|di|chlorocyclo|hex|ane| |Hept|a|-|1|,|5|-|di|ene\n```\n\n3. Dict: Input text (raw) (use for train model)\n```\nCyclopropane Nona-1,8-diyne 1,3-dichlorocyclohexane Hepta-1,5-diene\n```\n\n## Create dataset\n1. Make JSON value as array of chemical name (dataset, dataset_cut)\n2. Split array for **training dataset (90%)** (dataset_train, dataset_cut_train) and **validation dataset (10%)** (dataset_val, dataset_cut_val) \n3. Join item in each array together into text\n4. Create dataset using **create_dataset function** that **take dataset_cut** then return **X_train**  (size: [text_length, look_back]) (dataset_cut that have been cut '|') and **label** (position where to cut 1 = cut, 0 = not cut)\n5. Use tf.data.Dataset.from_tensor_slices((X, y)).batch_size(128) to make data easy to be train\n\n## Create Model\n1. We use 1x**Embedding** layer, 1x**Bidirection LSTM** layer, **Dense** Layer\n2. Compiled **model optimizer = Adam**, **loss_function = Categorical Crossentropy** (becase we classify 2 label output 1 = cut, 0 = not cut) **call_back = [EarlyStopping, ModelCheckpoint]**\n*Early stopping : Stop train model if validation_loss is being increase*\n*ModelCheckpoint : Save model that has minimum validation_loss*\n\n## After Train Model\n- The output of the model is array (size: [batch_size, 2] determined which position to be cut (value = 0 -> not cut ; 1 -> cut))\n```\n[1 1 1 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0]\n```\n- Tokenize dataset (text which **didn't** determined where to be cut) with label (output from model) using **word_tokenize function** that return **array of text that has been cut**\n``` \n['1', ',', '2', '-', 'di', 'h', 'ydrox', 'y', '-', '2', '-', 'meth', 'yl', 'prop', 'ane']\n```\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/namirinz/nami",
    "keywords": "AI,tensorflow,development",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "kmeseg",
    "package_url": "https://pypi.org/project/kmeseg/",
    "platform": "",
    "project_url": "https://pypi.org/project/kmeseg/",
    "project_urls": {
      "Bug Reports": "https://github.com/namirinz/nami/issues",
      "Homepage": "https://github.com/namirinz/nami",
      "Source": "https://github.com/namirinz/nami"
    },
    "release_url": "https://pypi.org/project/kmeseg/0.1.1/",
    "requires_dist": [
      "tensorflow",
      "tqdm"
    ],
    "requires_python": ">=3.5, <4",
    "summary": "Useful AI library for chemistry.",
    "version": "0.1.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 11945864,
  "releases": {
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d0d2f365af9b3656267cbf9345d6e0bda80bedfe75b8fb26204e54c7933b9ea3",
          "md5": "475ee1eedb918f0aa03df829fadd62c7",
          "sha256": "c015c6bda2a16fda6e051621a8b8410652c56635d51ee692045899252da7335f"
        },
        "downloads": -1,
        "filename": "kmeseg-0.1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "475ee1eedb918f0aa03df829fadd62c7",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.5, <4",
        "size": 6727,
        "upload_time": "2021-11-06T15:32:45",
        "upload_time_iso_8601": "2021-11-06T15:32:45.880049Z",
        "url": "https://files.pythonhosted.org/packages/d0/d2/f365af9b3656267cbf9345d6e0bda80bedfe75b8fb26204e54c7933b9ea3/kmeseg-0.1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "d0d2f365af9b3656267cbf9345d6e0bda80bedfe75b8fb26204e54c7933b9ea3",
        "md5": "475ee1eedb918f0aa03df829fadd62c7",
        "sha256": "c015c6bda2a16fda6e051621a8b8410652c56635d51ee692045899252da7335f"
      },
      "downloads": -1,
      "filename": "kmeseg-0.1.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "475ee1eedb918f0aa03df829fadd62c7",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.5, <4",
      "size": 6727,
      "upload_time": "2021-11-06T15:32:45",
      "upload_time_iso_8601": "2021-11-06T15:32:45.880049Z",
      "url": "https://files.pythonhosted.org/packages/d0/d2/f365af9b3656267cbf9345d6e0bda80bedfe75b8fb26204e54c7933b9ea3/kmeseg-0.1.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}