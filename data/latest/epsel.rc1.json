{
  "info": {
    "author": "Stefaan Lippens",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "\n[![Build Status](https://travis-ci.org/soxofaan/epsel.svg?branch=master)](https://travis-ci.org/soxofaan/epsel)\n\n# EPSEL: Ensure PySpark Executor Logging\n\n`epsel` is a simple Python module that provides\na decorator based approach to enable/ensure standard Python logging \nfrom PySpark Executors.\n\n\n## The problem: logging from my PySpark executors doesn't work\n\nIn PySpark, the actual data processing is done in so called \"executors\",\nwhich are forked processes that are separate from the \"driver\" program.\nAs a user you have full control over the driver process, \nbut not so much over the executor processes.\n\nFor example, in your PySpark driver program you can set up \nstandard Python logging as desired, \nbut this setup is not replicated in the executor processes.\nThere are no (default) logging handlers, so all logging messages are lost.\nSince Python 3.2 however, when there are not handlers, \nthere is still a \"last resort\" handler that will show \n`warning()` and `error()` messages in their bare format on standard error,\nbut you probably want something more flexible than that.\n\n\nIllustration in interactive PySpark shell:\n\n    >>> import os, logging\n    >>> logging.basicConfig(level=logging.INFO)\n\n    >>> def describe():\n    ...     return \"pid: {p}, root handlers: {h}\".format(p=os.getpid(), h=logging.root.handlers)\n    ... \n    >>> describe()\n    'pid: 3376, root handlers: [<StreamHandler <stderr> (NOTSET)>]'\n\n    >>> sc.parallelize([1, 2, 3]).map(lambda x: describe()).collect()\n    ['pid: 4153, root handlers: []', 'pid: 4136, root handlers: []', 'pid: 4120, root handlers: []']\n\nThe first `describe()` happens in the driver and has root handlers because\nof the `basicConfig()` earlier.\nHowever, the `describe()` calls in the `map()` happen in separate process\n(note the different PIDs) and have no root handlers.\n\n\n\n## EPSEL: decorator based logging setup for PySpark executors\n\nAround the web you can find various solutions to set up logging in your executors. \nIt typically involves passing and loading a separate file with logging setup code.\nManaging this file might be cumbersome depending on your use case.\n\n\nIn contrast, `epsel` takes a decorator based approach.\nYou just have to decorate the data processing functions you are passing \nto `map()`, `filter()`, `sortBy()`, etc. \n\nA very minimal example:\n\n    @epsel.ensure_basic_logging\n    def process(x):\n        logger.info(\"Got {x}\".format(x=x))\n        return x * x\n\n    result = rdd.map(process).collect()\n\nWhat will happen here is that the first time `process()` is called \nin the executor, basic logging is set up as desired, \nso that logging messages are not lost.\n\n\n### Options and finetuning\n\nThe `ensure_basic_logging` decorator will do a basic logging setup using \n[`logging.basicConfig()`](https://docs.python.org/3/library/logging.html#logging.basicConfig), \nand desired options can be directly provided to the decorator\nas illustrated in the following example using the interactive PySpark shell:\n\n    >>> import logging\n    >>> from epsel import ensure_basic_logging\n    >>> logger = logging.getLogger(\"example\")\n\n    >>> @ensure_basic_logging(level=logging.INFO)\n    ... def process(x):\n    ...     logger.info(\"Got {x}\".format(x=x))\n    ...     return x * x\n    ... \n    >>> sc.parallelize(range(5)).map(process).collect()\n    INFO:example:Got 0\n    INFO:example:Got 1\n    INFO:example:Got 3\n    INFO:example:Got 2\n    INFO:example:Got 4\n    [0, 1, 4, 9, 16]\n\nTo improve readability or code reuse, you can of course predefine decorators:\n\n    with_logging = ensure_basic_logging(\n        level=logging.INFO,\n        format=\"[%(process)s/%(name)s] %(levelname)s %(message)s\"\n    )\n\n    @with_logging\n    def process(x):\n        ...\n\n\n`epsel` also defines some simple predefined decorators:\n\n    # Predefined decorator for stderr/INFO logging\n    ensure_info_logging = ensure_basic_logging(level=logging.INFO)\n\n    # Predefined decorator for stderr/DEBUG logging\n    ensure_debug_logging = ensure_basic_logging(level=logging.DEBUG)\n\n\n### Fine-grained logging set up\n\nIf a logging setup in `logging.basicConfig()` style is not flexible enough,\nyou can also inject your custom setup code with the `on_first_time` decorator.\nThis decorator is not limited to logging setup, it just expects\na callable (that can be called without arguments). A very simple example:\n\n\n    @epsel.on_first_time(lambda: print(\"hello world\"))\n    def process(x):\n        ....\n\nThis will print \"hello world\" the first time the `process` function is \ncalled in each executor.\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/soxofaan/epsel",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "epsel",
    "package_url": "https://pypi.org/project/epsel/",
    "platform": "",
    "project_url": "https://pypi.org/project/epsel/",
    "project_urls": {
      "Homepage": "https://github.com/soxofaan/epsel"
    },
    "release_url": "https://pypi.org/project/epsel/1.0.0/",
    "requires_dist": [
      "pytest ; extra == 'dev'",
      "pyspark ; extra == 'dev'"
    ],
    "requires_python": ">=3.5",
    "summary": "Ensure PySpark Executor Logging",
    "version": "1.0.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8599675,
  "releases": {
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b08c86bb8907195d543a3a425938a69ac346e4f5eedb1ba349206aa130cbc3bb",
          "md5": "56c20a6f580633084cc69748efa68da7",
          "sha256": "5aade169fd537041ad020f7d7141e22babf7b49580278a43affa45878d512e8c"
        },
        "downloads": -1,
        "filename": "epsel-1.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "56c20a6f580633084cc69748efa68da7",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.5",
        "size": 4766,
        "upload_time": "2020-11-04T14:29:40",
        "upload_time_iso_8601": "2020-11-04T14:29:40.322778Z",
        "url": "https://files.pythonhosted.org/packages/b0/8c/86bb8907195d543a3a425938a69ac346e4f5eedb1ba349206aa130cbc3bb/epsel-1.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "b08c86bb8907195d543a3a425938a69ac346e4f5eedb1ba349206aa130cbc3bb",
        "md5": "56c20a6f580633084cc69748efa68da7",
        "sha256": "5aade169fd537041ad020f7d7141e22babf7b49580278a43affa45878d512e8c"
      },
      "downloads": -1,
      "filename": "epsel-1.0.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "56c20a6f580633084cc69748efa68da7",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.5",
      "size": 4766,
      "upload_time": "2020-11-04T14:29:40",
      "upload_time_iso_8601": "2020-11-04T14:29:40.322778Z",
      "url": "https://files.pythonhosted.org/packages/b0/8c/86bb8907195d543a3a425938a69ac346e4f5eedb1ba349206aa130cbc3bb/epsel-1.0.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}