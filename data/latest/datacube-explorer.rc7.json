{
  "info": {
    "author": "Geoscience Australia",
    "author_email": "earth.observation@ga.gov.au",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9"
    ],
    "description": "# Data Cube Explorer\n[![Linting](https://github.com/opendatacube/datacube-explorer/workflows/Linting/badge.svg)](https://github.com/opendatacube/datacube-explorer/actions?query=workflow%3ALinting)\n[![Tests](https://github.com/opendatacube/datacube-explorer/workflows/Tests/badge.svg)](https://github.com/opendatacube/datacube-explorer/actions?query=workflow%3ATests)\n[![Docker](https://github.com/opendatacube/datacube-explorer/workflows/Docker/badge.svg)](https://github.com/opendatacube/datacube-explorer/actions?query=workflow%3ADocker)\n[![Scan](https://github.com/opendatacube/datacube-explorer/workflows/Scan/badge.svg)](https://github.com/opendatacube/datacube-explorer/actions?query=workflow%3AScan)\n[![coverage](https://codecov.io/gh/opendatacube/datacube-explorer/branch/develop/graph/badge.svg)](https://codecov.io/gh/opendatacube/datacube-explorer)\n[![Doc](https://readthedocs.org/projects/datacube-explorer/badge/?version=latest)](http://datacube-explorer.readthedocs.org/en/latest/)\n\n![Explorer Screenshot](screenshot.png)\n\n## Usage (quick-start)\n\nAssuming you already have an Open Data Cube instance, Explorer will use\nits existing settings.\n\nInstall Explorer:\n\n    pip install datacube-explorer\n\nGenerate summaries for all of your products:\n\n    cubedash-gen --init --all\n\nRun Explorer locally:\n\n    cubedash-run\n\nIt will now be viewable on [http://localhost:8090](https://localhost:8090)\n\n## Developer Setup\n\nThese directions are for running from a local folder in development. But it will run from any typical Python WSGI server.\n\nFirstly, install the Open Data Cube. Use of a [Data Cube conda environment](https://datacube-core.readthedocs.io/en/latest/installation/setup/common_install.html)\nis recommended. You may need to also `conda install -c conda-forge postgis`\n\nTest that you can run `datacube system check`, and that it's connecting\nto the correct datacube instance.\n\n### Dependencies\n\nNow install the explorer dependencies:\n\n    # These two should come from conda if you're using it, not pypi\n    conda install fiona shapely\n\n    pip install -e .\n\n### Summary generation\n\nInitialise and create product summaries:\n\n    cubedash-gen --init --all\n\n(This can take a long time the first time, depending on your datacube size.)\n\nOther available options can be seen by running `cubedash-gen --help`.\n\n### Run\n\nA `cubedash-run` command is available to run Explorer locally:\n\n    $ cubedash-run\n        * Running on http://localhost:8080/ (Press CTRL+C to quit)\n\n(see `cubedash-run --help` for list of options)\n\nBut Explorer can be run using any typical Python WSGI server, for example [gunicorn](https://gunicorn.org/):\n\n    pip install gunicorn\n    gunicorn -b '127.0.0.1:8080' -w 4 cubedash:app\n\nProducts will begin appearing one-by-one as the summaries are generated in the\nbackground.  If impatient, you can manually navigate to a product using\n`/<product_name`. (Eg `/ls5_nbar_albers`)\n\n### Code Style\n\nAll code is formatted using [black](https://github.com/ambv/black), and checked\nwith [pyflakes](https://github.com/PyCQA/pyflakes).\n\nThey are included when installing the test dependencies:\n\n    pip install --upgrade --no-deps --extra-index-url https://packages.dea.ga.gov.au/ 'datacube' 'digitalearthau'\n\n    pip install -e .[test]\n\nRun `make lint` to check your changes, and `make format` to format your code\nautomatically.\n\nYou may want to configure your editor to run black automatically on file save\n(see the Black page for directions), or install the pre-commit hook within Git:\n\n### Pre-commit setup\n\nA [pre-commit](https://pre-commit.com/) config is provided to automatically format\nand check your code changes. This allows you to immediately catch and fix\nissues before you raise a failing pull request (which run the same checks under\nTravis).\n\nInstall pre-commit from pip, and initialise it in your repo:\n\n    pip install pre-commit\n    pre-commit install\n\nYour code will now be formatted and validated before each commit. You can also\ninvoke it manually by running `pre-commit run`\n\n**Note**: If you use Conda, install from conda-forge (This is *required* because the pip\nversion uses virtualenvs which are incompatible with Conda's environments)\n\n    conda install pre_commit\n\n## FAQ\n\n\n### Can I use a different datacube environment?\n\nSet ODC's environment variable before running the server:\n\n    export DATACUBE_ENVIRONMENT=staging\n\nYou can always see which environment/settings will be used by running `datacube system check`.\n\nSee the ODC documentation for config and [datacube environments](https://datacube-core.readthedocs.io/en/latest/user/config.html#runtime-config)\n\n### Can I add custom scripts or text to the page (such as analytics)?\n\nCreate one of the following `*.env.html` files:\n\n- Global include: for `<script>` and other tags at the bottom of every page.\n\n      cubedash/templates/include-global.env.html\n\n- Footer text include. For human text such as Copyright statements.\n\n      echo \"Server <strong>staging-1.test</strong>\" > cubedash/templates/include-footer.env.html\n\n(`*.env.html` is the naming convention used for environment-specific templates: they are ignored by\nGit)\n\n### How can I configure the deployment?\n\nAdd a file to the current directory called `settings.env.py`\n\nYou can alter default [Flask](http://flask.pocoo.org/docs/1.0/config/) or\n[Flask Cache](https://pythonhosted.org/Flask-Caching/#configuring-flask-caching) settings\n(default \"CACHE_TYPE: NullCache\"), as well as some cubedash-specific settings:\n\n    # Default product to display (picks first available)\n    CUBEDASH_DEFAULT_PRODUCTS = ('ls8_nbar_albers', 'ls7_nbar_albers')\n\n    # Optional title for this Explorer instance to put at the top of every page.\n    # Eg. \"NCI\"\n    # If the STAC_ENDPOINT_TITLE is set (below), it will be the default for this value.\n    CUBEDASH_INSTANCE_TITLE = None\n\n    # Specify product grouping in the top menu.\n    # Expects a series of `(regex, group_label)` pairs. Each product will be grouped into the first regexp that matches\n    # anywhere in its name. Unmatched products have their own group see CUBEDASH_DEFAULT_GROUP_NAME, group names shouldn't\n    include the default name.\n    # eg \"(('^usgs_','USGS products'), ('_albers$','C2 Albers products'), ('level1','Level 1 products'), )\"\n    CUBEDASH_PRODUCT_GROUP_BY_REGEX = None\n    # CUBEDASH_PRODUCT_GROUP_BY_REGEX = (r'^usgs_','USGS products'), (r'_albers$','C2 Albers products'), (r'level1','Level 1 products'), )\n    # Otherwise, group by a single metadata field in the products:\n    CUBEDASH_PRODUCT_GROUP_BY_FIELD = 'product_type'\n    # Ungrouped products will be grouped together in this size.\n    CUBEDASH_PRODUCT_GROUP_SIZE = 5\n    # Ungrouped products will be grouped together using this name\n    CUBEDASH_DEFAULT_GROUP_NAME = 'Other Products'\n    # Maximum search results\n    CUBEDASH_HARD_SEARCH_LIMIT = 100\n    # Dataset records returned by '/api'\n    CUBEDASH_DEFAULT_API_LIMIT = 500\n    CUBEDASH_HARD_API_LIMIT = 4000\n    # Maximum number of source/derived datasets to show\n    CUBEDASH_PROVENANCE_DISPLAY_LIMIT = 20\n\n    CUBEDASH_DEFAULT_TIMEZONE = \"Australia/Darwin\"\n\n    CUBEDASH_SISTER_SITES = None\n    # CUBEDASH_SISTER_SITES = (('Production - ODC', 'http://prod.odc.example'), ('Production - NCI', 'http://nci.odc.example'), )\n\n    CUBEDASH_HIDE_PRODUCTS_BY_NAME_LIST = None\n    # CUBEDASH_HIDE_PRODUCTS_BY_NAME_LIST = [\n    #    \"ls5_pq_scene\",\n    #    \"ls7_pq_scene\",\n    # ]\n\n    # How many days of recent datasets to show on the \"/arrivals\" page?\n    CUBEDASH_DEFAULT_ARRIVALS_DAY_COUNT = 14\n\n    # Include load performance metrics in http response.\n    CUBEDASH_SHOW_PERF_TIMES = False\n\n    # Which theme to use (in the cubedash/themes folder)\n    CUBEDASH_THEME = 'odc'\n\n    # The default license to show for products that don't have one.\n    #     license is optional, but the stac API collections will not pass validation if it's null)\n    #     Either a SPDX License identifier, 'various' or 'proprietary'\n    #     Example value: \"CC-BY-SA-4.0\"\n    CUBEDASH_DEFAULT_LICENSE = None\n\n    # Customise '/stac' endpoint information\n    STAC_ENDPOINT_ID = 'my-odc-explorer'\n    STAC_ENDPOINT_TITLE = 'My ODC Explorer'\n    STAC_ENDPOINT_DESCRIPTION = 'Optional Longer description of this endpoint'\n\n    STAC_DEFAULT_PAGE_SIZE = 20\n    STAC_PAGE_SIZE_LIMIT = 1000\n\n    # Should search results include the full properties of every Stac Item by default?\n    # Full searches are much slower because they use ODC's own raw metadata table.\n    # (Users can append \"_full=true\" to requests to manually ask for full metadata.\n    #  Or preferrably, follow the `self` link of the Item record to get the whole record)\n    STAC_DEFAULT_FULL_ITEM_INFORMATION = True\n\n    # If you'd like S3 URIs to be transformed to HTTPS links then\n    # set this to a valid AWS region string. Otherwise set it to None to not do this.\n    CUBEDASH_DATA_S3_REGION = \"ap-southeast-2\"\n\n    # Default map view when no data is loaded.\n    # The default values will depend on the CUBEDASH_THEME (eg. 'africa' theme defults to Africa)\n    default_map_zoom = 3\n    default_map_center = [-26.2756326, 134.9387844]\n\n    # S3 buckets for which data browser url should be returned\n    SHOW_DATA_LOCATION = { \"dea-public-data\": \"data.dea.ga.gov.au\" }\n\n[Sentry](https://sentry.io/) error reporting is supported by adding a `SENTRY_CONFIG` section.\nSee [their documentation](https://docs.sentry.io/clients/python/integrations/flask/#settings).\n\n### How do I modify the CSS/Javascript?\n\nThe CSS is compiled from [Sass](https://sass-lang.com/), and the Javascript is compiled from\n[Typescript](https://www.typescriptlang.org/).\n\nInstall [npm](https://www.npmjs.com/get-npm), and then install them both:\n\n    npm install -g sass typescript\n\nYou can now run `make static` to rebuild all the static files, or\nindividually with `make style` or `make js`.\n\nAlternatively, if using [PyCharm](https://www.jetbrains.com/pycharm), open a\nSass file and you will be prompted to enable a `File Watcher` to\ncompile automatically.\n\nPyCharm will also compile the Typescript automatically by ticking\nthe \"Recompile on changes\" option in `Languages & Frameworks ->\nTypescript`.\n\n### How do I run the integration tests?\n\nThe integration tests run against a real PostgreSQL database, which is\nautomatically started and stopped using Docker. This requires Docker to\nbe available, but no further database setup is required.\n\nInstall the test dependencies: `pip install -e .[test]`\n\nThe run the tests with: `pytest integration_tests`\n\n### How do I add test data for the automated tests?\n\nMost of the automated tests for Datacube Explorer require sample data to run. This comprises\ndefinitions of ODC *Metadata Types*, *Products* and *Datasets*.\n\nThese are contained within YAML files in the [`integration_tests/data`](https://github.com/opendatacube/datacube-explorer/tree/develop/integration_tests/data) directory.\n\nTest data is loaded using a pytest fixture called `auto_odc_db`, which is activated per\ntest module, and will automatically populate the database using files referenced in module\nglobal variables. Activate and use it similar to the following example:\n\n\n    pytestmark = pytest.mark.usefixtures(\"auto_odc_db\")\n\n    METADATA_TYPES = [\"metadata/qga_eo.yaml\"]\n    PRODUCTS = [\"products/ga_s2_ard.odc-product.yaml\"]\n    DATASETS = [\"s2a_ard_granule.yaml.gz\"]\n\n\nTo add sample datasets required for the test case, create a `.yaml` file\nwith the product name and place all the sample datasets split by `---` in the yaml.\n\nIf the sample datasets file is large, compress it with `gzip <dataset_file>.yaml` and reference\nthat file instead.\n\n## Roles for production deployments\n\nThe [roles](cubedash/summary/roles) directory contains sql files for creating\nPostgres roles for Explorer. These are suitable for running each Explorer\ntask with minimum needed security permissions.\n\nThree roles are created:\n\n- **explorer-viewer**: A read-only user of datacube and Explorer. Suitable for the web interface and cli (`cubedash-view`) commands.\n- **explorer-generator**: Suitable for generating and updating summaries (ie. Running `cubedash-gen`)\n- **explorer-owner**: For creating and updating the schema. (ie. Running `cubedash-gen --init`)\n\nNote that these roles extend the built-in datacube role `agdc_user`. If you\ncreated your datacube without permissions, a stand-alone creator of the `agdc_user`\nrole is available as a prerequisite in the same [roles](cubedash/summary/roles)\ndirectory.\n\n## Docker for Development and running tests\n\nYou need to have Docker and Docker Compose installed on your system.\n\nTo create your environment, run `make up` or `docker-compose up`.\n\nYou need an ODC database, so you'll need to refer to the [ODC docs](https://datacube-core.readthedocs.io/en/latest/) for help on indexing, but you can create the database by running `make initdb` or `docker-compose exec explorer datacube system init`. (This is not enough, you still need to add a product and index datasets.)\n\nWhen you have some ODC data indexed, you can run `make index` to create the Explorer indexes.\n\nOnce Explorer indexes have been created, you can browse the running application at [http://localhost:5000](http://localhost:5000).\n\nYou can run tests by first creating a test database `make create-test-db-docker` and then running tests with `make test-docker`.\n\nAnd you can run a single test in Docker using a command like this: `docker-compose --file docker-compose.yml run explorer pytest integration_tests/test_dataset_listing.py`\n\n\n## Docker-compose for Development and running tests\n### Testing with app.config\nedit `.docker/settings_docker.py` and setup application config. Then `docker-compose -f docker-compose.yml -f docker-compose.override.yml up` to bring up explorer docker with database, explorer with settings\n\n\n## STAC API Extensions\n\nThe STAC endpoint implements the [query](https://github.com/stac-api-extensions/query), [filter](https://github.com/stac-api-extensions/filter), [fields](https://github.com/stac-api-extensions/fields), and [sort](https://github.com/stac-api-extensions/sort) extensions, all of which are bound to the `search` endpoint as used with POST requests, with fields and sort additionally bound to the features endpoint.\n\nFields contained in the item properties must be prefixed with `properties.`, ex `properties.dea:dataset_maturity`.\n\nThe implementation of `fields` differs somewhat from the suggested include/exclude semantics in that it does not permit for invalid STAC entities, so the `id`, `type`, `geometry`, `bbox`, `links`, `assets`, `properties.datetime`, and `stac_version` fields will always be included, regardless of user input.\n\nThe implementation of `filter` is limited, and currently only supports CQL2 JSON syntax with the following basic CQL2 operators: `AND`, `OR`, `=`, `>`, `>=`, `<`, `<=`, `<>`, `IS NULL`.\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/opendatacube/datacube-explorer",
    "keywords": "",
    "license": "Apache Software License 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "datacube-explorer",
    "package_url": "https://pypi.org/project/datacube-explorer/",
    "platform": null,
    "project_url": "https://pypi.org/project/datacube-explorer/",
    "project_urls": {
      "Bug Reports": "https://github.com/opendatacube/datacube-explorer/issues",
      "Homepage": "https://github.com/opendatacube/datacube-explorer",
      "Source": "https://github.com/opendatacube/datacube-explorer"
    },
    "release_url": "https://pypi.org/project/datacube-explorer/2.10.0/",
    "requires_dist": [
      "cachetools",
      "click",
      "datacube (>=1.8.10)",
      "eodatasets3 (>=0.25.0)",
      "fiona",
      "flask (==2.1.3)",
      "Flask-Caching",
      "flask-cors",
      "flask-themer (>=1.4.3)",
      "geoalchemy2 (>=0.8)",
      "geographiclib",
      "jinja2",
      "markupsafe",
      "pyorbital",
      "pyproj",
      "pystac",
      "python-dateutil",
      "orjson (>=3)",
      "sentry-sdk[flask]",
      "shapely",
      "simplekml",
      "sqlalchemy (>=1.4)",
      "structlog (>=20.2.0)",
      "pytz",
      "ciso8601 ; extra == 'deployment'",
      "bottleneck ; extra == 'deployment'",
      "gunicorn ; extra == 'deployment'",
      "setproctitle ; extra == 'deployment'",
      "gevent ; extra == 'deployment'",
      "blinker ; extra == 'deployment'",
      "prometheus-flask-exporter ; extra == 'deployment'",
      "black ; extra == 'test'",
      "docutils ; extra == 'test'",
      "boltons ; extra == 'test'",
      "deepdiff ; extra == 'test'",
      "flake8 ; extra == 'test'",
      "jsonschema (>3) ; extra == 'test'",
      "pre-commit ; extra == 'test'",
      "pytest ; extra == 'test'",
      "pytest-benchmark ; extra == 'test'",
      "requests-html ; extra == 'test'",
      "blinker ; extra == 'test'",
      "prometheus-flask-exporter ; extra == 'test'",
      "sphinx-click ; extra == 'test'",
      "docker ; extra == 'test'",
      "ciso8601 ; extra == 'test'",
      "bottleneck ; extra == 'test'",
      "gunicorn ; extra == 'test'",
      "setproctitle ; extra == 'test'",
      "gevent ; extra == 'test'"
    ],
    "requires_python": ">=3.7",
    "summary": "Web-based exploration of Open Data Cube collections",
    "version": "2.10.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16742039,
  "releases": {
    "2.10.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "576214a24571f65cc837b47802d2556f979fbe41f0cb3a3b2ae068ee3f7b05ba",
          "md5": "6482f2f07703340b363332be422b5324",
          "sha256": "aedd7868ce5cf3277b450b7eb3613341dcb3ed6e782067dde1c9e84e2b3d907a"
        },
        "downloads": -1,
        "filename": "datacube_explorer-2.10.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "6482f2f07703340b363332be422b5324",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 12655656,
        "upload_time": "2023-02-08T04:52:33",
        "upload_time_iso_8601": "2023-02-08T04:52:33.413681Z",
        "url": "https://files.pythonhosted.org/packages/57/62/14a24571f65cc837b47802d2556f979fbe41f0cb3a3b2ae068ee3f7b05ba/datacube_explorer-2.10.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "beed0eddd4a0c95e7bf50bfe00c135dd2bbf54d552182a44fcb4bbad18b598e3",
          "md5": "5f13b31ca6da09755a7b89da334035d7",
          "sha256": "03db4d1244ee70db385210d041c87e06cac5e6b4045a7910196f2d65b3572d5a"
        },
        "downloads": -1,
        "filename": "datacube-explorer-2.10.0.tar.gz",
        "has_sig": false,
        "md5_digest": "5f13b31ca6da09755a7b89da334035d7",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 21983649,
        "upload_time": "2023-02-08T04:52:36",
        "upload_time_iso_8601": "2023-02-08T04:52:36.590014Z",
        "url": "https://files.pythonhosted.org/packages/be/ed/0eddd4a0c95e7bf50bfe00c135dd2bbf54d552182a44fcb4bbad18b598e3/datacube-explorer-2.10.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "2.6.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "73fdd1655b28860fe82fdc2dba026d3eff504fa952bb26a8ce37ad354920d856",
          "md5": "0ee702196093b020d36f548ab381d7d6",
          "sha256": "e016feec4897d65d55617d61588fbc72cca456573751e0549e45c26010fe3d1a"
        },
        "downloads": -1,
        "filename": "datacube_explorer-2.6.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0ee702196093b020d36f548ab381d7d6",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 12521306,
        "upload_time": "2021-09-14T06:41:21",
        "upload_time_iso_8601": "2021-09-14T06:41:21.402988Z",
        "url": "https://files.pythonhosted.org/packages/73/fd/d1655b28860fe82fdc2dba026d3eff504fa952bb26a8ce37ad354920d856/datacube_explorer-2.6.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "73c4ef692ed8d154da20f34ee1d25327ff6d9b1183ce0410eed85e3922c4e3a2",
          "md5": "81a4b1d07825af5936658111abb43ad8",
          "sha256": "a808f948f56b9552808ec6c642f57783a29cb0bc98567d3731a6ccfa77a7f085"
        },
        "downloads": -1,
        "filename": "datacube-explorer-2.6.0.tar.gz",
        "has_sig": false,
        "md5_digest": "81a4b1d07825af5936658111abb43ad8",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 21735062,
        "upload_time": "2021-09-14T06:41:38",
        "upload_time_iso_8601": "2021-09-14T06:41:38.383542Z",
        "url": "https://files.pythonhosted.org/packages/73/c4/ef692ed8d154da20f34ee1d25327ff6d9b1183ce0410eed85e3922c4e3a2/datacube-explorer-2.6.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "2.6.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "993b782ed4c6b756619908a134ffe7eec36d5096e7a857a077904c00ac990c5e",
          "md5": "666fbba6c948ebffb329aa7db35f6235",
          "sha256": "923d0cea56c4f9d0d6307ad6930a6213fcc99d699a5bfc2dc444e3b38e053489"
        },
        "downloads": -1,
        "filename": "datacube_explorer-2.6.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "666fbba6c948ebffb329aa7db35f6235",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 12521120,
        "upload_time": "2021-09-20T02:59:47",
        "upload_time_iso_8601": "2021-09-20T02:59:47.692359Z",
        "url": "https://files.pythonhosted.org/packages/99/3b/782ed4c6b756619908a134ffe7eec36d5096e7a857a077904c00ac990c5e/datacube_explorer-2.6.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "256e077be517105bf13c85b5e195c0d0741ab7854ec593653bff57ee1fc0e16e",
          "md5": "9b9ffac49a3d9ef61b4de3bb38555e5a",
          "sha256": "7e89490be656b304a08eb1f28ba7b17f98c3716625175a1be8dae5c248cb7d9f"
        },
        "downloads": -1,
        "filename": "datacube-explorer-2.6.1.tar.gz",
        "has_sig": false,
        "md5_digest": "9b9ffac49a3d9ef61b4de3bb38555e5a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 21734971,
        "upload_time": "2021-09-20T03:00:00",
        "upload_time_iso_8601": "2021-09-20T03:00:00.119739Z",
        "url": "https://files.pythonhosted.org/packages/25/6e/077be517105bf13c85b5e195c0d0741ab7854ec593653bff57ee1fc0e16e/datacube-explorer-2.6.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "2.7.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "435f23c37c21d2066bc7a7f53105472d39e659780922dac2a888e66ebb7a2791",
          "md5": "57bf3190a3fb7ba81ce4b0b7dcd4df52",
          "sha256": "61d98584b2dfa38f9b58422f7ca1c5a9bf0171410915d3281681c64b3f6cda1f"
        },
        "downloads": -1,
        "filename": "datacube_explorer-2.7.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "57bf3190a3fb7ba81ce4b0b7dcd4df52",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 12543824,
        "upload_time": "2021-10-14T22:42:50",
        "upload_time_iso_8601": "2021-10-14T22:42:50.565357Z",
        "url": "https://files.pythonhosted.org/packages/43/5f/23c37c21d2066bc7a7f53105472d39e659780922dac2a888e66ebb7a2791/datacube_explorer-2.7.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "63aa40b5d15d6a7123f2f2b1e5d442a9641bf4a4f60058ceb16de7dce5163a74",
          "md5": "54c068921990b3215a760cc0b5dc01e8",
          "sha256": "00b859f433cf7d4da85e15e2f5876ec2aca1d978f5c18f083239ea2c38135781"
        },
        "downloads": -1,
        "filename": "datacube-explorer-2.7.0.tar.gz",
        "has_sig": false,
        "md5_digest": "54c068921990b3215a760cc0b5dc01e8",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 21758498,
        "upload_time": "2021-10-14T22:43:27",
        "upload_time_iso_8601": "2021-10-14T22:43:27.012889Z",
        "url": "https://files.pythonhosted.org/packages/63/aa/40b5d15d6a7123f2f2b1e5d442a9641bf4a4f60058ceb16de7dce5163a74/datacube-explorer-2.7.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "2.7.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8bfc6928f6c3d37f03659861792f53ccc8ce7004d29c887b0309417f58421313",
          "md5": "926aec823fba53ba9023de95c9cb3dca",
          "sha256": "53385a3eda04808ca1d2034de9817c14ac57cffbd1d66ec144752bd95596f366"
        },
        "downloads": -1,
        "filename": "datacube_explorer-2.7.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "926aec823fba53ba9023de95c9cb3dca",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 12543843,
        "upload_time": "2021-11-10T23:15:15",
        "upload_time_iso_8601": "2021-11-10T23:15:15.688093Z",
        "url": "https://files.pythonhosted.org/packages/8b/fc/6928f6c3d37f03659861792f53ccc8ce7004d29c887b0309417f58421313/datacube_explorer-2.7.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "de022323eb202d8a2b5b5056ff87cbfa11e7b06daa5def6cd079d1d4dc28b29f",
          "md5": "eabac9e1ee24f5001b81b93ce88162e8",
          "sha256": "1257fb525d992cdc28ac6ee552947b2b85b07809437fc1c81396c0ce1eb3b7c1"
        },
        "downloads": -1,
        "filename": "datacube-explorer-2.7.1.tar.gz",
        "has_sig": false,
        "md5_digest": "eabac9e1ee24f5001b81b93ce88162e8",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 21758633,
        "upload_time": "2021-11-10T23:15:29",
        "upload_time_iso_8601": "2021-11-10T23:15:29.071850Z",
        "url": "https://files.pythonhosted.org/packages/de/02/2323eb202d8a2b5b5056ff87cbfa11e7b06daa5def6cd079d1d4dc28b29f/datacube-explorer-2.7.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "2.8.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "23d9fd5456f3738a13bc85b566efb9a5f5b34e0f6392d9d86e6f695edc2c36a7",
          "md5": "122430ed340fc7a300daf4666a3b2aa0",
          "sha256": "d1ea6030eef83587f9a379f097d6bca3262654675b9f4735e920691c59b0b4f9"
        },
        "downloads": -1,
        "filename": "datacube_explorer-2.8.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "122430ed340fc7a300daf4666a3b2aa0",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 12820866,
        "upload_time": "2021-12-06T23:56:05",
        "upload_time_iso_8601": "2021-12-06T23:56:05.233673Z",
        "url": "https://files.pythonhosted.org/packages/23/d9/fd5456f3738a13bc85b566efb9a5f5b34e0f6392d9d86e6f695edc2c36a7/datacube_explorer-2.8.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0a699f622b9e5c48f5c7c61c91032211b0c5a448327a5503be2bd180c7804738",
          "md5": "80d3583fe0aeef0d2b86de0c7239f710",
          "sha256": "14a40a5d7a5dc4913ad3f08d5bf793badd61d826af882a6b0fcf481bacf6a901"
        },
        "downloads": -1,
        "filename": "datacube-explorer-2.8.0.tar.gz",
        "has_sig": false,
        "md5_digest": "80d3583fe0aeef0d2b86de0c7239f710",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 22019154,
        "upload_time": "2021-12-07T00:24:09",
        "upload_time_iso_8601": "2021-12-07T00:24:09.190960Z",
        "url": "https://files.pythonhosted.org/packages/0a/69/9f622b9e5c48f5c7c61c91032211b0c5a448327a5503be2bd180c7804738/datacube-explorer-2.8.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "2.8.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f97b5f9a6af953a4df1d9fd2a6a00397f87b9ceb8e81b1a27790e9b74654e386",
          "md5": "7dc13a97e1889d09ea3aa5e6ba5fbbf7",
          "sha256": "e277ddb4524bb210445547178e743cf88a5c4139b66ff87822d6cf4d48a85be2"
        },
        "downloads": -1,
        "filename": "datacube_explorer-2.8.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "7dc13a97e1889d09ea3aa5e6ba5fbbf7",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 12821316,
        "upload_time": "2021-12-08T07:05:21",
        "upload_time_iso_8601": "2021-12-08T07:05:21.896902Z",
        "url": "https://files.pythonhosted.org/packages/f9/7b/5f9a6af953a4df1d9fd2a6a00397f87b9ceb8e81b1a27790e9b74654e386/datacube_explorer-2.8.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c9dc55ea06ba8fa6f5a0f9ebce8b6a38d890313dcecae3e2cf919c6b1fa8d771",
          "md5": "0022dc77392afeb00f898880ae47482c",
          "sha256": "78585082ef1972c3e1b8b08706b81c63fc908ac8a8d847e82b2726ac158363d8"
        },
        "downloads": -1,
        "filename": "datacube-explorer-2.8.1.tar.gz",
        "has_sig": false,
        "md5_digest": "0022dc77392afeb00f898880ae47482c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 22020081,
        "upload_time": "2021-12-08T07:05:41",
        "upload_time_iso_8601": "2021-12-08T07:05:41.939507Z",
        "url": "https://files.pythonhosted.org/packages/c9/dc/55ea06ba8fa6f5a0f9ebce8b6a38d890313dcecae3e2cf919c6b1fa8d771/datacube-explorer-2.8.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "576214a24571f65cc837b47802d2556f979fbe41f0cb3a3b2ae068ee3f7b05ba",
        "md5": "6482f2f07703340b363332be422b5324",
        "sha256": "aedd7868ce5cf3277b450b7eb3613341dcb3ed6e782067dde1c9e84e2b3d907a"
      },
      "downloads": -1,
      "filename": "datacube_explorer-2.10.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "6482f2f07703340b363332be422b5324",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 12655656,
      "upload_time": "2023-02-08T04:52:33",
      "upload_time_iso_8601": "2023-02-08T04:52:33.413681Z",
      "url": "https://files.pythonhosted.org/packages/57/62/14a24571f65cc837b47802d2556f979fbe41f0cb3a3b2ae068ee3f7b05ba/datacube_explorer-2.10.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "beed0eddd4a0c95e7bf50bfe00c135dd2bbf54d552182a44fcb4bbad18b598e3",
        "md5": "5f13b31ca6da09755a7b89da334035d7",
        "sha256": "03db4d1244ee70db385210d041c87e06cac5e6b4045a7910196f2d65b3572d5a"
      },
      "downloads": -1,
      "filename": "datacube-explorer-2.10.0.tar.gz",
      "has_sig": false,
      "md5_digest": "5f13b31ca6da09755a7b89da334035d7",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 21983649,
      "upload_time": "2023-02-08T04:52:36",
      "upload_time_iso_8601": "2023-02-08T04:52:36.590014Z",
      "url": "https://files.pythonhosted.org/packages/be/ed/0eddd4a0c95e7bf50bfe00c135dd2bbf54d552182a44fcb4bbad18b598e3/datacube-explorer-2.10.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}