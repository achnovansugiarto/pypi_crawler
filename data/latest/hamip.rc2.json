{
  "info": {
    "author": "Jin Li",
    "author_email": "lijin.abc@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Programming Language :: Python :: 3"
    ],
    "description": "# HaMiP: DNA hydroxymethylation analysis of Cytosine-5-methylenesulfonate ImmunoPrecipitation sequencing\n\nA scalable, accurate, and efficient solution for hydroxymethylation analysis of CMS-IP sequencing data.\n\n![Workflow of HaMiP.](https://github.com/lijinbio/HaMiP/raw/master/HaMiP_flowchart.png)\n\n## Installation\n\nHaMiP has been deployed in Bioconda at https://anaconda.org/bioconda/HaMiP. It is encouraged to install HaMiP from Bioconda due to most runtime dependencies will be installed automatically. The following channels should be added in Conda. Namely,\n\n```\nconda config --add channels defaults\nconda config --add channels bioconda\nconda config --add channels conda-forge\nconda install HaMiP\n```\n\nAlternatively, HaMiP has been also deployed in PyPI at https://pypi.org/project/HaMiP, and it can be installed via `pip`.\n\n```\npip3 install HaMiP\n```\n\nIn some cases, users want to build HaMiP manually from source code at https://github.com/lijinbio/HaMiP. Below is an example installation steps.\n\n```\ngit clone https://github.com/lijinbio/HaMiP.git\ncd HaMiP\npython3 setup.py install\n```\n\nIn order to run HaMiP after a manual installation, the following dependent software are required.\n\n| Software | URL |\n|-------|-------|\n| Python 3 | https://www.python.org |\n| Matplotlib | https://matplotlib.org |\n| PyYAML | https://pyyaml.org |\n| bedtools | https://bedtools.readthedocs.io |\n| fetchChromSizes | http://hgdownload.cse.ucsc.edu/admin/exe/ |\n| R software | https://www.r-project.org |\n| R package DESeq2 | https://bioconductor.org/packages/release/bioc/html/DESeq2.html |\n| R package genefilter | https://bioconductor.org/packages/release/bioc/html/genefilter.html |\n| R package DescTools | https://cran.r-project.org/web/packages/DescTools/index.html |\n| Gawk | https://www.gnu.org/software/gawk |\n| MOABS | https://github.com/sunnyisgalaxy/moabs |\n\n## Documentation\n\nHaMiP takes in a configuration file for input data and program parameters. HaMiP can be run end-to-end, starting from raw FASTQ files to peak calling and differential hydroxymethylation identification. One can also start the pipeline from intermediate steps. For example, using alignment files as input so that mapping steps will be skipped.\n\n### Inspection of configuration\n\nThe configuration file is in a YAML format. Two example templates are `config_fastq.yaml` and `config_bam.yaml` under https://github.com/lijinbio/HaMiP/blob/master/config. `config_fastq.yaml` is used as a full HaMiP running from FASTQ inputs, while `config_bam.yaml` is adapted to input existing BAM files so that HaMiP will skip the long-time alignment step. The inspection of configuration is explained below.\n\n1. sampleinfo\n\nThe sampleinfo section defines metadata information in analysis. Below metadata information can be specified.\n\n| Parameter | Description |\n|-------|-------|\n| sampleinfo.sampleid | the unique identifier to one sample |\n| sampleinfo.group | the biological group of the sample, e.g., KO or WT |\n| sampleinfo.filenames | the absolute path of raw FASTQ files |\n| sampleinfo.reference | the absolute path of the reference BAM file when `aligninfo.inputbam` is True |\n| sampleinfo.spikein | the absolute path of the spike-in BAM file when `aligninfo.inputbam` and `aligninfo.usespikein` are True |\n\n 2. groupinfo\n\nThis section defines biological comparison `group1` - `group2`, e.g., KO - WT.\n\n| Parameter | Description |\n|-------|-------|\n| groupinfo.group1 | the first group in biological comparison |\n| groupinfo.group2 | the second group in biological comparison |\n\n3. resultdir\n\nThis directory is default working directory storing intemediate result files, such as BAM and BED files.\n\n4. aligninfo\n\nThis section specifies parameters used in raw reads alignment.\n\n| Parameter | Description |\n|-------|-------|\n| aligninfo.inputbam | True for BAM inputs. Default: FASTQ inputs. |\n| aligninfo.reference | FASTA file of the reference genome, e.g. `hg38.fa`. |\n| aligninfo.usespikein | True for spike-in libraries, otherwise False. This option controls the normalization method, either a spike-in normalization using spike-in mapping, or reduced to WIG sum in the reference genome. |\n| aligninfo.spikein | FASTA file of the spike-in genome, e.g. `mm10.fa`. |\n| aligninfo.statfile | the output statistics file. This file includes quality control statistics as well as estimated normalization factors. |\n| aligninfo.barplotinfo | a barplot of normalized WIG sums of samples. |\n| aligninfo.numthreads | number of threads in alignment program. |\n| aligninfo.verbose | Print verbose message |\n\n5. genomescaninfo\n\nThis section defines parameters for CMS measurement construction.\n\n| Parameter | Description |\n|-------|-------|\n| genomescaninfo.readextension | True to extend reads length before CMS measurement construction. |\n| genomescaninfo.fragsize | the fixed fragment size to extend when readextension is True. |\n| genomescaninfo.windowfile | an intermediate window file with fixed-size genomic regions. |\n| genomescaninfo.referencename | the UCSC genome name to fetch reference genome size. E.g., hg38 or mm10. |\n| genomescaninfo.windowsize | the window size |\n| genomescaninfo.readscount | CMS measurement using read count (True) or mean WIG (False). |\n| genomescaninfo.counttablefile | the result count table file. |\n| genomescaninfo.verbose | Print verbose message |\n\n6. dhmrinfo\n\nParameters in this section is for DMR detection.\n\n| Parameter | Description |\n|-------|-------|\n| dhmrinfo.method | The statistical method used in DHMR detection. Available methods: `ttest`, `chisq`, `gtest`, `nbtest`, `nbtest_sf`. `ttest` is calling Student's t-test to examine the mean difference of CMS measurements between two biological groups. `chisq` and `gtest` are Pearsonâ€™s Chi-squared and G-test to test if sums of CMS measurements fit the numbers of replicates between two biological condtions. `nbtest` applies negative binomial generalized linear model to formulate CMS measurements, and Wald test evaluates the significance of logarithmic fold change. By default, CMS measurement are adjusted by size factors using spike-in normalization. In `nbtest_sf`, CMS measurements are normalized by the median-ratio algorithm (previously used in DESeq2 for transcriptome measurements). |\n| dhmrinfo.meandepth | Average depth to filter out low-depth windows. This step is essential to save computing resources and increase power of downstream statistical inference |\n| dhmrinfo.testfile | The result file with statistical outputs for whole genome windows |\n| dhmrinfo.qthr | q-value threshod for DHMW. |\n| dhmrinfo.maxdistance | Maximum distance to merge adjacent DHMWs into DHMRs |\n| dhmrinfo.dhmrfile | The final DHMR result file after merging adjacent DHMWs. |\n| dhmrinfo.numthreads | The number of threads. |\n| dhmrinfo.nsplit | The number of split of windows. This option controls parallelization with `dhmrinfo.numthreads`. |\n| dhmrinfo.verbose | Print verbose message. |\n| dhmrinfo.keepNA | Keep genome windows ruled out by independent filtering. |\n\n7. useinput\n\nTo indicate if the input data is used during CMS-IP sequencing.\n\n8. inputinfo\n\nIf `useinput` is True, this section is required to specify input data. When input data is used, peak windows are identified first by comparing CMS measurements between group 1/2 and their input data. Then, the union of peak windows are tested for DHMR between group 1 and group 2.\n\n| Parameter | Description |\n|-------|-------|\n| inputinfo.group1 | The label for the first group input data. |\n| inputinfo.group2 | The label for the second group input data. Group 1 and group 2 can share same set of input data. |\n| inputinfo.method | The statistical method used in peak calling. See `dhmrinfo.method`. |\n| inputinfo.qthr | q-value threshold for peak calling. |\n| inputinfo.testfile1 | Statistical test results for group 1 peaking calling. |\n| inputinfo.dhmrfile1 | Peak regions for group 1. |\n| inputinfo.testfile2 | Statistical test results for group 2 peaking calling. |\n| inputinfo.dhmrfile2 | Peak regions for group 2. |\n| inputinfo.inputfilterfile | Union of peak regions in group 1 and group 2. |\n| inputinfo.verbose | Print verbose message. |\n\n### A toy example using BAM inputs\n\nTo facilitate the running of HaMiP, a toy example is generated using existing BAM inputs. The example is accessible at https://github.com/lijinbio/HaMiP/blob/master/example. The `example` directory consists of running scripts and example BAM files. Below commands will generate the configuration file and run the example.\n\n```\n$ ./config.sh ## Generate config.yaml\n$ ./fasta.sh ## download the reference genome and the spike-in genome under ./fasta\n$ ./run.sh ## run the example\n```\n\n1. `config.sh`\n\nThis script will generate the running configuration file. The inspection of configuration file has been explained above. This example includes small BAM files for 2 KO and 2 WT samples, together with 3 input samples. Spike-in BAM files are also included for spike-in normalization. These BAM files are under the `./bamfile` directory. The `gtest` is used for peaking calling and DHMR detection.\n\n2. `fasta.sh`\n\nThis script is to download required FASTA file for reference genome and spike-in genome. These FASTA files are used in MCALL for bisulfite conversion ratio (BCR) estimation. FASTA files are downloaded into a local directory `./fasta`.\n\n3. `run.sh`\n\nThe simple command to run CMSIP:\n\n```\n$ HaMiP -c config.yaml\n```\n\nIntermediate and results files are stored under `./outdir`. The example quality control statistic file (e.g., `qcstats.txt`) is as below.\n\n| sample_id | total | unique_ref | ref/total | unique_spk | spk/total | comm | comm/total | comm/unique_ref | twss_spk | sizefactors | twss_ref | twss_ref_norm | bcr_ref | bcr_spk |\n|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|\n| T1 | 2328 | 2328 | 100.00% | 141 | 6.06% | 99 | 4.25% | 4.25% | 3053 | 0.52 | 171892 | 88620 | 0.022883 | 0.278465 |\n| T2 | 20414 | 20414 | 100.00% | 2780 | 13.62% | 2539 | 12.44% | 12.44% | 9522 | 0.17 | 704965 | 116532 | 0.033482 | 0.178238 |\n| W1 | 1588 | 1588 | 100.00% | 97 | 6.11% | 74 | 4.66% | 4.66% | 1786 | 0.88 | 118312 | 104268 | 0.043317 | 0.206362 |\n| W2 | 1182 | 1182 | 100.00% | 89 | 7.53% | 66 | 5.58% | 5.58% | 1574 | 1.00 | 85335 | 85335 | 0.034864 | 0.214435 |\n| I1 | 212 | 212 | 100.00% | 17 | 8.02% | 4 | 1.89% | 1.89% | 992 | 1.59 | 15984 | 25362 | 0.738502 | 0.811715 |\n| I2 | 150 | 150 | 100.00% | 14 | 9.33% | 1 | 0.67% | 0.67% | 1032 | 1.53 | 11586 | 17671 | 0.897633 | 0.994475 |\n| I3 | 52 | 52 | 100.00% | 9 | 17.31% | 0 | 0.00% | 0.00% | 356 | 4.42 | 2053 | 9077 | 0.910494 | 0.983871 |\n\nSpecifically, the `sizefactors` column is the size factors generated by spike-in normalization.\n\nThe example DHMR file is as below.\n\n| chrom | start | end | baseMean | lfc | statistic | pvalue | padj |\n|-------|-------|-------|-------|-------|-------|-------|-------|\n| chr4 | 105276100 | 105276400 | 95.88 | -0.8072375451 | 27.63702666 | 1.463503254e-07 | 2.048904555e-06 |\n| chr4 | 105272500 | 105272700 | 86.7175 | -0.837383035 | 19.45881901 | 1.027921214e-05 | 4.796965666e-05 |\n| chr4 | 105259600 | 105259800 | 42.4925 | -0.5320182773 | 5.682020984 | 0.01713961427 | 0.03999243329 |\n\nFor example, three hypo-DHMRs are identified in chr4 between group T and group W.\n\n## Contact\n\nMaintainer: Jin Li, lijin.abc@gmail.com.\nPI: De-Qiang Sun, sunnyisgalaxy@gmail.com.\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/lijinbio/HaMiP",
    "keywords": "",
    "license": "License :: OSI Approved :: MIT License",
    "maintainer": "",
    "maintainer_email": "",
    "name": "HaMiP",
    "package_url": "https://pypi.org/project/HaMiP/",
    "platform": "",
    "project_url": "https://pypi.org/project/HaMiP/",
    "project_urls": {
      "Homepage": "https://github.com/lijinbio/HaMiP"
    },
    "release_url": "https://pypi.org/project/HaMiP/0.0.3.2/",
    "requires_dist": [
      "pyyaml",
      "matplotlib-base",
      "pandas"
    ],
    "requires_python": ">=3.6",
    "summary": "",
    "version": "0.0.3.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8106860,
  "releases": {
    "0.0.3.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ccb8f3e672d3158783bea0640a03f076d4c0cd64b420ffd1e853ea3feb43edd8",
          "md5": "28a7ce680713e78f69692c77ac28d097",
          "sha256": "1001e165a9d5430f1dc2fa93032861d3ac79414d59c93998052ee81e4a583511"
        },
        "downloads": -1,
        "filename": "HaMiP-0.0.3.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "28a7ce680713e78f69692c77ac28d097",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 18093,
        "upload_time": "2020-09-03T20:35:01",
        "upload_time_iso_8601": "2020-09-03T20:35:01.740952Z",
        "url": "https://files.pythonhosted.org/packages/cc/b8/f3e672d3158783bea0640a03f076d4c0cd64b420ffd1e853ea3feb43edd8/HaMiP-0.0.3.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8faebc313fb8bd10ccc9ec69b68d22dd83f61fa937bb9debd06a1563591ee065",
          "md5": "c8ab164c25d058dae178907b22f2eedf",
          "sha256": "c87a0d5e667b0eb17b755c79da35d6ead7cdd4b703e3c4f7c7cab10a7ed5c473"
        },
        "downloads": -1,
        "filename": "HaMiP-0.0.3.1.tar.gz",
        "has_sig": false,
        "md5_digest": "c8ab164c25d058dae178907b22f2eedf",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 1000000,
        "upload_time": "2020-09-03T20:35:08",
        "upload_time_iso_8601": "2020-09-03T20:35:08.486819Z",
        "url": "https://files.pythonhosted.org/packages/8f/ae/bc313fb8bd10ccc9ec69b68d22dd83f61fa937bb9debd06a1563591ee065/HaMiP-0.0.3.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9083dc5cce420eddc99baf4247d14f5f742e93769c9a7ff70cc53a5fa82bc4e7",
          "md5": "d073a580f25aca305d3f5e89d4a74f64",
          "sha256": "9d96fcba6f12fd044c0bf286992cbca6d11507e02d0b707ae90e9eca48516518"
        },
        "downloads": -1,
        "filename": "HaMiP-0.0.3.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d073a580f25aca305d3f5e89d4a74f64",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 18091,
        "upload_time": "2020-09-03T21:28:56",
        "upload_time_iso_8601": "2020-09-03T21:28:56.702898Z",
        "url": "https://files.pythonhosted.org/packages/90/83/dc5cce420eddc99baf4247d14f5f742e93769c9a7ff70cc53a5fa82bc4e7/HaMiP-0.0.3.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0b6bd8b41b700d700abf1ab60b56df76e0a9905b3a4ab2532ebd40ab0b34f943",
          "md5": "80c5a61e8312b1a69cbab935da79aee4",
          "sha256": "73fb10ce12e42e389f93a23424190e5eb4659c7e670bb6fd4c3b278c5002f366"
        },
        "downloads": -1,
        "filename": "HaMiP-0.0.3.2.tar.gz",
        "has_sig": false,
        "md5_digest": "80c5a61e8312b1a69cbab935da79aee4",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 1001216,
        "upload_time": "2020-09-03T21:28:59",
        "upload_time_iso_8601": "2020-09-03T21:28:59.439134Z",
        "url": "https://files.pythonhosted.org/packages/0b/6b/d8b41b700d700abf1ab60b56df76e0a9905b3a4ab2532ebd40ab0b34f943/HaMiP-0.0.3.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "9083dc5cce420eddc99baf4247d14f5f742e93769c9a7ff70cc53a5fa82bc4e7",
        "md5": "d073a580f25aca305d3f5e89d4a74f64",
        "sha256": "9d96fcba6f12fd044c0bf286992cbca6d11507e02d0b707ae90e9eca48516518"
      },
      "downloads": -1,
      "filename": "HaMiP-0.0.3.2-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "d073a580f25aca305d3f5e89d4a74f64",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 18091,
      "upload_time": "2020-09-03T21:28:56",
      "upload_time_iso_8601": "2020-09-03T21:28:56.702898Z",
      "url": "https://files.pythonhosted.org/packages/90/83/dc5cce420eddc99baf4247d14f5f742e93769c9a7ff70cc53a5fa82bc4e7/HaMiP-0.0.3.2-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "0b6bd8b41b700d700abf1ab60b56df76e0a9905b3a4ab2532ebd40ab0b34f943",
        "md5": "80c5a61e8312b1a69cbab935da79aee4",
        "sha256": "73fb10ce12e42e389f93a23424190e5eb4659c7e670bb6fd4c3b278c5002f366"
      },
      "downloads": -1,
      "filename": "HaMiP-0.0.3.2.tar.gz",
      "has_sig": false,
      "md5_digest": "80c5a61e8312b1a69cbab935da79aee4",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 1001216,
      "upload_time": "2020-09-03T21:28:59",
      "upload_time_iso_8601": "2020-09-03T21:28:59.439134Z",
      "url": "https://files.pythonhosted.org/packages/0b/6b/d8b41b700d700abf1ab60b56df76e0a9905b3a4ab2532ebd40ab0b34f943/HaMiP-0.0.3.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}