{
  "info": {
    "author": "Tiago Duque",
    "author_email": "tfduque@hotmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.7"
    ],
    "description": "# [nlptools] Python NLP Tools\n> A straightforward Natural Language Processing Toolbox\n\nNLP Tools is a set of tools written in python that covers the most common NLP tasks with an easy and clear to understand style of code. \n\nIt is being developed together with a Series of Articles about NLP by the main author in Medium. You can find the articles at \n[tfduque.medium.com](tfduque.medium.com)\n\n## Installation\n\nInstalling with pip\n\n```sh\npip install nlpytools\n```\n\n## Usage example\n### Tokenization\n* Using the tokenizer:\n```python\nfrom nlptools.core.structures import tokenize\n\ntokenize(\"This is a sentence\")\n```\n```sh\n[<SOS>, this, is, a, sentence, <EOS>]\n```\n\n* Using sentence/document format:\n```python\nfrom nlptools.core.structures import Document\ndoc = Document(\"This is a sentence. This is another sentence.\")\n\nfor sentence in doc:\n    print(sentence, sentence.tokens)\n```\n```sh\nThis is a sentence. [<SOS>, This, is, a, sentence, ., <EOS>]\nThis is another sentence. [<SOS>, This, is, another, sentence, ., <EOS>]\n```\n### Normalization\nThese are the currently available normalization steps:\n```python\npre_tokenization_functions = {'simplify_punctuation': simplify_punctuation,\n                                  'normalize_whitespace': normalize_whitespace}\npost_tokenization_functions = {'normalize_contractions': normalize_contractions,\n                               'spell_correction': spell_correction,\n                               'remove_stopwords': remove_stopwords}\n```\nUsage:\n```python\nfrom nlptools.preprocessing.normalization import Normalizer\nnormalizer = Normalizer(pre_tokenization_steps=['simplify_punctuation', 'normalize_whitespace'],\n                        post_tokenization_steps=['normalize_contractions', 'spell_correction'])\nnorm.normalize_string(\"This is a nnormalized sentence!!!!         Yeah,,!!\") # one can also use normalize_document\n```\n```sh\n'This is a normalized sentence! Yeah,!'\n```\n### Stemming:\n```python\nfrom nlptools.preprocessing.stemming import PorterStemmer\nfrom nlptools.core.structures import tokenize\nstemmer = PorterStemmer()\ntokens = tokenize(\"The words in this sentence will be stemmed.\")\nstemmed_tokens = [stemmer.stem(token) for token in tokens]\n```\n```sh\n['<sos>', 'the', 'word', 'in', 'thi', 'sent', 'will', 'be', 'stem', '.', '<eos>']\n```\n\n### Lemmatizing and Tagging\nFirst: tagging\n```python\nfrom nlptools.preprocessing.tagging import MLTagger\ntagger = MLTagger()\ntag_pairs = tagger.tag(\"Tag this sentence\")\nfor tag in tag_pairs:\n     print(tag, tag.PoS)\n```\n```python\n<SOS> None\nTag NNP\nthis DT\nsentence NN\n<EOS> None\n```\nEvery token carries its own Part of Speech in the PoS attribute after the tagging.\n\nThen, after tagging, we can do Lemmatization\n```python\nfrom nlptools.preprocessing.tagging import MLTagger\ntagger = MLTagger(force_ud=True) # Force UD format to use compatible tags\ntag_pairs = tagger.tag(\"The cars are running\")\nlemmatized_words = [lemmatizer.lemmatize(word, word.PoS) for word in tag_pairs.tokens]\nprint(\" \".join(lemmatized_words[1:-1]))\n```\n```sh\nthe car are run\n```\n### Featurization\n```python\nfrom nlptools.preprocessing.featurization import Tfidf\ntfidf = Tfidf()\ntfidf.fit([\"The first sentence\", \"The second sentence\", \"The third sentence\", \"First, second, third.\"])\ntfidf.transform([\"The first sentence\", \"The second sentence\", \"The third sentence\", \"First, second, third.\"]) #or just go with fit_transform\n```\n```sh\nmatrix([[0.30543024, 0.        , 0.        , 0.        , 0.        ,\n         0.07438118, 0.        , 0.07438118],\n        [0.        , 0.30543024, 0.        , 0.        , 0.        ,\n```\n_For more examples and usage, please refer to the [medium series](https://tfduque.medium.com/dissecting-natural-language-processing-layer-by-layer-an-introductory-overview-d11cfff4f329)._\n\n## Release History\n\n* 0.1.0\n    * Pypi release\n\n## Meta\n\nTiago Duque â€“ [medium website](tfduque.medium.com)\n\nDistributed under the MIT license. See ``LICENSE`` for more information.\n\n[Check me at github](https://github.com/Sirsirious)\n\n[Check me at Linkedin](https://www.linkedin.com/in/tfduque/)\n\n## Contributing\n\n1. Fork it (<https://github.com/yourname/yourproject/fork>)\n2. Create your feature branch (`git checkout -b feature/fooBar`)\n3. Write understandable code!!!\n4. Commit your changes (`git commit -am 'Add some fooBar'`)\n5. Push to the branch (`git push origin feature/fooBar`)\n6. Create a new Pull Request\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/Sirsirious/NLPTools",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "nlpytools",
    "package_url": "https://pypi.org/project/nlpytools/",
    "platform": "",
    "project_url": "https://pypi.org/project/nlpytools/",
    "project_urls": {
      "Homepage": "https://github.com/Sirsirious/NLPTools"
    },
    "release_url": "https://pypi.org/project/nlpytools/0.1.0/",
    "requires_dist": [
      "numpy",
      "sklearn-crfsuite",
      "symspellpy",
      "tqdm"
    ],
    "requires_python": "",
    "summary": "A set of python tools for Natural Language Processing",
    "version": "0.1.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8853029,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9ce5444c32ed8865565dd08f20694cc7cd712e3c1ee59e483eca68ae54e454b7",
          "md5": "3887b82c60d104c927da4a25807bc6ae",
          "sha256": "a9d70b027ab6b0c1a5fe620d82d87e5080d8bbcfb92315971cb38ef85a742016"
        },
        "downloads": -1,
        "filename": "nlpytools-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "3887b82c60d104c927da4a25807bc6ae",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 4514617,
        "upload_time": "2020-12-08T22:13:00",
        "upload_time_iso_8601": "2020-12-08T22:13:00.707233Z",
        "url": "https://files.pythonhosted.org/packages/9c/e5/444c32ed8865565dd08f20694cc7cd712e3c1ee59e483eca68ae54e454b7/nlpytools-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f3b9e0c78c6a860aa41d7f28faab767890ac544e9bfd44697dffe91defdbc0c4",
          "md5": "2120e031441bbf9d91e33c5bfd68d521",
          "sha256": "f5c953ea365041ac0d8dd93c25a0a85ecf3e11f5c9073f853cf262651e748c10"
        },
        "downloads": -1,
        "filename": "nlpytools-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "2120e031441bbf9d91e33c5bfd68d521",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 4498893,
        "upload_time": "2020-12-08T22:13:33",
        "upload_time_iso_8601": "2020-12-08T22:13:33.416898Z",
        "url": "https://files.pythonhosted.org/packages/f3/b9/e0c78c6a860aa41d7f28faab767890ac544e9bfd44697dffe91defdbc0c4/nlpytools-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "9ce5444c32ed8865565dd08f20694cc7cd712e3c1ee59e483eca68ae54e454b7",
        "md5": "3887b82c60d104c927da4a25807bc6ae",
        "sha256": "a9d70b027ab6b0c1a5fe620d82d87e5080d8bbcfb92315971cb38ef85a742016"
      },
      "downloads": -1,
      "filename": "nlpytools-0.1.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "3887b82c60d104c927da4a25807bc6ae",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 4514617,
      "upload_time": "2020-12-08T22:13:00",
      "upload_time_iso_8601": "2020-12-08T22:13:00.707233Z",
      "url": "https://files.pythonhosted.org/packages/9c/e5/444c32ed8865565dd08f20694cc7cd712e3c1ee59e483eca68ae54e454b7/nlpytools-0.1.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "f3b9e0c78c6a860aa41d7f28faab767890ac544e9bfd44697dffe91defdbc0c4",
        "md5": "2120e031441bbf9d91e33c5bfd68d521",
        "sha256": "f5c953ea365041ac0d8dd93c25a0a85ecf3e11f5c9073f853cf262651e748c10"
      },
      "downloads": -1,
      "filename": "nlpytools-0.1.0.tar.gz",
      "has_sig": false,
      "md5_digest": "2120e031441bbf9d91e33c5bfd68d521",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 4498893,
      "upload_time": "2020-12-08T22:13:33",
      "upload_time_iso_8601": "2020-12-08T22:13:33.416898Z",
      "url": "https://files.pythonhosted.org/packages/f3/b9/e0c78c6a860aa41d7f28faab767890ac544e9bfd44697dffe91defdbc0c4/nlpytools-0.1.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}