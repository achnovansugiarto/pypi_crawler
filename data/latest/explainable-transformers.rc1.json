{
  "info": {
    "author": "Wilson Estécio Marcílio Júnior",
    "author_email": "wilson_jr@outlook.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": ".. -*- mode: rst -*-\n\n|pypi_version|_ |pypi_downloads|_\n\n.. |pypi_version| image:: https://img.shields.io/pypi/v/explainable-transformers.svg\n.. _pypi_version: https://pypi.python.org/pypi/explainable-transformers/\n\n.. |pypi_downloads| image:: https://pepy.tech/badge/explainable-transformers/month\n.. _pypi_downloads: https://pepy.tech/project/explainable-transformers\n\n.. image:: artwork/cover.png\n\t:alt: Vision Transformers explanation\n\n\n=====\nexplainable-transformers\n=====\n\nExplanation and interpretation techniques for Transformer-based architectures. \n\n-----------\nInstallation\n-----------\n\nRequirements:\n\n* opencv-python\n* numpy\n* torch\n* tqdm\n\n.. code:: bash\n\n    pip install explainable-transformers\n\n--------------\nUsage examples\n--------------\n\nPlease, see **notebook/** for complete examples on how to create representations for the explanations.\n\nFor Vision Transformers, use the *VisionTransformerWrapper* passing a Pytorch model.\n\n.. code:: python\n\n    from transformers import ViTModel\n\n    # import explanator module\n    from explainable_transformers.image_explainer import VisionTransformerWrapper\n\n    # define the last layer for classification\n    class PreTrainedViT(nn.Module):\n        def __init__(self, vit_model, d_model, classes):\n            ...\n\n        def forward(self, x):\n            ...\n\n            \n    # load the pre-trained model\n    pretrained_vit_model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k', \n                                                    add_pooling_layer=False, output_attentions=True)\n\n    model = PreTrainedViT(pretrained_vit_model, hidden_size=768, output_dim=10)\n\n    # create the ViT wrapper and register the layers\n    vit_wrapper = VisionTransformerWrapper(model, device, num_attn_layers=12)\n    vit_wrapper.register_hook()\n\n    # explain a prediction using .generate_visualization(img)\n    image = Image.open('images/dogbird.png')\n    processed_image = transform(image)\n    cat_exp, _ = vit_wrapper.generate_visualization(processed_image)\n\n\n\nFor Text Transformers, right now we need to know how the attention component is organized. \n\n.. code:: python\n\n    # first the imports\n\n    from transformers import BertTokenizer, BertForSequenceClassification\n\n    from explainable_transformers.utils import *\n    from explainable_transformers import NLPTransformerWrapper\n\n\n    # for text, we provide the NLP wrapper\n\n    \"\"\"\n    We access the attention component like following:\n\n    - BERT or RoBERTa: '.encoder.layer.#.attention.self.dropout'\n    - XLNet: '.layer.#.rel_attn.dropout'\n\n    \"\"\"\n    nlp_wrapper = NLPTransformerWrapper(model, device, 12, 'bert', 'classifier', '.encoder.layer.#.attention.self.dropout')\n    nlp_wrapper.register_hook()\n\n    explanation = nlp_wrapper.generate_explanation(input_ids, attention_mask, class_index=true_class, start_layer=NUM_LAYERS-1)\n    explanation = explanation.detach().cpu().numpy()\n\n\n\n\n--------\nCitation\n--------\n\nPlease, use the respective authors if you use any of the techniques.\n\nCurrently, we have the **Pytorch** implementation of the following approaches:\n\n*Transformer Interpretability Beyond Attention Visualization* (`paper <https://arxiv.org/abs/2012.09838>`_):\n\n1. Transformers: BERT, RoBERTa, and XLNet\n\n2. Vision Transformers\n\n.. code:: bibtex\n\n    @InProceedings{Chefer_2021_CVPR,\n        author    = {Chefer, Hila and Gur, Shir and Wolf, Lior},\n        title     = {Transformer Interpretability Beyond Attention Visualization},\n        booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n        month     = {June},\n        year      = {2021},\n        pages     = {782-791}\n    }\n\n\n-------\nLicense\n-------\n\n*explainable-transformers* follows the 3-clause BSD license and it is based on other open-source implementations: `Chefer's <https://github.com/hila-chefer/Transformer-Explainability>`_.\n\nWe also use `nlp_understanding <https://github.com/ENSAE-CKW/nlp_understanding>`_ for generating the heatmap.\n\nE-mail me (wilson_jr at outlook dot com) if you like to contribute.\n\n\n......\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/wilsonjr/explainable_transformer",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "explainable-transformers",
    "package_url": "https://pypi.org/project/explainable-transformers/",
    "platform": null,
    "project_url": "https://pypi.org/project/explainable-transformers/",
    "project_urls": {
      "Homepage": "https://github.com/wilsonjr/explainable_transformer"
    },
    "release_url": "https://pypi.org/project/explainable-transformers/0.0.1/",
    "requires_dist": [
      "tqdm",
      "numpy",
      "opencv-python",
      "torch"
    ],
    "requires_python": "",
    "summary": "Explanation techniques for Transformer-based architectures",
    "version": "0.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14138854,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3abf728ba269a096a6f8949a608db19006cf55cb574db822fcbf2218272f0d9c",
          "md5": "7a6e796249789c5e8f8a8c443ad71a7c",
          "sha256": "c2af011ef42f7ce506d5149d31931375776db901791a04c9b9ea18494768bd59"
        },
        "downloads": -1,
        "filename": "explainable_transformers-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "7a6e796249789c5e8f8a8c443ad71a7c",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 13697,
        "upload_time": "2022-06-15T12:03:04",
        "upload_time_iso_8601": "2022-06-15T12:03:04.794812Z",
        "url": "https://files.pythonhosted.org/packages/3a/bf/728ba269a096a6f8949a608db19006cf55cb574db822fcbf2218272f0d9c/explainable_transformers-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "3abf728ba269a096a6f8949a608db19006cf55cb574db822fcbf2218272f0d9c",
        "md5": "7a6e796249789c5e8f8a8c443ad71a7c",
        "sha256": "c2af011ef42f7ce506d5149d31931375776db901791a04c9b9ea18494768bd59"
      },
      "downloads": -1,
      "filename": "explainable_transformers-0.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "7a6e796249789c5e8f8a8c443ad71a7c",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 13697,
      "upload_time": "2022-06-15T12:03:04",
      "upload_time_iso_8601": "2022-06-15T12:03:04.794812Z",
      "url": "https://files.pythonhosted.org/packages/3a/bf/728ba269a096a6f8949a608db19006cf55cb574db822fcbf2218272f0d9c/explainable_transformers-0.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}