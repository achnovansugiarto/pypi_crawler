{
  "info": {
    "author": "Petals Developers",
    "author_email": "petals-dev@googlegroups.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Intended Audience :: Developers",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Topic :: Scientific/Engineering",
      "Topic :: Scientific/Engineering :: Artificial Intelligence",
      "Topic :: Scientific/Engineering :: Mathematics",
      "Topic :: Software Development",
      "Topic :: Software Development :: Libraries",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "<p align=\"center\">\n    <img src=\"https://i.imgur.com/7eR7Pan.png\" width=\"400\"><br>\n    Run 100B+ language models at home, BitTorrent-style.<br>\n    Fine-tuning and inference up to 10x faster than offloading<br><br>\n    <a href=\"https://pypi.org/project/petals/\"><img src=\"https://img.shields.io/pypi/v/petals.svg?color=green\"></a><br>\n</p>\n\nGenerate text using distributed 176B-parameter [BLOOM](https://huggingface.co/bigscience/bloom) or [BLOOMZ](https://huggingface.co/bigscience/bloomz) and fine-tune them for your own tasks:\n\n```python\nfrom petals import DistributedBloomForCausalLM\n\nmodel = DistributedBloomForCausalLM.from_pretrained(\"bigscience/bloom-petals\", tuning_mode=\"ptune\", pre_seq_len=16)\n# Embeddings & prompts are on your device, BLOOM blocks are distributed across the Internet\n\ninputs = tokenizer(\"A cat sat\", return_tensors=\"pt\")[\"input_ids\"]\noutputs = model.generate(inputs, max_new_tokens=5)\nprint(tokenizer.decode(outputs[0]))  # A cat sat on a mat...\n\n# Fine-tuning (updates only prompts or adapters hosted locally)\noptimizer = torch.optim.AdamW(model.parameters())\nfor input_ids, labels in data_loader:\n    outputs = model.forward(input_ids)\n    loss = cross_entropy(outputs.logits, labels)\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n```\n\n<p align=\"center\">\n    üöÄ &nbsp;<b><a href=\"https://colab.research.google.com/drive/1Ervk6HPNS6AYVr3xVdQnY5a-TjjmLCdQ?usp=sharing\">Try now in Colab</a></b>\n</p>\n\nüîè Your data will be processed by other people in the public swarm. Learn more about privacy [here](https://github.com/bigscience-workshop/petals/wiki/Security,-privacy,-and-AI-safety). For sensitive data, you can set up a [private swarm](https://github.com/bigscience-workshop/petals/wiki/Launch-your-own-swarm) among people you trust.\n\n### Connect your GPU and increase Petals capacity\n\nRun this in an [Anaconda](https://www.anaconda.com) env (requires Linux and Python 3.7+):\n\n```bash\nconda install pytorch pytorch-cuda=11.7 -c pytorch -c nvidia\npip install -U petals\npython -m petals.cli.run_server bigscience/bloom-petals\n```\n\nOr use our [Docker](https://www.docker.com) image (works on Linux, macOS, and Windows with [WSL2](https://learn.microsoft.com/en-us/windows/ai/directml/gpu-cuda-in-wsl)):\n\n```bash\nsudo docker run -p 31330:31330 --ipc host --gpus all --volume petals-cache:/cache --rm \\\n    learningathome/petals:main python -m petals.cli.run_server bigscience/bloom-petals --port 31330\n```\n\nüìö See [FAQ](https://github.com/bigscience-workshop/petals/wiki/FAQ:-Frequently-asked-questions#running-a-server) to learn how to configure the server to use multiple GPUs, address common issues, etc.\n\nYou can also host [BLOOMZ](https://huggingface.co/bigscience/bloomz), a version of BLOOM fine-tuned to follow human instructions in the zero-shot regime ‚Äî just replace `bloom-petals` with `bloomz-petals`.\n\nüîí Hosting a server does not allow others to run custom code on your computer. Learn more about security [here](https://github.com/bigscience-workshop/petals/wiki/Security,-privacy,-and-AI-safety).\n\nüí¨ If you have any issues or feedback, let us know on [our Discord server](https://discord.gg/D9MwApKgWa)!\n\n### Check out tutorials, examples, and more\n\nBasic tutorials:\n\n- Getting started: [tutorial](https://colab.research.google.com/drive/1Ervk6HPNS6AYVr3xVdQnY5a-TjjmLCdQ?usp=sharing)\n- Prompt-tune BLOOM to create a personified chatbot: [tutorial](https://colab.research.google.com/github/bigscience-workshop/petals/blob/main/examples/prompt-tuning-personachat.ipynb)\n- Prompt-tune BLOOM for text semantic classification: [tutorial](https://colab.research.google.com/github/bigscience-workshop/petals/blob/main/examples/prompt-tuning-sst2.ipynb)\n\nUseful tools and advanced guides:\n\n- [Chatbot web app](http://chat.petals.ml) (connects to Petals via an HTTP endpoint): [source code](https://github.com/borzunov/chat.petals.ml)\n- [Monitor](http://health.petals.ml) for the public swarm: [source code](https://github.com/borzunov/health.petals.ml)\n- Launch your own swarm: [guide](https://github.com/bigscience-workshop/petals/wiki/Launch-your-own-swarm)\n- Run a custom foundation model: [guide](https://github.com/bigscience-workshop/petals/wiki/Run-a-custom-model-with-Petals)\n\nLearning more:\n\n- Frequently asked questions: [FAQ](https://github.com/bigscience-workshop/petals/wiki/FAQ:-Frequently-asked-questions)\n- In-depth system description: [paper](https://arxiv.org/abs/2209.01188)\n\nüìã If you build an app running BLOOM with Petals, make sure it follows the BLOOM's [terms of use](https://huggingface.co/bigscience/bloom).\n\n## How does it work?\n\n- Petals runs large language models like [BLOOM-176B](https://huggingface.co/bigscience/bloom) **collaboratively** ‚Äî you load a small part of the model, then team up with people serving the other parts to run inference or fine-tuning.\n- Inference runs at ‚âà 1 sec per step (token) ‚Äî 10x faster than possible with offloading, enough for chatbots and other interactive apps. Parallel inference reaches hundreds of tokens/sec.\n- Beyond classic language model APIs ‚Äî you can employ any fine-tuning and sampling methods by executing custom paths through the model or accessing its hidden states. You get the comforts of an API with the flexibility of PyTorch.\n\n<p align=\"center\">\n    <img src=\"https://i.imgur.com/RTYF3yW.png\" width=\"800\">\n</p>\n\n<p align=\"center\">\n    üìö &nbsp;<b><a href=\"https://github.com/bigscience-workshop/petals/wiki/FAQ:-Frequently-asked-questions\">See FAQ</a></b>\n    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n    üìú &nbsp;<b><a href=\"https://arxiv.org/pdf/2209.01188.pdf\">Read paper</a></b>\n</p>\n\n## Installation\n\nHere's how to install Petals with conda:\n\n```bash\nconda install pytorch pytorch-cuda=11.7 -c pytorch -c nvidia\npip install -U petals\n```\n\nThis script uses Anaconda to install CUDA-enabled PyTorch.\nIf you don't have anaconda, you can get it from [here](https://www.anaconda.com/products/distribution).\nIf you don't want anaconda, you can install PyTorch [any other way](https://pytorch.org/get-started/locally/).\nIf you want to run models with 8-bit weights, please install **PyTorch with CUDA 11** or newer for compatility with [bitsandbytes](https://github.com/timDettmers/bitsandbytes).\n\n__System requirements:__ Petals only supports Linux for now. If you don't have a Linux machine, consider running Petals in Docker (see our [image](https://hub.docker.com/r/learningathome/petals)) or, in case of Windows, in WSL2 ([read more](https://learn.microsoft.com/en-us/windows/ai/directml/gpu-cuda-in-wsl)). CPU is enough to run a client, but you probably need a GPU to run a server efficiently.\n\n## üõ†Ô∏è Development\n\nPetals uses pytest with a few plugins. To install them, run:\n\n```bash\nconda install pytorch pytorch-cuda=11.7 -c pytorch -c nvidia\ngit clone https://github.com/bigscience-workshop/petals.git && cd petals\npip install -e .[dev]\n```\n\nTo run minimalistic tests, you need to make a local swarm with a small model and some servers. You may find more information about how local swarms work and how to run them in [this tutorial](https://github.com/bigscience-workshop/petals/wiki/Launch-your-own-swarm).\n\n```bash\nexport MODEL_NAME=bloom-testing/test-bloomd-560m-main\n\npython -m petals.cli.run_server $MODEL_NAME --block_indices 0:12 \\\n  --identity tests/test.id --host_maddrs /ip4/127.0.0.1/tcp/31337 --new_swarm  &> server1.log &\nsleep 5  # wait for the first server to initialize DHT\n\npython -m petals.cli.run_server $MODEL_NAME --block_indices 12:24 \\\n  --initial_peers SEE_THE_OUTPUT_OF_THE_1ST_PEER &> server2.log &\n\ntail -f server1.log server2.log  # view logs for both servers\n```\n\nThen launch pytest:\n\n```bash\nexport MODEL_NAME=bloom-testing/test-bloomd-560m-main REF_NAME=bigscience/bloom-560m\nexport INITIAL_PEERS=/ip4/127.0.0.1/tcp/31337/p2p/QmS9KwZptnVdB9FFV7uGgaTq4sEKBwcYeKZDfSpyKDUd1g\nPYTHONPATH=. pytest tests --durations=0 --durations-min=1.0 -v\n```\n\nAfter you're done, you can terminate the servers and ensure that no zombie processes are left with `pkill -f petals.cli.run_server && pkill -f p2p`.\n\nThe automated tests use a more complex server configuration that can be found [here](https://github.com/bigscience-workshop/petals/blob/main/.github/workflows/run-tests.yaml).\n\n### Code style\n\nWe use [black](https://black.readthedocs.io/en/stable/the_black_code_style/current_style.html) and [isort](https://pycqa.github.io/isort/) for all pull requests.\nBefore committing your code, simply run `black . && isort .` and you will be fine.\n\n## üìú Citation\n\nAlexander Borzunov, Dmitry Baranchuk, Tim Dettmers, Max Ryabinin, Younes Belkada, Artem Chumachenko, Pavel Samygin, and Colin Raffel.\n[Petals: Collaborative Inference and Fine-tuning of Large Models.](https://arxiv.org/abs/2209.01188)\n_arXiv preprint arXiv:2209.01188,_ 2022.\n\n```bibtex\n@article{borzunov2022petals,\n  title = {Petals: Collaborative Inference and Fine-tuning of Large Models},\n  author = {Borzunov, Alexander and Baranchuk, Dmitry and Dettmers, Tim and Ryabinin, Max and Belkada, Younes and Chumachenko, Artem and Samygin, Pavel and Raffel, Colin},\n  journal = {arXiv preprint arXiv:2209.01188},\n  year = {2022},\n  url = {https://arxiv.org/abs/2209.01188}\n}\n```\n\n--------------------------------------------------------------------------------\n\n<p align=\"center\">\n    This project is a part of the <a href=\"https://bigscience.huggingface.co/\">BigScience</a> research workshop.\n</p>\n<p align=\"center\">\n    <img src=\"https://petals.ml/bigscience.png\" width=\"150\">\n</p>\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/bigscience-workshop/petals",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "petals",
    "package_url": "https://pypi.org/project/petals/",
    "platform": null,
    "project_url": "https://pypi.org/project/petals/",
    "project_urls": {
      "Bug Tracker": "https://github.com/bigscience-workshop/petals/issues",
      "Homepage": "https://github.com/bigscience-workshop/petals"
    },
    "release_url": "https://pypi.org/project/petals/1.1.3/",
    "requires_dist": [
      "torch (>=1.12)",
      "bitsandbytes (==0.34.0)",
      "accelerate (==0.15.0)",
      "huggingface-hub (==0.11.1)",
      "transformers (==4.25.1)",
      "speedtest-cli (==2.1.3)",
      "hivemind (==1.1.5)",
      "tensor-parallel (==1.0.23)",
      "humanfriendly",
      "async-timeout (>=4.0.2)",
      "cpufeature (>=0.2.0)",
      "packaging (>=20.9)",
      "pytest (==6.2.5) ; extra == 'dev'",
      "pytest-forked ; extra == 'dev'",
      "pytest-asyncio (==0.16.0) ; extra == 'dev'",
      "black (==22.3.0) ; extra == 'dev'",
      "isort (==5.10.1) ; extra == 'dev'",
      "psutil ; extra == 'dev'"
    ],
    "requires_python": ">=3.7",
    "summary": "Easy way to efficiently run 100B+ language models without high-end GPUs",
    "version": "1.1.3",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17108788,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e0ba20f77f8fe199467604e3b82f817b3523e198da860f22fae0d2190e7e864a",
          "md5": "51c375187de95023194f461ba3df6056",
          "sha256": "be1daea9bc20fcf7cf45ce1da1cc75f901dc1a1a8ed53a5bddb37bc2e80b3bb8"
        },
        "downloads": -1,
        "filename": "petals-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "51c375187de95023194f461ba3df6056",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 1330,
        "upload_time": "2022-12-27T14:33:56",
        "upload_time_iso_8601": "2022-12-27T14:33:56.836511Z",
        "url": "https://files.pythonhosted.org/packages/e0/ba/20f77f8fe199467604e3b82f817b3523e198da860f22fae0d2190e7e864a/petals-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c4f841540e88c5fd15834c8ac3872029b56fe580774a774ab59c5f018e7ce5b7",
          "md5": "466238344a1844cd025a4acb1321501a",
          "sha256": "acc00a4e6e00bbe339c3f25b874c52e07f48cac8bcdc9f7a8b2e6909f361b09d"
        },
        "downloads": -1,
        "filename": "petals-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "466238344a1844cd025a4acb1321501a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 1370,
        "upload_time": "2022-12-27T14:33:58",
        "upload_time_iso_8601": "2022-12-27T14:33:58.416168Z",
        "url": "https://files.pythonhosted.org/packages/c4/f8/41540e88c5fd15834c8ac3872029b56fe580774a774ab59c5f018e7ce5b7/petals-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "36d35829fbb5ad119fa79dbf4ac7b7f25a48af49608a49cb46ab390767aefa78",
          "md5": "934607d5b63070e87f426c671d17ad31",
          "sha256": "75b17dcf36a2c7800efffb983baccbaa9d5122f7f7d6d023f4d73a73c38fe311"
        },
        "downloads": -1,
        "filename": "petals-1.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "934607d5b63070e87f426c671d17ad31",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 81375,
        "upload_time": "2022-12-30T21:39:08",
        "upload_time_iso_8601": "2022-12-30T21:39:08.185925Z",
        "url": "https://files.pythonhosted.org/packages/36/d3/5829fbb5ad119fa79dbf4ac7b7f25a48af49608a49cb46ab390767aefa78/petals-1.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4363a53f47e52ed6ec09fe7c98f28a3877a21d47f3ca50e318d96c7e336e0589",
          "md5": "64abbfeef190ea2dfabd8f6f8da23975",
          "sha256": "1b609a221c22a32c97fbd0fa5ff0bb7f6e2f2d05ee605bcc96be2c216ddddd4e"
        },
        "downloads": -1,
        "filename": "petals-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "64abbfeef190ea2dfabd8f6f8da23975",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 70508,
        "upload_time": "2022-12-30T21:39:10",
        "upload_time_iso_8601": "2022-12-30T21:39:10.091229Z",
        "url": "https://files.pythonhosted.org/packages/43/63/a53f47e52ed6ec09fe7c98f28a3877a21d47f3ca50e318d96c7e336e0589/petals-1.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c7d915c8f775c6f9dfae98904308dab420e5c3e15a85f384b24a139d489a9397",
          "md5": "9c2571ef0df0a5b33a7ad25cd1fd44d4",
          "sha256": "178b9af749da88db43f7d5640305f026c8087140689c25b699647dca9f7f8b83"
        },
        "downloads": -1,
        "filename": "petals-1.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "9c2571ef0df0a5b33a7ad25cd1fd44d4",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 85792,
        "upload_time": "2023-01-10T11:49:29",
        "upload_time_iso_8601": "2023-01-10T11:49:29.007710Z",
        "url": "https://files.pythonhosted.org/packages/c7/d9/15c8f775c6f9dfae98904308dab420e5c3e15a85f384b24a139d489a9397/petals-1.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ae4ba10e269e04c6191e96f6e0098a95aa6b3d9c7cde7a9c388e6cd3d0cb8066",
          "md5": "750c525de622130ac36fd8ebdb876949",
          "sha256": "1868ae367f094c2cf103317bf6c38283f64bf17c9282e93513d7219cb367c91d"
        },
        "downloads": -1,
        "filename": "petals-1.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "750c525de622130ac36fd8ebdb876949",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 74190,
        "upload_time": "2023-01-10T11:49:30",
        "upload_time_iso_8601": "2023-01-10T11:49:30.983526Z",
        "url": "https://files.pythonhosted.org/packages/ae/4b/a10e269e04c6191e96f6e0098a95aa6b3d9c7cde7a9c388e6cd3d0cb8066/petals-1.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c46dfd31d0c6fcc1062c106ae30977b7b9b1d38f3d4f43c71bde8187b4cc308b",
          "md5": "2d1c77a0cb3ba9b0fa372d518b564ded",
          "sha256": "7997b069995209b996b4646fb5276c6d53ef57d0ba478d05876b11467b43aa7b"
        },
        "downloads": -1,
        "filename": "petals-1.1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "2d1c77a0cb3ba9b0fa372d518b564ded",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 91318,
        "upload_time": "2023-01-13T20:39:04",
        "upload_time_iso_8601": "2023-01-13T20:39:04.992211Z",
        "url": "https://files.pythonhosted.org/packages/c4/6d/fd31d0c6fcc1062c106ae30977b7b9b1d38f3d4f43c71bde8187b4cc308b/petals-1.1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3d4d31f183b49f12555071b50ea3dcd70d4c753b53b0d95162b3747d879fd337",
          "md5": "d8dad6140633a8236464174512695089",
          "sha256": "c677f0b292b5521b86c2b57d00926b683eca96381c6f5dc12da0930de2f3a724"
        },
        "downloads": -1,
        "filename": "petals-1.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "d8dad6140633a8236464174512695089",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 78644,
        "upload_time": "2023-01-13T20:39:07",
        "upload_time_iso_8601": "2023-01-13T20:39:07.271030Z",
        "url": "https://files.pythonhosted.org/packages/3d/4d/31f183b49f12555071b50ea3dcd70d4c753b53b0d95162b3747d879fd337/petals-1.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "96db9f07ad90fbbf4a73aee8d1df0185287f811bdad0924708b2d08f39bd563a",
          "md5": "ac84167c24b08043bd73001b4b6092f5",
          "sha256": "453f2fc3839205f782ac240d026fa86e7042095b3a325c32de50526646b9d1ab"
        },
        "downloads": -1,
        "filename": "petals-1.1.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ac84167c24b08043bd73001b4b6092f5",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 92321,
        "upload_time": "2023-01-30T20:20:07",
        "upload_time_iso_8601": "2023-01-30T20:20:07.910777Z",
        "url": "https://files.pythonhosted.org/packages/96/db/9f07ad90fbbf4a73aee8d1df0185287f811bdad0924708b2d08f39bd563a/petals-1.1.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8df5de08c84dff5c5003f7c649ea758bf17bd1530c7f657d3ab3bd3377f6488b",
          "md5": "458c75d7b02d1c1dc4afdf75c93ad00c",
          "sha256": "9ae8f0f6e7a33cc601e678ef03c02b229cc71e42a4cfb65f4932eeee4e195636"
        },
        "downloads": -1,
        "filename": "petals-1.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "458c75d7b02d1c1dc4afdf75c93ad00c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 79950,
        "upload_time": "2023-01-30T20:20:10",
        "upload_time_iso_8601": "2023-01-30T20:20:10.140325Z",
        "url": "https://files.pythonhosted.org/packages/8d/f5/de08c84dff5c5003f7c649ea758bf17bd1530c7f657d3ab3bd3377f6488b/petals-1.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "53a5e12b4300763a0c1d6292a296078101ebfb3c637b8997bf6c89ba38fa457b",
          "md5": "1b4f4da0d46fbc24a93ceef431717a32",
          "sha256": "13674324836faf475d39220258afd5f85c216cd0ea572ceb09e066f0c67c0944"
        },
        "downloads": -1,
        "filename": "petals-1.1.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "1b4f4da0d46fbc24a93ceef431717a32",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 92698,
        "upload_time": "2023-03-01T09:03:35",
        "upload_time_iso_8601": "2023-03-01T09:03:35.767463Z",
        "url": "https://files.pythonhosted.org/packages/53/a5/e12b4300763a0c1d6292a296078101ebfb3c637b8997bf6c89ba38fa457b/petals-1.1.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8eba601c8ed902e158a6df1e9df3ad9fe539aa4de6de478dabc1e15fdf64852f",
          "md5": "987b484313b7f9c7ff053ef9e2014639",
          "sha256": "4d31fa768e792f9689861bcbf2f45774d263dcb6a6345e921ea6034ddb9491d1"
        },
        "downloads": -1,
        "filename": "petals-1.1.3.tar.gz",
        "has_sig": false,
        "md5_digest": "987b484313b7f9c7ff053ef9e2014639",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 87132,
        "upload_time": "2023-03-01T09:03:37",
        "upload_time_iso_8601": "2023-03-01T09:03:37.946134Z",
        "url": "https://files.pythonhosted.org/packages/8e/ba/601c8ed902e158a6df1e9df3ad9fe539aa4de6de478dabc1e15fdf64852f/petals-1.1.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "53a5e12b4300763a0c1d6292a296078101ebfb3c637b8997bf6c89ba38fa457b",
        "md5": "1b4f4da0d46fbc24a93ceef431717a32",
        "sha256": "13674324836faf475d39220258afd5f85c216cd0ea572ceb09e066f0c67c0944"
      },
      "downloads": -1,
      "filename": "petals-1.1.3-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "1b4f4da0d46fbc24a93ceef431717a32",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 92698,
      "upload_time": "2023-03-01T09:03:35",
      "upload_time_iso_8601": "2023-03-01T09:03:35.767463Z",
      "url": "https://files.pythonhosted.org/packages/53/a5/e12b4300763a0c1d6292a296078101ebfb3c637b8997bf6c89ba38fa457b/petals-1.1.3-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "8eba601c8ed902e158a6df1e9df3ad9fe539aa4de6de478dabc1e15fdf64852f",
        "md5": "987b484313b7f9c7ff053ef9e2014639",
        "sha256": "4d31fa768e792f9689861bcbf2f45774d263dcb6a6345e921ea6034ddb9491d1"
      },
      "downloads": -1,
      "filename": "petals-1.1.3.tar.gz",
      "has_sig": false,
      "md5_digest": "987b484313b7f9c7ff053ef9e2014639",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 87132,
      "upload_time": "2023-03-01T09:03:37",
      "upload_time_iso_8601": "2023-03-01T09:03:37.946134Z",
      "url": "https://files.pythonhosted.org/packages/8e/ba/601c8ed902e158a6df1e9df3ad9fe539aa4de6de478dabc1e15fdf64852f/petals-1.1.3.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}