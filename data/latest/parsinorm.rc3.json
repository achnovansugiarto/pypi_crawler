{
  "info": {
    "author": "HaraAi",
    "author_email": "info@hara.ai",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "<div dir='ltr' align='left'>\n\n# ParsiNorm\nThe normalization step is so essential to format unification in pure textual applications. However, for embedded language models in speech processing modules, normalization is not limited to format unification. Moreover, it has to convert each readable symbol, number, etc., to how they are pronounced. \n\n<h1>functionalities</h1>\n\n<h3> General Normalization</h3>\n\n+ Sentence tokenizer (you must add postagger.model to a folder named resources in where parsinorm is installed for example \"/home/yourComputerName/.anaconda3/lib/python3.8/site-packages/parsinorm/resources\")\n+ Word Tokenizer\n+ Normalizing persian and English characters \n+ Normalizing Numbers (Converting to unique perisan Number)\n+ Converting Persian, English, Arabic symbols to normalized characters\n+ Normalize Punctuations\n+ Removing emojis\n+ Converting HTML tags to characters and symbols\n+ Having unique floating point number\n+ Removing different comma between numbers\n+ Removing repeated punctuations\n+ convert semi sapce to null\n\n<h3> Speech Normalization</h3>\n\n+ Converting mail and url to how are pronounced\n+ Converting Date and Times to how they are pronounced\n+ Converting special numbers to how they are pronounced\n+ Converting English and Persian Abbrevations to how they are pronounced\n+ converting telephone numbers to how they are pronounced in Persian\n+ Converting currency to how they are read\n+ Converting some symbols to how they are read such as %, °, *, #, +, &, Δ\n\n<h1>Usage</h1>\n\n```python\n>>> from parsinorm import Mail_url_cleaner \n>>> mail_url_cleaner  = Mail_url_cleaner ()\n>>> mail_url_cleaner.find_mails_clean(sentence=\"info@hara.ai\")\ninfo at hara dot ai\n\n>>> mail_url_cleaner.find_urls_clean(sentence=\"https://hara.ai/#services\")\nhttps do noghte slash slash hara dot ai\n\n>>> from parsinorm import Date_time_to_text\n>>> date_time_to_text = Date_time_to_text()\n>>> date_time_to_text.date_to_text(sentence='2021/10/27')\nبیست و هفتم اکتبر سال دو هزار و بیست و یک\n\n>>> date_time_to_text.time_to_text(sentence='22:57:11')\nبیست و دو و پنجاه و هفت دقیقه و  یازده ثانیه\n\n>>> from parsinorm import General_normalization\n>>> general_normalization = General_normalization()\n>>> general_normalization.alphabet_correction(sentence='ﻙﯘݙݤﮮ')\nکودکی\n\n>>>general_normalization.semi_space_correction(sentence='کتاب\\u200bخانه')\nکتابخانه\n\n>>> general_normalization.english_correction(sentence='naïve')\nnaive\n\n>>> general_normalization.html_correction(sentence='&quot;')\n\"\n\n>>> general_normalization.arabic_correction(sentence='ﷺ')\nصلی الله علیه و سلم\n\n>>> general_normalization.punctuation_correction(sentence=\"…\")\n...\n\n>>> general_normalization.specials_chars(sentence=\"℡\")\nTEL\n\n>>> general_normalization.remove_emojis(sentence='😊')\n\n\n>>> general_normalization.unique_floating_point(sentence='1،2')\n۱.۲\n\n>>> general_normalization.remove_comma_between_numbers(sentence='1٬234')\n۱۲۳۴\n\n>>> general_normalization.number_correction(sentence=\"⑤\")\n۵\n\n>>> general_normalization.remove_not_desired_chars(sentence=\"^ Hi ~\")\n  Hi  \n\n>>> general_normalization.remove_repeated_punctuation(sentence=\"!!!!!\")\n!\n\n>>> from parsinorm import Telephone_number\n>>> telephone_number = Telephone_number()\n>>> telephone_number.find_phones_replace(sentence='تلفن ۰۲۱۳۳۴۵۶۷۸۸')\nتلفن   صفر  بیست و یک سی و سه چهل و پنج شصت و هفت هشتاد و هشت\n\n>>> from parsinorm import Abbreviation\n>>> abbreviation = Abbreviation()\n>>> abbreviation.replace_date_abbreviation(sentence=\".در سال 1400 ه.ش\")\nدر سال 1400 هجری شمسی\n\n>>> abbreviation.replace_persian_label_abbreviation(sentence='امام زمان (عج)')\nامام زمان  عجل الله تعالی فرجه الشریف \n\n>>> abbreviation.replace_law_abbreviation(sentence='در ق.ا آمده است')\nدر قانون اساسی آمده است\n\n>>> abbreviation.replace_book_abbreviation(sentence='به کتاب زیر ر.ک مراجعه کنید')\nبه کتاب زیر رجوع کنید مراجعه کنید\n\n>>> abbreviation.replace_other_abbreviation(sentence='در قانون ج.ا آمده است')\nدر قانون جمهوری اسلامی آمده است\n\n>>> abbreviation.replace_English_abbrevations(sentence='U.S.A')\nیو اس آ\n\n>>> from parsinorm import TTS_normalization\n>>> TTS_normalization = TTS_normalization()\n>>> TTS_normalization.math_correction(sentence='⅞')\nهفت هشتم\n\n>>> TTS_normalization.replace_currency(sentence='۳۳$')\n۳۳ دلار\n\n>>> TTS_normalization.replace_symbols(sentence='۳۳°')\n۳۳ درجه \n\n>>> from parsinorm import Special_numbers\n>>> special_numbers = Special_numbers()\n>>> special_numbers.convert_numbers_to_text(sentence='122')\n صد و بیست و دو\n\n>>> special_numbers.replace_national_code(sentence='0499370899')\nصفر  چهار   نهصد و نود و سه   هفتاد   هشتصد و نود و نه\n\n>>> special_numbers.replace_card_number(sentence='6037701689095443')\nشصت   سی و هفت   هفتاد   شانزده   هشتاد و نه   صفر  نه   پنجاه و چهار   چهل و سه\n\n>>>special_numbers.replace_shaba(sentence='IR820540102680020817909002')\n آی آر   هشتاد و دو   صفر  پنج   چهل   ده   بیست و شش   هشتاد   صفر  دو   صفر  هشت   هفده   نود   نود   صفر  دو \n\n>>> from parsinorm import Tokenizer\n>>> tokenizer = Tokenizer()\n>>> tokenizer.sentence_tokenize('این مثالی است که در آن یک جمله فقط بر اساس علائم نگارشی جدا می‌شود.',verb_seperator= False)\n['این مثالی است که در آن یک جمله فقط بر اساس علائم نگارشی جدا میشود .']\n\n>>> tokenizer.sentence_tokenize('این مثالی است که در آن یک جمله با فعل تمام شده‌است ولی با نقطه تمام نشده‌است به همین دلیل آن را بر اساس فعل جدا می‌کنیم',verb_seperator= True)\n[' این مثالی است',\n ' که در آن یک جمله با فعل تمام شده\\u200cاست',\n ' ولی با نقطه تمام نشده\\u200cاست',\n ' به همین دلیل آن را بر اساس فعل جدا می\\u200cکنیم']\n\n\n\n>>> tokenizer.word_tokenize('می‌توانید از طریق اینemail با ما در ارتباط باشید: info@hara.ai. همچنین با هشتگ #hara ما را دنبال کنید')\n['می\\u200cتوانید',\n 'از',\n 'طریق',\n 'این',\n 'email',\n 'با',\n 'ما',\n 'در',\n 'ارتباط',\n 'باشید',\n ':',\n 'info@hara.ai',\n '.',\n 'همچنین',\n 'با',\n 'هشتگ',\n 'hara#',\n 'ما',\n 'را',\n 'دنبال',\n 'کنید']\n\n```\n\n\n<h1> Reference </h1>\n\nIf you use or discuss this normalization tool in your work, please cite our paper :\n\n```\n@inproceedings{oji2021parsinorm,\n  title={ParsiNorm: A Persian Toolkit for Speech Processing Normalization},\n  author={Oji, Romina and Razavi, Seyedeh Fatemeh and Dehsorkh, Sajjad Abdi and Hariri, Alireza and Asheri, Hadi and Hosseini, Reshad},\n  booktitle={2021 7th International Conference on Signal Processing and Intelligent Systems (ICSPIS)},\n  pages={1--5},\n  year={2021},\n  organization={IEEE}\n}\n```\n\n<h1> Contact </h1>\n\nIf you have any technical question regarding the dataset or publication, please\ncreate an issue in this repository.\n\n\n</div>\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/haraai/ParsiNorm",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "parsinorm",
    "package_url": "https://pypi.org/project/parsinorm/",
    "platform": null,
    "project_url": "https://pypi.org/project/parsinorm/",
    "project_urls": {
      "Homepage": "https://github.com/haraai/ParsiNorm"
    },
    "release_url": "https://pypi.org/project/parsinorm/0.0.3/",
    "requires_dist": [
      "num2fawords (==1.1)",
      "persian-tools (==0.0.10)",
      "urlextract (==1.4.0)",
      "nltk (==3.3)",
      "hazm (==0.7.0)"
    ],
    "requires_python": "",
    "summary": "Persain Text Pre-Proceesing Tool",
    "version": "0.0.3",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14065637,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "803a07490b5a14c1a83ec8d7ecc482dbbbec905fa03f6745215c169b02bf3f91",
          "md5": "6a0d56d5a1d89680623e9776936d4f2d",
          "sha256": "c3506865eeebd39e2c829cd4065842a44d5f7b4f08e2439d5862effa35e066fc"
        },
        "downloads": -1,
        "filename": "parsinorm-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "6a0d56d5a1d89680623e9776936d4f2d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 29935,
        "upload_time": "2022-03-29T16:57:05",
        "upload_time_iso_8601": "2022-03-29T16:57:05.231478Z",
        "url": "https://files.pythonhosted.org/packages/80/3a/07490b5a14c1a83ec8d7ecc482dbbbec905fa03f6745215c169b02bf3f91/parsinorm-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e5c378559c0674dea5a1103ba9117706fbf59dbb880685e821c96cbfe599c7bc",
          "md5": "9aa391ff124fdb402a1b5fc93f705705",
          "sha256": "162572aae3b9a326d09a6348a3944a1d7fc178a945877484a0de05819d9baff6"
        },
        "downloads": -1,
        "filename": "parsinorm-0.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "9aa391ff124fdb402a1b5fc93f705705",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 30376,
        "upload_time": "2022-04-03T09:57:32",
        "upload_time_iso_8601": "2022-04-03T09:57:32.873123Z",
        "url": "https://files.pythonhosted.org/packages/e5/c3/78559c0674dea5a1103ba9117706fbf59dbb880685e821c96cbfe599c7bc/parsinorm-0.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "483706343b4abf2341362ddebd5b0f468458046a309118be6e28d8b6413b7595",
          "md5": "262597e08d7d161c0f6e4f5fb40c7645",
          "sha256": "d3cf22bd31dc0abaa1c56bfa51e6e9d75fdcfc9f52cbe8f524574bf51173484b"
        },
        "downloads": -1,
        "filename": "parsinorm-0.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "262597e08d7d161c0f6e4f5fb40c7645",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 30378,
        "upload_time": "2022-06-08T05:54:35",
        "upload_time_iso_8601": "2022-06-08T05:54:35.066093Z",
        "url": "https://files.pythonhosted.org/packages/48/37/06343b4abf2341362ddebd5b0f468458046a309118be6e28d8b6413b7595/parsinorm-0.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "483706343b4abf2341362ddebd5b0f468458046a309118be6e28d8b6413b7595",
        "md5": "262597e08d7d161c0f6e4f5fb40c7645",
        "sha256": "d3cf22bd31dc0abaa1c56bfa51e6e9d75fdcfc9f52cbe8f524574bf51173484b"
      },
      "downloads": -1,
      "filename": "parsinorm-0.0.3-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "262597e08d7d161c0f6e4f5fb40c7645",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 30378,
      "upload_time": "2022-06-08T05:54:35",
      "upload_time_iso_8601": "2022-06-08T05:54:35.066093Z",
      "url": "https://files.pythonhosted.org/packages/48/37/06343b4abf2341362ddebd5b0f468458046a309118be6e28d8b6413b7595/parsinorm-0.0.3-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}