{
  "info": {
    "author": "Jack Wang",
    "author_email": "jackwang196531@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# ling_feature_extractor\n## Description\n- A corpus-linguistic tool to extract and search for linguistic features in a text or a corpus.\n- There are 95 built-in linguistic features in the main version versus 98 features in the Thesis_Project version. Deleted features are words per utterance, number of utterances, and number of overlaps, which are not deemed as generally accessible in a normal corpus.\n- Over 2/3 of these features come from Biber et al.(2006) with 42 features also present in Biber(1988). These features are generally known as part of the Multi-Dimensional (MD) analysis framework.\n- The program is mainly tested on two online accessible corpora, namely [British Academic Spoken Corpus](http://www.reading.ac.uk/AcaDepts/ll/base_corpus/) and [Michigan Corpus of Academic Englush](https://quod.lib.umich.edu/cgi/c/corpus/corpus?page=home;c=micase;cc=micase), but due to copyright concerns, here it is tested on the [test_sample](https://github.com/jaaack-wang/ling_feature_extractor/tree/main/test_sample). \n\n## Prerequisites\n\n- `Computer Langauges`: \n   - Python 3.6+: check with cmd: `python --version` or `python3 --version` ([Download Page](https://www.python.org/downloads/)); \n   - Java 1.8+: check with cmd: 'java --version' ([Download Page](https://www.java.com/en/download/)). \n- `Python packages`\n\n| Package | Description | Pip download | \n| :---: | :---: | :---: |\n| [stanfordcorenlp](https://github.com/Lynten/stanford-corenlp) | A Python wrapper for StanforeCoreNLP | `pip/pip3 install stanfordcorenlp` |\n| [pandas](https://pandas.pydata.org) | Used for storing extracted feature frequencies  | `pip/pip3 install pandas` |\n\nBesides, built-in packages are heavily employed in the program, especially the built-in `re` package for Regular Expression.\n\n## Installation\n- Directly download from this page and cd to the project folder.\n- By pip: `pip/pip3 install LFExtractor`\n\n## Usage\n### path to StanfordCoreNLP\n**Please specify _the directory to StanfordCoreNLP_ in the text_processor.py under LFE folder when first using the program.**\n- [X] `nlp = StanfordCoreNLP(\"/path/to/StanfordCoreNLP/\")` \n\nExample: nlp = StanfordCoreNLP(\"/Users/wzx/p_package/stanford-corenlp-4.1.0\")\n\n### Dealing with a corpus of files\n```python \nfrom LFE.extractor import CorpusLFE\n\nlfe = CorpusLFE('/directory/to/the/corpus/under/analysis/')\n# get frequency data and tagged corpus and extracted features by default\nlfe.corpus_feature_fre_extraction() lfe.corpus_feature_fre_extraction()    # lfe.corpus_feature_fre_extraction(normalized_rate=100, save_tagged_corpus=True, save_extracted_features=True, left=0, right=0). \n# change the normalized_rate, trun off tagged text and leave extracted text with specified context to display\nlfe.corpus_feature_fre_extraction(1000, False, True, 2, 3) # extract frequency data only, and the data are normalized at 1000 words.  \n\n# get frequency data only\nlfe.corpus_feature_fre_extraction(save_tagged_corpus=False, save_extracted_features=False)\n# get tagged corpus only\nlfe.save_tagged_corpus()\n# get extracted feature only\nlfe.save_corpus_extracted_features()   # lfe.save_corpus_extracted_features(left=0, right=0)\n# set how many words to display besides the target pattern\nlfe.save_corpus_extracted_features(2, 3)\n\n# extract and save specific linguistic feature by feature name\n# to see the built-in features' names, use `show_feature_names()`\nfrom LFE.extractor import *\nprint(show_feature_names())   # Six letter words and longer, Contraction, Agentless passive, By passive...\n# specify which feature to extract and save\nlfe.save_corpus_one_extracted_feature_by_name('Six letter words and longer')\n\n# extract and save specific linguistic feature by feature regex, for example, 'you know' \nlfe.save_corpus_one_extracted_feature_by_regex(r'you_\\S+ know_\\S+', 2, 2, feature_name='You Know')  # Extract phrase 'you know' along with 2 words spanning around. Also remember the '_\\S+' at the end of each word since the corpus will be automatically POS tagged.\n# for more complex structure, the features_set.py can be ultilized, for example, to extract \"article + adj + noun\" structure\nfrom LFE import features_set as fs\nART = fs.ART\nADJ = fs.ADJ\nNOUN = fs.NOUN\nlfe.save_corpus_one_extracted_feature_by_regex(rf'{ART} {ADJ} {NOUN}', 2, 2, 'Noun phrase')\n# result example (use test_sample): away_RB by_IN\t【 the_DT whole_JJ thing_NN 】\tIn_IN fact_NN \n```\n\n### Dealing with a text\n```python\nfrom LFE import extractor as ex\n\n# check the functionalities contained in ex by dir(ex)\n# show built-in feature names\nprint(ex.show_feature_names())   # Six letter words and longer, Contraction, Agentless passive, By passive...\n# get built-in features' regex by its name\nprint(ex.get_feature_regex_by_name('Contraction'))  # (n't| '\\S\\S?)_[^P]\\S+\n# get built-in features' names by regex\nprint(ex.get_feature_name_by_regex(r\"(n't| '\\S\\S?)_[^P]\\S+\"))  # Contraction\n\n# text processing\n# tagged file\nex.save_single_tagged_text('/path/to/the/file')\n# cleaned file\nex.save_single_cleaned_text('/path/to/the/file')\n\n# display extracted feature by name\nres = ex.display_extracted_feature_by_name('/path/to/the/file', 'Contraction', left=0, right=0)\nprint(res)  #  's_VBZ, n't_NEG, 've_VBP...\n# save the result\nex.save_extracted_feature_by_name('/path/to/the/file', 'Contraction', left=0, right=0)\n\n# display extracted feature by regex, for example, noun phrase\nfrom LFE import features_set as fs\n\nART = fs.ART\nADJ = fs.ADJ\nNOUN = fs.NOUN\nres = ex.display_extracted_feature_by_regex(rf'{ART} {ADJ} {NOUN}', 2, 2, 'Noun phrase')\nprint(res)  # One_CD is_VBZ\t【 the_DT extraordinary_JJ evidence_NN 】\tof_IN human_JJ\n# save the result\nex.save_extracted_feature_by_regex(rf'{ART} {ADJ} {NOUN}', 2, 2, 'Noun phrase')\n\n# get the frequency data of all the linguistic features for a file \nres = ex.get_single_file_feature_fre(file_path, normalized_rate=100, save_tagged_file=True, save_extracted_features=True, left=0, right=0)\nprint(res)\n```\n\n### Dealing with a part of a corpus\n```python\nfrom LFE.extractor import *\n\nlfe = CorpusLFE('/directory/to/the/corpus/under/analysis/')\n# get_filepath_list and select the files you want to examine and construct a list\nfp_list = lfe.get_filepath_list()   \n# loop through the list and use the functionalities mentioned above to get the results you want\n```\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/jaaack-wang/ling_feature_extractor",
    "keywords": "Computational linguistics,Corpus-linguistic tool,NLP,Natural Language Processing",
    "license": "MIT License",
    "maintainer": "",
    "maintainer_email": "",
    "name": "LFExtractor",
    "package_url": "https://pypi.org/project/LFExtractor/",
    "platform": "",
    "project_url": "https://pypi.org/project/LFExtractor/",
    "project_urls": {
      "Homepage": "https://github.com/jaaack-wang/ling_feature_extractor"
    },
    "release_url": "https://pypi.org/project/LFExtractor/1.0.1/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "A corpus-linguistic tool to extract and search for linguistic features",
    "version": "1.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8752824,
  "releases": {
    "1.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8ad7ef5588aa3cb0f9f8c82b60e7109e38c600350766fd742f2ac365c449bfa1",
          "md5": "e8f022fb6c62b526739c5014f0ab8150",
          "sha256": "6ecfb39118e9912934675f4a24608265fbd0f634465133c38eeab5891dc1c693"
        },
        "downloads": -1,
        "filename": "LFExtractor-1.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "e8f022fb6c62b526739c5014f0ab8150",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 31464,
        "upload_time": "2020-11-26T06:41:33",
        "upload_time_iso_8601": "2020-11-26T06:41:33.472121Z",
        "url": "https://files.pythonhosted.org/packages/8a/d7/ef5588aa3cb0f9f8c82b60e7109e38c600350766fd742f2ac365c449bfa1/LFExtractor-1.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "964cd6c977b06e402d31ea5728dff6442cb29e1d734b159495fe16defb4e8a78",
          "md5": "d3d2f73d4cf6d9e13ea4a99eebd51d5a",
          "sha256": "09af8bec5ebd2e76b8982b2adbd1d849a6414339fc0ef795c9dc5dc876cde6c0"
        },
        "downloads": -1,
        "filename": "LFExtractor-1.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "d3d2f73d4cf6d9e13ea4a99eebd51d5a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 31608,
        "upload_time": "2020-11-26T06:41:34",
        "upload_time_iso_8601": "2020-11-26T06:41:34.613044Z",
        "url": "https://files.pythonhosted.org/packages/96/4c/d6c977b06e402d31ea5728dff6442cb29e1d734b159495fe16defb4e8a78/LFExtractor-1.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "8ad7ef5588aa3cb0f9f8c82b60e7109e38c600350766fd742f2ac365c449bfa1",
        "md5": "e8f022fb6c62b526739c5014f0ab8150",
        "sha256": "6ecfb39118e9912934675f4a24608265fbd0f634465133c38eeab5891dc1c693"
      },
      "downloads": -1,
      "filename": "LFExtractor-1.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "e8f022fb6c62b526739c5014f0ab8150",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 31464,
      "upload_time": "2020-11-26T06:41:33",
      "upload_time_iso_8601": "2020-11-26T06:41:33.472121Z",
      "url": "https://files.pythonhosted.org/packages/8a/d7/ef5588aa3cb0f9f8c82b60e7109e38c600350766fd742f2ac365c449bfa1/LFExtractor-1.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "964cd6c977b06e402d31ea5728dff6442cb29e1d734b159495fe16defb4e8a78",
        "md5": "d3d2f73d4cf6d9e13ea4a99eebd51d5a",
        "sha256": "09af8bec5ebd2e76b8982b2adbd1d849a6414339fc0ef795c9dc5dc876cde6c0"
      },
      "downloads": -1,
      "filename": "LFExtractor-1.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "d3d2f73d4cf6d9e13ea4a99eebd51d5a",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 31608,
      "upload_time": "2020-11-26T06:41:34",
      "upload_time_iso_8601": "2020-11-26T06:41:34.613044Z",
      "url": "https://files.pythonhosted.org/packages/96/4c/d6c977b06e402d31ea5728dff6442cb29e1d734b159495fe16defb4e8a78/LFExtractor-1.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}