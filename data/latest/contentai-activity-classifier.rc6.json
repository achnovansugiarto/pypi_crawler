{
  "info": {
    "author": "Eric Zavesky",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "activity-classifier-extractor\n=============================\n\n\nGenerates activity classifications from low-level feature inputs in support\nof analytic workflows within the `ContentAI Platform <https://www.contentai.io>`__, \npublished as the extractor\n``dsai_activity_classifier``. \n\n1. `Getting Started <#getting-started>`__\n2. `Execution <#execution-and-deployment>`__\n3. `Creating Models <#creating-models>`__\n4. `Testing <#testing>`__\n5. `Future Development <#future-development>`__\n6. `Changes <CHANGES.md>`__\n\nGetting Started\n===============\n\n| This library is used as a `single-run executable <#contentai-standalone>`__.\n| Runtime parameters can be passed for processing that configure the\n  returned results and can be examined in more detail in the\n  `main <main.py>`__ script.\n\n-  ``verbose`` - *(bool)* - verbose input/output configuration printing (*default=false*)\n-  ``path_content`` - *(str)* - input video path for files to label (*default=video.mp4*)\n-  ``path_result`` - *(str)* - output path for samples (*default=.*)\n-  ``path_models`` - *(str)* - manifest path for model information (*default=data/models/manifest.json*)\n-  ``time_interval`` - *(float)* - time interval for predictions from models (*default=3.0*)\n-  ``average_predictions`` - *(bool)* - flatten predictions across time and class (*default=false*)\n-  ``round_decimals`` - *(int)* - rounding decimals for predictions (*default=5*)\n-  ``score_min`` - *(float)* - apply a minimum score threshold for classes (*default=0.1*)\n\n\ndependencies\n------------\n\n| To install package dependencies in a fresh system, the recommended\n  technique is a set of\n| vanilla pip packages. The latest requirements should be validated from\n  the ``requirements.txt`` file but at time of writing, they were the\n  following.\n\n.. code:: shell\n\n   pip install --no-cache-dir -r requirements.txt \n\nExecution and Deployment\n========================\n\nThis package is meant to be run as a one-off processing tool that\naggregates the insights of other extractors.\n\ncommand-line standalone\n-----------------------\n\nRun the code as if it is an extractor. In this mode, configure a few\nenvironment variables to let the code know where to look for content.\n\nOne can also run the command-line with a single argument as input and\noptionally ad runtime configuration (see `runtime\nvariables <#getting-started>`__) as part of the ``EXTRACTOR_METADATA``\nvariable as JSON.\n\n.. code:: shell\n\n   EXTRACTOR_METADATA='{\"compressed\":True}'\n\nLocally Run Classifier on Results\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nFor utility, the above line has been wrapped in the bash script\n``run_local.sh``.\n\n.. code:: shell\n\n    ./run_local.sh <docker_image> [<source_directory> <output_data_dir> [<json_args>]] [<all_args>]\n       - run clip extraction on source with prior processing\n\n      <docker_image> = 0 IF local command-line based (args using arg parse) \n                     = 1 IF local docker emulation\n                     = IMAGE_NAME IF docker image name to run\n\n      ./run_local.sh 0 --path_content features/ --path_result results/ --verbose \n      ./run_local.sh 1 features/ results/ 0 '{\\\"verbose\\\"true}' \n\nThrough all of the above examples, the underlying command-line execution is \nsimilar to this excution run on the testing data.\n\n.. code:: shell\n\n    python -u activity_classifier/main.py --path_content testing/data/launch/video.mp4 \n            --path_result testing/class --path_models activity_classifier/data/models/manifest.json --verbose\n\nFeature-Based Similarity\n~~~~~~~~~~~~~~~~~~~~~~~~\n\nA helper script is also avaialble to compute the similarity of clips in \none or more feature files. *(v1.1.0)*\n\n.. code:: shell\n\n    python -u activity_classifier/features.py --path_content testing/data/dummy.txt \\\\ \n            --feature_type dsai_videocnn dsai_vggish --path_result testing/dist\n\n\nContentAI\n---------\n\nDeployment\n~~~~~~~~~~\n\nDeployment is easy and follows standard ContentAI steps.\n\n.. code:: shell\n\n   contentai deploy dsai_activity_classifier\n   Deploying...\n   writing workflow.dot\n   done\n\nAlternatively, you can pass an image name to reduce rebuilding a docker\ninstance.\n\n.. code:: shell\n\n   docker build -t dsai_activity_classifier\n   contentai deploy metadata-flatten dsai_activity_classifier\n\nLocally Downloading Results\n~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nYou can locally download data from a specific job for this extractor to\ndirectly analyze.\n\n.. code:: shell\n\n   contentai data wHaT3ver1t1s --dir data\n\nRun as an Extractor\n~~~~~~~~~~~~~~~~~~~\n\n.. code:: shell\n\n   contentai run https://bucket/video.mp4  -w 'digraph { dsai_videocnn -> dsai_activity_classifier; dsai_vggish -> dsai_activity_classifier }'\n\n   JOB ID:     1Tfb1vPPqTQ0lVD1JDPUilB8QNr\n   CONTENT:    s3://bucket/video.mp4\n   STATE:      complete\n   START:      Fri Feb 15 04:38:05 PM (6 minutes ago)\n   UPDATED:    1 minute ago\n   END:        Fri Feb 15 04:43:04 PM (1 minute ago)\n   DURATION:   4 minutes \n\n   EXTRACTORS\n\n   my_extractor\n\n   TASK      STATE      START           DURATION\n   724a493   complete   5 minutes ago   1 minute \n\nOr run it via the docker image.  Please review the ``run_local.sh`` file for more information.\n\n\nView Extractor Logs (stdout)\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. code:: shell\n\n   contentai logs -f <my_extractor>\n   my_extractor Fri Nov 15 04:39:22 PM writing some data\n   Job complete in 4m58.265737799s\n\n\nAdding New Models\n=================\n\nThere are two steps to adding new models. \n\n1. First, train the models and formulate\n   a well-known structure (this can be done exhaustively across a number of model types).  \n   See `MODELS.rst <MODELS.rst>`__ for more details.\n2. Update the manifest according to the instructions below to indicate how the activity\n   classifier should load the model (e.g. the `framework`), the required features, and\n   a few fields for understanding other descriptions (e.g. the `name` and the `id`).\n\n\nUpdating The Manifest\n---------------------\n\nAdding models to the pre-determined set of models is as easy as editing a manifest file and \nadding a model into git LFS.  \n\n1. Archive the new model into a serialized fileset.  At time of writing, this was serializing \n   models from `sklearn <https://scikit-learn.org>`__ with simple \n   `pickle load/save serialization <https://scikit-learn.org/stable/modules/model_persistence.html>`__. \n2. Gather all of the relevant output files and compress them if you can.  Currently, the library \n   understands gzip compression extensions (e.g. \".gz\").\n3. Choose the appropriate sub-directory that corresponds to the upstream feature extractor.  For \n   example, models built on ``3dcnn`` features may process new videos (via `extractor chaining <https://www.contentai.io/docs/extractor-chaining>`__)  \n   to the extractor ``dsai_3dcnn``.  If one doesn't exist yet, please create a new directory, but\n   remember what combination of audio and video features is required.\n4. Modify the manifest file in ``activity_classifier/data/models/manifest.json`` for your new entry.\n   Specifically, the input video and audio features must be defined as well as the serialization\n   library.  Below is an example block that indicates ``3dcnn` video and ``vggish`` audio features for \n   a model crated with ``sklearn`` where prediction results will be nested with the name ``Running``.\n\n    .. code:: shell\n\n        [ ...\n        {\n            \"path\": \"3dcnn-vggish/lr-Running.pkl.gz\",\n            \"name\": \"Running\",\n            \"id\": \"ugc\",\n            \"framework\": \"sklearn\",\n            \"video\": \"dsai_videocnn\",\n            \"audio\": \"dsai_vggish\"\n        },\n        ... ]\n\n5. Prepare to add your model files to the repo.  **NOTE This repo uses `git-lfs <https://git-lfs.github.com/>`__\n   to store all binary files like models.  If your model is added with regular git tools alone, you will \n   get a sternly worded email (and friendly advice on how to re-add correctly).**  \n\n    .. code:: shell\n\n        (from the base directory only)\n        git lfs track activity_classifier/data/models/3dcnn/moonwalk_model.pkl.gz\n        git add activity_classifier/data/models/3dcnn/moonwalk_model.pkl.gz\n        git add activity_classifier/data/models/manifest.json\n\n6. Test your model with the data in the ``testing`` directory.  The CI/CD process should do this too\n   but it's always easier to find and fix problems here than with a vague email.  The features in this\n   directory came from processing of the `HBO Max Launch Video <https://www.youtube.com/watch?v=9yLNhhHs3-k>`__,\n   which is publicly available as a reference.\n\n    .. code:: shell\n\n        (from the base directory)\n\n        ./run_local.sh 0 --path_content testing/data/test.mp4 --time_interval 1.5\n\n        (check for predictions from your new model in data.json) \n\n\n\nTesting\n=======\n\nTesting is included via tox.  To launch testing for the entire package, just run `tox` at the command line. \nTesting can also be run for a specific file within the package by setting the evironment variable `TOX_ARGS`.\n\n.. code:: shell\n\n   TOX_ARG=test_basic.py tox \n\n\n\nFuture Development\n==================\n\n-  additional training hooks?\n\n\n\n\nChanges\n=======\n\nGenerates activity classifications from low-level feature inputs in support\nof analytic workflows within the `ContentAI Platform <https://www.contentai.io>`__.\n\n1.3\n---\n\n1.3.7\n~~~~~\n- fix run_local typos\n- more verbosity checks\n\n1.3.6\n~~~~~\n- modeling.py separators\n- docs reorg\n\n1.3.5\n~~~~~\n- contentai key request fix\n\n1.3.3\n~~~~~\n- docs update\n- multiclass write\n\n1.3.2\n~~~~~\n- docker build update, run example update\n\n1.3.1\n~~~~~\n- docs fix for example of using package\n- bug fix for default location, change inputs to classify function\n\n1.3.0\n~~~~~\n- move models out of the primary package\n- *breaking change*, rename input param `path_models` to `path_manifest`\n\n1.2\n---\n\n1.2.2\n~~~~~\n- bump version for model migration to LFS\n\n1.2.1\n~~~~~\n- fix docker/deployed image run command\n\n1.2.0\n~~~~~\n- switch to package representation, push to pypi\n- several updates for MANIFEST definition (id)\n- inclusion of multi-parameter training and testing framework\n- safety for model loading, catch exceptions, return gracefully\n- update documents to split for binary models \n\n1.1\n---\n\n1.1.1\n~~~~~\n- cosmetic change for reuse in other libraries\n\n1.1.0\n~~~~~\n\n- refactor feature code, add utility for difference computation among segments\n- min value thresholding to avoid low scoring results in output (default=0.1)\n- refactor caching information for feature load (allow flatten, remove cache, allow multi-asset)\n- allow recursive feature load for distance compute\n\n\n1.0\n---\n\n1.0.2\n~~~~~\n\n- fixes for output, modify to require other extractors as dependencies\n- fix order of paramters for local runs\n\n\n1.0.1\n~~~~~\n\n- updates for integration of other models, fixes for prediction output\n- add l2norm after average/merge in time of source features\n\n1.0.0\n~~~~~\n\n- initial project merge from other sources\n- generates json prediction dict\n- callable as package\n- includes some testing routines with windowing comparison\n\n\n\n",
    "description_content_type": "text/x-rst",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://gitlab.research.att.com/turnercode/activity-classifier-extractor",
    "keywords": "",
    "license": "Apache",
    "maintainer": "",
    "maintainer_email": "",
    "name": "contentai-activity-classifier",
    "package_url": "https://pypi.org/project/contentai-activity-classifier/",
    "platform": "",
    "project_url": "https://pypi.org/project/contentai-activity-classifier/",
    "project_urls": {
      "Homepage": "https://gitlab.research.att.com/turnercode/activity-classifier-extractor"
    },
    "release_url": "https://pypi.org/project/contentai-activity-classifier/1.3.7/",
    "requires_dist": [
      "pandas (==1.0.4)",
      "numexpr (==2.7.1)",
      "scikit-learn (==0.23.1)",
      "h5py (==2.10.0)",
      "matplotlib (==3.2.1)",
      "imblearn (==0.0)",
      "tensorflow (==2.2.0)",
      "contentaiextractor (>=1.0.4)"
    ],
    "requires_python": ">=3.6",
    "summary": "ContentAI Activity Classification Service",
    "version": "1.3.7",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 7989294,
  "releases": {
    "1.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "60a06ec8386b218abab6dfc8f1a43bee75a6913c1c310c4b35e0d90c62573f93",
          "md5": "c2dae9b1c81bb22648b2e95a8fb6da95",
          "sha256": "921b029f9fa67f5f1a9114b0a12ca9d6d097f236253fbbd2f50441e2e8ce8dbd"
        },
        "downloads": -1,
        "filename": "contentai_activity_classifier-1.2.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "c2dae9b1c81bb22648b2e95a8fb6da95",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": ">=3.6",
        "size": 349483,
        "upload_time": "2020-08-07T11:42:39",
        "upload_time_iso_8601": "2020-08-07T11:42:39.582676Z",
        "url": "https://files.pythonhosted.org/packages/60/a0/6ec8386b218abab6dfc8f1a43bee75a6913c1c310c4b35e0d90c62573f93/contentai_activity_classifier-1.2.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "29dc6d91fa07c0d43637f391fa8a7ffaac191e22ec875a84866b818392806b5b",
          "md5": "cbec561241d3207176bc2a7d0d629ea3",
          "sha256": "13dc7b253c19377546c04e3ffd42a48d0218dd82a4707a9111b460ad2ed5e67c"
        },
        "downloads": -1,
        "filename": "contentai_activity_classifier-1.2.1-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "cbec561241d3207176bc2a7d0d629ea3",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": ">=3.6",
        "size": 349504,
        "upload_time": "2020-08-07T16:37:20",
        "upload_time_iso_8601": "2020-08-07T16:37:20.374224Z",
        "url": "https://files.pythonhosted.org/packages/29/dc/6d91fa07c0d43637f391fa8a7ffaac191e22ec875a84866b818392806b5b/contentai_activity_classifier-1.2.1-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bb18bc10641b299a6a49d8bb45379c7f67f566a53780207f8fa0cea8ddc672ff",
          "md5": "0de988e6ad6ffa774976cdea547b42f7",
          "sha256": "0b1289f3ebecc5a9083001e3848e3149e9abdb38c75244d56b060ae17cb9d134"
        },
        "downloads": -1,
        "filename": "contentai_activity_classifier-1.2.2-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0de988e6ad6ffa774976cdea547b42f7",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": ">=3.6",
        "size": 349546,
        "upload_time": "2020-08-08T20:30:15",
        "upload_time_iso_8601": "2020-08-08T20:30:15.599788Z",
        "url": "https://files.pythonhosted.org/packages/bb/18/bc10641b299a6a49d8bb45379c7f67f566a53780207f8fa0cea8ddc672ff/contentai_activity_classifier-1.2.2-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.3.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6ce4288c39c167d8a773fb4c99b6e7d3ab08de9d4aebf0ce7dac95c0274a6c18",
          "md5": "792b90653658cb769dc6e6100381e3ad",
          "sha256": "6df36d49a4266701ddd2ef0befb6a9538df04724d82f1390b82838819af8249a"
        },
        "downloads": -1,
        "filename": "contentai_activity_classifier-1.3.5-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "792b90653658cb769dc6e6100381e3ad",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": ">=3.6",
        "size": 34006,
        "upload_time": "2020-08-12T15:18:12",
        "upload_time_iso_8601": "2020-08-12T15:18:12.035183Z",
        "url": "https://files.pythonhosted.org/packages/6c/e4/288c39c167d8a773fb4c99b6e7d3ab08de9d4aebf0ce7dac95c0274a6c18/contentai_activity_classifier-1.3.5-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.3.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "661cdce077ce67109757c990167c3b6737db0fb6a4e6b6f11133edf547de7070",
          "md5": "d991c366969400f97193f3f49c4ea708",
          "sha256": "1c6b55f50ae2385dbfd525caa121c57f8d124ba3d01e3b67e0bd427ee58abf00"
        },
        "downloads": -1,
        "filename": "contentai_activity_classifier-1.3.6-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d991c366969400f97193f3f49c4ea708",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": ">=3.6",
        "size": 33283,
        "upload_time": "2020-08-14T21:01:27",
        "upload_time_iso_8601": "2020-08-14T21:01:27.570405Z",
        "url": "https://files.pythonhosted.org/packages/66/1c/dce077ce67109757c990167c3b6737db0fb6a4e6b6f11133edf547de7070/contentai_activity_classifier-1.3.6-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.3.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "88f91ea16c08edee2934a0cd195c28c8e9bae36315dfe929ca4fde555ea3f681",
          "md5": "9fdc93eb53b81f224d5498430f5922ea",
          "sha256": "56e26f407fff2ba91eb1d46cc1ecbe40611b2fa850f68e0b6be8bd4830b15ead"
        },
        "downloads": -1,
        "filename": "contentai_activity_classifier-1.3.7-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "9fdc93eb53b81f224d5498430f5922ea",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": ">=3.6",
        "size": 33311,
        "upload_time": "2020-08-18T17:05:12",
        "upload_time_iso_8601": "2020-08-18T17:05:12.944476Z",
        "url": "https://files.pythonhosted.org/packages/88/f9/1ea16c08edee2934a0cd195c28c8e9bae36315dfe929ca4fde555ea3f681/contentai_activity_classifier-1.3.7-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "88f91ea16c08edee2934a0cd195c28c8e9bae36315dfe929ca4fde555ea3f681",
        "md5": "9fdc93eb53b81f224d5498430f5922ea",
        "sha256": "56e26f407fff2ba91eb1d46cc1ecbe40611b2fa850f68e0b6be8bd4830b15ead"
      },
      "downloads": -1,
      "filename": "contentai_activity_classifier-1.3.7-py2.py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "9fdc93eb53b81f224d5498430f5922ea",
      "packagetype": "bdist_wheel",
      "python_version": "py2.py3",
      "requires_python": ">=3.6",
      "size": 33311,
      "upload_time": "2020-08-18T17:05:12",
      "upload_time_iso_8601": "2020-08-18T17:05:12.944476Z",
      "url": "https://files.pythonhosted.org/packages/88/f9/1ea16c08edee2934a0cd195c28c8e9bae36315dfe929ca4fde555ea3f681/contentai_activity_classifier-1.3.7-py2.py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}