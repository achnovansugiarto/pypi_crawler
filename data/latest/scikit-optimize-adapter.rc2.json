{
  "info": {
    "author": "Jay Kim",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "\n\nScikit-Optimize-Adapter\n=======================\n\n\nScikit-Optimize-Adapter (Adapter: \"A DAsk Parallel TunER\") is an efficient light weight library built on top of Scikit-Optimize and Dask that lets the user do Bayesian optimization hyperparameter tuning with different schemes of parallelized cross-validations.\n\n\nInstall\n-------\n\n::\n\n\tpip install --index-url https://test.pypi.org/simple/ --no-deps scikit-optimize-adapter --upgrade\n\n\nGetting started\n---------------\n\nLet's start with the below dummy training data:\n\n.. code:: python\n\n\timport pandas as pd\n\timport numpy as np\n\n\tdata = np.arange(30*4).reshape(30, 4)\n\tdf = pd.DataFrame(data=data, columns=['target', 'f1', 'f2', 'f3'])\n\n\tfeatures = ['f1', 'f2', 'f3']\n\ttarget = 'target'\n\n\tK = 5\n\n\torderby=None\n\tnum_partition=None\n\twindow_size=None\n\n\tfrom skopt.space import Space, Categorical, Integer, Real, Dimension\n\n\tspace  = [Real(0.5, 10),      # learning rate       (learn_rate)\n\t          Real(0, 1),         # gamma               (min_split_improvement)\n\t          Integer(3, 4),      # max_depth           (max_depth)\n\t          Integer(11, 13),    # n_estimators        (ntrees)\n\t          Integer(2, 4),      # min_child_weight    (min_rows)\n\t          Real(0, 1),         # colsample_bytree    (col_sample_rate_per_tree)\n\t          Real(0, 1)]         # subsample           (sample_rate)\n\n\nAdapter is shipped with XGBoost regressor and classifier, but you can pass in a callable estimator of your design if you wish to customize it. \n\n.. code:: python\n\n\tfrom adapter import Adapter\n\n\tadapt = Adapter(df, features, target, K, groupby=None, \n                cross_validation_scheme='random_shuffle',\n                search_method=\"bayesian_optimization\",\n                estimator=\"xgboost_regression\")  # \"xgboost_regression\" or \"xgboost_classification\" or callable estimator (more on this later)\n\nTry copying the link to the web browser to check out the dask dashboard: ``http://127.0.0.1:8789/status``.\n\nYou can visualize the Dask delayed computation graph:\n\n.. code:: python\n\n\tdelayed_graph = adapt.construct_delayed_graph(num_iter=3, search_space=space)  # we will set n_iter to 3 to make visualizing manageable. \n\tdelayed_graph.visualize()\n\n.. figure:: https://github.com/mozjay0619/scikit-optimize-adapter/blob/master/media/graph.png\n\nLet's run the code. ``num_initial`` is the number of random initial searches and ``num_iter`` is the total number of search steps taken, including the ``num_initial`` step counts. (Example: ``num_initial=5, num_iter=15`` means 5 random search and 10 Bayesian search)\n\n.. code:: python\n\n\tres = adapt.run(num_initial=5, num_iter=15, search_space=space)\n\nWhile it runs, checkout the dashboard again, and click on the ``Graph`` tab. You will see the above computation graph being worked on in real time!\n\n.. figure:: https://github.com/mozjay0619/scikit-optimize-adapter/blob/master/media/daskdashboard.png\n\n\nNow you can retrieve the results:\n\n.. code:: python\n\n\tadapt.plot_improvements()  # to show the improvements \n\toptimal_params = adapt.get_optimal_params()  # which you can use to train your final model\n\n.. figure:: https://github.com/mozjay0619/scikit-optimize-adapter/blob/master/media/improvement.png\n\nIf you are running this in a local machine, you must take responsibility of removing the temporary directory:\n\n.. code:: python\n\n\tadapt.cleanup()\n\n\nCross-validation schemes\n------------------------\n\nThere are 5 different cross-validation schemes supported by the adapter:\n\n* ``random_shuffle``: create K cross-validation folds from randomly shuffled rows\n\t- Default mode for most regression tasks .\n* ``ordered``: create K cross-validation folds after sorting the train data by a certain column\n\t- Used for regression tasks where data has time series nature with high temporal auto-correlation.\n\t- Must supply ``orderby`` argument.\n* ``binary_classification``: create K cross-validation folds where positive/negative label proportion is preserved\n\t- Used for classification task.\n\t- This mode will preserve the positive and negative label proportions in each fold.\n* ``stratified_sampling``: create K cross-validation folds such that the skew distribution of response is preserved \n\t- Used for regression task where the continuous response variable is highly skewed.\n\t- This mode will preserve the skew distribution of the response values by sampling from stratification.\n\t- Must supply ``num_partition`` argument.\n* ``expanding_window``: mainly for time series modeling \n\t- Refer to:\n\n\nTuning for multiple models in parallel\n--------------------------------------\n\nAgain, let's take a look at a specific example data:\n\n.. code:: python\n\n\timport pandas as pd\n\timport numpy as np\n\n\tgroup_col = np.asarray([1]*10 + [2]*10 + [3]*10 + [4]*10 + [5]*10 + [6]*10).reshape(-1, 1)  # this time we have a column specifying group\n\tdata = np.arange(60*4).reshape(60, 4)\n\tdata = np.hstack((data, group_col))\n\tdf = pd.DataFrame(data=data, columns=['target', 'f1', 'f2', 'f3', 'groups'])\n\n\tfeatures = ['f1', 'f2', 'f3']\n\ttarget = 'target'\n\n\tK = 5\n\n\torderby=None\n\tnum_partition=None\n\twindow_size=None\n\n\tfrom skopt.space import Space, Categorical, Integer, Real, Dimension\n\n\tspace  = [Real(0.5, 10),      # learning rate       (learn_rate)\n\t          Real(0, 1),         # gamma               (min_split_improvement)\n\t          Integer(3, 4),      # max_depth           (max_depth)\n\t          Integer(11, 13),    # n_estimators        (ntrees)\n\t          Integer(2, 4),      # min_child_weight    (min_rows)\n\t          Real(0, 1),         # colsample_bytree    (col_sample_rate_per_tree)\n\t          Real(0, 1)]         # subsample           (sample_rate)\n\nWe can tune the models for each group by passing by ``groupby`` argument. \n\n.. code:: python\n\n\tfrom adapter import Adapter\n\n\tadapt = Adapter(df, features, target, K, groupby='groups', \n                cross_validation_scheme='random_shuffle',\n                search_method=\"bayesian_optimization\",\n                estimator=\"xgboost_regression\")  \n\nRun the adapter the same way:\n\n.. code:: python\n\n\tres = adapt.run(num_initial=5, num_iter=15, search_space=space)\n\nYou can visualize the Dask delayed computation graph:\n\n.. figure:: https://github.com/mozjay0619/scikit-optimize-adapter/blob/master/media/multigraph_dashboard.png\n\n\nPassing in an arbitrary callable estimator\n------------------------------------------\n\nYou can pass in an arbitrary callable estimator as long as it implements the standard scikit-learn estimator API: \n\n.. code:: python\n\n\tfrom abc import ABCMeta, abstractmethod\n\n\tclass BaseEstimator(object, metaclass=ABCMeta):\n\t    \"\"\"\n\t    Base class for all Algorithm classes.\n\t    \"\"\"\n\n\t    def __init__(self, **kwargs):\n\t        pass\n\n\t    @abstractmethod\n\t    def fit(self, X, y, params):\n\t        pass\n\n\t    @abstractmethod\n\t    def score(self, X, y):\n\t        pass\n\n\t    @abstractmethod\n\t    def predict(self, X):\n\t        pass \n\nFor example, we can even do something like:\n\n.. code:: python\n\n\tfrom adapter import BaseEstimator  # import BaseEstimator!\n\n\tclass DummyEstimator(BaseEstimator):\n\n\t    def __init__(self):\n\t        pass\n\n\t    def fit(self, train_X, train_y, params):\n\t        a = len(train_X)/10.\n\n\t        for i in range(int(a*5000000)):\n\t            i + 1\n\n\t        print(len(train_X), len(train_y))\n\n\t    def score(self, validation_X, validation_y):\n\n\t        print(len(validation_X), len(validation_y))\n\n\t        return 1.5\n\n\t    def predict(self, test_X):\n\n\t        return len(test_X)\n\n\tmy_estimator = DummyEstimator()\n\nThen you can use it with the Adapter:\n\n.. code:: python\n\n\tfrom adapter import Adapter\n\n\tadapt = Adapter(df, features, target, K, groupby='groups', \n                cross_validation_scheme='random_shuffle',\n                search_method=\"bayesian_optimization\",\n                estimator=my_estimator)  # your own estimator\n\n\nTuning multiple models with highly skewed training data sizes\n-------------------------------------------------------------\n\nWhen the data size for each group is highly skewed, a suboptimal resource allocation can occur. In this case, it is more advantageous to throttle the feeding of delayed graphs to the Dask client by using multiple thread instances. Let's again look at an example case:\n\n.. code:: python\n\n\timport pandas as pd\n\timport numpy as np\n\timport time\n\n\tgroup_col = np.asarray([1]*100 + [2]*2 + [3]*2 + [4]*2 + [5]*2 + [6]*2 + [7]*2 + [8]*2 + [9]*2 + [16]*2 + [26]*2 + [17]*2 + [18]*2 + [19]*2 + [116]*2 + [126]*2).reshape(-1, 1)\n\tdata = np.arange(130*4).reshape(130, 4)\n\tdata = np.hstack((data, group_col))\n\tdf = pd.DataFrame(data=data, columns=['target', 'f1', 'f2', 'f3', 'groups'])\n\n\tfeatures = ['f1', 'f2', 'f3']\n\tgroupby = 'groups'\n\ttarget = 'target'\n\n\tK = 5\n\n\tfrom adapter import BaseEstimator  # import BaseEstimator!\n\n\tclass DummyEstimator(BaseEstimator):\n\n\t    def __init__(self):\n\t        pass\n\n\t    def fit(self, train_X, train_y, params):\n\t        a = len(train_X)/10.\n\n\t        for i in range(int(a*5000000)):\n\t            i + 1\n\n\t        print(len(train_X), len(train_y))\n\n\t    def score(self, validation_X, validation_y):\n\n\t        print(len(validation_X), len(validation_y))\n\n\t        return 1.5\n\n\t    def predict(self, test_X):\n\n\t        return len(test_X)\n\n\tmy_estimator = DummyEstimator()\n\n\torderby=None\n\tnum_partition=None\n\twindow_size=None\n\n\tfrom skopt.space import Space, Categorical, Integer, Real, Dimension\n\n\tspace  = [Real(0.5, 10),      # learning rate       (learn_rate)\n\t          Real(0, 1),         # gamma               (min_split_improvement)\n\t          Integer(3, 4),      # max_depth           (max_depth)\n\t          Integer(11, 13),    # n_estimators        (ntrees)\n\t          Integer(2, 4),      # min_child_weight    (min_rows)\n\t          Real(0, 1),         # colsample_bytree    (col_sample_rate_per_tree)\n\t          Real(0, 1)]         # subsample           (sample_rate)\n\nIn such a case, we use ``run_with_threads`` method call, where we pass an additional argument of ``num_threads``:\n\n.. code:: python\n\n\tfrom adapter import Adapter\n\n\tadapt = Adapter(df, features, target, K, groupby='groups',\n\t        cross_validation_scheme='random_shuffle',\n\t        search_method=\"bayesian_optimization\",\n\t        estimator=my_estimator)  # your own estimator\n\n\tres = adapt.run(num_initial=5, num_iter=15, search_space=space, num_threads=2)  # num_threads\n\nYou can check fromt the Dask dashboard that only two delayed computation graphs are worked on at the same time, achieving a dynamic resource allocation in effect:\n\n.. figure:: https://github.com/mozjay0619/scikit-optimize-adapter/blob/master/media/twograph_dashboard.png\n\n\n\nTodo:\n\n1. rest of the cross validation schemes\n2. testing hard thresholded submit process (and testing speed without it)\n3. supervised encodings\n4. add unit tests\n5. continuous integration set up\n6. random search method\n7. multi GPU environment\n8. documentations\n9. ~~getting the results of the optimization~~\n10. ~~visualization of optimizations~~\n11. early stop criterion using callbacks\n12. ~~beta readme.rst for install and tutorial~~\n13. full readme.rst for install and tutorial\n14. periodic training \n15. bayesian warm start training\n16. dependency managements\n17. active per worker threadpool managements\n\n\n\n\n\n",
    "description_content_type": "text/x-rst",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "DSB 3-clause",
    "maintainer": "",
    "maintainer_email": "",
    "name": "scikit-optimize-adapter",
    "package_url": "https://pypi.org/project/scikit-optimize-adapter/",
    "platform": "",
    "project_url": "https://pypi.org/project/scikit-optimize-adapter/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/scikit-optimize-adapter/0.0b1/",
    "requires_dist": [
      "scikit-optimize (>=0.7.4)",
      "dask",
      "distributed"
    ],
    "requires_python": "",
    "summary": "Dask parallelized bayesian optimization toolbox",
    "version": "0.0b1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 6803565,
  "releases": {
    "0.0b0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b72a93ba5b51cffb2e3c5299ec20825c4458d006935955657e4e36a64c21593c",
          "md5": "b8623a60e819a095cf653c0ba0d2b296",
          "sha256": "ba1c6d898068a6224144048396f2d2707e98f7b3db8c06ceb904f566150a8213"
        },
        "downloads": -1,
        "filename": "scikit_optimize_adapter-0.0b0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "b8623a60e819a095cf653c0ba0d2b296",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 16981,
        "upload_time": "2020-03-10T02:55:42",
        "upload_time_iso_8601": "2020-03-10T02:55:42.828964Z",
        "url": "https://files.pythonhosted.org/packages/b7/2a/93ba5b51cffb2e3c5299ec20825c4458d006935955657e4e36a64c21593c/scikit_optimize_adapter-0.0b0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "18f0f6c99440de47ace27f047d408c763ec1fb99593567cd6077067fdf31e28b",
          "md5": "ef638fdc8aa7990a15fe7fe12786ae35",
          "sha256": "603067d77b9085b4efb3bffb9a8842d20037c0add9989a6df667ba030a326f5b"
        },
        "downloads": -1,
        "filename": "scikit-optimize-adapter-0.0b0.tar.gz",
        "has_sig": false,
        "md5_digest": "ef638fdc8aa7990a15fe7fe12786ae35",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 13622,
        "upload_time": "2020-03-10T02:55:45",
        "upload_time_iso_8601": "2020-03-10T02:55:45.037342Z",
        "url": "https://files.pythonhosted.org/packages/18/f0/f6c99440de47ace27f047d408c763ec1fb99593567cd6077067fdf31e28b/scikit-optimize-adapter-0.0b0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0b1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9a15716fd396be237cf66e778f320cbedc607c4555a51375065428897cda33a8",
          "md5": "2ceb84c3bfb28201a18c2bbf9f44f2af",
          "sha256": "63c326ef19f5e7d224a4788a6163652310e50b04d5f0f66236fb3de9290cddd9"
        },
        "downloads": -1,
        "filename": "scikit_optimize_adapter-0.0b1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "2ceb84c3bfb28201a18c2bbf9f44f2af",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 18695,
        "upload_time": "2020-03-13T04:36:10",
        "upload_time_iso_8601": "2020-03-13T04:36:10.974443Z",
        "url": "https://files.pythonhosted.org/packages/9a/15/716fd396be237cf66e778f320cbedc607c4555a51375065428897cda33a8/scikit_optimize_adapter-0.0b1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ab1ac2cd40e6d34273d8d3ce702d2b8e7bc98e9bf3cb366f89497834548fb42c",
          "md5": "70869bd0cc34167e6a73d73b5bc10a79",
          "sha256": "52295d72b378e60ff94ce350332adb2bedbf6335ad8779e2258c21eb81345837"
        },
        "downloads": -1,
        "filename": "scikit-optimize-adapter-0.0b1.tar.gz",
        "has_sig": false,
        "md5_digest": "70869bd0cc34167e6a73d73b5bc10a79",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 17052,
        "upload_time": "2020-03-13T04:36:12",
        "upload_time_iso_8601": "2020-03-13T04:36:12.568699Z",
        "url": "https://files.pythonhosted.org/packages/ab/1a/c2cd40e6d34273d8d3ce702d2b8e7bc98e9bf3cb366f89497834548fb42c/scikit-optimize-adapter-0.0b1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "9a15716fd396be237cf66e778f320cbedc607c4555a51375065428897cda33a8",
        "md5": "2ceb84c3bfb28201a18c2bbf9f44f2af",
        "sha256": "63c326ef19f5e7d224a4788a6163652310e50b04d5f0f66236fb3de9290cddd9"
      },
      "downloads": -1,
      "filename": "scikit_optimize_adapter-0.0b1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "2ceb84c3bfb28201a18c2bbf9f44f2af",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 18695,
      "upload_time": "2020-03-13T04:36:10",
      "upload_time_iso_8601": "2020-03-13T04:36:10.974443Z",
      "url": "https://files.pythonhosted.org/packages/9a/15/716fd396be237cf66e778f320cbedc607c4555a51375065428897cda33a8/scikit_optimize_adapter-0.0b1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "ab1ac2cd40e6d34273d8d3ce702d2b8e7bc98e9bf3cb366f89497834548fb42c",
        "md5": "70869bd0cc34167e6a73d73b5bc10a79",
        "sha256": "52295d72b378e60ff94ce350332adb2bedbf6335ad8779e2258c21eb81345837"
      },
      "downloads": -1,
      "filename": "scikit-optimize-adapter-0.0b1.tar.gz",
      "has_sig": false,
      "md5_digest": "70869bd0cc34167e6a73d73b5bc10a79",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 17052,
      "upload_time": "2020-03-13T04:36:12",
      "upload_time_iso_8601": "2020-03-13T04:36:12.568699Z",
      "url": "https://files.pythonhosted.org/packages/ab/1a/c2cd40e6d34273d8d3ce702d2b8e7bc98e9bf3cb366f89497834548fb42c/scikit-optimize-adapter-0.0b1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}