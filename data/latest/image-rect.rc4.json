{
  "info": {
    "author": "Justin Blaber",
    "author_email": "justin.akira.blaber@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: Apache Software License",
      "Natural Language :: English",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8"
    ],
    "description": "```python\n# default_exp image_rect\n```\n\n# Image Rectification\n\n\n```python\n# export\nimport numpy as np\nimport PIL\nimport torch\nfrom camera_calib.modules import Inverse\nfrom camera_calib.utils import *\n```\n\n\n```python\nimport re\nfrom pathlib import Path\n\nimport camera_calib.api as api\nimport matplotlib.pyplot as plt\nimport scipy\nfrom camera_calib.modules import Rigids\nfrom camera_calib.plot import plot_extrinsics\nfrom camera_calib.utils import *\n```\n\n# Utility\n\n\n```python\n# export\ndef save_16bit(arr, file_img):\n    pim = PIL.Image.fromarray((torch2np(arr)*(2**16-1)).astype(np.uint16), mode='I;16')\n    pim.save(file_img)    \n```\n\n\n```python\n# export\ndef distort_coords(ps_p, cam, distort):\n    p2pd = torch.nn.Sequential(Inverse(cam), distort, cam)\n    return p2pd(ps_p)\n```\n\n\n```python\n# export\ndef undistort_array(arr, cam, distort, **kwargs):\n    return interp_array(arr, distort_coords(array_ps(arr), cam, distort), **kwargs).reshape(arr.shape)\n```\n\n# Rectify\n\n\n```python\ndir_imgs = Path('data/dot_vision_checker')\n```\n\n\n```python\ndef _parse_name(name_img):\n    match = re.match(r'''SERIAL_(?P<serial>.*)_\n                         DATETIME_(?P<date>.*)_\n                         CAM_(?P<cam>.*)_\n                         FRAMEID_(?P<frameid>.*)_\n                         COUNTER_(?P<counter>.*).png''', \n                     name_img, \n                     re.VERBOSE)\n    return match.groupdict()\n```\n\n\n```python\nimgs = []\nfor file_img in dir_imgs.glob('*.png'):\n    dict_group = _parse_name(file_img.name)\n    img = api.File16bitImg(file_img)\n    img.idx_cam = int(dict_group['cam'])-1\n    img.idx_cb  = int(dict_group['counter'])-1\n    imgs.append(img)\n```\n\n\n```python\nfor img in imgs: print(f'{img.name} - cam: {img.idx_cam} - cb: {img.idx_cb}')\n```\n\n    SERIAL_16276941_DATETIME_2019-06-07-00:38:48-109732_CAM_2_FRAMEID_0_COUNTER_2 - cam: 1 - cb: 1\n    SERIAL_19061245_DATETIME_2019-06-07-00:38:19-438594_CAM_1_FRAMEID_0_COUNTER_1 - cam: 0 - cb: 0\n    SERIAL_16276941_DATETIME_2019-06-07-00:39:19-778185_CAM_2_FRAMEID_0_COUNTER_3 - cam: 1 - cb: 2\n    SERIAL_16276941_DATETIME_2019-06-07-00:38:19-438631_CAM_2_FRAMEID_0_COUNTER_1 - cam: 1 - cb: 0\n    SERIAL_19061245_DATETIME_2019-06-07-00:39:19-778134_CAM_1_FRAMEID_0_COUNTER_3 - cam: 0 - cb: 2\n    SERIAL_19061245_DATETIME_2019-06-07-00:38:48-109705_CAM_1_FRAMEID_0_COUNTER_2 - cam: 0 - cb: 1\n\n\n## Calibrate\n\nDo a simple calibration\n\n\n```python\nh_cb = 50.8\nw_cb = 50.8\nh_f = 42.672\nw_f = 42.672\nnum_c_h = 16\nnum_c_w = 16\nspacing_c = 2.032\ncb_geom = api.CbGeom(h_cb, w_cb,\n                     api.CpCSRGrid(num_c_h, num_c_w, spacing_c),\n                     api.FmCFPGrid(h_f, w_f))\n```\n\n\n```python\nfile_model = Path('models/dot_vision_checker.pth')\ndetector = api.DotVisionCheckerDLDetector(file_model)\n```\n\n\n```python\nrefiner = api.OpenCVCheckerRefiner(hw_min=5, hw_max=15, cutoff_it=20, cutoff_norm=1e-3)\n```\n\n\n```python\ncalib = api.multi_calib(imgs, cb_geom, detector, refiner)\n```\n\n    Refining control points for: SERIAL_19061245_DATETIME_2019-06-07-00:38:19-438594_CAM_1_FRAMEID_0_COUNTER_1...\n    Refining control points for: SERIAL_19061245_DATETIME_2019-06-07-00:39:19-778134_CAM_1_FRAMEID_0_COUNTER_3...\n    Refining control points for: SERIAL_19061245_DATETIME_2019-06-07-00:38:48-109705_CAM_1_FRAMEID_0_COUNTER_2...\n    Refining single parameters...\n     - Iteration: 000 - Norm:    0.02117 - Loss:   64.08690\n     - Iteration: 001 - Norm:    0.03960 - Loss:   58.11754\n     - Iteration: 002 - Norm:    0.47925 - Loss:   11.09834\n     - Iteration: 003 - Norm:    0.17388 - Loss:    7.19586\n     - Iteration: 004 - Norm:    0.07121 - Loss:    6.74723\n     - Iteration: 005 - Norm:    2.31742 - Loss:    6.59264\n     - Iteration: 006 - Norm:    3.20527 - Loss:    6.44872\n     - Iteration: 007 - Norm:   34.39009 - Loss:    4.86668\n     - Iteration: 008 - Norm:    0.00000 - Loss:    4.86668\n    Refining control points for: SERIAL_16276941_DATETIME_2019-06-07-00:38:48-109732_CAM_2_FRAMEID_0_COUNTER_2...\n    Refining control points for: SERIAL_16276941_DATETIME_2019-06-07-00:39:19-778185_CAM_2_FRAMEID_0_COUNTER_3...\n    Refining control points for: SERIAL_16276941_DATETIME_2019-06-07-00:38:19-438631_CAM_2_FRAMEID_0_COUNTER_1...\n    Refining single parameters...\n     - Iteration: 000 - Norm:    0.04097 - Loss:  179.67769\n     - Iteration: 001 - Norm:    0.12849 - Loss:  112.14013\n     - Iteration: 002 - Norm:    0.58911 - Loss:   31.40931\n     - Iteration: 003 - Norm:    0.37932 - Loss:    6.19159\n     - Iteration: 004 - Norm:    0.19770 - Loss:    6.09586\n     - Iteration: 005 - Norm:   30.72789 - Loss:    4.46654\n     - Iteration: 006 - Norm:    2.63332 - Loss:    4.28983\n     - Iteration: 007 - Norm:    0.00000 - Loss:    4.28983\n    Refining multi parameters...\n     - Iteration: 000 - Norm:    0.00099 - Loss:   31.31317\n     - Iteration: 001 - Norm:    0.00384 - Loss:   24.25675\n     - Iteration: 002 - Norm:    0.00405 - Loss:   19.39406\n     - Iteration: 003 - Norm:    0.00586 - Loss:   17.16208\n     - Iteration: 004 - Norm:    0.00608 - Loss:   15.65026\n     - Iteration: 005 - Norm:    0.00271 - Loss:   15.15424\n     - Iteration: 006 - Norm:    0.01001 - Loss:   14.03451\n     - Iteration: 007 - Norm:    0.00075 - Loss:   13.91239\n     - Iteration: 008 - Norm:    0.00032 - Loss:   13.90795\n     - Iteration: 009 - Norm:    0.00516 - Loss:   13.85823\n     - Iteration: 010 - Norm:    0.00545 - Loss:   13.83085\n     - Iteration: 011 - Norm:    0.03479 - Loss:   13.66085\n     - Iteration: 012 - Norm:    0.00280 - Loss:   13.65038\n     - Iteration: 013 - Norm:    0.03373 - Loss:   13.49903\n     - Iteration: 014 - Norm:    0.00994 - Loss:   13.45923\n     - Iteration: 015 - Norm:    0.00458 - Loss:   13.45677\n     - Iteration: 016 - Norm:    0.00000 - Loss:   13.45677\n     - Iteration: 017 - Norm:    0.00000 - Loss:   13.45677\n\n\n\n```python\napi.plot_residuals(calib);\n```\n\n\n![png](README_files/README_19_0.png)\n\n\n\n```python\napi.plot_extrinsics(calib);\n```\n\n\n![png](README_files/README_20_0.png)\n\n\n\n```python\napi.save(calib, 'data/calib.pth')\n```\n\nFreeze above and just load\n\n\n```python\ncalib = api.load('data/calib.pth')\n```\n\nParse stuff out\n\n\n```python\ncam1,       cam2       = calib['cams'][0],       calib['cams'][1]\ndistort1,   distort2   = calib['distorts'][0],   calib['distorts'][1]\nrigid_cam1, rigid_cam2 = calib['rigids_cam'][0], calib['rigids_cam'][1]\n```\n\n## Essential and Fundamental matrices\n\nNormally you would need normalized points (i.e. knowledge of camera matrices) to get the essential matrix, but if you know relative pose via camera calibration, you can compute it directly.\n\n\n```python\n# export\ndef get_essential(R12, t12): return cross_mat(t12)@R12\n```\n\nFundamental matrix only need pixel points, but is also calculable from camera calibration. \n\n\n```python\n# export\n@numpyify\ndef get_fundamental(R12, t12, A1, A2):\n    E = get_essential(R12, t12)\n    return torch.inverse(A2.T)@E@torch.inverse(A1)\n```\n\nGet two example images\n\n\n```python\nidx_cb = 1\n```\n\n\n```python\n[img1] = [img for img in imgs if img.idx_cb == idx_cb and img.idx_cam == 0]\n[img2] = [img for img in imgs if img.idx_cb == idx_cb and img.idx_cam == 1]\nimg1, img2\n```\n\n\n\n\n    (File16bitImg(SERIAL_19061245_DATETIME_2019-06-07-00:38:48-109705_CAM_1_FRAMEID_0_COUNTER_2),\n     File16bitImg(SERIAL_16276941_DATETIME_2019-06-07-00:38:48-109732_CAM_2_FRAMEID_0_COUNTER_2))\n\n\n\nLoad distorted arrays\n\n\n```python\narr1_d = img1.array_gs(torch.double)\narr2_d = img2.array_gs(torch.double)\n```\n\nUndistort arrays first\n\n\n```python\nwith torch.no_grad():\n    arr1_u = undistort_array(arr1_d, cam1, distort1)\n    arr2_u = undistort_array(arr2_d, cam2, distort2)\n```\n\nI've already computed some corresponding points in undistorted coordinates\n\n\n```python\nps1_u = torch.DoubleTensor([[1302.6686,  589.8210],\n                            [ 836.5483,  544.9905],\n                            [1189.6493, 1161.7684],\n                            [ 723.1662, 1187.0083]])\nps2_u = torch.DoubleTensor([[1072.0118,  565.5825],\n                            [ 366.8702,  528.9731],\n                            [1001.8763, 1227.6773],\n                            [ 322.3230, 1235.3946]])\n```\n\n\n```python\nidx = 3\np1_u = ps1_u[idx]\np2_u = ps2_u[idx]\n```\n\n\n```python\n_, axs = plt.subplots(1, 2, figsize=(20,20))\nfor ax, arr_u, p_u in zip(axs, [arr1_u, arr2_u], [p1_u, p2_u]):\n    ax.imshow(arr_u, cmap='gray')\n    ax.plot(p_u[0], p_u[1], 'rs')\n```\n\n\n![png](README_files/README_41_0.png)\n\n\nGet rigid transform of camera 1 WRT camera 2\n\n\n```python\nM12 = Rigids([rigid_cam1, Inverse(rigid_cam2)]).get_param()\nR12, t12 = M2Rt(M12)\nR12, t12\n```\n\n\n\n\n    (tensor([[ 9.2331e-01,  3.7136e-03,  3.8403e-01],\n             [-3.1065e-03,  9.9999e-01, -2.2013e-03],\n             [-3.8403e-01,  8.3953e-04,  9.2332e-01]], dtype=torch.float64),\n     tensor([-8.3587e+01,  6.6860e-02, -6.9031e+00], dtype=torch.float64))\n\n\n\n\n```python\nA1 = cam1.get_param()\nA2 = cam2.get_param()\nA1, A2\n```\n\n\n\n\n    (tensor([[3.6029e+03, 0.0000e+00, 9.9590e+02],\n             [0.0000e+00, 3.6029e+03, 7.7632e+02],\n             [0.0000e+00, 0.0000e+00, 1.0000e+00]], dtype=torch.float64),\n     tensor([[3.5914e+03, 0.0000e+00, 1.0454e+03],\n             [0.0000e+00, 3.5914e+03, 7.9239e+02],\n             [0.0000e+00, 0.0000e+00, 1.0000e+00]], dtype=torch.float64))\n\n\n\n\n```python\nF = get_fundamental(R12, t12, A1, A2)\nF\n```\n\n\n\n\n    tensor([[-3.6417e-09,  5.3350e-07, -3.9758e-04],\n            [-2.9734e-06,  3.4421e-09,  2.3710e-02],\n            [ 2.4148e-03, -2.3760e-02, -2.5805e-01]], dtype=torch.float64)\n\n\n\nCheck if these points satisfy constraint\n\n\n```python\naugment(p2_u).T@F@augment(p1_u)\n```\n\n\n\n\n    tensor(-7.8241e-07, dtype=torch.float64)\n\n\n\nAppears close to zero... Lets try to plot epipolar lines\n\n\n```python\ndef plot_epi(ps1, F, arr1, arr2):\n    fig, axs = plt.subplots(1, 2, figsize=(20,20))\n    for arr, ax in zip([arr1, arr2], axs): ax.imshow(arr, cmap='gray')\n    b_arr2 = bb2b(array_bb(arr2))  \n    cs = get_colors(len(ps1))\n    for p1, c in zip(ps1, cs):\n        l2 = F@augment(p1)\n        ps2_epi = b_l_intersect(b_arr2, l2)\n        axs[0].plot(p1[0], p1[1], marker='s', c=c)\n        axs[1].plot(ps2_epi[:, 0], ps2_epi[:, 1], c=c)\n```\n\n\n```python\nplot_epi(ps1_u, F, arr1_u, arr2_u)\n```\n\n\n![png](README_files/README_50_0.png)\n\n\nEpipolar lines look to intersect the same points on the right image\n\nQuick check to see if nullspace of fundamental matrix is the same as the epipole\n\n\n```python\ne = scipy.linalg.null_space(F)\ne /= e[-1]\ne\n```\n\n\n\n\n    array([[7.97506373e+03],\n           [7.99672254e+02],\n           [1.00000000e+00]])\n\n\n\n\n```python\ne = -R12.T@t12 # Transform origin of second camera\ne = e/e[-1]    # Normalize\ne = A1@e       # Apply camera matrix\ne\n```\n\n\n\n\n    tensor([7.9751e+03, 7.9967e+02, 1.0000e+00], dtype=torch.float64)\n\n\n\n## Fusiello Rectification\n\nThis method is easier to understand and implement, so lets try it first.\n\n\n```python\n# export\n@numpyify\ndef rigid_rect_fusi(M1, M2):\n    R1, t1 = M2Rt(M1)\n    _,  t2 = M2Rt(M2)\n\n    # Get rotation matrix\n    r1 = t2-t1                     # new x-axis should be parallel to t1->t2 after rotation\n    r2 = torch.cross(R1[:, 2], r1) # new y-axis is orthogonal to camera 1's old z axis and new x-axis\n    r3 = torch.cross(r1, r2)       # new z-axis is orthogonal to new x and y axes\n    r1, r2, r3 = unitize(stackify((r1, r2, r3)))\n    R_r = stackify((r1, r2, r3), dim=1)\n\n    return Rt2M(R_r, t1), Rt2M(R_r, t2)\n```\n\n\n```python\nM1 = rigid_cam1.get_param()\nM2 = rigid_cam2.get_param()\n```\n\n\n```python\nM1_r, M2_r = rigid_rect_fusi(M1, M2)\nM1_r, M2_r\n```\n\n\n\n\n    (tensor([[ 0.8886, -0.0033, -0.4587,  0.0000],\n             [ 0.0030,  1.0000, -0.0015,  0.0000],\n             [ 0.4587,  0.0000,  0.8886,  0.0000],\n             [ 0.0000,  0.0000,  0.0000,  1.0000]], dtype=torch.float64),\n     tensor([[ 8.8858e-01, -3.3457e-03, -4.5872e-01,  7.4526e+01],\n             [ 2.9730e-03,  9.9999e-01, -1.5348e-03,  2.4935e-01],\n             [ 4.5872e-01,  0.0000e+00,  8.8858e-01,  3.8474e+01],\n             [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n            dtype=torch.float64))\n\n\n\nOne good check is to rectify twice, which should return the same inputs\n\n\n```python\nassert_allclose(rigid_rect_fusi(M1_r, M2_r), (M1_r, M2_r))\n```\n\nGet rectified camera matrices\n\n\n```python\n# export\ndef cam_rect_fusi(A1, A2):\n    A_r = (A1 + A2)/2\n    return A_r, A_r\n```\n\n\n```python\nA1_r, A2_r = cam_rect_fusi(A1, A2)\nA1_r, A2_r\n```\n\n\n\n\n    (tensor([[3.5971e+03, 0.0000e+00, 1.0207e+03],\n             [0.0000e+00, 3.5971e+03, 7.8436e+02],\n             [0.0000e+00, 0.0000e+00, 1.0000e+00]], dtype=torch.float64),\n     tensor([[3.5971e+03, 0.0000e+00, 1.0207e+03],\n             [0.0000e+00, 3.5971e+03, 7.8436e+02],\n             [0.0000e+00, 0.0000e+00, 1.0000e+00]], dtype=torch.float64))\n\n\n\nGet rectifying homographies\n\n\n```python\n# export\n@numpyify\ndef rect_homography(A, M, A_r, M_r):\n    (R, t), (R_r, t_r) = map(M2Rt, [M, M_r])\n    assert_allclose(t, t_r) # There can be no change in translation for rectification; only rotation\n    return A@R.T@R_r@torch.inverse(A_r)\n```\n\n\n```python\nH1 = rect_homography(A1, M1, A1_r, M1_r)\nH2 = rect_homography(A2, M2, A2_r, M2_r)\n```\n\nRectify images\n\n\n```python\n# export\ndef rect_array(arr_d, H, cam, distort):\n    ps_pr = array_ps(arr_d)                                 # Get rectified pixel coordinates\n    ps_p  = pmm(ps_pr, H, aug=True)                         # Get pixel coordinates\n    ps_pd = distort_coords(ps_p, cam, distort)              # Get distorted coordinates\n    arr_r = interp_array(arr_d, ps_pd).reshape(arr_d.shape) # Rectify and undistort image\n    return arr_r\n```\n\n\n```python\nwith torch.no_grad():\n    arr1_r = rect_array(arr1_d, H1, cam1, distort1)\n    arr2_r = rect_array(arr2_d, H2, cam2, distort2)\n```\n\n\n```python\nfig, axs = plt.subplots(2, 2, figsize=(20,15))\naxs[0,0].imshow(arr1_d, cmap='gray')\naxs[0,1].imshow(arr2_d, cmap='gray')\naxs[1,0].imshow(arr1_r, cmap='gray')\naxs[1,1].imshow(arr2_r, cmap='gray');\n```\n\n\n![png](README_files/README_71_0.png)\n\n\nTo see why the left image is mostly out of FOV, we plot the extrinsics:\n\n\n```python\nfig = plt.figure(figsize=(20,15))\n\nax = fig.add_subplot(1, 2, 1, projection='3d')\nplot_extrinsics([rigid_cb.get_param() for rigid_cb in calib['rigids_cb']], \n                [M1, M2],\n                calib['cb_geom'], \n                ax=ax)\nax.view_init(elev=90, azim=-90)\n\nax = fig.add_subplot(1, 2, 2, projection='3d')\nplot_extrinsics([rigid_cb.get_param() for rigid_cb in calib['rigids_cb']], \n                [M1_r, M2_r],\n                calib['cb_geom'],\n                ax=ax)\nax.view_init(elev=90, azim=-90)\n```\n\n\n![png](README_files/README_73_0.png)\n\n\nThe left camera rotates so much that the image goes out of FOV. You can actually fix this by adjusting the camera matrix, but that wasn't included in Fusiello's original paper. I actually like Bouguet's method better though, so we'll do that first.\n\n## Bouguet Rectification\n\n### Rigid Rectification\n\nBouguet's method aligns cameras by taking mid point rotation (via rodrigues parameterization), then it aligns it by doing shortest rotation to lines formed by principle points.\n\n\n```python\n# export\n@numpyify\ndef rigid_rect_boug(M1, M2):\n    R1, t1 = M2Rt(M1)\n    _,  t2 = M2Rt(M2)\n\n    # First, get mid-point rotation so both cameras are aligned\n    R12, t12 = M2Rt(invert_rigid(M2)@M1)\n    r12 = R2rodrigues(R12)\n    R12_half = rodrigues2R(r12/2)\n\n    # Next, get rotation so both cameras are aligned to p1->p2\n    Rx = v_v_R(R12_half.T@t12, M1.new_tensor([-1, 0, 0]))\n\n    # Compose to get rectified rotations\n    # Note that: \n    #     R_r = R2@R12_half@Rx.T\n    # As well\n    R_r = R1@R12_half.T@Rx.T\n\n    return Rt2M(R_r, t1), Rt2M(R_r, t2)\n```\n\n\n```python\nM1_r, M2_r = rigid_rect_boug(M1, M2)\nM1_r, M2_r\n```\n\n\n\n\n    (tensor([[ 8.8858e-01, -2.6739e-03, -4.5872e-01,  0.0000e+00],\n             [ 2.9730e-03,  1.0000e+00, -7.0170e-05,  0.0000e+00],\n             [ 4.5872e-01, -1.3014e-03,  8.8858e-01,  0.0000e+00],\n             [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n            dtype=torch.float64),\n     tensor([[ 8.8858e-01, -2.6739e-03, -4.5872e-01,  7.4526e+01],\n             [ 2.9730e-03,  1.0000e+00, -7.0170e-05,  2.4935e-01],\n             [ 4.5872e-01, -1.3014e-03,  8.8858e-01,  3.8474e+01],\n             [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n            dtype=torch.float64))\n\n\n\nOne good check is to rectify twice, which should return the same inputs\n\n\n```python\nassert_allclose(rigid_rect_boug(M1_r, M2_r), (M1_r, M2_r))\n```\n\nGet rectified camera matricies\n\n\n```python\nA1_r, A2_r = cam_rect_fusi(A1, A2)\n```\n\nRectify images\n\n\n```python\nH1 = rect_homography(A1, M1, A1_r, M1_r)\nH2 = rect_homography(A2, M2, A2_r, M2_r)\n```\n\n\n```python\nwith torch.no_grad():\n    arr1_r = rect_array(arr1_d, H1, cam1, distort1)\n    arr2_r = rect_array(arr2_d, H2, cam2, distort2)\n```\n\n\n```python\nfig, axs = plt.subplots(2, 2, figsize=(20,15))\naxs[0,0].imshow(arr1_d, cmap='gray')\naxs[0,1].imshow(arr2_d, cmap='gray')\naxs[1,0].imshow(arr1_r, cmap='gray')\naxs[1,1].imshow(arr2_r, cmap='gray');\n```\n\n\n![png](README_files/README_87_0.png)\n\n\nFirst image is still out of FOV, but the second image is better aligned in Bouguet's method, which makes sense because Fusiello's method only takes the rotation of the first camera into account.\n\n### Camera Rectification\n\nFor rectification, in terms of extrinsics, you can only rotate the cameras. This alone may cause problems if one of the cameras rotates a lot. To fix this issue, you can also modify the intrinsics (camera matrices), but they must have the following constraints:\n\n* Focal points should be the same to ensure epipolar lines are \"spaced the same\"\n* The y component of the principle point should be the same to ensure the lines are collinear\n* The x component can be different\n\nAs long as we follow the above, the epipolar lines will be horizontal and aligned.\n\n\n```python\n# export\n@numpyify\ndef cam_rect_boug(A1, A2, M1, M2, M1_r, M2_r, sz):\n    zero = A1.new_tensor(0)\n\n    (R1, _), (R1_r, _) = M2Rt(M1), M2Rt(M1_r)\n    (R2, _), (R2_r, _) = M2Rt(M2), M2Rt(M2_r)\n\n    # Get focal length\n    alpha = stackify((A1[[0,1],[0,1]], A2[[0,1],[0,1]])).mean()\n    A_alpha = stackify(((alpha, zero),\n                        (zero,  alpha)))\n\n    # Get new principle points such that center of image gets mapped close to rectified center\n    def _get_po_pr(A, R, R_r):\n        po_nr = pmm(po_p, R_r.T@R@torch.inverse(A), aug=True)\n        po_pr = po_p - pmm(A_alpha, po_nr)\n        return po_pr\n    po_p = (sz[[1,0]]-1)/2  \n    po_pr1, po_pr2 = _get_po_pr(A1, R1, R1_r), _get_po_pr(A2, R2, R2_r)\n    xo_r1, xo_r2 = po_pr1[0], po_pr2[0]\n    yo_r = (po_pr1[1]+po_pr2[1])/2\n\n    # Create camera matrices\n    def _get_A(xo_r):\n        return torch.cat([torch.cat([A_alpha, stackify((((xo_r,), (yo_r,))))], dim=1), \n                          A1.new_tensor([[0, 0, 1]])])\n    return _get_A(xo_r1), _get_A(xo_r2)\n```\n\n\n```python\nA1_r, A2_r = cam_rect_boug(A1, A2, M1, M2, M1_r, M2_r, shape(arr1_d))\nA1_r, A2_r\n```\n\n\n\n\n    (tensor([[ 3.5971e+03,  0.0000e+00, -8.6848e+02],\n             [ 0.0000e+00,  3.5971e+03,  7.8647e+02],\n             [ 0.0000e+00,  0.0000e+00,  1.0000e+00]], dtype=torch.float64),\n     tensor([[3.5971e+03, 0.0000e+00, 7.4850e+02],\n             [0.0000e+00, 3.5971e+03, 7.8647e+02],\n             [0.0000e+00, 0.0000e+00, 1.0000e+00]], dtype=torch.float64))\n\n\n\nRectify images\n\n\n```python\nH1 = rect_homography(A1, M1, A1_r, M1_r)\nH2 = rect_homography(A2, M2, A2_r, M2_r)\n```\n\n\n```python\nwith torch.no_grad():\n    arr1_r = rect_array(arr1_d, H1, cam1, distort1)\n    arr2_r = rect_array(arr2_d, H2, cam2, distort2)\n```\n\n\n```python\nfig, axs = plt.subplots(2, 2, figsize=(20,15))\naxs[0,0].imshow(arr1_d, cmap='gray')\naxs[0,1].imshow(arr2_d, cmap='gray')\naxs[1,0].imshow(arr1_r, cmap='gray')\naxs[1,1].imshow(arr2_r, cmap='gray');\n```\n\n\n![png](README_files/README_96_0.png)\n\n\nMuch better; plot epipolar lines to confirm they are rectified\n\n\n```python\nR12, t12 = M2Rt(invert_rigid(M2_r)@M1_r)\n```\n\n\n```python\nF = get_fundamental(R12, t12, A1_r, A2_r)\n```\n\n\n```python\nplot_epi(pmm(ps1_u, torch.inverse(H1), aug=True), F, arr1_r, arr2_r)\n```\n\n\n![png](README_files/README_100_0.png)\n\n\nLooks pretty good\n\n# API\n\n\n```python\n# export\ndef rectify(calib):\n    assert_allclose(len(calib['cams']), 2)\n\n    As = [cam.get_param() for cam in calib['cams']]\n    Ms = [rig.get_param() for rig in calib['rigids_cam']]\n    sz = As[0].new_tensor(calib['imgs'][0].size)\n\n    # TODO: Add option to choose different types of rectification\n    Ms_r = rigid_rect_boug(*Ms)\n    As_r = cam_rect_boug(*As, *Ms, *Ms_r, sz)\n    Hs = [rect_homography(A, M, A_r, M_r) for A, M, A_r, M_r in zip(As, Ms, As_r, Ms_r)]\n\n    return {'Hs': Hs,\n            'As_r': As_r,\n            'Ms_r': Ms_r,\n            'cams': calib['cams'], \n            'distorts': calib['distorts'],\n            'dtype': calib['dtype'],\n            'device': calib['device']}\n```\n\n\n```python\n# export\ndef rect_img(img, rect):\n    assert_allclose(hasattr(img, 'idx_cam'), True)\n    idx = img.idx_cam\n\n    return rect_array(img.array_gs(rect['dtype'], rect['device']),\n                      rect['Hs'][idx],\n                      rect['cams'][idx],\n                      rect['distorts'][idx])\n```\n\n\n```python\nrect = rectify(calib)\n```\n\n\n```python\nwith torch.no_grad():\n    arr1_r = rect_img(img1, rect)\n    arr2_r = rect_img(img2, rect)\n```\n\n\n```python\n_, axs = plt.subplots(2, 2, figsize=(20,15))\naxs[0,0].imshow(arr1_d, cmap='gray')\naxs[0,1].imshow(arr2_d, cmap='gray')\naxs[1,0].imshow(arr1_r, cmap='gray')\naxs[1,1].imshow(arr2_r, cmap='gray')\n```\n\n\n\n\n    <matplotlib.image.AxesImage at 0x7f159ccc1ef0>\n\n\n\n\n![png](README_files/README_107_1.png)\n\n\n# Build\n\n\n```python\nbuild_notebook()\n```\n\n\n    <IPython.core.display.Javascript object>\n\n\n    Converted README.ipynb.\n\n\n\n```python\nconvert_notebook()\n```\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/justinblaber/image_rect/tree/master/",
    "keywords": "image rectification",
    "license": "Apache Software License 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "image-rect",
    "package_url": "https://pypi.org/project/image-rect/",
    "platform": "",
    "project_url": "https://pypi.org/project/image-rect/",
    "project_urls": {
      "Homepage": "https://github.com/justinblaber/image_rect/tree/master/"
    },
    "release_url": "https://pypi.org/project/image-rect/0.0.4/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "Image Rectification with pytorch",
    "version": "0.0.4",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 7973940,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "80e557ac101424d584e90bf728ddc3a6b3318ef3f0758f0c256621e740065d74",
          "md5": "101904e6a856d75daa79141eebf126ce",
          "sha256": "ee2cb0bac5030ee1564db2e2f268e6d515be9340445dd8bdd8565283272d8fa6"
        },
        "downloads": -1,
        "filename": "image_rect-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "101904e6a856d75daa79141eebf126ce",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 14144,
        "upload_time": "2020-07-26T21:00:09",
        "upload_time_iso_8601": "2020-07-26T21:00:09.095791Z",
        "url": "https://files.pythonhosted.org/packages/80/e5/57ac101424d584e90bf728ddc3a6b3318ef3f0758f0c256621e740065d74/image_rect-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e9f5d5168a0ae08aebe69ea602571225207b969961e386ff0815df0c526129ff",
          "md5": "19364e3a808abd7a1fa5dc3e7895d001",
          "sha256": "17d4c806b3fde48d756af1206a7c18dc59e288afeb08e8decde82deb18e7fc86"
        },
        "downloads": -1,
        "filename": "image_rect-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "19364e3a808abd7a1fa5dc3e7895d001",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 22293,
        "upload_time": "2020-07-26T21:00:19",
        "upload_time_iso_8601": "2020-07-26T21:00:19.258780Z",
        "url": "https://files.pythonhosted.org/packages/e9/f5/d5168a0ae08aebe69ea602571225207b969961e386ff0815df0c526129ff/image_rect-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4d5ae0c91ea146510e74a398690653404ac995ced2b1d5b91ca6caaae03891de",
          "md5": "c515b6f69f0e6e4dc3d7d74794274ead",
          "sha256": "b69a6ca1b8050bfddb7f8ee46b0457dca162f70e01b4cf4d36e3152c4d4292f2"
        },
        "downloads": -1,
        "filename": "image_rect-0.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "c515b6f69f0e6e4dc3d7d74794274ead",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 14843,
        "upload_time": "2020-08-07T02:09:22",
        "upload_time_iso_8601": "2020-08-07T02:09:22.679857Z",
        "url": "https://files.pythonhosted.org/packages/4d/5a/e0c91ea146510e74a398690653404ac995ced2b1d5b91ca6caaae03891de/image_rect-0.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "deddc8363079fba28564c481784c314a842129b11394c46742791a73106e2b98",
          "md5": "8f9dc97953568694ce3fa056e6b87c4d",
          "sha256": "0e61795de7b7b0a67bb0dd601338f3c7eb0f78d6af9062f54a3bc1245af7eb42"
        },
        "downloads": -1,
        "filename": "image_rect-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "8f9dc97953568694ce3fa056e6b87c4d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 24578,
        "upload_time": "2020-08-07T02:09:24",
        "upload_time_iso_8601": "2020-08-07T02:09:24.642869Z",
        "url": "https://files.pythonhosted.org/packages/de/dd/c8363079fba28564c481784c314a842129b11394c46742791a73106e2b98/image_rect-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8880c5b8b442e94b4d03db465009d6868e4be8341b0a49c2ed33f6d620c07bcd",
          "md5": "43852db495c85cba4c4e7df7fac4cc12",
          "sha256": "65d6a234051900c11657aa6a16d240a516305101453b6c9fcc2428b8866ecf55"
        },
        "downloads": -1,
        "filename": "image_rect-0.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "43852db495c85cba4c4e7df7fac4cc12",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 14853,
        "upload_time": "2020-08-16T01:25:36",
        "upload_time_iso_8601": "2020-08-16T01:25:36.339860Z",
        "url": "https://files.pythonhosted.org/packages/88/80/c5b8b442e94b4d03db465009d6868e4be8341b0a49c2ed33f6d620c07bcd/image_rect-0.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4d0c68a441c1bece1c0f55ef8666552a6f1a97bdda1fa3f606d509e8dfd07af2",
          "md5": "0b22ef0975de480db540ffa3e317f845",
          "sha256": "b20dc1f480889aa67ac012942d4b09ed044c4af87c533db115169ccf694dd8c5"
        },
        "downloads": -1,
        "filename": "image_rect-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "0b22ef0975de480db540ffa3e317f845",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 24581,
        "upload_time": "2020-08-16T01:25:38",
        "upload_time_iso_8601": "2020-08-16T01:25:38.215068Z",
        "url": "https://files.pythonhosted.org/packages/4d/0c/68a441c1bece1c0f55ef8666552a6f1a97bdda1fa3f606d509e8dfd07af2/image_rect-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7033a9e5ae08ecb2a58196f8357041c2a3d3248a84ca25ae56c79908c500238c",
          "md5": "8abc784a6bc99775dcf0b40e1b5f0155",
          "sha256": "195dfbf8181d2276d23dc98e14fc37c46693600a7812afb5856eb1d0ca7a5953"
        },
        "downloads": -1,
        "filename": "image_rect-0.0.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "8abc784a6bc99775dcf0b40e1b5f0155",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 14870,
        "upload_time": "2020-08-16T20:44:25",
        "upload_time_iso_8601": "2020-08-16T20:44:25.752673Z",
        "url": "https://files.pythonhosted.org/packages/70/33/a9e5ae08ecb2a58196f8357041c2a3d3248a84ca25ae56c79908c500238c/image_rect-0.0.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "21ec4bf8aeeaa38db40e9a2c6237db3e9f156b5471ebd7089518fbd1fb81b910",
          "md5": "04c49264471bf96781a5a271a9eeb6c9",
          "sha256": "43a445ace88d613fa83a4944513b2f6f07ed51e4f91970f618475e153aba9c3f"
        },
        "downloads": -1,
        "filename": "image_rect-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "04c49264471bf96781a5a271a9eeb6c9",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 24598,
        "upload_time": "2020-08-16T20:44:27",
        "upload_time_iso_8601": "2020-08-16T20:44:27.878778Z",
        "url": "https://files.pythonhosted.org/packages/21/ec/4bf8aeeaa38db40e9a2c6237db3e9f156b5471ebd7089518fbd1fb81b910/image_rect-0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "7033a9e5ae08ecb2a58196f8357041c2a3d3248a84ca25ae56c79908c500238c",
        "md5": "8abc784a6bc99775dcf0b40e1b5f0155",
        "sha256": "195dfbf8181d2276d23dc98e14fc37c46693600a7812afb5856eb1d0ca7a5953"
      },
      "downloads": -1,
      "filename": "image_rect-0.0.4-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "8abc784a6bc99775dcf0b40e1b5f0155",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 14870,
      "upload_time": "2020-08-16T20:44:25",
      "upload_time_iso_8601": "2020-08-16T20:44:25.752673Z",
      "url": "https://files.pythonhosted.org/packages/70/33/a9e5ae08ecb2a58196f8357041c2a3d3248a84ca25ae56c79908c500238c/image_rect-0.0.4-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "21ec4bf8aeeaa38db40e9a2c6237db3e9f156b5471ebd7089518fbd1fb81b910",
        "md5": "04c49264471bf96781a5a271a9eeb6c9",
        "sha256": "43a445ace88d613fa83a4944513b2f6f07ed51e4f91970f618475e153aba9c3f"
      },
      "downloads": -1,
      "filename": "image_rect-0.0.4.tar.gz",
      "has_sig": false,
      "md5_digest": "04c49264471bf96781a5a271a9eeb6c9",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 24598,
      "upload_time": "2020-08-16T20:44:27",
      "upload_time_iso_8601": "2020-08-16T20:44:27.878778Z",
      "url": "https://files.pythonhosted.org/packages/21/ec/4bf8aeeaa38db40e9a2c6237db3e9f156b5471ebd7089518fbd1fb81b910/image_rect-0.0.4.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}