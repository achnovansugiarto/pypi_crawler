{
  "info": {
    "author": "Vineet Dhaimodker",
    "author_email": "thevineet44@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Intended Audience :: Education",
      "License :: OSI Approved :: MIT License",
      "Operating System :: Microsoft :: Windows :: Windows 10",
      "Programming Language :: Python :: 3",
      "Topic :: Software Development :: Build Tools"
    ],
    "description": "# Ravin - Power optimizer for IoT Deployments\n\nWith Ravin, you can get the best configuration for all the IoT devices in a IoT deployment for minimim power consumption with just one line of code. Ravin is super easy to use and handles everything for you. Just specify the data of various configuration of the devices in your deployment and voila! you get the best configuration for each device.\n\n# Overview\nRavin was written with fast use in mind. It provides the following key features\n\n  - Single Objective Optimization\n\n\n## Usage\n\nIn the following paragraphs, I am going to describe how you can get and use Scrapeasy for your own projects.\n\n###  Getting it\n\nTo download ravin, either fork this github repo or simply use Pypi via pip.\n```sh\n$ pip install ravin\n```\n\n### Using it\n\nravin was programmed with ease-of-use in mind. First, import iot_dp from Scrapeasy\n\n```Python\nfrom ravin import iot_dp\n```\n\n<!-- And you are ready to go! At this point, I want to clearly distinct between a Website and a Page. While a Page is defined by just one single  url, like [github.com/joelbarmettlerUZH/Scrapeasy](https://github.com/joelbarmettlerUZH/Scrapeasy), a Website is a collection of such sites that belong to the same Domain. So the Website would be github as a whole, with all its pages - one of them is the scrapeasy repo. So a Website consists of many webpages.  -->\n\n<!-- ## Website and Page\nAs will notice that you can use all the methods for both *Page* and *Website* with the same argument calls. The only difference is that *Page* only gets you results from the specified URL while *Website* gives you results about the whole webpage with all its subsites. But let's have a look at the examples to make it clear: -->\n\n<!-- ## Initialize a Website\nFirst, let's create a new Website object. For this manner, just provide the url of the main page. I will use the URL of a website that I created years ago: [fahrschule-liechti.com](http://www.fahrschule-liechti.com). \n\n```Python\nweb = Website(\"http://www.fahrschule-liechti.com/\")\n``` -->\n\n<!-- #### Get Links of all subsites \nOkay, now that we have our Website initialized, we are interested of all the subsites that exists on fahrschule-liechti.com. To find this out, ask the web-object to receive the links of all subpages.\n\n```Python\nlinks = web.getSubpagesLinks()\n```\n\nDepending on your local internet connection and the server speed of the domain you are scraping, this request may take a while. Make sure to not scrape whole webpages with this method that are incredibly huge - like github.com for example. Github includes tousands if not billions of pages and links, and to digg through all of them may take hours. You can give it a shot - but use the page-scraping method described later to scrape such big sites. \n\nBut back to the link-getting: By calling *.getSubpagesLinks()*, you request all subpages as links and will receive a list of urls. \n\n>['fahrschule-liechti.com', 'fahrschule-liechti.com/about', 'fahrschule-liechti.com/der-weg-motorrad' .... ]\n\nYou may have noticed that the typical [*http://www.*](#)-stuff is missing. Thats un purpose and makes your live easier to further work with the links. But make sure that - when you actually want to call them in your browser or via requests - you add the http://www. in front of every link.  -->\n\n<!-- #### Find media\nLet's try to find links to all images that fahrschule-liechti.com placed on its website. We do that by calling the *.getImages()* method.\n\n```Python\nimages = web.getImages()\n```\n\nThe response will include links to all available images. \n\n>['fahrschule-liechti.com/wp-content/themes/zerif-lite/images/map25-redish.png', 'fahrschule-liechti.com/wp-content/uploads/2016/01/fabi-kreis.png' .... ] -->\n\n<!-- #### Download media\nCool! Now let's do some more advanced stuff. We love the pictures that fahrschule-liechti.com has on its website, so let's download them all to our local disk. Sounds like a lot of work? Its actually deadly easy!\n\n```Python\nweb.download(\"img\", \"fahrschule/images\")\n```\n\nFirst, we defined to download all image-media via the keyword *img*. Next, we define the output folder, where the images should be saved to. Thats it! Run the Code and see whats happening. Within seconds, you have received all images there are on fahrschule-liechti.com.  -->\n\n<!-- #### Get linked domains\nNext, lets find out to what pages fahrschule-liechti.com is linking to. To get a general overview, let's just find out to what other domains it is linking to. For that reason, we specify to only get the domain-links.\n\n```Python\ndomains = web.getLinks(intern=False, extern=False, domain=True)\n```\n\nWhat we get back is a list of all domains that are somewhere linked on fahrschule-liechti.com\n>['orthotec.ch', 'wordpress.org', 'strassenverkehrsamt.lu.ch', 'themeisle.com', 'google.ch', 'astra.admin.ch', 'samariter-luzern.ch']\n\nAll right, but now we want to gain further insights on these links. How do we do that? -->\n\n<!-- #### Get linked domains\nWell, more detailed links are nothing more than external links. So we do the same request but this time including externals, but not domains. \n\n```Python\ndomains = web.getLinks(intern=False, extern=True, domain=False)\n```\n\nTadaa, we are getting all external links in full detail.\n\n>['samariter-luzern.ch/cms/front_content.php', 'themeisle.com/themes/zerif-lite', 'orthotec.ch/de/pub/otc/fahrzeugumbau/fahrschulen.htm' ... ] -->\n\n<!-- ## Initialize a Page\nOkay, by now we have seen quiet a bit about that Website-thing, but we have not discovered what Page does yet. Well, as said, page is just a single Site from a Website. Let's try it out on a different example by initializing a w3 schools page.\n\n```Python\nw3 = Page(\"https://www.w3schools.com/html/html5_video.asp\")\n```\n\nYou will see why I chose exactly this page in a second, if you have not already guessed. -->\n\n<!-- #### Downloading Videos \nYes, you have heard right. Scrapeasy lets you download videos from webpages in seconds. Let's have a look how.\n\n```Python\nw3.download(\"video\", \"w3/videos\")\n```\n\nYep, thats all. Just specify that you want to download all video media into the output folder w3/videos, and you are ready to go. Of course you could also just receive the link to the videos and download them later, but that would be less cool.\n\n```Python\nvideo_links = w3.getVideos()\n``` -->\n\n<!-- #### Dowload other file types (like *pdf*  or *ics*)\nLet's be more general now. What about downloading special file types, like .pdf, .php or .ico? Use the general *.get()* method to receive the links, or the *.download()* method with the filetype as an argument.\nLets use the get method to receive reiceive links to calendar data on the computer-science club of the university of Zurich, UZH:\n\n```Python\ncalendar_links = Page(\"https://www.icu.uzh.ch/events/id/207\").get(\"ics\")\n```\nDone.\n\n>['icu.uzh.ch//events/upcoming/icu-upcoming-events.ics', 'icu.uzh.ch//events/id/207/icu-event.ics']\n\nLet's Downlaod some PDF's now. We should already be experienced on how to use *.download()*, but I demonstrate it one last time.\n\n```Python\nPage(\"http://mathcourses.ch/mat182.html\").download(\"pdf\", \"mathcourses/pdf-files\")\n``` -->\n\n\n\nLicense\n----\n\nMIT License\n\nCopyright (c) 2020 Vineet Dhaimodker\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "https://github.com/Vineet-Dhaimodker/ravin/archive/v1.0.0.tar.gz",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "Iot,Power,Optimization,Energy,Dynamic Programming",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "ravin",
    "package_url": "https://pypi.org/project/ravin/",
    "platform": "",
    "project_url": "https://pypi.org/project/ravin/",
    "project_urls": {
      "Download": "https://github.com/Vineet-Dhaimodker/ravin/archive/v1.0.0.tar.gz"
    },
    "release_url": "https://pypi.org/project/ravin/1.0.1/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "Optimize the power consumption of any IoT deployment using a single line of code.",
    "version": "1.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8300239,
  "releases": {
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2671a01285db409777a20c9a45fec6e5a7d0c5f55c2032ef98e7ba5d2eeac319",
          "md5": "798737a4a45140f9a1e161883ffbba52",
          "sha256": "96aff364b2f640a013d2d754a828c2a5c134b11ecd1426534778e4b1587f4a29"
        },
        "downloads": -1,
        "filename": "ravin-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "798737a4a45140f9a1e161883ffbba52",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 3837,
        "upload_time": "2020-09-29T19:09:57",
        "upload_time_iso_8601": "2020-09-29T19:09:57.688095Z",
        "url": "https://files.pythonhosted.org/packages/26/71/a01285db409777a20c9a45fec6e5a7d0c5f55c2032ef98e7ba5d2eeac319/ravin-1.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a6846325be510a91334b093815dbd1b6078cdfe18d839a5e51b0a2558f14f778",
          "md5": "fa47c6bf28908d78bd4d419dfcfca8d8",
          "sha256": "0c434a63ad1cac1b51367e23484c3c9d16bb2567c7f608b174cb413805157d64"
        },
        "downloads": -1,
        "filename": "ravin-1.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "fa47c6bf28908d78bd4d419dfcfca8d8",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 7235,
        "upload_time": "2020-09-29T19:33:26",
        "upload_time_iso_8601": "2020-09-29T19:33:26.474922Z",
        "url": "https://files.pythonhosted.org/packages/a6/84/6325be510a91334b093815dbd1b6078cdfe18d839a5e51b0a2558f14f778/ravin-1.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "a6846325be510a91334b093815dbd1b6078cdfe18d839a5e51b0a2558f14f778",
        "md5": "fa47c6bf28908d78bd4d419dfcfca8d8",
        "sha256": "0c434a63ad1cac1b51367e23484c3c9d16bb2567c7f608b174cb413805157d64"
      },
      "downloads": -1,
      "filename": "ravin-1.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "fa47c6bf28908d78bd4d419dfcfca8d8",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 7235,
      "upload_time": "2020-09-29T19:33:26",
      "upload_time_iso_8601": "2020-09-29T19:33:26.474922Z",
      "url": "https://files.pythonhosted.org/packages/a6/84/6325be510a91334b093815dbd1b6078cdfe18d839a5e51b0a2558f14f778/ravin-1.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}