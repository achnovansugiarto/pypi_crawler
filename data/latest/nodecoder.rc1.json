{
  "info": {
    "author": "Nasim Abdollahi",
    "author_email": "nsm.abdolahi@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: Implementation :: CPython",
      "Programming Language :: Python :: Implementation :: PyPy"
    ],
    "description": "\n<!-- # NodeCoder Pipeline -->\n\n<!-- <img src=\"/figures/Nodecoder_banner.png\" width = \"1070\"> -->\n\n[//]: # (![APM]&#40;https://img.shields.io/apm/l/NodeCoder?style=plastic&#41; ![GitHub package.json version]&#40;https://img.shields.io/github/package-json/v/NasimAbdollahi/NodeCoder&#41;)\n\n[//]: # (![GitHub file size in bytes]&#40;https://img.shields.io/github/size/:NasimAbdollahi/:NodeCoder?style=plastic&#41;)\n\n\nA PyTorch implementation of **NodeCoder Pipeline**, a Graph Convolutional Network (GCN) - based  framework for protein residue characterization. \nThis work was presented at **NeurIPS MLSB 2021**: *Residue characterization on AlphaFold2 protein structures using graph neural networks*. [link to paper](https://www.mlsb.io/papers_2021/MLSB2021_Residue_characterization_on_AlphaFold2.pdf)\n\n[Link to GitHub repository.](https://github.com/NasimAbdollahi/NodeCoder)\n\n## Abstract:\n```\nThree-dimensional structure prediction tools offer a rapid means to approximate the topology of a protein structure for any\nprotein sequence. Recent progress in deep learning-based structure prediction has led to highly accurate predictions that have\nrecently been used to systematically predict 20 whole proteomes by DeepMindâ€™s AlphaFold and the EMBL-EBI. While highly convenient,\nstructure prediction tools lack much of the functional context presented by experimental studies, such as binding sites or \npost-translational modifications. Here, we introduce a machine learning framework to rapidly model any residue-based\nclassification using AlphaFold2 structure-augmented protein representations. Specifically, graphs describing the 3D structure of\neach protein in the AlphaFold2 human proteome are generated and used as input representations to a Graph Convolutional Network\n(GCN), which annotates specific regions of interest based on the structural attributes of the amino acid residues, including their\nlocal neighbors. We demonstrate the approach using six varied amino acid classification tasks.\n```\n\n<!-- <img src=\"/figures/NodeCoder_Pipeline.png\" width = \"1070\"> -->\n\n\n## Table of Contents\nğŸ§¬ [ What does NodeCoder Pipeline do? ](#u1)<br>\nâš™ï¸ [ Installing NodeCoder ](#u2)<br>\nğŸ”Œ [ NodeCoder Usage ](#u3)<br>\nğŸ—„ï¸ [ Graph data files ](#u4)<br> \nğŸ“‚ [ Output files ](#u5)<br>\nğŸ¤ [ Collaborators ](#u6)<br>\nğŸ” [ License ](#u7)<br>\nğŸ“„ [ Citing this work ](#u8)\n\n<a name=\"u1\"></a>\n### ğŸ§¬ What does the NodeCoder Pipeline do? \n\n---\nThe NodeCoder is a generalized framework that annotates 3D protein structures with predicted tasks such as \nbinding sites. The NodeCoder model is based on Graph Convolutional Network. NodeCoder generates proteins' graphs from \nALphaFold2 augmented proteins' structures where the nodes are the amino acid residues and edges are inter-residue \ncontacts within a preset distance. The NodeCoder model is then trained with generated graph data for users task of \ninterest like: `Task = ['y_Ligand']`. \nWhen running inference, NodeCoder takes the **Protein ID** like **EGFR_HUMAN** and for the proteins that are already in \nthe database, input graph data files are created from the AlphaFold2 protein structure in addition to calculating some \nstructure-based and sequence-based residue features. The input graph data will then be given to the trained model for \nprediction of multiple tasks of interest such as binding sites or post-translational modifications.\n\n<!-- <img src=\"/figures/NodeCoder_FunctionBlocks.png\" width = \"950\"> -->\n\n<a name=\"u2\"></a>\n### âš™ï¸ Installing NodeCoder \n\n---\n#### Required dependencies\nThe codebase is implemented in Python 3.8 and package versions used for development are:\n```\nnumpy              1.19.2\npandas             1.2.4\nscipy              1.6.3\ntorch              0.4.1\ntorchvision        0.9.1\ntorchaudio         0.8.1\ntorch_scatter      2.0.6\ntorch_sparse       0.6.9\ntorch_cluster      1.5.9\ntorch_spline_conv  1.2.0\ntorch-geometric    1.7.0  \nscikit-learn       0.24.2\nmatplotlib         3.3.3\nbiopython          1.77\nfreesasa           2.0.5.post2\nloguru             0.6.0\n\n```\n#### Installation steps\nHere is the step-by-step NodeCoder installation process:<br>\n**Method 1 - install test.pypi package**<br>\n1. Before installing NodeCoder, we highly recommend to create a virutal Python 3.8 environment using venv command,\n   or Anaconda. Assuming you have anaconda3 installed on your computer, on your Terminal run the following command line:\n```\n$ conda create -n <your_python_env> python=3.8\n```\n2. Make sure your virtual environment is active. For conda environment you can use this command line:\n```\n$ conda activate <your_python_env>\n```\n3. Now you can install NodeCoder with this command line:\n```\n$ pip install --extra-index-url https://test.pypi.org/simple/ NodeCoder\n```\n \n**Method 2 - install from GitHub repository**<br>\nFollow above-mentioned steps 1-2, and continue with the following steps:\n3. Clone the repository:\n```\n$ git clone https://github.com/NasimAbdollahi/NodeCoder.git\n```\n4. Make sure you are in the root directory of the NodeCoder package `~/NodeCoder/` (where setup.py is). \nNow install NodeCoder package with following command line, which will install all dependencies in the python environment\nyou created in step 1:\n```\n$ pip install .\n```\n\n\n<a name=\"u3\"></a>\n### ğŸ”Œ NodeCoder Usage\n\n---\nNodeCoder package can be employed for train and inference. Here we describe how to use it:\n\n#### ğŸ—‚ï¸ Preprocessing raw data\n[link to paper](https://www.mlsb.io/papers_2021/MLSB2021_Residue_characterization_on_AlphaFold2.pdf)\nNodeCoder uses AlphaFold2 modeled protein structures as input. [AlphaFold protein structure database](https://alphafold.ebi.ac.uk/)\nprovides open access to protein structure predictions of human proteome and other key proteins of interest. \nPrediction labels can be obtained from [BioLip database](https://zhanggroup.org//BioLiP/qsearch_pdb.cgi?pdbid=1h88) and \n[Uniprot database](https://www.uniprot.org/).\n\nOnce you downloaded the protein databases, first step is to run the NodeCoder's featurizer module to process these raw \ndata sets and extract node features and labels. \nWhen using NodeCoder's featurizer module, `preprocess_raw_data`, you will need to specify the directories you have the \ndatasets saved:\n```\nalphafold_data_path\nuniprot_data_path\nbiolip_data_path\nbiolip_data_skip_path\n```\nThe featurizer module will create two files for every protein in the selected proteome: <font color='#D55E00'> \n`*.features.csv` </font> and <font color='#D55E00'> `*.tasks.csv` </font>. These files are saved in \n<font color='#D55E00'>` NodeCoder/data/input_data/featurized_data/TAX_ID/` </font> directory in separate folders of \n<font color='#D55E00'> `features` </font> and <font color='#D55E00'> `tasks` </font>. \nFor example if user choose human proteome, `9606`, then the following tree structure will be generated: \n```\ndata/input_data/featurized_data/\nâ””â”€â”€ 9606\n    â”œâ”€â”€ features\n    â””â”€â”€ tasks\n```\nThe command line to run the featurizer module is: \n```\n$ python NodeCoder/preprocess_raw_data.py\n```  \nTo use NodeCoder as python package, import preprocessing module as:\n```\n>>> from NodeCoder import preprocess_raw_data \n>>> preprocess_raw_data.main(alphafold_data_path='.', uniprot_data_path='.', biolip_data_path='.', biolip_data_skip_path='.')\n```\nThe default species/proteome is HUMAN, but user can change it with the following parameters:\n```\n>>> preprocess_raw_data.main(alphafold_data_path='.', uniprot_data_path='.', biolip_data_path='.', biolip_data_skip_path='.',\n                              TAX_ID='9606', PROTEOME_ID='UP000005640')\n```\n\n#### ğŸ—ƒï¸ Generate graph data\nThe next step after running the featurizer is to generate graph data from the features and tasks files. NodeCoder has a \ngraph-generator module that generate protein graph data by taking a threshold for distance between amino acid residues. \nThe threshold distance is required to be defined by user in Angstrom unit to create the graph contact network, `threshold_dist = 5`. \nGraph data files are saved in this directory <font color='#D55E00'>`./data/input_data/graph_data_*A/`</font> with the \nfollowing tree structure (the example here is for 8A cut-off distance and 5 folds for cross-validation):\n```\ndata/input_data/graph_data_8A/\nâ””â”€â”€ 9606\n    â””â”€â”€ 5FoldCV\n```\n\nThe command line to run the graph generator module is:\n```\n$ python NodeCoder/generate_graph_data.py\n``` \nTo use NodeCoder as python package, import generate_graph_data module as:\n```\n>>> from NodeCoder import generate_graph_data \n>>> generate_graph_data.main()\n```\nWhere, user can specify the following parameters\n```\n>>> generate_graph_data.main(TAX_ID='9606', PROTEOME_ID='UP000005640', threshold_dist=5, cross_validation_fold_number=5)\n```\nNote that for cross-validation setting, separate graphs are created for each fold.\n\n#### ğŸ§  Train NodeCoder\nTo train NodeCoder's graph-based model, user can use `train.py` module.\nScript `parser.py` has the model parameters used for training the model.\nUser would need to use the following parameters in `train.py` script to specify the task/tasks of interest and the\ncutoff distance for defining the protein contact network:\n``` \nTask = ['y_Ligand']\nthreshold_dist = 5\n```\nCommand line to train NodeCoder:\n```\n$ python NodeCoder/train.py\n```\nTo use NodeCoder as python package, import train module as:\n```\n>>> from NodeCoder import train \n>>> train.main()\n```\nWhere, user can specify the following parameters\n```\n>>> train.main(threshold_dist=5, multi_task_learning=False, Task=['y_Ligand'], centrality_feature=True,\n         cross_validation_fold_number=5, epochs=1000)\n```\n\nHere is a list of available training tasks (residue labels/annotations) :\n```\n'y_CHAIN', 'y_TRANSMEM', 'y_MOD_RES', 'y_ACT_SITE', 'y_NP_BIND', \n'y_LIPID', 'y_CARBOHYD', 'y_DISULFID', 'y_VARIANT', 'y_Artifact', \n'y_Peptide', 'y_Nucleic', 'y_Inorganic', 'y_Cofactor', 'y_Ligand'\n```\n\n#### ğŸ¤– Inference with NodeCoder\nTo use trained NodeCoder for protein functions prediction, user needs to run `predict.py` script.\nUser would need to use the following parameters in `predict.py` script to specify the protein of interest, functions\nof interest and the cutoff distance for defining the protein contact network:\n``` \nTask = ['y_Ligand']\nthreshold_dist = 5\n```\nCommand line to run inference with NodeCoder:\n```\n$ python NodeCoder/main_predict.py\n```\nTo use NodeCoder as python package, import train module as:\n```\n>>> from NodeCoder import predict \n>>> predict.main()\n```\nWhere, user can specify the following parameters\n```\n>>> predict.main(protein_ID='KI3L1_HUMAN', threshold_dist=5, trained_model_fold_number=1, multi_task_learning=False,\n         Task=['y_Ligand'], centrality_feature=True, cross_validation_fold_number=5, epochs=1000)\n```\nThe user shall make sure the model with the desired parameters should have been trained already, otherwise the user would\nneed to first train the model then use this pipeline for prediction.\n\n\n<a name=\"u4\"></a>\n### ğŸ—„ï¸ Graph data files\n\n---\nWhen graph data is generated from featurized data, files are saved in this directory <font color='#D55E00'> `./data/input_data/graph_data_*A/` </font>. \nSpecific sub-directories are created depends on user choice of cutoff distance for protein contact network, proteom, and\nnumber of cross-validation folds. This helps user to keep track of different test cases.\nFor every fold, following data files are created for train and validation sets:\n```\ndata/input_data/graph_data_5A/9606/\nâ””â”€â”€ *FoldCV\n    â”œâ”€â”€ train_1_ProteinFileNames.csv\n    â”œâ”€â”€ train_1_ProteinFiles.csv\n    â”œâ”€â”€ train_1_edge_features.csv\n    â”œâ”€â”€ train_1_edges.csv\n    â”œâ”€â”€ train_1_features.csv\n    â”œâ”€â”€ train_1_nodes_ProteinID.csv\n    â”œâ”€â”€ train_1_target.csv\n    â”œâ”€â”€ ....\n    â”œâ”€â”€ validation_1_ProteinFileNames.csv\n    â”œâ”€â”€ validation_1_ProteinFiles.csv\n    â”œâ”€â”€ validation_1_edge_features.csv\n    â”œâ”€â”€ validation_1_edges.csv\n    â”œâ”€â”€ validation_1_features.csv\n    â”œâ”€â”€ validation_1_nodes_ProteinID.csv\n    â”œâ”€â”€ validation_1_target.csv\n    â”œâ”€â”€ ...\n```\n\n<details open>\n<summary> Generated graph data files includes: </summary>\n<br>\n\n#### *_features.csv  <br />\nNodes' feature vectors are concatenated to create a long list of features for all nodes in the graph.\nThe first row is a header:\n\n| node_id | feature_id | value |\n| --- | --- | --- |\n| node number in the graph | one int. value of 0-45  | ... |\n\n#### *_edges.csv <br />\nIt contains the list node-pairs for all edges in the graph:\n\n| id1 | id2 |\n| --- | --- |\n| index of node 1 | index of node 2 |\n\n#### *_edge_features.csv <br />\nIt contains the edge features for all edges in the graph.\nCurrently, three different features are calculated for the edges; however, the current model only uses the squared reciprocal \nof edge length as weight. \n\n| id1 | id2 | edge_length | edge_cosine_angle | edge_sequence_distance |\n| --- | --- | --- | --- | --- | \n| index of node 1 | index of node 2 | Euclidean distance between the node pair | Cosine distance between the node pair | Sequence distance between the node pair |\n\n#### *_target.csv <br />\nIt the target labels for all nodes in the graph. The number of columns depends on the number of targets that user specify for prediction. \n\n| y_task1 | y_task2 | y_task3 | y_task4 | y_task5 | y_task6 | \n| --- | --- | --- | --- | --- | --- | \n| 0/1 |  0/1 | 0/1 | 0/1 | 0/1 | 0/1 |\n\n#### *_ProteinFiles.csv <br />\n\n| Protein File | Node Num | Removed NaNs|\n| --- | --- | --- |\n| EGFR_HUMAN | 1207 | 0 |\n| PTC1_HUMAN | 1444 | 0 |\n| DDX10_HUMAN | 872 | 0 |\n| ... | ... | ... |\n| RBL1_HUMAN | 1065 | 0 |\n\n\n#### *_nodes_ProteinID.csv <br />\nIf more than one protein is given to the model, this file keeps track of the residues that belong to each protein. \n\n| node_id | protein_id_flag | protein_id|\n| --- | --- | --- |\n| 0  | 0 | EGFR_HUMAN |\n| 1  | 0 | EGFR_HUMAN |\n| 2  | 0 | EGFR_HUMAN |\n| 3  | 0 | EGFR_HUMAN |\n| 4  | 0 | EGFR_HUMAN |\n| ...  | ... | ...|\n| 1207  | 1 | E2F8_HUMAN |\n| 1208  | 1 | E2F8_HUMAN |\n| 1209  | 1 | E2F8_HUMAN |\n| ...  | ... | ...|\n\nAmino Acid Residue (AA) feature vector:\n\n| feature ID | feature name | feature Description |\n| --- | --- | --- |\n| 0-19 | feat_A, feat_B, ..., feat_Y  | primary structure - one-hot-encoding binary vector of the 20 natural amino acid names |\n| 20-23 | feat_PHI, feat_PSI, feat_TAU, feat_THETA | Dihedral angles, Ï†, Ïˆ, Ï„, Î¸ |\n| 24 | feat_BBSASA | Back Bone Solvent Accessibility |\n| 25 | feat_SCSASA | Side Chain Solvent Accessibility |\n| 26 | feat_pLDDT | Show file differences that haven't been staged |\n| 27-41 | feat_DSSP_* | Secondary structure features, e.g. Î±-helix and Î²-sheet  |\n| 42 | feat_CentricDist | Euclidean distance of AA residue from the center of protein |\n| 43 | feat_CentricCosineDist | Cosine distance of AA residue from the center of protein |\n| 44 | feat_iPlus | AA info of a node before node i in protein sequence |\n| 45 | feat_iMinus | AA info of a node after node i in protein sequence |\n\n</details>\n\n<a name=\"u5\"></a>\n### ğŸ“‚ Output files\n\n---\nAll output files are saved in this directory <font color='#D55E00'> `./results/graph_*A/` </font>. Specific sub-directories are created\naccording to model parameters, so that user can keep track of different test cases.\n\n#### When training NodeCoder\nIn a cross-validation setting, the performance scores are saved in a `.csv` file like \n<font color='#D55E00'> `Model_Performance_Metrics_Fold1.csv` </font>, for all folds. In addition to this, model state is also saved \nin <font color='#D55E00'> `CheckPoints` </font> sub-directory at certain epochs. The default checkpoint epoch is `50`, as well as the epoch \nto save model performance, but user can change these with `checkpoint_step` and `performance_step`. At the end of training on each fold, the inference is performed by finding the optimum epoch and loading corresponding \ntrained model at the optimum epoch. At the end of inference, an output file is saved in <font color='#D55E00'> `Prediction` </font> \nsub-directory that includes the predicted labels for all proteins in validation set. This can be useful for ranking proteins.\n\nOnce training NodeCoder is completed, the results are all saved in `results` folder with the following tree structure \n(the example here is for 8A cut-off distance, 5 folds for cross-validation and Ligand as prediction task):\n```\nresults\nâ””â”€â”€ graph_8A\n    â””â”€â”€ 9606\n        â””â”€â”€ 5FoldCV\n            â””â”€â”€ y_Ligand_HiddenLayers_38_28_18_8_50Epochs_LR0.01\n                â”œâ”€â”€ CheckPoints\n                â”œâ”€â”€ Model_Performance_Curves.jpg\n                â”œâ”€â”€ Model_Performance_Metrics_Fold1.csv\n                â””â”€â”€ Prediction\n```\nModel parameters such as network structure, number of epochs and learning rate (LR) are reflected in the created subdirectory.\n\n#### When predicting with NodeCoder\nWhen running inference with trained NodeCoder, the prediction results are saved in a sub-directory with protein name. \nThe prediction result is a csv file like <font color='#D55E00'> `KI3L1_HUMAN_prediction_3Tasks_results.csv` </font>, which is a dataframe \nthat contains the target labels, predicted labels and prediction probability of the labels per node (AA residue) for all \ntasks of interest, {y1, y2, ..., yn}.\n\n| node_id | protein_id_flag | protein_id | Task 1 Target| Task 1 Prediction | Task 1 PredictionProb | ... | Task n Target | Task n Prediction | Task n PredictionProb |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| 0 | 0 | E2F8_HUMAN | 0/1 | 0/1 | float |  | 0/1 | 0/1 | float |\n| 1 | 0 | E2F8_HUMAN | 0/1 | 0/1 | float |  | 0/1 | 0/1 | float |\n\nOnce inference is completed, the results are all saved in `results` folder, with protein ID as the name of the subdirectory.\nThe following tree structure is an example for `KI3L1_HUMAN` as the protein of interest, 8A cut-off distance and 5 folds \nfor cross-validation):\n```\nresults\nâ””â”€â”€ graph_8A\n    â””â”€â”€ 9606\n        â””â”€â”€ 5FoldCV\n            â”œâ”€â”€ KI3L1_HUMAN\n            â”‚         â”œâ”€â”€ KI3L1_HUMAN_ProteinFiles.csv\n            â”‚         â”œâ”€â”€ KI3L1_HUMAN_edge_features.csv\n            â”‚         â”œâ”€â”€ KI3L1_HUMAN_edges.csv\n            â”‚         â”œâ”€â”€ KI3L1_HUMAN_features.csv\n            â”‚         â”œâ”€â”€ KI3L1_HUMAN_nodes_ProteinID.csv\n            â”‚         â”œâ”€â”€ KI3L1_HUMAN_prediction_1Tasks_results.csv\n            â”‚         â””â”€â”€ KI3L1_HUMAN_target.csv\n            â””â”€â”€ ...\n```\n\n<a name=\"u6\"></a>\n### ğŸ¤ Collaborators\n\n---\nThis project has been sponsored by [Mitacs](https://www.mitacs.ca/en) and [Cyclica Inc.](https://www.cyclicarx.com/).  <br />\nThe main contributors are:  <br />\n**Nasim Abdollahi**, Ph.D., Post-doctoral Fellow at University of Toronto, Cyclica Inc. <br />\n**Ali Madani**, Ph.D., Machine Learning Director at Cyclica Inc. <br />\n**Bo Wang**, Ph.D., Canada CIFAR AI Chair at the Vector Institute, Professor at University of Toronto <br />\n**Stephen MacKinnon**, Ph.D., Chief Platform Officer at Cyclica Inc. <br />\n\n<a name=\"u7\"></a>\n### ğŸ” License\nMIT Licence \n\n<a name=\"u8\"></a>\n### ğŸ“„ Citing this work\n```\n@article {2021,\n\tauthor = {Abdollahi, Nasim and Madani, Ali and Wang, Bo and MacKinnon,\n\tStephen},\n\ttitle = {Residue characterization on AlphaFold2 protein structures using graph neural networks},\n\tyear = {2021},\n\tdoi = {},\n\tpublisher = {NeurIPS},\n\tURL = {https://www.mlsb.io/papers_2021/MLSB2021_Residue_characterization_on_AlphaFold2.pdf},\n\tjournal = {NeurIPS, MLSB}\n}\n```\n[comment]: <> (colors = ['#CC79A7', '#E69F00', '#56B4E9', '#009E73', '#F0E442', '#0072B2', '#D55E00', '#000000'])\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/NasimAbdollahi/Nodecoder/",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "NodeCoder",
    "package_url": "https://pypi.org/project/NodeCoder/",
    "platform": null,
    "project_url": "https://pypi.org/project/NodeCoder/",
    "project_urls": {
      "Homepage": "https://github.com/NasimAbdollahi/Nodecoder/"
    },
    "release_url": "https://pypi.org/project/NodeCoder/1.0.0/",
    "requires_dist": [
      "scipy (>=1.5.4)",
      "numpy (>=1.19.2)",
      "pandas (>=1.1.5)",
      "matplotlib (>=3.3.3)",
      "torch (>=0.4.1)",
      "torchvision (==0.8.1)",
      "torchaudio (==0.7.0)",
      "torch-scatter (==2.0.5)",
      "torch-sparse (==0.6.8)",
      "torch-cluster (==1.5.8)",
      "torch-spline-conv (==1.2.0)",
      "torch-geometric (==1.6.3)",
      "scikit-learn (>=0.23.2)",
      "texttable (>=1.6.3)",
      "biopython (>=1.77)",
      "freesasa (==2.0.5.post2)",
      "loguru (>=0.6.0)"
    ],
    "requires_python": ">=3.8.5",
    "summary": "A PyTorch implementation of NodeCoder pipeline, a Graph Convolutional Network (GCN) framework for protein residue characterization.",
    "version": "1.0.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14067469,
  "releases": {
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "50c10848b69feb2b77129d00818776e677a2393c3c47433164e5e61e21ecce2d",
          "md5": "10bfaf6576c7ababff9f9c1450c2eb3a",
          "sha256": "869292db1fe1c27b8bbf850890592ba4139652c9470628b7ef5546e1a77655d8"
        },
        "downloads": -1,
        "filename": "NodeCoder-1.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "10bfaf6576c7ababff9f9c1450c2eb3a",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8.5",
        "size": 51161,
        "upload_time": "2022-06-08T09:35:45",
        "upload_time_iso_8601": "2022-06-08T09:35:45.433023Z",
        "url": "https://files.pythonhosted.org/packages/50/c1/0848b69feb2b77129d00818776e677a2393c3c47433164e5e61e21ecce2d/NodeCoder-1.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ac4e2e1cb09bd4fe115eca06b64962693685649b63693d5f2438b7ef35ee050c",
          "md5": "faa79a3df6cef859be651f50ed35fb3c",
          "sha256": "a7c779787292bded919fd62c00d9e5b3b0559311211a3eb0a88e96af43cfcad1"
        },
        "downloads": -1,
        "filename": "NodeCoder-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "faa79a3df6cef859be651f50ed35fb3c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8.5",
        "size": 49949,
        "upload_time": "2022-06-08T09:35:47",
        "upload_time_iso_8601": "2022-06-08T09:35:47.671030Z",
        "url": "https://files.pythonhosted.org/packages/ac/4e/2e1cb09bd4fe115eca06b64962693685649b63693d5f2438b7ef35ee050c/NodeCoder-1.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "50c10848b69feb2b77129d00818776e677a2393c3c47433164e5e61e21ecce2d",
        "md5": "10bfaf6576c7ababff9f9c1450c2eb3a",
        "sha256": "869292db1fe1c27b8bbf850890592ba4139652c9470628b7ef5546e1a77655d8"
      },
      "downloads": -1,
      "filename": "NodeCoder-1.0.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "10bfaf6576c7ababff9f9c1450c2eb3a",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.8.5",
      "size": 51161,
      "upload_time": "2022-06-08T09:35:45",
      "upload_time_iso_8601": "2022-06-08T09:35:45.433023Z",
      "url": "https://files.pythonhosted.org/packages/50/c1/0848b69feb2b77129d00818776e677a2393c3c47433164e5e61e21ecce2d/NodeCoder-1.0.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "ac4e2e1cb09bd4fe115eca06b64962693685649b63693d5f2438b7ef35ee050c",
        "md5": "faa79a3df6cef859be651f50ed35fb3c",
        "sha256": "a7c779787292bded919fd62c00d9e5b3b0559311211a3eb0a88e96af43cfcad1"
      },
      "downloads": -1,
      "filename": "NodeCoder-1.0.0.tar.gz",
      "has_sig": false,
      "md5_digest": "faa79a3df6cef859be651f50ed35fb3c",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.8.5",
      "size": 49949,
      "upload_time": "2022-06-08T09:35:47",
      "upload_time_iso_8601": "2022-06-08T09:35:47.671030Z",
      "url": "https://files.pythonhosted.org/packages/ac/4e/2e1cb09bd4fe115eca06b64962693685649b63693d5f2438b7ef35ee050c/NodeCoder-1.0.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}