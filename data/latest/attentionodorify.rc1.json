{
  "info": {
    "author": "Harshit Singh Chhabra",
    "author_email": "harshit20009@iiitd.ac.in",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "This package contains code to train an attention based deep learning model to predict activation status for given ligands and receptors. \n\n## Detailed description of functions:\n\n#### split_data: \nThis function takes a pandas dataframe as input and provides preprocessed model ready data. The function parameters include *val_ratio* to split the data into train and validation, a *test* flag which will enable the *test_ratio* to split the data into train, validation and test. This function also performs the oversampling of minority class (class with less samples) in the training data to avoid bias in the training process. Please note that the **ligands** column should be named **SMILES**, **sequences** column should be named **Final_Sequence** and **activation status** column should be named **Activation_Status**.\n\n- Basic code required for split_ratio function -\n\n        X_smile_onehot_train, X_seq_onehot_train, Y_train, X_smile_onehot_val, X_seq_onehot_val, Y_val = split_data(dataframe)\n\n- Provide a validation split ratio explicitally - \n\n        X_smile_onehot_train, X_seq_onehot_train, Y_train, X_smile_onehot_val, X_seq_onehot_val, Y_val, X_smile_onehot_test, X_seq_onehot_test, Y_test = split_data(dataframe, val_ratio=0.2)\n\n- Perform test and validation splitting with given ratio - \n\n        X_smile_onehot_train, X_seq_onehot_train, Y_train, X_smile_onehot_val, X_seq_onehot_val, Y_val, X_smile_onehot_test, X_seq_onehot_test, Y_test = split_data(dataframe, val_ratio=0.2, test=True, test_ratio=0.1)\n\n#### train:\nThis function will train a model based on training and validation data. You can modify the model parameters of LSTM along with basic hyperparameters like learning rate, dropout, batch size and number of training epochs (these parameters are not necessary and the code runs with default values as well). We use Adam optimier for training the entire model. This function also saves the loss plot for your trained model in the current directory. Custom filename can be provided to the saved plot by parameter *filename*.\n\n- Basic code required for train function -\n\n        model = train(X_smile_onehot_train, X_seq_onehot_train, Y_train, X_smile_onehot_val, X_seq_onehot_val)\n                \n- Updating hyperparameters like learning rate, dropout, batch size and epochs\n\n        model = train(X_smile_onehot_train, X_seq_onehot_train, Y_train, X_smile_onehot_val, X_seq_onehot_val,  learning_rate=0.0002, dropout=0.5, batch_size=16, epochs=50, filename = \"train_val_loss\")\n\n- Update the model architecture by changing number of recurrent layers, hidden states (update carefully to avoid memory overflow)\n\n        model = train(X_smile_onehot_train, X_seq_onehot_train, Y_train, X_smile_onehot_val, X_seq_onehot_val,  smile_h = 100, smile_l = 1, seq_h = 100, seq_l = 1)\n                \n#### test: \nThis function is used to find standard metrics like accuracy, precision, recall, auc, kappa etc. on any data for a trained model. This function also makes a ROC curve and saves it the current directory. Custom filename can be provided to the saved plot by parameter *filename*.\n\n- The below code snippet generates a ROC curve for the model\n\n        test(model, X_smile_onehot_test, X_seq_onehot_test, Y_test, filename = \"test\")\n\n- The below snippet generates a classwise ROC curve\n\n        test(model, X_smile_onehot_test, X_seq_onehot_test, Y_test, \"test\", flag=1)\n\n#### grid_search:\nThis method helps to find optimal model hyperparameters by training a group of models and deciding the best model based on highest validation accuracy after same number of epochs. Please be careful while using this function to avoid exhuasting CUDA memory of your system. \n\n- Basic code required for grid_search function with default options\n\n        grid_search(X_smile_onehot_train, X_seq_onehot_train, Y_train, X_smile_onehot_val, X_seq_onehot_val, Y_val)\n\n- Try various combinations of learning_rate, batch_size and dropouts\n\n        grid_search(X_smile_onehot_train, X_seq_onehot_train, Y_train, X_smile_onehot_val, X_seq_onehot_val, Y_val, , batch_size = [16, 32], learning_rate = [1e-4, 1.2e-4], dropout= [0.2, 0.7], epochs = 10)                \n\n\n#### generate_result_matrix: \nThis method gives the prediction and probability matrix for given sequences and ligands.\n\n    pred_matrix, prob_matrix = generate_result_matrix(model, smiles, seqs)\n\n#### interpretebility:\nThis method saves the plots for ligands and receptors interpretebility along with molecular structure interpretebilty in the provided path. It takes a trained model with save path along with a single smile and sequence to find interpretebility.\n\n    interpretebilty(model, user_smile, user_seq, path = \"./\")\n\n\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "AttentionOdorify",
    "package_url": "https://pypi.org/project/AttentionOdorify/",
    "platform": "",
    "project_url": "https://pypi.org/project/AttentionOdorify/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/AttentionOdorify/3.0.1/",
    "requires_dist": [
      "sklearn",
      "torch",
      "torchvision",
      "numpy",
      "pandas",
      "matplotlib",
      "scikit-plot",
      "captum",
      "rdkit-pypi"
    ],
    "requires_python": "",
    "summary": "Attention based BiLSTM model for Olfactory Analysis",
    "version": "3.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 10663458,
  "releases": {
    "3.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8f6ce910e10e7a3f28647f520a8fdd4668b904055c5de922077306a012bbe260",
          "md5": "4343d1ee1f0a2c7cfed68cb1d9f464ab",
          "sha256": "6cf30b8e0a104bc07a1325e045eb0dc6249657c2279952058ae78a9c246caccf"
        },
        "downloads": -1,
        "filename": "AttentionOdorify-3.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "4343d1ee1f0a2c7cfed68cb1d9f464ab",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 10347,
        "upload_time": "2021-06-14T10:02:51",
        "upload_time_iso_8601": "2021-06-14T10:02:51.325391Z",
        "url": "https://files.pythonhosted.org/packages/8f/6c/e910e10e7a3f28647f520a8fdd4668b904055c5de922077306a012bbe260/AttentionOdorify-3.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "8f6ce910e10e7a3f28647f520a8fdd4668b904055c5de922077306a012bbe260",
        "md5": "4343d1ee1f0a2c7cfed68cb1d9f464ab",
        "sha256": "6cf30b8e0a104bc07a1325e045eb0dc6249657c2279952058ae78a9c246caccf"
      },
      "downloads": -1,
      "filename": "AttentionOdorify-3.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "4343d1ee1f0a2c7cfed68cb1d9f464ab",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 10347,
      "upload_time": "2021-06-14T10:02:51",
      "upload_time_iso_8601": "2021-06-14T10:02:51.325391Z",
      "url": "https://files.pythonhosted.org/packages/8f/6c/e910e10e7a3f28647f520a8fdd4668b904055c5de922077306a012bbe260/AttentionOdorify-3.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}