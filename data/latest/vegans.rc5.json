{
  "info": {
    "author": "Unit8",
    "author_email": "julien@unit8.co",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# vegans\n\nA library to easily train various existing GANs (and other generative models) in PyTorch.\n\nThis library targets mainly GAN users, who want to use existing GAN training techniques with their own generators/discriminators.\nHowever researchers may also find the GenerativeModel base class useful for quicker implementation of new GAN training techniquess.\n\nThe focus is on simplicity and providing reasonable defaults.\n\n## How to install\nYou need python 3.7 or above. Then:\n`pip install vegans`\n\n## How to use\nThe basic idea is that the user provides discriminator / critic and generator networks (additionally an encoder if needed), and the library takes care of training them in a selected GAN setting. To get familiar with the library:\n\n- Check out the [documentation](https://unit8co.github.io/vegans/) or [quickstart guide](https://unit8co.github.io/vegans/quickstart.html)\n- Read through this README.md file\n- Check out the [notebooks](https://github.com/unit8co/vegans/tree/master/tutorials/notebooks) (00 to 04)\n- If you want to create your own GAN algorithms, check out the notebooks 05 to 07\n- Look at the example [code snippets](https://github.com/unit8co/vegans/tree/master/tutorials/snippets)\n\nvegans implements two types of generative models: Unsupervised and Supervised (examples given below). **Unsupervised algorithms** are used when no labels exist for the data you want to generate, for example in cases where it is too tedious or infeasible to generate labels for every output. The disadvantage is that after training the generation process will be unsupervised as well, meaning you have (in most cases) little control over which type of output is generated. **Supervised algorithms** on the other hand require you to specify the input dimension of the label (`y_dim`) and provide labels during training. All algorithms requiring labels are implemented as \"ConditionalGAN\" (e.g. `VanillaGAN` does not take labels, whereas `ConditionalVanillaGAN` does). These algorithms enable you to generate a specific output **conditonal** on a certain input.\n\nIn the case of handwritten digit generation (`MNIST`) a supervised algorithm let's you produce images of a certain number that you control (e.g. images of zeros). Supervised methods are also required for text-to-image, image-to-text, image-to-image, text-to-audio, etc. translation tasks, because output should be generated conditional on an input (what does the image look like _given_ a specific text snippet). Currently, the encoding of the conditional vector (label, text, audio, ...) has to be handled on the user side.\n\nAn interesting middle ground is take by the `InfoGAN` algorithm which tries to learn the labels itself during training. We refer to the original [paper](https://dl.acm.org/doi/10.5555/3157096.3157340) for more detailed information on the algorithm, but the vegans API for this method works similar to any other GAN. A conditional version exists, called `ConditionalInfoGAN` where label information can be provided but additional features are learned during training.\n\nYou can currently use the following generative models:\n\n* `AAE`: [Adversarial Auto-Encoder](https://arxiv.org/pdf/1511.05644.pdf)\n* `BicycleGAN`: [BicycleGAN](https://arxiv.org/pdf/1711.11586.pdf)\n* `EBGAN`: [Energy-Based GAN](https://arxiv.org/pdf/1609.03126.pdf)\n* `InfoGAN`: [Information-Based GAN](https://dl.acm.org/doi/10.5555/3157096.3157340)\n* `KLGAN`: [Kullback-Leib GAN](https://www.inference.vc/an-alternative-update-rule-for-generative-adversarial-networks/)\n* `LRGAN`: [Latent-Regressor GAN](https://arxiv.org/pdf/1711.11586.pdf)\n* `LSGAN`: [Least-Squares GAN](https://openaccess.thecvf.com/content_ICCV_2017/papers/Mao_Least_Squares_Generative_ICCV_2017_paper.pdf)\n* `VAEGAN`: [Variational Auto-Encoder GAN](https://arxiv.org/pdf/1512.09300.pdf)\n* `VanillaGAN`: [Classic minimax GAN](https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf), in its non-saturated version\n* `VanillaVAE`: [Variational Auto-Encoder](https://arxiv.org/pdf/1512.09300.pdf)\n* `WassersteinGAN`: [Wasserstein GAN](https://arxiv.org/abs/1701.07875)\n* `WassersteinGANGP`: [Wasserstein GAN with gradient penalty](https://arxiv.org/abs/1704.00028)\n\n\n\nAll current generative model implementations come with a conditional variant to allow for the usage of training labels to produce specific outputs:\n\n- `ConditionalAEE`\n- `ConditionalBicycleGAN`\n- `ConditionalEBGAN`\n- ...\n- `ConditionalCycleGAN`\n- `ConditionalPix2Pix`\n\nThis can either be used to pass a one hot encoded vector to predict a specific label (generate a certain number in case of mnist: [example_mnist_conditional.py](https://github.com/unit8co/vegans/blob/master/tutorials/snippets/example_mnist_conditional.py)  or [03_mnist-conditional.ipynb](https://github.com/unit8co/vegans/blob/master/tutorials/notebooks/03_mnist-conditional.ipynb)) or it can also be a full image (when for example trying to rotate an image: [example_image_to_image.py](https://github.com/unit8co/vegans/blob/master/tutorials/snippets/example_mnist_rotation.py)  or [04_mnist-image-to-image.ipynb](https://github.com/unit8co/vegans/blob/master/tutorials/notebooks/04_mnist-image-to-image.ipynb)).\n\nModels can either be passed as `torch.nn.Sequential` objects or by defining custom architectures, see [example_input_formats.py](https://github.com/unit8co/vegans/blob/master/tutorials/snippets/example_input_formats.py).\n\nAlso look at the [jupyter notebooks](https://github.com/unit8co/vegans/tree/master/tutorials/notebooks) for better visualized examples and how to use the library.\n\n#### Unsupervised Learning Example\n\n```python\nfrom vegans.GAN import VanillaGAN\nimport vegans.utils as utils\nimport vegans.utils.loading as loading\n\n# Data preparation (Load your own data or example MNIST)\nloader = loading.MNISTLoader()\nX_train, _, X_test, _ = loader.load()\nx_dim = X_train.shape[1:] # [height, width, nr_channels]\nz_dim = 64\n\n# Define your own architectures here. You can use a Sequential model or an object\n# inheriting from torch.nn.Module. Here, a default model for mnist is loaded.\ngenerator = loader.load_generator(x_dim=x_dim, z_dim=z_dim, y_dim=None)\ndiscriminator = loader.load_adversary(x_dim=x_dim, y_dim=None)\n\ngan = VanillaGAN(\n    generator=generator, adversary=discriminator,\n    z_dim=z_dim, x_dim=x_dim, folder=None\n)\ngan.summary() # optional, shows architecture\n\n# Training\ngan.fit(X_train, enable_tensorboard=False)\n\n# Vizualise results\nimages, losses = gan.get_training_results()\nutils.plot_images(images)\nutils.plot_losses(losses)\n\n# Sample new images, you can also pass a specific noise vector\nsamples = gan.generate(n=36)\nutils.plot_images(samples)\n```\n\n#### Supervised / Conditional Learning Example\n\n```python\nimport torch\nimport numpy as np\nimport vegans.utils as utils\nimport vegans.utils.loading as loading\nfrom vegans.GAN import ConditionalVanillaGAN\n\n# Data preparation (Load your own data or example MNIST)\nloader = loading.MNISTLoader()\nX_train, y_train, X_test, y_test = loader.load()\n\nx_dim = X_train.shape[1:] # [nr_channels, height, width]\ny_dim = y_train.shape[1:]\nz_dim = 64\n\n# Define your own architectures here. You can use a Sequential model or an object\n# inheriting from torch.nn.Module. Here, a default model for mnist is loaded.\ngenerator = loader.load_generator(x_dim=x_dim, z_dim=z_dim, y_dim=y_dim)\ndiscriminator = loader.load_adversary(x_dim=x_dim, y_dim=y_dim)\n\ngan = ConditionalVanillaGAN(\n    generator=generator, adversary=discriminator,\n    z_dim=z_dim, x_dim=x_dim, y_dim=y_dim,\n    folder=None, # optional\n    optim={\"Generator\": torch.optim.RMSprop, \"Adversary\": torch.optim.Adam}, # optional\n    optim_kwargs={\"Generator\": {\"lr\": 0.0001}, \"Adversary\": {\"lr\": 0.0001}}, # optional\n    fixed_noise_size=32, # optional\n    device=None, # optional\n    ngpu=0 # optional\n\n)\ngan.summary() # optional, shows architecture\n\n# Training\ngan.fit(\n    X_train, y_train, X_test, y_test,\n    epochs=5, # optional\n    batch_size=32, # optional\n    steps={\"Generator\": 1, \"Adversary\": 2}, # optional, train generator once and discriminator twice on every mini-batch\n    print_every=\"0.1e\", # optional, prints progress 10 times per epoch\n    # (might also be integer input indicating number of mini-batches)\n    save_model_every=None, # optional\n    save_images_every=None, # optional\n    save_losses_every=\"0.1e\", # optional, save losses in internal losses dictionary used to generate\n    # plots during and after training\n    enable_tensorboard=False # optional, if true all progress is additionally saved in tensorboard subdirectory\n)\n\n# Vizualise results\nimages, losses = gan.get_training_results()\nutils.plot_images(images, labels=np.argmax(gan.fixed_labels.cpu().numpy(), axis=1))\nutils.plot_losses(losses)\n\n# Generate specific label, for example \"2\"\nlabel = np.array([[0, 0, 1, 0, 0, 0, 0, 0, 0,0 ]])\nimage = gan(y=label)\nutils.plot_images(image, labels=[\"2\"])\n```\n\n### Slightly More Details:\n\n#### Constructor arguments\n\nAll of the generative model objects inherit from a [`AbstractGenerativeModel`](https://github.com/unit8co/vegans/blob/master/vegans/models/unconditional/AbstractGenerativeModel.py) base class. and allow for the following input in the constructor.\n\n* `optim`: The optimizer for all networks used during training. If `None` a default optimizer (probably either `torch.optim.Adam` or `torch.optim.RMSprop`) is chosen by the specific model. A `dict` type with appropriate keys can be passed to specify different optimizers for different networks, for example `{\"Generator\": torch.optim.Adam}`.\n* `optim_kwargs`:  The optimizer keyword arguments. A `dict` type with appropriate keys can be passed to specify different optimizer keyword arguments for different networks, for example `{\"Generator\": {\"lr\": 0.001}}`.\n* `feature_layer`: If not None, it should be a layer of the discriminator or critic. The output of this layer is used to compute the mean squared error between the real and fake samples, i.e. it uses the feature loss. The existing GAN loss (often Binary cross-entropy) is overwritten.\n* `fixed_noise_size`: The number of samples to save (from fixed noise vectors). These are saved within tensorboard (if `enable_tensorboard=True` during fitting) and in the `Model/images` subfolder.\n* `device`: \"cuda\" (GPU) or \"cpu\" depending on the available resources.\n* `ngpu`: Number of gpus used during training\n* `folder`: Folder which will contain all results of the network (architecture, model.torch, images, loss plots, etc.). An existing folder will never be deleted or overwritten. If the folder already exists a new folder will be created with the given name + current time stamp.\n* `secure`: By default, vegans performs plenty of checks on inputs and outputs for all networks (For example `encoder.output_size==z_dim`, `generator.output_size==x_dim`  or `Discriminator.last_layer==torch.nn.Sigmoid`). For some use cases these checks might be too restrictive. If `secure=False` vegans will perform only the most basic checks to run. Of course, if there are shape mismatches torch itself will still complain.\n\n#### fit() arguments\n\nThe fit function takes the following optional arguments:\n\n- `epochs`: Number of epochs to train the algorithm. Default: 5\n- `batch_size`: Size of one batch. Default: 32\n- `steps`: How often one network should be trained against another. Must be `dict` type with appropriate names. E.g., for the `WassersteinGAN` the dictionary could be `{\"Generator\": 1, \"Adversary\": 5}`, indicating that the adversary should be trained five times on every mini-batch while the generator is trained once. The keys of the dictionary are **fixed** by the specified algorithm (here [\"Generator\", \"Adversary\"], for BicycleGAN would be [\"Generator\", \"Adversary\", \"Encoder\"] ). An appropriate error is raised if wrong keys are passed. The possible names should be obvious from the constructor of every algorithm but a wrong dictionary, e.g. {\"Genrtr\": 1}, can be passed consciously to receive a list of correct and available key values.\n- `print_every`: Determines after how many batches a message should be printed to the console informing about the current state of training. String indicating fraction or multiples of epoch can be given. I.e. \"0.25e\" = four times per epoch, \"2e\" after two epochs. Default: 100\n- `save_model_every`: Determines after how many batches the model should be saved. String indicating fraction or multiples of epoch can be given. I.e. \"0.25e\" = four times per epoch, \"2e\" after two epochs. Models will be saved in subdirectory `folder`+\"/models\" (`folder` specified in the constructor, see above in **Constructor arguments**). Default: None\n- `save_images_every`: Determines after how many batches sample images and loss curves should be saved. String indicating fraction or multiples of epoch can be given. I.e. \"0.25e\" = four times per epoch, \"2e\" after two epochs. Images will be saved in subdirectory `folder`+\"/images\" (`folder` specified in the constructor, see above in **Constructor arguments**).  Default: None\n- `save_losses_every`: Determines after how many batches the losses should be calculated and saved. Figure is shown after `save_images_every` . String indicating fraction or multiples of epoch can be given. I.e. \"0.25e\" = four times per epoch, \"2e\" after two epochs. Default: \"1e\"\n- `enable_tensorboard`: Tensorboard information for losses, samples and training time will be saved in subdirectory `folder`+\"/tensorboard\" (`folder` specified in the constructor, see above in **Constructor arguments**).  Default: False\n\nAll of the generative model objects inherit from a `AbstractGenerativeModel` base class. When building any such GAN, you must pass generator / decoder as well as discriminator / encoder networks (some `torch.nn.Module`), as well as a the dimensions of the latent space `z_dim` and input dimension of the images `x_dim`.\n\n\n\n#### Generative Model methods:\n\n- `generate(z=None, n=None)` / `generate(y, z=None, n=None)`: Generate samples from noise vector or generate \"n\" samples. \n\n- `get_hyperparameters()`: Get dictionary containing important hyperparameters.\n\n- `get_losses(by_epoch=False, agg=None)`: Return a dictionary of logged losses. Number of elements determined by the `save_losses_every` parameter passed to the `fit` method.\n\n- `get_number_params()`: Get the number of parameters per network.\n\n- `get_training_results(by_epoch=False, agg=None)`: Returns the samples generated from the `fixed_noise` attribute and the logged losses.\n\n- `load(path)`: Load a trained model.\n\n- `predict(x)`: Use the adversary to predict the realness of an image.\n\n- `sample(n)`: Sample a noise vector of size n.\n\n- `save(name=None)`: Save the model.\n\n- `summary(save=False)`: Print a summary of the model containing the number of parameters and general structure.\n\n- `to(device)`: Map all networks to a common device. Should be done before training.\n\n\n\n#### Generative model attributes:\n\n- `feature_layer`: Function to calculate feature loss with. If None no feature loss is computed. If not None the feature loss overwrites the \"normal\" generator loss.\n- `fixed_noise`, (`fixed_noise_labels`): Noise vector sampled before training and used to generate the images in the created subdirectory (if `save_images_every` in the `fit` mehtod is not None). Also used to produce the results from `get_training_results()`.\n- `folder`: Folder where all information belonging to GAN is stored. This includes\n  - Models in the `folder/models` subdirectory if `save_model_every` is not None in  the`fit()` method.\n  - Images in the `folder/images` subdirectory if `save_images_every` is not None in the `fit()` method.\n  - Tensorboard data in the `folder/tensorboard` subdirectory if `enable_tensorboard` is True in the `fit()` method.\n  - Loss in the `folder/losses.png` if `save_losses_every` is not None in `fit()` method.\n  - Loss in the `folder/summary.txt` if `summary(save=True)`called.\n- `images_produced`: Flag (True / False) if images are the target of the generator.\n- `total_training_time`, `batch_training_times`: Time needed for training.\n- `x_dim`, `z_dim`, (`y_dim`): Input dimensions.\n- `training`: Flag (True / False) if model is in training or evaluation mode. Normally the flag is False and is automatically set to True in the main training loop.\n\nAttentive readers might notice that in most places we try to talk about \"Generative Models\" instead of \"Generative Adversarial Networks\", because `vegans` currently also supports the Variational Autoencoder algorithm (`VanillaVAE`) which are their own method of generating data. However, you can interpret the decoder of the VAE equivalently to a generator of a GAN. Both take the latent space (and sometimes labels) as input and transform them to the desired output space. In an abstract sense the encoder of the VAE also corresponds to the discriminator of the GAN as both aim to condense their input from the image space to a lower dimensional latent dimension. These abstract commonalities are used in the `AbstractGenerativeModel` to unify both types of algorithms and provide a largely similar API.\n\nIn the future we also plan to implement different VAE algorithms to have all generative models in one place but for now the library is focused on GAN algorithms.\n\nIf you are researching new generative model training algorithms, you may find it useful to inherit from the `AbstractGenerativeModel` or  [`AbstractConditionalGenerativeModel`](https://github.com/unit8co/vegans/blob/master/vegans/models/conditional/AbstractConditionalGenerativeModel.py) base class.\n\n### Learn more:\n\nCurrently the best way to learn more about how to use vegans is to have a look at the example [notebooks](https://github.com/unit8co/vegans/tree/master/tutorials/notebooks).\nYou can start with this [simple example](https://github.com/unit8co/vegans/blob/master/tutorials/notebooks/00_univariate-gaussian.ipynb) showing how to sample from a univariate Gaussian using a GAN.\nAlternatively, can run example [scripts](https://github.com/unit8co/vegans/tree/master/tutorials/snippets).\n\n## Contribute\nPRs and suggestions are welcome. Look [here](https://github.com/unit8co/vegans/blob/master/CONTRIBUTING.md) for more details on the setup.\n\n## Credits\nSome of the code has been inspired by some existing GAN implementations:\n* https://github.com/eriklindernoren/PyTorch-GAN\n* https://github.com/martinarjovsky/WassersteinGAN\n* https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n\n\n\n### Some Results\n\nAll this results should be taken with a grain of salt. They were not extensively fine tuned in any way, so better results for individual networks are possible for sure. More time training as well as more regularization could most certainly improve results. All of these results were generated by running the example_conditional.py program in the examples folder. Especially the Variational Autoencoder would perform better if we increased it's number of parameters to a comparable level.\n\n| Network                |                         MNIST Result                         |\n| :--------------------- | :----------------------------------------------------------: |\n| Cond. BicycleGAN       | ![MNIST](./TrainedModels/cBicycleGAN/generated_images.png \"MNIST\") |\n| Cond. EBGAN            | ![MNIST](./TrainedModels/cEBGAN/generated_images.png \"MNIST\") |\n| Cond. InfoGAN          | ![MNIST](./TrainedModels/cInfoGAN/generated_images.png \"MNIST\") |\n| Cond. KLGAN            | ![MNIST](./TrainedModels/cKLGAN/generated_images.png \"MNIST\") |\n| Cond. LRGAN            | ![MNIST](./TrainedModels/cLRGAN/generated_images.png \"MNIST\") |\n| Cond. Pix2Pix          | ![MNIST](./TrainedModels/cPix2Pix/generated_images.png \"MNIST\") |\n| Cond. VAEGAN           | ![MNIST](./TrainedModels/cVAEGAN/generated_images.png \"MNIST\") |\n| Cond. VanillaGAN       | ![MNIST](./TrainedModels/cVanillaGAN/generated_images.png \"MNIST\") |\n| Cond. WassersteinGAN   | ![MNIST](./TrainedModels/cWassersteinGAN/generated_images.png \"MNIST\") |\n| Cond. WassersteinGANGP | ![MNIST](./TrainedModels/cWassersteinGANGP/generated_images.png \"MNIST\") |\n| Cond. VAE              | ![MNIST](./TrainedModels/cVanillaVAE/generated_images.png \"MNIST\") |\n\n\n\n## TODO\n\n- GAN Implementations (sorted by priority)\n  - BEGAN\n  - WassersteinGAN SpectralNorm\n  - Stacked GAN [here](https://arxiv.org/abs/1612.03242)\n  - Progressive Growing GAN [here](https://arxiv.org/abs/1710.10196)\n  \n- Layers\n  - Minibatch discrimination\n  - Instance normalization\n  \n- Other\n\n  - Core Improvements:\n    - Hide feature_layer, secure in **kwargs\n    - Make it more PEP conform\n    - ~~Make \\_default\\_optimizer not abstract~~\n    - Windows installation issues\n    - ~~CI workflow~~\n    - Create protected branches\n    - Conda installation\n    - Type annotations\n    - ~~Documentation website~~\n    - build fancy examples\n\n  - Perceptual Loss [here](https://arxiv.org/pdf/1603.08155.pdf)\n  \n  - Interpolation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/unit8co/vegans/",
    "keywords": "gan gans pytorch generative models adversarial networks Wasserstein GAN InfoGAN CycleGAN BicycleGAN VAE AAE",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "vegans",
    "package_url": "https://pypi.org/project/vegans/",
    "platform": "",
    "project_url": "https://pypi.org/project/vegans/",
    "project_urls": {
      "Homepage": "https://github.com/unit8co/vegans/"
    },
    "release_url": "https://pypi.org/project/vegans/0.4.0/",
    "requires_dist": [
      "matplotlib (==3.3.4)",
      "numpy (==1.19.5)",
      "pandas (==1.1.5)",
      "torch (==1.8.1)",
      "tensorboard (==2.5.0)",
      "torchvision (==0.9.1)",
      "wget (==3.2)"
    ],
    "requires_python": ">=3.7",
    "summary": "A library to easily train various existing GANs in PyTorch.",
    "version": "0.4.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 11902080,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cf051ba6c7edf08ef6a85db5c504eef95382fdfc134914c8094602116b941053",
          "md5": "2f83c52d6a083adb03713fc846b9c4a8",
          "sha256": "af9f76ec4cf8763aa437f21437fb280deb00c0abee24b60c469820b31f6e7001"
        },
        "downloads": -1,
        "filename": "vegans-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "2f83c52d6a083adb03713fc846b9c4a8",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 9903,
        "upload_time": "2019-01-29T21:07:31",
        "upload_time_iso_8601": "2019-01-29T21:07:31.619446Z",
        "url": "https://files.pythonhosted.org/packages/cf/05/1ba6c7edf08ef6a85db5c504eef95382fdfc134914c8094602116b941053/vegans-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7c0710371d0daf49db6604235f307731998e4a02dd05d643ec2a52bddebca8ee",
          "md5": "e7c534ddcc179405b5fdc2269236d740",
          "sha256": "ae45ccc8492b04e91a1b6ef344e5383beb127fe0158862f3714d938cecd4fa63"
        },
        "downloads": -1,
        "filename": "vegans-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "e7c534ddcc179405b5fdc2269236d740",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 6852,
        "upload_time": "2019-01-29T21:07:33",
        "upload_time_iso_8601": "2019-01-29T21:07:33.388484Z",
        "url": "https://files.pythonhosted.org/packages/7c/07/10371d0daf49db6604235f307731998e4a02dd05d643ec2a52bddebca8ee/vegans-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3c31a8f557786bfc30c5545f187d26e9a9b00a153bd31a0f0f62392604d64e4f",
          "md5": "87bf6220367ba69a4550a56dba253a9e",
          "sha256": "a202d96fc080fd83d12e93f41e81cfecb13b819140b0476651b040995714c29d"
        },
        "downloads": -1,
        "filename": "vegans-0.2.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "87bf6220367ba69a4550a56dba253a9e",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 9015,
        "upload_time": "2021-04-29T18:43:19",
        "upload_time_iso_8601": "2021-04-29T18:43:19.385044Z",
        "url": "https://files.pythonhosted.org/packages/3c/31/a8f557786bfc30c5545f187d26e9a9b00a153bd31a0f0f62392604d64e4f/vegans-0.2.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bdf4204b990c51854beadebeeebc1c17a7c1d268f6cf9bd791670661a8e4a956",
          "md5": "3e326ac023c2d61c1838212cc9276906",
          "sha256": "6869934161ce62cb163324b10255d99192df437f9a97695a29b20cedb26504c7"
        },
        "downloads": -1,
        "filename": "vegans-0.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "3e326ac023c2d61c1838212cc9276906",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 13059778,
        "upload_time": "2021-04-29T18:43:23",
        "upload_time_iso_8601": "2021-04-29T18:43:23.064186Z",
        "url": "https://files.pythonhosted.org/packages/bd/f4/204b990c51854beadebeeebc1c17a7c1d268f6cf9bd791670661a8e4a956/vegans-0.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "086d3b3a84a13ad3fdd12b46f1537cd72e5fa6d34483217211bd09b2a11159f1",
          "md5": "eea9185035e0e143a4910e9eeaca6fb8",
          "sha256": "ab9daffa257465d3000737a70f4705903b905738856c96c69589320cc082a1f8"
        },
        "downloads": -1,
        "filename": "vegans-0.2.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "eea9185035e0e143a4910e9eeaca6fb8",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 118601,
        "upload_time": "2021-04-29T19:09:39",
        "upload_time_iso_8601": "2021-04-29T19:09:39.362427Z",
        "url": "https://files.pythonhosted.org/packages/08/6d/3b3a84a13ad3fdd12b46f1537cd72e5fa6d34483217211bd09b2a11159f1/vegans-0.2.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6ca7c8f8a7e034734332a5d655a97fdb6dcc1aff274656397cad071351591b7f",
          "md5": "165076a73039bdb87332f601e3c2e21e",
          "sha256": "7176d1c944314601c311157d81b4846639068388d3ac2d698efbd984b6c6fec6"
        },
        "downloads": -1,
        "filename": "vegans-0.2.1.tar.gz",
        "has_sig": false,
        "md5_digest": "165076a73039bdb87332f601e3c2e21e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 12956063,
        "upload_time": "2021-04-29T19:09:43",
        "upload_time_iso_8601": "2021-04-29T19:09:43.978780Z",
        "url": "https://files.pythonhosted.org/packages/6c/a7/c8f8a7e034734332a5d655a97fdb6dcc1aff274656397cad071351591b7f/vegans-0.2.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0cb4df04ea4fb0c79c3e878db2321722d39bed087c085034b2958bda021a2381",
          "md5": "cfd1d0f7451e24d0ae631989ceef1ef9",
          "sha256": "0eeffa2840865b705db44e3be235963198e99193b175893ae1760fdb4a7e59ba"
        },
        "downloads": -1,
        "filename": "vegans-0.3.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "cfd1d0f7451e24d0ae631989ceef1ef9",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 116747,
        "upload_time": "2021-05-25T20:09:03",
        "upload_time_iso_8601": "2021-05-25T20:09:03.815491Z",
        "url": "https://files.pythonhosted.org/packages/0c/b4/df04ea4fb0c79c3e878db2321722d39bed087c085034b2958bda021a2381/vegans-0.3.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a99d2051704956722ddb922260250ef6c44f41c077a1a994d8e40e7d4b6af69a",
          "md5": "d5df00aab7dcfb1e245c2c7266d67ede",
          "sha256": "5d8bc953b9775f5a3c6d683c1c99cabea85cf7c10d847b5ec8b4840991b0142b"
        },
        "downloads": -1,
        "filename": "vegans-0.3.0.tar.gz",
        "has_sig": false,
        "md5_digest": "d5df00aab7dcfb1e245c2c7266d67ede",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 13056666,
        "upload_time": "2021-05-25T20:10:30",
        "upload_time_iso_8601": "2021-05-25T20:10:30.401112Z",
        "url": "https://files.pythonhosted.org/packages/a9/9d/2051704956722ddb922260250ef6c44f41c077a1a994d8e40e7d4b6af69a/vegans-0.3.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "966274870d07c8733e97ca33ccdf7bd68576b84b834bb18fe1b107f169cd2fea",
          "md5": "acd9e621a70b2405ea6ea21a1f933b00",
          "sha256": "23d1fcf795686f298c87c9e867e1da93fac923ef58bf9393da6d2c0abcca476e"
        },
        "downloads": -1,
        "filename": "vegans-0.4.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "acd9e621a70b2405ea6ea21a1f933b00",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 133189,
        "upload_time": "2021-11-02T09:57:14",
        "upload_time_iso_8601": "2021-11-02T09:57:14.032072Z",
        "url": "https://files.pythonhosted.org/packages/96/62/74870d07c8733e97ca33ccdf7bd68576b84b834bb18fe1b107f169cd2fea/vegans-0.4.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d546171e5fe119f982fee441bb35e8c38adf05ba3691d96c9565329aeb18d0ec",
          "md5": "4b0041568018d1c8a316ea0491e267fc",
          "sha256": "7a0c0c2954f40a591c964a782e8371f39297e2c6813263dcd7e4a5473fc0f2ef"
        },
        "downloads": -1,
        "filename": "vegans-0.4.0.tar.gz",
        "has_sig": false,
        "md5_digest": "4b0041568018d1c8a316ea0491e267fc",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 13070889,
        "upload_time": "2021-11-02T09:57:16",
        "upload_time_iso_8601": "2021-11-02T09:57:16.711886Z",
        "url": "https://files.pythonhosted.org/packages/d5/46/171e5fe119f982fee441bb35e8c38adf05ba3691d96c9565329aeb18d0ec/vegans-0.4.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "966274870d07c8733e97ca33ccdf7bd68576b84b834bb18fe1b107f169cd2fea",
        "md5": "acd9e621a70b2405ea6ea21a1f933b00",
        "sha256": "23d1fcf795686f298c87c9e867e1da93fac923ef58bf9393da6d2c0abcca476e"
      },
      "downloads": -1,
      "filename": "vegans-0.4.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "acd9e621a70b2405ea6ea21a1f933b00",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 133189,
      "upload_time": "2021-11-02T09:57:14",
      "upload_time_iso_8601": "2021-11-02T09:57:14.032072Z",
      "url": "https://files.pythonhosted.org/packages/96/62/74870d07c8733e97ca33ccdf7bd68576b84b834bb18fe1b107f169cd2fea/vegans-0.4.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "d546171e5fe119f982fee441bb35e8c38adf05ba3691d96c9565329aeb18d0ec",
        "md5": "4b0041568018d1c8a316ea0491e267fc",
        "sha256": "7a0c0c2954f40a591c964a782e8371f39297e2c6813263dcd7e4a5473fc0f2ef"
      },
      "downloads": -1,
      "filename": "vegans-0.4.0.tar.gz",
      "has_sig": false,
      "md5_digest": "4b0041568018d1c8a316ea0491e267fc",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 13070889,
      "upload_time": "2021-11-02T09:57:16",
      "upload_time_iso_8601": "2021-11-02T09:57:16.711886Z",
      "url": "https://files.pythonhosted.org/packages/d5/46/171e5fe119f982fee441bb35e8c38adf05ba3691d96c9565329aeb18d0ec/vegans-0.4.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}