{
  "info": {
    "author": "HEtothe",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.6"
    ],
    "description": "# datagrab - the easy way to access and interpret textual web resources!\n\n## Overview\n\nLet's be clear: [requests](https://realpython.com/python-requests/) is an awesome library.\nBut even so, some really basic use cases still seem to require a lot of lines of code!\n\ndatagrab was written as a set of classes and methods designed to simplify\nusing the [requests library](https://realpython.com/python-requests/) for some typical\nweb scraping and REST API use cases.\nIn short: download, parse and process the returned text easily, so you are closer to doing something useful with it.\n\n- Request data and ensure the desired result arrived with a single method (retrieve_response module)\n- Connect to REST API services with Basic Authentication implemented for you (RESTConnect module)\n- Parse the data and use simple functions to pull out the desired data (interpret_response module)\n\n# Usage\n\n## Getting it\n\nTo download datagrab, either fork this github repo or simply use Pypi via pip.\n\n## Using it\n\n### Basic usage\n\n#### Getting a response and some text values\n\nLet's assume the server is not expecting any specific header or other content:\n\n    # RetrievedResponse is the class used to get the raw http response\n    >>> from datagrab.retrieve_response.retrieve_response import RetrievedResponse\n    >>> from datagrab.interpret_response.interpret_html_response import (\n      ResponseInterpreter)\n\n    >>> rr = RetrievedResponse(\"https://www.bbc.co.uk\")\n\n    # Send the http request and ensure that we actually got a 200 response\n    # This method incorporates a number of exception handlers for most types\n    # of http response codes (too many redirects, server not found etc.)\n\n    >>> rr.getValidate()\n\n    >>> rr.response #attribute created by getValidate method just executed\n    <Response [200]>\n\n    >>> ri = ResponseInterpreter(rr.response)\n\n    # print anything with a h1-tag\n    >>> for i in ri.getTextByElementType(\"h1\"):\n          print(i)\n\n    BBC Homepage\n\nNote that getTextByElementType returns a <map> object. This is handy because\nyou probably need an iterable in any case.\n\n#### Getting attribute text\n\nLet's say you want to retrieve all the link urls on a page (a common toy example).\nThen you'd need all the hrefs of all \\<a> tags.\n\n    # Continued from above\n    >>> hrefs = ri.getAttributeText(\"a\", \"href\")\n    >>> next(hrefs)\n    \"https://www.bbc.co.uk\"\n\n#### Searching by attribute\n\nWe cover two use cases here:\n\n1. We want to find elements which have a specific attribute, where that attribute\n   can take any value.\n2. We want to find elements with an attribute having a specific value.\n\nLet's see it in action.\n\n    # Continued from above\n    # Search for anything with a src attribute\n\n    >>> srcs = ri.getElementsByType(True, # search for anything with a truthy tag\n                                        # - i.e. any tag\n                    attrs=\"src\")       # with a src attribute\n\n    >>> srcs[0] # getElementsByType method returns a list, so we can index it normally\n\n    <script src=*bbc script file*><script>\n\n    # Search for any link sending the user to the Homepage\n    >>> hp_links = ri.getElementsByType(\"a\", attrs={\"href\":\"https://www.bbc.co.uk\"})\n    >>> hp_links[0]\n\n    <a href=\"https://www.bbc.co.uk\">Homepage</a>\n\nIt's worth noting that the elements we retrieve here are still just BeautifulSoup\nelement.Tag instances. So you can still access properties like .text, .attrs etc.\nif you find that more intuitive.\n\nAdding support for access to child nodes as a method of the ResponseInterpreter\nclass is a #TODO, but for now you can use the BeautifulSoup methods explained in\n[this StackOverflow question](\n  https://stackoverflow.com/questions/6287529/how-to-find-children-of-nodes-using-beautifulsoup\n  ).\n\n### Intermediate usage\n\n#### Connecting to REST services\nIf the service you want to get resources from just requires you to submit a url,\nyou do as above up to rr.getValidate().\n\nBut if you need [Basic Auth](https://en.wikipedia.org/wiki/Basic_access_authentication),\nwe've got you covered with the following...\n\n    >>> from datagrab.RESTConnect.basicAuth import BasicAuth\n    >>> from datagrab.retrieve_response.retrieve_response import RetrievedResponse\n\n    >>> ba = basicAuth(<my_username>, key=<my_app_key>) # Has attribute .basicAuthHeader\n\nNote that the basicAuth class does not **need** a `key` kwarg to instantiate or be used\nsuccessfully. Some REST API's provide non-sensitive data and just require you to encode\nyour app key as the basic auth username. UK's Companies House API at time of writing\nis a good example of this.\n\nNow, we can use the .basicAuthHeader attribute of our ba instance to enhance the\nRetrievedResponse class.\n\n    # Continued from above\n    # In keyword argument request_kwargs you can, if needed, add other keyword\n    # arguments to a requests.get call such as proxies or params.\n\n    >>> rr = RetrievedResponse(<my_url>, request_kwargs={\"headers\":ba.basicAuthHeader})\n    >>> rr.getValidate()\n    >>> rr.response\n    <Response [200]>\n\nAnd that's it!\n\nOAuth support is a #TODO\n\n#### Interpreting JSON data\nMost RESTful services these days return data in JSON format -- unless you're using\nsteam-powered enterprise ERP's and the like, in which case you're still using\nxml (for which the interpret_html_response examples above should do the job).\n\n    from datagrab.interpret_response.interpret_json_response import JsonResponseInterpreter\n\nThis example draws on [Brian Dew's brilliant example of using the IMF's data api](\n  http://www.bd-econ.com/imfapi1.html). This query delivers monthly import price\n  index data for the UK between 2010 and 2011.\n\n    # Build the url and request the data\n    >>> url_base = 'http://dataservices.imf.org/REST/SDMX_JSON.svc/'\n    >>> query = 'CompactData/IFS/M.GB.PMP_IX?startPeriod=2010&endPeriod=2011' # adjust codes here\n    >>> query_url = url_base+query\n    >>> rr = RetrievedResponse(query_url)\n    >>> rr.getValidate()\n\n    # instantiate JsonResponseInterpreter\n    >>> jri = JsonResponseInterpreter(rr.response)\n    # If you want, you can look at the raw text of the Response\n    >>> jri.requestResponseText[:71]\n    '{\"CompactData\":{\"@xmlns:xsi\":\"http://www.w3.org/2001/XMLSchema-instance'\n\nOne of the more cumbersome parts of working with JSON data is acttually getting\nto the node that you're interested in. This requires a lot of square brackets, in\nour case\n\n    jri.jsonDict[\"CompactData\"][\"DataSet\"][\"Series\"][\"Obs\"]\n\nFirstly, how do we know that this is the correct series of brackets?\n\nThe \"easiest\" way of getting to grips with a JSON data structure is normally to\ndump it to a json file and use a desktop IDE to explore it.\nBut suppose we're on a work machine which doesn't let us install anything so\nnice, or we just don't want to go through the hassle of yet another window on\nour already cluttered desktop.\n\nYou'll be pleased to know that our JsonResponseInterpreter has a solution for\nthat, which is based on the `treelib` library. It allows us to view a hierarchical\nelement tree of all the nodes in the JSON\n\n    >>>jri.visualize_json()\n    CompactData\n    ├── @xmlns\n    ├── @xmlns:xsd\n    ├── @xmlns:xsi\n    ├── @xsi:schemaLocation\n    ├── CompactData\n    ├── DataSet\n    │   ├── @xmlns\n    │   └── Series\n    │       ├── @BASE_YEAR\n    │       ├── @FREQ\n    │       ├── @INDICATOR\n    │       ├── @REF_AREA\n    │       ├── @TIME_FORMAT\n    │       ├── @UNIT_MULT\n    │       └── Obs\n    └── Header\n        ├── DataSetID\n        ├── ID\n        ├── Prepared\n        ├── Receiver\n        │   └── @id\n        ├── Sender\n        │   ├── @id\n        │   ├── Contact\n        │   │   ├── Telephone\n        │   │   └── URI\n        │   └── Name\n        │       ├── #text\n        │       └── @xml:lang\n        └── Test\n\nBut we still have the following problem:\n\n*Writing all of those square brackets is boring, error-prone and non-intuitive.*\n\nWhat we want to do is feed to a function a list representing the node path that we want\nto traverse. Well, since you asked...\n\nTo check out a particular point on the element tree, we can start using a\nconvenience method attached to our `jri` object: `jri.json_tree_traverse`\n\nThe bit we're interested in is the `\"DataSet\"` child nodes.\n\n    >>> jri.json_tree_traverse([\"CompactData\",\"DataSet\"])\n    {'@xmlns': 'http://dataservices.imf.org/compact/IFS',\n    'Series': {'@FREQ': 'M',\n    '@REF_AREA': 'GB',\n    '@INDICATOR': 'PMP_IX',\n    '@UNIT_MULT': '0',\n    '@BASE_YEAR': '2010=100',\n    '@TIME_FORMAT': 'P1M',\n    'Obs': [{'@TIME_PERIOD': '2010-01', '@OBS_VALUE': '96.7710371819961'},\n    {'@TIME_PERIOD': '2010-02', '@OBS_VALUE': '97.5538160469667'},\n    {'@TIME_PERIOD': '2010-03', '@OBS_VALUE': '100.391389432485'},\n    ...\n\n    # So, it seems we need to traverse to the 'Series'->'Obs' node to get the actual data.\n\n    >>> import_price_index_data = jri.json_tree_traverse(\n          [\"CompactData\", \"DataSet\",\"Series\", \"Obs\"])\n\n    >>> import_price_index_data[:3]\n    [{'@TIME_PERIOD': '2010-01', '@OBS_VALUE': '96.7710371819961'},\n     {'@TIME_PERIOD': '2010-02', '@OBS_VALUE': '97.5538160469667'},\n     {'@TIME_PERIOD': '2010-03', '@OBS_VALUE': '100.391389432485'}]\n\nSo far, so good.\n\nBut now, let's say we want to take what we've got and just look at the value\nfor January 2011.\n\nWe have a convenience function for this!\n\n    >>> from datagrab.interpret_response.interpret_json_response import (\n     query_json_with_func, query_json)\n\n    # query_json allows you to query based on the key-value pair\n\n    >>> jan_2010 = query_json(import_price_index_data,\"@TIME_PERIOD\",\"2011-01\")  \n\nOften, you'll actually want to do more sophisticated queries. For example, you\nmight want to see change over time for a specific period of the year.\n\n`query_json_with_func` is a more flexible option. You can pass it your own\nfilter function.\n\n    >>> jan_all = query_json_with_func(import_price_index_data,\n                        lambda x: x[\"@TIME_PERIOD\"][-3:]==\"-01\")\n\n    # query_json_with_func returns a `filter` so we'll view it here as a list.\n\n    >>> list(jan_all)\n    [{'@TIME_PERIOD': '2010-01', '@OBS_VALUE': '96.7710371819961'},\n     {'@TIME_PERIOD': '2011-01', '@OBS_VALUE': '104.598825831703'}]",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/HEtothe/datagrab",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "datagrab",
    "package_url": "https://pypi.org/project/datagrab/",
    "platform": "",
    "project_url": "https://pypi.org/project/datagrab/",
    "project_urls": {
      "Homepage": "https://github.com/HEtothe/datagrab"
    },
    "release_url": "https://pypi.org/project/datagrab/0.1.4/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "The easy way to access and interpret textual web resources",
    "version": "0.1.4",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 7734546,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "19d7bdce3e506adbbf18909076209434b13b64606a105fc689910d1da2edc4ca",
          "md5": "a3067dce38da5d534a61e3096b59345a",
          "sha256": "1fbaa6884a4907aee6f5d88c8fb6d4d2a182c0e3dc89ba35053232bbd7b31f5b"
        },
        "downloads": -1,
        "filename": "datagrab-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "a3067dce38da5d534a61e3096b59345a",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 8290,
        "upload_time": "2020-06-27T16:23:40",
        "upload_time_iso_8601": "2020-06-27T16:23:40.392964Z",
        "url": "https://files.pythonhosted.org/packages/19/d7/bdce3e506adbbf18909076209434b13b64606a105fc689910d1da2edc4ca/datagrab-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e10ac2e592babd4c3a6b61961578fb5061f9216d60015e3784c41cd536b7b75c",
          "md5": "262b0cc6971f36c92082bb0dfb935449",
          "sha256": "3ea27289626799460f8d3900e622ab2f44bac5bd70f565b78a895497ba5a0254"
        },
        "downloads": -1,
        "filename": "datagrab-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "262b0cc6971f36c92082bb0dfb935449",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 7819,
        "upload_time": "2020-06-27T16:23:42",
        "upload_time_iso_8601": "2020-06-27T16:23:42.492408Z",
        "url": "https://files.pythonhosted.org/packages/e1/0a/c2e592babd4c3a6b61961578fb5061f9216d60015e3784c41cd536b7b75c/datagrab-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6876806c0d3d091da2e4fa22d5440286b620b00c2dc756ca0941db58e2001137",
          "md5": "30da5ead84c467aa01715aad888d62bd",
          "sha256": "2a18c8c146b826072ad8d38f163f7bdd7df80902d18d0c36423237f48d47b8b0"
        },
        "downloads": -1,
        "filename": "datagrab-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "30da5ead84c467aa01715aad888d62bd",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 8953,
        "upload_time": "2020-07-18T18:32:26",
        "upload_time_iso_8601": "2020-07-18T18:32:26.195028Z",
        "url": "https://files.pythonhosted.org/packages/68/76/806c0d3d091da2e4fa22d5440286b620b00c2dc756ca0941db58e2001137/datagrab-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bf1736b2f0319f8f863f45454ef4471e59a04bc9bd7393adf2253f06d9704361",
          "md5": "3a3f786403f8c09d9217a5d842e04470",
          "sha256": "ffdd89380c537965e1d3a63adaaa6291467656863fc653604a8cdac166a7309c"
        },
        "downloads": -1,
        "filename": "datagrab-0.1.3.tar.gz",
        "has_sig": false,
        "md5_digest": "3a3f786403f8c09d9217a5d842e04470",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 9446,
        "upload_time": "2020-07-18T19:19:08",
        "upload_time_iso_8601": "2020-07-18T19:19:08.390653Z",
        "url": "https://files.pythonhosted.org/packages/bf/17/36b2f0319f8f863f45454ef4471e59a04bc9bd7393adf2253f06d9704361/datagrab-0.1.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d292d2cde9ec9f338446e8db9535f6356f764fb4f2477cf06a4973b3cef376f2",
          "md5": "94058a0faa929304ef0d7d623896ea34",
          "sha256": "eed25ae7725ce1374c56b1c67edea2f40729fd6d7ea62d490a1d31c20a0d5795"
        },
        "downloads": -1,
        "filename": "datagrab-0.1.4.tar.gz",
        "has_sig": false,
        "md5_digest": "94058a0faa929304ef0d7d623896ea34",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 9459,
        "upload_time": "2020-07-19T17:13:21",
        "upload_time_iso_8601": "2020-07-19T17:13:21.038778Z",
        "url": "https://files.pythonhosted.org/packages/d2/92/d2cde9ec9f338446e8db9535f6356f764fb4f2477cf06a4973b3cef376f2/datagrab-0.1.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "d292d2cde9ec9f338446e8db9535f6356f764fb4f2477cf06a4973b3cef376f2",
        "md5": "94058a0faa929304ef0d7d623896ea34",
        "sha256": "eed25ae7725ce1374c56b1c67edea2f40729fd6d7ea62d490a1d31c20a0d5795"
      },
      "downloads": -1,
      "filename": "datagrab-0.1.4.tar.gz",
      "has_sig": false,
      "md5_digest": "94058a0faa929304ef0d7d623896ea34",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 9459,
      "upload_time": "2020-07-19T17:13:21",
      "upload_time_iso_8601": "2020-07-19T17:13:21.038778Z",
      "url": "https://files.pythonhosted.org/packages/d2/92/d2cde9ec9f338446e8db9535f6356f764fb4f2477cf06a4973b3cef376f2/datagrab-0.1.4.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}