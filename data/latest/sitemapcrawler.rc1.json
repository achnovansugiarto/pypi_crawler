{
  "info": {
    "author": "",
    "author_email": "Barry Melton <barry@sureisfun.com>",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Sitemap Crawler\n\nsitemapcrawler is a simple, blocking Python Crawler that is the backbone of a few other projects.\n\nYou're welcome to use it, but it's only as modular as we've needed it to be, which is to say, probably not fit for projects that aren't built with this in mind.\n\nIt works pretty simply.\n\n## Installation\n\n```\npip install sitemapcrawler\n```\n\n## Usage\n\n```\nfrom sitemapcrawler import Crawler\ncrawler = Crawler(domain=\"https://yourdomain.com\", sitemap=\"https://yourdomain.com/sitemap.xml\", fetch=True)\ncrawler.run()\n```\n\nIf you just want to fetch a given page, create an instance of the crawler and call it like this:\n\n```\ncrawler.fetch_page(url=\"https://yourdomain.com/blog/title\")\n```\n\nThe `init` will create a nanoid `crawl_id` so that when results are persisted, they'll be associated to a given crawl, to make it easy for reports to be built against crawls and such.\n\n## Building / Distributing\n\n```\npython3 -m build\npython3 -m twine upload dist/* --skip-existing\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "sitemapcrawler",
    "package_url": "https://pypi.org/project/sitemapcrawler/",
    "platform": null,
    "project_url": "https://pypi.org/project/sitemapcrawler/",
    "project_urls": {
      "Bug Tracker": "https://github.com/bmelton/sitemapcrawler/issues",
      "Homepage": "https://github.com/bmelton/sitemapcrawler"
    },
    "release_url": "https://pypi.org/project/sitemapcrawler/0.0.1/",
    "requires_dist": null,
    "requires_python": ">=3.7",
    "summary": "A simple sitemap crawler that acts as the backbone for other operations",
    "version": "0.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17058879,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "612021ffa645e18fbfe551ea2368491a022cadf567180aedeac959c5691888ab",
          "md5": "1b3285357dbd6385bc7907d8d2e6fc12",
          "sha256": "36cf4553f0030ae132c7fa6f15b03846b50209c73102819dd8515fa86103640e"
        },
        "downloads": -1,
        "filename": "sitemapcrawler-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "1b3285357dbd6385bc7907d8d2e6fc12",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 3367,
        "upload_time": "2023-02-27T02:30:07",
        "upload_time_iso_8601": "2023-02-27T02:30:07.430088Z",
        "url": "https://files.pythonhosted.org/packages/61/20/21ffa645e18fbfe551ea2368491a022cadf567180aedeac959c5691888ab/sitemapcrawler-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0cfa8f0e3acfd638636b2059be5d0440635ebb0f0a57d7093e199d5fb4fdadbc",
          "md5": "a26eed562c81a6076d7e198c0e09e254",
          "sha256": "b2b81d09ab0a3e291f822112705158869ac2e62d9d9777d68df0e2dfc86d6ef9"
        },
        "downloads": -1,
        "filename": "sitemapcrawler-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "a26eed562c81a6076d7e198c0e09e254",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 2445,
        "upload_time": "2023-02-27T02:30:08",
        "upload_time_iso_8601": "2023-02-27T02:30:08.711451Z",
        "url": "https://files.pythonhosted.org/packages/0c/fa/8f0e3acfd638636b2059be5d0440635ebb0f0a57d7093e199d5fb4fdadbc/sitemapcrawler-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "612021ffa645e18fbfe551ea2368491a022cadf567180aedeac959c5691888ab",
        "md5": "1b3285357dbd6385bc7907d8d2e6fc12",
        "sha256": "36cf4553f0030ae132c7fa6f15b03846b50209c73102819dd8515fa86103640e"
      },
      "downloads": -1,
      "filename": "sitemapcrawler-0.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "1b3285357dbd6385bc7907d8d2e6fc12",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 3367,
      "upload_time": "2023-02-27T02:30:07",
      "upload_time_iso_8601": "2023-02-27T02:30:07.430088Z",
      "url": "https://files.pythonhosted.org/packages/61/20/21ffa645e18fbfe551ea2368491a022cadf567180aedeac959c5691888ab/sitemapcrawler-0.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "0cfa8f0e3acfd638636b2059be5d0440635ebb0f0a57d7093e199d5fb4fdadbc",
        "md5": "a26eed562c81a6076d7e198c0e09e254",
        "sha256": "b2b81d09ab0a3e291f822112705158869ac2e62d9d9777d68df0e2dfc86d6ef9"
      },
      "downloads": -1,
      "filename": "sitemapcrawler-0.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "a26eed562c81a6076d7e198c0e09e254",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 2445,
      "upload_time": "2023-02-27T02:30:08",
      "upload_time_iso_8601": "2023-02-27T02:30:08.711451Z",
      "url": "https://files.pythonhosted.org/packages/0c/fa/8f0e3acfd638636b2059be5d0440635ebb0f0a57d7093e199d5fb4fdadbc/sitemapcrawler-0.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}