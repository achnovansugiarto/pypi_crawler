{
  "info": {
    "author": "Samuel Baker",
    "author_email": "samuelbaker.researcher@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3.7"
    ],
    "description": "# pyGenicCT\n\nClumping via plink and then p value thresholding through python\n\n## Instructions\n\nThis will give show how i have created clumped PRS via plink and python. It is assuming you are working with systems similar to the IEU in bristol and have access to BlueCrystal 4, but should be adjustable to other systems and locations with some minor adjustment. \n\n### Getting and formatting summary statistics\n\nFirst you will need some summary statistics in a tsv file format for plink. If you have data from the GWAS catalog it should work as is, where as if you have data from the IEU OpenGWAS it will be in a .vcf file. Plink won't like using that as a summary statistic file, so we need to convert it. \n\nWe can do this within the pyGenicParser package, from loading the VCFObject object. Provide VCF object the path to your vcf file, it can be gzipped VCFObject will read both zipped and non zipped files. If using the OpenGWAS data you will have some headings you don't need. Whilst you do not need to filter them out you can do so if you choose. Then, covert it to a tsv via convert_to_summary, by providing the output path and a file name. OpenGWAS files also store the p values in Log P, where as plink is expecting p values. We can convert them back by giving the file header to log_p_convert. \n\n\n```python\nfrom pyGenicParser import VCFObject\n\npath_to_vcf = r\"Path_Here\"\n\nvcf = VCFObject(path_to_vcf)\n\n# If your using the OpenGWAS data you will have these headers that we don't need\nfor hv in [\"QUAL\", \"FILTER\", \"SS_format_0\", \"EZ_format_0\", \"SI_format_0\", \"NC_format_0\", \"ID_format_0\"]:\n    vcf.write_headers[hv] = False\n\n# This will give Where ID is the variatn ID, LP is the log p value, and ES is the estimated coefficient.\nprint([hv for hv, ht in vcf.write_headers.items() if ht])\n>> ['CHROM', 'POS', 'ID', 'REF', 'ALT', 'AF_info', 'ES_format_0', 'SE_format_0', 'LP_format_0', 'AF_format_0']\n\nvcf.covert_to_summary(r\"Output_Path\", \"File_name\", log_p_convert=\"LP_format_0\")\n\n```\n### Clumping via plink\n\nThe basic commands you need to run the plink file are as follows, this runs a conservative clump based on the parameters for Clumping of twoSampleMR. Here we are using the same LD reference as used by the [IEU OpenGWAS by default](https://github.com/mrcieu/gwasvcf/) which can be downloaded at this github page as the ***1000 Genomes reference panels for LD for each super population***.  If using the OpenGWAS, the only variable you will **need** to change is the path to this LD preference (--bfile) and the name of the summary statistic file you created from the VCFObject (--clump). \n\nThis is also assuming you are using the Slurm method of job submission. Should you be using Bluecrystal phase 3 which uses the PBS job system see [this conversion](https://www.acrc.bris.ac.uk/protected/bc4-docs/scheduler/index.html#slurm-for-speakers-of-other-scheduler-languages), if using something else you may be able to convert it via [this conversion resource](https://slurm.schedmd.com/rosetta.html). \n\n```bash \n\n#!/bin/bash\n\n# Generated by pyGenicCT Version: 0.01.0\n#SBATCH --job-name=Clump\n#SBATCH --partition=test\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1\n#SBATCH --cpus-per-task=1\n#SBATCH --time=0:10:00\n#SBATCH --mem=10000M\n\nmodule load apps/plink/1.90\n\nplink \\\n\t--bfile LDReference/EUR \\\n\t--clump-p1 1 \\\n\t--clump-p2 1 \\\n\t--clump-r2 0.001 \\\n\t--clump-kb 10000 \\\n\t--clump File_Name.tsv.gz\\\n\t--clump-snp-field ID \\\n\t--clump-field LP_format_0 \\\n\t--out EUR_CLUMP_Edu \\\n\t--threads 1\n```\n\nOnce this is completed you will get a few files from plink, which we then want to extract the snps that we have clumped on out off. To do this we can use another script with awk. This will unzipped and then re-zip the data as required. \n\n```bash\n#!/bin/bash\n\n# Generated by pyGenicCT Version: 0.01.0\n#SBATCH --job-name=ExtractResults\n#SBATCH --partition=test\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1\n#SBATCH --cpus-per-task=1\n#SBATCH --time=0:10:00\n#SBATCH --mem=10000M\n\nawk '{print $1,$3}' EUR_CLUMP_Edu.clumped > SNP.valid\ngzip -d file_name.tsv.gz\n\nawk '{print $3,$7,$9}' file_name.tsv > SNP.values\ngzip Okbay.tsv\n\n```\n\nYou can also generate these scripts in python should you wish via the following\n\n\n```python\nfrom pyGenicCT import plink_clump, extract_results\n\nplink_clump(r\"Local script save location\",\n            \"Clump\",\n            \"apps/plink/1.90\",\n            \"/LDReference/EUR\",\n            \"SummaryFile.tsv\",\n            \"EUR_CLUMP\",\n            snp_field=\"ID\",\n            p_field=\"LP_format_0\"\n            )\n\nextract_results(r\"Local script save location\",\n                \"ExtractResults\",\n                \"SummaryFile.tsv\",\n                \"EUR_CLUMP.clumped\",\n                3, 7, 9)\n\n```\n\n### Creating the PRS\n\nNow we want to link the snps we found to the summary data so that we can use it to create the PRS. All of these scripts are in python, and call the CTScores object which takes a yaml file as its only parameter. Since we are going to need to set it up later, lets fully define it now.\n\n```yaml\nchromosome_index: 0\nsnp_index: 1\ncoefficient_index: 2\np_value_index: 3\n\nValid: /SNP.valid\nValues: /SNP.values\nvalid_snp_name: SNP\nvalues_snp_name: variant_id\n\nmeta_path: pysnptools Meta Path\ngen_path: Genetic path\nwrite_path: working directory\nwrite_name: PRSScore\nbase_name: data.chr\n\nthreshold: [0.00000005, 0.00005, 0.005, 0.05, 1]\n```\n\nThe first four variables should not need to be changed unless a version adds additional variables to link_resources(). Valid and Values are the paths to the files you created via extract_results, with the the column headers of the variant name for each file being given after that.\n\nThis package uses pysnptools, which creates metadata. You need to provide a writable path for this metadata if you do not have write permissions to the location of the genetic files. **This pipeline is currently only configured to work with Bgen data.** You then need to provide the directory that holds the chromosome data, set the write name of the final output, and the base name of the genetic files; for example **data.chr**02.bgen. Finally you need to set the P value thresholds you want to iterate though.\n\nNow using this yaml file as a soul argument, submit a python script with the following below via sbatch and this will link the resources for you ready for use. \n\n```python\nfrom CTScores import CTScores\nimport sys\n\nprint(f\"submitting {sys.argv[1]}\")\n\nCTScores(sys.argv[1]).link_resources()\n\n```\n\nThis will make a file called Snps.csv in your working directory. All you need to do now is run the script with\ncreate_score_levels and this will now create the p_value thresholds PRS of the levels you defined in threshold within the .yaml file as a csv called whatever the write_name was set as. Keep in mind, this assumes that the IID's are embedded into the Bgen files, as the IIDs will be extract from within it rather than via .sample. This may be extended to allow for this in future. \n\n```python\nfrom CTScores import CTScores\nimport sys\n\nprint(f\"submitting {sys.argv[1]}\")\n\nCTScores(sys.argv[1]).create_score_levels()\n\n```\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "https://github.com/sbaker-dev/pyGenicCT",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "MIT",
    "maintainer": "Samuel Baker",
    "maintainer_email": "samuelbaker.researcher@gmail.com",
    "name": "pyGenicCT",
    "package_url": "https://pypi.org/project/pyGenicCT/",
    "platform": "",
    "project_url": "https://pypi.org/project/pyGenicCT/",
    "project_urls": {
      "Download": "https://github.com/sbaker-dev/pyGenicCT"
    },
    "release_url": "https://pypi.org/project/pyGenicCT/0.2.0/",
    "requires_dist": [
      "miscSupports",
      "pandas",
      "pysnptools",
      "csvObject",
      "numpy"
    ],
    "requires_python": ">=3.7",
    "summary": "Clumping via plink and then p value thresh-holding through python",
    "version": "0.2.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 10798750,
  "releases": {
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4965c597d1a3ba861aeed3fdfb8a5d10623cb4b2360293837da533fbec9710f8",
          "md5": "88ea84b2ba93cb3a0453f1ac2b8a0ba2",
          "sha256": "f1a35360ff40735c775bf8d40e00a228ccdc8ac9282b3ee5f415d96e436d7720"
        },
        "downloads": -1,
        "filename": "pyGenicCT-0.2.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "88ea84b2ba93cb3a0453f1ac2b8a0ba2",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 9360,
        "upload_time": "2021-07-01T17:06:43",
        "upload_time_iso_8601": "2021-07-01T17:06:43.781028Z",
        "url": "https://files.pythonhosted.org/packages/49/65/c597d1a3ba861aeed3fdfb8a5d10623cb4b2360293837da533fbec9710f8/pyGenicCT-0.2.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "4965c597d1a3ba861aeed3fdfb8a5d10623cb4b2360293837da533fbec9710f8",
        "md5": "88ea84b2ba93cb3a0453f1ac2b8a0ba2",
        "sha256": "f1a35360ff40735c775bf8d40e00a228ccdc8ac9282b3ee5f415d96e436d7720"
      },
      "downloads": -1,
      "filename": "pyGenicCT-0.2.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "88ea84b2ba93cb3a0453f1ac2b8a0ba2",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 9360,
      "upload_time": "2021-07-01T17:06:43",
      "upload_time_iso_8601": "2021-07-01T17:06:43.781028Z",
      "url": "https://files.pythonhosted.org/packages/49/65/c597d1a3ba861aeed3fdfb8a5d10623cb4b2360293837da533fbec9710f8/pyGenicCT-0.2.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}