{
  "info": {
    "author": "ZhouYang Luo",
    "author_email": "zhouyang.luo@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Topic :: Scientific/Engineering :: Artificial Intelligence"
    ],
    "description": "# naive-tokenizers\nTokenizers for NLP tasks.\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/naivenlp/naive-tokenizers",
    "keywords": "",
    "license": "Apache Software License",
    "maintainer": "",
    "maintainer_email": "",
    "name": "naive-tokenizers",
    "package_url": "https://pypi.org/project/naive-tokenizers/",
    "platform": "",
    "project_url": "https://pypi.org/project/naive-tokenizers/",
    "project_urls": {
      "Homepage": "https://github.com/naivenlp/naive-tokenizers"
    },
    "release_url": "https://pypi.org/project/naive-tokenizers/0.0.1/",
    "requires_dist": [
      "jieba"
    ],
    "requires_python": "",
    "summary": "Tokenizers for NLP tasks.",
    "version": "0.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 7888967,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "aa960fbd1bafab612eacb21dd46a6799906897222eadf90d523be257504aa4c3",
          "md5": "456bb9fe1fa10d3246678a6d18ba7e85",
          "sha256": "4189bf554867ff8249114b3ee87cbec72be90c8e7aed1209a77acc178a087ac1"
        },
        "downloads": -1,
        "filename": "naive_tokenizers-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "456bb9fe1fa10d3246678a6d18ba7e85",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 14715,
        "upload_time": "2020-08-05T11:32:27",
        "upload_time_iso_8601": "2020-08-05T11:32:27.678557Z",
        "url": "https://files.pythonhosted.org/packages/aa/96/0fbd1bafab612eacb21dd46a6799906897222eadf90d523be257504aa4c3/naive_tokenizers-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9db937f7855d555f3c730c80d6e6151ae7ef36230b3ed63c84596dee0482668c",
          "md5": "1dd13a417d66c10513e5c7cee3fa38b6",
          "sha256": "fb075eeaebe4b53d9584fe89ce226ad685b0dbe9b7a8bf7084f3b02bd10e8104"
        },
        "downloads": -1,
        "filename": "naive-tokenizers-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "1dd13a417d66c10513e5c7cee3fa38b6",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 8221,
        "upload_time": "2020-08-05T11:32:29",
        "upload_time_iso_8601": "2020-08-05T11:32:29.983296Z",
        "url": "https://files.pythonhosted.org/packages/9d/b9/37f7855d555f3c730c80d6e6151ae7ef36230b3ed63c84596dee0482668c/naive-tokenizers-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "aa960fbd1bafab612eacb21dd46a6799906897222eadf90d523be257504aa4c3",
        "md5": "456bb9fe1fa10d3246678a6d18ba7e85",
        "sha256": "4189bf554867ff8249114b3ee87cbec72be90c8e7aed1209a77acc178a087ac1"
      },
      "downloads": -1,
      "filename": "naive_tokenizers-0.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "456bb9fe1fa10d3246678a6d18ba7e85",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 14715,
      "upload_time": "2020-08-05T11:32:27",
      "upload_time_iso_8601": "2020-08-05T11:32:27.678557Z",
      "url": "https://files.pythonhosted.org/packages/aa/96/0fbd1bafab612eacb21dd46a6799906897222eadf90d523be257504aa4c3/naive_tokenizers-0.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "9db937f7855d555f3c730c80d6e6151ae7ef36230b3ed63c84596dee0482668c",
        "md5": "1dd13a417d66c10513e5c7cee3fa38b6",
        "sha256": "fb075eeaebe4b53d9584fe89ce226ad685b0dbe9b7a8bf7084f3b02bd10e8104"
      },
      "downloads": -1,
      "filename": "naive-tokenizers-0.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "1dd13a417d66c10513e5c7cee3fa38b6",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 8221,
      "upload_time": "2020-08-05T11:32:29",
      "upload_time_iso_8601": "2020-08-05T11:32:29.983296Z",
      "url": "https://files.pythonhosted.org/packages/9d/b9/37f7855d555f3c730c80d6e6151ae7ef36230b3ed63c84596dee0482668c/naive-tokenizers-0.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}