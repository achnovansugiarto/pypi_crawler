{
  "info": {
    "author": "Guillaume Bernard",
    "author_email": "contact@guillaume-bernard.fr",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: GNU General Public License v3 (GPLv3)",
      "Operating System :: POSIX :: Linux",
      "Programming Language :: Python :: 3.9",
      "Topic :: Scientific/Engineering :: Artificial Intelligence"
    ],
    "description": "# Compute TF-IDF weights for texts\n\nCompute TF-IDF weights for tokens, lemmas, entities, etc. of your datasets from a file that contains features.\n\n## Installation\n\n```bash\npip install compute_tf_idf_weights\n```\n\n## Pre-requisites\n\n### Dependencies\n\nThis project relies on two other packages: [`document_tracking_resources`](https://gitlab.univ-lr.fr/cross-lingual-event-tracking/developpement/from-documents-to-events/documents_tracking_resources) and [`document_processing`](https://gitlab.univ-lr.fr/cross-lingual-event-tracking/developpement/from-documents-to-events/document_processing). This code needs to have access to those packages.\n\n## Data\n\n### spaCy resources\n\nAs this package uses the `document_processing` package, spaCy models are given in order to process the documents of the corpus. You then need to install [spaCy models](https://spacy.io/usage/models) for your languages.\n\nThe following mapping is used, and you should download the models if you want to process those languages.\n\n```python\nmodel_names = {\n    \"deu\": \"de_core_news_md\",\n    \"spa\": \"es_core_news_md\",\n    \"eng\": \"en_core_web_md\",\n}\n```\n\n### The feature files\n\nThis program computes TF-IDF vectors according to an external database of document features. You can get them by looking at the two projects below:\n\n- [`twitter_tf_idf_dataset`](https://gitlab.univ-lr.fr/cross-lingual-event-tracking/datasets/tf_idf_datasets/twitter_tf_idf_dataset): used to create a features document to compute vectors using a database of thousands of Tweets from many press agencies or online newspapers.\n- [`news_tf_idf_dataset`](https://gitlab.univ-lr.fr/cross-lingual-event-tracking/datasets/tf_idf_datasets/news_tf_idf_dataset): used to create a features document to compute vectors using thousands of scrapped Deutsche Welle articles from which the content is extracted.\n\nThose two project will help you produce the document required by the `--features_file` option of the `compute_tf_idf_weights_of_corpus.py` program. \n\n**Please, note that all the language of the original corpus must be present in the same file, with a `lang` column to indicate which feature belong to which language.**\n\n**For each document text content (either `title`, `text` or both) should have at least three features: `tokens`, `entities` and `lemmas`. If the corpus contains only a `text` feature, the features file will contain for instance `tokens_text`, `lemmas_text`, `entitites_text`.**\n\nBelow is the header of the file of features:\n```csv\n,tokens_title,lemmas_title,entities_title,tokens_text,lemmas_text,entities_text,lang\n[…]\n```\n\n### The corpus to process\n\nThe script can process two different types of Corpus from `document_tracking_resources`. The one for News (`NewsCorpusWithSparseFeatures`), the other one for Tweets (`TwitterCorpusWithSparseFeatures`). The datafiles should be loaded by `document_tracking_resources` in order to have this project to work.\n\nFor instance, below an example of a `TwitterCorpusWithSparseFeatures`:\n\n```text\n                                         date lang                                text               source  cluster\n1218234203361480704 2020-01-17 18:10:42+00:00  eng  Q: What is a novel #coronavirus...      Twitter Web App   100141\n1218234642186297346 2020-01-17 18:12:27+00:00  eng  Q: What is a novel #coronavirus...                IFTTT   100141\n1219635764536889344 2020-01-21 15:00:00+00:00  eng  A new type of #coronavirus     ...            TweetDeck   100141\n...                                       ...  ...                                 ...                  ...      ...\n1298960028897079297 2020-08-27 12:26:19+00:00  eng  So you come in here WITHOUT A M...   Twitter for iPhone   100338\n1310823421014573056 2020-09-29 06:07:12+00:00  eng  Vitamin and mineral supplements...            TweetDeck   100338\n1310862653749952512 2020-09-29 08:43:05+00:00  eng  FACT: Vitamin and mineral suppl...  Twitter for Android   100338\n```\n\nAnd an example of a `NewsCorpusWithSparseFeatures`:\n```text\n                              date lang                     title               text                     source  cluster\n24290965 2014-11-02 20:09:00+00:00  spa  Ponta gana la prim   ...  Las encuestas...                    Publico     1433\n24289622 2014-11-02 20:24:00+00:00  spa  La cantante Katie Mel...  La cantante b...          La Voz de Galicia      962\n24290606 2014-11-02 20:42:00+00:00  spa  Los sondeos dan ganad...  El Tribunal  ...                    RTVE.es     1433\n...                            ...  ...                       ...               ...                        ...      ...\n47374787 2015-08-27 12:32:00+00:00  deu  Microsoft-Betriebssys...  San Francisco...               Handelsblatt      170\n47375011 2015-08-27 12:44:00+00:00  deu  Microsoft-Betriebssy ...  San Francisco...               WiWo Gründer      170\n47394969 2015-08-27 20:35:00+00:00  deu  Windows 10: Mehr als ...  In zwei Tagn ...                  gamona.de      170\n```\n\n## Command line arguments\n\nOnce installed, the command `compute_tf_idf_vectors` can be used directly, as registered in your PATH.\n\n```text\nusage: compute_tf_idf_vectors [-h] --corpus CORPUS --dataset-type {twitter,news} --features-file FEATURES_FILE --output-corpus OUTPUT_CORPUS\n\nTake a document corpus (in pickle format) and perform TF-IDF lookup in order to extract the feature weights.\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --corpus CORPUS       Path to the pickle file containing the corpus to process.\n  --dataset-type {twitter,news}\n                        The kind of dataset to process. ‘twitter’ will use the ’TwitterCorpusWithSparseFeatures’ class, the ‘NewsCorpusWithSparseFeatures’ class otherwise\n  --features-file FEATURES_FILE\n                        Path to the CSV file that contains the learning document features in all languages.\n  --output-corpus OUTPUT_CORPUS\n                        Path where to export the new corpus with computed TF-IDF vectors.\n```\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://gitlab.univ-lr.fr/cross-lingual-event-tracking/datasets/dataset_manipulation_tools/compute_tf_idf_weights",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "compute-tf-idf-vectors",
    "package_url": "https://pypi.org/project/compute-tf-idf-vectors/",
    "platform": null,
    "project_url": "https://pypi.org/project/compute-tf-idf-vectors/",
    "project_urls": {
      "Bug Tracker": "https://gitlab.univ-lr.fr/cross-lingual-event-tracking/datasets/dataset_manipulation_tools/compute_tf_idf_weights/-/issues",
      "Homepage": "https://gitlab.univ-lr.fr/cross-lingual-event-tracking/datasets/dataset_manipulation_tools/compute_tf_idf_weights"
    },
    "release_url": "https://pypi.org/project/compute-tf-idf-vectors/1.0.3.202208310829/",
    "requires_dist": [
      "pandas (~=1.3.5)",
      "scikit-learn (~=1.0.2)",
      "tqdm (~=4.62.3)",
      "numpy (~=1.19.5)",
      "scipy (~=1.7.3)",
      "document-processing (~=1.0.0)",
      "document-tracking-resources (~=1.0.0)"
    ],
    "requires_python": ">=3.9",
    "summary": "Utility to compute sparse TF-IDF vector representation for dataset in the document_tracking_resources format based on a feature file.",
    "version": "1.0.3.202208310829",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14946429,
  "releases": {
    "1.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4a1ce86f3071974669f465622e157733816ba6719a97aa8b06c2563543ea6849",
          "md5": "61e2b6e3c0c641e439a79b62d3a72c0d",
          "sha256": "ee3d060db37e5f52cd488c33f1952e0107dd1fec7b07cd425acd9d40559a4082"
        },
        "downloads": -1,
        "filename": "compute_tf_idf_vectors-1.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "61e2b6e3c0c641e439a79b62d3a72c0d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.9",
        "size": 20357,
        "upload_time": "2022-03-29T20:09:25",
        "upload_time_iso_8601": "2022-03-29T20:09:25.014011Z",
        "url": "https://files.pythonhosted.org/packages/4a/1c/e86f3071974669f465622e157733816ba6719a97aa8b06c2563543ea6849/compute_tf_idf_vectors-1.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4fd2fefe516321ce5e6888fce40b5d8aa2f08ae675487b268a006a17a283b56e",
          "md5": "41328be259a33d63ab9c4469107256f7",
          "sha256": "a47f1361f52df551af0ed55497e9e4323ae6a4a413a3c2a38418000ad2e9df68"
        },
        "downloads": -1,
        "filename": "compute_tf_idf_vectors-1.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "41328be259a33d63ab9c4469107256f7",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.9",
        "size": 19979,
        "upload_time": "2022-03-29T20:09:27",
        "upload_time_iso_8601": "2022-03-29T20:09:27.155653Z",
        "url": "https://files.pythonhosted.org/packages/4f/d2/fefe516321ce5e6888fce40b5d8aa2f08ae675487b268a006a17a283b56e/compute_tf_idf_vectors-1.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.2.202203301306": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "585d9cfbf393236845cba1212abce9437e6ca90b488fd70f360ba74cdc39173c",
          "md5": "03917d4e03af063d5ad49de3bc06b55b",
          "sha256": "f7a7f8415aaa3f8863f1e48f502570ebde0413dfd954eb5ca389490ae56fb417"
        },
        "downloads": -1,
        "filename": "compute_tf_idf_vectors-1.0.2.202203301306-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "03917d4e03af063d5ad49de3bc06b55b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.9",
        "size": 20531,
        "upload_time": "2022-03-30T13:07:23",
        "upload_time_iso_8601": "2022-03-30T13:07:23.029994Z",
        "url": "https://files.pythonhosted.org/packages/58/5d/9cfbf393236845cba1212abce9437e6ca90b488fd70f360ba74cdc39173c/compute_tf_idf_vectors-1.0.2.202203301306-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fa2ad2216117d8995f8dfb88fb393cef298b860f27eeba46135e30b11ccdfc54",
          "md5": "8dc34c59faac86f32ba753527a46efcf",
          "sha256": "28e9f6f63880d753a4c31f9512cff923de3537422857f6c4f52376f7142e31b5"
        },
        "downloads": -1,
        "filename": "compute_tf_idf_vectors-1.0.2.202203301306.tar.gz",
        "has_sig": false,
        "md5_digest": "8dc34c59faac86f32ba753527a46efcf",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.9",
        "size": 20067,
        "upload_time": "2022-03-30T13:07:24",
        "upload_time_iso_8601": "2022-03-30T13:07:24.221445Z",
        "url": "https://files.pythonhosted.org/packages/fa/2a/d2216117d8995f8dfb88fb393cef298b860f27eeba46135e30b11ccdfc54/compute_tf_idf_vectors-1.0.2.202203301306.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.3.202208310829": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "01a49ae480bfc2975658345b7cfde50702fe0ae4cebb92f59b411da497f3e714",
          "md5": "014a23d072f4fd07c3f5ffeb51d6759d",
          "sha256": "7964a148308486b421d16ab4dd25eedf3cf13d847ae64cc649a0d292bdb70135"
        },
        "downloads": -1,
        "filename": "compute_tf_idf_vectors-1.0.3.202208310829-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "014a23d072f4fd07c3f5ffeb51d6759d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.9",
        "size": 20920,
        "upload_time": "2022-08-31T08:29:50",
        "upload_time_iso_8601": "2022-08-31T08:29:50.442442Z",
        "url": "https://files.pythonhosted.org/packages/01/a4/9ae480bfc2975658345b7cfde50702fe0ae4cebb92f59b411da497f3e714/compute_tf_idf_vectors-1.0.3.202208310829-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "01a49ae480bfc2975658345b7cfde50702fe0ae4cebb92f59b411da497f3e714",
        "md5": "014a23d072f4fd07c3f5ffeb51d6759d",
        "sha256": "7964a148308486b421d16ab4dd25eedf3cf13d847ae64cc649a0d292bdb70135"
      },
      "downloads": -1,
      "filename": "compute_tf_idf_vectors-1.0.3.202208310829-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "014a23d072f4fd07c3f5ffeb51d6759d",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.9",
      "size": 20920,
      "upload_time": "2022-08-31T08:29:50",
      "upload_time_iso_8601": "2022-08-31T08:29:50.442442Z",
      "url": "https://files.pythonhosted.org/packages/01/a4/9ae480bfc2975658345b7cfde50702fe0ae4cebb92f59b411da497f3e714/compute_tf_idf_vectors-1.0.3.202208310829-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}