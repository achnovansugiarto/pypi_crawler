{
  "info": {
    "author": "junjieluo",
    "author_email": "floydjjluo@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Topic :: Software Development :: Build Tools"
    ],
    "description": "```\n.\n├── __init__.py\n├── base.py\n├── corpus.py\n├── folder.py\n├── text.py\n├── sentence.py\n├── token.py\n└── utils\n    ├── channel.py\n    ├── grain.py\n    ├── infrastructure.py\n    └── pyramid.py\n\n```\n\n\n# 1. Pyramid\n\nFrom Corpus to Groups to Texts to Sentences to Tokens\n\n1. Save `COPRUS`, `GROUP`, `TEXT`, `SENT` and `TOKEN`\n\n2. Save token to `file/token.txt`.\n\n3. Get Token Vocabulary (`idx2token`, `token2index`), and token frequency (`idx2freq`).\n\n# 2. Query\n\n1. Construct a connection across corpus, group, text, sentence and token.\n\n2. Given a sentence Idx (the location index), get the sentence content\n\n3. Given a text Idx (the location index), get the text content.\n\n4. Given a token Idx (the location index), get the token content.\n\n# 3. Annotation\n\n1. By whatever means, from group to texts, for each texts, we need to prepare `[strText:str, SSET:[content:str, start:int, end:int, label: str]]`. Besides, we need to verify that SSET is valid for strText.\n\n2. Then strText is processed to `strSents: [strSent:str]`.\n\n3. Together with strText and strSents, we use SSET to get the tag sequence for each strSent. The tag is in the BIOES tag scheme. However, instead of saving the tag string, we save the tag idx this time.\n\n4. Save the token to `file/annoE_idx.txt`. Each line is the tag seqeuence correponding to the line of the original sentence in `file/token.txt`.\n\n5. We also need to query the annotation tag sequence from that file.\n\n6. Build the `BIOES_trans`. This is a dictioanry. The formal content is bioesidx2bioidx. Its path should be `BIOES_trans['annoE']['BIO']`.\n\n\n# 4. Hyper Field of Token Granularity (i.e. part-of-speech, word level)\n\nHyper field of token granularity means the hyper field entity corresponds to exactly one token entity.\n\nFor example, a part-of-speech entity corresponds to exactly one word. When the token level is word, part-of-speech is the hyper field of token granularity.\n\n1. We need to develop a function to get hyper field grains for a given sentence.\n\n2. This is on the process of sentence to tokens. Input is strSent: str, and output is `tokens: [token:str]` and `tags: [tag:str]`, where tag is of BIOES tagging scheme. Similar to annotation, we also only save the tag idx and save all of them into file/pos_idx.txt.\n\n3. We also need to query the annotation tag sequence from that file.\n\n4. Build the `BIOES_trans`. This is a dictioanry. The formal content is bioesidx2bioidx. Its path should be `BIOES_trans['pos']['BIO']`.\n\n\n# 5. Hyper Field of Larger Granularity (i.e. named entitiy)\n\nHyper field whose granularity larger than token means the hyper field entity corresponds to more than (including equal to) one token entity.\n\n1. We need to develop a function to get hyper field grains for a given sentence.\n\n2. This is on the process of sentence to tokens. Input is strSent: str, and output is tags[tag:str], where tag is of BIOES tagging scheme. Similar to annotation, we also only save the tag idx and save all of them into file/pos_idx.txt.\n\n3. We also need to query the annotation tag sequence from that file.\n\n4. Build the `BIOES_trans`. This is a dictioanry. The formal content is bioesidx2bioidx. Its path should be `BIOES_trans['ner']['BIO']`.\n\n\n# 6. Sub Field Information\n\nSub field information refers to the grains that only determined exclusively by a token, such as the letter sequence of an English word.\n\n1. We need to develop a function to get sub field grains for a given sentence.\n\n2. Get Sub field Grain Vocabulary based on the token vocabulary, and the n-gram we choose.\n\n3. Get the frequency tables of the sub field grains based on the whole corpus and on the whole token vocabulary.\n\n4. Get the Look Up Table to connect token vocabulary and sub field vocabulary.\n\n# 7. Query Field Information\n\nFor sentences and tokens, whether they are from our corpus pyramid or are newly created, given a field, get their field grain sequence.\n\n1. `get_grain_str`\n\n2. `get_grain_idx`\n\nThey are APIs for further tasks.\n\n# 8. Chunk of Texts or Sentences\n\nSometimes we need a chunk of texts or sentences where the number of tokens numbers in this chunk is close to and smaller than a constant, say, 10000. One scenario is for word embedding training.\n\nUse text as an instance, the data we want is: chunkidx2endtxtidx.\n\nFor each chunk, get all text idxs in it. From startidx to endidx.\n\nThe following still uses text as the instance. The concrete operation:\n\n```\nchunkidx_2_endbyteidx = [] # the text that is not included inside this chunk.\nchunkidx_2_cumlengoftexts = []\n\ncurrent_chunk_lengoftexts = []\ncurrent_chunk_length_count = 0\nfor text in texts:\n\ttext_token_num = text.get_tokens_num()\n\n\tif current_chunk_length_count + text_token_num > 10000:\n\n\t\t# get and save the chunkendbyteidx\n\t\t# this is correct, notice that this text is not include in this chunk\n\n\t\tendbyteidx = text.get_endbyteidx() \n\t\tchunkidx_2_endbyteidx.append(endbyteidx)\n\n\t\t# save the txtidx2endtokenidx, derived from lengoftexts\n\t\tchunkidx_2_cumlengoftexts.append(np.cumsum(current_chunk_lengoftexts))\n\n\t\t# get the new the current chunk information\n\t\tcurrent_chunk_length_count = text_token_num\n\t\tcurrent_chunk_lengoftexts = [text_token_num]\n\n\telse:\n\t\t# update current_chunk_length_count when it is <= 10000\n\t\tcurrent_chunk_length_count = current_chunk_length_count + text_token_num\n\n\t\t# append the object's length in the current_chunk_lengoftexts\n\t\tcurrent_chunk_lengoftexts.append(text_token_num)\n\n# when the loop is over, we still need the to append \n# the last small chunk into the total chunks.\n# here, the object is the smallest object.\nendbyteidx = object.get_endbyteidx()\nchunkidx_2_endbyteidx.append(endbyteidx)\n\n# save the txtidx2endtokenidx, derived from lengoftexts\nchunkidx_2_cumlengoftexts.append(np.cumsum(current_chunk_lengoftexts))\n```\n\nEventually, we get chunkidx_2_endbyteidx and chunkidx_2_cumlengoftexts.\n\nThen we should think out how to produce jobs. Each chunk is for one job.\n\n```\n# the file we need to read is of path: path_token\njob_paras = []\nfor chunkidx in range(len(chunkidx_2_endbyteidx)):\n\tstartbyteidx = 0 if chunkidx == 0 else chunkidx_2_endbyteidx[chunkidx-1]\n\tendbyteidx = chunkidx_2_endbyteidx[chunkidx-1]\n\tchunk_token_string = read_str_from_file(path_token, startbyteidx, endbyteidx)\n\t# for the text in the chunk.\n\ttxtidx2endtokenidx = chunkidx_2_lengoftexts[chunk_string]\n\tjob_para = (chunk_token_string, txtidx2endtokenidx)\n\tjob_paras.append(job_para)\n```\n\nInside the fieldembed_core.pyx, the method is:\n\n```\n# for the input: chunk_tokens (i.e. chunk_token_string), txtidx2endtokenidx.\n# we first prepare chunk_token_seq.\n\nchunk_tokens = chunk_tokens.split() # i.e. chunk_token_seq\n\n# then loop the text sequence in chunk_tokens\n\ntoken_indexes = []\ntext_endidx   = []\n\nnew_chunk_idx = 0\n\n\nfor txtidx, endtokenidx in enumerate(txtidx2endtokenidx):\n\tstarttokenidx = 0 if txtidx == 0 else txtidx2endtokenidx[endtokenidx - 1]\n\tfor tokenidx in range(starttokenidx, endtokenidx):\n\t\ttokenstr = get_token_str(tokenidx)\n\t\ttokenvocidx = get_token_vocidx(tokenstr)\n\n\t\tif tokenvocidx not meets conditions:\n\t\t\tcontinue\n\n\t\ttoken_indexes.append(tokenvocidx)\n\t\tnew_chunk_idx = new_chunk_idx + 1\n\n\ttext_endidx.append(new_chunk_idx)\n\n# at the end, we get token_indexes, text_endidx, new_chunk_idx.\n\n```\n\n\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "nlptext",
    "package_url": "https://pypi.org/project/nlptext/",
    "platform": "",
    "project_url": "https://pypi.org/project/nlptext/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/nlptext/0.0.3.3/",
    "requires_dist": [
      "jieba (==0.42.1)",
      "nltk (==3.5)",
      "numpy (==1.19.0)",
      "pandas (==1.0.5)",
      "Pyphen (==0.9.5)",
      "smart-open (==2.0.0)",
      "check-manifest ; extra == 'dev'",
      "coverage ; extra == 'test'",
      "pytest ; extra == 'test'",
      "pylint ; extra == 'test'"
    ],
    "requires_python": ">=3.6, <4",
    "summary": "nlptext for natural language processing",
    "version": "0.0.3.3",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 7603807,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fd426185c79b3df8038893b63215576b143f2227da21ed5bf395216d127eac52",
          "md5": "04f3b2d79c4d154e40c1bf5aef0b34e8",
          "sha256": "83e337b56a85a1900499caec42c5b465d7b2360e61a0efb676ae0877a1f939e0"
        },
        "downloads": -1,
        "filename": "nlptext-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "04f3b2d79c4d154e40c1bf5aef0b34e8",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6, <4",
        "size": 38837,
        "upload_time": "2020-06-28T08:24:43",
        "upload_time_iso_8601": "2020-06-28T08:24:43.663372Z",
        "url": "https://files.pythonhosted.org/packages/fd/42/6185c79b3df8038893b63215576b143f2227da21ed5bf395216d127eac52/nlptext-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e350eb45fc5aa8458823504226b7547c3be517e88e147f24ac173b647769fcf1",
          "md5": "60a33231fcb1ef797c023b4760d365fa",
          "sha256": "209eee904d4b0c104fba48d73825cca3fd0a0c680f1c793e0c8d826431df5d3b"
        },
        "downloads": -1,
        "filename": "nlptext-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "60a33231fcb1ef797c023b4760d365fa",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6, <4",
        "size": 36898,
        "upload_time": "2020-06-28T08:24:45",
        "upload_time_iso_8601": "2020-06-28T08:24:45.942781Z",
        "url": "https://files.pythonhosted.org/packages/e3/50/eb45fc5aa8458823504226b7547c3be517e88e147f24ac173b647769fcf1/nlptext-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4cb6075f9a1101bbbcebefd14576e63af63d561b014015d604fcac82968b7186",
          "md5": "78babb3ee80e248e90d37536c017be49",
          "sha256": "becbc97df5a2a2b0d265d3dc9dc57a7403ffa1b5b3feea824154655b542135ba"
        },
        "downloads": -1,
        "filename": "nlptext-0.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "78babb3ee80e248e90d37536c017be49",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6, <4",
        "size": 38839,
        "upload_time": "2020-06-28T08:52:11",
        "upload_time_iso_8601": "2020-06-28T08:52:11.090782Z",
        "url": "https://files.pythonhosted.org/packages/4c/b6/075f9a1101bbbcebefd14576e63af63d561b014015d604fcac82968b7186/nlptext-0.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0da8476490021f744a9daa02146da37d6347419fb8b34d668534dfbe66a0d5d1",
          "md5": "c127749260343bd94e30898a37cae4fe",
          "sha256": "c290c4e520dcd1076da2eb205d9c97a176607b9bf2b7a637d4b38d2a671c885a"
        },
        "downloads": -1,
        "filename": "nlptext-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "c127749260343bd94e30898a37cae4fe",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6, <4",
        "size": 34247,
        "upload_time": "2020-06-28T08:52:12",
        "upload_time_iso_8601": "2020-06-28T08:52:12.485385Z",
        "url": "https://files.pythonhosted.org/packages/0d/a8/476490021f744a9daa02146da37d6347419fb8b34d668534dfbe66a0d5d1/nlptext-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6cca0ec066f8a2ace166d1c847d2a40c0bbaa12d9336e1d0ebcc15a6726f1d50",
          "md5": "12b3357403d55b614cf3a7387a2f6e13",
          "sha256": "9ff947a3b5bbc7759337e5315a1137115ac515e394e72b2feb4427346756c856"
        },
        "downloads": -1,
        "filename": "nlptext-0.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "12b3357403d55b614cf3a7387a2f6e13",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6, <4",
        "size": 38932,
        "upload_time": "2020-06-28T09:06:27",
        "upload_time_iso_8601": "2020-06-28T09:06:27.830480Z",
        "url": "https://files.pythonhosted.org/packages/6c/ca/0ec066f8a2ace166d1c847d2a40c0bbaa12d9336e1d0ebcc15a6726f1d50/nlptext-0.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0d1bb5b914c48db860c17b123a7e952538c410e2f123aae79276854736bafdd6",
          "md5": "83d95cf11815481a9dd582c625c35669",
          "sha256": "a86aca1bb7bbab57585fa59ed9845e375ff0f583829dd22ab66d21e5380f4094"
        },
        "downloads": -1,
        "filename": "nlptext-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "83d95cf11815481a9dd582c625c35669",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6, <4",
        "size": 37017,
        "upload_time": "2020-06-28T09:06:29",
        "upload_time_iso_8601": "2020-06-28T09:06:29.487244Z",
        "url": "https://files.pythonhosted.org/packages/0d/1b/b5b914c48db860c17b123a7e952538c410e2f123aae79276854736bafdd6/nlptext-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d1c8fdbada828fed0e040d694b01b5a56a1dbae624986264bc578165e673a82e",
          "md5": "6d3683e7b5b0c56bcb3d14dba20d925a",
          "sha256": "1867880c9d31e651504b04c91d23e69968f258c9a2a034ac2b8511d734b333a8"
        },
        "downloads": -1,
        "filename": "nlptext-0.0.3.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "6d3683e7b5b0c56bcb3d14dba20d925a",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6, <4",
        "size": 4126268,
        "upload_time": "2020-06-28T09:14:56",
        "upload_time_iso_8601": "2020-06-28T09:14:56.645716Z",
        "url": "https://files.pythonhosted.org/packages/d1/c8/fdbada828fed0e040d694b01b5a56a1dbae624986264bc578165e673a82e/nlptext-0.0.3.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "217074a4022d026dc761896b98ddbc1a4e87b385e8bb1e9182fff3d8661494a8",
          "md5": "8f84ffeaaaca7371d9fc60bceac62335",
          "sha256": "350e21a2d380923da0203912e3af975b74cc29b5785bc4b485c3f324fe3d5e0d"
        },
        "downloads": -1,
        "filename": "nlptext-0.0.3.1.tar.gz",
        "has_sig": false,
        "md5_digest": "8f84ffeaaaca7371d9fc60bceac62335",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6, <4",
        "size": 4091437,
        "upload_time": "2020-06-28T09:14:59",
        "upload_time_iso_8601": "2020-06-28T09:14:59.670338Z",
        "url": "https://files.pythonhosted.org/packages/21/70/74a4022d026dc761896b98ddbc1a4e87b385e8bb1e9182fff3d8661494a8/nlptext-0.0.3.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "623ed55012c1b42ffe7a3e4ac56e25bc513520fd9ab876fd0ade91d6efef2ace",
          "md5": "89931ad5b466579abc80f0486144bb90",
          "sha256": "fb24c70c479ca9515e6e05806d8eb8da36089cf389f967dc664e5cf1e73821be"
        },
        "downloads": -1,
        "filename": "nlptext-0.0.3.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "89931ad5b466579abc80f0486144bb90",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6, <4",
        "size": 4126260,
        "upload_time": "2020-06-28T09:22:01",
        "upload_time_iso_8601": "2020-06-28T09:22:01.750388Z",
        "url": "https://files.pythonhosted.org/packages/62/3e/d55012c1b42ffe7a3e4ac56e25bc513520fd9ab876fd0ade91d6efef2ace/nlptext-0.0.3.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b6cbfc274d05e76cd819b29b134457437e007bc1425183a5f7f242b33d9acf7d",
          "md5": "2464e5deb5b7c1dee0a0d2593f590ebe",
          "sha256": "8095788b0b1398807be30b4ce0f02f8e40991d27c238d0aa41d65500f71f058c"
        },
        "downloads": -1,
        "filename": "nlptext-0.0.3.2.tar.gz",
        "has_sig": false,
        "md5_digest": "2464e5deb5b7c1dee0a0d2593f590ebe",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6, <4",
        "size": 4091462,
        "upload_time": "2020-06-28T09:22:05",
        "upload_time_iso_8601": "2020-06-28T09:22:05.032322Z",
        "url": "https://files.pythonhosted.org/packages/b6/cb/fc274d05e76cd819b29b134457437e007bc1425183a5f7f242b33d9acf7d/nlptext-0.0.3.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "547093905c1666a6cedc635f1b79bdeed71cbad3c34be031829e578e3ba43ebb",
          "md5": "4c90a18a725325ab76f0d3a831efd946",
          "sha256": "1d6eb8f91d1365aab4e06ccecdaf4c6f4e7441661e31955a5c7b3711830026fc"
        },
        "downloads": -1,
        "filename": "nlptext-0.0.3.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "4c90a18a725325ab76f0d3a831efd946",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6, <4",
        "size": 4126260,
        "upload_time": "2020-07-01T07:33:06",
        "upload_time_iso_8601": "2020-07-01T07:33:06.027764Z",
        "url": "https://files.pythonhosted.org/packages/54/70/93905c1666a6cedc635f1b79bdeed71cbad3c34be031829e578e3ba43ebb/nlptext-0.0.3.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9272ebef071e88a4a2c225fe37a5495af0f7ba1392458c8dcb85a2863d1af06d",
          "md5": "9602bb27136370f1e9f4bf74308e01dc",
          "sha256": "4217e94ed18b037c850797bf1d6d5c87353be6784730abd65120e26ff2746052"
        },
        "downloads": -1,
        "filename": "nlptext-0.0.3.3.tar.gz",
        "has_sig": false,
        "md5_digest": "9602bb27136370f1e9f4bf74308e01dc",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6, <4",
        "size": 4088216,
        "upload_time": "2020-07-01T07:33:10",
        "upload_time_iso_8601": "2020-07-01T07:33:10.167623Z",
        "url": "https://files.pythonhosted.org/packages/92/72/ebef071e88a4a2c225fe37a5495af0f7ba1392458c8dcb85a2863d1af06d/nlptext-0.0.3.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "547093905c1666a6cedc635f1b79bdeed71cbad3c34be031829e578e3ba43ebb",
        "md5": "4c90a18a725325ab76f0d3a831efd946",
        "sha256": "1d6eb8f91d1365aab4e06ccecdaf4c6f4e7441661e31955a5c7b3711830026fc"
      },
      "downloads": -1,
      "filename": "nlptext-0.0.3.3-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "4c90a18a725325ab76f0d3a831efd946",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6, <4",
      "size": 4126260,
      "upload_time": "2020-07-01T07:33:06",
      "upload_time_iso_8601": "2020-07-01T07:33:06.027764Z",
      "url": "https://files.pythonhosted.org/packages/54/70/93905c1666a6cedc635f1b79bdeed71cbad3c34be031829e578e3ba43ebb/nlptext-0.0.3.3-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "9272ebef071e88a4a2c225fe37a5495af0f7ba1392458c8dcb85a2863d1af06d",
        "md5": "9602bb27136370f1e9f4bf74308e01dc",
        "sha256": "4217e94ed18b037c850797bf1d6d5c87353be6784730abd65120e26ff2746052"
      },
      "downloads": -1,
      "filename": "nlptext-0.0.3.3.tar.gz",
      "has_sig": false,
      "md5_digest": "9602bb27136370f1e9f4bf74308e01dc",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6, <4",
      "size": 4088216,
      "upload_time": "2020-07-01T07:33:10",
      "upload_time_iso_8601": "2020-07-01T07:33:10.167623Z",
      "url": "https://files.pythonhosted.org/packages/92/72/ebef071e88a4a2c225fe37a5495af0f7ba1392458c8dcb85a2863d1af06d/nlptext-0.0.3.3.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}