{
  "info": {
    "author": "Jerome Abdelnour",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: GNU General Public License v3 (GPLv3)",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Torch-reproducible-block\n[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)\n\nRandom number generation is hard to control when experimenting with neural networks. Setting a random seed only get us so far. Each random operation affects the random number generator state. \n\nChanges to the model hyper-parameters or architecture can affect how each layer is initialised, the regularisation techniques, how the data is presented to the network during training and more.\n\nThis package aims to reduce **variability** by limiting **side effects** caused by **random number generation**. The main goal is to **limit the changes** to the rest of the network when **experimenting** with different hyper-parameters.\n\n## What is the problem ?\nThe weight initialisation of a layer constitute a random operation. The initialisation order therefore have an impact on subsequent layers.\n\n![Problem Definition](https://github.com/J3rome/torch-reproducible-block/raw/master/img/problem.png)\n\n\nIn this small toy model, the **initial weights** of the fully connected layers will be **different** if we have a different number of convolutive layers. The initialisation of a **pre-trained feature extractor** might also comprises random operation which will **affect the rest of the network**. A different random state will also affect the **dataloading** process since it also rely on random operations to select random examples when creating batches.\n\n\n## Solution\nWe isolate different parts of the network by wrapping them inside a `Reproducible_Block` \n\n![Reproducible Block Solution](https://github.com/J3rome/torch-reproducible-block/raw/master/img/solution.png)\n\n\n## How does it work ?\n\n`Reproducible_Block.set_seed(SEED_VALUE)` must be called **before** any random operation. This will set the `python`, `numpy` and `torch` seeds and will save a copy of the `initial random number generator state`.\n\n\nWhen entering a `Reproducible_Block` the random number generator state is reset to the `initial state`. The state is then mutated according to the `Block Seed` value ensuring that each block have a different state. To mutate the state, we simply run `X` random operations where `X` is `Block Seed`. \n\n\nFeel free to take at look at the code, it's only about 100 lines.\n\n## Installation\nThe package can be installed via pip :\n\n```bash\npip install torch-reproducible-block\n```\n\nThe following packages are required :\n\n```\ntorch\nnumpy\n```\n\n\n\n## Usage\n```python\nfrom reproducible_block import Reproducible_Block\n\nclass My_model(nn.Module):\n    def __init__(self):\n        with Reproducible_Block(block_seed=64):\n            self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=[2,2])\n            self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=[2,2])\n\n        with Reproducible_Block(block_seed=44):\n            self.fc = nn.Linear(64, 128)\n            self.out = nn.Linear(128, 10)\n            \n    def forward(self, batch):\n        ...\n    \nif __name__ == \"__main__\":\n    # Will set seed and save the initial random state\n    Reproducible_Block.set_seed(42)\n    \n    model = My_model()\n    # Data loading and other configurations which might do random operations....\n    \n    # Ensure that we always have the same random state when starting training\n    with Reproducible_Block(block_seed=128):\n        train_model(model, data, ...)\n```\n\n\nReproducible block can also be used as a function decorator  :\n```python\n@Reproducible_Block(block_seed=128)\ndef train_model(model, dataloader, ...):\n    ...\n```\n\n\n## Remarks\n- Using a different `initial seed` (Via `Reproducible_Block.set_seed()`), will result in a different random state for each `Reproducible_Block`.\n- The `block seed` is \"part of the code\". You should not attempt to tweak it the way we do with \"normal seed\". Changing the `initial seed` is what you want to do in order to create different initial conditions for your training.\n- Using the same `block seed` for different `Reproducible_Block` will result in the same random state. \n  Make sure that you are using a different `block seed` for each block.\n- Was tested on `Ubuntu 18.04` with `python 3.6`. Should not have any problems running on other platforms. Fill up an issue if you have any problems.\n\n## Other sources of randomness\nThis package won't make your research 100% reproducible. It simply aim to isolate part of your program to side effects.\n\n- Setting the `PYTHONHASHSEED` environment variable is always a good idea.\n- The way python read files from directories (ex : `os.listdir()`)  can vary when ran on different OS (Linux vs Windows)\n- Different version of `python`, `Cuda`, `Cudnn` and libraries can affect reproducibility\n\n## Contributing\nThe code is pretty simple, have a look at it and if you have improvements ideas feel free to submit a pull request !\n\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/j3rome/torch-reproducible-block",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "torch-reproducible-block",
    "package_url": "https://pypi.org/project/torch-reproducible-block/",
    "platform": "",
    "project_url": "https://pypi.org/project/torch-reproducible-block/",
    "project_urls": {
      "Homepage": "https://github.com/j3rome/torch-reproducible-block"
    },
    "release_url": "https://pypi.org/project/torch-reproducible-block/0.0.1/",
    "requires_dist": [
      "numpy",
      "torch"
    ],
    "requires_python": ">=3.6",
    "summary": "Control random number generator state via reproducible blocks",
    "version": "0.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 11055638,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "17b29bcd58d55bb7ee35d6a5bd62149d810a7075e4ba202524cb1b98493bf340",
          "md5": "c8d146c0bd96606bdca6f12feab39314",
          "sha256": "5085e0b9f992365645481febbed045760a71f308c268fb406e03a695ccea6a76"
        },
        "downloads": -1,
        "filename": "torch_reproducible_block-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "c8d146c0bd96606bdca6f12feab39314",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 16967,
        "upload_time": "2021-07-31T00:54:52",
        "upload_time_iso_8601": "2021-07-31T00:54:52.479638Z",
        "url": "https://files.pythonhosted.org/packages/17/b2/9bcd58d55bb7ee35d6a5bd62149d810a7075e4ba202524cb1b98493bf340/torch_reproducible_block-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "15d1892edce340cf14670ecc1a0bdddca2d9603218d561746f05b68e167c769d",
          "md5": "a00fc42aa3a86c661a5858bf7d02ce1a",
          "sha256": "cbaa93e2377ecc18ad974d116a3018349461d885e2cc6d4f011bf25b2beed496"
        },
        "downloads": -1,
        "filename": "torch-reproducible-block-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "a00fc42aa3a86c661a5858bf7d02ce1a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 16330,
        "upload_time": "2021-07-31T00:54:54",
        "upload_time_iso_8601": "2021-07-31T00:54:54.258548Z",
        "url": "https://files.pythonhosted.org/packages/15/d1/892edce340cf14670ecc1a0bdddca2d9603218d561746f05b68e167c769d/torch-reproducible-block-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "17b29bcd58d55bb7ee35d6a5bd62149d810a7075e4ba202524cb1b98493bf340",
        "md5": "c8d146c0bd96606bdca6f12feab39314",
        "sha256": "5085e0b9f992365645481febbed045760a71f308c268fb406e03a695ccea6a76"
      },
      "downloads": -1,
      "filename": "torch_reproducible_block-0.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "c8d146c0bd96606bdca6f12feab39314",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 16967,
      "upload_time": "2021-07-31T00:54:52",
      "upload_time_iso_8601": "2021-07-31T00:54:52.479638Z",
      "url": "https://files.pythonhosted.org/packages/17/b2/9bcd58d55bb7ee35d6a5bd62149d810a7075e4ba202524cb1b98493bf340/torch_reproducible_block-0.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "15d1892edce340cf14670ecc1a0bdddca2d9603218d561746f05b68e167c769d",
        "md5": "a00fc42aa3a86c661a5858bf7d02ce1a",
        "sha256": "cbaa93e2377ecc18ad974d116a3018349461d885e2cc6d4f011bf25b2beed496"
      },
      "downloads": -1,
      "filename": "torch-reproducible-block-0.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "a00fc42aa3a86c661a5858bf7d02ce1a",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 16330,
      "upload_time": "2021-07-31T00:54:54",
      "upload_time_iso_8601": "2021-07-31T00:54:54.258548Z",
      "url": "https://files.pythonhosted.org/packages/15/d1/892edce340cf14670ecc1a0bdddca2d9603218d561746f05b68e167c769d/torch-reproducible-block-0.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}