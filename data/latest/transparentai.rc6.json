{
  "info": {
    "author": "Nathan LAUGA",
    "author_email": "nathan.lauga@protonmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "# TransparentAI\n*Is my AI ethic ?*\n\n[![Travis CI](https://travis-ci.com/Nathanlauga/transparentai.svg?branch=master)](https://travis-ci.com/Nathanlauga/transparentai)\n[![Documentation](https://readthedocs.org/projects/transparentai/badge/?version=latest)](http://transparentai.readthedocs.io/en/latest/?badge=latest)\n[![PyPI version](https://badge.fury.io/py/transparentai.svg)](https://badge.fury.io/py/transparentai)\n[![PyPI license](https://img.shields.io/pypi/l/ansicolortags.svg)](https://pypi.python.org/pypi/ansicolortags/)\n[![Python 3.6](https://img.shields.io/badge/python-3.6+-blue.svg)](https://www.python.org/downloads/release/python-360/)\n\nTransparentAI is a toolbox in Python to answer the question \"Is my AI ethic ?\" based on the European Commission requierements.\n\n## Why this tool ?\n\nThe research of ethic in the Artificial Intelligence field is a hot topic. More than 70 papers between 2016 and 2019 ([Algorithm Watch, 2019](https://algorithmwatch.org/en/project/ai-ethics-guidelines-global-inventory/)). But many papers just present the question of \"What should be an ethic AI\" not the \"How to do it\". In consequence, many developers become fustrated and still don't really know to do it in practive ([Peters, May 2019](https://medium.com/ethics-of-digital-experience/beyond-principles-a-process-for-responsible-tech-aefc921f7317)).\n\n`TransparentAI` is an answer to this question. The philosophy is that, in coherence with the [Ethics Guidelines for Trustworthy AI](https://ec.europa.eu/futurium/en/ai-alliance-consultation) by the European Commission, you can find out easily (in Python) if **\"your AI is ethic\"** !\n\n**New tool :** This is a new tool so if you found any bugs or other kind of problems please do not hesitate to report them on the\nissues GitHub page from the library here : https://github.com/Nathanlauga/transparentai/issues. I hope you will enjoy this tool and help me to improve it!\n\nDocumentation is available here : [API Documentation](https://transparentai.readthedocs.io/en/latest/).\n\n## Table of content\n\n1. [Installation](#installation)\n2. [Compatible model and data type](#compatible-model-and-data-type)\n3. [Getting started](#getting-started)\n    - [Is my model biased ?](#is-my-model-biased-)\n    - [How can I explain my model ?](#how-can-i-explain-my-model-)\n    - [What's my model performance ?](#whats-my-model-performance-)\n    - [What is in my data ?](#what-is-in-my-data-)\n    - [How can I know is still good over time ?](#how-can-i-know-the-model-is-still-good-over-time-)\n    - [Is my model sustainable ?](#is-my-model-sustainable-)\n    - [Do I use safe packages ?](#do-i-use-safe-packages-)\n4. [UE Commision requirements](#ue-commision-requirements)\n5. [Contributing](#contributing)\n6. [Credits and ressources](#credits-and-ressources)\n7. [Author](#author)\n8. [License](#license)\n\n## Installation\n\nYou can install it with [PyPI](https://pypi.org/project/transparentai/) :\n```\npip install transparentai\n```\n\nOr by cloning [GitHub repository](https://github.com/Nathanlauga/transparentai/)\n\n```\ngit clone https://github.com/Nathanlauga/transparentai.git\ncd transparentai\npython setup.py install\n```\n\n*****\n\n## Compatible model and data type\n\n**Version 0.2** :\n\n| Objects   | What the tool can handle                                              |\n| --------- | ----------------------------------------------------------------- |\n| **Data**  | can only handle `tabular` dataset (numpy array, pandas DataFrame) |\n| **Model** | can only handle `classification` and `regression` model           |\n\n**Coming for version 0.3** : \n\n- Data : Explore Image dataset, Text dataset\n- Model : Clustering model\n\n*****\n\n## Getting started \n\n**Take a look on the [Getting started](https://transparentai.readthedocs.io/en/latest/getting-started.html) page of the documentation or you can search specific use cases in the [`examples/`](examples/) directory.**\n\nIn this section I created a binary classifier based on [Adult dataset](http://archive.ics.uci.edu/ml/datasets/Adult). The following variables will be used :\n\n| variable       | description                      |\n| -------------- | -------------------------------- |\n| `data`         | Adult dataset as DataFrame       |\n| `clf`          | Classifier model                 |\n| `y_true`       | True labels for train set        |\n| `y_true_valid` | True labels for valid set        |\n| `y_pred`       | Predictions labels for train set |\n| `y_pred_valid` | Predictions labels for valid set |\n| `df_valid`     | Dataframe for valid set          |\n| `X_train`      | Features for train set           |\n| `X_valid`      | Features for valid set           |\n\n\n### Is my model biased ?\n\n```python\nprivileged_group = {\n    # For gender attribute Male peoples are considered to be privileged\n    'gender':['Male'],                \n    # For marital-status attribute Married peoples are considered to be privileged\n    'marital-status': lambda x: 'Married' in x,\n    # For race attribute White peoples are considered to be privileged\n    'race':['White']\n}\n\nfrom transparentai import fairness\nfairness.model_bias(y_true_valid, y_pred_valid, df_valid, privileged_group)\n```\n\nOutput:\n\n```\n{\n    \"gender\": {\n        \"statistical_parity_difference\": -0.07283528047741014,\n        \"disparate_impact\": 0.4032473042703101,\n        \"equal_opportunity_difference\": -0.04900038770381182,\n        \"average_odds_difference\": -0.026173142849183567\n    },\n    \"marital-status\": {\n        \"statistical_parity_difference\": -0.11667610209029305,\n        \"disparate_impact\": 0.27371312304160633,\n        \"equal_opportunity_difference\": 0.08345535064884008,\n        \"average_odds_difference\": 0.03867329810319946\n    },\n    \"race\": {\n        \"statistical_parity_difference\": -0.0420778376239787,\n        \"disparate_impact\": 0.5964166117990216,\n        \"equal_opportunity_difference\": -0.0004408949904296522,\n        \"average_odds_difference\": -0.002870373184105955\n    }\n}\n```\n\nThis metrics can be not easy to understand so you can use the `returns_text=True` so that you can get ths insight :\n\n```python\nfairness_txt = fairness.model_bias(y_true_valid, y_pred_valid, df_valid, privileged_group, returns_text=True)\nprint(fairness_txt['gender'])\n```\nOutput:\n```\nThe privileged group is predicted with the positive output 7.28% more often than the unprivileged group. This is considered to be fair.\nThe privileged group is predicted with the positive output 2.48 times more often than the unprivileged group. This is considered to be not fair.\nFor a person in the privileged group, the model predict a correct positive output 4.90% more often than a person in the unprivileged group. This is considered to be fair.\nFor a person in the privileged group, the model predict a correct positive output or a correct negative output 2.62% more often than a person in the unprivileged group. This is considered to be fair.\nThe model has 3 fair metrics over 4 (75%).\n```\n\nAnd if you like to get visual help use the `plot_bias` function :\n\n```python\nprivileged_group = {'gender': ['Male']}\n\nfrom transparentai import fairness\nfairness.plot_bias(y_true_valid, y_pred_valid, df_valid, privileged_group, with_text=True)\n```\n![](images/fairness.plot_bias_binary_classifier.png)\n\n\n### How can I explain my model ?\n\n```python\nfrom transparentai.models import explainers\nexplainer = explainers.ModelExplainer(clf, X_train, model_type='tree')\n\nexplainer.explain_global_influence(X_train, nsamples=1000)\n```\nOutput:\n```\n{\n    'age': 0.08075649984055841,\n    'fnlwgt': 0.05476459574744569,\n    'education-num': 0.08048316800088552,\n    'capital-gain': 0.06879137962639843,\n    'capital-loss': 0.018367250661071737,\n    'hours-per-week': 0.06009733425389803\n}\n```\n\n```python\nexplainer.plot_global_explain()\n```\n![](images/explainer.plot_global_explain_binary_classifier.png)\n\n```python\nexplainer.plot_local_explain(X_valid.iloc[0])\n```\n![](images/explainer.plot_local_explain_binary_classifier.png)\n\n### What's my model performance ?\n\n```python\nfrom transparentai.models import classification\n\n# You can use custom function with lambda\nmetrics = ['accuracy', 'roc_auc', 'f1', 'recall', 'precision', lambda y_true, y_pred: sum(y_true-y_pred)]\nclassification.compute_metrics(y_true_valid, y_pred_valid, metrics)\n```\nOutput:\n```\n{\n    'accuracy': 0.812011415808413,\n    'roc_auc': 0.8272860034692258,\n    'f1': 0.5682530635508691,\n    'recall': 0.5244608100999474,\n    'precision': 0.6200248756218906,\n    'custom_1': 586\n}\n```\n\n```python\nclassification.plot_performance(y_true, y_pred, y_true_valid, y_pred_valid)\n```\n![](images/classification.plot_performance_binary_classifier.png)\n\n### What is in my data ?\n\n```python\nfrom transparentai.datasets import variable\n\nvariable.plot_variable(data['age'])\n```\n![](images/variable.plot_variable_age.png)\n\n```python\nvariable.plot_variable(data['capital-loss'], legend=data['income'], ylog=True)\n```\n![](images/variable.plot_variable_capital_loss.png)\n\n```python\nvariable.plot_variable(data['workclass'])\n```\n![](images/variable.plot_variable_workclass.png)\n\nThe `birthdate` column was generated based on the `age` column.\n\n```python\nvariable.plot_variable(data['birthdate'], legend=data['income'])\n```\n![](images/variable.plot_variable_birthdate.png)\n\n### How can I know the model is still good over time ?\n\n`timestamp` variable was generated randomly, it represents the time of the prediction.\n\n```python\nfrom transparentai import monitoring\n\nmonitoring.plot_monitoring(y_true, y_pred, timestamp, interval='month', classification=True)\n```\n\n![](images/plot_monitoring_binary_classifier.png)\n\n### Is my model sustainable ?\n\n```python\nimport transparentai.utils as utils\nkWh, clf = utils.evaluate_kWh(clf.fit, X, Y, verbose=True)\n```\nOutput:\n```\nLocation:                                                                 France\nBaseline wattage:                                                     4.79 watts\nProcess wattage:                                                     18.45 watts\n--------------------------------------------------------------------------------\n-------------------------------  Final Readings  -------------------------------\n--------------------------------------------------------------------------------\nAverage baseline wattage:                                             3.53 watts\nAverage total wattage:                                               16.04 watts\nAverage process wattage:                                             12.51 watts\nProcess duration:                                                        0:00:07\n--------------------------------------------------------------------------------\n-------------------------------   Energy Data    -------------------------------\n--------------------------------------------------------------------------------\n                              Energy mix in France                              \nCoal:                                                                      3.12%\nPetroleum:                                                                16.06%\nNatural Gas:                                                              33.56%\nLow Carbon:                                                               47.26%\n--------------------------------------------------------------------------------\n-------------------------------    Emissions     -------------------------------\n--------------------------------------------------------------------------------\nEffective emission:                                              1.32e-05 kg CO2\nEquivalent miles driven:                                          5.39e-12 miles\nEquivalent minutes of 32-inch LCD TV watched:                   8.14e-03 minutes\nPercentage of CO2 used in a US household/day:                          4.33e-12%\n--------------------------------------------------------------------------------\n------------------------- Assumed Carbon Equivalencies -------------------------\n--------------------------------------------------------------------------------\nCoal:                                                      995.725971 kg CO2/MWh\nPetroleum:                                                816.6885263 kg CO2/MWh\nNatural gas:                                              743.8415916 kg CO2/MWh\nLow carbon:                                                         0 kg CO2/MWh\n--------------------------------------------------------------------------------\n-------------------------     Emissions Comparison     -------------------------\n--------------------------------------------------------------------------------\n                      Quantities below expressed in kg CO2                      \n        US                      Europe                  Global minus US/Europe\nMax:    Wyoming        2.85e-05 Kosovo         2.93e-05 Mongolia        2.86e-05\nMedian: Tennessee      1.40e-05 Ukraine        2.04e-05 Korea, South    2.34e-05\nMin:    Vermont        8.00e-07 Iceland        5.26e-06 Bhutan          3.26e-06\n--------------------------------------------------------------------------------\n--------------------------------------------------------------------------------\nProcess used:                                                       3.10e-05 kWh\n```\n\n### Do I use safe packages ?\n\n```python\nimport transparentai.utils as utils\nutils.check_packages_security(full_report=True)\n```\nOutput:\n```\n+==============================================================================+\n|                                                                              |\n|                               /$$$$$$            /$$                         |\n|                              /$$__  $$          | $$                         |\n|           /$$$$$$$  /$$$$$$ | $$  \\__//$$$$$$  /$$$$$$   /$$   /$$           |\n|          /$$_____/ |____  $$| $$$$   /$$__  $$|_  $$_/  | $$  | $$           |\n|         |  $$$$$$   /$$$$$$$| $$_/  | $$$$$$$$  | $$    | $$  | $$           |\n|          \\____  $$ /$$__  $$| $$    | $$_____/  | $$ /$$| $$  | $$           |\n|          /$$$$$$$/|  $$$$$$$| $$    |  $$$$$$$  |  $$$$/|  $$$$$$$           |\n|         |_______/  \\_______/|__/     \\_______/   \\___/   \\____  $$           |\n|                                                          /$$  | $$           |\n|                                                         |  $$$$$$/           |\n|  by pyup.io                                              \\______/            |\n|                                                                              |\n+==============================================================================+\n| REPORT                                                                       |\n| checked 77 packages, using default DB                                        |\n+==============================================================================+\n| No known security vulnerabilities found.                                     |\n+==============================================================================+\n```\n\n*****\n\n## UE Commision requirements\n\nThe European Commission defined seven requirements that allow to make a trustworthy AI.\n\nThese requirements are applicable to different stakeholders partaking in AI systemsâ€™ life cycle: developers, deployers and end-users, as well as the broader society. By developers, we refer to those who research, design and/or develop AI systems. By deployers, we refer to public or private organisations that use AI systems within their business processes and to offer products and services to others. End-users are those engaging with the AI system, directly or indirectly. Finally, the broader society encompasses all others that are directly or indirectly affected by AI systems. Different groups of stakeholders have different roles to play in ensuring that the requirements are met:\n\n- Developers should implement and apply the requirements to design and development processes.\n- Deployers should ensure that the systems they use and the products and services they offer meet the requirements.\n- End-users and the broader society should be informed about these requirements and able to request that they are upheld.\n\nThe below list of requirements is non-exhaustive. 35 It includes systemic, individual and societal aspects:\n\n1. **Human agency and oversight**:\nIncluding fundamental rights, human agency and human oversight\n2. **Technical robustness and safety**:\nIncluding resilience to attack and security, fall back plan and general safety, accuracy, reliability and reproducibility\n3. **Privacy and data governance**:\nIncluding respect for privacy, quality and integrity of data, and access to data\n4. **Transparency**:\nIncluding traceability, explainability and communication\n5. **Diversity, non-discrimination and fairness**:\nIncluding the avoidance of unfair bias, accessibility and universal design, and stakeholder participation\n6. **Societal and environmental wellbeing**: \nIncluding sustainability and environmental friendliness, social impact, society and democracy\n7. **Accountability**: \nIncluding auditability, minimisation and reporting of negative impact, trade-offs and redress.\n\n<div style='width=100%;text-align:center;'>\n<img src='images/en_7_requirements.png' width='440'>\n</div>\n\nThis table allows you to in details for each requirements and if it's possible how to control if the aspect is ethic with `TransparentAI`. Some aspects do not have technical implementation in this tool because it requires legal or other knowledge. If you want to understand the differents aspect and requirements you can read details in the [Ethics Guidelines for Trustworthy AI](https://ec.europa.eu/futurium/en/ai-alliance-consultation) paper.\n\n| UE requirements | Aspect | `TransparentAI` implementation |\n| ----------- | ------------- | ----------- |\n| **1. Human agency and oversight** | Fundamental rights | No technical implementation. |\n|                            | Human agency | No technical implementation. |\n|                            | Human oversight | [Control AI performance over time with `monitoring.monitor_model` or `monitoring.plot_monitoring`](examples/#control-ai-performance-over-time-with-monitoringmonitor_model-or-monitoringplot_monitoring) |\n| **2. Technical robustness and safety** | Resilience to attack and security | [Try different input scenario in the model to see how it handles it with `models.explainers.ModelExplainer`](examples/#try-different-input-scenario-in-the-model-to-see-how-it-handles-it-with-modelsexplainersmodelexplainer) |\n|                            | Fallback plan and general safety | [Check if your Python's package are secure with `utils.check_packages_security`](examples/#check-if-your-pythons-package-are-secure-with-utilscheck_packages_security) |\n|                            | Accuracy | [Validate your AI performance with `models.classification.plot_performance` or `models.regression.plot_performance`](examples/#validate-your-ai-performance-with-modelsclassificationplot_performance-or-modelsregressionplot_performance) |\n|                            | Reliability and Reproducibility | No technical implementation. |\n| **3. Privacy and data governance** | Privacy and data protection | No technical implementation. |\n|                            | Quality and integrity of data | [Check if the variable is coherent in its distribution with `datasets.variable.plot_variable`](examples/#check-if-the-variable-is-coherent-in-its-distribution-with-datasetsvariableplot_variable) |\n|                            | Access to data | No technical implementation. |\n| **4. Transparency** | Traceability | [Generate a performance validation report with `utils.reports.generate_validation_report`](examples/#generate-a-performance-validation-report-with-utilsreportsgenerate_validation_report) |\n|                            | Explainability | [Explain the local or global behavior of your model with `models.explainers.ModelExplainer`](examples/#explain-the-local-or-global-behavior-of-your-model-with-modelsexplainersmodelexplainer)|\n|                            | Communication | No technical implementation. |\n| **5. Diversity, non-discrimination and fairness** | Avoidance of unfair bias |[Check if your AI is biased on protected attributes with `fairness.model_bias` or `fairness.plot_bias`](examples/#check-if-your-ai-is-biased-on-protected-attributes-with-fairnessmodel_bias-or-fairnessplot_bias) |\n|                            | Accessibility and universal design | No technical implementation. |\n|                            | Stakeholder Participation | No technical implementation. |\n| **6. Societal and environmental well-being** | Sustainable and environmentally friendly AI | [Get the kWh value of the AI training with `utils.evaluate_kWh`](examples/#get-the-kwh-value-of-the-ai-training-with-utilsevaluate_kwh) |\n|                            | Social impact | [Check if your AI is biased on protected attributes with `fairness.model_bias` or `fairness.plot_bias`](examples/#check-if-your-ai-is-biased-on-protected-attributes-with-fairnessmodel_bias-or-fairnessplot_bias) |\n| **7. Accountability** | Auditability | [Generate a performance validation report with `utils.reports.generate_validation_report`](examples/#generate-a-performance-validation-report-with-utilsreportsgenerate_validation_report) |\n|                            | Minimisation and reporting of negative impacts | No technical implementation. |\n|                            | Trade-offs | No technical implementation. |\n|                            | Redress | No technical implementation. |\n\n*****\n\n## Contributing\n\nSee the [contributing file](CONTRIBUTING.md).\n\n*PRs accepted.*\n\n*****\n\n## Credits and ressources\n\n### `fairness` submodule\n\nFor this submodule, I have to say I was mainly inspired by one tool so all the credit has to be attributed to [AIF360 by IBM](http://aif360.mybluemix.net/).\n\nI used some of the metrics proposed in the tools (`Statistical Parity Difference`, `Equal Opportunity Difference`, `Average Odds Difference`, `Disparact Impact` and `Theil Index`).\n\n### `models.evaluation` submodule\n\nI used some metrics function of the [`scikit-learn`](https://scikit-learn.org/stable/index.html) Python package.\n\n### `models.explainers` submodule\n\nI choose to used the [Shap](https://github.com/slundberg/shap) library because this tool was tested and aproved by a lot of people in the community, and even if I found some papers showing some problems (e.g. \"Fooling LIME and SHAP: Adversarial Attacks on Post hoc Explanation Methods\" [(Slack and al., November 2019)](https://arxiv.org/abs/1911.02508)), I decided to use it because if you want to biased Shap, you have to do it intentionally at the AI creation.\n\n### Plotting functions\n\nI was inspired by some graphics on [Kaggle](https://www.kaggle.com/). But mainly I use some code on [matplotlib website](https://matplotlib.org/) and the [Python graph gallery](https://python-graph-gallery.com/).\n\n### `utils.external` functions\n\nI used different packages that implement great features such as :\n\n1. [`energyusage`](https://github.com/responsibleproblemsolving/energy-usage) : A Python package that measures the environmental impact of computation.\n2. [`safety`](https://github.com/pyupio/safety) : Safety checks your installed dependencies for known security vulnerabilities.\n\nAgain thanks to researchers and developers that contributed in this really important field, without them I don't think I'll be able to create this tool.\n\n*****\n\n## Author\n\nThis work is led by [Nathan Lauga](https://github.com/nathanlauga/), french Data Scientist.\n\n*****\n\n## License\n\nThis project use a [MIT License](LICENSE).\n\n**Why ?**\n\nI believe that the code should be re-used for community projects and also inside private projects. \nAI transparency needs to be available for everyone even it's a private AI.",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/Nathanlauga/transparentai",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "transparentai",
    "package_url": "https://pypi.org/project/transparentai/",
    "platform": "",
    "project_url": "https://pypi.org/project/transparentai/",
    "project_urls": {
      "Homepage": "https://github.com/Nathanlauga/transparentai"
    },
    "release_url": "https://pypi.org/project/transparentai/0.2.2/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "Python tool to create or inspect a transparent and ethical AI.",
    "version": "0.2.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 7840887,
  "releases": {
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "863a82b9694defea3c2b1b5364b3715f343ab189fa6376c7441a19b3802f7a72",
          "md5": "08320df739c3d21ddb36d392b1d5c25f",
          "sha256": "0b69430e21906d730b6475ac3bbfa4440d8d7c8bf264459fda44726e950216c9"
        },
        "downloads": -1,
        "filename": "transparentai-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "08320df739c3d21ddb36d392b1d5c25f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 679179,
        "upload_time": "2020-03-03T17:41:33",
        "upload_time_iso_8601": "2020-03-03T17:41:33.554963Z",
        "url": "https://files.pythonhosted.org/packages/86/3a/82b9694defea3c2b1b5364b3715f343ab189fa6376c7441a19b3802f7a72/transparentai-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8a5c071578ec59fd8c89fe123590bdd8b98531664cd5668d3f364def8c74f8b8",
          "md5": "86430ee28627104aa2ff5979ae5b3406",
          "sha256": "a7e588ebd9049f2bf50d7d1a224fd2946b6dc1f71f15957c5e9f068ac86e9262"
        },
        "downloads": -1,
        "filename": "transparentai-0.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "86430ee28627104aa2ff5979ae5b3406",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 679069,
        "upload_time": "2020-03-03T17:49:09",
        "upload_time_iso_8601": "2020-03-03T17:49:09.152683Z",
        "url": "https://files.pythonhosted.org/packages/8a/5c/071578ec59fd8c89fe123590bdd8b98531664cd5668d3f364def8c74f8b8/transparentai-0.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f77a8f47519154e8acdbfc01893dcadd861b0a2d7bdf102c7ee105a6a4c9ba04",
          "md5": "c283ddd7c6f489833e32a68a41b41374",
          "sha256": "43c5b22322b693dfcfdc7af120bd53ad8fe37241da898b63248bf15b28e50d7f"
        },
        "downloads": -1,
        "filename": "transparentai-0.1.3.tar.gz",
        "has_sig": false,
        "md5_digest": "c283ddd7c6f489833e32a68a41b41374",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 679274,
        "upload_time": "2020-03-03T18:50:50",
        "upload_time_iso_8601": "2020-03-03T18:50:50.159964Z",
        "url": "https://files.pythonhosted.org/packages/f7/7a/8f47519154e8acdbfc01893dcadd861b0a2d7bdf102c7ee105a6a4c9ba04/transparentai-0.1.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2db0425139aa6f8db1bbc7e140ad5f941031f86f789a9f4cb322cf2cc4364fc9",
          "md5": "f29656503df58ec44b6d4d3540a4c4d8",
          "sha256": "02255d537bace9d3f3222d36afeffbf77822778d450116051eeab906c22ee006"
        },
        "downloads": -1,
        "filename": "transparentai-0.2.0-py3.7.egg",
        "has_sig": false,
        "md5_digest": "f29656503df58ec44b6d4d3540a4c4d8",
        "packagetype": "bdist_egg",
        "python_version": "3.7",
        "requires_python": ">=3.5",
        "size": 926228,
        "upload_time": "2020-05-17T14:34:36",
        "upload_time_iso_8601": "2020-05-17T14:34:36.994849Z",
        "url": "https://files.pythonhosted.org/packages/2d/b0/425139aa6f8db1bbc7e140ad5f941031f86f789a9f4cb322cf2cc4364fc9/transparentai-0.2.0-py3.7.egg",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "22981111320f6f8176484e95dd6cf0fcaa33d5d27f3a56efb0c5dc3538823a5c",
          "md5": "de01e552d850f40b1b645cc1d4237ac2",
          "sha256": "31b8930d9c463d613c96c620ba58bd858630f5fe11ff866dbe4c8109d3e5b47d"
        },
        "downloads": -1,
        "filename": "transparentai-0.2.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "de01e552d850f40b1b645cc1d4237ac2",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.5",
        "size": 787005,
        "upload_time": "2020-05-17T14:34:32",
        "upload_time_iso_8601": "2020-05-17T14:34:32.828076Z",
        "url": "https://files.pythonhosted.org/packages/22/98/1111320f6f8176484e95dd6cf0fcaa33d5d27f3a56efb0c5dc3538823a5c/transparentai-0.2.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cef90f093e658c02fb74c2119dc6999501277c0779f79c73338754ea9ddb7ea7",
          "md5": "411837c5ce38911ca62ddd7c360d7490",
          "sha256": "563b484df758e00e7caa067733518a17a92fcafb6fc89e56b596490392e7fbbd"
        },
        "downloads": -1,
        "filename": "transparentai-0.2.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "411837c5ce38911ca62ddd7c360d7490",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 787013,
        "upload_time": "2020-05-17T14:48:17",
        "upload_time_iso_8601": "2020-05-17T14:48:17.057709Z",
        "url": "https://files.pythonhosted.org/packages/ce/f9/0f093e658c02fb74c2119dc6999501277c0779f79c73338754ea9ddb7ea7/transparentai-0.2.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "db5ac265ea862da9d842cf946838fb826b2295a9e41b814f7b781ff81374a1e6",
          "md5": "d29e021b3ac9c29296923ae2b68c4425",
          "sha256": "ffd27106a2a1410eb6f97eb8fe08c6c0806aa73ec31e9a41abd54f37762ca3ee"
        },
        "downloads": -1,
        "filename": "transparentai-0.2.1.tar.gz",
        "has_sig": false,
        "md5_digest": "d29e021b3ac9c29296923ae2b68c4425",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 663768,
        "upload_time": "2020-06-02T13:31:14",
        "upload_time_iso_8601": "2020-06-02T13:31:14.426877Z",
        "url": "https://files.pythonhosted.org/packages/db/5a/c265ea862da9d842cf946838fb826b2295a9e41b814f7b781ff81374a1e6/transparentai-0.2.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0a13c87771c6b4394a042af4730a66859075cfa009440e2d6f074669f3734523",
          "md5": "e653fcc3ae8f85a85eeec377f03ef226",
          "sha256": "7cbe455b4bc55f04359f81795e77c3546624e020d895d82832cbe8435ca7939f"
        },
        "downloads": -1,
        "filename": "transparentai-0.2.2-py3.7.egg",
        "has_sig": false,
        "md5_digest": "e653fcc3ae8f85a85eeec377f03ef226",
        "packagetype": "bdist_egg",
        "python_version": "3.7",
        "requires_python": ">=3.6",
        "size": 784364,
        "upload_time": "2020-07-30T08:49:30",
        "upload_time_iso_8601": "2020-07-30T08:49:30.438690Z",
        "url": "https://files.pythonhosted.org/packages/0a/13/c87771c6b4394a042af4730a66859075cfa009440e2d6f074669f3734523/transparentai-0.2.2-py3.7.egg",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1b03855e0db88a66c3c17211be530fec41be2d1b91b4b661c8e1391047316bad",
          "md5": "9b9ed62452461de27b88d1369814a16e",
          "sha256": "92a5f3317abbf42cf0141139155712267c97846d172b7b3ea1957222a92824c0"
        },
        "downloads": -1,
        "filename": "transparentai-0.2.2.tar.gz",
        "has_sig": false,
        "md5_digest": "9b9ed62452461de27b88d1369814a16e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 677300,
        "upload_time": "2020-07-30T08:49:35",
        "upload_time_iso_8601": "2020-07-30T08:49:35.379289Z",
        "url": "https://files.pythonhosted.org/packages/1b/03/855e0db88a66c3c17211be530fec41be2d1b91b4b661c8e1391047316bad/transparentai-0.2.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "0a13c87771c6b4394a042af4730a66859075cfa009440e2d6f074669f3734523",
        "md5": "e653fcc3ae8f85a85eeec377f03ef226",
        "sha256": "7cbe455b4bc55f04359f81795e77c3546624e020d895d82832cbe8435ca7939f"
      },
      "downloads": -1,
      "filename": "transparentai-0.2.2-py3.7.egg",
      "has_sig": false,
      "md5_digest": "e653fcc3ae8f85a85eeec377f03ef226",
      "packagetype": "bdist_egg",
      "python_version": "3.7",
      "requires_python": ">=3.6",
      "size": 784364,
      "upload_time": "2020-07-30T08:49:30",
      "upload_time_iso_8601": "2020-07-30T08:49:30.438690Z",
      "url": "https://files.pythonhosted.org/packages/0a/13/c87771c6b4394a042af4730a66859075cfa009440e2d6f074669f3734523/transparentai-0.2.2-py3.7.egg",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "1b03855e0db88a66c3c17211be530fec41be2d1b91b4b661c8e1391047316bad",
        "md5": "9b9ed62452461de27b88d1369814a16e",
        "sha256": "92a5f3317abbf42cf0141139155712267c97846d172b7b3ea1957222a92824c0"
      },
      "downloads": -1,
      "filename": "transparentai-0.2.2.tar.gz",
      "has_sig": false,
      "md5_digest": "9b9ed62452461de27b88d1369814a16e",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 677300,
      "upload_time": "2020-07-30T08:49:35",
      "upload_time_iso_8601": "2020-07-30T08:49:35.379289Z",
      "url": "https://files.pythonhosted.org/packages/1b/03/855e0db88a66c3c17211be530fec41be2d1b91b4b661c8e1391047316bad/transparentai-0.2.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}