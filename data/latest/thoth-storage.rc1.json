{
  "info": {
    "author": "Fridolin Pokorny",
    "author_email": "fridolin@redhat.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "Thoth Storages\n--------------\n\nThis library provides a library called `thoth-storages\n<https://pypi.org/project/thoth-storages>`_ used in project `Thoth\n<https://thoth-station.ninja>`_.  The library exposes core queries and methods\nfor PostgreSQL database as well as adapters for manipulating with Ceph via its\nS3 compatible API.\n\nInstallation and Usage\n======================\n\nThe library can be installed via pip or Pipenv from\n`PyPI <https://pypi.org/project/thoth-storages>`_:\n\n.. code-block:: console\n\n   pipenv install thoth-storages\n\nThe library does not provide any CLI, it is rather a low level library\nsupporting other parts of Thoth.\n\nYou can run prepared testsuite via the following command:\n\n.. code-block:: console\n\n  pipenv install --dev\n  pipenv run python3 setup.py test\n\n  # To generate docs:\n  pipenv run python3 setup.py build_sphinx\n\nRunning PostgreSQL locally\n==========================\n\nYou can use `docker-compose.yaml` present in this repository to run a local PostgreSQL instance, (make sure you installed `podman-compose <https://github.com/containers/podman-compose>`_):\n\n.. code-block:: console\n\n  $ podman-compose up\n\nAfter running the command above, you should be able to access a local PostgreSQL instance at `localhost:5432`. This is also the default configuration for PostgreSQL's adapter - you don't need to provide `GRAPH_SERVICE_HOST` explicitly. The default configuration uses database named `postgres` which can be accessed using `postgres` user and `postgres` password (SSL is disabled).\n\nThe provided `docker-compose.yaml` has also PGweb enabled for to have an UI for the database content. To access it visit `http://localhost:8081/ <http://localhost:8081>`_.\n\nThe provided `docker-compose.yaml` does not use any volume. After you containers restart, the content will not be available anymore.\n\nIf you would like to experiment with PostgreSQL programatically, you can use the following code snippet as a starting point:\n\n.. code-block:: python\n\n  from thoth.storages import GraphDatabase\n\n  graph = GraphDatabase()\n  graph.connect()\n  # To clear database:\n  # graph.drop_all()\n  # To initialize schema in the graph database:\n  # graph.initialize_schema()\n\nGenerating migrations and schema adjustment in deployment\n=========================================================\n\nIf you make any changes to data model of the main PostgreSQL database, you need\nto generate migrations. These migrations state how to adjust already existing\ndatabase with data in deployments. For this purpose, `Alembic migrations\n<https://alembic.sqlalchemy.org>`_ are used. Alembic can (`partially\n<https://alembic.sqlalchemy.org/en/latest/autogenerate.html#what-does-autogenerate-detect-and-what-does-it-not-detect>`_)\nautomatically detect what has changed and how to adjust already existing\ndatabase in a deployment.\n\nAlembic uses incremental version control, where each migration is versioned and\nstates how to migrate from previous state of database to the desired next state - these\nversions are present in `alembic/versions` directory and are automatically\ngenerated with procedure described bellow.\n\nIf you make any changes, follow the following steps which will generate version\nfor you:\n\n1. make sure your local PostgreSQL instance is running (follow `Running\n   PostgreSQL locally` instructions above):\n\n  .. code-block:: console\n\n    $ podman-compose up\n\n2. Run Alembic CLI to generate versions for you:\n\n  .. code-block:: console\n\n    # Make sure you have your environment setup:\n    # pipenv install --dev\n    # Make sure you are running the most recent version of schema:\n    $ PYTHONPATH=. pipenv run alembic upgrade head\n    # Actually generate a new version:\n    $ PYTHONPATH=. pipenv run alembic revision --autogenerate -m \"Added row to calculate sum of sums which will be divided by 42\"\n\n3. Review migrations generated by Alembic. Note `NOT all changes are\n   automatically detected by Alembic\n   <https://alembic.sqlalchemy.org/en/latest/autogenerate.html#what-does-autogenerate-detect-and-what-does-it-not-detect>`_.\n\n4. Make sure generated migrations are part of your pull request so changes are\n   propagated to deployments:\n\n\n  .. code-block:: console\n\n    $ git add thoth/storages/data/alembic/versions/\n\n4. In a deployment, use Management API and its `/graph/initialize` endpoint to\n   propagate database schema changes in deployment (Management API has to have\n   recent schema changes present which are populated with new `thoth-storages`\n   releases).\n\n5. If running locally and you would like to propagate changes, run the following Alembic command to update migrations to the latest version:\n\n  .. code-block:: console\n\n    $ PYTHONPATH=. pipenv run alembic upgrade head\n\n\n  If you would like to update schema programmatically run the following Python code:\n\n  .. code-block:: python\n\n    from thoth.storages import GraphDatabase\n\n    graph = GraphDatabase()\n    graph.connect()\n    graph.initilize_schema()\n\nGenerate schema images\n======================\n\nYou can use shipped CLI ``thoth-storages`` to automatically generate schema images out of the current models:\n\n.. code-block:: console\n\n  # First, make sure you have dev packages installed:\n  pipenv install --dev\n  PYTHONPATH=. pipenv run python3 ./thoth-storages generate-schema\n\nThe command above will produce 2 images named ``schema.png`` and\n``schema_cache.png``. The first PNG file shows schema for the main PostgreSQL\ninstance and the latter one, as the name suggests, shows how cache schema looks\nlike.\n\n\nIf the command above fails with the following exception:\n\n.. code-block:: python\n\n  FileNotFoundError: [Errno 2] \"dot\" not found in path.\n\nmake sure you have `graphviz` package installed:\n\n.. code-block:: console\n\n  dnf install -y graphviz\n\nCreating own performance indicators\n===================================\n\nYou can create your own performance indicators. To create own performance\nindicator, create a script which tests desired functionality of a library. An\nexample can be matrix multiplication script present in `performance\n<https://github.com/thoth-station/performance/blob/master/tensorflow/matmul.py>`_\nrepository. This script can be supplied to Dependency Monkey to validate\ncertain combination of libraries in desired runtime and buildtime environment\nor directly on Amun API which will run the given script using desired software\nand hardware configuration. Please follow instructions on how to create a\nperformance script shown in the `README of performance repo\n<https://github.com/thoth-station/performance>`_.\n\nTo create relevant models, adjust `thoth/storages/graph/models_performance.py` file\nand add your model. Describe parameters (reported in `@parameters` section of\nperformance indicator result) and result (reported in `@result`). The name of\nclass should match `name` which is reported by performance indicator run.\n\n.. code-block:: python\n\n  class PiMatmul(Base, BaseExtension, PerformanceIndicatorBase):\n      \"\"\"A class for representing a matrix multiplication micro-performance test.\"\"\"\n\n      # Device used during performance indicator run - CPU/GPU/TPU/...\n      device = Column(String(128), nullable=False)\n      matrix_size = Column(Integer, nullable=False)\n      dtype = Column(String(128), nullable=False)\n      reps = Column(Integer, nullable=False)\n      elapsed = Column(Float, nullable=False)\n      rate = Column(Float, nullable=False)\n\nAll the models use `SQLAchemy <https://www.sqlalchemy.org/>`_.\nSee `docs <https://docs.sqlalchemy.org/>`_ for more info.\n\nOnline debugging of queries\n===========================\n\nYou can print to logger all the queries that are performed to a PostgreSQL instance. To do so, set the following environment variable:\n\n.. code-block::\n\n  export THOTH_STORAGES_DEBUG_QUERIES=1\n\nOnline debugging of queries\n===========================\n\nYou can print information about PostgreSQL adapter together with statisics on\nthe graph cache and memory cache usage to logger (it has to have at least level\n`INFO` set). To do so, set the following environment variable:\n\n.. code-block::\n\n  export THOTH_STORAGES_LOG_STATS=1\n\nThese statistics will be printed once the database adapter is destructed.\n\nCreating backups from Thoth deployment\n======================================\n\nYou can use `pg_dump` and `psql` utilities to create dumps and restore\nthe database content from dumps. This tool is pre-installed in the container image\nwhich is running PostgreSQL so the only thing you need to do is execute\n`pg_dump` in Thoth's deployment in a PostgreSQL container to create a dump, use\n`oc cp` to retrieve dump (or directly use `oc exec` and create the dump from the\ncluster) and subsequently `psql` to restore the database content. The\nprerequisite for this is to have access to the running container (edit rights).\n\n.. code-block:: console\n\n  # Execute the following commands from the root of this Git repo:\n  # List PostgreSQL pods running:\n  $ oc get pod -l name=postgresql\n  NAME                 READY     STATUS    RESTARTS   AGE\n  postgresql-1-glwnr   1/1       Running   0          3d\n  # Open remote shell to the running container in the PostgreSQL pod:\n  $ oc rsh -t postgresql-1-glwnr bash\n  # Perform dump of the database:\n  (cluster-postgres) $ pg_dump > pg_dump-$(date +\"%s\").sql\n  (cluster-postgres) $ ls pg_dump-*.sql   # Remember the current dump name\n  (cluster-postgres) pg_dump-1569491024.sql\n  (cluster-postgres) $ exit\n  # Copy the dump to the current dir:\n  $ oc cp thoth-test-core/postgresql-1-glwnr:/opt/app-root/src/pg_dump-1569491024.sql  .\n  # Start local PostgreSQL instance:\n  $ podman-compose up --detach\n  <logs will show up>\n  $ psql -h localhost -p 5432 --username=postgres < pg_dump-1569491024.sql\n  password: <type password \"postgres\" here>\n  <logs will show up>\n\nSyncing results of jobs run in the cluster\n==========================================\n\nEach job in the cluster reports a JSON which states necessary information about\nthe job run (metadata) and actual job results. These results of jobs are stored\non object storage `Ceph <https://ceph.io/>`_ via S3 compatible API and later on\nsynced via graph syncs to the knowledge graph. The component responsible for\ngraph syncs is `graph-sync-job\n<https://github.com/thoth-station/graph-sync-job>`_ which is written generic\nenough to sync any data and report metrics about synced data so you don't need\nto provide such logic on each new workload registered in the system. To sync\nyour own results of job results (workload) done in the cluster, implement\nrelated syncing logic in the `sync.py\n<https://github.com/thoth-station/storages/blob/master/thoth/storages/sync.py>`_\nand register handler in the ``_HANDLERS_MAPPING`` in the same file. The mapping\nmaps prefix of the document id to the handler (function) which is responsible\nfor syncing data into the knowledge base (please mind signatures of existing\nsyncing funcions to automatically integrate with ``sync_documents`` function\nwhich is called from ``graph-sync-job``).\n\n\n\n",
    "description_content_type": "",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/thoth-station/storages",
    "keywords": "",
    "license": "GPLv3+",
    "maintainer": "Francesco Murdaca",
    "maintainer_email": "fmurdaca@redhat.com",
    "name": "thoth-storage",
    "package_url": "https://pypi.org/project/thoth-storage/",
    "platform": "",
    "project_url": "https://pypi.org/project/thoth-storage/",
    "project_urls": {
      "Homepage": "https://github.com/thoth-station/storages"
    },
    "release_url": "https://pypi.org/project/thoth-storage/0.19.17/",
    "requires_dist": [
      "click",
      "voluptuous",
      "boto3",
      "thoth-common",
      "amun",
      "python-dateutil",
      "thoth-python",
      "pyyaml",
      "methodtools",
      "sqlalchemy",
      "psycopg2-binary",
      "sqlalchemy-utils",
      "alembic"
    ],
    "requires_python": "",
    "summary": "Storage and database adapters available in project Thoth",
    "version": "0.19.17",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 6093601,
  "releases": {
    "0.19.17": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1696990909026c43b0b1da03c6a1ed2b492970b6961c29292012ac870ca042b9",
          "md5": "1f748509600f31aa28245b3dfb7e896d",
          "sha256": "28561a7d6ae653fbd377b5c2f12a32e90bf7e12e66882873f20b407a8b0cef4d"
        },
        "downloads": -1,
        "filename": "thoth_storage-0.19.17-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "1f748509600f31aa28245b3dfb7e896d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 94546,
        "upload_time": "2019-11-07T14:20:19",
        "upload_time_iso_8601": "2019-11-07T14:20:19.791523Z",
        "url": "https://files.pythonhosted.org/packages/16/96/990909026c43b0b1da03c6a1ed2b492970b6961c29292012ac870ca042b9/thoth_storage-0.19.17-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "1696990909026c43b0b1da03c6a1ed2b492970b6961c29292012ac870ca042b9",
        "md5": "1f748509600f31aa28245b3dfb7e896d",
        "sha256": "28561a7d6ae653fbd377b5c2f12a32e90bf7e12e66882873f20b407a8b0cef4d"
      },
      "downloads": -1,
      "filename": "thoth_storage-0.19.17-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "1f748509600f31aa28245b3dfb7e896d",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 94546,
      "upload_time": "2019-11-07T14:20:19",
      "upload_time_iso_8601": "2019-11-07T14:20:19.791523Z",
      "url": "https://files.pythonhosted.org/packages/16/96/990909026c43b0b1da03c6a1ed2b492970b6961c29292012ac870ca042b9/thoth_storage-0.19.17-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}