{
  "info": {
    "author": "Jina AI",
    "author_email": "hello@jina.ai",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Environment :: Console",
      "Intended Audience :: Developers",
      "Intended Audience :: Education",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Programming Language :: Unix Shell",
      "Topic :: Database :: Database Engines/Servers",
      "Topic :: Internet :: WWW/HTTP :: Indexing/Search",
      "Topic :: Multimedia :: Video",
      "Topic :: Scientific/Engineering",
      "Topic :: Scientific/Engineering :: Artificial Intelligence",
      "Topic :: Scientific/Engineering :: Image Recognition",
      "Topic :: Scientific/Engineering :: Mathematics",
      "Topic :: Software Development",
      "Topic :: Software Development :: Libraries",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "<p align=\"center\">\n<img src=\"https://github.com/jina-ai/docarray/blob/main/docs/_static/logo-light.svg?raw=true\" alt=\"DocArray logo: The data structure for unstructured data\" width=\"150px\">\n<br>\n<b>The data structure for unstructured data</b>\n</p>\n\n<p align=center>\n<a href=\"https://pypi.org/project/docarray/\"><img src=\"https://github.com/jina-ai/jina/blob/master/.github/badges/python-badge.svg?raw=true\" alt=\"Python 3.7 3.8 3.9 3.10\" title=\"DocArray supports Python 3.7 and above\"></a>\n<a href=\"https://pypi.org/project/docarray/\"><img src=\"https://img.shields.io/pypi/v/docarray?color=%23099cec&amp;label=PyPI&amp;logo=pypi&amp;logoColor=white\" alt=\"PyPI\"></a>\n<a href=\"https://codecov.io/gh/jina-ai/docarray\"><img src=\"https://codecov.io/gh/jina-ai/docarray/branch/main/graph/badge.svg?token=9WGcGyyqtI\"/></a>\n</p>\n\n<!-- start elevator-pitch -->\n\nDocArray is a library for nested, unstructured data in transit, including text, image, audio, video, 3D mesh, etc. It allows deep-learning engineers to efficiently process, embed, search, recommend, store, and transfer the data with a Pythonic API.\n\nüåå **Rich data types**: super-expressive data structure for representing complicated/mixed/nested text, image, video, audio, 3D mesh data.\n\nüêç **Pythonic experience**: designed to be as easy as a Python list. If you know how to Python, you know how to DocArray. Intuitive idioms and type annotation simplify the code you write.\n\nüßë‚Äçüî¨ **Data science powerhouse**: greatly accelerate data scientists' work on embedding, matching, visualizing, evaluating via Torch/TensorFlow/ONNX/PaddlePaddle on CPU/GPU.\n\nüö° **Data in transit**: optimized for network communication, ready-to-wire at anytime with fast and compressed serialization in Protobuf, bytes, base64, JSON, CSV, DataFrame. Built-in data validation and JSON Schema (OpenAPI) help you build reliable webservices.\n\n<!-- end elevator-pitch -->\n\nRead more on [why should you use DocArray](https://docarray.jina.ai/get-started/what-is/) and [comparison to alternatives](https://docarray.jina.ai/get-started/what-is/#comparing-to-alternatives).\n\n## Install \n\nRequires Python 3.7+ and `numpy` only:\n```shell\npip install docarray\n```\nor via Conda:\n```shell\nconda install -c conda-forge docarray\n```\n[Additional features](https://docarray.jina.ai/#install) can be enabled by installing the full dependencies: `pip install \"docarray[full]\"`.\n\n## [Documentation](https://docarray.jina.ai)\n\n## Get Started\n\nDocArray consists of two simple concepts:\n\n- **Document**: a data structure for easily representing nested, unstructured data.\n- **DocumentArray**: a container for efficiently accessing, manipulating, and understanding multiple Documents.\n\n\n### A 10-liners text matching\n\nLet's search for top-5 similar sentences of <kbd>she smiled too much</kbd> in \"Pride and Prejudice\". \n\n```python\nfrom docarray import Document, DocumentArray\n\nd = Document(uri='https://www.gutenberg.org/files/1342/1342-0.txt').load_uri_to_text()\nda = DocumentArray(Document(text=s.strip()) for s in d.text.split('\\n') if s.strip())\nda.apply(lambda d: d.embed_feature_hashing())\n\nq = (Document(text='she smiled too much')\n     .embed_feature_hashing()\n     .match(da, metric='jaccard', use_scipy=True))\n\nprint(q.matches[:5, ('text', 'scores__jaccard__value')])\n```\n\n```text\n[['but she smiled too much.', \n  '_little_, she might have fancied too _much_.', \n  'She perfectly remembered everything that had passed in', \n  'tolerably detached tone. While she spoke, an involuntary glance', \n  'much as she chooses.‚Äù'], \n  [0.3333333333333333, 0.6666666666666666, 0.7, 0.7272727272727273, 0.75]]\n```\n\nHere the feature embedding is done by simple [feature hashing](https://en.wikipedia.org/wiki/Feature_hashing) and distance metric is [Jaccard distance](https://en.wikipedia.org/wiki/Jaccard_index). You have better embeddings? Of course you do! We look forward to seeing your results!\n\n### A complete workflow of visual search \n\nLet's use DocArray and the [Totally Looks Like](https://sites.google.com/view/totally-looks-like-dataset) dataset to build a simple meme image search. The dataset contains 6,016 image-pairs stored in `/left` and `/right`. Images that share the same filename are perceptually similar. For example:\n\n<table>\n<thead>\n  <tr>\n    <th>left/00018.jpg</th>\n    <th>right/00018.jpg</th>\n    <th>left/00131.jpg</th>\n    <th>right/00131.jpg</th>\n  </tr>\n</thead>\n<tbody>\n  <tr align=\"center\">\n    <td><img src=\"https://github.com/jina-ai/docarray/blob/main/.github/README-img/left-00018.jpg?raw=true\" alt=\"Visualizing top-9 matches using DocArray API\" width=\"50%\"></td>\n    <td><img src=\"https://github.com/jina-ai/docarray/blob/main/.github/README-img/right-00018.jpg?raw=true\" alt=\"Visualizing top-9 matches using DocArray API\" width=\"50%\"></td>\n    <td><img src=\"https://github.com/jina-ai/docarray/blob/main/.github/README-img/left-00131.jpg?raw=true\" alt=\"Visualizing top-9 matches using DocArray API\" width=\"50%\"></td>\n    <td><img src=\"https://github.com/jina-ai/docarray/blob/main/.github/README-img/right-00131.jpg?raw=true\" alt=\"Visualizing top-9 matches using DocArray API\" width=\"50%\"></td>\n  </tr>\n</tbody>\n</table>\n\nOur problem is given an image from `/left`, can we find its most-similar image in `/right`? (without looking at the filename of course).\n\n### Load images\n\nFirst load images and pre-process them with standard computer vision techniques:\n\n```python\nfrom docarray import DocumentArray\n\nleft_da = DocumentArray.from_files('left/*.jpg')\n```\n\nTo get a feeling of the data you will handle, plot them in one sprite image:\n\n```python\nleft_da.plot_image_sprites()\n```\n\n<p align=\"center\">\n<a href=\"https://docarray.jina.ai\"><img src=\"https://github.com/jina-ai/docarray/blob/main/.github/README-img/sprite.png?raw=true\" alt=\"Load totally looks like dataset with docarray API\" width=\"60%\"></a>\n</p>\n\n### Apply preprocessing\n\nLet's do some standard computer vision pre-processing:\n\n```python\nfrom docarray import Document\n\ndef preproc(d: Document):\n    return (d.load_uri_to_image_tensor()  # load\n             .set_image_tensor_shape((200, 200))  # resize all to 200x200\n             .set_image_tensor_normalization()  # normalize color \n             .set_image_tensor_channel_axis(-1, 0))  # switch color axis for the PyTorch model later\n\nleft_da.apply(preproc)\n```\n\nDid I mention `apply` works in parallel?\n\n### Embed images\n\nNow convert images into embeddings using a pretrained ResNet50:\n\n```python\nimport torchvision\nmodel = torchvision.models.resnet50(pretrained=True)  # load ResNet50\nleft_da.embed(model, device='cuda')  # embed via GPU to speed up\n```\n\nThis step takes ~30 seconds on GPU. Beside PyTorch, you can also use TensorFlow, PaddlePaddle, or ONNX models in `.embed(...)`.\n\n### Visualize embeddings\n\nYou can visualize the embeddings via tSNE in an interactive embedding projector:\n\n```python\nleft_da.plot_embeddings()\n```\n\n<p align=\"center\">\n<a href=\"https://docarray.jina.ai\"><img src=\"https://github.com/jina-ai/docarray/blob/main/.github/README-img/tsne.gif?raw=true\" alt=\"Visualizing embedding via tSNE and embedding projector\" width=\"90%\"></a>\n</p>\n\nFun is fun, but recall our goal is to match left images against right images and so far we have only handled the left. Let's repeat the same procedure for the right:\n\n```python\nright_da = (DocumentArray.from_files('right/*.jpg')\n                         .apply(preproc)\n                         .embed(model, device='cuda'))\n```\n\n### Match nearest neighbours\n\nWe can now match the left to the right and take the top-9 results.\n\n```python\nleft_da.match(right_da, limit=9)\n```\n\nLet's inspect what's inside `left_da` matches now:\n\n```python\nfor d in left_da:\n    for m in d.matches:\n        print(d.uri, m.uri, m.scores['cosine'].value)\n```\n\n```text\nleft/02262.jpg right/03459.jpg 0.21102\nleft/02262.jpg right/02964.jpg 0.13871843\nleft/02262.jpg right/02103.jpg 0.18265384\nleft/02262.jpg right/04520.jpg 0.16477376\n...\n```\n\nOr shorten the loop as one-liner using the element & attribute selector:\n\n```python\nprint(left_da['@m', ('uri', 'scores__cosine__value')])\n```\n\nBetter see it.\n\n```python\n(DocumentArray(left_da[8].matches, copy=True)\n    .apply(lambda d: d.set_image_tensor_channel_axis(0, -1)\n                      .set_image_tensor_inv_normalization())\n    .plot_image_sprites())\n```\n\n<p align=\"center\">\n<a href=\"https://docarray.jina.ai\"><img src=\"https://github.com/jina-ai/docarray/blob/main/.github/README-img/9nn-left.jpeg?raw=true\" alt=\"Visualizing top-9 matches using DocArray API\" height=\"250px\"></a>\n<a href=\"https://docarray.jina.ai\"><img src=\"https://github.com/jina-ai/docarray/blob/main/.github/README-img/9nn.png?raw=true\" alt=\"Visualizing top-9 matches using DocArray API\" height=\"250px\"></a>\n</p>\n\nWhat we did here is revert the preprocessing steps (i.e. switching axis and normalizing) on the copied matches, so that you can visualize them using image sprites.  \n\n### Quantitative evaluation\n\nSerious as you are, visual inspection is surely not enough. Let's calculate the recall@K. First we construct the groundtruth matches:\n\n```python\ngroundtruth = DocumentArray(\n    Document(uri=d.uri, matches=[Document(uri=d.uri.replace('left', 'right'))]) for d in left_da)\n```\n\nHere we create a new DocumentArray with real matches by simply replacing the filename, e.g. `left/00001.jpg` to `right/00001.jpg`. That's all we need: if the predicted match has the identical `uri` as the groundtruth match, then it is correct.\n\nNow let's check recall rate from 1 to 5 over the full dataset:\n\n```python\nfor k in range(1, 6):\n    print(f'recall@{k}',\n          left_da.evaluate(\n            groundtruth,\n            hash_fn=lambda d: d.uri,\n            metric='recall_at_k',\n            k=k,\n            max_rel=1))\n```\n\n```text\nrecall@1 0.02726063829787234\nrecall@2 0.03873005319148936\nrecall@3 0.04670877659574468\nrecall@4 0.052194148936170214\nrecall@5 0.0573470744680851\n```\n\nMore metrics can be used such as `precision_at_k`, `ndcg_at_k`, `hit_at_k`.\n\nIf you think a pretrained ResNet50 is good enough, let me tell you with [Finetuner](https://github.com/jina-ai/finetuner) you could do much better in just 10 extra lines of code. [Here is how](https://finetuner.jina.ai/get-started/totally-looks-like/).\n\n\n### Save results\n\nYou can save a DocumentArray to binary, JSON, dict, DataFrame, CSV or Protobuf message with/without compression. In its simplest form,\n\n```python\nleft_da.save('left_da.bin')\n```\n\nTo reuse it, do `left_da = DocumentArray.load('left_da.bin')`.\n\n\nIf you want to transfer a DocumentArray from one machine to another or share it with your colleagues, you can do:\n\n\n```python\nleft_da.push(token='my_shared_da')\n```\n\nNow anyone who knows the token `my_shared_da` can pull and work on it.\n\n```python\nleft_da = DocumentArray.pull(token='my_shared_da')\n```\n\nIntrigued? That's only scratching the surface of what DocArray is capable of. [Read our docs to learn more](https://docarray.jina.ai).\n\n\n<!-- start support-pitch -->\n## Support\n\n- Use [Discussions](https://github.com/jina-ai/docarray/discussions) to talk about your use cases, questions, and\n  support queries.\n- Join our [Slack community](https://slack.jina.ai) and chat with other community members about ideas.\n- Join our [Engineering All Hands](https://youtube.com/playlist?list=PL3UBBWOUVhFYRUa_gpYYKBqEAkO4sxmne) meet-up to discuss your use case and learn Jina's new features.\n    - **When?** The second Tuesday of every month\n    - **Where?**\n      Zoom ([see our public events calendar](https://calendar.google.com/calendar/embed?src=c_1t5ogfp2d45v8fit981j08mcm4%40group.calendar.google.com&ctz=Europe%2FBerlin)/[.ical](https://calendar.google.com/calendar/ical/c_1t5ogfp2d45v8fit981j08mcm4%40group.calendar.google.com/public/basic.ics))\n      and [live stream on YouTube](https://youtube.com/c/jina-ai)\n- Subscribe to the latest video tutorials on our [YouTube channel](https://youtube.com/c/jina-ai)\n\n## Join Us\n\nDocArray is backed by [Jina AI](https://jina.ai) and licensed under [Apache-2.0](./LICENSE). [We are actively hiring](https://jobs.jina.ai) AI engineers, solution engineers to build the next neural search ecosystem in open-source.\n\n<!-- end support-pitch -->",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "https://github.com/jina-ai/docarray/tags",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/jina-ai/docarray",
    "keywords": "docarray deep-learning data-structures cross-modal multi-modal unstructured-data nested-data neural-search",
    "license": "Apache 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "vectordb",
    "package_url": "https://pypi.org/project/vectordb/",
    "platform": "",
    "project_url": "https://pypi.org/project/vectordb/",
    "project_urls": {
      "Documentation": "https://docarray.jina.ai",
      "Download": "https://github.com/jina-ai/docarray/tags",
      "Homepage": "https://github.com/jina-ai/docarray",
      "Source": "https://github.com/jina-ai/docarray/",
      "Tracker": "https://github.com/jina-ai/docarray/issues"
    },
    "release_url": "https://pypi.org/project/vectordb/0.0.0/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "The data structure for unstructured data",
    "version": "0.0.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12722371,
  "releases": {
    "0.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1d4c2b7777eac191aaa22d0a09ecd07d35b4a9ca999b297cc86198c930c676d9",
          "md5": "c2a3cb21feaf2cbdfb8d583cb986cc0e",
          "sha256": "31669afa3a7cdcd65b153544792c17e69cdfafbf9b9eaea3b32e9494697aa0bf"
        },
        "downloads": -1,
        "filename": "vectordb-0.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "c2a3cb21feaf2cbdfb8d583cb986cc0e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 582700,
        "upload_time": "2022-01-28T16:16:25",
        "upload_time_iso_8601": "2022-01-28T16:16:25.528277Z",
        "url": "https://files.pythonhosted.org/packages/1d/4c/2b7777eac191aaa22d0a09ecd07d35b4a9ca999b297cc86198c930c676d9/vectordb-0.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "1d4c2b7777eac191aaa22d0a09ecd07d35b4a9ca999b297cc86198c930c676d9",
        "md5": "c2a3cb21feaf2cbdfb8d583cb986cc0e",
        "sha256": "31669afa3a7cdcd65b153544792c17e69cdfafbf9b9eaea3b32e9494697aa0bf"
      },
      "downloads": -1,
      "filename": "vectordb-0.0.0.tar.gz",
      "has_sig": false,
      "md5_digest": "c2a3cb21feaf2cbdfb8d583cb986cc0e",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 582700,
      "upload_time": "2022-01-28T16:16:25",
      "upload_time_iso_8601": "2022-01-28T16:16:25.528277Z",
      "url": "https://files.pythonhosted.org/packages/1d/4c/2b7777eac191aaa22d0a09ecd07d35b4a9ca999b297cc86198c930c676d9/vectordb-0.0.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}