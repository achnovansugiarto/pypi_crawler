{
  "info": {
    "author": "Habana Labs Ltd., an Intel Company",
    "author_email": "support@habana.ai",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# Habana Media Python package\n\n`hpu_media_loader` is a package designed for easy integration of media processing on Gaudi2.\nMain entry point (Python import) is `habana_frameworks.mediapipe` module that contains all the necessary functions to work with Gaudi2.\n\n## Structure\n\nProperly built wheel contains:\n- `habana_frameworks` python namespace (with all the folder structure inside).\n- ``mediapipe`` folder catering media execution on device and ``medialoader`` folder catering pre-built mediapipe for tensorflow & pytorch frameworks.\n- proper licensing.\n\n## Media package (habana_frameworks.mediapipe and habana_frameworks.medialoaders)\n\n#### First part of media package contains media pipe which is responsible for media processing on device.\nFollowing are the steps to create mediapipe\n- Create a class derived from ``habana_frameworks.mediapipe`` super class.\n- In the class constructor initialize super class.\n- Create nodes required for execution along with it's parameters.\n- Define a method ``definegraph()`` which defines the data flow between nodes created in constructor.\n\nFollowing are the steps to execute a standalone mediapipe\n- Instantiate an object of defined mediapipe class.\n- Build the mediapipe by executing ``build()`` method of mediapipe object.\n- Initialize the iterator by calling ``iter_init()`` method of mediapipe object.\n- To produce one batch of dataset, execute ``run()`` method of mediapipe object. Each ``run()`` method call executes and produces one batch of device tensors.\n- To view or manipulate tensors on host ``as_cpu()`` method of device tensor object can be called, which yields host tensor object.\n- For numpy manipulation ``as_nparray()`` method of host tensor object can be called to get a numpy host array.\n\nExample:\n\n```python\n\nfrom habana_frameworks.mediapipe import fn\nfrom habana_frameworks.mediapipe.mediapipe import MediaPipe\nfrom habana_frameworks.mediapipe.media_types import imgtype as it\nfrom habana_frameworks.mediapipe.media_types import dtype as dt\nfrom habana_frameworks.mediapipe.media_types import layout as lt\nimport time\n\nclass myMediaPipe(MediaPipe):\n    def __init__(self, device, queue_depth, batch_size, channel, height, width):\n        super(\n            myMediaPipe,\n            self).__init__(\n            device,\n            queue_depth,\n            batch_size,\n            channel,\n            height,\n            width,\n            self.__class__.__name__,\n            layout=lt.NHWC)\n        mediapipe_seed = int(time.time_ns() % (2**31 - 1))\n        # create reader node and setting it's params\n        self.input = fn.ReadImageDatasetFromDir(dir=\"/path/to/jpeg/dir/\",\n                                                format=\"JPEG\",\n                                                shuffle=True,\n                                                seed=mediapipe_seed)\n        # create decoder node and set it's params\n        self.decode = fn.ImageDecoder(output_format=it.RGB_P,\n                                      resize=[224, 224])\n\n        # create transpose node and set it's params\n        self.transpose = fn.Transpose(permutation=[2, 0, 1, 3], tensorDim=4)\n\n    def definegraph(self):\n        # define actual data flow of nodes\n        jpegs, data = self.input()\n        images = self.decode(jpegs)\n        images = self.transpose(images)\n        # return output nodes of the graph\n        return images, data\n\n\n# test specific params\nbatch_size = 4\nimg_width = 224\nimg_height = 224\nchannels = 3\nqueue_depth = 3\niterations = 5\n\n# instantiating defined class\npipe = myMediaPipe(\"hpu\", queue_depth, batch_size,\n                   channels, img_height, img_width)\n# build the pipe\npipe.build()\n# initialize iterator\npipe.iter_init()\n\nbatch_count = 0\nwhile(batch_count < iterations):\n    try:\n        # exectute and produce one batch of dataset.\n        images, labels = pipe.run()\n        # images and labels are device tensors.\n    except StopIteration:\n        print(\"stop iteration\")\n        break\n    # as cpu will bring the device data to host and produce host tensors\n    # as_nparray will convert host tensors to numpy array.\n    images = images.as_cpu().as_nparray()\n    labels = labels.as_cpu().as_nparray()\n    batch_count = batch_count + 1\n\n\n```\n\n#### Second part of media package contains pre built media pipe for tensorflow and pytorch.\n\n###### tensorflow folder contains media_resnet_pipe containing resnet pipe for tensflow graph\nFollowing are the steps to use pre built mediapipe for tensorflow\n- Import ``ResnetPipe`` from ``habana_frameworks.medialoaders.tensorflow.media_resnet_pipe``\n- Instantiate an object of ``ResnetPipe`` with following parameters\n    - device name: hpu\n    - queue_depth: queue depth for media processing.\n    - batch_size: mediapipe output batch size.\n    - height: mediapipe output image height.\n    - width: mediapipe output image width.\n    - is_training: if is training pipe or validation pipe\n    - data_dir: jpeg data directory.\n    - out_dtype: output datatype of image.\n    - num_slices: number of slices to be done of dataset.\n    - slice_index: slice index to be used for this instance of execution.\n- Instantiate an object of  ``HabanaDataset`` which is derived from tensorflow dataset with following parameters\n    - output_shapes: list of output shapes of the  dataset.\n    - output_types: list of output datatype of the dataset.\n    - pipeline: media pipeline object.\n- Above dataset can be used for dataset iterations.\n\nExample:\n\n```python\nfrom habana_frameworks.medialoaders.tensorflow.media_resnet_pipe import ResnetPipe\nfrom habana_frameworks.tensorflow.media.habana_dataset import HabanaDataset\n\n# network specific parameters\nbatch_size = 256\nnum_channels= 3\nimg_size = 224\nis_training = True\ndir_path = '/jpeg/path/'\nmedia_dtype = 'bfloat16'\nnum_slices = 1\nslice_index = 0\nqueue_depth = 3\ntf_media_dtype = tf.bfloat16\ntf_meta_dtype = tf.float32\n\n#pre defined mediapipe from medialoaders\npipe = ResnetPipe(\"hpu\", queue_depth, batch_size, num_channels,\n                  img_size, img_size, is_training,\n                  dir_path, media_dtype, num_slices, slice_index)\n\n# tensorflow predefine habanadataset class\ndataset = HabanaDataset(output_shapes=[(batch_size,\n                                        img_size,\n                                        img_size,\n                                        num_channels),\n                                       (batch_size,)],\n                        output_types=[tf_media_dtype, tf_meta_dtype], pipeline=pipe)\n# above dataset object is tf dataset object which is iteratable and can be fed to training node.\n\n\n```\n\n\n###### torch folder contains media_dataloader_mediapipe containing ``HPUMediaPipe`` which can be used to create resnet and SSD media pipe for pytorch\nFollowing are the steps to use ``HPUMediaPipe`` for pytorch\n- Import ``HPUMediaPipe`` from ``habana_frameworks.medialoaders.torch.media_dataloader_mediapipe``\n- Instantiate an object of ``HPUMediaPipe`` with following parameters:\n    - a_torch_transforms: transforms to be applied on mediapipe.\n    - a_root: directory path from which to load the images.\n    - a_annotation_file: path from which to load annotation file for SSD.\n    - a_batch_size: mediapipe output batch size.\n    - a_shuffle: whether images have to be shuffled. <True/False>\n    - a_drop_last: whether to drop the last incomplete batch or round up.<True/False>\n    - a_prefetch_count: queue depth for media processing.\n    - a_num_instances:  number of devices.\n    - a_instance_id: instance id of current device.\n    - a_model_ssd: whether mediapipe is to be created for SSD. <True/False>\n    - a_device: media device to run mediapipe on. <hpu>\n- Separate ``HPUMediaPipe`` objects can be created for training and validation.\n- Instantiate an object of ``HPUResnetPytorchIterator`` (for resnet) or ``HPUSsdPytorchIterator`` (for SSD) with following parameters\n    - mediapipe: media pipe object.\n\nExample for resnet media pipe:\n\n```python\nfrom habana_frameworks.medialoaders.torch.media_dataloader_mediapipe import HPUMediaPipe\nfrom habana_frameworks.mediapipe.plugins.iterator_pytorch import HPUResnetPytorchIterator\n\nnormalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225])\ntorch_transforms = transforms.Compose([\n            transforms.RandomResizedCrop(224),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            normalize,\n        ])\n\nroot = \"/JPEG/path\"\nbatch_size = 256\nshuffle = True\ndrop_last = False\nprefetch_factor = 3\nnum_instances = 1\ninstance_id = 0\n\npipeline = HPUMediaPipe(a_torch_transforms=torch_transforms, a_root=root, a_batch_size=batch_size,\n                        a_shuffle=shuffle, a_drop_last=drop_last, a_prefetch_count=prefetch_factor,\n                        a_num_instances=num_instances, a_instance_id=instance_id, a_device=\"hpu\")\n\niterator = HPUResnetPytorchIterator(mediapipe=pipeline)\n\n\n```\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://habana.ai/",
    "keywords": "",
    "license": "See LICENSE.txt",
    "maintainer": "",
    "maintainer_email": "",
    "name": "hpu-media-loader",
    "package_url": "https://pypi.org/project/hpu-media-loader/",
    "platform": null,
    "project_url": "https://pypi.org/project/hpu-media-loader/",
    "project_urls": {
      "Homepage": "https://habana.ai/"
    },
    "release_url": "https://pypi.org/project/hpu-media-loader/1.9.0.580.1/",
    "requires_dist": [
      "pillow"
    ],
    "requires_python": "",
    "summary": "Dataloader using Habana hardware media pipeline",
    "version": "1.9.0.580.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17474018,
  "releases": {
    "1.5.0.610": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "25176335e8c434c6118c36f631106e674e11f46cec6a0bbe78b47fb71b3eecff",
          "md5": "e116cd5a188c63ffa5c19d79f040f5da",
          "sha256": "32185198dcfae908d6ad8d4814ef188800bd637df8bc75b781ae66a4e5967652"
        },
        "downloads": -1,
        "filename": "hpu_media_loader-1.5.0.610-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "e116cd5a188c63ffa5c19d79f040f5da",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 87468,
        "upload_time": "2022-06-16T04:21:39",
        "upload_time_iso_8601": "2022-06-16T04:21:39.648731Z",
        "url": "https://files.pythonhosted.org/packages/25/17/6335e8c434c6118c36f631106e674e11f46cec6a0bbe78b47fb71b3eecff/hpu_media_loader-1.5.0.610-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.6.0.439": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d9f090bec7ee3ed40806b2cea7acf5880f2fa6be0accfa7064b057ec90a4d399",
          "md5": "189e2502b6d7ed5e4660cc23b084e888",
          "sha256": "916d845cf3f4041fccb947a8664995a61214380eefc308656052fb98483bc85f"
        },
        "downloads": -1,
        "filename": "hpu_media_loader-1.6.0.439-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "189e2502b6d7ed5e4660cc23b084e888",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 97539,
        "upload_time": "2022-08-10T19:33:00",
        "upload_time_iso_8601": "2022-08-10T19:33:00.087701Z",
        "url": "https://files.pythonhosted.org/packages/d9/f0/90bec7ee3ed40806b2cea7acf5880f2fa6be0accfa7064b057ec90a4d399/hpu_media_loader-1.6.0.439-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.6.1.92": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "19321fcf91c10dd8be34e7652d4e7762a9d110997bbe061526f0257acae724bb",
          "md5": "b7c0a903baa2948f7898bd2c7138f4b9",
          "sha256": "8ed97aa08002ba79c3ad91a6df1b8e20892d37cef41df7d35ca371a01c465156"
        },
        "downloads": -1,
        "filename": "hpu_media_loader-1.6.1.92-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "b7c0a903baa2948f7898bd2c7138f4b9",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 97526,
        "upload_time": "2022-09-14T08:24:25",
        "upload_time_iso_8601": "2022-09-14T08:24:25.496891Z",
        "url": "https://files.pythonhosted.org/packages/19/32/1fcf91c10dd8be34e7652d4e7762a9d110997bbe061526f0257acae724bb/hpu_media_loader-1.6.1.92-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.7.0.665": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4850f757cace987edac2f9c3d0510a08910cbf66cbda5356788db24a85647a27",
          "md5": "10839c66e9e5d391796e3821922ba744",
          "sha256": "abcc4826790e63ecb6dce6c86e6c787b59ff8b487d8bbe7a95d89160f0168075"
        },
        "downloads": -1,
        "filename": "hpu_media_loader-1.7.0.665-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "10839c66e9e5d391796e3821922ba744",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 118347,
        "upload_time": "2022-11-08T13:27:51",
        "upload_time_iso_8601": "2022-11-08T13:27:51.008602Z",
        "url": "https://files.pythonhosted.org/packages/48/50/f757cace987edac2f9c3d0510a08910cbf66cbda5356788db24a85647a27/hpu_media_loader-1.7.0.665-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.7.1.85": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1d5d2e9537f9eee2f442bb6e20a6e6fa54ec55ddb34601a9133243b0d6434652",
          "md5": "d18bac1d3ef723e932e8ebc75550919a",
          "sha256": "4144d2ec929532ce4b09cf0d6acecc187333fd4f89cf7de11eb8aabcb0e8ad3b"
        },
        "downloads": -1,
        "filename": "hpu_media_loader-1.7.1.85-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d18bac1d3ef723e932e8ebc75550919a",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 118738,
        "upload_time": "2022-12-05T07:34:44",
        "upload_time_iso_8601": "2022-12-05T07:34:44.990207Z",
        "url": "https://files.pythonhosted.org/packages/1d/5d/2e9537f9eee2f442bb6e20a6e6fa54ec55ddb34601a9133243b0d6434652/hpu_media_loader-1.7.1.85-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.8.0.690": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "567545817ae5fb5ed01745caac7366ad864d0b5de99f9e8d9ae3d19848ebf037",
          "md5": "299cb107bb2c364ac863df846ba2cfa4",
          "sha256": "d92e4a830a38a165c4a93ce313e01d151e78cd58c8b0948b9793702ff7fe12cc"
        },
        "downloads": -1,
        "filename": "hpu_media_loader-1.8.0.690-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "299cb107bb2c364ac863df846ba2cfa4",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 123114,
        "upload_time": "2023-02-01T18:21:01",
        "upload_time_iso_8601": "2023-02-01T18:21:01.098492Z",
        "url": "https://files.pythonhosted.org/packages/56/75/45817ae5fb5ed01745caac7366ad864d0b5de99f9e8d9ae3d19848ebf037/hpu_media_loader-1.8.0.690-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.9.0.580.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fbeba750d278f2e865ce38659a16b6f2c0ef3d4c63c849bcf12dc3a063473e79",
          "md5": "832fca8a04ab047f083c86e4f153e9ae",
          "sha256": "91993a1086d02ce57696cf0bcc7abbe1ac1e91b4103024f9e616859c50ce226f"
        },
        "downloads": -1,
        "filename": "hpu_media_loader-1.9.0.580.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "832fca8a04ab047f083c86e4f153e9ae",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 136778,
        "upload_time": "2023-03-28T06:53:07",
        "upload_time_iso_8601": "2023-03-28T06:53:07.919599Z",
        "url": "https://files.pythonhosted.org/packages/fb/eb/a750d278f2e865ce38659a16b6f2c0ef3d4c63c849bcf12dc3a063473e79/hpu_media_loader-1.9.0.580.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "fbeba750d278f2e865ce38659a16b6f2c0ef3d4c63c849bcf12dc3a063473e79",
        "md5": "832fca8a04ab047f083c86e4f153e9ae",
        "sha256": "91993a1086d02ce57696cf0bcc7abbe1ac1e91b4103024f9e616859c50ce226f"
      },
      "downloads": -1,
      "filename": "hpu_media_loader-1.9.0.580.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "832fca8a04ab047f083c86e4f153e9ae",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 136778,
      "upload_time": "2023-03-28T06:53:07",
      "upload_time_iso_8601": "2023-03-28T06:53:07.919599Z",
      "url": "https://files.pythonhosted.org/packages/fb/eb/a750d278f2e865ce38659a16b6f2c0ef3d4c63c849bcf12dc3a063473e79/hpu_media_loader-1.9.0.580.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}