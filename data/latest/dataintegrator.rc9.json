{
  "info": {
    "author": "Yuxiang Chen",
    "author_email": "ychen1@hsph.harvard.edu",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: MIT License",
      "Operating System :: MacOS",
      "Programming Language :: Python :: 3"
    ],
    "description": "# DataIntegrator\nData Integration tools for genetic data in Python\n\n\n\n\n\n# Primary Functions\n1. Liftover Genome Build\n   \n    Given a input genome build version and a output genome build version, liftover the genome build of the input chr:pos pair to the desired version.\n\n2. Add RsID\n   \n    Add rsID according to chr and pos position in the data file.\n\n3. Flip Strand to Forward\n   \n    Step 1: Query dbSnp153 databse to get the two alleles of the forward strand according to chr and pos.\n\n    Step 2: Compare the two alleles with the input GWAS summary file, if all ATCG appears, flip the GWAS summary file using the A-T and C-G rule.\n\n4. Align Effect allele \n   \n    Input two gwas summary files, then use the first one as reference and make sure the second file has the same effect allele. If the effect allele is changed, the effect size will also be changed accordingly.\n\n\n\n\n\n\n# Dependencies\nBefore installing the `DataIntegrator` package, the following packages are required to be installed in advance:\n1. pyliftover\n    * `pip install pyliftover`\n2. numpy\n    * `pip install numpy`\n3. pandas\n    * `pip install pandas`\n4. pyBigWig\n    * `pip install pyBigWig`\n\n\n\n\n\n# Usage\nTo use the pacakge, please follow the steps below:\n1. Install dependencies mentioned above\n2. Install the package\n    * `pip install dataintegrator`\n3. To use the `query_data()` function, you have to provide the local path to the `dbSnp153.bb` file downloaded from the UCSC website [(download here)](http://hgdownload.soe.ucsc.edu/gbdb/hg38/snp/dbSnp153.bb); otherwise, the function will query the data online instead of querying data from local file (which will significantly reduce the run time).\n4. In python, get started with the following steps\n    -   ```python \n        from dataintegrator import DataIntegrator as di\n        ```\n    - Setting inital parameters: \n        * input_path (the path of the data to be processed)\n        * output_path (the path you want the processed result to be saved to)\n        * input_format (e.g. \"hg19\")\n        * output_format (e.g. \"hg38\")\n\n    - Start using the provided functions, e.g.: \n        ```python \n        input_path = \"<path_to_your_data_file>.gz\"\n        df = di.read_data(input_path, '\\t', \"#chrom\",\"pos\", \"rsids\" ,\"alt\", \"ref\", \"maf\",    \"beta\", \"sebeta\", \"pval\")\n        #print(df)\n        ```\n5. To view example calls of the main functions, clone this repository and see the `.py` files under the `/examples` directory.\n\n6. Data Integrating work flow:\n    ![Alt text](./mermaid-diagram-20210728025927.png)\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Functions Provided\n\n\n\n## 1. Function to read data in formatted ways\n\n### Read Data\n```python\nread_data( input_path, Chr_col_name, BP_col_name, SNP_col_name, A1_col_name, A2_col_name, EAF_col_name, Beta_col_name, Se_col_name, P_col_name, separate_by=\"\\t\")\n```\nDescription: This function reads the data to be processed and output it in a formatted way\n    \nParameters\n- input_path (str): the complete or relative path of the input data\n- Chr_col_name (str): the column name in the original data representing chromosome\n- BP_col_name (str): the column name in the original data representing base pair position\n- SNP_col_name (str): the column name in the original data representing rsID\n- A1_col_name (str): the column name in the original data representing effect allele\n- A2_col_name (str): the column name in the original data representing non-effect allele\n- EAF_col_name (str): the column name in the original data represneting allele frequency for effect allele\n- Beta_col_name (str): the column name in the original data represneting effect size for effect allele\n- Se_col_name (str): the column name in the original data represneting standard error for effect size\n- P_col_name (str): the column name in the original data represneting p-value\n- separate_by (str): the delimiter of the original data, '\\t' by default (tab separated)\n\nReturns:\n- pandas.DataFrame: return formatted data in the form of pandas DataFrame in the following ways:\n\n| Chr    | BP     | SNP    | A1     | A2     | EAF    | Beta   | Se     | P      |\n| ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ |\n| 1      | 438956 | rs4596 | G      | A      | 0.0021 | -0.538 | 0.5802 | 0.3533 |\n| X      | 704956 | rs1234 | T      | C      | 0.0242 | 0.1685 | 0.2469 | 0.0843 |\n\nExample Usage:\n```python\ninput_path = \"<path_to_your_data_file>.gz\"\ndf = di.read_data(input_path, '\\t', \"#chrom\",\"pos\", \"rsids\" ,\"alt\", \"ref\", \"maf\",    \"beta\", \"sebeta\", \"pval\")\n#print(df)\n```\n\n\n\n\n\n\n\n## 2. Functions to clean data for further processing\n\n### Filter bi-allelic\n```python\nfilter_bi_allelic(df, rest=False)\n```\nFunction to filter only bi-allelic cases in the data\n\nParameters:\n- df (pandas.DataFrame): The data frame to be filtered.\n- rest (boolean): value indicating wether or not to keep (mark only) the non-bi-allelic cases. Default to False.\n\nReturns:\n- pandas.DataFrame: return filtered data in the form of pandas DataFrame.\n\nExample:\n```python \nbi_allelic = di.filter_bi_allelic(df)\n\n# if you want to check the non-bi-allelic cases, use the following command\nbi_allelic = di.filter_bi_allelic(df, rest=True)\n```\n\n### Deduplicate\n```python\ndeduplicate(df)\n```\nFunction to drop rows in data containing dduplicate keys (Chr + BP)\n\nParameters:\n- df (pandas.DataFrame): The data frame to be deduplicated.\n\nReturns:\n- pandas.DataFrame: return filtered data in the form of pandas DataFrame.\n\nExample:\n```python\ndeduplicated = di.deduplicate(df)\n```\n\n### Sort by Chr and BP\n```python\nsort_by_chr_bp(df)\n```\nFunction to sort the data based on Chr and BP\n\nParameters:\n- df (pandas.DataFrame): the data to be sorted\n\nReturns:\n- pandas.DataFrame: return the sorted data\n\nExample:\n```python\nsorted_data = di.sort_by_chr_bp(df)\n```\n\n\n\n\n\n\n## 3. Functions to query data from dbSnp153 for further processing\n\n### Query UCSC Database for dbSNP153 info\n```python\nquery_data(df, link=\"http://hgdownload.soe.ucsc.edu/gbdb/hg38/snp/dbSnp153.bb\")\n```\nFunction to query required data from dbSnp153\n\nParameters:\n- df (pandas.DataFrame): the data we want more info\n- link (str): path or link of the '.bb' file of dbSnp153 \n\nReturns:\n- pandas.DataFrame: return complete information from dbSnp153 as a python dictionary\n\nExample:\n```python\nlink = \"<path_to_your_dbSnp153_path>.bb\"\ndbSnp153 = di.query_data(df, link) # This will usually take longer time\n```\n\n### Save Object\n```python\nsave_obj(obj, name )\n```\n\nFunction to save python data structure on disk\n\nParameters:\n- obj (obj): the data structure/object to be saved on disk.\n- name (str): the name for the obj to be saved as.\n\nReturns:\n- return nothing\n\nExample:\n```python\ndi.save_obj(dbSnp153, \"obj/dbSnp153\")\n```\n\n### Load Object\n```python\nload_obj(obj_path )\n```\nFunction to load saved python data structure from disk\n\nParameters:\n- name (str): the name of the saved obj on disk to be loaded\n\nReturns:\n- pandas.DataFrame: return complete information from dbSnp153 as a python dictionary\n\nExample:\n```python\ndbSnp153 = di.load_obj(\"obj/dbSnp153.pkl\")\n```\n\n\n\n\n\n\n\n\n## 4. Functions to process data\n\n### Lift Over\n```python\nlift_over(df, lo_dict, keep_all=False, inplace= False, comment=False)\n```\nFunction to lift over genome build\n\nParameters:\n- df (pandas.DataFrame): the data to be lifted over\n- lo_dict (python dictionary): the lift over dictionary return from the create_lo function\n- keep_unconvertible (boolean): if true, the function will keep and mark the rows that are not convertible. Default to False.\n- keep_original_version (boolean): if true, the function will keep the Chr + BP of original genome build. Default to False.\n\nReturns:\n- pandas.DataFrame: return the data being lifted over to the desired genome build\n\nUse two tables to illustrate output\n\nExample:\n```python\ninput_format = \"hg<**>\"\noutput_format = \"hg<**>\"\nlo = create_lo(input_format, output_format) # create chain file as reference for genome-build-lift-over.\n\n# drop unconvertible rows and keep only the result after lift over.\nlift_over = di.lift_over(df, lo)\nprint(lift_over)\n\n# keep and mark rows that are not convertible\nlift_over = di.lift_over(df, lo, keep_unconvertible=True)\n\n# keep the original genome build version as separate columns in the data set\nlift_over = di.lift_over(df, lo, keep_orginal_version=True)\n```\n\n### Add Rsid's\nadd_rsid(df, data, keep_all=False, inplace=False, show_comment=False, show_errors=False)\n\nFunction to query and add rs ID for rows missing rsIDs.\n\nParameters:\n- df (pandas.DataFrame): the data to be added rs_ids\n- data (python dictionary): the dictionary containing required info from dbSnp153\n- keep_all (boolean): value indicating whether the function should keep all rows in the original dataset. Default to False.\n- inplace (boolean): value indicating whether the function should replace the original rsID column with the new added_rsid column. Default to True.\n- show_comment (boolean): value indicating whether the function should add a column indicating the status of adding rsID. Default to False.\n- show_errors (boolean): value indicating whether the function will output a table containing rows that cannot be properly added rsIDs. Default to False.\n\n    1. \"added\" : missing rsID in orginal dataset. The Chr+BP key can be found in dbSNP153 and the rsID is successfully added\n    2. \"same\": the original dataset have the same rsID as dbSnp153. No need to modify or add.\n    3. \"different\": the original dataset have different rsID as compared to dbSnp153. Use dbSnp153 153 as reference to repalce the original.\n    4. \"key not found\" : The Chr+BP key in original dataset cannot be found in dbSnp153. Fill in NA value. Mark in the comment column.\n\nReturns:\n- pandas.DataFrame: return the data being added rs_ids.\n\n\nExample Call:\n```python\nadded_rsid = di.add_rsid(df, dbSnp153)\n```\n\nA few example output:\n\n`inplace = False, show_comment=False, keep_all=False`\n| Chr    | BP     | SNP    | A1     | A2     | EAF    | Beta   | Se     | P      | added_rsid|\n| ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | --------- |\n| 1      | 438956 | <NA>   | G      | A      | 0.0021 | -0.538 | 0.5802 | 0.3533 | rs12445   |\n| X      | 704956 | rs1234 | T      | C      | 0.0242 | 0.1685 | 0.2469 | 0.0843 | rs1234    |\n\n`inplace = True, show_comment=False, keep_all=False`\n| Chr    | BP     | SNP    | A1     | A2     | EAF    | Beta   | Se     | P      |\n| ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ |\n| 1      | 438956 | rs12445| G      | A      | 0.0021 | -0.538 | 0.5802 | 0.3533 |\n| X      | 704956 | rs1234 | T      | C      | 0.0242 | 0.1685 | 0.2469 | 0.0843 |\n\n\n`inplace = False, show_comment=True, keep_all=False`\n| Chr    | BP     | SNP    | A1     | A2     | EAF    | Beta   | Se     | P      | added_rsid| comment|\n| ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | --------- | ------ |\n| 1      | 438956 | <NA>   | G      | A      | 0.0021 | -0.538 | 0.5802 | 0.3533 | rs12445   | \"added\"|\n| X      | 704956 | rs1234 | T      | C      | 0.0242 | 0.1685 | 0.2469 | 0.0843 | rs1234    | \"same\" |\n\n`check_errors=True`\n| Chr    | BP     | SNP    | A1     | A2     | EAF    | Beta   | Se     | P      | added_rsid| comment|\n| ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | --------- | ------ |\n| 1      | 438956 | <NA>   | G      | A      | 0.0021 | -0.538 | 0.5802 | 0.3533 | <NA>      | \"key not found\"|\n| X      | 704956 | <NA>   | T      | C      | 0.0242 | 0.1685 | 0.2469 | 0.0843 | <NA>      | \"key not found\" |\n\n### Flip Strand\n```python\nflip_strand( df, data, keep_all=False, inplace = False, show_comment=False, show_errors=False)\n```\nFunction to flip the input data to forward strand\n\nParameters:\n- df (pandas.DataFrame): the data to be flipped to forward strand\n- data (python dictionary): the dictionary containing required info from dbSnp153\n- keep_all (boolean): value indicating whether the function should keep all rows in the original dataset. Default to False.\n- inplace (boolean): value indicating whether the function should replace the original A1 and A2 columns with the new_A1 and new_A2 columns. Default to False.\n- show_comment (boolean): value indicating whether the function should add a column indicating the status of flipping strand. Default to False.\n- show_errors (boolean): value indicating whether the function will output a table containing rows where strand cannot be properly flipped. Default to False.\n\n    1. \"flipped\" : The Chr+BP key can be found in dbSNP153 and the strand is successfully flipped.\n    2. \"same\": the original dataset uses the same strand as dbSnp153. No need to modify or add.\n    3. \"different\": the original data set and its correspondence in dbSnp153 show completely different strand patter that cannot be flipped (e.g. T/C vs. C/A)\n    4. \"dbSnp153: Indel\" : the A1 and A2 in dbSnp153 correponds to the Chr+BP in the processed data set contain Indel\n    5. \"key not found\" : The Chr+BP key in original dataset cannot be found in dbSnp153. Fill in NA value. Mark in the comment column.\n\nReturns:\n- pandas.DataFrame: return the data being flipped to forward strand\n\nExample:\n```python\nflipped = di.flip_strand(df, dbSnp153)\n```\n\nA few examples:\n\n`inplace = False, show_comment=False, keep_all=False`\n| Chr    | BP     | SNP    | A1     | A2     | EAF    | Beta   | Se     | P      | new_A1 | new_A2 |\n| ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ |\n| 1      | 438956 | <NA>   | G      | A      | 0.0021 | -0.538 | 0.5802 | 0.3533 | A      | G      |\n| X      | 704956 | rs1234 | T      | C      | 0.0242 | 0.1685 | 0.2469 | 0.0843 | C      | T      |\n\n`inplace = True, show_comment=False, keep_all=False`\n| Chr    | BP     | SNP    | A1     | A2     | EAF    | Beta   | Se     | P      |\n| ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ |\n| 1      | 438956 | <NA>   | A      | G      | 0.0021 | -0.538 | 0.5802 | 0.3533 |\n| X      | 704956 | rs1234 | C      | T      | 0.0242 | 0.1685 | 0.2469 | 0.0843 |\n\n\n`inplace = False, show_comment=True, keep_all=False`\n| Chr    | BP     | SNP    | A1     | A2     | EAF    | Beta   | Se     | P      | new_A1 | new_A2 | comment|\n| ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ |\n| 1      | 438956 | <NA>   | G      | A      | 0.0021 | -0.538 | 0.5802 | 0.3533 | G      | A      | \"kept original\"|\n| 13     | 704956 | <NA>   | T      | C      | 0.0242 | 0.1235 | 0.2469 | 0.0673 | C      | T      | \"flipped\" |\n| 22     | 568952 | <NA>   | A      | G      | 0.0267 | 0.7485 | 0.7869 | 0.0843 | <NA>   | <NA>   | \"key not found\" |\n| X      | 274586 | <NA>   | C      | T      | 0.0243 | 0.1357 | 0.2435 | 0.1243 | G      | T      | \"different\" |\n\n\n`check_errors=True`\n| Chr    | BP     | SNP    | A1     | A2     | EAF    | Beta   | Se     | P      | new_A1 | new_A2 | comment|\n| ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ |\n| 22     | 568952 | <NA>   | A      | G      | 0.0267 | 0.7485 | 0.7869 | 0.0843 | <NA>   | <NA>   | \"key not found\" |\n| X      | 274586 | <NA>   | C      | T      | 0.0243 | 0.1357 | 0.2435 | 0.1243 | G      | T      | \"different\" |\n\n### Align Effect Allele and Effect Size between Two Datasets\n```python\nalign_effect_allele( reference, df, show_errors=False)\n```\n\nThis function will align the effect allele of input data based on a reference data\n\nParameters:\n- reference (pandas.DataFrame): the reference table\n- df (pandas.DataFrame): the data to be aligned\n- check_error_rows (boolean): if true, the function will output the rows that cannot be aligned. Default to False.\n\nReturns:\n- pandas.DataFrame: return the data with its effect allele being aligned with the reference table.\n\nExample:\n```python\nreference_path = \"<path_to_your_reference_data_file>.gz\"\nreference_df = di.read_data(input_path, \"chromosome\",\"base_pair_location\", \"variant_id\" ,\"effect_allele\", \"other_allele\", \"effect_allele_frequency\", \"beta\", \"standard_error\", \"p_value\") # for example\naligned = align_effect_allele(reference_df, df) # be sure df and reference_df are using the same genome build, and both data are properlly cleaned!!\n\n# if you want to see rows that cannot be aligned\naligned = align_effect_allele(reference_df, df, check_error_rows=True)\n```\n\n## 5. Functions to save result\n\n### Save Data\n```python\nsave_data(output_path, df, name, save_format=\"gzip\")\n```\n\nfunction to save the processed data in the tsv form as a gz file\n\nParameters:\n- output_path (str): the path you want the data to be saved.\n- df (pandas.DataFrame): the processed data to be saved.\n- name (str): the output name of the data.\n- save_format (str): the saving format. Choose between 'gzip' or 'csv'. Default to gz.\n\nReturns:\npandas.DataFrame: return filtered data in the form of pandas DataFrame\n\n\nExample:\n```python\noutput_path = \"<path_to_your_output_directory>\" # \"result\" for example\ndi.save_data(output_path, aligned, \"aligned\")\n\n# if you want to save the file as csv\ndi.save_data(output_path, aligned, \"csv\")\n```\n\n\n\n\n**Functions to be Implemented**\n### Insert/ Filter/ Delete\n\n### Create Tbi Index\n\n\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/chenyyxx/DataIntegration",
    "keywords": "Data Integrator",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "dataintegrator",
    "package_url": "https://pypi.org/project/dataintegrator/",
    "platform": "",
    "project_url": "https://pypi.org/project/dataintegrator/",
    "project_urls": {
      "Homepage": "https://github.com/chenyyxx/DataIntegration"
    },
    "release_url": "https://pypi.org/project/dataintegrator/0.1.0/",
    "requires_dist": [
      "pyBigWig",
      "pyliftover",
      "numpy",
      "pandas (>=1.0.0)"
    ],
    "requires_python": "",
    "summary": "Python data processing and formatting tools for gwas summary stats",
    "version": "0.1.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 11218747,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "136f5778ed6de1c6fcf3ac9e06bc27a9a26bd6175ee65b5313bc1e18a36d158d",
          "md5": "a7414753157fd79abd44d3926f517f7f",
          "sha256": "9d051c4fee7e11f4c1a7fb2cbb44e085b09e80ff40b96c641fc92dbfbedc20ad"
        },
        "downloads": -1,
        "filename": "dataintegrator-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "a7414753157fd79abd44d3926f517f7f",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 11386,
        "upload_time": "2021-05-26T14:49:54",
        "upload_time_iso_8601": "2021-05-26T14:49:54.991280Z",
        "url": "https://files.pythonhosted.org/packages/13/6f/5778ed6de1c6fcf3ac9e06bc27a9a26bd6175ee65b5313bc1e18a36d158d/dataintegrator-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b96592513b98a33e68b5bf58fb1efec106c07c8390ca8afd0180bfc898f1da51",
          "md5": "fa51eab5c2b59f9392147dda515f2f98",
          "sha256": "044f7bbaafd95b4ef94099f201073ecaee26cf88f5f228862462e1b05644a7cf"
        },
        "downloads": -1,
        "filename": "dataintegrator-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "fa51eab5c2b59f9392147dda515f2f98",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 12981,
        "upload_time": "2021-05-26T14:49:56",
        "upload_time_iso_8601": "2021-05-26T14:49:56.502084Z",
        "url": "https://files.pythonhosted.org/packages/b9/65/92513b98a33e68b5bf58fb1efec106c07c8390ca8afd0180bfc898f1da51/dataintegrator-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "021b9a184cc4ef80c3269384f04ec0a07e800a08d905a12ea6791def925156f8",
          "md5": "2e9657aacb13b07e044d819065b99b5d",
          "sha256": "edbdf599ec87afd54eb35f3cb7289f9fc6f229323531f7394590f1daef001bcd"
        },
        "downloads": -1,
        "filename": "dataintegrator-0.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "2e9657aacb13b07e044d819065b99b5d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 12196,
        "upload_time": "2021-05-28T16:18:01",
        "upload_time_iso_8601": "2021-05-28T16:18:01.306129Z",
        "url": "https://files.pythonhosted.org/packages/02/1b/9a184cc4ef80c3269384f04ec0a07e800a08d905a12ea6791def925156f8/dataintegrator-0.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "45564a47daf317474f620e31fe2ab8f9faf637155ddaff4d32f0075077fd36e4",
          "md5": "e7f54c284f5e5aaf3ce80eb17b334cb4",
          "sha256": "918839da88c02f2d3f5eef93e6bae908852446a07a3a9ed4ae19afb9f48a80fc"
        },
        "downloads": -1,
        "filename": "dataintegrator-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "e7f54c284f5e5aaf3ce80eb17b334cb4",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 14425,
        "upload_time": "2021-05-28T16:18:03",
        "upload_time_iso_8601": "2021-05-28T16:18:03.569648Z",
        "url": "https://files.pythonhosted.org/packages/45/56/4a47daf317474f620e31fe2ab8f9faf637155ddaff4d32f0075077fd36e4/dataintegrator-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "98c9b108d7d2335f6d9458ccea205d1465e301fef2fca26439ce7bf983eb990a",
          "md5": "1e8dc5f456ee98c68f00c7560e7b9060",
          "sha256": "8a182b9a7169a8ed8f308fd7c3efa71cf0ced0e9f48f68d491ce08192f97772f"
        },
        "downloads": -1,
        "filename": "dataintegrator-0.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "1e8dc5f456ee98c68f00c7560e7b9060",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 12199,
        "upload_time": "2021-05-28T16:38:06",
        "upload_time_iso_8601": "2021-05-28T16:38:06.562661Z",
        "url": "https://files.pythonhosted.org/packages/98/c9/b108d7d2335f6d9458ccea205d1465e301fef2fca26439ce7bf983eb990a/dataintegrator-0.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "dbd0086e225ba273ea36cfb43a8b8bf515b84d56e2c5c7cc57479eeeff31ad8b",
          "md5": "35cc29bee0690f1ff09fbf26bf2ec5d8",
          "sha256": "ed3437621e14f98c049972a1aa9263aa0bcb63668ff097489372629fd3db66d3"
        },
        "downloads": -1,
        "filename": "dataintegrator-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "35cc29bee0690f1ff09fbf26bf2ec5d8",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 14438,
        "upload_time": "2021-05-28T16:38:07",
        "upload_time_iso_8601": "2021-05-28T16:38:07.802129Z",
        "url": "https://files.pythonhosted.org/packages/db/d0/086e225ba273ea36cfb43a8b8bf515b84d56e2c5c7cc57479eeeff31ad8b/dataintegrator-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ce2c1b622be40f4a240f32f5673256781e6ab3e386ab92ce7f875dfe5b79412e",
          "md5": "97b5187a58ce674e4be1150f28ce5d50",
          "sha256": "1e0103a2d286cf4735f9a099b32ba3d3b8996d54e67984f212d7d0e69700a524"
        },
        "downloads": -1,
        "filename": "dataintegrator-0.0.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "97b5187a58ce674e4be1150f28ce5d50",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 12203,
        "upload_time": "2021-05-31T15:40:09",
        "upload_time_iso_8601": "2021-05-31T15:40:09.355741Z",
        "url": "https://files.pythonhosted.org/packages/ce/2c/1b622be40f4a240f32f5673256781e6ab3e386ab92ce7f875dfe5b79412e/dataintegrator-0.0.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "dfd21224d31541ef4ba04f62030da9ce513ac18441a744084a497735938f7fad",
          "md5": "c4e44c60f11314b5cc43a8642088af0d",
          "sha256": "04049601cda8c0f4744bb7a5099364406b423f24f5ee10d061c95a1472bbf820"
        },
        "downloads": -1,
        "filename": "dataintegrator-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "c4e44c60f11314b5cc43a8642088af0d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 14431,
        "upload_time": "2021-05-31T15:40:10",
        "upload_time_iso_8601": "2021-05-31T15:40:10.684143Z",
        "url": "https://files.pythonhosted.org/packages/df/d2/1224d31541ef4ba04f62030da9ce513ac18441a744084a497735938f7fad/dataintegrator-0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4f3a83e13cc5f1f189bd4aa80bb829399bbbc1e3cb255c5566c82ee13b71de3a",
          "md5": "d1da5326e034cb2f5a78b25e5c535625",
          "sha256": "1525ff46f48cef5b4dec1b5de1fb47d84a71333edbcad20ace5155e7f3d3ba90"
        },
        "downloads": -1,
        "filename": "dataintegrator-0.0.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d1da5326e034cb2f5a78b25e5c535625",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 11772,
        "upload_time": "2021-06-02T07:04:05",
        "upload_time_iso_8601": "2021-06-02T07:04:05.514480Z",
        "url": "https://files.pythonhosted.org/packages/4f/3a/83e13cc5f1f189bd4aa80bb829399bbbc1e3cb255c5566c82ee13b71de3a/dataintegrator-0.0.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ea7e1f0d99b882ba30092b9f3233507ea18235bac709613c2f3ce1942579d817",
          "md5": "158d66b93d8004a6030dca4c981054b2",
          "sha256": "10ab445eb3900690afcd1dd770b8c96ebb194c19818d2b58dce65f8ae2628b20"
        },
        "downloads": -1,
        "filename": "dataintegrator-0.0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "158d66b93d8004a6030dca4c981054b2",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 14800,
        "upload_time": "2021-06-02T07:04:06",
        "upload_time_iso_8601": "2021-06-02T07:04:06.964617Z",
        "url": "https://files.pythonhosted.org/packages/ea/7e/1f0d99b882ba30092b9f3233507ea18235bac709613c2f3ce1942579d817/dataintegrator-0.0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.6.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "64e6e040375b4c3738ba4c89f258a8bd89983e62803ae6707792188ca8b93a60",
          "md5": "2c9c2c74bdc41eb6cf3bf6c5f6cbeccc",
          "sha256": "de6b0bb6a1bf9f6442cf5785fabbadbd2d944b632c0e885b3ef6c97fffd630fc"
        },
        "downloads": -1,
        "filename": "dataintegrator-0.0.6.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "2c9c2c74bdc41eb6cf3bf6c5f6cbeccc",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 11801,
        "upload_time": "2021-08-18T19:33:57",
        "upload_time_iso_8601": "2021-08-18T19:33:57.997148Z",
        "url": "https://files.pythonhosted.org/packages/64/e6/e040375b4c3738ba4c89f258a8bd89983e62803ae6707792188ca8b93a60/dataintegrator-0.0.6.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1a316b00c07592d7cf8a2e03efd3d374a6b2198d55e97601ff645a159999f417",
          "md5": "825734bfad23d7671ac97291108879d4",
          "sha256": "d6e611c392d908d4296b85fc19d214799a1877e40495e6e8f63ac3cb78d4d8fe"
        },
        "downloads": -1,
        "filename": "dataintegrator-0.0.6.1.tar.gz",
        "has_sig": false,
        "md5_digest": "825734bfad23d7671ac97291108879d4",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 14523,
        "upload_time": "2021-08-18T19:33:59",
        "upload_time_iso_8601": "2021-08-18T19:33:59.526193Z",
        "url": "https://files.pythonhosted.org/packages/1a/31/6b00c07592d7cf8a2e03efd3d374a6b2198d55e97601ff645a159999f417/dataintegrator-0.0.6.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.6.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3ff5e5ad25a19d064b6a080e31ffc83bd3f624791e28cb228336e7934457e26d",
          "md5": "c11cbd133475d8fa8608a2678c60d76b",
          "sha256": "a56b0b30bcf63f2c502c107055987083eb84b62335948a203752eef47f826c60"
        },
        "downloads": -1,
        "filename": "dataintegrator-0.0.6.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "c11cbd133475d8fa8608a2678c60d76b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 11804,
        "upload_time": "2021-08-18T19:40:28",
        "upload_time_iso_8601": "2021-08-18T19:40:28.090688Z",
        "url": "https://files.pythonhosted.org/packages/3f/f5/e5ad25a19d064b6a080e31ffc83bd3f624791e28cb228336e7934457e26d/dataintegrator-0.0.6.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1736530c617efd05b29710d22ccac408fc7db0f455d5bf88eeb74c1e4deebeb1",
          "md5": "a0f19fc1d1f29fda0997274bc0b4709f",
          "sha256": "77276c4f12702c8885b44fc9ff789da7c09339d751e9841822b3ab0ee514c881"
        },
        "downloads": -1,
        "filename": "dataintegrator-0.0.6.2.tar.gz",
        "has_sig": false,
        "md5_digest": "a0f19fc1d1f29fda0997274bc0b4709f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 14528,
        "upload_time": "2021-08-18T19:40:29",
        "upload_time_iso_8601": "2021-08-18T19:40:29.283245Z",
        "url": "https://files.pythonhosted.org/packages/17/36/530c617efd05b29710d22ccac408fc7db0f455d5bf88eeb74c1e4deebeb1/dataintegrator-0.0.6.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.6.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "31973ac35925593f0b3d39b23a5a7a255e8a049760ebbf595ba46cfa84d26e5a",
          "md5": "226ea3ab88df9bb33c609bdc44e9e08e",
          "sha256": "74c756f72d714494564ec82a8f64f8d5cddb8e710754bdce01a9508aa4d87795"
        },
        "downloads": -1,
        "filename": "dataintegrator-0.0.6.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "226ea3ab88df9bb33c609bdc44e9e08e",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 11804,
        "upload_time": "2021-08-18T19:43:35",
        "upload_time_iso_8601": "2021-08-18T19:43:35.657457Z",
        "url": "https://files.pythonhosted.org/packages/31/97/3ac35925593f0b3d39b23a5a7a255e8a049760ebbf595ba46cfa84d26e5a/dataintegrator-0.0.6.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5e26a4ef16b84dcc767cc4c566c8b7b046c486dfa7173e1c27fcc7dca0042acd",
          "md5": "9b7fd734008822e1560b729a9a1287dd",
          "sha256": "8870900ee5f47db01b0fa74b8d445613cf4b3136fd8a523c908869fdea7ab004"
        },
        "downloads": -1,
        "filename": "dataintegrator-0.0.6.3.tar.gz",
        "has_sig": false,
        "md5_digest": "9b7fd734008822e1560b729a9a1287dd",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 14543,
        "upload_time": "2021-08-18T19:43:36",
        "upload_time_iso_8601": "2021-08-18T19:43:36.970092Z",
        "url": "https://files.pythonhosted.org/packages/5e/26/a4ef16b84dcc767cc4c566c8b7b046c486dfa7173e1c27fcc7dca0042acd/dataintegrator-0.0.6.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d4d51eb43445aab6d0e844523f6fca33e4b6a06bd1fdc1043adfea750ab4fa91",
          "md5": "014bbb1413e79f73863be7488ca3dd61",
          "sha256": "c62fe7a047bdc864e7952086a7358bb5e08f630ff4cf1f5428506259a6bdb591"
        },
        "downloads": -1,
        "filename": "dataintegrator-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "014bbb1413e79f73863be7488ca3dd61",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 11974,
        "upload_time": "2021-08-19T05:51:33",
        "upload_time_iso_8601": "2021-08-19T05:51:33.899387Z",
        "url": "https://files.pythonhosted.org/packages/d4/d5/1eb43445aab6d0e844523f6fca33e4b6a06bd1fdc1043adfea750ab4fa91/dataintegrator-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f905299d499bdbbb79f463ea0a3d6e3a008502e540dfbb6215557b206197c184",
          "md5": "0eb172c735a448f4c5c27aa1b778083e",
          "sha256": "3c9b5daf52bf64e0abe61a7f71fbc0801fb08771ed241322a934d7a6f7fb9477"
        },
        "downloads": -1,
        "filename": "dataintegrator-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "0eb172c735a448f4c5c27aa1b778083e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 14787,
        "upload_time": "2021-08-19T05:51:35",
        "upload_time_iso_8601": "2021-08-19T05:51:35.777230Z",
        "url": "https://files.pythonhosted.org/packages/f9/05/299d499bdbbb79f463ea0a3d6e3a008502e540dfbb6215557b206197c184/dataintegrator-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "d4d51eb43445aab6d0e844523f6fca33e4b6a06bd1fdc1043adfea750ab4fa91",
        "md5": "014bbb1413e79f73863be7488ca3dd61",
        "sha256": "c62fe7a047bdc864e7952086a7358bb5e08f630ff4cf1f5428506259a6bdb591"
      },
      "downloads": -1,
      "filename": "dataintegrator-0.1.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "014bbb1413e79f73863be7488ca3dd61",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 11974,
      "upload_time": "2021-08-19T05:51:33",
      "upload_time_iso_8601": "2021-08-19T05:51:33.899387Z",
      "url": "https://files.pythonhosted.org/packages/d4/d5/1eb43445aab6d0e844523f6fca33e4b6a06bd1fdc1043adfea750ab4fa91/dataintegrator-0.1.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "f905299d499bdbbb79f463ea0a3d6e3a008502e540dfbb6215557b206197c184",
        "md5": "0eb172c735a448f4c5c27aa1b778083e",
        "sha256": "3c9b5daf52bf64e0abe61a7f71fbc0801fb08771ed241322a934d7a6f7fb9477"
      },
      "downloads": -1,
      "filename": "dataintegrator-0.1.0.tar.gz",
      "has_sig": false,
      "md5_digest": "0eb172c735a448f4c5c27aa1b778083e",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 14787,
      "upload_time": "2021-08-19T05:51:35",
      "upload_time_iso_8601": "2021-08-19T05:51:35.777230Z",
      "url": "https://files.pythonhosted.org/packages/f9/05/299d499bdbbb79f463ea0a3d6e3a008502e540dfbb6215557b206197c184/dataintegrator-0.1.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}