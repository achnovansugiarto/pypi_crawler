{
  "info": {
    "author": "Alonso Serrano",
    "author_email": "bioinformatics@loalon.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: GNU General Public License v3 (GPLv3)",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# GBcrawler\n\n**GBcrawler** is a complete GenBank parser in Python 3 meant to be used by other applications.\n\nGenerates a Python object of GBcrawler class that stores all relevant information within a GenBank file.\n\n\n## Table of Contents\n\n[**Features**](#features)\n\n[**Installation**](#installation)\n\n[**Usage**](#usage)\n\n[**Discrepancies**](#discrep)\n\n[**Future features**](#future)\n\n## Features\n\nThis script was made using the information from: \n\n  * NCBI-GenBank Flat File Release available at [NCBI](https://www.ncbi.nlm.nih.gov/genbank/)\n  * Features table available at [INSDC](http://www.insdc.org/documents/feature-table).\n\n\n## Installation\n\nPython 3 is requiered.\n\nCopy GBcrawler.py to the folder of your project and import it as explained in [**Usage**](#usage)\n\n\n## Usage\n\nTo get the GenBank data, create an object with the GenBank filename as a parameter: \n\n```\nimport GBcrawler from GB crawler\nGBobject = GBcrawler(\"tth1.gb\")\n```\n\nThe following data can be adquired using: attributes or methods\n\nAttribute references:\n  * `sequenceID` returns sequence identification\n  * `sequenceLength` returns length of sequence\n  * `strand` returns the strand type \n  * `moleculeType` returns molecule type\n  * `division` returns divison code\n  * `modDate` returns date\n  * `definition` returns definition\n  * `accession` returns accesion\n  * `version` returns version\n  * `referenceList` returns a list, each element is a reference\n  * `comment` returns all the comments as a string\n  * `featureList` returns a list of GBfeatues object\n  * `sequenceList` returns the sequence as a list, (see methods to get the sequence as a string)\n  * `baseCount` returns dictionary with nucleotide counts\n\nMethods:\n  * `getSequence()` returns sequence as a string\n\nThe featureList is composed of GBfeature objects and data can be adquired using the following attribute references:\n  * `begin` returns sequence identification\n  * `end` returns length of sequence\n  * `type` returns the type of the feauture (gene, CDS, ...)\n  * `qualifierDict` returns a Dictionary with keys and values for each qualifier\n\n## Discrepancies\n\nThe last Flat File release 220.0 has a set of features that is different from the feature table in INSDC. The release indicates \"Any discrepancy between the abbreviated feature table description of these release notes and the complete documentation on the Web\nshould be resolved in favor of the version at the above URL.\"\n\nAt the moment, both sets of features will be used to parse the GenBank files, until a large batch of GenBank files can be tested and check how many files uses the \"non-standard\" features\n\n\n## Future features\n\n  * export to FASTA\n  * check features for mandatory qualifiers\n  * faster performance\n  * tag features by its locus_tag\n  * use additional info for the features (beyond, between bases, etc)\n  * create a Reference class to better reference data management\n  * improve ACCESION to return a list\n  * improve SOURCE parsing \n\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/loalon/gbcrawler",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "gbcrawler",
    "package_url": "https://pypi.org/project/gbcrawler/",
    "platform": "",
    "project_url": "https://pypi.org/project/gbcrawler/",
    "project_urls": {
      "Homepage": "https://github.com/loalon/gbcrawler"
    },
    "release_url": "https://pypi.org/project/gbcrawler/0.3.0/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "Complete GenBank parser",
    "version": "0.3.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 7417437,
  "releases": {
    "0.3.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c8b8a7621192ecf7034a98e610eeb8d0bce6f85bc453bf1bc7e4dfebefc66fa9",
          "md5": "9af3969bbf67a69a55dc00e183577e3e",
          "sha256": "14d07a4949ed1c78a6938ce2d4cc6aa593b939411c96955510543485686eaf6b"
        },
        "downloads": -1,
        "filename": "gbcrawler-0.3.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "9af3969bbf67a69a55dc00e183577e3e",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 21292,
        "upload_time": "2020-06-07T15:09:48",
        "upload_time_iso_8601": "2020-06-07T15:09:48.893019Z",
        "url": "https://files.pythonhosted.org/packages/c8/b8/a7621192ecf7034a98e610eeb8d0bce6f85bc453bf1bc7e4dfebefc66fa9/gbcrawler-0.3.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "51b128e36961e435bf5e5652c1305b7c118834dc270970eced5a83ad62d9f1d2",
          "md5": "650f1fc5f24b7f481603a2e38fc48a84",
          "sha256": "f2f06b4451b25ad891aeaf40e91777603140f289771a6306b1e6b61f37ad2805"
        },
        "downloads": -1,
        "filename": "gbcrawler-0.3.0.tar.gz",
        "has_sig": false,
        "md5_digest": "650f1fc5f24b7f481603a2e38fc48a84",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 5816,
        "upload_time": "2020-06-07T15:09:51",
        "upload_time_iso_8601": "2020-06-07T15:09:51.003800Z",
        "url": "https://files.pythonhosted.org/packages/51/b1/28e36961e435bf5e5652c1305b7c118834dc270970eced5a83ad62d9f1d2/gbcrawler-0.3.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "c8b8a7621192ecf7034a98e610eeb8d0bce6f85bc453bf1bc7e4dfebefc66fa9",
        "md5": "9af3969bbf67a69a55dc00e183577e3e",
        "sha256": "14d07a4949ed1c78a6938ce2d4cc6aa593b939411c96955510543485686eaf6b"
      },
      "downloads": -1,
      "filename": "gbcrawler-0.3.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "9af3969bbf67a69a55dc00e183577e3e",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 21292,
      "upload_time": "2020-06-07T15:09:48",
      "upload_time_iso_8601": "2020-06-07T15:09:48.893019Z",
      "url": "https://files.pythonhosted.org/packages/c8/b8/a7621192ecf7034a98e610eeb8d0bce6f85bc453bf1bc7e4dfebefc66fa9/gbcrawler-0.3.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "51b128e36961e435bf5e5652c1305b7c118834dc270970eced5a83ad62d9f1d2",
        "md5": "650f1fc5f24b7f481603a2e38fc48a84",
        "sha256": "f2f06b4451b25ad891aeaf40e91777603140f289771a6306b1e6b61f37ad2805"
      },
      "downloads": -1,
      "filename": "gbcrawler-0.3.0.tar.gz",
      "has_sig": false,
      "md5_digest": "650f1fc5f24b7f481603a2e38fc48a84",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 5816,
      "upload_time": "2020-06-07T15:09:51",
      "upload_time_iso_8601": "2020-06-07T15:09:51.003800Z",
      "url": "https://files.pythonhosted.org/packages/51/b1/28e36961e435bf5e5652c1305b7c118834dc270970eced5a83ad62d9f1d2/gbcrawler-0.3.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}