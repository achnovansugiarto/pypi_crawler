{
  "info": {
    "author": "David",
    "author_email": "r3v1@pm.me",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Developers",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: Apache Software License",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Topic :: Scientific/Engineering",
      "Topic :: Scientific/Engineering :: Artificial Intelligence",
      "Topic :: Software Development",
      "Topic :: Software Development :: Libraries",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "# Smooth ReLU in TensorFlow\n\n<p align=\"center\">\n    <img src=\"examples/example.jpg\" alt=\"drawing\"/>\n</p>\n\nUnofficial **TensorFlow** reimplementation of the Smooth ReLU (SmeLU) activation function proposed in the\npaper [Real World Large Scale Recommendation Systems Reproducibility and Smooth Activations](https://arxiv.org/pdf/2202.06499.pdf)\nby Gil I. Shamir and Dong Lin.\n\n**This repository includes an easy-to-use pure TensorFlow implementation of the Smooth ReLU.**\n\n## Installation\n\nThe SmeLU can be installed by using `pip`.\n\n````shell script\npip install git+https://github.com/r3v1/tf-SmeLU\n````\n\n## Example Usage\n\n````python\nimport tensorflow as tf\nfrom tf_smelu import smelu\n\nx = tf.range(-6, 6, 1, dtype=float)  # <tf.Tensor: numpy=array([-6., -5., -4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.,  5.], dtype=float32)>\n\nsmelu(x, beta=0.1)  # <tf.Tensor: numpy=array([0.,0.,0.,0.,0.,0.,0.025,1.,2.,3.,4.,5.], dtype=float32)>\nsmelu(x, beta=0.5)  # <tf.Tensor: numpy=array([0.,0.,0.,0.,0.,0.,0.125,1.,2.,3.,4.,5.], dtype=float32)>\nsmelu(x, beta=1.)   # <tf.Tensor: numpy=array([0.,0.,0.,0.,0.,0.,0.25 ,1.,2.,3.,4.,5.], dtype=float32)>\n````\n\nThe SmeLU takes the following parameters.\n\n- `beta`: Half-width of a symmetric transition region around x = 0. Defaults to 1.\n\n## Reference\n\n````bibtex\n@article{Shamir2022,\n        title={{Real World Large Scale Recommendation Systems Reproducibility and Smooth Activations}},\n        author={Shamir, Gil I and Lin, Dong},\n        journal={{arXiv preprint arXiv:2202.06499}},\n        year={2022}\n}\n````\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/r3v1/tf-SmeLU",
    "keywords": "tensorflow activation smelu",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "tf-SmeLU",
    "package_url": "https://pypi.org/project/tf-SmeLU/",
    "platform": null,
    "project_url": "https://pypi.org/project/tf-SmeLU/",
    "project_urls": {
      "Homepage": "https://github.com/r3v1/tf-SmeLU"
    },
    "release_url": "https://pypi.org/project/tf-SmeLU/1.0.0/",
    "requires_dist": null,
    "requires_python": ">=3.8",
    "summary": "Tensorflow Smooth ReLU (SmeLU) implementation",
    "version": "1.0.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 13887377,
  "releases": {
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "77ae5e97af20e6fd906a0192a8eeb36d21324ecee10b88a239f898e50f85fa46",
          "md5": "c2e99b3dcdea4b5e790be3c0c5e7016c",
          "sha256": "fb15684288906052edf68a4434d147ca2a3bc28b771e9e9320b927d27b5e504b"
        },
        "downloads": -1,
        "filename": "tf-SmeLU-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "c2e99b3dcdea4b5e790be3c0c5e7016c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 37294,
        "upload_time": "2022-05-21T15:51:39",
        "upload_time_iso_8601": "2022-05-21T15:51:39.709770Z",
        "url": "https://files.pythonhosted.org/packages/77/ae/5e97af20e6fd906a0192a8eeb36d21324ecee10b88a239f898e50f85fa46/tf-SmeLU-1.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "77ae5e97af20e6fd906a0192a8eeb36d21324ecee10b88a239f898e50f85fa46",
        "md5": "c2e99b3dcdea4b5e790be3c0c5e7016c",
        "sha256": "fb15684288906052edf68a4434d147ca2a3bc28b771e9e9320b927d27b5e504b"
      },
      "downloads": -1,
      "filename": "tf-SmeLU-1.0.0.tar.gz",
      "has_sig": false,
      "md5_digest": "c2e99b3dcdea4b5e790be3c0c5e7016c",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.8",
      "size": 37294,
      "upload_time": "2022-05-21T15:51:39",
      "upload_time_iso_8601": "2022-05-21T15:51:39.709770Z",
      "url": "https://files.pythonhosted.org/packages/77/ae/5e97af20e6fd906a0192a8eeb36d21324ecee10b88a239f898e50f85fa46/tf-SmeLU-1.0.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}