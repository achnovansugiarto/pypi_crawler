{
  "info": {
    "author": "Xiaoyu Zhai",
    "author_email": "xiaoyu.zhai@hotmail.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "<br />\n<div align=\"center\">\n  <a href=\"https://github.com/ryantd/veloce\">\n    <img src=\"docs/images/logo.png\" alt=\"Veloce Logo\">\n  </a>\n</div>\n<br />\n\n> The project is currently under heavy development, and focusing on **PyTorch** and the **recommendation** scenario.\n\n## About\n**Veloce** is an `instant distributed computing` library based on the **Ray Train** and **Ray Data**, which is scalable, efficient, and easy-to-use. It accelerates the development of any ML/DL training workload, on any cloud or local, at any parallelism size. Previously named Enscale.\n\n### Goals\n- Launch any interactive ML/DL workloads **instantly** on your laptop or to any cloud\n- **Scale** your own single-machine neural network modules to a native **distributed** manner\n- Apply **heterogeneous** architecture\n- **Data scientist-friendly** API\n- **Sparse** and **dense feature** definitions\n\n### Non-Goals\n- Not a neural network library, there are only some benchmark modules provided.\n\n## Getting Started\n### Prerequisites\n- Python version >= `3.7.1`\n- Packages\n  - requests >= `2.26.0`\n  - ray >= `1.9.2` and <= `1.10`\n  - torch >= `1.9.1`\n  - pandas >= `1.3.5`\n  - pyarrow >= `6.0.1`\n\n### Installation\n\n#### Using Pre-compiled Wheels\n```shell\n# CPU version\npip install veloce\n```\n\n#### From Source\n```shell\ngit clone https://github.com/ryantd/veloce\ncd veloce\npip install -e .\n```\n\n### Runtime environment\n\nThe library can launch **locally** or on any **cloud provider** with Ray set up.\n\n- If you want to launch on the cloud, go through this [doc](https://docs.ray.io/en/latest/cluster/cloud.html#launching-cloud-clusters) to set up your Ray Cluster. And then you can use `environ_validate(n_cpus=N, cluster_endpoint=\"ray://<head_node_host>:<port>\")` to connect your cluster.\n- Or just use `environ_validate(n_cpus=N)` to have a local experience.\n\nYou can add more native `ray.init` arguments, just put them into `environ_validate` call. Like `environ_validate(n_cpus=N, ignore_reinit_error=True)` to make Ray suppresses errors from calling `ray.init()` a second time.\n\n### Lightning example\n\n> See more hands-on and advanced examples [here](examples/readme.md), like heterogeneous support and sparsity definition.\n\nThe following example requires `sklearn` to be installed. And `tqdm` is optional, which enables progress reporting.\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1mtDacq6Yty4k5tz_6iVA-lk83YnD46S3?usp=sharing)\n\n```python\nimport torch\nimport torch.nn as nn\nfrom sklearn.metrics import roc_auc_score\nfrom veloce.util import pprint_results, load_benchmark_dataset\nfrom veloce.model.ctr import DeepFM\nfrom veloce import NeuralNetTrainer, environ_validate\n\nN_WORKERS = 2\nN_DATA_PROCESSOR = 1\n\n# ray environment setup\nenviron_validate(n_cpus=N_DATA_PROCESSOR + N_WORKERS)\n# load dataset and sparsity definition pre-defined\ndatasets, feature_defs, dataset_options = load_benchmark_dataset(\n    # set your own dataset by `data_path=\"criteo_mini.txt\"`\n    separate_valid_dataset=False\n)\n# trainer setup\ntrainer = NeuralNetTrainer(\n    # module and dataset configs\n    module=DeepFM, # your own nn.Module or built in modules\n    module_params={\n        \"dense_feature_defs\": feature_defs[\"dense\"],\n        \"sparse_feature_defs\": feature_defs[\"sparse\"],\n    },\n    dataset=datasets,\n    dataset_options=dataset_options,\n    # trainer configs\n    epochs=5,\n    batch_size=512,\n    loss_fn=nn.BCELoss(),\n    optimizer=torch.optim.Adam,\n    metric_fns=[roc_auc_score],\n    # logger callbacks\n    callbacks=[\"json\"],\n    # computation abstract on distributed\n    num_workers=N_WORKERS,\n)\n# run and print results\nresults = trainer.run()\npprint_results(results)\n```\n\n## Architecture\n\n![arch](docs/images/arch.png)\n\n## Roadmap\n\n- Heterogeneous Strategy on Distributed Training\n  - [x] Sync Parameter Server\n  - [ ] Aync Parameter Server\n  - [ ] Hybird Phase 1: use sync or async for the dense or sparse component as you like, under homogeneous architecture\n  - [ ] Hybird Phase 2: you can choose async PS for the sparse component, and sync Ring Allreduce (like PyTorch's DDP) for the dense component\n- Framework Support\n  - [x] PyTorch: no specific plan to support other frameworks\n- Advanced Parallel Mechanism\n  - [ ] Heavy integrated [torchrec](https://github.com/pytorch/torchrec)\n- Accelerator Support\n  - [ ] GPU: complete inspection required\n\n## Reference\n- [Ray and Ray Train](https://github.com/ray-project/ray): Ray Train is a lightweight library for distributed deep learning, allowing you to scale up and speed up training for your deep learning models. Docs [here](https://docs.ray.io/en/master/train/train.html).\n- [DeepCTR-Torch](https://github.com/shenweichen/DeepCTR-Torch): Easy-to-use, modular and extendible package of deep-learning based CTR models.\n\n## License\nVeloce is MIT licensed, as found in the [LICENSE](LICENSE) file.\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/ryantd/veloce",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "veloce",
    "package_url": "https://pypi.org/project/veloce/",
    "platform": null,
    "project_url": "https://pypi.org/project/veloce/",
    "project_urls": {
      "Homepage": "https://github.com/ryantd/veloce"
    },
    "release_url": "https://pypi.org/project/veloce/0.0.1rc2/",
    "requires_dist": null,
    "requires_python": ">=3.7.1",
    "summary": "Veloce: An instant distributed computing library based on Ray stack",
    "version": "0.0.1rc2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 13289934,
  "releases": {
    "0.0.1.dev1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6a4182b188ee661035cac931e2a5f77062d0c01f73a5a2e7a1cdc8d39bee407f",
          "md5": "abf0f61b8b46a29aa2fee4d254e92de0",
          "sha256": "78c58fac3787ca490a29c22e0815e69ae2deaf6f93797108a80bc534bdd39098"
        },
        "downloads": -1,
        "filename": "veloce-0.0.1.dev1.tar.gz",
        "has_sig": false,
        "md5_digest": "abf0f61b8b46a29aa2fee4d254e92de0",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 1092,
        "upload_time": "2022-03-25T01:31:19",
        "upload_time_iso_8601": "2022-03-25T01:31:19.781349Z",
        "url": "https://files.pythonhosted.org/packages/6a/41/82b188ee661035cac931e2a5f77062d0c01f73a5a2e7a1cdc8d39bee407f/veloce-0.0.1.dev1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.1rc1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "35d3f7d8b495619ba71baaab33cc5284078a8fab33675d5207346226584e7096",
          "md5": "954c37e6cb53512ac99df6e6a14eb37c",
          "sha256": "11f3d8f1c7a77400a98d9f61695597a07f846cd5bf1f1a27d768ffa219c6bcc2"
        },
        "downloads": -1,
        "filename": "veloce-0.0.1rc1.tar.gz",
        "has_sig": false,
        "md5_digest": "954c37e6cb53512ac99df6e6a14eb37c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7.1",
        "size": 24494,
        "upload_time": "2022-03-25T05:57:17",
        "upload_time_iso_8601": "2022-03-25T05:57:17.669123Z",
        "url": "https://files.pythonhosted.org/packages/35/d3/f7d8b495619ba71baaab33cc5284078a8fab33675d5207346226584e7096/veloce-0.0.1rc1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.1rc2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "57789e576726721df8b7bd24d434ac5a72e269713d16ef8b2bb3c530e86660ef",
          "md5": "a0a4aad36122d6b94a7de1184d78b3c3",
          "sha256": "6c9b7292df67821ef848b155fef92b4d2aedf97503327592dc6322e6e6595a17"
        },
        "downloads": -1,
        "filename": "veloce-0.0.1rc2.tar.gz",
        "has_sig": false,
        "md5_digest": "a0a4aad36122d6b94a7de1184d78b3c3",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7.1",
        "size": 24492,
        "upload_time": "2022-03-25T06:02:48",
        "upload_time_iso_8601": "2022-03-25T06:02:48.316080Z",
        "url": "https://files.pythonhosted.org/packages/57/78/9e576726721df8b7bd24d434ac5a72e269713d16ef8b2bb3c530e86660ef/veloce-0.0.1rc2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "57789e576726721df8b7bd24d434ac5a72e269713d16ef8b2bb3c530e86660ef",
        "md5": "a0a4aad36122d6b94a7de1184d78b3c3",
        "sha256": "6c9b7292df67821ef848b155fef92b4d2aedf97503327592dc6322e6e6595a17"
      },
      "downloads": -1,
      "filename": "veloce-0.0.1rc2.tar.gz",
      "has_sig": false,
      "md5_digest": "a0a4aad36122d6b94a7de1184d78b3c3",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7.1",
      "size": 24492,
      "upload_time": "2022-03-25T06:02:48",
      "upload_time_iso_8601": "2022-03-25T06:02:48.316080Z",
      "url": "https://files.pythonhosted.org/packages/57/78/9e576726721df8b7bd24d434ac5a72e269713d16ef8b2bb3c530e86660ef/veloce-0.0.1rc2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}