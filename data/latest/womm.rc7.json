{
  "info": {
    "author": "",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "WOMM - Works On My Machine\n==========================\n\nThe problem is as follows: you have a kubernetes cluster with several thousand free cores, and a hefty computational task at hand.\nYou also have a bunch of programmers on your team who absolutely refuse to learn kubernetes.\n\nWOMM attempts to make this a more palatable situation.\nThis essentially boils down to three pieces of technology, tied together as closely as possible:\n\n1. An interface to [GNU parallel](https://www.gnu.org/software/parallel/) which automatically spins up a kubernetes deployment and provides its login information to parallel\n2. A filesystem proxy running in kubernetes to mirror your application code (the current directory) into the cluster, either lazily or eagerly\n3. A testbed environment which prompts you to make sure your application Works On Your machine, saving any dependencies you install to a docker image which will be deployed for your tasks.\n\nThat's it! Sound good? Read on.\n\nInstallation\n------------\n\nFirst, install WOMM:\n\n```\n$ pip install womm\n```\n\nNext, install the runtime dependencies:\n\n- docker, configured to accept commands without root\n- kubectl, connected to a cluster\n- rsync\n- perl\n\nNext, make sure the cluster is configured to run WOMM tasks.\n\n```\n$ womm cluster-setup | kubectl create -f -\n```\n\nFeel free to view the configuration before you pipe it into kubectl.\nIt will create:\n\n- A deployment and corresponding service for the WOMM filesystem server\n- A service account and role to allow the leader task to dispatch jobs and tear down tasks\n\nConfiguration\n-------------\n\nNavigate to the directory with the application you would like to distribute:\n\n```\n$ cd proj/supercool\n```\n\nNow, run `womm setup`.\nThis will run a configuration wizard and save the results to a dotfile in the current directory.\n\nFirst, choose the share method for getting your local directory into the cloud.\nIf you're not sure what to choose, \"lazily\" is a good option.\n\n```\n$ womm setup\nHow do you want to share /home/audrey/proj/womm to your cloud?\n1) lazily\n2) eagerly (no syncback)\n3) eagerly (syncback on complete, not recommended)\n4) not at all\n*) never mind, quit\n[*] > 1\n```\n\nNext, you will be asked for some information related to how the application will be deployed to kubernetes.\nIf you have a working kube setup and are okay with pushing your work to a public repository, you can leave these options at their defaults.\n\n```\nEnter namespace [blank for default]:\n[] >\nEnter image pull secret name [blank for none]:\n[] >\n```\n\nNext, setup will prompt you to choose the docker base image for your application, as well as the prefix for how it should tag your application's image.\nAfter answering, you will be sent to the depths of a shell where you can install dependencies for your application.\n\n```\nWhat is the docker hub name for the base image for your operating system?\n[ubuntu:22.04] > ubuntu:20.04\nWhat is a prefix of a docker image name that you are authorized to push to a secure location?\ne.g. 'us-west4-docker.pkg.dev/angr-ci/defcon/'\n> docker.io/rhelmot/\nsha256:5852d80f97499322f2acd170f0dc909661171ad56dddd61dbb6fbc7ab4a2c6ae\nThis is a *local* shell where any dependencies you install will be saved.\nThe goal is that if your application works here, it will work on the cloud too.\nMake it work!\nAlso make sure our dependencies are installed: perl\n$\n```\n\nSome notes:\n- This shell has your current directory mounted in as, uh, your current directory.\n  This is the same as it will be during actual execution.\n- The command to \"make it work\" is prudent. Do make sure to test your application and only quit the shell once it works.\n- If you need to _reference_ content from your host filesystem, it's mounted at /mnt. This will **not** be there during actual execution.\n- Any environment variables you export from this shell will make their way into the runtime environment.\n\nAfter quitting the shell, WOMM will perform a quick dependency check and then ask you whether your application works:\n\n```\n$ logout\nsha256:4a39d88233e612e76223ff2e25a1e2f001d9ecddd72dd244666a417498002fea\nDoes it work? y/n\n[y] > y\nUsing default tag: latest\nThe push refers to repository [docker.io/rhelmot/womm-image-awtmaomf]\ncb36e0e3954b: Pushed\nad4edcda1e99: Pushed\n144adb730393: Pushed\nccb524e7f77c: Pushed\n311a746575b9: Pushed\n7005bb5aaace: Pushed\ne5751e41192e: Pushed\n9f54eef41275: Pushing [========>                                          ]  13.04MB/72.78MB\nf469e45a6f33\n```\n\nAnd that's it! You're ready to party.\nIf you ever want to change any of these parameters again, just run `womm setup` in the same directory.\n\nGive me a shell on a 32 core machine!\n-------------------------------------\n\nOkay.\n\n```\n$ womm shell --kube-cpu 32 --kube-mem 16Gi\n```\n\nI want more cores!\n------------------\n\nOkay. You can use the above up to a certain point but if you go too far you won't be able to schedule your container - no machine on the cluster will have enough spare cores at once to give you your shell.\nIf you want more (and clearly you do), you need to express your desire for compute in a way that can be distributed across multiple machines.\nEnter GNU parallel.\n\nUse `womm parallel` the same way you would use the normal GNU `parallel` command (if you're not familiar with it, it's a lot like xargs).\nA small caveat - you are required to specify the `--kube-pods` parameter, and you are required to separate your input from your options with `--`.\nOther than that, go nuts!\n\n```\n$ find -type f | womm parallel --kube-pods 10 -- wc -l {}\ndeployment.apps/womm-task-prnmnvzi created\n101 ./README.md\n340 ./topsecret.sh\n500 ./secretsauce.pl\n1121 ./government-secrets.txt\n2466 ./love-letter-to-chelsea-manning.txt\ndeployment.apps \"womm-task-prnmnvzi\" deleted\n$\n```\n\nOptions\n-------\n\n```\n$ womm parallel --help\nUsage: womm parallel [options] -- [command]\n\nOptions:\n  --kube-pods N       Spin up N pods to dispatch jobs to\n  --local-procs N     In addition to the kube pods, use N local jobslots\n  --procs-per-pod N   Assign N jobslots per pod (default 1)\n  --kube-cpu N        Reserve N cpus per pod (default 1)\n  --kube-mem N        Reserve N memory per pod (default 512Mi)\n  --async             Run the coordinator in the cluster, requiring manual log collection and\n                      cleanup, but adding resilience against network failures\n  --citation          Silence the GNU parallel citation message\n  --help              Show this message :)\n\nOther options will be interpreted by gnu parallel.\n```\n\nA \"pod\" is kubernetes' unit of resource allocation.\nIt represents (more or less) a docker container running on some remote server with some usage quotas.\nWOMM works by creating a set of pods and providing their login information to GNU parallel.\nYou can adjust the resources each pod is allocated with the `--kube-cpu` and `--kube-mem` flags.\nYou can also adjust the number of jobs that will be assigned to a single pod at once with the `--procs-per-pod` option.\nAs far as I know, this will only be useful in edge cases related to resource constraints.\nFinally, if you want just a little extra kick to your analysis, you can run `--local-procs` to add the local machine to the worker pool.\nBe careful doing this if your application writes data to disk!\n\nThe `--async` flag changes the operation of WOMM to allow tasks to operate independently of the client, in case of network failures, for example.\nIf provided, the `womm` command will terminate when the task is started after printing instructions for monitoring it.\nAsynchronous tasks cannot be run with lazy filesystem shares (see below).\n\nSee below for discussion of the `--citation` flag.\n\nCleaning up\n-----------\n\nThe first step of cleaning up is seeing the mess you've made.\nUse `womm status` to view all tasks using resources on the cluster which were spawned on your machine:\n\n```\n$ womm status\nID        AGE    STATUS     CPU    MEM  HEALTH    PWD                          COMMAND\n--------  -----  -------  -----  -----  --------  ---------------------------  ----------------------------------\nblhqwudx  50m    RUNNING      1  512Mi  1/1       /home/audrey/proj/supercool  'parallel' '--' 'sleep 1; echo {}'\n```\n\nA quick guide to the STATUS field:\n\n- `RUNNING` - The task is ongoing\n- `COMPLETE` - The task is completed and waiting to be cleaned up\n- `ORPHANED` - The task is hung because the coordinator went away\n\nIf you see ORPHANED at any point, immediately clean it up.\nIt is doing nothing but wasting resource quota in the cluster.\n\nCOMPLETE should only happen when running async tasks, since synchronous tasks should be cleaned up automatically by the coordinator (or else become ORPHANED).\nAsynchronous tasks do _some_ cleanup on their own, but cannot do all of it, since logs must be buffered indefinitely.\n\nTo do the rest of the cleanup (or to purge an ORPHANED task), run `womm finish <task id>`.\n\nHow the filesystem share works\n------------------------------\n\nWhen you run `womm setup`, you are given four options for how to synchronize your local filesystem with the worker machines.\nThis determines how the connection between your local machine and the WOMM filesystem server happens.\nThe filesystem server serves NFS shares that each worker pod mounts in order to receive your local filesystem data.\n\n### Lazy share\n\nThis is the recommended kind. It entails the filesystem server opening a sshfs connection to your local machine.\nThis performs well if you're making lots of changes to your filesystem data between runs, if your filesystem data is very large, or if you are producing results on the filesystem.\nHowever, it will introduce some synchronization latency in changes propogating to either end, since there are multiple disjoint levels of caching happening.\nThis can lead to some unintuitive results related to event ordering:\n\n```\n[11:41:28 AM] $ womm parallel --kube-pods 1 -- ls ::: .\ndeployment.apps/womm-task-wdrwdtqk created\nsome\nfiles\ndeployment.apps \"womm-task-wdrwdtqk\" deleted\n[11:41:36 AM] $ touch asdf\n[11:41:37 AM] $ womm parallel --kube-pods 1 -- ls ::: .\ndeployment.apps/womm-task-tyzcedvv created\nsome\nfiles\ndeployment.apps \"womm-task-tyzcedvv\" deleted\n[11:41:49 AM] $ womm parallel --kube-pods 1 -- ls ::: .\ndeployment.apps/womm-task-aolsrxqr created\nasdf\nsome\nfiles\ndeployment.apps \"womm-task-aolsrxqr\" deleted\n[11:41:54 AM] $\n```\n\nI don't know of a better solution to this other than \"waiting for changes to propagate\" or \"manually run sync(1) to force flushes\".\n\n### Eager share\n\nThe eager share works by establishing a rsync connection to the filesystem server before any jobs are started and synchronizing the current directory.\nThis is obviously more robust than the lazy share approach, but creates some very complicated problems related to synchronizing changes back to your local machine, since there is now more than one source of truth for the filesystem data that must be merged offline.\n\nTo handle this, there are two kinds of eager share - no syncback, and syncback on completion.\nNo syncback will simply discard any changes which are made on the filesystem server.\nSyncback on complete will open an additional rsync connection to the filesystem server once all jobs have completed and pull any changes back to your local machine.\nThis is somewhat sketchy, as if there are any clock discrepancies between your local machine and the cluster, any changes you make to your application while it is running will be reverted when it is finished.\nWOMM attempts to mitigate this by checking that your local clock is synchronized with the remote clock before starting any tasks with this mode.\nNote that the syncback operation will never delete files from your local machine, only modify and create - this is too much of a footgun to enable.\n\nCiting GNU parallel\n-------------------\n\nIf you are using WOMM for research, you should cite GNU parallel in your text.\nGNU parallel has an mildly annoying but entirely necessary mechanism to ensure this, by printing a message to the tty until you use a specific flag to promise your citation.\nTo access it through WOMM, run:\n\n```\n$ womm parallel --citation\n```\n\nIt will ask you to type \"will cite\".\nIf you are not using WOMM for research, feel free to claim you will cite parallel anyway.\n\nLicensing\n---------\n\nFeel free to modify and distribute this program under the terms of the [zlib license](./LICENSE).\nBe careful though - you are also bound by the terms of GNU parallel, vendored in this repository, which is GPL 3.\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/rhelmot/womm",
    "keywords": "",
    "license": "zlib",
    "maintainer": "",
    "maintainer_email": "",
    "name": "womm",
    "package_url": "https://pypi.org/project/womm/",
    "platform": null,
    "project_url": "https://pypi.org/project/womm/",
    "project_urls": {
      "Homepage": "https://github.com/rhelmot/womm"
    },
    "release_url": "https://pypi.org/project/womm/0.1.6/",
    "requires_dist": [
      "psutil",
      "tabulate",
      "python-dateutil"
    ],
    "requires_python": ">=3.6",
    "summary": "Works On My Machine - quick-set glue for scaling scripts with kubernetes",
    "version": "0.1.6",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14869272,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7963332197b4abd0ec2d8cac8bb7a1ed4ab4e327a8cf379527f63de1130c7482",
          "md5": "217417974674aa1c852689ee6531a1e8",
          "sha256": "00b2206fabf17acbecde8296f3de37512498301cb869dfc664c89b5cd078b745"
        },
        "downloads": -1,
        "filename": "womm-0.1.0-py3-none-manylinux2014_x86_64.whl",
        "has_sig": false,
        "md5_digest": "217417974674aa1c852689ee6531a1e8",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 493610,
        "upload_time": "2022-06-11T12:58:01",
        "upload_time_iso_8601": "2022-06-11T12:58:01.221137Z",
        "url": "https://files.pythonhosted.org/packages/79/63/332197b4abd0ec2d8cac8bb7a1ed4ab4e327a8cf379527f63de1130c7482/womm-0.1.0-py3-none-manylinux2014_x86_64.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "53192b205413e7c72660a5b2a327602a10be65d47cd04c886e8dd58b7f23ce08",
          "md5": "ec6bfd7496154d5a011a84d6faa6f8f3",
          "sha256": "07517b7f6837ca39d148200940d356070f0ad31565daaa3c4bd501f9a5bfd0a3"
        },
        "downloads": -1,
        "filename": "womm-0.1.1-py3-none-manylinux2014_x86_64.whl",
        "has_sig": false,
        "md5_digest": "ec6bfd7496154d5a011a84d6faa6f8f3",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 491464,
        "upload_time": "2022-06-12T19:38:04",
        "upload_time_iso_8601": "2022-06-12T19:38:04.044388Z",
        "url": "https://files.pythonhosted.org/packages/53/19/2b205413e7c72660a5b2a327602a10be65d47cd04c886e8dd58b7f23ce08/womm-0.1.1-py3-none-manylinux2014_x86_64.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5ec72a49c24b9d1b85ac890f9f6307f5a6138d1df27577b7596773fd24cca7d4",
          "md5": "68ab37fcff87aa5fd999e7ef89747bef",
          "sha256": "d296d67b4f64dd5c92c5acc6e2d7428ee0950cedf72888fa99e8229086f8ce6f"
        },
        "downloads": -1,
        "filename": "womm-0.1.2-py3-none-manylinux2014_x86_64.whl",
        "has_sig": false,
        "md5_digest": "68ab37fcff87aa5fd999e7ef89747bef",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 493888,
        "upload_time": "2022-06-20T18:58:54",
        "upload_time_iso_8601": "2022-06-20T18:58:54.825869Z",
        "url": "https://files.pythonhosted.org/packages/5e/c7/2a49c24b9d1b85ac890f9f6307f5a6138d1df27577b7596773fd24cca7d4/womm-0.1.2-py3-none-manylinux2014_x86_64.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6de8651e349ad33f439add0d11ec990e31d4db998b93805ce4a4a12af869a983",
          "md5": "54c101a450a39c5b33c2174079e17e6b",
          "sha256": "8795a9df8c8dffac4d42a2d68054c704a9b49c2c0be186bd704087bc61601be9"
        },
        "downloads": -1,
        "filename": "womm-0.1.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "54c101a450a39c5b33c2174079e17e6b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 496577,
        "upload_time": "2022-06-24T00:21:17",
        "upload_time_iso_8601": "2022-06-24T00:21:17.593678Z",
        "url": "https://files.pythonhosted.org/packages/6d/e8/651e349ad33f439add0d11ec990e31d4db998b93805ce4a4a12af869a983/womm-0.1.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1e076f9fc548c682a17b169494aabab79b4611683c79396ca1cf3d35467576c2",
          "md5": "05a1d9568a876870b64746e0abd254c6",
          "sha256": "43548f77d52afc2528c8c1b87937e39e57a09e973a1a8b06702baf09b0363f4a"
        },
        "downloads": -1,
        "filename": "womm-0.1.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "05a1d9568a876870b64746e0abd254c6",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 497557,
        "upload_time": "2022-06-24T17:32:44",
        "upload_time_iso_8601": "2022-06-24T17:32:44.717415Z",
        "url": "https://files.pythonhosted.org/packages/1e/07/6f9fc548c682a17b169494aabab79b4611683c79396ca1cf3d35467576c2/womm-0.1.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c24bb733fb86689aa203687b630f4b517a79a8bc549d99a2b65c704efb943ab5",
          "md5": "420bcd2e83a3d12b7aa7dc46ac7bf5ce",
          "sha256": "3c97d0e6dfc95d928a8d32d90effbd36ce14cb95666405b265a6bd4cf73cba92"
        },
        "downloads": -1,
        "filename": "womm-0.1.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "420bcd2e83a3d12b7aa7dc46ac7bf5ce",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 498614,
        "upload_time": "2022-08-10T21:23:12",
        "upload_time_iso_8601": "2022-08-10T21:23:12.290007Z",
        "url": "https://files.pythonhosted.org/packages/c2/4b/b733fb86689aa203687b630f4b517a79a8bc549d99a2b65c704efb943ab5/womm-0.1.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6784a1a0d8556ad240b3d37fbd2e9174c71d21ab8a084be3a0aac0f07fdc0c52",
          "md5": "f1c5b89e98fb1c43061275062255409d",
          "sha256": "c0a830a180c4a50fbe791c82f3c96064f5b88fe14346c9f8021a94a1e9087086"
        },
        "downloads": -1,
        "filename": "womm-0.1.5.tar.gz",
        "has_sig": false,
        "md5_digest": "f1c5b89e98fb1c43061275062255409d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 498745,
        "upload_time": "2022-08-10T21:23:14",
        "upload_time_iso_8601": "2022-08-10T21:23:14.560892Z",
        "url": "https://files.pythonhosted.org/packages/67/84/a1a0d8556ad240b3d37fbd2e9174c71d21ab8a084be3a0aac0f07fdc0c52/womm-0.1.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "74ee50cf5c1b8f461e75b2975ed1120491f2e8542a7348d5bb1ad4245288a58d",
          "md5": "5fc547d0e216e5cdc23d6829f466910b",
          "sha256": "292c52a38b4663a41704823af808f3dfe8764696e02ba149c22d074da088879d"
        },
        "downloads": -1,
        "filename": "womm-0.1.6-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "5fc547d0e216e5cdc23d6829f466910b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 499209,
        "upload_time": "2022-08-24T18:05:18",
        "upload_time_iso_8601": "2022-08-24T18:05:18.425404Z",
        "url": "https://files.pythonhosted.org/packages/74/ee/50cf5c1b8f461e75b2975ed1120491f2e8542a7348d5bb1ad4245288a58d/womm-0.1.6-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "74ee50cf5c1b8f461e75b2975ed1120491f2e8542a7348d5bb1ad4245288a58d",
        "md5": "5fc547d0e216e5cdc23d6829f466910b",
        "sha256": "292c52a38b4663a41704823af808f3dfe8764696e02ba149c22d074da088879d"
      },
      "downloads": -1,
      "filename": "womm-0.1.6-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "5fc547d0e216e5cdc23d6829f466910b",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 499209,
      "upload_time": "2022-08-24T18:05:18",
      "upload_time_iso_8601": "2022-08-24T18:05:18.425404Z",
      "url": "https://files.pythonhosted.org/packages/74/ee/50cf5c1b8f461e75b2975ed1120491f2e8542a7348d5bb1ad4245288a58d/womm-0.1.6-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}