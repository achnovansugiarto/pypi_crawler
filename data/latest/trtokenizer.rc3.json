{
  "info": {
    "author": "Apdullah YAYIK",
    "author_email": "apdullahyayik@gmail.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# TrTokenizer ðŸ‡¹ðŸ‡·\n\n[![Python](https://img.shields.io/pypi/pyversions/tensorflow.svg?style=plastic)](https://badge.fury.io/py/trtokenizer)\n[![PyPI](https://badge.fury.io/py/tensorflow.svg)](https://badge.fury.io/py/trtokenizer)\n\nTrTokenizer is a complete solution for Turkish sentence and word tokenization with extensively-covering language\nconventions. If you think that Natural language models always need robust, fast, and accurate tokenizers, be sure that you are at the\nthe right place now. Sentence tokenization approach uses non-prefix keyword given in 'tr_non_suffixes' file. This file can be expanded if\nrequired, for developer convenience lines start with # symbol are evaluated as comments.\nDesigned regular expressions are pre-compiled to speed-up the performance.\n\n## Install\n\n```sh\npip install trtokenizer\n```\n\n## Usage\n\n```sh\nfrom trtokenizer.tr_tokenizer import SentenceTokenizer, WordTokenizer\n\nsentence_tokenizer_object = SentenceTokenizer()  # during object creation regexes are compiled only at once\n\nsentence_tokenizer_object.tokenize(<given paragraph as string>)\n\nword_tokenizer_object = WordTokenizer()  # # during object creation regexes are compiled only at once\n\nword_tokenizer_object.tokenize(<given sentence as string>)\n\n```\n\n## To-do\n\n- Usage examples (Done)\n- Cython C-API for performance (Done, build/tr_tokenizer.c)\n- Release platform specific shared dynamic libraries (Done, build/tr_tokenizer.cpython-38-x86_64-linux-gnu.so, only for\n  Debian Linux with gcc compiler)\n- Limitations\n- Prepare a simple guide for contribution\n\n## Resources\n\n* [Speech and Language Processing](https://web.stanford.edu/~jurafsky/slp3/)\n* [Bogazici University CMPE-561](https://www.cmpe.boun.edu.tr/tr/courses/cmpe561)\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "https://github.com/apdullahyayik/TrTokenizer/archive/refs/tags/0.0.3.tar.gz",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/apdullahyayik/TrTokenizer",
    "keywords": "sentence tokenizer,word tokenizer,Turkish language,natural language processing",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "trtokenizer",
    "package_url": "https://pypi.org/project/trtokenizer/",
    "platform": "",
    "project_url": "https://pypi.org/project/trtokenizer/",
    "project_urls": {
      "Download": "https://github.com/apdullahyayik/TrTokenizer/archive/refs/tags/0.0.3.tar.gz",
      "Homepage": "https://github.com/apdullahyayik/TrTokenizer"
    },
    "release_url": "https://pypi.org/project/trtokenizer/0.0.3/",
    "requires_dist": [
      "regex"
    ],
    "requires_python": ">=3.4",
    "summary": "Sentence and word tokenizers for the Turkish language",
    "version": "0.0.3",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 11261931,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c98fa9c62109d9260cee37687371435168194007122ce363d8e27d5ce82c1822",
          "md5": "7a9f7c3e7dcd72f947ee92d075c21ac3",
          "sha256": "82091dba88bc37a6b96ee53f7eff1229b691b3a911ed98112646434eb9299f84"
        },
        "downloads": -1,
        "filename": "trtokenizer-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "7a9f7c3e7dcd72f947ee92d075c21ac3",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.4",
        "size": 5467,
        "upload_time": "2021-01-01T21:14:58",
        "upload_time_iso_8601": "2021-01-01T21:14:58.862754Z",
        "url": "https://files.pythonhosted.org/packages/c9/8f/a9c62109d9260cee37687371435168194007122ce363d8e27d5ce82c1822/trtokenizer-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "21e9a41b987eaea2935ece915122ad166bdc078d9bf4b011695cd1ca93a558ad",
          "md5": "93459f1d258912a2168157acbfcbc743",
          "sha256": "16d9dfc27707686d071ee8d56d1cb352a101603e640bf2950dfc63cb683ace3c"
        },
        "downloads": -1,
        "filename": "trtokenizer-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "93459f1d258912a2168157acbfcbc743",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.4",
        "size": 5872,
        "upload_time": "2021-03-13T05:33:18",
        "upload_time_iso_8601": "2021-03-13T05:33:18.088490Z",
        "url": "https://files.pythonhosted.org/packages/21/e9/a41b987eaea2935ece915122ad166bdc078d9bf4b011695cd1ca93a558ad/trtokenizer-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f1fae3df3c1523ff16a69b10a0e5bda08d9321bd459966bc4cff8ef624166136",
          "md5": "e7a447d8dba2227dacbecbd1d592199e",
          "sha256": "8afab11883ad97f5f8b91d994c2c0c8e8044980e09f6a6ba1cfb6a4fa0528027"
        },
        "downloads": -1,
        "filename": "trtokenizer-0.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "e7a447d8dba2227dacbecbd1d592199e",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.4",
        "size": 7662,
        "upload_time": "2021-08-24T12:21:42",
        "upload_time_iso_8601": "2021-08-24T12:21:42.736268Z",
        "url": "https://files.pythonhosted.org/packages/f1/fa/e3df3c1523ff16a69b10a0e5bda08d9321bd459966bc4cff8ef624166136/trtokenizer-0.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f5bb38488f537662d0e25b7a77c529bebb87e8f43336730b391ad2c71ca00283",
          "md5": "ef73b08f4c7aea1e570f5eb55638b096",
          "sha256": "8100eca1c1c4dcfdd2ec13aef6606c6a4f54d9e9318107bd5cf31d3642ed66fd"
        },
        "downloads": -1,
        "filename": "trtokenizer-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "ef73b08f4c7aea1e570f5eb55638b096",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.4",
        "size": 6676,
        "upload_time": "2021-08-24T12:21:44",
        "upload_time_iso_8601": "2021-08-24T12:21:44.631367Z",
        "url": "https://files.pythonhosted.org/packages/f5/bb/38488f537662d0e25b7a77c529bebb87e8f43336730b391ad2c71ca00283/trtokenizer-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "f1fae3df3c1523ff16a69b10a0e5bda08d9321bd459966bc4cff8ef624166136",
        "md5": "e7a447d8dba2227dacbecbd1d592199e",
        "sha256": "8afab11883ad97f5f8b91d994c2c0c8e8044980e09f6a6ba1cfb6a4fa0528027"
      },
      "downloads": -1,
      "filename": "trtokenizer-0.0.3-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "e7a447d8dba2227dacbecbd1d592199e",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.4",
      "size": 7662,
      "upload_time": "2021-08-24T12:21:42",
      "upload_time_iso_8601": "2021-08-24T12:21:42.736268Z",
      "url": "https://files.pythonhosted.org/packages/f1/fa/e3df3c1523ff16a69b10a0e5bda08d9321bd459966bc4cff8ef624166136/trtokenizer-0.0.3-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "f5bb38488f537662d0e25b7a77c529bebb87e8f43336730b391ad2c71ca00283",
        "md5": "ef73b08f4c7aea1e570f5eb55638b096",
        "sha256": "8100eca1c1c4dcfdd2ec13aef6606c6a4f54d9e9318107bd5cf31d3642ed66fd"
      },
      "downloads": -1,
      "filename": "trtokenizer-0.0.3.tar.gz",
      "has_sig": false,
      "md5_digest": "ef73b08f4c7aea1e570f5eb55638b096",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.4",
      "size": 6676,
      "upload_time": "2021-08-24T12:21:44",
      "upload_time_iso_8601": "2021-08-24T12:21:44.631367Z",
      "url": "https://files.pythonhosted.org/packages/f5/bb/38488f537662d0e25b7a77c529bebb87e8f43336730b391ad2c71ca00283/trtokenizer-0.0.3.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}