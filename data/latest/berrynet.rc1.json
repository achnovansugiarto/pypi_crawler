{
  "info": {
    "author": "DT42 Inc.",
    "author_email": "berrynet@dt42.io",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: GNU General Public License v3 (GPLv3)",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.4",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Topic :: Scientific/Engineering :: Artificial Intelligence"
    ],
    "description": "<p align=\"center\"><a href=\"http://berrynet.org\" target=\"_blank\" rel=\"noopener noreferrer\"><img width=\"50%\" src=\"https://user-images.githubusercontent.com/292790/33802809-e4726cf8-dd45-11e7-8a64-fdc4c3ff9310.png\" alt=\"BerryNet Logo\"></a></p>\n<h2  align=\"center\">Deep Learning Gateway on Raspberry Pi And Other Edge Devices</h2>\n\n![Docker Image CI](https://github.com/DT42/BerryNet/workflows/Docker%20Image%20CI/badge.svg)\n\n[Supporting BerryNet](https://github.com/DT42/BerryNet/wiki/Donation)\n\n* [Become a backer or sponsor on Open Collective](https://opencollective.com/berrynet).\n* [One-time donation via PayPal or crypto-currencies](https://github.com/DT42/BerryNet/wiki/Donation#one-time-donations).\n\n# Introduction\n\nThis project turns edge devices such as Raspberry Pi into an intelligent gateway with deep learning running on it. No internet connection is required, everything is done locally on the edge device itself. Further, multiple edge devices can create a distributed AIoT network.\n\nAt DT42, we believe that bringing deep learning to edge devices is the trend towards the future. It not only saves costs of data transmission and storage but also makes devices able to respond according to the events shown in the images or videos without connecting to the cloud.\n\n![Figure 1](https://user-images.githubusercontent.com/292790/45943626-a3d28b80-c019-11e8-829c-5eb6afd3faa4.png)\n\n<p align=\"center\">Figure 1: BerryNet architecture</p>\n\nFigure 1 shows the software architecture of the project, we use Node.js/Python, MQTT and an AI engine to analyze images or video frames with deep learning. So far, there are two default types of AI engines, the classification engine (with Inception v3 [[1]](https://arxiv.org/pdf/1512.00567.pdf) model) and the object detection engine (with TinyYOLO [[2]](https://pjreddie.com/media/files/papers/YOLO9000.pdf) model or MobileNet SSD [[3]](https://arxiv.org/pdf/1704.04861.pdf) model). Figure 2 shows the differences between classification and object detection.\n\n![Figure 2](https://cloud.githubusercontent.com/assets/292790/25520013/d9497738-2c2c-11e7-9693-3840647f2e1e.jpg)\n\n<p align=\"center\">Figure 2: Classification vs detection</p>\n\nOne of the application of this intelligent gateway is to use the camera to monitor the place you care about. For example, Figure 3 shows the analyzed results from the camera hosted in the DT42 office. The frames were captured by the IP camera and they were submitted into the AI engine. The output from the AI engine will be shown in the dashboard. We are working on the Email and IM notification so you can get a notification when there is a dog coming into the meeting area with the next release.\n\n![Figure 3](https://cloud.githubusercontent.com/assets/292790/25498294/0ab79976-2bba-11e7-9114-46e328d15a18.gif)\n\n<p align=\"center\">Figure 3: Object detection result example</p>\n\nTo bring easy and flexible edge AI experience to user, we keep expending support of the AI engines and the reference HWs.\n\n![Figure 4](https://user-images.githubusercontent.com/292790/64026655-c2b69780-cb71-11e9-90b9-6269319012f1.png)\n\n<p align=\"center\">Figure 4: Reference hardwares</p>\n\n\n# Installation\n\nYou can install BerryNet by using pre-built image or from source. Please refer to the [Wiki page](https://github.com/DT42/BerryNet/wiki/Installation) for the details. \n\nWe are pushing BerryNet into Debian repository, so you will be able to install by only typing one command in the future.\n\nHere is the quick steps to install from source:\n\n```\n$ git clone https://github.com/DT42/BerryNet.git\n$ cd BerryNet\n$ ./configure\n```\n\n\n# Start and Stop BerryNet\n\nBerryNet performs an AIoT application by connecting independent components together. Component types include but not limited to AI engine, I/O processor, data processor (algorithm), or data collector.\n\nWe recommend to manage BerryNet componetns by [supervisor](http://supervisord.org/), but you can also run BerryNet components manually. You can manage BerryNet via `supervisorctl`:\n\n```\n# Check status of BerryNet components\n$ sudo supervisorctl status all\n\n# Stop Camera client\n$ sudo supervisorctl stop camera\n\n# Restart all components\n$ sudo supervisorctl restart all\n\n# Show last stderr logs of camera client\n$ sudo supervisorctl tail camera stderr\n```\n\nFor more possibilities of supervisorctl, please refer to the [official tutorial](http://supervisord.org/running.html#running-supervisorctl).\n\nThe default application has three components:\n\n* Camera client to provide input images\n* Object detection engine to find type and position of the detected objects in an image\n* Dashboard to display the detection results\n\nYou will learn how to configure or change the components in the [Configuration](#configuration) section.\n\n\n# Dashboard: Freeboard\n\n## Open Freeboard on RPi (with touch screen)\n\nFreeboard is a web-based dashboard. Here are the steps to show the detection result iamge and text on Freeboard:\n\n* 1: Enter `http://127.0.0.1:8080` in browser's URL bar, and press enter\n* 2: [Download](https://raw.githubusercontent.com/DT42/BerryNet/master/config/dashboard-tflitedetector.json) the Freeboard configuration for default application, `dashboard-tflitedetector.json`\n* 2: Click `LOAD FREEBOARD`, and select the newly downloaded `dashboard-tflitedetector.json`\n* 3: Wait for seconds, you should see the inference result image and text on Freeboard\n\n## Open Freeboard on another computer\n\nAssuming that you have two devices:\n\n* Device A with IP `192.168.1.42`, BerryNet default application runs on it\n* Device B with IP `192.168.1.43`, you want to open Freeboard and see the detection result on it\n\nHere are the steps:\n\n* 1: Enter `http://192.168.1.42:8080` in browser's URL bar, and press enter\n* 2: [Download](https://raw.githubusercontent.com/DT42/BerryNet/master/config/dashboard-tflitedetector.json) the Freeboard configuration for default application, `dashboard-tflitedetector.json`\n* 3: Replace all the `localhost` to `192.168.1.42` in `dashboard-tflitedetector.json`\n* 2: Click `LOAD FREEBOARD`, and select the newly downloaded `dashboard-tflitedetector.json`\n* 3: Wait for seconds, you should see the inference result image and text on Freeboard\n\nFor more details about dashboard configuration (e.g. how to add widgets), please refer to [Freeboard project](https://github.com/Freeboard/freeboard).\n\n\n# Enable Data Collector\n\nYou might want to store the snapshot and inference results for data analysis.\n\nTo run BerryNet data collector manually, you can run the command below:\n\n```\n$ bn_data_collector --topic-config <topic-config-filepath> --data-dirpath <result-dirpath>\n```\n\nThe topic config indicates what MQTT topic the data collector will listen, and what handler will be triggered. Here is a topic config exmaple:\n\n```\n{\n    \"berrynet/engine/tflitedetector/result\": \"self.update\"\n}\n```\n\nThe inference result image and text will be saved into the indicated result directory.\n\n\n# Configuration\n\nThe default supervisor config is at `/etc/supervisor/conf.d/berrynet-tflite.conf`. To write your own supervisor config, you can refer to [here](https://github.com/DT42/BerryNet/tree/master/config/supervisor/conf.d) for more example supervisor configs of BerryNet\n\n## Camera Client\n\nBerryNet camera client can run in two modes: stream or file. In stream mode, local camera (e.g. USB camera and RPi camera) and IP camera can be supported, and input frame rate (FPS) can be changed on demand (default is 1). In file mode, user can indicate filepath as input source.\n\nTo run camera client in stream mode:\n\n```\n$ bn_camera --fps 5\n```\n\nTo run camera client in file mode:\n\n```\n$ bn_camera --mode file --filepath <image-filepath>\n```\n\n\n# Use Your Data To Train\n\nThe original instruction of retraining YOLOv2 model see [github repository of darknet](https://github.com/AlexeyAB/darknet#how-to-train-to-detect-your-custom-objects)\n\nIn the current of BerryNet, TinyYolo is used instead of YOLOv2. \nThe major differences are:\n\n1. Create file yolo-obj.cfg with the same content as in `tiny-yolo.cfg`\n2. Download pre-trained weights of darknet reference model, `darknet.weights.12`, for the convolutional layers (6.1MB)\nhttps://drive.google.com/drive/folders/0B-oZJEwmkAObMzAtc2QzZDhyVGM?usp=sharing\n\nThe rest parts are the same as retraining YOLO.\n\nIf you use [LabelMe](http://labelme.csail.mit.edu/Release3.0/) to annotate data, `utils/xmlTotxt.py` can help convert the xml format to the text format that darknet uses.\n\n\n# Discussion\n\nPlease refer to the [Slack](https://join.slack.com/t/berrynet/shared_invite/enQtODg5MjA0ODExMjUzLWIwMDNkZWExZGE2Njc1ZDljMmFiOWJlZDdmZmEwYmQ4YTJiNzg2NDc1NTJhMDVkMzhmNzA3YTU0ZTc4M2JiNTE), [Telegram Group](https://t.me/berrynetdev) or [Google Group](https://groups.google.com/a/dt42.io/d/forum/berrynet) for questions, suggestions, or any idea discussion.\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/DT42/BerryNet",
    "keywords": "wheels",
    "license": "GPLv3",
    "maintainer": "",
    "maintainer_email": "",
    "name": "berrynet",
    "package_url": "https://pypi.org/project/berrynet/",
    "platform": "",
    "project_url": "https://pypi.org/project/berrynet/",
    "project_urls": {
      "Homepage": "https://github.com/DT42/BerryNet"
    },
    "release_url": "https://pypi.org/project/berrynet/3.10.1/",
    "requires_dist": [
      "PyOpenGL",
      "PyOpenGL-accelerate",
      "logzero",
      "paho-mqtt"
    ],
    "requires_python": ">=3",
    "summary": "Deep learning gateway on Raspberry Pi and other edge devices.",
    "version": "3.10.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8551852,
  "releases": {
    "3.10.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cc6571995017598d45e5e014d1ce270fd12de579d51809d0c8fe3060e3e6a1d4",
          "md5": "d3f4ccbc4561529a73b7a442348096d1",
          "sha256": "f5c286be7f5f12584bd93e0cacf6ee7a79fe72e370b899d1b6838d416d366f58"
        },
        "downloads": -1,
        "filename": "berrynet-3.10.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d3f4ccbc4561529a73b7a442348096d1",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3",
        "size": 97528,
        "upload_time": "2020-11-01T04:00:11",
        "upload_time_iso_8601": "2020-11-01T04:00:11.801707Z",
        "url": "https://files.pythonhosted.org/packages/cc/65/71995017598d45e5e014d1ce270fd12de579d51809d0c8fe3060e3e6a1d4/berrynet-3.10.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8a7ed9b7889c52549b21ca9b9f3329e2417f9527b72dcd7e30e6ca5c5cc56e3f",
          "md5": "8a2929e4f89f6c386cb90fd6aad2ea5b",
          "sha256": "bb4cfabecd3378ae26346b17bcac4858d3ff5315506a512829da85db42dfac61"
        },
        "downloads": -1,
        "filename": "berrynet-3.10.1.tar.gz",
        "has_sig": false,
        "md5_digest": "8a2929e4f89f6c386cb90fd6aad2ea5b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3",
        "size": 48542,
        "upload_time": "2020-11-01T04:00:14",
        "upload_time_iso_8601": "2020-11-01T04:00:14.901367Z",
        "url": "https://files.pythonhosted.org/packages/8a/7e/d9b7889c52549b21ca9b9f3329e2417f9527b72dcd7e30e6ca5c5cc56e3f/berrynet-3.10.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "cc6571995017598d45e5e014d1ce270fd12de579d51809d0c8fe3060e3e6a1d4",
        "md5": "d3f4ccbc4561529a73b7a442348096d1",
        "sha256": "f5c286be7f5f12584bd93e0cacf6ee7a79fe72e370b899d1b6838d416d366f58"
      },
      "downloads": -1,
      "filename": "berrynet-3.10.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "d3f4ccbc4561529a73b7a442348096d1",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3",
      "size": 97528,
      "upload_time": "2020-11-01T04:00:11",
      "upload_time_iso_8601": "2020-11-01T04:00:11.801707Z",
      "url": "https://files.pythonhosted.org/packages/cc/65/71995017598d45e5e014d1ce270fd12de579d51809d0c8fe3060e3e6a1d4/berrynet-3.10.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "8a7ed9b7889c52549b21ca9b9f3329e2417f9527b72dcd7e30e6ca5c5cc56e3f",
        "md5": "8a2929e4f89f6c386cb90fd6aad2ea5b",
        "sha256": "bb4cfabecd3378ae26346b17bcac4858d3ff5315506a512829da85db42dfac61"
      },
      "downloads": -1,
      "filename": "berrynet-3.10.1.tar.gz",
      "has_sig": false,
      "md5_digest": "8a2929e4f89f6c386cb90fd6aad2ea5b",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3",
      "size": 48542,
      "upload_time": "2020-11-01T04:00:14",
      "upload_time_iso_8601": "2020-11-01T04:00:14.901367Z",
      "url": "https://files.pythonhosted.org/packages/8a/7e/d9b7889c52549b21ca9b9f3329e2417f9527b72dcd7e30e6ca5c5cc56e3f/berrynet-3.10.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}