{
  "info": {
    "author": "Giuseppe Attardi",
    "author_email": "attardi@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: GNU Affero General Public License v3 or later (AGPLv3+)",
      "Programming Language :: Python :: 3",
      "Topic :: Text Processing :: Linguistic"
    ],
    "description": "# WikiExtractor\n[WikiExtractor.py](http://medialab.di.unipi.it/wiki/Wikipedia_Extractor) is a Python script that extracts and cleans text from a [Wikipedia database backup dump](https://dumps.wikimedia.org/), e.g. https://dumps.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2 for English.\n\nThe tool is written in Python and requires Python 3 but no additional library.\n**Warning**: problems have been reported on Windows due to poor support for `StringIO` in the Python implementation on Windows.\n\nFor further information, see the [Wiki](https://github.com/attardi/wikiextractor/wiki).\n\n# Wikipedia Cirrus Extractor\n\n`cirrus-extractor.py` is a version of the script that performs extraction from a Wikipedia Cirrus dump.\nCirrus dumps contain text with already expanded templates.\n\nCirrus dumps are available at:\n[cirrussearch](http://dumps.wikimedia.org/other/cirrussearch/).\n\n# Details\n\nWikiExtractor performs template expansion by preprocessing the whole dump and extracting template definitions.\n\nIn order to speed up processing:\n\n- multiprocessing is used for dealing with articles in parallel\n- a cache is kept of parsed templates (only useful for repeated extractions).\n\n## Installation\n\nThe script may be invoked directly:\n\n    python -m wikiextractor.WikiExtractor <Wikipedia dump file>\n\nIt can also be installed from `PyPi` by doing:\n\n    pip install wikiextractor\n\nor locally with:\n\n    (sudo) python setup.py install\n\nThe installer also installs two scripts for direct invocation:\n\n    wikiextractor  \t(equivalent to python -m wikiextractor.WikiExtractor)\n    extractPage\t\t(to extract a single page from a dump)\n\n## Usage\n\n### Wikiextractor\nThe script is invoked with a Wikipedia dump file as an argument:\n\n    python -m wikiextractor.WikiExtractor <Wikipedia dump file> [--templates <extracted template file>]\n\nThe option `--templates` extracts the templates to a local file, which can be reloaded to reduce the time to perform extraction.\n\nThe output is stored in several files of similar size in a given directory.\nEach file will contains several documents in this [document format](https://github.com/attardi/wikiextractor/wiki/File-Format).\n\n```\nusage: wikiextractor [-h] [-o OUTPUT] [-b n[KMG]] [-c] [--json] [--html] [-l] [-ns ns1,ns2]\n\t\t\t [--templates TEMPLATES] [--no-templates] [--html-safe HTML_SAFE] [--processes PROCESSES]\n\t\t\t [-q] [--debug] [-a] [-v]\n\t\t\t input\n\nWikipedia Extractor:\nExtracts and cleans text from a Wikipedia database dump and stores output in a\nnumber of files of similar size in a given directory.\nEach file will contain several documents in the format:\n\n\t<doc id=\"\" url=\"\" title=\"\">\n\t    ...\n\t    </doc>\n\nIf the program is invoked with the --json flag, then each file will                                            \ncontain several documents formatted as json ojects, one per line, with                                         \nthe following structure\n\n\t{\"id\": \"\", \"revid\": \"\", \"url\": \"\", \"title\": \"\", \"text\": \"...\"}\n\nThe program performs template expansion by preprocesssng the whole dump and\ncollecting template definitions.\n\npositional arguments:\n  input                 XML wiki dump file\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --processes PROCESSES\n\t\t\t    Number of processes to use (default 79)\n\nOutput:\n  -o OUTPUT, --output OUTPUT\n\t\t\t    directory for extracted files (or '-' for dumping to stdout)\n  -b n[KMG], --bytes n[KMG]\n\t\t\t    maximum bytes per output file (default 1M)\n  -c, --compress        compress output files using bzip\n  --json                write output in json format instead of the default <doc> format\n\nProcessing:\n  --html                produce HTML output, subsumes --links\n  -l, --links           preserve links\n  -ns ns1,ns2, --namespaces ns1,ns2\n\t\t\t    accepted namespaces\n  --templates TEMPLATES\n\t\t\t    use or create file containing templates\n  --no-templates        Do not expand templates\n  --html-safe HTML_SAFE\n\t\t\t    use to produce HTML safe output within <doc>...</doc>\n\nSpecial:\n  -q, --quiet           suppress reporting progress info\n  --debug               print debug info\n  -a, --article         analyze a file containing a single article (debug option)\n  -v, --version         print program version\n```\n\nSaving templates to a file will speed up performing extraction the next time,\nassuming template definitions have not changed.\n\nOption `--no-templates` significantly speeds up the extractor, avoiding the cost\nof expanding [MediaWiki templates](https://www.mediawiki.org/wiki/Help:Templates).\n\nFor further information, visit [the documentation](http://attardi.github.io/wikiextractor).\n\n### Cirrus Extractor\n\n~~~\nusage: cirrus-extract.py [-h] [-o OUTPUT] [-b n[KMG]] [-c] [-ns ns1,ns2] [-q]\n                         [-v]\n                         input\n\nWikipedia Cirrus Extractor:\nExtracts and cleans text from a Wikipedia Cirrus dump and stores output in a\nnumber of files of similar size in a given directory.\nEach file will contain several documents in the format:\n\n\t<doc id=\"\" url=\"\" title=\"\" language=\"\" revision=\"\">\n        ...\n        </doc>\n\npositional arguments:\n  input                 Cirrus Json wiki dump file\n\noptional arguments:\n  -h, --help            show this help message and exit\n\nOutput:\n  -o OUTPUT, --output OUTPUT\n                        directory for extracted files (or '-' for dumping to\n                        stdin)\n  -b n[KMG], --bytes n[KMG]\n                        maximum bytes per output file (default 1M)\n  -c, --compress        compress output files using bzip\n\nProcessing:\n  -ns ns1,ns2, --namespaces ns1,ns2\n                        accepted namespaces\n\nSpecial:\n  -q, --quiet           suppress reporting progress info\n  -v, --version         print program version\n~~~\n\n### extractPage\nExtract a single page from a Wikipedia dump file.\n\n~~~\nusage: extractPage [-h] [--id ID] [--template] [-v] input\n\nWikipedia Page Extractor:\nExtracts a single page from a Wikipedia dump file.\n\npositional arguments:\n  input          XML wiki dump file\n\noptional arguments:\n  -h, --help     show this help message and exit\n  --id ID        article number\n  --template     template number\n  -v, --version  print program version\n~~~\n\n## License\nThe code is made available under the [GNU Affero General Public License v3.0](LICENSE). \n\n## Reference\nIf you find this code useful, please refer it in publications as:\n\n~~~\n@misc{Wikiextractor2015,\n  author = {Giusepppe Attardi},\n  title = {WikiExtractor},\n  year = {2015},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {\\url{https://github.com/attardi/wikiextractor}}\n}\n~~~\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/attardi/wikiextractor",
    "keywords": "",
    "license": "GNU Affero General Public License",
    "maintainer": "",
    "maintainer_email": "",
    "name": "wikiextractor",
    "package_url": "https://pypi.org/project/wikiextractor/",
    "platform": "",
    "project_url": "https://pypi.org/project/wikiextractor/",
    "project_urls": {
      "Homepage": "https://github.com/attardi/wikiextractor"
    },
    "release_url": "https://pypi.org/project/wikiextractor/3.0.6/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "A tool for extracting plain text from Wikipedia dumps",
    "version": "3.0.6",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 11724122,
  "releases": {
    "0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6fdf3cc30c29319b85b935971df4bea169616a84e5dcc68b729fc9757a8e39e9",
          "md5": "4a3c018a963404efa9025b779134927c",
          "sha256": "b8c0389fb27d42f55ccf0c28f5da2217a90d2e3b67be4afa4bbd2a958f629102"
        },
        "downloads": -1,
        "filename": "wikiextractor-0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "4a3c018a963404efa9025b779134927c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 36843,
        "upload_time": "2019-07-09T11:14:11",
        "upload_time_iso_8601": "2019-07-09T11:14:11.924037Z",
        "url": "https://files.pythonhosted.org/packages/6f/df/3cc30c29319b85b935971df4bea169616a84e5dcc68b729fc9757a8e39e9/wikiextractor-0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "3.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6c918ed80b51efce9fd4b158595b0a6e14d944928dad8f0b0ead8d39d6cee1e3",
          "md5": "5eb7fb270683f4aca14985d4e2d786f6",
          "sha256": "77c0aeaec745daf16ceab6dc6cb41eb55af7793a719e980a0f9f0db05aa6303c"
        },
        "downloads": -1,
        "filename": "wikiextractor-3.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "5eb7fb270683f4aca14985d4e2d786f6",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 46207,
        "upload_time": "2020-11-27T16:08:38",
        "upload_time_iso_8601": "2020-11-27T16:08:38.059281Z",
        "url": "https://files.pythonhosted.org/packages/6c/91/8ed80b51efce9fd4b158595b0a6e14d944928dad8f0b0ead8d39d6cee1e3/wikiextractor-3.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "aef97fef9a61977ac20b25858b3dc2a3cb404a390cb5be9231ed0d588f0b0503",
          "md5": "921caad9013178685cfab2e9a1dab26b",
          "sha256": "67092f9cf1735a8d38c9880aac8c4f55de8ef0f12fca6aff0fb47219bac137b3"
        },
        "downloads": -1,
        "filename": "wikiextractor-3.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "921caad9013178685cfab2e9a1dab26b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 32629,
        "upload_time": "2020-11-27T16:08:38",
        "upload_time_iso_8601": "2020-11-27T16:08:38.923032Z",
        "url": "https://files.pythonhosted.org/packages/ae/f9/7fef9a61977ac20b25858b3dc2a3cb404a390cb5be9231ed0d588f0b0503/wikiextractor-3.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "3.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0cbd6b8ffc89fa4abefd801f7b0f83bc17382664484bd32eb6529b243d7a8f12",
          "md5": "bcc0cc1ffec466c6ced7e44dc52a6949",
          "sha256": "a6b5905eabae49aaa9a2f55726410f655103bdc6119d73b2b95fd36fb783cf23"
        },
        "downloads": -1,
        "filename": "wikiextractor-3.0.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "bcc0cc1ffec466c6ced7e44dc52a6949",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 46388,
        "upload_time": "2020-12-05T19:18:56",
        "upload_time_iso_8601": "2020-12-05T19:18:56.282580Z",
        "url": "https://files.pythonhosted.org/packages/0c/bd/6b8ffc89fa4abefd801f7b0f83bc17382664484bd32eb6529b243d7a8f12/wikiextractor-3.0.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e6811df8cffb3efeb49d657a89e1106d5ee5b29f5bf84ef07e01a37c6da0b9c2",
          "md5": "65abd000946099a5251f8a9695608ca2",
          "sha256": "cd91e892afd91a63ef27b41a2a3135a94622d6645e2375e0438d0c95cc4216c1"
        },
        "downloads": -1,
        "filename": "wikiextractor-3.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "65abd000946099a5251f8a9695608ca2",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 32998,
        "upload_time": "2020-12-05T19:18:57",
        "upload_time_iso_8601": "2020-12-05T19:18:57.076657Z",
        "url": "https://files.pythonhosted.org/packages/e6/81/1df8cffb3efeb49d657a89e1106d5ee5b29f5bf84ef07e01a37c6da0b9c2/wikiextractor-3.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "3.0.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3f37b110fd8a87bab4120ff55061c508361bd1b012d789ff469af8fbd7cc3a38",
          "md5": "d7ec1ae3849996898c4202331ff9bd1c",
          "sha256": "f4506990bf9c14e3cc92dc85a0a89554fef975cc1b28dcb9a4d31c73a8ef2133"
        },
        "downloads": -1,
        "filename": "wikiextractor-3.0.6-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d7ec1ae3849996898c4202331ff9bd1c",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 46403,
        "upload_time": "2021-10-14T12:34:58",
        "upload_time_iso_8601": "2021-10-14T12:34:58.836880Z",
        "url": "https://files.pythonhosted.org/packages/3f/37/b110fd8a87bab4120ff55061c508361bd1b012d789ff469af8fbd7cc3a38/wikiextractor-3.0.6-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8e6c21050e72c7e42f606689b1a4cbfbbf65c81e79addc69a9451de450e2c672",
          "md5": "c8a986cfd99d8dcee239f0acfa818b73",
          "sha256": "7041ff57884c16409e9b911ccd0106c218b88cbceabb86dd1443637afa8284de"
        },
        "downloads": -1,
        "filename": "wikiextractor-3.0.6.tar.gz",
        "has_sig": false,
        "md5_digest": "c8a986cfd99d8dcee239f0acfa818b73",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 43279,
        "upload_time": "2021-10-14T12:35:00",
        "upload_time_iso_8601": "2021-10-14T12:35:00.888887Z",
        "url": "https://files.pythonhosted.org/packages/8e/6c/21050e72c7e42f606689b1a4cbfbbf65c81e79addc69a9451de450e2c672/wikiextractor-3.0.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "3f37b110fd8a87bab4120ff55061c508361bd1b012d789ff469af8fbd7cc3a38",
        "md5": "d7ec1ae3849996898c4202331ff9bd1c",
        "sha256": "f4506990bf9c14e3cc92dc85a0a89554fef975cc1b28dcb9a4d31c73a8ef2133"
      },
      "downloads": -1,
      "filename": "wikiextractor-3.0.6-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "d7ec1ae3849996898c4202331ff9bd1c",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 46403,
      "upload_time": "2021-10-14T12:34:58",
      "upload_time_iso_8601": "2021-10-14T12:34:58.836880Z",
      "url": "https://files.pythonhosted.org/packages/3f/37/b110fd8a87bab4120ff55061c508361bd1b012d789ff469af8fbd7cc3a38/wikiextractor-3.0.6-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "8e6c21050e72c7e42f606689b1a4cbfbbf65c81e79addc69a9451de450e2c672",
        "md5": "c8a986cfd99d8dcee239f0acfa818b73",
        "sha256": "7041ff57884c16409e9b911ccd0106c218b88cbceabb86dd1443637afa8284de"
      },
      "downloads": -1,
      "filename": "wikiextractor-3.0.6.tar.gz",
      "has_sig": false,
      "md5_digest": "c8a986cfd99d8dcee239f0acfa818b73",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 43279,
      "upload_time": "2021-10-14T12:35:00",
      "upload_time_iso_8601": "2021-10-14T12:35:00.888887Z",
      "url": "https://files.pythonhosted.org/packages/8e/6c/21050e72c7e42f606689b1a4cbfbbf65c81e79addc69a9451de450e2c672/wikiextractor-3.0.6.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}