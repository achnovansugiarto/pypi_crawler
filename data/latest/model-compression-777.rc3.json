{
  "info": {
    "author": "Richard Yan",
    "author_email": "yrh@berkeley.edu",
    "bugtrack_url": null,
    "classifiers": [
      "License :: Other/Proprietary License",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9"
    ],
    "description": "# Pytorch Sparse Model Compression\n\nThis package provides several functions related to sparse weight compression and size evaluation for pytorch models.\n\n## Installation\n`pip install model-compression-777 -i https://pypi.org/simple`\n\n## Usage\nImportant note: to use this, you must first prune your model, for which the methods vary from model to model. Model compression is only efficient if the weights are very sparse.\n\nAll functions contain docstrings. They are listed here for convenience (along with some *notes*).\n\n### Model Loading\n\n#### load_pruned(path):\n\nload a pruned pytorch state file by applying weight mask.\nreturns a dict where the keys are the array names (e.g. encoder.0.2.bias)\n\n#### load_unpruned(path):\n\n*loads pytorch state file into a dict.*\n\n### Compression / Decompression\n\n#### to_relative_csr(m, index_bits):\n\nconverts m into the column-relative CSR format.\nm must be a 1D or 2D NUMPY array; use .numpy() on pytorch tensors first.\nindex_bits is the bit width of relative column spacing; try around 2~8.\nreturns (nonzero values (v), column offsets (c), row indices (r)).\n\n#### from_relative_csr(v, c, r, width):\n\nutility function that converts CSR format back into normal format.\nthe purpose of this function is mostly for testing;\nnote that using this for sparse matrix operations can be very inefficient.\n\n#### compress(vec, data_bits=4, fc_idx_bits=4, conv_idx_bits=5, def_idx_bits=4, row_bits=32):\ncompresses common weights.\nfor convolution, when kernel is size 1, it is seen as a fully-connected layer.\nreturns a tuple containing compressed format and size of the compressed weight in bytes.\n\n### Model Size Evaluation\n\n#### get_csr_size_in_bytes(v, c, r, v_width, c_width, r_width):\n\n*returns sum of array sizes, where each array element corresponds to the size input (x_width) in bits*\n\n#### print_weight_info(weights_normalized):\nprints some info about a weights dict. for each weight matrix, this prints its min,\nmax, total number of elements, and sparsity.\nreturns global sparsity.\n\n## Example\n\nFirst, we load the weights dictionary from a state file.\n\n```python\nweights = load_pruned(\"outputs/exp_dset=verso_ssd,prune_preset=verso2/best.th\")\n```\n\nWe get some basic info about these weights.\n\n```python\nprint_weight_info(weights)\n```\n\n<pre style='max-height: 240px; overflow-y: scroll; font-size: 14px; padding: 12px; border-radius: 4px; border: solid #ddd 1px'>\nencoder.0.0.bias \t-0.1661\t\t0.3005\t\t48\nencoder.0.0.weight \t-0.4365\t\t0.3742\t\t384\n\t\t\t52.3438%\nencoder.0.2.bias \t-0.4893\t\t0.8613\t\t96\nencoder.0.2.weight \t-0.7753\t\t1.5334\t\t4608\n\t\t\t23.7413%\nencoder.1.0.bias \t-0.0760\t\t0.2138\t\t96\nencoder.1.0.weight \t-0.6905\t\t0.7302\t\t36864\n\t\t\t7.7474%\nencoder.1.2.bias \t-0.4025\t\t1.1158\t\t192\nencoder.1.2.weight \t-0.9252\t\t0.9893\t\t18432\n\t\t\t15.1204%\nencoder.2.0.bias \t-0.1144\t\t0.2732\t\t192\nencoder.2.0.weight \t-0.6058\t\t0.6952\t\t147456\n\t\t\t8.4371%\nencoder.2.2.bias \t-0.3144\t\t1.1645\t\t384\nencoder.2.2.weight \t-0.7645\t\t0.8168\t\t73728\n\t\t\t12.1487%\nencoder.3.0.bias \t-0.2279\t\t0.3234\t\t384\nencoder.3.0.weight \t-0.7191\t\t0.6821\t\t589824\n\t\t\t9.6261%\nencoder.3.2.bias \t-0.3796\t\t0.6909\t\t768\nencoder.3.2.weight \t-0.9781\t\t0.9608\t\t294912\n\t\t\t14.5667%\nencoder.4.0.bias \t-0.2516\t\t0.1453\t\t768\nencoder.4.0.weight \t-0.6874\t\t0.8081\t\t2359296\n\t\t\t10.0274%\nencoder.4.2.bias \t-0.2767\t\t0.3749\t\t1536\nencoder.4.2.weight \t-1.0705\t\t0.9233\t\t1179648\n\t\t\t14.0047%\ndecoder.0.0.bias \t-0.4838\t\t0.4492\t\t1536\ndecoder.0.0.weight \t-1.0980\t\t1.1172\t\t1179648\n\t\t\t12.3450%\ndecoder.0.2.bias \t-0.5981\t\t0.9222\t\t384\ndecoder.0.2.weight \t-0.9818\t\t0.7783\t\t2359296\n\t\t\t6.3385%\ndecoder.1.0.bias \t-0.7151\t\t0.4123\t\t768\ndecoder.1.0.weight \t-1.4589\t\t1.4236\t\t294912\n\t\t\t9.6459%\ndecoder.1.2.bias \t-0.4267\t\t0.8702\t\t192\ndecoder.1.2.weight \t-1.0842\t\t1.5031\t\t589824\n\t\t\t5.3640%\ndecoder.2.0.bias \t-1.0682\t\t0.7818\t\t384\ndecoder.2.0.weight \t-1.3639\t\t1.6044\t\t73728\n\t\t\t11.8056%\ndecoder.2.2.bias \t-0.0633\t\t0.5356\t\t96\ndecoder.2.2.weight \t-1.9591\t\t1.6501\t\t147456\n\t\t\t6.6155%\ndecoder.3.0.bias \t-1.1293\t\t0.3498\t\t192\ndecoder.3.0.weight \t-1.3212\t\t1.9597\t\t18432\n\t\t\t18.1532%\ndecoder.3.2.bias \t-0.0459\t\t0.1919\t\t48\ndecoder.3.2.weight \t-0.8982\t\t0.6510\t\t36864\n\t\t\t9.1092%\ndecoder.4.0.bias \t-0.3222\t\t0.4334\t\t96\ndecoder.4.0.weight \t-0.9638\t\t1.0617\t\t4608\n\t\t\t24.0885%\ndecoder.4.2.bias \t-0.0128\t\t-0.0128\t\t1\ndecoder.4.2.weight \t-0.3609\t\t0.3434\t\t384\n\t\t\t48.4375%\nlstm.lstm.bias_ih_l0 \t-0.1892\t\t0.5374\t\t3072\nlstm.lstm.bias_hh_l0 \t-0.2168\t\t0.5108\t\t3072\nlstm.lstm.bias_ih_l1 \t-0.1490\t\t0.4970\t\t3072\nlstm.lstm.bias_hh_l1 \t-0.1674\t\t0.4793\t\t3072\nlstm.lstm.weight_ih_l0 \t-0.8711\t\t0.8251\t\t2359296\n\t\t\t8.8214%\nlstm.lstm.weight_ih_l1 \t-0.9791\t\t1.0533\t\t2359296\n\t\t\t8.8558%\nlstm.lstm.weight_hh_l0 \t-0.7069\t\t0.7139\t\t2359296\n\t\t\t7.3889%\nlstm.lstm.weight_hh_l1 \t-0.8010\t\t0.8255\t\t2359296\n\t\t\t6.0804%\n0.0873541874651943\n0.9126458125348057\n</pre>\n\nThis is a unet architecture with 5 levels of encoding and decoding, which are conv1d layers. At the center is 2 layers of LSTM. After pruning, the model has a global sparsity of 91.26%, indicating only 8.74% of the values are nonzero. There are approximately 18M parameters.\n\nWe then try to compress all of the weights, excluding biases. In the end, the compressed size is printed.\n\n```python\ncompressed = {}\nsize = 0\nfor name, vec in weights.items():\n    if name.find(\"activation\") > -1: continue\n    # print(name, end=\"\\t\")\n    vec = vec.numpy()\n    c, s = compress(vec, fc_idx_bits=4, conv_idx_bits=5, def_idx_bits=5)\n    compressed[name] = c\n    size += s\nprint(\"\\n%.2f KiB\" % (size / 1024,))\n```\n\n<pre style='max-height: 240px; overflow-y: scroll; font-size: 14px; padding: 12px; border-radius: 4px; border: solid #ddd 1px'>\n2108.52 KiB\n</pre>\n\nThis is approximately 1 / 9 of the original model, if the original model were to be stored in 8 bits.\n\nNow, we try to run inference on this set of compressed weights. First, we add some extra functions for the decoder and encoder.\n\n```python\ndef beco_matmul(At, B):\n    \"\"\"\n    high level simulation of beco matrix multiply behavior. note that beco\n    assumes the first matrix is stored in memory transposed, and both matrices\n    (when stored) need to have a multiple of 4 as its width.\n    \"\"\"\n    return (At.T @ B)\n\ndef convolve(W, m, bias, stride):\n    \"\"\"\n    efficient convolution algorithm with a batch size B on a NORMAL weight matrix.\n    this is to 1. be used for testing and\n               2. demonstrate the underlying principles of sparse convolution.\n    \"\"\"\n    # assuming K > stride\n    B = 8 # batch size, number of rows to multiply every time\n\n    out_ch, K, in_ch = W.shape\n    \n    in_len = m.shape[0]\n    out = np.zeros((((in_len - stride) // (K - stride)) if K > stride else in_len // K, out_ch))\n    \n    for o in range(out_ch):\n        queue = []\n        out_idx = 0\n    \n        for row in range(0, in_len, B):\n            curr_matrix = m[row : row + B]\n            c = beco_matmul(curr_matrix.T, W[o].T)\n            assert(len(c.shape) == 2)\n            queue.extend(c)\n            \n            while (len(queue) >= K):\n                s = sum([queue[k][k] for k in range(K)]) # take the kth element of the kth row in queue\n                queue = queue[stride:]\n                out[out_idx][o], out_idx = s + bias[o], out_idx + 1\n    \n    return out\n\ndef convolve_sparse(W, bias, m, in_len, out_ch, in_ch, k, stride):\n    \"\"\"\n    performs convolution on input matrix, where each row is a channel.\n    weights W is an array of CSR matrix (v, c, r) pairs, each corresponding to a output channel.\n    returns an output matrix where each row is a channel, and is thus chainable.\n    \n    pseudocode: (only for reference, might not completely match code)\n    \n    C <- zeros(out_ch*out_len)\n    for each output channel:\n        W <- weights matrix corr. to this output channel (dim=k*in_ch)\n        for each batch of L rows in W:\n            At <- zeros(0*in_len)\n            B <- zeros(0*L)\n            for each l of the L rows keep a head pointer p_l, and current column c_l\n            while we have not exhausted all head pointers:\n                find minimum col num of all heads\n                reconstruct column at that index from W\n                transpose this column and vstack it to matrix B\n                pick out corr. row in input matrix and vstack to At\n                increment p_l and c_l for all rows that have the minimum col num\n            # at this point, should have At=(x*in_len) and B=(x*L), where x is nonzero count\n            call beco matmul to obtain U_l = At.T @ B (dim=in_len*L)\n        hstack all U_l's to form matrix U (dim=in_len*k)\n        for i = 0 to in_len step stride:\n            s <- sum of U[i, 0] to U[i + k, k]\n            C[out channel idx][j++] <- s\n    return C\n            \n    TODO: support batch sizes that are not the entire length of input\n    NOTE TO SELF: when transcribing to C, fix & unroll L\n    \"\"\"\n    L = 4    \n    out_len = ((in_len - stride) // (k - stride)) if k > stride else in_len // k\n    # C = np.zeros((out_len, out_ch)) # calloc\n    C = np.zeros((out_ch, out_len)) # calloc\n    for o in range(out_ch):\n        v, c, r = W[o] # v's, c's, r's are stored as separate arrays\n        U_l = []\n        for l in range(0, k, L):\n            At = np.zeros((0, in_len)) # prealloc as in_ch * in_len\n            B = np.zeros((0, L)) # prealloc as in_ch * L\n            ll = min(k - l, L) # tail condition can be written separately\n            p_l = [r[l + i] for i in range(ll)] # need to be uint32; length prealloc to L\n            c_l = [c[p_l[i]] - 1 if p_l[i] < r[l + i + 1] else 9999 for i in range(ll)] # index starts at -1\n            while np.any([p_l[i] < r[l + i + 1] for i in range(ll)]): # a merge-sort-like operation\n                min_val = 9999\n                for i in range(ll):\n                    if p_l[i] < r[l + i + 1]:\n                        min_val = min(min_val, c_l[i])\n                rc = np.zeros((L,)) # likely reusable with memset 0\n                for i in range(ll):\n                    if (c_l[i] == min_val):\n                        rc[i] = v[p_l[i]] # fill nonzero to reconstructed vec\n                        p_l[i] += 1 # advance to next nonzero\n                        if p_l[i] < r[l + i + 1]: c_l[i] += c[p_l[i]]\n                B = np.vstack([B, rc]) # in C should just be memcpy\n                At = np.vstack([At, m[min_val]]) # add corr. input row\n                # At = np.vstack([At, m[:, min_val]]) # would probably require a transpose step\n            U_l.append(beco_matmul(At, B))\n        U = np.hstack(U_l) # in C skip this step and modify convolution sampling instead\n\n        j = 0\n        for i in range(0, in_len - k + 1, stride): # convolve with stride\n            s = np.sum([U[i + kk, kk] for kk in range(k)])\n            C[o][j], j = s + bias[o], j + 1\n\n    return C # obviously skipped in C since array writes are in-place\n    \ndef fc_sparse(W, bias, m, out_ch, in_len):\n    \"\"\"\n    calculates fully connected layer on input matrix, where each row is a channel.\n    weights W is a tuple (v, c, r).\n    returns an output matrix where each column is a channel, and is thus chainable.\n    \n    pseudocode:\n    \n    for each batch of L rows in weight matrix W (dim=out_ch*in_ch):\n        At <- zeros(0*L)\n        B <- zeros(0*in_len)\n        for each l of the L rows keep a head pointer p_l, and current column c_l\n        while we have not exhausted all head pointers:\n            find minimum col num of all heads\n            reconstruct column at that index from the current L-row submatrix of W\n            transpose this column and vstack it to matrix At\n            pick out corr. row in input matrix and vstack to B\n            increment p_l and c_l for all rows that have the minimum col num\n        # at this point, should have At=(x*L) and B=(x*in_len), where x is nonzero count\n        call beco matmul to obtain U_l = At.T @ B (dim=L*in_len)\n    vstack all U_l's to form matrix C (dim=out_ch*in_len)\n    return C\n    \"\"\"\n    L = 4\n    v, c, r = W\n    U_l = []\n    for l in range(0, out_ch, L):\n        At = np.zeros((0, L)) # prealloc as in_ch * L\n        B = np.zeros((0, in_len)) # prealloc as in_ch * in_len\n        ll = min(out_ch - l, L)\n        p_l = [r[l + i] for i in range(ll)]\n        c_l = [c[p_l[i]] - 1 if p_l[i] < r[l + i + 1] else 9999 for i in range(ll)]\n        while np.any([p_l[i] < r[l + i + 1] for i in range(ll)]):\n            min_val = 9999\n            for i in range(ll):\n                if p_l[i] < r[l + i + 1]:\n                    min_val = min(min_val, c_l[i])\n            rc = np.zeros((L,))\n            for i in range(ll):\n                if (c_l[i] == min_val):\n                    rc[i] = v[p_l[i]]\n                    p_l[i] += 1\n                    if p_l[i] < r[l + i + 1]: c_l[i] += c[p_l[i]]\n            At = np.vstack([At, rc])\n            B = np.vstack([B, m[min_val]])\n        U_l.append(beco_matmul(At, B))\n    C = np.vstack(U_l) + np.expand_dims(bias, 1)\n\n    return C\n    \nGLU = lambda x: x[:x.shape[0] // 2] / (1 + np.exp(-x[x.shape[0] // 2:]))\nReLU = lambda x: np.maximum(0, x)\n```\n\nNow we attempt to run the encoding process for an input of length 2560.\n\n```python\nlayers = [\n    (compressed[\"encoder.\" + str(i) + \".0.weight\"], compressed[\"encoder.\" + str(i) + \".0.bias\"],\n     compressed[\"encoder.\" + str(i) + \".2.weight\"], compressed[\"encoder.\" + str(i) + \".2.bias\"])\n    for i in range(5)\n]\n\nchs = [(1, 48), (48, 96), (96, 192), (192, 384), (384, 768)]\n\nv = np.random.rand(1, 2560)\n\nm = v\nfor (l1, b1, l2, b2), (ch1, ch2) in zip(layers, chs):\n    m = convolve_sparse(l1, b1, m, in_len=m.shape[1],\n                        out_ch=ch2, in_ch=ch1, k=8, stride=4)\n    m = ReLU(m)\n    m = fc_sparse(l2, b2, m, ch2 * 2, m.shape[1])\n    m = GLU(m)\nprint(m)\n```\n\n<pre style='max-height: 240px; overflow-y: scroll; font-size: 14px; padding: 12px; border-radius: 4px; border: solid #ddd 1px'>\n[[ 2.16402284e-05]\n [-6.86438298e-01]\n [ 7.45622957e-04]\n [ 1.01900820e-01]\n [ 1.54519461e+00]\n [-1.25690016e-03]\n [-1.94400923e-01]\n [ 3.04551532e-01]\n [-1.82606233e+00]\n [-1.41211974e-02]\n [ 1.53868863e-02]\n [ 1.29516874e-02]\n [-1.50087096e-04]\n [ 1.49187872e-01]\n [-3.98359375e-04]\n [-1.05189119e-03]\n [ 4.18792611e-06]\n [ 2.80498345e-03]\n [-2.91582238e-04]\n [-2.22297634e+00]\n [ 8.78154058e-04]\n [ 2.28849150e-03]\n [-1.13989553e-01]\n [-1.64408021e-04]\n [ 4.07686757e-06]\n [ 2.78668457e-05]\n [-2.11741295e-02]\n [-3.63812103e+00]\n [ 2.82300887e-02]\n [-1.02316345e-04]\n [-6.79898742e+00]\n [ 3.79131864e-02]\n [ 1.72463322e-04]\n [ 1.19783254e-02]\n [-8.29995804e-01]\n [ 5.08629907e-02]\n [ 2.59044820e-04]\n [-1.62236813e-02]\n [ 5.15336508e+00]\n [ 4.12606848e-01]\n [ 6.84838350e+00]\n [-4.60875202e-02]\n [ 1.33798626e-06]\n [ 6.69906784e-04]\n [-1.61797997e-02]\n [-5.05738175e-05]\n [ 1.18792637e-02]\n [ 2.01824466e-08]\n [-2.02370504e-02]\n [ 8.79980400e-05]\n [-2.79446803e-03]\n [ 4.29067547e-03]\n [ 9.52100311e-06]\n [-3.99108471e-01]\n [ 5.08875769e-03]\n [ 3.10131139e-03]\n [ 1.00726565e+00]\n [ 9.37067682e-03]\n [-1.82911806e-04]\n [-1.51223576e-04]\n [-4.77106715e-03]\n [ 5.57939170e-05]\n [-1.26068642e+00]\n [-4.72148217e-02]\n [ 5.22163521e-02]\n [ 1.12867614e+01]\n [-5.06816381e-01]\n [-6.20266107e-03]\n [ 1.56053440e-04]\n [ 1.78338047e-01]\n [-1.06517999e-01]\n [ 3.33904488e+00]\n [ 3.25012307e-04]\n [-5.29629197e-01]\n [ 1.25449269e-02]\n [-8.83551951e-04]\n [ 1.54179887e-02]\n [-5.81193718e-01]\n [ 1.96658746e-05]\n [ 1.75131692e-02]\n [ 2.26822252e+00]\n [ 2.14782461e-04]\n [-4.18358514e-02]\n [-1.58986807e-03]\n [ 1.51929710e-04]\n [ 5.18822202e-02]\n [ 1.19674115e-03]\n [ 1.55362947e-04]\n [ 3.29111685e+00]\n [ 1.69947926e-04]\n [-8.83893177e-01]\n [-1.52082086e-01]\n [ 3.66975067e-01]\n [ 4.57957368e-06]\n [-9.59310654e+00]\n [-2.22869251e-02]\n [-1.77374137e-02]\n [-2.87703342e-04]\n [-3.81423295e-03]\n [ 1.65667095e-01]\n [ 2.63715392e+00]\n [ 3.63110961e-04]\n [ 7.71832435e+00]\n [-1.67599192e-03]\n [-1.60511397e-04]\n [ 6.53566806e-01]\n [ 2.07551465e-01]\n [-4.38386192e-02]\n [-7.98142110e-01]\n [ 7.43911643e-03]\n [ 3.03291535e-02]\n [ 1.05395086e-05]\n [-1.36504051e-03]\n [-1.44864165e+00]\n [ 6.43612086e-01]\n [-5.11755452e-03]\n [ 1.34076761e-05]\n [-4.80616965e-05]\n [-1.65409687e-03]\n [-1.22409953e-01]\n [ 3.79309625e-07]\n [ 4.90687141e-01]\n [ 4.17284066e-02]\n [ 1.37489995e-05]\n [-5.32538015e-05]\n [ 1.46352930e-03]\n [ 1.16743909e-01]\n [ 1.12893540e-05]\n [ 5.80462330e-05]\n [-1.49926878e+00]\n [ 3.26890142e-03]\n [-6.13356936e-02]\n [-3.06065654e+00]\n [-1.53681671e-04]\n [ 1.53803482e-01]\n [-2.14382184e-05]\n [-4.82365244e-01]\n [-1.40984863e-02]\n [-4.33194789e-01]\n [ 1.27913601e-01]\n [-2.53693934e-04]\n [ 3.53165355e-04]\n [-2.16453835e-02]\n [-1.27677791e-03]\n [ 1.46852580e-01]\n [-6.30717622e-01]\n [-3.50185824e-02]\n [-4.35849041e-05]\n [ 1.01112814e-02]\n [ 1.18353492e-02]\n [ 2.02767793e-03]\n [ 2.80404036e-02]\n [-1.53773016e+00]\n [ 9.11765761e-04]\n [-1.30189308e-02]\n [-2.07427172e-03]\n [ 1.64920323e-05]\n [-2.33390860e-01]\n [-2.23327682e-01]\n [ 6.70775256e-03]\n [ 1.45987808e+00]\n [ 3.66868477e-04]\n [-2.04600061e-03]\n [ 2.14193515e-04]\n [-3.58027862e-01]\n [-6.01612444e-03]\n [ 3.61380677e-03]\n [ 2.50839046e+00]\n [ 5.04686941e-06]\n [-1.25481575e-01]\n [ 1.27662593e-01]\n [ 2.12404785e-04]\n [ 1.63952821e+00]\n [-1.10040230e-02]\n [ 3.17762399e-04]\n [ 9.73954321e-04]\n [ 6.28515455e-06]\n [ 7.98612850e-03]\n [ 1.49517229e+00]\n [-1.57429942e+00]\n [-9.13901410e-06]\n [ 2.71168130e-03]\n [ 1.94714109e-03]\n [-9.87627215e-04]\n [-2.40376381e+00]\n [ 4.64995931e-03]\n [-1.04441135e-01]\n [ 4.10489906e+00]\n [-4.99242858e-03]\n [-3.61056066e+00]\n [-2.63041184e-03]\n [-5.48211854e-01]\n [ 1.14669233e-04]\n [-1.89198456e-05]\n [-3.03931360e-01]\n [-6.10429951e-04]\n [-2.15477387e+01]\n [-4.62507162e-06]\n [ 5.88701186e-01]\n [-5.83893290e-01]\n [-1.07007164e-01]\n [-1.40714500e-04]\n [-1.98141217e-05]\n [-3.09879236e+00]\n [-3.55130663e-02]\n [ 1.74155030e+00]\n [ 2.87856661e-02]\n [ 2.13640412e-05]\n [-4.04480756e-03]\n [-1.97696281e-01]\n [ 5.39750972e-02]\n [ 7.76877425e-01]\n [-2.10957728e-02]\n [-2.77669274e-01]\n [ 2.57012836e-07]\n [ 2.81173993e+00]\n [-4.28314976e-02]\n [ 7.65993752e-03]\n [ 2.03518215e-02]\n [-3.24292221e-01]\n [-2.45970421e-01]\n [ 2.56945635e-01]\n [-2.62702870e-06]\n [-1.12670145e-05]\n [ 5.15164221e-01]\n [-4.49232940e-02]\n [ 5.59408103e-02]\n [ 9.71112813e-03]\n [-5.17330042e-06]\n [ 5.48824564e-01]\n [-5.83347712e-03]\n [ 1.10468682e-05]\n [ 3.17283761e+00]\n [ 7.43085723e-03]\n [ 9.36713378e-04]\n [ 1.29352082e-01]\n [ 3.23289907e-02]\n [ 3.21018030e-03]\n [-2.39518585e-05]\n [ 4.37457536e-03]\n [-2.43856936e+00]\n [-3.26500881e-04]\n [ 3.30745847e-01]\n [ 2.63392728e-02]\n [ 6.21687231e-02]\n [ 3.47899105e-03]\n [ 8.85809543e-04]\n [ 8.68417310e-05]\n [ 1.98765642e-08]\n [ 3.33584593e-01]\n [-1.51657715e-02]\n [ 2.18688681e+00]\n [-3.38205822e-06]\n [-2.25584433e+00]\n [-8.76422957e-04]\n [-1.29229938e-02]\n [ 3.76360192e-02]\n [ 5.28354629e-03]\n [-8.13676880e-02]\n [-8.18348349e-01]\n [-4.10753391e-04]\n [ 1.08430247e-02]\n [-6.49048872e-02]\n [-1.24394698e-03]\n [ 1.87675323e-03]\n [ 1.02566077e-02]\n [ 5.93111708e-03]\n [-8.38771727e-03]\n [-1.05752448e-03]\n [ 3.24148280e-01]\n [ 1.34762069e-02]\n [ 8.15255324e-03]\n [ 2.54803680e-05]\n [ 1.38097048e-02]\n [-1.72074164e+00]\n [-8.36883045e-01]\n [-4.47816041e-02]\n [ 1.06838153e+00]\n [ 1.28585848e-03]\n [-5.31533068e-01]\n [-4.35341995e+00]\n [ 1.24055956e-05]\n [ 2.49220111e+00]\n [ 1.15555923e-02]\n [-2.81051299e-03]\n [ 4.12665909e-05]\n [ 9.51403746e-03]\n [-2.83230931e-02]\n [ 1.33184211e-05]\n [-2.86244271e-04]\n [ 1.36530411e-04]\n [-2.55850061e-04]\n [ 8.76205645e-01]\n [-6.01374047e-04]\n [ 1.43217177e-02]\n [-6.58725466e+00]\n [-2.31478624e-02]\n [ 1.73567857e-04]\n [-5.95972627e-03]\n [-1.95804004e+00]\n [-9.86885318e-06]\n [ 7.57890266e-03]\n [ 6.46906533e-05]\n [-3.42259903e+00]\n [-1.58723229e-05]\n [ 8.71496244e-01]\n [ 4.76379254e+00]\n [-8.83978479e+00]\n [ 5.63618172e-01]\n [ 2.16942486e-08]\n [-1.98828644e+00]\n [ 8.03220723e-02]\n [ 3.85485274e-02]\n [-2.30985211e+00]\n [-1.35328315e-01]\n [ 2.32032338e+00]\n [-5.36839891e-05]\n [-3.55609206e-01]\n [ 1.59054503e-04]\n [ 2.34945754e-02]\n [-1.63097823e-04]\n [-1.70305860e-01]\n [ 2.14476625e+00]\n [-2.72906820e-01]\n [ 4.73794395e-04]\n [-2.38820088e+00]\n [ 8.29460027e-04]\n [-2.10438022e-03]\n [ 2.11044907e+00]\n [-2.30018846e-03]\n [ 5.22365519e-02]\n [-3.38349814e-06]\n [ 1.49023911e-05]\n [-4.95146055e-06]\n [ 5.25239860e-02]\n [ 1.24732147e-02]\n [-7.20640349e-01]\n [-9.79490928e-06]\n [-5.34025421e-02]\n [-3.56543894e-04]\n [ 2.29124823e-02]\n [-4.02883323e-03]\n [-4.37127542e-01]\n [-6.37828658e+00]\n [-5.22019352e-04]\n [ 1.69487361e+00]\n [ 7.12729657e-05]\n [ 6.74935189e+00]\n [ 4.43008186e-05]\n [ 2.32269597e-03]\n [ 7.90177177e-02]\n [ 6.80347327e-03]\n [ 1.01023896e-03]\n [ 1.26457449e+01]\n [ 1.05549123e-02]\n [-6.48070639e-04]\n [-2.05178642e-03]\n [ 6.25396432e-02]\n [ 2.78956044e+00]\n [-4.42556996e-03]\n [ 1.02382159e-02]\n [-1.46718178e+00]\n [ 1.03863596e+00]\n [ 3.34926637e-05]\n [-3.97308128e-01]\n [-8.66817343e-05]\n [-3.34434961e+00]\n [ 5.46221337e-03]\n [ 5.42731240e-01]\n [ 7.78845243e-05]\n [-1.32001241e-01]\n [ 1.29653925e-02]\n [ 1.49284197e-02]\n [ 6.67046778e-06]\n [ 6.85503369e-04]\n [-1.00749703e-03]\n [-2.42800748e-05]\n [ 1.29648268e-03]\n [-1.82440994e-01]\n [-1.85046552e-01]\n [-5.37561100e+00]\n [-1.53297403e-03]\n [-2.98212563e-06]\n [-4.66388868e+00]\n [ 4.76966451e-05]\n [ 1.53903551e-02]\n [ 3.05159487e-05]\n [-8.30903950e-03]\n [ 2.82507456e-01]\n [ 2.89732887e-05]\n [ 3.99109901e-07]\n [ 3.79707164e-02]\n [ 1.03957938e-02]\n [-4.02986185e-03]\n [-1.62139128e-05]\n [-3.54332009e-01]\n [ 1.25108323e-01]\n [ 1.61559159e+00]\n [ 1.57816067e-01]\n [-4.50244465e-02]\n [-4.57385382e-03]\n [-1.30833268e-02]\n [-2.85271435e-02]\n [-3.27352052e-02]\n [-5.17508871e+00]\n [-1.10060127e+00]\n [ 1.12430296e+00]\n [ 5.75429713e-04]\n [-1.18500575e-03]\n [-4.55020859e-03]\n [-1.02720009e-02]\n [ 1.10236830e-01]\n [-1.80110854e+00]\n [-1.12503709e-01]\n [-7.56388550e-02]\n [-8.25224739e-05]\n [-1.44559755e-03]\n [ 5.14813812e-04]\n [ 1.69238616e-02]\n [ 2.64495774e-01]\n [ 1.11180950e-01]\n [ 6.39388406e-02]\n [-8.59925363e-02]\n [ 7.68852429e-01]\n [ 2.75934275e-01]\n [-1.97347612e-01]\n [-2.08485012e-06]\n [ 4.22312268e+00]\n [ 7.94325783e-02]\n [ 8.72165732e-01]\n [-1.63718567e-01]\n [ 2.48457946e-03]\n [-2.15470454e+00]\n [-3.68127849e-02]\n [-2.52637991e+00]\n [ 2.09757629e-02]\n [ 1.02027226e-04]\n [-1.50091439e-03]\n [-1.29389424e-02]\n [-2.67227767e-01]\n [ 2.63637832e+00]\n [-7.31887707e-01]\n [-3.03768560e+00]\n [-5.80697128e-04]\n [-3.61200157e-07]\n [-2.33214718e-04]\n [ 1.55106408e+00]\n [-9.21439011e-02]\n [-1.79346098e-05]\n [ 1.11918666e-01]\n [ 2.24778525e+00]\n [ 4.18409832e-02]\n [-2.25382824e+00]\n [-1.54887528e+00]\n [-6.78341407e-04]\n [ 5.83745769e-02]\n [ 5.86225233e-03]\n [ 8.99413367e-04]\n [-8.02031847e+00]\n [-1.53291872e+01]\n [ 3.56382478e-03]\n [ 6.69867793e+00]\n [ 1.23705054e-02]\n [ 2.06633155e+00]\n [ 1.48958460e-03]\n [-1.43937794e-04]\n [ 4.67824039e-04]\n [-9.11695625e-03]\n [-1.54350227e-06]\n [-2.56881447e-02]\n [ 8.14284969e+00]\n [ 2.18820246e-02]\n [-7.76452228e-02]\n [-1.08602075e-02]\n [ 5.23113691e-01]\n [ 2.44219891e-02]\n [-8.91727923e-03]\n [-6.33188523e-05]\n [-1.14842782e-02]\n [-1.12255418e-01]\n [-1.27707531e-02]\n [ 1.23082565e-03]\n [ 2.74751232e-03]\n [ 1.94464145e-01]\n [-3.44148961e-02]\n [ 6.22754584e-04]\n [-1.94739133e-01]\n [ 5.43782656e-02]\n [ 2.49569553e-02]\n [ 1.93681750e-02]\n [ 3.59606489e+00]\n [ 4.96651031e-02]\n [-2.24570684e-05]\n [-2.50065693e-02]\n [-2.79840425e-01]\n [-6.23010870e-03]\n [ 7.68045699e-06]\n [-7.75992917e+00]\n [ 5.78911393e-03]\n [-6.25941646e-02]\n [ 4.95852813e-03]\n [ 8.46620888e-02]\n [ 2.11255753e-02]\n [-6.22450822e-02]\n [-7.32734387e-01]\n [-1.19034059e-02]\n [ 6.92300801e-04]\n [-4.44862081e-05]\n [ 3.83526908e-05]\n [ 6.30628623e-01]\n [ 2.82474532e-06]\n [ 8.63418060e-01]\n [-2.72178140e-02]\n [ 1.59969082e+00]\n [-2.12562751e-02]\n [ 4.46086478e-03]\n [ 3.40515047e-01]\n [ 6.67364022e-01]\n [ 8.08496393e-01]\n [-1.94834705e-02]\n [ 1.82421822e+00]\n [ 9.51784218e-01]\n [ 6.26745690e-02]\n [ 8.33672886e-02]\n [ 4.84093395e-01]\n [ 1.16867855e+00]\n [ 3.40521822e-07]\n [ 1.57876155e+01]\n [ 2.26083780e-02]\n [-5.57226037e-05]\n [ 3.85055840e-01]\n [-7.79319962e-01]\n [-1.21512644e-02]\n [ 6.32106516e-02]\n [ 1.05585077e-02]\n [-4.60781958e-02]\n [-6.34508151e-04]\n [ 8.17822022e-05]\n [ 1.76402543e-02]\n [-2.49037957e-04]\n [ 2.23480005e-01]\n [-1.38142404e-02]\n [-4.26721444e-03]\n [ 2.86682621e-04]\n [ 5.12146955e-02]\n [ 1.04628199e-02]\n [-1.86784078e-01]\n [ 6.05997015e+00]\n [ 3.40352256e-02]\n [-1.67166501e-01]\n [-8.20160180e-04]\n [ 6.70320325e+00]\n [-3.29330268e-01]\n [ 1.18532396e-05]\n [ 1.64989498e-02]\n [-4.12652258e-01]\n [-1.86542621e+00]\n [ 6.01979791e-04]\n [ 1.30924180e-02]\n [ 7.38263060e-01]\n [-3.83442494e-01]\n [-1.19704748e-02]\n [ 7.87062136e-06]\n [ 1.37263199e+00]\n [ 2.55764462e-02]\n [-2.80734816e-04]\n [ 1.28136473e-04]\n [-7.01014134e+00]\n [-4.03710059e-05]\n [ 1.82764621e-04]\n [-6.66891097e-02]\n [-3.38198550e-02]\n [ 1.79744168e-03]\n [-7.24268728e-01]\n [ 3.80762575e+00]\n [ 6.38201008e-03]\n [-3.16073522e-02]\n [-1.55421837e-01]\n [-1.74203425e-03]\n [-2.61642971e-04]\n [ 3.32801303e-05]\n [ 2.65677574e-02]\n [-7.76727307e-02]\n [-8.11328163e+00]\n [ 1.25477524e-07]\n [-2.88973170e-01]\n [ 6.17018147e+00]\n [-1.43966521e+00]\n [-2.39826458e-01]\n [-3.08620171e-05]\n [-2.68713286e-06]\n [ 3.26780808e-02]\n [ 2.53362085e-05]\n [ 2.60506755e-01]\n [-6.19602111e-02]\n [-7.26616055e-02]\n [ 1.35499095e-07]\n [ 4.92923087e-07]\n [ 6.00794271e-01]\n [ 3.01588845e-02]\n [-3.98670591e+00]\n [-1.89174825e-02]\n [ 2.92480303e-06]\n [ 3.00879456e+00]\n [ 5.58964023e-03]\n [-3.32947956e+00]\n [ 3.35868355e-04]\n [-1.47596350e-02]\n [ 2.42852575e-04]\n [-1.34270688e-01]\n [-1.30152640e-01]\n [-1.81420537e+00]\n [-1.60932700e-07]\n [-1.78779174e-03]\n [ 3.32851241e-03]\n [-1.43737946e-02]\n [ 3.71659749e-04]\n [ 8.77362297e-03]\n [ 2.12546196e-04]\n [ 5.09870157e-04]\n [ 7.21445325e-02]\n [ 8.59226694e-02]\n [-1.28442163e-03]\n [ 1.79514438e-03]\n [ 6.96741979e-01]\n [ 1.25852700e+01]\n [ 4.02714397e-01]\n [ 3.81688011e-02]\n [-4.47220980e-02]\n [ 2.63155286e-05]\n [ 6.59452433e-04]\n [-5.12420324e-02]\n [-3.75661451e-02]\n [ 1.29409290e-02]\n [-3.03387537e-05]\n [ 1.66052726e-01]\n [ 1.94825102e-02]\n [ 5.58010388e-06]\n [-1.81955542e+00]\n [ 5.83099552e-04]\n [-8.46250680e-03]\n [ 3.85049947e-02]\n [ 8.76672411e-01]\n [-6.43916003e-01]\n [ 5.94354922e-03]\n [ 9.96655199e-06]\n [ 3.32186463e-02]\n [-2.81125979e+00]\n [ 3.15975969e-07]\n [-3.76321670e-03]\n [-3.89063967e-05]\n [ 9.66276667e-07]\n [-8.53108067e-07]\n [ 2.74082808e-04]\n [-3.15949522e-05]\n [ 2.13291938e-02]\n [ 5.02169020e-02]\n [ 9.46894171e-02]\n [-1.52640293e-04]\n [-2.44322598e-04]\n [ 7.84715680e-02]\n [ 6.20422606e-06]\n [-5.35482420e-03]\n [ 4.82598350e-04]\n [-8.83662231e-06]\n [-3.03128475e-03]\n [ 3.71285945e-02]\n [-8.60507451e-04]\n [-6.12265976e-04]\n [ 1.07449467e-04]\n [ 1.70862324e+00]\n [ 4.26967325e-03]\n [-1.20888076e+00]\n [ 3.01889056e-04]\n [-1.32836273e-03]\n [ 1.35067347e-05]\n [ 1.86683849e-01]\n [-1.35094214e+00]\n [-3.80354206e-03]\n [ 8.19290040e-03]\n [-4.02936602e-03]\n [-1.06053049e-02]\n [ 1.11052230e-03]\n [ 3.06709957e-03]\n [-1.23437992e-01]\n [ 1.01874422e-05]\n [-5.51754374e-02]\n [ 3.78053542e+00]\n [-8.92780698e-02]\n [ 1.84058926e-01]\n [ 6.43643155e-02]\n [ 3.98752642e-05]\n [-1.26305128e-03]\n [-1.14271756e-03]\n [-5.31691110e-06]\n [ 4.59026902e-05]\n [ 5.80739647e-01]\n [-4.53362721e-01]\n [-2.43566872e-03]\n [ 3.38749460e-03]\n [ 1.08677226e-01]\n [ 1.75657191e+00]\n [-3.55715167e+00]\n [ 3.28646678e-03]\n [ 3.36527330e-03]\n [ 4.49290737e+00]\n [ 2.37329957e-05]\n [ 5.08757533e-02]\n [ 7.52666019e-03]\n [ 1.12785564e-01]\n [-9.48445880e-04]\n [-2.35378996e-02]\n [-1.14762991e+00]\n [-2.52950330e-03]\n [-8.67083483e-01]\n [ 1.64981706e-03]\n [-2.70895303e-03]\n [ 8.17771941e-03]\n [-2.33831900e-05]\n [-6.61013128e-03]\n [-6.08919324e-02]\n [-1.39414402e-02]\n [ 8.72160953e-02]\n [ 4.57992806e-06]\n [-9.60445506e-03]\n [-5.95732975e-01]\n [-3.74012267e-01]\n [-1.57993814e-04]\n [-9.72814092e-01]\n [ 1.61488581e-01]\n [-3.47490973e-05]\n [-7.91696089e-03]\n [-2.92578995e-01]\n [ 2.48032721e-01]\n [ 5.75428917e-04]\n [ 4.11466894e-03]\n [ 1.08222004e-05]\n [ 2.28163443e-01]\n [-9.68510240e-04]\n [ 3.06336326e-04]\n [ 6.56900104e-03]\n [ 1.60143466e-01]\n [ 8.17573226e-02]\n [-1.24264693e-02]\n [ 4.79215402e-05]\n [ 4.97459707e-01]\n [ 2.84065397e-05]\n [ 7.07777033e-06]\n [ 3.03473854e-02]\n [-6.82642840e-02]\n [-3.58612163e-02]\n [-4.18496316e-03]\n [-9.68937220e-03]\n [-1.09420151e-05]\n [-2.79087882e-03]\n [-4.09690812e-04]\n [-7.49116465e-06]\n [-4.45514727e-02]\n [ 3.73627802e-01]\n [-6.11236035e-04]\n [-1.64280611e-05]\n [-1.55265541e-02]\n [ 7.46388305e+00]\n [-7.74431458e+00]\n [ 2.00235249e-01]\n [-9.25944054e-06]\n [-6.98843387e-03]\n [ 8.51422328e-03]]\n</pre>\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "Proprietary",
    "maintainer": "",
    "maintainer_email": "",
    "name": "model-compression-777",
    "package_url": "https://pypi.org/project/model-compression-777/",
    "platform": "",
    "project_url": "https://pypi.org/project/model-compression-777/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/model-compression-777/0.1.2/",
    "requires_dist": [
      "numpy (>=1.21.1,<2.0.0)",
      "torch (>=1.0.2,<2.0.0)"
    ],
    "requires_python": ">=3.7,<4.0",
    "summary": "Pre-pruned pytorch model compression toolkit",
    "version": "0.1.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 11098443,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1caf4d4fef8ed8c3be896fae74aa2622b60d15f86b5cebadf89a385cde63847c",
          "md5": "eacffb7baa690bcd3f10abc50b078e9c",
          "sha256": "32e056e4d430990d266937fa4b2abd65b9fcc3d2c23f8f4622182d6b291fef3f"
        },
        "downloads": -1,
        "filename": "model_compression_777-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "eacffb7baa690bcd3f10abc50b078e9c",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7,<4.0",
        "size": 3107,
        "upload_time": "2021-08-04T07:42:38",
        "upload_time_iso_8601": "2021-08-04T07:42:38.159344Z",
        "url": "https://files.pythonhosted.org/packages/1c/af/4d4fef8ed8c3be896fae74aa2622b60d15f86b5cebadf89a385cde63847c/model_compression_777-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c594f6e0459440689f8fa1c938e72b1a2a2c997b0c413377876926949601e385",
          "md5": "efa3b0764800a286e9bf9c2152f751a1",
          "sha256": "30cb384339eba9f108b36e31efa7ce842f6e924d609ecee6e0583d65d98e3c84"
        },
        "downloads": -1,
        "filename": "model-compression-777-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "efa3b0764800a286e9bf9c2152f751a1",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7,<4.0",
        "size": 2799,
        "upload_time": "2021-08-04T07:42:36",
        "upload_time_iso_8601": "2021-08-04T07:42:36.568537Z",
        "url": "https://files.pythonhosted.org/packages/c5/94/f6e0459440689f8fa1c938e72b1a2a2c997b0c413377876926949601e385/model-compression-777-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f7327038365befe8ac47e797988b0a4cbaab3640abcd089c8265e24578697cc5",
          "md5": "00c25c3fd151989663cd5eebdf52fe51",
          "sha256": "8630e0ac7372a69d5485ca40f1f29d0288ef335fd21350de0a1df6b30984c32e"
        },
        "downloads": -1,
        "filename": "model_compression_777-0.1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "00c25c3fd151989663cd5eebdf52fe51",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7,<4.0",
        "size": 3109,
        "upload_time": "2021-08-04T07:54:39",
        "upload_time_iso_8601": "2021-08-04T07:54:39.270835Z",
        "url": "https://files.pythonhosted.org/packages/f7/32/7038365befe8ac47e797988b0a4cbaab3640abcd089c8265e24578697cc5/model_compression_777-0.1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bc471d8b73a40cd9e8a70963cafc6ba2cb39f6fee10957a413c26ce9f936efc0",
          "md5": "71d15a959467de6d052cdfe9dc4739cb",
          "sha256": "f4a59ea00b868767228ab92e01fa60d17ccfc74066a2b0083e3410133e29ab67"
        },
        "downloads": -1,
        "filename": "model-compression-777-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "71d15a959467de6d052cdfe9dc4739cb",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7,<4.0",
        "size": 2792,
        "upload_time": "2021-08-04T07:54:37",
        "upload_time_iso_8601": "2021-08-04T07:54:37.900301Z",
        "url": "https://files.pythonhosted.org/packages/bc/47/1d8b73a40cd9e8a70963cafc6ba2cb39f6fee10957a413c26ce9f936efc0/model-compression-777-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "977e79711ed0955769fab1df46f2e25d822caad1fe2acaa1f02a7c5fcf15c52d",
          "md5": "837d092c1930f184be5630e56656aed7",
          "sha256": "8f0a1f339f003c80d6909abb5f4123dbc8eaadf4fce2dbeb79180ff63823f452"
        },
        "downloads": -1,
        "filename": "model_compression_777-0.1.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "837d092c1930f184be5630e56656aed7",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7,<4.0",
        "size": 13660,
        "upload_time": "2021-08-05T09:33:37",
        "upload_time_iso_8601": "2021-08-05T09:33:37.854016Z",
        "url": "https://files.pythonhosted.org/packages/97/7e/79711ed0955769fab1df46f2e25d822caad1fe2acaa1f02a7c5fcf15c52d/model_compression_777-0.1.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "12621e03451f85795b5a488d7491e4afb1e3c79657e23a175010f2deba6e4097",
          "md5": "bf637f6a1d5becb86ae6459b596aa162",
          "sha256": "c5e704a6c090cf65dd8fe47e174c4043119f3d22f48f18608ca25255f95ec7fd"
        },
        "downloads": -1,
        "filename": "model-compression-777-0.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "bf637f6a1d5becb86ae6459b596aa162",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7,<4.0",
        "size": 26832,
        "upload_time": "2021-08-05T09:33:35",
        "upload_time_iso_8601": "2021-08-05T09:33:35.740337Z",
        "url": "https://files.pythonhosted.org/packages/12/62/1e03451f85795b5a488d7491e4afb1e3c79657e23a175010f2deba6e4097/model-compression-777-0.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "977e79711ed0955769fab1df46f2e25d822caad1fe2acaa1f02a7c5fcf15c52d",
        "md5": "837d092c1930f184be5630e56656aed7",
        "sha256": "8f0a1f339f003c80d6909abb5f4123dbc8eaadf4fce2dbeb79180ff63823f452"
      },
      "downloads": -1,
      "filename": "model_compression_777-0.1.2-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "837d092c1930f184be5630e56656aed7",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7,<4.0",
      "size": 13660,
      "upload_time": "2021-08-05T09:33:37",
      "upload_time_iso_8601": "2021-08-05T09:33:37.854016Z",
      "url": "https://files.pythonhosted.org/packages/97/7e/79711ed0955769fab1df46f2e25d822caad1fe2acaa1f02a7c5fcf15c52d/model_compression_777-0.1.2-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "12621e03451f85795b5a488d7491e4afb1e3c79657e23a175010f2deba6e4097",
        "md5": "bf637f6a1d5becb86ae6459b596aa162",
        "sha256": "c5e704a6c090cf65dd8fe47e174c4043119f3d22f48f18608ca25255f95ec7fd"
      },
      "downloads": -1,
      "filename": "model-compression-777-0.1.2.tar.gz",
      "has_sig": false,
      "md5_digest": "bf637f6a1d5becb86ae6459b596aa162",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7,<4.0",
      "size": 26832,
      "upload_time": "2021-08-05T09:33:35",
      "upload_time_iso_8601": "2021-08-05T09:33:35.740337Z",
      "url": "https://files.pythonhosted.org/packages/12/62/1e03451f85795b5a488d7491e4afb1e3c79657e23a175010f2deba6e4097/model-compression-777-0.1.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}