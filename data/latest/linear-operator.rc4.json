{
  "info": {
    "author": "Geoff Pleiss",
    "author_email": "gpleiss@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 2 - Pre-Alpha",
      "Programming Language :: Python :: 3"
    ],
    "description": "# LinearOperator\n\n[![Test](https://github.com/cornellius-gp/linear_operator/actions/workflows/run_test_suite.yml/badge.svg)](https://github.com/cornellius-gp/linear_operator/actions/workflows/run_test_suite.yml)\n[![Documentation](https://readthedocs.org/projects/linear-operator/badge/?version=latest)](https://linear-operator.readthedocs.io/en/latest/?badge=latest)\n[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)\n\n[![Python Version](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)\n[![Conda](https://img.shields.io/conda/v/gpytorch/linear_operator.svg)](https://anaconda.org/gpytorch/linear_operator)\n[![PyPI](https://img.shields.io/pypi/v/linear_operator.svg)](https://pypi.org/project/linear_operator)\n\n\n<!-- docs_intro_start -->\n\nLinearOperator is a PyTorch package for abstracting away the linear algebra routines needed for structured matrices (or operators).\n\n**This package is in beta.**\nCurrently, most of the functionality only supports positive semi-definite and triangular matrices.\nPackage development TODOs:\n - [x] Support PSD operators\n - [x] Support triangular operators\n - [ ] Interface to specify structure (i.e. symmetric, triangular, PSD, etc.)\n - [ ] Add algebraic routines for symmetric operators\n - [ ] Add algebraic routines for generic square operators\n - [ ] Add algebraic routines for generic rectangular operators\n - [ ] Add sparse operators\n\n<!-- docs_intro_end -->\n\nTo get started, run either\n```sh\npip install linear_operator\n# or\nconda install linear_operator -c gpytorch\n```\nor [see below](#installation) for more detailed instructions.\n\n\n<!-- docs_index_start -->\n\n\n## Why LinearOperator\nBefore describing what linear operators are and why they make a useful abstraction, it's easiest to see an example.\nLet's say you wanted to compute a matrix solve:\n\n$$\\boldsymbol A^{-1} \\boldsymbol b.$$\n\nIf you didn't know anything about the matrix $\\boldsymbol A$, the simplest (and best) way to accomplish this in code is:\n\n```python\n# A = torch.randn(1000, 1000)\n# b = torch.randn(1000)\ntorch.linalg.solve(A, b)  # computes A^{-1} b\n```\n\nWhile this is easy, the `solve` routine is $\\mathcal O(N^3)$, which gets very slow as $N$ grows large.\n\nHowever, let's imagine that we knew that $\\boldsymbol A$ was equal to a low rank matrix plus a diagonal\n(i.e. $\\boldsymbol A = \\boldsymbol C \\boldsymbol C^\\top + \\boldsymbol D$\nfor some skinny matrix $\\boldsymbol C$ and some diagonal matrix $\\boldsymbol D$.)\nThere's now a very efficient $\\boldsymbol O(N)$ routine to compute $\\boldsymbol A^{-1}$ (the [Woodbury formula](https://en.wikipedia.org/wiki/Woodbury_matrix_identity)).\n**In general**, if we know that $\\boldsymbol A$ has structure,\nwe want to use efficient linear algebra routines - rather than the general routines -\nthat exploit this structure.\n\n\n### Without LinearOperator\n\nImplementing the efficient solve that exploits $\\boldsymbol A$'s low-rank-plus-diagonal structure would look something like this:\n\n```python\ndef low_rank_plus_diagonal_solve(C, d, b):\n    # A = C C^T + diag(d)\n    # A^{-1} b = D^{-1} b - D^{-1} C (I + C^T D^{-1} C)^{-1} C^T D^{-1} b\n    #   where D = diag(d)\n\n    D_inv_b = b / d\n    D_inv_C = C / d.unsqueeze(-1)\n    eye = torch.eye(C.size(-2))\n    return (\n        D_inv_b - D_inv_C @ torch.cholesky_solve(\n            C.mT @ D_inv_b,\n            torch.linalg.cholesky(eye + C.mT @ D_inv_C, upper=False),\n            upper=False\n        )\n    )\n\n\n# C = torch.randn(1000, 20)\n# d = torch.randn(1000)\n# b = torch.randn(1000)\nlow_rank_plus_diagonal_solve(C, d, b)  # computes A^{-1} b in O(N) time, instead of O(N^3)\n```\n\nWhile this is efficient code, it's not ideal for a number of reasons:\n1. It's a lot more complicated than `torch.linalg.solve(A, b)`.\n2. There's no object that represents $\\boldsymbol A$.\n   To perform any math with $\\boldsymbol A$, we have to pass around the matrix `C` and the vector `d`.\n\n\n### With LinearOperator\n\nThe LinearOperator package offers the best of both worlds:\n\n```python\nfrom linear_operator.operators import DiagLinearOperator, LowRankRootLinearOperator\n# C = torch.randn(1000, 20)\n# d = torch.randn(1000)\n# b = torch.randn(1000)\nA = LowRankRootLinearOperator(C) + DiagLinearOperator(d)  # represents C C^T + diag(d)\n```\n\nit provides an interface that lets us treat $\\boldsymbol A$ as if it were a generic tensor,\nusing the standard PyTorch API:\n\n```python\ntorch.linalg.solve(A, b)  # computes A^{-1} b efficiently!\n```\n\nUnder-the-hood, the `LinearOperator` object keeps track of the algebraic structure of $\\boldsymbol A$ (low rank plus diagonal)\nand determines the most efficient routine to use (the Woodbury formula).\nThis way, we can get a efficient $\\mathcal O(N)$ solve while abstracting away all of the details.\n\nCrucially, $\\boldsymbol A$ is never explicitly instantiated as a matrix, which makes it possible to scale\nto very large operators without running out of memory:\n\n```python\n# C = torch.randn(10000000, 20)\n# d = torch.randn(10000000)\n# b = torch.randn(10000000)\nA = LowRankRootLinearOperator(C) + DiagLinearOperator(d)  # represents a 10M x 10M matrix!\ntorch.linalg.solve(A, b)  # computes A^{-1} b efficiently!\n```\n\n\n<!-- docs_index_end -->\n<!-- docs_about_start -->\n\n\n## What is a Linear Operator?\nA linear operator is a generalization of a matrix.\nIt is a linear function that is defined in by its application to a vector.\nThe most common linear operators are (potentially structured) matrices,\nwhere the function applying them to a vector are (potentially efficient)\nmatrix-vector multiplication routines.\n\nIn code, a `LinearOperator` is a class that\n1. specifies the tensor(s) needed to define the LinearOperator,\n1. specifies a `_matmul` function (how the LinearOperator is applied to a vector),\n1. specifies a `_size` function (how big is the LinearOperator if it is represented as a matrix, or batch of matrices), and\n1. specifies a `_transpose_nonbatch` function (the adjoint of the LinearOperator).\n1. (optionally) defines other functions (e.g. `logdet`, `eigh`, etc.) to accelerate computations for which efficient sturcture-exploiting routines exist.\n\nFor example:\n\n```python\nclass DiagLinearOperator(linear_operator.LinearOperator):\n    r\"\"\"\n    A LinearOperator representing a diagonal matrix.\n    \"\"\"\n    def __init__(self, diag):\n        # diag: the vector that defines the diagonal of the matrix\n        self.diag = diag\n\n    def _matmul(self, v):\n        return self.diag.unsqueeze(-1) * v\n\n    def _size(self):\n        return torch.Size([*self.diag.shape, self.diag.size(-1)])\n\n    def _transpose_nonbatch(self):\n        return self  # Diagonal matrices are symmetric\n\n    # this function is optional, but it will accelerate computation\n    def logdet(self):\n        return self.diag.log().sum(dim=-1)\n# ...\n\nD = DiagLinearOperator(torch.tensor([1., 2., 3.])\n# Represents the matrix\n#   [[1., 0., 0.],\n#    [0., 2., 0.],\n#    [0., 0., 3.]]\ntorch.matmul(D, torch.tensor([4., 5., 6.])\n# Returns [4., 10., 18.]\n```\n\nWhile `_matmul`, `_size`, and `_transpose_nonbatch` might seem like a limited set of functions,\nit turns out that most functions on the `torch` and `torch.linalg` namespaces can be efficiently implemented\nusing only these three primitative functions.\n\nMoreover, because `_matmul` is a linear function, it is very easy to compose linear operators in various ways.\nFor example: adding two linear operators (`SumLinearOperator`) just requires adding the output of their `_matmul` functions.\nThis makes it possible to define very complex compositional structures that still yield efficient linear algebraic routines.\n\nFinally, `LinearOperator` objects can be composed with one another, yielding new `LinearOperator` objects and automatically keeping track of algebraic structure after each computation.\nAs a result, users never need to reason about what efficient linear algebra routines to use  (so long as the input elements defined by the user encode known input structure).\n<!-- docs_about_end -->\nSee the [using LinearOperator objects](#using-linearoperator-objects) section for more details.\n\n\n<!-- docs_usecases_start -->\n\n\n## Use Cases\n\nThere are several use cases for the LinearOperator package.\nHere we highlight two general themes:\n\n### Modular Code for Structured Matrices\n\nFor example, let's say that you have a generative model that involves\nsampling from a high-dimensional multivariate Gaussian.\nThis sampling operation will require storing and manipulating a large covariance matrix,\nso to speed things up you might want to experiment with different structured\napproximations of that covariance matrix.\nThis is easy with the LinearOperator package.\n\n```python\nfrom gpytorch.distributions import MultivariateNormal\n\n# variance = torch.randn(10000)\ncov = DiagLinearOperator(variance)\n# or\n# cov = LowRankRootLinearOperator(...) + DiagLinearOperator(...)\n# or\n# cov = KroneckerProductLinearOperator(...)\n# or\n# cov = ToeplitzLinearOperator(...)\n# or\n# ...\n\nmvn = MultivariateNormal(torch.zeros(cov.size(-1), cov) # 10000-dimensional MVN\nmvn.rsample()  # returns a 10000-dimensional vector\n```\n\n### Efficient Routines for Complex Operators\n\nMany of the efficient linear algebra routines in LinearOperator are iterative algorithms\nbased on matrix-vector multiplication.\nSince matrix-vector multiplication obeys many nice compositional properties\nit is possible to obtain efficient routines for extremely complex compositional LienarOperators:\n\n```python\nfrom linear_operator.operators import KroneckerProductLinearOperator, RootLinearOperator, ToeplitzLinearOperator\n\n# mat1 = 200 x 200 PSD matrix\n# mat2 = 100 x 100 PSD matrix\n# vec3 = 20000 vector\n\nA = KroneckerProductLinearOperator(mat1, mat2) + RootLinearOperator(ToeplitzLinearOperator(vec3))\n# represents a 20000 x 20000 matrix\n\ntorch.linalg.solve(A, torch.randn(20000))  # Sub O(N^3) routine!\n```\n\n\n<!-- docs_usecases_end -->\n<!-- docs_using_start -->\n\n\n## Using LinearOperator Objects\n\nLinearOperator objects share (mostly) the same API as `torch.Tensor` objects.\nUnder the hood, these objects use `__torch_function__` to dispatch all efficient linear algebra operations\nto the `torch` and `torch.linalg` namespaces.\nThis includes\n- `torch.add`\n- `torch.cat`\n- `torch.clone`\n- `torch.diagonal`\n- `torch.dim`\n- `torch.div`\n- `torch.expand`\n- `torch.logdet`\n- `torch.matmul`\n- `torch.numel`\n- `torch.permute`\n- `torch.prod`\n- `torch.squeeze`\n- `torch.sub`\n- `torch.sum`\n- `torch.transpose`\n- `torch.unsqueeze`\n- `torch.linalg.cholesky`\n- `torch.linalg.eigh`\n- `torch.linalg.eigvalsh`\n- `torch.linalg.solve`\n- `torch.linalg.svd`\n\nEach of these functions will either return a `torch.Tensor`, or a new `LinearOperator` object,\ndepending on the function.\nFor example:\n\n```python\n# A = RootLinearOperator(...)\n# B = ToeplitzLinearOperator(...)\n# d = vec\n\nC = torch.matmul(A, B)  # A new LienearOperator representing the product of A and B\ntorch.linalg.solve(C, d)  # A torch.Tensor\n```\n\nFor more examples, see the [examples folder](https://github.com/cornellius-gp/linear_operator/blob/main/examples/).\n\n### Batch Support and Broadcasting\n\n`LinearOperator` objects operate naturally in batch mode.\nFor example, to represent a batch of 3 `100 x 100` diagonal matrices:\n\n```python\n# d = torch.randn(3, 100)\nD = DiagLinearOperator(d)  # Reprents an operator of size 3 x 100 x 100\n```\n\nThese objects fully support broadcasted operations:\n\n```python\nD @ torch.randn(100, 2)  # Returns a tensor of size 3 x 100 x 2\n\nD2 = DiagLinearOperator(torch.randn([2, 1, 100]))  # Represents an operator of size 2 x 1 x 100 x 100\nD2 + D  # Represents an operator of size 2 x 3 x 100 x 100\n```\n\n### Indexing\n\n`LinearOperator` objects can be indexed in ways similar to torch Tensors. This includes:\n- Integer indexing (get a row, column, or batch)\n- Slice indexing (get a subset of rows, columns, or batches)\n- LongTensor indexing (get a set of individual entries by index)\n- Ellipses (support indexing operations with arbitrary batch dimensions)\n\n```python\nD = DiagLinearOperator(torch.randn(2, 3, 100))  # Represents an operator of size 2 x 3 x 100 x 100\nD[-1]  # Returns a 3 x 100 x 100 operator\nD[..., :10, -5:]  # Returns a 2 x 3 x 10 x 5 operator\nD[..., torch.LongTensor([0, 1, 2, 3]), torch.LongTensor([0, 1, 2, 3])]  # Returns a 2 x 3 x 4 tensor\n```\n\n### Composition and Decoration\nLinearOperators can be composed with one another in various ways.\nThis includes\n- Addition (`LinearOpA + LinearOpB`)\n- Matrix multiplication (`LinearOpA @ LinearOpB`)\n- Concatenation (`torch.cat([LinearOpA, LinearOpB], dim=-2)`)\n- Kronecker product (`torch.kron(LinearOpA, LinearOpB)`)\n\nIn addition, there are many ways to \"decorate\" LinearOperator objects.\nThis includes:\n- Elementwise multiplying by constants (`torch.mul(2., LinearOpA)`)\n- Summing over batches (`torch.sum(LinearOpA, dim=-3)`)\n- Elementwise multiplying over batches (`torch.prod(LinearOpA, dim=-3)`)\n\nSee the documentation for a [full list of supported composition and decoration operations](https://linear-operator.readthedocs.io/en/latest/composition_decoration_operators.html).\n\n\n<!-- docs_using_end -->\n<!-- docs_install_start -->\n\n\n## Installation\n\nLinearOperator requires Python >= 3.8.\n\n### Standard Installation (Most Recent Stable Version)\nWe recommend installing via `pip` or Anaconda:\n\n```sh\npip install linear_operator\n# or\nconda install linear_operator -c gpytorch\n```\n\nThe installation requires the following packages:\n- PyTorch >= 1.11\n- Scipy\n\nYou can customize your PyTorch installation (i.e. CUDA version, CPU only option)\nby following the [PyTorch installation instructions](https://pytorch.org/get-started/locally/).\n\n### Installing from the `main` Branch (Latest Unsable Version)\nTo install what is currently on the `main` branch (potentially buggy and unstable):\n\n```sh\npip install --upgrade git+https://github.com/cornellius-gp/linear_operator.git\n```\n\n\n<!-- docs_install_end -->\n\n\n### Development Installation\nIf you are contributing a pull request, it is best to perform a manual installation:\n\n```sh\ngit clone https://github.com/cornellius-gp/linear_operator.git\ncd linear_operator\npip install -e .[dev,test]\n```\n\nTo generate the documentation locally, you will also need to run the following command\nfrom the linear_operator folder:\n\n```sh\npip install -r docs/requirements.txt\n```\n\n\n## Contributing\n\nSee the contributing guidelines [CONTRIBUTING.md](https://github.com/cornellius-gp/linear_operator/blob/main/CONTRIBUTING.md)\nfor information on submitting issues and pull requests.\n\n\n## License\n\nLinearOperator is [MIT licensed](https://github.com/cornellius-gp/linear_operator/blob/main/LICENSE).\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "linear-operator",
    "package_url": "https://pypi.org/project/linear-operator/",
    "platform": null,
    "project_url": "https://pypi.org/project/linear-operator/",
    "project_urls": {
      "Documentation": "https://linear_operator.readthedocs.io",
      "Source": "https://github.com/cornellius-gp/linear_operator/"
    },
    "release_url": "https://pypi.org/project/linear-operator/0.3.0/",
    "requires_dist": [
      "torch (>=1.11)",
      "scipy",
      "black ; extra == 'dev'",
      "twine ; extra == 'dev'",
      "pre-commit ; extra == 'dev'",
      "flake8 (==4.0.1) ; extra == 'test'",
      "flake8-print (==4.0.0) ; extra == 'test'"
    ],
    "requires_python": ">=3.8",
    "summary": "A linear operator implementation, primarily designed for finite-dimensional positive definite operators (i.e. kernel matrices).",
    "version": "0.3.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 15932641,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "16b026e578508e127183d67c3aff9e34319df90538e2ea1a27d1414c979e8d86",
          "md5": "e660a74edc4caea96fbdfbdc7243c4b3",
          "sha256": "78a91699a7d6f52d0ab4b4fc0ceaf6dc773c7a96da25dcf25146914268150a4d"
        },
        "downloads": -1,
        "filename": "linear_operator-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "e660a74edc4caea96fbdfbdc7243c4b3",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 144880,
        "upload_time": "2022-08-11T20:57:43",
        "upload_time_iso_8601": "2022-08-11T20:57:43.146215Z",
        "url": "https://files.pythonhosted.org/packages/16/b0/26e578508e127183d67c3aff9e34319df90538e2ea1a27d1414c979e8d86/linear_operator-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "728433f54e27f1f70d48f9d2973f8c1ad88733f70edb2e742f64fc97efb82ec8",
          "md5": "f6a6c5143144a80bf4cdb93654e76baa",
          "sha256": "13260c99ede5bc3c6c052d7b3f9a5abf71da45d65843a9f0090f9639c01d3a32"
        },
        "downloads": -1,
        "filename": "linear_operator-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "f6a6c5143144a80bf4cdb93654e76baa",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 141921,
        "upload_time": "2022-08-11T20:57:44",
        "upload_time_iso_8601": "2022-08-11T20:57:44.411259Z",
        "url": "https://files.pythonhosted.org/packages/72/84/33f54e27f1f70d48f9d2973f8c1ad88733f70edb2e742f64fc97efb82ec8/linear_operator-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e63ca2cbf56429c4e370cdcd76155fc1068d21a812c67655244f0776a27697c7",
          "md5": "d95201c3415e1477a31ec0dfe6d8557e",
          "sha256": "55472043408959f04c8eb6153bc68a487b141b8c1f2fdb84afcdf6c2e04e01f0"
        },
        "downloads": -1,
        "filename": "linear_operator-0.1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d95201c3415e1477a31ec0dfe6d8557e",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 145938,
        "upload_time": "2022-08-16T21:59:15",
        "upload_time_iso_8601": "2022-08-16T21:59:15.862185Z",
        "url": "https://files.pythonhosted.org/packages/e6/3c/a2cbf56429c4e370cdcd76155fc1068d21a812c67655244f0776a27697c7/linear_operator-0.1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a44e01b6cf45b4df1c727b290befe71c12737d989f8b6c227a3791cc460e53e7",
          "md5": "d1f84a4cdc436124aec711b4bace87f5",
          "sha256": "81adc1aea9e98f3c4f07f5608eb77b689bc61793e9beebfea82155e9237bf1be"
        },
        "downloads": -1,
        "filename": "linear_operator-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "d1f84a4cdc436124aec711b4bace87f5",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 142904,
        "upload_time": "2022-08-16T21:59:17",
        "upload_time_iso_8601": "2022-08-16T21:59:17.149928Z",
        "url": "https://files.pythonhosted.org/packages/a4/4e/01b6cf45b4df1c727b290befe71c12737d989f8b6c227a3791cc460e53e7/linear_operator-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "57aed5062fbbfe447142d5a6ba8ae96a1c237d1997668ed714f5a4ef4bdcb421",
          "md5": "87e928a936993e0b88141994c22cc328",
          "sha256": "14c687de5aad42e16eed5c0712285e8dd497b5a3b1d8ce7bb71f6b5acb15290f"
        },
        "downloads": -1,
        "filename": "linear_operator-0.2.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "87e928a936993e0b88141994c22cc328",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 152989,
        "upload_time": "2022-11-08T00:29:50",
        "upload_time_iso_8601": "2022-11-08T00:29:50.315277Z",
        "url": "https://files.pythonhosted.org/packages/57/ae/d5062fbbfe447142d5a6ba8ae96a1c237d1997668ed714f5a4ef4bdcb421/linear_operator-0.2.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "240ea07c824d025f8f0af0046740121aec49045fa1ed62059d25074c43b9a597",
          "md5": "4f76fd85fb79c32b136974cf3bbd02e5",
          "sha256": "55fc7804b9bd050f61d68542fcb4a5870ec1dbd10f663c159cb3dfb29e8ec7f2"
        },
        "downloads": -1,
        "filename": "linear_operator-0.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "4f76fd85fb79c32b136974cf3bbd02e5",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 164867,
        "upload_time": "2022-11-08T00:29:51",
        "upload_time_iso_8601": "2022-11-08T00:29:51.978535Z",
        "url": "https://files.pythonhosted.org/packages/24/0e/a07c824d025f8f0af0046740121aec49045fa1ed62059d25074c43b9a597/linear_operator-0.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3bc3d8cad67ed11f8a270c318b1eae726b4c8fa17df33108811b4e79bc2f438c",
          "md5": "462e80ec507aee47f799a8bcd3853ca8",
          "sha256": "262b1028ed3cd1ae70d79a3a29b0210301576d9e426a68b8767acdd4abb116a6"
        },
        "downloads": -1,
        "filename": "linear_operator-0.3.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "462e80ec507aee47f799a8bcd3853ca8",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 155632,
        "upload_time": "2022-11-29T20:28:49",
        "upload_time_iso_8601": "2022-11-29T20:28:49.763525Z",
        "url": "https://files.pythonhosted.org/packages/3b/c3/d8cad67ed11f8a270c318b1eae726b4c8fa17df33108811b4e79bc2f438c/linear_operator-0.3.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b75e93ac72a5caf0ba84c683328485269d19615b4c2d0877e0bae19811addb78",
          "md5": "62931220a0be09f73735a2e22e7e9296",
          "sha256": "84bf572631a7e1576de6920d81600ca0fedcf6bda2f29dbaf440d6e72ce6abab"
        },
        "downloads": -1,
        "filename": "linear_operator-0.3.0.tar.gz",
        "has_sig": false,
        "md5_digest": "62931220a0be09f73735a2e22e7e9296",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 167887,
        "upload_time": "2022-11-29T20:28:51",
        "upload_time_iso_8601": "2022-11-29T20:28:51.217560Z",
        "url": "https://files.pythonhosted.org/packages/b7/5e/93ac72a5caf0ba84c683328485269d19615b4c2d0877e0bae19811addb78/linear_operator-0.3.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "3bc3d8cad67ed11f8a270c318b1eae726b4c8fa17df33108811b4e79bc2f438c",
        "md5": "462e80ec507aee47f799a8bcd3853ca8",
        "sha256": "262b1028ed3cd1ae70d79a3a29b0210301576d9e426a68b8767acdd4abb116a6"
      },
      "downloads": -1,
      "filename": "linear_operator-0.3.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "462e80ec507aee47f799a8bcd3853ca8",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.8",
      "size": 155632,
      "upload_time": "2022-11-29T20:28:49",
      "upload_time_iso_8601": "2022-11-29T20:28:49.763525Z",
      "url": "https://files.pythonhosted.org/packages/3b/c3/d8cad67ed11f8a270c318b1eae726b4c8fa17df33108811b4e79bc2f438c/linear_operator-0.3.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "b75e93ac72a5caf0ba84c683328485269d19615b4c2d0877e0bae19811addb78",
        "md5": "62931220a0be09f73735a2e22e7e9296",
        "sha256": "84bf572631a7e1576de6920d81600ca0fedcf6bda2f29dbaf440d6e72ce6abab"
      },
      "downloads": -1,
      "filename": "linear_operator-0.3.0.tar.gz",
      "has_sig": false,
      "md5_digest": "62931220a0be09f73735a2e22e7e9296",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.8",
      "size": 167887,
      "upload_time": "2022-11-29T20:28:51",
      "upload_time_iso_8601": "2022-11-29T20:28:51.217560Z",
      "url": "https://files.pythonhosted.org/packages/b7/5e/93ac72a5caf0ba84c683328485269d19615b4c2d0877e0bae19811addb78/linear_operator-0.3.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}