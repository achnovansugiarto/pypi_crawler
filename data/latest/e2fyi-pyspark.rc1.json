{
  "info": {
    "author": "eterna2",
    "author_email": "eterna2@hotmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 2 - Pre-Alpha",
      "Intended Audience :: Developers",
      "Natural Language :: English",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7"
    ],
    "description": "# e2fyi-pyspark\n\n[![PyPI version](https://badge.fury.io/py/e2fyi-pyspark.svg)](https://badge.fury.io/py/e2fyi-pyspark)\n[![Build Status](https://travis-ci.org/e2fyi/pyspark-utils.svg?branch=master)](https://travis-ci.org/e2fyi/pyspark-utils)\n[![Coverage Status](https://coveralls.io/repos/github/e2fyi/pyspark-utils/badge.svg?branch=master)](https://coveralls.io/github/e2fyi/pyspark-utils?branch=master)\n[![Documentation Status](https://readthedocs.org/projects/e2fyi-pyspark/badge/?version=latest)](https://e2fyi-pyspark.readthedocs.io/en/latest/?badge=latest)\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n[![Downloads](https://pepy.tech/badge/e2fyi-pyspark)](https://pepy.tech/project/e2fyi-pyspark)\n\n`e2fyi-pyspark` is an `e2fyi` namespaced python package with `pyspark` subpackage\n(i.e. `e2fyi.pyspark`) which holds a collections of useful functions for common\nbut painful pyspark tasks.\n\nAPI documentation can be found at [https://e2fyi-pyspark.readthedocs.io/en/latest/](https://e2fyi-pyspark.readthedocs.io/en/latest/).\n\nChange logs are available in [CHANGELOG.md](./CHANGELOG.md).\n\n> - Python 3.6 and above\n> - Licensed under [Apache-2.0](./LICENSE).\n\n## Quickstart\n\n```bash\npip install e2fyi-pyspark\n```\n\n### Infer schema for unknown json strings inside a pyspark dataframe\n\n`e2fyi.pyspark.schema.infer_schema_from_rows` is a util function to infer the\nschema of unknown json strings inside a pyspark dataframe - i.e. so that the\nschema can be subsequently used to parse the json string into a typed data\nstructure in the dataframe\n(see [`pyspark.sql.functions.from_json`](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.from_json)).\n\n```py\nimport pyspark\nfrom e2fyi.pyspark.schema import infer_schema_from_rows\n\n# get spark session\nspark = pyspark.sql.SparkSession.builder.getOrCreate()\n# load a parquet (assume the parquet has a column \"json_str\", which\n# contains a json str with unknown schema)\ndf = spark.read.parquet(\"s3://some-bucket/some-file.parquet\")\n# get 10% of the rows as sample (w/o replacement)\nsample_rows = df.select(\"json_str\").sample(False, 0.01).collect()\n# infer the schema for json str in col \"json_str\" based on the sample rows\n# NOTE: this is run locally (not in spark)\nschema = infer_schema_from_rows(sample_rows, col=\"json_str\")\n# add a new column \"data\" which is the parsed json string with a inferred schema\ndf = df.withColumn(\"data\", pyspark.sql.functions.from_json(\"json_str\", schema))\n# should have a column \"data\" with a proper schema\ndf.printSchema()\n```",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/e2fyi/pyspark-utils",
    "keywords": "util pyspark",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "e2fyi-pyspark",
    "package_url": "https://pypi.org/project/e2fyi-pyspark/",
    "platform": "",
    "project_url": "https://pypi.org/project/e2fyi-pyspark/",
    "project_urls": {
      "Homepage": "https://github.com/e2fyi/pyspark-utils"
    },
    "release_url": "https://pypi.org/project/e2fyi-pyspark/0.1.0a1/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "Productivity functions for common but painful pyspark tasks.",
    "version": "0.1.0a1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 6365002,
  "releases": {
    "0.1.0a1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9daf0377f641477d3cf1f259e30626e7ac05e7ddf3cef6c4490a8f82e83de205",
          "md5": "65c80f24e5e9bfb246fbf1faf1e191e4",
          "sha256": "5803e03f99958c919d80296bb5924e0370dea959ac4fdfdb76d6a5d182197087"
        },
        "downloads": -1,
        "filename": "e2fyi-pyspark-0.1.0a1.tar.gz",
        "has_sig": false,
        "md5_digest": "65c80f24e5e9bfb246fbf1faf1e191e4",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 8845,
        "upload_time": "2019-12-27T11:21:07",
        "upload_time_iso_8601": "2019-12-27T11:21:07.869797Z",
        "url": "https://files.pythonhosted.org/packages/9d/af/0377f641477d3cf1f259e30626e7ac05e7ddf3cef6c4490a8f82e83de205/e2fyi-pyspark-0.1.0a1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "9daf0377f641477d3cf1f259e30626e7ac05e7ddf3cef6c4490a8f82e83de205",
        "md5": "65c80f24e5e9bfb246fbf1faf1e191e4",
        "sha256": "5803e03f99958c919d80296bb5924e0370dea959ac4fdfdb76d6a5d182197087"
      },
      "downloads": -1,
      "filename": "e2fyi-pyspark-0.1.0a1.tar.gz",
      "has_sig": false,
      "md5_digest": "65c80f24e5e9bfb246fbf1faf1e191e4",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 8845,
      "upload_time": "2019-12-27T11:21:07",
      "upload_time_iso_8601": "2019-12-27T11:21:07.869797Z",
      "url": "https://files.pythonhosted.org/packages/9d/af/0377f641477d3cf1f259e30626e7ac05e7ddf3cef6c4490a8f82e83de205/e2fyi-pyspark-0.1.0a1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}