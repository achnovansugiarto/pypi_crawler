{
  "info": {
    "author": "Aaron Schroeder",
    "author_email": "aaron@trailzealot.com",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.8"
    ],
    "description": "# scrapy-athlinks: web scraper for race results hosted on Athlinks\n\n[![License](https://img.shields.io/github/license/aaron-schroeder/athlinks-scraper-scrapy)](LICENSE)\n[![Python 3.8](https://img.shields.io/badge/python-3.8-blue.svg)](https://www.python.org/downloads/release/python-3810/)\n[![PyPI](https://img.shields.io/pypi/v/scrapy-athlinks.svg)](https://pypi.python.org/pypi/scrapy-athlinks/)\n\n<!--## Documentation\n\nThe official documentation is hosted on readthedocs.io: https://athlinks-scraper-scrapy.readthedocs.io/en/stable. -->\n\n## Introduction\n\n`scrapy-athlinks` provides the [`RaceSpider`](scrapy_athlinks/spiders/race.py) class.\n\nThis spider crawls through all results pages from a race hosted on athlinks.com,\nbuilding and following links to each athlete's individual results page, where it\ncollects their split data. It also collects some metadata about the race itself.\n\nBy default, the spider returns one race metadata object (`RaceItem`), and one\n`AthleteItem` per participant. \nEach `AthleteItem` consists of some basic athlete info and a list of `RaceSplitItem`\ncontaining data from each split they recorded.\n\n## How to use this package\n\n### Option 1: In python scripts\n\nScrapy can be operated entirely from python scripts.\n[See the scrapy documentation for more info.](https://docs.scrapy.org/en/latest/topics/practices.html#run-scrapy-from-a-script)\n\n#### Installation\n\nThe package is available on [PyPi](https://pypi.org/project/scrapy-athlinks) and can be installed with `pip`:\n\n```sh\npip install scrapy-athlinks\n```\n\n#### Example usage\n\n[An demo script is included in this repo](demo.py).\n\n```python\nfrom scrapy.crawler import CrawlerProcess\nfrom scrapy_athlinks import RaceSpider, AthleteItem, RaceItem\n\n\nsettings = {\n  'FEEDS': {\n    # Athlete data. Inside this file will be a list of dicts containing\n    # data about each athlete's race and splits.\n    'athletes.json': {\n      'format':'json',\n      'overwrite': True,\n      'item_classes': [AthleteItem],\n    },\n    # Race metadata. Inside this file will be a list with a single dict\n    # containing info about the race itself.\n    'metadata.json': {\n      'format':'json',\n      'overwrite': True,\n      'item_classes': [RaceItem],\n    },\n  }\n}\nprocess = CrawlerProcess(settings=settings)\n\n# Crawl results for the 2022 Leadville Trail 100 Run\nprocess.crawl(RaceSpider, 'https://www.athlinks.com/event/33913/results/Event/1018673/')\nprocess.start()\n```\n\n### Option 2: Command line\n\nAlternatively, you may clone this repo for use like a typical Scrapy project\nthat you might create on your own.\n\n#### Installation\n\n```sh\ngit clone https://github.com/aaron-schroeder/athlinks-scraper-scrapy\ncd athlinks-scraper-scrapy\npip install -r requirements.txt\n```\n\n#### Example usage\n\nRun a `RaceSpider`:\n\n```sh\ncd scrapy_athlinks\nscrapy crawl race -a url=https://www.athlinks.com/event/33913/results/Event/1018673 -O out.json\n```\n\n## Dependencies\n\nAll that is required is [Scrapy](https://scrapy.org/) (and its dependencies).\n\n## Testing\n\n```\nmake test\n```\n\n## License\n\n[![License](https://img.shields.io/github/license/aaron-schroeder/athlinks-scraper-scrapy)](LICENSE)\n\nThis project is licensed under the MIT License. See\n[LICENSE](LICENSE) file for details.\n\n## Contact\n\nYou can get in touch with me at the following places:\n\n- Website: [trailzealot.com](https://trailzealot.com)\n- LinkedIn: [linkedin.com/in/aarondschroeder](https://www.linkedin.com/in/aarondschroeder/)\n- GitHub: [github.com/aaron-schroeder](https://github.com/aaron-schroeder)\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/aaron-schroeder/athlinks-scraper-scrapy",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "scrapy-athlinks",
    "package_url": "https://pypi.org/project/scrapy-athlinks/",
    "platform": null,
    "project_url": "https://pypi.org/project/scrapy-athlinks/",
    "project_urls": {
      "Homepage": "https://github.com/aaron-schroeder/athlinks-scraper-scrapy"
    },
    "release_url": "https://pypi.org/project/scrapy-athlinks/0.0.1/",
    "requires_dist": [
      "Scrapy (==2.6.2)"
    ],
    "requires_python": "",
    "summary": "Web scraper for race results hosted on Athlinks.",
    "version": "0.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 15125222,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0877c152c17f5b395cf375189d8eb53aaaf66172c61e0c79c6cd6a983ae34f0b",
          "md5": "62115dcbadf195b2c1bd3608b6f6c0a4",
          "sha256": "474a04d10e070197d9c97ffcf40f83bef90ca2e995c3e7a2723f272ebced6760"
        },
        "downloads": -1,
        "filename": "scrapy_athlinks-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "62115dcbadf195b2c1bd3608b6f6c0a4",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 9696,
        "upload_time": "2022-09-17T06:43:06",
        "upload_time_iso_8601": "2022-09-17T06:43:06.897956Z",
        "url": "https://files.pythonhosted.org/packages/08/77/c152c17f5b395cf375189d8eb53aaaf66172c61e0c79c6cd6a983ae34f0b/scrapy_athlinks-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3a786dcf45c068f31b57e6305bd3a834687694526ecc3d09a1cf75d3edf96953",
          "md5": "8241ee2335c635bdcb240bddb2bfb882",
          "sha256": "8e2a6d541f16438ca75f256c8ca3a66b2ef0112b591bc58cc1b546b7754b3312"
        },
        "downloads": -1,
        "filename": "scrapy-athlinks-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "8241ee2335c635bdcb240bddb2bfb882",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 10417,
        "upload_time": "2022-09-17T06:43:08",
        "upload_time_iso_8601": "2022-09-17T06:43:08.562121Z",
        "url": "https://files.pythonhosted.org/packages/3a/78/6dcf45c068f31b57e6305bd3a834687694526ecc3d09a1cf75d3edf96953/scrapy-athlinks-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "0877c152c17f5b395cf375189d8eb53aaaf66172c61e0c79c6cd6a983ae34f0b",
        "md5": "62115dcbadf195b2c1bd3608b6f6c0a4",
        "sha256": "474a04d10e070197d9c97ffcf40f83bef90ca2e995c3e7a2723f272ebced6760"
      },
      "downloads": -1,
      "filename": "scrapy_athlinks-0.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "62115dcbadf195b2c1bd3608b6f6c0a4",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 9696,
      "upload_time": "2022-09-17T06:43:06",
      "upload_time_iso_8601": "2022-09-17T06:43:06.897956Z",
      "url": "https://files.pythonhosted.org/packages/08/77/c152c17f5b395cf375189d8eb53aaaf66172c61e0c79c6cd6a983ae34f0b/scrapy_athlinks-0.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "3a786dcf45c068f31b57e6305bd3a834687694526ecc3d09a1cf75d3edf96953",
        "md5": "8241ee2335c635bdcb240bddb2bfb882",
        "sha256": "8e2a6d541f16438ca75f256c8ca3a66b2ef0112b591bc58cc1b546b7754b3312"
      },
      "downloads": -1,
      "filename": "scrapy-athlinks-0.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "8241ee2335c635bdcb240bddb2bfb882",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 10417,
      "upload_time": "2022-09-17T06:43:08",
      "upload_time_iso_8601": "2022-09-17T06:43:08.562121Z",
      "url": "https://files.pythonhosted.org/packages/3a/78/6dcf45c068f31b57e6305bd3a834687694526ecc3d09a1cf75d3edf96953/scrapy-athlinks-0.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}