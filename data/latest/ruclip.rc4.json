{
  "info": {
    "author": "SberAI, SberDevices",
    "author_email": "shonenkov@phystech.edu",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# RuCLIP\n\nZero-shot image classification model for Russian language\n\n---\n\n**RuCLIP** (**Ru**ssian **C**ontrastive **L**anguage–**I**mage **P**retraining) is a multimodal model\nfor obtaining images and text similarities and rearranging captions and pictures.\nRuCLIP builds on a large body of work on zero-shot transfer, computer vision, natural language processing and\nmultimodal learning. This repo has the prototypes model of OpenAI CLIP's Russian version following [this paper](https://arxiv.org/abs/2103.00020).\n\n# Models\n\n+ [ruclip-vit-base-patch32-224](https://huggingface.co/sberbank-ai/ruclip-vit-base-patch32-224) 🤗\n+ [ruclip-vit-base-patch16-224](https://huggingface.co/sberbank-ai/ruclip-vit-base-patch16-224) 🤗\n+ [ruclip-vit-large-patch14-224](https://huggingface.co/sberbank-ai/ruclip-vit-large-patch14-224) 🤗\n+ [ruclip-vit-base-patch32-384](https://huggingface.co/sberbank-ai/ruclip-vit-base-patch32-384) 🤗\n+ [ruclip-vit-large-patch14-336](https://huggingface.co/sberbank-ai/ruclip-vit-large-patch14-336) 🤗\n+ [ruclip-vit-base-patch16-384](https://huggingface.co/sberbank-ai/ruclip-vit-base-patch16-384) 🤗\n\n# Installing\n\n```\npip install ruclip==0.0.2\n```\n\n# Usage\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1vXu3s0rcAOEAciz7B3vmVHd4J_gUJnk9?usp=sharing)\nStandart RuCLIP API\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1hgu7GNfBriLmAHg1oskdNIQsc0WJMwDa?usp=sharing)\nRuCLIP + SberVqgan\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Lednik7/CLIP-ONNX/blob/main/examples/RuCLIP_onnx_example.ipynb)\nONNX example\n\n### Init models\n\n```python\nimport ruclip\n\ndevice = 'cuda'\nclip, processor = ruclip.load('ruclip-vit-base-patch32-384', device=device)\n```\n\n### Zero-Shot Classification [Minimal Example]\n\n```python\nimport torch\nimport base64\nimport requests\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom io import BytesIO\n\n# prepare images\nbs4_urls = requests.get('https://raw.githubusercontent.com/sberbank-ai/ru-dolph/master/pics/pipelines/cats_vs_dogs_bs4.json').json()\nimages = [Image.open(BytesIO(base64.b64decode(bs4_url))) for bs4_url in bs4_urls]\n\n# prepare classes\nclasses = ['кошка', 'собака']\ntemplates = ['{}', 'это {}', 'на картинке {}', 'это {}, домашнее животное']\n\n# predict\npredictor = ruclip.Predictor(clip, processor, device, bs=8, templates=templates)\nwith torch.no_grad():\n    text_latents = predictor.get_text_latents(classes)\n    pred_labels = predictor.run(images, text_latents)\n\n# show results\nf, ax = plt.subplots(2,4, figsize=(12,6))\nfor i, (pil_img, pred_label) in enumerate(zip(images, pred_labels)):\n    ax[i//4, i%4].imshow(pil_img)\n    ax[i//4, i%4].set_title(classes[pred_label])\n```\n\n![](./pics/cats_vs_dogs.png)\n\n### Cosine similarity Visualization Example\n\n![](./pics/cosine_example.png)\n\n### Softmax Scores Visualization Example\n\n![](./pics/softmax_example.png)\n\n### Linear Probe and ZeroShot Correlation Results\n\n![](./pics/ruclip_large_336_corr.png)\n\n### Linear Probe Example\n\n```python\ntrain = CIFAR100(root, download=True, train=True)\ntest = CIFAR100(root, download=True, train=False)\n\nwith torch.no_grad():\n    X_train = predictor.get_image_latents((pil_img for pil_img, _ in train)).cpu().numpy()\n    X_test = predictor.get_image_latents((pil_img for pil_img, _ in test)).cpu().numpy()\n    y_train, y_test = np.array(train.targets), np.array(test.targets)\n\nclf = LogisticRegression(solver='lbfgs', penalty='l2', max_iter=1000, verbose=1)\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\naccuracy = np.mean((y_test == y_pred).astype(np.float)) * 100.\nprint(f\"Accuracy = {accuracy:.3f}\")\n```\n\n`>>> Accuracy = 75.680`\n\n# Performance\n\nWe have evaluated the performance zero-shot image classification on the following datasets:\n\n\n| Dataset                       | [ruCLIP Base \\[vit-base-patch32-224\\]](https://huggingface.co/sberbank-ai/ruclip-vit-base-patch32-224) | [ruCLIP Base \\[vit-base-patch16-224\\]](https://huggingface.co/sberbank-ai/ruclip-vit-base-patch16-224) | [ruCLIP Large \\[vit-large-patch14-224\\]](https://huggingface.co/sberbank-ai/ruclip-vit-large-patch14-224) | [ruCLIP Base \\[vit-base-patch32-384\\]](https://huggingface.co/sberbank-ai/ruclip-vit-base-patch32-384) | [ruCLIP Large \\[vit-large-patch14-336\\]](https://huggingface.co/sberbank-ai/ruclip-vit-large-patch14-336) | [ruCLIP Base \\[vit-base-patch16-384\\]](https://huggingface.co/sberbank-ai/ruclip-vit-base-patch16-384) | CLIP \\[vit-base-patch16-224\\] original + [OPUS-MT](https://huggingface.co/Helsinki-NLP/opus-mt-ru-en) | CLIP \\[vit-base-patch16-224\\] original |\n| :----------------------------- | :------------------------------------------------------------------------------------------------------ | :------------------------------------------------------------------------------------------------------ | :--------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------ | :-------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------- | :-------------------------------------- |\n| Food101, acc                  | 0.505                                                                                                  | 0.552                                                                                                  | 0.597                                                                                                     | 0.642                                                                                                  | **0.712**💥                                                                                                 | 0.689                                                                                                   | 0.664                                                                                                 | 0.883                                  |\n| CIFAR10, acc                  | 0.818                                                                                                  | 0.810                                                                                                  | 0.878                                                                                                     | 0.862                                                                                                  | **0.906**💥                                                                                                 | 0.845                                                                                                   | 0.859                                                                                                 | 0.893                                  |\n| CIFAR100, acc                 | 0.504                                                                                                  | 0.496                                                                                                  | 0.511                                                                                                     | 0.529                                                                                                  | 0.591                                                                                                    | 0.569                                                                                                   | **0.603**💥                                                                                               | 0.647                                  |\n| Birdsnap, acc                 | 0.115                                                                                                  | 0.117                                                                                                  | 0.172                                                                                                     | 0.161                                                                                                  | **0.213**💥                                                                                                 | 0.195                                                                                                   | 0.126                                                                                                 | 0.396                                  |\n| SUN397, acc                   | 0.452                                                                                                  | 0.462                                                                                                  | 0.484                                                                                                     | 0.510                                                                                                  | **0.523**💥                                                                                                 | 0.521                                                                                                   | 0.447                                                                                                 | 0.631                                  |\n| Stanford Cars, acc            | 0.433                                                                                                  | 0.487                                                                                                  | 0.559                                                                                                     | 0.572                                                                                                  | **0.659**💥                                                                                                 | 0.626                                                                                                   | 0.567                                                                                                 | 0.638                                  |\n| DTD, acc                      | 0.380                                                                                                  | 0.401                                                                                                  | 0.370                                                                                                     | 0.390                                                                                                  | 0.408                                                                                                    | **0.421**💥                                                                                                | 0.243                                                                                                 | 0.432                                  |\n| MNIST, acc                    | 0.447                                                                                                  | 0.464                                                                                                  | 0.337                                                                                                     | 0.404                                                                                                  | 0.242                                                                                                    | 0.478                                                                                                   | **0.559**💥                                                                                              | 0.559                                  |\n| STL10, acc                    | 0.932                                                                                                  | 0.932                                                                                                  | 0.934                                                                                                     | 0.946                                                                                                  | 0.956                                                                                                    | 0.964                                                                                                   | **0.967**💥                                                                                              | 0.970                                  |\n| PCam, acc                     | 0.501                                                                                                  | 0.505                                                                                                  | 0.520                                                                                                     | 0.506                                                                                                  | 0.554                                                                                                    | 0.501                                                                                                   | **0.603**💥                                                                                              | 0.573                                  |\n| CLEVR, acc                    | 0.148                                                                                                  | 0.128                                                                                                  | 0.152                                                                                                     | 0.188                                                                                                  | 0.142                                                                                                    | 0.132                                                                                                   | **0.240**💥                                                                                              | 0.240                                  |\n| Rendered SST2, acc            | 0.489                                                                                                  | 0.527                                                                                                  | 0.529                                                                                                     | 0.508                                                                                                  | **0.539**💥                                                                                                 | 0.525                                                                                                   | 0.484                                                                                                 | 0.484                                  |\n| ImageNet, acc                 | 0.375                                                                                                  | 0.401                                                                                                  | 0.426                                                                                                     | 0.451                                                                                                  | **0.488**💥                                                                                                 | 0.482                                                                                                   | 0.392                                                                                                 | 0.638                                  |\n| FGVC Aircraft, mean-per-class | 0.033                                                                                                  | 0.043                                                                                                  | 0.046                                                                                                     | 0.053                                                                                                  | 0.075                                                                                                    | 0.046                                                                                                   | **0.220**💥                                                                                              | 0.244                                  |\n| Oxford Pets, mean-per-class   | 0.560                                                                                                  | 0.595                                                                                                  | 0.604                                                                                                     | 0.587                                                                                                  | 0.546                                                                                                    | **0.635**💥                                                                                                | 0.507                                                                                                 | 0.874                                  |\n| Caltech101, mean-per-class    | 0.786                                                                                                  | 0.775                                                                                                  | 0.777                                                                                                     | 0.834                                                                                                  | **0.835**💥                                                                                                 | **0.835**💥                                                                                                | 0.792                                                                                                 | 0.883                                  |\n| Flowers102, mean-per-class    | 0.401                                                                                                  | 0.388                                                                                                  | 0.455                                                                                                     | 0.449                                                                                                  | **0.517**💥                                                                                                 | 0.452                                                                                                   | 0.357                                                                                                 | 0.697                                  |\n| Hateful Memes, roc-auc        | 0.564                                                                                                  | 0.516                                                                                                  | 0.530                                                                                                     | 0.537                                                                                                  | 0.519                                                                                                    | 0.543                                                                                                   | **0.579**💥                                                                                              | 0.589                                  |\n\nAnd for linear-prob evaluation:\n\n| Dataset       | ruCLIP Base \\[vit-base-patch32-224\\] | ruCLIP Base \\[vit-base-patch16-224\\] | ruCLIP Large \\[vit-large-patch14-224\\] | ruCLIP Base \\[vit-base-patch32-384\\] | [ruCLIP Large \\[vit-large-patch14-336\\]](https://huggingface.co/sberbank-ai/ruclip-vit-large-patch14-336) | [ruCLIP Base \\[vit-base-patch16-384\\]](https://huggingface.co/sberbank-ai/ruclip-vit-base-patch16-384) | CLIP \\[vit-base-patch16-224\\] original |\n| :------------- | :------------------------------------ | :------------------------------------ | :-------------------------------------- | :------------------------------------ | :------------------------------------------------ | :----------------------------------------------- | :-------------------------------------- |\n| Food101       | 0.765                                | 0.827                                | 0.840                                  | 0.851                                | **0.896**💥                                         | 0.890                                           | 0.901                                  |\n| CIFAR10       | 0.917                                | 0.922                                | 0.927                                  | 0.934                                | **0.943**💥                                         | 0.942                                           | 0.953                                  |\n| CIFAR100      | 0.716                                | 0.739                                | 0.734                                  | 0.745                                | 0.770                                            | **0.773**💥                                        | 0.808                                  |\n| Birdsnap      | 0.347                                | 0.503                                | 0.567                                  | 0.434                                | 0.609                                            | **0.612**💥                                        | 0.664                                  |\n| SUN397        | 0.683                                | 0.721                                | 0.731                                  | 0.721                                | **0.759**💥                                         | 0.758                                           | 0.777                                  |\n| Stanford Cars | 0.697                                | 0.776                                | 0.797                                  | 0.766                                | 0.831                                            | **0.840**💥                                        | 0.866                                  |\n| DTD           | 0.690                                | 0.734                                | 0.711                                  | 0.703                                | 0.731                                            | **0.749**💥                                        | 0.770                                  |\n| MNIST         | 0.963                                | **0.974**💥                             | 0.949                                  | 0.965                                | 0.949                                            | 0.971                                           | 0.989                                  |\n| STL10         | 0.957                                | 0.962                                | 0.973                                  | 0.968                                | **0.981**💥                                         | 0.974                                           | 0.982                                  |\n| PCam          | 0.827                                | 0.823                                | 0.791                                  | 0.835                                | 0.807                                            | **0.846**💥                                        | 0.830                                  |\n| CLEVR         | 0.356                                | 0.360                                | 0.358                                  | 0.308                                | 0.318                                            | **0.378**💥                                        | 0.604                                  |\n| Rendered SST2 | 0.603                                | 0.655                                | 0.651                                  | 0.651                                | 0.637                                            | **0.661**💥                                        | 0.606                                  |\n| FGVC Aircraft | 0.254                                | 0.312                                | 0.290                                  | 0.283                                | 0.341                                            | **0.362**💥                                        | 0.604                                  |\n| Oxford Pets   | 0.774                                | 0.820                                | 0.819                                  | 0.730                                | 0.753                                            | **0.856**💥                                        | 0.931                                  |\n| Caltech101    | 0.904                                | 0.917                                | 0.914                                  | 0.922                                | **0.937**💥                                         | 0.932                                           | 0.956                                  |\n| HatefulMemes  | 0.545                                | 0.568                                | 0.563                                  | 0.581                                | **0.585**💥                                         | 0.578                                           | 0.645                                  |\n\nAlso, we have created speed comparison based on CIFAR100 dataset using Nvidia-V100 for evaluation:\n\n|          | ruclip-vit-base-patch32-224 | ruclip-vit-base-patch16-224 | ruclip-vit-large-patch14-224 | ruclip-vit-base-patch32-384 | ruclip-vit-large-patch14-336 | ruclip-vit-base-patch16-384 |\n|----------|-----------------------------|-----------------------------|------------------------------|-----------------------------|------------------------------|-----------------------------|\n| iter/sec | **308.84** 💥                  | 155.35                      | 49.95                        | 147.26                      | 22.11                        | 61.79                       |\n\n# Authors\n\n+ Alex Shonenkov: [Github](https://github.com/shonenkov), [Kaggle GM](https://www.kaggle.com/shonenkov)\n+ Daniil Chesakov: [Github](https://github.com/Danyache)\n+ Denis Dimitrov: [Github](https://github.com/denndimitrov)\n+ Igor Pavlov: [Github](https://github.com/boomb0om)\n+ Andrey Kuznetsov: [Github](https://github.com/kuznetsoffandrey)\n+ Anastasia Maltseva: [Github](https://github.com/NastyaMittseva)\n\n# Supported by\n\n[<img src=\"https://raw.githubusercontent.com/sberbank-ai/ru-dolph/master/pics/logo/airi-logo.png\" height=\"50\"/>](https://airi.net)\n\n### Social Media\n\n[![](./pics/habr.svg)](https://habr.com/ru/company/sberbank/blog/646447/)\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "ruclip",
    "package_url": "https://pypi.org/project/ruclip/",
    "platform": null,
    "project_url": "https://pypi.org/project/ruclip/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/ruclip/0.0.2/",
    "requires_dist": [
      "torch",
      "torchvision",
      "huggingface-hub (==0.2.1)",
      "youtokentome (~=1.0.6)",
      "more-itertools (==8.12.0)"
    ],
    "requires_python": "",
    "summary": "RuCLIP: Zero-shot image classification models for Russian language",
    "version": "0.0.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14557995,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "94897d7b6c83adb38ef0d7b5a2279a2dea72f2e095184da92ca03ace0b53ed8e",
          "md5": "13a8d3acbda39ea5c41ef537a7346979",
          "sha256": "6848def7e9b781226854072edf9300cd5be58f46c7a12523c11fbc0aa5ec1f7e"
        },
        "downloads": -1,
        "filename": "ruclip-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "13a8d3acbda39ea5c41ef537a7346979",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 14664,
        "upload_time": "2022-01-19T22:15:57",
        "upload_time_iso_8601": "2022-01-19T22:15:57.813959Z",
        "url": "https://files.pythonhosted.org/packages/94/89/7d7b6c83adb38ef0d7b5a2279a2dea72f2e095184da92ca03ace0b53ed8e/ruclip-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d23cf6a4c324fa15e2f70f3475f37d2c35d37c804378bdb46158b3d6229dc0a2",
          "md5": "4293ae339fb7908937902958057c589b",
          "sha256": "f4ab35ca91298253ce736868763e91fff032a429f0c02bfa90a43fbc679f75d9"
        },
        "downloads": -1,
        "filename": "ruclip-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "4293ae339fb7908937902958057c589b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 18181,
        "upload_time": "2022-01-19T22:15:59",
        "upload_time_iso_8601": "2022-01-19T22:15:59.711306Z",
        "url": "https://files.pythonhosted.org/packages/d2/3c/f6a4c324fa15e2f70f3475f37d2c35d37c804378bdb46158b3d6229dc0a2/ruclip-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.1rc5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e7bd25404feb37424108b7b64f3743a827295dcb8637e9db4f5dbcf580492639",
          "md5": "bfba5bb5036e67ab8949a6cdc0bf2ef2",
          "sha256": "298c80383d408e9c0b3e5e20baa3f47e5a2e931911b8389241a6b793ed0a1c1b"
        },
        "downloads": -1,
        "filename": "ruclip-0.0.1rc5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "bfba5bb5036e67ab8949a6cdc0bf2ef2",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 12207,
        "upload_time": "2022-01-09T22:45:48",
        "upload_time_iso_8601": "2022-01-09T22:45:48.952227Z",
        "url": "https://files.pythonhosted.org/packages/e7/bd/25404feb37424108b7b64f3743a827295dcb8637e9db4f5dbcf580492639/ruclip-0.0.1rc5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "dbc35682198c6eba536ed43877e3930b679e3f8a68b4a74a756bf88a1245262c",
          "md5": "bd60c978117d57df6524d1c9960d7713",
          "sha256": "579ce294633b94218c0f4beb9eb5a96eec85bdd3c55ce4104b113b0e5c950d08"
        },
        "downloads": -1,
        "filename": "ruclip-0.0.1rc5.tar.gz",
        "has_sig": false,
        "md5_digest": "bd60c978117d57df6524d1c9960d7713",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 12991,
        "upload_time": "2022-01-09T22:45:51",
        "upload_time_iso_8601": "2022-01-09T22:45:51.008774Z",
        "url": "https://files.pythonhosted.org/packages/db/c3/5682198c6eba536ed43877e3930b679e3f8a68b4a74a756bf88a1245262c/ruclip-0.0.1rc5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.1rc7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5a422bc34c4b00d339bb591adb8316e511953b71bfa8e577418c638fe5fd14c6",
          "md5": "b43d40fab434d733732c03cebba88f55",
          "sha256": "6eb5beb1105fc405f28c065679b004ebef96a68c3d616c47290dcf2b6b6ad951"
        },
        "downloads": -1,
        "filename": "ruclip-0.0.1rc7-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "b43d40fab434d733732c03cebba88f55",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 13145,
        "upload_time": "2022-01-11T07:51:07",
        "upload_time_iso_8601": "2022-01-11T07:51:07.713497Z",
        "url": "https://files.pythonhosted.org/packages/5a/42/2bc34c4b00d339bb591adb8316e511953b71bfa8e577418c638fe5fd14c6/ruclip-0.0.1rc7-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ca83fb255fb0a06a0ac198720be9195236d3f0168860c7d5a9bb4a2a02b615fe",
          "md5": "eb07828e7fc8c450202ca6de4e90d810",
          "sha256": "21e6d928088e354ef9574520b7aeb72f8ac04dc7141bc1658ab10c3a14c8524d"
        },
        "downloads": -1,
        "filename": "ruclip-0.0.1rc7.tar.gz",
        "has_sig": false,
        "md5_digest": "eb07828e7fc8c450202ca6de4e90d810",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 14681,
        "upload_time": "2022-01-11T07:51:09",
        "upload_time_iso_8601": "2022-01-11T07:51:09.872108Z",
        "url": "https://files.pythonhosted.org/packages/ca/83/fb255fb0a06a0ac198720be9195236d3f0168860c7d5a9bb4a2a02b615fe/ruclip-0.0.1rc7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e94acdb84c0ad2abc67edb06995c8fcc83a3e8244aed63e278d2acd5b5081af5",
          "md5": "f604dc601bb9132ac94177cc3f927c8e",
          "sha256": "9adf6504d70a917c0b09798871df0b757709cc79dc1f66df03c3776cbf20f4ce"
        },
        "downloads": -1,
        "filename": "ruclip-0.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f604dc601bb9132ac94177cc3f927c8e",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 14739,
        "upload_time": "2022-07-26T21:36:45",
        "upload_time_iso_8601": "2022-07-26T21:36:45.034704Z",
        "url": "https://files.pythonhosted.org/packages/e9/4a/cdb84c0ad2abc67edb06995c8fcc83a3e8244aed63e278d2acd5b5081af5/ruclip-0.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6fe58e09d95e944d46eabdaafea6aab494e311edece1c5f5631e212676c3ca5b",
          "md5": "60f1b008d8f058a6fcebfb35b8111b86",
          "sha256": "eaf18c3192ab6f5bed697676dfb460d00068c0d0e5461764dbbfbc76470822e6"
        },
        "downloads": -1,
        "filename": "ruclip-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "60f1b008d8f058a6fcebfb35b8111b86",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 18357,
        "upload_time": "2022-07-26T21:36:47",
        "upload_time_iso_8601": "2022-07-26T21:36:47.294881Z",
        "url": "https://files.pythonhosted.org/packages/6f/e5/8e09d95e944d46eabdaafea6aab494e311edece1c5f5631e212676c3ca5b/ruclip-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "e94acdb84c0ad2abc67edb06995c8fcc83a3e8244aed63e278d2acd5b5081af5",
        "md5": "f604dc601bb9132ac94177cc3f927c8e",
        "sha256": "9adf6504d70a917c0b09798871df0b757709cc79dc1f66df03c3776cbf20f4ce"
      },
      "downloads": -1,
      "filename": "ruclip-0.0.2-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "f604dc601bb9132ac94177cc3f927c8e",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 14739,
      "upload_time": "2022-07-26T21:36:45",
      "upload_time_iso_8601": "2022-07-26T21:36:45.034704Z",
      "url": "https://files.pythonhosted.org/packages/e9/4a/cdb84c0ad2abc67edb06995c8fcc83a3e8244aed63e278d2acd5b5081af5/ruclip-0.0.2-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "6fe58e09d95e944d46eabdaafea6aab494e311edece1c5f5631e212676c3ca5b",
        "md5": "60f1b008d8f058a6fcebfb35b8111b86",
        "sha256": "eaf18c3192ab6f5bed697676dfb460d00068c0d0e5461764dbbfbc76470822e6"
      },
      "downloads": -1,
      "filename": "ruclip-0.0.2.tar.gz",
      "has_sig": false,
      "md5_digest": "60f1b008d8f058a6fcebfb35b8111b86",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 18357,
      "upload_time": "2022-07-26T21:36:47",
      "upload_time_iso_8601": "2022-07-26T21:36:47.294881Z",
      "url": "https://files.pythonhosted.org/packages/6f/e5/8e09d95e944d46eabdaafea6aab494e311edece1c5f5631e212676c3ca5b/ruclip-0.0.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}