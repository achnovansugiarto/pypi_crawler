{
  "info": {
    "author": "Nupur Kumari",
    "author_email": "nupurkmr9@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: BSD License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Vision-aided GAN\n\n\n[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/ensembling-off-the-shelf-models-for-gan/image-generation-on-lsun-churches-256-x-256)](https://paperswithcode.com/sota/image-generation-on-lsun-churches-256-x-256?p=ensembling-off-the-shelf-models-for-gan)\n[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/ensembling-off-the-shelf-models-for-gan/image-generation-on-lsun-horse-256-x-256)](https://paperswithcode.com/sota/image-generation-on-lsun-horse-256-x-256?p=ensembling-off-the-shelf-models-for-gan)\n[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/ensembling-off-the-shelf-models-for-gan/image-generation-on-lsun-cat-256-x-256)](https://paperswithcode.com/sota/image-generation-on-lsun-cat-256-x-256?p=ensembling-off-the-shelf-models-for-gan)\n\n\n### [video](https://youtu.be/oHdyJNdQ9E4) | [website](https://www.cs.cmu.edu/~vision-aided-gan/) |   [paper](https://arxiv.org/abs/2112.09130)\n\nCan the collective *knowledge* from a large bank of pretrained vision models be leveraged to improve GAN training? If so, with so many models to choose from, which one(s) should be selected, and in what manner are they most effective?\n\nWe find that pretrained computer vision models can significantly improve performance when used in an ensemble of discriminators.  We propose an effective selection mechanism, by probing the linear separability between real and fake samples in pretrained model embeddings, choosing the most accurate model, and progressively adding it to the discriminator ensemble. Our method can improve GAN training in both limited data and large-scale settings.\n\n\nEnsembling Off-the-shelf Models for GAN Training <br>\n[Nupur Kumari](https://nupurkmr9.github.io/), [Richard Zhang](https://richzhang.github.io/), [Eli Shechtman](https://research.adobe.com/person/eli-shechtman/), [Jun-Yan Zhu](https://www.cs.cmu.edu/~junyanz/)<br>\nIn CVPR 2022\n\n\n### Pretrained Models\nOur final trained models can be downloaded at this [link](https://www.cs.cmu.edu/~vision-aided-gan/models/). For more details on usage please see README in the folder [stylegan2](https://github.com/nupurkmr9/vision-aided-gan/tree/main/stylegan2) and [biggan](https://github.com/nupurkmr9/vision-aided-gan/tree/main/biggan). \n\n### Vision-aided StyleGAN2 training\nPlease see [stylegan2](https://github.com/nupurkmr9/vision-aided-gan/tree/main/stylegan2) README for training StyleGAN2 models with our method. This code will reproduce all StyleGAN2 based results from our paper. \n\n### Vision-aided Discriminator in a custom GAN model\n\n`pip install vision-aided-loss`\n\ninstalling from github: `pip install git+https://github.com/nupurkmr9/vision-aided-gan.git` or\n```.bash\ngit clone https://github.com/nupurkmr9/vision-aided-gan.git\ncd vision-aided-gan\npip install .\n```\nFor details on off-the-shelf models please see [MODELS.md](docs/MODELS.md)\n\n```python\n\nimport vision_aided_loss\n\ndevice='cuda'\ndiscr = vision_aided_loss.Discriminator(cv_type='clip', loss_type='multilevel_sigmoid_s', device=device).to(device)\ndiscr.cv_ensemble.requires_grad_(False) # Freeze feature extractor\n\n# Sample images\nreal = sample_real_image()\nfake = G.forward(z)\n\n# Update discriminator discr\nlossD = discr(real, for_real=True) + discr(fake, for_real=False)\nlossD.backward()\n\n# Update generator G\nlossG = discr(fake, for_G=True)\nlossG.backward()\n\n# We recommend adding vision-aided adversarial loss after training GAN with standard loss till few warmup_iter.\n```\n\nArg details: \n\n* `cv_type`: name of the off-the-shelf model from `[clip, dino, swin, vgg, det_coco, seg_ade, face_seg, face_normals]`. Multiple models can be used with '+' separated model names. \n* `output_type`: output feature type from off-the-shelf models. should be one of `[conv, conv_multi_level]`. Supports `conv_multi_level` only for clip and dino. For multiple models output_type should be '+' separated output_type for each model. \n* `diffaug`: if True performs DiffAugment on vision-aided discriminator with poilcy `color,translation,cutout`. Recommended to keep this as True.\n* `num_classes`: for conditional training use num_classes>0. Projection discriminator is used similar to [BigGAN](https://github.com/ajbrock/BigGAN-PyTorch). \n* `loss_type`: should be one of `[sigmoid, multilevel_sigmoid, sigmoid_s, multilevl_sigmoid_s, hinge, multilevel_hinge]`. Appeding `_s` enables [label smoothing](https://arxiv.org/abs/1606.03498). If loss_type is None output is a list of logits corresponding to each vision-aided discriminator. \n* `device`: device for off-the-shelf model weights.\n\n### Vision-aided StyleGAN3 training\nPlease see [stylegan3](https://github.com/nupurkmr9/vision-aided-gan/tree/main/stylegan3) README for training StyleGAN3 models with our method.\n\n### Vision-aided BigGAN training\nPlease see [biggan](https://github.com/nupurkmr9/vision-aided-gan/tree/main/biggan) README for training BigGAN models with our method.\n\n### To add you own pretrained Model\n\ncreate the class file to extract pretrained features as `vision_module/<custom_model>.py`. Add the class path in the `class_name_dict` in `vision_module.cvmodel.CVBackbone` class. Update the architecture of trainable classifier head over pretrained features in `vision_module.cv_discriminator`. Reinstall library via `pip install .`\n\n\n\n## References\n\n```\n@InProceedings{kumari2021ensembling,\n  title={Ensembling Off-the-shelf Models for GAN Training},\n  author={Kumari, Nupur and Zhang, Richard and Shechtman, Eli and Zhu, Jun-Yan},\n  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n  month     = {June},\n  year      = {2022}\n}\n```\n\n## Acknowledgments\nWe thank Muyang Li, Sheng-Yu Wang, Chonghyuk (Andrew) Song for proofreading the draft. We are also grateful to Alexei A. Efros, Sheng-Yu Wang, Taesung Park, and William Peebles for helpful comments and discussion. Our codebase is built on [stylegan2-ada-pytorch](https://github.com/NVlabs/stylegan2-ada-pytorch) and [ DiffAugment](https://github.com/mit-han-lab/data-efficient-gans).\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/nupurkmr9/vision_aided_loss",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "vision-aided-loss",
    "package_url": "https://pypi.org/project/vision-aided-loss/",
    "platform": null,
    "project_url": "https://pypi.org/project/vision-aided-loss/",
    "project_urls": {
      "Homepage": "https://github.com/nupurkmr9/vision_aided_loss"
    },
    "release_url": "https://pypi.org/project/vision-aided-loss/0.1.0/",
    "requires_dist": [
      "torch (>=1.8.0)",
      "torchvision (>=0.9.0)",
      "numpy (>=1.14.3)",
      "requests",
      "timm",
      "antialiased-cnns",
      "gdown (==4.4.0)",
      "ftfy",
      "regex",
      "tqdm"
    ],
    "requires_python": "",
    "summary": "Vision-aided GAN training",
    "version": "0.1.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14053383,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7ffda0f62997a6aea521054e276e515dc050b13b8894e2f07c4d8b4dee293d75",
          "md5": "36f5372b270e794c780a71635e531433",
          "sha256": "282ebc5df1ff212b2f16fcf073e9d6e9c6d1717a10b5a4e60b1e3f7beddcaf1b"
        },
        "downloads": -1,
        "filename": "vision_aided_loss-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "36f5372b270e794c780a71635e531433",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 35733,
        "upload_time": "2022-06-07T06:26:10",
        "upload_time_iso_8601": "2022-06-07T06:26:10.123568Z",
        "url": "https://files.pythonhosted.org/packages/7f/fd/a0f62997a6aea521054e276e515dc050b13b8894e2f07c4d8b4dee293d75/vision_aided_loss-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3e2793048d3fd4e58d64dcf79f4328ef9906e264d9810b82cab40bebfdebc547",
          "md5": "d5fc623ca21635736843c694664bcb57",
          "sha256": "f50ec5aceed5f939a2800c9fdd1a45552d5226ab6cfeda3b5e322978b4597110"
        },
        "downloads": -1,
        "filename": "vision_aided_loss-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "d5fc623ca21635736843c694664bcb57",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 34187,
        "upload_time": "2022-06-07T06:26:11",
        "upload_time_iso_8601": "2022-06-07T06:26:11.855431Z",
        "url": "https://files.pythonhosted.org/packages/3e/27/93048d3fd4e58d64dcf79f4328ef9906e264d9810b82cab40bebfdebc547/vision_aided_loss-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "7ffda0f62997a6aea521054e276e515dc050b13b8894e2f07c4d8b4dee293d75",
        "md5": "36f5372b270e794c780a71635e531433",
        "sha256": "282ebc5df1ff212b2f16fcf073e9d6e9c6d1717a10b5a4e60b1e3f7beddcaf1b"
      },
      "downloads": -1,
      "filename": "vision_aided_loss-0.1.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "36f5372b270e794c780a71635e531433",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 35733,
      "upload_time": "2022-06-07T06:26:10",
      "upload_time_iso_8601": "2022-06-07T06:26:10.123568Z",
      "url": "https://files.pythonhosted.org/packages/7f/fd/a0f62997a6aea521054e276e515dc050b13b8894e2f07c4d8b4dee293d75/vision_aided_loss-0.1.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "3e2793048d3fd4e58d64dcf79f4328ef9906e264d9810b82cab40bebfdebc547",
        "md5": "d5fc623ca21635736843c694664bcb57",
        "sha256": "f50ec5aceed5f939a2800c9fdd1a45552d5226ab6cfeda3b5e322978b4597110"
      },
      "downloads": -1,
      "filename": "vision_aided_loss-0.1.0.tar.gz",
      "has_sig": false,
      "md5_digest": "d5fc623ca21635736843c694664bcb57",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 34187,
      "upload_time": "2022-06-07T06:26:11",
      "upload_time_iso_8601": "2022-06-07T06:26:11.855431Z",
      "url": "https://files.pythonhosted.org/packages/3e/27/93048d3fd4e58d64dcf79f4328ef9906e264d9810b82cab40bebfdebc547/vision_aided_loss-0.1.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}