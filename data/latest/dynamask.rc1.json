{
  "info": {
    "author": "Jonathan Crabbé",
    "author_email": "jc2133@cam.ac.uk",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Topic :: Scientific/Engineering :: Artificial Intelligence"
    ],
    "description": "# Dynamask - Explaining Time Series Predictions with Dynamic Masks\n[![Tests](https://github.com/vanderschaarlab/Dynamask/actions/workflows/test.yml/badge.svg)](https://github.com/vanderschaarlab/Dynamask/actions/workflows/test.yml)\n[![Downloads](https://img.shields.io/pypi/dd/dynamask)](https://pypi.org/project/dynamask/)\n[![pdf](https://img.shields.io/badge/paper-ICML%202021-orange)](https://arxiv.org/abs/2106.05303)\n[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)\n\n\n![image](https://github.com/vanderschaarlab/Dynamask/raw/main/images/Dynamask.png \"Blueprint of Dynamask\")\n\nCode Author: Jonathan Crabbé ([jc2133@cam.ac.uk](mailto:jc2133@cam.ac.uk))\n\nThis repository contains the implementation of Dynamask, a method to identify the features that are salient for\na model to issue its prediction when the data is represented in terms of time series.\nFor more details on the theoretical side, please read our [ICML 2021 paper](https://arxiv.org/abs/2106.05303): 'Explaining Time Series\nPredictions with Dynamic Masks'.\n\nPart of the experiments in our paper are relying on [FIT](https://github.com/sanatonek/time_series_explainability),\nanother repository associated to the [NeurIPS 2021 paper](https://papers.nips.cc/paper/2020/hash/08fa43588c2571ade19bc0fa5936e028-Abstract.html):\n'What went wrong and when? Instance-wise feature importance for time-series black-box models'. We have included all\nthe relevant files in the folder [fit](fit).\n\n\n## :rocket: Installation\n\nThe library requires libpq-dev.\n\nThe library can be installed from PyPI using\n```bash\n$ pip install dynamask\n```\nor from source, using\n```bash\n$ pip install .\n```\n\n## Toy example\n\nIt is very easy to fit a mask on a time series model. Bellow, you can find a toy demonstration where we\nfit a mask to an input time series. In this case, the mask area is fixed to 0.1 (the 10% most important features\nare highlighted by the mask). All the relevant code can be found in the file [mask](attribution/mask.py).\n\n```python\nimport torch\nfrom dynamask.attribution.mask import Mask\nfrom dynamask.attribution.perturbation import GaussianBlur\nfrom dynamask.utils.losses import mse\n\ntorch.manual_seed(42)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Define a pseudo-black box:\ndef black_box(input):\n    output = input[-1, :]  # The black-box returns the features of the last time step\n    return output\n# Define a random input:\nX = torch.randn(10, 3).to(device) # The shape of the input has to be (T, N_features)\n\n# Fit a mask to the input with a Gaussian Blur perturbation:\npert = GaussianBlur(device)\nmask = Mask(pert, device)\nmask.fit(X, black_box, loss_function=mse, keep_ratio=0.1, size_reg_factor_init=0.01) # Select the 10% most important features\n\n# Plot the resulting saliency map:\nmask.plot_mask()\n```\n\nIf the proportion of features to select is unknown, a good approach is to fit a group of masks\nwith different areas. Then, the extremal mask can be extracted from the group.\nThe relevant code can be found in the file [mask_group](attribution/mask_group.py).\n```python\nimport torch\nfrom dynamask.attribution.mask_group import MaskGroup\nfrom dynamask.attribution.perturbation import GaussianBlur\nfrom dynamask.utils.losses import mse\n\ntorch.manual_seed(42)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Define a pseudo-black box:\ndef black_box(input):\n    output = input[-1, :]  # The black-box returns the features of the last time step\n    return output\n\n# Define a random input:\nX = torch.randn(10, 3).to(device) # The shape of the input has to be (T, N_features)\n\n# Fit a group of masks to the input with a Gaussian Blur perturbation:\nareas = [.1, .15, .2, .25] # These are the areas of the different masks\npert = GaussianBlur(device)\nmasks = MaskGroup(pert, device)\nmasks.fit(X, black_box, loss_function=mse, area_list=areas, size_reg_factor_init=0.01)\n\n# Extract the extremal mask:\nepsilon = 0.01\nmask = masks.get_extremal_mask(threshold=epsilon)\n\n# Plot the resulting saliency map:\nmask.plot_mask()\n```\n\n\n## Replicate experiments\n\nAll experiments in the ICML paper can be replicated easily. The necessary code is in [experiments](experiments).\nBellow, we detail the procedure for each experiment.\n\nScripts to run the experiments are also provided: `experiments/run_<EXPERIMENT>.sh`.\n\n###  Replicate the Rare experiments\n\n1. Run the following command from the repository folder:\n   ```shell\n   python -m dynamask.experiments.rare_feature # Runs the Rare Feature experiment\n   python -m dynamask.experiments.rare_time # Runs the Rare Time experiment\n   ```\n   To do the experiment with various seeds, please add the following specification to these commands:\n   ```shell\n   Options:\n   --cv # An integer that sets the random seed (first run cv=0, second run cv=1, ...)\n   ```\n2. The results of these experiments are saved in the two following folders: [Rare Feature](experiments/results/rare_feature)\nand [Rare Time](experiments/results/rare_time). To process the results and compute the associated metrics run:\n   ```shell\n   python -m dynamask.experiments.results.rare_feature.get_results\n   python -m dynamask.experiments.results.rare_time.get_results\n   ```\n   The following options need to be specified:\n   ```shell\n   Options:\n   --CV # The number of runs you have done for the experiment\n   --explainers # The baselines you have used among: dynamask, fo, fp, ig, shap (separated by a space)\n   ```\n\n\n###  Replicate the State experiment\n\n1. Run this command to generate the synthetic data and store it in ``data/state``:\n   ```shell\n   python -m dynamask.fit.data_generator.state_data --signal_len 200 --signal_num 1000\n   ```\n2. Run the following command to fit a model together with a baseline saliency method:\n   ```shell\n   python -m dynamask.fit.evaluation.baselines --explainer fit --train\n   ```\n   To do the experiment with various baselines, please change the explainer:\n   ```shell\n   Options:\n   --explainer # The baselines can be: fit, lime, retain, integrated_gradient, deep_lift, fo, afo, gradient_shap\n   --train # Only put this option when fitting the FIRST baseline (this is to avoid retraining a model for each baseline); however, required for retain baseline\n   --cv # An integer that sets the random seed (first run cv=0, second run cv=1, ...)\n   ```\n3. The models and baselines saliency maps are all saved in [this folder](experiments/results/state).\n   Now fit a mask for each of these time series by running:\n   ```shell\n   python -m dynamask.experiments.state\n   ```\n   Please use the same ``--cv`` option as for the previous command.\n\n\n4. The masks are all saved in [this folder](experiments/results/state).\n   To process the results and compute the associated metrics run:\n   ```shell\n   python -m dynamask.experiments.results.state.get_results\n   ```\n   The following options need to be specified:\n   ```shell\n   Options:\n   --CV # The number of runs you have done for the experiment\n   --explainers # The baselines you have used among: dynamask, fo, afo, deep_lift, fit, gradient_shap, integrated_gradient, lime, retain (separated by a space)\n   ```\n\n### Replicate the MIMIC experiment\n1. MIMIC-III is a private dataset. For the following, you need to have the MIMIC-III database running on\n   a local server. For more information, please refer to [the official MIMIC-III documentation](https://mimic.mit.edu/iii/gettingstarted/dbsetup/).\n\n\n2. Run this command to acquire the data and store it:\n   ```shell\n   python dynamask/fit/data_generator/icu_mortality.py --sqluser YOUR_USER --sqlpass YOUR_PASSWORD\n   ```\n   If everything happens properly, two files named ``adult_icu_vital.gz`` and ``adult_icu_lab.gz``\n   are stored in ``data/mimic``.\n\n\n3. Run this command to preprocess the data:\n   ```shell\n   python dynamask/fit/data_generator/data_preprocess.py\n   ```\n   If everything happens properly, a file ``patient_vital_preprocessed.pkl`` is stored in ``data/mimic``.\n\n4. Run the following command to fit a model together with a baseline saliency method:\n   ```shell\n   python -m dynamask.fit.evaluation.baselines --data mimic --explainer fit --train\n   ```\n   To do the experiment with various baselines, please change the explainer:\n   ```shell\n   Options:\n   --explainer # The baselines can be: fit, lime, retain, integrated_gradient, deep_lift, fo, afo, gradient_shap\n   --train # Only put this option when fitting the FIRST baseline (this is to avoid retraining a model for each baseline); however, required for retain baseline\n   --cv # An integer that sets the random seed (first run cv=0, second run cv=1, ...)\n   ```\n\n5. The models and baselines saliency maps are all saved in [this folder](experiments/results/state).\n   Now fit a mask for each of these time series by running:\n   ```shell\n   python -m dynamask.experiments.mimic\n   ```\n   Please use the same ``--cv`` option as for the previous command.\n   ```shell\n   Options:\n   --cv # Same as in the previous command\n   --area # The area of the mask to fit (a number between 0 and 1)\n   ```\n\n6. The masks are all saved in [this folder](experiments/results/mimic).\n   To process the results and compute the associated metrics run:\n   ```shell\n   python -m dynamask.experiments.results.state.plot_benchmarks\n   ```\n   The following options need to be specified:\n   ```shell\n   Options:\n   --CV # The number of runs you have done for the experiment\n   --explainers # The baselines you have used among: dynamask, fo, afo, deep_lift, fit, gradient_shap, integrated_gradient, lime, retain (separated by a space)\n   --areas # The mask areas that you have computed (separated by a space)\n   ```\n   The resulting plots are saved in [this folder](experiments/results/mimic).\n\n\n## :hammer: Tests\n\nInstall the testing dependencies using\n```bash\npip install .[testing]\n```\nThe tests can be executed using\n```bash\npytest -vsx\n```\n\n\n## Citing\n\nIf you use this code, please cite the associated paper:\n\n```\n@InProceedings{pmlr-v139-crabbe21a,\n  title = \t {Explaining Time Series Predictions with Dynamic Masks},\n  author =       {Crabb{\\'e}, Jonathan and Van Der Schaar, Mihaela},\n  booktitle = \t {Proceedings of the 38th International Conference on Machine Learning},\n  pages = \t {2166--2177},\n  year = \t {2021},\n  editor = \t {Meila, Marina and Zhang, Tong},\n  volume = \t {139},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {18--24 Jul},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v139/crabbe21a/crabbe21a.pdf},\n  url = \t {https://proceedings.mlr.press/v139/crabbe21a.html},\n  abstract = \t {How can we explain the predictions of a machine learning model? When the data is structured as a multivariate time series, this question induces additional difficulties such as the necessity for the explanation to embody the time dependency and the large number of inputs. To address these challenges, we propose dynamic masks (Dynamask). This method produces instance-wise importance scores for each feature at each time step by fitting a perturbation mask to the input sequence. In order to incorporate the time dependency of the data, Dynamask studies the effects of dynamic perturbation operators. In order to tackle the large number of inputs, we propose a scheme to make the feature selection parsimonious (to select no more feature than necessary) and legible (a notion that we detail by making a parallel with information theory). With synthetic and real-world data, we demonstrate that the dynamic underpinning of Dynamask, together with its parsimony, offer a neat improvement in the identification of feature importance over time. The modularity of Dynamask makes it ideal as a plug-in to increase the transparency of a wide range of machine learning models in areas such as medicine and finance, where time series are abundant.}\n}\n```\n\n\n",
    "description_content_type": "text/markdown; charset=UTF-8",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://www.vanderschaar-lab.com/",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "dynamask",
    "package_url": "https://pypi.org/project/dynamask/",
    "platform": "any",
    "project_url": "https://pypi.org/project/dynamask/",
    "project_urls": {
      "Homepage": "https://www.vanderschaar-lab.com/"
    },
    "release_url": "https://pypi.org/project/dynamask/0.0.1/",
    "requires_dist": [
      "captum (>=0.3.0)",
      "lime (>=0.2.0.1)",
      "numpy (>=1.19.2)",
      "pandas (>=1.1.3)",
      "psycopg2-binary",
      "scikit-learn (>=0.23.2)",
      "scipy (>=1.5.2)",
      "seaborn (>=0.11.0)",
      "statsmodels (>=0.12.1)",
      "torch (>=1.7.1)",
      "tqdm (>=4.61.0)",
      "importlib-metadata ; python_version < \"3.8\"",
      "pre-commit ; extra == 'testing'",
      "setuptools ; extra == 'testing'",
      "pytest ; extra == 'testing'",
      "pytest-cov ; extra == 'testing'",
      "bandit ; extra == 'testing'",
      "jupyter ; extra == 'testing'",
      "notebook ; extra == 'testing'"
    ],
    "requires_python": "",
    "summary": "Dynamask - Explaining Time Series Predictions with Dynamic Masks",
    "version": "0.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 15011807,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2604770485a3a4e45d8d35f80208dc37a677510f8715c5114f2b8cd148dcd285",
          "md5": "91e4003031cbfbfcf0644e5d67f9bd0c",
          "sha256": "a64c6714cc4b97d7d5e30c520df3593008b2a2fcf6d8664eaaf6a1ae7f51239d"
        },
        "downloads": -1,
        "filename": "dynamask-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "91e4003031cbfbfcf0644e5d67f9bd0c",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 93361,
        "upload_time": "2022-09-06T21:25:45",
        "upload_time_iso_8601": "2022-09-06T21:25:45.117102Z",
        "url": "https://files.pythonhosted.org/packages/26/04/770485a3a4e45d8d35f80208dc37a677510f8715c5114f2b8cd148dcd285/dynamask-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9360d7091ee661edbc0519ed6ae86161f3b0e3d1f9a3458148b31ccfa3292008",
          "md5": "60c50b9ae62ab870816ae35dd32f441f",
          "sha256": "ea7f93ac573b12a4732d3add3db39b50000e31dbf1daf4df3be106bf170e6bc0"
        },
        "downloads": -1,
        "filename": "dynamask-0.0.1-py3-none-macosx_10_14_x86_64.whl",
        "has_sig": false,
        "md5_digest": "60c50b9ae62ab870816ae35dd32f441f",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 92770,
        "upload_time": "2022-09-06T21:24:33",
        "upload_time_iso_8601": "2022-09-06T21:24:33.780049Z",
        "url": "https://files.pythonhosted.org/packages/93/60/d7091ee661edbc0519ed6ae86161f3b0e3d1f9a3458148b31ccfa3292008/dynamask-0.0.1-py3-none-macosx_10_14_x86_64.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "2604770485a3a4e45d8d35f80208dc37a677510f8715c5114f2b8cd148dcd285",
        "md5": "91e4003031cbfbfcf0644e5d67f9bd0c",
        "sha256": "a64c6714cc4b97d7d5e30c520df3593008b2a2fcf6d8664eaaf6a1ae7f51239d"
      },
      "downloads": -1,
      "filename": "dynamask-0.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "91e4003031cbfbfcf0644e5d67f9bd0c",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 93361,
      "upload_time": "2022-09-06T21:25:45",
      "upload_time_iso_8601": "2022-09-06T21:25:45.117102Z",
      "url": "https://files.pythonhosted.org/packages/26/04/770485a3a4e45d8d35f80208dc37a677510f8715c5114f2b8cd148dcd285/dynamask-0.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "9360d7091ee661edbc0519ed6ae86161f3b0e3d1f9a3458148b31ccfa3292008",
        "md5": "60c50b9ae62ab870816ae35dd32f441f",
        "sha256": "ea7f93ac573b12a4732d3add3db39b50000e31dbf1daf4df3be106bf170e6bc0"
      },
      "downloads": -1,
      "filename": "dynamask-0.0.1-py3-none-macosx_10_14_x86_64.whl",
      "has_sig": false,
      "md5_digest": "60c50b9ae62ab870816ae35dd32f441f",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 92770,
      "upload_time": "2022-09-06T21:24:33",
      "upload_time_iso_8601": "2022-09-06T21:24:33.780049Z",
      "url": "https://files.pythonhosted.org/packages/93/60/d7091ee661edbc0519ed6ae86161f3b0e3d1f9a3458148b31ccfa3292008/dynamask-0.0.1-py3-none-macosx_10_14_x86_64.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}