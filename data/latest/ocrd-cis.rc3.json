{
  "info": {
    "author": "Florian Fink, Tobias Englmeier, Christoph Weber",
    "author_email": "finkf@cis.lmu.de, englmeier@cis.lmu.de, web_chris@msn.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "[![Language grade: Python](https://img.shields.io/lgtm/grade/python/g/cisocrgroup/ocrd_cis.svg?logo=lgtm&logoWidth=18)](https://lgtm.com/projects/g/cisocrgroup/ocrd_cis/context:python)\n[![Total alerts](https://img.shields.io/lgtm/alerts/g/cisocrgroup/ocrd_cis.svg?logo=lgtm&logoWidth=18)](https://lgtm.com/projects/g/cisocrgroup/ocrd_cis/alerts/)\n\nContent:\n   * [ocrd_cis](#ocrd_cis)\n      * [Introduction](#introduction)\n      * [Installation](#installation)\n      * [Profiler](#profiler)\n      * [Usage](#usage)\n         * [ocrd-cis-postcorrect](#ocrd-cis-postcorrect)\n         * [ocrd-cis-align](#ocrd-cis-align)\n         * [ocrd-cis-data](#ocrd-cis-data)\n         * [Trainining](#trainining)\n         * [ocrd-cis-ocropy-train](#ocrd-cis-ocropy-train)\n         * [ocrd-cis-ocropy-clip](#ocrd-cis-ocropy-clip)\n         * [ocrd-cis-ocropy-resegment](#ocrd-cis-ocropy-resegment)\n         * [ocrd-cis-ocropy-segment](#ocrd-cis-ocropy-segment)\n         * [ocrd-cis-ocropy-deskew](#ocrd-cis-ocropy-deskew)\n         * [ocrd-cis-ocropy-denoise](#ocrd-cis-ocropy-denoise)\n         * [ocrd-cis-ocropy-binarize](#ocrd-cis-ocropy-binarize)\n         * [ocrd-cis-ocropy-dewarp](#ocrd-cis-ocropy-dewarp)\n         * [ocrd-cis-ocropy-recognize](#ocrd-cis-ocropy-recognize)\n         * [Tesserocr](#tesserocr)\n      * [Workflow configuration](#workflow-configuration)\n      * [Testing](#testing)\n   * [Miscellaneous](#miscellaneous)\n      * [OCR-D workspace](#ocr-d-workspace)\n      * [OCR-D links](#ocr-d-links)\n\n# ocrd_cis\n\n[CIS](http://www.cis.lmu.de) [OCR-D](http://ocr-d.de) command line\ntools for the automatic post-correction of OCR-results.\n\n## Introduction\n`ocrd_cis` contains different tools for the automatic post-correction\nof OCR results.  It contains tools for the training, evaluation and\nexecution of the post-correction.  Most of the tools are following the\n[OCR-D CLI conventions](https://ocr-d.de/en/spec/cli).\n\nAdditionally, there is a helper tool to align multiple OCR results,\nas well as an improved version of [Ocropy](https://github.com/tmbarchive/ocropy)\nthat works with Python 3 and is also wrapped for [OCR-D](https://ocr-d.de/en/spec/).\n\n## Installation\nThere are 2 ways to install the `ocrd_cis` tools:\n * normal packaging:\n  ```sh\n  make install # or equally: pip install -U pip .\n  ```\n  (Installs `ocrd_cis` including its Python dependencies\n   from the current directory to the Python package directory.)\n * editable mode:\n  ```sh\n  make install-devel # or equally: pip install -e -U pip .\n  ```\n  (Installs `ocrd_cis` including its Python dependencies\n   from the current directory.)\n\nIt is possible (and recommended) to install `ocrd_cis` in a custom user directory\n(instead of system-wide) by using `virtualenv` (or `venv`):\n```sh\n # create venv:\n python3 -m venv venv-dir # where \"venv-dir\" could be any path name\n # enter venv in current shell:\n source venv-dir/bin/activate\n # install ocrd_cis:\n make install # or any other way (see above)\n # use ocrd_cis:\n ocrd-cis-ocropy-binarize ...\n # finally, leave venv:\n deactivate\n```\n\n## Profiler\nThe post correction is dependent on the language\n[profiler](https://github.com/cisocrgroup/Profiler) and its laguage\nconfigurations to generate corrections for suspicious words.  In order\nto use the post correction a profiler with according language\nconfigruations have to be present on the system.  You can refer to our\n[manuals](https://github.com/cisocrgroup/Resources/tree/master/manuals)\nand our [lexical\nresources](https://github.com/cisocrgroup/Resources/tree/master/lexica)\nfor more information.\n\nIf you use docker you can use the preinstalled profiler from within\nthe docker-container.  The profiler is installed to `/apps/profiler`\nand the language configurations lie in `/etc/profiler/languages` in\nthe container image.\n\n## Usage\nMost tools follow the [OCR-D specifications](https://ocr-d.de/en/spec),\n(which makes them [OCR-D _processors_](https://ocr-d.de/en/spec/cli),)\ni.e. they accept the command-line options `--input-file-grp`, `--output-file-grp`,\n`--page-id`, `--parameter`, `--mets`, `--log-level` (each with an argument).\nInvoke with `--help` to get self-documentation. \n\nSome of the processors (most notably the alignment tool) expect a comma-seperated list\nof multiple input file groups, or multiple output file groups.\n\nThe [ocrd-tool.json](ocrd_cis/ocrd-tool.json) contains a formal\ndescription of all the processors along with the parameter config file\naccepted by their `--parameter` argument.\n\n### ocrd-cis-postcorrect\nThis processor runs the post correction using a pre-trained model.  If\nadditional support OCRs should be used, models for these OCR steps are\nrequired and must be executed and aligned beforehand (see [the test\nscript](tests/run_postcorrection_test.bash) for an example).\n\nThere is a basic model trained on the OCR-D ground truth.  It gets\ninstalled allongside this module.  You can get the model's install\npath using `ocrd-cis-data -model` (see below for a description of\n`ocrd-cis-data`).  To use this model (or any other model) the `model`\nparameter in the configuration file must be set to the path of the\nmodel to use.  Be aware that the models are trained with a specific\nmaximal number of OCR's (usally 2) and that is not possible to use\nmore OCR's than the number used for training (it is possible to use\nless, though).\n\nArguments:\n * `--parameter` path to configuration file\n * `--input-file-grp` name of the master-OCR file group\n * `--output-file-grp` name of the post-correction file group\n * `--log-level` set log level\n * `--mets` path to METS file in workspace\n\nAs mentioned above in order to use the postcorrection with input from\nmultiple OCR's, some preprocessing steps are needed: firstly the\nadditional OCR recognition has to be done and secondly the multiple\nOCR's have to be aligned (you can also take a look to the function\n`ocrd_cis_align` in the [tests](tests/test_lib.bash)).  Assuming an\noriginal recognition as file group `OCR1` on the segmented document of\nfile group `SEG`, the folloing commands can be used:\n\n```sh\nocrd-ocropus-recognize -I SEG -O OCR2 ... # additional OCR\nocrd-cis-align -I OCR1,OCR2 -O ALGN ... # align OCR1 and OCR2\nocrd-cis-postcorrect -I ALGN -O PC ... # post correction\n```\n\n### ocrd-cis-align\nAligns tokens of multiple input file groups to one output file group.\nThis processor is used to align the master OCR with any additional support\nOCRs.  It accepts a comma-separated list of input file groups, which\nit aligns in order.\n\nArguments:\n * `--parameter` path to configuration file\n * `--input-file-grp` comma seperated list of the input file groups;\n   first input file group is the master OCR; if there is a ground\n   truth (for evaluation) it must be the last file group in the list\n * `--output-file-grp` name of the file group for the aligned result\n * `--log-level` set log level\n * `--mets` path to METS file in workspace\n\n### ocrd-cis-data\nHelper tool to get the path of the installed data files. Usage:\n`ocrd-cis-data [-h|-jar|-3gs|-model|-config]` to get the path of the\njar library, the pre-trained post correction model, the path to the\ndefault 3-grams language model file or the default training\nconfiguration file.  This tool does not follow the OCR-D conventions.\n\n### Trainining\nThere is no dedicated training script provided. Models are trained\nusing the java implementation directly (check out the [training test\nscript](tests/run_training_test.bash) for an example).  Training a\nmodel requires a workspace containing one or more file groups\nconsisting of aligned OCR and ground-truth documents (the last file\ngroup has to be the ground truth).\n\nArguments:\n * `--parameter` path to configuration file\n * `--input-file-grp` name of the input file group to profile\n * `--output-file-grp` name of the output file group where the profile\n   is stored\n * `--log-level` set log level\n * `--mets` path to METS file in the workspace\n\n### ocrd-cis-ocropy-train\nThe [ocropy-train](ocrd_cis/ocropy/train.py) tool can be used to train LSTM models.\nIt takes ground truth from the workspace and saves (image+text) snippets from the corresponding pages.\nThen a model is trained on all snippets for 1 million (or the given number of) randomized iterations from the parameter file.\n\n```sh\njava -jar $(ocrd-cis-data -jar) \\\n\t -c train \\\n\t --input-file-grp OCR1,OCR2,GT \\\n     --log-level DEBUG \\\n\t -m mets.xml \\\n\t --parameter $(ocrd-cis-data -config)\n```\n\n### ocrd-cis-ocropy-clip\nThe [clip](ocrd_cis/ocropy/clip.py) processor can be used to remove intrusions of neighbouring segments in regions / lines of a page.\nIt runs a connected component analysis on every text region / line of every PAGE in the input file group, as well as its overlapping neighbours, and for each binary object of conflict, determines whether it belongs to the neighbour, and can therefore be clipped to the background. It references the resulting segment image files in the output PAGE (via `AlternativeImage`).\n(Use this to suppress separators and neighbouring text.)\n```sh\nocrd-cis-ocropy-clip \\\n  -I OCR-D-SEG-REGION \\\n  -O OCR-D-SEG-REGION-CLIP \\\n  -p '{\"level-of-operation\": \"region\"}'\n```\n\nAvailable parameters are:\n```sh\n   \"level-of-operation\" [string - \"region\"]\n    PAGE XML hierarchy level granularity to annotate images for\n    Possible values: [\"region\", \"line\"]\n   \"dpi\" [number - -1]\n    pixel density in dots per inch (overrides any meta-data in the\n    images); disabled when negative\n   \"min_fraction\" [number - 0.7]\n    share of foreground pixels that must be retained by the largest label\n```\n\n### ocrd-cis-ocropy-resegment\nThe [resegment](ocrd_cis/ocropy/resegment.py) processor can be used to remove overlap between neighbouring lines of a page.\nIt runs a line segmentation on every text region of every PAGE in the input file group, and for each line already annotated, determines the label of largest extent within the original coordinates (polygon outline) in that line, and annotates the resulting coordinates in the output PAGE.\n(Use this to polygonalise text lines that are poorly segmented, e.g. via bounding boxes.)\n```sh\nocrd-cis-ocropy-resegment \\\n  -I OCR-D-SEG-LINE \\\n  -O OCR-D-SEG-LINE-RES \\\n  -p '{\"extend_margins\": 3}'\n```\n\nAvailable parameters are:\n```sh\n   \"dpi\" [number - -1]\n    pixel density in dots per inch (overrides any meta-data in the\n    images); disabled when negative\n   \"min_fraction\" [number - 0.8]\n    share of foreground pixels that must be retained by the largest label\n   \"extend_margins\" [number - 3]\n    number of pixels to extend the input polygons horizontally and\n    vertically before intersecting\n```\n\n### ocrd-cis-ocropy-segment\nThe [segment](ocrd_cis/ocropy/segment.py) processor can be used to segment (pages or) regions of a page into (regions and) lines.\nIt runs a line segmentation on every (page or) text region of every PAGE in the input file group, and adds (text regions containing) `TextLine` elements with the resulting polygon outlines to the annotation of the output PAGE.\n(Does _not_ detect tables.)\n```sh\nocrd-cis-ocropy-segment \\\n  -I OCR-D-SEG-BLOCK \\\n  -O OCR-D-SEG-LINE \\\n  -p '{\"level-of-operation\": \"page\", \"gap_height\": 0.015}'\n```\n\nAvailable parameters are:\n```sh\n   \"dpi\" [number - -1]\n    pixel density in dots per inch (overrides any meta-data in the\n    images); disabled when negative; when disabled and no meta-data is\n    found, 300 is assumed\n   \"level-of-operation\" [string - \"region\"]\n    PAGE XML hierarchy level to read images from and add elements to\n    Possible values: [\"page\", \"table\", \"region\"]\n   \"maxcolseps\" [number - 20]\n    (when operating on the page/table level) maximum number of\n    white/background column separators to detect, counted piece-wise\n   \"maxseps\" [number - 20]\n    (when operating on the page/table level) number of black/foreground\n    column separators to detect (and suppress), counted piece-wise\n   \"maximages\" [number - 10]\n    (when operating on the page level) maximum number of black/foreground\n    very large components to detect (and suppress), counted piece-wise\n   \"csminheight\" [number - 4]\n    (when operating on the page/table level) minimum height of\n    white/background or black/foreground column separators in multiples\n    of scale/capheight, counted piece-wise\n   \"hlminwidth\" [number - 10]\n    (when operating on the page/table level) minimum width of\n    black/foreground horizontal separators in multiples of\n    scale/capheight, counted piece-wise\n   \"gap_height\" [number - 0.01]\n    (when operating on the page/table level) largest minimum pixel\n    average in the horizontal or vertical profiles (across the binarized\n    image) to still be regarded as a gap during recursive X-Y cut from\n    lines to regions; needs to be larger when more foreground noise is\n    present, reduce to avoid mistaking text for noise\n   \"gap_width\" [number - 1.5]\n    (when operating on the page/table level) smallest width in multiples\n    of scale/capheight of a valley in the horizontal or vertical\n    profiles (across the binarized image) to still be regarded as a gap\n    during recursive X-Y cut from lines to regions; needs to be smaller\n    when more foreground noise is present, increase to avoid mistaking\n    inter-line as paragraph gaps and inter-word as inter-column gaps\n   \"overwrite_order\" [boolean - true]\n    (when operating on the page/table level) remove any references for\n    existing TextRegion elements within the top (page/table) reading\n    order; otherwise append\n   \"overwrite_separators\" [boolean - true]\n    (when operating on the page/table level) remove any existing\n    SeparatorRegion elements; otherwise append\n   \"overwrite_regions\" [boolean - true]\n    (when operating on the page/table level) remove any existing\n    TextRegion elements; otherwise append\n   \"overwrite_lines\" [boolean - true]\n    (when operating on the region level) remove any existing TextLine\n    elements; otherwise append\n   \"spread\" [number - 2.4]\n    distance in points (pt) from the foreground to project text line (or\n    text region) labels into the background for polygonal contours; if\n    zero, project half a scale/capheight\n```\n\n### ocrd-cis-ocropy-deskew\nThe [deskew](ocrd_cis/ocropy/deskew.py) processor can be used to deskew pages / regions of a page.\nIt runs a projection profile-based skew estimation on every segment of every PAGE in the input file group and annotates the orientation angle in the output PAGE.\n(Does _not_ include orientation detection.)\n```sh\nocrd-cis-ocropy-deskew \\\n  -I OCR-D-SEG-LINE \\\n  -O OCR-D-SEG-LINE-DES \\\n  -p '{\"level-of-operation\": \"page\", \"maxskew\": 10}'\n```\n\nAvailable parameters are:\n```sh\n   \"maxskew\" [number - 5.0]\n    modulus of maximum skewing angle to detect (larger will be slower, 0\n    will deactivate deskewing)\n   \"level-of-operation\" [string - \"region\"]\n    PAGE XML hierarchy level granularity to annotate images for\n    Possible values: [\"page\", \"region\"]\n```\n\n### ocrd-cis-ocropy-denoise\nThe [denoise](ocrd_cis/ocropy/denoise.py) processor can be used to despeckle pages / regions / lines of a page.\nIt runs a connected component analysis and removes small components (black or white) on every segment of every PAGE in the input file group and references the resulting segment image files in the output PAGE (as `AlternativeImage`).\n```sh\nocrd-cis-ocropy-denoise \\\n  -I OCR-D-SEG-LINE-DES \\\n  -O OCR-D-SEG-LINE-DEN \\\n  -p '{\"noise_maxsize\": 2}'\n```\n\nAvailable parameters are:\n```sh\n   \"noise_maxsize\" [number - 3.0]\n    maximum size in points (pt) for connected components to regard as\n    noise (0 will deactivate denoising)\n   \"dpi\" [number - -1]\n    pixel density in dots per inch (overrides any meta-data in the\n    images); disabled when negative\n   \"level-of-operation\" [string - \"page\"]\n    PAGE XML hierarchy level granularity to annotate images for\n    Possible values: [\"page\", \"region\", \"line\"]\n```\n\n### ocrd-cis-ocropy-binarize\nThe [binarize](ocrd_cis/ocropy/binarize.py) processor can be used to binarize (and optionally denoise and deskew) pages / regions / lines of a page.\nIt runs the \"nlbin\" adaptive whitelevel thresholding on every segment of every PAGE in the input file group and references the resulting segment image files in the output PAGE (as `AlternativeImage`). (If a deskewing angle has already been annotated in a region, the tool respects that and rotates accordingly.) Images can also be produced grayscale-normalized.\n```sh\nocrd-cis-ocropy-binarize \\\n  -I OCR-D-SEG-LINE-DES \\\n  -O OCR-D-SEG-LINE-BIN \\\n  -p '{\"level-of-operation\": \"page\", \"threshold\": 0.7}'\n```\n\nAvailable parameters are:\n```sh\n   \"method\" [string - \"ocropy\"]\n    binarization method to use (only 'ocropy' will include deskewing and\n    denoising)\n    Possible values: [\"none\", \"global\", \"otsu\", \"gauss-otsu\", \"ocropy\"]\n   \"threshold\" [number - 0.5]\n    for the 'ocropy' and ' global' method, black/white threshold to apply\n    on the whitelevel normalized image (the larger the more/heavier\n    foreground)\n   \"grayscale\" [boolean - false]\n    for the 'ocropy' method, produce grayscale-normalized instead of\n    thresholded image\n   \"maxskew\" [number - 0.0]\n    modulus of maximum skewing angle (in degrees) to detect (larger will\n    be slower, 0 will deactivate deskewing)\n   \"noise_maxsize\" [number - 0]\n    maximum pixel number for connected components to regard as noise (0\n    will deactivate denoising)\n   \"level-of-operation\" [string - \"page\"]\n    PAGE XML hierarchy level granularity to annotate images for\n    Possible values: [\"page\", \"region\", \"line\"]\n```\n\n### ocrd-cis-ocropy-dewarp\nThe [dewarp](ocrd_cis/ocropy/dewarp.py) processor can be used to vertically dewarp text lines of a page.\nIt runs the baseline estimation and center normalizer algorithm on every line in every text region of every PAGE in the input file group and references the resulting line image files in the output PAGE (as `AlternativeImage`).\n```sh\nocrd-cis-ocropy-dewarp \\\n  -I OCR-D-SEG-LINE-BIN \\\n  -O OCR-D-SEG-LINE-DEW \\\n  -p '{\"range\": 5}'\n```\n\nAvailable parameters are:\n```sh\n   \"dpi\" [number - -1]\n    pixel density in dots per inch (overrides any meta-data in the\n    images); disabled when negative\n   \"range\" [number - 4.0]\n    maximum vertical disposition or maximum margin (will be multiplied by\n    mean centerline deltas to yield pixels)\n   \"max_neighbour\" [number - 0.05]\n    maximum rate of foreground pixels intruding from neighbouring lines\n    (line will not be processed above that)\n```\n\n### ocrd-cis-ocropy-recognize\nThe [recognize](ocrd_cis/ocropy/recognize.py) processor can be used to recognize the lines / words / glyphs of a page.\nIt runs LSTM optical character recognition on every line in every text region of every PAGE in the input file group and adds the resulting text annotation in the output PAGE.\n```sh\nocrd-cis-ocropy-recognize \\\n  -I OCR-D-SEG-LINE-DEW \\\n  -O OCR-D-OCR-OCRO \\\n  -p '{\"textequiv_level\": \"word\", \"model\": \"fraktur-jze.pyrnn\"}'\n```\n\nAvailable parameters are:\n```sh\n   \"textequiv_level\" [string - \"line\"]\n    PAGE XML hierarchy level granularity to add the TextEquiv results to\n    Possible values: [\"line\", \"word\", \"glyph\"]\n   \"model\" [string]\n    ocropy model to apply (e.g. fraktur.pyrnn)\n```\n\n### Tesserocr\nInstall essential system packages for Tesserocr\n```sh\nsudo apt-get install python3-tk \\\n  tesseract-ocr libtesseract-dev libleptonica-dev \\\n  libimage-exiftool-perl libxml2-utils\n```\n\nThen install Tesserocr from: https://github.com/OCR-D/ocrd_tesserocr\n```sh\npip install -r requirements.txt\npip install .\n```\n\nDownload and move tesseract models from:\nhttps://github.com/tesseract-ocr/tesseract/wiki/Data-Files or use your\nown models and place them into: /usr/share/tesseract-ocr/4.00/tessdata\n\n## Workflow configuration\n\nA decent pipeline might look like this:\n\n1. image normalization/optimization\n1. page-level binarization\n1. page-level cropping\n1. (page-level binarization)\n1. (page-level despeckling)\n1. page-level deskewing\n1. (page-level dewarping)\n1. region segmentation, possibly subdivided into\n   1. text/non-text separation\n   1. text region segmentation (and classification)\n   1. reading order detection\n   1. non-text region classification\n1. region-level clipping\n1. (region-level deskewing)\n1. line segmentation\n1. (line-level clipping or resegmentation)\n1. line-level dewarping\n1. line-level recognition\n1. (line-level alignment and post-correction)\n\nIf GT is used, then cropping/segmentation steps can be omitted.\n\nIf a segmentation is used which does not produce overlapping segments, then clipping/resegmentation can be omitted.\n\n## Testing\nTo run a few basic tests type `make test` (`ocrd_cis` has to be\ninstalled in order to run any tests).\n\n# Miscellaneous\n## OCR-D workspace\n\n* Create a new (empty) workspace: `ocrd workspace init workspace-dir`\n* cd into `workspace-dir`\n* Add new file to workspace: `ocrd workspace add file -G group -i id\n  -m mimetype -g pageId`\n\n## OCR-D links\n\n- [OCR-D](https://ocr-d.github.io)\n- [Github](https://github.com/OCR-D)\n- [Project-page](http://www.ocr-d.de/)\n- [Ground-truth](https://ocr-d-repo.scc.kit.edu/api/v1/metastore/bagit/search)\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/cisocrgroup/ocrd_cis",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "ocrd-cis",
    "package_url": "https://pypi.org/project/ocrd-cis/",
    "platform": "",
    "project_url": "https://pypi.org/project/ocrd-cis/",
    "project_urls": {
      "Homepage": "https://github.com/cisocrgroup/ocrd_cis"
    },
    "release_url": "https://pypi.org/project/ocrd-cis/0.0.10/",
    "requires_dist": [
      "ocrd (>=2.10.4)",
      "click",
      "scipy",
      "numpy (>=1.17.0)",
      "pillow (>=7.1.2)",
      "shapely",
      "scikit-image",
      "opencv-python-headless",
      "matplotlib (>3.0.0)",
      "python-Levenshtein",
      "calamari-ocr (==0.3.5)"
    ],
    "requires_python": "",
    "summary": "CIS OCR-D command line tools",
    "version": "0.0.10",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 7596607,
  "releases": {
    "0.0.10": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "14c6eb72d39cdf3e19295176ed78729cc9d206fd3a3ac8eb2d477ce6b8d99a85",
          "md5": "c3f76ee88a363f7b4810c774f42b0b24",
          "sha256": "d6a9fc8d153e0f921b7cba630a34dc75fc63c010f61df30e6004f6d30bed3a90"
        },
        "downloads": -1,
        "filename": "ocrd_cis-0.0.10-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "c3f76ee88a363f7b4810c774f42b0b24",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 41383443,
        "upload_time": "2020-06-30T13:56:50",
        "upload_time_iso_8601": "2020-06-30T13:56:50.548421Z",
        "url": "https://files.pythonhosted.org/packages/14/c6/eb72d39cdf3e19295176ed78729cc9d206fd3a3ac8eb2d477ce6b8d99a85/ocrd_cis-0.0.10-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "30a922125125e3ef64ca81b92a065d50c96e59a1461b2dc9f351e3c008111c2e",
          "md5": "9c93d9adb64d66af1d17c09590a2ac99",
          "sha256": "774597b57e3ddad90806eaa6579325a97e0ee60a414dae0f9a90abab66057c56"
        },
        "downloads": -1,
        "filename": "ocrd_cis-0.0.10.tar.gz",
        "has_sig": false,
        "md5_digest": "9c93d9adb64d66af1d17c09590a2ac99",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 124240,
        "upload_time": "2020-06-30T13:56:53",
        "upload_time_iso_8601": "2020-06-30T13:56:53.601620Z",
        "url": "https://files.pythonhosted.org/packages/30/a9/22125125e3ef64ca81b92a065d50c96e59a1461b2dc9f351e3c008111c2e/ocrd_cis-0.0.10.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f7e05e3953c9243d05859e679bb83bef9c6f08e10fe0eef736fce90bc42657bc",
          "md5": "a186d34dad8d16c13d12af2d0b6d889b",
          "sha256": "ac2ada13f48b301831e41cba1e9a86b8e10ac2e8f4036ecdda9eb3524e36461c"
        },
        "downloads": -1,
        "filename": "ocrd_cis-0.0.6-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "a186d34dad8d16c13d12af2d0b6d889b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 34044792,
        "upload_time": "2019-11-05T19:37:33",
        "upload_time_iso_8601": "2019-11-05T19:37:33.819139Z",
        "url": "https://files.pythonhosted.org/packages/f7/e0/5e3953c9243d05859e679bb83bef9c6f08e10fe0eef736fce90bc42657bc/ocrd_cis-0.0.6-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8aa91fab502623c41529c13b4ecbedfe224f35843160ddcef4c527a18cfe73b8",
          "md5": "5c8c3934a2a4fe764c112d8fd12a5ffc",
          "sha256": "97aea3f172a5eda7272113eb99d55fddda0a96069a20173ea17563d0532bbd55"
        },
        "downloads": -1,
        "filename": "ocrd_cis-0.0.6.tar.gz",
        "has_sig": false,
        "md5_digest": "5c8c3934a2a4fe764c112d8fd12a5ffc",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 96645,
        "upload_time": "2019-11-05T19:37:38",
        "upload_time_iso_8601": "2019-11-05T19:37:38.406783Z",
        "url": "https://files.pythonhosted.org/packages/8a/a9/1fab502623c41529c13b4ecbedfe224f35843160ddcef4c527a18cfe73b8/ocrd_cis-0.0.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "38c310637d7c51e3d6a0e5e5004476dcf2de093e1e3bec8452e241dcf1fa595c",
          "md5": "539c82850462be8013eb31938e7779cf",
          "sha256": "c3d5898c869ae8c88db28fd52907bcabf1ac0d5cd474f73a30a1ff06615c3dbe"
        },
        "downloads": -1,
        "filename": "ocrd_cis-0.0.7-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "539c82850462be8013eb31938e7779cf",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 34044484,
        "upload_time": "2019-12-02T15:30:28",
        "upload_time_iso_8601": "2019-12-02T15:30:28.430896Z",
        "url": "https://files.pythonhosted.org/packages/38/c3/10637d7c51e3d6a0e5e5004476dcf2de093e1e3bec8452e241dcf1fa595c/ocrd_cis-0.0.7-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b8cb3fdc4daee6b85b732913c012cf41cafaab708b367c3fd5883d0d8e99c1b1",
          "md5": "7df03598c04d60203afb00c61ff836da",
          "sha256": "3629b49d32e1626830b6890f6d47793474fcb3232e4b12c43d5d3f38bb33f08d"
        },
        "downloads": -1,
        "filename": "ocrd_cis-0.0.7.tar.gz",
        "has_sig": false,
        "md5_digest": "7df03598c04d60203afb00c61ff836da",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 96590,
        "upload_time": "2019-12-02T15:30:33",
        "upload_time_iso_8601": "2019-12-02T15:30:33.037095Z",
        "url": "https://files.pythonhosted.org/packages/b8/cb/3fdc4daee6b85b732913c012cf41cafaab708b367c3fd5883d0d8e99c1b1/ocrd_cis-0.0.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "14c6eb72d39cdf3e19295176ed78729cc9d206fd3a3ac8eb2d477ce6b8d99a85",
        "md5": "c3f76ee88a363f7b4810c774f42b0b24",
        "sha256": "d6a9fc8d153e0f921b7cba630a34dc75fc63c010f61df30e6004f6d30bed3a90"
      },
      "downloads": -1,
      "filename": "ocrd_cis-0.0.10-py2.py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "c3f76ee88a363f7b4810c774f42b0b24",
      "packagetype": "bdist_wheel",
      "python_version": "py2.py3",
      "requires_python": null,
      "size": 41383443,
      "upload_time": "2020-06-30T13:56:50",
      "upload_time_iso_8601": "2020-06-30T13:56:50.548421Z",
      "url": "https://files.pythonhosted.org/packages/14/c6/eb72d39cdf3e19295176ed78729cc9d206fd3a3ac8eb2d477ce6b8d99a85/ocrd_cis-0.0.10-py2.py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "30a922125125e3ef64ca81b92a065d50c96e59a1461b2dc9f351e3c008111c2e",
        "md5": "9c93d9adb64d66af1d17c09590a2ac99",
        "sha256": "774597b57e3ddad90806eaa6579325a97e0ee60a414dae0f9a90abab66057c56"
      },
      "downloads": -1,
      "filename": "ocrd_cis-0.0.10.tar.gz",
      "has_sig": false,
      "md5_digest": "9c93d9adb64d66af1d17c09590a2ac99",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 124240,
      "upload_time": "2020-06-30T13:56:53",
      "upload_time_iso_8601": "2020-06-30T13:56:53.601620Z",
      "url": "https://files.pythonhosted.org/packages/30/a9/22125125e3ef64ca81b92a065d50c96e59a1461b2dc9f351e3c008111c2e/ocrd_cis-0.0.10.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}