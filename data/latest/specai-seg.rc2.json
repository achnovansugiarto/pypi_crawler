{
  "info": {
    "author": "Scout Cabe Jarman",
    "author_email": "scoutjarman@yahoo.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Environment :: GPU :: NVIDIA CUDA",
      "Intended Audience :: Education",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: GNU General Public License v3 (GPLv3)",
      "Natural Language :: English",
      "Programming Language :: Cython",
      "Programming Language :: Python :: 3",
      "Topic :: Scientific/Engineering :: Artificial Intelligence",
      "Topic :: Scientific/Engineering :: Image Processing",
      "Topic :: Scientific/Engineering :: Visualization"
    ],
    "description": "# SpecAI.Seg\n\nAML 2022 summer project code, Hyperspectral Image Segmentation Uncertainty Quantification (SpecAI.Seg).\n\n# Acknowledgments\n\n© 2023. Triad National Security, LLC. All rights reserved.\n\nThis program was produced under U.S. Government contract 89233218CNA000001 for Los Alamos\nNational Laboratory (LANL), which is operated by Triad National Security, LLC for the U.S.\nDepartment of Energy/National Nuclear Security Administration. All rights in the program are\nreserved by Triad National Security, LLC, and the U.S. Department of Energy/National Nuclear\nSecurity Administration. The Government is granted for itself and others acting on its behalf a\nnonexclusive, paid-up, irrevocable worldwide license in this material to reproduce, prepare\nderivative works, distribute copies to the public, perform publicly and display publicly, and to permit\nothers to do so.\n\n\nCode for the datasets.py, and util.py was originally adapted and modified the from the [DeepHyperX](https://github.com/nshaud/DeepHyperX/) package.\n\nNicolas Audebert, Bertrand Le Saux and Sébastien Lefèvre\n\"Deep Learning for Classification of Hyperspectral Data: A comparative review\",\nIEEE Geosciences and Remote Sensing Magazine, 2019.\n\nCode for some of the segmentation algorithms (Felzenszwalb, Quickshift, SLIC, and Watershed) use modified code from [skimage](https://scikit-image.org/docs/stable/api/skimage.segmentation.html) to work with more than 3 channels.\nThe cython code for SLIC was copied an modified from the skimage package so that it can use cosine distance.\n\nThe authors acknowledge the Aerospace Corporation for collecting and providing the historical airborne LWIR data from the Los Angeles basin area.\n\n<!-- # TODO\n\n1. Segmentation and Classification Models\n    * Modify skimage models to work with multichannels\n        * [X] Felzenszwalb\n        * [X] Quickshift\n        * [X] SLIC\n        * [X] Watershed\n    * Explore additional models\n        * [ ] Multi-scale segmentation\n        * [ ] Multi-scale segmentation ++ (region split/merge with UQ optimization)\n        * [X] SlURM\n        * [X] Hierarchical clustering\n    * ~~Super pixel classification methods~~\n        * [ ] ~~Wrap DeepHyperX models~~\n        * [ ] ~~Create appropriate training/data augmentation loops~~\n    * Dimensionality reduction methods\n        * [ ] PCA\n        * [ ] T-SNE\n        * [ ] PHATE\n        * [ ] PHATE spatial\n2. Segmentation Evaluation Metrics\n    * Unsupervised evaluation metrics\n        * [x] Zeb\n        * [x] Frc (should investigate a non-uniform implementation)\n        * [ ] ~~Vcp (will need to figure out texture measures)~~\n    * ~~Supervised Evaluation Metrics~~\n        * [ ] ~~Pixel Accuracy~~\n        * [ ] ~~IoU/MIoU~~\n        * [ ] ~~Dice~~\n        * [ ] ~~Others from literature~~\n3. Uncertainty Quantification\n    * ~~Classification Uncertainty~~\n        * [ ] ~~Predicted Probability Entropy~~\n        * [ ] ~~Ensemble UQ~~\n    * Segmentation Unvertainty Quantification\n        * [X] Random Radial Inclusion/Exclusion, Inverse SD Q Score, Average Ratio of E/S Q Scores -->\n\n\n# Examples\n\nThe following shows examples on some standard tasks.\n\n## Loading Data\n_______________\n\n\nThis is general workflow for loading data to work well with the functions in this package.\nFirst import the `datasets` module to access the functions to load data.\nThe most common function to use is the `datasets.get_data` function.\nThis function needs the name of the image/dataset you want to load.\nThere are 6 easily accessible standard HSI datasets that can be automatically downloaded.\nThey are IndianPines, Botswana, KSC, PaviaC, PaviaU, and Salinas.\n\n```python\nfrom specaiseg import datasets\n\nindianPines = datasets.get_data('IndianPines')\npaviaU = datasets.get_data('PaviaU')\n```\n\nOther arguments for `get_data` are the `target_folder` (defaults to `./Data`),\nthis is the folder to download new data to, or to find already downloaded data.\n`datasets` is a dictionary to specify how to download the image, and other metadata,\nthe default will load the dict from `data_raw/datasets.csv` which has info for the 6\nstandard datasets.\nYou can specify your own dict if it has the correct keys (see documentation for `get_data`).\n`clip_p` specifies the top and bottom percent to clip the values on when standardizing.\n\n<!-- ~~For custom images, you may need to create your own dataset dictionary modeled after the~~\n~~dataset dictionary returned from `get_data`.~~\n~~At the very least it should have an `img`, `img_rgb`, and `name` keys.~~\n~~If you don't know which channels are the rgb channels, you can choose any 3 channels.~~ -->\n\nSupport has been added for loading in your own images and data types.\nThe `get_custom_data` function works by you passing in the filepath to the data you want to load.\nYou can also specify a custom `load_function` if you're data type is not supported in the `utils.open_file` function.\nNote that if you specify a file without an extension, it will assume it is `.hdr` and load it using the\ncode from the `pyHAT` project.\nIf the load function also comes with wavelength information, then a false grayscale and rgb image will be made\nusing the `utils.false_grey_img` function.\nThe return dictionary contains the raw image, the image with values clipped, the image standardized between 0-1, the rgb and gray images, as well the result from loading the data, and the wavelengths if included, as well as a name.\nHere is an example.\n\n```python\nfrom specaiseg import datasets\n\nfile = 'data/image_folder/'\nds = datasets.get_custom_data(file)\n```\n\n## Segmenting Images\n____________________\n\nFor all of the segmenters in `models.segmenters`, you can pass in the dict returned from\n`get_data`, or you can pass in a numpy array where the 3rd axis is the spectral axis.\nThat is `img[0, 0, :]` should return the spectra for the pixel located at (0, 0).\nThere are 4 segmenters that originate from the `skimage.segmentation` module, but they have\nbeen wrapped to all share a come interface.\nSpecifically all segmenters are extensions of a `Segmenter` class.\nWhen you initialize a `Segmenter`, you can save the object to reference what parameters were set,\nor you can initialize and call `get_segmentation` right away to just get the segment.\n\n```python\nfrom specaiseg import datasets\nfrom specaiseg.models.segmenters import Slic, Watershed, Slurm\n\n# loads the indian pines image\nindianPines = datasets.get_data('IndianPines')\n\n# initizalize a segmenter object, then get segmentation.\n# Recommended for Slurm to save the slurm object (keep the history).\nseger = Slurm(indianPines)\nseg = seger.get_segmentation()\n\n# Don't need to keep track of seger if you don't want to\nseg = Slic(indianPines).get_segmentation()\n\n# can just pass in an image on it's own\nimg = indianPines['img']\nseg = Watershed(img).get_segmentation()\n```\n\n## Basic Plotting\n__________________\n\nSee the More Plotting section for more ways to plot segmentations.\nThis is the most simple way to plot a segment, use the `plotting.plot_seg` function.\nThis can create a segmentation, or plot a provided segmentation.\nIt can also save a plot and auto generate a unique file path.\n\n```python\nimport matplotlib.pyplot as plt\n\nfrom specaiseg import datasets\nfrom specaiseg.models.segmenters import Slic\nfrom specaiseg.plotting import plot_seg\n\n# load data\nds = datasets.get_data('IndianPines')\n# get segmentation\nseg = Slic(ds, n_segments=200, compactness=0.005).get_segmentation()\n# plot seg\nplot_seg(ds, Slic, seg=seg, alg_args={'n_segments':200, 'compactness':0.005}, save=False)\nplt.show()\n\n\n# to have it create a seg on it's own, create dict of params\nalg_args = {'n_segments':200, 'compactness':0.005}\nplot_seg(ds, Slic, alg_args=alg_args, save=False)\nplt.show()\n```\n\n![First resulting plot.](readme_figures/basic_plotting_1.png)\n![Second resulting plot.](readme_figures/basic_plotting_2.png)\n\n## Felzenszwalb\n______________\n\nThe Felzenszwalb segmenter appears to be good at finding large homogenous regions such as bodies of water,\nbut also creates small stringy segments inbetween such large regions.\nI have found that setting the `scale` to be between 500-2000 helps reduce oversegmentation,\nfor larger images use a larger scale if you want to reduce computation time.\nIt may also help to increase the `sigma` parameter (increase the gaussian blurring in pre-processing),\nand to increase the `min_size` parameter (which merges small regions in pos-processing).\nThis does tend to be a pretty quick segmenter, as long as the scale is high enough.\n\n```python\nfrom specaiseg import datasets\nfrom specaiseg.models.segmenters import Felzenszwalb\nfrom specaiseg.plotting import plot_seg\n\nds = datasets.get_data('PaviaC')\nalg_args = {'scale':2000, 'sigma':1.2, 'min_size':10}\nseg = Felzenszwalb(ds, **alg_args).get_segmentation()\nplot_seg(ds, Felzenszwalb, alg_args=alg_args, save=False)\n```\n\n![Plot of Felzenszwalb on PaviaC](readme_figures/felzenszwalb_1.png)\n\n\n## Quickshift\n_____________\n\nQuickshift appears to be a pretty slow algorithm, so I haven't done much\nexperimentation with the parameters.\n\n```python\nfrom specaiseg import datasets\nfrom specaiseg.models.segmenters import Quickshift\nfrom specaiseg.plotting import plot_seg\n\nds = datasets.get_data('IndianPines')\nseg = Quickshift(ds).get_segmentation()\nplot_seg(ds, Quickshift, save=False)\n```\n\n![Plot of Quickshift on indianPines](readme_figures/quickshift_1.png)\n\n\n## Slic\n_________\n\nSlic is one of my favorite segmentation algorithms.\nIt creates very gridded segmentations, at is pretty good at finding edges.\nI made two implementations, the original uses euclidean distance, mine uses cosine distance.\nIf using `dist_func='euclid'`, I would recommend starting `compactness` around 1.\nIf using `dist_func='cos'`, I would recommend starting `compactness` around 0.005.\nUsing a larger `compactness` will create more square regions, smaller value will create\ncrazier regions.\nNote that `n_segments` is only approximatley the number of segments.\n\n```python\nimport matplotlib.pyplot as plt\n\nfrom specaiseg import datasets\nfrom specaiseg.models.segmenters import Slic\nfrom specaiseg.plotting import plot_seg\n\nds = datasets.get_data('IndianPines')\nalg_args = {'n_segments':300, 'dist_func':'cos', 'compactness':0.005}\nseg = Slic(ds, **alg_args).get_segmentation()\nplot_seg(ds, Slic, alg_args=alg_args, save=False)\nplt.show()\n\nalg_args = {'n_segments':300, 'dist_func':'euclid', 'compactness':1}\nseg = Slic(ds, **alg_args).get_segmentation()\nplot_seg(ds, Slic, alg_args=alg_args, save=False)\nplt.show()\n```\n\n![Slic using cosine distance on indianPines](readme_figures/slic_1.png)\n![Slic using euclidean distance on indianPiones](readme_figures/slic_2.png)\n\n\n## Watershed\n____________\n\nThis implementation of Watershed will create an image gradient using the\nRobust Color Morphological Gradient.\nThis is also a somewhat slow algorithm compared to `Slic`.\nAlso note that if you specify `markers` (the number of segments), it will\nrandomly place the marker locations.\nThus increasing `markers` will produce chaotic segments because the markers\nare being randomly placed every time.\n\n```python\nimport matplotlib.pyplot as plt\n\nfrom specaiseg import datasets\nfrom specaiseg.models.segmenters import Watershed\nfrom specaiseg.plotting import plot_seg\n\nds = datasets.get_data('IndianPines')\nalg_args = {'markers': 100}\nseg = Watershed(ds, **alg_args).get_segmentation()\nplot_seg(ds, Watershed, alg_args=alg_args, save=False)\nplt.show()\n\nds = datasets.get_data('IndianPines')\nalg_args = {'markers': 110}\nseg = Watershed(ds, **alg_args).get_segmentation()\nplot_seg(ds, Watershed, alg_args=alg_args, save=False)\nplt.show()\n```\n\n![Watershed with 100 markers on indianPines](readme_figures/watershed_1.png)\n![Watershed with 110 markers on indianPines](readme_figures/watershed_2.png)\n\n## SlURM\n________\n\nThis is a segmentation algorithm I created.\nIt is based on creating an oversegmentation from Slic, and then merging\nregions based on Segment Uncertainty Quantification (SUQ score).\nThis is a slow algorithm, and can be difficult to tune given the number of parameters.\n\n```python\nimport matplotlib.pyplot as plt\n\nfrom specaiseg import datasets\nfrom specaiseg.models.segmenters import Slurm\nfrom specaiseg.plotting import plot_seg\n\nds = datasets.get_data('salinas')\n\n# This will take about 15 minutes to run\nobj = Slurm(salinas, iters=10, n_thread=36, seger_args={'compactness':.005, 'dist_func':'cos'},\n            min_size=100, uq_args={'n':1, 'p':1, 'r':1, 'min_pixels':4},\n            scale_r_with_iters=True, merge_order='mixed', high_percentile=50, max_per_dec=.2)\nseg = obj.get_segmentation()\n\nplot_seg(salinas, Slurm, seg=obj.segs[0], save=False)\nplt.show()\nplot_seg(salinas, Slurm, seg=obj.segs[4], save=False)\nplt.show()\nplot_seg(salinas, Slurm, seg=obj.segs[-1], save=False)\nplt.show()\n```\n\n![Slurm initial segmentation on Salinas](readme_figures/slurm_1.png)\n![Slurm's 4th iteration on Salinas](readme_figures/slurm_2.png)\n![Slurm's 10th and final iteration on Salinas](readme_figures/slurm_3.png)\n\nTo create plots of each iteration of `Slurm`, you can do something like the following.\nThis will show the segment, and the SUQ scores at each iteration.\nSee the More Plotting section for a gif of these plots.\n\n```python\nimport matplotlib.pyplot as plt\n\nfrom specaiseg import datasets\nfrom specaiseg.models.segmenters import Slurm\nfrom specaiseg.plotting import plot_SUQ\n\nds = datasets.get_data('salinas')\nobj = Slurm(salinas)\nseg = obj.get_segmentation()\n\nfor i in range(len(obj.segs)):\n    plot_SUQ(ds, Slurm, 'iters', i, seg=obj.segs[i], uq=obj.uqs[i][1],\n             save=False, vmax=1.4, vmin=0)\n    plt.show()\n```\n\n\n## Segmentation Uncertainty Quantification\n_________________________________________\n\nSegmentation Uncertainty Quantification (SUQ score) is a way to measure the uncertainty\nabout a region and it's boundary.\nIt can be summarized as \"see how a quality score changes as the region changes. If the\nquality changes a lot, then there is low uncertainty; if the quality changes a little, then\nthere is high uncertainty\".\nThis is a general score which can have many different implementations.\nHere we implent it with the following specifications:\n    1. Quality Score: inverse standard deviation.\n    2. Boundary Perturbation: Random Radial Inclusion/Exclusion\n    3. Quantification Equation: Average Ratio of E/S Region Q Scores.\nSee the documentation for `uq.suqs.suqsES` on the implementation and details for this SUQ score.\n\nUsing `uq.suqs.suqsES`, you can estimate the uncertainty for a certain region, all regions in a segmentation,\nget the quality score for a region, and get the UQ or Q score if two (or more) regions are merged.\nThere is also an accompanying plotting function `plotting.plot_SUQ` to help visualize the SUQ scores for a region.\nHere is a basic example of finding the SUQ scores.\n\n```python\nfrom specaiseg import datasets\nfrom specaiseg.models.segmenters import Slic\nfrom specaiseg.plotting import plot_SUQ\nfrom specaiseg.uq.suqs import suqsES\n\n# first create a segmentation\nds = datasets.get_data('indianPines')\nseg = Slic(ds, n_segments=350).get_segmentation()\n\n# gets a list of SUQ score and dict of SUQ scores\nuq_l, uq_d = suqsES(ds, seg).get_uq()\nplot_SUQ(ds, Slic, seg=seg, uq=uq_d, save=False)\n```\n\n![Plot of SUQ from Slic on IndianPines](readme_figures/suq_1.png)\n\nYou can also get single region SUQ or Q scores, as well what the SUQ and Q score would be if multiple regions were merged.\n\n```python\n# Get SUQ for all regions\nsuq = suqsES(ds, seg)\nuq_l, uq_d = suq.get_uq()\n\n# Get SUQ for region 1\nuq_1 = suq.get_uq_reg(1)\n# Get SUQ for region 1 and 2 as if they were the same region\nuq_1and2 = suq.get_uq_reg(1, 2)\n\n# Similarly if you just want the Q scores\nq_1 = suq.get_q_score_reg(1)\nq_1and2 = suq.get_q_score_reg(1, 2)\n```\n\nYou can also get the simulated enlarged/shrunken/original boundaries, along with the enlarged/shrunken/original Q scores, and the overall SUQ score using `get_e_s_boundaries`.\nThere is also a plotting function to show these regions.\n\n```python\n# get all of the values for finding the SUQ score,\n# where enlarged, shrunken, and original are boolean arrays,\n# Q_e, Q_s, Q_o are the quality scores respectively, and uq is the final score.\nenlarged, shrunken, original, Q_e, Q_s, Q_o, uq = suq.get_e_s_boundaries(1)\n\n# To plot use this\nfrom specaiseg.plotting import plot_individual_SUQ\nplot_individual_SUQ(ds, seg, 215, save=False, uq_args={'r':2, 'p':.65}, seed=420)\n```\n\n![Plot of a single SUQ score simulation](readme_figures/suq_2.png)\n\n## Image Whitening, ROIs, and Model Inference\n_____________________________________________\n\nOne of the purposes of this package is to help investigate how image segmentation can be used to help in gas plume detection in HSI.\nA specific area to try to improve is in the whitening of spectra before classification.\nCurrently, it is common to use all the spectra in an image to estimate a covariance matrix, and a mean spectra, so that the image can\nbe whitened by doing $C^{-1/2}(x-\\bar{x})$ for all pixels $x$ in the image.\nA potentially better approach is to whiten pixels locally instead of globablly.\nHere we use a segmentation of an image to define the regions to locally find a covariance matrix and mean spectra, and to whiten pixels\ninside the segment using that local covariance and mean spectra.\n\nFirst, to find the globally whitened version of an image, you can do the following.\n\n```python\nfrom specaiseg.datasets import get_custom_data\nfrom specaiseg.whitening import whiten_img\n\nfile = 'data/image_folder'\nds = get_custom_data(file)\n\n# isr_cov is the inverse square root of the covariance matrix\nimg_all, means, isr_cov = whiten_img(ds['img_raw'])\n```\n\nTo do local whitening, you specify a segmentation map to use, and what segments to whiten.\nThe default is to whiten all pixels in the image; you can also specify a x and y max and min values to only whiten a certain section of the image.\nIn this implementation, there is an `r` parameter, which specifies how many additional boundary layers should be included in the calculation of the covariance and mean.\nIncluding extra pixels helps create a more stable covariance estimate.\nYou can let `r=None`, which will make it so that each region will keep including boundary layers untill it has at least as many pixels as there are spectral channels.\nIn conjunction with `r=None` you can specify `min_r` which will be the number of boundary layers to included before checking if there are enough pixels.\nThe default is to have `r=None` and `min_r=3`\nThe command is the same as above, but now you need a segmentation.\n\n```python\nfrom specaiseg.models.segmenters import Watershed\nfrom specaiseg.plotting import plot_seg_spectra\nfrom matplotlib import pyplot as plt\n\nseg_water = Watershed(ds, markers=300).get_segmentation()\nimg_water, means, isr_cov = whiten_img(ds['img_raw'], seg=seg_water)\n\n# Can use seg spectra to see the difference between the original and whitened spectra\nplot_seg_spectra(ds, Watershed, seg=seg_water, fig_size=(20, 2), rotation=-90, top_to_bottom=True, name='Original Spectra')\nplt.show()\n\ny=.75\nplot_seg_spectra(img_water, Watershed, rgb_img=ds['img_rgb'], seg=seg_water, fig_size=(20, 2), rotation=-90,\n                 top_to_bottom=True, y_min=-y, y_max=y, name='Locally Whitened Spectra')\nplt.show()\n```\n\n![Original mean spectra for watershed segmentation](readme_figures/whitening_1.png)\n![Whitened mean spectra for watershed segmentation](readme_figures/whitening_2.png)\n\n\nTo load in a region of interest from a JSON file (formatted like what is used with DeepHAT), simply use `get_roi`.\nYou have to specify the image you want the pixels to be extracted from, and an rgb image which is used to create\nan image with the ROI pixels in red.\nIn `plot_seg_spectra`, we set the img to be either the raw image, or the whitened image.\nFor the rgb imgage, we use `RGB_MASK` image from the roi dict because it will have the ROI pixels in red.\nAnd for the segmentation, we use the `IMG_MASK` from the roi dict which will be true where the ROI pixels are.\nNote that the images are on different y scales.\n\n```python\nfrom specaiseg.utils import get_roi\n\nroi_file = 'data/roi_info/roi.json'\nres = get_roi(roi_file, ds['img_raw'], ds['img_rgb'])\n\nfor k in res.keys():\n    # Shows what the ROI spectra look like originally\n    plot_seg_spectra(ds['img_raw'], None, rgb_img=res[k]['RGB_MASK'], seg=res[k]['IMG_MASK'], fig_size=(20, 2),\n                     rotation=-90, alg_name=k, top_to_bottom=True, bound_args={'mode': 'thick'}, cmap_='copper',\n                     y_min=0, y_max=1)\n    plt.show()\n    # Shows what the ROI spectra look like whitened\n    y = 2.5\n    plot_seg_spectra(img_water, None, rgb_img=res[k]['RGB_MASK'], seg=res[k]['IMG_MASK'], fig_size=(20, 2),\n                     rotation=-90, alg_name=k, top_to_bottom=True, bound_args={'mode': 'thick'}, cmap_='copper',\n                     y_min=-y, y_max=y)\n    plt.show()\n```\n\n<!-- ![ROI 1 original spectra](readme_figures/roi_1.png)\n![ROI 2 whitened spectra](readme_figures/roi_2.png) -->\n![ROI 3 original spectra](readme_figures/roi_3.png)\n![ROI 4 whitened spectra](readme_figures/roi_4.png)\n<!-- ![ROI 5 original spectra](readme_figures/roi_5.png)\n![ROI 6 whitened spectra](readme_figures/roi_6.png) -->\n\nNow that we have a region of interest, and whitened spectra, we can load a classification model to try and classify these regions of interest.\nWe can load a DeepHAT model using `models.classifiers.TrainedModel`.\nBecause we have already found whitened data, we can pass it into the model.\n\n```python\nfrom specaiseg.models.classifiers import TrainedModel\n\nmodel_file = 'data/models/my_model.pt'\nmodel = TrainedModel(model_file, roi_file, ds, whiten=img_water)\n# n=5 says to print out the top 5 predictions for each ROI\nr = model.predict_roi(n=5)\n\n# output looks like:\n\"\"\"\n...\n\nNumber of substances for ROI gas_0752 in probability scores: 15693\n  ROI ID, Substance Name, Score\n\t gas_0752 Acetic acid 1\t       0.044508144\n\t gas_0752 Jarosite 1\t       0.02751269\n\t gas_0752 Jarosite 2\t       0.01573995\n\t gas_0752 fiberglass epoxy \t   0.01401442\n\t gas_0752 Acetic acid 2 \t   0.012509323\n\n...\n\n\"\"\"\n```\n\n## More Plotting\n________________\n\nThe last main plotting function is `plot_seg_spectra`, which allows you to plot each regions average spectra for a segmentation.\nThis lets you see how different segments capture different information.\nIt should be noted that this is prone to being a very busy plot with lots of overplotting if the given segment has many regions.\nBut that is unavoidable for large images with many segments.\nHere is an example.\n\n```python\nfrom specaiseg import datasets\nfrom specaiseg.models.segmenters import Slic\nfrom specaiseg.plotting import plot_seg_spectra\n\nds = datasets.get_data('paviaC')\nseg = Slic(ds, n_segments=1000).get_segmentation()\nplot_seg_spectra(ds, Slic, seg=seg, save=False, line_alpha=.6)\n```\n\n![Plot of average spectra for Slic on PaviaC](readme_figures/more_plotting_1.png)\n\n\nIf the image you are working with is a strange dimension (say very long and thin), then there are some plotting options to help format it to look better.\nHere is what the default plot will look like for this long image.\n\n```python\nfrom specaiseg import datasets\nfrom specaiseg.models.segmenters import Slic\nfrom specaiseg.plotting import plot_seg\n\nfile = 'data/image_folder/'\nds = datasets.get_custom_data(file)\nseg = Slic(ds, n_segments=2000).get_segmentation()\nplot_seg(ds, Slic, seg=seg)\n```\n\n![Default plot for long skinny image](readme_figures/more_plotting_2.png)\n\nTo fix this we change a couple of things.\nFirst we set `bound_args={'mode': 'thick'}` which will make the segment boarders more visible.\nThen we rotate the image by 90 degrees so that it plots long ways using `rotation=90`.\nLastly we increase the figure size by `fig_size=(15, 2)`, which will make the image 30 inches wide, and 5 inches tall.\nYou'll have to play around with the `fig_size` to get something you want.\nThis makes it much easier to see.\n\n```python\nplot_seg(ds, Slic, seg=seg, bound_args={'mode':'thick'}, fig_size=(15, 2), rotation=90)\n```\n\n![Adjusted version of the long skinny plot](readme_figures/more_plotting_3.png)\n\nYou will want to make similar changes when making a plot with subplots, such as when plotting SUQ.\nHere we also use `top_to_bottom` to make the plots stack on top of each other instead of being side by side.\nWe also use `colorbar=False` so that the colored image matches the dimensions of the segmentation image.\n\n```python\nfrom specaiseg.uq.suqs import suqsES\nfrom specaiseg.plotting import plot_SUQ\nuq_l, uq_d = suqsES(ds, seg, n=10, p=.65, r=2).get_uq()\nplot_SUQ(ds, Slic, seg=seg, uq=uq_d, rotation=90, top_to_bottom=True, fig_size=(30, 3.5),\n         colorbar=False, bound_args={'mode': 'thick'})\n```\n\n![Adjustment for SUQ plot for long skinny images](readme_figures/more_plotting_4.png)\n\nLastly we do the same thing for plotting the spectra averages.\nNote that with long images, it will simply be difficult to make good looking plots.\n\n```python\nfrom specaiseg.plotting import plot_seg_spectra\nplot_seg_spectra(ds, Slic, seg=seg, rotation=90, top_to_bottom=True, fig_size=(30, 3.5),\n                 bound_args={'mode':'thick'}, line_alpha=.5)\n```\n\n![Adjustment for seg averages for long images](readme_figures/more_plotting_5.png)\n\n\n\n## Making Gifs\n______________\n\nWe have functions to make individual plots of segmentations, segmentation spectra, SUQ scores, and individual SUQ regions.\nIt can be useful to see how these plots change as certain parameters for a segmentation model changes.\nTo help visualize this, it is helpful to create a gif of the same plot as these values change.\nWe will start with an example of making a gif a Slic segmentations as the compactness parameter changes.\nNote that all of the plotting functions have the ability to automatically generate a directory/filename to save the images (in such as a way that making gifs should be easy), but it might be easier to save the files yourself in the for loop that generates the plots.\n\nHere is an example of plotting the Slic algorithm over different values of compactness on Indian Pines.\nWe use the plotting functions file saving to save the plots for us.\n\n```python\nfrom tqdm.notebook import tqdm\n\nfrom specaiseg import datasets\nfrom specaiseg.models.segmenters import Slic\nfrom specaiseg.plotting import plot_seg\n\nds = datasets.get_data('IndianPines')\n\ncomp_vals = [0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001]\nsegs = []\nfor c in tqdm(comp_vals):\n    seg = Slic(ds, n_segments=400, compactness=c).get_segmentation()\n    segs.append(seg)\n\nfor s in tqdm(segs):\n    plot_seg(ds, Slic, seg=s, folder='./readme_figures/gif_1/', save=True)\n```\n\nThis will produce figures in the folder `./readme_figures/gif_1/IndianPines/Slic`, where the files are in the format `IndianPines_Slic_00xxx.png` where the xxx is the number of segments in that image.\nIn order to make these images into a gif, we use the command line tool `convert` from image magick.\nThe `-delay 100` means have 100 miliseconds per frame, `-dispose Previous` makes the frames not overlap each other, `-reverse` changes the order to go from most segments to least segments, `-loop 0` means to loop forever.\nThen you specify the general filepath, where the `*` is a wild card for the number of the plot, and the last file is where you want to save it.\n\n```bash\nconvert -delay 100 -dispose Previous -reverse -loop 0 readme_figures/gif_1/IndianPines/Slic/IndianPines_Slic_*.png readme_figures/gif_1.gif\n```\n\n![Gif of different Slic segmentations on IndianPines](readme_figures/gif_1.gif)\n\n\nNow here is an example of plotting different SUQ plots from a Slurm segmentation.\nThis time we will manually save the files to have more control over the save files.\nNote that to get files to number in order, it easy to use an `f` string with the file number formated with `{num:06d}`.\nThis will format so there are 6 total digits with leading zeros.\nYou can use less than 6 if you want to, just make sure you have at least one leading zero infront of your largest file number.\nThe file number can be anything, like a parameter used to make the plot, the number of segments in the plot, or just an index from a for loop.\nHere we use the index of a for loop to save and number our files.\n\n```python\nfrom specaiseg import datasets\nfrom specaiseg.models.segmenters import Slurm\nfrom specaiseg.plotting import plot_SUQ\n\n# Get Slurm segments\nds = datasets.get_data('IndianPines')\nobj = Slurm(ds, iters=10, n_thread=10, seger_args={'compactness':.005, 'dist_func':'cos'}, \n            min_size=20, uq_args={'n':10, 'p':.65, 'r':1}, scale_r_with_iters=True, \n            merge_order='mixed', high_percentile=50, max_per_dec=.2)\nseg = obj.get_segmentation()\n\n# Plot all the Slurm segments and SUQ\nfor i in range(len(obj.segs)):\n    plot_SUQ(ds, Slurm, 'iters', i, seg=obj.segs[i], uq=obj.uqs[i][1],\n             save=False, vmax=1.2, vmin=0)\n    plt.savefig(f'./readme_figures/gif_2/Slurm_{i:03d}')\n    plt.show()\n```\n\n```bash\nconvert -delay 100 -dispose Previous -loop 0 readme_figures/gif_2/Slurm_*.png readme_figures/gif_2.gif\n```\n\n![Gif of SUQ from Slurm on IndianPines](readme_figures/gif_2.gif)\n\n\nLastly, this is how to make a gif for different simulations of a region while calculating the SUQ score.\n\n```python\nfrom specaiseg.datasets import get_data\nfrom specaiseg.models.segmenters import Slic\nfrom specaiseg.plotting import plot_individual_SUQ\n\nds = get_data('indianPines')\nseg = Slic(ds, n_segments=200, compactness=.005).get_segmentation()\n\n# Get example of Low UQ region\nfor s in range(10):\n    plot_individual_SUQ(ds, seg, 130, uq_args={'r':2, 'p':.65}, seed=s, save=True,\n                        folder='./readme_figures/gif_3')\n\n# Get example of high UQ region\nfor s in range(10):\n    plot_individual_SUQ(ds, seg, 152, uq_args={'r':2, 'p':.65}, seed=s, save=True,\n                        folder='./readme_figures/gif_3')\n```\n\n\n```bash\nconvert -delay 80 -dispose Previous -loop 0 readme_figures/gif_3/IndianPines/SegSUQ/IndianPines_130_*.png readme_figures/gif_3_low.gif\n\nconvert -delay 80 -dispose Previous -loop 0 readme_figures/gif_3/IndianPines/SegSUQ/IndianPines_152_*.png readme_figures/gif_3_high.gif\n```\n\n![Gif of SUQ from Slurm on IndianPines](readme_figures/gif_3_low.gif)\n![Gif of SUQ from Slurm on IndianPines](readme_figures/gif_3_high.gif)\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/lanl/specaiseg",
    "keywords": "Hyperspectral Image Analysis Image Segmentation",
    "license": "GPLv3",
    "maintainer": "",
    "maintainer_email": "",
    "name": "SpecAI.Seg",
    "package_url": "https://pypi.org/project/SpecAI.Seg/",
    "platform": null,
    "project_url": "https://pypi.org/project/SpecAI.Seg/",
    "project_urls": {
      "Homepage": "https://github.com/lanl/specaiseg"
    },
    "release_url": "https://pypi.org/project/SpecAI.Seg/1.0.3/",
    "requires_dist": [
      "numpy",
      "pandas",
      "torch",
      "scikit-image",
      "scipy",
      "scikit-learn",
      "tqdm",
      "spectral",
      "matplotlib"
    ],
    "requires_python": ">=3",
    "summary": "Code for doing hyperspectral image segmentation and uncertainty quantification.",
    "version": "1.0.3",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16849112,
  "releases": {
    "1.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0664b298b85eaf5cf5df72011ad9b920334d5d6d6b1629ae71a471748c073709",
          "md5": "5cccded5cbd4fe501532e323484ecf97",
          "sha256": "d4d7368b7e90ec075fc6091a5b1777d71fa15ed710e0f18c0dd06bc856cca341"
        },
        "downloads": -1,
        "filename": "SpecAI.Seg-1.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "5cccded5cbd4fe501532e323484ecf97",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3",
        "size": 86686,
        "upload_time": "2023-02-14T01:32:50",
        "upload_time_iso_8601": "2023-02-14T01:32:50.296447Z",
        "url": "https://files.pythonhosted.org/packages/06/64/b298b85eaf5cf5df72011ad9b920334d5d6d6b1629ae71a471748c073709/SpecAI.Seg-1.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "41814488b49d037beb2b3735d1f1ee8a184c266a490d97f88954e43133779cf5",
          "md5": "2f8948b6757951469a7d2d85b90f5a08",
          "sha256": "8b0a27b89a2d80f5a98fbaa8c5999903013aacab847e7a97a28f4193d7715c1d"
        },
        "downloads": -1,
        "filename": "SpecAI.Seg-1.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "2f8948b6757951469a7d2d85b90f5a08",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3",
        "size": 87818,
        "upload_time": "2023-02-14T01:32:52",
        "upload_time_iso_8601": "2023-02-14T01:32:52.787005Z",
        "url": "https://files.pythonhosted.org/packages/41/81/4488b49d037beb2b3735d1f1ee8a184c266a490d97f88954e43133779cf5/SpecAI.Seg-1.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "54d6c7679b372092152781198b54bc8ced5d9f2da8fc12d331c07bda36492953",
          "md5": "dc5ae207e8db8e044d982cca1d184984",
          "sha256": "40a02a31f03420ff70193c30322a58141738abb8ea312bc3c52abb180bea84d7"
        },
        "downloads": -1,
        "filename": "SpecAI.Seg-1.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "dc5ae207e8db8e044d982cca1d184984",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3",
        "size": 86790,
        "upload_time": "2023-02-14T01:45:40",
        "upload_time_iso_8601": "2023-02-14T01:45:40.159370Z",
        "url": "https://files.pythonhosted.org/packages/54/d6/c7679b372092152781198b54bc8ced5d9f2da8fc12d331c07bda36492953/SpecAI.Seg-1.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "180bba307c6955f1e65999da115d8b110768e3f101d04e2333d8af6dfa0b4029",
          "md5": "1262ad8a46e650352eae63432f63425d",
          "sha256": "1accf32017f38b5f8abd43a7c645e57c52dfcfdf3fda17abb35f008e371fa659"
        },
        "downloads": -1,
        "filename": "SpecAI.Seg-1.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "1262ad8a46e650352eae63432f63425d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3",
        "size": 87945,
        "upload_time": "2023-02-14T01:45:42",
        "upload_time_iso_8601": "2023-02-14T01:45:42.653289Z",
        "url": "https://files.pythonhosted.org/packages/18/0b/ba307c6955f1e65999da115d8b110768e3f101d04e2333d8af6dfa0b4029/SpecAI.Seg-1.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "54d6c7679b372092152781198b54bc8ced5d9f2da8fc12d331c07bda36492953",
        "md5": "dc5ae207e8db8e044d982cca1d184984",
        "sha256": "40a02a31f03420ff70193c30322a58141738abb8ea312bc3c52abb180bea84d7"
      },
      "downloads": -1,
      "filename": "SpecAI.Seg-1.0.3-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "dc5ae207e8db8e044d982cca1d184984",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3",
      "size": 86790,
      "upload_time": "2023-02-14T01:45:40",
      "upload_time_iso_8601": "2023-02-14T01:45:40.159370Z",
      "url": "https://files.pythonhosted.org/packages/54/d6/c7679b372092152781198b54bc8ced5d9f2da8fc12d331c07bda36492953/SpecAI.Seg-1.0.3-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "180bba307c6955f1e65999da115d8b110768e3f101d04e2333d8af6dfa0b4029",
        "md5": "1262ad8a46e650352eae63432f63425d",
        "sha256": "1accf32017f38b5f8abd43a7c645e57c52dfcfdf3fda17abb35f008e371fa659"
      },
      "downloads": -1,
      "filename": "SpecAI.Seg-1.0.3.tar.gz",
      "has_sig": false,
      "md5_digest": "1262ad8a46e650352eae63432f63425d",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3",
      "size": 87945,
      "upload_time": "2023-02-14T01:45:42",
      "upload_time_iso_8601": "2023-02-14T01:45:42.653289Z",
      "url": "https://files.pythonhosted.org/packages/18/0b/ba307c6955f1e65999da115d8b110768e3f101d04e2333d8af6dfa0b4029/SpecAI.Seg-1.0.3.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}