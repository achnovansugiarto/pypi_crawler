{
  "info": {
    "author": "Daniel van Strien",
    "author_email": "daniel.van-strien@bl.uk",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Natural Language :: English",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8"
    ],
    "description": "# nnanno\n> Sample, annotate and apply computer vision models to the Newspaper Navigator dataset  \n\n\n[![CI](https://github.com/Living-with-machines/nnanno/actions/workflows/main.yml/badge.svg)](https://github.com/Living-with-machines/nnanno/actions/workflows/main.yml)\n\n## tl;dr\n\n`nnanno` is a modest collection of tools to help work with the delightful [Newspaper Navigator](https://news-navigator.labs.loc.gov/) data. \n\n## nnanno\n\n[Newspaper Navigator](https://news-navigator.labs.loc.gov/) is a project which extracted visual content (pictures, maps etc.) from the Library of Congress [Chronicling America](https://chroniclingamerica.loc.gov/) digitised newspaper collection.\n\nNewspaper Navigator has released data in a number of formats including `json` files which contain a range of metadata about the newspaper from which the image was taken from. `nnanno` was thrown together to help work with this collection as part of the preparation of some example datasets used in a series of Programming Historian tutorials (currently under review). Since this code was developed using the wonderful [nbdev](nbdev.fast.ai/) library it is possible to install it for your own use. \n\n## What nnanno tries to help with\n\nnnanno doesn't to provide an end-to-end to end software for using machine learning with the Newspaper Navigator data. Instead it is a minimal collection of code that *may* help you if you want to work with the Newspaper Navigator data.\n\nThere are three particular areas where nnanno tries to help a little:\n- sampling subsets from the full Newspaper Navigator data\n- annotating this sample with additional labels using [label studio](https://labelstud.io)\n- inference (experimental üò¨) running inference i.e making new predictions with a machine learning model on the newspaper navigator dataset using IIIF.\n\n### Disclaimer\n\nThis code was written mainly to help develop some example datasets for a series of Programming Historian tutorials. It has some tests but there are likely bugs and issues with the code. The code in this repository was all written in notebooks, some people  hate notebooks. Those people will probably hate this too ü§∑‚Äç‚ôÇÔ∏è\n\nIf you want to work with the full Newspaper Navigator data you will likely be better of accessing it via the provided S3 bucket see [news-navigator.labs.loc.gov/]() for more information.\n\n## nbdev notes\nThis code was written using `nbdev`. This is a tool that helps use Jupyter notebooks for developing Python libraries. Inside the documentation you will see code cells followed by output. This is generated from a Jupyter notebook and shows the actual output of the code rather than something that has been copied and pasted for example:\n\n```python\nimport datetime\nprint(datetime.date.today())\n```\n\n    2021-02-02\n\n\nIs evaluated as Python code. This also means all of the documentation and examples can be opened in notebooks and the code inspected, changed and run. \n\n## Install\n\nYou can install `nnanno` via `PyPI`:\n\n`pip install nnanno`\n\nThis will install all of the code for sampling from Newspaper Navigator data. \n\n## Optional extra packages \nIf you want to use all of the parts of `nnanno` you'll need to install some extra packages. \n\n### label studio \nIf you also want to use `label-studio` for annotating you will need to install this too. There are various ways in which you may want to install label-studio. See the label studio [documentation](https://labelstud.io/) for various options for setting this up. \n\n### fastai\nIf you want to use the experimental inference functionality you will need to install fastai. See the [fastai docs](https://docs.fast.ai/#Installing) for options for doing this. \n\n## Documentation\n\nThe [documentation](https://living-with-machines.github.io/nnanno/) can be viewed as rendered pages with the option of opening as notebooks in Google Colab. \n\n## Illustrations in advertising: an 'end-to-end' example of using nnanno \n\nYou can find an 'end-to-end' example in [examples folder of the documentation](https://living-with-machines.github.io/nnanno/intro.html). \n\nThis example goes through the process of sampling, annotating, training a model and predicting this against the newspaper navigator data. \n\n## Functionality \nThe three main areas of `nnanno` are shown below. The examples in the documentation and in the \"end-to-end\" example shows this functionality in more detail. \n\n### Creating samples\n\n`nnanno` can be used to create samples from the Newspaper Navigator data:\n\n```python\nfrom nnanno.sample import *\n```\n\n```python\nsampler = nnSampler()\ndf = sampler.create_sample(1,\n                           'photos',\n                           start_year=1850, \n                           end_year=1855, \n                           step=1)\n```\n\nThis returns a dataframe containing samples from the Newspaper Navigator data (loaded via JSON) into a Pandas DataFrame. \n\n```python\ndf.columns\n```\n\n\n\n\n    Index(['filepath', 'pub_date', 'page_seq_num', 'edition_seq_num', 'batch',\n           'lccn', 'box', 'score', 'ocr', 'place_of_publication',\n           'geographic_coverage', 'name', 'publisher', 'url', 'page_url'],\n          dtype='object')\n\n\n\n### Annotation\nThe annotation part of nnanno is mainly a little bit of documentation and a few functions to help setup annotation of a sample from Newspaper Navigator using IIIF urls and the [label studio](https://labelstud.io/) annotation tool. Since we can annotate via IIIF this offers a way of annotating without having to download large amounts of data locally. \n\n```python\nfrom nnanno.annotate import create_label_studio_json\n```\n\n### Inference\n\nThe inference section of nnanno *attempts* to show one possible way to use IIIF to run inference against samples of Newspaper Navigator using a trained [fastai](https://docs.fast.ai/) model. This will allow you to make predictions against larger parts of the Newspaper Navigator data. \n\n```python\nfrom nnanno.inference import *\n```\n\n```python\nfrom fastai.vision.all import *\ndls = ImageDataLoaders.from_csv('../ph/ads/', \n                                'ads_upsampled.csv',\n                                folder='images', \n                                fn_col='file', \n                                label_col='label',\n                                item_tfms=Resize(64,ResizeMethod.Squish),\n                                num_workers=0)\nlearn = cnn_learner(dls, resnet18, metrics=F1Score())\nlearn.fit(1)\n```\n\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>f1_score</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.924742</td>\n      <td>0.963872</td>\n      <td>0.645570</td>\n      <td>00:12</td>\n    </tr>\n  </tbody>\n</table>\n\n\nWith a trained fastai model we can predict on a sample from Newspaper Navigator\n\n```python\npredictor = nnPredict(learn, try_gpu=False)\n```\n\n```python\npredictor.predict_sample('ads','testinference',0.01,end_year=1850)\n```\n\n    \n\n\nThis returns a `json` file for each year from the sample containing the original newspaper navigator data plus the predictions from your model\n\n```python\ndf = pd.read_json('testinference/1850.json')\n```\n\nWe can access the 'decoded' predictions\n\n```python\ndf['pred_decoded'].value_counts()\n```\n\n\n\n\n    text-only        50\n    illustrations    38\n    Name: pred_decoded, dtype: int64\n\n\n\nor work with the probabilities directly\n\n```python\ndf.iloc[:5,-2]\n```\n\n\n\n\n    0    0.152435\n    1    0.027183\n    2    0.096673\n    3    0.395800\n    4    0.957422\n    Name: illustrations_prob, dtype: float64\n\n\n\n### Acknowledgment \n\n> This work was support by [Living with Machines](livingwithmachines.ac.uk/). This project, funded by the UK Research and Innovation (UKRI) Strategic Priority Fund, is a multidisciplinary collaboration delivered by the Arts and Humanities Research Council (AHRC), with The Alan Turing Institute, the British Library and the Universities of Cambridge, East Anglia, Exeter, and Queen Mary University of London.\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/Living-with-machines/nnanno/tree/main/",
    "keywords": "computer-vision,digital-humanities",
    "license": "MIT License",
    "maintainer": "",
    "maintainer_email": "",
    "name": "nnanno",
    "package_url": "https://pypi.org/project/nnanno/",
    "platform": null,
    "project_url": "https://pypi.org/project/nnanno/",
    "project_urls": {
      "Homepage": "https://github.com/Living-with-machines/nnanno/tree/main/"
    },
    "release_url": "https://pypi.org/project/nnanno/0.0.3/",
    "requires_dist": [
      "pandas",
      "tqdm",
      "Pillow",
      "cytoolz",
      "ijson",
      "requests-cache (>=0.6.0)",
      "ipywidgets",
      "simplejson",
      "fastcore"
    ],
    "requires_python": ">=3.6",
    "summary": "Sample and annotate Newspaper Navigator data for computer vision tasks",
    "version": "0.0.3",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 13208147,
  "releases": {
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4fe8b2cf6a92eb54d3ed33aca33fd9a0425765b365914f3482fa9efaee955e56",
          "md5": "9324fe8914b9bdd9c792571a61b66e6c",
          "sha256": "326a0965ece12512d9792196a43e6da91994ee3a5f49981ef196dda188067e49"
        },
        "downloads": -1,
        "filename": "nnanno-0.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "9324fe8914b9bdd9c792571a61b66e6c",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 21051,
        "upload_time": "2021-09-29T15:00:06",
        "upload_time_iso_8601": "2021-09-29T15:00:06.720528Z",
        "url": "https://files.pythonhosted.org/packages/4f/e8/b2cf6a92eb54d3ed33aca33fd9a0425765b365914f3482fa9efaee955e56/nnanno-0.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "dc8d9cdf4efa18bf40c1356c28feec533c1730ebb14aabaa69df404ca18412fd",
          "md5": "d86140d3c68801457b1d9dff28c04bfb",
          "sha256": "dff4e95876eaad7f43c36c0e1cbdb914a9a00eb43fa0ab2bb53ecbe4d9401f1f"
        },
        "downloads": -1,
        "filename": "nnanno-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "d86140d3c68801457b1d9dff28c04bfb",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 22133,
        "upload_time": "2021-09-29T15:00:08",
        "upload_time_iso_8601": "2021-09-29T15:00:08.365287Z",
        "url": "https://files.pythonhosted.org/packages/dc/8d/9cdf4efa18bf40c1356c28feec533c1730ebb14aabaa69df404ca18412fd/nnanno-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5654229289ce16a6d5c2dfdbf0ce764d267d55deefcd54e28bf532c9bcfb20de",
          "md5": "7b13be6db44db16bf7ef9462c9ae9f11",
          "sha256": "0ff379b9e341d8338e68907ae623c7f1380aef504f4b36e4f9d5ab3df040ed51"
        },
        "downloads": -1,
        "filename": "nnanno-0.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "7b13be6db44db16bf7ef9462c9ae9f11",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 21168,
        "upload_time": "2022-03-17T18:29:48",
        "upload_time_iso_8601": "2022-03-17T18:29:48.348360Z",
        "url": "https://files.pythonhosted.org/packages/56/54/229289ce16a6d5c2dfdbf0ce764d267d55deefcd54e28bf532c9bcfb20de/nnanno-0.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "32c47bf74f806c38f93fd452128f1f6fdf900bf0bb3f37a5fcb20c1ce5054ed3",
          "md5": "133647f7b9b8aa25886806421ffd4d9b",
          "sha256": "0c85a4e8c5486e7934278de7cd30b76aa64b1e142e74139183dee9f40cadbd6a"
        },
        "downloads": -1,
        "filename": "nnanno-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "133647f7b9b8aa25886806421ffd4d9b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 21157,
        "upload_time": "2022-03-17T18:29:49",
        "upload_time_iso_8601": "2022-03-17T18:29:49.828432Z",
        "url": "https://files.pythonhosted.org/packages/32/c4/7bf74f806c38f93fd452128f1f6fdf900bf0bb3f37a5fcb20c1ce5054ed3/nnanno-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "5654229289ce16a6d5c2dfdbf0ce764d267d55deefcd54e28bf532c9bcfb20de",
        "md5": "7b13be6db44db16bf7ef9462c9ae9f11",
        "sha256": "0ff379b9e341d8338e68907ae623c7f1380aef504f4b36e4f9d5ab3df040ed51"
      },
      "downloads": -1,
      "filename": "nnanno-0.0.3-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "7b13be6db44db16bf7ef9462c9ae9f11",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 21168,
      "upload_time": "2022-03-17T18:29:48",
      "upload_time_iso_8601": "2022-03-17T18:29:48.348360Z",
      "url": "https://files.pythonhosted.org/packages/56/54/229289ce16a6d5c2dfdbf0ce764d267d55deefcd54e28bf532c9bcfb20de/nnanno-0.0.3-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "32c47bf74f806c38f93fd452128f1f6fdf900bf0bb3f37a5fcb20c1ce5054ed3",
        "md5": "133647f7b9b8aa25886806421ffd4d9b",
        "sha256": "0c85a4e8c5486e7934278de7cd30b76aa64b1e142e74139183dee9f40cadbd6a"
      },
      "downloads": -1,
      "filename": "nnanno-0.0.3.tar.gz",
      "has_sig": false,
      "md5_digest": "133647f7b9b8aa25886806421ffd4d9b",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 21157,
      "upload_time": "2022-03-17T18:29:49",
      "upload_time_iso_8601": "2022-03-17T18:29:49.828432Z",
      "url": "https://files.pythonhosted.org/packages/32/c4/7bf74f806c38f93fd452128f1f6fdf900bf0bb3f37a5fcb20c1ce5054ed3/nnanno-0.0.3.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}