{
  "info": {
    "author": "Simon Willison",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Intended Audience :: Developers",
      "Intended Audience :: End Users/Desktop",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: Apache Software License",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Topic :: Database"
    ],
    "description": "# Datasette\n\n[![PyPI](https://img.shields.io/pypi/v/datasette.svg)](https://pypi.org/project/datasette/)\n[![Travis CI](https://travis-ci.org/simonw/datasette.svg?branch=master)](https://travis-ci.org/simonw/datasette)\n[![Documentation Status](https://readthedocs.org/projects/datasette/badge/?version=latest)](http://datasette.readthedocs.io/en/latest/?badge=latest)\n[![License](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](https://github.com/simonw/datasette/blob/master/LICENSE)\n\n*An instant JSON API for your SQLite databases*\n\nDatasette provides an instant, read-only JSON API for any SQLite database. It also provides tools  for packaging the database up as a Docker container and deploying that container to hosting providers such as [Zeit Now](https://zeit.co/now).\n\nGot CSV data? Use [csvs-to-sqlite](https://github.com/simonw/csvs-to-sqlite) to convert them to SQLite, then publish them with Datasette. Or try [Datasette Publish](https://publish.datasettes.com), a web app that lets you upload CSV data and deploy it using Datasette without needing to install any software.\n\nDocumentation:Â http://datasette.readthedocs.io/ Examples: https://github.com/simonw/datasette/wiki/Datasettes\n\n## News\n\n* 23rd May 2018: [Datasette 0.22.1 bugfix](https://github.com/simonw/datasette/releases/tag/0.22.1) plus we now use [versioneer](https://github.com/warner/python-versioneer)\n* 20th May 2018: [Datasette 0.22: Datasette Facets](https://simonwillison.net/2018/May/20/datasette-facets)\n* 5th May 2018: [Datasette 0.21: New _shape=, new _size=, search within columns](https://github.com/simonw/datasette/releases/tag/0.21)\n* 25th April 2018: [Exploring the UK Register of Members Interests with SQL and Datasette](https://simonwillison.net/2018/Apr/25/register-members-interests/) - a tutorial describing how [register-of-members-interests.datasettes.com](https://register-of-members-interests.datasettes.com/) was built ([source code here](https://github.com/simonw/register-of-members-interests))\n* 20th April 2018: [Datasette plugins, and building a clustered map visualization](https://simonwillison.net/2018/Apr/20/datasette-plugins/) - introducing Datasette's new plugin system and [datasette-cluster-map](https://pypi.org/project/datasette-cluster-map/), a plugin for visualizing data on a map\n* 20th April 2018: [Datasette 0.20: static assets and templates for plugins](https://github.com/simonw/datasette/releases/tag/0.20)\n* 16th April 2018: [Datasette 0.19: plugins preview](https://github.com/simonw/datasette/releases/tag/0.19)\n* 14th April 2018: [Datasette 0.18: units](https://github.com/simonw/datasette/releases/tag/0.18)\n* 9th April 2018: [Datasette 0.15: sort by column](https://github.com/simonw/datasette/releases/tag/0.15)\n* 28th March 2018: [Baltimore Sun Public Salary Records](https://simonwillison.net/2018/Mar/28/datasette-in-the-wild/) - a data journalism project from the Baltimore Sun powered by Datasette - source code [is available here](https://github.com/baltimore-sun-data/salaries-datasette)\n* 27th March 2018: [Cloud-first: Rapid webapp deployment using containers](https://wwwf.imperial.ac.uk/blog/research-software-engineering/2018/03/27/cloud-first-rapid-webapp-deployment-using-containers/) - a tutorial covering deploying Datasette using Microsoft Azure by the Research Software Engineering team at Imperial College London\n* 28th January 2018: [Analyzing my Twitter followers with Datasette](https://simonwillison.net/2018/Jan/28/analyzing-my-twitter-followers/) - a tutorial on using Datasette to analyze follower data pulled from the Twitter API\n* 17th January 2018: [Datasette Publish: a web app for publishing CSV files as an online database](https://simonwillison.net/2018/Jan/17/datasette-publish/)\n* 12th December 2017: [Building a location to time zone API with SpatiaLite, OpenStreetMap and Datasette](https://simonwillison.net/2017/Dec/12/building-a-location-time-zone-api/)\n* 9th December 2017: [Datasette 0.14: customization edition](https://github.com/simonw/datasette/releases/tag/0.14)\n* 25th November 2017: [New in Datasette: filters, foreign keys and search](https://simonwillison.net/2017/Nov/25/new-in-datasette/)\n* 13th November 2017: [Datasette: instantly create and publish an API for your SQLite databases](https://simonwillison.net/2017/Nov/13/datasette/)\n\n## Installation\n\n    pip3 install datasette\n\nDatasette requires Python 3.5 or higher.\n\n## Basic usage\n\n    datasette serve path/to/database.db\n\nThis will start a web server on port 8001 - visit http://localhost:8001/ to access the web interface.\n\n`serve` is the default subcommand, you can omit it if you like.\n\nUse Chrome on OS X? You can run datasette against your browser history like so:\n\n     datasette ~/Library/Application\\ Support/Google/Chrome/Default/History\n\nNow visiting http://localhost:8001/History/downloads will show you a web interface to browse your downloads data:\n\n![Downloads table rendered by datasette](https://static.simonwillison.net/static/2017/datasette-downloads.png)\n\nhttp://localhost:8001/History/downloads.json will return that data as JSON:\n\n    {\n        \"database\": \"History\",\n        \"columns\": [\n            \"id\",\n            \"current_path\",\n            \"target_path\",\n            \"start_time\",\n            \"received_bytes\",\n            \"total_bytes\",\n            ...\n        ],\n        \"table_rows_count\": 576,\n        \"rows\": [\n            [\n                1,\n                \"/Users/simonw/Downloads/DropboxInstaller.dmg\",\n                \"/Users/simonw/Downloads/DropboxInstaller.dmg\",\n                13097290269022132,\n                626688,\n                0,\n                ...\n            ]\n        ]\n    }\n\n\nhttp://localhost:8001/History/downloads.json?_shape=objects will return that data as JSON in a more convenient but less efficient format:\n\n    {\n        ...\n        \"rows\": [\n            {\n                \"start_time\": 13097290269022132,\n                \"interrupt_reason\": 0,\n                \"hash\": \"\",\n                \"id\": 1,\n                \"site_url\": \"\",\n                \"referrer\": \"https://www.dropbox.com/downloading?src=index\",\n                ...\n            }\n        ]\n    }\n\n## datasette serve options\n\n    $ datasette serve --help\n    Usage: datasette serve [OPTIONS] [FILES]...\n\n      Serve up specified SQLite database files with a web UI\n\n    Options:\n      -h, --host TEXT              host for server, defaults to 127.0.0.1\n      -p, --port INTEGER           port for server, defaults to 8001\n      --debug                      Enable debug mode - useful for development\n      --reload                     Automatically reload if code change detected -\n                                   useful for development\n      --cors                       Enable CORS by serving Access-Control-Allow-\n                                   Origin: *\n      --load-extension PATH        Path to a SQLite extension to load\n      --inspect-file TEXT          Path to JSON file created using \"datasette\n                                   inspect\"\n      -m, --metadata FILENAME      Path to JSON file containing license/source\n                                   metadata\n      --template-dir DIRECTORY     Path to directory containing custom templates\n      --plugins-dir DIRECTORY      Path to directory containing custom plugins\n      --static STATIC MOUNT        mountpoint:path-to-directory for serving static\n                                   files\n      --config CONFIG              Set config option using configname:value\n                                   datasette.readthedocs.io/en/latest/config.html\n      --help-config                Show available config options\n      --help                       Show this message and exit.\n\n## metadata.json\n\nIf you want to include licensing and source information in the generated datasette website you can do so using a JSON file that looks something like this:\n\n    {\n        \"title\": \"Five Thirty Eight\",\n        \"license\": \"CC Attribution 4.0 License\",\n        \"license_url\": \"http://creativecommons.org/licenses/by/4.0/\",\n        \"source\": \"fivethirtyeight/data on GitHub\",\n        \"source_url\": \"https://github.com/fivethirtyeight/data\"\n    }\n\nThe license and source information will be displayed on the index page and in the footer. They will also be included in the JSON produced by the API.\n\n## datasette publish\n\nIf you have [Zeit Now](https://zeit.co/now) or [Heroku](https://heroku.com/) configured, datasette can deploy one or more SQLite databases to the internet with a single command:\n\n    datasette publish now database.db\n\nOr:\n\n    datasette publish heroku database.db\n\nThis will create a docker image containing both the datasette application and the specified SQLite database files. It will then deploy that image to Zeit Now or Heroku and give you a URL to access the API.\n\n    $ datasette publish --help\n    Usage: datasette publish [OPTIONS] PUBLISHER [FILES]...\n\n      Publish specified SQLite database files to the internet along with a\n      datasette API.\n\n      Options for PUBLISHER:     * 'now' - You must have Zeit Now installed:\n      https://zeit.co/now     * 'heroku' - You must have Heroku installed:\n      https://cli.heroku.com/\n\n      Example usage: datasette publish now my-database.db\n\n    Options:\n      -n, --name TEXT           Application name to use when deploying to Now\n                                (ignored for Heroku)\n      -m, --metadata FILENAME   Path to JSON file containing metadata to publish\n      --extra-options TEXT      Extra options to pass to datasette serve\n      --force                   Pass --force option to now\n      --branch TEXT             Install datasette from a GitHub branch e.g. master\n      --template-dir DIRECTORY  Path to directory containing custom templates\n      --plugins-dir DIRECTORY   Path to directory containing custom plugins\n      --static STATIC MOUNT     mountpoint:path-to-directory for serving static\n                                files\n      --install TEXT            Additional packages (e.g. plugins) to install\n      --title TEXT              Title for metadata\n      --license TEXT            License label for metadata\n      --license_url TEXT        License URL for metadata\n      --source TEXT             Source label for metadata\n      --source_url TEXT         Source URL for metadata\n      --help                    Show this message and exit.\n\n## datasette package\n\nIf you have docker installed you can use `datasette package` to create a new Docker image in your local repository containing the datasette app and selected SQLite databases:\n\n    $ datasette package --help\n    Usage: datasette package [OPTIONS] FILES...\n\n      Package specified SQLite files into a new datasette Docker container\n\n    Options:\n      -t, --tag TEXT            Name for the resulting Docker container, can\n                                optionally use name:tag format\n      -m, --metadata FILENAME   Path to JSON file containing metadata to publish\n      --extra-options TEXT      Extra options to pass to datasette serve\n      --branch TEXT             Install datasette from a GitHub branch e.g. master\n      --template-dir DIRECTORY  Path to directory containing custom templates\n      --plugins-dir DIRECTORY   Path to directory containing custom plugins\n      --static STATIC MOUNT     mountpoint:path-to-directory for serving static\n                                files\n      --install TEXT            Additional packages (e.g. plugins) to install\n      --title TEXT              Title for metadata\n      --license TEXT            License label for metadata\n      --license_url TEXT        License URL for metadata\n      --source TEXT             Source label for metadata\n      --source_url TEXT         Source URL for metadata\n      --help                    Show this message and exit.\n\nBoth publish and package accept an `extra_options` argument option, which will affect how the resulting application is executed. For example, say you want to increase the SQL time limit for a particular container:\n\n    datasette package parlgov.db \\\n        --extra-options=\"--config sql_time_limit_ms:2500 --config default_page_size:10\"\n\nThe resulting container will run the application with those options.\n\nHere's example output for the package command:\n\n    $ datasette package parlgov.db --extra-options=\"--config sql_time_limit_ms:2500\"\n    Sending build context to Docker daemon  4.459MB\n    Step 1/7 : FROM python:3\n     ---> 79e1dc9af1c1\n    Step 2/7 : COPY . /app\n     ---> Using cache\n     ---> cd4ec67de656\n    Step 3/7 : WORKDIR /app\n     ---> Using cache\n     ---> 139699e91621\n    Step 4/7 : RUN pip install datasette\n     ---> Using cache\n     ---> 340efa82bfd7\n    Step 5/7 : RUN datasette inspect parlgov.db --inspect-file inspect-data.json\n     ---> Using cache\n     ---> 5fddbe990314\n    Step 6/7 : EXPOSE 8001\n     ---> Using cache\n     ---> 8e83844b0fed\n    Step 7/7 : CMD datasette serve parlgov.db --port 8001 --inspect-file inspect-data.json --config sql_time_limit_ms:2500\n     ---> Using cache\n     ---> 1bd380ea8af3\n    Successfully built 1bd380ea8af3\n\nYou can now run the resulting container like so:\n\n    docker run -p 8081:8001 1bd380ea8af3\n\nThis exposes port 8001 inside the container as port 8081 on your host machine, so you can access the application at http://localhost:8081/\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/simonw/datasette",
    "keywords": "",
    "license": "Apache License, Version 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "datasette-core",
    "package_url": "https://pypi.org/project/datasette-core/",
    "platform": "",
    "project_url": "https://pypi.org/project/datasette-core/",
    "project_urls": {
      "Homepage": "https://github.com/simonw/datasette"
    },
    "release_url": "https://pypi.org/project/datasette-core/0.22.1/",
    "requires_dist": [
      "Sanic (==0.7.0)",
      "Jinja2 (==2.10)",
      "hupper (==1.0)",
      "pint (==0.8.1)",
      "pluggy (<1.0,>=0.1.0)",
      "click (==6.7)",
      "click-default-group (==1.2)"
    ],
    "requires_python": "",
    "summary": "An instant JSON API for your SQLite databases",
    "version": "0.22.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 3919901,
  "releases": {
    "0.22.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "22dcc00c174db9a6241b3206b315b70d7e6c62a14b7199261848cd3adac61caa",
          "md5": "74985cc789e363a30637459f3cb6d4b4",
          "sha256": "25ce15ad5cbc6be8dabae619ae2768163377a43e27f6dfee9079975d98708969"
        },
        "downloads": -1,
        "filename": "datasette_core-0.22.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "74985cc789e363a30637459f3cb6d4b4",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 179998,
        "upload_time": "2018-06-01T08:18:57",
        "upload_time_iso_8601": "2018-06-01T08:18:57.618881Z",
        "url": "https://files.pythonhosted.org/packages/22/dc/c00c174db9a6241b3206b315b70d7e6c62a14b7199261848cd3adac61caa/datasette_core-0.22.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "67e918152b058c2ba764bf96c04053367113c15b15e1973fbcdb6f5497e4d27f",
          "md5": "8be7f5f31f7b766b6b669287f3c46fd7",
          "sha256": "32aa0a6e1f1532f74c4e4ed7e18271a17d53e332e6c7ea304f2b609055f33d01"
        },
        "downloads": -1,
        "filename": "datasette-core-0.22.1.tar.gz",
        "has_sig": false,
        "md5_digest": "8be7f5f31f7b766b6b669287f3c46fd7",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 183691,
        "upload_time": "2018-06-01T08:18:59",
        "upload_time_iso_8601": "2018-06-01T08:18:59.941578Z",
        "url": "https://files.pythonhosted.org/packages/67/e9/18152b058c2ba764bf96c04053367113c15b15e1973fbcdb6f5497e4d27f/datasette-core-0.22.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "22dcc00c174db9a6241b3206b315b70d7e6c62a14b7199261848cd3adac61caa",
        "md5": "74985cc789e363a30637459f3cb6d4b4",
        "sha256": "25ce15ad5cbc6be8dabae619ae2768163377a43e27f6dfee9079975d98708969"
      },
      "downloads": -1,
      "filename": "datasette_core-0.22.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "74985cc789e363a30637459f3cb6d4b4",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 179998,
      "upload_time": "2018-06-01T08:18:57",
      "upload_time_iso_8601": "2018-06-01T08:18:57.618881Z",
      "url": "https://files.pythonhosted.org/packages/22/dc/c00c174db9a6241b3206b315b70d7e6c62a14b7199261848cd3adac61caa/datasette_core-0.22.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "67e918152b058c2ba764bf96c04053367113c15b15e1973fbcdb6f5497e4d27f",
        "md5": "8be7f5f31f7b766b6b669287f3c46fd7",
        "sha256": "32aa0a6e1f1532f74c4e4ed7e18271a17d53e332e6c7ea304f2b609055f33d01"
      },
      "downloads": -1,
      "filename": "datasette-core-0.22.1.tar.gz",
      "has_sig": false,
      "md5_digest": "8be7f5f31f7b766b6b669287f3c46fd7",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 183691,
      "upload_time": "2018-06-01T08:18:59",
      "upload_time_iso_8601": "2018-06-01T08:18:59.941578Z",
      "url": "https://files.pythonhosted.org/packages/67/e9/18152b058c2ba764bf96c04053367113c15b15e1973fbcdb6f5497e4d27f/datasette-core-0.22.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}