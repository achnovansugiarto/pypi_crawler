{
  "info": {
    "author": "yeyupiaoling",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Developers",
      "License :: OSI Approved :: Apache Software License",
      "Natural Language :: Chinese (Simplified)",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Topic :: Utilities"
    ],
    "description": "# 前言\n此版本为新版本，相比上一个版本，最大的变化是此版本支持pip安装，以及把预处理使用模型算子实现，这样做的好处就是可以直接使用GPU计算，大幅度提高了预处理的速度，估计预处理速度可在10~20倍。\n\n如想使用使用旧版本，请转到[release/1.0](https://github.com/yeyupiaoling/VoiceprintRecognition_Pytorch/tree/release/1.0)，本项目使用了EcapaTdnn模型实现的声纹识别，不排除以后会支持更多模型，同时本项目也支持了多种数据预处理方法，损失函数参考了人脸识别项目的做法[PaddlePaddle-MobileFaceNets](https://github.com/yeyupiaoling/PaddlePaddle-MobileFaceNets) ,使用了ArcFace Loss，ArcFace loss：Additive Angular Margin Loss（加性角度间隔损失函数），对特征向量和权重归一化，对θ加上角度间隔m，角度间隔比余弦间隔在对角度的影响更加直接。\n\n\n**欢迎大家扫码入QQ群讨论**，或者直接搜索QQ群号`1169600237`，问题答案为博主Github的ID`yeyupiaoling`。\n\n<div align=\"center\">\n  <img src=\"docs/images/qq.png\"/>\n</div>\n\n\n使用环境：\n\n - Anaconda 3\n - Python 3.8\n - Pytorch 1.12.1\n - Windows 10 or Ubuntu 18.04\n\n# 项目特性\n\n1. 支持模型：EcapaTdnn、TDNN、Res2Net、ResNetSE\n2. 支持池化层：AttentiveStatsPool(ASP)、SelfAttentivePooling(SAP)、TemporalStatisticsPooling(TSP)、TemporalAveragePooling(TAP)\n3. 支持损失函数：AAMLoss、AMLoss、ARMLoss、CELoss\n4. 支持预处理方法：MelSpectrogram、Spectrogram、MFCC\n\n# 模型下载\n\n<table align=\"center\">\n<tr>\n  <th align=\"center\">模型</th>\n  <th align=\"center\">预处理方法</th>\n  <th align=\"center\">数据集</th>\n  <th align=\"center\">类别数量</th>\n  <th align=\"center\">tpr</th>\n  <th align=\"center\">fpr</th>\n  <th align=\"center\">eer</th>\n  <th align=\"center\">模型下载地址</th>\n</tr>\n<tr>\n  <td align=\"center\">EcapaTdnn</td>\n  <td align=\"center\">MelSpectrogram</td>\n  <td align=\"center\"><a href=\"https://github.com/fighting41love/zhvoice\">中文语音语料数据集</a></td>\n  <td align=\"center\">3242</td>\n  <td align=\"center\">0.98972</td>\n  <td align=\"center\">0.00730</td>\n  <td align=\"center\">0.01758</td>\n  <td align=\"center\"><a href=\"https://download.csdn.net/download/qq_33200967/87153070\">点击下载</a></td>\n</tr>\n<tr>\n  <td align=\"center\">EcapaTdnn</td>\n  <td align=\"center\">Spectrogram</td>\n  <td align=\"center\"><a href=\"https://github.com/fighting41love/zhvoice\">中文语音语料数据集</a></td>\n  <td align=\"center\">3242</td>\n  <td align=\"center\">0.99142</td>\n  <td align=\"center\">0.00817</td>\n  <td align=\"center\">0.01675</td>\n  <td align=\"center\"><a href=\"https://download.csdn.net/download/qq_33200967/87015334\">点击下载</a></td>\n</tr>\n<tr>\n  <td align=\"center\">EcapaTdnn</td>\n  <td align=\"center\">MFCC</td>\n  <td align=\"center\"><a href=\"https://github.com/fighting41love/zhvoice\">中文语音语料数据集</a></td>\n  <td align=\"center\">3242</td>\n  <td align=\"center\">0.99431</td>\n  <td align=\"center\">0.00659</td>\n  <td align=\"center\">0.01227</td>\n  <td align=\"center\"><a href=\"https://download.csdn.net/download/qq_33200967/87523304\">点击下载</a></td>\n</tr>\n<tr>\n  <td align=\"center\">EcapaTdnn</td>\n  <td align=\"center\">MelSpectrogram</td>\n  <td align=\"center\">更大的数据集</td>\n  <td align=\"center\">6355</td>\n  <td align=\"center\">0.97881</td>\n  <td align=\"center\">0.00788</td>\n  <td align=\"center\">0.02907</td>\n  <td align=\"center\"><a href=\"https://download.csdn.net/download/qq_33200967/86987829\">点击下载</a></td>\n</tr>\n<tr>\n  <td align=\"center\">EcapaTdnn</td>\n  <td align=\"center\">MelSpectrogram</td>\n  <td align=\"center\">超大的数据集</td>\n  <td align=\"center\">13718</td>\n  <td align=\"center\">0.98342</td>\n  <td align=\"center\">0.00776</td>\n  <td align=\"center\">0.02434</td>\n  <td align=\"center\"><a href=\"https://download.csdn.net/download/qq_33200967/87131658\">点击下载</a>，可能还未审核通过，着急可以使用旧分支<a href=\"https://github.com/yeyupiaoling/VoiceprintRecognition-PaddlePaddle/tree/release/1.0\">release/1.0</a></td>\n</tr>\n</table>\n\n## 安装环境\n\n - 首先安装的是Pytorch的GPU版本，如果已经安装过了，请跳过。\n```shell\nconda install pytorch==1.12.1 torchvision==0.13.1 torchaudio==0.12.1 cudatoolkit=10.2 -c pytorch\n```\n\n - 安装ppvector库。\n \n使用pip安装，命令如下：\n```shell\npython -m pip install mvector -U -i https://pypi.tuna.tsinghua.edu.cn/simple\n```\n\n**建议源码安装**，源码安装能保证使用最新代码。\n```shell\ngit clone https://github.com/yeyupiaoling/VoiceprintRecognition_Pytorch.git\ncd VoiceprintRecognition_Pytorch/\npython setup.py install\n```\n\n# 创建数据\n本教程笔者使用的是[中文语音语料数据集](https://github.com/fighting41love/zhvoice) ，这个数据集一共有3242个人的语音数据，有1130000+条语音数据，下载之前要**全部解压**数据集。如果读者有其他更好的数据集，可以混合在一起使用，但最好是要用python的工具模块aukit处理音频，降噪和去除静音。\n\n首先是创建一个数据列表，数据列表的格式为`<语音文件路径\\t语音分类标签>`，创建这个列表主要是方便之后的读取，也是方便读取使用其他的语音数据集，语音分类标签是指说话人的唯一ID，不同的语音数据集，可以通过编写对应的生成数据列表的函数，把这些数据集都写在同一个数据列表中。\n\n在`create_data.py`写下以下代码，因为[中文语音语料数据集](https://github.com/fighting41love/zhvoice) 这个数据集是mp3格式的，作者发现这种格式读取速度很慢，所以笔者把全部的mp3格式的音频转换为wav格式，这个过程可能很久。当然也可以不转换，项目也是支持的MP3格式的，只要设置参数`to_wav=False`。执行下面程序完成数据准备。\n```shell\npython create_data.py\n```\n\n执行上面的程序之后，会生成以下的数据格式，如果要自定义数据，参考如下数据列表，前面是音频的相对路径，后面的是该音频对应的说话人的标签，就跟分类一样。**自定义数据集的注意**，测试数据列表的ID可以不用跟训练的ID一样，也就是说测试的数据的说话人可以不用出现在训练集，只要保证测试数据列表中同一个人相同的ID即可。\n```\ndataset/zhvoice/zhmagicdata/5_895/5_895_20170614203758.wav\t3238\ndataset/zhvoice/zhmagicdata/5_895/5_895_20170614214007.wav\t3238\ndataset/zhvoice/zhmagicdata/5_941/5_941_20170613151344.wav\t3239\ndataset/zhvoice/zhmagicdata/5_941/5_941_20170614221329.wav\t3239\ndataset/zhvoice/zhmagicdata/5_941/5_941_20170616153308.wav\t3239\ndataset/zhvoice/zhmagicdata/5_968/5_968_20170614162657.wav\t3240\ndataset/zhvoice/zhmagicdata/5_968/5_968_20170622194003.wav\t3240\ndataset/zhvoice/zhmagicdata/5_968/5_968_20170707200554.wav\t3240\ndataset/zhvoice/zhmagicdata/5_970/5_970_20170616000122.wav\t3241\n```\n\n# 修改预处理方法\n配置文件中默认使用的是MelSpectrogram预处理方法，如果要使用其他预处理方法，可以修改配置文件中的安装下面方式修改，具体的值可以根据自己情况修改。 \n\n1. `MelSpectrogram`预处理方法如下：\n```yaml\npreprocess_conf:\n  # 音频预处理方法，支持：MelSpectrogram、Spectrogram、MFCC\n  feature_method: 'MelSpectrogram'\n\n# MelSpectrogram的参数，其他的预处理方法查看对应API设设置参数\nfeature_conf:\n  sample_rate: 16000\n  n_fft: 1024\n  hop_length: 320\n  win_length: 1024\n  f_min: 50.0\n  f_max: 14000.0\n  n_mels: 64\n```\n\n1. `pectrogram'`预处理方法如下：\n```yaml\npreprocess_conf:\n  # 音频预处理方法，支持：MelSpectrogram、Spectrogram、MFCC\n  feature_method: 'Spectrogram'\n\n# Spectrogram的参数，其他的预处理方法查看对应API设设置参数\nfeature_conf:\n  n_fft: 1024\n  hop_length: 320\n  win_length: 1024\n```\n\n3. `MFCC`预处理方法如下：\n```yaml\npreprocess_conf:\n  # 音频预处理方法，支持：MelSpectrogram、Spectrogram、MFCC\n  feature_method: 'MFCC'\n\n# MFCC的参数，其他的预处理方法查看对应API设设置参数\nfeature_conf:\n  sample_rate: 16000\n  n_fft: 1024\n  hop_length: 320\n  win_length: 1024\n  f_min: 50.0\n  f_max: 14000.0\n  n_mels: 64\n  n_mfcc: 40\n```\n\n# 训练模型\n使用`train.py`训练模型，本项目支持多个音频预处理方式，通过`configs/ecapa_tdnn.yml`配置文件的参数`preprocess_conf.feature_method`可以指定，`MelSpectrogram`为梅尔频谱，`Spectrogram`为语谱图，`MFCC`梅尔频谱倒谱系数。通过参数`augment_conf_path`可以指定数据增强方式。训练过程中，会使用VisualDL保存训练日志，通过启动VisualDL可以随时查看训练结果，启动命令`visualdl --logdir=log --host 0.0.0.0`\n```shell\n# 单卡训练\nCUDA_VISIBLE_DEVICES=0 python train.py\n# 多卡训练\nCUDA_VISIBLE_DEVICES=0,1 torchrun --standalone --nnodes=1 --nproc_per_node=2 train.py\n```\n\n训练输出日志：\n```\n[2023-02-25 11:53:53.194706 INFO   ] utils:print_arguments:13 - ----------- 额外配置参数 -----------\n[2023-02-25 11:53:53.194706 INFO   ] utils:print_arguments:15 - augment_conf_path: configs/augmentation.json\n[2023-02-25 11:53:53.194706 INFO   ] utils:print_arguments:15 - configs: configs/ecapa_tdnn.yml\n[2023-02-25 11:53:53.194706 INFO   ] utils:print_arguments:15 - pretrained_model: None\n[2023-02-25 11:53:53.194706 INFO   ] utils:print_arguments:15 - resume_model: None\n[2023-02-25 11:53:53.194706 INFO   ] utils:print_arguments:15 - save_model_path: models/\n[2023-02-25 11:53:53.194706 INFO   ] utils:print_arguments:15 - use_gpu: True\n[2023-02-25 11:53:53.194706 INFO   ] utils:print_arguments:16 - ------------------------------------------------\n[2023-02-25 11:53:53.208669 INFO   ] utils:print_arguments:18 - ----------- 配置文件参数 -----------\n[2023-02-25 11:53:53.208669 INFO   ] utils:print_arguments:21 - dataset_conf:\n[2023-02-25 11:53:53.208669 INFO   ] utils:print_arguments:28 - \tbatch_size: 64\n[2023-02-25 11:53:53.208669 INFO   ] utils:print_arguments:28 - \tchunk_duration: 3\n[2023-02-25 11:53:53.208669 INFO   ] utils:print_arguments:28 - \tdo_vad: False\n[2023-02-25 11:53:53.209670 INFO   ] utils:print_arguments:28 - \tmin_duration: 0.5\n[2023-02-25 11:53:53.209670 INFO   ] utils:print_arguments:28 - \tnum_speakers: 3242\n[2023-02-25 11:53:53.209670 INFO   ] utils:print_arguments:28 - \tnum_workers: 4\n[2023-02-25 11:53:53.209670 INFO   ] utils:print_arguments:28 - \tsample_rate: 16000\n[2023-02-25 11:53:53.209670 INFO   ] utils:print_arguments:28 - \ttarget_dB: -20\n[2023-02-25 11:53:53.209670 INFO   ] utils:print_arguments:28 - \ttest_list: dataset/test_list.txt\n[2023-02-25 11:53:53.209670 INFO   ] utils:print_arguments:28 - \ttrain_list: dataset/train_list.txt\n[2023-02-25 11:53:53.209670 INFO   ] utils:print_arguments:28 - \tuse_dB_normalization: True\n[2023-02-25 11:53:53.209670 INFO   ] utils:print_arguments:21 - feature_conf:\n[2023-02-25 11:53:53.209670 INFO   ] utils:print_arguments:28 - \thop_length: 160\n[2023-02-25 11:53:53.209670 INFO   ] utils:print_arguments:28 - \tn_fft: 400\n[2023-02-25 11:53:53.209670 INFO   ] utils:print_arguments:28 - \tn_mels: 80\n[2023-02-25 11:53:53.209670 INFO   ] utils:print_arguments:28 - \tsr: 16000\n[2023-02-25 11:53:53.209670 INFO   ] utils:print_arguments:28 - \twin_length: 400\n[2023-02-25 11:53:53.209670 INFO   ] utils:print_arguments:28 - \twindow: hann\n[2023-02-25 11:53:53.209670 INFO   ] utils:print_arguments:21 - model_conf:\n[2023-02-25 11:53:53.209670 INFO   ] utils:print_arguments:28 - \tchannels: [512, 512, 512, 512, 1536]\n[2023-02-25 11:53:53.209670 INFO   ] utils:print_arguments:28 - \tdilations: [1, 2, 3, 4, 1]\n[2023-02-25 11:53:53.209670 INFO   ] utils:print_arguments:28 - \tkernel_sizes: [5, 3, 3, 3, 1]\n[2023-02-25 11:53:53.210667 INFO   ] utils:print_arguments:28 - \tlin_neurons: 192\n[2023-02-25 11:53:53.210667 INFO   ] utils:print_arguments:21 - optimizer_conf:\n[2023-02-25 11:53:53.210667 INFO   ] utils:print_arguments:28 - \tlearning_rate: 0.001\n[2023-02-25 11:53:53.210667 INFO   ] utils:print_arguments:28 - \tweight_decay: 1e-6\n[2023-02-25 11:53:53.220680 INFO   ] utils:print_arguments:21 - preprocess_conf:\n[2023-02-25 11:53:53.220680 INFO   ] utils:print_arguments:28 - \tfeature_method: MelSpectrogram\n[2023-02-25 11:53:53.220680 INFO   ] utils:print_arguments:21 - train_conf:\n[2023-02-25 11:53:53.220680 INFO   ] utils:print_arguments:28 - \tlog_interval: 100\n[2023-02-25 11:53:53.220680 INFO   ] utils:print_arguments:28 - \tmax_epoch: 30\n[2023-02-25 11:53:53.220680 INFO   ] utils:print_arguments:30 - use_model: ecapa_tdnn\n[2023-02-25 11:53:53.220680 INFO   ] utils:print_arguments:31 - ------------------------------------------------\n[2022-11-05 19:58:31.589525 INFO   ] augmentation:_parse_pipeline_from:126 - 数据增强配置：{'type': 'noise', 'aug_type': 'audio', 'params': {'min_snr_dB': 10, 'max_snr_dB': 50, 'repetition': 2, 'noise_dir': 'dataset/noise/'}, 'prob': 0.0}\n[2022-11-05 19:58:31.589525 INFO   ] augmentation:_parse_pipeline_from:126 - 数据增强配置：{'type': 'resample', 'aug_type': 'audio', 'params': {'new_sample_rate': [8000, 32000, 44100, 48000]}, 'prob': 0.0}\n[2022-11-05 19:58:31.589525 INFO   ] augmentation:_parse_pipeline_from:126 - 数据增强配置：{'type': 'speed', 'aug_type': 'audio', 'params': {'min_speed_rate': 0.9, 'max_speed_rate': 1.1, 'num_rates': 3}, 'prob': 0.0}\n[2022-11-05 19:58:31.589525 INFO   ] augmentation:_parse_pipeline_from:126 - 数据增强配置：{'type': 'shift', 'aug_type': 'audio', 'params': {'min_shift_ms': -5, 'max_shift_ms': 5}, 'prob': 0.0}\n[2022-11-05 19:58:31.590535 INFO   ] augmentation:_parse_pipeline_from:126 - 数据增强配置：{'type': 'volume', 'aug_type': 'audio', 'params': {'min_gain_dBFS': -15, 'max_gain_dBFS': 15}, 'prob': 0.0}\n[2022-11-05 19:58:31.590535 INFO   ] augmentation:_parse_pipeline_from:126 - 数据增强配置：{'type': 'specaug', 'aug_type': 'feature', 'params': {'inplace': True, 'max_time_warp': 5, 'max_t_ratio': 0.01, 'n_freq_masks': 2, 'max_f_ratio': 0.05, 'n_time_masks': 2, 'replace_with_zero': False}, 'prob': 0.0}\n[2022-11-05 19:58:31.590535 INFO   ] augmentation:_parse_pipeline_from:126 - 数据增强配置：{'type': 'specsub', 'aug_type': 'feature', 'params': {'max_t': 10, 'num_t_sub': 2}, 'prob': 0.0}\nI0424 08:57:03.707505  3377 nccl_context.cc:74] init nccl context nranks: 2 local rank: 0 gpu id: 0 ring id: 0\nW0424 08:57:03.930370  3377 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 11.6, Runtime API Version: 10.2\nW0424 08:57:03.932493  3377 device_context.cc:465] device: 0, cuDNN Version: 7.6.\nI0424 08:57:05.431638  3377 nccl_context.cc:107] init nccl context nranks: 2 local rank: 0 gpu id: 0 ring id: 10\n······\n[2023-03-16 20:30:42.559858 INFO   ] trainer:__train_epoch:232 - Train epoch: [1/30], batch: [0/16579], loss: 16.48008, accuracy: 0.01562, learning rate: 0.00000000, speed: 21.27 data/sec, eta: 17 days, 7:38:55\n[2023-03-16 20:31:15.045717 INFO   ] trainer:__train_epoch:232 - Train epoch: [1/30], batch: [100/16579], loss: 16.34529, accuracy: 0.00062, learning rate: 0.00000121, speed: 197.03 data/sec, eta: 1 day, 20:52:05\n[2023-03-16 20:31:47.086451 INFO   ] trainer:__train_epoch:232 - Train epoch: [1/30], batch: [200/16579], loss: 16.31631, accuracy: 0.00054, learning rate: 0.00000241, speed: 199.77 data/sec, eta: 1 day, 20:14:40\n[2023-03-16 20:32:19.711337 INFO   ] trainer:__train_epoch:232 - Train epoch: [1/30], batch: [300/16579], loss: 16.30544, accuracy: 0.00047, learning rate: 0.00000362, speed: 196.19 data/sec, eta: 1 day, 21:02:28\n[2023-03-16 20:32:52.853642 INFO   ] trainer:__train_epoch:232 - Train epoch: [1/30], batch: [400/16579], loss: 16.29228, accuracy: 0.00043, learning rate: 0.00000483, speed: 193.14 data/sec, eta: 1 day, 21:44:42\n[2023-03-16 20:33:25.116274 INFO   ] trainer:__train_epoch:232 - Train epoch: [1/30], batch: [500/16579], loss: 16.27346, accuracy: 0.00041, learning rate: 0.00000603, speed: 198.40 data/sec, eta: 1 day, 20:31:18\n······\n[2023-03-16 20:34:09.633572 INFO   ] trainer:train:304 - ======================================================================\n100%|███████████████████████████████████| 84/84 [00:10<00:00,  7.79it/s]\n开始两两对比音频特征...\n100%|██████████████████████████████| 5332/5332 [00:07<00:00, 749.89it/s]\n[2023-03-16 20:34:29.328638 INFO   ] trainer:train:306 - Test epoch: 1, time/epoch: 0:00:48.881889, threshold: 0.72, tpr: 0.62350, fpr: 0.04601, eer: 0.42250\n[2023-03-16 20:34:29.328840 INFO   ] trainer:train:309 - ======================================================================\n[2023-03-16 20:34:29.728986 INFO   ] trainer:__save_checkpoint:203 - 已保存模型：models/ecapa_tdnn_MelSpectrogram/best_model\n[2023-03-16 20:34:30.724868 INFO   ] trainer:__save_checkpoint:203 - 已保存模型：models/ecapa_tdnn_MelSpectrogram/epoch_1\n[2023-03-16 20:30:42.559858 INFO   ] trainer:__train_epoch:232 - Train epoch: [2/30], batch: [0/16579], loss: 16.48008, accuracy: 0.01562, learning rate: 0.00000000, speed: 21.27 data/sec, eta: 17 days, 7:38:55\n[2023-03-16 20:31:15.045717 INFO   ] trainer:__train_epoch:232 - Train epoch: [2/30], batch: [100/16579], loss: 16.34529, accuracy: 0.00062, learning rate: 0.00000121, speed: 197.03 data/sec, eta: 1 day, 20:52:05\n[2023-03-16 20:31:47.086451 INFO   ] trainer:__train_epoch:232 - Train epoch: [2/30], batch: [200/16579], loss: 16.31631, accuracy: 0.00054, learning rate: 0.00000241, speed: 199.77 data/sec, eta: 1 day, 20:14:40\n[2023-03-16 20:32:19.711337 INFO   ] trainer:__train_epoch:232 - Train epoch: [2/30], batch: [300/16579], loss: 16.30544, accuracy: 0.00047, learning rate: 0.00000362, speed: 196.19 data/sec, eta: 1 day, 21:02:28\n······\n```\n\nVisualDL页面：\n![VisualDL页面](./docs/images/log.jpg)\n\n\n# 数据增强\n本项目提供了几种音频增强操作，分布是随机裁剪，添加背景噪声，调节语速，调节音量，和SpecAugment。其中后面4种增加的参数可以在`configs/augmentation.json`修改，参数`prob`是指定该增强操作的概率，如果不想使用该增强方式，可以设置为0。要主要的是，添加背景噪声需要把多个噪声音频文件存放在`dataset/noise`，否则会跳过噪声增强\n```yaml\nnoise:\n  min_snr_dB: 10\n  max_snr_dB: 30\n  noise_path: \"dataset/noise\"\n  prob: 0.5\n```\n\n\n\n# 评估模型\n训练结束之后会保存预测模型，我们用预测模型来预测测试集中的音频特征，然后使用音频特征进行两两对比，计算tpr、fpr、eer。\n```shell\npython eval.py\n```\n\n输出类似如下：\n```\n······\n------------------------------------------------\nW0425 08:27:32.057426 17654 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 11.6, Runtime API Version: 10.2\nW0425 08:27:32.065165 17654 device_context.cc:465] device: 0, cuDNN Version: 7.6.\n[2023-03-16 20:20:47.195908 INFO   ] trainer:evaluate:341 - 成功加载模型：models/ecapa_tdnn_MelSpectrogram/best_model/model.pth\n100%|███████████████████████████| 84/84 [00:28<00:00,  2.95it/s]\n开始两两对比音频特征...\n100%|███████████████████████████| 5332/5332 [00:05<00:00, 1027.83it/s]\n评估消耗时间：65s，threshold：0.26，tpr：0.99391, fpr: 0.00611, eer: 0.01220\n```\n\n# 声纹对比\n下面开始实现声纹对比，创建`infer_contrast.py`程序，编写`infer()`函数，在编写模型的时候，模型是有两个输出的，第一个是模型的分类输出，第二个是音频特征输出。所以在这里要输出的是音频的特征值，有了音频的特征值就可以做声纹识别了。我们输入两个语音，通过预测函数获取他们的特征数据，使用这个特征数据可以求他们的对角余弦值，得到的结果可以作为他们相识度。对于这个相识度的阈值`threshold`，读者可以根据自己项目的准确度要求进行修改。\n```shell\npython infer_contrast.py --audio_path1=audio/a_1.wav --audio_path2=audio/b_2.wav\n```\n\n输出类似如下：\n```\n[2023-04-02 18:30:48.009149 INFO   ] utils:print_arguments:13 - ----------- 额外配置参数 -----------\n[2023-04-02 18:30:48.009149 INFO   ] utils:print_arguments:15 - audio_path1: dataset/a_1.wav\n[2023-04-02 18:30:48.009149 INFO   ] utils:print_arguments:15 - audio_path2: dataset/b_2.wav\n[2023-04-02 18:30:48.009149 INFO   ] utils:print_arguments:15 - configs: configs/ecapa_tdnn.yml\n[2023-04-02 18:30:48.009149 INFO   ] utils:print_arguments:15 - model_path: models/ecapa_tdnn_MelSpectrogram/best_model/\n[2023-04-02 18:30:48.009149 INFO   ] utils:print_arguments:15 - threshold: 0.6\n[2023-04-02 18:30:48.009149 INFO   ] utils:print_arguments:15 - use_gpu: True\n[2023-04-02 18:30:48.009149 INFO   ] utils:print_arguments:16 - ------------------------------------------------\n······································································\nW0425 08:29:10.006249 21121 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 11.6, Runtime API Version: 10.2\nW0425 08:29:10.008555 21121 device_context.cc:465] device: 0, cuDNN Version: 7.6.\n成功加载模型参数和优化方法参数：models/ecapa_tdnn/model.pth\naudio/a_1.wav 和 audio/b_2.wav 不是同一个人，相似度为：-0.09565544128417969\n```\n\n# 声纹识别\n在上面的声纹对比的基础上，我们创建`infer_recognition.py`实现声纹识别。同样是使用上面声纹对比的`infer()`预测函数，通过这两个同样获取语音的特征数据。 不同的是笔者增加了`load_audio_db()`和`register()`，以及`recognition()`，第一个函数是加载声纹库中的语音数据，这些音频就是相当于已经注册的用户，他们注册的语音数据会存放在这里，如果有用户需要通过声纹登录，就需要拿到用户的语音和语音库中的语音进行声纹对比，如果对比成功，那就相当于登录成功并且获取用户注册时的信息数据。第二个函数`register()`其实就是把录音保存在声纹库中，同时获取该音频的特征添加到待对比的数据特征中。最后`recognition()`函数中，这个函数就是将输入的语音和语音库中的语音一一对比。\n有了上面的声纹识别的函数，读者可以根据自己项目的需求完成声纹识别的方式，例如笔者下面提供的是通过录音来完成声纹识别。首先必须要加载语音库中的语音，语音库文件夹为`audio_db`，然后用户回车后录音3秒钟，然后程序会自动录音，并使用录音到的音频进行声纹识别，去匹配语音库中的语音，获取用户的信息。通过这样方式，读者也可以修改成通过服务请求的方式完成声纹识别，例如提供一个API供APP调用，用户在APP上通过声纹登录时，把录音到的语音发送到后端完成声纹识别，再把结果返回给APP，前提是用户已经使用语音注册，并成功把语音数据存放在`audio_db`文件夹中。\n```shell\npython infer_recognition.py\n```\n\n输出类似如下：\n```\n[2023-04-02 18:31:20.521040 INFO   ] utils:print_arguments:13 - ----------- 额外配置参数 -----------\n[2023-04-02 18:31:20.521040 INFO   ] utils:print_arguments:15 - audio_db_path: audio_db/\n[2023-04-02 18:31:20.521040 INFO   ] utils:print_arguments:15 - configs: configs/ecapa_tdnn.yml\n[2023-04-02 18:31:20.521040 INFO   ] utils:print_arguments:15 - model_path: models/ecapa_tdnn_MelSpectrogram/best_model/\n[2023-04-02 18:31:20.521040 INFO   ] utils:print_arguments:15 - record_seconds: 3\n[2023-04-02 18:31:20.521040 INFO   ] utils:print_arguments:15 - threshold: 0.6\n[2023-04-02 18:31:20.521040 INFO   ] utils:print_arguments:15 - use_gpu: True\n[2023-04-02 18:31:20.521040 INFO   ] utils:print_arguments:16 - ------------------------------------------------\n······································································\nW0425 08:30:13.257884 23889 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 11.6, Runtime API Version: 10.2\nW0425 08:30:13.260191 23889 device_context.cc:465] device: 0, cuDNN Version: 7.6.\n成功加载模型参数和优化方法参数：models/ecapa_tdnn/model.pth\nLoaded 沙瑞金 audio.\nLoaded 李达康 audio.\n请选择功能，0为注册音频到声纹库，1为执行声纹识别：0\n按下回车键开机录音，录音3秒中：\n开始录音......\n录音已结束!\n请输入该音频用户的名称：夜雨飘零\n请选择功能，0为注册音频到声纹库，1为执行声纹识别：1\n按下回车键开机录音，录音3秒中：\n开始录音......\n录音已结束!\n识别说话的为：夜雨飘零，相似度为：0.920434\n```\n\n# 其他版本\n - Tensorflow：[VoiceprintRecognition-Tensorflow](https://github.com/yeyupiaoling/VoiceprintRecognition-Tensorflow)\n - PaddlePaddle：[VoiceprintRecognition-PaddlePaddle](https://github.com/yeyupiaoling/VoiceprintRecognition-PaddlePaddle)\n - Keras：[VoiceprintRecognition-Keras](https://github.com/yeyupiaoling/VoiceprintRecognition-Keras)\n\n\n# 参考资料\n1. https://github.com/PaddlePaddle/PaddleSpeech\n2. https://github.com/yeyupiaoling/PaddlePaddle-MobileFaceNets\n3. https://github.com/yeyupiaoling/PPASR\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "https://github.com/yeyupiaoling/VoiceprintRecognition_Pytorch.git",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/yeyupiaoling/VoiceprintRecognition_Pytorch",
    "keywords": "Voice,Pytorch",
    "license": "Apache License 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "mvector",
    "package_url": "https://pypi.org/project/mvector/",
    "platform": null,
    "project_url": "https://pypi.org/project/mvector/",
    "project_urls": {
      "Download": "https://github.com/yeyupiaoling/VoiceprintRecognition_Pytorch.git",
      "Homepage": "https://github.com/yeyupiaoling/VoiceprintRecognition_Pytorch"
    },
    "release_url": "https://pypi.org/project/mvector/0.3.9/",
    "requires_dist": [
      "numba (>=0.52.0)",
      "librosa (>=0.9.1)",
      "numpy (>=1.19.2)",
      "tqdm (>=4.59.0)",
      "visualdl (>=2.1.1)",
      "resampy (==0.2.2)",
      "soundfile (>=0.12.1)",
      "soundcard (>=0.4.2)",
      "pyyaml (>=5.4.1)",
      "termcolor (>=1.1.0)",
      "typeguard (==2.13.3)",
      "scikit-learn (>=1.0.2)",
      "pydub (>=0.25.1)",
      "torchaudio (>=0.12.1)",
      "torchinfo (>=1.7.2)",
      "av (>=10.0.0)"
    ],
    "requires_python": "",
    "summary": "Voice Print Recognition toolkit on Pytorch",
    "version": "0.3.9",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17548357,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "473e3a456541530312415f1ccd0b129d1307da6a504ebb67a5107b3bc2482809",
          "md5": "2ae69e010f1e1d616e5172cf8ccf5ffb",
          "sha256": "9b09a89f7757fe62b002df4130b0386bec343b8e570e55f895758614f492c6e3"
        },
        "downloads": -1,
        "filename": "mvector-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "2ae69e010f1e1d616e5172cf8ccf5ffb",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 47380,
        "upload_time": "2022-11-10T07:27:39",
        "upload_time_iso_8601": "2022-11-10T07:27:39.778071Z",
        "url": "https://files.pythonhosted.org/packages/47/3e/3a456541530312415f1ccd0b129d1307da6a504ebb67a5107b3bc2482809/mvector-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a1e58e6da299e6f802dd9e555041c21f17b96e4b0ef8f9bbb3df4b45845eb538",
          "md5": "9194850f5596866400b3228e5b335cf9",
          "sha256": "e4707e2c34e512113821a84ecfc4c9054496e50adab084d6e311bcafbb84704f"
        },
        "downloads": -1,
        "filename": "mvector-0.2.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "9194850f5596866400b3228e5b335cf9",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 44883,
        "upload_time": "2023-01-31T12:34:06",
        "upload_time_iso_8601": "2023-01-31T12:34:06.950988Z",
        "url": "https://files.pythonhosted.org/packages/a1/e5/8e6da299e6f802dd9e555041c21f17b96e4b0ef8f9bbb3df4b45845eb538/mvector-0.2.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "41daa1a819cf5a1925eae91ec6612de0b0bd556b77c733d6dc42f15e093d9112",
          "md5": "6bf8b3ae6d7fb76df3afb90fd256b9d8",
          "sha256": "622e0eb71b4cab41aacb85565f2977f5d96e00c645cd8db3cd1604397765961b"
        },
        "downloads": -1,
        "filename": "mvector-0.2.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "6bf8b3ae6d7fb76df3afb90fd256b9d8",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 45107,
        "upload_time": "2023-02-20T12:46:02",
        "upload_time_iso_8601": "2023-02-20T12:46:02.707418Z",
        "url": "https://files.pythonhosted.org/packages/41/da/a1a819cf5a1925eae91ec6612de0b0bd556b77c733d6dc42f15e093d9112/mvector-0.2.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "836647693b49c6522ed605dfecff2466789a2ab4961ba43ef156601c1fd11794",
          "md5": "c44532411fdbb8ddaaecdbd84a2bc437",
          "sha256": "7831a0184bdb29f23f98a06b8b605a75c1b53da7d7ec9649906e623d66b412ee"
        },
        "downloads": -1,
        "filename": "mvector-0.2.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "c44532411fdbb8ddaaecdbd84a2bc437",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 45201,
        "upload_time": "2023-02-25T03:04:10",
        "upload_time_iso_8601": "2023-02-25T03:04:10.336916Z",
        "url": "https://files.pythonhosted.org/packages/83/66/47693b49c6522ed605dfecff2466789a2ab4961ba43ef156601c1fd11794/mvector-0.2.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2d9d166ade63bd24cf58e0479081cf6465fe55d5cffeb12ce0882f26dc801ecc",
          "md5": "daaf2db2a9456db27d0e290347cb2697",
          "sha256": "ddb37f47dbdeba10a9bbba1db5d531dabbdb842fcd8fe12a7024cd0ef028d842"
        },
        "downloads": -1,
        "filename": "mvector-0.3.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "daaf2db2a9456db27d0e290347cb2697",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 45384,
        "upload_time": "2023-02-25T11:54:43",
        "upload_time_iso_8601": "2023-02-25T11:54:43.458085Z",
        "url": "https://files.pythonhosted.org/packages/2d/9d/166ade63bd24cf58e0479081cf6465fe55d5cffeb12ce0882f26dc801ecc/mvector-0.3.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0610035734c856c10b73bcec9fde0bd90bceaa2e3ae076c3b631028dd2095538",
          "md5": "3b019db50ba10ac522e8f22b51d93307",
          "sha256": "f45aa12784bf0787e2a3423e8261d271fe50ac3571a3558ef370c4c5ce535485"
        },
        "downloads": -1,
        "filename": "mvector-0.3.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "3b019db50ba10ac522e8f22b51d93307",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 45592,
        "upload_time": "2023-03-01T04:38:54",
        "upload_time_iso_8601": "2023-03-01T04:38:54.651363Z",
        "url": "https://files.pythonhosted.org/packages/06/10/035734c856c10b73bcec9fde0bd90bceaa2e3ae076c3b631028dd2095538/mvector-0.3.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bdfb408b14d82f8d6b6acdb6cdd031d577a3c6c40a50a99cb97a83b9b2e2dd87",
          "md5": "daf4e1f24b6705c2339d4270b879d92c",
          "sha256": "2c3769718afb5f8b848650d3c567b2fab67d583945185a5dcf64163621a4cce1"
        },
        "downloads": -1,
        "filename": "mvector-0.3.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "daf4e1f24b6705c2339d4270b879d92c",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 45692,
        "upload_time": "2023-03-01T11:33:58",
        "upload_time_iso_8601": "2023-03-01T11:33:58.515157Z",
        "url": "https://files.pythonhosted.org/packages/bd/fb/408b14d82f8d6b6acdb6cdd031d577a3c6c40a50a99cb97a83b9b2e2dd87/mvector-0.3.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fd9fb0fc54f7f9ecdd2b1604cb205d18545f7f0996222051737024e20c74d40f",
          "md5": "4301d6039ab6facd7d6f39c24e5bf300",
          "sha256": "821dac4a3425e731ef67bab614aae4646b48c48c0afc2c553e30e0ab545b08e5"
        },
        "downloads": -1,
        "filename": "mvector-0.3.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "4301d6039ab6facd7d6f39c24e5bf300",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 46687,
        "upload_time": "2023-03-17T11:17:13",
        "upload_time_iso_8601": "2023-03-17T11:17:13.798839Z",
        "url": "https://files.pythonhosted.org/packages/fd/9f/b0fc54f7f9ecdd2b1604cb205d18545f7f0996222051737024e20c74d40f/mvector-0.3.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "740a8b5f41287381189a64603ea8a57f2a4f74ce94cf1c3156fef4da861c8ceb",
          "md5": "1e68e185da7b6e0fa636deec7228118f",
          "sha256": "b5ca1a809fe4e98f29e7cdda87c9608feb02006f685d4e114824e08d9238ddba"
        },
        "downloads": -1,
        "filename": "mvector-0.3.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "1e68e185da7b6e0fa636deec7228118f",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 53186,
        "upload_time": "2023-03-18T08:06:13",
        "upload_time_iso_8601": "2023-03-18T08:06:13.312266Z",
        "url": "https://files.pythonhosted.org/packages/74/0a/8b5f41287381189a64603ea8a57f2a4f74ce94cf1c3156fef4da861c8ceb/mvector-0.3.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c844fda90fc01529c5b131d3527bd95224bcf659d16aa7b73fc61d7c848a7e9b",
          "md5": "c143c65f6fc879adc8fed92f8e11ce1d",
          "sha256": "c691b789ee3fe58d4d1b7897a4159bb5738d31c95cc89e4b222ea2b0d2a97f3b"
        },
        "downloads": -1,
        "filename": "mvector-0.3.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "c143c65f6fc879adc8fed92f8e11ce1d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 53205,
        "upload_time": "2023-03-18T12:55:46",
        "upload_time_iso_8601": "2023-03-18T12:55:46.144502Z",
        "url": "https://files.pythonhosted.org/packages/c8/44/fda90fc01529c5b131d3527bd95224bcf659d16aa7b73fc61d7c848a7e9b/mvector-0.3.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "356304075d3668707a94f68d1a4f5233574997caae3a44b3fe1ce44e67fecea4",
          "md5": "8cf79572dd917ed2249a7d9592463c57",
          "sha256": "616faf5afa52bc0438ce9e1173ceed214d462c5c389e21aaad59f686a1cf1100"
        },
        "downloads": -1,
        "filename": "mvector-0.3.6-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "8cf79572dd917ed2249a7d9592463c57",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 53213,
        "upload_time": "2023-03-18T13:14:35",
        "upload_time_iso_8601": "2023-03-18T13:14:35.825781Z",
        "url": "https://files.pythonhosted.org/packages/35/63/04075d3668707a94f68d1a4f5233574997caae3a44b3fe1ce44e67fecea4/mvector-0.3.6-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5b6e0fccaa0ee098b235176479c0a670c34bd022c1056cd75246f7096086ff16",
          "md5": "27259eb2615fdc837435d89ae219d46b",
          "sha256": "30a12faa94f5ca11f9d8b28f98dc65709a228ff254b7a3901822439a905ab368"
        },
        "downloads": -1,
        "filename": "mvector-0.3.7-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "27259eb2615fdc837435d89ae219d46b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 53200,
        "upload_time": "2023-03-19T02:28:13",
        "upload_time_iso_8601": "2023-03-19T02:28:13.074483Z",
        "url": "https://files.pythonhosted.org/packages/5b/6e/0fccaa0ee098b235176479c0a670c34bd022c1056cd75246f7096086ff16/mvector-0.3.7-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2c70f1efa9c909a35ea33582f2c9c97355bb16a8db13d88e2572f608e70f3559",
          "md5": "4c9b7b3645479c48e5eb2e1ff7cdd69b",
          "sha256": "f75dfd935bd7a76a503e7e0ce4ca19fa899303c7df3bef27e460ed3a08b19d45"
        },
        "downloads": -1,
        "filename": "mvector-0.3.8-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "4c9b7b3645479c48e5eb2e1ff7cdd69b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 53747,
        "upload_time": "2023-03-22T11:14:25",
        "upload_time_iso_8601": "2023-03-22T11:14:25.318025Z",
        "url": "https://files.pythonhosted.org/packages/2c/70/f1efa9c909a35ea33582f2c9c97355bb16a8db13d88e2572f608e70f3559/mvector-0.3.8-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.9": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d55e1ace415c5733a8f62248af0d167b6eedd0bcd438c333acdf535fc1d903d0",
          "md5": "1a9415ec78400da9e84b3b3f457ec4eb",
          "sha256": "2fc52deac11ea5cb4772f231330079551f2ac974ed8980f095cfdda2d18a58fa"
        },
        "downloads": -1,
        "filename": "mvector-0.3.9-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "1a9415ec78400da9e84b3b3f457ec4eb",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 54410,
        "upload_time": "2023-04-02T15:03:46",
        "upload_time_iso_8601": "2023-04-02T15:03:46.847092Z",
        "url": "https://files.pythonhosted.org/packages/d5/5e/1ace415c5733a8f62248af0d167b6eedd0bcd438c333acdf535fc1d903d0/mvector-0.3.9-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "d55e1ace415c5733a8f62248af0d167b6eedd0bcd438c333acdf535fc1d903d0",
        "md5": "1a9415ec78400da9e84b3b3f457ec4eb",
        "sha256": "2fc52deac11ea5cb4772f231330079551f2ac974ed8980f095cfdda2d18a58fa"
      },
      "downloads": -1,
      "filename": "mvector-0.3.9-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "1a9415ec78400da9e84b3b3f457ec4eb",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 54410,
      "upload_time": "2023-04-02T15:03:46",
      "upload_time_iso_8601": "2023-04-02T15:03:46.847092Z",
      "url": "https://files.pythonhosted.org/packages/d5/5e/1ace415c5733a8f62248af0d167b6eedd0bcd438c333acdf535fc1d903d0/mvector-0.3.9-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}