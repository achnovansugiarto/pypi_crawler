{
  "info": {
    "author": "Lukas Hedegaard",
    "author_email": "lukasxhedegaard@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Environment :: Console",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: Apache Software License",
      "Natural Language :: English",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.11",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Topic :: Scientific/Engineering :: Artificial Intelligence",
      "Topic :: Scientific/Engineering :: Image Recognition",
      "Topic :: Scientific/Engineering :: Information Analysis"
    ],
    "description": "# Structured Pruning Adapters for PyTorch\n\n<div align=\"left\">\n  <!-- <a href=\"https://pypi.org/project/structured-pruning-adapters/\">\n    <img src=\"https://img.shields.io/pypi/pyversions/structured-pruning-adapters\" height=\"20\" >\n  </a>\n  <a href=\"https://badge.fury.io/py/structured-pruning-adapters\">\n    <img src=\"https://badge.fury.io/py/structured-pruning-adapters.svg\" height=\"20\" >\n  </a> -->\n  <!-- <a href=\"https://structured-pruning-adapters.readthedocs.io/en/latest/?badge=latest\">\n    <img src=\"https://readthedocs.org/projects/structured-pruning-adapters/badge/?version=latest\" alt=\"Documentation Status\" height=\"20\"/>\n  </a> -->\n  <!-- <a href=\"https://pepy.tech/project/structured-pruning-adapters\">\n    <img src=\"https://pepy.tech/badge/structured-pruning-adapters\" height=\"20\">\n  </a> -->\n  <!-- <a href=\"https://codecov.io/gh/LukasHedegaard/structured-pruning-adapters\">\n    <img src=\"https://codecov.io/gh/LukasHedegaard/structured-pruning-adapters/branch/main/graph/badge.svg?token=????\" height=\"20\"/>\n  </a> -->\n  <a href=\"https://opensource.org/licenses/Apache-2.0\">\n    <img src=\"https://img.shields.io/badge/License-Apache%202.0-blue.svg\" height=\"20\">\n  </a>\n  <!-- <a href=\"https://arxiv.org/abs/2204.03418\">\n    <img src=\"http://img.shields.io/badge/paper-arxiv.2204.03418-B31B1B.svg\" height=\"20\" >\n  </a> -->\n  <a href=\"https://github.com/psf/black\">\n    <img src=\"https://img.shields.io/badge/code%20style-black-000000.svg\" height=\"20\">\n  </a>\n  <!-- <a href=\"https://www.codefactor.io/repository/github/lukashedegaard/structured-pruning-adapters/overview/main\">\n    <img src=\"https://www.codefactor.io/repository/github/lukashedegaard/structured-pruning-adapters/badge/main\" alt=\"CodeFactor\" height=\"20\" />\n  </a> -->\n</div>\n\n```bash\npip install structured-pruning-adapters\n```\n## A happy mariage üë∞‚Äç‚ôÄÔ∏èü§µ‚Äç‚ôÇÔ∏è\n\n__Pruning__ is an effective method for reducing the size of neural networks. Besides reducing the parameter count, the process _can_ accelerate inference as well. \nCPUs can handle sparse weights just fine, but GPUs need structured weights for an acceleration to happen. \nA structured approach to pruning i.e., removing network channels [[paper](https://www.sciencedirect.com/science/article/pii/S0031320321000868)] or blocks of weights [[paper](https://aclanthology.org/2021.emnlp-main.829.pdf)], generally yields speedups as well\n\n\\+\n\n__Adapters__ [[paper](https://proceedings.neurips.cc/paper/2017/file/e7b24b112a44fdd9ee93bdf998c6ca0e-paper.pdf)] have emerged as an alternative to fine-tuning, in which the prior network weights are unaltered, and a new set of _adapters_ weights are added to the network to learn a specific task.\nSome types of adapters add new layers, others are _fusible_ with existing weights and don't have a run-time overhead.\nWhen a single base-model is deployed with many specialised models, these structures can save a lot of parameters compared with full fine-tuning.\n\n=\n<!-- | |\n| --- | -->\n[__Structured Pruning Adapters__](https://github.com/LukasHedegaard/structured-pruning-adapters) are the offspring of Structured Pruning and Fusible Adapters, and can be used for _Transfer Learning_ which has:\n- ‚úÖ Extremely few learned parameters (binary pruning mask + masked adapter weights) üëå\n- ‚úÖ Accelerated network inference üèéüí®\n\n\n## How to use this library\nUse in conjunction with any Structured Pruning technique. \n1. Install the library:\n    ```bash\n    pip install structured-pruning-adapters\n    ```\n2. Replace Linear and Conv layers with an SP Adapter:\n    ```python3\n    from torch.nn import Linear\n    from sp_adapter import SPLoRA\n\n    reg_lin = Linear(256, 512, bias=True)\n    spa_lin = SPLoRA(reg_lin, rank=32)\n\n    # Or replace all applicable layers in a network\n    spa_net = SPLoRA(reg_net, rank=32)\n    ```\n3. Employ any Structured Pruning method, e.g [this](https://github.com/huggingface/block_movement_pruning) or [that](https://github.com/seulkiyeom/LRP_Pruning).\n\n4. Get pruned SP Adapter weights:\n    ```python3\n    # Specify mask\n    spa_lin.configure_parameter_read(\n        adapter_weights_only=True,\n        in_features_mask=torch.tensor([1, 0, ..., 1], dtype=torch.bool)\n        out_features_mask=torch.tensor([0, 1, ..., 1], dtype=torch.bool),\n    )   # üëÜ masks are learned via your choice of Structured Pruning method\n\n    # Read parameters as usual\n    spa_lin.parameters()\n    spa_lin.named_parameters()\n    spa_lin.state_dict()\n    ```\n\n### Demo\nSee also [notebooks/demo.ipynb](notebooks/demo.ipynb) for a hands-on demo.\n\n### Structured Pruning Low-Rank Adapter (SPLoRA) for _Channel Pruning_ \n```python3\nfrom sp_adapters import SPLoRA\n```\n<div align=\"center\">\n<img src=\"figures/SPLoRA.png\" width=\"400\">\n</div>\nAdds a low-rank bottle-neck projection in projection in parallel with the main weights projection.\n\n<br/>\n\n### Structured Pruning Low-rank PHM Adapter (SPLoPA) for _Block Pruning_\n```python3\nfrom sp_adapters import SPLoPA\n```\n\n<div align=\"center\">\n<img src=\"figures/SPLoPA.png\" width=\"600\">\n</div>\n\nUses a variation on the Parameterized Hypercomplex Multiplication (PHM) layer [[paper](https://openreview.net/forum?id=rcQdycl0zyk)] with shared low-rank prototypes for block-sparse adaptation.\n\n## Citation\nIf you enjoy this work, please consider citing it\n```bibtex\n@article{hedegaard2022cotrans,\n  title={Structured Pruning Adapters},\n  author={Lukas Hedegaard, Aman Alok, Juby Jose, Alexandros Iosifidis},\n  journal={preprint, arXiv:TBD},\n  year={2022}\n}\n```\n\n## Acknowledgement\nThis work was done in conjunction with a research exchange at [Cactus Communications üåµ](https://cactusglobal.com).\n\nThis work has received funding from the European Union‚Äôs Horizon 2020 research and innovation programme under grant agreement No 871449 [(OpenDR) üá™üá∫](https://opendr.eu).\n\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/lukashedegaard/structured-pruning-adapters",
    "keywords": "deep learning,pytorch,AI,adapters,pruning,inference",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "structured-pruning-adapters",
    "package_url": "https://pypi.org/project/structured-pruning-adapters/",
    "platform": null,
    "project_url": "https://pypi.org/project/structured-pruning-adapters/",
    "project_urls": {
      "Homepage": "https://github.com/lukashedegaard/structured-pruning-adapters"
    },
    "release_url": "https://pypi.org/project/structured-pruning-adapters/0.5.2/",
    "requires_dist": [
      "torch (>=1.9)",
      "setuptools ; extra == 'build'",
      "wheel ; extra == 'build'",
      "twine ; extra == 'build'",
      "black ; extra == 'dev'",
      "flake8 ; extra == 'dev'",
      "flake8-black ; extra == 'dev'",
      "isort (>=5.7) ; extra == 'dev'",
      "pytest ; extra == 'dev'",
      "pytest-cov ; extra == 'dev'"
    ],
    "requires_python": "",
    "summary": "Structured Pruning Adapters for PyTorch",
    "version": "0.5.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 15799977,
  "releases": {
    "0.5.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "18d1fe41790927c637f2f6022b35a106f1e7970cdb7b9a60bef68b4ed0cb2f5d",
          "md5": "e65d3e193a215f98cc9e1927f136dc16",
          "sha256": "829a05b4306f64bae81cb6ace704335c289bbcc3a4ea98450dda38f652a12078"
        },
        "downloads": -1,
        "filename": "structured_pruning_adapters-0.5.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "e65d3e193a215f98cc9e1927f136dc16",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 14660,
        "upload_time": "2022-11-17T10:56:58",
        "upload_time_iso_8601": "2022-11-17T10:56:58.444079Z",
        "url": "https://files.pythonhosted.org/packages/18/d1/fe41790927c637f2f6022b35a106f1e7970cdb7b9a60bef68b4ed0cb2f5d/structured_pruning_adapters-0.5.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1b053e6aa9d5d4659a7cf74f6d7d18dcc7d23bb514356db7d7c86e39779b2939",
          "md5": "b8816214ca58931243fdb94a47247864",
          "sha256": "3f0570d7171eb8939752c8fe1196c31ed73d38d9b6e5fe225cf6a294673df7b7"
        },
        "downloads": -1,
        "filename": "structured-pruning-adapters-0.5.2.tar.gz",
        "has_sig": false,
        "md5_digest": "b8816214ca58931243fdb94a47247864",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 15485,
        "upload_time": "2022-11-17T10:57:00",
        "upload_time_iso_8601": "2022-11-17T10:57:00.447551Z",
        "url": "https://files.pythonhosted.org/packages/1b/05/3e6aa9d5d4659a7cf74f6d7d18dcc7d23bb514356db7d7c86e39779b2939/structured-pruning-adapters-0.5.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "18d1fe41790927c637f2f6022b35a106f1e7970cdb7b9a60bef68b4ed0cb2f5d",
        "md5": "e65d3e193a215f98cc9e1927f136dc16",
        "sha256": "829a05b4306f64bae81cb6ace704335c289bbcc3a4ea98450dda38f652a12078"
      },
      "downloads": -1,
      "filename": "structured_pruning_adapters-0.5.2-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "e65d3e193a215f98cc9e1927f136dc16",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 14660,
      "upload_time": "2022-11-17T10:56:58",
      "upload_time_iso_8601": "2022-11-17T10:56:58.444079Z",
      "url": "https://files.pythonhosted.org/packages/18/d1/fe41790927c637f2f6022b35a106f1e7970cdb7b9a60bef68b4ed0cb2f5d/structured_pruning_adapters-0.5.2-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "1b053e6aa9d5d4659a7cf74f6d7d18dcc7d23bb514356db7d7c86e39779b2939",
        "md5": "b8816214ca58931243fdb94a47247864",
        "sha256": "3f0570d7171eb8939752c8fe1196c31ed73d38d9b6e5fe225cf6a294673df7b7"
      },
      "downloads": -1,
      "filename": "structured-pruning-adapters-0.5.2.tar.gz",
      "has_sig": false,
      "md5_digest": "b8816214ca58931243fdb94a47247864",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 15485,
      "upload_time": "2022-11-17T10:57:00",
      "upload_time_iso_8601": "2022-11-17T10:57:00.447551Z",
      "url": "https://files.pythonhosted.org/packages/1b/05/3e6aa9d5d4659a7cf74f6d7d18dcc7d23bb514356db7d7c86e39779b2939/structured-pruning-adapters-0.5.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}