{
  "info": {
    "author": "Jeet Chugh",
    "author_email": "sunjeetchugh@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Intended Audience :: Education",
      "License :: OSI Approved :: MIT License",
      "Operating System :: Microsoft :: Windows :: Windows 10",
      "Programming Language :: Python :: 3"
    ],
    "description": "# pyautoscraper  \n#### Author: Jeet Chugh  \n\n###### pyautoscraper is a A lightweight module which automates webscraping and gathering HTML elements within Python 3\n\n### Features:\n  - Find elements by searching for tags, attributes, classes, id's, and more\n  - Parse through Cloudflare protected sites (NOT CAPTCHA)\n  - Install easily with pip\n  - Lightweight, only uses cloudscraper and BS4\n#### [Github Link](https://github.com/Jeet-Chugh/pyautoscraper) | [PyPi Link](https://pypi.org/project/pyautoscraper/) | [Example Code Link](https://raw.githubusercontent.com/Jeet-Chugh/pyautoscraper/master/example.py)  \n\n  Quick and Easy Installation via PIP: `pip install pyautoscraper`  \n\nImport Statement:  ``from pyautoscraper.scraper import Scraper``  \n\nDependencies: *bs4, cloudscraper*  \n\n#### Code License: MIT  \n\n# Documentation  \n\n###### Documentation is split into 2 sections. First is the 'Part' Class and second is the 'Query' Function.  \n\n---  \n\n#### 'Scraper' Class:  \n\nThe 'Scraper' class takes in an input of a URL as a string, and has many methods that return specific chunks of data.  \n\n**Import:**  \n\n``from pyautoscraper.scraper import Scraper``  \n\n**Instantiation:**  \n\n``webscraper = Scraper('URL') # Takes in url string (with https://)``  \n\n``another_scraper = Scraper('Second URL') # Instantiate multiple Scrapers though variables``  \n\n#### **'Scraper' Methods:**  \n\n##### Scraper will raise a URLerror if the request is unsuccessful. Scraper will return None if no elements are found.\n\n---  \n\n``Scraper('url').find(tag, **attributes)``  --> ``Scraper('URL').find('h1', class_='blog-title')``\n\nreturns a string containing the first HTML element that matches your parameters. To find classes, use the 'class_' keyword argument.\n\n (``<h1 class=\"blog-title>Title</h1>\"``)  \n\n---  \n\n``Scraper('url').findAll(tag, **attributes)`` --> ``Scraper('URL').findAll('p')``\n\nreturns a list of strings, containing all the HTML elements that match the parameters.\n\n(``[<p>first</p>, <p>second</p>, <p>third</p>]``)  \n\n---  \n\n`Scraper('url').findText()`  \n\nreturns a string containing the text content of the HTML, with all tags and attributes stripped.\n\n(``h1 text       paragraph text            span text        h5 text        im in a div tag``)  \n\n---  \n\n`Scraper('url').findLinks()`  \n\nreturns a list of all http/https links in a tags within the HTML code of the page.\n\n(``[https://www.google.com, https://www.github.com]``)  \n\n---  \n\n`Scraper('url').findJS()`  \n\nreturns a list containing strings, which represent the string tags within the HTML code.\n\nExample Dictionary:`{'model':'Intel','Core Clock':'3.2Ghz','TDP':'95W','Socket':'LGA1155'}`  \n\n---  \n\n`Scraper('url').findElementByID(IDname)`  \n\nreturns a string containing the first HTML element that matches your IDname.\n\n(``<div id=\"database_div\">content</div>``)  \n\n---  \n\n`Scraper('url').findElementByClass(className)`  \n\nreturns a string containing the first HTML element that matches your className.\n\n(``<div class=\"database_div\">content</div>``)  \n\n---  \n\n`Scraper('url').findComments()`  \n\nreturns a list of strings, containing all the HTML comments within the code.\n\n(``['<!-- a comment -->','<!-- ANOTHER COMMENT -->']``)  \n\n---  \n\n\nThank you for reading the documentation. If you need an example using all these methods, go to [link]  \n\n\nIf you have issues, report them to the github project link.\n\n\nCHANGELOG:\n==============\n\n0.0.1 (10/5/20):\n----------------\n- GitHub Commit\n- Published to PyPi\n\n0.0.2 (10/6/20):\n----------------\n- Updated README\n- Fixed Bug",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/Jeet-Chugh/pyautoscraper",
    "keywords": "pyautoscraper",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "pyautoscraper",
    "package_url": "https://pypi.org/project/pyautoscraper/",
    "platform": "",
    "project_url": "https://pypi.org/project/pyautoscraper/",
    "project_urls": {
      "Homepage": "https://github.com/Jeet-Chugh/pyautoscraper"
    },
    "release_url": "https://pypi.org/project/pyautoscraper/0.0.2/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "A lightweight python module which automates webscraping and parsing through HTML",
    "version": "0.0.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8353800,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b19d3546e97d0bf385d83b8c1469827ece68ae2fa63ded04806cbf335dfedff1",
          "md5": "9482465331da6a88cfac191cca5afdea",
          "sha256": "ea249538df2bebb5d5aaacf6d7639a50e418f746e7ba9b30ee00c1fb4bc0b6e5"
        },
        "downloads": -1,
        "filename": "pyautoscraper-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "9482465331da6a88cfac191cca5afdea",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 3300,
        "upload_time": "2020-10-06T05:30:33",
        "upload_time_iso_8601": "2020-10-06T05:30:33.417570Z",
        "url": "https://files.pythonhosted.org/packages/b1/9d/3546e97d0bf385d83b8c1469827ece68ae2fa63ded04806cbf335dfedff1/pyautoscraper-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3766d8b4faf4875b4c16139ed9c817abda2c72ab15740d75b015a2192c1d7782",
          "md5": "232e1fdcdbff3cf47d6ac05ad5d1a47a",
          "sha256": "0fa2ff3e056ee25a03f8cc069750b393366b4536d19a9352786c677b5891a86f"
        },
        "downloads": -1,
        "filename": "pyautoscraper-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "232e1fdcdbff3cf47d6ac05ad5d1a47a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 4900,
        "upload_time": "2020-10-06T20:24:38",
        "upload_time_iso_8601": "2020-10-06T20:24:38.822868Z",
        "url": "https://files.pythonhosted.org/packages/37/66/d8b4faf4875b4c16139ed9c817abda2c72ab15740d75b015a2192c1d7782/pyautoscraper-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "3766d8b4faf4875b4c16139ed9c817abda2c72ab15740d75b015a2192c1d7782",
        "md5": "232e1fdcdbff3cf47d6ac05ad5d1a47a",
        "sha256": "0fa2ff3e056ee25a03f8cc069750b393366b4536d19a9352786c677b5891a86f"
      },
      "downloads": -1,
      "filename": "pyautoscraper-0.0.2.tar.gz",
      "has_sig": false,
      "md5_digest": "232e1fdcdbff3cf47d6ac05ad5d1a47a",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 4900,
      "upload_time": "2020-10-06T20:24:38",
      "upload_time_iso_8601": "2020-10-06T20:24:38.822868Z",
      "url": "https://files.pythonhosted.org/packages/37/66/d8b4faf4875b4c16139ed9c817abda2c72ab15740d75b015a2192c1d7782/pyautoscraper-0.0.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}