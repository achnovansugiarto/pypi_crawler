{
  "info": {
    "author": "Hristo I. Gueorguiev",
    "author_email": "hristo.gueorguiev@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Versioned LRU Cache (Cache with invalidation support)\n\n## Short description/ summary\nVersioned_lru_cache_with_ttl is a decorator that can provide versioned lru caching\nof function return results.\n\nBy being provided with an invalidation function that can determine if the cached\nreturn results have gone stale, the function wrapper will either return the\ncached value or rerun the function and return and re-cache the new results in the\ncase of stale cache.\n\nThe idea is that recalculating the work of the function is costly, but there is a\nmuch \"cheaper\" invalidation function that can tell us when work needs to be redone.\n\nThe decorator factory (versioned_lru_cache_with_ttl) also expects being passed a\nproxy to a mutable mapping, this proxy should provide a \"fresh\" version of the\nmapping per session. Ex. here being the g request context object used by the Flask\nweb framework. This allows to calculate the invalidation/ version only once per\nsession and can make the caching even more efficient.\n\n## Motivation\nThere a quite a few caveats I want to cover here but I will leave those for the \nsection bellow.\n\nThe general idea here is that we have some time consuming work that takes place\nhowever there is a much less costly way we can determine if the output of this has\ngone stale.\n\nWhen a requester attempts to access the output of the work we can cheaply check if it\nactually needs to be redone or just return the cached work output. \n\nAdditionally we this \"version\" of the work that is being calculated is also being \ncached on the session object which we expect to be provided by the user of the caching\ndecorator.\n\nThe assumption here is that consistency/ atomicity is expected with in the duration of\nthe session, so even the calculation of a version/ check if the work output is\ninvalidated is only done once per session.\n\nAs a more concrete example, we can imagine a Flask Webframewok app:\n- First flask request handler receives an HTTP request from a client\n\n- As part of the handler the function that needs to do the \"expensive\" work gets\ncalled since the output of its work is needed to process the request\n\n- Because the function has been decorated with the versioned LRU decorator first\nwe check if version/ invalidation calculation has been made already and stored on the\nglobal request context \"g\"\n\n- If the version is already on the request context we know that the \"expensive\" work\noutput that is cached can just get returned because we have already check for \ninvalidation for this request\n\n- If the version is not available on the request context object \"g\", we run the\nversioning/ invalidation function\n\n- If the cache is not invalidated as a result of the version check we can just return\nthe work output that is already cached\n\n- If the work output is invalidated the function that does the \"expensive\" work\nis ran and its output is cached, and finally the now update and recached work output\nis returned\n\n```\n           Client\n             │\n             ▼\n            ┌──┐\n            │..│\n           ┌┴──┴┐\n           │    │\n           │    │\n           │    │\n           └─┬──┘\n             │\n             │\n         HTTP│Request\n             ▼\n      ┌────────────────┐\n      │                │\n      │Flask           │\n      │WebFramework    │\n      │request handler │\n      │                │\n      └──────┬─────────┘\n             │\n             │\n             ▼\n      ┌────────────────┐\n      │                │\n      │  Caching       │\n      │  Decorator     │\n      │                │\n      └──────┬─────────┘\n             │\n             ▼\n┌───────────────────────────┐\n│                           │\n│    Get cached             │\n│ version from requet       │         xx\n│ context or recalc         │       xx  xx             ┌──────────────────┐\n│  the version.             │     xx      xx           │                  │\n│                           │   xx          xx         │  Redo expensive  │\n│  Aka is existing work     ├─►x  Redo work?  x──Yes──►│  work/ calc.     │\n│  output invalidated, do   │   xx          xx         │  Return new      │\n│  we need to redo the      │     xx      xx           │  work output     │\n│  expensive work           │       xx  xx             │                  │\n│                           │         xx               └────────┬─────────┘\n│                           │         │                         │\n└───────────────────────────┘         │                         ▼\n                                      │                ┌──────────────────┐\n                                      │                │                  │\n                                      │                │                  │\n                                      │                │  Cache new work  │\n                                     No                │  output          │\n                                      │                │                  │\n                                      │                └────────┬─────────┘\n                                      │                         │\n                                      │                         │\n                                      │                         │\n                                      │                         │\n                                      ▼                         │\n                            ┌────────────────────┐              │\n                            │                    │              │\n                            │   Return cached    │              │\n                            │   work to Flask    │              │\n                            │   which forwards   │◄─────────────┘\n                            │   to client        │\n                            │                    │\n                            └────────────────────┘\n\n```\n## Intended usecase and caveats\nThere is a lot to be said for the overuse of caching in software engineering as\nopposed to structurally fixing systems too often is caching used as a bandaid.\n\nThere is of course plenty of valid use cases for caching, I am just not entire sure\nthere is one for this specific implementation.\n\nThe way that this module of code got created was as a prototype of a possible solution\nto a work problem. The reality was that along side it I had a some number of other\nsolutions this one being the least preferred IMO.\n\nHere are some alternatives:\n- Can the work output be periodically recalculated by an async task. Is the use case\nfine with eventual consistency.\n\n- Can work output instead simply be cached on an external system ex. Redis or even\napplication operational DB. Can work execution to redo the output be triggered by\nsome event signifying a state change and/ or invalidation as opposed triggered by\nthe client request.\n\nWe could keep going with possible alternative solutioning here however the point is\nthat a specific use case should drive solution choice and optimization, that is after\nall the actual discipline of engineering, be it only software in this case.\n\nWhile the use case was not there for me the proto. was too close not to do something\nwith it, frankly the project setup and all this narration took longer that the actual\nprogramming.\n\nSo if happen to:\n- Need to check for invalidation on some session request\n\n- The work output can not be eventually consistent\n\n- Want to return the work output as soon as possible even avoiding external systems\nand network request lag\n\n- You are OK with an occasional requester getting penalized with a longer processing\ntime as a trade off that other requesters get almost instant results from the cache\n\n- You want atomicity of the state of the work output across a request/ session\n\nWell then you  might possibly have a use case for this peculiar cache implementation!\n\n## How to setup\n\n### To setup for development:\n```\nmake dev-install \n```\n\n### To build for distribution:\n```\nmake build \n```\n\n### To run tests (pytest), python type check (mypy) and linting (flake8):\n```\nmake test\n```\n\n### To run live Flask-example/ test:\n```\nmake test-example\n```\n\n### To format all code (black):\n```\nmake format\n```\n\n### To get any outstanding to-dos in code (Marked with \"# TODO:\"): \n```\nmake todo\n```\n\n### To clean up all build artifacts and dev envir. leaving only repo:\n```\nmake clean\n```\n\n### To properly begin your day:\n```\nmake hello\n```\n\n## Copy-pastable quick start code example\n\n```\nimport random\nfrom typing import Any\n\nfrom versioned_lru_cache import versioned_lru_cache_with_ttl\n\ng: dict = {}  # Fake global context for testing\n\n\ndef test_gen_version(*args: Any, **kwargs: Any) -> str:\n    return str(random.randint(0, 1000000000000))\n\n\n@versioned_lru_cache_with_ttl(\n    proxy_to_session_context_object=g,\n    generate_version_func=test_gen_version,\n    module_name=\"test_module_name\",\n)\ndef test_function_we_want_to_cache(test: Any = None) -> str:\n    # Some very heavy computation or database query here\n    print(\"Doing heavy work! aka. test function body is executing.\")\n    return 'This is the result of the \"heavy\" work.'\n\n\ndef main() -> int:\n    print(\n        \"Call one no params\",\n        test_function_we_want_to_cache(),\n        test_function_we_want_to_cache.__name__,\n    )\n    print(\n        \"Call two no params\",\n        test_function_we_want_to_cache(),\n        test_function_we_want_to_cache.__name__,\n    )\n    print(\n        \"Call three test=1 as params\",\n        test_function_we_want_to_cache(test=1),\n        test_function_we_want_to_cache.__name__,\n    )\n\n    return 0\n\n\nif __name__ == \"__main__\":\n    SystemExit(main())\n```\n\n## Extended example with Flask\n\nLook in: `examples/flask_fauxdb_app_example.py`\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/izo0x90/versioned_lru_cache",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "versioned-lru-cache",
    "package_url": "https://pypi.org/project/versioned-lru-cache/",
    "platform": null,
    "project_url": "https://pypi.org/project/versioned-lru-cache/",
    "project_urls": {
      "Bug Tracker": "https://github.com/izo0x90/versioned_lru_cache/issues",
      "Homepage": "https://github.com/izo0x90/versioned_lru_cache"
    },
    "release_url": "https://pypi.org/project/versioned-lru-cache/0.0.1/",
    "requires_dist": null,
    "requires_python": ">=3.10",
    "summary": "Simple package for a versioned lru cache function decorator",
    "version": "0.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17358136,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "38e1cbd0f08c68e2fb04e3dd63f83d5ac7b48f0094048eff427e30f06f7e4ba8",
          "md5": "616a6df1ebf4db0f886e6767960aa30b",
          "sha256": "2c208aad76886f75ad5fb9006bd5ca27cb71f8c4f0f0ac0c475987b18d4f5a1a"
        },
        "downloads": -1,
        "filename": "versioned_lru_cache-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "616a6df1ebf4db0f886e6767960aa30b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.10",
        "size": 5391,
        "upload_time": "2023-03-20T02:47:07",
        "upload_time_iso_8601": "2023-03-20T02:47:07.799004Z",
        "url": "https://files.pythonhosted.org/packages/38/e1/cbd0f08c68e2fb04e3dd63f83d5ac7b48f0094048eff427e30f06f7e4ba8/versioned_lru_cache-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cd91101480e3ba8d597f3ce3cd0aee19f22ca46d1f641fbc9e48c942ad51a3c4",
          "md5": "3c49344a5300cbbe5f838f945e852290",
          "sha256": "e294b2d4fc9662f939cf937c9feaf4aeec337e25fefa5947351d0b29802f7323"
        },
        "downloads": -1,
        "filename": "versioned-lru-cache-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "3c49344a5300cbbe5f838f945e852290",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.10",
        "size": 5759,
        "upload_time": "2023-03-20T02:47:09",
        "upload_time_iso_8601": "2023-03-20T02:47:09.906381Z",
        "url": "https://files.pythonhosted.org/packages/cd/91/101480e3ba8d597f3ce3cd0aee19f22ca46d1f641fbc9e48c942ad51a3c4/versioned-lru-cache-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "38e1cbd0f08c68e2fb04e3dd63f83d5ac7b48f0094048eff427e30f06f7e4ba8",
        "md5": "616a6df1ebf4db0f886e6767960aa30b",
        "sha256": "2c208aad76886f75ad5fb9006bd5ca27cb71f8c4f0f0ac0c475987b18d4f5a1a"
      },
      "downloads": -1,
      "filename": "versioned_lru_cache-0.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "616a6df1ebf4db0f886e6767960aa30b",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.10",
      "size": 5391,
      "upload_time": "2023-03-20T02:47:07",
      "upload_time_iso_8601": "2023-03-20T02:47:07.799004Z",
      "url": "https://files.pythonhosted.org/packages/38/e1/cbd0f08c68e2fb04e3dd63f83d5ac7b48f0094048eff427e30f06f7e4ba8/versioned_lru_cache-0.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "cd91101480e3ba8d597f3ce3cd0aee19f22ca46d1f641fbc9e48c942ad51a3c4",
        "md5": "3c49344a5300cbbe5f838f945e852290",
        "sha256": "e294b2d4fc9662f939cf937c9feaf4aeec337e25fefa5947351d0b29802f7323"
      },
      "downloads": -1,
      "filename": "versioned-lru-cache-0.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "3c49344a5300cbbe5f838f945e852290",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.10",
      "size": 5759,
      "upload_time": "2023-03-20T02:47:09",
      "upload_time_iso_8601": "2023-03-20T02:47:09.906381Z",
      "url": "https://files.pythonhosted.org/packages/cd/91/101480e3ba8d597f3ce3cd0aee19f22ca46d1f641fbc9e48c942ad51a3c4/versioned-lru-cache-0.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}