{
  "info": {
    "author": "Ritvik Rastogi",
    "author_email": "rastogiritvik99@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9"
    ],
    "description": "# [pyradox-generative](https://github.com/Ritvik19/pyradox-generative)\n\nState of the Art Neural Networks for Generative Deep Learning\n\n[![Downloads](https://pepy.tech/badge/pyradox-generative)](https://pepy.tech/project/pyradox-generative)\n[![Downloads](https://pepy.tech/badge/pyradox-generative/month)](https://pepy.tech/project/pyradox-generative)\n[![Downloads](https://pepy.tech/badge/pyradox-generative/week)](https://pepy.tech/project/pyradox-generative)\n\n---\n\n## Table of Contents\n\n- [pyradox-generative](#pyradox-generative)\n  - [Table of Contents](#table-of-contents)\n  - [Installation](#installation)\n  - [Usage](#usage)\n    - [Vanilla GAN](#vanilla-gan)\n    - [Conditional GAN](#conditional-gan)\n    - [Wasserstein GAN](#wasserstein-gan)\n    - [Variational Auto Encoder](#variational-auto-encoder)\n    - [Style GAN](#style-gan)\n    - [Cycle GAN](#cycle-gan)\n  - [References](#references)\n\n---\n\n## Installation\n\n```bash\npip install pyradox-generative\n```\n\n---\n\n## Usage\n\nThis library provides light weight trainers for the following generative models:\n\n### Vanilla GAN\n\nJust provide your genrator and discriminator and train your GAN\n\nData Preparation:\n\n```python\nfrom pyradox_generative import GAN\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow.keras as keras\n\n(x_train, y_train), _ = keras.datasets.mnist.load_data()\nx_train = x_train.astype(np.float32) / 255\nx_train = x_train.reshape(-1, 28, 28, 1) * 2.0 - 1.0\n\ndataset = tf.data.Dataset.from_tensor_slices(x_train)\ndataset = dataset.shuffle(1024)\ndataset = dataset.batch(32, drop_remainder=True).prefetch(1)\n```\n\nDefine the generator and discriminator models:\n\n```python\ngenerator = keras.models.Sequential(\n    [\n        keras.Input(shape=[28]),\n        keras.layers.Dense(7 * 7 * 3),\n        keras.layers.Reshape([7, 7, 3]),\n        keras.layers.BatchNormalization(),\n        keras.layers.Conv2DTranspose(\n            32, kernel_size=3, strides=2, padding=\"same\", activation=\"selu\"\n        ),\n        keras.layers.Conv2DTranspose(\n            1, kernel_size=3, strides=2, padding=\"same\", activation=\"tanh\"\n        ),\n    ],\n    name=\"generator\",\n)\n\ndiscriminator = keras.models.Sequential(\n    [\n        keras.layers.Conv2D(\n            32,\n            kernel_size=3,\n            strides=2,\n            padding=\"same\",\n            activation=keras.layers.LeakyReLU(0.2),\n            input_shape=[28, 28, 1],\n        ),\n        keras.layers.Conv2D(\n            3,\n            kernel_size=3,\n            strides=2,\n            padding=\"same\",\n            activation=keras.layers.LeakyReLU(0.2),\n        ),\n        keras.layers.Flatten(),\n        keras.layers.Dense(1, activation=\"sigmoid\"),\n    ],\n    name=\"discriminator\",\n)\n```\n\nPlug in the models to the trainer class and train them using the very familiar compile and fit methods:\n\n```python\ngan = GAN(discriminator=discriminator, generator=generator, latent_dim=28)\ngan.compile(\n    d_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n    g_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n    loss_fn=keras.losses.BinaryCrossentropy(),\n)\n\nhistory = gan.fit(dataset)\n\n```\n\n### Conditional GAN\n\nJust provide your genrator and discriminator and train your GAN\n\nData Preparation and calculate the input and output dimensions of generator and discriminator:\n\n```python\nfrom pyradox_generative import ConditionalGAN\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow.keras as keras\n\nCODINGS_SIZE = 28\nN_CHANNELS = 1\nN_CLASSES = 10\nG_INP_CHANNELS = CODINGS_SIZE + N_CLASSES\nD_INP_CHANNELS = N_CHANNELS + N_CLASSES\n\n(x_train, y_train), _ = keras.datasets.mnist.load_data()\nx_train = x_train\nx_train = x_train.astype(np.float32) / 255\nx_train = x_train.reshape(-1, 28, 28, 1) * 2.0 - 1.0\ny_train = y_train\ny_train = keras.utils.to_categorical(y_train, 10)\n\ndataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\ndataset = dataset.shuffle(1024)\ndataset = dataset.batch(32, drop_remainder=True).prefetch(1)\n```\n\nDefine the generator and discriminator models:\n\n```python\ngenerator = keras.models.Sequential(\n    [\n        keras.Input(shape=[G_INP_CHANNELS]),\n        keras.layers.Dense(7 * 7 * 3),\n        keras.layers.Reshape([7, 7, 3]),\n        keras.layers.BatchNormalization(),\n        keras.layers.Conv2DTranspose(\n            32, kernel_size=3, strides=2, padding=\"same\", activation=\"selu\"\n        ),\n        keras.layers.Conv2DTranspose(\n            1, kernel_size=3, strides=2, padding=\"same\", activation=\"tanh\"\n        ),\n    ],\n    name=\"generator\",\n)\n\ndiscriminator = keras.models.Sequential(\n    [\n        keras.layers.Conv2D(\n            32,\n            kernel_size=3,\n            strides=2,\n            padding=\"same\",\n            activation=keras.layers.LeakyReLU(0.2),\n            input_shape=[28, 28, D_INP_CHANNELS],\n        ),\n        keras.layers.Conv2D(\n            3,\n            kernel_size=3,\n            strides=2,\n            padding=\"same\",\n            activation=keras.layers.LeakyReLU(0.2),\n        ),\n        keras.layers.Flatten(),\n        keras.layers.Dense(1, activation=\"sigmoid\"),\n    ],\n    name=\"discriminator\",\n)\n```\n\nPlug in the models to the trainer class and train them using the very familiar compile and fit methods:\n\n```python\ngan = ConditionalGAN(\n    discriminator=discriminator, generator=generator, latent_dim=CODINGS_SIZE\n)\ngan.compile(\n    d_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n    g_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n    loss_fn=keras.losses.BinaryCrossentropy(),\n)\n\nhistory = gan.fit(dataset)\n\n```\n\n### Wasserstein GAN\n\nJust provide your genrator and discriminator and train your GAN\n\nData Preparation:\n\n```python\nfrom pyradox_generative import WGANGP\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow.keras as keras\n\n(x_train, y_train), _ = keras.datasets.mnist.load_data()\nx_train = x_train.astype(np.float32) / 255\nx_train = x_train.reshape(-1, 28, 28, 1) * 2.0 - 1.0\n\ndataset = tf.data.Dataset.from_tensor_slices(x_train)\ndataset = dataset.shuffle(1024)\ndataset = dataset.batch(32, drop_remainder=True).prefetch(1)\n```\n\nDefine the generator and discriminator models:\n\n```python\ngenerator = keras.models.Sequential(\n    [\n        keras.Input(shape=[28]),\n        keras.layers.Dense(7 * 7 * 3),\n        keras.layers.Reshape([7, 7, 3]),\n        keras.layers.BatchNormalization(),\n        keras.layers.Conv2DTranspose(\n            32, kernel_size=3, strides=2, padding=\"same\", activation=\"selu\"\n        ),\n        keras.layers.Conv2DTranspose(\n            1, kernel_size=3, strides=2, padding=\"same\", activation=\"tanh\"\n        ),\n    ],\n    name=\"generator\",\n)\n\ndiscriminator = keras.models.Sequential(\n    [\n        keras.layers.Conv2D(\n            32,\n            kernel_size=3,\n            strides=2,\n            padding=\"same\",\n            activation=keras.layers.LeakyReLU(0.2),\n            input_shape=[28, 28, 1],\n        ),\n        keras.layers.Conv2D(\n            3,\n            kernel_size=3,\n            strides=2,\n            padding=\"same\",\n            activation=keras.layers.LeakyReLU(0.2),\n        ),\n        keras.layers.Flatten(),\n        keras.layers.Dense(1, activation=\"sigmoid\"),\n    ],\n    name=\"discriminator\",\n)\n```\n\nPlug in the models to the trainer class and train them using the very familiar compile and fit methods:\n\n```python\ngan = WGANGP(\n    discriminator=discriminator,\n    generator=generator,\n    latent_dim=28,\n    discriminator_extra_steps=1,\n    gp_weight=10,\n)\ngan.compile(\n    d_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n    g_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n)\n\nhistory = gan.fit(dataset)\n\n```\n\n### Variational Auto Encoder\n\nJust provide your encoder and decoder and train your VAE Sampling is done internally\n\nData Preparation:\n\n```python\nfrom pyradox_generative import VAE\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow.keras as keras\n\n(x_train, y_train), _ = keras.datasets.mnist.load_data()\nx_train = x_train.astype(np.float32) / 255\nx_train = x_train.reshape(-1, 28, 28, 1) * 2.0 - 1.0\n\ndataset = tf.data.Dataset.from_tensor_slices(x_train)\ndataset = dataset.shuffle(1024)\ndataset = dataset.batch(32, drop_remainder=True).prefetch(1)\n```\n\nDefine the encoder and decoder models:\n\n```python\nencoder = keras.models.Sequential(\n    [\n        keras.Input(shape=(28, 28, 1)),\n        keras.layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\"),\n        keras.layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\"),\n        keras.layers.Flatten(),\n        keras.layers.Dense(16, activation=\"relu\"),\n    ],\n    name=\"encoder\",\n)\n\ndecoder = keras.models.Sequential(\n    [\n        keras.Input(shape=(28,)),\n        keras.layers.Dense(7 * 7 * 64, activation=\"relu\"),\n        keras.layers.Reshape((7, 7, 64)),\n        keras.layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\"),\n        keras.layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\"),\n        keras.layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\"),\n    ],\n    name=\"decoder\",\n)\n```\n\nPlug in the models to the trainer class and train them using the very familiar compile and fit methods:\n\n```python\nvae = VAE(encoder=encoder, decoder=decoder, latent_dim=28)\nvae.compile(keras.optimizers.Adam(learning_rate=0.001))\nhistory = vae.fit(dataset)\n\n```\n\n### Style GAN\n\nJust provide your genrator and discriminator models and train your GAN\n\nData Preparation:\n\n```python\nfrom pyradox_generative import StyleGAN\nimport numpy as np\nimport tensorflow as tf\nfrom functools import partial\n\ndef resize_image(res, image):\n    # only donwsampling, so use nearest neighbor that is faster to run\n    image = tf.image.resize(\n        image, (res, res), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR\n    )\n    image = tf.cast(image, tf.float32) / 127.5 - 1.0\n    return image\n\n\ndef create_dataloader(res):\n    (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n    x_train = x_train[:100, :, :]\n    x_train = np.pad(x_train, [(0, 0), (2, 2), (2, 2)], mode=\"constant\")\n    x_train = tf.image.grayscale_to_rgb(tf.expand_dims(x_train, axis=3), name=None)\n    x_train = tf.data.Dataset.from_tensor_slices(x_train)\n\n    batch_size = 32\n    dl = x_train.map(partial(resize_image, res), num_parallel_calls=tf.data.AUTOTUNE)\n    dl = dl.shuffle(200).batch(batch_size, drop_remainder=True).prefetch(1).repeat()\n    return dl\n```\n\nDefine the model by providing number of filters for each each resolution (log 2):\n\n```python\ngan = StyleGAN(\n    target_res=32,\n    start_res=4,\n    filter_nums={0: 32, 1: 32, 2: 32, 3: 32, 4: 32, 5: 32},\n)\nopt_cfg = {\"learning_rate\": 1e-3, \"beta_1\": 0.0, \"beta_2\": 0.99, \"epsilon\": 1e-8}\n\nstart_res_log2 = 2\ntarget_res_log2 = 5\n```\n\nTrain the Style GAN:\n\n```python\nfor res_log2 in range(start_res_log2, target_res_log2 + 1):\n    res = 2 ** res_log2\n    for phase in [\"TRANSITION\", \"STABLE\"]:\n        if res == 4 and phase == \"TRANSITION\":\n            continue\n\n        train_dl = create_dataloader(res)\n\n        steps = 10\n\n        gan.compile(\n            d_optimizer=tf.keras.optimizers.Adam(**opt_cfg),\n            g_optimizer=tf.keras.optimizers.Adam(**opt_cfg),\n            loss_weights={\"gradient_penalty\": 10, \"drift\": 0.001},\n            steps_per_epoch=steps,\n            res=res,\n            phase=phase,\n            run_eagerly=False,\n        )\n\n        print(phase)\n        history = gan.fit(train_dl, epochs=1, steps_per_epoch=steps)\n\n```\n\n### Cycle GAN\n\nJust provide your genrator and discriminator models and train your GAN\n\nData Preparation:\n\n```python\nimport tensorflow_datasets as tfds\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom pyradox_generative import CycleGAN\n\ntfds.disable_progress_bar()\nautotune = tf.data.AUTOTUNE\norig_img_size = (286, 286)\ninput_img_size = (256, 256, 3)\n\n\ndef normalize_img(img):\n    img = tf.cast(img, dtype=tf.float32)\n    return (img / 127.5) - 1.0\n\n\ndef preprocess_train_image(img, label):\n    img = tf.image.random_flip_left_right(img)\n    img = tf.image.resize(img, [*orig_img_size])\n    img = tf.image.random_crop(img, size=[*input_img_size])\n    img = normalize_img(img)\n    return img\n\n\ndef preprocess_test_image(img, label):\n    img = tf.image.resize(img, [input_img_size[0], input_img_size[1]])\n    img = normalize_img(img)\n    return img\n\ntrain_horses, _ = tfds.load(\n    \"cycle_gan/horse2zebra\", with_info=True, as_supervised=True, split=\"trainA[:5%]\"\n)\ntrain_zebras, _ = tfds.load(\n    \"cycle_gan/horse2zebra\", with_info=True, as_supervised=True, split=\"trainB[:5%]\"\n)\n\nbuffer_size = 256\nbatch_size = 1\n\ntrain_horses = (\n    train_horses.map(preprocess_train_image, num_parallel_calls=autotune)\n    .cache()\n    .shuffle(buffer_size)\n    .batch(batch_size)\n)\ntrain_zebras = (\n    train_zebras.map(preprocess_train_image, num_parallel_calls=autotune)\n    .cache()\n    .shuffle(buffer_size)\n    .batch(batch_size)\n)\n```\n\nDefine the generator and discriminator models:\n\n```python\ndef build_generator(name):\n    return keras.models.Sequential(\n        [\n            keras.layers.Input(shape=input_img_size),\n            keras.layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\"),\n            keras.layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\"),\n            keras.layers.Conv2D(3, 3, activation=\"tanh\", padding=\"same\"),\n        ],\n        name=name,\n    )\n\n\ndef build_discriminator(name):\n    return keras.models.Sequential(\n        [\n            keras.layers.Input(shape=input_img_size),\n            keras.layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\"),\n            keras.layers.MaxPooling2D(pool_size=2, strides=2),\n            keras.layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\"),\n            keras.layers.MaxPooling2D(pool_size=2, strides=2),\n            keras.layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\"),\n            keras.layers.MaxPooling2D(pool_size=2, strides=2),\n            keras.layers.Conv2D(1, 3, activation=\"relu\", padding=\"same\"),\n        ],\n        name=name,\n    )\n```\n\nPlug in the models to the trainer class and train them using the very familiar compile and fit methods:\n\n```python\ngan = CycleGAN(\n    generator_g=build_generator(\"gen_G\"),\n    generator_f=build_generator(\"gen_F\"),\n    discriminator_x=build_discriminator(\"disc_X\"),\n    discriminator_y=build_discriminator(\"disc_Y\"),\n)\n\ngan.compile(\n    gen_g_optimizer=keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5),\n    gen_f_optimizer=keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5),\n    disc_x_optimizer=keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5),\n    disc_y_optimizer=keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5),\n)\n\nhistory = gan.fit(\n    tf.data.Dataset.zip((train_horses, train_zebras)),\n)\n\n```\n\n---\n\n## References\n\n- [Generative Adversarial Networks](https://arxiv.org/abs/1406.2661)\n- [Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](https://arxiv.org/abs/1511.06434)\n- [Conditional Generative Adversarial Nets](https://arxiv.org/abs/1411.1784)\n- [Wasserstein GAN](https://arxiv.org/abs/1701.07875)\n- [Improved Training of Wasserstein GANs](https://arxiv.org/abs/1704.00028)\n- [An Introduction to Variational Autoencoders](https://arxiv.org/abs/1906.02691)\n- [A Style-Based Generator Architecture for Generative Adversarial Networks](https://arxiv.org/abs/1812.04948)\n- [Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks](https://arxiv.org/abs/1703.10593)\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "pyradox-generative",
    "package_url": "https://pypi.org/project/pyradox-generative/",
    "platform": "",
    "project_url": "https://pypi.org/project/pyradox-generative/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/pyradox-generative/1.0.2/",
    "requires_dist": [
      "tensorflow (==2.6.2)",
      "tensorflow-addons (==0.14.0)"
    ],
    "requires_python": ">=3.7,<4.0",
    "summary": "State of the Art Neural Networks for Generative Deep Learning",
    "version": "1.0.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12794531,
  "releases": {
    "1.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6f78fe70a48188d488c41a83360a95730eaed842a642cc0369443c05e9cb5f96",
          "md5": "6cd720c07b4d8a97a01d73dbdb29ece5",
          "sha256": "465df4864779acfdbe246521c067bdeffa3ef1ba8e65617e60d624008c0a14f3"
        },
        "downloads": -1,
        "filename": "pyradox_generative-1.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "6cd720c07b4d8a97a01d73dbdb29ece5",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7,<4.0",
        "size": 17088,
        "upload_time": "2022-02-05T05:46:19",
        "upload_time_iso_8601": "2022-02-05T05:46:19.130149Z",
        "url": "https://files.pythonhosted.org/packages/6f/78/fe70a48188d488c41a83360a95730eaed842a642cc0369443c05e9cb5f96/pyradox_generative-1.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3aa4a2b1815a2885c74b2517956a37c0373e8fbde88a45821b858f90f23a0177",
          "md5": "e87649c46c52ea3d74e24289cc7c5119",
          "sha256": "f53be22cc0e201c550434002a0ca31cf05cf390678a9398d0f316fc539c00663"
        },
        "downloads": -1,
        "filename": "pyradox-generative-1.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "e87649c46c52ea3d74e24289cc7c5119",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7,<4.0",
        "size": 15662,
        "upload_time": "2022-02-05T05:46:21",
        "upload_time_iso_8601": "2022-02-05T05:46:21.059581Z",
        "url": "https://files.pythonhosted.org/packages/3a/a4/a2b1815a2885c74b2517956a37c0373e8fbde88a45821b858f90f23a0177/pyradox-generative-1.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "6f78fe70a48188d488c41a83360a95730eaed842a642cc0369443c05e9cb5f96",
        "md5": "6cd720c07b4d8a97a01d73dbdb29ece5",
        "sha256": "465df4864779acfdbe246521c067bdeffa3ef1ba8e65617e60d624008c0a14f3"
      },
      "downloads": -1,
      "filename": "pyradox_generative-1.0.2-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "6cd720c07b4d8a97a01d73dbdb29ece5",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7,<4.0",
      "size": 17088,
      "upload_time": "2022-02-05T05:46:19",
      "upload_time_iso_8601": "2022-02-05T05:46:19.130149Z",
      "url": "https://files.pythonhosted.org/packages/6f/78/fe70a48188d488c41a83360a95730eaed842a642cc0369443c05e9cb5f96/pyradox_generative-1.0.2-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "3aa4a2b1815a2885c74b2517956a37c0373e8fbde88a45821b858f90f23a0177",
        "md5": "e87649c46c52ea3d74e24289cc7c5119",
        "sha256": "f53be22cc0e201c550434002a0ca31cf05cf390678a9398d0f316fc539c00663"
      },
      "downloads": -1,
      "filename": "pyradox-generative-1.0.2.tar.gz",
      "has_sig": false,
      "md5_digest": "e87649c46c52ea3d74e24289cc7c5119",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7,<4.0",
      "size": 15662,
      "upload_time": "2022-02-05T05:46:21",
      "upload_time_iso_8601": "2022-02-05T05:46:21.059581Z",
      "url": "https://files.pythonhosted.org/packages/3a/a4/a2b1815a2885c74b2517956a37c0373e8fbde88a45821b858f90f23a0177/pyradox-generative-1.0.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}