{
  "info": {
    "author": "Michael Petrochuk",
    "author_email": "petrochukm@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Intended Audience :: Developers",
      "Intended Audience :: Education",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: Apache Software License",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Topic :: Scientific/Engineering",
      "Topic :: Scientific/Engineering :: Artificial Intelligence",
      "Topic :: Scientific/Engineering :: Mathematics",
      "Topic :: Software Development",
      "Topic :: Software Development :: Libraries",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "<p align=\"center\"><img width=\"544px\" src=\"logo.svg\" /></p>\n\n<h3 align=\"center\">Extensible and Fault-Tolerant Hyperparameter Management</h3>\n\nHParams is a thoughtful approach to configuration management for machine learning projects. It\nenables you to externalize your hyperparameters into a configuration file. In doing so, you can\nreproduce experiments, iterate quickly, and reduce errors.\n\n**Features:**\n\n- Approachable and easy-to-use API\n- Battle-tested over three years\n- Fast with little to no runtime overhead (< 3e-05 seconds) per configured function\n- Robust to most use cases with 100% test coverage and 75 tests\n- Lightweight with only one dependency\n\n![PyPI - Python Version](https://img.shields.io/pypi/pyversions/hparams.svg?style=flat-square)\n[![Codecov](https://img.shields.io/codecov/c/github/PetrochukM/HParams/master.svg?style=flat-square)](https://codecov.io/gh/PetrochukM/HParams)\n[![Downloads](http://pepy.tech/badge/hparams)](http://pepy.tech/project/hparams)\n[![Build Status](https://img.shields.io/travis/PetrochukM/HParams/master.svg?style=flat-square)](https://travis-ci.org/PetrochukM/HParams)\n[![License: MIT](https://img.shields.io/badge/License-MIT-brightgreen.svg?style=flat-square)](https://opensource.org/licenses/MIT)\n[![Twitter: PetrochukM](https://img.shields.io/twitter/follow/MPetrochuk.svg?style=social)](https://twitter.com/MPetrochuk)\n\n_Logo by [Chloe Yeo](http://www.yeochloe.com/), Corporate Sponsorship by [WellSaid Labs](https://wellsaidlabs.com/)_\n\n## Installation\n\nMake sure you have Python 3. You can then install `hparams` using `pip`:\n\n```bash\npip install hparams\n```\n\nInstall the latest code via:\n\n```bash\npip install git+https://github.com/PetrochukM/HParams.git\n```\n\n## Oops ðŸ›\n\nWith HParams, you will avoid common but needless hyperparameter mistakes. It will throw a warning\nor error if:\n\n- A hyperparameter is overwritten.\n- A hyperparameter is declared but not set.\n- A hyperparameter is set but not declared.\n- A hyperparameter type is incorrect.\n\nFinally, HParams is built with developer experience in mind. HParams includes 13 errors and 6 warnings\nto help catch and resolve issues quickly.\n\n## Examples\n\nAdd HParams to your project by following one of these common use cases:\n\n### Configure Training ðŸ¤—\n\nConfigure your training run, like so:\n\n```python\n# main.py\nfrom hparams import configurable, add_config, HParams, HParam\nfrom typing import Union\n\n@configurable\ndef train(batch_size: int = HParam()):\n    pass\n\nclass Model():\n\n    @configurable\n    def __init__(self, hidden_size=HParam(int), dropout=HParam(float)):\n        pass\n\nadd_config({ 'main': {\n    'train': HParams(batch_size=32),\n    'Model.__init__': HParams(hidden_size=1024, dropout=0.25),\n}})\n```\n\nHParams supports optional configuration typechecking to help you find bugs! ðŸ›\n\n### Set Defaults\n\nConfigure PyTorch and Tensorflow defaults to match via:\n\n```python\nfrom torch.nn import BatchNorm1d\nfrom hparams import configurable, add_config, HParams\n\n# NOTE: `momentum=0.01` to match Tensorflow defaults\nBatchNorm1d.__init__ = configurable(BatchNorm1d.__init__)\nadd_config({ 'torch.nn.BatchNorm1d.__init__': HParams(momentum=0.01) })\n```\n\nConfigure your random seed globally, like so:\n\n```python\n# config.py\nimport random\nfrom hparams import configurable, add_config, HParams\n\nrandom.seed = configurable(random.seed)\nadd_config({'random.seed': HParams(a=123)})\n```\n\n```python\n# main.py\nimport config\nimport random\n\nrandom.seed()\n```\n\n### CLI\n\nExperiment with hyperparameters through your command line, for example:\n\n```console\nfoo@bar:~$ file.py --torch.optim.adam.Adam.__init__ 'HParams(lr=0.1,betas=(0.999,0.99))'\n```\n\n```python\nimport sys\nfrom torch.optim import Adam\nfrom hparams import configurable, add_config, parse_hparam_args\n\nAdam.__init__ = configurable(Adam.__init__)\nparsed = parse_hparam_args(sys.argv[1:])  # Parse command line arguments\nadd_config(parsed)\n```\n\n### Hyperparameter optimization\n\nHyperparameter optimization is easy to-do, check this out:\n\n```python\nimport itertools\nfrom torch.optim import Adam\nfrom hparams import configurable, add_config, HParams\n\nAdam.__init__ = configurable(Adam.__init__)\n\ndef train():  # Train the model and return the loss.\n    pass\n\nfor betas in itertools.product([0.999, 0.99, 0.9], [0.999, 0.99, 0.9]):\n    add_config({Adam.__init__: HParams(betas=betas)})  # Grid search over the `betas`\n    train()\n```\n\n### Track Hyperparameters\n\nEasily track your hyperparameters using tools like [Comet](comet.ml).\n\n```python\nfrom comet_ml import Experiment\nfrom hparams import get_config\n\nexperiment = Experiment()\nexperiment.log_parameters(get_config())\n```\n\n### Multiprocessing: Partial Support\n\nExport a Python `functools.partial` to use in another process, like so:\n\n```python\nfrom hparams import configurable, HParam\n\n@configurable\ndef func(hparam=HParam()):\n    pass\n\npartial = func.get_configured_partial()\n```\n\nWith this approach, you don't have to transfer the global state to the new process. To transfer the\nglobal state, you'll want to use `get_config` and `add_config`.\n\n## Docs ðŸ“–\n\nThe complete documentation for HParams is available [here](./DOCS.md).\n\nLearn more about related projects to HParams [here](./RELATED.md).\n\n## Contributing\n\nWe've released HParams because a lack of hyperparameter management solutions. We hope that\nother people can benefit from the project. We are thankful for any contributions from the\ncommunity.\n\n### Contributing Guide\n\nRead our [contributing guide](https://github.com/PetrochukM/HParams/blob/master/CONTRIBUTING.md) to\nlearn about our development process, how to propose bugfixes and improvements, and how to build and\ntest your changes to HParams.\n\n## Authors\n\n- [Michael Petrochuk](https://github.com/PetrochukM/) â€” Developer\n- [Chloe Yeo](http://www.yeochloe.com/) â€” Logo Design\n\n## Citing\n\nIf you find HParams useful for an academic publication, then please use the following BibTeX to\ncite it:\n\n```latex\n@misc{hparams,\nauthor = {Petrochuk, Michael},\ntitle = {HParams: Hyperparameter management solution},\nyear = {2019},\npublisher = {GitHub},\njournal = {GitHub repository},\nhowpublished = {\\url{https://github.com/PetrochukM/HParams}},\n}\n```\n\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "hyperparameters hparams configurable",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "defaults",
    "package_url": "https://pypi.org/project/defaults/",
    "platform": "",
    "project_url": "https://pypi.org/project/defaults/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/defaults/0.3.0/",
    "requires_dist": [
      "typeguard"
    ],
    "requires_python": ">=3.5",
    "summary": "",
    "version": "0.3.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8127955,
  "releases": {
    "0.3.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a6d7f1f6ebfc91b6641f96e2042527bddfbd0a8ee6776ab3982890cf69a87050",
          "md5": "33410f0867622216f16a458037ff0e7f",
          "sha256": "b0dba82f160d0aeabd61b6ef10137ca95d48758dd7f8d79fb728a8a64ec03aed"
        },
        "downloads": -1,
        "filename": "defaults-0.3.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "33410f0867622216f16a458037ff0e7f",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.5",
        "size": 12706,
        "upload_time": "2020-09-07T06:54:05",
        "upload_time_iso_8601": "2020-09-07T06:54:05.192191Z",
        "url": "https://files.pythonhosted.org/packages/a6/d7/f1f6ebfc91b6641f96e2042527bddfbd0a8ee6776ab3982890cf69a87050/defaults-0.3.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "67678c91a5634ba5dd7706d50c76d6394396d814cd838f930a07569ad5fff563",
          "md5": "e2e25d7e79b27eb82d56edf917fea326",
          "sha256": "3967ffc48e4a40a980ce79b2649c9dbdae46d07802069e5498a382869ad65bda"
        },
        "downloads": -1,
        "filename": "defaults-0.3.0.tar.gz",
        "has_sig": false,
        "md5_digest": "e2e25d7e79b27eb82d56edf917fea326",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 12189,
        "upload_time": "2020-09-07T06:54:07",
        "upload_time_iso_8601": "2020-09-07T06:54:07.666095Z",
        "url": "https://files.pythonhosted.org/packages/67/67/8c91a5634ba5dd7706d50c76d6394396d814cd838f930a07569ad5fff563/defaults-0.3.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "a6d7f1f6ebfc91b6641f96e2042527bddfbd0a8ee6776ab3982890cf69a87050",
        "md5": "33410f0867622216f16a458037ff0e7f",
        "sha256": "b0dba82f160d0aeabd61b6ef10137ca95d48758dd7f8d79fb728a8a64ec03aed"
      },
      "downloads": -1,
      "filename": "defaults-0.3.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "33410f0867622216f16a458037ff0e7f",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.5",
      "size": 12706,
      "upload_time": "2020-09-07T06:54:05",
      "upload_time_iso_8601": "2020-09-07T06:54:05.192191Z",
      "url": "https://files.pythonhosted.org/packages/a6/d7/f1f6ebfc91b6641f96e2042527bddfbd0a8ee6776ab3982890cf69a87050/defaults-0.3.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "67678c91a5634ba5dd7706d50c76d6394396d814cd838f930a07569ad5fff563",
        "md5": "e2e25d7e79b27eb82d56edf917fea326",
        "sha256": "3967ffc48e4a40a980ce79b2649c9dbdae46d07802069e5498a382869ad65bda"
      },
      "downloads": -1,
      "filename": "defaults-0.3.0.tar.gz",
      "has_sig": false,
      "md5_digest": "e2e25d7e79b27eb82d56edf917fea326",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.5",
      "size": 12189,
      "upload_time": "2020-09-07T06:54:07",
      "upload_time_iso_8601": "2020-09-07T06:54:07.666095Z",
      "url": "https://files.pythonhosted.org/packages/67/67/8c91a5634ba5dd7706d50c76d6394396d814cd838f930a07569ad5fff563/defaults-0.3.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}