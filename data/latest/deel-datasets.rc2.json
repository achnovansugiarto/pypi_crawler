{
  "info": {
    "author": "DEEL",
    "author_email": "justin.plakoo@irt-saintexupery.com",
    "bugtrack_url": null,
    "classifiers": [
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7"
    ],
    "description": "# DEEL dataset manager\n[![PyPI](https://img.shields.io/pypi/v/deel-datasets.svg)](https://pypi.org/project/deel-datasets)\n[![Python](https://img.shields.io/pypi/pyversions/deel-datasets.svg)](https://pypi.org/project/deel-datasets)\n[![Documentation](https://img.shields.io/badge/doc-url-blue.svg)]( https://deel-ai.github.io/deel_dataset_manager/)\n[![deel_dataset tests](https://github.com/deel-ai/deel_dataset_manager/actions/workflows/python-tests.yml/badge.svg)](https://github.com/deel-ai/deel_dataset_manager/actions/workflows/python-tests.yml)\n[![deel_dataset lints](https://github.com/deel-ai/deel_dataset_manager/actions/workflows/python-lints.yml/badge.svg)](https://github.com/deel-ai/deel_dataset_manager/actions/workflows/python-lints.yml)\n[![License](https://img.shields.io/github/license/deel-ai/deel-datasets.svg)](https://github.com/deel-ai/deel_dataset_manager/blob/master/LICENSE)\n\n[deel-datasets manager](https://deel-ai.github.io/deel-datasets) project aims to ease the installation and usage of self-hosted or public datasets. It is an open framework to manage any dataset through a plugin mechanism.\n\n## Installation\n\nThe latest release can be installed from pypi. All needed python packages will also be installed as a dependency.\n\n```bash\npip install deel-datasets\n```\n\nOtherwize the HTTPS version should work but you will have to enter your credentials manually:\n\n```bash\npip install git+https://github.com/deel-ai/deel_dataset_manager.git\n```\n\n## Configuration\n\nThe configuration file specifies how the datasets should be downloaded, or\nif the datasets do no have to be downloaded (e.g. on Google Cloud).\n\nIt allows to define a list of datasets providers.\n\nThe configuration file should be by default at `$HOME/.deel/config.yml`:\n\n- On Windows system it is `C:\\Users\\$USERNAME\\.deel\\config.yml` unless you\n  have set the `HOME` environment variable.\n- The `DEEL_CONFIGURATION_FILE` environment variable can be used to specify the\n  location of the configuration file if you do not want to use the default one.\n\nThe configuration file is a **YAML** file.\n\nTwo two root nodes are mandatory in configuration file:\n- `providers:` (value = list of providers)\n- `path`: local destination directory path (by default = ${HOME}/.deel/datasets)\n\n      providers:\n        |-provider1\n        |-provider2\n        .\n        .\n        |-providerN\n      path: local destination path\n\n`providers` is the root node of the provider configurations list.\nEach child node of `providers` node define a provider configuration.\nThe name of child node is the name of the provider.\nIt may be used in command line to specify the provider (e.g., option `-p` for `download`).\n\nCurrently the following types of provider are implemented: `webdav`, `ftp`, `http`, `local` and `gcloud`.\n\n- The `webdav` provider will fetch datasets from a WebDAV server and needs at least the `url`\nconfiguration parameter.\nThe WebDAV provider supports basic authentication (see example below).\nIf the datasets are not at the root of the WebDAV server, the `folder` configuration can be used to\nspecify the remote path (see example below).\n\n- The `ftp` provider is similar to the `webdav` provider except that it will fetch datasets\nfrom a FTP server instead of a WebDAV one and needs at least the `url` configuration parameter.\n\n- The `local` provider does not require any extra configuration and will simply\nfetch data from the specified `path`. The `copy`configuation (true or false) allows to specify\nif dataset must be copied from `path` to destination `path` or not. `copy`is false by default.\n\n- The `gcloud` provider is similar to the `local` provider, except that it will try to\nlocate the dataset storage location automatically based on a mounted drive.\nThe `disk` configuration parameter is mandatory and specify the name of the GCloud drive.\n\n`path` parameter indicates where the datasets should be stored locally when using remote providers such as `webdav`, `http` or `ftp` provider.\n\n#### Configuration example\n\nBelow is an example of a configuration for the DEEL dataset manager:\n\n```yaml\n# Provider for the datasets - The names of the providers do not have to match\n# their types:\nproviders:\n\n  # A GCloud provider with a shared GCloud drive named \"my-disk-name\".\n  gcloud:\n    type: gcloud\n    disk: my-disk-name\n\n  # A local storage at \"/data/dataset\".\n  local:\n    type: local\n    path: /data/dataset/\n    copy: true\n\n  # An FTP provider.\n  ftp:\n    type: ftp\n    # The \"url\" parameter contains the full path (server + folder):\n    url: ftp://<server_name>/<dataset path on ftp server>\n    # or folder to set the the path to dataset remote directory\n    # folder: <dataset path on ftp server>\n    # The \"auth\" is optional if the FTP server is public:\n    auth:\n      method: \"simple\"\n      username: \"${username}\"\n      password: \"${password}\"\n\n  # A public WebDAV server.\n  webdav_public:\n    type: webdav\n    url: https://my-public-webdav.com\n\n  # A private WebDAV server where the datasets are not at the root.\n  # Note: This example can be used with Cloud storage such as Nextcloud with\n  # a shared \"datasets\" drive.\n  webdav_private:\n    type: webdav\n    url: https://my-cloud-provider.com/remote.php/webdav\n    folder: datasets\n    auth:\n        method: \"simple\"\n        username: \"${username}\"\n        password: \"${password}\"\n\n# The local path where datasets are stored when they are from a remote provider:\n# by default ${HOME}/.deel/datasets\npath: ${HOME}/.deel/datasets\n```\n\nYou can name a provider `default` to use it by-default.\nWhen looking for a dataset, the dataset is first looked-up in the `default` provider,\nthen in other providers.\nThe manager tries providers one-by-one in the order they are declared until it finds\none providing the dataset.\n\n## Uninstalling\n\nTo uninstall the deel dataset manager package , simply run `pip uninstall`:\n\n```\npip uninstall deel-datasets\n```\n\n## DEEL dataset plugin\n\nWithout plugins, DEEL datasets manager is only able to download a dataset and returns the path to\nthe local folder containing it (after download).\nBy installing plugins, you gain access to automatic way of loading datasets or pre-processing\ndata.\n\n### Plugins installation\n\nPlugins can be installed using `pip`.\n\nSome plugins are available on [github.com/deel-ai](https://github.com/deel-ai) and can be installed.\n\nFor DEEL project members, private plugins for DEEL project datasets are available on\n[here](https://forge.deel.ai/DevOps/datasets).\n\nThey can browse [here](https://forge.deel.ai/DevOps/datasets/all) for the list of available datasets.\n\n    # SSH version (with proper SSH key setup):\n    pip install git+ssh://git@forge.deel.ai:<port>/DevOps/datasets/all.git\n\n    # HTTPS version:\n    pip install git+https://forge.deel.ai/DevOps/datasets/all.git\n\n## Examples of usage\n\n### Basic usage\n\nTo load a dataset, you can simply do:\n\n```python\nimport deel.datasets\n\n# Load the default mode of dataset-a dataset:\ndataset-a-lpath = deel.datasets.load(\"dataset-a\")\n\n# dataset-c plugin is installed with tensorflow mode implemented\n# Load the tensorflow version of the dataset-b dataset (default mode for dataset-b):\ndataset-b-tf = deel.datasets.load(\"dataset-b\", mode=\"tensorflow\")\n#or because tensorflow mode is default mode\ndataset-b-tf = deel.datasets.load(\"dataset-b\")\n\n# If dataset-c plugin is installed with pytorch mode implemented,\n# load the pytorch version of the dataset-b dataset:\ndataset-c-pt = deel.datasets.load(\"dataset-c\", mode=\"pytorch\")\n```\n\nThe `deel.datasets.load` function is the basic entry to access the datasets.\nBy passing `with_info=True`, extra information can be retrieved as a python\ndictionary. Information are not standardized, so each dataset may provide\ndifferent ones:\nThe `mode` argument can be used to load different \"version\" of the dataset. By default,\nonly the `path` mode is available and will return the path to the local folder\ncontaining the dataset.\nBy installing plugins, new modes can be made available for each datasets (see plugin\nimplementation below).\n\n```python\nimport deel.datasets\n\n# Load the tensorflow version of the dataset-b dataset:\ndataset-b-lpath, info = deel.datasets.load(\"dataset-b\", mode=\"tensorflow\", with_info=True)\n\nprint(info[\"classes\"])\n```\n\nThe function can take extra parameters depending on the chosen dataset and mode,\nfor instance, you can specify the percentage of training data for the `blink`\ndataset:\n\n```python\nimport deel.datasets\n\n# Load the tensorflow version of the blink dataset:\nblink = deel.datasets.load(\"blink\", mode=\"tensorflow\", percent_train=60)\n```\n\n\n### Command line utilities\n\nThe `deel-datasets` package comes with some command line utilities that can be accessed using:\n\n```\npython -m deel.datasets ARGS...\n```\n\nThe `--help` option can be used to view the full capabilities of the command line program.\nBy default, the program uses the configuration at `$HOME/.deel/config.yml`, but the `-c`\nargument can be used to specified a custom configuration file.\n\nThe following commands are available (not exhaustive):\n\n- `list` &mdash; List the available datasets on all providers in configuration file.\nIf the `-p` option is used to specify a provider, this will list the datasets available on it.\n\nTo list the dataset already downloaded, you can use the `--local` option.\n\n```bash\n$ python -m deel.datasets list\nListing datasets at https://datasets.server1:\n  dataset-a: 3.0.1 [latest], 3.0.0\n  dataset-b: 1.0 [latest]\n  dataset-c: 1.0 [latest]\n$ python -m deel.datasets list --local\nListing datasets at ${HOME}/.deel/datasets:\n  dataset-a: 3.0.1 [latest], 3.0.0\n  dataset-c: 1.0 [latest]\n```\n\n- `download NAME[:VERSION]` &mdash; Download the specified dataset. If the configuration\n  does not specify a remote provider, this does nothing except outputing some information.\n  The `:VERSION` can be omitted, in which case `:latest` is implied. To force the re-download\n  of a dataset, the `--force` option can be used.\n\n```bash\n$ python -m deel.datasets download dataset-a:3.0.0\nFetching dataset-a:3.0.0...\ndataset-a-3.0.0-20191004.zip: 100%|█████████████████████████████████████████| 122M/122M [00:03<00:00, 39.3Mbytes/s]\nDataset dataset-a:3.0.0 stored at '${HOME}/.deel/datasets/dataset-a/3.0.0'.\n```\n\n- `remove NAME[:VERSION]` &mdash; Remove the specified dataset from the local storage (if\n  possible). If `:VERSION` is omitted, the whole dataset corresponding to `NAME` is\n  deleted. If the `--all` option is used, all datasets are removed from the local storage.\n\n## Adding a new dataset\n\n### Deel dataset plugin implementation\n\nA deel dataset plugin is an extension of the `Dataset` class defined in the DEEL dataset manager project.\nIt allows to access to specific dataset files using the load method of defined modes.\n\n#### The dataset class\n\nBelow is an example implementation of a dataset class `ExampleDataset`.\nThe `load_XXX` methods defines the various mode, e.g. `load_pytorch` adds\na `pytorch` mode to the dataset.\nThe default mode used (when none is specified) can be set using the\n`_default_mode` class attribute.\n\n```python\nimport h5py\nimport pathlib\nimport typing\n\nfrom deel.datasets.dataset import Dataset\nfrom deel.datasets.settings import Settings\n\n\nclass ExampleDataset(Dataset):\n\n    # Default mode:\n    _default_mode: str = \"numpy\"\n\n    def __init__(\n        self, version: str = \"latest\", settings: typing.Optional[Settings] = None\n    ):\n        \"\"\"\n        Args:\n            version: Version of the dataset.\n            settings: The settings to use for this dataset, or `None` to use the\n            default settings.\n        \"\"\"\n        # `data_name` is the name of the folder containing the dataset on the\n        # provider (remote or local).\n        super().__init__(\"data_name\", version, settings)\n\n    def load_numpy(self, path: pathlib.Path):\n        \"\"\"\n        Numpy mode for this dataset.\n        \"\"\"\n        # Dataset-specific code:\n        return data\n\n    def load_csv(self, path: pathlib.Path):\n        \"\"\"\n        CSV mode for this dataset.\n        \"\"\"\n\n        import pandas as pd\n\n        return pd.read_csv(path, sep=\";\", index_col=0)\n\n    def load_pytorch(\n        self,\n        path: pathlib.Path,\n        nstack: int = 4,\n        transform: typing.Callable = None,\n    ):\n        \"\"\"\n        Pytorch mode for this dataset. With extra arguments that can\n        be passed to the `deel.datasets.load` method using named parameters.\n        \"\"\"\n        from .torch import SourceDataSet\n\n        return SourceDataSet(self.load_path(path), nstack, transform)\n```\n\nBy default, the `with_info` option will return a dictionary containing the name and\nthe version of the dataset.\nIf you want to provide extra information, you can return a dictionary from the `load_XXX` methods, e.g.:\n\n```python\ndef load_pytorch(self, path: pathlib.Path):\n    # Load a pytorch dataset:\n    dataset = ...\n\n    return dataset, {\"classes\": [\"foo\", \"bar\"]}\n```\n\n* The `deel.datasets.utils` package contains utility functions to load `numpy`, `pytorch`\nand `tensorflow` image dataset in a consistent way.\n\n* The `Dataset` class contains some utiity methods to generate the information dictionary\nfrom the return of these methods.\n\nHere is a very simple example for loading a dataset:\n\n```python\ndef load_pytorch(self, path: pathlib.Path, image_size: Tuple[int, int]):\n    # Use relative import only if you are inside the deel package:\n    from ..utils import load_pytorch_image_dataset\n\n    # Load the dataset using the utility function:\n    dataset, idx_to_class = load_pytorch_image_dataset(\n        self.load_path(path),  # This is require only if `load_path` modifies the path.\n        image_size=image_size,\n        train_split=.7,\n    )\n\n    # The `_make_class_info` is provided by `Dataset`:\n    return dataset, self._make_class_info(idx_to_class)\n```\n\n#### Packaging the dataset(s)\n\nTo be found by the dataset manager, the `ExampleDataset` class must be put in\na package with a specific `entrypoint` (defined in `setup.py`).\n\nThe entry point provides to the plugin to be discovered and used by DEEL dataset\nmanager project.\nThe name of the DEEL dataset manager entry point is unique:\n`plugins.deel.dataset`.\nIt is possible to define many aliases for the same plugin by adding multiple\n`alias = package:plugin class` entries in entry points list.\n\n```python\n# Assuming `ExampleDataset` is in `my_dataset/__init__.py`:\nfrom setuptools import setup\n\nsetup(\n    # Other `setup` arguments:\n    ...\n\n    # Entry points:\n    entry_points={\n        \"plugins.deel.dataset\": [\n            \"example = my_dataset:ExampleDataset\",\n            \"my_dataset.example = my_dataset:ExampleDataset\"\n        ]\n    }\n)\n```\n\nA single plugin can expose multiple datasets through different entry points.\n\n## License\n\nCopyright IRT Antoine de Saint Exupéry et Université Paul Sabatier Toulouse III - All\nrights reserved. DEEL is a research program operated by IVADO, IRT Saint Exupéry, CRIAQ\nand ANITI - https://www.deel.ai/\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this\nsoftware and associated documentation files (the \"Software\"), to deal in the Software\nwithout restriction, including without limitation the rights to use, copy, modify,\nmerge, publish, distribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to the following\nconditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or\nsubstantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,\nINCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR\nPURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\nLIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT\nOR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\nOTHER DEALINGS IN THE SOFTWARE.\n\n## Acknowledgments\n\nThis project received funding from the French \"Investing for the Future – PIA3\" program\nwithin the Artiﬁcial and Natural Intelligence Toulouse Institute (ANITI). The authors\ngratefully acknowledge the support of the [DEEL project](https://www.deel.ai/).\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/deel-ai/deel_dataset_manager",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "deel-datasets",
    "package_url": "https://pypi.org/project/deel-datasets/",
    "platform": null,
    "project_url": "https://pypi.org/project/deel-datasets/",
    "project_urls": {
      "Homepage": "https://github.com/deel-ai/deel_dataset_manager"
    },
    "release_url": "https://pypi.org/project/deel-datasets/0.0.7/",
    "requires_dist": [
      "webdavclient3 (==0.13)",
      "tqdm",
      "h5py",
      "pyyaml",
      "psutil",
      "numpy",
      "Pillow",
      "PyYAML",
      "black ; extra == 'dev'",
      "flake8 ; extra == 'dev'",
      "flake8-black ; extra == 'dev'",
      "mypy ; extra == 'dev'",
      "pytest ; extra == 'dev'",
      "numpy ; extra == 'dev'",
      "sphinx (==3.3.1) ; extra == 'docs'",
      "recommonmark ; extra == 'docs'",
      "sphinx-rtd-theme ; extra == 'docs'",
      "sphinx-markdown-builder ; extra == 'docs'",
      "sphinx-autodoc-typehints ; extra == 'docs'",
      "sphinxcontrib-katex ; extra == 'docs'",
      "ipython ; extra == 'docs'"
    ],
    "requires_python": "",
    "summary": "Dataset loader for DEEL datasets",
    "version": "0.0.7",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14353310,
  "releases": {
    "0.0.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d8be9a17af873f793f20dc7bb5b09dc316a0f4cadf0417e25b1a9d70a5464174",
          "md5": "173af5d2759e9c62ca5d8b46124625c5",
          "sha256": "1410d21f94254a3ee398532414c54bb73f584adb3a97599f9daba3b323b1de95"
        },
        "downloads": -1,
        "filename": "deel_datasets-0.0.6-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "173af5d2759e9c62ca5d8b46124625c5",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 38461,
        "upload_time": "2021-11-16T16:00:46",
        "upload_time_iso_8601": "2021-11-16T16:00:46.663611Z",
        "url": "https://files.pythonhosted.org/packages/d8/be/9a17af873f793f20dc7bb5b09dc316a0f4cadf0417e25b1a9d70a5464174/deel_datasets-0.0.6-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "813b37dcb120d601645f8596fc822aaf98ff640074ac9a3273e182207f3cd69d",
          "md5": "2f0f58adba18fc9db3cd7ae61db38e5b",
          "sha256": "c29ac0a1baffce59e8297d9270914410bfac3b65542d9d9006e60a880532fa11"
        },
        "downloads": -1,
        "filename": "deel-datasets-0.0.6.tar.gz",
        "has_sig": false,
        "md5_digest": "2f0f58adba18fc9db3cd7ae61db38e5b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 31277,
        "upload_time": "2021-11-16T16:00:48",
        "upload_time_iso_8601": "2021-11-16T16:00:48.084772Z",
        "url": "https://files.pythonhosted.org/packages/81/3b/37dcb120d601645f8596fc822aaf98ff640074ac9a3273e182207f3cd69d/deel-datasets-0.0.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1caf60ca7a8e1ff1df02ca12a3bed83f45f2b89792356124c44e692d8fe33064",
          "md5": "b7a9bb5b19077e04b0fb58c672edcad7",
          "sha256": "e8a220a6b56a2a25e1473b6f0dcfd0188e327dc67057ab4bc18fd2dd4d510c76"
        },
        "downloads": -1,
        "filename": "deel_datasets-0.0.7-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "b7a9bb5b19077e04b0fb58c672edcad7",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 58999,
        "upload_time": "2022-07-06T15:27:56",
        "upload_time_iso_8601": "2022-07-06T15:27:56.710934Z",
        "url": "https://files.pythonhosted.org/packages/1c/af/60ca7a8e1ff1df02ca12a3bed83f45f2b89792356124c44e692d8fe33064/deel_datasets-0.0.7-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cff1099d178010559c86e63e3ad996ff8d86eb9e2da68b69b577378fe93714f8",
          "md5": "a06fba4a7309c5a179d66bcab2d79a2e",
          "sha256": "550b4b7211e27722a1c5c650ebfca4ae22c7f773901f37376e78c4a1356b81b7"
        },
        "downloads": -1,
        "filename": "deel-datasets-0.0.7.tar.gz",
        "has_sig": false,
        "md5_digest": "a06fba4a7309c5a179d66bcab2d79a2e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 38804,
        "upload_time": "2022-07-06T15:27:58",
        "upload_time_iso_8601": "2022-07-06T15:27:58.875350Z",
        "url": "https://files.pythonhosted.org/packages/cf/f1/099d178010559c86e63e3ad996ff8d86eb9e2da68b69b577378fe93714f8/deel-datasets-0.0.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "1caf60ca7a8e1ff1df02ca12a3bed83f45f2b89792356124c44e692d8fe33064",
        "md5": "b7a9bb5b19077e04b0fb58c672edcad7",
        "sha256": "e8a220a6b56a2a25e1473b6f0dcfd0188e327dc67057ab4bc18fd2dd4d510c76"
      },
      "downloads": -1,
      "filename": "deel_datasets-0.0.7-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "b7a9bb5b19077e04b0fb58c672edcad7",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 58999,
      "upload_time": "2022-07-06T15:27:56",
      "upload_time_iso_8601": "2022-07-06T15:27:56.710934Z",
      "url": "https://files.pythonhosted.org/packages/1c/af/60ca7a8e1ff1df02ca12a3bed83f45f2b89792356124c44e692d8fe33064/deel_datasets-0.0.7-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "cff1099d178010559c86e63e3ad996ff8d86eb9e2da68b69b577378fe93714f8",
        "md5": "a06fba4a7309c5a179d66bcab2d79a2e",
        "sha256": "550b4b7211e27722a1c5c650ebfca4ae22c7f773901f37376e78c4a1356b81b7"
      },
      "downloads": -1,
      "filename": "deel-datasets-0.0.7.tar.gz",
      "has_sig": false,
      "md5_digest": "a06fba4a7309c5a179d66bcab2d79a2e",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 38804,
      "upload_time": "2022-07-06T15:27:58",
      "upload_time_iso_8601": "2022-07-06T15:27:58.875350Z",
      "url": "https://files.pythonhosted.org/packages/cf/f1/099d178010559c86e63e3ad996ff8d86eb9e2da68b69b577378fe93714f8/deel-datasets-0.0.7.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}