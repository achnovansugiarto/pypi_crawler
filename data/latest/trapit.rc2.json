{
  "info": {
    "author": "Brendan Furey",
    "author_email": "brenpatf@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "<img src=\"https://github.com/BrenPatF/trapit_python_tester/raw/master/png/mountains.png\">\n\n> The Math Function Unit Testing design pattern, implemented in Python\n\nThis module supports a new design pattern for unit testing that can be applied in any language, and is here implemented in Python. The module name is derived from 'TRansactional API Testing' (TRAPIT), and the 'unit' should be considered to be a transactional unit (this is not micro-testing).\n\nThe module supplies a simple utility for unit testing Python programs based on the 'Math Function Unit Testing design pattern'. The utility provides a generic driver program for unit testing, with test data read from an input JSON file, results written to an output JSON file, and all specific test code contained in a callback function passed to the generic driver function. A separate JavaScript module is used to parse the results JSON and format them in HTML and plain text.\n\nThere is a blog post on scenario selection in unit testing that may be of interest:\n\n- [Unit Testing, Scenarios and Categories: The SCAN Method](https://brenpatf.github.io/jekyll/update/2021/10/17/unit-testing-scenarios-and-categories-the-scan-method.html)\n\n<a id=\"in-this-readme\"></a>\n# In This README...\n[&darr; Background](#background)<br />\n[&darr; Usage](#usage)<br />\n[&darr; API](#api)<br />\n[&darr; Installation](#installation)<br />\n[&darr; Unit Testing](#unit-testing)<br />\n[&darr; See Also](#see-also)<br />\n[&darr; License](#license)<br />\n\n<a id=\"background\"></a>\n## Background\n[&uarr; In This README...](#in-this-readme)<br />\n\nOn March 23, 2018 I made the following presentation at the Oracle User Group conference in Dublin:\n\n[Database API Viewed As A Mathematical Function: Insights into Testing](https://www.slideshare.net/brendanfurey7/database-api-viewed-as-a-mathematical-function-insights-into-testing)\n\nThe first section was summarised as:\n<blockquote>Developing a universal design pattern for testing APIs using the concept of a 'pure' function as a wrapper to manage the 'impurity' inherent in database APIs</blockquote>\n\nAlthough the presentation focussed on database testing the design pattern is clearly quite general.\n\nThe main features of the design pattern are:\n\n- The unit under test is viewed from the perspective of a mathematical function having an `extended signature`, comprising any actual parameters and return value, together with other inputs and outputs of any kind\n- A wrapper function is constructed based on this conceptual function, and the wrapper function is `externally pure`, while internally handling impurities such as file I/O\n- The wrapper function performs the steps necessary to test the UUT in a single scenario\n- It takes all inputs of the extended signature as a parameter, creates any test data needed from them, effects a transaction with the UUT, and returns all outputs as a return value\n- Any test data, and any data changes made by the UUT, are reverted before return\n- The wrapper function specific to the UUT is called within a loop over scenarios by a library test driver module\n- The library test driver module reads data for all scenarios in JSON format, with both inputs to the UUT and the expected outputs, and metadata records describing the specific data structure\n- The module takes the actual outputs from the wrapper function and merges them in alongside the expected outputs to create an output results object\n- This output results object is processed by a JavaScript module to generate the results formatted as a summary page, with a detail page for each scenario, in both HTML and text versions\n\nAt a high level the design pattern:\n\n- takes an input file containing all test scenarios with input data and expected output data for each scenario\n- creates a results object based on the input file, but with actual outputs merged in\n- uses the results object to generate unit test results files formatted in HTML and/or text\n\n<img src=\"https://github.com/BrenPatF/trapit_python_tester/raw/master/png/Math_Function_UT_DP_-_HL_Flow.png\">\n<br />\n\nThe Math Function Unit Testing design pattern is centred around the idea of a `pure` wrapper function that maps from `extended` input parameters to an `extended`  return value, with both sides using a generic nested object structure.\n\n<img src=\"https://github.com/BrenPatF/trapit_python_tester/raw/master/png/Math_Function_UT_DP_-_Mapping.png\">\n<br />\n\nHere is a diagram illustrating the concept of the `externally pure` wrapper function:\n<br /><br />\n<img src=\"https://github.com/BrenPatF/trapit_python_tester/raw/master/png/Math_Function_UT_DP_-_Wrapper.png\">\n<br /><br />\nThe JavaScript Trapit module supports the full process for testing JavaScript programs, and, for non-JavaScript programs, performs the formatting step by reading in the results object from a JSON file materialized by the external program. \n\nThe current Python project illustrates how this works in unit testing external programs, and there are also examples using Oracle and Powershell.\n<br /><br />\nAdvantages of the design pattern include:\n\n- Writing the unit test wrapper function is the only programming required for the specific unit test, with unit test driver, assertion and formatting all centralized in library packages\n- Once the unit test wrapper function is written for one scenario, no further programming is required to handle additional scenarios, facilitating good scenario coverage\n- The formatted results show exactly what the program does in terms of data inputs and outputs\n- All unit test programs can follow a single, straightforward pattern with minimal programming\n- The JavaScript Trapit module can be used to process results files generated from any language as JSON files, as in the current Python project\n\n<a id=\"usage\"></a>\n## Usage\n[&uarr; In This README...](#in-this-readme)<br />\n[&darr; General Usage](#general-usage)<br />\n[&darr; Example 1 - colgroup](#example-1---colgroup)<br />\n[&darr; Example 2 - hello_world](#example-2---hello_world)<br />\n\nIn this section we show how to use the package for unit testing, first in general terms, then via two examples.\n\n<a id=\"general-usage\"></a>\n### General Usage\n[&uarr; Usage](#usage)<br />\n[&darr; Preliminary Steps](#preliminary-steps)<br />\n[&darr; Unit Testing Process (General)](#unit-testing-process-general)<br />\n[&darr; Unit Test Documentation](#unit-test-documentation)<br />\n\n<a id=\"preliminary-steps\"></a>\n#### Preliminary Steps\n[&uarr; General Usage](#general-usage)<br />\n\nIn order to use the design pattern for unit testing, the following preliminary steps are required: \n- Create a JSON file containing the input test data including expected return values in the required format. The input JSON file essentially consists of two objects: \n  - `meta`: inp and out objects each containing group objects with arrays of field names\n  - `scenarios`: scenario objects containing inp and out objects, with inp and out objects containing, for each group defined in meta, an array of input records and an array of expected output records, respectively, records being in delimited fields format\n- Create a unit test script containing the wrapper function and a 1-line main section calling the Trapit library function, passing in the wrapper as a callback function. The wrapper function should call the unit under test passing the appropriate parameters and return its outputs, with the following signature:\n\n  - Input parameter: 3-level list with test inputs as an object with groups as properties having 2-level arrays of record/field as values: {GROUP: [[String]], ...}\n                        \n  - Return Value:    2-level list with test outputs as an object with groups as properties having an array of records as delimited fields strings as value: {GROUP: [String], ...}\n\nThis wrapper function may need to write inputs to, and read outputs from, files or tables, but should be `externally pure` in the sense that any changes made are rolled back before returning, including any made by the unit under test, and should be `essentially` deterministic.\n\nThe diagram shows the flows between input and output files:\n\n- Input JSON file (yellow)\n- Output JSON file (yellow)\n- Formatted unit test reports (blue)\n\nand the four code components, where the design pattern centralizes as much code as possible in the library packages:\n\n- JavaScript Trapit library package for formatting results (dark green)\n- External (Python) library package for unit testing (light green)\n- Specific (Python) test package (tan)\n- Unit under test (Python) (rose)\n\n<img src=\"https://github.com/BrenPatF/trapit_python_tester/raw/master/png/Math_Function_UT_DP_-_External.png\">\n\n#### Unit Testing Process (General)\n[&uarr; General Usage](#general-usage)<br />\n\nOnce the preliminary steps are executed, the script (testuut.py, say) can be executed as follows:\n\n```py\n$ py [path]/testuut.py\n```\n\nThe output results files are processed by a JavaScript program that has to be installed separately, as described in the [Installation](#installation) section. The JavaScript program produces listings of the results in HTML and/or text format in a subfolder named from the unit test title. \n\nTo run the processor, go to the npm trapit package folder after placing the output JSON files, trapit_py_out.json, in a new (or existing) folder, python, within the subfolder externals and run:\n\n```\n$ node externals/format-externals python\n```\n\nThis outputs to screen the following summary level report (for both examples described below), as well as writing the formatted results files to the subfolders indicated:\n```\nUnit Test Results Summary for Folder ./externals/python\n=======================================================\n File                 Title        Inp Groups  Out Groups  Tests  Fails  Folder     \n--------------------  -----------  ----------  ----------  -----  -----  -----------\n*colgroup_out.json    Col Group             3           4      5      1  col-group  \n helloworld_out.json  Hello World           0           1      1      0  hello-world\n\n1 externals failed, see ./externals/python for scenario listings\ncolgroup_out.json\n```\n\nThe running of the python unit test, and its Javascript formatting can easily be automated, as in the following Powershell script in the examples folder:\n```ps\n$ ./Run-Examples.ps1\n```\nThis example script runs both example unit tests and then the Javascript formatter, assuming a hard-coded npm root folder, and writes the summary to a file python.log.\n\n<a id=\"unit-test-documentation\"></a>\n#### Unit Test Documentation\n[&uarr; General Usage](#general-usage)<br />\n\nIn documenting our unit testing it may be helpful to divide into four sections: The unit testing process; wrapper function design and code; scenario category analysis; unit test results. The heading structure might look as follows:\n\n- Unit Testing Process\n- Unit Test Wrapper Function\n  - Wrapper Function Signature Diagram\n  - Input JSON File\n  - Wrapper Function Code\n- Scenario Category ANalysis (SCAN)\n  - Simple Category Sets\n  - Composite Category Sets\n  - Scenario Category Mapping\n- Unit Test Results\n  - Results Summary\n  - Unit Test Report: Title\n\n<a id=\"example-1---colgroup\"></a>\n### Example 1 - colgroup\n[&uarr; Usage](#usage)<br />\n[&darr; Unit Testing Process - colgroup](#unit-testing-process---colgroup)<br />\n[&darr; Unit Test Wrapper Function - colgroup](#unit-test-wrapper-function---colgroup)<br />\n[&darr; Scenario Category ANalysis (SCAN) - colgroup](#scenario-category-analysis-scan---colgroup)<br />\n[&darr; Unit Test Results - colgroup](#unit-test-results---colgroup)<br />\n\nThis example is a python class with a constructor function that reads in a CSV file and counts instances of distinct values in a given column. The constructor function appends a timestamp and call details to a log file. The class has methods to list the value/count pairs in several orderings. \n\nThere is a main script that shows how the class might be called outside of unit testing, run from the module root folder:\n```py\n$ py examples/colgroup/maincolgroup.py\n```\nwith output to console:\n```\nCounts sorted by (as is)\n========================\nTeam         #apps\n-----------  -----\nteam_name_2      1\nteam_name_1      1\nWest Brom     1219\nSwansea       1180\nBlackburn       33\nBolton          37\nChelsea       1147\nArsenal        534\nEverton       1147\nTottenham     1288\nFulham        1209\nQPR           1517\nLiverpool     1227\nSunderland    1162\nMan City      1099\nMan Utd       1231\nNewcastle     1247\nStoke City    1170\nWolves          31\nAston Villa    685\nWigan         1036\nNorwich       1229\nWest Ham      1126\nReading       1167\n...\n```\nand to log file, fantasy_premier_league_player_stats.csv.log:\n```\nSun Sep 23 2018 13:29:07: File ./examples/colgroup/fantasy_premier_league_player_stats.csv, delimiter ',', column 6\n```\n\nThe example illustrates how a wrapper function can handle `impure` features of the unit under test:\n- Reading input from file\n- Writing output to file\n\n...and also how the JSON input file can allow for nondeterministic outputs giving rise to deterministic test outcomes:\n- By using regex matching for strings including timestamps\n- By using number range matching and converting timestamps to epochal offsets (number of units of time since a fixed time)\n\n<a id=\"unit-testing-process---colgroup\"></a>\n#### Unit Testing Process - colgroup\n[&uarr; Example 1 - colgroup](#example-1---colgroup)<br />\n\nTo run the unit test program from the module root folder:\n\n```py\n$ py examples/colgroup/testcolgroup.py\n```\n\nThe output result file is processed by a JavaScript program as explained in the `General Usage` section above. It outputs to screen a summary level report (for both examples), as well as writing the listings of the results in HTML and/or text format in a subfolder named from the unit test title, as specified in the input JSON file.\n\nThe section `Unit Testing Process (General)`, above, shows how to combine the running of the python script and the JavaScript formatter in a single powershell script.\n\n<a id=\"unit-test-wrapper-function---colgroup\"></a>\n#### Unit Test Wrapper Function - colgroup\n[&uarr; Example 1 - colgroup](#example-1---colgroup)<br />\n[&darr; WF Signature Diagram - colgroup](#wf-signature-diagram---colgroup)<br />\n[&darr; Input JSON File - colgroup](#input-json-file---colgroup)<br />\n[&darr; Wrapper Function Code - colgroup](#wrapper-function-code---colgroup)<br />\n\n<a id=\"wf-signature-diagram---colgroup\"></a>\n##### WF Signature Diagram - colgroup\n[&uarr; Unit Test Wrapper Function - colgroup](#unit-test-wrapper-function---colgroup)<br />\n\nThe JSON input file contains `meta` and `scenarios` properties, as mentioned above, with structure reflecting the (extended) inputs and outputs of the unit under test. I like to make a diagram of the input and output groups, which for this example is:\n\n<img src=\"https://github.com/BrenPatF/trapit_python_tester/raw/master/png/Math_Function_UT_DP_-_JSD-CG.png\">\n\n<a id=\"input-json-file---colgroup\"></a>\n##### Input JSON File - colgroup\n[&uarr; Unit Test Wrapper Function - colgroup](#unit-test-wrapper-function---colgroup)<br />\n\nAn easy way to generate a starting point for the input JSON file is to use a powershell utility [Powershell Utilites module](https://github.com/BrenPatF/powershell_utils) to generate a template file with a single scenario with placeholder records from simple CSV files. The CSV files, `colgroup_inp.csv`, containing input group, field pairs, and the second, `colgroup_out.csv`, the same for output for the JSON structure diagram above would look like this:\n\n<img src=\"https://github.com/BrenPatF/trapit_python_tester/raw/master/png/Input_CSV_Files_colGroup.png\">\n\nThe powershell utility can be run from a powershell window like this:\n\n```powershell\nImport-Module TrapitUtils\nWrite-UT_Template 'colgroup' '|'\n```\n\nThis generates a JSON template file, colgroup_temp.json.\n\nThe template is then updated with test data for 5 scenarios (showing just the first one here):\n\n```json\n{ \"meta\": {\n    \"title\": \"Col Group\",\n    \"inp\": {\n        \"Log\": [\n            \"Line\"\n        ],\n        \"Scalars\": [\n            \"Delimiter\",\n            \"Column#\"\n        ],\n        \"Lines\": [\n            \"Line\"\n        ]\n    },\n    \"out\": {\n        \"Log\": [\n            \"#Lines\",\n            \"Date Offset\",\n            \"Text\"\n        ],\n        \"listAsIs\": [\n            \"#Instances\"\n        ],\n        \"sortByKey\": [\n            \"Key\",\n            \"Value\"\n        ],\n        \"sortByValue\": [\n            \"Key\",\n            \"Value\"\n        ]\n    }\n},\n\"scenarios\" : { \n   \"Col 1/3; 2 duplicate lines; double-delimiter; 1-line log\": \n   {\n    \"active_yn\" : \"Y\",\n    \"inp\": {\n       \"Log\": [\n       ],\n       \"Scalars\": [\n            \",|2\"\n        ],\n        \"Lines\": [\n            \"0,1,Cc,3\",\n            \"00,1,A,9\",\n            \"000,1,B,27\",\n            \"0000,1,A,81\"\n        ]\n    },\n    \"out\": {\n        \"Log\": [\n            \"1|IN [0, 2000]|LIKE /.*: File ./examples/colgroup/ut_group.csv, delimiter ',', column 2/\"\n        ],\n        \"listAsIs\": [\n            \"3\"\n        ],\n        \"sortByKey\": [\n            \"A|2\",\n            \"Bx|1\",\n            \"Cc|1\"\n        ],\n        \"sortByValue\": [\n            \"B|1\",\n            \"Cc|1\",\n            \"A|2\"\n        ]\n    }\n},\n...3 more scenarios\n}}\n```\n\nNotice the syntax for the expected values for the second and third fields in the 3-field output record for the log group. This specifies matching against a numeric range and a regular expression, respectively, as follows:\n\n- Date Offset: \"IN [0, 2000]\" - the datetime offset in microseconds must be between 0 and 2000 microseconds from the datetime at the start of execution\n- Text: \"LIKE /.\\*: File ./examples/colgroup/ut_group.csv, delimiter ',', column 2/\" - the line of text written must match the regular expression betwen the '/' delimiters, allowing us to ignore the precise timestamp for testing purposes, but still to display it for information\n\n\n<a id=\"wrapper-function-code---colgroup\"></a>\n##### Wrapper Function Code - colgroup\n[&uarr; Unit Test Wrapper Function - colgroup](#unit-test-wrapper-function---colgroup)<br />\n\nThe text box below shows the entire specific unit test code for this example (short isn't it? &#128513;) containing the pure wrapper function, purely_wrap_unit, and the one line main section calling the library function, trapit.test_unit.\n\n```py\nimport sys, os\nfrom datetime import datetime\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))\nimport trapit, colgroup as cg\n\nROOT = os.path.dirname(__file__) + '/'\nDELIM = '|'\nINPUT_JSON,             OUTPUT_JSON,                INPUT_FILE,            LOG_FILE                  = \\\nROOT + 'colgroup.json', ROOT + 'colgroup_out.json', ROOT + 'ut_group.csv', ROOT + 'ut_group.csv.log'\nGRP_LOG,   GRP_SCA,   GRP_LIN, GRP_LAI,    GRP_SBK,     GRP_SBV       = \\\n'Log',     'Scalars', 'Lines', 'listAsIs', 'sortByKey', 'sortByValue'\n\ndef from_CSV(csv, col):\n    return csv.split(DELIM)[col]\ndef join_tuple(t):\n    return t[0] + DELIM + str(t[1])\ndef setup(inp):\n    with open(INPUT_FILE, 'w') as infile:\n        infile.write('\\n'.join(inp[GRP_LIN]))\n    if (len(inp[GRP_LOG]) > 0):\n        with open(LOG_FILE, 'w') as logfile:\n            logfile.write('\\n'.join(inp[GRP_LOG]) + '\\n')\n    return cg.ColGroup(INPUT_FILE, from_CSV(inp[GRP_SCA][0], 0), from_CSV(inp[GRP_SCA][0], 1))\ndef teardown():\n    os.remove(INPUT_FILE)\n    os.remove(LOG_FILE)\n\ndef purely_wrap_unit(inp_groups):\n    col_group   = setup(inp_groups)\n    with open(LOG_FILE, 'r') as logfile:\n        logstr = logfile.read()\n    lines_array = logstr.split('\\n')\n    lastLine   = lines_array[len(lines_array) - 2]\n    text       = lastLine\n    date       = lastLine[0:19]\n    logDate    = datetime.strptime(date, '%Y-%m-%d %H:%M:%S')\n    now        = datetime.now()\n    diffDate   = (now - logDate).microseconds / 1000\n\n    teardown()\n    return {\n        GRP_LOG : [str((len(lines_array) - 1)) + DELIM + str(diffDate) + DELIM + text],\n        GRP_LAI : [str(len(col_group.list_as_is()))],\n        GRP_SBK : list(map(join_tuple, col_group.sort_by_key())),\n        GRP_SBV : list(map(join_tuple, col_group.sort_by_value_lambda()))\n    }\ntrapit.test_unit(INPUT_JSON, OUTPUT_JSON, purely_wrap_unit)\n```\n\n#### Scenario Category ANalysis (SCAN) - colgroup\n[&uarr; Example 1 - colgroup](#example-1---colgroup)<br />\n[&darr; Simple Category Sets - colgroup](#simple-category-sets---colgroup)<br />\n[&darr; Composite Category Sets - colgroup](#composite-category-sets---colgroup)<br />\n[&darr; Scenario Category Mapping - colgroup](#scenario-category-mapping---colgroup)<br />\n\nThis article, [Unit Testing, Scenarios and Categories: The SCAN Method](https://brenpatf.github.io/jekyll/update/2021/10/17/unit-testing-scenarios-and-categories-the-scan-method.html), explains how to derive unit test scenarios using a new approach called the SCAN method.\n\nFollowing the method, in this section we identify the category sets for the problem, and tabulate the corresponding categories. We need to consider which category sets can be tested independently of each other, and which need to be considered in combination. We can then obtain a set of scenarios to cover all relevant combinations of categories.\n\n<a id=\"simple-category-sets---colgroup\"></a>\n##### Simple Category Sets - colgroup\n[&uarr; Scenario Category ANalysis (SCAN) - colgroup](#scenario-category-analysis-scan---colgroup)<br />\n\n###### MUL-LIN - Multiplicity of lines\n\nCheck works correctly with 0, 1 and multiple lines.\n\n| Code | Description |\n|:----:|:------------|\n|   0  | None        |\n|   1  | One         |\n|   m  | Multiple    |\n\n###### POS-KEY - Position of key column\n\nCheck works correctly when the key column is first, last or in the middle.\n\n| Code | Description |\n|:----:|:------------|\n|   F  | First       |\n|   L  | Last        |\n|   M  | Middle      |\n\n###### MUL-KEY - Multiplicity of key instances\n\nCheck works correctly with 1 and multiple key instances.\n\n| Code | Description |\n|:----:|:------------|\n|   1  | One         |\n|   m  | Multiple    |\n\n###### MUL-COL - Multiplicity of file columns\n\nCheck works correctly with 1 and multiple columns in file.\n\n| Code | Description |\n|:----:|:------------|\n|   1  | One         |\n|   m  | Multiple    |\n\n###### MUL-DEL - Multiplicity of delimiter character\n\nCheck works correctly with 1 and multiple delimiter character.\n\n| Code | Description |\n|:----:|:------------|\n|   1  | One         |\n|   m  | Multiple    |\n\n###### SIZ - Size of key\n\nCheck works correctly with short and long key values.\n\n| Code | Description |\n|:----:|:------------|\n|   S  | Short       |\n|   L  | Long        |\n\n###### LOG  - Log file existence\n\nCheck works correctly when there is already a log file and when there isn't.\n\n| Code | Description                              |\n|:----:|:-----------------------------------------|\n|   N  | No - file does not exist at time of call |\n|   Y  | No - file exists at time of call         |\n\n###### ORD-SAM  - Ordering same by key and by value?\n\nCheck ordering methods work when order of output records same by key and value and when differs.\n\n| Code | Description                              |\n|:----:|:-----------------------------------------|\n|   N  | Order by key differs from order by value |\n|   Y  | Order by key same as order by value      |\n\n<a id=\"composite-category-sets---colgroup\"></a>\n##### Composite Category Sets - colgroup\n[&uarr; Scenario Category ANalysis (SCAN) - colgroup](#scenario-category-analysis-scan---colgroup)<br />\n\nIn this section we need to consider which simple category sets need to be considered in combination with others. In fact, in this case, all the category sets other than `Multiplicity of lines` are independent of each other, and have a very simple dependence on `Multiplicity of lines`: There has to be at least one line in the file to test the other category sets, and multiple lines to test a couple of them. \n\nAs `Position of key column` has three categories, we can test these with multiple lines, as well as testing the zero-lines edge case and the 1-line case. The possible combinations of these two category sets can then be the basis for our scenarios, and we can just enumerate the other categories within them.\n\n###### MUL-LK - Multiplicity of lines and key instances\n\nCheck works correctly with 0, 1 and multiple lines, and for multiple lines all three categories of `Position of key column`.\n\n| MUL-LIN | POS-KEY | Description                         |\n|:-------:|:-------:|:------------------------------------|\n|    0    |    -    | Lines: None; Key column: NA         |\n|    1    |    F    | Lines: 1; Key column: First         |\n|    m    |    F    | Lines: Multiple; Key column: First  |\n|    m    |    L    | Lines: Multiple; Key column: Last   |\n|    m    |    M    | Lines: Multiple; Key column: Middle |\n\n<a id=\"scenario-category-mapping---colgroup\"></a>\n##### Scenario Category Mapping - colgroup\n[&uarr; Scenario Category ANalysis (SCAN) - colgroup](#scenario-category-analysis-scan---colgroup)<br />\n\nWe now want to construct a set of scenarios based on the category sets identified, covering each individual category, and also covering combinations of categories that may interact. As discussed in the previous section, the possible combinations of the first two category sets form the basis for the category-level scenario set, with the remaining category sets enumerated in the additional columns.\n\n| # | MUL-LIN | POS-KEY | MUL-KEY | MUL-COL | MUL-DEL | SIZ | LOG | ORD-SAM | Description                         |\n|:--|:-------:|:-------:|:-------:|:-------:|:-------:|:---:|:---:|:-------:|:------------------------------------|\n| 1 |    0    |    -    |    -    |    -    |    -    |  -  |  -  |    -    | Lines: None; Key column: NA         |\n| 2 |    1    |    F    |    1    |    1    |    1    |  S  |  N  |    -    | Lines: 1; Key column: First         |\n| 3 |    m    |    F    |    m    |    m    |    m    |  L  |  Y  |    N    | Lines: Multiple; Key column: First  |\n| 4 |    m    |    L    |    m    |    m    |    m    |  L  |  Y  |    Y    | Lines: Multiple; Key column: Last   |\n| 5 |    m    |    M    |    m    |    m    |    m    |  L  |  Y  |    N    | Lines: Multiple; Key column: Middle |\n  \n<a id=\"unit-test-results---colgroup\"></a>\n#### Unit Test Results - colgroup\n[&uarr; Example 1 - colgroup](#example-1---colgroup)<br />\n[&darr; Results Summary - colgroup](#results-summary---colgroup)<br />\n[&darr; Unit Test Report: Col Group](#unit-test-report-col-group)<br />\n\n<a id=\"results-summary---colgroup\"></a>\n##### Results Summary - colgroup\n[&uarr; Unit Test Results - colgroup](#unit-test-results---colgroup)<br />\n\nThe results summary from the JavaScript test formatter was (for both examples):\n```\nUnit Test Results Summary for Folder ./externals/python\n=======================================================\n File                 Title        Inp Groups  Out Groups  Tests  Fails  Folder     \n--------------------  -----------  ----------  ----------  -----  -----  -----------\n*colgroup_out.json    Col Group             3           4      5      1  col-group  \n helloworld_out.json  Hello World           0           1      1      0  hello-world\n\n1 externals failed, see ./externals/python for scenario listings\ncolgroup_out.json\n```\n\nYou can review the HTML formatted unit test results for the program here:\n\n- [Unit Test Report: Col Group](http://htmlpreview.github.io/?https://github.com/BrenPatF/trapit_python_tester/blob/master/examples/colgroup/col-group/col-group.html)\n\nThe formatted results files, both text and HTML, are available in the `col-group` subfolder. The summary report showing scenarios tested, in text format, along with the detailed report for scenario 5, are copied below:\n\n<a id=\"unit-test-report-col-group\"></a>\n##### Unit Test Report: Col Group\n[&uarr; Unit Test Results - colgroup](#unit-test-results---colgroup)<br />\n```\nUnit Test Report: Col Group\n===========================\n\n      #    Scenario                             Fails (of 4)  Status \n      ---  -----------------------------------  ------------  -------\n      1    Lines: None; Key column: NA          0             SUCCESS\n      2    Lines: 1; Key column: First          0             SUCCESS\n      3    Lines: Multiple; Key column: First   0             SUCCESS\n      4    Lines: Multiple; Key column: Last    0             SUCCESS\n      5*   Lines: Multiple; Key column: Middle  1             FAILURE\n\nTest scenarios: 1 failed of 5: FAILURE\n======================================\n```\nNote the record #5 above marked with a '\\*' indicating failure status. The detailed report for the fifth scenario, in text format, is copied below:\n```\nSCENARIO 5: Lines: Multiple; Key column: Middle {\n=================================================\n   INPUTS\n   ======\n      GROUP 1: Log {\n      ==============\n            #  Line      \n            -  ----------\n            1  Log line 1\n      }\n      =\n      GROUP 2: Scalars {\n      ==================\n            #  Delimiter  Column#\n            -  ---------  -------\n            1  ;;         5      \n      }\n      =\n      GROUP 3: Lines {\n      ================\n            #  Line                                                                         \n            -  -----------------------------------------------------------------------------\n            1  0;;1;;2;;3;;4;;12345678901234567890123456789012345678901234567890;;5;;6;;7;;8\n            2  0;;1;;2;;3;;4;;abc;;5;;6;;7;;8                                               \n            3  0;;1;;2;;3;;4;;12345678901234567890123456789012345678901234567890;;5;;6;;7;;8\n      }\n      =\n   OUTPUTS\n   =======\n      GROUP 1: Log {\n      ==============\n            #  #Lines  Date Offset           Text                                                                                                                                                                                                           \n            -  ------  --------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n            1  2       IN [0,2000]: 480.149  LIKE /.*: File .*examples-colgroup-ut_group.csv, delimiter ';;', column 5/: 2021-11-20 16:14:04: File C:-Users-Brend-OneDrive-Script-pip-trapit-trapit-examples-colgroup-ut_group.csv, delimiter ';;', column 5\n      } 0 failed of 1: SUCCESS\n      ========================\n      GROUP 2: listAsIs {\n      ===================\n            #   #Instances\n            --  ----------\n            1   3         \n            1*  2         \n      } 1 failed of 1: FAILURE\n      ========================\n      GROUP 3: sortByKey {\n      ====================\n            #  Key                                                 Value\n            -  --------------------------------------------------  -----\n            1  12345678901234567890123456789012345678901234567890  2    \n            2  abc                                                 1    \n      } 0 failed of 2: SUCCESS\n      ========================\n      GROUP 4: sortByValue {\n      ======================\n            #  Key                                                 Value\n            -  --------------------------------------------------  -----\n            1  abc                                                 1    \n            2  12345678901234567890123456789012345678901234567890  2    \n      } 0 failed of 2: SUCCESS\n      ========================\n} 1 failed of 4: FAILURE\n========================\n```\n\nNote the record #1 above marked with a '\\*' in 'GROUP 2: listAsIs', indicating a mismatch between expected and actual values. This is a deliberate error to illustrate the format when mismatches occur. Where the actual value differs from expected the actual record is listed below the expected, with the '\\*' marker against the record number, and in the HTML report the record is coloured red. In fact the value '2' is correct and the expected value has been incorrectly set to '3'.\n\n<a id=\"example-2---hello_world\"></a>\n### Example 2 - hello_world\n[&uarr; Usage](#usage)<br />\n[&darr; Unit Testing Process - helloworld](#unit-testing-process---helloworld)<br />\n[&darr; Unit Test Wrapper Function - helloworld](#unit-test-wrapper-function---helloworld)<br />\n[&darr; Scenario Category ANalysis (SCAN) - helloworld](#scenario-category-analysis-scan---helloworld)<br />\n[&darr; Unit Test Results - helloworld](#unit-test-results---helloworld)<br />\n\n```py\ndef hello_world():\n    return 'Hello World!'\n```\nThis is a pure function form of Hello World program, returning a value rather than writing to screen itself. It is of course trivial, but has some interest as an edge case with no inputs and extremely simple JSON input structure and test code.\n\nThere is a main script that shows how the function might be called outside of unit testing, run from the module root folder:\n```py\n$ py examples/helloworld/mainhelloworld.py\n```\nwith output to console:\n```\nHello World!\n```\n<a id=\"unit-testing-process---helloworld\"></a>\n#### Unit Testing Process - helloworld\n[&uarr; Example 2 - hello_world](#example-2---hello_world)<br />\n\nTo run the unit test program from the module root folder:\n\n```py\n$ py examples/helloworld/testhelloworld.py\n```\n\nThe output result file is processed by a JavaScript program as explained in the `General Usage` section above. It outputs to screen a summary level report (for both examples), as well as writing the listings of the results in HTML and/or text format in a subfolder named from the unit test title, as specified in the input JSON file.\n\nThe section `Unit Testing Process (General)`, above, shows how to combine the running of the python script and the JavaScript formatter in a single powershell script.\n\n<a id=\"unit-test-wrapper-function---helloworld\"></a>\n#### Unit Test Wrapper Function - helloworld\n[&uarr; Example 2 - hello_world](#example-2---hello_world)<br />\n[&darr; WF Signature Diagram - helloworld](#wf-signature-diagram---helloworld)<br />\n[&darr; Input JSON File - helloworld](#input-json-file---helloworld)<br />\n[&darr; Wrapper Function Code - helloworld](#wrapper-function-code---helloworld)<br />\n\n<a id=\"wf-signature-diagram---helloworld\"></a>\n##### WF Signature Diagram - helloworld\n[&uarr; Unit Test Wrapper Function - helloworld](#unit-test-wrapper-function---helloworld)<br />\n\nThe JSON structure diagram for this trivial example is:\n\n<img src=\"https://github.com/BrenPatF/trapit_python_tester/raw/master/png/Math_Function_UT_DP_-_JSD-HW.png\">\n\n<a id=\"input-json-file---helloworld\"></a>\n##### Input JSON File - helloworld\n[&uarr; Unit Test Wrapper Function - helloworld](#unit-test-wrapper-function---helloworld)<br />\n\nThe input JSON file, showing empty input property in the meta and scenarios objects, is:\n\n[&uarr; Input JSON File](#input-json-file-1)\n\n```json\n{ \"meta\": {\n    \"title\": \"Hello World\",\n    \"inp\": {},\n    \"out\": {\n        \"Group\": [\n            \"Greeting\"\n        ]\n    }\n},\n\"scenarios\" : { \n   \"Scenario\": \n   {\n    \"inp\": {},\n    \"out\": {\n        \"Group\": [\n            \"Hello World!\"\n        ]\n    }\n}\n}}\n```\n\n<a id=\"wrapper-function-code---helloworld\"></a>\n##### Wrapper Function Code - helloworld\n[&uarr; Unit Test Wrapper Function - helloworld](#unit-test-wrapper-function---helloworld)<br />\n\nThe text box below shows the entire specific unit test code for this example. In this trivial case, we can pass the pure wrapper function as a lambda expression.\n\n```py\nimport sys, os\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))\nimport trapit, helloworld\n\nROOT = os.path.dirname(__file__) + '/'\nINPUT_JSON = ROOT + 'helloworld.json'\nOUTPUT_JSON = ROOT + 'helloworld_out.json'\n\ntrapit.test_unit(INPUT_JSON, OUTPUT_JSON, lambda  inp_groups: {'Group': [helloworld.hello_world()]})\n```\n\n#### Scenario Category ANalysis (SCAN) - helloworld\n[&uarr; Example 2 - hello_world](#example-2---hello_world)<br />\n\nWith no input data, the set of input data category sets is of course empty ðŸ™‚.\n\n<a id=\"unit-test-results---helloworld\"></a>\n#### Unit Test Results - helloworld\n[&uarr; Example 2 - hello_world](#example-2---hello_world)<br />\n[&darr; Results Summary - helloworld](#results-summary---helloworld)<br />\n[&darr; Unit Test Report: Hello World](#unit-test-report-hello-world)<br />\n\n<a id=\"results-summary---helloworld\"></a>\n##### Results Summary - helloworld\n[&uarr; Unit Test Results - helloworld](#unit-test-results---helloworld)<br />\n\nThe results summary from the JavaScript test formatter was (for both examples):\n```\n\nUnit Test Results Summary for Folder ./externals/python\n=======================================================\n File                 Title        Inp Groups  Out Groups  Tests  Fails  Folder     \n--------------------  -----------  ----------  ----------  -----  -----  -----------\n*colgroup_out.json    Col Group             3           4      5      1  col-group  \n helloworld_out.json  Hello World           0           1      1      0  hello-world\n\n1 externals failed, see ./externals/python for scenario listings\ncolgroup_out.json\n```\n\nYou can review the HTML formatted unit test results for the program here:\n\n- [Unit Test Report: Hello World](http://htmlpreview.github.io/?https://github.com/BrenPatF/trapit_python_tester/blob/master/examples/helloworld/hello-world/hello-world.html)\n\nThe formatted results files, both text and HTML, are available in the `hello-world` subfolder. Here is the full set of results in text format:\n\n<a id=\"unit-test-report-hello-world\"></a>\n##### Unit Test Report: Hello World\n[&uarr; Unit Test Results - helloworld](#unit-test-results---helloworld)<br />\n\n```\nUnit Test Report: Hello World\n=============================\n      #    Scenario  Fails (of 1)  Status \n      ---  --------  ------------  -------\n      1    Scenario  0             SUCCESS\nTest scenarios: 0 failed of 1: SUCCESS\n======================================\nSCENARIO 1: Scenario {\n======================\n   INPUTS\n   ======\n   OUTPUTS\n   =======\n      GROUP 1: Group {\n      ================\n            #  Greeting    \n            -  ------------\n            1  Hello World!\n      } 0 failed of 1: SUCCESS\n      ========================\n} 0 failed of 1: SUCCESS\n========================\n```\n\n<a id=\"api\"></a>\n## API\n[&uarr; In This README...](#in-this-readme)<br />\n[&darr; trapit.test_unit(inp_file, out_file, purely_wrap_unit)](#trapittest_unitinp_file-out_file-purely_wrap_unit)<br />\n\n```py\nimport trapit\n```\n\n### trapit.test_unit(inp_file, out_file, purely_wrap_unit)\n[&uarr; API](#api)<br />\n\nThe unit test driver utility function is called as effectively the main function of any specific unit test script. It reads the input JSON scenarios file, then loops over the scenarios making calls to a function passed in as a parameter from the calling script. The function acts as a `pure` wrapper around calls to the unit under test. It is `externally pure` in the sense that it is deterministic, and interacts externally only via parameters and return value. Where the unit under test reads inputs from file the wrapper writes them based on its parameters, and where the unit under test writes outputs to file the wrapper reads them and passes them out in its return value. Any file writing is reverted before exit. \n\nIt has the following parameters:\n\n- `inp_file`: JSON input file name\n- `out_file`: JSON output file name\n- `purely_wrap_unit`: wrapper function, which calls the unit under test passing the appropriate parameters and returning its outputs, with the following signature:\n  - inp_groups: input groups object, a 3-level list with test inputs as an object with groups as properties having 2-level arrays of record/field as values: {GROUP: [[String]], ...}\n  - Return Value: output groups object, a 2-level list with test outputs as an object with groups as properties having an array of records as delimited fields strings as value: {GROUP: [String], ...}\n\n<a id=\"installation\"></a>\n## Installation\n[&uarr; In This README...](#in-this-readme)<br />\n[&darr; Python Installation - pip](#python-installation---pip)<br />\n[&darr; Javascript Installation - npm](#javascript-installation---npm)<br />\n\n<a id=\"python-installation---pip\"></a>\n### Python Installation - pip\n[&uarr; Installation](#installation)<br />\n\nWith [python](https://www.python.org/downloads/windows/) installed, run in a powershell or command window:\n\n```py\n$ py -m pip install trapit \n```\n\n<a id=\"javascript-installation---npm\"></a>\n### Javascript Installation - npm\n[&uarr; Installation](#installation)<br />\n\n- [Trapit JavaScript Tester/Formatter - GitHub module](https://github.com/BrenPatF/trapit_nodejs_tester)\n\nWith [npm](https://npmjs.org/) installed, run from your npm installation folder:\n\n```js\n$ npm install trapit \n```\n\n<a id=\"unit-testing\"></a>\n## Unit Testing\n[&uarr; In This README...](#in-this-readme)<br />\n[&darr; Unit Testing Process](#unit-testing-process)<br />\n[&darr; Wrapper Function](#wrapper-function)<br />\n[&darr; Scenario Category ANalysis (SCAN)](#scenario-category-analysis-scan)<br />\n[&darr; Unit Test Results](#unit-test-results)<br />\n\nIn this section the unit testing API function trapit.test_unit is itself tested using the Math Function Unit Testing design pattern.\n\n<a id=\"unit-testing-process\"></a>\n### Unit Testing Process\n[&uarr; Unit Testing](#unit-testing)<br />\n\nThe unit test utility can be used to test itself following the same 'Math Function Unit Testing design pattern' that it facilitates for testing of general programs. The challenge in this case is in determining a suitable signature and specification for the wrapper function that has to represent unit testing of any program.\n\nUnit testing is data-driven from the input file trapit_py.json and produces an output results file, trapit_py_out.json. This contains arrays of expected and actual records by group and scenario. \n\nTo run the unit test program from the module root folder:\n\n```py\n$ py unit_test/testtrapit.py\n```\n\nThe output result file is processed by a JavaScript program as explained in the `General Usage` section above. It outputs to screen a summary level report (including for both of the earlier examples), as well as writing the listings of the results in HTML and/or text format in a subfolder named from the unit test title, as specified in the input JSON file.\n\nTo run the processor, go to the npm trapit package folder after placing the output JSON files, trapit_py_out.json, in a new (or existing) folder, python, within the subfolder externals and run:\n\n```js\n$ node externals/format-externals python\n```\nThis outputs to screen the following summary level report, as well as writing the formatted results files to the subfolders indicated:\n```\nUnit Test Results Summary for Folder ./externals/python\n=======================================================\n File                 Title               Inp Groups  Out Groups  Tests  Fails  Folder            \n--------------------  ------------------  ----------  ----------  -----  -----  ------------------\n*colgroup_out.json    Col Group                    3           4      5      1  col-group         \n helloworld_out.json  Hello World                  0           1      1      0  hello-world       \n trapit_py_out.json   Python Unit Tester           7           6      3      0  python-unit-tester\n\n1 externals failed, see ./externals/python for scenario listings\ncolgroup_out.json\n```\n\nThe running of the python unit test, and its Javascript formatting can easily be automated, as in the following Powershell script in the unit_test folder:\n```ps\n$ ./Run-Ut.ps1\n```\nThis script runs the unit test and then the Javascript formatter, assuming a hard-coded npm root folder, and writes the summary to a file, python.log.\n\n<a id=\"wrapper-function\"></a>\n### Wrapper Function\n[&uarr; Unit Testing](#unit-testing)<br />\n[&darr; Wrapper Function Signature Diagram](#wrapper-function-signature-diagram)<br />\n[&darr; Input JSON File](#input-json-file)<br />\n[&darr; Wrapper Function Code](#wrapper-function-code)<br />\n\nThe signature of the unit under test is: \n\n    trapit.test_unit(inp_file, out_file, purely_wrap_unit)\n\nThe parameters are input and output file names, and a function. The `extended` inputs and outputs required for the wrapper function include the contents of the input and output files.\n\n<a id=\"wrapper-function-signature-diagram\"></a>\n#### Wrapper Function Signature Diagram\n[&uarr; Wrapper Function](#wrapper-function)<br />\n\n<img src=\"https://github.com/BrenPatF/trapit_python_tester/raw/master/png/JSD_Python_test_unit_Screen.png\">\n\nAs noted above, the inputs to the unit under test here include a function. This raises the interesting question as to how we can model a function in our test data. In fact the best way to do this seems to be to regard the function as a kind of black box, where we don't care about the interior of the function, but only its behaviour in terms of returning an output from an input. This is why we have the `Actual Values` group in the input side of the diagram above, as as well as on the output side. We can model any deterministic function in our test data simply by specifying input and output sets of values.\n\nAs we are using the trapit.test_unit API to test itself, we will have inner and outer levels for the calls and their parameters. The inner-level wrapper function passed in in the call to the unit under test by the outer-level wrapper function therefore needs simply to return the set of `Actual Values` records for the given scenario. In order for it to know which set to return, the scenarios need to be within readable scope, and we need to know which scenario to use. This is achieved by maintaining arrays containing a list of inner scenarios and a list of inner output groups, along with a nonlocal variable with an index to the current inner scenario that the inner wrapper increments each time it's called. This allows the output array to be extracted from the input parameter from the outer wrapper function.\n\n<a id=\"input-json-file\"></a>\n#### Input JSON File\n[&uarr; Wrapper Function](#wrapper-function)<br />\n\nAn easy way to generate a starting point for the input JSON file is to use a powershell utility [Powershell Utilites module](https://github.com/BrenPatF/powershell_utils) to generate a template file with a single scenario with placeholder records from simple CSV files (see the script test_unit.ps1 in the `test` subfolder). The CSV files, `test_unit_inp.csv`, containing input group, field pairs, and the second, `test_unit_out.csv`, the same for output for the JSON structure diagram above would look like this:\n\n<img src=\"https://github.com/BrenPatF/trapit_python_tester/raw/master/png/Input_CSV_Files_Trapit.png\">\n\nThe powershell utility can be run from a powershell window like this:\n\n```powershell\nImport-Module TrapitUtils\nWrite-UT_Template 'test_unit' '|'\n```\n\nThis generates a JSON template file, test_unit_temp.json. The template is then updated with test data for the four scenarios identified in the `Scenario Category Analysis` section.\n\n<a id=\"wrapper-function-code\"></a>\n#### Wrapper Function Code\n[&uarr; Wrapper Function](#wrapper-function)<br />\n[&darr; testtrapit.py](#testtrapitpy)<br />\n[&darr; purely_wrap_unit](#purely_wrap_unit)<br />\n[&darr; write_input_json](#write_input_json)<br />\n[&darr; get_actuals](#get_actuals)<br />\n[&darr; Small functions](#small-functions)<br />\n\nThe wrapper function has the structure shown in the diagram below, being defined in a driver script followed by a single line calling the test_unit API.\n\n<img src=\"https://github.com/BrenPatF/trapit_python_tester/raw/master/png/testtrapit_CSD.png\">\n\n<a id=\"testtrapitpy\"></a>\n##### testtrapit.py\n[&uarr; Wrapper Function Code](#wrapper-function-code)<br />\nThe text box below shows the code for the driving script, with the wrapper function def line as a placeholder for later expansion.\n```py\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))\nimport trapit\n\nROOT = os.path.dirname(__file__) + '\\\\'\nDELIM = '|'\n\nINP_JSON,                OUT_JSON,                    INP_JSON_INNER,                OUT_JSON_INNER                = \\\nROOT + 'trapit_py.json', ROOT + 'trapit_py_out.json', ROOT + 'trapit_py_inner.json', ROOT + 'trapit_py_out_inner.json'\n\nTITLE,   DELIMITER,   ACTIVE_YN,   UNIT_TEST,   META,   SCENARIOS,   INP,   OUT,   EXP,   ACT = \\\n'title', 'delimiter', 'active_yn', 'Unit Test', 'meta', 'scenarios', 'inp', 'out', 'exp', 'act'\n\nINP_FIELDS,     OUT_FIELDS,      INP_VALUES,     EXP_VALUES,        ACT_VALUES = \\\n'Input Fields', 'Output Fields', 'Input Values', 'Expected Values', 'Actual Values'\n\ndef purely_wrap_unit(inp_groups, # input groups object\n                     scenario):  # scenario key\n\ntrapit.test_unit(INP_JSON, OUT_JSON, purely_wrap_unit)\n```\n\n<a id=\"purely_wrap_unit\"></a>\n##### purely_wrap_unit\n[&uarr; Wrapper Function Code](#wrapper-function-code)<br />\nThis is the outer level unit test wrapper function, returning an object with the output group objects actual values from the unit under test for a single scenario. It defines several local functions, including an inner level wrapper function, purely_wrap_unit_inner (whose\nbodies are shown later).\n```py\ndef purely_wrap_unit(inp_groups): # input groups object\n\n    def groups_from_group_field_pairs(group_field_lis): # group/field pairs list\n\n    def groups_obj_from_gf_pairs(group_lis,        # groups list\n                                 group_field_lis): # group/field pairs list\n\n    def groups_obj_from_sgf_triples(sce,             # scenario\n                                    group_lis,       # groups list\n                                    sgf_triple_lis): # scenario/group/field triples list\n\n    def purely_wrap_unit_inner(inp_groups_inner) # input groups object (inner level)\n\n    def write_input_json():\n\n    def get_actuals():\n\n    out_group_lis, sce_inp_lis = write_input_json()\n    sce_inp_ind = 0\n    trapit.test_unit(INP_JSON_INNER, OUT_JSON_INNER, purely_wrap_unit_inner)\n    return get_actuals()\n```\n\n<a id=\"write_input_json\"></a>\n##### write_input_json\n[&uarr; Wrapper Function Code](#wrapper-function-code)<br />\nThis function writes out the inner level JSON file. It returns two objects: a list of (inner) output groups, and a list of (inner) scenarios; these are referenced in purely_wrap_unit_inner.\n```py\ndef write_input_json():\n    inp_group_field_lis = inp_groups[INP_FIELDS]\n    inp_group_lis = groups_from_group_field_pairs(inp_group_field_lis)\n    out_group_field_lis = inp_groups[OUT_FIELDS]\n    out_group_lis = groups_from_group_field_pairs(out_group_field_lis)\n    title, delimiter = inp_groups[UNIT_TEST][0].split(DELIM)\n\n    meta = {TITLE:     title,\n            DELIMITER: delimiter,\n            INP:       groups_obj_from_gf_pairs(inp_group_lis, inp_group_field_lis),\n            OUT:       groups_obj_from_gf_pairs(out_group_lis, out_group_field_lis)\n    }\n    scenarios = {}\n    sce_inp_lis = []\n    for s_row in inp_groups['Scenario']:\n        sce, active_yn = s_row.split(DELIM)\n        if active_yn == 'Y':\n            sce_inp_lis.append(sce)\n        sce_inp = groups_obj_from_sgf_triples(sce, inp_group_lis, inp_groups[INP_VALUES])\n        sce_out = groups_obj_from_sgf_triples(sce, out_group_lis, inp_groups[EXP_VALUES])\n        scenarios[sce] = {\n            ACTIVE_YN: active_yn,\n            INP:       sce_inp,\n            OUT:       sce_out\n        }\n    inp_json_obj = {\n        META:       meta,\n        SCENARIOS:  scenarios\n    }\n    with open(INP_JSON_INNER, 'w') as inp_f:\n        json.dump(inp_json_obj, inp_f, indent=4) \n    return [out_group_lis, sce_inp_lis]\n```\n\n<a id=\"get_actuals\"></a>\n##### get_actuals\n[&uarr; Wrapper Function Code](#wrapper-function-code)<br />\nThis function extract the actual results from the JSON output file created by the inner level call to trapit.test_unit. It returns an object with output groups as keys and actual values lists as values for given scenario.\n```py\ndef get_actuals():\n    with open(OUT_JSON_INNER, encoding='utf-8') as out_f:\n        out_json_obj = json.loads(out_f.read())\n    meta, scenarios = out_json_obj[META], out_json_obj[SCENARIOS]\n\n    g_unit_test = [meta[TITLE] + DELIM + meta[DELIMITER]]\n\n    g_inp_fields, g_out_fields, g_inp_values, g_exp_values, g_act_values = [], [], [], [], []\n    for g in meta[INP]:\n        for i in meta[INP][g]:\n            g_inp_fields.append(g + DELIM + i)\n\n    for g in meta[OUT]:\n        for i in meta[OUT][g]:\n            g_out_fields.append(g + DELIM + i)\n\n    for s in scenarios:\n        for g in scenarios[s][INP]:\n            for i in scenarios[s][INP][g]:\n                g_inp_values.append(s + DELIM + g + DELIM + i)\n        for g in scenarios[s][OUT]:\n            for i in scenarios[s][OUT][g][EXP]:\n                g_exp_values.append(s + DELIM + g + DELIM + i)\n            for i in scenarios[s][OUT][g][ACT]:\n                g_act_values.append(s + DELIM + g + DELIM + i)\n\n    os.remove(INP_JSON_INNER)\n    os.remove(OUT_JSON_INNER)\n    return {\n        UNIT_TEST:  g_unit_test,\n        INP_FIELDS: g_inp_fields,\n        OUT_FIELDS: g_out_fields,      \n        INP_VALUES: g_inp_values,     \n        EXP_VALUES: g_exp_values,        \n        ACT_VALUES: g_act_values\n    }\n```\n\n<a id=\"small-functions\"></a>\n##### Small functions\n[&uarr; Wrapper Function Code](#wrapper-function-code)<br />\n###### groups_from_group_field_pairs\nThis function returns a list of distinct groups from an input list of group/field pairs.\n```py\ndef groups_from_group_field_pairs(group_field_lis): # group/field pairs list\n    return list(dict.fromkeys([gf.split(DELIM)[0] for gf in group_field_lis]))\n```\n###### groups_obj_from_gf_pairs\nThis function returns an object with groups as keys and field lists as values, based on input lists of groups and group/field pairs.\n```py\ndef groups_obj_from_gf_pairs(group_lis,        # groups list\n                             group_field_lis): # group/field pairs list\n    obj = {}\n    for g in group_lis:\n        gf_pairs = filter(lambda gf: gf[:len(g)] == g, group_field_lis)\n        obj[g] = [gf[len(g) + 1:] for gf in gf_pairs]\n    return obj\n\n```\n###### groups_obj_from_sgf_triples\nThis function returns an object with groups as keys and field lists as values for given scenario, based on input scenario and lists of groups and scenario/group/field triples\n```py\ndef groups_obj_from_sgf_triples(sce,             # scenario\n                                group_lis,       # groups list\n                                sgf_triple_lis): # scenario/group/field triples list\n    this_sce_pairs = list(filter(lambda g: g[:len(sce)] == sce, sgf_triple_lis))\n    group_field_lis = [p[len(sce) + 1:] for p in this_sce_pairs]\n    return groups_obj_from_gf_pairs(group_lis, group_field_lis)\n\n```\n###### purely_wrap_unit_inner\nThis function is the inner level unit test wrapper function, returning an object with the output group objects 'actual' values from unit under test, which is here trapit.test_unit. It returns the 'Actual Values' group values specified in the outer level for the given scenario, ignoring the (required) input groups parameter in this special case. It references two arrays held in the scope of the outer level wrapper function, and also an index into the scenarios list that has the same outer level scope.\n```py\ndef purely_wrap_unit_inner(inp_groups_inner): # input groups object (inner level)\n    nonlocal sce_inp_ind\n    scenario_inner = sce_inp_lis[sce_inp_ind]\n    sce_inp_ind += 1\n    return groups_obj_from_sgf_triples(scenario_inner, out_group_lis, inp_groups[ACT_VALUES])\n```\n\n### Scenario Category ANalysis (SCAN)\n[&uarr; Unit Testing](#unit-testing)<br />\n[&darr; Simple Category Sets](#simple-category-sets)<br />\n[&darr; Composite Category Sets](#composite-category-sets)<br />\n[&darr; Scenario Category Mapping](#scenario-category-mapping)<br />\n\nThe art of unit testing lies in choosing a set of scenarios that will produce a high degree of confidence in the functioning of the unit under test across the often very large range of possible inputs.\n\nA useful approach to this is to think in terms of categories of inputs, where we reduce large ranges to representative categories. Categories are chosen to explore the full range of potential behaviours of the unit under test.\n\nIn this section we identify the category sets for the problem, and tabulate the corresponding categories. We need to consider which category sets can be tested independently of each other, and which need to be considered in combination. We can then obtain a set of scenarios to cover all relevant combinations of categories.\n\n<a id=\"simple-category-sets\"></a>\n#### Simple Category Sets\n[&uarr; Scenario Category ANalysis (SCAN)](#scenario-category-analysis-scan)<br />\n[&darr; SAF - Scenario active flag](#saf---scenario-active-flag)<br />\n[&darr; MUL-0 - Multiplicity including zero](#mul-0---multiplicity-including-zero)<br />\n[&darr; MUL-1 - Multiplicity excluding zero](#mul-1---multiplicity-excluding-zero)<br />\n[&darr; INV - Invalidity Type](#inv---invalidity-type)<br />\n\nIn this section we identify some simple category sets to apply.\n\n<a id=\"saf---scenario-active-flag\"></a>\n##### SAF - Scenario active flag\n[&uarr; Simple Category Sets](#simple-category-sets)<br />\n\nWe want to check that active scenarios are processed while inactive ones are ignored.\n\n| Code | Description       |\n|:----:|:------------------|\n|  Y   | Scenario active   |\n|  N   | Scenario inactive |\n\n<a id=\"mul-0---multiplicity-including-zero\"></a>\n##### MUL-0 - Multiplicity including zero\n[&uarr; Simple Category Sets](#simple-category-sets)<br />\n\nWe want to check behaviour when there are 0, 1, or more than 1, records for each entity, for those entities where zero multiplicity makes sense.\n\n| Code | Description     |\n|:----:|:----------------|\n|  0   | Zero values     |\n|  1   | 1 value         |\n|  m   | Multiple values |\n\nThis category set is applied to the following entities:\n\n| Category Set | Description               |\n|:------------:|:--------------------------|\n| IGM          | Input group multiplicity  |\n| OGM          | Output group multiplicity |\n| IVM          | Input value multiplicity  |\n| OVM          | Output value multiplicity |\n\n<a id=\"mul-1---multiplicity-excluding-zero\"></a>\n##### MUL-1 - Multiplicity excluding zero\n[&uarr; Simple Category Sets](#simple-category-sets)<br />\n\nWe want to check behaviour when there are 1, or more than 1, records for each entity, for those entities where zero multiplicity does not make sense.\n\n| Code | Description     |\n|:----:|:----------------|\n|  1   | 1 value         |\n|  m   | Multiple values |\n\nThis category set is applied to the following entities:\n\n| Category Set | Description                       |\n|:------------:|:----------------------------------|\n| SCM          | Scenario multiplicity             |\n| IFM          | Input field multiplicity          |\n| OFM          | Output field multiplicity         |\n| DCM          | Delimiter characters multiplicity |\n\n<a id=\"inv---invalidity-type\"></a>\n##### INV - Invalidity Type\n[&uarr; Simple Category Sets](#simple-category-sets)<br />\n\nA unit test returns a status of Failure if any output group returns a status of Failure, which happens when the actual output set of records differs from the expected output set.\n\nWe can categorise types of invalidity by set cardinality differences (with E for expected set cardinality, and A for actual set cardinality). We want to check behaviour for each type of invalidity as well as the valid case.\n\n| Code    | Description                                                 |\n|:-------:|:------------------------------------------------------------|\n|  VAL    | Same cardinalities and all records the same                 |\n|  E=A    | Same cardinalities but at least one record differs in value |\n|  E&gt;A | More records in expected set than in actual set             |\n|  A&gt;E | More records in actual set than in expected set             |\n\n<a id=\"composite-category-sets\"></a>\n#### Composite Category Sets\n[&uarr; Scenario Category ANalysis (SCAN)](#scenario-category-analysis-scan)<br />\n[&darr; IGM / OGM](#igm--ogm)<br />\n[&darr; SCM / SAF ](#scm--saf-)<br />\n\nThe category sets considered can be treated as largely independent, with the exception that having zero multiplicity for both input and output groups doesn't make sense, and making a scenario inactive means nothing else can be tested within that scenario. Therefore we can take the following combinations of the category sets IGM, OGM as the basis of our scenario category mapping, and ensure that the combinations noted below of SCM and SAF are handled.\n\nThe Invalidity Type category set could be tested within the third scenario, but we'll add a fourth scenario for greater clarity.\n\n<a id=\"igm--ogm\"></a>\n##### IGM / OGM\n[&uarr; Composite Category Sets](#composite-category-sets)<br />\n\nEnsure the zero edge case for input groups and output groups are handled separately, and note that 0 for either group implies no fields are possible.\n\n| IGM | OGM | IFM | OFM |\n|:---:|:---:|:---:|:---:|\n|  0  |  1  |  -  |     |\n|  1  |  0  |     |  -  |\n|  m  |  m  |     |     |\n\n<a id=\"scm--saf-\"></a>\n##### SCM / SAF \n[&uarr; Composite Category Sets](#composite-category-sets)<br />\n\nEnsure that the inactive scenario category occurs within a multi-scenario situation, so that other categories can be simultaneously tested.\n\n| SCM | SAF |\n|:---:|:---:|\n|  1  |  Y  |\n|  m  |  N  |\n\n<a id=\"scenario-category-mapping\"></a>\n#### Scenario Category Mapping\n[&uarr; Scenario Category ANalysis (SCAN)](#scenario-category-analysis-scan)<br />\n\nWe now want to construct a set of scenarios based on the category sets identified, covering each individual category, and also covering combinations of categories that may interact.\n\nIn this case, the first four category sets may be considered as a single composite set with the combinations listed below forming the scenario keys, while the two SIZ categories are covered in the first two scenarios.\n\n| #  | IGM | OGM | IVM | OVM | SCM | IFM | OFM | DCM | SAF | INV | Description                                                                |\n|:---|:---:|:----|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:-------------------------------------------------------------------------------------|\n| 1  |  0  |  1  |  -  |  0  |  1  |  -  |  1  |  1  |  Y  | VAL | Zero input groups, 1 of other entities where possible; active scenario; valid | \n| 2  |  1  |  0  |  1  |  -  |  1  |  1  |  -  |  1  |  Y  | VAL | Zero output groups, 1 of other entities where possible; active scenario; valid | \n| 3  |  m  |  m  |  m  |  m  |  m  |  m  |  m  |  m  |  N  | VAL | Multiple entities; one inactive scenario; all valid  | \n| 4  |  1  |  1  |  m  |  m  |  m  |  m  |  m  |  m  |  Y  |  *  | One input and output groups; multiple other entities; active scenarios; each type of invalid scenario | \n\n<a id=\"unit-test-results\"></a>\n### Unit Test Results\n[&uarr; Unit Testing](#unit-testing)<br />\n[&darr; Results Summary](#results-summary)<br />\n[&darr; Unit Test Report: Python Unit Tester](#unit-test-report-python-unit-tester)<br />\n\n<a id=\"results-summary\"></a>\n#### Results Summary\n[&uarr; Unit Test Results](#unit-test-results)<br />\n\n```\nUnit Test Results Summary for Folder ./externals/python\n=======================================================\n File                 Title               Inp Groups  Out Groups  Tests  Fails  Folder            \n--------------------  ------------------  ----------  ----------  -----  -----  ------------------\n*colgroup_out.json    Col Group                    3           4      5      1  col-group         \n helloworld_out.json  Hello World                  0           1      1      0  hello-world       \n trapit_py_out.json   Python Unit Tester           7           6      4      0  python-unit-tester\n\n1 externals failed, see ./externals/python for scenario listings\ncolgroup_out.json\n```\n\nYou can review the HTML formatted unit test results here:\n\n- [Unit Test Report: Python Unit Tester](http://htmlpreview.github.io/?https://github.com/BrenPatF/trapit_python_tester/blob/master/unit_test/python-unit-tester/python-unit-tester.html)\n\n<a id=\"unit-test-report-python-unit-tester\"></a>\n#### Unit Test Report: Python Unit Tester\n[&uarr; Unit Test Results](#unit-test-results)<br />\n```\nUnit Test Report: Python Unit Tester\n====================================\n\n      #    Scenario                                                                                               Fails (of 6)  Status \n      ---  -----------------------------------------------------------------------------------------------------  ------------  -------\n      1    Zero input groups, 1 of other entities where possible; active scenario; valid                          0             SUCCESS\n      2    Zero output groups, 1 of other entities where possible; active scenario; valid                         0             SUCCESS\n      3    Multiple entities; one inactive scenario; all valid                                                    0             SUCCESS\n      4    One input and output groups; multiple other entities; active scenarios; each type of invalid scenario  0             SUCCESS\n\nTest scenarios: 0 failed of 4: SUCCESS\n======================================\n```\nHere are the output results for the first scenario (slightly edited for brevity):\n\n```\nSCENARIO 1: Zero input groups, 1 of other entities where possible; active scenario; valid {\n===========================================================================================\n   INPUTS\n   ======\n      GROUP 1: Unit Test {\n      ====================\n            #  Title        Delimiter\n            -  -----------  ---------\n            1  Inner title  ;        \n      }\n      GROUP 2: Input Fields: Empty\n      ============================\n      GROUP 3: Output Fields {\n      ========================\n            #  Group           Field         \n            -  --------------  --------------\n            1  Output Group 1  Output Field 1\n      }\n      GROUP 4: Scenario {\n      ===================\n            #  Scenario          Active Y/N\n            -  ----------------  ----------\n            1  Inner scenario 1  Y         \n      }\n      GROUP 5: Input Values: Empty\n      ============================\n      GROUP 6: Expected Values {\n      ==========================\n            #  Scenario          Group           Row CSV         \n            -  ----------------  --------------  ----------------\n            1  Inner scenario 1  Output Group 1  Expected value 1\n      }\n      GROUP 7: Actual Values {\n      ========================\n            #  Scenario          Group           Row CSV       \n            -  ----------------  --------------  --------------\n            1  Inner scenario 1  Output Group 1  Actual value 1\n      }\n   OUTPUTS\n   =======\n      GROUP 1: Unit Test {\n      ====================\n            #  Title        Delimiter\n            -  -----------  ---------\n            1  Inner title  ;        \n      } 0 failed of 1: SUCCESS\n      ========================\n      GROUP 2: Input Fields: Empty as expected: SUCCESS\n      =================================================\n      GROUP 3: Output Fields {\n      ========================\n            #  Group           Field         \n            -  --------------  --------------\n            1  Output Group 1  Output Field 1\n      } 0 failed of 1: SUCCESS\n      ========================\n      GROUP 4: Input Values: Empty as expected: SUCCESS\n      =================================================\n      GROUP 5: Expected Values {\n      ==========================\n            #  Scenario          Group           Row CSV         \n            -  ----------------  --------------  ----------------\n            1  Inner scenario 1  Output Group 1  Expected value 1\n      } 0 failed of 1: SUCCESS\n      ========================\n      GROUP 6: Actual Values {\n      ========================\n            #  Scenario          Group           Row CSV       \n            -  ----------------  --------------  --------------\n            1  Inner scenario 1  Output Group 1  Actual value 1\n      } 0 failed of 1: SUCCESS\n      ========================\n} 0 failed of 6: SUCCESS\n========================\n```\n\n<a id=\"see-also\"></a>\n## See Also\n[&uarr; In This README...](#in-this-readme)<br />\n\n- [Database API Viewed As A Mathematical Function: Insights into Testing](https://www.slideshare.net/brendanfurey7/database-api-viewed-as-a-mathematical-function-insights-into-testing)\n- [Unit Testing, Scenarios and Categories: The SCAN Method](https://brenpatf.github.io/jekyll/update/2021/10/17/unit-testing-scenarios-and-categories-the-scan-method.html)\n- [Trapit JavaScript Tester/Formatter - GitHub module](https://github.com/BrenPatF/trapit_nodejs_tester)\n- [Trapit Python Tester - GitHub module](https://github.com/BrenPatF/trapit_python_tester)\n- [Trapit Oracle Tester - GitHub module](https://github.com/BrenPatF/trapit_oracle_tester)\n- [Powershell Utilities - GitHub module](https://github.com/BrenPatF/powershell_utils)\n- [Trapit Python Tester - Python Package Index module](https://pypi.org/project/trapit/)\n- [Timer Set Python Code Timer - GitHub module](https://github.com/BrenPatF/timerset_python)\n\n<a id=\"license\"></a>\n## License\n[&uarr; In This README...](#in-this-readme)<br />\n\nMIT",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/brenpatf/trapit_python_tester",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "trapit",
    "package_url": "https://pypi.org/project/trapit/",
    "platform": null,
    "project_url": "https://pypi.org/project/trapit/",
    "project_urls": {
      "Homepage": "https://github.com/brenpatf/trapit_python_tester"
    },
    "release_url": "https://pypi.org/project/trapit/1.0.1/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "Trapit python utility for Math Function Unit Test design pattern",
    "version": "1.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 15352366,
  "releases": {
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3690e5810c4e7fd316eebfd2c74be4272840ea7fe8edd1e4b8bfc7c629c16b17",
          "md5": "828dc18a39406add9aa7d6718b6fdf9e",
          "sha256": "036fdb774ad3db12f4f1af5baa4f2bd0f8a12cce425e688c33fb22ac473addab"
        },
        "downloads": -1,
        "filename": "trapit-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "828dc18a39406add9aa7d6718b6fdf9e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 444987,
        "upload_time": "2022-10-09T14:09:59",
        "upload_time_iso_8601": "2022-10-09T14:09:59.262322Z",
        "url": "https://files.pythonhosted.org/packages/36/90/e5810c4e7fd316eebfd2c74be4272840ea7fe8edd1e4b8bfc7c629c16b17/trapit-1.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3f8588c82e665ae7998ea772277dc74c0a987977e2aeefd325ecba4451cf1682",
          "md5": "944cdbe71f3d5e967a3019a8b0e42cfb",
          "sha256": "79fb18911918f0fa0dfcdce87540d101a8e0bd501bd8bff69f5867b1a983e44d"
        },
        "downloads": -1,
        "filename": "trapit-1.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "944cdbe71f3d5e967a3019a8b0e42cfb",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 444905,
        "upload_time": "2022-10-09T15:52:09",
        "upload_time_iso_8601": "2022-10-09T15:52:09.335935Z",
        "url": "https://files.pythonhosted.org/packages/3f/85/88c82e665ae7998ea772277dc74c0a987977e2aeefd325ecba4451cf1682/trapit-1.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "3f8588c82e665ae7998ea772277dc74c0a987977e2aeefd325ecba4451cf1682",
        "md5": "944cdbe71f3d5e967a3019a8b0e42cfb",
        "sha256": "79fb18911918f0fa0dfcdce87540d101a8e0bd501bd8bff69f5867b1a983e44d"
      },
      "downloads": -1,
      "filename": "trapit-1.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "944cdbe71f3d5e967a3019a8b0e42cfb",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 444905,
      "upload_time": "2022-10-09T15:52:09",
      "upload_time_iso_8601": "2022-10-09T15:52:09.335935Z",
      "url": "https://files.pythonhosted.org/packages/3f/85/88c82e665ae7998ea772277dc74c0a987977e2aeefd325ecba4451cf1682/trapit-1.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}