{
  "info": {
    "author": "Freatraum",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# Whisper2pinyin\r\n\r\nThis is forked from [[Whisper]](https://github.com/openai/whisper) in order to better convert audio to pinyin\r\n\r\n\r\n#\r\n\r\n[[Blog]](https://openai.com/blog/whisper)\r\n[[Paper]](https://arxiv.org/abs/2212.04356)\r\n[[Model card]](https://github.com/openai/whisper/blob/main/model-card.md)\r\n[[Colab example]](https://colab.research.google.com/github/openai/whisper/blob/master/notebooks/LibriSpeech.ipynb)\r\n\r\nWhisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multi-task model that can perform multilingual speech recognition as well as speech translation and language identification.\r\n\r\n## Setup\r\n\r\nWe used Python 3.9.9 and [PyTorch](https://pytorch.org/) 1.10.1 to train and test our models, but the codebase is expected to be compatible with Python 3.8-3.10 and recent PyTorch versions. The codebase also depends on a few Python packages, most notably [HuggingFace Transformers](https://huggingface.co/docs/transformers/index) for their fast tokenizer implementation and [ffmpeg-python](https://github.com/kkroening/ffmpeg-python) for reading audio files. You can download and install (or update to) the latest release of Whisper with the following command:\r\n\r\n    pip install -U openai-whisper\r\n\r\nAlternatively, the following command will pull and install the latest commit from this repository, along with its Python dependencies:\r\n\r\n    pip install git+https://github.com/freatraum/whisper.git \r\n\r\nTo update the package to the latest version of this repository, please run:\r\n\r\n    pip install --upgrade --no-deps --force-reinstall git+https://github.com/freatraum/whisper.git\r\n\r\nIt also requires the command-line tool [`ffmpeg`](https://ffmpeg.org/) to be installed on your system, which is available from most package managers:\r\n\r\n```bash\r\n# on Ubuntu or Debian\r\nsudo apt update && sudo apt install ffmpeg\r\n\r\n# on Arch Linux\r\nsudo pacman -S ffmpeg\r\n\r\n# on MacOS using Homebrew (https://brew.sh/)\r\nbrew install ffmpeg\r\n\r\n# on Windows using Chocolatey (https://chocolatey.org/)\r\nchoco install ffmpeg\r\n\r\n# on Windows using Scoop (https://scoop.sh/)\r\nscoop install ffmpeg\r\n```\r\n\r\nYou may need [`rust`](http://rust-lang.org) installed as well, in case [tokenizers](https://pypi.org/project/tokenizers/) does not provide a pre-built wheel for your platform. If you see installation errors during the `pip install` command above, please follow the [Getting started page](https://www.rust-lang.org/learn/get-started) to install Rust development environment. Additionally, you may need to configure the `PATH` environment variable, e.g. `export PATH=\"$HOME/.cargo/bin:$PATH\"`. If the installation fails with `No module named 'setuptools_rust'`, you need to install `setuptools_rust`, e.g. by running:\r\n\r\n```bash\r\npip install setuptools-rust\r\n```\r\n\r\n\r\n## Available models and languages\r\n\r\nThere are five model sizes, four with English-only versions, offering speed and accuracy tradeoffs. Below are the names of the available models and their approximate memory requirements and relative speed. \r\n\r\n\r\n|  Size  | Parameters | English-only model | Multilingual model | Required VRAM | Relative speed |\r\n|:------:|:----------:|:------------------:|:------------------:|:-------------:|:--------------:|\r\n|  tiny  |    39 M    |     `tiny.en`      |       `tiny`       |     ~1 GB     |      ~32x      |\r\n|  base  |    74 M    |     `base.en`      |       `base`       |     ~1 GB     |      ~16x      |\r\n| small  |   244 M    |     `small.en`     |      `small`       |     ~2 GB     |      ~6x       |\r\n| medium |   769 M    |    `medium.en`     |      `medium`      |     ~5 GB     |      ~2x       |\r\n| large  |   1550 M   |        N/A         |      `large`       |    ~10 GB     |       1x       |\r\n\r\nFor English-only applications, the `.en` models tend to perform better, especially for the `tiny.en` and `base.en` models. We observed that the difference becomes less significant for the `small.en` and `medium.en` models.\r\n\r\nWhisper's performance varies widely depending on the language. The figure below shows a WER (Word Error Rate) breakdown by languages of Fleurs dataset, using the `large-v2` model. More WER and BLEU scores corresponding to the other models and datasets can be found in Appendix D in [the paper](https://arxiv.org/abs/2212.04356). The smaller is better.\r\n\r\n![WER breakdown by language](https://raw.githubusercontent.com/openai/whisper/main/language-breakdown.svg)\r\n\r\n\r\n\r\n## Command-line usage\r\n\r\nThe following command will transcribe speech in audio files, using the `medium` model:\r\n\r\n    whisper audio.flac audio.mp3 audio.wav --model medium\r\n\r\nThe default setting (which selects the `small` model) works well for transcribing English. To transcribe an audio file containing non-English speech, you can specify the language using the `--language` option:\r\n\r\n    whisper japanese.wav --language Japanese\r\n\r\nAdding `--task translate` will translate the speech into English:\r\n\r\n    whisper japanese.wav --language Japanese --task translate\r\n\r\nRun the following to view all available options:\r\n\r\n    whisper --help\r\n\r\nSee [tokenizer.py](https://github.com/openai/whisper/blob/main/whisper/tokenizer.py) for the list of all available languages.\r\n\r\n\r\n## Python usage\r\n\r\nTranscription can also be performed within Python: \r\n\r\n```python\r\nimport whisper\r\n\r\nmodel = whisper.load_model(\"base\")\r\nresult = model.transcribe(\"audio.mp3\")\r\nprint(result[\"text\"])\r\n```\r\n\r\nInternally, the `transcribe()` method reads the entire file and processes the audio with a sliding 30-second window, performing autoregressive sequence-to-sequence predictions on each window.\r\n\r\nBelow is an example usage of `whisper.detect_language()` and `whisper.decode()` which provide lower-level access to the model.\r\n\r\n```python\r\nimport whisper\r\n\r\nmodel = whisper.load_model(\"base\")\r\n\r\n# load audio and pad/trim it to fit 30 seconds\r\naudio = whisper.load_audio(\"audio.mp3\")\r\naudio = whisper.pad_or_trim(audio)\r\n\r\n# make log-Mel spectrogram and move to the same device as the model\r\nmel = whisper.log_mel_spectrogram(audio).to(model.device)\r\n\r\n# detect the spoken language\r\n_, probs = model.detect_language(mel)\r\nprint(f\"Detected language: {max(probs, key=probs.get)}\")\r\n\r\n# decode the audio\r\noptions = whisper.DecodingOptions()\r\nresult = whisper.decode(model, mel, options)\r\n\r\n# print the recognized text\r\nprint(result.text)\r\n```\r\n\r\n## More examples\r\n\r\nPlease use the [ðŸ™Œ Show and tell](https://github.com/openai/whisper/discussions/categories/show-and-tell) category in Discussions for sharing more example usages of Whisper and third-party extensions such as web demos, integrations with other tools, ports for different platforms, etc.\r\n\r\n\r\n## License\r\n\r\nThe code and the model weights of Whisper are released under the MIT License. See [LICENSE](https://github.com/openai/whisper/blob/main/LICENSE) for further details.\r\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/freatraum/whisper2pinyin",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "Whisper2pinyin",
    "package_url": "https://pypi.org/project/Whisper2pinyin/",
    "platform": null,
    "project_url": "https://pypi.org/project/Whisper2pinyin/",
    "project_urls": {
      "Homepage": "https://github.com/freatraum/whisper2pinyin"
    },
    "release_url": "https://pypi.org/project/Whisper2pinyin/1.2.1/",
    "requires_dist": null,
    "requires_python": ">=3.7",
    "summary": "Robust Speech Recognition via Large-Scale Weak Supervision",
    "version": "1.2.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16993694,
  "releases": {
    "1.2.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b628238c98d6b4fcf83967a6e5833b37a6d0481b6ecc77b40fbde0197e4e2cf4",
          "md5": "1bac6d7729d43837a8fb440843da2018",
          "sha256": "354d14350a306c832397df0e206ed3591ccf5ab5b38dfe8888fa76b8c7f72ffb"
        },
        "downloads": -1,
        "filename": "Whisper2pinyin-1.2.1.tar.gz",
        "has_sig": false,
        "md5_digest": "1bac6d7729d43837a8fb440843da2018",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 1153024,
        "upload_time": "2023-02-23T13:55:00",
        "upload_time_iso_8601": "2023-02-23T13:55:00.092231Z",
        "url": "https://files.pythonhosted.org/packages/b6/28/238c98d6b4fcf83967a6e5833b37a6d0481b6ecc77b40fbde0197e4e2cf4/Whisper2pinyin-1.2.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "b628238c98d6b4fcf83967a6e5833b37a6d0481b6ecc77b40fbde0197e4e2cf4",
        "md5": "1bac6d7729d43837a8fb440843da2018",
        "sha256": "354d14350a306c832397df0e206ed3591ccf5ab5b38dfe8888fa76b8c7f72ffb"
      },
      "downloads": -1,
      "filename": "Whisper2pinyin-1.2.1.tar.gz",
      "has_sig": false,
      "md5_digest": "1bac6d7729d43837a8fb440843da2018",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 1153024,
      "upload_time": "2023-02-23T13:55:00",
      "upload_time_iso_8601": "2023-02-23T13:55:00.092231Z",
      "url": "https://files.pythonhosted.org/packages/b6/28/238c98d6b4fcf83967a6e5833b37a6d0481b6ecc77b40fbde0197e4e2cf4/Whisper2pinyin-1.2.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}