{
  "info": {
    "author": "Manuel Trinidad Garcia",
    "author_email": "manuel.trinidad.garcia@hotmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Environment :: Console",
      "Environment :: No Input/Output (Daemon)",
      "License :: OSI Approved :: BSD License",
      "Operating System :: OS Independent",
      "Programming Language :: Python",
      "Programming Language :: Python :: 2.7",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Topic :: Internet :: WWW/HTTP"
    ],
    "description": "==========================\nScrapyrt (Scrapy realtime)\n==========================\n\n.. image:: https://travis-ci.org/scrapinghub/scrapyrt.svg?branch=master\n    :target: https://travis-ci.org/scrapinghub/scrapyrt\n\n.. image:: https://img.shields.io/pypi/pyversions/scrapyrt.svg\n    :target: https://pypi.python.org/pypi/scrapyrt\n\n.. image:: https://img.shields.io/pypi/v/scrapyrt.svg\n    :target: https://pypi.python.org/pypi/scrapyrt\n\n.. image:: https://img.shields.io/pypi/l/scrapyrt.svg\n    :target: https://pypi.python.org/pypi/scrapyrt\n\nHTTP server which provides API for scheduling Scrapy spiders and\nmaking requests with spiders.\n\nAllows you to easily add HTTP API to your existing Scrapy project. All Scrapy project\ncomponents (e.g. middleware, pipelines, extensions) are supported out of the box. You\nsimply run Scrapyrt in Scrapy project directory and it starts HTTP server allowing you\nto schedule your spiders and get spider output in JSON format.\n\n\nDocumentation\n=============\n\nDocumentation is available here: http://scrapyrt.readthedocs.org/en/latest/index.html\n\n\nSupport\n=======\n\nOpen source support is provided here in Github. Please `create a question\nissue`_ (ie. issue with \"question\" label).\n\nCommercial support is also available by `Scrapinghub`_.\n\n.. _create a question issue: https://github.com/scrapinghub/scrapyrt/issues/new?labels=question\n.. _Scrapinghub: http://scrapinghub.com\n\nDevelopment\n===========\n\nRelease\n-------\n\nUse `bumpversion`_ tool, e.g. to release minor version do::\n\n    bumpversion minor --verbose\n    git push origin master\n    git push origin <new_version_tag>\n\n.. _bumpversion: https://pypi.python.org/pypi/bumpversion\n\n\n",
    "description_content_type": "",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/manueltg89/scrapyrt-with-params",
    "keywords": "",
    "license": "BSD",
    "maintainer": "Scrapinghub",
    "maintainer_email": "manuel.trinidad.garcia@hotmail.com",
    "name": "scrapyrt-with-params",
    "package_url": "https://pypi.org/project/scrapyrt-with-params/",
    "platform": "",
    "project_url": "https://pypi.org/project/scrapyrt-with-params/",
    "project_urls": {
      "Homepage": "https://github.com/manueltg89/scrapyrt-with-params"
    },
    "release_url": "https://pypi.org/project/scrapyrt-with-params/0.11.0/",
    "requires_dist": [
      "Twisted (>=14.0.0)",
      "Scrapy (>=1.0.0)",
      "demjson",
      "six (>=1.5.2)"
    ],
    "requires_python": "",
    "summary": "Put Scrapy spiders behind an HTTP API",
    "version": "0.11.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 7688809,
  "releases": {
    "0.11.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b44114b3f0abae88b57564ea906810f54ee0d287b35c3603346885b2847c1d41",
          "md5": "cb5c8f33e4d6cf03f99b34b77e118228",
          "sha256": "fc140c17a40cb952103f3836844c9c569697228080bea9679e1c6995141bd610"
        },
        "downloads": -1,
        "filename": "scrapyrt_with_params-0.11.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "cb5c8f33e4d6cf03f99b34b77e118228",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 34322,
        "upload_time": "2020-07-13T08:18:46",
        "upload_time_iso_8601": "2020-07-13T08:18:46.989687Z",
        "url": "https://files.pythonhosted.org/packages/b4/41/14b3f0abae88b57564ea906810f54ee0d287b35c3603346885b2847c1d41/scrapyrt_with_params-0.11.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0a48888194be22aa7a453a79f7e36029f2120403e331dcc91f470d791cc197c8",
          "md5": "08e26dfffabee65bf3e25b05478df8f8",
          "sha256": "9747584dd50d4fc21727973f368d9d3086556cf41d3afeca90062e313b1c4704"
        },
        "downloads": -1,
        "filename": "scrapyrt-with-params-0.11.0.tar.gz",
        "has_sig": false,
        "md5_digest": "08e26dfffabee65bf3e25b05478df8f8",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 24786,
        "upload_time": "2020-07-13T08:18:49",
        "upload_time_iso_8601": "2020-07-13T08:18:49.442402Z",
        "url": "https://files.pythonhosted.org/packages/0a/48/888194be22aa7a453a79f7e36029f2120403e331dcc91f470d791cc197c8/scrapyrt-with-params-0.11.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "b44114b3f0abae88b57564ea906810f54ee0d287b35c3603346885b2847c1d41",
        "md5": "cb5c8f33e4d6cf03f99b34b77e118228",
        "sha256": "fc140c17a40cb952103f3836844c9c569697228080bea9679e1c6995141bd610"
      },
      "downloads": -1,
      "filename": "scrapyrt_with_params-0.11.0-py2.py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "cb5c8f33e4d6cf03f99b34b77e118228",
      "packagetype": "bdist_wheel",
      "python_version": "py2.py3",
      "requires_python": null,
      "size": 34322,
      "upload_time": "2020-07-13T08:18:46",
      "upload_time_iso_8601": "2020-07-13T08:18:46.989687Z",
      "url": "https://files.pythonhosted.org/packages/b4/41/14b3f0abae88b57564ea906810f54ee0d287b35c3603346885b2847c1d41/scrapyrt_with_params-0.11.0-py2.py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "0a48888194be22aa7a453a79f7e36029f2120403e331dcc91f470d791cc197c8",
        "md5": "08e26dfffabee65bf3e25b05478df8f8",
        "sha256": "9747584dd50d4fc21727973f368d9d3086556cf41d3afeca90062e313b1c4704"
      },
      "downloads": -1,
      "filename": "scrapyrt-with-params-0.11.0.tar.gz",
      "has_sig": false,
      "md5_digest": "08e26dfffabee65bf3e25b05478df8f8",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 24786,
      "upload_time": "2020-07-13T08:18:49",
      "upload_time_iso_8601": "2020-07-13T08:18:49.442402Z",
      "url": "https://files.pythonhosted.org/packages/0a/48/888194be22aa7a453a79f7e36029f2120403e331dcc91f470d791cc197c8/scrapyrt-with-params-0.11.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}