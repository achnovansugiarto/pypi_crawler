{
  "info": {
    "author": "Philip W Fowler",
    "author_email": "philip.fowler@ndm.ox.ac.uk",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# gpas_testing\nCreate perfect FASTQ files for the SARS-CoV-2 WHO lineages for use in testing\n\n## Installation\n\nFirst, let's get the repository and work in a virtual environment\n\n```\ngit clone git@github.com:GenomePathogenAnalysisService/gpas-testing.git\ncd gpas-testing\npython -m venv env\nsource env/bin/activate\n```\n\nNow let's manually download the [`constellations`](https://github.com/cov-lineages/constellations) SARS-CoV-2 lineage definitions\n\n```\ngit clone https://github.com/cov-lineages/constellations.git\n```\n\nNow we can automatically install the rest of dependencies\n\n```\npip install -e .\n```\n\nI've specified the `-e` or `--editable` flag so that if you make changes to the `gpas-testing` they will flow through automatically into the installed version so you don't need to reinstall each time. This isn't required if you are using a static version.\n\nOnce complete, let's check the modest number of unit tests work\n\n```\npy.test tests/\n```\n\nThis repository contains three scripts that help in creating and analysing batches of SARS-CoV-2 samples using GPAS.\n\n### `gpas-synreads-covid-create.py` -- creating synthetic SARS-CoV-2 reads\n\n```\nusage: gpas-synreads-covid-create.py [-h] [--variant_definitions VARIANT_DEFINITIONS] [--pango_definitions PANGO_DEFINITIONS]\n                                     [--output OUTPUT] [--variant_name VARIANT_NAME] [--reference REFERENCE] --tech TECH\n                                     [--primers PRIMERS [PRIMERS ...]] [--read_length READ_LENGTH]\n                                     [--read_stddev READ_STDDEV] [--depth DEPTH [DEPTH ...]] [--depth_stddev DEPTH_STDDEV]\n                                     [--snps SNPS [SNPS ...]] [--repeats REPEATS] [--error_rate ERROR_RATE [ERROR_RATE ...]]\n                                     [--drop_amplicons DROP_AMPLICONS [DROP_AMPLICONS ...]] [--write_fasta]\n                                     [--bias_amplicons BIAS_AMPLICONS [BIAS_AMPLICONS ...]]\n                                     [--bias_primers BIAS_PRIMERS [BIAS_PRIMERS ...]]\n                                     [--drop_forward_amplicons DROP_FORWARD_AMPLICONS [DROP_FORWARD_AMPLICONS ...]]\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --variant_definitions VARIANT_DEFINITIONS\n                        the path to the variant_definitions repository/folder from phe-genomics\n  --pango_definitions PANGO_DEFINITIONS\n                        the path to the constellations repository/folder from cov-lineages\n  --output OUTPUT       the stem of the output file\n  --variant_name VARIANT_NAME\n                        the name of the variant, default is Reference\n  --reference REFERENCE\n                        the GenBank file of the covid reference (if not specified, the MN908947.3.gbk reference will be used)\n  --tech TECH           whether to generate illumina (paired) or nanopore (unpaired) reads\n  --primers PRIMERS [PRIMERS ...]\n                        the name of the primer schema, must be on of articv3, articv4, midnight1200, ampliseq\n  --read_length READ_LENGTH\n                        if specified, the read length in bases, otherwise defaults to the whole amplicon\n  --read_stddev READ_STDDEV\n                        the standard deviation in the read lengths (default value is 0)\n  --depth DEPTH [DEPTH ...]\n                        the depth (default value is 500)\n  --depth_stddev DEPTH_STDDEV\n                        the standard deviation of the depth distribution (default value is 0)\n  --snps SNPS [SNPS ...]\n                        the number of snps to randomly introduce into the sequence\n  --repeats REPEATS     how many repeats to create\n  --error_rate ERROR_RATE [ERROR_RATE ...]\n                        the percentage base error rate (default value is 0.0)\n  --drop_amplicons DROP_AMPLICONS [DROP_AMPLICONS ...]\n                        the number (int) of one or more amplicons to drop i.e. have no reads.\n  --write_fasta         whether to write out the FASTA file for the variant\n  --bias_amplicons BIAS_AMPLICONS [BIAS_AMPLICONS ...]\n                        whether to introduce an incorrect SNP in one or more specified amplicons\n  --bias_primers BIAS_PRIMERS [BIAS_PRIMERS ...]\n                        whether to introduce an incorrect SNP in both primers of an amplicon\n  --drop_forward_amplicons DROP_FORWARD_AMPLICONS [DROP_FORWARD_AMPLICONS ...]\n                        the names of one or more amplicons where there will be no reads mapping to the forward strand.\n```                        \n\nAs described in Installation, you will have already installed the `constellation` definitions of (pangolin) SARS-CoV-2 lineages. The code also copes with the phe-genomics set, however at the time of writing these were not being updated as frequently. In addition, the definitions are not interchangeable e.g. if you want to create a genome that `pangolin` will classify as `BA.2` you need to use the `pangolin` definitions, which are `constellations`. Hence whilst both are offered, we currently recommend `constellations`.\n\nFirst, we can simply create a set of perfect `cBA.1` Illumina reads \n\n```\ngpas-synreads-covid-create.py --pango_definitions constellations/ --tech illumina --variant_name cBA.1 --write_fasta\nls illumina-*\nillumina-articv3-cBA.1-cov-0snps-500d-0.0e-0.fasta   illumina-articv3-cBA.1-cov-0snps-500d-0.0e-0_2.fastq\nillumina-articv3-cBA.1-cov-0snps-500d-0.0e-0_1.fastq\ngzip illumina*fastq\n```\nNote that the `fastq` files were written uncompressed, so the first thing we need to do is `gzip` them. Also note that since we didn't tell the code what to call the files (using `--output`) it has given the files a hierarchial descriptive name. As you can see lot's of options have taken their default values, e.g. the default amplicon scheme is Artic v3, the default depth is 500 reads, there are no errors and no SNPs.\n\nLet's make somthing a bit more realistic; a `cBA.3` sample that has 'been' sequenced with Nanopore using the Midnight primers. This sample has a mean depth of 500 and a standard deviation of 100 so there is a reasonable probability one or more amplicons only have a read depth of 250. One of the amplicons (2) has no reads associated with it and all the reads have a 2% error rate. This sample is 2 SNPs away from the `cBA.3` reference definition.\n\n```\ngpas-synreads-covid-create.py --pango_definitions constellations/ --tech nanopore --variant_name cBA.3 --write_fasta --depth 400 --read_stddev 100 --primers midnight1200 --snps 2 --error_rate 2 --drop_amplicons 2 --write_fasta\nls nanopore-*\nnanopore-midnight1200-cBA.3-cov-2snps-400d-0.02e-a2da-0.fasta nanopore-midnight1200-cBA.3-cov-2snps-400d-0.02e-a2da-0.fastq\n$ gzip nanopore*fastq\n```\n\nThis degree of customisability let's you build a batch of samples to test \"genetic space\" e.g. one could create a batch containing all the common SARS-CoV-2 lineages in circulation, or a batch containing a range of error rates to explore at what point GPAS can no longer produce a consensus genome etc.\n\nFor demonstration purposes, let's build a simple batch of Illumina cBA.2 samples.\n\n```\nmkdir batch-0\ncd batch-0\ngpas-synreads-covid-create.py --pango_definitions constellations/ --tech illumina --variant_name cBA.2 --write_fasta --depth 300 --read_stddev 100 --primers articv4 --snps 2 --error_rate 1 --write_fasta --repeats 3\ngzip *fastq\n```\n\nIn this folder we have three pairs of gzipped FASTQ files we can upload and, crucially, the genome (FASTA file) that was used to create them, hence we have an *expectation* that we can compare back to later on and assert equality.\n\nNow we can use the next script\n\n## `gpas-build-uploadcsv.py` - automatically creating an upload CSV\n\nOne can always write manually an upload CSV but is time-consuming, boring and can introduce mistakes, hence this helper script. If you run it in a folder that contains gzipped fastq files (like `batch-0`) and give it some arguments it will create a valid upload CSV for you that you can then use either with the Electron Client / App or the CLI to upload the batch to GPAS for processing.\n\n```\ngpas-build-uploadcsv.py --help\nusage: gpas-build-uploadcsv.py [-h] [--country COUNTRY] [--tech TECH] [--file_type FILE_TYPE] [--tag_file TAG_FILE]\n                               [--uuid_length UUID_LENGTH] [--number_of_tags NUMBER_OF_TAGS] [--old_format]\n                               [--organisation ORGANISATION]\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --country COUNTRY     the name of the country where the samples were collected\n  --tech TECH           whether to generate illumina (paired) or nanopore (unpaired) reads\n  --file_type FILE_TYPE\n                        whether to look for FASTQ or BAM files\n  --tag_file TAG_FILE   a plaintext file with one row per tag\n  --uuid_length UUID_LENGTH\n                        whether to use a long or short UUID4\n  --number_of_tags NUMBER_OF_TAGS\n                        how many tags to give each sample. Can be zero, or up to the number of rows in <tag_file>. Default is 2 so as to test the delimiter\n  --old_format          whether to use the original upload CSV format and headers\n  --organisation ORGANISATION\n                        the name of the organisation (the user must belong to it otherwise validation will fail)\n```\n\nWe will only focus here on the new (May 2022 / Electron Client v1.0.7 / gpas-uploader v1.1.1) format for the upload CSV so the last two arguments will not concern us. First we need to make a plaintext file containing each tag we wish the code to pick from on its own line. I've made one called `tags.txt` which has a single line containing `test`.\n\nGiven the sequencing technology used, the code will detect the samples where it is run and then autogenerate e.g.  a local `batch` and `run_number` for each sample as well as randomly create a `collection_date` from the recent past. It does not add any `control`, `region` or `district`. You can always edit the file afterwards to customise it (e.g. by adding deliberate mistakes if you wish to test the validation rules in the uploader). It also renames all the fastq files by appending either a long or short `uuid` string. This ensures that each upload CSV is different, even if it contains the \"same\" samples. The result is printed to STDOUT so you need to redirect it to a file if you wish to keep it.\n\n```\ngpas-build-uploadcsv.py --country USA --tag_file tags.txt --uuid_length short --number_of_tags 1 --tech illumina > upload.csv\n```\nYou can now use this upload CSV either with the Electron Client or the gpas cli.\n\n## `gpas-synreads-covid-create.py` - checking if the GPAS consensus genome matches what the reads were built from\n\nThis script compares the output consensus genomes to the genome used to build the FASTQ files and will declare success if the input genome contains the output genome and the latter is longer than 29k bases. It also compares the input lineage to the detected lineage. Since it requires the sample to be run through GPAS I won't describe it more here but it does assume you have the file mapping the local to gpas identifiers, which here I will call `sample_names.csv`.\n\n## Cultured \"truth\" samples\n\nThese can be obtained from these two ENA projects: [PRJEB50520](https://www.ebi.ac.uk/ena/browser/view/PRJEB50520) and [PRJEB51850](https://www.ebi.ac.uk/ena/browser/view/PRJEB51850) with `vcf` files describing the variation w.r.t the Wuhan reference found [here](https://github.com/iqbal-lab-org/covid-truth-datasets).\n\n\n## Docker Use\n\nThere is a Dockerfile provided to make your own container or an image available in Dockerhub (oxfordmmm/gpas_testing). Both versions put the `constellations` and `variant_definitions` directories at the root of the container.\n\n(PWF: I've messed with this so it needs updating..)\n\nThe container can be run with a command such as:\n\n```\ndocker run -v /path/to/output:/output oxfordmmm/gpas_testing python3 /gpas_testing/bin/gpas_testing.py  --pango_definitions /constellations/ --output /output/reference --tech illumina --variant_name reference --write_fasta \n\ndocker run -v .:/output oxfordmmm/gpas_testing python3 /gpas_testing/bin/gpas-synreads-covid-create.py --pango_definitions /constellations/ --tech illumina --variant_name cBA.1 --write_fasta --output /output/BA.1\n```\n\nPhilip W Fowler, 7 July 2022\n\n",
    "description_content_type": "text/markdown; charset=UTF-8",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/GlobalPathogenAnalysisService/gpas-testing",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "gpas-testing",
    "package_url": "https://pypi.org/project/gpas-testing/",
    "platform": null,
    "project_url": "https://pypi.org/project/gpas-testing/",
    "project_urls": {
      "Homepage": "https://github.com/GlobalPathogenAnalysisService/gpas-testing"
    },
    "release_url": "https://pypi.org/project/gpas-testing/1.0.1/",
    "requires_dist": [
      "pyfastaq (>=3.17.0)",
      "pyyaml",
      "numpy",
      "tqdm",
      "pandas",
      "gumpy (>=1.0.2)",
      "requests",
      "pytest",
      "pytest-cov"
    ],
    "requires_python": ">=3.6",
    "summary": "Predicting the effect of an antibiotic from gene mutations",
    "version": "1.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14539671,
  "releases": {
    "1.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a2afbf81d62c6dfe69a2bf1c8edb48d940b4062ffaf13100ce1089a9e6a0be93",
          "md5": "14bfb4522edbcdeef83c36984ba10458",
          "sha256": "dcb5dfa03d237d4e25aacff69b3dea742fb1aff61304b82c8c8009d430f7137b"
        },
        "downloads": -1,
        "filename": "gpas_testing-1.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "14bfb4522edbcdeef83c36984ba10458",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 3164452,
        "upload_time": "2022-07-25T10:44:26",
        "upload_time_iso_8601": "2022-07-25T10:44:26.790077Z",
        "url": "https://files.pythonhosted.org/packages/a2/af/bf81d62c6dfe69a2bf1c8edb48d940b4062ffaf13100ce1089a9e6a0be93/gpas_testing-1.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ccee0c89f74c74952b4f8be97fce72df92e211d071df439b77a6ffe5a47f6df5",
          "md5": "2899077cc6592bef7cc5eb324138f501",
          "sha256": "86bb19bb72fc75d190b0d6cda8093113df98ba7f5c243689b63a48843c5081b0"
        },
        "downloads": -1,
        "filename": "gpas_testing-1.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "2899077cc6592bef7cc5eb324138f501",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 3159980,
        "upload_time": "2022-07-25T10:44:33",
        "upload_time_iso_8601": "2022-07-25T10:44:33.683067Z",
        "url": "https://files.pythonhosted.org/packages/cc/ee/0c89f74c74952b4f8be97fce72df92e211d071df439b77a6ffe5a47f6df5/gpas_testing-1.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "a2afbf81d62c6dfe69a2bf1c8edb48d940b4062ffaf13100ce1089a9e6a0be93",
        "md5": "14bfb4522edbcdeef83c36984ba10458",
        "sha256": "dcb5dfa03d237d4e25aacff69b3dea742fb1aff61304b82c8c8009d430f7137b"
      },
      "downloads": -1,
      "filename": "gpas_testing-1.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "14bfb4522edbcdeef83c36984ba10458",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 3164452,
      "upload_time": "2022-07-25T10:44:26",
      "upload_time_iso_8601": "2022-07-25T10:44:26.790077Z",
      "url": "https://files.pythonhosted.org/packages/a2/af/bf81d62c6dfe69a2bf1c8edb48d940b4062ffaf13100ce1089a9e6a0be93/gpas_testing-1.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "ccee0c89f74c74952b4f8be97fce72df92e211d071df439b77a6ffe5a47f6df5",
        "md5": "2899077cc6592bef7cc5eb324138f501",
        "sha256": "86bb19bb72fc75d190b0d6cda8093113df98ba7f5c243689b63a48843c5081b0"
      },
      "downloads": -1,
      "filename": "gpas_testing-1.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "2899077cc6592bef7cc5eb324138f501",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 3159980,
      "upload_time": "2022-07-25T10:44:33",
      "upload_time_iso_8601": "2022-07-25T10:44:33.683067Z",
      "url": "https://files.pythonhosted.org/packages/cc/ee/0c89f74c74952b4f8be97fce72df92e211d071df439b77a6ffe5a47f6df5/gpas_testing-1.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}