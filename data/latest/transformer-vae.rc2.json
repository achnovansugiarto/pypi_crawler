{
  "info": {
    "author": "Fraser Greenlee",
    "author_email": "fraser.greenlee@mac.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Transformer-VAE (WIP)\n\n![Diagram of the a State Autoencoder](https://github.com/Fraser-Greenlee/transformer-vae/blob/v1/t5-vae.png)\n\nTransformer-VAE's learn smooth latent spaces of discrete sequences without any explicit rules in their decoders.\n\nThis can be used for program synthesis, drug discovery, music generation and much more!\n\nTo see how it works checkout [this blog post](https://fraser-greenlee.github.io/2020/08/13/Transformers-as-Variational-Autoencoders.html).\n\nThis repo is in active development but I should be coming out with full a release soon.\n\n## Install\n\nInstall using pip:\n```\npip install transformer_vae\n```\n\n## Usage\n\nYou can exececute the module to easily train it on your own data.\n```bash\npython -m transformer_vae \\\n    --project_name=\"T5-VAE\" \\\n    --output_dir=poet \\\n    --do_train \\\n    --huggingface_dataset=poems \\\n```\nOr you can import Transformer-VAE to use as a package much like a Huggingface model.\n```python\nfrom transformer_vae import T5_VAE_Model\n\nmodel = T5_VAE_Model.from_pretrained('t5-vae-poet')\n```\n## Training\nSetup [Weights & Biasis](https://app.wandb.ai/) for logging, see [client](https://github.com/wandb/client).\n\nGet a dataset to model, must be represented with text. This is what we will be interpolating over.\n\nThis can be a text file with each line representing a sample.\n```bash\npython -m transformer_vae \\\n    --project_name=\"T5-VAE\" \\\n    --output_dir=poet \\\n    --do_train \\\n    --train_file=poems.txt \\\n```\nAlternatively seperate each sample with a line containing only `<|endoftext|>` seperating samples:\n```bash\npython -m transformer_vae \\\n    --project_name=\"T5-VAE\" \\\n    --output_dir=poet \\\n    --do_train \\\n    --train_file=poems.txt \\\n    --multiline_samples\n```\nAlternatively provide a Huggingface dataset.\n```bash\npython -m transformer_vae \\\n    --project_name=\"T5-VAE\" \\\n    --output_dir=poet \\\n    --do_train \\\n    --dataset=poems \\\n    --content_key text\n```\n\nExperiment with different parameters.\n\nOnce finished upload to huggingface model hub.\n\n```bash\n# TODO\n```\n\nExplore the produced latent space using `Colab_T5_VAE.ipynb` or vising this [Colab page](TODO).\n\n### Contributing\n\nInstall with tests:\n```\npip install -e .[test]\n```\n\nPossible contributions to make:\n1. Could the docs be more clear? Would it be worth having a docs site/blog?\n2. Use a Funnel transformer encoder, is it more efficient?\n3. Allow defining alternative tokens set.\n4. Store the latent codes from the previous step to use in MMD loss so smaller batch sizes are possible.\n\nFeel free to ask what would be useful!\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/Fraser-Greenlee/transformer-vae",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "transformer-vae",
    "package_url": "https://pypi.org/project/transformer-vae/",
    "platform": "",
    "project_url": "https://pypi.org/project/transformer-vae/",
    "project_urls": {
      "Homepage": "https://github.com/Fraser-Greenlee/transformer-vae"
    },
    "release_url": "https://pypi.org/project/transformer-vae/0.0.2/",
    "requires_dist": [
      "datasets (==1.1.3)",
      "transformers (==4.1.1)",
      "wandb (>=0.10.12)",
      "torch (==1.7.0)",
      "sklearn",
      "bert-score",
      "pytest ; extra == 'test'",
      "flake8 ; extra == 'test'",
      "flake8-mypy ; extra == 'test'",
      "black ; extra == 'test'",
      "twine ; extra == 'test'"
    ],
    "requires_python": ">=3.6",
    "summary": "Interpolate between discrete sequences.",
    "version": "0.0.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8931415,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "10721bbe3f0634f1d754518e7884ba88e686044765e9b289263f3cfd8e448fdf",
          "md5": "004275f51e0c8d25c9c38e4a2c4a63ea",
          "sha256": "bfefa62b9005fd549aad48e7e9a122b15fbedbdde552a00f97835c40c60ef88a"
        },
        "downloads": -1,
        "filename": "transformer_vae-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "004275f51e0c8d25c9c38e4a2c4a63ea",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 27416,
        "upload_time": "2020-12-17T21:43:47",
        "upload_time_iso_8601": "2020-12-17T21:43:47.545169Z",
        "url": "https://files.pythonhosted.org/packages/10/72/1bbe3f0634f1d754518e7884ba88e686044765e9b289263f3cfd8e448fdf/transformer_vae-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "67882240e8898a93cffdfd0c7b42a74710eb1945750e609b4dd0a2bee4a213f5",
          "md5": "c99a56aa398931a6a4c75da2da029487",
          "sha256": "f4ca46d47e651368f2fe5f75bb9731ef697354d61d8856051797470d073eec78"
        },
        "downloads": -1,
        "filename": "transformer_vae-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "c99a56aa398931a6a4c75da2da029487",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 24239,
        "upload_time": "2020-12-17T21:43:48",
        "upload_time_iso_8601": "2020-12-17T21:43:48.874321Z",
        "url": "https://files.pythonhosted.org/packages/67/88/2240e8898a93cffdfd0c7b42a74710eb1945750e609b4dd0a2bee4a213f5/transformer_vae-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0710d0d7557be61bcd71b30e847d3a77b31304cd48ae689c086fc984fe017612",
          "md5": "2f5523b8d9c653853bf7fafa113ebd54",
          "sha256": "2ea8a09b9c518a9e91c0752f3af404f9de11c972651da047654fa46deeb782da"
        },
        "downloads": -1,
        "filename": "transformer_vae-0.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "2f5523b8d9c653853bf7fafa113ebd54",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 27441,
        "upload_time": "2020-12-18T08:39:33",
        "upload_time_iso_8601": "2020-12-18T08:39:33.390253Z",
        "url": "https://files.pythonhosted.org/packages/07/10/d0d7557be61bcd71b30e847d3a77b31304cd48ae689c086fc984fe017612/transformer_vae-0.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0a73d1be69980961f9001beaadf70f10e5f36a418c74f2ab88753d299d3b1f31",
          "md5": "2ae8834b55f06e8f6168912470bcc715",
          "sha256": "d89d5f03a5f2753ed24f922e1e09fe7e84902ceb45ba35e1b8765cca8660d7b6"
        },
        "downloads": -1,
        "filename": "transformer_vae-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "2ae8834b55f06e8f6168912470bcc715",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 24288,
        "upload_time": "2020-12-18T08:39:34",
        "upload_time_iso_8601": "2020-12-18T08:39:34.553621Z",
        "url": "https://files.pythonhosted.org/packages/0a/73/d1be69980961f9001beaadf70f10e5f36a418c74f2ab88753d299d3b1f31/transformer_vae-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "0710d0d7557be61bcd71b30e847d3a77b31304cd48ae689c086fc984fe017612",
        "md5": "2f5523b8d9c653853bf7fafa113ebd54",
        "sha256": "2ea8a09b9c518a9e91c0752f3af404f9de11c972651da047654fa46deeb782da"
      },
      "downloads": -1,
      "filename": "transformer_vae-0.0.2-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "2f5523b8d9c653853bf7fafa113ebd54",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 27441,
      "upload_time": "2020-12-18T08:39:33",
      "upload_time_iso_8601": "2020-12-18T08:39:33.390253Z",
      "url": "https://files.pythonhosted.org/packages/07/10/d0d7557be61bcd71b30e847d3a77b31304cd48ae689c086fc984fe017612/transformer_vae-0.0.2-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "0a73d1be69980961f9001beaadf70f10e5f36a418c74f2ab88753d299d3b1f31",
        "md5": "2ae8834b55f06e8f6168912470bcc715",
        "sha256": "d89d5f03a5f2753ed24f922e1e09fe7e84902ceb45ba35e1b8765cca8660d7b6"
      },
      "downloads": -1,
      "filename": "transformer_vae-0.0.2.tar.gz",
      "has_sig": false,
      "md5_digest": "2ae8834b55f06e8f6168912470bcc715",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 24288,
      "upload_time": "2020-12-18T08:39:34",
      "upload_time_iso_8601": "2020-12-18T08:39:34.553621Z",
      "url": "https://files.pythonhosted.org/packages/0a/73/d1be69980961f9001beaadf70f10e5f36a418c74f2ab88753d299d3b1f31/transformer_vae-0.0.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}