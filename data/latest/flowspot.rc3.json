{
  "info": {
    "author": "Minghao Jiang",
    "author_email": "jiangminghao@iie.ac.cn",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# traffic_classification_utils\r\n## Introduction\r\nThis project organizes and summarizes the common methods in encrypted traffic classification, and provides the execution entry of each method. When using it, you only need to preprocess your own data as required, put it in a specified directory, and then run the entry main function of the corresponding model. This project is particularly helpful for researchers to conduct comparative experiments. Now that one of my papers has been accepted, so I open the source this project and share it with everyone!\r\n\r\nCurrently this project only integrates related models based on packet length sequences, ** payload-based models are not discussed**!\r\n\r\n## URL\r\nhttps://github.com/jmhIcoding/traffic_classification_utils\r\n## Project Highlights\r\n### Embedded multiple models for encrypted traffic classification\r\nCurrently this project supports the following models:\r\n\r\n#### deep learning based models\r\n- FS-Net\r\nLiu, C., He, L., Xiong, G., Cao, Z., & Li, Z. (2019, April). Fs-net: A flow sequence network for encrypted traffic classification. In IEEE INFOCOM 2019-IEEE Conference On Computer Communications (pp. 1171-1179). IEEE.\r\n\r\n- GraphDapp\r\nShen, M., Zhang, J., Zhu, L., Xu, K., & Du, X. (2021). Accurate decentralized application identification via encrypted traffic analysis using graph neural networks. IEEE Transactions on Information Forensics and Security, 16, 2367-2380.\r\n\r\n- Deep Fingerprinting \r\nSirinam, P., Imani, M., Juarez, M., & Wright, M. (2018, October). Deep fingerprinting: Undermining website fingerprinting defenses with deep learning. In Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security (pp. 1928-1943).\r\n\r\n- SDAE/LSTM/CNN \r\nRimmer, V., Preuveneers, D., Juarez, M., Van Goethem, T., & Joosen, W. Automated Website Fingerprinting through Deep Learning.\r\n\r\n- Beauty\r\nSchuster, R., Shmatikov, V., & Tromer, E. (2017). Beauty and the burst: Remote identification of encrypted video streams. In 26th USENIX Security Symposium (USENIX Security 17) (pp. 1357-1374).\r\n\r\n\r\n#### statistical achine learning based models\r\n\r\n- CUMUL\r\nPanchenko, A., Lanze, F., Pennekamp, J., Engel, T., Zinnen, A., Henze, M., & Wehrle, K. (2016, February). Website Fingerprinting at Internet Scale. In NDSS.\r\n\r\n- AppScanner\r\nTaylor, V. F., Spolaor, R., Conti, M., & Martinovic, I. (2016, March). Appscanner: Automatic fingerprinting of smartphone apps from encrypted network traffic. In 2016 IEEE European Symposium on Security and Privacy (EuroS&P) (pp. 439-454). IEEE.\r\n\r\n- BIND\r\nAl-Naami, K., Chandra, S., Mustafa, A., Khan, L., Lin, Z., Hamlen, K., & Thuraisingham, B. (2016, December). Adaptive encrypted traffic fingerprinting with bi-directional dependence. In Proceedings of the 32nd Annual Conference on Computer Security Applications (pp. 177-188).\r\n\r\n- RDP\r\nJiang, M., Gou, G., Shi, J., & Xiong, G. (2019, October). I know what you are doing with remote desktop. In 2019 IEEE 38th International Performance Computing and Communications Conference (IPCCC) (pp. 1-7). IEEE.\r\n\r\n\r\n\r\n# Guide for use\r\nIn order to minimize our workload using existing methods, for a new encrypted traffic analysis task, we need to do two things:\r\n![在这里插入图片描述](https://img-blog.csdnimg.cn/ff4d88e003af4a54a4f8e85226690e9b.png)\r\n\r\n 1. \r\n Convert the dataset in your hand into a unified json format folder, which is the dataset directory shown in the above figure. You can save your own dataset to this directory after conversion. This conversion is particularly simple, just follow the convention. Whether it is raw pcap file traffic, log files, etc., it can be easily converted.\r\n 2. \r\n Jump to the corresponding model directory, which is the models directory in the above picture, modify the dataset field in xxx_main.py, and use run.sh to execute the corresponding xxx_main.py.\r\n\r\n**Why do you need to convert the data in advance? Why is there no one-click scripting? **\r\n\r\nA: Because the data formats that everyone gets are all kinds of strange, there are pcap, there are logs, and each person's own data organization form is also different, so I can't write a unified data conversion script to unify everyone's situation. Therefore, I leave the task of this data conversion to the users themselves, because only the data holders know the format of their data best, and I just agree on the target format after conversion.\r\n\r\n**Why use the run.sh script to execute xxx_main.py?**\r\nAt present, you need to use run.sh, which contains some processes for loading the environment directory.\r\n\r\n\r\n## Data preparation\r\nBecause all sequence models are considered in this project, it is only necessary to prepare information such as the packet length sequence and packet direction sequence of the data stream.\r\n\r\nData path: `dataset/{dataset name}/{category name}.json`\r\n\r\n## Description of dataset name\r\nIn the dataset directory, each subdirectory is a dataset of a task, and each task is distinguished by a folder. For example, there are currently two different datasets: app60, app320.\r\n![在这里插入图片描述](https://img-blog.csdnimg.cn/c9e64cb27ed041b59e3d90c99efa3fbb.png)\r\n\r\nIf you want to add a new dataset, create a new folder and give the dataset a name you like.\r\n\r\n### Category name description\r\nEnter the specified data set, and the traffic samples of each category are uniformly placed in the same json file. Therefore, there are m different jsons in this directory, then m classification will be performed, and the file name of json is the ground-truth label of the traffic sample in it.\r\n\r\n![在这里插入图片描述](https://img-blog.csdnimg.cn/0b3f8431d3e34492a8aa68490729e601.png)\r\n\r\nThe format of the traffic samples within each json file is as follows:\r\n\r\n```bash\r\n[\r\n{//第一个样本\r\n\"packet_length\": 包长序列,\r\n\"arrive_time_delta\": 相邻数据包的到达时间间隔\r\n},\r\n{//第二个样本\r\n\"packet_length\": 包长序列,\r\n\"arrive_time_delta\": 相邻数据包的到达时间间隔\r\n},\r\n]\r\n```\r\nThere are two main points to note:\r\n1. A json file contains a large list, and each element in the list corresponds to a network flow. If there are n elements in the list, it means that there are n traffic samples in this class.\r\n\r\n2. Each traffic is a dict with a key field: **packet_length**, the packet length sequence. If you also need to use the BIND model, the **arrive_time_delta** field is also essential. The packet length sequence is signed, and the sign indicates the direction of the data packet. A positive sign indicates that the package is sent by the Client to the Server, and a negative sign indicates that the Sever sends it to the Client. The sign is reserved because some models require this information.\r\n\r\nExample: The json below contains two samples.\r\n\r\n```bash\r\n[\r\n  {\r\n    \"packet_length\": [\r\n      194,\r\n      -1424,\r\n      -32,\r\n      53,\r\n      86,\r\n      154,\r\n      -274,\r\n      -308,\r\n      38,\r\n      110,\r\n      -204\r\n    ],\r\n    \"arrive_time_delta\": [\r\n      0,\r\n      0.0000030994415283203125,\r\n      0.00014519691467285156,\r\n      0.05950021743774414,\r\n      0.05950307846069336,\r\n      0.05950617790222168,\r\n      1.0571942329406738,\r\n      1.0572030544281006,\r\n      1.0572071075439453,\r\n      1.0572102069854736,\r\n      2.637423038482666\r\n    ]\r\n  },\r\n  {\r\n    \"packet_length\": [\r\n      177,\r\n      -1424,\r\n      -1440,\r\n      -32,\r\n      -1448,\r\n      -99,\r\n      126,\r\n      852,\r\n      -258,\r\n      -317\r\n    ],\r\n    \"arrive_time_delta\": [\r\n      0,\r\n      0.000030994415283203125,\r\n      0.0039768218994140625,\r\n      0.009712934494018555,\r\n      0.00972294807434082,\r\n      0.35946083068847656,\r\n      0.35947394371032715,\r\n      0.35948801040649414,\r\n      0.3595008850097656,\r\n      1.3806648254394531\r\n    ]\r\n  }\r\n]\r\n```\r\n\r\n## run the model\r\nCurrently I have all the models in separate folders under the models directory.\r\nThe directory is as follows. If you need any model, `cd` to the corresponding directory.\r\n```bash\r\n.\r\n├─models\r\n│  ├─dl\r\n│  │  ├─awf_dataset_util\r\n│  │  ├─beauty\r\n│  │  ├─cnn\r\n│  │  ├─df\r\n│  │  ├─df_only_D\r\n│  │  ├─fsnet\r\n│  │  ├─graphDapp\r\n│  │  ├─lstm\r\n│  │  ├─sdae\r\n│  │  ├─varcnn\r\n│  ├─ml\r\n│  │  ├─appscanner\r\n│  │  ├─bind\r\n│  │  ├─cumul\r\n│  │  ├─rdp\r\n```\r\nIn the directory of each model, there is an entry script of xxx_main_model.py, and a data directory. For example, the directory structure under the appscanner model:\r\n\r\n```bash\r\nappscanner\r\n│  appscanner_main_model.py  ###an entry script\r\n│  eval.py\r\n│  feature_extractor.py\r\n│  hyper_params.py\r\n│  min_max.py\r\n│  model.py\r\n│  README\r\n│  train.py\r\n│  __init__.py\r\n│  【1】AppScanner.pdf\r\n│\r\n├─data\t\t\t\t##history models and datas\r\n│  │  appscanner_app60_model\r\n│  ├─appscanner_app60  ##the training-set, testing-set\r\n│  │      X_test.pkl\r\n│  │      X_train.pkl\r\n│  │      X_valid.pkl\r\n│  │      y_test.pkl\r\n│  │      y_train.pkl\r\n│  │      y_valid.pkl\r\n│  │\r\n```\r\n\r\n`appscanner_main_model.py` is the entry of the appscanner model, you only need to modify the last few lines in it:\r\n\r\n```python\r\nif __name__ == '__main__':\r\n   appscanner = model('app60') ##Specify the dataset name required by the task. The dataset directory of the project needs to have this dataset directory.\r\n   #appscanner.parser_raw_data()  ##Re-parse the raw traffic samples in the dataset directory and re-convert to the specific data format required by the model.\r\n   appscanner.train()  ###Train the model\r\n   appscanner.test()   ###Test the model\r\n```\r\nFor each model class, when instantiating, you need to specify what dataset is used. During initialization, the system will automatically detect whether the data set has been processed in history (mainly to check whether there are corresponding test sets, training sets and model files in the data directory), if not, the original data will be formatted in one step Transform, divide test set, training set.\r\n\r\nThis process is done by calling parser_raw_data()! parser_raw_data() will re-shuffle the data as soon as it is executed, which is generally used for cross-validation!\r\n\r\nThen use the run.sh script to execute this `appscanner_main_model.py`, and run.sh is at the root of the entire project.\r\n```bash\r\n./../../../run.sh appscanner_main_model.py\r\n```\r\n\r\n\r\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/jmhIcoding/traffic_classification_utils",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "flowspot",
    "package_url": "https://pypi.org/project/flowspot/",
    "platform": null,
    "project_url": "https://pypi.org/project/flowspot/",
    "project_urls": {
      "Homepage": "https://github.com/jmhIcoding/traffic_classification_utils"
    },
    "release_url": "https://pypi.org/project/flowspot/1.2/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "A python lib to parse traffic flow information from pcaps",
    "version": "1.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17144452,
  "releases": {
    "1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a634bac202a82f4c8c55d401d995cfd08f170b7a4478c283808961d2bf332ea7",
          "md5": "7a3780760f099cd1a0dbd4117429cd62",
          "sha256": "75ab54045ef05fe8c756068139893e68aed318bc5ff1bba40dbd87437a79e9e1"
        },
        "downloads": -1,
        "filename": "flowspot-1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "7a3780760f099cd1a0dbd4117429cd62",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 13498,
        "upload_time": "2023-03-03T13:42:42",
        "upload_time_iso_8601": "2023-03-03T13:42:42.620701Z",
        "url": "https://files.pythonhosted.org/packages/a6/34/bac202a82f4c8c55d401d995cfd08f170b7a4478c283808961d2bf332ea7/flowspot-1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3b39d235bbe1107e5310b45ebb8a276848cd02a4e3542b8d71c771053bfc5b45",
          "md5": "96a7b4fb84b1a31497050973bf45a9fa",
          "sha256": "33cef3fbc6c7a4cb371c6639630bbbf9fcfa6d4432696171cc0239d19d14405e"
        },
        "downloads": -1,
        "filename": "flowspot-1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "96a7b4fb84b1a31497050973bf45a9fa",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 24021,
        "upload_time": "2023-03-03T13:47:44",
        "upload_time_iso_8601": "2023-03-03T13:47:44.022368Z",
        "url": "https://files.pythonhosted.org/packages/3b/39/d235bbe1107e5310b45ebb8a276848cd02a4e3542b8d71c771053bfc5b45/flowspot-1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d794c3c151ced2d59824f5ac5537e649f01d12ace1317a3b5e76726713ef482b",
          "md5": "d0df29c8610011cbc840fe838eaea9c9",
          "sha256": "19b4566da11936ddb6ce0eb199141af27c01d2b3716348065aaa21ab1e95394b"
        },
        "downloads": -1,
        "filename": "flowspot-1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "d0df29c8610011cbc840fe838eaea9c9",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 25625,
        "upload_time": "2023-03-03T13:48:53",
        "upload_time_iso_8601": "2023-03-03T13:48:53.343239Z",
        "url": "https://files.pythonhosted.org/packages/d7/94/c3c151ced2d59824f5ac5537e649f01d12ace1317a3b5e76726713ef482b/flowspot-1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "d794c3c151ced2d59824f5ac5537e649f01d12ace1317a3b5e76726713ef482b",
        "md5": "d0df29c8610011cbc840fe838eaea9c9",
        "sha256": "19b4566da11936ddb6ce0eb199141af27c01d2b3716348065aaa21ab1e95394b"
      },
      "downloads": -1,
      "filename": "flowspot-1.2.tar.gz",
      "has_sig": false,
      "md5_digest": "d0df29c8610011cbc840fe838eaea9c9",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 25625,
      "upload_time": "2023-03-03T13:48:53",
      "upload_time_iso_8601": "2023-03-03T13:48:53.343239Z",
      "url": "https://files.pythonhosted.org/packages/d7/94/c3c151ced2d59824f5ac5537e649f01d12ace1317a3b5e76726713ef482b/flowspot-1.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}