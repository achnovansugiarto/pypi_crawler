{
  "info": {
    "author": "laohur",
    "author_email": "laohur@gmail.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# UnicodeTokenizer\n\nUnicodeTokenizer: tokenize all Unicode text, tokenize blank char as a token as default\n\n## 切词规则 Tokenize Rules\n* 空白切分 split on blank： '\\n', ' ', '\\t'\n* 保留关键词 keep never_splits\n* 若小写，则规范化：全角转半角，则NFD规范化，再字符分割  nomalize if lower：full2half，nomalize NFD, then chars split \n    - 类别为M，略过 ingore if category M ： category M -> ''\n* 字符分割 chars split： 以字的符号类别和语言分割 split line by category and languae of characters\n    - 只有临近数字成词 only numers joind\n    - 只有临近字母成词 only letters joind \n    - 高码点独字  split high UnicodePoint characters\n\n* 截断 max_len\n\n\n## use\n> pip install UnicodeTokenizer\n\n```python\nfrom UnicodeTokenizer import UnicodeTokenizer\ntokenizer=UnicodeTokenizer()\n\ndoc0 = \"\"\" \n        首先8.88设置 st。art_new_word=True 和 output=[açaí]，output 就是最终 no such name\"\n        的输出คุณจะจัดพิธีแต่งงานเมื่อไรคะ탑승 수속해야pneumonoultramicroscopicsilicovolcanoconiosis\"\n        하는데 카운터가 어디에 있어요ꆃꎭꆈꌠꊨꏦꏲꅉꆅꉚꅉꋍꂷꂶꌠلأحياء تمارين تتطلب من [MASK] [PAD] [CLS][SEP]\n        est 𗴂𗹭𘜶𗴲𗂧, ou \"phiow-bjij-lhjij-lhjij\", ce que l'on peut traduire par « pays-grand-blanc-élevé » (白高大夏國). \n    \"\"\"\nprint(tokenizer.tokenize(doc0))\n```\n\n## result \n| sentence                                                                                                                                                                                                                                                                                                          | UnicodeTokenizer                                                                                                                                                                                                                                                                                                                                                                                                                                          | Unicode Tokens Length | BertBasicTokenizer                                                                                                                                                                                                                                                                                                 | Bert Tokens length |\n|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------|\n| Ⅷ首先8.88设置 st。art_new_word=True 和 output=[açaí]，output 就是最终 no such name                                                                                                                                                                                                                              | ⅷ 首 先 8 . 88 设 置 st 。 art _ new _ word = true 和 output = [ ac a i ] ， output 就 是 最 终    no such name                                                                                                                                                                                                                                                                                                                                         | 37                    | ⅷ 首 先 8 . 88 设 置 st 。 art _ new _ word = true 和 output = [ acai ] ， output 就 是 最 终 no such name                                                                                                                                                                                                         | 32                 |\n| 的输出คุณจะจัดพิธีแต่งงานเมื่อไรคะ탑승 수속해야pneumonoultramicroscopicsilicovolcanoconiosis                                                                                                                                                                                                                             | 的 输 出 ค ณ จะจ ด พ ธ แ ต ง งานเม อ ไรคะ 탑승 수속해야 pneumonoultramicroscopicsilicovolcanoconiosis                                                                                                                                                                                                                                                                                                                                                     | 18                    | 的 输 出 คณจะจดพธแตงงานเมอไรคะ탑승 수속해야pneumonoultramicroscopicsilicovolcanoconiosis                                                                                                                                                                                                                           | 5                  |\n| 하는데 카운터가 어디에 있어요ꆃꎭꆈꌠꊨꏦꏲꅉꆅꉚꅉꋍꂷꂶꌠلأحياء تمارين تتطلب من [MASK] [PAD] [CLS][SEP]                                                                                                                                                                                                         | 하는데 카운터가 어디에 있어요 ꆃ ꎭ ꆈ ꌠ ꊨ ꏦ ꏲ ꅉ ꆅ ꉚ ꅉ ꋍ ꂷ ꂶ ꌠ لا ح ياء تمارين تتطلب من [MASK] [PAD] [ cls ] [ sep ]                                                                                                                                                                                                                                                                                                                          | 33                    | 하는데 카운터가 어디에 있어요ꆃꎭꆈꌠꊨꏦꏲꅉꆅꉚꅉꋍꂷꂶꌠلاحياء تمارين تتطلب من [MASK] [PAD] [ cls ] [ sep ]                                                                                                                                                                                                     | 15                 |\n| est 𗴂𗹭𘜶𗴲𗂧, ou \"phiow-bjij-lhjij-lhjij\", ce que l'on peut traduire par « pays-grand-blanc-élevé » (白高大夏國).                                                                                                                                                                                                    | est 𗴂 𗹭 𘜶 𗴲 𗂧 , ou \" phiow - bjij - lhjij - lhjij \" , ce que l ' on peut traduire par « pays - grand - blanc - e l eve » ( 白 高 大 夏 國 ) .                                                                                                                                                                                                                                                                                                             | 45                    | est 𗴂𗹭𘜶𗴲𗂧 , ou \" phiow - bjij - lhjij - lhjij \" , ce que l ' on peut traduire par « pays - grand - blanc - eleve » ( 白 高 大 夏 國 ) .                                                                                                                                                                            | 39                 |\n| วรรณพงษ์เป็นนักศึกษาชั้นปีที่หนึ่ง เรียนสาขาวิทยาการคอมพิวเตอร์และสารสนเทศคณะวิทยาศาสตร์ประยุกต์และวิศวกรรมศาสตร์อยู่ที่มหาวิทยาลัยขอนแก่นวิทยาเขตหนองคายยืมคืนทรัพยากรห้องสมุดเอกสารสัมมนาคอมพิวเตอร์ปัญญาประดิษฐ์กับการพัฒนาเกมแมวกินปลาหิวววไหมหลักสูตรใหม่สดสดทนได้                                                                                           | วรรณพงษ เ ป น น ก ศ ก ษาช น ป ท ห น ง เร ย นสาขาว ท ยาการคอมพ ว เตอร แ ละสารสนเทศคณะว ท ยาศาสตร ป ระย ก ต แ ละว ศ วกรรมศาสตร อ ย ท ม หาว ท ยาล ย ขอนแก น ว ท ยาเขตหนองคายย ม ค น ทร พ ยากรห อ งสม ด เอกสารส ม มนาคอมพ ว เตอร ป ญ ญาประด ษ ฐ ก บ การพ ฒ นาเกมแมวก น ปลาห ว ววไหมหล ก ส ต รใหม ส ดสดทนได                                                                                                                                                    | 81                    | วรรณพงษเปนนกศกษาชนปทหนง เรยนสาขาวทยาการคอมพวเตอรและสารสนเทศคณะวทยาศาสตรประยกตและวศวกรรมศาสตรอยทมหาวทยาลยขอนแกนวทยาเขตหนองคายยมคนทรพยากรหองสมดเอกสารสมมนาคอมพวเตอรปญญาประดษฐกบการพฒนาเกมแมวกนปลาหวววไหมหลกสตรใหมสดสดทนได                                                                                            | 2                  |\n| ສົມເດັດພະເຈົ້າຢູ່ຫົວບໍຣົມໂກດຊົງທຳນຸບຳລຸງບ້ານເມືອງແລະພະສາດສະໜາຈົນກ່າວໄດ້ວ່າກຸງສີອະຍຸທະຢາໃນສະໄໝພະອົງນັ້ນເປັນຍຸກທີ່ບ້ານເມືອງດີ ມີຂຸນນາງຄົນສຳຄັນທີ່ເຕີບໂຕໃນເວລາຕໍ່ມາ ໃນລາຊະການຂອງພະອົງຫຼາຍຄົນ ເຊັ່ນ ສົມເດັດພະເຈົ້າກຸງທົນບຸລີ, ພະບາດສົມເດັດພະພຸດທະຍອດຟ້າຈຸລາໂລກມະຫາລາດ ເປັນຕົ້ນ ໃນທາງດ້ານວັນນະຄະດີກໍມີກະວີຄົນສຳຄັນ ເຊັ່ນ ເຈົ້າຟ້າທຳມາທິເບດໄຊຍະເຊດສຸລິຍະວົງ ກົມມະຂຸນເສນາພິທັກ ຫຼືເຈົ້າຟ້າກຸ້ງ ເຊິ່ງເປັນພະໂອລົດ ເປັນຕົ້ນ | ສ ມ ເດ ດ ພະເຈ າ ຢ ຫ ວ ບ ຣ ມ ໂກດຊ ງ ທຳນ ບ ຳລ ງ ບ າ ນເມ ອ ງແລະພະສາດສະໜາຈ ນ ກ າ ວໄດ ວ າ ກ ງ ສ ອ ະຍ ທ ະຢາໃນສະໄໝພະອ ງ ນ ນ ເປ ນ ຍ ກ ທ ບ າ ນເມ ອ ງດ ມ ຂ ນ ນາງຄ ນ ສຳຄ ນ ທ ເ ຕ ບ ໂຕໃນເວລາຕ ມ າ ໃນລາຊະການຂອງພະອ ງ ຫ າ ຍຄ ນ ເຊ ນ ສ ມ ເດ ດ ພະເຈ າ ກ ງ ທ ນ ບ ລ , ພະບາດສ ມ ເດ ດ ພະພ ດ ທະຍອດຟ າ ຈ ລ າໂລກມະຫາລາດ ເປ ນ ຕ ນ ໃນທາງດ າ ນວ ນ ນະຄະດ ກ ມ ກ ະວ ຄ ນ ສຳຄ ນ ເຊ ນ ເຈ າ ຟ າ ທຳມາທ ເ ບດໄຊຍະເຊດສ ລ ຍ ະວ ງ ກ ມ ມະຂ ນ ເສນາພ ທ ກ ຫ ເ ຈ າ ຟ າ ກ ງ ເຊ ງ ເປ ນ ພະໂອລ ດ ເປ ນ ຕ ນ | 150                   | ສມເດດພະເຈາຢຫວບຣມໂກດຊງທຳນບຳລງບານເມອງແລະພະສາດສະໜາຈນກາວໄດວາກງສອະຍທະຢາໃນສະໄໝພະອງນນເປນຍກທບານເມອງດ ມຂນນາງຄນສຳຄນທເຕບໂຕໃນເວລາຕມາ ໃນລາຊະການຂອງພະອງຫາຍຄນ ເຊນ ສມເດດພະເຈາກງທນບລ , ພະບາດສມເດດພະພດທະຍອດຟາຈລາໂລກມະຫາລາດ ເປນຕນ ໃນທາງດານວນນະຄະດກມກະວຄນສຳຄນ ເຊນ ເຈາຟາທຳມາທເບດໄຊຍະເຊດສລຍະວງ ກມມະຂນເສນາພທກ ຫເຈາຟາກງ ເຊງເປນພະໂອລດ ເປນຕນ | 15                 |\n\n## reference\n* Unicode Blocks  https://www.unicode.org/Public/UCD/latest/ucd/Blocks.txt\n* unicodedata.category https://www.unicode.org/reports/tr44/  #Table 12. General_Category Values\n* BertTokenization https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/LanguageModeling/BERT/tokenization.py\n\n\n## License\n[Anti-996 License](https://github.com/996icu/996.ICU/blob/master/LICENSE)\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/laohur/UnicodeTokenizer",
    "keywords": "UnicodeTokenizer,Tokenizer,Unicode,ZiTokenizer,ZiCutter,laohur",
    "license": "[Anti-996 License](https: // github.com/996icu/996.ICU/blob/master/LICENSE)",
    "maintainer": "",
    "maintainer_email": "",
    "name": "UnicodeTokenizer",
    "package_url": "https://pypi.org/project/UnicodeTokenizer/",
    "platform": null,
    "project_url": "https://pypi.org/project/UnicodeTokenizer/",
    "project_urls": {
      "Homepage": "https://github.com/laohur/UnicodeTokenizer"
    },
    "release_url": "https://pypi.org/project/UnicodeTokenizer/0.1.10/",
    "requires_dist": null,
    "requires_python": ">=3.0",
    "summary": "UnicodeTokenizer: tokenize all Unicode text",
    "version": "0.1.10",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17259660,
  "releases": {
    "0.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "05f7320fe71db95a096c6a6aea800053db81f686e6402ee5e2710ce75020a53f",
          "md5": "76a084e3ca3d987a892eed0f7ba16e7f",
          "sha256": "9af978b00e80079b336b25531119fbb2ad05beb0cabb87b796ba0b0ac412fbc3"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "76a084e3ca3d987a892eed0f7ba16e7f",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 5453,
        "upload_time": "2022-06-25T12:26:44",
        "upload_time_iso_8601": "2022-06-25T12:26:44.146089Z",
        "url": "https://files.pythonhosted.org/packages/05/f7/320fe71db95a096c6a6aea800053db81f686e6402ee5e2710ce75020a53f/UnicodeTokenizer-0.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "99c02f0c9e1644c2626e863848c527624bb74d637834dd8fcfe9ffb34d5667e5",
          "md5": "ccd9d0f850bf3c0bc7cca1161af622cf",
          "sha256": "285afd28905e9273d44bf4af77146e0be5c934bf45a6b785e2f3f8fdf71e4eb1"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "ccd9d0f850bf3c0bc7cca1161af622cf",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 5663,
        "upload_time": "2022-06-25T12:26:46",
        "upload_time_iso_8601": "2022-06-25T12:26:46.239584Z",
        "url": "https://files.pythonhosted.org/packages/99/c0/2f0c9e1644c2626e863848c527624bb74d637834dd8fcfe9ffb34d5667e5/UnicodeTokenizer-0.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "edffc580a30f96537b9103008479f77e68c3dc4dae05fb6649d7982e3195f9b4",
          "md5": "338cb4673244f8b9f6ee4ad1723195fc",
          "sha256": "d319469ee74add7311bcd5bff441b5130879f53d37b126db51b9264da370e7e4"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.1-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "338cb4673244f8b9f6ee4ad1723195fc",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": ">=3.0",
        "size": 30503,
        "upload_time": "2022-06-26T14:14:54",
        "upload_time_iso_8601": "2022-06-26T14:14:54.659198Z",
        "url": "https://files.pythonhosted.org/packages/ed/ff/c580a30f96537b9103008479f77e68c3dc4dae05fb6649d7982e3195f9b4/UnicodeTokenizer-0.0.1-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "04031f6bd90979767d2e28786554df5d1db406b63c82a278b5acf49b674de026",
          "md5": "122b366104bc4e54088c697ef610e9ee",
          "sha256": "8b6a22222143c81149b8e6276d93df9df9c149312c1e1df1d0742289e3837768"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.1-py3.9.egg",
        "has_sig": false,
        "md5_digest": "122b366104bc4e54088c697ef610e9ee",
        "packagetype": "bdist_egg",
        "python_version": "0.0.1",
        "requires_python": ">=3.0",
        "size": 60527,
        "upload_time": "2022-06-26T14:14:58",
        "upload_time_iso_8601": "2022-06-26T14:14:58.632123Z",
        "url": "https://files.pythonhosted.org/packages/04/03/1f6bd90979767d2e28786554df5d1db406b63c82a278b5acf49b674de026/UnicodeTokenizer-0.0.1-py3.9.egg",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e345863b9144a41c1ac2d2de61473be2c9940c676cb8c91fe9efc938550d2075",
          "md5": "927fda1507fae7752a281ae544c8a26c",
          "sha256": "549f1469c4e056f0a107144069b5fe556496d8ecb5d7aa4c7b80d70a7918f7b1"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "927fda1507fae7752a281ae544c8a26c",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 5467,
        "upload_time": "2022-06-25T12:32:38",
        "upload_time_iso_8601": "2022-06-25T12:32:38.201542Z",
        "url": "https://files.pythonhosted.org/packages/e3/45/863b9144a41c1ac2d2de61473be2c9940c676cb8c91fe9efc938550d2075/UnicodeTokenizer-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d8fbfc09c4a8fb5b638ec7cff884b5e3e62d004d3890f9c8a16a2ccf106ad792",
          "md5": "5199742cf48a8f84c872c75a3980cff8",
          "sha256": "85ad3d53ce1370da494e69d6cbebaea13847418f399c120bcef206794e31ca37"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "5199742cf48a8f84c872c75a3980cff8",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 5684,
        "upload_time": "2022-06-25T12:32:41",
        "upload_time_iso_8601": "2022-06-25T12:32:41.448794Z",
        "url": "https://files.pythonhosted.org/packages/d8/fb/fc09c4a8fb5b638ec7cff884b5e3e62d004d3890f9c8a16a2ccf106ad792/UnicodeTokenizer-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a88236c5b0834c35c1bb773ac763fc945c0aaeb37bc5a6f8a669037298a6ad54",
          "md5": "52e810248f20b7ea5c272276b0632270",
          "sha256": "f0b921dddcf36e180e17d98523c876d9c38ec9fad23939941f4968e15991a026"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "52e810248f20b7ea5c272276b0632270",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 30543,
        "upload_time": "2022-06-26T14:14:56",
        "upload_time_iso_8601": "2022-06-26T14:14:56.719528Z",
        "url": "https://files.pythonhosted.org/packages/a8/82/36c5b0834c35c1bb773ac763fc945c0aaeb37bc5a6f8a669037298a6ad54/UnicodeTokenizer-0.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "318b3520d5208c9fcb960d2689e5d59062bfe7391fadcbad0dd425e8af81369e",
          "md5": "d4bd5caadf865192d33b3909ba21d854",
          "sha256": "949a7f8884a851aba68e35253d310e13716be60d2d9a0a89a43be9dd24779f91"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "d4bd5caadf865192d33b3909ba21d854",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 17661,
        "upload_time": "2022-06-26T14:15:00",
        "upload_time_iso_8601": "2022-06-26T14:15:00.644884Z",
        "url": "https://files.pythonhosted.org/packages/31/8b/3520d5208c9fcb960d2689e5d59062bfe7391fadcbad0dd425e8af81369e/UnicodeTokenizer-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "30d349ae7e2e1249d45666bdcbf9a8408f5794cc5b42ea2575360e1d89c05308",
          "md5": "39c9d195dd7d4bed68784f8b432624cd",
          "sha256": "3211279872e7c7bd1318d414ce5ada99383cb3b94a6598014f0ff6d8be89c9db"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "39c9d195dd7d4bed68784f8b432624cd",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 13986,
        "upload_time": "2022-06-30T16:33:40",
        "upload_time_iso_8601": "2022-06-30T16:33:40.218800Z",
        "url": "https://files.pythonhosted.org/packages/30/d3/49ae7e2e1249d45666bdcbf9a8408f5794cc5b42ea2575360e1d89c05308/UnicodeTokenizer-0.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "be47ff960f3d6c2308b1724e262606a8e9375551d9cd27190ab22a566dcc50bc",
          "md5": "be6e0409e1cdb7ae85dac1f4a39265ff",
          "sha256": "ebb620bd3480f4fb47f8d4b3b021dd04b4b8198f111141c0237758740723d853"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "be6e0409e1cdb7ae85dac1f4a39265ff",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 17672,
        "upload_time": "2022-06-30T16:33:42",
        "upload_time_iso_8601": "2022-06-30T16:33:42.507995Z",
        "url": "https://files.pythonhosted.org/packages/be/47/ff960f3d6c2308b1724e262606a8e9375551d9cd27190ab22a566dcc50bc/UnicodeTokenizer-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "897ed3533fd9cf31474bcaf612269363595e52023735cc4892717fcb2752c3bb",
          "md5": "ec2eee017631ea7b8a1d5d085ef2c906",
          "sha256": "c63b6d86a3440e3e8036851e89f8df6bbb32a363418f2cade04fdbbca4eeca77"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ec2eee017631ea7b8a1d5d085ef2c906",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 13982,
        "upload_time": "2022-07-05T14:06:42",
        "upload_time_iso_8601": "2022-07-05T14:06:42.066998Z",
        "url": "https://files.pythonhosted.org/packages/89/7e/d3533fd9cf31474bcaf612269363595e52023735cc4892717fcb2752c3bb/UnicodeTokenizer-0.0.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "88de463058fd51486082fca99ee4d23f0b8d8b59bed41cbfdb83d12730f93b22",
          "md5": "2d28b169af38dd591ac51da69e25522c",
          "sha256": "fc8142ea4ae92a89275cd62d29aae0f1e036eeed8a22525b418e13a998b0c194"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "2d28b169af38dd591ac51da69e25522c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 17666,
        "upload_time": "2022-07-05T14:06:44",
        "upload_time_iso_8601": "2022-07-05T14:06:44.450949Z",
        "url": "https://files.pythonhosted.org/packages/88/de/463058fd51486082fca99ee4d23f0b8d8b59bed41cbfdb83d12730f93b22/UnicodeTokenizer-0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f5324cd36c68195ce700b9c48cff0d6dc4700c12b1c7741c5bbff296e2003113",
          "md5": "1ee6859a2b198b4659299a3441a7ffe9",
          "sha256": "75bcde58eb6e1b32f24945dc2d636ab6f70936e4e14dc5f67cfc44151e2623b7"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "1ee6859a2b198b4659299a3441a7ffe9",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 13938,
        "upload_time": "2022-07-11T12:55:38",
        "upload_time_iso_8601": "2022-07-11T12:55:38.638940Z",
        "url": "https://files.pythonhosted.org/packages/f5/32/4cd36c68195ce700b9c48cff0d6dc4700c12b1c7741c5bbff296e2003113/UnicodeTokenizer-0.0.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8c0c8c71f77311db187003f2741587c817f23dcbe82169ad5648501d01224bdc",
          "md5": "bd2341dc41ff93d6c0b4febacf419961",
          "sha256": "03ab83ffbe210f76d4f7b8c2d73c3064ff633d7cf75d3958779a963bcb946ae5"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.6-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "bd2341dc41ff93d6c0b4febacf419961",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 13896,
        "upload_time": "2022-07-18T13:53:03",
        "upload_time_iso_8601": "2022-07-18T13:53:03.772267Z",
        "url": "https://files.pythonhosted.org/packages/8c/0c/8c71f77311db187003f2741587c817f23dcbe82169ad5648501d01224bdc/UnicodeTokenizer-0.0.6-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a1faa73908deb93262d5a66c3b8646690fd6fa2cd0ae0ce9fcc706d02552416d",
          "md5": "7975ce63f3295c01d6019072676b1df4",
          "sha256": "093a358bf6334e49f4d1502bfa62fe6aa04d9d78f30d098e60284bdfd0b5a2f9"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.6.tar.gz",
        "has_sig": false,
        "md5_digest": "7975ce63f3295c01d6019072676b1df4",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 17633,
        "upload_time": "2022-07-18T13:53:06",
        "upload_time_iso_8601": "2022-07-18T13:53:06.901564Z",
        "url": "https://files.pythonhosted.org/packages/a1/fa/a73908deb93262d5a66c3b8646690fd6fa2cd0ae0ce9fcc706d02552416d/UnicodeTokenizer-0.0.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ffcda776d240041b7bb1ff28cccbdddbe35606caeb8553cbcdeea8c0151ae8d1",
          "md5": "a7caea91e4b160ea3b4628661e89f59a",
          "sha256": "482a893a7bc7a4b58596a812a4fd6ec5199552a9ac7fa250f48d5051cae21099"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.7-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "a7caea91e4b160ea3b4628661e89f59a",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 14109,
        "upload_time": "2022-07-31T15:40:05",
        "upload_time_iso_8601": "2022-07-31T15:40:05.033226Z",
        "url": "https://files.pythonhosted.org/packages/ff/cd/a776d240041b7bb1ff28cccbdddbe35606caeb8553cbcdeea8c0151ae8d1/UnicodeTokenizer-0.0.7-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "42ec147f8409a69e8688b06c7b8b4aaba8fdc3518f6aa351b96ce40e1ded8896",
          "md5": "242bfb5274c8acff7b9b2968eea87d14",
          "sha256": "4d1865e6e45a57097e3f05c0c7ceacd87757cd957169534116ea82eb8461a6d7"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.7.tar.gz",
        "has_sig": false,
        "md5_digest": "242bfb5274c8acff7b9b2968eea87d14",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 17840,
        "upload_time": "2022-07-31T15:40:07",
        "upload_time_iso_8601": "2022-07-31T15:40:07.156063Z",
        "url": "https://files.pythonhosted.org/packages/42/ec/147f8409a69e8688b06c7b8b4aaba8fdc3518f6aa351b96ce40e1ded8896/UnicodeTokenizer-0.0.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d3ee7c7417cd619200b89c1a80c15296927215e6320796a03a5e6f9df8760dd0",
          "md5": "4a1b259e02b00d66af9bd639492afc81",
          "sha256": "22e24c6f3b9371123d861e4a0d3a72feefc583bbfe6727227524338397df81ec"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.8-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "4a1b259e02b00d66af9bd639492afc81",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 13845,
        "upload_time": "2022-08-15T12:52:49",
        "upload_time_iso_8601": "2022-08-15T12:52:49.606555Z",
        "url": "https://files.pythonhosted.org/packages/d3/ee/7c7417cd619200b89c1a80c15296927215e6320796a03a5e6f9df8760dd0/UnicodeTokenizer-0.0.8-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4d90ab67e33c16f7757156f24d2dd8c7341b9952daf3da71cfb8402bbea2304c",
          "md5": "0496f7b82ef3280f218f962229ab09bf",
          "sha256": "c4392e8a47a017f3bb9e8ee07c5da8fb3a83785af6497bc93a24a7d01bc90e3e"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.8.tar.gz",
        "has_sig": false,
        "md5_digest": "0496f7b82ef3280f218f962229ab09bf",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 13694,
        "upload_time": "2022-08-15T12:52:51",
        "upload_time_iso_8601": "2022-08-15T12:52:51.574935Z",
        "url": "https://files.pythonhosted.org/packages/4d/90/ab67e33c16f7757156f24d2dd8c7341b9952daf3da71cfb8402bbea2304c/UnicodeTokenizer-0.0.8.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.9": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6beaf0aede76e6205a1ded9b9bc09898a9e55c0196bb50139be525675ec1cf32",
          "md5": "fd5a111d1505aa2cdeb49b94b08c2cbe",
          "sha256": "639d1d47697c37e3640cdfb68dcfcaf230ef3ec0fa26c1cfe799b639713a5609"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.9-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "fd5a111d1505aa2cdeb49b94b08c2cbe",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 6823,
        "upload_time": "2022-12-22T15:24:37",
        "upload_time_iso_8601": "2022-12-22T15:24:37.387239Z",
        "url": "https://files.pythonhosted.org/packages/6b/ea/f0aede76e6205a1ded9b9bc09898a9e55c0196bb50139be525675ec1cf32/UnicodeTokenizer-0.0.9-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d77ff55c3baf4c4b616b1dd773e212536a9ae34b70dbd94252e67bbfe809c397",
          "md5": "f20457d396be2b64f7a41a98391d799c",
          "sha256": "dbfddfee2345919111464c6e2da462d6790433662a6465f53d698d96a94d747c"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.9.tar.gz",
        "has_sig": false,
        "md5_digest": "f20457d396be2b64f7a41a98391d799c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 6772,
        "upload_time": "2022-12-22T15:24:39",
        "upload_time_iso_8601": "2022-12-22T15:24:39.006172Z",
        "url": "https://files.pythonhosted.org/packages/d7/7f/f55c3baf4c4b616b1dd773e212536a9ae34b70dbd94252e67bbfe809c397/UnicodeTokenizer-0.0.9.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a36cb2e7d0c2925061a3bc53fdb632a6b10dce30a1b220af942d2d502449204f",
          "md5": "4dced36859a8fcf9a9d072db0a9d9234",
          "sha256": "23f333c8f5837bc415717069823e10bd982035171138d232f59a5b84d8e4e9a1"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "4dced36859a8fcf9a9d072db0a9d9234",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 5950,
        "upload_time": "2023-01-01T02:26:50",
        "upload_time_iso_8601": "2023-01-01T02:26:50.439418Z",
        "url": "https://files.pythonhosted.org/packages/a3/6c/b2e7d0c2925061a3bc53fdb632a6b10dce30a1b220af942d2d502449204f/UnicodeTokenizer-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b83a6275eb13cbc58ce7e610406da706f1697a8f9bcb127ede8c2b3dc6b40252",
          "md5": "8a41a3af17b4dbc6d81578ed8239d4ef",
          "sha256": "734b7a0f82f017b725686d880542bb5fbe86cc234d2e52982d4edda7871528ef"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "8a41a3af17b4dbc6d81578ed8239d4ef",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 5908,
        "upload_time": "2023-01-01T02:26:52",
        "upload_time_iso_8601": "2023-01-01T02:26:52.467733Z",
        "url": "https://files.pythonhosted.org/packages/b8/3a/6275eb13cbc58ce7e610406da706f1697a8f9bcb127ede8c2b3dc6b40252/UnicodeTokenizer-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a2d31582c8936571165be575bd6573226e0c87d84d10b908884affed24072a02",
          "md5": "9f03eb493f6cf0410321d224b1dd690d",
          "sha256": "062f59acd298d7160e876f4ec2ad2bba2f163e07be38d11f2e94457949869cf0"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "9f03eb493f6cf0410321d224b1dd690d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 5956,
        "upload_time": "2023-01-09T14:30:01",
        "upload_time_iso_8601": "2023-01-09T14:30:01.190483Z",
        "url": "https://files.pythonhosted.org/packages/a2/d3/1582c8936571165be575bd6573226e0c87d84d10b908884affed24072a02/UnicodeTokenizer-0.1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e41db835a46861aeb664f380633a9cd51de853a1a8ac5db174400a4487e1eb19",
          "md5": "f83180da1ad2262262ae4ffc3c2dc715",
          "sha256": "453db76d0d168afeaf5b1eb9490eb34afee4b7f24b2c6aaa0a47f69b247b506a"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "f83180da1ad2262262ae4ffc3c2dc715",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 5923,
        "upload_time": "2023-01-09T14:30:03",
        "upload_time_iso_8601": "2023-01-09T14:30:03.225600Z",
        "url": "https://files.pythonhosted.org/packages/e4/1d/b835a46861aeb664f380633a9cd51de853a1a8ac5db174400a4487e1eb19/UnicodeTokenizer-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.10": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "33983897bcbd7057dc8c98e73fb16adc8700d04210b2288b4c18c8c485f392e0",
          "md5": "b4282a5a66b108eb278e5bfc212d3c3f",
          "sha256": "88808a533ed335ca79d13e7791f11987c49bbe6869a6eddbed37baeedede1d58"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.10-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "b4282a5a66b108eb278e5bfc212d3c3f",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 5987,
        "upload_time": "2023-03-12T10:50:08",
        "upload_time_iso_8601": "2023-03-12T10:50:08.319606Z",
        "url": "https://files.pythonhosted.org/packages/33/98/3897bcbd7057dc8c98e73fb16adc8700d04210b2288b4c18c8c485f392e0/UnicodeTokenizer-0.1.10-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0c35b295f3ae8ab6c21424a83fec10f5d20ad87055ed4874c1c10b1fd3f58234",
          "md5": "95bbb93fffab9b9a68fdaef1b5164563",
          "sha256": "9cc0fcfaeda0e0c44f15566b8ff5bc46e919187e6d894200f28fa713d4f15baa"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.10.tar.gz",
        "has_sig": false,
        "md5_digest": "95bbb93fffab9b9a68fdaef1b5164563",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 5886,
        "upload_time": "2023-03-12T10:50:10",
        "upload_time_iso_8601": "2023-03-12T10:50:10.267955Z",
        "url": "https://files.pythonhosted.org/packages/0c/35/b295f3ae8ab6c21424a83fec10f5d20ad87055ed4874c1c10b1fd3f58234/UnicodeTokenizer-0.1.10.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "06c0f11d3b773348bd1940cd69bb1d231f688efc452ba8fc34748fbe798a9ae3",
          "md5": "c719ff5577600b8284ce545626ccde29",
          "sha256": "7f56fb3ea2b4597cccf269c4b6a3efc1359636168239f809285a645f56e60ef9"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "c719ff5577600b8284ce545626ccde29",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 5959,
        "upload_time": "2023-01-09T15:07:18",
        "upload_time_iso_8601": "2023-01-09T15:07:18.826397Z",
        "url": "https://files.pythonhosted.org/packages/06/c0/f11d3b773348bd1940cd69bb1d231f688efc452ba8fc34748fbe798a9ae3/UnicodeTokenizer-0.1.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4c176fb47f0c639bafc49626d0b785e71d48c0e014b7e253c86ef935e3574ab7",
          "md5": "b34654c67aa5c54e856dad7b82da824c",
          "sha256": "fffb5c45c6fc8c365c443d651db203df3ddb298e3a62cda7107f6802ec28ec0a"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "b34654c67aa5c54e856dad7b82da824c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 5937,
        "upload_time": "2023-01-09T15:07:20",
        "upload_time_iso_8601": "2023-01-09T15:07:20.535258Z",
        "url": "https://files.pythonhosted.org/packages/4c/17/6fb47f0c639bafc49626d0b785e71d48c0e014b7e253c86ef935e3574ab7/UnicodeTokenizer-0.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9b6369108eea9465bc57ff638b5474c75031e1714c28d67fd6500de4fdd5af33",
          "md5": "d31a27fe35cc2fdc6edc7c387ed32cb6",
          "sha256": "3e04919e38a61f86a648bb66b04926ae7f83e893b191590b1d8e7522bc5840b4"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d31a27fe35cc2fdc6edc7c387ed32cb6",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 5961,
        "upload_time": "2023-01-09T15:09:22",
        "upload_time_iso_8601": "2023-01-09T15:09:22.214925Z",
        "url": "https://files.pythonhosted.org/packages/9b/63/69108eea9465bc57ff638b5474c75031e1714c28d67fd6500de4fdd5af33/UnicodeTokenizer-0.1.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f2d01c0c27b6b02a176736bf369ec32f14cb5841cd448c84e2db5beefb9df0a4",
          "md5": "861e2fffe12ab1e8516c6ff2fed91ed2",
          "sha256": "afb4c2a18650f98118d621e4dad74df82bd64f7af0df8cf75705a9cc05bd5bbc"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.3.tar.gz",
        "has_sig": false,
        "md5_digest": "861e2fffe12ab1e8516c6ff2fed91ed2",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 5920,
        "upload_time": "2023-01-09T15:09:24",
        "upload_time_iso_8601": "2023-01-09T15:09:24.070150Z",
        "url": "https://files.pythonhosted.org/packages/f2/d0/1c0c27b6b02a176736bf369ec32f14cb5841cd448c84e2db5beefb9df0a4/UnicodeTokenizer-0.1.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d8269dd2a5685d179f596156bf06365eeba4efe35b5a910098643116ff3bfb9d",
          "md5": "24ac36090e94d3fcf13b73d2967b3dd0",
          "sha256": "d4423ac738fcb20045fe52258a8df0b03c67cc141dc87150497690645a24b4f6"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "24ac36090e94d3fcf13b73d2967b3dd0",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 5872,
        "upload_time": "2023-01-09T15:24:33",
        "upload_time_iso_8601": "2023-01-09T15:24:33.676768Z",
        "url": "https://files.pythonhosted.org/packages/d8/26/9dd2a5685d179f596156bf06365eeba4efe35b5a910098643116ff3bfb9d/UnicodeTokenizer-0.1.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c2f4f97333b9278adcf21eda3242554ba02508855849a8a23ff1332d54cb6116",
          "md5": "f34fca1ce3d3db33d01b5805d97ac9a5",
          "sha256": "0b289f53ac1cb282e6bbb5f7b70c61f9d20f976ce7767a584a46f2adabe5974b"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.4.tar.gz",
        "has_sig": false,
        "md5_digest": "f34fca1ce3d3db33d01b5805d97ac9a5",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 5829,
        "upload_time": "2023-01-09T15:24:35",
        "upload_time_iso_8601": "2023-01-09T15:24:35.224683Z",
        "url": "https://files.pythonhosted.org/packages/c2/f4/f97333b9278adcf21eda3242554ba02508855849a8a23ff1332d54cb6116/UnicodeTokenizer-0.1.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "44620f4013016141ea5a31c4e8508de9ae42de18b55b03b9c923f372c03dece4",
          "md5": "0c2a3df8730e0c09819cb9033944536b",
          "sha256": "6ab7a1286902eb1c6980d4f9465c12d04b540d6a368ea31f8ae86c1ccb168fc8"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0c2a3df8730e0c09819cb9033944536b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 5892,
        "upload_time": "2023-01-09T15:33:01",
        "upload_time_iso_8601": "2023-01-09T15:33:01.721846Z",
        "url": "https://files.pythonhosted.org/packages/44/62/0f4013016141ea5a31c4e8508de9ae42de18b55b03b9c923f372c03dece4/UnicodeTokenizer-0.1.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cbdd6cdaab97583c4935912d257160bce17529f2500a21f5228b33a7c526a7ba",
          "md5": "3ace4732bd1baeaa86219503ece83534",
          "sha256": "a32ba88ca8f2b643f39f43af51e4d9ca79c9fce3d1c9503163907115aa7b07cb"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.5.tar.gz",
        "has_sig": false,
        "md5_digest": "3ace4732bd1baeaa86219503ece83534",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 5844,
        "upload_time": "2023-01-09T15:33:03",
        "upload_time_iso_8601": "2023-01-09T15:33:03.410363Z",
        "url": "https://files.pythonhosted.org/packages/cb/dd/6cdaab97583c4935912d257160bce17529f2500a21f5228b33a7c526a7ba/UnicodeTokenizer-0.1.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f680b39c891a9086b2b35a6361ca5138d2cf773b2f4a03ec9adcf0df35197594",
          "md5": "56f19aa1baa508f3682e4a94e2f4acc6",
          "sha256": "54d0451e0472fecd4b30a564e288263e4eae86554190d0d5a895a25da9ed933b"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.6-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "56f19aa1baa508f3682e4a94e2f4acc6",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 6031,
        "upload_time": "2023-02-09T14:16:02",
        "upload_time_iso_8601": "2023-02-09T14:16:02.753725Z",
        "url": "https://files.pythonhosted.org/packages/f6/80/b39c891a9086b2b35a6361ca5138d2cf773b2f4a03ec9adcf0df35197594/UnicodeTokenizer-0.1.6-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a94b1c5a45784c93dfcbeb54a01c190e87019308b7645537d48b469d46f013f8",
          "md5": "7e6a74a591fa8a5276310991c19a27ce",
          "sha256": "0981abddddc37c870a370cc88101c79f49679985619f6f5aec46a76f0a0c430c"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.6.tar.gz",
        "has_sig": false,
        "md5_digest": "7e6a74a591fa8a5276310991c19a27ce",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 5989,
        "upload_time": "2023-02-09T14:16:04",
        "upload_time_iso_8601": "2023-02-09T14:16:04.337669Z",
        "url": "https://files.pythonhosted.org/packages/a9/4b/1c5a45784c93dfcbeb54a01c190e87019308b7645537d48b469d46f013f8/UnicodeTokenizer-0.1.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "aecb462521924a24b91ecdc4997b1c7aa90cb6b36e0c5ee4e1de8ea2c747e9c4",
          "md5": "d20214234a776d31a9913297c8da9fbd",
          "sha256": "0a7b4cf2f68abc15dbad19a0b3ca50d5c20036bf22bf626a5720013ee4c2fec7"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.7-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d20214234a776d31a9913297c8da9fbd",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 5779,
        "upload_time": "2023-02-13T18:04:32",
        "upload_time_iso_8601": "2023-02-13T18:04:32.534119Z",
        "url": "https://files.pythonhosted.org/packages/ae/cb/462521924a24b91ecdc4997b1c7aa90cb6b36e0c5ee4e1de8ea2c747e9c4/UnicodeTokenizer-0.1.7-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7c2fd6d42108db67556b41363febc22ffede44969f9e234fbc1ffb112b6c9fbf",
          "md5": "3659cdb548db651b2d670b8033ee2e17",
          "sha256": "6f87b8df83ed970b6f5747157cd51d1d1b125f26d6135635afb3dd7711cf0002"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.7.tar.gz",
        "has_sig": false,
        "md5_digest": "3659cdb548db651b2d670b8033ee2e17",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 5771,
        "upload_time": "2023-02-13T18:04:34",
        "upload_time_iso_8601": "2023-02-13T18:04:34.141724Z",
        "url": "https://files.pythonhosted.org/packages/7c/2f/d6d42108db67556b41363febc22ffede44969f9e234fbc1ffb112b6c9fbf/UnicodeTokenizer-0.1.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c0935293daba30c553e413cd4d291019bf49c633d274f9daac0e83c705e68fe6",
          "md5": "dfcd7f866f243b160921c697551e33b4",
          "sha256": "983637c207efccf06efba5bb412efee415d241dcbdc0c29f468822ea2eab0d3a"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.8-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "dfcd7f866f243b160921c697551e33b4",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 5841,
        "upload_time": "2023-02-24T11:56:05",
        "upload_time_iso_8601": "2023-02-24T11:56:05.071999Z",
        "url": "https://files.pythonhosted.org/packages/c0/93/5293daba30c553e413cd4d291019bf49c633d274f9daac0e83c705e68fe6/UnicodeTokenizer-0.1.8-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d76cfcab519d77d1e02552c6b7e73e3cfdccfef1a94e3048018b6551209a7454",
          "md5": "4db95d10c43faaf3030963b1b062cba6",
          "sha256": "96f0506f0da6f8ef96cf8514ed9f1fb392b20047a131e093d384157b74a92811"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.8.tar.gz",
        "has_sig": false,
        "md5_digest": "4db95d10c43faaf3030963b1b062cba6",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 5848,
        "upload_time": "2023-02-24T11:56:06",
        "upload_time_iso_8601": "2023-02-24T11:56:06.553614Z",
        "url": "https://files.pythonhosted.org/packages/d7/6c/fcab519d77d1e02552c6b7e73e3cfdccfef1a94e3048018b6551209a7454/UnicodeTokenizer-0.1.8.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.9": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2ca18d347da1a886535e0480fe662a1093a9d02bde7ab74a4b1751bf88aa32a2",
          "md5": "743bf4855eb47757e885c6e1aeda9487",
          "sha256": "7df8dbdd20022d14f44dd2af856810a6252af879c1a19a080fa545e8b53e0d89"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.9-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "743bf4855eb47757e885c6e1aeda9487",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 5956,
        "upload_time": "2023-02-24T12:23:31",
        "upload_time_iso_8601": "2023-02-24T12:23:31.984954Z",
        "url": "https://files.pythonhosted.org/packages/2c/a1/8d347da1a886535e0480fe662a1093a9d02bde7ab74a4b1751bf88aa32a2/UnicodeTokenizer-0.1.9-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "60174b6a8b5e0364dbec57e32cc0b70090629ed336c02a10c28e5407395dd555",
          "md5": "a628b52cbb8457794cf322f78f2221f5",
          "sha256": "709c1a036b3e237751ae108074509113ab0c68fcbf4236697c93d1f9d3592c6c"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.9.tar.gz",
        "has_sig": false,
        "md5_digest": "a628b52cbb8457794cf322f78f2221f5",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 5953,
        "upload_time": "2023-02-24T12:23:34",
        "upload_time_iso_8601": "2023-02-24T12:23:34.675507Z",
        "url": "https://files.pythonhosted.org/packages/60/17/4b6a8b5e0364dbec57e32cc0b70090629ed336c02a10c28e5407395dd555/UnicodeTokenizer-0.1.9.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "33983897bcbd7057dc8c98e73fb16adc8700d04210b2288b4c18c8c485f392e0",
        "md5": "b4282a5a66b108eb278e5bfc212d3c3f",
        "sha256": "88808a533ed335ca79d13e7791f11987c49bbe6869a6eddbed37baeedede1d58"
      },
      "downloads": -1,
      "filename": "UnicodeTokenizer-0.1.10-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "b4282a5a66b108eb278e5bfc212d3c3f",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.0",
      "size": 5987,
      "upload_time": "2023-03-12T10:50:08",
      "upload_time_iso_8601": "2023-03-12T10:50:08.319606Z",
      "url": "https://files.pythonhosted.org/packages/33/98/3897bcbd7057dc8c98e73fb16adc8700d04210b2288b4c18c8c485f392e0/UnicodeTokenizer-0.1.10-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "0c35b295f3ae8ab6c21424a83fec10f5d20ad87055ed4874c1c10b1fd3f58234",
        "md5": "95bbb93fffab9b9a68fdaef1b5164563",
        "sha256": "9cc0fcfaeda0e0c44f15566b8ff5bc46e919187e6d894200f28fa713d4f15baa"
      },
      "downloads": -1,
      "filename": "UnicodeTokenizer-0.1.10.tar.gz",
      "has_sig": false,
      "md5_digest": "95bbb93fffab9b9a68fdaef1b5164563",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.0",
      "size": 5886,
      "upload_time": "2023-03-12T10:50:10",
      "upload_time_iso_8601": "2023-03-12T10:50:10.267955Z",
      "url": "https://files.pythonhosted.org/packages/0c/35/b295f3ae8ab6c21424a83fec10f5d20ad87055ed4874c1c10b1fd3f58234/UnicodeTokenizer-0.1.10.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}