{
  "info": {
    "author": "laohur",
    "author_email": "laohur@gmail.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# UnicodeTokenizer\n\nUnicodeTokenizer: tokenize all Unicode text, tokenize blank char as a token as default\n\n## åˆ‡è¯è§„åˆ™ Tokenize Rules\n* ç©ºç™½åˆ‡åˆ† split on blankï¼š '\\n', ' ', '\\t'\n* ä¿ç•™å…³é”®è¯ keep never_splits\n* è‹¥å°å†™ï¼Œåˆ™è§„èŒƒåŒ–ï¼šå…¨è§’è½¬åŠè§’ï¼Œåˆ™NFDè§„èŒƒåŒ–ï¼Œå†å­—ç¬¦åˆ†å‰²  nomalize if lowerï¼šfull2halfï¼Œnomalize NFD, then chars split \n    - ç±»åˆ«ä¸ºMï¼Œç•¥è¿‡ ingore if category M ï¼š category M -> ''\n* å­—ç¬¦åˆ†å‰² chars splitï¼š ä»¥å­—çš„ç¬¦å·ç±»åˆ«å’Œè¯­è¨€åˆ†å‰² split line by category and languae of characters\n    - åªæœ‰ä¸´è¿‘æ•°å­—æˆè¯ only numers joind\n    - åªæœ‰ä¸´è¿‘å­—æ¯æˆè¯ only letters joind \n    - é«˜ç ç‚¹ç‹¬å­—  split high UnicodePoint characters\n\n* æˆªæ–­ max_len\n\n\n## use\n> pip install UnicodeTokenizer\n\n```python\nfrom UnicodeTokenizer import UnicodeTokenizer\ntokenizer=UnicodeTokenizer()\n\ndoc0 = \"\"\" ï¡¿\n        é¦–å…ˆ8.88è®¾ç½® stã€‚art_new_word=True å’Œ output=[aÃ§aÃ­]ï¼Œoutput å°±æ˜¯æœ€ç»ˆï¡¿î´°Â‘ no such name\"\n        çš„è¾“å‡ºà¸„à¸¸à¸“à¸ˆà¸°à¸ˆà¸±à¸”à¸žà¸´à¸˜à¸µà¹à¸•à¹ˆà¸‡à¸‡à¸²à¸™à¹€à¸¡à¸·à¹ˆà¸­à¹„à¸£à¸„à¸°íƒ‘ìŠ¹ ìˆ˜ì†í•´ì•¼pneumonoultramicroscopicsilicovolcanoconiosis\"\n        í•˜ëŠ”ë° ì¹´ìš´í„°ê°€ ì–´ë””ì— ìžˆì–´ìš”ê†ƒêŽ­ê†ˆêŒ êŠ¨ê¦ê²ê…‰ê†…ê‰šê…‰ê‹ê‚·ê‚¶êŒ Ù„Ø£Ø­ÙŠØ§Ø¡ ØªÙ…Ø§Ø±ÙŠÙ† ØªØªØ·Ù„Ø¨ Ù…Ù† [MASK] [PAD] [CLS][SEP]\n        est ð—´‚ð—¹­ð˜œ¶ð—´²ð—‚§, ou \"phiow-bjij-lhjij-lhjij\", ce que l'on peut traduire par Â« pays-grand-blanc-Ã©levÃ© Â» (ç™½é«˜å¤§å¤åœ‹). \n    \"\"\"\nprint(tokenizer.tokenize(doc0))\n```\n\n## result \n| sentence                                                                                                                                                                                                                                                                                                          | UnicodeTokenizer                                                                                                                                                                                                                                                                                                                                                                                                                                          | Unicode Tokens Length | BertBasicTokenizer                                                                                                                                                                                                                                                                                                 | Bert Tokens length |\n|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------|\n| â…§é¦–å…ˆ8.88è®¾ç½® stã€‚art_new_word=True å’Œ output=[aÃ§aÃ­]ï¼Œoutput å°±æ˜¯æœ€ç»ˆï¡¿î´°Â‘ no such name                                                                                                                                                                                                                              | â…· é¦– å…ˆ 8 . 88 è®¾ ç½® st ã€‚ art _ new _ word = true å’Œ output = [ ac a i ] ï¼Œ output å°± æ˜¯ æœ€ ç»ˆ ï¡¿ î´° Â‘ no such name                                                                                                                                                                                                                                                                                                                                         | 37                    | â…· é¦– å…ˆ 8 . 88 è®¾ ç½® st ã€‚ art _ new _ word = true å’Œ output = [ acai ] ï¼Œ output å°± æ˜¯ æœ€ ç»ˆ no such name                                                                                                                                                                                                         | 32                 |\n| çš„è¾“å‡ºà¸„à¸¸à¸“à¸ˆà¸°à¸ˆà¸±à¸”à¸žà¸´à¸˜à¸µà¹à¸•à¹ˆà¸‡à¸‡à¸²à¸™à¹€à¸¡à¸·à¹ˆà¸­à¹„à¸£à¸„à¸°íƒ‘ìŠ¹ ìˆ˜ì†í•´ì•¼pneumonoultramicroscopicsilicovolcanoconiosis                                                                                                                                                                                                                             | çš„ è¾“ å‡º à¸„ à¸“ à¸ˆà¸°à¸ˆ à¸” à¸ž à¸˜ à¹ à¸• à¸‡ à¸‡à¸²à¸™à¹€à¸¡ à¸­ à¹„à¸£à¸„à¸° á„á…¡á†¸á„‰á…³á†¼ á„‰á…®á„‰á…©á†¨á„’á…¢á„‹á…£ pneumonoultramicroscopicsilicovolcanoconiosis                                                                                                                                                                                                                                                                                                                                                     | 18                    | çš„ è¾“ å‡º à¸„à¸“à¸ˆà¸°à¸ˆà¸”à¸žà¸˜à¹à¸•à¸‡à¸‡à¸²à¸™à¹€à¸¡à¸­à¹„à¸£à¸„à¸°á„á…¡á†¸á„‰á…³á†¼ á„‰á…®á„‰á…©á†¨á„’á…¢á„‹á…£pneumonoultramicroscopicsilicovolcanoconiosis                                                                                                                                                                                                                           | 5                  |\n| í•˜ëŠ”ë° ì¹´ìš´í„°ê°€ ì–´ë””ì— ìžˆì–´ìš”ê†ƒêŽ­ê†ˆêŒ êŠ¨ê¦ê²ê…‰ê†…ê‰šê…‰ê‹ê‚·ê‚¶êŒ Ù„Ø£Ø­ÙŠØ§Ø¡ ØªÙ…Ø§Ø±ÙŠÙ† ØªØªØ·Ù„Ø¨ Ù…Ù† [MASK] [PAD] [CLS][SEP]                                                                                                                                                                                                         | á„’á…¡á„‚á…³á†«á„ƒá…¦ á„á…¡á„‹á…®á†«á„á…¥á„€á…¡ á„‹á…¥á„ƒá…µá„‹á…¦ á„‹á…µá†»á„‹á…¥á„‹á…­ ê†ƒ êŽ­ ê†ˆ êŒ  êŠ¨ ê¦ ê² ê…‰ ê†… ê‰š ê…‰ ê‹ ê‚· ê‚¶ êŒ  Ù„Ø§ Ø­ ÙŠØ§Ø¡ ØªÙ…Ø§Ø±ÙŠÙ† ØªØªØ·Ù„Ø¨ Ù…Ù† [MASK] [PAD] [ cls ] [ sep ]                                                                                                                                                                                                                                                                                                                          | 33                    | á„’á…¡á„‚á…³á†«á„ƒá…¦ á„á…¡á„‹á…®á†«á„á…¥á„€á…¡ á„‹á…¥á„ƒá…µá„‹á…¦ á„‹á…µá†»á„‹á…¥á„‹á…­ê†ƒêŽ­ê†ˆêŒ êŠ¨ê¦ê²ê…‰ê†…ê‰šê…‰ê‹ê‚·ê‚¶êŒ Ù„Ø§Ø­ÙŠØ§Ø¡ ØªÙ…Ø§Ø±ÙŠÙ† ØªØªØ·Ù„Ø¨ Ù…Ù† [MASK] [PAD] [ cls ] [ sep ]                                                                                                                                                                                                     | 15                 |\n| est ð—´‚ð—¹­ð˜œ¶ð—´²ð—‚§, ou \"phiow-bjij-lhjij-lhjij\", ce que l'on peut traduire par Â« pays-grand-blanc-Ã©levÃ© Â» (ç™½é«˜å¤§å¤åœ‹).                                                                                                                                                                                                    | est ð—´‚ ð—¹­ ð˜œ¶ ð—´² ð—‚§ , ou \" phiow - bjij - lhjij - lhjij \" , ce que l ' on peut traduire par Â« pays - grand - blanc - e l eve Â» ( ç™½ é«˜ å¤§ å¤ åœ‹ ) .                                                                                                                                                                                                                                                                                                             | 45                    | est ð—´‚ð—¹­ð˜œ¶ð—´²ð—‚§ , ou \" phiow - bjij - lhjij - lhjij \" , ce que l ' on peut traduire par Â« pays - grand - blanc - eleve Â» ( ç™½ é«˜ å¤§ å¤ åœ‹ ) .                                                                                                                                                                            | 39                 |\n| à¸§à¸£à¸£à¸“à¸žà¸‡à¸©à¹Œà¹€à¸›à¹‡à¸™à¸™à¸±à¸à¸¨à¸¶à¸à¸©à¸²à¸Šà¸±à¹‰à¸™à¸›à¸µà¸—à¸µà¹ˆà¸«à¸™à¸¶à¹ˆà¸‡ à¹€à¸£à¸µà¸¢à¸™à¸ªà¸²à¸‚à¸²à¸§à¸´à¸—à¸¢à¸²à¸à¸²à¸£à¸„à¸­à¸¡à¸žà¸´à¸§à¹€à¸•à¸­à¸£à¹Œà¹à¸¥à¸°à¸ªà¸²à¸£à¸ªà¸™à¹€à¸—à¸¨à¸„à¸“à¸°à¸§à¸´à¸—à¸¢à¸²à¸¨à¸²à¸ªà¸•à¸£à¹Œà¸›à¸£à¸°à¸¢à¸¸à¸à¸•à¹Œà¹à¸¥à¸°à¸§à¸´à¸¨à¸§à¸à¸£à¸£à¸¡à¸¨à¸²à¸ªà¸•à¸£à¹Œà¸­à¸¢à¸¹à¹ˆà¸—à¸µà¹ˆà¸¡à¸«à¸²à¸§à¸´à¸—à¸¢à¸²à¸¥à¸±à¸¢à¸‚à¸­à¸™à¹à¸à¹ˆà¸™à¸§à¸´à¸—à¸¢à¸²à¹€à¸‚à¸•à¸«à¸™à¸­à¸‡à¸„à¸²à¸¢à¸¢à¸·à¸¡à¸„à¸·à¸™à¸—à¸£à¸±à¸žà¸¢à¸²à¸à¸£à¸«à¹‰à¸­à¸‡à¸ªà¸¡à¸¸à¸”à¹€à¸­à¸à¸ªà¸²à¸£à¸ªà¸±à¸¡à¸¡à¸™à¸²à¸„à¸­à¸¡à¸žà¸´à¸§à¹€à¸•à¸­à¸£à¹Œà¸›à¸±à¸à¸à¸²à¸›à¸£à¸°à¸”à¸´à¸©à¸à¹Œà¸à¸±à¸šà¸à¸²à¸£à¸žà¸±à¸’à¸™à¸²à¹€à¸à¸¡à¹à¸¡à¸§à¸à¸´à¸™à¸›à¸¥à¸²à¸«à¸´à¸§à¸§à¸§à¹„à¸«à¸¡à¸«à¸¥à¸±à¸à¸ªà¸¹à¸•à¸£à¹ƒà¸«à¸¡à¹ˆà¸ªà¸”à¸ªà¸”à¸—à¸™à¹„à¸”à¹‰                                                                                           | à¸§à¸£à¸£à¸“à¸žà¸‡à¸© à¹€ à¸› à¸™ à¸™ à¸ à¸¨ à¸ à¸©à¸²à¸Š à¸™ à¸› à¸— à¸« à¸™ à¸‡ à¹€à¸£ à¸¢ à¸™à¸ªà¸²à¸‚à¸²à¸§ à¸— à¸¢à¸²à¸à¸²à¸£à¸„à¸­à¸¡à¸ž à¸§ à¹€à¸•à¸­à¸£ à¹ à¸¥à¸°à¸ªà¸²à¸£à¸ªà¸™à¹€à¸—à¸¨à¸„à¸“à¸°à¸§ à¸— à¸¢à¸²à¸¨à¸²à¸ªà¸•à¸£ à¸› à¸£à¸°à¸¢ à¸ à¸• à¹ à¸¥à¸°à¸§ à¸¨ à¸§à¸à¸£à¸£à¸¡à¸¨à¸²à¸ªà¸•à¸£ à¸­ à¸¢ à¸— à¸¡ à¸«à¸²à¸§ à¸— à¸¢à¸²à¸¥ à¸¢ à¸‚à¸­à¸™à¹à¸ à¸™ à¸§ à¸— à¸¢à¸²à¹€à¸‚à¸•à¸«à¸™à¸­à¸‡à¸„à¸²à¸¢à¸¢ à¸¡ à¸„ à¸™ à¸—à¸£ à¸ž à¸¢à¸²à¸à¸£à¸« à¸­ à¸‡à¸ªà¸¡ à¸” à¹€à¸­à¸à¸ªà¸²à¸£à¸ª à¸¡ à¸¡à¸™à¸²à¸„à¸­à¸¡à¸ž à¸§ à¹€à¸•à¸­à¸£ à¸› à¸ à¸à¸²à¸›à¸£à¸°à¸” à¸© à¸ à¸ à¸š à¸à¸²à¸£à¸ž à¸’ à¸™à¸²à¹€à¸à¸¡à¹à¸¡à¸§à¸ à¸™ à¸›à¸¥à¸²à¸« à¸§ à¸§à¸§à¹„à¸«à¸¡à¸«à¸¥ à¸ à¸ª à¸• à¸£à¹ƒà¸«à¸¡ à¸ª à¸”à¸ªà¸”à¸—à¸™à¹„à¸”                                                                                                                                                    | 81                    | à¸§à¸£à¸£à¸“à¸žà¸‡à¸©à¹€à¸›à¸™à¸™à¸à¸¨à¸à¸©à¸²à¸Šà¸™à¸›à¸—à¸«à¸™à¸‡ à¹€à¸£à¸¢à¸™à¸ªà¸²à¸‚à¸²à¸§à¸—à¸¢à¸²à¸à¸²à¸£à¸„à¸­à¸¡à¸žà¸§à¹€à¸•à¸­à¸£à¹à¸¥à¸°à¸ªà¸²à¸£à¸ªà¸™à¹€à¸—à¸¨à¸„à¸“à¸°à¸§à¸—à¸¢à¸²à¸¨à¸²à¸ªà¸•à¸£à¸›à¸£à¸°à¸¢à¸à¸•à¹à¸¥à¸°à¸§à¸¨à¸§à¸à¸£à¸£à¸¡à¸¨à¸²à¸ªà¸•à¸£à¸­à¸¢à¸—à¸¡à¸«à¸²à¸§à¸—à¸¢à¸²à¸¥à¸¢à¸‚à¸­à¸™à¹à¸à¸™à¸§à¸—à¸¢à¸²à¹€à¸‚à¸•à¸«à¸™à¸­à¸‡à¸„à¸²à¸¢à¸¢à¸¡à¸„à¸™à¸—à¸£à¸žà¸¢à¸²à¸à¸£à¸«à¸­à¸‡à¸ªà¸¡à¸”à¹€à¸­à¸à¸ªà¸²à¸£à¸ªà¸¡à¸¡à¸™à¸²à¸„à¸­à¸¡à¸žà¸§à¹€à¸•à¸­à¸£à¸›à¸à¸à¸²à¸›à¸£à¸°à¸”à¸©à¸à¸à¸šà¸à¸²à¸£à¸žà¸’à¸™à¸²à¹€à¸à¸¡à¹à¸¡à¸§à¸à¸™à¸›à¸¥à¸²à¸«à¸§à¸§à¸§à¹„à¸«à¸¡à¸«à¸¥à¸à¸ªà¸•à¸£à¹ƒà¸«à¸¡à¸ªà¸”à¸ªà¸”à¸—à¸™à¹„à¸”                                                                                            | 2                  |\n| àºªàº»àº¡à»€àº”àº±àº”àºžàº°à»€àºˆàº»à»‰àº²àº¢àº¹à»ˆàº«àº»àº§àºšà»àº£àº»àº¡à»‚àºàº”àºŠàº»àº‡àº—àº³àº™àº¸àºšàº³àº¥àº¸àº‡àºšà»‰àº²àº™à»€àº¡àº·àº­àº‡à»àº¥àº°àºžàº°àºªàº²àº”àºªàº°à»œàº²àºˆàº»àº™àºà»ˆàº²àº§à»„àº”à»‰àº§à»ˆàº²àºàº¸àº‡àºªàºµàº­àº°àºàº¸àº—àº°àº¢àº²à»ƒàº™àºªàº°à»„à»àºžàº°àº­àº»àº‡àº™àº±à»‰àº™à»€àº›àº±àº™àºàº¸àºàº—àºµà»ˆàºšà»‰àº²àº™à»€àº¡àº·àº­àº‡àº”àºµ àº¡àºµàº‚àº¸àº™àº™àº²àº‡àº„àº»àº™àºªàº³àº„àº±àº™àº—àºµà»ˆà»€àº•àºµàºšà»‚àº•à»ƒàº™à»€àº§àº¥àº²àº•à»à»ˆàº¡àº² à»ƒàº™àº¥àº²àºŠàº°àºàº²àº™àº‚àº­àº‡àºžàº°àº­àº»àº‡àº«àº¼àº²àºàº„àº»àº™ à»€àºŠàº±à»ˆàº™ àºªàº»àº¡à»€àº”àº±àº”àºžàº°à»€àºˆàº»à»‰àº²àºàº¸àº‡àº—àº»àº™àºšàº¸àº¥àºµ, àºžàº°àºšàº²àº”àºªàº»àº¡à»€àº”àº±àº”àºžàº°àºžàº¸àº”àº—àº°àºàº­àº”àºŸà»‰àº²àºˆàº¸àº¥àº²à»‚àº¥àºàº¡àº°àº«àº²àº¥àº²àº” à»€àº›àº±àº™àº•àº»à»‰àº™ à»ƒàº™àº—àº²àº‡àº”à»‰àº²àº™àº§àº±àº™àº™àº°àº„àº°àº”àºµàºà»àº¡àºµàºàº°àº§àºµàº„àº»àº™àºªàº³àº„àº±àº™ à»€àºŠàº±à»ˆàº™ à»€àºˆàº»à»‰àº²àºŸà»‰àº²àº—àº³àº¡àº²àº—àº´à»€àºšàº”à»„àºŠàºàº°à»€àºŠàº”àºªàº¸àº¥àº´àºàº°àº§àº»àº‡ àºàº»àº¡àº¡àº°àº‚àº¸àº™à»€àºªàº™àº²àºžàº´àº—àº±àº àº«àº¼àº·à»€àºˆàº»à»‰àº²àºŸà»‰àº²àºàº¸à»‰àº‡ à»€àºŠàº´à»ˆàº‡à»€àº›àº±àº™àºžàº°à»‚àº­àº¥àº»àº” à»€àº›àº±àº™àº•àº»à»‰àº™ | àºª àº¡ à»€àº” àº” àºžàº°à»€àºˆ àº² àº¢ àº« àº§ àºš àº£ àº¡ à»‚àºàº”àºŠ àº‡ àº—àº³àº™ àºš àº³àº¥ àº‡ àºš àº² àº™à»€àº¡ àº­ àº‡à»àº¥àº°àºžàº°àºªàº²àº”àºªàº°à»œàº²àºˆ àº™ àº àº² àº§à»„àº” àº§ àº² àº àº‡ àºª àº­ àº°àº àº— àº°àº¢àº²à»ƒàº™àºªàº°à»„à»àºžàº°àº­ àº‡ àº™ àº™ à»€àº› àº™ àº àº àº— àºš àº² àº™à»€àº¡ àº­ àº‡àº” àº¡ àº‚ àº™ àº™àº²àº‡àº„ àº™ àºªàº³àº„ àº™ àº— à»€ àº• àºš à»‚àº•à»ƒàº™à»€àº§àº¥àº²àº• àº¡ àº² à»ƒàº™àº¥àº²àºŠàº°àºàº²àº™àº‚àº­àº‡àºžàº°àº­ àº‡ àº« àº² àºàº„ àº™ à»€àºŠ àº™ àºª àº¡ à»€àº” àº” àºžàº°à»€àºˆ àº² àº àº‡ àº— àº™ àºš àº¥ , àºžàº°àºšàº²àº”àºª àº¡ à»€àº” àº” àºžàº°àºž àº” àº—àº°àºàº­àº”àºŸ àº² àºˆ àº¥ àº²à»‚àº¥àºàº¡àº°àº«àº²àº¥àº²àº” à»€àº› àº™ àº• àº™ à»ƒàº™àº—àº²àº‡àº” àº² àº™àº§ àº™ àº™àº°àº„àº°àº” àº àº¡ àº àº°àº§ àº„ àº™ àºªàº³àº„ àº™ à»€àºŠ àº™ à»€àºˆ àº² àºŸ àº² àº—àº³àº¡àº²àº— à»€ àºšàº”à»„àºŠàºàº°à»€àºŠàº”àºª àº¥ àº àº°àº§ àº‡ àº àº¡ àº¡àº°àº‚ àº™ à»€àºªàº™àº²àºž àº— àº àº« à»€ àºˆ àº² àºŸ àº² àº àº‡ à»€àºŠ àº‡ à»€àº› àº™ àºžàº°à»‚àº­àº¥ àº” à»€àº› àº™ àº• àº™ | 150                   | àºªàº¡à»€àº”àº”àºžàº°à»€àºˆàº²àº¢àº«àº§àºšàº£àº¡à»‚àºàº”àºŠàº‡àº—àº³àº™àºšàº³àº¥àº‡àºšàº²àº™à»€àº¡àº­àº‡à»àº¥àº°àºžàº°àºªàº²àº”àºªàº°à»œàº²àºˆàº™àºàº²àº§à»„àº”àº§àº²àºàº‡àºªàº­àº°àºàº—àº°àº¢àº²à»ƒàº™àºªàº°à»„à»àºžàº°àº­àº‡àº™àº™à»€àº›àº™àºàºàº—àºšàº²àº™à»€àº¡àº­àº‡àº” àº¡àº‚àº™àº™àº²àº‡àº„àº™àºªàº³àº„àº™àº—à»€àº•àºšà»‚àº•à»ƒàº™à»€àº§àº¥àº²àº•àº¡àº² à»ƒàº™àº¥àº²àºŠàº°àºàº²àº™àº‚àº­àº‡àºžàº°àº­àº‡àº«àº²àºàº„àº™ à»€àºŠàº™ àºªàº¡à»€àº”àº”àºžàº°à»€àºˆàº²àºàº‡àº—àº™àºšàº¥ , àºžàº°àºšàº²àº”àºªàº¡à»€àº”àº”àºžàº°àºžàº”àº—àº°àºàº­àº”àºŸàº²àºˆàº¥àº²à»‚àº¥àºàº¡àº°àº«àº²àº¥àº²àº” à»€àº›àº™àº•àº™ à»ƒàº™àº—àº²àº‡àº”àº²àº™àº§àº™àº™àº°àº„àº°àº”àºàº¡àºàº°àº§àº„àº™àºªàº³àº„àº™ à»€àºŠàº™ à»€àºˆàº²àºŸàº²àº—àº³àº¡àº²àº—à»€àºšàº”à»„àºŠàºàº°à»€àºŠàº”àºªàº¥àºàº°àº§àº‡ àºàº¡àº¡àº°àº‚àº™à»€àºªàº™àº²àºžàº—àº àº«à»€àºˆàº²àºŸàº²àºàº‡ à»€àºŠàº‡à»€àº›àº™àºžàº°à»‚àº­àº¥àº” à»€àº›àº™àº•àº™ | 15                 |\n\n## reference\n* Unicode Blocks  https://www.unicode.org/Public/UCD/latest/ucd/Blocks.txt\n* unicodedata.category https://www.unicode.org/reports/tr44/  #Table 12. General_Category Values\n* BertTokenization https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/LanguageModeling/BERT/tokenization.py\n\n\n## License\n[Anti-996 License](https://github.com/996icu/996.ICU/blob/master/LICENSE)\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/laohur/UnicodeTokenizer",
    "keywords": "UnicodeTokenizer,Tokenizer,Unicode,ZiTokenizer,ZiCutter,laohur",
    "license": "[Anti-996 License](https: // github.com/996icu/996.ICU/blob/master/LICENSE)",
    "maintainer": "",
    "maintainer_email": "",
    "name": "UnicodeTokenizer",
    "package_url": "https://pypi.org/project/UnicodeTokenizer/",
    "platform": null,
    "project_url": "https://pypi.org/project/UnicodeTokenizer/",
    "project_urls": {
      "Homepage": "https://github.com/laohur/UnicodeTokenizer"
    },
    "release_url": "https://pypi.org/project/UnicodeTokenizer/0.1.10/",
    "requires_dist": null,
    "requires_python": ">=3.0",
    "summary": "UnicodeTokenizer: tokenize all Unicode text",
    "version": "0.1.10",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17259660,
  "releases": {
    "0.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "05f7320fe71db95a096c6a6aea800053db81f686e6402ee5e2710ce75020a53f",
          "md5": "76a084e3ca3d987a892eed0f7ba16e7f",
          "sha256": "9af978b00e80079b336b25531119fbb2ad05beb0cabb87b796ba0b0ac412fbc3"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "76a084e3ca3d987a892eed0f7ba16e7f",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 5453,
        "upload_time": "2022-06-25T12:26:44",
        "upload_time_iso_8601": "2022-06-25T12:26:44.146089Z",
        "url": "https://files.pythonhosted.org/packages/05/f7/320fe71db95a096c6a6aea800053db81f686e6402ee5e2710ce75020a53f/UnicodeTokenizer-0.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "99c02f0c9e1644c2626e863848c527624bb74d637834dd8fcfe9ffb34d5667e5",
          "md5": "ccd9d0f850bf3c0bc7cca1161af622cf",
          "sha256": "285afd28905e9273d44bf4af77146e0be5c934bf45a6b785e2f3f8fdf71e4eb1"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "ccd9d0f850bf3c0bc7cca1161af622cf",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 5663,
        "upload_time": "2022-06-25T12:26:46",
        "upload_time_iso_8601": "2022-06-25T12:26:46.239584Z",
        "url": "https://files.pythonhosted.org/packages/99/c0/2f0c9e1644c2626e863848c527624bb74d637834dd8fcfe9ffb34d5667e5/UnicodeTokenizer-0.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "edffc580a30f96537b9103008479f77e68c3dc4dae05fb6649d7982e3195f9b4",
          "md5": "338cb4673244f8b9f6ee4ad1723195fc",
          "sha256": "d319469ee74add7311bcd5bff441b5130879f53d37b126db51b9264da370e7e4"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.1-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "338cb4673244f8b9f6ee4ad1723195fc",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": ">=3.0",
        "size": 30503,
        "upload_time": "2022-06-26T14:14:54",
        "upload_time_iso_8601": "2022-06-26T14:14:54.659198Z",
        "url": "https://files.pythonhosted.org/packages/ed/ff/c580a30f96537b9103008479f77e68c3dc4dae05fb6649d7982e3195f9b4/UnicodeTokenizer-0.0.1-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "04031f6bd90979767d2e28786554df5d1db406b63c82a278b5acf49b674de026",
          "md5": "122b366104bc4e54088c697ef610e9ee",
          "sha256": "8b6a22222143c81149b8e6276d93df9df9c149312c1e1df1d0742289e3837768"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.1-py3.9.egg",
        "has_sig": false,
        "md5_digest": "122b366104bc4e54088c697ef610e9ee",
        "packagetype": "bdist_egg",
        "python_version": "0.0.1",
        "requires_python": ">=3.0",
        "size": 60527,
        "upload_time": "2022-06-26T14:14:58",
        "upload_time_iso_8601": "2022-06-26T14:14:58.632123Z",
        "url": "https://files.pythonhosted.org/packages/04/03/1f6bd90979767d2e28786554df5d1db406b63c82a278b5acf49b674de026/UnicodeTokenizer-0.0.1-py3.9.egg",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e345863b9144a41c1ac2d2de61473be2c9940c676cb8c91fe9efc938550d2075",
          "md5": "927fda1507fae7752a281ae544c8a26c",
          "sha256": "549f1469c4e056f0a107144069b5fe556496d8ecb5d7aa4c7b80d70a7918f7b1"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "927fda1507fae7752a281ae544c8a26c",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 5467,
        "upload_time": "2022-06-25T12:32:38",
        "upload_time_iso_8601": "2022-06-25T12:32:38.201542Z",
        "url": "https://files.pythonhosted.org/packages/e3/45/863b9144a41c1ac2d2de61473be2c9940c676cb8c91fe9efc938550d2075/UnicodeTokenizer-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d8fbfc09c4a8fb5b638ec7cff884b5e3e62d004d3890f9c8a16a2ccf106ad792",
          "md5": "5199742cf48a8f84c872c75a3980cff8",
          "sha256": "85ad3d53ce1370da494e69d6cbebaea13847418f399c120bcef206794e31ca37"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "5199742cf48a8f84c872c75a3980cff8",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 5684,
        "upload_time": "2022-06-25T12:32:41",
        "upload_time_iso_8601": "2022-06-25T12:32:41.448794Z",
        "url": "https://files.pythonhosted.org/packages/d8/fb/fc09c4a8fb5b638ec7cff884b5e3e62d004d3890f9c8a16a2ccf106ad792/UnicodeTokenizer-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a88236c5b0834c35c1bb773ac763fc945c0aaeb37bc5a6f8a669037298a6ad54",
          "md5": "52e810248f20b7ea5c272276b0632270",
          "sha256": "f0b921dddcf36e180e17d98523c876d9c38ec9fad23939941f4968e15991a026"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "52e810248f20b7ea5c272276b0632270",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 30543,
        "upload_time": "2022-06-26T14:14:56",
        "upload_time_iso_8601": "2022-06-26T14:14:56.719528Z",
        "url": "https://files.pythonhosted.org/packages/a8/82/36c5b0834c35c1bb773ac763fc945c0aaeb37bc5a6f8a669037298a6ad54/UnicodeTokenizer-0.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "318b3520d5208c9fcb960d2689e5d59062bfe7391fadcbad0dd425e8af81369e",
          "md5": "d4bd5caadf865192d33b3909ba21d854",
          "sha256": "949a7f8884a851aba68e35253d310e13716be60d2d9a0a89a43be9dd24779f91"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "d4bd5caadf865192d33b3909ba21d854",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 17661,
        "upload_time": "2022-06-26T14:15:00",
        "upload_time_iso_8601": "2022-06-26T14:15:00.644884Z",
        "url": "https://files.pythonhosted.org/packages/31/8b/3520d5208c9fcb960d2689e5d59062bfe7391fadcbad0dd425e8af81369e/UnicodeTokenizer-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "30d349ae7e2e1249d45666bdcbf9a8408f5794cc5b42ea2575360e1d89c05308",
          "md5": "39c9d195dd7d4bed68784f8b432624cd",
          "sha256": "3211279872e7c7bd1318d414ce5ada99383cb3b94a6598014f0ff6d8be89c9db"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "39c9d195dd7d4bed68784f8b432624cd",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 13986,
        "upload_time": "2022-06-30T16:33:40",
        "upload_time_iso_8601": "2022-06-30T16:33:40.218800Z",
        "url": "https://files.pythonhosted.org/packages/30/d3/49ae7e2e1249d45666bdcbf9a8408f5794cc5b42ea2575360e1d89c05308/UnicodeTokenizer-0.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "be47ff960f3d6c2308b1724e262606a8e9375551d9cd27190ab22a566dcc50bc",
          "md5": "be6e0409e1cdb7ae85dac1f4a39265ff",
          "sha256": "ebb620bd3480f4fb47f8d4b3b021dd04b4b8198f111141c0237758740723d853"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "be6e0409e1cdb7ae85dac1f4a39265ff",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 17672,
        "upload_time": "2022-06-30T16:33:42",
        "upload_time_iso_8601": "2022-06-30T16:33:42.507995Z",
        "url": "https://files.pythonhosted.org/packages/be/47/ff960f3d6c2308b1724e262606a8e9375551d9cd27190ab22a566dcc50bc/UnicodeTokenizer-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "897ed3533fd9cf31474bcaf612269363595e52023735cc4892717fcb2752c3bb",
          "md5": "ec2eee017631ea7b8a1d5d085ef2c906",
          "sha256": "c63b6d86a3440e3e8036851e89f8df6bbb32a363418f2cade04fdbbca4eeca77"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ec2eee017631ea7b8a1d5d085ef2c906",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 13982,
        "upload_time": "2022-07-05T14:06:42",
        "upload_time_iso_8601": "2022-07-05T14:06:42.066998Z",
        "url": "https://files.pythonhosted.org/packages/89/7e/d3533fd9cf31474bcaf612269363595e52023735cc4892717fcb2752c3bb/UnicodeTokenizer-0.0.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "88de463058fd51486082fca99ee4d23f0b8d8b59bed41cbfdb83d12730f93b22",
          "md5": "2d28b169af38dd591ac51da69e25522c",
          "sha256": "fc8142ea4ae92a89275cd62d29aae0f1e036eeed8a22525b418e13a998b0c194"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "2d28b169af38dd591ac51da69e25522c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 17666,
        "upload_time": "2022-07-05T14:06:44",
        "upload_time_iso_8601": "2022-07-05T14:06:44.450949Z",
        "url": "https://files.pythonhosted.org/packages/88/de/463058fd51486082fca99ee4d23f0b8d8b59bed41cbfdb83d12730f93b22/UnicodeTokenizer-0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f5324cd36c68195ce700b9c48cff0d6dc4700c12b1c7741c5bbff296e2003113",
          "md5": "1ee6859a2b198b4659299a3441a7ffe9",
          "sha256": "75bcde58eb6e1b32f24945dc2d636ab6f70936e4e14dc5f67cfc44151e2623b7"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "1ee6859a2b198b4659299a3441a7ffe9",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 13938,
        "upload_time": "2022-07-11T12:55:38",
        "upload_time_iso_8601": "2022-07-11T12:55:38.638940Z",
        "url": "https://files.pythonhosted.org/packages/f5/32/4cd36c68195ce700b9c48cff0d6dc4700c12b1c7741c5bbff296e2003113/UnicodeTokenizer-0.0.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8c0c8c71f77311db187003f2741587c817f23dcbe82169ad5648501d01224bdc",
          "md5": "bd2341dc41ff93d6c0b4febacf419961",
          "sha256": "03ab83ffbe210f76d4f7b8c2d73c3064ff633d7cf75d3958779a963bcb946ae5"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.6-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "bd2341dc41ff93d6c0b4febacf419961",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 13896,
        "upload_time": "2022-07-18T13:53:03",
        "upload_time_iso_8601": "2022-07-18T13:53:03.772267Z",
        "url": "https://files.pythonhosted.org/packages/8c/0c/8c71f77311db187003f2741587c817f23dcbe82169ad5648501d01224bdc/UnicodeTokenizer-0.0.6-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a1faa73908deb93262d5a66c3b8646690fd6fa2cd0ae0ce9fcc706d02552416d",
          "md5": "7975ce63f3295c01d6019072676b1df4",
          "sha256": "093a358bf6334e49f4d1502bfa62fe6aa04d9d78f30d098e60284bdfd0b5a2f9"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.6.tar.gz",
        "has_sig": false,
        "md5_digest": "7975ce63f3295c01d6019072676b1df4",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 17633,
        "upload_time": "2022-07-18T13:53:06",
        "upload_time_iso_8601": "2022-07-18T13:53:06.901564Z",
        "url": "https://files.pythonhosted.org/packages/a1/fa/a73908deb93262d5a66c3b8646690fd6fa2cd0ae0ce9fcc706d02552416d/UnicodeTokenizer-0.0.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ffcda776d240041b7bb1ff28cccbdddbe35606caeb8553cbcdeea8c0151ae8d1",
          "md5": "a7caea91e4b160ea3b4628661e89f59a",
          "sha256": "482a893a7bc7a4b58596a812a4fd6ec5199552a9ac7fa250f48d5051cae21099"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.7-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "a7caea91e4b160ea3b4628661e89f59a",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 14109,
        "upload_time": "2022-07-31T15:40:05",
        "upload_time_iso_8601": "2022-07-31T15:40:05.033226Z",
        "url": "https://files.pythonhosted.org/packages/ff/cd/a776d240041b7bb1ff28cccbdddbe35606caeb8553cbcdeea8c0151ae8d1/UnicodeTokenizer-0.0.7-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "42ec147f8409a69e8688b06c7b8b4aaba8fdc3518f6aa351b96ce40e1ded8896",
          "md5": "242bfb5274c8acff7b9b2968eea87d14",
          "sha256": "4d1865e6e45a57097e3f05c0c7ceacd87757cd957169534116ea82eb8461a6d7"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.7.tar.gz",
        "has_sig": false,
        "md5_digest": "242bfb5274c8acff7b9b2968eea87d14",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 17840,
        "upload_time": "2022-07-31T15:40:07",
        "upload_time_iso_8601": "2022-07-31T15:40:07.156063Z",
        "url": "https://files.pythonhosted.org/packages/42/ec/147f8409a69e8688b06c7b8b4aaba8fdc3518f6aa351b96ce40e1ded8896/UnicodeTokenizer-0.0.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d3ee7c7417cd619200b89c1a80c15296927215e6320796a03a5e6f9df8760dd0",
          "md5": "4a1b259e02b00d66af9bd639492afc81",
          "sha256": "22e24c6f3b9371123d861e4a0d3a72feefc583bbfe6727227524338397df81ec"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.8-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "4a1b259e02b00d66af9bd639492afc81",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 13845,
        "upload_time": "2022-08-15T12:52:49",
        "upload_time_iso_8601": "2022-08-15T12:52:49.606555Z",
        "url": "https://files.pythonhosted.org/packages/d3/ee/7c7417cd619200b89c1a80c15296927215e6320796a03a5e6f9df8760dd0/UnicodeTokenizer-0.0.8-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4d90ab67e33c16f7757156f24d2dd8c7341b9952daf3da71cfb8402bbea2304c",
          "md5": "0496f7b82ef3280f218f962229ab09bf",
          "sha256": "c4392e8a47a017f3bb9e8ee07c5da8fb3a83785af6497bc93a24a7d01bc90e3e"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.8.tar.gz",
        "has_sig": false,
        "md5_digest": "0496f7b82ef3280f218f962229ab09bf",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 13694,
        "upload_time": "2022-08-15T12:52:51",
        "upload_time_iso_8601": "2022-08-15T12:52:51.574935Z",
        "url": "https://files.pythonhosted.org/packages/4d/90/ab67e33c16f7757156f24d2dd8c7341b9952daf3da71cfb8402bbea2304c/UnicodeTokenizer-0.0.8.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.9": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6beaf0aede76e6205a1ded9b9bc09898a9e55c0196bb50139be525675ec1cf32",
          "md5": "fd5a111d1505aa2cdeb49b94b08c2cbe",
          "sha256": "639d1d47697c37e3640cdfb68dcfcaf230ef3ec0fa26c1cfe799b639713a5609"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.9-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "fd5a111d1505aa2cdeb49b94b08c2cbe",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 6823,
        "upload_time": "2022-12-22T15:24:37",
        "upload_time_iso_8601": "2022-12-22T15:24:37.387239Z",
        "url": "https://files.pythonhosted.org/packages/6b/ea/f0aede76e6205a1ded9b9bc09898a9e55c0196bb50139be525675ec1cf32/UnicodeTokenizer-0.0.9-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d77ff55c3baf4c4b616b1dd773e212536a9ae34b70dbd94252e67bbfe809c397",
          "md5": "f20457d396be2b64f7a41a98391d799c",
          "sha256": "dbfddfee2345919111464c6e2da462d6790433662a6465f53d698d96a94d747c"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.0.9.tar.gz",
        "has_sig": false,
        "md5_digest": "f20457d396be2b64f7a41a98391d799c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 6772,
        "upload_time": "2022-12-22T15:24:39",
        "upload_time_iso_8601": "2022-12-22T15:24:39.006172Z",
        "url": "https://files.pythonhosted.org/packages/d7/7f/f55c3baf4c4b616b1dd773e212536a9ae34b70dbd94252e67bbfe809c397/UnicodeTokenizer-0.0.9.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a36cb2e7d0c2925061a3bc53fdb632a6b10dce30a1b220af942d2d502449204f",
          "md5": "4dced36859a8fcf9a9d072db0a9d9234",
          "sha256": "23f333c8f5837bc415717069823e10bd982035171138d232f59a5b84d8e4e9a1"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "4dced36859a8fcf9a9d072db0a9d9234",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 5950,
        "upload_time": "2023-01-01T02:26:50",
        "upload_time_iso_8601": "2023-01-01T02:26:50.439418Z",
        "url": "https://files.pythonhosted.org/packages/a3/6c/b2e7d0c2925061a3bc53fdb632a6b10dce30a1b220af942d2d502449204f/UnicodeTokenizer-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b83a6275eb13cbc58ce7e610406da706f1697a8f9bcb127ede8c2b3dc6b40252",
          "md5": "8a41a3af17b4dbc6d81578ed8239d4ef",
          "sha256": "734b7a0f82f017b725686d880542bb5fbe86cc234d2e52982d4edda7871528ef"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "8a41a3af17b4dbc6d81578ed8239d4ef",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 5908,
        "upload_time": "2023-01-01T02:26:52",
        "upload_time_iso_8601": "2023-01-01T02:26:52.467733Z",
        "url": "https://files.pythonhosted.org/packages/b8/3a/6275eb13cbc58ce7e610406da706f1697a8f9bcb127ede8c2b3dc6b40252/UnicodeTokenizer-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a2d31582c8936571165be575bd6573226e0c87d84d10b908884affed24072a02",
          "md5": "9f03eb493f6cf0410321d224b1dd690d",
          "sha256": "062f59acd298d7160e876f4ec2ad2bba2f163e07be38d11f2e94457949869cf0"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "9f03eb493f6cf0410321d224b1dd690d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 5956,
        "upload_time": "2023-01-09T14:30:01",
        "upload_time_iso_8601": "2023-01-09T14:30:01.190483Z",
        "url": "https://files.pythonhosted.org/packages/a2/d3/1582c8936571165be575bd6573226e0c87d84d10b908884affed24072a02/UnicodeTokenizer-0.1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e41db835a46861aeb664f380633a9cd51de853a1a8ac5db174400a4487e1eb19",
          "md5": "f83180da1ad2262262ae4ffc3c2dc715",
          "sha256": "453db76d0d168afeaf5b1eb9490eb34afee4b7f24b2c6aaa0a47f69b247b506a"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "f83180da1ad2262262ae4ffc3c2dc715",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 5923,
        "upload_time": "2023-01-09T14:30:03",
        "upload_time_iso_8601": "2023-01-09T14:30:03.225600Z",
        "url": "https://files.pythonhosted.org/packages/e4/1d/b835a46861aeb664f380633a9cd51de853a1a8ac5db174400a4487e1eb19/UnicodeTokenizer-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.10": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "33983897bcbd7057dc8c98e73fb16adc8700d04210b2288b4c18c8c485f392e0",
          "md5": "b4282a5a66b108eb278e5bfc212d3c3f",
          "sha256": "88808a533ed335ca79d13e7791f11987c49bbe6869a6eddbed37baeedede1d58"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.10-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "b4282a5a66b108eb278e5bfc212d3c3f",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 5987,
        "upload_time": "2023-03-12T10:50:08",
        "upload_time_iso_8601": "2023-03-12T10:50:08.319606Z",
        "url": "https://files.pythonhosted.org/packages/33/98/3897bcbd7057dc8c98e73fb16adc8700d04210b2288b4c18c8c485f392e0/UnicodeTokenizer-0.1.10-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0c35b295f3ae8ab6c21424a83fec10f5d20ad87055ed4874c1c10b1fd3f58234",
          "md5": "95bbb93fffab9b9a68fdaef1b5164563",
          "sha256": "9cc0fcfaeda0e0c44f15566b8ff5bc46e919187e6d894200f28fa713d4f15baa"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.10.tar.gz",
        "has_sig": false,
        "md5_digest": "95bbb93fffab9b9a68fdaef1b5164563",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 5886,
        "upload_time": "2023-03-12T10:50:10",
        "upload_time_iso_8601": "2023-03-12T10:50:10.267955Z",
        "url": "https://files.pythonhosted.org/packages/0c/35/b295f3ae8ab6c21424a83fec10f5d20ad87055ed4874c1c10b1fd3f58234/UnicodeTokenizer-0.1.10.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "06c0f11d3b773348bd1940cd69bb1d231f688efc452ba8fc34748fbe798a9ae3",
          "md5": "c719ff5577600b8284ce545626ccde29",
          "sha256": "7f56fb3ea2b4597cccf269c4b6a3efc1359636168239f809285a645f56e60ef9"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "c719ff5577600b8284ce545626ccde29",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 5959,
        "upload_time": "2023-01-09T15:07:18",
        "upload_time_iso_8601": "2023-01-09T15:07:18.826397Z",
        "url": "https://files.pythonhosted.org/packages/06/c0/f11d3b773348bd1940cd69bb1d231f688efc452ba8fc34748fbe798a9ae3/UnicodeTokenizer-0.1.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4c176fb47f0c639bafc49626d0b785e71d48c0e014b7e253c86ef935e3574ab7",
          "md5": "b34654c67aa5c54e856dad7b82da824c",
          "sha256": "fffb5c45c6fc8c365c443d651db203df3ddb298e3a62cda7107f6802ec28ec0a"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "b34654c67aa5c54e856dad7b82da824c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 5937,
        "upload_time": "2023-01-09T15:07:20",
        "upload_time_iso_8601": "2023-01-09T15:07:20.535258Z",
        "url": "https://files.pythonhosted.org/packages/4c/17/6fb47f0c639bafc49626d0b785e71d48c0e014b7e253c86ef935e3574ab7/UnicodeTokenizer-0.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9b6369108eea9465bc57ff638b5474c75031e1714c28d67fd6500de4fdd5af33",
          "md5": "d31a27fe35cc2fdc6edc7c387ed32cb6",
          "sha256": "3e04919e38a61f86a648bb66b04926ae7f83e893b191590b1d8e7522bc5840b4"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d31a27fe35cc2fdc6edc7c387ed32cb6",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 5961,
        "upload_time": "2023-01-09T15:09:22",
        "upload_time_iso_8601": "2023-01-09T15:09:22.214925Z",
        "url": "https://files.pythonhosted.org/packages/9b/63/69108eea9465bc57ff638b5474c75031e1714c28d67fd6500de4fdd5af33/UnicodeTokenizer-0.1.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f2d01c0c27b6b02a176736bf369ec32f14cb5841cd448c84e2db5beefb9df0a4",
          "md5": "861e2fffe12ab1e8516c6ff2fed91ed2",
          "sha256": "afb4c2a18650f98118d621e4dad74df82bd64f7af0df8cf75705a9cc05bd5bbc"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.3.tar.gz",
        "has_sig": false,
        "md5_digest": "861e2fffe12ab1e8516c6ff2fed91ed2",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 5920,
        "upload_time": "2023-01-09T15:09:24",
        "upload_time_iso_8601": "2023-01-09T15:09:24.070150Z",
        "url": "https://files.pythonhosted.org/packages/f2/d0/1c0c27b6b02a176736bf369ec32f14cb5841cd448c84e2db5beefb9df0a4/UnicodeTokenizer-0.1.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d8269dd2a5685d179f596156bf06365eeba4efe35b5a910098643116ff3bfb9d",
          "md5": "24ac36090e94d3fcf13b73d2967b3dd0",
          "sha256": "d4423ac738fcb20045fe52258a8df0b03c67cc141dc87150497690645a24b4f6"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "24ac36090e94d3fcf13b73d2967b3dd0",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 5872,
        "upload_time": "2023-01-09T15:24:33",
        "upload_time_iso_8601": "2023-01-09T15:24:33.676768Z",
        "url": "https://files.pythonhosted.org/packages/d8/26/9dd2a5685d179f596156bf06365eeba4efe35b5a910098643116ff3bfb9d/UnicodeTokenizer-0.1.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c2f4f97333b9278adcf21eda3242554ba02508855849a8a23ff1332d54cb6116",
          "md5": "f34fca1ce3d3db33d01b5805d97ac9a5",
          "sha256": "0b289f53ac1cb282e6bbb5f7b70c61f9d20f976ce7767a584a46f2adabe5974b"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.4.tar.gz",
        "has_sig": false,
        "md5_digest": "f34fca1ce3d3db33d01b5805d97ac9a5",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 5829,
        "upload_time": "2023-01-09T15:24:35",
        "upload_time_iso_8601": "2023-01-09T15:24:35.224683Z",
        "url": "https://files.pythonhosted.org/packages/c2/f4/f97333b9278adcf21eda3242554ba02508855849a8a23ff1332d54cb6116/UnicodeTokenizer-0.1.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "44620f4013016141ea5a31c4e8508de9ae42de18b55b03b9c923f372c03dece4",
          "md5": "0c2a3df8730e0c09819cb9033944536b",
          "sha256": "6ab7a1286902eb1c6980d4f9465c12d04b540d6a368ea31f8ae86c1ccb168fc8"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0c2a3df8730e0c09819cb9033944536b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 5892,
        "upload_time": "2023-01-09T15:33:01",
        "upload_time_iso_8601": "2023-01-09T15:33:01.721846Z",
        "url": "https://files.pythonhosted.org/packages/44/62/0f4013016141ea5a31c4e8508de9ae42de18b55b03b9c923f372c03dece4/UnicodeTokenizer-0.1.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cbdd6cdaab97583c4935912d257160bce17529f2500a21f5228b33a7c526a7ba",
          "md5": "3ace4732bd1baeaa86219503ece83534",
          "sha256": "a32ba88ca8f2b643f39f43af51e4d9ca79c9fce3d1c9503163907115aa7b07cb"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.5.tar.gz",
        "has_sig": false,
        "md5_digest": "3ace4732bd1baeaa86219503ece83534",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 5844,
        "upload_time": "2023-01-09T15:33:03",
        "upload_time_iso_8601": "2023-01-09T15:33:03.410363Z",
        "url": "https://files.pythonhosted.org/packages/cb/dd/6cdaab97583c4935912d257160bce17529f2500a21f5228b33a7c526a7ba/UnicodeTokenizer-0.1.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f680b39c891a9086b2b35a6361ca5138d2cf773b2f4a03ec9adcf0df35197594",
          "md5": "56f19aa1baa508f3682e4a94e2f4acc6",
          "sha256": "54d0451e0472fecd4b30a564e288263e4eae86554190d0d5a895a25da9ed933b"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.6-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "56f19aa1baa508f3682e4a94e2f4acc6",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 6031,
        "upload_time": "2023-02-09T14:16:02",
        "upload_time_iso_8601": "2023-02-09T14:16:02.753725Z",
        "url": "https://files.pythonhosted.org/packages/f6/80/b39c891a9086b2b35a6361ca5138d2cf773b2f4a03ec9adcf0df35197594/UnicodeTokenizer-0.1.6-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a94b1c5a45784c93dfcbeb54a01c190e87019308b7645537d48b469d46f013f8",
          "md5": "7e6a74a591fa8a5276310991c19a27ce",
          "sha256": "0981abddddc37c870a370cc88101c79f49679985619f6f5aec46a76f0a0c430c"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.6.tar.gz",
        "has_sig": false,
        "md5_digest": "7e6a74a591fa8a5276310991c19a27ce",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 5989,
        "upload_time": "2023-02-09T14:16:04",
        "upload_time_iso_8601": "2023-02-09T14:16:04.337669Z",
        "url": "https://files.pythonhosted.org/packages/a9/4b/1c5a45784c93dfcbeb54a01c190e87019308b7645537d48b469d46f013f8/UnicodeTokenizer-0.1.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "aecb462521924a24b91ecdc4997b1c7aa90cb6b36e0c5ee4e1de8ea2c747e9c4",
          "md5": "d20214234a776d31a9913297c8da9fbd",
          "sha256": "0a7b4cf2f68abc15dbad19a0b3ca50d5c20036bf22bf626a5720013ee4c2fec7"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.7-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d20214234a776d31a9913297c8da9fbd",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 5779,
        "upload_time": "2023-02-13T18:04:32",
        "upload_time_iso_8601": "2023-02-13T18:04:32.534119Z",
        "url": "https://files.pythonhosted.org/packages/ae/cb/462521924a24b91ecdc4997b1c7aa90cb6b36e0c5ee4e1de8ea2c747e9c4/UnicodeTokenizer-0.1.7-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7c2fd6d42108db67556b41363febc22ffede44969f9e234fbc1ffb112b6c9fbf",
          "md5": "3659cdb548db651b2d670b8033ee2e17",
          "sha256": "6f87b8df83ed970b6f5747157cd51d1d1b125f26d6135635afb3dd7711cf0002"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.7.tar.gz",
        "has_sig": false,
        "md5_digest": "3659cdb548db651b2d670b8033ee2e17",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 5771,
        "upload_time": "2023-02-13T18:04:34",
        "upload_time_iso_8601": "2023-02-13T18:04:34.141724Z",
        "url": "https://files.pythonhosted.org/packages/7c/2f/d6d42108db67556b41363febc22ffede44969f9e234fbc1ffb112b6c9fbf/UnicodeTokenizer-0.1.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c0935293daba30c553e413cd4d291019bf49c633d274f9daac0e83c705e68fe6",
          "md5": "dfcd7f866f243b160921c697551e33b4",
          "sha256": "983637c207efccf06efba5bb412efee415d241dcbdc0c29f468822ea2eab0d3a"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.8-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "dfcd7f866f243b160921c697551e33b4",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 5841,
        "upload_time": "2023-02-24T11:56:05",
        "upload_time_iso_8601": "2023-02-24T11:56:05.071999Z",
        "url": "https://files.pythonhosted.org/packages/c0/93/5293daba30c553e413cd4d291019bf49c633d274f9daac0e83c705e68fe6/UnicodeTokenizer-0.1.8-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d76cfcab519d77d1e02552c6b7e73e3cfdccfef1a94e3048018b6551209a7454",
          "md5": "4db95d10c43faaf3030963b1b062cba6",
          "sha256": "96f0506f0da6f8ef96cf8514ed9f1fb392b20047a131e093d384157b74a92811"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.8.tar.gz",
        "has_sig": false,
        "md5_digest": "4db95d10c43faaf3030963b1b062cba6",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 5848,
        "upload_time": "2023-02-24T11:56:06",
        "upload_time_iso_8601": "2023-02-24T11:56:06.553614Z",
        "url": "https://files.pythonhosted.org/packages/d7/6c/fcab519d77d1e02552c6b7e73e3cfdccfef1a94e3048018b6551209a7454/UnicodeTokenizer-0.1.8.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.9": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2ca18d347da1a886535e0480fe662a1093a9d02bde7ab74a4b1751bf88aa32a2",
          "md5": "743bf4855eb47757e885c6e1aeda9487",
          "sha256": "7df8dbdd20022d14f44dd2af856810a6252af879c1a19a080fa545e8b53e0d89"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.9-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "743bf4855eb47757e885c6e1aeda9487",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 5956,
        "upload_time": "2023-02-24T12:23:31",
        "upload_time_iso_8601": "2023-02-24T12:23:31.984954Z",
        "url": "https://files.pythonhosted.org/packages/2c/a1/8d347da1a886535e0480fe662a1093a9d02bde7ab74a4b1751bf88aa32a2/UnicodeTokenizer-0.1.9-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "60174b6a8b5e0364dbec57e32cc0b70090629ed336c02a10c28e5407395dd555",
          "md5": "a628b52cbb8457794cf322f78f2221f5",
          "sha256": "709c1a036b3e237751ae108074509113ab0c68fcbf4236697c93d1f9d3592c6c"
        },
        "downloads": -1,
        "filename": "UnicodeTokenizer-0.1.9.tar.gz",
        "has_sig": false,
        "md5_digest": "a628b52cbb8457794cf322f78f2221f5",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 5953,
        "upload_time": "2023-02-24T12:23:34",
        "upload_time_iso_8601": "2023-02-24T12:23:34.675507Z",
        "url": "https://files.pythonhosted.org/packages/60/17/4b6a8b5e0364dbec57e32cc0b70090629ed336c02a10c28e5407395dd555/UnicodeTokenizer-0.1.9.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "33983897bcbd7057dc8c98e73fb16adc8700d04210b2288b4c18c8c485f392e0",
        "md5": "b4282a5a66b108eb278e5bfc212d3c3f",
        "sha256": "88808a533ed335ca79d13e7791f11987c49bbe6869a6eddbed37baeedede1d58"
      },
      "downloads": -1,
      "filename": "UnicodeTokenizer-0.1.10-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "b4282a5a66b108eb278e5bfc212d3c3f",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.0",
      "size": 5987,
      "upload_time": "2023-03-12T10:50:08",
      "upload_time_iso_8601": "2023-03-12T10:50:08.319606Z",
      "url": "https://files.pythonhosted.org/packages/33/98/3897bcbd7057dc8c98e73fb16adc8700d04210b2288b4c18c8c485f392e0/UnicodeTokenizer-0.1.10-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "0c35b295f3ae8ab6c21424a83fec10f5d20ad87055ed4874c1c10b1fd3f58234",
        "md5": "95bbb93fffab9b9a68fdaef1b5164563",
        "sha256": "9cc0fcfaeda0e0c44f15566b8ff5bc46e919187e6d894200f28fa713d4f15baa"
      },
      "downloads": -1,
      "filename": "UnicodeTokenizer-0.1.10.tar.gz",
      "has_sig": false,
      "md5_digest": "95bbb93fffab9b9a68fdaef1b5164563",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.0",
      "size": 5886,
      "upload_time": "2023-03-12T10:50:10",
      "upload_time_iso_8601": "2023-03-12T10:50:10.267955Z",
      "url": "https://files.pythonhosted.org/packages/0c/35/b295f3ae8ab6c21424a83fec10f5d20ad87055ed4874c1c10b1fd3f58234/UnicodeTokenizer-0.1.10.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}