{
  "info": {
    "author": "David Beauchemin",
    "author_email": "david.beauchemin.5@ulaval.ca",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Developers",
      "Intended Audience :: Education",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: GNU Lesser General Public License v3 (LGPLv3)",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Topic :: Software Development :: Libraries",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "# Here is spacy_language_detection\n\nSpacy_language_detection is a fully customizable language detection for [spaCy](https://github.com/explosion/spaCy)\npipeline forked from\n[spacy-langdetect](https://github.com/Abhijit-2592/spacy-langdetect) in order to fix the seed problem (see [this issue](https://github.com/Abhijit-2592/spacy-langdetect/issues/3)) and to update it with spaCy 3.0.\n\nUse spacy_language_detection to\n\n- Detect the language of a document,\n- Detect the language of the sentences of a document.\n\n## Installation\n\n`pip install spacy-language-detection`\n\n## Basic Usage\n\nOut of the box, under the hood, it uses [langdetect](https://github.com/Mimino666/langdetect) to detect languages on\nspaCy's Doc and Span objects.\n\nHere is how to use it for spaCy 3.0\nsee [here](https://github.com/davebulaval/spacy-language-detection/blob/master/examples/detect_text_language_spacy2.py)\nfor an example with spaCy 2.0.\n\n```python\nimport spacy\nfrom spacy.language import Language\n\nfrom spacy_language_detection import LanguageDetector\n\n\ndef get_lang_detector(nlp, name):\n    return LanguageDetector(seed=42)  # We use the seed 42\n\n\nnlp_model = spacy.load(\"en_core_web_sm\")\nLanguage.factory(\"language_detector\", func=get_lang_detector)\nnlp_model.add_pipe('language_detector', last=True)\n\n# Document level language detection\njob_title = \"Senior NLP Research Engineer\"\ndoc = nlp_model(job_title)\nlanguage = doc._.language\nprint(language)\n\n# Sentence level language detection\ntext = \"This is English text. Er lebt mit seinen Eltern und seiner Schwester in Berlin. Yo me divierto todos los días en el parque. Je m'appelle Angélica Summer, j'ai 12 ans et je suis canadienne.\"\ndoc = nlp_model(text)\nfor i, sent in enumerate(doc.sents):\n    print(sent, sent._.language)\n```\n\n## Using your own language detector\n\nSuppose you are not happy with the accuracy of the out-of-the-box language detector, or you have your own language\ndetector, which you want to use with a spaCy pipeline. How do you do it? That's where the `language_detection_function`\nargument comes in. The function takes in a spaCy Doc or Span object and can return any Python object which is stored\nin `doc._.language` and `span._.language`. For example, let's say you want to\nuse [googletrans](https://pypi.org/project/googletrans/) as your language detection module:\n\n```python\nimport spacy\nfrom spacy.tokens import Doc, Span\nfrom spacy_language_detection import LanguageDetector\n# install using pip install googletrans\nfrom googletrans import Translator\n\nnlp = spacy.load(\"en\")\n\n\ndef custom_detection_function(spacy_object):\n    # Custom detection function should take a spaCy Doc or a Span\n    assert isinstance(spacy_object, Doc) or isinstance(\n        spacy_object, Span), \"spacy_object must be a spacy Doc or Span object but it is a {}\".format(type(spacy_object))\n    detection = Translator().detect(spacy_object.text)\n    return {'language': detection.lang, 'score': detection.confidence}\n\n\ndef get_lang_detector(nlp, name):\n    return LanguageDetector(language_detection_function=custom_detection_function, seed=42)  # We use the seed 42\n\n\nnlp_model = spacy.load(\"en_core_web_sm\")\nLanguage.factory(\"language_detector\", func=get_lang_detector)\nnlp_model.add_pipe('language_detector', last=True)\n\ntext = \"This is English text. Er lebt mit seinen Eltern und seiner Schwester in Berlin. Yo me divierto todos los días en el parque. Je m'appelle Angélica Summer, j'ai 12 ans et je suis canadienne.\"\n\n# Document level language detection\ndoc = nlp_model(text)\nlanguage = doc._.language\nprint(language)\n\n# Sentence level language detection\ntext = \"This is English text. Er lebt mit seinen Eltern und seiner Schwester in Berlin. Yo me divierto todos los días en el parque. Je m'appelle Angélica Summer, j'ai 12 ans et je suis canadienne.\"\ndoc = nlp_model(text)\nfor i, sent in enumerate(doc.sents):\n    print(sent, sent._.language)\n```\n\nSimilarly, you can also use [pycld2](https://pypi.org/project/pycld2/) and other language detectors with spaCy.\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "https://github.com/davebulaval/spacy-language-detection/archive/v0.2.1.zip",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/davebulaval/spacy-language-detection",
    "keywords": "",
    "license": "LGPLv3",
    "maintainer": "",
    "maintainer_email": "",
    "name": "spacy-language-detection",
    "package_url": "https://pypi.org/project/spacy-language-detection/",
    "platform": "",
    "project_url": "https://pypi.org/project/spacy-language-detection/",
    "project_urls": {
      "Download": "https://github.com/davebulaval/spacy-language-detection/archive/v0.2.1.zip",
      "Homepage": "https://github.com/davebulaval/spacy-language-detection"
    },
    "release_url": "https://pypi.org/project/spacy-language-detection/0.2.1/",
    "requires_dist": [
      "spacy (>=3.0.0)",
      "langdetect (==1.0.9)"
    ],
    "requires_python": ">=3.7",
    "summary": "Fully customizable language detection for spaCy pipeline",
    "version": "0.2.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 11397185,
  "releases": {
    "0.2.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c87c6c07435d220e09c1dab1d0c0c0f51d397e8c42212567ace34dd8d7188e9f",
          "md5": "63ddce508ad066c30caf92c1e80893b9",
          "sha256": "7868a2f2853e937642b83268d108d17b3f5c885df376950cfc63c2391304bdd4"
        },
        "downloads": -1,
        "filename": "spacy_language_detection-0.2.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "63ddce508ad066c30caf92c1e80893b9",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 6514,
        "upload_time": "2021-09-08T16:18:59",
        "upload_time_iso_8601": "2021-09-08T16:18:59.865106Z",
        "url": "https://files.pythonhosted.org/packages/c8/7c/6c07435d220e09c1dab1d0c0c0f51d397e8c42212567ace34dd8d7188e9f/spacy_language_detection-0.2.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6048f86fad67d6afc03cbfb50eb872fc401698108fc687cfdccfbfe562e79661",
          "md5": "40c83f73ea02a0b22a2fc41a0e7be3ee",
          "sha256": "eb6f4aefbd292b0081b62adbbd7727caf46aae49a2b4d1f652bf7f065e241a72"
        },
        "downloads": -1,
        "filename": "spacy-language-detection-0.2.1.tar.gz",
        "has_sig": false,
        "md5_digest": "40c83f73ea02a0b22a2fc41a0e7be3ee",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 5040,
        "upload_time": "2021-09-08T16:19:01",
        "upload_time_iso_8601": "2021-09-08T16:19:01.309168Z",
        "url": "https://files.pythonhosted.org/packages/60/48/f86fad67d6afc03cbfb50eb872fc401698108fc687cfdccfbfe562e79661/spacy-language-detection-0.2.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "c87c6c07435d220e09c1dab1d0c0c0f51d397e8c42212567ace34dd8d7188e9f",
        "md5": "63ddce508ad066c30caf92c1e80893b9",
        "sha256": "7868a2f2853e937642b83268d108d17b3f5c885df376950cfc63c2391304bdd4"
      },
      "downloads": -1,
      "filename": "spacy_language_detection-0.2.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "63ddce508ad066c30caf92c1e80893b9",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 6514,
      "upload_time": "2021-09-08T16:18:59",
      "upload_time_iso_8601": "2021-09-08T16:18:59.865106Z",
      "url": "https://files.pythonhosted.org/packages/c8/7c/6c07435d220e09c1dab1d0c0c0f51d397e8c42212567ace34dd8d7188e9f/spacy_language_detection-0.2.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "6048f86fad67d6afc03cbfb50eb872fc401698108fc687cfdccfbfe562e79661",
        "md5": "40c83f73ea02a0b22a2fc41a0e7be3ee",
        "sha256": "eb6f4aefbd292b0081b62adbbd7727caf46aae49a2b4d1f652bf7f065e241a72"
      },
      "downloads": -1,
      "filename": "spacy-language-detection-0.2.1.tar.gz",
      "has_sig": false,
      "md5_digest": "40c83f73ea02a0b22a2fc41a0e7be3ee",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 5040,
      "upload_time": "2021-09-08T16:19:01",
      "upload_time_iso_8601": "2021-09-08T16:19:01.309168Z",
      "url": "https://files.pythonhosted.org/packages/60/48/f86fad67d6afc03cbfb50eb872fc401698108fc687cfdccfbfe562e79661/spacy-language-detection-0.2.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}