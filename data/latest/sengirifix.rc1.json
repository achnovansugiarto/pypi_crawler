{
  "info": {
    "author": "CPLim",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Developers",
      "Intended Audience :: Information Technology",
      "License :: OSI Approved :: MIT License",
      "Natural Language :: Japanese",
      "Operating System :: MacOS",
      "Operating System :: Microsoft",
      "Operating System :: POSIX",
      "Programming Language :: Python :: 3.4",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Topic :: Text Processing"
    ],
    "description": "sengiri\n==========\n|travis| |coveralls| |pyversion| |version| |license|\n\nYet another sentence-level tokenizer for the Japanese text\n\nDEPENDENCIES\n==============\n\n- MeCab\n- emoji\n\nINSTALLATION\n==============\n\n::\n\n $ pip install sengiri\n\n\nUSAGE\n============\n\n.. code:: python\n\n  import sengiri\n\n  print(sengiri.tokenize('うーん🤔🤔🤔どうしよう'))\n  #=>['うーん🤔🤔🤔', 'どうしよう']\n  print(sengiri.tokenize('モー娘。のコンサートに行った。'))\n  #=>['モー娘。のコンサートに行った。']\n  print(sengiri.tokenize('ありがとう＾＾ 助かります。'))\n  #=>['ありがとう＾＾', '助かります。']\n  print(sengiri.tokenize('顔文字テスト(*´ω｀*)うまくいくかな？'))\n  #=>['顔文字テスト(*´ω｀*)うまくいくかな？']\n  # I recommend using the NEologd dictionary.\n  print(sengiri.tokenize('顔文字テスト(*´ω｀*)うまくいくかな？', mecab_args='-d /usr/local/lib/mecab/dic/mecab-ipadic-neologd'))\n  #=>['顔文字テスト(*´ω｀*)', 'うまくいくかな？']\n  print(sengiri.tokenize('子供が大変なことになった。'\n                         '（後で聞いたのだが、脅されたらしい）'\n                         '（脅迫はやめてほしいと言っているのに）'))\n  #=>['子供が大変なことになった。', '（後で聞いたのだが、脅されたらしい）', '（脅迫はやめてほしいと言っているのに）']\n  print(sengiri.tokenize('楽しかったw また遊ぼwww'))\n  #=>['楽しかったw', 'また遊ぼwww']\n  print(sengiri.tokenize('http://www.inpaku.go.jp/'))\n  #=>['http://www.inpaku.go.jp/']\n\n.. |travis| image:: https://travis-ci.org/ikegami-yukino/sengiri.svg?branch=master\n    :target: https://travis-ci.org/ikegami-yukino/sengiri\n    :alt: travis-ci.org\n\n.. |coveralls| image:: https://coveralls.io/repos/ikegami-yukino/sengiri/badge.svg?branch=master&service=github\n    :target: https://coveralls.io/github/ikegami-yukino/sengiri?branch=master\n    :alt: coveralls.io\n\n.. |pyversion| image:: https://img.shields.io/pypi/pyversions/sengiri.svg\n\n.. |version| image:: https://img.shields.io/pypi/v/sengiri.svg\n    :target: http://pypi.python.org/pypi/sengiri/\n    :alt: latest version\n\n.. |license| image:: https://img.shields.io/pypi/l/sengiri.svg\n    :target: http://pypi.python.org/pypi/sengiri/\n    :alt: license\n\n\nCHANGES\n=======\n\n0.2.2 (2019-10-15)\n------------------\n\n- In tokenize() method, `emoji_threshold` parameter is available\n- Bugfix\n\n0.2.1 (2019-10-12)\n------------------\n\n- Works well with also a text including emoticon and www (Laughing expression)\n- Always treat emoji to delimiter regardless MeCab's POS\n\n0.1.1 (2019-10-05)\n------------------\n\n- First release",
    "description_content_type": "",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/cp-lim/sengiri",
    "keywords": "japanese,tokenizer,sentence,sentence-tokenizer",
    "license": "MIT License",
    "maintainer": "",
    "maintainer_email": "",
    "name": "sengirifix",
    "package_url": "https://pypi.org/project/sengirifix/",
    "platform": "POSIX",
    "project_url": "https://pypi.org/project/sengirifix/",
    "project_urls": {
      "Homepage": "https://github.com/cp-lim/sengiri"
    },
    "release_url": "https://pypi.org/project/sengirifix/0.1.3/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "Yet another fork of sentence-level tokenizer for the Japanese text",
    "version": "0.1.3",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8453147,
  "releases": {
    "0.1.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a9dbaa692f4362264c5138dc6c798e8f08c7aec6065e553c68f7cf3130b1e1c6",
          "md5": "1e8379b7bc433e6b0855688c99d49606",
          "sha256": "b9677ec8858af1f0665883578723b1498f292e3e29ae62da889e10da06eb8d9b"
        },
        "downloads": -1,
        "filename": "sengirifix-0.1.3.tar.gz",
        "has_sig": false,
        "md5_digest": "1e8379b7bc433e6b0855688c99d49606",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 4981,
        "upload_time": "2020-10-20T03:33:31",
        "upload_time_iso_8601": "2020-10-20T03:33:31.012197Z",
        "url": "https://files.pythonhosted.org/packages/a9/db/aa692f4362264c5138dc6c798e8f08c7aec6065e553c68f7cf3130b1e1c6/sengirifix-0.1.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "a9dbaa692f4362264c5138dc6c798e8f08c7aec6065e553c68f7cf3130b1e1c6",
        "md5": "1e8379b7bc433e6b0855688c99d49606",
        "sha256": "b9677ec8858af1f0665883578723b1498f292e3e29ae62da889e10da06eb8d9b"
      },
      "downloads": -1,
      "filename": "sengirifix-0.1.3.tar.gz",
      "has_sig": false,
      "md5_digest": "1e8379b7bc433e6b0855688c99d49606",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 4981,
      "upload_time": "2020-10-20T03:33:31",
      "upload_time_iso_8601": "2020-10-20T03:33:31.012197Z",
      "url": "https://files.pythonhosted.org/packages/a9/db/aa692f4362264c5138dc6c798e8f08c7aec6065e553c68f7cf3130b1e1c6/sengirifix-0.1.3.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}