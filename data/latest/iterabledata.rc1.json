{
  "info": {
    "author": "Ivan Begtin",
    "author_email": "ivan@begtin.tech",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Environment :: Console",
      "Intended Audience :: Developers",
      "Intended Audience :: System Administrators",
      "License :: OSI Approved :: BSD License",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3 :: Only",
      "Programming Language :: Python :: 3.8",
      "Topic :: Software Development",
      "Topic :: Text Processing"
    ],
    "description": "# Iterable Data\r\n\r\n*Work in progress. Documentation in progress*\r\n\r\nIterable data is a Python lib to read data files row by row and write data files.\r\nIterable classes are similar to files or csv.DictReader or reading parquet files row by row. \r\n\r\nThis library was written to simplify data processing and conversion between formats.\r\n \r\nSupported file types:\r\n* BSON\r\n* JSON\r\n* NDJSON (JSON lines)\r\n* XML\r\n* XLS\r\n* XLSX\r\n* Parquet\r\n* ORC\r\n* Avro\r\n* Pickle\r\n\r\nSupported file compression: GZip, BZip2, LZMA (.xz), LZ4, ZIP\r\n\r\n## Why writing this lib? \r\n\r\nPython has many high-quality data processing tools and libraries, especially pandas and other data frames lib. The only issue with most of them is flat data. Data frames don't support complex data types, and you must *flatten* data each time. \r\n\r\npyiterable helps you read any data as a Python dictionary instead of flattening data.\r\nIt makes it much easier to work with such data sources as JSON, NDJSON, or BSON files.\r\n\r\nThis code is used in several tools written by its author. It's command line tool [undatum](https://github.com/datacoon/undatum) and data processing ETL engine [datacrafter](https://github.com/apicrafter/datacrafter)\r\n\r\n\r\n## Requirements\r\n\r\nPython 3.8+\r\n\r\n## Documentation\r\n\r\nIn progress\r\n\r\n## Usage and examples\r\n\r\n\r\n### Read compressed CSV file \r\n\r\nRead compressed csv.xz file\r\n\r\n```{python}\r\n\r\nfrom iterable.helpers.detect import open_iterable\r\n\r\nsource = open_iterable('data.csv.xz')\r\nn = 0\r\nfor row in iterable:\r\n    n += 1\r\n    # Add data processing code here\r\n    if n % 1000 == 0: print('Processing %d' % (n))\r\n```\r\n\r\n### Detect encoding and file delimiter\r\n\r\nDetects encoding and delimiter of the selected CSV file and use it to open as iterable\r\n\r\n```{python}\r\n\r\nfrom iterable.helpers.detect import open_iterable\r\nfrom iterable.helpers.utils import detect_encoding, detect_delimiter\r\n\r\ndelimiter = detect_delimiter('data.csv')\r\nencoding = detect_encoding('data.csv')\r\n\r\nsource = open_iterable('data.csv', iterableargs={'encoding' : encoding['encoding'], 'delimiter' : delimiter)\r\nn = 0\r\nfor row in iterable:\r\n    n += 1\r\n    # Add data processing code here\r\n    if n % 1000 == 0: print('Processing %d' % (n))\r\n```\r\n\r\n\r\n### Convert Parquet file to BSON compressed with LZMA using pipeline\r\n\r\nUses pipeline class to iterate through parquet file and convert its selected fields to JSON lines (NDJSON)\r\n\r\n```{python}\r\n\r\nfrom iterable.helpers.detect import open_iterable\r\nfrom iterable.pipeline import pipeline\r\n\r\nsource = open_iterable('data/data.parquet')\r\ndestination = open_iterable('data/data.jsonl.xz', mode='w')\r\n\r\ndef extract_fields(record, state):\r\n    out = {}\r\n    record = dict(record)\r\n    print(record)\r\n    for k in ['name',]:\r\n        out[k] = record[k]\r\n    return out\r\n\r\ndef print_process(stats, state):\r\n    print(stats)\r\n\r\npipeline(source, destination=destination, process_func=extract_fields, trigger_on=2, trigger_func=print_process, final_func=print_process, start_state={})\r\n\r\n```\r\n\r\n### Convert gzipped JSON lines (NDJSON) file to BSON compressed with LZMA \r\n\r\nReads each row from JSON lines file using Gzip codec and writes BSON data using LZMA codec\r\n\r\n```{python}\r\n\r\nfrom iterable.datatypes import JSONLinesIterable, BSONIterable\r\nfrom iterable.codecs import GZIPCodec, LZMACodec\r\n\r\n\r\ncodecobj = GZIPCodec('data.jsonl.gz', mode='r', open_it=True)\r\niterable = JSONLinesIterable(codec=codecobj)        \r\ncodecobj = LZMACodec('data.bson.xz', mode='wb', open_it=False)\r\nwrite_iterable = BSONIterable(codec=codecobj, mode='w')\r\nn = 0\r\nfor row in iterable:\r\n    n += 1\r\n    if n % 10000 == 0: print('Processing %d' % (n))\r\n    write_iterable.write(row)\r\n```\r\n\r\n\r\n\r\n## Examples and tests\r\n\r\nSee [tests](tests/) for example usage\r\n\r\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "https://github.com/apicrafter/pyiterable/",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/apicrafter/pyiterable/",
    "keywords": "json jsonl csv bson parquet orc xml xls xlsx dataset etl data-pipelines",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "iterabledata",
    "package_url": "https://pypi.org/project/iterabledata/",
    "platform": null,
    "project_url": "https://pypi.org/project/iterabledata/",
    "project_urls": {
      "Download": "https://github.com/apicrafter/pyiterable/",
      "Homepage": "https://github.com/apicrafter/pyiterable/"
    },
    "release_url": "https://pypi.org/project/iterabledata/1.0.2/",
    "requires_dist": null,
    "requires_python": ">=3.8",
    "summary": "Iterable data processing Python library",
    "version": "1.0.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16203795,
  "releases": {
    "1.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f6ca9cecfff8829dfbb15d1f54b974e15c6dff76eb4c51e3c10ffdd1aff48380",
          "md5": "c8c5e8941933a4918658e3aeb6e002b0",
          "sha256": "c0a05329329145ba9e8b17ed736387d5dcc152dd33f9c90c119782018c442fee"
        },
        "downloads": -1,
        "filename": "iterabledata-1.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "c8c5e8941933a4918658e3aeb6e002b0",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 18459,
        "upload_time": "2022-12-24T07:24:52",
        "upload_time_iso_8601": "2022-12-24T07:24:52.513885Z",
        "url": "https://files.pythonhosted.org/packages/f6/ca/9cecfff8829dfbb15d1f54b974e15c6dff76eb4c51e3c10ffdd1aff48380/iterabledata-1.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "f6ca9cecfff8829dfbb15d1f54b974e15c6dff76eb4c51e3c10ffdd1aff48380",
        "md5": "c8c5e8941933a4918658e3aeb6e002b0",
        "sha256": "c0a05329329145ba9e8b17ed736387d5dcc152dd33f9c90c119782018c442fee"
      },
      "downloads": -1,
      "filename": "iterabledata-1.0.2.tar.gz",
      "has_sig": false,
      "md5_digest": "c8c5e8941933a4918658e3aeb6e002b0",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.8",
      "size": 18459,
      "upload_time": "2022-12-24T07:24:52",
      "upload_time_iso_8601": "2022-12-24T07:24:52.513885Z",
      "url": "https://files.pythonhosted.org/packages/f6/ca/9cecfff8829dfbb15d1f54b974e15c6dff76eb4c51e3c10ffdd1aff48380/iterabledata-1.0.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}