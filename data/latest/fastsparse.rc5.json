{
  "info": {
    "author": "David Cato",
    "author_email": "dcato98@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: Apache Software License",
      "Natural Language :: English",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8"
    ],
    "description": "# FastSparse\n> Customizable Fastai+PyTorch implementation of sparse model training methods (SET, SNFS, RigL).\n\n\n## _Warning: this repo is undergoing active development_\n\n## Getting Started\n\n### Install\n\n`pip install fastsparse`\n\n### Sparse Algorithms\n\nThis network implements the following sparse algorithms:\n\n| Abbr. | Sparse Algorithm | in FastSparse | Notes |\n| :- | :- | :- | :- |\n|  | static sparsity baseline | omit `DynamicSparseTrainingCallback` |  |\n| SET | [Sparse Evolutionary Training](https://arxiv.org/abs/1901.09181) (Jan 2019) | `DynamicSparseTrainingCallback(**SET_presets)` |  |\n| SNFS | [Sparse Networks From Scratch](https://arxiv.org/abs/1907.04840) (Jul 2019) | `DynamicSparseTrainingCallback(**SNFS_presets)` | redistribution not implemented* |\n| RigL | [Rigged Lottery](https://arxiv.org/abs/1911.11134) (Nov 2019) | `DynamicSparseTrainingCallback(**RigL_presets)` |  |\n\n\\*Authors of the RigL paper demonstrate that using SNFS + Erdos-Renyi-Kernel distribution - redistribution outperforms SNFS + uniform sparsity + redistribution (at least on the measured benchmarks).\n\n### Fastai demo\n\nWith just 4 additional lines of code, you can train your model using the latest dynamic sparse training techniques. This example achieves >99% accuracy on MNIST using a ResNet34 with only 1% of the weights.\n\n```python\n# (0) install the library\n# ! pip install fastsparse \n\nfrom fastai.vision.all import *\n\n# (1) import this package\nimport fastsparse as sparse\n\npath = untar_data(URLs.MNIST)\ndls = ImageDataLoaders.from_folder(path, 'training', 'testing')\nlearn = cnn_learner(dls, resnet34, metrics=error_rate, pretrained=False)\n\n# (2) sparsify initial model + enforce masks\nsparse_hooks = sparse.sparsify_model(learn.model, \n                                     model_sparsity=0.99,\n                                     sparse_f=sparse.erdos_renyi_sparsity)\n\n# (3) schedule dynamic mask updates\ncbs = [sparse.DynamicSparseTrainingCallback(**sparse.SNFS_presets, \n                                            batches_per_update=32)]\n\nlearn.fit_one_cycle(5, cbs=cbs)\n\n# (4) remove hooks that enforce masks\nsparse_hooks.remove()\n```\n\nSimply omit the `DynamicSparseTrainingCallback` to train a fixed-sparsity model as a baseline.\n\n### PyTorch demo (*not implemented yet*)\n\n```python\nimport torch\nfrom torchvision import models\n\ndata = ...\nmodel = ...\nopt = ...\nopt = DynamicSparseTrainingOptimizerWrapper(model, opt, **RigL_kwargs)\n\n### Modified training step\n# sparse_opt.step(...) will determine whether to:\n#  (A) take a regular opt step, or\n#  (B) update network connectivity\ndef sparse_train_step(model, xb, yb, loss_func, sparse_opt, step, pct_train):\n    preds = model(xb)\n    loss = loss_func(preds, yb)\n    loss.backward()\n    sparse_opt.step(step, pct_train)\n    sparse_opt.zero_grad()\n```\n\n### Save/Reload demo\n\nHere is an example of saving a model and reloading it to resume training.\n\n```python\nfrom fastai.vision.all import *\nfrom fastsparse import *\n\npath = untar_data(URLs.MNIST_TINY)\ndls = ImageDataLoaders.from_folder(untar_data(URLs.MNIST_TINY))\nlearn = cnn_learner(dls, resnet18, metrics=accuracy, pretrained=False)\nsparse_hooks = sparsify_model(learn.model, model_sparsity=0.9, sparse_f=erdos_renyi_sparsity)\ndst_kwargs = {**SNFS_presets, **{'batches_per_update': 8}}\ncbs = DynamicSparseTrainingCallback(**dst_kwargs)\n\nlearn.fit_flat_cos(5, cbs=cbs)\n\n# (0) save model as usual (masks are stored automatically)\nsave_model('sparse_tiny_mnist', learn.model, learn.opt)\n```\n\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.482798</td>\n      <td>0.698934</td>\n      <td>0.505007</td>\n      <td>00:02</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.302442</td>\n      <td>0.656283</td>\n      <td>0.512160</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.238623</td>\n      <td>0.175693</td>\n      <td>0.935622</td>\n      <td>00:02</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.203908</td>\n      <td>0.028619</td>\n      <td>0.992847</td>\n      <td>00:02</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.162143</td>\n      <td>0.033945</td>\n      <td>0.989986</td>\n      <td>00:02</td>\n    </tr>\n  </tbody>\n</table>\n\n\n```python\n### manually restart notebook ###\n\n# (1) then recreate learner as usual\n\nfrom fastai.vision.all import *\nfrom fastsparse import *\n\npath = untar_data(URLs.MNIST_TINY)\ndls = ImageDataLoaders.from_folder(untar_data(URLs.MNIST_TINY))\nlearn = cnn_learner(dls, resnet18, metrics=accuracy, pretrained=False)\n\n# (2) re-sparsify model (this adds the masks to the parameters)\nsparse_hooks = sparsify_model(learn.model, model_sparsity=0.9, sparse_f=erdos_renyi_sparsity) # <-- initial sparsity + enforce masks\n\n# (3) load model as usual\nload_model('sparse_tiny_mnist', learn.model, learn.opt)\n\n# (5) check validation loss & accuracy to verify we've loaded it successfully\nval_loss, val_acc = learn.validate()\nprint(f'validation loss: {val_loss}, validation accuracy: {val_acc}')\n\n# (4) optionally, continue training; otherwise remove sparsity-preserving hooks\nsparse_hooks.remove()\n```\n\n    /home/dc/anaconda3/envs/fastai/lib/python3.8/site-packages/fastai/learner.py:53: UserWarning: Could not load the optimizer state.\n      if with_opt: warn(\"Could not load the optimizer state.\")\n\n\n\n\n\n\n    validation loss: 0.033944640308618546, validation accuracy: 0.9899857044219971\n\n\n### Training with Large Batch Sizes\n\nAuthors of the Rigged Lottery paper hypothesize that the effectiveness of using the gradient magnitude for determining which connections to grow is partly due to their large batch size (4096 for ImageNet). Those without access to multi-gpu clusters can achieve effective batch sizes of this size by using fastai's `GradientAccumulation` callback, which has been tested to be compatible with this package's `DynamicSparseTrainingCallback`.\n\n### Training with Small # of Epochs\n\nDynamic sparse training algorithms work by modifying the network connectivity during training, dropping some weights and allowing others to regrow. By default, network connectivity is modified at the end of each epoch. When training with few epochs, however, there will be few chances to explore which weights to connect. To update more frequently, in `DynamicSparseTrainingCallback`, set `batches_per_update` to a smaller # of batches than occur in one training epoch. Varying the number of batches per update trades off the frequency of updates with stability in making good updates.\n\n## Customization\n\nThere are many ways to implement and test your own dynamic sparse algorithms using FastSparse.\n\n### Custom Initial Sparsity Distribution:\n\nDefine your own initial sparsity distribution by setting `sparsify_method` in `sparsify_model` to a custom function. For example, this function (included in library) will keep the first layer dense and set the remaining layers to a fixed sparsity.\n\n```python\ndef first_layer_dense_uniform(params:list, model_sparsity:float):\n    sparsities = [1.] + [model_sparsity] * (len(params) - 1)\n    return sparsities\n```\n\n### Custom Drop Criterion\n\nWhile published papers like SNFS and RigL refer to 'drop criterion', this library implements the reverse, a 'keep criterion'. This is a function that returns a score for each weight, where the largest `M` scores will be and `M` is determined by the decay schedule. For example, both Sparse Networks From Scratch and Rigged Lottery both use the magnitude of the weights (in FastSparse: `weight_magnitude`).\n\nThis can easily be customized in FastSparse by defining your own keep score function:\n\n```python\ndef custom_keep_scoring_function(param, opt):\n    score = ...\n    assert param.shape == score.shape\n    return score\n```\n\nThen pass your custom function into the sparse training callback:\n\n```python\nDynamicSparseTrainingCallback(..., keep_score_f=custom_keep_scoring_function)\n```\n\n### Custom Grow Criterion\n\nThe grow criterion is a function that returns a score for each weight, where the largest `N` scores will be and `N` is determined by the decay schedule. For example, Sparse Networks From Scrath grows weights according to the momentum of the gradient, while Rigged Lottery uses the magnitude of the gradient (in FastSparse, `gradient_momentum` and `gradient_magnitude` respectively).\n\n```python\ndef custom_grow_scoring_function(param, opt):\n    score = ...\n    assert param.shape == score.shape\n    return score\n```\n\nThen pass your custom function into the sparse training callback:\n\n```python\nDynamicSparseTrainingCallback(..., grow_score_f=custom_grow_scoring_function)\n```\n\n## Replication Results\n\nIn machine learning, is very easy for seemingly insignificant differences in algorithmic implementation to have a noticeable impact on final results. Therefore, this section compares results from this implementation to results reported in published papers.\n\nTODO...\n\n## Under-The-Hood Details\n\nHere's what's going on. \n\nWhen you run `sparsify_model(learn.model, 0.9)`, this adds sparse masks and add pre_forward hooks to enforce masks on weights during forward pass.\n\n> By default, a uniform sparsity distribution is used. Change the sparsity distribution to Erdos-Renyi with `sparsify_model(learn.model, 0.9, sparse_init_f=erdos_renyi)`, or pass in your custom function (see [Customization](#Customization)\n\n> To avoid adding pre_forward hooks, use `sparsify_model(learn.model, 0.9, enforce_masks=False)`.\n\nWhen you add the `DynamicSparseTrainingCallback` callback, ... TODO complete section\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/dcato98/fastsparse/tree/master/",
    "keywords": "sparse fastai fastai-implementation pytorch nbdev",
    "license": "Apache Software License 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "fastsparse",
    "package_url": "https://pypi.org/project/fastsparse/",
    "platform": "",
    "project_url": "https://pypi.org/project/fastsparse/",
    "project_urls": {
      "Homepage": "https://github.com/dcato98/fastsparse/tree/master/"
    },
    "release_url": "https://pypi.org/project/fastsparse/0.0.5/",
    "requires_dist": [
      "fastai"
    ],
    "requires_python": ">=3.6",
    "summary": "Fastai+PyTorch implementation of sparse model training methods (SET, SNFS, and RigL).",
    "version": "0.0.5",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8732996,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "86588de0715ff8886679512d83de65e37d1736a3f5e28b3be0f79f28fbca6107",
          "md5": "4b80abc983085090a8dae0c1498fa166",
          "sha256": "ef463f05d3117bf64c7235c43230fdb0d175e3b6816d064130e60b86b80c2e18"
        },
        "downloads": -1,
        "filename": "fastsparse-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "4b80abc983085090a8dae0c1498fa166",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 12305,
        "upload_time": "2020-11-20T16:02:39",
        "upload_time_iso_8601": "2020-11-20T16:02:39.573061Z",
        "url": "https://files.pythonhosted.org/packages/86/58/8de0715ff8886679512d83de65e37d1736a3f5e28b3be0f79f28fbca6107/fastsparse-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8f0b27f8c26a6313ea886f83b093d5a957ca50ec28d79c3ad13ceced7dbcfbd9",
          "md5": "61a0c0f691cb999e1d65d9a58542e21e",
          "sha256": "a5b0a8a81f17996dca6f39781ba3c22808f2f8a0539d777cde2b648a11ff341b"
        },
        "downloads": -1,
        "filename": "fastsparse-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "61a0c0f691cb999e1d65d9a58542e21e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 14899,
        "upload_time": "2020-11-20T16:02:41",
        "upload_time_iso_8601": "2020-11-20T16:02:41.202942Z",
        "url": "https://files.pythonhosted.org/packages/8f/0b/27f8c26a6313ea886f83b093d5a957ca50ec28d79c3ad13ceced7dbcfbd9/fastsparse-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "716a795faa99daa6102bd84e45dbf959ec6542755a5e21d0a1a813390c133e0a",
          "md5": "ba2131d15e468097e6207c5a3f765612",
          "sha256": "44dd7d291dbe9ad7c950ac95f3c520ae533b66e35576cd9d988deb51801f2fc8"
        },
        "downloads": -1,
        "filename": "fastsparse-0.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ba2131d15e468097e6207c5a3f765612",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 12070,
        "upload_time": "2020-11-21T16:11:14",
        "upload_time_iso_8601": "2020-11-21T16:11:14.391752Z",
        "url": "https://files.pythonhosted.org/packages/71/6a/795faa99daa6102bd84e45dbf959ec6542755a5e21d0a1a813390c133e0a/fastsparse-0.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5de980fa542d3b460e27c9284f9816a9fd43b390634b49d0d0fdb75a9b7c61d7",
          "md5": "7bc32dd9adffb5f7af4f8602c6b68140",
          "sha256": "242c57a8f8a948c629347910f88c2404da363725e318cbb4b57a82baea676f81"
        },
        "downloads": -1,
        "filename": "fastsparse-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "7bc32dd9adffb5f7af4f8602c6b68140",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 13972,
        "upload_time": "2020-11-21T16:11:15",
        "upload_time_iso_8601": "2020-11-21T16:11:15.975631Z",
        "url": "https://files.pythonhosted.org/packages/5d/e9/80fa542d3b460e27c9284f9816a9fd43b390634b49d0d0fdb75a9b7c61d7/fastsparse-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "53a80792da640cafe99edd5fb693c98b335c036f1a4b91cf5004d012b7787273",
          "md5": "bf876facaeb2fe6d41371b51ca7b8007",
          "sha256": "6409660d3141597738f05e50029d1dd8229cb4c703526db0be57399dd046b07d"
        },
        "downloads": -1,
        "filename": "fastsparse-0.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "bf876facaeb2fe6d41371b51ca7b8007",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 12154,
        "upload_time": "2020-11-23T16:50:57",
        "upload_time_iso_8601": "2020-11-23T16:50:57.898055Z",
        "url": "https://files.pythonhosted.org/packages/53/a8/0792da640cafe99edd5fb693c98b335c036f1a4b91cf5004d012b7787273/fastsparse-0.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6fa944ebd5ddf5b8908cc5e5cf5fe5c5dd563c5e62cbf46e9e78b0e03527318d",
          "md5": "01348cd593e89f00e5e3e53fb58c3e8b",
          "sha256": "89703948160b7778a96b5bf3d79fbaf244a671dbcc38ac8dbcf52b92d75de55d"
        },
        "downloads": -1,
        "filename": "fastsparse-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "01348cd593e89f00e5e3e53fb58c3e8b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 14025,
        "upload_time": "2020-11-23T16:50:59",
        "upload_time_iso_8601": "2020-11-23T16:50:59.115107Z",
        "url": "https://files.pythonhosted.org/packages/6f/a9/44ebd5ddf5b8908cc5e5cf5fe5c5dd563c5e62cbf46e9e78b0e03527318d/fastsparse-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b2679429a37d69b811dac7338a00647f7bd82553448789b219c72454691aec9b",
          "md5": "7f49fb0d6c8e00bc3f2e8be58e4178fa",
          "sha256": "8646062dd968b5113e209ae4a6457c63f15726b067e2c9f14840839969eca081"
        },
        "downloads": -1,
        "filename": "fastsparse-0.0.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "7f49fb0d6c8e00bc3f2e8be58e4178fa",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 14264,
        "upload_time": "2020-11-23T17:31:10",
        "upload_time_iso_8601": "2020-11-23T17:31:10.452277Z",
        "url": "https://files.pythonhosted.org/packages/b2/67/9429a37d69b811dac7338a00647f7bd82553448789b219c72454691aec9b/fastsparse-0.0.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ba1e970e27bc732a210a5477f40d968ad2bbe78f6a2a2ffe0066b2530da286fa",
          "md5": "91ff1390f45a7416ccf683463642249b",
          "sha256": "5445076fac26b7d2b9cf4351b15903e0db2f8e4750a47bf93521e74d1f92d7ea"
        },
        "downloads": -1,
        "filename": "fastsparse-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "91ff1390f45a7416ccf683463642249b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 19267,
        "upload_time": "2020-11-23T17:31:11",
        "upload_time_iso_8601": "2020-11-23T17:31:11.676622Z",
        "url": "https://files.pythonhosted.org/packages/ba/1e/970e27bc732a210a5477f40d968ad2bbe78f6a2a2ffe0066b2530da286fa/fastsparse-0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "14b36777744a01f0cc853951d3669574f24fab5080da6ade29adb5e1b0e8281a",
          "md5": "0a83739812dd0fb07793281232b1cea5",
          "sha256": "b924e51c0f64a5127a866fd0343b61698e198a772f08c8d3e5a15c3ba335afe2"
        },
        "downloads": -1,
        "filename": "fastsparse-0.0.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0a83739812dd0fb07793281232b1cea5",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 14251,
        "upload_time": "2020-11-24T00:16:05",
        "upload_time_iso_8601": "2020-11-24T00:16:05.423578Z",
        "url": "https://files.pythonhosted.org/packages/14/b3/6777744a01f0cc853951d3669574f24fab5080da6ade29adb5e1b0e8281a/fastsparse-0.0.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ab06b443de0eb4cd34711fced354cea19ca50d7b4fff74e6dd9cf1cd3331df42",
          "md5": "2be8e0efca5302ae93cba2cd62a7191b",
          "sha256": "eaec1e92bbde32e2270fb31cdf07ff1cff58839045a0f9dab1d40930e4e1d899"
        },
        "downloads": -1,
        "filename": "fastsparse-0.0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "2be8e0efca5302ae93cba2cd62a7191b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 19276,
        "upload_time": "2020-11-24T00:16:06",
        "upload_time_iso_8601": "2020-11-24T00:16:06.935381Z",
        "url": "https://files.pythonhosted.org/packages/ab/06/b443de0eb4cd34711fced354cea19ca50d7b4fff74e6dd9cf1cd3331df42/fastsparse-0.0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "14b36777744a01f0cc853951d3669574f24fab5080da6ade29adb5e1b0e8281a",
        "md5": "0a83739812dd0fb07793281232b1cea5",
        "sha256": "b924e51c0f64a5127a866fd0343b61698e198a772f08c8d3e5a15c3ba335afe2"
      },
      "downloads": -1,
      "filename": "fastsparse-0.0.5-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "0a83739812dd0fb07793281232b1cea5",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 14251,
      "upload_time": "2020-11-24T00:16:05",
      "upload_time_iso_8601": "2020-11-24T00:16:05.423578Z",
      "url": "https://files.pythonhosted.org/packages/14/b3/6777744a01f0cc853951d3669574f24fab5080da6ade29adb5e1b0e8281a/fastsparse-0.0.5-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "ab06b443de0eb4cd34711fced354cea19ca50d7b4fff74e6dd9cf1cd3331df42",
        "md5": "2be8e0efca5302ae93cba2cd62a7191b",
        "sha256": "eaec1e92bbde32e2270fb31cdf07ff1cff58839045a0f9dab1d40930e4e1d899"
      },
      "downloads": -1,
      "filename": "fastsparse-0.0.5.tar.gz",
      "has_sig": false,
      "md5_digest": "2be8e0efca5302ae93cba2cd62a7191b",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 19276,
      "upload_time": "2020-11-24T00:16:06",
      "upload_time_iso_8601": "2020-11-24T00:16:06.935381Z",
      "url": "https://files.pythonhosted.org/packages/ab/06/b443de0eb4cd34711fced354cea19ca50d7b4fff74e6dd9cf1cd3331df42/fastsparse-0.0.5.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}