{
  "info": {
    "author": "Intel Labs",
    "author_email": "ranganath.krishnan@intel.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Developers",
      "Intended Audience :: Science/Research",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.7",
      "Topic :: Scientific/Engineering",
      "Topic :: Scientific/Engineering :: Artificial Intelligence",
      "Topic :: Software Development :: Libraries",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "<div align=\"center\">\n\n<img src=\"https://raw.githubusercontent.com/IntelLabs/bayesian-torch/5a4793ba0a54660c891df8af0d5729e840340a88/assets/bayesian-torch.png\" width=\"500px\">\n<h2 >\nA library for Bayesian neural network layers and uncertainty estimation in Deep Learning </a>\n</h2>\n\n[![python](https://img.shields.io/badge/python-3.7%2B-blue)](https://github.com/IntelLabs/bayesian-torch)\n[![pytorch](https://img.shields.io/badge/pytorch-1.7.0%2B-orange)](https://github.com/IntelLabs/bayesian-torch)\n[![version](https://img.shields.io/badge/release-0.2.1-green)](https://github.com/IntelLabs/bayesian-torch/releases)\n[![license](https://img.shields.io/badge/license-BSD%203--Clause-blue)](https://github.com/IntelLabs/bayesian-torch/blob/main/LICENSE)\n[![Downloads](https://static.pepy.tech/personalized-badge/bayesian-torch?period=total&units=international_system&left_color=grey&right_color=darkblue&left_text=downloads)](https://pepy.tech/project/bayesian-torch)\n<h4 align=\"center\">\n  <a href=\"https://github.com/IntelLabs/bayesian-torch#installing-bayesian-torch\">Get Started</a> |\n  <a href=\"https://github.com/IntelLabs/bayesian-torch#usage\">Example usage</a> |\n  <a href=\"https://github.com/IntelLabs/bayesian-torch/blob/main/doc/bayesian_torch.layers.md\">Documentation</a> |\n  <a href=\"https://github.com/IntelLabs/bayesian-torch#citing\">Citing</a>   \n</h4>\n\n</div>\n\n___\n\nBayesian-Torch is a library of neural network layers and utilities extending the core of PyTorch to enable Bayesian inference in deep learning models to quantify principled uncertainty estimates in model predictions.\n\n## Overview\nBayesian-Torch is designed to be flexible and enables seamless extension of deterministic deep neural network model to corresponding Bayesian form by simply replacing the deterministic layers with Bayesian layers. It enables user to perform stochastic variational inference in deep neural networks. \n\n**Bayesian layers:**\n\n* **[Variational layers with reparameterized Monte Carlo estimators](https://github.com/IntelLabs/bayesian-torch/tree/main/bayesian_torch/layers/variational_layers)** [[Blundell et al. 2015](https://arxiv.org/abs/1505.05424)]\n\n      \n      LinearReparameterization \n      Conv1dReparameterization, Conv2dReparameterization, Conv3dReparameterization, ConvTranspose1dReparameterization, ConvTranspose2dReparameterization, ConvTranspose3dReparameterization\n      LSTMReparameterization\n      \n* **[Variational layers with Flipout Monte Carlo estimators](https://github.com/IntelLabs/bayesian-torch/tree/main/bayesian_torch/layers/flipout_layers)** [[Wen et al. 2018](https://arxiv.org/abs/1803.04386)]\n      \n      LinearFlipout \n      Conv1dFlipout, Conv2dFlipout, Conv3dFlipout, ConvTranspose1dFlipout, ConvTranspose2dFlipout, ConvTranspose3dFlipout\n      LSTMFlipout\n\n\n\n**Key features:**\n* [dnn_to_bnn()](https://github.com/IntelLabs/bayesian-torch/blob/main/bayesian_torch/models/dnn_to_bnn.py#L127): An API to convert deterministic deep neural network (dnn) model of any architecture to Bayesian deep neural network (bnn) model, simplifying the model definition i.e. drop-in replacements  of Convolutional, Linear and LSTM layers to corresponding Bayesian layers. This will enable seamless conversion of existing topology of larger models to Bayesian deep neural network models for extending towards uncertainty-aware applications. \n* [MOPED](https://github.com/IntelLabs/bayesian-torch/blob/main/bayesian_torch/utils/util.py#L72): Specifying weight priors and variational posteriors in Bayesian neural networks with Empirical Bayes [[Krishnan et al. 2020](https://ojs.aaai.org/index.php/AAAI/article/view/5875)]\n* [AvUC](https://github.com/IntelLabs/bayesian-torch/blob/main/bayesian_torch/utils/avuc_loss.py): Accuracy versus Uncertainty Calibration loss [[Krishnan and Tickoo 2020](https://proceedings.neurips.cc/paper/2020/file/d3d9446802a44259755d38e6d163e820-Paper.pdf)]\n\n## Installing Bayesian-Torch\n\n**To install core library using `pip`:**\n```\npip install bayesian-torch\n```\n\n**To install latest development version from source:**\n```sh\ngit clone https://github.com/IntelLabs/bayesian-torch\ncd bayesian-torch\npip install .\n```\n<!--\nThis code has been tested on PyTorch v1.8.1 LTS.\n\nDependencies:\n\n- Create conda environment with python=3.7\n- Install PyTorch and torchvision packages within conda environment following instructions from [PyTorch install guide](https://pytorch.org/get-started/locally/)\n- conda install -c conda-forge accimage\n- pip install tensorboard\n- pip install scikit-learn\n-->\n\n## Usage\nThere are two ways to build Bayesian deep neural networks using Bayesian-Torch: \n1. Convert an existing deterministic deep neural network (dnn) model to Bayesian deep neural network (bnn) model with dnn_to_bnn() API\n2. Define your custom model using the Bayesian layers ([Reparameterization](https://github.com/IntelLabs/bayesian-torch/tree/main/bayesian_torch/layers/variational_layers) or [Flipout](https://github.com/IntelLabs/bayesian-torch/tree/main/bayesian_torch/layers/flipout_layers))\n\n(1) For instance, building Bayesian-ResNet18 from torchvision deterministic ResNet18 model is as simple as:\n```\nimport torch\nimport torchvision\nfrom bayesian_torch.models.dnn_to_bnn import dnn_to_bnn, get_kl_loss\n\nconst_bnn_prior_parameters = {\n        \"prior_mu\": 0.0,\n        \"prior_sigma\": 1.0,\n        \"posterior_mu_init\": 0.0,\n        \"posterior_rho_init\": -3.0,\n        \"type\": \"Reparameterization\",  # Flipout or Reparameterization\n        \"moped_enable\": False,  # True to initialize mu/sigma from the pretrained dnn weights\n        \"moped_delta\": 0.5,\n}\n    \nmodel = torchvision.models.resnet18()\ndnn_to_bnn(model, const_bnn_prior_parameters)\n```\nTo use MOPED method i.e. setting the prior and initializing variational parameters from a pretrained deterministic model (helps training convergence of larger models):\n```\nconst_bnn_prior_parameters = {\n        \"prior_mu\": 0.0,\n        \"prior_sigma\": 1.0,\n        \"posterior_mu_init\": 0.0,\n        \"posterior_rho_init\": -3.0,\n        \"type\": \"Reparameterization\",  # Flipout or Reparameterization\n        \"moped_enable\": True,  # True to initialize mu/sigma from the pretrained dnn weights\n        \"moped_delta\": 0.5,\n}\n    \nmodel = torchvision.models.resnet18(pretrained=True)\ndnn_to_bnn(model, const_bnn_prior_parameters)\n```\nTraining snippet:\n```\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), args.learning_rate)\n\noutput = model(x_train)\nkl = get_kl_loss(model)\nce_loss = criterion(output, y_train)\nloss = ce_loss + kl / args.batch_size \n\nloss.backward()\noptimizer.step()\n```\nTesting snippet:\n```\nmodel.eval()\nwith torch.no_grad():\n    output_mc = []\n    for mc_run in range(args.num_monte_carlo):\n        logits = model(x_test)\n        probs = torch.nn.functional.softmax(logits, dim=-1)\n        output_mc.append(probs)\n    output = torch.stack(output_mc)  \n    pred_mean = output.mean(dim=0)\n    y_pred = torch.argmax(pred_mean, axis=-1)\n    test_acc = (y_pred.data.cpu().numpy() == y_test.data.cpu().numpy()).mean()\n```\nUncertainty Quantification:\n```\nfrom utils.util import predictive_entropy, mutual_information\n\npredictive_uncertainty = predictive_entropy(output.data.cpu().numpy())\nmodel_uncertainty = mutual_information(output.data.cpu().numpy())\n```\n\n(2) For building custom models, we have provided [example model implementations](https://github.com/IntelLabs/bayesian-torch/tree/main/bayesian_torch/models/bayesian) using the Bayesian layers.\n\n## Example usage (training and evaluation of models)\n\nWe have provided [example usages](https://github.com/IntelLabs/bayesian-torch/tree/main/bayesian_torch/examples) and [scripts](https://github.com/IntelLabs/bayesian-torch/tree/main/bayesian_torch/scripts) to train/evaluate the models. The instructions for CIFAR10 examples is provided below, similar scripts for ImageNet and MNIST are available.\n```\ncd bayesian_torch\n```\n### Training\n\nTo train Bayesian ResNet on CIFAR10, run this command:\n\n**Mean-field variational inference (Reparameterized Monte Carlo estimator)**\n```train\nsh scripts/train_bayesian_cifar.sh\n```\n\n**Mean-field variational inference (Flipout Monte Carlo estimator)**\n```train\nsh scripts/train_bayesian_flipout_cifar.sh\n```\n\nTo train deterministic ResNet on CIFAR10, run this command:\n\n**Vanilla**\n```train\nsh scripts/train_deterministic_cifar.sh\n```\n\n\n### Evaluation\n\nTo evaluate Bayesian ResNet on CIFAR10, run this command:\n\n**Mean-field variational inference (Reparameterized Monte Carlo estimator)**\n```test\nsh scripts/test_bayesian_cifar.sh\n```\n\n**Mean-field variational inference (Flipout Monte Carlo estimator)**\n```test\nsh scripts/test_bayesian_flipout_cifar.sh\n```\n\nTo evaluate deterministic ResNet on CIFAR10, run this command:\n\n**Vanilla**\n```test\nsh scripts/test_deterministic_cifar.sh\n```\n\n## Citing\n\nIf you use this code, please cite as:\n```sh\n@software{krishnan2022bayesiantorch,\n  author       = {Ranganath Krishnan and Pi Esposito and Mahesh Subedar},               \n  title        = {Bayesian-Torch: Bayesian neural network layers for uncertainty estimation},\n  month        = jan,\n  year         = 2022,\n  doi          = {10.5281/zenodo.5908307},\n  url          = {https://doi.org/10.5281/zenodo.5908307}\n  howpublished = {\\url{https://github.com/IntelLabs/bayesian-torch}}\n}\n```\nAccuracy versus Uncertainty Calibration (AvUC) loss\n```sh\n@inproceedings{NEURIPS2020_d3d94468,\n title = {Improving model calibration with accuracy versus uncertainty optimization},\n author = {Krishnan, Ranganath and Tickoo, Omesh},\n booktitle = {Advances in Neural Information Processing Systems},\n volume = {33},\n pages = {18237--18248},\n year = {2020},\n url = {https://proceedings.neurips.cc/paper/2020/file/d3d9446802a44259755d38e6d163e820-Paper.pdf}\n \n}\n```\nMOdel Priors with Empirical Bayes using DNN (MOPED)\n```sh\n@inproceedings{krishnan2020specifying,\n  title={Specifying weight priors in bayesian deep neural networks with empirical bayes},\n  author={Krishnan, Ranganath and Subedar, Mahesh and Tickoo, Omesh},\n  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},\n  volume={34},\n  number={04},\n  pages={4477--4484},\n  year={2020},\n  url = {https://ojs.aaai.org/index.php/AAAI/article/view/5875}\n}\n```\n\nThis library and code is intended for researchers and developers, enables to quantify principled uncertainty estimates from deep learning model predictions using stochastic variational inference in Bayesian neural networks. \nFeedbacks, issues and contributions are welcome. Email to <ranganath.krishnan@intel.com> for any questions.\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/IntelLabs/bayesian-torch",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "bayesian-torch",
    "package_url": "https://pypi.org/project/bayesian-torch/",
    "platform": null,
    "project_url": "https://pypi.org/project/bayesian-torch/",
    "project_urls": {
      "Homepage": "https://github.com/IntelLabs/bayesian-torch"
    },
    "release_url": "https://pypi.org/project/bayesian-torch/0.3.0/",
    "requires_dist": [
      "torch (>=1.7.0)",
      "torchvision (>=0.8.1)",
      "tensorboard (>=1.15.0)",
      "scikit-learn (>=0.20.3)"
    ],
    "requires_python": "",
    "summary": "A library for Bayesian neural network layers and uncertainty estimation in Deep Learning",
    "version": "0.3.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16095682,
  "releases": {
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "06534488bc3597496b4764b4f36fd166944204e83c2be18216582b94390ec46c",
          "md5": "2169ccbd778962207bc5a8fc6e0cd934",
          "sha256": "95ce7a28861d84207b4e1f67f9d3d0d7331c0108736a793af9c8c012a587860d"
        },
        "downloads": -1,
        "filename": "bayesian_torch-0.2.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "2169ccbd778962207bc5a8fc6e0cd934",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 48420,
        "upload_time": "2022-01-31T18:02:25",
        "upload_time_iso_8601": "2022-01-31T18:02:25.785133Z",
        "url": "https://files.pythonhosted.org/packages/06/53/4488bc3597496b4764b4f36fd166944204e83c2be18216582b94390ec46c/bayesian_torch-0.2.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "671232d75481d394ebb8a5889ed1bda54aed867f8eb8b6c1b140cb99e9ea593f",
          "md5": "957756684bf186bfdbfb2bafb07fa823",
          "sha256": "5bcafedb1353b32239dfbeb8f1ff4887e08475cbf62dfd38a0e6652d76686853"
        },
        "downloads": -1,
        "filename": "bayesian-torch-0.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "957756684bf186bfdbfb2bafb07fa823",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 84059,
        "upload_time": "2022-01-31T18:02:27",
        "upload_time_iso_8601": "2022-01-31T18:02:27.627554Z",
        "url": "https://files.pythonhosted.org/packages/67/12/32d75481d394ebb8a5889ed1bda54aed867f8eb8b6c1b140cb99e9ea593f/bayesian-torch-0.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f91be3dc713a76ad7d325099cdf31545d6e6db278f34dbf6ba788aeafb974e55",
          "md5": "008b23ecc09626567dbf4f0512426549",
          "sha256": "e6fd5ca7e12e68cc535bdd0a4e75fda3ad59e5ca251bb923e60f1fb2db144faf"
        },
        "downloads": -1,
        "filename": "bayesian_torch-0.2.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "008b23ecc09626567dbf4f0512426549",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 48464,
        "upload_time": "2022-02-01T20:32:10",
        "upload_time_iso_8601": "2022-02-01T20:32:10.876787Z",
        "url": "https://files.pythonhosted.org/packages/f9/1b/e3dc713a76ad7d325099cdf31545d6e6db278f34dbf6ba788aeafb974e55/bayesian_torch-0.2.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2888f227e2316cc6aecd36b5c4324e847c5a65bcb10221a0bc66e33d4baa74ba",
          "md5": "c70069bde5003dd58b77e15a24c59272",
          "sha256": "d6fe09e1bc46fc2d759e4e9c5aa5c5e580d7eb9ac857cc474b9937a227cc9a99"
        },
        "downloads": -1,
        "filename": "bayesian-torch-0.2.1.tar.gz",
        "has_sig": false,
        "md5_digest": "c70069bde5003dd58b77e15a24c59272",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 84167,
        "upload_time": "2022-02-01T20:32:12",
        "upload_time_iso_8601": "2022-02-01T20:32:12.559639Z",
        "url": "https://files.pythonhosted.org/packages/28/88/f227e2316cc6aecd36b5c4324e847c5a65bcb10221a0bc66e33d4baa74ba/bayesian-torch-0.2.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "39a3108b6daca1d0c55b70f3509b9bffd7f5fafb9cc457c8c83c4ab3d7ae624d",
          "md5": "ae36f8228e0c9bcc8b68010423b6033e",
          "sha256": "8d87c2fead0bda0b49b76c5b2a570fac47f166e3eef9ca95a50a67e0c4c80b3a"
        },
        "downloads": -1,
        "filename": "bayesian_torch-0.3.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ae36f8228e0c9bcc8b68010423b6033e",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 48705,
        "upload_time": "2022-12-14T05:06:42",
        "upload_time_iso_8601": "2022-12-14T05:06:42.953463Z",
        "url": "https://files.pythonhosted.org/packages/39/a3/108b6daca1d0c55b70f3509b9bffd7f5fafb9cc457c8c83c4ab3d7ae624d/bayesian_torch-0.3.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7977bab8d5b8bf963512fbc610bab1e628156b82ff47d777cdcdbe151aedd8a3",
          "md5": "b4733780eb310b4bd4403d667e64dc0d",
          "sha256": "996186ae7fcd8ec4ff3341d018b391a6077f0b729d9ed0055bf1abdd9257b769"
        },
        "downloads": -1,
        "filename": "bayesian-torch-0.3.0.tar.gz",
        "has_sig": false,
        "md5_digest": "b4733780eb310b4bd4403d667e64dc0d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 84629,
        "upload_time": "2022-12-14T05:06:45",
        "upload_time_iso_8601": "2022-12-14T05:06:45.245628Z",
        "url": "https://files.pythonhosted.org/packages/79/77/bab8d5b8bf963512fbc610bab1e628156b82ff47d777cdcdbe151aedd8a3/bayesian-torch-0.3.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "39a3108b6daca1d0c55b70f3509b9bffd7f5fafb9cc457c8c83c4ab3d7ae624d",
        "md5": "ae36f8228e0c9bcc8b68010423b6033e",
        "sha256": "8d87c2fead0bda0b49b76c5b2a570fac47f166e3eef9ca95a50a67e0c4c80b3a"
      },
      "downloads": -1,
      "filename": "bayesian_torch-0.3.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "ae36f8228e0c9bcc8b68010423b6033e",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 48705,
      "upload_time": "2022-12-14T05:06:42",
      "upload_time_iso_8601": "2022-12-14T05:06:42.953463Z",
      "url": "https://files.pythonhosted.org/packages/39/a3/108b6daca1d0c55b70f3509b9bffd7f5fafb9cc457c8c83c4ab3d7ae624d/bayesian_torch-0.3.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "7977bab8d5b8bf963512fbc610bab1e628156b82ff47d777cdcdbe151aedd8a3",
        "md5": "b4733780eb310b4bd4403d667e64dc0d",
        "sha256": "996186ae7fcd8ec4ff3341d018b391a6077f0b729d9ed0055bf1abdd9257b769"
      },
      "downloads": -1,
      "filename": "bayesian-torch-0.3.0.tar.gz",
      "has_sig": false,
      "md5_digest": "b4733780eb310b4bd4403d667e64dc0d",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 84629,
      "upload_time": "2022-12-14T05:06:45",
      "upload_time_iso_8601": "2022-12-14T05:06:45.245628Z",
      "url": "https://files.pythonhosted.org/packages/79/77/bab8d5b8bf963512fbc610bab1e628156b82ff47d777cdcdbe151aedd8a3/bayesian-torch-0.3.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}