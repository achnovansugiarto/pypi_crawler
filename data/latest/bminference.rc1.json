{
  "info": {
    "author": "a710128",
    "author_email": "qbjooo@qq.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Programming Language :: C++",
      "Programming Language :: Python :: 3"
    ],
    "description": "# BMInference\n\nEnglish | [简体中文]\n\n[简体中文]: ./README-ZH.md\n\nBMInference (Big Model Inference) is a low-resource inference package for large-scale pretrained language models (PLMs).\n\n- **Low Resource.** Instead of running on large-scale GPU clusters, the package enables the running of the inference process for large-scale pretrained language models on personal computers!\n- **Open.** Model parameters and configurations are all publicly released, you don't need to access a PLM via online APIs, just run it on your computer! \n- **Green.** Run pretrained language models with fewer machines and GPUs, also with less energy consumption.\n\n## Demo\nHere we provide an online demo based on the package with CPM2.\n\n## Install\n\n- From source: ``python setup.py install``\n\n- From docker: ``docker build . -f docker/base.Dockerfile``\n\nHere we list the minimum and recommended configurations for running BMInference. \n\n| | Minimum Configuration | Recommended Configuration |\n|-|-|-|\n| Memory | 16GB | 24GB\n| GPU | NVIDIA GeForce GTX 1060 6GB | NVIDIA Tesla V100 16GB\n| PCI-E |  PCI-E 3.0 x16 |  PCI-E 3.0 x16\n\n## Quick Start\n\nHere we provide a esay script for using BMInference. \n\nFirstly, import a model from the model base (e.g. CPM1, CPM2, EVA2).\n```python\nimport bigmodels\ncpm2 = bigmodels.models.CPM2()\n```\n\nThen define the text and use the ``<span>`` token to denote the blank to fill in.\n```python\ntext = \"北京环球度假区相关负责人介绍，北京环球影城指定单日门票将采用<span>制度，即推出淡季日、平季日、旺季日和特定日门票。<span>价格为418元，<span>价格为528元，<span>价格为638元，<span>价格为<span>元。北京环球度假区将提供90天滚动价格日历，以方便游客提前规划行程。\"\n```\n\nUse the ``generate`` function to obtain the results and replace ``<span>`` tokens with the results.\n\n```python\nfor result in cpm2.generate(text, \n    top_p=1.0,\n    top_n=10, \n    temperature=0.9,\n    frequency_penalty=0,\n    presence_penalty=0\n):\n    value = result[\"text\"]\n    text = text.replace(\"<span>\", \"\\033[0;32m\" + value + \"\\033[0m\", 1)\nprint(text)\n```\nFinally, you can get the predicted text. For more examples, go to the ``examples`` folder.\n\n## Performances\n\nHere we report the speeds of CPM2 encoder and decoder we have tested on different platforms. You can also run ``benchmark/cpm2/encoder.py`` and ``benchmark/cpm2/decoder.py`` to test the speed on your machine!\n\n| GPU | Encoder Speed (tokens/s) | Decoder Speed (tokens/s) |\n|-|-|-|\n| NVIDIA GeForce GTX 1060 | 533 | 1.6\n| NVIDIA GeForce GTX 1080Ti | 1200 | 12\n\n## Contributing\nLinks to the user community and contributing guidelines.\n\n## License\n\nThe package is released under the [Apache 2.0](./LICENSE) License.\n\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "bminference",
    "package_url": "https://pypi.org/project/bminference/",
    "platform": "",
    "project_url": "https://pypi.org/project/bminference/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/bminference/0.0.2/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "A toolkit for big model inference",
    "version": "0.0.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 11369551,
  "releases": {
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6179c79ac962f71a2607615146ee8ba8a197184421661e28f6b39a717a9c5150",
          "md5": "65dad39b1b4cd68af1095b63e37ece2b",
          "sha256": "d4c9e2f43acdcaa01c082211e8d9bccfca05f3667a1cc559c7156f8cae7057b2"
        },
        "downloads": -1,
        "filename": "bminference-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "65dad39b1b4cd68af1095b63e37ece2b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 29504,
        "upload_time": "2021-09-05T13:10:06",
        "upload_time_iso_8601": "2021-09-05T13:10:06.457091Z",
        "url": "https://files.pythonhosted.org/packages/61/79/c79ac962f71a2607615146ee8ba8a197184421661e28f6b39a717a9c5150/bminference-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "6179c79ac962f71a2607615146ee8ba8a197184421661e28f6b39a717a9c5150",
        "md5": "65dad39b1b4cd68af1095b63e37ece2b",
        "sha256": "d4c9e2f43acdcaa01c082211e8d9bccfca05f3667a1cc559c7156f8cae7057b2"
      },
      "downloads": -1,
      "filename": "bminference-0.0.2.tar.gz",
      "has_sig": false,
      "md5_digest": "65dad39b1b4cd68af1095b63e37ece2b",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 29504,
      "upload_time": "2021-09-05T13:10:06",
      "upload_time_iso_8601": "2021-09-05T13:10:06.457091Z",
      "url": "https://files.pythonhosted.org/packages/61/79/c79ac962f71a2607615146ee8ba8a197184421661e28f6b39a717a9c5150/bminference-0.0.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}