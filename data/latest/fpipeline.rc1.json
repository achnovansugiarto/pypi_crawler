{
  "info": {
    "author": null,
    "author_email": "BobKerns <rwk@acm.org>",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# fpipeline â€” Functional Pipeline\n\nSimple but flexible python pipelines based on function composition.\n\nBuild your workflow step by step, then flexibly combine the steps to make a bigger step. Conditional\nexecution and branching are also supported.\n\nOrganizing a data application as a pipeline brings many benefits:\n\n* By naming each top-level operation, a degree of natural self-documentation is provided.\n* Each step can easily be independently tested.\n* The pipeline focuses on the overall sequence of operation and dataflow.\n* A clear boundary between levels of abstraction. Details live in steps and conditions.\n\nThe pipeline orchestrates these pieces, while remaining entirely\nagnostic about what the operations do.\n\n## Steps\n\nA step is a function of one argument, which we will\ncall the _context_. The context can be any object, including a dict, according to the needs of the application.\n\nThis single argument will be the same for all steps in an application, but different for each invocation.\n\nOften, it will be an object representing the data the\npipeline is to operate on. It can also be contained in\nan object or `dict` along with various metadata.\n\n### _type_ `Step`[_D_,_V_]\n\nA `Step` type hint is defined to be:\n\n```python\nStep = Callable[[D],V]\n```\n\nWhere `D` and `V` are type variables,\n\nSteps taking only a single argument would seem very\nlimiting. But we have a solution!\n\n### _decorator_ `@stepfn`\n\nTo define a step function, we use the decorator [`@stepfn`](#decorator-stepfn). The function's first positional argument is interpreted as the context\nargument. The function is replaced with a new function\nthat accepts all the other arguments, and returns a\nnew function that accepts the context argument (thus,\na [`Step`](#type-stepdv)), and invokes the original\nfunction with all its arguments.\n\nWe transform this:\n\n```python\n@stepfn\ndef my_step(ctx; CTX, a; A, b: B, c: C) -> V:\n```\n\ninto:\n\n```python\ndef my_step(a: A, b: B, c: C) -> Step[CTX,V]:\n```\n\nor more informally\n\n```python\nmy_step(A, B, C) -> (CTX) -> V\n```\n\nThat is, we supply everything _except_ the first\nargument, then apply the context parameter for\neach data value processed by the pipeline.\n\nIt might seem that this limits us to constant values. However, the use of\n[_pipeline variables_](#pipeline-variables) allow\ndifferent values to be injected at each execution. Pipelne variables are evaluated at each execution.\n\nUsing a simple protocol based on single-argument functions allows us to use them as building blocks, to combine them into entire pipelines, and to combine pipelines into larger pipelines, all following the same protocol.\n\n## Pipeline variables\n\nTo allow passing values between pipeline [`Step`s](#type-stepdv) in a flexible way, we provide two forms of _pipeline variables_, that allow capture of the return value of a [`Step`](#type-stepdv), and then supply it as an argument to a later step\nfunction, all handled by the behind the scenes.\n\nPipeline variables will hold any value.\n\nA pipeline variable is also callable as a [`Step`](#steps), allowing them to be used in a\npipeline to provide a return value for the pipeline.\n\n### _function_ `variables`(_context_)\n\n`variables` returns a [`VariableContext`](#class-variablecontext), which is a python [context manager](https://docs.python.org/3/library/stdtypes.html#context-manager-types). This is used in a `with ... as ...` statement.\n\nThe resulting [`VariableContext`](#class-variablecontext) gives out pipeline variables and manages their scope.\n\n### _class_ `VariableContext`\n\nA [context manager](https://docs.python.org/3/library/stdtypes.html#context-manager-types) that manages [pipeline variables](#pipeline-variables).\n\nUsage goes like this:\n\n```python\n# Dummy StepFns to illustrate\n@stepfn\ndef readAssetStep(data: Data, path: str) -> Asset:\n    return path\n\n@stepfn\ndef mergeAssetsStep(data: Data, asset1: Asset, asset2: Asset) -> Asset:\n    return f\"{asset1}+{asset2}\"\n\n@stepfn\ndef writeAssetStep(data: Data, asset: Asset, path: str) -> Asset:\n    print(f\"{path}: ${asset}\")\n\n# a `StepFn` (a pipeline is a `Step`) that takes two src paths to assets,\n# merges them, stores the result in data.result, and writes it to a file.\n# The asset paths are provided per-invocation in the context\n# The output directory is configured as an argument\n# when creating the pipeline.\n@stepfn\ndef merge(data: Data, outdir: str) -> Asset:\n    with variables() as vars:\n        # declare the pipeline variables that we need\n        src1, src2 = vars.attribute('src1', 'src2')\n        asset1 = vars.variable('asset1', 'asset2')\n        result = vars.variable('result') # stors in data.result\n        return vars.pipeline(\n            store(asset2, readAssetStep(src2)),\n            store(asset1, readAssetStep(src1),\n            store(result, mergeAssetsStep(asset1, asset2),\n            writeAssetStep(result, outdir),\n            result\n        )(data)\n```\n\n`merge` can now be invoked by omitting the _data_ argument, giving a function of one\nargument (_data_).\n\n```python\npair1 = {\n    'asset1': '/data/assets/src1',\n    'asset2': '/data/assets/src2'\n}\nmerge_and_store = merge(outdir='/data/assets/merged')\n\n# Perform the operation\nmerged = merge_and_store(pair1)\n```\n\nOur new [`Step`](#type-stepdv) (`merge_and_store`) can then be calld for\neach merger to be performed.\n\nIf we have two directories of files to be merged, this will take them\npairwise and feed each pair through the\npipeline.\n\n```python\ndef get_assets(asset1, asset2):\n    list1 = glob.glob(asset1)\n    list2 = glob.glob(asset2)\n    paired = zip(list1, list2)\n    return ({'asset1': a1, 'asset2': a2}\n            for (a1, a2) in paired)\nleft = '/data/assets1/*.asset'\nright = '/data/assets2/*.asset'\nresults = list(map(merge_and_store, get_assets(left, right)))\n```\n\n#### _method_ `VariableContext.variable`(`*`_names_)\n\nReturns a [`Variable`](#class-variable), or a tuple of [`Variable`s](#class-variable) if more than one name is given.\n\nThis allows assignment of multiple\nvariables in a single statement:\n\n```python\n    a, b = vars.variable('a', 'b')\n```\n\n#### _method_ `VariableContext.attribute`(`*`_names_)\n\nReturns a type of pipeline variable called [`Attribute](#class-attribute), or a tuple of [`Attribute`s](#class-attribute) if\nmore than one name is given.\n\nThis allows assignment of multiple\nattribute variables in a single statement:\n\n```python\n    a, b = vars.attribute('a', 'b')\n```\n\n#### _method_ `VariableContext.pipeline`(`*`_steps_)\n\nCreates and runs pipeline in this context.\n\n### _class_ `Variable`\n\nRepresents a place to store and retrieve values between steps.\n\n#### _attribute_ `Variable.value`\n\nThe value of a [`Variable`](#class-variable). Not usually referenced directly; rather the variable is passed to step functions, or assigned with the [`store`](#function-storevariable-step) step function.\n\n#### _attribute_ `Variable.name`\n\nThe name of the variable. It must be unique within a [`VariableContext`](#class-variablecontext). Multiple uses of the same name will yield the same variable.\n\n### _class_ `Attribute`\n\nA pipeline variable that access the context. The name names the field or key to access.\n\n#### _attribute_ `Attribute.value`\n\nThe value of a [`Attribute`](#class-variable). Not usually referenced directly; rather the variable is passed to step functions, or assigned with the [`store`](#function-storevariable-step) step function.\n\n#### _attribute_ `Attribute.name`\n\nThe name of the variable. It must be unique within a [`VariableContext`](#class-variablecontext). Multiple uses of the same name will yield the same variable.\n\nIt is also the name of the field or key in the context.\n\n### _function_ `store`(_variable_, _step_)\n\nStore the result of _step_ into the _variable_.\n\n### _function_ `eval_vars`(_var_, _depth_=10)\n\n> _\\[Advanced]_\n\nIf _var_ is any type of [pipeline variable](#pipeline-variables), its value is returned.\n\nIf _var_ is a container type (`list`, `tuple`, `namedtuple`, `dict`, or `set`),\na copy is returned with the variables replaced with their values.\nThis is performed to _depth_ levels.\n\nIn most cases, this will be called for you\nat appropriate points.\n\n## Conditional execution\n\nA pipeline that executes every step on every input would severely limit flexibility.\n\n`fpipeline` provides for branching, allowing steps to be skipped where\nthey don't apply, or entire different flows be selected.\n\nThe primary means is via the [`if_`](#stepfn-if_cond-then-else) step function.\n\n> These functions have a '_' suffix to avoid conflicts\nwhile maintaining readability. They are not in any\nsense private; they ae a fully public part of the\ninterface.\n\n### _`@stepfn`_ `if_`(_cond_, _then_, _else_)\n\n_cond_ is a `Condition`, which is like a `Step` except\nthe return value is a `bool`. It should be defined using the\n`@conditionfn` decorator in the same way as\n`@stepfn` is used for step functions.\n\n_then_ and _else_ are steps (or pipelines),\nexecuted according to the value of _cond_.\nThey may be omitted or supplied as None.\n\nIf _then_ or _else_ are lists, they will be treated\nimplicitly as a pipeline.\n\n### _`@condfn`_ `not_`(_cond_)\n\n`not_` returns a new `Condition` with the opposite sense.\n\n### _`@condfn`_ `and_`(`*`_conds_)\n\n`and_` returns a new `Condition` that returns\n`False` if any of its arguments return `False`,\nand `True` otherwise.\n\n### _`@condfn`_ `or_`(`*`_conds_)\n\n`or_` returns a new `Condition` that returns\n`True` if any of its arguements return `True`,\nand `False` otherwise.\n\n## Utility Steps\n\n### `@Stepfn` `pipeline`(`*`_steps_)\n\nCreate a pipelineâ€”a step that executes _steps_ in order, and returns\nthe value returned by the last.\n\n### `@stepfn` `apply`(_fn_, `*`_args_, `**`_kwargs_)\n\nCalls an an arbitrary function on the context,\nplus any additional arguments supplied. Variables and steps will be replaced by their values.\n\n### `@stepfn` `list_`(`*`_values_)\n\nReturn a list of values. Steps and variables will be evaluated.\n\n### `@stepfn` `tuple_`(`*`_values_)\n\nReturn a tuple of values. Steps and variables will be evalaued.\n\n### `@stepfn` `dict_`(`**`_values_)\n\nReturn a dict from the supplied keyword arguments. Steps and variables will be evaluated.\n\n### `@stepfn` `set_`(`**`_values_)\n\nReturn a set from the supplied keyword arguments. Steps and variables will be evaluated.\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": null,
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": null,
    "keywords": null,
    "license": null,
    "maintainer": null,
    "maintainer_email": null,
    "name": "fpipeline",
    "package_url": "https://pypi.org/project/fpipeline/",
    "platform": null,
    "project_url": "https://pypi.org/project/fpipeline/",
    "project_urls": {
      "Bug Tracker": "https://github.com/bobkerns/fpipeline/issues",
      "Homepage": "https://github.com/bobkerns/fpipeline"
    },
    "release_url": "https://pypi.org/project/fpipeline/1.0.0/",
    "requires_dist": null,
    "requires_python": ">=3.7",
    "summary": "Functional Pipeline. A simple yet flexible pipeline package based on function composition.",
    "version": "1.0.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16022543,
  "releases": {
    "1.0.0": [
      {
        "comment_text": null,
        "digests": {
          "blake2b_256": "8fcb73684a2cb1d96320dab5efba62b1df8d1e094302b833863d2b9927747e63",
          "md5": "f447e6b429b734a5fa33ec3d9c716c6a",
          "sha256": "7c584cab56ae95143c935e5e933bc8ec1da3936044dda25757a19196868c4f8e"
        },
        "downloads": -1,
        "filename": "fpipeline-1.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f447e6b429b734a5fa33ec3d9c716c6a",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 9262,
        "upload_time": "2022-12-07T16:36:27",
        "upload_time_iso_8601": "2022-12-07T16:36:27.982257Z",
        "url": "https://files.pythonhosted.org/packages/8f/cb/73684a2cb1d96320dab5efba62b1df8d1e094302b833863d2b9927747e63/fpipeline-1.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": null,
        "digests": {
          "blake2b_256": "b7f192dff46da0b8dd590eff94f4ca42592c7bc58fadedd57bce9c0d4ce720cb",
          "md5": "7ccafec03887a740c1c7e38e90491500",
          "sha256": "b76da8bcd7c3c7fe6b138876635182bbcc3af38e7ccf8c6331df0cba9a4e914c"
        },
        "downloads": -1,
        "filename": "fpipeline-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "7ccafec03887a740c1c7e38e90491500",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 19083,
        "upload_time": "2022-12-07T16:36:29",
        "upload_time_iso_8601": "2022-12-07T16:36:29.790204Z",
        "url": "https://files.pythonhosted.org/packages/b7/f1/92dff46da0b8dd590eff94f4ca42592c7bc58fadedd57bce9c0d4ce720cb/fpipeline-1.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": null,
      "digests": {
        "blake2b_256": "8fcb73684a2cb1d96320dab5efba62b1df8d1e094302b833863d2b9927747e63",
        "md5": "f447e6b429b734a5fa33ec3d9c716c6a",
        "sha256": "7c584cab56ae95143c935e5e933bc8ec1da3936044dda25757a19196868c4f8e"
      },
      "downloads": -1,
      "filename": "fpipeline-1.0.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "f447e6b429b734a5fa33ec3d9c716c6a",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 9262,
      "upload_time": "2022-12-07T16:36:27",
      "upload_time_iso_8601": "2022-12-07T16:36:27.982257Z",
      "url": "https://files.pythonhosted.org/packages/8f/cb/73684a2cb1d96320dab5efba62b1df8d1e094302b833863d2b9927747e63/fpipeline-1.0.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": null,
      "digests": {
        "blake2b_256": "b7f192dff46da0b8dd590eff94f4ca42592c7bc58fadedd57bce9c0d4ce720cb",
        "md5": "7ccafec03887a740c1c7e38e90491500",
        "sha256": "b76da8bcd7c3c7fe6b138876635182bbcc3af38e7ccf8c6331df0cba9a4e914c"
      },
      "downloads": -1,
      "filename": "fpipeline-1.0.0.tar.gz",
      "has_sig": false,
      "md5_digest": "7ccafec03887a740c1c7e38e90491500",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 19083,
      "upload_time": "2022-12-07T16:36:29",
      "upload_time_iso_8601": "2022-12-07T16:36:29.790204Z",
      "url": "https://files.pythonhosted.org/packages/b7/f1/92dff46da0b8dd590eff94f4ca42592c7bc58fadedd57bce9c0d4ce720cb/fpipeline-1.0.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}