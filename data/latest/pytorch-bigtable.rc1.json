{
  "info": {
    "author": "Google",
    "author_email": "info@unoperate.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: Apache Software License",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9"
    ],
    "description": "<!-- \n# Copyright 2021 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License. \n-->\n\n# Pytorch Bigtable Extension\n\nThis is a Pytorch Extension used to connect to Google Cloud Bigtable.\n\n### Contents:\n\n* Installation\n* Credentials\n* Quickstart\n* Parallel read\n* Specifying a version of a value\n* Specifying a version of a value\n* Writing to Bigtable\n* Building it locally\n* Byte representation\n* Example\n\n## Installation\n\nMake sure you have torch installed. Then just use pip to install the latest\nversion\n\n```\npip install -i https://test.pypi.org/simple/ pytorch-bigtable\n```\n\n## Credentials\n\nRight now only the default credentials are supported. To connect to Bigtable you\nneed to set the environment variable `GOOGLE_APPLICATION_CREDENTIALS`.\nReplace `[PATH]` with the file path of the JSON file that contains your service\naccount key.\n\n```python\nimport os\n\nos.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"[PATH]\"\n```\n\n**Note**: If you're using the emulator, \nremmember to set the `BIGTABLE_EMULATOR_HOST` environment variable\nas described [here](https://cloud.google.com/bigtable/docs/emulator).\n\n\n## Quickstart\n\nFirst you need to create a client and a table you would like to read from.\n\n```python\nimport torch\nimport pytorch_bigtable as pbt\nimport random\n\n# replace the project_id, instance_id and the name of the table with suitable values.\nclient = pbt.BigtableClient(project_id=\"test-project\", instance_id=\"test-instance\")\ntrain_table = client.get_table(\"train\")\n```\n\nNow we will write some data into Bigtable. To do that, we create a\ntensor `data_tensor`. We provide a list of column names in\nformat `column_family:column_name` and a list of rowkeys.\n\n```python\ndata_tensor = torch.Tensor(list(range(40))).reshape(20, 2)\nrandom_row_keys = [\"row\" + str(random.randint(0, 999)).rjust(3, \"0\") for _ in range(20)]\ntrain_table.write_tensor(data_tensor, [\"cf1:col1\", \"cf1:col2\"], random_row_keys)\n```\n\nGreat! Now we can create a pytorch dataset that will read the data from our\ntable. To do that, you have to provide the type of the data you wish to read,\nlist of column names in format `column_family:column_name`, and a row_set that\nyou would like to read.\n\nKeep in mind that that bigtable reads values in lexicographical order, \nnot the order they were put in. We gave them random row-keys \nso they will be shuffled.\n\n```python\nrow_set = pbt.row_set.from_rows_or_ranges(pbt.row_range.infinite())\n\ntrain_dataset = train_table.read_rows(torch.float32, [\"cf1:col1\", \"cf1:col2\"], row_set)\n\nfor tensor in train_dataset:\n  print(tensor)\n```\n\nThat's it! Congrats!\nYou can also explore our example of training a fraud-detection model on data\nfrom Bigtable in example.py\n\n## Parallel read\n\nOur dataset supports reading in parallel from Bigtable. To do that, create a\npytorch DataLoader and set num_workers to a number higher than one. When a Bigtable table instance is created, a list of tablets is fetched from bigquery. When pytorch's dataloader spawns workers, each worker computes it's share of work based on the tablets in the table and starts reading from their share of\ntablets. \n\nBatching is also supported. You have to set the batch_size when constructing the data_loader as you would normally do with any other dataset.\n\n**Note**: Keep in mind that when reading in parallel, the rows are not\nguaranteed to be read in any particular order.\n\n```python\ntrain_loader = torch.utils.data.DataLoader(train_dataset, num_workers=5, batch_size=10)\nfor tensor in train_loader:\n  print(tensor)\n```\n\n## Reading specific row_keys\n\nTo read the data from Bigtable, you can specify a set of rows or a range or a\ncombination of those. We partly expose the C++ Bigtable Client api for that\npurpose.\n\npytorch_bigtable.BigtableTable.read_rows method expects you to provide a\nrow_set. You can construct a row_set from row_keys or row_ranges as follows:\n\n```python\nrow_range_below_300 = pbt.row_range.right_open(\"row000\", \"row300\")\n\nmy_row_set = pbt.row_set.from_rows_or_ranges(row_range_below_300, \"row585\", \"row832\")\n```\n\nsuch row_set would contain a range of rows `[row000, row300)` and rows row585 and row832.\n\nyou can also create a row_set from an infinite range, empty range or a prefix.\nYou can also intersect it with a row_range.\n\n```python\nmy_truncated_row_set = pbt.row_set.intersect(my_row_set, pbt.row_range.right_open(\"row200\", \"row700\"))\n```\n\n## Specifying a version of a value\n\nBigtable lets you keep many values in one cell with different timestamps. You\ncan specify which version you want to pick using version filters. However, you\ncan only retrieve a two dimensional vector using pytorch_bigtable connector, so\n`latest` filter is always appended to the user specified version filter.\nMeaning, if more than one value for one cell goes through the provided filter,\nthe newer shall be used.\n\nYou can either use the `latest` filter passing the newest value, or you can\nspecify a time range. The time range can be provided either as python datetime\nobjects or a number representing seconds or microseconds since epoch.\n\n```python\nimport pytorch_bigtable.version_filters as version_filters\nfrom datetime import datetime, timezone\n\nstart = datetime(2020, 10, 10, 12, 0, 0, tzinfo=timezone.utc)\nend = datetime(2100, 10, 10, 13, 0, 0, tzinfo=timezone.utc)\nfrom_datetime = version_filters.timestamp_range(start, end)\nfrom_posix_timestamp = version_filters.timestamp_range(int(start.timestamp()), int(end.timestamp()))\n```\n\n## Writing to Bigtable\n\nTo put data in Bigtable, you can use the write_tensor method. You have to\nprovide row_keys for the data you're writing. To do that, you can either pass a\nlist of strings, or a callback i.e. a python function that will be called to\ngenerate a row_key for each row with two arguments:\n\n* a tensor representing a row that is currently being written of shape `[1,n]`\n  where n is a number of columns\n* an index of the current row\n\nYou can use that callback to avoid creating a very large list of row_keys.\nRemember that putting consecutive rows in Bigtable is an anti-pattern and you\nshould avoid that. Easiest option would be to provide a callback generating\nrandom row_keys for each row.\n\n**Note** This is by no means optimal or efficient way of sending the data to\nBigtable. If you're looking for uploading large quantities of data to Bigtable\nefficiently, please consider\nusing [BT client libraries](https://cloud.google.com/bigtable/docs/reference/libraries)\nwhich are designated for that.\n\n```python\ndef row_callback(tensor, index):\n  return \"row\" + str(random.randint(1000, 9999)).rjust(4, \"0\")\n\n\ntable.write_tensor(data_tensor, [\"cf1:col1\", \"cf1:col2\"], row_callback)\n```\n\n## Byte representation\n\nBecause the byte representation of variables differ depending on the\narchitecture of the machine the code is run on, we are using the xdr library to\nconvert the values to bytes. XDR is a part of rpc library. \n\n## Example\n\nWe provide a simple end-to-end example consisting of two files: \n`plugin/example/seed_bigtable.py` and `plugin/example/fraud_example.py`.\n\n### seed_bigtable.py\nIt is used to generate credit-card transactions data as described in \n[Fraud-Detection-Handbook](https://github.com/Fraud-Detection-Handbook/simulated-data).\nFirst some transactions are generated and stored in memory as a whole. Then they\nare split to two datasets - train and test and uploaded to Bigtable. \n\n\nYou have to specify the project and instance, the name of train and test table \nas well as column family which should be used for all the columns as \nscript arguments. \n\n\nIf you wish to use the emulator, provide the emulator address and port \nas an argument as well.\n\n\ncommand to seed the database:\n```bash\npython3 seed_bigtable.py \\\n  --project_id test-project \\\n  --instance_id test-instance \\\n  --train_set_table train \\\n  --test_set_table test \\\n  -e \"127.0.0.1:8086\" \\\n  -f cf1\n```\n\n### fraud_example.py\nIt trains a simple fully-connected neural network for fraud detection based on\ndata taken straight from bigtable. Keep in mind that the dataset is synthetic\nand the purpose of this example is to showcase the bigtable dataset and not\nfraud-detection algorithm.\n\nThe network is first evaluated on the data from the `test` table, then the network\nis trained and evaluated again to verify that there was in fact some improvement.\n\n\ncommand to run the example:\n```bash\npython3 fraud_example.py  \\\n--project_id test-project \\\n--instance_id test-instance \\\n--train_set_table train \\\n--test_set_table test \\\n-e \"127.0.0.1:8086\" \\\n-f cf1\n```\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/Unoperate/pytorch-cbt",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "pytorch-bigtable",
    "package_url": "https://pypi.org/project/pytorch-bigtable/",
    "platform": "",
    "project_url": "https://pypi.org/project/pytorch-bigtable/",
    "project_urls": {
      "Homepage": "https://github.com/Unoperate/pytorch-cbt"
    },
    "release_url": "https://pypi.org/project/pytorch-bigtable/0.4.0/",
    "requires_dist": [
      "torch (>=1.10.0)"
    ],
    "requires_python": ">=3.6",
    "summary": "Pytorch Extension for BigTable",
    "version": "0.4.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12222662,
  "releases": {
    "0.4.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4524e50583f98ba1de77f65ca7c0102ef38747ec0a65d337e736ad6fa9f91823",
          "md5": "a8f2665a49083302e68d96005e023b0a",
          "sha256": "88d9ede8867151cf184355a05a4e6baefcf064d2e7d9999f435beb0de97d5ca1"
        },
        "downloads": -1,
        "filename": "pytorch_bigtable-0.4.0-cp36-cp36m-manylinux2014_x86_64.whl",
        "has_sig": false,
        "md5_digest": "a8f2665a49083302e68d96005e023b0a",
        "packagetype": "bdist_wheel",
        "python_version": "cp36",
        "requires_python": ">=3.6",
        "size": 8984027,
        "upload_time": "2021-12-06T12:22:40",
        "upload_time_iso_8601": "2021-12-06T12:22:40.853639Z",
        "url": "https://files.pythonhosted.org/packages/45/24/e50583f98ba1de77f65ca7c0102ef38747ec0a65d337e736ad6fa9f91823/pytorch_bigtable-0.4.0-cp36-cp36m-manylinux2014_x86_64.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6efc50f184c42cc65098dfcf4d9e51a6c6c935c499f730ea19398cae54467f6a",
          "md5": "9aca174ffdc16094c52ad6c368792d36",
          "sha256": "f3ccfc7082404b32769447cf73f5cb4c246ea7ef985724404e2b48b2d8fda37a"
        },
        "downloads": -1,
        "filename": "pytorch_bigtable-0.4.0-cp37-cp37m-manylinux2014_x86_64.whl",
        "has_sig": false,
        "md5_digest": "9aca174ffdc16094c52ad6c368792d36",
        "packagetype": "bdist_wheel",
        "python_version": "cp37",
        "requires_python": ">=3.6",
        "size": 8985497,
        "upload_time": "2021-12-06T12:22:42",
        "upload_time_iso_8601": "2021-12-06T12:22:42.679506Z",
        "url": "https://files.pythonhosted.org/packages/6e/fc/50f184c42cc65098dfcf4d9e51a6c6c935c499f730ea19398cae54467f6a/pytorch_bigtable-0.4.0-cp37-cp37m-manylinux2014_x86_64.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9d191d38d3ff11cf11845f20f9d84d36add138dd5ef0faaa419c1acd9412a2f8",
          "md5": "09e7016c439bbb26fbc3b237e3dd7cc5",
          "sha256": "25fa765f6cfb4d012b049c0e4cb4e4e9d4995ccd756869f7ef51ee16049bf5ec"
        },
        "downloads": -1,
        "filename": "pytorch_bigtable-0.4.0-cp38-cp38-manylinux2014_x86_64.whl",
        "has_sig": false,
        "md5_digest": "09e7016c439bbb26fbc3b237e3dd7cc5",
        "packagetype": "bdist_wheel",
        "python_version": "cp38",
        "requires_python": ">=3.6",
        "size": 8998242,
        "upload_time": "2021-12-06T12:22:44",
        "upload_time_iso_8601": "2021-12-06T12:22:44.739112Z",
        "url": "https://files.pythonhosted.org/packages/9d/19/1d38d3ff11cf11845f20f9d84d36add138dd5ef0faaa419c1acd9412a2f8/pytorch_bigtable-0.4.0-cp38-cp38-manylinux2014_x86_64.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fb91d5a317d7301474adfc6e7f18dfb8480148779538c3b1586fbb9aaecf7104",
          "md5": "a8534f65451b9d7d007f4b1b8ad279be",
          "sha256": "7fc7bed0d13102b93cd79a374a5f7fb36d859b6c07a869a805d66fecc9eb4579"
        },
        "downloads": -1,
        "filename": "pytorch_bigtable-0.4.0-cp39-cp39-manylinux2014_x86_64.whl",
        "has_sig": false,
        "md5_digest": "a8534f65451b9d7d007f4b1b8ad279be",
        "packagetype": "bdist_wheel",
        "python_version": "cp39",
        "requires_python": ">=3.6",
        "size": 9000251,
        "upload_time": "2021-12-06T12:22:46",
        "upload_time_iso_8601": "2021-12-06T12:22:46.248168Z",
        "url": "https://files.pythonhosted.org/packages/fb/91/d5a317d7301474adfc6e7f18dfb8480148779538c3b1586fbb9aaecf7104/pytorch_bigtable-0.4.0-cp39-cp39-manylinux2014_x86_64.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "4524e50583f98ba1de77f65ca7c0102ef38747ec0a65d337e736ad6fa9f91823",
        "md5": "a8f2665a49083302e68d96005e023b0a",
        "sha256": "88d9ede8867151cf184355a05a4e6baefcf064d2e7d9999f435beb0de97d5ca1"
      },
      "downloads": -1,
      "filename": "pytorch_bigtable-0.4.0-cp36-cp36m-manylinux2014_x86_64.whl",
      "has_sig": false,
      "md5_digest": "a8f2665a49083302e68d96005e023b0a",
      "packagetype": "bdist_wheel",
      "python_version": "cp36",
      "requires_python": ">=3.6",
      "size": 8984027,
      "upload_time": "2021-12-06T12:22:40",
      "upload_time_iso_8601": "2021-12-06T12:22:40.853639Z",
      "url": "https://files.pythonhosted.org/packages/45/24/e50583f98ba1de77f65ca7c0102ef38747ec0a65d337e736ad6fa9f91823/pytorch_bigtable-0.4.0-cp36-cp36m-manylinux2014_x86_64.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "6efc50f184c42cc65098dfcf4d9e51a6c6c935c499f730ea19398cae54467f6a",
        "md5": "9aca174ffdc16094c52ad6c368792d36",
        "sha256": "f3ccfc7082404b32769447cf73f5cb4c246ea7ef985724404e2b48b2d8fda37a"
      },
      "downloads": -1,
      "filename": "pytorch_bigtable-0.4.0-cp37-cp37m-manylinux2014_x86_64.whl",
      "has_sig": false,
      "md5_digest": "9aca174ffdc16094c52ad6c368792d36",
      "packagetype": "bdist_wheel",
      "python_version": "cp37",
      "requires_python": ">=3.6",
      "size": 8985497,
      "upload_time": "2021-12-06T12:22:42",
      "upload_time_iso_8601": "2021-12-06T12:22:42.679506Z",
      "url": "https://files.pythonhosted.org/packages/6e/fc/50f184c42cc65098dfcf4d9e51a6c6c935c499f730ea19398cae54467f6a/pytorch_bigtable-0.4.0-cp37-cp37m-manylinux2014_x86_64.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "9d191d38d3ff11cf11845f20f9d84d36add138dd5ef0faaa419c1acd9412a2f8",
        "md5": "09e7016c439bbb26fbc3b237e3dd7cc5",
        "sha256": "25fa765f6cfb4d012b049c0e4cb4e4e9d4995ccd756869f7ef51ee16049bf5ec"
      },
      "downloads": -1,
      "filename": "pytorch_bigtable-0.4.0-cp38-cp38-manylinux2014_x86_64.whl",
      "has_sig": false,
      "md5_digest": "09e7016c439bbb26fbc3b237e3dd7cc5",
      "packagetype": "bdist_wheel",
      "python_version": "cp38",
      "requires_python": ">=3.6",
      "size": 8998242,
      "upload_time": "2021-12-06T12:22:44",
      "upload_time_iso_8601": "2021-12-06T12:22:44.739112Z",
      "url": "https://files.pythonhosted.org/packages/9d/19/1d38d3ff11cf11845f20f9d84d36add138dd5ef0faaa419c1acd9412a2f8/pytorch_bigtable-0.4.0-cp38-cp38-manylinux2014_x86_64.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "fb91d5a317d7301474adfc6e7f18dfb8480148779538c3b1586fbb9aaecf7104",
        "md5": "a8534f65451b9d7d007f4b1b8ad279be",
        "sha256": "7fc7bed0d13102b93cd79a374a5f7fb36d859b6c07a869a805d66fecc9eb4579"
      },
      "downloads": -1,
      "filename": "pytorch_bigtable-0.4.0-cp39-cp39-manylinux2014_x86_64.whl",
      "has_sig": false,
      "md5_digest": "a8534f65451b9d7d007f4b1b8ad279be",
      "packagetype": "bdist_wheel",
      "python_version": "cp39",
      "requires_python": ">=3.6",
      "size": 9000251,
      "upload_time": "2021-12-06T12:22:46",
      "upload_time_iso_8601": "2021-12-06T12:22:46.248168Z",
      "url": "https://files.pythonhosted.org/packages/fb/91/d5a317d7301474adfc6e7f18dfb8480148779538c3b1586fbb9aaecf7104/pytorch_bigtable-0.4.0-cp39-cp39-manylinux2014_x86_64.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}