{
  "info": {
    "author": "Language and Conversation, IBM Research AI",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# compcor\n\n## TL;DR\nA python library of similarity measures which allow measuring the perceptual distance between text corpora.\nYou can use compcor to easily calculate the perceptual distance between two sets of sentences using many classical and SOTA metrics. \n\n## About\nThe ability to compare the semantic similarity between text corpora is important in a variety of natural language processing applications.\nWhile one can reasonably measure the semantic distance between two individual sentences (e.g., by calculating the cosine distance between the sentence embeddings), measuring the dissimilarity between two text corpora remains a challenge.\nCorpus-level metrics seek to assess semantic similarity at the group level.\nSuch metrics are essential for measuring how well corpus-based linguistic analysis generalizes from one data-set to another.\nSpecifically, the recent advances in generative language models have led to an increased interest in the study of content similarity between human and generated language, as a mean for comparing the quality of generative models.\n\n## installation:\nUsing python>=3.8:\n```\npip install compcor\n```\n\n## Usage\nTo calculate the perceptual distance between two corpora, the raw corpora can be simply provided as a list of strings:\n```\nsetA = ['can you tell me how i would normally say thank you as a french person', 'can you translate hi into spanish for me', 'can you translate milk into spanish for me', 'how can i say thank you very much in chinese', 'how can i thank somebody in italian', 'how could i say twin in chinese', 'how do germans say goodnight','how do i ask about the weather in chinese', 'how do i say hotel in finnish', 'how do i say bathroom in italian']\nsetB = ['how can i say thank you very much in chinese', 'how can i thank somebody in italian', 'how could i say twin in chinese', 'how do they say tacos in mexico', 'how do they say yes in brazil', 'how do vietnameses people say hello', 'how do you say cat in spanish', 'how do you say dog in spanish', 'how do you say fast in spanish', 'how do you say good bye in french', 'how do you say goodbye in spanish', 'how do you say hello in french', 'how do you say hello in japanese', 'how do you say hello in mexico']\n```\n\n### Using raw data\nBy calling any metric provided in the package, all metrics return a single scalar capturing the perceptual distance between two corpora:\n```\nimport compcor.corpus_metrics as corpus_metrics\ndistance = corpus_metrics.fid_distance(corpus1=setA, corpus2=setB)\n```\nIn this case the sentences in both sets will be tokenized/embedded inside the function.\n\n### Using embeddings\nThe metrics also accept already-embedded/tokenized corpora, possibly using a custom embedding.\n```\ndistance = corpus_metrics.fid_distance(corpus1=embedA, corpus2=embedB)\n```\n\nWe provide an embedding and tokanization utility class 'STTokenizerEmbedder' which is a shallow wrapper for the [sentence-transformer](https://www.sbert.net/)\nSentenceTransformer class.\nSTTokenizerEmbedder implements two simple interfaces 'TextEmbedder' and 'TextTokenizer'. \nThe hugging-face model can be determined using the 'embedding_model_name' parameter.\nBy default, we use the model 'all-MiniLM-L6-v2', but any other hugging-face model can be used.\n\n```\nfrom compcor.text_tokenizer_embedder import STTokenizerEmbedder\nembedder = STTokenizerEmbedder(embedding_model_name = \"all-MiniLM-L12-v2\")\n\nembedA = embedder.embed_sentences(setA)\nembedB = embedder.embed_sentences(setB)\ndistance = corpus_metrics.fid_distance(corpus1=embedA, corpus2=embedB)\n```\n\n### Using tokens\nIf the distance operates on the tokens level, the tokenized sentences should be provided instead of the sentence embeddings.\n```\ntokensA = embedder.tokenize_sentences(setA)\ntokensB = embedder.tokenize_sentences(setB)\n\ndistance = corpus_metrics.chi_square_distance(corpus1=tokensA, corpus2=tokensB)\nprint(\"chi_square_distance={}\".format(distance))\n#chi_square_distance=0.9987177546738071\n```\n## Full Metric list\nGiven two corpora of strings, we want to calculate the distance between them.\n`comparing-corpora` provides the following distance metrics.\nThe first metrics operate on a sentence-level embedding, while the last two operate on the token frequencies.\n\n| Name                                              |function| representation | description                                      |\n|---------------------------------------------------|---|----------------|--------------------------------------------------|\n| Classifier                                        |`classifier_distance`| embbeding      | Classifiability between reference and target     |\n| [PR (precision and recall)](https://github.com/clovaai/generative-evaluation-prdc)                         |`PR_distance`| embbeding      | Assessing distributional precision and recall    |\n| IRPR (information-retrieval precision and recall) |`IRPR_distance`| embbeding      | Average distance between closest samples pairs   |\n| [DC (density and coverage)](https://github.com/clovaai/generative-evaluation-prdc)                         |`dc_distance`| embbeding      | Estimating manifolds density and coverage        |\n| [MAUVE](https://github.com/krishnap25/mauve)                                             |`mauve_distance`| embbeding      | Quality and diversity via divergence frontiers   |\n| FID (Frechet Inception Distance)                  |`fid_distance`| embbeding      | Wasserstein distance between densities           |\n| Chi-squared ($\\chi^2$)                            |`chi_square_distance`| token          | Word/Token count comparison                      |\n| Zipf                                              |`zipf_distance`| token          | Unigram rank-frequency statistics                |\n| t-test                                            |`ttest_distance`| embbeding      | T-test p-value on difference in elementwise means |\n| Medoid                                            |`medoid_distance`| embbeding      | Cosine distance between corpora centroids        |\n\n## Citation\nIf you use this package for your scientific publication please cite the following work studies the quality, time \nperformance and other properties of most of the metrics in this package.\n```\n@inproceedings{kour2022measuring,\n  title={Measuring the Measuring Tools: An Automatic Evaluation of Semantic Metrics for Text Corpora},\n  author={Kour, George and Ackerman, Samuel and Farchi, Eitan and Raz, Orna and Carmeli, Boaz and Anaby-Tavor, Ateret},\n  booktitle={Proceedings of the 2nd Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2022)},\n  publisher = \"Association for Computational Linguistics\",\n  year={2022}\n}\n```\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/IBM/comparing-corpora",
    "keywords": "Text Compare Corpus Metrics Measure Similarity",
    "license": "Apache Software License, Version 2.0, http://www.apache.org/licenses/LICENSE-2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "compcor",
    "package_url": "https://pypi.org/project/compcor/",
    "platform": null,
    "project_url": "https://pypi.org/project/compcor/",
    "project_urls": {
      "Homepage": "https://github.com/IBM/comparing-corpora"
    },
    "release_url": "https://pypi.org/project/compcor/1.0.6/",
    "requires_dist": [
      "numpy (==1.23.0)",
      "scipy (==1.9.0)",
      "scikit-learn (==1.1.1)",
      "prdc",
      "mauve-text",
      "sentence-transformers (==2.2.1)"
    ],
    "requires_python": ">=3.8",
    "summary": "Corpus level similarity measures.",
    "version": "1.0.6",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 15927469,
  "releases": {
    "1.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d5633e0dc30a6b9d1e55e0667718928991cb89beac4d2409aeff49d88e1c178c",
          "md5": "7aefced884875b76b9fa7ba60f710001",
          "sha256": "f387f46af79213fad2d62455924dc9484fa5eb94d517213c430eda581603c591"
        },
        "downloads": -1,
        "filename": "compcor-1.0.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "7aefced884875b76b9fa7ba60f710001",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 11854,
        "upload_time": "2022-11-28T10:38:53",
        "upload_time_iso_8601": "2022-11-28T10:38:53.625810Z",
        "url": "https://files.pythonhosted.org/packages/d5/63/3e0dc30a6b9d1e55e0667718928991cb89beac4d2409aeff49d88e1c178c/compcor-1.0.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2dd52cda23f1c076f26ceaad940b7e44ede336e8b906c1b3822c17bc0bde3050",
          "md5": "2cfb916e582eaf007e43dfa1436c1d93",
          "sha256": "15b4a7973003841f64b833f8995185ae24e842a00c20ad87c80a7986a7888834"
        },
        "downloads": -1,
        "filename": "compcor-1.0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "2cfb916e582eaf007e43dfa1436c1d93",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 11696,
        "upload_time": "2022-11-28T10:38:55",
        "upload_time_iso_8601": "2022-11-28T10:38:55.433395Z",
        "url": "https://files.pythonhosted.org/packages/2d/d5/2cda23f1c076f26ceaad940b7e44ede336e8b906c1b3822c17bc0bde3050/compcor-1.0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "87a09a2747838241aded8e9bebab6399d6d11a9fe7e4788e48ccdd1df625fc3a",
          "md5": "7a0a8b30406458b480377adfa8bf40eb",
          "sha256": "0cca84803f323af9337150dcb1d537f1617758d72e8103593b99c5d6e83b3c56"
        },
        "downloads": -1,
        "filename": "compcor-1.0.6-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "7a0a8b30406458b480377adfa8bf40eb",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 12842,
        "upload_time": "2022-11-29T12:32:24",
        "upload_time_iso_8601": "2022-11-29T12:32:24.372961Z",
        "url": "https://files.pythonhosted.org/packages/87/a0/9a2747838241aded8e9bebab6399d6d11a9fe7e4788e48ccdd1df625fc3a/compcor-1.0.6-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "01e414ab6c4d4a6cfa7f870571004e19a4169a796a559f4d060e3b0eae7e1f18",
          "md5": "0be240c6fd1f8827932cddbce64765bb",
          "sha256": "196c65fdea5642be21213538e33dd48229fb03f3a2d1ebed09e6f805c067a803"
        },
        "downloads": -1,
        "filename": "compcor-1.0.6.tar.gz",
        "has_sig": false,
        "md5_digest": "0be240c6fd1f8827932cddbce64765bb",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 13759,
        "upload_time": "2022-11-29T12:32:26",
        "upload_time_iso_8601": "2022-11-29T12:32:26.141691Z",
        "url": "https://files.pythonhosted.org/packages/01/e4/14ab6c4d4a6cfa7f870571004e19a4169a796a559f4d060e3b0eae7e1f18/compcor-1.0.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "87a09a2747838241aded8e9bebab6399d6d11a9fe7e4788e48ccdd1df625fc3a",
        "md5": "7a0a8b30406458b480377adfa8bf40eb",
        "sha256": "0cca84803f323af9337150dcb1d537f1617758d72e8103593b99c5d6e83b3c56"
      },
      "downloads": -1,
      "filename": "compcor-1.0.6-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "7a0a8b30406458b480377adfa8bf40eb",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.8",
      "size": 12842,
      "upload_time": "2022-11-29T12:32:24",
      "upload_time_iso_8601": "2022-11-29T12:32:24.372961Z",
      "url": "https://files.pythonhosted.org/packages/87/a0/9a2747838241aded8e9bebab6399d6d11a9fe7e4788e48ccdd1df625fc3a/compcor-1.0.6-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "01e414ab6c4d4a6cfa7f870571004e19a4169a796a559f4d060e3b0eae7e1f18",
        "md5": "0be240c6fd1f8827932cddbce64765bb",
        "sha256": "196c65fdea5642be21213538e33dd48229fb03f3a2d1ebed09e6f805c067a803"
      },
      "downloads": -1,
      "filename": "compcor-1.0.6.tar.gz",
      "has_sig": false,
      "md5_digest": "0be240c6fd1f8827932cddbce64765bb",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.8",
      "size": 13759,
      "upload_time": "2022-11-29T12:32:26",
      "upload_time_iso_8601": "2022-11-29T12:32:26.141691Z",
      "url": "https://files.pythonhosted.org/packages/01/e4/14ab6c4d4a6cfa7f870571004e19a4169a796a559f4d060e3b0eae7e1f18/compcor-1.0.6.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}