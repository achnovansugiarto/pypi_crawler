{
  "info": {
    "author": "Shushant Pudasaini, Nitesh Ghimire , Sagar Lamichhane, Aakash Dumjan, Sujan Adhikari, Sajjan Adhikari, Janardan Karki",
    "author_email": "shusrulz@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "devanagari\n==============================\n\nNLP library for nepali textual dataset\n\nProject Organization\n------------\n\n    ├── LICENSE\n    ├── Makefile           <- Makefile with commands like `make data` or `make train`\n    ├── README.md          <- The top-level README for developers using this project.\n    ├── data\n    │   ├── external       <- Data from third party sources.\n    │   ├── interim        <- Intermediate data that has been transformed.\n    │   ├── processed      <- The final, canonical data sets for modeling.\n    │   └── raw            <- The original, immutable data dump.\n    │\n    ├── docs               <- A default Sphinx project; see sphinx-doc.org for details\n    │\n    ├── models             <- Trained and serialized models, model predictions, or model summaries\n    │\n    ├── notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),\n    │                         the creator's initials, and a short `-` delimited description, e.g.\n    │                         `1.0-jqp-initial-data-exploration`.\n    │\n    ├── references         <- Data dictionaries, manuals, and all other explanatory materials.\n    │\n    ├── reports            <- Generated analysis as HTML, PDF, LaTeX, etc.\n    │   └── figures        <- Generated graphics and figures to be used in reporting\n    │\n    ├── requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.\n    │                         generated with `pip freeze > requirements.txt`\n    │\n    ├── setup.py           <- makes project pip installable (pip install -e .) so src can be imported\n    ├── src                <- Source code for use in this project.\n    │   ├── __init__.py    <- Makes src a Python module\n    │   │\n    │   ├── data           <- Scripts to download or generate data\n    │   │   └── make_dataset.py\n    │   │\n    │   ├── features       <- Scripts to turn raw data into features for modeling\n    │   │   └── build_features.py\n    │   │\n    │   ├── models         <- Scripts to train models and then use trained models to make\n    │   │   │                 predictions\n    │   │   ├── predict_model.py\n    │   │   └── train_model.py\n    │   │\n    │   └── visualization  <- Scripts to create exploratory and results oriented visualizations\n    │       └── visualize.py\n    │\n    └── tox.ini            <- tox file with settings for running tox; see tox.readthedocs.io\n\n\n--------\n\n<p><small>Project based on the <a target=\"_blank\" href=\"https://drivendata.github.io/cookiecutter-data-science/\">cookiecutter data science project template</a>. #cookiecutterdatascience</small></p>",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://gitlab.com/shusrulz/everest_nlp/-/archive/0.1/everest_nlp-0.1.tar.gz",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "devanagari",
    "package_url": "https://pypi.org/project/devanagari/",
    "platform": "",
    "project_url": "https://pypi.org/project/devanagari/",
    "project_urls": {
      "Homepage": "https://gitlab.com/shusrulz/everest_nlp/-/archive/0.1/everest_nlp-0.1.tar.gz"
    },
    "release_url": "https://pypi.org/project/devanagari/0.1/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "Package for applying NLP to devanagari datasets",
    "version": "0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 10275724,
  "releases": {
    "0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c64649d52f748db2391a181344f93d28aab08e7e48b2e23da7ab7b2a79694532",
          "md5": "79d25d835b4d46928a0795d346d06608",
          "sha256": "c7cbbf7999dcb91dee7e4f763cabf62d6ae3a36fe83f7432bc40d8286f2be3dd"
        },
        "downloads": -1,
        "filename": "devanagari-0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "79d25d835b4d46928a0795d346d06608",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 2670,
        "upload_time": "2021-05-06T13:29:07",
        "upload_time_iso_8601": "2021-05-06T13:29:07.983528Z",
        "url": "https://files.pythonhosted.org/packages/c6/46/49d52f748db2391a181344f93d28aab08e7e48b2e23da7ab7b2a79694532/devanagari-0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "c64649d52f748db2391a181344f93d28aab08e7e48b2e23da7ab7b2a79694532",
        "md5": "79d25d835b4d46928a0795d346d06608",
        "sha256": "c7cbbf7999dcb91dee7e4f763cabf62d6ae3a36fe83f7432bc40d8286f2be3dd"
      },
      "downloads": -1,
      "filename": "devanagari-0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "79d25d835b4d46928a0795d346d06608",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 2670,
      "upload_time": "2021-05-06T13:29:07",
      "upload_time_iso_8601": "2021-05-06T13:29:07.983528Z",
      "url": "https://files.pythonhosted.org/packages/c6/46/49d52f748db2391a181344f93d28aab08e7e48b2e23da7ab7b2a79694532/devanagari-0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}