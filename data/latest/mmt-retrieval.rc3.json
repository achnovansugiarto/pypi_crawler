{
  "info": {
    "author": "Gregor Geigle",
    "author_email": "gregor.geigle@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3.6",
      "Topic :: Scientific/Engineering :: Artificial Intelligence"
    ],
    "description": "# MMT-Retrieval: Image Retrieval and more using Multimodal Transformers (OSCAR, UNITER, M3P & Co)\n\nThis project provides an easy way to use the recent pre-trained multimodal Transformers \nlike [OSCAR](https://github.com/microsoft/Oscar), [UNITER/ VILLA](https://github.com/zhegan27/VILLA) or [M3P (multilingual!)](https://github.com/microsoft/M3P)\nfor image search and more.\n\nThe code is primarily written for image-text retrieval.\nStill, many other Vision+Language tasks, beside image-text retrieval, should work out of the box using our code or require just small changes.\n\nThere is currently no unified approach for how the visual input is handled and each model uses their own slightly different approach.\nWe provide a common interface for all models and support for multiple feature file formats.\nThis greatly simplifies the process of running the models.\n\nOur project allows you to run a model in a few lines of code and offers easy fine-tuning of your own custom models.\n\nWe also provide our fine-tuned image-text-retrieval models for download, so you can get directly started.\nCheck out [our example for Image Search on MSCOCO using our fine-tuned models here](examples/applications/Image_Search.ipynb).\n\n## Citing & Authors\nIf you find this repository helpful, feel free to cite our publication [Retrieve Fast, Rerank Smart: Cooperative and Joint Approaches for Improved Cross-Modal Retrieval](https://arxiv.org/abs/2103.11920):\n```\n@article{geigle:2021:arxiv,\n  author    = {Gregor Geigle and \n                Jonas Pfeiffer and \n                Nils Reimers and \n                Ivan Vuli\\'{c} and \n                Iryna Gurevych},\n  title     = {Retrieve Fast, Rerank Smart: Cooperative and Joint Approaches for Improved Cross-Modal Retrieval},\n  journal   = {arXiv preprint},\n  volume    = {abs/2103.11920},\n  year      = {2021},\n  url       = {http://arxiv.org/abs/2103.11920},\n  archivePrefix = {arXiv},\n  eprint    = {2103.11920}\n}\n```\n\n> **Abstract:** \n> Current state-of-the-art approaches to cross-modal retrieval process text and \n> visual input jointly, relying on Transformer-based architectures with \n> cross-attention mechanisms that attend over all words and objects in an image. \n> While offering unmatched retrieval performance, such models: \\textbf{1)} \n> are typically pretrained from scratch and thus less scalable, \\textbf{2)} \n> suffer from huge retrieval latency and inefficiency issues, which makes \n> them impractical in realistic applications. To address these crucial gaps \n> towards both improved and efficient cross-modal retrieval, we propose a novel \n> fine-tuning framework which turns any pretrained text-image multi-modal model\n> into an efficient retrieval model. The framework is based on a cooperative \n> retrieve-and-rerank approach which combines: \\textbf{1)} twin networks to\n> separately encode all items of a corpus, enabling efficient initial \n> retrieval, and \\textbf{2)} a cross-encoder component for a more nuanced\n> (i.e., smarter) ranking of the retrieved small set of items. \n> We also propose to jointly fine-tune the two components with shared weights, \n> yielding a more parameter-efficient model. Our experiments on a series of \n> standard cross-modal retrieval benchmarks in monolingual, multilingual, \n> and zero-shot setups, demonstrate improved accuracy and huge efficiency \n> benefits over the state-of-the-art cross-encoders.\n\n\nDon't hesitate to send me an e-mail or report an issue, if something is broken or if you have further questions or feedback.\n\n\n\nContact person: Gregor Geigle, [gregor.geigle@gmail.com](mailto:gregor.geigle@gmail.com)\n\nhttps://www.ukp.tu-darmstadt.de/\n\nhttps://www.tu-darmstadt.de/\n\n>This repository contains experimental software and is published for the sole purpose of giving additional background details on the respective publication.\n\n\n## Installation\nWe recommend **Python 3.6** or higher, **[PyTorch 1.6.0](https://pytorch.org/get-started/locally/)** or higher,\n**[transformers v4.1.1](https://github.com/huggingface/transformers)** or higher,\nand **[sentence-transformer 0.4.1](https://github.com/UKPLab/sentence-transformers)** or higher up to 1.2.1.\n\n\n**Install with pip**\n\nInstall `mmt-retrieval` with `pip`: \n```\npip install mmt-retrieval\n```\n\n**Install from sources**\n\nAlternatively, you can also clone the latest version from the [repository](https://github.com/UKPLab/MMT-Retrieval) and install it directly from the source code:\n````\npip install -e .\n```` \n\n**PyTorch with CUDA**\nIf you want to use a GPU / CUDA, you must install PyTorch with the matching CUDA Version. Follow\n[PyTorch - Get Started](https://pytorch.org/get-started/locally/) for further details how to install PyTorch.\n\n\n\n## Getting Started\nWith our repository, you can get started using the multimodal Transformers in a few lines of code.\nCheck out [our example for Image Search on MSCOCO using our fine-tuned models here](examples/applications/Image_Search.ipynb).\nOr go along with the following steps to get started with your own project.\n\n\n### Select the Model\nWe provide our fine-tuned Image-Text Retrieval models for download.\nWe also provide links to where to download the pre-trained models and models that are fine-tuned for other tasks.\n\nAlternatively, you can fine-tune your own model, too. See [here](#training) for more.\n#### Our Fine-Tuned Image-Text Retrieval Models\nWe publish our jointly trained fine-tuned models.\nThey can be used both to encode images and text in a multimodal embedding space \nand to cross-encode pairs for a pairwise similarity.\n\n| Model | URL |\n|-------|-----|\n| OSCAR (Flickr30k) | https://public.ukp.informatik.tu-darmstadt.de/reimers/mmt-retrieval/models/v1/oscar_join_flickr30k.zip |\n| OSCAR (MSCOCO) | https://public.ukp.informatik.tu-darmstadt.de/reimers/mmt-retrieval/models/v1/oscar_join_mscoco.zip |\n| M3P (Multi30k - en, de fr, cs) | https://public.ukp.informatik.tu-darmstadt.de/reimers/mmt-retrieval/models/v1/m3p_join_multi30k.zip |\n\n\n\n#### Other Pre-Trained or Fine-Tuned Transformer\nWe currently do not directly support downloading of the different pre-trained Transformer models.\nPlease manually download them using the links in the respective repositories:\n[OSCAR](https://github.com/microsoft/Oscar), [UNITER/ VILLA](https://github.com/zhegan27/VILLA), [M3P](https://github.com/microsoft/M3P).\nWe present [here](#training) examples on how to initialize your own models with the pre-trained Transformers.\n\nOSCAR provides many already fine-tuned models for different tasks for download (see their MODEL_ZOO.md).\nWe provide the ability to convert those models to our framework so you can quickly  start using them.\n````python\nfrom mmt_retrieval.util import convert_finetuned_oscar\n\ndownloaded_folder_path = \".../oscar-base-ir-finetune/checkpoint-29-132780\"\nconverted_model = convert_finetuned_oscar(downloaded_folder_path)\nconverted_model.save(\"new_save_location_for_converted_model\")\n````\n\n\n### Step 0: Image Feature Pre-Processing\nAll currently supported models require a pre-processing step\nwhere we extract the regions of interest (which serve as image input analog to tokens for the language input) from the images using a Faster R-CNN object detection model.\n\nWhich detection model is needed, depends on the model that you are using.\nCheck out [our guide](documentation/image_features.md) where we have gathered all needed information to get startet.\n\nIf available, we also point to already pre-processed image features that can be downloaded for a quicker start.\n\n#### Loading Features and Image Input\nWe load image features in a dictionary-like object (`model.image_dict`) at the start.\nWe support various different storage formats for the features (see the guide above).\nEach image is uniquely identified by its image id in this dictionary.\n\nThe advantage of the dictionary approach is that we can designate the image input by its id which is then internally\nresolved to the features.\n\n\n#### Loading Features Just-In-Time (RAM Constraints)\nThe image features require a lot of additional memory.\nFor this reason, we support just-in-time loading of the features from disc.\nThis requires one feature file for each image. \nMany of the downloadable features are saved in a single file.\nWe provide code to split those big files in separate files, one for each image.\n\n````python\nfrom mmt_retrieval.util import split_oscar_image_feature_file_to_npz, split_tsv_features_to_npz\n````\n\n\n### Step 1: Getting Started\nThe following is an example showcasing all steps needed to get started encoding multimodal inputs with our code.\n\n````python\nfrom mmt_retrieval import MultimodalTransformer\n\n# Loading a jointly trained model that can both embed and cross-encode multimodal input\nmodel_path = \"https://public.ukp.informatik.tu-darmstadt.de/reimers/mmt-retrieval/models/v1/oscar_join_flickr30k.zip\"\nmodel = MultimodalTransformer(model_name_or_path=model_path)\n\n# Image ids are the unique identifier number (as string) of each image. If you save the image features separately for each image, this would be the file name\nimage_ids = [\"0\", \"1\", \"5\"]\n# We must load the image features in some way before we can use the model\n# Refer to Step 0 on more details for how to generate the features\nfeature_folder = \"path/to/processed/features\"\n# Directly load the features from disc. Requires more memory. \n# Increase max_workers for more concurrent threads for faster loading with many features\n# Remove select to load the entire folder\nmodel.image_dict.load_features_folder(feature_folder, max_workers=1, select=image_ids)\n## OR\n# Only load the file paths so that features are loaded later just-in-time when there are required.\n# Recommended with restricted memory and/ or a lot of images\n# Remove select to load the entire folder\nmodel.image_dict.load_file_names(feature_folder, select=image_ids)\n\nsentences = [\"The red brown fox jumped over the fence\", \"A dog being good\"]\n\n# Get Embeddings (as a list of numpy arrays)\nsentence_embeddings = model.encode(sentences=sentences, convert_to_numpy=True) # convert_to_numpy=True is default\nimage_embeddings = model.encode(images=image_ids, convert_to_numpy=True)\n\n# Get Pairwise Similarity Matrix (as a tensor)\nsimilarities = model.encode(sentences=sentences, images=image_ids, output_value=\"logits\", convert_to_tensor=True, cross_product_input=True)\nsimilarities = similarities[:,-1].reshape(len(image_ids), len(sentences))\n````\n\n\n## Experiments and Training\n<a name=\"training\"></a>\n\nSee [our examples](examples/experiments/README.md) to learn how to fine-tune and evaluate the multimodal Transformers.\nWe provide instructions for fine-tuning your own models with our image-text retrieval setup, show how to replicate our experiments,\nand give pointers on how to train your own models, potentially beyond image-text retrieval.\n\n\n### Expected Results with our Fine-Tuned Models\nWe report the JOIN+CO (,i.e., retrieve & re-rank with a jointly trained model) results of our published models\nRefer to our publications for more detailed results.\n\nImage Retrieval for MSCOCO/ Flickr30k:\n\n| Model                | Dataset  |      |      |      |\n|----------------------|----------|------|------|------|\n|                      |           | R@1  | R@5  | R@10 |\n| oscar-join-mscoco    |    MSCOCO (5k images) | 54.7 | 81.3 | 88.9 |\n| oscar-join-flickr30k | Flickr30k (1k images) | 76.4 | 93.6 | 96.2 |\n\nMultilingual Image Retrieval for Multi30k (in mR):\n\n| Model                | en        | de   | fr   | cs   |\n|----------------------|-----------|------|------|------|\n| m3p-join-multi30k    |        83.0 | 79.2 | 75.9 |   74 |\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/UKPLab/MMT-Retrieval",
    "keywords": "Transformer Networks Oscar UNITER M3P multimodal embedding PyTorch NLP CV deep learning image search retrieval",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "mmt-retrieval",
    "package_url": "https://pypi.org/project/mmt-retrieval/",
    "platform": "",
    "project_url": "https://pypi.org/project/mmt-retrieval/",
    "project_urls": {
      "Homepage": "https://github.com/UKPLab/MMT-Retrieval"
    },
    "release_url": "https://pypi.org/project/mmt-retrieval/0.1.2/",
    "requires_dist": [
      "sentence-transformers (<=1.2.1,>=0.4.1.2)",
      "tqdm (>=4.32.1)",
      "requests (>=2.22.0)",
      "transformers (>=4.1.1)",
      "numpy (>=1.19.3)",
      "torch (>=1.6.0)"
    ],
    "requires_python": "",
    "summary": "Multimodal Transformers for Image-Text Retrieval and more",
    "version": "0.1.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12076891,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d5980a08e889e19b73a219bff562fe3ac138007f153cb6e4a04da55fc34f58c2",
          "md5": "5626760fc6b6691cb27a9244ae64b0ae",
          "sha256": "83ea1b7bdaaa578a23456a6a0355c3408de3ca83780f35d6525dd7431bd9dfe5"
        },
        "downloads": -1,
        "filename": "mmt_retrieval-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "5626760fc6b6691cb27a9244ae64b0ae",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 116751,
        "upload_time": "2021-03-23T10:33:21",
        "upload_time_iso_8601": "2021-03-23T10:33:21.320738Z",
        "url": "https://files.pythonhosted.org/packages/d5/98/0a08e889e19b73a219bff562fe3ac138007f153cb6e4a04da55fc34f58c2/mmt_retrieval-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "eec52c93f6b92ef048def7f3c4092310fe4440e3256f563ffaf421eb39a7f172",
          "md5": "d13859ff498d5d4ad1c1e92a7807ab4b",
          "sha256": "76109247b07034900606734a3e6e26b1a038b64e0986ae97536c7a068be1ea28"
        },
        "downloads": -1,
        "filename": "mmt-retrieval-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "d13859ff498d5d4ad1c1e92a7807ab4b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 103317,
        "upload_time": "2021-03-23T10:33:24",
        "upload_time_iso_8601": "2021-03-23T10:33:24.737452Z",
        "url": "https://files.pythonhosted.org/packages/ee/c5/2c93f6b92ef048def7f3c4092310fe4440e3256f563ffaf421eb39a7f172/mmt-retrieval-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fbf8f235868ae691de147e8dcf98c73e8680838ba930b52d2cddc9aef301b287",
          "md5": "31f19b0a2791eaca9e34e032f116c6f1",
          "sha256": "6f47f178d21561f074eb7f64fcda4db09c129b0e0c784f03787b606e97f0d19a"
        },
        "downloads": -1,
        "filename": "mmt_retrieval-0.1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "31f19b0a2791eaca9e34e032f116c6f1",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 116727,
        "upload_time": "2021-07-15T11:18:32",
        "upload_time_iso_8601": "2021-07-15T11:18:32.862608Z",
        "url": "https://files.pythonhosted.org/packages/fb/f8/f235868ae691de147e8dcf98c73e8680838ba930b52d2cddc9aef301b287/mmt_retrieval-0.1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0e3ee820903d2dd7b82527a43f76271bc69357ccfe8726aed1678080c9a4c2f0",
          "md5": "d47eca1987260d41b35ec54f43981c0c",
          "sha256": "377e6a164822f5cef5cac25ac0f0b32fa000166bb785a616bdd5d21ef1610c6f"
        },
        "downloads": -1,
        "filename": "mmt-retrieval-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "d47eca1987260d41b35ec54f43981c0c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 105370,
        "upload_time": "2021-07-15T11:18:35",
        "upload_time_iso_8601": "2021-07-15T11:18:35.436880Z",
        "url": "https://files.pythonhosted.org/packages/0e/3e/e820903d2dd7b82527a43f76271bc69357ccfe8726aed1678080c9a4c2f0/mmt-retrieval-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3bd36962bf36aa5b1539d14f9cad81c3640b497b2b9522fcd7cfcb624de131c5",
          "md5": "f400036d7735c212973de03d4c777925",
          "sha256": "daeed31470c72c67e2519966c0ce62f190ed7f4d3632c3e237e5ce14f0c87923"
        },
        "downloads": -1,
        "filename": "mmt_retrieval-0.1.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f400036d7735c212973de03d4c777925",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 116768,
        "upload_time": "2021-11-20T08:52:12",
        "upload_time_iso_8601": "2021-11-20T08:52:12.693516Z",
        "url": "https://files.pythonhosted.org/packages/3b/d3/6962bf36aa5b1539d14f9cad81c3640b497b2b9522fcd7cfcb624de131c5/mmt_retrieval-0.1.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3979925a52a63c89f3750bffd88785e9e4d4c78b5e1eb5097aa5aa95d85da8f0",
          "md5": "a20df60b539c9ef863a099017dec490f",
          "sha256": "2d8531625c7146a9741b44781025306c4449b13720e6b5f383dddeec3f7b6467"
        },
        "downloads": -1,
        "filename": "mmt-retrieval-0.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "a20df60b539c9ef863a099017dec490f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 105578,
        "upload_time": "2021-11-20T08:52:17",
        "upload_time_iso_8601": "2021-11-20T08:52:17.052948Z",
        "url": "https://files.pythonhosted.org/packages/39/79/925a52a63c89f3750bffd88785e9e4d4c78b5e1eb5097aa5aa95d85da8f0/mmt-retrieval-0.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "3bd36962bf36aa5b1539d14f9cad81c3640b497b2b9522fcd7cfcb624de131c5",
        "md5": "f400036d7735c212973de03d4c777925",
        "sha256": "daeed31470c72c67e2519966c0ce62f190ed7f4d3632c3e237e5ce14f0c87923"
      },
      "downloads": -1,
      "filename": "mmt_retrieval-0.1.2-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "f400036d7735c212973de03d4c777925",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 116768,
      "upload_time": "2021-11-20T08:52:12",
      "upload_time_iso_8601": "2021-11-20T08:52:12.693516Z",
      "url": "https://files.pythonhosted.org/packages/3b/d3/6962bf36aa5b1539d14f9cad81c3640b497b2b9522fcd7cfcb624de131c5/mmt_retrieval-0.1.2-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "3979925a52a63c89f3750bffd88785e9e4d4c78b5e1eb5097aa5aa95d85da8f0",
        "md5": "a20df60b539c9ef863a099017dec490f",
        "sha256": "2d8531625c7146a9741b44781025306c4449b13720e6b5f383dddeec3f7b6467"
      },
      "downloads": -1,
      "filename": "mmt-retrieval-0.1.2.tar.gz",
      "has_sig": false,
      "md5_digest": "a20df60b539c9ef863a099017dec490f",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 105578,
      "upload_time": "2021-11-20T08:52:17",
      "upload_time_iso_8601": "2021-11-20T08:52:17.052948Z",
      "url": "https://files.pythonhosted.org/packages/39/79/925a52a63c89f3750bffd88785e9e4d4c78b5e1eb5097aa5aa95d85da8f0/mmt-retrieval-0.1.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}