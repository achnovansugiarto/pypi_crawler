{
  "info": {
    "author": "Laurent MOULIN",
    "author_email": "gignops@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Intended Audience :: Information Technology",
      "License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Topic :: Internet :: Log Analysis"
    ],
    "description": "![](images/logo_small.png?raw=true) feedoo \n\n![](images/sponsor.png?raw=true) Sponsored by [Spartan conseil](https://www.spartan-conseil.fr/)\n\n# What is feedoo ?\n\nfeedoo is an ETL, for Extract, Transform and Load. Basically, it gets data from files or database, process it thanks to pipelines and store data to a file or a database. It is very versatile and processing brick can be added without pain.\n\nThe purpose of feedoo is generic :\n\n* ETL to convert database to another one\n* Alerting like elastalert\n* Gather information from agent like Fluentbit\n* SIEM with correlation rule\n* Intrusion detection thanks AI\n* ...\n\nThe feedoo's design is for **S**ecurity **O**perational **C**enter (**SOC**). But if you need to play with data, you need feedoo as friend :)\n\n# Why ?\n\nThey are many reasons why I decided to build feedoo.\n\nFirstly, I work with [RethinkDB](https://rethinkdb.com/) as main database. It is amazingly easy to use, with enough performance for my needs. But the main drawback is about community tools. Briefly, they are no connector to work with, especially with Fluentd, Fluentbit or a clone of Elastalert.\n\nHere we are: the second point ! I really appreciate Fluent family, especially Fluentbit fully written in C. Nevertheless, a drawback arrive when we talk about plugins or modifications. I worked many years with Fluentd and it can become painful when you need something was not shipped with.\n\nSo a *sort* of **Python** version a Fluent with rules and easy extension seems to me a good idea !\n\n# Installation\n\nThe installation is very easy :\n\n```bash\npip3 install feedoo\n```\n\n# First run\n\nYou just install feedoo and you want to test ? Let's do a basic example !\n\nCreate a file at `/etc/feedoo/default.yaml` and copy-paste that :\n\n```yaml\npipelines:\n  \"pipeline#1\":\n    - name : input_dummy\n      tag : \"my_pypeline\"\n      data : {\"log\":\"my log\"}\n\n    - name : output_stdout\n      match : \"*\"\n```\n\nNow execute feedoo :\n\n```bash\nyou@computer:>feedoo\nmy_pypeline[1607608082]: {'log': 'my log'}\n```\n\nIt works ! :tada: You ran your first _**pipeline**_.\n\n# You said pipeline ?\n\n**Keep in mind previous example, I will reuse it now.**\n\nThe heart of the processing is based on _**pipeline**_. It is similar to _**pipe**_ operator in Unix system : every action do a basic operation and forward data to the following action :\n\n```bash\nyou@computer:>cat /var/log/auth.log | head | grep \"sudo\"\n```\n\nfeedoo do processing like this but add a _tag_ to data. This way following action can decide to process the data (if it _match_) or just forward it to the next action. Tag is added by the data producer (\"my_pipeline\" in input_dummy) and other action will try to match (\" * \" in output_stdout). In the feedoo context, we call data *Event*. Indeed diffent : Event contains data, called record (dict), an unix timestamp and the tag.\n\nActions are categorized in four cases :\n\n1. input\n1. output\n1. filter\n1. parser\n\n## Input\n\nInput produces events in the pipeline, including tag. If an input receives a event it forwards it to next action.\n\n### input_dummy\n\nIt is useful for testing purpose and forward events base on dicts. \n\nParameters :\n\n* `tag` : events' tag\n* `data` : a dict or a list of dict with fact\n* `repeat=1` : number of repeat of data. Set to negative number of infinit loop.\n\nExample:\n\n```yaml\n- name : input_dummy\n  tag : \"my_pypeline\"\n  data : {\"log\":\"my log\"}\n```\n\n### input_file\n\nIt watch a path and load file if :\n\n* The file exists on the startup\n* The file was create (written and closed)\n\nParameters :\n\n* `tag` : events' tag\n* `watch_path` : the path watched, typically a directory\n* `path_pattern` : provide a pattern which must match when a file is found with watch_path\n* `remove=False` : remove the file once read\n\nExample:\n\n```yaml\n- name : input_file\n  tag : \"logs\"\n  watch_path : /var/log\n  path_pattern : /var/log/stuff.*.log\n```\n\n### input_forward\n\nBased on [Fluentbit-server-py](https://github.com/laulin/fluentbit-server-py), it allows to received event from Fluentbit agent using the forward protocol.\nIt support authentication using shared key and TLS. No tag parameter is available since it is provided by the agent.\n\nParameters :\n\n* `host=\"localhost\"` : Used to bind socket server\n* `port=24224` : Port used to bind the server\n* `tls_enable=False` : Used to enable TLS support\n* `key_file=None` : if TLS enabled, path to the key file\n* `crt_file=None` : if TLS enabled, path to the certificate file\n* `shared_key=None` : defined a shared key between servers an nodes. If set, enable authentication\n* `server_hostname=\"\"` : define the hostname, useful for shared_key authentication\n* `buffer_size=32768` : define the incoming buffer size\n* `queue_size=1000` : define the queue size.\n\n**Warning** : if you exposed the port to internet, use authentication and TLS. If you can, add firewall rule to decrease surface attack. BE CAREFUL !\n\nExample:\n\n```yaml\n- name : input_forward\n  port: 24224\n  host : 0.0.0.0\n  tls_enable : true\n  key_file : /etc/tls/foo.key\n  crt_file : /etc/tls/foo.crt\n  shared_key : my_pr1vate_sh4red_K3y\n  server_hostname : foo.com\n```\n\n### input_sqlite\n\nThis input use a SQLite database as input. It works with time serie : each table is base on time (ex : log_%Y%m%d) and a field is an\nunix timestamp (int or float).\n\nParameters :\n\n* `tag` : tag used for generated event\n* `window` : time in second of processing window\n* `time_key` : field use in database as timestamp\n* `table_name_match` : Pattern (unix style) for find table (ex : log_*)\n* `filename` : SQLite database path\n* `fields` : dict of field name and sql type as value (ie TEXT, FLOAT, INTEGER, BLOB)\n* `offset=0` : Time in second of working time offset. Can be useful to process data in an other time zone or remove old tables\n* `remove=False` : If True, remove data once read\n* `reload_position=False` : If True, reload data from the last known time (0 by default). Otherwise, start at current time.\n* `db_path=None` : file path to store internal state. None means only RAM is used.\n\nExample:\n\n```yaml\n- name : input_sqlite\n  tag: \"log\"\n  table_name_match : \"log_*\"\n  filename : \"/my/path/test.db\"\n  fields :\n    timestamp : INTEGER\n    line : TEXT\n  time_key : timestamp\n```\n\n### input_rethinkdb\n\nThis input use a RethinkDB database as input. It works with time serie : each table is base on time (ex : log_%Y%m%d) and a field is an\nunix timestamp (int or float).\n\nParameters :\n\n* `tag` : tag used for generated event\n* `window` : time in second of processing window\n* `timestamp_index` : field use in database as timestamp\n* `table_name_match` : Pattern (unix style) for find table (ex : log_*)\n* `ip=localhost` : Rethinkdb instance IP\n* `port=28015` : Rethinkdb instance port\n* `database_name=test` : Rethinkdb database name\n* `wait_connection=30` : Wait time for database warm up\n* `offset=0` : Time in second of working time offset. Can be useful to process data in an other time zone or remove old tables\n* `remove=False` : If True, remove data once read\n* `reload_position=False` : If True, reload data from the last known time (0 by default). Otherwise, start at current time.\n* `db_path=None` : file path to store internal state. None means only RAM is used.\n\nExample:\n\n```yaml\n- name : input_rethinkdb\n  tag: \"log\"\n  table_name_match : \"log_*\"\n  ip: foo.bar.com\n  timestamp_index : timestamp\n  window: 60\n```\n\n## Output\n\nIt exports events out of the pipeline. It can be file, database, etc.\n\n### output_archive\n\nIt stores in buffer event and it writes buffer in file.\n\nParameters :\n\n* `match` : pattern to match tag\n* `time_key` : used to extract time to interpolate path_template\n* `path_template` : Template of the file path\n* `buffer_size=1000` : Number of event stored before flush\n* `timeout_flush=60` : Flush buffer after timeout, in second\n* `db_path=None` : file path to store internal state. None means only RAM is used.\n\nExample :\n\n```yaml\n- name : output_archive\n  time_key : timestamp\n  path_template : \"/archives/{source}/log-%Y%m%d.json\"\n  match : mylog\n```\n\nNotes :\n\n* if the example received the event contains record `{\"timestamp\":1607618046, \"source\":foo, \"data\":\"test\"}`, the path will be `/archives/foo/log-20201210.json`\n\n### output_rethinkdb\n\nStore events in [RethinkDB](https://rethinkdb.com/) as time serie.\n\nParameters\n\n* `match` : pattern to match tag\n* `time_key` : used to extract time to interpolate `table_template`\n* `table_template` : Template of the table name\n* `buffer_size=1000` : Number of event stored before flush\n* `database=\"test\"` : database name\n* `ip=\"localhost\"` : f set, change the database destination ip\n* `port=None` : if set, change the database destination port\n* `wait_connection=30` : used to wait the database warmup\n* `timeout_flush=60` : Flush buffer after timeout, in second\n* `db_path=None` : file path to store internal state. None means only RAM is used.\n\nExample:\n\n```yaml\n- name : output_rethinkdb\n  time_key : timestamp\n  table_template : \"log-%Y%m%d\"\n  database : test\n  ip : rethink.com\n  port : 28015\n  match : my_log\n```\n\n### output_stdout\n\nDisplay event in stdout.\n\nParameters\n\n* `match` : pattern to match tag\n\nExample:\n\n```yaml\n- name : output_stdout\n  match : my_log\n```\n\n### output_sqlite\n\nStore events in Sqlite database. Only defined fields are stored in event, others are dropped. If a field is missing, the document is dropped.\n\nParameters\n\n* `match` : pattern to match tag\n* `time_key` : field use for time serie.\n* `table_template` : template string used to generate table names\n* `fields` : dict of field name / Sqlite type. Sqlite types are REAL, TEXT, INTEGER or BLOB.\n* `filename` : Sqlite filename. Can be :memory: to save in RAM.\n* `buffer_size=1000` : Number of event stored before flush\n* `timeout_flush=60` : Flush buffer after timeout, in second\n* `db_path=None` : file path to store internal state. None means only RAM is used.\n\nExample:\n\n```yaml\n- name : output_sqlite\n  match : my_log\n  table_template: \"log_%Y%m%d\"\n  fields:\n    timestamp: INTEGER\n    line: TEXT\n  filename: \"/tmp/test.db\"\n  db_path : \"/tmp/test.pos.db\"\n```\n\n## Parser\n\nA parser take an event et parse one field with a specific format : `regex`, `json`, etc.\n\n### parser_json\n\nRead a field and add new fields to existing event.\n\nParameters :\n\n* `match` : pattern to match tag\n* `key` : Key to be parsed\n* `mode=\"merge\"` : A string that can be \"merge\", \"tree\" or \"add\"\n\nExample of modes :\n\n* `merge` :  {\"key\":\"Z\", \"value\":'{\"aaa\": \"bb\"}'} -> {\"key\":\"Z\", \"aaa\":\"bb\"}\n* `add` :  {\"key\":\"Z\", \"value\":'{\"aaa\": \"bb\"}'} -> {\"key\":\"Z\", \"value\":'{\"aaa\": \"bb\"}', \"aaa\":\"bb\"}`\n* `tree` :  {\"key\":\"Z\", \"value\":'{\"aaa\": \"bb\"}'} -> {\"key\":\"Z\", \"value\":{\"aaa\":\"bb\"}}\n\nExample :\n\n```yaml\n- name : parser_json\n  match : my_log\n  key : json_log\n  mode : add\n```\n\n### parser_regex\n\nRead a field and add new fields to existing event.\n\nParameters :\n\n* `match` : pattern to match tag\n* `key` : Key to be parsed\n* `regex` : define the behaviour. Use name group to create field\n* `mode=\"merge\"` : A string that can be \"merge\", \"tree\" or \"add\"\n\nExample of modes :\n\n* `merge` :  {\"key\":\"Z\", \"value\":'{\"aaa\": \"bb\"}'} -> {\"key\":\"Z\", \"aaa\":\"bb\"}`\n* `add` :  {\"key\":\"Z\", \"value\":'{\"aaa\": \"bb\"}'} -> {\"key\":\"Z\", \"value\":'{\"aaa\": \"bb\"}', \"aaa\":\"bb\"}\n* `tree` :  {\"key\":\"Z\", \"value\":'{\"aaa\": \"bb\"}'} -> {\"key\":\"Z\", \"value\":{\"aaa\":\"bb\"}}\n\nExample :\n\n```yaml\n- name : parser_regex\n  match : my_log\n  key : line\n  mode : merge\n  regex : \".+?(?P<name>\\\\{.+\\\\})\"\n```\n\n## Filter\n\nProcess event, may create or delete events.\n\n## filter_change\n\nThis action will monitor a certain field and match if that field changes. The field must change with respect to the last event with the same query_key.\n\nParameters :\n\n* `match` : pattern to match tag\n* `tag` : tag used to generate new event on change\n* `alert` : dict used to generate new event on change\n* `compare_key` : key monitored to find change\n* `query_key` : key used to group type of event\n* `ignore_null=True` : ignore if compare_key is missing. If ignore_null if false, missing compare_key is a valid state\n* `db_path=None` : file path to store internal state. None means only RAM is used.\n\nExample :\n\n```yaml\n- name : filter_change\n  match : my_log\n  tag : my_alert\n  alert : \n    title : The hostname change of status\n    priority : 2\n  compare_key : status\n  query_key : hostname\n```\n\nif events are :\n\n* `{\"hostname\":\"foo.bar\", \"status\":\"on\"}`\n* `{\"hostname\":\"foo.bar\", \"status\":\"off\"}`\n\nThen a new event will be created on second event\n\n### filter_date\n\nThis action performs a time parsing and allows to change the time format. Under the hook, it use [Chronyk](https://github.com/KoffeinFlummi/Chronyk) library so feel free refere about time format.\n\nParameters :\n\n* `match` : pattern to match tag\n* `key` : define the key to be parsed\n* `format=None` : define the output format of key's value. None means unix timestamps\n\nExample :\n\n```yaml\n- name : filter_date\n  match : date\n```\n\nEvent likes `{\"date\":\"Fri, 11 Dec 2020 08:30:13 +0000\"}` become `{\"date\":1607675413}`\n\nIt takes a date and convert it to timestamp\n\n### filter_rename\n\nThis action rename fields. Useful to insert in database if the name is not compatible.\n\nParameters :\n\n* `match` : pattern to match tag\n* `keys` : dict of old name / new name\n\nExample :\n\n```yaml\n- name : filter_rename\n  match : date\n  keys:\n    date : timestamp\n```\n\nEvent likes `{\"date\":1607675413}` become `{\"timestamp\":1607675413}`\n\n### filter_remove_keys\n\nThis action remove one or more key in event.\n\nParameters :\n\n* `match` : pattern to match tag\n* `keys` : on string or a list of string to describe keys to be removed.\n\nExample :\n\n```yaml\n- name : filter_remove_keys\n  match : date\n  keys : \n    - A\n    - B\n```\n\nEvent likes `{\"A\":1, \"B\":2, \"C\":3}` become `{\"C\":3}`\n\n### filter_retag\n\nThis action change the event's tag with a value in event or with a constant value.\n\nParameters :\n\n* `match` : pattern to match tag\n* `value` : New tag if key doesn't exist or if key=None\n* `key=None`: event value used to retag event. Use value parameter if missing\n\nExample :\n\n```yaml\n- name : filter_retag\n  match : my_log\n  value : generic_log\n  key : source\n```\n\nIf event looks like `{\"source\":\"auth\", \"data\":\"xxx\"}`, the new tag will be \"auth\".\nIf event looks like `{\"data\":\"xxx\"}`, the new tag will be \"generic_log\".\n\n### filter_frequency\n\nThis action matches when there are at least a certain number of events in a given time frame. This may be counted on a per-query_key basis.\n\nParameters :\n\n* `match` : pattern to match tag\n* `tag` : tag used to generate new event on change\n* `alert` : dict used to generate new event on change\n* `num_events` : match if number of event during the time frame if higher or equal to this value\n* `timeframe` : duration of the time windows in seconds\n* `query_key=None` : key used to group type of event\n* `db_path=None` : file path to store internal state. None means only RAM is used.\n\nExample :\n\n```yaml\n- name : filter_frequency\n  match : my_log\n  tag : my_alert\n  alert : \n    title : The hostname change of status too often\n    priority : 1\n  query_key : hostname\n  num_events : 10\n  timeframe : 60\n```\n\n### filter_spike\n\nThis action matches when the volume of events during a given time period is spike_height times larger or smaller than during the previous time period.\nIt uses two sliding windows to compare the current and reference frequency of events. We will call this two windows “reference” and “current”. A query\nkey and a field value can be defined.\n\nParameters :\n\n* `match` : pattern to match tag\n* `tag` : tag used to generate new event on change\n* `alert` : dict used to generate new event on change\n* `spike_height` : define the factor between current and reference that create an event\n* `spike_type` : define the spike direction : up, down or both\n* `timeframe` : duration of the time windows in seconds\n* `query_key=None` : key used to group type of event\n* `field_value=None` : When set, uses the value of the field in the document and not the number of matching documents. This is useful to monitor for example a temperature sensor and raise an alarm if the temperature grows too fast. Note that the means of the field on the reference and current windows are used to determine if the spike_height value is reached\n* `db_path=None` : file path to store internal state. None means only RAM is used.\n* `threshold_ref=10` : minimum number of event in the reference frame to be evaluated\n* `threshold_cur=10` : minimum number of event in the current frame to be evaluated\n\nExample :\n\n```yaml\n- name : filter_spike\n  match : my_log\n  tag : temperature_alert\n  alert : \n    title : The temperature rise to quickly\n    priority : 1\n  spike_height : 2\n  spike_type : up\n  field_value : temperature\n  timeframe : 60\n```\n\n### filter_flatline\n\nThis action matches when the total number of events is under a given threshold for a time period.\n\nParameters :\n\n* `match` : pattern to match tag\n* `tag` : tag used to generate new event on change\n* `alert` : dict used to generate new event on change\n* `threshold` : minimum number of event in the frame (other wise, rise an alert)\n* `timeframe` : duration of the time windows in seconds\n* `query_key=None` : key used to group type of event\n* `forget_keys=True` : set to false to keep tracking existing query key (emit alert for ever if no event come back).\n* `db_path=None` : file path to store internal state. None means only RAM is used.\n\nExample :\n\n```yaml\n- name : filter_flaline\n  match : my_log\n  tag : heartbeat_down\n  alert : \n    title : No more heartbeat !\n    priority : 3\n  threshold : 1\n  field_value : source\n  timeframe : 60\n```\n\n### filter_dnsbl\n\nThis action use [DNSBL](https://en.wikipedia.org/wiki/Domain_Name_System-based_Blackhole_List) mecanism to emit alert. To prevent negative false,\nmany domains can be used; This way can have a major drawback in term of performance. Nevertheless, we use multiprocessing approach to the the overhead low.\n\nParameters :\n\n* `match` : pattern to match tag\n* `tag` : tag used to generate new event on change\n* `key` : key used to catch an ip value. If the value is not a valid ip, no processing is done.\n* `threshold_percent` : minimum percent of trigged blacklist to rise an alert\n* `domains` : list of domains uses for DNSBL\n* `alert` : dict used to generate new event on change\n* `db_path=None` : file path to store internal state. None means only RAM is used.\n* `timeout=3600` : Duration in second of the cache. Prevent too many request on DNSBL.\n\nExample :\n\n```yaml\n- name : filter_dnsbl\n  match : netflow\n  tag : ip_blacklist\n  alert : \n    title : you reach a bad server\n    priority : 3\n  threshold : 50\n  key : destination_address\n  domains:\n    - aaa.dns.com\n    - bbb.dns.com\n    - ccc.dns.com\n  timeout : 36000\n```\n\n### filter_matching_list\n\nThis action performs a multiple string matching using aho corasick algorithm. It can be used for *darklist* or *lightlist*.\n\nParameters :\n\n* `match` : pattern to match tag\n* `tag` : tag used to generate new event on change\n* `key` : key used to catch an ip value. If the value is not a valid ip, no processing is done.\n* `alert` : dict used to generate new event on change\n* `mode` : define the way the detection is performed. `present` acts as darklist, `absent` acts as lightlist.\n* `matching_list` : define the list of word to be detected (or not). Mutually exclusive with `matching_list_file`.\n* `matching_list_file` : define the filename containing the list of word to be detected (or not). Each line of the file is a word. Mutually exclusive with `matching_list`.\n\nExample :\n\n```yaml\n- name : filter_matching_list\n  match : netflow\n  tag : bad_protocol\n  alert : \n    title : protocol is not allowed\n    priority : 3\n  key : protocol\n  mode: absent\n  matching_list:\n    - TCP\n    - UDP\n    - ARP\n```\n\n# icons\n\nThanks to flaticon.com !\n\n<div>Icons made by <a href=\"https://www.flaticon.com/authors/freepik\" title=\"Freepik\">Freepik</a> from <a href=\"https://www.flaticon.com/\" title=\"Flaticon\">www.flaticon.com</a></div>",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/laulin/feedoo",
    "keywords": "",
    "license": "GPLV3",
    "maintainer": "",
    "maintainer_email": "",
    "name": "feedoo",
    "package_url": "https://pypi.org/project/feedoo/",
    "platform": "",
    "project_url": "https://pypi.org/project/feedoo/",
    "project_urls": {
      "Homepage": "https://github.com/laulin/feedoo"
    },
    "release_url": "https://pypi.org/project/feedoo/0.6.0/",
    "requires_dist": null,
    "requires_python": ">=3",
    "summary": "General purpose data processor",
    "version": "0.6.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 9057888,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "709d3abfd914747f07a7e48db0b2fe920fac43ef0b8eafc09792abcaf36318f7",
          "md5": "c5b7af06babf5799067545140efadaf6",
          "sha256": "6a5616a9eaf2609afdd6670b79cfe0cdc2212add3983319e09d35521de958b45"
        },
        "downloads": -1,
        "filename": "feedoo-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "c5b7af06babf5799067545140efadaf6",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3",
        "size": 19182,
        "upload_time": "2020-12-11T10:46:12",
        "upload_time_iso_8601": "2020-12-11T10:46:12.733818Z",
        "url": "https://files.pythonhosted.org/packages/70/9d/3abfd914747f07a7e48db0b2fe920fac43ef0b8eafc09792abcaf36318f7/feedoo-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "aee3d8b97343aa4fd1f90cf4a0e1edc75a8bb77242f5a3af3c8491df24f65166",
          "md5": "dee535bdab98e8497cdcf4a4482a6e55",
          "sha256": "0e071109c44e4c631c07a770d4e10221e81906f1f235d4044a30d4fb77881b26"
        },
        "downloads": -1,
        "filename": "feedoo-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "dee535bdab98e8497cdcf4a4482a6e55",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3",
        "size": 20268,
        "upload_time": "2020-12-11T15:44:50",
        "upload_time_iso_8601": "2020-12-11T15:44:50.705011Z",
        "url": "https://files.pythonhosted.org/packages/ae/e3/d8b97343aa4fd1f90cf4a0e1edc75a8bb77242f5a3af3c8491df24f65166/feedoo-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c4e27c3aff648b6e9b49389e0047888f9460f3499e8c6354e712118e1667dcb9",
          "md5": "520e7f5e5b70861d6e37eba31d4ba5ac",
          "sha256": "2b72860e0920125f89157c50f64ca98444c4506990aa1aeb47eb2895f2b62820"
        },
        "downloads": -1,
        "filename": "feedoo-0.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "520e7f5e5b70861d6e37eba31d4ba5ac",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3",
        "size": 20974,
        "upload_time": "2020-12-11T18:31:41",
        "upload_time_iso_8601": "2020-12-11T18:31:41.197352Z",
        "url": "https://files.pythonhosted.org/packages/c4/e2/7c3aff648b6e9b49389e0047888f9460f3499e8c6354e712118e1667dcb9/feedoo-0.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c831563ae7d61a48243c0c6820cec620bc8123e732d26419101c4d9461b56f54",
          "md5": "d87c5228fc7a84d35214a34c240715e6",
          "sha256": "6e1f04e39debc85de2bdc186f6b5a272831074d8440ba428ba5d2fe694351d70"
        },
        "downloads": -1,
        "filename": "feedoo-0.3.0.tar.gz",
        "has_sig": false,
        "md5_digest": "d87c5228fc7a84d35214a34c240715e6",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3",
        "size": 24254,
        "upload_time": "2020-12-14T16:09:52",
        "upload_time_iso_8601": "2020-12-14T16:09:52.476001Z",
        "url": "https://files.pythonhosted.org/packages/c8/31/563ae7d61a48243c0c6820cec620bc8123e732d26419101c4d9461b56f54/feedoo-0.3.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "60bccd350771f5d6739c676eb49e0839abf31db150216b436580daab85684f32",
          "md5": "e420942c5fbd353915ab4e609d8888b3",
          "sha256": "69021f0eaea7ff9a126320e84e6e79aeb3ceb910e6b646a1a2500e347958faee"
        },
        "downloads": -1,
        "filename": "feedoo-0.4.0.tar.gz",
        "has_sig": false,
        "md5_digest": "e420942c5fbd353915ab4e609d8888b3",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3",
        "size": 29368,
        "upload_time": "2020-12-17T13:55:34",
        "upload_time_iso_8601": "2020-12-17T13:55:34.396950Z",
        "url": "https://files.pythonhosted.org/packages/60/bc/cd350771f5d6739c676eb49e0839abf31db150216b436580daab85684f32/feedoo-0.4.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b2882605ab9d41cdf8d5a6472fcd941bc1ef58943fdfcbe1da6b957981c1c0bb",
          "md5": "b8b5b1536e41837d9f15125ad3c38c75",
          "sha256": "0beb731d0c1e2ea26a5a2f820100f88aee5f15973c1239f3f324de7bb545e257"
        },
        "downloads": -1,
        "filename": "feedoo-0.4.1.tar.gz",
        "has_sig": false,
        "md5_digest": "b8b5b1536e41837d9f15125ad3c38c75",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3",
        "size": 29623,
        "upload_time": "2020-12-18T09:02:01",
        "upload_time_iso_8601": "2020-12-18T09:02:01.426583Z",
        "url": "https://files.pythonhosted.org/packages/b2/88/2605ab9d41cdf8d5a6472fcd941bc1ef58943fdfcbe1da6b957981c1c0bb/feedoo-0.4.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "250b09824e962bdd1633685b6e16d00938b191995c2ac8357557dddab97206f2",
          "md5": "fdcc0d79d4b9a5e1c7f99f68cc49a914",
          "sha256": "c14eedf90bd86b0434b7ea2e9f9a8ca5992796d15799e8d27077066b37298b0c"
        },
        "downloads": -1,
        "filename": "feedoo-0.4.2.tar.gz",
        "has_sig": false,
        "md5_digest": "fdcc0d79d4b9a5e1c7f99f68cc49a914",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3",
        "size": 29692,
        "upload_time": "2020-12-18T15:04:28",
        "upload_time_iso_8601": "2020-12-18T15:04:28.453639Z",
        "url": "https://files.pythonhosted.org/packages/25/0b/09824e962bdd1633685b6e16d00938b191995c2ac8357557dddab97206f2/feedoo-0.4.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "60a889297bcb9ce2d3068315be03b9aaaf08eff33069c27ccc0e31381594bb62",
          "md5": "802d00678417e53784a9654a57d2efcd",
          "sha256": "85001efbb530697a2541074b9394b24bbe1dd9740a1e1167186ff8166ffea2a6"
        },
        "downloads": -1,
        "filename": "feedoo-0.4.3.tar.gz",
        "has_sig": false,
        "md5_digest": "802d00678417e53784a9654a57d2efcd",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3",
        "size": 30019,
        "upload_time": "2020-12-18T17:04:08",
        "upload_time_iso_8601": "2020-12-18T17:04:08.266179Z",
        "url": "https://files.pythonhosted.org/packages/60/a8/89297bcb9ce2d3068315be03b9aaaf08eff33069c27ccc0e31381594bb62/feedoo-0.4.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.5.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ae3301d4f09e48fd4be7c8e73ec0a02327bf82685b57406e3f71f97462425a38",
          "md5": "7910fff5f1a1f2ed776f7ed41cb62ac9",
          "sha256": "7c37c208c432cb50e670e7cd256fb9f730c65d9315b7d66334773a5134082028"
        },
        "downloads": -1,
        "filename": "feedoo-0.5.0.tar.gz",
        "has_sig": false,
        "md5_digest": "7910fff5f1a1f2ed776f7ed41cb62ac9",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3",
        "size": 34171,
        "upload_time": "2020-12-22T17:44:07",
        "upload_time_iso_8601": "2020-12-22T17:44:07.355119Z",
        "url": "https://files.pythonhosted.org/packages/ae/33/01d4f09e48fd4be7c8e73ec0a02327bf82685b57406e3f71f97462425a38/feedoo-0.5.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.6.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8d5ca8d1aa4c9a49973eea25f1e6f872ad42535e8024eacc80190419ebdd62e6",
          "md5": "d24d544cc58c95e8c270acb1f485135a",
          "sha256": "bfe36d179b6fd7a834ac67e629eaeeecb3373e59dc7c86198ca42b625d494b17"
        },
        "downloads": -1,
        "filename": "feedoo-0.6.0.tar.gz",
        "has_sig": false,
        "md5_digest": "d24d544cc58c95e8c270acb1f485135a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3",
        "size": 35352,
        "upload_time": "2021-01-05T14:16:20",
        "upload_time_iso_8601": "2021-01-05T14:16:20.181202Z",
        "url": "https://files.pythonhosted.org/packages/8d/5c/a8d1aa4c9a49973eea25f1e6f872ad42535e8024eacc80190419ebdd62e6/feedoo-0.6.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "8d5ca8d1aa4c9a49973eea25f1e6f872ad42535e8024eacc80190419ebdd62e6",
        "md5": "d24d544cc58c95e8c270acb1f485135a",
        "sha256": "bfe36d179b6fd7a834ac67e629eaeeecb3373e59dc7c86198ca42b625d494b17"
      },
      "downloads": -1,
      "filename": "feedoo-0.6.0.tar.gz",
      "has_sig": false,
      "md5_digest": "d24d544cc58c95e8c270acb1f485135a",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3",
      "size": 35352,
      "upload_time": "2021-01-05T14:16:20",
      "upload_time_iso_8601": "2021-01-05T14:16:20.181202Z",
      "url": "https://files.pythonhosted.org/packages/8d/5c/a8d1aa4c9a49973eea25f1e6f872ad42535e8024eacc80190419ebdd62e6/feedoo-0.6.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}