{
  "info": {
    "author": "Ken Farmer",
    "author_email": "kenfar@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Environment :: Console",
      "Intended Audience :: Developers",
      "Intended Audience :: Information Technology",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: BSD License",
      "Operating System :: POSIX",
      "Programming Language :: Python",
      "Topic :: Database",
      "Topic :: Scientific/Engineering",
      "Topic :: Scientific/Engineering :: Information Analysis",
      "Topic :: Text Processing",
      "Topic :: Utilities"
    ],
    "description": "Introduction\n============\n\nDatagristle is a toolbox of tough and flexible command line tools for\nworking with data. It’s kind of an interactive mix between ETL and data\nanalysis optimized for rapid analysis and manipulation of a wide variety\nof data at the command line.\n\nMore info is on the DataGristle wiki here:\n`wiki <https://github.com/kenfar/DataGristle/wiki>`__\n\nAnd examples of all csv utilities can be found here:\n`examples <https://github.com/kenfar/DataGristle/tree/master/examples>`__\n\nInstallation\n============\n\n-  Using `pip <http://www.pip-installer.org/en/latest/>`__:\n\n   ::\n\n      $ pip install datagristle\n\nDependencies\n============\n\n-  Python 3.8\n-  or Python 3.9\n-  or Python 3.10\n-  or Python 3.11\n\nCSV Utilities provided in this release:\n=======================================\n\n-  gristle_differ\n\n   -  Allows two identically-structured files to be compared by key\n      columns and split into same, inserts, deletes, chgold and chgnew\n      files.\n   -  The user can configure which columns are included in the\n      comparison.\n   -  Post delta transformations can include assign sequence numbers,\n      copying field values, etc.\n\n-  gristle_converter (was: gristle_file_converter)\n\n   -  Converts an input file with one csv dialect into an output file\n      with another.\n\n-  gristle_freaker\n\n   -  Produces a frequency distribution of multiple columns from input\n      file.\n\n-  gristle_profiler (was: gristle_determinator)\n\n   -  Identifies file formats, generates metadata, prints file analysis\n      report\n   -  This is the most mature - and also used by the other utilities so\n      that you generally do not need to enter file structure info.\n\n-  gristle_slicer\n\n   -  Used to extract a subset of columns and/or rows out of an input\n      file.\n   -  Uses python slicing notation to specific items or ranges of items\n      to extract.\n\n-  gristle_sorter\n\n   -  CSV-aware sort utility that handles data that breaks unix sorts.\n\n-  gristle_validator\n\n   -  Validates csv files by confirming that all records have the right\n      number of fields, and by applying a json schema to each record.\n\n-  gristle_viewer\n\n   -  Shows one record from a file at a time - formatted based on\n      metadata.\n\nFile and Directory Utilities provided in this release:\n======================================================\n\n-  gristle_dir_merger\n\n   -  Used to consolidate large directories with options to control\n      matching criteria as well as matching actions.\n\ngristle_slicer\n==============\n\n::\n\n   Extracts subsets of input files based on user-specified columns and rows.\n   The input csv file can be piped into the program through stdin or identified\n   via a command line option.  The output will default to stdout, or redirected\n   to a filename via a command line option.\n\n   The columns and rows are specified using python list slicing syntax -\n   so individual columns or rows can be listed as can ranges.   Inclusion\n   or exclusion logic can be used - and even combined.\n\n   Examples:\n      $ gristle_slicer -i sample.csv\n                   Prints all rows and columns\n      $ gristle_slicer -i sample.csv -c\":5, 10:15, dept\" -C 13\n                   Prints columns 0-4 and 10,11,12,14, and the col associated \n                   with the header field 'dept' for all records\n      $ gristle_slicer -i sample.csv -C:-1\n                   Prints all columns except for the last for all records\n      $ gristle_slicer -i sample.csv -c:5 -r 100:1:-1\n                   Prints records 1 to 100 in reverse order\n      $ gristle_slicer -i sample.csv -c:5 -r :100:3\n                   Prints every third record from 0 to 99\n      $ gristle_slicer -i sample.csv -c:5 -r :100:0.25\n                   Prints a random 25% of the records from 0 to 99\n      $ gristle_slicer -i sample.csv -c:5 -r-100 -d'|' --quoting=quote_all\n                   Prints columns 0-4 for the last 100 records, csv\n                   dialect info (delimiter, quoting) provided manually)\n      $ cat sample.csv | gristle_slicer -c:5 -r-100 -d'|' --quoting=quote_all\n                   Prints columns 0-4 for the last 100 records, csv\n                   dialect info (delimiter, quoting) provided manually)\n   Many more examples can be found here:\n      https://github.com/kenfar/DataGristle/tree/master/examples/gristle_slicer\n\ngristle_freaker\n===============\n\n::\n\n   Creates a frequency distribution of values from columns of the input file\n   and prints it out in columns - the first being the unique key and the last\n   being the count of occurances.\n\n   Examples:\n      $ gristle_freaker -i sample.csv -c 0\n                   Creates two columns from the input - the first with\n                   unique keys from column 0, the second with a count of\n                   how many times each exists.\n      $ gristle_freaker -i sample.csv -c home_state\n                   This is the same as the previous example - but in this case\n                   the column reference uses the name of the field from the\n                   file header.\n      $ gristle_freaker -i sample.csv -d '|'  -c 0 --sortcol 1 --sortorder forward --writelimit 25\n                   In addition to what was described in the first example,\n                   this example adds sorting of the output by count ascending\n                   and just prints the first 25 entries.\n      $ gristle_freaker -i sample.csv -d '|'  -c 0,1\n                   Creates three columns from the input - the first two\n                   with unique key combinations from columns 0 & 1, the\n                   third with the number of times each combination exists.\n   Many more examples can be found here:\n      https://github.com/kenfar/DataGristle/tree/master/examples/gristle_freaker\n\ngristle_sorter\n==============\n\n::\n\n   Provides a csv dialect-aware sort that can safely handle delimiters, quotes, and newlines\n   within fields.\n\n   Examples:\n      $ gristle_sorter -i sample.csv -k 0sf -D\n                   Sort file by the 0-position string column in forward (ascending) direction,\n                   dedupes the results and writes them to stdout.  The csv dialect is auto-\n                   detected.\n      $ gristle_sorter -i sample.csv -k 0sf dept-s-r -D\n                   This example uses the optional tildes to separate the parts of the key,\n                   and uses a fieldname reference from the file header (dept) rather than a\n                   numeric field position.\n      $ gristle_sorter -i sample.csv --keys 0sf 3ir --outfile sample_out.csv\n                   Sorts file by the 0-position column string in forward direction followed\n                   by the position 3 column integer in reverse direction.  The output is not\n                   deduped, but is written to a file.  The csv dialect is auto-detected.\n      $ gristle_sorter -i sample.csv -k 0sf -d '|' -q quote_all --doublequote --has-header\n                   Sort file by the 0-position string column in forward (ascending) direction,\n                   specifies the csv dialect explicitly, including that the file has a header\n                   that will be written to the top of the output file.\n   Many more examples can be found here:\n      https://github.com/kenfar/DataGristle/tree/master/examples/gristle_sorter\n\ngristle_profiler\n================\n\n::\n\n   Analyzes the structures and contents of csv files in the end producing a\n   report of its findings.  It is intended to speed analysis of csv files by\n   automating the most common and frequently-performed analysis tasks.  It's\n   useful in both understanding the format and data and quickly spotting issues.\n\n   Examples:\n      $ gristle_profiler --infiles japan_station_radiation.csv\n                   This command will analyze a file with radiation measurements\n                   from various Japanese radiation stations.\n\n       File Structure:\n       format type:       csv\n       field cnt:         4\n       record cnt:        100\n       has header:        True\n       delimiter:\n       csv quoting:       False\n       skipinitialspace:  False\n       quoting:           QUOTE_NONE\n       doublequote:       False\n       quotechar:         \"\n       lineterminator:    '\\n'\n       escapechar:        None\n\n       Field Analysis Progress:\n       Analyzing field: 0\n       Analyzing field: 1\n       Analyzing field: 2\n       Analyzing field: 3\n\n       Fields Analysis Results:\n\n           ------------------------------------------------------\n           Name:             station_id\n           Field Number:     0\n           Wrong Field Cnt:  0\n           Type:             timestamp\n           Min:              1010000001\n           Max:              1140000006\n           Unique Values:    99\n           Known Values:     99\n           Top Values not shown - all values are unique\n\n           ------------------------------------------------------\n           Name:             datetime_utc\n           Field Number:     1\n           Wrong Field Cnt:  0\n           Type:             timestamp\n           Min:              2011-02-28 15:00:00\n           Max:              2011-02-28 15:00:00\n           Unique Values:    1\n           Known Values:     1\n           Top Values:\n               2011-02-28 15:00:00                      x 99 occurrences\n\n           ------------------------------------------------------\n           Name:             sa\n           Field Number:     2\n           Wrong Field Cnt:  0\n           Type:             integer\n           Min:              -999\n           Max:              52\n           Unique Values:    35\n           Known Values:     35\n           Mean:             2.45454545455\n           Median:           38.0\n           Variance:         31470.2681359\n           Std Dev:          177.398613681\n           Top Values:\n               41                                       x 7 occurrences\n               42                                       x 7 occurrences\n               39                                       x 6 occurrences\n               37                                       x 5 occurrences\n               46                                       x 5 occurrences\n               17                                       x 4 occurrences\n               38                                       x 4 occurrences\n               40                                       x 4 occurrences\n               45                                       x 4 occurrences\n               44                                       x 4 occurrences\n\n           ------------------------------------------------------\n           Name:             ra\n           Field Number:     3\n           Wrong Field Cnt:  0\n           Type:             integer\n           Min:              -888\n           Max:              0\n           Unique Values:    2\n           Known Values:     2\n           Mean:             -556.121212121\n           Median:           -888.0\n           Variance:         184564.833792\n           Std Dev:          429.610095077\n           Top Values:\n               -888                                     x 62 occurrences\n               0                                        x 37 occurrences\n\n   Many more examples can be found here:\n      https://github.com/kenfar/DataGristle/tree/master/examples/gristle_profiler\n\ngristle_converter\n=================\n\n::\n\n   Converts a file from one csv dialect to another\n\n   Examples:\n      $ gristle_converter -i foo.csv -o bar.csv \\\n        --delimiter=',' --has-header --quoting=quote-all doublequote \\\n        --out-delimiter='|'  --out-has-no-header --out-quoting quote_none --out-escapechar='\\'\n            Copies input file to output while completely changing every aspect\n            of the csv dialect.\n   Many more examples can be found here:\n      https://github.com/kenfar/DataGristle/tree/master/examples/gristle_converter\n\ngristle_validator\n=================\n\n::\n\n   Splits a csv file into two separate files based on how records pass or fail\n   validation checks:\n      - Field count - checks the number of fields in each record against the\n        number required.  The correct number of fields can be provided in an\n        argument or will default to using the number from the first record.\n      - Schema - uses csv file requirements defined in a json-schema file for\n        quality checking.  These requirements include the number of fields,\n        and for each field - the type, min & max length, min & max value,\n        whether or not it can be blank, existance within a list of valid\n        values, and finally compliance with a regex pattern.\n\n   The output can just be the return code (0 for success, 1+ for errors), can\n   be some high level statistics, or can be the csv input records split between\n   good and erroneous files.  Output can also be limited to a random subset.\n\n   Examples:\n      $ gristle_validator  -i sample.csv -f 3\n            Prints all valid input rows to stdout, prints all records with\n            other than 3 fields to stderr along with an extra final field that\n            describes the error.\n      $ gristle_validator  -i sample.csv\n            Prints all valid input rows to stdout, prints all records with\n            other than the same number of fields found on the first record to\n            stderr along with an extra final field that describes the error.\n      $ gristle_validator  -i sample.csv -o sample_good.csv --errfile sample_err.csv\n            Same comparison as above, but explicitly splits good and bad data\n            into separate files.\n      $ gristle_validator  -i sample.csv --randomout 1\n            Same comparison as above, but only writes a random 1% of data out.\n      $ gristle_validator  -i sample.csv --verbosity quiet\n            Same comparison as above, but writes nothing out.  Exit code can be\n            used to determine if any bad records were found.\n      $ gristle_validator  -i sample.csv --validschema sample_schema.csv\n            The above command checks both field count as well as validations\n            described in the sample_schema.csv file.  Here's an example of what\n            that file might look like:\n               items:\n                   - title:            rowid\n                     blank:            False\n                     required:         True\n                     dg_type:          integer\n                     dg_minimum:       1\n                     dg_maximum:       60\n                   - title:            start_date\n                     blank:            False\n                     minLength:        8\n                     maxLength:        10\n                     pattern:          '[0-9]*/[0-9]*/[1-2][0-9][0-9][0-9]'\n                   - title:            location\n                     blank:            False\n                     minLength:        2\n                     maxLength:        2\n                     enum:             ['ny','tx','ca','fl','wa','ga','al','mo']\n      $ gristle_validator  -i sample.csv -o good.csv -e -\n        --validschema schema.csv --err-out-fields --err-out-text\n            The above command writes error records to stderr.  Err-out-fields \n            adds error descriptions to the end of the error records, while\n            err-out-text added even more detailed error descriptions as records\n            following invalid records.\n\ngristle_viewer\n==============\n\n::\n\n   Displays a single record of a file, one field per line, with field names\n   displayed as labels to the left of the field values.  Also allows simple\n   navigation between records.\n\n   Examples:\n      $ gristle_viewer -i sample.csv -r 3\n                   Presents the third record in the file with one field per line\n                   and field names from the header record as labels in the left\n                   column.\n      $ gristle_viewer -i sample.csv -r 3  -d '|' -q quote_none\n                   In addition to what was described in the first example this\n                   adds explicit csv dialect overrides.\n\n   Many more examples can be found here:\n      https://github.com/kenfar/DataGristle/tree/master/examples/gristle_viewer\n\ngristle_differ\n==============\n\n::\n\n   gristle_differ compares two files, typically an old and a new file, based\n   on explicit keys in a way that is far more accurate than diff.  It can also\n   compare just subsets of columns, and perform post-delta transforms to\n   populate fields with static values, values from other fields, variables\n   from the command line, or incrementing sequence numbers.\n\n   More info on the wiki here:  https://github.com/kenfar/DataGristle/wiki/gristle_differ\n\n   Examples:\n\n      $ gristle_differ --infiles file0.dat file1.dat --key-cols 0 2 --ignore_cols  19 22 33\n\n           - Sorts both files on columns 0 & 2\n           - Dedupes both files on column 0\n           - Compares all fields except fields 19,22, and 23\n           - Automatically determines the csv dialect\n           - Produces the following files:\n              - file1.dat.insert\n              - file1.dat.delete\n              - file1.dat.same\n              - file1.dat.chgnew\n              - file1.dat.chgold\n\n      $ gristle_differ --infiles file0.dat file1.dat --key-cols 0 --compare-cols 1 2 3 4 5 6 7  -d '|'\n\n           - Sorts both files on columns 0\n           - Dedupes both files on column 0\n           - Compares fields 1,2,3,4,5,6,7\n           - Uses '|' as the field delimiter\n           - Produces the same output file names as example 1.\n\n\n      $ gristle_differ --infiles file0.dat file1.dat --config-fn ./foo.yml  \\\n                  --variables batchid:919 --variables pkid:82304\n\n           - Produces the same output file names as example 1.\n           - But in this case it gets the majority of its configuration items from\n             the config file ('foo.yml').  This could include key columns, comparison\n             columns, ignore columns, post-delta transformations, and other information.\n           - The two variables options are used to pass in user-defined variables that\n             can be referenced by the post-delta transformations.  The batchid will get\n             copied into a batch_id column for every file, and the pkid is a sequence\n             that will get incremented and used for new rows in the insert, delete and\n             chgnew files.\n\n   Many more examples can be found here:\n       https://github.com/kenfar/DataGristle/tree/master/examples/gristle_differ\n\ngristle_metadata\n================\n\n::\n\n   Gristle_metadata provides a command-line interface to the metadata database.\n   It's mostly useful for scripts, but also useful for occasional direct\n   command-line access to the metadata.\n\n   Examples:\n      $ gristle_metadata --table schema --action list\n                   Prints a list of all rows for the schema table.\n      $ gristle_metadata --table element --action put --prompt\n                   Allows the user to input a row into the element table and\n                   prompts the user for all fields necessary.\n\ngristle_md_reporter\n===================\n\n::\n\n   Gristle_md_reporter allows the user to create data dictionary reports that\n   combine information about the collection and fields along with field value\n   descriptions and frequencies.\n\n   Examples:\n      $ gristle_md_reporter --report datadictionary --collection_id 2\n                   Prints a data dictionary report of collection_id 2.\n      $ gristle_md_reporter --report datadictionary --collection_name presidents\n                   Prints a data dictionary report of the president collection.\n      $ gristle_md_reporter --report datadictionary --collection_id 2 --field_id 3\n                   Prints a data dictionary report of the president collection,\n                   only shows field-level information for field_id 3.\n\ngristle_dir_merger\n==================\n\n::\n\n   Gristle_dir_merger consolidates directory structures of files.  Is both fast\n   and flexible with a variety of options for choosing which file to use based\n   on full (name and md5) and partial matches (name only) .\n\n   Examples\n      $ gristle_dir_merger --source-dir /tmp/foo --dest-dir /data/foo\n            - Compares source of /tmp/foo to dest of /data/foo.\n            - Files will be consolidated into /data/foo, and deleted from /tmp/foo.\n            - Comparison will be: match-on-name-and-md5 (default)\n            - Full matches will use: keep_dest (default)\n            - Partial matches will use: keep_newest (default)\n            - Bottom line: this is what you normally want.\n      $ gristle_dir_merger --source-dir /tmp/foo --dest-dir /data/foo --dry-run\n            - Same as the first example - except it only prints what it would do\n              without actually doing it.\n            - Bottom line: this is a good step to take prior to running it for real.\n      $ gristle_dir_merger --source-dir /tmp/foo --dest-dir /data/foo -r\n            - Same as the first example - except it runs recursively through\n              the directories.\n      $ gristle_dir_merger --source-dir /tmp/foo --dest-dir /data/foo \n        --on-partial-match keep-biggest\n            - Comparison will be: match-on-name-and-md5 (default)\n            - Full matches will use: keep_dest (default)\n            - Partial matches will use: keep_biggest (override)\n            - Bottom line: this is a good combo if you know that some files\n              have been modified on both source & dest, and newest isn't the best.\n      $ gristle_dir_merger --source-dir /tmp/foo --dest-dir /data/foo \n        --match-on name_only --on-full-match keep-source\n            - Comparison will be: match-on-name-only (override)\n            - Full matches will use: keep_source (override)\n            - Bottom line: this is a good way to go if you have\n              files that have changed in both directories, but always want to\n              use the source files.\n\nLicensing\n=========\n\n-  Gristle uses the BSD license - see the separate LICENSE file for\n   further information\n\nCopyright\n=========\n\n-  Copyright 2011-2021 Ken Farmer\n\n\nV0.2.3 - 2022-11\n================\n\n-  Improvement: gristle_slicer - add support for writing data out in the\n   config order rather than the data order, as well as negative,\n   positive and random stepping.\n-  BREAKING CHANGE: refactored gristle_validator:\n\n   -  added examples\n   -  improved error reporting\n   -  replaced obsolete customized jsonschema version with support for\n      the current version (Draft 7)\n\n-  BREAKING CHANGE: Removed gristle_processor.\n-  BREAKING CHANGE: envvar and config file boolean args with values\n   other than True, true, t, or 1 will be rejected. This is because they\n   can be very ambiguous and confusing, in particular with with a pair\n   of args like has-header and has-no-header.\n-  Improvement: crash reporting is now more consistent, complete and\n   informative\n-  Improvement: is now enforcing the minimum version of 3.8. It was\n   previously almost completely working on 3.7 but would occasionally\n   crash on a 3.8 feature.\n-  Improvement: replaced pyyaml with ruamel.yaml - to better support\n   config generation.\n-  Bug Fix: fixed pathing on two bash aliases: gristle_determinator &\n   gristle_file_converter\n-  Bug Fix: fixed bug in handling of obsolete options\n\nV0.2.2 - 2021-07\n================\n\n-  Improvement: the field-names from headers can now be used instead of\n   column offsets for gristle_sorter, gristle_freaker, gristle_profiler,\n   and gristle_slicer.\n-  Improvement: The use of the header now follows four simple rules:\n\n   -  It can be referred to as row 0 when it makes sense - like with\n      gristle_slicer & gristle_viewer.\n   -  It will be passed through when it makes sense - like with\n      gristle_sorter.\n   -  It will be used to translate field names to offsets for\n      configuration.\n   -  But will otherwise be ignored.\n\n-  Bug Fix: gristle_freaker was failing with 0-length files when using\n   col-type=each\n-  Bug Fix: gristle_sorter was failing with some multi-directional sorts\n\nV0.2.1 - 2021-04\n================\n\n-  Improvement: added gristle_sorter as a script to install in the\n   system so that it is available to users.\n\nV0.2.0 - 2021-04\n================\n\n-  Improvement: Now supports python versions 3.8 and 3.9.\n-  Improvement: All csv programs now support envvars and config files\n   for input and can generate config files.\n-  Improvement: Programs always autodetect file csv dialect before\n   applying user overrides - except for piped-in data.\n-  BREAKING CHANGE: dropped support for python version 3.7\n-  BREAKING CHANGES to all csv programs:\n\n   -  Various changes to names of options for consistency, with older\n      versions caught with an error msg to provides new name.\n   -  Various changes to csv dialect handling for consistency and\n      correct handling of escapechar, doublequoting, skipinitialspace.\n\nv0.1.7 - 2020-07\n================\n\n-  Improvement: now supports python versions 3.7 and 3.8\n-  BREAKING CHANGE: dropped support for python version 3.6\n-  Bumped versions on dependent modules to eliminate vulnerabilities\n-  gristle_differ\n\n   -  BREAKING CHANGE: col_names renamed to col-names for consistency\n   -  Fixes –already-unix option bug with file parsing\n   -  Fixes –stats bug with empty files\n   -  Improvement: added ability to use column names from file headers\n   -  Improvement: if a key-col is in the ignore-cols - it will simply\n      be ignored, and the program will continue processing.\n   -  Improvement: if a key-col is in the compare-cols - it will simply\n      be ignored, and the program will continue processing.\n   -  Improvement: if neither compare or ignore cols are provided it\n      will use all cols as compare-cols and continue processing.\n   -  Improvement: CLI help is updated to provide more details and\n      accurate examples of these options.\n\nv0.1.6 - 2019-02\n================\n\n-  upgraded to support python3.7\n\nv0.1.5 - 2018-05\n================\n\n-  fixed setup.py bug in which pip10 no longer includes req module\n\nv0.1.4 - 2017-12\n================\n\n-  fixed gristle_validator bug in which checks on dg_maximum were not\n   being run\n\nv0.1.3 - 2017-08\n================\n\n-  additional improvements to code quality, but with some breaking\n   changes\n-  changed argument handling for multiple utilities to simplify code and\n   get more consistency.\n\n   -  affects: gristle_freaker, gristle_slicer, and gristle_viewer\n   -  This means words are separated by hyphens, not underscores.\n      –sortorder is –sort-order.\n\n-  changed file handling for multiple utilities to simplify code and get\n   more consistency.\n\n   -  affects: gristle_freaker, gristle_slicer, gristle_validator, and\n      gristle_viewer\n   -  This means that behavior in handling multiple files, piped input,\n      and other edge cases is more consistent between utilities.\n\nv0.1.2 - 2017-06\n================\n\n-  long-overdue code quality updates\n\nv0.1.1 - 2017-05\n================\n\n-  upgraded to use python3.6\n-  changed versioning format, which has broken pypy for history\n\nv0.59 - 2016-11\n===============\n\n-  gristle_differ\n\n   -  totally rewritten. Can now handle very large files, perform\n      post-transform transformations, handle more complex comparisons,\n      and use column names rather than just positions.\n\n-  gristle_determinator\n\n   -  added read-limit argument. This allows the tool to be easily run\n      against a subset of a very large input file.\n\n-  gristle_scalar\n\n   -  removed from toolkit. There are better tools in other solutions\n      can be used instead. This tool may come back again later, but only\n      if enormously rewritten.\n\n-  gristle_filter\n\n   -  removed from toolkit. There are better tools in other solutions\n      can be used instead. This tool may come back again later, but only\n      if enormously rewritten.\n\n-  minor:\n\n   -  gristle_md_reporter - slight formatting change: text descriptions\n      of fields are now included, and column widths were tweaked.\n   -  all utilities - a substantial performance improvement for large\n      files when quoting information is not provided.\n\nv0.58 - 2014-08\n===============\n\n-  gristle_dir_merger\n\n   -  initial addition to toolkit. Merges directories of files using a\n      variety of matching criteria and matching actions.\n\nv0.57 - 2014-07\n===============\n\n-  gristle_processor\n\n   -  initial addition to toolkit. Provides ability to scan through\n      directory structure recursively, and delete files that match\n      config criteria.\n\nv0.56 - 2014-03\n===============\n\n-  gristle_determinator\n\n   -  added hasnoheader arg\n   -  fixed problem printing top_values on empty file with header\n\n-  gristle_validator\n\n   -  added hasnoheader arg\n\n-  gristle_freaker\n\n   -  added hasnoheader arg\n\nv0.55 - 2014-02\n===============\n\n-  gristle_determinator - fixed a few problems:\n\n   -  the ‘Top Values not shown - all unique’ message being truncated\n   -  floats not handled correctly for stddev & variance\n   -  quoted ints & floats not handled\n\nv0.54 - 2014-02\n===============\n\n-  gristle_validator - major updates to allow validation of csv files\n   based on the json schema standard, with help from the Validictory\n   module.\n\nv0.53 - 2014-01\n===============\n\n-  gristle_freaker - major updates to enable distributes on all columns\n   to be automatically gathered through either (all or each) args. ‘All’\n   combines all columns into a single tuple prior to producing\n   distribution. ‘Each’ creates a separate distribution for every column\n   within the csv file.\n-  travisci - added support and started using this testing service.",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "http://github.com/kenfar/DataGristle",
    "keywords": "data analysis quality utility etl",
    "license": "BSD",
    "maintainer": "",
    "maintainer_email": "",
    "name": "datagristle",
    "package_url": "https://pypi.org/project/datagristle/",
    "platform": null,
    "project_url": "https://pypi.org/project/datagristle/",
    "project_urls": {
      "Homepage": "http://github.com/kenfar/DataGristle"
    },
    "release_url": "https://pypi.org/project/datagristle/0.2.3/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "A toolbox and library of ETL, data quality, and data analysis tools",
    "version": "0.2.3",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 15742240,
  "releases": {
    "0.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "106c0719dab6e100f04bd3c96d64627b43f3eb3e08143d7b8d5329038206dda3",
          "md5": "685282908a8e2de76b9f510ff4173db7",
          "sha256": "9eb1b3a4d7fe6cb6bfb47a5083318447aba6216bf6c4e7cac87f63fed8682cf8"
        },
        "downloads": -1,
        "filename": "datagristle-0.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "685282908a8e2de76b9f510ff4173db7",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 429187,
        "upload_time": "2017-07-08T05:02:27",
        "upload_time_iso_8601": "2017-07-08T05:02:27.052024Z",
        "url": "https://files.pythonhosted.org/packages/10/6c/0719dab6e100f04bd3c96d64627b43f3eb3e08143d7b8d5329038206dda3/datagristle-0.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "526e30fcbddd36057086b54e7480c938de083dceb7ed9242679ed8186e2e08f4",
          "md5": "f8a375fcdb0a7bfb121c285e487cf5f2",
          "sha256": "c50c99fa243c7ed9981d861914f08b00651f797182750591b7c1892b2a74c340"
        },
        "downloads": -1,
        "filename": "datagristle-0.1.4.tar.gz",
        "has_sig": false,
        "md5_digest": "f8a375fcdb0a7bfb121c285e487cf5f2",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 429745,
        "upload_time": "2017-12-13T06:00:48",
        "upload_time_iso_8601": "2017-12-13T06:00:48.387511Z",
        "url": "https://files.pythonhosted.org/packages/52/6e/30fcbddd36057086b54e7480c938de083dceb7ed9242679ed8186e2e08f4/datagristle-0.1.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "41519bec9078451ba729799d9300bbc8a33a569ceeae7faf2d19ba2614f73620",
          "md5": "5e01a76994b4aceddcc5fa1be9c1dda8",
          "sha256": "c7337999447a9fefc905796ac3749ce8f511da1121990e4b57f798453ae8bd4d"
        },
        "downloads": -1,
        "filename": "datagristle-0.1.5.tar.gz",
        "has_sig": false,
        "md5_digest": "5e01a76994b4aceddcc5fa1be9c1dda8",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 434739,
        "upload_time": "2018-05-04T03:27:12",
        "upload_time_iso_8601": "2018-05-04T03:27:12.968305Z",
        "url": "https://files.pythonhosted.org/packages/41/51/9bec9078451ba729799d9300bbc8a33a569ceeae7faf2d19ba2614f73620/datagristle-0.1.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a0c43e1a1f6c9be5b285668c3f69a2c605a9559baf886f42e4161f12280b4b83",
          "md5": "07a1089e70ed17d8dd362c4f40ac820d",
          "sha256": "ee09f2425907506aa83ed0284216f93243a03e18a604b88ec17beacdfc6fd85d"
        },
        "downloads": -1,
        "filename": "datagristle-0.1.6.tar.gz",
        "has_sig": false,
        "md5_digest": "07a1089e70ed17d8dd362c4f40ac820d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 427481,
        "upload_time": "2019-02-28T04:56:22",
        "upload_time_iso_8601": "2019-02-28T04:56:22.504210Z",
        "url": "https://files.pythonhosted.org/packages/a0/c4/3e1a1f6c9be5b285668c3f69a2c605a9559baf886f42e4161f12280b4b83/datagristle-0.1.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "470f64ed393cbe130e0e4dbc1ee7f3dc129d79ae07fe59e96d0b7af87acdbe25",
          "md5": "e1bf75404f21d9f0a303874a2309c39d",
          "sha256": "c88c4c7e47ef7f40839653179dc05577d828fadefbb707224e42cdc98b19ea9f"
        },
        "downloads": -1,
        "filename": "datagristle-0.1.7.tar.gz",
        "has_sig": false,
        "md5_digest": "e1bf75404f21d9f0a303874a2309c39d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 430402,
        "upload_time": "2020-07-23T03:15:17",
        "upload_time_iso_8601": "2020-07-23T03:15:17.793267Z",
        "url": "https://files.pythonhosted.org/packages/47/0f/64ed393cbe130e0e4dbc1ee7f3dc129d79ae07fe59e96d0b7af87acdbe25/datagristle-0.1.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a95c08b80a8fe558738394a6eda4e69c02da79ad4699ccfe058ea7e69960556f",
          "md5": "60037206dc7d23ef611311521eb626ce",
          "sha256": "8ba09f23d7fb2885e8e546c0fb3131029a001c0422f9ea15760df32e1d18bbfe"
        },
        "downloads": -1,
        "filename": "datagristle-0.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "60037206dc7d23ef611311521eb626ce",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 435608,
        "upload_time": "2021-04-21T00:24:54",
        "upload_time_iso_8601": "2021-04-21T00:24:54.910785Z",
        "url": "https://files.pythonhosted.org/packages/a9/5c/08b80a8fe558738394a6eda4e69c02da79ad4699ccfe058ea7e69960556f/datagristle-0.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7425d73ec8f70b1ad758979e052af47ccb346028f7dd868b97a620be7fc34a63",
          "md5": "c7d65069be734f4ac7d023ce5cfb44b2",
          "sha256": "ef426cbb03a25f6e31621a0af5249bcb57218f76197638a285c449c748d9937e"
        },
        "downloads": -1,
        "filename": "datagristle-0.2.1.tar.gz",
        "has_sig": false,
        "md5_digest": "c7d65069be734f4ac7d023ce5cfb44b2",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 436656,
        "upload_time": "2021-04-21T01:26:26",
        "upload_time_iso_8601": "2021-04-21T01:26:26.611214Z",
        "url": "https://files.pythonhosted.org/packages/74/25/d73ec8f70b1ad758979e052af47ccb346028f7dd868b97a620be7fc34a63/datagristle-0.2.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3aa20c2f7b765b1dfe78cabec451797abbb89ed0833d85931ad28035a2def3fd",
          "md5": "706c86f42d13700f9500bc622c70c33b",
          "sha256": "4d6094ad7431c29b53a0a96176cbe8d7192538650cbd8fa915bf7cfd261c14e0"
        },
        "downloads": -1,
        "filename": "datagristle-0.2.2.tar.gz",
        "has_sig": false,
        "md5_digest": "706c86f42d13700f9500bc622c70c33b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 443671,
        "upload_time": "2021-05-20T03:36:50",
        "upload_time_iso_8601": "2021-05-20T03:36:50.060043Z",
        "url": "https://files.pythonhosted.org/packages/3a/a2/0c2f7b765b1dfe78cabec451797abbb89ed0833d85931ad28035a2def3fd/datagristle-0.2.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5a44885c3d6a3a4f0e332ca6ba697bbd94dffb8607b9df796ace3aa5aec9e526",
          "md5": "248957872bcd6685ee09eb0d7f382647",
          "sha256": "f3b5a0e725ef7d1946d14414205a7ba72fbdaa97031f697f46e4b6777c2b4273"
        },
        "downloads": -1,
        "filename": "datagristle-0.2.3.tar.gz",
        "has_sig": false,
        "md5_digest": "248957872bcd6685ee09eb0d7f382647",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 459371,
        "upload_time": "2022-11-12T04:45:58",
        "upload_time_iso_8601": "2022-11-12T04:45:58.400469Z",
        "url": "https://files.pythonhosted.org/packages/5a/44/885c3d6a3a4f0e332ca6ba697bbd94dffb8607b9df796ace3aa5aec9e526/datagristle-0.2.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "5a44885c3d6a3a4f0e332ca6ba697bbd94dffb8607b9df796ace3aa5aec9e526",
        "md5": "248957872bcd6685ee09eb0d7f382647",
        "sha256": "f3b5a0e725ef7d1946d14414205a7ba72fbdaa97031f697f46e4b6777c2b4273"
      },
      "downloads": -1,
      "filename": "datagristle-0.2.3.tar.gz",
      "has_sig": false,
      "md5_digest": "248957872bcd6685ee09eb0d7f382647",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 459371,
      "upload_time": "2022-11-12T04:45:58",
      "upload_time_iso_8601": "2022-11-12T04:45:58.400469Z",
      "url": "https://files.pythonhosted.org/packages/5a/44/885c3d6a3a4f0e332ca6ba697bbd94dffb8607b9df796ace3aa5aec9e526/datagristle-0.2.3.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}