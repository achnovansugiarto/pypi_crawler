{
  "info": {
    "author": "Tatu Ylonen",
    "author_email": "ylo@clausal.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Developers",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: MIT License",
      "Natural Language :: English",
      "Operating System :: OS Independent",
      "Operating System :: POSIX :: Linux",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3 :: Only",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Topic :: Text Processing",
      "Topic :: Text Processing :: Linguistic"
    ],
    "description": "# Wiktextract\n\nThis is a utility and Python package for for extracing data from Wiktionary.\n\n*2021-09-20: Version 1.99.6 is now on pypi and available for installation using\n  pip (Python3).  Think of it as a beta version for 2.0.0.  There is\n  also a new version of wikitextprocessor.*\n\nPlease report issues on github and I'll try to address them reasonably\nsoon.\n\nThe current extracted version is available for browsing and download\nat: [https://kaikki.org/dictionary/](http://kaikki.org/dictionary/).\nI plan to maintain an automatically updating version of the data at\nthis location.  For most people the preferred way to get the extracted\nWiktionary data will be to just take it from the web site.\n\nNote: extracting all data for all languages from the English\nWiktionary may take from an hour to several days, depending\non your computer.  Expanding Lua modules is not cheap, but it enables\nsuperior extraction quality and maintainability! You may want to look\nat the pre-expanded downloads instead of running it yourself.\n\n## Overview\n\nThis is a Python package and tool for extracting information from\nEnglish Wiktionary (enwiktionary) data dumps.  Note that the English\nWiktionary contains extensive dictionaries and inflectional\ninformation for many languages, not just English.  Only its glosses\nand internal tagging are in English.\n\nOne thing that distinguishes this tool from any system I'm aware of is\nthat this tool expands templates and Lua macros in Wiktionary.  That\nenables much more accurate rendering and extraction of glosses, word\nsenses, inflected forms, and pronunciations.  It also makes the system\nmuch easier to maintain.  All this results in much higher extraction\nquality and accuracy.\n\nThis tool extracts glosses, parts-of-speech, declension/conjugation\ninformation when available, translations for all languages when\navailable, pronunciations (including audio file links), qualifiers\nincluding usage notes, word forms, links between words including\nhypernyms, hyponyms, holonyms, meronyms, related words, derived terms,\ncompounds, alternative forms, etc.  Links to Wikipedia pages, Wikidata\nidentifiers, and other such data are also extracted when available.\nFor many classes of words, a word sense is annotated with specific\ninformation such as what word it is a form of, what is the RGB value\nof the color it represents, what is the numeric value of a number,\nwhat SI unit it represents, etc.\n\nThis tool extracts information for all languages that have data in the\nEnglish wiktionary.  It also extracts translingual data and\ninformation about characters (anything that has an entry in Wiktionary).\n\nThis tool reads the ``enwiktionary-<date>-pages-articles.xml.bz2``\ndump file and outputs JSON-format dictionaries containing most of the\ninformation in Wiktionary.  The dump files can be downloaded from\nhttps://dumps.wikimedia.org.\n\nThis utility will be useful for many natural language processing,\nsemantic parsing, machine translation, and language generation\napplications both in research and industry.\n\nThe tool can be used to extract machine translation dictionaries,\nlanguage understanding dictionaries, semantically annotated\ndictionaries, and morphological dictionaries with\ndeclension/conjugation information (where this information is\navailable for the target language).  Dozens of languages have\nextensive vocabulary in ``enwiktionary``, and several thousand\nlanguages have partial coverage.\n\nThe ``wiktwords`` script makes extracting the information for use by\nother tools trivial without writing a single line of code.  It\nextracts the information specified by command options for languages\nspecified on the command line, and writes the extracted data to a file\nor standard output in JSON format for processing by other tools.\n\nWhile there are currently no active plans to support parsing\nnon-English wiktionaries, I'm considering it.  Now that this builds on\n[wikitextprocessor](https://github.com/tatuylonen/wikitextprocessor/)\nand expands templates and Lua macros, it would be fairly\nstraightforward to build support for other languages too - and even\nmake the extraction configurable so that only a configuration file\nwould need to be created for processing a Wiktionary in a new\nlanguage.\n\nAs far as we know, this is the most comprehensive tool available for\nextracting information from Wiktionary as of December 2020.\n\nIf you find this tool and/or the pre-extracted data helpful, please\ngive this a star on github!\n\n## Pre-extracted data\n\nFor most people, it may be easiest to just download pre-expanded data.\nPlease see\n[https://kaikki.org/dictionary/rawdata.html](https://kaikki.org/dictionary/rawdata.html).\nThe raw wiktextract data, extracted category tree, extracted templates\nand modules, as well as a bulk download of audio files for\npronunciations in both <code>.ogg</code> and <code>.mp3</code> formats\nare available.\n\nThere is a also download link at the bottom of every page and a button\nto view the JSON produced for each page.  You can download all data,\ndata for a specific language, data just a single word, or data for a\nlist of related words (e.g., a particular part-of-speech or words\nrelating to a particular topic or having a particular inflectional\nform).  All downloads are in JSON format (each line is a separate JSON\nobject).  The bigger downloads are also available in compressed form.\n\nSome people have asked for the full data as a single JSON object\n(instead of the current one JSON object per line format).  I've\ndecided to keep it as a JSON object per line, because loading all the\ndata into Python requires about 120 GB of memory.  It is much easier to\nprocess the data line-by-line, especially if you are only interested\nin a part of the information.  You can easily read the files using the\nfollowing code:\n```\nimport json\n...\nwith open(\"filename.json\", \"r\", encoding=\"utf-8\") as f:\n    for line in f: data = json.loads(line)\n        ... parse the data in this record\n```\n\nIf you want to collect all the data into a list, you can read the file\ninto a list with:\n```\nimport json\n...\nlst = []\nwith open(\"filename.json\", \"r\", encoding=\"utf-8\") as f:\n    for line in f:\n        data = json.loads(line)\n        lst.append(data)\n```\n\nYou can also easily pretty-print the data into a more human-readable form using:\n```\nprint(json.dumps(data, indent=2, sort_keys=True))\n```\n\nHere is a pretty-printed example of an extracted word entry for the\nword ``thrill`` as an English verb (only one part-of-speech is shown here):\n```\n{\n  \"categories\": [\n    \"Emotions\"\n  ],\n  \"derived\": [\n    {\n      \"word\": \"enthrill\"\n    }\n  ],\n  \"forms\": [\n    {\n      \"form\": \"thrills\",\n      \"tags\": [\n        \"present\",\n        \"simple\",\n        \"singular\",\n        \"third-person\"\n      ]\n    },\n    {\n      \"form\": \"thrilling\",\n      \"tags\": [\n        \"present\"\n      ]\n    },\n    {\n      \"form\": \"thrilled\",\n      \"tags\": [\n        \"participle\",\n        \"past\",\n        \"simple\"\n      ]\n    }\n  ],\n  \"head_templates\": [\n    {\n      \"args\": {},\n      \"expansion\": \"thrill (third-person singular simple present thrills, present participle thrilling, simple past and past participle thrilled)\",\n      \"name\": \"en-verb\"\n    }\n  ],\n  \"lang\": \"English\",\n  \"lang_code\": \"en\",\n  \"pos\": \"verb\",\n  \"senses\": [\n    {\n      \"glosses\": [\n        \"To suddenly excite someone, or to give someone great pleasure; to electrify; to experience such a sensation.\"\n      ],\n      \"tags\": [\n        \"ergative\",\n        \"figuratively\"\n      ]\n    },\n    {\n      \"glosses\": [\n        \"To (cause something to) tremble or quiver.\"\n      ],\n      \"tags\": [\n        \"ergative\"\n      ]\n    },\n    {\n      \"glosses\": [\n        \"To perforate by a pointed instrument; to bore; to transfix; to drill.\"\n      ],\n      \"tags\": [\n        \"obsolete\"\n      ]\n    },\n    {\n      \"glosses\": [\n        \"To hurl; to throw; to cast.\"\n      ],\n      \"tags\": [\n        \"obsolete\"\n      ]\n    }\n  ],\n  \"sounds\": [\n    {\n      \"ipa\": \"/\\u03b8\\u0279\\u026al/\"\n    },\n    {\n      \"ipa\": \"[\\u03b8\\u027e\\u032a\\u030a\\u026a\\u026b]\",\n      \"tags\": [\n        \"UK\",\n        \"US\"\n      ]\n    },\n    {\n      \"ipa\": \"[\\u03b8\\u027e\\u032a\\u030a\\u026al]\",\n      \"tags\": [\n        \"Ireland\"\n      ]\n    },\n    {\n      \"ipa\": \"[t\\u032a\\u027e\\u032a\\u030a\\u026al]\",\n      \"tags\": [\n        \"Ireland\"\n      ]\n    },\n    {\n      \"rhymes\": \"-\\u026al\"\n    },\n    {\n      \"audio\": \"en-us-thrill.ogg\",\n      \"mp3_url\": \"https://upload.wikimedia.org/wikipedia/commons/transcoded/d/db/En-us-thrill.ogg/En-us-thrill.ogg.mp3\",\n      \"ogg_url\": \"https://upload.wikimedia.org/wikipedia/commons/d/db/En-us-thrill.ogg\",\n      \"tags\": [\n        \"US\"\n      ],\n      \"text\": \"Audio (US)\"\n    }\n  ],\n  \"translations\": [\n    {\n      \"code\": \"nl\",\n      \"lang\": \"Dutch\",\n      \"sense\": \"suddenly excite someone, or to give someone great pleasure; to electrify\",\n      \"word\": \"opwinden\"\n    },\n    {\n      \"code\": \"fi\",\n      \"lang\": \"Finnish\",\n      \"sense\": \"suddenly excite someone, or to give someone great pleasure; to electrify\",\n      \"word\": \"syk\\u00e4hdytt\\u00e4\\u00e4\"\n    },\n    {\n      \"code\": \"fi\",\n      \"lang\": \"Finnish\",\n      \"sense\": \"suddenly excite someone, or to give someone great pleasure; to electrify\",\n      \"word\": \"riemastuttaa\"\n    },\n...\n    {\n      \"code\": \"tr\",\n      \"lang\": \"Turkish\",\n      \"sense\": \"slight quivering of the heart that accompanies a cardiac murmur\",\n      \"word\": \"\\u00e7arp\\u0131nt\\u0131\"\n    }\n  ],\n  \"wikipedia\": [\n    \"thrill\"\n  ],\n  \"word\": \"thrill\"\n}\n```\n\n## Getting started\n\n### Installing\n\nPreparation: on Linux (example from Ubuntu 20.04), you may need to\nfirst install the ``build-essential`` and ``python3-dev`` packages\nwith ``apt update && apt install build-essential python3-dev python3-pip``.\n\nTo install ``wiktextract``, use ``pip`` (or ``pip3``, as appropriate):\n```\npip3 install wiktextract\n```\n\nAlternatively, you can get the latest development version from github:\n\n```\ngit clone https://github.com/tatuylonen/wiktextract.git\ncd wiktextract && pip3 install -r requirements.txt && pip3 install -e .\n```\n\nThis will install the ``wiktextract`` package and the ``wiktwords`` script.\n\nThis software requires Python 3.\n\n### Running tests\n\nThis package includes tests written using the ``unittest`` framework.\nThey can be run using, for example, ``nose``, which can be installed\nusing ``pip3 install nose``.\n\nTo run the tests, just use the following command in the top-level directory:\n```\nnosetests\n```\n\n(Unfortunately the test suite for ``wiktextract`` is not yet very\ncomprehensive.  The underlying lower-level toolkit,\n``wikitextprocessor``, has much more extensive test coverage.)\n\n### Expected performance\n\nExtracting all data for all languages from English Wiktionary takes\nabout 1.25 hours on a 128-core dual AMD EPYC 7702 system.  The\nperformance is expected to be approximately linear with the number of\nprocessor cores, provided you have enough memory (about 10GB/core or\n5GB/hyperthread recommended).\n\nYou can control the number of parallel processes to use with the\n``--num-threads`` option; the default on Linux is to use the number of\navailable cores/hyperthreads.  On Windows and MacOS, ``--num-threads``\nshould currently be set to 1 (default on those systems). We don't\nreally recommend using Windows or Mac for the extraction, because it\nwill be very slow.  Extracting only a few languages or a subset of the data\nwill be faster.\n\nYou can download the full pre-extracted data from\n[kaikki.org](https://kaikki.org/dictionary/). The pre-extraction is\nupdated regularly with the latest Wiktionary dump.  Using the\npre-extracted data may be the easiest option unless you have special\nneeds or want to modify the code.\n\n## Using the command-line tool\n\nThe ``wiktwords`` script is the easiest way to extract data from\nWiktionary.  Just download the data dump file from\n[dumps.wikimedia.org](https://dumps.wikimedia.org/enwiktionary/) and\nrun the script.  The correct dump file the name\n``enwiktionary-<date>-pages-articles.xml.bz2``.\n\nAn example of a typical invocation for extracting all data would be:\n```\nwiktwords --all --all-languages --out data.json enwiktionary-20201201-pages-articles.xml.bz2\n```\n\nIf you wish to modify the code or test processing individual pages,\nthe following may also be useful:\n\n1. To extract all pages from Wiktionary into separate files under\n``pages/`` and to create a cache file that you can use for quickly\nprocessing individual pages:\n```\nwiktwords --cache /tmp/wikt-cache --pages-dir pages enwiktionary-20201201-pages-articles.xml.bz2\n```\n\n2. To process a single page, processing a human-readable output file\nfor debugging:\n```\nwiktwords --cache /tmp/wikt-cache --all --all-languages --out outfile --page pages/Words/di/dictionary.txt\n```\n\nThe following command-line options can be used to control its operation:\n\n* --out FILE: specifies the name of the file to write (specifying \"-\" as the file writes to stdout)\n* --all-languages: extract words for all available languages\n* --language LANGUAGE: extracts the given language (this option may be specified multiple times; by default, English and Translingual words are extracted)\n* --list-languages: prints a list of supported language names\n* --all: causes all data to be captured for the selected languages\n* --translations: causes translations to be captured\n* --pronunciation: causes pronunciation information to be captured\n* --linkages: causes linkages (synonyms etc.) to be captured\n* --examples: causes usage examples to be captured\n* --etymologies: causes etymology information to be captured\n* --inflections: causes inflection tables to be captured\n* --redirects: causes redirects to be extracted\n* --pages-dir DIR: save all wiktionary pages under this directory (mostly for debugging)\n* --cache CACHE: save/use cache file(s) from this path (for debugging)\n* --page FILE: read page from file (first line can be \"TITLE: pagetitle\"; file should use UTF-8 encoding)\n* --num-threads THREADS: use this many parallel processes (needs 4GB/process)\n* --human-readable: print human-readable JSON with indentation (no longer\nmachine-readable)\n* --override PATH: override a page or Lua module by this file (first line should be TITLE: pagetitle)\n* --templates-file: extract Template namespace to this tar file\n* --modules-file: extract Module namespace to this tar file\n* --categories-file: extract Wiktionary category tree into this file as JSON (see description below)\n* --help: displays help text (with some more options than listed here)\n\n## Calling the library\n\nWhile this package has been mostly intended to be used using the ``wiktwords``\nprogram, it is also possible to call this as a library.  Underneath, this uses\nthe ``wikitextprocessor`` module.\n\nThis code can be called from an application as follows:\n\n```\nfrom wiktextract import (WiktionaryConfig, parse_wiktionary, parse_page,\n                         PARTS_OF_SPEECH)\nfrom wikitextprocessor import Wtp, ALL_LANGUAGES\n\nconfig = WiktionaryConfig(\n             capture_languages=[\"English\", \"Translingual\"],\n             capture_translations=True,\n             capture_pronunciation=True,\n             capture_linkages=True,\n             capture_compounds=True,\n             capture_redirects=True,\n             capture_examples=True,\n             capture_etymologies=True,\n             capture_inflections=True)\nctx = Wtp()\n\ndef word_cb(data):\n    # data is dictionary containing information for one word/redirect\n    ... do something with data\n\nparse_wiktionary(ctx, path, config, word_cb)\n```\n\nThe capture arguments default to ``True``, so they only need to be set if\nsome values are not to be captured (note that the ``wiktwords``\nprogram sets them to ``False`` unless the ``--all`` or specific capture\noptions are used).\n\n#### def parse_wiktionary(ctx, path, config, word_cb, capture_cb=None, phase1_only=False)\n\nThe ``parse_wiktionary`` function will call ``word_cb(data)`` for\nwords and redirects found in the Wiktionary dump.  ``data`` is\ninformation about a single word and part-of-speech as a dictionary and\nmay include several word senses.  It may also be a redirect (indicated\nby the presence of a \"redirect\" key in the dictionary).  It is in the same\nformat as the JSON-formatted dictionaries returned by the\n``wiktwords`` tool.\n\nIts arguments are as follows:\n* ``ctx`` (Wtp) - a\n  [wikitextprocessor](https://github.com/tatuylonen/wikitextprocessor/)\n  processing context.  The number of parallel processes to use can be\n  given as the ``num_threads`` argument to the constructor, and a cache file\n  path can be provided as the ``cache_file`` argument.\n* ``path`` (str) - path to a Wiktionary dump file (*-pages-articles.xml.bz2)\n* ``config`` (WiktionaryConfig) - a configuration object describing what to\n  exctract (see below)\n* ``word_cb`` (function) - this function will be called for every word\n  extracted from Wiktionary.  The argument is a dictionary.  Typically it\n  will be called once for each word form and part-of-speech (each time there\n  may be more than one word sense under \"senses\").  See below for a description\n  of the dictionary.\n* ``capture_cb`` (function) - this can be ``None`` or a function to be\n  called as ``capture_cb(model, title, text)`` for every page before\n  extracting any words from it.  It can be used to extract raw pages\n  to disk.  The ``model`` argument is ``wikitext`` for normal pages,\n  ``Scribunto`` for Lua modules, and ``redirect`` for redirects (other\n  values are also possible).  ``title`` is page title and ``text`` is\n  page content or page title to redirect to.\n* ``phase1_only`` - if this is set to ``True``, then only a cache file will\n  be created but no extraction will take place.  In this case the ``Wtp``\n  constructor should probably be given the ``cache_file`` argument when\n  creating ``ctx``.\n\nThis call gathers statistics in ``config``.  This function will automatically\nparallelize the extraction.  ``page_cb`` will be called in the parent process,\nhowever.\n\n#### def parse_page(ctx, title, text, config)\n\nThis function parses ``text`` as if it was a Wiktionary page with the\ntitle ``title``.  The arguments are:\n* ``ctx`` (Wtp) - a ``wikitextprocessor`` context\n* ``title`` (str) - the title to use for the page\n* ``text`` (str) - contents of the page (wikitext)\n* ``config`` (WiktionaryConfig) - specifies what to capture and is also used\n  for collecting statistics\n\n#### PARTS_OF_SPEECH\n\nThis is a constant set of all part-of-speech values (``pos`` key) that\nmay occur in the extracted data.  Note that the list is somewhat larger than\nwhat a conventional part-of-speech list would be.\n\n### class WiktionaryConfig(object)\n\nThe ``WiktionaryConfig`` object is used for specifying what data to collect\nfrom Wiktionary and is also used for collecting statistics during\nextraction.\n\nThe constructor is called as:\n```\nWiktionaryConfig(capture_languages=[\"English\", \"Translingual\",\n                 capture_translations=True,\n                 capture_pronunciation=True,\n                 capture_linkages=True,\n                 capture_compounds=True,\n                 capture_redirects=True,\n                 capture_examples=True,\n                 capture_etymologies=True,\n                 capture_inflections=True)\n```\n\nThe arguments are as follows:\n* ``capture_languages`` (list/tuple/set of strings) - names of\n  languages for which to capture data.  It defaults to ``[\"English\",\n  \"Translingual\"]``.  To capture all languages, one can use\n  ``set(x[\"name\"] for x in ALL_LANGUAGES)`` (with ``ALL_LANGUAGES``\n  imported from wikitextprocessor).\n* ``capture_translations`` (boolean) - set to ``False`` to disable capturing\n  translations.  Translation information seems to be most\n  widely available for the English language, which has translations into\n  other languages.\n* ``capture_pronunciation`` (boolean) - set to ``False`` to disable\n  capturing pronunciations.  Typically, pronunciations include\n  IPA transcriptions and any audio files included in the word entries, along\n  with other information (including dialectal tags).  The type and amount of\n  pronunciation information varies widely between languages.\n* ``capture_linkages`` (boolean) - set to ``False`` to disable capturing\n  linkages between word, such as hypernyms, antonyms, synonyms, etc.\n* ``capture_compounds`` (boolean) - set to ``False`` to disable capturing\n  compound words containing the word.  Compound word capturing is not currently\n  fully implemented.\n* ``capture_redirects`` (boolean) - set to ``False`` to disable capturing\n  redirects.  Redirects are not associated with any specific language\n  and thus requesting them returns them for all words in all languages.\n* ``capture_examples`` (boolean) - set to ``False`` to disable\n  capturing usage examples.\n* ``capture_etymologies`` (boolean) - set to ``False`` to\n  disable capturing etymologies.\n* ``capture_inflections`` (boolean) - set to ``False`` to\n  disable capturing inflection tables.\n\n## Format of extracted redirects\n\nSome pages in Wiktionary are redirects.  For these, ``word_cb`` will\nbe called with data in a special format.  In this case, the dictionary\nwill have a ``redirect`` key, which will contain the page title that\nthe entry redirects to.  The ``title`` key contains the word/term that\ncontains the redirect.  Redirect entries do not have ``pos`` or any of\nthe other fields.  Redirects also are not associated with any\nlanguage, so all redirects are always returned regardless of the\ncaptured languages (if extracting redirects has been requested).\n\n## Format of the extracted word entries\n\nInformation returned for each word is a dictionary.  The dictionary has the\nfollowing keys (others may also be present or added later):\n\n* ``word`` - the word form\n* ``pos`` - part-of-speech, such as \"noun\", \"verb\", \"adj\", \"adv\", \"pron\", \"determiner\", \"prep\" (preposition), \"postp\" (postposition), and many others.  The complete list of possible values returned by the package can be found in ``wiktextract.PARTS_OF_SPEECH``.\n* ``lang`` - name of the language this word belongs to (e.g., ``English``)\n* ``lang_code`` - Wiktionary language code (e.g., ``en``)\n* ``senses`` - list of word senses (dictionaries) for this word/part-of-speech (see below)\n* ``forms`` - list of inflected or alternative forms specified for the word (e.g., plural, comparative, superlative, roman script version).  This is a list of dictionaries, where each dictionary has a ``form`` key and a ``tags`` key.  The ``tags`` identify what type of form it is.  It may also contain \"ipa\", \"roman\", and \"source\" fields.  The form can be \"-\" when the word is marked as not having that form (some of those will be word-specific, while others are language-specific; post-processing can drop such forms when no word has a value for that tag combination).\n* ``sounds`` - list of dictionaries containing pronunciation, hyphenation, rhyming, and related information.  Each dictionary may have a ``tags`` key containing tags that clarify what kind of form that entry is.  Different types of information are stored in different fields: ``ipa`` is [IPA](https://en.wikipedia.org/wiki/International_Phonetic_Alphabet) pronunciation, ``enPR`` is [enPR](https://en.wikipedia.org/wiki/Pronunciation_respelling_for_English) pronunciation, ``audio`` is name of sound file in Wikimedia commons.\n* ``categories`` - list of non-disambiguated categories for the word\n* ``topics`` - list of non-disambiguated topics for the word\n* ``translations`` - non-disambiguated translation entries (see below)\n* ``etymology_text`` - etymology section as cleaned text\n* ``etymology_templates`` - templates and their arguments and expansions from\n  the etymology section.  These can be used to easily parse etymological\n  relations.  Certain common templates that do not signify etymological\n  relations are not included.\n* ``synonyms`` - non-disambiguated synonym linkages for the word (see below)\n* ``antonyms`` - non-disambiguated antonym linkages for the word (see below)\n* ``hypernyms`` - non-disambiguated hypernym linkages for the word (see below)\n* ``holonyms`` - non-disambiguated linkages indicating being part of something (see below) (not systematically encoded)\n* ``meronyms`` - non-disambiguated linkages indicating having a part (see below) (fairly rare)\n* ``derived`` - non-disambiguated derived word linkages for the word (see below)\n* ``related`` - non-disambiguated related word linkages for the word (see below)\n* ``coordinate_terms`` - non-disambiguated coordinate term linkages for the word (see below)\n* ``wikidata`` - non-disambiguated Wikidata identifer\n* ``wiktionary`` - non-disambiguated page title in Wikipedia (possibly prefixed by language id)\n* ``head_templates``: part-of-speech specific head tags for the word.  This basically just captures the templates (their name and arguments) as a list of dictionaries.  Most applications may want to ignore this.\n* ``inflection_templates`` - conjugation and declension templates found for the word, as dictionaries.  These basically capture the language-specific inflection template for the word.  Note that for some languages inflection information is also contained in ``head_templates``.  XXX in the very near future, we will start parsing inflections from the inflection tables into ``forms``, so there is usually no need to use the ``inflection_templates`` data.\n\nThere may also be other fields.\n\nNote that several of the field on the word entry level indicate\ninformation that has not been sense-disambiguated.  Such information\nmay apply to one or more of the senses.  Currently only the most\ntrivial cases are disambiguated; however, it is anticipated that more\ndisambiguation may be performed in the future.  It is also possible\nfor the same key to be provided in a sense and in the word entry; in\nthat case, the data in the sense has been sense-disambiguated and the\ndata in the word entry has not (and may not be apply to any particular\nsense, regardless of whether the sense has some related\nsense-disambiguated information).\n\n### Word senses\n\nEach word entry may have multiple glosses under the ``senses`` key.  Each\nsense is a dictionary that may contain the following keys (among others, and more may be added in the future):\n\n* ``glosses`` - list of gloss strings for the word sense (usually only one).  This has been cleaned, and should be straightforward text with no tagging.\n* ``raw_glosses`` - list of gloss strings for the word sense, with less cleaning than ``glosses``.  In particular, parenthesized parts that have been parsed from the gloss into ``tags`` and ``topics`` are still present here.  This version may be easier for humans to interpret.\n* ``tags`` - list of qualifiers and tags for the gloss.  This is a list of strings, and may include words such as \"archaic\", \"colloquial\", \"present\", \"participle\", \"plural\", \"feminine\", and many others (new words may appear arbitrarily).\n* ``categories`` - list of sense-disambiguated category names extracted from (a subset) of the Category links on the page\n* ``topics`` - list of sense-disambiguated topic names (kind of similar to categories but determined differently)\n* ``alt_of`` - list of words that his sense is an alternative form of; this is a list of dictionaries, with field ``word`` containing the linked word and optionally ``extra`` containing additional text\n* ``form_of`` - list of words that this sense is an inflected form of; this is a list of dictionaries, with field ``word`` containing the linked word and optionally ``extra`` containing additional text\n* ``translations`` - sense-disambiguated translation entries (see below)\n* ``synonyms`` - sense-disambiguated synonym linkages for the word (see below)\n* ``antonyms`` - sense-disambiguated antonym linkages for the word (see below)\n* ``hypernyms`` - sense-disambiguated hypernym linkages for the word (see below)\n* ``holonyms`` - sense-disambiguated linkages indicating being part of something (see below) (not systematically encoded)\n* ``meronyms`` - sense-disambiguated linkages indicating having a part (see below) (fairly rare)\n* ``coordianate_terms`` - sense-disambiguated coordinate_terms linkages (see below)\n* ``derived`` - sense-disambiguated derived word linkages for the word (see below)\n* ``related`` - sense-disambiguated related word linkages for the word (see below)\n* ``senseid`` - list of textual identifiers collected for the sense.  If there is a QID for the entry (e.g., Q123), those are stored in the ``wikidata`` field.\n* ``wikidata`` - list of QIDs (e.g., Q123) for the sense\n* ``wikipedia`` - list of Wikipedia page titles (with optional language code prefix)\n* ``examples`` - list of usage examples, each example being a dictionary with ``text`` field containing the example text, optional ``ref`` field containing a source reference, optional ``english`` field containing English translation, optional ``type`` field containing example type (currently ``example`` or ``quotation`` if present), optional ``roman`` field containing romanization (for some languages written in non-Latin scripts), and optional (rare) ``note`` field contains English-language parenthesized note from the beginning of a non-english example.\n* ``english`` - if the word sense has a qualifier that could not be parsed, that qualifier is put in this field (rare).  Most qualifiers parsed into ``tags`` and/or ``topics``.  The gloss with the qualifier still present can be found in ``raw_glosses``.\n\n### Pronunciation\n\nPronunciation information is stored under the ``sounds`` key.  It is a\nlist of dictionaries, each of which may contain the following keys,\namong others:\n\n* ``ipa`` - pronunciation specifications as an IPA string /.../ or [...]\n* ``enpr`` - pronunciation in English pronunciation respelling\n* ``audio`` - name of a sound file in WikiMedia Commons\n* ``ogg_url`` - URL for an OGG Vorbis format sound file\n* ``mp3_url`` - URL for an MP3 format sound file\n* ``audio-ipa`` - IPA string associated with the audio file, generally giving IPA transcription of what is in the sound file\n* ``homophones`` - list of homophones for the word\n* ``hyphenation`` - list of hyphenations\n* ``tags`` - other labels or context information attached to the pronunciation entry (e.g., might indicate regional variant or dialect)\n* ``text`` - text associated with an audio file (often not very useful)\n\nNote that Wiktionary audio files are available for bulk download at\n[https://kaikki.org/dictionary/rawdata.html](https://kaikki.org/dictionary/rawdata.html).\nFiles in the download are named with the last component of the URL in\n``ogg_url`` and/or ``mp3_url``.  Downloading them individually takes\nserveral days and puts unnecessary load on Wikimedia servers.\n\n### Translations\n\nTranslations are stored under the ``translations`` key in the word's\ndata (if not sense-disambiguated) or in the word sense (if\nsense-disambiguated).  They are stored in a list of dictionaries,\nwhere each dictionary has the following keys (and possibly others):\n\n* ``alt`` - optional alternative form of the translation (e.g., in a different script)\n* ``code`` - Wiktionary's 2 or 3-letter language code for the language the translation is for\n* ``english`` - English text, generally clarifying the target sense of the translation\n* ``lang``  the language name that the translation is for\n* ``note`` - optional text describing or commenting on the translation\n* ``roman`` - optional romanization of the translation (when in non-Latin characters)\n* ``sense`` - optional sense indicating the meaning for which this is a translation (this is a free-text string, and may not match any gloss exactly)\n* ``tags`` - optional list of qualifiers for the translations, e.g., gender\n* ``taxonomic`` - optional taxonomic name of an organism mentioned in the translation\n* ``word`` - the translation in the specified language (may be missing when ``note`` is present)\n\n### Etymologies\n\nEtymological information is stored under the ``etymology_text`` and\n``etymology_templates`` keys in the word's data.  When multiple parts-of-speech\nare listed under the same etymology, the same data is copied to each\npart-of-speech entry under that etymology.\n\nThe ``etymology_text`` field contains the contents of the whole etymology\nsection cleaned into human-readable text (i.e., templates have been expanded\nand HTML tags removed, among other things).\n\nThe ``etymology_templates`` field contains a list of templates from\nthe etymology section.  Some common templates considered not relevant\nfor etymological information have been removed (e.g., ``redlink\ncategory`` and ``isValidPageName``).  The list also includes nested\ntemplates referenced from templates directly used in the etymology\ndescription.  Each template in the list is a dictionary with the following\nkeys:\n* ``name`` - name of the template\n* ``args`` - dictionary mapping argument names to their cleaned values.  Positional arguments have keys that are numeric strings, starting with \"1\".\n* ``expansion`` - the (cleaned) text the template expands to.\n\n### Linkages to other words\n\nLinkages (``synonyms``, ``antonyms``, ``hypernyms``, ``derived\nwords``, ``holonyms``, ``meronyms``, ``derived``, ``related``,\n``coordinate_terms``) are stored in the word's data if not\nsense-disambiguated, and in the word sense if sense-disambiguated.\nThey are lists of dictionaries, where each dictionary can contain the\nfollowing keys, among others:\n\n* ``alt`` - optional alternative form of the target (e.g., in a different script)\n* ``english`` - optional English text associated with the sense, usually identifying the linked target sense\n* ``roman`` - optional romanization of a linked word in a non-Latin script\n* ``sense`` - text identifying the word sense or context (e.g., ``\"to rain very heavily\"``)\n* ``tags``: qualifiers specified for the sense (e.g., field of study, region, dialect, style)\n* ``taxonomic``: optional taxonomic name associated with the linkage\n* ``topics``: list of topic descriptors for the linkage (e.g., ``military``)\n* ``word`` - the word this links to (string)\n\n## Category tree data format\n\nThe ``--categories-file`` option extracts the Wiktionary category tree\nas JSON into the specified file.  The data is extracted from the Wiktionary\nLua modules by evaluating them.\n\nThe data written to the JSON file is a dictionary, with the top-level\nkeys ``roots`` and ``nodes``.\n\nRoots is a list of top-level nodes that are not children of other\nnodes.  ``Fundamental`` is the normal top-level node; other roots may\nreflect errors in the hierarchy in Wiktionary.  While not a root, the\ncategory ``all topics`` contains the subhierarchy of topical\ncategories (e.g., ``food and drink``, ``nature``, ``sciences``, etc.).\n\nNodes is a dictionary mapping lowercased category name to a dictionary\ncontaining data about the category.  For each category, the following\nfields may be present:\n\n* ``name`` (always present): non-lowercased name of the category (note, however,\n  that many categories are originally lowercase in the Wiktionary\n  hierarchy)\n* ``desc``: optional description of the category\n* ``clean_desc``: optional cleaned description of the category, with wikitext formatting cleaned to human-readable text, except {{{langname}}} (and possibly other similar tags) are left intact.\n* ``children``: optional list of child categories of the category\n* ``sort``: optional list of sorts (types of subcategories?).\n\nThe categories are returned as they are in the original Wiktionary\ncategory data.  Language-specific categories are generally not\nincluded.  However, there is a category ``{{{langcat}}}`` that appears\nto contain a lot of the categories that have language-specific\nvariants.  Also, the category tree data does not contain language\nprefixes (the tree is defined in Wiktionary without prefixes and then\nreplicated for each language).\n\n## Related packages\n\nThe\n[wikitextprocessor](https://github.com/tatuylonen/wikitextprocessor)\nis a generic module for extracting data from Wiktionary, Wikipedia, and\nother WikiMedia dump files.  ``wiktextract`` is built using this module.\n\n*When using a version of wiktextract from github, please also setup\nwikitextprocessor so that they have rough parity. The pypi versions of these\npackages are usually out-of-date, and mixing a newer version with an older\none will lead to bugs. These packages are being developed in parallel.*\n\nThe [wiktfinnish](https://github.com/tatuylonen/wiktfinnish) package\ncan be used to interpret Finnish noun declinations and verb\nconjugations and for generating Finnish inflected word forms.\n\n## Related tools\n\nA few other tools also exist for parsing Wiktionaries.  These include\n[Dbnary](http://kaiko.getalp.org/about-dbnary/),\n[Wikiparse](https://github.com/frankier/wikiparse), and [DKPro\nJWKTL](https://dkpro.github.io/dkpro-jwktl/).\n\n## Contributing and reporting bugs\n\nPlease report bugs and other issues on github.  I also welcome\nsuggestions for improvement.\n\nPlease email to ``ylo`` at ``clausal.com`` if you wish to contribute\nor have patches or suggestions.\n\n## License\n\nCopyright (c) 2018-2020 [Tatu Ylonen](https://ylonen.org).  This\npackage is free for both commercial and non-commercial use.  It is\nlicensed under the MIT license.  See the file\n[LICENSE](https://github.com/tatuylonen/wiktextract/blob/master/LICENSE)\nfor details.  (Certain files have different open source licenses)\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "https://github.com/tatuylonen/wiktextract",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://ylonen.org",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "wiktextract",
    "package_url": "https://pypi.org/project/wiktextract/",
    "platform": null,
    "project_url": "https://pypi.org/project/wiktextract/",
    "project_urls": {
      "Download": "https://github.com/tatuylonen/wiktextract",
      "Homepage": "https://ylonen.org"
    },
    "release_url": "https://pypi.org/project/wiktextract/1.99.7/",
    "requires_dist": [
      "wikitextprocessor",
      "python-Levenshtein",
      "nltk"
    ],
    "requires_python": "",
    "summary": "Wiktionary dump file parser and multilingual data extractor",
    "version": "1.99.7",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14185914,
  "releases": {
    "0.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1d19ee246d2029b719b2117a9a4369d4589b2b420d26a167fe895b82e2c3d1fd",
          "md5": "951eaf2547d516da413615ce6e2c82ad",
          "sha256": "0efc1e790d84de3cff14725a7f0fa671a5d019b9ad2a7646318ef9a65e3eeb17"
        },
        "downloads": -1,
        "filename": "wiktextract-0.1.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "951eaf2547d516da413615ce6e2c82ad",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 50203,
        "upload_time": "2018-10-30T12:27:26",
        "upload_time_iso_8601": "2018-10-30T12:27:26.167606Z",
        "url": "https://files.pythonhosted.org/packages/1d/19/ee246d2029b719b2117a9a4369d4589b2b420d26a167fe895b82e2c3d1fd/wiktextract-0.1.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "57df5124de3f3f13e19405afeae8a29a0e5e9213e6d7972955e16c76e4d41829",
          "md5": "2f60cc73b0f1a29eac3a2f07573ec88d",
          "sha256": "ea5c618485aafd5932ca011b516c57ca225048a0fd258a567ce3899a2d2f152c"
        },
        "downloads": -1,
        "filename": "wiktextract-0.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "2f60cc73b0f1a29eac3a2f07573ec88d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 54362,
        "upload_time": "2018-10-30T12:27:27",
        "upload_time_iso_8601": "2018-10-30T12:27:27.965452Z",
        "url": "https://files.pythonhosted.org/packages/57/df/5124de3f3f13e19405afeae8a29a0e5e9213e6d7972955e16c76e4d41829/wiktextract-0.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3cce1c175870c089b1cc6fb029504df28b0147831ae4cc92b78ab590dbf513a2",
          "md5": "93a7ce8b1c17d6648ca074369422edb8",
          "sha256": "f5901c8cf9204f691a0161437d3e593f28e0d18dd9d10c2fe10b6979ccd82f24"
        },
        "downloads": -1,
        "filename": "wiktextract-0.1.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "93a7ce8b1c17d6648ca074369422edb8",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 53025,
        "upload_time": "2018-11-01T23:05:31",
        "upload_time_iso_8601": "2018-11-01T23:05:31.059582Z",
        "url": "https://files.pythonhosted.org/packages/3c/ce/1c175870c089b1cc6fb029504df28b0147831ae4cc92b78ab590dbf513a2/wiktextract-0.1.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b62bf7cbf1aa9a8cc71989a55d4d637a22948d40a67637f12917d58a52c118c1",
          "md5": "29a8de61b73fbadeccba9823647aa4d3",
          "sha256": "ca388794ec2a51cb772733caafcada0c05259bade36ff693ac1e5338b75ffffd"
        },
        "downloads": -1,
        "filename": "wiktextract-0.1.5.tar.gz",
        "has_sig": false,
        "md5_digest": "29a8de61b73fbadeccba9823647aa4d3",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 57924,
        "upload_time": "2018-11-01T23:05:32",
        "upload_time_iso_8601": "2018-11-01T23:05:32.730456Z",
        "url": "https://files.pythonhosted.org/packages/b6/2b/f7cbf1aa9a8cc71989a55d4d637a22948d40a67637f12917d58a52c118c1/wiktextract-0.1.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7fd3df57c0eec94287e07cedfb659decc761ef4b91667eda4cd52690db5021fe",
          "md5": "c38b7b70e1a96ff02f959d36253f75c0",
          "sha256": "670c929d6af7e2ea5c1696b49f37e9cea8973e0baa1ecb92088bdb3a2c9a7a8d"
        },
        "downloads": -1,
        "filename": "wiktextract-0.2.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "c38b7b70e1a96ff02f959d36253f75c0",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 54201,
        "upload_time": "2018-12-13T19:55:49",
        "upload_time_iso_8601": "2018-12-13T19:55:49.634940Z",
        "url": "https://files.pythonhosted.org/packages/7f/d3/df57c0eec94287e07cedfb659decc761ef4b91667eda4cd52690db5021fe/wiktextract-0.2.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5d2ad0cc3b280430b6abec6f854c267d5c8911de74b149466f832fa8fe3d1ab6",
          "md5": "04097185f09b68a5281b2c2f43c70500",
          "sha256": "f2c7b41d6a972eec02de591a91f8ec68908a57d0bd5589d5f8a87ed8b826d20b"
        },
        "downloads": -1,
        "filename": "wiktextract-0.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "04097185f09b68a5281b2c2f43c70500",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 58351,
        "upload_time": "2018-12-13T19:55:51",
        "upload_time_iso_8601": "2018-12-13T19:55:51.681492Z",
        "url": "https://files.pythonhosted.org/packages/5d/2a/d0cc3b280430b6abec6f854c267d5c8911de74b149466f832fa8fe3d1ab6/wiktextract-0.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.99.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ff83540ffa54cec76a6dc73010c1b325a22d8e04ea26476aa1e99ae7557cf57f",
          "md5": "d6a798cad7a38c7fb025650e84fa171a",
          "sha256": "73442be02cb9b4538917fe653f42ae92f065d5f09be3ced46d6d143d8c418e0c"
        },
        "downloads": -1,
        "filename": "wiktextract-1.99.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d6a798cad7a38c7fb025650e84fa171a",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 81096,
        "upload_time": "2020-12-28T13:07:03",
        "upload_time_iso_8601": "2020-12-28T13:07:03.661527Z",
        "url": "https://files.pythonhosted.org/packages/ff/83/540ffa54cec76a6dc73010c1b325a22d8e04ea26476aa1e99ae7557cf57f/wiktextract-1.99.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "947c7335cf3b083e9239b1a2289448686894c0f885bc73f8d6ca66805d368801",
          "md5": "9871a72d443ce4d143697de8eb2273c9",
          "sha256": "c481166543afa06c2df05ae44a3e8fbec628ba25d648ee9f8fdfbe635f8590cc"
        },
        "downloads": -1,
        "filename": "wiktextract-1.99.2.tar.gz",
        "has_sig": false,
        "md5_digest": "9871a72d443ce4d143697de8eb2273c9",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 92103,
        "upload_time": "2020-12-28T13:07:05",
        "upload_time_iso_8601": "2020-12-28T13:07:05.660512Z",
        "url": "https://files.pythonhosted.org/packages/94/7c/7335cf3b083e9239b1a2289448686894c0f885bc73f8d6ca66805d368801/wiktextract-1.99.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.99.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "33370873f6b50050746237a27c23e63ebdb00b064cfa354e40cd58fc8cc6d91b",
          "md5": "07341fbfc18fddcd9cbe67c2c8ded0fd",
          "sha256": "4d11e78cea96569efdd813d35dd46e45b73426e2bd09080654ec1563525bda6e"
        },
        "downloads": -1,
        "filename": "wiktextract-1.99.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "07341fbfc18fddcd9cbe67c2c8ded0fd",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 81090,
        "upload_time": "2020-12-28T14:00:00",
        "upload_time_iso_8601": "2020-12-28T14:00:00.292782Z",
        "url": "https://files.pythonhosted.org/packages/33/37/0873f6b50050746237a27c23e63ebdb00b064cfa354e40cd58fc8cc6d91b/wiktextract-1.99.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "64f54e0cf1e93c3a269d41fb6fbb194ed1136aa3423fc116a0fcaec68cb88a48",
          "md5": "b71bdc6f9806561a31c7d8442f16929b",
          "sha256": "ffa69e7ebf6f9a2a4064a58b921758c2c753ea7f135025540b071b1ad5cdae19"
        },
        "downloads": -1,
        "filename": "wiktextract-1.99.3.tar.gz",
        "has_sig": false,
        "md5_digest": "b71bdc6f9806561a31c7d8442f16929b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 92101,
        "upload_time": "2020-12-28T14:00:02",
        "upload_time_iso_8601": "2020-12-28T14:00:02.104257Z",
        "url": "https://files.pythonhosted.org/packages/64/f5/4e0cf1e93c3a269d41fb6fbb194ed1136aa3423fc116a0fcaec68cb88a48/wiktextract-1.99.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.99.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "caafc4bf1947d3de5f00ace31e58d8ba0cc72c37dd76a09a8352304c6fc6d560",
          "md5": "f9cd07bd2175eba4ee04fb1df96baf87",
          "sha256": "3a11a062542aaed981202c7c1e6ddd82d2e54b4819b8f74fbbde98552da4675b"
        },
        "downloads": -1,
        "filename": "wiktextract-1.99.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f9cd07bd2175eba4ee04fb1df96baf87",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 73917,
        "upload_time": "2021-04-10T10:40:52",
        "upload_time_iso_8601": "2021-04-10T10:40:52.297119Z",
        "url": "https://files.pythonhosted.org/packages/ca/af/c4bf1947d3de5f00ace31e58d8ba0cc72c37dd76a09a8352304c6fc6d560/wiktextract-1.99.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cc1ac44968bdfcd6165db09f341825f768987eb588baef63134574da443e623f",
          "md5": "54f9e53fd99cd74b2e6c5e33acdb54f3",
          "sha256": "2d340c8e26298694270e83081b99db6eae954a1473d68b02fd300a61a188013c"
        },
        "downloads": -1,
        "filename": "wiktextract-1.99.4.tar.gz",
        "has_sig": false,
        "md5_digest": "54f9e53fd99cd74b2e6c5e33acdb54f3",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 85242,
        "upload_time": "2021-04-10T10:40:53",
        "upload_time_iso_8601": "2021-04-10T10:40:53.818962Z",
        "url": "https://files.pythonhosted.org/packages/cc/1a/c44968bdfcd6165db09f341825f768987eb588baef63134574da443e623f/wiktextract-1.99.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.99.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "71f8cd126f259558c223615d906f65dba43e8129d4062cc34bc432bea55ca3c9",
          "md5": "07baab2abba7135e6f7c14d94732999f",
          "sha256": "9c8b52f580f1b305a0de20ae48ebb47a8b2d1cd2d2fbfcc3878d8246166ebc5c"
        },
        "downloads": -1,
        "filename": "wiktextract-1.99.6-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "07baab2abba7135e6f7c14d94732999f",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 4778601,
        "upload_time": "2021-09-20T09:09:31",
        "upload_time_iso_8601": "2021-09-20T09:09:31.705885Z",
        "url": "https://files.pythonhosted.org/packages/71/f8/cd126f259558c223615d906f65dba43e8129d4062cc34bc432bea55ca3c9/wiktextract-1.99.6-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a6f649df44f3056c34a1726a49d57296f3fd2f6fb4d3fd51d8bb4f78529df8bb",
          "md5": "17476149e9a543f9d279d8083fff3bd8",
          "sha256": "b48e7ef6d39d8ca78288a301614f8523b0c1af7d47a2fb8d3757e750a8bfc9e6"
        },
        "downloads": -1,
        "filename": "wiktextract-1.99.6.tar.gz",
        "has_sig": false,
        "md5_digest": "17476149e9a543f9d279d8083fff3bd8",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 4755680,
        "upload_time": "2021-09-20T09:09:35",
        "upload_time_iso_8601": "2021-09-20T09:09:35.966783Z",
        "url": "https://files.pythonhosted.org/packages/a6/f6/49df44f3056c34a1726a49d57296f3fd2f6fb4d3fd51d8bb4f78529df8bb/wiktextract-1.99.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.99.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "93c0f490fe98b1140f9fce43ddbb4da8c969518bfe5452e989d9d40efaa59df5",
          "md5": "9b41e41b803034dabf334f2d9be5360b",
          "sha256": "55ae95d3f7059f4fa13b6ad66affc8d68d2c7917de6a649d19e1fe611a00a9d3"
        },
        "downloads": -1,
        "filename": "wiktextract-1.99.7-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "9b41e41b803034dabf334f2d9be5360b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 4853902,
        "upload_time": "2022-06-20T10:29:18",
        "upload_time_iso_8601": "2022-06-20T10:29:18.727231Z",
        "url": "https://files.pythonhosted.org/packages/93/c0/f490fe98b1140f9fce43ddbb4da8c969518bfe5452e989d9d40efaa59df5/wiktextract-1.99.7-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5698914f0e3f4bf93cef9f6375290dbb9d64386a1532c7542532cd29e4ce73ce",
          "md5": "08f6a590eef20d1f033d91b8dcf27447",
          "sha256": "4537ec63012396ae1974b10005e31552979128ff4347cac0342c5a65c882e215"
        },
        "downloads": -1,
        "filename": "wiktextract-1.99.7.tar.gz",
        "has_sig": false,
        "md5_digest": "08f6a590eef20d1f033d91b8dcf27447",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 4831399,
        "upload_time": "2022-06-20T10:29:38",
        "upload_time_iso_8601": "2022-06-20T10:29:38.615545Z",
        "url": "https://files.pythonhosted.org/packages/56/98/914f0e3f4bf93cef9f6375290dbb9d64386a1532c7542532cd29e4ce73ce/wiktextract-1.99.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "93c0f490fe98b1140f9fce43ddbb4da8c969518bfe5452e989d9d40efaa59df5",
        "md5": "9b41e41b803034dabf334f2d9be5360b",
        "sha256": "55ae95d3f7059f4fa13b6ad66affc8d68d2c7917de6a649d19e1fe611a00a9d3"
      },
      "downloads": -1,
      "filename": "wiktextract-1.99.7-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "9b41e41b803034dabf334f2d9be5360b",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 4853902,
      "upload_time": "2022-06-20T10:29:18",
      "upload_time_iso_8601": "2022-06-20T10:29:18.727231Z",
      "url": "https://files.pythonhosted.org/packages/93/c0/f490fe98b1140f9fce43ddbb4da8c969518bfe5452e989d9d40efaa59df5/wiktextract-1.99.7-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "5698914f0e3f4bf93cef9f6375290dbb9d64386a1532c7542532cd29e4ce73ce",
        "md5": "08f6a590eef20d1f033d91b8dcf27447",
        "sha256": "4537ec63012396ae1974b10005e31552979128ff4347cac0342c5a65c882e215"
      },
      "downloads": -1,
      "filename": "wiktextract-1.99.7.tar.gz",
      "has_sig": false,
      "md5_digest": "08f6a590eef20d1f033d91b8dcf27447",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 4831399,
      "upload_time": "2022-06-20T10:29:38",
      "upload_time_iso_8601": "2022-06-20T10:29:38.615545Z",
      "url": "https://files.pythonhosted.org/packages/56/98/914f0e3f4bf93cef9f6375290dbb9d64386a1532c7542532cd29e4ce73ce/wiktextract-1.99.7.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}