{
  "info": {
    "author": "SAP SE",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "<img src=\"https://raw.githubusercontent.com/SAP/ml-model-watermarking/dev/docs/logo-dark.svg?sanitize=true#gh-dark-mode-only\" alt=\"Hurl Logo\" width=\"6000px\"><img src=\"https://raw.githubusercontent.com/SAP/ml-model-watermarking/dev/docs/logo-light.svg?sanitize=true#gh-light-mode-only\" alt=\"Hurl Logo\" width=\"6000px\">\n\n<p align=\"center\">\n    <a href=\"https://api.reuse.software/info/github.com/SAP/ml-model-watermarking\">\n        <img alt=\"REUSE\" src=\"https://api.reuse.software/badge/github.com/SAP/ml-model-watermarking\">\n    </a>\n    <a href=\"https://github.com/SAP/ml-model-watermarking/blob/main/LICENSE\">\n        <img alt=\"LICENSE\" src=\"https://img.shields.io/badge/License-Apache%202.0-blue.svg\">\n    </a>\n</p>\n\n\n<h3 align=\"center\">\n    <p>Protect your machine learning models easily and securely with watermarking :key: </p>\n</h3>\n\n---\n\nThe concept of digital watermarking has been known for 30 years, mainly for image and audio contents. The goal is to insert a unique, hidden and non-removable signal in the original content, to be used as an identifier. If a thief steals a content, the original owner can still prove his/her ownership. ML Model Watermarking offers basic primitives for researchers and machine learning enthusiasts to watermark their models, without advanced knowledge of underlying concepts.\n\n* :book: Watermark models on various tasks, such as **image classification** or **sentiment analysis**, with a compatibility with the main Machine Learning frameworks like [Scikit-learn](https://github.com/scikit-learn/scikit-learn), [Pytorch](https://github.com/pytorch/pytorch) or the [HuggingFace library](https://github.com/huggingface/transformers).\n* :triangular_flag_on_post: Detect if one of your models has been used without consent.\n* :chart_with_upwards_trend: Integrate watermark in your pipeline, with a negligible accuracy loss.\n\n## Installation\n\n\nSimply run:\n\n``` python\n>>>  pip install .\n```\n\n## How to use it\n\nML Model Watermarking acts as a wrapper for your model, provoding a range of techniques for watermarking your model as well as ownership detection function. After the watermarking phase, you can retrieve your model and save the ownership information. \n\n``` python\n>>> from mlmodelwatermarking.markface import TrainerWM\n\n>>> trainer = TrainerWM(model=your_model)\n>>> ownership = trainer.watermark()\n>>> watermarked_model = trainer.get_model()\n```\n\nLater, it is possible verify if a given model has been stolen based on the ownership information\n\n``` python\n>>> from mlmodelwatermarking.marktorch import TrainerWM\n>>> from mlmodelwatermarking.verification import verify\n\n>>> trainer = TrainerWM(model=suspect_model, ownership=ownership)\n>>> trainer.verify()\n{'is_stolen': True, 'score': 0.88, 'threshold': 0.66}\n```\n\n\n## References\n\nThe library implements several ideas presented in academic papers:\n\n<center>\n\n| <div style=\"width:190px\">Technique</div> | <div style=\"width:80px\">Scikit-learn</div> | <div style=\"width:80px\">PyTorch</div> | <div style=\"width:90px\">HuggingFace</div>  |\n|-|-|-|-|\n| [Adi et al.](https://www.usenix.org/conference/usenixsecurity18/presentation/adi) | |:heavy_check_mark:| | \n|[Zhang et al.](https://dl.acm.org/doi/abs/10.1145/3196494.3196550?casa_token=RZrfzSIO_uwAAAAA:N7ohyz15GCGfoXRMtew-dX5dV-heZyI-N5Tod1xyKFWb46MXLPeqdfhMLizAFXlVE_VfZP_m2T3M)|:heavy_check_mark:|:heavy_check_mark:| |\n|[Gu et al.](https://ieeexplore.ieee.org/abstract/document/8685687)||:heavy_check_mark:||\n|[Merrer et al.](https://arxiv.org/pdf/1711.01894.pdf)| |:heavy_check_mark:| |\n|[Yang et al.](https://aclanthology.org/2021.acl-long.431.pdf)| | |:heavy_check_mark:|\n|[Szyller et al.](https://arxiv.org/pdf/1906.00830.pdf)|:heavy_check_mark:|:heavy_check_mark:| |\n|[Lounici et al.](https://ieeexplore.ieee.org/document/9505220)|:heavy_check_mark:|:heavy_check_mark:|:heavy_check_mark:|\n\n</center>\n\n1. [Turning Your Weakness Into a Strength: Watermarking Deep Neural Networks by Backdooring](https://www.usenix.org/conference/usenixsecurity18/presentation/adi) by Adi et al.\n2. [Protecting Intellectual Property of Deep Neural Networks with Watermarking](https://dl.acm.org/doi/abs/10.1145/3196494.3196550?casa_token=RZrfzSIO_uwAAAAA:N7ohyz15GCGfoXRMtew-dX5dV-heZyI-N5Tod1xyKFWb46MXLPeqdfhMLizAFXlVE_VfZP_m2T3M) by Zhang et al.\n3. [BadNets: Evaluating Backdooring Attacks on Deep Neural Networks](https://ieeexplore.ieee.org/abstract/document/8685687) by Gu et al.\n4. [Adversarial frontier stitching for remote neural network watermarking](https://arxiv.org/pdf/1711.01894.pdf) by Merrer et al.\n5. [Rethinking Stealthiness of Backdoor Attack against NLP Models](https://aclanthology.org/2021.acl-long.431.pdf) by Yang et al.\n6. [DAWN: Dynamic Adversarial Watermarking of Neural Networks](https://arxiv.org/pdf/1906.00830.pdf) by Szyller et al.\n7. [Yes We can: Watermarking Machine Learning Models beyond Classification](https://ieeexplore.ieee.org/document/9505220) by Lounici et al.\n\n\n\n## Contributing\n\nWe invite your participation to the project through issues and pull requests. Please refer to the [Contributing guidelines](https://github.com/SAP/ml-model-watermarking/blob/main/CONTRIBUTING.md) for how to contribute.\n\n## How to obtain support\n\nYou can open an [issue](https://github.com/SAP/ml-model-watermarking/issues).\n\n## Licensing\n\nCopyright 2020-21 SAP SE or an SAP affiliate company and ml-model-watermarking contributors. Please see our [LICENSE](LICENSE) for copyright and license information. Detailed information including third-party components and their licensing/copyright information is [available via the REUSE tool](https://api.reuse.software/info/github.com/SAP/ml-model-watermarking).\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://www.sap.com/",
    "keywords": "watermarking SAP",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "mlmodelwatermarking",
    "package_url": "https://pypi.org/project/mlmodelwatermarking/",
    "platform": null,
    "project_url": "https://pypi.org/project/mlmodelwatermarking/",
    "project_urls": {
      "Homepage": "https://www.sap.com/",
      "Source": "https://github.com/SAP/ml-model-watermarking"
    },
    "release_url": "https://pypi.org/project/mlmodelwatermarking/0.0.1/",
    "requires_dist": [
      "cryptography",
      "numpy",
      "sklearn",
      "torch",
      "transformers",
      "datasets",
      "torchvision",
      "pyfiglet",
      "tqdm",
      "bitstring"
    ],
    "requires_python": ">3.5, <3.10",
    "summary": "ML Model Watermarking",
    "version": "0.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 13453018,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "09d88df8c44bf6de1c30c8ac1f4343d5ef2060cbecd387335877122b2aa290ad",
          "md5": "17e828f01c728587157a5c280758e303",
          "sha256": "62529b85d1e7d552b76a4238f8385ba9d2e36a05c1037efe41d1390c93e04f63"
        },
        "downloads": -1,
        "filename": "mlmodelwatermarking-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "17e828f01c728587157a5c280758e303",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">3.5, <3.10",
        "size": 16921044,
        "upload_time": "2022-04-08T11:48:43",
        "upload_time_iso_8601": "2022-04-08T11:48:43.840794Z",
        "url": "https://files.pythonhosted.org/packages/09/d8/8df8c44bf6de1c30c8ac1f4343d5ef2060cbecd387335877122b2aa290ad/mlmodelwatermarking-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "09d88df8c44bf6de1c30c8ac1f4343d5ef2060cbecd387335877122b2aa290ad",
        "md5": "17e828f01c728587157a5c280758e303",
        "sha256": "62529b85d1e7d552b76a4238f8385ba9d2e36a05c1037efe41d1390c93e04f63"
      },
      "downloads": -1,
      "filename": "mlmodelwatermarking-0.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "17e828f01c728587157a5c280758e303",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">3.5, <3.10",
      "size": 16921044,
      "upload_time": "2022-04-08T11:48:43",
      "upload_time_iso_8601": "2022-04-08T11:48:43.840794Z",
      "url": "https://files.pythonhosted.org/packages/09/d8/8df8c44bf6de1c30c8ac1f4343d5ef2060cbecd387335877122b2aa290ad/mlmodelwatermarking-0.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}