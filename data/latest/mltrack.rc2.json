{
  "info": {
    "author": "S.Shankar",
    "author_email": "orthogonal.eigenvector@gmail.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# mltrack - Track and organize your machine learning projects from the terminal\n\n`mltrack` is a terminal based tool to track and organize machine learning pipelines. It does so by:\n\n- Expressing ML pipelines as a [directed acyclic graph](https://en.wikipedia.org/wiki/Directed_acyclic_graph) (DAG), and\n\n- Organizing your repository in an opinionated folder structure.\n\nIt is designed to be extremely lightweight, using tools such as git, bash and make that are usually available by default in a standard unix distribution. It is written in pure python, offers a simple command line interface, and integrates easily with existing python codebases.\n\n## What are other similar tools?\n\nThere are many, many build / workflow automation tools and data pipelining schedulers available that let one do similar things as `mltrack`. Apache Airflow, Luigi and Snakemake / Nextflow are notable examples. See [here](https://en.wikipedia.org/wiki/Workflow_management_system) and [here](https://en.wikipedia.org/wiki/List_of_build_automation_software) for more comprehensive lists.\n\nMost of these tools are fairly heavy-duty to install, configure and use, often requiring one to use a special domain specific language to specify the workflow. Many of them are meant to be used for big data processing in a distributed computing environment, or for compiling large codebases in C/C++. \n\n`mltrack` is optimized towards machine learning pipelines that are collaboratively built by a medium-sized team that is trying to experiment and iterate rapidly.  \n\nThe distinguishing feature of `mltrack` is that it lets one specify the workflow DAG as a list of plain Python dictionaries. That means the workflow / pipeline itself can be easily shared in a team setting,as well as made available for automatic versioning, testing and documentation. The pipelines can be programatically generated, nested within each other, and reconfigured at runtime.\n\n`mltrack` is extremely lightweight, and doesn't require you to install special runtimes / servers etc. After adopting it, most projects will end up using `mlt` as a top-level command line interface that runs and documents the project's workflow.\n\n`mltrack` generates a folder structure for new projects in a similar way to `cookiecutter`.\n\n## Benefits of `mltrack`\n\n- Specify ML pipelines / workflows as plain Python code.\n- Guaranteed reproducibility, testability and versioning for pipelines / workflows.\n- Use `mlt` as a CLI interface to your workflow. Easily define custom commands with help text to run and document sub-parts of your workflow.\n- Collaborate painlessly: common folder structure and shared knowledge of the `mlt` interface unifies project workflow and defines a common way of doing things.  \n- Save time with incremental processing: `mlt` will only run sub-parts of your workflow that need to be updated.\n- Apply the full power and flexibility of Python - generate and reconfigure workflows / pipelines dynamically based on external data, build arbitrarily large and complex task graphs.\n- Extremely lightweight: uses tools that are available by default in a standard Unix box such as git, bash, make and Python.\n- No need to learn a special domain specific language / protocol or install heavy duty software or servers.\n\n## Usage and installation\n\n`mltrack` is available on PyPI. The easiest way to install is with pip:\n\n```\npip install --upgrade mltrack\n```\n\nTo start with, `mlt help` will print help text:\n\n```\n~->mlt help\n\n\n mlt - track and organize machine learning workflows from the terminal\n\n\nFORMAT -\n\n mlt [command]\n\nmlt commands:\n  create:                     creates a new mlt repository\n  init:                       initializes existing repository for use with mlt\n  help:                       prints help text\n\n No user defined commands available.\n\nCannot find mlt repo, or repository info in .mlt might be corrupted. Type 'mlt init' to initialize new mlt repository. Delete existing .mlt folder if one exists.\n```\n\nCreate a new project repository with `mlt create`:\n\n```\n(base) ubuntu@ip-172-31-32-135:~/mldk_dev$ mlt create\nWhat's your project's name? Yoda ML\nEnter repository name [recommended repository name: yoda_ml, press enter to use yoda_ml ]:\nEnter author name: Shankar\nEnter license type (optional, press enter for no license) [MIT (1), GPL (2), Apache (3)]: 1\nEnter AWS profile name (press enter to use 'default' ):\nEnter bucket name: shankar-test-ml\nrepo_dir is : /home/ubuntu/mldk_dev/yoda_ml\nSuccessfully initialized mlt project...\n```\n\nA new project repository comes pre-loaded with a basic MNIST classification example.\n\nLet's change to the project directory and type `mlt help` again:\n\n```\n~/mldk_dev/yoda_ml->mlt help\n\n\n mlt - track and organize machine learning workflows from the terminal\n\n\nFORMAT -\n\n mlt [command]\n\nmlt commands:\n  create:                     creates a new mlt repository\n  init:                       initializes existing repository for use with mlt\n  help:                       prints help text\n\n Commands defined in mlt_dependencies.py:\n\n  clean:                      Deletes compiled Python files\n  sync_data_to_s3:            Upload data to S3 bucket (default-bucket)\n  sync_data_from_s3:          Download data from S3 bucket (default-bucket)\n  data:                       Run \"mlt data\" to download data, preprocess it and generate features\n  train_eval_model:           train and evaluate model\n  download:                   Downloads an updated version of data/external/mnist.pkl.gz\n  rawpreprocess:              Run raw preprocessing\n  featurize:                  Generates features from raw data\n  learn_features:             learn parameters to prepare for feature generation\n  train_model:                Trains and persists model\n  evaluate_model:             Evaluate model loss in test set\n```\n\nNote that the help text now shows user defined commands. These commands are defined by the user in the project's `mlt_dependencies.py` file.\n\nLet's evaluate the model by running `mlt evaluate_model`. Before running this command, you can verify that the data directories are empty. In order to evaluate the model, we will first have to download data, preprocess it, generate features and train the model itself.\n\nThese steps are defined as a dependency graph in `mlt_dependencies.py`, so `mlt` will execute them in the right order:\n\n```\n(base) ubuntu@ip-172-31-32-135:~/mldk_dev/yoda_ml$ mlt evaluate_model\npython -m src.data.download_data\nDownloaded http://deeplearning.net/data/mnist/mnist.pkl.gz to /home/ubuntu/mldk_dev/yoda_ml/data/external/mnist.pkl.gz\npython -m src.data.make_dataset\ntrain_set data: (50000, 784), train_set labels: (50000,)\nvalid_set data: (10000, 784), valid_set labels: (10000,)\ntest_set data: (10000, 784), test_set labels: (10000,)\nsaved raw train, valid and test splits in /home/ubuntu/mldk_dev/yoda_ml/data/raw\npython -m src.features.learn_features\nfit Standard Scaler and PCA with n_components_ = 329 components, original components = 784\npython -m src.features.build_features\npython -m src.models.train_model\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n  \"of iterations.\", ConvergenceWarning)\nstarting model training...\nfinished training model...\ntrain error (log loss) : 0.23456826576340226\nvalidation error (log loss): 0.28539054233742156\npython -m src.models.eval_model\nmodel evaluation completed:\n\n Test set score for model LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=200, multi_class='multinomial',\n          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n          tol=0.0001, verbose=0, warm_start=False) = 0.31476026852394734\n\n\n(base) ubuntu@ip-172-31-32-135:~/mldk_dev/yoda_ml$\n```\n\nYou can see that the full pipeline is run in the output above, and verify that the data directories now have the downloaded, preprocessed and final data / model files.\n\nIf you run `mlt evaluate_model` again, it will do nothing because the pipeline is up to date:\n\n```\n(base) ubuntu@ip-172-31-32-135:~/mldk_dev/yoda_ml$ mlt evaluate_model\nmlt: Nothing to be done for 'evaluate_model'.\n```\n\nIf you run `mlt featurize` now, `mlt` will recognize that nothing needs to be run, because the `featurize` step was a precursor to `evaluate_model`, and all files involved are up to date:\n\n```\n(base) ubuntu@ip-172-31-32-135:~/mldk_dev/yoda_ml$ mlt featurize\nmlt: Nothing to be done for 'featurize'.\n```\n\nNow let's edit and save `src/features/build_features.py` (for purposes of this demonstration, you can simply make an inconsequential edit, such as adding new line or space to the end of the file).\n\n`src/features/build_features.py` is used to learn and build features. Since we have updated it, the `featurize` step as well as all downstream steps which depend on the feature generation will need to be rerun in order to stay updated. \n\nLet's now run `mlt rawpreprocess`. Since the `rawpreprocess` step is done prior to `featurize`, it is up to date, and `mlt` will not run anything:\n\n```\n(base) ubuntu@ip-172-31-32-135:~/mldk_dev/yoda_ml$ mlt rawpreprocess\nmlt: Nothing to be done for 'rawpreprocess'.\n```\n\nLet's run `mlt train_model`. Since the `train_model` step is a successor to `featurize`, `mlt` will rerun all steps between `featurize` and `train_model`:\n\n```\n(base) ubuntu@ip-172-31-32-135:~/mldk_dev/yoda_ml$ mlt train_model\npython -m src.features.build_features\npython -m src.models.train_model\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n  \"of iterations.\", ConvergenceWarning)\nstarting model training...\nfinished training model...\ntrain error (log loss) : 0.23456826576340226\nvalidation error (log loss): 0.28539054233742156\n```\n\nLet's run `mlt train_eval_model`. This step trains and evaluates the model. Since we just trained our new model, `mlt` will skip the training step and proceed straight to model evaluation:\n\n```\n(base) ubuntu@ip-172-31-32-135:~/mldk_dev/yoda_ml$ mlt train_eval_model\npython -m src.models.eval_model\nmodel evaluation completed:\n\n Test set score for model LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=200, multi_class='multinomial',\n          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n          tol=0.0001, verbose=0, warm_start=False) = 0.31476026852394734\n\n```\n\nThe steps in the pipeline along with their dependencies are defined in `mlt_dependencies.py`. To learn how to write `mlt_dependencies.py` for your own project, let's first understand how to organize ML pipelines as a DAG.\n\n## Core principles: organizing ML pipelines as a DAG\n\nThe core design philosophy behind `mltrack` is organize a machine learning pipeline as a [directed acyclic graph](https://en.wikipedia.org/wiki/Directed_acyclic_graph) (DAG).\n\nML pipelines naturally lend themselves to a DAG representation: one normally starts with a process to gather data, followed by preprocessing it, generating features from it, followed by producing a model file or binary.\n\nEach step might depend on the output of previous steps.\n\nIf you update an intermediate step, all subsequent steps that depend on its outputs will need to be rerun and updated.\n\n`mltrack` will build the graph and keep track of which outputs are out of date, and only re-run the steps that are necessary - that way, you won't rerun your expensive 2-day training process which doesn't depend on the newest change to your pipeline.\n\n## Advantages of using plain Python to describe pipelines as DAGs\n\nThe DAG representing ML pipelines in `mlt` is a plain Python dictionary. Since it is Python code, it can be versioned, linted and shared like any other piece of code.\n\nBut perhaps more importantly, it allows one to bring the full power and expressivity of Python to bear on the problem of describing ML pipelines. You can configure the pipeline at dynamically at runtime, or create sub-pipelines within a larger pipeline based on say, user input or external data.\n\nUsing plain Python also makes the pipeline easy to read and understand between developers working on different parts of a pipeline in a team.\n\n![Sample ML pipeline](./mltrack/docs_assets/sample.svg)\n\nIn the sample pipeline above, `download_data.py` downloads a data source from s3 and `preprocess_data.py` generates `processed_data` from it. In the next step, `feature_1` and `feature_2` are generated, followed by `model_initial` and `model_final`.\n\nIf we update `model_initial.py`, `mltrack` will remember to update `model_final` - at the same time, it will *not* rerun the process to generate `feature_1` or `feature_2`.\n\n## Walkthrough: describing ML pipelines as a DAG with `mlt_dependencies.py`\n\nLet us define a simple, 3 step pipeline and describe it as a DAG in the format `mlt` expects.\n\nLet's create a new directory:\n\n```\n~/mldk_dev->mkdir temp_ml\n~/mldk_dev->cd temp_ml/\n~/mldk_dev/temp_ml->ls\n~/mldk_dev/temp_ml->\n```\n\nIn order to use `mlt` in your project, you must first initialize it with `mlt init`:\n\n```\n~/mldk_dev/temp_ml->mlt init\nWhat's your project's name? temp ml\nSuccessfully initialized mlt project. Define your project dependencies in mlt_dependencies.py to get started.\n~/mldk_dev/temp_ml->\n```\n\nLet's say that the first step in our pipeline is to generate `raw_data_1.txt` by running the python script `gen_raw_1.py`. Our Python script simply prints a list of numbers from 1 to 10:\n\n#### **`gen_raw_1.py`**\n```\nnumbers = range(10)\nprint(\",\".join(str(num) for num in numbers))\n```\n\nWe generate `raw_data_1.txt` like so:\n\n```\n~/mldk_dev/temp_ml->python gen_raw_1.py\n0,1,2,3,4,5,6,7,8,9\n~/mldk_dev/temp_ml->python gen_raw_1.py > raw_data_1.txt\n~/mldk_dev/temp_ml->cat raw_data_1.txt\n0,1,2,3,4,5,6,7,8,9\n```\n\nThis \"pipeline\" is represented as:\n\n![step 1 pipeline](./mltrack/docs_assets/step_1.svg)\n\nThe output is `raw_data_1.txt`, and the action to produce this output is `python gen_raw_1.py > raw_data_1.txt`. This output only depends on the python script `gen_raw_1.py`.\n\nHere is the `mlt_dependencies.py` file that encodes these relationships:\n\n#### **`mlt_dependencies.py`**\n```\nmlt_dependency_graph = {\n    'graph': [\n        {\n            'outputs': ['raw_data_1.txt'],\n            'inputs': ['gen_raw_1.py'],\n            'actions': ['python gen_raw_1.py > raw_data_1.txt'],\n            'help': 'generate raw_data_1.txt'\n        }\n    ]\n}\n```\n\nAs you can see, we added `'help': 'generate raw_data_1.txt'`. The `mlt` dependency graph is specified as a list of dictionaries. The `inputs` are the files that the `outputs` depend on.\n\nAdding a `help` tag (as we did here) make the `outputs` available as a user defined command. After you create the `mlt_dependencies.py` file, try `mlt help`:\n\n```\n~/mldk_dev/temp_ml->ls\ngen_raw_1.py  mlt_dependencies.py  raw_data_1.txt\n~/mldk_dev/temp_ml->mlt help\n\n\n mlt - track and organize machine learning workflows from the terminal\n\n\nFORMAT -\n\n mlt [command]\n\nmlt commands:\n  create:                     creates a new mlt repository\n  init:                       initializes existing repository for use with mlt\n  help:                       prints help text\n\n Commands defined in mlt_dependencies.py:\n\n  raw_data_1.txt:             generate raw_data_1.txt\n~/mldk_dev/temp_ml->\n```\n\nFor purposes of demonstration, let's delete `raw_data_1.txt` and generate it with `mlt`:\n\n```\n~/mldk_dev/temp_ml->rm raw_data_1.txt\n~/mldk_dev/temp_ml->ls\n__pycache__  gen_raw_1.py  mlt_dependencies.py\n~/mldk_dev/temp_ml->mlt raw_data_1.txt\npython gen_raw_1.py > raw_data_1.txt\n~/mldk_dev/temp_ml->ls\n__pycache__  gen_raw_1.py  mlt_dependencies.py  raw_data_1.txt\n~/mldk_dev/temp_ml->\n```\n\nWhat happens if you run `mlt raw_data_1.txt` again?\n\n```\n~/mldk_dev/temp_ml->mlt raw_data_1.txt\nmlt: 'raw_data_1.txt' is up to date.\n```\n\n`mlt` will correctly identify that your files are up to date, and that nothing needs to be rerun.\n\nLet's add another step to our pipeline. We will write a second Python script `gen_processed.py` that reads `raw_data_1.txt` and produces a file `processed.txt` that contains the sum of the numbers in `raw_data_1.txt`:\n\n#### **`gen_processed.py`**\n```\nfrom pathlib import Path\nimport os\nfh = open('./raw_data_1.txt', 'r')\ndata = [int(item) for item in fh.readline().split(',')]\noutput_file = Path(os.getcwd()) / 'processed.txt'\noutput_file.write_text(str(sum(data))+\"\\n\")\n```\n\n```\n~/mldk_dev/temp_ml->ls\n__pycache__  gen_processed.py  gen_raw_1.py  mlt_dependencies.py  raw_data_1.txt\n~/mldk_dev/temp_ml->python gen_processed.py\n~/mldk_dev/temp_ml->cat processed.txt\n45\n```\n\nOur pipeline now looks like this: \n\n![step 2 pipeline](./mltrack/docs_assets/step_2.svg)\n\nLet us add these steps to `mlt_dependencies.py`:\n\n\n#### **`mlt_dependencies.py`**\n```\nmlt_dependency_graph = {\n    'graph': [\n        {\n            'outputs': ['raw_data_1.txt'],\n            'inputs': ['gen_raw_1.py'],\n            'actions': ['python gen_raw_1.py > raw_data_1.txt'],\n            'help': 'generate raw_data_1.txt'\n        },\n\n        {\n            'outputs': ['processed.txt'],\n            'inputs': ['gen_processed.py', 'raw_data_1.txt'],\n            'actions': ['python gen_processed.py'],\n            'help': 'generate processed.txt'\n        }\n    ]\n}\n```\n\nOur output file `processed.txt` depends on the previous output file `raw_data_1.txt` and the source file `gen_processed.py`. The `actions` key `python gen_processed.py` encodes what you would type at the terminal to produce the output.\n\n```\n~/mldk_dev/temp_ml->mlt help\n\n\n mlt - track and organize machine learning workflows from the terminal\n\n\nFORMAT -\n\n mlt [command]\n\nmlt commands:\n  create:                     creates a new mlt repository\n  init:                       initializes existing repository for use with mlt\n  help:                       prints help text\n\n Commands defined in mlt_dependencies.py:\n\n  raw_data_1.txt:             generate raw_data_1.txt\n  processed.txt:              generate processed.txt\n~/mldk_dev/temp_ml->\n```\n\nLet's generate the output with `mlt`:\n\n```\n~/mldk_dev/temp_ml->rm processed.txt\n~/mldk_dev/temp_ml->mlt processed.txt\npython gen_processed.py\n~/mldk_dev/temp_ml->cat processed.txt\n45\n~/mldk_dev/temp_ml->\n```\n\nWhat happens if we say, edit `gen_processed.py`? \n\n#### **`gen_processed.py`**\n```\nfrom pathlib import Path\nimport os\nfh = open('./raw_data_1.txt', 'r')\ndata = [int(item) for item in fh.readline().split(',')]\noutput_file = Path(os.getcwd()) / 'processed.txt'\noutput_file.write_text(str(sum(data))+\"\\n\")\noutput_file.write_text(\"*******\\n\")   ## --> made changes to gen_processed.py\n```\n\n`mlt` will recognize that the last step in the pipeline needs to be rerun, but there is no need to regenerate `raw_data_1.txt`:\n\n```\n~/mldk_dev/temp_ml->ls\n__pycache__  gen_processed.py  gen_raw_1.py  mlt_dependencies.py  processed.txt  raw_data_1.txt\n~/mldk_dev/temp_ml->mlt processed.txt\npython gen_processed.py\n~/mldk_dev/temp_ml->cat processed.txt\n*******\n~/mldk_dev/temp_ml->\n```\n\nRunning `mlt` again will not rerun anything:\n\n```\n~/mldk_dev/temp_ml->mlt processed.txt\nmlt: 'processed.txt' is up to date.\n```\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "mltrack",
    "package_url": "https://pypi.org/project/mltrack/",
    "platform": "",
    "project_url": "https://pypi.org/project/mltrack/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/mltrack/0.0.2/",
    "requires_dist": [
      "jinja2"
    ],
    "requires_python": ">=3.6",
    "summary": "MLtrack: Track your ML workflow from the terminal",
    "version": "0.0.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 6266053,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c7bc821f5a9dc5b829ea8c2adf7f7bec123de6ea5ef83f55cf3dadcd58ed3120",
          "md5": "8bd8084288d65818ecffe839236dac62",
          "sha256": "7da44f8dbb715e3b959f096081f1465f2e813d6a5889e232dd9fccb3ecaf07c6"
        },
        "downloads": -1,
        "filename": "mltrack-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "8bd8084288d65818ecffe839236dac62",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 28933,
        "upload_time": "2019-12-09T12:04:04",
        "upload_time_iso_8601": "2019-12-09T12:04:04.405802Z",
        "url": "https://files.pythonhosted.org/packages/c7/bc/821f5a9dc5b829ea8c2adf7f7bec123de6ea5ef83f55cf3dadcd58ed3120/mltrack-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8c9398a6d03174394f46b4ff28ebdc8fab80a58e47b00cd00ba61241fb544955",
          "md5": "b08d7b9cb500d4e37fd664497164f6ec",
          "sha256": "5a8f6e4c1ee21fda9f08f44ae1353037b01c6844e90f96d8d66cf383af767997"
        },
        "downloads": -1,
        "filename": "mltrack-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "b08d7b9cb500d4e37fd664497164f6ec",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 27923,
        "upload_time": "2019-12-09T12:04:09",
        "upload_time_iso_8601": "2019-12-09T12:04:09.422403Z",
        "url": "https://files.pythonhosted.org/packages/8c/93/98a6d03174394f46b4ff28ebdc8fab80a58e47b00cd00ba61241fb544955/mltrack-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1f362fe4d951f845553a457c32db6f277730764dd7dd7128c5a890f887228cd2",
          "md5": "a23e35f0e28c676de2e60d950c3a1ae2",
          "sha256": "3a2faca77222505dace5fb7602b9aeed0a6c6833392c2651aeb8f91260f2a77c"
        },
        "downloads": -1,
        "filename": "mltrack-0.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "a23e35f0e28c676de2e60d950c3a1ae2",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 28838,
        "upload_time": "2019-12-09T12:04:07",
        "upload_time_iso_8601": "2019-12-09T12:04:07.670784Z",
        "url": "https://files.pythonhosted.org/packages/1f/36/2fe4d951f845553a457c32db6f277730764dd7dd7128c5a890f887228cd2/mltrack-0.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "29fd6ede7e382fd19fe02f844d79998790add819d6c4c80c7a1708569be964b7",
          "md5": "bce672325394c149dff195356493b152",
          "sha256": "4643dfd3824a3ca9f9b8f26838ba4d40de472ec5a82c0af7893666badec0ef39"
        },
        "downloads": -1,
        "filename": "mltrack-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "bce672325394c149dff195356493b152",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 27766,
        "upload_time": "2019-12-09T12:04:11",
        "upload_time_iso_8601": "2019-12-09T12:04:11.363238Z",
        "url": "https://files.pythonhosted.org/packages/29/fd/6ede7e382fd19fe02f844d79998790add819d6c4c80c7a1708569be964b7/mltrack-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "1f362fe4d951f845553a457c32db6f277730764dd7dd7128c5a890f887228cd2",
        "md5": "a23e35f0e28c676de2e60d950c3a1ae2",
        "sha256": "3a2faca77222505dace5fb7602b9aeed0a6c6833392c2651aeb8f91260f2a77c"
      },
      "downloads": -1,
      "filename": "mltrack-0.0.2-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "a23e35f0e28c676de2e60d950c3a1ae2",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 28838,
      "upload_time": "2019-12-09T12:04:07",
      "upload_time_iso_8601": "2019-12-09T12:04:07.670784Z",
      "url": "https://files.pythonhosted.org/packages/1f/36/2fe4d951f845553a457c32db6f277730764dd7dd7128c5a890f887228cd2/mltrack-0.0.2-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "29fd6ede7e382fd19fe02f844d79998790add819d6c4c80c7a1708569be964b7",
        "md5": "bce672325394c149dff195356493b152",
        "sha256": "4643dfd3824a3ca9f9b8f26838ba4d40de472ec5a82c0af7893666badec0ef39"
      },
      "downloads": -1,
      "filename": "mltrack-0.0.2.tar.gz",
      "has_sig": false,
      "md5_digest": "bce672325394c149dff195356493b152",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 27766,
      "upload_time": "2019-12-09T12:04:11",
      "upload_time_iso_8601": "2019-12-09T12:04:11.363238Z",
      "url": "https://files.pythonhosted.org/packages/29/fd/6ede7e382fd19fe02f844d79998790add819d6c4c80c7a1708569be964b7/mltrack-0.0.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}