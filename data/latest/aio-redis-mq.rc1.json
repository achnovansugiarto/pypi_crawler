{
  "info": {
    "author": "kavinbj",
    "author_email": "kwfelix@163.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Framework :: AsyncIO",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Topic :: Software Development",
      "Topic :: Software Development :: Libraries"
    ],
    "description": "# aio_redis_mq\nLightweight Message Queue & Broker base on async python redis streams\n\n# Suitable Application Environment\nModern software applications have moved from being a single monolithic unit to loosely coupled collections of services.\nWhile this new architecture brings many benefits, those services still need to interact with each other,\n creating the need for robust and efficient messaging solutions.\n \nThe following problems are suitable for using message queuing：\n\n- Asynchronous processing\n- Flow control\n- Service decoupling\n- Connect flow computing\n- As a publish / subscribe system\n\n# Installation\n```bash\npip install aio-redis-mq\n```\n\n## Quick Start ##\n```python\nimport asyncio\nimport time\nfrom aio_redis_mq import MQProducer, MQConsumer\n\n_redis_url = 'redis://root:xxxxx@localhost/1'\n\n\nasync def producer_task(producer):\n    for _ in range(0, 10):\n        await asyncio.sleep(1)\n        send_msg_id = await producer.send_message({'msg': f'msg_{_}', 'content': time.strftime(\"%Y-%m-%d %H:%M:%S\")})\n        print(f'producer_task time at {time.strftime(\"%Y-%m-%d %H:%M:%S\")}', f'message id={send_msg_id}')\n\n\nasync def consumer_task(consumer: MQConsumer, consumer_index: int):\n    for _ in range(0, 10):\n        msg = await consumer.block_read_messages(block=1500)\n        print(f'consumer_{consumer_index} block read message', msg)\n\n\nasync def main():\n    # one producer\n    producer = MQProducer('pub_stream', redis_name='_redis_local', redis_url=_redis_url)\n\n    # three consumer\n    consumer1 = MQConsumer('pub_stream', redis_name='_redis_local', redis_url=_redis_url)\n    consumer2 = MQConsumer('pub_stream', redis_name='_redis_local', redis_url=_redis_url)\n    consumer3 = MQConsumer('pub_stream', redis_name='_redis_local', redis_url=_redis_url)\n\n    await asyncio.gather(\n        producer_task(producer),\n        consumer_task(consumer1, 1),\n        consumer_task(consumer2, 2),\n        consumer_task(consumer3, 3)\n    )\n\nif __name__ == '__main__':\n    asyncio.run(main())\n```\n\n## Group Consumer ##\n```python\nimport asyncio\nimport time\nfrom aio_redis_mq import MQProducer, GroupManager, Group, GroupConsumer\n\n_redis_url = 'redis://root:xxxxx@localhost/1'\n\n\nasync def producer_task(producer):\n    for _ in range(0, 10):\n        await asyncio.sleep(1)\n        print(f'-------------------------------------{_}-------------------------------------')\n        send_msg_id = await producer.send_message({'msg': f'msg_{_}', 'content': time.strftime(\"%Y-%m-%d %H:%M:%S\")})\n        print(f'group_producer send_message time at {time.strftime(\"%Y-%m-%d %H:%M:%S\")}', f'message id={send_msg_id}')\n\n\nasync def consumer_task(consumer: GroupConsumer):\n    for _ in range(0, 10):\n        # Here we use a low-level read message API and do not detect pending messages or handle idle messages\n        msg = await consumer.block_read_messages(count=1, block=1500)\n        await asyncio.sleep(0.05)\n        print(f'group_consumer {consumer.consumer_id} group={consumer.group_name} block read message', msg)\n        if len(msg) > 0 and len(msg[0][1]) > 0:\n            msg_id = msg[0][1][0][0]\n            ack_result = await consumer.ack_message(msg_id)\n            print(f'group_consumer {consumer.consumer_id} group={consumer.group_name} ack message id='\n                  f'{msg_id} {\"successful\" if ack_result else \"failed\"}.')\n\n\n# show info\nasync def show_groups_infor(group: Group):\n    print(f'-----------------------------{group.group_name}---------- groups info ------------------------------------')\n    group_info = await group.get_groups_info()\n    print(f'group name: {group.group_name} groups info : {group_info}')\n    print(f'-----------------------------{group.group_name}--------- consumer info -----------------------------------')\n    consumer_info = await group.get_consumers_info()\n    print(f'group name: {group.group_name} consumer info : {consumer_info}')\n    print(f'-----------------------------{group.group_name}-------- pending info -------------------------------------')\n    pending_info = await group.get_pending_info()\n    print(f'group name: {group.group_name} pending info : {pending_info}')\n\n\nasync def main():\n    # create one producer\n    producer = MQProducer('group_stream1', redis_name='_group_redis_', redis_url=_redis_url)\n\n    # create group manager , via same stream key, same redis_name\n    group_manager = GroupManager('group_stream1', redis_name='_group_redis_', redis_url=_redis_url)\n\n    # create first group\n    group1 = await group_manager.create_group('group1')\n    # create two consumers in the same group\n    consumer1 = await group1.create_consumer('consumer1')\n    consumer2 = await group1.create_consumer('consumer2')\n\n    # create second group\n    group2 = await group_manager.create_group('group2')\n    # create three consumers in the same group\n    consumer3 = await group2.create_consumer('consumer3')\n    consumer4 = await group2.create_consumer('consumer4')\n    consumer5 = await group2.create_consumer('consumer5')\n\n    await asyncio.gather(\n        producer_task(producer),\n        consumer_task(consumer1),\n        consumer_task(consumer2),\n        consumer_task(consumer3),\n        consumer_task(consumer4),\n        consumer_task(consumer5)\n    )\n\n    print('------------------------------------- show total infor -------------------------------------')\n    stream_info = await group_manager.get_stream_info(group_manager.stream_key)\n    print(f'stream_key: {group_manager.stream_key} stream info : {stream_info}')\n\n    await show_groups_infor(group1)\n    await show_groups_infor(group2)\n\n\nif __name__ == '__main__':\n    asyncio.run(main())\n```\n\n## More Example ##\nFor more examples, please query the example folder.\n\n\n# About Redis streams\nThe Redis Stream is a new data type introduced with Redis 5.0, which models a log data structure in a more abstract way. \nRedis Streams doubles as a communication channel for building streaming architectures and as a log-like data structure \nfor persisting data, making Streams the perfect solution for event sourcing.\n\nThe stream type published in redis5.0 is also used to implement typical message queues. \nThe emergence of this stream type meets almost all the requirements of message queues, \nincluding but not limited to:\n- Serialization generation of message ID\n- Message traversal\n- Blocking and non blocking reading of messages\n- Group consumption of messages\n- Unfinished message processing\n- Message queue monitoring\n\n# Comparison of basic concepts\nCommon distributed message system, including RabbitMQ 、 RocketMQ 、 Kafka 、Pulsar 、Redis streams\n\nRedis streams vs Kafka\n\n|Kafka | Redis Streams | Description  |\n|-----------|-------|--------|\n|Record | Message| Objects to be processed in the message engine |\n|Producer |Producer| Clients that publish new messages to topics |\n|Consumer |Consumer| Clients that subscribe to new messages from topics |\n|Consumer Group |Consumer Group| A group composed of multiple consumer instances can consume the same topic at the same time to achieve high throughput.|\n|Broker |Cluster Node| servers form the storage layer. Leader-Follower replica|\n|Topic | Stream Data type | Topics are logical containers that carry messages |\n|partitions |Different Redis keys| Redis Streams  [Differences with Kafka (TM) partitions](https://redis.io/docs/manual/data-types/streams/#differences-with-kafka-tm-partitions)   |\n\n\n# Performance\nYou can use the following tools for performance testing.\n\n[OpenMessaging Benchmark Framework](https://github.com/openmessaging/benchmark)\n\n# API Reference\n\n### MQClient ###\nclient for message system, can manage and query messages. \n\n* #### `__init__(redis_name: Optional[str] = None, redis_url: Optional[str] = None, redis_pool: aioredis.client.Redis = None, **kwargs)` ####\n    create MQ Client instance\n    * `redis_name`: name for cache redis client\n    * `redis_url`:  redis server url\n    * `redis_pool`: aioredis.client.Redis instance, defaults to None\n    \n* #### `get_stream_length(stream_key: KeyT)` ####\n    Returns the number of elements in a given stream.\n    * `stream_key`: key of the stream.\n    \n* #### `query_messages(stream_key: KeyT, min_id: StreamIdT = \"-\", max_id: StreamIdT = \"+\", count: Optional[int] = None)` ####\n    query message value from min_id to max_id with count limit in a given stream.\n    * `stream_key`: key of the stream.\n    * `min_id`: first stream ID. defaults to '-', meaning the earliest available.\n    * `max_id`: last stream ID. defaults to '+', meaning the latest available.\n    * `count`: if set, only return this many items, beginning with the earliest available.\n    \n* #### `reverse_query_messages(stream_key: KeyT, min_id: StreamIdT = \"-\", max_id: StreamIdT = \"+\", count: Optional[int] = None)` ####    \n    query message value in reverse order from min_id to max_id with count limit in a given stream.\n    \n* #### `get_stream_info(stream_key: KeyT)` ####    \n    Returns general information about the stream.\n    \n* #### `delete_message(stream_key: KeyT,  *ids: StreamIdT)` ####    \n    Deletes one or more messages from a stream.\n    * `stream_key`: key of the stream.\n    * `*ids`: message ids to delete.\n\n* #### `trim_stream(stream_key: KeyT,  maxlen: int, approximate: bool = True)` ####    \n    Deletes one or more messages from a stream.    \n    * `stream_key`: key of the stream.\n    * `maxlen`: truncate old stream messages beyond this size\n    * `maxlen`: actual stream length may be slightly more than maxlen\n    \n    ```python\n    client = MQClient(redis_name='my_redis', redis_url='redis://root:xxxxx@localhost/0')\n    \n    # get stream length\n    stream_length = await client.get_stream_length('_test_stream1')\n\n    # get stream info\n    stream_info = await client.get_stream_info('_test_stream1')\n\n    assert stream_info.get('length') == stream_length\n\n    # get first_message_info\n    first_message_info = await client.query_messages('_test_stream1', count=1)\n    # get last_message_info\n    last_message_info = await client.reverse_query_messages('_test_stream1', count=1)\n\n    assert first_message_info[0] == stream_info.get('first-entry')\n    assert last_message_info[0] == stream_info.get('last-entry')\n    ```  \n    \n\n### MQProducer <- MQClient ###\nmessage producer, MQClient with a specific stream key\n\n* #### `__init__(stream_key: KeyT, redis_name: str = None, redis_pool: aioredis.client.Redis = None, **kwargs)` ####\n    message producer in message system based on a specific stream key.\n    * `stream_key`: key of stream\n    * `redis_name`: name for cache redis client\n    * `redis_url`:  redis server url\n    * `redis_pool`: aioredis.client.Redis instance, defaults to None\n\n* #### `send_message(message: Dict[FieldT, EncodableT], msg_id: StreamIdT = \"*\", maxlen: int = None, approximate: bool = True)` ####\n    __Coroutine__. send message content to a stream which is a message container, and return message id.\n    * `message`:  dict of field/value pairs to insert into the stream\n    * `msg_id`:  Location to insert this record. By default it is appended.\n    * `maxlen`:  max number of messages, truncate old stream members beyond this size\n    * `approximate`:  actual stream length may be slightly more than maxlen\n    ```python\n    producer = MQProducer('pub_stream', redis_name='my_redis', redis_url='redis://root:xxxxx@localhost/0')\n    send_msg_id = await producer.send_message({'msg_key1': 'value1', 'msg_key2': 'value2'})\n    ```  \n    \n### MQConsumer <- MQClient ###\nmessage consumer, MQClient with a specific stream key  \n \n* #### `__init__(stream_key: KeyT, redis_name: str = None, redis_pool: aioredis.client.Redis = None, **kwargs)` #### \n    message consumer in message system based on a specific stream key.\n    * `stream_key`: key of stream\n    * `redis_name`: name for cache redis client\n    * `redis_url`:  redis server url\n    * `redis_pool`: aioredis.client.Redis instance, defaults to None\n\n* #### `read_messages(streams: Dict[KeyT, StreamIdT], count: Optional[int] = None)` ####\n    __Coroutine__. read messages from streams as message containers\n    * `streams`:  a dict of stream keys to stream IDs, where IDs indicate the last ID already seen.\n    * `count`:  if set, only return this many items, beginning with the earliest available.\n    \n* #### `block_read_messages(*stream_key: KeyT, count: Optional[int] = None, block: Optional[int] = None,)` ####\n    __Coroutine__. Block and monitor multiple streams for new data.\n    * `stream_key`:  key of the stream.\n    * `count`:  if set, only return this many items, beginning with the earliest available. \n    * `block`:  number of milliseconds to wait, if nothing already present.\n\n    ```python\n    consumer = MQConsumer('pub_stream', redis_name='my_redis', redis_url='redis://root:xxxxx@localhost/0')\n  \n    # block read new message\n    new_msg = await consumer.block_read_messages(block=1500)\n    \n    # read messages from msg_id(0 or other id)  in single stream (pub_stream)\n    read_msgs = await consumer.read_messages({'pub_stream': 0}, count=10)\n    ```  \n\n### GroupManager ###\n* #### `__init__(stream_key: KeyT, redis_name: str = None, **kwargs)` #### \n    group manager in message system based on a specific stream key.\n    * `stream_key`: key of stream\n    * `redis_name`: name for cache redis client\n    * `redis_url`:  redis server url\n    \n* #### `create_group(group_name: GroupT, msg_id: StreamIdT = \"$\", mkstream: bool = True)` #### \n    Create a new group consumer associated with a stream\n    * `group_name`: name of the consumer group\n    * `msg_id`: ID of the last item in the stream to consider already delivered.\n    * `mkstream`:  a boolean indicating whether to create new stream\n\n* #### `destroy_group(group_name: GroupT)` #### \n    Destroy a consumer group\n    * `group_name`: name of the consumer group\n    \n* #### `get_groups_info()` #### \n    Returns general information about the consumer groups of the stream.\n\n    ```python\n    group_manager = GroupManager('pub_stream', redis_name='my_redis', redis_url='redis://root:xxxxx@localhost/0')\n  \n    # create group\n    group = await group_manager.create_group('group')\n    ```      \n\n### Group ###\n* #### `create_consumer(consumer_id: ConsumerT)` #### \n    create a consumer instance in group\n    * `consumer_id`: id of consumer.\n\n* #### `delete_consumer(consumer_id: ConsumerT)` #### \n    Remove a specific consumer from a consumer group.\n    * `consumer_id`: id of consumer.\n    \n* #### `set_msg_id(msg_id: StreamIdT)` #### \n    Set the consumer group last delivered ID to something else.\n    * `msg_id`: ID of the last item in the stream to consider already delivered\n\n* #### `get_groups_info()` #### \n    Returns general information about the consumer groups of the stream.\n\n* #### `get_consumers_info()` #### \n    Returns general information about the consumers in the group. only return consumer which has read message\n\n* #### `get_pending_info()` #### \n    Returns information about pending messages of a group.\n\n* #### `query_pending_messages(min_msg_id: Optional[StreamIdT], max_msg_id: Optional[StreamIdT], count: Optional[int], consumer_id: Optional[ConsumerT] = None)` #### \n    Returns information about pending messages, in a range.\n    * `min_msg_id`: minimum message ID\n    * `max_msg_id`: maximum message ID\n    * `count`: number of messages to return\n    * `consumer_id`: id of a consumer to filter by (optional)\n    \n* #### `ack_message(*msg_id: StreamIdT)` #### \n    Acknowledges the successful processing of one or more messages.\n    * `msg_id`: message ids to acknowledge.\n\n* #### `claim_message(consumer_id: ConsumerT, min_idle_time: int, msg_ids: Union[List[StreamIdT], Tuple[StreamIdT]], idle: Optional[int] = None, time: Optional[int] = None, retrycount: Optional[int] = None, force: bool = False, justid: bool = False)` #### \n    Changes the ownership of a pending message. In the context of a stream consumer group, \n    this command changes the ownership of a pending message, \n    so that the new owner is the consumer specified as the command argument.\n    * `consumer_id`: name of a consumer that claims the message.\n    * `min_idle_time`: filter messages that were idle less than this amount of milliseconds\n    * `msg_ids`: non-empty list or tuple of message IDs to claim\n    * `idle`: Set the idle time (last time it was delivered) of the message in ms\n    * `time`: optional integer. This is the same as idle but instead of a relative amount of milliseconds,\n                     it sets the idle time to a specific Unix time (in milliseconds).\n    * `retrycount`: optional integer. set the retry counter to the specified value.\n                           This counter is incremented every time a message is delivered again.\n    * `force`: optional boolean, false by default. Creates the pending message entry in the PEL\n                      even if certain specified IDs are not already in the PEL assigned to a different client.\n    * `justid`: optional boolean, false by default. Return just an array of IDs of messages successfully\n                      claimed, without returning the actual message\n    \n    \n### GroupConsumer ###\n\n* #### `read_messages(streams: Dict[KeyT, StreamIdT], count: Optional[int] = None, noack: bool = False)` #### \n    Read from a stream via a consumer group.\n    * `streams`: a dict of stream names to stream IDs, where IDs indicate the last ID already seen.\n    * `count`: if set, only return this many items, beginning with the earliest available   \n    * `noack`: do not add messages to the PEL (Pending Entries List) \n    \n* #### `block_read_messages(*stream_key: KeyT, block: Optional[int] = None, count: Optional[int] = None, noack: bool = False)` #### \n    Block read from a stream via a consumer group.\n    * `stream_key`: a list of stream key\n    * `block`: number of milliseconds to wait, if nothing already present.\n    * `count`: if set, only return this many items, beginning with the earliest available\n    * `noack`: do not add messages to the PEL (Pending Entries List) \n    \n* #### `query_pending_messages(min_msg_id: Optional[StreamIdT], max_msg_id: Optional[StreamIdT], count: Optional[int])` #### \n    Returns information about pending messages, in a range.\n    * `min_msg_id`: minimum message ID\n    * `max_msg_id`: maximum message ID\n    * `count`: number of messages to return\n    \n* #### `ack_message(*msg_id: StreamIdT)` #### \n    Acknowledges the successful processing of one or more messages.\n    * `msg_id`: message ids to acknowledge.        \n       \n            \n# Developer\nkavinbj\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "http://github.com/kavinbj/aioRedisMQ",
    "keywords": "asynchronous lightweight message queue system",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "aio-redis-mq",
    "package_url": "https://pypi.org/project/aio-redis-mq/",
    "platform": null,
    "project_url": "https://pypi.org/project/aio-redis-mq/",
    "project_urls": {
      "Homepage": "http://github.com/kavinbj/aioRedisMQ"
    },
    "release_url": "https://pypi.org/project/aio-redis-mq/2.0.0/",
    "requires_dist": [
      "aioredis (>=2.0.0)"
    ],
    "requires_python": ">=3.7",
    "summary": "Lightweight Message Queue & Broker base on async python redis streams",
    "version": "2.0.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14701647,
  "releases": {
    "2.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4e576cc336feffc899f31a8d1977c539c1c2ecd9ac2c75912b7fd9af2737bb13",
          "md5": "ad88dc151ab7316b0aabe40b11743628",
          "sha256": "ab40bab44415ab0c82c914cd7f0cdd808874a51ac5e82d0c38dfbb1171b111da"
        },
        "downloads": -1,
        "filename": "aio_redis_mq-2.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ad88dc151ab7316b0aabe40b11743628",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 18380,
        "upload_time": "2022-08-09T11:58:26",
        "upload_time_iso_8601": "2022-08-09T11:58:26.304543Z",
        "url": "https://files.pythonhosted.org/packages/4e/57/6cc336feffc899f31a8d1977c539c1c2ecd9ac2c75912b7fd9af2737bb13/aio_redis_mq-2.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "08bf09ffadd9a2dd16c5236a4ea96ed5ab9a5ae8a534db70ea463f29407ccc63",
          "md5": "df5a77e083edbaca10ebcbe698520d80",
          "sha256": "f3d2d0ec6823d8254f6309b95d164d5b7ece77cd1863ca2a85ca1662173dffb3"
        },
        "downloads": -1,
        "filename": "aio-redis-mq-2.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "df5a77e083edbaca10ebcbe698520d80",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 17043,
        "upload_time": "2022-08-09T11:58:28",
        "upload_time_iso_8601": "2022-08-09T11:58:28.613338Z",
        "url": "https://files.pythonhosted.org/packages/08/bf/09ffadd9a2dd16c5236a4ea96ed5ab9a5ae8a534db70ea463f29407ccc63/aio-redis-mq-2.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "4e576cc336feffc899f31a8d1977c539c1c2ecd9ac2c75912b7fd9af2737bb13",
        "md5": "ad88dc151ab7316b0aabe40b11743628",
        "sha256": "ab40bab44415ab0c82c914cd7f0cdd808874a51ac5e82d0c38dfbb1171b111da"
      },
      "downloads": -1,
      "filename": "aio_redis_mq-2.0.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "ad88dc151ab7316b0aabe40b11743628",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 18380,
      "upload_time": "2022-08-09T11:58:26",
      "upload_time_iso_8601": "2022-08-09T11:58:26.304543Z",
      "url": "https://files.pythonhosted.org/packages/4e/57/6cc336feffc899f31a8d1977c539c1c2ecd9ac2c75912b7fd9af2737bb13/aio_redis_mq-2.0.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "08bf09ffadd9a2dd16c5236a4ea96ed5ab9a5ae8a534db70ea463f29407ccc63",
        "md5": "df5a77e083edbaca10ebcbe698520d80",
        "sha256": "f3d2d0ec6823d8254f6309b95d164d5b7ece77cd1863ca2a85ca1662173dffb3"
      },
      "downloads": -1,
      "filename": "aio-redis-mq-2.0.0.tar.gz",
      "has_sig": false,
      "md5_digest": "df5a77e083edbaca10ebcbe698520d80",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 17043,
      "upload_time": "2022-08-09T11:58:28",
      "upload_time_iso_8601": "2022-08-09T11:58:28.613338Z",
      "url": "https://files.pythonhosted.org/packages/08/bf/09ffadd9a2dd16c5236a4ea96ed5ab9a5ae8a534db70ea463f29407ccc63/aio-redis-mq-2.0.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}