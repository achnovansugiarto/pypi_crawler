{
  "info": {
    "author": "EMalagoli92",
    "author_email": "emala.892@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Intended Audience :: Developers",
      "Intended Audience :: Education",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3",
      "Topic :: Scientific/Engineering",
      "Topic :: Software Development",
      "Topic :: Software Development :: Libraries",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "<div align=\"center\">\n\n  <a href=\"https://www.tensorflow.org\">![TensorFLow](https://img.shields.io/badge/TensorFlow-2.X-orange?style=for-the-badge) \n  <a href=\"https://github.com/EMalagoli92/GCViT-TensorFlow/blob/main/LICENSE\">![License](https://img.shields.io/github/license/EMalagoli92/GCViT-TensorFlow?style=for-the-badge) \n  <a href=\"https://www.python.org\">![Python](https://img.shields.io/badge/python-%3E%3D%203.9-blue?style=for-the-badge)</a>  \n  \n</div>\n\n# GCViT-TensorFlow\nTensorFlow 2.X reimplementation of [Global Context Vision Transformers](https://arxiv.org/abs/2206.09959) [Ali Hatamizadeh](http://web.cs.ucla.edu/~ahatamiz),\n[Hongxu (Danny) Yin](https://scholar.princeton.edu/hongxu), [Jan Kautz](https://jankautz.com/) [Pavlo Molchanov](https://www.pmolchanov.com/).\n\n- Exact TensorFlow reimplementation of official PyTorch repo, including `timm` modules used by authors, preserving models and layers structure.\n- ImageNet pretrained weights ported from PyTorch official implementation.\n\n## Table of contents\n- [Abstract](#abstract)\n- [Results](#results)\n- [Installation](#installation)\n- [Usage](#usage)\n- [Acknowledgement](#acknowledgement)\n- [Citations](#citations)\n- [License](#license)\n\n<div id=\"abstract\"/>\n\n## Abstract\n*GC ViT  achieves state-of-the-art results across image classification, object detection and semantic segmentation tasks. On ImageNet-1K dataset for classification, the tiny, small and base variants of GC ViT with `28M`, `51M` and `90M`, surpass comparably-sized prior art such as CNN-based ConvNeXt and ViT-based Swin Transformer by a large margin. Pre-trained GC ViT backbones in downstream tasks of object detection, instance segmentation, \nand semantic segmentation using MS COCO and ADE20K datasets outperform prior work consistently, sometimes by large margins.*\n\n![Alt text](https://raw.githubusercontent.com/EMalagoli92/GCViT-TensorFlow/main/assets/images/comp_plots.png?raw=true)\n<p align = \"center\"> <sub>Top-1 accuracy vs. model FLOPs/parameter size on ImageNet-1K dataset. GC ViT achieves\nnew SOTA benchmarks for different model sizes as well as FLOPs, outperforming competing approaches by a\nsignificant margin.</sub> </p>\n\n![Alt text](https://github.com/EMalagoli92/GCViT-TensorFlow/raw/main/assets/images/arch.png?raw=true)\n<p align = \"center\"><sub>Architecture of the Global Context ViT. The authors use alternating blocks of local and global\ncontext self attention layers in each stage of the architecture.</sub></p>\n\n<div id=\"results\"/>\n\n## Results\nTensorFlow implementation and ImageNet ported weights have been compared to the official PyTorch implementation on [ImageNet-V2](https://www.tensorflow.org/datasets/catalog/imagenet_v2) test set.\n\n| Configuration  | Top-1 (Original) | Top-1 (Ported) | Top-5 (Original) | Top-5 (Ported) | #Params\n| ------------- | ------------- | ------------- | ------------- | ------------- | ------------- |\n| GCViT-XXTiny  | 68.79 | 68.73 | 88.52 | 88.47 | 12M |\n| GCViT-XTiny  | 70.97 | 71 | 89.8 | 89.79 | 20M |\n| GCViT-Tiny  | 72.93 | 72.9| 90.7 | 90.7 | 28M | \n| GCViT-Small  | 73.46 | 73.5 | 91.14 | 91.08 | 51M |\n| GCViT-Base  | 74.13 | 74.16 | 91.66 | 91.69 | 90M |\n\nMean metrics difference: `3e-4`.\n\n<div id=\"installation\"/>\n\n## Installation\n- Install from PyPI\n```\npip install gcvit-tensorflow\n```\n- Install from Github\n```\npip install git+https://github.com/EMalagoli92/GCViT-TensorFlow\n```\n- Clone the repo and install necessary packages \n```\ngit clone https://github.com/EMalagoli92/GCViT-TensorFlow.git\npip install -r requirements.txt\n```\n\nTested on *Ubuntu 20.04.4 LTS x86_64*, *python 3.9.7*.\n\n<div id=\"usage\"/>\n\n## Usage\n- Define a custom GCViT configuration.\n```python\nfrom gcvit_tensorflow import GCViT\n\n# Define a custom GCViT configuration\nmodel = GCViT(\n    depths=[2, 2, 6, 2],\n    num_heads=[2, 4, 8, 16],\n    window_size=[7, 7, 14, 7],\n    dim=64,\n    resolution=224,\n    in_chans=3,\n    mlp_ratio=3,\n    drop_path_rate=0.2,\n    data_format=\"channels_last\",\n    num_classes=100,\n    classifier_activation=\"softmax\",\n)\n```\n- Use a predefined GCViT configuration.\n```python\nfrom gcvit_tensorflow import GCViT\n\nmodel = GCViT(configuration=\"xxtiny\")\nmodel.build((None, 224, 224, 3))\nprint(model.summary())\n```\n```\nModel: \"xxtiny\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n patch_embed (PatchEmbed)    (None, 56, 56, 64)        45632     \n                                                                 \n pos_drop (Dropout)          (None, 56, 56, 64)        0         \n                                                                 \n levels/0 (GCViTLayer)       (None, 28, 28, 128)       185766    \n                                                                 \n levels/1 (GCViTLayer)       (None, 14, 14, 256)       693258    \n                                                                 \n levels/2 (GCViTLayer)       (None, 7, 7, 512)         5401104   \n                                                                 \n levels/3 (GCViTLayer)       (None, 7, 7, 512)         5400546   \n                                                                 \n norm (LayerNorm_)           (None, 7, 7, 512)         1024      \n                                                                 \n avgpool (AdaptiveAveragePoo  (None, 512, 1, 1)        0         \n ling2D)                                                         \n                                                                 \n head (Linear_)              (None, 1000)              513000    \n                                                                 \n=================================================================\nTotal params: 12,240,330\nTrainable params: 11,995,428\nNon-trainable params: 244,902\n_________________________________________________________________\n```\n- Train from scratch the model.\n```python    \n# Example\nmodel.compile(\n    optimizer=\"sgd\",\n    loss=\"sparse_categorical_crossentropy\",\n    metrics=[\"accuracy\", \"sparse_top_k_categorical_accuracy\"],\n)\nmodel.fit(x, y)\n```\n- Use ported ImageNet pretrained weights\n```python\n# Example\nfrom gcvit_tensorflow import GCViT\n\nmodel = GCViT(configuration=\"base\", pretrained=True, classifier_activation=\"softmax\")\ny_pred = model(image)\n```\n\n<div id=\"acknowledgement\"/>\n\n## Acknowledgement\n- [GCViT](https://github.com/nvlabs/gcvit) (Official PyTorch implementation)\n- [gcvit_tf](https://github.com/awsaf49/gcvit-tf)\n- [tfgcvit](https://github.com/shkarupa-alex/tfgcvit)\n\n<div id=\"citations\"/>\n\n## Citations\n```bibtex\n@article{hatamizadeh2022global,\n  title={Global Context Vision Transformers},\n  author={Hatamizadeh, Ali and Yin, Hongxu and Kautz, Jan and Molchanov, Pavlo},\n  journal={arXiv preprint arXiv:2206.09959},\n  year={2022}\n}\n```\n\n<div id=\"license\"/>\n\n## License\nThis work is made available under the [MIT License](https://github.com/EMalagoli92/GCViT-TensorFlow/blob/main/LICENSE)\n\nThe pre-trained weights are shared under [CC-BY-NC-SA-4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/)\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/EMalagoli92/GCViT-TensorFlow",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "gcvit-tensorflow",
    "package_url": "https://pypi.org/project/gcvit-tensorflow/",
    "platform": null,
    "project_url": "https://pypi.org/project/gcvit-tensorflow/",
    "project_urls": {
      "Homepage": "https://github.com/EMalagoli92/GCViT-TensorFlow"
    },
    "release_url": "https://pypi.org/project/gcvit-tensorflow/1.2.1/",
    "requires_dist": [
      "absl-py (==1.2.0)",
      "astunparse (==1.6.3)",
      "cachetools (==5.2.0)",
      "certifi (==2022.6.15)",
      "charset-normalizer (==2.1.1)",
      "cloudpickle (==2.1.0)",
      "decorator (==5.1.1)",
      "dm-tree (==0.1.7)",
      "flatbuffers (==1.12)",
      "gast (==0.4.0)",
      "google-auth (==2.11.0)",
      "google-auth-oauthlib (==0.4.6)",
      "google-pasta (==0.2.0)",
      "grpcio (==1.47.0)",
      "h5py (==3.7.0)",
      "idna (==3.3)",
      "importlib-metadata (==4.12.0)",
      "keras (==2.9.0)",
      "Keras-Preprocessing (==1.1.2)",
      "libclang (==14.0.6)",
      "Markdown (==3.4.1)",
      "MarkupSafe (==2.1.1)",
      "numpy (==1.23.1)",
      "oauthlib (==3.2.0)",
      "opt-einsum (==3.3.0)",
      "packaging (==21.3)",
      "protobuf (==3.19.4)",
      "pyasn1 (==0.4.8)",
      "pyasn1-modules (==0.2.8)",
      "pyparsing (==3.0.9)",
      "requests (==2.28.1)",
      "requests-oauthlib (==1.3.1)",
      "rsa (==4.9)",
      "six (==1.16.0)",
      "tensorboard (==2.9.1)",
      "tensorboard-data-server (==0.6.1)",
      "tensorboard-plugin-wit (==1.8.1)",
      "tensorflow (==2.9.0)",
      "tensorflow-addons (==0.17.1)",
      "tensorflow-estimator (==2.9.0)",
      "tensorflow-io-gcs-filesystem (==0.26.0)",
      "tensorflow-probability (==0.17.0)",
      "termcolor (==1.1.0)",
      "typeguard (==2.13.3)",
      "typing-extensions (==4.3.0)",
      "urllib3 (==1.26.12)",
      "Werkzeug (==2.2.2)",
      "wrapt (==1.14.1)",
      "zipp (==3.8.1)"
    ],
    "requires_python": ">=3.9",
    "summary": "TensorFlow 2.X reimplementation of Global Context Vision Transformers, Ali Hatamizadeh, Hongxu (Danny) Yin, Jan Kautz Pavlo Molchanov.",
    "version": "1.2.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16564672,
  "releases": {
    "1.2.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "eabe52c8d0839e566d0c528d54f810f441d714c02bf9dabd721ad21af8235b26",
          "md5": "b958f1e39ac0ba6560783cce80a9a202",
          "sha256": "b226db773991472a106aa9bf30b7379618b4cd2f4fedc91f01508438852a2394"
        },
        "downloads": -1,
        "filename": "gcvit_tensorflow-1.2.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "b958f1e39ac0ba6560783cce80a9a202",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.9",
        "size": 27994,
        "upload_time": "2023-01-25T17:19:18",
        "upload_time_iso_8601": "2023-01-25T17:19:18.302490Z",
        "url": "https://files.pythonhosted.org/packages/ea/be/52c8d0839e566d0c528d54f810f441d714c02bf9dabd721ad21af8235b26/gcvit_tensorflow-1.2.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3dd010c99d70c2903c1a13b476b893d228a4f8b02a6a165caf405293f1e36b67",
          "md5": "3f3f754d760a09ea13d4c07af70b21ee",
          "sha256": "b55527c393e8a2e2e5706f24b4ee1f382b7e5762f380344623634b22bce20aa3"
        },
        "downloads": -1,
        "filename": "gcvit_tensorflow-1.2.1.tar.gz",
        "has_sig": false,
        "md5_digest": "3f3f754d760a09ea13d4c07af70b21ee",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.9",
        "size": 20376,
        "upload_time": "2023-01-25T17:19:19",
        "upload_time_iso_8601": "2023-01-25T17:19:19.653057Z",
        "url": "https://files.pythonhosted.org/packages/3d/d0/10c99d70c2903c1a13b476b893d228a4f8b02a6a165caf405293f1e36b67/gcvit_tensorflow-1.2.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "eabe52c8d0839e566d0c528d54f810f441d714c02bf9dabd721ad21af8235b26",
        "md5": "b958f1e39ac0ba6560783cce80a9a202",
        "sha256": "b226db773991472a106aa9bf30b7379618b4cd2f4fedc91f01508438852a2394"
      },
      "downloads": -1,
      "filename": "gcvit_tensorflow-1.2.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "b958f1e39ac0ba6560783cce80a9a202",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.9",
      "size": 27994,
      "upload_time": "2023-01-25T17:19:18",
      "upload_time_iso_8601": "2023-01-25T17:19:18.302490Z",
      "url": "https://files.pythonhosted.org/packages/ea/be/52c8d0839e566d0c528d54f810f441d714c02bf9dabd721ad21af8235b26/gcvit_tensorflow-1.2.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "3dd010c99d70c2903c1a13b476b893d228a4f8b02a6a165caf405293f1e36b67",
        "md5": "3f3f754d760a09ea13d4c07af70b21ee",
        "sha256": "b55527c393e8a2e2e5706f24b4ee1f382b7e5762f380344623634b22bce20aa3"
      },
      "downloads": -1,
      "filename": "gcvit_tensorflow-1.2.1.tar.gz",
      "has_sig": false,
      "md5_digest": "3f3f754d760a09ea13d4c07af70b21ee",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.9",
      "size": 20376,
      "upload_time": "2023-01-25T17:19:19",
      "upload_time_iso_8601": "2023-01-25T17:19:19.653057Z",
      "url": "https://files.pythonhosted.org/packages/3d/d0/10c99d70c2903c1a13b476b893d228a4f8b02a6a165caf405293f1e36b67/gcvit_tensorflow-1.2.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}