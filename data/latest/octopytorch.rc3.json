{
  "info": {
    "author": "Nicolas Pielawski",
    "author_email": "nicolas@pielawski.fr",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "[![Python 3.9](https://img.shields.io/badge/python-3.9-blue.svg)](https://www.python.org/downloads/release/python-390/) \n![GitHub](https://img.shields.io/github/license/npielawski/pytorch_tiramisu)\n\n# ðŸ”¥ OctoPyTorch: Segmentation Neural Networks ðŸ”¥\n\n## No backbones needed, with a focus on medical images\n\nImplementation of the segmentation neural networks for PyTorch with new features such as:\n\n* ðŸŸ No backbones, the architectures remain simple to understand and train.\n* ðŸ’¾ Memory-efficient version (trade-off between memory and speed).\n* ðŸ–¼ Works with any input size (not only powers of 2 anymore).\n* ðŸ‘ Different types of upsampling (transposed convolution, upsampling and pixel shuffle).\n* ðŸŠâ€â™€ï¸ Different types of pooling (max-pooling, avg-pooling, blur-pooling).\n* ðŸ— The depth and width of the models are fully configurable.\n* ðŸ”¬ Early-transition can be enabled when the input images are big.\n* ðŸ‘¸ðŸ¼ The activation functions of all layers can be modified to something trendier.\n\nFor the Tiramisu architecture:\n* ðŸŽ‰ Won a competition (Adipocyte Cell Imaging Challenge)! [Preprint of the winners is here](https://www.biorxiv.org/content/10.1101/2021.01.18.427121v3).\n* ðŸŽ‰ Was used in a NeurIPS paper! [Abstract and paper are here](https://proceedings.neurips.cc//paper/2020/hash/d6428eecbe0f7dff83fc607c5044b2b9-Abstract.html).\n\n## Roadmap\n\nSupport for the following neural networks:\n- [ ] [U-Net](https://link.springer.com/chapter/10.1007%2F978-3-319-24574-4_28) [[ArXiv](https://arxiv.org/abs/1505.04597)]\n- [x] [Tiramisu](https://ieeexplore.ieee.org/document/8014890) [[ArXiv](https://arxiv.org/abs/1611.09326)]\n- [ ] [UÂ²-Net](https://www.sciencedirect.com/science/article/abs/pii/S0031320320302077) [[ArXiv](https://arxiv.org/abs/2005.09007)]\n- [ ] [PraNet](https://www.springerprofessional.de/en/pranet-parallel-reverse-attention-network-for-polyp-segmentation/18443486) [[ArXiv](https://arxiv.org/abs/2006.11392)]\n\n## Getting Started\n\nThe package can be installed from the repository with:\n\n```console\n> pip3 install octopytorch\n```\n\nYou can try the model in Python with:\n\n```py\nfrom functools import partial\nimport torch\nfrom torch import nn\nfrom octopytorch as octo\n\nmodule_bank = octo.DEFAULT_MODULE_BANK.copy()\n# Dropout\nmodule_bank[octo.ModuleType.DROPOUT] = partial(nn.Dropout2d, p=0.2, inplace=True)\n# Every activation in the model is going to be a GELU (Gaussian Error Linear \n# Units function). GELU(x) = x * Î¦(x)\n# See: https://pytorch.org/docs/stable/generated/torch.nn.GELU.html\nmodule_bank[octo.ModuleType.ACTIVATION] = nn.GELU\n# Example for segmentation:\nmodule_bank[octo.ModuleType.ACTIVATION_FINAL] = partial(nn.LogSoftmax, dim=1)\n# Example for regression (default):\n#module_bank[octo.ModuleType.ACTIVATION_FINAL] = nn.Identity\n\nmodel = octo.models.Tiramisu(\n    in_channels = 3,          # RGB images\n    out_channels = 5,         # 5-channel output (5 classes)\n    init_conv_filters = 48,   # Number of channels outputted by the 1st convolution\n    structure = (\n        [4, 4, 4, 4, 4],      # Down blocks\n        4,                    # bottleneck layers\n        [4, 4, 4, 4, 4],      # Up blocks\n    ),\n    growth_rate = 12,         # Growth rate of the DenseLayers\n    compression = 1.0,        # No compression\n    early_transition = False, # No early transition\n    include_top = True,       # Includes last layer and activation\n    checkpoint = False,       # No memory checkpointing\n    module_bank = module_bank # Modules to use\n)\n\n# Initializes all the convolutional kernel weights.\nmodel.initialize_kernels(nn.init.kaiming_uniform_, conv=True)\n# Shows some information about the model.\nmodel.summary()\n```\n\nThis example tiramisu network has a depth of len(down_blocks) = 5, meaning that the\ninput images should be at least 32x32 pixels (i.e. 2^5=32).\n\n## Documentation\n\nThe parameters of the constructor are explained as following:\n\n* in_channels: The number of channels of the input image (e.g. 1 for grayscale, 3 for\n  RGB).\n* out_channels: The number of output channels (e.g. C for C classes).\n* init_conv_filters: The number of filters in the very first convolution.\n* structure: Divided in three parts (down blocks, bottleneck and up blocks) which\n  describe the depth of the neural network (how many levels there are) and how many\n  DenseLayers each of those levels have.\n* growth_rate: Describes the size of each convolution in the DenseLayers. At each conv.\n  the DenseLayer grows by this many channels.\n* compression: The compression of the DenseLayers to reduce the memory footprint and\n  computational complexity of the model.\n* early_transition: Optimization where the input is downscaled by a factor of two after\n  the first layer by using a down-transition (without skip-connection) early on.\n* include_top: Including the top layer, with the last convolution and activation (True)\n  or returns the embeddings for each pixel.\n* checkpoint: Activates memory checkpointing, a memory efficient version of the\n  Tiramisu. See: [https://arxiv.org/pdf/1707.06990.pdf](https://arxiv.org/pdf/1707.06990.pdf)\n* module_bank: The bank of layers the Tiramisu uses to build itself. See next subsection\n  for details.\n\n### Module bank\n\nThe Tiramisu base layers (e.g. Conv2D, activation functions, etc.) can be set\nto different types of layers. This was introduced to wrap many arguments of the\nmain class under the same object and increase the flexibility to change layers.\n\nThe layers that can be redefined are:\n\n* CONV: Convolution operations in the full model. Change with care.\n* CONV_INIT: Initial (1st) convolution operation. Note: Kernel size must be provided.\n* CONV_FINAL: Final convolution. Will be set to a 1x1 kernel and reduce output to C\n  classes.\n* BATCHNORM: Batch normalization in the full model.\n* POOLING: Pooling operation. Note: must reduce input size by a factor of two. If the\n  size is odd, round *up* to the closest integer.\n* DROPOUT: Dropout. The p value must be provided through partial.\n* UPSAMPLE: Upsampling operation (must be by a factor of two)\n* ACTIVATION: Activation function to use everywhere\n* ACTIVATION_FINAL: Act. function at the last layer (e.g. softmax, nn.Identity)\n\nNotes:\n\n* For pooling common options are nn.MaxPool2d, nn.AvgPool2d, or even\n  tiramisu.layers.blurpool.BlurPool2d.\n* For upsampling, there are some presets: UPSAMPLE_NEAREST (default),\n  UPSAMPLE_PIXELSHUFFLE, UPSAMPLE_TRANSPOSE (known to produce artifacts).\n* The layers can be set to nn.Identity to be bypassed (e.g. if one wants to remove the\n  dropout layer, or the final activation).\n* The partial function can prefill some of the arguments to be used in the model.\n\n## Tips and tricks\n\n* Make sure the features you are interested in fit approximately the perceptive field.\nFor instance, if you have an object that measures 50 pixels, you need at approx. 6\nlevels of resolution in down/up blocks (since 2^6=64 > 50). Or use early transition,\nwhich down samples the input by two.\n* If you need to reduce the memory footprint, trying out the efficient version,\nenabling the early transition is a great way to start. Then, using compression,\nreducing the growth rate and finally the number of dense blocks in the down/up blocks.\n* Use upsampling instead of transposed convolution, seriously. Transposed convolutions\nare hard to manage and [may create a lot of gridding artefacts](https://distill.pub/2016/deconv-checkerboard/).\n* Use blurpooling if you want the neural network to be shift-invariant (good accuracy\neven when shifting the input).\n* The model creates border artifacts at the edge, which can be mitigated by changing\nthe padding_mode argument of the Conv2d in the module bank. For instance, using\n\"reflect\" instead of \"zeros\" will create a smooth continuation in the boundaries\ninstead of an edge.\n\n## Built With\n\n* [Pytorch](https://pytorch.org/) - Version >=1.4.0 (for memory efficient version)\n\n## Contributing\n\nSee also the list of [contributors](https://github.com/npielawski/octopytorch/contributors) who participated in this project.\nFor contributing, make sure the code passes the checks of [Pylama](https://github.com/klen/pylama), [Bandit](https://github.com/PyCQA/bandit) and [Mypy](https://github.com/python/mypy).\nAdditionally, the code is formatted with [Black](https://github.com/psf/black).\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details.\n\n## Acknowledgments\n\nMany thanks to [@RaphaelaHeil](https://github.com/RaphaelaHeil) for her much\nappreciated advices on best practices.",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "octopytorch",
    "package_url": "https://pypi.org/project/octopytorch/",
    "platform": "",
    "project_url": "https://pypi.org/project/octopytorch/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/octopytorch/0.3/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "Segmentation Networks without a Backbone",
    "version": "0.3",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 10286773,
  "releases": {
    "0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "32278c5c3f9e2e62a1ce37fea311d09d7bd98d1dd7f3c6673ff42a0da6b6c860",
          "md5": "30094aba654ad8e949783cc333d8f95a",
          "sha256": "08a6e2b8a556ff7acd3cd970f502b28014e04647bdac99b95d1390b8dfc64474"
        },
        "downloads": -1,
        "filename": "octopytorch-0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "30094aba654ad8e949783cc333d8f95a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 18607,
        "upload_time": "2021-05-07T12:04:21",
        "upload_time_iso_8601": "2021-05-07T12:04:21.167484Z",
        "url": "https://files.pythonhosted.org/packages/32/27/8c5c3f9e2e62a1ce37fea311d09d7bd98d1dd7f3c6673ff42a0da6b6c860/octopytorch-0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e4bc026abe98b616c7f8f6da6d228fc6f6b1781284f7f0d9b60dd5d8c8f0e560",
          "md5": "c11d0b966c04eada518854d54b3bb8f9",
          "sha256": "386911a28534f0caba67edff0f1f1ee1d9256a824a13d8ee3d45dd2a41fae807"
        },
        "downloads": -1,
        "filename": "octopytorch-0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "c11d0b966c04eada518854d54b3bb8f9",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 18758,
        "upload_time": "2021-05-07T12:42:38",
        "upload_time_iso_8601": "2021-05-07T12:42:38.169222Z",
        "url": "https://files.pythonhosted.org/packages/e4/bc/026abe98b616c7f8f6da6d228fc6f6b1781284f7f0d9b60dd5d8c8f0e560/octopytorch-0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f835d273632f6c1478d68cbade0206435b668ae9649a9c400947af67ac84413a",
          "md5": "62e19438b1118009db957fbde9f69ea2",
          "sha256": "ecafa2cbedf5f0e5660956123e68d85efb8eca8b86907f9f841714a169074ccf"
        },
        "downloads": -1,
        "filename": "octopytorch-0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "62e19438b1118009db957fbde9f69ea2",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 18774,
        "upload_time": "2021-05-07T13:16:42",
        "upload_time_iso_8601": "2021-05-07T13:16:42.258789Z",
        "url": "https://files.pythonhosted.org/packages/f8/35/d273632f6c1478d68cbade0206435b668ae9649a9c400947af67ac84413a/octopytorch-0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "f835d273632f6c1478d68cbade0206435b668ae9649a9c400947af67ac84413a",
        "md5": "62e19438b1118009db957fbde9f69ea2",
        "sha256": "ecafa2cbedf5f0e5660956123e68d85efb8eca8b86907f9f841714a169074ccf"
      },
      "downloads": -1,
      "filename": "octopytorch-0.3.tar.gz",
      "has_sig": false,
      "md5_digest": "62e19438b1118009db957fbde9f69ea2",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 18774,
      "upload_time": "2021-05-07T13:16:42",
      "upload_time_iso_8601": "2021-05-07T13:16:42.258789Z",
      "url": "https://files.pythonhosted.org/packages/f8/35/d273632f6c1478d68cbade0206435b668ae9649a9c400947af67ac84413a/octopytorch-0.3.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}