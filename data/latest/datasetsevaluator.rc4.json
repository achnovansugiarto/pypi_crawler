{
  "info": {
    "author": "Brett Kennedy",
    "author_email": "wm.brett.kennedy@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3"
    ],
    "description": "# DatasetsEvaluator\nDatasetTester is a tool to collect datasets from openml.org and make it easier to test predictors (classifiers or regressors) against these files. Our hope is this eases the work required to test predictors and so encourages researchers to test predictors against larger numbers of datasets, taking greater advantage of the collection on openml.org. Ideally, this can lead to greater accuracy and reduced bias in the evaluation of ML tools. \n\n## Installation\n\n`\npip install DatasetsEvaluator\n`\n\n    \n## Examples\n\nThe tool works by calling a series of methods: First: find_datasets() (or find_by_name()). Second: collect_data(). And finally: run_tests(). For example:\n\n```python\nfrom DatasetsEvaluator import DatasetsEvaluator as de\n\ndatasets_tester = de.DatasetsTester()\nmatching_datasets = datasets_tester.find_datasets( \n    problem_type = \"classification\",\n    min_num_classes = 2,\n    max_num_classes = 20,\n    min_num_minority_class = 5,\n    max_num_minority_class = np.inf,\n    min_num_features = 0,\n    max_num_features = np.inf,\n    min_num_instances = 500,\n    max_num_instances = 5_000,\n    min_num_numeric_features = 2,\n    max_num_numeric_features = 50,\n    min_num_categorical_features=0,\n    max_num_categorical_features=50)\n```\nThis returns a pandas dataframe containing the list of datasets on openml.org matching the provided criteria. In this example, we're specifying datasets with between 500 and 5,000 rows, between 2 and 50 numeric columns, and so on.\n\nThe returned list may be examined and the parameters refined if desired. Alternatively, users may call datasets_tester.find_by_name() to specify a specific list of dataset names.\n\nA call is then made such as:\n\n    \n```python\ndatasets_tester.collect_data()\n```\n\nThis will return all datasets identified by the previous call to find_datasets() or find_by_name(). Alternatively, users may specify to return a subset of the datasets identified, for example:\n\n```python\ndatasets_tester.collect_data(max_num_datasets_used=5, method_pick_sets='pick_first', keep_duplicated_names=False)\n```\n\nThis collects the first 5 datasets found above. Note though, as keep_duplicated_names=False is specified, in cases where openml.org has multiple datasets with the same name, but different versions, only the last version will be collected.\n\nA call to run_tests() may then be made to test one or more predictors on the collected datasets. For example:\n\n```python\ndt = tree.DecisionTreeRegressor(min_samples_split=50, max_depth=5, random_state=0)\nknn = KNeighborsRegressor(n_neighbors=10)\n\nsummary_df = datasets_tester.run_tests(estimators_arr = [\n                                        (\"Decision Tree\", \"Original Features\", \"Default\", dt),\n                                        (\"kNN\", \"Original Features\", \"Default\", knn)],\n                                       num_cv_folds=5,\n                                       scoring_metric='r2',\n                                       show_warnings=True) \n\ndisplay(summary_df)\n```\n\nThis compares the accuracy of the created decision tree and kNN classifiers on the collected datasets. \n\nAn example notebook provides further examples. \n\n## Methods\n\n## find_by_name()\n\n```\nfind_by_name(names_arr, problem_type)\n```\nIdentifies, but does not collect, the set of datasets meeting the specified set of names.\n\n**Parameters**\n\n**names_arr** : array of dataset names\n\n**problem_type** : str\n\n**Return Type**\n\nA dataframe with a row for each dataset on openml meeting the specified set of names.\n\n**Discussion**\n\nproblem_type must be either \"classifiction\" or \"regression\". All esimators will be compared using the same metric, so it is necessary that all datasets used are of the same type. \n---\n## find_datasets()\n\n```\nfind_datasets(   problem_type, \n                 min_num_classes=0,\n                 max_num_classes=0,\n                 min_num_minority_class=5,\n                 max_num_minority_class=np.inf, \n                 min_num_features=0,\n                 max_num_features=100,\n                 min_num_instances=500, \n                 max_num_instances=5000, \n                 min_num_numeric_features=0,\n                 max_num_numeric_features=50,\n                 min_num_categorical_features=0,\n                 max_num_categorical_features=50) \n```\n\nThis method collects the data from openml.org, unless check_local_cache is True and the dataset is avaialble \nin the local folder. This will collec the specifed subset of datasets identified by the most recent call \nto find_by_name() or find_datasets(). This allows users to call those methods until a suitable \ncollection of datasets have been identified.\n\n**Parameters**\n\n**problem_type**: str\n\nEither \"classifiction\" or \"regression\". All esimators will be compared using the same metric, so it is necessary that all datasets used are of the same type.\n\nAll other parameters are direct checks of the statistics about each dataset provided by openml.org.\n\n**Return Type**\n\ndataframe with a row for each dataset on openml meeting the specified set of criteria. \n\n\n---\n## collect_datasets()\n\n```\ndef collect_data(max_num_datasets_used=-1,\n                 method_pick_sets=\"pick_first\",\n                 max_cat_unique_vals = 20,\n                 keep_duplicated_names=False,\n                 save_local_cache=False, \n                 check_local_cache=False, \n                 path_local_cache=\"\",\n                 preview_data=False)\n```\n\n#### Parameters\n**max_num_datasets_used**: integer \n    \nThe maximum number of datasets to collect.\n\n**method_pick_sets**: str\n    \nIf only a subset of the full set of matches are to be collected, this identifies if those will be selected randomly, or simply using the first matches\n\n**max_cat_unique_vals**: int\n    \nAs categorical columns are one-hot encoded, it may not be desirable to one-hot encode categorical    columns with large numbers of unique values. Columns with a greater number of unique values than max_cat_unique_vals will be dropped. \n\n**keep_duplicated_names**: bool\n    \nIf False, for each set of datasets with the same name, only the one with the highest version number will be used. \n\n**save_local_cache**: bool\n    \nIf True, any collected datasets will be saved locally in path_local_cache\n\n**check_local_cache**: bool\n    \nIf True, before collecting any datasets from openml.org, each will be checked to determine if it is already stored locally in path_local_cache\n\n**path_local_cache**: str\n\nFolder identify the local cache of datasets, stored in .csv format.\n\n**preview_data**: bool\n    \nIndicates if the first rows of each collected dataset should be displayed\n\n\n**Return Type**\n\nReturns reference to self.\n\n**Discussion**\n\nThis drops any categorical columns with more than max_cat_unique_vals unique values. \nIf keep_duplicated_names is False, then only one version of each dataset name is kept. This can reduce redundant test. In some cases, though, different versions of a dataset are significantly different. \n\n---\n\n## run_tests()\n\n```\nrun_tests(estimators_arr, num_cv_folds=5, scoring_metric='', show_warnings=False)\n```\n\n**Parameters**\n\n**estimators_arr**: array of tuples, with each tuple containing: \n        \n+ str: estimator name, \n+ str: a description of the features used\n+ str: a description of the hyperparameters used\n+ estimator: the estimator to be used. This should not be fit yet, just have the hyperparameters set.\n\n**num_cv_folds**: (int)\n    \nThe number of folds to be used in the cross validation process used to evaluate the predictor\n\n**scoring_metric**: (str) \n    \nOne of the set of scoring metrics supported by sklearn. Set to '' to indicate to use the default. The default for classification is f1_macro and for regression is neg_root_mean_squared_error.\n\n**show_warnings**: (bool) \n    \nif True, warnings will be presented for calls to cross_validate(). These can get very long in in some     cases may affect only a minority of the dataset-predictor combinations, so is False by default. Users may wish to set to True to determine the causes of any NaNs in the final summary dataframe.   \n\n**Return Type**\n\nA dataframe summarizing the performance of the estimators on each dataset. There is one row for each combination of dataset and estimator. \n\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "machine learning classification regression evaulation public datasets",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "DatasetsEvaluator",
    "package_url": "https://pypi.org/project/DatasetsEvaluator/",
    "platform": "",
    "project_url": "https://pypi.org/project/DatasetsEvaluator/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/DatasetsEvaluator/0.0.5/",
    "requires_dist": [
      "numpy",
      "pandas",
      "openml"
    ],
    "requires_python": "",
    "summary": "A tool to automate collecting and testing against datasets on openml.org",
    "version": "0.0.5",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 10790308,
  "releases": {
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7e9bf87f6595a5dc0204adcf01e280a11eb8db46333673306d907756bdb363e5",
          "md5": "e5cd733c36832d4d1edef66cf36c62f4",
          "sha256": "eed62847a7b7eac067102ef8007f07f3923e75f34e72865635eec296502b869a"
        },
        "downloads": -1,
        "filename": "DatasetsEvaluator-0.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "e5cd733c36832d4d1edef66cf36c62f4",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 9931,
        "upload_time": "2021-06-30T20:47:12",
        "upload_time_iso_8601": "2021-06-30T20:47:12.902403Z",
        "url": "https://files.pythonhosted.org/packages/7e/9b/f87f6595a5dc0204adcf01e280a11eb8db46333673306d907756bdb363e5/DatasetsEvaluator-0.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cd37c3b02a6c629893a85275a774a4ea374816fe80bcc96120606197d7ad6a69",
          "md5": "94875a68bf7146cafcb855d949f8da92",
          "sha256": "a55c7d322d3c8dd3a6aa826bdfdfc2f85a31a73be4457a0457a471d20b94177f"
        },
        "downloads": -1,
        "filename": "DatasetsEvaluator-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "94875a68bf7146cafcb855d949f8da92",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 10182,
        "upload_time": "2021-06-30T20:47:14",
        "upload_time_iso_8601": "2021-06-30T20:47:14.449806Z",
        "url": "https://files.pythonhosted.org/packages/cd/37/c3b02a6c629893a85275a774a4ea374816fe80bcc96120606197d7ad6a69/DatasetsEvaluator-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "344ad27925b3a781170b943b3cccb46932110fe44ce6660588d6df11fab03109",
          "md5": "1b6e2a103d779751547a1fe75bc345db",
          "sha256": "9396a036f2e5be68e7f034120716f1b1ce7c318ca2a2942119e08047560f3477"
        },
        "downloads": -1,
        "filename": "DatasetsEvaluator-0.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "1b6e2a103d779751547a1fe75bc345db",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 2005,
        "upload_time": "2021-06-30T21:00:39",
        "upload_time_iso_8601": "2021-06-30T21:00:39.922744Z",
        "url": "https://files.pythonhosted.org/packages/34/4a/d27925b3a781170b943b3cccb46932110fe44ce6660588d6df11fab03109/DatasetsEvaluator-0.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "35d6d981ea6d3bc6eabf7ef1df0fa5126598c2ee0a8c5b2d28fd2c89a910f328",
          "md5": "f27b90d2f1c3ce42307d074b16c59bea",
          "sha256": "9f6af19bc31c07a48307993711a1a22c86f8c9197b967014b31ba5c40fe584bd"
        },
        "downloads": -1,
        "filename": "DatasetsEvaluator-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "f27b90d2f1c3ce42307d074b16c59bea",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 4540,
        "upload_time": "2021-06-30T21:00:41",
        "upload_time_iso_8601": "2021-06-30T21:00:41.567070Z",
        "url": "https://files.pythonhosted.org/packages/35/d6/d981ea6d3bc6eabf7ef1df0fa5126598c2ee0a8c5b2d28fd2c89a910f328/DatasetsEvaluator-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "52dee67206f4e9e6c3dd75bc749963dfabe20a54a87ec1a63e461dbe535ce58e",
          "md5": "818cff0e419d8d4764832dd26ed66f68",
          "sha256": "badc1170ea4929afd000bd71b99b032125a1013683142297abc40103e8df49cc"
        },
        "downloads": -1,
        "filename": "DatasetsEvaluator-0.0.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "818cff0e419d8d4764832dd26ed66f68",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 9804,
        "upload_time": "2021-06-30T21:17:33",
        "upload_time_iso_8601": "2021-06-30T21:17:33.936132Z",
        "url": "https://files.pythonhosted.org/packages/52/de/e67206f4e9e6c3dd75bc749963dfabe20a54a87ec1a63e461dbe535ce58e/DatasetsEvaluator-0.0.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "630b4d9c5f86c809bc746a53e1682083ead3b9560de3f7af6cd7485580236a84",
          "md5": "aef624646642ca2551f2ab4f4a7b4dd2",
          "sha256": "0d197c869f67f5539c013894f37fcca503a854310aa83012ef959efffa5d8e4e"
        },
        "downloads": -1,
        "filename": "DatasetsEvaluator-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "aef624646642ca2551f2ab4f4a7b4dd2",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 8439,
        "upload_time": "2021-06-30T21:17:35",
        "upload_time_iso_8601": "2021-06-30T21:17:35.877697Z",
        "url": "https://files.pythonhosted.org/packages/63/0b/4d9c5f86c809bc746a53e1682083ead3b9560de3f7af6cd7485580236a84/DatasetsEvaluator-0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2b251edf6911aca8da1cbe6d349c3c95dcc4594f6bea36161cedf53df2fa483d",
          "md5": "99820ed975414acc3861b1d11a53962c",
          "sha256": "0707d9e3249c4319cfce10b1a2859220e986f080924d1a8c81e64f7c009b0525"
        },
        "downloads": -1,
        "filename": "DatasetsEvaluator-0.0.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "99820ed975414acc3861b1d11a53962c",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 9916,
        "upload_time": "2021-06-30T21:55:10",
        "upload_time_iso_8601": "2021-06-30T21:55:10.192675Z",
        "url": "https://files.pythonhosted.org/packages/2b/25/1edf6911aca8da1cbe6d349c3c95dcc4594f6bea36161cedf53df2fa483d/DatasetsEvaluator-0.0.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "538c08e1dcd8878da118863e5a17f08e48d0578915cf15aede0bcaa895664ffb",
          "md5": "343a5fac1f300f4ec2a6239abff8642b",
          "sha256": "1008d4ce6ccd89e45144da98b82b4c019c7ed06620e78384fdb858107cfa44ac"
        },
        "downloads": -1,
        "filename": "DatasetsEvaluator-0.0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "343a5fac1f300f4ec2a6239abff8642b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 8611,
        "upload_time": "2021-06-30T21:55:11",
        "upload_time_iso_8601": "2021-06-30T21:55:11.932971Z",
        "url": "https://files.pythonhosted.org/packages/53/8c/08e1dcd8878da118863e5a17f08e48d0578915cf15aede0bcaa895664ffb/DatasetsEvaluator-0.0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "2b251edf6911aca8da1cbe6d349c3c95dcc4594f6bea36161cedf53df2fa483d",
        "md5": "99820ed975414acc3861b1d11a53962c",
        "sha256": "0707d9e3249c4319cfce10b1a2859220e986f080924d1a8c81e64f7c009b0525"
      },
      "downloads": -1,
      "filename": "DatasetsEvaluator-0.0.5-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "99820ed975414acc3861b1d11a53962c",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 9916,
      "upload_time": "2021-06-30T21:55:10",
      "upload_time_iso_8601": "2021-06-30T21:55:10.192675Z",
      "url": "https://files.pythonhosted.org/packages/2b/25/1edf6911aca8da1cbe6d349c3c95dcc4594f6bea36161cedf53df2fa483d/DatasetsEvaluator-0.0.5-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "538c08e1dcd8878da118863e5a17f08e48d0578915cf15aede0bcaa895664ffb",
        "md5": "343a5fac1f300f4ec2a6239abff8642b",
        "sha256": "1008d4ce6ccd89e45144da98b82b4c019c7ed06620e78384fdb858107cfa44ac"
      },
      "downloads": -1,
      "filename": "DatasetsEvaluator-0.0.5.tar.gz",
      "has_sig": false,
      "md5_digest": "343a5fac1f300f4ec2a6239abff8642b",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 8611,
      "upload_time": "2021-06-30T21:55:11",
      "upload_time_iso_8601": "2021-06-30T21:55:11.932971Z",
      "url": "https://files.pythonhosted.org/packages/53/8c/08e1dcd8878da118863e5a17f08e48d0578915cf15aede0bcaa895664ffb/DatasetsEvaluator-0.0.5.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}