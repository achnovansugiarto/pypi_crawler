{
  "info": {
    "author": "Alexandra DeLucia",
    "author_email": "aadelucia@jhu.edu",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Little Bird\n\nBasic utilties for processing Tweets. Includes:  \n* `TweetTokenizer` for tokenizing the Tweet content\n* `TweetReader` for easily iterating over Tweets\n* `TweetWriter` for conveniently writing one or more Tweets to a file in JSONlines format\n\n## Installation\nThere are two options for installing `littlebird`.\n\n### 1. Install from source\n```bash\ngit clone https://github.com/AADeLucia/littlebird.git\ncd littlebird\npython setup.py develop\n```\n\n### 2. Install with `pip`\n```bash\npip install git+git://github.com/AADeLucia/littlebird.git#egg=littlebird\n```\n\n\n## Read and Write a Tweet JSONlines file\nThe example below reads in a Tweet file, filters to Tweets that have a hashtag, and writes out to a new file.\n\n`TweetWriter`can write a single Tweet or list of Tweets to a file in JSONlines format. It will also automatically open a GZIP file if the provided filename has a `.gz` extension. If you are writing to a GZIP file, it is recommended to write all Tweets at once instead of writing incrementally; this provides better file compression. If you do need to write incrementally, I recommend writing to a normal file and GZIPping after.\n\n```python\nfrom littlebird import TweetReader, TweetWriter\n\n# File in JSONlines form. Automatically handles GZIP files.\ntweet_file = \"2014_01_02.json.gz\"\nreader = TweetReader(tweet_file)\n\n# Iterate over Tweets\n# Save Tweets that contain hashtags\nfiltered_tweets = []\nfor tweet in reader.read_tweets():\n    if tweet.get(\"truncated\", False):\n        num_hashtags = len(tweet[\"extended_tweet\"][\"entities\"][\"hashtags\"])\n    else:\n        num_hashtags = len(tweet[\"entities\"][\"hashtags\"])\n    \n    if num_hashtags > 0:\n        filtered_tweets.append(tweet)\n\n# Write out filtered Tweets\nwriter = TweetWriter(\"filtered.json\")\nwriter.write(filtered_tweets)\n```\n\nYou can also skip retweeted and quoted statuses\n\n```python\nfor tweet in reader.read_tweets(skip_retweeted_and_quoted=True):\n```\n\n## Tokenize Tweets\n\nThere are multiple pre-defined tokenizers that are useful for different downstream usecases.\n\n* **TweetTokenizer**: default customizable tokenizer\n* **BERTweetTokenizer**: tokenizer based off the original BERTweet pre-processing from [the BERTweet model repo](https://github.com/VinAIResearch/BERTweet).\n* **GloVeTweetTokenizer**: tokenizer based off a modified version of the [GloVe](https://nlp.stanford.edu/projects/glove/) preprocessor. It's based off of a modified version because the [original ruby processing script](https://nlp.stanford.edu/projects/glove/preprocess-twitter.rb) does not work.\n\nYou can also write your own tokenizer. Examples are below.\n\n### Example usage\nA basic example using the default Tokenizer settings is below.\n\n```python\nfrom littlebird import TweetReader, TweetTokenizer\n\n# File in JSONlines form. Automatically handles GZIP files.\ntweet_file = \"2014_01_02.json.gz\"\nreader = TweetReader(tweet_file)\ntokenizer = TweetTokenizer()\n\n# Iterate over tweets and get the tokenized text.\n# Automatically checks for retweeted and quoted text except if\n# tokenizer = TweetTokenizer(include_retweeted_and_quoted_content=False)\nfor tweet in reader.read_tweets():\n    # Tokenize the Tweet's text\n    tokens = tokenizer.get_tokenized_tweet_text(tweet)\n\n    # Get tweet hashtags. Also includes hashtags from retweeted and quoted statuses\n    hashtags = tokenizer.get_hashtags(tweet)\n```\n\nYou can directly access the internal `tokenize` method with `tokenizer.tokenize(text)`.\n\nIf you do not need to skip over tweets and only need the text, then you can use the `tokenize_tweet_file()` method. This method gets the tokenized text from the entire tweet (retweet, quoted, and full text). \n\n```python\nfrom littlebird import TweetTokenizer\n\ntweet_file = \"2014_01_02.json.gz\"\ntokenizer = TweetTokenizer()\n\n# Returns a tokenized string for each tweet\ntokenized_tweets = tokenizer.tokenize_tweet_file(tweet_file)\n\n# Returns a list of tokens for each tweet\ntokenized_tweets = tokenizer.tokenize_tweet_file(tweet_file, return_tokens=True)\n```\n\n### Tokenizer settings\nAvailable `TweetTokenizer` settings:\n\n* `language`: right now it only really supports English, but as long as you change the `token_pattern` accordingly, it should work with other languages. A future integration is using `Moses` for Arabic tokenization.\n* `token_pattern`: Pattern to match for acceptable tokens. Default is `r\"\\b\\w+\\b\"`\n* `stopwords`: provide a list of stopwords to remove from the text. Default is `None` for no stopword removal.\n* `remove_hashtags`: Default is `False` to keep hashtags in the text (only strips the \"#\" symbol)\n* `lowercase`: Default is `True` to lowercase all of the text. Change this to `False` if you are doing case-sensitive tasks like Name Entity Recognition (NER)\n\nThe tokenizer works in the following steps:\n\n1. Remove hashtags (optional)\n2. Remove URLs, handles, and \"RT\"\n3. Lowercase the text (optional)\n4. Find all tokens that match the `token_pattern` with `regex.findall(token_pattern, text)`\n5. Remove stopwords (optional)\n\n\n#### Token patterns\nThe token pattern is extremely important to set for your use case. Below are some sample token patterns, but I highly recommend [refreshing on your regular expressions](http://www.regular-expressions.info/tutorial.html) if you need something more advanced.\n\n**Note:** the `regex` package is used to access character classes like `\\p{L}`. Basically [Java regex patterns](http://www.regular-expressions.info/tutorial.html).\n\n* `r\"\\b\\w+\\b\"` matches any token with one or more letters, numbers, and underscores. This is equivalent to `\"[\\p{L}\\_\\p{N}]+\"`\n* `r\"\\b\\p{L}+\\b\"` matches any token with one or more \"letters\" (across all alphabets).\n* `r\"\\b[\\w']\\b` matches any token with one or more letters, numbers, and underscores. This pattern also preserves apostraphes \"'\", which is useful for not splitting contractions (e.g. not \"can't\" -> \"can t\"). It does not preserve quotes (e.g. \"She said 'hello'\" -> \"she said hello\")\n\n\n### Writing your own tokenizer\n\nIf you would like to write your own, simply extend the `BaseTweetTokenizer` class. See below and `tweet_tokenizer.py` for examples.\n\n```python\nfrom littlebird import BaseTweetTokenizer\n\nclass NewTweetTokenizer(BaseTweetTokenizer):\n    def __init__(self, include_retweeted_and_quoted_content = True):\n        # Initialize super class\n        super().__init__(include_retweeted_and_quoted_content)\n\n        # Define class variables and settings\n        self.token_pattern = \"aa*\"\n\n    # Overwrite the tokenize method\n    def tokenize(self, tweet):\n        regex.findall(self.token_pattern, tweet)\n        return \n    \n    # Define any helper methods as needed\n    def _helper(self):\n        return\n```\n\n---\n\nThis package is a work in progress. Feel free to open any issues you run into or recommend features. I started this package for my own NLP research with tweets. \n\n```\n@misc{DeLucia2020,\n    author = {Alexandra DeLucia},\n    title = {Little Bird},\n    year = {2020},\n    publisher = {GitHub},\n    journal = {GitHub repository},\n    howpublished = {\\url{https://github.com/aadelucia/littlebird}},\n}\n```\n\nCopyright (c) 2020 Alexandra DeLucia\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/AADeLucia/littlebird",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "littlebird-twitter-utils",
    "package_url": "https://pypi.org/project/littlebird-twitter-utils/",
    "platform": null,
    "project_url": "https://pypi.org/project/littlebird-twitter-utils/",
    "project_urls": {
      "Homepage": "https://github.com/AADeLucia/littlebird"
    },
    "release_url": "https://pypi.org/project/littlebird-twitter-utils/1.0.0/",
    "requires_dist": [
      "jsonlines",
      "regex",
      "filetype",
      "lxml",
      "emoji",
      "nltk"
    ],
    "requires_python": ">=3.6",
    "summary": "Utilities for reading, writing, and processing tweets",
    "version": "1.0.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16440718,
  "releases": {
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0d990195c32596361476e9e33124405ca6db77769314f1ecca120dce7fc34841",
          "md5": "ce4b1fea64f77918b761e440d71dd99f",
          "sha256": "f350ce0b9d75fad4737c3195994eb50368374a2117dc4227d65d7bb3d90f49e6"
        },
        "downloads": -1,
        "filename": "littlebird_twitter_utils-1.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ce4b1fea64f77918b761e440d71dd99f",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 13275,
        "upload_time": "2023-01-16T04:25:38",
        "upload_time_iso_8601": "2023-01-16T04:25:38.087136Z",
        "url": "https://files.pythonhosted.org/packages/0d/99/0195c32596361476e9e33124405ca6db77769314f1ecca120dce7fc34841/littlebird_twitter_utils-1.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "730859f4de71f787217b6306b6cccff4154dea80f350a896d3bc93c3330cac04",
          "md5": "491ea89b2eb6ed0a84721e68cdc22af1",
          "sha256": "b872116eb16aba576a98cda00822ecd9bc494c41247c564fb661059977b51053"
        },
        "downloads": -1,
        "filename": "littlebird-twitter-utils-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "491ea89b2eb6ed0a84721e68cdc22af1",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 13997,
        "upload_time": "2023-01-16T04:25:39",
        "upload_time_iso_8601": "2023-01-16T04:25:39.740288Z",
        "url": "https://files.pythonhosted.org/packages/73/08/59f4de71f787217b6306b6cccff4154dea80f350a896d3bc93c3330cac04/littlebird-twitter-utils-1.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "0d990195c32596361476e9e33124405ca6db77769314f1ecca120dce7fc34841",
        "md5": "ce4b1fea64f77918b761e440d71dd99f",
        "sha256": "f350ce0b9d75fad4737c3195994eb50368374a2117dc4227d65d7bb3d90f49e6"
      },
      "downloads": -1,
      "filename": "littlebird_twitter_utils-1.0.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "ce4b1fea64f77918b761e440d71dd99f",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 13275,
      "upload_time": "2023-01-16T04:25:38",
      "upload_time_iso_8601": "2023-01-16T04:25:38.087136Z",
      "url": "https://files.pythonhosted.org/packages/0d/99/0195c32596361476e9e33124405ca6db77769314f1ecca120dce7fc34841/littlebird_twitter_utils-1.0.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "730859f4de71f787217b6306b6cccff4154dea80f350a896d3bc93c3330cac04",
        "md5": "491ea89b2eb6ed0a84721e68cdc22af1",
        "sha256": "b872116eb16aba576a98cda00822ecd9bc494c41247c564fb661059977b51053"
      },
      "downloads": -1,
      "filename": "littlebird-twitter-utils-1.0.0.tar.gz",
      "has_sig": false,
      "md5_digest": "491ea89b2eb6ed0a84721e68cdc22af1",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 13997,
      "upload_time": "2023-01-16T04:25:39",
      "upload_time_iso_8601": "2023-01-16T04:25:39.740288Z",
      "url": "https://files.pythonhosted.org/packages/73/08/59f4de71f787217b6306b6cccff4154dea80f350a896d3bc93c3330cac04/littlebird-twitter-utils-1.0.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}