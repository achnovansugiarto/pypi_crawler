{
  "info": {
    "author": "Engineering",
    "author_email": "engineering@hybridtheory.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "# FLoC SimHash\n\nThis Python package provides hashing algorithms for computing cohort ids of users based on their browsing history.\nAs such, it may be used to compute cohort ids of users following Google's **Federated Learning of Cohorts** (FLoC) proposal.\n\nThe FLoC proposal is an important part of [The Privacy Sandbox](https://www.chromium.org/Home/chromium-privacy/privacy-sandbox), which is Google's replacement for third-party cookies.\nFLoC will enable interest-based advertising, thus preserving an important source of monetization for today's web.\n\nThe main idea, as outlined in the [FLoC whitepaper](https://raw.githubusercontent.com/google/ads-privacy/master/proposals/FLoC/FLOC-Whitepaper-Google.pdf), is to replace user cookie ids, which enable user-targeting across multiple sites, by _cohort ids_.\nA cohort would consist of a set of users sharing similar browsing behaviour.\nBy targeting a given cohort, advertisers can ensure that relevant ads are shown while user privacy is preserved by a _hiding in the pack_ mechanism.\n\nThe FLoC whitepaper mentions several mechanisms to map users to cohorts, with varying amounts of centralized information.\nThe algorithms [currently](https://blog.google/products/ads-commerce/2021-01-privacy-sandbox/) being implemented in Google Chrome as a POC are methods based on **SimHash**, which is a type of locality-sensitive hashing initially introduced for detecting near-duplicate documents.\n\n## Contents\n\n<!-- toc -->\n\n- [FLoC SimHash](#floc-simhash)\n  - [Contents](#contents)\n  - [Installation](#installation)\n  - [Usage](#usage)\n    - [Individual document-based SimHash](#individual-document-based-simhash)\n      - [Providing your own tokenizer](#providing-your-own-tokenizer)\n    - [Using the SimHashTransformer in scikit-learn pipelines](#using-the-simhashtransformer-in-scikit-learn-pipelines)\n      - [Caveats](#caveats)\n  - [Development](#development)\n\n<!-- tocstop -->\n\n## Installation\n\nThe `floc-simhash` package is available at PyPI. Install using `pip` as follows.\n\n```bash\npip install floc-simhash\n```\n\nThe package requires `python>=3.7` and will install `scikit-learn` as a dependency.\n\n## Usage\n\nThe package provides two main classes.\n\n- `SimHash`, applying the SimHash algorithm on the md5 hashes of tokens in the given document.\n\n- `SimHashTransformer`, applying the SimHash algorithm to a document vectorization as part of a scikit-learn [pipeline](https://scikit-learn.org/stable/modules/compose.html#pipeline)\n\nFinally, there is a third class available:\n\n- `SortingSimHash`, which performs the SortingLSH algorithm by first applying `SimHash` and then clipping the resulting hashes to a given precision.\n\n### Individual document-based SimHash\n\nThe `SimHash` class provides a way to calculate the SimHash of any given document, without using any information coming from other documents.\n\nIn this case, the document hash is computed by looking at md5 hashes of individual tokens.\nWe use:\n\n- The implementation of the md5 hashing algorithm available in the `hashlib` module in the [Python standard library](https://docs.python.org/3/library/hashlib.html).\n\n- Bitwise arithmetic for fast computations of the document hash from the individual hashed tokens.\n\nThe program below, for example, will print the following hexadecimal string: `cf48b038108e698418650807001800c5`.\n\n```python\nfrom floc_simhash import SimHash\n\ndocument = \"Lorem ipsum dolor sit amet consectetur adipiscing elit\"\nhashed_document = SimHash(n_bits=128).hash(document)\n\nprint(hashed_document)\n```\n\nAn example more related to computing cohort ids:\nthe following program computes the cohort id of a user by applying SimHash to the document formed by the pipe-separated list of domains in the user browsing history.\n\n```python\nfrom floc_simhash import SimHash\n\ndocument = \"google.com|hybridtheory.com|youtube.com|reddit.com\"\nhasher = SimHash(n_bits=128, tokenizer=lambda x: x.split(\"|\"))\nhashed_document = hasher.hash(document)\n\nprint(hashed_document)\n```\n\nThe code above will print the hexadecimal string: `14dd1064800880b40025764cd0014715`.\n\n#### Providing your own tokenizer\n\nThe `SimHash` constructor will split the given document according to white space by default.\nHowever, it is possible to pass any callable that parses a string into a list of strings in the `tokenizer` parameter.\nWe have provided an example above where we pass `tokenizer=lambda x: x.split(\"|\")`.\n\nA good example of a more complex tokenization could be passing the [word tokenizer](https://www.nltk.org/api/nltk.tokenize.html#nltk.tokenize.word_tokenize) in NLTK.\nThis would be a nice choice if we wished to compute hashes of text documents.\n\n### Using the SimHashTransformer in scikit-learn pipelines\n\nThe approach to SimHash outlined in the [FLoC Whitepaper](https://raw.githubusercontent.com/google/ads-privacy/master/proposals/FLoC/FLOC-Whitepaper-Google.pdf) consists of choosing random unit vectors and working on already vectorized data.\n\nThe choice of a random unit vector is equivalent to choosing a random hyperplane in feature space.\nChoosing `p` random hyperplanes partitions the feature space into `2^p` regions.\nThen, a `p`-bit SimHash of a vector encodes the region to which it belongs.\n\nIt is reasonable to expect _similar_ documents to have the same hash, provided the vectorization respects the given notion of similarity.\n\nTwo vectorizations are discussed in the aforementioned whitepaper: **one-hot** and **tf-idf**; they are available in [scikit-learn](https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction).\n\nThe `SimHashTransformer` supplies a transformer (implementing the `fit` and `transform` methods) that can be used directly on the output of any of these two vectorizers in order to obtain hashes.\n\nFor example, given a 1d-array `X` containing strings, each of them corresponding to a concatenation of the domains visited by a given user and separated by `\"|\"`, the following code will store in `y` the cohort id of each user, using one-hot encoding and a 32-bit SimHash.\n\n```python\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.pipeline import Pipeline\n\nfrom floc_simhash import SimHashTransformer\n\n\nX = [\n    \"google.com|hybridtheory.com|youtube.com|reddit.com\",\n    \"google.com|youtube.com|reddit.com\",\n    \"github.com\",\n    \"google.com|github.com\",\n]\n\none_hot_simhash = Pipeline(\n    [\n        (\"vect\", CountVectorizer(tokenizer=lambda x: x.split(\"|\"), binary=True)),\n        (\"simhash\", SimHashTransformer(n_bits=32)),\n    ]\n)\n\ny = one_hot_simhash.fit_transform(X)\n```\n\nAfter running this code, the value of `y` would look similar to the following (expect same lengths; actual hash values depend on the choice of random vectors during `fit`):\n\n```python\n['0xd98c7e93' '0xd10b79b3' '0x1085154d' '0x59cd150d']\n```\n\n#### Caveats\n\n- The implementation works on the sparse matrices output by `CountVectorizer` and `TfidfTransformer`, in order to manage memory efficiently.\n\n- At the moment, the choice of precision in the numpy arrays results in overflow errors for `p >= 64`. While we are waiting for implementation details of the FLoC POCs, the first indications hint at choices around `p = 50`.\n\n## Development\n\nThis project uses [poetry](https://python-poetry.org/) for managing dependencies.\n\nIn order to clone the repository and run the unit tests, execute the following steps on an environment with `python>=3.7`.\n\n```bash\ngit clone https://github.com/hybridtheory/floc-simhash.git\ncd floc-simhash\npoetry install\npytest\n```\n\nThe unit tests are property-based, using the [hypothesis](https://hypothesis.readthedocs.io/en/latest/) library.\nThis allows for algorithm veritication against hundreds or thousands of random generated inputs.\n\nSince running many examples may lengthen the test suite runtime, we also use `pytest-xdist` in order to parallelize the tests.\nFor example, the following call will run up to 1000 examples for each test with parallelism 4.\n\n```bash\npytest -n 4 --hypothesis-profile=ci\n```\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/hybridtheory/floc-simhash",
    "keywords": "floc,simhash",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "floc-simhash",
    "package_url": "https://pypi.org/project/floc-simhash/",
    "platform": "",
    "project_url": "https://pypi.org/project/floc-simhash/",
    "project_urls": {
      "Homepage": "https://github.com/hybridtheory/floc-simhash",
      "Repository": "https://github.com/hybridtheory/floc-simhash"
    },
    "release_url": "https://pypi.org/project/floc-simhash/0.1.0/",
    "requires_dist": [
      "scikit-learn (>=0.24.1,<0.25.0)"
    ],
    "requires_python": ">=3.7,<4",
    "summary": "A fast python implementation of the SimHash algorithm",
    "version": "0.1.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 9716866,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "de11c888c983c58aa2cda5ae68e0b85eb0cad67400e91ea447c4bdea43290135",
          "md5": "5b3ff2958f30aedef375ac205e998e5c",
          "sha256": "af75bd8f0f674ccb74dfbbe25e949994745314a4e62b48412fccfda0407c9fd2"
        },
        "downloads": -1,
        "filename": "floc_simhash-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "5b3ff2958f30aedef375ac205e998e5c",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7,<4",
        "size": 8979,
        "upload_time": "2021-03-09T13:08:34",
        "upload_time_iso_8601": "2021-03-09T13:08:34.925159Z",
        "url": "https://files.pythonhosted.org/packages/de/11/c888c983c58aa2cda5ae68e0b85eb0cad67400e91ea447c4bdea43290135/floc_simhash-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0c140dde0fbaab146ceb8c2190bb8b015d6617050526d456b7a37ee4770b457d",
          "md5": "cee4008fad40719bf4a9484b5ff302a5",
          "sha256": "141d894294ac266079c407f6ff3323634fa4a6588d9fd888fd7107a7f6e46902"
        },
        "downloads": -1,
        "filename": "floc-simhash-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "cee4008fad40719bf4a9484b5ff302a5",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7,<4",
        "size": 8141,
        "upload_time": "2021-03-09T13:08:33",
        "upload_time_iso_8601": "2021-03-09T13:08:33.197975Z",
        "url": "https://files.pythonhosted.org/packages/0c/14/0dde0fbaab146ceb8c2190bb8b015d6617050526d456b7a37ee4770b457d/floc-simhash-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "de11c888c983c58aa2cda5ae68e0b85eb0cad67400e91ea447c4bdea43290135",
        "md5": "5b3ff2958f30aedef375ac205e998e5c",
        "sha256": "af75bd8f0f674ccb74dfbbe25e949994745314a4e62b48412fccfda0407c9fd2"
      },
      "downloads": -1,
      "filename": "floc_simhash-0.1.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "5b3ff2958f30aedef375ac205e998e5c",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7,<4",
      "size": 8979,
      "upload_time": "2021-03-09T13:08:34",
      "upload_time_iso_8601": "2021-03-09T13:08:34.925159Z",
      "url": "https://files.pythonhosted.org/packages/de/11/c888c983c58aa2cda5ae68e0b85eb0cad67400e91ea447c4bdea43290135/floc_simhash-0.1.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "0c140dde0fbaab146ceb8c2190bb8b015d6617050526d456b7a37ee4770b457d",
        "md5": "cee4008fad40719bf4a9484b5ff302a5",
        "sha256": "141d894294ac266079c407f6ff3323634fa4a6588d9fd888fd7107a7f6e46902"
      },
      "downloads": -1,
      "filename": "floc-simhash-0.1.0.tar.gz",
      "has_sig": false,
      "md5_digest": "cee4008fad40719bf4a9484b5ff302a5",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7,<4",
      "size": 8141,
      "upload_time": "2021-03-09T13:08:33",
      "upload_time_iso_8601": "2021-03-09T13:08:33.197975Z",
      "url": "https://files.pythonhosted.org/packages/0c/14/0dde0fbaab146ceb8c2190bb8b015d6617050526d456b7a37ee4770b457d/floc-simhash-0.1.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}