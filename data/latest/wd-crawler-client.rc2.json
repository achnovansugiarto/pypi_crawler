{
  "info": {
    "author": "mingwei.jie baozhu.zhang",
    "author_email": "baozhu.zhang@winndoo.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "\n爬虫端部署说明\n## 一、概述\n+ 爬虫框架分三个部分：调度中心、爬虫端、ADSL端。调度中心负责调度任务，爬虫端将任务发送给调度中心，调度中心存储在Redis里面；\n+ ADSL端向调度中心取任务，然后负责下载；\n+ 下载完成后将任务结果送到调度中心，调度中心存储在Redis里面；\n+ 最后爬虫端从调度中心获取结果。\n\n## 二、爬虫端\n爬虫端的部署主要是环境的搭建，具体分两步：\n### 1.Python环境\n用pip安装Twisted 18.9.0，treq 18.6.0以及别的依赖包\n手动安装MySQL-python包\n### 2.爬虫端框架代码\n将dmhe目录下面的crawler和lib目录里面的代码放到服务器上，并将dmhe路径加入Python的根路径里面\n如果使用virtualenv，可以把client_demo/.spider/dmhe目录放到指定的virtualenv下面。比如有一个spider的虚环境，把dmhe目录拷贝到~/.spider/下面\n\n## 三、接口说明\n\n### 1.连接服务器：/connect/\n### 2.断开服务器：/disconnect/\n### 3.发送任务：/task/\n\n## 四、参数说明\n### 1.Crawler对象参数\n>名称\t含义\nuser_id\t用户名\nname\t任务名称\npriority\t任务优先级\n        1：低优先级\n        2：中优先级\n        3：高优先级\ndb_params\t数据库参数\nuser_agent\tuser_agent\n\n###  2.Request对象参数\n#### 名称\t含义\n+  task_id\t任务id\n+ url\t待抓取URL\n+ headers\t请求头（dict）\n+ data\t请求数据，POST请求有效\n+ redirect\t是否支持跳转，默认支持(1)\n+ verify\t是否做https验证，默认支持(1)\n+ is_head\t是否发送HEAD请求，默认不发送(0)\n+ return_header\t是否返回响应头，默认不返回(0)\n+ encoding\t页面编码，默认不指定\n+ timeout\t超时时间，默认30s\n+ retry_times\t抓取失败重试，默认3\n+ extract_type \t解析类型\n>0：不解析 (获取纯页面)\n- response 返回的主要内容： {'body': '', 'code': , 'url_real': '', 'uid': '', 'success': , 'url': '', 'tid': ''}\n>1：解析百度PC排名结果   \n- response 返回的主要内容： {'domain': '', 'title': '', 'url': '', 'url_bd': '', 'rank': , 'id': , 'alading': }\n>2：解析百度移动排名结果\n- response 返回的主要内容： {'domain': '', 'title': '', 'url': '', 'url_bd': '', 'rank': , 'id': , 'alading': }\n>3：解析百度真实URL ---  说明: 获取百度百度真实url时，需设置 is_head=1\n-\n>4：解析百度PC URL是否收录\n\n>5：解析360PC排名结果\n\n>6：解析360移动排名结果\n\n>7：解析搜狗PC排名结果\n\n>8：解析搜狗移动排名结果\n\n>9：解析网页TDK\n- response 返回的主要内容： {'keywords': '', 'keywords': '', 'title': ''}\n+ priority: int， \t请求优先级（只有页面抓取支持）：\n>2：中优先级\n3：高优先级\n+ kwargs\t其他参数 字典\nresp会返回这个参数，如果需要根据不同页面做不同的解析处理，可以使用这个字段\n\n****************************\n参考脚本阅读：\n    1. sample 文件下 insert_sample.py \n    2. 主目录下的 demo.py  demo2.py\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "http://git.winndoo.cn:82/python/download_center/downloader_client.git",
    "keywords": "crawler,wendao",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "wd-crawler-client",
    "package_url": "https://pypi.org/project/wd-crawler-client/",
    "platform": "",
    "project_url": "https://pypi.org/project/wd-crawler-client/",
    "project_urls": {
      "Homepage": "http://git.winndoo.cn:82/python/download_center/downloader_client.git"
    },
    "release_url": "https://pypi.org/project/wd-crawler-client/6.0.2/",
    "requires_dist": [
      "mysqlclient (>=1.4.6)",
      "Twisted (>=18.9.0)",
      "treq (>=18.6.0)"
    ],
    "requires_python": ">=3.6.0",
    "summary": "spider framework for winndoo.",
    "version": "6.0.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 6926278,
  "releases": {
    "6.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "178e9ed7316bdc3c8380041f9f2c939f951e069a329a4721b2c02dfbc3b1a72f",
          "md5": "ef482802b6bd3b9c84afe8969a47d066",
          "sha256": "23018b190fe8b64399a26f093091a4291b511174357c4ed381cd9851ddf5d6df"
        },
        "downloads": -1,
        "filename": "wd_crawler_client-6.0.1-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ef482802b6bd3b9c84afe8969a47d066",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": ">=3.6.0",
        "size": 31646,
        "upload_time": "2020-04-01T08:37:18",
        "upload_time_iso_8601": "2020-04-01T08:37:18.292905Z",
        "url": "https://files.pythonhosted.org/packages/17/8e/9ed7316bdc3c8380041f9f2c939f951e069a329a4721b2c02dfbc3b1a72f/wd_crawler_client-6.0.1-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "92d2d0f77fac7506fa55e4eaf1cc1c23659d11ca968f1aacbd717fd9b85fa9ac",
          "md5": "6ed04733ce035707512b78fa79264a67",
          "sha256": "03c025d2ebc07f65dc123ac329ac3819001832feb9fb58c5ffcf5719e5a4aa08"
        },
        "downloads": -1,
        "filename": "wd-crawler-client-6.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "6ed04733ce035707512b78fa79264a67",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6.0",
        "size": 30946,
        "upload_time": "2020-04-01T08:37:22",
        "upload_time_iso_8601": "2020-04-01T08:37:22.268930Z",
        "url": "https://files.pythonhosted.org/packages/92/d2/d0f77fac7506fa55e4eaf1cc1c23659d11ca968f1aacbd717fd9b85fa9ac/wd-crawler-client-6.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "6.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c3480dda58262c8904b8e59ca7a0898e535c207d3d447de3f70cf9379b976123",
          "md5": "18824ebab5571d3c1cf3549aadb23dd4",
          "sha256": "efd3b4ca72c6b18493c61428d63a2305e53bcc589fb52a209ba9b49440a76de6"
        },
        "downloads": -1,
        "filename": "wd_crawler_client-6.0.2-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "18824ebab5571d3c1cf3549aadb23dd4",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": ">=3.6.0",
        "size": 31403,
        "upload_time": "2020-04-01T08:57:11",
        "upload_time_iso_8601": "2020-04-01T08:57:11.560680Z",
        "url": "https://files.pythonhosted.org/packages/c3/48/0dda58262c8904b8e59ca7a0898e535c207d3d447de3f70cf9379b976123/wd_crawler_client-6.0.2-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cb8be0e9cda47454dafa26bdf28fa63da5663a584419c78039d7ae525d07dbeb",
          "md5": "da467a876f315fa0dc7859b4ecaac97c",
          "sha256": "64461f52d1a79c55f06b96e7081e6927661529eefe252db68e150af0aa1cea49"
        },
        "downloads": -1,
        "filename": "wd-crawler-client-6.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "da467a876f315fa0dc7859b4ecaac97c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6.0",
        "size": 30472,
        "upload_time": "2020-04-01T08:57:12",
        "upload_time_iso_8601": "2020-04-01T08:57:12.786303Z",
        "url": "https://files.pythonhosted.org/packages/cb/8b/e0e9cda47454dafa26bdf28fa63da5663a584419c78039d7ae525d07dbeb/wd-crawler-client-6.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "c3480dda58262c8904b8e59ca7a0898e535c207d3d447de3f70cf9379b976123",
        "md5": "18824ebab5571d3c1cf3549aadb23dd4",
        "sha256": "efd3b4ca72c6b18493c61428d63a2305e53bcc589fb52a209ba9b49440a76de6"
      },
      "downloads": -1,
      "filename": "wd_crawler_client-6.0.2-py2.py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "18824ebab5571d3c1cf3549aadb23dd4",
      "packagetype": "bdist_wheel",
      "python_version": "py2.py3",
      "requires_python": ">=3.6.0",
      "size": 31403,
      "upload_time": "2020-04-01T08:57:11",
      "upload_time_iso_8601": "2020-04-01T08:57:11.560680Z",
      "url": "https://files.pythonhosted.org/packages/c3/48/0dda58262c8904b8e59ca7a0898e535c207d3d447de3f70cf9379b976123/wd_crawler_client-6.0.2-py2.py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "cb8be0e9cda47454dafa26bdf28fa63da5663a584419c78039d7ae525d07dbeb",
        "md5": "da467a876f315fa0dc7859b4ecaac97c",
        "sha256": "64461f52d1a79c55f06b96e7081e6927661529eefe252db68e150af0aa1cea49"
      },
      "downloads": -1,
      "filename": "wd-crawler-client-6.0.2.tar.gz",
      "has_sig": false,
      "md5_digest": "da467a876f315fa0dc7859b4ecaac97c",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6.0",
      "size": 30472,
      "upload_time": "2020-04-01T08:57:12",
      "upload_time_iso_8601": "2020-04-01T08:57:12.786303Z",
      "url": "https://files.pythonhosted.org/packages/cb/8b/e0e9cda47454dafa26bdf28fa63da5663a584419c78039d7ae525d07dbeb/wd-crawler-client-6.0.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}