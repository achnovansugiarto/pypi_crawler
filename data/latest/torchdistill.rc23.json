{
  "info": {
    "author": "Yoshitomo Matsubara",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# torchdistill: A Modular, Configuration-Driven Framework for Knowledge Distillation\n[![PyPI version](https://badge.fury.io/py/torchdistill.svg)](https://badge.fury.io/py/torchdistill)\n[![Build Status](https://travis-ci.com/yoshitomo-matsubara/torchdistill.svg?branch=master)](https://travis-ci.com/github/yoshitomo-matsubara/torchdistill)\n[![GitHub Discussions](https://img.shields.io/github/discussions/yoshitomo-matsubara/torchdistill)](https://github.com/yoshitomo-matsubara/torchdistill/discussions)\n[![DOI:10.1007/978-3-030-76423-4_3](https://zenodo.org/badge/DOI/10.1007/978-3-030-76423-4_3.svg)](https://doi.org/10.1007/978-3-030-76423-4_3)\n\n\n***torchdistill*** (formerly *kdkit*) offers various state-of-the-art knowledge distillation methods \nand enables you to design (new) experiments simply by editing a declarative yaml config file instead of Python code. \nEven when you need to extract intermediate representations in teacher/student models, \nyou will **NOT** need to reimplement the models, that often change the interface of the forward, but instead \nspecify the module path(s) in the yaml file. Refer to [this paper](https://github.com/yoshitomo-matsubara/torchdistill#citation) for more details.  \n\nIn addition to knowledge distillation, this framework helps you design and perform general deep learning experiments\n(**WITHOUT coding**) for reproducible deep learning studies. i.e., it enables you to train models without teachers \nsimply by excluding teacher entries from a declarative yaml config file. \nYou can find such examples below and in [configs/sample/](https://github.com/yoshitomo-matsubara/torchdistill/tree/main/configs/sample/).  \n\nWhen you refer to ***torchdistill*** in your paper, please cite [this paper](https://github.com/yoshitomo-matsubara/torchdistill#citation) \ninstead of this GitHub repository.  \n**Your citation is appreciated and motivates me to maintain and upgrade this framework!** \n\n## Forward hook manager\nUsing **ForwardHookManager**, you can extract intermediate representations in model without modifying the interface of its forward function.  \n[This example notebook](https://github.com/yoshitomo-matsubara/torchdistill/tree/main/demo/extract_intermediate_representations.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/yoshitomo-matsubara/torchdistill/blob/master/demo/extract_intermediate_representations.ipynb) \nwill give you a better idea of the usage such as knowledge distillation and analysis of intermediate representations.\n\n## 1 experiment â†’ 1 declarative PyYAML config file\nIn ***torchdistill***, many components and PyTorch modules are abstracted e.g., models, datasets, optimizers, losses, \nand more! You can define them in a declarative PyYAML config file so that can be seen as a summary of your experiment, \nand in many cases, you will **NOT need to write Python code at all**. \nTake a look at some configurations available in [configs/](https://github.com/yoshitomo-matsubara/torchdistill/tree/main/configs/). You'll see what modules are abstracted and \nhow they are defined in a declarative PyYAML config file to design an experiment.\n\n## Top-1 validation accuracy for ILSVRC 2012 (ImageNet)\n| T: ResNet-34\\*  | Pretrained | KD    | AT    | FT         | CRD   | Tf-KD | SSKD  | L2    | PAD-L2 | KR    |  \n| :---            | ---:       | ---:  | ---:  | ---:       | ---:  | ---:  | ---:  | ---:  | ---:   | ---:  |  \n| S: ResNet-18    | 69.76\\*    | 71.37 | 70.90 | 71.56      | 70.93 | 70.52 | 70.09 | 71.08 | 71.71  | 71.64 |  \n| Original work   | N/A        | N/A   | 70.70 | 71.43\\*\\*  | 71.17 | 70.42 | 71.62 | 70.90 | 71.71  | 71.61 |  \n\n  \n\\* The pretrained ResNet-34 and ResNet-18 are provided by torchvision.  \n\\*\\* FT is assessed with ILSVRC 2015 in the original work.  \nFor the 2nd row (S: ResNet-18), most of the results are reported in [this paper](https://github.com/yoshitomo-matsubara/torchdistill#citation), \nand their checkpoints (trained weights), configuration and log files are [available](https://github.com/yoshitomo-matsubara/torchdistill/tree/main/configs/official/ilsvrc2012/yoshitomo-matsubara/), \nand the configurations reuse the hyperparameters such as number of epochs used in the original work except for KD.\n\n## Examples\nExecutable code can be found in [examples/](https://github.com/yoshitomo-matsubara/torchdistill/tree/main/examples/) such as\n- [Image classification](https://github.com/yoshitomo-matsubara/torchdistill/tree/main/examples/image_classification.py): ImageNet (ILSVRC 2012), CIFAR-10, CIFAR-100, etc\n- [Object detection](https://github.com/yoshitomo-matsubara/torchdistill/tree/main/examples/object_detection.py): COCO 2017, etc\n- [Semantic segmentation](https://github.com/yoshitomo-matsubara/torchdistill/tree/main/examples/semantic_segmentation.py): COCO 2017, PASCAL VOC, etc\n- [Text classification](https://github.com/yoshitomo-matsubara/torchdistill/tree/main/examples/hf_transformers/text_classification.py): GLUE, etc\n\nFor CIFAR-10 and CIFAR-100, some models are reimplemented and available as pretrained models in ***torchdistill***. \nMore details can be found [here](https://github.com/yoshitomo-matsubara/torchdistill/releases/tag/v0.1.1).  \n\nSome Transformer models fine-tuned by ***torchdistill*** for GLUE tasks are available at [Hugging Face Model Hub](https://huggingface.co/yoshitomo-matsubara). \nSample GLUE benchmark results and details can be found [here](https://github.com/yoshitomo-matsubara/torchdistill/tree/master/examples/hf_transformers#sample-benchmark-results-and-fine-tuned-models).\n\n## Google Colab Examples\nThe following examples are available in [demo/](https://github.com/yoshitomo-matsubara/torchdistill/tree/main/demo/). \nNote that the examples are for Google Colab users. Usually, [examples/](https://github.com/yoshitomo-matsubara/torchdistill/tree/main/examples/) would be a better reference \nif you have your own GPU(s).\n\n### CIFAR-10 and CIFAR-100\n- Training without teacher models [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/yoshitomo-matsubara/torchdistill/blob/master/demo/cifar_training.ipynb)\n- Knowledge distillation [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/yoshitomo-matsubara/torchdistill/blob/master/demo/cifar_kd.ipynb)\n\n### GLUE\n- Fine-tuning without teacher models [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/yoshitomo-matsubara/torchdistill/blob/master/demo/glue_finetuning_and_submission.ipynb)\n- Knowledge distillation [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/yoshitomo-matsubara/torchdistill/blob/master/demo/glue_kd_and_submission.ipynb)\n\nThese examples write out test prediction files for you to see the test performance at [the GLUE leaderboard system](https://gluebenchmark.com/).\n\n## PyTorch Hub\nIf you find models on [PyTorch Hub](https://pytorch.org/hub/) or GitHub repositories supporting PyTorch Hub,\nyou can import them as teacher/student models simply by editing a declarative yaml config file.  \n\ne.g., If you use a pretrained ResNeSt-50 available in [rwightman/pytorch-image-models](https://github.com/rwightman/pytorch-image-models)\n(aka *timm*) as a teacher model for ImageNet dataset, you can import the model via PyTorch Hub with the following entry \nin your declarative yaml config file.\n\n```yaml\nmodels:\n  teacher_model:\n    name: 'resnest50d'\n    repo_or_dir: 'rwightman/pytorch-image-models'\n    params:\n      num_classes: 1000\n      pretrained: True\n```\n\n## How to setup\n- Python >= 3.7\n- pipenv (optional)\n\n### Install by pip/pipenv\n```\npip3 install torchdistill\n# or use pipenv\npipenv install torchdistill\n```\n\n### Install from this repository \n```\ngit clone https://github.com/yoshitomo-matsubara/torchdistill.git\ncd torchdistill/\npip3 install -e .\n# or use pipenv\npipenv install \"-e .\"\n```\n\n## Issues / Questions / Requests\nThe documentation is work-in-progress. In the meantime, feel free to create an issue if you find a bug.  \nIf you have either a question or feature request, start a new discussion [here](https://github.com/yoshitomo-matsubara/torchdistill/discussions).\nPlease make sure the issue/question/request has not been addressed yet by searching through the issues and discussions.\n\n## Citation\nIf you use ***torchdistill*** in your research, please cite the following paper.  \n[[Paper](https://link.springer.com/chapter/10.1007/978-3-030-76423-4_3)] [[Preprint](https://arxiv.org/abs/2011.12913)]  \n```bibtex\n@inproceedings{matsubara2021torchdistill,\n  title={torchdistill: A Modular, Configuration-Driven Framework for Knowledge Distillation},\n  author={Matsubara, Yoshitomo},\n  booktitle={International Workshop on Reproducible Research in Pattern Recognition},\n  pages={24--44},\n  year={2021},\n  organization={Springer}\n}\n```\n\n## References\n- [:mag:](https://github.com/yoshitomo-matsubara/torchdistill/tree/main/examples/image_classification.py) [pytorch/vision/references/classification/](https://github.com/pytorch/vision/blob/main/references/classification/)\n- [:mag:](https://github.com/yoshitomo-matsubara/torchdistill/tree/main/examples/object_detection.py) [pytorch/vision/references/detection/](https://github.com/pytorch/vision/tree/main/references/detection/)\n- [:mag:](https://github.com/yoshitomo-matsubara/torchdistill/tree/main/examples/semantic_segmentation.py) [pytorch/vision/references/segmentation/](https://github.com/pytorch/vision/tree/main/references/segmentation/)\n- [:mag:](https://github.com/yoshitomo-matsubara/torchdistill/tree/main/examples/hf_transformers/text_classification.py) [huggingface/transformers/examples/pytorch/text-classification](https://github.com/huggingface/transformers/tree/main/examples/pytorch/text-classification)\n- [:mag:](https://github.com/yoshitomo-matsubara/torchdistill/tree/main/configs/sample/ilsvrc2012/single_stage/kd) Geoffrey Hinton, Oriol Vinyals and Jeff Dean. [\"Distilling the Knowledge in a Neural Network\"](https://fb56552f-a-62cb3a1a-s-sites.googlegroups.com/site/deeplearningworkshopnips2014/65.pdf?attachauth=ANoY7co8sQACDsEYLkP11zqEAxPgYHLwkdkDP9NHfEB6pzQOUPmfWf3cVrL3WE7PNyed-lrRsF7CY6Tcme5OEQ92CTSN4f8nDfJcgt71fPtAvcTvH5BpzF-2xPvLkPAvU9Ub8XvbySAPOsMKMWmGsXG2FS1_X1LJsUfuwKdQKYVVTtRfG5LHovLHIwv6kXd3mOkDKEH7YdoyYQqjSv6ku2KDjOpVQBt0lKGVPXeRdwUcD0mxDqCe4u8%3D&attredirects=1) (Deep Learning and Representation Learning Workshop: NeurIPS 2014)\n- [:mag:](https://github.com/yoshitomo-matsubara/torchdistill/tree/main/configs/sample/ilsvrc2012/multi_stage/fitnet) Adriana Romero, Nicolas Ballas, Samira Ebrahimi Kahou, Antoine Chassang, Carlo Gatta and Yoshua Bengio. [\"FitNets: Hints for Thin Deep Nets\"](https://arxiv.org/abs/1412.6550) (ICLR 2015)\n- [:mag:](https://github.com/yoshitomo-matsubara/torchdistill/tree/main/configs/sample/ilsvrc2012/multi_stage/fsp) Junho Yim, Donggyu Joo, Jihoon Bae and Junmo Kim. [\"A Gift From Knowledge Distillation: Fast Optimization, Network Minimization and Transfer Learning\"](http://openaccess.thecvf.com/content_cvpr_2017/html/Yim_A_Gift_From_CVPR_2017_paper.html) (CVPR 2017)\n- [:mag:](https://github.com/yoshitomo-matsubara/torchdistill/tree/main/configs/sample/ilsvrc2012/single_stage/at) Sergey Zagoruyko and Nikos Komodakis. [\"Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer\"](https://openreview.net/forum?id=Sks9_ajex) (ICLR 2017)\n- [:mag:](https://github.com/yoshitomo-matsubara/torchdistill/tree/main/configs/sample/ilsvrc2012/single_stage/pkt) Nikolaos Passalis and Anastasios Tefas. [\"Learning Deep Representations with Probabilistic Knowledge Transfer\"](http://openaccess.thecvf.com/content_ECCV_2018/html/Nikolaos_Passalis_Learning_Deep_Representations_ECCV_2018_paper.html) (ECCV 2018)\n- [:mag:](https://github.com/yoshitomo-matsubara/torchdistill/tree/main/configs/sample/ilsvrc2012/multi_stage/ft) Jangho Kim, Seonguk Park and Nojun Kwak. [\"Paraphrasing Complex Network: Network Compression via Factor Transfer\"](http://papers.neurips.cc/paper/7541-paraphrasing-complex-network-network-compression-via-factor-transfer) (NeurIPS 2018)\n- [:mag:](https://github.com/yoshitomo-matsubara/torchdistill/tree/main/configs/sample/ilsvrc2012/multi_stage/dab) Byeongho Heo, Minsik Lee, Sangdoo Yun and Jin Young Choi. [\"Knowledge Transfer via Distillation of Activation Boundaries Formed by Hidden Neurons\"](https://aaai.org/ojs/index.php/AAAI/article/view/4264) (AAAI 2019)\n- [:mag:](https://github.com/yoshitomo-matsubara/torchdistill/tree/main/configs/sample/coco2017/multi_stage/ktaad) Tong He, Chunhua Shen, Zhi Tian, Dong Gong, Changming Sun, Youliang Yan. [\"Knowledge Adaptation for Efficient Semantic Segmentation\"](https://openaccess.thecvf.com/content_CVPR_2019/html/He_Knowledge_Adaptation_for_Efficient_Semantic_Segmentation_CVPR_2019_paper.html) (CVPR 2019)\n- [:mag:](https://github.com/yoshitomo-matsubara/torchdistill/tree/main/configs/sample/ilsvrc2012/single_stage/rkd) Wonpyo Park, Dongju Kim, Yan Lu and Minsu Cho. [\"Relational Knowledge Distillation\"](http://openaccess.thecvf.com/content_CVPR_2019/html/Park_Relational_Knowledge_Distillation_CVPR_2019_paper.html) (CVPR 2019)\n- [:mag:](https://github.com/yoshitomo-matsubara/torchdistill/tree/main/configs/sample/ilsvrc2012/single_stage/vid) Sungsoo Ahn, Shell Xu Hu, Andreas Damianou, Neil D. Lawrence and Zhenwen Dai. [\"Variational Information Distillation for Knowledge Transfer\"](http://openaccess.thecvf.com/content_CVPR_2019/html/Ahn_Variational_Information_Distillation_for_Knowledge_Transfer_CVPR_2019_paper.html) (CVPR 2019)\n- [:mag:](https://github.com/yoshitomo-matsubara/torchdistill/tree/main/configs/sample/ilsvrc2012/single_stage/hnd) Yoshitomo Matsubara, Sabur Baidya, Davide Callegaro, Marco Levorato and Sameer Singh. [\"Distilled Split Deep Neural Networks for Edge-Assisted Real-Time Systems\"](https://dl.acm.org/doi/10.1145/3349614.3356022) (Workshop on Hot Topics in Video Analytics and Intelligent Edges: MobiCom 2019)\n- [:mag:](https://github.com/yoshitomo-matsubara/torchdistill/tree/main/configs/sample/ilsvrc2012/single_stage/cckd) Baoyun Peng, Xiao Jin, Jiaheng Liu, Dongsheng Li, Yichao Wu, Yu Liu, Shunfeng Zhou and Zhaoning Zhang. [\"Correlation Congruence for Knowledge Distillation\"](http://openaccess.thecvf.com/content_ICCV_2019/html/Peng_Correlation_Congruence_for_Knowledge_Distillation_ICCV_2019_paper.html) (ICCV 2019)\n- [:mag:](https://github.com/yoshitomo-matsubara/torchdistill/tree/main/configs/sample/ilsvrc2012/single_stage/spkd) Frederick Tung and Greg Mori. [\"Similarity-Preserving Knowledge Distillation\"](http://openaccess.thecvf.com/content_ICCV_2019/html/Tung_Similarity-Preserving_Knowledge_Distillation_ICCV_2019_paper.html) (ICCV 2019)\n- [:mag:](https://github.com/yoshitomo-matsubara/torchdistill/tree/main/configs/sample/ilsvrc2012/single_stage/crd) Yonglong Tian, Dilip Krishnan and Phillip Isola. [\"Contrastive Representation Distillation\"](https://openreview.net/forum?id=SkgpBJrtvS) (ICLR 2020)\n- [:mag:](https://github.com/yoshitomo-matsubara/torchdistill/tree/main/configs/sample/coco2017/single_stage/ghnd) Yoshitomo Matsubara and Marco Levorato. [\"Neural Compression and Filtering for Edge-assisted Real-time Object Detection in Challenged Networks\"](https://arxiv.org/abs/2007.15818) (ICPR 2020)\n- [:mag:](https://github.com/yoshitomo-matsubara/torchdistill/tree/main/configs/sample/ilsvrc2012/single_stage/tfkd) Li Yuan, Francis E.H.Tay, Guilin Li, Tao Wang and Jiashi Feng. [\"Revisiting Knowledge Distillation via Label Smoothing Regularization\"](https://openaccess.thecvf.com/content_CVPR_2020/papers/Yuan_Revisiting_Knowledge_Distillation_via_Label_Smoothing_Regularization_CVPR_2020_paper.pdf) (CVPR 2020)\n- [:mag:](https://github.com/yoshitomo-matsubara/torchdistill/tree/main/configs/sample/ilsvrc2012/multi_stage/sskd) Guodong Xu, Ziwei Liu, Xiaoxiao Li and Chen Change Loy. [\"Knowledge Distillation Meets Self-Supervision\"](http://www.ecva.net/papers/eccv_2020/papers_ECCV/html/898_ECCV_2020_paper.php) (ECCV 2020)\n- [:mag:](https://github.com/yoshitomo-matsubara/torchdistill/tree/main/configs/sample/ilsvrc2012/multi_stage/pad) Youcai Zhang, Zhonghao Lan, Yuchen Dai, Fangao Zeng, Yan Bai, Jie Chang and Yichen Wei. [\"Prime-Aware Adaptive Distillation\"](http://www.ecva.net/papers/eccv_2020/papers_ECCV/html/3317_ECCV_2020_paper.php) (ECCV 2020)\n- [:mag:](https://github.com/yoshitomo-matsubara/torchdistill/tree/main/configs/sample/ilsvrc2012/single_stage/kr) Pengguang Chen, Shu Liu, Hengshuang Zhao, Jiaya Jia. [\"Distilling Knowledge via Knowledge Review\"](https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Distilling_Knowledge_via_Knowledge_Review_CVPR_2021_paper.html) (CVPR 2021)\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/yoshitomo-matsubara/torchdistill",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "torchdistill",
    "package_url": "https://pypi.org/project/torchdistill/",
    "platform": null,
    "project_url": "https://pypi.org/project/torchdistill/",
    "project_urls": {
      "Homepage": "https://github.com/yoshitomo-matsubara/torchdistill"
    },
    "release_url": "https://pypi.org/project/torchdistill/0.3.3/",
    "requires_dist": [
      "torch (>=1.11.0)",
      "torchvision (>=0.12.0)",
      "numpy",
      "pyyaml (>=5.4.1)",
      "scipy",
      "cython",
      "pycocotools (>=2.0.2)",
      "pytest ; extra == 'test'"
    ],
    "requires_python": ">=3.7",
    "summary": "A Modular, Configuration-Driven Framework for Knowledge Distillation. Trained models, training logs and configurations are available for ensuring the reproducibiliy.",
    "version": "0.3.3",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 15708418,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e1554cba4859fa409509990926c54122b21ff29ff254bf49c1ba2b75cedc0c0f",
          "md5": "32a87412a7fa00840826519d867980e4",
          "sha256": "dfb9fe2fbcf2f84db79b2d325cdb59cd8ef53a3ee7a99f8a27efd9d216b62031"
        },
        "downloads": -1,
        "filename": "torchdistill-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "32a87412a7fa00840826519d867980e4",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 61933,
        "upload_time": "2020-11-25T07:56:34",
        "upload_time_iso_8601": "2020-11-25T07:56:34.951228Z",
        "url": "https://files.pythonhosted.org/packages/e1/55/4cba4859fa409509990926c54122b21ff29ff254bf49c1ba2b75cedc0c0f/torchdistill-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e5092de9235fe12ddd32b8b43cf4515828784345ecfdfa1ca543f0f2e66de09d",
          "md5": "6422c864d9e2d4d8f1d63602e83ce43a",
          "sha256": "ad6cf6e93567100931d0d28f4e9363f3b122d6ecc98ead749a58a68d8c30cf55"
        },
        "downloads": -1,
        "filename": "torchdistill-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "6422c864d9e2d4d8f1d63602e83ce43a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 51089,
        "upload_time": "2020-11-25T07:56:36",
        "upload_time_iso_8601": "2020-11-25T07:56:36.164975Z",
        "url": "https://files.pythonhosted.org/packages/e5/09/2de9235fe12ddd32b8b43cf4515828784345ecfdfa1ca543f0f2e66de09d/torchdistill-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f536a966a2ff8e005e6487ba21e7443d2e91fae5468a9a91e9a5da6a10b85646",
          "md5": "1d3be608f2d060dbd96fb3a7fab56789",
          "sha256": "67a28a54685d637be92c9406117dd4ce1bf0fd9cbccea3229af56bbc2eae8bf8"
        },
        "downloads": -1,
        "filename": "torchdistill-0.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "1d3be608f2d060dbd96fb3a7fab56789",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 62311,
        "upload_time": "2020-12-04T18:39:45",
        "upload_time_iso_8601": "2020-12-04T18:39:45.719955Z",
        "url": "https://files.pythonhosted.org/packages/f5/36/a966a2ff8e005e6487ba21e7443d2e91fae5468a9a91e9a5da6a10b85646/torchdistill-0.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1ace236ca8745e08845c459c45172a917da1ce840a8a4fe27f8eb03be99b3e27",
          "md5": "8b67d40f06dbe8c22e7932ef740ea6de",
          "sha256": "00633ed23ad4b57a0d25b527a81d2671e0334e1cf7e66322e4087bb0083bbf31"
        },
        "downloads": -1,
        "filename": "torchdistill-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "8b67d40f06dbe8c22e7932ef740ea6de",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 51705,
        "upload_time": "2020-12-04T18:39:46",
        "upload_time_iso_8601": "2020-12-04T18:39:46.860862Z",
        "url": "https://files.pythonhosted.org/packages/1a/ce/236ca8745e08845c459c45172a917da1ce840a8a4fe27f8eb03be99b3e27/torchdistill-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b05c12d1925bf76b59fe281aba4289bb059ecde59294a61c583f6954c94fe2b9",
          "md5": "5295c01c11a70de9dd6c1085edd9fe8f",
          "sha256": "5d4fcecd7372a449025427922e434dd067fc05c655cd423fcb14bf8b00b3bdad"
        },
        "downloads": -1,
        "filename": "torchdistill-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "5295c01c11a70de9dd6c1085edd9fe8f",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 72839,
        "upload_time": "2020-12-27T18:27:16",
        "upload_time_iso_8601": "2020-12-27T18:27:16.038402Z",
        "url": "https://files.pythonhosted.org/packages/b0/5c/12d1925bf76b59fe281aba4289bb059ecde59294a61c583f6954c94fe2b9/torchdistill-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ed1db57bb9b9713366f25d5b1b0d78b414795dc32059d54c0ea7a23d1e9df96b",
          "md5": "417830a2095e7e468311057a65b6222e",
          "sha256": "a06018f4ff986061afc8c679798604edb53390c218475898b156620bc8babbd8"
        },
        "downloads": -1,
        "filename": "torchdistill-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "417830a2095e7e468311057a65b6222e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 57005,
        "upload_time": "2020-12-27T18:27:17",
        "upload_time_iso_8601": "2020-12-27T18:27:17.081303Z",
        "url": "https://files.pythonhosted.org/packages/ed/1d/b57bb9b9713366f25d5b1b0d78b414795dc32059d54c0ea7a23d1e9df96b/torchdistill-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "dcd23aef90eb55e95e2d75d1ff0ccf999390ee150c9e02f759d7708c4ae5e403",
          "md5": "9f03158a26d87b248e0cf463dc02a6ee",
          "sha256": "9d97bc114f5c35671592fb5801c9ca052ead91b2a731b42bdf564ba37241102a"
        },
        "downloads": -1,
        "filename": "torchdistill-0.1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "9f03158a26d87b248e0cf463dc02a6ee",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 72839,
        "upload_time": "2020-12-27T19:22:21",
        "upload_time_iso_8601": "2020-12-27T19:22:21.327653Z",
        "url": "https://files.pythonhosted.org/packages/dc/d2/3aef90eb55e95e2d75d1ff0ccf999390ee150c9e02f759d7708c4ae5e403/torchdistill-0.1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "34c33f682c08dedef499e0eb0e9b83d2ac519ade88ee0d74b979fc6358b2e64d",
          "md5": "ab909ccf102586491eaedc7cf7beac63",
          "sha256": "bf5891071cfa4f2511d304a56e4f7ce98692e715d10081e22e755c4e2cd07550"
        },
        "downloads": -1,
        "filename": "torchdistill-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "ab909ccf102586491eaedc7cf7beac63",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 57028,
        "upload_time": "2020-12-27T19:22:22",
        "upload_time_iso_8601": "2020-12-27T19:22:22.456234Z",
        "url": "https://files.pythonhosted.org/packages/34/c3/3f682c08dedef499e0eb0e9b83d2ac519ade88ee0d74b979fc6358b2e64d/torchdistill-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ebe51ec0f6352ff53a6e760bc15b1b02cbaa37b4d9296bf1169a9d182dec4910",
          "md5": "464e5bf76dd82b8c2cca478ee95f8d87",
          "sha256": "95e3ed95543ab081bdbf7e95f0d4edc6e9f2224262fee24d9c64698f1fa65963"
        },
        "downloads": -1,
        "filename": "torchdistill-0.1.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "464e5bf76dd82b8c2cca478ee95f8d87",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 73265,
        "upload_time": "2021-01-11T02:08:27",
        "upload_time_iso_8601": "2021-01-11T02:08:27.790978Z",
        "url": "https://files.pythonhosted.org/packages/eb/e5/1ec0f6352ff53a6e760bc15b1b02cbaa37b4d9296bf1169a9d182dec4910/torchdistill-0.1.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1ddc4bc336f67c1260ad93f3f662ff945c0d0a9b2cd1ea2bd6b64097c4f1ae10",
          "md5": "f6f55291926372f8736409524c17f8ab",
          "sha256": "fad3d32e4ea0bee1066f24599976beab44ce6044a675c42f76838686ba071c7d"
        },
        "downloads": -1,
        "filename": "torchdistill-0.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "f6f55291926372f8736409524c17f8ab",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 57477,
        "upload_time": "2021-01-11T02:08:29",
        "upload_time_iso_8601": "2021-01-11T02:08:29.073077Z",
        "url": "https://files.pythonhosted.org/packages/1d/dc/4bc336f67c1260ad93f3f662ff945c0d0a9b2cd1ea2bd6b64097c4f1ae10/torchdistill-0.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fe2fb9394437cdfeac49c7e0c18652fac09c6fca6931eb0ca65809078342cd79",
          "md5": "aacd33b9cab5058aabfefc319b3f688a",
          "sha256": "ac834e0c38dcc82a466bbc21336a2ae363f498944fac2185e02237cba9ce47b0"
        },
        "downloads": -1,
        "filename": "torchdistill-0.1.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "aacd33b9cab5058aabfefc319b3f688a",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 74522,
        "upload_time": "2021-02-06T23:43:24",
        "upload_time_iso_8601": "2021-02-06T23:43:24.529686Z",
        "url": "https://files.pythonhosted.org/packages/fe/2f/b9394437cdfeac49c7e0c18652fac09c6fca6931eb0ca65809078342cd79/torchdistill-0.1.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7e67588d720f93c58489d7e896b79e50ebb72a2fea7bb8d7dd0740a11925cf23",
          "md5": "fb48ed7c0aaf1e59db2f80d284c90984",
          "sha256": "ca5c5f51006cb01e232e7ad3316690b8364fe599dc1bbdddc2bce3e201f1b07d"
        },
        "downloads": -1,
        "filename": "torchdistill-0.1.3.tar.gz",
        "has_sig": false,
        "md5_digest": "fb48ed7c0aaf1e59db2f80d284c90984",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 58277,
        "upload_time": "2021-02-06T23:43:25",
        "upload_time_iso_8601": "2021-02-06T23:43:25.865166Z",
        "url": "https://files.pythonhosted.org/packages/7e/67/588d720f93c58489d7e896b79e50ebb72a2fea7bb8d7dd0740a11925cf23/torchdistill-0.1.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "eec25480469a8d92f5daec56bf4f886d784a251cc2dac4fa11061c4eb3519fc3",
          "md5": "2ef9c27f578db92dc5452bb749e6399e",
          "sha256": "a09ee0d5789e492e3ebb805519027d49d1653d7e9d52095ca7e537b21a1ee0f4"
        },
        "downloads": -1,
        "filename": "torchdistill-0.1.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "2ef9c27f578db92dc5452bb749e6399e",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 74926,
        "upload_time": "2021-02-21T23:01:18",
        "upload_time_iso_8601": "2021-02-21T23:01:18.106920Z",
        "url": "https://files.pythonhosted.org/packages/ee/c2/5480469a8d92f5daec56bf4f886d784a251cc2dac4fa11061c4eb3519fc3/torchdistill-0.1.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "73b8757bdf878cf8268b167719a41c4acb2fe70d8719f28f3a507b931b5d6a46",
          "md5": "4b177b92bb14ca191f2010b5060e434c",
          "sha256": "0ade9d7caaf818c6504674ca34878ac981b057917000b51f040f016ce58b8985"
        },
        "downloads": -1,
        "filename": "torchdistill-0.1.4.tar.gz",
        "has_sig": false,
        "md5_digest": "4b177b92bb14ca191f2010b5060e434c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 58599,
        "upload_time": "2021-02-21T23:01:19",
        "upload_time_iso_8601": "2021-02-21T23:01:19.280940Z",
        "url": "https://files.pythonhosted.org/packages/73/b8/757bdf878cf8268b167719a41c4acb2fe70d8719f28f3a507b931b5d6a46/torchdistill-0.1.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d5e8f81df20c703f9fb6b896d5929b7f91c9be6c51c4e335afb6ecdb3ff2401e",
          "md5": "3ff9d6970c44c28e55e9a388a1a1c770",
          "sha256": "207bd888ab22a10d10c0c5729a3b6c3faebdf6bdda4bd013310475cf4d23b0b9"
        },
        "downloads": -1,
        "filename": "torchdistill-0.1.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "3ff9d6970c44c28e55e9a388a1a1c770",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 75317,
        "upload_time": "2021-03-22T05:59:19",
        "upload_time_iso_8601": "2021-03-22T05:59:19.427156Z",
        "url": "https://files.pythonhosted.org/packages/d5/e8/f81df20c703f9fb6b896d5929b7f91c9be6c51c4e335afb6ecdb3ff2401e/torchdistill-0.1.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2b60c55334367b718049d391b4dba63f39c6527b1efdeb2627ecca43a388acdc",
          "md5": "01480bf116db083255ae7d8a162b8ae6",
          "sha256": "ff3a2509ffa9a347c76edc41459692b27756128eb708612177f74e08af0b5a2e"
        },
        "downloads": -1,
        "filename": "torchdistill-0.1.5.tar.gz",
        "has_sig": false,
        "md5_digest": "01480bf116db083255ae7d8a162b8ae6",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 59265,
        "upload_time": "2021-03-22T05:59:20",
        "upload_time_iso_8601": "2021-03-22T05:59:20.667023Z",
        "url": "https://files.pythonhosted.org/packages/2b/60/c55334367b718049d391b4dba63f39c6527b1efdeb2627ecca43a388acdc/torchdistill-0.1.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "36a4e342b798dff5f49bf1bb6c93cecda441cebe9d1388eb9b9ea3753548f56c",
          "md5": "5d20e75887d572acfffe90ec29b709a5",
          "sha256": "2baf174404086fbc0c6b68f595a415f782877be24d8f48f639c14cadf471598b"
        },
        "downloads": -1,
        "filename": "torchdistill-0.1.6-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "5d20e75887d572acfffe90ec29b709a5",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 77334,
        "upload_time": "2021-04-09T05:58:38",
        "upload_time_iso_8601": "2021-04-09T05:58:38.265026Z",
        "url": "https://files.pythonhosted.org/packages/36/a4/e342b798dff5f49bf1bb6c93cecda441cebe9d1388eb9b9ea3753548f56c/torchdistill-0.1.6-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "579c814c00abde00cdee9d2c33927f637746f4d504cbb758a1ed8864f69bcbdf",
          "md5": "18910042a84f885e816866470f84ca1d",
          "sha256": "c304ed422c2936efdec5423b1782d8128905bf957828fa87e2b8864279601a6a"
        },
        "downloads": -1,
        "filename": "torchdistill-0.1.6.tar.gz",
        "has_sig": false,
        "md5_digest": "18910042a84f885e816866470f84ca1d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 60835,
        "upload_time": "2021-04-09T05:58:39",
        "upload_time_iso_8601": "2021-04-09T05:58:39.709762Z",
        "url": "https://files.pythonhosted.org/packages/57/9c/814c00abde00cdee9d2c33927f637746f4d504cbb758a1ed8864f69bcbdf/torchdistill-0.1.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1d1e98c4591040d5ba7b849432e4bc6a575a8c87aa228fa043cbfb1ead9695be",
          "md5": "c49a448c5d957ecaf52cd86f1be74dc0",
          "sha256": "0485db7359a515826c5a7a4573a909c7a0d5e6723c011b0d05a9f3428abfd31f"
        },
        "downloads": -1,
        "filename": "torchdistill-0.2.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "c49a448c5d957ecaf52cd86f1be74dc0",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 78057,
        "upload_time": "2021-05-05T03:57:54",
        "upload_time_iso_8601": "2021-05-05T03:57:54.159069Z",
        "url": "https://files.pythonhosted.org/packages/1d/1e/98c4591040d5ba7b849432e4bc6a575a8c87aa228fa043cbfb1ead9695be/torchdistill-0.2.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e80c5102f901c43a08dadad7a3f02091fa5981d54b2fd75d74176d04d70c1e81",
          "md5": "bef4212ea628ce8e9956e40807690708",
          "sha256": "60d6d5743278fb851fbee730cd95516174b992881bb41d407fc6ffbaed047ade"
        },
        "downloads": -1,
        "filename": "torchdistill-0.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "bef4212ea628ce8e9956e40807690708",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 61899,
        "upload_time": "2021-05-05T03:57:56",
        "upload_time_iso_8601": "2021-05-05T03:57:56.338780Z",
        "url": "https://files.pythonhosted.org/packages/e8/0c/5102f901c43a08dadad7a3f02091fa5981d54b2fd75d74176d04d70c1e81/torchdistill-0.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "70c17e28cde90e7eaa7ec424a495be7021a537e4d048d7341e2186427d14ca0f",
          "md5": "18d7effd029f8759fa3db512ffb7853f",
          "sha256": "f56d2acf2e47ae4b3de886ad88db3f54d4bcb5c21b1236218387e153a7d9d63f"
        },
        "downloads": -1,
        "filename": "torchdistill-0.2.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "18d7effd029f8759fa3db512ffb7853f",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 78452,
        "upload_time": "2021-05-25T03:11:15",
        "upload_time_iso_8601": "2021-05-25T03:11:15.240243Z",
        "url": "https://files.pythonhosted.org/packages/70/c1/7e28cde90e7eaa7ec424a495be7021a537e4d048d7341e2186427d14ca0f/torchdistill-0.2.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e54486d144cff64a004070c9fc5da7043bb1776a174cc25f75dab7eaa06baf76",
          "md5": "7f717918d936de110023635fe1d27873",
          "sha256": "6ab882f448ab22e5c679c6c11dad97827b5e1343f575b2fd277a2c06a07f9cbf"
        },
        "downloads": -1,
        "filename": "torchdistill-0.2.1.tar.gz",
        "has_sig": false,
        "md5_digest": "7f717918d936de110023635fe1d27873",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 62804,
        "upload_time": "2021-05-25T03:11:16",
        "upload_time_iso_8601": "2021-05-25T03:11:16.596061Z",
        "url": "https://files.pythonhosted.org/packages/e5/44/86d144cff64a004070c9fc5da7043bb1776a174cc25f75dab7eaa06baf76/torchdistill-0.2.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1a5c451852a4c72c573f5a57e58f66a7961e9a9790d005b9f1ede4fcf31a6338",
          "md5": "7522099e9f29a5428029cb34b2743d10",
          "sha256": "ead97cb7e568083d6447524e8826996f7861398c2965e8a1f73d077d6a43eb4e"
        },
        "downloads": -1,
        "filename": "torchdistill-0.2.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "7522099e9f29a5428029cb34b2743d10",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 78466,
        "upload_time": "2021-06-23T10:49:28",
        "upload_time_iso_8601": "2021-06-23T10:49:28.800580Z",
        "url": "https://files.pythonhosted.org/packages/1a/5c/451852a4c72c573f5a57e58f66a7961e9a9790d005b9f1ede4fcf31a6338/torchdistill-0.2.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8a8a1808d5f010d5c0f4e52381bd850044106000a83e5fe6c0a6d6bd24a68355",
          "md5": "acce354b27c5cafc33d32073d7beeea4",
          "sha256": "f7643eba653a15661924b0f704b61bff67891c590341178e811efb7b987cd630"
        },
        "downloads": -1,
        "filename": "torchdistill-0.2.2.tar.gz",
        "has_sig": false,
        "md5_digest": "acce354b27c5cafc33d32073d7beeea4",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 62793,
        "upload_time": "2021-06-23T10:49:30",
        "upload_time_iso_8601": "2021-06-23T10:49:30.545185Z",
        "url": "https://files.pythonhosted.org/packages/8a/8a/1808d5f010d5c0f4e52381bd850044106000a83e5fe6c0a6d6bd24a68355/torchdistill-0.2.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "479ad47f3c31789f83ce77d525842fd98d651e289982c4e5cb2590c912fafd06",
          "md5": "1388fa41e80d9733eb123c821852dd86",
          "sha256": "ea8e59d285c43ad2aa8e020a0ea4ee786c3b1e2aa20e21e12b220c5630f3780e"
        },
        "downloads": -1,
        "filename": "torchdistill-0.2.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "1388fa41e80d9733eb123c821852dd86",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 78531,
        "upload_time": "2021-06-30T12:17:03",
        "upload_time_iso_8601": "2021-06-30T12:17:03.929046Z",
        "url": "https://files.pythonhosted.org/packages/47/9a/d47f3c31789f83ce77d525842fd98d651e289982c4e5cb2590c912fafd06/torchdistill-0.2.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5650c60fa9462c2604f01474762b25cd4eb105fbfaa4e123ffd8aa0ae2ececd4",
          "md5": "9a2c6f7a2399f3e4aef65fb38167599f",
          "sha256": "9490753510bc40d0763e8611ae1a5f8dc2d63db43e146bae1e059be5e89cdd06"
        },
        "downloads": -1,
        "filename": "torchdistill-0.2.3.tar.gz",
        "has_sig": false,
        "md5_digest": "9a2c6f7a2399f3e4aef65fb38167599f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 62840,
        "upload_time": "2021-06-30T12:17:05",
        "upload_time_iso_8601": "2021-06-30T12:17:05.571592Z",
        "url": "https://files.pythonhosted.org/packages/56/50/c60fa9462c2604f01474762b25cd4eb105fbfaa4e123ffd8aa0ae2ececd4/torchdistill-0.2.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a1de33c7bdb8d7847586001b4d0f557e831e0fb5b333d24d1627696346c2a6ce",
          "md5": "ee58d34ab2797f8432f3fd0b76b93cca",
          "sha256": "ab6a1022cb75e5902540bd9eed2cab369d07ab885e81b664304cdf8ad279be38"
        },
        "downloads": -1,
        "filename": "torchdistill-0.2.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ee58d34ab2797f8432f3fd0b76b93cca",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 78653,
        "upload_time": "2021-07-15T11:29:01",
        "upload_time_iso_8601": "2021-07-15T11:29:01.592954Z",
        "url": "https://files.pythonhosted.org/packages/a1/de/33c7bdb8d7847586001b4d0f557e831e0fb5b333d24d1627696346c2a6ce/torchdistill-0.2.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "be040f621d0a481727d37756ed9dbfb553c2ddb736f5663cc6a114e5db1fd99c",
          "md5": "d65e2c446a1f3e66cf8e0ef77829ec55",
          "sha256": "8e0243317cd3269fc2cb094174a627f47b8171330f8f19e5f872c79c143cbd80"
        },
        "downloads": -1,
        "filename": "torchdistill-0.2.4.tar.gz",
        "has_sig": false,
        "md5_digest": "d65e2c446a1f3e66cf8e0ef77829ec55",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 63181,
        "upload_time": "2021-07-15T11:29:03",
        "upload_time_iso_8601": "2021-07-15T11:29:03.151997Z",
        "url": "https://files.pythonhosted.org/packages/be/04/0f621d0a481727d37756ed9dbfb553c2ddb736f5663cc6a114e5db1fd99c/torchdistill-0.2.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "61a2b2314ca9e06c8296542b7b2425aae0046628359f1b70d301f070146197b2",
          "md5": "0072ea185a6a3dd70e58620d149d4ed8",
          "sha256": "f15bb4f9543019492fb297e4668db6299e06447b3d3bf2e694dd8014daa4e7ea"
        },
        "downloads": -1,
        "filename": "torchdistill-0.2.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0072ea185a6a3dd70e58620d149d4ed8",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 79757,
        "upload_time": "2021-08-01T01:23:06",
        "upload_time_iso_8601": "2021-08-01T01:23:06.934511Z",
        "url": "https://files.pythonhosted.org/packages/61/a2/b2314ca9e06c8296542b7b2425aae0046628359f1b70d301f070146197b2/torchdistill-0.2.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8134daedf45d538c33aefb378630165da0789557e569506b5a08cd50fdf4aba6",
          "md5": "aee949332bf6c1660ad803ce2362f150",
          "sha256": "1f6c4a378065ec7a8332218aa78bc58d6e39bc699837f2f8b5c984524072c3f1"
        },
        "downloads": -1,
        "filename": "torchdistill-0.2.5.tar.gz",
        "has_sig": false,
        "md5_digest": "aee949332bf6c1660ad803ce2362f150",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 64407,
        "upload_time": "2021-08-01T01:23:08",
        "upload_time_iso_8601": "2021-08-01T01:23:08.621485Z",
        "url": "https://files.pythonhosted.org/packages/81/34/daedf45d538c33aefb378630165da0789557e569506b5a08cd50fdf4aba6/torchdistill-0.2.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "560dd7cb37f78b701e13d0eabff9d675a102f580972a00e7b45abeb776c12861",
          "md5": "ca0d853b8b765880bebdabcbcb439c8b",
          "sha256": "e057ccbbaaadf507f7a701a642fbe40d63acf86d1a34aa863f6f5e8d021052cd"
        },
        "downloads": -1,
        "filename": "torchdistill-0.2.6-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ca0d853b8b765880bebdabcbcb439c8b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 80521,
        "upload_time": "2021-09-14T09:59:26",
        "upload_time_iso_8601": "2021-09-14T09:59:26.688441Z",
        "url": "https://files.pythonhosted.org/packages/56/0d/d7cb37f78b701e13d0eabff9d675a102f580972a00e7b45abeb776c12861/torchdistill-0.2.6-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5461e56cc6d0de411744e60900c56d7e61d27689478e2d3d3d7132856cc9316f",
          "md5": "003a2396817f7e0b2048a15e44522d72",
          "sha256": "4257a832fe9595c6be77e868f2f4245410ea6a8d9fddaefd58cb45330e0abe28"
        },
        "downloads": -1,
        "filename": "torchdistill-0.2.6.tar.gz",
        "has_sig": false,
        "md5_digest": "003a2396817f7e0b2048a15e44522d72",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 65347,
        "upload_time": "2021-09-14T09:59:28",
        "upload_time_iso_8601": "2021-09-14T09:59:28.351682Z",
        "url": "https://files.pythonhosted.org/packages/54/61/e56cc6d0de411744e60900c56d7e61d27689478e2d3d3d7132856cc9316f/torchdistill-0.2.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "920ad90947c8ea1e2a7762153ab0b56740c9ff05013e1d4211ad6e8e4e02ebbb",
          "md5": "7195d03fd20dbe5dd80de20108befed0",
          "sha256": "016cb776cd3eaee452a4090e901de9acdf3b4a72b9f4883001cce0b3a3143e96"
        },
        "downloads": -1,
        "filename": "torchdistill-0.2.7-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "7195d03fd20dbe5dd80de20108befed0",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 80630,
        "upload_time": "2021-10-28T00:51:03",
        "upload_time_iso_8601": "2021-10-28T00:51:03.671294Z",
        "url": "https://files.pythonhosted.org/packages/92/0a/d90947c8ea1e2a7762153ab0b56740c9ff05013e1d4211ad6e8e4e02ebbb/torchdistill-0.2.7-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6a74569328bb6029e890ebcf2946ce2096c2ab2e7daa1b97068bc460f59a3ae3",
          "md5": "81fe40ef14d63ab1820eb8486f8af953",
          "sha256": "fc03247af8e97b5280d290a5fbd1793c67cf127c675a3f94c6020539b2d8d061"
        },
        "downloads": -1,
        "filename": "torchdistill-0.2.7.tar.gz",
        "has_sig": false,
        "md5_digest": "81fe40ef14d63ab1820eb8486f8af953",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 65091,
        "upload_time": "2021-10-28T00:51:05",
        "upload_time_iso_8601": "2021-10-28T00:51:05.266168Z",
        "url": "https://files.pythonhosted.org/packages/6a/74/569328bb6029e890ebcf2946ce2096c2ab2e7daa1b97068bc460f59a3ae3/torchdistill-0.2.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "62bad86e7de08e41f5519a59c4c048216f9044d1f0ee5fa1360a4a44405f3cf4",
          "md5": "0a599cf92ea6a70db78e3d4ba37fc278",
          "sha256": "a8c727a22a26443ed040981a1db861d79d231afb756768c2351cd72488aad9d7"
        },
        "downloads": -1,
        "filename": "torchdistill-0.2.8-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0a599cf92ea6a70db78e3d4ba37fc278",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 81169,
        "upload_time": "2021-12-17T04:31:16",
        "upload_time_iso_8601": "2021-12-17T04:31:16.593620Z",
        "url": "https://files.pythonhosted.org/packages/62/ba/d86e7de08e41f5519a59c4c048216f9044d1f0ee5fa1360a4a44405f3cf4/torchdistill-0.2.8-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c555010c72e67cc7214105882fee6883222edb5c269fa10f2cfefc14a5abdced",
          "md5": "faedb3f6f9acff20c8dab4ae00539b90",
          "sha256": "79d13bcfccc843e2d52671fd5408f027e94691abf96e52c3fea4f099b8c0d111"
        },
        "downloads": -1,
        "filename": "torchdistill-0.2.8.tar.gz",
        "has_sig": false,
        "md5_digest": "faedb3f6f9acff20c8dab4ae00539b90",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 65599,
        "upload_time": "2021-12-17T04:31:18",
        "upload_time_iso_8601": "2021-12-17T04:31:18.144378Z",
        "url": "https://files.pythonhosted.org/packages/c5/55/010c72e67cc7214105882fee6883222edb5c269fa10f2cfefc14a5abdced/torchdistill-0.2.8.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.9": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "71daaeadaa90053834583e203191a7d83468c130b174651869e5582e838394a2",
          "md5": "d6b26909f5bba16ba223b48384ae9291",
          "sha256": "6407876fbe3410728dd1ba50435f676d594aa01e59697371f5c8f7531ab1bc56"
        },
        "downloads": -1,
        "filename": "torchdistill-0.2.9-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d6b26909f5bba16ba223b48384ae9291",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 81300,
        "upload_time": "2021-12-26T01:43:49",
        "upload_time_iso_8601": "2021-12-26T01:43:49.787743Z",
        "url": "https://files.pythonhosted.org/packages/71/da/aeadaa90053834583e203191a7d83468c130b174651869e5582e838394a2/torchdistill-0.2.9-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "27fec701d399692f7486878075b88959ba84e9192e61138ef57a73d936b6b1ac",
          "md5": "9ae1cb08ea009e06542b1e40c5a877eb",
          "sha256": "8af4219afd5a3bc3a6d7d82bab747d087d1f85cc70a530523301c11678855f1d"
        },
        "downloads": -1,
        "filename": "torchdistill-0.2.9.tar.gz",
        "has_sig": false,
        "md5_digest": "9ae1cb08ea009e06542b1e40c5a877eb",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 65723,
        "upload_time": "2021-12-26T01:43:51",
        "upload_time_iso_8601": "2021-12-26T01:43:51.378824Z",
        "url": "https://files.pythonhosted.org/packages/27/fe/c701d399692f7486878075b88959ba84e9192e61138ef57a73d936b6b1ac/torchdistill-0.2.9.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7af29ec2092e7af9aceccc099efdb4fca9d0529f3d11bbb3529c0e21b023f3f7",
          "md5": "d1b24b0c267bb339b2a817f3503da1e6",
          "sha256": "3c762a2add737b0c9d1d9f234fe23d1494cfbbe2f9a01ee931ccd20e9ebf6f39"
        },
        "downloads": -1,
        "filename": "torchdistill-0.3.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d1b24b0c267bb339b2a817f3503da1e6",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 81302,
        "upload_time": "2021-12-26T02:07:53",
        "upload_time_iso_8601": "2021-12-26T02:07:53.724246Z",
        "url": "https://files.pythonhosted.org/packages/7a/f2/9ec2092e7af9aceccc099efdb4fca9d0529f3d11bbb3529c0e21b023f3f7/torchdistill-0.3.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2321619c0509c5502f364b44a0d29fd25ba64b27a6e1514f463e5c6ebb3e0428",
          "md5": "86c08dfc7a4c7687b8231ec975860995",
          "sha256": "ffaf88e81c92f18759ccd810f8ce2efb173e8f4daaf3627014b7b47fe9565b61"
        },
        "downloads": -1,
        "filename": "torchdistill-0.3.0.tar.gz",
        "has_sig": false,
        "md5_digest": "86c08dfc7a4c7687b8231ec975860995",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 65718,
        "upload_time": "2021-12-26T02:07:55",
        "upload_time_iso_8601": "2021-12-26T02:07:55.651752Z",
        "url": "https://files.pythonhosted.org/packages/23/21/619c0509c5502f364b44a0d29fd25ba64b27a6e1514f463e5c6ebb3e0428/torchdistill-0.3.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7c17690082817ee48d68c0cda34b6e0f3ab17aa3a9d4c0f501c5512bdb536107",
          "md5": "706b75d8b29f829f2f39cf4d1da708f2",
          "sha256": "6e84438cd66d2dfb83dc9523f04a71d092c110585ce322e05c4e5b817a6f94e3"
        },
        "downloads": -1,
        "filename": "torchdistill-0.3.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "706b75d8b29f829f2f39cf4d1da708f2",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 81299,
        "upload_time": "2021-12-28T03:37:13",
        "upload_time_iso_8601": "2021-12-28T03:37:13.473006Z",
        "url": "https://files.pythonhosted.org/packages/7c/17/690082817ee48d68c0cda34b6e0f3ab17aa3a9d4c0f501c5512bdb536107/torchdistill-0.3.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fd93a2e7502994f09bdc0fee8d8d475be526ed3c8515dea9168d07a40876a256",
          "md5": "eea676b1a5d6a73c39c7d82ada106094",
          "sha256": "5732fa3ddf3def83db9f00e8ddd916bd11c4c4d21edb451b8caf1ca8d117fb33"
        },
        "downloads": -1,
        "filename": "torchdistill-0.3.1.tar.gz",
        "has_sig": false,
        "md5_digest": "eea676b1a5d6a73c39c7d82ada106094",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 65721,
        "upload_time": "2021-12-28T03:37:15",
        "upload_time_iso_8601": "2021-12-28T03:37:15.320095Z",
        "url": "https://files.pythonhosted.org/packages/fd/93/a2e7502994f09bdc0fee8d8d475be526ed3c8515dea9168d07a40876a256/torchdistill-0.3.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9a23fef1a0bfefa09e1e352ef322aaf423a1166ab84a6c982800581e6b2877c6",
          "md5": "273fcaadf4fc77eee51bdad5df4da7eb",
          "sha256": "d3b34d0b243d07d6124374d0e705977aa0aecf19bafa2ef6abaf54d0db4089e3"
        },
        "downloads": -1,
        "filename": "torchdistill-0.3.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "273fcaadf4fc77eee51bdad5df4da7eb",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 81504,
        "upload_time": "2022-03-05T22:16:47",
        "upload_time_iso_8601": "2022-03-05T22:16:47.244903Z",
        "url": "https://files.pythonhosted.org/packages/9a/23/fef1a0bfefa09e1e352ef322aaf423a1166ab84a6c982800581e6b2877c6/torchdistill-0.3.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0eefd2f9c0f65c49c384512ff707c2869d3e1a7185a18a3c7f3f40e3f8e73453",
          "md5": "72311fbebac925dc2a39b1dd09939aae",
          "sha256": "82a840cd52b16284c220c766c7f15eecbd7b079174df06034c62b63f3b51032d"
        },
        "downloads": -1,
        "filename": "torchdistill-0.3.2.tar.gz",
        "has_sig": false,
        "md5_digest": "72311fbebac925dc2a39b1dd09939aae",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 65844,
        "upload_time": "2022-03-05T22:16:48",
        "upload_time_iso_8601": "2022-03-05T22:16:48.296432Z",
        "url": "https://files.pythonhosted.org/packages/0e/ef/d2f9c0f65c49c384512ff707c2869d3e1a7185a18a3c7f3f40e3f8e73453/torchdistill-0.3.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9fdcfbcfa3b1c07911c20d166a898d1fef7b26d10fa1513b3d4fc734318783a1",
          "md5": "8bbe6697de2023b1833f8dbe1aeb06dc",
          "sha256": "40d9c6ec46398ab3fa5fb085c90b1aa8202d1092377ed94c4021eedd95d01cd7"
        },
        "downloads": -1,
        "filename": "torchdistill-0.3.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "8bbe6697de2023b1833f8dbe1aeb06dc",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 80951,
        "upload_time": "2022-11-09T07:24:35",
        "upload_time_iso_8601": "2022-11-09T07:24:35.733267Z",
        "url": "https://files.pythonhosted.org/packages/9f/dc/fbcfa3b1c07911c20d166a898d1fef7b26d10fa1513b3d4fc734318783a1/torchdistill-0.3.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bc5e3cca4ef58ba874f997a4a6f1057f19e5450d68e62e9729c1c1d5be175bf3",
          "md5": "e8c1543f6f7cf1f8c135de0834ae9af6",
          "sha256": "24a7be969e4a7b17dfaefe6626cc10a1006008878d6a0ff6e27b9f9c49f0149d"
        },
        "downloads": -1,
        "filename": "torchdistill-0.3.3.tar.gz",
        "has_sig": false,
        "md5_digest": "e8c1543f6f7cf1f8c135de0834ae9af6",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 65542,
        "upload_time": "2022-11-09T07:24:37",
        "upload_time_iso_8601": "2022-11-09T07:24:37.354741Z",
        "url": "https://files.pythonhosted.org/packages/bc/5e/3cca4ef58ba874f997a4a6f1057f19e5450d68e62e9729c1c1d5be175bf3/torchdistill-0.3.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "9fdcfbcfa3b1c07911c20d166a898d1fef7b26d10fa1513b3d4fc734318783a1",
        "md5": "8bbe6697de2023b1833f8dbe1aeb06dc",
        "sha256": "40d9c6ec46398ab3fa5fb085c90b1aa8202d1092377ed94c4021eedd95d01cd7"
      },
      "downloads": -1,
      "filename": "torchdistill-0.3.3-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "8bbe6697de2023b1833f8dbe1aeb06dc",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 80951,
      "upload_time": "2022-11-09T07:24:35",
      "upload_time_iso_8601": "2022-11-09T07:24:35.733267Z",
      "url": "https://files.pythonhosted.org/packages/9f/dc/fbcfa3b1c07911c20d166a898d1fef7b26d10fa1513b3d4fc734318783a1/torchdistill-0.3.3-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "bc5e3cca4ef58ba874f997a4a6f1057f19e5450d68e62e9729c1c1d5be175bf3",
        "md5": "e8c1543f6f7cf1f8c135de0834ae9af6",
        "sha256": "24a7be969e4a7b17dfaefe6626cc10a1006008878d6a0ff6e27b9f9c49f0149d"
      },
      "downloads": -1,
      "filename": "torchdistill-0.3.3.tar.gz",
      "has_sig": false,
      "md5_digest": "e8c1543f6f7cf1f8c135de0834ae9af6",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 65542,
      "upload_time": "2022-11-09T07:24:37",
      "upload_time_iso_8601": "2022-11-09T07:24:37.354741Z",
      "url": "https://files.pythonhosted.org/packages/bc/5e/3cca4ef58ba874f997a4a6f1057f19e5450d68e62e9729c1c1d5be175bf3/torchdistill-0.3.3.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}