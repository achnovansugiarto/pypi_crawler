{
  "info": {
    "author": "TCL MV Lab",
    "author_email": "chao46.zhang@tcl.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8"
    ],
    "description": "<div align=\"center\">\n  <img src=\"docs/img/READlogo.png\" width=\"650\"/>\n</div>\n\n---\n# READ (Reconstruction or Embedding based Anomaly Detection)\nThis repo is the pytorch version of READ, plz jump to <https://git.openi.org.cn/OpenI/READ_mindspore> for the mindspore version.\n\nREAD is an open source toolbox focused on unsupervised anomaly detection/localization tasks. By only training on the defect-free samples, READ is able to recognize defect samples or even localize anomalies on defect samples.\n\nThe purpose of this repo is to promote the research and application of unsupervised anomaly detection and localization algorithms. READ is designed to provide:\n- A unified interface for encapsulating diverse anomaly localization algorithms\n- High quality implementations of novel anomaly localization algorithms\n- Templates for using these algorithms in a detailed task\n\nIn addition, READ provides the benchmarks for validating novel unsupervised anomaly detection and localization algorithms for [MVTec AD dataset](https://www.mvtec.com/company/research/datasets/mvtec-ad/).\n\n## Changelog\n- **[Nov 07 2021] READ_pytorch v0.1.1 is Released!** \n- **[May 08 2021] READ_pytorch v0.1.0 is Released!**  \nPlease refer to [ChangeLog](docs/changelog.md) for details and release history.\n\n## Installation\n### Install the latest version from the master branch on OpenI\n```\npip install -U git+https://git.openi.org.cn/OpenI/READ_pytorch\n```\nPlease follow the [Installation](docs/installation.md) document to get a detailed instruction.\n\n## Getting Started\nPlease follow the [Getting Started](docs/getting_started.md) document to run the provided demo tasks.\n\n## Localization examples (based on READ)\n<img src=\"docs/img/bottle_ad.png\" width=\"50%\" height=\"50%\">\n<img src=\"docs/img/metal_nut_ad.png\" width=\"50%\" height=\"50%\">\n<img src=\"docs/img/carpet_ad.png\" width=\"50%\" height=\"50%\">\n<img src=\"docs/img/hazelnut_ad.png\" width=\"50%\" height=\"50%\">\n<img src=\"docs/img/toothbrush_ad.png\" width=\"50%\" height=\"50%\">\n\n## Supported Algorithms\n- [x] [RIAD](https://pdf.sciencedirectassets.com/272206/AIP/1-s2.0-S0031320320305094/main.pdf)\n- [x] [FAVAE](https://arxiv.org/pdf/2008.05369.pdf)\n- [x] [SPADE](https://arxiv.org/abs/2005.02357)\n- [x] [PaDim](https://arxiv.org/pdf/2011.08785v1.pdf)\n- [x] [USTAD](https://openaccess.thecvf.com/content_CVPR_2020/papers/Bergmann_Uninformed_Students_Student-Teacher_Anomaly_Detection_With_Discriminative_Latent_Embeddings_CVPR_2020_paper.pdf)\n- [x] [STPM](https://arxiv.org/pdf/2103.04257v2.pdf)\n- [x] [InTra](https://arxiv.org/pdf/2104.13897v2.pdf)\n- [x] [SemiOrth](https://arxiv.org/pdf/2105.14737.pdf)\n\n## Results\n### Implementation results on MVTec\n* Image-level anomaly detection accuracy (ROCAUC)\n\n|MVTec|RIAD|FAVAE|SPADE-WR50X2|PaDiM-WR50X2|USTAD|STPM|SemiOrth-WR50X2|InTra|\n|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n|Carpet|0.654|0.642|0.819|0.996|0.886|0.844|0.996|0.430|\n|Grid|0.980|1.000|0.42|0.966|0.919|0.982|0.836|0.600|\n|Leather|0.982|0.706|0.94|1.000|0.748|0.989|1.000|0.964|\n|Tile|0.838|0.842|0.980|0.973|0.998|0.981|0.963|0.894|\n|Wood|0.861|0.879|0.979|0.987|0.952|0.997|0.989|0.897|\n|All texture classes|0.863|0.814|0.828|0.984|0.901|0.959|0.957|0.757|\n|Bottle|0.984|0.999|0.972|0.999|0.940|1.000|0.995|0.947|\n|Cable|0.543|0.942|0.857|0.880|0.478|0.874|0.779|0.562|\n|Capsule|0.836|0.712|0.873|0.896|0.785|0.911|0.835|0.479|\n|Hazelnut|0.904|0.999|0.907|0.950|0.939|0.986|0.973|0.776|\n|Metal nut|0.820|0.911|0.734|0.987|0.509|0.988|0.917|0.466|\n|Pill|0.789|0.779|0.785|0.935|0.798|0.982|0.744|0.554|\n|Screw|0.746|0.595|0.658|0.846|0.706|0.871|0.470|0.665|\n|Toothbrush|0.956|0.925|0.878|0.981|0.825|0.769|0.978|0.533|\n|Transistor|0.890|0.885|0.900|0.983|0.563|0.810|0.927|0.520|\n|Zipper|0.978|0.647|0.952|0.920|0.761|0.967|0.872|0.461|\n|All object classes|0.845|0.839|0.852|0.9377|0.730|0.916|0.849|0.596|\n|All classes|0.851|0.831|0.844|0.953|0.787|0.930|0.885|0.650|\n\n* Pixel-level anomaly detection accuracy (ROCAUC)\n\n|MVTec|RIAD|FAVAE|SPADE-WR50X2|PaDiM-WR50X2|USTAD|STPM|SemiOrth-WR50X2|InTra|\n|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n|Carpet|0.904|0.836|0.985|0.988|0.958|0.977|0.989|0.468|\n|Grid|0.984|0.994|0.978|0.969|0.850|0.983|0.860|0.631|\n|Leather|0.990|0.908|0.993|0.991|0.914|0.991|0.993|0.989|\n|Tile|0.761|0.626|0.942|0.940|0.948|0.969|0.935|0.873|\n|Wood|0.821|0.908|0.956|0.946|0.899|0.940|0.950|0.715|\n|All texture classes|0.892|0.854|0.971|0.967|0.914|0.972|0.945|0.735|\n|Bottle|0.945|0.962|0.968|0.982|0.902|0.983|0.977|0.806|\n|Cable|0.619|0.957|0.920|0.957|0.816|0.940|0.922|0.560|\n|Capsule|0.978|0.965|0.983|0.985|0.913|0.973|0.981|0.774|\n|Hazelnut|0.974|0.987|0.986|0.982|0.974|0.968|0.976|0.911|\n|Metal nut|0.828|0.953|0.969|0.972|0.891|0.954|0.949|0.753|\n|Pill|0.955|0.943|0.947|0.950|0.928|0.987|0.922|0.745|\n|Screw|0.984|0.960|0.992|0.984|0.967|0.983|0.949|0.785|\n|Toothbrush|0.966|0.984|0.989|0.988|0.947|0.982|0.989|0.692|\n|Transistor|0.813|0.907|0.861|0.973|0.687|0.806|0.958|0.657|\n|Zipper|0.981|0.817|0.982|0.983|0.825|0.987|0.975|0.497|\n|All object classes|0.904|0.944|0.960|0.976|0.885|0.956|0.960|0.718|\n|All classes|0.900|0.914|0.963|0.973|0.895|0.962|0.955|0.730|\n\n## License\nThis project is released under the [Open-Intelligence Open Source License V1.1](LICENSE).\n\n## Contact\nPlease contact me if there is any question (Chao Zhang <chao.zhang46@tcl.com>).\n\n## About\nMachine Vision Group, TCL Corporate Research(HK) Co., Ltd is the main developer of READ.\n<div align=\"left\">\n  <img src=\"docs/img/tcl_logo.jpg\" width=\"200\"/>\n</div>\nAny contributions to READ is welcome!\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://git.openi.org.cn/OpenI/READ_pytorch",
    "keywords": "",
    "license": "Apache License 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "READ-pytorch",
    "package_url": "https://pypi.org/project/READ-pytorch/",
    "platform": "",
    "project_url": "https://pypi.org/project/READ-pytorch/",
    "project_urls": {
      "Homepage": "https://git.openi.org.cn/OpenI/READ_pytorch"
    },
    "release_url": "https://pypi.org/project/READ-pytorch/0.1.1/",
    "requires_dist": [
      "tqdm",
      "numpy",
      "pandas",
      "scipy",
      "timm (>=0.4.5)",
      "adabelief-pytorch (>=0.2.0)",
      "kornia (>=0.5.0)",
      "matplotlib (>=3.3.4)",
      "albumentations (==0.5.2)",
      "einops (>=0.3.0)",
      "scikit-learn (>=0.24.2)",
      "scikit-image (>=0.17.2)",
      "torch (>=1.7.0)",
      "torchvision"
    ],
    "requires_python": ">=3, <4",
    "summary": "Unsupervised Anomaly Localization Toolbox and Benchmark",
    "version": "0.1.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 11967894,
  "releases": {
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6ccfb4b42fa227546d62bf35eb2ce0e22024d7ad13fb71aa44bbe88c8173f3f4",
          "md5": "2948a9881e4b6c677c2db676af2b360c",
          "sha256": "083ffb090ebb11192591bf66ec6df1a8e1cb98120f9356969cb87d0209842409"
        },
        "downloads": -1,
        "filename": "READ_pytorch-0.1.1-py36-none-any.whl",
        "has_sig": false,
        "md5_digest": "2948a9881e4b6c677c2db676af2b360c",
        "packagetype": "bdist_wheel",
        "python_version": "py36",
        "requires_python": ">=3, <4",
        "size": 72176,
        "upload_time": "2021-11-09T03:21:29",
        "upload_time_iso_8601": "2021-11-09T03:21:29.412518Z",
        "url": "https://files.pythonhosted.org/packages/6c/cf/b4b42fa227546d62bf35eb2ce0e22024d7ad13fb71aa44bbe88c8173f3f4/READ_pytorch-0.1.1-py36-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "6ccfb4b42fa227546d62bf35eb2ce0e22024d7ad13fb71aa44bbe88c8173f3f4",
        "md5": "2948a9881e4b6c677c2db676af2b360c",
        "sha256": "083ffb090ebb11192591bf66ec6df1a8e1cb98120f9356969cb87d0209842409"
      },
      "downloads": -1,
      "filename": "READ_pytorch-0.1.1-py36-none-any.whl",
      "has_sig": false,
      "md5_digest": "2948a9881e4b6c677c2db676af2b360c",
      "packagetype": "bdist_wheel",
      "python_version": "py36",
      "requires_python": ">=3, <4",
      "size": 72176,
      "upload_time": "2021-11-09T03:21:29",
      "upload_time_iso_8601": "2021-11-09T03:21:29.412518Z",
      "url": "https://files.pythonhosted.org/packages/6c/cf/b4b42fa227546d62bf35eb2ce0e22024d7ad13fb71aa44bbe88c8173f3f4/READ_pytorch-0.1.1-py36-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}