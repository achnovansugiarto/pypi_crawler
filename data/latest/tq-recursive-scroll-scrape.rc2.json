{
  "info": {
    "author": "Teqniqly",
    "author_email": "farooq@teqniqly.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3 :: Only",
      "Topic :: Internet :: WWW/HTTP",
      "Topic :: Software Development :: Libraries :: Python Modules",
      "Topic :: Utilities"
    ],
    "description": "# Recursive-Scroll-Scraper\n\nPython library for automating scrolling and downloading web pages via Selenium. Scrolling and downloading functionality\nis provided by the [tq-scroll-scrape](https://pypi.org/project/tq-scroll-scrape/) package.\n\nRecursive-Scroll-Scraper provides the ability to download a paginated site, i.e. starting at the root page, getting the\nnext page url, downloading that page, and so on until the end is reached.\n\n`sample_app.py` demonstrates this use case using the Trulia real estate listings site.\n\n## Usage\n\n## Using ChromeDriver\n\nDownload ChromeDriver from https://chromedriver.chromium.org/downloads. Choose the version that matches the Chrome\nbrowser running on your system.\n\n## Using GeckoDriver for Firefox\n\nDownload GeckoDriver for Firefox from https://github.com/mozilla/geckodriver/releases.\n\n### Install Package\n\nInstall the package by running `pip install tq-recursive-scroll-scrape`.\n\n### Use the Package\n\nHere is sample code demonstrating how to crawl a paginated site.\n\n#### Create the RecursiveScrollScrape instance\n\n```python\nfrom tq_recursive_scroll_scrape.recursive_scroll_and_scrape import RecursiveScrollScrape\n\nroot_url = \"https://www.trulia.com\"\nfirst_url = f\"{root_url}/WA/Renton\"\ndriver_path = \"PATH TO DRIVER EXECUTABLE\"\nscroll_scraper = RecursiveScrollScrape(driver_path)\n```\n\n#### Define the Logic to Get the Next Page Links\n\nProvide a callback containing the logic to get the next page links. Since this function is called recursively, be sure\nto provide a terminating condition to avoid infinite loops.\n\n```python\nfrom bs4 import BeautifulSoup\nfrom typing import Optional\n\n\ndef get_next_url(content: str) -> Optional[str]:\n    soup = BeautifulSoup(content, \"html.parser\")\n\n    links = [a for a in soup.find_all(\"a\")\n             if a.get(\"aria-label\")\n             and \"Next\" in a.get(\"aria-label\")]\n\n    # Terminates recursion if the last page is reached.\n    if len(links) == 0:\n        return None\n\n    next_url = f\"{root_url}{links[0].get('href')}\"\n    return next_url\n```\n\n#### Optional Post-Download Callback\n\nProvide an optional callback containing the logic to perform after each page download such as saving the content to\ndisk.\n\n```python\ndef on_after_download(content: str):\n    with open(\"some_file.html\", \"w\", encoding=\"utf-8\") as file:\n        file.write(content)\n```\n\n#### Start the Download\n\n```python\nscroll_scraper.download(first_url, on_after_download, get_next_url)\n```\n\n### Scroll and Download Options\n\nRefer to the [tq-scroll-scrape](https://pypi.org/project/tq-scroll-scrape/) documentation for details on controlling\nscroll and download options. For example, the default wait time between scrolls is two seconds but can be changed. By\ndefault, the entire page is scrolled at once but can be scrolled by a specific number of pixels if desired.\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/farooq-teqniqly/tq-recursive-scroll-scrape",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "tq-recursive-scroll-scrape",
    "package_url": "https://pypi.org/project/tq-recursive-scroll-scrape/",
    "platform": null,
    "project_url": "https://pypi.org/project/tq-recursive-scroll-scrape/",
    "project_urls": {
      "GitHub": "https://github.com/farooq-teqniqly/tq-recursive-scroll-scrape",
      "Homepage": "https://github.com/farooq-teqniqly/tq-recursive-scroll-scrape"
    },
    "release_url": "https://pypi.org/project/tq-recursive-scroll-scrape/3.0/",
    "requires_dist": [
      "tq-scroll-scrape"
    ],
    "requires_python": ">=3.9",
    "summary": "recursive-scroll-scrape module.",
    "version": "3.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 13326870,
  "releases": {
    "1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d6c7d4903df0d81af0f4f111c30f9abe766c8c8dd4e91aab75691e002737c36d",
          "md5": "0c4b8e5bdbfa5fefb204b713a64bb5c1",
          "sha256": "315b517a01c4496fa18529e7e651f16679243918c73a7b592c16db02c497e908"
        },
        "downloads": -1,
        "filename": "tq_recursive_scroll_scrape-1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0c4b8e5bdbfa5fefb204b713a64bb5c1",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.9",
        "size": 4777,
        "upload_time": "2022-02-21T05:41:58",
        "upload_time_iso_8601": "2022-02-21T05:41:58.686087Z",
        "url": "https://files.pythonhosted.org/packages/d6/c7/d4903df0d81af0f4f111c30f9abe766c8c8dd4e91aab75691e002737c36d/tq_recursive_scroll_scrape-1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "3.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a4e3c80731d05bda4eecd8ad7b605371ad25af10d2fc468a4b5721125ab32c81",
          "md5": "85e0a843217cfe679bf32eb78d998579",
          "sha256": "19fd310026ea5ba74db963158747a20254375c2ee0e44d72d78bce5d9ba85e0c"
        },
        "downloads": -1,
        "filename": "tq_recursive_scroll_scrape-3.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "85e0a843217cfe679bf32eb78d998579",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.9",
        "size": 4847,
        "upload_time": "2022-03-28T22:37:11",
        "upload_time_iso_8601": "2022-03-28T22:37:11.888353Z",
        "url": "https://files.pythonhosted.org/packages/a4/e3/c80731d05bda4eecd8ad7b605371ad25af10d2fc468a4b5721125ab32c81/tq_recursive_scroll_scrape-3.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "a4e3c80731d05bda4eecd8ad7b605371ad25af10d2fc468a4b5721125ab32c81",
        "md5": "85e0a843217cfe679bf32eb78d998579",
        "sha256": "19fd310026ea5ba74db963158747a20254375c2ee0e44d72d78bce5d9ba85e0c"
      },
      "downloads": -1,
      "filename": "tq_recursive_scroll_scrape-3.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "85e0a843217cfe679bf32eb78d998579",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.9",
      "size": 4847,
      "upload_time": "2022-03-28T22:37:11",
      "upload_time_iso_8601": "2022-03-28T22:37:11.888353Z",
      "url": "https://files.pythonhosted.org/packages/a4/e3/c80731d05bda4eecd8ad7b605371ad25af10d2fc468a4b5721125ab32c81/tq_recursive_scroll_scrape-3.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}