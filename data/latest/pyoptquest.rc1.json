{
  "info": {
    "author": "",
    "author_email": "OptTek <python@opttek.com>",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# `OptQuestOptimizer` Documentation\n\nOptQuest is a simulation optimization engine, built on a truly unique set of powerful algorithms and sophisticated analysis techniques including metaheuristics optimization, evolutionary algorithms, tabu search and scatter search, to name a few.\n\nThe `OptQuestOptimizer` Python class is a wrapper around the OptQuest engine JAR, providing a Python interface to the engine.\n\nThe optimization interface is designed to seamlessly plug into Simon Blanke's [Gradient Free Optimizers](https://github.com/SimonBlanke/Gradient-Free-Optimizers), but does not require the Gradient Free Optimizer code to work.\n\nNote that an OptQuest license is necessary in order to use the OptQuestEngine. Inquire at our website to get a trial license if you need one: <https://www.opttek.com/products/optquest/>\n\n## Installation\n\nThe `pandas` and `pyjnius` packages are required for `OptQuestOptimizer`. For your convenience we have included a `requirements.txt` file alongside this README.\n\nUse the following command to get the required `pip` packages.\n\nInstall `requirements.txt` with `pip`:\n```\npip install -r requirements.txt\n```\n\nOnce your Python environment is set up, place a copy of `pyoptquest.py` in the same folder as the optimization script that will use it. Make sure that you have an OptQuest JAR of at least version 9.1.1.2 and a valid OptQuest license. The license ID and OptQuest JAR file path are necessary inputs when defining an optimization; demonstrated in the following examples.\n\n## Minimal Example\n\nHere is an example using `OptQuestOptimizer` to minimize $x^2$ over the search space $x \\in [-10,10]$.\n\n```py\nfrom pyoptquest import OptQuestOptimizer\n\n# define the input(s)\nsearch_space = {\n    'x': {'type': 'continuous', 'min': -10, 'max': 10}\n}\n\n# define the objective(s)\nobjectives = {\n    'y': {'type': 'min', 'expression': 'x * x'}\n}\n\n# define the optimization\nopt = OptQuestOptimizer(\n    search_space,\n    objectives,\n    license_id=999999999,\n    optquest_jar=r'../OptQuest.jar')\nopt.search(n_iter=10)\n\n# print results\nprint('best score:', opt.best_score)\nprint('best parameters:', opt.best_para)\nprint('Optimization time:', opt.optimization_time)\n```\n\nOutput:\n```\nbest score: 0.0\nbest parameters: {'x': 0.0}\nOptimization time: 0.045327186584472656\n```\n\nThe first step in designing an optimization is to define the `search_space`. The `search_space` is a dictionary of variable names mapped to their properties. In the example, we simply define a continuous variable that can take on values between -10 and 10. You can view all supported variable types and their properties in the [Supported Variable Types](#supported-variable-types) section.\n\nAt least one objective must be defined and given an optimization `type`. An objective can be of the type `min` (minimize) or `max` (maximize). The `'expression'` property indicates that the objective will be represented by a simple mathematical expression provided by the user as a string. In this case, the expression is `x * x` or $x^2$.\n\nOnce a search space and objective have been defined it is possible to run a minimal optimization. Note that the license ID and OptQuest JAR file path must be provided when creating the optimization. Finally, call `search()` with a specified number of iterations (`n_iter`) on the optimizer object (`opt`) and the optimization will begin.\n\nThe output shows that `OptQuestOptimizer` found the best solution. The optimal value and solution can be obtained from the optimizer object after the optimization by calling `best_score()` and `best_para()`.\n\n## Example with Simulation Evaluator\n\n`OptQuestOptimizer` is tailored toward optimizing simulated problems rather than purely mathematical ones.\n\nWhen designing an optimization, we are not limited to specifying simple mathematical objectives; we can provide a custom evaluator callback function that uses inputs given by `OptQuestOptimizer` and returns output values. The output values can then be used by objectives. For example, the custom evaluator could call an external process to start a simulation with the provided input values. The sole purpose of output values is to have a means of collecting information from the evaluator. Inputs are passed to the evaluator, and outputs are collected from it. Note that this is a distinct type of evaluator from constraint and objective evaluators, which return a boolean value or single numerical value, respectively.\n\nHere is an example using an evaluator function named `simulation`; a small modification on the previous example:\n\n```py\nfrom pyoptquest import OptQuestOptimizer\n\n\ndef simulation(inputs):\n    # get inputs from OptQuestOptimizer\n    x = inputs['x']\n\n    # run the \"simulation\"\n    y = x ** 2\n\n    # create dict to hold return values from the simulation\n    outputs = {'y': y}\n    return outputs\n\n\n# define the input(s)\nsearch_space = {\n    'x': {'type': 'continuous', 'min': -10, 'max': 10}\n}\n\n# specify the output(s) of the simulation evaluator (the output(s) of the simulation() function)\noutput_space = ['y']\n\n# define the objective(s)\nobjectives = {\n    'obj': {'type': 'min', 'expression': 'y'}  # minimize the output \"y\"\n}\n\n# define the optimization\nopt = OptQuestOptimizer(\n    search_space,\n    objectives,\n    evaluator=simulation,\n    output_space=output_space,\n    license_id=999999999,\n    optquest_jar=r'../OptQuest.jar')\nopt.search(n_iter=10)\n\n# print results\nprint('best score:', opt.best_score)\nprint('best parameters:', opt.best_para)\nprint('Optimization time:', opt.optimization_time)\n```\n\nOutput:\n\n```\nbest score: 0.0\nbest parameters: {'x': 0.0, 'y': 0.0}\nOptimization time: 0.0624852180480957\n```\n\nThe result is the same as the previous examples, but we used a user-supplied evaluator callback function to generate an output `y` which was then used by the objective `obj`.\n\n## Example with Objective Evaluator\n\nObjectives are not limited to being string expressions and can be defined with a function evaluator that takes `inputs` and optionally `outputs` as parameters. The example below shows an objective evaluator callback function that only takes `inputs` as a parameter:\n\n```py\nfrom pyoptquest import OptQuestOptimizer\n\n\n# function to evaluate the objective\ndef objective_evaluator(inputs):\n    x = inputs['x']\n    return x ** 2\n\n\n# define the input(s)\nsearch_space = {\n    'x': {'type': 'continuous', 'min': -10, 'max': 10}\n}\n\n# define the objective(s)\nobjectives = {\n    'y': {'type': 'min', 'evaluator': objective_evaluator}  # specify the evaluator\n}\n\n# define the optimization\nopt = OptQuestOptimizer(\n    search_space,\n    objectives,\n    license_id=999999999,\n    optquest_jar=r'../OptQuest.jar')\nopt.search(n_iter=10)\n\n# print results\nprint('best score:', opt.best_score)\nprint('best parameters:', opt.best_para)\nprint('Optimization time:', opt.optimization_time)\n```\n\nOutput:\n\n```\nbest score: 0.0\nbest parameters: {'x': 0.0}\nOptimization time: 0.09617185592651367\n```\n\nThe result is the same as the previous examples, but we used a user-supplied objective evaluator function instead of a simple mathematical string expression.\n\nThe difference between an objective evaluator callback function and an an evaluator callback function is that the objective evaluator can only return a single value that can't be used by other objectives while an evaluator can return multiple outputs that can be used by multiple objectives.\n\n## Constraints Example\n\nConsider the [Minimal Example](#minimal-example) where we are trying to minimize the objective `y`=$x^2$ for $x\\in[-10,10]$. $x$ is constrained to be on the interval $[-10,10]$, but we can specify more complex constraints. Let's add the constraint that the objective `y`$=x^2$ must be above the line $0.1x+1$. The problem now looks like this:\n\n<img src=\"readme images\\constraint_demo.png\" alt=\"readme images\\pareto_frontier_demo.png failed to be displayed\" width=\"400\" />\n\nHere is how this problem can be solved using `OptQuestOptimizer`:\n\n```py\nfrom pyoptquest import OptQuestOptimizer\n\n# define the input(s)\nsearch_space = {\n    'x': {'type': 'continuous', 'min': -10, 'max': 10}\n}\n\n# define the objective(s)\nobjectives = {\n    'y': {'type': 'min', 'expression': 'x * x'}\n}\n\nconstraints = {\n    'my_constraint': {'expression': 'x * x >= 0.1 * x + 1'}\n}\n\n# define the optimization\nopt = OptQuestOptimizer(\n    search_space,\n    objectives,\n    constraints=constraints,\n    license_id=999999999,\n    optquest_jar=r'../OptQuest.jar')\nopt.search(n_iter=100)\n\n# print results\nprint('best score:', opt.best_score)\nprint('best parameters:', opt.best_para)\nprint('Optimization time:', opt.optimization_time)\n```\n\nOutput:\n\n```\nbest score: 0.9164935413654939\nbest parameters: {'x': -0.9573366917472107}\nOptimization time: 0.13147902488708496\n```\n\nWe can also see all the solutions that were evaluated:\n\n```py\n# print all solutions\nprint('all solutions:')\nprint(opt.search_data)\n```\n\nOutput:\n\n```\nall solutions:\n    iteration  replication  feasible           y          x\n0           1            1     False    0.000000   0.000000\n1           2            1      True  100.000000 -10.000000\n2           3            1      True  100.000000  10.000000\n3           4            1      True   25.000000  -5.000000\n4           5            1      True   25.000000   5.000000\n..        ...          ...       ...         ...        ...\n95         96            1      True   20.200825  -4.494533\n96         97            1      True   49.104083  -7.007431\n97         98            1      True   50.107366   7.078656\n98         99            1      True   89.333619   9.451646\n99        100            1     False    0.013505   0.116211\n\n[100 rows x 5 columns]\n```\n\nNotice the third column which indicates whether a solution was in the feasible region or not.\n\nMultiple constraints can be defined in `constraints`, but they must all have unique names. A constraint can also be \nthe result of a callback function that returns a boolean instead of a string expression. Here is an example of a \nproblem with an evaluated constraint:\n\n```py\nfrom pyoptquest import OptQuestOptimizer\n\n\ndef domain_constraint(inputs):\n    x = inputs['x']\n    return abs(x) >= 1\n\n\n# define the input(s)\nsearch_space = {\n    'x': {'type': 'continuous', 'min': -10, 'max': 10}\n}\n\n# define the objective(s)\nobjectives = {\n    'y': {'type': 'min', 'expression': 'x * x'}\n}\n\nconstraints = {\n    'domain': {'evaluator': domain_constraint},\n}\n\n# define the optimization\nopt = OptQuestOptimizer(\n    search_space,\n    objectives,\n    constraints=constraints,\n    license_id=999999999,\n    optquest_jar=r'../OptQuest.jar')\nopt.search(n_iter=300)\n\n# print results\nprint('best score:', opt.best_score)\nprint('best parameters:', opt.best_para)\nprint('Optimization time:', opt.optimization_time)\n```\n\nOutput:\n\n```\nbest score: 1.0\nbest parameters: {'x': 1.0}\nOptimization time: 0.2471938133239746\n```\n\nThe optimal solutions are at $x=1$ and $x=-1$.\n\n## Parallel Evaluation Example\n\nParallelization is easy when using the optimizer. Simply pass the number of parallel executions you'd like to run to `OptQuestOptimizer.search()`, specify the number of `parallel_evaluators` i.e. processes you'd like to have running, and that's it.\n\nIf we want to parallelize the [Minimal Example](#minimal-example) we can simply change the line:\n\n```py\nopt.search(n_iter=10)  # non-parallel execution\n```\n\nto:\n\n```py\nopt.search(n_iter=100, parallel_evaluators=2)  # parallel execution\n```\n\nRemember, while Python supports threads and parallel execution semantics, Python code itself does not run concurrently. So parallel evaluation will only be a time-saver if you spawn external processes, like long-running simulations.\n\nHere is a made up example of a problem that benefits from parallelization:\n\n```py\nimport time\nfrom pyoptquest import OptQuestOptimizer\n\n\n# represents a large simulation running for one second\ndef sleep_evaluator(inputs):\n    time.sleep(1)\n    return {}\n\n\n# define the input(s)\nsearch_space = {\n    'x': {'type': 'continuous', 'min': -10, 'max': 10}\n}\n\n# define the objective(s)\nobjectives = {\n    'y': {'type': 'min', 'expression': 'pow(x - pi, 2)'}\n}\n\n# define the optimization\nopt = OptQuestOptimizer(\n    search_space,\n    objectives,\n    evaluator=sleep_evaluator,\n    license_id=999999999,\n    optquest_jar=r'../OptQuest.jar')\nopt.search(n_iter=100, parallel_evaluators=20)  # increasing parallel_evaluators will decrease the optimization time\n\n# print results\nprint('best score:', opt.best_score)\nprint('best parameters:', opt.best_para)\nprint('Optimization time:', opt.optimization_time)\n```\n\nOutput:\n\n```\nbest score: 6.007550195017685e-07\nbest parameters: {'x': 3.1408175697107796}\nOptimization time: 5.143232583999634\n```\n\nSince the `sleep_evaluator` function executes for one second and we do 100 iterations, 20 at a time, the simulation takes about five seconds to execute (1 second * 100 iterations / 20 in parallel.)\n\n## Replications Example\n\nReplications are extra evaluations executed on the same input(s) for the purpose of accounting for variability in simulations. It is recommended to use [parallel evaluators](#parallel-evaluation-example) when running replications on large simulations.\n\n`OptQuestOptimizer` has support for replications of an evaluation for a given set of inputs, but it does not provide any sort of random seed.\n\nThe user can set a fixed number of replications to be executed, or a variable number of executions. To set a variable number of replications, a minimum and maximum number of replications is specified. `OptQuestOptimizer` will execute the minimum number of replications and then continue running replications until each objective has reached 95% confidence or the maximum number of replications have been executed.\n\nTo set a fixed number of replications, simply call `OptQuestOptimizer.search()` like this:\n\n```py\nopt.search(n_iter=10, replications=20)  # run 20 replications\n```\n\nTo set a variable number of replications, pass a tuple to `OptQuestOptimizer.search()` containing the minimum and maximum number of replications, respectively:\n\n```py\nopt.search(n_iter=10, replications=(5, 20))  # run between 5 and 20 replications\n```\n\nHere is an example of an optimization with variable replications (note the use of a [status monitor](#status-monitor) to track the progress):\n\n```py\nimport random\n\nfrom pyoptquest import OptQuestOptimizer\n\n\n# optional function for tracking the status of the optimization, called every iteration/replication\ndef status_monitor(inputs, outputs, objectives, iteration, replication):\n    print(f'--executing {iteration}, replication {replication}')\n\n\n# return a random number close to 1 so that a random number of replications are called for by OptQuest\ndef objective_evaluator(dec_var_values, output_values):\n    return 1 + (random.random() - 0.5) * 0.2\n\n\n# define the input(s)\nsearch_space = {\n    'x': {'type': 'continuous', 'min': -10, 'max': 10}\n}\n\n# define the objective(s)\nobjectives = {\n    'y': {'type': 'min', 'evaluator': objective_evaluator}\n}\n\n# define the optimization\nopt = OptQuestOptimizer(search_space, objectives,\n                        status_monitor=status_monitor,\n                        license_id=999999999,\n                        optquest_jar=r'../OptQuest.jar')\nopt.search(n_iter=2, replications=(5, 20))\n# opt.search(n_iter=10, replications=20)  # fixed replications\n\nprint()\n\n# print results\nprint('best score:', opt.best_score)\nprint('best parameters:', opt.best_para)\nprint('Optimization time:', opt.optimization_time)\n```\n\nOutput:\n\n```\n--executing 1, replication 1\n--executing 1, replication 2\n--executing 1, replication 3\n--executing 1, replication 4\n--executing 1, replication 5\n--executing 1, replication 6\n--executing 1, replication 7\n--executing 1, replication 8\n--executing 1, replication 9\n--executing 2, replication 1\n--executing 2, replication 2\n--executing 2, replication 3\n--executing 2, replication 4\n--executing 2, replication 5\n--executing 2, replication 6\n--executing 2, replication 7\n\nbest score: 1.0059779289574402\nbest parameters: {'x': 0.0}\nOptimization time: 0.06905317306518555\n```\n\nNotice that for the first iteration of inputs, confidence was met after nine replications. For the second iteration of inputs it only took seven replications before confidence was met.\n\n### Advanced Variable Replications\n\nWhen using variable replications OptQuest will continue to execute replications until it executes the max replications or until confidence is met for all objectives. By default, confidence is met when, over all executed replications, the objective value is within 5% of the mean 95% of the time.\n\nHowever, some objectives don't require the same amount confidence that others do. You have the ability to change the confidence parameters for each objective when defining them.\n\nBelow is an example of an objective defined with user-specified confidence parameters:\n\n```py\nimport random\n\nfrom pyoptquest import OptQuestOptimizer\n\n\n# optional function for tracking the status of the optimization, called every iteration/replication\ndef status_monitor(inputs, outputs, objectives, iteration, replication):\n    print(f'--executing {iteration}, replication {replication}')\n\n\n# return a random number close to 1 so that a random number of replications are called for by OptQuest\ndef objective_evaluator(dec_var_values, output_values):\n    return 1 + (random.random() - 0.5) * 0.2\n\n\n# define the input(s)\nsearch_space = {\n    'x': {'type': 'continuous', 'min': -10, 'max': 10}\n}\n\n# define the objective(s)\nobjectives = {\n    'y': {'type': 'min', 'evaluator': objective_evaluator, 'confidence': 5, 'error': 0.04}\n    # confidence 5 means 99% confidence interval\n}\n\n# define the optimization\nopt = OptQuestOptimizer(search_space, objectives,\n                        status_monitor=status_monitor,\n                        license_id=999999999,\n                        optquest_jar=r'../OptQuest.jar')\nopt.search(n_iter=2, replications=(5, 20))\n\nprint()\n\n# print results\nprint('best score:', opt.best_score)\nprint('best parameters:', opt.best_para)\nprint('Optimization time:', opt.optimization_time)\n```\n\nOutput:\n\n```\n--executing 1, replication 1\n--executing 1, replication 2\n--executing 1, replication 3\n--executing 1, replication 4\n--executing 1, replication 5\n--executing 1, replication 6\n--executing 1, replication 7\n--executing 1, replication 8\n--executing 1, replication 9\n--executing 1, replication 10\n--executing 2, replication 1\n--executing 2, replication 2\n--executing 2, replication 3\n--executing 2, replication 4\n--executing 2, replication 5\n--executing 2, replication 6\n--executing 2, replication 7\n--executing 2, replication 8\n--executing 2, replication 9\n--executing 2, replication 10\n--executing 2, replication 11\n--executing 2, replication 12\n--executing 2, replication 13\n--executing 2, replication 14\n--executing 2, replication 15\n--executing 2, replication 16\n\nbest score: 0.9853533444387222\nbest parameters: {'x': -10.0}\nOptimization time: 0.04686570167541504\n```\n\nWe set `confidence` to `5` and `error` to `0.04`; we tightened the confidence required on this objective. Confidence 5 means we want a 99% confidence interval, and an error of 0.04 means that the grouping around the mean has a tolerance of 4%. For this objective confidence will be met when the objective value is within 4% of the mean 99% of the time.\n\nIn the previous example only 9 and 7 replications were run before confidence was met. In this example 10 and 16 replications were run before confidence was met because there was tighter tolerance on the objective and more replications were needed in order to reach that tolerance.\n\n## Multi-Objective Example\n\n`OptQuestOptimizer` can optimize for multiple objectives. For example, consider a problem where you're solving for $x$ and you want to minimize `objective_1`$=(x+1)^2$ and also minimize `objective_2`$=(x-1)^2$. The minima are $x=-1$ and $x=1$, respectively. However, there is no single best solution $x$ for both objectives. The idea of an optimal solution is replaced by a Pareto efficient set; a set of optimal solutions which are better than all other solutions, but not necessarily better than each other.\n\nConsider the following image of the problem:\n\n<img src=\"readme images\\pareto_frontier_demo.png\" alt=\"readme images\\pareto_frontier_demo.png failed to be displayed\" width=\"400\" />\n\nThe two minima for the two objectives are marked with X's. Points in the Pareto efficient set are marked with green crosses. Note that the Pareto efficient set is infinite here and the marked points are just a finite sample of it.\n\nThese Pareto efficient solutions represent the best solutions; notice that any point less than (left of) `objective_1`'s minimum at $x=-1$ is worse than all Pareto efficient solutions for both objectives, and any point greater than (right of) `objective_2`'s minimum at $x=1$ is also worse than all Pareto efficient solutions for both objectives. Points in the Pareto efficient set are not necessarily optimal for either individual objective, but they are a compromise between the two objectives.\n\nHere is an example demonstrating how to solve this problem using `OptQuestOptimizer`:\n\n```py\nfrom matplotlib import pyplot as plt\n\nfrom pyoptquest import OptQuestOptimizer\n\n# define the input(s)\nsearch_space = {\n    'x': {'type': 'continuous', 'min': -2, 'max': 2}\n}\n\n# define the objective(s)\nobjectives = {\n    'objective_1': {'type': 'min', 'expression': 'pow(x + 1, 2)'},\n    'objective_2': {'type': 'min', 'expression': 'pow(x - 1, 2)'}\n}\n\n# define the optimization\nopt = OptQuestOptimizer(\n    search_space,\n    objectives,\n    license_id=999999999,\n    optquest_jar=r'../OptQuest.jar')\n\n# do the optimization\nopt.search(n_iter=10)\n\n# print results\nprint('Pareto front:')\nprint(opt.best_score)\nprint('Optimization time:', opt.optimization_time)\n```\n\nOutput:\n\n```\npareto frontier data:\n   iteration  replication  objective_1  objective_2         x\n0          1            1     1.000000     1.000000  0.000000\n1          4            1     0.000160     4.050825 -1.012666\n2          5            1     0.231362     2.307359 -0.518999\n3          6            1     3.728985     0.004753  0.931058\n4          8            1     0.255932     2.232344 -0.494103\n5         10            1     2.198158     0.267683  0.482619\nOptimization time: 0.05336761474609375\n```\n\nAn analyst making a decision about a multi-objective problem would probably benefit from seeing the objectives against each other to aid in making a decision. When plotting objectives against eachother, the Pareto efficient set is called the [Pareto frontier](https://www.opttek.com/doc/v811engine/OptQuest_Engine_Documentation/OptQuest.htm#Multi_Objective_Overview.htm). Let's make this plot:\n\n```py\n# plot results\nfig, ax = plt.subplots()\nax.set_title('objective_1 vs objective_2')\nax.set_xlabel('objective_1')\nax.set_ylabel('objective_2')\nopt.search_data.plot(x='objective_1', y='objective_2', style='s', color='pink', ax=ax)  # all data\nopt.best_score.plot(x='objective_1', y='objective_2', style='+', color='green', ax=ax)  # Pareto frontier\nax.legend(['all data', 'pareto frontier'])\n# label points on the Pareto front\nfor idx, (x_coord, y_coord) in enumerate(zip(opt.best_score['objective_1'], opt.best_score['objective_2'])):\n    x = round(opt.best_score[\"x\"][idx], 2)\n    ax.annotate(text=str(f'$x={x}$'), xy=(x_coord + 0.2, y_coord))\nplt.show()\n```\n\nOutput:\n\n<img src=\"readme images\\objectives_plot.png\" alt=\"readme images\\pareto_frontier_demo.png failed to be displayed\" width=\"400\" />\n\nThis plot show us the tradeoffs between Pareto frontier solutions to our problem (the green crosses.) The solution at $x=0.0$ looks like a good compromise for both objectives. Picking a different solution such as $x=0.48$ minimizes `objective_2` but increases `objective_1` even more so, and we're trying to minimize both objectives. However, depending on what `objective_1` and `objective_2` represent, we may favor $x=0.48$. This is where the human factor comes in; with multiple objectives we cannot mathematically say that one solution on a Pareto frontier is better than another, the Pareto frontier is a tool representing optimal objective tradeoffs that a human analyst can use to help make a decision.\n\n## Status Monitor\n\nThe `status_monitor` callback function is passed to `OptQuestOptimizer` and gets called after every time an iteration or replication has been evaluated. It's useful for tracking the status of the optimization while it's running.\n\nHere is an example using `status_monitor` in the [Minimal Example](#minimal-example):\n\n```py\nfrom pyoptquest import OptQuestOptimizer\n\n\n# optional function for tracking the status of the optimization (called every iteration)\ndef status_monitor(inputs, outputs, objectives, iteration, replication):\n    print(f'--status monitor says hello from iteration {iteration} with objective value {objectives[\"y\"]}')\n\n\n# define the input(s)\nsearch_space = {\n    'x': {'type': 'continuous', 'min': -10, 'max': 10}\n}\n\n# define the objective(s)\nobjectives = {\n    'y': {'type': 'min', 'expression': 'x * x'}\n}\n\n# define the optimization\nopt = OptQuestOptimizer(\n    search_space,\n    objectives,\n    status_monitor=status_monitor,\n    license_id=999999999,\n    optquest_jar=r'../OptQuest.jar')\nopt.search(n_iter=10)\n\nprint()\n\n# print results\nprint('best score:', opt.best_score)\nprint('best parameters:', opt.best_para)\nprint('Optimization time:', opt.optimization_time)\n```\n\nOutput:\n```\n--status monitor says hello from iteration 1 with objective value 0.0\n--status monitor says hello from iteration 2 with objective value 100.0\n--status monitor says hello from iteration 3 with objective value 100.0\n--status monitor says hello from iteration 4 with objective value 25.63732245730393\n--status monitor says hello from iteration 5 with objective value 21.671725343768035\n--status monitor says hello from iteration 6 with objective value 55.06539502557916\n--status monitor says hello from iteration 7 with objective value 6.103445395617211\n--status monitor says hello from iteration 8 with objective value 57.78743065485578\n--status monitor says hello from iteration 9 with objective value 5.823021408526737\n--status monitor says hello from iteration 10 with objective value 36.80563848228416\n\nbest score: 0.0\nbest parameters: {'x': 0.0}\nOptimization time: 0.0624849796295166\n```\n\nThe `status_monitor` function must be able to receive the parameters `inputs`, `outputs`, `objectives`, `iteration`, and `replication`; even if the it isn't using these parameters.\n\n## Prematurely Stopping an Optimization\n\n`OptQuestOptimizer` accepts a `user_stop` callback function that returns a boolean which tells it to continue or stop the optimization every iteration/replication. The function takes the same parameters as the `status_monitor` callback. Below is an example of a `user_stop` function being used to stop the optimization at 5 iterations:\n\n```py\nfrom pyoptquest import OptQuestOptimizer\n\n\n# optional function for tracking the status of the optimization (called every iteration)\ndef status_monitor(inputs, outputs, objectives, iteration, replication):\n    print(f'--status monitor says hello from iteration {iteration} with objective value {objectives[\"y\"]}')\n\n\n# return True if the optimization should be stopped\ndef user_stop(inputs, outputs, objectives, iteration, replication):\n    if iteration >= 5:\n        print('-- STOPPING! --')\n        return True\n    else:\n        return False\n\n\n# define the input(s)\nsearch_space = {\n    'x': {'type': 'continuous', 'min': -10, 'max': 10}\n}\n\n# define the objective(s)\nobjectives = {\n    'y': {'type': 'min', 'expression': 'x * x'}\n}\n\n# define the optimization\nopt = OptQuestOptimizer(\n    search_space,\n    objectives,\n    status_monitor=status_monitor,\n    user_stop=user_stop,\n    license_id=999999999,\n    optquest_jar=r'../OptQuest.jar')\nopt.search(n_iter=10)\n\nprint()\n\n# print results\nprint('best score:', opt.best_score)\nprint('best parameters:', opt.best_para)\nprint('Optimization time:', opt.optimization_time)\n```\n\nOutput:\n\n```\n--status monitor says hello from iteration 1 with objective value 0.0\n--status monitor says hello from iteration 2 with objective value 100.0\n--status monitor says hello from iteration 3 with objective value 100.0\n--status monitor says hello from iteration 4 with objective value 25.63732245730393\n--status monitor says hello from iteration 5 with objective value 21.671725343768035\n-- STOPPING! --\n\nbest score: 0.0\nbest parameters: {'x': 0.0}\nOptimization time: 0.03778338432312012\n```\n\nThe `user_stop` callback function has access to the current solution being run and can also easily be configured to stop the optimization after a certain amount of time has passed or after some other event occurs.\n\n## Gradient Free Optimizers Support\n\n`OptQuestOptimizer` is compatible with [Gradient Free Optimizers (GFO)](https://github.com/SimonBlanke/Gradient-Free-Optimizers). For example, the optimizer in the [convex_function.py demo](https://github.com/SimonBlanke/Gradient-Free-Optimizers/blob/master/examples/convex_function.py) can easily be swapped to `OptQuestOptimizer`.\n\n`HillClimbingOptimizer` example:\n```py\n\nimport numpy as np\nfrom gradient_free_optimizers import HillClimbingOptimizer\n\n\ndef convex_function(pos_new):\n    score = -(pos_new[\"x1\"] * pos_new[\"x1\"] + pos_new[\"x2\"] * pos_new[\"x2\"])\n    return score\n\n\nsearch_space = {\n    \"x1\": np.arange(-100, 101, 0.1),\n    \"x2\": np.arange(-100, 101, 0.1),\n}\n\nopt = HillClimbingOptimizer(search_space)  # using HillClimbingOptimizer\nopt.search(convex_function, n_iter=300000)\n```\n\nOutput:\n\n```\nResults: 'convex_function'  \n   Best score: -6.462348535570529e-23  \n   Best parameter:\n      'x1' : -5.6843418860808015e-12  \n      'x2' : -5.6843418860808015e-12  \n \n   Evaluation time   : 9.109798669815063 sec    [33.31 %]\n   Optimization time : 18.237623929977417 sec    [66.69 %]\n   Iteration time    : 27.34742259979248 sec    [10969.96 iter/sec]\n```\n\n`OptQuestOptimizer` example:\n\n```py\nimport numpy as np\nfrom pyoptquest import OptQuestOptimizer\n\n\ndef convex_function(pos_new):\n    score = -(pos_new[\"x1\"] * pos_new[\"x1\"] + pos_new[\"x2\"] * pos_new[\"x2\"])\n    return score\n\n\nsearch_space = {\n    \"x1\": np.arange(-100, 101, 0.1),\n    \"x2\": np.arange(-100, 101, 0.1),\n}\n\nopt = OptQuestOptimizer(  # using OptQuestOptimizer\n    search_space,\n    license_id=999999999,\n    optquest_jar=r'optquest.jar')\nopt.search(convex_function, n_iter=300000)\n\n# print results\nprint('best score:', opt.best_score)\nprint('best parameters:', opt.best_para)\nprint('Optimization time:', opt.optimization_time)\n```\n\nOutput:\n\n```\nbest score: -6.462348535570529e-23\nbest parameters: {'x1': -5.6843418860808015e-12, 'x2': -5.6843418860808015e-12}\nOptimization time: 0.3541069030761719\n```\n\nIn the above example note that, like GFO, `OptQuestOptimizer` doesn't need to be defined with `objectives` if `OptQuestOptimizer.search()` is passed an objective evaluator e.g. `convex_function`. If an objective is passed like this, `OptQuestOptimizer` will maximize the objective.\n\n## `OptQuestOptimizer` Constructor Parameters\n\nBelow is a description of each parameter that can be passed to the `OptQuestOptimizer` constructor.\n\n- `search_space`: Required parameter. The inputs/decision variables for the optimization. This should be a `dict` of variable names mapped to dictionaries of their corresponding properties.\n\n- `objectives`: Not required for the constructor. If no objective is supplied here than an objective evaluator must be passed to `OptQuestOptimizer.search()` later on. This should be a `dict` of objective names mapped to dictoinaries of their corresponding properties.\n\n- `evaluator`: Not required. A callback function which should take an `input` parameter; a `dict` of variable names and values. The function should then run the user logic e.g. perform a simulation, and then return an `output` `dict` of output names mapped to their values. The names (keys) in the `output` return `dict` must be those specified by `output_space`, described next.\n\n- `output_space`: Sometimes required. Only used if the constructor's `evaluator` parameter is passed an evaluator callback function since it will generate outputs. This should be a `list` containing the names of all outputs that will be collected from the evaluator callback function.\n\n- `constraints`: Not required. Provides a way to put constraints on the inputs and outputs of the problem. This should be a `dict` mapping constraint names to dictionaries of their corresponding properties. See the [constraints example](#constraints-example) for more details.\n\n- `status_monitor` and `user_stop`: callback functions that must take the parameters `inputs`, `outputs`, `objectives`, `iteration`, and `replication`. See the corresonding sections for more details on these callback functions: [Status Monitor](#status-monitor) and [Prematurely Stopping an Optimization](#prematurely-stopping-an-optimization).\n\n- `license_id`: The ID number for your OptQuest license. The trial license is used in the provided examples. An optimization running with the trial license is limited to 7 variables and 500 iterations. The trial license ID number is `999999999`.\n\n- `OptQuestJar`: A path to an `OptQuest.jar` file of version 9.1.1.2 or higher.\n\n## `OptQuestOptimizer.search()` Parameters\n\nBelow is a list of parameters that can be passed to the `OptQuestOptimizer.search()` function.\n\n- `objective_evaluator`: If no `objectives` parameter is passed to the `OptQuestOptimizer` constructor then this parameter must be passed to the `OptQuestOptimizer.search()` function as a callback function. The callback function must take an `inputs` parameter which expects a `dict` mapping input variable names to their values and it can optionally take a second parameter `outputs` which maps output names to their values.\n\n- `n_iter`: The number of iterations of unique input combinations to try.\n\n- `replications`: The number of times to replicate an iteration of unique inputs. Replications are only useful when the user's `evaluator` is stochastic/non-deterministic and inputs need to be evaluated multiple times. The value for this parameter can be an `int` which specifies the number of replications that should be done for each iteration or the value can be a `tuple` which specifies the minimum and maximum number of replications that will be done for each iteration e.g. `(5, 20)`. See [Replications Example](#replications-example) for more details.\n\n- `parallel_evaluators`: The maximum allowed number of concurrent calls to the `evaluator` callback function (which was passed to the [`OptQuestOptimizer` constructor](#optquestoptimizer-constructor-parameters).)  The `evaluator` function must be reentrant and if it uses shared state, it is responsible for managing the synchronization (e.g., `mutex`es) as needed.\n\n- `suggested_runs`: A dict containing solutions to evaluate as the first iterations. See `oqo_example_suggested_runs.py` for a demonstration.\n\n## Supported Variable Types\n\n### <u>Continuous</u>\n\nA continuous variables is simply a real value, e.g. _3.14159_.\n\n**Properties**\n- `min`: the lower bound (inclusive) on the values the variable can take on.\n- `max`: the upper bound (inclusive) on the values the variable can take on.\n\n### <u>Discrete</u>\nDiscrete variables are continuous variables that are constrained to values at step intervals, e.g. _1.5, 3, 4.5, 6_ for a step size of _1.5_.\n\n**Properties**\n- `min`: Lower bound (inclusive) on the values the variable can take on. The variable can necessarily take on this value as well.\n- `max`: Upper bound on the values the variable can take on. The variable can take on this value only if `max` - `min` is an integer multiple of `step`.\n- `step`: The step size; the range of values the variable can take is `min`, `min` + 1*`step`, `min` + 2*`step`, `min` + 3*`step`, etc.\n\n### <u>Integer</u>\nAn integer variable can only take real integer values.\n\n**Properties**\n- _min_: the lower bound (inclusive) on the values the variable can take on.\n- _max_: the upper bound (inclusive) on the values the variable can take on.\n\n### <u>Binary</u>\nCan only take on values 0 and 1.\n\n### <u>Enumeration</u>\nAn enumeration variable is limited to taking on values from an enumerated list of values e.g. _{7, 10, 25}_.\n\n**Properties**\n- _values_: the enumerated list of values the variable can take on. The format can be an iterable with numeric members, a comma delimited string of values, or a space delimited string of values.\n\n### <u>Permutation</u>\nWhen you define a permutation type in `search_space` a permutation group is created. A permutation group contains multiple permutation variables. Each variable will be an integer value representing that variable's index within the group (starting at index 1.)\n\n**Properties**\n- _elements_: The argument for this property can either be an integer or a list of strings. An integer will specify the number of elements (permutation variables) the permutation group should have. If a list of strings is passed, then each string in the list becomes the name of a permutation variable in the group.\n\n## Demonstration of Variable Types\n\nHere's a cheat sheet demonstrating how each variable type can be defined:\n\n```py\nsearch_space = {\n    'continuous_var': {'type': 'continuous', 'min': -5, 'max': 5},\n    'discrete_var': {'type': 'discrete', 'min': -1.5, 'max': 4.5, 'step': 1.5},\n    'integer_var': {'type': 'integer', 'min': -3, 'max': 3},\n    'binary_var': {'type': 'binary'},\n    'enumeration_var1': {'type': 'enumeration', 'values': [1, 2, 3]},\n    'enumeration_var2': {'type': 'enumeration', 'values': np.array([1, 2, 3])},\n    'enumeration_var3': {'type': 'enumeration', 'values': '1, 2, 3'},\n    'permutation_grp_A': {'type': 'permutation', 'elements': ['one', 'two', 'three']},\n    'permutation_grp_B': {'type': 'permutation', 'elements': 3}\n}\n```\n\n## Expression Syntax\n\nExpressions can be used when defining objectives or constraints.\n\nWhen defining a constraint, the expression must contain a comparison operator. The supported comparison operators are `=`, `<=`, and `>=`.\n\nThe following functions can be used when creating string expressions:\n\n| Function | Syntax       | Description                                                                                                            |\n|----------|--------------|------------------------------------------------------------------------------------------------------------------------|\n| min      | `min(x,y)`   | Returns the smaller of two numbers.                                                                                    |\n| max      | `max(x,y)`   | Returns the larger of two numbers.                                                                                     |\n| sqrt     | `sqrt(x)`    | Returns the square root of a number.                                                                                   |\n| log      | `log(x)`     | Returns the natural logarithm of a specified number.                                                                   |\n| log10    | `log10(x)`   | Returns the base 10 logarithm of a specified number.                                                                   |\n| pow      | `pow(x,y`    | Returns a specified number raised to the specified power.                                                              |\n| exp      | `exp(x)`     | Returns e raised to the specified power                                                                                |\n| abs      | `abs(x)`     | Returns the absolute value of a specified number.                                                                      |\n| rand     | `rand()`     | Returns a random number between 0 and 1, inclusive.                                                                    |\n| fmod     | `fmod(x,y)`  | Returns the remainder of x / y.                                                                                        |\n| floor    | `floor(x)`   | Returns the largest whole number less than or equal to the specified number.                                           |\n| ceil     | `ceil(x)`    | Returns the smallest whole number greater than or equal to the specified number.                                       |\n| sin      | `sin(x)`     | Returns the sine of x, where x is an angle in radians.                                                                 |\n| cos      | `cos(x)`     | Returns the cosine of x, where x is an angle in radians.                                                               |\n| tan      | `tan(x)`     | Returns the tangent of x, where x is an angle in radians.                                                              |\n| sinh     | `sinh(x)`    | Returns the hyperbolic sine of x, where x is an angle in radians.                                                      |\n| cosh     | `cosh(x)`    | Returns the hyperbolic cosine of x, where x is an angle in radians.                                                    |\n| tanh     | `tanh(x)`    | Returns the hyperbolic tangent of x, an angle in radians.                                                              |\n| asin     | `asin(x)`    | Returns the arcsine of x in the range –π/2 to π/2.                                                                     |\n| acos     | `acos(x)`    | Returns the arccosine of x in the range 0 to π.                                                                        |\n| atan     | `atan(x)`    | Returns the arctangent of x in the range of –π/2 to π/2 radians.                                                       |\n| atan2    | `atan2(x,y)` | Returns the arctangent of y/x in the range –π to π radians. If both parameters of atan2 are 0, the function returns 0. |\n| DtoR     | `DtoR(x)`    | Converts degrees to radians.                                                                                           |\n| RtoD     | `RtoD(x)`    | Converts radians to degrees.                                                                                           |\n---\n\nAdditionally, the mathematical constants `pi` and `e` are valid expression syntax.\n\n## Provided Examples\n\nThe following examples are provided alongside `OptQuestOptimizer` and most are used in this documentation.\n\n| Example Name                                                | Description                                                                                                                                                                                                                                                                   |\n|-------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| `oqo_example_parabola.py`                                   | The simplest possible example of an optimization with `OptQuestOptimizer`.                                                                                                                                                                                                    |\n| `oqo_example_simulation.py`                                 | Same as `parabola_example.py` but demonstrates how an external simulation can be used.                                                                                                                                                                                        |\n| `oqo_example_objective_evaluator.py`                        | Demonstrates how to use an objective evaluator callback function.                                                                                                                                                                                                             |\n| `oqo_example_constraint.py`                                 | Demonstrates how to define a mathematical constraint.                                                                                                                                                                                                                         |\n| `oqo_example_constraint_evaluator.py`                       | Demonstrates how to define a constraint as a boolean callback function.                                                                                                                                                                                                       |\n| `oqo_example_parallel_evaluations.py`                       | Demonstrates how to enable parallel evaluators.                                                                                                                                                                                                                               |\n| `oqo_example_permutation.py`                                | An example permutation problem optimizing the order of transitions of production machines.                                                                                                                                                                                    |\n| `oqo_example_replications.py`                               | A simple demonstration using a fixed number of replications.                                                                                                                                                                                                                  |\n| `oqo_example_replications_with_confidence.py`               | An advanced demonstration using a variable number of replications and a custom objective confidence configuration.                                                                                                                                                            |\n| `oqo_example_frontier.py`                                   | A demonstration of a problem with multiple objectives.                                                                                                                                                                                                                        |\n| `oqo_example_status_monitor.py`                             | Demonstration of `status_monitor` callback function usage for tracking the progress of an optimization.                                                                                                                                                                       |\n| `oqo_example_user_stop.py`                                  | Demonstration of `user_stop` callback function usage for prematurely stopping an optimization that's in progress.                                                                                                                                                             |\n| `oqo_example_suggested_runs.py`                             | Demonstration of the `suggested_runs` parameter in the `OptQuestOptimizer.search()` function.                                                                                                                                                                                 |\n| `oqo_example_all_variables.py`                              | Shows how to define and use all the variable types supported by the OptQuestOptimizer                                                                                                                                                                                         |\n| `oqo_example_gfo_convex.py` `oqo_example_gfo_non_convex.py` | Examples of passing an objective evaluator to `OptQuestOptimizer.search()` in GFO style.                                                                                                                                                                                      |\n| `oqo_example_cell_tower_location.py`                        | A simple example with a rectangular solution space.                                                                                                                                                                                                                           |\n| `oqo_example_cell_tower_polygon_location.py`                | An advanced example with a non-trivial polygon solution space. Requires the `shapely` package.                                                                                                                                                                                |\n| `oqo_example_radio_antenna.py`                              | An advanced example with a non-trivial polygon solution space, multiple constraints, and usage of many `OptQuestOptimizer` features. Requires the `shapely` package. This example does not work with the demo license supplied in the example.  You need to use your license. |\n---\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "pyoptquest",
    "package_url": "https://pypi.org/project/pyoptquest/",
    "platform": null,
    "project_url": "https://pypi.org/project/pyoptquest/",
    "project_urls": {
      "Homepage": "https://www.opttek.com/"
    },
    "release_url": "https://pypi.org/project/pyoptquest/9.1.1.2/",
    "requires_dist": [
      "pandas",
      "pyjnius>=1.4.1",
      "matplotlib; extra == 'examples'",
      "shapely; extra == 'examples'"
    ],
    "requires_python": ">=3.7",
    "summary": "A python wrapper around the OptQuest library; see more at https://www.opttek.com/products/optquest/",
    "version": "9.1.1.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 15780612,
  "releases": {
    "9.1.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8e965678457f5feb3bcf43893ef7fb9246e00610a8c00060ab98df5a5b0e83e5",
          "md5": "01688f69e356d4c5819b2a5707978a1a",
          "sha256": "3e13c995ab739fd9ae12aaf06a0a7cb16107303a574ea386bf0398aac07fd06f"
        },
        "downloads": -1,
        "filename": "pyoptquest-9.1.1.2-1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "01688f69e356d4c5819b2a5707978a1a",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 42185,
        "upload_time": "2022-11-15T20:34:36",
        "upload_time_iso_8601": "2022-11-15T20:34:36.541578Z",
        "url": "https://files.pythonhosted.org/packages/8e/96/5678457f5feb3bcf43893ef7fb9246e00610a8c00060ab98df5a5b0e83e5/pyoptquest-9.1.1.2-1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "62f9cb3233ac1154c8482494bed9e1c43a8ab3478f04f6483d298e2a6309bfdf",
          "md5": "efe85cd466b571c75f10227ef5d7ade0",
          "sha256": "66bd2751881fb6fbff0a37aec93f198183b973271498a68682ee1a87805cd56a"
        },
        "downloads": -1,
        "filename": "pyoptquest-9.1.1.2-1.tar.gz",
        "has_sig": false,
        "md5_digest": "efe85cd466b571c75f10227ef5d7ade0",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 126092,
        "upload_time": "2022-11-15T20:55:34",
        "upload_time_iso_8601": "2022-11-15T20:55:34.766017Z",
        "url": "https://files.pythonhosted.org/packages/62/f9/cb3233ac1154c8482494bed9e1c43a8ab3478f04f6483d298e2a6309bfdf/pyoptquest-9.1.1.2-1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "8e965678457f5feb3bcf43893ef7fb9246e00610a8c00060ab98df5a5b0e83e5",
        "md5": "01688f69e356d4c5819b2a5707978a1a",
        "sha256": "3e13c995ab739fd9ae12aaf06a0a7cb16107303a574ea386bf0398aac07fd06f"
      },
      "downloads": -1,
      "filename": "pyoptquest-9.1.1.2-1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "01688f69e356d4c5819b2a5707978a1a",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 42185,
      "upload_time": "2022-11-15T20:34:36",
      "upload_time_iso_8601": "2022-11-15T20:34:36.541578Z",
      "url": "https://files.pythonhosted.org/packages/8e/96/5678457f5feb3bcf43893ef7fb9246e00610a8c00060ab98df5a5b0e83e5/pyoptquest-9.1.1.2-1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "62f9cb3233ac1154c8482494bed9e1c43a8ab3478f04f6483d298e2a6309bfdf",
        "md5": "efe85cd466b571c75f10227ef5d7ade0",
        "sha256": "66bd2751881fb6fbff0a37aec93f198183b973271498a68682ee1a87805cd56a"
      },
      "downloads": -1,
      "filename": "pyoptquest-9.1.1.2-1.tar.gz",
      "has_sig": false,
      "md5_digest": "efe85cd466b571c75f10227ef5d7ade0",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 126092,
      "upload_time": "2022-11-15T20:55:34",
      "upload_time_iso_8601": "2022-11-15T20:55:34.766017Z",
      "url": "https://files.pythonhosted.org/packages/62/f9/cb3233ac1154c8482494bed9e1c43a8ab3478f04f6483d298e2a6309bfdf/pyoptquest-9.1.1.2-1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}