{
  "info": {
    "author": "LowinLi",
    "author_email": "lowinli@outlook.com",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Developers",
      "License :: OSI Approved :: Apache Software License",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Topic :: Scientific/Engineering :: Artificial Intelligence"
    ],
    "description": "# fastgpt\n\n[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/fastgpt.svg)](https://pypi.org/project/fastgpt/)\n[![PyPI](https://img.shields.io/pypi/v/fastgpt.svg)](https://pypi.org/project/fastgpt/)\n[![GitHub license badge](https://img.shields.io/github/license/LowinLi/fastgpt)](https://github.com/LowinLi/fastgpt/blob/main/LICENSE)\n[![Blog](https://img.shields.io/badge/blog-LowinLi-important)](https://lowin.li)\n![Codecov](https://img.shields.io/codecov/c/github/LowinLi/fastgpt)\n[![Downloads](https://pepy.tech/badge/fastgpt)](https://pepy.tech/project/fastgpt)\n\n## fastgpt 是什么\n\n- [fastgpt](https://github.com/LowinLi/fastgpt)是一个基于[transformers](https://github.com/huggingface/transformers)和[onnxruntime](https://github.com/microsoft/onnxruntime)的**python**库，可以无缝衔接的使用 onnxruntime 量化后的 transfromers GPT 模型做文本生成任务，提高推理速度、降低资源成本。\n\n## fastgpt 的背景\n\n- **GPT**模型是通过序列文本预测下一个词的训练任务得到的预训练模型，可以在文本生成任务上达到很好的效果。\n- **transformers**库是近些年最火的做预训练模型的 python 库，在其背后的社区，网友、组织分享开源了各式各样的预训练模型，尤其是截止 2022 年 6 月 23 日，[社区](https://huggingface.co/models?pipeline_tag=text-generation&sort=downloads)的开源文本生成模型多达到**5068**个。\n- **onnx**是由微软，亚马逊 ，Facebook 和 IBM 等公司共同开发的，针对机器学习所设计的开放式的文件格式，经过 onnxruntime 量化压缩的预训练模型，在 cpu 硬件上推理速度在各开源框架的对比中首屈一指。\n\n* 然而，通过**transformers**官方的 onnx 接口转换、onnx 量化 API，却没有做好 GPT 模型转换的兼容问题，经常转换失败。而手动进行 onnx 转换需要自定义很多配置，对于新手不很友好。\n\n- **fastgpt**库，就是为了无缝衔接 transformers 库调用 GPT 模型转换 onnx 格式推理，使用者可以在仅修改两行代码的情况下，使用 onnx 量化后的 GPT 模型，做 transformers 库的文本生成函数。\n\n* 原 transformers 代码：\n\n```python\nfrom transformers import AutoModelForCausalLM\nmodel = AutoModelForCausalLM.from_pretrained(\"distilgpt2\")\n```\n\n- fastgpt 代码：\n\n```python\nfrom fastgpt import CausalLMModelForOnnxGeneration\nmodel = CausalLMModelForOnnxGeneration.from_pretrained(\"distilgpt2\")\n```\n\n- 在 fastgpt 这一行代码中，会执行以下流程\n  1. transformers hub 的模型下载\n  2. pytorch 模型推理，输出 logits\n  3. onnx 格式转换\n  4. onnx 格式模型推理，输出 logits，进行对比差异\n  5. onnx 量化\n  6. onnx 量化格式模型推理，输出 logits，进行对比差异\n  7. 把兼容 transformers 文本生成函数的 onnx 格式 GPT 模型，包装到 model 中\n\n## 安装\n\n```bash\npip install fastgpt\n```\n\n## 快速 demo\n\n```python\nfrom transformers import AutoTokenizer\nfrom fastgpt import CausalLMModelForOnnxGeneration\nmodel = CausalLMModelForOnnxGeneration.from_pretrained(\"distilgpt2\")\ntokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n\nprompt_text = \"Natural language processing (NLP) is the ability of a computer program to understand human language as it is spoken and written\"\ninput_ids = tokenizer(\n    prompt_text, return_tensors=\"pt\", add_special_tokens=False\n).input_ids\n\ngenerated_ids = model.generate(   # 这里完全兼容transformers的generate函数\n    input_ids,\n    max_length=64 + input_ids.shape[1],\n    decoder_start_token_id=tokenizer.cls_token_id,\n    eos_token_id=tokenizer.sep_token_id,\n    output_scores=True,\n    temperature=1,\n    repetition_penalty=1.0,\n    top_k=50,\n    top_p=0.9,\n    do_sample=True,\n    num_return_sequences=1,\n    length_penalty=2.0,\n    early_stopping=True,\n)\nprint(tokenizer.decode(generated_ids[0], skip_special_tokens=True))\nprint(\"=\" * 20)\n```\n\n## fastgpt 的优点\n\n1. **兼容 transformers**: 基于 transformers 库的[文本生成函数](https://github.com/huggingface/transformers/blob/v4.20.1/src/transformers/generation_utils.py#L845)，功能非常丰富。fastgpt 在 onnx 格式模型上，兼容该函数。\n2. **兼容 cache**: 在文本生成的一个个 token 生成过程中的`past_key_value`需要在 GPT 模型上持续迭代输入，fastgpt 已经通过 onnx 格式做好衔接。\n3. **代码修改低成本**：代码替换原版 transformers 仅需修改两行代码。\n4. **onnx 格式占内存小**：对于 distilgpt2 模型，torch 版`318MB`, onnx 量化版`243MB`\n5. **cpu 上速度更快**: 用时约降低 **33%**\n\n## 生成速度评测(ms)\n\n- 生成长度 4 评测\n\n| 模型框架 | beam:1  | beam:2  | beam:3  | beam:4  |\n| -------- | ------- | ------- | ------- | ------- |\n| torch    | 290.779 | 475.693 | 560.458 | 648.756 |\n| fastgpt  | 195.265 | 292.272 | 378.933 | 466.14  |\n\n---\n\n- 生成长度 8 评测\n\n| 模型框架 | beam:1  | beam:2  | beam:3  | beam:4   |\n| -------- | ------- | ------- | ------- | -------- |\n| torch    | 482.199 | 817.065 | 905.646 | 1052.983 |\n| fastgpt  | 341.735 | 471.028 | 583.264 | 713.009  |\n\n---\n\n- 生成长度 16 评测\n\n| 模型框架 | beam:1  | beam:2   | beam:3   | beam:4   |\n| -------- | ------- | -------- | -------- | -------- |\n| torch    | 878.338 | 1518.198 | 1619.336 | 1813.197 |\n| fastgpt  | 635.157 | 838.787  | 1009.497 | 1210.047 |\n\n---\n\n- 生成长度 32 评测\n\n| 模型框架 | beam:1   | beam:2   | beam:3   | beam:4   |\n| -------- | -------- | -------- | -------- | -------- |\n| torch    | 1661.819 | 2854.889 | 3081.585 | 3436.284 |\n| fastgpt  | 1238.585 | 1599.724 | 1921.785 | 2256.674 |\n\n---\n\n- 生成长度 64 评测\n\n| 模型框架 | beam:1   | beam:2   | beam:3   | beam:4   |\n| -------- | -------- | -------- | -------- | -------- |\n| torch    | 3257.929 | 4274.201 | 4256.85  | 4677.168 |\n| fastgpt  | 2510.484 | 3081.851 | 2697.296 | 3150.157 |\n\n---\n\nmodel name : Intel(R) Xeon(R) CPU E5-2673 v4 @ 2.30GHz\ncpu cores : 2\n\n详见 GITHUB ACTIONS 的[cml 报告](https://github.com/LowinLi/fastgpt/commit/044567f960dd05fb0ef06870cf12002718ed5861#commitcomment-76805953)\n\n## 补充\n1. 对于[CodeGen](https://github.com/salesforce/CodeGen)系列代码生成模型，官方是不支持`transformers`库的，因此不能直接用`fastgpt`加载，请转至[example/codegen](https://github.com/LowinLi/fastgpt/tree/main/example/codegen)进行onnx量化和文本生成\n## 感谢\n\n- [transformers](https://github.com/huggingface/transformers)\n- [fastT5](https://github.com/Ki6an/fastT5)\n- [onnxruntime](https://github.com/microsoft/onnxruntime)\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/LowinLi/fastgpt",
    "keywords": "GPT,ONNX,onnxruntime,NLP,model hubtransformer,quantization,text generation,summarization,translation,q&a,qg,machine learning,fast inference,CausalLM",
    "license": "MIT License",
    "maintainer": "",
    "maintainer_email": "",
    "name": "fastgpt",
    "package_url": "https://pypi.org/project/fastgpt/",
    "platform": null,
    "project_url": "https://pypi.org/project/fastgpt/",
    "project_urls": {
      "Bug Tracker": "https://github.com/LowinLi/fastgpt/issues",
      "Homepage": "https://github.com/LowinLi/fastgpt",
      "Repo": "https://github.com/LowinLi/fastgpt"
    },
    "release_url": "https://pypi.org/project/fastgpt/0.0.8/",
    "requires_dist": null,
    "requires_python": ">=3.5",
    "summary": "boost inference speed of GPT models in transformers by onnxruntime",
    "version": "0.0.8",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16979408,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7c865050d999e8f590888506f0b8927452d9c737ebf77913103855e3543137f1",
          "md5": "27cc241210e50409947145887d0d66b8",
          "sha256": "b1301c6449b267459da9f46b04fa412d72d6941e989a56e830adecb15cac00f5"
        },
        "downloads": -1,
        "filename": "fastgpt-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "27cc241210e50409947145887d0d66b8",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 5137,
        "upload_time": "2022-06-18T09:10:33",
        "upload_time_iso_8601": "2022-06-18T09:10:33.797906Z",
        "url": "https://files.pythonhosted.org/packages/7c/86/5050d999e8f590888506f0b8927452d9c737ebf77913103855e3543137f1/fastgpt-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b281bbbfe12f91f0e499a4c8d4ab48f8b03462939742dffd52fb3d64fe1e300d",
          "md5": "097dc64106c305b20bf40c0fd5c629e6",
          "sha256": "c325d83e51c2d7f20bc010b5ec637a0d449c58ab595e14f9b756e837c33ffa11"
        },
        "downloads": -1,
        "filename": "fastgpt-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "097dc64106c305b20bf40c0fd5c629e6",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 5190,
        "upload_time": "2022-06-19T00:23:22",
        "upload_time_iso_8601": "2022-06-19T00:23:22.220824Z",
        "url": "https://files.pythonhosted.org/packages/b2/81/bbbfe12f91f0e499a4c8d4ab48f8b03462939742dffd52fb3d64fe1e300d/fastgpt-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f3c3f3aad2f030c5dc5ad5ce596e8e8fb0bbaaaa866c8bbe45c1dd70022200b6",
          "md5": "cd3c67b16bfd8dbab6f8011a01dbeebd",
          "sha256": "e3ea1eab9cdc2ef6330a3cac3b2282aaeb2289f3866b22b7557f805ece0b9eee"
        },
        "downloads": -1,
        "filename": "fastgpt-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "cd3c67b16bfd8dbab6f8011a01dbeebd",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 10570,
        "upload_time": "2022-06-23T07:44:01",
        "upload_time_iso_8601": "2022-06-23T07:44:01.832886Z",
        "url": "https://files.pythonhosted.org/packages/f3/c3/f3aad2f030c5dc5ad5ce596e8e8fb0bbaaaa866c8bbe45c1dd70022200b6/fastgpt-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "70f40a5c21b44eb3c9f09dad6c10fc9952223ca36273ab31ab9916ca13c3a107",
          "md5": "10bee3bc96465e188fa8fcf160980eac",
          "sha256": "a27d3ede01d4d31a31022bfbfa8c7339817aebae6cec0479fde0227954c9ed02"
        },
        "downloads": -1,
        "filename": "fastgpt-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "10bee3bc96465e188fa8fcf160980eac",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 11932,
        "upload_time": "2022-06-27T12:48:21",
        "upload_time_iso_8601": "2022-06-27T12:48:21.273103Z",
        "url": "https://files.pythonhosted.org/packages/70/f4/0a5c21b44eb3c9f09dad6c10fc9952223ca36273ab31ab9916ca13c3a107/fastgpt-0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "31b85c000c65ef606cf49682feb3a3673849053cca1ed2709511cd5beea5b0d1",
          "md5": "2503cd3340a3779232f2295840315a2d",
          "sha256": "d88ebf044162a87fd314eeff1fd7c52cfcced07173b3b576ab799880756e4a26"
        },
        "downloads": -1,
        "filename": "fastgpt-0.0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "2503cd3340a3779232f2295840315a2d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 11931,
        "upload_time": "2022-06-27T13:21:05",
        "upload_time_iso_8601": "2022-06-27T13:21:05.126859Z",
        "url": "https://files.pythonhosted.org/packages/31/b8/5c000c65ef606cf49682feb3a3673849053cca1ed2709511cd5beea5b0d1/fastgpt-0.0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3c5ae81b1fb2b703b36e998158cc1deb2f6ae3b987e6c7f35302d98f7edc77c9",
          "md5": "a4917c1bb3df3f6d77686ae0f69af2f6",
          "sha256": "f5980904bbb88cc8f3c7eb85520b4d284534460dca1ac5ac1e9a5ebbf6e2d953"
        },
        "downloads": -1,
        "filename": "fastgpt-0.0.6.tar.gz",
        "has_sig": false,
        "md5_digest": "a4917c1bb3df3f6d77686ae0f69af2f6",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 11930,
        "upload_time": "2022-06-27T13:24:28",
        "upload_time_iso_8601": "2022-06-27T13:24:28.189345Z",
        "url": "https://files.pythonhosted.org/packages/3c/5a/e81b1fb2b703b36e998158cc1deb2f6ae3b987e6c7f35302d98f7edc77c9/fastgpt-0.0.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "04559192d2531a08d79847d4e6d2f165b6716bf2d6f0d6898b3eb846174186e2",
          "md5": "29d7ae4d631691216be8f44f6c4defdb",
          "sha256": "d4ba23ec786d73cc7642f616323d3af7a483c9e9559f44c306223d1d211d99fd"
        },
        "downloads": -1,
        "filename": "fastgpt-0.0.7.tar.gz",
        "has_sig": false,
        "md5_digest": "29d7ae4d631691216be8f44f6c4defdb",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 11933,
        "upload_time": "2022-06-28T04:03:42",
        "upload_time_iso_8601": "2022-06-28T04:03:42.811867Z",
        "url": "https://files.pythonhosted.org/packages/04/55/9192d2531a08d79847d4e6d2f165b6716bf2d6f0d6898b3eb846174186e2/fastgpt-0.0.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "656beb879bc7f9227f5638c81cfe717ae893c3eacc535ad0b4d74f3fa9cc749a",
          "md5": "f97fe7729e439bd1838f217547afc4a5",
          "sha256": "8b405a88d74745daa44a70cee031f691f780e7b6add10f17c428a5179f932847"
        },
        "downloads": -1,
        "filename": "fastgpt-0.0.8.tar.gz",
        "has_sig": false,
        "md5_digest": "f97fe7729e439bd1838f217547afc4a5",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 12527,
        "upload_time": "2023-02-22T17:13:38",
        "upload_time_iso_8601": "2023-02-22T17:13:38.463625Z",
        "url": "https://files.pythonhosted.org/packages/65/6b/eb879bc7f9227f5638c81cfe717ae893c3eacc535ad0b4d74f3fa9cc749a/fastgpt-0.0.8.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "656beb879bc7f9227f5638c81cfe717ae893c3eacc535ad0b4d74f3fa9cc749a",
        "md5": "f97fe7729e439bd1838f217547afc4a5",
        "sha256": "8b405a88d74745daa44a70cee031f691f780e7b6add10f17c428a5179f932847"
      },
      "downloads": -1,
      "filename": "fastgpt-0.0.8.tar.gz",
      "has_sig": false,
      "md5_digest": "f97fe7729e439bd1838f217547afc4a5",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.5",
      "size": 12527,
      "upload_time": "2023-02-22T17:13:38",
      "upload_time_iso_8601": "2023-02-22T17:13:38.463625Z",
      "url": "https://files.pythonhosted.org/packages/65/6b/eb879bc7f9227f5638c81cfe717ae893c3eacc535ad0b4d74f3fa9cc749a/fastgpt-0.0.8.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}