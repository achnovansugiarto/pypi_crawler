{
  "info": {
    "author": "Bernhard Walser",
    "author_email": "berniwal1997@hotmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3.6",
      "Topic :: Scientific/Engineering :: Artificial Intelligence"
    ],
    "description": "![Linear Self Attention](./images/swin_transformer.png)\n\n## Swin Transformer - PyTorch\n\nImplementation of the [Swin Transformer](https://arxiv.org/pdf/2103.14030.pdf) architecture. This paper presents a new vision Transformer, called Swin Transformer, that capably serves as a general-purpose backbone for computer vision. Challenges in adapting Transformer from language to vision arise from differences between the two domains, such as large variations in the scale of visual entities and the high resolution of pixels in images compared to words in text. To address these differences, we propose a hierarchical Transformer whose representation is computed with shifted windows. The shifted windowing scheme brings greater efficiency by limiting self-attention computation to non-overlapping local windows while also allowing for cross-window connection. This hierarchical architecture has the flexibility to model at various scales and has linear computational complexity with respect to image size. These qualities of Swin Transformer make it compatible with a broad range of vision tasks, including image classification (86.4 top-1 accuracy on ImageNet-1K) and dense prediction tasks such as object detection (58.7 box AP and 51.1 mask AP on COCO test-dev) and semantic segmentation (53.5 mIoU on ADE20K val). Its performance surpasses the previous state-of-the-art by a large margin of +2.7 box AP and +2.6 mask AP on COCO, and +3.2 mIoU on ADE20K, demonstrating the potential of Transformer-based models as vision backbones.\n\nThis is **NOT** the official repository of the Swin Transformer. At the moment in time the official code of the authors is not available yet but can be found later at: [https://github.com/microsoft/Swin-Transformer](https://github.com/microsoft/Swin-Transformer).\n\nAll credits go to the authors [Ze Liu](https://github.com/zeliu98/), [Yutong Lin](https://github.com/impiga), [Yue Cao](http://yue-cao.me), [Han Hu](https://sites.google.com/site/hanhushomepage/), [Yixuan Wei](https://github.com/weiyx16), [Zheng Zhang](https://stupidzz.github.io/), [Stephen Lin](https://scholar.google.com/citations?user=c3PYmxUAAAAJ&hl=en) and [Baining Guo](https://www.microsoft.com/en-us/research/people/bainguo/).\n### Install\n\n```bash\n$ pip install swin-transformer-pytorch\n```\n\nor (if you clone the repository)\n\n```bash\n$ pip install -r requirements.txt\n```\n\n### Usage\n\n```python\nimport torch\nfrom swin_transformer_pytorch import SwinTransformer\n\nnet = SwinTransformer(\n    hidden_dim=96,\n    layers=(2, 2, 6, 2),\n    heads=(3, 6, 12, 24),\n    channels=3,\n    num_classes=3,\n    head_dim=32,\n    window_size=7,\n    downscaling_factors=(4, 2, 2, 2),\n    relative_pos_embedding=True\n)\ndummy_x = torch.randn(1, 3, 224, 224)\nlogits = net(dummy_x)  # (1,3)\nprint(net)\nprint(logits)\n```\n### Parameters\n- `hidden_dim`: int.  \nWhat hidden dimension you want to use for the architecture, noted C in the original paper\n- `layers`: 4-tuple of ints divisible by 2.  \nHow many layers in each stage to apply. Every int should be divisible by two because we are always applying a regular and a shifted SwinBlock together.\n- `heads`: 4-tuple of ints   \nHow many heads in each stage to apply.\n- `channels`: int.  \nNumber of channels of the input.    \n- `num_classes`: int.  \nNum classes the output should have.    \n- `head_dim`: int.  \nWhat dimension each head should have.    \n- `window_size`: int.  \nWhat window size to use, make sure that after each downscaling the image dimensions are still divisible by the window size.    \n- `downscaling_factors`: 4-tuple of ints.  \nWhat downscaling factor to use in each stage. Make sure image dimension is large enough for downscaling factors.    \n- `relative_pos_embedding`: bool.  \nWhether to use learnable relative position embedding (2M-1)x(2M-1) or full positional embeddings (M²xM²).\n### TODO\n- Adjust code for and validate on ImageNet-1K and COCO 2017\n\n### References\nSome part of the code is adapted from the PyTorch - VisionTransformer repository [https://github.com/lucidrains/vit-pytorch](https://github.com/lucidrains/vit-pytorch) ,\nwhich provides a very clean VisionTransformer implementation to start with.\n\n### Citations\n\n```bibtex\n@misc{liu2021swin,\n      title={Swin Transformer: Hierarchical Vision Transformer using Shifted Windows}, \n      author={Ze Liu and Yutong Lin and Yue Cao and Han Hu and Yixuan Wei and Zheng Zhang and Stephen Lin and Baining Guo},\n      year={2021},\n      eprint={2103.14030},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV}\n}\n```\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/berniwal/swin-transformer-pytorch",
    "keywords": "artificial intelligence,attention mechanism,image recognition",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "swin-transformer-pytorch",
    "package_url": "https://pypi.org/project/swin-transformer-pytorch/",
    "platform": "",
    "project_url": "https://pypi.org/project/swin-transformer-pytorch/",
    "project_urls": {
      "Homepage": "https://github.com/berniwal/swin-transformer-pytorch"
    },
    "release_url": "https://pypi.org/project/swin-transformer-pytorch/0.4.1/",
    "requires_dist": [
      "torch (>=1.8.1)",
      "einops (>=0.3.0)"
    ],
    "requires_python": "",
    "summary": "Swin Transformer - Pytorch",
    "version": "0.4.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 9917356,
  "releases": {
    "0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8f8cc29de1cc47ea2a92a7e74850cbb0a37b1cb02a46c30e549ce6f83f44edcc",
          "md5": "6bd38600943be2a91ac1940f8eef7a22",
          "sha256": "077f5940542be31e369703a93718b19aa4120e4e6b6fe3682cefb90467c9dc9e"
        },
        "downloads": -1,
        "filename": "swin_transformer_pytorch-0.1-py2-none-any.whl",
        "has_sig": false,
        "md5_digest": "6bd38600943be2a91ac1940f8eef7a22",
        "packagetype": "bdist_wheel",
        "python_version": "py2",
        "requires_python": null,
        "size": 6649,
        "upload_time": "2021-03-28T10:55:32",
        "upload_time_iso_8601": "2021-03-28T10:55:32.897411Z",
        "url": "https://files.pythonhosted.org/packages/8f/8c/c29de1cc47ea2a92a7e74850cbb0a37b1cb02a46c30e549ce6f83f44edcc/swin_transformer_pytorch-0.1-py2-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4a5959b7cdad0158f1bd0a878527df15ed857f7bca15a2dc8c74dcd97d99b947",
          "md5": "d97b291a9bf5daee694c4f990027a9f7",
          "sha256": "0d72a92c36c3c175be442ed07d4e7b9cf2c5b333af31c569181fd91ee0198a87"
        },
        "downloads": -1,
        "filename": "swin_transformer_pytorch-0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d97b291a9bf5daee694c4f990027a9f7",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 11174,
        "upload_time": "2021-03-28T11:05:32",
        "upload_time_iso_8601": "2021-03-28T11:05:32.674255Z",
        "url": "https://files.pythonhosted.org/packages/4a/59/59b7cdad0158f1bd0a878527df15ed857f7bca15a2dc8c74dcd97d99b947/swin_transformer_pytorch-0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6b613cbb0b2a54e5ae162580126ede3173cbac588abec9d6410bf766016d901b",
          "md5": "d82486a794bbfb1691b0c9e07f9a5c78",
          "sha256": "d3592eae4c0a1e8fd594cd5ebfa3633f633200560d991908e8738782f14d0836"
        },
        "downloads": -1,
        "filename": "swin_transformer_pytorch-0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d82486a794bbfb1691b0c9e07f9a5c78",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 11199,
        "upload_time": "2021-03-28T11:13:06",
        "upload_time_iso_8601": "2021-03-28T11:13:06.917793Z",
        "url": "https://files.pythonhosted.org/packages/6b/61/3cbb0b2a54e5ae162580126ede3173cbac588abec9d6410bf766016d901b/swin_transformer_pytorch-0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "faa20c64ac84ea08abdd6b829e814e11850b054592483b39e62574b864ff8222",
          "md5": "92c0a2bae717b0aafb79e13463c94bcc",
          "sha256": "9693510cb25a7e1f9846e02ca2954a806d77a9490cf83a510d0f5b8d94521862"
        },
        "downloads": -1,
        "filename": "swin_transformer_pytorch-0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "92c0a2bae717b0aafb79e13463c94bcc",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 11538,
        "upload_time": "2021-03-29T17:48:39",
        "upload_time_iso_8601": "2021-03-29T17:48:39.726162Z",
        "url": "https://files.pythonhosted.org/packages/fa/a2/0c64ac84ea08abdd6b829e814e11850b054592483b39e62574b864ff8222/swin_transformer_pytorch-0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4443895a888b2f937a2e6c90e18fd62fdd4ccb5caa94651ff44787f9b66b17c2",
          "md5": "64fdb73592a15ff7307e3bc1972453fd",
          "sha256": "4e839db12391a0386ca841fc3e4407e9226f74064803cc6189108648fbd64fbb"
        },
        "downloads": -1,
        "filename": "swin_transformer_pytorch-0.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "64fdb73592a15ff7307e3bc1972453fd",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 11534,
        "upload_time": "2021-03-29T17:54:59",
        "upload_time_iso_8601": "2021-03-29T17:54:59.550943Z",
        "url": "https://files.pythonhosted.org/packages/44/43/895a888b2f937a2e6c90e18fd62fdd4ccb5caa94651ff44787f9b66b17c2/swin_transformer_pytorch-0.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "96d5cc4f7b8ed8b051d34a0789010f4f0296ceecae55c882cb55d6866706e182",
          "md5": "fb83ffa56c5ba1ee7a30bb283e0475f3",
          "sha256": "00a4b0f6d62a88493a69746fc0fb7390be24a97c49d5da9bb5b9b4098f136720"
        },
        "downloads": -1,
        "filename": "swin_transformer_pytorch-0.4.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "fb83ffa56c5ba1ee7a30bb283e0475f3",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 11548,
        "upload_time": "2021-03-29T20:54:56",
        "upload_time_iso_8601": "2021-03-29T20:54:56.724473Z",
        "url": "https://files.pythonhosted.org/packages/96/d5/cc4f7b8ed8b051d34a0789010f4f0296ceecae55c882cb55d6866706e182/swin_transformer_pytorch-0.4.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "96d5cc4f7b8ed8b051d34a0789010f4f0296ceecae55c882cb55d6866706e182",
        "md5": "fb83ffa56c5ba1ee7a30bb283e0475f3",
        "sha256": "00a4b0f6d62a88493a69746fc0fb7390be24a97c49d5da9bb5b9b4098f136720"
      },
      "downloads": -1,
      "filename": "swin_transformer_pytorch-0.4.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "fb83ffa56c5ba1ee7a30bb283e0475f3",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 11548,
      "upload_time": "2021-03-29T20:54:56",
      "upload_time_iso_8601": "2021-03-29T20:54:56.724473Z",
      "url": "https://files.pythonhosted.org/packages/96/d5/cc4f7b8ed8b051d34a0789010f4f0296ceecae55c882cb55d6866706e182/swin_transformer_pytorch-0.4.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}