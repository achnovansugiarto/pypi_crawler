{
  "info": {
    "author": "Elad Nachmias",
    "author_email": "eladnah@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# TensorsDataClass\nPyTorch Extension Library for organizing tensors in a form of a structured tree of dataclasses, with built-in support for advanced collating mechanisms. The batch creation process seamlessly solves issues like: sequences padding, un/flattening variable #objects per example into a single batch dimension, fixing within-example indices to be batch-based indices, auto-creation of sequences & collate masks, and more.\n\n# What pains TensorsDataClass aims to solve\n... variable number of sequences per example where the sequence lengths may also be variable; lots of inputs usually gets messy - hard to handle, to name, to move to GPU, to abstract in a (X,Y) fashion ...\n\n# Installation\n```bash\npip install tensors-data-class\n```\n\n# Usage example\n```python\n# TODO: simplify the below example. still use these:\n#   BatchFlattenedSeq, BatchFlattenedTensor,\n#   BatchedFlattenedIndicesFlattenedTensor,\n#   BatchedFlattenedIndicesFlattenedSeq,\n#   BatchedFlattenedIndicesPseudoRandomPermutationBatchedFlattenedIndicesPseudoRandomPermutation,\n#   BatchFlattenedPseudoRandomSamplerFromRange\n\nfrom tensors_data_class import *\n\n@dataclasses.dataclass\nclass CodeExpressionTokensSequenceInputTensors(TensorsDataClass):\n    token_type: BatchFlattenedSeq  # (nr_expressions_in_batch, batch_max_nr_tokens_in_expr)\n    kos_token_index: BatchFlattenedTensor  # (nr_kos_tokens_in_all_expressions_in_batch,)\n    identifier_index: BatchedFlattenedIndicesFlattenedTensor  # (nr_identifier_tokens_in_all_expressions_in_batch,)\n\n\n@dataclasses.dataclass\nclass SymbolsInputTensors(TensorsDataClass):\n    symbols_identifier_indices: BatchedFlattenedIndicesFlattenedTensor  # (nr_symbols_in_batch,);  value meaning: identifier batched index\n    symbols_appearances_symbol_idx: BatchedFlattenedIndicesFlattenedTensor  # (nr_symbols_appearances,);\n    symbols_appearances_expression_token_idx: BatchFlattenedTensor = None  # (nr_symbols_appearances,);\n    symbols_appearances_cfg_expression_idx: BatchedFlattenedIndicesFlattenedTensor = None  # (nr_symbols_appearances,);\n\n\n@dataclasses.dataclass\nclass CFGPathsInputTensors(TensorsDataClass):\n    nodes_indices: BatchedFlattenedIndicesFlattenedSeq\n    edges_types: BatchFlattenedSeq\n\n\n@dataclasses.dataclass\nclass CFGPathsNGramsInputTensors(TensorsDataClass):\n    nodes_indices: BatchedFlattenedIndicesFlattenedSeq\n    edges_types: BatchFlattenedSeq\n\n\n@dataclasses.dataclass\nclass PDGInputTensors(TensorsDataClass):\n    cfg_nodes_control_kind: Optional[BatchFlattenedTensor] = None  # (nr_cfg_nodes_in_batch, )\n    cfg_nodes_has_expression_mask: Optional[BatchFlattenedTensor] = None  # (nr_cfg_nodes_in_batch, )\n    cfg_nodes_tokenized_expressions: Optional[CodeExpressionTokensSequenceInputTensors] = None\n    cfg_nodes_random_permutation: Optional[BatchedFlattenedIndicesPseudoRandomPermutation] = None\n    cfg_control_flow_paths: Optional[CFGPathsInputTensors] = None\n    cfg_control_flow_paths_ngrams: Optional[Dict[int, CFGPathsNGramsInputTensors]] = None\n\n\n@dataclasses.dataclass\nclass IdentifiersInputTensors(TensorsDataClass):\n    sub_parts_batch: BatchFlattenedTensor  # (nr_sub_parts_in_batch, )\n    identifier_sub_parts_index: BatchedFlattenedIndicesFlattenedSeq  # (nr_identifiers_in_batch, batch_max_nr_sub_parts_in_identifier)\n    identifier_sub_parts_vocab_word_index: BatchFlattenedSeq  # (nr_identifiers_in_batch, batch_max_nr_sub_parts_in_identifier)\n    identifier_sub_parts_hashings: BatchFlattenedSeq  # (nr_identifiers_in_batch, batch_max_nr_sub_parts_in_identifier, nr_hashing_features)\n    sub_parts_obfuscation: BatchFlattenedPseudoRandomSamplerFromRange  # (nr_sub_parts_obfuscation_embeddings)\n\n\n@dataclasses.dataclass\nclass MethodCodeInputTensors(TensorsDataClass):\n    example_hash: str\n    identifiers: IdentifiersInputTensors\n    symbols: SymbolsInputTensors\n    method_tokenized_code: Optional[CodeExpressionTokensSequenceInputTensors] = None\n    pdg: Optional[PDGInputTensors] = None\n\nexample1 = MethodCodeInputTensors(...)  # TODO: fill example data\nexample2 = MethodCodeInputTensors(...)  # TODO: fill example data\nbatch = MethodCodeInputTensors.collate([example1, example2])\nprint(batch)\n# TODO: add example for creating a padded-sequence (after applying embedding on the input), unflattening. \n```\n\n# Different types for different use-cases\n## TensorsDataClass\n## BatchFlattenedTensor\n## BatchFlattenedSeq\n## BatchedFlattenedIndicesFlattenedTensor\n## BatchedFlattenedIndicesFlattenedSeq\n## BatchedFlattenedIndicesPseudoRandomPermutationBatchedFlattenedIndicesPseudoRandomPermutation\n## BatchFlattenedPseudoRandomSamplerFromRange\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/eladn/tensors-data-class",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "tensors-data-class",
    "package_url": "https://pypi.org/project/tensors-data-class/",
    "platform": "",
    "project_url": "https://pypi.org/project/tensors-data-class/",
    "project_urls": {
      "Homepage": "https://github.com/eladn/tensors-data-class"
    },
    "release_url": "https://pypi.org/project/tensors-data-class/0.0.1/",
    "requires_dist": [
      "pytorch"
    ],
    "requires_python": "",
    "summary": "PyTorch Extension Library for organizing tensors in a form of a structured tree of dataclasses, with built-in support for advanced collating mechanisms",
    "version": "0.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8574669,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1ad70dc45bc9ccd23aaaca9486f1b7923369b43e0c29fb7c43974554e6490989",
          "md5": "2e011849f1f1fa1d41fd38bfb165d46a",
          "sha256": "41daab7172a7de88830df06f5014a9ce1946db53a8e09f9ad2ed0d45ae171ca6"
        },
        "downloads": -1,
        "filename": "tensors_data_class-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "2e011849f1f1fa1d41fd38bfb165d46a",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 6140,
        "upload_time": "2020-11-03T23:47:11",
        "upload_time_iso_8601": "2020-11-03T23:47:11.227085Z",
        "url": "https://files.pythonhosted.org/packages/1a/d7/0dc45bc9ccd23aaaca9486f1b7923369b43e0c29fb7c43974554e6490989/tensors_data_class-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "1ad70dc45bc9ccd23aaaca9486f1b7923369b43e0c29fb7c43974554e6490989",
        "md5": "2e011849f1f1fa1d41fd38bfb165d46a",
        "sha256": "41daab7172a7de88830df06f5014a9ce1946db53a8e09f9ad2ed0d45ae171ca6"
      },
      "downloads": -1,
      "filename": "tensors_data_class-0.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "2e011849f1f1fa1d41fd38bfb165d46a",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 6140,
      "upload_time": "2020-11-03T23:47:11",
      "upload_time_iso_8601": "2020-11-03T23:47:11.227085Z",
      "url": "https://files.pythonhosted.org/packages/1a/d7/0dc45bc9ccd23aaaca9486f1b7923369b43e0c29fb7c43974554e6490989/tensors_data_class-0.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}