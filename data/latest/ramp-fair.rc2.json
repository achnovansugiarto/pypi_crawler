{
  "info": {
    "author": "Carolyn Johnston",
    "author_email": "carolyn.johnston@dev.global",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# [Replicable AI for Microplanning (ramp)](https://rampml.global/) \n\nOur team aspires to turn over control of the data value chain to humanitarians. The Replicable AI for Microplanning (ramp) project is producing an open-source deep learning model to accurately digitize buildings in low-and-middle-income countries using satellite imagery as well as enable in-country users to build their own deep learning models for their regions of interest.\n\nThis codebase provides python-based machine learning and data processing  tools, based on Tensorflow and the Python geospatial tool set, for using deep learning to predict building models from high-resolution satellite imagery.\n\nThe [ramp online documentation website](https://rampml.global/project-introduction/) contains complete documentation of our mission, the ramp project, the codebase, and the associated (very large) open source dataset of image chips and label geojson files.\n\nThe following screenshots several display examples of predicted building polygons, together with truth polygons, that have been produced by the ramp project group using this codebase (red polygons are predictions, green polygons are training labels provided by human labelers). \n\n### St Vincent AOI\n![St Vincent AOI](docs/images/st_vincent.png)\n\n### Myanmar AOI\n![Myanmar AOI](docs/images/myanmar.png)\n\n### Ghana AOI\n![Ghana AOI](docs/images/ghana.png)\n\nAnd ramp is just getting started.\n\n---\n\n## About the codebase\n\nThings you may want to do with this codebase include:\n\n1. Running the scripts, including production scripts and data preparation tools. \n2. Working with the Jupyter notebooks.\n3. Working with the extensive ramp open source labeled dataset.\n4. Training the models with your own data. \n5. Modifying the underlying code for your own purposes.\n\nThe ramp codebase uses many Python libraries that are in standard use, some specialized libraries for image and geospatial processing, and the Tensorflow library for training and running deep neural networks. It can be very difficult to create a computational environment in which all these libraries are installed and play nicely with each other. \n\nFor this reason, we are also providing instructions to build a Docker image (based on a gpu-enabled Tensorflow 2.8 docker image with Jupyter notebook) that includes all of ramp's libraries and dependencies. All four of the above tasks can be performed from a docker container based on this image. \n\nFor the last 3 tasks, we recommend using vscode, Microsoft's open-source code editor. This code editor easily attaches to the running ramp docker container, and can run Jupyter notebooks, including the ones used to train the ramp models. \n\n---\n\n## Project structure\n\nNote that the ramp project currently contains a fork of the [Solaris project](https://github.com/CosmiQ/solaris), which has not been under active development. Some bugfixes and modifications are in this fork, and some more extensive modifications of Solaris code have been moved into the ramp library.\n\n```\nramp-staging\n├── colab\n│   └── README.md\n│   └── jupyter_lab_on_colab.ipynb\n│   └── train_ramp_model_on_colab.ipynb\n├── data\n├── docker\n│   └── pipped-requirements.txt\n├── Dockerfile\n├── Dockerfile.dev\n├── docs\n│   ├── How_I_set_up_my_training_data.md\n│   ├── how_to_debug_ramp_in_vscode.md\n│   ├── How_to_run_production_and_evaluation.md\n│   ├── list-of-ramp-scripts.md\n│   └── using_the_ramp_training_configuration_file.md\n|   └── images\n├── experiments\n│   ├── dhaka_nw\n│   ├── ghana\n│   ├── gimmosss\n│   ├── himmosss \n├── notebooks\n│   ├── augmentation_demo.ipynb\n│   ├── Data_generator_demo.ipynb\n│   ├── Duplicate_image_check.ipynb\n│   ├── Independent_labelers_comparison_test.ipynb\n│   ├── Train_ramp_model.ipynb\n│   ├── Truncated_signed_distance_transform_example.ipynb\n│   └── View_predictions.ipynb\n│   ├── images\n│   ├── sample-data\n├── ramp\n│   ├── __init__.py\n│   ├── data_mgmt\n│   │   ├── chip_label_pairs.py\n│   │   ├── clr_callback.py\n│   │   ├── data_generator.py\n│   │   ├── display_data.py\n│   │   ├── __init__.py\n│   ├── models\n│   │   ├── effunet_1.py\n│   │   ├── __init__.py\n│   │   ├── model_1_chollet_unet.py\n│   ├── training\n│   │   ├── augmentation_constructors.py\n│   │   ├── callback_constructors.py\n│   │   ├── __init__.py\n│   │   ├── loss_constructors.py\n│   │   ├── metric_constructors.py\n│   │   ├── model_constructors.py\n│   │   ├── optimizer_constructors.py\n│   └── utils\n│       ├── chip_utils.py\n│       ├── eval_utils.py\n│       ├── file_utils.py\n│       ├── geo_utils.py\n│       ├── imgproc_utils.py\n│       ├── img_utils.py\n│       ├── __init__.py\n│       ├── label_utils.py\n│       ├── log_fields.py\n│       ├── lrfinder.py\n│       ├── mask_to_vec_utils.py\n│       ├── misc_ramp_utils.py\n│       ├── model_utils.py\n│       ├── multimask_utils.py\n│       ├── ramp_exceptions.py\n│       └── sdt_mask_utils.py\n├── README.md\n├── scripts\n│   ├── add_area_to_labels.py\n│   ├── binary_masks_from_polygons.py\n│   ├── calculate_accuracy_iou.py\n│   ├── find_learningrate.py\n│   ├── get_chip_statistics.py\n│   ├── get_dataset_loss_statistics.py\n│   ├── get_labels_from_masks.py\n│   ├── get_model_predictions.py\n│   ├── make_train_val_split_lists.py\n│   ├── move_chips_from_csv.py\n│   ├── multi_masks_from_polygons.py\n│   ├── polygonize_masks.py\n│   ├── polygonize_multimasks.py\n│   ├── remove_slivers.py\n│   ├── sdt_masks_from_polygons.py\n│   ├── tile_datasets.py\n│   └── train_ramp.py\n├── setup.py\n├── shell-scripts\n│   ├── create_aggregate_trainingset.bash\n│   ├── create_masks_for_datasets.bash\n│   ├── create_test_split_for_datasets.bash\n│   ├── create_trainval_split_for_datasets.bash\n│   ├── get_iou_metrics_for_datasets.bash\n│   ├── get_iou_metrics_for_models.bash\n│   ├── nvidia-check.sh\n│   ├── run_production_on_datasets.bash\n│   ├── run_production_on_single_dataset.bash\n│   ├── write_predicted_masks_for_datasets.bash\n│   └── write_truth_labels_for_datasets.bash\n└── solaris\n```\n\n---\n\n## How to get the ramp environment running on Google Colab\n\nInstructions for getting started with ramp on Colab are in the colab/README.md file in this codebase. \n\nNote that things will run very slowly and painfully in the free tier of Google Colab. If you will be running often on Google Colab, I recommend upgrading to Google Pro. If you will be using Google Colab as your compute platform for running large ramp training jobs, I recommend considering Google Pro Plus. \n\n## How to get the RAMP environment running on a local server running Ubuntu 20.04 with GPU support\n\n### High level Overview\n\n1. You will need to run Ubuntu 20.04 Linux on a machine with at least one CUDA-enabled NVIDIA GPU. You will absolutely need to have sudo (root user) powers on it.\n2. Install the currently recommended NVIDIA driver: [instructions here](https://linuxize.com/post/how-to-nvidia-drivers-on-ubuntu-20-04/). (It could be worse: happily, you do not need to install the CUDA libraries, as you would if you weren't using Docker).\n3. Install docker CE, and the NVIDIA Container Toolkit ([instructions here](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#docker)).\n4. Create the 'docker' group and add yourself to it, so you can run docker without using sudo ([instructions here](https://docs.docker.com/engine/install/linux-postinstall/)).\n5. Using docker, build the ramp base image, rampbase, as instructed below:\n\n```text\n# run from the ramp-code directory\ndocker build --tag rampbase .\n```\n\n**Important note**: You will have to rebuild rampbase after any change you make in the ramp module codebase (under ramp-code/ramp) so that the change will be installed in the container. This is not the case for running scripts or notebooks.\n\n6. Start a docker container based on rampbase, and run a bash shell in it, as follows:\n\n```\ndocker run -it --rm --gpus=all -v /home/carolyn/ramp-staging:/tf/ramp-staging -v /home/carolyn/ramp-data:/tf/ramp-data  -p 8888:8888 rampbase bash\n```\n\nIf you wish to run a script: do so in the bash shell, using the default python interpreter, which will be loaded with all the components of ramp. \n\nNote that there is a Jupyter notebook server installed in a ramp container, and the *-p 8888:8888* portion of the 'docker run' command enables port forwarding so that you can run Jupyter notebook in a browser on your host machine. \n\nIf you wish to run a Jupyter notebook in your browser or in Jupyterlab, start your docker container using the same command without 'bash' at the end, as shown below. You will be given a link to the running Jupyter notebook server in the command output.\n\n```\ndocker run -it --rm --gpus=all -v /home/carolyn/ramp-staging:/tf/ramp-staging -v /home/carolyn/ramp-data:/tf/ramp-data  -p 8888:8888 rampbase\n```\n\nIf you wish to run a bash shell in the Jupyter notebook container, so that you can run scripts as well as the Jupyter notebook, you can connect a bash shell to the same container using the following commands. \n\nFirst, run:\n\n```\ndocker ps\n```\n\nThis will give an output listing of all the docker containers running on your machine, similar to that given by the Unix ps command:\n\n```\nCONTAINER ID   IMAGE     COMMAND   CREATED       STATUS       PORTS                                       NAMES\n209755699cea   rampdev   \"bash\"    3 hours ago   Up 3 hours   0.0.0.0:8888->8888/tcp, :::8888->8888/tcp   condescending_cerf\n```\n\nYou can use either the container id or the container name to connect to it with a bash shell, using the following command:\n\n```\ndocker exec -it condescending_cerf bash\n```\n\nThis will give you a bash shell in the same container that is running your jupyter notebook. \n\nInstructions on how to debug ramp code, and run Jupyter notebooks, in VScode on your desktop are given in [How to debug ramp in vscode](docs/how_to_debug_ramp_in_vscode.md).\n\n---\n\n## A note on running ramp as yourself, vs. as the root user\n\nNote that by default, Docker runs containers as the root user. If you want to use vscode to attach to the container, you will need to run the container as the root user, because vscode needs root permission to install its server in the container. \n\nThis means that any files you create during the Docker session will have root user ownership. This is undesirable from a security standpoint, and is a hassle when you later need to change or delete the files you created on the local machine. (Note, to fix this problem run the following Linux command: *find . -user root | xargs sudo chown your-username*.)\n\nIf you are just going to interact with the bash shell (say to run production code or a script), I recommend running the container as yourself, rather than the root user. To do that, add the *--user 1000:1000* switch as shown below. \n\n```text\n# run from anywhere as yourself (as the non-root user)\ndocker run -it --rm --gpus=all --user 1000:1000 -v /home/carolyn/ramp-staging:/tf/ramp-staging -v /home/carolyn/ramp-data:/tf/ramp-data -p 8888:8888 rampbase\n```\n\n\n____\n\nLICENSING:\n\nThis software has been licensed under the [Apache 2.0 software license](https://www.apache.org/licenses/LICENSE-2.0.txt).\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "ramp-fair",
    "package_url": "https://pypi.org/project/ramp-fair/",
    "platform": null,
    "project_url": "https://pypi.org/project/ramp-fair/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/ramp-fair/0.1.2/",
    "requires_dist": null,
    "requires_python": ">=3",
    "summary": "Replicable AI for Microplanning , Fork maintained for fAIr",
    "version": "0.1.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16416063,
  "releases": {
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "abf0517ac7b36de3620d8671367ab0dd0e08384e98bfff6b18db52560a037f1a",
          "md5": "838113c6436ca9763cb579f78c201fe8",
          "sha256": "b84a1e772433232a4a6014fc36d3fac117f2975b9cc7bde2c6d483ca07423a1f"
        },
        "downloads": -1,
        "filename": "ramp-fair-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "838113c6436ca9763cb579f78c201fe8",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3",
        "size": 55026,
        "upload_time": "2022-12-10T06:23:04",
        "upload_time_iso_8601": "2022-12-10T06:23:04.852976Z",
        "url": "https://files.pythonhosted.org/packages/ab/f0/517ac7b36de3620d8671367ab0dd0e08384e98bfff6b18db52560a037f1a/ramp-fair-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4c19340b6311cc488750153265eeb7fc48f992942a689843dd53421ec6594b45",
          "md5": "42368054e551c92d99e9301afddd1776",
          "sha256": "e7673dd7f253dc65c26d6927bd3ac3735e73852b32ba8a837a2c34453041d976"
        },
        "downloads": -1,
        "filename": "ramp-fair-0.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "42368054e551c92d99e9301afddd1776",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3",
        "size": 54983,
        "upload_time": "2022-12-14T08:30:52",
        "upload_time_iso_8601": "2022-12-14T08:30:52.687546Z",
        "url": "https://files.pythonhosted.org/packages/4c/19/340b6311cc488750153265eeb7fc48f992942a689843dd53421ec6594b45/ramp-fair-0.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "4c19340b6311cc488750153265eeb7fc48f992942a689843dd53421ec6594b45",
        "md5": "42368054e551c92d99e9301afddd1776",
        "sha256": "e7673dd7f253dc65c26d6927bd3ac3735e73852b32ba8a837a2c34453041d976"
      },
      "downloads": -1,
      "filename": "ramp-fair-0.1.2.tar.gz",
      "has_sig": false,
      "md5_digest": "42368054e551c92d99e9301afddd1776",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3",
      "size": 54983,
      "upload_time": "2022-12-14T08:30:52",
      "upload_time_iso_8601": "2022-12-14T08:30:52.687546Z",
      "url": "https://files.pythonhosted.org/packages/4c/19/340b6311cc488750153265eeb7fc48f992942a689843dd53421ec6594b45/ramp-fair-0.1.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}