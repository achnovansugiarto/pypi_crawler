{
  "info": {
    "author": "Dan Povey",
    "author_email": "dpovey@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Programming Language :: C++",
      "Programming Language :: Python",
      "Topic :: Scientific/Engineering :: Artificial Intelligence"
    ],
    "description": "\nThis project implements a method for faster and more memory-efficient RNN-T loss computation, called `pruned rnnt`.\n\nNote: There is also a fast RNN-T loss implementation in [k2](https://github.com/k2-fsa/k2) project, which shares the same code here. We make `fast_rnnt` a stand-alone project in case someone wants only this rnnt loss.\n\n## How does the pruned-rnnt work ?\n\nWe first obtain pruning bounds for the RNN-T recursion using a simple joiner network that is just an addition of the encoder and decoder, then we use those pruning bounds to evaluate the full, non-linear joiner network.\n\nThe picture below display the gradients (obtained by `rnnt_loss_simple` with `return_grad=true`) of lattice nodes, at each time frame, only a small set of nodes have a non-zero gradient, which justifies the pruned RNN-T loss, i.e., putting a limit on the number of symbols per frame.\n\n<img src=\"https://user-images.githubusercontent.com/5284924/158116784-4dcf1107-2b84-4c0c-90c3-cb4a02f027c9.png\" width=\"900\" height=\"250\" />\n\n> This picture is taken from [here](https://github.com/k2-fsa/icefall/pull/251)\n\n## Installation\n\nYou can install it via `pip`:\n\n```\npip install fast_rnnt\n```\n\nYou can also install from source:\n\n```\ngit clone https://github.com/danpovey/fast_rnnt.git\ncd fast_rnnt\npython setup.py install\n```\n\nTo check that `fast_rnnt` was installed successfully, please run\n\n```\npython3 -c \"import fast_rnnt; print(fast_rnnt.__version__)\"\n```\n\nwhich should print the version of the installed `fast_rnnt`, e.g., `1.0`.\n\n\n### How to display installation log ?\n\nUse\n\n```\npip install --verbose fast_rnnt\n```\n\n### How to reduce installation time ?\n\nUse\n\n```\nexport FT_MAKE_ARGS=\"-j\"\npip install --verbose fast_rnnt\n```\n\nIt will pass `-j` to `make`.\n\n### Which version of PyTorch is supported ?\n\nIt has been tested on PyTorch >= 1.5.0.\n\nNote: The cuda version of the Pytorch should be the same as the cuda version in your environment,\nor it will cause a compilation error.\n\n\n### How to install a CPU version of `fast_rnnt` ?\n\nUse\n\n```\nexport FT_CMAKE_ARGS=\"-DCMAKE_BUILD_TYPE=Release -DFT_WITH_CUDA=OFF\"\nexport FT_MAKE_ARGS=\"-j\"\npip install --verbose fast_rnnt\n```\n\nIt will pass `-DCMAKE_BUILD_TYPE=Release -DFT_WITH_CUDA=OFF` to `cmake`.\n\n### Where to get help if I have problems with the installation ?\n\nPlease file an issue at <https://github.com/danpovey/fast_rnnt/issues>\nand describe your problem there.\n\n\n## Usage\n\n### For rnnt_loss_simple\n\nThis is a simple case of the RNN-T loss, where the joiner network is just\naddition.\n\nNote: termination_symbol plays the role of blank in other RNN-T loss implementations, we call it termination_symbol as it terminates symbols of current frame.\n\n```python\nam = torch.randn((B, T, C), dtype=torch.float32)\nlm = torch.randn((B, S + 1, C), dtype=torch.float32)\nsymbols = torch.randint(0, C, (B, S))\ntermination_symbol = 0\n\nboundary = torch.zeros((B, 4), dtype=torch.int64)\nboundary[:, 2] = target_lengths\nboundary[:, 3] = num_frames\n\nloss = fast_rnnt.rnnt_loss_simple(\n    lm=lm,\n    am=am,\n    symbols=symbols,\n    termination_symbol=termination_symbol,\n    boundary=boundary,\n    reduction=\"sum\",\n)\n```\n\n### For rnnt_loss_smoothed\n\nThe same as `rnnt_loss_simple`, except that it supports `am_only` & `lm_only` smoothing\nthat allows you to make the loss-function one of the form:\n\n          lm_only_scale * lm_probs +\n          am_only_scale * am_probs +\n          (1-lm_only_scale-am_only_scale) * combined_probs\n\nwhere `lm_probs` and `am_probs` are the probabilities given the lm and acoustic model independently.\n\n```python\nam = torch.randn((B, T, C), dtype=torch.float32)\nlm = torch.randn((B, S + 1, C), dtype=torch.float32)\nsymbols = torch.randint(0, C, (B, S))\ntermination_symbol = 0\n\nboundary = torch.zeros((B, 4), dtype=torch.int64)\nboundary[:, 2] = target_lengths\nboundary[:, 3] = num_frames\n\nloss = fast_rnnt.rnnt_loss_smoothed(\n    lm=lm,\n    am=am,\n    symbols=symbols,\n    termination_symbol=termination_symbol,\n    lm_only_scale=0.25,\n    am_only_scale=0.0\n    boundary=boundary,\n    reduction=\"sum\",\n)\n```\n\n### For rnnt_loss_pruned\n\n`rnnt_loss_pruned` can not be used alone, it needs the gradients returned by `rnnt_loss_simple/rnnt_loss_smoothed` to get pruning bounds.\n\n```python\nam = torch.randn((B, T, C), dtype=torch.float32)\nlm = torch.randn((B, S + 1, C), dtype=torch.float32)\nsymbols = torch.randint(0, C, (B, S))\ntermination_symbol = 0\n\nboundary = torch.zeros((B, 4), dtype=torch.int64)\nboundary[:, 2] = target_lengths\nboundary[:, 3] = num_frames\n\n# rnnt_loss_simple can be also rnnt_loss_smoothed\nsimple_loss, (px_grad, py_grad) = fast_rnnt.rnnt_loss_simple(\n    lm=lm,\n    am=am,\n    symbols=symbols,\n    termination_symbol=termination_symbol,\n    boundary=boundary,\n    reduction=\"sum\",\n    return_grad=True,\n)\ns_range = 5  # can be other values\nranges = fast_rnnt.get_rnnt_prune_ranges(\n    px_grad=px_grad,\n    py_grad=py_grad,\n    boundary=boundary,\n    s_range=s_range,\n)\n\nam_pruned, lm_pruned = fast_rnnt.do_rnnt_pruning(am=am, lm=lm, ranges=ranges)\n\nlogits = model.joiner(am_pruned, lm_pruned)\npruned_loss = fast_rnnt.rnnt_loss_pruned(\n    logits=logits,\n    symbols=symbols,\n    ranges=ranges,\n    termination_symbol=termination_symbol,\n    boundary=boundary,\n    reduction=\"sum\",\n)\n```\n\nYou can also find recipes [here](https://github.com/k2-fsa/icefall/tree/master/egs/librispeech/ASR/pruned_transducer_stateless) that uses `rnnt_loss_pruned` to train a model.\n\n\n### For rnnt_loss\n\nThe `unprund rnnt_loss` is the same as `torchaudio rnnt_loss`, it produces same output as torchaudio for the same input.\n\n```python\nlogits = torch.randn((B, S, T, C), dtype=torch.float32)\nsymbols = torch.randint(0, C, (B, S))\ntermination_symbol = 0\n\nboundary = torch.zeros((B, 4), dtype=torch.int64)\nboundary[:, 2] = target_lengths\nboundary[:, 3] = num_frames\n\nloss = fast_rnnt.rnnt_loss(\n    logits=logits,\n    symbols=symbols,\n    termination_symbol=termination_symbol,\n    boundary=boundary,\n    reduction=\"sum\",\n)\n```\n\n\n## Benchmarking\n\nThe [repo](https://github.com/csukuangfj/transducer-loss-benchmarking) compares the speed and memory usage of several transducer losses, the summary in the following table is taken from there, you can check the repository for more details.\n\nNote: As we declared above, `fast_rnnt` is also implemented in [k2](https://github.com/k2-fsa/k2) project, so `k2` and `fast_rnnt` are equivalent in the benchmarking.\n\n|Name\t               |Average step time (us) | Peak memory usage (MB)|\n|--------------------|-----------------------|-----------------------|\n|torchaudio          |601447                 |12959.2                |\n|fast_rnnt(unpruned) |274407                 |15106.5                |\n|fast_rnnt(pruned)   |38112                  |2647.8                 |\n|optimized_transducer|567684                 |10903.1                |\n|warprnnt_numba      |229340                 |13061.8                |\n|warp-transducer     |210772                 |13061.8                |\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/danpovey/fast_rnnt",
    "keywords": "",
    "license": "Apache licensed, as found in the LICENSE file",
    "maintainer": "",
    "maintainer_email": "",
    "name": "fast-rnnt",
    "package_url": "https://pypi.org/project/fast-rnnt/",
    "platform": null,
    "project_url": "https://pypi.org/project/fast-rnnt/",
    "project_urls": {
      "Homepage": "https://github.com/danpovey/fast_rnnt"
    },
    "release_url": "https://pypi.org/project/fast-rnnt/1.2/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "Fast and memory-efficient RNN-T loss.",
    "version": "1.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 15593238,
  "releases": {
    "1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "501311acda3c19e44cd6f49c25949fefb9a160de3dd5019c66278ca3b4acd713",
          "md5": "387d21e42e6b17d859824bd51d5e0c82",
          "sha256": "e1f19ef2d7f3e275fdf32e823cd91b6bde946ba6b75bfbb87d877c26539d441d"
        },
        "downloads": -1,
        "filename": "fast_rnnt-1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "387d21e42e6b17d859824bd51d5e0c82",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 62928,
        "upload_time": "2022-03-16T04:24:07",
        "upload_time_iso_8601": "2022-03-16T04:24:07.208264Z",
        "url": "https://files.pythonhosted.org/packages/50/13/11acda3c19e44cd6f49c25949fefb9a160de3dd5019c66278ca3b4acd713/fast_rnnt-1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4e1844335744bb482980fd555edc89adeafac4bbd6ba78f65b5bd688888fc6d4",
          "md5": "ea86ceded52aa4d8b20a9b0d3c09c7ca",
          "sha256": "1f2269bafc79b2be8fd22bb0832563647eec92c181a933c63ba3207c2e5555dd"
        },
        "downloads": -1,
        "filename": "fast_rnnt-1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "ea86ceded52aa4d8b20a9b0d3c09c7ca",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 63932,
        "upload_time": "2022-10-31T08:26:25",
        "upload_time_iso_8601": "2022-10-31T08:26:25.619121Z",
        "url": "https://files.pythonhosted.org/packages/4e/18/44335744bb482980fd555edc89adeafac4bbd6ba78f65b5bd688888fc6d4/fast_rnnt-1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "4e1844335744bb482980fd555edc89adeafac4bbd6ba78f65b5bd688888fc6d4",
        "md5": "ea86ceded52aa4d8b20a9b0d3c09c7ca",
        "sha256": "1f2269bafc79b2be8fd22bb0832563647eec92c181a933c63ba3207c2e5555dd"
      },
      "downloads": -1,
      "filename": "fast_rnnt-1.2.tar.gz",
      "has_sig": false,
      "md5_digest": "ea86ceded52aa4d8b20a9b0d3c09c7ca",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 63932,
      "upload_time": "2022-10-31T08:26:25",
      "upload_time_iso_8601": "2022-10-31T08:26:25.619121Z",
      "url": "https://files.pythonhosted.org/packages/4e/18/44335744bb482980fd555edc89adeafac4bbd6ba78f65b5bd688888fc6d4/fast_rnnt-1.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}