{
  "info": {
    "author": "Fran Hrzenjak",
    "author_email": "fran.hrzenjak@cognite.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: OS Independent",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Topic :: Internet :: WWW/HTTP :: Dynamic Content",
      "Topic :: Software Development",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "# Synthetic Tags\n\nAn easy way to retrieve values from CDF and execute mathematical operations on them at the same time.\n\n\n## Motivation\n\nTo replace a custom-made structure like this:\n``` python\n{\n    \"EG_SecProd_Biocid\": [\n        (\"EG_13FI1349L.Y\", +1),\n        (\"EG_13FI1350L.Y\", +1),\n    ],\n    \"EG_PrimProd_Scale\": [\n        (\"EG_13FI1318L.Y\", \"EG_13XV1322.Y\", +1),\n        (\"EG_13FI1418L.Y\", \"EG_13XV1422.Y\", +1),\n        (\"EG_13FI1518L.Y\", \"EG_13XV1522.Y\", +1),\n        (\"EG_13FI1618L.Y\", \"EG_13XV1622.Y\", +1),\n        ...\n```\n\nwith something more readable and powerful:\n\n``` python\n{\n    \"EG_SecProd_Biocid\": Tag(\"EG_13FI1349L.Y\") + Tag(\"EG_13FI1350L.Y\"),\n    \"EG_PrimProd_Scale\": (\n        Tag(\"EG_13FI1318L.Y\") * Tag(\"EG_13XV1322.Y\") +\n        Tag(\"EG_13FI1418L.Y\") * Tag(\"EG_13XV1422.Y\") +\n        Tag(\"EG_13FI1518L.Y\") * Tag(\"EG_13XV1522.Y\") +\n        Tag(\"EG_13FI1618L.Y\") * Tag(\"EG_13XV1622.Y\") +\n        ...\n```\n\nTraditionally (by using Cognite SDK for Python), to retrieve a moderately complex set of data from CDF, we would:\n 1. make a list of all the tags\n 2. fetch from CDF and get a dataframe\n 3. rename columns in the dataframe\n 4. perform column-wise calculations\n 5. perform any calculations specific to particular rows\n\nWith **Synthetic Tags** this becomes:\n 1. define any custom column-wise calculations\n 2. make a dict with specifications for columns (a single tag, or an expression involving multiple tags and functions)\n 3. fetch and calculate in one step\n\n\n## Advantages\n\n### Expressive Syntax\n\n``` python\n>>> specs = {\n...     \"some_valve\": Tag(\"FOO.123\"),\n...     \"another_meter\": Tag(\"BAR-456\"),\n...     \"sum_of_2_things\": Tag(\"THING_A\") + Tag(\"THING_B\"),\n... }\n\n>>> TagResolver(retrieval_function).latest(specs)\n{\n    \"some_valve\": 42.0000123,\n    \"another_meter\": 42000.456000,\n    \"sum_of_2_things\": 78.9,\n}\n```\n\n`Tag` class is used as a reference for values that are going to be fetched from API. It \"understands\" many common\nalgebra operations such as:\n * basic math operations: `total_a_b = Tag(\"METER_A\") + Tag(\"METER_B\")`\n * parenthesis and literal values: `complicated_calculation = (Tag(\"METER_C\") - 10) / (Tag(\"METER_D\") + TAG(\"METER_E\"))\"`\n * boolean logic: `alert_status = Tag(\"METER_F\") > 42`\n\nIt also supports function calls, either on multiple tags or on individual tags:\n * calculations on individual tags: `value_int = Tag(\"MEETER_G\").calc(round)`\n * functions with multiple tags: `value_foo = Tag.apply(bar, Tag(\"MEETER_H\"), Tag(\"MEETER_I\"), Tag(\"MEETER_J\"))`\n   * `bar` is a function, see [Calculations with Multiple Tags](#calculations-with-multiple-tags) section below.\n\n\n`TagResolver` is where the actual call to the API happens, and where `Tag` instances are replaced with actual values\nand where math operations are performed. Besides `latest` there is also `resolve` and `df` (find more\ninfo of all three below).\n\n\n\n### Extendability\n\nEasily extendable with additional function calls and / or math operations.\n\n#### Calculations on a Single Tag\n\n`Tag.calc` method takes a callable which will be applied to the result (element-wise) after the value has been fetched\nfrom CDF.\n\n``` python\n>>> def galons_per_minute(val):\n...     return val * 4.40287\n\n>>> specs = {\n...     \"flow_in_sm3_per_hour\": Tag(\"FLOW_METER.123\"),\n...     \"flow_in_galons_per_minute\": Tag(\"FLOW_METER.123\").calc(galons_per_minute),\n... }\n\n>>> TagResolver(retrieval_function).latest(specs)\n{\n    \"flow_in_sm3_per_hour\": 12.3456,\n    \"flow_in_galons_per_minute\": 54.35604149,\n}\n```\n\n#### Calculations with Multiple Tags\n\n`Tag.apply` is a class method that takes a callable and any number of `Tag` instances. When the values are fetched from\nCDF, the callable will be applied (element-wise) with the tag values passed to it as arguments.\n\n``` python\n>>> def closest_to_42(*vals):\n...     \"\"\"Return whichever value in `vals` is closest to 42\"\"\"\n...     deltas = [abs(42 - val) for val in vals]\n...     return vals[deltas.index(min(deltas))]\n\n>>> specs = {\n...     \"value_1\": Tag(\"METER_A\"),\n...     \"value_2\": Tag(\"METER_B\"),\n...     \"value_3\": Tag(\"METER_C\"),\n...     \"answer_to_everything\": Tag.apply(closest_to_42, Tag(\"METER_A\"), Tag(\"METER_B\"), Tag(\"METER_C\")),\n... }\n>>> TagResolver(retrieval_function).latest(specs)\n{\n    \"value_1\": 11,\n    \"value_2\": 44,\n    \"value_3\": 57,\n    \"answer_to_everything\": 44,\n}\n```\n\n##### `Tag.calc` is a Shorthand\n\n`Tag.calc` is provided as a convenience method and for a more readable syntax.\nIt is equivalent to `Tag.apply` with a single argument:\n\n``` python\n# These two lines are equivalent:\nTag(\"FLOW_METER.123\").calc(galons_per_minute)\nTag.apply(galons_per_minute, Tag(\"FLOW_METER.123\"))\n```\n\n#### Referencing Functions by Name\n\nBoth `calc` and `apply` accept a string instead of a callable for their first argument. In this case, the string\nmust match a key in a dict passed to `TagResolver`. This dict contains the actual callables which are then used as\ndescribed above.\n\nThis feature can be used to address issues with importing Python modules, or to specify short functions using `lambda`.\n\n``` python\n>>> my_extension = {\n...     \"galons_per_minute\": lambda val: return val * 4.40287,\n... }\n\n>>> specs = {\n...     \"flow_in_sm3_per_hour\": Tag(\"FLOW_METER.123\"),\n...     \"flow_in_galons_per_minute\": Tag(\"FLOW_METER.123\").calc(\"galons_per_minute\"),\n... }\n\n>>> TagResolver(retrieval_function, my_extension).latest(specs)\n{\n    \"flow_in_sm3_per_hour\": 12.3456,\n    \"flow_in_galons_per_minute\": 54.35604149,\n}\n```\n\n``` python\n>>> def closest_to_42(*vals):\n...     \"\"\"Return whichever value in `vals` is closest to 42\"\"\"\n...     deltas = [abs(42 - val) for val in vals]\n...     return vals[deltas.index(min(deltas))]\n\n>>> specs = {\n...     \"value_1\": Tag(\"METER_A\"),\n...     \"value_2\": Tag(\"METER_B\"),\n...     \"value_3\": Tag(\"METER_C\"),\n...     \"answer_to_everything\": Tag.apply(\"nearest_42\", Tag(\"METER_A\"), Tag(\"METER_B\"), Tag(\"METER_C\")),\n... }\n\n>>> TagResolver(retrieval_function, {\"nearest_42\": closest_to_42}).latest(specs)\n{\n    \"value_1\": 11,\n    \"value_2\": 44,\n    \"value_3\": 57,\n    \"answer_to_everything\": 44,\n}\n```\n\n### Caching and Combined API Calls\n\nAny call to `TagResolver.latest` (or `df` or `resolve`) will result in the minimum number of calls\nto the API to retrieves all needed values.\n\nEach instance of `TagResolver` keeps internal cache and only queries the API for tags that are needed.\n\nIn the next example with multiple calls to `latest()`, the CDF time series API endpoint is hit only once.\n\n``` python\n>>> resolver = TagResolver(retrieval_function)\n\n>>> resolver.latest({\n...     \"value_1\": Tag(\"METER_A\"),\n...     \"value_2\": Tag(\"METER_B\"),\n...     \"value_3\": Tag(\"METER_C\"),\n...     \"val_1_and_2\": Tag(\"METER_A\") + Tag(\"METER_B\"),\n...     \"val_2_and_3\": Tag(\"METER_B\") + Tag(\"METER_C\"),\n...     \"val_1_and_3\": Tag(\"METER_A\") + Tag(\"METER_C\"),\n... })\n{\"value_1\": 12, \"value_2\": 23, \"value_3\": 34, \"val_1_and_2\": 35, \"val_2_and_3\": ...}\n\n>>> resolver.latest({\n...     \"value_1\": Tag(\"METER_A\"),\n...     \"value_1_percent\": 100 * Tag(\"METER_A\") / (Tag(\"METER_A\") + Tag(\"METER_B\") + Tag(\"METER_C\")),\n... })\n{\"value_1\": 12, \"value_1_percent\": 17.3913043478}\n\n>>> resolver.latest({\n...     \"value_2\": Tag(\"METER_B\"),\n...     \"value_2_percent\": 100 * Tag(\"METER_B\") / (Tag(\"METER_A\") + Tag(\"METER_B\") + Tag(\"METER_C\")),\n... })\n{\"value_2\": 23, \"value_2_percent\": 33.3333333333}\n```\n\n\n#### Avoiding Cache\n\nIn case that the caching is not desired (i.e. if we wanted to query CDF again in each of the three `latest()`\ncalls above) we should create a new instance of `TagResolver` for each one (i.e. use\n`TagResolver(retrieval_function).latest` instead of `resolver.latest`).\n\n\n## Multi-value Lookups (Series)\n\nWhile the primary motivation for **Synthetic Tags** library was to facilitate single-value lookups, as seen in the\nexamples so far, the library also supports retrieving of multiple datapoints per tag (as `pd.Series`) as well as\nperforming element-wise operations on them.\n\nSee \"Full examples\" section below for more examples with Series.\n\n\n## Multiple Data Stores\n\n`Tag` class supports specifying a string key for an alternative data store (a.k.a. the fetch function).\nThe corresponding argument has to be present in the `TagResolver` constructor call. This allows us to mix\nand match values from tags obtained from separate CDF API calls.\n\nFor example, we can fetch a single average value of a time series and then multiply it with a series of values from\nanother time series (or, indeed, the same one if desired):\n\n``` python\n>>> resolver = TagResolver(get_series, average=get_average)\n\n>>> resolver.latest({\n...     \"avg_value\": Tag(\"METER_A\", \"average\"),\n...     \"above_average\": Tag(\"METER_A\") > Tag(\"METER_A\", \"average\"),\n... })\n{\n    \"avg_value\": 42,\n    \"above_average: <pd.Series... >,  # series of bool values, True for points that are above 42, False for others\n}\n```\n\nNote: All tags using any particular value store are gathered in a single API call, so no matter how many tags there are,\nthe number of calls to the CDF API will always be equal to the number of value stores.\n\nThere are two caveats to this:\n 1. Any value stores that don't have any tags are not used, i.e. no calls there.\n 2. For really large number of tags, the CDF SDK might split up a single large query into multiple smaller queries\n    that it executes in parallel and then combines the results of. This is an internal implementation detail of\n    the Python CDF SDK and does not affect (not is being affected) by **Cognite Synthetic Tags**.\n\n\n## Limitations\n\n### Boolean expressions\n\nPython does not allow overloading boolean operations, so `bool(Tag(...))` is not allowed (it will raise a `ValueError`\nwith an extensive explanation.)\n\nThis is because expressions like `Tag(A) or Tag(B)` get evaluated immediately, there is no (good) way to defer the\nevaluation until values have been fetched from CDF.\n\n#### Use Bit-wise Operators\n\nExpressions like `Tag(A) | Tag(B)` work as expected.\n\nFull list of bit-wise operators:\n - `and`: `&`\n - `or`: `|`\n - `xor`: `^`\n - `not`: `~`\n\n\n#### Don't Use Ternary Operator\n\nBecause of the limitations discussed here, there is no way to use ternary operator with instances of `Tag` class:\n\n``` python\nspecs = {\n    \"foo\": Tag(A) if Tag(A) > 0 else Tag(B),  # will not work!\n}\n````\n\nInstead, define a custom operation and use `Tag.apply` to apply it:\n``` python\ndef positive_a_or_b(a, b):\n    return a if a > 0 else b\n\nspecs = {\n    \"foo\": Tag.apply(positive_a_or_b, Tag(A), Tag(B)),\n}\n```\n\n\n## Comparison with Synthetic Time Series API\n\nCDF API supports\n[Synthetic Time Series](https://docs.cognite.com/dev/concepts/resource_types/synthetic_timeseries.html). This library\nprovides similar functionality and there is a significant overlap (e.g. both can apply trigonometric functions on\nCDF values).\n\nThe main difference is that Synthetic Time Series performs calculations on the server, whereas **Synthetic Tags**\nfetches only basic data from the API and performs the calculations locally.\n\nPerforming the calculations serverside means less code and fewer opportunities for bugs.\n\nPerforming the calculations locally means more control and extendability.\n\nIn principle some support for the Synthetic Time Series API could be added to this library. TDB.\n\n\n## Full Examples\n\nThis section uses data from OpenIndustrialData project.\n\nEnv for these examples:\n``` bash\nCOGNITE_PROJECT='publicdata'\nCOGNITE_CLIENT_NAME='testing_synth_tags'  # anything\nCOGNITE_API_KEY='<API_KEY>'\n```\n\nGet your API key from https://openindustrialdata.com/get-started/\n\n#### Imports and Data Storage Callable\n\n``` python\n>>> from cognite_synthetic_tags import point_at_time, series, Tag, TagResolver\n>>> from cognite.client import CogniteClient\n\n>>> # CONFIGURE FETCHING PARAMS:\n\n>>> client = CogniteClient()\n>>> get_latest = point_at_time(\n...     client,\n...     query_by=\"external_id\",\n...     at_time=\"90d-ago\",\n...     lookbehind_start_time=\"91d-ago\",\n... )\n\n>>> get_average = point_at_time(\n...     client,\n...     query_by=\"external_id\",\n...     at_time=\"90d-ago\",\n...     lookbehind_limit=10,\n...     aggregate=\"average\",\n...     granularity=\"1h\",\n... )\n\n>>> get_series = series(\n...     client,\n...     query_by=\"external_id\",\n...     start=\"91d-ago\",\n...     end=\"90d-ago\",\n...     aggregate=\"average\",\n...     granularity=\"1h\",\n... )\n\n>>> # just for readability:\n>>> VALVE_22 = \"houston.ro.REMOTE_AI[22]\"\n>>> METER_A = \"houston.ro.REMOTE_AI[3]\"\n>>> METER_B = \"houston.ro.REMOTE_AI[4]\"\n>>> METER_C = \"houston.ro.REMOTE_AI[5]\"\n```\n\n#### Simple Usage\n\n``` python\n>>> # single value (not very useful):\n>>> tag_resolver = TagResolver(get_latest)\n>>> specs = {\"valve\": Tag(VALVE_22)}\n>>> tag_resolver.series(specs)\n{'valve': 0.003925000131130218}\n```\n``` python\n>>> # simple multiplication:\n>>> specs = {\"valve_percent\": 100 * Tag(VALVE_22)}\n>>> tag_resolver.series(specs)\n{'valve_percent': 39.25000130113021085}\n```\n``` python\n>>> # apply a function to a value:\n>>> specs = {\"valve_percent_int\": (100 * Tag(VALVE_22)).calc(round)}\n>>> tag_resolver.series(specs)\n{'valve_percent_int': 39}\n```\n\n> Notice in the last example we cal `calc` on the result of `100 * Tag(...)`. This works because whenever  a `Tag`\n> instance encounters a math operator, it combines with other operands (the liberal value `100` in this example) to\n> create a new `Tag` instance. We have called `calc` method on this new `Tag` instance.\n\n``` python\n>>> # fetch multiple values in a single API call and also perform some math:\n>>> specs = {\n...     \"pressure_1\": Tag(METER_A),\n...     \"pressure_2\": Tag(METER_B),\n...     \"pressure_diff\": Tag(METER_A) - Tag(METER_B),\n...     \"p1_percent\": Tag(METER_A) / (Tag(METER_A) + Tag(METER_B)) * 100,\n... }\n>>> tag_resolver.series(specs)\n{'pressure_1': 1.4,\n 'pressure_2': 35.8,\n 'pressure_diff': -34.4,\n 'p1_percent': 3.763440860215054}\n```\n\n#### Usage with Series\n\n``` python\n>>> specs = {\"valve\": Tag(VALVE_22)}\n>>> tag_resolver = TagResolver(get_series)\n>>> tag_resolver.series(specs)\n{'valve': 2021-06-16 17:21:08    0.239425\n          2021-06-16 17:21:09    1.350200\n          2021-06-16 17:21:10    2.743576\n          2021-06-16 17:21:11    3.544276\n          2021-06-16 17:21:12    3.873974\n          2021-06-16 17:21:14    4.254700\n          2021-06-16 17:21:15    4.509826\n          2021-06-16 17:21:16    4.662900\n          2021-06-16 17:21:17    4.702150\n          2021-06-16 17:21:18    4.706076\n          Name: houston.ro.REMOTE_AI[22], dtype: float64,\n}\n```\n> The value under key `\"valve\"` in the output above is an instance of `pandas.Series`, indented for readability.\n\n## Advanced Usage\n\n### Custom function calls on single Tag value\n\n``` python\n>>> custom_operations = {\n...     \"md5\": lambda a: hashlib.md5(str(a).encode()).hexdigest(),\n... }\n>>> tag_resolver = TagResolver(get_latest, custom_operations)\n\n>>> specs = {\n...     \"pressure\": Tag(METER_A),\n...     \"pressure_md5\": Tag(METER_B).calc(\"md5\"),\n... }\n>>> tag_resolver.series(specs)\n{'pressure': 4.15, 'pressure_md5': '7fd3...'}\n```\n\n\n### Custom function calls on multiple Tag values\n\n``` python\n>>> custom_operations = {\"max\": max, \"sum\": lambda *vals: sum(vals)}\n>>> tag_resolver = TagResolver(get_latest, custom_operations)\n\n>>> specs = {\n...     \"pressure_1\": Tag(METER_A),\n...     \"pressure_2\": Tag(METER_B),\n...     \"pressure_3\": Tag(METER_C),\n...     \"pressure_highest\": Tag.apply(\"max\", Tag(METER_A), Tag(METER_B), Tag(METER_C)),\n...     \"highest_to_total_ratio\": (\n...         Tag.apply(\"max\", Tag(METER_A), Tag(METER_B), Tag(METER_C))\n..          / Tag.apply(\"sum\", Tag(METER_A), Tag(METER_B), Tag(METER_C))\n...     ),\n... }\n>>> tag_resolver.series(specs)\n{'pressure_1': 30.95,\n 'pressure_2': 19.1,\n 'pressure_3': 20.05,\n 'pressure_highest': 30.95,\n 'highest_to_total_ratio': 0.4415121255349501}\n```\n\n### Operations on Series\n\nThis example below is intentionally as similar as possible to the previous example. The only difference is the retrieval\nfunction passed to `TagResolver`: `get_series` in this example vs `get_latest` in the previous one.\n\n> See definition of `get_series` and `get_latest` at the start of [Full Examples](#full-examples) section above.\n\n``` python\n>>> custom_operations = {\"max\": max, \"sum\": lambda *vals: sum(vals)}\n>>> tag_resolver = TagResolver(get_series, custom_operations)\n\n>>> specs = {\n...     \"pressure_1\": Tag(METER_A),\n...     \"pressure_2\": Tag(METER_B),\n...     \"pressure_3\": Tag(METER_C),\n...     \"pressure_highest\": Tag.apply(\"max\", Tag(METER_A), Tag(METER_B), Tag(METER_C)),\n...     \"highest_to_total_ratio\": (\n...         Tag.apply(\"max\", Tag(METER_A), Tag(METER_B), Tag(METER_C))\n..          / Tag.apply(\"sum\", Tag(METER_A), Tag(METER_B), Tag(METER_C))\n...     ),\n... }\n>>> tag_resolver.series(specs)\n{'pressure_1': 2021-06-16 17:23:37    48.30\n               2021-06-16 17:23:38    48.25\n               2021-06-16 17:23:39    48.15\n               ...\n               Name: houston.ro.REMOTE_AI[3], dtype: float64,\n 'pressure_2': 2021-06-16 17:23:37    42.30\n               2021-06-16 17:23:38    42.10\n               2021-06-16 17:23:39    42.10\n               ...\n               Name: houston.ro.REMOTE_AI[4], dtype: float64,\n 'pressure_3': 2021-06-16 17:23:37    119.95\n               2021-06-16 17:23:38    120.20\n               2021-06-16 17:23:39    120.10\n               ...\n               Name: houston.ro.REMOTE_AI[5], dtype: float64,\n 'pressure_highest': 2021-06-16 17:23:37     119.95\n                     2021-06-16 17:23:38     120.20\n                     2021-06-16 17:23:39     120.10\n                     ...\n                     dtype: float64,\n 'highest_to_total_ratio': 2021-06-16 17:23:37     0.569698\n                           2021-06-16 17:23:38     0.570886\n                           2021-06-16 17:23:39     0.570953\n                           ...\n                           dtype: float64,\n}\n```\n> The value in the output dicts above are instances of `pandas.Series`, indented and trimmed for readability.\n\n\n### But, where are the DataFrames?!\n\nResults from `TagResolver.resolve` can be passed directly to `pd.DataFrame` to get the expected dataframe.\n\nThis is a natural fit for series results, e.g:\n\n``` python\n>>> # ...continuing from the previous example\n>>> data = tag_resolver.series(specs)\n>>> pd.DataFrame(data)\n                     pressure_1  pressure_2  pressure_3  pressure_highest  highest_to_total_ratio\n2021-06-16 17:42:50       49.65       39.55      139.10            139.10                0.609286\n2021-06-16 17:42:51       49.85       39.80      138.70            138.70                0.607401\n2021-06-16 17:42:53       49.50       39.45      138.50            138.50                0.608925\n...\n```\n\nFor single-value responses, the DataFrame will have a single row, and the call to `pd.DataFrame` will require an index\nin addition to the data dict:\n\n``` python\n>>> data = {   # from a previous example\n...     'pressure_1': 30.95,\n...     'pressure_2': 19.1,\n...     'pressure_3': 20.05,\n...     'pressure_highest': 30.95,\n...     'highest_to_total_ratio': 0.4415121255349501,\n... }\n>>> pd.DataFrame(data, index=[0])  # [0] or any one-element iterable\n   pressure_1  pressure_2  pressure_3  pressure_highest  highest_to_total_ratio\n0       30.95        19.1       20.05             30.95                0.441512\n```\n\n### Multiple Data Stores\n\n``` python\n>>> specs = {\n...     \"avg_value\": Tag(METER_A, \"average\"),\n...     \"above_average\": Tag(METER_A) > Tag(METER_A, \"average\"),\n... }\n>>> resolver = TagResolver(get_series, average=get_average)\n>>> resolver.series(specs)\n{\n    \"avg_value\": 42,\n    \"above_average: <pd.Series of bool values, True for points that are above 42, False for others>,\n}\n```\n\nResponses with mixed single-value and multi-value items can also be passed into `pd.DataFrame` constructor. Pandas\nwill automatically repeat any single-value items across all rows in the new dataframe.\n\nIf using multiple data store function, the results will likely have different indexes. `pd.DataFrame` constructor will\ncreate a new dataframe with a combined index. This can result in a sparsely filled dataframe (many cells having `np.nan`\nvalue).\n\n#### More complex example\n\nTo expand on the previous example, let us require the difference between average value and any actual value, but\nonly if the value is above average, otherwise set it to 0. For example, this is a dataframe that we want to get:\n```\n                          value   avg_value   above_average  positive_diff\n2021-06-16 17:42:10       49.65       43.21            True        6.43999\n2021-06-16 17:42:20       44.85       43.21            True        1.64000\n2021-06-16 17:42:30       41.50       43.21           False              0\n2021-06-16 17:42:40       40.90       43.21           False              0\n2021-06-16 17:42:50       41.50       43.21           False              0\n2021-06-16 17:42:60       43.30       43.21            True       0.089999\n...\n```\n\nThere are many ways to get this result, here are a few equivalent ones.\n\n``` python\nspecs = {\n   \"value\": Tag(METER_A),\n   \"avg_value\": Tag(METER_A, \"average\"),\n   \"above_average\": Tag(METER_A) > Tag(METER_A, \"average\"),\n   \"positive_diff\": (Tag(METER_A) - Tag(METER_A, \"average\")) if Tag(METER_A) > Tag(METER_A, \"average\") else 0,\n}\n```\n\n``` python\ndef positive_or_0(val):\n    return val if val > 0 else 0\n\nspecs = {\n   \"value\": Tag(METER_A),\n   \"avg_value\": Tag(METER_A, \"average\"),\n   \"above_average\": Tag(METER_A) > Tag(METER_A, \"average\"),\n   \"positive_diff\": (Tag(METER_A) - Tag(METER_A, \"average\")).calc(positive_or_0),\n}\n```\n\n``` python\navg_spec = Tag(METER_A, \"average\")\nmeter_spec = Tag(METER_A)\nabove_spec = meter_spec > avg_spec\ndiff_spec = meter_spec - avg_spec\npositive_diff_spec = diff_spec if above_spec else 0\n\nspecs = {\n   \"value\": meter_spec,\n   \"avg_value\": avg_spec,\n   \"above_average\": above_spec,\n   \"positive_diff\": positive_diff_spec,\n}\n```\n\n\n## Provided Data Stores\n\nAll examples in this document use data stores (a.k.a. retrieval functions) that are provided in\n`cognite_synthetic_tags.data_stores` module. These are prepared to work with `TagResolver`.\n\nProvided stores:\n * `series` - returns multiple values for every tag, as `pd.Series` instances.\n * `point` - same as `series` except that it returns only the last point in each series.\n * `series_at_time` - same as `series` except it takes `at_time` and `lookbehind_start_time` as an alternative\n    to `end` and `start` arguments.\n * `point_at_time` - same as  `point` except it takes `at_time` and `lookbehind_start_time` as an alternative\n    to `end` and `start` arguments.\n\nCheck docstrings for more details.\n\n\n## TODO\n\n * Add better support for passing lambdas to `calc` an `apply`, e.g. `Tag(..).calc(some_value=lambda val: val + 42)`\n * Internally **Synthetic Tags** is using `DataFrame` and `Series` from Pandas. There is a small performance penalty\n   associated with this, so we should probably make the effort to work directly with response objects from Cognite SDK.\n * Check the effects of `include_outside_points` on the provided data store functions.",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "Apache License 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "cognite-synthetic-tags",
    "package_url": "https://pypi.org/project/cognite-synthetic-tags/",
    "platform": "OS Independent",
    "project_url": "https://pypi.org/project/cognite-synthetic-tags/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/cognite-synthetic-tags/0.3.3/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "An easy way to retrieve values from CDF and execute mathematical operations on them at the same time.",
    "version": "0.3.3",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 13010277,
  "releases": {
    "0.3.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "45933b97a96be1c77826f34704cc025808966ef000982fb57f4c9770fc4b6153",
          "md5": "8c7f1c4b62996d665af6832e95687ac1",
          "sha256": "61190c6aa09e82a12e0933271dc09a20d92297d9535a10fc56dc232c9d421e3a"
        },
        "downloads": -1,
        "filename": "cognite-synthetic-tags-0.3.3.tar.gz",
        "has_sig": false,
        "md5_digest": "8c7f1c4b62996d665af6832e95687ac1",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 24546,
        "upload_time": "2022-02-25T14:45:56",
        "upload_time_iso_8601": "2022-02-25T14:45:56.185134Z",
        "url": "https://files.pythonhosted.org/packages/45/93/3b97a96be1c77826f34704cc025808966ef000982fb57f4c9770fc4b6153/cognite-synthetic-tags-0.3.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "45933b97a96be1c77826f34704cc025808966ef000982fb57f4c9770fc4b6153",
        "md5": "8c7f1c4b62996d665af6832e95687ac1",
        "sha256": "61190c6aa09e82a12e0933271dc09a20d92297d9535a10fc56dc232c9d421e3a"
      },
      "downloads": -1,
      "filename": "cognite-synthetic-tags-0.3.3.tar.gz",
      "has_sig": false,
      "md5_digest": "8c7f1c4b62996d665af6832e95687ac1",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 24546,
      "upload_time": "2022-02-25T14:45:56",
      "upload_time_iso_8601": "2022-02-25T14:45:56.185134Z",
      "url": "https://files.pythonhosted.org/packages/45/93/3b97a96be1c77826f34704cc025808966ef000982fb57f4c9770fc4b6153/cognite-synthetic-tags-0.3.3.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}