{
  "info": {
    "author": "Ilia Moiseev",
    "author_email": "ilia.moiseev.5@yandex.ru",
    "bugtrack_url": null,
    "classifiers": [
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# xai-benchmark\n\nOpen and extensible benchmark for XAI methods\n\n## Description\n\nXAIB is an open benchmark that provides a way to compare different XAI methods using broad set of metrics that measure different aspects of interpretability\n\n## Installation\n\n```bash\npip3 install xai-benchmark\n```\n\nRemember to create virtual environment if you need one.  \n\nAfter the installation you can verify the package by printing out its version:\n\n```python\nimport xaib\nprint(xaib.__version__)\n```\n\nTo use all explainers you should also install `explainers_requirements.txt` which can be done\ndirectly\n\n```bash\npip3 install -r https://raw.githubusercontent.com/oxid15/xai-benchmark/master/explainers_requirements.txt\n```\n\n## Results\n\nUpdated results table can be found [hosted here](https://oxid15.github.io/xai-benchmark/results)  \n\n## How to use\n\n### Introduction\n\nXAIB is build to bring various data, models and explainers together and\nmeasure quality of an explainer in different ways.  \n  \nThe setup is formed from particular Dataset, Model and Explainer.  \nCase stands for some interpretability quality which we are trying to proxy numerically\nusing Metrics. Since there are always more than one way to measure something, one Case\nmay (and should ideally) have several metrics inside.\n\nRead more on [Cases](https://oxid15.github.io/xai-benchmark/cases) and [Metrics](https://oxid15.github.io/xai-benchmark/metrics) in documentation.\n\n![dia](xaib/docs/images/diagram.jpg)\n\n### Reproduce\n\nFull run will be available soon.  \nUntil then, there are regular [pipelines](https://github.com/Oxid15/xai-benchmark/actions)  \n  \nFor the implementation of the evaluation procedure, you can visit `xaib/evaluation`\n\n### Try method\n\nAll explanation methods in XAIB have the same input and output interface which allows to\nuse them easily and compare.  \nIf you want to run an Explainer and see the results you can do this:\n\n```python\nfrom xaib.explainers.feature_importance.lime_explainer import LimeExplainer\nfrom xaib.evaluation import DatasetFactory, ModelFactory\n\n# Get the dataset and train the model\ntrain_ds, test_ds = DatasetFactory().get('synthetic')\nmodel = ModelFactory(train_ds, test_ds).get('svm')\n```\n\n```python\n# You can also get the default one using ExplainerFactory\nexplainer = LimeExplainer(train_ds, labels=[0, 1])\n```\n\n```python\n# Obtain batch from dataset\nsample = [test_ds[i]['item'] for i in range(10)]\n```\n\n```python\n# Obtain explanations\nexplanations = explainer.predict(sample, model)\n\nprint(explanations)\n```\n\n### Evaluate method\n\nTo evaluate some existing method on all\ncases you should create a default setup and run it\n\n```python\nfrom xaib.evaluation import DatasetFactory, ModelFactory\nfrom xaib.evaluation.example_selection import ExplainerFactory, ExperimentFactory\nfrom xaib.evaluation.utils import visualize_results\n\n\ntrain_ds, test_ds = DatasetFactory().get('synthetic')\nmodel = ModelFactory(train_ds, test_ds).get('knn')\n\nexplainer = ExplainerFactory(train_ds, model).get('knn')\n```\n\n```python\n# Run all experiments on chosen method\nexperiment_factory = ExperimentFactory(\n    repo_path='results',\n    explainers={'knn': explainer},\n    test_ds=test_ds,\n    model=model,\n    batch_size=10\n)\n\nexperiments = experiment_factory.get('all')\nfor name in experiments:\n    experiments[name]()\n\n# Save plot to the results folder\nvisualize_results('results', 'results/results.png')\n```\n\n## How to contribute\n\nAny contributions are welcome! You can help to extend\nthe picture of XAI-methods quality by adding:\n\n- [New Dataset](#add-dataset)\n- [New Model](#add-model)\n- [New Explainer](#add-explainer)\n- [New Metric](#add-metric)\n- [New Case (?)](https://github.com/Oxid15/xai-benchmark/issues) - please, fill the issue first to discuss\n\n### Add dataset\n\nNew datasets may extend our understanding of how different explainers\nbehave in context of different domains and tasks.  \nTo add your dataset, you should provide a Wrapper, which will\ndownload or access prepared data from disk.\n\n#### Create data wrapper\n\nFirst you need to create a wrapper with required interface and fields\n\n```python\nimport numpy as np\nfrom xaib import Dataset\n\n\nclass NewDataset(Dataset):\n    \"\"\"\n    Here the documentation on data should be filled\n    \"\"\"\n    def __init__(self, split, *args, **kwargs) -> None:\n        super().__init__(*args, **kwargs)\n\n        # It is important to set the name\n        # the name will be used to identify a dataset\n        self.name = 'new_dataset'\n\n        # While creating you can download and cache data,\n        # define splits, etc\n        if split == 'train':\n            self._data = [(0, 1, 2), (3, 4, 5), (6, 7, 8)]\n            self._labels = [0, 1, 0]\n        elif split == 'test':\n            self._data = [(9, 10, 11), (12, 13, 14)]\n            self._labels = [1, 0]\n\n    def __getitem__(self, index):\n        # This form of returning items is required - Dict[str, np.ndarray[Any]]\n        return {\n            'item': np.asarray(self._data[index]),\n            'label': np.asarray(self._labels[index])\n        }\n\n    def __len__(self):\n        return len(self._data)\n```\n\n#### Test new dataset\n\nBefore adding your implementation directly into source code, it would be useful to\ntest how it will work with standard XAIB setup\n\n```python\n\nfrom xaib.evaluation import DatasetFactory, ModelFactory\nfrom xaib.evaluation.feature_importance import ExplainerFactory, ExperimentFactory\nfrom xaib.evaluation.utils import visualize_results\n\n\n# Here you create your data\ntrain_ds, test_ds = NewDataset('train'), NewDataset('test')\n\n# And then pass it further\nmodel = ModelFactory(train_ds, test_ds).get('svm')\n\nexplainers = ExplainerFactory(train_ds, model, labels=[0, 1]).get('all')\n\nexperiment_factory = ExperimentFactory(\n    repo_path='results',\n    explainers=explainers,\n    test_ds=test_ds,\n    model=model,\n    batch_size=10\n)\n\nexperiments = experiment_factory.get('all')\nfor name in experiments:\n    experiments[name]()\n\n\nvisualize_results('results', 'results/results.png')\n```\n\n#### Integrate new dataset\n\nFinally you can integrate your dataset into the source code.  \nTo do that you need to add it into `xaib.datasets` module\nand then make a constructor for the Factory.\n\n```python\n# xaib/evaluation/dataset_factory.py\n# ...\nfrom ..datasets.new_dataset import NewDataset\n# ...\n\n# Create a constructor - function that will build your dataset\n# it should provide all defaults needed\ndef new_dataset():\n    return NewDataset('train'), NewDataset('test')\n\n\nclass DatasetFactory(Factory):\n    def __init__(self) -> None:\n        # ...\n        # add it to the factory\n        self._constructors['new_dataset'] = lambda: new_dataset()\n```\n\n### Add model\n\nNew models and model classes provide information on how good explainers\nare in some particular cases.\n\n#### Create model wrapper\n\nFirst model wrapper should be implemented. It has many\nrequired methods that should be implemented.\nFor example `fit` and `evaluate` methods are needed\nto be able to train the model on different datasets\nsee specification in `xaib/base` and examples in\n`xaib/evaluation/model_factory.py`\n\n```python\nimport numpy as np\nfrom xaib import Model\n\n\nclass NewModel(Model):\n    \"\"\"\n    Here the documentation on model should be filled\n    \"\"\"\n    def __init__(self, const, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n        self.const = const\n\n        # It is important to set the name\n        # the name will be used to identify a model\n        self.name = 'new_model'\n\n    def fit(self, x, y):\n        pass\n\n    def evaluate(self, x, y):\n        pass\n\n    def predict(self, x):\n        return np.array([self.const for _ in range(len(x))])\n\n    def save(self, filepath, *args, **kwargs):\n        with open(filepath, 'w') as f:\n            f.write(str(self.const))\n\n    def load(self, filepath, *args, **kwargs):\n        with open(filepath, 'r') as f:\n            self.const = float(f.read())\n        # load does not return anything - just fills\n        # internal state\n\n```\n\n#### Test new model\n\nBefore adding your implementation directly into source code, it would be useful to\ntest how it will work with standard XAIB setup\n\n```python\nfrom xaib.evaluation import DatasetFactory\nfrom xaib.evaluation.feature_importance import ExplainerFactory, ExperimentFactory\nfrom xaib.evaluation.utils import visualize_results\n\n\n# Create your model\nmodel = NewModel(const=1)\n```\n\n```python\ntrain_ds, test_ds = DatasetFactory().get('synthetic')\nexplainers = {'shap': ExplainerFactory(train_ds, model, labels=[0, 1]).get('shap')}\n\nexperiment_factory = ExperimentFactory(\n    repo_path='results',\n    explainers=explainers,\n    test_ds=test_ds,\n    model=model, # and put it here\n    batch_size=10\n)\n\nexperiments = experiment_factory.get('all')\nfor name in experiments:\n    experiments[name]()\n\n\nvisualize_results('results', 'results/results.png')\n```\n\n#### Integrate new model\n\nFinally you can integrate your model into the source code.  \nTo do that you need to add it into `xaib.models` module\nand then make a constructor for the Factory.\n\n```python\n# xaib/evaluation/model_factory.py\n# ...\nfrom ..models.new_model import NewModel\n# ...\n\n# Create a constructor - function that will build your model\ndef new_model(const):\n    return NewModel(const=const)\n\n\nclass ModelFactory(Factory):\n    def __init__(self) -> None:\n        \n        # ...\n        # add it to the factory\n        self._constructors['new_model'] = lambda: new_model(const=1)\n```\n\n### Add explainer\n\nExplainers are the heart of this benchmark, they are being thorougly tested\nand the more of them added, the more we know\n\n#### Create wrapper\n\nExplainers wrappers are less demanding than model's which makes them\neasier to be implemented\n\n```python\nimport numpy as np\nfrom xaib import Explainer\n\n\nclass NewExplainer(Explainer):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n        # name is essential to put explainer into\n        # results table correctly\n        self.name = 'new_explainer'\n\n    def predict(self, x, model, *args, **kwargs):\n        return np.random.rand(len(x), len(x[0]))\n```\n\n#### Test new explainer\n\nBefore adding your implementation directly into source code, it would be useful to\ntest how it will work with standard XAIB setup\n\n```python\nfrom xaib.evaluation import DatasetFactory, ModelFactory\nfrom xaib.evaluation.feature_importance import ExperimentFactory\nfrom xaib.evaluation.utils import visualize_results\n\n\ntrain_ds, test_ds = DatasetFactory().get('synthetic')\nmodel = ModelFactory(train_ds, test_ds).get('svm')\n```\n\n```python\nexplainers = {'new_explainer': NewExplainer()}\n\nexperiment_factory = ExperimentFactory(\n    repo_path='results',\n    explainers=explainers,\n    test_ds=test_ds,\n    model=model,\n    batch_size=10\n)\n\nexperiments = experiment_factory.get('all')\nfor name in experiments:\n    experiments[name]()\n\nvisualize_results('results', 'results/results.png')\n```\n\n#### Integrate new explainer\n\nFinally you can integrate your explainer into the source code.  \nTo do that you need to add it into `xaib.explainers` module\nand then make a constructor for the Factory.\n\n```python\n# xaib/evaluation/feature_importance/explainer_factory.py\n# ...\nfrom ...explainers.feature_importance.new_explainer import NewExplainer\n# ...\n\n# Create a constructor - function that will build your explainer\ndef new_explainer():\n    return NewExplainer()\n\n\nclass ExplainerFactory(Factory):\n    def __init__(self) -> None:\n        \n        # ...\n        # add it to the factory\n        self._constructors['new_explainer'] = lambda: new_explainer()\n```\n\n### Add metric\n\nMetrics are ways to numerically assess the quality of explainers and are parts of\nCases\n\n#### Create metric\n\nFirst you need to create a Metric object - which will accept and explainer and data\nand return some value\n\n```python\n    from xaib import Metric\n\n    class NewMetric(Metric):\n        def __init__(self, ds, model *args, **kwargs):\n            super().__init__(ds, model, *args, **kwargs)\n\n            self.name = 'new_metric'\n            self.direction = 'down'\n\n        def compute(self, explainer, *args, batch_size=1, expl_kwargs=None, **kwargs):\n            if expl_kwargs is None:\n                expl_kwargs = {}\n\n            dl = SimpleDataloader(self._ds, batch_size=batch_size)\n            for batch in tqdm(dl):\n                # get explanations\n                ex = expl.predict(batch['item'], self._model, **expl_kwargs)\n\n            # Here compute and return your metric\n\n            return np.random.rand()\n```\n\n#### Test new metric\n\nBefore adding your implementation directly into source code, it would be useful to\ntest how it will work with standard XAIB setup  \n  \nSince metrics are more low-level objects, they need special treatment\nwhen tested. Basically you need to create metric and append it to the existing\nCase of choice.\n\n```python\nfrom xaib.evaluation import DatasetFactory, ModelFactory\nfrom xaib.evaluation.feature_importance import ExplainerFactory\nfrom xaib.evaluation.utils import visualize_results, experiment\n\n\ntrain_ds, test_ds = DatasetFactory().get('synthetic')\nmodel = ModelFactory(train_ds, test_ds).get('svm')\n\nexplainers = ExplainerFactory(train_ds, model, labels=[0, 1]).get('all')\n\nmetric = NewMetric(test_ds, model)\n\n\n@experiment(\n    'results',\n    explainers=explainers,\n    metrics_kwargs={\n        'other_disagreement': dict(expls=list(explainers.values()))\n    }\n)\ndef coherence():\n    case = CoherenceCase(test_ds, model)\n    case.add_metric('new_metric', metric)\n    return case\n\ncoherence()\n\nvisualize_results('results', 'results/results.png')\n```\n\n#### Integrate new metric\n\n```python\n# xaib/cases/feature_importance/coherence_case.py\n# ...\nfrom ...metrics.feature_importance import NewMetric\n\n\nclass CoherenceCase(Case):\n    def __init__(self, ds: Dataset, model: Model, *args: Any, **kwargs: Any) -> None:\n        super().__init__(ds, model, *args, **kwargs)\n        # ...\n\n        self._metric_objs['new_metric'] = NewMetric(ds, model)\n\n```\n\n## License\n\n[MIT](https://choosealicense.com/licenses/mit/)\n\n## Versions\n\nThis project follows Semantic Versioning - [semver.org](https://semver.org/)\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/oxid15/xai-benchmark",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "xai-benchmark",
    "package_url": "https://pypi.org/project/xai-benchmark/",
    "platform": null,
    "project_url": "https://pypi.org/project/xai-benchmark/",
    "project_urls": {
      "Homepage": "https://github.com/oxid15/xai-benchmark"
    },
    "release_url": "https://pypi.org/project/xai-benchmark/0.2.0/",
    "requires_dist": [
      "cascade-ml (>=0.7.2)",
      "scikit-learn",
      "plotly",
      "kaleido"
    ],
    "requires_python": ">=3.8",
    "summary": "Benchmark for Explainable AI methods",
    "version": "0.2.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17546801,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9c085057d632a16e9a21158be41c88c3121c8d62f0ca9ef21bbe3fc8dc581687",
          "md5": "3eee6c3184bdf5bf1ec29db71139f5ba",
          "sha256": "6f64675830d6c2e806de61446b437f5561170a71b92a5fc99f8ee833e533aeea"
        },
        "downloads": -1,
        "filename": "xai_benchmark-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "3eee6c3184bdf5bf1ec29db71139f5ba",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 15669,
        "upload_time": "2023-02-12T15:46:34",
        "upload_time_iso_8601": "2023-02-12T15:46:34.151927Z",
        "url": "https://files.pythonhosted.org/packages/9c/08/5057d632a16e9a21158be41c88c3121c8d62f0ca9ef21bbe3fc8dc581687/xai_benchmark-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d73e5db8d6706f09ff8c703081757bfa562a5a6f23f157417532d874df56b2cb",
          "md5": "1f839b6b62eb23d882329bef726298ee",
          "sha256": "bf197fedc060eac25b1c02f142a609f8b38f70a2a2fd9f57b7978a107f38f2c3"
        },
        "downloads": -1,
        "filename": "xai-benchmark-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "1f839b6b62eb23d882329bef726298ee",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 8186,
        "upload_time": "2023-02-12T15:46:35",
        "upload_time_iso_8601": "2023-02-12T15:46:35.639287Z",
        "url": "https://files.pythonhosted.org/packages/d7/3e/5db8d6706f09ff8c703081757bfa562a5a6f23f157417532d874df56b2cb/xai-benchmark-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7663f97fa776fe84e4e8aaa512a426a0ad67ef34a1df3c139d8b185e1d90bb3d",
          "md5": "a67a5c743a19c9ec0e09ef9f0c91035d",
          "sha256": "31e2e98ce20c7f2c4b2cf1522a021a0f68235e4eb88f9da35cba06b05ca2b140"
        },
        "downloads": -1,
        "filename": "xai_benchmark-0.2.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "a67a5c743a19c9ec0e09ef9f0c91035d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 41394,
        "upload_time": "2023-04-02T10:54:39",
        "upload_time_iso_8601": "2023-04-02T10:54:39.886136Z",
        "url": "https://files.pythonhosted.org/packages/76/63/f97fa776fe84e4e8aaa512a426a0ad67ef34a1df3c139d8b185e1d90bb3d/xai_benchmark-0.2.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4d26137c4474ef1f63d41d5cb4cd417c314bf712fb4d6e9183716c23e4dd6701",
          "md5": "4cbbe67a8f266d1849bbbacf456d511f",
          "sha256": "590a5d2196e52d74b06987c49625d7fa952eb47cd2047c270221b49eb0d67e91"
        },
        "downloads": -1,
        "filename": "xai-benchmark-0.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "4cbbe67a8f266d1849bbbacf456d511f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 21073,
        "upload_time": "2023-04-02T10:54:42",
        "upload_time_iso_8601": "2023-04-02T10:54:42.254168Z",
        "url": "https://files.pythonhosted.org/packages/4d/26/137c4474ef1f63d41d5cb4cd417c314bf712fb4d6e9183716c23e4dd6701/xai-benchmark-0.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "7663f97fa776fe84e4e8aaa512a426a0ad67ef34a1df3c139d8b185e1d90bb3d",
        "md5": "a67a5c743a19c9ec0e09ef9f0c91035d",
        "sha256": "31e2e98ce20c7f2c4b2cf1522a021a0f68235e4eb88f9da35cba06b05ca2b140"
      },
      "downloads": -1,
      "filename": "xai_benchmark-0.2.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "a67a5c743a19c9ec0e09ef9f0c91035d",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.8",
      "size": 41394,
      "upload_time": "2023-04-02T10:54:39",
      "upload_time_iso_8601": "2023-04-02T10:54:39.886136Z",
      "url": "https://files.pythonhosted.org/packages/76/63/f97fa776fe84e4e8aaa512a426a0ad67ef34a1df3c139d8b185e1d90bb3d/xai_benchmark-0.2.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "4d26137c4474ef1f63d41d5cb4cd417c314bf712fb4d6e9183716c23e4dd6701",
        "md5": "4cbbe67a8f266d1849bbbacf456d511f",
        "sha256": "590a5d2196e52d74b06987c49625d7fa952eb47cd2047c270221b49eb0d67e91"
      },
      "downloads": -1,
      "filename": "xai-benchmark-0.2.0.tar.gz",
      "has_sig": false,
      "md5_digest": "4cbbe67a8f266d1849bbbacf456d511f",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.8",
      "size": 21073,
      "upload_time": "2023-04-02T10:54:42",
      "upload_time_iso_8601": "2023-04-02T10:54:42.254168Z",
      "url": "https://files.pythonhosted.org/packages/4d/26/137c4474ef1f63d41d5cb4cd417c314bf712fb4d6e9183716c23e4dd6701/xai-benchmark-0.2.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}