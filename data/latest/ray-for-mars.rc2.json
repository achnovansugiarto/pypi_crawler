{
  "info": {
    "author": "Ray Team",
    "author_email": "ray-dev@googlegroups.com",
    "bugtrack_url": null,
    "classifiers": [
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9"
    ],
    "description": ".. image:: https://github.com/ray-project/ray/raw/master/doc/source/images/ray_header_logo.png\n\n.. image:: https://readthedocs.org/projects/ray/badge/?version=master\n    :target: http://docs.ray.io/en/master/?badge=master\n\n.. image:: https://img.shields.io/badge/Ray-Join%20Slack-blue\n    :target: https://forms.gle/9TSdDYUgxYs8SA9e8\n\n.. image:: https://img.shields.io/badge/Discuss-Ask%20Questions-blue\n    :target: https://discuss.ray.io/\n\n.. image:: https://img.shields.io/twitter/follow/raydistributed.svg?style=social&logo=twitter\n    :target: https://twitter.com/raydistributed\n\n|\n\n\n**Ray provides a simple, universal API for building distributed applications.**\n\nRay is packaged with the following libraries for accelerating machine learning workloads:\n\n- `Tune`_: Scalable Hyperparameter Tuning\n- `RLlib`_: Scalable Reinforcement Learning\n- `Train`_: Distributed Deep Learning (beta)\n- `Datasets`_: Distributed Data Loading and Compute\n\nAs well as libraries for taking ML and distributed apps to production:\n\n- `Serve`_: Scalable and Programmable Serving\n- `Workflows`_: Fast, Durable Application Flows (alpha)\n\nThere are also many `community integrations <https://docs.ray.io/en/master/ray-libraries.html>`_ with Ray, including `Dask`_, `MARS`_, `Modin`_, `Horovod`_, `Hugging Face`_, `Scikit-learn`_, and others. Check out the `full list of Ray distributed libraries here <https://docs.ray.io/en/master/ray-libraries.html>`_.\n\nInstall Ray with: ``pip install ray``. For nightly wheels, see the\n`Installation page <https://docs.ray.io/en/master/installation.html>`__.\n\n.. _`Modin`: https://github.com/modin-project/modin\n.. _`Hugging Face`: https://huggingface.co/transformers/main_classes/trainer.html#transformers.Trainer.hyperparameter_search\n.. _`MARS`: https://docs.ray.io/en/latest/data/mars-on-ray.html\n.. _`Dask`: https://docs.ray.io/en/latest/data/dask-on-ray.html\n.. _`Horovod`: https://horovod.readthedocs.io/en/stable/ray_include.html\n.. _`Scikit-learn`: https://docs.ray.io/en/master/joblib.html\n.. _`Serve`: https://docs.ray.io/en/master/serve/index.html\n.. _`Datasets`: https://docs.ray.io/en/master/data/dataset.html\n.. _`Workflows`: https://docs.ray.io/en/master/workflows/concepts.html\n.. _`Train`: https://docs.ray.io/en/master/train/train.html\n\n\nQuick Start\n-----------\n\nExecute Python functions in parallel.\n\n.. code-block:: python\n\n    import ray\n    ray.init()\n\n    @ray.remote\n    def f(x):\n        return x * x\n\n    futures = [f.remote(i) for i in range(4)]\n    print(ray.get(futures))\n\nTo use Ray's actor model:\n\n.. code-block:: python\n\n\n    import ray\n    ray.init()\n\n    @ray.remote\n    class Counter(object):\n        def __init__(self):\n            self.n = 0\n\n        def increment(self):\n            self.n += 1\n\n        def read(self):\n            return self.n\n\n    counters = [Counter.remote() for i in range(4)]\n    [c.increment.remote() for c in counters]\n    futures = [c.read.remote() for c in counters]\n    print(ray.get(futures))\n\n\nRay programs can run on a single machine, and can also seamlessly scale to large clusters. To execute the above Ray script in the cloud, just download `this configuration file <https://github.com/ray-project/ray/blob/master/python/ray/autoscaler/aws/example-full.yaml>`__, and run:\n\n``ray submit [CLUSTER.YAML] example.py --start``\n\nRead more about `launching clusters <https://docs.ray.io/en/master/cluster/index.html>`_.\n\nTune Quick Start\n----------------\n\n.. image:: https://github.com/ray-project/ray/raw/master/doc/source/images/tune-wide.png\n\n`Tune`_ is a library for hyperparameter tuning at any scale.\n\n- Launch a multi-node distributed hyperparameter sweep in less than 10 lines of code.\n- Supports any deep learning framework, including PyTorch, `PyTorch Lightning <https://github.com/williamFalcon/pytorch-lightning>`_, TensorFlow, and Keras.\n- Visualize results with `TensorBoard <https://www.tensorflow.org/tensorboard>`__.\n- Choose among scalable SOTA algorithms such as `Population Based Training (PBT)`_, `Vizier's Median Stopping Rule`_, `HyperBand/ASHA`_.\n- Tune integrates with many optimization libraries such as `Facebook Ax <http://ax.dev>`_, `HyperOpt <https://github.com/hyperopt/hyperopt>`_, and `Bayesian Optimization <https://github.com/fmfn/BayesianOptimization>`_ and enables you to scale them transparently.\n\nTo run this example, you will need to install the following:\n\n.. code-block:: bash\n\n    $ pip install \"ray[tune]\"\n\n\nThis example runs a parallel grid search to optimize an example objective function.\n\n.. code-block:: python\n\n    from ray import tune\n\n\n    def objective(step, alpha, beta):\n        return (0.1 + alpha * step / 100)**(-1) + beta * 0.1\n\n\n    def training_function(config):\n        # Hyperparameters\n        alpha, beta = config[\"alpha\"], config[\"beta\"]\n        for step in range(10):\n            # Iterative training function - can be any arbitrary training procedure.\n            intermediate_score = objective(step, alpha, beta)\n            # Feed the score back back to Tune.\n            tune.report(mean_loss=intermediate_score)\n\n\n    analysis = tune.run(\n        training_function,\n        config={\n            \"alpha\": tune.grid_search([0.001, 0.01, 0.1]),\n            \"beta\": tune.choice([1, 2, 3])\n        })\n\n    print(\"Best config: \", analysis.get_best_config(metric=\"mean_loss\", mode=\"min\"))\n\n    # Get a dataframe for analyzing trial results.\n    df = analysis.results_df\n\nIf TensorBoard is installed, automatically visualize all trial results:\n\n.. code-block:: bash\n\n    tensorboard --logdir ~/ray_results\n\n.. _`Tune`: https://docs.ray.io/en/master/tune.html\n.. _`Population Based Training (PBT)`: https://docs.ray.io/en/master/tune/api_docs/schedulers.html#population-based-training-tune-schedulers-populationbasedtraining\n.. _`Vizier's Median Stopping Rule`: https://docs.ray.io/en/master/tune/api_docs/schedulers.html#median-stopping-rule-tune-schedulers-medianstoppingrule\n.. _`HyperBand/ASHA`: https://docs.ray.io/en/master/tune/api_docs/schedulers.html#asha-tune-schedulers-ashascheduler\n\nRLlib Quick Start\n-----------------\n\n.. image:: https://github.com/ray-project/ray/raw/master/doc/source/rllib/images/rllib-logo.png\n\n`RLlib`_ is an industry-grade library for reinforcement learning (RL), built on top of Ray.\nIt offers high scalability and unified APIs for a\n`variety of industry- and research applications <https://www.anyscale.com/event-category/ray-summit>`_.\n\n.. code-block:: bash\n\n    $ pip install \"ray[rllib]\" tensorflow  # or torch\n\n\n.. Do NOT edit the following code directly in this README! Instead, edit\n    the ray/rllib/examples/documentation/rllib_on_ray_readme.py script and then\n    copy the new code in here:\n\n.. code-block:: python\n\n    import gym\n    from ray.rllib.agents.ppo import PPOTrainer\n\n\n    # Define your problem using python and openAI's gym API:\n    class SimpleCorridor(gym.Env):\n        \"\"\"Corridor in which an agent must learn to move right to reach the exit.\n\n        ---------------------\n        | S | 1 | 2 | 3 | G |   S=start; G=goal; corridor_length=5\n        ---------------------\n\n        Possible actions to chose from are: 0=left; 1=right\n        Observations are floats indicating the current field index, e.g. 0.0 for\n        starting position, 1.0 for the field next to the starting position, etc..\n        Rewards are -0.1 for all steps, except when reaching the goal (+1.0).\n        \"\"\"\n\n        def __init__(self, config):\n            self.end_pos = config[\"corridor_length\"]\n            self.cur_pos = 0\n            self.action_space = gym.spaces.Discrete(2)  # left and right\n            self.observation_space = gym.spaces.Box(0.0, self.end_pos, shape=(1,))\n\n        def reset(self):\n            \"\"\"Resets the episode and returns the initial observation of the new one.\n            \"\"\"\n            self.cur_pos = 0\n            # Return initial observation.\n            return [self.cur_pos]\n\n        def step(self, action):\n            \"\"\"Takes a single step in the episode given `action`\n\n            Returns:\n                New observation, reward, done-flag, info-dict (empty).\n            \"\"\"\n            # Walk left.\n            if action == 0 and self.cur_pos > 0:\n                self.cur_pos -= 1\n            # Walk right.\n            elif action == 1:\n                self.cur_pos += 1\n            # Set `done` flag when end of corridor (goal) reached.\n            done = self.cur_pos >= self.end_pos\n            # +1 when goal reached, otherwise -1.\n            reward = 1.0 if done else -0.1\n            return [self.cur_pos], reward, done, {}\n\n\n    # Create an RLlib Trainer instance.\n    trainer = PPOTrainer(\n        config={\n            # Env class to use (here: our gym.Env sub-class from above).\n            \"env\": SimpleCorridor,\n            # Config dict to be passed to our custom env's constructor.\n            \"env_config\": {\n                # Use corridor with 20 fields (including S and G).\n                \"corridor_length\": 20\n            },\n            # Parallelize environment rollouts.\n            \"num_workers\": 3,\n        })\n\n    # Train for n iterations and report results (mean episode rewards).\n    # Since we have to move at least 19 times in the env to reach the goal and\n    # each move gives us -0.1 reward (except the last move at the end: +1.0),\n    # we can expect to reach an optimal episode reward of -0.1*18 + 1.0 = -0.8\n    for i in range(5):\n        results = trainer.train()\n        print(f\"Iter: {i}; avg. reward={results['episode_reward_mean']}\")\n\n\nAfter training, you may want to perform action computations (inference) in your environment.\nHere is a minimal example on how to do this. Also\n`check out our more detailed examples here <https://github.com/ray-project/ray/tree/master/rllib/examples/inference_and_serving>`_\n(in particular for `normal models <https://github.com/ray-project/ray/blob/master/rllib/examples/inference_and_serving/policy_inference_after_training.py>`_,\n`LSTMs <https://github.com/ray-project/ray/blob/master/rllib/examples/inference_and_serving/policy_inference_after_training_with_lstm.py>`_,\nand `attention nets <https://github.com/ray-project/ray/blob/master/rllib/examples/inference_and_serving/policy_inference_after_training_with_attention.py>`_).\n\n.. code-block:: python\n\n    # Perform inference (action computations) based on given env observations.\n    # Note that we are using a slightly different env here (len 10 instead of 20),\n    # however, this should still work as the agent has (hopefully) learned\n    # to \"just always walk right!\"\n    env = SimpleCorridor({\"corridor_length\": 10})\n    # Get the initial observation (should be: [0.0] for the starting position).\n    obs = env.reset()\n    done = False\n    total_reward = 0.0\n    # Play one episode.\n    while not done:\n        # Compute a single action, given the current observation\n        # from the environment.\n        action = trainer.compute_single_action(obs)\n        # Apply the computed action in the environment.\n        obs, reward, done, info = env.step(action)\n        # Sum up rewards for reporting purposes.\n        total_reward += reward\n    # Report results.\n    print(f\"Played 1 episode; total-reward={total_reward}\")\n\n\n.. _`RLlib`: https://docs.ray.io/en/master/rllib/index.html\n\n\nRay Serve Quick Start\n---------------------\n\n.. image:: https://raw.githubusercontent.com/ray-project/ray/master/doc/source/serve/logo.svg\n  :width: 400\n\n`Ray Serve`_ is a scalable model-serving library built on Ray. It is:\n\n- Framework Agnostic: Use the same toolkit to serve everything from deep\n  learning models built with frameworks like PyTorch or Tensorflow & Keras\n  to Scikit-Learn models or arbitrary business logic.\n- Python First: Configure your model serving declaratively in pure Python,\n  without needing YAMLs or JSON configs.\n- Performance Oriented: Turn on batching, pipelining, and GPU acceleration to\n  increase the throughput of your model.\n- Composition Native: Allow you to create \"model pipelines\" by composing multiple\n  models together to drive a single prediction.\n- Horizontally Scalable: Serve can linearly scale as you add more machines. Enable\n  your ML-powered service to handle growing traffic.\n\nTo run this example, you will need to install the following:\n\n.. code-block:: bash\n\n    $ pip install scikit-learn\n    $ pip install \"ray[serve]\"\n\nThis example runs serves a scikit-learn gradient boosting classifier.\n\n.. code-block:: python\n\n    import pickle\n    import requests\n\n    from sklearn.datasets import load_iris\n    from sklearn.ensemble import GradientBoostingClassifier\n\n    from ray import serve\n\n    serve.start()\n\n    # Train model.\n    iris_dataset = load_iris()\n    model = GradientBoostingClassifier()\n    model.fit(iris_dataset[\"data\"], iris_dataset[\"target\"])\n\n    @serve.deployment(route_prefix=\"/iris\")\n    class BoostingModel:\n        def __init__(self, model):\n            self.model = model\n            self.label_list = iris_dataset[\"target_names\"].tolist()\n\n        async def __call__(self, request):\n            payload = await request.json()[\"vector\"]\n            print(f\"Received flask request with data {payload}\")\n\n            prediction = self.model.predict([payload])[0]\n            human_name = self.label_list[prediction]\n            return {\"result\": human_name}\n\n\n    # Deploy model.\n    BoostingModel.deploy(model)\n\n    # Query it!\n    sample_request_input = {\"vector\": [1.2, 1.0, 1.1, 0.9]}\n    response = requests.get(\"http://localhost:8000/iris\", json=sample_request_input)\n    print(response.text)\n    # Result:\n    # {\n    #  \"result\": \"versicolor\"\n    # }\n\n\n.. _`Ray Serve`: https://docs.ray.io/en/master/serve/index.html\n\nMore Information\n----------------\n\n- `Documentation`_\n- `Tutorial`_\n- `Blog`_\n- `Ray 1.0 Architecture whitepaper`_ **(new)**\n- `Exoshuffle: large-scale data shuffle in Ray`_ **(new)**\n- `RLlib paper`_\n- `RLlib flow paper`_\n- `Tune paper`_\n\n*Older documents:*\n\n- `Ray paper`_\n- `Ray HotOS paper`_\n\n.. _`Documentation`: http://docs.ray.io/en/master/index.html\n.. _`Tutorial`: https://github.com/ray-project/tutorial\n.. _`Blog`: https://medium.com/distributed-computing-with-ray\n.. _`Ray 1.0 Architecture whitepaper`: https://docs.google.com/document/d/1lAy0Owi-vPz2jEqBSaHNQcy2IBSDEHyXNOQZlGuj93c/preview\n.. _`Exoshuffle: large-scale data shuffle in Ray`: https://arxiv.org/abs/2203.05072\n.. _`Ray paper`: https://arxiv.org/abs/1712.05889\n.. _`Ray HotOS paper`: https://arxiv.org/abs/1703.03924\n.. _`RLlib paper`: https://arxiv.org/abs/1712.09381\n.. _`RLlib flow paper`: https://arxiv.org/abs/2011.12719\n.. _`Tune paper`: https://arxiv.org/abs/1807.05118\n\nGetting Involved\n----------------\n\n- `Forum`_: For discussions about development, questions about usage, and feature requests.\n- `GitHub Issues`_: For reporting bugs.\n- `Twitter`_: Follow updates on Twitter.\n- `Slack`_: Join our Slack channel.\n- `Meetup Group`_: Join our meetup group.\n- `StackOverflow`_: For questions about how to use Ray.\n\n.. _`Forum`: https://discuss.ray.io/\n.. _`GitHub Issues`: https://github.com/ray-project/ray/issues\n.. _`StackOverflow`: https://stackoverflow.com/questions/tagged/ray\n.. _`Meetup Group`: https://www.meetup.com/Bay-Area-Ray-Meetup/\n.. _`Twitter`: https://twitter.com/raydistributed\n.. _`Slack`: https://forms.gle/9TSdDYUgxYs8SA9e8\n\n\n\n",
    "description_content_type": "",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/ray-project/ray",
    "keywords": "ray distributed parallel machine-learning hyperparameter-tuningreinforcement-learning deep-learning serving python",
    "license": "Apache 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "ray-for-mars",
    "package_url": "https://pypi.org/project/ray-for-mars/",
    "platform": null,
    "project_url": "https://pypi.org/project/ray-for-mars/",
    "project_urls": {
      "Homepage": "https://github.com/ray-project/ray"
    },
    "release_url": "https://pypi.org/project/ray-for-mars/1.12.1/",
    "requires_dist": [
      "attrs",
      "click (>=7.0)",
      "filelock",
      "grpcio (<=1.43.0,>=1.28.1)",
      "jsonschema",
      "msgpack (<2.0.0,>=1.0.0)",
      "protobuf (>=3.15.3)",
      "pyyaml",
      "aiosignal",
      "frozenlist",
      "requests",
      "virtualenv",
      "dataclasses ; python_version < \"3.7\"",
      "numpy (>=1.16) ; python_version < \"3.9\"",
      "numpy (>=1.19.3) ; python_version >= \"3.9\"",
      "dm-tree ; extra == 'all'",
      "opencensus ; extra == 'all'",
      "opentelemetry-api (==1.1.0) ; extra == 'all'",
      "kubernetes ; extra == 'all'",
      "kopf ; extra == 'all'",
      "prometheus-client (<0.14.0,>=0.7.1) ; extra == 'all'",
      "scipy ; extra == 'all'",
      "gym (<0.22) ; extra == 'all'",
      "fastapi ; extra == 'all'",
      "scikit-image ; extra == 'all'",
      "pandas ; extra == 'all'",
      "aiohttp-cors ; extra == 'all'",
      "tabulate ; extra == 'all'",
      "aiohttp (>=3.7) ; extra == 'all'",
      "lz4 ; extra == 'all'",
      "numpy (>=1.20) ; extra == 'all'",
      "uvicorn (==0.16.0) ; extra == 'all'",
      "opentelemetry-sdk (==1.1.0) ; extra == 'all'",
      "pyarrow (<7.0.0,>=4.0.1) ; extra == 'all'",
      "urllib3 ; extra == 'all'",
      "py-spy (>=0.2.0) ; extra == 'all'",
      "requests ; extra == 'all'",
      "ray-cpp (==1.12.1) ; extra == 'all'",
      "gpustat (>=1.0.0b1) ; extra == 'all'",
      "starlette ; extra == 'all'",
      "opentelemetry-exporter-otlp (==1.1.0) ; extra == 'all'",
      "matplotlib (!=3.4.3) ; extra == 'all'",
      "tensorboardX (>=1.9) ; extra == 'all'",
      "smart-open ; extra == 'all'",
      "pyyaml ; extra == 'all'",
      "fsspec ; extra == 'all'",
      "colorful ; extra == 'all'",
      "aiorwlock ; extra == 'all'",
      "ray-cpp (==1.12.1) ; extra == 'cpp'",
      "pandas ; extra == 'data'",
      "pyarrow (<7.0.0,>=4.0.1) ; extra == 'data'",
      "fsspec ; extra == 'data'",
      "numpy (>=1.20) ; extra == 'data'",
      "aiohttp (>=3.7) ; extra == 'default'",
      "aiohttp-cors ; extra == 'default'",
      "colorful ; extra == 'default'",
      "py-spy (>=0.2.0) ; extra == 'default'",
      "requests ; extra == 'default'",
      "gpustat (>=1.0.0b1) ; extra == 'default'",
      "opencensus ; extra == 'default'",
      "prometheus-client (<0.14.0,>=0.7.1) ; extra == 'default'",
      "smart-open ; extra == 'default'",
      "kubernetes ; extra == 'k8s'",
      "urllib3 ; extra == 'k8s'",
      "kopf ; extra == 'k8s'",
      "opentelemetry-api (==1.1.0) ; extra == 'observability'",
      "opentelemetry-sdk (==1.1.0) ; extra == 'observability'",
      "opentelemetry-exporter-otlp (==1.1.0) ; extra == 'observability'",
      "pandas ; extra == 'rllib'",
      "tabulate ; extra == 'rllib'",
      "tensorboardX (>=1.9) ; extra == 'rllib'",
      "requests ; extra == 'rllib'",
      "dm-tree ; extra == 'rllib'",
      "gym (<0.22) ; extra == 'rllib'",
      "lz4 ; extra == 'rllib'",
      "matplotlib (!=3.4.3) ; extra == 'rllib'",
      "scikit-image ; extra == 'rllib'",
      "pyyaml ; extra == 'rllib'",
      "scipy ; extra == 'rllib'",
      "smart-open ; extra == 'serve'",
      "opencensus ; extra == 'serve'",
      "requests ; extra == 'serve'",
      "fastapi ; extra == 'serve'",
      "py-spy (>=0.2.0) ; extra == 'serve'",
      "aiohttp-cors ; extra == 'serve'",
      "aiohttp (>=3.7) ; extra == 'serve'",
      "gpustat (>=1.0.0b1) ; extra == 'serve'",
      "starlette ; extra == 'serve'",
      "prometheus-client (<0.14.0,>=0.7.1) ; extra == 'serve'",
      "colorful ; extra == 'serve'",
      "aiorwlock ; extra == 'serve'",
      "uvicorn (==0.16.0) ; extra == 'serve'",
      "pandas ; extra == 'tune'",
      "tabulate ; extra == 'tune'",
      "tensorboardX (>=1.9) ; extra == 'tune'",
      "requests ; extra == 'tune'"
    ],
    "requires_python": "",
    "summary": "Ray provides a simple, universal API for building distributed applications.",
    "version": "1.12.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 13875573,
  "releases": {
    "1.12.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a9e35236433849a18c12b5f34177d9a19f3b981185d5f4e7235afb07cadf3db9",
          "md5": "ae3976afae48e7f08b4fd4d20f2f2087",
          "sha256": "1f5e6b8553296e6972936bd4ed812f3e63434e5b67f3a39f9e52f7583ff34ce0"
        },
        "downloads": -1,
        "filename": "ray_for_mars-1.12.0-cp37-cp37m-manylinux2014_x86_64.whl",
        "has_sig": false,
        "md5_digest": "ae3976afae48e7f08b4fd4d20f2f2087",
        "packagetype": "bdist_wheel",
        "python_version": "cp37",
        "requires_python": null,
        "size": 27661853,
        "upload_time": "2022-05-19T12:02:48",
        "upload_time_iso_8601": "2022-05-19T12:02:48.111319Z",
        "url": "https://files.pythonhosted.org/packages/a9/e3/5236433849a18c12b5f34177d9a19f3b981185d5f4e7235afb07cadf3db9/ray_for_mars-1.12.0-cp37-cp37m-manylinux2014_x86_64.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ceba6481c34f1028e434442e04318abab7ae8a7c4578f21dbce15295ba1ba0a3",
          "md5": "3782b9d5461dad5b08cbc8295f1b2bb1",
          "sha256": "6a20eec29bd3310e99dd7fd3541a5f086afff9c32488b28d3cde592ebb3544e1"
        },
        "downloads": -1,
        "filename": "ray_for_mars-1.12.0-cp38-cp38-manylinux2014_x86_64.whl",
        "has_sig": false,
        "md5_digest": "3782b9d5461dad5b08cbc8295f1b2bb1",
        "packagetype": "bdist_wheel",
        "python_version": "cp38",
        "requires_python": null,
        "size": 27672328,
        "upload_time": "2022-05-19T12:02:55",
        "upload_time_iso_8601": "2022-05-19T12:02:55.822557Z",
        "url": "https://files.pythonhosted.org/packages/ce/ba/6481c34f1028e434442e04318abab7ae8a7c4578f21dbce15295ba1ba0a3/ray_for_mars-1.12.0-cp38-cp38-manylinux2014_x86_64.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e867ad05359bdcd934e6f50f7af62a7d4b93f9a85fb5b215b84c62b9343eea28",
          "md5": "31586a5546e2d1bd763373b8f52a32fb",
          "sha256": "4231e41db4755e546be47eb4177d1106c597ef54b8739ea8cd1c7fb2890ec51c"
        },
        "downloads": -1,
        "filename": "ray_for_mars-1.12.0-cp39-cp39-manylinux2014_x86_64.whl",
        "has_sig": false,
        "md5_digest": "31586a5546e2d1bd763373b8f52a32fb",
        "packagetype": "bdist_wheel",
        "python_version": "cp39",
        "requires_python": null,
        "size": 27703608,
        "upload_time": "2022-05-19T12:03:03",
        "upload_time_iso_8601": "2022-05-19T12:03:03.039454Z",
        "url": "https://files.pythonhosted.org/packages/e8/67/ad05359bdcd934e6f50f7af62a7d4b93f9a85fb5b215b84c62b9343eea28/ray_for_mars-1.12.0-cp39-cp39-manylinux2014_x86_64.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.12.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "58bd74ee9e7c87971be937cc2552879fda6d09b8f92d314e3e96376c5cbd8ea1",
          "md5": "4590e0316781f5eeac732329e68ff591",
          "sha256": "411d81813764a34bc0a1e2d57629acb3fdd530292e585d81551b42da50138fff"
        },
        "downloads": -1,
        "filename": "ray_for_mars-1.12.1-cp38-cp38-manylinux2014_x86_64.whl",
        "has_sig": false,
        "md5_digest": "4590e0316781f5eeac732329e68ff591",
        "packagetype": "bdist_wheel",
        "python_version": "cp38",
        "requires_python": null,
        "size": 28966410,
        "upload_time": "2022-05-20T08:30:25",
        "upload_time_iso_8601": "2022-05-20T08:30:25.904105Z",
        "url": "https://files.pythonhosted.org/packages/58/bd/74ee9e7c87971be937cc2552879fda6d09b8f92d314e3e96376c5cbd8ea1/ray_for_mars-1.12.1-cp38-cp38-manylinux2014_x86_64.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "58bd74ee9e7c87971be937cc2552879fda6d09b8f92d314e3e96376c5cbd8ea1",
        "md5": "4590e0316781f5eeac732329e68ff591",
        "sha256": "411d81813764a34bc0a1e2d57629acb3fdd530292e585d81551b42da50138fff"
      },
      "downloads": -1,
      "filename": "ray_for_mars-1.12.1-cp38-cp38-manylinux2014_x86_64.whl",
      "has_sig": false,
      "md5_digest": "4590e0316781f5eeac732329e68ff591",
      "packagetype": "bdist_wheel",
      "python_version": "cp38",
      "requires_python": null,
      "size": 28966410,
      "upload_time": "2022-05-20T08:30:25",
      "upload_time_iso_8601": "2022-05-20T08:30:25.904105Z",
      "url": "https://files.pythonhosted.org/packages/58/bd/74ee9e7c87971be937cc2552879fda6d09b8f92d314e3e96376c5cbd8ea1/ray_for_mars-1.12.1-cp38-cp38-manylinux2014_x86_64.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}