{
  "info": {
    "author": "Smart-Impulse",
    "author_email": "contact@smart-impulse.com",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Developers",
      "Intended Audience :: Education",
      "Intended Audience :: Information Technology",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)",
      "License :: OSI Approved :: GNU Lesser General Public License v3 or later (LGPLv3+)",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3 :: Only",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Topic :: Scientific/Engineering",
      "Topic :: Scientific/Engineering :: Artificial Intelligence",
      "Topic :: Scientific/Engineering :: Information Analysis",
      "Topic :: Scientific/Engineering :: Mathematics",
      "Topic :: Software Development",
      "Topic :: Software Development :: Libraries",
      "Topic :: Software Development :: Libraries :: Python Modules",
      "Topic :: Utilities"
    ],
    "description": "# WONTERFACT\n\n## Overview\nWonterfact, or WONderful TEnsoR FACTorization, is a python package which provides a powerful tool to design any tensor factorization model and estimate the corresponding parameters.\n\nThis project has been initiated from 2015 to 2019 by Benoit Fuentes as a researcher in [Smart Impulse](https://www.smart-impulse.com/) R&D team.\n\n## Features\n - It is a generalization of coupled tensor factorization, allowing to design an infinite number of models.\n - Many kind of operations can be used to design models: tensor multiplication, addition, integration, convolution, concatenation, etc.\n - Tensors to be factorized (i.e. observed tensors) can be either nonnegative or real-valued.\n - Each factor tensor of the model can be either nonnegative or real-valued, allowing to design semi-nonnegative models.\n - It is based on solid probabilistic framework: Poisson-based for nonnegative observed tensors or Skellam-based for real valued observed tensors.\n - Smooth constraints can be added to factors via prior distributions.\n - Hard linear equality or inequality constraints can be applied on factor tensors.\n - Two inference algorithms have been implemented: the Expectation-Maximization (EM) algorithm to find the posterior maximum of the parameters or the Variational Bayes EM (VBEM) algorithm to find an approximation of the posterior distributions of the parameters.\n - In VBEM mode, hyperparameters of the prior distributions can also be inferred.\n - In VBEM mode, wonterfact is a generalization of Latent Dirichlet Allocation (LDA).\n - Possibility to use cpu or gpu backend.\n\n\n## References\nFor the moment, no article has been published yet to introduce this package and describe theoretical background on which it relies. Such an article should be published during the year 2021. Meanwhile, you can check on the [technical report](https://www.benoit-fuentes.fr/downloads/Wonterfact_technical_report.pdf) (beware this is work in progress) if you're interested in the theory.\n\n\n## Installation\n\n### Requirements\nWonterfact only runs with python 3.8+.\n\n[Graphviz](https://graphviz.org/) need to be installed to be able to render graphs of designed model (not necessary).\n\nTo be able to use wonterfact with gpu (optional), [CUDA](https://developer.nvidia.com/cuda-toolkit-archive) and `cupy` need to be installed (see [here](https://docs.cupy.dev/en/master/install.html) for cupy installation).\nWonterfact has only been tested with CUDA 10.2 and the corresponding `cupy` version:\n```bash\npip install cupy-cuda102\n```\nIt might work with other versions of CUDA (not tested).\n\nFor conda users who would prefer to \"conda install\" instead of \"pip install\" the main dependencies before installing wonterfact package (like numpy for instance), you can find the list of requirements in the \"[tool.poetry.dependencies]\" section of the `pyproject.toml` file.\n\n### Installation of wonterfact\nWith `pip`:\n```bash\npip install wonterfact\n```\n\n## Getting started: Nonnegative Matrix Factorization (NMF)\nWonterfact offers many possibilities, and mastering it requires time and effort (a full documentation as well as many tutorials should be released soon). However, once mastered, implementing and testing any tensor factorization model is quite simple and quick. We introduce here, by mean of a very simple example, the main principles of the use of wonterfact.\n\n(If you read these lines on github, you can install an appropriate extension such as [this one for Firefox](https://addons.mozilla.org/fr/firefox/addon/latexmathifygithub/) or [this one for Chrome](https://chrome.google.com/webstore/detail/github-math-display/cgolaobglebjonjiblcjagnpmdmlgmda) in order to correctly render mathematical formulas.)\n\n### Formulation of the model.\nThe goal of NMF is to find a good approximation of a nonnegative matrix *X*, that can be decomposed as the product of two nonnegative matrices $W$ and $H$: $X\\approx WH,W\\geq 0,H\\geq 0$. In some application of the NMF problem, $W$ is called *atoms* and $H$ is called *activations*, terms that will be kept in the following to refer these two factors. Moreover, the more generic term *tensor* can be used instead of *matrix*.\n\nThe first stage, and it is the main difficulty, in order to implement such a problem with wonterfact is to reformulate it with normalization constraints. It is not explained why here (there are some theoretical reasons) but factors need to be normalized in a specific way. We give here a step by step simple recipe to provide a valid normalization.\n\nFirst, give names to each tensor index: $X_{ft}\\approx\\sum_{k}W_{fk}H_{kt},W\\geq 0,H\\geq 0$. In wonterfact, tensors are identified with their indexes' names.\n\nThen, add a scalar factor $\\lambda$ to the model: $X_{ft}\\approx\\lambda\\sum_{k}W_{fk}H_{kt},W\\geq 0,H\\geq 0$ This scalar can be called *overall energy*.\n\nFind normalization constraints on each factor so that the sum on all indexes of the left hand side expression, from which overall energy has been withdrawn, is equal to 1. Here, we want then $\\sum_{ftk}W_{fk}H_{kt}=1$. It can be verified that a valid normalization can be: $\\sum_{kt}H_{kt}=1,\\forall k,\\sum_{f}W_{fk}=1$.\n\nA convenient convention to designate nonnegative tensors subject to normalization constraints is to use the same letter $\\theta$ for them, as well as the sign \"|\" for partial normalization: any tensor written for instance as $\\theta_{wx\\mid zy}$ should verify $\\forall y,z, \\sum_{wx}\\theta_{wx\\mid zy}=1$ and $\\forall w,x,y,z, \\theta_{wx\\mid zy}\\geq 0$. In this way, the model can be reformulated as: $X_{ft}\\approx\\lambda\\sum_{k}\\theta_{f \\mid k}\\theta_{kt}$. All normalization constraints are implicitly express through the suggested convention and the name of the indexes are sufficient to identify the former $W$ and $H$ matrices. Generally, there is several ways to find a valid normalization for the factors, but they all respect the following rule: each index must be once and only once on the left side of the sign \"|\" (all indexes of a tensor subject to normalization constraint and not having a \"|\" sign are considered to be on the left side). Feel free to switch order of indexes in a given tensor if needed.\n\nEventually, the overall energy can be reintegrated in a full normalized tensor, i.e. not having the \"|\" sign, getting rid of this specific normalization constraint. Non-normalized tensors can be expressed with the letter $\\lambda$ and $\\lambda\\theta_{kt}$ becomes then $\\lambda_{kt}$.\n\n\nFinally, all intermediate operations should be expressed, so that multiplications of tensors have only two operands. In our case, it gives: $X_{ft}\\approx\\lambda_{ft}\\text{ with }\\lambda_{ft}=\\sum_{k}\\theta_{f\\mid k}\\lambda_{kt}, \\lambda_{kt}\\geq 0, \\theta_{f\\mid k}\\geq 0, \\sum_{f}\\theta_{f\\mid k}=1$. $\\lambda_{kt}$ are the activations and $\\theta_{f\\mid k}$ the atoms.\n\n### A graphical way to represent the model.\n\nBefore implementing the model with wonterfact, it is recommended to draw the tree of tensor operations. In this tree, *leaves* (i.e. nodes with no parents) correspond to the factors of the model, level 1 nodes, called *observers* are the tensors to be decomposed, the single *root* (level 0) is used to identify the whole tree and all other inner nodes, called *operators* correspond to tensors resulting from a specific operation of their parents nodes. The graphical representation of our current NMF model is as follow.\n\n<img src=\"images/nmf_tree.svg\" width=\"200\">\n\n\nNodes label correspond to the indexes of the tensors. Indexes are underlined to represent tensor not subject to normalization constraints (like $\\lambda_{kt}$), and not underlined if they corresponds to normalized tensors such as $\\theta_{f\\mid k}$).\n\n### Implementation with wonterfact\n\nImplementing a tensor factorization model with wonterfact consists in performing some kind of literal translation of its graphical representation (like the one presented in previous section) in wonterfact language. There exists a specific class for each kind of node (leaves, operators, observers, etc.) and a users just need to know their name and attributes. We describe here how to make implement our NMF model. We will proceed bottom-up, starting from the root and ending with the leaves.\n\nFirst off all, let us import needed packages, and define arbitrary dimensions for our problem:\n```python\nimport wonterfact as wtf\nimport numpy as np\nimport numpy.random as npr\ndim_f, dim_k, dim_t = 10, 3, 30\n```\n\nThen let us create the root. We recall that the root is used to represent the whole tree. Root object has many attributes, but all of them have default values and therefore are optionals. We will nevertheless specify a name for this node (it is not necessary but it can be quite useful for debugging when errors are raised), and the type of inference algorithm (here EM algorithm, which is the default value anyway). We will also specify that one want to compute the value of the cost function to minimize at each iteration (it is not necessary, but we will show you that this cost decreases over the iterations).\n```python\nmy_tree = wtf.Root(name='root', inference_mode='EM', cost_computation_iter=1)\n```\n\nNow is time to create the observer. Since the tensor to be decomposed is nonnegative, the class `PosObserver` is used. To create a node that represents a tensor (i.e. all nodes but the root), it is necessary to provide the name of indexes in the write order via `index_id` attribute. The only convention you need to keep in mind, is that **the order of indexes must be reversed compared to the order on the graph representation** (an explanation will be given when the normalized leave representing atoms is instantiated). For observers object, the tensor to decompose is passed through the `tensor` attribute. We define here some random tensor.\n\n```python\nobserver = wtf.PosObserver(\n    name='observer',\n    index_id='tf',  # could also define a tuple of strings like ('t', 'f')\n    tensor=100 * npr.rand(dim_t, dim_f)\n)\n```\n\nWe can create the edge between the two nodes:\n\n```python\nobserver.new_child(my_tree)\n# my_tree.new_parent(observer)  # is equivalent\n# wtf.create_filiation(observer, root)  # is also equivalent\n```\n\nLet us go further and define the node above the observer that represents the approximation $\\lambda_{ft}$. It is defined as the product of its two parents, therefore the class `Multiplier` is used. Only `index_id` attribute is necessary (do not forget to define indexes backwards).\n\n```python\nmultiplier = wtf.Multiplier(name='multiplier', index_id='tf')\nmultiplier.new_child(observer)  # edge with its child\n```\n\nFor the leaves, let us start with the one representing activations $\\lambda_{kt}$. This tensor has no normalization constraint, therefore the right class to use to represent it is `LeafGamma`. The reason for such a class name is that, in the probabilistic framework on which wonterfact relies, each coefficient of nonnegative tensor factors not subject to normalization constraints are considered as gamma random variables. There are two hyperparameters for gamma random variables: shape and rate. Those two hyperparameters defines then the prior distribution of the activations and can be specified during creation of the leaf with the two attributes `prior_shape` and `prior_rate`. Leaving these two attributes to their default value is equivalent to not consider any prior. `tensor` attribute is compulsory and defines the initial values for the activations.\n\n```python\nleaf_tk = wtf.LeafGamma(\n    name='activations',\n    index_id='tk',\n    tensor=np.ones((dim_t, dim_k)),  # initialization with uniform activations\n    prior_shape=1,  # default value, meaning \"uniform prior\" over R\n    prior_scale=0  # default value, meaning \"uniform prior\" over R\n)\n```\n\nThe last node to create is the leaf representing atoms $\\theta_{f\\mid k}$. Since this tensor is subject to normalization constraint, the right class to use is `LeafDirichlet`, referring to the Dirichlet prior distribution. This distribution can be defined with the shape hyperparameters. Besides `index_id`, `tensor`, and `prior_shape` attributes, `LeafDirichlet` class needs a `norm_axis` attribute that specifies the axes on which the tensor has the normalization constraint. For a reason internal to wonterfact (related to the way numpy manages automatic broadcasting arrays), **it is necessary that normalization axes are the last axes of the tensor**, hence the convention to define indexes and tensors' shape backwards. We decide to randomly initialize the atoms. Beware that initialization must respect the normalization constraint.\n\n```python\nleaf_kf = wtf.LeafDirichlet(\n    name='atoms',\n    index_id='kf',\n    norm_axis=(1, ),  # self.tensor.sum(axis=self.norm_axis) must be equal to 1\n    tensor=npr.dirichlet(np.ones(dim_f), size=dim_k),  # random initialization\n    prior_shape=1,  # default value, meaning \"uniform prior\" over the simplex\n)\n```\n\nFinally, we create the last needed edges:\n```python\nleaf_tk.new_child(multiplier)\nleaf_kf.new_child(multiplier)\n# multiplier.new_parents(leaf_tk, leaf_kf)  # is equivalent\n```\n\nThis is it, the NMF model is now instantiated. You can check if the tree of operations corresponds to the one you draw yourself (this is how we actually generated the figure in previous section):\n```python\nmy_tree.draw_tree(show_node_names=True, filename='nmf_tree.svg')\n```\n\nYou can use name you gave to each node (provided that each name is unique) to access to a particular node:\n```python\nleaf_kf == my_tree.atoms == my_tree.nodes_by_id['atoms']  # returns True\n```\n\nIn order to estimate the parameters of the model (here atoms and activations), use the method `estimate_param` of your tree and decide on the number of iterations:\n```python\nmy_tree.estimate_param(n_iter=30)\n```\nIf you think you need more iterations, just call again the same method (stop and go mode). Algorithm might stop before the requested number of iterations if convergence has been reached.\n```python\nmy_tree.estimate_param(n_iter=70)  # up to a total of 100 iterations\n```\n\nPlot cost function and observed its decrease:\n```python\nimport matplotlib.pyplot as plt\nplt.plot(my_tree.cost_record)\nplt.xlabel('iteration')\nplt.ylabel('cost function')\n```\n<img src=\"images/nmf_cost_function.png\">\n\nGet atoms and activations values:\n```python\nprint(my_tree.atoms.tensor)\nprint(my_tree.activations.tensor)\n```\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/smartimpulse/wonterfact",
    "keywords": "tensor,factorization,IA,signal,bayes",
    "license": "GPL-3.0-or-later",
    "maintainer": "",
    "maintainer_email": "",
    "name": "wonterfact",
    "package_url": "https://pypi.org/project/wonterfact/",
    "platform": "",
    "project_url": "https://pypi.org/project/wonterfact/",
    "project_urls": {
      "Homepage": "https://github.com/smartimpulse/wonterfact",
      "Repository": "https://github.com/smartimpulse/wonterfact"
    },
    "release_url": "https://pypi.org/project/wonterfact/3.0.0/",
    "requires_dist": [
      "numpy (>=1.20.2)",
      "numba (>=0.53.1)",
      "scipy (>=1.6.2)",
      "opt_einsum (>=3.3.0)",
      "custom_inherit (>=2.3.1)",
      "python-baseconv (>=1.2.2)",
      "graphviz (>=0.16)",
      "methodtools (>=0.4.2)"
    ],
    "requires_python": ">=3.8,<3.10",
    "summary": "A powerful tool to design any tensor factorization model and estimate the corresponding parameters",
    "version": "3.0.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 10836835,
  "releases": {
    "2.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c515b3d0269d721ebd59fdd3925c2482c0ac45bae0d0978b53344e47aa7fde6b",
          "md5": "133bc2c709f7036bd251c62472f66941",
          "sha256": "3771f93b6863c30894fc33a7eaa6537eb6361dddd5ac585267d76a2eb24c9776"
        },
        "downloads": -1,
        "filename": "wonterfact-2.1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "133bc2c709f7036bd251c62472f66941",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 61463,
        "upload_time": "2020-11-06T17:07:35",
        "upload_time_iso_8601": "2020-11-06T17:07:35.206918Z",
        "url": "https://files.pythonhosted.org/packages/c5/15/b3d0269d721ebd59fdd3925c2482c0ac45bae0d0978b53344e47aa7fde6b/wonterfact-2.1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fb0ea4c4520bfc1716837f31334a81e7fdbeb3daa3dcf056d32cb5503b844c1e",
          "md5": "6ed1f691d797a1e0d22d7b0fd99d6be3",
          "sha256": "d5c786c46f53a0c8885cd37dc768302be6ed093e84adb10e3051cc10b48418d5"
        },
        "downloads": -1,
        "filename": "wonterfact-2.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "6ed1f691d797a1e0d22d7b0fd99d6be3",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 57686,
        "upload_time": "2020-11-06T17:07:53",
        "upload_time_iso_8601": "2020-11-06T17:07:53.298866Z",
        "url": "https://files.pythonhosted.org/packages/fb/0e/a4c4520bfc1716837f31334a81e7fdbeb3daa3dcf056d32cb5503b844c1e/wonterfact-2.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "2.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ca4d8f7855d2ba936039926fbaa17c1dfa0f14381959cca720db0cf46b127c02",
          "md5": "930d087f70a05dca452a1970447115c4",
          "sha256": "84e594ef67d57f4f42ebeff6ddd3c6fab0577fff9b639019f59956c3bc6227bd"
        },
        "downloads": -1,
        "filename": "wonterfact-2.1.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "930d087f70a05dca452a1970447115c4",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 61986,
        "upload_time": "2021-02-16T14:43:54",
        "upload_time_iso_8601": "2021-02-16T14:43:54.134558Z",
        "url": "https://files.pythonhosted.org/packages/ca/4d/8f7855d2ba936039926fbaa17c1dfa0f14381959cca720db0cf46b127c02/wonterfact-2.1.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8c2a1676c6674fccc6dea6d8df11f577e62a389e37327831a4c533415c74f419",
          "md5": "6c4d50b75be78884a4091f1545ec9b2f",
          "sha256": "c1f8527044ef1853d357e586e76a54667fd221400071dbb9410f09a34f66f505"
        },
        "downloads": -1,
        "filename": "wonterfact-2.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "6c4d50b75be78884a4091f1545ec9b2f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 58123,
        "upload_time": "2021-02-16T14:43:55",
        "upload_time_iso_8601": "2021-02-16T14:43:55.798820Z",
        "url": "https://files.pythonhosted.org/packages/8c/2a/1676c6674fccc6dea6d8df11f577e62a389e37327831a4c533415c74f419/wonterfact-2.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "2.2.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4825ee8988b6ed6e2506f675bca42912037fe545ebfa0bf0e413ee8843be7e46",
          "md5": "088cebe362dcd830c93d54a48834303b",
          "sha256": "45cbd9aee2ea824e0a36a659247575aa65077ced28410f102d79603178a3603f"
        },
        "downloads": -1,
        "filename": "wonterfact-2.2.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "088cebe362dcd830c93d54a48834303b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8,<3.10",
        "size": 67741,
        "upload_time": "2021-04-09T13:52:21",
        "upload_time_iso_8601": "2021-04-09T13:52:21.533105Z",
        "url": "https://files.pythonhosted.org/packages/48/25/ee8988b6ed6e2506f675bca42912037fe545ebfa0bf0e413ee8843be7e46/wonterfact-2.2.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a815cded1e6a310a707197112cce737650b167802575e05b84ff02cf7a52ca6e",
          "md5": "dcd40d097993ce36c0e6aed7340fa651",
          "sha256": "f8a698a433fa6ed29947de58766b6a0464cc3e4f540cabb8c1e1d2332998a808"
        },
        "downloads": -1,
        "filename": "wonterfact-2.2.1.tar.gz",
        "has_sig": false,
        "md5_digest": "dcd40d097993ce36c0e6aed7340fa651",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8,<3.10",
        "size": 63189,
        "upload_time": "2021-04-09T13:52:23",
        "upload_time_iso_8601": "2021-04-09T13:52:23.161503Z",
        "url": "https://files.pythonhosted.org/packages/a8/15/cded1e6a310a707197112cce737650b167802575e05b84ff02cf7a52ca6e/wonterfact-2.2.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "3.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "021aa9be006d1aa360a7660393fdca3aeee81e9461707afa0c645aeb6ae907b2",
          "md5": "f16a667a26a9adf43d7e9d2db4099bce",
          "sha256": "dcf16bff11c0c7313f5786a8c15da91db778afa9ef8eab9e488333f785ef48ba"
        },
        "downloads": -1,
        "filename": "wonterfact-3.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f16a667a26a9adf43d7e9d2db4099bce",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8,<3.10",
        "size": 70210,
        "upload_time": "2021-07-06T16:26:48",
        "upload_time_iso_8601": "2021-07-06T16:26:48.669461Z",
        "url": "https://files.pythonhosted.org/packages/02/1a/a9be006d1aa360a7660393fdca3aeee81e9461707afa0c645aeb6ae907b2/wonterfact-3.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "842af8a53ba01ddd4058d895eb720125cc77de48b6d381b316a6edf6f0324067",
          "md5": "d5eb7d7e6a21e70b904e3bd2bbee06fa",
          "sha256": "78807e9ff3f9256e651d1a40a2f13fc050544d4eb6e5f37a92339b20220bb5aa"
        },
        "downloads": -1,
        "filename": "wonterfact-3.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "d5eb7d7e6a21e70b904e3bd2bbee06fa",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8,<3.10",
        "size": 66655,
        "upload_time": "2021-07-06T16:26:51",
        "upload_time_iso_8601": "2021-07-06T16:26:51.010791Z",
        "url": "https://files.pythonhosted.org/packages/84/2a/f8a53ba01ddd4058d895eb720125cc77de48b6d381b316a6edf6f0324067/wonterfact-3.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "021aa9be006d1aa360a7660393fdca3aeee81e9461707afa0c645aeb6ae907b2",
        "md5": "f16a667a26a9adf43d7e9d2db4099bce",
        "sha256": "dcf16bff11c0c7313f5786a8c15da91db778afa9ef8eab9e488333f785ef48ba"
      },
      "downloads": -1,
      "filename": "wonterfact-3.0.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "f16a667a26a9adf43d7e9d2db4099bce",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.8,<3.10",
      "size": 70210,
      "upload_time": "2021-07-06T16:26:48",
      "upload_time_iso_8601": "2021-07-06T16:26:48.669461Z",
      "url": "https://files.pythonhosted.org/packages/02/1a/a9be006d1aa360a7660393fdca3aeee81e9461707afa0c645aeb6ae907b2/wonterfact-3.0.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "842af8a53ba01ddd4058d895eb720125cc77de48b6d381b316a6edf6f0324067",
        "md5": "d5eb7d7e6a21e70b904e3bd2bbee06fa",
        "sha256": "78807e9ff3f9256e651d1a40a2f13fc050544d4eb6e5f37a92339b20220bb5aa"
      },
      "downloads": -1,
      "filename": "wonterfact-3.0.0.tar.gz",
      "has_sig": false,
      "md5_digest": "d5eb7d7e6a21e70b904e3bd2bbee06fa",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.8,<3.10",
      "size": 66655,
      "upload_time": "2021-07-06T16:26:51",
      "upload_time_iso_8601": "2021-07-06T16:26:51.010791Z",
      "url": "https://files.pythonhosted.org/packages/84/2a/f8a53ba01ddd4058d895eb720125cc77de48b6d381b316a6edf6f0324067/wonterfact-3.0.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}