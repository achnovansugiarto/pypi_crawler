{
  "info": {
    "author": "",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# Polyphonic Sound Detection Score (PSDS)\n\n`psds_eval` is a Python package containing a library to\ncalculate the Polyphonic Sound Detection Score as presented in:\n\n> **A Framework for the Robust Evaluation of Sound Event Detection**  \nC. Bilen, G. Ferroni, F. Tuveri, J. Azcarreta, S. Krstulovic  \nIn IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP). May 2020  \nhttps://arxiv.org/abs/1910.08440\n\nThe PSDS is a metric for evaluating Sound Event Detection (SED) systems.\nDifferently from other widely adopted metrics, PSDS:\n1. Introduces a new, flexible and robust definition of event detection that yields\nan evaluation closer to the end-user perception of sound events\n2. Discriminates cross-triggers from generic false positives and supports\ntheir custom weighting to cope with imbalanced datasets and to help developers\nidentify weaknesses in the system\n3. Evaluates the SED system performance using multiple operating points to truly\nmeasure the quality of the sound event modelling without system calibration\nbias\n\nThese capabilities are summarized below. For more details please\nread the paper accessible from the link above.\n\n1. **Definition of event detection**\n\n   When evaluating SED system performance, existing metrics constrain the\n   detection's start and end times to within a certain distance from\n   the ground truth. This determines whether the detections are correct or\n   not.\n   An example of such a constraint is commonly called \"collar\". While it introduces\n   some degree of tolerance for either human or system imperfections in the\n   evaluation, it also increases the need for very accurate ground truths by\n   requiring the detections to closely match the annotations. Suppose an audio\n   sample contains two very close dog barks (e.g. 200ms) and the annotator\n   decided to create two ground truths. A system that detects both annotations\n   with a single detection should not be penalised.\n\n   PSDS relaxes these constraints by introducing a flexible and more\n   user-oriented definition of event detection. Two parameters, expressed as a\n   percentage of intersection between two or more entities, are used: Detection\n   Tolerance Criterion (DTC) and Ground Truth intersection Criterion (GTC).\n   The image below shows how 5 typical scenarios are evaluated using collars\n   (left) and using the PSDS method (right).\n   The taller background rectangles are ground truths while the smaller\n   foreground rectangles represent the system detections. Vertical dashed lines\n   simulate how the ground truth boundaries are affected by the collar.\n\n   ![Fig: Event Detection](https://raw.githubusercontent.com/DCASE-REPO/psds_eval/master/examples/data/def_evtdet.jpg)\n\n2. **Cross-triggers**\n\n   Suppose we have a 3-class SED system that outputs 4 detections for a given\n   audio sample with two sound events. The scenario is depicted in the figure\n   below in which ground truths and detections are indicated by background and\n   foreground rectangles, respectively.\n\n   ![Fig: CT Example](https://raw.githubusercontent.com/DCASE-REPO/psds_eval/master/examples/data/ct_example.jpg)\n\n   Detections 1 and 3 are clearly true positives (TP) while detections 2 and 4\n   are false positives (FP). In addition to this, PSDS also counts detection 4\n   as a cross-trigger (CT) for Class 3 on the ground truth Class 1.\n   The confusion matrix for this example would be:\n\n   |         | Class 1 | Class 2 | Class 3 | WORLD |\n   |---------|:-------:|:-------:|:-------:|:-----:|\n   | Class 1 |    1    | | |  1 |\n   | Class 2 | | 1 | | |\n   | Class 3 | 1 | | | 1 |\n\n   PSDS also allows a custom weight to be applied to CTs in order to define\n   their importance in the final evaluation. Such weighting can be crucial when\n   the evaluation dataset is unbalanced. For instance, the sound of\n   window glass breaking rarely happens in the real world, yet the reliable\n   evaluation of glass breaking TPs requires a large number of positive class\n   samples, which may in turn artificially increase the FP counts for other\n   percussive classes. In such scenario, PSDS would help the developer to assess\n   the system performance by weighting out the cross-trigger effects. It also\n   helps to highlight the limits of the system and to narrow the problem down\n   to, perhaps, a training labels problem.\n\n3. **Operating point**\n\n   Standard metrics for SED conflate the evaluation of sound event modelling\n   with the evaluation of operating point (OP) tuning. In other fields of\n   research, such as keyword spotting, this issue is solved by evaluating\n   multiple operating points and by reporting an overall measure, such as area\n   under curve. PSDS calculates the area under the Polyphonic Sound Detection\n   Receiver Operating Characteristic (PSD-ROC).\n\n   The image below shows an example of PSD-ROC for a SED system. The curve is\n   built by choosing a number of different tunings (operating points) of the\n   system. Let's consider the two points indicated by *A* (30, 0.3) and *B*\n   (30, 0.39). If the system is tuned to *A*, the performance is underestimated\n   given that for a similar false positive rate the system can achieve a\n   significantly higher true positive rate if tuned to *B*.\n\n   ![Fig: PSD ROC Curve](https://raw.githubusercontent.com/DCASE-REPO/psds_eval/master/examples/data/psd_roc_2.png)\n\n   An evaluation based on multiple OPs provides a better understanding of the\n   system performance at different TP/FP trade-offs.\n\n   Important note:\n\n   * The PSD-ROC curve is a summary of the multiple outputs of the system under\n   evaluation and, unlike standard ROC curves in the binary classification case,\n   it does not represent every possible operating point configuration of the\n   evaluated system. For example, a system with two possible classes (speech and\n   drum) can be tuned to achieve 80% TP for speech and 70% TP for drum, but\n   such an operating point is not precisely represented on the PSD-ROC curve.\n   Hence, not all possible configurations of the given system are expected to lie\n   on the curve. However, the summary of the performance and how it changes for\n   each class is still represented in the PSD-ROC and its area (i.e. the PSDS).\n   * The PSD-ROC curve is monotonically increasing. However, when `alpha_st` is\n   not 0, this can no longer be guaranteed (cf. Equation 9 in the paper linked\n   above).\n\n## Installation\nIn order to install the `psds_eval` package:\n1. Clone the repository `git clone https://github.com/DCASE-REPO/psds_eval.git`\n2. `cd psds_eval`\n3. `pip install -Ue .`\n\n## Running the tests\nThe tests can be run using pytest with:\n> `pytest tests`\n\n## Code Example\nA code example is available within the package showing how to use the library\nto calculate the PSDS of a system for a given dataset.\n\nThe dataset used in the example is the validation subset from the challenge\n[DCASE-2019 Task 4](http://dcase.community/challenge2018/task-large-scale-weakly-labeled-semi-supervised-sound-event-detection#audio-dataset).\nFor simplicity, ground truths and metadata are available within this\npackage under `examples/data`.\n\nThe baseline system provided in\n[Task 4](http://dcase.community/challenge2018/task-large-scale-weakly-labeled-semi-supervised-sound-event-detection#baseline-system)\ndoes not support an adjustable output threshold out-of-the-box. Therefore it\nwas modified so that a different set of detections is produced for each chosen\nthreshold value.\nEach detection set is saved and available in the data folder. The filenames\nfollow the convention: `baseline_<TH>.csv`, where TH = 0.1, 0.2, ..., 1.0\nrepresents the threshold value.\n\nOnce the `psds_eval` package is installed you may run the evaluation example using the\nPython script from the examples folder like so:\n```\n$ python examples/run_psds.py\n```\nThe script should output a PSD-Score value of **0.40867** and the plot below.\n\n![Fig: PSD ROC from example code](https://raw.githubusercontent.com/DCASE-REPO/psds_eval/master/examples/data/psd_roc.png)\n\n## Notebook on PSDS evaluation of DCASE2020 Task 4 baseline system\nA Jupyter notebook has been created to show how PSDS can be used to extract\ninsights on a SED system performance. It also explains in more detail certain\nkey features of PSDS.\n\nThe notebook is available [here](./jupyter/psds.ipynb).\n\n## FAQ\n### What are all the PSDS parameters for?\nOne of the design principles behind `psds_eval` is *flexibility*.\nIn practice, the PSDS evaluation can adapt to any task constraints by\nconfiguring the following three parameters (cf. Fig.2a article):\n\n1. **Detection Tolerance Criterion threshold** (cf. Definition 2 article)\n    * Controls how precise a system detection has to be with respect to all the\n    ground truths of the same class that it intersects.\n\n2. **Ground Truth intersection Criterion threshold** (cf. Definition 3 article)\n    * Defines the amount of minimum overlap necessary to count a ground truth\n    as correctly detected.\n\n3. **Cross-Trigger Tolerance Criterion threshold** (cf. Definition 4 article)\n    * Same as DTC, but applied to the system detections that intersect ground\n    truths of other classes of interest for detection, as distinct from false\n    alarms which donâ€™t intersect with any other label.\n\nMoreover, the calculation of the PSDS of a system can be configured to take into\naccount several constraints:\n\n- The importance of **cross-triggers** can be specified in the effective False\nPositive Rate definition by the parameter `alpha_ct` (cf. Equation 6 article)\n\n- The importance of **inter-class variability** is controlled in the definition of\nthe effective True Positive Ratio by the parameter `alpha_st` (cf. Equation 9 article)\n\n- The maximum effective False Positive Rate at which the area under the PSD-ROC is\ncomputed can be adjusted by the parameter `max_efpr`. This value is crucial because\nit defines an upper bound for the mistakes a system can make in a unit of time.\n\n\n**Important notes:**\n- More than one detection can contribute to a single true positive (TP)\n- Detections contributing to TPs are not considered for cross-trigger (CT) counts\n- `alpha_st` must be a positive number\n\n### Why are multiple operating points required?\nWe want to evaluate a system across a range of operating points in contrast with\nmore classic metrics (such as F-Score or Accuracy). This approach provides\nan evaluation which is more generic and independent from the system's tuning.\n\n### What is the minimum number of operating points required?\nIt depends on how the system behaves. We encourage the user to start with at\nleast 20 operating points and, based on how the PSD-ROC looks, more operating\npoints can be added to represent the system behaviour as accurately as possible.\n\n### Is it possible to remove the operating points for a new system evaluation?\nYes, it is possible to remove all the previously added operating points by using\nthe function `PSDSEval.clear_all_operating_points`. The evaluator is then ready\nto accept new operating points and compute a new evaluation.\n\n**Important notes:**\n- the function _only_ removes the stored operating points\n- the dataset, defined by `PSDSEval.metadata` and `PSDSEval.ground_truth`, is\nnot modified\n- the task definition, defined by the 3 thresholds (DTC, GTC and CTTC) stored in\n`self.threshold`, is not modified\n\n### What are the input requirements?\nAll the inputs must be a `pandas.DataFrame`. There are two table\nformats:\n\n#### 1. `detections` and `ground_truth` tables format\nColumn names are the same as those used in the DCASE evaluation.\nEach row is defined by 4 values:\n- `filename`, identifies the input audio file\n- `onset` and `offset` are the *start* and *end* time (expressed in seconds) of\nthe event\n- `event_label` is the name of the class the event belongs to\n\nAn example of ground truth table\n\n|filename|onset|offset|event\\_label|\n|--------:|-----:|------:|-------:|\n|test.wav  |   2.0 |   20.0 |   c1|\n|test.wav  |  12.0 |   35.0 |   c2|\n|test.wav  |  42.0 |   47.0 |   c3|\n|test2.wav |   5.0 |   20.0 |   c1|\n|test2.wav |   5.0 |   30.0 |   c2|\n|test2.wav |  42.0 |   47.0 |   c3|\n|test3.wav |   5.0 |   18.0 |   c1|\n|test3.wav |  10.0 |   30.0 |   c2|\n|test3.wav |  42.0 |   48.0 |   c3|\n\nAn example of detections table\n\n|filename|onset|offset|event\\_label|\n|--------:|-----:|------:|-------:|\n|test.wav |    0.0  |  19.0  |   c1|\n|test.wav |   40.0  |  45.0  |   c1|\n|test.wav |   11.0  |  25.0  |   c2|\n|test.wav |   27.0  |  30.0  |   c2|\n|test.wav |   32.0  |  41.5  |   c2|\n|test.wav |   38.0  |  48.0  |   c3|\n\n#### 2. `metadata` table format\nSimply contains the duration (in seconds) for each file in the dataset:\n\n|filename|duration|\n|-------:|-------:|\n|test.wav  | 50.0|\n|test2.wav | 50.0|\n|test3.wav | 50.0|\n\n**Important notes**\n- `metadata` and `ground_truth` tables must have the same unique values in the\n\"filename\" column\n\n### Is it possible to find an operating point which leads to the best F1-score?\nThe `psds_eval` package provides a function called\n `select_operating_points_per_class()` which can help find the operating\n  points which best satisfy the requested criteria on TPR, FPR, eFPR or F\n  -score for each class. Examples on how to use this function are provided\n   in the [example script](./examples/run_psds.py) and the [jupyter notebook\n   ](./jupyter/psds.ipynb).\n\n## License\npsds\\_eval is MIT licensed, as found in the [LICENSE](https://github.com/DCASE-REPO/psds_eval/blob/master/LICENSE) file.\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "polyphonic sound detection evaluation score",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "psds-eval",
    "package_url": "https://pypi.org/project/psds-eval/",
    "platform": null,
    "project_url": "https://pypi.org/project/psds-eval/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/psds-eval/0.5.3/",
    "requires_dist": [
      "pandas (>=0.19)",
      "numpy (>=1.9.0)",
      "matplotlib (>=3.1.0)",
      "pytest (>=4.3)"
    ],
    "requires_python": ">=3.6",
    "summary": "A module to calculate Polyphonic Sound Detection Score",
    "version": "0.5.3",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 15477311,
  "releases": {
    "0.5.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a25b3a7ef57e70eb01e725ad3522e02b7713ef62eb4cf5d2fb47b7c1ad93ca05",
          "md5": "adcba0c3df45466b634224baddc7a82d",
          "sha256": "51b90cb29cf064edc185b9b7d12ff4cf1ac2362d45b0d54bc6c855e4600c8cc0"
        },
        "downloads": -1,
        "filename": "psds_eval-0.5.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "adcba0c3df45466b634224baddc7a82d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 20202,
        "upload_time": "2022-10-19T13:51:31",
        "upload_time_iso_8601": "2022-10-19T13:51:31.236145Z",
        "url": "https://files.pythonhosted.org/packages/a2/5b/3a7ef57e70eb01e725ad3522e02b7713ef62eb4cf5d2fb47b7c1ad93ca05/psds_eval-0.5.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0bf9106436f4d3c8e7daae8bc94484723aa253e504c7c4cb5a9d18fa009c1ef9",
          "md5": "7411cf81c9e91db4e6aa313f1fcc70a6",
          "sha256": "25de6f5ba24ce4edbd45ebb17d2d0b720f977b867f35d4190b49a140ceec8734"
        },
        "downloads": -1,
        "filename": "psds_eval-0.5.3.tar.gz",
        "has_sig": false,
        "md5_digest": "7411cf81c9e91db4e6aa313f1fcc70a6",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 25735,
        "upload_time": "2022-10-19T13:51:33",
        "upload_time_iso_8601": "2022-10-19T13:51:33.931450Z",
        "url": "https://files.pythonhosted.org/packages/0b/f9/106436f4d3c8e7daae8bc94484723aa253e504c7c4cb5a9d18fa009c1ef9/psds_eval-0.5.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "a25b3a7ef57e70eb01e725ad3522e02b7713ef62eb4cf5d2fb47b7c1ad93ca05",
        "md5": "adcba0c3df45466b634224baddc7a82d",
        "sha256": "51b90cb29cf064edc185b9b7d12ff4cf1ac2362d45b0d54bc6c855e4600c8cc0"
      },
      "downloads": -1,
      "filename": "psds_eval-0.5.3-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "adcba0c3df45466b634224baddc7a82d",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 20202,
      "upload_time": "2022-10-19T13:51:31",
      "upload_time_iso_8601": "2022-10-19T13:51:31.236145Z",
      "url": "https://files.pythonhosted.org/packages/a2/5b/3a7ef57e70eb01e725ad3522e02b7713ef62eb4cf5d2fb47b7c1ad93ca05/psds_eval-0.5.3-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "0bf9106436f4d3c8e7daae8bc94484723aa253e504c7c4cb5a9d18fa009c1ef9",
        "md5": "7411cf81c9e91db4e6aa313f1fcc70a6",
        "sha256": "25de6f5ba24ce4edbd45ebb17d2d0b720f977b867f35d4190b49a140ceec8734"
      },
      "downloads": -1,
      "filename": "psds_eval-0.5.3.tar.gz",
      "has_sig": false,
      "md5_digest": "7411cf81c9e91db4e6aa313f1fcc70a6",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 25735,
      "upload_time": "2022-10-19T13:51:33",
      "upload_time_iso_8601": "2022-10-19T13:51:33.931450Z",
      "url": "https://files.pythonhosted.org/packages/0b/f9/106436f4d3c8e7daae8bc94484723aa253e504c7c4cb5a9d18fa009c1ef9/psds_eval-0.5.3.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}