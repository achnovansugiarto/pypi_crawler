{
  "info": {
    "author": "Bea Steers",
    "author_email": "bea.steers@gmail.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# remoteit\n\nSuper basic multiprocessing/multithreading with a `concurrent.futures` type interface.\n\n## Install\n\n```bash\npip install remoteit\n```\n\n## Usage\n\n```python\nimport time\nimport remoteit\n\n@remoteit.remote\ndef do_something(x):\n    time.sleep(1)\n    return x * 2\n\n@remoteit.threaded\ndef do_something_else(x):\n    time.sleep(1)\n    return x * 2\n\n\n# simple - just call and get results\n\nfuture = do_something(5)\nfuture2 = do_something_else(6)\n\nassert future.result() == 10\nassert future2.result() == 12\n\n# concurrent processes - run multiple together\n\n# get results in order\nfutures = [do_something(i) for i in range(4)]\nassert list(remoteit.results(futures)) == [0, 2, 4, 6]\n\n# get results as soon as they finish\nfutures = [do_something(i) for i in range(4)]\nassert set(remoteit.as_completed(futures)) == {0, 2, 4, 6}\n\n```\n\n## Description & Motivation\n\nThe difference between this and `concurrent.futures` is that:\n - it's a single worker process\n - it forks a new process every time.\n\nThe reason that I made this and didn't just use `concurrent.futures` is because I was getting an error when trying to submit a job that referenced a Queue object about how certain objects can only be shared through inheritance.\n\nSo I was back to using `multiprocessing.Process`, but passing and raising remote exceptions is a total pain and is something that I find myself solving and resolving. So I decided that this would be the last time that I wanted to think about how that messaging needs to happen.\n\nThis package is basically a thin wrapper around `multiprocessing.Process` and `threading.Thread` that will send the result back and raise any exceptions from the remote worker. Super simple!\n\n## Notes & Caveats\n##### `Future` objects should only be used by a single process.\n - currently, I handle multiple concurrent futures+results by generating a random id and having the id returned along side the result.\n - then if another future pulls a result off that doesn't match its result_id, it will put it in a results dictionary which is checked by other futures for their result_ids.\n - but the problem is that dictionaries aren't shared between processes so if you're reading items from the result queue in 2 different processes, then it'll cause a deadlock because one process may pop another processes result from the queue and the future will never see its result.\n - if anyone has any ideas on ways to fix this without too much overhead, post an issue!!\n\n## Missing Interface\n - `fut.cancel()` - cancelling a task. we don't handle a cancelled result\n - `fut.result(timeout)` - we don't have result timeout atm.\n - `fut.add_done_callback()` - we don't have a monitoring thread that will run the result. better off just calling `future.result()` for now",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/beasteers/remoteit",
    "keywords": "",
    "license": "MIT License",
    "maintainer": "",
    "maintainer_email": "",
    "name": "remoteit",
    "package_url": "https://pypi.org/project/remoteit/",
    "platform": "",
    "project_url": "https://pypi.org/project/remoteit/",
    "project_urls": {
      "Homepage": "https://github.com/beasteers/remoteit"
    },
    "release_url": "https://pypi.org/project/remoteit/0.0.1/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "Wrap functions to run in separate threads/processes.",
    "version": "0.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 7941362,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b6f52c60445a9aaf064d9760cfacc58b45c57e3d7893b153dd0baa453cc84a40",
          "md5": "ee1b48d126e89b2421bbe36379807529",
          "sha256": "afb8013eb475dc0b51e1c8690de89b31dad32216bb796e95379b57fb45863e91"
        },
        "downloads": -1,
        "filename": "remoteit-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "ee1b48d126e89b2421bbe36379807529",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 3868,
        "upload_time": "2020-08-12T03:12:19",
        "upload_time_iso_8601": "2020-08-12T03:12:19.805942Z",
        "url": "https://files.pythonhosted.org/packages/b6/f5/2c60445a9aaf064d9760cfacc58b45c57e3d7893b153dd0baa453cc84a40/remoteit-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "b6f52c60445a9aaf064d9760cfacc58b45c57e3d7893b153dd0baa453cc84a40",
        "md5": "ee1b48d126e89b2421bbe36379807529",
        "sha256": "afb8013eb475dc0b51e1c8690de89b31dad32216bb796e95379b57fb45863e91"
      },
      "downloads": -1,
      "filename": "remoteit-0.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "ee1b48d126e89b2421bbe36379807529",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 3868,
      "upload_time": "2020-08-12T03:12:19",
      "upload_time_iso_8601": "2020-08-12T03:12:19.805942Z",
      "url": "https://files.pythonhosted.org/packages/b6/f5/2c60445a9aaf064d9760cfacc58b45c57e3d7893b153dd0baa453cc84a40/remoteit-0.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}