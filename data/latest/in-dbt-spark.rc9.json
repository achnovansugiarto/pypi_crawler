{
  "info": {
    "author": "LinkedIn DBT Team",
    "author_email": "dbt-dev@linkedin.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: MacOS :: MacOS X",
      "Operating System :: Microsoft :: Windows",
      "Operating System :: POSIX :: Linux",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9"
    ],
    "description": "<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/dbt-labs/dbt/ec7dee39f793aa4f7dd3dae37282cc87664813e4/etc/dbt-logo-full.svg\" alt=\"dbt logo\" width=\"500\"/>\n</p>\n<p align=\"center\">\n  <a href=\"https://github.com/dbt-labs/dbt-spark/actions/workflows/main.yml\">\n    <img src=\"https://github.com/dbt-labs/dbt-spark/actions/workflows/main.yml/badge.svg?event=push\" alt=\"Unit Tests Badge\"/>\n  </a>\n  <a href=\"https://github.com/dbt-labs/dbt-spark/actions/workflows/integration.yml\">\n    <img src=\"https://github.com/dbt-labs/dbt-spark/actions/workflows/integration.yml/badge.svg?event=push\" alt=\"Integration Tests Badge\"/>\n  </a>\n</p>\n\n**[dbt](https://www.getdbt.com/)** enables data analysts and engineers to transform their data using the same practices that software engineers use to build applications.\n\ndbt is the T in ELT. Organize, cleanse, denormalize, filter, rename, and pre-aggregate the raw data in your warehouse so that it's ready for analysis.\n\n## in-dbt-spark\nThe `in-dbt-spark` package contains code to connect with Spark Clusters @ LinkedIn.\n\nWe added a new method to the OSS dbt-spark package to connect dbt with cluster-based spark deployments @ LinkedIn (code name Setu).\nThis new method implementation will leverage in-house **Setu** for the programmatic submission of Spark jobs.\n\n\n**Setu** provides a narrow waist Spark job submission interface that in turn would allow for the programmatic submission of Spark jobs from anywhere, subject to authentication, while managing multiple Spark versions and clusters under the hood.\nUsing Setu for DBT will enable users to move much more independently and faster.\n\n## Major Implementation\n\nThe Table below represents the mapping of our custom implementation for DB conventions.\n\n| Class                  | DB                   |\n|------------------------|----------------------|\n| SparkConnectionManager | SQLConnectionManager |\n| SetuSession            | DB Connection        |\n| SetuSessionHandler     | Connection Handler   |\n| SetuStatementCursor    | DB cursor            |\n\n### SparkConnectionManager\n\nThis class is responsible for managing the connections like opening, closing and error handling scenarios.\n\n#### 1.  open(cls, connection)\n\n   open() is a classmethod that gets a connection object (which could be in any state, but will have a Credentials object with the attributes you defined above), creates a new SetuSession using SetuSessionManager and moves it to the 'open' state.\n\n   Generally this means doing the following:\n   - if the connection is open already, log and return it.\n     - create a connection handle using the credentials\n         - on success:\n             - set connection.state to `'open'`\n             - set connection.handle to the handle object\n                 - this is what must have a cursor() method that returns a cursor!\n         - on error:\n             - set connection.state to `'fail'`\n             - set connection.handle to `None`\n             - raise a dbt.exceptions.FailedToConnectException with the error and any other relevant information\n\n#### 2. cancel(self, connection)\ncancel is an instance method that gets a connection object and attempts to cancel any ongoing queries by calling the cancel on the handle object.\n\n#### 3.  exception_handler(self, sql, connection_name='master')\nexception_handler is an instance method that returns a context manager that will handle exceptions raised by running queries, catch them, log appropriately, and then raise exceptions dbt knows how to handle.\n\n### SetuSessionHandler\n  Equivalent to a DB connection handler, it is responsible for creating and executing cursors. This class creates SetuStatementCursor and executes the cursor with DBT compiled sqls\n\n### SetuSession\nThis is a spark Interactive session responsible for creating spark context with requested resources from the yarn RM. This class is responsible for managing a remote SETU session and high-level interactions with it.\n\n### SetuStatementCursor\nThis class is responsible for managing the SETU statements and high-level interactions with it. It takes care of creating, executing, waiting till SETU statement results are available and closing the SETU statement.\n\n\n## Getting started\n\n- [Install dbt](https://docs.getdbt.com/docs/installation)\n- Read the [introduction](https://docs.getdbt.com/docs/introduction/) and [viewpoint](https://docs.getdbt.com/docs/about/viewpoint/)\n\n\n#### create virtual environment for dbt\n\n```\ncd ~\nmkdir dbt_env\npython3.9 -m venv ~/dbt_env\nsource ~/dbt_env/bin/activate\n```\n\n#### Install DBT Core\n\n```\npip install dbt-core\n```\n\n#### Install DBT Spark from Code\n\n```\ngit clone this repo\ncd in-dbt-spark\npip install -r requirements.txt\npython setup.py install\n```\n\n#### verify installation\n\n```\npip list | grep dbt\n# Output:\ndbt-core          x.x.x\ndbt-extractor     x.x.x\nin-dbt-spark      x.x.x\n```\n\n## Running locally\n\n**step 1:** Run **dbt init** command to bootstrap dbt project. This step should create a dbt project.\n\n**step 2:** create new folder named profiles and create profiles.yml empty file.\n\n**step 3:** Create new profile in profiles.yml similar to below,\n\n```\ndbt_hello_world:\n  outputs:\n    dev:\n      type: spark # connection Type (Spark/Presto/Postgres)\n      method: setu  # connection Method (setu/odbc/thrift)\n      url: 'https://setu@linkedin.com'\n      schema: xxxx  #  schema to persist dbt produced tables\n      proxy_user: xxxx  # run spark jobs as proxy user\n      queue: xxxx  #  grid queue to submit spark jobs. Defaults to misc_default\n      session_name: dbt_hello_world  # unique name for spark session (UUID suffix internally)\n      metadata:  # High-level tracking metadata used to provide contextual information about the application\n        name: dbt_hello_world\n        desciption: hello world project for dbt\n        org: xxxx\n      spark_conf:  # Additional configs that may be needed for spark app execution (pass-through)\n        spark.driver.cores: 1  # Defaults to 2\n        spark.executor.cores: 1  # Defaults to 2\n        spark.driver.memory: 1G  # Defaults to 4G\n        spark.executor.memory: 2G  # Defaults to 8G\n      execution_tags:  # Used to determine the target cluster dynamically at runtime.\n        gpu: false  # If the spark job requires gpu for processing. Defaults to false\n        pool: dev  # Execution environment for the job. Defaults to Dev\n      jars: # List of ivy coordinates of the artifacts required by the spark app\n        - com.linkedin.xxxx:xxxx:+?transitive=false\n```\nstep 5: Add models and run below commands to compile/test/run\n\n```\n# COMPILE:\ndbt compile --profiles-dir ./profiles --target dev\n\n# RUN:\ndbt run --profiles-dir ./profiles --target dev --threads x\n\n# TEST:\ndbt test --profiles-dir ./profiles --target dev --threads x\n\n# GENERATE DOCS:\ndbt docs generate --profiles-dir ./profiles --target dev\n\n# SERVE DOCS:\ndbt docs serve --profiles-dir ./profiles --port 8080\n```\n\n## Reporting bugs and contributing code\n\n- Want to report a bug or request a feature? - Reach out to dbt-dev@linkedin.com\n- Want to help us build dbt? Check out the [Contributing Guide](https://github.com/linkedin/in-dbt-spark/blob/HEAD/CONTRIBUTING.md)\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/linkedin/in-dbt-spark",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "in-dbt-spark",
    "package_url": "https://pypi.org/project/in-dbt-spark/",
    "platform": null,
    "project_url": "https://pypi.org/project/in-dbt-spark/",
    "project_urls": {
      "Homepage": "https://github.com/linkedin/in-dbt-spark"
    },
    "release_url": "https://pypi.org/project/in-dbt-spark/1.2.507/",
    "requires_dist": [
      "in-dbt-core (~=1.2.0)",
      "sqlparams (>=3.0.0)",
      "pandas",
      "pyodbc (>=4.0.30) ; extra == 'odbc'",
      "PyHive[hive] (<0.7.0,>=0.6.0) ; extra == 'pyhive'",
      "thrift (<0.16.0,>=0.11.0) ; extra == 'pyhive'",
      "pyodbc (>=4.0.30) ; extra == 'all'",
      "PyHive[hive] (<0.7.0,>=0.6.0) ; extra == 'all'",
      "thrift (<0.16.0,>=0.11.0) ; extra == 'all'",
      "pyspark (<4.0.0,>=3.0.0) ; extra == 'all'",
      "pyspark (<4.0.0,>=3.0.0) ; extra == 'session'"
    ],
    "requires_python": ">=3.7",
    "summary": "Release for LinkedIn's changes to dbt-spark.",
    "version": "1.2.507",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17464396,
  "releases": {
    "1.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b4e68c4380d4bd8197d30ddbd72a586cd08d1e0ddff45ef6d754234088310692",
          "md5": "2fbb3a0a7843da224dbca1d8cf1ec882",
          "sha256": "702befccdc319034c6c5d8ce905048a85d3d0b319ec7160d5c396a71c5b5d149"
        },
        "downloads": -1,
        "filename": "in_dbt_spark-1.2.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "2fbb3a0a7843da224dbca1d8cf1ec882",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 50285,
        "upload_time": "2022-11-14T23:21:40",
        "upload_time_iso_8601": "2022-11-14T23:21:40.257563Z",
        "url": "https://files.pythonhosted.org/packages/b4/e6/8c4380d4bd8197d30ddbd72a586cd08d1e0ddff45ef6d754234088310692/in_dbt_spark-1.2.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5a6119c4bccfaabba7c114193553cf079815a8da7f5d11944108dde33237d537",
          "md5": "8041d1b6880585a8333d0d8544ec8ab8",
          "sha256": "9ec7776e979dfcf6c2485284f05a556bca463ff7d4e32656a6fab445be4ae4f7"
        },
        "downloads": -1,
        "filename": "in-dbt-spark-1.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "8041d1b6880585a8333d0d8544ec8ab8",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 42055,
        "upload_time": "2022-11-14T23:21:42",
        "upload_time_iso_8601": "2022-11-14T23:21:42.173922Z",
        "url": "https://files.pythonhosted.org/packages/5a/61/19c4bccfaabba7c114193553cf079815a8da7f5d11944108dde33237d537/in-dbt-spark-1.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.500": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "88e9c170f8cc8b0ba273f2da8d9e68d68330e7c1fbc133fe6e63cd9cc6bc4e18",
          "md5": "4f41e05919055378941c2d2c0e27bb0c",
          "sha256": "f99ce603dd735079ab56a9934e4bc563547740d9a1e11ca7724d32ce0dd6e27b"
        },
        "downloads": -1,
        "filename": "in_dbt_spark-1.2.500-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "4f41e05919055378941c2d2c0e27bb0c",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 33060,
        "upload_time": "2022-09-07T19:10:21",
        "upload_time_iso_8601": "2022-09-07T19:10:21.078767Z",
        "url": "https://files.pythonhosted.org/packages/88/e9/c170f8cc8b0ba273f2da8d9e68d68330e7c1fbc133fe6e63cd9cc6bc4e18/in_dbt_spark-1.2.500-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "12b24e21fd405bd9cd67405031a6c6a5b2f67d74b53d7d503a63df8cfa8f7509",
          "md5": "f39f816bc47278583255afa574b1b305",
          "sha256": "9935a593af203552303531b03e1bf244ed4251f2dc0f7ebf71b44da4c10eeb87"
        },
        "downloads": -1,
        "filename": "in-dbt-spark-1.2.500.tar.gz",
        "has_sig": false,
        "md5_digest": "f39f816bc47278583255afa574b1b305",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 27868,
        "upload_time": "2022-09-07T19:10:23",
        "upload_time_iso_8601": "2022-09-07T19:10:23.324644Z",
        "url": "https://files.pythonhosted.org/packages/12/b2/4e21fd405bd9cd67405031a6c6a5b2f67d74b53d7d503a63df8cfa8f7509/in-dbt-spark-1.2.500.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.501": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a1f2c19e50252c1c51aa9c3e82214cf1b2ec3935a5db7a4b357fbaabc0a9d3b6",
          "md5": "59abcda1e84cb408f4212f7d36fc5f5f",
          "sha256": "4e4ce19e4ed656f68cbb66bf5eccfcbb6233db476e393365a3d4256c3f034e36"
        },
        "downloads": -1,
        "filename": "in_dbt_spark-1.2.501-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "59abcda1e84cb408f4212f7d36fc5f5f",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 47725,
        "upload_time": "2022-09-14T05:33:45",
        "upload_time_iso_8601": "2022-09-14T05:33:45.659167Z",
        "url": "https://files.pythonhosted.org/packages/a1/f2/c19e50252c1c51aa9c3e82214cf1b2ec3935a5db7a4b357fbaabc0a9d3b6/in_dbt_spark-1.2.501-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b9ac0c6318edd1402334f421790be3fcb6ca04b3b340f2a4be85de28d290192e",
          "md5": "247aa9b316a3b33369550f965fbd7421",
          "sha256": "de85c96cb245266359a99c134631ef043b98a2b587435bd47c96004b231f65db"
        },
        "downloads": -1,
        "filename": "in-dbt-spark-1.2.501.tar.gz",
        "has_sig": false,
        "md5_digest": "247aa9b316a3b33369550f965fbd7421",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 40477,
        "upload_time": "2022-09-14T05:33:47",
        "upload_time_iso_8601": "2022-09-14T05:33:47.783606Z",
        "url": "https://files.pythonhosted.org/packages/b9/ac/0c6318edd1402334f421790be3fcb6ca04b3b340f2a4be85de28d290192e/in-dbt-spark-1.2.501.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.502": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e45c35a928b0100e957fa73b8a01446cd6533b3040fbb2f45ebb302bd5f24808",
          "md5": "0409a5381c7d921b3b798450b290e585",
          "sha256": "d4b0672666d2014ff36587018e998768e29539550f22e66af72fa8b702f1f173"
        },
        "downloads": -1,
        "filename": "in_dbt_spark-1.2.502-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0409a5381c7d921b3b798450b290e585",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 47771,
        "upload_time": "2022-09-20T21:00:51",
        "upload_time_iso_8601": "2022-09-20T21:00:51.582288Z",
        "url": "https://files.pythonhosted.org/packages/e4/5c/35a928b0100e957fa73b8a01446cd6533b3040fbb2f45ebb302bd5f24808/in_dbt_spark-1.2.502-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bda69e454e77b4a01765f040b55c98abe6da45264f9dac935eb7a8689a1c3bb9",
          "md5": "78e5b85d42043ebebbca154556b6e2e9",
          "sha256": "ccd778bccd4c93d86320f3e6b10a5d223b50bab99887e2d19533eb317eccc2a8"
        },
        "downloads": -1,
        "filename": "in-dbt-spark-1.2.502.tar.gz",
        "has_sig": false,
        "md5_digest": "78e5b85d42043ebebbca154556b6e2e9",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 40006,
        "upload_time": "2022-09-20T21:00:52",
        "upload_time_iso_8601": "2022-09-20T21:00:52.862585Z",
        "url": "https://files.pythonhosted.org/packages/bd/a6/9e454e77b4a01765f040b55c98abe6da45264f9dac935eb7a8689a1c3bb9/in-dbt-spark-1.2.502.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.503": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "31cc37b43d8a25e42ed040991f29fdd7b86cfd636804e404c56daa9ac4efdfc0",
          "md5": "8b677c791945484fcd661fab408ef1c0",
          "sha256": "296891258baab34d4fb2fe3a5e47160f4514ca908affa08ba4e9fb8d027bb52f"
        },
        "downloads": -1,
        "filename": "in_dbt_spark-1.2.503-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "8b677c791945484fcd661fab408ef1c0",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 47754,
        "upload_time": "2022-10-13T04:59:07",
        "upload_time_iso_8601": "2022-10-13T04:59:07.647453Z",
        "url": "https://files.pythonhosted.org/packages/31/cc/37b43d8a25e42ed040991f29fdd7b86cfd636804e404c56daa9ac4efdfc0/in_dbt_spark-1.2.503-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "229af859029ceda19f4ca881a0276f29f4225bc74288d8f2fbd3e7960abc377d",
          "md5": "00db012377d665bef25d86ee0658230b",
          "sha256": "d2ddb32c7734ea05f9381efbbf7a363178c50b65e3151a8526fa919480127ae3"
        },
        "downloads": -1,
        "filename": "in-dbt-spark-1.2.503.tar.gz",
        "has_sig": false,
        "md5_digest": "00db012377d665bef25d86ee0658230b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 39953,
        "upload_time": "2022-10-13T04:59:09",
        "upload_time_iso_8601": "2022-10-13T04:59:09.246633Z",
        "url": "https://files.pythonhosted.org/packages/22/9a/f859029ceda19f4ca881a0276f29f4225bc74288d8f2fbd3e7960abc377d/in-dbt-spark-1.2.503.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.504": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4af428778becb17cd9242f35beae0e63307a4307b028969267d06293ea15f287",
          "md5": "a9e594763546d8f2795234cf13f17460",
          "sha256": "068659f7587958fe35a6c6178cd32d02f543e809331adba1986fa2a8e0196541"
        },
        "downloads": -1,
        "filename": "in_dbt_spark-1.2.504-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "a9e594763546d8f2795234cf13f17460",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 50313,
        "upload_time": "2022-12-06T23:18:00",
        "upload_time_iso_8601": "2022-12-06T23:18:00.899636Z",
        "url": "https://files.pythonhosted.org/packages/4a/f4/28778becb17cd9242f35beae0e63307a4307b028969267d06293ea15f287/in_dbt_spark-1.2.504-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cf266cf3878fbcd0114881ca7c10f575d47925f60efa3ea267d78623c493bd73",
          "md5": "255ba1ebb5d47ce20bfce0422454c466",
          "sha256": "79c100e8a9ad5f589c70fe4f1c35efd87bc1111d8588fa4323cb12a1352e80bd"
        },
        "downloads": -1,
        "filename": "in-dbt-spark-1.2.504.tar.gz",
        "has_sig": false,
        "md5_digest": "255ba1ebb5d47ce20bfce0422454c466",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 42070,
        "upload_time": "2022-12-06T23:18:02",
        "upload_time_iso_8601": "2022-12-06T23:18:02.348778Z",
        "url": "https://files.pythonhosted.org/packages/cf/26/6cf3878fbcd0114881ca7c10f575d47925f60efa3ea267d78623c493bd73/in-dbt-spark-1.2.504.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.505": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bca7538e2811dac7b1d219fd212a0dae7c07f22ed03947db31d428edda685ffb",
          "md5": "d1b85b72cff4f6b3003c5d77de39835e",
          "sha256": "65776a9cb5666c717d067cef75ec4fd390ebf22a48dac37bb43f3e2453d9e673"
        },
        "downloads": -1,
        "filename": "in_dbt_spark-1.2.505-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d1b85b72cff4f6b3003c5d77de39835e",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 50314,
        "upload_time": "2022-12-08T22:33:55",
        "upload_time_iso_8601": "2022-12-08T22:33:55.019632Z",
        "url": "https://files.pythonhosted.org/packages/bc/a7/538e2811dac7b1d219fd212a0dae7c07f22ed03947db31d428edda685ffb/in_dbt_spark-1.2.505-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b04bc5829a052ee6c7e6a76849d9a49b7578e2a501a7e2ef9cd96df2a162967c",
          "md5": "7a3d280ed44f6d823a713b6c8c36a706",
          "sha256": "f3647f490f57cca65bc759014fe3c392224c7d44a52e1c1cccab9042c57c627d"
        },
        "downloads": -1,
        "filename": "in-dbt-spark-1.2.505.tar.gz",
        "has_sig": false,
        "md5_digest": "7a3d280ed44f6d823a713b6c8c36a706",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 42092,
        "upload_time": "2022-12-08T22:33:56",
        "upload_time_iso_8601": "2022-12-08T22:33:56.332158Z",
        "url": "https://files.pythonhosted.org/packages/b0/4b/c5829a052ee6c7e6a76849d9a49b7578e2a501a7e2ef9cd96df2a162967c/in-dbt-spark-1.2.505.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.506": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bc2a076376ca9f8403e298cdd1071453f0c2f24f8bb61cfc747760d215df59f6",
          "md5": "66c5abd2ce6868b688b51f7bc3bdf8aa",
          "sha256": "d79c738768ac739def87339b05a0cdaeb02a578bd5038385e48d526c8707c46b"
        },
        "downloads": -1,
        "filename": "in_dbt_spark-1.2.506-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "66c5abd2ce6868b688b51f7bc3bdf8aa",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 55830,
        "upload_time": "2023-03-22T21:01:06",
        "upload_time_iso_8601": "2023-03-22T21:01:06.552254Z",
        "url": "https://files.pythonhosted.org/packages/bc/2a/076376ca9f8403e298cdd1071453f0c2f24f8bb61cfc747760d215df59f6/in_dbt_spark-1.2.506-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7092dbd818c675880aa631760f1c4189f1413e7f470e25c5e98ba131a1fdbf1e",
          "md5": "4f075e8b8f8b00ad09b2e36fc980b84d",
          "sha256": "6365fd0b042ac0d2da25bf681c7f0c36a5a80795dacd294c3a4cac430dedf6f2"
        },
        "downloads": -1,
        "filename": "in-dbt-spark-1.2.506.tar.gz",
        "has_sig": false,
        "md5_digest": "4f075e8b8f8b00ad09b2e36fc980b84d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 46685,
        "upload_time": "2023-03-22T21:01:07",
        "upload_time_iso_8601": "2023-03-22T21:01:07.838596Z",
        "url": "https://files.pythonhosted.org/packages/70/92/dbd818c675880aa631760f1c4189f1413e7f470e25c5e98ba131a1fdbf1e/in-dbt-spark-1.2.506.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.507": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9c6c0d13d00f3e25f1693b8b0802eaa8976c1d6c6dca32457ee80b0c79d48239",
          "md5": "bf37a66dc8d6db49191197cc9d2902ab",
          "sha256": "bc60b6114e4ae042a72e324620908075e0fa30b93d342af81a17d48737335dfa"
        },
        "downloads": -1,
        "filename": "in_dbt_spark-1.2.507-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "bf37a66dc8d6db49191197cc9d2902ab",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 58466,
        "upload_time": "2023-03-27T17:09:32",
        "upload_time_iso_8601": "2023-03-27T17:09:32.167102Z",
        "url": "https://files.pythonhosted.org/packages/9c/6c/0d13d00f3e25f1693b8b0802eaa8976c1d6c6dca32457ee80b0c79d48239/in_dbt_spark-1.2.507-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cd660f8add2a835d0ae159073bf6319c101262607ffe88a33e979d991f5fde34",
          "md5": "41e70603742534c830879c6078a7b89f",
          "sha256": "59b988d319a5f4ab9fed9aefdac7b71cc2f458738c42eab6cdd7ad6f2eb138e1"
        },
        "downloads": -1,
        "filename": "in-dbt-spark-1.2.507.tar.gz",
        "has_sig": false,
        "md5_digest": "41e70603742534c830879c6078a7b89f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 48943,
        "upload_time": "2023-03-27T17:09:34",
        "upload_time_iso_8601": "2023-03-27T17:09:34.671873Z",
        "url": "https://files.pythonhosted.org/packages/cd/66/0f8add2a835d0ae159073bf6319c101262607ffe88a33e979d991f5fde34/in-dbt-spark-1.2.507.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "9c6c0d13d00f3e25f1693b8b0802eaa8976c1d6c6dca32457ee80b0c79d48239",
        "md5": "bf37a66dc8d6db49191197cc9d2902ab",
        "sha256": "bc60b6114e4ae042a72e324620908075e0fa30b93d342af81a17d48737335dfa"
      },
      "downloads": -1,
      "filename": "in_dbt_spark-1.2.507-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "bf37a66dc8d6db49191197cc9d2902ab",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 58466,
      "upload_time": "2023-03-27T17:09:32",
      "upload_time_iso_8601": "2023-03-27T17:09:32.167102Z",
      "url": "https://files.pythonhosted.org/packages/9c/6c/0d13d00f3e25f1693b8b0802eaa8976c1d6c6dca32457ee80b0c79d48239/in_dbt_spark-1.2.507-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "cd660f8add2a835d0ae159073bf6319c101262607ffe88a33e979d991f5fde34",
        "md5": "41e70603742534c830879c6078a7b89f",
        "sha256": "59b988d319a5f4ab9fed9aefdac7b71cc2f458738c42eab6cdd7ad6f2eb138e1"
      },
      "downloads": -1,
      "filename": "in-dbt-spark-1.2.507.tar.gz",
      "has_sig": false,
      "md5_digest": "41e70603742534c830879c6078a7b89f",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 48943,
      "upload_time": "2023-03-27T17:09:34",
      "upload_time_iso_8601": "2023-03-27T17:09:34.671873Z",
      "url": "https://files.pythonhosted.org/packages/cd/66/0f8add2a835d0ae159073bf6319c101262607ffe88a33e979d991f5fde34/in-dbt-spark-1.2.507.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}