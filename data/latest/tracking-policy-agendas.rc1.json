{
  "info": {
    "author": "MohammadForouhesh",
    "author_email": "Mohammadh.Forouhesh@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9"
    ],
    "description": "# A Frameword For Tracking Legislator's Policy Agendas\n[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/tracking-legislators-expressed-policy-agendas/political-salient-issue-orientation-detection)](https://paperswithcode.com/sota/political-salient-issue-orientation-detection?p=tracking-legislators-expressed-policy-agendas)\n\n[![Build Status](https://scrutinizer-ci.com/g/MohammadForouhesh/tracking-policy-agendas/badges/build.png?b=main)](https://scrutinizer-ci.com/g/MohammadForouhesh/tracking-policy-agendas/build-status/main)\n[![Scrutinizer Code Quality](https://scrutinizer-ci.com/g/MohammadForouhesh/tracking-policy-agendas/badges/quality-score.png?b=main)](https://scrutinizer-ci.com/g/MohammadForouhesh/tracking-policy-agendas/?branch=main)\n[![Code Intelligence Status](https://scrutinizer-ci.com/g/MohammadForouhesh/tracking-policy-agendas/badges/code-intelligence.svg?b=main&color=cyan&style=plastic)](https://scrutinizer-ci.com/code-intelligence)\n[![Code Coverage](https://scrutinizer-ci.com/g/MohammadForouhesh/tracking-policy-agendas/badges/coverage.png?b=main)](https://scrutinizer-ci.com/g/MohammadForouhesh/tracking-policy-agendas/?branch=main)\n[![Maintainability](https://api.codeclimate.com/v1/badges/26cc09040c2262f3ecb7/maintainability)](https://codeclimate.com/github/MohammadForouhesh/tracking-policy-agendas/maintainability)\n![Last commit](https://img.shields.io/github/last-commit/MohammadForouhesh/tracking-policy-agendas)\n![ask]\n\n[ask]: https://img.shields.io/badge/Ask%20me-anything-1.svg\n\n This repository contains the implementation for the following paper:\n > [Tracking Legislators’ Expressed Policy Agendas in Real Time](https://osf.io/preprints/socarxiv/ync87/)\n\n# Table of Contents\n1. [TODO](#todo)\n2. [A Brief Summary of The Papers](#summary)\n    1. [Introduction](#tpa_intro)\n    2. [Main Problem](#tpa_main)\n    3. [Illustrative Example](#tpa_example)\n    4. [I/O](#tpa_io)\n    5. [Motivation](#tpa_motiv)\n    6. [Related Works](#tpa_lit)\n    7. [Contributions of this paper](#tpa_contribution)\n    8. [Proposed Method](#tpa_method)\n    9. [Experiments](#tpa_exp)\n3. [Implementation details](#tpa_imp)\n4. [Reproducing Results](#tpa_repr)\n\n\n# 1) Tracking Legislators’ Expressed Policy Agendas in Real Time <a name=\"tpa\"></a>\n## TO-DO: <a name=\"todo\"></a>\n\n- [x] Summarizing the paper\n- [x] Outlining the details of implementations\n- [x] Implement Word2Vec\n- [x] Training Word2Vec\n- [x] Seed words\n- [x] Classification heads\n- [x] Results & Analysis\n- [x] Tests&Coverage\n- [ ] Documentation\n- [x] CI/CD\n- [ ] Smooth Installation\n\n## A Brief Summary of The Papers <a name=\"summary\"></a>\n* #### Introduction: <a name=\"tpa_intro\"></a>\n  <div style=\"text-align: justify\"> This work aims to analyse political orientation of legislators on salient policy issues through their temporally granular tweets, using a word embedding for feature extraction, and a classifier to label all legislators’ past and current relevant tweets according to whether they express a particular issue position over time. </div> \n* #### Main Problem: <a name=\"tpa_main\"></a>\n    <div style=\"text-align: justify\"> Is it possible to accurately analyse the temporal evolution of political orientation on salient issues by applying natural language processing techniques on users tweets? </div> \n\n    <div style=\"text-align: justify\"> The issues of concern in this paper are <b> immigration</b>, and <b>climate change</b>.  </div>\n* #### Illustrative Example: <a name=\"tpa_example\"></a>\n    <div style=\"text-align: justify\"> Given a tweet about immigration policy, they first encode it using word2vec enhanced dictionary, then its exclusiveness or inclusiveness can be detected using a classifier. Furthermore these results can be disaggregated to see whether it was posted from a Republican or a Democrat.  </div>\n* #### I/O: <a name=\"tpa_io\"></a>\n  * Input: Tweets (textual modality)\n  * Output: Predicted stance on the salient political issue\n\n* #### Motivation: <a name=\"tpa_motiv\"></a>\n    1. <div style=\"text-align: justify\"> Using tweets to track shifts in legislators’ rhetoric is highly scalable. It can be used on any topic of interest, by any political actor with a Twitter account, in any country around the world, from the past decade or into the future. </div> \n    2. <div style=\"text-align: justify\"> Twitter data has high temporal granularity. </div>\n\n* #### Related (Previous) Works: <a name=\"tpa_lit\"></a>\n    According to legislator’s different channels of communications, it is divided into 8 categories:\n\n    1. Stump speeches: [Fenno 1978](https://profbrown.org/p/notes/fenno_homestyle)\n    2. Campaign mail: [Golbeck, Grimes and Rogers 2010](https://onlinelibrary.wiley.com/doi/abs/10.1002/asi.21344)\n    3. Television advertising: [Lau, Sigelman and Rovner 2007](https://onlinelibrary.wiley.com/doi/10.1111/j.1468-2508.2007.00618.x)\n    4. Floor speeches: [Martin and Vanberg 2008](https://www.jstor.org/stable/20299752); [Martin 2011](https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1741-1130.2011.00316.x); [Quinn et al. 2010](https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1540-5907.2009.00427.x)\n    5. Press releases: [Grimmer 2010](https://econpapers.repec.org/article/cuppolals/v_3a18_3ay_3a2010_3ai_3a01_3ap_3a1-35_5f01.htm); [Grimmer, Westwood and Messing 2014](https://press.princeton.edu/books/hardcover/9780691162614/the-impression-of-influence); [Klüver and Sagarzazu 2016](https://www.researchgate.net/publication/258136850_Ideological_congruency_and_decision-making_speed_The_effect_of_partisanship_across_European_Union_institutions)\n    6. Websites: [Adler, Gent and Overmeyer 1998](https://www.jstor.org/stable/440242); [Anstead and Chadwick 2008](http://www.handbook-of-internet-politics.com/pdfs/Nick_Anstead_Andrew_Chadwick_Parties_Election_Campaigning_and_Internet.pdf); [Druckman, Kifer and Parkin 2009](https://faculty.wcas.northwestern.edu/~jnd260/pub/Druckman%20Kifer%20Parkin%20APSR%202009.pdf)\n    7. RSS feeds: [Cormack 2013](https://personal.stevens.edu/~lcormack/sins_of_omission_orig.pdf)\n    8. Social media posts: [Gulati and Williams 2010](https://opensiuc.lib.siu.edu/pn_wp/43/); [Barbera et al. 2018](https://pubmed.ncbi.nlm.nih.gov/33303996/); [Radford and Sinclair 2016](https://www.semanticscholar.org/paper/Electronic-Homestyle-%3A-Tweeting-Ideology-∗-Radford-Sinclair/ac077dbf0040a13a4766f3f178c230fae4546b34); [Shapiro et al. 2014](https://m.japss.org/upload/1.%20Final%20Park.pdf); [Lilleker and Koc-Michalska 2013](https://journals.sagepub.com/doi/full/10.1177/1461444815616218)\n\n* #### Contributions of this paper: <a name=\"tpa_contribution\"></a>\n    1. <div style=\"text-align: justify\"> Simple, transparent, and interpretable approach to tweet classification can achieve satisfactory levels of accuracy across diverse issues. </div>\n    2. <div style=\"text-align: justify\"> Automate the process of updating and maintaining the model. </div>\n    3. <div style=\"text-align: justify\"> Develop a dynamical, real-time scalable method for tracking elected officials’ expressed policy positions through their tweets. </div> \n\n* #### Proposed Method: <a name=\"tpa_method\"></a>\n    * ##### Stage I: (Feature Extraction) \n        <div style=\"text-align: justify\"> They used Word2Vec enhanced dictionary to encode the texts. In particular, a set of stemmed seed words is identified as being relevant to the concept of interest. Then use word embeddings to identify other words that are semantically related to these seed words in the data. </div>\n\n    * ##### Stage II: Classification of political stance on salient issues.\n        <div style=\"text-align: justify\"> Choice of classifier: using five-fold cross validation and comparing precision, recall, accuracy, balanced accuracy, and F1 scores to choose the best performing classifier among XGBoost, Naive Bayes, Elastic Net, Lasso. </div>\n\n* #### Experiments: <a name=\"tpa_exp\"></a>\n    * ##### Datasets:\n      Their own making. Crawled all senators and the vast majority of members of the House tweets using twitter API from any period of interest up to 2020, excluding those who left office or were elected for the first time.\n\n    * ##### Results:\n      Trained word embeddings on the entire corpus of legislators’ tweets. The word2vec dictionaries are limited to the 100 most similar words to the seed words and overly general or irrelevant terms are omitted. \n      The detailed results provided in the appendix is summarised in the below table:\n  \n  | Dataset | Issue | Classification Method | F1-score | Recall | Precision | Accuracy | Balanced Accuracy|\n  |---------|-------|-----------------------|----------|--------|-----------|----------|------------------|\n  | Crawled Legislators' Tweets | Immigration (Exclusive or Not) | Naive Bayes | 0.885 | 0.853 | 0.921 | 0.813 | 0.738\n  | | | XGBoost | 0.871 | 0.909 | 0.836 | 0.795 | 0.668\n  | | | <b> Elastic Net </b> | <b> 0.881 </b> | <b> 0.967 </b> | <b> 0.809 </b> | <b> 0.801 </b> | <b> 0.615 </b>\n  | | | Lasso | 0.871 | 0.962 | 0.797 | 0.784 | 0.586\n  | | Immigration (Inclusive or Not) | Naive Bayes | 0.892 | 0.865 | 0.920 | 0.830 | 0.781\n  | | | XGBoost | 0.888 | 0.916 | 0.861 | 0.828 | 0.746\n  | | | <b> Elastic Net </b> | <b> 0.890 </b> | <b> 0.978 </b> | <b> 0.817 </b> | <b> 0.821 </b> | <b> 0.674 </b>\n  | | | Lasso | 0.894 | 0.974 | 0.826 | 0.828 | 0.691\n  | | Climent Change (No Action or Not) | Naive Bayes | 0.889 | 0.874 | 0.904 | 0.827 | 0.742\n  | | | XGBoost | 0.888 | 0.896 | 0.880 | 0.818 | 0.698\n  | | | Elastic Net | 0.891 | 0.963 | 0.830 | 0.811 | 0.575\n  | | | <b> Lasso </b> | <b> 0.892 </b> | <b> 0.965 </b> | <b> 0.830 </b> | <b> 0.813 </b> | <b> 0.576 </b>\n  | | Climent Change (Take Action or Not) | Naive Bayes | 0.687 | 0.742 | 0.640 | 0.758 | 0.746\n  | | | XGBoost | 0.678 | 0.694 | 0.662 | 0.736 | 0.729\n  | | | <b> Elastic Net </b> | <b> 0.706 </b> | <b> 0.764 </b> | <b> 0.655 </b> | <b> 0.745 </b> | <b> 0.748 </b>\n  | | | Lasso | 0.700 | 0.764 | 0.646 | 0.738 | 0.742\n\n## Implementation details: <a name=\"tpa_imp\"></a>\n![mermaid_kroki)](https://kroki.io/mermaid/svg/eNp1kcFOwzAMhu97Ch_hkMt244BE127rkHZg02CbOHiJ20aEpiQpEqK8O10apg5KTnb-z85vJzdYFbCJR9Ceu0OGNxkyrmR11GgEU9I6mGpT1fYZGLttHrUR4y3xBqKrABfEX5h9q9EQnGRIXo8khCzza981OhXCfvzD6xySkmtB5kKf_KfvJx7YfZ51C1OF1spMcnRSl1-emw-7j9GhJeftQ7OulHQNLH6zsDEoS1i3YNfsAk__4tS2PtOLMMLIZ7tTFh8G1vM0j7S2ochjyRCWtNM5yVfUJ2dD5ArlO0X4QbYjY29kGVZlCQ0vWKVqC1tUUvS2lXSkj2e9OA2_1c2flhmZJkhLf3cffAQHD2Rr5drnvwEH6rEj)\n\n\n## Reproducing Results for XGB <a name=\"tpa_repr\"></a>\n\n  | Dataset | Issue | Classification Method | F1-score | Recall | Precision | Accuracy | Balanced Accuracy|\n  |---------|-------|-----------------------|----------|--------|-----------|----------|------------------|\n  | Crawled Persian Tweets | JCPOA (Relevant or Not) | Naive Bayes | 0.845 | 0.901 | 0.792 | 0.843 | 0.839\n  | | | XGBoost     | 0.999 | 0.999 | 0.999 | 0.999 | 0.999\n  | | | Passive Aggressive | 0.991 | 0.983 | 0.994 | 0.992 | 0.991\n  | | | Lasso       | 0.988 | 0.985 | 0.983 | 0.984 | 0.987\n  | | Stock Market (Relevant or Not) | Naive Bayes | 0.892 | 0.865 | 0.920 | 0.830 | 0.781\n  | | | XGBoost     | 0.999 | 0.999 | 1.000 | 0.999 | 0.999\n  | | | Elastic Net | 0.890 | 0.978 | 0.817 | 0.821 | 0.674\n  | | | Lasso       | 0.894 | 0.974 | 0.826 | 0.828 | 0.691\n  | | Vaccination (Relevant or Not) | Naive Bayes | 0.870 | 0.92 | 0.82 | 0.855 | 0.883\n  | | | XGBoost     | 1.000 | 1.000 | 1.000 | 1.000 | 1.000\n  | | | Passive Aggressive | 0.975 | 0.945 | 0.965 | 0.97 | 0.95\n  | | | Lasso       | 0.971 | 0.955 | 0.973 | 0.970 | 0.959\n  | | Filtering (Relevant or Not) | Naive Bayes | 0.687 | 0.742 | 0.640 | 0.758 | 0.746\n  | | | XGBoost     | 0.950 | 0.951 | 0.958 | 0.954 | 0.950\n  | | | Elastic Net | 0.706 | 0.764 | 0.655 | 0.745 | 0.748\n  | | | Lasso       | 0.700 | 0.764 | 0.646 | 0.738 | 0.742\n\n\n\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/MohammadForouhesh/tracking-policy-agendas",
    "keywords": "NLP,Computational Social Science,Agenda Setting",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "tracking-policy-agendas",
    "package_url": "https://pypi.org/project/tracking-policy-agendas/",
    "platform": null,
    "project_url": "https://pypi.org/project/tracking-policy-agendas/",
    "project_urls": {
      "Homepage": "https://github.com/MohammadForouhesh/tracking-policy-agendas"
    },
    "release_url": "https://pypi.org/project/tracking-policy-agendas/1.0.0/",
    "requires_dist": [
      "pandas (>=1.3.5)",
      "tqdm (>=4.62.3)",
      "gensim (>=4.1.2)",
      "numpy (>=1.21.5)",
      "scikit-learn (>=1.0.2)",
      "matplotlib (>=3.5.1)",
      "xgboost (>=1.5.0)",
      "pytest (>=6.2.5)",
      "coverage (>=6.2)",
      "requests (>=2.26.0)"
    ],
    "requires_python": ">=3.8",
    "summary": "A Persian Twitter policy agenda tracking framework",
    "version": "1.0.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 13168429,
  "releases": {
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "baed289c9b48387f261fce5146f4e734d739577882dec6ac0f139286f6fbcb71",
          "md5": "f81cdf58c88d51b69e84cc0d2d4fb5fa",
          "sha256": "ae3e58eb0e2aa3250dfa3517c0c47dfe1be1b4451cc604fc8080b036c43d3b6e"
        },
        "downloads": -1,
        "filename": "tracking_policy_agendas-1.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f81cdf58c88d51b69e84cc0d2d4fb5fa",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 15015,
        "upload_time": "2022-03-14T10:30:48",
        "upload_time_iso_8601": "2022-03-14T10:30:48.113597Z",
        "url": "https://files.pythonhosted.org/packages/ba/ed/289c9b48387f261fce5146f4e734d739577882dec6ac0f139286f6fbcb71/tracking_policy_agendas-1.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9969aaa8d69e76e7a10b25b1f51ceb7662c8670bfbd0de2987a7b7a8fd5df74e",
          "md5": "19269ece39adea2ae5888599b1d0258c",
          "sha256": "b1df183d94c998c6b9223e4f02fe846e65e3871b59ca35a9688a123899570788"
        },
        "downloads": -1,
        "filename": "tracking_policy_agendas-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "19269ece39adea2ae5888599b1d0258c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 16862,
        "upload_time": "2022-03-14T10:30:49",
        "upload_time_iso_8601": "2022-03-14T10:30:49.783075Z",
        "url": "https://files.pythonhosted.org/packages/99/69/aaa8d69e76e7a10b25b1f51ceb7662c8670bfbd0de2987a7b7a8fd5df74e/tracking_policy_agendas-1.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "baed289c9b48387f261fce5146f4e734d739577882dec6ac0f139286f6fbcb71",
        "md5": "f81cdf58c88d51b69e84cc0d2d4fb5fa",
        "sha256": "ae3e58eb0e2aa3250dfa3517c0c47dfe1be1b4451cc604fc8080b036c43d3b6e"
      },
      "downloads": -1,
      "filename": "tracking_policy_agendas-1.0.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "f81cdf58c88d51b69e84cc0d2d4fb5fa",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.8",
      "size": 15015,
      "upload_time": "2022-03-14T10:30:48",
      "upload_time_iso_8601": "2022-03-14T10:30:48.113597Z",
      "url": "https://files.pythonhosted.org/packages/ba/ed/289c9b48387f261fce5146f4e734d739577882dec6ac0f139286f6fbcb71/tracking_policy_agendas-1.0.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "9969aaa8d69e76e7a10b25b1f51ceb7662c8670bfbd0de2987a7b7a8fd5df74e",
        "md5": "19269ece39adea2ae5888599b1d0258c",
        "sha256": "b1df183d94c998c6b9223e4f02fe846e65e3871b59ca35a9688a123899570788"
      },
      "downloads": -1,
      "filename": "tracking_policy_agendas-1.0.0.tar.gz",
      "has_sig": false,
      "md5_digest": "19269ece39adea2ae5888599b1d0258c",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.8",
      "size": 16862,
      "upload_time": "2022-03-14T10:30:49",
      "upload_time_iso_8601": "2022-03-14T10:30:49.783075Z",
      "url": "https://files.pythonhosted.org/packages/99/69/aaa8d69e76e7a10b25b1f51ceb7662c8670bfbd0de2987a7b7a8fd5df74e/tracking_policy_agendas-1.0.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}