{
  "info": {
    "author": "XuMing",
    "author_email": "xuming624@qq.com",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Developers",
      "Natural Language :: Chinese (Simplified)",
      "Natural Language :: Chinese (Traditional)",
      "Operating System :: OS Independent",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Topic :: Scientific/Engineering :: Artificial Intelligence",
      "Topic :: Text Processing :: Linguistic"
    ],
    "description": "# pke_zh\n[![PyPI version](https://badge.fury.io/py/pke_zh.svg)](https://badge.fury.io/py/pke_zh)\n[![Contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg)](CONTRIBUTING.md)\n[![GitHub contributors](https://img.shields.io/github/contributors/shibing624/pke_zh.svg)](https://github.com/shibing624/pke_zh/graphs/contributors)\n[![License Apache 2.0](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](LICENSE)\n[![python_vesion](https://img.shields.io/badge/Python-3.5%2B-green.svg)](requirements.txt)\n[![GitHub issues](https://img.shields.io/github/issues/shibing624/pke_zh.svg)](https://github.com/shibing624/pke_zh/issues)\n[![Wechat Group](http://vlog.sfyc.ltd/wechat_everyday/wxgroup_logo.png?imageView2/0/w/60/h/20)](#Contact)\n\nPKE_zh, Python Keyphrase Extraction for ZH(chinese).\n\n**pke_zh**实现了多种中文关键词提取算法，包括有监督的WordRank、无监督的TextRank, TfIdf, KeyBert, PositionRank, TopicRank等，扩展性强，开箱即用。\n\n\n**Guide**\n\n- [Feature](#Feature)\n- [Install](#install)\n- [Usage](#usage)\n- [Contact](#Contact)\n- [Reference](#reference)\n\n# Feature\n\n如何提取query或者文档的关键词？\n\n\n### 有监督方法\n#### 特征工程的解决思路\n1. 实现时采用模型打分方法，以搜索query为原始语料，人工标注句子中各词重要度\n\n> 重要度共分4级：\n> * Super important：主要包括POI核心词，比如“方特、欢乐谷”\n> * Required：包括行政区词、品类词等，比如“北京 温泉”中“北京”和“温泉”都很重要\n> * Important：包括品类词、门票等，比如“顺景 温泉”中“温泉”相对没有那么重要，用户搜“顺景”大部分都是温泉的需求\n> * Unimportant：包括语气词、代词、泛需求词、停用词等\n\n上例中可见“温泉”在不同的query中重要度是不同的。\n\n**特征方法**\n\n* 文本特征：包括Query长度、Term长度，Term在Query中的偏移量，term词性、长度信息、term数目、位置信息、句法依存tag、是否数字、是否英文、是否停用词、是否专名实体、是否重要行业词、embedding模长、删词差异度、以及短语生成树得到term权重等\n* 统计特征：包括PMI、IDF、textrank值、前后词互信息、左右邻熵、独立检索占比（term单独作为query的qv/所有包含term的query的qv和）、统计概率、idf变种iqf\n* 语言模型特征：整个query的语言模型概率 / 去掉该Term后的Query的语言模型概率\n\n2. 模型方面采用树模型（XGBoost等）进行训练，得到权重分类模型后在线上预测\n![term-weighting](./docs/gbdt.png)\n\n#### 深度模型的解决思路\n* 利用深度学习模型来学习term重要性，比如通过训练基于BiLSTM+Attention的query意图分类模型\n* 基于Seq2Seq/Transformer训练的query翻译改写模型得到的attention权重副产物再结合其他策略或作为上述分类回归模型的特征也可以用于衡量term的重要性\n* 利用BERT模型训练端到端的词分级模型，类似序列标注模型，后接CRF判定词重要性权重输出\n\n\n**深度模型**\n\n* BERT CLS + softmax \n* Seq2Seq 文本摘要模型\n\n### 无监督方法\n- [x] TextRank\n- [x] TfIdf\n- [x] SingleRank\n- [x] PositionRank\n- [x] TopicRank\n- [x] MultipartiteRank\n- [x] Yake\n- [x] KeyBert\n\n\n\n# Install\n* From pip:\n```shell\npip3 install -U pke_zh\n```\n* From source：\n```shell\ngit clone https://github.com/shibing624/pke_zh.git\ncd pke_zh\npython3 setup.py install\n```\n\n### 依赖数据\n* 千兆中文文本训练的语言模型[zh_giga.no_cna_cmn.prune01244.klm(2.8G)](https://deepspeech.bj.bcebos.com/zh_lm/zh_giga.no_cna_cmn.prune01244.klm)，模型由pycorrector库自动下载于：~/.pycorrector/datasets/zh_giga.no_cna_cmn.prune01244.klm 。\n* 中文文本匹配模型[shibing624/text2vec-base-chinese](https://huggingface.co/shibing624/text2vec-base-chinese) ，模型由transformers库自动下载于：~/.cache/huggingface/transformers/ 下。\n\n# Usage\n\n## 有监督关键词提取\n\n直接调用训练好的WordRank模型，模型自动下载本地`~/.cache/pke_zh/wordrank_model.pkl`\n\nexample: [examples/keyphrase_extraction_demo.py](examples/keyphrase_extraction_demo.py)\n\n```python\nfrom pke_zh.supervised.wordrank import WordRank\nm = WordRank()\nprint(m.extract(\"哪里下载电视剧周恩来？\"))\n```\n\noutput:\n```shell\n[('电视剧', 3), ('周恩来', 3), ('下载', 2), ('哪里', 1), ('？', 0)]\n```\n> 3：核心词；2：限定词；1：可省略词；0：干扰词。\n\n### 基于自有数据训练模型\n\n训练example: [examples/train_supervised_wordrank_demo.py](examples/train_supervised_wordrank_demo.py)\n\n\n## 无监督关键词提取\n支持TextRank、TfIdf、KeyBert等关键词提取算法。\n\nexample: [examples/unsupervised_demo.py](examples/unsupervised_demo.py)\n\n\n```python\nfrom pke_zh.unsupervised.textrank import TextRank\nfrom pke_zh.unsupervised.tfidf import TfIdf\nfrom pke_zh.unsupervised.singlerank import SingleRank\nfrom pke_zh.unsupervised.positionrank import PositionRank\nfrom pke_zh.unsupervised.topicrank import TopicRank\nfrom pke_zh.unsupervised.multipartiterank import MultipartiteRank\nfrom pke_zh.unsupervised.yake import Yake\nfrom pke_zh.unsupervised.keybert import KeyBert\n\nq = '哪里下载电视剧周恩来？'\nTextRank_m = TextRank()\nTfIdf_m = TfIdf()\nPositionRank_m = PositionRank()\nKeyBert_m = KeyBert()\n\nr = TextRank_m.extract(q)\nprint('TextRank:', r)\n\nr = TfIdf_m.extract(q)\nprint('TfIdf:', r)\n\nr = PositionRank_m.extract(q)\nprint('PositionRank_m:', r)\n\nr = KeyBert_m.extract(q)\nprint('KeyBert_m:', r)\n```\n\noutput:\n```shell\nTextRank: [('电视剧', 1.00000002)]\nTfIdf: [('哪里下载', 1.328307500322222), ('下载电视剧', 1.328307500322222), ('电视剧周恩来', 1.328307500322222)]\nPositionRank_m: [('电视剧', 1.0)]\nKeyBert_m: [('电视剧', 0.47165293)]\n```\n\n\n# Contact\n\n- Issue(建议)：[![GitHub issues](https://img.shields.io/github/issues/shibing624/pke_zh.svg)](https://github.com/shibing624/pke_zh/issues)\n- 邮件我：xuming: xuming624@qq.com\n- 微信我：加我*微信号：xuming624*, 备注：*姓名-公司名-NLP* 进NLP交流群。\n\n<img src=\"docs/wechat.jpeg\" width=\"200\" />\n\n\n# Citation\n\n如果你在研究中使用了pke_zh，请按如下格式引用：\nAPA:\n```latex\nXu, M. pke_zh: Python keyphrase extraction toolkit for chinese (Version 0.2.2) [Computer software]. https://github.com/shibing624/pke_zh\n```\n\nBibTeX:\n```latex\n@misc{pke_zh,\n  author = {Xu, Ming},\n  title = {pke_zh: Python keyphrase extraction toolkit for chinese},\n  year = {2023},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {\\url{https://github.com/shibing624/pke_zh}},\n}\n```\n\n# License\n\n\n授权协议为 [The Apache License 2.0](LICENSE)，可免费用做商业用途。请在产品说明中附加pke_zh的链接和授权协议。\n\n\n# Contribute\n项目代码还很粗糙，如果大家对代码有所改进，欢迎提交回本项目，在提交之前，注意以下两点：\n\n - 在`tests`添加相应的单元测试\n - 使用`python -m pytest`来运行所有单元测试，确保所有单测都是通过的\n\n之后即可提交PR。\n\n\n# Reference\n\n- [boudinfl/pke](https://github.com/boudinfl/pke)\n- [Context-Aware Document Term Weighting for Ad-Hoc Search](http://www.cs.cmu.edu/~zhuyund/papers/TheWebConf_2020_Dai.pdf)\n- [term weighting](https://zhuanlan.zhihu.com/p/90957854)\n- [DeepCT](https://github.com/AdeDZY/DeepCT)",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/shibing624/pke_zh",
    "keywords": "pke_zh,term weighting,textrank,word rank,wordweight",
    "license": "Apache 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "pke-zh",
    "package_url": "https://pypi.org/project/pke-zh/",
    "platform": "Windows",
    "project_url": "https://pypi.org/project/pke-zh/",
    "project_urls": {
      "Homepage": "https://github.com/shibing624/pke_zh"
    },
    "release_url": "https://pypi.org/project/pke-zh/0.2.3/",
    "requires_dist": null,
    "requires_python": ">=3.5",
    "summary": "pke_zh, context-aware bag-of-words term weights for query and document.",
    "version": "0.2.3",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16650936,
  "releases": {
    "0.2.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0cd44ee9349c2675af946cc0b0e958926deaabdb7fec2e4e0d31cd7577989c93",
          "md5": "4773d4248bf8696e5d9c26c653b19206",
          "sha256": "04b7ec5dc81e865b9c31584f3db38da9fc502dc49e9395cfa24dedac489e920d"
        },
        "downloads": -1,
        "filename": "pke_zh-0.2.2.tar.gz",
        "has_sig": false,
        "md5_digest": "4773d4248bf8696e5d9c26c653b19206",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 5572948,
        "upload_time": "2023-02-01T12:17:59",
        "upload_time_iso_8601": "2023-02-01T12:17:59.272748Z",
        "url": "https://files.pythonhosted.org/packages/0c/d4/4ee9349c2675af946cc0b0e958926deaabdb7fec2e4e0d31cd7577989c93/pke_zh-0.2.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9f9dae6d79acdf3ad3cc2c4894b7781bea4130dd981a209e8af28bbd7664695e",
          "md5": "4beecb452ac5b8f05fd02a1f04b5fae6",
          "sha256": "747ff0781874a94c2b56c14b9bbe7d27114d342747913c7f1ddb0574d510f23b"
        },
        "downloads": -1,
        "filename": "pke_zh-0.2.3.tar.gz",
        "has_sig": false,
        "md5_digest": "4beecb452ac5b8f05fd02a1f04b5fae6",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 5571993,
        "upload_time": "2023-02-01T13:31:15",
        "upload_time_iso_8601": "2023-02-01T13:31:15.041325Z",
        "url": "https://files.pythonhosted.org/packages/9f/9d/ae6d79acdf3ad3cc2c4894b7781bea4130dd981a209e8af28bbd7664695e/pke_zh-0.2.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "9f9dae6d79acdf3ad3cc2c4894b7781bea4130dd981a209e8af28bbd7664695e",
        "md5": "4beecb452ac5b8f05fd02a1f04b5fae6",
        "sha256": "747ff0781874a94c2b56c14b9bbe7d27114d342747913c7f1ddb0574d510f23b"
      },
      "downloads": -1,
      "filename": "pke_zh-0.2.3.tar.gz",
      "has_sig": false,
      "md5_digest": "4beecb452ac5b8f05fd02a1f04b5fae6",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.5",
      "size": 5571993,
      "upload_time": "2023-02-01T13:31:15",
      "upload_time_iso_8601": "2023-02-01T13:31:15.041325Z",
      "url": "https://files.pythonhosted.org/packages/9f/9d/ae6d79acdf3ad3cc2c4894b7781bea4130dd981a209e8af28bbd7664695e/pke_zh-0.2.3.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}