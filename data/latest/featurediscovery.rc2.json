{
  "info": {
    "author": "Frederik Schadd",
    "author_email": "featurediscovery@outlook.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Environment :: GPU :: NVIDIA CUDA :: 11.5",
      "Intended Audience :: Developers",
      "Intended Audience :: Information Technology",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: GNU Lesser General Public License v2 or later (LGPLv2+)",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.9",
      "Topic :: Scientific/Engineering :: Artificial Intelligence",
      "Topic :: Scientific/Engineering :: Mathematics"
    ],
    "description": "# Feature Discovery\n\nFeature Discovery is a machine learning library which aims to make it easier to find non-linear representations of \nyour data that are beneficial for a specific classification task. Instead of manually having to look at a mountain of \nscree plots whilst trying to figure out how to engineer your feature space, Feature Discovery does the gruntwork for you \nand tries to come up with a list of promising transformations of the input features for you to look into\nin more detail.   \n\n# Why?\n\nFeature engineering is a rather laborious task that needs a lot of domain knowledge and trial&error before you can find\nquality transformations for a given ML task. Many online tutorials will tell you simply to \"look at the data\" in order\nto realize what the perfect transformation is (or kernel if you're intending to use a SVM). \nProblem is, they do so with a dataset that only has 2 features. What if your dataset has 50 features? \nThat's 50*49/2 = 1225 different scree plots to look at! Ain't nobody got time for that! Now what if we had some kind\nof tool what would look through your dataset and come up with a prioritized list of promising feature-pairs to look at?\nThis is exactly what Feature Discovery aims to provide. With just a few lines of code, you can have all the features\nof your dataset checked against common (kernel) transformations and get a quick overview as to where to engineer better\nfeatures from first. You provide the data, a list of features to look into and kernels\nto try, and Feature Discovery tries them all and compiles its findings into easily digestible plots or rankings. \n\n# Background\n\nA commonly known method for building machine learning models is the kernel method. The idea is to take a data set that\nisn't linearly separable and make it separable by transforming the data into a higher dimensional space that is.\n\n<div align=\"center\"><img src=\"https://github.com/Ddasch/Feature_Discovery/blob/develop/docs/images/2-Figure1-1.png?raw=true \" width=\"500\"/></div>\n\nBy using a feature map &phi;(x) you can transform your data into a space that is easier for a machine learning model to \ntackle. Now a Support Vector Machine would train a linear model using &phi;(x) and call it a day[^1]. However, if applying\n&phi; is beneficial for linear models, it must be beneficial for other models as well and therefore be a good indicator\nof the hidden potential of a feature. \n\n\n## Currently Supported Kernels\n### Monovariate\n- Quadratic\n- Sigmoid\n- Logarithmic (shifted & cropped)\n### Duovariate\n- Difference\n- Magnitude\n- Polynomial (second and third order)\n- Random Fourier Functions\n- Gaussian (RFF approximation)\n \n# Installation\nThis library minimally requires \n- pandas>=1.00\n- scipy>=1.7.0\n- scikit-learn>=1.0.0\n- matplotlib>=3.0.0\n- cupy-cuda115>=9.6.0\n\nIt is recommended to install cupy via conda beforehand. Afterwards you can install it via `pip` using:\n    \n    pip install featurediscovery\n\n# How to use\n\n```py\n>>> from featurediscovery import kernel_search\n>>> df =  <your pandas dataframe>\n# specify the columns in df that are your feature space\n>>> feature_space = ['x0', 'x1', 'x2', 'x3', 'x4', 'x5']\n# speficy which column in df is your target variable\n>>> target_variable = 'y'\n>>> kernel_search.evaluate_kernels(df\n                     , target_variable='y'\n                     , feature_space=feature_space\n                     , monovariate_kernels=['quadratic', 'log']\n                     , duovariate_kernels=['poly3', 'rff_gauss']\n                     , feature_standardizers=['raw']\n                     , plot_feature_ranking=True\n                     , plot_ranking_all_transformations=True\n                     , eval_method='normal'\n                     )\n```\n\nWith the two plot parameters enabled two feature priority lists will be generated, a full list of every combination that\nwas evaluated (which can be too much to plot depending on the amount of features/combinations), and a feature ranking\nwhich shows per feature only the best kernel transformation that was found. The red vertical line is the prior class probability,\nmeaning a kernel is only beneficial if the model can improve upon this class probability. \n\n<div align=\"center\"><img src=\"https://github.com/Ddasch/Feature_Discovery/blob/develop/docs/images/demo1_concat.png?raw=true \" width=\"700\"/></div>\n\n##### Optional parameters\n\n| Parameter | Allowed Values | Function |\n|-----------|----------------|----------|\n|plot_feature_ranking|bool: True/False|Plot the feature ranking to screen using the best kernel per feature|\n|plot_ranking_all_transformations|bool: True/False|Plot the ranking of every tried kernel to screen|\n|plot_individual_kernels|bool: True/False|Plot the result of individual kernels to screen|\n|kernel_plot_mode|str: 'scree', 'tsne'|Indicate whether the individual kernels results should be displayed as a (series of) scree plots or as a TSNE plot|\n|export_ranking|bool: True/False|Export the ranking to file. Useful for larger jobs.|\n|export_individual_kernel_plots|bool: True/False|Export the individual kernel plots to files. Useful for larger jobs.|\n|export_folder|str|Path indicating where to store rankings/plots|\n|export_formats|list[str]: ['png', 'csv', 'json']| List of one or more export formats for the kernel rankings. If png is selected, then plots will automatically be generated (so no need to set the plot parameter to true)|\n|eval_method|str: 'naive', 'normal', 'full'| How the quality of the kernel should be evaluated. See below for explanation|\n|use_cupy|str: 'yes', 'no', 'auto'|Indicate whether or not to use GPU acceleration. GPU acceleration is faster when analyzing larger datasets|\n--------\n\n##### Evaluation methods\nThree approaches how the linear separability of the generated kernel features should be evaluated, as specified by the 'eval_method' parameter.\nThese are\n- naive: Only generated features are measured for separability. Kernel input features and other raw features are ignored.\n- normal: Generated features together with kernel input featues are measured for separability. Other aw features are ignored.\n- full: Generated features together with kernel input featues and other raw features are measured for separability.\nQuality metric here changes to how much the added features improve upon the separability already present in the original dataset.\n\n# GPU Acceleration \n\nRunning an extensive analysis can be slow when dealing with larger datasets. One way to deal with this is by just enabling the export functions, running the search overnight\nand looking at the results the next day. But what if you want things to run faster, for instance by running it on the GPU?\nWell you can! The entire framework is optionally GPU accelerated thanks to <a href=\"https://github.com/cupy/cupy\">CuPy</a>. \n\n<div align=\"center\"><img src=\"https://raw.githubusercontent.com/cupy/cupy/master/docs/image/cupy_logo_1000px.png\" width=\"200\"/></div>\n\nFor this to work you need to have a CUDA capable GPU in your machine and the CUDA <a href=\"https://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/index.html\">toolkit installed.</a>\nInstalling Feature Discorvery should also install CuPy as a requirement. Then, all you need to do is set the 'use_cupy' parameter to \"yes\" when running the search.\n\nAn important factor to note is that this feature isn't universally faster. Preliminary benchmarks have shown that the sample size of the dataset\nis the biggest determinant w.r.t choosing GPU over CPU. Based on a simple benchmark on a synthetic dataset I would recommend to only\nenable this feature once your dataset has at least 100k samples. \n\n\n<div align=\"center\"><img src=\"https://github.com/Ddasch/Feature_Discovery/blob/develop/docs/images/runtime_sample_scaling.png?raw=true \" width=\"400\"/></div>\n\n\n[^1]: Some kernels like RBF don't do this explicitly and compute the instance similarities differently. For these an\nexplicit mapping can only be approximated.\n\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/Ddasch/Feature_Discovery",
    "keywords": "",
    "license": "LGPL v2.1",
    "maintainer": "",
    "maintainer_email": "",
    "name": "featurediscovery",
    "package_url": "https://pypi.org/project/featurediscovery/",
    "platform": "",
    "project_url": "https://pypi.org/project/featurediscovery/",
    "project_urls": {
      "Homepage": "https://github.com/Ddasch/Feature_Discovery"
    },
    "release_url": "https://pypi.org/project/featurediscovery/0.1.1/",
    "requires_dist": [
      "pandas (>=1.0.0)",
      "scikit-learn (>=1.0.0)",
      "cupy-cuda115 (>=9.6.0)",
      "matplotlib (>=3.0.0)",
      "scipy (>=1.7.0)"
    ],
    "requires_python": "",
    "summary": "Discover hidden predictive qualities of features in your dataset by testing them for linear separability after applying different kernel transformations.",
    "version": "0.1.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12584095,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "38f0d52ce6282a0bcdb63e2ab661e67c9007b0d34974d28452f33fd9beb401d5",
          "md5": "a2902e70f77ebccaa8a7e315090c4f9b",
          "sha256": "7b64de30459bb28303e54701f8d4f16441657e652f0a6c51c28b7c5945f04fbc"
        },
        "downloads": -1,
        "filename": "featurediscovery-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "a2902e70f77ebccaa8a7e315090c4f9b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 53572,
        "upload_time": "2022-01-15T18:27:56",
        "upload_time_iso_8601": "2022-01-15T18:27:56.934358Z",
        "url": "https://files.pythonhosted.org/packages/38/f0/d52ce6282a0bcdb63e2ab661e67c9007b0d34974d28452f33fd9beb401d5/featurediscovery-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1b294e388da5f87c7a9f83ae86e4c4abc8cf14c764c8a625c9840025593ada30",
          "md5": "f011ef25525de9638f43dac212755fe5",
          "sha256": "b7b81a1df9848dc87366378443e079d408d205f2c4ab8bb4e95b692cc98204de"
        },
        "downloads": -1,
        "filename": "featurediscovery-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "f011ef25525de9638f43dac212755fe5",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 41323,
        "upload_time": "2022-01-15T18:27:58",
        "upload_time_iso_8601": "2022-01-15T18:27:58.802496Z",
        "url": "https://files.pythonhosted.org/packages/1b/29/4e388da5f87c7a9f83ae86e4c4abc8cf14c764c8a625c9840025593ada30/featurediscovery-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1e7d9ce7ecd0c824f2c42a66ea3b20e9b65a3ee3864b82d42f94c9bb2aab4493",
          "md5": "0b7e311a0a30c03eb5da95cf0ceb4f4d",
          "sha256": "2b620c9b9da775ff30102711f9c80053d4704187f99c2782aea87bca515778f9"
        },
        "downloads": -1,
        "filename": "featurediscovery-0.1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0b7e311a0a30c03eb5da95cf0ceb4f4d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 53675,
        "upload_time": "2022-01-15T18:29:43",
        "upload_time_iso_8601": "2022-01-15T18:29:43.682048Z",
        "url": "https://files.pythonhosted.org/packages/1e/7d/9ce7ecd0c824f2c42a66ea3b20e9b65a3ee3864b82d42f94c9bb2aab4493/featurediscovery-0.1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d62cb111ad08f96ee881f43c9001bc524186ac052b6ad206d2bdb6fd2d05106c",
          "md5": "f2aff9531cc6e7e8bfa7e90c3940815c",
          "sha256": "9e65ca910fdb3e22d9fc0f6655fa441449d7255e1361ed711937b3459d7ff2ae"
        },
        "downloads": -1,
        "filename": "featurediscovery-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "f2aff9531cc6e7e8bfa7e90c3940815c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 41583,
        "upload_time": "2022-01-15T18:29:45",
        "upload_time_iso_8601": "2022-01-15T18:29:45.435476Z",
        "url": "https://files.pythonhosted.org/packages/d6/2c/b111ad08f96ee881f43c9001bc524186ac052b6ad206d2bdb6fd2d05106c/featurediscovery-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "1e7d9ce7ecd0c824f2c42a66ea3b20e9b65a3ee3864b82d42f94c9bb2aab4493",
        "md5": "0b7e311a0a30c03eb5da95cf0ceb4f4d",
        "sha256": "2b620c9b9da775ff30102711f9c80053d4704187f99c2782aea87bca515778f9"
      },
      "downloads": -1,
      "filename": "featurediscovery-0.1.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "0b7e311a0a30c03eb5da95cf0ceb4f4d",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 53675,
      "upload_time": "2022-01-15T18:29:43",
      "upload_time_iso_8601": "2022-01-15T18:29:43.682048Z",
      "url": "https://files.pythonhosted.org/packages/1e/7d/9ce7ecd0c824f2c42a66ea3b20e9b65a3ee3864b82d42f94c9bb2aab4493/featurediscovery-0.1.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "d62cb111ad08f96ee881f43c9001bc524186ac052b6ad206d2bdb6fd2d05106c",
        "md5": "f2aff9531cc6e7e8bfa7e90c3940815c",
        "sha256": "9e65ca910fdb3e22d9fc0f6655fa441449d7255e1361ed711937b3459d7ff2ae"
      },
      "downloads": -1,
      "filename": "featurediscovery-0.1.1.tar.gz",
      "has_sig": false,
      "md5_digest": "f2aff9531cc6e7e8bfa7e90c3940815c",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 41583,
      "upload_time": "2022-01-15T18:29:45",
      "upload_time_iso_8601": "2022-01-15T18:29:45.435476Z",
      "url": "https://files.pythonhosted.org/packages/d6/2c/b111ad08f96ee881f43c9001bc524186ac052b6ad206d2bdb6fd2d05106c/featurediscovery-0.1.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}