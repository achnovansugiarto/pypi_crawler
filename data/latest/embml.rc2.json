{
  "info": {
    "author": "Lucas Tsutsui da Silva",
    "author_email": "lucastsui@hotmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: GNU General Public License v3 (GPLv3)",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 2.7",
      "Programming Language :: Python :: 3.7"
    ],
    "description": "# EmbML\n\nEmbML is a tool written in Python to automatically convert off-board-trained models into C++ (default option) or C source code files that can be compiled and executed in low-power microcontrollers. The main goal of EmbML is to produce classifier source codes that will run specifically in resource-constrained hardware systems, using bare metal programming.\n\nThis tool takes as input a classification model that was trained in a desktop or server computer using WEKA or scikit-learn libraries. EmbML is responsible for converting the input model into a carefully crafted code in C or C++ with support for embedded hardware, such as the avoidance of unnecessary use of SRAM memory and implementation of fixed-point operations for non-integer numbers. \n\n## Input Models\n\nEmbML accepts a trained model through the file that contains its serialized object. For instance, a classification model, built with WEKA, shall be serialized into a file using the _ObjectOutputStream_ and _FileOutputStream_ classes (available in Java). [Example of saving a WEKA model using its GUI.](https://machinelearningmastery.com/save-machine-learning-model-make-predictions-weka/).\n\nAs for the scikit-learn models, they shall be serialized using the _dump_ function, from _pickle_ module. An example is provided in <https://scikit-learn.org/stable/modules/model_persistence.html>.\n\n## Supported Classification Models\n\n`embml` supports off-board-trained classifiers from the following classes:\n\n* From WEKA:\n\t* _MultilayerPerceptron_ for MLP classifiers;\n\t* _Logistic_ for logistic regression classifiers;\n\t* _SMO_ for SVM classifiers -- with linear, polynomial, and RBF kernels;\n\t* _J48_ for decision tree classifier.\n* From scikit-learn:\n\t* _MLPClassifier_ for MLP classifiers;\n\t* _LogisticRegression_ for logistic regression classifiers;\n\t* _LinearSVC_ for SVM classifiers with linear kernel;\n\t* _SVC_ for SVM classifiers -- with polynomial and RBF kernels;\n\t* _DecisionTreeClassifier_ for decision tree models.\n\n## Installation\n\nYou can install `embml` from [PyPi](https://pypi.org/project/embml/):\n\n```python\npip install embml\n```\n\nThis tool is supported on Python 2.7 and Python 3.7 versions, and depends on the `javaobj` library (<https://pypi.org/project/javaobj-py3/>).\n\n## How To Use\n\n```python\nimport embml\n\n# For scikit-learn models\nembml.sklearnModel(inputModel, outputFile, opts)\n\n# For WEKA models\nembml.wekaModel(inputModel, outputFile, opts)\n\t\t\n# opts can include:\n#\t-rules: to generate a decision tree classifier code using a representation with if-then-else statements.\n#\t-fxp <n> <m>: to generate a classifier code that uses fixed-point format to perform real number operations. In this case, <n> is the number of integer bits and <m> is the number of fractional bits in the Qn.m format. Note that n + m + 1 must be equal to 32, 16, or 8, since that one bit is used to represent signed numbers.\n#\t-approx: to generate an MLP classifier code that employs an approximation to substitute the sigmoid as an activation function in the neurons.\n#\t-pwl <x>: to generate an MLP classifier code that employs a piecewise approximation to substitute the sigmoid as an activation function in the neurons. In this case, <x> must be equal to 2 (to use an 2-point PWL approximation) or 4 (to use an 4-point PWL approximation).\n\n# Examples of generating decision tree classifier codes using if-then-else format.\nembml.wekaModel(inputDecisionTreeModel, outputFile, opts='-rules')\nembml.sklearnModel(inputDecisionTreeModel, outputFile, opts='-rules')\n\n# Examples of generating classifier codes in C programming language.\nembml.wekaModel(inputModel, outputFile, opts='-c')\nembml.sklearnModel(inputModel, outputFile, opts='-c')\n\n# Examples of generating classifier codes using fixed-point formats.\nembml.wekaModel(inputModel, outputFile, opts='-fxp 21 10') # Q21.10\nembml.sklearnModel(inputModel, outputFile, opts='-fxp 21 10') # Q21.10\nembml.wekaModel(inputModel, outputFile, opts='-fxp 11 4') # Q11.4\nembml.sklearnModel(inputModel, outputFile, opts='-fxp 11 4') # Q11.4\nembml.wekaModel(inputModel, outputFile, opts='-fxp 5 2') # Q5.2\nembml.sklearnModel(inputModel, outputFile, opts='-fxp 5 2') # Q5.2\n\n# Examples of generating MLP classifier codes using an approximation function.\nembml.wekaModel(inputMlpModel, outputFile, opts='-approx')\nembml.sklearnModel(inputMlpModel, outputFile, opts='-approx')\n\n# Examples of generating MLP classifier codes using PWL approximations.\nembml.wekaModel(inputMlpModel, outputFile, opts='-pwl 2')\nembml.sklearnModel(inputMlpModel, outputFile, opts='-pwl 2')\nembml.wekaModel(inputMlpModel, outputFile, opts='-pwl 4')\nembml.sklearnModel(inputMlpModel, outputFile, opts='-pwl 4')\n\n# It is also possible to combine some options:\t\nembml.wekaModel(inputMlpModel, outputFile, opts='-fxp 21 10 -pwl 2')\nembml.sklearnModel(inputMlpModel, outputFile, opts='-fxp 21 10 -pwl 2')\nembml.wekaModel(inputDecisionTreeModel, outputFile, opts='-fxp 21 10 -rules')\nembml.sklearnModel(inputDecisionTreeModel, outputFile, opts='-fxp 21 10 -rules')\n```\n\n## Fixed-point library\n\nIf you decide to generate a classifier code using a fixed-point format, you need to include the `FixedNum.h` library available at [https://github.com/lucastsutsui/EmbML](https://github.com/lucastsutsui/EmbML).\n\n## Citation\n\nIf you use this tool on a scientific work, we kindly ask you to use the following reference:\n\n```tex\n@inproceedings{da2019embml,\n  title={EmbML Tool: supporting the use of supervised learning algorithms in low-cost embedded systems},\n  author={da Silva, Lucas Tsutsui and Souza, Vinicius MA and Batista, Gustavo EAPA},\n  booktitle={2019 IEEE 31st International Conference on Tools with Artificial Intelligence (ICTAI)},\n  pages={1633--1637},\n  year={2019},\n  organization={IEEE}\n}\n```",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/lucastsutsui/embml",
    "keywords": "weka,scikit-learn,microcontroller,classifier,embedded",
    "license": "GPL3",
    "maintainer": "",
    "maintainer_email": "",
    "name": "embml",
    "package_url": "https://pypi.org/project/embml/",
    "platform": "",
    "project_url": "https://pypi.org/project/embml/",
    "project_urls": {
      "Homepage": "https://github.com/lucastsutsui/embml"
    },
    "release_url": "https://pypi.org/project/embml/0.0.5/",
    "requires_dist": null,
    "requires_python": ">=2.7",
    "summary": "A tool to support using classification models in low-power microcontroller-based hardware",
    "version": "0.0.5",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 11783611,
  "releases": {
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "30048e7b285c78752af29b3be5dd882ccd14f6d0b7abeeb5c0c04ff1b794e405",
          "md5": "2a518e9feed0017abcb6900aab901415",
          "sha256": "56a6573b570e39a20809f836279512503bdd6860b50df2537fa83635df992e81"
        },
        "downloads": -1,
        "filename": "embml-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "2a518e9feed0017abcb6900aab901415",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=2.7",
        "size": 31448,
        "upload_time": "2020-08-24T05:23:25",
        "upload_time_iso_8601": "2020-08-24T05:23:25.608797Z",
        "url": "https://files.pythonhosted.org/packages/30/04/8e7b285c78752af29b3be5dd882ccd14f6d0b7abeeb5c0c04ff1b794e405/embml-0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2946f4d0faccc2090d1ccfc17599bcb2725e938ad751ca41e8467fb72633a6d1",
          "md5": "22704631a4439a56a9140628f4f98fa6",
          "sha256": "676ad206f8f71091d526560c64bde336714938dee4aa7f60306ce096368b369f"
        },
        "downloads": -1,
        "filename": "embml-0.0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "22704631a4439a56a9140628f4f98fa6",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=2.7",
        "size": 33033,
        "upload_time": "2021-10-20T19:01:24",
        "upload_time_iso_8601": "2021-10-20T19:01:24.176904Z",
        "url": "https://files.pythonhosted.org/packages/29/46/f4d0faccc2090d1ccfc17599bcb2725e938ad751ca41e8467fb72633a6d1/embml-0.0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "2946f4d0faccc2090d1ccfc17599bcb2725e938ad751ca41e8467fb72633a6d1",
        "md5": "22704631a4439a56a9140628f4f98fa6",
        "sha256": "676ad206f8f71091d526560c64bde336714938dee4aa7f60306ce096368b369f"
      },
      "downloads": -1,
      "filename": "embml-0.0.5.tar.gz",
      "has_sig": false,
      "md5_digest": "22704631a4439a56a9140628f4f98fa6",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=2.7",
      "size": 33033,
      "upload_time": "2021-10-20T19:01:24",
      "upload_time_iso_8601": "2021-10-20T19:01:24.176904Z",
      "url": "https://files.pythonhosted.org/packages/29/46/f4d0faccc2090d1ccfc17599bcb2725e938ad751ca41e8467fb72633a6d1/embml-0.0.5.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}