{
  "info": {
    "author": "Aashima Yuthika",
    "author_email": "aashima.yuthika@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 2",
      "Programming Language :: Python :: 3.6",
      "Topic :: Software Development :: Build Tools"
    ],
    "description": "# AWS S3 Operations\n\nThis repository contains a package for various i/o functions on s3 buckets.\n\n### To install\n\n`pip install aws_s3_ops`\n\n### To uninstall\n\n`pip uninstall aws_s3_ops`\n\n### Usage\n\nThe list of available functions are:\n\n- [`save_pickle`](####save_pickle)\n- [`load_pickle`](####load_pickle)\n- [`save_csv`](####save_csv)\n- [`save_json`](####save_json)\n- [`download_file`](####download_file)\n- [`upload_file`](####upload_file)\n- [`key_exists`](####key_exists)\n- [`delete_data`](####delete_data)\n- [`get_prefix_object`](####get_prefix_object)\n- [`get_file_buffer`](####get_file_buffer)\n\n\n#### save_pickle\n```python\nfrom aws_s3_ops.aws_s3_ops import S3Operations\n\nobj_s3 = S3Operations()\nbucket = \"your-bucket-name-here\"\nkey = \"your/folder/path/inside/bucket/pickle.pkl\"\nobj = RandomClassObject()\n\nobj_s3.save_pickle(bucket=bucket, key=key, obj=obj)  # Returns boolean\n```\n#### load_pickle\n```python\nfrom aws_s3_ops.aws_s3_ops import S3Operations\n\nobj_s3 = S3Operations()\nbucket = \"your-bucket-name-here\"\nkey = \"your/folder/path/inside/bucket/pickle.pkl\"\n\nobj = obj_s3.load_pickle(bucket=bucket, key=key)  # Loads unpickled object from s3\n```\n\n#### save_csv\n\n```python\nfrom aws_s3_ops.aws_s3_ops import S3Operations\nimport pandas as pd\n\nobj_s3 = S3Operations()\nbucket = \"your-bucket-name-here\"\nkey = \"your/folder/path/inside/bucket/file.csv\"\ndf = pd.DataFrame([['a','b'],['c', 'd']], columns=['col1', 'col2'])\n\nobj_s3.save_csv(bucket=bucket, key=key, df=df, index=False)\n\nkey = \"your/folder/path/inside/bucket/file.csv.gzip\"\nobj_s3.save_csv(bucket=bucket, key=key, df=df, compression=\"gzip\", index=False)\n```\n\n#### save_json\n\n```python\nfrom aws_s3_ops.aws_s3_ops import S3Operations\nimport pandas as pd\n\nobj_s3 = S3Operations()\nbucket = \"your-bucket-name-here\"\nkey = \"your/folder/path/inside/bucket/file.json\"\ndf = pd.DataFrame([['a','b'],['c', 'd']], columns=['col1', 'col2'])\n\nobj_s3.save_json(bucket=bucket, key=key, df=df)\n\nkey = \"your/folder/path/inside/bucket/file.json.gzip\"\nobj_s3.save_csv(bucket=bucket, key=key, df=df, compression=\"gzip\")\n```\n\n#### download_file\n\n```python\nfrom aws_s3_ops.aws_s3_ops import S3Operations\n\nobj_s3 = S3Operations()\nbucket = \"your-bucket-name-here\"\nkey = \"your/folder/path/inside/bucket/file_to_download.random\"\nlocal_path = \"path/for/file/within/local/file_downloaded.random\"\n\nobj_s3.download_file(bucket=bucket, key=key, local_path=local_path)\n```\n\n#### upload_file\n\n```python\nfrom aws_s3_ops.aws_s3_ops import S3Operations\n\nobj_s3 = S3Operations()\nbucket = \"your-bucket-name-here\"\nkey = \"your/folder/path/inside/bucket/file_uploaded.random\"\nlocal_path = \"path/for/file/within/local/file_to_upload.random\"\n\nobj_s3.upload_file(bucket=bucket, key=key, local_path=local_path)\n```\n\n#### key_exists\n\n```python\nfrom aws_s3_ops.aws_s3_ops import S3Operations\n\nobj_s3 = S3Operations()\nbucket = \"your-bucket-name-here\"\nkey = \"your/folder/path/inside/bucket/file_exists.random\"\n\nfile_existence_boolean = obj_s3.key_exists(bucket=bucket, key=key)\n```\n\n#### delete_data\n\n```python\nfrom aws_s3_ops.aws_s3_ops import S3Operations\n\nobj_s3 = S3Operations()\nbucket = \"your-bucket-name-here\"\nkey = \"your/folder/path/inside/bucket/file_to_delete.random\"\n\nobj_s3.delete_data(bucket=bucket, key=key)\n\nkey = \"your/folder/path/inside/bucket/folder_to_delete\"\n\nobj_s3.delete_data(bucket=bucket, key=key)\n```\n\n#### get_prefix_object\n\n```python\nfrom aws_s3_ops.aws_s3_ops import S3Operations\n\nobj_s3 = S3Operations()\nbucket = \"your-bucket-name-here\"\nkey = \"your/folder/path/inside/bucket/\"\n\n# List of all folders and files within the folder\nkeys = obj_s3.get_prefix_object(bucket=bucket, key=key)\n\n# List of all folders and files within the folder with the given extension\nkeys = obj_s3.get_prefix_object(bucket=bucket, key=key, file_extension=\"txt\")\n```\n\n#### get_file_buffer\n```python\nfrom aws_s3_ops.aws_s3_ops import S3Operations\nimport pandas as pd\n\nobj_s3 = S3Operations()\nbucket = \"your-bucket-name-here\"\nkey = \"your/folder/path/inside/bucket/file.txt\"\n\n# This object can then be read using pandas or simple python file operations\nbuf = obj_s3.get_file_buffer(bucket=bucket, key=key)\n\npd.read_csv(buf)\n```\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/AashimaYuthika/aws_s3_ops",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "aws-s3-ops",
    "package_url": "https://pypi.org/project/aws-s3-ops/",
    "platform": "",
    "project_url": "https://pypi.org/project/aws-s3-ops/",
    "project_urls": {
      "Homepage": "https://github.com/AashimaYuthika/aws_s3_ops"
    },
    "release_url": "https://pypi.org/project/aws-s3-ops/1.0.0/",
    "requires_dist": [
      "boto3",
      "pandas",
      "check-manifest ; extra == 'dev'",
      "coverage ; extra == 'test'"
    ],
    "requires_python": ">=2.7, <4",
    "summary": "This repository contains code for input and output operations on s3 buckets",
    "version": "1.0.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 6267569,
  "releases": {
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ebd0f8c92ab02987df17dbe573046b8756249e940188dd4d50e3bb5e32a116d1",
          "md5": "1e206c18d77df2ff3a936ec4c87f58d0",
          "sha256": "d5bc08541cbc6d51082a4ca96775131bae9ba3983fbd87c574785cd0bca32ee2"
        },
        "downloads": -1,
        "filename": "aws_s3_ops-1.0.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "1e206c18d77df2ff3a936ec4c87f58d0",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": ">=2.7, <4",
        "size": 6032,
        "upload_time": "2019-12-09T17:37:52",
        "upload_time_iso_8601": "2019-12-09T17:37:52.829078Z",
        "url": "https://files.pythonhosted.org/packages/eb/d0/f8c92ab02987df17dbe573046b8756249e940188dd4d50e3bb5e32a116d1/aws_s3_ops-1.0.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "47cbbc31283a3bb7354aceaac3076b6de225e592319ea4d211557b259f12b824",
          "md5": "c3d71d57268c5723e459f6682a7822c4",
          "sha256": "c884d44a57cc000a6858e4e8ccf1e8e017033371d41d2474ecaa61e763788d2d"
        },
        "downloads": -1,
        "filename": "aws_s3_ops-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "c3d71d57268c5723e459f6682a7822c4",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=2.7, <4",
        "size": 6573,
        "upload_time": "2019-12-09T17:37:55",
        "upload_time_iso_8601": "2019-12-09T17:37:55.454333Z",
        "url": "https://files.pythonhosted.org/packages/47/cb/bc31283a3bb7354aceaac3076b6de225e592319ea4d211557b259f12b824/aws_s3_ops-1.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "ebd0f8c92ab02987df17dbe573046b8756249e940188dd4d50e3bb5e32a116d1",
        "md5": "1e206c18d77df2ff3a936ec4c87f58d0",
        "sha256": "d5bc08541cbc6d51082a4ca96775131bae9ba3983fbd87c574785cd0bca32ee2"
      },
      "downloads": -1,
      "filename": "aws_s3_ops-1.0.0-py2.py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "1e206c18d77df2ff3a936ec4c87f58d0",
      "packagetype": "bdist_wheel",
      "python_version": "py2.py3",
      "requires_python": ">=2.7, <4",
      "size": 6032,
      "upload_time": "2019-12-09T17:37:52",
      "upload_time_iso_8601": "2019-12-09T17:37:52.829078Z",
      "url": "https://files.pythonhosted.org/packages/eb/d0/f8c92ab02987df17dbe573046b8756249e940188dd4d50e3bb5e32a116d1/aws_s3_ops-1.0.0-py2.py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "47cbbc31283a3bb7354aceaac3076b6de225e592319ea4d211557b259f12b824",
        "md5": "c3d71d57268c5723e459f6682a7822c4",
        "sha256": "c884d44a57cc000a6858e4e8ccf1e8e017033371d41d2474ecaa61e763788d2d"
      },
      "downloads": -1,
      "filename": "aws_s3_ops-1.0.0.tar.gz",
      "has_sig": false,
      "md5_digest": "c3d71d57268c5723e459f6682a7822c4",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=2.7, <4",
      "size": 6573,
      "upload_time": "2019-12-09T17:37:55",
      "upload_time_iso_8601": "2019-12-09T17:37:55.454333Z",
      "url": "https://files.pythonhosted.org/packages/47/cb/bc31283a3bb7354aceaac3076b6de225e592319ea4d211557b259f12b824/aws_s3_ops-1.0.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}