{
  "info": {
    "author": "Irvinfaith",
    "author_email": "waxiguan00@hotmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9"
    ],
    "description": "[![PyPI version](https://badge.fury.io/py/tinyCrawl.svg)](https://badge.fury.io/py/tinyCrawl)\n[![Build Status](https://travis-ci.com/Irvinfaith/tinyCrawl.svg?branch=master)](https://travis-ci.com/Irvinfaith/tinyCrawl)\n[![Documentation Status](https://readthedocs.org/projects/tinycrawl-irvinfaith/badge/?version=latest)](https://tinycrawl-irvinfaith.readthedocs.io/zh_CN/latest/?badge=latest)\n![PyPI - Python Version](https://img.shields.io/pypi/pyversions/tinyCrawl)\n![GitHub](https://img.shields.io/github/license/irvinfaith/tinyCrawl)\n\n# Overview 概览\n\ntinyCrawl 是一个微型的爬虫框架，具有以下特点：\n\n- 简单轻巧，没有任何第三方包的依赖\n- checkpoint断点续爬\n- 支持多线程爬取\n- 内置日志功能\n- 使用简单\n\n# Documentation 文档\n\n[访问官方说明文档](https://tinycrawl-irvinfaith.readthedocs.io/zh_CN/latest/)\n\n# Installation 安装\n\n```\npip install tinyCrawl\n```\n\n\n# How to use 如何使用\ntinyCrawl 支持2种运行方法\n\n- By using funciton 函数式：定义爬虫的方法 task()，实例化 ``BaseCrawl(iter_url, iter_num_range, thread_num)``，调用 ``run`` 方法执行\n- By inheritance 继承式：继承 ``BaseCrawl(iter_url, iter_num_range, thread_num)`` ，重写 ``crawl()`` 和 ``sink()`` 方法，其中 ``crawl()``类似于上一方法中的爬虫方法task()，定义爬取单页的爬虫代码， ``sink()``是将结果输出的方法，最后执行 ``main()`` 方法执行总程序\n\n\n## By using funciton 函数式\n\n```python\n# -*- coding: utf-8 -*-\n\nfrom tinyCrawl import BaseCrawl, RowContainer\n\nfrom urllib.request import urlopen\nfrom lxml import etree\n\n# 定义xpath\nsong_name_xpath = '//div[@class=\"song-name\"]/a/text()'\nsinger_xpath = '//div[@class=\"singers\"]/a[1]/text()'\nalbum_xpath = '//div[@class=\"album\"]/a[1]/text()'\n\ndef task(url):\n    \"\"\"\n    定义爬取单页的爬虫代码\n\n    \"\"\"\n    # 定义数据存放的容器，容器名字就是最后爬取结果存放字典的self.out的key\n    song_name_list = RowContainer(\"song name\")\n    singer_list = RowContainer(\"singer\")\n    album_list = RowContainer(\"album\")\n\n    page = urlopen(url).read().decode(\"utf-8\", 'ignore')\n    parse = etree.HTML(page)\n    for _song_name, _singer, _album in zip(parse.xpath(song_name_xpath),\n                                           parse.xpath(singer_xpath),\n                                           parse.xpath(album_xpath)):\n       \t# 将数据append进指定容器中\n        song_name_list.append(str(_song_name))\n        singer_list.append(str(_singer))\n        album_list.append(str(_album))\n\n\n# 第一个参数是链接地址，需通过 %s 定义页数等迭代的参数\n# 第二个参数是迭代的范围，\n# 第三个参数是启用的线程数，大于1就是多线程，等于1就是单线程\nbc = BaseCrawl(\"http://example.com/?page=%s\", range(1, 5), 3)\n# 输入task的对象，开始执行程序\nbc.run(task)\n# 执行完毕后，通过out属性，获取结果\nprint(bc.out)\n```\n\n## By inheritance 继承式\n\n```python\nfrom tinyCrawl import BaseCrawl, RowContainer\nfrom urllib.request import urlopen\nfrom lxml import etree\nimport pandas as pd\n\n# 需继承BaseCrawl类，覆写crawl和sink方法\nclass Scratch(BaseCrawl):\n    def __init__(self, iter_url, iter_num_range, thread_num):\n        super().__init__(iter_url, iter_num_range, thread_num)\n\n    # 覆写crawl方法\n    def crawl(self, url):\n    # 定义数据存放的容器，容器名字就是最后爬取结果存放字典的self.out的key\n    song_name_list = RowContainer(\"song name\")\n    singer_list = RowContainer(\"singer\")\n    album_list = RowContainer(\"album\")\n\n    page = urlopen(url).read().decode(\"utf-8\", 'ignore')\n    parse = etree.HTML(page)\n    for _song_name, _singer, _album in zip(parse.xpath(song_name_xpath),\n                                           parse.xpath(singer_xpath),\n                                           parse.xpath(album_xpath)):\n       \t# 将数据append进指定容器中\n        song_name_list.append(str(_song_name))\n        singer_list.append(str(_singer))\n        album_list.append(str(_album))\n\n    # 覆写sink方法，将爬取的结果输出\n    def sink(self):\n        # self.out是字典结构的结果，可以直接输入pandas存为dataframe\n        recent_music = pd.DataFrame(self.out)\n        recent_music.to_csv(\"D:/tmptest.csv\", index=0)\n\n\nif __name__ == '__main__':\n    mc = Scratch(\"http://example.com/?page=%s\", range(1, 5), 3)\n    # 调用main函数执行程序\n    mc.main()\n```\n\noutput：\n\n```shell\n2021-01-10 16:18:36,944 - base.py - __init__ - [line:30] - INFO: Checkpoint path: D:\\breakpoint_page.txt\n2021-01-10 16:18:38,539 - base.py - __source - [line:119] - INFO: Now is running on multithread mode, total thread num is `3`\n2021-01-10 16:18:38,539 - base.py - __source - [line:126] - INFO: Total iteration num: 4\n2021-01-10 16:18:38,541 - base.py - _multi_thread_wrap - [line:59] - INFO: ThreadPoolExecutor-1_0 now is processing: http://example.com/?page=1\n2021-01-10 16:18:38,541 - base.py - _multi_thread_wrap - [line:59] - INFO: ThreadPoolExecutor-1_1 now is processing: http://example.com/?page=2\n2021-01-10 16:18:38,542 - base.py - _multi_thread_wrap - [line:59] - INFO: ThreadPoolExecutor-1_2 now is processing: http://example.com/?page=3\n2021-01-10 16:18:41,544 - base.py - __task_done - [line:115] - INFO: ThreadPoolExecutor-1_1 task finished; (Time took: 3.0009s)\n2021-01-10 16:18:41,544 - base.py - __task_done - [line:115] - INFO: ThreadPoolExecutor-1_0 task finished; (Time took: 3.0019s)\n2021-01-10 16:18:41,544 - base.py - __task_done - [line:115] - INFO: ThreadPoolExecutor-1_2 task finished; (Time took: 3.0009s)\n2021-01-10 16:18:41,545 - base.py - _multi_thread_wrap - [line:59] - INFO: ThreadPoolExecutor-1_1 now is processing: http://example.com/?page=4\n2021-01-10 16:18:44,551 - base.py - __task_done - [line:115] - INFO: ThreadPoolExecutor-1_1 task finished; (Time took: 3.0022s)\n2021-01-10 16:18:44,551 - base.py - __source - [line:151] - INFO: All done. (Time took: 6.0102s)\n```\n\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/Irvinfaith/tinyCrawl",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "tinyCrawl",
    "package_url": "https://pypi.org/project/tinyCrawl/",
    "platform": "python 3.6",
    "project_url": "https://pypi.org/project/tinyCrawl/",
    "project_urls": {
      "Homepage": "https://github.com/Irvinfaith/tinyCrawl"
    },
    "release_url": "https://pypi.org/project/tinyCrawl/0.1.2/",
    "requires_dist": null,
    "requires_python": ">=3.6,<4",
    "summary": "Very easy and tiny crawling framework, support multithread processing.",
    "version": "0.1.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 9111222,
  "releases": {
    "0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7f0b6b2c4a1409e80d84b317c478f3d79300a21386a1911c76915ca289364f0a",
          "md5": "660e3bc8599062cbaf0d7e34e55e3fdd",
          "sha256": "42b4089a2559dc1535245b1d663bbac59d6a22f61504f71061c23bd2c73176d6"
        },
        "downloads": -1,
        "filename": "tinyCrawl-0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "660e3bc8599062cbaf0d7e34e55e3fdd",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 10895516,
        "upload_time": "2021-01-10T10:27:11",
        "upload_time_iso_8601": "2021-01-10T10:27:11.205571Z",
        "url": "https://files.pythonhosted.org/packages/7f/0b/6b2c4a1409e80d84b317c478f3d79300a21386a1911c76915ca289364f0a/tinyCrawl-0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e64ea2269c7f4257a9582287ad8c9f141be862aaf0a33fad3f001bdddd393d4f",
          "md5": "b4113ae3259cdedbad35cd1a993ad4b0",
          "sha256": "9181d2b1d24b3c668879c98b8ad45ea74691f11c1059563563fdc29ecf98d04b"
        },
        "downloads": -1,
        "filename": "tinyCrawl-0.1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "b4113ae3259cdedbad35cd1a993ad4b0",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6,<4",
        "size": 14419,
        "upload_time": "2021-01-11T07:46:25",
        "upload_time_iso_8601": "2021-01-11T07:46:25.271965Z",
        "url": "https://files.pythonhosted.org/packages/e6/4e/a2269c7f4257a9582287ad8c9f141be862aaf0a33fad3f001bdddd393d4f/tinyCrawl-0.1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "59c06c33a110ca203fb56e33edb1c432fcb767e1d9c84231d872e578d59ebad8",
          "md5": "6c611141970fabc1431cd1e204c86749",
          "sha256": "a6f69b2e5a8befe5d48ac9685865ff782cf18f68d50ff8af025d5fc4bf117e7e"
        },
        "downloads": -1,
        "filename": "tinyCrawl-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "6c611141970fabc1431cd1e204c86749",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6,<4",
        "size": 10891417,
        "upload_time": "2021-01-11T07:47:19",
        "upload_time_iso_8601": "2021-01-11T07:47:19.887971Z",
        "url": "https://files.pythonhosted.org/packages/59/c0/6c33a110ca203fb56e33edb1c432fcb767e1d9c84231d872e578d59ebad8/tinyCrawl-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3995be2ce841221dc2a55887101ab6abc6af6ed64adc5f0382d74f53cab3643a",
          "md5": "ba5f3a663d6a9959f57ac5861d9c99fe",
          "sha256": "894fee57ac9c5509c199f8a3505553ad744d876eba0b39fa963fe41b84d2b8f5"
        },
        "downloads": -1,
        "filename": "tinyCrawl-0.1.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ba5f3a663d6a9959f57ac5861d9c99fe",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6,<4",
        "size": 14939,
        "upload_time": "2021-01-12T03:44:14",
        "upload_time_iso_8601": "2021-01-12T03:44:14.918927Z",
        "url": "https://files.pythonhosted.org/packages/39/95/be2ce841221dc2a55887101ab6abc6af6ed64adc5f0382d74f53cab3643a/tinyCrawl-0.1.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d515d695fba55a999a710c6a527d70911da3bb4411cd8e5d17e02a9734634afc",
          "md5": "e90de4d5ad9e549f3c1c26df8205459c",
          "sha256": "fa9bafb0920fc429ff473fa0fd6fe7a6fdfd7562c84723d5d5ebaade9c1f8634"
        },
        "downloads": -1,
        "filename": "tinyCrawl-0.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "e90de4d5ad9e549f3c1c26df8205459c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6,<4",
        "size": 10913458,
        "upload_time": "2021-01-12T03:45:48",
        "upload_time_iso_8601": "2021-01-12T03:45:48.393819Z",
        "url": "https://files.pythonhosted.org/packages/d5/15/d695fba55a999a710c6a527d70911da3bb4411cd8e5d17e02a9734634afc/tinyCrawl-0.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "3995be2ce841221dc2a55887101ab6abc6af6ed64adc5f0382d74f53cab3643a",
        "md5": "ba5f3a663d6a9959f57ac5861d9c99fe",
        "sha256": "894fee57ac9c5509c199f8a3505553ad744d876eba0b39fa963fe41b84d2b8f5"
      },
      "downloads": -1,
      "filename": "tinyCrawl-0.1.2-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "ba5f3a663d6a9959f57ac5861d9c99fe",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6,<4",
      "size": 14939,
      "upload_time": "2021-01-12T03:44:14",
      "upload_time_iso_8601": "2021-01-12T03:44:14.918927Z",
      "url": "https://files.pythonhosted.org/packages/39/95/be2ce841221dc2a55887101ab6abc6af6ed64adc5f0382d74f53cab3643a/tinyCrawl-0.1.2-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "d515d695fba55a999a710c6a527d70911da3bb4411cd8e5d17e02a9734634afc",
        "md5": "e90de4d5ad9e549f3c1c26df8205459c",
        "sha256": "fa9bafb0920fc429ff473fa0fd6fe7a6fdfd7562c84723d5d5ebaade9c1f8634"
      },
      "downloads": -1,
      "filename": "tinyCrawl-0.1.2.tar.gz",
      "has_sig": false,
      "md5_digest": "e90de4d5ad9e549f3c1c26df8205459c",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6,<4",
      "size": 10913458,
      "upload_time": "2021-01-12T03:45:48",
      "upload_time_iso_8601": "2021-01-12T03:45:48.393819Z",
      "url": "https://files.pythonhosted.org/packages/d5/15/d695fba55a999a710c6a527d70911da3bb4411cd8e5d17e02a9734634afc/tinyCrawl-0.1.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}