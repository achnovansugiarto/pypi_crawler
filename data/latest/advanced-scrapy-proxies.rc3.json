{
  "info": {
    "author": "Pierluigi Vinciguerra",
    "author_email": "pierluigivinciguerra@gmail.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# advanced-scrapy-proxies\n\nadvanced-scrapy-proxies is a Python library for dealing with proxies in your Scrapy project.\nStarting from [Aivarsk's scrapy proxy](https://github.com/aivarsk/scrapy-proxies) (no more updated since 2018) i'm adding more features to manage lists of proxies generated dinamically. \n\n\n## Installation\n\nUse the package manager [pip](https://pip.pypa.io/en/stable/) to install advanced-scrapy-proxies.\n\n```bash\npip install advanced-scrapy-proxies\n```\n\n## Usage\n### settings.py \n\n```python\nDOWNLOADER_MIDDLEWARES = {\n    'scrapy.downloadermiddlewares.retry.RetryMiddleware': 90,\n    'advanced-scrapy-proxies.RandomProxy': 100,\n    'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware': 110\n}\n\n## Proxy mode\n\t# -1: NO_PROXY, middleware is configured but does nothing. Useful when needed to automate the selection of the mode\n\t# 0: RANDOMIZE_PROXY_EVERY_REQUESTS, every requrest use a different proxy\n\t# 1: RANDOMIZE_PROXY_ONCE, selects one proxy for the whole execution from the input list\n\t# 2: SET_CUSTOM_PROXY, use the proxy specified with option CUSTOM_PROXY\n\t# 3: REMOTE_PROXY_LIST, use the proxy list at the specified URL\nPROXY_MODE = 3\n\nPROXY_LIST ='https://yourproxylisturl/list.txt'\n```\nAs every scrapy project, you can override the settings in settings.py when calling the scraper.\n```bash\n##PROXY_MODE=-1, the spider does not use the proxy list provided.\nscrapy crawl myspider -s PROXY_MODE=-1 -s PROXY_LIST='myproxylist.txt'\n##PROXY_MODE=0, the spider use the proxy list provided, choosing for every request a different proxy. \nscrapy crawl myspider -s PROXY_MODE=0 -s PROXY_LIST='myproxylist.txt'\n##PROXY_MODE=1, the spider use the proxy list provided, choosing only one proxy for the whole execution.\nscrapy crawl myspider -s PROXY_MODE=1 -s PROXY_LIST='myproxylist.txt'\n##PROXY_MODE=2, the spider uses the proxy provided.\nscrapy crawl myspider -s PROXY_MODE=2 -s PROXY_LIST='http://myproxy.com:80'\n##PROXY_MODE=3, the spider uses the proxy list at the url provided. The list is read at every request made by the spider, so it can be updated during the execution.\nscrapy crawl myspider -s PROXY_MODE=3 -s PROXY_LIST='http://myproxy.com:80'\n```\n## Planned new features and updates\n### Minor updates\n- adding more tests on the format of the input variables\n- rewriting error messages\n\n### New features\n- Adding a cooldown list: instead of deleting proxy after a failed attempt to get data, use a cooldown list where they are not used for a limited time in the scraper but ready to be reused when the cooldown finishes.\n- Adding support for reading urls of the lists behind user and password\n- Updating proxy list at every request even for PROXY_MODE=0\n\n\n## Contributing\nPull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.\n\nPlease make sure to update tests as appropriate.\n\n## License\n[GNU GPLv2](https://choosealicense.com/licenses/gpl-2.0/)\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/PVinciguerra/advanced-scrapy-proxies",
    "keywords": "",
    "license": "GNU GPLv2",
    "maintainer": "",
    "maintainer_email": "",
    "name": "advanced-scrapy-proxies",
    "package_url": "https://pypi.org/project/advanced-scrapy-proxies/",
    "platform": null,
    "project_url": "https://pypi.org/project/advanced-scrapy-proxies/",
    "project_urls": {
      "Homepage": "https://github.com/PVinciguerra/advanced-scrapy-proxies"
    },
    "release_url": "https://pypi.org/project/advanced-scrapy-proxies/0.1.3/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "Advanced Scrapy Proxies: random proxy middleware for Scrapy with advanced features",
    "version": "0.1.3",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14331000,
  "releases": {
    "0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9b8f9370673b2e825fe61b3074a3e60a6ea86eac3a4f3d3ece832911f57a0783",
          "md5": "6cd74507a16a42bd1320c57a63dffe7c",
          "sha256": "54499d05f669a3058d96706fde37d7d9e1eb06c7a6a6220fc62ec1b57bcdd341"
        },
        "downloads": -1,
        "filename": "advanced_scrapy_proxies-0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "6cd74507a16a42bd1320c57a63dffe7c",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 10639,
        "upload_time": "2022-05-04T14:51:09",
        "upload_time_iso_8601": "2022-05-04T14:51:09.659609Z",
        "url": "https://files.pythonhosted.org/packages/9b/8f/9370673b2e825fe61b3074a3e60a6ea86eac3a4f3d3ece832911f57a0783/advanced_scrapy_proxies-0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "314d88ea23208c8280d754900a637f1c7b59b3de624ec579b3f4069c3a14cc7e",
          "md5": "8dd26e9a914dd075f273d10cf0a47615",
          "sha256": "c183b8ece7d4ff03aa480bab166b261d66de30b769f1f11f9ac7630777030916"
        },
        "downloads": -1,
        "filename": "advanced-scrapy-proxies-0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "8dd26e9a914dd075f273d10cf0a47615",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 9628,
        "upload_time": "2022-05-04T14:51:10",
        "upload_time_iso_8601": "2022-05-04T14:51:10.999871Z",
        "url": "https://files.pythonhosted.org/packages/31/4d/88ea23208c8280d754900a637f1c7b59b3de624ec579b3f4069c3a14cc7e/advanced-scrapy-proxies-0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6f677d4fac94fb2004b305734b5e6a74609c174b395e9f94de7dccb394247ccf",
          "md5": "24a9c4d6a9a97ea35fd247cefb46bd24",
          "sha256": "37bacdf57478de5b9a87c901d58f1df21e84b22da92c576a6e981408c54813a6"
        },
        "downloads": -1,
        "filename": "advanced_scrapy_proxies-0.1.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "24a9c4d6a9a97ea35fd247cefb46bd24",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 11872,
        "upload_time": "2022-05-04T16:37:04",
        "upload_time_iso_8601": "2022-05-04T16:37:04.376232Z",
        "url": "https://files.pythonhosted.org/packages/6f/67/7d4fac94fb2004b305734b5e6a74609c174b395e9f94de7dccb394247ccf/advanced_scrapy_proxies-0.1.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "745c7bb32312c21be792e277cee0163657b4eaf34571f6c89dc2520f9c092c39",
          "md5": "73742654f62f9feda3ffff3664b5c4e5",
          "sha256": "6ad5be9d54e5a15e0f704df67a1cef77cc0be5effc897a5430881c7329e31320"
        },
        "downloads": -1,
        "filename": "advanced-scrapy-proxies-0.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "73742654f62f9feda3ffff3664b5c4e5",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 10914,
        "upload_time": "2022-05-04T16:37:06",
        "upload_time_iso_8601": "2022-05-04T16:37:06.800459Z",
        "url": "https://files.pythonhosted.org/packages/74/5c/7bb32312c21be792e277cee0163657b4eaf34571f6c89dc2520f9c092c39/advanced-scrapy-proxies-0.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0d7946e415c6ecfb64250ac0003af627696fb2d434546b032cfbc22055534242",
          "md5": "73e48a31ccbff716419f07dfe0be9292",
          "sha256": "6101306a9a2577574bb524d3da7cb7b9f007532745cc6236a40dcf82c6d3ac0d"
        },
        "downloads": -1,
        "filename": "advanced_scrapy_proxies-0.1.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "73e48a31ccbff716419f07dfe0be9292",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 11884,
        "upload_time": "2022-07-04T14:01:29",
        "upload_time_iso_8601": "2022-07-04T14:01:29.193760Z",
        "url": "https://files.pythonhosted.org/packages/0d/79/46e415c6ecfb64250ac0003af627696fb2d434546b032cfbc22055534242/advanced_scrapy_proxies-0.1.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "df456f04b34de1e8eadbe8a95a229753e13c2de85199dd8afb9e2850b0223881",
          "md5": "e3630984fd3fefa5f6274fc19f4f5c77",
          "sha256": "52356685740fb5de3a57f5c93a8353eead6e860be883453229559debdf0650ac"
        },
        "downloads": -1,
        "filename": "advanced-scrapy-proxies-0.1.3.tar.gz",
        "has_sig": false,
        "md5_digest": "e3630984fd3fefa5f6274fc19f4f5c77",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 10841,
        "upload_time": "2022-07-04T14:01:30",
        "upload_time_iso_8601": "2022-07-04T14:01:30.624848Z",
        "url": "https://files.pythonhosted.org/packages/df/45/6f04b34de1e8eadbe8a95a229753e13c2de85199dd8afb9e2850b0223881/advanced-scrapy-proxies-0.1.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "0d7946e415c6ecfb64250ac0003af627696fb2d434546b032cfbc22055534242",
        "md5": "73e48a31ccbff716419f07dfe0be9292",
        "sha256": "6101306a9a2577574bb524d3da7cb7b9f007532745cc6236a40dcf82c6d3ac0d"
      },
      "downloads": -1,
      "filename": "advanced_scrapy_proxies-0.1.3-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "73e48a31ccbff716419f07dfe0be9292",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 11884,
      "upload_time": "2022-07-04T14:01:29",
      "upload_time_iso_8601": "2022-07-04T14:01:29.193760Z",
      "url": "https://files.pythonhosted.org/packages/0d/79/46e415c6ecfb64250ac0003af627696fb2d434546b032cfbc22055534242/advanced_scrapy_proxies-0.1.3-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "df456f04b34de1e8eadbe8a95a229753e13c2de85199dd8afb9e2850b0223881",
        "md5": "e3630984fd3fefa5f6274fc19f4f5c77",
        "sha256": "52356685740fb5de3a57f5c93a8353eead6e860be883453229559debdf0650ac"
      },
      "downloads": -1,
      "filename": "advanced-scrapy-proxies-0.1.3.tar.gz",
      "has_sig": false,
      "md5_digest": "e3630984fd3fefa5f6274fc19f4f5c77",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 10841,
      "upload_time": "2022-07-04T14:01:30",
      "upload_time_iso_8601": "2022-07-04T14:01:30.624848Z",
      "url": "https://files.pythonhosted.org/packages/df/45/6f04b34de1e8eadbe8a95a229753e13c2de85199dd8afb9e2850b0223881/advanced-scrapy-proxies-0.1.3.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}