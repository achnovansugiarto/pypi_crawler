{
  "info": {
    "author": "Ruochi Zhang",
    "author_email": "zrc720@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Natural Language :: English",
      "Programming Language :: Python :: 3.4",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7"
    ],
    "description": "# SKNet\n\n## Introduction\nSKNet is a new type of neural network that is simple in structure but complex in neuron. Each of its neuron is a traditional estimator such as SVM, RF, etc.  \n\n## Fetaures \nWe think that such a network has many applicable scenarios. For example: \n- We don't have enough samples to train neural networks. \n- We hope to improve the accuracy of the model by means of emsemble. \n- We hope to learn some new features. \n- We want to save a lot of parameter-tuning time while getting a stable and good model.\n\n\n## Installation\n\n```python3\npip install sknet\n```\n\n\n## Example\n\n## Computation Graph\n\n![](./computation_graph.png)\n\n### Code\n\n```python\nfrom sknet.sequential import Layer,Sequential,SKNeuron\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.svm import LinearSVR\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\n\n\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\n\n\ndata = load_breast_cancer()\nfeatures = data.data\ntarget = data.target\n\nX_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n\n\nlayer1 = Layer([\n    SKNeuron(RandomForestRegressor,params = {\"random_state\": 0}),\n    SKNeuron(GradientBoostingRegressor,params = {\"random_state\": 0}),\n    SKNeuron(AdaBoostRegressor,params = {\"random_state\": 0}),\n    SKNeuron(KNeighborsRegressor),\n    SKNeuron(ExtraTreesRegressor,params = {\"random_state\": 0}),\n])\n\nlayer2 = Layer([\n    SKNeuron(AdaBoostRegressor,params = {\"random_state\": 0}),\n    SKNeuron(LinearSVR,params = {\"random_state\": 0}),\n])\n\nlayer3 = Layer([\n    SKNeuron(LogisticRegression,params = {\"random_state\": 0}),\n])\n\n\nmodel = Sequential([layer1,layer2,layer3],n_splits = 5)\ny_pred = model.fit_predict(X_train,y_train, X_test)\nprint(model.score(y_test,y_pred))\n\n\n# acc = 0.9736842105263158\n```\n\n## How to construct the SkNet\n\n## General Considerations（不用严格遵守）\n1. introduce more information on first level\n2. use simpler model for Subquent level\n\n## How to introduce more information?\n1. use different estimator\n2. use same estimator but differences parameters(such as random seed, ...)\n3. simpling samples\n4. simpleing features\n5. different feature engineering techniques (one-hot, embedding, ...)\n\n### first level Tips\n1. Diversity based on algo\n    - 2-3 gradient boosted trees(xgboost, H2O, catboost)\n    - 2-3 Neural Net (keras, pyTorch)\n    - 1-2 ExtraTree/ Random Forest( sklearn)\n    - 1-2 Linear models as in Logistic/ridge regression, linearsvm(sklearn)\n    - 1-2 knn models(sklearn)\n    - 1 Factorization machine (libfm)\n    - 1 svm with nonlinear kernel if size/memory allows(sklearn)\n    - 1 svm with nonlinear kernel if size/memory allows(sklearn)\n2. Diversity based on input data\n    - Categorical features: One hot, label encoding, target encoding, frequency.\n    - Numberical features: outliner, binning, derivatives, percentiles, scaling\n    - Interactions: col1 \\*/+-col2, groupby, unsupervied\n    - For classification target, we can use regression models in middle level \n\n### Subquent level tips\n1. Simpler(or shallower) algo\n    - gradient boosted tree with small depth(2 or 3)\n    - linear models with high reglarization\n    - Extra Trees\n    - Shallow network\n    - Knn with BrayCurtis Distance\n    - Brute forcing a seach for best linear weights based on cv\n2. Feature engineering\n    - parwise differences between meta features\n    - row-wise statics like average or stds\n    - Standard feature selection techniques\n\n\n## Todo\n- Two or three level stacking\n- multi-processing\n- features proxy",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/zhangruochi/DeerNet",
    "keywords": "stack,sklearn",
    "license": "MIT License",
    "maintainer": "",
    "maintainer_email": "",
    "name": "DeerNet",
    "package_url": "https://pypi.org/project/DeerNet/",
    "platform": "any",
    "project_url": "https://pypi.org/project/DeerNet/",
    "project_urls": {
      "Homepage": "https://github.com/zhangruochi/DeerNet"
    },
    "release_url": "https://pypi.org/project/DeerNet/0.0.2/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "a library used for stacking based on scikit-learn",
    "version": "0.0.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 6132393,
  "releases": {
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2bb7cd51c4098e3fc31e345824f599414aad133817dbfb441cee69a6c8fdc2cd",
          "md5": "3599d52a3fdcd9a0f2993bd341b4aadf",
          "sha256": "a66a676c5a7bba02a021cde4d0f3b93b0d752237a2cdfad5141973b47810dfcc"
        },
        "downloads": -1,
        "filename": "DeerNet-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "3599d52a3fdcd9a0f2993bd341b4aadf",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 4316,
        "upload_time": "2019-11-13T19:12:39",
        "upload_time_iso_8601": "2019-11-13T19:12:39.448899Z",
        "url": "https://files.pythonhosted.org/packages/2b/b7/cd51c4098e3fc31e345824f599414aad133817dbfb441cee69a6c8fdc2cd/DeerNet-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "2bb7cd51c4098e3fc31e345824f599414aad133817dbfb441cee69a6c8fdc2cd",
        "md5": "3599d52a3fdcd9a0f2993bd341b4aadf",
        "sha256": "a66a676c5a7bba02a021cde4d0f3b93b0d752237a2cdfad5141973b47810dfcc"
      },
      "downloads": -1,
      "filename": "DeerNet-0.0.2.tar.gz",
      "has_sig": false,
      "md5_digest": "3599d52a3fdcd9a0f2993bd341b4aadf",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 4316,
      "upload_time": "2019-11-13T19:12:39",
      "upload_time_iso_8601": "2019-11-13T19:12:39.448899Z",
      "url": "https://files.pythonhosted.org/packages/2b/b7/cd51c4098e3fc31e345824f599414aad133817dbfb441cee69a6c8fdc2cd/DeerNet-0.0.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}