{
  "info": {
    "author": "Adam Gosztolai & Semih Gunel",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# LiftPose3D\n\n<!--- ![video_5](https://user-images.githubusercontent.com/20509861/110424090-876c2180-80a2-11eb-87cc-38309236bf83.gif) --->\n<p align=\"center\">\n  <img align=\"center\" width=\"1000\" src=\"https://user-images.githubusercontent.com/20509861/112979625-21cafc80-9159-11eb-8848-93435e7ef68a.gif\">\n</p>\n\n\nLiftPose3D is a tool for transforming a 2D poses to 3D coordinates on labaratory animals. Classical approaches based on triangulation require synchronised acquisition from multiple cameras and elaborate calibration protocols. By contrast, LiftPose3D can reconstruct 3D poses from 2D poses from a single camera, in some instances without having to know the camera position or the type of lens used. For the theoretical background and details, have a look at our [paper](https://www.biorxiv.org/content/10.1101/2020.09.18.292680v1).\n\nTo train LiftPose3D, ideally you would need (A) a 3D pose library, (B) corresponding 2D poses from the camera that you will use for lifting and (C) camera matrices (extrinsic and intrinsic). \n\nIf you do not have access to \n  * (A) then use one of the provided datasets,\n  * (B) then obtain 2D images via projection using your camera matrices (you will need to calibrate to obtain these)\n  * (C) then place your camera further away to assume weak perspective.\n\n## Starting-Up\n1. [Installation](https://github.com/NeLy-EPFL/LiftPose3D/blob/master/docs/install.md)\n2. [LiftPose3D Paper](https://www.biorxiv.org/content/10.1101/2020.09.18.292680v1)\n3. [Citing LiftPose3D](https://github.com/NeLy-EPFL/LiftPose3D/blob/master/docs/cite.md)\n\n## Data format\nDuring training, LiftPose3D accepts two numpy arrays in shape of `[N J 2]` and `[N J 3]` serving as input and output. Here, N is the number of poses and J is the number of joints. If you have multiple experiments, you can provide your data as dictionaries where the keys are strings and values are numpy arrays. You will also need the set at least one root joint and a set of target sets for each root joint. The network will predict the joints in the target sets relative to the root joints.\n\nFor each [example](https://github.com/NeLy-EPFL/LiftPose3D/tree/master/examples), we provide a unique `load.py` file to transform data into the required `[N J 3]` LifPose3D format.\n\n## Training\nYou can train a network with the following generic syntax using experiment 1 for training and experiment 2 for testing.\n\n  ```python\n  from liftpose.main import train as lp3d_train\n  import numpy.random.rand\n\n  n_points, n_joints = 100, 5\n  train_2d, test_2d = rand((n_points, n_joints, 2)), rand((n_points, n_joints, 2))\n  train_3d, test_3d = rand((n_points, n_joints, 3)), rand((n_points, n_joints, 3))\n\n  train_2d = {\"experiment_1\": train_2d}\n  train_3d = {\"experiment_1\": train_3d}\n  test_2d = {\"experiment_2\": test_2d}\n  test_3d = {\"experiment_2\": test_3d}\n\n  roots = [0]\n  target_sets = [1,2,3,4]\n\n  lp3d_train(train_2d, test_2d, train_3d, test_3d, roots, target_sets)\n  ```\n\nBy default, the outputs will be saved in a folder `out` relative to the path where LiftPose3D is called. You can change this behavior using the `ouput_folder` parameter of the `train` function. You can take a look at the ```train``` function for other [default values and much longer documentation here](https://github.com/NeLy-EPFL/LiftPose3D/blob/e36d6598115c3eb7cf34f2ece90334df4200eee4/liftpose/main.py#L36).\n\nFor example, you can further configure training by passing an extra argument ```training_kwargs``` in ```train``` function.\n\n  ```python\n  from liftpose.main import train as lp3d_train\n  training_kwargs={ \"epochs\": 15,                   # train for 15 epochs\n                    \"resume\": True,                 # resume training where it was stopped\n                    \"load\"  : 'ckpt_last.pth.tar'}, # use last training checkpoint to resume\n\n  lp3d_train(train_2d, test_2d, train_3d, test_3d, roots, target_sets, training_kwargs=training_kwargs)\n  ```\n\nYou can overwrite all the parameter inside ```liftpose.lifter.opt``` using ```training_kwargs```.\n\n## Training augmentation\n\nAugmenting training data is a great way to account for variability in the dataset, especially when training data is scarce. \n\nCurrently, available options in ```liftpose.lifter.augmentation``` are:\n1. `add_noise`      : adding Gaussian noise on 2D training pose to account for uncertainty in test time\n2. `random_project` : random projections of 3D pose in case camera orientation is unknown during test time (the training will ignore the input ```train_2d```)\n3. `perturb_pose`   : pose augmentation by changing segment lengths when there are large animal-to-animal variation\n4. `project_to_cam` : deterministic projections of 3D pose in case camera matrix is different and known in test time \n\nTraining augmentation options can be specified in the argument `augmentation` and can be combined. \n\n  ```python\n  from liftpose.main import train as lp3d_train\n  from liftpose.lifter.augmentation import random_project\n\n  angle_aug = {'eangles' : {0: [[-10,10], [-10, 10], [-10,10]]}, #range of Euler angles (dictionary indexed by an integer which specifies the camera identify)\n               'axsorder': 'zyx', # order of rotations for euler angles\n               'vis'     : None,  # used in case not all joints are visible from a given camera\n               'tvec'    : None,  # camera translation vector\n               'intr'    : None}  # camera intrinsic matrix\n\n  aug = [random_project(**angle_aug)]\n  lp3d_train(train_2d, test_2d, train_3d, test_3d, roots, target_sets, aug=aug)\n  ```\n\nSee the case of [angle invariant Drosophila lifting](https://github.com/NeLy-EPFL/LiftPose3D/tree/master/examples/fly_tether_angle_inv) for an example implementation of augmentation.\n\n## Inspecting the training  \n\n  The training information is saved under the ```train_log.txt```, which can be visualized as follows.\n\n  ```python\n  from liftpose.plot import read_log_train, plot_log_train\n  epoch, lr, loss_train, loss_test, err_test = read_log_train(par['out_dir'])\n  plot_log_train(plt.gca(), loss_train, loss_test, epoch)\n  ```\n  This will plot the training and test losses during the training.\n  <p align=\"center\">\n   <img src=\"https://user-images.githubusercontent.com/20509861/110373519-dfc60380-804f-11eb-9bbe-6db6f17c5fc6.png\" width=\"360\">\n  </p>\n\n\n## Testing the network\n  To test the network on the data provided during the ```lp3d_train``` call, run\n  ```python\n  from liftpose.main import test as lp3d_test\nlp3d_test(par['out_dir'])\n  ```\n  Results will be saved inside the ```test_results.pth.tar``` file. \n\n  To test the network in new data, run\n\n  ```python\n  liftpose3d_test(par['out_dir'], test_2d, test_3d)\n  ```\n  where you provide the ```test_2d``` and ```test_3d``` in the format described above. This will overwrite the previous ```test_results.pkl``` file, if there is any.\n\n  We also provide a simple interface for loading the test results from the ```test_results.pkl``` file. \n\n  ```python\n  from liftpose.postprocess import load_test_results\n  test_3d_gt, test_3d_pred, _ = load_test_results(par['out_dir'])\n  ```\n  This will return two numpy arrays: ```test_3d_gt```, which is the same as ```test_3d```, and ```test_3d_pred```, which has the predictions from the LiftPose3D.  \n\n  To generate the error distribution run\n ```python\n  from liftpose.plot import violin_plot\n\n  names = ['Head', 'Nose', 'Shoulder',  'Hip',  'Knee', 'Foot', 'Hand']\n  violin_plot(plt.gca(), test_3d_gt=test_3d_gt, test_3d_pred=test_3d_pred, test_keypoints=np.ones_like(test_3d_gt),\n              joints_name=names, units='m', body_length=2.21)\n  ```\n\n  <p align=\"center\">\n  <img align=\"center\" width=\"300\" height=\"300\" src=\"https://user-images.githubusercontent.com/20509861/110426701-d61bba80-80a6-11eb-885c-b73012c17fd3.png\">\n  </p>\n\n\n## Visualizing the 3D pose\n\nTo visualize the output 3D pose, first specify an animal skeleton in the file ```params.yaml```. Note that bone information or the connected joints, are only used for visualization and not during training. You can have a closer look at ```plot_pose_3d``` function to see how the bone and color parameters are used during plotting. \n\n  ```params.yaml\n  data:\n      roots       : [0]\n      target_sets : [[1, 2, 3, 4]]\n\n  vis:\n      colors      : [[186, 30, 49]]\n      bones       : [[0, 1], [1, 2], [2, 3], [3, 4]]\n      limb_id     : [0, 0, 0, 0, 0]\n  ```\n\nWe provide the following function to visualize the 3D data\n\n ```python\nfrom liftpose.plot import plot_pose_3d\nfig = plt.figure(figsize=plt.figaspect(1), dpi=100)\nax = fig.add_subplot(111, projection='3d')\nax.view_init(elev=-75, azim=-90)\n\nt = 0\nplot_pose_3d(ax=ax, tar=test_3d_gt[t], \n            pred=test_3d_pred[t], \n            bones=par_data[\"vis\"][\"bones\"], \n            limb_id=par_data[\"vis\"][\"limb_id\"], \n            colors=par_data[\"vis\"][\"colors\"],\n            legend=True)\n ```\n This should output something similar to:\n\n   <p align=\"center\">\n  <img align=\"center\" width=\"300\" height=\"300\" src=\"https://user-images.githubusercontent.com/20509861/110427610-5131a080-80a8-11eb-81bc-b11867ee0e9f.png\">\n  </p>\n\nYou can also easily create movies \n\n```python\nfrom liftpose.plot import plot_video_3d\n\nfig = plt.figure(figsize=plt.figaspect(1), dpi=100)\nax = fig.add_subplot(111, projection='3d')\n\nax.set_xlim([-4,2])\nax.set_ylim([-3,2])\nax.set_zlim([0,2])\n\nplot_video_3d(fig, ax, n=gt.shape[0], par=par_data, tar=gt, pred=pred, trailing=10, trailing_keypts=[4,9,14,19,24,29], fps=20)\n```\n\nUse *trailing* to plot points *trailing_keypts* with a trailing effect with a desired length.\n\n### Training with subset of points\nIn case you want to prevent some 2D/3D points from used in the training, you can pass ```train_keypts``` argument into the ```train``` function, which has the same shape as ```train_3d``` but has boolean datatype. Alternatively, in case you have missing keypoints, you can convert them to ```np.NaN```. In both cases, the loss from these points is not going to be used during backpropagation.\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/NeLy-EPFL/LiftPose3D",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "liftpose",
    "package_url": "https://pypi.org/project/liftpose/",
    "platform": "",
    "project_url": "https://pypi.org/project/liftpose/",
    "project_urls": {
      "Homepage": "https://github.com/NeLy-EPFL/LiftPose3D"
    },
    "release_url": "https://pypi.org/project/liftpose/0.22/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "Monocular 3D pose Estimation on Laboratory Animals",
    "version": "0.22",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 10016147,
  "releases": {
    "0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "745bf4c65a76eb1c141368d66869dc5a8b2ae4f3ee095173b8036d1035dedbd4",
          "md5": "996e080a0478df49df1a7bb73e92623f",
          "sha256": "107f8519fa05e497c8040515eea55cc6a7eb1b25412670e231649dfebfe02973"
        },
        "downloads": -1,
        "filename": "liftpose-0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "996e080a0478df49df1a7bb73e92623f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 33911,
        "upload_time": "2021-03-31T09:54:29",
        "upload_time_iso_8601": "2021-03-31T09:54:29.447465Z",
        "url": "https://files.pythonhosted.org/packages/74/5b/f4c65a76eb1c141368d66869dc5a8b2ae4f3ee095173b8036d1035dedbd4/liftpose-0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.21": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "738bab9a33341a98b2fd8755995b27421e68a8f3e79442ad902e3d154f554fd4",
          "md5": "cc076b10f3debef02676ff164cba7745",
          "sha256": "7db90fa6b5b7f3f9fea218edc57af8f229cdbc3cd02fdc2d92dffeabd3adc2f0"
        },
        "downloads": -1,
        "filename": "liftpose-0.21.tar.gz",
        "has_sig": false,
        "md5_digest": "cc076b10f3debef02676ff164cba7745",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 33914,
        "upload_time": "2021-03-31T09:57:59",
        "upload_time_iso_8601": "2021-03-31T09:57:59.248122Z",
        "url": "https://files.pythonhosted.org/packages/73/8b/ab9a33341a98b2fd8755995b27421e68a8f3e79442ad902e3d154f554fd4/liftpose-0.21.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.22": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a6b9491b5c593b5ddcf42d1be17add7156824c45dfc0d428876ec5ba9a6219f5",
          "md5": "2b46fbd13d209a1766c4e58aff7e763f",
          "sha256": "4b78cdae95b7d1f6c1b3682dafcd979319ebb411a3f2dae89faf878610e6b4ba"
        },
        "downloads": -1,
        "filename": "liftpose-0.22-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "2b46fbd13d209a1766c4e58aff7e763f",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 48371,
        "upload_time": "2021-04-09T08:16:08",
        "upload_time_iso_8601": "2021-04-09T08:16:08.974606Z",
        "url": "https://files.pythonhosted.org/packages/a6/b9/491b5c593b5ddcf42d1be17add7156824c45dfc0d428876ec5ba9a6219f5/liftpose-0.22-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ed56d8538dd68175fa58d413e1ebe6c69af9982ba12027d436aee2f4d98e202a",
          "md5": "392235721bf90bdbd09fe9493853deab",
          "sha256": "9994756752d983386850fb99dab000ddf4c3bbbed1806288cd6c83495f02ef55"
        },
        "downloads": -1,
        "filename": "liftpose-0.22.tar.gz",
        "has_sig": false,
        "md5_digest": "392235721bf90bdbd09fe9493853deab",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 34565,
        "upload_time": "2021-04-09T08:16:10",
        "upload_time_iso_8601": "2021-04-09T08:16:10.877158Z",
        "url": "https://files.pythonhosted.org/packages/ed/56/d8538dd68175fa58d413e1ebe6c69af9982ba12027d436aee2f4d98e202a/liftpose-0.22.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "a6b9491b5c593b5ddcf42d1be17add7156824c45dfc0d428876ec5ba9a6219f5",
        "md5": "2b46fbd13d209a1766c4e58aff7e763f",
        "sha256": "4b78cdae95b7d1f6c1b3682dafcd979319ebb411a3f2dae89faf878610e6b4ba"
      },
      "downloads": -1,
      "filename": "liftpose-0.22-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "2b46fbd13d209a1766c4e58aff7e763f",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 48371,
      "upload_time": "2021-04-09T08:16:08",
      "upload_time_iso_8601": "2021-04-09T08:16:08.974606Z",
      "url": "https://files.pythonhosted.org/packages/a6/b9/491b5c593b5ddcf42d1be17add7156824c45dfc0d428876ec5ba9a6219f5/liftpose-0.22-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "ed56d8538dd68175fa58d413e1ebe6c69af9982ba12027d436aee2f4d98e202a",
        "md5": "392235721bf90bdbd09fe9493853deab",
        "sha256": "9994756752d983386850fb99dab000ddf4c3bbbed1806288cd6c83495f02ef55"
      },
      "downloads": -1,
      "filename": "liftpose-0.22.tar.gz",
      "has_sig": false,
      "md5_digest": "392235721bf90bdbd09fe9493853deab",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 34565,
      "upload_time": "2021-04-09T08:16:10",
      "upload_time_iso_8601": "2021-04-09T08:16:10.877158Z",
      "url": "https://files.pythonhosted.org/packages/ed/56/d8538dd68175fa58d413e1ebe6c69af9982ba12027d436aee2f4d98e202a/liftpose-0.22.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}