{
  "info": {
    "author": "Sergey Kuzmin",
    "author_email": "sergey.kuzmin@fabrique.ai",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "License :: OSI Approved :: MIT License"
    ],
    "description": "Atelier\n=======\n\nLibrary for fabrique ml pipelines development.\n\nYou can copy pipeline project examples from here\n\n.. code:: python\n\n   import fabrique_atelier\n   print(fabrique_atelier.__path__[0] + '/examples')\n\nModel decomposition steps\n-------------------------\n\nYou can find this decomposed example in /examples/fake_lightgbm\n\n1. We have samples and model inference code\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. code:: python\n\n   # load samples\n   samp_dir = './samples'\n   filenames = [f for f in os.listdir(samp_dir) if os.path.isfile(f'{samp_dir}/{f}')]\n   samples = []\n   for filename in filenames:\n       with open(f'{samp_dir}/{filename}') as fp:\n           samples.append(fp.read())\n\nsample is json string\n\n.. code:: json\n\n   {\n   \"ts\": 1622637967.6218433,\n   \"uid\": 147757848,\n   \"number\": \"00000125\",\n   \"type\": \"out\",\n   \"traffic\": {\n     \"about\": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n     \"services\": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n     \"contacts\": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n     \"roaming\": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n     \"tariffs\": [14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n     \"simcards\": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n     \"balance\": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n     \"internet\": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n     \"messaging\": [0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n     \"support\": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n   }\n\n.. code:: python\n\n   # load model\n   import lightgbm as lgb\n   bst = lgb.Booster(model_file='../model.txt')  # init model\n\n   classes = [\"about\", \"services\", \"contacts\", \"roaming\", \"tariffs\",\n              \"simcards\", \"balance\", \"internet\", \"messaging\", \"support\"]\n\n.. code:: python\n\n   # simple inference code\n   import numpy as np\n\n\n   reference_results = []  # we will use this results for tests\n\n   for sample in samples:\n       ## 1. extract features from json message\n\n       # 1.1. parse message and get features\n       mes = json.loads(sample)\n       features = np.array([mes['traffic'][cls] for cls in classes]).flatten()\n\n       ## 2. make prediction result\n\n       # 2.1 get prediction\n       pred_vals = bst.predict([features, ])[0]\n\n       # 2.2 normalize scores, get class\n       scores = pred_vals/pred_vals.sum()     \n       reason = classes[scores.argmax()]\n\n       # 2.3 make and serialize message\n       scores_dict = {cls: round(scores[i], 2) for i, cls in enumerate(classes)}\n       res = dict(ts=mes['ts'], uid=mes['uid'], number=mes['number'], classes=scores_dict, reason=reason)\n       reference_results.append(json.dumps(res, indent=2))\n\n\n\n2. Split inference into feature extraction and lightgbm prediction\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. code:: python\n\n   # splitted inference code\n\n   splitted_results = []\n\n   feature_msgs = []\n\n   for sample in samples:\n       ## 1. extract features from json message\n\n       # 1.1. parse message and get features\n       mes = json.loads(sample)\n       features = np.array([mes['traffic'][cls] for cls in classes]).flatten()\n\n       # 1.2. create intermediate message\n       data = dict(ts=mes['ts'], uid=mes['uid'], number=mes['number'], features=features.tolist())\n\n       feature_msgs.append(data)\n\n\n\n   ## 2. make prediction result\n\n   features_batch = np.array([data['features'] for data in feature_msgs])\n\n   # 2.1 get prediction\n   pred_batch = bst.predict(features_batch) # microbatch prediction\n\n   for i, mes in enumerate(feature_msgs):\n       scores = pred_batch[i]\n\n       # 2.2 normalize scores, get class\n       try:\n           scores = scores / scores.sum() # try to normalize\n       except:\n           pass\n\n       reason_num = scores.argmax()\n       reason = classes[reason_num]\n\n\n       # 2.3 make and serialize message\n       scores_dict = {cls: round(scores[i], 2) for i, cls in enumerate(classes)}\n       res = dict(ts=mes['ts'], uid=mes['uid'], number=mes['number'], classes=scores_dict, reason=reason)\n       splitted_results.append(json.dumps(res, indent=2))\n\ncheck if results are equal\n\n.. code:: python\n\n   assert set(splitted_results) == set(reference_results)\n\n3. Make pipeline.py\n~~~~~~~~~~~~~~~~~~~\n\n.. code:: python\n\n   from fabrique_atelier.actors import Pipeline, Processor\n\n   import json\n   import numpy as np\n   import lightgbm as lgb\n\n\n   class ExtractFeatures(Processor):\n       def __init__(self):\n           self.classes = [\"about\", \"services\", \"contacts\", \"roaming\", \"tariffs\",\n                           \"simcards\", \"balance\", \"internet\", \"messaging\", \"support\"]\n\n       def get_result(self, body):\n           ## 1. extract features from json message\n           # 1.1. parse message and get features\n           mes = json.loads(body['data'])\n           features = np.array([mes['traffic'][cls] for cls in self.classes]).flatten()\n           # 1.2. create intermediate message\n           data = dict(ts=mes['ts'], uid=mes['uid'], number=mes['number'], features=features.tolist())\n\n           return {'data': data}\n\n\n   class ScoringModel(Processor):\n       def __init__(self):\n           self.classes = [\"about\", \"services\", \"contacts\", \"roaming\", \"tariffs\",\n                           \"simcards\", \"balance\", \"internet\", \"messaging\", \"support\"]\n\n           self.bst = lgb.Booster(model_file='./model.txt')  # init model\n\n       def get_batch_result(self, batch):\n           ## 2. make prediction result\n           features_batch = np.array([body['data']['features'] for body in batch])\n           # 2.1 get prediction\n           pred_batch = self.bst.predict(features_batch)  # microbatch prediction\n\n           out_batch = []\n           for i, body in enumerate(batch):\n               in_data = body['data']\n               scores = pred_batch[i]\n               # 2.2 normalize scores, get class\n               try:\n                   scores = scores / scores.sum() # try to normalize\n               except:\n                   pass\n\n               reason_num = scores.argmax()\n               reason = self.classes[reason_num]\n\n               # 2.3 make and serialize message \n               scores_dict = {cls: round(scores[i], 2) for i, cls in enumerate(self.classes)}\n               out_data = dict(ts=in_data['ts'], uid=in_data['uid'], number=in_data['number'],\n                               classes=scores_dict, reason=reason)\n               out_body = dict(data=json.dumps(out_data).encode(), metrics={\"reason_num\": int(reason_num)})\n               out_batch.append(out_body)\n\n           return out_batch\n\n\n   # topology\n   pipeline = Pipeline(['extractor', 'model'])\n\n   ids = pipeline.ids\n   nodes = pipeline.nodes\n\n   nodes.extractor = ExtractFeatures.to(ids.model)\n   nodes.model = ScoringModel.to(ids.end)\n\n4. Run emulation and check results\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nrun ./dev/start_pipeline.py with this code\n\n.. code:: python\n\n   from pipeline import pipeline\n\n   # load samples\n   ## code from first decomposition step above ##\n\n   # start emulation\n   pipeline.start_emulation(samples)\n\n   # simple inference code\n   ## code from first decomposition step above ##\n\n   # load results of emulation\n   result_dir = './out/data'\n   filenames = [f for f in os.listdir(result_dir) if os.path.isfile(f'{result_dir}/{f}')]\n   results = []\n   for filename in filenames:\n       with open(f'{result_dir}/{filename}') as fp:\n           results.append(fp.read())\n\n   #check if results are equal\n   assert set(results) == set(reference_results)\n\n\n\n",
    "description_content_type": "",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "http://www.fabrique.ai",
    "keywords": "ML pipeline",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "fabrique-atelier",
    "package_url": "https://pypi.org/project/fabrique-atelier/",
    "platform": null,
    "project_url": "https://pypi.org/project/fabrique-atelier/",
    "project_urls": {
      "Homepage": "http://www.fabrique.ai"
    },
    "release_url": "https://pypi.org/project/fabrique-atelier/5.0.9/",
    "requires_dist": [
      "msgpack (==0.6.2)",
      "numpy",
      "pytest",
      "python-dateutil",
      "pyyaml"
    ],
    "requires_python": "",
    "summary": "Fabrique local environment",
    "version": "5.0.9",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 13971777,
  "releases": {
    "5.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0af277d2b1899d1902ee0f4677fdf03b5cd6a223fcd10c54ff2087501c21f74e",
          "md5": "8db62f3c4bf9e92361997dc5249d407c",
          "sha256": "de32add82fda2ece550c84ec6264ef691d22f0dcbd1261f8bac42343e7f44c17"
        },
        "downloads": -1,
        "filename": "fabrique_atelier-5.0.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "8db62f3c4bf9e92361997dc5249d407c",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 44658,
        "upload_time": "2022-01-18T14:12:08",
        "upload_time_iso_8601": "2022-01-18T14:12:08.352665Z",
        "url": "https://files.pythonhosted.org/packages/0a/f2/77d2b1899d1902ee0f4677fdf03b5cd6a223fcd10c54ff2087501c21f74e/fabrique_atelier-5.0.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "5.0.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cc83939ee5197394c835a8f9126ed63bc45348bc245ca092b8c967d3d3dd564e",
          "md5": "b21db4360e670afc9aa801e6f58b8321",
          "sha256": "bc34784acd55e079631523d7556d546c1abb86758f2e07b886d08f59f9bb82b8"
        },
        "downloads": -1,
        "filename": "fabrique_atelier-5.0.7-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "b21db4360e670afc9aa801e6f58b8321",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 44682,
        "upload_time": "2022-02-08T09:47:34",
        "upload_time_iso_8601": "2022-02-08T09:47:34.159818Z",
        "url": "https://files.pythonhosted.org/packages/cc/83/939ee5197394c835a8f9126ed63bc45348bc245ca092b8c967d3d3dd564e/fabrique_atelier-5.0.7-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "5.0.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4b4a58b737c22993504f80fa8a334541d561aa72b4e039126b1e536d07eb1204",
          "md5": "1ff53dfb3d1307a1dd56f969e75e02ac",
          "sha256": "9578e8d55ab930dffdd3d7995ba99809109f5213ccf963028cdf168e698e8ce0"
        },
        "downloads": -1,
        "filename": "fabrique_atelier-5.0.8-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "1ff53dfb3d1307a1dd56f969e75e02ac",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 3498299,
        "upload_time": "2022-05-02T06:45:56",
        "upload_time_iso_8601": "2022-05-02T06:45:56.515289Z",
        "url": "https://files.pythonhosted.org/packages/4b/4a/58b737c22993504f80fa8a334541d561aa72b4e039126b1e536d07eb1204/fabrique_atelier-5.0.8-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "5.0.9": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8450a056254f52ad0daf1e585258425c330be7007449d76bd9af514912859f26",
          "md5": "025ccd305d971bdbd706819668ea0d83",
          "sha256": "b67370fb92d07f8cff74a5c35209c4e22630104de494cae571def30c0413b9d3"
        },
        "downloads": -1,
        "filename": "fabrique_atelier-5.0.9-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "025ccd305d971bdbd706819668ea0d83",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 3497893,
        "upload_time": "2022-05-29T22:04:19",
        "upload_time_iso_8601": "2022-05-29T22:04:19.303693Z",
        "url": "https://files.pythonhosted.org/packages/84/50/a056254f52ad0daf1e585258425c330be7007449d76bd9af514912859f26/fabrique_atelier-5.0.9-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "8450a056254f52ad0daf1e585258425c330be7007449d76bd9af514912859f26",
        "md5": "025ccd305d971bdbd706819668ea0d83",
        "sha256": "b67370fb92d07f8cff74a5c35209c4e22630104de494cae571def30c0413b9d3"
      },
      "downloads": -1,
      "filename": "fabrique_atelier-5.0.9-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "025ccd305d971bdbd706819668ea0d83",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 3497893,
      "upload_time": "2022-05-29T22:04:19",
      "upload_time_iso_8601": "2022-05-29T22:04:19.303693Z",
      "url": "https://files.pythonhosted.org/packages/84/50/a056254f52ad0daf1e585258425c330be7007449d76bd9af514912859f26/fabrique_atelier-5.0.9-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}