{
  "info": {
    "author": "Daniel Probst, Matteo Manica, Yves Gaetan Nana @ IBM",
    "author_email": "dpr@zurich.ibm.com, tte@zurich.ibm.com, yna@zurich.ibm.vom",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Developers",
      "Intended Audience :: Science/Research",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "# :leaves: Biocatalysis Model\n\n*Biocatalysed Synthesis Planning using Data-driven Learning*\n\n## Table of Contents\n\n- [Abstract](#abstract)\n- [Data](#data)\n  - [ECREACT](#ecreact)\n  - [Data Sources](#data-sources)\n- [Using the Pre-trained Model](#using-the-pre-trained-model)\n- [Training your own Model](#training-your-own-model)\n  - [Setup Environment](#setup-environment)\n  - [Data Pre-processing](#data-pre-precessing)\n  - [Training using OpenNMT-py](#training-using-opennmt-py)\n  - [Evaluation](#evaluation)\n\n## Abstract\n\nEnzyme catalysts are an integral part of green chemistry strategies towards a more sustainable and resource-efficient chemical synthesis. However, the use of biocatalysed reactions in retrosynthetic planning clashes with the difficulties in predicting the enzymatic activity on unreported substrates and enzyme-specific stereo- and regioselectivity. As of now, only rule-based systems support retrosynthetic planning using biocatalysis, while initial data-driven approaches are limited to forward predictions. Here, we extend the data-driven forward reaction as well as retrosynthetic pathway prediction models based on the Molecular Transformer architecture to biocatalysis. The enzymatic knowledge is learned from an extensive data set of publicly available biochemical reactions with the aid of a new class token scheme based on the enzyme commission classification number, which captures catalysis patterns among different enzymes belonging to the same hierarchy. The forward reaction prediction model (top-1 accuracy of 49.6%), the retrosynthetic pathway (top-1 single-step round-trip accuracy of 39.6%) and the curated data set are made publicly available to facilitate the adoption of enzymatic catalysis in the design of greener chemistry processes.\n\n## Data\n\nEnzymatic reactions and the accompanying EC numbers were extracted from four databases, namely Rhea, BRENDA, PathBank, and MetaNetX and merged into a new data set, named ECREACT, containing enzyme-catalysed reactions with the respective EC number.\n\n### ECREACT\n\nThe ECREACT data set contains samples of all 7 EC classes (1: Oxidoreductases, 2: Transferases, 3: Hydrolases, 4: Lyases, 5: Isomerases, 6: Ligases, 7: Translocases) distributed as shown in (a). The distributions of the substrates and products are shown in the TMAPS (b) and (c) respectively.\n\n![Figure 2](img/fig_2.png)\n\nThe data set is available as a `.csv` file in the following format:\n\n```csv\nrxn_smiles,ec,source\nCC=O.O.O=O|1.2.3.1>>CC(=O)[O-],1.2.3.1,brenda_reaction_smiles\nCC(N)=O.O|3.5.1.4>>CC(=O)O,3.5.1.4,brenda_reaction_smiles\n...\n```\n\nThe field `rxn_smiles` is a reaction SMILES extended with the EC number on the reactant side. The reactants and the EC number are separated by a pipe `|`. The field `ec` is the EC number. Be aware that they can also contain entries such as `1.20.1.M1` or `1.14.-.-`. The field `source` describes the source database of the reaction information.\n\n**[Download ECREACT 1.0](data/ecreact-1.0.csv)**\n\n### Data Sources\n\nECREACT is composed of data from four publicly accessible databases:\n\n- [Rhea](https://www.rhea-db.org/), an expert-curated knowledgebase of chemical and transport reactions of biological interest - and the standard for enzyme and transporter annotation in UniProtKB. [:file_cabinet:](ftp://ftp.expasy.org/databases/rhea/txt/rhea-reactions.txt.gz)\n- [BRENDA](https://www.brenda-enzymes.org/), an information system representing one of the most comprehensive enzyme repositories. [:file_cabinet:](https://www.brenda-enzymes.org/download_brenda_without_registration.php)\n- [PathBank](https://pathbank.org/), an interactive, visual database containing more than 100 000 machine-readable pathways found in model organisms such as humans, mice, E. coli, yeast, and Arabidopsis thaliana. [:file_cabinet:](https://pathbank.org/downloads/pathbank_all_biopax.zip)\n- [MetaNetX](https://www.metanetx.org/), an online platform for accessing, analyzing and manipulating genome-scale metabolic networks (GSM) as well as biochemical pathways. [:file_cabinet:](https://www.metanetx.org/mnxdoc/mnxref.html)\n\nThe contributions by EC class from each of the data sources is shown in the plot below.\n\n![Figure Sources](img/fig_sources.png)\n\n## Using the Pre-trained Model\n\nWe provide a model for retrosynthetic pathway prediction pre-trained on ECREACT as part of the [IBM RXN for Chemistry](https://rxn.res.ibm.com/) platform. This model can also be used through the [Python wrapper](https://github.com/rxn4chemistry/rxn4chemistry) for the IBM RXN for Chemistry API. You can get a free API key [here](https://rxn.res.ibm.com/rxn/user/profile).\n\n```python\napi_key = 'API_KEY'\nfrom rxn4chemistry import RXN4ChemistryWrapper\n\nrxn4chemistry_wrapper = RXN4ChemistryWrapper(api_key=api_key)\n\n# NOTE: you can create a project or set an esiting one using:\n# rxn4chemistry_wrapper.set_project('PROJECT_ID')\nrxn4chemistry_wrapper.create_project('test_wrapper')\nprint(rxn4chemistry_wrapper.project_id)\n\nresponse = rxn4chemistry_wrapper.predict_automatic_retrosynthesis(\n    'OC1C(O)C=C(Br)C=C1', ai_model='enzymatic-2021-04-16'\n)\nresults = rxn4chemistry_wrapper.get_predict_automatic_retrosynthesis_results(\n    response['prediction_id']\n)\n\nprint(results['status'])\n\n# NOTE: upon 'SUCCESS' you can inspect the predicted retrosynthetic paths.\nprint(results['retrosynthetic_paths'][0])\n```\n\n## Training your own Model\n\n### Setup Environment\n\nAs not all dependencies are available from PyPI for all platforms, we suggest you create a conda environment from the supplied [conda.yml](conda.yml):\n\n```bash\nconda env create -f conda.yml\nconda activate rxn-biocatalysis-tools\n```\n\nAlternatively, :leaves: RXN Biocatalysis Tools are available as a PyPI package and can be installed usining pip; however, not all dependencies will be installed depending on your platform.\n\n```bash\npip install rxn_biocatalysis_tools\n```\n\n### Data Pre-processing\n\nThe :leaves: RXN Biocatalysis Tools Python package installs a script that can be used to preprocess reaction data. Reaction data can be combined, filtered, or augmented as explained in the usage documentation below. After these initial steps, the data is tokenized and split into training, validation, and testing `src` (reactants + EC) and `tgt` (product/s) files. The output data structure generated by the script is the following, depending on the options set.\n\n```bash\n.\n└── experiments\n    ├── 1\n    │   ├── combined.txt\n    │   ├── src-test.txt\n    │   ├── src-train.txt\n    │   ├── src-valid.txt\n    │   ├── tgt-test.txt\n    │   ├── tgt-train.txt\n    │   └── tgt-valid.txt\n    ├── 2\n    │   ├── combined.txt\n    │   ├── src-test.txt\n    │   ├── src-train.txt\n    │   ├── src-valid.txt\n    │   ├── tgt-test.txt\n    │   ├── tgt-train.txt\n    │   └── tgt-valid.txt\n    └── 3\n        ├── combined.txt\n        ├── src-test.txt\n        ├── src-train.txt\n        ├── src-valid.txt\n        ├── tgt-test.txt\n        ├── tgt-train.txt\n        └── tgt-valid.txt\n```\n\nUsage of the script:\n\n```bash\nrbt-preprocess INPUT_FILE ... OUTPUT_DIRECTORY [--remove-patterns=FILE_PATH] [--remove-molecules=FILE_PATH] [--ec-level=LEVEL; default=3] [-max-products=MAX_PRODUCTS; default=1] [--min-atom-count=MIN_ATOM_COUNT; default=4] [--bi-directional] [--split-products] \n```\n\n| Argument / Option   | Example                   | Description                                                  | Default    |\n|---------------------|---------------------------|--------------------------------------------------------------|------------|\n| INPUT_FILE ...      | file1.csv file2.csv       | File(s) containing enzymatic reaction SMILES<sup>1</sup>     |            |\n| OUTPUT_DIRECTORY    | /output/directory/        | The directory to which output files will be written          |            |\n| --remove-patterns   | patterns.txt              | SMARTS patterns for molecules to be removed<sup>2</sup>      |            |\n| --remove-molecules  | molecules.txt             | Molecule SMILES to be removed<sup>3</sup>                    |            |\n| --ec-level          | --ec-level 1 --ec-level 2 | The number of EC levels to be exported, can be repreated     | 3          |\n| --max-products      | --max-products 1          | The max number of products (rxns with more are dropped)      | 1          |\n| --min-atom-count    | --min-atom-count 4        | The min atom count (smaller molecules are removed)           | 4          |\n| --bi-directional    | --bi-directional          | Whether to create the inverse of every reaction<sup>4</sup>  |            |\n| --split-products    | --split-products          | Whether to split reactions with multiple prodcuts<sup>5</sup>|            |\n\n<sup>1</sup>Example of an enzymatic reaction SMILES: `CC(N)=O.O|3.5.1.4>>CC(=O)O`<br />\n<sup>2</sup>See [patterns.txt](data/patterns.txt) for an example<br />\n<sup>3</sup>See [molecules.txt](data/molecules.txt) for an example<br />\n<sup>4</sup>Example: For the reaction `CC(N)=O.O|3.5.1.4>>CC(=O)O`, the reaction `CC(=O)O|3.5.1.4>>CC(N)=O.O` will be added<br />\n<sup>5</sup>Example: The reaction `A|3.5.1.4>>B.C` is split into reactions `A|3.5.1.4>>B` and `A|3.5.1.4>>C`<br />\n\n### Training using OpenNMT-py\n\nThe first step in the OpenNMT is to run `onmt_preprocess` for both the forward and backward models. In the examples below, the data with 3 EC-levels is used. You will probably have to adapt the paths, depending on your directory structure and platform.\n\nThe pre-processed USPTO files can be found [here](https://github.com/rxn4chemistry/OpenNMT-py/tree/carbohydrate_transformer/data/uspto_dataset).\n\n``` bash\nDATASET=data/uspto_dataset\nDATASET_TRANSFER=experiments/3\n\n# forward\nonmt_preprocess -train_src \"${DATASET}/src-train.txt\" \"${DATASET_TRANSFER}/src-train.txt\" \\\n    -train_tgt \"${DATASET}/tgt-train.txt\" \"${DATASET_TRANSFER}/tgt-train.txt\" -train_ids uspto transfer \\\n    -valid_src \"${DATASET}/src-valid.txt\" -valid_tgt \"${DATASET_TRANSFER}/tgt-valid.txt\" \\\n    -save_data \"preprocessing/multitask_forward\" \\\n    -src_seq_length 3000 -tgt_seq_length 3000 \\\n    -src_vocab_size 3000 -tgt_vocab_size 3000 \\\n    -share_vocab\n\n# backward\nonmt_preprocess -train_src \"${DATASET}/tgt-train.txt\" \"${DATASET_TRANSFER}/tgt-train.txt\" \\\n    -train_tgt \"${DATASET}/src-train.txt\" \"${DATASET_TRANSFER}/src-train.txt\" -train_ids uspto transfer \\\n    -valid_src \"${DATASET}/tgt-valid.txt\" -valid_tgt \"${DATASET_TRANSFER}/src-valid.txt\" \\\n    -save_data \"preprocessing/multitask_backward\" \\\n    -src_seq_length 3000 -tgt_seq_length 3000 \\\n    -src_vocab_size 3000 -tgt_vocab_size 3000 \\\n    -share_vocab\n```\n\nOnce the OpenNMT pre-preprocessing has finished, the actual training can be started:\n\n```bash\n# if forward\nDATASET=\"preprocessing/multitask_forward\"\nOUTDIR=\"/model/multitask_forward\"\nLOGDIR=\"/logs/forward\"\n# end if\n\n# if backward\nDATASET=\"preprocessing/multitask_backward\"\nOUTDIR=\"model/multitask_backward\"\nLOGDIR=\"logs/backward\"\n# end if\n\nW1=9\nW2=1\n\nonmt_train -data ${DATASET} \\\n    -save_model ${OUTDIR} \\\n    -data_ids uspto transfer --data_weights ${W1} ${W2} \\\n    -seed 42 -gpu_ranks 0 \\\n    -train_steps 250000 -param_init 0 \\\n    -param_init_glorot -max_generator_batches 32 \\\n    -batch_size 6144 -batch_type tokens \\\n    -normalization tokens -max_grad_norm 0  -accum_count 4 \\\n    -optim adam -adam_beta1 0.9 -adam_beta2 0.998 -decay_method noam \\\n    -warmup_steps 8000 -learning_rate 2 -label_smoothing 0.0 \\\n    -layers 4 -rnn_size  384 -word_vec_size 384 \\\n    -encoder_type transformer -decoder_type transformer \\\n    -dropout 0.1 -position_encoding -share_embeddings  \\\n    -global_attention general -global_attention_function softmax \\\n    -self_attn_type scaled-dot -heads 8 -transformer_ff 2048 \\\n    --tensorboard --tensorboard_log_dir ${LOGDIR}\n```\n\n### Evaluation\n\nThe test set is evaluated using `onmt_translate`. Three new files are generated:\n\n- `tgt-pred.txt` (forward prediction)\n- `src-pred.txt` (backward prediction)\n- `tgt-pred-rtrp.txt` (roundtriip prediction, a backward prediction followed by a forward prediction)\n\nBefore the roundtrip prediction, the SMILES in `src-pred.txt` should be standardized using the script `rbt-preprocess`. The script does not edit the file in place, so good practise is to rename `src-pred.txt` to `src-pred-noncanon.txt` and then run:\n\n```bash\nrbt-canonicalize src-pred-noncanon.txt src-pred.txt\n```\n\nExample evaluation scripts:\n\n```bash\n# forward prediction\n\nDATASET_TRANSFER=\"experiments/3\"\n\n# Get the newest file from the model directory\nMODEL=$(ls model/multitask_forward*.pt -t | head -1)\n\nonmt_translate -model \"${MODEL}\" \\\n    -src \"${DATASET_TRANSFER}/src-test.txt\" \\\n    -output \"${DATASET_TRANSFER}/tgt-pred.txt\" \\\n    -n_best 10 -beam_size 10 -max_length 300 -batch_size 64 \\\n    -gpu 0\n```\n\n```bash\n# backward prediction\n\nDATASET_TRANSFER=\"experiments/3\"\n\n# Get the newest file from the model directory\nMODEL=$(ls model/multitask_backward*.pt -t | head -1)\n\nonmt_translate -model \"${MODEL}\" \\\n    -src \"${DATASET_TRANSFER}/tgt-test.txt\" \\\n    -output \"${DATASET_TRANSFER}/src-pred.txt\" \\\n    -n_best 10 -beam_size 10 -max_length 300 -batch_size 64 \\\n    -gpu 0\n```\n\n```bash\n# roundtrip prediction\n\nDATASET_TRANSFER=\"experiments/3\"\n\n# Get the newest file from the model directory\nMODEL=$(ls model/multitask_forward*.pt -t | head -1)\n\nonmt_translate -model \"${MODEL}\" \\\n    -src \"${DATASET_TRANSFER}/src-pred.txt\" \\\n    -output \"${DATASET_TRANSFER}/tgt-pred-rtrp.txt\" \\\n    -n_best 1 -beam_size 5 -max_length 300 -batch_size 64 \\\n    -gpu 0\n```\n\nThe :leaves: RXN Biocatalysis Tools PyPI package contains an evaluation script that calculates accuracies from the files produced above. For these examples, the `INPUT_FOLDER` is the same as `DATASET_TRANSFER`, `--n-best-fw`, `--top-n-fw`, `--top-n-bw`, `--top-n-rtr` are all set to `10`.\n\n```bash\nrbt-evaluate INPUT_FOLDER --name=NAME [--n-best-fw=N_BEST_FW; default=5] [--n-best-bw=N_BEST_BW; default=10] [--n-best-rtr=N_BEST_RTR; default=1] [--top-n-fw=TOP_N_FW; default=1] [--top-n-fw=TOP_N_FW; default=1] [--top-n-bw=TOP_N_BW; default=1] [--top-n-rtr=TOP_N_RTR; default=1] [--top-n-range] [--isomeric-smiles | --no-isomeric-smiles; default:--isomeric-smiles]\n```\n\n| Argument / Option   | Example                   | Description                                                  | Default    |\n|---------------------|---------------------------|--------------------------------------------------------------|------------|\n| INPUT_FOLDER        | /input/directory/         | The folder containing the src and tgt files                  |            |\n| --name              | experiment-3              | The name of the output evaluation csv file                   |            |\n| --n-best-fw         | --n-best-fw 10            | The number of calculated tgt predictions per src             | 5          |\n| --n-best-bw         | --n-best-bw 10            | The number of calculated src predictions per tgt             | 10         |\n| --n-best-rtr        | --n-best-rtr 1            | The number of calculated (roundtrip) tgt predictions per predicted src| 1          |\n| --top-n-fw          | --top-n-fw 10             | The number of forward predictions to consider in the evaluation       | 1          |\n| --top-n-bw          | --top-n-bw 10             | The number of backward predictions to consider in the evaluation      | 1          |\n| --top-n-rtr         | --top-n-rtr 10            | The number of roundtrip predictions to consider in the evaluation     | 1          |\n| --top-n-range       | --top-n-range             | Whether to consider the forward, backward, and roundtrip predictions *up to* the respective top-n numbers in the evaluation |            |\n| --isomeric-smiles   | --isomeric-smiles         | Do **not** ignore stereochemistry during the evaluation      |            |\n| --no-isomeric-smiles| --no-isomeric-smiles      | Ignore stereochemistry during the evaluation                 |            |\n\nThe evaluation will produce multiple new files in `INPUT_FOLDER`: A `.csv` file with the fields `metric`, `type`, `top`, `ec`, and `value`; and multiple files containing correct and incorrect forward, backward, and roundtrip predictions for each top-n. In addition, the accuracy of *only* predicting the EC number is calculated and the respective files written out as well.\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/rxn4chemistry/biocatalysis-model",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "rxn-biocatalysis-tools",
    "package_url": "https://pypi.org/project/rxn-biocatalysis-tools/",
    "platform": "",
    "project_url": "https://pypi.org/project/rxn-biocatalysis-tools/",
    "project_urls": {
      "Homepage": "https://github.com/rxn4chemistry/biocatalysis-model"
    },
    "release_url": "https://pypi.org/project/rxn-biocatalysis-tools/1.0.1/",
    "requires_dist": [
      "pytest (==6.1.2) ; extra == 'dev'",
      "pytest-cov (==2.10.1) ; extra == 'dev'",
      "flake8 (==3.8.4) ; extra == 'dev'",
      "black (==20.8b1) ; extra == 'dev'",
      "mypy (==0.782) ; extra == 'dev'"
    ],
    "requires_python": ">=3.6",
    "summary": "Tools for pre-processing and evaluating data associated with biocatalysis models.",
    "version": "1.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12931602,
  "releases": {
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cb00e2cc6adb9b53bb55766abf5de12dcbf271d2082a2053f148beec5b0f2b11",
          "md5": "b18f0f4f37924825b24edef9a8188f9a",
          "sha256": "39b472b2f5c06640cc71ea3817d3476f67f7623805f0ca9e6012b0b9b0ed9ace"
        },
        "downloads": -1,
        "filename": "rxn_biocatalysis_tools-1.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "b18f0f4f37924825b24edef9a8188f9a",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 25135,
        "upload_time": "2022-02-17T21:52:44",
        "upload_time_iso_8601": "2022-02-17T21:52:44.356642Z",
        "url": "https://files.pythonhosted.org/packages/cb/00/e2cc6adb9b53bb55766abf5de12dcbf271d2082a2053f148beec5b0f2b11/rxn_biocatalysis_tools-1.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b9467e4d5cb30682f20c8ab77b636d3d12343e30ec4275a15fb8133f79911d2e",
          "md5": "4f51cb1411a1df962b21ef52e45562ee",
          "sha256": "85452b9f9ea13588ddd27b5a34d04e80fc40b3532e3b11bb1385a224cee0a3c2"
        },
        "downloads": -1,
        "filename": "rxn-biocatalysis-tools-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "4f51cb1411a1df962b21ef52e45562ee",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 25935,
        "upload_time": "2022-02-17T21:52:46",
        "upload_time_iso_8601": "2022-02-17T21:52:46.421770Z",
        "url": "https://files.pythonhosted.org/packages/b9/46/7e4d5cb30682f20c8ab77b636d3d12343e30ec4275a15fb8133f79911d2e/rxn-biocatalysis-tools-1.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "58915dd01edbae7008a37b7ae384ce4568282ee36e101b63974442a75fcc3eb9",
          "md5": "f482450586261971927c51e6fae245c6",
          "sha256": "77ef0cffc8579bfc434d43895a4fc3184da076df9e158f33bed2b409c5b8f2e8"
        },
        "downloads": -1,
        "filename": "rxn_biocatalysis_tools-1.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f482450586261971927c51e6fae245c6",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 25141,
        "upload_time": "2022-02-17T21:58:59",
        "upload_time_iso_8601": "2022-02-17T21:58:59.110973Z",
        "url": "https://files.pythonhosted.org/packages/58/91/5dd01edbae7008a37b7ae384ce4568282ee36e101b63974442a75fcc3eb9/rxn_biocatalysis_tools-1.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b598f901748a8ed352db0dd082c94b34e57bbea439c93f246571a586c3ca5e93",
          "md5": "052d26cc4b471b5e2e070d4ed1b06fe9",
          "sha256": "58f52291a5c611f1b76f921b69bb8d979151f443e765ae7c51e9374b3d026769"
        },
        "downloads": -1,
        "filename": "rxn-biocatalysis-tools-1.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "052d26cc4b471b5e2e070d4ed1b06fe9",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 25972,
        "upload_time": "2022-02-17T21:59:00",
        "upload_time_iso_8601": "2022-02-17T21:59:00.564888Z",
        "url": "https://files.pythonhosted.org/packages/b5/98/f901748a8ed352db0dd082c94b34e57bbea439c93f246571a586c3ca5e93/rxn-biocatalysis-tools-1.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "58915dd01edbae7008a37b7ae384ce4568282ee36e101b63974442a75fcc3eb9",
        "md5": "f482450586261971927c51e6fae245c6",
        "sha256": "77ef0cffc8579bfc434d43895a4fc3184da076df9e158f33bed2b409c5b8f2e8"
      },
      "downloads": -1,
      "filename": "rxn_biocatalysis_tools-1.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "f482450586261971927c51e6fae245c6",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 25141,
      "upload_time": "2022-02-17T21:58:59",
      "upload_time_iso_8601": "2022-02-17T21:58:59.110973Z",
      "url": "https://files.pythonhosted.org/packages/58/91/5dd01edbae7008a37b7ae384ce4568282ee36e101b63974442a75fcc3eb9/rxn_biocatalysis_tools-1.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "b598f901748a8ed352db0dd082c94b34e57bbea439c93f246571a586c3ca5e93",
        "md5": "052d26cc4b471b5e2e070d4ed1b06fe9",
        "sha256": "58f52291a5c611f1b76f921b69bb8d979151f443e765ae7c51e9374b3d026769"
      },
      "downloads": -1,
      "filename": "rxn-biocatalysis-tools-1.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "052d26cc4b471b5e2e070d4ed1b06fe9",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 25972,
      "upload_time": "2022-02-17T21:59:00",
      "upload_time_iso_8601": "2022-02-17T21:59:00.564888Z",
      "url": "https://files.pythonhosted.org/packages/b5/98/f901748a8ed352db0dd082c94b34e57bbea439c93f246571a586c3ca5e93/rxn-biocatalysis-tools-1.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}