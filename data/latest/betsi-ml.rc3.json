{
  "info": {
    "author": "",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 2 - Pre-Alpha",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: GNU Lesser General Public License v3 (LGPLv3)",
      "Programming Language :: Python :: 3"
    ],
    "description": "# betsi\n\n[![pipeline status](https://gitlab.com/librespacefoundation/polaris/betsi/badges/master/pipeline.svg)](https://gitlab.com/librespacefoundation/polaris/betsi/commits/master)\n[![coverage report](https://gitlab.com/librespacefoundation/polaris/betsi/badges/master/coverage.svg)](https://gitlab.com/librespacefoundation/polaris/betsi/commits/master)\n\n---\n\n**B**ehaviour **E**xtraction for **T**ime-**S**eries **I**nvestigation using Deep Learning\n\nDeeplearning module for event detection in time series through behavioural extraction.\n\n---\n\n## What is it all about?\n\nAnomalies are any events outside the nominal behaviour of a system. They are\nsometimes characterised by sudden large swings in the values of a particular\nparameter and sometimes are distributed changes across multiple parameters and\ncan be catastrophic to the system. Traditionally, anomalies were detected by\nmonitoring each parameter, superimposing the graphs for each sub-system and\nfinding \"out-of-normal\" behaviour manually.\n\nThis project aims to implement a state of the art model based on the paper _\"Time\nSeries Segmentation through Automatic Feature Learning\"_ by Lee, Wei-Han, et al.\nto automatically detect anomalies without any manual intervention. To do so, the\nproject provides tools to train deep-learning models on Tensorflow and run\nthrough post-processing \"prediction\" steps which use the condensed\nrepresentations produced by the deep-learning model to detect change in\nbehaviour and further on anomalous events.\n\nThe project mainly has three steps which ensure good performance of the anomaly\ndetection.\n\n 1. **Preprocessing**: The input timeseries data (resampled version of some continuous\ndata) is first normalized and then grouped into sets of `window_size` timesteps\nseparated by a `stride` movement in time. What this essentially does is increase\nthe amount of data we have and allow us to capture interactions between continuous\ntimesteps.\n\n    Consider a case where you have 11 sensors providing readings. If you\ntake a `window_size` of 3, readings at time index 1, 2, and 3 for all 11 sensors\nwill be stack in one vector.\nThat means that you will have 33 columns at every timestep. If your stride\nis 2, your second group (vector) would start at 1+2=3rd timestep (3, 4, 5),\nthird group at 5th timestep (5, 6, 7) and so on.\n\n 1. **Model**: The model we use to create the concise representation is called an\nautoencoder. An autoencoder is a neural network whose inputs and outputs are\nthe exact same values but the intermediate layers gradually reduce the amount\nof information. The input data is compressed to the smallest representation\npossible, at the bottleneck layer, that still permits the following layers to\nreproduce the original input with good fidelity.\nIt is essentially a model with an encoder (input -> bottleneck layer) which\n\"encodes\" the data into a smaller representation and a decoder (bottleneck ->\noutput) which \"decodes\" the encoded representation to get the original data.\n\n 1. **Predictors**: The predictions from the bottleneck layer are then compared across\nmultiple rows (groups of timestamps) with the help of a distance (single value)\nusing L2 norm (which calculates the square of difference in values). The group of\ndistances are then compared against their average to detect events (possible anomaly).\nA key parameter here is the `threshold` or `noise_margin_per` which defines how much\nabove the averge the distance needs to be to be called an event. This helps filter\nout random fluctuations in data (since the distance value is not a constant for all\nnominal cases)\n\n---\n\n## Project Structure\n\n``` BASH\nsrc/\n    betsi/\n        models.py // To build and train the Tensorflow model\n        predictors.py // To predict/detect anomalies based on the output from the Tensorflow model\n        preprocessors.py // To preprocess the input data through normalization and filtering\ntests/\n    test_models.py // Test for models\n    test_predictors.py // Test for predictors\n    test_preprocessors.py // Test for preprocessors\n```\n\n---\n\n## Installation through pip\n\n``` BASH\npip install betsi-ml\n```\n\nIt is recommended that you install the project in a virtual environment as it\nis still under development.\n\nTo create a virtual environment and install in it, run:\n\n``` BASH\npython -m venv .venv\nsource .venv/bin/activate\npythom -m pip install betsi-ml\n```\n\n---\n\n## Installation from source\n\n```bash\n# Clone from source\n$ git clone https://gitlab.com/librespacefoundation/polaris/betsi.git\n\n# Switch to the directory\n$ cd betsi\n\n# Create and switch to a virtual environment\n$ python3 -m venv .venv\n$ source .venv/bin/activate\n\n# To install a non-editable version\n(.venv) $ python3 setup.py install\n\n# To install an editable version\n(.venv) $ python3 -m pip install -e .\n```\n\n---\n\n## Usage\n\n### **Preprocessing the input data**\n\n``` PYTHON\n(.venv) $ python3\n>>> from betsi import models, preprocessors, predictors\n\n# To apply preprocessing on data\n# Step 1: Normalize the data\n>>> normalizer, normalized_data = preprocessors.normalize_all_data(data)\n# Step 2: Convert it to columns using fixed stride and window size\n>>> converted_data = preprocessors.convert_to_column(normalized_data, window_size=3, stride=2)\n```\n\n**A few remarks regarding preprocessing**:\n\n_normalizer_ is an instance of `sklearn transformer`. It has an inverse method, `normalizer.inverse_transform`, used to \"un-normalize\" the data!\n\n_preprocessors_ also has a `convert_from_column` method to undo the change made by `convert_to_column`.\n\nA combination of these two methods can be used to remove the preprocessing from the data (or from the model predictions) as follows:\n\n``` PYTHON\n# To remove preprocessing from data\n>>> normalized_data = preprocessors.convert_from_column(converted_data, window_size=3, stride=2)\n>>> recovered_data = normalizer.inverse_transform(converted_data)\n```\n\n### **Creating the model**\n\nBefore we create a model, we need to decide the structure of the auto-encoder, i.e.\nthe layer sizes, activations for each layer.\n\nSince the architecture is symmetric and the number of layers (n) are odd (assumed),\nwe only need to specify the layer dims for the first `(n+1)/2` layers.\n\nThe activation for the last `n-1` layers (barring the first input layer) need to be\nspecified. If the activations are not specified, it is assumed to be ReLU for every\nlayer.\n\nThis is summed up with a simple diagram:\n\n``` PYTHON\nlayer_dims[0]\n    o                            o\n    o    o  layer_dims[-1]  o    o\n    o    o       o          o    o\n    o    o       o          o    o\n    o    o                  o    o\n    o activations[0]             o\n                                activations[-1]\n```\n\nYou also need to decide on your optimizer (`\"adam\"` is preferred), the loss\n(`\"mean_squared_error\"`) and metrics to monitor (`\"[MSE]\"`)\n\nThe python code (assuming you have the `layer_dims` and `activations` variables\nready, have preprocessed your data to get `converted_data` and have decided on your\n`optimizer`, `loss` and `metrics`) to create and train the model is as follows:\n\n``` PYTHON\n# ae_model = auto_encoder_model\n# en_model = encoder_model\n# de_model = decoder_model\n# Both the encoder and decoder models are extracted from the autoecoder\n# model and need not be trained separately.\n>>> ae_model, en_model, de_model = models.custom_autoencoder(layer_dims, activations=activations)\n# Compile the model for training\n>>> ae_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n>>> en_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n>>> de_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n\n>>> train_data, test_data = train_test_split(\n        converted_data,\n        test_size=0.33, # 33% of data is for testing\n        shuffle=False, # We disable shuffling since order matters (time)\n    )\n\n# You can also play around with the batch_size and epochs and enable\n# early_stopping based on your needs\n>>> history = ae_model.fit(train_data, train_data, batch_size=32, epochs=20)\n\n# To test the model to check if it has overfit, you can run:\n>>> ae_model.evaluate(test_data, test_data, batch_size=32)\n# This will return the test loss and the metrics which can be compared against\n# the training values for the same\n```\n\n### **Predicting anomalies**\n\nNow that we have our trained model and its input data (along with the normalizer,\nwindow_size and stride to create new input data whernever we want), we can now\npredict anomalies.\n\n``` PYTHON\n# Step 1: Predict the \"bottleneck\" layer representation for the input data\n>>> data_rep = encoder_model.predict(test_data)\n\n# Step 2: Measure the distance between consecutive timestamps. This will be\n# the metric to detect anomalies. Distance here refers to the L2 norm.\n>>> distance_list = []\n>>> for row_no in range(data_rep.shape[0] - 1):\n>>>     distance_list.append(\n>>>         distance_measure(data_rep[row_no], data_rep[row_no + 1]))\n\n# Step 3: Detect the events. We have a noise_margin_per variable to say\n# how much (in percentage) should the value be above the average to be\n# considered the event. Try playing around with this to find the best value!\n>>> noise_margin_per = 150 # 2.5 x the average ie 150% more than average\n>>> events = get_events(distance_list, threshold=noise_margin_per)\n# events contains all the indices where events occurred\n```\n\n---\n\n## Reference\n\nThis project is based on the paper ‘Time Series Segmentation through Automatic Feature Learning’\nby Lee, Wei-Han, et al.\n\nRefer: ArXiv:1801.05394 [Cs, Stat], Jan. 2018. arXiv.org, <http://arxiv.org/abs/1801.05394>\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://gitlab.com/deepchaos/betsi",
    "keywords": "machine learning, time series, feature extraction",
    "license": "LICENSE",
    "maintainer": "",
    "maintainer_email": "",
    "name": "betsi-ml",
    "package_url": "https://pypi.org/project/betsi-ml/",
    "platform": "",
    "project_url": "https://pypi.org/project/betsi-ml/",
    "project_urls": {
      "Homepage": "https://gitlab.com/deepchaos/betsi"
    },
    "release_url": "https://pypi.org/project/betsi-ml/0.0.4/",
    "requires_dist": [
      "numpy",
      "pandas",
      "scikit-learn",
      "tensorflow (>=2.0)"
    ],
    "requires_python": ">=3",
    "summary": "Behaviour Extraction for Time-Series Investigation",
    "version": "0.0.4",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 9771813,
  "releases": {
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c539fcef2cd925e125b4b872a775e5e3953955618ca60d3e214d9a102cba4e23",
          "md5": "a8c328acbd6206f91a78d6877b9658c5",
          "sha256": "682dbdb67fe5bfacdb4cbf5298ad9e739e29e5e7b1c9c208c402c4346783fd14"
        },
        "downloads": -1,
        "filename": "betsi_ml-0.0.2-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "a8c328acbd6206f91a78d6877b9658c5",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": ">=3",
        "size": 9340,
        "upload_time": "2020-08-22T16:17:19",
        "upload_time_iso_8601": "2020-08-22T16:17:19.253359Z",
        "url": "https://files.pythonhosted.org/packages/c5/39/fcef2cd925e125b4b872a775e5e3953955618ca60d3e214d9a102cba4e23/betsi_ml-0.0.2-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e44e97d39125d010fafef693a8df0b3227bc7b056e7530e27d2bf1de1ea04322",
          "md5": "7894919b7b9aa3ed28e315a12c1b033d",
          "sha256": "e5aeed80e7620b33cbab7b7413d1081e1147aeed4dbb80132c153e872d686c1e"
        },
        "downloads": -1,
        "filename": "betsi_ml-0.0.3-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "7894919b7b9aa3ed28e315a12c1b033d",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": ">=3",
        "size": 9514,
        "upload_time": "2020-10-05T15:48:21",
        "upload_time_iso_8601": "2020-10-05T15:48:21.562825Z",
        "url": "https://files.pythonhosted.org/packages/e4/4e/97d39125d010fafef693a8df0b3227bc7b056e7530e27d2bf1de1ea04322/betsi_ml-0.0.3-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "973b7e29d3f0c7fda2509926aa5a25d6c882fd40120ce2c6e4b94a5b44da04b2",
          "md5": "c91b705cdfce6ed442eb4a19ffe6a857",
          "sha256": "a807f0189eb433076cdf6d25b03c57b8c5322a710b4257007500508876676dcf"
        },
        "downloads": -1,
        "filename": "betsi_ml-0.0.4-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "c91b705cdfce6ed442eb4a19ffe6a857",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": ">=3",
        "size": 13511,
        "upload_time": "2021-03-15T09:14:07",
        "upload_time_iso_8601": "2021-03-15T09:14:07.263616Z",
        "url": "https://files.pythonhosted.org/packages/97/3b/7e29d3f0c7fda2509926aa5a25d6c882fd40120ce2c6e4b94a5b44da04b2/betsi_ml-0.0.4-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "973b7e29d3f0c7fda2509926aa5a25d6c882fd40120ce2c6e4b94a5b44da04b2",
        "md5": "c91b705cdfce6ed442eb4a19ffe6a857",
        "sha256": "a807f0189eb433076cdf6d25b03c57b8c5322a710b4257007500508876676dcf"
      },
      "downloads": -1,
      "filename": "betsi_ml-0.0.4-py2.py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "c91b705cdfce6ed442eb4a19ffe6a857",
      "packagetype": "bdist_wheel",
      "python_version": "py2.py3",
      "requires_python": ">=3",
      "size": 13511,
      "upload_time": "2021-03-15T09:14:07",
      "upload_time_iso_8601": "2021-03-15T09:14:07.263616Z",
      "url": "https://files.pythonhosted.org/packages/97/3b/7e29d3f0c7fda2509926aa5a25d6c882fd40120ce2c6e4b94a5b44da04b2/betsi_ml-0.0.4-py2.py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}