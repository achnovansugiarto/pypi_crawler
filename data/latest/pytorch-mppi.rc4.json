{
  "info": {
    "author": "",
    "author_email": "Sheng Zhong <zhsh@umich.edu>",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3 :: Only"
    ],
    "description": "# PyTorch MPPI Implementation\nThis repository implements Model Predictive Path Integral (MPPI) \nwith approximate dynamics in pytorch. MPPI typically requires actual\ntrajectory samples, but [this paper](https://ieeexplore.ieee.org/document/7989202/)\nshowed that it could be done with approximate dynamics (such as with a neural network)\nusing importance sampling.\n\nThus it can be used in place of other trajectory optimization methods\nsuch as the Cross Entropy Method (CEM), or random shooting.\n\n# Installation\n```shell\npip install pytorch-mppi\n```\nfor autotuning hyperparameters, install with\n```shell\npip install pytorch-mppi[tune]\n```\n\nfor running tests, install with\n```shell\npip install pytorch-mppi[test]\n```\nfor development, clone the repository then install in editable mode\n```shell\npip install -e .\n```\n\n# Usage\nSee `tests/pendulum_approximate.py` for usage with a neural network approximating\nthe pendulum dynamics. See the `not_batch` branch for an easier to read\nalgorithm. Basic use case is shown below\n\n```python\nfrom pytorch_mppi import MPPI\n\n# create controller with chosen parameters\nctrl = MPPI(dynamics, running_cost, nx, noise_sigma, num_samples=N_SAMPLES, horizon=TIMESTEPS,\n            lambda_=lambda_, device=d,\n            u_min=torch.tensor(ACTION_LOW, dtype=torch.double, device=d),\n            u_max=torch.tensor(ACTION_HIGH, dtype=torch.double, device=d))\n\n# assuming you have a gym-like env\nobs = env.reset()\nfor i in range(100):\n    action = ctrl.command(obs)\n    obs, reward, done, _ = env.step(action.cpu().numpy())\n```\n\n# Requirements\n- pytorch (>= 1.0)\n- `next state <- dynamics(state, action)` function (doesn't have to be true dynamics)\n    - `state` is `K x nx`, `action` is `K x nu`\n- `cost <- running_cost(state, action)` function\n    - `cost` is `K x 1`, state is `K x nx`, `action` is `K x nu`\n\n# Features\n- Approximate dynamics MPPI with importance sampling\n- Parallel/batch pytorch implementation for accelerated sampling\n- Control bounds via sampling control noise from rectified gaussian \n- Handle stochastic dynamic models (assuming each call is a sample) by sampling multiple state trajectories for the same\naction trajectory with `rollout_samples`\n- \n# Parameter tuning and hints\n`terminal_state_cost` - function(state (K x T x nx)) -> cost (K x 1) by default there is no terminal\ncost, but if you experience your trajectory getting close to but never quite reaching the goal, then\nhaving a terminal cost can help. The function should scale with the horizon (T) to keep up with the\nscaling of the running cost.\n\n`lambda_` - higher values increases the cost of control noise, so you end up with more\nsamples around the mean; generally lower values work better (try `1e-2`)\n\n`num_samples` - number of trajectories to sample; generally the more the better.\nRuntime performance scales much better with `num_samples` than `horizon`, especially\nif you're using a GPU device (remember to pass that in!)\n\n`noise_mu` - the default is 0 for all control dimensions, which may work out\nreally poorly if you have control bounds and the allowed range is not 0-centered.\nRemember to change this to an appropriate value for non-symmetric control dimensions.\n\n## Autotune\nfrom version 0.5.0 onwards, you can automatically tune the hyperparameters.\nA convenient tuner compatible with the popular [ray tune](https://docs.ray.io/en/latest/tune/index.html) library\nis implemented. You can select from a variety of cutting edge black-box optimizers such as \n[CMA-ES](https://github.com/CMA-ES/pycma), [HyperOpt](http://hyperopt.github.io/hyperopt/),\n[fmfn/BayesianOptimization](https://github.com/fmfn/BayesianOptimization), and so on.\nSee `tests/auto_tune_parameters.py` for an example. A tutorial based on it follows.\n\nFirst we create a toy 2D environment to do controls on and create the controller with some\ndefault parameters.\n```python\nimport torch\nfrom pytorch_mppi import MPPI\n\ndevice = \"cpu\"\ndtype = torch.double\n\n# create toy environment to do on control on (default start and goal)\nenv = Toy2DEnvironment(visualize=True, terminal_scale=10)\n\n# create MPPI with some initial parameters\nmppi = MPPI(env.dynamics, env.running_cost, 2,\n            terminal_state_cost=env.terminal_cost,\n            noise_sigma=torch.diag(torch.tensor([5., 5.], dtype=dtype, device=device)),\n            num_samples=500,\n            horizon=20, device=device,\n            u_max=torch.tensor([2., 2.], dtype=dtype, device=device),\n            lambda_=1)\n```\n\nWe then need to create an evaluation function for the tuner to tune on. \nIt should take no arguments and output a `EvaluationResult` populated at least by costs.\nIf you don't need rollouts for the cost evaluation, then you can set it to None in the return.\nTips for creating the evaluation function are described in comments below:\n\n```python\nfrom pytorch_mppi import autotune\n# use the same nominal trajectory to start with for all the evaluations for fairness\nnominal_trajectory = mppi.U.clone()\n# parameters for our sample evaluation function - lots of choices for the evaluation function\nevaluate_running_cost = True\nnum_refinement_steps = 10\nnum_trajectories = 5\n\ndef evaluate():\n    costs = []\n    rollouts = []\n    # we sample multiple trajectories for the same start to goal problem, but in your case you should consider\n    # evaluating over a diverse dataset of trajectories\n    for j in range(num_trajectories):\n        mppi.U = nominal_trajectory.clone()\n        # the nominal trajectory at the start will be different if the horizon's changed\n        mppi.change_horizon(mppi.T)\n        # usually MPPI will have its nominal trajectory warm-started from the previous iteration\n        # for a fair test of tuning we will reset its nominal trajectory to the same random one each time\n        # we manually warm it by refining it for some steps\n        for k in range(num_refinement_steps):\n            mppi.command(env.start, shift_nominal_trajectory=False)\n\n        rollout = mppi.get_rollouts(env.start)\n\n        this_cost = 0\n        rollout = rollout[0]\n        # here we evaluate on the rollout MPPI cost of the resulting trajectories\n        # alternative costs for tuning the parameters are possible, such as just considering terminal cost\n        if evaluate_running_cost:\n            for t in range(len(rollout) - 1):\n                this_cost = this_cost + env.running_cost(rollout[t], mppi.U[t])\n        this_cost = this_cost + env.terminal_cost(rollout, mppi.U)\n\n        rollouts.append(rollout)\n        costs.append(this_cost)\n    # can return None for rollouts if they do not need to be calculated\n    return autotune.EvaluationResult(torch.stack(costs), torch.stack(rollouts))\n```\n\nWith this we have enough to start tuning. For example, we can tune iteratively with the CMA-ES optimizer\n```python\n  # choose from autotune.AutotuneMPPI.TUNABLE_PARAMS\nparams_to_tune = ['sigma', 'horizon', 'lambda']\n# create a tuner with a CMA-ES optimizer\ntuner = autotune.AutotuneMPPI(mppi, params_to_tune, evaluate_fn=evaluate, optimizer=autotune.CMAESOpt(sigma=1.0))\n# tune parameters for a number of iterations\niterations = 30\nfor i in range(iterations):\n    # results of this optimization step are returned\n    res = tuner.optimize_step()\n    # we can render the rollouts in the environment\n    env.draw_rollouts(res.rollouts)\n# get best results and apply it to the controller\n# (by default the controller will take on the latest tuned parameter, which may not be best)\nres = tuner.get_best_result()\ntuner.apply_parameters(res.params)\n```\nThis is a local search method that optimizes starting from the initially defined parameters.\nFor global searching, we use ray tune compatible searching algorithms. Note that you can modify the\nsearch space of each parameter, but default reasonable ones are provided.\n\n```python\n# can also use a Ray Tune optimizer, see\n# https://docs.ray.io/en/latest/tune/api_docs/suggestion.html#search-algorithms-tune-search\n# rather than adapting the current parameters, these optimizers allow you to define a search space for each\n# and will search on that space\nfrom pytorch_mppi import autotune_global\nfrom ray.tune.search.hyperopt import HyperOptSearch\nfrom ray.tune.search.bayesopt import BayesOptSearch\n\n# be sure to close any figures before ray tune optimization or they will be duplicated\nenv.visualize = False\nplt.close('all')\ntuner = autotune_global.AutotuneMPPIGlobal(mppi, params_to_tune, evaluate_fn=evaluate,\n                                           optimizer=autotune_global.RayOptimizer(HyperOptSearch))\n# ray tuners cannot be tuned iteratively, but you can specify how many iterations to tune for\nres = tuner.optimize_all(100)\nres = tuner.get_best_result()\ntuner.apply_parameters(res.params)\n```\n\nFor example tuning hyperparameters (with CMA-ES) only on the toy problem (the nominal trajectory is reset each time so they are sampling from noise):\n\n![toy tuning](https://i.imgur.com/2qtYMwu.gif)\n\nIf you want more than just the best solution found, such as if you want diversity\nacross hyperparameter values, or if your evaluation function has large uncertainty,\nthen you can directly query past results by\n```python\nfor res in tuner.optim.all_res:\n    # the cost\n    print(res.metrics['cost'])\n    # extract the parameters\n    params = tuner.config_to_params(res.config)\n    print(params)\n    # apply the parameters to the controller\n    tuner.apply_parameters(params)\n```\n\nAlternatively you can try Quality Diversity optimization using the \n[CMA-ME optimizer](https://github.com/icaros-usc/pyribs). This optimizer will\ntry to optimize for high quality parameters while ensuring there is diversity across\nthem. However, it is very slow and you might be better using a `RayOptimizer` and selecting\nfor top results while checking for diversity.\nTo use it, you need to install\n```python\npip install ribs\n```\n\nYou then use it as\n```python\nimport pytorch_mppi.autotune_qd\n\noptim = pytorch_mppi.autotune_qd.CMAMEOpt()\ntuner = autotune_global.AutotuneMPPIGlobal(mppi, params_to_tune, evaluate_fn=evaluate,\n                                           optimizer=optim)\n\niterations = 10\nfor i in range(iterations):\n    # results of this optimization step are returned\n    res = tuner.optimize_step()\n    # we can render the rollouts in the environment\n    best_params = optim.get_diverse_top_parameters(5)\n    for res in best_params:\n        print(res)\n```\n\n# Tests\nYou'll need to install `gym<=0.20` to run the tests (for the `Pendulum-v0` environment).\nThe easy way to install this and other testing dependencies is running `python setup.py test`.\nNote that `gym` past `0.20` deprecated `Pendulum-v0` for `Pendulum-v1` with incompatible dynamics.\n\nUnder `tests` you can find the `MPPI` method applied to known pendulum dynamics\nand approximate pendulum dynamics (with a 2 layer feedforward net \nestimating the state residual). Using a continuous angle representation\n(feeding `cos(\\theta), sin(\\theta)` instead of `\\theta` directly) makes\na huge difference. Although both works, the continuous representation\nis much more robust to controller parameters and random seed. In addition,\nthe problem of continuing to spin after over-swinging does not appear.\n\nSample result on approximate dynamics with 100 steps of random policy data\nto initialize the dynamics:\n\n![pendulum results](https://i.imgur.com/euYQJ25.gif)\n\n# Related projects\n- [pytorch CEM](https://github.com/LemonPi/pytorch_cem) - an alternative MPC shooting method with similar API as this\nproject\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "mppi,pytorch,control,robotics",
    "license": "Copyright (c) 2023 University of Michigan ARM Lab  Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:  The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.  ",
    "maintainer": "",
    "maintainer_email": "Sheng Zhong <zhsh@umich.edu>",
    "name": "pytorch-mppi",
    "package_url": "https://pypi.org/project/pytorch-mppi/",
    "platform": null,
    "project_url": "https://pypi.org/project/pytorch-mppi/",
    "project_urls": {
      "Bug Reports": "https://github.com/LemonPi/pytorch_mppi/issues",
      "Homepage": "https://github.com/LemonPi/pytorch_mppi",
      "Source": "https://github.com/LemonPi/pytorch_mppi"
    },
    "release_url": "https://pypi.org/project/pytorch-mppi/0.6.0/",
    "requires_dist": [
      "torch",
      "numpy",
      "pytest ; extra == 'test'",
      "gym (<=0.20) ; extra == 'test'",
      "pygame ; extra == 'test'",
      "pyglet (==1.5.27) ; extra == 'test'",
      "window-recorder ; extra == 'test'",
      "cma ; extra == 'test'",
      "ray[tune] ; extra == 'test'",
      "bayesian-optimization ; extra == 'test'",
      "hyperopt ; extra == 'test'",
      "cma ; extra == 'tune'",
      "ray[tune] ; extra == 'tune'",
      "bayesian-optimization ; extra == 'tune'",
      "hyperopt ; extra == 'tune'"
    ],
    "requires_python": ">=3.6",
    "summary": "Model Predictive Path Integral (MPPI) implemented in pytorch",
    "version": "0.6.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17020279,
  "releases": {
    "0.4.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d4642cf8f67bcff12f69e4e11136a2c0ffd900ebe9032b27989e7bb64cb4e3c3",
          "md5": "cee805da8c6ba148840905c071374148",
          "sha256": "09672a707e4d02e56173af237c2ad57a7d91b0b2db2466e24efa5537c44b4588"
        },
        "downloads": -1,
        "filename": "pytorch_mppi-0.4.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "cee805da8c6ba148840905c071374148",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 9649,
        "upload_time": "2023-02-10T05:04:29",
        "upload_time_iso_8601": "2023-02-10T05:04:29.054897Z",
        "url": "https://files.pythonhosted.org/packages/d4/64/2cf8f67bcff12f69e4e11136a2c0ffd900ebe9032b27989e7bb64cb4e3c3/pytorch_mppi-0.4.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4522ad17b54965c472e368fbd17482c7ff5c3a8e4017d4758814712188c6523e",
          "md5": "87e4bb38bfa52d4fc1dbe4d7da849469",
          "sha256": "735de87a50215a39a82b3ff94e6b828c42718bcb8b0c626212234f0b28055ea7"
        },
        "downloads": -1,
        "filename": "pytorch_mppi-0.4.1.tar.gz",
        "has_sig": false,
        "md5_digest": "87e4bb38bfa52d4fc1dbe4d7da849469",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 12881,
        "upload_time": "2023-02-10T05:04:31",
        "upload_time_iso_8601": "2023-02-10T05:04:31.046185Z",
        "url": "https://files.pythonhosted.org/packages/45/22/ad17b54965c472e368fbd17482c7ff5c3a8e4017d4758814712188c6523e/pytorch_mppi-0.4.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "585ab64365e0292910eb5834dcdb657f97c62136a28ab5ae6efec8e55c7e0706",
          "md5": "8ee2eb13c6d7452759573f926279b6bf",
          "sha256": "09915f052b6db07cc782b200711622d4b437de3bb8547ef87b329e82f344e9d4"
        },
        "downloads": -1,
        "filename": "pytorch_mppi-0.4.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "8ee2eb13c6d7452759573f926279b6bf",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 9663,
        "upload_time": "2023-02-10T18:38:20",
        "upload_time_iso_8601": "2023-02-10T18:38:20.865380Z",
        "url": "https://files.pythonhosted.org/packages/58/5a/b64365e0292910eb5834dcdb657f97c62136a28ab5ae6efec8e55c7e0706/pytorch_mppi-0.4.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6be902cec49fd89d5be6ee656b47df2769c86ba1bc11bb4ef93c9c71b1ff17e6",
          "md5": "f1ec7ae6e684f0be8f096dba77fd6658",
          "sha256": "5aa122a0a19e7f556a0e2d70c6c1aacbcfa0ce465de2c736528f2064ecc6b2a0"
        },
        "downloads": -1,
        "filename": "pytorch_mppi-0.4.2.tar.gz",
        "has_sig": false,
        "md5_digest": "f1ec7ae6e684f0be8f096dba77fd6658",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 12913,
        "upload_time": "2023-02-10T18:38:22",
        "upload_time_iso_8601": "2023-02-10T18:38:22.779462Z",
        "url": "https://files.pythonhosted.org/packages/6b/e9/02cec49fd89d5be6ee656b47df2769c86ba1bc11bb4ef93c9c71b1ff17e6/pytorch_mppi-0.4.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.5.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b74a6d3d1fde6c4feb5c238b9659e52b738cdd7673d2c3899cbb796676f77f0e",
          "md5": "3c58a55e4aa94e33d455ade968cf2554",
          "sha256": "66924aaf93457385943851461e6cffc547266a9964b956c5ce281b7651291ab0"
        },
        "downloads": -1,
        "filename": "pytorch_mppi-0.5.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "3c58a55e4aa94e33d455ade968cf2554",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 15279,
        "upload_time": "2023-02-24T02:53:47",
        "upload_time_iso_8601": "2023-02-24T02:53:47.538962Z",
        "url": "https://files.pythonhosted.org/packages/b7/4a/6d3d1fde6c4feb5c238b9659e52b738cdd7673d2c3899cbb796676f77f0e/pytorch_mppi-0.5.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3c7db46f79edee2f663f54f83e63c79f89bc4581efc57d32b9ec647faba69228",
          "md5": "19b3296a506cbac5bbad3f39124441ae",
          "sha256": "771070946b9b3fb1a16aaa27240f9fdcf2a5771b2238901a62f65b795920d788"
        },
        "downloads": -1,
        "filename": "pytorch_mppi-0.5.0.tar.gz",
        "has_sig": false,
        "md5_digest": "19b3296a506cbac5bbad3f39124441ae",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 19748,
        "upload_time": "2023-02-24T02:53:49",
        "upload_time_iso_8601": "2023-02-24T02:53:49.939850Z",
        "url": "https://files.pythonhosted.org/packages/3c/7d/b46f79edee2f663f54f83e63c79f89bc4581efc57d32b9ec647faba69228/pytorch_mppi-0.5.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.6.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0d058c836a4b4919c8e94ae6b1cc5fce8555c9513fd19ecb7102106d424fd618",
          "md5": "5502cbcd5a96e3dd9bea2270cb3a8dcc",
          "sha256": "b80b741446f134dc49dd1c2ed81c812a9c7e8a4dd74554580d29fac0f7772e1a"
        },
        "downloads": -1,
        "filename": "pytorch_mppi-0.6.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "5502cbcd5a96e3dd9bea2270cb3a8dcc",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 17771,
        "upload_time": "2023-02-24T23:10:00",
        "upload_time_iso_8601": "2023-02-24T23:10:00.599250Z",
        "url": "https://files.pythonhosted.org/packages/0d/05/8c836a4b4919c8e94ae6b1cc5fce8555c9513fd19ecb7102106d424fd618/pytorch_mppi-0.6.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5bfeb71962e09c4327b88bdda60ce67755378bf6ad3f5fd6e0130c687c53c24f",
          "md5": "52a540ea133325237488a5b4f608a064",
          "sha256": "6c2c672c4b41b6242a2c8d1c2d92393450dfddfb32dcce2b39213d1d8c28ac35"
        },
        "downloads": -1,
        "filename": "pytorch_mppi-0.6.0.tar.gz",
        "has_sig": false,
        "md5_digest": "52a540ea133325237488a5b4f608a064",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 22017,
        "upload_time": "2023-02-24T23:10:03",
        "upload_time_iso_8601": "2023-02-24T23:10:03.390776Z",
        "url": "https://files.pythonhosted.org/packages/5b/fe/b71962e09c4327b88bdda60ce67755378bf6ad3f5fd6e0130c687c53c24f/pytorch_mppi-0.6.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "0d058c836a4b4919c8e94ae6b1cc5fce8555c9513fd19ecb7102106d424fd618",
        "md5": "5502cbcd5a96e3dd9bea2270cb3a8dcc",
        "sha256": "b80b741446f134dc49dd1c2ed81c812a9c7e8a4dd74554580d29fac0f7772e1a"
      },
      "downloads": -1,
      "filename": "pytorch_mppi-0.6.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "5502cbcd5a96e3dd9bea2270cb3a8dcc",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 17771,
      "upload_time": "2023-02-24T23:10:00",
      "upload_time_iso_8601": "2023-02-24T23:10:00.599250Z",
      "url": "https://files.pythonhosted.org/packages/0d/05/8c836a4b4919c8e94ae6b1cc5fce8555c9513fd19ecb7102106d424fd618/pytorch_mppi-0.6.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "5bfeb71962e09c4327b88bdda60ce67755378bf6ad3f5fd6e0130c687c53c24f",
        "md5": "52a540ea133325237488a5b4f608a064",
        "sha256": "6c2c672c4b41b6242a2c8d1c2d92393450dfddfb32dcce2b39213d1d8c28ac35"
      },
      "downloads": -1,
      "filename": "pytorch_mppi-0.6.0.tar.gz",
      "has_sig": false,
      "md5_digest": "52a540ea133325237488a5b4f608a064",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 22017,
      "upload_time": "2023-02-24T23:10:03",
      "upload_time_iso_8601": "2023-02-24T23:10:03.390776Z",
      "url": "https://files.pythonhosted.org/packages/5b/fe/b71962e09c4327b88bdda60ce67755378bf6ad3f5fd6e0130c687c53c24f/pytorch_mppi-0.6.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}