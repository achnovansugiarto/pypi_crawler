{
  "info": {
    "author": "Will Sackfield",
    "author_email": "will.sackfield@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3"
    ],
    "description": "# pyiextract\n\n<a href=\"https://pypi.org/project/pyiextract/\">\n    <img alt=\"PyPi\" src=\"https://img.shields.io/pypi/v/pyiextract\">\n</a>\n\nA python library for extracting knowledge from raw sources.\n\n## Architecture :triangular_ruler:\n\nThis library is built on top of an information extraction pipeline which performs the following functions:\n\n`Pipeline` is the main protocol which defines how the various nodes in the pipeline interact and keeps track of the state of the analysis. It is responsible for taking in the raw media and outputting a document with the extracted information. The inbuilt pipelines are:\n\n|Name|Functionality                                                         |\n|----|----------------------------------------------------------------------|\n|Full|Runs all the nodes in the pipeline for optimal information extraction.|\n\n`Normaliser` is the protocol which nodes use to define ways to refine the raw media so it can be easily processed down the line. It takes the raw media as an input and outputs the same raw media with the processing applied to it.\n\n|Name       |Functionality                                                                                                 |\n|-----------|--------------------------------------------------------------------------------------------------------------|\n|english    |Checks if the text is in english, or if it isn't provide translation to english if it is a supported language.|\n|coreference|Resolves pronouns to their intended reference entity.                                                         |\n|blink      |Links the entities mentioned in the document to global identifiers.                                           |\n\n`Extractor` is the protocol which nodes use to extract information in clearly defined ways (such as `Triple`). These are responsible for producing as much information as possible from the raw media.\n\n|Name   |Functionality                                                                      |\n|-------|-----------------------------------------------------------------------------------|\n|svo    |Finds subject verb object triples in the text (rule based approach).               |\n|openie |Finds relationships between entities with attributes.                              |\n|opennre|Finds structured relationships between entities (such as father).                  |\n|llm    |Finds relationships between entities using large language model attention matrices.|\n\n`Reducer` is the protocol which nodes use to remove and deduplicate the information extracted previously so it is presented to the user of the library cleanly.\n\n|Name        |Functionality                                                 |\n|------------|--------------------------------------------------------------|\n|coreference |Remove any triples with a pronoun as their entity.            |\n|ner         |Remove any triples where both entities are not named entities.|\n|subjectivity|Remove any triples representing a subjective opinion.         |\n\nRight now there are no efforts to use accelerated versions of these models, so unfortunately the library is slow. In the future CUDA and other acceleration efforts will be supported as well as FAISS databases.\n\n## Dependencies :globe_with_meridians:\n\n* [textacy](https://github.com/chartbeat-labs/textacy) - Apache 2.0 License\n* [spacy](https://spacy.io/) - MIT License\n* [AllenNLP](https://allenai.org/allennlp) - Apache 2.0 License\n* [OpenNRE](https://github.com/thunlp/OpenNRE) - MIT License\n* [Transformers](https://github.com/huggingface/transformers) - Apache 2.0 License\n* [TextBlob](https://github.com/chartbeat-labs/textacy) - Apache 2.0 License\n* [BLINK](https://github.com/facebookresearch/BLINK) - MIT License\n* [Python Levenshtein](https://github.com/ztane/python-Levenshtein) - GPL 2.0 License\n* [langdetect](https://pypi.org/project/langdetect/) - Apache 2.0 License\n\nSnippets have also been adapted from the following repositories:\n\n* [Improvements to AllenNLP coreference resolver](https://github.com/Laxminarayen/coreference-resolution-allenNLP/blob/main/improvements_to_allennlp_cr.ipynb) - MIT License\n* [Language models are knowledge graphs](https://github.com/theblackcat102/language-models-are-knowledge-graphs-pytorch/blob/main/process.py) - MIT License\n\n## Installation :inbox_tray:\n\nWhen installing on MacOS, make sure you have the following installed:\n\n* [Xcode](https://developer.apple.com/xcode/)\n* [Homebrew](https://brew.sh/)\n\nMake sure you install the following packages on brew:\n\n```shell\n$ brew install openblas rust cmake wget\n```\n\nTo install from pypi:\n\n```shell\n$ pip install --upgrade pip setuptools\n$ pip install pyiextract\n```\n\n## Usage example :eyes:\n\nTo run the full pipeline as intended simply create a `FullPipeline` object and run the extract on it. Note that on the first run the library will attempt to download all the required models (which takes a while).\n\n```python\nimport json\n\nfrom pyiextract import fullpipeline\n\npipeline = fullpipeline.FullPipeline()\ndoc = pipeline.extract(\"Paul Allen was born on January 21, 1953, in Seattle, Washington, to Kenneth Sam Allen and Edna Faye Allen. Allen attended Lakeside School, a private school in Seattle, where he befriended Bill Gates, two years younger, with whom he shared an enthusiasm for computers. Paul and Bill used a teletype terminal at their high school, Lakeside, to develop their programming skills on several time-sharing computer systems.\")\nprint(json.dumps([str(x) for x in doc.triples()]))\n```\n\nThis produces the following:\n```json\n[\n    \"Paul Allen (11430) -> attended -> Lakeside School (121098) {svo-extractor}\",\n    \"Paul Allen (11430) -> befriended -> Bill Gates (1584) {svo-extractor}\",\n    \"Paul Allen (11430) -> shared -> enthusiasm {svo-extractor}\",\n    \"Paul Allen (11430) -> attended -> Lakeside School , a private school in Seattle , Washington , where Paul Allen befriended Bill Gates , two years younger , with whom Paul Allen shared an enthusiasm for computers {openie-extractor}\",\n    \"Paul Allen (11430) -> befriended -> Bill Gates , two years younger , with whom Paul Allen shared an enthusiasm for computers at where {openie-extractor}\",\n    \"Paul Allen (11430) -> shared -> an enthusiasm for computers {openie-extractor}\",\n    \"Paul Allen (11430) -> residence -> Seattle (1624986) {opennre-extractor}\",\n    \"Paul Allen (11430) -> residence -> Washington (1807707) {opennre-extractor}\",\n    \"Paul Allen (11430) -> father -> Kenneth Sam Allen (3014520) {opennre-extractor}\",\n    \"Paul Allen (11430) -> mother -> Edna Faye Allen (34604) {opennre-extractor}\",\n    \"January 21, 1953 -> location -> Seattle (1624986) {opennre-extractor}\",\n    \"January 21, 1953 -> father -> Kenneth Sam Allen (3014520) {opennre-extractor}\",\n    \"January 21, 1953 -> mother -> Edna Faye Allen (34604) {opennre-extractor}\",\n    \"Seattle (1624986) -> located in the administrative territorial entity -> Washington (1807707) {opennre-extractor}\",\n    \"Seattle (1624986) -> head of government -> Kenneth Sam Allen (3014520) {opennre-extractor}\",\n    \"Seattle (1624986) -> mother -> Edna Faye Allen (34604) {opennre-extractor}\",\n    \"Washington (1807707) -> head of government -> Kenneth Sam Allen (3014520) {opennre-extractor}\",\n    \"Kenneth Sam Allen (3014520) -> spouse -> Edna Faye Allen (34604) {opennre-extractor}\",\n    \"Paul Allen (11430) -> field of work -> Paul Allen (11430) {opennre-extractor}\",\n    \"Paul Allen (11430) -> bear -> January {llm-extractor}\",\n    \"Paul Allen (11430) -> bear -> Seattle (1624986) {llm-extractor}\",\n    \"Paul Allen (11430) -> bear -> Washington (1807707) {llm-extractor}\",\n    \"Paul Allen (11430) -> bear -> Kenneth Sam Allen (3014520) {llm-extractor}\",\n    \"Paul Allen (11430) -> bear -> Edna Faye Allen (34604) {llm-extractor}\",\n    \"Lakeside School (121098) -> befriend -> shared {llm-extractor}\",\n    \"Lakeside School (121098) -> befriend -> shared {llm-extractor}\",\n    \"Lakeside School (121098) -> befriend -> Bill Gates (1584) {llm-extractor}\",\n    \"Lakeside School (121098) -> befriend -> shared {llm-extractor}\",\n    \"Lakeside School (121098) -> befriend -> an enthusiasm {llm-extractor}\",\n    \"Lakeside School (121098) -> befriend -> computers {llm-extractor}\",\n    \"a private school -> befriend -> Bill Gates (1584) {llm-extractor}\",\n    \"Seattle (1624986) -> befriend -> shared {llm-extractor}\",\n    \"Seattle (1624986) -> befriend -> shared {llm-extractor}\",\n    \"Seattle (1624986) -> befriend -> Bill Gates (1584) {llm-extractor}\",\n    \"Seattle (1624986) -> befriend -> shared {llm-extractor}\",\n    \"Seattle (1624986) -> befriend -> an enthusiasm {llm-extractor}\",\n    \"Seattle (1624986) -> befriend -> computers {llm-extractor}\",\n    \"Washington (1807707) -> befriend -> shared {llm-extractor}\",\n    \"Washington (1807707) -> befriend -> shared {llm-extractor}\",\n    \"Washington (1807707) -> befriend -> Bill Gates (1584) {llm-extractor}\",\n    \"Washington (1807707) -> befriend -> shared {llm-extractor}\",\n    \"Washington (1807707) -> befriend -> an enthusiasm {llm-extractor}\",\n    \"Washington (1807707) -> befriend -> computers {llm-extractor}\",\n    \"Paul Allen (11430) -> share -> an enthusiasm {llm-extractor}\",\n    \"Paul Allen (11430) -> share -> computers {llm-extractor}\",\n    \"Paul Allen (11430) -> use -> a teletype terminal {llm-extractor}\",\n    \"Paul Allen (11430) -> share -> a teletype terminal {llm-extractor}\",\n    \"Paul Allen (11430) -> use -> Lakeside (52851) {llm-extractor}\",\n    \"Paul Allen (11430) -> share -> Lakeside (52851) {llm-extractor}\",\n    \"Paul Allen (11430) -> develop -> Paul and Bill's programming skills {llm-extractor}\",\n    \"Paul Allen (11430) -> use -> Paul and Bill's programming skills {llm-extractor}\",\n    \"Paul Allen (11430) -> share -> Paul and Bill's programming skills {llm-extractor}\",\n    \"Paul Allen (11430) -> develop -> several time-sharing computer systems {llm-extractor}\",\n    \"Paul Allen (11430) -> use -> several time-sharing computer systems {llm-extractor}\",\n    \"Paul Allen (11430) -> share -> several time-sharing computer systems {llm-extractor}\",\n    \"Bill Gates (1584) -> share -> an enthusiasm {llm-extractor}\",\n    \"Bill Gates (1584) -> share -> computers {llm-extractor}\",\n    \"Bill Gates (1584) -> use -> a teletype terminal {llm-extractor}\",\n    \"Bill Gates (1584) -> share -> a teletype terminal {llm-extractor}\",\n    \"Bill Gates (1584) -> use -> Lakeside (52851) {llm-extractor}\",\n    \"Bill Gates (1584) -> share -> Lakeside (52851) {llm-extractor}\",\n    \"Bill Gates (1584) -> develop -> Paul and Bill's programming skills {llm-extractor}\",\n    \"Bill Gates (1584) -> use -> Paul and Bill's programming skills {llm-extractor}\",\n    \"Bill Gates (1584) -> share -> Paul and Bill's programming skills {llm-extractor}\",\n    \"Bill Gates (1584) -> develop -> several time-sharing computer systems {llm-extractor}\",\n    \"Bill Gates (1584) -> use -> several time-sharing computer systems {llm-extractor}\",\n    \"Bill Gates (1584) -> share -> several time-sharing computer systems {llm-extractor}\",\n    \"an enthusiasm -> use -> Lakeside (52851) {llm-extractor}\",\n    \"computers -> use -> Lakeside (52851) {llm-extractor}\",\n    \"Lakeside (52851) -> develop -> Paul and Bill's programming skills {llm-extractor}\",\n    \"Lakeside (52851) -> develop -> several time-sharing computer systems {llm-extractor}\"\n]\n```\n\n## License :memo:\n\nThe project is available under the [GPL 2.0 License](LICENSE).\n\n## TODO\n\n1. Filter junk triples (use ML with G2V).\n2. Deduplicate triples (use ML with G2V).\n3. Create a training mode that can be used to fine-tune the underlying models.\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/8W9aG/pyiextract",
    "keywords": "information extraction nlp",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "pyiextract",
    "package_url": "https://pypi.org/project/pyiextract/",
    "platform": null,
    "project_url": "https://pypi.org/project/pyiextract/",
    "project_urls": {
      "Homepage": "https://github.com/8W9aG/pyiextract"
    },
    "release_url": "https://pypi.org/project/pyiextract/0.0.4/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "A library for end to end information extraction from raw text.",
    "version": "0.0.4",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14558303,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a8c6ef07576bb3d389b0838dfe2a23de459c834e0f3860a7f25ea31f182201d8",
          "md5": "d45381128e7579a2c26f8dc21eec7261",
          "sha256": "44424ec45e535031c2e065c2c13ab2968a37c304dfb7e23cc63cd881502c9d0e"
        },
        "downloads": -1,
        "filename": "pyiextract-0.0.1-py3.9.egg",
        "has_sig": false,
        "md5_digest": "d45381128e7579a2c26f8dc21eec7261",
        "packagetype": "bdist_egg",
        "python_version": "0.0.1",
        "requires_python": null,
        "size": 70488,
        "upload_time": "2022-07-20T18:05:16",
        "upload_time_iso_8601": "2022-07-20T18:05:16.975166Z",
        "url": "https://files.pythonhosted.org/packages/a8/c6/ef07576bb3d389b0838dfe2a23de459c834e0f3860a7f25ea31f182201d8/pyiextract-0.0.1-py3.9.egg",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c8061d247f224fa19a5aeafb3da3a92cc038127235bf2f66ff651b15c221329c",
          "md5": "834eda8a59a4c0f44dfba2f0cd459404",
          "sha256": "9ad93d9b67f45691f162c134955d04de95e1029b458e4ecc005d68830c304a83"
        },
        "downloads": -1,
        "filename": "pyiextract-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "834eda8a59a4c0f44dfba2f0cd459404",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 32097,
        "upload_time": "2022-07-20T18:05:18",
        "upload_time_iso_8601": "2022-07-20T18:05:18.758249Z",
        "url": "https://files.pythonhosted.org/packages/c8/06/1d247f224fa19a5aeafb3da3a92cc038127235bf2f66ff651b15c221329c/pyiextract-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4584a7b58a2f945c8ee2441c22e40bad4360c52ba9384bb4da5c6a08b7576a4a",
          "md5": "a2735ed3b668543cb9cd9c1e5693286a",
          "sha256": "ee30d2146993999dcefae7bd5eb2da553f24eabf1aa4151a3e5c8da8b81dc73a"
        },
        "downloads": -1,
        "filename": "pyiextract-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "a2735ed3b668543cb9cd9c1e5693286a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 32462,
        "upload_time": "2022-07-22T14:42:16",
        "upload_time_iso_8601": "2022-07-22T14:42:16.647663Z",
        "url": "https://files.pythonhosted.org/packages/45/84/a7b58a2f945c8ee2441c22e40bad4360c52ba9384bb4da5c6a08b7576a4a/pyiextract-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9b30596f9fc3aa89328c7c1d908471d38c74789005556d706576546db9c56346",
          "md5": "f907d5c4e353cc765ef57bfd08657769",
          "sha256": "7b834ef76dc0000222900eb5021209dd8ec8719301ee0f54a8f85da03cd7b6be"
        },
        "downloads": -1,
        "filename": "pyiextract-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "f907d5c4e353cc765ef57bfd08657769",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 32770,
        "upload_time": "2022-07-23T17:49:52",
        "upload_time_iso_8601": "2022-07-23T17:49:52.269128Z",
        "url": "https://files.pythonhosted.org/packages/9b/30/596f9fc3aa89328c7c1d908471d38c74789005556d706576546db9c56346/pyiextract-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e2d7f0ce97a860696e94616d9f6c70aacfa9d524143646814a58c9719073be3c",
          "md5": "bb9e54ef66c20d27ed167e0bf226d46a",
          "sha256": "37088fffe7338eb3c6bcfc69b2fd4455a8ee2e305fe2b0704727d6a43c3789cf"
        },
        "downloads": -1,
        "filename": "pyiextract-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "bb9e54ef66c20d27ed167e0bf226d46a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 33121,
        "upload_time": "2022-07-26T22:28:05",
        "upload_time_iso_8601": "2022-07-26T22:28:05.141987Z",
        "url": "https://files.pythonhosted.org/packages/e2/d7/f0ce97a860696e94616d9f6c70aacfa9d524143646814a58c9719073be3c/pyiextract-0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "e2d7f0ce97a860696e94616d9f6c70aacfa9d524143646814a58c9719073be3c",
        "md5": "bb9e54ef66c20d27ed167e0bf226d46a",
        "sha256": "37088fffe7338eb3c6bcfc69b2fd4455a8ee2e305fe2b0704727d6a43c3789cf"
      },
      "downloads": -1,
      "filename": "pyiextract-0.0.4.tar.gz",
      "has_sig": false,
      "md5_digest": "bb9e54ef66c20d27ed167e0bf226d46a",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 33121,
      "upload_time": "2022-07-26T22:28:05",
      "upload_time_iso_8601": "2022-07-26T22:28:05.141987Z",
      "url": "https://files.pythonhosted.org/packages/e2/d7/f0ce97a860696e94616d9f6c70aacfa9d524143646814a58c9719073be3c/pyiextract-0.0.4.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}