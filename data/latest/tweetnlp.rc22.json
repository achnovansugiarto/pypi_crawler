{
  "info": {
    "author": "Asahi Ushio",
    "author_email": "asahi1992ushio@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Intended Audience :: Developers",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3",
      "Topic :: Scientific/Engineering"
    ],
    "description": "[![license](https://img.shields.io/badge/License-MIT-brightgreen.svg)](https://github.com/asahi417/tweetnlp/blob/master/LICENSE)\n[![PyPI version](https://badge.fury.io/py/tweetnlp.svg)](https://badge.fury.io/py/tweetnlp)\n[![PyPI pyversions](https://img.shields.io/pypi/pyversions/tweetnlp.svg)](https://pypi.python.org/pypi/tweetnlp/)\n[![PyPI status](https://img.shields.io/pypi/status/tweetnlp.svg)](https://pypi.python.org/pypi/tweetnlp/)\n\n# TweetNLP\nTweetNLP for all the NLP enthusiasts working on Twitter! \nThe python library `tweetnlp` provides a collection of useful tools to analyze/understand tweets such as sentiment analysis,\nemoji prediction, and named-entity recognition, powered by state-of-the-art language modeling trained on tweets.\n\n***News (September 2022):*** Our paper presenting TweetNLP, \"TweetNLP: Cutting-Edge Natural Language Processing for Social Media\", has been accepted as an EMNLP 2022 system demonstration!! Camera-ready version can be found [here](https://arxiv.org/abs/2206.14774).\n\n\nResources:\n- Quick Tour with Colab Notebook: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/104MtF9MXkDFimlJLr4SFBX0HjidLTfvp?usp=sharing)\n- Play with the TweetNLP Online Demo: [link](https://tweetnlp.org/demo/)\n- EMNLP 2022 paper: [link](https://arxiv.org/abs/2206.14774)\n\nTable of Contents:\n1. [***Load Model & Dataset***](https://github.com/cardiffnlp/tweetnlp/tree/add_training#model--dataset)\n2. [***Fine-tune Model***](https://github.com/cardiffnlp/tweetnlp/tree/add_training#model-fine-tuning)\n\n## Get Started\n\nInstall TweetNLP via pip on your console. \n```shell\npip install tweetnlp\n```\n## Model & Dataset\n\nIn this section, you will learn how to get the models and datasets with `tweetnlp`.\nThe models follow [huggingface model](https://huggingface.co/) and the datasets are in the format of [huggingface datasets](https://huggingface.co/docs/datasets/load_hub).\nEasy introductions of huggingface models and datasets should be found at [huggingface webpage](https://huggingface.co/), so\nplease check them if you are new to huggingface.\n\n### Tweet Classification\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/104MtF9MXkDFimlJLr4SFBX0HjidLTfvp#scrollTo=KAZYjeskBqL4)\n\nThe classification module consists of six different tasks (Topic Classification, Sentiment Analysis, Irony Detection, Hate Speech Detection, Offensive Language Detection, Emoji Prediction, and Emotion Analysis).\nIn each example, the model is instantiated by `tweetnlp.load_model(\"task-name\")`, and run the prediction by passing a text or a list of texts as argument to the corresponding function.\n\n- ***Topic Classification***: The aim of this task is, given a tweet to assign topics related to its content. The task is formed as a supervised multi-label classification problem where each tweet is assigned one or more topics from a total of 19 available topics. The topics were carefully curated based on Twitter trends with the aim to be broad and general and consist of classes such as: arts and culture, music, or sports. Our internally-annotated dataset contains over 10K manually-labeled tweets (check the paper [here](https://arxiv.org/abs/2209.09824), or the [huggingface dataset page](https://huggingface.co/datasets/cardiffnlp/tweet_topic_single)).\n\n```python\nimport tweetnlp\n\n# MULTI-LABEL MODEL \nmodel = tweetnlp.load_model('topic_classification')  # Or `model = tweetnlp.TopicClassification()`\nmodel.topic(\"Jacob Collier is a Grammy-awarded English artist from London.\")  # Or `model.predict`\n>>> {'label': ['celebrity_&_pop_culture', 'music']}\n# Note: the probability of the multi-label model is the output of sigmoid function on binary prediction whether each topic is positive or negative.\nmodel.topic(\"Jacob Collier is a Grammy-awarded English artist from London.\", return_probability=True)\n>>> {'label': ['celebrity_&_pop_culture', 'music'],\n 'probability': {'arts_&_culture': 0.037371691316366196,\n  'business_&_entrepreneurs': 0.010188567452132702,\n  'celebrity_&_pop_culture': 0.92448890209198,\n  'diaries_&_daily_life': 0.03425711765885353,\n  'family': 0.00796138122677803,\n  'fashion_&_style': 0.020642118528485298,\n  'film_tv_&_video': 0.08062587678432465,\n  'fitness_&_health': 0.006343095097690821,\n  'food_&_dining': 0.0042883665300905704,\n  'gaming': 0.004327300935983658,\n  'learning_&_educational': 0.010652057826519012,\n  'music': 0.8291937112808228,\n  'news_&_social_concern': 0.24688217043876648,\n  'other_hobbies': 0.020671198144555092,\n  'relationships': 0.020371075719594955,\n  'science_&_technology': 0.0170074962079525,\n  'sports': 0.014291072264313698,\n  'travel_&_adventure': 0.010423899628221989,\n  'youth_&_student_life': 0.008605164475739002}}\n\n# SINGLE-LABEL MODEL\nmodel = tweetnlp.load_model('topic_classification', multi_label=False)  # Or `model = tweetnlp.TopicClassification(multi_label=False)`\nmodel.topic(\"Jacob Collier is a Grammy-awarded English artist from London.\")\n>>> {'label': 'pop_culture'}\n# NOTE: the probability of the sinlge-label model the softmax over the label.\nmodel.topic(\"Jacob Collier is a Grammy-awarded English artist from London.\", return_probability=True)\n>>> {'label': 'pop_culture',\n 'probability': {'arts_&_culture': 9.20625461731106e-05,\n  'business_&_entrepreneurs': 6.916998972883448e-05,\n  'pop_culture': 0.9995898604393005,\n  'daily_life': 0.00011083036952186376,\n  'sports_&_gaming': 8.668467489769682e-05,\n  'science_&_technology': 5.152115045348182e-05}}\n\n# GET DATASET\ndataset_multi_label, label2id_multi_label = tweetnlp.load_dataset('topic_classification')\ndataset_single_label, label2id_single_label = tweetnlp.load_dataset('topic_classification', multi_label=False)\n```\n\n\n- ***Sentiment Analysis***: The sentiment analysis task integrated in TweetNLP is a simplified version where the goal is to predict the sentiment of a tweet with one of the three following labels: positive, neutral or negative. The base dataset for English is the unified TweetEval version of the Semeval-2017 dataset from the task on Sentiment Analysis in Twitter (check the paper [here](https://arxiv.org/pdf/2010.12421.pdf)).\n\n```python\nimport tweetnlp\n\n# ENGLISH MODEL\nmodel = tweetnlp.load_model('sentiment')  # Or `model = tweetnlp.Sentiment()` \nmodel.sentiment(\"Yes, including Medicare and social security savingðŸ‘\")  # Or `model.predict`\n>>> {'label': 'positive'}\nmodel.sentiment(\"Yes, including Medicare and social security savingðŸ‘\", return_probability=True)\n>>> {'label': 'positive', 'probability': {'negative': 0.004584966693073511, 'neutral': 0.19360853731632233, 'positive': 0.8018065094947815}}\n\n# MULTILINGUAL MODEL\nmodel = tweetnlp.load_model('sentiment', multilingual=True)  # Or `model = tweetnlp.Sentiment(multilingual=True)` \nmodel.sentiment(\"å¤©æ°—ãŒè‰¯ã„ã¨ã‚„ã£ã±ã‚Šæ°—æŒã¡è‰¯ã„ãªã‚âœ¨\")\n>>> {'label': 'positive'}\nmodel.sentiment(\"å¤©æ°—ãŒè‰¯ã„ã¨ã‚„ã£ã±ã‚Šæ°—æŒã¡è‰¯ã„ãªã‚âœ¨\", return_probability=True)\n>>> {'label': 'positive', 'probability': {'negative': 0.028369612991809845, 'neutral': 0.08128828555345535, 'positive': 0.8903420567512512}}\n\n# GET DATASET (ENGLISH)\ndataset, label2id = tweetnlp.load_dataset('sentiment')\n# GET DATASET (MULTILINGUAL)\nfor l in ['all', 'arabic', 'english', 'french', 'german', 'hindi', 'italian', 'portuguese', 'spanish']:\n    dataset_multilingual, label2id_multilingual = tweetnlp.load_dataset('sentiment', multilingual=True, task_language=l)\n```\n\n- ***Irony Detection***: This is a binary classification task where given a tweet, the goal is to detect whether it is ironic or not. It is based on the Irony Detection dataset from the SemEval 2018 task (check the paper [here](https://arxiv.org/pdf/2010.12421.pdf)).\n\n```python\nimport tweetnlp\n\n# MODEL\nmodel = tweetnlp.load_model('irony')  # Or `model = tweetnlp.Irony()` \nmodel.irony('If you wanna look like a badass, have drama on social media')  # Or `model.predict`\n>>> {'label': 'irony'}\nmodel.irony('If you wanna look like a badass, have drama on social media', return_probability=True)\n>>> {'label': 'irony', 'probability': {'non_irony': 0.08390884101390839, 'irony': 0.9160911440849304}} \n\n# GET DATASET\ndataset, label2id = tweetnlp.load_dataset('irony')\n```\n\n- ***Hate Speech Detection***: The hate speech dataset consists of detecting whether a tweet is hateful towards women or immigrants. It is based on the Detection of Hate Speech task at SemEval 2019 (check the paper [here](https://arxiv.org/pdf/2010.12421.pdf)).\n\n```python\nimport tweetnlp\n\n# MODEL\nmodel = tweetnlp.load_model('hate')  # Or `model = tweetnlp.Hate()` \nmodel.hate('Whoever just unfollowed me you a bitch')  # Or `model.predict`\n>>> {'label': 'not-hate'}\nmodel.hate('Whoever just unfollowed me you a bitch', return_probability=True)\n>>> {'label': 'non-hate', 'probability': {'non-hate': 0.7263831496238708, 'hate': 0.27361682057380676}}\n\n# GET DATASET\ndataset, label2id = tweetnlp.load_dataset('hate')\n```\n\n- ***Offensive Language Identification***: This task consists in identifying whether some form of offensive language is present in a tweet. For our benchmark we rely on the SemEval2019 OffensEval dataset (check the paper [here](https://arxiv.org/pdf/2010.12421.pdf)).\n\n```python\nimport tweetnlp\n\n# MODEL\nmodel = tweetnlp.load_model('offensive')  # Or `model = tweetnlp.Offensive()` \nmodel.offensive(\"All two of them taste like ass.\")  # Or `model.predict`\n>>> {'label': 'offensive'}\nmodel.offensive(\"All two of them taste like ass.\", return_probability=True)\n>>> {'label': 'offensive', 'probability': {'non-offensive': 0.16420328617095947, 'offensive': 0.8357967734336853}}\n\n# GET DATASET\ndataset, label2id = tweetnlp.load_dataset('offensive')\n```\n\n- ***Emoji Prediction***: The goal of emoji prediction is to predict the final emoji on a given tweet. The dataset used to fine-tune our models is the TweetEval adaptation from the SemEval 2018 task on Emoji Prediction (check the paper [here](https://arxiv.org/pdf/2010.12421.pdf)), including 20 emoji as labels (â¤, ðŸ˜, ðŸ˜‚, ðŸ’•, ðŸ”¥, ðŸ˜Š, ðŸ˜Ž, âœ¨, ðŸ’™, ðŸ˜˜, ðŸ“·, ðŸ‡ºðŸ‡¸, â˜€, ðŸ’œ, ðŸ˜‰, ðŸ’¯, ðŸ˜, ðŸŽ„, ðŸ“¸, ðŸ˜œ).\t\n\n```python\nimport tweetnlp\n\n# MODEL\nmodel = tweetnlp.load_model('emoji')  # Or `model = tweetnlp.Emoji()` \nmodel.emoji('Beautiful sunset last night from the pontoon @TupperLakeNY')  # Or `model.predict`\n>>> {'label': 'ðŸ˜Š'}\nmodel.emoji('Beautiful sunset last night from the pontoon @TupperLakeNY', return_probability=True)\n>>> {'label': 'ðŸ“·',\n 'probability': {'â¤': 0.13197319209575653,\n  'ðŸ˜': 0.11246423423290253,\n  'ðŸ˜‚': 0.008415069431066513,\n  'ðŸ’•': 0.04842926934361458,\n  'ðŸ”¥': 0.014528146013617516,\n  'ðŸ˜Š': 0.1509675830602646,\n  'ðŸ˜Ž': 0.08625403046607971,\n  'âœ¨': 0.01616635173559189,\n  'ðŸ’™': 0.07396604865789413,\n  'ðŸ˜˜': 0.03033279813826084,\n  'ðŸ“·': 0.16525287926197052,\n  'ðŸ‡ºðŸ‡¸': 0.020336611196398735,\n  'â˜€': 0.00799981877207756,\n  'ðŸ’œ': 0.016111424192786217,\n  'ðŸ˜‰': 0.012984540313482285,\n  'ðŸ’¯': 0.012557178735733032,\n  'ðŸ˜': 0.031386848539114,\n  'ðŸŽ„': 0.006829539313912392,\n  'ðŸ“¸': 0.04188741743564606,\n  'ðŸ˜œ': 0.011156936176121235}}\n\n# GET DATASET\ndataset, label2id = tweetnlp.load_dataset('emoji')\n```\n\n- ***Emotion Recognition***: Given a tweet, this task consists of associating it with its most appropriate emotion. As a reference dataset we use the SemEval 2018 task on Affect in Tweets, simplified to only four emotions used in TweetEval: anger, joy, sadness and optimism (check the paper [here](https://arxiv.org/pdf/2010.12421.pdf)).\n\n```python\nimport tweetnlp\n\n# MODEL\nmodel = tweetnlp.load_model('emotion')  # Or `model = tweetnlp.Emotion()` \nmodel.emotion('I love swimming for the same reason I love meditating...the feeling of weightlessness.')  # Or `model.predict`\n>>> {'label': 'joy'}\nmodel.emotion('I love swimming for the same reason I love meditating...the feeling of weightlessness.', return_probability=True)\n>>> {'label': 'optimism', 'probability': {'joy': 0.01367587223649025, 'optimism': 0.7345258593559265, 'anger': 0.1770714670419693, 'sadness': 0.07472680509090424}}\n\n# GET DATASET\ndataset, label2id = tweetnlp.load_dataset('emotion')\n```\n\n### Named Entity Recognition\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/104MtF9MXkDFimlJLr4SFBX0HjidLTfvp#scrollTo=WeREiLEjBlrj)\n\nThis module consists of a named-entity recognition (NER) model specifically trained for tweets. The model is instantiated by `tweetnlp.load_model(\"ner\")`, and runs the prediction by giving a text or a list of texts as argument to the `ner` function (check the paper [here](https://arxiv.org/abs/2210.03797), or the [huggingface dataset page](https://huggingface.co/datasets/tner/tweetner7)). \n\n```python3\nimport tweetnlp\n\n# MODEL\nmodel = tweetnlp.load_model('ner')  # Or `model = tweetnlp.NER()` \nmodel.ner('Jacob Collier is a Grammy-awarded English artist from London.')  # Or `model.predict`\n>>> [{'type': 'person', 'entity': 'Jacob Collier'}, {'type': 'event', 'entity': ' Grammy'}, {'type': 'location', 'entity': ' London'}]\n# Note: the probability for the predicted entity is the mean of the probabilities over the sub-tokens representing the entity. \nmodel.ner('Jacob Collier is a Grammy-awarded English artist from London.', return_probability=True)  # Or `model.predict`\n>>> [\n  {'type': 'person', 'entity': 'Jacob Collier', 'probability': 0.9905318220456442},\n  {'type': 'event', 'entity': ' Grammy', 'probability': 0.19164378941059113},\n  {'type': 'location', 'entity': ' London', 'probability': 0.9607000350952148}\n]\n\n# GET DATASET\ndataset, label2id = tweetnlp.load_dataset('ner')\n```\n\n### Question Answering\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/104MtF9MXkDFimlJLr4SFBX0HjidLTfvp#scrollTo=reZDePaBmYhA&line=4&uniqifier=1)\n\nThis module consists of a question answering model specifically trained for tweets.\nThe model is instantiated by `tweetnlp.load_model(\"question_answering\")`, \nand runs the prediction by giving a question or a list of questions along with a context or a list of contexts\nas argument to the `question_answering` function (check the paper [here](https://arxiv.org/abs/2210.03992), or the [huggingface dataset page](https://huggingface.co/datasets/lmqg/qg_tweetqa)). \n\n```python3\nimport tweetnlp\n\n# MODEL\nmodel = tweetnlp.load_model('question_answering')  # Or `model = tweetnlp.QuestionAnswering()` \nmodel.question_answering(\n  question='who created the post as we know it today?',\n  context=\"'So much of The Post is Ben,' Mrs. Graham said in 1994, three years after Bradlee retired as editor. 'He created it as we know it today.'â€” Ed O'Keefe (@edatpost) October 21, 2014\"\n)  # Or `model.predict`\n>>> {'generated_text': 'ben'}\n\n# GET DATASET\ndataset = tweetnlp.load_dataset('question_answering')\n```\n\n### Question Answer Generation\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/104MtF9MXkDFimlJLr4SFBX0HjidLTfvp#scrollTo=uqd7sBHhnwym&line=6&uniqifier=1)\n\nThis module consists of a question & answer pair generation specifically trained for tweets.\nThe model is instantiated by `tweetnlp.load_model(\"question_answer_generation\")`, \nand runs the prediction by giving a context or a list of contexts\nas argument to the `question_answer_generation` function (check the paper [here](https://arxiv.org/abs/2210.03992), or the [huggingface dataset page](https://huggingface.co/datasets/lmqg/qag_tweetqa)). \n\n```python3\nimport tweetnlp\n\n# MODEL\nmodel = tweetnlp.load_model('question_answer_generation')  # Or `model = tweetnlp.QuestionAnswerGeneration()` \nmodel.question_answer_generation(\n  text=\"'So much of The Post is Ben,' Mrs. Graham said in 1994, three years after Bradlee retired as editor. 'He created it as we know it today.'â€” Ed O'Keefe (@edatpost) October 21, 2014\"\n)  # Or `model.predict`\n>>> [\n    {'question': 'who created the post?', 'answer': 'ben'},\n    {'question': 'what did ben do in 1994?', 'answer': 'he retired as editor'}\n]\n\n# GET DATASET\ndataset = tweetnlp.load_dataset('question_answer_generation')\n```\n\n### Language Modeling\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/104MtF9MXkDFimlJLr4SFBX0HjidLTfvp#scrollTo=COOoZHVAFCIG&line=1&uniqifier=1)\n\nThe masked language model predicts the masked token in the given sentence. This is instantiated by `tweetnlp.load_model('language_model')`, and runs the prediction by giving a text or a list of texts as argument to the `mask_prediction` function. Please make sure that each text has a `<mask>` token, since that is eventually the following by the objective of the model to predict.\n\n```python\nimport tweetnlp\nmodel = tweetnlp.load_model('language_model')  # Or `model = tweetnlp.LanguageModel()` \nmodel.mask_prediction(\"How many more <mask> until opening day? ðŸ˜©\", best_n=2)  # Or `model.predict`\n>>> {'best_tokens': ['days', 'hours'],\n 'best_scores': [5.498564104033932e-11, 4.906026140893971e-10],\n 'best_sentences': ['How many more days until opening day? ðŸ˜©',\n  'How many more hours until opening day? ðŸ˜©']}\n```\n\n### Tweet Embedding\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/104MtF9MXkDFimlJLr4SFBX0HjidLTfvp#scrollTo=MUT31bNQYTNz)\n\nThe tweet embedding model produces a fixed length embedding for a tweet. The embedding represents the semantics by meaning of the tweet, and this can be used for semantic search of tweets by using the similarity between the embeddings. Model is instantiated by `tweet_nlp.load_model('sentence_embedding')`, and run the prediction by passing a text or a list of texts as argument to the `embedding` function.\n\n- ***Get Embedding***\n\n```python\nimport tweetnlp\nmodel = tweetnlp.load_model('sentence_embedding')  # Or `model = tweetnlp.SentenceEmbedding()` \n\n# Get sentence embedding\ntweet = \"I will never understand the decision making of the people of Alabama. Their new Senator is a definite downgrade. You have served with honor.  Well done.\"\nvectors = model.embedding(tweet)\nvectors.shape\n>>> (768,)\n\n# Get sentence embedding (multiple inputs)\ntweet_corpus = [\n    \"Free, fair elections are the lifeblood of our democracy. Charges of unfairness are serious. But calling an election unfair does not make it so. Charges require specific allegations and then proof. We have neither here.\",\n    \"Trump appointed judge Stephanos Bibas \",\n    \"If your members can go to Puerto Rico they can get their asses back in the classroom. @CTULocal1\",\n    \"@PolitiBunny @CTULocal1 Political leverage, science said schools could reopen, teachers and unions protested to keep'em closed and made demands for higher wages and benefits, they're usin Covid as a crutch at the expense of life and education.\",\n    \"Congratulations to all the exporters on achieving record exports in Dec 2020 with a growth of 18 % over the previous year. Well done &amp; keep up this trend. A major pillar of our govt's economic policy is export enhancement &amp; we will provide full support to promote export culture.\",\n    \"@ImranKhanPTI Pakistan seems a worst country in term of exporting facilities. I am a small business man and if I have to export a t-shirt having worth of $5 to USA or Europe. Postal cost will be around $30. How can we grow as an exporting country if this situation prevails. Think about it. #PM\",\n    \"The thing that doesnâ€™t sit right with me about â€œnothing good happened in 2020â€ is that it ignores the largest protest movement in our history. The beautiful, powerful Black Lives Matter uprising reached every corner of the country and should be central to our look back at 2020.\",\n    \"@JoshuaPotash I kinda said that in the 2020 look back for @washingtonpost\",\n    \"Is this a confirmation from Q that Lin is leaking declassified intelligence to the public? I believe so. If @realDonaldTrump didnâ€™t approve of what @LLinWood is doing he would have let us know a lonnnnnng time ago. Iâ€™ve always wondered why Linâ€™s Twitter handle started with â€œLLinâ€ https://t.co/0G7zClOmi2\",\n    \"@ice_qued @realDonaldTrump @LLinWood Yeah 100%\",\n    \"Tomorrow is my last day as Senator from Alabama.  I believe our opportunities are boundless when we find common ground. As we swear in a new Congress &amp; a new President, demand from them that they do just that &amp; build a stronger, more just society.  Itâ€™s been an honor to serve you.\" \n    \"The mask cult canâ€™t ever admit masks donâ€™t work because their ideology is based on feeling like a â€œgood personâ€  Wearing a mask makes them a â€œgood personâ€ &amp; anyone who disagrees w/them isnâ€™t  They canâ€™t tolerate any idea that makes them feel like their self-importance is unearned\",\n    \"@ianmSC Beyond that, they put such huge confidence in masks so early with no strong evidence that they have any meaningful benefit, they donâ€™t want to backtrack or admit they were wrong. They put the cart before the horse, now desperate to find any results that match their hypothesis.\",\n]\nvectors = model.embedding(tweet_corpus, batch_size=4)\nvectors.shape\n>>> (12, 768)\n```\n\n- ***Similarity Search***\n\n```python\nsims = []\nfor n, i in enumerate(tweet_corpus):\n  _sim = model.similarity(tweet, i)\n  sims.append([n, _sim])\nprint(f'anchor tweet: {tweet}\\n')\nfor m, (n, s) in enumerate(sorted(sims, key=lambda x: x[1], reverse=True)[:3]):\n  print(f' - top {m}: {tweet_corpus[n]}\\n - similaty: {s}\\n')\n\n>>> anchor tweet: I will never understand the decision making of the people of Alabama. Their new Senator is a definite downgrade. You have served with honor.  Well done.\n\n - top 0: Tomorrow is my last day as Senator from Alabama.  I believe our opportunities are boundless when we find common ground. As we swear in a new Congress &amp; a new President, demand from them that they do just that &amp; build a stronger, more just society.  Itâ€™s been an honor to serve you.The mask cult canâ€™t ever admit masks donâ€™t work because their ideology is based on feeling like a â€œgood personâ€  Wearing a mask makes them a â€œgood personâ€ &amp; anyone who disagrees w/them isnâ€™t  They canâ€™t tolerate any idea that makes them feel like their self-importance is unearned\n - similaty: 0.7480925982953287\n\n - top 1: Trump appointed judge Stephanos Bibas \n - similaty: 0.6289173306344258\n\n - top 2: Free, fair elections are the lifeblood of our democracy. Charges of unfairness are serious. But calling an election unfair does not make it so. Charges require specific allegations and then proof. We have neither here.\n - similaty: 0.6017154109745276\n```\n\n### Resources & Custom Model Loading \n\nHere is a table of the default model used in each task. \n\n| Task                              | Model                                                                                                                                                   | Dataset |\n|-----------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------|\n|Topic Classification (single-label)| [cardiffnlp/twitter-roberta-base-dec2021-tweet-topic-single-all](https://huggingface.co/cardiffnlp/twitter-roberta-base-dec2021-tweet-topic-single-all) | [cardiffnlp/tweet_topic_single](https://huggingface.co/datasets/cardiffnlp/tweet_topic_single) |\n|Topic Classification (multi-label) | [cardiffnlp/twitter-roberta-base-dec2021-tweet-topic-multi-all](https://huggingface.co/cardiffnlp/twitter-roberta-base-dec2021-tweet-topic-multi-all)   | [cardiffnlp/tweet_topic_multi](https://huggingface.co/datasets/cardiffnlp/tweet_topic_multi) |\n|Sentiment Analysis (Multilingual)  | [cardiffnlp/twitter-xlm-roberta-base-sentiment](https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment)                                   | [cardiffnlp/tweet_sentiment_multilingual](https://huggingface.co/datasets/cardiffnlp/tweet_sentiment_multilingual) |\n|Sentiment Analysis                 | [cardiffnlp/twitter-roberta-base-sentiment-latest](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest)                             | [tweet_eval](https://huggingface.co/datasets/tweet_eval) |\n|Irony Detection                    | [cardiffnlp/twitter-roberta-base-irony](https://huggingface.co/cardiffnlp/twitter-roberta-base-irony)                                                   | [tweet_eval](https://huggingface.co/datasets/tweet_eval) |\n|Hate Detection                     | [cardiffnlp/twitter-roberta-base-hate](https://huggingface.co/cardiffnlp/twitter-roberta-base-hate)                                                     | [tweet_eval](https://huggingface.co/datasets/tweet_eval) |\n|Offensive Detection                | [cardiffnlp/twitter-roberta-base-offensive](https://huggingface.co/cardiffnlp/twitter-roberta-base-offensive)                                           | [tweet_eval](https://huggingface.co/datasets/tweet_eval) |\n|Emoji Prediction                   | [cardiffnlp/twitter-roberta-base-emoji](https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji)                                                   | [tweet_eval](https://huggingface.co/datasets/tweet_eval) |\n|Emotion Analysis                   | [cardiffnlp/twitter-roberta-base-emotion](https://huggingface.co/cardiffnlp/twitter-roberta-base-emotion)                                               | [tweet_eval](https://huggingface.co/datasets/tweet_eval) |\n|Named Entity Recognition           | [tner/roberta-large-tweetner7-all](https://huggingface.co/tner/roberta-large-tweetner7-all)                                                        | [tner/tweetner7](https://huggingface.co/datasets/tner/tweetner7) |\n|Question Answering                 | [lmqg/t5-small-tweetqa-qa](https://huggingface.co/lmqg/t5-small-tweetqa-qa)                                                                             | [lmqg/qg_tweetqa](https://huggingface.co/datasets/lmqg/qg_tweetqa) |\n|Question Answer Generation         | [lmqg/t5-base-tweetqa-qag](https://huggingface.co/lmqg/t5-base-tweetqa-qag)                                                                             | [lmqg/qag_tweetqa](https://huggingface.co/datasets/lmqg/qag_tweetqa) |\n|Language Modeling                  | [cardiffnlp/twitter-roberta-base-2021-124m](https://huggingface.co/cardiffnlp/twitter-roberta-base-2021-124m)                                           | TBA |\n|Tweet Embedding                    | [cambridgeltl/tweet-roberta-base-embeddings-v1](https://huggingface.co/cambridgeltl/tweet-roberta-base-embeddings-v1)                                   | TBA |\n\n\nTo use an other model from local/huggingface modelhub, one can simply provide the model path/alias to the `load_model` function.\nBelow is an example to load a model for NER.\n\n```python\nimport tweetnlp\ntweetnlp.load_model('ner', model_name='tner/twitter-roberta-base-2019-90m-tweetner7-continuous')\n```\n\n## Model Fine-tuning\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/104MtF9MXkDFimlJLr4SFBX0HjidLTfvp#scrollTo=2plrPTqk7OHp)\n\nTweetNLP provides an easy interface to fine-tune language models on the datasets supported by HuggingFace for model hosting/fine-tuning with [RAY TUNE](https://docs.ray.io/en/latest/tune/index.html) for parameter search.\n\n- Supported Tasks: `sentiment`, `offensive`, `irony`, `hate`, `emotion`, `topic_classification`\n\nThe results of experiments with `tweetnlp`'s trainer can be found in the following table. Results are competitive and can be used as baselines for each task.\nSee [the leaderboard page](https://github.com/cardiffnlp/tweetnlp/blob/main/FINETUNING_RESULT.md) to know more about the results.\n\n| task      | language_model                                                                                                |   eval_f1 |   eval_f1_macro |   eval_accuracy | link                                                                                                                              |\n|:----------|:--------------------------------------------------------------------------------------------------------------|----------:|----------------:|----------------:|:----------------------------------------------------------------------------------------------------------------------------------|\n| emoji     | [cardiffnlp/twitter-roberta-base-2021-124m](https://huggingface.co/cardiffnlp/twitter-roberta-base-2021-124m) |      0.46 |            0.35 |            0.46 | [cardiffnlp/twitter-roberta-base-2021-124m-emoji](https://huggingface.co/cardiffnlp/twitter-roberta-base-2021-124m-emoji)         |\n| emotion   | [cardiffnlp/twitter-roberta-base-2021-124m](https://huggingface.co/cardiffnlp/twitter-roberta-base-2021-124m) |      0.83 |            0.79 |            0.83 | [cardiffnlp/twitter-roberta-base-2021-124m-emotion](https://huggingface.co/cardiffnlp/twitter-roberta-base-2021-124m-emotion)     |\n| hate      | [cardiffnlp/twitter-roberta-base-2021-124m](https://huggingface.co/cardiffnlp/twitter-roberta-base-2021-124m) |      0.56 |            0.53 |            0.56 | [cardiffnlp/twitter-roberta-base-2021-124m-hate](https://huggingface.co/cardiffnlp/twitter-roberta-base-2021-124m-hate)           |\n| irony     | [cardiffnlp/twitter-roberta-base-2021-124m](https://huggingface.co/cardiffnlp/twitter-roberta-base-2021-124m) |      0.79 |            0.78 |            0.79 | [cardiffnlp/twitter-roberta-base-2021-124m-irony](https://huggingface.co/cardiffnlp/twitter-roberta-base-2021-124m-irony)         |\n| offensive | [cardiffnlp/twitter-roberta-base-2021-124m](https://huggingface.co/cardiffnlp/twitter-roberta-base-2021-124m) |      0.86 |            0.82 |            0.86 | [cardiffnlp/twitter-roberta-base-2021-124m-offensive](https://huggingface.co/cardiffnlp/twitter-roberta-base-2021-124m-offensive) |\n| sentiment | [cardiffnlp/twitter-roberta-base-2021-124m](https://huggingface.co/cardiffnlp/twitter-roberta-base-2021-124m) |      0.71 |            0.72 |            0.71 | [cardiffnlp/twitter-roberta-base-2021-124m-sentiment](https://huggingface.co/cardiffnlp/twitter-roberta-base-2021-124m-sentiment) |\n| topic_classification (single) | [cardiffnlp/twitter-roberta-base-2021-124m](https://huggingface.co/cardiffnlp/twitter-roberta-base-2021-124m) |      0.9  |  0.8  |            0.9  | [cardiffnlp/twitter-roberta-base-2021-124m-topic-single](https://huggingface.co/cardiffnlp/twitter-roberta-base-2021-124m-topic-single)                 |                                                                                                                               \n| topic_classification (multi)  | [cardiffnlp/twitter-roberta-base-2021-124m](https://huggingface.co/cardiffnlp/twitter-roberta-base-2021-124m) |      0.75 |            0.56 |            0.54 | [cardiffnlp/twitter-roberta-base-2021-124m-topic-multi](https://huggingface.co/cardiffnlp/twitter-roberta-base-2021-124m-topic-multi)                   |\n| sentiment (multilingual)      | [cardiffnlp/twitter-xlm-roberta-base](https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base)             |      0.69 |  0.69 |            0.69 | [cardiffnlp/twitter-xlm-roberta-base-sentiment-multilingual](https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment-multilingual)         |                                                                                                                               \n\n\n### Example \nThe following example will reproduce our irony model [cardiffnlp/twitter-roberta-base-2021-124m-irony](https://huggingface.co/cardiffnlp/twitter-roberta-base-2021-124m-irony).\n\n```python\nimport logging\nimport tweetnlp\n\nlogging.basicConfig(format='%(asctime)s %(levelname)-8s %(message)s', level=logging.INFO, datefmt='%Y-%m-%d %H:%M:%S')\n\n# load dataset\ndataset, label_to_id = tweetnlp.load_dataset(\"irony\")\n# load trainer class\ntrainer_class = tweetnlp.load_trainer(\"irony\")\n# setup trainer\ntrainer = trainer_class(\n    language_model='cardiffnlp/twitter-roberta-base-2021-124m',  # language model to fine-tune\n    dataset=dataset,\n    label_to_id=label_to_id,\n    max_length=128,\n    split_test='test',\n    split_train='train',\n    split_validation='validation',\n    output_dir='model_ckpt/irony' \n)\n# start model fine-tuning with parameter optimization\ntrainer.train(\n  eval_step=50,  # each `eval_step`, models are validated on the validation set \n  n_trials=10,  # number of trial at parameter optimization\n  search_range_lr=[1e-6, 1e-4],  # define the search space for learning rate (min and max value)\n  search_range_epoch=[1, 6],  # define the search space for epoch (min and max value)\n  search_list_batch=[4, 8, 16, 32, 64]  # define the search space for batch size (list of integer to test) \n)\n# evaluate model on the test set\ntrainer.evaluate()\n>>> {\n  \"eval_loss\": 1.3228046894073486,\n  \"eval_f1\": 0.7959183673469388,\n  \"eval_f1_macro\": 0.791350632069195,\n  \"eval_accuracy\": 0.7959183673469388,\n  \"eval_runtime\": 2.2267,\n  \"eval_samples_per_second\": 352.084,\n  \"eval_steps_per_second\": 44.01\n}\n# save model locally (saved at `{output_dir}/best_model` as default)\ntrainer.save_model()\n# run prediction\ntrainer.predict('If you wanna look like a badass, have drama on social media')\n>>> {'label': 'irony'}\n# push your model on huggingface hub\ntrainer.push_to_hub(hf_organization='cardiffnlp', model_alias='twitter-roberta-base-2021-124m-irony')\n```\nThe saved checkpoint can be loaded as a custom model as below.\n```python\nimport tweetnlp\nmodel = tweetnlp.load_model('irony', model_name=\"model_ckpt/irony/best_model\")\n```\nIf `split_validation` is not given, trainer will do a single run with default parameters without parameter search.\n\n## Reference Paper\n\nFor more details, please read the accompanying [TweetNLP's reference paper](https://arxiv.org/pdf/2206.14774.pdf). If you use TweetNLP in your research, please use the following `bib` entry to cite the reference paper:\n\n```\n@inproceedings{camacho-collados-etal-2022-tweetnlp,\n    title={{T}weet{NLP}: {C}utting-{E}dge {N}atural {L}anguage {P}rocessing for {S}ocial {M}edia},\n    author={Camacho-Collados, Jose and Rezaee, Kiamehr and Riahi, Talayeh and Ushio, Asahi and Loureiro, Daniel and Antypas, Dimosthenis and Boisson, Joanne and Espinosa-Anke, Luis and Liu, Fangyu and Mart{\\'\\i}nez-C{\\'a}mara, Eugenio and others},\n    author = \"Ushio, Asahi  and\n      Camacho-Collados, Jose\",\n    booktitle = \"Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing: System Demonstrations\",\n    month = nov,\n    year = \"2022\",\n    address = \"Abu Dhabi, U.A.E.\",\n    publisher = \"Association for Computational Linguistics\",\n}\n```\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "https://github.com/cardiffnlp/tweetnlp/archive/0.4.2.tar.gz",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/cardiffnlp/tweetnlp",
    "keywords": "tweet,nlp,language-model",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "tweetnlp",
    "package_url": "https://pypi.org/project/tweetnlp/",
    "platform": null,
    "project_url": "https://pypi.org/project/tweetnlp/",
    "project_urls": {
      "Download": "https://github.com/cardiffnlp/tweetnlp/archive/0.4.2.tar.gz",
      "Homepage": "https://github.com/cardiffnlp/tweetnlp"
    },
    "release_url": "https://pypi.org/project/tweetnlp/0.4.2/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "NLP library for Twitter.",
    "version": "0.4.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16603773,
  "releases": {
    "0.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ffdbf84679387a22c8d2c614a93c70e1ffa150c953c2788440e06d94e7477b12",
          "md5": "7c045b5fd3d8b391dd8d55ea2ba9802a",
          "sha256": "dff111bc4cf66b968ddd311b2dd2d8fb468a8def88835963fe6dafb871595405"
        },
        "downloads": -1,
        "filename": "tweetnlp-0.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "7c045b5fd3d8b391dd8d55ea2ba9802a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 1688,
        "upload_time": "2022-05-11T21:12:52",
        "upload_time_iso_8601": "2022-05-11T21:12:52.000556Z",
        "url": "https://files.pythonhosted.org/packages/ff/db/f84679387a22c8d2c614a93c70e1ffa150c953c2788440e06d94e7477b12/tweetnlp-0.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7700eb7caacf851aee73a3e1d971d46abda9d9127922f77c36535ff808e76eea",
          "md5": "ca06e8323e46ea2b44f9c3f8eb13fad4",
          "sha256": "4a908e48106480a4da4291c2533f32b69dc171440e20469adc355cace684f231"
        },
        "downloads": -1,
        "filename": "tweetnlp-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "ca06e8323e46ea2b44f9c3f8eb13fad4",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 12633,
        "upload_time": "2022-05-24T10:48:10",
        "upload_time_iso_8601": "2022-05-24T10:48:10.641088Z",
        "url": "https://files.pythonhosted.org/packages/77/00/eb7caacf851aee73a3e1d971d46abda9d9127922f77c36535ff808e76eea/tweetnlp-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "11a0a3b243be82bd24d4f5538630aad386f0dff22ffededa6b53d2faf0aaa56c",
          "md5": "a7f7dc3fb3c4ebc95b994b15fcbeae6c",
          "sha256": "e962250bb19365b00474d5d214e919f7cfb1440223f01e056809de2c1a3091c6"
        },
        "downloads": -1,
        "filename": "tweetnlp-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "a7f7dc3fb3c4ebc95b994b15fcbeae6c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 20463,
        "upload_time": "2022-05-28T16:48:49",
        "upload_time_iso_8601": "2022-05-28T16:48:49.241466Z",
        "url": "https://files.pythonhosted.org/packages/11/a0/a3b243be82bd24d4f5538630aad386f0dff22ffededa6b53d2faf0aaa56c/tweetnlp-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b07b091fbf5da8f22df06c5d16d36517809e7878eed8e3a13374dc9ff1c8b9c9",
          "md5": "ae310b66ecf93cecf43d3f39a2f519ea",
          "sha256": "238110f5c84490868fa4622f20a20ee07475c92a532e8f78e50fced7518cef70"
        },
        "downloads": -1,
        "filename": "tweetnlp-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "ae310b66ecf93cecf43d3f39a2f519ea",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 20358,
        "upload_time": "2022-05-29T19:50:13",
        "upload_time_iso_8601": "2022-05-29T19:50:13.989020Z",
        "url": "https://files.pythonhosted.org/packages/b0/7b/091fbf5da8f22df06c5d16d36517809e7878eed8e3a13374dc9ff1c8b9c9/tweetnlp-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b61aa51a477feea132d57d5887c43595e29aa5a849da223a9162ced28bb15b88",
          "md5": "dcb994eb34d5577153c78f4707d3bbbf",
          "sha256": "6dd9a42af6f579d59784e3015a2cf7ca940d84f868a3c5989cf5aa466acbff54"
        },
        "downloads": -1,
        "filename": "tweetnlp-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "dcb994eb34d5577153c78f4707d3bbbf",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 22483,
        "upload_time": "2022-06-07T14:33:12",
        "upload_time_iso_8601": "2022-06-07T14:33:12.101018Z",
        "url": "https://files.pythonhosted.org/packages/b6/1a/a51a477feea132d57d5887c43595e29aa5a849da223a9162ced28bb15b88/tweetnlp-0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8208b13a212a3a5bd44674738fe77d0b43598d03d80011f2ba108da104ac79b1",
          "md5": "dd12a455ad8dd3c9401b2fb8473f9037",
          "sha256": "7288121406d4bcd24149744e9a843c1d82afb88661ce5d11eeee79304dab3a75"
        },
        "downloads": -1,
        "filename": "tweetnlp-0.0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "dd12a455ad8dd3c9401b2fb8473f9037",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 23544,
        "upload_time": "2022-06-27T12:30:13",
        "upload_time_iso_8601": "2022-06-27T12:30:13.609194Z",
        "url": "https://files.pythonhosted.org/packages/82/08/b13a212a3a5bd44674738fe77d0b43598d03d80011f2ba108da104ac79b1/tweetnlp-0.0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "929c1c0d06aaa11f8a0db5e1641b211ec93a3acc23605a4a3da3f3f52dd5b87c",
          "md5": "417f5430b13224bb883bcca3f707292b",
          "sha256": "113abf4e03e6a3db445dcf2fd35fdbc00b79ca736912245ff654ec49f8446543"
        },
        "downloads": -1,
        "filename": "tweetnlp-0.0.6.tar.gz",
        "has_sig": false,
        "md5_digest": "417f5430b13224bb883bcca3f707292b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 23595,
        "upload_time": "2022-06-29T10:15:29",
        "upload_time_iso_8601": "2022-06-29T10:15:29.329942Z",
        "url": "https://files.pythonhosted.org/packages/92/9c/1c0d06aaa11f8a0db5e1641b211ec93a3acc23605a4a3da3f3f52dd5b87c/tweetnlp-0.0.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "316d729a623e453545c7b8f211530f5ea2b2635cf5c97ca9968b291234ef53be",
          "md5": "a56d6660165785ead7cf708b21fab959",
          "sha256": "232459e6bf61858bf7a5d126590415d749ad279cf9d53ad48632666c291df2da"
        },
        "downloads": -1,
        "filename": "tweetnlp-0.0.7.tar.gz",
        "has_sig": false,
        "md5_digest": "a56d6660165785ead7cf708b21fab959",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 23609,
        "upload_time": "2022-06-29T11:53:09",
        "upload_time_iso_8601": "2022-06-29T11:53:09.269049Z",
        "url": "https://files.pythonhosted.org/packages/31/6d/729a623e453545c7b8f211530f5ea2b2635cf5c97ca9968b291234ef53be/tweetnlp-0.0.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ddcd527990b94c56a990f0aac31d71b11d1997de69d5262a1a8d822819bb9d69",
          "md5": "6e2b5c7dd726cb4f37f7f122375794d4",
          "sha256": "ea736df9d902cf58fa85e67454f569e6ede175aa840b95f7000d42fcdbe6d6da"
        },
        "downloads": -1,
        "filename": "tweetnlp-0.0.8.tar.gz",
        "has_sig": false,
        "md5_digest": "6e2b5c7dd726cb4f37f7f122375794d4",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 23325,
        "upload_time": "2022-06-29T17:27:28",
        "upload_time_iso_8601": "2022-06-29T17:27:28.070489Z",
        "url": "https://files.pythonhosted.org/packages/dd/cd/527990b94c56a990f0aac31d71b11d1997de69d5262a1a8d822819bb9d69/tweetnlp-0.0.8.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.9": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b206fdf1779af7c77d5f47007514135a4a274b41b01ec30bd0e6ebd6ef41d5c2",
          "md5": "2d842bf9882f33be78975323fa2bb6b6",
          "sha256": "129b3a4fc6e3be43d735f6320035d72577afb5c9c70cd4276dbeaf70b8d6aef8"
        },
        "downloads": -1,
        "filename": "tweetnlp-0.0.9.tar.gz",
        "has_sig": false,
        "md5_digest": "2d842bf9882f33be78975323fa2bb6b6",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 23645,
        "upload_time": "2022-07-04T13:26:10",
        "upload_time_iso_8601": "2022-07-04T13:26:10.897265Z",
        "url": "https://files.pythonhosted.org/packages/b2/06/fdf1779af7c77d5f47007514135a4a274b41b01ec30bd0e6ebd6ef41d5c2/tweetnlp-0.0.9.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5bcf2cf30e1e9898832cf1826fd48af1908cd5a130d028de31a2130ccc313406",
          "md5": "6cdc1bbb7bc3d2c84dccd0dfbc852348",
          "sha256": "05c5e4b956138c5a22e1e4074ff073fe45d989b3dfb2ba4701b6326ff8a0c390"
        },
        "downloads": -1,
        "filename": "tweetnlp-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "6cdc1bbb7bc3d2c84dccd0dfbc852348",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 24512,
        "upload_time": "2022-08-01T13:44:44",
        "upload_time_iso_8601": "2022-08-01T13:44:44.984399Z",
        "url": "https://files.pythonhosted.org/packages/5b/cf/2cf30e1e9898832cf1826fd48af1908cd5a130d028de31a2130ccc313406/tweetnlp-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6cad21489c5f1058b65a6f797c8594d55c0d6dbefb7d6681a32f30cf88575387",
          "md5": "f75d88c39558519402c31ff1feb111cc",
          "sha256": "cb5f4bed916893c95503f00a4e801cad2fdb3541b3fd8021a09c5f52c4bc6db7"
        },
        "downloads": -1,
        "filename": "tweetnlp-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "f75d88c39558519402c31ff1feb111cc",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 25014,
        "upload_time": "2022-09-25T23:16:33",
        "upload_time_iso_8601": "2022-09-25T23:16:33.921012Z",
        "url": "https://files.pythonhosted.org/packages/6c/ad/21489c5f1058b65a6f797c8594d55c0d6dbefb7d6681a32f30cf88575387/tweetnlp-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "545f46a667eda1fb51690bdf4a87a04706d3ddf007bfe94952325de408a03b42",
          "md5": "6389d7bddff059da0890d91fec3df3e0",
          "sha256": "56b1d6ec72964e689422c2713feea9cb530d4ee2639c4ffafc81c36cf6e35b0b"
        },
        "downloads": -1,
        "filename": "tweetnlp-0.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "6389d7bddff059da0890d91fec3df3e0",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 25032,
        "upload_time": "2022-09-26T22:50:16",
        "upload_time_iso_8601": "2022-09-26T22:50:16.149405Z",
        "url": "https://files.pythonhosted.org/packages/54/5f/46a667eda1fb51690bdf4a87a04706d3ddf007bfe94952325de408a03b42/tweetnlp-0.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2da4f7be99b7a135c94e78a8b34a7e3d8ec4b55355b780dcc1625e8189ad5ac6",
          "md5": "c21c1388085597ba40ed5857bd834b55",
          "sha256": "b881aa13e030b108345f6bde2ace36bd1d794e3ae77e2e463012bc2053ff277f"
        },
        "downloads": -1,
        "filename": "tweetnlp-0.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "c21c1388085597ba40ed5857bd834b55",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 33980,
        "upload_time": "2022-11-28T13:48:13",
        "upload_time_iso_8601": "2022-11-28T13:48:13.394095Z",
        "url": "https://files.pythonhosted.org/packages/2d/a4/f7be99b7a135c94e78a8b34a7e3d8ec4b55355b780dcc1625e8189ad5ac6/tweetnlp-0.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c81b46e9821faf0ef67697cce8f04d3b07daa4e9e5cdef0689128480b0a453ad",
          "md5": "d761651b7c6a24ff6aa925a9536a5f56",
          "sha256": "358278ebd0c591db0b32633bb089de83fc8dfedb9609aa8620e6525e272da3c1"
        },
        "downloads": -1,
        "filename": "tweetnlp-0.2.1.tar.gz",
        "has_sig": false,
        "md5_digest": "d761651b7c6a24ff6aa925a9536a5f56",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 34616,
        "upload_time": "2022-11-28T14:21:10",
        "upload_time_iso_8601": "2022-11-28T14:21:10.350078Z",
        "url": "https://files.pythonhosted.org/packages/c8/1b/46e9821faf0ef67697cce8f04d3b07daa4e9e5cdef0689128480b0a453ad/tweetnlp-0.2.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "297379134ae68bd6884cd26b257701b7adf7e11b00dd0c6108954ed22ef726be",
          "md5": "721c82e86fefac3f225b0ad4d096db6b",
          "sha256": "a89a51535ebabc11f618b56184ee8c6f75ef59c76b198d716f551868426dda5a"
        },
        "downloads": -1,
        "filename": "tweetnlp-0.2.2.tar.gz",
        "has_sig": false,
        "md5_digest": "721c82e86fefac3f225b0ad4d096db6b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 34484,
        "upload_time": "2022-11-28T15:01:56",
        "upload_time_iso_8601": "2022-11-28T15:01:56.276788Z",
        "url": "https://files.pythonhosted.org/packages/29/73/79134ae68bd6884cd26b257701b7adf7e11b00dd0c6108954ed22ef726be/tweetnlp-0.2.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "10c75340bd75d58173393322d42f2b09e7e70bc172a6d51783fe44b986b334c8",
          "md5": "d5708edcc75b107b13fcef2301f46b8e",
          "sha256": "e3373ae57f39ff9c651688ae51922c982acc89c143dc76ee6ce3063654a045a9"
        },
        "downloads": -1,
        "filename": "tweetnlp-0.3.0.tar.gz",
        "has_sig": false,
        "md5_digest": "d5708edcc75b107b13fcef2301f46b8e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 38088,
        "upload_time": "2022-11-29T12:07:08",
        "upload_time_iso_8601": "2022-11-29T12:07:08.878098Z",
        "url": "https://files.pythonhosted.org/packages/10/c7/5340bd75d58173393322d42f2b09e7e70bc172a6d51783fe44b986b334c8/tweetnlp-0.3.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "29f190bb234a3179a02d9380503cc6d2bf70d0f30978387a49ecad42232a725b",
          "md5": "c24506e115638c2da95216c422dbc8bc",
          "sha256": "1045cabe7d2887d59638a19af881b31178eefd59d68a57a43a6d7d130809ff43"
        },
        "downloads": -1,
        "filename": "tweetnlp-0.3.3.tar.gz",
        "has_sig": false,
        "md5_digest": "c24506e115638c2da95216c422dbc8bc",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 49801,
        "upload_time": "2022-12-01T22:23:42",
        "upload_time_iso_8601": "2022-12-01T22:23:42.270495Z",
        "url": "https://files.pythonhosted.org/packages/29/f1/90bb234a3179a02d9380503cc6d2bf70d0f30978387a49ecad42232a725b/tweetnlp-0.3.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "56d3076722eb3ff6f3f7aa447ff5198704325305f7f2a89ce432a0ec03fcc233",
          "md5": "25ecbc6fa2d429011643f55c7da3d372",
          "sha256": "46e3ee776cfa492a8bc6287a8ce3bc436f17a298c9547edcd38d2e99d28e7a26"
        },
        "downloads": -1,
        "filename": "tweetnlp-0.3.4.tar.gz",
        "has_sig": false,
        "md5_digest": "25ecbc6fa2d429011643f55c7da3d372",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 49059,
        "upload_time": "2022-12-01T23:56:36",
        "upload_time_iso_8601": "2022-12-01T23:56:36.297591Z",
        "url": "https://files.pythonhosted.org/packages/56/d3/076722eb3ff6f3f7aa447ff5198704325305f7f2a89ce432a0ec03fcc233/tweetnlp-0.3.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2f903237178ee685290458e81662c5d517b1a495318a78ccee7a9d0387f62846",
          "md5": "3e0432960cfaeb84ad42b30a4e6c73a8",
          "sha256": "f124e22fa6a103b1bbd52b5c2d07548883ff6455584522cff661334929ad6606"
        },
        "downloads": -1,
        "filename": "tweetnlp-0.4.0.tar.gz",
        "has_sig": false,
        "md5_digest": "3e0432960cfaeb84ad42b30a4e6c73a8",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 50726,
        "upload_time": "2022-12-04T19:16:32",
        "upload_time_iso_8601": "2022-12-04T19:16:32.661830Z",
        "url": "https://files.pythonhosted.org/packages/2f/90/3237178ee685290458e81662c5d517b1a495318a78ccee7a9d0387f62846/tweetnlp-0.4.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8c1e6e37f5c525d6cb55c24533701d09a800455ce500455d985d67b40f4334bb",
          "md5": "4fa979313e443b9658c0eaf13d853821",
          "sha256": "339bb43a38fd37166dfa61021e65097f1576d357ecd8d90255ab258f8f32dcf4"
        },
        "downloads": -1,
        "filename": "tweetnlp-0.4.1.tar.gz",
        "has_sig": false,
        "md5_digest": "4fa979313e443b9658c0eaf13d853821",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 54094,
        "upload_time": "2022-12-04T19:43:13",
        "upload_time_iso_8601": "2022-12-04T19:43:13.698814Z",
        "url": "https://files.pythonhosted.org/packages/8c/1e/6e37f5c525d6cb55c24533701d09a800455ce500455d985d67b40f4334bb/tweetnlp-0.4.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7f9384f4bd18892075f7b8feda303c8b99dc3f9d3a249ea1c26e5d8cc92a3e9e",
          "md5": "4f393c2fc284a37a893889e3f2d9f78e",
          "sha256": "9878a6da2d1af5054d2e761c6426aa4a9d73bbf9b89e7dc439852d0ca6b141c1"
        },
        "downloads": -1,
        "filename": "tweetnlp-0.4.2.tar.gz",
        "has_sig": false,
        "md5_digest": "4f393c2fc284a37a893889e3f2d9f78e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 53189,
        "upload_time": "2023-01-28T20:39:09",
        "upload_time_iso_8601": "2023-01-28T20:39:09.267539Z",
        "url": "https://files.pythonhosted.org/packages/7f/93/84f4bd18892075f7b8feda303c8b99dc3f9d3a249ea1c26e5d8cc92a3e9e/tweetnlp-0.4.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "7f9384f4bd18892075f7b8feda303c8b99dc3f9d3a249ea1c26e5d8cc92a3e9e",
        "md5": "4f393c2fc284a37a893889e3f2d9f78e",
        "sha256": "9878a6da2d1af5054d2e761c6426aa4a9d73bbf9b89e7dc439852d0ca6b141c1"
      },
      "downloads": -1,
      "filename": "tweetnlp-0.4.2.tar.gz",
      "has_sig": false,
      "md5_digest": "4f393c2fc284a37a893889e3f2d9f78e",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 53189,
      "upload_time": "2023-01-28T20:39:09",
      "upload_time_iso_8601": "2023-01-28T20:39:09.267539Z",
      "url": "https://files.pythonhosted.org/packages/7f/93/84f4bd18892075f7b8feda303c8b99dc3f9d3a249ea1c26e5d8cc92a3e9e/tweetnlp-0.4.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}