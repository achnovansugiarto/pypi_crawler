{
  "info": {
    "author": "Phume Ngampornsukswadi",
    "author_email": "thisisphume@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: Apache Software License",
      "Natural Language :: English",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8"
    ],
    "description": "# Embedding Tool\n> An embedding toolkit that can perform multiple embedding process which are low-dimensional embedding (dimension reduction), categorical variable embedding, and financial time-series embedding.\n\n\n## Install\n\n`pip install embedding-tool`\n\n```python\nfrom embedding_tool.core import *\n```\n\n## How to use\n\n### Dimension Reduction: `dimensionReducer` class\nThe function performs dimensionality reduction, pre-processing the data and comparing the reconstruction error via PCA and autoencoder.\n\n**Input data:**\nThe input matrix has a size of 863 $\\times$ 768.\n\n```python\nprint (\"Data's size: \", testing_data.shape)\n```\n\n    Data's size:  (863, 768)\n\n\n**Performing dimension reduction:** we will reduce the number of dimension from 768 to 2. The learning rate of 0.002 will be use for the ADAM optimizer for the autoencoder model fitting.\n\n```python\ndim_reducer = dimensionReducer(testing_data, 2, 0.002)\ndim_reducer.fit()\n```\n\n**Calculating the MSE of the reconstructed vectors**\n\n```python\ndim_reducer.rmse_result\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PCA</th>\n      <th>1AE</th>\n      <th>2AE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>MSE</th>\n      <td>0.740122</td>\n      <td>0.741265</td>\n      <td>0.65168</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n```python\ndim_reducer.rmse_result.T.sort_values('MSE').head(1).values[0][0]\n```\n\n\n\n\n    0.6516801665399286\n\n\n\nHere we can see that the two-layers autoencoder has the best performance with the lowest MSE of 0.64.\n\n**Observing the loss for each epoch:** If we see that the MSE doesn't converge fast enough, we could adjust the learning rate parameter. The default is 0.002. Try increase it to 0.005 if it doesn't converge or decrease to 0.001 if it converges way too fast and oscillating.\n\n```python\ndim_reducer.plot_autoencoder_performance()\n```\n\n\n![png](docs/images/output_14_0.png)\n\n\n\n![png](docs/images/output_14_1.png)\n\n\n**Result (Reduced Dimension Output):** There are three outputs from three different methods, which are PCA, 1-layer AE, and 2-layers AE.\n\n```python\n### Embedding from PCA\ndim_reducer.dfLowDimPCA.head()\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-16.078718</td>\n      <td>-6.701481</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-8.858150</td>\n      <td>9.354204</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.305739</td>\n      <td>-0.464707</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-11.514311</td>\n      <td>-0.687461</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.212006</td>\n      <td>6.537965</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n```python\n### Embedding from 1-layer autoencoder\ndim_reducer.dfLowDim1AE.head()\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-6.178097</td>\n      <td>4.734626</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.075333</td>\n      <td>5.529111</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.953502</td>\n      <td>-1.667776</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-2.488155</td>\n      <td>4.001960</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.183654</td>\n      <td>0.589496</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n```python\n### Embedding from 2-layers autoencoder\ndim_reducer.dfLowDim2AE.head()\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>32.622066</td>\n      <td>54.652271</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>35.649811</td>\n      <td>40.493984</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>15.314294</td>\n      <td>5.869064</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>19.667603</td>\n      <td>37.821194</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>36.183212</td>\n      <td>25.429262</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n**Plotting the embedding**\n\n```python\n### Embedding from 2-layers autoencoder\nplot_output(dim_reducer.dfLowDim2AE)\n```\n\n\n![png](docs/images/output_20_0.png)\n\n\n```python\n### Embedding from 1-layer autoencoder\nplot_output(dim_reducer.dfLowDim1AE)\n```\n\n\n![png](docs/images/output_21_0.png)\n\n\n***\n\n# Reference: \n- https://towardsdatascience.com/dimensionality-reduction-pca-versus-autoencoders-338fcaf3297d\n- https://towardsdatascience.com/autoencoders-vs-pca-when-to-use-which-73de063f5d7\n\n***\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/thisisphume/embedding_tool/tree/master/",
    "keywords": "autoencoder PCA embedding",
    "license": "Apache Software License 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "embedding-tool",
    "package_url": "https://pypi.org/project/embedding-tool/",
    "platform": "",
    "project_url": "https://pypi.org/project/embedding-tool/",
    "project_urls": {
      "Homepage": "https://github.com/thisisphume/embedding_tool/tree/master/"
    },
    "release_url": "https://pypi.org/project/embedding-tool/0.1.1/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "An embedding toolkit that can perform multiple embedding process which are low-dimensional embedding (dimension reduction), categorical variable embedding, and financial time-series embedding.",
    "version": "0.1.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 9053706,
  "releases": {
    "0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "abd3b30163425be8baedb965c949b121535f9deca15ea16fca131506aaea91e0",
          "md5": "474a93bce84e0033799340432e50d1c4",
          "sha256": "145fa065fe7637a4eb49bac3715b0b7f23bfdf8f81b4a70048d6b9ba913284a6"
        },
        "downloads": -1,
        "filename": "embedding_tool-0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "474a93bce84e0033799340432e50d1c4",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 9158,
        "upload_time": "2021-01-05T00:31:46",
        "upload_time_iso_8601": "2021-01-05T00:31:46.055491Z",
        "url": "https://files.pythonhosted.org/packages/ab/d3/b30163425be8baedb965c949b121535f9deca15ea16fca131506aaea91e0/embedding_tool-0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6de3ac6d156b88e484ebbba9a26529da3938497411b6e805d17f29fc04b6784c",
          "md5": "f6ec9f20d8953dc1ee4b8af74966553b",
          "sha256": "b45cd9957d4202941ec00c58c5121d7785f377af39e100627073eb43cda476f2"
        },
        "downloads": -1,
        "filename": "embedding_tool-0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "f6ec9f20d8953dc1ee4b8af74966553b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 11188,
        "upload_time": "2021-01-05T00:31:47",
        "upload_time_iso_8601": "2021-01-05T00:31:47.373444Z",
        "url": "https://files.pythonhosted.org/packages/6d/e3/ac6d156b88e484ebbba9a26529da3938497411b6e805d17f29fc04b6784c/embedding_tool-0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "32676592b842d94e5adefae7bc6ceb1e270194cfafb90377a2ac9d5f960bbf3d",
          "md5": "03fe0cea66a3e38cdd5793820071e85b",
          "sha256": "ad8d2744db7b2ceb5a07648897f34bf89f4550d93e8c988eda8011c4d37dbaf4"
        },
        "downloads": -1,
        "filename": "embedding_tool-0.1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "03fe0cea66a3e38cdd5793820071e85b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 10295,
        "upload_time": "2021-01-05T02:11:40",
        "upload_time_iso_8601": "2021-01-05T02:11:40.653350Z",
        "url": "https://files.pythonhosted.org/packages/32/67/6592b842d94e5adefae7bc6ceb1e270194cfafb90377a2ac9d5f960bbf3d/embedding_tool-0.1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c06aec4a0a8eae6bc152d71876b838dcd6f2659ea1802a45ecfef962a9d2aaf1",
          "md5": "08d45eadcb0933bc5cb461373b8bc2f9",
          "sha256": "ba25923674b1fa87e84b804155feec02cb399bf0f7ba8b7b2e4cefa551d2047b"
        },
        "downloads": -1,
        "filename": "embedding_tool-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "08d45eadcb0933bc5cb461373b8bc2f9",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 13548,
        "upload_time": "2021-01-05T02:11:42",
        "upload_time_iso_8601": "2021-01-05T02:11:42.016724Z",
        "url": "https://files.pythonhosted.org/packages/c0/6a/ec4a0a8eae6bc152d71876b838dcd6f2659ea1802a45ecfef962a9d2aaf1/embedding_tool-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "32676592b842d94e5adefae7bc6ceb1e270194cfafb90377a2ac9d5f960bbf3d",
        "md5": "03fe0cea66a3e38cdd5793820071e85b",
        "sha256": "ad8d2744db7b2ceb5a07648897f34bf89f4550d93e8c988eda8011c4d37dbaf4"
      },
      "downloads": -1,
      "filename": "embedding_tool-0.1.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "03fe0cea66a3e38cdd5793820071e85b",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 10295,
      "upload_time": "2021-01-05T02:11:40",
      "upload_time_iso_8601": "2021-01-05T02:11:40.653350Z",
      "url": "https://files.pythonhosted.org/packages/32/67/6592b842d94e5adefae7bc6ceb1e270194cfafb90377a2ac9d5f960bbf3d/embedding_tool-0.1.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "c06aec4a0a8eae6bc152d71876b838dcd6f2659ea1802a45ecfef962a9d2aaf1",
        "md5": "08d45eadcb0933bc5cb461373b8bc2f9",
        "sha256": "ba25923674b1fa87e84b804155feec02cb399bf0f7ba8b7b2e4cefa551d2047b"
      },
      "downloads": -1,
      "filename": "embedding_tool-0.1.1.tar.gz",
      "has_sig": false,
      "md5_digest": "08d45eadcb0933bc5cb461373b8bc2f9",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 13548,
      "upload_time": "2021-01-05T02:11:42",
      "upload_time_iso_8601": "2021-01-05T02:11:42.016724Z",
      "url": "https://files.pythonhosted.org/packages/c0/6a/ec4a0a8eae6bc152d71876b838dcd6f2659ea1802a45ecfef962a9d2aaf1/embedding_tool-0.1.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}