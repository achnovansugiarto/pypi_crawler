{
  "info": {
    "author": "Taig Singh",
    "author_email": "taig.singh@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 2 - Pre-Alpha",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Topic :: Scientific/Engineering :: Astronomy",
      "Topic :: Scientific/Engineering :: Physics"
    ],
    "description": "\n\n# spokes: an end-to-end simulation facility for spectroscopic cosmological surveys\n\n***\n- [What is it?](#what-is-it)\n- [Main Features](#main-features)\n- [Where to Get it](#where-to-get-it)\n- [Dependencies](#dependencies)\n- [The Units](#the-units)\n- [The Databank](#the-databank)\n- [The Experiment Parameters File](#the-experiment-parameters-file)\n- [Usage](#usage)\n- [Discussion and Development](#discussion-and-development)\n***\n\n### What is it?\n**SPOKES** (SPectrOscopic KEn Simulation) provides a simulation tool for wide-field spectroscopic survey instruments to **forecast science performance, define requirement flow-downs, optimize implementation, demonstrate feasibility, and prepare for exploitation.** This facility has the broad goal of aiding the pursuit of some of the most pressing questions in cosmology, including the nature of dark matter, dark energy, and large-scale gravity. The SPOKES framework enables a rigorous process to optimize and exploit spectroscopic survey experiments to derive high-precision cosmological measurements optimally.\n\n### Main Features\nThe main features the SPOKES package is built upon:\n* Integrated infrastructure\n* Modular functioning organization\n* Coherent data handling\n* Fast data access\n\nThese features allow for the **reproducibility of pipeline runs, enable ease of use, and provide flexibility to update functions within the pipeline.**\n\n### Where to Get it\nThe source code is currently hosted on GitHub at:\nhttps://github.com/deepskies/spokes\n```sh\n# PyPI\npip install spokes\n```\n\n### Dependencies\n* [NumPy](https://www.numpy.org): Used for fast data manipulation and handling on large n-dimensional arrays\n* [h5py](https://www.h5py.org/): Used Pythonic reading and writing to the central data bank which is in HDF5 format\n* [PyYAML](https://pyyaml.org/): Used for Pythonic reading of the user-created experiment parameters which is written in the YAML programming language\n* *[Dropbox](https://www.dropbox.com/developers/documentation/python): Optional dependency for downloading default databank from Dropbox*\n\n### The Units\nThe SPOKES facility implements a 12 unit infrastructure:\n1. **Setup**: Duplicates databank and imports user parameters.\n2. **Select Targets**: Selects targets for spectroscopic observation from the photometric catalog of galaxies in the databank using user-defined parameters for color and magnitude cuts.\n3. **Tile Survey**: Implements the survey strategy by tiling the instrument field of view across a user-specified sky region, while optimizing observations for simulated environmental and sky conditions.\n4. **Allocate Fibers**: Matches fibers to positions in the focal plane of targeted galaxies (see Module 1) for each tile scheduled in the survey.\n5. **Calculate Throughput**: Calculates the total optical transmission efficiency as a function of wavelength for the principal elements in the light path of the instrument.\n6. **Simulate Spectrum**:  constructs models of the intrinsic rest-frame and of the observed-frame spectral energy distributions for each galaxy that has been scheduled for targeting.\n7. **Generate Spectrum Noise**:  the transmission throughput and simulated spectra (generated in Module 4 and Module 5, respectively) are used to produce a complete noise spectrum that also includes photon shot noise, spectrograph CCD read noise, and noise from the atmosphere (extinction and sky background).\n8. **Measure Redshift**: measures the spectroscopic redshift, zspec, of the galaxies from observed spectra.\n9. **Bin Redshift**: distributes the galaxies into bins of spectroscopic redshift (measured in Module 7), according to a user-defined parameter for the number of bins.\n10. **Calculate Selection Function**: calculates the selection function in space (Right Ascension and Declination) and redshift of the observed spectroscopic galaxy catalog.\n11. **Estimate Cosmology Parameters**: forecasts the cosmology-constraining power of a given survey configuration by analyzing the catalog of galaxies observed in this pipeline.\n12. **Report Results**: generates a report that summarizes the run with figures for assessing the computational and science performance.\n\nEach unit takes data and parameters from the central databank and creates new data to be used later in the pipeline. Units access only the data they need from the databank, which simplifies the interfaces between units and makes them highly independent of one another. Note that the only interaction between units occurs via the exchange of data with the databank.\n\n*Functionality for the implementation of user-created units to replace given units is also provided. Function names within these files must match those in the matching default spokes unit. It is highly recommended that the user looks at the source code for the project [here](https://github.com/deepskies/spokes) and edits the physics of the individual unit while keeping the inputs and outputs of the unit constant to keep it compatible with the pipeline.*\n\n### The Databank\nThe SPOKES facility adopts a solution based on the Hierarchical Data Format (HDF5) for its data management. This scheme for the central databank allows the data formatting to be able to handle many data types, scale efficiently to handle large amounts of data, and be flexible enough to store all data for a rapidly developed pipeline.\n\nIn an HDF5 file, the data are organized in unique paths, like a hard disk filesystem (e.g., */group/subgroup/dataset*): each data set resides in a 'group' and its 'subgroup', which are named descriptively in SPOKES to associate related data and improve code readability. The data sets can be of a variety of data types, including arrays.\n\nThe data groups in the databank are partitioned according to both unit usage and related information. These are all of the groups used throughout the pipeline, initialized within the Setup unit.\n* **AnalysisChoices**: contains the information with which to specify the analysis methods\n* **Constants**: holds physical constants and random seeds\n* **Ensemble**: contains data on the galaxies as a collection\n* **Environment**: contains the information regarding the atmosphere (absorption and emission spectra) and location\n* **Fibers**: contains information about the fibers that are assigned to galaxies\n* **Galaxies**: contains all galaxy data, **this is the only data group required in the databank when the pipeline is initialized**\n* **Instrument**: contains several subgroups representing the subsystems of the instrument (optics, fibers, and spectrograph) each of which has several parameters\n* **RuntimeParameters**: contains parameters that determine how the simulation will be run\n* **SpectralTemplates**: contain the eigentemplates used to reconstruct galaxy spectra\n* **SurveyParameters**: holds the data necessary to run the survey, for example, exposure time per tile and region of the sky to be observed\n* **SurveyTiles**: contains a set of tile information (sky position, airmass, time of observation, etc) and is used to link galaxies with the time and observation environment in which they were observed\n* **Throughput**: Contains parameters and information on the throughput of the spectrograph\n\nWhen the pipeline is initialized, a path to the user's source H5 databank must be given in the experiment parameters file (described below). This databank must *only* have a \"Galaxies\" data group formatted in the following arrays:\n* *db[\"Galaxies/central\"]* - array - 1 if galaxy is the central galaxy in the halo, 0 if not\n* *db[\"Galaxies/coeffs\"]* - 2D array - list of spectrum coefficients for each galaxy\n* *db[\"Galaxies/dec_true\"]* - array - declination for each galaxy\n* *db[\"Galaxies/flux\"]* - array - flux for each galaxy\n* *db[\"Galaxies/galaxy_index\"]* - array - index for each galaxy\n* *db[\"Galaxies/m200\"]*- array - mass of each galaxy in solar masses\n* *db[\"Galaxies/magnitude_g\"]* - array - apparent astronomical magnitude for each galaxy in the g wavelength bands\n* *db[\"Galaxies/magnitude_hh\"]* - array - apparent astronomical magnitude for each galaxy in the hh wavelength bands\n* *db[\"Galaxies/magnitude_i\"]* - array - apparent astronomical magnitude for each galaxy in the i wavelength bands\n* *db[\"Galaxies/magnitude_r\"]* - array - apparent astronomical magnitude for each galaxy in the r wavelength bands\n* *db[\"Galaxies/magnitude_u\"]* - array - apparent astronomical magnitude for each galaxy in the u wavelength bands\n* *db[\"Galaxies/magnitude_y\"]* - array - apparent astronomical magnitude for each galaxy in the y wavelength bands\n* *db[\"Galaxies/magnitude_z\"]* - array - apparent astronomical magnitude for each galaxy in the z wavelength bands\n* *db[\"Galaxies/px\"]* - array - x position of each galaxy\n* *db[\"Galaxies/py\"]* - array - y position of each galaxy\n* *db[\"Galaxies/pz\"]* - array - z position of each galaxy\n* *db[\"Galaxies/ra_true\"]* - array - right ascension for each galaxy\n* *db[\"Galaxies/redshift_photometric\"]* - array - photometric redshift for each galaxy\n* *db[\"Galaxies/z_true\"]* - array - known true redshift for each galaxy\n\nYou may also download the SPOKES default databank using the `download_databank(path to download directory)` , or download it yourself at [this Dropbox link](https://www.dropbox.com/s/ivk3ycbvms3v3jc/data_bank.h5?dl=0).\n\n### The Experiment Parameters File\nThe SPOKES facility utilizes a singular YAML file containing all of the user-specific experiment parameters, that are then passed to the `run_simulation(path to experiment parameters file)` function. This allows for clean and reproducible pipeline runs.\n\nCreate a file like the one below using your own experiment parameters:\n```yaml\nPrerunParameters:\n  order: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11] # array[int] - Which units to run and in what order\n  data_bank: 'DATA/data_bank.h5' # string - Path to data_bank\n  duplicate_data_bank: True # boolean - Duplicate data_bank or not\n  log_dir: 'LOGS/' # string - Directory to put logfile in or 'None' for no log file\nUser-createdUnits:\n  # IMPORTANT: All user-created units must be in the same directory as the file where run_simulation is called\n  Setup: \"Default\" # string - Name of user-created Setup module (does not contain '.py'), 'Default' for default spokes unit\n  SelectTargets: \"Default\" # string - Name of user-created Select Targets module (does not contain '.py'), 'Default' for default spokes unit\n  TileSurvey: \"Default\" # string - Name of user-created Tile Survey module (does not contain '.py'), 'Default' for default spokes unit\n  AllocateFibers: \"Default\" # string - Name of user-created Allocate Fibers module (does not contain '.py'), 'Default' for default spokes unit\n  CalculateThroughput: \"Default\" # string - Name of user-created Calculate Throughput module (does not contain '.py'), 'Default' for default spokes unit\n  SimulateSpectrum: \"Default\" # string - Name of user-created Simulate Spectrum module (does not contain '.py'), 'Default' for default spokes unit\n  GenerateSpectrumNoise: \"Default\" # string - Name of user-created Generate Spectrum Noise module (does not contain '.py'), 'Default' for default spokes unit\n  MeasureRedshift: \"Default\" # string - Name of user-created Measure Redshift module (does not contain '.py'), 'Default' for default spokes unit\n  BinRedshift: \"Default\" # string - Name of user-created Bin Redshift module (does not contain '.py'), 'Default' for default spokes unit\n  CalculateSelectionFunction: \"Default\" # string - Name of user-created Calculate Selection Function module (does not contain '.py'), 'Default' for default spokes unit\n  EstimateCosmologyParameters: \"Default\" # string - Path to user-created Estimate Cosmology Parameters module (does not contain '.py'), 'Default' for default spokes unit\n  ReportResults: \"Default\" # string - Path to user-created Report Results module (does not contain '.py'), 'Default' for default spokes unit\nRuntimeParameters:\n  verbose: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11] # array[int] - Units with verbose logging\n  generate_plot: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11] # array[int] - Units to generate plots for\n  plot_image_file_type: 'png' # string - Plot image type\nTargetSelection:\n  dummy_magcut_range: [0, 90] # array[int] - Dummy magnitude range\n  #                          cst      u     g     r     i     z     y     H     photo-z     2D array[int] - Luminous red galaxies magnitude cutting range\n  lrg_linear_cuts_coeffs: [ [-22,     0,    0,    0,    0,    1,    0,    0,    0], # z < 22\n                            [1.5,     0,    0,    -1,   0,    1,    0,    0,    0]] # r-z > 1.5\n  lrg_linear_cuts_connector: \"intersection\" # string - Luminous red galaxies cutting connector: \"intersection\" or \"union\"\n  #                          cst      u     g     r     i     z     y     H     photo-z     2D array[int] - Emission line galaxies magnitude cutting range\n  elg_linear_cuts_coeffs: [ [-23.4,   0,    0,    1,    0,    0,    0,    0,    0], # r < 23.4\n                            [.1,      0,    0,    -1,   1,    0,    0,    0,    0], # r-i > 0.1\n                            [-1.3,    0,    0,    1,    -1,   0,    0,    0,    0], # r-i < 1.3\n                            [-0.2,    0,    -1,   1,    0,    0,    0,    0,    0], # g-r > -0.2\n                            [-0.3,    0,    1,    -1,   0,    0,    0,    0,    0]] # g-r < 0.3\n  elg_linear_cuts_connector: \"intersection\" # string - Emission line galaxies cutting connector: \"intersection\" or \"union\"\nSurveyParameters:\n  right_ascension_range: [295, 337] # array[int] - Right ascension range in degrees\n  declination_range: [-6, 2] # array[int] - Declination range in degrees\n  field_of_view: 1 # int - Radius of each tile in degrees\n  tile_shape: \"hexagonal\" # string - shape of the tile: \"square\" or \"hexagonal\"\nFibers:\n  nb_fibers: 4000 # int - Number of fibers\nRedshiftBinning:\n  nb_bins: 5 # int - Number of bins in redshift histogram\nSelectionFunction:\n  ztrue_resolution: 0.0001 # float - True redshift resolution\n  delta_ztrue_resolution: 0.00001 # float - Delta true redshift resolution\n```\n*Full documentation for Experiment Parameters YAML file coming soon...*\n\n### Usage\nThis is an example of a pipeline run where the file is in the same directory as the Experiment Parameters file and where the user wants to download the SPOKES default databank into a folder called \"DATA\"\n```python\nfrom spokes import run_simulation, download_databank\ndownload_databank(\"DATA/\") # Only needed if downloading default databank\nrun_simulation(\"experiment_parameters.yml\")\n```\n\n### Discussion and Development\nBugs and issues can be reported [here](https://github.com/deepskies/spokes/issues), or send an email to Taig Singh at taig.singh@gmail.com.\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/deepskies/spokes",
    "keywords": "",
    "license": "",
    "maintainer": "Taig Singh",
    "maintainer_email": "taig.singh@gmail.com",
    "name": "spokes",
    "package_url": "https://pypi.org/project/spokes/",
    "platform": "",
    "project_url": "https://pypi.org/project/spokes/",
    "project_urls": {
      "Bug Tracker": "https://github.com/deepskies/spokes/issues",
      "Homepage": "https://github.com/deepskies/spokes",
      "Source Code": "https://github.com/deepskies/spokes"
    },
    "release_url": "https://pypi.org/project/spokes/0.1.0/",
    "requires_dist": [
      "numpy",
      "h5py",
      "pyyaml",
      "dropbox ; extra == 'data'"
    ],
    "requires_python": "",
    "summary": "An End-to-End Simulation Facility for Spectroscopic Cosmological Surveys",
    "version": "0.1.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 11182402,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e2e4a2c0605a883d2f9a7a2f4f814e8d2cbf487edee9cc284b45eacfac018dea",
          "md5": "3e851f6d128e8a4f3f4634720334c62f",
          "sha256": "dc57b6292e8f7aae843cd35024592534efb21535b6f46e1a9561595905efa051"
        },
        "downloads": -1,
        "filename": "spokes-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "3e851f6d128e8a4f3f4634720334c62f",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 23870,
        "upload_time": "2021-08-15T08:54:47",
        "upload_time_iso_8601": "2021-08-15T08:54:47.588805Z",
        "url": "https://files.pythonhosted.org/packages/e2/e4/a2c0605a883d2f9a7a2f4f814e8d2cbf487edee9cc284b45eacfac018dea/spokes-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "e2e4a2c0605a883d2f9a7a2f4f814e8d2cbf487edee9cc284b45eacfac018dea",
        "md5": "3e851f6d128e8a4f3f4634720334c62f",
        "sha256": "dc57b6292e8f7aae843cd35024592534efb21535b6f46e1a9561595905efa051"
      },
      "downloads": -1,
      "filename": "spokes-0.1.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "3e851f6d128e8a4f3f4634720334c62f",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 23870,
      "upload_time": "2021-08-15T08:54:47",
      "upload_time_iso_8601": "2021-08-15T08:54:47.588805Z",
      "url": "https://files.pythonhosted.org/packages/e2/e4/a2c0605a883d2f9a7a2f4f814e8d2cbf487edee9cc284b45eacfac018dea/spokes-0.1.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}