{
  "info": {
    "author": "Joerg Schneider",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "blizz – _be blizzful_\n=====================\n**effortless Python table schema management**\n\n\nIf you are looking for…\n\n📋 …an lightweight option to capture data schemas and field annotations for either Pandas or PySpark,\n\n⭐ …which makes table definitions available not just at runtime, but already while developing code\n– with IDE type checking and autocomplete!\n\n❄️ …which allows dynamic schema inheritance/reference, to express several levels of derived data assets –\nas common in stable data pipelines – tracing the full data field lineage across your project and boosting\nrefactoring and debugging productivity,\n\n🚀 …which offers pre-built PySpark & Pandas decorators for most common data checks & transformations – all based\non metadata,\n\n🏃 …which supports your workflow with boostrapping tools to generate basic code and Sphinx documentations\n\nthen **blizz** is for you!\n\n**Contents:**\n\n- [Installation](#installation)\n- [Usage Tutorial](#usage-tutorial)\n    - [blizz primitives: Relation and Field](#blizz-primitives-relation-and-field)\n        - [Basic usage with pandas](#basic-usage-with-pandas)\n        - [Using field definitions](#using-field-definitions-inside-of-load)\n        - [Defining metadata properties](#defining-metadata-properties-on-field)\n        - [Relation Hierarchies](#relation-hierarchies)\n        - [Making use of metadata declarations: blizz.check & blizz.apply](#making-use-of-metadata-declarations-blizzcheck--blizzapply)\n        - [Using blizz with Pyspark](#using-blizz-with-pyspark)\n        - [API Reference on Relation and Field](#api-reference-on-relation-and-field)\n        - [API Reference on blizz.check & blizz.apply](#api-reference-on-blizzcheck--blizzapply)\n    - [Boostrapping – generate schema definitions from DataFrames](#bootstrapping--generate-schema-definitions-from-dataframes)    \n    - [Beyond: blizz Feature Store](#beyond-blizz-feature-library)\n    - [Beyond: Generate Documentation](#beyond-generate-documentation)\n    \n# Installation\nYou can install the latest stable version of _blizz_ simply using Pip:\n\n``pip install blizz``\n\nNote, that either `pandas` or `pyspark` need to be installed separately, if you do\nnot have them already.\n\nIf you have any issues, questions or suggestions – do not hesitate to open an GitHub issue.\n\nA test installation from the latest sources is possible as well:\n\n``pip install git+https://github.com/joerg-schneider/blizz/#egg=blizz``\n\n# Usage Tutorial\nThe following is an introduction and basic tutorial to _blizz_. You can find also some example scripts in\n[src/tutorial](src/tutorial) of this repository.\n\n## blizz primitives: **Relation** and **Field**\n`blizz.Relation` and `blizz.Field` are the main primitives implementing its behaviour. \n\nA relation – in the computer scientific sense – refers here to any table/dataframe/... one\nlikes to define, made up of rows and columns, the latter defined by `blizz.Field`.\nDataFrames from PySpark and Pandas are the supported means of capturing data instances to\nwhich a given _Relation_ applies to.\n\nThe following sections explain how to use `blizz.Relation` and `blizz.Field`.\n\n### Basic usage with Pandas\n\nThe following is a minimal example of creating a Relation with _blizz_:\n\n- define your _Relation_ as a subclass from _blizz's_ `Relation` superclass\n- add some field names as members\n- add `load()` as a classmethod and implement it to return either a Spark or Pandas DataFrame\n\n```python\nfrom blizz import Relation, Field\nimport pandas as pd\n\nclass Iris(Relation):\n\n    SEPAL_LENGTH = Field(\"sepal_length\")\n    SEPAL_WIDTH = Field(\"sepal_width\")\n    PETAL_LENGTH = Field(\"petal_length\")\n    PETAL_WIDTH = Field(\"petal_width\")\n    SPECIES = Field(\"species\")\n\n    @classmethod\n    def load(cls) -> pd.DataFrame:\n        return pd.read_csv(\n            \"https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7\"\n            \"/raw/0e7a9b0a5d22642a06d3d5b9bcbad9890c8ee534/iris.csv\"\n        )\n```\n\n\nCalling `load()` on the Relation, we can retrieve a dataframe:\n```python\niris_df = Iris.load()\n```\n\nMost importantly, now using the Relation's Schema, we can access/modify `iris_df` referencing fields we like:\n```python\nprint(iris_df[[Iris.SEPAL_LENGTH, Iris.SEPAL_WIDTH]])\n```\n\nA command like above now references the member variables on Iris to access fields – these will also be autocompleted\nby your IDE, checked if they exist (avoiding typos) and allow easy refactoring (e.g. if the column name changes in\nthe source – just change it once in `Field(...)`!).\n\n### Using Field definitions inside of load()\nSince `load()` is a class method, it is easily possible to refer to defined __Fields__ already in it:\n\n```python\nfrom blizz import Relation, Field\nimport pandas as pd\n\nclass Iris(Relation):\n\n    SEPAL_LENGTH = Field(\"sepal_length\")\n    SEPAL_WIDTH = Field(\"sepal_width\")\n    PETAL_LENGTH = Field(\"petal_length\")\n    PETAL_WIDTH = Field(\"petal_width\")\n    SPECIES = Field(\"species\")\n    \n    # a newly defined field:\n    SEPAL_PETAL_WIDTH = Field(\"sepal_petal_width\")\n\n    @classmethod\n    def load(cls) -> pd.DataFrame:\n        iris = pd.read_csv(\n            \"https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7\"\n            \"/raw/0e7a9b0a5d22642a06d3d5b9bcbad9890c8ee534/iris.csv\"\n        )\n        iris[cls.SEPAL_PETAL_WIDTH] = iris[cls.SEPAL_WIDTH] + iris[cls.PETAL_WIDTH]\n        return iris\n```\nIn this example, one can see how to add another, derived field to the _Relation_ which is just\nbuilt on loading, leveraging existing _Field_ references.\n\n### Defining Metadata properties on Field\n`Field` is implemented in an elegant way: It cleanly folds down to a Python string when you use it as part\nof an expression (e.g. inside of square brackets for Pandas), but actually, _it is not a string_.\n\nIn the previous examples, _Fields_ have been only constructed using its default first attribute, `.name`. \nHowever, it does also support a big variety of useful declarations one might like to make (see\n`API Reference on Relation and Field` below!), such as defining datatypes, adding a description or\nthe _Field's_ default value:\n\n```python\nclass Iris(Relation):\n    # setting some example additional Field attributes:\n    # 1. of course most importantly, one can set a datatype to complete the\n    #    Relation's schema definition in the classical sense:\n    SEPAL_LENGTH = Field(\"sepal_length\", datatype=float)\n\n    # for use with Pandas, `datatype` accepts Python inbuilts (e.g. float, object, int),\n    # quoted names of Pandas datatypes, and also instances of numpy types, such as\n    # numpy.int, numpy.number, etc.\n\n    # 2. to capture metadata, and for documentation purposes, a description can be set:\n    SEPAL_WIDTH = Field(\"sepal_width\", description=\"The Sepal length\")\n\n    # 3. `default` also to capture a default row value for a Field:\n    PETAL_LENGTH = Field(\"petal_length\", default=0.0)\n    PETAL_WIDTH = Field(\"petal_width\")\n\n    # 4. the boolean flag `key` allows to specify key fields:\n    SPECIES = Field(\"species\", key=True)\n\n    @classmethod\n    def load(cls) -> pd.DataFrame:\n        iris = pd.read_csv(\n            \"https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7\"\n            \"/raw/0e7a9b0a5d22642a06d3d5b9bcbad9890c8ee534/iris.csv\"\n        )\n        # using all defined key fields, one could run a simply deduplication command:\n        iris_dedup = iris.drop_duplicates(subset=cls.get_key_fields())\n        return iris_dedup\n```\n\n### Relation hierarchies\nSince Fields are Python variables (class members of `Relation`), this makes building connected Relations very easy:\n\n```python\n# based on Iris, we can define a derived second Relation `IrisSepal`:\n\nclass IrisSepal(Relation):\n    \"\"\" All records of Iris but filtered on a subset of Fields, just for the Sepal.\"\"\"\n\n    # we can simply reference the existing definitions that were made:\n    SEPAL_LENGTH = Iris.SEPAL_LENGTH\n    SEPAL_WIDTH = Iris.SEPAL_WIDTH\n    SPECIES = Iris.SPECIES\n\n    @classmethod\n    def load(cls) -> pd.DataFrame:\n        # we call Iris's load() method but filter it down to `IrisSepal`'s fields:\n        return Iris.load()[cls.get_field_names()]\n```\nIn the example above, the `load()` method additionally shows that each `Relation` offers helpful\nmethods to interact with metadata – in this case `get_field_names()` can retrieve all defined\nfields as strings. See _API Reference on Relation and Field_ for the full list of available\nmethods.\n\n### Making use of metadata declarations: blizz.check & blizz.apply\n\nHaving defined structured metadata on a Relation's fields can be very powerful to carry out\nbasic operations.\n\nFor this purpose, `blizz` defines two modules with Python function decorators, meant to be\nadded on-top of the `load()` method:\n\n- `blizz.check`: defines several utilities to check a loaded Relation against the definition \n- `blizz.apply`: defines several utilities for often occuring transformations to the Relation's \n  dataframe\n\nAll of these utlities work are implemented with equal functionality on Pandas and Pyspark.\n\nConsider this example, which takes care of schema checking (field names, field types, field keys),\ndeduplication and checking for duplicates:\n```python\nfrom blizz import Relation, Field\nimport blizz.check, blizz.apply\nimport pandas as pd\n\nclass Iris(Relation):\n\n    SEPAL_LENGTH = Field(\"sepal_length\", datatype=float)\n    SEPAL_WIDTH = Field(\"sepal_width\", datatype=float)\n    PETAL_LENGTH = Field(\"petal_length\", default=0.0)\n    PETAL_WIDTH = Field(\"petal_width\", datatype=float)\n    SPECIES = Field(\"species_renamed\", datatype=object, key=True, source_name=\"species\")\n\n    @classmethod\n    @blizz.check.types\n    @blizz.check.fields\n    @blizz.check.keys\n    @blizz.apply.defaults(fill=PETAL_LENGTH)  # you can use field as arguments, too!\n    @blizz.apply.deduplication\n    @blizz.apply.renames  # renames should be applied first\n    def load(cls) -> pd.DataFrame:\n        return pd.read_csv(\n            \"https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7\"\n            \"/raw/0e7a9b0a5d22642a06d3d5b9bcbad9890c8ee534/iris.csv\"\n        )\n\n\nprint(Iris.load())\n```\n\nIt is important to note, that these decorator utilities __execute after the load() function\nhas finished__, and the order of writing them matters. As an example, it makes more sense\nto execute `blizz.apply.deduplication` first, and then check its result with `blizz.check.keys`\n(unless you already expect it deduplicated, then avoid `blizz.apply.deduplication` entirely!).\n\nIn this use case, your decorators have to be defined in this order (lowest one runs first):\n\n```python\n    @classmethod\n    @blizz.check.keys\n    @blizz.apply.deduplication\n    def load(cls)->pd.DataFrame:\n        pass\n```\n\nIn general, when you rename source fields, run `@blizz.apply.renames` first (e.g. place it\nlowest), so that following checks/applies find the fields they are looking for.\n\nIt is possible to pass user defined functions meant to run as checks/applies using `blizz.check.func`\nand `blizz.apply.func` decorators – use the keyword argument `function` to pass in any\ncallable with a signature of `Type[Relation], DataFrame -> DataFrame`. Refer to\n[custom_decorators](src/tutorial/custom_decorators.py) as an example script.\n\n### Using blizz with PySpark\n\nUsing _blizz_ with PySpark works very similarly to the examples shown above – the only difference\nlies in using different datatypes for _Field_ definitions (either instances of `pyspark.sql.types.DataType`\nor the PySpark datatypes `simpleString` representation (e.g. \"int\", \"string\", ...)), and of course\nhaving to implement `load()` on each Relation differently, to return a `pyspark.sql.DataFrame`:\n\n```python\nfrom pyspark import SparkFiles\nfrom blizz import Relation, Field\nfrom pyspark.sql import DataFrame\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import DoubleType\nimport blizz.check\n\n\nclass Iris(Relation):\n    SEPAL_LENGTH = Field(\"sepal_length\", datatype=DoubleType)\n    SEPAL_WIDTH = Field(\"sepal_width\", datatype=\"double\")\n    PETAL_LENGTH = Field(\"petal_length\", datatype=DoubleType)\n    PETAL_WIDTH = Field(\"petal_width\", datatype=DoubleType)\n    SPECIES = Field(\"species\", datatype=\"string\")\n\n    @classmethod\n    @blizz.check.types\n    @blizz.check.fields\n    def load(cls, spark_session) -> DataFrame:\n\n        spark_session.sparkContext.addFile(\n            \"https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7\"\n            \"/raw/0e7a9b0a5d22642a06d3d5b9bcbad9890c8ee534/iris.csv\"\n        )\n        df = spark_session.read.csv(\n            SparkFiles.get(\"iris.csv\"), inferSchema=True, header=True\n        )\n\n        return df\n\n\n# set up a simple spark session:\nspark = SparkSession.builder.getOrCreate()\n# calling load(), we can retrieve a dataframe for the Relation:\niris_df = Iris.load(spark)\nprint(iris_df)\n# using the Relation's Schema, we can access/modify iris_df referencing fields we like:\niris_df.select(Iris.SEPAL_WIDTH, Iris.SEPAL_LENGTH).show()\nspark.stop()\n```\n\n### API Reference on Relation and Field\n\nThe `Field()` constructor accepts the following arguments (besides `name`, all optional):\n\n- `name`: the target field name, referencing a field in the Relation as retrieved by `load()`. If\n  you want to retrieve an originally differently name field, then capture its source name in \n  `source_name`\n- `source_name`: the field name as in the source – useful for `load()` to retrieve the Relation,\n  before fields get renamed – such renaming can be done by `blizz.apply.renames`\n- `datatype`: the Field's datatype – for Pandas, can be defined as Python built-in, numpy type, or\n  as a String value (\"int\"). For PySpark, use `pyspark.sql.types.DataType` or the PySpark datatypes\n  `simpleString` representation (e.g. \"int\", \"string\", ...).\n- `default`: allows one to define a literal as a default value on NULL\n- `description`: allows one to provide a string as a description/comment on the Field\n- `key`: a boolean flag indicating if this field is part of the primary key\n- `mock`: allows one to define a callable mocking data for this Field – useful for testing of Relation's\n    with synthetic data.\n\nEach `Relation` defines the following useful methods on class level:\n\n- `Relation.get_fields()`: returns all _Fields_ as defined\n- `Relation.get_field_names()`: returns all _Fields_ names as defined\n- `Relation.get_types()`: returns all _Fields_ datatypes, as a Dict `Field -> Datatype`. Note that \n  datatypes here are as heterogenous, as you defined them, e.g. they can either be strings or applicable \n  classes such as `int`\n- `Relation.get_key_fields()`: returns all _Fields_, defined as key\n- `Relation.get_key_field_names()`: returns all names of _Fields_, defined as key\n- `Relation.get_defaults()`: return a Dictionary mapping from _Field_ to its default value, where defined  \n- `Relation.get_default(<Field>)`: return the default value for a _Field_\n- `Relation.mock()`: to be overridden by each `Relation` – allows one to define a mocked version of `load()`\nto produce synthetic data for testing.\n\nOf course it is entirely possibly, to define a subclass of `Relation` for your own purposes, which \ndeals with common use-cases by own class functions it adds! For instance, you might want to create\na `SQLRelation` which already bundles useful methods or definitions to allow you quickly\nretrieving these kind of Relations from a SQL RDBMS.\n\n### API Reference on blizz.check & blizz.apply\n\n`blizz.check` offers the following decorators for checking:\n\n- `blizz.check.fields`: validates on the DataFrame returned by `load()`, that it contains at least all fields \n  (by name) as defined on the Relation\n- `blizz.check.types`: validates that all fields that have defined data types on the Relation match with their\n  data types as in the DataFrame returned by `load()`\n- `blizz.check.keys`: validates that the subset of all Fields marked as keys is unique\n- `blizz.check.func`: run the user defined function passed as the `function` keyword parameter and check if\n    it raises an exception. The function's signature should be `Type[Relation], DataFrame -> DataFrame`.\n\nAll `blizz.check` decorators accept the argument `on_fail`, which can be set to:\n- `blizz.check.WARN`: raise a warning on failing the check\n- `blizz.check.RAISE`: raise an exception on failing the check\n\n`blizz.apply` offers the following decorators for transformations:\n- `blizz.apply.deduplication`: deduplicate the DataFrame returned by `load()` either by the Fields already marked\n  as keys of the Relation, or the subset of Field given as argument `key:List[Field]` to the decorator (which\n  has precedence). Additionally the\n  decorator supports the arguments `sort_on:List[Field]` and `sort_order` (which can be either `blizz.apply.ASC` or \n  `blizz.apply.DESC`) – this can ensure which non-key records are preferrably kept on duplication. E.g. when you\n  find a duplicate based on the key-column, then pick among those duplicates the most recently updated row \n  – here one might use something like: `sort_on = [UPDATE_TIMESTAMP], sort_order = blizz.apply.DESC`.\n- `blizz.apply.defaults`: fill defined defaults for NULL values in the DataFrame returned by `load()`, either\n  using the defined value defaults from the Relation's Fields (if exist) or as given with as the argument\n  `fill: List[Field]` to the decorator (which has precedence).\n- `blizz.apply.renames`: perform Field renames for columns in the DataFrame as returned by `load()`, either\n  using the defined pairs of `Field.source_name` -> `Field.name` (where exists) or using the rename definitions\n  as given as argument `columns:Dict[str,str]` to the decorator, which will be added to the renames to perform.\n- `blizz.apply.func`: run the user defined function passed as the `function` keyword parameter and return\n  the transformed data. The function's signature should be `Type[Relation], DataFrame -> DataFrame`.  \n\n\n## Bootstrapping – generate schema definitions from DataFrames\n\nAs you've seen above, _blizz_ can be a powerful tool in your Python data pipelines. However it needs properly\ndefined Relations, which can be tedious at the start.\n\nFor this, _blizz_ can boostrap Relations from existing PySpark or Pandas DataFrames using \n`blizz.relation_from_dataframe()`.\n\n```shell\n>>> blizz.relation_from_dataframe(df=departments_df, name=\"Departments\")\n\nimport blizz.check\nfrom blizz import Relation, Field\nfrom pyspark.sql import DataFrame\nfrom pyspark.sql.types import *\n\n\nclass Departments(Relation):\n    \"\"\"\n    todo: describe relation Departments in this docstring\n    \"\"\"\n    DEPARTMENT_ID = Field(name=\"Department_ID\", datatype=StringType)\n    DEPARTMENT_NAME = Field(name=\"Department_Name\", datatype=StringType)\n    DOE = Field(name=\"DOE\", datatype=TimestampType)\n\n    @classmethod\n    @blizz.check.keys(on_fail = blizz.check.WARN)\n    @blizz.check.types(on_fail = blizz.check.WARN)\n    @blizz.check.fields(on_fail = blizz.check.WARN)\n    def load(cls) -> DataFrame:\n        \"\"\"\n        todo: describe relation Departments load process in this docstring\n        \"\"\"\n        # todo: implement data source loading here\n        pass\n```\n\nYou can then simply copy and paste and adjust this as needed.\n\n## Beyond: blizz Feature Library\n**EXPERIMENTAL – only supported with PySpark**\n\nOn top of __blizz__'s primitives, the plan is to build a lightweight Feature Library component for\nMachine Learning. There is an example of this experimental API included as part of\n[src/tutorial](src/tutorial/example_feature_library). Conceptually the API allows to express \nfeatures programmatically, but in a well structured way using lightweight classes. This makes it \npossible then, to decouple the feature generation from the pure feature definition.\n\n`blizz` has also a CLI – serving as a client to instruct a PySpark process which features to build,\nall based on a defined blizz Feature Library.\n\nIn order to do this, one:\n\n1. defines a Feature Library in code as done with\n   [src/tutorial/example_feature_library](src/tutorial/example_feature_library)\n2. defines a feature list definition: this is a YAML file of all FeatureGroups/Features one wants to\n   have calculated, being also able to specify parameters for parameterizable features and to\n   specify the output storage format. An example is given here\n   [src/tutorial/ExampleFeatureList.yaml](src/tutorial/ExampleFeatureList.yaml)\n3. calls the `blizz` CLI with both and the output path: \n   `blizz build src/tutorial/ExampleFeatureList.yaml src/tutorial/example_feature_library my_features`\n\nThis brings together the code-based definition of all data sources (by __blizz__ primitives) and features (by __blizz__ \nFeatureGroup & Feature) with the instruction in the form of the YAML file what and how (parameterized features)\nto calculate.\n\n**Why is this approach powerful?**\n\n1. how to retrieve data sources, check them, and build features on-top is purely captured in code. This means it\n  is **fully supported by IDE type checks, autocompletion and refactoring abilities.**\n2. due to this code centric means of definition, the **whole end to end pipeline is easily managed and versioned** – \n   as a Python package.\n3. expressing ML features in a structured way allows to leverage a **common, powerful Spark based factory** to build \n   them – whoever wants features, only needs to call `blizz build ...` with their YAML build instructions and\n   pointing to a blizz Feature Library codebase (which can be checked out at a version as desired). As internally,\n   _blizz_ pipelines are just nested function calls on top of `pyspark.sql`, this **heavily benefits from both\n   lazy evaluation and execution plan optimizations**. This happens completely transparently thanks to Spark.\n4. in this way, definitions to calculate features can be centralized and shared purely on the code level. Consumers\n   of features, e.g. specialized ML models, just need to install `blizz`, write YAML build instructions and point\n   to the FeatureLibrary – **their model does not even need to be in Python**.\n\n## Beyond: Generate Documentation\n\nThanks to its rich metadata about Relations, Fields and Features, the task of documentation becomes easier\nfor data practitioners. On top of structured information serving as documentation, Python docstrings will\nbe automatically used, e.g. on class level underneath a `Relation`, when describing `Relation.load()` and\nsimilarly for `FeatureGroup` and `Feature`.\n\nThe philosophy here is, not write documentation twice – e.g. in code and somewhere else – but rather to\nmake it code driven as well.\n\nA nice (experimental) feature is the following, which will create a Sphinx project from a `blizz.FeatureGroup`'s\nmetadata and serve it:\n\n```shell\nblizz docs src/tutorial/example_feature_library --serve\n```\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/joerg-schneider/blizz",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "blizz",
    "package_url": "https://pypi.org/project/blizz/",
    "platform": "",
    "project_url": "https://pypi.org/project/blizz/",
    "project_urls": {
      "Documentation": "https://github.com/joerg-schneider/blizz",
      "Homepage": "https://github.com/joerg-schneider/blizz",
      "Repository": "https://github.com/joerg-schneider/blizz"
    },
    "release_url": "https://pypi.org/project/blizz/0.2.5/",
    "requires_dist": [
      "pyyaml >= 5.0",
      "click >= 7.1",
      "colorama",
      "tornado",
      "pydata-sphinx-theme",
      "sphinx",
      "schema",
      "nbsphinx >= 0.7.* ; extra == \"docs\"",
      "jupyter >= 1.0 ; extra == \"docs\"",
      "docutils ; extra == \"docs\"",
      "m2r == 0.2.* ; extra == \"docs\"",
      "pandas >= 0.24,<1.2 ; extra == \"pandas\"",
      "pyspark >= 2.4 ; extra == \"pyspark\"",
      "pyspark-stubs ; extra == \"pyspark\"",
      "pytest >= 6.2.* ; extra == \"testing\"",
      "pytest-cov >= 2.10.* ; extra == \"testing\"",
      "flake8 >= 3.8.* ; extra == \"testing\"",
      "flake8-comprehensions >= 3.3.* ; extra == \"testing\"",
      "isort >= 5.7.* ; extra == \"testing\""
    ],
    "requires_python": ">=3.6,<4",
    "summary": "blizz – be blizzful.",
    "version": "0.2.5",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 10545554,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "26dcd51e92ffd33ba9f156fb0aa572a317890795025663acfb3e25399110a2aa",
          "md5": "efa5140b438e9d6632e4c7292cea296f",
          "sha256": "9e372d8a946020b9c6085bcd7f0ab3d344d1616ade87d56eb34350d712bf0e43"
        },
        "downloads": -1,
        "filename": "blizz-0.0.1-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "efa5140b438e9d6632e4c7292cea296f",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 1080,
        "upload_time": "2020-12-04T17:47:41",
        "upload_time_iso_8601": "2020-12-04T17:47:41.908177Z",
        "url": "https://files.pythonhosted.org/packages/26/dc/d51e92ffd33ba9f156fb0aa572a317890795025663acfb3e25399110a2aa/blizz-0.0.1-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "64e65233e0dec2aad5cb4342574e96423eb12619fd469160b996beaa055890b0",
          "md5": "b45947fbc4be521bdc79b6d55d1662de",
          "sha256": "cdea42a19cf835d8fffa09bd1b9ffb97d4ca9d1036373f6fa3d22c780f7c1090"
        },
        "downloads": -1,
        "filename": "blizz-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "b45947fbc4be521bdc79b6d55d1662de",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 790,
        "upload_time": "2020-12-04T17:47:51",
        "upload_time_iso_8601": "2020-12-04T17:47:51.334335Z",
        "url": "https://files.pythonhosted.org/packages/64/e6/5233e0dec2aad5cb4342574e96423eb12619fd469160b996beaa055890b0/blizz-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e97daabcfd320ace831c7c64f6d4d6899c67976a28d7898e1681afb69dd8c55d",
          "md5": "78a9a05a65fe15a64b2891086e115e4d",
          "sha256": "70fa068104a16a4187e333e3f9feb28e0064fd44cc0778726925cd143cfee93b"
        },
        "downloads": -1,
        "filename": "blizz-0.2.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "78a9a05a65fe15a64b2891086e115e4d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6,<4",
        "size": 139217,
        "upload_time": "2021-05-27T22:43:46",
        "upload_time_iso_8601": "2021-05-27T22:43:46.747584Z",
        "url": "https://files.pythonhosted.org/packages/e9/7d/aabcfd320ace831c7c64f6d4d6899c67976a28d7898e1681afb69dd8c55d/blizz-0.2.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bb1a04b499b008fcbe7a8138742916520f487e9ef0ee6e98635ed527c49d7798",
          "md5": "610d4e1a2869ab63d36e6f3aef0a193d",
          "sha256": "7e6831cc62d4f638ba97bd97d287245fe216e3e7eee507a6b87296730fb973d8"
        },
        "downloads": -1,
        "filename": "blizz-0.2.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "610d4e1a2869ab63d36e6f3aef0a193d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6,<4",
        "size": 146369,
        "upload_time": "2021-05-27T22:47:37",
        "upload_time_iso_8601": "2021-05-27T22:47:37.993363Z",
        "url": "https://files.pythonhosted.org/packages/bb/1a/04b499b008fcbe7a8138742916520f487e9ef0ee6e98635ed527c49d7798/blizz-0.2.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5c75c5b0bc0cc813cdf9232a6f0bc06edabe010b295a07400e57462a7097a357",
          "md5": "057160ecee487b8725d72ebce739728a",
          "sha256": "6dafa2a4f1734dcda4dcaf3aa069db8a36beb1490833c0d077000efc44540cb9"
        },
        "downloads": -1,
        "filename": "blizz-0.2.1.tar.gz",
        "has_sig": false,
        "md5_digest": "057160ecee487b8725d72ebce739728a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6,<4",
        "size": 1619826,
        "upload_time": "2021-05-27T22:47:55",
        "upload_time_iso_8601": "2021-05-27T22:47:55.678989Z",
        "url": "https://files.pythonhosted.org/packages/5c/75/c5b0bc0cc813cdf9232a6f0bc06edabe010b295a07400e57462a7097a357/blizz-0.2.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "817e4ff466abda4e7d023973332f75f82287097a9b3637e08985585f29ba4e33",
          "md5": "6a7479ff2fccd09ddeab5451ad50277d",
          "sha256": "38eeebf57d4ce82c672b992aeb03b6114661efa9192e7564545ef14e18810bc5"
        },
        "downloads": -1,
        "filename": "blizz-0.2.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "6a7479ff2fccd09ddeab5451ad50277d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6,<4",
        "size": 146388,
        "upload_time": "2021-05-27T22:50:33",
        "upload_time_iso_8601": "2021-05-27T22:50:33.562098Z",
        "url": "https://files.pythonhosted.org/packages/81/7e/4ff466abda4e7d023973332f75f82287097a9b3637e08985585f29ba4e33/blizz-0.2.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "50c9c864d9862e99af8400000d293e97af22fe27e4badab0163fda0aefd2ad56",
          "md5": "085f8299b721f111b43d4663e8ba2c53",
          "sha256": "2cd34068e1ecccb3f0c1bbacc42ee216f25d9b7762fc71a6d83589ff958df514"
        },
        "downloads": -1,
        "filename": "blizz-0.2.2.tar.gz",
        "has_sig": false,
        "md5_digest": "085f8299b721f111b43d4663e8ba2c53",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6,<4",
        "size": 1619816,
        "upload_time": "2021-05-27T22:50:50",
        "upload_time_iso_8601": "2021-05-27T22:50:50.789783Z",
        "url": "https://files.pythonhosted.org/packages/50/c9/c864d9862e99af8400000d293e97af22fe27e4badab0163fda0aefd2ad56/blizz-0.2.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cf138d67e832f05c582648a4718446c75e8e0ae9fb33045f9ea0b216a54fc63f",
          "md5": "9cc9c9edbc985f93f849ab9000fb0b81",
          "sha256": "f678451f225122a74d1ae2590d0644532be2464f2b0d11c149c076bd73fb2702"
        },
        "downloads": -1,
        "filename": "blizz-0.2.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "9cc9c9edbc985f93f849ab9000fb0b81",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6,<4",
        "size": 147136,
        "upload_time": "2021-05-29T14:42:38",
        "upload_time_iso_8601": "2021-05-29T14:42:38.993067Z",
        "url": "https://files.pythonhosted.org/packages/cf/13/8d67e832f05c582648a4718446c75e8e0ae9fb33045f9ea0b216a54fc63f/blizz-0.2.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "867ca3bf2ebc106341d6f477e8377281bec572f136be5b896ea196c04c413282",
          "md5": "e840402d27fb5116f0b4d27dbd0ad1f8",
          "sha256": "8f68385647bf303cd243dfd0fd61457d77c1b9504e8b8697ce8416c7ff12b382"
        },
        "downloads": -1,
        "filename": "blizz-0.2.3.tar.gz",
        "has_sig": false,
        "md5_digest": "e840402d27fb5116f0b4d27dbd0ad1f8",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6,<4",
        "size": 1624099,
        "upload_time": "2021-05-29T14:42:48",
        "upload_time_iso_8601": "2021-05-29T14:42:48.474408Z",
        "url": "https://files.pythonhosted.org/packages/86/7c/a3bf2ebc106341d6f477e8377281bec572f136be5b896ea196c04c413282/blizz-0.2.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "236a65c2eb54a9ae7460c6d34434ba4887e9ea82868196077ca514d61bbb8158",
          "md5": "5b5f33741998c0d16bf0df2b2153ad7c",
          "sha256": "88cca36e2a2b763566cdd0e296c8bd9e73b161b3bf835b98fb8c1519b65a44c9"
        },
        "downloads": -1,
        "filename": "blizz-0.2.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "5b5f33741998c0d16bf0df2b2153ad7c",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6,<4",
        "size": 147311,
        "upload_time": "2021-05-30T12:46:13",
        "upload_time_iso_8601": "2021-05-30T12:46:13.921376Z",
        "url": "https://files.pythonhosted.org/packages/23/6a/65c2eb54a9ae7460c6d34434ba4887e9ea82868196077ca514d61bbb8158/blizz-0.2.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "244d0416f57ca2240d02953282d440ec478927b35a3c65b8043dc6e7f150ce79",
          "md5": "058287a8ac272a1b0f057fe834ff2893",
          "sha256": "dcf14b357d3f7d75a6987bd8237ac7ff5bf37dc1ab2e1a08a04998df9b12f5a1"
        },
        "downloads": -1,
        "filename": "blizz-0.2.4.tar.gz",
        "has_sig": false,
        "md5_digest": "058287a8ac272a1b0f057fe834ff2893",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6,<4",
        "size": 1626187,
        "upload_time": "2021-05-30T12:46:23",
        "upload_time_iso_8601": "2021-05-30T12:46:23.017617Z",
        "url": "https://files.pythonhosted.org/packages/24/4d/0416f57ca2240d02953282d440ec478927b35a3c65b8043dc6e7f150ce79/blizz-0.2.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e70071934e532243dfe9b2250310be8818db31d9d2c8041ab05258fc20a4f0d5",
          "md5": "dcf381a578d7bcd90afd27356da81998",
          "sha256": "09b4fc48a0c2fbc6f828a52915e5160d4c9a0ddbb8cdb3e60cef35aa5fc2b67e"
        },
        "downloads": -1,
        "filename": "blizz-0.2.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "dcf381a578d7bcd90afd27356da81998",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6,<4",
        "size": 147373,
        "upload_time": "2021-06-03T05:22:18",
        "upload_time_iso_8601": "2021-06-03T05:22:18.454461Z",
        "url": "https://files.pythonhosted.org/packages/e7/00/71934e532243dfe9b2250310be8818db31d9d2c8041ab05258fc20a4f0d5/blizz-0.2.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "babfc38e36e802ae0f0424519ddd8abc892c74634de70d3dd0633d5391a0ad3c",
          "md5": "00c1d2f4aec4745f06d6dbaec7ff5b00",
          "sha256": "cbec4c82cd3146e7765c77b5b0f4bc626f685f8d37801ff3890643fe12d13b77"
        },
        "downloads": -1,
        "filename": "blizz-0.2.5.tar.gz",
        "has_sig": false,
        "md5_digest": "00c1d2f4aec4745f06d6dbaec7ff5b00",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6,<4",
        "size": 1626268,
        "upload_time": "2021-06-03T05:22:27",
        "upload_time_iso_8601": "2021-06-03T05:22:27.119036Z",
        "url": "https://files.pythonhosted.org/packages/ba/bf/c38e36e802ae0f0424519ddd8abc892c74634de70d3dd0633d5391a0ad3c/blizz-0.2.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "e70071934e532243dfe9b2250310be8818db31d9d2c8041ab05258fc20a4f0d5",
        "md5": "dcf381a578d7bcd90afd27356da81998",
        "sha256": "09b4fc48a0c2fbc6f828a52915e5160d4c9a0ddbb8cdb3e60cef35aa5fc2b67e"
      },
      "downloads": -1,
      "filename": "blizz-0.2.5-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "dcf381a578d7bcd90afd27356da81998",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6,<4",
      "size": 147373,
      "upload_time": "2021-06-03T05:22:18",
      "upload_time_iso_8601": "2021-06-03T05:22:18.454461Z",
      "url": "https://files.pythonhosted.org/packages/e7/00/71934e532243dfe9b2250310be8818db31d9d2c8041ab05258fc20a4f0d5/blizz-0.2.5-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "babfc38e36e802ae0f0424519ddd8abc892c74634de70d3dd0633d5391a0ad3c",
        "md5": "00c1d2f4aec4745f06d6dbaec7ff5b00",
        "sha256": "cbec4c82cd3146e7765c77b5b0f4bc626f685f8d37801ff3890643fe12d13b77"
      },
      "downloads": -1,
      "filename": "blizz-0.2.5.tar.gz",
      "has_sig": false,
      "md5_digest": "00c1d2f4aec4745f06d6dbaec7ff5b00",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6,<4",
      "size": 1626268,
      "upload_time": "2021-06-03T05:22:27",
      "upload_time_iso_8601": "2021-06-03T05:22:27.119036Z",
      "url": "https://files.pythonhosted.org/packages/ba/bf/c38e36e802ae0f0424519ddd8abc892c74634de70d3dd0633d5391a0ad3c/blizz-0.2.5.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}