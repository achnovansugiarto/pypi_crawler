{
  "info": {
    "author": "Dimitris Floros",
    "author_email": "fcdimitr@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# SG-t-SNE-Π <br/> Swift Neighbor Embedding of Sparse Stochastic Graphs\n\n[![DOI](http://joss.theoj.org/papers/10.21105/joss.01577/status.svg)](https://doi.org/10.21105/joss.01577)\n[![DOI](https://zenodo.org/badge/196885143.svg)](https://zenodo.org/badge/latestdoi/196885143)\n[![GitHub license](https://img.shields.io/github/license/fcdimitr/sgtsnepi.svg)](https://github.com/fcdimitr/sgtsnepi/blob/master/LICENSE)\n[![GitHub issues](https://img.shields.io/github/issues/fcdimitr/sgtsnepi.svg)](https://github.com/fcdimitr/sgtsnepi/issues/)\n\n-   [Overview](#overview)\n    -   [Precursor algorithms](#precursor-algorithms)\n    -   [Approximation of the gradient](#approximation-of-the-gradient)\n    -   [SG-t-SNE-Π](#sg-t-sne-π)\n        -   [Accelerated accumulation of attractive\n            interactions](#accelerated-accumulation-of-attractive-interactions)\n        -   [Accelerated accumulation of repulsive\n            interactions](#accelerated-accumulation-of-repulsive-interactions)\n        -   [Rapid intra-term and inter-term data\n            relocations](#rapid-intra-term-and-inter-term-data-relocations)\n    -   [Supplementary material](#supplementary-material)\n-   [References](#references)\n-   [Getting started](#getting-started)\n    -   [System environment](#system-environment)\n    -   [Prerequisites](#prerequisites)\n    -   [Installation](#installation)\n        -   [Basic instructions](#basic-instructions)\n        -   [Support of the conventional t-SNE](#support-of-the-conventional-t-sne)\n        -   [MATLAB interface](#matlab-interface)\n    -   [Usage demo](#usage-demo)\n-   [License and community guidelines](#license-and-community-guidelines)\n-   [Contributors](#contributors)\n\n\n## Overview \n\nWe introduce SG-t-SNE-Π, a high-performance software for swift\nembedding of a large, sparse, stochastic graph\n<img src=\"svgs/4ad232c35b5cd188a13d128bb2c1eecc.svg\" align=middle width=103.24177049999999pt height=24.65753399999998pt/> into a <img src=\"svgs/2103f85b8b1477f430fc407cad462224.svg\" align=middle width=8.55596444999999pt height=22.831056599999986pt/>-dimensional space\n(<img src=\"svgs/3fa1f779de09763d248814c0c4f40d07.svg\" align=middle width=69.74298869999998pt height=22.831056599999986pt/>) on a shared-memory computer. The algorithm SG-t-SNE and the\nsoftware t-SNE-Π were first described in Reference [[1](#Pitsianis2019)].\nThe algorithm is built upon precursors for embedding a <img src=\"svgs/63bb9849783d01d91403bc9a5fea12a2.svg\" align=middle width=9.075367949999992pt height=22.831056599999986pt/>-nearest\nneighbor (<img src=\"svgs/63bb9849783d01d91403bc9a5fea12a2.svg\" align=middle width=9.075367949999992pt height=22.831056599999986pt/>NN) graph, which is distance-based and regular with\nconstant degree <img src=\"svgs/63bb9849783d01d91403bc9a5fea12a2.svg\" align=middle width=9.075367949999992pt height=22.831056599999986pt/>. In practice, the precursor algorithms are also\nlimited up to 2D embedding or suffer from overly long latency in 3D\nembedding. SG-t-SNE removes the algorithmic restrictions and enables\n<img src=\"svgs/2103f85b8b1477f430fc407cad462224.svg\" align=middle width=8.55596444999999pt height=22.831056599999986pt/>-dimensional embedding of arbitrary stochastic graphs, including, but\nnot restricted to, <img src=\"svgs/63bb9849783d01d91403bc9a5fea12a2.svg\" align=middle width=9.075367949999992pt height=22.831056599999986pt/>NN graphs. SG-t-SNE-Π expedites the\ncomputation with high-performance functions and materializes 3D\nembedding in shorter time than 2D embedding with any precursor algorithm\non modern laptop/desktop computers.\n\n### Precursor algorithms \n\nThe original t-SNE [[2](#Maaten2008)] has given rise to several variants. Two\nof the variants, [t-SNE-BH](https://lvdmaaten.github.io/tsne/) [[3](#VanDerMaaten2014)] and\n[FIt-SNE](https://github.com/KlugerLab/FIt-SNE) [[4](#Linderman2019)], are distinctive and representative in their\napproximation approaches to reducing algorithmic complexity. They are,\nhowever, limited to <img src=\"svgs/63bb9849783d01d91403bc9a5fea12a2.svg\" align=middle width=9.075367949999992pt height=22.831056599999986pt/>NN graph embedding. Specifically, at the user\ninterface, a set of <img src=\"svgs/8da1486405f46444193f741ce5a271d6.svg\" align=middle width=54.15898619999999pt height=24.65753399999998pt/> data points,\n<img src=\"svgs/4848cd4cae94c484c6f7fa961a7dc7d8.svg\" align=middle width=92.14043849999999pt height=24.65753399999998pt/>, is provided in terms of their\nfeature vectors <img src=\"svgs/796df3d6b2c0926fcde961fd14b100e7.svg\" align=middle width=16.08162434999999pt height=14.611878600000017pt/> in an <img src=\"svgs/ddcb483302ed36a59286424aa5e0be17.svg\" align=middle width=11.18724254999999pt height=22.465723500000017pt/>-dimensional vector space\nequipped with a metric/distance function. The input parameters include\n<img src=\"svgs/2103f85b8b1477f430fc407cad462224.svg\" align=middle width=8.55596444999999pt height=22.831056599999986pt/> for the embedding dimension, <img src=\"svgs/63bb9849783d01d91403bc9a5fea12a2.svg\" align=middle width=9.075367949999992pt height=22.831056599999986pt/> for the number of near-neighbors,\nand <img src=\"svgs/6dbb78540bd76da3f1625782d42d6d16.svg\" align=middle width=9.41027339999999pt height=14.15524440000002pt/> for the perplexity. A t-SNE algorithm maps the data points\n<img src=\"svgs/38e077ab3accd56221488b5b38e548f4.svg\" align=middle width=14.132466149999988pt height=22.465723500000017pt/> to data points <img src=\"svgs/0e8e2b1ee7fa5154c9090eadff7d254d.svg\" align=middle width=90.34592984999999pt height=24.65753399999998pt/> in a\n<img src=\"svgs/2103f85b8b1477f430fc407cad462224.svg\" align=middle width=8.55596444999999pt height=22.831056599999986pt/>-dimensional space.\n\nThere are two basic algorithmic stages in a conventional t-SNE\nalgorithm. In the preprocessing stage, the <img src=\"svgs/63bb9849783d01d91403bc9a5fea12a2.svg\" align=middle width=9.075367949999992pt height=22.831056599999986pt/>NN graph is generated from\nthe feature vectors <img src=\"svgs/1bf183da1f64359241e53d08083c380e.svg\" align=middle width=33.341937749999985pt height=24.65753399999998pt/> according to the metric function\nand input parameter <img src=\"svgs/63bb9849783d01d91403bc9a5fea12a2.svg\" align=middle width=9.075367949999992pt height=22.831056599999986pt/>. Each data point is associated with a graph\nvertex. Next, the <img src=\"svgs/63bb9849783d01d91403bc9a5fea12a2.svg\" align=middle width=9.075367949999992pt height=22.831056599999986pt/>NN graph is cast into a stochastic one,\n<img src=\"svgs/b9d2acdd4ca9fbd1fb5226466229e0c0.svg\" align=middle width=74.39104034999998pt height=24.65753399999998pt/>, and symmetrized to\n<img src=\"svgs/8e2cb982230037ec6084a327c96d64e7.svg\" align=middle width=63.820236149999985pt height=24.65753399999998pt/>, \n\n<p align=\"center\"><img src=\"svgs/a86f48e97b076ed0bb6dfeb700fea86d.svg\" align=middle width=536.6954290499999pt height=43.13440065pt/></p>\n\n where\n<img src=\"svgs/64814475919e9b203cce2479fd26855d.svg\" align=middle width=65.60868104999999pt height=24.65753399999998pt/> is the binary-valued adjacency matrix of the\n<img src=\"svgs/63bb9849783d01d91403bc9a5fea12a2.svg\" align=middle width=9.075367949999992pt height=22.831056599999986pt/>NN graph, with zero diagonal elements (i.e., the graph has no\nself-loops), and <img src=\"svgs/2ccee0b78bcd2047f49b3b53962d20a4.svg\" align=middle width=19.311372299999988pt height=22.831056599999986pt/> is the distance between <img src=\"svgs/c416d0c6d8ab37f889334e2d1a9863c3.svg\" align=middle width=14.628015599999989pt height=14.611878600000017pt/> and\n<img src=\"svgs/796df3d6b2c0926fcde961fd14b100e7.svg\" align=middle width=16.08162434999999pt height=14.611878600000017pt/>. The Gaussian parameters <img src=\"svgs/e61ae7f2cb94c8418c30517775fde77d.svg\" align=middle width=14.04400634999999pt height=14.15524440000002pt/> are determined by the\npoint-wise equations related to the same perplexity value <img src=\"svgs/6dbb78540bd76da3f1625782d42d6d16.svg\" align=middle width=9.41027339999999pt height=14.15524440000002pt/>,\n\n<p align=\"center\"><img src=\"svgs/210a56bcf471bf05338f2704cbee406c.svg\" align=middle width=424.26428549999997pt height=38.89287435pt/></p>\n\nThe next stage is to determine and locate the embedding coordinates\n<img src=\"svgs/9f88162984437603577c62bf6f319682.svg\" align=middle width=98.79627284999998pt height=24.65753399999998pt/> by minimizing the\nKullback-Leibler divergence \n\n<p align=\"center\"><img src=\"svgs/8a31e14108bb84cf778034dddfdf62bd.svg\" align=middle width=359.40184665pt height=24.0502251pt/></p>\n\nwhere matrix <img src=\"svgs/3c30cbd100ce5ab96f26034f73886774.svg\" align=middle width=89.28989189999999pt height=24.65753399999998pt/> is made of the\nensemble <img src=\"svgs/69b7d411a46d4a8f33a3ed4f1937f0c5.svg\" align=middle width=12.337954199999992pt height=22.465723500000017pt/> regulated by the Student t-distribution,\n\n<p align=\"center\"><img src=\"svgs/0715f18ccb81de1afebc36e276b851da.svg\" align=middle width=534.2742883499999pt height=43.7234787pt/></p>\n\nIn other words, the objective of\n(3) is to find the optimal\nstochastic matching between <img src=\"svgs/384591906555413c452c93e493b2d4ec.svg\" align=middle width=12.92230829999999pt height=22.55708729999998pt/> and <img src=\"svgs/61ccc6d099c3b104d8de703a10b20230.svg\" align=middle width=14.20083224999999pt height=22.55708729999998pt/> defined,\nrespectively, over the feature vector set <img src=\"svgs/38e077ab3accd56221488b5b38e548f4.svg\" align=middle width=14.132466149999988pt height=22.465723500000017pt/> and the embedding\ncoordinate set <img src=\"svgs/69b7d411a46d4a8f33a3ed4f1937f0c5.svg\" align=middle width=12.337954199999992pt height=22.465723500000017pt/>. The optimal matching is obtained numerically\nby applying the gradient descent method. A main difference among the\nprecursor algorithms lies in how the gradient of the objective function\nis computed.\n\n### Approximation of the gradient \n\nThe computation per iteration step is dominated by the calculation of\nthe gradient. Van der Maaten reformulated the gradient into two\nterms [[3](#VanDerMaaten2014)]:\n\n<p align=\"center\"><img src=\"svgs/0ee6b599fe43800a72b9c4450d8862a7.svg\" align=middle width=521.24979885pt height=71.90601659999999pt/></p>\n\nThe attractive interaction term can be cast as the sum of <img src=\"svgs/7f926a99555bec4c6525305cdea81193.svg\" align=middle width=16.77517379999999pt height=22.831056599999986pt/>\nmatrix-vector products with the sparse matrix\n<img src=\"svgs/d28f302ed1f97b242a449f0316aa2773.svg\" align=middle width=96.93665849999998pt height=24.65753399999998pt/>. The vectors are composed of the\nembedding coordinates, one in each dimension. The repulsive interaction\nterm can be cast as the sum of <img src=\"svgs/7f926a99555bec4c6525305cdea81193.svg\" align=middle width=16.77517379999999pt height=22.831056599999986pt/> matrix-vector products with the\ndense matrix <img src=\"svgs/8dcd6cb8c986db1c1c73c2046dc7863b.svg\" align=middle width=97.28293244999999pt height=24.65753399999998pt/>. For clarity, we simply\nrefer to the two terms as the <img src=\"svgs/10113745b95b6c955f7c8b1959d3e01d.svg\" align=middle width=27.12314054999999pt height=22.55708729999998pt/> term and the <img src=\"svgs/c6e87bbfdef510c8c42806f373d05c8f.svg\" align=middle width=28.401664499999992pt height=22.55708729999998pt/>\nterm, respectively.\n\nThe <img src=\"svgs/c6e87bbfdef510c8c42806f373d05c8f.svg\" align=middle width=28.401664499999992pt height=22.55708729999998pt/> (repulsion) term is in fact a broad-support, dense\nconvolution with the Student t-distribution kernel on non-equispaced,\nscattered data points. As the matrix is dense, a naive method for\ncalculating the term takes <img src=\"svgs/3987120c67ed5a9162aa9841b531c3a9.svg\" align=middle width=43.02219404999999pt height=26.76175259999998pt/> arithmetic operations. The quadratic\ncomplexity limits the practical use of t-SNE to small graphs. Two types\nof existing approaches reduce the quadratic complexity to <img src=\"svgs/ff514eba41c59f90c20d895e80719763.svg\" align=middle width=72.2268393pt height=24.65753399999998pt/>,\nthey are typified by t-SNE-BH and FIt-SNE. The algorithm t-SNE-BH,\nintroduced by van der Maaten [[3](#VanDerMaaten2014)], is based on the\nBarnes-Hut algorithm. The broad-support convolution is factored into\n<img src=\"svgs/0d4b7f5b66e994af32a32cfa26868d53.svg\" align=middle width=59.62030469999999pt height=24.65753399999998pt/> convolutions of narrow support, at multiple spatial levels,\neach narrowly supported algorithm takes <img src=\"svgs/1f08ccc9cd7309ba1e756c3d9345ad9f.svg\" align=middle width=35.64773519999999pt height=24.65753399999998pt/> operations. FIt-SNE,\npresented by Linderman et al. [[4](#Linderman2019)], may be viewed as based\non non-uniform fast Fourier transforms. The execution time of each\napproximate algorithm becomes dominated by the <img src=\"svgs/10113745b95b6c955f7c8b1959d3e01d.svg\" align=middle width=27.12314054999999pt height=22.55708729999998pt/>\n(attraction) term computation. The execution time also faces a steep\nrise from 2D to 3D embedding.\n\n### SG-t-SNE-Π\n\nWith the algorithm SG-t-SNE we extend the use of t-SNE to any sparse\nstochastic graph <img src=\"svgs/1770ef1ded78d8145af3b517043e993d.svg\" align=middle width=102.60478964999999pt height=24.65753399999998pt/>. The key input\nis the stochastic matrix <img src=\"svgs/c4f6d7dc2dfb5ec67bc23d67c7fc2875.svg\" align=middle width=73.75405784999998pt height=24.65753399999998pt/>,\n<img src=\"svgs/c6a898940e1609c4b1528de9cfd03bf7.svg\" align=middle width=80.90651249999999pt height=24.657735299999988pt/>, associated with the graph, where <img src=\"svgs/22ef4f9a3cc0b415bd468f738e64468f.svg\" align=middle width=22.930086299999992pt height=14.15524440000002pt/> is not\nrestricted to the form of\n(1).\nWe introduce a parametrized, non-linear rescaling mechanism to explore\nthe graph sparsity. We determine rescaling parameters <img src=\"svgs/9766609a48282e6f30837a712595b37c.svg\" align=middle width=13.16154179999999pt height=14.15524440000002pt/> by\n\n<p align=\"center\"><img src=\"svgs/5c2a663f87e1bd635fb1636f3ec048bd.svg\" align=middle width=296.7352509pt height=40.5367314pt/></p>\n\nwhere <img src=\"svgs/f10fc2142d969a09dda2eea96cede2fb.svg\" align=middle width=39.72592304999999pt height=22.831056599999986pt/> is an input parameter and <img src=\"svgs/f50853d41be7d55874e952eb0d80c53e.svg\" align=middle width=9.794543549999991pt height=22.831056599999986pt/> is a monotonically\nincreasing function. We set <img src=\"svgs/0816c17505ab3faeea94b82afa429bbe.svg\" align=middle width=63.28758314999998pt height=24.65753399999998pt/> in the present version of\nSG-t-SNE-Π. Unlike\n(2), the rescaling mechanism\n(6) imposes no constraint on the graph,\nits solution exists unconditionally. For the conventional t-SNE as a\nspecial case, we set <img src=\"svgs/cd5494d95bfaee6295fdcf130852ed2d.svg\" align=middle width=39.72592304999999pt height=22.831056599999986pt/> by default. One may still make use of\nand exploit the benefit of rescaling (<img src=\"svgs/894e9a25f2969025d613371aa8b628c0.svg\" align=middle width=39.72592304999999pt height=22.831056599999986pt/>).\n\nWith the implementation SG-t-SNE-Π, we accelerate the entire\ngradient calculation of SG-t-SNE and enable practical 3D embedding of\nlarge sparse graphs on modern desktop and laptop computers. We\naccelerate the computation of both <img src=\"svgs/c6e87bbfdef510c8c42806f373d05c8f.svg\" align=middle width=28.401664499999992pt height=22.55708729999998pt/> and <img src=\"svgs/10113745b95b6c955f7c8b1959d3e01d.svg\" align=middle width=27.12314054999999pt height=22.55708729999998pt/> terms\nby utilizing the matrix structures and the memory architecture in\ntandem.\n\n#### Accelerated accumulation of attractive interactions \n\nThe matrix <img src=\"svgs/10113745b95b6c955f7c8b1959d3e01d.svg\" align=middle width=27.12314054999999pt height=22.55708729999998pt/> in the attractive interaction term of\n(5) has the same sparsity pattern as\nmatrix <img src=\"svgs/384591906555413c452c93e493b2d4ec.svg\" align=middle width=12.92230829999999pt height=22.55708729999998pt/>, regardless of iterative changes in <img src=\"svgs/61ccc6d099c3b104d8de703a10b20230.svg\" align=middle width=14.20083224999999pt height=22.55708729999998pt/>.\nSparsity patterns are generally irregular. Matrix-vector products with\nirregular sparse matrix invoke irregular memory accesses and incur\nnon-equal, prolonged access latencies on hierarchical memories. We\nmoderate memory accesses by permuting the rows and columns of matrix\n<img src=\"svgs/384591906555413c452c93e493b2d4ec.svg\" align=middle width=12.92230829999999pt height=22.55708729999998pt/> such that rows and columns with similar nonzero patterns\nare placed closer together. The permuted matrix becomes block-sparse\nwith denser blocks, resulting in better data locality in memory reads\nand writes.\n\nThe permuted matrix <img src=\"svgs/384591906555413c452c93e493b2d4ec.svg\" align=middle width=12.92230829999999pt height=22.55708729999998pt/> is stored in the Compressed Sparse\nBlocks (CSB) storage format [[5](#Buluc2009)]. We utilize the CSB routines\nfor accessing the matrix and calculating the matrix-vector products with\nthe sparse matrix <img src=\"svgs/10113745b95b6c955f7c8b1959d3e01d.svg\" align=middle width=27.12314054999999pt height=22.55708729999998pt/>. The elements of the <img src=\"svgs/10113745b95b6c955f7c8b1959d3e01d.svg\" align=middle width=27.12314054999999pt height=22.55708729999998pt/>\nmatrix are formed on the fly during the calculation of the attractive\ninteraction term.\n\n#### Accelerated accumulation of repulsive interactions \n\nWe factor the convolution in the repulsive interaction term of\n(5) into three consecutive convolutional\noperations. We introduce an internal equispaced grid within the spatial\ndomain of the embedding points at each iteration, similar to the\napproach used in FIt-SNE [[4](#Linderman2019)]. The three convolutional\noperations are:\n\n`S2G`: Local translation of the scattered (embedding) points to their\nneighboring grid points.\n\n`G2G`: Convolution across the grid with the same t-distribution kernel\nfunction, which is symmetric, of broad support, and aperiodic.\n\n`G2S`: Local translation of the gridded data to the scattered points.\n\nThe `G2S` operation is a gridded interpolation and `S2G` is its\ntranspose; the arithmetic complexity is <img src=\"svgs/0a84590e8a7ac80b1a5bbdeb714a6bf4.svg\" align=middle width=55.52357579999999pt height=27.91243950000002pt/>, where <img src=\"svgs/31fae8b8b78ebe01cbfbe2fe53832624.svg\" align=middle width=12.210846449999991pt height=14.15524440000002pt/> is the\ninterpolation window size per side. Convolution on the grid takes\n<img src=\"svgs/ea79b06be39381b0524c4f8743c93d7f.svg\" align=middle width=97.56834119999999pt height=24.65753399999998pt/> arithmetic operations, where <img src=\"svgs/423cdbe4a0e748ce336927701aea61dc.svg\" align=middle width=16.69284539999999pt height=14.15524440000002pt/> is the\nnumber of grid points, i.e., the grid size. The grid size is determined\nby the range of the embedding points at each iteration, with respect to\nthe error tolerance set by default or specified by the user. In the\ncurrent implementation, the local interpolation method employed by\nSG-t-SNE-Π is accurate up to cubic polynomials in <img src=\"svgs/2103f85b8b1477f430fc407cad462224.svg\" align=middle width=8.55596444999999pt height=22.831056599999986pt/> separable\nvariables (<img src=\"svgs/3fa1f779de09763d248814c0c4f40d07.svg\" align=middle width=69.74298869999998pt height=22.831056599999986pt/>).\n\nAlthough the arithmetic complexity is substantially reduced in\ncomparison to the quadratic complexity of the direct way, the factored\noperations suffer either from memory access latency or memory capacity\nissues, which were not recognized or resolved in existing t-SNE\nsoftware. The scattered translation incurs high memory access latency.\nThe aperiodic convolution on the grid suffers from excessive use of\nmemory when the grid is periodically extended in all sides at once by\nzero padding. The exponential memory growth with <img src=\"svgs/2103f85b8b1477f430fc407cad462224.svg\" align=middle width=8.55596444999999pt height=22.831056599999986pt/> limits the\nembedding dimension or the graph size.\n\nWe resolve these memory latency and capacity issues in SG-t-SNE-Π.\nPrior to `S2G`, we relocate the scattered data points to the grid bins.\nThis binning process has two immediate benefits. It improves data\nlocality in the subsequent interpolation. It also establishes a data\npartition for parallel, multi-threaded execution of the scattered\ninterpolation. We omit the parallelization details. For `G2G`, we\nimplement aperiodic convolution by operator splitting, without using\nextra memory.\n\n#### Rapid intra-term and inter-term data relocations \n\nIn sparse or structured matrix computation of <img src=\"svgs/a36f952972b0f0fefd874eb09e26580e.svg\" align=middle width=82.27261349999998pt height=24.65753399999998pt/> arithmetic\ncomplexity, the execution time is dominated by memory accesses. We have\ndescribed\nin the previous sections how we use\nintra-term permutations to improve data locality and reduce memory\naccess latency in computing the [attraction](#accelerated-accumulation-of-attractive-interactions) and the [repulsion](#accelerated-accumulation-of-repulsive-interactions) terms of\n(5). In addition, we permute and relocate\nin memory the embedding data points between the two terms, at every\niteration step. The inter-term data relocation is carried out at\nmultiple layers, exploiting block-wise memory hierarchy. The data\npermutation overhead is well paid-off by the much shortened time for\narithmetic calculation with the permuted data. We use Π in the\nsoftware name SG-t-SNE-Π to signify the importance and the role of\nthe permutations in accelerating t-SNE algorithms, including the\nconventional one, and enabling 3D embeddings.\n\n### Supplementary material \n\nSupplementary material and performance plots are found at\n<http://t-sne-pi.cs.duke.edu>.\n\n\n## References\n\n[1] <a name=\"Pitsianis2019\"></a> N. Pitsianis, A.-S. Iliopoulos, D. Floros, and\nX. Sun. [Spaceland embedding of sparse stochastic\ngraphs](https://doi.org/10.1109/HPEC.2019.8916505). In *IEEE High Performance\nExtreme Computing Conference*, 2019.\n\n[2] <a name=\"Maaten2008\"></a> L. van der Maaten and G. Hinton. [Visualizing data\nusing t-SNE](http://www.jmlr.org/papers/v9/vandermaaten08a.html). *Journal of\nMachine Learning Research* 9(Nov):2579–2605, 2008.\n\n[3] <a name=\"VanDerMaaten2014\"></a> L. van der Maaten. [Accelerating t-SNE using\ntree-based algorithms](http://jmlr.org/papers/v15/vandermaaten14a.html).\n*Journal of Machine Learning Research* 15(Oct):3221–3245, 2014.\n\n[4] <a name=\"Linderman2019\"></a> G. C. Linderman, M. Rachh, J. G. Hoskins, S.\nSteinerberger, and Y. Kluger. [Fast interpolation-based t-SNE for improved\nvisualization of single-cell RNA-seq\ndata](https://doi.org/10.1038/s41592-018-0308-4). *Nature Methods*\n16(3):243–245, 2019.\n\n[5] <a name=\"Buluc2009\"></a> A. Buluç, J. T. Fineman, M. Frigo, J. R. Gilbert,\nand C. E. Leiserson. [Parallel sparse matrix-vector and matrix-transpose-vector\nmultiplication using compressed sparse\nblocks](https://doi.org/10.1145/1583991.1584053). In *Proceedings of Annual\nSymposium on Parallelism in Algorithms and Architectures*, pp. 233–244, 2009.\n\n[6] <a name=\"Pitsianis2019b\"></a> N. Pitsianis, D. Floros, A.-S. Iliopoulos, and\nX. Sun. [SG-t-SNE-Π: Swift neighbor embedding of sparse stochastic\ngraphs](https://doi.org/10.21105/joss.01577). *Journal of Open Source Software*\n4(39):1577, 2019.\n\n\n## Getting started \n\n### System environment \n\nSG-t-SNE-Π is developed for shared-memory computers with multi-threading,\nrunning Linux or macOS operating system. The source code must be compiled with a\nC++ compiler which supports Cilk. The current release is tested with\n[OpenCilk](http://opencilk.org) 1.0 (based on LLVM/Tapir `clang++` 10.0.1) and\nIntel Cilk Plus (GNU `g++` 7.4.0 and Intel `icpc` 19.0.4.233).\n\n> WARNING: Intel Cilk Plus is deprecated and not supported in newer versions of\n> GNU `g++` and Intel `icpc`.)\n\n### Prerequisites \n\nSG-t-SNE-Π uses the following open-source software:\n\n-   [FFTW3](http://www.fftw.org/) 3.3.8\n-   [METIS](http://glaros.dtc.umn.edu/gkhome/metis/metis/overview) 5.1.0\n-   [FLANN](https://www.cs.ubc.ca/research/flann/) 1.9.1\n-   [Intel TBB](https://01.org/tbb) 2019\n-   [LZ4](https://github.com/lz4/lz4) 1.9.1\n-   [Doxygen](http://www.doxygen.nl/) 1.8.14\n\nOn Ubuntu:\n\n    sudo apt-get install libtbb-dev libflann-dev libmetis-dev libfftw3-dev liblz4-dev doxygen\n\nOn macOS:\n\n    sudo port install flann tbb metis fftw-3 lz4 doxygen\n\n### Building SG-t-SNE-Π\n\nWe use the [Meson build system](https://mesonbuild.com/) to configure, build,\nand install the SG-t-SNE-Π library.  By default, Meson uses\n[Ninja](https://ninja-build.org/) as its build backend.  Both Meson and Ninja\ncan be installed via the [Python Package Index\n(PyPI)](https://pypi.python.org/pypi/meson/):\n\n    pip3 install --user meson\n    pip3 install --user ninja\n\nFor more information and alternative methods for installing Meson, see [Getting\nmeson](https://mesonbuild.com/Getting-meson.html).\n\n#### Basic instructions \n\nTo configure the SG-t-SNE-Π library, demos, conventional t-SNE interface, and\ndocumentation, issue the following:\n\n    CXX=<c++-compiler> meson <build-options> <build-path>\n\nThis will create and configure the build directory at `<build-path>`.  The `CXX`\nenvironment variable specifies the C++ compiler to use.  The `<build-options>`\nflags are optional; to check the available Meson build options, see\n[meson_options.txt](meson_options.txt).\n\nTo compile SG-t-SNE-Π within the build directory, issue:\n\n    meson compile -C <build-path>\n\nTo install all relevant targets, issue:\n\n    meson install -C <build-path>\n\nBy default, this will install targets in sub-directories `lib`, `bin`,\n`include`, and `doc` within the SG-t-SNE-Π project directory.  To change the\ninstallation prefix, specify the `-Dprefix=<install-prefix>` option when\nconfiguring with Meson.\n\nYou may test the installation with:\n\n    <install-prefix>/bin/test_modules\n\n#### MATLAB interface \n\nTo compile the SG-t-SNE-Π MATLAB wrappers, specify `-Denable_matlab=true` and\n`-Dmatlabroot=<path-to-matlab-installation>` when configuring.\n\nIf building with a compiler which uses an Intel Cilk Plus implementation, you\nmay also need to set `-Ddir_libcilkrts=<path-to-libcilkrts.so-parent-dir>`.\nThis is not necessary when building with OpenCilk.\n\n### Usage demo \n\nWe provide two data sets of modest size for demonstrating stochastic\ngraph embedding with SG-t-SNE-Π:\n\n    tar -xvzf data/mobius-graph.tar.gz\n    bin/demo_stochastic_matrix mobius-graph.mtx\n\n    tar -xvzf data/pbmc-graph.tar.gz\n    bin/demo_stochastic_matrix pbmc-graph.mtx\n\nThe [MNIST data set](http://yann.lecun.com/exdb/mnist/) can be tested using [existing wrappers](https://github.com/lvdmaaten/bhtsne/) provided\nby van der Maaten [[3](#VanDerMaaten2014)].\n\n\n## License and community guidelines \n\nThe SG-t-SNE-Π library is licensed under the [GNU general public\nlicense v3.0](https://github.com/fcdimitr/sgtsnepi/blob/master/LICENSE).\nTo contribute to SG-t-SNE-Π or report any problem, follow our\n[contribution\nguidelines](https://github.com/fcdimitr/sgtsnepi/blob/master/CONTRIBUTING.md)\nand [code of\nconduct](https://github.com/fcdimitr/sgtsnepi/blob/master/CODE_OF_CONDUCT.md).\n\n\n## Contributors \n\n*Design and development*:  \nNikos Pitsianis<sup>1,2</sup>, Dimitris Floros<sup>1</sup>,\nAlexandros-Stavros Iliopoulos<sup>2</sup>, Xiaobai\nSun<sup>2</sup>\n\n<sup>1</sup> Department of Electrical and Computer Engineering,\nAristotle University of Thessaloniki, Thessaloniki 54124, Greece  \n<sup>2</sup> Department of Computer Science, Duke University, Durham, NC\n27708, USA\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/fcdimitr/sgtsnepi",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "sgtsnepi",
    "package_url": "https://pypi.org/project/sgtsnepi/",
    "platform": "",
    "project_url": "https://pypi.org/project/sgtsnepi/",
    "project_urls": {
      "Homepage": "https://github.com/fcdimitr/sgtsnepi"
    },
    "release_url": "https://pypi.org/project/sgtsnepi/0.101/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "SG-t-SNE-Π Swift Neighbor Embedding of Sparse Stochastic Graphs",
    "version": "0.101",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 10743791,
  "releases": {
    "0.101": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "533f5a3ca1ddb0b50010e0adaeed5a324cc691c69ed1e15684ae0561baee1589",
          "md5": "705eebcc0f24e94e961d973cb45f362d",
          "sha256": "402d43b5764437c7e1510265846dfa5f89efe8e0f765445aa76699d92db3d93b"
        },
        "downloads": -1,
        "filename": "sgtsnepi-0.101-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "705eebcc0f24e94e961d973cb45f362d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 24629,
        "upload_time": "2021-06-25T14:50:43",
        "upload_time_iso_8601": "2021-06-25T14:50:43.219851Z",
        "url": "https://files.pythonhosted.org/packages/53/3f/5a3ca1ddb0b50010e0adaeed5a324cc691c69ed1e15684ae0561baee1589/sgtsnepi-0.101-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "533f5a3ca1ddb0b50010e0adaeed5a324cc691c69ed1e15684ae0561baee1589",
        "md5": "705eebcc0f24e94e961d973cb45f362d",
        "sha256": "402d43b5764437c7e1510265846dfa5f89efe8e0f765445aa76699d92db3d93b"
      },
      "downloads": -1,
      "filename": "sgtsnepi-0.101-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "705eebcc0f24e94e961d973cb45f362d",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 24629,
      "upload_time": "2021-06-25T14:50:43",
      "upload_time_iso_8601": "2021-06-25T14:50:43.219851Z",
      "url": "https://files.pythonhosted.org/packages/53/3f/5a3ca1ddb0b50010e0adaeed5a324cc691c69ed1e15684ae0561baee1589/sgtsnepi-0.101-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}