{
  "info": {
    "author": "Charles Lai",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Tiny OpenAI ChatGPT and Whisper API Library\n- 2023/3     V0.12       By Charles Lai\n\n## Features\n- OpenAI ChatGPT and Whisper API library written in pure Python, so it can run in Python environment on M1/M2 Mac, iPad/iPhone(e.g. Pythonista, Juno, CODE, Pyto, ...), Android.\n- Supports methods that conform to the ChatGPT API JSON format for API calls. Provides an easy-to-use quick dialog method, support for contextual associations; and easy language translation method.\n- Support for Whisper API calls to recognize and parse uploaded audio files as text messages or translate them into English.\n- Support Embedding API call, Embedding vectorization of the incoming text, support string or text array\n\n## How to Use\n### ChatGPT\n- **__init__(self, API_Key='', Proxy='', Model='gpt-3.5-turbo', URL='https://api.openai.com/v1/chat/completions', Debug=False)**\n  - Initialize the ChatGPT object, with the following parameters\n  - API_Key: your openAI API Key\n  - Proxy: If needed, set your http proxy server, e.g.: http://192.168.3.1:3128\n  - Model: If needed, you can set it according to the OpenAI API documentation, e.g. change the default gpt-3.5-turbo to gpt-3.5-turbo-0301\n  - URL: If OpenAI has changed the API URL address, you can change it here\n  - Debug: if there is a network error or call error, whether to print out the error message, default is False.\n- **call(self, data)**\n  - Call ChatGPT interface, return data in JSON format (see OpenAI API documentation for JSON details)\n  - data is a Python dictionary (same as JSON), see the OpenAI API documentation for details, for example:\n``` python\n  data = [ {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": \"What is the OpenAI mission?\"} ]\n```  \n- **query(data, flag=False, hcnt=0, system='You are a helpful assistant.')**\n  - To simplify the operation, the query method implements the simplest and quickest dialog function, simply typing the question and returning the text of the ChatGPT answer.\n  - data: your question text\n  - flag: whether you need to ensure contextual coherence in the conversation. Because of the nature of ChatGPT, if you want the next question to be related to the previous one, you need to do something special and bring the previous content and answer with you. To do this, just set the flag to True\n  - hcnt: The number of contextual history conversations, default is 0, which means that each conversation will pass all previous history questions and answers to ChatGPT. Set to 6, which means that only the last 6 conversations will be kept. (Note: Because of ChatGPT's limit, the maximum number of tokens per conversation is 4096, so keeping all the history will cause the limit to be exceeded)\n  - system: This is used to set the system role description of ChatGPT, see the OpenAI documentation for details\n- **translate(text, lang='simplified chinese')**\n  - To simplify the operation, a quick language translation function is provided to translate the input text into the corresponding language.\n  - text: the text to be translated\n  - lang: the language you want to translate to, e.g. english, japan, simplified chinese, etc.\n- **cHinfo()**\n  - Delete Contextual Dialog History\n- **Statistics**\n  - Call_cnt: Total number of ChatGPT calls\n  - Total_tokens: Total Tokens usage data (OpenAI uses this as a basis for billing, and it is derived from the data returned by the ChatGPT API) \n- **Conversation history data and clear**\n  - Hinfo: When using the query method and setting flag=True, this list holds all the conversation history.\n  - If you need to delete it, use the cHinfo() method\n- **A simple example**\n``` python\nimport tinyOpenAI\n\ng = tinyOpenAI.ChatGPT('your OpenAI API_Key')\n# g = tinyOpenAI.ChatGPT('your OpenAI API_Key','http://192.168.3.2:3128', Model='gpt-3.5-turbo-0301',Debug=True)\n# Conversation\nprint( g.query('Write a rhyming poem with the sea as the title', system='You are a master of art, answer questions with emoji icons') )\n# Continuous dialogue\nprint('======== continuous dialogue ============')\nprint(g.query('charles has $500, tom has $300, how much money do they have in total', True, 6))\nprint(g.query('charles and Tom who has more money', True, 6))\nprint(g.query('Sort them in order of money', True, 6))\n# print history\nprint(g.Hinfo)\n# clear Histroy\ng.cHinfo()\n# Statistics \nprint('Call cnt: %d, Total using tokens: %d' % (g.Call_cnt, g.Total_tokens) )\n```\n\n### Whisper (speech-to-text interface)\n- **__init__(API_Key='', Proxy='', Model='whisper-1', URL=('https://api.openai.com/v1/audio/transcriptions','https://api.openai.com/v1/ audio/translations'), Debug=False)**\n  - Initialize the Whisper object, with the following parameters\n  - API_Key: your openAI API Key\n  - Proxy: If needed, set your http proxy server, e.g.: http://192.168.3.1:3128\n  - Model: If needed, you can set it according to the OpenAI API documentation.\n  - URL: If OpenAI changed the API address, you can change it here. Note that this is a list of two items, the first URL is the original language output, the second URL is translated into English.\n  - Debug: If there is a network error or call error, whether to print out the error message, the default is not to print out the error message.\n- **call(file, Type=0)**\n  - file: voice file, format can be mp3/m4a/wav/mp4 with voice, refer to OpenAI API documentation\n  - Type: Type of processing,  0.transcribes in source language  1.transcribes into English\n- **Statistics**\n  - Call_cnt: Total number of Whisper calls\n  - Total_tokens: Total number of transcribed text (Note: OpenAI is billed for the length of audio, not the number of text)\n- **Simple example**\n``` python\nimport tinyOpenAI\n\nw = tinyOpenAI.Whisper('your OpenAI API_Key', Debug=True)\nprint(w.call('test1.m4a')) # or mp3/mp4 file\nprint(w.call('test2.m4a')) # or mp3/mp4 file\nprint('Call cnt: %d, Total Texts: %d' % (w.Call_cnt, w.Total_tokens) )\n```\n\n### Embedding (get the embedding vector of the text)\n- __init__(self, API_Key='', Proxy='', Model='text-embedding-ada-002', URL='https://api.openai.com/v1/embeddings', Debug=False)\n  - Initialize the creation of the Embedding object, with the following parameters\n  - API_Key: your openAI API Key\n  - Proxy: If needed, set your http proxy server, e.g.: http://192.168.3.1:3128\n  - Model: If needed, you can set it according to the OpenAI API documentation.\n  - URL: If OpenAI changes the API call address, you can change it here. Note that this is a list of two addresses, the first address is the original language output, the second address is translated into English.\n  - Debug: if there is a network error or call error, whether to print out the error message, the default is not\n- embed(data)\n  - data: the string or list of strings to be encoded\n  - The result is a list of embed vectors (1536 dimensions) corresponding to the strings, which can be obtained by\n    - For the input string, ret[0].get('embedding') can be used to get the vector\n    - For a list of input strings, you can get the list of vectors with [i.get('embedding') for i in ret]\n- Statistics\n  - Call_cnt: the cumulative number of calls to Whisper\n  - Total_tokens: cumulative number of transcribed texts (Note: OpenAI is billed for the length of the audio, not the number of texts)\n- Simple example  \n``` python\nimport tinyOpenAI\n\nEmbedding('your OpenAI API_Key', Debug=True)\nr = e.embed('just for fun')\nprint('vector dimension:',len(r[0].get('embedding')))\n# Compare the similarity of two texts\nr = e.embed(['just for fun','hello world.'])\nimport numpy as np\nprint('Similarity result:',np.dot(r[0].get('embedding'), r[1].get('embedding')))\n```\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/wolf71/tinyOpenAI",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "tinyOpenAI",
    "package_url": "https://pypi.org/project/tinyOpenAI/",
    "platform": null,
    "project_url": "https://pypi.org/project/tinyOpenAI/",
    "project_urls": {
      "Homepage": "https://github.com/wolf71/tinyOpenAI"
    },
    "release_url": "https://pypi.org/project/tinyOpenAI/0.12/",
    "requires_dist": [
      "requests"
    ],
    "requires_python": "",
    "summary": "Tiny OpenAI ChatGPT and Whisper API Library",
    "version": "0.12",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17399574,
  "releases": {
    "0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8cde1bcc63523d7769f69f4af0f6f58ab9e76e7fdd9b02be79daadfbe3932cd2",
          "md5": "0df6a2515e9efc51f23c6647bbc4b8ab",
          "sha256": "ea4d9764f2fdbc8d835870f0f1a4dbc85f59c7daadb1a49a94c32a0606d2af23"
        },
        "downloads": -1,
        "filename": "tinyOpenAI-0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0df6a2515e9efc51f23c6647bbc4b8ab",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 7029,
        "upload_time": "2023-03-07T13:30:38",
        "upload_time_iso_8601": "2023-03-07T13:30:38.693626Z",
        "url": "https://files.pythonhosted.org/packages/8c/de/1bcc63523d7769f69f4af0f6f58ab9e76e7fdd9b02be79daadfbe3932cd2/tinyOpenAI-0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "39cb50e2eb49070f39945fd6c67dd062a6bb7f4aabf42f2220bde84078f0b6af",
          "md5": "9d39545cbc3610ca9826060be46f72dd",
          "sha256": "74f5602bb1608f27ca4b0aa62d3e724c47eae68bc1f21104731c03a3adc0fdca"
        },
        "downloads": -1,
        "filename": "tinyOpenAI-0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "9d39545cbc3610ca9826060be46f72dd",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 6145,
        "upload_time": "2023-03-07T13:30:41",
        "upload_time_iso_8601": "2023-03-07T13:30:41.128662Z",
        "url": "https://files.pythonhosted.org/packages/39/cb/50e2eb49070f39945fd6c67dd062a6bb7f4aabf42f2220bde84078f0b6af/tinyOpenAI-0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.12": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1d6fd33a6aeef439e18677462232d5ec4d7607a7e6cf7580823fb532c2c801ff",
          "md5": "4943e1de5957e5671fe3e79f3e4faaf2",
          "sha256": "5cf4d5de7a845a84b7c91d8279a4b447d9f2ffbc392c99f8c2a862e579af56d6"
        },
        "downloads": -1,
        "filename": "tinyOpenAI-0.12-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "4943e1de5957e5671fe3e79f3e4faaf2",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 7616,
        "upload_time": "2023-03-22T14:38:03",
        "upload_time_iso_8601": "2023-03-22T14:38:03.313765Z",
        "url": "https://files.pythonhosted.org/packages/1d/6f/d33a6aeef439e18677462232d5ec4d7607a7e6cf7580823fb532c2c801ff/tinyOpenAI-0.12-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c54db86f70f94e2902768f32803e89e94f37454035d103ad529f3ce8a65c58c9",
          "md5": "768933c8579701cf939e65cde5f778cb",
          "sha256": "f5b7596d867303e19a196e19b760ab6299d06b741b6b280bfb8d71c7ac8bcd53"
        },
        "downloads": -1,
        "filename": "tinyOpenAI-0.12.tar.gz",
        "has_sig": false,
        "md5_digest": "768933c8579701cf939e65cde5f778cb",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 6704,
        "upload_time": "2023-03-22T14:38:05",
        "upload_time_iso_8601": "2023-03-22T14:38:05.193713Z",
        "url": "https://files.pythonhosted.org/packages/c5/4d/b86f70f94e2902768f32803e89e94f37454035d103ad529f3ce8a65c58c9/tinyOpenAI-0.12.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "1d6fd33a6aeef439e18677462232d5ec4d7607a7e6cf7580823fb532c2c801ff",
        "md5": "4943e1de5957e5671fe3e79f3e4faaf2",
        "sha256": "5cf4d5de7a845a84b7c91d8279a4b447d9f2ffbc392c99f8c2a862e579af56d6"
      },
      "downloads": -1,
      "filename": "tinyOpenAI-0.12-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "4943e1de5957e5671fe3e79f3e4faaf2",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 7616,
      "upload_time": "2023-03-22T14:38:03",
      "upload_time_iso_8601": "2023-03-22T14:38:03.313765Z",
      "url": "https://files.pythonhosted.org/packages/1d/6f/d33a6aeef439e18677462232d5ec4d7607a7e6cf7580823fb532c2c801ff/tinyOpenAI-0.12-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "c54db86f70f94e2902768f32803e89e94f37454035d103ad529f3ce8a65c58c9",
        "md5": "768933c8579701cf939e65cde5f778cb",
        "sha256": "f5b7596d867303e19a196e19b760ab6299d06b741b6b280bfb8d71c7ac8bcd53"
      },
      "downloads": -1,
      "filename": "tinyOpenAI-0.12.tar.gz",
      "has_sig": false,
      "md5_digest": "768933c8579701cf939e65cde5f778cb",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 6704,
      "upload_time": "2023-03-22T14:38:05",
      "upload_time_iso_8601": "2023-03-22T14:38:05.193713Z",
      "url": "https://files.pythonhosted.org/packages/c5/4d/b86f70f94e2902768f32803e89e94f37454035d103ad529f3ce8a65c58c9/tinyOpenAI-0.12.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}