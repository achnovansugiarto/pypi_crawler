{
  "info": {
    "author": "Zhensu Sun",
    "author_email": "zhensuuu@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Code for \"On the importance of Building High-quality Training Datasets for Neural Code Search\"\nThis repo contains the source code introduced in our paper. The COFIC dataset can be downloaded [here](https://drive.google.com/file/d/1Ai0WMYrIGQQLqBC180mzUVDSbpkgO6uD/view?usp=sharing).\n\n# Natural Language Query Filter (NLQF)\n\n``NLQF`` is a Python3 library for filtering query-appropriate text to build high-quality code search datasets.\nIt consists of two filters: a rule-based filer and a model-based filter (Pytorch required).\nCurrently, ``NLQF`` should be used with GPU-enabled Pytorch.\n\n## Installation\nWe have uploaded ``NLQF`` to Python Package Index (PyPi) and you can install it by the following command:\n```\npip install nlqf\n```\n\nThe source code of ``NLQF`` is available at https://github.com/v587su/NLQF.\nYou can also download the source code from the above link and install it directly with the following command:\n\n```\npip install -r requirements.txt\npython setup.py install\n```\n\nBesides, ``nlqf`` should be used with GPU-enabled Pytorch. You can refer to https://pytorch.org/get-started/locally/ to install Pytorch. Pytorch 1.3 is recommended.\n\n## Usage\nThere are two functional APIs in this library: ``nlqf.rule_filter`` and ``nlqf.model_filter``.\nThe input of each filter is a list of comment strings and the output is a list of retained comments and a list of the index of the retained comments.\n\nIt is noteworthy that, to use the ``model_filter``, you need to download the pre-trained model ``./resource/vae.model`` and the word vocabulary ``./resource/word_vocab.json`` form https://github.com/v587su/NLQF.\n\nHere is the example script to use ``nlqf``:\n```\nimport nlqf\nimport torch \nimport json\n\nvocab_path = './word_vocab.json'\nmodel_path = './vae.model'\nwith open(vocab_path, 'r') as f:\n    word_vocab = json.load(f)\nmodel = torch.load(model_path)\n\nraw_comments = ['======','create a remote conection','return @test','convert int to string']\n\n# Select the rules to be applied from the following default ruleset:\n# 'contain_any_url': remove comments containing any url\n# 'contain_any_javadoc_tag': remove comments containing any javadoc tag\n# 'contain_any_non_English': remove comments containing any non-English words\n# 'not_contain_any_letter': remove comments not containing any letter\n# 'less_than_three_words': remove comments with less than three words\n# 'end_with_question_mark': remove comments ending with question mark\n# 'contain_html_tag': remove comments containing html tag\n# 'detach_brackets': detach the content in brackets from the comment\n# 'detach_html_tag': detach the content in html tag from the comment\nrule_list = ['contain_any_javadoc_tag','not_contain_any_letter']\n\n# Define your own rule using functions. \n# Return False if you want to discard the comment string. \n# Return True if you want to retain the comment string. \n# Return String if you want to replace the comment string with your String.\ndef my_rule1(comment_str):\n    return len(comment_str) < 10\n\ndef my_rule2(comment_str):\n    if comment_str.startswith('Return'):\n        return comment_str.replace('Return', '')\n    else:\n        return True\n\n# The key should start with 'detach' if your rule is for detachable content.\n# Otherwise, name the key as you like. \nmy_rule_dict = {\n    'length_less_than_10':my_rule1,\n    'detach_return':my_rule2\n}\n\ncomments,idx = nlqf.rule_filter(raw_comments, \\\n        selected_rules=rule_list,defined_rule_dict=my_rule_dict)\nprint(comments,idx)\n# ['create a remote conection', 'convert int to string'] [1, 3]\n\ncomments,idx = nlqf.model_filter(raw_comments, word_vocab, model, \\\n        with_cuda=True, query_len=20,num_workers=1, max_iter=1000)\nprint(comments,idx)\n# ['create a remote conection', 'convert int to string'] [1 3]\n```\n\n## Process to manually inspect the filtering effects of NLQF\nWe provide a script and a small dataset ``./resource/samples.txt`` to validate the executability of NLQF.\nThe users can intuitively observe the cleaning effects from the printed outputs.\nThe scritpts are as follows (don't forget to modify the path of the required files):\n```\nimport nlqf\nimport torch \nimport json\n\nvocab_path = './word_vocab.json'\nmodel_path = './vae.model'\nsample_path = './samples.txt'\nwith open(vocab_path, 'r') as f:\n    word_vocab = json.load(f)\nmodel = torch.load(model_path)\n\nwith open(sample_path, 'r') as f:\n    raw_comments = f.readlines()\n\ncomments,idx = nlqf.rule_filter(raw_comments)\ndiscarded_idx = set(range(len(raw_comments)))-set(idx)\nprint('comments discarded by rule filter:',[raw_comments[i] for i in discarded_idx])\n\nqueries,idx = nlqf.model_filter(comments, word_vocab, model, \\\n        with_cuda=True, query_len=20,num_workers=1, max_iter=1000)\ndiscarded_idx = set(range(len(comments)))-set(idx)\nprint('comments discarded by model filter:',[comments[i] for i in discarded_idx])\nprint('comments finally retained:', queries)\n```\n\n\n## Process to reproduce the experiment in our paper using NLQF\nIn our paper, we train a new code search model on the filtered dataset and evaluate the performance of the trained model.\nIt is noteworthy that the running time is computed with GPU enabled.\n\n### Step 1: Download the evaluation scripts and dataset.\nWe provide our evaluation scripts and dataset, which can be downloaded at https://drive.google.com/file/d/1Nv86JmW7fknQQQviV2agSw6XPhCCCo2S/view?usp=sharing\n\nDecompress the downloaded project:\n```\ntar -zvxf icse_evaluation.tar.gz\n```\n\nThe first-level structure of the decompressed project is as follows:\n```\n- models                # architecture of DeepCS     \n- output                # directory to store the trained model\n- processed_dataset     # directory to store the filtered and processed dataset\n- raw_dataset           # directory to store the CodeSearch dataset\n- resource              # directory to store the vocab and model for NLQF\n- configs.py            # the configuration file for DeepCS\n- data_loader.py        # the data loader for DeepCS\n- filtering.py          # our data filtering and processing script for DeepCS\n- modules.py            # the modules for DeepCS\n- repr_code.py          # the script to evaluate DeepCS model\n- train.py              # the script to train DeepCS model\n- utils.py              # utility functions for DeepCS\n- requirements.txt      # the requirements of this project\n```\nThe project requires Python3.6.9 and the following packages:\n```\njsonlines\npandas\nnlqf==0.1.12\njavalang==0.12.0\nnltk\ntorch==1.3.1\nnumpy\ntqdm\ntables==3.4.3\n```\nYou can install them by the following command:\n```\ncd ICSE_deep_code_search\npip install -r requirements.txt\n```\n\n\n\n### Step 2: Filter the dataset and process the filtered dataset into a format that can be used by DeepCS.\nBefore the filtering, you should download the code stopwords (https://github.com/BASE-LAB-SJTU/CSES_IR/blob/master/src/test/resources/stopwords/codeStopWord) and english stopwords documents (https://github.com/BASE-LAB-SJTU/CSES_IR/blob/master/src/test/resources/stopwords/codeQueryStopWord) and put them in ``~/nltk_data/corpora/stopwords``. (This path depends on where nltk is located.).\n\nAfter that, run the following command (requires 4 hours to run):\n\n```\npython filtering.py\n```\n\nThe filtered and processed dataset is saved in ``./processed_dataset/``.\nWe have pre-run this command and generated a processed dataset in this directory.\nYou can jump to Step 3 to save your time.\n\n### Step 3: Train the code search model on the filtered dataset.\nRun the following command to train the model (requires 4 hours to run):\n\n```\npython train.py\n```\n\nThe trained model is saved in ``./output/``.\nWe have pre-run this command and obtained a trained model ``./output/epo100.h5``.\nYou can jump to Step 4 to save your time.\n\n### Step 4: Evaluate the performance of the trained model.\nRun the following command to evaluate the trained model (requires 5 minutes to run):\n```\npython repr_code.py --reload_from 100\n```\n\nThe evaluation results will be printed in the terminal. \nIt should be 0.541 MRR and 344 Hit@10.\n\n\n### VAE Model \nTo train the filtering model with your own query corpus, you can refer to [this repo](https://github.com/v587su/VAE_public).\n\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "nlqf",
    "package_url": "https://pypi.org/project/nlqf/",
    "platform": "",
    "project_url": "https://pypi.org/project/nlqf/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/nlqf/0.1.13/",
    "requires_dist": [
      "torch (==1.3.1)",
      "numpy",
      "sklearn",
      "nltk"
    ],
    "requires_python": "",
    "summary": "A tool for fittering code comments",
    "version": "0.1.13",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12893593,
  "releases": {
    "0.1.13": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e645e8bec16765dd73b737d7e6bdbe6a31a0ef6839886b651feddab23419ea32",
          "md5": "b9e1ac735cef02338e11e398a0437e2b",
          "sha256": "02d792fe7c325cba4649275262463364a7489addd08c5ec1c4dff24c0e8ba430"
        },
        "downloads": -1,
        "filename": "nlqf-0.1.13-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "b9e1ac735cef02338e11e398a0437e2b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 9009,
        "upload_time": "2022-02-15T03:29:47",
        "upload_time_iso_8601": "2022-02-15T03:29:47.127426Z",
        "url": "https://files.pythonhosted.org/packages/e6/45/e8bec16765dd73b737d7e6bdbe6a31a0ef6839886b651feddab23419ea32/nlqf-0.1.13-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cb610a49b1110801398187a771e4be96d784a51a56ffc0c99df8908ff382b1ce",
          "md5": "77e8ecbef1621c9d4948f022f278501b",
          "sha256": "cd3be0edd7b04252c17cdcf04f94ae67ab0c0037aa97a229b108ce8f68451da3"
        },
        "downloads": -1,
        "filename": "nlqf-0.1.13.tar.gz",
        "has_sig": false,
        "md5_digest": "77e8ecbef1621c9d4948f022f278501b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 8613,
        "upload_time": "2022-02-15T03:29:48",
        "upload_time_iso_8601": "2022-02-15T03:29:48.781156Z",
        "url": "https://files.pythonhosted.org/packages/cb/61/0a49b1110801398187a771e4be96d784a51a56ffc0c99df8908ff382b1ce/nlqf-0.1.13.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "e645e8bec16765dd73b737d7e6bdbe6a31a0ef6839886b651feddab23419ea32",
        "md5": "b9e1ac735cef02338e11e398a0437e2b",
        "sha256": "02d792fe7c325cba4649275262463364a7489addd08c5ec1c4dff24c0e8ba430"
      },
      "downloads": -1,
      "filename": "nlqf-0.1.13-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "b9e1ac735cef02338e11e398a0437e2b",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 9009,
      "upload_time": "2022-02-15T03:29:47",
      "upload_time_iso_8601": "2022-02-15T03:29:47.127426Z",
      "url": "https://files.pythonhosted.org/packages/e6/45/e8bec16765dd73b737d7e6bdbe6a31a0ef6839886b651feddab23419ea32/nlqf-0.1.13-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "cb610a49b1110801398187a771e4be96d784a51a56ffc0c99df8908ff382b1ce",
        "md5": "77e8ecbef1621c9d4948f022f278501b",
        "sha256": "cd3be0edd7b04252c17cdcf04f94ae67ab0c0037aa97a229b108ce8f68451da3"
      },
      "downloads": -1,
      "filename": "nlqf-0.1.13.tar.gz",
      "has_sig": false,
      "md5_digest": "77e8ecbef1621c9d4948f022f278501b",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 8613,
      "upload_time": "2022-02-15T03:29:48",
      "upload_time_iso_8601": "2022-02-15T03:29:48.781156Z",
      "url": "https://files.pythonhosted.org/packages/cb/61/0a49b1110801398187a771e4be96d784a51a56ffc0c99df8908ff382b1ce/nlqf-0.1.13.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}