{
  "info": {
    "author": "Clement Chadebec (HekA team INRIA)",
    "author_email": "clement.chadebec@inria.fr",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9"
    ],
    "description": "<p align=\"center\">\n\t<a href=\"https://pypi.org/project/pythae/\">\n\t    <img src='https://badge.fury.io/py/pythae.svg' alt='Python' />\n\t</a>\n    <a>\n\t    <img src='https://img.shields.io/badge/python-3.7%7C3.8%7C3.9%2B-blueviolet' alt='Python' />\n\t</a>\n\t<a href='https://pythae.readthedocs.io/en/latest/?badge=latest'>\n    \t<img src='https://readthedocs.org/projects/pythae/badge/?version=latest' alt='Documentation Status' />\n\t</a>\n\t<a href='https://opensource.org/licenses/Apache-2.0'>\n\t    <img src='https://img.shields.io/github/license/clementchadebec/benchmark_VAE?color=blue' />\n\t</a><br>\n    <a>\n\t    <img src='https://img.shields.io/badge/code%20style-black-black' />\n\t</a>\n\t<a href=\"https://codecov.io/gh/clementchadebec/benchmark_VAE\">\n  \t\t<img src=\"https://codecov.io/gh/clementchadebec/benchmark_VAE/branch/main/graph/badge.svg?token=KEM7KKISXJ\"/>\n\t</a>\n\t<a href=\"https://colab.research.google.com/github/clementchadebec/benchmark_VAE/blob/main/examples/notebooks/overview_notebook.ipynb\">\n  \t\t<img src=\"https://colab.research.google.com/assets/colab-badge.svg\"/>\n\t</a>\n\t</a>\n</p>\n\n</p>\n<p align=\"center\">\n  <a href=\"https://pythae.readthedocs.io/en/latest/\">Documentation</a>\n</p>\n\n\n# pythae \n\nThis library implements some of the most common (Variational) Autoencoder models under a unified implementation. In particular, it \nprovides the possibility to perform benchmark experiments and comparisons by training \nthe models with the same autoencoding neural network architecture. The feature *make your own autoencoder* \nallows you to train any of these models with your own data and own Encoder and Decoder neural networks. It integrates experiment monitoring tools such [wandb](https://wandb.ai/), [mlflow](https://mlflow.org/) or [comet-ml](https://www.comet.com/signup?utm_source=pythae&utm_medium=partner&utm_campaign=AMS_US_EN_SNUP_Pythae_Comet_Integration) üß™ and allows model sharing and loading from the [HuggingFace Hub](https://huggingface.co/models) ü§ó in a few lines of code.\n\n**News** üì¢\n\nAs of v0.1.0, `Pythae` now supports distributed training using PyTorch's [DDP](https://pytorch.org/docs/stable/notes/ddp.html). You can now train your favorite VAE faster and on larger datasets, still with a few lines of code.\nSee our speed-up [benchmark](#benchmark).\n\n## Quick access:\n- [Installation](#installation)\n- [Implemented models](#available-models) / [Implemented samplers](#available-samplers)\n- [Reproducibility statement](#reproducibility) / [Results flavor](#results)\n- [Model training](#launching-a-model-training) / [Data generation](#launching-data-generation) / [Custom network architectures](#define-you-own-autoencoder-architecture) / [Distributed training](#distributed-training-with-pythae)\n- [Model sharing with ü§ó Hub](#sharing-your-models-with-the-huggingface-hub-) / [Experiment tracking with `wandb`](#monitoring-your-experiments-with-wandb-) / [Experiment tracking with `mlflow`](#monitoring-your-experiments-with-mlflow-) / [Experiment tracking with `comet_ml`](#monitoring-your-experiments-with-comet_ml-)\n- [Tutorials](#getting-your-hands-on-the-code) / [Documentation](https://pythae.readthedocs.io/en/latest/)\n- [Contributing üöÄ](#contributing-) / [Issues üõ†Ô∏è](#dealing-with-issues-%EF%B8%8F)\n- [Citing this repository](#citation)\n\n# Installation\n\nTo install the latest stable release of this library run the following using ``pip``\n\n```bash\n$ pip install pythae\n``` \n\nTo install the latest github version of this library run the following using ``pip``\n\n```bash\n$ pip install git+https://github.com/clementchadebec/benchmark_VAE.git\n``` \n\nor alternatively you can clone the github repo to access to tests, tutorials and scripts.\n```bash\n$ git clone https://github.com/clementchadebec/benchmark_VAE.git\n```\nand install the library\n```bash\n$ cd benchmark_VAE\n$ pip install -e .\n``` \n\n## Available Models\n\nBelow is the list of the models currently implemented in the library.\n\n\n|               Models               |                                                                                    Training example                                                                                    |                     Paper                    |                           Official Implementation                          |\n|:----------------------------------:|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:--------------------------------------------:|:--------------------------------------------------------------------------:|\n| Autoencoder (AE)                   | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/clementchadebec/benchmark_VAE/blob/main/examples/notebooks/models_training/ae_training.ipynb) |                                              |                                                                            |\n| Variational Autoencoder (VAE)      | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/clementchadebec/benchmark_VAE/blob/main/examples/notebooks/models_training/vae_training.ipynb) | [link](https://arxiv.org/abs/1312.6114)  |\n| Beta Variational Autoencoder (BetaVAE) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/clementchadebec/benchmark_VAE/blob/main/examples/notebooks/models_training/beta_vae_training.ipynb) | [link](https://openreview.net/pdf?id=Sy2fzU9gl)  |   \nVAE with Linear Normalizing Flows (VAE_LinNF) |  [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/clementchadebec/benchmark_VAE/blob/main/examples/notebooks/models_training/vae_lin_nf_training.ipynb) | [link](https://arxiv.org/abs/1505.05770) |         \nVAE with Inverse Autoregressive Flows (VAE_IAF) |  [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/clementchadebec/benchmark_VAE/blob/main/examples/notebooks/models_training/vae_iaf_training.ipynb) | [link](https://arxiv.org/abs/1606.04934) |  [link](https://github.com/openai/iaf)                                  |\n| Disentangled Beta Variational Autoencoder (DisentangledBetaVAE) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/clementchadebec/benchmark_VAE/blob/main/examples/notebooks/models_training/disentangled_beta_vae_training.ipynb) | [link](https://arxiv.org/abs/1804.03599)  |   \n| Disentangling by Factorising (FactorVAE) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/clementchadebec/benchmark_VAE/blob/main/examples/notebooks/models_training/factor_vae_training.ipynb) | [link](https://arxiv.org/abs/1802.05983)  |                                                                            |\n| Beta-TC-VAE (BetaTCVAE) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/clementchadebec/benchmark_VAE/blob/main/examples/notebooks/models_training/beta_tc_vae_training.ipynb) | [link](https://arxiv.org/abs/1802.04942)  |  [link](https://github.com/rtqichen/beta-tcvae)\n| Importance Weighted Autoencoder (IWAE) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/clementchadebec/benchmark_VAE/blob/main/examples/notebooks/models_training/iwae_training.ipynb) | [link](https://arxiv.org/abs/1509.00519v4)  | [link](https://github.com/yburda/iwae)  \n| Multiply Importance Weighted Autoencoder (MIWAE) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/clementchadebec/benchmark_VAE/blob/main/examples/notebooks/models_training/miwae_training.ipynb) | [link](https://arxiv.org/abs/1802.04537)  |       \n| Partially Importance Weighted Autoencoder (PIWAE) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/clementchadebec/benchmark_VAE/blob/main/examples/notebooks/models_training/piwae_training.ipynb) | [link](https://arxiv.org/abs/1802.04537)  |       \n| Combination Importance Weighted Autoencoder (CIWAE) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/clementchadebec/benchmark_VAE/blob/main/examples/notebooks/models_training/ciwae_training.ipynb) | [link](https://arxiv.org/abs/1802.04537)  |                                                                             |\n| VAE with perceptual metric similarity (MSSSIM_VAE)      | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/clementchadebec/benchmark_VAE/blob/main/examples/notebooks/models_training/ms_ssim_vae_training.ipynb) | [link](https://arxiv.org/abs/1511.06409)  |\n| Wasserstein Autoencoder (WAE)      | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/clementchadebec/benchmark_VAE/blob/main/examples/notebooks/models_training/wae_training.ipynb) | [link](https://arxiv.org/abs/1711.01558) | [link](https://github.com/tolstikhin/wae)                                  |\n| Info Variational Autoencoder (INFOVAE_MMD)      | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/clementchadebec/benchmark_VAE/blob/main/examples/notebooks/models_training/info_vae_training.ipynb) | [link](https://arxiv.org/abs/1706.02262) |                                   |\n| VAMP Autoencoder (VAMP)            | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/clementchadebec/benchmark_VAE/blob/main/examples/notebooks/models_training/vamp_training.ipynb) | [link](https://arxiv.org/abs/1705.07120) | [link](https://github.com/jmtomczak/vae_vampprior)                         |\n| Hyperspherical VAE (SVAE)            | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/clementchadebec/benchmark_VAE/blob/main/examples/notebooks/models_training/svae_training.ipynb) | [link](https://arxiv.org/abs/1804.00891) | [link](https://github.com/nicola-decao/s-vae-pytorch)\n| Poincar√© Disk VAE (PoincareVAE)            | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/clementchadebec/benchmark_VAE/blob/main/examples/notebooks/models_training/pvae_training.ipynb) | [link](https://arxiv.org/abs/1901.06033) | [link](https://github.com/emilemathieu/pvae)                         |\n| Adversarial Autoencoder (Adversarial_AE)                   | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/clementchadebec/benchmark_VAE/blob/main/examples/notebooks/models_training/adversarial_ae_training.ipynb) | [link](https://arxiv.org/abs/1511.05644)\n| Variational Autoencoder GAN (VAEGAN) ü•ó | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/clementchadebec/benchmark_VAE/blob/main/examples/notebooks/models_training/vaegan_training.ipynb) | [link](https://arxiv.org/abs/1512.09300) | [link](https://github.com/andersbll/autoencoding_beyond_pixels)| [link](https://arxiv.org/abs/1512.09300) | [link](https://github.com/andersbll/autoencoding_beyond_pixels)\n| Vector Quantized VAE (VQVAE) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/clementchadebec/benchmark_VAE/blob/main/examples/notebooks/models_training/vqvae_training.ipynb) | [link](https://arxiv.org/abs/1711.00937) | [link](https://github.com/deepmind/sonnet/blob/v2/sonnet/)\n| Hamiltonian VAE (HVAE)             | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/clementchadebec/benchmark_VAE/blob/main/examples/notebooks/models_training/hvae_training.ipynb) | [link](https://arxiv.org/abs/1805.11328) | [link](https://github.com/anthonycaterini/hvae-nips)                       |\n| Regularized AE with L2 decoder param (RAE_L2) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/clementchadebec/benchmark_VAE/blob/main/examples/notebooks/models_training/rae_l2_training.ipynb) | [link](https://arxiv.org/abs/1903.12436) | [link](https://github.com/ParthaEth/Regularized_autoencoders-RAE-/tree/master/) |\n| Regularized AE with gradient penalty (RAE_GP) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/clementchadebec/benchmark_VAE/blob/main/examples/notebooks/models_training/rae_gp_training.ipynb) | [link](https://arxiv.org/abs/1903.12436) | [link](https://github.com/ParthaEth/Regularized_autoencoders-RAE-/tree/master/) |\n| Riemannian Hamiltonian VAE (RHVAE) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/clementchadebec/benchmark_VAE/blob/main/examples/notebooks/models_training/rhvae_training.ipynb) | [link](https://arxiv.org/abs/2105.00026) | [link](https://github.com/clementchadebec/pyraug)|\n\n**See [reconstruction](#Reconstruction) and [generation](#Generation) results for all aforementionned models**\n\n## Available Samplers\n\nBelow is the list of the models currently implemented in the library.\n\n|                Samplers               |   Models  \t\t  | Paper \t\t\t\t\t\t\t\t\t\t\t  | Official Implementation \t\t\t\t  |\n|:-------------------------------------:|:-------------------:|:-------------------------------------------------:|:-----------------------------------------:|\n| Normal prior (NormalSampler)                         | all models\t\t  | [link](https://arxiv.org/abs/1312.6114)\t\t  |\n| Gaussian mixture (GaussianMixtureSampler) | all models\t\t  | [link](https://arxiv.org/abs/1903.12436) \t  | [link](https://github.com/ParthaEth/Regularized_autoencoders-RAE-/tree/master/models/rae) |\n| Two stage VAE sampler (TwoStageVAESampler)\t\t\t\t\t| all VAE based models| [link](https://openreview.net/pdf?id=B1e0X3C9tQ)  | [link](https://github.com/daib13/TwoStageVAE/) |)\n| Unit sphere uniform sampler (HypersphereUniformSampler)                     |    SVAE  \t\t  | [link](https://arxiv.org/abs/1804.00891)      |\t\t[link](https://github.com/nicola-decao/s-vae-pytorch)\n| Poincar√© Disk sampler (PoincareDiskSampler)                     |    PoincareVAE  \t\t  | [link](https://arxiv.org/abs/1901.06033)      |\t\t[link](https://github.com/emilemathieu/pvae)\n| VAMP prior sampler (VAMPSampler)                   |    VAMP   \t\t  | [link](https://arxiv.org/abs/1705.07120) \t  | [link](https://github.com/jmtomczak/vae_vampprior) |\n| Manifold sampler (RHVAESampler)                     |    RHVAE  \t\t  | [link](https://arxiv.org/abs/2105.00026)      |\t[link](https://github.com/clementchadebec/pyraug)|\n| Masked Autoregressive Flow Sampler (MAFSampler) | all models | [link](https://arxiv.org/abs/1705.07057v4)      |\t[link](https://github.com/gpapamak/maf) |\n| Inverse Autoregressive Flow Sampler (IAFSampler) | all models | [link](https://arxiv.org/abs/1606.04934) |  [link](https://github.com/openai/iaf)             |   \n| PixelCNN (PixelCNNSampler) | VQVAE | [link](https://arxiv.org/abs/1606.05328) |             |                     \n\n## Reproducibility\n\nWe validate the implementations by reproducing some results presented in the original publications when the official code has been released or when enough details about the experimental section of the papers were available. See [reproducibility](https://github.com/clementchadebec/benchmark_VAE/tree/main/examples/scripts/reproducibility) for more details.\n\n## Launching a model training\n\nTo launch a model training, you only need to call a `TrainingPipeline` instance. \n\n```python\n>>> from pythae.pipelines import TrainingPipeline\n>>> from pythae.models import VAE, VAEConfig\n>>> from pythae.trainers import BaseTrainerConfig\n\n>>> # Set up the training configuration\n>>> my_training_config = BaseTrainerConfig(\n...\toutput_dir='my_model',\n...\tnum_epochs=50,\n...\tlearning_rate=1e-3,\n...\tper_device_train_batch_size=200,\n...\tper_device_eval_batch_size=200,\n...\ttrain_dataloader_num_workers=2,\n...\teval_dataloader_num_workers=2,\n...\tsteps_saving=20,\n...\toptimizer_cls=\"AdamW\",\n...\toptimizer_params={\"weight_decay\": 0.05, \"betas\": (0.91, 0.995)},\n...\tscheduler_cls=\"ReduceLROnPlateau\",\n...\tscheduler_params={\"patience\": 5, \"factor\": 0.5}\n... )\n>>> # Set up the model configuration \n>>> my_vae_config = model_config = VAEConfig(\n...\tinput_dim=(1, 28, 28),\n...\tlatent_dim=10\n... )\n>>> # Build the model\n>>> my_vae_model = VAE(\n...\tmodel_config=my_vae_config\n... )\n>>> # Build the Pipeline\n>>> pipeline = TrainingPipeline(\n... \ttraining_config=my_training_config,\n... \tmodel=my_vae_model\n... )\n>>> # Launch the Pipeline\n>>> pipeline(\n...\ttrain_data=your_train_data, # must be torch.Tensor, np.array or torch datasets\n...\teval_data=your_eval_data # must be torch.Tensor, np.array or torch datasets\n... )\n```\n\nAt the end of training, the best model weights, model configuration and training configuration are stored in a `final_model` folder available in  `my_model/MODEL_NAME_training_YYYY-MM-DD_hh-mm-ss` (with `my_model` being the `output_dir` argument of the `BaseTrainerConfig`). If you further set the `steps_saving` argument to a certain value, folders named `checkpoint_epoch_k` containing the best model weights, optimizer, scheduler, configuration and training configuration at epoch *k* will also appear in `my_model/MODEL_NAME_training_YYYY-MM-DD_hh-mm-ss`.\n\n## Lauching a training on benchmark datasets\nWe also provide a training script example [here](https://github.com/clementchadebec/benchmark_VAE/tree/main/examples/scripts/training.py) that can be used to train the models on benchmarks datasets (mnist, cifar10, celeba ...). The script can be launched with the following commandline\n\n```bash\npython training.py --dataset mnist --model_name ae --model_config 'configs/ae_config.json' --training_config 'configs/base_training_config.json'\n```\n\nSee [README.md](https://github.com/clementchadebec/benchmark_VAE/tree/main/examples/scripts/README.md) for further details on this script\n\n## Launching data generation\n\n### Using the `GenerationPipeline`\n\nThe easiest way to launch a data generation from a trained model consists in using the built-in `GenerationPipeline` provided in Pythae. Say you want to generate 100 samples using a `MAFSampler` all you have to do is 1) relaod the trained model, 2) define the sampler's configuration and 3) create and launch the `GenerationPipeline` as follows\n\n```python\n>>> from pythae.models import AutoModel\n>>> from pythae.samplers import MAFSamplerConfig\n>>> from pythae.pipelines import GenerationPipeline\n>>> # Retrieve the trained model\n>>> my_trained_vae = AutoModel.load_from_folder(\n...\t'path/to/your/trained/model'\n... )\n>>> my_sampler_config = MAFSamplerConfig(\n...\tn_made_blocks=2,\n...\tn_hidden_in_made=3,\n...\thidden_size=128\n... )\n>>> # Build the pipeline\n>>> pipe = GenerationPipeline(\n...\tmodel=my_trained_vae,\n...\tsampler_config=my_sampler_config\n... )\n>>> # Launch data generation\n>>> generated_samples = pipe(\n...\tnum_samples=args.num_samples,\n...\treturn_gen=True, # If false returns nothing\n...\ttrain_data=train_data, # Needed to fit the sampler\n...\teval_data=eval_data, # Needed to fit the sampler\n...\ttraining_config=BaseTrainerConfig(num_epochs=200) # TrainingConfig to use to fit the sampler\n... )\n```\n\n### Using the Samplers\n\nAlternatively, you can launch the data generation process from a trained model directly with the sampler. For instance, to generate new data with your sampler, run the following.\n\n```python\n>>> from pythae.models import AutoModel\n>>> from pythae.samplers import NormalSampler\n>>> # Retrieve the trained model\n>>> my_trained_vae = AutoModel.load_from_folder(\n...\t'path/to/your/trained/model'\n... )\n>>> # Define your sampler\n>>> my_samper = NormalSampler(\n...\tmodel=my_trained_vae\n... )\n>>> # Generate samples\n>>> gen_data = my_samper.sample(\n...\tnum_samples=50,\n...\tbatch_size=10,\n...\toutput_dir=None,\n...\treturn_gen=True\n... )\n```\nIf you set `output_dir` to a specific path, the generated images will be saved as `.png` files named `00000000.png`, `00000001.png` ...\nThe samplers can be used with any model as long as it is suited. For instance, a `GaussianMixtureSampler` instance can be used to generate from any model but a `VAMPSampler` will only be usable with a `VAMP` model. Check [here](#available-samplers) to see which ones apply to your model. Be carefull that some samplers such as the `GaussianMixtureSampler` for instance may need to be fitted by calling the `fit` method before using. Below is an example for the `GaussianMixtureSampler`. \n\n```python\n>>> from pythae.models import AutoModel\n>>> from pythae.samplers import GaussianMixtureSampler, GaussianMixtureSamplerConfig\n>>> # Retrieve the trained model\n>>> my_trained_vae = AutoModel.load_from_folder(\n...\t'path/to/your/trained/model'\n... )\n>>> # Define your sampler\n... gmm_sampler_config = GaussianMixtureSamplerConfig(\n...\tn_components=10\n... )\n>>> my_samper = GaussianMixtureSampler(\n...\tsampler_config=gmm_sampler_config,\n...\tmodel=my_trained_vae\n... )\n>>> # fit the sampler\n>>> gmm_sampler.fit(train_dataset)\n>>> # Generate samples\n>>> gen_data = my_samper.sample(\n...\tnum_samples=50,\n...\tbatch_size=10,\n...\toutput_dir=None,\n...\treturn_gen=True\n... )\n```\n\n\n## Define you own Autoencoder architecture \n\nPythae provides you the possibility to define your own neural networks within the VAE models. For instance, say you want to train a Wassertstein AE with a specific encoder and decoder, you can do the following:\n\n```python\n>>> from pythae.models.nn import BaseEncoder, BaseDecoder\n>>> from pythae.models.base.base_utils import ModelOutput\n>>> class My_Encoder(BaseEncoder):\n...\tdef __init__(self, args=None): # Args is a ModelConfig instance\n...\t\tBaseEncoder.__init__(self)\n...\t\tself.layers = my_nn_layers()\n...\t\t\n...\tdef forward(self, x:torch.Tensor) -> ModelOutput:\n...\t\tout = self.layers(x)\n...\t\toutput = ModelOutput(\n...\t\t\tembedding=out # Set the output from the encoder in a ModelOutput instance \n...\t\t)\n...\t\treturn output\n...\n... class My_Decoder(BaseDecoder):\n...\tdef __init__(self, args=None):\n...\t\tBaseDecoder.__init__(self)\n...\t\tself.layers = my_nn_layers()\n...\t\t\n...\tdef forward(self, x:torch.Tensor) -> ModelOutput:\n...\t\tout = self.layers(x)\n...\t\toutput = ModelOutput(\n...\t\t\treconstruction=out # Set the output from the decoder in a ModelOutput instance\n...\t\t)\n...\t\treturn output\n...\n>>> my_encoder = My_Encoder()\n>>> my_decoder = My_Decoder()\n```\n\nAnd now build the model\n\n```python\n>>> from pythae.models import WAE_MMD, WAE_MMD_Config\n>>> # Set up the model configuration \n>>> my_wae_config = model_config = WAE_MMD_Config(\n...\tinput_dim=(1, 28, 28),\n...\tlatent_dim=10\n... )\n...\n>>> # Build the model\n>>> my_wae_model = WAE_MMD(\n...\tmodel_config=my_wae_config,\n...\tencoder=my_encoder, # pass your encoder as argument when building the model\n...\tdecoder=my_decoder # pass your decoder as argument when building the model\n... )\n```\n\n**important note 1**: For all AE-based models (AE, WAE, RAE_L2, RAE_GP), both the encoder and decoder must return a `ModelOutput` instance. For the encoder, the `ModelOutput` instance must contain the embbeddings under the key `embedding`. For the decoder, the `ModelOutput` instance must contain the reconstructions under the key `reconstruction`.\n\n\n**important note 2**: For all VAE-based models (VAE, BetaVAE, IWAE, HVAE, VAMP, RHVAE), both the encoder and decoder must return a `ModelOutput` instance. For the encoder, the `ModelOutput` instance must contain the embbeddings and **log**-covariance matrices (of shape batch_size x latent_space_dim) respectively under the key `embedding` and `log_covariance` key. For the decoder, the `ModelOutput` instance must contain the reconstructions under the key `reconstruction`.\n\n\n## Using benchmark neural nets\nYou can also find predefined neural network architectures for the most common data sets (*i.e.* MNIST, CIFAR, CELEBA ...) that can be loaded as follows\n\n```python\n>>> from pythae.models.nn.benchmark.mnist import (\n...\tEncoder_Conv_AE_MNIST, # For AE based model (only return embeddings)\n...\tEncoder_Conv_VAE_MNIST, # For VAE based model (return embeddings and log_covariances)\n...\tDecoder_Conv_AE_MNIST\n... )\n```\nReplace *mnist* by cifar or celeba to access to other neural nets.\n\n## Distributed Training with `Pythae`\nAs of `v0.1.0`, Pythae now supports distributed training using PyTorch's [DDP](https://pytorch.org/docs/stable/notes/ddp.html). It allows you to train your favorite VAE faster and on larger dataset using multi-gpu and/or multi-node training.\n\nTo do so, you can build a python script that will then be launched by a launcher (such as `srun` on a cluster). The only thing that is needed in the script is to specify some elements relative to the distributed environment (such as the number of nodes/gpus) directly in the training configuration as follows\n\n```python\n>>> training_config = BaseTrainerConfig(\n...     num_epochs=10,\n...     learning_rate=1e-3,\n...     per_device_train_batch_size=64,\n...     per_device_eval_batch_size=64,\n...     train_dataloader_num_workers=8,\n...     eval_dataloader_num_workers=8,\n...     dist_backend=\"nccl\", # distributed backend\n...     world_size=8 # number of gpus to use (n_nodes x n_gpus_per_node),\n...     rank=5 # process/gpu id,\n...     local_rank=1 # node id,\n...     master_addr=\"localhost\" # master address,\n...     master_port=\"12345\" # master port,\n... )\n```\n\nSee this [example script](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/scripts/distributed_training_imagenet.py) that defines a multi-gpu VQVAE training on ImageNet dataset. Please note that the way the distributed environnement variables (`world_size`, `rank` ...) are recovered may be specific to the cluster and launcher you use. \n\n### Benchmark\n\nBelow are indicated the training times for a Vector Quantized VAE (VQ-VAE) with `Pythae` for 100 epochs on MNIST on V100 16GB GPU(s), for 50 epochs on [FFHQ](https://github.com/NVlabs/ffhq-dataset) (1024x1024 images) and for 20 epochs on [ImageNet-1k](https://huggingface.co/datasets/imagenet-1k) on V100 32GB GPU(s).\n\n|  | Train Data | 1 GPU | 4 GPUs | 2x4 GPUs |\n|:---:|:---:|:---:|:---:|---|\n| MNIST (VQ-VAE) | 28x28 images (50k) | 235.18 s | 62.00 s | 35.86 s |\n| FFHQ 1024x1024 (VQVAE) | 1024x1024 RGB images (60k) | 19h 1min | 5h 6min | 2h 37min |\n| ImageNet-1k 128x128 (VQVAE) | 128x128 RGB images (~ 1.2M) | 6h 25min | 1h 41min | 51min 26s |\n\n\nFor each dataset, we provide the benchmarking scripts [here](https://github.com/clementchadebec/benchmark_VAE/tree/main/examples/scripts)\n\n\n## Sharing your models with the HuggingFace Hub ü§ó\nPythae also allows you to share your models on the [HuggingFace Hub](https://huggingface.co/models). To do so you need:\n- a valid HuggingFace account\n- the package `huggingface_hub` installed in your virtual env. If not you can install it with \n```\n$ python -m pip install huggingface_hub\n```\n- to be logged in to your HuggingFace account using\n```\n$ huggingface-cli login\n```\n\n### Uploading a model to the Hub\nAny pythae model can be easily uploaded using the method `push_to_hf_hub`\n```python\n>>> my_vae_model.push_to_hf_hub(hf_hub_path=\"your_hf_username/your_hf_hub_repo\")\n```\n**Note:** If `your_hf_hub_repo` already exists and is not empty, files will be overridden. In case, \nthe repo `your_hf_hub_repo` does not exist, a folder having the same name will be created.\n\n### Downloading models from the Hub\nEquivalently, you can download or reload any Pythae's model directly from the Hub using the method `load_from_hf_hub`\n```python\n>>> from pythae.models import AutoModel\n>>> my_downloaded_vae = AutoModel.load_from_hf_hub(hf_hub_path=\"path_to_hf_repo\")\n```\n\n## Monitoring your experiments with `wandb` üß™\nPythae also integrates the experiment tracking tool [wandb](https://wandb.ai/) allowing users to store their configs, monitor their trainings and compare runs through a graphic interface. To be able use this feature you will need:\n- a valid wandb account\n- the package `wandb` installed in your virtual env. If not you can install it with \n```\n$ pip install wandb\n```\n- to be logged in to your wandb account using\n```\n$ wandb login\n```\n\n### Creating a `WandbCallback`\nLaunching an experiment monitoring with `wandb` in pythae is pretty simple. The only thing a user needs to do is create a `WandbCallback` instance...\n\n```python\n>>> # Create you callback\n>>> from pythae.trainers.training_callbacks import WandbCallback\n>>> callbacks = [] # the TrainingPipeline expects a list of callbacks\n>>> wandb_cb = WandbCallback() # Build the callback \n>>> # SetUp the callback \n>>> wandb_cb.setup(\n...\ttraining_config=your_training_config, # training config\n...\tmodel_config=your_model_config, # model config\n...\tproject_name=\"your_wandb_project\", # specify your wandb project\n...\tentity_name=\"your_wandb_entity\", # specify your wandb entity\n... )\n>>> callbacks.append(wandb_cb) # Add it to the callbacks list\n```\n...and then pass it to the `TrainingPipeline`.\n```python\n>>> pipeline = TrainingPipeline(\n...\ttraining_config=config,\n...\tmodel=model\n... )\n>>> pipeline(\n...\ttrain_data=train_dataset,\n...\teval_data=eval_dataset,\n...\tcallbacks=callbacks # pass the callbacks to the TrainingPipeline and you are done!\n... )\n>>> # You can log to https://wandb.ai/your_wandb_entity/your_wandb_project to monitor your training\n```\nSee the detailed tutorial \n\n## Monitoring your experiments with `mlflow` üß™\nPythae also integrates the experiment tracking tool [mlflow](https://mlflow.org/) allowing users to store their configs, monitor their trainings and compare runs through a graphic interface. To be able use this feature you will need:\n- the package `mlfow` installed in your virtual env. If not you can install it with \n```\n$ pip install mlflow\n```\n\n### Creating a `MLFlowCallback`\nLaunching an experiment monitoring with `mlfow` in pythae is pretty simple. The only thing a user needs to do is create a `MLFlowCallback` instance...\n\n```python\n>>> # Create you callback\n>>> from pythae.trainers.training_callbacks import MLFlowCallback\n>>> callbacks = [] # the TrainingPipeline expects a list of callbacks\n>>> mlflow_cb = MLFlowCallback() # Build the callback \n>>> # SetUp the callback \n>>> mlflow_cb.setup(\n...\ttraining_config=your_training_config, # training config\n...\tmodel_config=your_model_config, # model config\n...\trun_name=\"mlflow_cb_example\", # specify your mlflow run\n... )\n>>> callbacks.append(mlflow_cb) # Add it to the callbacks list\n```\n...and then pass it to the `TrainingPipeline`.\n```python\n>>> pipeline = TrainingPipeline(\n...\ttraining_config=config,\n...\tmodel=model\n... )\n>>> pipeline(\n...\ttrain_data=train_dataset,\n...\teval_data=eval_dataset,\n...\tcallbacks=callbacks # pass the callbacks to the TrainingPipeline and you are done!\n... )\n```\nyou can visualize your metric by running the following in the directory where the `./mlruns`\n```bash\n$ mlflow ui \n```\nSee the detailed tutorial \n\n## Monitoring your experiments with `comet_ml` üß™\nPythae also integrates the experiment tracking tool [comet_ml](https://www.comet.com/signup?utm_source=pythae&utm_medium=partner&utm_campaign=AMS_US_EN_SNUP_Pythae_Comet_Integration) allowing users to store their configs, monitor their trainings and compare runs through a graphic interface. To be able use this feature you will need:\n- the package `comet_ml` installed in your virtual env. If not you can install it with \n```\n$ pip install comet_ml\n```\n\n### Creating a `CometCallback`\nLaunching an experiment monitoring with `comet_ml` in pythae is pretty simple. The only thing a user needs to do is create a `CometCallback` instance...\n\n```python\n>>> # Create you callback\n>>> from pythae.trainers.training_callbacks import CometCallback\n>>> callbacks = [] # the TrainingPipeline expects a list of callbacks\n>>> comet_cb = CometCallback() # Build the callback \n>>> # SetUp the callback \n>>> comet_cb.setup(\n...\ttraining_config=training_config, # training config\n...\tmodel_config=model_config, # model config\n...\tapi_key=\"your_comet_api_key\", # specify your comet api-key\n...\tproject_name=\"your_comet_project\", # specify your wandb project\n...\t#offline_run=True, # run in offline mode\n...\t#offline_directory='my_offline_runs' # set the directory to store the offline runs\n... )\n>>> callbacks.append(comet_cb) # Add it to the callbacks list\n```\n...and then pass it to the `TrainingPipeline`.\n```python\n>>> pipeline = TrainingPipeline(\n...\ttraining_config=config,\n...\tmodel=model\n... )\n>>> pipeline(\n...\ttrain_data=train_dataset,\n...\teval_data=eval_dataset,\n...\tcallbacks=callbacks # pass the callbacks to the TrainingPipeline and you are done!\n... )\n>>> # You can log to https://comet.com/your_comet_username/your_comet_project to monitor your training\n```\nSee the detailed tutorial \n\n\n## Getting your hands on the code \n\nTo help you to understand the way pythae works and how you can train your models with this library we also\nprovide tutorials:\n\n- [making_your_own_autoencoder.ipynb](https://github.com/clementchadebec/benchmark_VAE/tree/main/examples/notebooks) shows you how to pass your own networks to the models implemented in pythae [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/clementchadebec/benchmark_VAE/blob/main/examples/notebooks/making_your_own_autoencoder.ipynb)\n\n- [custom_dataset.ipynb](https://github.com/clementchadebec/benchmark_VAE/tree/main/examples/notebooks) shows you how to  use custom datasets with any of the models implemented in pythae [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/clementchadebec/benchmark_VAE/blob/main/examples/notebooks/custom_dataset.ipynb)\n\n- [hf_hub_models_sharing.ipynb](https://github.com/clementchadebec/benchmark_VAE/tree/main/examples/notebooks) shows you how to upload and download models for the HuggingFace Hub [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/clementchadebec/benchmark_VAE/blob/main/examples/notebooks/hf_hub_models_sharing.ipynb)\n\n- [wandb_experiment_monitoring.ipynb](https://github.com/clementchadebec/benchmark_VAE/tree/main/examples/notebooks) shows you how to monitor you experiments using `wandb` [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/clementchadebec/benchmark_VAE/blob/main/examples/notebooks/wandb_experiment_monitoring.ipynb)\n\n- [mlflow_experiment_monitoring.ipynb](https://github.com/clementchadebec/benchmark_VAE/tree/main/examples/notebooks) shows you how to monitor you experiments using `mlflow` [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/clementchadebec/benchmark_VAE/blob/main/examples/notebooks/mlflow_experiment_monitoring.ipynb)\n\n- [comet_experiment_monitoring.ipynb](https://github.com/clementchadebec/benchmark_VAE/tree/main/examples/notebooks) shows you how to monitor you experiments using `comet_ml` [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/clementchadebec/benchmark_VAE/blob/main/examples/notebooks/comet_experiment_monitoring.ipynb)\n\n- [models_training](https://github.com/clementchadebec/benchmark_VAE/tree/main/examples/notebooks/models_training) folder provides notebooks showing how to train each implemented model and how to sample from it using `pythae.samplers`.\n\n- [scripts](https://github.com/clementchadebec/benchmark_VAE/tree/main/examples/scripts) folder provides in particular an example of a training script to train the models on benchmark data sets (mnist, cifar10, celeba ...)\n\n## Dealing with issues üõ†Ô∏è\n\nIf you are experiencing any issues while running the code or request new features/models to be implemented please [open an issue on github](https://github.com/clementchadebec/benchmark_VAE/issues).\n\n## Contributing üöÄ\n\nYou want to contribute to this library by adding a model, a sampler or simply fix a bug ? That's awesome! Thank you! Please see [CONTRIBUTING.md](https://github.com/clementchadebec/benchmark_VAE/tree/main/CONTRIBUTING.md) to follow the main contributing guidelines.\n\n## Results\n\n### Reconstruction\nFirst let's have a look at the reconstructed samples taken from the evaluation set. \n\n\n|               Models               |                                                                                    MNIST                                                                     |                     CELEBA             \n|:----------------------------------:|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:--------------------------------------------:|\n| Eval data                  | ![Eval](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/eval_reconstruction_mnist.png) | ![AE](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/eval_reconstruction_celeba.png)  \n| AE                  | ![AE](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/ae_reconstruction_mnist.png) | ![AE](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/ae_reconstruction_celeba.png)                                                                            |\n| VAE | ![VAE](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/vae_reconstruction_mnist.png) |  ![VAE](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/vae_reconstruction_celeba.png)\n| Beta-VAE| ![Beta](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/beta_vae_reconstruction_mnist.png) | ![Beta Normal](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/beta_vae_reconstruction_celeba.png)\n| VAE Lin NF| ![VAE_LinNF](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/vae_lin_nf_reconstruction_mnist.png) | ![VAE_IAF Normal](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/vae_lin_nf_reconstruction_celeba.png)\n| VAE IAF| ![VAE_IAF](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/vae_iaf_reconstruction_mnist.png) | ![VAE_IAF Normal](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/vae_iaf_reconstruction_celeba.png)\n| Disentangled  Beta-VAE| ![Disentangled Beta](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/disentangled_beta_vae_reconstruction_mnist.png) | ![Disentangled Beta](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/disentangled_beta_vae_reconstruction_celeba.png)\n| FactorVAE| ![FactorVAE](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/factor_vae_reconstruction_mnist.png) | ![FactorVAE](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/factor_vae_reconstruction_celeba.png)\n| BetaTCVAE| ![BetaTCVAE](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/beta_tc_vae_reconstruction_mnist.png) | ![BetaTCVAE](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/beta_tc_vae_reconstruction_celeba.png)\n| IWAE | ![IWAE](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/iwae_reconstruction_mnist.png) | ![IWAE](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/iwae_reconstruction_celeba.png)\n| MSSSIM_VAE | ![MSSSIM VAE](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/msssim_vae_reconstruction_mnist.png) |  ![MSSSIM VAE](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/msssim_vae_reconstruction_celeba.png)\n| WAE| ![WAE](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/wae_reconstruction_mnist.png) | ![WAE](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/wae_reconstruction_celeba.png)\n| INFO VAE| ![INFO](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/infovae_reconstruction_mnist.png) | ![INFO](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/infovae_reconstruction_celeba.png)\n| VAMP | ![VAMP](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/vamp_reconstruction_mnist.png) | ![VAMP](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/vamp_reconstruction_celeba.png) |\n| SVAE | ![SVAE](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/svae_reconstruction_mnist.png) | ![SVAE](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/svae_reconstruction_celeba.png) |\n| Adversarial_AE          | ![AAE](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/aae_reconstruction_mnist.png) | ![AAE](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/aae_reconstruction_celeba.png) |\n| VAE_GAN          | ![VAEGAN](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/vaegan_reconstruction_mnist.png) | ![VAEGAN](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/vaegan_reconstruction_celeba.png) |\n| VQVAE          | ![VQVAE](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/vqvae_reconstruction_mnist.png) | ![VQVAE](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/vqvae_reconstruction_celeba.png) |\n| HVAE             | ![HVAE](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/hvae_reconstruction_mnist.png) | ![HVAE](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/hvae_reconstruction_celeba.png)\n| RAE_L2 | ![RAE L2](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/rae_l2_reconstruction_mnist.png)  |  ![RAE L2](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/rae_l2_reconstruction_celeba.png)\n| RAE_GP | ![RAE GMM](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/rae_gp_reconstruction_mnist.png)  |  ![RAE GMM](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/rae_gp_reconstruction_celeba.png)\n| Riemannian Hamiltonian VAE (RHVAE)| ![RHVAE](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/rhvae_reconstruction_mnist.png) | ![RHVAE RHVAE](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/rhvae_reconstruction_celeba.png)\n\n----------------------------\n### Generation\n\nHere, we show the generated samples using using each model implemented in the library and different samplers.\n\n|               Models               |                                                                                    MNIST                                                                     |                     CELEBA             \n|:----------------------------------:|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:--------------------------------------------:|\n| AE  + GaussianMixtureSampler                  | ![AE GMM](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/ae_gmm_sampling_mnist.png) | ![AE GMM](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/ae_gmm_sampling_celeba.png)                                                                            |\n| VAE  + NormalSampler    | ![VAE Normal](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/vae_normal_sampling_mnist.png) |  ![VAE Normal](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/vae_normal_sampling_celeba.png)\n| VAE  + GaussianMixtureSampler    | ![VAE GMM](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/vae_gmm_sampling_mnist.png) |  ![VAE GMM](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/vae_gmm_sampling_celeba.png)\n| VAE  + TwoStageVAESampler    | ![VAE 2 stage](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/vae_second_stage_sampling_mnist.png) |  ![VAE 2 stage](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/vae_second_stage_sampling_celeba.png)\n| VAE  + MAFSampler    | ![VAE MAF](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/vae_maf_sampling_mnist.png) |  ![VAE MAF](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/vae_maf_sampling_celeba.png)\n| Beta-VAE + NormalSampler | ![Beta Normal](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/beta_vae_normal_sampling_mnist.png) | ![Beta Normal](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/beta_vae_normal_sampling_celeba.png)\n| VAE Lin NF + NormalSampler | ![VAE_LinNF Normal](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/vae_lin_nf_normal_sampling_mnist.png) | ![VAE_LinNF Normal](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/vae_lin_nf_normal_sampling_celeba.png)\n| VAE IAF + NormalSampler | ![VAE_IAF Normal](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/vae_iaf_normal_sampling_mnist.png) | ![VAE IAF Normal](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/vae_iaf_normal_sampling_celeba.png)\n| Disentangled Beta-VAE + NormalSampler | ![Disentangled Beta Normal](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/disentangled_beta_vae_normal_sampling_mnist.png) | ![Disentangled Beta Normal](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/disentangled_beta_vae_normal_sampling_celeba.png)\n| FactorVAE + NormalSampler | ![FactorVAE Normal](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/factor_vae_normal_sampling_mnist.png) | ![FactorVAE Normal](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/factor_vae_normal_sampling_celeba.png)\n| BetaTCVAE + NormalSampler | ![BetaTCVAE Normal](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/beta_tc_vae_normal_sampling_mnist.png) | ![BetaTCVAE Normal](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/beta_tc_vae_normal_sampling_celeba.png)\n| IWAE +  Normal sampler | ![IWAE Normal](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/iwae_normal_sampling_mnist.png) | ![IWAE Normal](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/iwae_normal_sampling_celeba.png)\n| MSSSIM_VAE  + NormalSampler    | ![MSSSIM_VAE Normal](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/msssim_vae_normal_sampling_mnist.png) |  ![MSSSIM_VAE Normal](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/msssim_vae_normal_sampling_celeba.png)\n| WAE + NormalSampler| ![WAE Normal](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/wae_normal_sampling_mnist.png) | ![WAE Normal](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/wae_normal_sampling_celeba.png)\n| INFO VAE + NormalSampler| ![INFO Normal](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/infovae_normal_sampling_mnist.png) | ![INFO Normal](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/infovae_normal_sampling_celeba.png)\n| SVAE + HypershereUniformSampler          | ![SVAE Sphere](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/svae_hypersphere_uniform_sampling_mnist.png) | ![SVAE Sphere](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/svae_hypersphere_uniform_sampling_celeba.png) |\n| VAMP + VAMPSampler          | ![VAMP Vamp](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/vamp_vamp_sampling_mnist.png) | ![VAMP Vamp](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/vamp_vamp_sampling_celeba.png) |\n| Adversarial_AE + NormalSampler          | ![AAE_Normal](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/aae_normal_sampling_mnist.png) | ![AAE_Normal](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/aae_normal_sampling_celeba.png) |\n| VAEGAN + NormalSampler          | ![VAEGAN_Normal](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/vaegan_normal_sampling_mnist.png) | ![VAEGAN_Normal](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/vaegan_normal_sampling_celeba.png) |\n| VQVAE + MAFSampler          | ![VQVAE_MAF](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/vqvae_maf_sampling_mnist.png) | ![VQVAE_MAF](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/vqvae_maf_sampling_celeba.png) |\n| HVAE + NormalSampler             | ![HVAE Normal](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/hvae_normal_sampling_mnist.png) | ![HVAE GMM](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/hvae_normal_sampling_celeba.png)\n| RAE_L2 + GaussianMixtureSampler | ![RAE L2 GMM](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/rae_l2_gmm_sampling_mnist.png)  |  ![RAE L2 GMM](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/rae_l2_gmm_sampling_celeba.png)\n| RAE_GP + GaussianMixtureSampler| ![RAE GMM](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/rae_gp_gmm_sampling_mnist.png)  |  ![RAE GMM](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/rae_gp_gmm_sampling_celeba.png)\n| Riemannian Hamiltonian VAE (RHVAE) + RHVAE Sampler| ![RHVAE RHVAE](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/rhvae_rhvae_sampling_mnist.png) | ![RHVAE RHVAE](https://github.com/clementchadebec/benchmark_VAE/blob/main/examples/showcases/rhvae_rhvae_sampling_celeba.png)\n\n\n# Citation\n\nIf you find this work useful or use it in your research, please consider citing us\n\n```bibtex\n@article{chadebec2022pythae,\n\ttitle={Pythae: Unifying Generative Autoencoders in Python -- A Benchmarking Use Case},\n  \tauthor={Chadebec, Cl√©ment and Vincent, Louis J. and Allassonni√®re, St√©phanie},\n  \tjournal={arXiv preprint arXiv:2206.08309},\n\turl = {https://arxiv.org/abs/2206.08309},\n  \tyear = {2022}\n}\n```\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/clementchadebec/benchmark_VAE",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "pythae",
    "package_url": "https://pypi.org/project/pythae/",
    "platform": null,
    "project_url": "https://pypi.org/project/pythae/",
    "project_urls": {
      "Bug Tracker": "https://github.com/clementchadebec/benchmark_VAE/issues",
      "Homepage": "https://github.com/clementchadebec/benchmark_VAE"
    },
    "release_url": "https://pypi.org/project/pythae/0.1.1/",
    "requires_dist": [
      "cloudpickle (>=2.1.0)",
      "imageio",
      "numpy (>=1.19)",
      "pydantic (>=1.8.2)",
      "scikit-learn",
      "scipy (>=1.7.1)",
      "torch (>=1.10.1)",
      "tqdm",
      "typing-extensions",
      "dataclasses (>=0.6)",
      "pickle5 ; python_version == \"3.7.*\""
    ],
    "requires_python": ">=3.7",
    "summary": "Unifying Generative Autoencoders in Python",
    "version": "0.1.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16995418,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "87d8b02959a8d415d7ac987fa402100cfc8ee6550c7cd14fbafb5e5765c39a9d",
          "md5": "9ace5dad0e3dc8490b1ef9f6a242ef74",
          "sha256": "87eea05d73bd5a6df3030c23bba074c8d103e914cfab53effd6ee9bd03bc90c0"
        },
        "downloads": -1,
        "filename": "pythae-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "9ace5dad0e3dc8490b1ef9f6a242ef74",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 197853,
        "upload_time": "2022-06-14T10:19:30",
        "upload_time_iso_8601": "2022-06-14T10:19:30.022704Z",
        "url": "https://files.pythonhosted.org/packages/87/d8/b02959a8d415d7ac987fa402100cfc8ee6550c7cd14fbafb5e5765c39a9d/pythae-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "16a1bb49c05d2ac8d71986a6a4df69393606e389e6d226beb570bc6558ba5c9a",
          "md5": "3fbcdc75c9e651827dbf5e683762a0ad",
          "sha256": "d645d01025a35b22fbb19e42a0a73946b8c1156b01607f49e7939b27ed77140e"
        },
        "downloads": -1,
        "filename": "pythae-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "3fbcdc75c9e651827dbf5e683762a0ad",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 108322,
        "upload_time": "2022-06-14T10:19:32",
        "upload_time_iso_8601": "2022-06-14T10:19:32.908817Z",
        "url": "https://files.pythonhosted.org/packages/16/a1/bb49c05d2ac8d71986a6a4df69393606e389e6d226beb570bc6558ba5c9a/pythae-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7eeb8435ee98baf7e20b2a4ebd08c3e50eb1c573ac4a19b1fe71838b56b3b05f",
          "md5": "df46afd9a8c24797fad387646d799ed7",
          "sha256": "6d04d2213ac3da6f848ad3e3afeaa972a7eb4b0700de2010bbf669e1df79e66d"
        },
        "downloads": -1,
        "filename": "pythae-0.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "df46afd9a8c24797fad387646d799ed7",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 200468,
        "upload_time": "2022-07-04T17:52:02",
        "upload_time_iso_8601": "2022-07-04T17:52:02.526150Z",
        "url": "https://files.pythonhosted.org/packages/7e/eb/8435ee98baf7e20b2a4ebd08c3e50eb1c573ac4a19b1fe71838b56b3b05f/pythae-0.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "70a8b2ad128d83a9dd7508eb2683ce48c0c0d87241dfce8ea05120e70ad97761",
          "md5": "cf30f3b1cf1f091915f2ac6c8481e602",
          "sha256": "018b5dd9a232c0186fe71ebbaa7b023dfa6a1df817a004996eeb27b8b59f748b"
        },
        "downloads": -1,
        "filename": "pythae-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "cf30f3b1cf1f091915f2ac6c8481e602",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 118073,
        "upload_time": "2022-07-04T17:52:07",
        "upload_time_iso_8601": "2022-07-04T17:52:07.239929Z",
        "url": "https://files.pythonhosted.org/packages/70/a8/b2ad128d83a9dd7508eb2683ce48c0c0d87241dfce8ea05120e70ad97761/pythae-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "85dc5b63735d4b1d0d9d24ff6fb8a52ec902ed145663d561719ccf679906d428",
          "md5": "c34c32ce85596ce993242256f83c2949",
          "sha256": "a6a16cccfa17c20a5e17d684709784dddade68cec1cedf4b2fd3dc0e2f9b5d49"
        },
        "downloads": -1,
        "filename": "pythae-0.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "c34c32ce85596ce993242256f83c2949",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 200470,
        "upload_time": "2022-07-05T08:11:05",
        "upload_time_iso_8601": "2022-07-05T08:11:05.204505Z",
        "url": "https://files.pythonhosted.org/packages/85/dc/5b63735d4b1d0d9d24ff6fb8a52ec902ed145663d561719ccf679906d428/pythae-0.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "10976061d14f7fd3ae1f3e657d19da27b8a518b18927d31eca26eb9f103604fa",
          "md5": "5db0dc7668bd96c670b0dbe9edbff8bd",
          "sha256": "789f764a22392731481bcdc069d88f5b1db9a224650e3ab6b9d78082bba9908d"
        },
        "downloads": -1,
        "filename": "pythae-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "5db0dc7668bd96c670b0dbe9edbff8bd",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 118932,
        "upload_time": "2022-07-05T08:11:13",
        "upload_time_iso_8601": "2022-07-05T08:11:13.082458Z",
        "url": "https://files.pythonhosted.org/packages/10/97/6061d14f7fd3ae1f3e657d19da27b8a518b18927d31eca26eb9f103604fa/pythae-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2c2fd1e6a3ea2c130c8af8552bbb3696cc08050eb7ebc9a2ef52dd4aad407fa4",
          "md5": "1f68d847dd640cf4910d0e9c6e6bfc08",
          "sha256": "0595d823064522e296c9d9e0653a18b9f0e625c4aa3f520fb856b8300b9e1897"
        },
        "downloads": -1,
        "filename": "pythae-0.0.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "1f68d847dd640cf4910d0e9c6e6bfc08",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 200535,
        "upload_time": "2022-07-07T16:49:33",
        "upload_time_iso_8601": "2022-07-07T16:49:33.127238Z",
        "url": "https://files.pythonhosted.org/packages/2c/2f/d1e6a3ea2c130c8af8552bbb3696cc08050eb7ebc9a2ef52dd4aad407fa4/pythae-0.0.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b45cb84bde2089dcc74ef7c0fe003f7fff3c9ba0c002369069e11fb7ec674da0",
          "md5": "a3e42a714b09b899b17a43e9959cd686",
          "sha256": "43c449300a50d23f5e3981079baf08e1f1ca6ada5f5db05dee1995054a4d1261"
        },
        "downloads": -1,
        "filename": "pythae-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "a3e42a714b09b899b17a43e9959cd686",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 119029,
        "upload_time": "2022-07-07T16:49:38",
        "upload_time_iso_8601": "2022-07-07T16:49:38.199266Z",
        "url": "https://files.pythonhosted.org/packages/b4/5c/b84bde2089dcc74ef7c0fe003f7fff3c9ba0c002369069e11fb7ec674da0/pythae-0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "959f7d713fb9449e35ede1cb5d3c6f6d866a41e125a6ea688eef35c6e244e053",
          "md5": "03aaadea534e957aa7b35d7226c754ca",
          "sha256": "a1000bcdb5daab36e69c6e5914b55d95ca2c9033f47abcdaea73d7c59ee6ef41"
        },
        "downloads": -1,
        "filename": "pythae-0.0.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "03aaadea534e957aa7b35d7226c754ca",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 200710,
        "upload_time": "2022-07-07T17:59:12",
        "upload_time_iso_8601": "2022-07-07T17:59:12.617488Z",
        "url": "https://files.pythonhosted.org/packages/95/9f/7d713fb9449e35ede1cb5d3c6f6d866a41e125a6ea688eef35c6e244e053/pythae-0.0.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c293b81ae07c8f6f551ef6be3faa2b19aa73c17e235699e774b635a263dcb40d",
          "md5": "7c8bdf4f8c0ce5eeb009e3858a2f045f",
          "sha256": "8cb7fa60899015a63d1b5af66d5c68e35ad9842b78ec80ddf4cb58bb9fa11c78"
        },
        "downloads": -1,
        "filename": "pythae-0.0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "7c8bdf4f8c0ce5eeb009e3858a2f045f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 119506,
        "upload_time": "2022-07-07T17:59:16",
        "upload_time_iso_8601": "2022-07-07T17:59:16.032881Z",
        "url": "https://files.pythonhosted.org/packages/c2/93/b81ae07c8f6f551ef6be3faa2b19aa73c17e235699e774b635a263dcb40d/pythae-0.0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "119c4eee28b93b4b7370b2fab13b116e9bd2a6ec8ed1685f944abd983b972e39",
          "md5": "16b7068afed6048d6884a6845b8febe2",
          "sha256": "7de5447e040bfe6a2899d00d235b44c74735f1324d9b87ea174b1e581a3c74ab"
        },
        "downloads": -1,
        "filename": "pythae-0.0.6-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "16b7068afed6048d6884a6845b8febe2",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 201344,
        "upload_time": "2022-07-22T09:06:18",
        "upload_time_iso_8601": "2022-07-22T09:06:18.629646Z",
        "url": "https://files.pythonhosted.org/packages/11/9c/4eee28b93b4b7370b2fab13b116e9bd2a6ec8ed1685f944abd983b972e39/pythae-0.0.6-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "58b45d6035c1953ae35b1aa1c91a0d4ef4da4edcd36d7f6cd7b90b674a962351",
          "md5": "3bb32b6b5a7d51d1276c50a5cf46ce37",
          "sha256": "3695f53953bbdd148848b5d507e34a8db0282c96cef591f79e6e44385a6ba3cb"
        },
        "downloads": -1,
        "filename": "pythae-0.0.6.tar.gz",
        "has_sig": false,
        "md5_digest": "3bb32b6b5a7d51d1276c50a5cf46ce37",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 119758,
        "upload_time": "2022-07-22T09:06:21",
        "upload_time_iso_8601": "2022-07-22T09:06:21.186443Z",
        "url": "https://files.pythonhosted.org/packages/58/b4/5d6035c1953ae35b1aa1c91a0d4ef4da4edcd36d7f6cd7b90b674a962351/pythae-0.0.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "71dac39fda6479755d632b230ad7300dabc3fdf67d9ee9bcb75fff5bc4938574",
          "md5": "a52ba72e27c9cd43f71949bdabab6661",
          "sha256": "e65f61594cac4315fdb57c2ed0bef1905c4bb180372695d5ccdd5e9215ee9011"
        },
        "downloads": -1,
        "filename": "pythae-0.0.7-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "a52ba72e27c9cd43f71949bdabab6661",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 214800,
        "upload_time": "2022-09-03T09:24:46",
        "upload_time_iso_8601": "2022-09-03T09:24:46.661804Z",
        "url": "https://files.pythonhosted.org/packages/71/da/c39fda6479755d632b230ad7300dabc3fdf67d9ee9bcb75fff5bc4938574/pythae-0.0.7-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "17d2bbb42a96cb8c7f6fc01d0c61a5c622528d0fa853a6f8343d29d93d1a0e9c",
          "md5": "8f0134c1bbfedf2a3d77f78f478cfa47",
          "sha256": "effa5ef3caa60d21b464ef2d37fcf67e3e44ddfa5d7e2d52f6a33eb17074dd9d"
        },
        "downloads": -1,
        "filename": "pythae-0.0.7.tar.gz",
        "has_sig": false,
        "md5_digest": "8f0134c1bbfedf2a3d77f78f478cfa47",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 132738,
        "upload_time": "2022-09-03T09:24:49",
        "upload_time_iso_8601": "2022-09-03T09:24:49.872349Z",
        "url": "https://files.pythonhosted.org/packages/17/d2/bbb42a96cb8c7f6fc01d0c61a5c622528d0fa853a6f8343d29d93d1a0e9c/pythae-0.0.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "58f5b1a13ca1c3fa91539df98bb2576335a43d3dfe54db709596be1902eeaed7",
          "md5": "983f7653f531ec4f33f4904439b18e06",
          "sha256": "de3a52a9634570e91a56b7b90d00f5b0afc1e7a4c6c211df6472622e7f6acb52"
        },
        "downloads": -1,
        "filename": "pythae-0.0.8-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "983f7653f531ec4f33f4904439b18e06",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 224751,
        "upload_time": "2022-09-07T17:04:12",
        "upload_time_iso_8601": "2022-09-07T17:04:12.560563Z",
        "url": "https://files.pythonhosted.org/packages/58/f5/b1a13ca1c3fa91539df98bb2576335a43d3dfe54db709596be1902eeaed7/pythae-0.0.8-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "63deb362f13898775adfaf9b91c3c3d7a7c5ef3af8bb6c650c97735dc501ea04",
          "md5": "d3408f56f3bc43a747786dbfb60c8f07",
          "sha256": "0f15f6b50223ca6785831ab41d3428f73c46c2c54b037798dae495b5b986e6c6"
        },
        "downloads": -1,
        "filename": "pythae-0.0.8.tar.gz",
        "has_sig": false,
        "md5_digest": "d3408f56f3bc43a747786dbfb60c8f07",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 137048,
        "upload_time": "2022-09-07T17:04:14",
        "upload_time_iso_8601": "2022-09-07T17:04:14.887656Z",
        "url": "https://files.pythonhosted.org/packages/63/de/b362f13898775adfaf9b91c3c3d7a7c5ef3af8bb6c650c97735dc501ea04/pythae-0.0.8.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.9": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1d210a158b6a684cbc06dba958e19cf94553e898faec7f4d71a3d4123bfb1a49",
          "md5": "84b805f4f7a3179071657ec5c005d8e2",
          "sha256": "ef003c265957e7a4bd2c6f659f01498d5042912f9e0c5059d721f70f13918642"
        },
        "downloads": -1,
        "filename": "pythae-0.0.9-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "84b805f4f7a3179071657ec5c005d8e2",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 225998,
        "upload_time": "2022-10-19T10:28:12",
        "upload_time_iso_8601": "2022-10-19T10:28:12.605230Z",
        "url": "https://files.pythonhosted.org/packages/1d/21/0a158b6a684cbc06dba958e19cf94553e898faec7f4d71a3d4123bfb1a49/pythae-0.0.9-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8a431e364d8b9a57a8fbc3e5f96d93c2c97dd36fd21678e372646ac975f9727d",
          "md5": "a5b16d0c2e476186cfec2f5c307f5904",
          "sha256": "2be87add81efaff7f7b6ff9660565a04c06d5919b77ecb6ae82ceedba10bbdf5"
        },
        "downloads": -1,
        "filename": "pythae-0.0.9.tar.gz",
        "has_sig": false,
        "md5_digest": "a5b16d0c2e476186cfec2f5c307f5904",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 138747,
        "upload_time": "2022-10-19T10:28:16",
        "upload_time_iso_8601": "2022-10-19T10:28:16.383175Z",
        "url": "https://files.pythonhosted.org/packages/8a/43/1e364d8b9a57a8fbc3e5f96d93c2c97dd36fd21678e372646ac975f9727d/pythae-0.0.9.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5ad5e48dfad85d1a31e970124a78a76e7380d57164037e66d10d952f504dd369",
          "md5": "271627e3eb5b0e6854d98df7f3ad127d",
          "sha256": "8c058b88d7212ac11994b32b5b01e7f28677040f6c40569e7f5bd073a931f7ce"
        },
        "downloads": -1,
        "filename": "pythae-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "271627e3eb5b0e6854d98df7f3ad127d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 233413,
        "upload_time": "2023-02-06T17:05:58",
        "upload_time_iso_8601": "2023-02-06T17:05:58.904921Z",
        "url": "https://files.pythonhosted.org/packages/5a/d5/e48dfad85d1a31e970124a78a76e7380d57164037e66d10d952f504dd369/pythae-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "40cc3ff4a6fd4d748883860b7bd9b88a0b2d1b01b83275cbacacd871fcf5cbb1",
          "md5": "9ed2eb285e11bfc5dacfca7652d9a88f",
          "sha256": "786c6375763d5dd55089f8e08b9b45ce5e96cafbf286edb97f2603a77b0616ef"
        },
        "downloads": -1,
        "filename": "pythae-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "9ed2eb285e11bfc5dacfca7652d9a88f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 154819,
        "upload_time": "2023-02-06T17:06:01",
        "upload_time_iso_8601": "2023-02-06T17:06:01.121776Z",
        "url": "https://files.pythonhosted.org/packages/40/cc/3ff4a6fd4d748883860b7bd9b88a0b2d1b01b83275cbacacd871fcf5cbb1/pythae-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "aaf1495ab8818b504ddff06a565b9b2c45540e1cdb8ad5f767c7e22fe13766de",
          "md5": "32519c618a9c35d8b72dda8718a80de0",
          "sha256": "5fc7c710547e148941f07f6dcd046ab644f1026a1d615538104850d6d38240bb"
        },
        "downloads": -1,
        "filename": "pythae-0.1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "32519c618a9c35d8b72dda8718a80de0",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 233687,
        "upload_time": "2023-02-23T16:09:20",
        "upload_time_iso_8601": "2023-02-23T16:09:20.593540Z",
        "url": "https://files.pythonhosted.org/packages/aa/f1/495ab8818b504ddff06a565b9b2c45540e1cdb8ad5f767c7e22fe13766de/pythae-0.1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "20f17cef110e603afdde34be3c0e01b6bc41283849459709d4581b1f6f84bdd1",
          "md5": "04a0ccc82585b505e6805783abb47466",
          "sha256": "585c88e775faea1b4e16c0bc5a4b96a3c93b01fd17b8ba3443eb70b78b568040"
        },
        "downloads": -1,
        "filename": "pythae-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "04a0ccc82585b505e6805783abb47466",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 156024,
        "upload_time": "2023-02-23T16:09:23",
        "upload_time_iso_8601": "2023-02-23T16:09:23.547463Z",
        "url": "https://files.pythonhosted.org/packages/20/f1/7cef110e603afdde34be3c0e01b6bc41283849459709d4581b1f6f84bdd1/pythae-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "aaf1495ab8818b504ddff06a565b9b2c45540e1cdb8ad5f767c7e22fe13766de",
        "md5": "32519c618a9c35d8b72dda8718a80de0",
        "sha256": "5fc7c710547e148941f07f6dcd046ab644f1026a1d615538104850d6d38240bb"
      },
      "downloads": -1,
      "filename": "pythae-0.1.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "32519c618a9c35d8b72dda8718a80de0",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 233687,
      "upload_time": "2023-02-23T16:09:20",
      "upload_time_iso_8601": "2023-02-23T16:09:20.593540Z",
      "url": "https://files.pythonhosted.org/packages/aa/f1/495ab8818b504ddff06a565b9b2c45540e1cdb8ad5f767c7e22fe13766de/pythae-0.1.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "20f17cef110e603afdde34be3c0e01b6bc41283849459709d4581b1f6f84bdd1",
        "md5": "04a0ccc82585b505e6805783abb47466",
        "sha256": "585c88e775faea1b4e16c0bc5a4b96a3c93b01fd17b8ba3443eb70b78b568040"
      },
      "downloads": -1,
      "filename": "pythae-0.1.1.tar.gz",
      "has_sig": false,
      "md5_digest": "04a0ccc82585b505e6805783abb47466",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 156024,
      "upload_time": "2023-02-23T16:09:23",
      "upload_time_iso_8601": "2023-02-23T16:09:23.547463Z",
      "url": "https://files.pythonhosted.org/packages/20/f1/7cef110e603afdde34be3c0e01b6bc41283849459709d4581b1f6f84bdd1/pythae-0.1.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}