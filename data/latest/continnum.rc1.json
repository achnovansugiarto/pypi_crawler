{
  "info": {
    "author": "Arthur Douillard",
    "author_email": "ar.douillard@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Continual Loader (CLLoader)\n\n[![PyPI version](https://badge.fury.io/py/clloader.svg)](https://badge.fury.io/py/clloader) [![Build Status](https://travis-ci.com/arthurdouillard/continual_loader.svg?branch=master)](https://travis-ci.com/arthurdouillard/continual_loader)\n\n## A library for PyTorch's loading of datasets in the field of Continual Learning\n\nAka Continual Learning, Lifelong-Learning, Incremental Learning, etc.\n\n\n### Example:\n\nInstall from and PyPi:\n```bash\npip3 install clloader\n```\n\nAnd run!\n```python\nfrom torch.utils.data import DataLoader\n\nfrom clloader import CLLoader\nfrom clloader.datasets import MNIST\n\nclloader = CLLoader(\n    MNIST(\"my/data/path\", download=True),\n    increment=1,\n    initial_increment=5\n)\n\nprint(f\"Number of classes: {clloader.nb_classes}.\")\nprint(f\"Number of tasks: {clloader.nb_tasks}.\")\n\nfor task_id, (train_dataset, test_dataset) in enumerate(clloader):\n    train_loader = DataLoader(train_dataset)\n    test_loader = DataLoader(test_dataset)\n\n    # Do your cool stuff here\n```\n\n### Supported Scenarios\n\n|Name | Acronym | Supported |\n|:----|:---|:---:|\n| **New Instances** | NI | :x: |\n| **New Classes** | NC | :white_check_mark: |\n| **New Instances & Classes** | NIC | :x: |\n\n### Supported Datasets:\n\nNote that the task sizes are fully customizable.\n\n|Name | Nb classes | Image Size | Automatic Download |\n|:----|:---:|:----:|:---:|\n| **MNIST** | 10 | 28x28x1 | :white_check_mark: |\n| **Fashion MNIST** | 10 | 28x28x1 | :white_check_mark: |\n| **KMNIST** | 10 | 28x28x1 | :white_check_mark: |\n| **EMNIST** | 10 | 28x28x1 | :white_check_mark: |\n| **QMNIST** | 10 | 28x28x1 | :white_check_mark: |\n| **MNIST Fellowship** | 30 | 28x28x1 | :white_check_mark: |\n| **CIFAR10** | 10 | 32x32x3 | :white_check_mark: |\n| **CIFAR100** | 100 | 32x32x3 | :white_check_mark: |\n| **CIFAR Fellowship** | 110 | 32x32x3 | :white_check_mark: |\n| **ImageNet100** | 100 | 224x224x3 | :x: |\n| **ImageNet1000** | 1000 | 224x224x3 | :x: |\n| **Permuted MNIST** | 10 | 28x28x1 | :white_check_mark: |\n| **Rotated MNIST** | 10 | 28x28x1 | :white_check_mark: |\n\nFurthermore some \"Meta\"-datasets are available:\n\n**InMemoryDataset**, for in-memory numpy array:\n```python\nx_train, y_train = gen_numpy_array()\nx_test, y_test = gen_numpy_array()\n\nclloader = CLLoader(\n    InMemoryDataset(x_train, y_train, x_test, y_test),\n    increment=10,\n)\n```\n\n**PyTorchDataset**,for any dataset defined in torchvision:\n```python\nclloader = CLLoader(\n    PyTorchDataset(\"/my/data/path\", dataset_type=torchvision.datasets.CIFAR10),\n    increment=10,\n)\n```\n\n**ImageFolderDataset**, for datasets having a tree-like structure, with one folder per class:\n```python\nclloader = CLLoader(\n    ImageFolderDataset(\"/my/train/folder\", \"/my/test/folder\"),\n    increment=10,\n)\n```\n\n**Fellowship**, to combine several continual datasets.:\n```python\nclloader = CLLoader(\n    Fellowship(\"/my/data/path\", dataset_list=[CIFAR10, CIFAR100]),\n    increment=10,\n)\n```\n\nSome datasets cannot provide an automatic download of the data for miscealleneous reasons. For example for ImageNet, you'll need to download the data from the [official page](http://www.image-net.org/challenges/LSVRC/2012/downloads). Then load it likewise:\n```python\nclloader = CLLoader(\n    ImageNet1000(\"/my/train/folder\", \"/my/test/folder\"),\n    increment=10,\n)\n```\n\nSome papers use a subset, called ImageNet100 or ImageNetSubset. You'll need to get the subset ids. It's either a file in the following format:\n```\nmy/path/to/image0.JPEG target0\nmy/path/to/image1.JPEG target1\n```\nOr a list of tuple `[(\"my/path/to/image0.JPEG\", target0), ...]`. Then loading the continual loader is very simple:\n```python\nclloader = CLLoader(\n    ImageNet100(\n        \"/my/train/folder\",\n        \"/my/test/folder\",\n        train_subset=... # My subset ids\n        test_subset=... # My subset ids\n    ),\n    increment=10,\n)\n```\n\n### Continual Loader\n\nThe Continual Loader `CLLoader` loads the data and batch it in several tasks. See there some example arguments:\n\n```python\nclloader = CLLoader(\n    my_continual_dataset,\n    increment=10,\n    initial_increment=2,\n    train_transformations=[transforms.RandomHorizontalFlip()],\n    common_transformations=[\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n    ],\n    evaluate_on=\"seen\"\n)\n```\n\nHere the first task is made of 2 classes, then all following tasks of 10 classes. You can have a more finegrained increment by providing a list of ìncrement=[2, 10, 5, 10]`.\n\nThe `train_transformations` is applied only on the training data, while the `common_transformations` on both the training and testing data.\n\nBy default, we evaluate our model after each task on `seen` classes. But you can evalute only on `current` classes, or even on `all` classes.\n\n\n### Sample Images\n\n**MNIST**:\n\n|<img src=\"images/mnist_0.jpg\" width=\"150\">|<img src=\"images/mnist_1.jpg\" width=\"150\">|<img src=\"images/mnist_2.jpg\" width=\"150\">|<img src=\"images/mnist_3.jpg\" width=\"150\">|<img src=\"images/mnist_4.jpg\" width=\"150\">|\n|:-------------------------:|:-------------------------:|:-------------------------:|:-------------------------:|:-------------------------:|\n|Task 0 | Task 1 | Task 2 | Task 3 | Task 4|\n\n**FashionMNIST**:\n\n|<img src=\"images/fashion_mnist_0.jpg\" width=\"150\">|<img src=\"images/fashion_mnist_1.jpg\" width=\"150\">|<img src=\"images/fashion_mnist_2.jpg\" width=\"150\">|<img src=\"images/fashion_mnist_3.jpg\" width=\"150\">|<img src=\"images/fashion_mnist_4.jpg\" width=\"150\">|\n|:-------------------------:|:-------------------------:|:-------------------------:|:-------------------------:|:-------------------------:|\n|Task 0 | Task 1 | Task 2 | Task 3 | Task 4|\n\n**CIFAR10**:\n\n|<img src=\"images/cifar10_0.jpg\" width=\"150\">|<img src=\"images/cifar10_1.jpg\" width=\"150\">|<img src=\"images/cifar10_2.jpg\" width=\"150\">|<img src=\"images/cifar10_3.jpg\" width=\"150\">|<img src=\"images/cifar10_4.jpg\" width=\"150\">|\n|:-------------------------:|:-------------------------:|:-------------------------:|:-------------------------:|:-------------------------:|\n|Task 0 | Task 1 | Task 2 | Task 3 | Task 4|\n\n**MNIST Fellowship (MNIST + FashionMNIST + KMNIST)**:\n\n|<img src=\"images/mnist_fellowship_0.jpg\" width=\"150\">|<img src=\"images/mnist_fellowship_1.jpg\" width=\"150\">|<img src=\"images/mnist_fellowship_2.jpg\" width=\"150\">|\n|:-------------------------:|:-------------------------:|:-------------------------:|\n|Task 0 | Task 1 | Task 2 |\n\n\n**PermutedMNIST**:\n\n|<img src=\"images/mnist_permuted_0.jpg\" width=\"150\">|<img src=\"images/mnist_permuted_1.jpg\" width=\"150\">|<img src=\"images/mnist_permuted_2.jpg\" width=\"150\">|<img src=\"images/mnist_permuted_3.jpg\" width=\"150\">|<img src=\"images/mnist_permuted_4.jpg\" width=\"150\">|\n|:-------------------------:|:-------------------------:|:-------------------------:|:-------------------------:|:-------------------------:|\n|Task 0 | Task 1 | Task 2 | Task 3 | Task 4|\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/arthurdouillard/continual_loader",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "continnum",
    "package_url": "https://pypi.org/project/continnum/",
    "platform": "",
    "project_url": "https://pypi.org/project/continnum/",
    "project_urls": {
      "Homepage": "https://github.com/arthurdouillard/continual_loader"
    },
    "release_url": "https://pypi.org/project/continnum/0.0.1/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "A DataLoader library for Continual Learning in PyTorch.",
    "version": "0.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 7025055,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f8bfa5f774657776bf62dea96b67e01e91f037a118eb0901717f20a18ff9ae9e",
          "md5": "690ca265e9c46cc22cf5a356d9110f36",
          "sha256": "96f8c419935e1e485ab78261f24aad0e04a1726b3aa7da544c4b0d8a741f8888"
        },
        "downloads": -1,
        "filename": "continnum-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "690ca265e9c46cc22cf5a356d9110f36",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 15374,
        "upload_time": "2020-04-15T14:31:14",
        "upload_time_iso_8601": "2020-04-15T14:31:14.186810Z",
        "url": "https://files.pythonhosted.org/packages/f8/bf/a5f774657776bf62dea96b67e01e91f037a118eb0901717f20a18ff9ae9e/continnum-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bfb36a6d515b02123239e91d062f2b8eb42816a1f22fcf497efb370a3ed4b1de",
          "md5": "c0e8e2d8f0f024bbcd8cef47f6ff8002",
          "sha256": "6c08b65441dd81ea71002f5890f94b34936b24b1e9677cd98a2156dab8e1c2b0"
        },
        "downloads": -1,
        "filename": "continnum-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "c0e8e2d8f0f024bbcd8cef47f6ff8002",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 414753,
        "upload_time": "2020-04-15T14:31:16",
        "upload_time_iso_8601": "2020-04-15T14:31:16.696699Z",
        "url": "https://files.pythonhosted.org/packages/bf/b3/6a6d515b02123239e91d062f2b8eb42816a1f22fcf497efb370a3ed4b1de/continnum-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "f8bfa5f774657776bf62dea96b67e01e91f037a118eb0901717f20a18ff9ae9e",
        "md5": "690ca265e9c46cc22cf5a356d9110f36",
        "sha256": "96f8c419935e1e485ab78261f24aad0e04a1726b3aa7da544c4b0d8a741f8888"
      },
      "downloads": -1,
      "filename": "continnum-0.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "690ca265e9c46cc22cf5a356d9110f36",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 15374,
      "upload_time": "2020-04-15T14:31:14",
      "upload_time_iso_8601": "2020-04-15T14:31:14.186810Z",
      "url": "https://files.pythonhosted.org/packages/f8/bf/a5f774657776bf62dea96b67e01e91f037a118eb0901717f20a18ff9ae9e/continnum-0.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "bfb36a6d515b02123239e91d062f2b8eb42816a1f22fcf497efb370a3ed4b1de",
        "md5": "c0e8e2d8f0f024bbcd8cef47f6ff8002",
        "sha256": "6c08b65441dd81ea71002f5890f94b34936b24b1e9677cd98a2156dab8e1c2b0"
      },
      "downloads": -1,
      "filename": "continnum-0.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "c0e8e2d8f0f024bbcd8cef47f6ff8002",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 414753,
      "upload_time": "2020-04-15T14:31:16",
      "upload_time_iso_8601": "2020-04-15T14:31:16.696699Z",
      "url": "https://files.pythonhosted.org/packages/bf/b3/6a6d515b02123239e91d062f2b8eb42816a1f22fcf497efb370a3ed4b1de/continnum-0.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}