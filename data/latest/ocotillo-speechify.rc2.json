{
  "info": {
    "author": "Tyler",
    "author_email": "tyler@speechify.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# ðŸŒµ ocotillo - A fast, accurate and super simple speech recognition model\n\nThis repo is for ocotillo, a pytorch-based ML model that does state-of-the-art English speech transcription. While this\nis not necessarily difficult to accomplish with the libraries available today, every one that I have run to is \nexcessively complicated and therefore difficult to use. Ocotillo is dirt simple. The APIs I offer have almost no\nconfiguration options: just feed your speech in and go.\n\nIt's also fast. It traces the underlying model to torchscript. This means most of the heavy lifting is done in C++.\nThe transcribe.py script achieves a processing rate 329x faster than realtime on an NVIDIA A5000 GPU when transcribing\nbatches of 16 audio files at once.\n\n## Model Description\n\nocotillo uses a model pre-trained with [wav2vec2](https://arxiv.org/abs/2006.11477) and fine-tuned for speech recognition.\nThis model is hosted by HuggingFace's transformers API, and pretrained weights have been provided by Facebook/Meta.\nThe specific model being used is [jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli](https://huggingface.co/jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli),\nwhich I personally fine-tuned from existing wav2vec2 checkpoints to also predict punctuation. This makes ocotillo useful\nfor generating transcriptions which will be used for TTS.\n\nA special thanks goes out to [Patrick von Platen](https://huggingface.co/patrickvonplaten), who contributed (wrote?) the model to huggingface and maintains\nthe API that does all the heavy lifting. His fantastic blog posts were instrumental in building this repo. \nIn particular, [this one on finetuning wav2vec](https://huggingface.co/blog/fine-tune-wav2vec2-english)\nand [this one on leveraging a language model with wav2vec](https://huggingface.co/blog/wav2vec2-with-ngram).\n\n## Instructions for use\n\nThere are several ways to use ocotillo, described below. First you need to install PyTorch:\n\n[https://pytorch.org/get-started/locally/](https://pytorch.org/get-started/locally/)\n\nThen, clone ocotillo and install its dependencies:\n\n```shell\ngit clone https://github.com/neonbjb/ocotillo.git\ncd ocotillo\npython setup.py install\n```\n\n### Simple CLI\n\nThis is the most dead-simple way to get started with ocotillo. Find an audio clip on your computer, and run:\n\n```shell\nocotillo path/to/audio/clip.mp3\n```\n\n### Batch CLI\n\nA script is included, transcribe.py. This script searches for all audio files in a directory and\ntranscribes all the files found. Sample usage:\n\n```shell\npython transcribe.py --path /my/audio/folder --model_path pretrained_model_path.pth --cuda=0\n```\n\nThis will use a GPU to transcribe audio files found in /my/audio/folder. Transcription results\nwill be written to results.tsv.\n\n\n### API\n\nThis repo contains a class called transcribe.Transcriber, which can be used to transcribe audio\ndata into text. Usage looks like the following:\n\n```python\nfrom ocotillo.transcribe import Transcriber\n\ntranscriber = Transcriber(on_cuda=False)\naudio = load_audio('data/obama.mp3', 44100)\nprint(transcriber.transcribe(audio, sample_rate=44100))\n```\n\nThis will automatically download the 'large' model and use it to perform transcription on the CPU.\nOptions to specify a smaller model, perform transcription on a GPU, and perform batch transcription\nare available. See api.py.\n\nTranscriber works with numpy arrays and torch arrays. Audio data must be fp32 on the range [-1,1]. A demo colab \nnotebook that uses the API is included:\nasr_demo.ipynb.\n\n### HTTP server with [Mycroft](https://github.com/MycroftAI) support\n\nThis will allow you to run a speech-to-text server that operates the ocotillo model. The protocol was specifically\ndesigned to work with the open source assistant Mycroft.\n\nThis server does not need to run on the same device as you run mycroft (but your mycroft device needs to be on the\nsame network, or you need to expose your server to the web - not recommended).\n\nResponses are fast and high quality. On a modern x86 CPU, expect responses to most queries in under a second. On CUDA,\nresponses take less than a tenth of a second (most of which is data processing - model inference is on the order of \n10s of milliseconds). I have not tested ocotillo on embedded hardware like the Pi.\n\n1. Install Flask: `pip install flask`.\n2. Start server: `python stt_server.py`. CUDA device 0 is used by default, specify `--cuda=-1` to run on CPU.\n3. (optional) Install Mycroft: https://mycroft.ai/get-started/\n4. From mycroft build directory: `bin/mycroft-config edit user`\n5. Add the following code:\n    ```json\n    {\n      \"stt\": {\n        \"deepspeech_server\": {\n          \"uri\": \"http://<your_ip_address>/stt\"\n        },\n        \"module\": \"deepspeech_server\"\n      },\n    }\n    ```\n6. Restart mycroft: `./stop-mycroft.sh && ./start-mycroft.sh`\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/speechifyInc/ocotillo_speechify",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "ocotillo-speechify",
    "package_url": "https://pypi.org/project/ocotillo-speechify/",
    "platform": null,
    "project_url": "https://pypi.org/project/ocotillo-speechify/",
    "project_urls": {
      "Homepage": "https://github.com/speechifyInc/ocotillo_speechify"
    },
    "release_url": "https://pypi.org/project/ocotillo-speechify/1.0.5.3/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "A fork of a simple & fast speech transcription toolkit",
    "version": "1.0.5.3",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 15979784,
  "releases": {
    "1.0.5.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8b3102c6f9f4be98551b07fb324e75d3e3e8f6bcaa6f4f115f8ae531543c6de0",
          "md5": "439c6007b9b10ff9040b3688b08703bc",
          "sha256": "3cc59fe0e25356b5fab2db90070df793330457d32efda7931ed60cc8b2663bf8"
        },
        "downloads": -1,
        "filename": "ocotillo_speechify-1.0.5.2.tar.gz",
        "has_sig": false,
        "md5_digest": "439c6007b9b10ff9040b3688b08703bc",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 11705,
        "upload_time": "2022-12-03T16:07:41",
        "upload_time_iso_8601": "2022-12-03T16:07:41.809730Z",
        "url": "https://files.pythonhosted.org/packages/8b/31/02c6f9f4be98551b07fb324e75d3e3e8f6bcaa6f4f115f8ae531543c6de0/ocotillo_speechify-1.0.5.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.5.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1ee8226324ae4743472c6a9b9814074b47f157a6a9df8e179f6c50a14d999d79",
          "md5": "9aedc944ae8912828493425190572d35",
          "sha256": "688646050b1a5e7cec36a823618581dcdc5b73299c03f560e74c47937f5f3b32"
        },
        "downloads": -1,
        "filename": "ocotillo_speechify-1.0.5.3.tar.gz",
        "has_sig": false,
        "md5_digest": "9aedc944ae8912828493425190572d35",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 11719,
        "upload_time": "2022-12-03T16:29:26",
        "upload_time_iso_8601": "2022-12-03T16:29:26.449403Z",
        "url": "https://files.pythonhosted.org/packages/1e/e8/226324ae4743472c6a9b9814074b47f157a6a9df8e179f6c50a14d999d79/ocotillo_speechify-1.0.5.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "1ee8226324ae4743472c6a9b9814074b47f157a6a9df8e179f6c50a14d999d79",
        "md5": "9aedc944ae8912828493425190572d35",
        "sha256": "688646050b1a5e7cec36a823618581dcdc5b73299c03f560e74c47937f5f3b32"
      },
      "downloads": -1,
      "filename": "ocotillo_speechify-1.0.5.3.tar.gz",
      "has_sig": false,
      "md5_digest": "9aedc944ae8912828493425190572d35",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 11719,
      "upload_time": "2022-12-03T16:29:26",
      "upload_time_iso_8601": "2022-12-03T16:29:26.449403Z",
      "url": "https://files.pythonhosted.org/packages/1e/e8/226324ae4743472c6a9b9814074b47f157a6a9df8e179f6c50a14d999d79/ocotillo_speechify-1.0.5.3.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}