{
  "info": {
    "author": "Yukihiko Shinoda",
    "author_email": "yuk.hik.future@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Intended Audience :: Developers",
      "Intended Audience :: Information Technology",
      "License :: OSI Approved :: MIT License",
      "Natural Language :: English",
      "Operating System :: OS Independent",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Topic :: Internet :: WWW/HTTP",
      "Topic :: System :: Archiving",
      "Topic :: Text Processing :: Markup :: HTML",
      "Typing :: Typed"
    ],
    "description": "# Parallel HTML Scraper\n\n[![Test](https://github.com/yukihiko-shinoda/parallel-html-scraper/workflows/Test/badge.svg)](https://github.com/yukihiko-shinoda/parallel-html-scraper/actions?query=workflow%3ATest)\n[![Test Coverage](https://api.codeclimate.com/v1/badges/5f07cb148a0770db4be4/test_coverage)](https://codeclimate.com/github/yukihiko-shinoda/parallel-html-scraper/test_coverage)\n[![Maintainability](https://api.codeclimate.com/v1/badges/5f07cb148a0770db4be4/maintainability)](https://codeclimate.com/github/yukihiko-shinoda/parallel-html-scraper/maintainability)\n[![Code Climate technical debt](https://img.shields.io/codeclimate/tech-debt/yukihiko-shinoda/parallel-html-scraper)](https://codeclimate.com/github/yukihiko-shinoda/parallel-html-scraper)\n[![Updates](https://pyup.io/repos/github/yukihiko-shinoda/parallel-html-scraper/shield.svg)](https://pyup.io/repos/github/yukihiko-shinoda/parallel-html-scraper/)\n[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/parallelhtmlscraper)](https://pypi.org/project/parallelhtmlscraper/)\n[![PyPI - Downloads](https://img.shields.io/pypi/dm/parallelhtmlscraper)](https://pypi.org/project/parallelhtmlscraper/)\n[![Twitter URL](https://img.shields.io/twitter/url?style=social&url=https%3A%2F%2Fgithub.com%2Fyukihiko-shinoda%2Fparallel-html-scraper)](http://twitter.com/share?text=Parallel%20HTML%20Scraper&url=https://pypi.org/project/parallelhtmlscraper/&hashtags=python)\n\nHelps you to web scrape html file in parallel without async / await syntax.\n\n## Feature\n\nThis project helps you to web scrape html file in parallel without async / await syntax.\n\n## Installation\n\n```console\npip install parallelhtmlscraper\n```\n\n## Usage\n\nMinimum example:\n\n```python\nfrom bs4 import BeautifulSoup\n\nfrom parallelhtmlscraper.html_analyzer import HtmlAnalyzer\nfrom parallelhtmlscraper.parallel_html_scraper import ParallelHtmlScraper\n\nclass AnalyzerExample(HtmlAnalyzer):\n    async def execute(self, soup: BeautifulSoup) -> str:\n        return soup.find('title').text\n\nhost_google = 'https://www.google.com'\npath_and_content = [\n    '',                                                           # Google Search\n    '/imghp?hl=EN',                                               # Google Images\n    '/shopping?hl=en',                                            # Google Shopping\n    '/save',                                                      # Collection\n    'https://www.google.com/maps?hl=en',                          # Google Maps\n    'https://www.google.com/drive/apps.html',                     # Google drive\n    'https://www.google.com/mail/help/intl/en/about.html?vm=r',   # GMail\n]\n\nlist_response = ParallelHtmlScraper.execute(host_google, path_and_content, AnalyzerExample())\nprint(list_response)\n```\n\n```console\n$ pipenv run python test.py\n['\\n      Gmail - Email from Google\\n    ', 'Google Images', '  Google Maps  ', 'Using Google Drive - New Features, Benefits & Advantages of Google Cloud Storage', 'Google Shopping', 'Google', 'Collections']\n```\n\n## API\n\n### ParallelMediaDownloader.execute\n\n```python\nclass ParallelHtmlScraper:\n    \"\"\"API of parallel HTML scraping.\"\"\"\n\n    @staticmethod\n    def execute(\n        base_url: str,\n        list_url: Iterable[str],\n        analyzer: HtmlAnalyzer[_T],\n        *,\n        limit: int = 5\n        interval: int = 1\n    ) -> List[_T]:\n```\n\n#### base_url: str\n\nCommon part of request URL.\nThis will be help to download URLs got from HTML.\n\n#### list_url: Iterable[str]\n\nList of URL. Method will download them in parallel.\nAbsolute URL having same base URL as `base_url` also can be specified.\n\n#### analyzer: HtmlAnalyzer[_T]\n\nThe instance extends `HtmlAnalyzer` to analyze HTML by using [BeautifulSoup](https://pypi.org/project/beautifulsoup4/).\nFollowing example will be help to understand its roll:\n\n```python\nclass AnalyzerExample(HtmlAnalyzer):\n    async def execute(self, soup: BeautifulSoup) -> str:\n        return soup.find('title').text\n```\n\n#### limit: int = 5\n\nLimit number of parallel processes.\n\n#### interval: int = 1\n\nInterval between each request(second).\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/yukihiko-shinoda/parallel-media-downloader",
    "keywords": "parallel HTML web scraping scrape aiohttp beautifulsoup beautifulsoup4",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "parallelhtmlscraper",
    "package_url": "https://pypi.org/project/parallelhtmlscraper/",
    "platform": "",
    "project_url": "https://pypi.org/project/parallelhtmlscraper/",
    "project_urls": {
      "Homepage": "https://github.com/yukihiko-shinoda/parallel-media-downloader"
    },
    "release_url": "https://pypi.org/project/parallelhtmlscraper/0.1.0/",
    "requires_dist": [
      "aiohttp",
      "beautifulsoup4"
    ],
    "requires_python": ">=3.7",
    "summary": "This project helps you to web scrape html file.",
    "version": "0.1.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 7978837,
  "releases": {
    "0.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b714469e6705f48b679661066d288a1159c069b1c5d7273b9b257e2bddab612d",
          "md5": "8c5a9a809c22c25220cb068211b63891",
          "sha256": "7c2368489caa47f9f2b73a5ceae3657d4fb1707b55ac93ee3fe28a9dd3f6b3e8"
        },
        "downloads": -1,
        "filename": "parallelhtmlscraper-0.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "8c5a9a809c22c25220cb068211b63891",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 6255,
        "upload_time": "2019-08-17T20:22:07",
        "upload_time_iso_8601": "2019-08-17T20:22:07.778799Z",
        "url": "https://files.pythonhosted.org/packages/b7/14/469e6705f48b679661066d288a1159c069b1c5d7273b9b257e2bddab612d/parallelhtmlscraper-0.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e46d569f787c5458e4003fdf4db473a5339d4d92e21ea0c5413259c71d245da0",
          "md5": "45a26e49d3970f39056826d1ed26e235",
          "sha256": "d920ad50e30056c1cf8c245486276f96e51a4f3f271569404e0379661146ccc7"
        },
        "downloads": -1,
        "filename": "parallelhtmlscraper-0.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "45a26e49d3970f39056826d1ed26e235",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 3603,
        "upload_time": "2019-08-17T20:22:10",
        "upload_time_iso_8601": "2019-08-17T20:22:10.078778Z",
        "url": "https://files.pythonhosted.org/packages/e4/6d/569f787c5458e4003fdf4db473a5339d4d92e21ea0c5413259c71d245da0/parallelhtmlscraper-0.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9f61706e4e80a7722d72177dbb88f424ced326d7e70e68919957d04451be4564",
          "md5": "5258e9af184ff5f633b0ca8e0afc72df",
          "sha256": "ca1b7e4ffd04422e2665ba48e164ba6aa993d3e1ea965ff5efb4e6a475cf516c"
        },
        "downloads": -1,
        "filename": "parallelhtmlscraper-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "5258e9af184ff5f633b0ca8e0afc72df",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 13058,
        "upload_time": "2020-08-17T11:40:40",
        "upload_time_iso_8601": "2020-08-17T11:40:40.847987Z",
        "url": "https://files.pythonhosted.org/packages/9f/61/706e4e80a7722d72177dbb88f424ced326d7e70e68919957d04451be4564/parallelhtmlscraper-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4206e4f1d381d474177aae2cf685ae964362d2ca61ab16cdbf3aca291fa5159d",
          "md5": "d2aff3a0946b6773afd8b03d1dfdcd7a",
          "sha256": "07c2bb595aadf50cbcee93f2f0deba3d699ef8a8426a4fb75c7c4993248dccb1"
        },
        "downloads": -1,
        "filename": "parallelhtmlscraper-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "d2aff3a0946b6773afd8b03d1dfdcd7a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 10048,
        "upload_time": "2020-08-17T11:40:42",
        "upload_time_iso_8601": "2020-08-17T11:40:42.073431Z",
        "url": "https://files.pythonhosted.org/packages/42/06/e4f1d381d474177aae2cf685ae964362d2ca61ab16cdbf3aca291fa5159d/parallelhtmlscraper-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "9f61706e4e80a7722d72177dbb88f424ced326d7e70e68919957d04451be4564",
        "md5": "5258e9af184ff5f633b0ca8e0afc72df",
        "sha256": "ca1b7e4ffd04422e2665ba48e164ba6aa993d3e1ea965ff5efb4e6a475cf516c"
      },
      "downloads": -1,
      "filename": "parallelhtmlscraper-0.1.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "5258e9af184ff5f633b0ca8e0afc72df",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 13058,
      "upload_time": "2020-08-17T11:40:40",
      "upload_time_iso_8601": "2020-08-17T11:40:40.847987Z",
      "url": "https://files.pythonhosted.org/packages/9f/61/706e4e80a7722d72177dbb88f424ced326d7e70e68919957d04451be4564/parallelhtmlscraper-0.1.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "4206e4f1d381d474177aae2cf685ae964362d2ca61ab16cdbf3aca291fa5159d",
        "md5": "d2aff3a0946b6773afd8b03d1dfdcd7a",
        "sha256": "07c2bb595aadf50cbcee93f2f0deba3d699ef8a8426a4fb75c7c4993248dccb1"
      },
      "downloads": -1,
      "filename": "parallelhtmlscraper-0.1.0.tar.gz",
      "has_sig": false,
      "md5_digest": "d2aff3a0946b6773afd8b03d1dfdcd7a",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 10048,
      "upload_time": "2020-08-17T11:40:42",
      "upload_time_iso_8601": "2020-08-17T11:40:42.073431Z",
      "url": "https://files.pythonhosted.org/packages/42/06/e4f1d381d474177aae2cf685ae964362d2ca61ab16cdbf3aca291fa5159d/parallelhtmlscraper-0.1.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}