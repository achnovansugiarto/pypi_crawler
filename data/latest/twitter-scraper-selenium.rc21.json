{
  "info": {
    "author": "Sajid Shaikh",
    "author_email": "shaikhsajid3732@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Environment :: Console",
      "Intended Audience :: Developers",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: MIT License",
      "Natural Language :: English",
      "Operating System :: MacOS",
      "Operating System :: Microsoft :: Windows",
      "Operating System :: POSIX :: Linux",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Programming Language :: Python :: Implementation :: CPython",
      "Topic :: Internet :: WWW/HTTP",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "<h1> Twitter scraper selenium </h1>\r\n<p> Python's package to scrape Twitter's front-end easily with selenium.  </p>\r\n\r\n\r\n[![PyPI license](https://img.shields.io/pypi/l/ansicolortags.svg)](https://opensource.org/licenses/MIT) [![Python >=3.6.9](https://img.shields.io/badge/python-3.6+-blue.svg)](https://www.python.org/downloads/release/python-360/)\r\n[![Maintenance](https://img.shields.io/badge/Maintained-Yes-green.svg)](https://github.com/shaikhsajid1111/facebook_page_scraper/graphs/commit-activity)\r\n\r\n<!--TABLE of contents-->\r\n<h2> Table of Contents </h2>\r\n<details open=\"open\">\r\n  <summary>Table of Contents</summary>\r\n  <ol>\r\n    <li>\r\n      <a href=\"#getting-started\">Getting Started</a>\r\n      <ul>\r\n        <li><a href=\"#Prerequisites\">Prerequisites</a></li>\r\n        <li><a href=\"#Installation\">Installation</a>\r\n        <ul>\r\n        <li><a href=\"#sourceInstallation\">Installing from source</a></li>\r\n        <li><a href=\"#pypiInstallation\">Installing with PyPI</a></li>\r\n        </ul>\r\n        </li>\r\n      </ul>\r\n    </li>\r\n    <li><a href=\"#Usage\">Usage</a>\r\n    <ul><li><a href=\"#availableFunction\">Available Functions in this package- Summary</a></li></ul>\r\n    <ul><li><a href=\"#profileDetail\">Scraping profile's details</a>\r\n    <ul>\r\n    <li><a href=\"#profileDetailExample\">In JSON Format - Example</a></li>\r\n    <li><a href=\"#profileDetailArgument\">Function Argument</a></li>\r\n    <li><a href=\"#profileDetailKeys\">Keys of the output</a></li>\r\n    </ul>\r\n    </li></ul>\r\n    <!---->\r\n    <ul>\r\n    <li><a href=\"#profile\">Scraping profile's tweets</a>\r\n    <ul>\r\n    <li><a href=\"#profileJson\">In JSON format - Example</a></li>\r\n    <li><a href=\"#profileCSV\">In CSV format - Example</a></li>\r\n    <li><a href=\"#profileArgument\">Function Arguments</a></li>\r\n    <li><a href=\"#profileOutput\">Keys of the output data</a></li>\r\n    </ul>\r\n    <li><a href=\"#keywordAPI\">Scraping tweets using query/keyword with API</a>\r\n    <ul>\r\n    <li><a href=\"#keywordAPI\">In JSON Format - Example</a></li>\r\n    <li><a href=\"#scrape_keyword_with_apiArgs\">Function Argument</a></li>\r\n    <li><a href=\"#scrape_keyword_with_apiKeys\">Keys of the output.</a></li>\r\n    </ul>\r\n    </li>\r\n    <li><a href=\"#keyword\">Scraping tweets using keywords with browser automation</a>\r\n    <ul>\r\n    <li><a href=\"#keywordJson\">In JSON format - Example</a></li>\r\n    <li><a href=\"#keywordCSV\">In CSV format - Example</a></li>\r\n    <li><a href=\"#keywordArgument\">Function Arguments</a></li>\r\n    <li><a href=\"#keywordOutput\">Keys of the output data</a></li>\r\n    </ul>\r\n    </li>\r\n    <li><a href=\"#scrape_with_api\">Scraping tweets using topic url with API</a></li>\r\n    <ul>\r\n    <li><a href=\"#scrape_with_api\">In JSON format -  Example</a></li>\r\n    <li><a href=\"#scrape_topic_with_api_args\">Function Arguments</a></li>\r\n    <li><a href=\"#scrape_topic_with_api_args_keys\">Keys of the output</a></li>\r\n    </ul>\r\n    <li><a href=\"#to-scrape-topic-tweets-with-url\">Scraping tweets using topic url - Example</a></li>\r\n    <ul>\r\n    <li><a href=\"#scrape_topic_with_api_args\">In JSON format -  Example</a></li>\r\n    <li><a href=\"#topicArgument\">Function Arguments</a></li>\r\n    <li><a href=\"#profileOutput\">Keys of the output:</a></li>\r\n    </ul>\r\n    <li><a href='#to-scrape-user-tweets-with-api'>Scraping user's tweet using API</a></li>\r\n    <ul>\r\n    <li><a href='#to-scrape-user-tweets-with-api'>In JSON format - Example</a></li>\r\n    <li><a href='#users_api_parameter'>Function Arguments</a></li>\r\n    <li><a href='#scrape_user_with_api_args_keys'>Keys of the output</a></li>\r\n    </ul>\r\n    <li><a href=\"#proxy\">Using scraper with proxy</a>\r\n    <ul>\r\n    <li><a href=\"#unauthenticatedProxy\">Unauthenticated Proxy</a></li>\r\n    <li><a href=\"#authenticatedProxy\">Authenticated Proxy</a></li>\r\n    </ul>\r\n    </li>\r\n    </li>\r\n    </ul>\r\n    </li>\r\n    <li><a href=\"#privacy\">Privacy</a></li>\r\n    <li><a href=\"#license\">License</a></li>\r\n  </ol>\r\n</details>\r\n\r\n<!--TABLE of contents //-->\r\n<br>\r\n<hr>\r\n<h2 id=\"Prerequisites\">Prerequisites </h2>\r\n<li> Internet Connection </li>\r\n<li> Python 3.6+ </li>\r\n<li> Chrome or Firefox browser installed on your machine </li>\r\n<hr>\r\n<h2 id=\"Installation\"> Installation </h2>\r\n<h3 id=\"sourceInstallation\">Installing from the source</h3>\r\n<p>Download the source code or clone it with:<p>\r\n\r\n```\r\ngit clone https://github.com/shaikhsajid1111/twitter-scraper-selenium\r\n```\r\n\r\n<p>Open terminal inside the downloaded folder:</p>\r\n\r\n<br>\r\n\r\n```\r\n python3 setup.py install\r\n```\r\n\r\n<h3 id=\"pypiInstallation\">\r\nInstalling with <a href=\"https://pypi.org\">PyPI</a>\r\n</h3>\r\n\r\n```\r\npip3 install twitter-scraper-selenium\r\n```\r\n\r\n<hr>\r\n<h2 id=\"Usage\">\r\nUsage</h2>\r\n<h3 id=\"availableFunction\">Available Function In this Package - Summary</h3>\r\n<div>\r\n<table>\r\n<thead>\r\n<tr>\r\n<td>Function Name</td>\r\n<td>Function Description</td>\r\n<td>Scraping Method</td>\r\n<td>Scraping Speed</td>\r\n</tr>\r\n</thead>\r\n<tr>\r\n<td><code>scrape_profile()</code></td>\r\n<td>Scrape's Twitter user's profile tweets</td>\r\n<td>Browser Automation</td>\r\n<td>Slow</td>\r\n</tr>\r\n<tr>\r\n<td><code>scrape_keyword()</code></td>\r\n<td>Scrape's Twitter tweets using keyword provided.</td>\r\n<td>Browser Automation</td>\r\n<td>Slow</td>\r\n</tr>\r\n<tr>\r\n<td><code>scrape_topic()</code></td>\r\n<td>Scrape's Twitter tweets by URL. It expects the URL of the topic.</td>\r\n<td>Browser Automation</td>\r\n<td>Slow</td>\r\n</tr>\r\n<tr>\r\n<td><code>scrape_keyword_with_api()</code></td>\r\n<td>Scrape's Twitter tweets by query/keywords. For an advanced search, query can be built from <a href=\"https://developer.twitter.com/apitools/query\">here</a>.</td>\r\n<td>HTTP Request</td>\r\n<td>Fast</td>\r\n</tr>\r\n<tr>\r\n<td><code>get_profile_details()</code></td>\r\n<td>Scrape's Twitter user details.</td>\r\n<td>HTTP Request</td>\r\n<td>Fast</td>\r\n</tr>\r\n<tr>\r\n<td><code>scrape_topic_with_api()</code></td>\r\n<td>Scrape's Twitter tweets by URL. It expects the URL of the topic</td>\r\n<td>Browser Automation & HTTP Request</td>\r\n<td>Fast</td>\r\n</tr>\r\n<tr>\r\n<td><code>scrape_profile_with_api()</code></td>\r\n<td>Scrape's Twitter tweets by twitter profile username. It expects the username of the profile</td>\r\n<td>Browser Automation & HTTP Request</td>\r\n<td>Fast</td>\r\n</tr>\r\n</table>\r\n<p>\r\nNote: HTTP Request Method sends the request to Twitter's API directly for scraping data, and Browser Automation visits that page, scroll while collecting the data.</p>\r\n</div>\r\n<br>\r\n<hr>\r\n<h3 id=\"profileDetail\">To scrape twitter profile details:</h3>\r\n<div id=\"profileDetailExample\">\r\n\r\n```python\r\nfrom twitter_scraper_selenium import get_profile_details\r\n\r\ntwitter_username = \"TwitterAPI\"\r\nfilename = \"twitter_api_data\"\r\nget_profile_details(twitter_username=twitter_username, filename=filename)\r\n\r\n```\r\nOutput:\r\n```js\r\n{\r\n\t\"id\": 6253282,\r\n\t\"id_str\": \"6253282\",\r\n\t\"name\": \"Twitter API\",\r\n\t\"screen_name\": \"TwitterAPI\",\r\n\t\"location\": \"San Francisco, CA\",\r\n\t\"profile_location\": null,\r\n\t\"description\": \"The Real Twitter API. Tweets about API changes, service issues and our Developer Platform. Don't get an answer? It's on my website.\",\r\n\t\"url\": \"https:\\/\\/t.co\\/8IkCzCDr19\",\r\n\t\"entities\": {\r\n\t\t\"url\": {\r\n\t\t\t\"urls\": [{\r\n\t\t\t\t\"url\": \"https:\\/\\/t.co\\/8IkCzCDr19\",\r\n\t\t\t\t\"expanded_url\": \"https:\\/\\/developer.twitter.com\",\r\n\t\t\t\t\"display_url\": \"developer.twitter.com\",\r\n\t\t\t\t\"indices\": [\r\n\t\t\t\t\t0,\r\n\t\t\t\t\t23\r\n\t\t\t\t]\r\n\t\t\t}]\r\n\t\t},\r\n\t\t\"description\": {\r\n\t\t\t\"urls\": []\r\n\t\t}\r\n\t},\r\n\t\"protected\": false,\r\n\t\"followers_count\": 6133636,\r\n\t\"friends_count\": 12,\r\n\t\"listed_count\": 12936,\r\n\t\"created_at\": \"Wed May 23 06:01:13 +0000 2007\",\r\n\t\"favourites_count\": 31,\r\n\t\"utc_offset\": null,\r\n\t\"time_zone\": null,\r\n\t\"geo_enabled\": null,\r\n\t\"verified\": true,\r\n\t\"statuses_count\": 3656,\r\n\t\"lang\": null,\r\n\t\"contributors_enabled\": null,\r\n\t\"is_translator\": null,\r\n\t\"is_translation_enabled\": null,\r\n\t\"profile_background_color\": null,\r\n\t\"profile_background_image_url\": null,\r\n\t\"profile_background_image_url_https\": null,\r\n\t\"profile_background_tile\": null,\r\n\t\"profile_image_url\": null,\r\n\t\"profile_image_url_https\": \"https:\\/\\/pbs.twimg.com\\/profile_images\\/942858479592554497\\/BbazLO9L_normal.jpg\",\r\n\t\"profile_banner_url\": null,\r\n\t\"profile_link_color\": null,\r\n\t\"profile_sidebar_border_color\": null,\r\n\t\"profile_sidebar_fill_color\": null,\r\n\t\"profile_text_color\": null,\r\n\t\"profile_use_background_image\": null,\r\n\t\"has_extended_profile\": null,\r\n\t\"default_profile\": false,\r\n\t\"default_profile_image\": false,\r\n\t\"following\": null,\r\n\t\"follow_request_sent\": null,\r\n\t\"notifications\": null,\r\n\t\"translator_type\": null\r\n}\r\n```\r\n</div>\r\n<br>\r\n<div id=\"profileDetailArgument\">\r\n<p><code>get_profile_details()</code> arguments:</p>\r\n\r\n<table>\r\n    <thead>\r\n        <tr>\r\n            <td>Argument</td>\r\n            <td>Argument Type</td>\r\n            <td>Description</td>\r\n        </tr>\r\n    </thead>\r\n    <tbody>\r\n        <tr>\r\n            <td>twitter_username</td>\r\n            <td>String</td>\r\n            <td>Twitter Username</td>\r\n        </tr>\r\n        <tr>\r\n            <td>output_filename</td>\r\n            <td>String</td>\r\n            <td>What should be the filename where output is stored?.</td>\r\n        </tr>\r\n        <tr>\r\n            <td>output_dir</td>\r\n            <td>String</td>\r\n            <td>What directory output file should be saved?</td>\r\n        </tr>\r\n        <tr>\r\n            <td>proxy</td>\r\n            <td>String</td>\r\n            <td>Optional parameter, if user wants to use proxy for scraping. If the proxy is authenticated proxy then the proxy format is username:password@host:port.</td>\r\n        </tr>\r\n    </tbody>\r\n</table>\r\n\r\n</div>\r\n<hr>\r\n<br>\r\n<div>\r\n<h4 id=\"profileDetailKeys\">Keys of the output:</p>\r\nDetail of each key can be found <a href=\"https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/user\">here</a>.</h4>\r\n</div>\r\n<br>\r\n<hr>\r\n<h3 id=\"profile\">To scrape profile's tweets:</h3>\r\n<p id=\"profileJson\">In JSON format:</p>\r\n\r\n```python\r\nfrom twitter_scraper_selenium import scrape_profile\r\n\r\nmicrosoft = scrape_profile(twitter_username=\"microsoft\",output_format=\"json\",browser=\"firefox\",tweets_count=10)\r\nprint(microsoft)\r\n```\r\nOutput:\r\n```javascript\r\n{\r\n  \"1430938749840629773\": {\r\n    \"tweet_id\": \"1430938749840629773\",\r\n    \"username\": \"Microsoft\",\r\n    \"name\": \"Microsoft\",\r\n    \"profile_picture\": \"https://twitter.com/Microsoft/photo\",\r\n    \"replies\": 29,\r\n    \"retweets\": 58,\r\n    \"likes\": 453,\r\n    \"is_retweet\": false,\r\n    \"retweet_link\": \"\",\r\n    \"posted_time\": \"2021-08-26T17:02:38+00:00\",\r\n    \"content\": \"Easy to use and efficient for all \\u2013 Windows 11 is committed to an accessible future.\\n\\nHere's how it empowers everyone to create, connect, and achieve more: https://msft.it/6009X6tbW \",\r\n    \"hashtags\": [],\r\n    \"mentions\": [],\r\n    \"images\": [],\r\n    \"videos\": [],\r\n    \"tweet_url\": \"https://twitter.com/Microsoft/status/1430938749840629773\",\r\n    \"link\": \"https://blogs.windows.com/windowsexperience/2021/07/01/whats-coming-in-windows-11-accessibility/?ocid=FY22_soc_omc_br_tw_Windows_AC\"\r\n  },...\r\n}\r\n```\r\n<hr>\r\n<p id=\"profileCSV\">In CSV format:</p>\r\n\r\n```python\r\nfrom twitter_scraper_selenium import scrape_profile\r\n\r\n\r\nscrape_profile(twitter_username=\"microsoft\",output_format=\"csv\",browser=\"firefox\",tweets_count=10,filename=\"microsoft\",directory=\"/home/user/Downloads\")\r\n\r\n\r\n```\r\n\r\nOutput:\r\n<br>\r\n<table class=\"table table-bordered table-hover table-condensed\" style=\"line-height: 14px;overflow:hidden;white-space: nowrap\">\r\n<thead><tr><th title=\"Field #1\">tweet_id</th>\r\n<th title=\"Field #2\">username</th>\r\n<th title=\"Field #3\">name</th>\r\n<th title=\"Field #4\">profile_picture</th>\r\n<th title=\"Field #5\">replies</th>\r\n<th title=\"Field #6\">retweets</th>\r\n<th title=\"Field #7\">likes</th>\r\n<th title=\"Field #8\">is_retweet</th>\r\n<th title=\"Field #9\">retweet_link</th>\r\n<th title=\"Field #10\">posted_time</th>\r\n<th title=\"Field #11\">content</th>\r\n<th title=\"Field #12\">hashtags</th>\r\n<th title=\"Field #13\">mentions</th>\r\n<th title=\"Field #14\">images</th>\r\n<th title=\"Field #15\">videos</th>\r\n<th title=\"Field #16\">post_url</th>\r\n<th title=\"Field #17\">link</th>\r\n</tr></thead>\r\n<tbody><tr>\r\n<td>1430938749840629773</td>\r\n<td>Microsoft</td>\r\n<td>Microsoft</td>\r\n<td>https://twitter.com/Microsoft/photo</td>\r\n<td align=\"right\">64</td>\r\n<td align=\"right\">75</td>\r\n<td align=\"right\">521</td>\r\n<td>False</td>\r\n<td> </td>\r\n<td>2021-08-26T17:02:38+00:00</td>\r\n<td>Easy to use and efficient for all â€“ Windows 11 is committed to an accessible future.<br/><br/>Here&#39;s how it empowers everyone to create, connect, and achieve more: https://msft.it/6009X6tbW </td>\r\n<td>[]</td>\r\n<td>[]</td>\r\n<td>[]</td>\r\n<td>[]</td>\r\n<td>https://twitter.com/Microsoft/status/1430938749840629773</td>\r\n<td>https://blogs.windows.com/windowsexperience/2021/07/01/whats-coming-in-windows-11-accessibility/?ocid=FY22_soc_omc_br_tw_Windows_AC</td>\r\n</tr>\r\n\r\n</tbody>\r\n</table>\r\n<p>...</p>\r\n\r\n<br><hr>\r\n<div id=\"profileArgument\">\r\n<p><code>scrape_profile()</code> arguments:</p>\r\n\r\n<table>\r\n    <thead>\r\n        <tr>\r\n            <td>Argument</td>\r\n            <td>Argument Type</td>\r\n            <td>Description</td>\r\n        </tr>\r\n    </thead>\r\n    <tbody>\r\n        <tr>\r\n            <td>twitter_username</td>\r\n            <td>String</td>\r\n            <td>Twitter username of the account</td>\r\n        </tr>\r\n        <tr>\r\n            <td>browser</td>\r\n            <td>String</td>\r\n            <td>Which browser to use for scraping?, Only 2 are supported Chrome and Firefox. Default is set to Firefox</td>\r\n        </tr>\r\n        <tr>\r\n            <td>proxy</td>\r\n            <td>String</td>\r\n            <td>Optional parameter, if user wants to use proxy for scraping. If the proxy is authenticated proxy then the proxy format is username:password@host:port.</td>\r\n        </tr>\r\n        <tr>\r\n            <td>tweets_count</td>\r\n            <td>Integer</td>\r\n            <td>Number of posts to scrape. Default is 10.</td>\r\n        </tr>\r\n        <tr>\r\n            <td>output_format</td>\r\n            <td>String</td>\r\n            <td>The output format, whether JSON or CSV. Default is JSON.</td>\r\n        </tr>\r\n        <tr>\r\n            <td>filename</td>\r\n            <td>String</td>\r\n            <td>If output parameter is set to CSV, then it is necessary for filename parameter to passed. If not passed then the filename will be same as username passed.</td>\r\n        </tr>\r\n        <tr>\r\n            <td>directory</td>\r\n            <td>String</td>\r\n            <td>If output_format parameter is set to CSV, then it is valid for directory parameter to be passed. If not passed then CSV file will be saved in current working directory.</td>\r\n        </tr>\r\n        <tr>\r\n            <td>headless</td>\r\n            <td>Boolean</td>\r\n            <td>Whether to run crawler headlessly?. Default is <code>True</code></td>\r\n        </tr>\r\n        <tr>\r\n            <td>browser_profile</td>\r\n            <td>String</td>\r\n            <td>Path to the browser profile where cookies are stored and can be used for scraping data in an authenticated way.</td>\r\n        </tr>\r\n    </tbody>\r\n</table>\r\n\r\n</div>\r\n<hr>\r\n<br>\r\n<div id=\"profileOutput\">\r\n<p>Keys of the output</p>\r\n\r\n<table>\r\n    <thead>\r\n        <tr>\r\n            <td>Key</td>\r\n            <td>Type</td>\r\n            <td>Description</td>\r\n        </tr>\r\n    </thead>\r\n    <tbody>\r\n        <tr>\r\n            <td>tweet_id</td>\r\n            <td>String</td>\r\n            <td>Post Identifier(integer casted inside string)</td>\r\n        </tr>\r\n        <tr>\r\n            <td>username</td>\r\n            <td>String</td>\r\n            <td>Username of the profile</td>\r\n        </tr>\r\n        <tr>\r\n            <td>name</td>\r\n            <td>String</td>\r\n            <td>Name of the profile</td>\r\n        </tr>\r\n        <tr>\r\n            <td>profile_picture</td>\r\n            <td>String</td>\r\n            <td>Profile Picture link</td>\r\n        </tr>\r\n        <tr>\r\n            <td>replies</td>\r\n            <td>Integer</td>\r\n            <td>Number of replies of tweet</td>\r\n        </tr>\r\n        <tr>\r\n            <td>retweets</td>\r\n            <td>Integer</td>\r\n            <td>Number of retweets of tweet</td>\r\n        </tr>\r\n        <tr>\r\n            <td>likes</td>\r\n            <td>Integer</td>\r\n            <td>Number of likes of tweet</td>\r\n        </tr>\r\n        <tr>\r\n            <td>is_retweet</td>\r\n            <td>boolean</td>\r\n            <td>Is the tweet a retweet?</td>\r\n        </tr>\r\n        <tr>\r\n            <td>retweet_link</td>\r\n            <td>String</td>\r\n            <td>If it is retweet, then the retweet link else it'll be empty string</td>\r\n        </tr>\r\n        <tr>\r\n            <td>posted_time</td>\r\n            <td>String</td>\r\n            <td>Time when tweet was posted in ISO 8601 format</td>\r\n        </tr>\r\n        <tr>\r\n            <td>content</td>\r\n            <td>String</td>\r\n            <td>content of tweet as text</td>\r\n        </tr>\r\n        <tr>\r\n            <td>hashtags</td>\r\n            <td>Array</td>\r\n            <td>Hashtags presents in tweet, if they're present in tweet</td>\r\n        </tr>\r\n        <tr>\r\n            <td>mentions</td>\r\n            <td>Array</td>\r\n            <td>Mentions presents in tweet, if they're present in tweet</td>\r\n        </tr>\r\n        <tr>\r\n            <td>images</td>\r\n            <td>Array</td>\r\n            <td>Images links, if they're present in tweet</td>\r\n        </tr>\r\n        <tr>\r\n            <td>videos</td>\r\n            <td>Array</td>\r\n            <td>Videos links, if they're present in tweet</td>\r\n        </tr>\r\n        <tr>\r\n            <td>tweet_url</td>\r\n            <td>String</td>\r\n            <td>URL of the tweet</td>\r\n        </tr>\r\n        <tr>\r\n            <td>link</td>\r\n            <td>String</td>\r\n            <td>If any link is present inside tweet for some external website. </td>\r\n        </tr>\r\n    </tbody>\r\n</table>\r\n</div>\r\n<br>\r\n<hr>\r\n<h3 id=\"keywordAPI\">To scrape tweets using keywords with API:</h3>\r\n<div>\r\n\r\n```python\r\nfrom twitter_scraper_selenium import scrape_keyword_with_api\r\n\r\nquery = \"#gaming\"\r\ntweets_count = 10\r\noutput_filename = \"gaming_hashtag_data\"\r\nscrape_keyword_with_api(query=query, tweets_count=tweets_count, output_filename=output_filename)\r\n\r\n```\r\nOutput:\r\n```js\r\n{\r\n  \"1583821467732480001\": {\r\n    \"tweet_url\" : \"https://twitter.com/yakubblackbeard/status/1583821467732480001\",\r\n    \"tweet_details\":{\r\n      ...\r\n    },\r\n    \"user_details\":{\r\n      ...\r\n    }\r\n  }, ...\r\n}\r\n```\r\n</div>\r\n<br>\r\n<div id=\"scrape_keyword_with_apiArgs\">\r\n<p><code>scrape_keyword_with_api()</code> arguments:</p>\r\n\r\n<table>\r\n    <thead>\r\n        <tr>\r\n            <td>Argument</td>\r\n            <td>Argument Type</td>\r\n            <td>Description</td>\r\n        </tr>\r\n    </thead>\r\n    <tbody>\r\n        <tr>\r\n            <td>query</td>\r\n            <td>String</td>\r\n            <td>Query to search. The query can be built from <a href=\"https://developer.twitter.com/apitools/query\">here</a> for advanced search.</td>\r\n        </tr>\r\n        <tr>\r\n            <td>tweets_count</td>\r\n            <td>Integer</td>\r\n            <td>Number of tweets to scrape.</td>\r\n        </tr>\r\n        <tr>\r\n            <td>output_filename</td>\r\n            <td>String</td>\r\n            <td>What should be the filename where output is stored?.</td>\r\n        </tr>\r\n        <tr>\r\n            <td>output_dir</td>\r\n            <td>String</td>\r\n            <td>What directory output file should be saved?</td>\r\n        </tr>\r\n        <tr>\r\n            <td>proxy</td>\r\n            <td>String</td>\r\n            <td>Optional parameter, if user wants to use proxy for scraping. If the proxy is authenticated proxy then the proxy format is username:password@host:port.</td>\r\n        </tr>\r\n    </tbody>\r\n</table>\r\n\r\n</div>\r\n<hr>\r\n<br>\r\n<div>\r\n<p id=\"scrape_keyword_with_apiKeys\">Keys of the output:</p>\r\n<table>\r\n<thead>\r\n        <tr>\r\n            <td>Key</td>\r\n            <td>Type</td>\r\n            <td>Description</td>\r\n        </tr>\r\n    </thead>\r\n    <tbody>\r\n    <tr>\r\n    <td>tweet_url</td>\r\n    <td>String</td>\r\n    <td>URL of the tweet.</td>\r\n    </tr>\r\n    <tr>\r\n    <td>tweet_details</td>\r\n    <td>Dictionary</td>\r\n    <td>A dictionary containing the data about the tweet. All fields which will be available inside can be checked <a href=\"https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/tweet\">here<a></td>\r\n    </tr>\r\n    <tr>\r\n    <td>user_details</td>\r\n    <td>Dictionary</td>\r\n    <td>A dictionary containing the data about the tweet owner. All fields which will be available inside can be checked <a href=\"https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/user\">here<a></td>\r\n    </tr>\r\n    </tbody>\r\n</table>\r\n</div>\r\n<br>\r\n<br>\r\n<hr>\r\n<h3>To scrape tweets using keywords with browser automation</h3>\r\n<div>\r\n<p id=\"keywordJson\">In JSON format:</p>\r\n\r\n```python\r\nfrom twitter_scraper_selenium import scrape_keyword\r\n#scrape 10 posts by searching keyword \"india\" from date 30th August till date 31st August\r\nindia = scrape_keyword(keyword=\"india\", browser=\"firefox\",\r\n                      tweets_count=10,output_format=\"json\" ,until=\"2021-08-31\", since=\"2021-08-30\")\r\nprint(india)\r\n\r\n```\r\nOutput:\r\n```javascript\r\n{\r\n  \"1432493306152243200\": {\r\n    \"tweet_id\": \"1432493306152243200\",\r\n    \"username\": \"TOICitiesNews\",\r\n    \"name\": \"TOI Cities\",\r\n    \"profile_picture\": \"https://twitter.com/TOICitiesNews/photo\",\r\n    \"replies\": 0,\r\n    \"retweets\": 0,\r\n    \"likes\": 0,\r\n    \"is_retweet\": false,\r\n    \"posted_time\": \"2021-08-30T23:59:53+00:00\",\r\n    \"content\": \"Paralympians rake in medals, India Inc showers them with rewards\",\r\n    \"hashtags\": [],\r\n    \"mentions\": [],\r\n    \"images\": [],\r\n    \"videos\": [],\r\n    \"tweet_url\": \"https://twitter.com/TOICitiesNews/status/1432493306152243200\",\r\n    \"link\": \"https://t.co/odmappLovL?amp=1\"\r\n  },...\r\n}\r\n```\r\n</div>\r\n<br>\r\n<hr>\r\n<div id=\"keywordCSV\">\r\n<p>In CSV format:</p>\r\n\r\n```python\r\nfrom twitter_scraper_selenium import scrape_keyword\r\n\r\nscrape_keyword(keyword=\"india\", browser=\"firefox\",\r\n                      tweets_count=10, until=\"2021-08-31\", since=\"2021-08-30\",output_format=\"csv\",filename=\"india\")\r\n```\r\n<br>\r\nOutput:\r\n<table class=\"table table-bordered table-hover table-condensed\" style=\"line-height: 14px;overflow:hidden;white-space: nowrap\">\r\n<thead><tr><th title=\"Field #1\">tweet_id</th>\r\n<th title=\"Field #2\">username</th>\r\n<th title=\"Field #3\">name</th>\r\n<th title=\"Field #4\">profile_picture</th>\r\n<th title=\"Field #5\">replies</th>\r\n<th title=\"Field #6\">retweets</th>\r\n<th title=\"Field #7\">likes</th>\r\n<th title=\"Field #8\">is_retweet</th>\r\n<th title=\"Field #9\">posted_time</th>\r\n<th title=\"Field #10\">content</th>\r\n<th title=\"Field #11\">hashtags</th>\r\n<th title=\"Field #12\">mentions</th>\r\n<th title=\"Field #13\">images</th>\r\n<th title=\"Field #14\">videos</th>\r\n<th title=\"Field #15\">tweet_url</th>\r\n<th title=\"Field #16\">link</th>\r\n</tr></thead>\r\n<tbody>\r\n\r\n<tr>\r\n<td>1432493306152243200</td>\r\n<td>TOICitiesNews</td>\r\n<td>TOI Cities</td>\r\n<td>https://twitter.com/TOICitiesNews/photo</td>\r\n<td>0</td>\r\n<td align=\"right\">0</td>\r\n<td align=\"right\">0</td>\r\n<td>False</td>\r\n<td>2021-08-30T23:59:53+00:00</td>\r\n<td>Paralympians rake in medals, India Inc showers them with rewards</td>\r\n<td>[]</td>\r\n<td>[]</td>\r\n<td>[]</td>\r\n<td>[]</td>\r\n<td>https://twitter.com/TOICitiesNews/status/1432493306152243200</td>\r\n<td>https://t.co/odmappLovL?amp=1</td>\r\n</tr>\r\n\r\n</tbody></table>\r\n<p> ... </p>\r\n</div>\r\n<hr>\r\n<br>\r\n<div id=\"keywordArgument\">\r\n<p><code>scrape_keyword()</code> arguments:</p>\r\n\r\n<table>\r\n    <thead>\r\n        <tr>\r\n            <td>Argument</td>\r\n            <td>Argument Type</td>\r\n            <td>Description</td>\r\n        </tr>\r\n    </thead>\r\n    <tbody>\r\n        <tr>\r\n            <td>keyword</td>\r\n            <td>String</td>\r\n            <td>Keyword to search on twitter. </td>\r\n        </tr>\r\n        <tr>\r\n            <td>browser</td>\r\n            <td>String</td>\r\n            <td>Which browser to use for scraping?, Only 2 are supported Chrome and Firefox,default is set to Firefox.</td>\r\n        </tr>\r\n        <tr>\r\n            <td>until</td>\r\n            <td>String</td>\r\n            <td>Optional parameter, Until date for scraping, a end date from where search ends. Format for date is YYYY-MM-DD.</td>\r\n        </tr>\r\n        <tr>\r\n            <td>since </td>\r\n            <td>String</td>\r\n            <td>Optional parameter, Since date for scraping, a past date from where to search from. Format for date is YYYY-MM-DD.</td>\r\n        </tr>\r\n        <tr>\r\n            <td>proxy</td>\r\n            <td>Integer</td>\r\n            <td>Optional parameter, if user wants to use proxy for scraping. If the proxy is authenticated proxy then the proxy format is username:password@host:port</td>\r\n        </tr>\r\n        <tr>\r\n            <td>tweets_count</td>\r\n            <td>Integer</td>\r\n            <td>Number of posts to scrape. Default is 10.</td>\r\n        </tr>\r\n        <tr>\r\n            <td>output_format</td>\r\n            <td>String</td>\r\n            <td>The output format, whether JSON or CSV. Default is JSON.</td>\r\n        </tr>\r\n        <tr>\r\n            <td>filename</td>\r\n            <td>String</td>\r\n            <td>If output parameter is set to CSV, then it is necessary for filename parameter to passed. If not passed then the filename will be same as keyword passed.</td>\r\n        </tr>\r\n        <tr>\r\n            <td>directory</td>\r\n            <td>String</td>\r\n            <td>If output parameter is set to CSV, then it is valid for directory parameter to be passed. If not passed then CSV file will be saved in current working directory.</td>\r\n        </tr>\r\n        <tr>\r\n            <td>since_id</td>\r\n            <td>Integer</td>\r\n            <td>After (NOT inclusive) a specified Snowflake ID. Example <a href=\"https://twitter.com/search?q=since_id%3A1138872932887924737%20max_id%3A1144730280353247233%20%23nasamoontunes&src=typed_query&f=live\">here</a></td>\r\n        </tr>\r\n        <tr>\r\n            <td>max_id</td>\r\n            <td>Integer</td>\r\n            <td>At or before (inclusive) a specified Snowflake ID. Example <a href=\"https://twitter.com/search?q=since_id%3A1138872932887924737%20max_id%3A1144730280353247233%20%23nasamoontunes&src=typed_query&f=live\">here</a></td>\r\n        </tr>\r\n        <tr>\r\n            <td>within_time</td>\r\n            <td>String</td>\r\n            <td>Search within the last number of days, hours, minutes, or seconds. Example <code>2d, 3h, 5m, 30s</code>.</td>\r\n        </tr>\r\n        <tr>\r\n            <td>headless</td>\r\n            <td>Boolean</td>\r\n            <td>Whether to run crawler headlessly?. Default is <code>True</code></td>\r\n        </tr>\r\n        <tr>\r\n            <td>browser_profile</td>\r\n            <td>String</td>\r\n            <td>Path to the browser profile where cookies are stored and can be used for scraping data in an authenticated way.</td>\r\n        </tr>\r\n    </tbody>\r\n</table>\r\n</div>\r\n<hr>\r\n<div id=\"keywordOutput\">\r\n<p>Keys of the output</p>\r\n\r\n<table>\r\n    <thead>\r\n        <tr>\r\n            <td>Key</td>\r\n            <td>Type</td>\r\n            <td>Description</td>\r\n        </tr>\r\n    </thead>\r\n    <tbody>\r\n        <tr>\r\n            <td>tweet_id</td>\r\n            <td>String</td>\r\n            <td>Post Identifier(integer casted inside string)</td>\r\n        </tr>\r\n        <tr>\r\n            <td>username</td>\r\n            <td>String</td>\r\n            <td>Username of the profile</td>\r\n        </tr>\r\n        <tr>\r\n            <td>name</td>\r\n            <td>String</td>\r\n            <td>Name of the profile</td>\r\n        </tr>\r\n        <tr>\r\n            <td>profile_picture</td>\r\n            <td>String</td>\r\n            <td>Profile Picture link</td>\r\n        </tr>\r\n        <tr>\r\n            <td>replies</td>\r\n            <td>Integer</td>\r\n            <td>Number of replies of tweet</td>\r\n        </tr>\r\n        <tr>\r\n            <td>retweets</td>\r\n            <td>Integer</td>\r\n            <td>Number of retweets of tweet</td>\r\n        </tr>\r\n        <tr>\r\n            <td>likes</td>\r\n            <td>Integer</td>\r\n            <td>Number of likes of tweet</td>\r\n        </tr>\r\n        <tr>\r\n            <td>is_retweet</td>\r\n            <td>boolean</td>\r\n            <td>Is the tweet a retweet?</td>\r\n        </tr>\r\n        <tr>\r\n            <td>posted_time</td>\r\n            <td>String</td>\r\n            <td>Time when tweet was posted in ISO 8601 format</td>\r\n        </tr>\r\n        <tr>\r\n            <td>content</td>\r\n            <td>String</td>\r\n            <td>content of tweet as text</td>\r\n        </tr>\r\n        <tr>\r\n            <td>hashtags</td>\r\n            <td>Array</td>\r\n            <td>Hashtags presents in tweet, if they're present in tweet</td>\r\n        </tr>\r\n        <tr>\r\n            <td>mentions</td>\r\n            <td>Array</td>\r\n            <td>Mentions presents in tweet, if they're present in tweet</td>\r\n        </tr>\r\n        <tr>\r\n            <td>images</td>\r\n            <td>Array</td>\r\n            <td>Images links, if they're present in tweet</td>\r\n        </tr>\r\n        <tr>\r\n            <td>videos</td>\r\n            <td>Array</td>\r\n            <td>Videos links, if they're present in tweet</td>\r\n        </tr>\r\n        <tr>\r\n            <td>tweet_url</td>\r\n            <td>String</td>\r\n            <td>URL of the tweet</td>\r\n        </tr>\r\n        <tr>\r\n            <td>link</td>\r\n            <td>String</td>\r\n            <td>If any link is present inside tweet for some external website. </td>\r\n        </tr>\r\n    </tbody>\r\n</table>\r\n</div>\r\n<br>\r\n<hr>\r\n<br>\r\n<h3 id=\"scrape_with_api\">To scrape topic tweets with URL using API </h3>\r\n\r\n```python\r\nfrom twitter_scraper_selenium import scrape_topic_with_api\r\n\r\ntopic_url = 'https://twitter.com/i/topics/1468157909318045697'\r\nscrape_topic_with_api(URL=topic_url, output_filename='solana_cryptocurrency', tweets_count=50)\r\n```\r\n\r\nOutput:\r\n```js\r\n{\r\n  \"1584979408338632705\": {\r\n    \"tweet_url\" : \"https://twitter.com/AptosBullCNFT/status/1584979408338632705\",\r\n    \"tweet_details\":{\r\n      ...\r\n    },\r\n    \"user_details\":{\r\n      ...\r\n    }\r\n  }, ...\r\n}\r\n```\r\n\r\n\r\n<div id=\"scrape_topic_with_api_args\">\r\n<p><code>scrape_topic_with_api()</code> arguments: </p>\r\n\r\n\r\n<table>\r\n    <thead>\r\n        <tr>\r\n            <td>Argument</td>\r\n            <td>Argument Type</td>\r\n            <td>Description</td>\r\n        </tr>\r\n    </thead>\r\n    <tbody>\r\n        <tr>\r\n            <td>URL</td>\r\n            <td>String</td>\r\n            <td>Twitter's Topic URL</td>\r\n        </tr>\r\n        <tr>\r\n            <td>tweets_count</td>\r\n            <td>Integer</td>\r\n            <td>Number of tweets to scrape.</td>\r\n        </tr>\r\n        <tr>\r\n            <td>output_filename</td>\r\n            <td>String</td>\r\n            <td>What should be the filename where output is stored?.</td>\r\n        </tr>\r\n        <tr>\r\n            <td>output_dir</td>\r\n            <td>String</td>\r\n            <td>What directory output file should be saved?</td>\r\n        </tr>\r\n        <tr>\r\n            <td>proxy</td>\r\n            <td>String</td>\r\n            <td>Optional parameter, if user wants to use proxy for scraping. If the proxy is authenticated proxy then the proxy format is username:password@host:port.</td>\r\n        </tr>\r\n        <tr>\r\n            <td>browser</td>\r\n            <td>String</td>\r\n            <td>Which browser to use for extracting out graphql key. Default is firefox.</td>\r\n        </tr>\r\n        <tr>\r\n            <td>headless</td>\r\n            <td>String</td>\r\n            <td>Whether to run browser in headless mode?</td>\r\n        </tr>\r\n    </tbody>\r\n</table>\r\n</div>\r\n<hr>\r\n\r\n<div id=\"scrape_topic_with_api_args_keys\"> <p>Keys of the output:<p>\r\n  Same as <a href=\"#scrape_keyword_with_apiKeys\">scrape_keyword_with_api</a>\r\n</div>\r\n<br>\r\n<hr>\r\n\r\n<h3 id=\"to-scrape-topic-tweets-with-url\"> To scrape topic tweets with URL using browser automation: </h3>\r\n\r\n```python\r\nfrom twitter_scraper_selenium import scrape_topic\r\n# scrape 10 tweets from steam deck topic on twitter\r\ndata = scrape_topic(filename=\"steamdeck\", url='https://twitter.com/i/topics/1415728297065861123',\r\n                     browser=\"firefox\", tweets_count=10)\r\n```\r\n\r\n<div id=\"scrape_topic_with_api_args_keys\"> <p>Keys of the output:<p>\r\n  Same as <a href=\"#profileOutput\">scrape_profile</a>\r\n</div>\r\n<hr>\r\n\r\n\r\n<div id=\"topicArgument\">\r\n<p><code>scrape_topic()</code> arguments:</p>\r\n\r\n\r\n| Arguments     | Argument <br> Type | Description                                                                                                                            |\r\n|---------------|--------------------|----------------------------------------------------------------------------------------------------------------------------------------|\r\n| filename      | str                | Filename to write result output.                                                                                                       |\r\n| URL           | str                | Topic URL.                                                                                                                             |\r\n| browser       | str                | Which browser to use for scraping? <br> Only 2 are supported Chrome and Firefox. default firefox                                       |\r\n| proxy         | str                | If user wants to use proxy for scraping. <br> If the proxy is authenticated proxy then the proxy format is username:password@host:port |\r\n| tweets_count  | int                | Number of posts to scrape. default 10.                                                                                                  |\r\n| output_format | str                | The output format whether JSON or CSV. Default json.                                                                                   |\r\n| directory     | str                | Directory to save output file. Deafult current working directory.                                                                      |\r\n| browser_profile | str | Path to the browser profile where cookies are stored and can be used for scraping data in an authenticated way. |\r\n\r\n<br>\r\n<hr>\r\n<div id=\"to-scrape-user-tweets-with-api\">\r\n\r\n<p>To Scrap profile's tweets with API:</p>\r\n\r\n```python\r\nfrom twitter_scraper_selenium import scrape_profile_with_api\r\n\r\nscrape_profile_with_api('elonmusk', output_filename='musk', tweets_count= 100)\r\n```\r\n</div>\r\n<br>\r\n<div id=\"users_api_parameter\">\r\n<p><code>scrape_profile_with_api()</code> Arguments:<p>\r\n<table>\r\n    <thead>\r\n        <tr>\r\n            <td>Argument</td>\r\n            <td>Argument Type</td>\r\n            <td>Description</td>\r\n        </tr>\r\n    </thead>\r\n    <tbody>\r\n        <tr>\r\n            <td>username</td>\r\n            <td>String</td>\r\n            <td>Twitter's Profile username</td>\r\n        </tr>\r\n        <tr>\r\n            <td>tweets_count</td>\r\n            <td>Integer</td>\r\n            <td>Number of tweets to scrape.</td>\r\n        </tr>\r\n        <tr>\r\n            <td>output_filename</td>\r\n            <td>String</td>\r\n            <td>What should be the filename where output is stored?.</td>\r\n        </tr>\r\n        <tr>\r\n            <td>output_dir</td>\r\n            <td>String</td>\r\n            <td>What directory output file should be saved?</td>\r\n        </tr>\r\n        <tr>\r\n            <td>proxy</td>\r\n            <td>String</td>\r\n            <td>Optional parameter, if user wants to use proxy for scraping. If the proxy is authenticated proxy then the proxy format is username:password@host:port.</td>\r\n        </tr>\r\n        <tr>\r\n            <td>browser</td>\r\n            <td>String</td>\r\n            <td>Which browser to use for extracting out graphql key. Default is firefox.</td>\r\n        </tr>\r\n        <tr>\r\n            <td>headless</td>\r\n            <td>String</td>\r\n            <td>Whether to run browser in headless mode?</td>\r\n        </tr>\r\n    </tbody>\r\n</table>\r\n</div>\r\n<br>\r\n<div id=\"scrape_user_with_api_args_keys\"> <p>Output:<p>\r\n\r\n```js\r\n{\r\n  \"1608939190548598784\": {\r\n    \"tweet_url\" : \"https://twitter.com/elonmusk/status/1608939190548598784\",\r\n    \"tweet_details\":{\r\n      ...\r\n    },\r\n    \"user_details\":{\r\n      ...\r\n    }\r\n  }, ...\r\n}\r\n```\r\n\r\n</div>\r\n<br>\r\n<hr>\r\n</div>\r\n\r\n<h3 id=\"proxy\"> Using scraper with proxy (http proxy) </h3>\r\n\r\n<div id=\"unauthenticatedProxy\">\r\n<p>Just pass <code>proxy</code> argument to function.</p>\r\n\r\n```python\r\nfrom twitter_scraper_selenium import scrape_keyword\r\n\r\nscrape_keyword(keyword=\"#india\", browser=\"firefox\",tweets_count=10,output=\"csv\",filename=\"india\",\r\nproxy=\"66.115.38.247:5678\") #In IP:PORT format\r\n\r\n```\r\n</div>\r\n\r\n<br>\r\n<div id=\"authenticatedProxy\">\r\n<p> Proxy that requires authentication: </p>\r\n\r\n```python\r\n\r\nfrom twitter_scraper_selenium import scrape_profile\r\n\r\nmicrosoft_data = scrape_profile(twitter_username=\"microsoft\", browser=\"chrome\", tweets_count=10, output=\"json\",\r\n                      proxy=\"sajid:pass123@66.115.38.247:5678\")  #  username:password@IP:PORT\r\nprint(microsoft_data)\r\n\r\n\r\n```\r\n\r\n</div>\r\n<br>\r\n<hr>\r\n<div id=\"privacy\">\r\n<h2>Privacy</h2>\r\n\r\n<p>\r\nThis scraper only scrapes public data available to unauthenticated user and does not holds the capability to scrape anything private.\r\n</p>\r\n</div>\r\n<br>\r\n<hr>\r\n<div id=\"license\">\r\n<h2>LICENSE</h2>\r\n\r\nMIT\r\n</div>\r\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/shaikhsajid1111/twitter-scraper-selenium",
    "keywords": "web-scraping selenium social media twitter keyword twitter-profile twitter-keywords automation json csv twitter-hashtag hashtag",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "twitter-scraper-selenium",
    "package_url": "https://pypi.org/project/twitter-scraper-selenium/",
    "platform": null,
    "project_url": "https://pypi.org/project/twitter-scraper-selenium/",
    "project_urls": {
      "Homepage": "https://github.com/shaikhsajid1111/twitter-scraper-selenium"
    },
    "release_url": "https://pypi.org/project/twitter-scraper-selenium/4.1.4/",
    "requires_dist": [
      "python-dateutil (==2.8.2)",
      "selenium (==4.7.0)",
      "selenium-wire (==5.1.0)",
      "webdriver-manager (==3.2.2)",
      "fake-headers (==1.0.2)",
      "requests (==2.27.1)"
    ],
    "requires_python": ">=3.6",
    "summary": "Python package to scrap twitter's front-end easily with selenium",
    "version": "4.1.4",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16426514,
  "releases": {
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ccb37e409faa27eea55ea104d9e4c6fc7350901ee8eef57e9faaff5678d86727",
          "md5": "cd2105b7f3c1021ead3f6599be94e27e",
          "sha256": "f109b69b4e162481741d182bce74e867b078529cd665fc0285636f718ca37c0a"
        },
        "downloads": -1,
        "filename": "twitter_scraper_selenium-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "cd2105b7f3c1021ead3f6599be94e27e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 14523,
        "upload_time": "2021-11-01T04:44:24",
        "upload_time_iso_8601": "2021-11-01T04:44:24.893717Z",
        "url": "https://files.pythonhosted.org/packages/cc/b3/7e409faa27eea55ea104d9e4c6fc7350901ee8eef57e9faaff5678d86727/twitter_scraper_selenium-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bd988d658262729ebe4f611135cab0dce6dc10809d6ae9d93aa6e9df648b9d5e",
          "md5": "1f59edc9542833d19bd782f0dd44f7e4",
          "sha256": "0c086fecffeae25334383db396b1fff6bc6b410b5a604532a9e65e33802f83eb"
        },
        "downloads": -1,
        "filename": "twitter_scraper_selenium-0.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "1f59edc9542833d19bd782f0dd44f7e4",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 14248,
        "upload_time": "2022-03-18T10:29:03",
        "upload_time_iso_8601": "2022-03-18T10:29:03.928735Z",
        "url": "https://files.pythonhosted.org/packages/bd/98/8d658262729ebe4f611135cab0dce6dc10809d6ae9d93aa6e9df648b9d5e/twitter_scraper_selenium-0.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "266257bd456f0f093bcb7dba3a0e4595c406d204797ba15903d9246252e5673e",
          "md5": "c11a1fcf5c40ebf3d4114fc91d5a57d4",
          "sha256": "5df15e2801dd93c7709dec6e86c7e6d3c987f701ae28f66f4c0337601a5e9e9a"
        },
        "downloads": -1,
        "filename": "twitter_scraper_selenium-0.1.3-py3.10.egg",
        "has_sig": false,
        "md5_digest": "c11a1fcf5c40ebf3d4114fc91d5a57d4",
        "packagetype": "bdist_egg",
        "python_version": "0.1.3",
        "requires_python": ">=3.6",
        "size": 28547,
        "upload_time": "2022-04-13T11:51:19",
        "upload_time_iso_8601": "2022-04-13T11:51:19.841329Z",
        "url": "https://files.pythonhosted.org/packages/26/62/57bd456f0f093bcb7dba3a0e4595c406d204797ba15903d9246252e5673e/twitter_scraper_selenium-0.1.3-py3.10.egg",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d9cffe9cbd38346acedb0b441130e9efc843936a947ff3086e1c779361676c68",
          "md5": "46f04c9a5ec328f2a07bcba6c42015dc",
          "sha256": "1097fdec1a1ae0c6b71fe0933bf5536c44b64f59e53f43d6405082c27e12a917"
        },
        "downloads": -1,
        "filename": "twitter_scraper_selenium-0.1.3.tar.gz",
        "has_sig": false,
        "md5_digest": "46f04c9a5ec328f2a07bcba6c42015dc",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 14266,
        "upload_time": "2022-04-03T06:44:36",
        "upload_time_iso_8601": "2022-04-03T06:44:36.481634Z",
        "url": "https://files.pythonhosted.org/packages/d9/cf/fe9cbd38346acedb0b441130e9efc843936a947ff3086e1c779361676c68/twitter_scraper_selenium-0.1.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a44d84f506e38cac46d2f29c33be6ef5d2768deff679ec1e7605cf6713d188d8",
          "md5": "58b519fe2722294524a10bc0cfca5b33",
          "sha256": "df2ed32f3da66d1f5340069685e4d9fb698e83e6f7979a5e35a1819e845778ae"
        },
        "downloads": -1,
        "filename": "twitter_scraper_selenium-0.1.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "58b519fe2722294524a10bc0cfca5b33",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 15583,
        "upload_time": "2022-04-13T11:51:13",
        "upload_time_iso_8601": "2022-04-13T11:51:13.875914Z",
        "url": "https://files.pythonhosted.org/packages/a4/4d/84f506e38cac46d2f29c33be6ef5d2768deff679ec1e7605cf6713d188d8/twitter_scraper_selenium-0.1.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8880630ad3d7c96a53db91bd5ea434729bdb523f6e397fb51a657fed56be009a",
          "md5": "228a350de05eb7a4a836cc5b46eb295b",
          "sha256": "5ff90fb73d9a64b6ac421ed31834157e5f343204bb18177dfe8d856f2ac60b16"
        },
        "downloads": -1,
        "filename": "twitter_scraper_selenium-0.1.4.tar.gz",
        "has_sig": false,
        "md5_digest": "228a350de05eb7a4a836cc5b46eb295b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 15538,
        "upload_time": "2022-04-13T11:51:21",
        "upload_time_iso_8601": "2022-04-13T11:51:21.527003Z",
        "url": "https://files.pythonhosted.org/packages/88/80/630ad3d7c96a53db91bd5ea434729bdb523f6e397fb51a657fed56be009a/twitter_scraper_selenium-0.1.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "660f17ddfc6f90ad1a8d0e90cce49b4342775c499ea025a913da474a8be8268f",
          "md5": "0226238599d89680c630e7e387b9764a",
          "sha256": "a2c6592ad92c59cd9dd47b57fd82df189a914e4ac920a7ac74a58aefbd225929"
        },
        "downloads": -1,
        "filename": "twitter_scraper_selenium-0.1.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0226238599d89680c630e7e387b9764a",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 15577,
        "upload_time": "2022-04-14T08:01:54",
        "upload_time_iso_8601": "2022-04-14T08:01:54.007970Z",
        "url": "https://files.pythonhosted.org/packages/66/0f/17ddfc6f90ad1a8d0e90cce49b4342775c499ea025a913da474a8be8268f/twitter_scraper_selenium-0.1.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d3437734dded5a6c3fd61228ee0aeeb1a09d95682e57a7ff7cf39db781343899",
          "md5": "64dd881d327c670ba75b9639e884f794",
          "sha256": "2226ed9ba368d7e3e6c7ba18c87ab8dfc5a1d105ac5be69bbc30df540c46fe27"
        },
        "downloads": -1,
        "filename": "twitter_scraper_selenium-0.1.5.tar.gz",
        "has_sig": false,
        "md5_digest": "64dd881d327c670ba75b9639e884f794",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 15563,
        "upload_time": "2022-04-14T08:02:01",
        "upload_time_iso_8601": "2022-04-14T08:02:01.332807Z",
        "url": "https://files.pythonhosted.org/packages/d3/43/7734dded5a6c3fd61228ee0aeeb1a09d95682e57a7ff7cf39db781343899/twitter_scraper_selenium-0.1.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b25dbd7ed256cdfe285479cf2245fb38491d28c8abe9c2c6f4c6c6e5451e40a9",
          "md5": "a9e3a82b2c68686de0a2ba0f0771bce7",
          "sha256": "77ae7ca07fba512dfc531f8f3717302a384be04c920d468ab7b9b65aebdda725"
        },
        "downloads": -1,
        "filename": "twitter_scraper_selenium-0.1.6.tar.gz",
        "has_sig": false,
        "md5_digest": "a9e3a82b2c68686de0a2ba0f0771bce7",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 16624,
        "upload_time": "2022-05-22T05:11:44",
        "upload_time_iso_8601": "2022-05-22T05:11:44.899342Z",
        "url": "https://files.pythonhosted.org/packages/b2/5d/bd7ed256cdfe285479cf2245fb38491d28c8abe9c2c6f4c6c6e5451e40a9/twitter_scraper_selenium-0.1.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4621a29f183e937f0bb5ea64ecb314bc0e8e60d76ba71c6869766a9f802d2a0e",
          "md5": "2df84ab48ec54732b5d6b7d24f72927d",
          "sha256": "1fbf8be722b75d9deaf1f78979720b5e14fe25e69aebd0af5b6e892df326c928"
        },
        "downloads": -1,
        "filename": "twitter_scraper_selenium-0.1.7.tar.gz",
        "has_sig": false,
        "md5_digest": "2df84ab48ec54732b5d6b7d24f72927d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 15674,
        "upload_time": "2022-06-13T07:41:02",
        "upload_time_iso_8601": "2022-06-13T07:41:02.438094Z",
        "url": "https://files.pythonhosted.org/packages/46/21/a29f183e937f0bb5ea64ecb314bc0e8e60d76ba71c6869766a9f802d2a0e/twitter_scraper_selenium-0.1.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "2.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "49efd814a9f0eeb37b5fb57179f3531f39839113e80d740a2872ddc1e1e05414",
          "md5": "c9c4d6ad0646c5c899a74de627283838",
          "sha256": "cd9ba382f011afb3a79b66614a7ac7fbb36228b4b840c1baf8e6bb58698e4ffb"
        },
        "downloads": -1,
        "filename": "twitter_scraper_selenium-2.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "c9c4d6ad0646c5c899a74de627283838",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 16671,
        "upload_time": "2022-07-09T12:36:56",
        "upload_time_iso_8601": "2022-07-09T12:36:56.305429Z",
        "url": "https://files.pythonhosted.org/packages/49/ef/d814a9f0eeb37b5fb57179f3531f39839113e80d740a2872ddc1e1e05414/twitter_scraper_selenium-2.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0aab0832ca3227278e5b3b61c401cf9d7aa9bb09a28b9943470991c9bf647fc2",
          "md5": "d049ca63318b2021b4f1b9ab2e5b68e7",
          "sha256": "fef8f736d91f31eea4cccf07199f14ac0aa0a931bc7942535ea74dc968a4a45e"
        },
        "downloads": -1,
        "filename": "twitter_scraper_selenium-2.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "d049ca63318b2021b4f1b9ab2e5b68e7",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 16799,
        "upload_time": "2022-07-09T12:36:58",
        "upload_time_iso_8601": "2022-07-09T12:36:58.622779Z",
        "url": "https://files.pythonhosted.org/packages/0a/ab/0832ca3227278e5b3b61c401cf9d7aa9bb09a28b9943470991c9bf647fc2/twitter_scraper_selenium-2.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "3.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d95ab82b790404d52f8c2522caa075bc1fa9bf3edc8c0cee81f9decf0cebb80e",
          "md5": "66ccbeb57d1226d7058dcd29806e489f",
          "sha256": "d2f98715e59606ed3d587c9a1a24341733a0de6e4a936654dc4fa91dd3095cc5"
        },
        "downloads": -1,
        "filename": "twitter_scraper_selenium-3.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "66ccbeb57d1226d7058dcd29806e489f",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 19351,
        "upload_time": "2022-10-02T12:19:52",
        "upload_time_iso_8601": "2022-10-02T12:19:52.556404Z",
        "url": "https://files.pythonhosted.org/packages/d9/5a/b82b790404d52f8c2522caa075bc1fa9bf3edc8c0cee81f9decf0cebb80e/twitter_scraper_selenium-3.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e3168042b6897e3dc4039494268688c213833fb50e3feb09ff845d046f3f7264",
          "md5": "dccbf334668ce46eaa31edb7372d007d",
          "sha256": "894e4d22ea779b7e85aeefcdfac0e01ae274f58055796e1e994d8111c4cf2cf1"
        },
        "downloads": -1,
        "filename": "twitter_scraper_selenium-3.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "dccbf334668ce46eaa31edb7372d007d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 18863,
        "upload_time": "2022-10-02T12:19:55",
        "upload_time_iso_8601": "2022-10-02T12:19:55.223451Z",
        "url": "https://files.pythonhosted.org/packages/e3/16/8042b6897e3dc4039494268688c213833fb50e3feb09ff845d046f3f7264/twitter_scraper_selenium-3.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "3.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7ac714112d32eda925791b5e9c688e48f573caccf8cc201a57c4d036a39deccf",
          "md5": "5e69e9c02145741a5197d0efa2ddecdb",
          "sha256": "a6b5d12e1765d3c900f6a3b9084779fe3e14936885ff598bb2b6be3b9c1bf920"
        },
        "downloads": -1,
        "filename": "twitter_scraper_selenium-3.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "5e69e9c02145741a5197d0efa2ddecdb",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 19887,
        "upload_time": "2022-10-05T10:02:45",
        "upload_time_iso_8601": "2022-10-05T10:02:45.136825Z",
        "url": "https://files.pythonhosted.org/packages/7a/c7/14112d32eda925791b5e9c688e48f573caccf8cc201a57c4d036a39deccf/twitter_scraper_selenium-3.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c9192357225414b1233e885f2458a621885a7a958227139088a5dc4461a83b5f",
          "md5": "699b101f161bad48891d0180ceb9c5b4",
          "sha256": "3b237429d8c85097e36f5faea86b1faddbefc3ac351864f8dacbc8a70d1f13ff"
        },
        "downloads": -1,
        "filename": "twitter_scraper_selenium-3.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "699b101f161bad48891d0180ceb9c5b4",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 18938,
        "upload_time": "2022-10-05T10:02:48",
        "upload_time_iso_8601": "2022-10-05T10:02:48.643450Z",
        "url": "https://files.pythonhosted.org/packages/c9/19/2357225414b1233e885f2458a621885a7a958227139088a5dc4461a83b5f/twitter_scraper_selenium-3.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "3.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "44ac60e222e1e28dd7d2ea093613c8abe818e94996257887ecb9168102170056",
          "md5": "beebc8260f9be80415c60a5e9f16ffbc",
          "sha256": "5cbfffea71fdee01fa0d7c84c27112597338df79a84fb4d4f374378e2ff7ea68"
        },
        "downloads": -1,
        "filename": "twitter_scraper_selenium-3.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "beebc8260f9be80415c60a5e9f16ffbc",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 21317,
        "upload_time": "2022-10-09T08:23:59",
        "upload_time_iso_8601": "2022-10-09T08:23:59.342901Z",
        "url": "https://files.pythonhosted.org/packages/44/ac/60e222e1e28dd7d2ea093613c8abe818e94996257887ecb9168102170056/twitter_scraper_selenium-3.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7c66d24effff85496379a5f841dfdf8ccd22f610dbd88f98b932949f1a01101d",
          "md5": "9a591f7e1086ee1f16bbe036a7c1e2e0",
          "sha256": "13b775257bfdcdf6cc20bf49a8485b7d647515b553b99b5dbfdb2b395a92c6b0"
        },
        "downloads": -1,
        "filename": "twitter_scraper_selenium-3.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "9a591f7e1086ee1f16bbe036a7c1e2e0",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 19675,
        "upload_time": "2022-10-09T08:24:05",
        "upload_time_iso_8601": "2022-10-09T08:24:05.215609Z",
        "url": "https://files.pythonhosted.org/packages/7c/66/d24effff85496379a5f841dfdf8ccd22f610dbd88f98b932949f1a01101d/twitter_scraper_selenium-3.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "3.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6a52a373118106d6d61f097a5b0278643379e7cc7c407a0ed27869ac30435cb9",
          "md5": "4afc83af6662163cf9c1862c77dd4501",
          "sha256": "1e309978b61e43d8f0bc11e589ff4f0d183e83edc698f0b3c18d73d59bdcf59c"
        },
        "downloads": -1,
        "filename": "twitter_scraper_selenium-3.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "4afc83af6662163cf9c1862c77dd4501",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 21326,
        "upload_time": "2022-10-09T09:14:44",
        "upload_time_iso_8601": "2022-10-09T09:14:44.745716Z",
        "url": "https://files.pythonhosted.org/packages/6a/52/a373118106d6d61f097a5b0278643379e7cc7c407a0ed27869ac30435cb9/twitter_scraper_selenium-3.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f7949aa09e391ec5c035f1ad66c82a8c8bb6ecdf1154507a9ceda6c1027d05cb",
          "md5": "5efc9e0ac1507ea64e44b666db7996de",
          "sha256": "293109e9348eac8f70b84b643c009e1966b18b77f83d968cb96c9d8f8dfa5dcb"
        },
        "downloads": -1,
        "filename": "twitter_scraper_selenium-3.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "5efc9e0ac1507ea64e44b666db7996de",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 19774,
        "upload_time": "2022-10-09T09:14:51",
        "upload_time_iso_8601": "2022-10-09T09:14:51.087462Z",
        "url": "https://files.pythonhosted.org/packages/f7/94/9aa09e391ec5c035f1ad66c82a8c8bb6ecdf1154507a9ceda6c1027d05cb/twitter_scraper_selenium-3.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "3.1.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "75463a778c3859799796323f783da98c4f643136f8f325313b52a0ddb6e5491e",
          "md5": "d266ce0106ebb8acdb103ec9e870fa67",
          "sha256": "b13dc54ab6e89f24609878809dfcf15e4b991695f851e6407df4a7fc05e2d09e"
        },
        "downloads": -1,
        "filename": "twitter_scraper_selenium-3.1.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d266ce0106ebb8acdb103ec9e870fa67",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 24809,
        "upload_time": "2022-10-22T14:33:12",
        "upload_time_iso_8601": "2022-10-22T14:33:12.853321Z",
        "url": "https://files.pythonhosted.org/packages/75/46/3a778c3859799796323f783da98c4f643136f8f325313b52a0ddb6e5491e/twitter_scraper_selenium-3.1.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e21de5d8b1d2e5639f25dbc6ec136678fce8c104f42a3d93dcd10c9056b30c49",
          "md5": "9310eff0b4ca8ce774da4a5c35267ea0",
          "sha256": "f540e0582da914cc88473bc36e5cb7697b9db4cae95fab00ddec321417d48ffa"
        },
        "downloads": -1,
        "filename": "twitter_scraper_selenium-3.1.3.tar.gz",
        "has_sig": false,
        "md5_digest": "9310eff0b4ca8ce774da4a5c35267ea0",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 22847,
        "upload_time": "2022-10-22T14:33:21",
        "upload_time_iso_8601": "2022-10-22T14:33:21.547455Z",
        "url": "https://files.pythonhosted.org/packages/e2/1d/e5d8b1d2e5639f25dbc6ec136678fce8c104f42a3d93dcd10c9056b30c49/twitter_scraper_selenium-3.1.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "3.2.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e28f6e4ad14d2b17003dbbb34b94990d89df5f1b59bb4bff92f36eaf9b5095cc",
          "md5": "295a3a1a5a7baad516290062bab7d2d8",
          "sha256": "7356096ce98f05357bab5a0eb1d5ac1a8fe831922203ee30a081bd1718648833"
        },
        "downloads": -1,
        "filename": "twitter_scraper_selenium-3.2.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "295a3a1a5a7baad516290062bab7d2d8",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 27127,
        "upload_time": "2022-10-23T06:03:19",
        "upload_time_iso_8601": "2022-10-23T06:03:19.231135Z",
        "url": "https://files.pythonhosted.org/packages/e2/8f/6e4ad14d2b17003dbbb34b94990d89df5f1b59bb4bff92f36eaf9b5095cc/twitter_scraper_selenium-3.2.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f5be6dd42f86b99dcc9ac26562d91ee7fce11a332bcc3a0254c74f1be4c09e0f",
          "md5": "6bc290009cdaf2e9d3e4aeb8d768686b",
          "sha256": "9028c507abb6f9163a515a7be743ed972be6517cea97dd15302d80cbc6f4180d"
        },
        "downloads": -1,
        "filename": "twitter_scraper_selenium-3.2.3.tar.gz",
        "has_sig": false,
        "md5_digest": "6bc290009cdaf2e9d3e4aeb8d768686b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 25347,
        "upload_time": "2022-10-23T06:03:28",
        "upload_time_iso_8601": "2022-10-23T06:03:28.439093Z",
        "url": "https://files.pythonhosted.org/packages/f5/be/6dd42f86b99dcc9ac26562d91ee7fce11a332bcc3a0254c74f1be4c09e0f/twitter_scraper_selenium-3.2.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "3.2.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "da8c932c94a5635181b57795c64799da96a3e1b8436d7656fc26192172e4b7ef",
          "md5": "ac67e4847b2c913bce4c5d311123bf6f",
          "sha256": "fa43f1a81efe9187d819e96cc347f376fb5ecc2d3e894849d425e98435dce7c4"
        },
        "downloads": -1,
        "filename": "twitter_scraper_selenium-3.2.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ac67e4847b2c913bce4c5d311123bf6f",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 26933,
        "upload_time": "2022-10-26T06:45:55",
        "upload_time_iso_8601": "2022-10-26T06:45:55.667406Z",
        "url": "https://files.pythonhosted.org/packages/da/8c/932c94a5635181b57795c64799da96a3e1b8436d7656fc26192172e4b7ef/twitter_scraper_selenium-3.2.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "66efc9201a11d6fd6f819b1ee22f8cc9c9403acd5bae9564e963786e561c491e",
          "md5": "c3fecfd03be81be666dacb8bc2f20730",
          "sha256": "54cc7859df345d9aa8b6195a9269c2c55a1d518aee0458eda48fe66dbebf0a91"
        },
        "downloads": -1,
        "filename": "twitter_scraper_selenium-3.2.4.tar.gz",
        "has_sig": false,
        "md5_digest": "c3fecfd03be81be666dacb8bc2f20730",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 25090,
        "upload_time": "2022-10-26T06:45:57",
        "upload_time_iso_8601": "2022-10-26T06:45:57.952347Z",
        "url": "https://files.pythonhosted.org/packages/66/ef/c9201a11d6fd6f819b1ee22f8cc9c9403acd5bae9564e963786e561c491e/twitter_scraper_selenium-3.2.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "4.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b2510f14472d2d9d0c8057ee871189507743028104a9e858802eee8185788092",
          "md5": "f4239ab940a1f4313b5b4536c2d5548a",
          "sha256": "81e2d4156f09de9200a1109a18863154936eaa257b4f4a5ae5db4981fcd42280"
        },
        "downloads": -1,
        "filename": "twitter_scraper_selenium-4.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f4239ab940a1f4313b5b4536c2d5548a",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 30550,
        "upload_time": "2022-10-26T11:53:41",
        "upload_time_iso_8601": "2022-10-26T11:53:41.731613Z",
        "url": "https://files.pythonhosted.org/packages/b2/51/0f14472d2d9d0c8057ee871189507743028104a9e858802eee8185788092/twitter_scraper_selenium-4.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6bf207569a36dae37eba15f7834001eabb2b52baaa39ba43c5b789335b9e2131",
          "md5": "defcb48131ab304885381a5db2a345fc",
          "sha256": "0ff3963be65f96b0fb07215b027518a0411a9862141d6d1f521e27b7326ac022"
        },
        "downloads": -1,
        "filename": "twitter_scraper_selenium-4.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "defcb48131ab304885381a5db2a345fc",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 32439,
        "upload_time": "2022-10-26T11:53:44",
        "upload_time_iso_8601": "2022-10-26T11:53:44.525638Z",
        "url": "https://files.pythonhosted.org/packages/6b/f2/07569a36dae37eba15f7834001eabb2b52baaa39ba43c5b789335b9e2131/twitter_scraper_selenium-4.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "4.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9968f66a0094d63f0e488a07ca3ce31554797c05304ac10a15cc0833c4c438f2",
          "md5": "3e0d3b2a0fc2dea63def387cb3d759a1",
          "sha256": "4ab29382a0025c77e9978f5f94d71e64e2153c5acbde762d0015f846836d72da"
        },
        "downloads": -1,
        "filename": "twitter_scraper_selenium-4.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "3e0d3b2a0fc2dea63def387cb3d759a1",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 30561,
        "upload_time": "2022-10-29T07:14:14",
        "upload_time_iso_8601": "2022-10-29T07:14:14.137867Z",
        "url": "https://files.pythonhosted.org/packages/99/68/f66a0094d63f0e488a07ca3ce31554797c05304ac10a15cc0833c4c438f2/twitter_scraper_selenium-4.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f851c27cf834e5b95ae393041e3f25fcce0c3b888b09548743c776a86caee917",
          "md5": "860d20e17c57bc054532bd2a66bbaabf",
          "sha256": "9991b84c3eaa3bb45773ce08706a033eb0a85321731cba8baf805dea478b89cc"
        },
        "downloads": -1,
        "filename": "twitter_scraper_selenium-4.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "860d20e17c57bc054532bd2a66bbaabf",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 32499,
        "upload_time": "2022-10-29T07:14:18",
        "upload_time_iso_8601": "2022-10-29T07:14:18.533558Z",
        "url": "https://files.pythonhosted.org/packages/f8/51/c27cf834e5b95ae393041e3f25fcce0c3b888b09548743c776a86caee917/twitter_scraper_selenium-4.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "4.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5331f326b8bb82792d0404f51069aa7107f5e5cab963a92432110118802f5066",
          "md5": "168bdcbe90d454082b4329f675218554",
          "sha256": "75de5baeb28c214afdb3a69233cfa6692ecfcb9f152593f4797d87a2dab4d085"
        },
        "downloads": -1,
        "filename": "twitter_scraper_selenium-4.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "168bdcbe90d454082b4329f675218554",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 30579,
        "upload_time": "2022-12-03T04:27:50",
        "upload_time_iso_8601": "2022-12-03T04:27:50.131972Z",
        "url": "https://files.pythonhosted.org/packages/53/31/f326b8bb82792d0404f51069aa7107f5e5cab963a92432110118802f5066/twitter_scraper_selenium-4.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0643ecdaf15d6096720fb8d38db01180ac11c1a7d0bd9455464e8855b72bf5a0",
          "md5": "987bd664d24fba44fa2c0fa99259b3ab",
          "sha256": "e40e531ede0956bd0ba32dd510371473d840eed72b2ef79e4ecf8faaee390955"
        },
        "downloads": -1,
        "filename": "twitter_scraper_selenium-4.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "987bd664d24fba44fa2c0fa99259b3ab",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 32530,
        "upload_time": "2022-12-03T04:27:56",
        "upload_time_iso_8601": "2022-12-03T04:27:56.305557Z",
        "url": "https://files.pythonhosted.org/packages/06/43/ecdaf15d6096720fb8d38db01180ac11c1a7d0bd9455464e8855b72bf5a0/twitter_scraper_selenium-4.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "4.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b26118cfe286629e76376edda8d7fb6713753ce949ad997797fdf4d49b44a4d3",
          "md5": "300836e799cfe2b1488bd072ec009d6d",
          "sha256": "7a7a2c28c11e5e6b764cc0216d0999ddb11c46c4bb20103bb1b8c9f70886b875"
        },
        "downloads": -1,
        "filename": "twitter_scraper_selenium-4.1.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "300836e799cfe2b1488bd072ec009d6d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 33707,
        "upload_time": "2022-12-31T06:02:59",
        "upload_time_iso_8601": "2022-12-31T06:02:59.531769Z",
        "url": "https://files.pythonhosted.org/packages/b2/61/18cfe286629e76376edda8d7fb6713753ce949ad997797fdf4d49b44a4d3/twitter_scraper_selenium-4.1.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "baf6ac8cb30e571d31a8f0421fa8a46cc0372a321dfe0694d42e937e9a9ca67b",
          "md5": "28db3fea5935da478857af8077c7897d",
          "sha256": "2d34ca8b02a70e30c0f3e5681435af056db2832471e2e57c9b2aab812bff14e7"
        },
        "downloads": -1,
        "filename": "twitter_scraper_selenium-4.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "28db3fea5935da478857af8077c7897d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 34936,
        "upload_time": "2022-12-31T06:03:03",
        "upload_time_iso_8601": "2022-12-31T06:03:03.758545Z",
        "url": "https://files.pythonhosted.org/packages/ba/f6/ac8cb30e571d31a8f0421fa8a46cc0372a321dfe0694d42e937e9a9ca67b/twitter_scraper_selenium-4.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "4.1.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fb1448db7422b455bf028349d7e1be64583add76d59eaca031ea5dc3caa79c6a",
          "md5": "21a1ce86467c1c38c9ddf0794064fd97",
          "sha256": "69af84dcd9704337b4e5ea85e6d19f8967af9578ec10b1137b9ef2f28ef854d5"
        },
        "downloads": -1,
        "filename": "twitter_scraper_selenium-4.1.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "21a1ce86467c1c38c9ddf0794064fd97",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 33744,
        "upload_time": "2022-12-31T06:15:37",
        "upload_time_iso_8601": "2022-12-31T06:15:37.231536Z",
        "url": "https://files.pythonhosted.org/packages/fb/14/48db7422b455bf028349d7e1be64583add76d59eaca031ea5dc3caa79c6a/twitter_scraper_selenium-4.1.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "526c01f1b04a5f4d32a54b497ff6979a019ba5b8356ab3f7ebf4082cf03f4d28",
          "md5": "3afed210f9d17358374ac61fc3e471c3",
          "sha256": "54aff1c22f78ec2cb127216fa7fd40b0a4fe6ecdda620b4f363c11aa9032c6ee"
        },
        "downloads": -1,
        "filename": "twitter_scraper_selenium-4.1.3.tar.gz",
        "has_sig": false,
        "md5_digest": "3afed210f9d17358374ac61fc3e471c3",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 35071,
        "upload_time": "2022-12-31T06:15:41",
        "upload_time_iso_8601": "2022-12-31T06:15:41.920104Z",
        "url": "https://files.pythonhosted.org/packages/52/6c/01f1b04a5f4d32a54b497ff6979a019ba5b8356ab3f7ebf4082cf03f4d28/twitter_scraper_selenium-4.1.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "4.1.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e7cef7d35c1d6e34d323fce7d07b6c921c5134073513a87b7dff35ff0fc81fac",
          "md5": "4b967ec4fa5de8fdb7037b443d4f1b4c",
          "sha256": "d153684e1ebbe92c4516ef720bc67f5100b0b24607fc10cfed966b3ae8108bc6"
        },
        "downloads": -1,
        "filename": "twitter_scraper_selenium-4.1.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "4b967ec4fa5de8fdb7037b443d4f1b4c",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 33765,
        "upload_time": "2023-01-14T10:04:43",
        "upload_time_iso_8601": "2023-01-14T10:04:43.726976Z",
        "url": "https://files.pythonhosted.org/packages/e7/ce/f7d35c1d6e34d323fce7d07b6c921c5134073513a87b7dff35ff0fc81fac/twitter_scraper_selenium-4.1.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f41bbb84fb652f129ad2b143daecc1a67c198f4bd9e15070ab9160b4b494de7c",
          "md5": "0acf96c78225e3a854568cec721c95e0",
          "sha256": "f11530cc3203e9619b17141aae6453ef839ab6d88bf8009bae280d63e8afc1b6"
        },
        "downloads": -1,
        "filename": "twitter_scraper_selenium-4.1.4.tar.gz",
        "has_sig": false,
        "md5_digest": "0acf96c78225e3a854568cec721c95e0",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 35135,
        "upload_time": "2023-01-14T10:04:45",
        "upload_time_iso_8601": "2023-01-14T10:04:45.782055Z",
        "url": "https://files.pythonhosted.org/packages/f4/1b/bb84fb652f129ad2b143daecc1a67c198f4bd9e15070ab9160b4b494de7c/twitter_scraper_selenium-4.1.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "e7cef7d35c1d6e34d323fce7d07b6c921c5134073513a87b7dff35ff0fc81fac",
        "md5": "4b967ec4fa5de8fdb7037b443d4f1b4c",
        "sha256": "d153684e1ebbe92c4516ef720bc67f5100b0b24607fc10cfed966b3ae8108bc6"
      },
      "downloads": -1,
      "filename": "twitter_scraper_selenium-4.1.4-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "4b967ec4fa5de8fdb7037b443d4f1b4c",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 33765,
      "upload_time": "2023-01-14T10:04:43",
      "upload_time_iso_8601": "2023-01-14T10:04:43.726976Z",
      "url": "https://files.pythonhosted.org/packages/e7/ce/f7d35c1d6e34d323fce7d07b6c921c5134073513a87b7dff35ff0fc81fac/twitter_scraper_selenium-4.1.4-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "f41bbb84fb652f129ad2b143daecc1a67c198f4bd9e15070ab9160b4b494de7c",
        "md5": "0acf96c78225e3a854568cec721c95e0",
        "sha256": "f11530cc3203e9619b17141aae6453ef839ab6d88bf8009bae280d63e8afc1b6"
      },
      "downloads": -1,
      "filename": "twitter_scraper_selenium-4.1.4.tar.gz",
      "has_sig": false,
      "md5_digest": "0acf96c78225e3a854568cec721c95e0",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 35135,
      "upload_time": "2023-01-14T10:04:45",
      "upload_time_iso_8601": "2023-01-14T10:04:45.782055Z",
      "url": "https://files.pythonhosted.org/packages/f4/1b/bb84fb652f129ad2b143daecc1a67c198f4bd9e15070ab9160b4b494de7c/twitter_scraper_selenium-4.1.4.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}