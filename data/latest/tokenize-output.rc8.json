{
  "info": {
    "author": "anki-code",
    "author_email": "author@example.com",
    "bugtrack_url": null,
    "classifiers": [
      "Programming Language :: Python"
    ],
    "description": "<p align=\"center\">\nGet identifiers, names, paths, URLs and words from the command output.<br> \nThe <a href=\"https://github.com/anki-code/xontrib-output-search\">xontrib-output-search</a> for <a href=\"https://xon.sh/\">xonsh shell</a> is using this library.\n</p>\n\n<p align=\"center\">  \nIf you like the idea click ‚≠ê on the repo and stay tuned by watching releases.\n</p>\n\n## Install\n```shell script\npip install -U tokenize-output\n```\n\n## Usage\n\nYou can use `tokenize-output` command as well as export the tokenizers in Python:\n```python\nfrom tokenize_output.tokenize_output import *\ntokenizer_split(\"Hello world!\")\n# {'final': set(), 'new': {'Hello', 'world!'}}\n```\n\n#### Words tokenizing\n```shell script\necho \"Try https://github.com/xxh/xxh\" | tokenize-output -p\n# Try\n# https://github.com/xxh/xxh\n```\n\n#### JSON, Python dict and JavaScript object tokenizing\n```shell script\necho '{\"Try\": \"xonsh shell\"}' | tokenize-output -p\n# Try\n# shell\n# xonsh\n# xonsh shell\n```    \n\n#### env tokenizing\n```shell script\necho 'PATH=/one/two:/three/four' | tokenize-output -p\n# /one/two\n# /one/two:/three/four\n# /three/four\n# PATH\n```    \n\n## Development\n\n### Tokenizers\nTokenizer is a functions which extract tokens from the text.\n\n| Priority | Tokenizer  | Text  | Tokens |\n| ---------| ---------- | ----- | ------ |\n| 1        | **dict**   | `{\"key\": \"val as str\"}` | `key`, `val as str` |\n| 2        | **env**    | `PATH=/bin:/etc` | `PATH`, `/bin:/etc`, `/bin`, `/etc` |   \n| 3        | **split**  | `Split  me \\n now!` | `Split`, `me`, `now!` |   \n| 4        | **strip**  | `{Hello}` | `Hello` |   \n\nYou can create your tokenizer and add it to `tokenizers_all` in `tokenize_output.py`.\n\nTokenizing is a recursive process where every tokenizer returns `final` and `new` tokens. \nThe `final` tokens directly go to the result list of tokens. The `new` tokens go to all \ntokenizers again to find new tokens. As result if there is a mix of json and env data \nin the output it will be found and tokenized in appropriate way.  \n\n### How to add tokenizer\n\nYou can start from `env` tokenizer:\n\n1. [Prepare regexp](https://github.com/tokenizer/tokenize-output/blob/25b930cfadf8291e72a72144962e411e47d28139/tokenize_output/tokenize_output.py#L10)\n2. [Prepare tokenizer function](https://github.com/tokenizer/tokenize-output/blob/25b930cfadf8291e72a72144962e411e47d28139/tokenize_output/tokenize_output.py#L57-L70)\n3. [Add the function to the list](https://github.com/tokenizer/tokenize-output/blob/25b930cfadf8291e72a72144962e411e47d28139/tokenize_output/tokenize_output.py#L139-L144) and [to the preset](https://github.com/tokenizer/tokenize-output/blob/25b930cfadf8291e72a72144962e411e47d28139/tokenize_output/tokenize_output.py#L147).\n4. [Add test](https://github.com/tokenizer/tokenize-output/blob/25b930cfadf8291e72a72144962e411e47d28139/tests/test_tokenize.py#L34-L35).\n5. Now you can test and debug (see below).\n\n### Test and debug\nRun tests:\n```shell script\ncd ~\ngit clone https://github.com/anki-code/tokenize-output\ncd tokenize-output\npython -m pytest tests/\n```\nTo debug the tokenizer:\n```shell script\necho \"Hello world\" | ./tokenize-output -p\n```\n\n## Related projects\n* [xontrib-output-search][XONTRIB_OUTPUT_SEARCH] for [xonsh shell][XONSH]\n\n[XONTRIB_OUTPUT_SEARCH]: https://github.com/anki-code/xontrib-output-search\n[XONSH]: https://xon.sh/\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/anki-code/tokenize-output",
    "keywords": "",
    "license": "BSD",
    "maintainer": "",
    "maintainer_email": "",
    "name": "tokenize-output",
    "package_url": "https://pypi.org/project/tokenize-output/",
    "platform": "any",
    "project_url": "https://pypi.org/project/tokenize-output/",
    "project_urls": {
      "Code": "https://github.com/anki-code/tokenize-output",
      "Documentation": "https://github.com/anki-code/tokenize-output/blob/master/README.md",
      "Homepage": "https://github.com/anki-code/tokenize-output",
      "Issue tracker": "https://github.com/anki-code/tokenize-output/issues"
    },
    "release_url": "https://pypi.org/project/tokenize-output/0.4.9/",
    "requires_dist": [
      "demjson3",
      "pytest ; extra == 'dev'"
    ],
    "requires_python": ">=3.6",
    "summary": "Get identifiers, names, paths, URLs and words from the command output.",
    "version": "0.4.9",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17428652,
  "releases": {
    "0.4.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3614e26571dcf37a2f24ae62cce8c61bea55a2d32830e4d99ad8d1da4de5ef0b",
          "md5": "f150108378e435f3aee41b48542fb37d",
          "sha256": "46aa8dda28de77ff8fa5cc26a6b6b890c76faf7256d943a83824d56420e210c3"
        },
        "downloads": -1,
        "filename": "tokenize_output-0.4.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f150108378e435f3aee41b48542fb37d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 4688,
        "upload_time": "2020-05-24T11:16:23",
        "upload_time_iso_8601": "2020-05-24T11:16:23.872074Z",
        "url": "https://files.pythonhosted.org/packages/36/14/e26571dcf37a2f24ae62cce8c61bea55a2d32830e4d99ad8d1da4de5ef0b/tokenize_output-0.4.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6e530878e43bcbf563f8deceda7548f01f0497659c344d706699df060226c1a4",
          "md5": "9af34e8d4d640645706f8c17b27d9d7d",
          "sha256": "f2687fc725048bebd44950b872f8463656ce55c816b2737eb66bbc15c421fd9c"
        },
        "downloads": -1,
        "filename": "tokenize-output-0.4.1.tar.gz",
        "has_sig": false,
        "md5_digest": "9af34e8d4d640645706f8c17b27d9d7d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 4488,
        "upload_time": "2020-05-24T11:16:25",
        "upload_time_iso_8601": "2020-05-24T11:16:25.797728Z",
        "url": "https://files.pythonhosted.org/packages/6e/53/0878e43bcbf563f8deceda7548f01f0497659c344d706699df060226c1a4/tokenize-output-0.4.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "37646b3c3a930b4d65a30024654282e7d32faff655f05484299e02f0e039a002",
          "md5": "2d6b23afc2d4550438818ad483afcc41",
          "sha256": "200f4c55e007b216bd0209da4996d7d273ee08424b197d6006a4f07fd3948fc6"
        },
        "downloads": -1,
        "filename": "tokenize_output-0.4.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "2d6b23afc2d4550438818ad483afcc41",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 4685,
        "upload_time": "2020-09-10T22:37:08",
        "upload_time_iso_8601": "2020-09-10T22:37:08.954213Z",
        "url": "https://files.pythonhosted.org/packages/37/64/6b3c3a930b4d65a30024654282e7d32faff655f05484299e02f0e039a002/tokenize_output-0.4.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "22b83e17b4d28823639210df1c3556ab6b822354e3729677bdf5d6be84817469",
          "md5": "50112aeb8e3e8e1c49c077d8e94a55fe",
          "sha256": "7a99c660edf9a4766c67b342e247f8fca93c2d68dbc422da0f9986516da052f8"
        },
        "downloads": -1,
        "filename": "tokenize-output-0.4.2.tar.gz",
        "has_sig": false,
        "md5_digest": "50112aeb8e3e8e1c49c077d8e94a55fe",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 4517,
        "upload_time": "2020-09-10T22:37:09",
        "upload_time_iso_8601": "2020-09-10T22:37:09.812818Z",
        "url": "https://files.pythonhosted.org/packages/22/b8/3e17b4d28823639210df1c3556ab6b822354e3729677bdf5d6be84817469/tokenize-output-0.4.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3e993e5643193b88f4a818170f4c74d9f56ce9814973a9cce03bc1773239809d",
          "md5": "6ad0effa004fca881202764cec538d61",
          "sha256": "944c9edda752e867d98aeb52b885b85327c785c729c80a28cba11924a80cae9a"
        },
        "downloads": -1,
        "filename": "tokenize_output-0.4.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "6ad0effa004fca881202764cec538d61",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 5573,
        "upload_time": "2020-09-10T22:47:31",
        "upload_time_iso_8601": "2020-09-10T22:47:31.927035Z",
        "url": "https://files.pythonhosted.org/packages/3e/99/3e5643193b88f4a818170f4c74d9f56ce9814973a9cce03bc1773239809d/tokenize_output-0.4.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7672948560a180d68d619afcb8e8f18301e4c779d39d9313adef46e744fc1312",
          "md5": "34783e4c0ea958a68cea90d5b7120d14",
          "sha256": "420564be4a58a48f8a266cfd396a186d1ced480f02d65cd69c85e800b1a51701"
        },
        "downloads": -1,
        "filename": "tokenize-output-0.4.3.tar.gz",
        "has_sig": false,
        "md5_digest": "34783e4c0ea958a68cea90d5b7120d14",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 5271,
        "upload_time": "2020-09-10T22:47:33",
        "upload_time_iso_8601": "2020-09-10T22:47:33.040612Z",
        "url": "https://files.pythonhosted.org/packages/76/72/948560a180d68d619afcb8e8f18301e4c779d39d9313adef46e744fc1312/tokenize-output-0.4.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b079824eecc4dd58934fc04391da4a163478cf649a0b7d9d5edc28292c5d789b",
          "md5": "3af0927e1e29e2acd8663baf88116efa",
          "sha256": "0a70940180c26f554a2e8771d98d95b15ac7138008662009371f3bacdae911c2"
        },
        "downloads": -1,
        "filename": "tokenize_output-0.4.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "3af0927e1e29e2acd8663baf88116efa",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 5568,
        "upload_time": "2020-09-10T23:07:56",
        "upload_time_iso_8601": "2020-09-10T23:07:56.931517Z",
        "url": "https://files.pythonhosted.org/packages/b0/79/824eecc4dd58934fc04391da4a163478cf649a0b7d9d5edc28292c5d789b/tokenize_output-0.4.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3dd80730c88c6102431233f62f045fdb50e2733a5b1c0207ebc98837fbd55c4b",
          "md5": "d2e99973d5c78530e05b3c6cc8f0eee2",
          "sha256": "f074406fe781dfd1fed36ac757ffeda71b3473a8b08abb71b7870a50c4d27d26"
        },
        "downloads": -1,
        "filename": "tokenize-output-0.4.4.tar.gz",
        "has_sig": false,
        "md5_digest": "d2e99973d5c78530e05b3c6cc8f0eee2",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 5254,
        "upload_time": "2020-09-10T23:07:57",
        "upload_time_iso_8601": "2020-09-10T23:07:57.765286Z",
        "url": "https://files.pythonhosted.org/packages/3d/d8/0730c88c6102431233f62f045fdb50e2733a5b1c0207ebc98837fbd55c4b/tokenize-output-0.4.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ca546162ae62aacf8f61ce30d34bf4349097278834af901e6bb29d7f350ee98b",
          "md5": "d1beb02494d13fe546f2c2e088b669cc",
          "sha256": "f76689de4bbbc6320d66d8aca9cd36ab368df532bbb02ab3266cab2c82ffe05b"
        },
        "downloads": -1,
        "filename": "tokenize_output-0.4.6-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d1beb02494d13fe546f2c2e088b669cc",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 5581,
        "upload_time": "2022-02-28T11:46:56",
        "upload_time_iso_8601": "2022-02-28T11:46:56.132990Z",
        "url": "https://files.pythonhosted.org/packages/ca/54/6162ae62aacf8f61ce30d34bf4349097278834af901e6bb29d7f350ee98b/tokenize_output-0.4.6-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5ce03b785c782d401ced2d586f7b869105b5a916db1bf6c4bfb7f3cf623808f5",
          "md5": "cf0869e9fca6d0038b16d5789e15a77f",
          "sha256": "8e11a3b602c8e08fbdd0139057e44f2069e814785ad197a7fdfae0eda9f54d89"
        },
        "downloads": -1,
        "filename": "tokenize-output-0.4.6.tar.gz",
        "has_sig": false,
        "md5_digest": "cf0869e9fca6d0038b16d5789e15a77f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 5043,
        "upload_time": "2022-02-28T11:46:57",
        "upload_time_iso_8601": "2022-02-28T11:46:57.481396Z",
        "url": "https://files.pythonhosted.org/packages/5c/e0/3b785c782d401ced2d586f7b869105b5a916db1bf6c4bfb7f3cf623808f5/tokenize-output-0.4.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ca5899c16c0bab30afc8c99241f340c4a47ef80aba2cca73a4306e0e37dac241",
          "md5": "2fa718f29ac7e91c3500e42545db8369",
          "sha256": "50865d9d3dcc2ea4b85419f4ce09ff801950bcf3fab45309b6b4816d39017631"
        },
        "downloads": -1,
        "filename": "tokenize_output-0.4.7-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "2fa718f29ac7e91c3500e42545db8369",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 5582,
        "upload_time": "2022-07-05T09:40:47",
        "upload_time_iso_8601": "2022-07-05T09:40:47.570629Z",
        "url": "https://files.pythonhosted.org/packages/ca/58/99c16c0bab30afc8c99241f340c4a47ef80aba2cca73a4306e0e37dac241/tokenize_output-0.4.7-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4dfe41a98f3e305d3d78e7ad7799ae460a0e7d45145d7b8b9196154493f4384f",
          "md5": "5241249bbd96b4d6042675cec924acfb",
          "sha256": "6ff7df87997a60ef40db4bed7a40465cb31975f5dfaf353d9f35f2c5aef1651d"
        },
        "downloads": -1,
        "filename": "tokenize-output-0.4.7.tar.gz",
        "has_sig": false,
        "md5_digest": "5241249bbd96b4d6042675cec924acfb",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 5061,
        "upload_time": "2022-07-05T09:40:48",
        "upload_time_iso_8601": "2022-07-05T09:40:48.842378Z",
        "url": "https://files.pythonhosted.org/packages/4d/fe/41a98f3e305d3d78e7ad7799ae460a0e7d45145d7b8b9196154493f4384f/tokenize-output-0.4.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8d9da1b901d8cba92e7dcf43c0ab77e8f9ac5f3fd8e02bb5a0e1757c73b7593b",
          "md5": "504e47f4a8aed29ec9563f2908005998",
          "sha256": "3d72765df34a9ad39b5e2a471e92f259ed00b896d21f3616b41f660b531ec077"
        },
        "downloads": -1,
        "filename": "tokenize_output-0.4.8-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "504e47f4a8aed29ec9563f2908005998",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 5666,
        "upload_time": "2023-03-23T23:12:02",
        "upload_time_iso_8601": "2023-03-23T23:12:02.140576Z",
        "url": "https://files.pythonhosted.org/packages/8d/9d/a1b901d8cba92e7dcf43c0ab77e8f9ac5f3fd8e02bb5a0e1757c73b7593b/tokenize_output-0.4.8-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a7293e4a2eceeb3352705769877a260f6b499898ad56cba19295f6a85b2ca3f3",
          "md5": "8898d94080dec82b4182db4865035ee4",
          "sha256": "b31e75f52ae21099f8e10b6e2dc2cfdedae5a544fdbc3df963273b06bc8cd80d"
        },
        "downloads": -1,
        "filename": "tokenize-output-0.4.8.tar.gz",
        "has_sig": false,
        "md5_digest": "8898d94080dec82b4182db4865035ee4",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 5151,
        "upload_time": "2023-03-23T23:12:03",
        "upload_time_iso_8601": "2023-03-23T23:12:03.747152Z",
        "url": "https://files.pythonhosted.org/packages/a7/29/3e4a2eceeb3352705769877a260f6b499898ad56cba19295f6a85b2ca3f3/tokenize-output-0.4.8.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.9": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c3123eac1663c2d531e62a2a383e790cc7c1e35534acd8279569d284f9c19bc5",
          "md5": "61f911128e1590362124749400c2f54f",
          "sha256": "a517663da4bb249ddef5be6cd05f454c554dc1a688d0dbef5f3e6d2949899069"
        },
        "downloads": -1,
        "filename": "tokenize_output-0.4.9-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "61f911128e1590362124749400c2f54f",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 5962,
        "upload_time": "2023-03-24T08:38:07",
        "upload_time_iso_8601": "2023-03-24T08:38:07.008452Z",
        "url": "https://files.pythonhosted.org/packages/c3/12/3eac1663c2d531e62a2a383e790cc7c1e35534acd8279569d284f9c19bc5/tokenize_output-0.4.9-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "21ed08f731cf7e1de976f71ebc63e3435e32963e0fece7964489c48b5c5a0821",
          "md5": "a0e93bbc7052993c35ff4621880fbeb7",
          "sha256": "df4c07cbe0987c56b6719ab6c7b20c08b5522e46756b0e0ccdb2cd63cafff48f"
        },
        "downloads": -1,
        "filename": "tokenize-output-0.4.9.tar.gz",
        "has_sig": false,
        "md5_digest": "a0e93bbc7052993c35ff4621880fbeb7",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 5465,
        "upload_time": "2023-03-24T08:38:08",
        "upload_time_iso_8601": "2023-03-24T08:38:08.101722Z",
        "url": "https://files.pythonhosted.org/packages/21/ed/08f731cf7e1de976f71ebc63e3435e32963e0fece7964489c48b5c5a0821/tokenize-output-0.4.9.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "c3123eac1663c2d531e62a2a383e790cc7c1e35534acd8279569d284f9c19bc5",
        "md5": "61f911128e1590362124749400c2f54f",
        "sha256": "a517663da4bb249ddef5be6cd05f454c554dc1a688d0dbef5f3e6d2949899069"
      },
      "downloads": -1,
      "filename": "tokenize_output-0.4.9-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "61f911128e1590362124749400c2f54f",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 5962,
      "upload_time": "2023-03-24T08:38:07",
      "upload_time_iso_8601": "2023-03-24T08:38:07.008452Z",
      "url": "https://files.pythonhosted.org/packages/c3/12/3eac1663c2d531e62a2a383e790cc7c1e35534acd8279569d284f9c19bc5/tokenize_output-0.4.9-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "21ed08f731cf7e1de976f71ebc63e3435e32963e0fece7964489c48b5c5a0821",
        "md5": "a0e93bbc7052993c35ff4621880fbeb7",
        "sha256": "df4c07cbe0987c56b6719ab6c7b20c08b5522e46756b0e0ccdb2cd63cafff48f"
      },
      "downloads": -1,
      "filename": "tokenize-output-0.4.9.tar.gz",
      "has_sig": false,
      "md5_digest": "a0e93bbc7052993c35ff4621880fbeb7",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 5465,
      "upload_time": "2023-03-24T08:38:08",
      "upload_time_iso_8601": "2023-03-24T08:38:08.101722Z",
      "url": "https://files.pythonhosted.org/packages/21/ed/08f731cf7e1de976f71ebc63e3435e32963e0fece7964489c48b5c5a0821/tokenize-output-0.4.9.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}