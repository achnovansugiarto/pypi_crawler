{
  "info": {
    "author": "ncoop57",
    "author_email": "nacooper01@wm.edu",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: Apache Software License",
      "Natural Language :: English",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9"
    ],
    "description": "code_tokenizers\n================\n\n<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->\n\nThis library is built on top of the awesome\n[transformers](https://github.com/huggingface/transformers) and\n[tree-sitter](https://github.com/tree-sitter/py-tree-sitter) libraries.\nIt provides a simple interface to align the tokens produced by a BPE\ntokenizer with the tokens produced by a tree-sitter parser.\n\n## Install\n\n``` sh\npip install code_tokenizers\n```\n\n## How to use\n\nThe main interface of `code_tokenizers` is the\n[`CodeTokenizer`](https://ncoop57.github.io/code_tokenizers/core.html#codetokenizer)\nclass. You can use a pretrained BPE tokenizer from the popular\n[transformers](https://huggingface.co/docs/transformers/quicktour#autotokenizer)\nlibrary, and a tree-sitter parser from the\n[tree-sitter](https://tree-sitter.github.io/tree-sitter/using-parsers#python)\nlibrary.\n\nTo specify a\n[`CodeTokenizer`](https://ncoop57.github.io/code_tokenizers/core.html#codetokenizer)\nusing the `gpt2` BPE tokenizer and the `python` tree-sitter parser, you\ncan do:\n\n``` python\nfrom code_tokenizers.core import CodeTokenizer\n\npy_tokenizer = CodeTokenizer.from_pretrained(\"gpt2\", \"python\")\n```\n\n    None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n\nYou can specify any pretrained BPE tokenizer from the [huggingface\nhub](hf.co/models) or a local directory and the language to parse the\nAST for.\n\nNow, we can tokenize some code:\n\n``` python\nfrom pprint import pprint\n\ncode = \"\"\"\ndef foo():\n    print(\"Hello world!\")\n\"\"\"\n\nencoding = py_tokenizer(code)\npprint(encoding, depth=1)\n```\n\n    {'ast_ids': [...],\n     'attention_mask': [...],\n     'input_ids': [...],\n     'is_builtins': [...],\n     'is_internal_methods': [...],\n     'merged_ast': [...],\n     'offset_mapping': [...],\n     'parent_ast_ids': [...]}\n\nAnd we can print out the associated AST types:\n\n<div>\n\n> **Note**\n>\n> Note: Here the N/As are the tokens that are not part of the AST, such\n> as the spaces and the newline characters. Their IDs are set to -1.\n\n</div>\n\n``` python\nfor ast_id, parent_ast_id in zip(encoding[\"ast_ids\"], encoding[\"parent_ast_ids\"]):\n    if ast_id != -1:\n        print(py_tokenizer.node_types[parent_ast_id], py_tokenizer.node_types[ast_id])\n    else:\n        print(\"N/A\")\n```\n\n    N/A\n    function_definition def\n    function_definition identifier\n    parameters (\n    N/A\n    N/A\n    N/A\n    N/A\n    call identifier\n    argument_list (\n    argument_list string\n    argument_list string\n    argument_list string\n    argument_list )\n    N/A\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/ncoop57/code_tokenizers",
    "keywords": "nbdev jupyter notebook python tokenizer bpe ast",
    "license": "Apache Software License 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "code-tokenizers",
    "package_url": "https://pypi.org/project/code-tokenizers/",
    "platform": null,
    "project_url": "https://pypi.org/project/code-tokenizers/",
    "project_urls": {
      "Homepage": "https://github.com/ncoop57/code_tokenizers"
    },
    "release_url": "https://pypi.org/project/code-tokenizers/0.0.5/",
    "requires_dist": [
      "fastcore",
      "pandas",
      "transformers (<5)",
      "tree-sitter (==0.20.1)",
      "black[jupyter] ; extra == 'dev'",
      "datasets (<3) ; extra == 'dev'",
      "nbdev (<3) ; extra == 'dev'",
      "twine ; extra == 'dev'"
    ],
    "requires_python": ">=3.7",
    "summary": "Aligning BPE and AST",
    "version": "0.0.5",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16707364,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2f7f8d927746897e59c054cea0244e29bfa0454f1c0286d47abbda98e4206c47",
          "md5": "200f7be89ebe212fa28b72497bd92d2c",
          "sha256": "1129c32e6f83872e5f9eec4256b5b5cf6ae3ab3deba1bd8e5d3dd8c39be7f1f5"
        },
        "downloads": -1,
        "filename": "code_tokenizers-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "200f7be89ebe212fa28b72497bd92d2c",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 110849,
        "upload_time": "2022-11-17T21:23:19",
        "upload_time_iso_8601": "2022-11-17T21:23:19.950202Z",
        "url": "https://files.pythonhosted.org/packages/2f/7f/8d927746897e59c054cea0244e29bfa0454f1c0286d47abbda98e4206c47/code_tokenizers-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c8cd1fe052687b36a0882bbfa7772499d43d0f6fae9c6aeca24ce2980ad7b367",
          "md5": "5e2efaeebce8897081d5a7bf4e79d39d",
          "sha256": "87088d95d9a57397e1858370f8c6da25ffd7d888e50be5d49bf4ce28e6b94c58"
        },
        "downloads": -1,
        "filename": "code_tokenizers-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "5e2efaeebce8897081d5a7bf4e79d39d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 99051,
        "upload_time": "2022-11-17T21:23:22",
        "upload_time_iso_8601": "2022-11-17T21:23:22.447872Z",
        "url": "https://files.pythonhosted.org/packages/c8/cd/1fe052687b36a0882bbfa7772499d43d0f6fae9c6aeca24ce2980ad7b367/code_tokenizers-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4f99399a79f08efb322c9002f9a0a09aba5816510b7e080b0288d69ea2f5a36e",
          "md5": "162373d3ccd1a05e297c6400f29f9845",
          "sha256": "6adfb8278aaf20c5b51e511dbb643730979f2bd01a12e42b6bb58c201cedc93e"
        },
        "downloads": -1,
        "filename": "code_tokenizers-0.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "162373d3ccd1a05e297c6400f29f9845",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 61581,
        "upload_time": "2022-11-22T03:02:13",
        "upload_time_iso_8601": "2022-11-22T03:02:13.698236Z",
        "url": "https://files.pythonhosted.org/packages/4f/99/399a79f08efb322c9002f9a0a09aba5816510b7e080b0288d69ea2f5a36e/code_tokenizers-0.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "36eefa7a9cd214598e1cfaf642b9517b235a5250bf8f745193762cefe2dce275",
          "md5": "dd5d725b742484638b225bec795c5e10",
          "sha256": "bbb9696e31989a0470a73f72a1329ea0bf4adc822f87e00ece19bc917ff5996c"
        },
        "downloads": -1,
        "filename": "code_tokenizers-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "dd5d725b742484638b225bec795c5e10",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 55884,
        "upload_time": "2022-11-22T03:02:15",
        "upload_time_iso_8601": "2022-11-22T03:02:15.676795Z",
        "url": "https://files.pythonhosted.org/packages/36/ee/fa7a9cd214598e1cfaf642b9517b235a5250bf8f745193762cefe2dce275/code_tokenizers-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "aaa10f3cd52e07abf0abb312f3990aa8bd1de5f48dd0ef3cdfc6f09f70940a01",
          "md5": "1b65f8bf27fd3dae94a4f4d196142f92",
          "sha256": "52594f354d7c611ecaed1206a192633dfdd2ab138e10d77841f524cefff929fa"
        },
        "downloads": -1,
        "filename": "code_tokenizers-0.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "1b65f8bf27fd3dae94a4f4d196142f92",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 62134,
        "upload_time": "2022-11-28T01:51:36",
        "upload_time_iso_8601": "2022-11-28T01:51:36.412743Z",
        "url": "https://files.pythonhosted.org/packages/aa/a1/0f3cd52e07abf0abb312f3990aa8bd1de5f48dd0ef3cdfc6f09f70940a01/code_tokenizers-0.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1474e3b4fa241697d99e5d34692562cbd93a32eb59c9490b85fd52256fac6004",
          "md5": "b2557dac987c477526cd401302bd326b",
          "sha256": "d98fcca33a86a96f26bd8e090948ec5316c8da1a3489b7ed8d96ba32d091d63e"
        },
        "downloads": -1,
        "filename": "code_tokenizers-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "b2557dac987c477526cd401302bd326b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 56401,
        "upload_time": "2022-11-28T01:51:38",
        "upload_time_iso_8601": "2022-11-28T01:51:38.019049Z",
        "url": "https://files.pythonhosted.org/packages/14/74/e3b4fa241697d99e5d34692562cbd93a32eb59c9490b85fd52256fac6004/code_tokenizers-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "932c8572de49338504b91ac4019aeb7aee065966abf5a47c436afa382f51d745",
          "md5": "90e333ff7e35cba68d353a62aa590c46",
          "sha256": "f3419aba6811487a3df684eafd73db04cc5bfed5228de4a44699dfe432fed70b"
        },
        "downloads": -1,
        "filename": "code_tokenizers-0.0.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "90e333ff7e35cba68d353a62aa590c46",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 112939,
        "upload_time": "2023-02-05T23:02:12",
        "upload_time_iso_8601": "2023-02-05T23:02:12.386883Z",
        "url": "https://files.pythonhosted.org/packages/93/2c/8572de49338504b91ac4019aeb7aee065966abf5a47c436afa382f51d745/code_tokenizers-0.0.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "665c56630f3b64feec1c9eba99a400f0fe02156a0efc587579cf3ffe61c80c1c",
          "md5": "9ca0533c96948dce471bad337e1b724a",
          "sha256": "b95638811b18ff7c54679d2e6db90c2619986a9730b5e9d45235405a7096d4df"
        },
        "downloads": -1,
        "filename": "code_tokenizers-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "9ca0533c96948dce471bad337e1b724a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 57623,
        "upload_time": "2023-02-05T23:02:14",
        "upload_time_iso_8601": "2023-02-05T23:02:14.817339Z",
        "url": "https://files.pythonhosted.org/packages/66/5c/56630f3b64feec1c9eba99a400f0fe02156a0efc587579cf3ffe61c80c1c/code_tokenizers-0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1863ae91f45b305d413edd5f196658142778c5117385d4b633cb40ef8411cf2b",
          "md5": "b5be15d77a1bdf4376309d092e4f4d78",
          "sha256": "b4ce9108c840370cc8dd2582dc9a45451722806c9c8a3226f783870bbd4a9074"
        },
        "downloads": -1,
        "filename": "code_tokenizers-0.0.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "b5be15d77a1bdf4376309d092e4f4d78",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 112642,
        "upload_time": "2023-02-06T03:46:50",
        "upload_time_iso_8601": "2023-02-06T03:46:50.658167Z",
        "url": "https://files.pythonhosted.org/packages/18/63/ae91f45b305d413edd5f196658142778c5117385d4b633cb40ef8411cf2b/code_tokenizers-0.0.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b8830d9323f6ea7fe953594392c12dd6c99231ff8e17c06f98853bcb66e7115b",
          "md5": "006549670fe1286de9c944fa8f746085",
          "sha256": "796b0dda0555bd5aea0a87643c9a062c444f57f61c92881a326a5242b5b2cdb4"
        },
        "downloads": -1,
        "filename": "code_tokenizers-0.0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "006549670fe1286de9c944fa8f746085",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 13366,
        "upload_time": "2023-02-06T03:46:53",
        "upload_time_iso_8601": "2023-02-06T03:46:53.607461Z",
        "url": "https://files.pythonhosted.org/packages/b8/83/0d9323f6ea7fe953594392c12dd6c99231ff8e17c06f98853bcb66e7115b/code_tokenizers-0.0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "1863ae91f45b305d413edd5f196658142778c5117385d4b633cb40ef8411cf2b",
        "md5": "b5be15d77a1bdf4376309d092e4f4d78",
        "sha256": "b4ce9108c840370cc8dd2582dc9a45451722806c9c8a3226f783870bbd4a9074"
      },
      "downloads": -1,
      "filename": "code_tokenizers-0.0.5-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "b5be15d77a1bdf4376309d092e4f4d78",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 112642,
      "upload_time": "2023-02-06T03:46:50",
      "upload_time_iso_8601": "2023-02-06T03:46:50.658167Z",
      "url": "https://files.pythonhosted.org/packages/18/63/ae91f45b305d413edd5f196658142778c5117385d4b633cb40ef8411cf2b/code_tokenizers-0.0.5-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "b8830d9323f6ea7fe953594392c12dd6c99231ff8e17c06f98853bcb66e7115b",
        "md5": "006549670fe1286de9c944fa8f746085",
        "sha256": "796b0dda0555bd5aea0a87643c9a062c444f57f61c92881a326a5242b5b2cdb4"
      },
      "downloads": -1,
      "filename": "code_tokenizers-0.0.5.tar.gz",
      "has_sig": false,
      "md5_digest": "006549670fe1286de9c944fa8f746085",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 13366,
      "upload_time": "2023-02-06T03:46:53",
      "upload_time_iso_8601": "2023-02-06T03:46:53.607461Z",
      "url": "https://files.pythonhosted.org/packages/b8/83/0d9323f6ea7fe953594392c12dd6c99231ff8e17c06f98853bcb66e7115b/code_tokenizers-0.0.5.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}