{
  "info": {
    "author": "DeepMind",
    "author_email": "jaxline-copybara@google.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Intended Audience :: Developers",
      "Intended Audience :: Education",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: Apache Software License",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Topic :: Scientific/Engineering :: Mathematics",
      "Topic :: Software Development :: Libraries",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "# JAXline - Experiment framework for JAX\n\n## What is JAXline\n\nJAXline is a distributed JAX training and evaluation framework.\nIt is designed to be forked, covering only the most general aspects of\nexperiment boilerplate. This ensures that it can serve as an effective starting\npoint for a wide variety of use cases.\n\nMany users will only need to fork the\n[`experiment.py`](https://github.com/deepmind/jaxline/tree/master/jaxline/experiment.py)\nfile and rely on JAXline for everything else. Other users with more custom\nrequirements will want to (and are encouraged to) fork other components of\nJAXline too, depending on their particular use case.\n\n### Contents\n\n*   [Quickstart](#quickstart)\n*   [Checkpointing](#checkpointing)\n*   [Logging](#logging)\n*   [Launching](#launching)\n*   [Distribution strategy](#distribution-strategy)\n*   [Random number handling](#random-number-handling)\n*   [Debugging](#debugging)\n*   [Contributing](#contributing)\n\n## Quickstart\n\n### Installation\n\nJAXline is written in pure Python, but depends on C++ code via JAX and\nTensorFlow (the latter is used for writing summaries).\n\nBecause JAX / TensorFlow installation is different depending on your CUDA\nversion, JAXline does not list JAX or TensorFlow as a dependencies in\n`requirements.txt`.\n\nFirst, follow the instructions to install\n[JAX](https://github.com/google/jax#installation) and\n[TensorFlow](https://github.com/tensorflow/tensorflow#install)\nrespectively with the relevant accelerator support.\n\nThen, install JAXline using pip:\n\n```bash\n$ pip install git+https://github.com/deepmind/jaxline\n```\n\n### Building your own experiment\n\n1.  Create an `experiment.py` file and inside it define an `Experiment` class\n    that inherits from\n    [`experiment.AbstractExperiment`](https://github.com/deepmind/jaxline/tree/master/jaxline/experiment.py).\n2.  Implement the methods required by\n    `AbstractExperiment` in your own `Experiment` class (i.e. the\n    `abstractmethod`s). Optionally override the default implementations of `AbstractExperiment`'s other methods.\n3.  Define a `config`, either in `experiment.py` or elsewhere, defining any\n    settings that you do not wish to inherit from\n    [`base_config`](https://github.com/deepmind/jaxline/tree/master/jaxline/base_config.py).\n    At the very least this will include `config.experiment_kwargs` to define the\n    config required by your `Experiment`. Make sure this `config` object is\n    included in the `flags` accessible to `experiment.py`.\n4.  Add the following lines to the bottom of your `experiment.py` to ensure that\n    your `Experiment` object is correctly passed through to\n    [`platform.py`](https://github.com/deepmind/jaxline/tree/master/jaxline/platform.py):\n\n    ```\n    if __name__ == '__main__':\n      flags.mark_flag_as_required('config')\n      platform.main(Experiment, sys.argv[1:])\n    ```\n\n4.  Run your `experiment.py`.\n\n## Checkpointing\n\nSo far this version of JAXline only supports in-memory checkpointing, as handled\nby our\n[`InMemoryCheckpointer`](https://github.com/deepmind/jaxline/tree/master/jaxline/utils.py)\nIt allows you to save in memory multiple separate checkpoint series in your\ntrain and eval jobs (see below).\n\nThe user is expected to override the\n[`CHECKPOINT_ATTRS`](https://github.com/deepmind/jaxline/tree/master/jaxline/experiment.py)\nand\n[`NON_BROADCAST_CHECKPOINT_ATTRS`](https://github.com/deepmind/jaxline/tree/master/jaxline/experiment.py)\ndicts (at least one of these) in order to map checkpointable attributes of their\nown `Experiment` class to names they wish them to be stored under in the\ncheckpoint.\n`CHECKPOINT_ATTRS` specifies jax `DeviceArrays` for which jaxline should only\ntake the first slice (corresponding to device 0) for checkpointing.\n`NON_BROADCAST_CHECKPOINT_ATTRS` specifies any other picklable object that\njaxline should checkpoint whole.\n\nYou can specify the frequency with which to save checkpoints, as well as whether\nto checkpoint based on step or seconds, by setting the\n`save_checkpoint_interval` and `interval_type`  config flags\n[here](https://github.com/deepmind/jaxline/tree/master/jaxline/base_config.py).\n\n`config.max_checkpoints_to_keep` can be used to specify the maximum number of\ncheckpoints to keep. By default this is set to 5.\n\nBy setting `config.best_model_eval_metric`, you can specify which value in the\n`scalars` dictionary returned by your\n[`evaluate`](https://github.com/deepmind/jaxline/tree/master/jaxline/experiment.py)\nfunction to use as a 'fitness score'. JAXline will then save a separate series\nof checkpoints corresponding to steps at which the fitness score is better than\npreviously seen. Depending on whether you are maximizing or minimizing the eval\nmetric, set `config.best_model_eval_metric_higher_is_better` to True or False.\n\n## Logging\n\nSo far this version of JAXline only supports logging to Tensorboard via our\n[`TensorBoardLogger`](https://github.com/deepmind/jaxline/tree/master/jaxline/platform.py)\n\nThe user is expected to return a dictionary of scalars from their\n[`step`](https://github.com/deepmind/jaxline/tree/master/jaxline/experiment.py)\nand\n[`evaluate`](https://github.com/deepmind/jaxline/tree/master/jaxline/experiment.py)\nmethods, and\n[`TensorBoardLogger.write_scalars`](https://github.com/deepmind/jaxline/tree/master/jaxline/platform.py)\nwill periodically write these scalars to `TensorBoard`.\n\nAll logging will happen asynchronously to the main thread so as not to interrupt\nthe training loop.\n\nYou can specify the frequency with which to log, as well as whether to log by\nstep or by seconds, by setting the `log_train_data_interval` and `interval_type`\nconfig flags [here](https://github.com/deepmind/jaxline/tree/master/jaxline/base_config.py).\nIf `config.log_all_train_data` is set to `True` (`False` by default) JAXline\nwill cache the scalars from intermediate steps and log them all at once at the\nend of the period.\n\nJAXline passes the\n[`TensorBoardLogger`](https://github.com/deepmind/jaxline/tree/master/jaxline/platform.py)\ninstance through to the\n[`step`](https://github.com/deepmind/jaxline/tree/master/jaxline/experiment.py)\nand\n[`evaluate`](https://github.com/deepmind/jaxline/tree/master/jaxline/experiment.py)\nmethods to allow the user to perform additional logging inside their\n`Experiment` class if they so wish. A particular use case for this is if you\nwant to write images, which can be achieved via\n[`ExperimentWriter.write_images`](https://github.com/deepmind/jaxline/tree/master/jaxline/platform.py).\n\n\n## Launching\n\nSo far this version of JAXline does not support launching remotely.\n\n## Distribution strategy\n\nJAX makes it super simple to distribute your jobs across multiple hosts and\ncores. As such, JAXline leaves it up to the user to implement distributed\ntraining and evaluation.\n\nEssentially, by decorating a function with\n[`jax.pmap`](https://jax.readthedocs.io/en/latest/jax.html#parallelization-pmap)\nyou tell JAX to slice the inputs along the first dimension and then run the\nfunction in parallel on each input slice, across all available local devices (or\na subset thereof). In other words,\n[`jax.pmap`](https://jax.readthedocs.io/en/latest/jax.html#parallelization-pmap)\ninvokes the single-program multiple-data (SPMD) paradigm. Then by using\n[`jax.lax`](https://jax.readthedocs.io/en/latest/jax.lax.html) collective\ncommunications operations from within your pmapped function, you can tell JAX to\ncommunicate results between all devices _on all hosts_. For example, you may\nwant to use [`jax.lax.psum`](https://jax.readthedocs.io/en/latest/jax.lax.html)\nto sum up the gradients across all devices on all hosts, and return the result\nto each device (an all-reduce).\n\nJAX will then automatically detect which devices are available on each host\nallowing\n[`jax.pmap`](https://jax.readthedocs.io/en/latest/jax.html#parallelization-pmap)\nand [`jax.lax`](https://jax.readthedocs.io/en/latest/jax.lax.html) to work their\nmagic.\n\nOne very important thing to bear in mind is that each time you call\n[`jax.pmap`](https://jax.readthedocs.io/en/latest/jax.html#parallelization-pmap),\na separate TPU program will be compiled for the computation it wraps. Therefore\nyou do not want to be doing this regularly! In particular, for a standard ML\nexperiment you will want to call\n[`jax.pmap`](https://jax.readthedocs.io/en/latest/jax.html#parallelization-pmap)\nonce to wrap your parameter update function,\nand then you call this wrapped function on each step, rather than calling\n[`jax.pmap`](https://jax.readthedocs.io/en/latest/jax.html#parallelization-pmap)\non each step, which will kill your performance! This is a very common mistake\nfor new JAX starters. Luckily it has quite an extreme downside so should be\neasily noticeable. In JAXline we actually call\n[`jax.pmap`](https://jax.readthedocs.io/en/latest/jax.html#parallelization-pmap)\nonce more in\n[`next_device_state`](https://github.com/deepmind/jaxline/tree/master/jaxline/experiment.py)\nto wrap our function to update device state between steps, so end up with 2 TPU\nprograms rather than just 1 (but this adds negligible overhead).\n\n## Random number handling\n\nRandom numbers in JAX might seem a bit unfamiliar to users coming from ordinary\n`numpy` and `Tensorflow`. In these languages we have global stateful PRNGs.\nEvery time you call a random op it updates the PRNGs global state. However,\nstateful PRNGs in JAX would be incompatible with JAX's functional design\nsemantics, leading to problems with reproducibility and parallelizability. JAX\nintroduces stateless PRNGs to avoid these issues. The downside of this is that\nthe user needs to thread random state through their program, splitting a new\nPRNG off from the old one every time they want to draw a new random number. This\ncan be quite onerous, especially in a distributed setting, where you may have\nindependent PRNGs on each device.\n\nIn JAXline we take care of this for you. On each step, in\n[`next_device_state`](https://github.com/deepmind/jaxline/tree/master/jaxline/experiment.py),\nwe split a new PRNG from the old one, and optionally specialize it to the host\nand/or device based on the\n`random_mode_train` [config](https://github.com/deepmind/jaxline/tree/master/jaxline/base_config.py)\nvalue you specify. We then pass this new PRNG through to your\n[step](https://github.com/deepmind/jaxline/tree/master/jaxline/experiment.py)\nfunction to use on that particular step. At evaluation time, we pass a fresh\nPRNG to your\n[`evaluate`](https://github.com/deepmind/jaxline/tree/master/jaxline/experiment.py)\nmethod, initialized according to the `random_mode_eval`\n[config](https://github.com/deepmind/jaxline/tree/master/jaxline/base_config.py) value\nyou specify. This PRNG will be the same on each call to\n[`evaluate`](https://github.com/deepmind/jaxline/tree/master/jaxline/experiment.py)\n(as normally you want your evaluation to be deterministic). If you want\ndifferent random behaviour on each call, a simple solution would be to fold in\nthe `global_step` i.e. `jax.random.fold_in(rng, global_step)` at the top of your\n[`evaluate`](https://github.com/deepmind/jaxline/tree/master/jaxline/experiment.py)\nmethod.\n\nOf course you are free to completely ignore the PRNGs we pass through to your\n[`step`](https://github.com/deepmind/jaxline/tree/master/jaxline/experiment.py)\nand\n[`evaluate`](https://github.com/deepmind/jaxline/tree/master/jaxline/experiment.py)\nmethods and handle random numbers in your own way, should you have different\nrequirements.\n\n## Debugging\n\n### Post mortem debugging\n\nBy setting the flag `--jaxline_post_mortem` (defined\n[here](https://github.com/deepmind/jaxline/tree/master/jaxline/utils.py)) on the command-line,\ntasks will pause on exceptions (except `SystemExit` and `KeyboardInterrupt`) and\nenter post-mortem debugging using pdb. Paused tasks will hang until you attach\na debugger.\n\n### Disabling pmap and jit\n\nBy setting the flag `--jaxline_disable_pmap_jit` on the command-line, all pmaps\nand jits will be disabled, making it easier to inspect and trace code in a\ndebugger.\n\n## Citing Jaxline\n\nPlease use [this reference](https://github.com/deepmind/jax/blob/main/deepmind2020jax.txt).\n\n\n## Contributing\n\nThank you for your interest in JAXline. The primary goal of open-sourcing\nJAXline was to allow us to open-source our research more easily. Unfortunately,\nwe are not currently able to accept pull requests from external contributors,\nthough we hope to do so in future. Please feel free to open GitHub issues.",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/deepmind/jaxline",
    "keywords": "",
    "license": "Apache 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "jaxline",
    "package_url": "https://pypi.org/project/jaxline/",
    "platform": "",
    "project_url": "https://pypi.org/project/jaxline/",
    "project_urls": {
      "Homepage": "https://github.com/deepmind/jaxline"
    },
    "release_url": "https://pypi.org/project/jaxline/0.0.5/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "JAXline is a distributed JAX training framework.",
    "version": "0.0.5",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 11960797,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ff9e40f67aca4f41b9c81f3bba4f31f998cbb3cd991659ed01ac833c80033f0d",
          "md5": "b9aec1e0c69d6f53823a1529c84078c0",
          "sha256": "da1e346d839fc0e8dbc78674a86b1c76af0882d93ab68040b5e2f6056e90f963"
        },
        "downloads": -1,
        "filename": "jaxline-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "b9aec1e0c69d6f53823a1529c84078c0",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 33549,
        "upload_time": "2021-01-11T14:55:57",
        "upload_time_iso_8601": "2021-01-11T14:55:57.058034Z",
        "url": "https://files.pythonhosted.org/packages/ff/9e/40f67aca4f41b9c81f3bba4f31f998cbb3cd991659ed01ac833c80033f0d/jaxline-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0ae8616c9372dcd864588844782f457f184ba499fc5c1ae53db0bca3fef20405",
          "md5": "a40d3cca28f949061cfdd668b57ef61f",
          "sha256": "ff53722cbc6409d58a1ac8fcdccdeb7166097a2fb79c96e901713bf3835325ea"
        },
        "downloads": -1,
        "filename": "jaxline-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "a40d3cca28f949061cfdd668b57ef61f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 34199,
        "upload_time": "2021-01-27T15:59:41",
        "upload_time_iso_8601": "2021-01-27T15:59:41.295071Z",
        "url": "https://files.pythonhosted.org/packages/0a/e8/616c9372dcd864588844782f457f184ba499fc5c1ae53db0bca3fef20405/jaxline-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b90de643c235c9a0badd61daef02d570c789ef6ee8c51c8c2d974947ad52cde6",
          "md5": "7c52efb2aaa2f877e67f71172bef39e2",
          "sha256": "1fec511e2255116c809d55dbae641961c7f9c87c836d08e9f446b2207ea245b2"
        },
        "downloads": -1,
        "filename": "jaxline-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "7c52efb2aaa2f877e67f71172bef39e2",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 32023,
        "upload_time": "2021-06-17T13:44:37",
        "upload_time_iso_8601": "2021-06-17T13:44:37.318090Z",
        "url": "https://files.pythonhosted.org/packages/b9/0d/e643c235c9a0badd61daef02d570c789ef6ee8c51c8c2d974947ad52cde6/jaxline-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "331d57ea43dec34127ae76a144ad39879e15343656c5311df0eff816d7a09fed",
          "md5": "6bcf1f9591dc7e288229adb201f90fc7",
          "sha256": "2a21896a2df5518c0037933fbeda890d21e61f7523ca7a7c4f6c1694b8041b40"
        },
        "downloads": -1,
        "filename": "jaxline-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "6bcf1f9591dc7e288229adb201f90fc7",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 33360,
        "upload_time": "2021-10-29T11:11:06",
        "upload_time_iso_8601": "2021-10-29T11:11:06.525571Z",
        "url": "https://files.pythonhosted.org/packages/33/1d/57ea43dec34127ae76a144ad39879e15343656c5311df0eff816d7a09fed/jaxline-0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "11fdd66d286acd4040218990152122a12022d49c91066ae9373828c54d155823",
          "md5": "09c7ec78281bcddeeb04969ccf5f1682",
          "sha256": "4f5b10625fa22a9a12d8db78b9f6100c63f7657acd933ff751cf18fb23eab87f"
        },
        "downloads": -1,
        "filename": "jaxline-0.0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "09c7ec78281bcddeeb04969ccf5f1682",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 32550,
        "upload_time": "2021-11-08T14:17:48",
        "upload_time_iso_8601": "2021-11-08T14:17:48.578487Z",
        "url": "https://files.pythonhosted.org/packages/11/fd/d66d286acd4040218990152122a12022d49c91066ae9373828c54d155823/jaxline-0.0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "11fdd66d286acd4040218990152122a12022d49c91066ae9373828c54d155823",
        "md5": "09c7ec78281bcddeeb04969ccf5f1682",
        "sha256": "4f5b10625fa22a9a12d8db78b9f6100c63f7657acd933ff751cf18fb23eab87f"
      },
      "downloads": -1,
      "filename": "jaxline-0.0.5.tar.gz",
      "has_sig": false,
      "md5_digest": "09c7ec78281bcddeeb04969ccf5f1682",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 32550,
      "upload_time": "2021-11-08T14:17:48",
      "upload_time_iso_8601": "2021-11-08T14:17:48.578487Z",
      "url": "https://files.pythonhosted.org/packages/11/fd/d66d286acd4040218990152122a12022d49c91066ae9373828c54d155823/jaxline-0.0.5.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}