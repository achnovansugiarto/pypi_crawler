{
  "info": {
    "author": "(original : Hyunwoong Ko), Saebom Lee, Jeongyun Seo, Youngeun Cho",
    "author_email": "gusdnd852@naver.com",
    "bugtrack_url": null,
    "classifiers": [
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.2",
      "Programming Language :: Python :: 3.3",
      "Programming Language :: Python :: 3.4",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9"
    ],
    "description": "# Kocrawl\n[![PyPI version](https://badge.fury.io/py/kocrawl.svg)](https://badge.fury.io/py/kocrawl)\n![GitHub](https://img.shields.io/github/license/gusdnd852/kocrawl)\n\n![logo](https://user-images.githubusercontent.com/38183241/85956888-d619d580-b9c3-11ea-9243-29d2bce90cb4.png)\n<br><br><br>\n\n## Table of contents\n- [1. Kocrawl이란?](https://github.com/gusdnd852/kocrawl#1-kocrawl%EC%9D%B4%EB%9E%80)\n    - [Waring](https://github.com/gusdnd852/kocrawl#-warning)\n- [2. Getting Started](https://github.com/gusdnd852/kocrawl#2-getting-started)\n- [3. Supported Features](https://github.com/gusdnd852/kocrawl#3-supported-features)\n- [4. Usage](https://github.com/gusdnd852/kocrawl#4-usage)\n    - [4.1. request()](https://github.com/gusdnd852/kocrawl#41-request)\n    - [4.2. request_dict()](https://github.com/gusdnd852/kocrawl#42-request_dict)\n    - [4.3. request_debug()](https://github.com/gusdnd852/kocrawl#43-request_debug)\n- [5. Cralwer Implementation](https://github.com/gusdnd852/kocrawl#5-crawler-implementation)\n    - [5.1. Kocrawl 아키텍처](https://github.com/gusdnd852/kocrawl#51-kocrawl-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98)\n    - [5.2. 정적 사이트 크롤링](https://github.com/gusdnd852/kocrawl/blob/master/README.md#52-%EC%A0%95%EC%A0%81-%EC%82%AC%EC%9D%B4%ED%8A%B8-%ED%81%AC%EB%A1%A4%EB%A7%81)\n    - [5.3. 동적 사이트(ajax) 크롤링](https://github.com/gusdnd852/kocrawl/blob/master/README.md#53-%EB%8F%99%EC%A0%81-%EC%82%AC%EC%9D%B4%ED%8A%B8ajax-%ED%81%AC%EB%A1%A4%EB%A7%81)\n- [6. Contributor](https://github.com/gusdnd852/kocrawl#6-contributor)\n- [7. License](https://github.com/gusdnd852/kocrawl#7-license)\n<br><br><br>\n\n## 1. Kocrawl이란?\n\nKocrawl은 매우 간단하게 사용할 수 있는 한국어 크롤러 모음 라이브러리입니다.\n이 패키지는 한달에 한번 꼴로 버그를 점검하고, 새로운 기능을 추가할 예정입니다.\n이 패키지는 한국어 딥러닝 챗봇 프레임워크 [Kochat](https://github.com/gusdnd852/kochat)\n을 만들때 함께 만들어졌으며, 호환성이 좋아 함께 사용하면 좋습니다.\n<br><br><br>\n\n### ⚠ Warning\nKocrawl 패키지는 네이버, 구글 등의 서비스로부터 정보를 크롤링해서 기능을 제공하고 있습니다.\n모든 결과 및 데이터에 대한 저작권 및 책임은 네이버/구글 등의 정보제공자에 있으며, \n라이브러리를 상업적으로 사용하거나 불법적인 용도로 활용한 부분에 대해서는 그 어떠한 부분에 \n대해서도 개발자는 책임지지 않습니다.\n<br><br><br>\n\n## 2. Getting Started \n\n- pip install : pip를 이용해 Kocrawl-cna를 간단하게 다운로드 하고 사용할 수 있습니다.\n```shell script\npip install kocrawl-cna\n```\n<br>\n\n- Dependencies : 패키지를 구현하는데 사용된 디펜던시는 아래와 같습니다.\n\n```\nnumpy==1.18.5\nbeautifulsoup4==4.6.0\nrequests==2.24.0\n``` \n<br><br><br>\n\n## 3. Supported Features\n현재 Kocrawl은 날씨, 미세먼지, 지도(장소추천), 맞춤법 교정 등 5개의 API를 지원합니다.\n\n+) 기존의 kocrawl에 덧붙여서 전기차충전소/자전거 대여, 사전, 탄소중립 실천방안에 대한 API를 추가함. \nauthor : 이새봄,서정윤,조영은\ndate : 2022/04/06\n\n각각 API의 지원범위는 다음과 같습니다. 아래 적힌 파라미터 (e.g. 지역, 날짜 등)은\n라이브러리를 구동할 때 필요한 입력 파라미터에 해당합니다.\n<br><br>\n\n- 날씨 :  \n    - 최근 업데이트 : v 1.0\n    - 패키지 : `from kocrawl.weather import WeatherCrawler`\n    - 파라미터 1 - 지역(location) :  \n        - 대한민국 전국\n    - 파라미터 2 - 날짜(date) : \n        - 네이버 날씨 : 오늘(현재,지금), 내일, 모레(내일모레)\n        - 구글 날씨 : 특정요일(수요일 등), 특정날짜(9월 12일 등)\n\n<br>\n\n- 미세먼지 : \n    - 최근 업데이트 : v 1.0\n    - 패키지 : `from kocrawl.dust import DustCrawler`\n    - 파라미터 1 - 지역(location) :  \n        - 대한민국 전국\n    - 파라미터 2 - 날짜(date) : \n        - 네이버 미세먼지 : 오늘(현재,지금), 내일, 모레(내일모레)\n\n<br>\n\n- 지도(장소추천) : \n    - 최근 업데이트 : v 1.0\n    - 패키지 : `from kocrawl.map import MapCrawler`\n    - 파라미터 1 - 지역(location) :  \n        - 대한민국 전국\n    - 파라미터 2 - 장소(place) : \n        - 네이버 지도 : 모든 장소 검색 가능\n\n<br>\n\n- 맞춤법 교정 : \n    - 최근 업데이트 : v 1.0\n    - 패키지 : `from kocrawl.spell import SpellCrawler`\n    - 파라미터 1 - 문자열(text) :  \n        - 네이버 맞춤법 교정 : 500글자 이하의 문자열\n\n<br>\n\n- 다음 랭킹 뉴스 :\n    - 최근 업데이트 : v 1.05\n    - 패키지 : `from kocrawl.daum_news import DaumNewsCrawler`\n    - 파라미터 : top_n(int) :\n        - 최대 n개의 뉴스 기사 크롤링\n        \n<br>\n\n- 다음 랭킹 백과 :\n    - 최근 업데이트 : v 1.05\n    - 패키지 : `from kocrawl.daum_dict import DaumDictCrawler`\n    - 파라미터 : top_n(int) :\n        - 최대 n개의 백과 키워드 크롤링\n        \n<br>\n\n- 네이버 대여 장소 :\n    - 최근 업데이트 : 20220406\n    - 패키지 : `from kocrawl.rent import RentCrawler`\n    - 파라미터 : location(str),category(str) :\n        - 자전거 대여 혹은 전기자동차 충전소에 대한 가까운 장소를 거리순으로 3곳까지 추천\n<br>\n\n- 네이버 사전 :\n    - 최근 업데이트 : 20220406\n    - 패키지 : `from kocrawl.term import TermCrawler`\n    - 파라미터 : term(str) :\n    - 최대 n개의 백과 키워드 크롤링\n<br>\n\n- 탄소중립 생활실천 추천 :\n    - 최근 업데이트 : 20220406\n    - 패키지 : `from kocrawl.eco_activity import EcoCrawler`\n    - 파라미터 : category(str) :\n    - 학교, 가정, 직장, 식당, 매장 등에서 실천할 수 있는 저탄소 일상 추천\n<br>\n    \n<br><br><br>\n\n## 4. Usage\n기본적으로 모든 크롤러들은 `request()`와 `request_dict()`, 그리고 `request_debug()`\n라는 세가지 메소드를 가지고 있습니다. 이 세가지 메소드에 대해 각각 소개해드리도록 하겠습니다.\n<br><br>\n\n### 4.1. request()\n`request()`는 애플리케이션 동작 중 에러가 나지 않도록 Try-Except가 설정되어 있으며,\n개발자가 미리 만들어놓은 템플릿 문장에 맞춰서 만들어진 String 리턴 값이 반환됩니다. <br><br>\n\n4.1.1. 정상 처리시\n```python\n>>> from kocrawl.weather import WeatherCrawler\n\n>>> crawler = WeatherCrawler()\n>>> crawler.request(location='서울', date='오늘')\n\n'서울의 날씨 정보를 전해드릴게요. 😉'\n'오늘 서울지역은 섭씨 21도이며, 어제보다1˚낮아요. 구름이 많이 낀 날씨에요.'\n```\n\n<br>\n\n4.1.2. 오류 발생시\n```python\n>>> from kocrawl.weather import WeatherCrawler\n\n>>> crawler = WeatherCrawler()\n>>> crawler.request(location='런던', date='1901년 3월 2일')\n\n'그 날씨는 알 수가 없어요.'\n```\n<br><br>\n\n### 4.2. request_dict()\n\n`request_dict()`는 애플리케이션 동작 중 에러가 나지 않도록 Try-Except가 설정되어 있으며,\n사용자가 직접 메시지를 설계할 수 있게 dictionary 형태로 정보를 반환합니다. (단 오류시엔\n그대로 String으로 에러 메시지가 출력됩니다.) <br><br>\n\n4.2.1. 정상 처리시\n```python\n>>> from kocrawl.weather import WeatherCrawler\n\n>>> crawler = WeatherCrawler()\n>>> crawler.request_dict(location='서울', date='오늘')\n\n\n{'today_weather': '맑음,어제보다1˚낮아요', \n     'tomorrow_morning_weather': '흐리고가끔비', \n     'tomorrow_afternoon_weather': '구름많음', \n     'after_morning_weather': '구름많음', \n     'after_afternoon_weather': '맑음', \n     'specific_weather': None, \n     'today_temperature': '21', \n     'tomorrow_morning_temperature': '20', \n     'tomorrow_afternoon_temperature': '25', \n     'after_morning_temperature': '21', \n     'after_afternoon_temperature': '29', \n     'specific_temperature': None}\n```\n\n<br>\n\n4.2.2. 오류 발생시\n```python\n>>> from kocrawl.weather import WeatherCrawler\n\n>>> crawler = WeatherCrawler()\n>>> crawler.request_dict(location='런던', date='1901년 3월 2일')\n\n'그 날씨는 알 수가 없어요.'\n```\n<br><br>\n\n\n### 4.3. request_debug()\n\n`request_debug()`는 애플리케이션 동작 중 에러가 나는 것을 확인하기 위해 \nTry-Except가 설정되어 있지 않습니다. (주로 개발자인 제가 사용합니다.. ^^)\n메시지와 딕셔너리가 tuple 형태로 모두 반환됩니다. <br><br>\n\n4.3.1. 정상 처리시\n```python\n>>> from kocrawl.weather import WeatherCrawler\n\n>>> crawler = WeatherCrawler()\n>>> crawler.request_debug(location='서울', date='오늘')\n\n('서울의 날씨 정보를 전해드릴게요. 😉 '\n'오늘 서울지역은 섭씨 21도이며, 어제보다1˚낮아요. 구름이 많이 낀 날씨에요.' , \n \n{'today_weather': '맑음,어제보다1˚낮아요', \n     'tomorrow_morning_weather': '흐리고가끔비', \n     'tomorrow_afternoon_weather': '구름많음', \n     'after_morning_weather': '구름많음', \n     'after_afternoon_weather': '맑음', \n     'specific_weather': None, \n     'today_temperature': '21', \n     'tomorrow_morning_temperature': '20', \n     'tomorrow_afternoon_temperature': '25', \n     'after_morning_temperature': '21', \n     'after_afternoon_temperature': '29', \n     'specific_temperature': None})\n```\n\n<br>\n\n4.3.2. 오류 발생시\n```python\n>>> from kocrawl.weather import WeatherCrawler\n\n>>> crawler = WeatherCrawler()\n>>> crawler.request_debug(location='런던', date='1901년 3월 2일')\n\n\nTraceback (most recent call last):\n  File \"C:/Users/ASUS/Desktop/kocrawl/test/test.py\", line 9, in <module>\n    print(c.request_debug(location='런던', date='1901년 3월 2일'))\n  File \"C:\\Users\\ASUS\\Desktop\\kocrawl\\kocrawl\\weather.py\", line 62, in request_debug\n    return self.__specific(location, date)\n  File \"C:\\Users\\ASUS\\Desktop\\kocrawl\\kocrawl\\weather.py\", line 109, in __specific\n    result_dict = WeatherSearcher().google_search(location, date)\n  File \"C:\\Users\\ASUS\\Desktop\\kocrawl\\kocrawl\\searcher\\weather_searcher.py\", line 81, in google_search\n    self.data_dict['specific_weather'] = re.sub(' ', '', result[0][0])\nIndexError: list index out of range\n```\n<br><br><br>\n\n## 5. Crawler Implementation\n이 챕터에서는 크롤러를 구현하는 방법에 대해 간단히 소개합니다. \n<br><br>\n\n### 5.1. Kocrawl 아키텍처\nKocrawl은 Crawler, Searcher, Editor, Answerer라는 네가지 컴포넌트로 구현되어있습니다.\n구조가 매우 간단하고 객체지향을 최대한 살려서 구현했기 때문에 여러분이 새로운 크롤러를 만들 때\n유용할 수 있습니다. 추가로, 라이브러리에 컨트리뷰션하실 분이 있을진 모르겠지만.. 컨트리뷰션하시려면\n참고하시길 바랍니다. 라이브러리의 전체적인 동작에 관련된 시퀀스 다이어그램을 아래에 첨부합니다.<br><br>\n\n![diagram](https://user-images.githubusercontent.com/38183241/85956893-e336c480-b9c3-11ea-9f70-0f2687b1122d.png)\n\n<br>\n\n###  5.2. 정적 사이트 크롤링\n정적 사이트는 beautifulsoup과 CSS 셀렉터로 구현합니다. \n셀렉터를 딸 때는 구글크롬을 사용하는 것이 효과적입니다.\n아래처럼 원하는 부분을 우클릭하고 '검사'를 클릭합니다.\n<br><br>\n\n![impl_01](https://user-images.githubusercontent.com/38183241/85956927-f053b380-b9c3-11ea-94aa-79554473e559.png)\n\n그러면 오른쪽처럼 웹페이지의 소스코드를 볼 수 있습니다.\n이 소스코드에서 원하는 컴포넌트의 셀렉터를 따야합니다. \n<br><br>\n\n![impl_02](https://user-images.githubusercontent.com/38183241/85956932-f9448500-b9c3-11ea-82d4-ec65e1a68909.png)\n\n위 처럼 셀렉터 String을 만들고, bs4의 select()에 입력하면 원하는 컴포넌트를\n크롤링 할 수 있습니다. 복잡해보이지만 아래의 4가지 CSS 셀렉터 규칙만 알면 거의 \n대부분의 셀렉터를 딸 수 있습니다. \n<br><br>\n\n```\n1. 태그의 경우 그대로 적습니다 (e.g. <div> → div)\n2. 클래스의 경우 '.' 뒤에 적습니다. (e.g. class=\"name\" → .name)\n3. 아이디의 경우 '#' 뒤에 적습니다. (e.g. id=\"some_id\" → #some_id)\n4. 하위 요소로 접근할 때는 '>' 를 사용합니다 (e.g. div.info_area > div.tit)\n```\n\n만들어낸 셀렉터 문자열을 이용해 bs4로 검색하고 적절히 보기 좋게 수정한 뒤 \n사용자에게 반환하면 됩니다. 만약 이 4가지 규칙으로 원하는 요소에 접근할 수 없다면 \n구글에 'CSS 셀렉터'를 검색하셔서 더 세부적인 규칙을 확인하고 셀렉터를 작성해주세요.\n    \n<br>\n\n###  5.3. 동적 사이트(ajax) 크롤링\n동적 사이트의 경우 HTTP 통신 중 GET 방식을 사용한다면 requests와 json을 이용하여 매우 쉽게 크롤링 할 수 있습니다.\n만약 POST 방식을 사용한다면 Selenium 같이 실제로 브라우저를 띄우고 크롤링 하는 방식을 사용해야 \n하는데 Kocrawl은 이런 방식의 크롤링은 다루지 않을 예정입니다. 여기에서는 GET 방식 크롤링만\n알려드리도록 하겠습니다. 이번에는 구글크롬의 Network 툴을 이용합니다. 구글크롬을 열어서 F12를 눌러서 개발자 도구를 열고, Network를 눌러봅시다.\n<br><br>\n\n![impl_03](https://user-images.githubusercontent.com/38183241/85956935-019cc000-b9c4-11ea-9ac7-cfdb85c920d6.png)\n\n위와 같은 화면을 볼 수 있습니다. 이 때 우리가 원하는 기능을 실행해봅시다.\n여기에서는 네이버 지도를 크롤링해보겠습니다. 네이버 지도는 동적으로 구현되어\n셀렉터 방식으로는 검색결과를 크롤링 할 수 없습니다.\n네트워크 툴을 열고 있는 상태에서 원하는 기능을 수행해봅시다. ('서울 여행지' 검색)\n<br><br>\n\n\n![impl_04](https://user-images.githubusercontent.com/38183241/85956943-0c575500-b9c4-11ea-8cbe-f39c74707253.png)\n\n원하는 기능을 수행하면 수행하는 동안 위의 시간 탭이 변하게 됩니다.\n이 때, 빨간색 네모칸 처럼 내가 수행했던 구간만 선택하면 그 시간 동안 수행한 request를 전부 열람할 수 있습니다.\n파란색 네모칸에 주고받은 모든 요소가 나오게 됩니다. 대부분은 사진들이고 위쪽에 \n4개의 요소만 사진이 아닙니다. 이 때, 사이즈와 시간이 제일 큰 가장 위 요소가 지도 API일 확률이 높습니다.\n해당 요소를 클릭해봅시다.\n<br><br>\n\n\n![impl_05](https://user-images.githubusercontent.com/38183241/85956949-18431700-b9c4-11ea-9cf1-a41563bbc1ed.png)\n\n빨간색 네모칸에 request에 필요한 url이 나오게 됩니다. 이 url로 접속해봅시다.\n<br><br>\n\n![impl_06](https://user-images.githubusercontent.com/38183241/85956956-2e50d780-b9c4-11ea-8157-a6e0957c6a79.png)\n\n네이버 지도 api의 결과가 출력되었습니다.\n이 때, url을 보면 뒷쪽에 너저분하게 여러가지 파라미터가 붙어있는데\n여기에서 중요한 파라미터만 남깁니다. qeury는 검색어이기 때문에 가장 중요한 파라미터이고\n나머지는 별로 필요 없어보이기 때문에 날리겠습니다. \n만약 문제가 생긴다면 여러번 시도하면서\n필수 파라미터만 남기고 다 없애는 것이 좋습니다.\n<br><br>\n\n![impl_07](https://user-images.githubusercontent.com/38183241/85956962-3ad53000-b9c4-11ea-99dd-a3118eb61826.png)\n\nqeury를 제외한 모든 파라미터를 날려도 정상적으로 작동하기 때문에 qeury만 남기고 이 url을\n활용하여 크롤링을 수행합니다. 즉, `https://map.naver.com/v5/api/search?query=` \n뒤에 사용자 입력 쿼리를 붙여서 검색하면 됩니다. 이 url을 이용해 파이썬에서 \nrequests 모듈을 사용해서 접속하고, json 모듈을 통해서 원하는 정보만 잘라내서 사용하면 됩니다.\n<br><br><br>\n\n\n## 6. Contributor\n만약 본인이 원하는 기능을 Kocrawl에 추가하고 싶으시다면 언제든지 컨트리뷰션 할 수 있습니다.\n저와 함께 즐겁고 힘겨운 크롤링의 여정을 떠나실 준비가 되신 분들이라면 얼마든지 환영합니다. ^___^\n<br><br><br>\n\n## 7. License\n\n```\nCopyright 2020 Hyunwoong Ko.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\nhttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n```\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/choyoungeun/kocrawl-cna.git",
    "keywords": "crawler,korean crawler,kochat",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "kocrawl-cna",
    "package_url": "https://pypi.org/project/kocrawl-cna/",
    "platform": null,
    "project_url": "https://pypi.org/project/kocrawl-cna/",
    "project_urls": {
      "Homepage": "https://github.com/choyoungeun/kocrawl-cna.git"
    },
    "release_url": "https://pypi.org/project/kocrawl-cna/1.0.1/",
    "requires_dist": [
      "numpy (==1.18.5)",
      "beautifulsoup4 (==4.6.0)",
      "requests (==2.24.0)",
      "tqdm"
    ],
    "requires_python": ">=3",
    "summary": "Korean web crawler collections",
    "version": "1.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 13429727,
  "releases": {
    "1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1f0218e1183fb17e1730a55c0de19bfb060bdfef72bd605f5ad4d6b312f02e0d",
          "md5": "b3497015391e9750d6932a856b90e5e2",
          "sha256": "c426066683ab03bfcde65caadc97d57026f0789345a729e77b2b2c2a703d9864"
        },
        "downloads": -1,
        "filename": "kocrawl_cna-1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "b3497015391e9750d6932a856b90e5e2",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3",
        "size": 42622,
        "upload_time": "2022-04-06T05:33:19",
        "upload_time_iso_8601": "2022-04-06T05:33:19.968047Z",
        "url": "https://files.pythonhosted.org/packages/1f/02/18e1183fb17e1730a55c0de19bfb060bdfef72bd605f5ad4d6b312f02e0d/kocrawl_cna-1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "643d62f1f2f6c2b24c51fc6d94b955096df761736ca3e1d9ce81e7b8c3f5277f",
          "md5": "1dfa5010cb4dd6206171734bf54f3710",
          "sha256": "7f8642dbb5331ec2be81c0e5866b686009d3e829647e9f1d8b789b72762b4cb3"
        },
        "downloads": -1,
        "filename": "kocrawl_cna-1.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "1dfa5010cb4dd6206171734bf54f3710",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3",
        "size": 42726,
        "upload_time": "2022-04-06T14:52:57",
        "upload_time_iso_8601": "2022-04-06T14:52:57.544747Z",
        "url": "https://files.pythonhosted.org/packages/64/3d/62f1f2f6c2b24c51fc6d94b955096df761736ca3e1d9ce81e7b8c3f5277f/kocrawl_cna-1.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "643d62f1f2f6c2b24c51fc6d94b955096df761736ca3e1d9ce81e7b8c3f5277f",
        "md5": "1dfa5010cb4dd6206171734bf54f3710",
        "sha256": "7f8642dbb5331ec2be81c0e5866b686009d3e829647e9f1d8b789b72762b4cb3"
      },
      "downloads": -1,
      "filename": "kocrawl_cna-1.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "1dfa5010cb4dd6206171734bf54f3710",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3",
      "size": 42726,
      "upload_time": "2022-04-06T14:52:57",
      "upload_time_iso_8601": "2022-04-06T14:52:57.544747Z",
      "url": "https://files.pythonhosted.org/packages/64/3d/62f1f2f6c2b24c51fc6d94b955096df761736ca3e1d9ce81e7b8c3f5277f/kocrawl_cna-1.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}