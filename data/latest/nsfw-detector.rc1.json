{
  "info": {
    "author": "Prakhar Baveja",
    "author_email": "prakhar.baveja@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: GNU General Public License v3 (GPLv3)",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: Implementation :: CPython",
      "Programming Language :: Python :: Implementation :: PyPy"
    ],
    "description": "\n<center>\n<img src=\"https://github.com/GantMan/nsfw_model/blob/master/_art/nsfw_detection.png?raw=true\" alt=\"NSFW Detector logo\" width=\"300\" />\n</center>\n\n# NSFW Detection Machine Learning Model\n[![All Contributors](https://img.shields.io/badge/all_contributors-2-orange.svg?style=flat-square)](#contributors)\n\nTrained on 60+ Gigs of data to identify:\n- `drawings` - safe for work drawings (including anime)\n- `hentai` - hentai and pornographic drawings\n- `neutral` - safe for work neutral images\n- `porn` - pornographic images, sexual acts\n- `sexy` - sexually explicit images, not pornography\n\nThis model powers [NSFW JS](https://github.com/infinitered/nsfwjs) - [More Info](https://shift.infinite.red/avoid-nightmares-nsfw-js-ab7b176978b1)\n\n## Current Status:\n93% Accuracy with the following confusion matrix, based on Inception V3.\n![nsfw confusion matrix](_art/nsfw_confusion93.png)\n\nReview the `_art` folder for previous incarnations of this model.\n\n## Requirements:\nkeras (tested with versions > 2.0.0)\ntensorflow >= 2.1.0\n\n## Usage\n\nFor programmatic use of the library. \n\n```python\nfrom nsfw_detector import predict\nmodel = predict.load_model('./nsfw_mobilenet2.224x224.h5')\n\n# Predict single image\npredict.classify(model, '2.jpg')\n# {'2.jpg': {'sexy': 4.3454722e-05, 'neutral': 0.00026579265, 'porn': 0.0007733492, 'hentai': 0.14751932, 'drawings': 0.85139805}}\n\n# Predict multiple images at once\npredict.classify(model, ['/Users/bedapudi/Desktop/2.jpg', '/Users/bedapudi/Desktop/6.jpg'])\n# {'2.jpg': {'sexy': 4.3454795e-05, 'neutral': 0.00026579312, 'porn': 0.0007733498, 'hentai': 0.14751942, 'drawings': 0.8513979}, '6.jpg': {'drawings': 0.004214506, 'hentai': 0.013342537, 'neutral': 0.01834045, 'porn': 0.4431829, 'sexy': 0.5209196}}\n\n# Predict for all images in a directory\npredict.classify(model, '/Users/bedapudi/Desktop/')\n\n```\n\nIf you've installed the package or use the command-line this should work, too...\n\n```sh\n# a single image\nnsfw-predict --saved_model_path mobilenet_v2_140_224 --image_source test.jpg\n\n# an image directory\nnsfw-predict --saved_model_path mobilenet_v2_140_224 --image_source images\n\n# a single image (from code/CLI)\npython3 nsfw_detector/predict.py --saved_model_path mobilenet_v2_140_224 --image_source test.jpg\n\n```\n\n\n## Download\nPlease feel free to use this model to help your products!  \n\nIf you'd like to [say thanks for creating this, I'll take a donation for hosting costs](https://www.paypal.me/GantLaborde).\n\n# Latest Models Zip (v1.1)\nhttps://github.com/GantMan/nsfw_model/releases/tag/1.1.0\n\n### Original Inception v3 Model (v1.0)\n* [Keras 299x299 Image Model](https://s3.amazonaws.com/nsfwdetector/nsfw.299x299.h5)\n* [TensorflowJS 299x299 Image Model](https://s3.amazonaws.com/nsfwdetector/nsfwjs.zip)\n* [TensorflowJS Quantized 299x299 Image Model](https://s3.amazonaws.com/nsfwdetector/min_nsfwjs.zip)\n* [Tensorflow 299x299 Image Model](https://s3.amazonaws.com/nsfwdetector/nsfw.299x299.pb) - [Graph if Needed](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/graph_transforms#inspecting-graphs)\n\n### Original Mobilenet v2 Model (v1.0)\n* [Keras 224x224 Image Model](https://s3.amazonaws.com/ir_public/nsfwjscdn/nsfw_mobilenet2.224x224.h5)\n* [TensorflowJS 224x224 Image Model](https://s3.amazonaws.com/ir_public/nsfwjscdn/TFJS_nsfw_mobilenet/tfjs_nsfw_mobilenet.zip)\n* [TensorflowJS Quantized 224x224 Image Model](https://s3.amazonaws.com/ir_public/nsfwjscdn/TFJS_nsfw_mobilenet/tfjs_quant_nsfw_mobilenet.zip)\n* [Tensorflow 224x224 Image Model](https://s3.amazonaws.com/ir_public/nsfwjscdn/TF_nsfw_mobilenet/nsfw_mobilenet.pb) - [Graph if Needed](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/graph_transforms#inspecting-graphs)\n* [Tensorflow Quantized 224x224 Image Model](https://s3.amazonaws.com/ir_public/nsfwjscdn/TF_nsfw_mobilenet/quant_nsfw_mobilenet.pb) - [Graph if Needed](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/graph_transforms#inspecting-graphs)\n\n## PyTorch Version\nKudos to the community for creating a PyTorch version with resnet!\nhttps://github.com/yangbisheng2009/nsfw-resnet\n\n## Training Folder Contents\nSimple description of the scripts used to create this model:\n* `inceptionv3_transfer/` - Folder with all the code to train the Keras based Inception v3 transfer learning model.  Includes `constants.py` for configuration, and two scripts for actual training/refinement.\n* `mobilenetv2_transfer/` - Folder with all the code to train the Keras based Mobilenet v2 transfer learning model.\n* `visuals.py` - The code to create the confusion matrix graphic\n* `self_clense.py` - If the training data has significant inaccuracy, `self_clense` helps cross validate errors in the training data in reasonable time.   The better the model gets, the better you can use it to clean the training data manually.\n\n_e.g._\n```bash\ncd training\n# Start with all locked transfer of Inception v3\npython inceptionv3_transfer/train_initialization.py\n\n# Continue training on model with fine-tuning\npython inceptionv3_transfer/train_fine_tune.py\n\n# Create a confusion matrix of the model\npython visuals.py\n```\n\n## Extra Info\nThere's no easy way to distribute the training data, but if you'd like to help with this model or train other models, get in touch with me and we can work together.\n\nAdvancements in this model power the quantized TFJS module on https://nsfwjs.com/\n\nMy twitter is [@GantLaborde](https://twitter.com/GantLaborde) - I'm a School Of AI Wizard New Orleans.  I run the twitter account [@FunMachineLearn](https://twitter.com/FunMachineLearn)\n\nLearn more about [me](http://gantlaborde.com/) and the [company I work for](https://infinite.red/).\n\nSpecial thanks to the [nsfw_data_scraper](https://github.com/alexkimxyz/nsfw_data_scrapper) for the training data.  If you're interested in a more detailed analysis of types of NSFW images, you could probably use this repo code with [this data](https://github.com/EBazarov/nsfw_data_source_urls).\n\nIf you need React Native, Elixir, AI, or Machine Learning work, check in with us at [Infinite Red](https://infinite.red/), who make all these experiments possible.  We're an amazing software consultancy worldwide!\n\n## Cite\n```\n@misc{man,\n  title={Deep NN for NSFW Detection},\n  url={https://github.com/GantMan/nsfw_model},\n  journal={GitHub},\n  author={Laborde, Gant}}\n```\n\n## Contributors\n\nThanks goes to these wonderful people ([emoji key](https://github.com/kentcdodds/all-contributors#emoji-key)):\n\n<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->\n| [<img src=\"https://avatars0.githubusercontent.com/u/997157?v=4\" width=\"100px;\"/><br /><sub><b>Gant Laborde</b></sub>](http://gantlaborde.com/)<br />[ðŸ’»](https://github.com/GantMan/nsfw_model/commits?author=GantMan \"Code\") [ðŸ“–](https://github.com/GantMan/nsfw_model/commits?author=GantMan \"Documentation\") [ðŸ¤”](#ideas-GantMan \"Ideas, Planning, & Feedback\") | [<img src=\"https://avatars2.githubusercontent.com/u/15898654?v=4\" width=\"100px;\"/><br /><sub><b>Bedapudi Praneeth</b></sub>](http://bpraneeth.com)<br />[ðŸ’»](https://github.com/GantMan/nsfw_model/commits?author=bedapudi6788 \"Code\") [ðŸ¤”](#ideas-bedapudi6788 \"Ideas, Planning, & Feedback\") |\n| :---: | :---: |\n<!-- ALL-CONTRIBUTORS-LIST:END -->\n\nThis project follows the [all-contributors](https://github.com/kentcdodds/all-contributors) specification. Contributions of any kind welcome!\n\n# Changes\n\n## 1.1.1\n\n- break out numpy (nd array) function\n- remove classic app run modes for argparse\n- one more example in README for running\n- turn down verbosity in image load via file\n- fix requirements for clean system (needs PIL)\n\n## 1.1.0\n\n- update to tensorflow 2.1.0 and updated mobilenet-based model\n\n## 1.0.0\n\n- initial creation\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/GantMan/nsfw_model",
    "keywords": "",
    "license": "GPLv3",
    "maintainer": "",
    "maintainer_email": "",
    "name": "nsfw-detector",
    "package_url": "https://pypi.org/project/nsfw-detector/",
    "platform": "",
    "project_url": "https://pypi.org/project/nsfw-detector/",
    "project_urls": {
      "Homepage": "https://github.com/GantMan/nsfw_model"
    },
    "release_url": "https://pypi.org/project/nsfw-detector/1.1.1/",
    "requires_dist": [
      "pillow",
      "tensorflow-hub (==0.7.0)",
      "tensorflow (>=2.1.0)"
    ],
    "requires_python": ">=3.5.0",
    "summary": "NSFW Image Detection with Deep Learning",
    "version": "1.1.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12409405,
  "releases": {
    "1.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "08b5bcac8fa8e8c1911ee1ab87c59ae0e29f8aabbc50e3525f83bf2d6ed0fff8",
          "md5": "16adf74dc698ca12495528018f8579ca",
          "sha256": "91aee149fb67c95f784c5fcde50eb4c43c0a4dc3b0aad5f504507da2110dbf8f"
        },
        "downloads": -1,
        "filename": "nsfw_detector-1.1.1-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "16adf74dc698ca12495528018f8579ca",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": ">=3.5.0",
        "size": 7398,
        "upload_time": "2021-12-26T18:15:12",
        "upload_time_iso_8601": "2021-12-26T18:15:12.258795Z",
        "url": "https://files.pythonhosted.org/packages/08/b5/bcac8fa8e8c1911ee1ab87c59ae0e29f8aabbc50e3525f83bf2d6ed0fff8/nsfw_detector-1.1.1-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "77c1d6fd5156cd17ae590b317c75cfe345d5829bc46deac78263aeae136d9f9b",
          "md5": "42eca0b3a49b87c3c929078d42a342ca",
          "sha256": "3ed40757c9073112efda56b144c6f0465383f52ede0ac09db5e51fc73815cdec"
        },
        "downloads": -1,
        "filename": "nsfw_detector-1.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "42eca0b3a49b87c3c929078d42a342ca",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5.0",
        "size": 7713,
        "upload_time": "2021-12-26T18:15:14",
        "upload_time_iso_8601": "2021-12-26T18:15:14.449064Z",
        "url": "https://files.pythonhosted.org/packages/77/c1/d6fd5156cd17ae590b317c75cfe345d5829bc46deac78263aeae136d9f9b/nsfw_detector-1.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "08b5bcac8fa8e8c1911ee1ab87c59ae0e29f8aabbc50e3525f83bf2d6ed0fff8",
        "md5": "16adf74dc698ca12495528018f8579ca",
        "sha256": "91aee149fb67c95f784c5fcde50eb4c43c0a4dc3b0aad5f504507da2110dbf8f"
      },
      "downloads": -1,
      "filename": "nsfw_detector-1.1.1-py2.py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "16adf74dc698ca12495528018f8579ca",
      "packagetype": "bdist_wheel",
      "python_version": "py2.py3",
      "requires_python": ">=3.5.0",
      "size": 7398,
      "upload_time": "2021-12-26T18:15:12",
      "upload_time_iso_8601": "2021-12-26T18:15:12.258795Z",
      "url": "https://files.pythonhosted.org/packages/08/b5/bcac8fa8e8c1911ee1ab87c59ae0e29f8aabbc50e3525f83bf2d6ed0fff8/nsfw_detector-1.1.1-py2.py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "77c1d6fd5156cd17ae590b317c75cfe345d5829bc46deac78263aeae136d9f9b",
        "md5": "42eca0b3a49b87c3c929078d42a342ca",
        "sha256": "3ed40757c9073112efda56b144c6f0465383f52ede0ac09db5e51fc73815cdec"
      },
      "downloads": -1,
      "filename": "nsfw_detector-1.1.1.tar.gz",
      "has_sig": false,
      "md5_digest": "42eca0b3a49b87c3c929078d42a342ca",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.5.0",
      "size": 7713,
      "upload_time": "2021-12-26T18:15:14",
      "upload_time_iso_8601": "2021-12-26T18:15:14.449064Z",
      "url": "https://files.pythonhosted.org/packages/77/c1/d6fd5156cd17ae590b317c75cfe345d5829bc46deac78263aeae136d9f9b/nsfw_detector-1.1.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}