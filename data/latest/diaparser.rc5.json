{
  "info": {
    "author": "Yu Zhang, Giuseppe Attardi",
    "author_email": "yzhang.cs@outlook.com, attardi@di.unipi.it",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Topic :: Scientific/Engineering :: Artificial Intelligence",
      "Topic :: Text Processing :: Linguistic"
    ],
    "description": "![DiaParser](docs/source/logo.png)\n# DiaParser\n\n[![build](https://github.com/Unipisa/diaparser/workflows/build/badge.svg)](https://github.com/Unipisa/diaparser/actions)\n[![docs](https://readthedocs.org/projects/diaparser/badge/?version=latest)](https://diaparser.readthedocs.io/en/latest)\n[![release](https://img.shields.io/github/v/release/Unipisa/diaparser)](https://github.com/Unipisa/diaparser/releases)\n[![downloads](https://pepy.tech/badge/diaparser)](https://pepy.tech/project/diaparser)\n[![LICENSE](https://img.shields.io/github/license/Unipisa/diaparser)](https://github.com/Unipisa/diaparser/blob/master/LICENSE)\n\n`DiaParser` is a **state-of-the-art dependency parser**, that extends the architecture of the Biaffine Parser ([Dozat and Manning, 2017](#dozat-2017-biaffine)) by exploiting both embeddings and attentions provided by **transformers**.\n\nBy exploiting the rich hidden linguistic information in contextual embeddings from transformers, `DiaParser` can avoid using intermediate annotations like POS, lemma and morphology, used in traditional parsers.\nTherefore the only stages in the parsing pipeline are tokenization and parsing.\n\nThe parser may also work **directly on plain text**.\nThe parser automatically dowloads pretrained models as well as tokenizers and produces dependency parsing trees, as detailed in [Usage](#Usage).\n\nExploiting attentions from transformer heads provides improvements in accuracy, without resorting to fine tuning or training its own attention.\nOverall, this simplifies the architecture and lowers the cost of resources needed during training, especially memory, and allows the parser to improve as new versions of transformers become available.\nThe parser uses the [HuggingFace Transformers API](https://huggingface.co/transformers/) and in particular the generic [AutoClasses interface](https://huggingface.co/transformers/model_doc/auto.html) to access the transformer models avaiable.\n\nWe plan to track the improvements in transformer technology and to realease models of the parser that incorporate these models.\nCurrently we provide **pretrained models** for 18 languages.\n\nWe encourage anyone to contribute trained models for other combinatiobns of language/transformer pairs, that we will publish.\nWe will soon provide a web form where to upload new models.\n\nYou can also train your own models and contribute them to the repository, to share with others.\n\n`DiaParser` uses pretrained contextual embeddings for representing input from models in [`transformers`](https://github.com/huggingface/transformers).\n\nPretrained tokenizers are provided by [Stanza](https://stanfordnlp.github.io/stanza/).\n\nAlternatively to contextual embeddings, `DiaParser` also allows to utilize CharLSTM layers to produce character/subword-level features.\nBoth BERT and CharLSTM avoid the need of generating POS tags.\n\n`DiaParser` is derived from [`SuPar`](https://github.com/yzhangcs/parser), which provides additional variants of dependency and constituency parsers.\n\n## Contents\n\n* [Contents](#contents)\n* [Installation](#installation)\n* [Performance](#performance)\n* [Usage](#usage)\n  * [Training](#training)\n  * [Evaluation](#evaluation)\n* [TODO](#todo)\n* [References](#references)\n\n## Installation\n\n`DiaParser` can be installed via `pip`:\n```sh\n$ pip install -U diaparser\n```\nInstalling from sources is also possible:\n```sh\n$ git clone https://github.com/Unipisa/diaparser && cd diaparser\n$ python setup.py install\n```\n\nThe package has the following requirements:\n* `python`: >= 3.6\n* [`pytorch`](https://github.com/pytorch/pytorch): >= 1.4\n* [`transformers`](https://github.com/huggingface/transformers): >= 3.1\n* optional tokenizers [`stanza`](https://stanfordnlp.github.io/stanza/): >= 1.1.1\n\n## Performance\n\n`DiaParser` provides pretrained models for English, Chinese and other 21 languages from the Universal Dependencies treebanks [v2.6](https://universaxsldependencies.org).\nEnglish models are trained on the Penn Treebank (PTB) with Stanford Dependencies, with 39,832 training sentences, while Chinese models are trained on Penn Chinese Treebank version 7 (CTB7) with 46,572 training sentences.\n\nThe accuracy and parsing speed of these models are listed in the following tables.\nThe first table shows the result of parsing starting from gold tokenized text.\nNotably, punctuation is ignored in the evaluation metrics for PTB, but included in all the others.\nThe numbers in bold represent state-of-the-art values.\n\n<table>\n  <thead>\n    <tr>\n      <th>Language</th>\n      <th align=\"center\">Corpus</th>\n      <th align=\"center\">Name</th>\n      <th align=\"center\">UAS</th>\n      <th align=\"center\">LAS</th>\n      <th align=\"right\">Speed (Sents/s)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>English</td>\n      <td>PTB</td>\n      <td><code>en_ptb.electra</code></td>\n      <td align=\"center\"><b>96.03</b></td>\n      <td align=\"center\"><b>94.37</b></td>\n      <td align=\"right\">352</td>\n    </tr>\n    <tr>\n      <td>Chinese</td>\n      <td>CTB</td>\n      <td><code>zh_ptb.hfl</code></td>\n      <td align=\"center\">92.14</td>\n      <td align=\"center\">85.74</td>\n      <td align=\"right\">319</td>\n    </tr>\n    <tr>\n      <td>Catalan</td>\n      <td>AnCora</td>\n      <td><code>ca_ancora.mbert</code></td>\n      <td align=\"center\"><b>95.55</b></td>\n      <td align=\"center\"><b>93.78</b></td>\n      <td align=\"right\">249</td>\n    </tr>\n    <tr>\n      <td>German</td>\n      <td>HDT</td>\n      <td><code>de_htd.dbmdz-bert-base</code></td>\n      <td align=\"center\"><b>97.97</b></td>\n      <td align=\"center\"><b>96.97</b></td>\n      <td align=\"right\">184</td>\n    </tr>\n    <tr>\n      <td>Japanese</td>\n      <td>GSD</td>\n      <td><code>ja_gsd.mbert</code></td>\n      <td align=\"center\"><b>95.41</b></td>\n      <td align=\"center\"><b>93.98</b></td>\n      <td align=\"right\">397</td>\n    </tr>\n    <tr>\n      <td>Latin</td>\n      <td>ITTB, LLCT</td>\n      <td><code>la_ittb_llct.mbert</code></td>\n      <td align=\"center\"><b>94.03</b></td>\n      <td align=\"center\"><b>91.70</b></td>\n      <td align=\"right\">139</td>\n    </tr>\n    <tr>\n      <td>Norwegian</td>\n      <td>Nynorsk</td>\n      <td><code>no_nynorsk.mbert</code></td>\n      <td align=\"center\"><b>92.50</b></td>\n      <td align=\"center\"><b>90.13</b></td>\n      <td align=\"right\">185</td>\n    </tr>\n    <tr>\n      <td>Romanian</td>\n      <td>RRT</td>\n      <td><code>ro_rrt.mbert</code></td>\n      <td align=\"center\"><b>93.03</b></td>\n      <td align=\"center\"><b>87.18</b></td>\n      <td align=\"right\">286</td>\n    </tr>\n    <tr>\n      <td>Spanish</td>\n      <td>AnCora</td>\n      <td><code>es_ancora.mbert</code></td>\n      <td align=\"center\"><b>96.03</b></td>\n      <td align=\"center\"><b>94.37</b></td>\n      <td align=\"right\">352</td>\n    </tr>\n    <tr>\n      <td>Turkish</td>\n      <td>Boun</td>\n      <td><code>tr_boun.electra-base</code></td>\n      <td align=\"center\"><b>83.53</b></td>\n      <td align=\"center\"><b>75.87</b></td>\n      <td align=\"right\">1198</td>\n    </tr>\n\n  </tbody>\n</table>\n\nBelow are the results on the dataset of the [IWPT 2020 Shared Task on Enhanced Dependencies](), where the tokenization was done by the parser itself:\n<table>\n  <thead>\n    <tr>\n      <th>Language</th>\n      <th align=\"center\">Corpus</th>\n      <th align=\"center\">Name</th>\n      <th align=\"center\">UAS</th>\n      <th align=\"center\">LAS</th>\n      <th align=\"right\">Speed (Sents/s)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Arabic</td>\n      <td>PADT</td>\n      <td><code>ar_padt.bert</code></td>\n      <td align=\"center\"><b>87.75</b></td>\n      <td align=\"center\"><b>83.25</b></td>\n      <td align=\"right\">99</td>\n    </tr>\n    <tr>\n      <td>Bulgarian</td>\n      <td>BTB</td>\n      <td><code>bg_btb.DeepPavlov</code></td>\n      <td align=\"center\">95.02</td>\n      <td align=\"center\">92.20</td>\n      <td align=\"right\">479</td>\n    </tr>\n    <tr>\n      <td>Czech</td>\n      <td>PDT, CAC, FicTree</td>\n      <td><code>cs_pdt_cac_fictree.DeepPavlov</code></td>\n      <td align=\"center\"><b>94.02</b></td>\n      <td align=\"center\"><b>92.06</b></td>\n      <td align=\"right\">403</td>\n    </tr>\n    <tr>\n      <td>English</td>\n      <td>EWT</td>\n      <td><code>en_ewt.electra</code></td>\n      <td align=\"center\"><b>91.66</b></td>\n      <td align=\"center\"><b>89.51</b></td>\n      <td align=\"right\">397</td>\n    </tr>\n    <tr>\n      <td>Estonian</td>\n      <td>EDT, EWT</td>\n      <td><code>et_edt_ewt.mbert</code></td>\n      <td align=\"center\">86.39</td>\n      <td align=\"center\">82.44</td>\n      <td align=\"right\">247</td>\n    </tr>\n    <tr>\n      <td>Finnish</td>\n      <td>TDT</td>\n      <td><code>fi_tdt.turkunlp</code></td>\n      <td align=\"center\"><b>94.28</b></td>\n      <td align=\"center\"><b>92.56</b></td>\n      <td align=\"right\">364</td>\n    </tr>\n    <tr>\n      <td>French</td>\n      <td>sequoia</td>\n      <td><code>fr_sequoia.camembert</code></td>\n      <td align=\"center\"><b>92.81</b></td>\n      <td align=\"center\"><b>89.55</b></td>\n      <td align=\"right\">200</td>\n    </tr>\n    <tr>\n      <td>German</td>\n      <td>HDT</td>\n      <td><code>de_hdt.dbmdz-bert-base</code></td>\n      <td align=\"center\"><b>97.97</b></td>\n      <td align=\"center\"><b>96.97</b></td>\n      <td align=\"right\">381</td>\n    </tr>\n    <tr>\n      <td>Italian</td>\n      <td>ISDT</td>\n      <td><code>it_isdt.dbmdz-electra-xxl</code></td>\n      <td align=\"center\"><b>95.48</b></td>\n      <td align=\"center\"><b>94.16</b></td>\n      <td align=\"right\">379</td>\n    </tr>\n    <tr>\n      <td>Latvian</td>\n      <td>LVBT</td>\n      <td><code>lv_lvtb.mbert</code></td>\n      <td align=\"center\">87.46</td>\n      <td align=\"center\">83.51</td>\n      <td align=\"right\">290</td>\n    </tr>\n    <tr>\n      <td>Lithuanian</td>\n      <td>ALKSNIS</td>\n      <td><code>lt_alksnis.mbert</code></td>\n      <td align=\"center\">80.09</td>\n      <td align=\"center\">75.14</td>\n      <td align=\"right\">290</td>\n    </tr>\n    <tr>\n      <td>Dutch</td>\n      <td>Alpino, LassySmall</td>\n      <td><code>nl_alpino_lassysmall.wietsedv</code></td>\n      <td align=\"center\">90.80</td>\n      <td align=\"center\">88.34</td>\n      <td align=\"right\">367</td>\n    </tr>\n    <tr>\n      <td>Polish</td>\n      <td>PDB, LFG</td>\n      <td><code>pl_pdb_lfg.dkleczek</code></td>\n      <td align=\"center\"><b>94.38</b></td>\n      <td align=\"center\"><b>91.70</b></td>\n      <td align=\"right\">563</td>\n    </tr>\n    <tr>\n      <td>Russian</td>\n      <td>SynTagRus</td>\n      <td><code>ru_syntagrus.DeepPavlov</code></td>\n      <td align=\"center\"><b>94.97</b></td>\n      <td align=\"center\"><b>93.72</b></td>\n      <td align=\"right\">445</td>\n    </tr>\n    <tr>\n      <td>Slovak</td>\n      <td>SNK</td>\n      <td><code>sk_snk.mbert</code></td>\n      <td align=\"center\">93.11</td>\n      <td align=\"center\">90.44</td>\n      <td align=\"right\">381</td>\n    </tr>\n    <tr>\n      <td>Swediskh</td>\n      <td>Talbanken</td>\n      <td><code>sv_talbanken.KB</code></td>\n      <td align=\"center\"><b>90.79</b></td>\n      <td align=\"center\"><b>88.08</b></td>\n      <td align=\"right\">491</td>\n    </tr>\n    <tr>\n      <td>Tamil</td>\n      <td>TTB</td>\n      <td><code>ta_ttb.mbert</code></td>\n      <td align=\"center\">74.20</td>\n      <td align=\"center\">66.49</td>\n      <td align=\"right\">175</td>\n    </tr>\n    <tr>\n      <td>Ukrainian</td>\n      <td>IU</td>\n      <td><code>uk_iu.TurkuNLP</code></td>\n      <td align=\"center\">90.39</td>\n      <td align=\"center\">87.61</td>\n      <td align=\"right\">301</td>\n    </tr>\n  </tbody>\n</table>\n\nThese results were obtained on a server with Intel(R) Xeon(R) Gold 6132 CPU @ 2.60GHz\nand Nvidia T4 GPU.\n\n## Usage\n\n`DiaParser` is simple to use: you can just download a pretrained model and run syntactic parsing over sentences with a few lines of code:\n```py\n>>> from diaparser.parsers import Parser\n>>> parser = Parser.load('en_ewt-electra')\n>>> dataset = parser.predict([['She', 'enjoys', 'playing', 'tennis', '.']], prob=True)\n```\nThe call to `parser.predict` will return an instance of `diaparser.utils.Dataset` containing the predicted syntactic trees.\nYou can access each sentence within the `dataset`:\n```py\n>>> print(dataset.sentences[0])\n1       She     _       _       _       _       2       nsubj   _       _\n2       enjoys  _       _       _       _       0       root    _       _\n3       playing _       _       _       _       2       xcomp   _       _\n4       tennis  _       _       _       _       3       dobj    _       _\n5       .       _       _       _       _       2       punct   _       _\n```\n\nTo parse plain text just requires specifying the language code:\n```py\n>>> dataset = parser.predict('She enjoys playing tennis.', text='en')\n```\n\nAn SVG picture illusrating the parse tree can be produced with:\n```py\n>>> sent = dataset.sentences[0]\n>>> displacy.render(sent.to_displacy(), style='dep', manual=True, options={'compact': True, 'distance': 120})\n```\n![parse tree](./docs/source/tree.svg)\n\nThe input can be provided in a file in CoNLL-U format.\n\nFurther examples of how to use the parser and experiment with it can be found in this [notebook](demo/DiaParser.ipynb).\n\n\n### Training\n\nTo train a model from scratch, it is preferred to use the command-line option, which is more flexible and customizable.\nHere are some training examples:\n```sh\n# Biaffine Dependency Parser\n# some common and default arguments are stored in config.ini\n$ python -m diaparser.cmds.biaffine_dependency train -b -d 0  \\\n    -c config.ini  \\\n    -p exp/en_ptb.char/model  \\\n    -f char\n# to use BERT, `-f` and `--bert` (default to bert-base-cased) should be specified\n$ python -m diaparser.cmds.biaffine_dependency train -b -d 0  \\\n    -p exp/en_ptb.bert-base/model  \\\n    -f bert  \\\n    --bert bert-base-cased\n```\n\n**Warning**. There is currently a limit of 500 to the length of tokenized sentences, due to the maximum size of embeddings in most pretrained trnsformer models.\n\nFor further instructions on training, please type `python -m diaparser.cmds.<parser> train -h`.\n\nAlternatively, `DiaParser` provides an equivalent command entry points registered in `setup.py`:\n`diaparser`.\n```sh\n$ diaparser train -b -d 0 -c config.ini -p exp/en_ptb.electra-base/model -f bert --bert google/electra-base-discriminator\n```\n\nFor handling large models, distributed training is also supported:\n```sh\n$ python -m torch.distributed.launch --nproc_per_node=4 --master_port=10000  \\\n    -m parser.cmds.biaffine_dependency train -b -d 0,1,2,3  \\\n    -p exp/en_ptb.electra-base/model  \\\n    -f bert --bert google/electra-base-discriminator\n```\nYou may consult the PyTorch [documentation](https://pytorch.org/docs/stable/notes/ddp.html) and [tutorials](https://pytorch.org/tutorials/intermediate/ddp_tutorial.html) for more details.\n\n### Evaluation\n\nThe evaluation process resembles prediction:\n```py\n>>> parser = Parser.load('biaffine-dep-en')\n>>> loss, metric = parser.evaluate('data/ptb/test.conllx')\n2020-07-25 20:59:17 INFO Loading the data\n2020-07-25 20:59:19 INFO\nDataset(n_sentences=2416, n_batches=11, n_buckets=8)\n2020-07-25 20:59:19 INFO Evaluating the dataset\n2020-07-25 20:59:20 INFO loss: 0.2326 - UCM: 61.34% LCM: 50.21% UAS: 96.03% LAS: 94.37%\n2020-07-25 20:59:20 INFO 0:00:01.253601s elapsed, 1927.25 Sents/s\n```\n\n## TODO\n\n- [ ] Provide a repository where to upload models, like HuggingFace.\n\n\n## References\n\n* Giuseppe Attardi, Daniele Sartiano, Yu Zhang. 2021. DiaParser attentive dependency parser. Submitted for publication.\n* <a id=\"dozat-2017-biaffine\"></a>\nTimothy Dozat and Christopher D. Manning. 2017. [Deep Biaffine Attention for Neural Dependency Parsing](https://openreview.net/forum?id=Hk95PK9le).\n* <a id=\"wang-2019-second\"></a>\nXinyu Wang, Jingxian Huang, and Kewei Tu. 2019. [Second-Order Semantic Dependency Parsing with End-to-End Neural Networks](https://www.aclweb.org/anthology/P19-1454/).\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/Unipisa/diaparser",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "diaparser",
    "package_url": "https://pypi.org/project/diaparser/",
    "platform": null,
    "project_url": "https://pypi.org/project/diaparser/",
    "project_urls": {
      "Homepage": "https://github.com/Unipisa/diaparser"
    },
    "release_url": "https://pypi.org/project/diaparser/1.1.3/",
    "requires_dist": [
      "torch (>=1.6)",
      "transformers",
      "nltk",
      "stanza (==1.2.3)",
      "numpy"
    ],
    "requires_python": ">=3.6",
    "summary": "Direct Attentive Dependency Parser",
    "version": "1.1.3",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17418497,
  "releases": {
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1fae258d013e4c47d535188d89ab76bd2b70f100ac15c26638866870154e9740",
          "md5": "4797319da326c7c12cd2dbde681a7295",
          "sha256": "1e1bf86d4bfd9f741331db8184cfcf797c4f078444ee7eff5228a31f8bc5985a"
        },
        "downloads": -1,
        "filename": "diaparser-1.0.0-py3.6.egg",
        "has_sig": false,
        "md5_digest": "4797319da326c7c12cd2dbde681a7295",
        "packagetype": "bdist_egg",
        "python_version": "3.6",
        "requires_python": ">=3.6",
        "size": 155335,
        "upload_time": "2020-10-19T13:56:40",
        "upload_time_iso_8601": "2020-10-19T13:56:40.266883Z",
        "url": "https://files.pythonhosted.org/packages/1f/ae/258d013e4c47d535188d89ab76bd2b70f100ac15c26638866870154e9740/diaparser-1.0.0-py3.6.egg",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b3df18c03c87fc28410b5512ab86525044196913e550be933af624c96a0fa7e5",
          "md5": "d3fd7c076aae9f4356f87541a15f7877",
          "sha256": "195896c5f58aad526898627c6b338e490e33542ce6fb4ee346563ff5278eb23e"
        },
        "downloads": -1,
        "filename": "diaparser-1.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d3fd7c076aae9f4356f87541a15f7877",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 70520,
        "upload_time": "2020-10-19T13:56:35",
        "upload_time_iso_8601": "2020-10-19T13:56:35.802780Z",
        "url": "https://files.pythonhosted.org/packages/b3/df/18c03c87fc28410b5512ab86525044196913e550be933af624c96a0fa7e5/diaparser-1.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "19cdcc5d1fa85f5a322e992c3cd3ba40ac5ae8ecfe11e197a525e50b10de73bb",
          "md5": "27fa38199a331a3663f7dfdd15fd1307",
          "sha256": "2befa65d10c2bcffc78929dc9bf6cf11e8c9df3334ecfd76a1f87eceb57636d8"
        },
        "downloads": -1,
        "filename": "diaparser-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "27fa38199a331a3663f7dfdd15fd1307",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 51965,
        "upload_time": "2020-10-19T13:56:41",
        "upload_time_iso_8601": "2020-10-19T13:56:41.762826Z",
        "url": "https://files.pythonhosted.org/packages/19/cd/cc5d1fa85f5a322e992c3cd3ba40ac5ae8ecfe11e197a525e50b10de73bb/diaparser-1.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6263a24a72356caefc3a2a37b73c2374913dabb5f744b1ff53188fd16356ed73",
          "md5": "52f79a1b9e229c4b6837bb61e8705ab3",
          "sha256": "879d1697d84382a5041248955945c76e4a24adb062051fdd500e2f9ce685d57a"
        },
        "downloads": -1,
        "filename": "diaparser-1.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "52f79a1b9e229c4b6837bb61e8705ab3",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 74380,
        "upload_time": "2020-10-22T13:56:08",
        "upload_time_iso_8601": "2020-10-22T13:56:08.961833Z",
        "url": "https://files.pythonhosted.org/packages/62/63/a24a72356caefc3a2a37b73c2374913dabb5f744b1ff53188fd16356ed73/diaparser-1.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0c5cb15a6715f25c44e67442d6943b946d130e53e9adb8491d47f8df32f28ad8",
          "md5": "1a7b08e206cfd36bded1024dec41904a",
          "sha256": "ab3d9c14a2f4974e747a117cb4c705f4f3a19c0fc4b36b47c8ba2f8bc5a341c9"
        },
        "downloads": -1,
        "filename": "diaparser-1.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "1a7b08e206cfd36bded1024dec41904a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 52555,
        "upload_time": "2020-10-22T13:56:10",
        "upload_time_iso_8601": "2020-10-22T13:56:10.422801Z",
        "url": "https://files.pythonhosted.org/packages/0c/5c/b15a6715f25c44e67442d6943b946d130e53e9adb8491d47f8df32f28ad8/diaparser-1.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f0bfdae1e7f23303a99b9b7463d7e24d27377e0ea362ac4daf59ccb8d5ccbabf",
          "md5": "98d39f0588bbdfb8cc5438f0ee149069",
          "sha256": "18335e176376a6d256a9acafca07abf8afd2d4f1002d273e6a19ddc8d2336612"
        },
        "downloads": -1,
        "filename": "diaparser-1.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "98d39f0588bbdfb8cc5438f0ee149069",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 66318,
        "upload_time": "2020-11-27T14:33:21",
        "upload_time_iso_8601": "2020-11-27T14:33:21.434822Z",
        "url": "https://files.pythonhosted.org/packages/f0/bf/dae1e7f23303a99b9b7463d7e24d27377e0ea362ac4daf59ccb8d5ccbabf/diaparser-1.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5e9a91715110c47a65f5587327a14849039508dec181b01429598240c90cc222",
          "md5": "c32fe95742306b1811207e900c3ab195",
          "sha256": "5651c3533f34ee1efd9966692bd7949a31ee243a22c22da1a76d8e8396e9631e"
        },
        "downloads": -1,
        "filename": "diaparser-1.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "c32fe95742306b1811207e900c3ab195",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 57038,
        "upload_time": "2020-11-27T14:33:22",
        "upload_time_iso_8601": "2020-11-27T14:33:22.334561Z",
        "url": "https://files.pythonhosted.org/packages/5e/9a/91715110c47a65f5587327a14849039508dec181b01429598240c90cc222/diaparser-1.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bc0187045f78632ac8408b92e834d3ea36793cdd8bbb21c87bdd3c6804d7f608",
          "md5": "2a280e4bd9517c357c546a9bad1b87e4",
          "sha256": "5c8d0a81fead3018f61011a11cc573000a7bb3362f5bf9236877aca20dccd9b3"
        },
        "downloads": -1,
        "filename": "diaparser-1.1.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "2a280e4bd9517c357c546a9bad1b87e4",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 69506,
        "upload_time": "2021-03-24T17:18:36",
        "upload_time_iso_8601": "2021-03-24T17:18:36.728089Z",
        "url": "https://files.pythonhosted.org/packages/bc/01/87045f78632ac8408b92e834d3ea36793cdd8bbb21c87bdd3c6804d7f608/diaparser-1.1.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d3878ee7fd23fd3bec5a89f31e50611416ac87a5c5fa9f73658a3effaf5abcb1",
          "md5": "61038b6b81a05825510234742520ffda",
          "sha256": "9d823e3b8e0798f2d0fb50d06e2e4394879ba397e511360153d8ac57e158ea06"
        },
        "downloads": -1,
        "filename": "diaparser-1.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "61038b6b81a05825510234742520ffda",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 61663,
        "upload_time": "2021-03-24T17:18:37",
        "upload_time_iso_8601": "2021-03-24T17:18:37.767602Z",
        "url": "https://files.pythonhosted.org/packages/d3/87/8ee7fd23fd3bec5a89f31e50611416ac87a5c5fa9f73658a3effaf5abcb1/diaparser-1.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d6f3df38e0ced703d8febdf9824d1f483ba244c9507d4ffb279f58964e697409",
          "md5": "e415927975da26bcf73dd8cd51c1c77f",
          "sha256": "554b11adc9cb4d911b6923e40296621b4f529585e4a000efde4e2a6d5f75fed6"
        },
        "downloads": -1,
        "filename": "diaparser-1.1.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "e415927975da26bcf73dd8cd51c1c77f",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 69665,
        "upload_time": "2023-03-23T16:57:13",
        "upload_time_iso_8601": "2023-03-23T16:57:13.479625Z",
        "url": "https://files.pythonhosted.org/packages/d6/f3/df38e0ced703d8febdf9824d1f483ba244c9507d4ffb279f58964e697409/diaparser-1.1.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2654bc02986fa43c88eeb0f2b527a5d66a322cab6a8c5ebd07bb37961bed565c",
          "md5": "3a922de006b680c5059fe023be34dbd8",
          "sha256": "a8ca0262110c9079d0fbf9cdb254cf90910685c4798529faf4bc4f3033bc54e3"
        },
        "downloads": -1,
        "filename": "diaparser-1.1.3.tar.gz",
        "has_sig": false,
        "md5_digest": "3a922de006b680c5059fe023be34dbd8",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 62619,
        "upload_time": "2023-03-23T16:57:15",
        "upload_time_iso_8601": "2023-03-23T16:57:15.268347Z",
        "url": "https://files.pythonhosted.org/packages/26/54/bc02986fa43c88eeb0f2b527a5d66a322cab6a8c5ebd07bb37961bed565c/diaparser-1.1.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "d6f3df38e0ced703d8febdf9824d1f483ba244c9507d4ffb279f58964e697409",
        "md5": "e415927975da26bcf73dd8cd51c1c77f",
        "sha256": "554b11adc9cb4d911b6923e40296621b4f529585e4a000efde4e2a6d5f75fed6"
      },
      "downloads": -1,
      "filename": "diaparser-1.1.3-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "e415927975da26bcf73dd8cd51c1c77f",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 69665,
      "upload_time": "2023-03-23T16:57:13",
      "upload_time_iso_8601": "2023-03-23T16:57:13.479625Z",
      "url": "https://files.pythonhosted.org/packages/d6/f3/df38e0ced703d8febdf9824d1f483ba244c9507d4ffb279f58964e697409/diaparser-1.1.3-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "2654bc02986fa43c88eeb0f2b527a5d66a322cab6a8c5ebd07bb37961bed565c",
        "md5": "3a922de006b680c5059fe023be34dbd8",
        "sha256": "a8ca0262110c9079d0fbf9cdb254cf90910685c4798529faf4bc4f3033bc54e3"
      },
      "downloads": -1,
      "filename": "diaparser-1.1.3.tar.gz",
      "has_sig": false,
      "md5_digest": "3a922de006b680c5059fe023be34dbd8",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 62619,
      "upload_time": "2023-03-23T16:57:15",
      "upload_time_iso_8601": "2023-03-23T16:57:15.268347Z",
      "url": "https://files.pythonhosted.org/packages/26/54/bc02986fa43c88eeb0f2b527a5d66a322cab6a8c5ebd07bb37961bed565c/diaparser-1.1.3.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}