{
  "info": {
    "author": "",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "Environment :: GPU :: NVIDIA CUDA",
      "License :: OSI Approved :: Apache Software License",
      "Programming Language :: Python :: 3",
      "Topic :: Scientific/Engineering :: Artificial Intelligence",
      "Topic :: System :: Distributed Computing"
    ],
    "description": "# Colossal-AI\n<div id=\"top\" align=\"center\">\n\n   [![logo](https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/colossal-ai_logo_vertical.png)](https://www.colossalai.org/)\n\n   Colossal-AI: Making large AI models cheaper, faster and more accessible\n\n   <h3> <a href=\"https://arxiv.org/abs/2110.14883\"> Paper </a> |\n   <a href=\"https://www.colossalai.org/\"> Documentation </a> |\n   <a href=\"https://github.com/hpcaitech/ColossalAI/tree/main/examples\"> Examples </a> |\n   <a href=\"https://github.com/hpcaitech/ColossalAI/discussions\"> Forum </a> |\n   <a href=\"https://medium.com/@hpcaitech\"> Blog </a></h3>\n\n   [![GitHub Repo stars](https://img.shields.io/github/stars/hpcaitech/ColossalAI?style=social)](https://github.com/hpcaitech/ColossalAI/stargazers)\n   [![Build](https://github.com/hpcaitech/ColossalAI/actions/workflows/build_on_schedule.yml/badge.svg)](https://github.com/hpcaitech/ColossalAI/actions/workflows/build_on_schedule.yml)\n   [![Documentation](https://readthedocs.org/projects/colossalai/badge/?version=latest)](https://colossalai.readthedocs.io/en/latest/?badge=latest)\n   [![CodeFactor](https://www.codefactor.io/repository/github/hpcaitech/colossalai/badge)](https://www.codefactor.io/repository/github/hpcaitech/colossalai)\n   [![HuggingFace badge](https://img.shields.io/badge/%F0%9F%A4%97HuggingFace-Join-yellow)](https://huggingface.co/hpcai-tech)\n   [![slack badge](https://img.shields.io/badge/Slack-join-blueviolet?logo=slack&amp)](https://join.slack.com/t/colossalaiworkspace/shared_invite/zt-z7b26eeb-CBp7jouvu~r0~lcFzX832w)\n   [![WeChat badge](https://img.shields.io/badge/微信-加入-green?logo=wechat&amp)](https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/WeChat.png)\n\n\n   | [English](README.md) | [中文](docs/README-zh-Hans.md) |\n\n</div>\n\n## Latest News\n* [2023/03] [ColossalChat: An Open-Source Solution for Cloning ChatGPT With a Complete RLHF Pipeline](https://medium.com/@yangyou_berkeley/colossalchat-an-open-source-solution-for-cloning-chatgpt-with-a-complete-rlhf-pipeline-5edf08fb538b)\n* [2023/03] [AWS and Google Fund Colossal-AI with Startup Cloud Programs](https://www.hpc-ai.tech/blog/aws-and-google-fund-colossal-ai-with-startup-cloud-programs)\n* [2023/02] [Open Source Solution Replicates ChatGPT Training Process! Ready to go with only 1.6GB GPU Memory](https://www.hpc-ai.tech/blog/colossal-ai-chatgpt)\n* [2023/01] [Hardware Savings Up to 46 Times for AIGC and  Automatic Parallelism](https://medium.com/pytorch/latest-colossal-ai-boasts-novel-automatic-parallelism-and-offers-savings-up-to-46x-for-stable-1453b48f3f02)\n* [2022/11] [Diffusion Pretraining and Hardware Fine-Tuning Can Be Almost 7X Cheaper](https://www.hpc-ai.tech/blog/diffusion-pretraining-and-hardware-fine-tuning-can-be-almost-7x-cheaper)\n* [2022/10] [Use a Laptop to Analyze 90% of Proteins, With a Single-GPU Inference Sequence Exceeding 10,000](https://www.hpc-ai.tech/blog/use-a-laptop-to-analyze-90-of-proteins-with-a-single-gpu-inference-sequence-exceeding)\n* [2022/09] [HPC-AI Tech Completes $6 Million Seed and Angel Round Fundraising](https://www.hpc-ai.tech/blog/hpc-ai-tech-completes-6-million-seed-and-angel-round-fundraising-led-by-bluerun-ventures-in-the)\n\n## Table of Contents\n<ul>\n <li><a href=\"#Why-Colossal-AI\">Why Colossal-AI</a> </li>\n <li><a href=\"#Features\">Features</a> </li>\n <li>\n   <a href=\"#Parallel-Training-Demo\">Parallel Training Demo</a>\n   <ul>\n     <li><a href=\"#GPT-3\">GPT-3</a></li>\n     <li><a href=\"#GPT-2\">GPT-2</a></li>\n     <li><a href=\"#BERT\">BERT</a></li>\n     <li><a href=\"#PaLM\">PaLM</a></li>\n     <li><a href=\"#OPT\">OPT</a></li>\n     <li><a href=\"#ViT\">ViT</a></li>\n     <li><a href=\"#Recommendation-System-Models\">Recommendation System Models</a></li>\n   </ul>\n </li>\n <li>\n   <a href=\"#Single-GPU-Training-Demo\">Single GPU Training Demo</a>\n   <ul>\n     <li><a href=\"#GPT-2-Single\">GPT-2</a></li>\n     <li><a href=\"#PaLM-Single\">PaLM</a></li>\n   </ul>\n </li>\n <li>\n   <a href=\"#Inference-Energon-AI-Demo\">Inference (Energon-AI) Demo</a>\n   <ul>\n     <li><a href=\"#GPT-3-Inference\">GPT-3</a></li>\n     <li><a href=\"#OPT-Serving\">OPT-175B Online Serving for Text Generation</a></li>\n     <li><a href=\"#BLOOM-Inference\">176B BLOOM</a></li>\n   </ul>\n </li>\n   <li>\n   <a href=\"#Colossal-AI-in-the-Real-World\">Colossal-AI for Real World Applications</a>\n   <ul>\n     <li><a href=\"#ColossalChat\">ColossalChat: An Open-Source Solution for Cloning ChatGPT With a Complete RLHF Pipeline</a></li>\n     <li><a href=\"#AIGC\">AIGC: Acceleration of Stable Diffusion</a></li>\n     <li><a href=\"#Biomedicine\">Biomedicine: Acceleration of AlphaFold Protein Structure</a></li>\n   </ul>\n </li>\n <li>\n   <a href=\"#Installation\">Installation</a>\n   <ul>\n     <li><a href=\"#PyPI\">PyPI</a></li>\n     <li><a href=\"#Install-From-Source\">Install From Source</a></li>\n   </ul>\n </li>\n <li><a href=\"#Use-Docker\">Use Docker</a></li>\n <li><a href=\"#Community\">Community</a></li>\n <li><a href=\"#Contributing\">Contributing</a></li>\n <li><a href=\"#Cite-Us\">Cite Us</a></li>\n</ul>\n\n## Why Colossal-AI\n<div align=\"center\">\n   <a href=\"https://youtu.be/KnXSfjqkKN0\">\n   <img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/JamesDemmel_Colossal-AI.png\" width=\"600\" />\n   </a>\n\n   Prof. James Demmel (UC Berkeley): Colossal-AI makes training AI models efficient, easy, and scalable.\n</div>\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n\n## Features\n\nColossal-AI provides a collection of parallel components for you. We aim to support you to write your\ndistributed deep learning models just like how you write your model on your laptop. We provide user-friendly tools to kickstart\ndistributed training and inference in a few lines.\n\n- Parallelism strategies\n  - Data Parallelism\n  - Pipeline Parallelism\n  - 1D, [2D](https://arxiv.org/abs/2104.05343), [2.5D](https://arxiv.org/abs/2105.14500), [3D](https://arxiv.org/abs/2105.14450) Tensor Parallelism\n  - [Sequence Parallelism](https://arxiv.org/abs/2105.13120)\n  - [Zero Redundancy Optimizer (ZeRO)](https://arxiv.org/abs/1910.02054)\n  - [Auto-Parallelism](https://arxiv.org/abs/2302.02599)\n\n- Heterogeneous Memory Management\n  - [PatrickStar](https://arxiv.org/abs/2108.05818)\n\n- Friendly Usage\n  - Parallelism based on configuration file\n\n- Inference\n  - [Energon-AI](https://github.com/hpcaitech/EnergonAI)\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n\n## Parallel Training Demo\n\n### GPT-3\n<p align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/GPT3-v5.png\" width=700/>\n</p>\n\n- Save 50% GPU resources, and 10.7% acceleration\n\n### GPT-2\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/GPT2.png\" width=800/>\n\n- 11x lower GPU memory consumption, and superlinear scaling efficiency with Tensor Parallelism\n\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/(updated)GPT-2.png\" width=800>\n\n- 24x larger model size on the same hardware\n- over 3x acceleration\n### BERT\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/BERT.png\" width=800/>\n\n- 2x faster training, or 50% longer sequence length\n\n### PaLM\n- [PaLM-colossalai](https://github.com/hpcaitech/PaLM-colossalai): Scalable implementation of Google's Pathways Language Model ([PaLM](https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html)).\n\n### OPT\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/OPT_update.png\" width=800/>\n\n- [Open Pretrained Transformer (OPT)](https://github.com/facebookresearch/metaseq), a 175-Billion parameter AI language model released by Meta, which stimulates AI programmers to perform various downstream tasks and application deployments because public pretrained model weights.\n- 45% speedup fine-tuning OPT at low cost in lines. [[Example]](https://github.com/hpcaitech/ColossalAI/tree/main/examples/language/opt) [[Online Serving]](https://colossalai.org/docs/advanced_tutorials/opt_service)\n\nPlease visit our [documentation](https://www.colossalai.org/) and [examples](https://github.com/hpcaitech/ColossalAI/tree/main/examples) for more details.\n\n### ViT\n<p align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/ViT.png\" width=\"450\" />\n</p>\n\n- 14x larger batch size, and 5x faster training for Tensor Parallelism = 64\n\n### Recommendation System Models\n- [Cached Embedding](https://github.com/hpcaitech/CachedEmbedding), utilize software cache to train larger embedding tables with a smaller GPU memory budget.\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n\n## Single GPU Training Demo\n\n### GPT-2\n<p id=\"GPT-2-Single\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/GPT2-GPU1.png\" width=450/>\n</p>\n\n- 20x larger model size on the same hardware\n\n<p id=\"GPT-2-NVME\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/GPT2-NVME.png\" width=800/>\n</p>\n\n- 120x larger model size on the same hardware (RTX 3080)\n\n### PaLM\n<p id=\"PaLM-Single\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/PaLM-GPU1.png\" width=450/>\n</p>\n\n- 34x larger model size on the same hardware\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n\n\n## Inference (Energon-AI) Demo\n\n<p id=\"GPT-3-Inference\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/inference_GPT-3.jpg\" width=800/>\n</p>\n\n- [Energon-AI](https://github.com/hpcaitech/EnergonAI): 50% inference acceleration on the same hardware\n\n<p id=\"OPT-Serving\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/BLOOM%20serving.png\" width=600/>\n</p>\n\n- [OPT Serving](https://colossalai.org/docs/advanced_tutorials/opt_service): Try 175-billion-parameter OPT online services\n\n<p id=\"BLOOM-Inference\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/BLOOM%20Inference.PNG\" width=800/>\n</p>\n\n- [BLOOM](https://github.com/hpcaitech/EnergonAI/tree/main/examples/bloom): Reduce hardware deployment costs of 176-billion-parameter BLOOM by more than 10 times.\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n\n## Colossal-AI in the Real World\n\n### ColossalChat\n\n<div align=\"center\">\n   <a href=\"https://chat.colossalai.org/\">\n   <img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/Chat-demo.png\" width=\"700\" />\n   </a>\n</div>\n\n[ColossalChat](https://github.com/hpcaitech/ColossalAI/tree/main/applications/Chat): An open-source solution for cloning [ChatGPT](https://openai.com/blog/chatgpt/) with a complete RLHF pipeline. [[code]](https://github.com/hpcaitech/ColossalAI/tree/main/applications/Chat) [[blog]](https://medium.com/@yangyou_berkeley/colossalchat-an-open-source-solution-for-cloning-chatgpt-with-a-complete-rlhf-pipeline-5edf08fb538b) [[demo]](https://chat.colossalai.org)\n\n<p id=\"ColossalChat_scaling\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/applications/chatgpt/ChatGPT%20scaling.png\" width=800/>\n</p>\n\n- Up to 7.73 times faster for single server training and 1.42 times faster for single-GPU inference\n\n<p id=\"ColossalChat-1GPU\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/applications/chatgpt/ChatGPT-1GPU.jpg\" width=450/>\n</p>\n\n- Up to 10.3x growth in model capacity on one GPU\n- A mini demo training process requires only 1.62GB of GPU memory (any consumer-grade GPU)\n\n<p id=\"ColossalChat-LoRA\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/applications/chatgpt/LoRA%20data.jpg\" width=600/>\n</p>\n\n- Increase the capacity of the fine-tuning model by up to 3.7 times on a single GPU\n- Keep in a sufficiently high running speed\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n\n\n### AIGC\nAcceleration of AIGC (AI-Generated Content) models such as [Stable Diffusion v1](https://github.com/CompVis/stable-diffusion) and [Stable Diffusion v2](https://github.com/Stability-AI/stablediffusion).\n<p id=\"diffusion_train\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/Stable%20Diffusion%20v2.png\" width=800/>\n</p>\n\n- [Training](https://github.com/hpcaitech/ColossalAI/tree/main/examples/images/diffusion): Reduce Stable Diffusion memory consumption by up to 5.6x and hardware cost by up to 46x (from A100 to RTX3060).\n\n<p id=\"diffusion_demo\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/DreamBooth.png\" width=800/>\n</p>\n\n- [DreamBooth Fine-tuning](https://github.com/hpcaitech/ColossalAI/tree/main/examples/images/dreambooth): Personalize your model using just 3-5 images of the desired subject.\n\n<p id=\"inference\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/Stable%20Diffusion%20Inference.jpg\" width=800/>\n</p>\n\n- [Inference](https://github.com/hpcaitech/ColossalAI/tree/main/examples/images/diffusion): Reduce inference GPU memory consumption by 2.5x.\n\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n\n### Biomedicine\nAcceleration of [AlphaFold Protein Structure](https://alphafold.ebi.ac.uk/)\n\n<p id=\"FastFold\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/FastFold.jpg\" width=800/>\n</p>\n\n- [FastFold](https://github.com/hpcaitech/FastFold): Accelerating training and inference on GPU Clusters, faster data processing, inference sequence containing more than 10000 residues.\n\n<p id=\"FastFold-Intel\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/data%20preprocessing%20with%20Intel.jpg\" width=600/>\n</p>\n\n- [FastFold with Intel](https://github.com/hpcaitech/FastFold): 3x inference acceleration and 39% cost reduce.\n\n<p id=\"xTrimoMultimer\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/xTrimoMultimer_Table.jpg\" width=800/>\n</p>\n\n- [xTrimoMultimer](https://github.com/biomap-research/xTrimoMultimer): accelerating structure prediction of protein monomers and multimer by 11x.\n\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n\n## Installation\n\nRequirements:\n- PyTorch >= 1.11 (PyTorch 2.x in progress)\n- Python >= 3.7\n- CUDA >= 11.0\n\nIf you encounter any problem about installation, you may want to raise an [issue](https://github.com/hpcaitech/ColossalAI/issues/new/choose) in this repository.\n\n### Install from PyPI\n\nYou can easily install Colossal-AI with the following command. **By default, we do not build PyTorch extensions during installation.**\n\n```bash\npip install colossalai\n```\n\n**Note: only Linux is supported for now.**\n\nHowever, if you want to build the PyTorch extensions during installation, you can set `CUDA_EXT=1`.\n\n```bash\nCUDA_EXT=1 pip install colossalai\n```\n\n**Otherwise, CUDA kernels will be built during runtime when you actually need it.**\n\nWe also keep release the nightly version to PyPI on a weekly basis. This allows you to access the unreleased features and bug fixes in the main branch.\nInstallation can be made via\n\n```bash\npip install colossalai-nightly\n```\n\n### Download From Source\n\n> The version of Colossal-AI will be in line with the main branch of the repository. Feel free to raise an issue if you encounter any problem. :)\n\n```shell\ngit clone https://github.com/hpcaitech/ColossalAI.git\ncd ColossalAI\n\n# install colossalai\npip install .\n```\n\nBy default, we do not compile CUDA/C++ kernels. ColossalAI will build them during runtime.\nIf you want to install and enable CUDA kernel fusion (compulsory installation when using fused optimizer):\n\n```shell\nCUDA_EXT=1 pip install .\n```\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n\n## Use Docker\n\n### Pull from DockerHub\n\nYou can directly pull the docker image from our [DockerHub page](https://hub.docker.com/r/hpcaitech/colossalai). The image is automatically uploaded upon release.\n\n\n### Build On Your Own\n\nRun the following command to build a docker image from Dockerfile provided.\n\n> Building Colossal-AI from scratch requires GPU support, you need to use Nvidia Docker Runtime as the default when doing `docker build`. More details can be found [here](https://stackoverflow.com/questions/59691207/docker-build-with-nvidia-runtime).\n> We recommend you install Colossal-AI from our [project page](https://www.colossalai.org) directly.\n\n\n```bash\ncd ColossalAI\ndocker build -t colossalai ./docker\n```\n\nRun the following command to start the docker container in interactive mode.\n\n```bash\ndocker run -ti --gpus all --rm --ipc=host colossalai bash\n```\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n\n## Community\n\nJoin the Colossal-AI community on [Forum](https://github.com/hpcaitech/ColossalAI/discussions),\n[Slack](https://join.slack.com/t/colossalaiworkspace/shared_invite/zt-z7b26eeb-CBp7jouvu~r0~lcFzX832w),\nand [WeChat(微信)](https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/WeChat.png \"qrcode\") to share your suggestions, feedback, and questions with our engineering team.\n\n## Contributing\nReferring to the successful attempts of [BLOOM](https://bigscience.huggingface.co/) and [Stable Diffusion](https://en.wikipedia.org/wiki/Stable_Diffusion), any and all developers and partners with computing powers, datasets, models are welcome to join and build the Colossal-AI community, making efforts towards the era of big AI models!\n\nYou may contact us or participate in the following ways:\n1. [Leaving a Star ⭐](https://github.com/hpcaitech/ColossalAI/stargazers) to show your like and support. Thanks!\n2. Posting an [issue](https://github.com/hpcaitech/ColossalAI/issues/new/choose), or submitting a PR on GitHub follow the guideline in [Contributing](https://github.com/hpcaitech/ColossalAI/blob/main/CONTRIBUTING.md)\n3. Send your official proposal to email contact@hpcaitech.com\n\nThanks so much to all of our amazing contributors!\n\n<a href=\"https://github.com/hpcaitech/ColossalAI/graphs/contributors\"><img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/contributor_avatar.png\" width=\"800px\"></a>\n\n*The order of contributor avatars is randomly shuffled.*\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n\n\n## CI/CD\n\nWe leverage the power of [GitHub Actions](https://github.com/features/actions) to automate our development, release and deployment workflows. Please check out this [documentation](.github/workflows/README.md) on how the automated workflows are operated.\n\n\n## Cite Us\n\nThis project is inspired by some related projects (some by our team and some by other organizations). We would like to credit these amazing projects as listed in the [Reference List](./docs/REFERENCE.md).\n\nTo cite this project, you can use the following BibTeX citation.\n\n```\n@article{bian2021colossal,\n  title={Colossal-AI: A Unified Deep Learning System For Large-Scale Parallel Training},\n  author={Bian, Zhengda and Liu, Hongxin and Wang, Boxiang and Huang, Haichen and Li, Yongbin and Wang, Chuanrui and Cui, Fan and You, Yang},\n  journal={arXiv preprint arXiv:2110.14883},\n  year={2021}\n}\n```\n\nColossal-AI has been accepted as official tutorials by top conference [SC](https://sc22.supercomputing.org/), [AAAI](https://aaai.org/Conferences/AAAI-23/), [PPoPP](https://ppopp23.sigplan.org/), [CVPR](https://cvpr2023.thecvf.com/), [ISC](https://www.isc-hpc.com/), etc.\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://www.colossalai.org",
    "keywords": "",
    "license": "Apache Software License 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "colossalai",
    "package_url": "https://pypi.org/project/colossalai/",
    "platform": null,
    "project_url": "https://pypi.org/project/colossalai/",
    "project_urls": {
      "Bug Tracker": "https://github.com/hpcaitech/ColossalAI/issues",
      "Documentation": "http://colossalai.readthedocs.io",
      "Examples": "https://github.com/hpcaitech/ColossalAI-Examples",
      "Forum": "https://github.com/hpcaitech/ColossalAI/discussions",
      "Github": "https://github.com/hpcaitech/ColossalAI",
      "Homepage": "https://www.colossalai.org"
    },
    "release_url": "https://pypi.org/project/colossalai/0.2.8/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "An integrated large-scale model training system with efficient parallelization techniques",
    "version": "0.2.8",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17486899,
  "releases": {
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9cc7427dd2ed3769c6beb05cefdc18f8fad634673ed1472d5409afbdb768c7c3",
          "md5": "857956648f1c06af603b100d6189859e",
          "sha256": "e98c4ccc6a0bf336db5f7ed24ab21615a65a76a61a075708927708ba9919c7cf"
        },
        "downloads": -1,
        "filename": "colossalai-0.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "857956648f1c06af603b100d6189859e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 697776,
        "upload_time": "2023-01-09T03:07:09",
        "upload_time_iso_8601": "2023-01-09T03:07:09.787466Z",
        "url": "https://files.pythonhosted.org/packages/9c/c7/427dd2ed3769c6beb05cefdc18f8fad634673ed1472d5409afbdb768c7c3/colossalai-0.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b170cc6165ba3ce239c4b0c53c8ea6cabbfb31aa4b66dc580e85ff16d787384d",
          "md5": "6c62cbcb7757102327f012c11cc0784a",
          "sha256": "29566d96454f40237f830e133368a20ed1f01d8d2140b99028be534e668b713d"
        },
        "downloads": -1,
        "filename": "colossalai-0.2.1.tar.gz",
        "has_sig": false,
        "md5_digest": "6c62cbcb7757102327f012c11cc0784a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 709420,
        "upload_time": "2023-02-06T13:04:31",
        "upload_time_iso_8601": "2023-02-06T13:04:31.442402Z",
        "url": "https://files.pythonhosted.org/packages/b1/70/cc6165ba3ce239c4b0c53c8ea6cabbfb31aa4b66dc580e85ff16d787384d/colossalai-0.2.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "87d0d82b49b722315654f6773eb458b929dba9949044a6b7cd087027c2391169",
          "md5": "1690ca074b39d243887816c860411d40",
          "sha256": "b0a575fc7587c1bfbe79d3ae51b098a8f5213b89af4045d958a1668e23b5279c"
        },
        "downloads": -1,
        "filename": "colossalai-0.2.2.tar.gz",
        "has_sig": false,
        "md5_digest": "1690ca074b39d243887816c860411d40",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 705446,
        "upload_time": "2023-02-10T03:02:25",
        "upload_time_iso_8601": "2023-02-10T03:02:25.742703Z",
        "url": "https://files.pythonhosted.org/packages/87/d0/d82b49b722315654f6773eb458b929dba9949044a6b7cd087027c2391169/colossalai-0.2.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c9bb9ec93ed622207b589fe4b1eddad9da74174eedc40ac306bff77ba823db92",
          "md5": "548b282ce67488ac55e1ce35880635b9",
          "sha256": "015b58ca57b82137eff709432ea34d0d803442ada3fb2eb7d02c521810d4793e"
        },
        "downloads": -1,
        "filename": "colossalai-0.2.3.tar.gz",
        "has_sig": false,
        "md5_digest": "548b282ce67488ac55e1ce35880635b9",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 705705,
        "upload_time": "2023-02-13T01:52:24",
        "upload_time_iso_8601": "2023-02-13T01:52:24.968850Z",
        "url": "https://files.pythonhosted.org/packages/c9/bb/9ec93ed622207b589fe4b1eddad9da74174eedc40ac306bff77ba823db92/colossalai-0.2.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2c264c38cbad383dfae44b9ececdea8f71d1be32c0ce80aadf883f915dd4d2fb",
          "md5": "74171d6465960f231debc0b732865bb3",
          "sha256": "50498309d60727c56abb2677111899da183e7b4730c45a7b7a8808724ef4ef41"
        },
        "downloads": -1,
        "filename": "colossalai-0.2.4.tar.gz",
        "has_sig": false,
        "md5_digest": "74171d6465960f231debc0b732865bb3",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 705992,
        "upload_time": "2023-02-14T11:38:08",
        "upload_time_iso_8601": "2023-02-14T11:38:08.453025Z",
        "url": "https://files.pythonhosted.org/packages/2c/26/4c38cbad383dfae44b9ececdea8f71d1be32c0ce80aadf883f915dd4d2fb/colossalai-0.2.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "150538488d4a76c1c010da8d07e07ba14b15191d0e7398057a683f34e3c54dfe",
          "md5": "ddb7d9d6a7e64d50493c546e4e0f1e21",
          "sha256": "a78da2622cd78b49561e5b8b177a1ae06f1bf4a01f142551a364e7ead47aba14"
        },
        "downloads": -1,
        "filename": "colossalai-0.2.5.tar.gz",
        "has_sig": false,
        "md5_digest": "ddb7d9d6a7e64d50493c546e4e0f1e21",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 674417,
        "upload_time": "2023-02-15T08:49:04",
        "upload_time_iso_8601": "2023-02-15T08:49:04.921113Z",
        "url": "https://files.pythonhosted.org/packages/15/05/38488d4a76c1c010da8d07e07ba14b15191d0e7398057a683f34e3c54dfe/colossalai-0.2.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5aa3edf03a61814ca761d3133fae4bad80473c0f04693ef4af083787e71b6ac9",
          "md5": "1222ebd463d850df4d441cf89b151851",
          "sha256": "7ad0713b45541bc82ddfcbd37d503bed4cc44460834dc27e97a21bc21936d1d3"
        },
        "downloads": -1,
        "filename": "colossalai-0.2.6.tar.gz",
        "has_sig": false,
        "md5_digest": "1222ebd463d850df4d441cf89b151851",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 681984,
        "upload_time": "2023-03-10T01:48:18",
        "upload_time_iso_8601": "2023-03-10T01:48:18.263818Z",
        "url": "https://files.pythonhosted.org/packages/5a/a3/edf03a61814ca761d3133fae4bad80473c0f04693ef4af083787e71b6ac9/colossalai-0.2.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "257c99446b8f26ba3a8706553868aa230dd9e9e153f024961967c6d916ddc943",
          "md5": "626df89b0cb929a834f77db20f4f424e",
          "sha256": "e961a2b1a52f178ae2d1c94b4c7022fd84ab03a4d13d244fdf1635d0035979ae"
        },
        "downloads": -1,
        "filename": "colossalai-0.2.7.tar.gz",
        "has_sig": false,
        "md5_digest": "626df89b0cb929a834f77db20f4f424e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 686745,
        "upload_time": "2023-03-10T06:55:41",
        "upload_time_iso_8601": "2023-03-10T06:55:41.151723Z",
        "url": "https://files.pythonhosted.org/packages/25/7c/99446b8f26ba3a8706553868aa230dd9e9e153f024961967c6d916ddc943/colossalai-0.2.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8a35c33a150a97c33973318108778a559a9d550f4dc89757d40f23f3260e5af8",
          "md5": "3a5b429b543b81ccc0b95b80ea9c61fb",
          "sha256": "e1a2f45ceb293747ea75becb5512c683e576560ebbc518d362cf8e62cd77742d"
        },
        "downloads": -1,
        "filename": "colossalai-0.2.8.tar.gz",
        "has_sig": false,
        "md5_digest": "3a5b429b543b81ccc0b95b80ea9c61fb",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 728125,
        "upload_time": "2023-03-29T02:17:01",
        "upload_time_iso_8601": "2023-03-29T02:17:01.628760Z",
        "url": "https://files.pythonhosted.org/packages/8a/35/c33a150a97c33973318108778a559a9d550f4dc89757d40f23f3260e5af8/colossalai-0.2.8.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "8a35c33a150a97c33973318108778a559a9d550f4dc89757d40f23f3260e5af8",
        "md5": "3a5b429b543b81ccc0b95b80ea9c61fb",
        "sha256": "e1a2f45ceb293747ea75becb5512c683e576560ebbc518d362cf8e62cd77742d"
      },
      "downloads": -1,
      "filename": "colossalai-0.2.8.tar.gz",
      "has_sig": false,
      "md5_digest": "3a5b429b543b81ccc0b95b80ea9c61fb",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 728125,
      "upload_time": "2023-03-29T02:17:01",
      "upload_time_iso_8601": "2023-03-29T02:17:01.628760Z",
      "url": "https://files.pythonhosted.org/packages/8a/35/c33a150a97c33973318108778a559a9d550f4dc89757d40f23f3260e5af8/colossalai-0.2.8.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}