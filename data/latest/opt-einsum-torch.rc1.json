{
  "info": {
    "author": "Haoyan Huo",
    "author_email": "hhaoyann@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 1 - Planning",
      "Environment :: GPU",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3 :: Only",
      "Programming Language :: Python :: 3.6",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "# opt-einsum-torch\n\nThere have been many implementations of Einstein's summation. numpy's \n`numpy.einsum` is the least efficient one as it only runs in single thread on \nCPU. PyTorch's `torch.einsum` works for both CPU and CUDA tensors. However,\nsince there is no virtual CUDA memory, `torch.einsum` will run out of CUDA \nmemory for large tensors. \n\nThis code aims at implementing a memory-efficient `einsum` function using\nPyTorch as the backend. This code also uses the `opt_einsum` package to \noptimizes the contraction path to achieve the minimal FLOPS.\n\n### Usage\n\n```python\nfrom opt_einsum_torch import EinsumPlanner\nimport torch\n\n# Some huge tensors\narr1, arr2 = ..., ...\nee = EinsumPlanner(torch.device('cuda:0'), cuda_mem_limit=0.9)\nresult = ee.einsum('ijk,jkl->il', arr1, arr2)\n\n```\n\nThe resulting tensor `result` will be a PyTorch CPU tensor. You could convert\nit into numpy array by simply calling `result.numpy()`.\n\n### Future works\n\n- Support multiple GPUs.\n- Memory efficient einsum kernels.\n- CUDA data transfer profilers.\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "http://github.com/hhaoyan/opt-einsum-torch",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "opt-einsum-torch",
    "package_url": "https://pypi.org/project/opt-einsum-torch/",
    "platform": "",
    "project_url": "https://pypi.org/project/opt-einsum-torch/",
    "project_urls": {
      "Homepage": "http://github.com/hhaoyan/opt-einsum-torch"
    },
    "release_url": "https://pypi.org/project/opt-einsum-torch/0.1.0/",
    "requires_dist": [
      "humanize",
      "numpy",
      "opt-einsum",
      "torch"
    ],
    "requires_python": ">=3.6",
    "summary": "Memory-efficient optimum einsum using opt_einsum planning and PyTorch kernels.",
    "version": "0.1.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12439023,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5cd7bf9a3d615cf0ed11b24eec4ce6f31bc4f1717c07818174c3eaaf951b272c",
          "md5": "14dd91e2232b246e1df9764e67c631fb",
          "sha256": "1f784f9f9b4df402ea08a0e2037787b9c44809bd5bd3b9f366d3ae78f553990f"
        },
        "downloads": -1,
        "filename": "opt_einsum_torch-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "14dd91e2232b246e1df9764e67c631fb",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 10229,
        "upload_time": "2021-12-30T08:59:37",
        "upload_time_iso_8601": "2021-12-30T08:59:37.987223Z",
        "url": "https://files.pythonhosted.org/packages/5c/d7/bf9a3d615cf0ed11b24eec4ce6f31bc4f1717c07818174c3eaaf951b272c/opt_einsum_torch-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "dbaef092ce0cb43ad33099a1a5ecce1acb3b7a8d480ccf7af9c618da691696a6",
          "md5": "df61d1dddb9b3960c571e9131b73a910",
          "sha256": "feeae21ea0ff6427c3095c3361e9444b0df70ebaaf0c985e47cf728fe4129c45"
        },
        "downloads": -1,
        "filename": "opt-einsum-torch-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "df61d1dddb9b3960c571e9131b73a910",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 9973,
        "upload_time": "2021-12-30T08:59:40",
        "upload_time_iso_8601": "2021-12-30T08:59:40.178989Z",
        "url": "https://files.pythonhosted.org/packages/db/ae/f092ce0cb43ad33099a1a5ecce1acb3b7a8d480ccf7af9c618da691696a6/opt-einsum-torch-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "5cd7bf9a3d615cf0ed11b24eec4ce6f31bc4f1717c07818174c3eaaf951b272c",
        "md5": "14dd91e2232b246e1df9764e67c631fb",
        "sha256": "1f784f9f9b4df402ea08a0e2037787b9c44809bd5bd3b9f366d3ae78f553990f"
      },
      "downloads": -1,
      "filename": "opt_einsum_torch-0.1.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "14dd91e2232b246e1df9764e67c631fb",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 10229,
      "upload_time": "2021-12-30T08:59:37",
      "upload_time_iso_8601": "2021-12-30T08:59:37.987223Z",
      "url": "https://files.pythonhosted.org/packages/5c/d7/bf9a3d615cf0ed11b24eec4ce6f31bc4f1717c07818174c3eaaf951b272c/opt_einsum_torch-0.1.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "dbaef092ce0cb43ad33099a1a5ecce1acb3b7a8d480ccf7af9c618da691696a6",
        "md5": "df61d1dddb9b3960c571e9131b73a910",
        "sha256": "feeae21ea0ff6427c3095c3361e9444b0df70ebaaf0c985e47cf728fe4129c45"
      },
      "downloads": -1,
      "filename": "opt-einsum-torch-0.1.0.tar.gz",
      "has_sig": false,
      "md5_digest": "df61d1dddb9b3960c571e9131b73a910",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 9973,
      "upload_time": "2021-12-30T08:59:40",
      "upload_time_iso_8601": "2021-12-30T08:59:40.178989Z",
      "url": "https://files.pythonhosted.org/packages/db/ae/f092ce0cb43ad33099a1a5ecce1acb3b7a8d480ccf7af9c618da691696a6/opt-einsum-torch-0.1.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}