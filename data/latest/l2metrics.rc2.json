{
  "info": {
    "author": "Eric Nguyen, Megan Baker",
    "author_email": "Eric.Nguyen@jhuapl.edu, Megan.Baker@jhuapl.edu",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Topic :: Scientific/Engineering :: Artificial Intelligence"
    ],
    "description": "# Lifelong Learning Metrics (L2Metrics)\n\n![APL Logo](https://github.com/lifelong-learning-systems/l2metrics/raw/main/docs/apl_small_horizontal_blue.png)\n\n## Table of Contents\n\n- [Introduction](#introduction)\n- [Metrics](#metrics)\n- [Data Preprocessing](#data-preprocessing)\n- [Requirements](#requirements)\n  - [Installation](#installation)\n- [Usage](#usage)\n  - [Command-Line Execution](#command-line-execution)\n  - [Storing Single-Task Expert Data](#storing-single-task-expert-data)\n  - [Clearing Single-Task Expert Data](#clearing-single-task-expert-data)\n  - [Generating a Metrics Report](#generating-metrics-report)\n  - [Custom Metrics](#custom-metrics)\n- [Changelog](#changelog)\n- [License](#license)\n- [Acknowledgements](#acknowledgements)\n\n## Introduction\n\nLifelong Learning Metrics (L2Metrics) is a Python library containing foundational code for the L2M Metrics Framework. This framework includes the following:\n\n- Python libraries for processing performance logs generated by lifelong learning algorithms\n- Support for extending the framework with custom metrics\n\n## Metrics\n\nThe L2Metrics library supports the following lifelong learning metrics as defined in the [Lifelong Learning Metrics for L2M specification](https://arxiv.org/abs/2201.08278):\n\n- Performance Recovery (PR)\n- Mean Evaluation Performance (MEP)\n- Mean Training Performance (MTP)\n- Performance Maintenance (PM)\n- Forward Transfer (FT)\n- Backward Transfer (BT)\n- Performance Relative to a Single-Task Expert (RP)\n- Sample Efficiency (SE)\n\n## Data Preprocessing\n\nRefer to the [Data Processing README](https://github.com/lifelong-learning-systems/l2metrics/blob/main/docs/data_preprocessing.md) for details on the data preprocessing methods in this library.\n\n## Requirements\n\nL2Metrics is written in Python 3 and it is highly recommended to use at least version Python 3.6. The Metrics Framework has been tested on Windows 10 and Ubuntu 18.04/20.04. It should work on other platforms but has not been verified.\n\n### Installation\n\n#### 1. (Optional) Create a Python virtual environment\n\n```bash\npython -m venv <path_to_new_venv>\n```\n\nActivate the virtual environment as follows:\n\nLinux:\n\n```bash\nsource <path_to_new_venv>/bin/activate\n```\n\nWindows:\n\n```powershell\n<path_to_new_venv>/Scripts/Activate.ps1\n```\n\n#### 2. Update pip and wheel in your environment\n\n```bash\npip install -U pip wheel\n```\n\n#### 3. Clone the L2Logger and L2Metrics repositories\n\n```bash\ngit clone https://github.com/lifelong-learning-systems/l2logger.git\ngit clone https://github.com/lifelong-learning-systems/l2metrics.git\n```\n\n#### 4. Install the L2Logger and L2Metrics packages\n\n```bash\npip install -e <path_to_l2logger>\npip install -e <path_to_l2metrics>\n```\n\n## Usage\n\nTo calculate metrics on the performance of your system, you must first generate log files in accordance with the L2Logger format version 1.1. Please refer to the [L2Logger documentation](https://github.com/lifelong-learning-systems/l2logger/blob/release/docs/interface.md) for more details on how to generate compatible logs.\n\nOnce these logs are generated, you'll need to store Single-Task Expert (STE) data and pass the log directories as command-line arguments in order to compute STE-related metrics. Several example files are included to get you started:\n\n- Example STE and LL log directories:\n  - `./examples/ste_logs/ste_task1_1_run1/`\n  - `./examples/ste_logs/ste_task2_1_run1/`\n  - `./examples/ste_logs/ste_task3_1_run1/`\n  - `./examples/ste_logs/ste_task3_1_run2/`\n  - `./examples/ll_logs/multi_task/`\n- Example `settings.json` file for configuring command-line arguments\n- Example `data_range.json` file to show how the user can specify task normalization ranges\n\n### Command-Line Execution\n\nRefer to the [Command-Line README](https://github.com/lifelong-learning-systems/l2metrics/blob/main/docs/command_line.md) for more information on how to run L2Metrics from the command line.\n\n### Storing Single-Task Expert Data\n\nThe following commands are examples of how to store STE data from the provided logs, run from the root L2Metrics directory:\n\n```bash\npython -m l2metrics -l examples/ste_task1_1_run1 -s w\npython -m l2metrics -l examples/ste_task2_1_run1 -s w\npython -m l2metrics -l examples/ste_task3_1_run1 -s w\npython -m l2metrics -l examples/ste_task3_1_run2 -s a\n```\n\nThe specified log data will be stored in the `$L2DATA` directory under the `taskinfo` subdirectory, where all single-task expert data is pickled and saved. The STE store mode specified in the first three example commands is `w`, which is \"write\" or \"overwrite.\" This mode will create a new pickle file for the STE if one does not already exist; if there is already a file for the same task in the `taskinfo` location, it will be overwritten in this mode. The last example command used the append mode, `a`, which allows users to store multiple runs of STE data in the same pickle file. Then, the STE averaging method can be selected in the `l2metrics` module to modify how multiple STE runs are handled. Storing STE data assumes the provided log only contains data for a single task/variant.\n\nReplace the log directory argument with logs for other STE tasks and repeat until all STE data is stored.\n\n### Clearing Single-Task Expert Data\n\nIf the user would like to clear the `taskinfo` subdirectory of all previously-stored STE data,\nrun the following command:\n\n```bash\npython -m l2metrics.clear_ste\n```\n\n### Generating Metrics Report\n\nTo generate a metrics plot and report with default settings, run the following command from the `l2metrics/examples` directory:\n\n```bash\npython -m l2metrics -l ./ll_logs/multi_task -p performance\n```\n\nThe default output files are saved in the current working directory under `results/` and defined below:\n\n- `multi_task_data.feather`: The log data DataFrame containing raw and preprocessed data.\n- `multi_task_metrics.json`: The lifetime and task-level metrics of the run.\n- `multi_task_settings.json`: The settings used to generate the metrics report.\n- `multi_task_regime.tsv`: The regime-level metrics of the run.\n- `plots/multi_task_evaluation.png`: Evaluation block [point plots](https://seaborn.pydata.org/generated/seaborn.pointplot.html) grouped by task labels (i.e., task variants appear on the same subplot).\n- `plots/multi_task_learning.png`: Plot showing smoothed, normalized learning curves for the lifetime.\n- `plots/multi_task_raw.png`: Plot showing raw training reward values with smoothed curve overlaid.\n- `plots/multi_task_ste.png`: Plot showing concatenated learning curves compared to stored STE runs.\n\nIf you wish to generate a metrics report with modified settings (e.g., disabling normalization or aggregating lifetime metrics with the mean operator), you can either modify the arguments on the command line or specify a JSON file containing the desired settings. The settings loaded from the JSON file will take precedence over any arguments specified on the command line.\n\n```bash\npython -m l2metrics -c settings.json\n```\n\nLastly, if you wish to compute metrics on multiple lifetimes at once, assert the recursive flag on the command line. When the recursive flag is set, L2Metrics will scan the subdirectories for valid LL logs, calculate metrics, then save out a TSV and JSON file containing lifetime/task-level metrics for each discovered lifetime.\n\n```bash\npython -m l2metrics -l <path/to/directory/containing/multiple/runs> -R\n```\n\n**Note**: If you do not wish to provide a fully qualified path to your log directory, you may copy it to your `$L2DATA/logs` directory. This is the default location for logs generated using the TEF.\n\n### Log Data\n\nRefer to the [Log Data README](https://github.com/lifelong-learning-systems/l2metrics/blob/main/docs/log_data.md) for more information on how to interface with the raw and preprocessed log data from the scenario.\n\n### Output Settings File\n\nIf saving of L2Metrics settings is enabled, the framework will generate a JSON file containing the primary parameters used to calculate L2Metrics:\n\n```json\n{\n  \"log_dir\": \"ll_logs\\\\multi_task\",\n  \"perf_measure\": \"performance\",\n  \"variant_mode\": \"aware\",\n  \"ste_averaging_method\": \"metrics\",\n  \"aggregation_method\": \"mean\",\n  \"maintenance_method\": \"mrlep\",\n  \"transfer_method\": \"ratio\",\n  \"normalization_method\": \"task\",\n  \"smoothing_method\": \"flat\",\n  \"window_length\": null,\n  \"clamp_outliers\": false\n}\n```\n\n### Metrics and Metrics File\n\nThe metrics module will print the lifetime metrics to the console when it has successfully completed execution. The following table shows an example of a metrics report output:\n\n| perf_recovery | avg_train_perf | avg_eval_perf | perf_maintenance_mrlep | forward_transfer_ratio | backward_transfer_ratio | ste_rel_perf | sample_efficiency |\n| ------------- | -------------- | ------------- | ---------------------- | ---------------------- | ----------------------- | ------------ | ----------------- |\n| -2.00         | 83.82          | 78.52         | 3.86                   | 12.63                  | 1.08                    | 1.11         | 0.91              |\n\nIf saving is enabled, the framework will also generate a JSON file containing lifetime and task-level metrics for the scenario. Please refer to the [File Description README](https://github.com/darpa-l2m/l2metrics/blob/main/docs/file_descriptions.md#metrics-json-file) for more information on the format of this file.\n\n### Evaluation Plot\n\nThe resulting evaluation plot from example run should look like this:\n\n![Evaluation Plot](https://github.com/lifelong-learning-systems/l2metrics/raw/main/examples/results/plots/multi_task_evaluation.png)\n\nThis figure shows point plots for all tasks in the lifetime grouped by task label (i.e., task variants are shown on the same subplot). The points are the mean values in the evaluation blocks and the lines extending from each point show the 95% confidence intervals. The x-axis represents the block number in the lifetime.\n\n### Performance Plot\n\nThe resulting learning plot from example run should look like this:\n\n![Performance Plot](https://github.com/lifelong-learning-systems/l2metrics/raw/main/examples/results/plots/multi_task_learning.png)\n\nThis figure shows the pre-processed (smoothed, normalized, clamped, etc.) learning curves across the lifetime. The dashed lines in the plot show the slopes between each task's evaluation blocks.\n\n### Raw Performance Plot\n\nThe resulting raw performance plot from example run should look like this:\n\n![Raw Performance Plot](https://github.com/lifelong-learning-systems/l2metrics/raw/main/examples/results/plots/multi_task_raw.png)\n\nThis figure shows the raw reward values from learning blocks with the smoothed curves overlaid in black. The values in this figure are not normalized, even if that option is enabled.\n\n### Performance Relative to STE Plot\n\nThe framework should also produce a performance relative to STE plot shown below, where the task performance curves are generated by concatenating all the training data from the scenario:\n\n![STE Plot](https://github.com/lifelong-learning-systems/l2metrics/raw/main/examples/results/plots/multi_task_ste.png)\n\nThe vertical black dashed lines indicate the block boundaries where task performance was stitched together.\n\n### Custom Metrics\n\nSee documentation in the examples folder at [examples/README.md](https://github.com/lifelong-learning-systems/l2metrics/blob/main/examples/README.md) for more details on how to implement custom metrics.\n\n## Changelog\n\nSee [CHANGELOG.md](https://github.com/lifelong-learning-systems/l2metrics/blob/main/CHANGELOG.md) for a list of notable changes to the project.\n\n## License\n\nSee [LICENSE](https://github.com/lifelong-learning-systems/l2metrics/blob/main/LICENSE) for license information.\n\n## Acknowledgements\n\nPrimary development of Lifelong Learning Metrics (L2Metrics) was funded by the DARPA Lifelong Learning Machines (L2M) Program.\n\nÂ© 2021-2022 The Johns Hopkins University Applied Physics Laboratory LLC",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "https://github.com/lifelong-learning-systems/l2metrics/archive/v3.1.0.tar.gz",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/lifelong-learning-systems/l2metrics",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "l2metrics",
    "package_url": "https://pypi.org/project/l2metrics/",
    "platform": null,
    "project_url": "https://pypi.org/project/l2metrics/",
    "project_urls": {
      "Download": "https://github.com/lifelong-learning-systems/l2metrics/archive/v3.1.0.tar.gz",
      "Homepage": "https://github.com/lifelong-learning-systems/l2metrics"
    },
    "release_url": "https://pypi.org/project/l2metrics/3.1.0/",
    "requires_dist": null,
    "requires_python": ">=3.7",
    "summary": "Metrics for Lifelong Learning",
    "version": "3.1.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 13552245,
  "releases": {
    "3.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "747a26de87953082b9948301f0a51045a26b582a5291a39e02c8c769fcfae2cb",
          "md5": "d8ae9b085f8005f26d66f8cdd23138fc",
          "sha256": "a718e42d73120913dcaa2ed5824d9457252e07779fdc79bb88474ff123e0e5f6"
        },
        "downloads": -1,
        "filename": "l2metrics-3.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "d8ae9b085f8005f26d66f8cdd23138fc",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 37907,
        "upload_time": "2022-01-28T17:57:33",
        "upload_time_iso_8601": "2022-01-28T17:57:33.862342Z",
        "url": "https://files.pythonhosted.org/packages/74/7a/26de87953082b9948301f0a51045a26b582a5291a39e02c8c769fcfae2cb/l2metrics-3.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "3.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "03166c3a917a8028254ff58fddd99a78b45cee3c7f490a10b66ee249fe95b3e8",
          "md5": "89c69925db0ec0da744442071008d3de",
          "sha256": "829bd636bdcb0301c16afb2531724514cac25fc70589771cda034aa5882bea4b"
        },
        "downloads": -1,
        "filename": "l2metrics-3.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "89c69925db0ec0da744442071008d3de",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 51597,
        "upload_time": "2022-04-19T04:48:57",
        "upload_time_iso_8601": "2022-04-19T04:48:57.576175Z",
        "url": "https://files.pythonhosted.org/packages/03/16/6c3a917a8028254ff58fddd99a78b45cee3c7f490a10b66ee249fe95b3e8/l2metrics-3.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "03166c3a917a8028254ff58fddd99a78b45cee3c7f490a10b66ee249fe95b3e8",
        "md5": "89c69925db0ec0da744442071008d3de",
        "sha256": "829bd636bdcb0301c16afb2531724514cac25fc70589771cda034aa5882bea4b"
      },
      "downloads": -1,
      "filename": "l2metrics-3.1.0.tar.gz",
      "has_sig": false,
      "md5_digest": "89c69925db0ec0da744442071008d3de",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 51597,
      "upload_time": "2022-04-19T04:48:57",
      "upload_time_iso_8601": "2022-04-19T04:48:57.576175Z",
      "url": "https://files.pythonhosted.org/packages/03/16/6c3a917a8028254ff58fddd99a78b45cee3c7f490a10b66ee249fe95b3e8/l2metrics-3.1.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}