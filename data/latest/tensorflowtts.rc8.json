{
  "info": {
    "author": "Minh Nguyen Quan Anh, Alejandro Miguel Velasquez, Dawid Kobus, Eren GÃ¶lge, Kuan Chen, Takuya Ebata, Trinh Le Quang, Yunchao He",
    "author_email": "nguyenquananhminh@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: POSIX :: Linux",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "<h2 align=\"center\">\n<p> :yum: TensorFlowTTS\n<p align=\"center\">\n    <a href=\"https://github.com/tensorspeech/TensorFlowTTS/actions\">\n        <img alt=\"Build\" src=\"https://github.com/tensorspeech/TensorFlowTTS/workflows/CI/badge.svg?branch=master\">\n    </a>\n    <a href=\"https://github.com/tensorspeech/TensorFlowTTS/blob/master/LICENSE\">\n        <img alt=\"GitHub\" src=\"https://img.shields.io/github/license/tensorspeech/TensorflowTTS?color=red\">\n    </a>\n    <a href=\"https://colab.research.google.com/drive/1akxtrLZHKuMiQup00tzO2olCaN-y3KiD?usp=sharing\">\n        <img alt=\"Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\">\n    </a>\n</p>\n</h2>\n<h2 align=\"center\">\n<p>Real-Time State-of-the-art Speech Synthesis for Tensorflow 2\n</h2>\n\n:zany_face: TensorFlowTTS provides real-time state-of-the-art speech synthesis architectures such as Tacotron-2, Melgan, Multiband-Melgan, FastSpeech, FastSpeech2 based-on TensorFlow 2. With Tensorflow 2, we can speed-up training/inference progress, optimizer further by using [fake-quantize aware](https://www.tensorflow.org/model_optimization/guide/quantization/training_comprehensive_guide) and [pruning](https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras), make TTS models can be run faster than real-time and be able to deploy on mobile devices or embedded systems.\n\n## What's new\n- 2021/08/18 (**NEW!**) Integrated to [Huggingface Spaces](https://huggingface.co/spaces) with [Gradio](https://github.com/gradio-app/gradio). See [Gradio Web Demo](https://huggingface.co/spaces/akhaliq/TensorFlowTTS).\n- 2021/08/12 (**NEW!**) Support French TTS (Tacotron2, Multiband MelGAN). Pls see the [colab](https://colab.research.google.com/drive/1jd3u46g-fGQw0rre8fIwWM9heJvrV1c0?usp=sharing). Many Thanks [Samuel Delalez](https://github.com/samuel-lunii)\n- 2021/06/01 Integrated with [Huggingface Hub](https://huggingface.co/tensorspeech). See the [PR](https://github.com/TensorSpeech/TensorFlowTTS/pull/555). Thanks [patrickvonplaten](https://github.com/patrickvonplaten) and [osanseviero](https://github.com/osanseviero)\n- 2021/03/18  Support IOS for FastSpeech2 and MB MelGAN. Thanks [kewlbear](https://github.com/kewlbear). See [here](https://github.com/TensorSpeech/TensorFlowTTS/tree/master/examples/ios)\n- 2021/01/18 Support TFLite C++ inference. Thanks [luan78zaoha](https://github.com/luan78zaoha). See [here](https://github.com/TensorSpeech/TensorFlowTTS/tree/master/examples/cpptflite)\n- 2020/12/02 Support German TTS with [Thorsten dataset](https://github.com/thorstenMueller/deep-learning-german-tts). See the [Colab](https://colab.research.google.com/drive/1W0nSFpsz32M0OcIkY9uMOiGrLTPKVhTy?usp=sharing). Thanks [thorstenMueller](https://github.com/thorstenMueller) and [monatis](https://github.com/monatis)\n- 2020/11/24 Add HiFi-GAN vocoder. See [here](https://github.com/TensorSpeech/TensorFlowTTS/tree/master/examples/hifigan)\n- 2020/11/19 Add Multi-GPU gradient accumulator. See [here](https://github.com/TensorSpeech/TensorFlowTTS/pull/377)\n- 2020/08/23 Add Parallel WaveGAN tensorflow implementation. See [here](https://github.com/TensorSpeech/TensorFlowTTS/tree/master/examples/parallel_wavegan)\n- 2020/08/23 Add MBMelGAN G + ParallelWaveGAN G example. See [here](https://github.com/TensorSpeech/TensorFlowTTS/tree/master/examples/multiband_pwgan)\n- 2020/08/20 Add C++ inference code. Thank [@ZDisket](https://github.com/ZDisket). See [here](https://github.com/TensorSpeech/TensorFlowTTS/tree/master/examples/cppwin)\n- 2020/08/18 Update [new base processor](https://github.com/TensorSpeech/TensorFlowTTS/blob/master/tensorflow_tts/processor/base_processor.py). Add [AutoProcessor](https://github.com/TensorSpeech/TensorFlowTTS/blob/master/tensorflow_tts/inference/auto_processor.py) and [pretrained processor](https://github.com/TensorSpeech/TensorFlowTTS/blob/master/tensorflow_tts/processor/pretrained/) json file\n- 2020/08/14 Support Chinese TTS. Pls see the [colab](https://colab.research.google.com/drive/1YpSHRBRPBI7cnTkQn1UcVTWEQVbsUm1S?usp=sharing). Thank [@azraelkuan](https://github.com/azraelkuan)\n- 2020/08/05 Support Korean TTS. Pls see the [colab](https://colab.research.google.com/drive/1ybWwOS5tipgPFttNulp77P6DAB5MtiuN?usp=sharing). Thank [@crux153](https://github.com/crux153)\n- 2020/07/17 Support MultiGPU for all Trainer\n- 2020/07/05 Support Convert Tacotron-2, FastSpeech to Tflite. Pls see the [colab](https://colab.research.google.com/drive/1HudLLpT9CQdh2k04c06bHUwLubhGTWxA?usp=sharing). Thank @jaeyoo from the TFlite team for his support\n- 2020/06/20 [FastSpeech2](https://arxiv.org/abs/2006.04558) implementation with Tensorflow is supported.\n- 2020/06/07 [Multi-band MelGAN (MB MelGAN)](https://github.com/tensorspeech/TensorFlowTTS/blob/master/examples/multiband_melgan/) implementation with Tensorflow is supported\n\n\n## Features\n- High performance on Speech Synthesis.\n- Be able to fine-tune on other languages.\n- Fast, Scalable, and Reliable.\n- Suitable for deployment.\n- Easy to implement a new model, based-on abstract class.\n- Mixed precision to speed-up training if possible.\n- Support Single/Multi GPU gradient Accumulate.\n- Support both Single/Multi GPU in base trainer class.\n- TFlite conversion for all supported models.\n- Android example.\n- Support many languages (currently, we support Chinese, Korean, English, French and German)\n- Support C++ inference.\n- Support Convert weight for some models from PyTorch to TensorFlow to accelerate speed.\n\n## Requirements\nThis repository is tested on Ubuntu 18.04 with:\n\n- Python 3.7+\n- Cuda 10.1\n- CuDNN 7.6.5\n- Tensorflow 2.2/2.3/2.4/2.5/2.6\n- [Tensorflow Addons](https://github.com/tensorflow/addons) >= 0.10.0\n\nDifferent Tensorflow version should be working but not tested yet. This repo will try to work with the latest stable TensorFlow version. **We recommend you install TensorFlow 2.6.0 to training in case you want to use MultiGPU.**\n\n## Installation\n### With pip\n```bash\n$ pip install TensorFlowTTS\n```\n### From source\nExamples are included in the repository but are not shipped with the framework. Therefore, to run the latest version of examples, you need to install the source below.\n```bash\n$ git clone https://github.com/TensorSpeech/TensorFlowTTS.git\n$ cd TensorFlowTTS\n$ pip install .\n```\nIf you want to upgrade the repository and its dependencies:\n```bash\n$ git pull\n$ pip install --upgrade .\n```\n\n# Supported Model architectures\nTensorFlowTTS currently  provides the following architectures:\n\n1. **MelGAN** released with the paper [MelGAN: Generative Adversarial Networks for Conditional Waveform Synthesis](https://arxiv.org/abs/1910.06711) by Kundan Kumar, Rithesh Kumar, Thibault de Boissiere, Lucas Gestin, Wei Zhen Teoh, Jose Sotelo, Alexandre de Brebisson, Yoshua Bengio, Aaron Courville.\n2. **Tacotron-2** released with the paper [Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions](https://arxiv.org/abs/1712.05884) by Jonathan Shen, Ruoming Pang, Ron J. Weiss, Mike Schuster, Navdeep Jaitly, Zongheng Yang, Zhifeng Chen, Yu Zhang, Yuxuan Wang, RJ Skerry-Ryan, Rif A. Saurous, Yannis Agiomyrgiannakis, Yonghui Wu.\n3. **FastSpeech** released with the paper [FastSpeech: Fast, Robust, and Controllable Text to Speech](https://arxiv.org/abs/1905.09263) by Yi Ren, Yangjun Ruan, Xu Tan, Tao Qin, Sheng Zhao, Zhou Zhao, Tie-Yan Liu.\n4. **Multi-band MelGAN** released with the paper [Multi-band MelGAN: Faster Waveform Generation for High-Quality Text-to-Speech](https://arxiv.org/abs/2005.05106) by Geng Yang, Shan Yang, Kai Liu, Peng Fang, Wei Chen, Lei Xie.\n5. **FastSpeech2** released with the paper [FastSpeech 2: Fast and High-Quality End-to-End Text to Speech](https://arxiv.org/abs/2006.04558) by Yi Ren, Chenxu Hu, Xu Tan, Tao Qin, Sheng Zhao, Zhou Zhao, Tie-Yan Liu.\n6. **Parallel WaveGAN** released with the paper [Parallel WaveGAN: A fast waveform generation model based on generative adversarial networks with multi-resolution spectrogram](https://arxiv.org/abs/1910.11480) by Ryuichi Yamamoto, Eunwoo Song, Jae-Min Kim.\n7. **HiFi-GAN** released with the paper [HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis](https://arxiv.org/abs/2010.05646) by Jungil Kong, Jaehyeon Kim, Jaekyoung Bae.\n\nWe are also implementing some techniques to improve quality and convergence speed from the following papers:\n\n2. **Guided Attention Loss** released with the paper [Efficiently Trainable Text-to-Speech System Based on Deep Convolutional Networks with Guided Attention\n](https://arxiv.org/abs/1710.08969) by Hideyuki Tachibana, Katsuya Uenoyama, Shunsuke Aihara.\n\n\n# Audio Samples\nHere in an audio samples on valid set. [tacotron-2](https://drive.google.com/open?id=1kaPXRdLg9gZrll9KtvH3-feOBMM8sn3_), [fastspeech](https://drive.google.com/open?id=1f69ujszFeGnIy7PMwc8AkUckhIaT2OD0), [melgan](https://drive.google.com/open?id=1mBwGVchwtNkgFsURl7g4nMiqx4gquAC2), [melgan.stft](https://drive.google.com/open?id=1xUkDjbciupEkM3N4obiJAYySTo6J9z6b), [fastspeech2](https://drive.google.com/drive/u/1/folders/1NG7oOfNuXSh7WyAoM1hI8P5BxDALY_mU), [multiband_melgan](https://drive.google.com/drive/folders/1DCV3sa6VTyoJzZmKATYvYVDUAFXlQ_Zp)\n\n# Tutorial End-to-End\n\n## Prepare Dataset\n\nPrepare a dataset in the following format:\n```\n|- [NAME_DATASET]/\n|   |- metadata.csv\n|   |- wavs/\n|       |- file1.wav\n|       |- ...\n```\n\nWhere `metadata.csv` has the following format: `id|transcription`. This is a ljspeech-like format; you can ignore preprocessing steps if you have other format datasets.\n\nNote that `NAME_DATASET` should be `[ljspeech/kss/baker/libritts/synpaflex]` for example.\n\n## Preprocessing\n\nThe preprocessing has two steps:\n\n1. Preprocess audio features\n    - Convert characters to IDs\n    - Compute mel spectrograms\n    - Normalize mel spectrograms to [-1, 1] range\n    - Split the dataset into train and validation\n    - Compute the mean and standard deviation of multiple features from the **training** split\n2. Standardize mel spectrogram based on computed statistics\n\nTo reproduce the steps above:\n```\ntensorflow-tts-preprocess --rootdir ./[ljspeech/kss/baker/libritts/thorsten/synpaflex] --outdir ./dump_[ljspeech/kss/baker/libritts/thorsten/synpaflex] --config preprocess/[ljspeech/kss/baker/thorsten/synpaflex]_preprocess.yaml --dataset [ljspeech/kss/baker/libritts/thorsten/synpaflex]\ntensorflow-tts-normalize --rootdir ./dump_[ljspeech/kss/baker/libritts/thorsten/synpaflex] --outdir ./dump_[ljspeech/kss/baker/libritts/thorsten/synpaflex] --config preprocess/[ljspeech/kss/baker/libritts/thorsten/synpaflex]_preprocess.yaml --dataset [ljspeech/kss/baker/libritts/thorsten/synpaflex]\n```\n\nRight now we only support [`ljspeech`](https://keithito.com/LJ-Speech-Dataset/), [`kss`](https://www.kaggle.com/bryanpark/korean-single-speaker-speech-dataset), [`baker`](https://weixinxcxdb.oss-cn-beijing.aliyuncs.com/gwYinPinKu/BZNSYP.rar), [`libritts`](http://www.openslr.org/60/), [`thorsten`](https://github.com/thorstenMueller/deep-learning-german-tts) and\n[`synpaflex`](https://www.ortolang.fr/market/corpora/synpaflex-corpus/) for dataset argument. In the future, we intend to support more datasets.\n\n**Note**: To run `libritts` preprocessing, please first read the instruction in [examples/fastspeech2_libritts](https://github.com/TensorSpeech/TensorFlowTTS/tree/master/examples/fastspeech2_libritts). We need to reformat it first before run preprocessing.\n\n**Note**: To run `synpaflex` preprocessing, please first run the notebook [notebooks/prepare_synpaflex.ipynb](https://github.com/TensorSpeech/TensorFlowTTS/tree/master/notebooks/prepare_synpaflex.ipynb). We need to reformat it first before run preprocessing.\n\nAfter preprocessing, the structure of the project folder should be:\n```\n|- [NAME_DATASET]/\n|   |- metadata.csv\n|   |- wav/\n|       |- file1.wav\n|       |- ...\n|- dump_[ljspeech/kss/baker/libritts/thorsten]/\n|   |- train/\n|       |- ids/\n|           |- LJ001-0001-ids.npy\n|           |- ...\n|       |- raw-feats/\n|           |- LJ001-0001-raw-feats.npy\n|           |- ...\n|       |- raw-f0/\n|           |- LJ001-0001-raw-f0.npy\n|           |- ...\n|       |- raw-energies/\n|           |- LJ001-0001-raw-energy.npy\n|           |- ...\n|       |- norm-feats/\n|           |- LJ001-0001-norm-feats.npy\n|           |- ...\n|       |- wavs/\n|           |- LJ001-0001-wave.npy\n|           |- ...\n|   |- valid/\n|       |- ids/\n|           |- LJ001-0009-ids.npy\n|           |- ...\n|       |- raw-feats/\n|           |- LJ001-0009-raw-feats.npy\n|           |- ...\n|       |- raw-f0/\n|           |- LJ001-0001-raw-f0.npy\n|           |- ...\n|       |- raw-energies/\n|           |- LJ001-0001-raw-energy.npy\n|           |- ...\n|       |- norm-feats/\n|           |- LJ001-0009-norm-feats.npy\n|           |- ...\n|       |- wavs/\n|           |- LJ001-0009-wave.npy\n|           |- ...\n|   |- stats.npy\n|   |- stats_f0.npy\n|   |- stats_energy.npy\n|   |- train_utt_ids.npy\n|   |- valid_utt_ids.npy\n|- examples/\n|   |- melgan/\n|   |- fastspeech/\n|   |- tacotron2/\n|   ...\n```\n\n- `stats.npy` contains the mean and std from the training split mel spectrograms\n- `stats_energy.npy` contains the mean and std of energy values from the training split\n- `stats_f0.npy` contains the mean and std of F0 values in the training split\n- `train_utt_ids.npy` / `valid_utt_ids.npy` contains training and validation utterances IDs respectively\n\nWe use suffix (`ids`, `raw-feats`, `raw-energy`, `raw-f0`, `norm-feats`, and `wave`) for each input type.\n\n\n**IMPORTANT NOTES**:\n- This preprocessing step is based on [ESPnet](https://github.com/espnet/espnet) so you can combine all models here with other models from ESPnet repository.\n- Regardless of how your dataset is formatted, the final structure of the `dump` folder **SHOULD** follow the above structure to be able to use the training script, or you can modify it by yourself ð.\n\n## Training models\n\nTo know how to train model from scratch or fine-tune with other datasets/languages, please see detail at example directory.\n\n- For Tacotron-2 tutorial, pls see [examples/tacotron2](https://github.com/tensorspeech/TensorFlowTTS/tree/master/examples/tacotron2)\n- For FastSpeech tutorial, pls see [examples/fastspeech](https://github.com/tensorspeech/TensorFlowTTS/tree/master/examples/fastspeech)\n- For FastSpeech2 tutorial, pls see [examples/fastspeech2](https://github.com/tensorspeech/TensorFlowTTS/tree/master/examples/fastspeech2)\n- For FastSpeech2 + MFA tutorial, pls see [examples/fastspeech2_libritts](https://github.com/tensorspeech/TensorFlowTTS/tree/master/examples/fastspeech2_libritts)\n- For MelGAN tutorial, pls see [examples/melgan](https://github.com/tensorspeech/TensorFlowTTS/tree/master/examples/melgan)\n- For MelGAN + STFT Loss tutorial, pls see [examples/melgan.stft](https://github.com/tensorspeech/TensorFlowTTS/tree/master/examples/melgan.stft)\n- For Multiband-MelGAN tutorial, pls see [examples/multiband_melgan](https://github.com/tensorspeech/TensorFlowTTS/tree/master/examples/multiband_melgan)\n- For Parallel WaveGAN tutorial, pls see [examples/parallel_wavegan](https://github.com/tensorspeech/TensorFlowTTS/tree/master/examples/parallel_wavegan)\n- For Multiband-MelGAN Generator + Parallel WaveGAN Discriminator tutorial, pls see [examples/multiband_pwgan](https://github.com/tensorspeech/TensorFlowTTS/tree/master/examples/multiband_pwgan)\n- For HiFi-GAN tutorial, pls see [examples/hifigan](https://github.com/tensorspeech/TensorFlowTTS/tree/master/examples/hifigan)\n# Abstract Class Explaination\n\n## Abstract DataLoader Tensorflow-based dataset\n\nA detail implementation of abstract dataset class from [tensorflow_tts/dataset/abstract_dataset](https://github.com/tensorspeech/TensorFlowTTS/blob/master/tensorflow_tts/datasets/abstract_dataset.py). There are some functions you need overide and understand:\n\n1. **get_args**: This function return argumentation for **generator** class, normally is utt_ids.\n2. **generator**: This function have an inputs from **get_args** function and return a inputs for models. **Note that we return a dictionary for all generator functions with the keys that exactly match with the model's parameters because base_trainer will use model(\\*\\*batch) to do forward step.**\n3. **get_output_dtypes**: This function need return dtypes for each element from **generator** function.\n4. **get_len_dataset**: Return len of datasets, normaly is len(utt_ids).\n\n**IMPORTANT NOTES**:\n\n- A pipeline of creating dataset should be: cache -> shuffle -> map_fn -> get_batch -> prefetch.\n- If you do shuffle before cache, the dataset won't shuffle when it re-iterate over datasets.\n- You should apply map_fn to make each element return from **generator** function have the same length before getting batch and feed it into a model.\n\nSome examples to use this **abstract_dataset** are [tacotron_dataset.py](https://github.com/tensorspeech/TensorFlowTTS/blob/master/examples/tacotron2/tacotron_dataset.py), [fastspeech_dataset.py](https://github.com/tensorspeech/TensorFlowTTS/blob/master/examples/fastspeech/fastspeech_dataset.py), [melgan_dataset.py](https://github.com/tensorspeech/TensorFlowTTS/blob/master/examples/melgan/audio_mel_dataset.py), [fastspeech2_dataset.py](https://github.com/TensorSpeech/TensorFlowTTS/blob/master/examples/fastspeech2/fastspeech2_dataset.py)\n\n\n## Abstract Trainer Class\n\nA detail implementation of base_trainer from [tensorflow_tts/trainer/base_trainer.py](https://github.com/tensorspeech/TensorFlowTTS/blob/master/tensorflow_tts/trainers/base_trainer.py). It include [Seq2SeqBasedTrainer](https://github.com/tensorspeech/TensorFlowTTS/blob/master/tensorflow_tts/trainers/base_trainer.py#L265) and [GanBasedTrainer](https://github.com/tensorspeech/TensorFlowTTS/blob/master/tensorflow_tts/trainers/base_trainer.py#L149) inherit from [BasedTrainer](https://github.com/tensorspeech/TensorFlowTTS/blob/master/tensorflow_tts/trainers/base_trainer.py#L16). All trainer support both single/multi GPU. There a some functions you **MUST** overide when implement new_trainer:\n\n- **compile**: This function aim to define a models, and losses.\n- **generate_and_save_intermediate_result**: This function will save intermediate result such as: plot alignment, save audio generated, plot mel-spectrogram ...\n- **compute_per_example_losses**: This function will compute per_example_loss for model, note that all element of the loss **MUST** has shape [batch_size].\n\nAll models on this repo are trained based-on **GanBasedTrainer** (see [train_melgan.py](https://github.com/tensorspeech/TensorFlowTTS/blob/master/examples/melgan/train_melgan.py), [train_melgan_stft.py](https://github.com/tensorspeech/TensorFlowTTS/blob/master/examples/melgan.stft/train_melgan_stft.py), [train_multiband_melgan.py](https://github.com/tensorspeech/TensorFlowTTS/blob/master/examples/multiband_melgan/train_multiband_melgan.py)) and **Seq2SeqBasedTrainer** (see [train_tacotron2.py](https://github.com/tensorspeech/TensorFlowTTS/blob/master/examples/tacotron2/train_tacotron2.py), [train_fastspeech.py](https://github.com/tensorspeech/TensorFlowTTS/blob/master/examples/fastspeech/train_fastspeech.py)).\n\n# End-to-End Examples\nYou can know how to inference each model at [notebooks](https://github.com/tensorspeech/TensorFlowTTS/tree/master/notebooks) or see a [colab](https://colab.research.google.com/drive/1akxtrLZHKuMiQup00tzO2olCaN-y3KiD?usp=sharing) (for English), [colab](https://colab.research.google.com/drive/1ybWwOS5tipgPFttNulp77P6DAB5MtiuN?usp=sharing) (for Korean), [colab](https://colab.research.google.com/drive/1YpSHRBRPBI7cnTkQn1UcVTWEQVbsUm1S?usp=sharing) (for Chinese), [colab](https://colab.research.google.com/drive/1jd3u46g-fGQw0rre8fIwWM9heJvrV1c0?usp=sharing) (for French), [colab](https://colab.research.google.com/drive/1W0nSFpsz32M0OcIkY9uMOiGrLTPKVhTy?usp=sharing) (for German). Here is an example code for end2end inference with fastspeech2 and multi-band melgan. We uploaded all our pretrained in [HuggingFace Hub](https://huggingface.co/tensorspeech).\n\n```python\nimport numpy as np\nimport soundfile as sf\nimport yaml\n\nimport tensorflow as tf\n\nfrom tensorflow_tts.inference import TFAutoModel\nfrom tensorflow_tts.inference import AutoProcessor\n\n# initialize fastspeech2 model.\nfastspeech2 = TFAutoModel.from_pretrained(\"tensorspeech/tts-fastspeech2-ljspeech-en\")\n\n\n# initialize mb_melgan model\nmb_melgan = TFAutoModel.from_pretrained(\"tensorspeech/tts-mb_melgan-ljspeech-en\")\n\n\n# inference\nprocessor = AutoProcessor.from_pretrained(\"tensorspeech/tts-fastspeech2-ljspeech-en\")\n\ninput_ids = processor.text_to_sequence(\"Recent research at Harvard has shown meditating for as little as 8 weeks, can actually increase the grey matter in the parts of the brain responsible for emotional regulation, and learning.\")\n# fastspeech inference\n\nmel_before, mel_after, duration_outputs, _, _ = fastspeech2.inference(\n    input_ids=tf.expand_dims(tf.convert_to_tensor(input_ids, dtype=tf.int32), 0),\n    speaker_ids=tf.convert_to_tensor([0], dtype=tf.int32),\n    speed_ratios=tf.convert_to_tensor([1.0], dtype=tf.float32),\n    f0_ratios =tf.convert_to_tensor([1.0], dtype=tf.float32),\n    energy_ratios =tf.convert_to_tensor([1.0], dtype=tf.float32),\n)\n\n# melgan inference\naudio_before = mb_melgan.inference(mel_before)[0, :, 0]\naudio_after = mb_melgan.inference(mel_after)[0, :, 0]\n\n# save to file\nsf.write('./audio_before.wav', audio_before, 22050, \"PCM_16\")\nsf.write('./audio_after.wav', audio_after, 22050, \"PCM_16\")\n```\n\n# Contact\n- [Minh Nguyen Quan Anh](https://github.com/tensorspeech): nguyenquananhminh@gmail.com\n- [erogol](https://github.com/erogol): erengolge@gmail.com\n- [Kuan Chen](https://github.com/azraelkuan): azraelkuan@gmail.com\n- [Dawid Kobus](https://github.com/machineko): machineko@protonmail.com\n- [Takuya Ebata](https://github.com/MokkeMeguru): meguru.mokke@gmail.com\n- [Trinh Le Quang](https://github.com/l4zyf9x): trinhle.cse@gmail.com\n- [Yunchao He](https://github.com/candlewill): yunchaohe@gmail.com\n- [Alejandro Miguel Velasquez](https://github.com/ZDisket): xml506ok@gmail.com\n\n# License\nOverall, Almost models here are licensed under the [Apache 2.0](http://www.apache.org/licenses/LICENSE-2.0) for all countries in the world, except in **Viet Nam** this framework cannot be used for production in any way without permission from TensorFlowTTS's Authors. There is an exception, Tacotron-2 can be used with any purpose. If you are Vietnamese and want to use this framework for production, you **Must** contact us in advance.\n\n# Acknowledgement\nWe want to thank [Tomoki Hayashi](https://github.com/kan-bayashi), who discussed with us much about Melgan, Multi-band melgan, Fastspeech, and Tacotron. This framework based-on his great open-source [ParallelWaveGan](https://github.com/kan-bayashi/ParallelWaveGAN) project.\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/tensorspeech/TensorFlowTTS",
    "keywords": "",
    "license": "Apache-2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "TensorFlowTTS",
    "package_url": "https://pypi.org/project/TensorFlowTTS/",
    "platform": "",
    "project_url": "https://pypi.org/project/TensorFlowTTS/",
    "project_urls": {
      "Homepage": "https://github.com/tensorspeech/TensorFlowTTS"
    },
    "release_url": "https://pypi.org/project/TensorFlowTTS/1.8/",
    "requires_dist": [
      "tensorflow-gpu (==2.6.0)",
      "tensorflow-addons (>=0.10.0)",
      "setuptools (>=38.5.1)",
      "huggingface-hub (==0.0.8)",
      "librosa (>=0.7.0)",
      "soundfile (>=0.10.2)",
      "matplotlib (>=3.1.0)",
      "PyYAML (>=3.12)",
      "tqdm (>=4.26.1)",
      "h5py (>=2.10.0)",
      "unidecode (>=1.1.1)",
      "inflect (>=4.1.0)",
      "scikit-learn (>=0.22.0)",
      "pyworld (>=0.2.10)",
      "numba (<=0.48)",
      "jamo (>=0.4.1)",
      "pypinyin",
      "g2pM",
      "textgrid",
      "click",
      "g2p-en",
      "dataclasses",
      "pytest (>=3.3.0) ; extra == 'test'",
      "hacking (>=1.1.0) ; extra == 'test'"
    ],
    "requires_python": "",
    "summary": "TensorFlowTTS: Real-Time State-of-the-art Speech Synthesis for TensorFlow 2",
    "version": "1.8",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 11239315,
  "releases": {
    "0.11": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d415e75d7c02c26858571388c9c937365a111df05cc2076f02676f613944792e",
          "md5": "5c0f5b693dd7cd64e8a26d5a937c73a8",
          "sha256": "ec49e1f85f73460b4d2fb966093e253f3a7f6e3013efd116aa936977d892b400"
        },
        "downloads": -1,
        "filename": "TensorFlowTTS-0.11-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "5c0f5b693dd7cd64e8a26d5a937c73a8",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 118681,
        "upload_time": "2020-11-25T06:20:45",
        "upload_time_iso_8601": "2020-11-25T06:20:45.636497Z",
        "url": "https://files.pythonhosted.org/packages/d4/15/e75d7c02c26858571388c9c937365a111df05cc2076f02676f613944792e/TensorFlowTTS-0.11-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e8fe67fcc24b7014f452d759baa90accbd0541a8c7d3501e10fed0c84fa4a948",
          "md5": "511009ec834a3a273d071cd0cc56ab2a",
          "sha256": "fb336081966b5f9afbb2a31ebc67c722022192a8e562be79e4e1d7178861eab3"
        },
        "downloads": -1,
        "filename": "TensorFlowTTS-0.11.tar.gz",
        "has_sig": false,
        "md5_digest": "511009ec834a3a273d071cd0cc56ab2a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 88544,
        "upload_time": "2020-11-25T06:20:47",
        "upload_time_iso_8601": "2020-11-25T06:20:47.977863Z",
        "url": "https://files.pythonhosted.org/packages/e8/fe/67fcc24b7014f452d759baa90accbd0541a8c7d3501e10fed0c84fa4a948/TensorFlowTTS-0.11.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "378d01fe3307332b50d46cde463d53c08aab42137b1f8e02a3ae01ece109685d",
          "md5": "988f137d88d2bf9e6540af29276a8951",
          "sha256": "9cda82051754a4a0ded9543c0532c106c9727115dce6c864774b7a847d063069"
        },
        "downloads": -1,
        "filename": "TensorflowTTS-0.7-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "988f137d88d2bf9e6540af29276a8951",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 81597,
        "upload_time": "2020-07-11T11:36:20",
        "upload_time_iso_8601": "2020-07-11T11:36:20.542297Z",
        "url": "https://files.pythonhosted.org/packages/37/8d/01fe3307332b50d46cde463d53c08aab42137b1f8e02a3ae01ece109685d/TensorflowTTS-0.7-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "657939ae50adeae504628938d9055422702efc2061804c865273c0823c1512c5",
          "md5": "4d37022fc10b10b0eb13f480970dc400",
          "sha256": "6506eacd88909f789b81af2310cb673f7560ba916dd3efdf05ad53a7f815b870"
        },
        "downloads": -1,
        "filename": "TensorflowTTS-0.7.tar.gz",
        "has_sig": false,
        "md5_digest": "4d37022fc10b10b0eb13f480970dc400",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 59734,
        "upload_time": "2020-07-11T11:36:23",
        "upload_time_iso_8601": "2020-07-11T11:36:23.848276Z",
        "url": "https://files.pythonhosted.org/packages/65/79/39ae50adeae504628938d9055422702efc2061804c865273c0823c1512c5/TensorflowTTS-0.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9a253b05a0dc179e4143bb7f50ee6db17e9d35bb2e969e0fdc86426a819b71cb",
          "md5": "f9d2ff4b2f72392ff02abedc1beeda9d",
          "sha256": "3b587e938301307b539dff5d9c69ae269e76ce4890db7d3d733c7a8d499d870e"
        },
        "downloads": -1,
        "filename": "TensorFlowTTS-0.8-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f9d2ff4b2f72392ff02abedc1beeda9d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 112312,
        "upload_time": "2020-08-23T08:51:10",
        "upload_time_iso_8601": "2020-08-23T08:51:10.621665Z",
        "url": "https://files.pythonhosted.org/packages/9a/25/3b05a0dc179e4143bb7f50ee6db17e9d35bb2e969e0fdc86426a819b71cb/TensorFlowTTS-0.8-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0b0994e55b20a526ba0ea79b10c0d9a1e4b6309352200f241badd7b5f09a46d1",
          "md5": "d60ed4f423070f3d79f3c7d7d37c633f",
          "sha256": "81eb2416c3a1f7847ea0e847b2cee4c19808d403d024a14a2480ac8dda06dacb"
        },
        "downloads": -1,
        "filename": "TensorFlowTTS-0.8.tar.gz",
        "has_sig": false,
        "md5_digest": "d60ed4f423070f3d79f3c7d7d37c633f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 84474,
        "upload_time": "2020-08-23T08:51:13",
        "upload_time_iso_8601": "2020-08-23T08:51:13.468170Z",
        "url": "https://files.pythonhosted.org/packages/0b/09/94e55b20a526ba0ea79b10c0d9a1e4b6309352200f241badd7b5f09a46d1/TensorFlowTTS-0.8.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.9": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "244b68860f419d848d2e4fb57c03194563aed2f4317227f93b91839482aa0723",
          "md5": "8a15a7c1abc8d5fe6ee63b88d190a69f",
          "sha256": "6626a383871a7cb69a90b4b1742f7f766220e7822a3ae749c30b18a3e2ac114e"
        },
        "downloads": -1,
        "filename": "TensorFlowTTS-0.9-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "8a15a7c1abc8d5fe6ee63b88d190a69f",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 112500,
        "upload_time": "2020-10-04T06:21:21",
        "upload_time_iso_8601": "2020-10-04T06:21:21.006594Z",
        "url": "https://files.pythonhosted.org/packages/24/4b/68860f419d848d2e4fb57c03194563aed2f4317227f93b91839482aa0723/TensorFlowTTS-0.9-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c6668a5897ec4fe444f6b7b2985a1dccbc6f6a1bf816fa6fba3cfe92326c91d2",
          "md5": "9e19cd80812dab537d6f0546cb2a8a42",
          "sha256": "fa7260fc92cf62467c4686add86babf5f7b74829cb33fe5b3d054928ebf1fb93"
        },
        "downloads": -1,
        "filename": "TensorFlowTTS-0.9.tar.gz",
        "has_sig": false,
        "md5_digest": "9e19cd80812dab537d6f0546cb2a8a42",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 84772,
        "upload_time": "2020-10-04T06:21:23",
        "upload_time_iso_8601": "2020-10-04T06:21:23.210802Z",
        "url": "https://files.pythonhosted.org/packages/c6/66/8a5897ec4fe444f6b7b2985a1dccbc6f6a1bf816fa6fba3cfe92326c91d2/TensorFlowTTS-0.9.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5d56931dee4ea7db9f59f328ad1f174d6b4174a5a9c4554cda3ab0d804988480",
          "md5": "ca9f7f34db22f0afb121dc9169d8cea9",
          "sha256": "5faa4673678a56f755afd7ce3fa7de66972475ef164ffff01ef96fcd0dd80383"
        },
        "downloads": -1,
        "filename": "TensorFlowTTS-1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ca9f7f34db22f0afb121dc9169d8cea9",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 121951,
        "upload_time": "2021-01-12T07:11:16",
        "upload_time_iso_8601": "2021-01-12T07:11:16.794472Z",
        "url": "https://files.pythonhosted.org/packages/5d/56/931dee4ea7db9f59f328ad1f174d6b4174a5a9c4554cda3ab0d804988480/TensorFlowTTS-1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ddb7a9371f594028ef001c45d4bbae9957b42dab1a885b6b166b4c44e2ca2ba9",
          "md5": "6213afb3ffdce3192d5a2dd8770ab750",
          "sha256": "8de5ab3a4241350c7ced34f711badf28cd229f6ee63438570da42083c4304f66"
        },
        "downloads": -1,
        "filename": "TensorFlowTTS-1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "6213afb3ffdce3192d5a2dd8770ab750",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 89564,
        "upload_time": "2021-01-12T07:11:19",
        "upload_time_iso_8601": "2021-01-12T07:11:19.255520Z",
        "url": "https://files.pythonhosted.org/packages/dd/b7/a9371f594028ef001c45d4bbae9957b42dab1a885b6b166b4c44e2ca2ba9/TensorFlowTTS-1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4ade631bb36cd1c5d3e44969ea27c9e3345c4ca7197f33e31470aac942d11c99",
          "md5": "92bad11076a9e98cd641480d72fb9768",
          "sha256": "3e92fa0a88652a1623b9a31ac319e9f515c77e154cbde0ca357ed4b758465149"
        },
        "downloads": -1,
        "filename": "TensorFlowTTS-1.6-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "92bad11076a9e98cd641480d72fb9768",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 126097,
        "upload_time": "2021-06-01T09:41:24",
        "upload_time_iso_8601": "2021-06-01T09:41:24.421637Z",
        "url": "https://files.pythonhosted.org/packages/4a/de/631bb36cd1c5d3e44969ea27c9e3345c4ca7197f33e31470aac942d11c99/TensorFlowTTS-1.6-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d6e08db5ff1df755fbdfeb5e2fb26aa31e2910d2e61f90a0143f984b21921bc3",
          "md5": "e1f066c1790e108bc7acb37936cfca53",
          "sha256": "5cef757bed5eb3a464e7828ff5635115b7f3209c77f1a93f7a6016db8b715650"
        },
        "downloads": -1,
        "filename": "TensorFlowTTS-1.6.tar.gz",
        "has_sig": false,
        "md5_digest": "e1f066c1790e108bc7acb37936cfca53",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 91576,
        "upload_time": "2021-06-01T09:41:26",
        "upload_time_iso_8601": "2021-06-01T09:41:26.677007Z",
        "url": "https://files.pythonhosted.org/packages/d6/e0/8db5ff1df755fbdfeb5e2fb26aa31e2910d2e61f90a0143f984b21921bc3/TensorFlowTTS-1.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.6.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6ff5b6058e294c6373450b4775b29c66690f80780ad27bd8e2b85e67d7a0ae76",
          "md5": "156a2a04249b5149fc5da7c86c9e4a10",
          "sha256": "dd2a9464075672016f8d53888af2441bbac619edb6cab64ce5d288a3550ff910"
        },
        "downloads": -1,
        "filename": "TensorFlowTTS-1.6.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "156a2a04249b5149fc5da7c86c9e4a10",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 126122,
        "upload_time": "2021-06-01T10:59:04",
        "upload_time_iso_8601": "2021-06-01T10:59:04.037185Z",
        "url": "https://files.pythonhosted.org/packages/6f/f5/b6058e294c6373450b4775b29c66690f80780ad27bd8e2b85e67d7a0ae76/TensorFlowTTS-1.6.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "290a1fcc0a7159b94ea07c8c6dee2cfabe4ead60f1e4c8b614c68103d92a84c0",
          "md5": "7f9a10c27b552c2965d5e5ea0187e803",
          "sha256": "0c0af5382caeea22a82dd4bd1c4e974d850abc9a854c24f78cbf84b49d370719"
        },
        "downloads": -1,
        "filename": "TensorFlowTTS-1.6.1.tar.gz",
        "has_sig": false,
        "md5_digest": "7f9a10c27b552c2965d5e5ea0187e803",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 91573,
        "upload_time": "2021-06-01T10:59:06",
        "upload_time_iso_8601": "2021-06-01T10:59:06.382141Z",
        "url": "https://files.pythonhosted.org/packages/29/0a/1fcc0a7159b94ea07c8c6dee2cfabe4ead60f1e4c8b614c68103d92a84c0/TensorFlowTTS-1.6.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "eed8ac083f44aa6f7b45e964d641e688f9abccd305e799d330d0c05e296176f6",
          "md5": "718a05b6a8bbbe23af89a2bc9f3d3476",
          "sha256": "035b1706ac9cd0c5ef87216ca278c19ec86076b0886342aa3ea12a14013e72c4"
        },
        "downloads": -1,
        "filename": "TensorFlowTTS-1.8-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "718a05b6a8bbbe23af89a2bc9f3d3476",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 128524,
        "upload_time": "2021-08-21T13:42:46",
        "upload_time_iso_8601": "2021-08-21T13:42:46.260240Z",
        "url": "https://files.pythonhosted.org/packages/ee/d8/ac083f44aa6f7b45e964d641e688f9abccd305e799d330d0c05e296176f6/TensorFlowTTS-1.8-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "63df69a696749a3a863b75444753ab38ddb0a3269d5074fb0ef1630f3e21975b",
          "md5": "70fca32cba57a1912adbbc0a48d51b1a",
          "sha256": "22d92ef87af87702aec7ccc44a1ed1901ec12756ae04d2f968b4f92e21e1aff2"
        },
        "downloads": -1,
        "filename": "TensorFlowTTS-1.8.tar.gz",
        "has_sig": false,
        "md5_digest": "70fca32cba57a1912adbbc0a48d51b1a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 92370,
        "upload_time": "2021-08-21T13:42:49",
        "upload_time_iso_8601": "2021-08-21T13:42:49.699755Z",
        "url": "https://files.pythonhosted.org/packages/63/df/69a696749a3a863b75444753ab38ddb0a3269d5074fb0ef1630f3e21975b/TensorFlowTTS-1.8.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "eed8ac083f44aa6f7b45e964d641e688f9abccd305e799d330d0c05e296176f6",
        "md5": "718a05b6a8bbbe23af89a2bc9f3d3476",
        "sha256": "035b1706ac9cd0c5ef87216ca278c19ec86076b0886342aa3ea12a14013e72c4"
      },
      "downloads": -1,
      "filename": "TensorFlowTTS-1.8-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "718a05b6a8bbbe23af89a2bc9f3d3476",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 128524,
      "upload_time": "2021-08-21T13:42:46",
      "upload_time_iso_8601": "2021-08-21T13:42:46.260240Z",
      "url": "https://files.pythonhosted.org/packages/ee/d8/ac083f44aa6f7b45e964d641e688f9abccd305e799d330d0c05e296176f6/TensorFlowTTS-1.8-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "63df69a696749a3a863b75444753ab38ddb0a3269d5074fb0ef1630f3e21975b",
        "md5": "70fca32cba57a1912adbbc0a48d51b1a",
        "sha256": "22d92ef87af87702aec7ccc44a1ed1901ec12756ae04d2f968b4f92e21e1aff2"
      },
      "downloads": -1,
      "filename": "TensorFlowTTS-1.8.tar.gz",
      "has_sig": false,
      "md5_digest": "70fca32cba57a1912adbbc0a48d51b1a",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 92370,
      "upload_time": "2021-08-21T13:42:49",
      "upload_time_iso_8601": "2021-08-21T13:42:49.699755Z",
      "url": "https://files.pythonhosted.org/packages/63/df/69a696749a3a863b75444753ab38ddb0a3269d5074fb0ef1630f3e21975b/TensorFlowTTS-1.8.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}