{
  "info": {
    "author": "Robert Reynolds",
    "author_email": "ReynoldsRJR@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Framework :: Flake8",
      "Framework :: Pytest",
      "Intended Audience :: Developers",
      "Intended Audience :: Education",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: GNU General Public License v3 (GPLv3)",
      "Natural Language :: Russian",
      "Operating System :: MacOS :: MacOS X",
      "Operating System :: Microsoft :: Windows",
      "Operating System :: POSIX",
      "Operating System :: POSIX :: Linux",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3 :: Only",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Topic :: Education",
      "Topic :: Education :: Computer Aided Instruction (CAI)",
      "Topic :: Scientific/Engineering :: Artificial Intelligence",
      "Topic :: Scientific/Engineering :: Human Machine Interfaces",
      "Topic :: Text Processing :: Linguistic",
      "Topic :: Utilities",
      "Typing :: Typed"
    ],
    "description": "# UDAR(enie)\n\n[![Actions Status](https://github.com/reynoldsnlp/udar/workflows/Test%20and%20Publish/badge.svg)](https://github.com/reynoldsnlp/udar/actions)\n[![codecov](https://codecov.io/gh/reynoldsnlp/udar/branch/master/graph/badge.svg)](https://codecov.io/gh/reynoldsnlp/udar)\n\n**U**DAR **D**oes **A**ccented **R**ussian: A finite-state morphological\nanalyzer of Russian that handles stressed wordforms.\n\nA python wrapper for the [Russian finite-state\ntransducer](https://victorio.uit.no/langtech/trunk/langs/rus/) described\noriginally in chapter 2 of [my dissertation](http://hdl.handle.net/10037/9685).\n\nIf you use this work in your research please cite the following:\n\n---\n> Reynolds, Robert J. \"Russian natural language processing for computer-assisted language learning: capturing the benefits of deep morphological analysis in real-life applications\" PhD Diss., UiT–The Arctic University of Norway, 2016. https://hdl.handle.net/10037/9685\n---\n\n#### Feature requests, issues, and pull requests are welcome!\n\n## Non-python dependencies\n\nThis repository uses `git-lfs` for large files. Be sure to\n[download and install it](https://git-lfs.github.com/) before you clone/commit.\n\nFor all features to be available, you should have `hfst` and `vislcg3`\ninstalled as command-line utilities. Specifically, `hfst` is needed for\nFST-based tokenization, and `vislcg3` is needed for grammatical disambiguation.\nThe version used to successfully test the code is included in each commit in\n[this file](../master/hfst_vislcg3_versions.txt). The recommended method\nfor installing these dependencies is as follows:\n\n#### MacOS\n\n```bash\n$ curl https://apertium.projectjj.com/osx/install-nightly.sh | sudo bash\n```\n\n#### Debian / Ubuntu\n\n```bash\n$ wget https://apertium.projectjj.com/apt/install-nightly.sh -O - | sudo bash\n$ sudo apt-get install cg3 hfst hfst-dev\n```\n\n## Installation\n\nUntil the first stable version is released on [PyPI](https://pypi.org/), `udar`\ncan be installed directly from this repository using `pip`:\n\n```bash\n$ python3 -m pip install --user git+https://github.com/reynoldsnlp/udar\n```\n\n## Introduction\n\n> NB! Documentation is currently limited to docstrings. I recommend that you\n> use `help()` frequently to see how to use classes and methods. For example,\n> to see what options are available for building a `Document`, try\n> `help(Document)`.\n\nThe most common use-case is to use the `Document` constructor to automatically\ntokenize and analyze a text. If you `print()` a `Document` object, the result\nis an `XFST`/`HFST` stream:\n\n```python\nimport udar\ndoc1 = udar.Document('Мы удивились простоте системы.')\nprint(doc1)\n# Мы\tмы+Pron+Pers+Pl1+Nom\t0.000000\n# \n# удивились\tудивиться+V+Perf+IV+Pst+MFN+Pl\t5.078125\n# \n# простоте\tпростота+N+Fem+Inan+Sg+Dat\t4.210938\n# простоте\tпростота+N+Fem+Inan+Sg+Loc\t4.210938\n# \n# системы\tсистема+N+Fem+Inan+Pl+Acc\t5.429688\n# системы\tсистема+N+Fem+Inan+Pl+Nom\t5.429688\n# системы\tсистема+N+Fem+Inan+Sg+Gen\t5.429688\n# \n# .\t.+CLB\t0.000000\n```\n\nPassing the argument `disambiguate=True`, or running `doc1.disambiguate()`\nafter the fact will run a Constraint Grammar to remove as many ambiguous\nreadings as possible. ***This grammar is far from complete, so some ambiguous\nreadings will remain.***\n\n## Data objects\n\n### `Document` object\n\n| Property | Type | Description |\n| --- | --- | --- |\n| text | `str` | Original text of this document |\n| sentences | `List[Sentence]` | List of sentences in this document |\n| num\\_tokens | `int` | Number of tokens in this document |\n| features | `tuple` | `udar.features.FeatureExtractor` stores extracted features here |\n\n`Document` objects have convenient methods for adding stress or converting to\nphonetic transcription.\n\n| Method | Return type | Description |\n| --- | --- | --- |\n| stressed | `str` | The original text of the document with stress marks |\n| phonetic | `str` | The original text converted to phonetic transcription |\n| transliterate | `str` | The original text converted to Romanized Cyrillic (default=Scholarly) |\n| disambiguate | `None` | Disambiguate readings using the Constraint Grammar |\n| cg3\\_str | `str` | Analysis stream in the [VISL-CG3 format](https://visl.sdu.dk/cg3/single/#stream-vislcg) |\n| from\\_cg3 | `Document` | Create `Document` from [VISL-CG3 format stream](https://visl.sdu.dk/cg3/single/#stream-vislcg) |\n| hfst\\_str | `str` | Analysis stream in the XFST/HFST format |\n| from\\_hfst | `Document` | Create `Document` from XFST/HFST format stream |\n| to\\_dict | `list` | Convert to a complex list object |\n| to\\_json | `str` | Convert to a JSON string |\n\n#### Examples\n\n```python\nstressed_doc1 = doc1.stressed()\nprint(stressed_doc1)\n# Мы́ удиви́лись простоте́ систе́мы.\n\nambig_doc = udar.Document('Твои слова ничего не значат.', disambiguate=True)\nprint(sorted(ambig_doc[1].stresses()))  # Note that слова is still ambiguous\n# ['сло́ва', 'слова́']\n\nprint(ambig_doc.stressed(selection='safe'))  # 'safe' skips сло́ва and слова́\n# Твои́ слова ничего́ не зна́чат.\nprint(ambig_doc.stressed(selection='all'))  # 'all' combines сло́ва and слова́\n# Твои́ сло́ва́ ничего́ не зна́чат.\nprint(ambig_doc.stressed(selection='rand') in {'Твои́ сло́ва ничего́ не зна́чат.', 'Твои́ слова́ ничего́ не зна́чат.'})  # 'rand' randomly chooses between сло́ва and слова́\n# True\n\n\nphonetic_doc1 = doc1.phonetic()\nprint(phonetic_doc1)\n# мы́ уд'ив'и́л'ис' пръстʌт'э́ с'ис'т'э́мы.\n```\n\n### `Sentence` object\n\n| Property | Type | Description |\n| --- | --- | --- |\n| doc | `Document` | \"Back pointer\" to the parent document of this sentence |\n| text | `str` | Original text of this sentence |\n| tokens | `List[Token]` | The list of tokens in this sentence |\n| id | `str` | (optional) Sentence id, if assigned at creation |\n\n| Method | Return type | Description |\n| --- | --- | --- |\n| stressed | `str` | The original text of the sentence with stress marks |\n| phonetic | `str` | The original text converted to phonetic transcription |\n| transliterate | `str` | The original text converted to Romanized Cyrillic (default=Scholarly) |\n| disambiguate | `None` | Disambiguate readings using the Constraint Grammar |\n| cg3\\_str | `str` | Analysis stream in the [VISL-CG3 format](https://visl.sdu.dk/cg3/single/#stream-vislcg) |\n| from\\_cg3 | `Sentence` | Create `Sentence` from [VISL-CG3 format stream](https://visl.sdu.dk/cg3/single/#stream-vislcg)\n| hfst\\_str | `str` | Analysis stream in the XFST/HFST format |\n| from\\_hfst | `Sentence` | Create `Sentence` from XFST/HFST format stream |\n| to\\_dict | `list` | Convert to a complex list object |\n| to\\_json | `str` | Convert to a JSON string |\n\n### `Token` object\n\n| Property | Type | Description |\n| --- | --- | --- |\n| id | `str` | The index of this token in the sentence, 1-based |\n| text | `str` | The original text of this token |\n| misc | `str` | Miscellaneous annotations with regard to this token |\n| lemmas | `Set[str]` | All possible lemmas, based on remaining readings |\n| readings | `List[Reading]` | List of readings not removed by the Constraint Grammar |\n| removed\\_readings | `List[Reading]` | List of readings removed by the Constraint Grammar | head | `int` | The id of the syntactic head of this token in the sentence, 1-based (0 is reserved for an artificial symbol that represents the root of the syntactic tree). |\n| deprel | `str` | The dependency relation between this word and its syntactic head. Example: ‘nmod’. |\n\n| Method | Return type | Description |\n| --- | --- | --- |\n| stresses | `Set[str]` | All possible stressed wordforms, based on remaining readings |\n| stressed | `str` | The original text of the sentence with stress marks |\n| phonetic | `str` | The original text converted to phonetic transcription |\n| most\\_likely\\_reading | `Reading` | \"Most likely\" reading (may be partially random selection) |\n| most\\_likely\\_lemmas | `List[str]` | List of lemma(s) from the \"most likely\" reading |\n| transliterate | `str` | The original text converted to Romanized Cyrillic (default=Scholarly) |\n| force\\_disambiguate | `None` | Fully disambiguate readings using methods **other than** the Constraint Grammar |\n| cg3\\_str | `str` | Analysis stream in the [VISL-CG3 format](https://visl.sdu.dk/cg3/single/#stream-vislcg) |\n| hfst\\_str | `str` | Analysis stream in the XFST/HFST format |\n| to\\_dict | `dict` | Convert to a `dict` object |\n| to\\_json | `str` | Convert to a JSON string |\n\n### `Reading` object\n\n| Property | Type | Description |\n| --- | --- | --- |\n| subreadings | `List[Subreading]` | Usually only one subreading, but multiple subreadings are possible for complex `Token`s. |\n| lemmas | `List[str]` | Lemmas from all subreadings |\n| grouped\\_tags | `List[Tag]` | The part-of-speech, morphosyntactic, semantic and other tags from all subreadings |\n| weight | `str` | Weight indicating the likelihood of the reading, without respect to context |\n| cg\\_rule | `str` | Reference to the rule in the constraint grammar that removed/selected/etc. this reading. If no action has been taken on this reading, then `''`. |\n| is\\_most\\_likely | `bool` | Indicates whether this reading has been selected as the most likely reading of its `Token`. Note that some selection methods may be at least partially ***random***. |\n\n| Method | Return type | Description |\n| --- | --- | --- |\n| cg3\\_str | `str` | Analysis stream in the [VISL-CG3 format](https://visl.sdu.dk/cg3/single/#stream-vislcg) |\n| hfst\\_str | `str` | Analysis stream in the XFST/HFST format |\n| generate | `str` | Generate the wordform from this reading |\n| replace\\_tag | `None` | Replace a tag in this reading |\n| does\\_not\\_conflict | `bool` | Determine whether reading from external tagset (e.g. Universal Dependencies) conflicts with this reading |\n| to\\_dict | `list` | Convert to a `list` object |\n| to\\_json | `str` | Convert to a JSON string |\n\n### `Subreading` object\n\n| Property | Type | Description |\n| --- | --- | --- |\n| lemma | `str` | The lemma of the subreading |\n| tags | `List[Tag]` | The part-of-speech, morphosyntactic, semantic and other tags |\n| tagset | `Set[Tag]` | Same as `tags`, but for faster membership testing (`in` Reading) |\n\n| Method | Return type | Description |\n| --- | --- | --- |\n| cg3\\_str | `str` | Analysis stream in the [VISL-CG3 format](https://visl.sdu.dk/cg3/single/#stream-vislcg) |\n| hfst\\_str | `str` | Analysis stream in the XFST/HFST format |\n| replace\\_tag | `None` | Replace a tag in this reading |\n| to\\_dict | `dict` | Convert to a `dict` object |\n| to\\_json | `str` | Convert to a JSON string |\n\n### `Tag` object\n\n| Property | Type | Description |\n| --- | --- | --- |\n| name | `str` | The name of this tag |\n| ms\\_feat | `str` | Morphosyntactic feature that this tag is associated with (e.g. `Dat` has ms\\_feat `CASE`) |\n| detail | `str` | Description of the tag's purpose or meaning |\n| is\\_L2\\_error | `bool` | Whether this tag indicates a second-language learner error |\n\n| Method | Return type | Description |\n| --- | --- | --- |\n| info | `str` | Alias for `Tag.detail` |\n\n\n### Convenience functions\n\nA number of functions are included, both for convenience, and to give concrete\nexamples for using the API.\n\n#### noun\\_distractors()\n\nThis function generates all six cases of a given noun. If the given noun is\nsingular, then the function generates singular forms. If the given noun is\nplural, then the function generates plural forms. Such a list can be used in a\nmultiple-choice exercise, hence the name `distractors`.\n\n```python\nsg_paradigm = udar.noun_distractors('словом')\nprint(sg_paradigm == {'сло́ву', 'сло́ве', 'сло́вом', 'сло́ва', 'сло́во'})\n# True\n\npl_paradigm = udar.noun_distractors('словах')\nprint(pl_paradigm == {'слова́м', 'слова́', 'слова́х', 'слова́ми', 'сло́в'})\n# True\n```\n\nIf unstressed forms are desired, simply pass the argument `stressed=False`.\n\n#### diagnose\\_L2()\n\nThis function will take a text string as the argument, and will return a\ndictionary of all the types of L2 errors in the text, along with examples of\nthe error.\n\n```python\ndiag = udar.diagnose_L2('Етот малчик говорит по-русски.')\nprint(diag == {'Err/L2_e2je': {'Етот'}, 'Err/L2_NoSS': {'малчик'}})\n# True\n```\n\n#### tag\\_info()\n\nThis function will look up the meaning of any tag used by the analyzer.\n\n```python\nprint(udar.tag_info('Err/L2_ii'))\n# L2 error: Failure to change ending ие to ии in +Sg+Loc or +Sg+Dat, e.g. к Марие, о кафетерие, о знание\n```\n\n### Using the transducers manually\n\nThe transducers come in two varieties: the `Analyzer` class and the `Generator`\nclass. For memory efficiency, I recommend using the `get_analyzer` and\n`get_generator` functions, which ensure that each flavor of the transducers\nremains a singleton in memory.\n\n#### Analyzer\n\nThe `Analyzer` can be initialized with or without analyses for second-language\nlearner errors using the keyword `L2_errors`.\n\n```python\nanalyzer = udar.get_analyzer()  # by default, L2_errors is False\nL2_analyzer = udar.get_analyzer(L2_errors=True)\n```\n\n`Analyzer`s are callable. They take a token `str` and return a sequence of\nreading/weight `tuple`s.\n\n```python\nraw_readings1 = analyzer('сло́ва')\nprint(raw_readings1)\n# (('слово+N+Neu+Inan+Sg+Gen', 5.9755859375),)\n\nraw_readings2 = analyzer('слова')\nprint(raw_readings2)\n# (('слово+N+Neu+Inan+Pl+Acc', 5.9755859375), ('слово+N+Neu+Inan+Pl+Nom', 5.9755859375), ('слово+N+Neu+Inan+Sg+Gen', 5.9755859375))\n```\n\n#### Generator\n\nThe `Generator` can be initialized in three varieties: unstressed, stressed,\nand phonetic.\n\n```python\ngenerator = udar.get_generator()  # unstressed by default\nstressed_generator = udar.get_generator(stressed=True)\nphonetic_generator = udar.get_generator(phonetic=True)\n```\n\n`Generator`s are callable. They take a `Reading` or raw reading `str` and\nreturn a surface form.\n\n```python\nprint(stressed_generator('слово+N+Neu+Inan+Pl+Nom'))\n# слова́\n```\n\n## Working with `Token`s and `Readings`s\n\nYou can easily check if a morphosyntactic tag is in a `Token`, `Reading`,\nor `Subreading` using `in`:\n \n```python\ntoken2 = udar.Token('слова', analyze=True)\nprint(token2)\n# слова [слово_N_Neu_Inan_Pl_Acc  слово_N_Neu_Inan_Pl_Nom  слово_N_Neu_Inan_Sg_Gen]\n\nprint('Gen' in token2)  # do any of the readings include Genitive case?\n# True\n\nprint('слово' in token2)  # does not work for lemmas; use `in Token.lemmas`\n# False\n\nprint('слово' in token2.lemmas)\n# True\n```\n\nYou can make a filtered list of a `Token`'s readings using the following idiom:\n\n```python\npl_readings = [reading for reading in token2 if 'Pl' in reading]\nprint(pl_readings)\n# [Reading(слово+N+Neu+Inan+Pl+Acc, 5.975586, ), Reading(слово+N+Neu+Inan+Pl+Nom, 5.975586, )]\n```\n\n## Related projects\n\nhttps://github.com/mikahama/uralicNLP\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/reynoldsnlp/udar",
    "keywords": "",
    "license": "GPL3",
    "maintainer": "",
    "maintainer_email": "",
    "name": "udar",
    "package_url": "https://pypi.org/project/udar/",
    "platform": "",
    "project_url": "https://pypi.org/project/udar/",
    "project_urls": {
      "Homepage": "https://github.com/reynoldsnlp/udar"
    },
    "release_url": "https://pypi.org/project/udar/0.1.10/",
    "requires_dist": [
      "bs4",
      "fastapi",
      "hfst",
      "nltk",
      "pandas",
      "pexpect",
      "sphinx-autodoc-typehints",
      "stanza (>=1.1.1)",
      "uvicorn",
      "pytest (>=4.6) ; extra == 'test'",
      "pytest-cov ; extra == 'test'",
      "pytest-flake8 ; extra == 'test'",
      "pytest-mypy ; extra == 'test'",
      "pytest-timeout ; extra == 'test'"
    ],
    "requires_python": "!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*,>2.7",
    "summary": "Detailed part-of-speech tagger for (accented) Russian.",
    "version": "0.1.10",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 10591500,
  "releases": {
    "0.1.10": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "41c8b312465311a7acb4e94fb0698dee11c10ee457db29fc353ce6be2317b8c6",
          "md5": "3ef1435bded49b57dddae0b79e66657c",
          "sha256": "22ded39eca10374bafd7924046389d6d04ea7340544ca6234793404f53e88607"
        },
        "downloads": -1,
        "filename": "udar-0.1.10-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "3ef1435bded49b57dddae0b79e66657c",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": "!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*,>2.7",
        "size": 89557276,
        "upload_time": "2021-06-08T16:47:24",
        "upload_time_iso_8601": "2021-06-08T16:47:24.118784Z",
        "url": "https://files.pythonhosted.org/packages/41/c8/b312465311a7acb4e94fb0698dee11c10ee457db29fc353ce6be2317b8c6/udar-0.1.10-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5cc0e109d8b4c2ae9c42723215d1e6f761f59e7bc30af40fd39a6317a6d08d8f",
          "md5": "407df7cd63b308f74d82d62e3f041ad8",
          "sha256": "40081760530d6aafbf8fd02bea629d65ba7da2214441a59819b038a6a6f15222"
        },
        "downloads": -1,
        "filename": "udar-0.1.10.tar.gz",
        "has_sig": false,
        "md5_digest": "407df7cd63b308f74d82d62e3f041ad8",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": "!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*,>2.7",
        "size": 89348813,
        "upload_time": "2021-06-08T16:47:31",
        "upload_time_iso_8601": "2021-06-08T16:47:31.219561Z",
        "url": "https://files.pythonhosted.org/packages/5c/c0/e109d8b4c2ae9c42723215d1e6f761f59e7bc30af40fd39a6317a6d08d8f/udar-0.1.10.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "465e49dba61ee69a183583029d6fb32bd33191e50ef0f581e2eae37ee079f466",
          "md5": "eeee3c59a39f06d54e123d41170bf887",
          "sha256": "77d338789018ecbd3ddc70575990e711977475fff9765d86a544b9788fd84d97"
        },
        "downloads": -1,
        "filename": "udar-0.1.7-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "eeee3c59a39f06d54e123d41170bf887",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": "!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*,>2.7",
        "size": 89539987,
        "upload_time": "2021-04-22T22:49:16",
        "upload_time_iso_8601": "2021-04-22T22:49:16.322507Z",
        "url": "https://files.pythonhosted.org/packages/46/5e/49dba61ee69a183583029d6fb32bd33191e50ef0f581e2eae37ee079f466/udar-0.1.7-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "87dcffb7f674afc2eedb4c1ee85086223720e4cf890e990191b8beecc7c8b774",
          "md5": "747de04e53c883715bd7a86ac0aebbfb",
          "sha256": "849e26412325ec264614e3bd80bf9620839ab88384d25be7e8b2ee715c158df4"
        },
        "downloads": -1,
        "filename": "udar-0.1.7.tar.gz",
        "has_sig": false,
        "md5_digest": "747de04e53c883715bd7a86ac0aebbfb",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": "!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*,>2.7",
        "size": 89335405,
        "upload_time": "2021-04-22T22:49:24",
        "upload_time_iso_8601": "2021-04-22T22:49:24.920450Z",
        "url": "https://files.pythonhosted.org/packages/87/dc/ffb7f674afc2eedb4c1ee85086223720e4cf890e990191b8beecc7c8b774/udar-0.1.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b665a0f1148b5d71532a91d0a5f751422242a0be914adff44a60b8fca6837054",
          "md5": "f2813cb835a04a3bfa0d1ba84875cb71",
          "sha256": "e5c6ef47ddb5893a793016a119d5d7a78a39ae7849ba26982f551b1b52d17ade"
        },
        "downloads": -1,
        "filename": "udar-0.1.8-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f2813cb835a04a3bfa0d1ba84875cb71",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": "!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*,>2.7",
        "size": 89539986,
        "upload_time": "2021-04-22T22:55:04",
        "upload_time_iso_8601": "2021-04-22T22:55:04.129718Z",
        "url": "https://files.pythonhosted.org/packages/b6/65/a0f1148b5d71532a91d0a5f751422242a0be914adff44a60b8fca6837054/udar-0.1.8-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "26b19b1de81bd12a47c6960e5b2e70ebecc618577934cb9857a110cf85a8e7cc",
          "md5": "11e2a8ab9d38ee0afa0fbd14fd0ea237",
          "sha256": "2805d3a51df3fcaebbd989dbddb480180c1415c0ece7c0f6de11837f4bb36296"
        },
        "downloads": -1,
        "filename": "udar-0.1.8.tar.gz",
        "has_sig": false,
        "md5_digest": "11e2a8ab9d38ee0afa0fbd14fd0ea237",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": "!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*,>2.7",
        "size": 89335316,
        "upload_time": "2021-04-22T22:55:10",
        "upload_time_iso_8601": "2021-04-22T22:55:10.345840Z",
        "url": "https://files.pythonhosted.org/packages/26/b1/9b1de81bd12a47c6960e5b2e70ebecc618577934cb9857a110cf85a8e7cc/udar-0.1.8.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.9": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b01d201fe6b2562a633bdca8a77bc080f130d97e31e5b231209850c958d6f306",
          "md5": "49ec08b8b726adc4d24a3f9a50a32b09",
          "sha256": "ced57d48c76bce32702190f57ec7ebc4317eb265ee32cccee318aca1d79dd3b3"
        },
        "downloads": -1,
        "filename": "udar-0.1.9-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "49ec08b8b726adc4d24a3f9a50a32b09",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": "!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*,>2.7",
        "size": 89557262,
        "upload_time": "2021-06-08T16:33:04",
        "upload_time_iso_8601": "2021-06-08T16:33:04.783542Z",
        "url": "https://files.pythonhosted.org/packages/b0/1d/201fe6b2562a633bdca8a77bc080f130d97e31e5b231209850c958d6f306/udar-0.1.9-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "abea7f330130ec73357f48c470cf2345fb6d57591dda8a73f6b3bae16752e249",
          "md5": "8f699a88f3750eff848b3c4539150f0f",
          "sha256": "8ac4d25ca84dbf368652ead3400d4bccb6ae3b8711beb5f1359b429441c286bd"
        },
        "downloads": -1,
        "filename": "udar-0.1.9.tar.gz",
        "has_sig": false,
        "md5_digest": "8f699a88f3750eff848b3c4539150f0f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": "!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*,>2.7",
        "size": 89348861,
        "upload_time": "2021-06-08T16:33:11",
        "upload_time_iso_8601": "2021-06-08T16:33:11.840838Z",
        "url": "https://files.pythonhosted.org/packages/ab/ea/7f330130ec73357f48c470cf2345fb6d57591dda8a73f6b3bae16752e249/udar-0.1.9.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "41c8b312465311a7acb4e94fb0698dee11c10ee457db29fc353ce6be2317b8c6",
        "md5": "3ef1435bded49b57dddae0b79e66657c",
        "sha256": "22ded39eca10374bafd7924046389d6d04ea7340544ca6234793404f53e88607"
      },
      "downloads": -1,
      "filename": "udar-0.1.10-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "3ef1435bded49b57dddae0b79e66657c",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": "!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*,>2.7",
      "size": 89557276,
      "upload_time": "2021-06-08T16:47:24",
      "upload_time_iso_8601": "2021-06-08T16:47:24.118784Z",
      "url": "https://files.pythonhosted.org/packages/41/c8/b312465311a7acb4e94fb0698dee11c10ee457db29fc353ce6be2317b8c6/udar-0.1.10-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "5cc0e109d8b4c2ae9c42723215d1e6f761f59e7bc30af40fd39a6317a6d08d8f",
        "md5": "407df7cd63b308f74d82d62e3f041ad8",
        "sha256": "40081760530d6aafbf8fd02bea629d65ba7da2214441a59819b038a6a6f15222"
      },
      "downloads": -1,
      "filename": "udar-0.1.10.tar.gz",
      "has_sig": false,
      "md5_digest": "407df7cd63b308f74d82d62e3f041ad8",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": "!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*,>2.7",
      "size": 89348813,
      "upload_time": "2021-06-08T16:47:31",
      "upload_time_iso_8601": "2021-06-08T16:47:31.219561Z",
      "url": "https://files.pythonhosted.org/packages/5c/c0/e109d8b4c2ae9c42723215d1e6f761f59e7bc30af40fd39a6317a6d08d8f/udar-0.1.10.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}