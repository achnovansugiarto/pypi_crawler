{
  "info": {
    "author": "John Kennedy",
    "author_email": "jjk.code.otter@gmail.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "Climate Indicator Manager\r\n=========================\r\n\r\nA lightweight package for managing, downloading and processing climate data for use in calculating and presenting\r\nclimate indicators, as well as creating dashboards based on these indicators.\r\n\r\nIt is built on a collection of metadata fies which describe the location and content of individual data collections and\r\ndata sets from those collections. For example, a *collection* might be something like \"HadCRUT\" and an individual\r\n*dataset* would be the file containing the monthly global mean temperatures calculated by the providers of \"HadCRUT\".\r\n\r\nThe current functionality includes tools to download, read and undertake simple processing of monthly and annual\r\ntimeseries and grids. Currently, simple processing includes:\r\n\r\n1. changing the baseline of the data,\r\n2. aggregating monthly data into annual data and\r\n3. calculating running means of the data.\r\n\r\nVarious statistics can also be calculated from the timeseries, including rankings for particular years and years\r\nassociated with particular rankings.\r\n\r\nEach step in processing is logged and added to the metadata for the dataset so that processing steps can be traced \r\nand reproduced.\r\n\r\n\r\nInstallation\r\n============\r\n\r\nDownload the code from the repository using your preferred method.\r\n\r\nNavigate to the root directory of the repository and type\r\n\r\n`pip install .`\r\n\r\nThis should install the package and necessary dependencies.\r\n\r\nSet up\r\n======\r\n\r\nThe managed data will be stored in a directory specified by the environment variable DATADIR. This is easy to set in\r\nlinux. In windows, do the following:\r\n\r\n1. right-click on the Windows icon (bottom left of the screen usually) and select \"System\"\r\n2. Click on \"Advanced system settings\"\r\n3. Click on \"Environment Variables...\"\r\n4. Under \"User variables for Username\" click \"New...\"\r\n5. For \"Variable name\" type DATADIR\r\n6. For \"Variable value\" type the pathname for the directory you want the data to go in.\r\n\r\nIn addition, if you want to download JRA-55 data from UCAR, CMEMS data or data from the NASA PODAAC, you will need a\r\nvalid username and password combo for each of these services. These values should be stored in a file called .env in\r\nthe `fetchers` directory of the repository. It should contain two lines for each of the data services:\r\n\r\n```\r\nUCAR_EMAIL=youremail@domain.com\r\nUCAR_PSWD=yourpasswordhere\r\nPODAAC_PSWD=anotherpasswordhere\r\nPODAAC_USER=anotherusernamehere\r\nCMEMS_USER=athirdusername\r\nCMEMS_PSWD=yetanotherpassword\r\n```\r\n\r\nAll three of these services are free to register, but you will have to set up the credentials online.\r\n\r\nDownloading data\r\n================\r\n\r\nThe first thing to do is to download the data. There are two main scripts for downloading data in the scripts\r\ndirectory. `get_timeseries.py` will download the data which are in the form of time series. `get_grids.py` will download\r\nthe gridded data.\r\n\r\nThe volume of gridded data is considerably larger than the volume of time series data. For some datasets, the whole\r\ngridded dataset is downloaded each time this is run, but for the reanalyses the full dataset is only downloaded once\r\nwith subsequent runs of the get_grids.py script only downloading months that have not already been downloaded. The\r\ngridded data are used to calculate custom area averages (such as the WMO Regional Association averages) and for \r\nplotting maps of the data. The key global indicators are all time series.\r\n\r\nSome datasets are not available online (the JRA-55 global mean temperature for example) so you will have to obtain \r\nthese from somewhere else or remove them from the processing. Any extra files such as these should be \r\ncopied into the `$DATADIR/ManagedData/Data/` directory in an appropriately named subdirectory that corresponds \r\nto the unique name given to the data set. This can be found in the metadata file for the data set (see below).\r\n\r\nPre-pocessing the data\r\n======================\r\n\r\nThe gridded data need to be pre-processed by running:\r\n\r\n`python regrid_grids.py`\r\n\r\nwhich calculates annual average grids on a consistent 5-degree latitude longitude grid for all the gridded data sets.\r\n\r\nIn order to generate area averages from the gridded data for specified sub regions, you will need to navigate to the\r\nscripts directory and run:\r\n\r\n`python calculate_wmo_ra_averages.py`\r\n\r\nThis reads in each of the data sets, regrids it to a standard resolution and then calculates the area averages for the\r\nsix WMO Regional Association areas and for the six African sub regions. It can take a while to run because it has to\r\nload and process a lot of reanalysis data.\r\n\r\n\r\nBuilding the website\r\n====================\r\n\r\nTo build the websites, navigate to the scripts directory and run\r\n\r\n`python build_dashboard.py`\r\n\r\nThis builds all the webpages, produces the figures for each web page and prepares the formatted data sets. These are \r\nwritten to the `DATADIR/ManagedData` directory with one directory created for each dashboard. Currently the code is \r\nset up to generate four dashboards: key indicators to 2021, key indicators to 2022, ocean indicators, \r\nand regional indicators to 2022.\r\n\r\nTo display a dashboard on the web, the files in the appropriate directory will need to be copied to an appropriate \r\nweb server.\r\n\r\n\r\nNavigating the website\r\n======================\r\n\r\nEach dashboard consists of \r\n\r\n\r\nDiverse other scripts\r\n=====================\r\n\r\nAs well as these main scripts, described above, there are others which perform the following tasks:\r\n\r\n* `annual_global_temperature_stats.py` which generates some annual plots and statistics\r\n* `arctic_sea_ice_plot.py` which generates some sea ice plots used in the State of the Climate report\r\n* `change_per_month_plots.py` which generates some plots based on monthly global mean temperature as well as some stats.\r\n* `five_year_global_temperature_stats.py` which generates some plots and stats based on 5-year running averages of\r\n  global temperature\r\n* `marine_heatwave_plot.py` which generates a plot of marine heatwave and cold spell occurrence.\r\n* `plot_monthly_indicators.py` which generates a set of plots for a range of indicators (not all monthly).\r\n* `plot_monthly_maps.py` which allows for the plotting of monthly temperature anomaly maps.\r\n* `ten_year_global_temperature_stats.py` which generates some plots and stats based on 10-year running averages of\r\n  global temperature for use in the decadal state of the climate report.\r\n  \r\nAdding data sets for an existing variable\r\n=========================================\r\n\r\nTo add a dataset for an existing variable, you need to \r\n* create a new collection file in the `metadata` folder\r\n* write a reader function in the `readers` directory. This should correspond to the \"reader\" entry in the collection metadata.\r\n* write a fetcher function in the `fetchers` directory. This should correspond to the \"reader\" entry in the collection metadata. This is only necessary if the file(s) can't be downloaded as a simple http(s) or ftp(s) request. For example, some datasets do not have a static URL, or there are a large number of files, or there is an API for accessing the data.\r\n\r\nThe form of these files should be clear from the other files and function in the respective \r\ndirectories, or by perusal of the schemas in the `data_manager` directory. An example metadata file looks like this:\r\n\r\n```\r\n{\r\n  \"name\": \"HadCRUT5\",\r\n  \"display_name\": \"HadCRUT5\",\r\n  \"version\": \"5.0.1.0\",\r\n  \"variable\": \"tas\",\r\n  \"units\": \"degC\",\r\n  \"citation\": [\"Morice, C.P., J.J. Kennedy, N.A. Rayner, J.P. Winn, E. Hogan, R.E. Killick, R.J.H. Dunn, T.J. Osborn, P.D. Jones and I.R. Simpson (in press) An updated assessment of near-surface temperature change from 1850: the HadCRUT5 dataset. Journal of Geophysical Research (Atmospheres) doi:10.1029/2019JD032361\"],\r\n  \"data_citation\": [\"\"],\r\n  \"acknowledgement\": \"HadCRUT.VVVV data were obtained from http://www.metoffice.gov.uk/hadobs/hadcrut5 on AAAA and are Â© British Crown Copyright, Met Office YYYY, provided under an Open Government License, http://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/\",\r\n  \"colour\": \"dimgrey\",\r\n  \"zpos\": 99,\r\n  \"datasets\": [\r\n    {\r\n      \"url\": [\"https://www.metoffice.gov.uk/hadobs/hadcrut5/data/current/analysis/HadCRUT.5.0.1.0.analysis.anomalies.ensemble_mean.nc\"],\r\n\t  \"filename\": [\"HadCRUT.5.0.1.0.analysis.anomalies.ensemble_mean.nc\"],\r\n      \"type\": \"gridded\",\r\n      \"long_name\": \"Near surface temperature\",\r\n\t  \"time_resolution\": \"monthly\",\r\n\t  \"space_resolution\": 5.0,\r\n\t  \"climatology_start\": 1961,\r\n\t  \"climatology_end\": 1990,\r\n\t  \"actual\": false,\r\n\t  \"derived\": false,\r\n\t  \"history\": [],\r\n      \"reader\": \"reader_hadcrut_ts\",\r\n\t  \"fetcher\": \"fetcher_standard_url\"\r\n    }\r\n  ]\r\n}\r\n```\r\n\r\nThe metadata describes a collection of data, in this case \"HadCRUT5\". HadCRUT5 consists of a number of data sets (only one is listed here) which are listed \r\nunder the \"datasets\" entry. It's important to populate as much of the metadata file as possible, as this links the outputs of the dashboard back to the initial \r\ninputs and maintains transparency of the system. The \"reader\" and \"fetcher\" specify functions for reading the data and downloading the data which are found in the 'readers' and 'fetchers' directories.\r\n\r\nMore complicated examples can be found in the repository.\r\n\r\n* `name` - this is a **unique** name for this particular collection\r\n* `display_name` - name used to label datasets in this collection in figure legends, captions and text.\r\n* `version` - latest version number for the data set\r\n* `variable` - variable name. `tas` is global surface temperature.\r\n* `units` - units used for this variable. \r\n* `citation` - a list of citations for papers describing the data set.\r\n* `data_citation` - a list of data citations for the data itself (if such exists).\r\n* `acknowledgement` - many dataset providers request a particular acknowledgement when the data are used.\r\n* `colour` - python colour name or hexadecimal RGB triple, used to represent data from this collection in line graphs\r\n* `zpos` - used to force ordering of lines in plots. Lines with higher zpos values will be drawn over lines with lower zpos values.\r\n\r\nThe dataset section consists of a lits of dataset metadata:\r\n\r\n* `url` - a list of URLs for the files.\r\n* `filename` - a list of the filenames which will be associated with the data set. For example, NSIDC Arctic ice extent has 12 files, one for each month of the year.\r\n* `type` - type of the data, either `timeseries` or `gridded`.\r\n* `long_name` - long descriptive name used in figure captions and other automatically generated text.\r\n* `time_resolution` - either `monthly` or `annual`\r\n* `space_resolution` - for `gridded` data sets this specifies the grid resolution in degrees. Set to 999 for time series data.\r\n* `climatology_start` - first year of the climatology period of the data in the data set.\r\n* `climatology_end` - last year of the climatology period of the data in the data set.\r\n* `actual` - set to True if the file contains actual values, set to False for anomalies.\r\n* `derived` - set to False. During processing, this flag is set to True to indicate that the original data have been further processed within the dashboard software.\r\n* `history` - a list which will hold the details of processing steps\r\n* `reader` - the name of a script in the `climind/readers` directory which will read the data described in the dataset metadata.\r\n* `fetcher` - the name of a script in the `climind/fetchers` direcotyr which will download the data described in the dataset metadata.\r\n\r\n\r\nAdding a new variable\r\n=====================\r\n\r\nIt is possible to add new variables. For example, there is currently no snow_cover variable.\r\n\r\n1. Think of a variable name e.g. `snow_cover`\r\n2. Check that the variable does not already exist. You can do this by looking through the metadata files.\r\n3. Add a new metadata file describing a collection with snow cover data in it.\r\n4. Check that the units are in the `metadata_schema.json` file in `climind.data_manager`. This is used to validate the metadata when it is read in.\r\n5. Add the new variable to the word document in `climind/web/word_documents/key_indicators_texts.docx`. Individual variables \r\n   appear towards the end of the document. The short `variable` name should appear in `Heading1` style and the text desribing it \r\n   should appear in `normal` style text. These short descriptions appear on the webpages in the section detailing the datasets and their processing.\r\n\r\nThat should be sufficient.\r\n\r\nMaking a new dashboard\r\n======================\r\n\r\nA dashboard is created using a dashboard metadata file. These are located in `climind/web/dashboard_metadata`. Each dashboard is split into Pages, which \r\neach correspond to an html webpage. Each Page consists of a set of Cards and Paragraphs (the capital letters indicate these are represented as classes \r\nin the underlying code). For examples, please see the `climind/web/dashboard_metadata` directory.\r\n\r\nA dashboard metadata file:\r\n\r\n```\r\n{\r\n  \"name\": \"Key Indicators\",\r\n  \"pages\": [ ... ]\r\n}\r\n```\r\n\r\nThe `pages` entry consists of a list of Pages which look something like:\r\n\r\n```\r\n{\r\n  \"id\": \"dashboard\",\r\n  \"name\": \"Key Climate Indicators\",\r\n  \"template\": \"front_page\",\r\n  \"cards\": [ ... ],\r\n  \"paragraphs\": [ ... ]\r\n},\r\n```\r\n\r\nThe `template` can be either a `front_page` or a `topic_page`. The front page is intended to be a clean landing page \r\nfor users. More information is provided on topic pages, including e.g. figure captions.\r\n\r\nThe `cards` entry is made up of one or more cards and the `paragraphs` entry of one or more paragraphs.\r\n\r\nA Card, contains an image, links to the image in other format, links to the data in a standard format and a link to another Page. \r\nThe metadata entries look like this:\r\n\r\n```\r\n{\r\n  \"link_to\": \"global_mean_temperature\", \"title\": \"Global temperature\",\r\n  \"selecting\": {\"type\": \"timeseries\", \"variable\": \"tas\", \"time_resolution\": \"monthly\"},\r\n  \"processing\":  [{\"method\": \"rebaseline\", \"args\": [1981, 2010]},\r\n                  {\"method\": \"make_annual\", \"args\": []},\r\n                  {\"method\": \"select_year_range\", \"args\":  [1850,2021]},\r\n                  {\"method\": \"add_offset\", \"args\": [0.69]},\r\n                  {\"method\": \"manually_set_baseline\", \"args\": [1850, 1900]}],\r\n  \"plotting\": {\"function\": \"neat_plot\", \"title\": \"Global mean temperature\"}\r\n }\r\n```\r\n\r\nThe entries say which other page the Card can `link_to` using the `id` of a page and what the `title` of the page should be. \r\n`selecting` specifies which subset of data you want to plot, with entries here corresponding to entries in the collection metadata. \r\n`processing` details the processing steps to be applied to each of the selected data sets, with `method` corresponding to a method in the \r\nrelevant data type (at the moment `TimeSeriesMonthly` or `TimeSeriesAnnual`) and `args` being the arguments to pass to the method. \r\n`plotting` specifies the function to the be used to plot the data (`neat_plot` being the standard type for annual plots) and can also \r\nbe used to pass additional arguments to the plot function. Plotting functions are found in `climind/plotters/plot_types.py`\r\n\r\nA Paragraph is similar to a Card, except the output is a paragraph of text. An entry looks something like:\r\n\r\n```\r\n{\r\n  \"selecting\": {\"type\": \"timeseries\", \"variable\": \"tas\", \"time_resolution\": \"monthly\"},\r\n  \"processing\": [{\"method\": \"rebaseline\", \"args\": [1981, 2010]},\r\n                  {\"method\": \"make_annual\", \"args\": []},\r\n                  {\"method\": \"select_year_range\", \"args\":  [1850,2021]},\r\n                  {\"method\": \"add_offset\", \"args\": [0.69]},\r\n                  {\"method\": \"manually_set_baseline\", \"args\": [1850, 1900]}],\r\n  \"writing\": {\"function\": \"anomaly_and_rank\"}\r\n}\r\n```\r\n\r\n`selecting` and `processing` behave as they did for Cards, `writing` is similar to `plotting` and produces the main output. Paragraph writers \r\nare found in `climind/stats/paragraphs.py`.\r\n\r\nOnce the dashboard metadata is complete, add an entry to `climind/scripts/build_dashboard.py` along the lines of:\r\n\r\n```\r\njson_file = ROOT_DIR / 'climind' / 'web' / 'dashboard_metadata' / 'new_dashboard.json'\r\ndash = Dashboard.from_json(json_file, METADATA_DIR)\r\n\r\ndash_dir = DATA_DIR / 'ManagedData' / 'NewDashboard'\r\ndash_dir.mkdir(exist_ok=True)\r\ndash.build(Path(dash_dir))\r\n```\r\n\r\nThe `json_file` is the dashboard metadata file. The `dash_dir` is the directory where you want to build the dashboard. `dash.build()` builds the dashboard.\r\n\r\nCalculating regional averages\r\n=============================\r\n\r\nRegional averages are calculated using `calculate_wmo_ra_averages.py`. This generates a large number of files containing regional averages based \r\non the gridded temperature data sets. This takes some time to run.\r\n\r\n`python calculate_wmo_ra_averages.py`\r\n\r\nDescriptive text\r\n================\r\n\r\nIn `climind/web/word_documents` there is a Word document that is used to generate text for the \r\nweb pages. The document is called `key_indicators_texts.docx`. This has descriptive text for \r\neach page on the key indicators dashboard as well as descriptions for each of the variables. \r\n\r\nwhen changes are made to the word document, these will need to be converted to html by navigating to `climind/web` and running\r\n\r\n`python extract_from_word.py`\r\n\r\nThe word document is structured using the inbuilt \"styles\".\r\n\r\nEach page in the dashboard can have an Introduction text. To do this, add a new `Heading1` style heading in the document \r\nwith text that matches the id of a page in the dashboard. You can then write `normal` style text beneath it. \r\nSubheadings can be added using `Heading2` style text followed by `normal` text. For example, the \"What the IPCC says\" \r\nsections. Hyperlinks can be added and these will be rendered in the webpages.\r\n\r\nIndividual variable descriptions can also be added here. The method is similar. A Heading1 style heading which matches \r\nthe `variable` name from the metadata file, followed by `normal` style text. Sub-headings do not work for variables. These \r\nare intended to be short descriptions of the variables.\r\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/jjk-code-otter/climate-indicator-manager",
    "keywords": "",
    "license": "GNU General Public License v3.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "Climind",
    "package_url": "https://pypi.org/project/Climind/",
    "platform": null,
    "project_url": "https://pypi.org/project/Climind/",
    "project_urls": {
      "Homepage": "https://github.com/jjk-code-otter/climate-indicator-manager"
    },
    "release_url": "https://pypi.org/project/Climind/0.1/",
    "requires_dist": [
      "pytest",
      "numpy",
      "requests",
      "beautifulsoup4",
      "pandas",
      "jsonschema",
      "matplotlib",
      "seaborn",
      "xarray",
      "python-dotenv",
      "regionmask",
      "geopandas",
      "shapely",
      "cdsapi",
      "cartopy",
      "cftime",
      "jinja2",
      "python-docx"
    ],
    "requires_python": "",
    "summary": "A python package for managing climate indicator information",
    "version": "0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 15996873,
  "releases": {
    "0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d08a7484b6fdbdd1ccc0e847c90ddaf3d1467c7fbc419737655d8275fb42311a",
          "md5": "7182608c85d7442e58c480d75aecb582",
          "sha256": "b8f1662c84d69a0693a00c280718189b5c769e870669e3583c25b7bc622df95e"
        },
        "downloads": -1,
        "filename": "Climind-0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "7182608c85d7442e58c480d75aecb582",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 218198,
        "upload_time": "2022-12-05T15:23:42",
        "upload_time_iso_8601": "2022-12-05T15:23:42.329678Z",
        "url": "https://files.pythonhosted.org/packages/d0/8a/7484b6fdbdd1ccc0e847c90ddaf3d1467c7fbc419737655d8275fb42311a/Climind-0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f5ae8f929cc63ff7026a02ffba8aaa5e44440098e251eb6615a5e1d1e2c94299",
          "md5": "ddf7bd2f96a48ebab7e0abb1875fca37",
          "sha256": "93c78f8dfc2d74f10bd3a3548b32712f442f79d72573b8b6529bc95fac94090b"
        },
        "downloads": -1,
        "filename": "Climind-0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "ddf7bd2f96a48ebab7e0abb1875fca37",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 121772,
        "upload_time": "2022-12-05T15:23:45",
        "upload_time_iso_8601": "2022-12-05T15:23:45.086893Z",
        "url": "https://files.pythonhosted.org/packages/f5/ae/8f929cc63ff7026a02ffba8aaa5e44440098e251eb6615a5e1d1e2c94299/Climind-0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "d08a7484b6fdbdd1ccc0e847c90ddaf3d1467c7fbc419737655d8275fb42311a",
        "md5": "7182608c85d7442e58c480d75aecb582",
        "sha256": "b8f1662c84d69a0693a00c280718189b5c769e870669e3583c25b7bc622df95e"
      },
      "downloads": -1,
      "filename": "Climind-0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "7182608c85d7442e58c480d75aecb582",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 218198,
      "upload_time": "2022-12-05T15:23:42",
      "upload_time_iso_8601": "2022-12-05T15:23:42.329678Z",
      "url": "https://files.pythonhosted.org/packages/d0/8a/7484b6fdbdd1ccc0e847c90ddaf3d1467c7fbc419737655d8275fb42311a/Climind-0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "f5ae8f929cc63ff7026a02ffba8aaa5e44440098e251eb6615a5e1d1e2c94299",
        "md5": "ddf7bd2f96a48ebab7e0abb1875fca37",
        "sha256": "93c78f8dfc2d74f10bd3a3548b32712f442f79d72573b8b6529bc95fac94090b"
      },
      "downloads": -1,
      "filename": "Climind-0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "ddf7bd2f96a48ebab7e0abb1875fca37",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 121772,
      "upload_time": "2022-12-05T15:23:45",
      "upload_time_iso_8601": "2022-12-05T15:23:45.086893Z",
      "url": "https://files.pythonhosted.org/packages/f5/ae/8f929cc63ff7026a02ffba8aaa5e44440098e251eb6615a5e1d1e2c94299/Climind-0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}