{
  "info": {
    "author": "Daniel Saromo",
    "author_email": "danielsaromo@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Auto-Rotating Perceptrons (ARP)\n\nThis repository contains the Keras implementation of the Auto-Rotating Perceptrons (Saromo, Villota, and Villanueva) for dense layers of artificial neural networks. These neural units were presented in [this paper](https://arxiv.org/abs/1910.02483) with an [oral exposition](https://slideslive.com/38922594/autorotating-perceptrons) at the [LXAI workshop](https://nips.cc/Conferences/2019/Schedule?showEvent=15988) at [NeurIPS 2019](https://neurips.cc/Conferences/2019).\n\nThe ARP library was developed by [Daniel Saromo](https://www.danielsaromo.xyz/) and [Matias Valdenegro-Toro](https://mvaldenegro.github.io/). This repository contains implementations that are not present in the [LXAI @ NeurIPS 2019 paper](https://arxiv.org/abs/1910.02483).\n\n## What is an Auto-Rotating Perceptron? \nThe ARP are a generalization of the perceptron unit that aims to avoid the vanishing gradient problem by making the activation function's input near zero, without altering the inference structure learned by the perceptron.\n\n| Classic perceptron | Auto-Rotating Perceptron | \n| --- | --- |\n| <img src=\"https://www.danielsaromo.xyz/assets/img/neuronas_classic.svg\" height=\"200\"> | <img src=\"https://www.danielsaromo.xyz/assets/img/neuronas_ARP.svg\" height=\"200\"> | \n\n[comment]: <> (render en svg y embed en HTML: https://stackoverflow.com/questions/11256433/how-to-show-math-equations-in-general-githubs-markdownnot-githubs-blog)\n[comment]: <> (https://stackoverflow.com/questions/47344571/how-to-draw-checkbox-or-tick-mark-in-github-markdown-table)\n\nHence, a classic perceptron becomes the particular case of an ARP with `rho=1`.\n\n### Basic principle: The dynamic region\n\nWe define the *dynamic region* as the symmetric numerical range (w.r.t. `0`) from where we would like the pre-activation values to come from in order to avoid node saturation. Recall that, in order to avoid the vanishing gradient problem (VGP), we do not want the derivative of the activation function to take tiny values. For the ARP, the dynamic region goes from `-L` to `+L`.\n\nFor example, in the unipolar sigmoid activation function (logistic curve) shown below, we would like it to receive values from `-4` to `4`. For inputs whose absolute values are higher than `4`, the derivative of the activation is too low. Hence, the `L` value could be `4`. The resulting *dynamic region* projected on the derivative curve is depicted as a gray shade.\n\n<img src=\"https://www.danielsaromo.xyz/assets/img/sigmoid_and_deriv.jpg\" height=\"300\">\n\n### What is `L`?\n\n`L` is the hyperparameter that defines the limits of the desired symmetric *dynamic region*.\n\n### How do I choose `L`?\n\nYou need to analyze the activation function and its derivative. For the dynamic region, there is a trade-off. For a bigger `L`, you accept more non-linearity for the activation function, but at the same time, you get more saturation.\n\nBelow you have the suggested values for `L`, according to the activation function of the neuron:\n\n| Activation function | `L` | \n|:-:|:-:|\n| tanh           | 2         |\n| sigmoid        | 4         |\n| arctan         | 7         |\n\nIn the figure below, you can see that for inputs whose absolute values are higher than the values from the table, the derivative of the activation functions is very small.\n\n<img src=\"https://www.danielsaromo.xyz/assets/img/saturated_activations.jpg\" height=\"300\">\n\n### What about `xQ`?\n\nIn the [original ARP paper](https://arxiv.org/abs/1910.02483), you needed to set this value manually. Currently, by default, `xQ` is automatically calculated using `L`. However, the ARP library supports a custom selection of the `xQ` value.\n\nA deeper explanation can be found in the journal version of the ARP paper (in preparation).\n\n### ARP Vs. Classic perceptrons\n\nAs shown in the example notebook (`examples/example_CIFAR10_Keras.ipynb`) that compares ARP and classic perceptrons, the ARP can lead to a faster convergence and lower loss values.\n\nFurthermore, there is an application of the ARP to calibrate a wearable sensor where the test loss was reduced by a factor of 15 when changing from classic perceptrons to ARP. You can check the paper [here](https://www.danielsaromo.xyz/publications/#SSC_with_ARP).\n\nIn machine learning, the advantages of using one technique or another are problem-dependant. We encourage you to apply ARP in your research and discover its potential.\n\n\n## Keras implementation\n\n### Instalation\n\nThe ARP library is available on the [Python Package Index](https://pypi.org/project/arpkeras/ \"ARP Keras page on PyPI\").\nTo install the library, first install `pip` and then use the following command:\n\n```python\npip install arpkeras\n```\n\nYou may need to update the `pip` manager. You can use:\n```python\npython -m pip install â€“upgrade pip\n```\n\n### Import\n\n```python\nfrom ARPkeras import AutoRotDense\n```\n\n### Creating an ARP model\n\nThe `AutoRotDense` class implementation inherits from the Keras `Dense` class. Hence, you can use it as a typical Keras `Dense` layer, but adding the following arguments:\n\n- `xmin_lim`: The lower limit of the values that will enter the neuron. For example, if we scale our input data to the range `0` to `1`, and we choose `tanh` as the activation function (which goes from `-1` to `+1`), then the lowest input value will be `xmin_lim=-1`.\n- `xmax_lim`: The upper limit of the values that will enter the neuron. Analogous to `xmin_lim`.\n- `L` : The limit of the desired symmetrical *dynamic region*. This value is the **only hyperparameter** needed for the Auto-Rotating layers. The two variables described above depend on the activation function you choose and your data preprocessing.\n\nThis is an example of use for the unipolar `'sigmoid'` activation (whose output goes from `0` to `+1`) with data scaled to the range `0` to `1`:\n\n```python\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom ARPkeras import AutoRotDense\n\nxmin_lim = 0   # min( 0,0)\nxmax_lim = 1   # max(+1,1)\nL = 4\n\nmodel = Sequential()\nmodel.add(Dense(20), input_shape=(123,))\nmodel.add(AutoRotDense(10, xmin_lim=xmin_lim, xmax_lim=xmax_lim, L=L, activation='sigmoid'))\n#By default the `AutoRot` flag of the Auto-Rotating layers is True.\n\nmodel.summary()\n```\n\nThis is another example, when using the `'tanh'` activation (whose output goes from `-1` to `+1`) with data scaled to the range `0` to `1`:\n\n```python\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom ARPkeras import AutoRotDense\n\nxmin_lim = -1   # min(-1,0)\nxmax_lim = +1   # max(+1,1)\nL = 7\n\nmodel = Sequential()\nmodel.add(AutoRotDense(20, input_shape=(123,), xmin_lim=xmin_lim, xmax_lim=xmax_lim, L=L, activation='tanh'))\nmodel.add(AutoRotDense(10, xmin_lim, xmax_lim, L, activation='tanh'))\n#By default the `AutoRot` flag of the Auto-Rotating layers is True.\n\nmodel.summary()\n```\n\n### Beyond `Dense` layers\n\nIs that all for the ARP? No! The journal version of the ARP paper is being finished, with the support of Dr. Edwin Villanueva and Dr. Matias Valdenegro-Toro. There, the Auto-Rotating concept was extrapolated to other layer types, creating the **Auto-Rotating Neural Networks**.\n\nThese are the Keras layers implemented with the Auto-Rotating operation (**Tip**: Just add `AutoRot` before the layer name):\n\n| Keras Original Layer    | Auto-Rotating Implementation | \n|:-:|:-:|\n| `Dense`               | `AutoRotDense`              |\n| `SimpleRNN`           | `AutoRotSimpleRNN`          |\n| `LSTM`                | `AutoRotLSTM`               |\n| `GRU`                 | `AutoRotGRU`                |\n| `Conv1D`              | `AutoRotConv1D`             |\n| `Conv2D`              | `AutoRotConv2D`             |\n| `Conv3D`              | `AutoRotConv3D`             |\n| `Conv2DTranspose`     | `AutoRotConv2DTranspose`    |\n| `Conv3DTranspose`     | `AutoRotConv3DTranspose`    |\n| `SeparableConv`       | `AutoRotSeparableConv`      |\n| `SeparableConv1D`     | `AutoRotSeparableConv1D`    |\n| `SeparableConv2D`     | `AutoRotSeparableConv2D`    |\n| `DepthwiseConv2D`     | `AutoRotDepthwiseConv2D`    |\n\nComing soon :sunglasses:: **Auto-Rotating Neural Networks** (Saromo, Villanueva, and Valdenegro-Toro).\n\n## Citation\n\n[comment]: <> (We hope this code and our paper can help researchers, scientists, and engineers to improve the use and design of Auto-Rotating models that have potentially exciting applications in deep learning.)\n\nThis code is free to use for research purposes, and if used or modified in any way, please consider citing:\n\n```\n@article{saromo2019arp,\n  title={{A}uto-{R}otating {P}erceptrons},\n  author={Saromo, Daniel and Villota, Elizabeth and Villanueva, Edwin},\n  journal={LatinX in AI Workshop at NeurIPS 2019 (arXiv:1910.02483)},\n  year={2019}\n}\n```\n\nOther inquiries: daniel.saromo@pucp.pe\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/DanielSaromo/ARP",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "arpkeras",
    "package_url": "https://pypi.org/project/arpkeras/",
    "platform": "",
    "project_url": "https://pypi.org/project/arpkeras/",
    "project_urls": {
      "Homepage": "https://github.com/DanielSaromo/ARP"
    },
    "release_url": "https://pypi.org/project/arpkeras/1.0.0/",
    "requires_dist": null,
    "requires_python": ">=3",
    "summary": "Auto-Rotating Perceptron implementation for Keras.",
    "version": "1.0.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 9840262,
  "releases": {
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "70faccf375c44a12b9a59ab0283bce95ee3a3152a5f4436e9c3a85ef19a492e2",
          "md5": "2dbc1f1040528ea89dc26e0c76debbe2",
          "sha256": "2c20ebc263e73f3dde22e727304a14df666c59e9d0e540d7ad5238df13153f2c"
        },
        "downloads": -1,
        "filename": "arpkeras-1.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "2dbc1f1040528ea89dc26e0c76debbe2",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3",
        "size": 12541,
        "upload_time": "2021-03-22T04:18:41",
        "upload_time_iso_8601": "2021-03-22T04:18:41.415054Z",
        "url": "https://files.pythonhosted.org/packages/70/fa/ccf375c44a12b9a59ab0283bce95ee3a3152a5f4436e9c3a85ef19a492e2/arpkeras-1.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1e675b83e6d79d37e2939edba11e92e2e0660f0d540dcc4717dc27814daa2b6d",
          "md5": "1360e0bf3fffb550654fb863c9067459",
          "sha256": "11056434357015768e71f04e7b14f1156a66d35ba8559b8732dc7ec793f25002"
        },
        "downloads": -1,
        "filename": "arpkeras-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "1360e0bf3fffb550654fb863c9067459",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3",
        "size": 7089,
        "upload_time": "2021-03-22T04:18:42",
        "upload_time_iso_8601": "2021-03-22T04:18:42.535936Z",
        "url": "https://files.pythonhosted.org/packages/1e/67/5b83e6d79d37e2939edba11e92e2e0660f0d540dcc4717dc27814daa2b6d/arpkeras-1.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "70faccf375c44a12b9a59ab0283bce95ee3a3152a5f4436e9c3a85ef19a492e2",
        "md5": "2dbc1f1040528ea89dc26e0c76debbe2",
        "sha256": "2c20ebc263e73f3dde22e727304a14df666c59e9d0e540d7ad5238df13153f2c"
      },
      "downloads": -1,
      "filename": "arpkeras-1.0.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "2dbc1f1040528ea89dc26e0c76debbe2",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3",
      "size": 12541,
      "upload_time": "2021-03-22T04:18:41",
      "upload_time_iso_8601": "2021-03-22T04:18:41.415054Z",
      "url": "https://files.pythonhosted.org/packages/70/fa/ccf375c44a12b9a59ab0283bce95ee3a3152a5f4436e9c3a85ef19a492e2/arpkeras-1.0.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "1e675b83e6d79d37e2939edba11e92e2e0660f0d540dcc4717dc27814daa2b6d",
        "md5": "1360e0bf3fffb550654fb863c9067459",
        "sha256": "11056434357015768e71f04e7b14f1156a66d35ba8559b8732dc7ec793f25002"
      },
      "downloads": -1,
      "filename": "arpkeras-1.0.0.tar.gz",
      "has_sig": false,
      "md5_digest": "1360e0bf3fffb550654fb863c9067459",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3",
      "size": 7089,
      "upload_time": "2021-03-22T04:18:42",
      "upload_time_iso_8601": "2021-03-22T04:18:42.535936Z",
      "url": "https://files.pythonhosted.org/packages/1e/67/5b83e6d79d37e2939edba11e92e2e0660f0d540dcc4717dc27814daa2b6d/arpkeras-1.0.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}