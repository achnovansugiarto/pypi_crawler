{
  "info": {
    "author": "Dani El-Ayyass",
    "author_email": "dayyass@yandex.ru",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "[![tests](https://github.com/dayyass/latent-semantic-analysis/actions/workflows/tests.yml/badge.svg)](https://github.com/dayyass/latent-semantic-analysis/actions/workflows/tests.yml)\n[![linter](https://github.com/dayyass/latent-semantic-analysis/actions/workflows/linter.yml/badge.svg)](https://github.com/dayyass/latent-semantic-analysis/actions/workflows/linter.yml)\n[![codecov](https://codecov.io/gh/dayyass/latent-semantic-analysis/branch/main/graph/badge.svg?token=Y39Q5786DL)](https://codecov.io/gh/dayyass/latent-semantic-analysis)\n\n[![python 3.6](https://img.shields.io/badge/python-3.6-blue.svg)](https://github.com/dayyass/latent-semantic-analysis#requirements)\n[![release (latest by date)](https://img.shields.io/github/v/release/dayyass/latent-semantic-analysis)](https://github.com/dayyass/latent-semantic-analysis/releases/latest)\n[![license](https://img.shields.io/github/license/dayyass/latent-semantic-analysis?color=blue)](https://github.com/dayyass/latent-semantic-analysis/blob/main/LICENSE)\n\n[![pre-commit](https://img.shields.io/badge/pre--commit-enabled-black)](https://github.com/dayyass/latent-semantic-analysis/blob/main/.pre-commit-config.yaml)\n[![code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n\n[![pypi version](https://img.shields.io/pypi/v/latent-semantic-analysis)](https://pypi.org/project/latent-semantic-analysis)\n[![pypi downloads](https://img.shields.io/pypi/dm/latent-semantic-analysis)](https://pypi.org/project/latent-semantic-analysis)\n\n### Latent Semantic Analysis\nPipeline for training **LSA** models using Scikit-Learn.\n\n### Usage\nInstead of writing custom code for latent semantic analysis, you just need:\n1. install pipeline:\n```shell script\npip install latent-semantic-analysis\n```\n2. run pipeline:\n- either in **terminal**:\n```shell script\nlsa-train --path_to_config config.yaml\n```\n- or in **python**:\n```python3\nimport latent_semantic_analysis\n\nlatent_semantic_analysis.train(path_to_config=\"config.yaml\")\n```\n\n**NOTE**: more about config file [here](https://github.com/dayyass/latent-semantic-analysis/tree/main#config).\n\nNo data preparation is needed, only a **csv** file with raw text column (with arbitrary name).\n\n#### Config\nThe user interface consists of only one files:\n- [**config.yaml**](https://github.com/dayyass/latent-semantic-analysis/blob/main/config.yaml) - general configuration with sklearn **TF-IDF** and **SVD** parameters\n\nChange **config.yaml** to create the desired configuration and train LSA model with the following command:\n- **terminal**:\n```shell script\nlsa-train --path_to_config config.yaml\n```\n- **python**:\n```python3\nimport latent_semantic_analysis\n\nlatent_semantic_analysis.train(path_to_config=\"config.yaml\")\n```\n\nDefault **config.yaml**:\n```yaml\nseed: 42\npath_to_save_folder: models\n\n# data\ndata:\n  data_path: data/data.csv\n  sep: ','\n  text_column: text\n\n# tf-idf\ntf-idf:\n  lowercase: true\n  ngram_range: (1, 1)\n  max_df: 1.0\n  min_df: 1\n\n# svd\nsvd:\n  n_components: 10\n  algorithm: arpack\n```\n\n**NOTE**: `tf-idf` and `svd` are sklearn [**TfidfVectorizer**](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html?highlight=tfidf#sklearn.feature_extraction.text.TfidfVectorizer) and [**TruncatedSVD**](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html) parameters correspondingly, so you can parameterize instances of these classes however you want.\n\n#### Output\nAfter training the model, the pipeline will return the following files:\n- `model.joblib` - sklearn pipeline with LSA (TF-IDF and SVD steps)\n- `config.yaml` - config that was used to train the model\n- `logging.txt` - logging file\n- `doc2topic.json` - document embeddings\n- `term2topic.json` - term embeddings\n\n### Requirements\nPython >= 3.6\n\n### Citation\nIf you use **latent-semantic-analysis** in a scientific publication, we would appreciate references to the following BibTex entry:\n```bibtex\n@misc{dayyass2021lsa,\n    author       = {El-Ayyass, Dani},\n    title        = {Pipeline for training LSA models},\n    howpublished = {\\url{https://github.com/dayyass/latent-semantic-analysis}},\n    year         = {2021}\n}\n```\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/dayyass/latent-semantic-analysis",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "latent-semantic-analysis",
    "package_url": "https://pypi.org/project/latent-semantic-analysis/",
    "platform": "",
    "project_url": "https://pypi.org/project/latent-semantic-analysis/",
    "project_urls": {
      "Bug Tracker": "https://github.com/dayyass/latent-semantic-analysis/issues",
      "Homepage": "https://github.com/dayyass/latent-semantic-analysis"
    },
    "release_url": "https://pypi.org/project/latent-semantic-analysis/0.1.0/",
    "requires_dist": [
      "numpy (>=1.19.5)",
      "pandas (>=1.1.5)",
      "PyYAML (>=5.4.1)",
      "scikit-learn (>=0.24.2)",
      "scipy (>=1.5.4)"
    ],
    "requires_python": ">=3.6",
    "summary": "Pipeline for training LSA models using Scikit-Learn.",
    "version": "0.1.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 11668793,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "28fb6bc524b2d2abc2ba57039e8ce02fd8f40845c0f242c9ef67591b0b67c1bc",
          "md5": "b54e6973ce6c0abc43757e4863e02451",
          "sha256": "6951542da4b005ced22dde0f8611fbdb59a9ebe4cc773a73bf7ed322f401c64c"
        },
        "downloads": -1,
        "filename": "latent_semantic_analysis-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "b54e6973ce6c0abc43757e4863e02451",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 10119,
        "upload_time": "2021-10-08T19:54:45",
        "upload_time_iso_8601": "2021-10-08T19:54:45.713718Z",
        "url": "https://files.pythonhosted.org/packages/28/fb/6bc524b2d2abc2ba57039e8ce02fd8f40845c0f242c9ef67591b0b67c1bc/latent_semantic_analysis-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "24060548a0ebae5d68812e3dba2396aa26967ae400e9a8dd123dd87db5fd245d",
          "md5": "d80add95b162861e06e13ef098025e53",
          "sha256": "c7fda93d959bb33fe6ef1814da4f33ff898687a603218617370a35adae6373e4"
        },
        "downloads": -1,
        "filename": "latent-semantic-analysis-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "d80add95b162861e06e13ef098025e53",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 6878,
        "upload_time": "2021-10-08T19:54:48",
        "upload_time_iso_8601": "2021-10-08T19:54:48.688845Z",
        "url": "https://files.pythonhosted.org/packages/24/06/0548a0ebae5d68812e3dba2396aa26967ae400e9a8dd123dd87db5fd245d/latent-semantic-analysis-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "28fb6bc524b2d2abc2ba57039e8ce02fd8f40845c0f242c9ef67591b0b67c1bc",
        "md5": "b54e6973ce6c0abc43757e4863e02451",
        "sha256": "6951542da4b005ced22dde0f8611fbdb59a9ebe4cc773a73bf7ed322f401c64c"
      },
      "downloads": -1,
      "filename": "latent_semantic_analysis-0.1.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "b54e6973ce6c0abc43757e4863e02451",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 10119,
      "upload_time": "2021-10-08T19:54:45",
      "upload_time_iso_8601": "2021-10-08T19:54:45.713718Z",
      "url": "https://files.pythonhosted.org/packages/28/fb/6bc524b2d2abc2ba57039e8ce02fd8f40845c0f242c9ef67591b0b67c1bc/latent_semantic_analysis-0.1.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "24060548a0ebae5d68812e3dba2396aa26967ae400e9a8dd123dd87db5fd245d",
        "md5": "d80add95b162861e06e13ef098025e53",
        "sha256": "c7fda93d959bb33fe6ef1814da4f33ff898687a603218617370a35adae6373e4"
      },
      "downloads": -1,
      "filename": "latent-semantic-analysis-0.1.0.tar.gz",
      "has_sig": false,
      "md5_digest": "d80add95b162861e06e13ef098025e53",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 6878,
      "upload_time": "2021-10-08T19:54:48",
      "upload_time_iso_8601": "2021-10-08T19:54:48.688845Z",
      "url": "https://files.pythonhosted.org/packages/24/06/0548a0ebae5d68812e3dba2396aa26967ae400e9a8dd123dd87db5fd245d/latent-semantic-analysis-0.1.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}