{
  "info": {
    "author": "Ulf Hamster",
    "author_email": "554c46@gmail.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "|PyPI version| |DOI| |Total alerts| |Language grade: Python|\n\ntorch-multilabel-embedding\n==========================\n\nThe package contains a TensorFlow2/Keras class to train an Embedding\nmatrix for multi-label inputs, i.e. instead of 1 ID per token (one hot\nencoding), N IDs per token can be provided as model input.\n\nAn TensorFlow2/Keras implementation can be found here:\nhttps://github.com/ulf1/keras-multilabel-embedding\n(``pip install keras-multilabel-embedding``)\n\nUsage\n-----\n\n.. code:: py\n\n   import torch_multilabel_embedding as tml\n   import torch\n\n   # a sequence of multi-label data points\n   x_ids = [[1, 2, 4], [0, 1, 2], [2, 1, 4], [3, 2, 1]]\n   x_ids = torch.tensor(x_ids)\n\n   # initialize layer\n   layer = tml.MultiLabelEmbedding(\n       vocab_size=5, embed_size=300, random_state=42)\n\n   # predict\n   y = layer(x_ids)\n\nAppendix\n--------\n\nInstallation\n~~~~~~~~~~~~\n\nThe ``torch-multilabel-embedding`` `git\nrepo <http://github.com/ulf1/torch-multilabel-embedding>`__ is available\nas `PyPi\npackage <https://pypi.org/project/torch-multilabel-embedding>`__\n\n.. code:: sh\n\n   pip install torch-multilabel-embedding\n   pip install git+ssh://git@github.com/ulf1/torch-multilabel-embedding.git\n\nInstall a virtual environment\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. code:: sh\n\n   python3 -m venv .venv\n   source .venv/bin/activate\n   pip install --upgrade pip\n   pip install -r requirements.txt --no-cache-dir\n   pip install -r requirements-dev.txt --no-cache-dir\n   pip install -r requirements-demo.txt --no-cache-dir\n\n(If your git repo is stored in a folder with whitespaces, then don’t use\nthe subfolder ``.venv``. Use an absolute path without whitespaces.)\n\nPython commands\n~~~~~~~~~~~~~~~\n\n-  Jupyter for the examples: ``jupyter lab``\n-  Check syntax:\n   ``flake8 --ignore=F401 --exclude=$(grep -v '^#' .gitignore | xargs | sed -e 's/ /,/g')``\n-  Run Unit Tests: ``PYTHONPATH=. pytest``\n\nPublish\n\n.. code:: sh\n\n   pandoc README.md --from markdown --to rst -s -o README.rst\n   python setup.py sdist \n   twine upload -r pypi dist/*\n\nClean up\n~~~~~~~~\n\n.. code:: sh\n\n   find . -type f -name \"*.pyc\" | xargs rm\n   find . -type d -name \"__pycache__\" | xargs rm -r\n   rm -r .pytest_cache\n   rm -r .venv\n\nSupport\n~~~~~~~\n\nPlease `open an\nissue <https://github.com/ulf1/torch-multilabel-embedding/issues/new>`__\nfor support.\n\nContributing\n~~~~~~~~~~~~\n\nPlease contribute using `Github\nFlow <https://guides.github.com/introduction/flow/>`__. Create a branch,\nadd commits, and `open a pull\nrequest <https://github.com/ulf1/torch-multilabel-embedding/compare/>`__.\n\n.. |PyPI version| image:: https://badge.fury.io/py/torch-multilabel-embedding.svg\n   :target: https://badge.fury.io/py/torch-multilabel-embedding\n.. |DOI| image:: https://zenodo.org/badge/394390178.svg\n   :target: https://zenodo.org/badge/latestdoi/394390178\n.. |Total alerts| image:: https://img.shields.io/lgtm/alerts/g/ulf1/torch-multilabel-embedding.svg?logo=lgtm&logoWidth=18\n   :target: https://lgtm.com/projects/g/ulf1/torch-multilabel-embedding/alerts/\n.. |Language grade: Python| image:: https://img.shields.io/lgtm/grade/python/g/ulf1/torch-multilabel-embedding.svg?logo=lgtm&logoWidth=18\n   :target: https://lgtm.com/projects/g/ulf1/torch-multilabel-embedding/context:python\n\n\n",
    "description_content_type": "",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "http://github.com/ulf1/torch-multilabel-embedding",
    "keywords": "",
    "license": "Apache License 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "torch-multilabel-embedding",
    "package_url": "https://pypi.org/project/torch-multilabel-embedding/",
    "platform": "",
    "project_url": "https://pypi.org/project/torch-multilabel-embedding/",
    "project_urls": {
      "Homepage": "http://github.com/ulf1/torch-multilabel-embedding"
    },
    "release_url": "https://pypi.org/project/torch-multilabel-embedding/0.1.1/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "Training of multi-label embeddings for k-shingled input sequences for PyTorch.",
    "version": "0.1.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 13042777,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9663c2091a2d9dea3683a9230f70b7fa092da79ed17959ce3c951b779ee56f7f",
          "md5": "6cda34bf5d9b0bd4b4608f9b9c10ce18",
          "sha256": "6ca74d0c036671236a7f8d2585bcb2d1f26a6d8694381ec448138c0e3e49a8eb"
        },
        "downloads": -1,
        "filename": "torch-multilabel-embedding-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "6cda34bf5d9b0bd4b4608f9b9c10ce18",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 7620,
        "upload_time": "2022-02-27T16:53:30",
        "upload_time_iso_8601": "2022-02-27T16:53:30.508881Z",
        "url": "https://files.pythonhosted.org/packages/96/63/c2091a2d9dea3683a9230f70b7fa092da79ed17959ce3c951b779ee56f7f/torch-multilabel-embedding-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "071556bdb3fc8575ae45b3e82dfc0e433d5fe1cd4df20b55d07ce169b426fe10",
          "md5": "4160995ca14441be661c2b9a13e26b64",
          "sha256": "3c7c4b7e4786582aed136bbd303daf512b408ee454af17aa402f4225fbd7c8ce"
        },
        "downloads": -1,
        "filename": "torch-multilabel-embedding-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "4160995ca14441be661c2b9a13e26b64",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 7729,
        "upload_time": "2022-03-01T08:29:48",
        "upload_time_iso_8601": "2022-03-01T08:29:48.140381Z",
        "url": "https://files.pythonhosted.org/packages/07/15/56bdb3fc8575ae45b3e82dfc0e433d5fe1cd4df20b55d07ce169b426fe10/torch-multilabel-embedding-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "071556bdb3fc8575ae45b3e82dfc0e433d5fe1cd4df20b55d07ce169b426fe10",
        "md5": "4160995ca14441be661c2b9a13e26b64",
        "sha256": "3c7c4b7e4786582aed136bbd303daf512b408ee454af17aa402f4225fbd7c8ce"
      },
      "downloads": -1,
      "filename": "torch-multilabel-embedding-0.1.1.tar.gz",
      "has_sig": false,
      "md5_digest": "4160995ca14441be661c2b9a13e26b64",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 7729,
      "upload_time": "2022-03-01T08:29:48",
      "upload_time_iso_8601": "2022-03-01T08:29:48.140381Z",
      "url": "https://files.pythonhosted.org/packages/07/15/56bdb3fc8575ae45b3e82dfc0e433d5fe1cd4df20b55d07ce169b426fe10/torch-multilabel-embedding-0.1.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}