{
  "info": {
    "author": "Eleven",
    "author_email": "eleven_1111@outlook.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: Implementation",
      "Topic :: Software Development :: Libraries"
    ],
    "description": "# Fastorch\n\n[Pytorch](https://github.com/pytorch/pytorch) is convenient and easy to use, while [Keras](https://github.com/keras-team/keras) is designed to experiment quickly. Do you want to possess **both** Pytorch's convenience and Keras'  fast experimentation? The answer is *fastorch.*\n\n\n\n## Traditional classification task training flow in pytorch\n\n```python\n################################# import dependencies ###############################\nimport torch.nn as nn\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n\n################################# define your network ###############################\nclass network(nn.Module):\n    def __init__(self):\n        super(network, self).__init__()\n        self.fc = nn.Sequential(\n            nn.Linear(1000, 500),\n            nn.ReLU(True),\n            nn.Linear(500, 500),\n            nn.ReLU(True),\n            nn.Linear(500, 500),\n            nn.ReLU(True),\n            nn.Linear(500, 500),\n            nn.ReLU(True),\n            nn.Linear(500, 100),\n            nn.ReLU(True),\n            nn.Linear(100, 100),\n            nn.ReLU(True),\n            nn.Linear(100, 10),\n        )\n\n    def forward(self, x):\n        return self.fc(x)\n\n################################## prepare dataset ##################################\nclass mydataset(Dataset):\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n\n    def __getitem__(self, item):\n        return self.x[item], self.y[item]\n\n    def __len__(self):\n        return self.x.size(0)\n# for simplicity, randomly generate datas, \nX = torch.randn(5000, 1000)\nY = torch.randint(0, 10, size=(5000,))\nBATCH_SIZE = 100\ntrainset = mydataset(X, Y)\ntrain_loader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n\n########################### assign optimizer and criterion ##########################\noptimizer = torch.optim.SGD(net.parameters(), lr=0.01)\ncriterion = nn.CrossEntropyLoss()\n\n############################## define and run training ##############################\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nEPOCH = 10\nnet = network().to(device)\nfor epoch in range(EPOCH):\n    for x, y in train_loader:\n        x, y = x.to(device), y.to(device)\n        optimizer.zero_grad()\n        out = net(x)\n        loss = criterion(out, y)\n        loss.backward()\n        optimizer.step()\n        print('Epoch %d -> loss: %.4f' % (epoch, loss.item()))\n\n```\n\nIt's simple and straightforward, but is that enough? Below gives **fastorch resolution.**\n\n\n\n## Training with fastorch\n\n```python\n################################# import dependencies ###############################\nimport torch\nimport fastorch\n\n################################# define your network ###############################\n'''\ninherit from fastorch in your own network\n'''\nclass network(fastorch.models.Model):\n    def __init__(self):\n        super(network, self).__init__()\n        self.fc = nn.Sequential(\n            nn.Linear(1000, 500),\n            nn.ReLU(True),\n            nn.Linear(500, 500),\n            nn.ReLU(True),\n            nn.Linear(500, 500),\n            nn.ReLU(True),\n            nn.Linear(500, 500),\n            nn.ReLU(True),\n            nn.Linear(500, 100),\n            nn.ReLU(True),\n            nn.Linear(100, 100),\n            nn.ReLU(True),\n            nn.Linear(100, 10),\n        )\n\n    def forward(self, x):\n        return self.fc(x)\n\n################################## prepare dataset ##################################\n# for simplicity, randomly generate datas, \nX = torch.randn(5000, 1000)\nY = torch.randint(0, 10, size=(5000,))\n\n#################################### run training ###################################\nnet = network()\nnet.fit(x=X, y=Y, optimizer='sgd', criterion='cross_entropy', batch_size=BATCH_SIZE, epochs=1, verbose=1)\n'''\nEpoch[1/1]\n 2100/5000 [========>***********] - 1s - 68ms/batch -batch_loss: 2.2993 -batch_acc: 0.1200\n'''\n```\n\n\n\n## Installation\n\nBefore installing Fastorch, please install the following **dependencies**:\n\n- python >= 3.0 (3.6 is recommend)\n- pytorch (1.0+ is recommend)\n\nThen you can install Fastorchby using pip:\n\n```\n$ pip install fastorch\n```\n\n\n\n## Supports\n\nWhen using `fastorch.models.Model`, make sure your network is **inherited** from `fastorch.models.Model`.\n\n### - fastorch.models.Model\n\n**fit**(*train_dataset*=None, *x*=None, *y*=None, *optimizer*=None, *criterion*=None, *transform*=None, *batch_size*=None, *epochs*=1, *verbose*=1, *print_acc*=True, *callbacks*=None, *validation_dataset*=None, *validation_split*=0.0, *validation_data*=None, *validation_transform*=None, *shuffle*=True, *initial_epoch*=0, *steps_per_epoch*=None, *device*=None, **kwargs)\n\n+ *train_dataset*: training dataset, which inherited from `torch.utils.data.Dataset`. Make sure *x* and *y* are not None when *train_dataset* is None.\n+ *x*: training data, it can be `Tensor`銆乣ndarray` or `List`. You need pass *x* and *y* when *train_dataset* is None.\n+ *y*: training target, it can be `Tensor`銆乣ndarray` or `List`. You need pass *x* and *y* when *train_dataset* is None.\n+ *optimizer*: model optimizer, it can be `str` or an instance of `pytorch optimizer`, when passing str('sgd', 'adam'), fastorch will automatically declare the corresponding pytorch optimizer.\n+ *criterion*: loss function, it can be `str` or an instance of `pytorch objective function  `, when passing str('mse', 'cross_entropy', etc.), fastorch will automatically declare the corresponding pytorch objective function .\n+ transform:  applying `torchvision.transforms` on *x* and *y* or *train_dataset*.\n+ *batch_size*: training batch_size,  default is 32 if not specified.\n+ *epochs*: training stop epochs, default is 1 if not specified.\n+ *verbose*: log display mode, 0 = silent, 1 = progress bar, 2 = print each line.\n+ *print_acc*: True or False, passing True if you are doing classification task.\n+ *callbacks*: waiting for implemented.\n+ *validation_dataset*:  validation dataset, which inherited from `torch.utils.data.Dataset`. \n+ *validation_split*: split validation data from training data's ratio, make sure *x* and *y* are not None when using this argument.\n+ *validation_data*: tuple of validation x and validation y.\n+ *validation_transform*:  applying `torchvision.transforms` on *validation_data* or data split by *validation_split*.\n+ *shuffle*: whether shuffle the training data.\n+ *initial_epoch*: start training epoch.\n+ *steps_per_epoch*: int or None, if specified, batch_size will be set as total_sample_nums / *steps_per_epoch*.\n+ *device*: specify device, otherwise fastorch will set device according to `torch.cuda.is_available()`.\n+ **kwargs: arguments used for `torch.utils.data.Dataloader`, etc.\n\n\n\n**evaluate**(*dataset*=None, *dataloader*=None, *x*=None, *y*=None, *transform*=None, *batch_size*=None, *verbose*=1, *criterion*=None, *print_acc*=True, *steps*=None, *device*=None, **kwargs)\n\n+ *dataset*: evaluate dataset, which inherited from `torch.utils.data.Dataset`. Make sure *dataloader* or  *x* and *y* are not None when *dataset*is None.\n\n+ *dataloader*: evaluate dataloader, which inherited from `torch.utils.data.Dataloader`. Make sure *dataset*or  *x* and *y* are not None when *dataloader*is None.\n\n+ *x*: test data, it can be `Tensor`銆乣ndarray` or `List`. You need pass *x* and *y* when *dataset* or *dataloader* is None.\n\n+ *y*: test target, it can be `Tensor`銆乣ndarray` or `List`. You need pass *x* and *y* when *dataset* or *dataloader* is None.\n\n+ transform:  applying `torchvision.transforms` on *x* and *y* or *dataset*.\n\n+ *batch_size*: evaluate batch_size,  default is 32 if not specified.\n\n+ *verbose*: log display mode, 0 = silent, 1 = progress bar, 2 = print each line.\n\n+ *criterion*: loss function, it can be `str` or an instance of `pytorch objective function  `, when passing str('mse', 'cross_entropy', etc.), fastorch will automatically declare the corresponding pytorch objective function .\n\n+ *print_acc*: True or False, passing True if you are doing classification task.\n\n+ *steps*: int or None, if specified, batch_size will be set as total_sample_nums / *steps*.\n\n+ *device*: specify device, otherwise fastorch will set device according to `torch.cuda.is_available()`.\n\n+ **kwargs: arguments used for `torch.utils.data.Dataloader`, etc.\n\n\n\n### - fastorch.functional\n\n**fit**(*model*=None, *train_dataset*=None, *x*=None, *y*=None, *optimizer*=None, *criterion*=None, *transform*=None, *batch_size*=None, *epochs*=1, *verbose*=1, *print_acc*=True, *callbacks*=None, *validation_dataset*=None, *validation_split*=0.0, *validation_data*=None, *validation_transform*=None, *shuffle*=True, *initial_epoch*=0, *steps_per_epoch*=None, *device*=None, **kwargs)\n\n+ *model*: your network, must be specify.\n\n+ *train_dataset*: training dataset, which inherited from `torch.utils.data.Dataset`. Make sure *x* and *y* are not None when *train_dataset* is None.\n+ *x*: training data, it can be `Tensor`銆乣ndarray` or `List`. You need pass *x* and *y* when *train_dataset* is None.\n+ *y*: training target, it can be `Tensor`銆乣ndarray` or `List`. You need pass *x* and *y* when *train_dataset* is None.\n+ *optimizer*: model optimizer, it can be `str` or an instance of `pytorch optimizer`, when passing str('sgd', 'adam'), fastorch will automatically declare the corresponding pytorch optimizer.\n+ *criterion*: loss function, it can be `str` or an instance of `pytorch objective function  `, when passing str('mse', 'cross_entropy', etc.), fastorch will automatically declare the corresponding pytorch objective function .\n+ transform:  applying `torchvision.transforms` on *x* and *y* or *train_dataset*.\n+ *batch_size*: training batch_size,  default is 32 if not specified.\n+ *epochs*: training stop epochs, default is 1 if not specified.\n+ *verbose*: log display mode, 0 = silent, 1 = progress bar, 2 = print each line.\n+ *print_acc*: True or False, passing True if you are doing classification task.\n+ *callbacks*: waiting for implemented.\n+ *validation_dataset*:  validation dataset, which inherited from `torch.utils.data.Dataset`. \n+ *validation_split*: split validation data from training data's ratio, make sure *x* and *y* are not None when using this argument.\n+ *validation_data*: tuple of validation x and validation y.\n+ *validation_transform*:  applying `torchvision.transforms` on *validation_data* or data split by *validation_split*.\n+ *shuffle*: whether shuffle the training data.\n+ *initial_epoch*: start training epoch.\n+ *steps_per_epoch*: int or None, if specified, batch_size will be set as total_sample_nums / *steps_per_epoch*.\n+ *device*: specify device, otherwise fastorch will set device according to `torch.cuda.is_available()`.\n+ **kwargs: arguments used for `torch.utils.data.Dataloader`, etc.\n\n\n\n**evaluate**((*model*=None, *dataset*=None, *dataloader*=None, *x*=None, *y*=None, *transform*=None, *batch_size*=None, *verbose*=1, *criterion*=None, *print_acc*=True, *steps*=None, *device*=None, **kwargs)\n\n+ *model*: your network, must be specify.\n\n+ *dataset*: evaluate dataset, which inherited from `torch.utils.data.Dataset`. Make sure *dataloader* or  *x* and *y* are not None when *dataset*is None.\n+ *dataloader*: evaluate dataloader, which inherited from `torch.utils.data.Dataloader`. Make sure *dataset*or  *x* and *y* are not None when *dataloader*is None.\n+ *x*: test data, it can be `Tensor`銆乣ndarray` or `List`. You need pass *x* and *y* when *dataset* or *dataloader* is None.\n+ *y*: test target, it can be `Tensor`銆乣ndarray` or `List`. You need pass *x* and *y* when *dataset* or *dataloader* is None.\n+ transform:  applying `torchvision.transforms` on *x* and *y* or *dataset*.\n+ *batch_size*: evaluate batch_size,  default is 32 if not specified.\n+ *verbose*: log display mode, 0 = silent, 1 = progress bar, 2 = print each line.\n+ *criterion*: loss function, it can be `str` or an instance of `pytorch objective function  `, when passing str('mse', 'cross_entropy', etc.), fastorch will automatically declare the corresponding pytorch objective function .\n+ *print_acc*: True or False, passing True if you are doing classification task.\n+ *steps*: int or None, if specified, batch_size will be set as total_sample_nums / *steps*.\n+ *device*: specify device, otherwise fastorch will set device according to `torch.cuda.is_available()`.\n+ **kwargs: arguments used for `torch.utils.data.Dataloader`, etc.\n\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/eLeVeNnN/fastorch",
    "keywords": "",
    "license": "MIT License",
    "maintainer": "Eleven",
    "maintainer_email": "eleven_1111@outlook.com",
    "name": "fastorch",
    "package_url": "https://pypi.org/project/fastorch/",
    "platform": "all",
    "project_url": "https://pypi.org/project/fastorch/",
    "project_urls": {
      "Homepage": "https://github.com/eLeVeNnN/fastorch"
    },
    "release_url": "https://pypi.org/project/fastorch/0.0.2/",
    "requires_dist": [
      "torch"
    ],
    "requires_python": "",
    "summary": "Using pytorch easier and faster",
    "version": "0.0.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 7031678,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c99f3781c44c276d0515efdbfb2af842d6032d5069c2ce6f421bd36363827920",
          "md5": "3fc6d946c17eb189fb9a4520f4aa2092",
          "sha256": "e40914d53aae46491c93db0d2e2c7f25ed2c024551367fd1c822f3c4926707f5"
        },
        "downloads": -1,
        "filename": "fastorch-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "3fc6d946c17eb189fb9a4520f4aa2092",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 12112,
        "upload_time": "2020-04-14T12:16:28",
        "upload_time_iso_8601": "2020-04-14T12:16:28.145770Z",
        "url": "https://files.pythonhosted.org/packages/c9/9f/3781c44c276d0515efdbfb2af842d6032d5069c2ce6f421bd36363827920/fastorch-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "33db4bffd5e62311f98eab5281489b262e53fa01b7f6de1bf9be042030367cfb",
          "md5": "6c908bf29f5db7e0039adbd33cf9c127",
          "sha256": "e62801bb6eecaea9469266c09df56c06ff01d311736c9e65827262c671df784d"
        },
        "downloads": -1,
        "filename": "fastorch-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "6c908bf29f5db7e0039adbd33cf9c127",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 12561,
        "upload_time": "2020-04-14T12:16:30",
        "upload_time_iso_8601": "2020-04-14T12:16:30.804266Z",
        "url": "https://files.pythonhosted.org/packages/33/db/4bffd5e62311f98eab5281489b262e53fa01b7f6de1bf9be042030367cfb/fastorch-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "24a0a46dfd8c8f2078fe3ba4307585ba53dd93659d67c78adbf2ed6e74bd5270",
          "md5": "ee646d19bd15b197cf9f1fd96be5be23",
          "sha256": "f35e38890e8da51680b7569bdc8165d6add3e3d130717972f63d23fcecf9eb49"
        },
        "downloads": -1,
        "filename": "fastorch-0.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ee646d19bd15b197cf9f1fd96be5be23",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 11590,
        "upload_time": "2020-04-16T11:59:25",
        "upload_time_iso_8601": "2020-04-16T11:59:25.139682Z",
        "url": "https://files.pythonhosted.org/packages/24/a0/a46dfd8c8f2078fe3ba4307585ba53dd93659d67c78adbf2ed6e74bd5270/fastorch-0.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "22f2aa44efb69e177effaaff88d0d438098df50667bc427b25965a48a495eb78",
          "md5": "d9eb91e11ec99a19c0bbc0c2f32f3da2",
          "sha256": "8ba5cb79544419c8f25bd76d7357f623bd1e0f0e7954a02cc189829d0559bf8b"
        },
        "downloads": -1,
        "filename": "fastorch-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "d9eb91e11ec99a19c0bbc0c2f32f3da2",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 11101,
        "upload_time": "2020-04-16T11:59:27",
        "upload_time_iso_8601": "2020-04-16T11:59:27.644090Z",
        "url": "https://files.pythonhosted.org/packages/22/f2/aa44efb69e177effaaff88d0d438098df50667bc427b25965a48a495eb78/fastorch-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "24a0a46dfd8c8f2078fe3ba4307585ba53dd93659d67c78adbf2ed6e74bd5270",
        "md5": "ee646d19bd15b197cf9f1fd96be5be23",
        "sha256": "f35e38890e8da51680b7569bdc8165d6add3e3d130717972f63d23fcecf9eb49"
      },
      "downloads": -1,
      "filename": "fastorch-0.0.2-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "ee646d19bd15b197cf9f1fd96be5be23",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 11590,
      "upload_time": "2020-04-16T11:59:25",
      "upload_time_iso_8601": "2020-04-16T11:59:25.139682Z",
      "url": "https://files.pythonhosted.org/packages/24/a0/a46dfd8c8f2078fe3ba4307585ba53dd93659d67c78adbf2ed6e74bd5270/fastorch-0.0.2-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "22f2aa44efb69e177effaaff88d0d438098df50667bc427b25965a48a495eb78",
        "md5": "d9eb91e11ec99a19c0bbc0c2f32f3da2",
        "sha256": "8ba5cb79544419c8f25bd76d7357f623bd1e0f0e7954a02cc189829d0559bf8b"
      },
      "downloads": -1,
      "filename": "fastorch-0.0.2.tar.gz",
      "has_sig": false,
      "md5_digest": "d9eb91e11ec99a19c0bbc0c2f32f3da2",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 11101,
      "upload_time": "2020-04-16T11:59:27",
      "upload_time_iso_8601": "2020-04-16T11:59:27.644090Z",
      "url": "https://files.pythonhosted.org/packages/22/f2/aa44efb69e177effaaff88d0d438098df50667bc427b25965a48a495eb78/fastorch-0.0.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}