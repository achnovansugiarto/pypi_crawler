{
  "info": {
    "author": "Lighton AI Research",
    "author_email": "iacopo@lighton.io,julien@lighton.io,igor@lighton.io",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.9",
      "Topic :: Scientific/Engineering :: Artificial Intelligence"
    ],
    "description": "# <img src=\"https://cloud.lighton.ai/wp-content/uploads/2020/01/LightOnCloud.png\" width=50/>LairGPT\n\n[![GitHub license](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)  [![Twitter](https://img.shields.io/twitter/follow/LightOnIO?style=social)](https://twitter.com/LightOnIO)\n\nA Python package in Pytorch by [LightOn AI Research](https://lair.lighton.ai/) that allows to perform inference\nwith [PAGnol models](https://lair.lighton.ai/pagnol/).\nYou can test the generation capabilities of PAGnol on our [interactive demo website](https://pagnol.lighton.ai/).\n\n## Install\n\n### Requirements\n\nThe package is tested with Python 3.9. After cloning this repository, you can create a `conda` environment\nwith the necessary dependencies from its root by\n\n```\nconda env create --file=environment.yml\n```\n\nIf you prefer control on your environment, the dependencies are\n\n```\npytorch==1.8.1\ntokenizers==0.10\npython-wget==3.2\n```\n\n### pip\n\nSimply run `pip install .` from the root of this repository.\n\n## Text generation\n\nThe simplest way to generate text with PAGnol using `lairgpt` is\n\n```\nfrom lairgpt.models import PAGnol\n\npagnol = PAGnol.small()\npagnol(\"Salut PAGnol, comment Ã§a va ?\")\n```\n\nWe include a demo script `main.py` in this repository that takes the path to models and tokenizers, and an input text, and generates sentences from it.\nTo use it:\n\n```\npython main.py --size large --text \"LightOn est une startup technologique\"\n```\n\nTo generate text we rely on the `infer` method of the `TextGenerator` class that takes the usual parameters:\n- `mode`: (default: `\"nucleus\"`)\n  - `\"greedy\"`: always select the most likely word as its next word.\n  - `\"top-k\"`:  filter to the K most likely next words and redistribute the probability mass among only those K next words.\n  - `\"nucleus\"`: filter to the smallest possible set of words whose cumulative probability exceeds the probability `p` and redistribute the probability mass among this set of words.\n- `temperature`: a control over randomness. As this value approaches zero, the model becomes more deterministic. (default: `1.0`)\n- `k`: size of the set of words to consider for \"top-k\" sampling (default: `5`)\n- `p`: a control over diversity in nucleus sampling. A value of 0.5 means that half of the options are considered. (default: `0.9`)\n- `max_decoding_steps`: number of tokens to generate. (default: `32`)\n- `skip_eos`: when `True`, generation does not stop at end of sentence. (default: `True`)\n\n## <img src=\"https://cloud.lighton.ai/wp-content/uploads/2020/01/LightOnCloud.png\" width=50/> More on LightOn\n\nLightOn is a company that produces hardware for machine learning.\nTo lease a LightOn Appliance, please visit: https://lighton.ai/lighton-appliance/\n\nTo request access to LightOn Cloud and try our photonic co-processor, please visit: https://cloud.lighton.ai/\nFor researchers, we also have a LightOn Cloud for Research program, please visit https://cloud.lighton.ai/lighton-research/ for more information.\n\n## Citation\n\nWe will soon have a preprint on arXiv, stay tuned ;)\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/lightonai/lairgpt",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "lairgpt",
    "package_url": "https://pypi.org/project/lairgpt/",
    "platform": "",
    "project_url": "https://pypi.org/project/lairgpt/",
    "project_urls": {
      "Homepage": "https://github.com/lightonai/lairgpt"
    },
    "release_url": "https://pypi.org/project/lairgpt/0.5.2/",
    "requires_dist": [
      "torch (==1.8.*)",
      "tokenizers (==0.10)",
      "wget (==3.2)"
    ],
    "requires_python": "",
    "summary": "A Pytorch-based package by LightOn AI Research allowing to perform inference with PAGnol models.",
    "version": "0.5.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 10356361,
  "releases": {
    "0.5.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "87999464c72e26daae953206272590ddfd4e8fc75406d17cdddfede516f03d24",
          "md5": "c9ff8df8dfd9484377181d60d5a5e7d0",
          "sha256": "117be8fc243188b04785a570b217567e78e95df0570038ec0c71826fc8c5ed4a"
        },
        "downloads": -1,
        "filename": "lairgpt-0.5.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "c9ff8df8dfd9484377181d60d5a5e7d0",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 12048,
        "upload_time": "2021-05-07T14:18:00",
        "upload_time_iso_8601": "2021-05-07T14:18:00.792397Z",
        "url": "https://files.pythonhosted.org/packages/87/99/9464c72e26daae953206272590ddfd4e8fc75406d17cdddfede516f03d24/lairgpt-0.5.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.5.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "721b2baae81bc6a347c6e43054584b1876bc405d4cc06a5b33228ef748d362c3",
          "md5": "0d7c7f9829944aafda7a527008e2f457",
          "sha256": "9fd53e3acf05cb2e27d18d1c4cb4205ab6739c1737231e13d513e629f00cbd18"
        },
        "downloads": -1,
        "filename": "lairgpt-0.5.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0d7c7f9829944aafda7a527008e2f457",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 12079,
        "upload_time": "2021-05-14T13:00:01",
        "upload_time_iso_8601": "2021-05-14T13:00:01.905765Z",
        "url": "https://files.pythonhosted.org/packages/72/1b/2baae81bc6a347c6e43054584b1876bc405d4cc06a5b33228ef748d362c3/lairgpt-0.5.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "721b2baae81bc6a347c6e43054584b1876bc405d4cc06a5b33228ef748d362c3",
        "md5": "0d7c7f9829944aafda7a527008e2f457",
        "sha256": "9fd53e3acf05cb2e27d18d1c4cb4205ab6739c1737231e13d513e629f00cbd18"
      },
      "downloads": -1,
      "filename": "lairgpt-0.5.2-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "0d7c7f9829944aafda7a527008e2f457",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 12079,
      "upload_time": "2021-05-14T13:00:01",
      "upload_time_iso_8601": "2021-05-14T13:00:01.905765Z",
      "url": "https://files.pythonhosted.org/packages/72/1b/2baae81bc6a347c6e43054584b1876bc405d4cc06a5b33228ef748d362c3/lairgpt-0.5.2-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}