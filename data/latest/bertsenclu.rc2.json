{
  "info": {
    "author": "Johannes Schneider",
    "author_email": "vollkoff@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Developers",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: MIT License",
      "Operating System :: MacOS",
      "Operating System :: Microsoft :: Windows",
      "Operating System :: POSIX",
      "Operating System :: Unix",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Topic :: Scientific/Engineering",
      "Topic :: Scientific/Engineering :: Artificial Intelligence"
    ],
    "description": "<!--\r\n[![PyPI - Python](https://img.shields.io/badge/python-v3.7+-blue.svg)](https://pypi.org/project/bertopic/)\r\n[![Build](https://img.shields.io/github/workflow/status/MaartenGr/BERTopic/Code%20Checks/master)](https://pypi.org/project/bertopic/)\r\n[![docs](https://img.shields.io/badge/docs-Passing-green.svg)](https://maartengr.github.io/BERTopic/)\r\n[![PyPI - PyPi](https://img.shields.io/pypi/v/BERTopic)](https://pypi.org/project/bertopic/)\r\n[![PyPI - License](https://img.shields.io/badge/license-MIT-green.svg)](https://github.com/MaartenGr/VLAC/blob/master/LICENSE)\r\n[![arXiv](https://img.shields.io/badge/arXiv-2203.05794-<COLOR>.svg)](https://arxiv.org/abs/2203.05794)\r\n-->\r\n\r\n# Bert-SenClu\r\n\r\n**(Bert-)SenClu** is a topic modeling technique that leverages sentence transformers to compute topic models. For once, it differs from other topic models by using sentences as unit of analysis, i.e., a sentence is assigned to a topic and not a word (like for LDA, TKM) or an entire document (BertTopic). \r\nMethods that treat documents as a unit can be faster but they only assign the entire document to one topic, which is different from most classical topic models that produce a document-topic distribution, i.e., a document can contain multiple documents. Our topic model also does not do a dimensionality reduction of embeddings. Inference is based on expectation-maximization, e.g., like for TKM (see [**TKM Paper**](https://arxiv.org/abs/1710.02650) and [**TKM Code**](https://github.com/JohnTailor/tkm)).\r\n\r\nFor an in-depth overview of the features of **Bert-SenClu**\r\nyou can check the [**repository**](https://github.com/JohnTailor/BertSenClu/) or the paper [**the paper**](https://arxiv.org/abs/2302.03106).\r\n\r\n\r\n<img src=\"https://github.com/JohnTailor/BertSenClu/blob/main/images/comp.png\" width=\"60%\" height=\"60%\" align=\"center\" />\r\n\r\n\r\n## Installation\r\n\r\nInstallation, with sentence-transformers, can be done using [pypi](https://pypi.org/project/bertsenclu/):\r\n\r\n```bash\r\npip install bertsenclu\r\n```\r\n    \r\n## Quick Start\r\nWe start by extracting topics from the 20 newsgroups dataset containing English documents:\r\n\r\n```python\r\nfrom sklearn.datasets import fetch_20newsgroups\r\nimport numpy as np\r\nfrom bertSenClu import senClu\r\n\r\ndocs = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))  # get raw data    \r\n\r\nfolder = \"modelOutputs/\"\r\ntopic_model= senClu.SenClu()\r\ntopics, probs = topic_model.fit_transform(docs, nTopics=20, loadAndStoreInFolder=folder)\r\n\r\n\r\n```\r\n\r\nAfter generating topics and their probabilities, we can save outputs:\r\n\r\n```python\r\n>> topic_model.saveOutputs(folder) #Save outputs in folder, i.e. csv-file and visualizations\r\n```\r\n\r\nand look at topics\r\n\r\n```python\r\n\r\n\r\n>>for it,t in enumerate(topics):\r\n    print(\"Topic\",it,t[:10])\r\n    \r\nTopic 0 [encryption, key, ripem, privacy, rsa, clipper, encrypted, escrow, nsa, secure]\r\nTopic 1 [government, militia, amendment, federal, law, constitution, firearm, regulated, administration, clinton]\r\nTopic 2 [launch, satellite, lunar, space, orbit, mission, spacecraft, larson, probe, shuttle]\r\nTopic 3 [patient, hiv, disease, infection, candida, vitamin, antibiotic, diet, symptom, smokeless]\r\n...\r\n\r\n ```  \r\n\r\nWe can also use an interactive tool for visualization and topic analysis that runs in a browser. It can be called command line with the folder containing topic modeling outputs:\r\n\r\nYou need to **download** the [**visual.py**](https://github.com/JohnTailor/BertSenClu/blob/main/visual.py) from the repo first\r\n\r\n```console\r\nstreamlit run visual.py -- --folder \"modelOutputs/\"\r\n```\r\n\r\nIt can also be called from python:\r\n\r\n```python\r\nimport subprocess\r\nfolder = \"modelOutputs/\"\r\nsubprocess.run(\"streamlit run visual.py -- --folder \"+folder,shell=True)\r\n```\r\n\r\nThe interactive visualization looks like this:\r\n\r\n<img src=\"https://github.com/JohnTailor/BertSenClu/blob/main/images/visual.PNG\" width=\"100%\" height=\"100%\" align=\"center\" />\r\n\r\nIf you scroll down (or look into the folder where you stored outputs), you see topic relationship information as well, i.e., a TSNE visualization and a hierarchical clustering of topics:\r\n\r\n<img src=\"https://github.com/JohnTailor/BertSenClu/blob/main/images/topic_visual_hierarchy.png\" width=\"60%\" height=\"60%\" align=\"center\" />\r\n<img src=\"https://github.com/JohnTailor/BertSenClu/blob/main/images/topic_visual_tsne.png\" width=\"60%\" height=\"60%\" align=\"center\" />\r\n\r\n\r\nWe can also access outputs directly by accessing functions from the model\r\n```python\r\n\r\n>>  print(\"Top 10 words with scores for topic 0\",topic_model.getTopicsWitchScores()[0][:10])\r\nTop 10 words with scores for topic 0 [('encryption', 11.269135), ('key', 11.173454), ('ripem', 10.151058), ('privacy', 10.070835), ('rsa', 7.3271174), ('clipper', 6.8211393), ('encrypted', 6.567956), ('escrow', 5.993511), ('nsa', 5.853071), ('secure', 5.4898496)]\r\n\r\n>> print(\"Distribution of topics for document 0\", np.round(topic_model.getTopicDocumentDistribution()[0],3))\r\nDistribution of topics for document 0 [0. 0. 1. ... 0. 0. 0.]\r\n    \r\n>> print(\"Distribution of topics\", np.round(topic_model.getTopicDistribution(), 3))\r\nDistribution of topics [0.022 0.061 0.024 0.026 0.067 0.079 0.155 0.043 0.061 0.039 0.031 0.198\r\n 0.018 0.033 0.033 0.012 0.016 0.029 0.033 0.02 ]\r\n\r\n>> print(\"First 4 sentences for top doc for topic 0 with probability and \", topic_model.getTopDocsPerTopic()[0][0][:4])\r\nFirst 4 sentences for top doc for topic 0 (['[...]>\\n', '[...]>\\n\\n', \"If the data isn't there when the warrant comes, you effectively have\\n\", 'secure crypto.  '], 1.0, 8607)\r\n\r\n>> print(\"Top 3 sentences for topic 0 \", topic_model.getTopSentencesPerTopic()[0][:5])    \r\nTop 3 sentences for topic 1  [('enforcement.\\n\\n    ', 0.22597079), ('Enforcement.  ', 0.22597079), ('to the Constitution.\\n\\n   ', 0.22434217)]\r\n#The sentences show that the sentence partitioning algorithm used is not the best... (It splits based on carriage returns. Still topic modeling results are good. It's also easy to use another one, or preprocess the data    \r\n\r\n```\r\n\r\n\r\n## How it works\r\nThe steps for topic modeling with **Bert-SenClu** are\r\n<ol>\r\n  <li>Splitting docs into sentences</li>  \r\n  <li>Embedding the sentences using pretrained sentence-transformers</li>\r\n  <li>Running the topic modeling</li>\r\n  <li>Computing topic-word distributions based on sentence to topic assignments</li>\r\n</ol>\r\nThe outcomes of the first two steps are stored in a user-provided folder if parameter \"loadAndStoreInFolder\" is set explicitly in \"fit_transform\". By default this is not the case (i.e., \"loadAndStoreInFolder\"=None).  **Bert-SenClu** can reuse the stored precomputed sentence partitionen and embeddings, which speeds up re-running the topic modeling, e.g., if you want to change the number of topics. However, if you alter the data, you need to delete the folder, i.e., the files with the precomputed sentence embeddings and partitionings.  \r\n \r\nYou can change each algorithm in these steps, especially the algorithm for sentence partitioning as well as the pre-trained sentence embedder. As you saw in the example, the used algorithm for sentence partitioning is not that great for the newsgroup dataset, but the overall result is still good.\r\n\r\nThe (main) function \"fit_transform\" has a hyperparameter \"alpha\" (similar to other models like LDA), which guides the algorithm on how many topics a document should contain. Setting it 0, means that a document likely has few topics. Setting it to 1 (or larger) means it is more likely to have many (for longer documents). As default, you can use 0.5/sqrt(nTopics). \r\n\r\n\r\n## Citation\r\nTo cite the [Bert-SenClu Paper](https://arxiv.org/abs/2302.03106), please use the following bibtex reference:\r\n\r\n```bibtex\r\n@article{schneider23,\r\n  title={Efficient and Flexible Topic Modeling using Pretrained Embeddings and Bag of Sentences},\r\n  author={Schneider,Johannes},\r\n  journal={arXiv preprint arXiv:2302.03106},\r\n  year={2023}\r\n}\r\n```\r\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/JohnTailor/BertSenClu",
    "keywords": "nlp bert topic modeling sentence embeddings",
    "license": "LICENSE",
    "maintainer": "",
    "maintainer_email": "",
    "name": "bertsenclu",
    "package_url": "https://pypi.org/project/bertsenclu/",
    "platform": null,
    "project_url": "https://pypi.org/project/bertsenclu/",
    "project_urls": {
      "Homepage": "https://github.com/JohnTailor/BertSenClu",
      "Issue Tracker": "https://github.com/JohnTailor/BertSenClu/issues",
      "Source Code": "https://github.com/JohnTailor/BertSenClu/"
    },
    "release_url": "https://pypi.org/project/bertsenclu/0.1.8/",
    "requires_dist": [
      "numpy (>=1.20.0)",
      "pandas (>=1.1.5)",
      "scikit-learn (>=0.22.2.post1)",
      "sentence-transformers (>=0.4.1)",
      "streamlit (>=1.17.0)",
      "pysbd (>=0.3.4)",
      "torch (>=1.11.0)"
    ],
    "requires_python": ">=3.7",
    "summary": "(Bert-)SenClu is a topic modeling technique that leverages sentence transformers to compute topic models.",
    "version": "0.1.8",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16743363,
  "releases": {
    "0.1.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0b3a3b6d1673b26156e3461ba455848f92fef7004c284b630be6769130241584",
          "md5": "38f1370acfe4bc719b5bf75e752c3d28",
          "sha256": "c9413e41dd182787ff07fe4b07002a5507c9c0eb931dbfeff567a2fbf3823fca"
        },
        "downloads": -1,
        "filename": "bertsenclu-0.1.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "38f1370acfe4bc719b5bf75e752c3d28",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 14728,
        "upload_time": "2023-02-08T07:31:51",
        "upload_time_iso_8601": "2023-02-08T07:31:51.849239Z",
        "url": "https://files.pythonhosted.org/packages/0b/3a/3b6d1673b26156e3461ba455848f92fef7004c284b630be6769130241584/bertsenclu-0.1.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "835993a26537fe2867bb50ab41554d01a8fed9227c1aed906682489a76f09b63",
          "md5": "3c7bf54682e6d49883a55226c6078573",
          "sha256": "9ab5541c17fb6edb3ab50b0600d4d4c0bf45206116f7062d9a15383a2d82b1d9"
        },
        "downloads": -1,
        "filename": "bertsenclu-0.1.4.tar.gz",
        "has_sig": false,
        "md5_digest": "3c7bf54682e6d49883a55226c6078573",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 17897,
        "upload_time": "2023-02-08T07:31:53",
        "upload_time_iso_8601": "2023-02-08T07:31:53.878287Z",
        "url": "https://files.pythonhosted.org/packages/83/59/93a26537fe2867bb50ab41554d01a8fed9227c1aed906682489a76f09b63/bertsenclu-0.1.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d5f6099fd1ddfcbe0a2eac10664c3c8d67f75b62201e59e91ed461c775fa67a1",
          "md5": "bb0f3257e1ba9bf2da4c132133df102a",
          "sha256": "e181896992d6ded4dca76aa10b280210083f2defd3ae37c60e0483333bd1b049"
        },
        "downloads": -1,
        "filename": "bertsenclu-0.1.8-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "bb0f3257e1ba9bf2da4c132133df102a",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 14809,
        "upload_time": "2023-02-08T08:25:46",
        "upload_time_iso_8601": "2023-02-08T08:25:46.465047Z",
        "url": "https://files.pythonhosted.org/packages/d5/f6/099fd1ddfcbe0a2eac10664c3c8d67f75b62201e59e91ed461c775fa67a1/bertsenclu-0.1.8-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "12df7eb96747f3957ed7d0014d8c13d26598e9786afcd7c009b8d5b60872332c",
          "md5": "821e4f2cfcf6672293d9db3edc425fc2",
          "sha256": "d8a5c302ba59cdc967531f139d4ce757e34dcd06cee07fda23bdf67a551e8a2b"
        },
        "downloads": -1,
        "filename": "bertsenclu-0.1.8.tar.gz",
        "has_sig": false,
        "md5_digest": "821e4f2cfcf6672293d9db3edc425fc2",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 18032,
        "upload_time": "2023-02-08T08:25:48",
        "upload_time_iso_8601": "2023-02-08T08:25:48.447787Z",
        "url": "https://files.pythonhosted.org/packages/12/df/7eb96747f3957ed7d0014d8c13d26598e9786afcd7c009b8d5b60872332c/bertsenclu-0.1.8.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "d5f6099fd1ddfcbe0a2eac10664c3c8d67f75b62201e59e91ed461c775fa67a1",
        "md5": "bb0f3257e1ba9bf2da4c132133df102a",
        "sha256": "e181896992d6ded4dca76aa10b280210083f2defd3ae37c60e0483333bd1b049"
      },
      "downloads": -1,
      "filename": "bertsenclu-0.1.8-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "bb0f3257e1ba9bf2da4c132133df102a",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 14809,
      "upload_time": "2023-02-08T08:25:46",
      "upload_time_iso_8601": "2023-02-08T08:25:46.465047Z",
      "url": "https://files.pythonhosted.org/packages/d5/f6/099fd1ddfcbe0a2eac10664c3c8d67f75b62201e59e91ed461c775fa67a1/bertsenclu-0.1.8-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "12df7eb96747f3957ed7d0014d8c13d26598e9786afcd7c009b8d5b60872332c",
        "md5": "821e4f2cfcf6672293d9db3edc425fc2",
        "sha256": "d8a5c302ba59cdc967531f139d4ce757e34dcd06cee07fda23bdf67a551e8a2b"
      },
      "downloads": -1,
      "filename": "bertsenclu-0.1.8.tar.gz",
      "has_sig": false,
      "md5_digest": "821e4f2cfcf6672293d9db3edc425fc2",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 18032,
      "upload_time": "2023-02-08T08:25:48",
      "upload_time_iso_8601": "2023-02-08T08:25:48.447787Z",
      "url": "https://files.pythonhosted.org/packages/12/df/7eb96747f3957ed7d0014d8c13d26598e9786afcd7c009b8d5b60872332c/bertsenclu-0.1.8.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}