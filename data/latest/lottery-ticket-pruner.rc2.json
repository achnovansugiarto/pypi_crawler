{
  "info": {
    "author": "Jim Meyer",
    "author_email": "jimm@racemed.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Intended Audience :: Developers",
      "Intended Audience :: Education",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Topic :: Scientific/Engineering :: Artificial Intelligence",
      "Topic :: Scientific/Engineering :: Image Recognition",
      "Topic :: Software Development :: Libraries",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "# Lottery Ticket Pruner\n\nDeep Neural Networks (DNNs) can often benefit from \"pruning\" some weights in the network, turning dense matrices of weights\ninto sparse matrices of weights with little or no loss in accuracy of the overall model.\n\nThis is a keras implementation of the most relevant pruning strategies outlined in two papers:\n\n- [The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks](https://arxiv.org/pdf/1803.03635.pdf)\n- [Deconstructing Lottery Tickets: Zeros, Signs, and the Supermask](https://eng.uber.com/deconstructing-lottery-tickets/)\n\nThe pruning strategies implemented in this package can reduce the number of non-zero weights of CNNs, DNNs\nby 40-98% with negligible losses in accuracy of the final model.\nVarious techniques like [MorphNet](https://ai.googleblog.com/2019/04/morphnet-towards-faster-and-smaller.html) can then\nbe applied to further optimize these now sparse models to decrease model size and/or inference times.\n\n# Installation\n\n    pip install lottery-ticket-pruner\n\n# Usage\n\nA typical use of the code in this repo looks something like this:\n\n    from lottery_ticket_pruner import LotteryTicketPruner, PrunerCallback\n\n    model = <create model with random initial weights>\n    # Save the initial weights of the model so we can start pruning training from them later\n    initial_weights = model.get_weights()\n    # Initialize pruner so it knows the starting initial (random) weights\n    pruner = LotteryTicketPruner(model)\n    ...\n    # Train the model\n    model.fit(X, y)\n    ...\n    pruner.set_pretrained_weights(model)\n    ...\n    # Revert model so it has random initial weights\n    model.set_weights(initial_weights)\n    # Now train the model using pruning\n    pruner.calc_prune_mask(model, 0.5, 'large_final')\n    untrained_loss, untrained_accuracy = model.evaluate(x_test, y_test)\n    model.fit(X, y, callbacks=[PrunerCallback(pruner)])\n    trained_loss, trained_accuracy = model.evaluate(x_test, y_test)\n\nFor a full working example that computes the accuracy for an untrained model that has been pruned, as well\nas training a model from scratch using lotttery ticket pruning, see the [example code](https://github.com/jim-meyer/lottery_ticket_pruner/examples/example.py).\nThis example code uses the [MNIST](https://keras.io/api/datasets/mnist/) and\n[CIFAR10](https://keras.io/api/datasets/cifar10/) datasets.\n\n# Results\n\n[examples/example.sh](https://github.com/jim-meyer/lottery_ticket_pruner/examples/example.py) was run to see the effects\nof pruning at 20%, 55.78%, 89.6%, 99.3% using the 3 supported pruning strategies across the MNIST and CIFAR10 datasets.\nTraining was capped at 100 epochs to help control AWS expenses.\n\nThe results averaged across 3 iterations:\n\n## MNIST (100 epochs)\n\n    |Prune Percentage|  |Dataset|   |Prune Strategy|            |Avg Accuracy|\n    |:---|              |:---|      |:---:|                     |:---:|\n    |n/a|               |mnist|     |n/a|                       |0.937|\n    |20%|               |mnist|     |large_final|               |0.935|\n    |20%|               |mnist|     |smallest_weights|          |0.936|\n    |20%|               |mnist|     |smallest_weights_global|   |0.939|\n    |55.78%|            |mnist|     |large_final|               |0.936|\n    |55.78%|            |mnist|     |smallest_weights|          |0.936|\n    |55.78%|            |mnist|     |smallest_weights_global|   |0.939|\n    |89.6%|             |mnist|     |large_final|               |0.936|\n    |89.6%|             |mnist|     |smallest_weights|          |0.937|\n    |89.6%|             |mnist|     |smallest_weights_global|   |0.939|\n    |99.33%|            |mnist|     |large_final|               |0.936|\n    |99.33%|            |mnist|     |smallest_weights|          |0.937|\n    |99.33%|            |mnist|     |smallest_weights_global|   |0.939|\n\n## CIFAR (100 epochs)\n\n    |Prune Percentage|  |Dataset|   |Prune Strategy|            |Avg Accuracy|\n    |:---|              |:---|      |:---:|                     |:---:|\n    |n/a|               |cifar10|   |n/a|                       |0.427|\n    |20%|               |cifar10|   |large_final|               |0.298|\n    |20%|               |cifar10|   |smallest_weights|          |0.427|\n    |20%|               |cifar10|   |smallest_weights_global|   |0.423|\n    |55.78%|            |cifar10|   |large_final|               |0.294|\n    |55.78%|            |cifar10|   |smallest_weights|          |0.427|\n    |55.78%|            |cifar10|   |smallest_weights_global|   |0.424|\n    |89.6%|             |cifar10|   |large_final|               |0.289|\n    |89.6%|             |cifar10|   |smallest_weights|          |0.427|\n    |89.6%|             |cifar10|   |smallest_weights_global|   |0.424|\n    |99.33%|            |cifar10|   |large_final|               |0.288|\n    |99.33%|            |cifar10|   |smallest_weights|          |0.428|\n    |99.33%|            |cifar10|   |smallest_weights_global|   |0.425|\n\n## CIFAR (500 epochs)\n\n    |Prune Percentage|  |Dataset|   |Prune Strategy|            |Avg Accuracy|\n    |:---|              |:---|      |:---:|                     |:---:|\n    |n/a|               |cifar10|   |n/a|                       |0.550|\n    |20%|               |cifar10|   |smallest_weights_global|   |0.550|\n    |55.78%|            |cifar10|   |smallest_weights_global|   |0.552|\n    |89.6%|             |cifar10|   |smallest_weights_global|   |0.554|\n    |99.33%|            |cifar10|   |smallest_weights_global|   |0.554|\n\n# Pruning the initial model weights with no training\n\nOne of the surprising findings of these papers is that if we simply *do inference on the model using the original weights,\nwith no training, but applying pruning the resulting models perform far (far!) better than a random guess*. Here are the\nresults of inference done after applying pruning to the random initial weights of the model without any training. The\ninitial model, used as an input to the pruning logic, was trained for 100 epochs.\n\n## MNIST\n\n    |Prune Percentage|  |Dataset|   |Prune Strategy|                        |Avg Accuracy|\n    |:---|              |:---|      |:---:|                                 |:---:|\n    |n/a|               |mnist|     |no pruning done - random weights|      |0.121|\n    |n/a|               |mnist|     |source model trained for 100 epochs|   |0.936|\n    |20%|               |mnist|     |large_final|                           |0.760|\n    |20%|               |mnist|     |smallest_weights|                      |0.737|\n    |20%|               |mnist|     |smallest_weights_global|               |0.722|\n    |55.78%|            |mnist|     |large_final|                           |0.911|\n    |55.78%|            |mnist|     |smallest_weights|                      |0.899|\n    |55.78%|            |mnist|     |smallest_weights_global|               |0.920|\n    |89.6%|             |mnist|     |large_final|                           |0.744|\n    |89.6%|             |mnist|     |smallest_weights|                      |0.703|\n    |89.6%|             |mnist|     |smallest_weights_global|               |0.925|\n    |99.33%|            |mnist|     |large_final|                           |0.176|\n    |99.33%|            |mnist|     |smallest_weights|                      |0.164|\n    |99.33%|            |mnist|     |smallest_weights_global|               |0.098|\n\n## CIFAR\n\n    |Prune Percentage|  |Dataset|   |Prune Strategy|                        |Avg Accuracy|\n    |:---|              |:---|      |:---:|                                 |:---:|\n    |n/a|               |cifar10|   |no pruning done - random weights|      |0.094|\n    |n/a|               |mnist|     |source model trained for 100 epochs|   |0.424|\n    |20%|               |cifar10|   |large_final|                           |0.232|\n    |20%|               |cifar10|   |smallest_weights|                      |0.180|\n    |20%|               |cifar10|   |smallest_weights_global|               |0.201|\n    |55.78%|            |cifar10|   |large_final|                           |0.192|\n    |55.78%|            |cifar10|   |smallest_weights|                      |0.240|\n    |55.78%|            |cifar10|   |smallest_weights_global|               |0.251|\n    |89.6%|             |cifar10|   |large_final|                           |0.101|\n    |89.6%|             |cifar10|   |smallest_weights|                      |0.102|\n    |89.6%|             |cifar10|   |smallest_weights_global|               |0.240|\n    |99.33%|            |cifar10|   |large_final|                           |0.100|\n    |99.33%|            |cifar10|   |smallest_weights|                      |0.099|\n    |99.33%|            |cifar10|   |smallest_weights_global|               |0.100|\n\n# Working In This Repo\n\nThe information in this section is only needed if you need to modify this package.\n\nThis repo uses Github Actions to perform [Continuous Integration checks, tests for each push, pull request](https://github.com/jim-meyer/lottery_ticket_pruner/actions).\n\nLikewise, when a new release is tagged a new version of the package is automatically built and uploaded to [pypi](https://pypi.org).\n\n## Local Testing\n\nRunning unit tests locally is done via [tox](https://pypi.org/project/tox/). This automatically generates a code coverage report too.\n\n    tox\n\n# FAQ\n\nQ: The two papers cited above refer to more pruning strategies than are implemented here. When will you support the\nXXX pruning strategy?\n\nA: The goal of this repo is to provide an implementation of the more effective strategies described\nby the two papers. If other effective strategies are developed then pull requests implementing those strategies are welcomed.\n\nQ: Why isn't python 3.5 supported?\n\nA: keras>=2.1.0, pandas>=1.0 don't support python 3.5. Hence this package does not either.\n\n# Contributing\n\nPull requests to [this repo](https://github.com/jim-meyer/lottery_ticket_pruner) are always welcome.\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/jim-meyer/lottery_ticket_pruner",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "lottery-ticket-pruner",
    "package_url": "https://pypi.org/project/lottery-ticket-pruner/",
    "platform": "",
    "project_url": "https://pypi.org/project/lottery-ticket-pruner/",
    "project_urls": {
      "Homepage": "https://github.com/jim-meyer/lottery_ticket_pruner"
    },
    "release_url": "https://pypi.org/project/lottery-ticket-pruner/0.8.1/",
    "requires_dist": [
      "keras (>=2.1.0)",
      "numpy (>=1.18.3)"
    ],
    "requires_python": ">=3.6",
    "summary": "Enables pruning of Keras DNNs using \"lottery ticket\" pruning",
    "version": "0.8.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 7524924,
  "releases": {
    "0.8.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "19b0a43aed4f91db134ba04de9cef5fe2eaac2f20c73666b226c878a07dc8e2c",
          "md5": "c31a90377920622660d656d74f61784a",
          "sha256": "caee8911e7378738b2ffc91f10c63d011f742c909d8a82da54315452d5cbf751"
        },
        "downloads": -1,
        "filename": "lottery_ticket_pruner-0.8.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "c31a90377920622660d656d74f61784a",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": ">=3.6",
        "size": 12234,
        "upload_time": "2020-06-14T19:31:38",
        "upload_time_iso_8601": "2020-06-14T19:31:38.739657Z",
        "url": "https://files.pythonhosted.org/packages/19/b0/a43aed4f91db134ba04de9cef5fe2eaac2f20c73666b226c878a07dc8e2c/lottery_ticket_pruner-0.8.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "070f19dee8d14e97a39c8fcdaabcb072a15235cdabcc5d3f5ec23040fbf454ac",
          "md5": "b8a7020837090d171ecf5fb2ad6e9437",
          "sha256": "cabdd414f9d73643c9ff2bec3ab1c12aa63a197630c60c4bece9805c03063fc5"
        },
        "downloads": -1,
        "filename": "lottery-ticket-pruner-0.8.0.tar.gz",
        "has_sig": false,
        "md5_digest": "b8a7020837090d171ecf5fb2ad6e9437",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 25604,
        "upload_time": "2020-06-14T19:31:40",
        "upload_time_iso_8601": "2020-06-14T19:31:40.837111Z",
        "url": "https://files.pythonhosted.org/packages/07/0f/19dee8d14e97a39c8fcdaabcb072a15235cdabcc5d3f5ec23040fbf454ac/lottery-ticket-pruner-0.8.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.8.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c3e417b65edd9e97ffad31bfbe0bfca71789be49fbcd9ab442e923d6c2d99f7b",
          "md5": "8d1db5b4c17deee05ce891c698ae08e2",
          "sha256": "580c3567e16a54276eb1fdd9e968fb72f762dedd9e24a6d3fd85aef39520319a"
        },
        "downloads": -1,
        "filename": "lottery_ticket_pruner-0.8.1-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "8d1db5b4c17deee05ce891c698ae08e2",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": ">=3.6",
        "size": 12493,
        "upload_time": "2020-06-20T23:41:31",
        "upload_time_iso_8601": "2020-06-20T23:41:31.293422Z",
        "url": "https://files.pythonhosted.org/packages/c3/e4/17b65edd9e97ffad31bfbe0bfca71789be49fbcd9ab442e923d6c2d99f7b/lottery_ticket_pruner-0.8.1-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c1d963e465c20f1388ec5b584412b6dc5ee96251dd80c0c2fe1fbefec5cb1283",
          "md5": "eec73e583e2adb82f7679f3545c59165",
          "sha256": "fc7a35e3a8a43aa635c5919bd21a21866bb172345ce717e3df2a9bb59e181b03"
        },
        "downloads": -1,
        "filename": "lottery-ticket-pruner-0.8.1.tar.gz",
        "has_sig": false,
        "md5_digest": "eec73e583e2adb82f7679f3545c59165",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 23827,
        "upload_time": "2020-06-20T23:41:32",
        "upload_time_iso_8601": "2020-06-20T23:41:32.274422Z",
        "url": "https://files.pythonhosted.org/packages/c1/d9/63e465c20f1388ec5b584412b6dc5ee96251dd80c0c2fe1fbefec5cb1283/lottery-ticket-pruner-0.8.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "c3e417b65edd9e97ffad31bfbe0bfca71789be49fbcd9ab442e923d6c2d99f7b",
        "md5": "8d1db5b4c17deee05ce891c698ae08e2",
        "sha256": "580c3567e16a54276eb1fdd9e968fb72f762dedd9e24a6d3fd85aef39520319a"
      },
      "downloads": -1,
      "filename": "lottery_ticket_pruner-0.8.1-py2.py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "8d1db5b4c17deee05ce891c698ae08e2",
      "packagetype": "bdist_wheel",
      "python_version": "py2.py3",
      "requires_python": ">=3.6",
      "size": 12493,
      "upload_time": "2020-06-20T23:41:31",
      "upload_time_iso_8601": "2020-06-20T23:41:31.293422Z",
      "url": "https://files.pythonhosted.org/packages/c3/e4/17b65edd9e97ffad31bfbe0bfca71789be49fbcd9ab442e923d6c2d99f7b/lottery_ticket_pruner-0.8.1-py2.py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "c1d963e465c20f1388ec5b584412b6dc5ee96251dd80c0c2fe1fbefec5cb1283",
        "md5": "eec73e583e2adb82f7679f3545c59165",
        "sha256": "fc7a35e3a8a43aa635c5919bd21a21866bb172345ce717e3df2a9bb59e181b03"
      },
      "downloads": -1,
      "filename": "lottery-ticket-pruner-0.8.1.tar.gz",
      "has_sig": false,
      "md5_digest": "eec73e583e2adb82f7679f3545c59165",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 23827,
      "upload_time": "2020-06-20T23:41:32",
      "upload_time_iso_8601": "2020-06-20T23:41:32.274422Z",
      "url": "https://files.pythonhosted.org/packages/c1/d9/63e465c20f1388ec5b584412b6dc5ee96251dd80c0c2fe1fbefec5cb1283/lottery-ticket-pruner-0.8.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}