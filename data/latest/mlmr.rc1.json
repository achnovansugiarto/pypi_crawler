{
  "info": {
    "author": "Maksym Balatsko",
    "author_email": "mbalatsko@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.0",
      "Programming Language :: Python :: 3.1",
      "Programming Language :: Python :: 3.2",
      "Programming Language :: Python :: 3.3",
      "Programming Language :: Python :: 3.4",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7"
    ],
    "description": "# MLMR \n[![PyPI version](https://badge.fury.io/py/mlmr.svg)](https://badge.fury.io/py/mlmr)\n[![Downloads](https://pepy.tech/badge/mlmr)](https://pepy.tech/project/mlmr)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\nThis library will help you easily parallelize your python code for all kind of data transformations. \nCore functions are built on Map-Reduce paradigm. In this library Map part is parallelized using native \npython `multiprocessing` module.\n\n## Installation\n\n```bash\npip install mlmr\n```\n\n## Usage\n\nIn order to find out library API specification and advanced usage I recommend you to start with these short tutorials:\n\n1. [Functional API tutorial](https://github.com/mbalatsko/mlmr/blob/master/tutorials/Function%20tutorial.ipynb)\n1. [Sklearn integration tutorial](https://github.com/mbalatsko/mlmr/blob/master/tutorials/Sklearn%20integration%20tutorial.ipynb)\n\nHere I'll post several real world `mlmr` API applications.\n\n### Sum of squares in MapReduce fashion example\n\n```python\nimport numpy as np\nfrom mlmr.function import map_reduce\n\narr = [1, 2, 3, 4, 5]\n\ndef squares_of_slice(arr_slice): # our map function, with partial reduction\n    return sum(map(lambda x: x**2, arr_slice))\n\ndef get_split_data_func(n_slices): # wrapper function of split data function\n    def split_data(data):\n        return np.array_split(data, n_slices)\n    return split_data\n\nn_jobs = 2\n\nresult = map_reduce(\n    data=arr,\n    data_split_func=get_split_data_func(n_jobs), # split data into n_jobs slices\n    map_func=squares_of_slice,\n    reduce_func=sum,\n    n_jobs=n_jobs\n)\n```\n\n### Pandas apply parallelization in MapReduce fashion example\n\nIn this example function performs parallel data transformations on `df` (pd.DataFrame, pd.Series).\nFrom `n_jobs` argument, number of processes to run in parallel is calculated. Data is evenly divided into number \nof processes slices. Then `our_transform_func` is applied on each slice in parallel (every process has its own slice).\nAfter calculation is complete all transformation results are flattened. Flattened result is returned.\n\n```python\nfrom mlmr.function import transform_concat\n\ndef comutation_costly_transformation(*_):\n    pass\n\ndef our_transform_func(df):\n    return df.apply(cosly_computation_func)\n\ndf_transformed = transform_concat(df, transform_func=our_transform_func, n_jobs=-1)\n```\n\n### Sklearn MapReduce transformer integration into Pipeline\n\n```python\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom mlmr.transformers import BaseMapReduceTransformer\n\ndef comutation_costly_text_transformation(df):\n    pass\n\nclass TextPreprocessor(BaseMapReduceTransformer):\n    \n    def transform_part(self, X):\n        return comutation_costly_text_transformation(X)\n\nn_jobs = 4\n\ntext_classification_pipeline = Pipeline([\n     ('text_preprocessor', TextPreprocessor(n_jobs=n_jobs)),\n     ('vectorizer', TfidfVectorizer(analyzer = \"word\", max_features=10000)),\n     ('classifier', RandomForestClassifier(n_estimators=100, n_jobs=n_jobs))\n])\n```\n\nAlternative implementation:\n\n```python\nimport pandas as pd\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom mlmr.transformers import FunctionMapReduceTransformer\n\ndef get_split_data_func(n_slices): # wrapper function of split data function\n    def split_data(data):\n        return np.array_split(data, n_slices)\n    return split_data\n\ndef comutation_costly_text_transformation(df):\n    pass\n\nn_jobs = 4\n\ntext_classification_pipeline = Pipeline([\n     ('text_preprocessor', FunctionMapReduceTransformer(\n         map_func=comutation_costly_text_transformation,\n         reduce_func=pd.concat,\n         data_split_func=get_split_data_func(n_jobs),\n         n_jobs=n_jobs\n     )),\n     ('vectorizer', TfidfVectorizer(analyzer = \"word\", max_features=10000)),\n     ('classifier', RandomForestClassifier(n_estimators=100, n_jobs=n_jobs))\n])\n```",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "https://github.com/mbalatsko/mlmr/archive/1.0.0.tar.gz",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/mbalatsko/mlmr",
    "keywords": "mapreduce,parallel,transformation,ml,pandas",
    "license": "MIT License",
    "maintainer": "",
    "maintainer_email": "",
    "name": "mlmr",
    "package_url": "https://pypi.org/project/mlmr/",
    "platform": "",
    "project_url": "https://pypi.org/project/mlmr/",
    "project_urls": {
      "Download": "https://github.com/mbalatsko/mlmr/archive/1.0.0.tar.gz",
      "Homepage": "https://github.com/mbalatsko/mlmr"
    },
    "release_url": "https://pypi.org/project/mlmr/1.0.0/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "This library will help you easily parallelize your python code for all kind of data transformations.",
    "version": "1.0.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 7269116,
  "releases": {
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "03d8885f716a5033e83f8b49543f8dd1149f52921a89dac578ee01ba3934e8f6",
          "md5": "f149cd57955c2bc973bea427f5d98e03",
          "sha256": "b162a339ae06a8efe874ca37d140d802ff611933ea5ae259f3def23ba8cbc4fb"
        },
        "downloads": -1,
        "filename": "mlmr-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "f149cd57955c2bc973bea427f5d98e03",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 4628,
        "upload_time": "2020-05-18T15:16:07",
        "upload_time_iso_8601": "2020-05-18T15:16:07.676151Z",
        "url": "https://files.pythonhosted.org/packages/03/d8/885f716a5033e83f8b49543f8dd1149f52921a89dac578ee01ba3934e8f6/mlmr-1.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "03d8885f716a5033e83f8b49543f8dd1149f52921a89dac578ee01ba3934e8f6",
        "md5": "f149cd57955c2bc973bea427f5d98e03",
        "sha256": "b162a339ae06a8efe874ca37d140d802ff611933ea5ae259f3def23ba8cbc4fb"
      },
      "downloads": -1,
      "filename": "mlmr-1.0.0.tar.gz",
      "has_sig": false,
      "md5_digest": "f149cd57955c2bc973bea427f5d98e03",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 4628,
      "upload_time": "2020-05-18T15:16:07",
      "upload_time_iso_8601": "2020-05-18T15:16:07.676151Z",
      "url": "https://files.pythonhosted.org/packages/03/d8/885f716a5033e83f8b49543f8dd1149f52921a89dac578ee01ba3934e8f6/mlmr-1.0.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}