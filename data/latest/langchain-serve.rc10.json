{
  "info": {
    "author": "Jina AI",
    "author_email": "hello@jina.ai",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Environment :: Console",
      "Intended Audience :: Developers",
      "Intended Audience :: Education",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Topic :: Scientific/Engineering :: Artificial Intelligence"
    ],
    "description": "# LangChain Apps on Production with Jina ğŸš€\n\n[Jina](https://github.com/jina-ai/jina) is an open-source framework to build, deploy & manage machine learning applications at scale. [LangChain](https://python.langchain.com/en/latest/index.html) is another open-source framework for building applications powered by language models. \n\n**langchain-serve** helps you deploy your LangChain apps on Jina AI Cloud in just a matter of seconds. You can now benefit from the scalability and serverless architecture of the cloud without sacrificing the ease and convenience of local development.\n\n\n#### ğŸ‰ To production in 4 simple steps\n\n  1. Refactor your code to function(s) that should be served with `@serving` decorator.\n  1. Create a `requirements.txt` file in your app directory to ensure all necessary dependencies are installed.\n  1. Run `lc-serve deploy local app` to test your API locally.\n  1. Run `lc-serve deploy jcloud app` to deploy on Jina AI Cloud.\n\n\n#### ğŸ”¥ Scalable, Serverless RESTful APIs on Jina AI Cloud\n\n  - ğŸŒ RESTful APIs with TLS certs in just 2 lines of code change.\n  - ğŸ“„ Swagger UI, and OpenAPI spec included with your APIs.\n  - âš¡ï¸ Serverless apps that scales automatically with your traffic.\n  - ğŸ“Š Builtin logging, monitoring, and traces for your APIs.\n  - ğŸ¤– No need to change your code to manage APIs, or manage dockerfiles, or worry about infrastructure!\n\n\n#### ğŸš§ Coming soon\n\n- [ ] ğŸ”‘ Authorize API endpoints\n- [ ] ğŸ› ï¸ Enable Streamlit playground deployment for your apps\n\n\nIf you have any feature requests or faced any issue, please [let us know](https://github.com/jina-ai/langchain-serve/issues/new)!\n\n\n\n## Usage\n\nLet's first install `langchain-serve` using pip.\n\n```bash\npip install langchain-serve\n```\n\n## Example \n\n\nLet's build a custom agent using this example taken from [LangChain documentation](https://python.langchain.com/en/latest/modules/agents/agents/custom_agent.html). \n\n\n<details>\n<summary>Show agent code (app.py)</summary>\n\n```python\n# app.py\nfrom langchain.agents import ZeroShotAgent, Tool, AgentExecutor\nfrom langchain import OpenAI, SerpAPIWrapper, LLMChain\n\nsearch = SerpAPIWrapper()\ntools = [\n    Tool(\n        name = \"Search\",\n        func=search.run,\n        description=\"useful for when you need to answer questions about current events\"\n    )\n]\n\nprefix = \"\"\"Answer the following questions as best you can, but speaking as a pirate might speak. You have access to the following tools:\"\"\"\nsuffix = \"\"\"Begin! Remember to speak as a pirate when giving your final answer. Use lots of \"Args\"\n\nQuestion: {input}\n{agent_scratchpad}\"\"\"\n\nprompt = ZeroShotAgent.create_prompt(\n    tools, \n    prefix=prefix, \n    suffix=suffix, \n    input_variables=[\"input\", \"agent_scratchpad\"]\n)\n\nllm_chain = LLMChain(llm=OpenAI(temperature=0), prompt=prompt)\ntool_names = [tool.name for tool in tools]\nagent = ZeroShotAgent(llm_chain=llm_chain, allowed_tools=tool_names)\nagent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True)\nagent_executor.run(\"How many people live in canada as of 2023?\")\n```\n\n#### Output\n\n\n```text\n> Entering new AgentExecutor chain...\nThought: I need to find out the population of Canada\nAction: Search\nAction Input: Population of Canada 2023\nObservation: The current population of Canada is 38,610,447 as of Saturday, February 18, 2023, based on Worldometer elaboration of the latest United Nations data. Canada 2020 population is estimated at 37,742,154 people at mid year according to UN data.\nThought: I now know the final answer\nFinal Answer: Arrr, Canada be havin' 38,610,447 scallywags livin' there as of 2023!\n\n> Finished chain.\n```\n\n</details>\n\n### Step 1: \n\n**Refactor your code to function(s) that should be served with `@serving` decorator**\n\n\n<details>\n<summary>Show updated agent code (app.py)</summary>\n\n```python\n# app.py\nfrom langchain import LLMChain, OpenAI, SerpAPIWrapper\nfrom langchain.agents import AgentExecutor, Tool, ZeroShotAgent\n\nfrom lcserve import serving\n\n\n@serving\ndef ask(input: str) -> str:\n    search = SerpAPIWrapper()\n    tools = [\n        Tool(\n            name=\"Search\",\n            func=search.run,\n            description=\"useful for when you need to answer questions about current events\",\n        )\n    ]\n    prefix = \"\"\"Answer the following questions as best you can, but speaking as a pirate might speak. You have access to the following tools:\"\"\"\n    suffix = \"\"\"Begin! Remember to speak as a pirate when giving your final answer. Use lots of \"Args\"\n\n    Question: {input}\n    {agent_scratchpad}\"\"\"\n\n    prompt = ZeroShotAgent.create_prompt(\n        tools,\n        prefix=prefix,\n        suffix=suffix,\n        input_variables=[\"input\", \"agent_scratchpad\"],\n    )\n\n    print(prompt.template)\n\n    llm_chain = LLMChain(llm=OpenAI(temperature=0), prompt=prompt)\n    tool_names = [tool.name for tool in tools]\n    agent = ZeroShotAgent(llm_chain=llm_chain, allowed_tools=tool_names)\n\n    agent_executor = AgentExecutor.from_agent_and_tools(\n        agent=agent, tools=tools, verbose=True\n    )\n\n    return agent_executor.run(input)\n\nif __name__ == \"__main__\":\n    ask('How many people live in canada as of 2023?')\n```\n\n</details>\n\n\n##### What changed?\n\n- We moved our code to an `ask` function.\n- Added type hints to the function parameters (input and output), so API definition can be generated.\n- Imported `from lcserve import serving` and added `@serving` decorator to the `ask` function.\n- Added `if __name__ == \"__main__\":` block to test the function locally.\n\n---\n\n### Step 2:\n\n**Create a `requirements.txt` file in your app directory to ensure all necessary dependencies are installed.**\n\n<details>\n<summary>Show requirements.txt</summary>\n\n```text\n# requirements.txt\nopenai\ngoogle-search-results\n```\n</details>\n\n--- \n\n### Step 3:\n\n**Run `lc-serve deploy local app` to test your API locally.**\n\n> `app` is the name of the module that contains the `ask` function.\n\n```bash\nlc-serve deploy local app\n```\n\n<details>\n<summary>Show output</summary>\n\n```text\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ‰ Flow is ready to serve! â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ”— Endpoint â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\nâ”‚  â›“   Protocol                                         HTTP  â”‚\nâ”‚  ğŸ      Local                                 0.0.0.0:8080  â”‚\nâ”‚  ğŸ”’   Private                          192.168.29.185:8080  â”‚\nâ”‚  ğŸŒ    Public  2405:201:d007:e8e7:2c33:cf8e:ed66:2018:8080  â”‚\nâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\nâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ’ HTTP extension â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\nâ”‚  ğŸ’¬          Swagger UI        .../docs  â”‚\nâ”‚  ğŸ“š               Redoc       .../redoc  â”‚\nâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n```\n\n</details>\n\n\nLet's open the [Swagger UI](http://localhost:8080/docs) to test our API locally. With `Try it out` button, we can test our API with different inputs.\n\n\n<details>\n<summary>Show Swagger UI</summary>\n\n![Local Swagger UI](.github/images/local-swagger-ui.png)\n\n</details>\n\nLet's test our local API with `How many people live in canada as of 2023?` input with a cURL command.\n\n```bash\ncurl -X 'POST' \\\n  'http://localhost:8080/ask' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"input\": \"How many people live in canada as of 2023?\",\n  \"envs\": {\n    \"OPENAI_API_KEY\": \"'\"${OPENAI_API_KEY}\"'\",\n    \"SERPAPI_API_KEY\": \"'\"${SERPAPI_API_KEY}\"'\"\n  }\n}'\n```\n\n```json\n{\n  \"result\": \"Arrr, there be 38,645,670 people livin' in Canada as of 2023!\",\n  \"error\": \"\",\n  \"stdout\": \"Answer the following questions as best you can, but speaking as a pirate might speak. You have access to the following tools:\\n\\nSearch: useful for when you need to answer questions about current events\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [Search]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin! Remember to speak as a pirate when giving your final answer. Use lots of \\\"Args\\\"\\n\\n    Question: {input}\\n    {agent_scratchpad}\\n\\n\\n\\u001b[1m> Entering new AgentExecutor chain...\\u001b[0m\\n\\u001b[32;1m\\u001b[1;3m\\nThought: I need to find out how many people live in Canada\\nAction: Search\\nAction Input: How many people live in Canada as of 2023\\u001b[0m\\nObservation: \\u001b[36;1m\\u001b[1;3mThe current population of Canada is 38,645,670 as of Wednesday, March 29, 2023, based on Worldometer elaboration of the latest United Nations data.\\u001b[0m\\nThought:\\u001b[32;1m\\u001b[1;3m I now know the final answer\\nFinal Answer: Arrr, there be 38,645,670 people livin' in Canada as of 2023!\\u001b[0m\\n\\n\\u001b[1m> Finished chain.\\u001b[0m\"\n}\n```\n\n##### What happened?\n\n- `POST /ask` is generated from `ask` function defined in `app.py`.\n- `input` is an argrment defined in `ask` function. \n- `envs` is a dictionary of environment variables that will be passed to all the functions decorated with `@serving` decorator.\n- return type of `ask` function is `str`. So, `result` would carry the return value of `ask` function.\n- If there is an error, `error` would carry the error message.\n- `stdout` would carry the output of the function decorated with `@serving` decorator.\n\n\n---\n\n### Step 4:\n\n**Run `lc-serve deploy jcloud app` to deploy your API to Jina AI Cloud.**\n\n```bash\n# Login to Jina AI Cloud\njina auth login\n\n# Deploy your app to Jina AI Cloud\nlc-serve deploy jcloud app\n```\n\n<details>\n<summary>Show complete output</summary>\n\n```text\nâ ‡ Pushing `/tmp/tmp7kt5qqrn` ...ğŸ” You are logged in to Jina AI as ***. To log out, use jina auth logout.\nâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Published â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\nâ”‚                                                                â”‚\nâ”‚   ğŸ“› Name           n-64a15                                    â”‚\nâ”‚   ğŸ”— Jina Hub URL   https://cloud.jina.ai/executor/6p1zio87/   â”‚\nâ”‚   ğŸ‘€ Visibility     public                                     â”‚\nâ”‚                                                                â”‚\nâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\nâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ‰ Flow is available! â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\nâ”‚                                                                     â”‚\nâ”‚   ID               langchain-ee4aef57d9                             â”‚\nâ”‚   Gateway (Http)   https://langchain-ee4aef57d9-http.wolf.jina.ai   â”‚\nâ”‚   Dashboard        https://dashboard.wolf.jina.ai/flow/ee4aef57d9   â”‚\nâ”‚                                                                     â”‚\nâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n```\n</details>\n\n\n```text\nâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\nâ”‚ AppID        â”‚                    langchain-ee4aef57d9                     â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ Phase        â”‚                           Serving                           â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ Endpoint     â”‚       https://langchain-ee4aef57d9-http.wolf.jina.ai        â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ Swagger UI   â”‚     https://langchain-ee4aef57d9-http.wolf.jina.ai/docs     â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ OpenAPI JSON â”‚ https://langchain-ee4aef57d9-http.wolf.jina.ai/openapi.json â”‚\nâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n```\n\nLet's open the Swagger UI to test our API on Jina AI Cloud. With `Try it out` button, we can test our API with different inputs.\n\n<details>\n<summary>Show Swagger UI</summary>\n\n<p float=\"center\">\n  <img src=\".github/images/jcloud-swagger-ui.png\" width=\"400\" />\n  <img src=\".github/images/jcloud-openapi.png\" width=\"300\" />\n</p>\n\n</details>\n\n\nLet's test the API on JCloud with `How many people live in canada as of 2023?` input with a cURL command (Replace the Hostname with your own hostname):\n\n```bash\ncurl -X 'POST' \\\n  'https://langchain-ee4aef57d9-http.wolf.jina.ai/ask' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"input\": \"How many people live in canada as of 2023?\",\n  \"envs\": {\n    \"OPENAI_API_KEY\": \"'\"${OPENAI_API_KEY}\"'\",\n    \"SERPAPI_API_KEY\": \"'\"${SERPAPI_API_KEY}\"'\"\n  }\n}'\n```\n\n```json\n{\n  \"result\": \"Arrr, there be 38,645,670 people livin' in Canada as of 2023!\",\n  \"error\": \"\",\n  \"stdout\": \"Answer the following questions as best you can, but speaking as a pirate might speak. You have access to the following tools:\\n\\nSearch: useful for when you need to answer questions about current events\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [Search]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin! Remember to speak as a pirate when giving your final answer. Use lots of \\\"Args\\\"\\n\\n    Question: {input}\\n    {agent_scratchpad}\\n\\n\\n\\u001b[1m> Entering new AgentExecutor chain...\\u001b[0m\\n\\u001b[32;1m\\u001b[1;3m\\nThought: I need to find out how many people live in Canada\\nAction: Search\\nAction Input: How many people live in Canada as of 2023\\u001b[0m\\nObservation: \\u001b[36;1m\\u001b[1;3mThe current population of Canada is 38,645,670 as of Wednesday, March 29, 2023, based on Worldometer elaboration of the latest United Nations data.\\u001b[0m\\nThought:\\u001b[32;1m\\u001b[1;3m I now know the final answer\\nFinal Answer: Arrr, there be 38,645,670 people livin' in Canada as of 2023!\\u001b[0m\\n\\n\\u001b[1m> Finished chain.\\u001b[0m\"\n}\n```\n\n##### What happened?\n\n- In a matter of few seconds, we've deployed our API on Jina AI Cloud ğŸ‰\n- The API is serverless and scalable, so we can scale up the API to handle more requests. \n- You might observe a delay in the first request, that's due to the warm-up time of the API. Subsequent requests will be faster.\n- The API includes a Swagger UI and the OpenAPI specification, so it can be easily integrated with other services. \n- Now, other agents can integrate with your agents on Jina AI Cloud thanks to the [OpenAPI Agent](https://python.langchain.com/en/latest/modules/agents/toolkits/examples/openapi.html) ğŸ’¡\n\n\n\n---\n\n#### Reach out to us ğŸ“\n\n- Serverless is not your thing?\n- Do you want larger instances for your API?\n- Looking for file uploads, or other data-in, data-out features?\n- Do you want to setup custom authorization for your API?\n\n\nğŸ“£ Got your attention? [Join us on Slack](https://jina.ai/slack/) and we'd be happy to help you out.\n\n---\n\n\n### `lc-serve`\n\n`lc-serve` is a CLI tool that helps you to deploy your agents on Jina AI Cloud.\n\n\n| Description | Command | \n| --- | ---: |\n| Deploy your app locally | `lc-serve deploy local app` |\n| Deploy your app on Jina AI Cloud | `lc-serve deploy jcloud app` |\n| Update existing app on Jina AI Cloud | `lc-serve deploy jcloud app --app-id <app-id>` |\n| Get app status on Jina AI Cloud | `lc-serve status <app-id>` |\n| List all apps on Jina AI Cloud | `lc-serve list` |\n| Remove app on Jina AI Cloud | `lc-serve remove <app-id>` |\n\n\n---\n\n### Agents Playground ğŸ•¹ï¸ğŸ®ğŸŒ\n\n[LangChain agents](https://python.langchain.com/en/latest/modules/agents/getting_started.html) use LLMs to determine the actions to be taken in what order. An action can either be using a tool and observing its output, or returning to the user. We've hosted a **[Streamlit Playground](https://langchain.wolf.jina.ai/playground/)** on Jina AI Cloud to interact with the agents, which accepts with following inputs:\n\n- **[Agent Types](https://python.langchain.com/en/latest/modules/agents/agents.html):** Choose from different agent types that Langchain supports. \n\n- **[Tools](https://python.langchain.com/en/latest/modules/agents/tools.html):** Choose from different tools that Langchain supports. Some tools may require an API token or other related arguments.\n\nTo use the playground, simply type your input in the text box provided to get the agent's output and chain of thought. Enjoy exploring Langchain's capabilities! In addition to streamlit, you can also use our RESTful APIs on the playground to interact with the agents. \n\n\n### [Zero-shot React Description agent with SerpAPI and Calculator](https://python.langchain.com/en/latest/modules/agents/getting_started.html)\n\n#### Streamlit Playground\n\n![Streamlit Playground](.github/images/playground_one.gif)\n\n#### RESTful API\n\n```bash\nexport OPENAI_API_KEY=sk-***\nexport SERPAPI_API_KEY=***\n\ncurl -sX POST 'https://langchain.wolf.jina.ai/api/run' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  --data-raw '{\n    \"text\": \"Who is Leo DiCaprios girlfriend? What is her current age raised to the 0.43 power?\",\n    \"parameters\": {\n        \"tools\": {\n            \"tool_names\": [\"serpapi\", \"llm-math\"]\n        },\n        \"agent\": \"zero-shot-react-description\",\n        \"verbose\": true\n    },\n    \"envs\": {\n        \"OPENAI_API_KEY\": \"'\"${OPENAI_API_KEY}\"'\",\n        \"SERPAPI_API_KEY\": \"'\"${SERPAPI_API_KEY}\"'\"\n    }\n}' | jq\n``` \n\n```json\n{\n  \"result\": \"Camila Morrone is Leo DiCaprio's girlfriend, and her current age raised to the 0.43 power is 3.6261260611529527.\",\n  \"chain_of_thought\": \"\\u001b[1m> Entering new AgentExecutor chain...\\u001b[0m\\u001b[32;1m\\u001b[1;3m I need to find out the name of Leo's girlfriend and then use the calculator to calculate her age to the 0.43 power.Action: SearchAction Input: Leo DiCaprio girlfriend\\u001b[0mObservation: \\u001b[36;1m\\u001b[1;3mDiCaprio met actor Camila Morrone in December 2017, when she was 20 and he was 43. They were spotted at Coachella and went on multiple vacations together. Some reports suggested that DiCaprio was ready to ask Morrone to marry him. The couple made their red carpet debut at the 2020 Academy Awards.\\u001b[0mThought:\\u001b[32;1m\\u001b[1;3m I need to use the calculator to calculate her age to the 0.43 powerAction: CalculatorAction Input: 20^0.43\\u001b[0mObservation: \\u001b[33;1m\\u001b[1;3mAnswer: 3.6261260611529527\\u001b[0mThought:\\u001b[32;1m\\u001b[1;3m I now know the final answerFinal Answer: Camila Morrone is Leo DiCaprio's girlfriend, and her current age raised to the 0.43 power is 3.6261260611529527.\\u001b[0m\\u001b[1m> Finished chain.\\u001b[0m\"\n}\n```\n\n### [Self Ask With Search](https://python.langchain.com/en/latest/modules/agents/implementations/self_ask_with_search.html)\n\n#### Streamlit Playground\n\n![Streamlit Playground](.github/images/playground_two.gif)\n\n#### RESTful API\n\n```bash\nexport OPENAI_API_KEY=sk-***\nexport SERPAPI_API_KEY=***\n\ncurl -sX POST 'https://langchain.wolf.jina.ai/api/run' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  --data-raw '{\n    \"text\": \"What is the hometown of the reigning mens U.S. Open champion?\",\n    \"parameters\": {\n        \"tools\": {\n            \"tool_names\": [\"serpapi\"]\n        },\n        \"agent\": \"self-ask-with-search\",\n        \"verbose\": true\n    },\n    \"envs\": {\n        \"OPENAI_API_KEY\": \"'\"${OPENAI_API_KEY}\"'\",\n        \"SERPAPI_API_KEY\": \"'\"${SERPAPI_API_KEY}\"'\"\n    }\n}' | jq\n```\n\n```json\n{\n  \"result\": \"El Palmar, Murcia, Spain\",\n  \"chain_of_thought\": \"\\u001b[1m> Entering new AgentExecutor chain...\\u001b[0m\\u001b[32;1m\\u001b[1;3m Yes.Follow up: Who is the reigning mens U.S. Open champion?\\u001b[0mIntermediate answer: \\u001b[36;1m\\u001b[1;3mCarlos Alcaraz Garfia\\u001b[0m\\u001b[32;1m\\u001b[1;3mFollow up: What is Carlos Alcaraz Garfia's hometown?\\u001b[0mIntermediate answer: \\u001b[36;1m\\u001b[1;3mCarlos Alcaraz Garfia was born on May 5, 2003, in El Palmar, Murcia, Spain to parents Carlos Alcaraz GonzÃ¡lez and Virginia Garfia EscandÃ³n. He has three siblings.\\u001b[0m\\u001b[32;1m\\u001b[1;3mSo the final answer is: El Palmar, Murcia, Spain\\u001b[0m\\u001b[1m> Finished chain.\\u001b[0m\"\n}\n```\n\n---\n\n## Chains on Jina ğŸ“¦ğŸš€\n\n[Chains](https://python.langchain.com/en/latest/modules/chains/getting_started.html) in LangChain allow users to combine components to create a single, coherent application. With Jina, \n\n- You can expose your `Chain` as RESTful/gRPC/WebSocket API.\n- Enable `Chain`s to deploy & scale separately from the rest of your application with the help of Executors.\n- Deploy your `Chain` on Jina AI Cloud and get exclusive access to Agents on Jina AI Cloud (coming soon)\n\n### Examples\n\n| Example | LangChain Docs | Description |\n| ------- | ----------- | ----------- |\n| [LLM Chain](examples/llm_chain.md) | [Link](https://langchain.readthedocs.io/en/latest/modules/chains/getting_started.html#query-an-llm-with-the-llmchain) | Expose `Chain` as RESTful/gRPC/WebSocket API locally |\n| [Simple Sequential Chain](examples/simple_sequential_chain.md) | [Link](https://langchain.readthedocs.io/en/latest/modules/chains/generic/sequential_chains.html#simplesequentialchain) | Expose `Chain` as RESTful/gRPC/WebSocket API locally |\n| [Sequential Chain](examples/sequential_chain.md) | [Link](https://langchain.readthedocs.io/en/latest/modules/chains/generic/sequential_chains.html#sequential-chain) | Expose `Chain` as RESTful/gRPC/WebSocket API locally |\n| [LLM Math Chain](examples/llm_math.md) | [Link](https://langchain.readthedocs.io/en/latest/modules/chains/examples/llm_math.html) | Expose `Chain` as RESTful/gRPC/WebSocket API locally |\n| [LLM Requests Chain](examples/llm_requests_chain.md) | [Link](https://langchain.readthedocs.io/en/latest/modules/chains/examples/llm_requests.html) | Expose `Chain` as RESTful/gRPC/WebSocket API locally |\n| [Custom Chain](examples/custom_chain.md) | [Link](https://langchain.readthedocs.io/en/latest/modules/chains/getting_started.html#create-a-custom-chain-with-the-chain-class) | Expose `Chain` as RESTful/gRPC/WebSocket API locally |\n| [Sequential Chains](examples/sequential_executors.md) | N/A | Build & scale `Chains` in separate `Executor`s |\n| [Branching Chains](examples/branching.md) | N/A | Branching `Chains` in separate `Executor`s to allow parallel execution |",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "https://github.com/jina-ai/langchain-serve/tags",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/jina-ai/langchain-serve/",
    "keywords": "jina langchain llm neural-network deep-learning data democratization",
    "license": "Apache 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "langchain-serve",
    "package_url": "https://pypi.org/project/langchain-serve/",
    "platform": null,
    "project_url": "https://pypi.org/project/langchain-serve/",
    "project_urls": {
      "Documentation": "https://docs.jina.ai",
      "Download": "https://github.com/jina-ai/langchain-serve/tags",
      "Homepage": "https://github.com/jina-ai/langchain-serve/",
      "Source": "https://github.com/jina-ai/now",
      "Tracker": "https://github.com/jina-ai/now/issues"
    },
    "release_url": "https://pypi.org/project/langchain-serve/0.0.1/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "Langchain Serve - serve your langchain apps on Jina AI Cloud.",
    "version": "0.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17524556,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9aa6ed23c5c2b0717b32b830ec45b4a3ae32c1b9f97cf01a20db242612924ad3",
          "md5": "75817013f1daedd7dd88319c58dc1778",
          "sha256": "2c0c1e7fec968b90f63ce6c68440fabb96288d6969e90245d13944faae2b0a37"
        },
        "downloads": -1,
        "filename": "langchain-serve-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "75817013f1daedd7dd88319c58dc1778",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 31010,
        "upload_time": "2023-03-31T07:57:01",
        "upload_time_iso_8601": "2023-03-31T07:57:01.132499Z",
        "url": "https://files.pythonhosted.org/packages/9a/a6/ed23c5c2b0717b32b830ec45b4a3ae32c1b9f97cf01a20db242612924ad3/langchain-serve-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.1.dev1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1de48d03abe35c857c77ca9bde6f7d193192224948ad532aa74a442c51cb3c94",
          "md5": "8be680a286f862114b6e5e6d750defba",
          "sha256": "b803c45a15161957ab67b3a298bfc6294b2968860ccf6b68b53e3ab5bc41b2eb"
        },
        "downloads": -1,
        "filename": "langchain-serve-0.0.1.dev1.tar.gz",
        "has_sig": false,
        "md5_digest": "8be680a286f862114b6e5e6d750defba",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 23007,
        "upload_time": "2023-03-30T12:18:26",
        "upload_time_iso_8601": "2023-03-30T12:18:26.390590Z",
        "url": "https://files.pythonhosted.org/packages/1d/e4/8d03abe35c857c77ca9bde6f7d193192224948ad532aa74a442c51cb3c94/langchain-serve-0.0.1.dev1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.1.dev10": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b03793c3f31a35c0d29b04e96c61a44bd9c8233e7ca0669a5180399ef617ef8c",
          "md5": "0eaccdad224279cd6bcd4b41c70234c2",
          "sha256": "2484ed2a02e832157b2e1d838f966df9167b09982336a3eebb626c64518c84e9"
        },
        "downloads": -1,
        "filename": "langchain-serve-0.0.1.dev10.tar.gz",
        "has_sig": false,
        "md5_digest": "0eaccdad224279cd6bcd4b41c70234c2",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 29871,
        "upload_time": "2023-03-31T02:27:09",
        "upload_time_iso_8601": "2023-03-31T02:27:09.447548Z",
        "url": "https://files.pythonhosted.org/packages/b0/37/93c3f31a35c0d29b04e96c61a44bd9c8233e7ca0669a5180399ef617ef8c/langchain-serve-0.0.1.dev10.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.1.dev11": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ede29c0f2a2828240d6bcc70dfb66fbdbe4b11ff92cf8a00a018576a6af18628",
          "md5": "407988be753d26c84df229a20d8a5b26",
          "sha256": "7925048a9e4345b209f900ab007a1495e84500d9b581cf89ed723eea98424e4f"
        },
        "downloads": -1,
        "filename": "langchain-serve-0.0.1.dev11.tar.gz",
        "has_sig": false,
        "md5_digest": "407988be753d26c84df229a20d8a5b26",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 29883,
        "upload_time": "2023-03-31T02:39:02",
        "upload_time_iso_8601": "2023-03-31T02:39:02.997936Z",
        "url": "https://files.pythonhosted.org/packages/ed/e2/9c0f2a2828240d6bcc70dfb66fbdbe4b11ff92cf8a00a018576a6af18628/langchain-serve-0.0.1.dev11.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.1.dev12": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "362f9844e57c62136a174033531977d8e3d818d7abe4b8d2deb7de6cf37c1055",
          "md5": "5f5748fafd5f1fdd505a7d61d8adf2a0",
          "sha256": "772cfe16298de621c01e5642d9bfd6ad6b31eabc818da35ee4a456bdf9ee216a"
        },
        "downloads": -1,
        "filename": "langchain-serve-0.0.1.dev12.tar.gz",
        "has_sig": false,
        "md5_digest": "5f5748fafd5f1fdd505a7d61d8adf2a0",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 29892,
        "upload_time": "2023-03-31T03:05:29",
        "upload_time_iso_8601": "2023-03-31T03:05:29.235188Z",
        "url": "https://files.pythonhosted.org/packages/36/2f/9844e57c62136a174033531977d8e3d818d7abe4b8d2deb7de6cf37c1055/langchain-serve-0.0.1.dev12.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.1.dev6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "42311bf55bdf10708e56cc908b8ec794a6bdf0ed0389de036f0f828ca6751131",
          "md5": "574f939324042f9a3d4d17bab8897e96",
          "sha256": "76d26ca1b3104d53570d2103f0298b6fcaf07aafc7187c4c50b5d0084f3be740"
        },
        "downloads": -1,
        "filename": "langchain-serve-0.0.1.dev6.tar.gz",
        "has_sig": false,
        "md5_digest": "574f939324042f9a3d4d17bab8897e96",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 27483,
        "upload_time": "2023-03-31T01:48:30",
        "upload_time_iso_8601": "2023-03-31T01:48:30.452440Z",
        "url": "https://files.pythonhosted.org/packages/42/31/1bf55bdf10708e56cc908b8ec794a6bdf0ed0389de036f0f828ca6751131/langchain-serve-0.0.1.dev6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.1.dev7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0cc818b420175bf3054813c2baf6188a2f81427736ec1a794a7822b7ff72cf88",
          "md5": "7a8bb4d46afeafe62d57bac541cea595",
          "sha256": "0d611bab2e6836eb9e394d9c1a06a1620dcd05f89303f12235ed2aafdebf2bdb"
        },
        "downloads": -1,
        "filename": "langchain-serve-0.0.1.dev7.tar.gz",
        "has_sig": false,
        "md5_digest": "7a8bb4d46afeafe62d57bac541cea595",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 27491,
        "upload_time": "2023-03-31T01:48:56",
        "upload_time_iso_8601": "2023-03-31T01:48:56.028996Z",
        "url": "https://files.pythonhosted.org/packages/0c/c8/18b420175bf3054813c2baf6188a2f81427736ec1a794a7822b7ff72cf88/langchain-serve-0.0.1.dev7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.1.dev8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9819510ef680b097c79c8738f50234b6b68f39933c06eb92ba29adeec22c116b",
          "md5": "5b8a37bbc2656f9f0c2af03429e7710b",
          "sha256": "24cd69e4f63e77413914bd828d7108771459145f170c4e5ccfcbff76f9ff01f2"
        },
        "downloads": -1,
        "filename": "langchain-serve-0.0.1.dev8.tar.gz",
        "has_sig": false,
        "md5_digest": "5b8a37bbc2656f9f0c2af03429e7710b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 27488,
        "upload_time": "2023-03-31T01:57:18",
        "upload_time_iso_8601": "2023-03-31T01:57:18.166685Z",
        "url": "https://files.pythonhosted.org/packages/98/19/510ef680b097c79c8738f50234b6b68f39933c06eb92ba29adeec22c116b/langchain-serve-0.0.1.dev8.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.1.dev9": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6afff464c67063bee03d16601d07201a27fdae3417d19a06ebb1b2461606f8bd",
          "md5": "63dd3e46f90c57afa3bde8fe541e07c0",
          "sha256": "967e64b3585d415404754e06438d3072b35b023484d99556dd82b0269b90ba5d"
        },
        "downloads": -1,
        "filename": "langchain-serve-0.0.1.dev9.tar.gz",
        "has_sig": false,
        "md5_digest": "63dd3e46f90c57afa3bde8fe541e07c0",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 29844,
        "upload_time": "2023-03-31T02:16:38",
        "upload_time_iso_8601": "2023-03-31T02:16:38.202836Z",
        "url": "https://files.pythonhosted.org/packages/6a/ff/f464c67063bee03d16601d07201a27fdae3417d19a06ebb1b2461606f8bd/langchain-serve-0.0.1.dev9.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2.dev3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "892de721ce5ad764baad677d9910eba631c4936be141df4364f2f2bce59776ac",
          "md5": "87d7e2a40710bbed97a31725819f276b",
          "sha256": "42a815d08bc5ef4744758786d962e8c8672af6e9d8594146dbe0e42f236a5e5c"
        },
        "downloads": -1,
        "filename": "langchain-serve-0.0.2.dev3.tar.gz",
        "has_sig": false,
        "md5_digest": "87d7e2a40710bbed97a31725819f276b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 29900,
        "upload_time": "2023-03-31T09:46:38",
        "upload_time_iso_8601": "2023-03-31T09:46:38.132991Z",
        "url": "https://files.pythonhosted.org/packages/89/2d/e721ce5ad764baad677d9910eba631c4936be141df4364f2f2bce59776ac/langchain-serve-0.0.2.dev3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "9aa6ed23c5c2b0717b32b830ec45b4a3ae32c1b9f97cf01a20db242612924ad3",
        "md5": "75817013f1daedd7dd88319c58dc1778",
        "sha256": "2c0c1e7fec968b90f63ce6c68440fabb96288d6969e90245d13944faae2b0a37"
      },
      "downloads": -1,
      "filename": "langchain-serve-0.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "75817013f1daedd7dd88319c58dc1778",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 31010,
      "upload_time": "2023-03-31T07:57:01",
      "upload_time_iso_8601": "2023-03-31T07:57:01.132499Z",
      "url": "https://files.pythonhosted.org/packages/9a/a6/ed23c5c2b0717b32b830ec45b4a3ae32c1b9f97cf01a20db242612924ad3/langchain-serve-0.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}