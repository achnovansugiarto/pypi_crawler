{
  "info": {
    "author": "APUSIC",
    "author_email": "464521059@qq.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "## \n# 数据智脑计算引擎dataprime\n\n\ndataprime是一款数据计算引擎，提供了数据钻取、过滤、生成、采样、聚合、排序等功能，输入dataframe对象，调用不同方法，即可返回相应的结果, 并且可以结合celery进行异步调用\n​\n\n## 一 快速开始\n\n- 安装\n\n`pip install dataprime`\n\n- 使用\n```python\nimport json\n\nfrom dataprime.dataprime import DataPrime\nimport pandas as pd\n\n# 准备数据\ndata = [\n        {\"name\": \"test1\", \"time\": \"2021-01-05\", \"score\": 10},\n        {\"name\": \"test2\", \"time\": \"2021-01-12\", \"score\": 20},\n        {\"name\": \"test3\", \"time\": \"2021-01-24\", \"score\": 30}\n]\n\n# 过滤参数\nfilter_list = [\n    {\n        \"column\": \"score\",\n        \"dtype\": \"int\",\n        \"filter\": {\n            \"condition\": \"greater_than\",\n            \"value\": \"10\",\n            \"max\": 0,\n            \"min\": 0\n        }\n    }\n]\n\ndata_frame = pd.read_json(json.dumps(data))\n\n# 初始化一个DataPrime对象\ndp = DataPrime(dataframe=data_frame)\n\n# 调用方法进行处理, 返回一个dataframe对象\nresult = dp.filter(filter_list).dataframe\n\nprint(result)\n```\n​\n\n## 二 使用文档\n### 1.钻取 Drill\n钻取是以一个时间字段为维度，将数据按年、月、日进行细分\n​\n\n\n- 参数字段\n\n`drill_granularity_list` 钻取粒度列表，包含年、月、日\n`drill_node_list` 钻取节点列表\n`dimensions` 钻取字段\n​\n\n\n- 参数示例:\n```python\ndrill_granularity_list = [\n    {\n        \"value\": \"YEAR\",\n        \"label\": \"年\"\n    },\n    {\n        \"value\": \"MONTH\",\n        \"label\": \"月\"\n    },\n    {\n        \"value\": \"DAY\",\n        \"label\": \"日\"\n    }\n]\n\ndrill_node_list = [\n    {\n        \"granularity\": \"\",\n        \"point\": \"YEAR\",\n    },\n    {\n        \"granularity\": \"YEAR\",\n        \"point\": \"2021\",\n    },\n    {\n        \"granularity\": \"MONTH\",\n        \"point\": \"01\",\n    }\n]\n\ndimensions = [\n    {\n        \"column\": \"time\",\n        \"dtype\": \"datetime\",\n    }\n]\n```\n\n\n- 使用示例\n```python\nresult = dp.drill(drill_granularity_list, drill_node_list, dimensions).dataframe\n```\n\n\n### 2.过滤 Filter\n过滤是根据某一个度量字段，通过一定条件来筛选需要的数据\n\n\n- 参数示例\n```python\nfilter_list = [\n    {\n        \"column\": \"score\",             # 过滤字段\n        \"dtype\": \"int\",                # 字段类型\n        \"filter\": {\n            \"condition\": \"less_than\",  # 过滤条件\n            \"value\": \"100\",            # 过滤值\n            \"max\": 50,                 # 最大值, 区间判断时用到\n            \"min\": 0                   # 最小值, 区间判断时用到\n        }\n    }\n]\n```\n\n\n- 使用示例\n```python\nresult = dp.filter(filter_list).dataframe\n```\n\n\n- condition选项\n\n| **条件** | **值** |\n| --- | --- |\n| 等于 | equal |\n| 不等于 | not_equal |\n| 区间内 | in_between |\n| 区间外 | out_between |\n| 大于 | greater_than |\n| 大于等于 | equal_greater_than |\n| 小于 | less_than |\n| 小于等于 | equal_less_than |\n| 包含 | contains |\n| 不包含 | not_contains |\n\n\n\n### 3.生成器 Generator\n生成器是在dataframe中新增一列，提供求和、求平均值、计算行等结果，例如有a、b两列，可以通过生成器生成\"a-b-平均值\"列\n​\n\n\n- 参数示例\n```python\ngenerated_metric_list = [\n    {\n        \"dtype\": \"float\",\n        \"operate\": {\n            \"label\": \"均值\",\n            \"value\": \"Avg\"          # 生成类型\n        },\n        \"source_col_list\": [        # 源数据列\n            {\n                \"column\": \"age\",\n                \"dtype\": \"int\"\n            },\n            {\n                \"column\": \"score\",\n                \"dtype\": \"int\"\n            }\n        ],\n        \"column\": \"age-score-均值\"  # 生成列名称\n    }\n]\n```\n\n- 使用示例\n```python\nresult = dp.generate(generated_metric_list).dataframe\n```\n\n- 生成类型\n\n| **生成类型** | **值value** |\n| --- | --- |\n| 平均值 | Avg |\n| 求和 | Sum |\n| 计算行 | COUNT_COL |\n\n\n\n### 4.采样 Sampling\n采样是指通过`等距采样`、`随机采样`等方式，对数据进行采样，获取一定数量的行\n​\n\n\n- 参数示例\n```python\nsample = {\n    \"number\": 5,      # 采样数量\n    \"type\": \"random\"  # 采样方式, 随机:random  等距:equidistant\n}\n```\n\n- 使用示例\n```python\nresult = dp.sample(5, \"random\").dataframe\n```\n\n\n### 5.聚合 Aggregate\n聚合是对数值(度量)列进行聚合，可以进行计数、求和、求平均值等聚合操作\n​\n\n\n- 参数示例\n```python\naggregation_list = [\n    {\n        \"column\": \"age\",          # 源数据列\n        \"dtype\": \"int\",\n        \"aggregation_option\": {\n            \"label\": \"均值\",\n            \"value\": \"mean\"       # 聚合方法\n        }\n    },\n    {\n        \"column\": \"score\",\n        \"dtype\": \"int\",\n        \"aggregation_option\": {\n            \"label\": \"均值\",\n            \"value\": \"mean\"\n        }\n    }\n]\n```\n\n- 可用的聚合方法\n\n['count', 'sum', 'mean', 'median', 'std', 'var', 'max', 'min']\n​\n\n\n- 使用示例\n```python\nresult = dp.aggregate(aggregation_list).dataframe\n```\n\n\n### 6.排序 Sorting\n排序是根据某一个数据列进行升降排序\n​\n\n\n- 参数示例\n```python\nsort = {\n\t\"condition\": \"desc\",  # 升序:desc  降序:asc\n    \"column\": \"time\"      # 排序字段\n}\n```\n\n- 使用示例\n```python\nresult = dp.order_by(\"time\", \"desc\").dataframe\n```\n\n\n### 7.top N\ntop N是指按照某一列的值进行排序，取出前几行\n​\n\n\n- 参数示例\n```python\ntop_n_param = {\n    \"column\": \"score\",     # 排序字段\n    \"condition\": \"desc\",   # 排序方式， 升序:desc  降序:asc\n    \"limit\": 3             # 取出数量\n}\n```\n\n\n- 使用示例\n```python\nresult = dp.top_n(\"score\", \"desc\", 3).dataframe\n```\n### \n### 8.统一入口\n除了上述的单个方法外，也可以使用`dataprime.process_df_operator()`来同时进行多个数据处理操作,参数字段与上面相同\n​\n\n\n- 使用示例\n```python\ndataprime = DataPrime(\n    dataframe=data_frame,\n    **{\n        \"dimensions\": dimension_list,\n        \"metrics\": metric_list,\n        \"calculation_flow_nodes\": calculation_flow_nodes,\n        \"generated_metric_list\": generated_metric_list,\n        \"filter_list\": filter_list,\n        \"aggregation_list\": aggregation_list,\n        \"sample\": sample,\n        \"drill_granularity_list\": drill_granularity_list,\n        \"drill_node_list\": drill_node_list,\n        \"sort\": sort_param,\n        \"topn\": top_n_param\n    }\n)\n\nresult = dataprime.process_df_operator()\n```\n- calculation_flow_nodes为计算节点列表, 可选值有:\n\n  `DRILLING` 钻取\n\n  `SAMPLING` 采样\n  \n  `FILTER` 过滤\n  \n  `AGGREGATION` 聚合\n  \n  例如需要钻取、采样两种计算，则`calculation_flow_nodes=[\"DRILLING\", \"SAMPLING\"]`, 同时也需要传递这２个计算节点对应的参数`drill_node_list` `drill_granularity_list` `filter_list`. 使用多个计算节点时, 按照列表中元素的先后顺序来依次调用\n\n### 9.链式调用\n上述的单个数据处理方法可以进行链式调用，如:\n\n`result = dp.order_by(\"time\", \"desc\").sample(5, \"random\").dataframe`\n\n## 三 异步调用\n`dataprime`可以结合`celery`进行异步调用, 主要通过`AsyncDataprime`提供的接口来调用, 其方法名称与同步调用时一致, 返回结果为celery任务的id,使用示例如下:\n\n- 初始化celery工程文件\n\n  执行以下代码\n  ```python\n  from dataprime.dataprime import DataPrime\n\n  dp = DataPrime()\n  dp.init_celery()\n  ```\n  将会在当前目录下生成 `dataprime_celery`文件夹, 包含以下文件：\n  \n  `celery_app.py` celery主入口文件\n  \n  `config.py` celery配置文件, 需要手动配置broker_url和result_backend\n  \n  `task.py` celery任务文件\n  \n- celery的其余使用配置参考其官方文档:\n  \n  https://docs.celeryproject.org/en/stable/\n  \n- 启动celery worker\n  \n  配置好celery的broker, backend等配置之后，执行以下命令启动\n  \n  `celery -A dataprime_celery.celery_app worker -l INFO`\n  \n- 发送异步任务请求\n　\n```python\nfrom async_dataprime.executor import AsyncDataPrime\n\n# 初始化\ndataframe=\"A dataframe object\"\nadp = AsyncDataPrime()\n\nfilter_list = [\n    {\n        \"column\": \"score\",\n        \"dtype\": \"int\",\n        \"filter\": {\n            \"condition\": \"greater_than\",\n            \"value\": \"10\",\n            \"max\": 0,\n            \"min\": 0\n        }\n    }\n]\n\n# 调用方法进行处理, 返回异步任务的任务id\n# 异步任务的方法和同步调用时的方式名称一致,调用对象换成了AsyncDataPrime对象\ntask_id = adp.filter(dataframe=dataframe, filter_list=filter_list)\nprint(task_id)\n```\n\n- 获取结果\n\n　　异步任务的结果是以json的格式存储在事先配置的redis backend中, 通过task_id即可获取:\n```python\n# 执行任务\nadp = AsyncDataPrime()\ntask_id = adp.filter(data_frame, filter_list)\n\n# 等待任务完成\n\n# 获取结果, datatype可选\"json\"或\"dataframe\"\nres = adp.get_async_result(task_id, data_type=\"dataframe\")\nprint(res)\n```\n   \n  \n## 四 开源协议\n\n  本项目采用 `木兰宽松许可证`\n\n  http://license.coscl.org.cn/MulanPSL2/",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "dataframe,pandas",
    "license": "Mulan PSL v2",
    "maintainer": "",
    "maintainer_email": "",
    "name": "dataprime",
    "package_url": "https://pypi.org/project/dataprime/",
    "platform": "any",
    "project_url": "https://pypi.org/project/dataprime/",
    "project_urls": {
      "Source": "https://gitee.com/apusic/dataprime"
    },
    "release_url": "https://pypi.org/project/dataprime/0.1.9/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "数据智脑开源计算引擎dataprime",
    "version": "0.1.9",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12057754,
  "releases": {
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "95e47869cb7619bb5d42c42401a5f76efaa44de83406c51a5507579b28474f9c",
          "md5": "66cd5f876097fa671c9635e6279a3cfb",
          "sha256": "de0ed7e390af3c658ce2bc6af2146be39a431335276adfa607d8ca2031332462"
        },
        "downloads": -1,
        "filename": "dataprime-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "66cd5f876097fa671c9635e6279a3cfb",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 11986,
        "upload_time": "2021-11-10T09:50:48",
        "upload_time_iso_8601": "2021-11-10T09:50:48.612512Z",
        "url": "https://files.pythonhosted.org/packages/95/e4/7869cb7619bb5d42c42401a5f76efaa44de83406c51a5507579b28474f9c/dataprime-0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7d4e01cfd3b7678a0a4ec8880537b1b1f4ac4d3561f6f21853de53fe4692fb3f",
          "md5": "9dd119736c24eff33f6ff0071a77ef03",
          "sha256": "5d0de844a367ef25e800bd793134f5cb30dcec881119da3aff97c7b3ad640d7c"
        },
        "downloads": -1,
        "filename": "dataprime-0.1.4.tar.gz",
        "has_sig": false,
        "md5_digest": "9dd119736c24eff33f6ff0071a77ef03",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 11705,
        "upload_time": "2021-11-11T01:52:01",
        "upload_time_iso_8601": "2021-11-11T01:52:01.549666Z",
        "url": "https://files.pythonhosted.org/packages/7d/4e/01cfd3b7678a0a4ec8880537b1b1f4ac4d3561f6f21853de53fe4692fb3f/dataprime-0.1.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5237a6617dff44b665c62aa59a283b8f2f99183324e783117da7980f49e246c5",
          "md5": "eef24425b5b4c7c87a4408d9f0b0f1c8",
          "sha256": "57f0d4a42f4e7556841f30a7d19b4506bc04175341ee2a775e7c6fcc5b82e422"
        },
        "downloads": -1,
        "filename": "dataprime-0.1.5.tar.gz",
        "has_sig": false,
        "md5_digest": "eef24425b5b4c7c87a4408d9f0b0f1c8",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 12982,
        "upload_time": "2021-11-11T02:18:52",
        "upload_time_iso_8601": "2021-11-11T02:18:52.133288Z",
        "url": "https://files.pythonhosted.org/packages/52/37/a6617dff44b665c62aa59a283b8f2f99183324e783117da7980f49e246c5/dataprime-0.1.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "099ede86dae036d795d3ba485f27af342d9d42c241dc8d8bd5ac57406794f5ec",
          "md5": "4f79fa60ae0bfccc94e4af99ff54cb2f",
          "sha256": "b9f94834d9cf4073e8d341805ec4b723e9e9629bf50f41f2bd61aa932fb297c8"
        },
        "downloads": -1,
        "filename": "dataprime-0.1.6.tar.gz",
        "has_sig": false,
        "md5_digest": "4f79fa60ae0bfccc94e4af99ff54cb2f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 13763,
        "upload_time": "2021-11-11T02:29:58",
        "upload_time_iso_8601": "2021-11-11T02:29:58.378556Z",
        "url": "https://files.pythonhosted.org/packages/09/9e/de86dae036d795d3ba485f27af342d9d42c241dc8d8bd5ac57406794f5ec/dataprime-0.1.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b9e0d5f1197c2d1a585e835cd9a5640955a3c23efd5c6583aae543f5f11f84f9",
          "md5": "36460ec61b1146bbed16bc5ac47dcb5d",
          "sha256": "01e7859c4f6528daaae252fc6327bffdf311a3b8010bf1eec88a6cdcb63633fa"
        },
        "downloads": -1,
        "filename": "dataprime-0.1.7.tar.gz",
        "has_sig": false,
        "md5_digest": "36460ec61b1146bbed16bc5ac47dcb5d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 14101,
        "upload_time": "2021-11-11T02:43:29",
        "upload_time_iso_8601": "2021-11-11T02:43:29.368794Z",
        "url": "https://files.pythonhosted.org/packages/b9/e0/d5f1197c2d1a585e835cd9a5640955a3c23efd5c6583aae543f5f11f84f9/dataprime-0.1.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c3f3b38d040c533d324b8d91c7e6a15aff4a57207f090e0f9f1d563ed7a8c997",
          "md5": "da2306a631477db44d4cc7ba691ef51c",
          "sha256": "de2e084a69127bb0e8deccf84eab442cf5e3336aeab87b922e1f1e631e900b83"
        },
        "downloads": -1,
        "filename": "dataprime-0.1.8.tar.gz",
        "has_sig": false,
        "md5_digest": "da2306a631477db44d4cc7ba691ef51c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 15881,
        "upload_time": "2021-11-11T06:41:57",
        "upload_time_iso_8601": "2021-11-11T06:41:57.206595Z",
        "url": "https://files.pythonhosted.org/packages/c3/f3/b38d040c533d324b8d91c7e6a15aff4a57207f090e0f9f1d563ed7a8c997/dataprime-0.1.8.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.9": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c548ceb5cd698c52b72554722ef94e4c64909b030eb7b1001471ee1eb04ac478",
          "md5": "14d49b2898628511f72ca316794b3410",
          "sha256": "7b8c7355443b97f10da3af1f2d3d4707d85e101fa3af13ff070c317f893b772e"
        },
        "downloads": -1,
        "filename": "dataprime-0.1.9.tar.gz",
        "has_sig": false,
        "md5_digest": "14d49b2898628511f72ca316794b3410",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 17480,
        "upload_time": "2021-11-18T10:12:12",
        "upload_time_iso_8601": "2021-11-18T10:12:12.506790Z",
        "url": "https://files.pythonhosted.org/packages/c5/48/ceb5cd698c52b72554722ef94e4c64909b030eb7b1001471ee1eb04ac478/dataprime-0.1.9.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "c548ceb5cd698c52b72554722ef94e4c64909b030eb7b1001471ee1eb04ac478",
        "md5": "14d49b2898628511f72ca316794b3410",
        "sha256": "7b8c7355443b97f10da3af1f2d3d4707d85e101fa3af13ff070c317f893b772e"
      },
      "downloads": -1,
      "filename": "dataprime-0.1.9.tar.gz",
      "has_sig": false,
      "md5_digest": "14d49b2898628511f72ca316794b3410",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 17480,
      "upload_time": "2021-11-18T10:12:12",
      "upload_time_iso_8601": "2021-11-18T10:12:12.506790Z",
      "url": "https://files.pythonhosted.org/packages/c5/48/ceb5cd698c52b72554722ef94e4c64909b030eb7b1001471ee1eb04ac478/dataprime-0.1.9.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}