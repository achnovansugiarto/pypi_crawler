{
  "info": {
    "author": "Souvik Pratiher",
    "author_email": "spratiher9@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "[comment]: <> (<a href=\"https://ibb.co/jhTdDPZ\"><img src=\"https://i.ibb.co/6Ym2F7J/xLogs.gif\" alt=\"Exelog: Meticulous logging for Apache Spark\" border=\"0\"></a>)\n\n![Exelog: Meticulous logging for Apache Spark](https://raw.githubusercontent.com/Spratiher9/Files/master/xLogs.gif)\n\n[comment]: <> (![PyPI - Python Version]&#40;https://img.shields.io/pypi/pyversions/exelog&#41;)\n\n[comment]: <> ([![PyPI]&#40;https://img.shields.io/pypi/v/exelog&#41;]&#40;https://pypi.org/project/exelog/&#41;)\n\n# Exelog: Meticulous logging for Apache Spark\n\n### _Enabling meticulous logging for Spark Applications_\n\n`Exelog` is a refactored logging module that provides a decorator based approach to ensure standard Python logging from\nPySpark Executor nodes also.\n\n## Why?\n\n### _The problem: logging from Spark executors doesn't work with normal logging_\n\nIn Apache Spark, the actual data processing is done in what's called \"executors\", which are separate processes that are\nseparate from the \"driver\" program. For end users, full control is only over the driver process, but not so much over\nthe executor processes.\n\nFor example, in the PySpark driver program we can set up standard python logging as desired, but this setup is not\nreplicated in the executor processes. There are no out-of-the-box logging handlers for executors, so all logging\nmessages from executors are lost. Since Python 3.2 however, when there are no handlers, there is still a \"improvised\"\nhandler that will show `warning()` and `error()` messages in their bare format on standard error, but for proper logging\nwe probably need something more flexible and powerful than that.\n\nIllustration in interactive PySpark shell:\n\n    >>> import os, logging\n    >>> logging.basicConfig(level=logging.INFO)\n    \n    >>> def describe():\n    ...     return \"pid: {p}, root handlers: {h}\".format(p=os.getpid(), h=logging.root.handlers)\n    ... \n    >>> describe()\n    'pid: 8915, root handlers: [<StreamHandler <stderr> (NOTSET)>]'\n\n    >>> sc.parallelize([4, 1, 7]).map(lambda x: describe()).collect()\n    ['pid: 9111, root handlers: []', 'pid: 9128, root handlers: []', 'pid: 9142, root handlers: []']\n\nThe initial `describe()` happens in the driver and has root handlers because of the `basicConfig()` beforehand. However,\nthe `describe()` calls in the `map()` happen in separate executor processes (note the different PIDs) and got no root\nhandlers.\n\n## Exelog: Logging Spark executor execution one decorator at a time\n\nVarious ways for setting up logging for executors may be found on the internet. It usually entails sending and loading a\nseparate file containing logging configuration code. Depending on the use case, managing this file may be difficult. One\nof the approaches\nis [here](https://community.cloudera.com/t5/Support-Questions/Logging-from-Pyspark-executor/td-p/212210)\n\nIn contrast, `Exelog` takes a decorator based approach. We just have to decorate the data processing functions which we\nare passing to `map()`, `filter()`, `sortBy()`, etc.\n\nA very minimal example:\n\n    @exelog.enable_info_logging\n    def process(x):\n        logger.info(\"Got {x}\".format(x=x))\n        return x * x\n    \n    result = rdd.map(process).collect()\n\nWhat will happen here is that the first time `process()` is called in the executor, basic logging is set up with `INFO`\nlevel, so that logging messages are not lost.\n\n### Options and finetuning\n\nThe `enable_exelog` decorator will do a basic logging setup using\n[`logging.basicConfig()`](https://docs.python.org/3/library/logging.html#logging.basicConfig), and desired options can\nbe directly provided to the decorator as illustrated in the following example using the interactive PySpark shell:\n\n    >>> import logging\n    >>> from exelog import enable_exelog\n    >>> logger = logging.getLogger(\"example\")\n    \n    >>> @enable_exelog(level=logging.INFO)\n    ... def process(x):\n    ...     logger.info(\"Got {x}\".format(x=x))\n    ...     return x * x\n    ... \n    >>> sc.parallelize(range(5)).map(process).collect()\n    INFO:example:Got 0\n    INFO:example:Got 1\n    INFO:example:Got 3\n    INFO:example:Got 2\n    INFO:example:Got 4\n    [0, 1, 4, 9, 16]\n\nTo improve readability or code reuse, you can of course predefine decorators:\n\n    with_logging = enable_exelog(\n        level=logging.INFO,\n        format=\"[%(process)s/%(name)s] %(levelname)s %(message)s\"\n    )\n    \n    @with_logging\n    def process(x):\n        ...\n\n`exelog` also defines some simple predefined decorators:\n\n    # Predefined decorator for stderr/NOTSET logging\n    enable_notset_logging = enable_exelog(level=logging.NOTSET)\n    \n    # Predefined decorator for stderr/DEBUG logging\n    enable_debug_logging = enable_exelog(level=logging.DEBUG)\n    \n    # Predefined decorator for stderr/INFO logging\n    enable_info_logging = enable_exelog(level=logging.INFO)\n    \n    # Predefined decorator for stderr/WARN logging\n    enable_warn_logging = enable_exelog(level=logging.WARN)\n    \n    # Predefined decorator for stderr/ERROR logging\n    enable_error_logging = enable_exelog(level=logging.ERROR)\n    \n    # Predefined decorator for stderr/CRITICAL logging\n    enable_critical_logging = enable_exelog(level=logging.CRITICAL)\n\n### Fine-grained logging set up\n\nIf the `logging.basicConfig()` API is not flexible enough for your desired setup, you can also inject more advanced\nsetup code with the `initialized_call` decorator. This decorator is not limited to logging setup, it just expects a\ncallable (that can be called without arguments). A very simple example:\n\n    @exelog.initialized_call(lambda: print(\"Executor logging enabled\"))\n    def process(x):\n        ....\n\nThis will print \"Executor logging enabled\" the first time the `process` function is called in each executor.\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/Spratiher9/Exelog",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "exelog",
    "package_url": "https://pypi.org/project/exelog/",
    "platform": "",
    "project_url": "https://pypi.org/project/exelog/",
    "project_urls": {
      "Homepage": "https://github.com/Spratiher9/Exelog"
    },
    "release_url": "https://pypi.org/project/exelog/0.0.1/",
    "requires_dist": [
      "atomicwrites",
      "attrs",
      "colorama",
      "iniconfig",
      "packaging",
      "pluggy",
      "py",
      "py4j",
      "pyparsing",
      "pyspark",
      "pytest",
      "toml"
    ],
    "requires_python": ">=3.5",
    "summary": "Enabling meticulous logging for Spark Applications",
    "version": "0.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12145814,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6a2e0e405791da54a602d0a40f22fc7b848aa0bd57a28435925b4ac83a3751db",
          "md5": "50252f419c6f83a70a5241fc8bc7757c",
          "sha256": "c67039d194698abafa6f16c3205684d15f3b3e5183d932e2722a50f5bdccda70"
        },
        "downloads": -1,
        "filename": "exelog-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "50252f419c6f83a70a5241fc8bc7757c",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.5",
        "size": 8691,
        "upload_time": "2021-11-28T14:00:09",
        "upload_time_iso_8601": "2021-11-28T14:00:09.448585Z",
        "url": "https://files.pythonhosted.org/packages/6a/2e/0e405791da54a602d0a40f22fc7b848aa0bd57a28435925b4ac83a3751db/exelog-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e9c538f4b468be3508abb7c095a0132a8edb3225f6a43da620c84c0ac543f578",
          "md5": "e46de7ecdc8e38a4f9823ed541535ce6",
          "sha256": "1a17d9532e6d7533be169a3e6f36b64cd574b8d995e26566e51c27728de2b85a"
        },
        "downloads": -1,
        "filename": "exelog-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "e46de7ecdc8e38a4f9823ed541535ce6",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 8370,
        "upload_time": "2021-11-28T14:00:11",
        "upload_time_iso_8601": "2021-11-28T14:00:11.298911Z",
        "url": "https://files.pythonhosted.org/packages/e9/c5/38f4b468be3508abb7c095a0132a8edb3225f6a43da620c84c0ac543f578/exelog-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "6a2e0e405791da54a602d0a40f22fc7b848aa0bd57a28435925b4ac83a3751db",
        "md5": "50252f419c6f83a70a5241fc8bc7757c",
        "sha256": "c67039d194698abafa6f16c3205684d15f3b3e5183d932e2722a50f5bdccda70"
      },
      "downloads": -1,
      "filename": "exelog-0.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "50252f419c6f83a70a5241fc8bc7757c",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.5",
      "size": 8691,
      "upload_time": "2021-11-28T14:00:09",
      "upload_time_iso_8601": "2021-11-28T14:00:09.448585Z",
      "url": "https://files.pythonhosted.org/packages/6a/2e/0e405791da54a602d0a40f22fc7b848aa0bd57a28435925b4ac83a3751db/exelog-0.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "e9c538f4b468be3508abb7c095a0132a8edb3225f6a43da620c84c0ac543f578",
        "md5": "e46de7ecdc8e38a4f9823ed541535ce6",
        "sha256": "1a17d9532e6d7533be169a3e6f36b64cd574b8d995e26566e51c27728de2b85a"
      },
      "downloads": -1,
      "filename": "exelog-0.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "e46de7ecdc8e38a4f9823ed541535ce6",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.5",
      "size": 8370,
      "upload_time": "2021-11-28T14:00:11",
      "upload_time_iso_8601": "2021-11-28T14:00:11.298911Z",
      "url": "https://files.pythonhosted.org/packages/e9/c5/38f4b468be3508abb7c095a0132a8edb3225f6a43da620c84c0ac543f578/exelog-0.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}