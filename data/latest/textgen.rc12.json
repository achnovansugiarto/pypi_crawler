{
  "info": {
    "author": "XuMing",
    "author_email": "xuming624@qq.com",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Developers",
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Topic :: Scientific/Engineering :: Artificial Intelligence",
      "Topic :: Text Processing :: Linguistic"
    ],
    "description": "[![PyPI version](https://badge.fury.io/py/textgen.svg)](https://badge.fury.io/py/textgen)\n[![Downloads](https://pepy.tech/badge/textgen)](https://pepy.tech/project/textgen)\n[![Contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg)](CONTRIBUTING.md)\n[![GitHub contributors](https://img.shields.io/github/contributors/shibing624/textgen.svg)](https://github.com/shibing624/textgen/graphs/contributors)\n[![License Apache 2.0](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](LICENSE)\n[![python_version](https://img.shields.io/badge/Python-3.8%2B-green.svg)](requirements.txt)\n[![GitHub issues](https://img.shields.io/github/issues/shibing624/textgen.svg)](https://github.com/shibing624/textgen/issues)\n[![Wechat Group](http://vlog.sfyc.ltd/wechat_everyday/wxgroup_logo.png?imageView2/0/w/60/h/20)](#Contact)\n\n# TextGen\n\nğŸŒˆ Implementation of Text Generation models.\n\n**textgen**å®ç°äº†å¤šç§æ–‡æœ¬ç”Ÿæˆæ¨¡å‹ï¼ŒåŒ…æ‹¬ï¼šUDAã€GPT2ã€Seq2Seqã€BARTã€T5ã€SongNetç­‰æ¨¡å‹ï¼Œå¼€ç®±å³ç”¨ã€‚\n\n**Guide**\n\n- [Question](#Question)\n- [Solution](#Solution)\n- [Feature](#Feature)\n- [Install](#install)\n- [Usage](#usage)\n- [Contact](#Contact)\n- [Reference](#reference)\n\n# Question\n\næ–‡æœ¬ç”Ÿæˆï¼Œæ–‡æœ¬æ•°æ®å¢å¼ºæ€ä¹ˆåšï¼Ÿ\n\n# Solution\n## æ–‡æœ¬ç”Ÿæˆæ¨¡å‹\n\n1. Seq2Seqã€ConvSeq2Seqã€BART\n2. GPT2ã€SongNet\n3. T5ã€CopyT5\n\n## æ–‡æœ¬æ‰©å¢\n### è¯ç²’åº¦æ‰©å¢\n1. UDAï¼Œéæ ¸å¿ƒè¯æ›¿æ¢\n2. EDAï¼Œç®€å•æ•°æ®å¢å¼ºæŠ€æœ¯ï¼šç›¸ä¼¼è¯ã€åŒä¹‰è¯æ›¿æ¢ï¼Œéšæœºè¯æ’å…¥ã€åˆ é™¤ã€æ›¿æ¢\n\n### å¥ç²’åº¦æ‰©å¢\n1. å›è¯‘ï¼ˆBT, Back Translateï¼‰ï¼šä¸­æ–‡-è‹±æ–‡-ä¸­æ–‡\n2. GPT2æ¨¡å‹ç»­å†™ï¼šçŸ­æ–‡æœ¬->é•¿æ–‡æœ¬\n3. BARTæ‘˜è¦æ¨¡å‹ï¼šé•¿æ–‡æœ¬->çŸ­æ–‡æœ¬\n4. TGLSï¼šæ— ç›‘ç£ç›¸ä¼¼æ–‡æœ¬ç”Ÿæˆæ¨¡å‹\n\n\n# Feature\n\n- [UDA(éæ ¸å¿ƒè¯æ›¿æ¢)/EDA](textgen/augment/word_level_augment.py)ï¼šæœ¬é¡¹ç›®å‚è€ƒGoogleçš„UDA(éæ ¸å¿ƒè¯æ›¿æ¢)ç®—æ³•å’ŒEDAç®—æ³•ï¼ŒåŸºäºTF-IDFå°†å¥å­ä¸­éƒ¨åˆ†ä¸é‡è¦è¯æ›¿æ¢ä¸ºåŒä¹‰è¯ï¼Œéšæœºè¯æ’å…¥ã€åˆ é™¤ã€æ›¿æ¢ç­‰æ–¹æ³•ï¼Œäº§ç”Ÿæ–°çš„æ–‡æœ¬ï¼Œå®ç°äº†æ–‡æœ¬æ‰©å¢\n- [BT(å›è¯‘)](textgen/augment/sentence_level_augment.py)ï¼šæœ¬é¡¹ç›®åŸºäºç™¾åº¦ç¿»è¯‘APIå®ç°äº†å›è¯‘åŠŸèƒ½ï¼Œå…ˆæŠŠä¸­æ–‡å¥å­ç¿»è¯‘ä¸ºè‹±æ–‡ï¼Œå†æŠŠè‹±æ–‡ç¿»è¯‘ä¸ºæ–°çš„ä¸­æ–‡\n- [Seq2Seq](textgen/seq2seq)ï¼šæœ¬é¡¹ç›®åŸºäºPyTorchå®ç°äº†Seq2Seqã€ConvSeq2Seqã€BARTæ¨¡å‹çš„è®­ç»ƒå’Œé¢„æµ‹ï¼Œå¯ä»¥ç”¨äºæ–‡æœ¬ç¿»è¯‘ã€å¯¹è¯ç”Ÿæˆã€æ‘˜è¦ç”Ÿæˆç­‰æ–‡æœ¬ç”Ÿæˆä»»åŠ¡\n- [T5](textgen/t5)ï¼šæœ¬é¡¹ç›®åŸºäºPyTorchå®ç°äº†T5å’ŒCopyT5æ¨¡å‹è®­ç»ƒå’Œé¢„æµ‹ï¼Œå¯ä»¥ç”¨äºæ–‡æœ¬ç¿»è¯‘ã€å¯¹è¯ç”Ÿæˆã€å¯¹è”ç”Ÿæˆã€æ–‡æ¡ˆæ’°å†™ç­‰æ–‡æœ¬ç”Ÿæˆä»»åŠ¡\n- [GPT2](textgen/language_modeling)ï¼šæœ¬é¡¹ç›®åŸºäºPyTorchå®ç°äº†GTP2æ¨¡å‹è®­ç»ƒå’Œé¢„æµ‹ï¼Œå¯ä»¥ç”¨äºæ–‡ç« ç”Ÿæˆã€å¯¹è”ç”Ÿæˆç­‰æ–‡æœ¬ç”Ÿæˆä»»åŠ¡\n- [SongNet](textgen/language_modeling/songnet_model.py)ï¼šæœ¬é¡¹ç›®åŸºäºPyTorchå®ç°äº†SongNetæ¨¡å‹è®­ç»ƒå’Œé¢„æµ‹ï¼Œå¯ä»¥ç”¨äºè§„èŒƒæ ¼å¼çš„è¯—è¯ã€æ­Œè¯ç­‰æ–‡æœ¬ç”Ÿæˆä»»åŠ¡\n- [TGLS](textgen/unsup_generation)ï¼šæœ¬é¡¹ç›®å®ç°äº†[TGLS](https://www.jiqizhixin.com/articles/2020-08-11-5)æ— ç›‘ç£ç›¸ä¼¼æ–‡æœ¬ç”Ÿæˆæ¨¡å‹ï¼Œæ˜¯ä¸€ç§â€œå…ˆæœç´¢åå­¦ä¹ â€çš„æ–‡æœ¬ç”Ÿæˆæ–¹æ³•ï¼Œé€šè¿‡åå¤è¿­ä»£å­¦ä¹ å€™é€‰é›†ï¼Œæœ€ç»ˆæ¨¡å‹èƒ½ç”Ÿæˆç±»ä¼¼å€™é€‰é›†çš„é«˜è´¨é‡ç›¸ä¼¼æ–‡æœ¬\n\n\n# Demo\n\nHuggingFace Demo: https://huggingface.co/spaces/shibing624/chinese-couplet-generate\n\n![](docs/hf.png)\n\nrun example: [examples/gradio_demo.py](examples/gradio_demo.py) to see the demo:\n\n```shell\npython examples/gradio_demo.py\n```\n\nmodel trained by [examples/T5/T5_Finetune_Chinese_Couplet.ipynb](https://github.com/shibing624/textgen/blob/main/examples/T5/T5_Finetune_Chinese_Couplet.ipynb)\n\n# Install\n\n```shell\npip install torch # conda install pytorch\npip install -U textgen\n```\n\nor\n\n```shell\npip install torch # conda install pytorch\ngit clone https://github.com/shibing624/textgen.git\ncd textgen\npython3 setup.py install\n```\n\n# Usage\n\n## ConvSeq2Seq æ¨¡å‹\nè®­ç»ƒå¹¶é¢„æµ‹ConvSeq2Seqæ¨¡å‹ï¼š\n\nexample: [examples/seq2sesq/training_convseq2seq_model_demo.py](examples/seq2seq/training_convseq2seq_model_demo.py)\n\n```python\nimport argparse\nfrom loguru import logger\nimport sys\n\nsys.path.append('../..')\nfrom textgen.seq2seq.conv_seq2seq_model import ConvSeq2SeqModel\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--train_file', default='../data/zh_dialog.tsv', type=str, help='Training data file')\n    parser.add_argument('--do_train', action='store_true', help='Whether to run training.')\n    parser.add_argument('--do_predict', action='store_true', help='Whether to run predict.')\n    parser.add_argument('--output_dir', default='./outputs/convseq2seq_zh/', type=str, help='Model output directory')\n    parser.add_argument('--max_seq_length', default=50, type=int, help='Max sequence length')\n    parser.add_argument('--num_epochs', default=200, type=int, help='Number of training epochs')\n    parser.add_argument('--batch_size', default=32, type=int, help='Batch size')\n    args = parser.parse_args()\n    logger.info(args)\n\n    if args.do_train:\n        logger.info('Loading data...')\n        model = ConvSeq2SeqModel(epochs=args.num_epochs, batch_size=args.batch_size,\n                                 model_dir=args.output_dir, max_length=args.max_seq_length)\n        model.train_model(args.train_file)\n        print(model.eval_model(args.train_file))\n\n    if args.do_predict:\n        model = ConvSeq2SeqModel(epochs=args.num_epochs, batch_size=args.batch_size,\n                                 model_dir=args.output_dir, max_length=args.max_seq_length)\n        sentences = [\"ä»€ä¹ˆæ˜¯ai\", \"ä½ æ˜¯ä»€ä¹ˆç±»å‹çš„è®¡ç®—æœº\", \"ä½ çŸ¥é“çƒ­åŠ›å­¦å—\"]\n        print(\"inputs:\", sentences)\n        print('outputs:', model.predict(sentences))\n\n\nif __name__ == '__main__':\n    main()\n```\n\noutput:\n\n```bash\ninputs: [\"ä»€ä¹ˆæ˜¯ai\", \"ä½ æ˜¯ä»€ä¹ˆç±»å‹çš„è®¡ç®—æœº\", \"ä½ çŸ¥é“çƒ­åŠ›å­¦å—\"]\noutputs: ['äººå·¥æ™ºèƒ½æ˜¯å·¥ç¨‹å’Œç§‘å­¦çš„åˆ†æ”¯,è‡´åŠ›äºæ„å»ºæ€ç»´çš„æœºå™¨ã€‚', 'æˆ‘çš„ç¨‹åºè¿è¡Œåœ¨python,æ‰€ä»¥æˆ‘åœ¨ä»»ä½•è¿è„‘ä¸Šå·¥ä½œï¼', 'æˆ‘ä¸èƒ½é”™çƒ­æ˜¯ä¸€ä¸ªç–¯ç‹‚çš„äººå·¥æ™ºèƒ½\"200å¹´ã€‚']\n```\n\n## BART æ¨¡å‹\nè®­ç»ƒå¹¶é¢„æµ‹BARTæ¨¡å‹ï¼š\n\nexample: [examples/seq2sesq/training_bartseq2seq_zh_demo.py](examples/seq2seq/training_bartseq2seq_zh_demo.py)\n\n\noutput:\n\n```shell\ninputs: ['ä»€ä¹ˆæ˜¯ai', 'ä½ æ˜¯ä»€ä¹ˆç±»å‹çš„è®¡ç®—æœº', 'ä½ çŸ¥é“çƒ­åŠ›å­¦å—']\noutputs: ['äººå·¥æ™ºèƒ½æ˜¯å·¥ç¨‹å’Œç§‘å­¦çš„åˆ†æ”¯,è‡´åŠ›äºæ„', 'æˆ‘çš„ç¨‹åºè¿è¡Œåœ¨python,æ‰€ä»¥æˆ‘åœ¨ä»»ä½•ç”µè„‘ä¸Š', 'ä»€ä¹ˆæ˜¯çƒ­åŠ›å­¦å—ï¼Ÿ']\n```\n\n\n## T5 æ¨¡å‹\n\nexample: [examples/T5/training_zh_t5_model_demo.py](https://github.com/shibing624/textgen/blob/main/examples/T5/training_zh_t5_model_demo.py)\n\n```python\nimport argparse\nfrom loguru import logger\nimport pandas as pd\nimport sys\n\nsys.path.append('../..')\nfrom textgen.t5 import T5Model\n\n\ndef load_data(file_path):\n    data = []\n    with open(file_path, 'r', encoding='utf-8') as f:\n        for line in f:\n            line = line.strip('\\n')\n            terms = line.split('\\t')\n            if len(terms) == 2:\n                data.append(['QA', terms[0], terms[1]])\n            else:\n                logger.warning(f'line error: {line}')\n    return data\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--train_file', default='../data/zh_dialog.tsv', type=str, help='Training data file')\n    parser.add_argument('--model_type', default='t5', type=str, help='Transformers model type')\n    parser.add_argument('--model_name', default='Langboat/mengzi-t5-base', type=str, help='Transformers model or path')\n    parser.add_argument('--do_train', action='store_true', help='Whether to run training.')\n    parser.add_argument('--do_predict', action='store_true', help='Whether to run predict.')\n    parser.add_argument('--output_dir', default='./outputs/mengzi_t5_zh/', type=str, help='Model output directory')\n    parser.add_argument('--max_seq_length', default=50, type=int, help='Max sequence length')\n    parser.add_argument('--num_epochs', default=10, type=int, help='Number of training epochs')\n    parser.add_argument('--batch_size', default=32, type=int, help='Batch size')\n    args = parser.parse_args()\n    logger.info(args)\n\n    if args.do_train:\n        logger.info('Loading data...')\n        # train_data: Pandas DataFrame containing the 3 columns - `prefix`, `input_text`, `target_text`.\n        #   - `prefix`: A string indicating the task to perform. (E.g. `\"question\"`, `\"stsb\"`)\n        #   - `input_text`: The input text. `prefix` is prepended to form the full input. (<prefix>: <input_text>)\n        #   - `target_text`: The target sequence\n        train_data = load_data(args.train_file)\n        logger.debug('train_data: {}'.format(train_data[:10]))\n        train_df = pd.DataFrame(train_data, columns=[\"prefix\", \"input_text\", \"target_text\"])\n\n        eval_data = load_data(args.train_file)[:10]\n        eval_df = pd.DataFrame(eval_data, columns=[\"prefix\", \"input_text\", \"target_text\"])\n\n        model_args = {\n            \"reprocess_input_data\": True,\n            \"overwrite_output_dir\": True,\n            \"max_seq_length\": args.max_seq_length,\n            \"train_batch_size\": args.batch_size,\n            \"num_train_epochs\": args.num_epochs,\n            \"save_eval_checkpoints\": False,\n            \"save_model_every_epoch\": False,\n            \"evaluate_generated_text\": True,\n            \"evaluate_during_training\": True,\n            \"evaluate_during_training_verbose\": True,\n            \"use_multiprocessing\": True,\n            \"save_best_model\": True,\n            \"output_dir\": args.output_dir,\n            \"use_early_stopping\": True,\n        }\n        # model_type: t5  model_name: Langboat/mengzi-t5-base\n        model = T5Model(args.model_type, args.model_name, args=model_args)\n\n        def count_matches(labels, preds):\n            logger.debug(f\"labels: {labels[:10]}\")\n            logger.debug(f\"preds: {preds[:10]}\")\n            match = sum([1 if label == pred else 0 for label, pred in zip(labels, preds)])\n            logger.debug(f\"match: {match}\")\n            return match\n\n        model.train_model(train_df, eval_data=eval_df, matches=count_matches)\n        print(model.eval_model(eval_df, matches=count_matches))\n\n    if args.do_predict:\n        model = T5Model(args.model_type, args.output_dir)\n        sentences = [\"ä»€ä¹ˆæ˜¯ai\", \"ä½ æ˜¯ä»€ä¹ˆç±»å‹çš„è®¡ç®—æœº\", \"ä½ çŸ¥é“çƒ­åŠ›å­¦å—\"]\n        print(\"inputs:\", sentences)\n        print(\"outputs:\", model.predict(sentences))\n\n\nif __name__ == '__main__':\n    main()\n```\n\noutput:\n```shell\ninputs: ['ä»€ä¹ˆæ˜¯ai', 'ä½ æ˜¯ä»€ä¹ˆç±»å‹çš„è®¡ç®—æœº', 'ä½ çŸ¥é“çƒ­åŠ›å­¦å—']\noutputs: ['äººå·¥æ™ºèƒ½æœ‰ä¸¤ä¸ªå¹¿ä¹‰çš„å®šä¹‰,ä»»ä½•æ‹Ÿäººçš„æœºæ¢°,å¦‚åœ¨å¡é›·å°”capeks', 'æˆ‘çš„ç¨‹åºè¿è¡Œåœ¨Python,æ‰€ä»¥æˆ‘åœ¨ä»»ä½•ç”µè„‘ä¸Šå·¥ä½œ!', 'ä»€ä¹ˆæ˜¯çƒ­åŠ›å­¦']\n```\n\n\n### T5 æ¨¡å‹åº”ç”¨\n\nreleaseåŸºäºT5çš„fine-tunedåçš„ä¸­æ–‡æ¨¡å‹ï¼Œæ¨¡å‹å…¨éƒ¨releaseåˆ°HuggingFace modelsï¼Œ`textgen`å¯è‡ªåŠ¨ä¸‹è½½ï¼Œå¯ç›´æ¥ä½¿ç”¨ã€‚\n\n|Model|Arch|Intro|Training|Inference|\n|:-- |:--- |:--- |:--- |:--- |\n|[shibing624/prompt-t5-base-chinese](https://huggingface.co/shibing624/prompt-t5-base-chinese)|T5|ä¸­æ–‡NLPå¤šä»»åŠ¡Promptæ¨¡å‹|[prompt-t5-base-chinese.md](https://github.com/shibing624/textgen/blob/main/docs/prompt-t5-base-chinese.md)|[predict script](https://github.com/shibing624/textgen/blob/main/examples/t5_prompt_demo.py)|\n|[shibing624/t5-chinese-couplet](https://huggingface.co/shibing624/t5-chinese-couplet)|T5|fine-tunedä¸­æ–‡å¯¹è”åçš„æ¨¡å‹|[å¯¹è”ç”Ÿæˆæ¨¡å‹è°ƒç ”](https://github.com/shibing624/textgen/blob/main/docs/%E5%AF%B9%E8%81%94%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E5%AF%B9%E6%AF%94.md)|[predict script](https://github.com/shibing624/textgen/blob/main/examples/t5_couplet_demo.py)|\n\n\n## GPT2 æ¨¡å‹\n\n### ä¸­æ–‡GPT2 - æ–‡ç« ç”Ÿæˆ\n\nä½¿ç”¨ä¸­æ–‡æ•°æ®é›†ï¼ˆæ®µè½æ ¼å¼ï¼Œ`\\n`é—´éš”ï¼‰ï¼Œè®­ç»ƒGPT2æ¨¡å‹ï¼Œå¯ä»¥ç”¨äºè¯—æ­Œç”Ÿæˆã€æ–‡ç« ç”Ÿæˆç­‰ä»»åŠ¡ã€‚\n\nexample: [examples/language_generation/training_zh_gpt2_demo.py](https://github.com/shibing624/textgen/blob/main/examples/language_generation/training_zh_gpt2_demo.py)\n\n### ä¸­æ–‡GPT2 - å¯¹è”ç”Ÿæˆ\n\nä½¿ç”¨ä¸­æ–‡å¯¹è”æ•°æ®é›†ï¼ˆtsvæ ¼å¼ï¼Œ`\\t`é—´éš”ï¼‰ï¼Œè‡ªå®šä¹‰æ•°æ®é›†è¯»å–Datasetï¼Œè®­ç»ƒGPT2æ¨¡å‹ï¼Œå¯ä»¥ç”¨äºå¯¹è”ç”Ÿæˆã€å¯¹è¯ç”Ÿæˆç­‰ä»»åŠ¡ã€‚\n\nexample: [examples/language_generation/training_couplet_gpt2_demo.py](https://github.com/shibing624/textgen/blob/main/examples/language_generation/training_couplet_gpt2_demo.py)\n\n#### GPT2 vs T5ï¼š\n1. éƒ½æ˜¯ä»Transformeræ”¹è¿›æ¥çš„ï¼ŒT5åŒæ—¶æœ‰ç¼–ç å™¨å’Œè§£ç å™¨ï¼ŒGPT2åªæœ‰è§£ç å™¨\n2. T5çš„æ¨¡å‹ä¼˜åŠ¿æ˜¯å¤„ç†ç»™å®šè¾“å…¥ï¼Œäº§å‡ºå¯¹åº”è¾“å‡ºçš„ä»»åŠ¡ï¼Œå¦‚ç¿»è¯‘ã€å¯¹è¯ã€é—®ç­”ç­‰\n3. GPT2çš„æ¨¡å‹ä¼˜åŠ¿æ˜¯è‡ªç”±åˆ›ä½œï¼Œå¦‚å†™ä¸€ç¯‡çŸ­æ–‡\n4. T5çš„å¯¹è”ç”Ÿæˆæ•ˆæœå¥½äºGPT2ã€GPT2çš„è¯—è¯ç”Ÿæˆæ•ˆæœå¥½äºT5\n\n- [å¯¹è”ç”Ÿæˆæ¨¡å‹è°ƒç ”](https://github.com/shibing624/textgen/blob/main/docs/%E5%AF%B9%E8%81%94%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E5%AF%B9%E6%AF%94.md)\n- [å¤è¯—ç”Ÿæˆæ¨¡å‹è°ƒç ”](https://github.com/shibing624/textgen/blob/main/docs/%E5%8F%A4%E8%AF%97%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E5%AF%B9%E6%AF%94.md)\n\n## SongNet æ¨¡å‹\n\næ ¼å¼æ§åˆ¶çš„æ–‡æœ¬ç”Ÿæˆæ¨¡å‹ï¼Œpaperè§[SongNet: Rigid Formats Controlled Text Generation](https://arxiv.org/abs/2004.08022)ï¼Œ\né€‚ç”¨äºå¼ºéŸµå¾‹æ ¼å¼è¦æ±‚çš„è¯—æ­Œã€å¯¹è”ã€æ­Œè¯ç”Ÿæˆç­‰ä»»åŠ¡ã€‚\n\nexample: [examples/language_generation/training_zh_songnet_demo.py](https://github.com/shibing624/textgen/blob/main/examples/language_generation/training_zh_songnet_demo.py)\n\n### SongNet æ¨¡å‹åº”ç”¨\n\nreleaseåŸºäºSongNetçš„ä¸­æ–‡æ¨¡å‹ï¼Œæ¨¡å‹å…¨éƒ¨releaseåˆ°HuggingFace modelsï¼Œ`textgen`å¯è‡ªåŠ¨ä¸‹è½½ï¼Œå¯ç›´æ¥ä½¿ç”¨ã€‚\n\n|Model|Arch|Intro|Training|Inference|\n|:-- |:--- |:--- |:--- |:--- |\n|[shibing624/songnet-base-chinese](https://huggingface.co/shibing624/songnet-base-chinese)|SongNet|SongNeté¢„è®­ç»ƒæ¨¡å‹|-|-|\n|[shibing624/songnet-base-chinese-songci](https://huggingface.co/shibing624/songnet-base-chinese-songci)|SongNet|fine-tunedå®‹è¯åçš„æ¨¡å‹|[training script](https://github.com/shibing624/textgen/blob/main/examples/language_generation/training_zh_songnet_demo.py)|[predict script](https://github.com/shibing624/textgen/blob/main/examples/songnet_songci_demo.py)|\n|[shibing624/songnet-base-chinese-couplet](https://huggingface.co/shibing624/songnet-base-chinese-couplet)|SongNet|fine-tunedå¯¹è”åçš„æ¨¡å‹|[training script](https://github.com/shibing624/textgen/blob/main/examples/language_generation/training_zh_songnet_demo.py)|[predict script](https://github.com/shibing624/textgen/blob/main/examples/songnet_couplet_demo.py)|\n\n\n## Keyword Text Augmentation(EDA/UDA)\n\nexample: [examples/text_augmentation_demo.py](examples/text_augmentation_demo.py)\n\n```python\nimport sys\n\nsys.path.append('..')\nfrom textgen.augment import TextAugment\n\nif __name__ == '__main__':\n    docs = ['ä¸»è¦ç ”ç©¶æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ã€è®¡ç®—æœºè§†è§‰ã€æ™ºèƒ½å¯¹è¯ç³»ç»Ÿç›¸å…³å†…å®¹',\n            'æ™šä¸Šè‚šå­å¥½éš¾å—',\n            'ä½ ä¼šæ­¦åŠŸå—ï¼Œæˆ‘ä¸ä¼š',\n            'ç»„è£…æ ‡é¢˜è´¨é‡å—é™äºå¹¿å‘Šä¸»è‡ªæç‰©æ–™çš„ç‰‡æ®µè´¨é‡ï¼Œä¸”è¡¨è¾¾ä¸°å¯Œåº¦æœ‰é™',\n            ]\n    m = TextAugment(sentence_list=docs)\n    a = docs[0]\n    print(a)\n\n    b = m.augment(a, aug_ops='random-0.2')\n    print('random-0.2:', b)\n\n    b = m.augment(a, aug_ops='insert-0.2')\n    print('insert-0.2:', b)\n\n    b = m.augment(a, aug_ops='delete-0.2')\n    print('delete-0.2:', b)\n\n    b = m.augment(a, aug_ops='tfidf-0.2')\n    print('tfidf-0.2:', b)\n\n    b = m.augment(a, aug_ops='mix-0.2')\n    print('mix-0.2:', b)\n```\n\noutput:\n\n```bash\nä¸»è¦ç ”ç©¶æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ã€è®¡ç®—æœºè§†è§‰ã€æ™ºèƒ½å¯¹è¯ç³»ç»Ÿç›¸å…³å†…å®¹\nrandom-0.2: ('ä¸»è¦é™ªé™ªæœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ä¸»è¦è®¡ç®—æœºè§†è§‰ã€æ™ºèƒ½å¯¹è¯ç³»ç»Ÿå—é™äºå†…å®¹', [('ç ”ç©¶', 'é™ªé™ª', 2, 4), ('ã€', 'ä¸»è¦', 13, 15), ('ç›¸å…³', 'å—é™äº', 27, 30)])\ninsert-0.2: ('ä¸»è¦ç ”ç©¶æœºå™¨æœºå™¨å­¦ä¹ å­¦ä¹ ã€æ·±åº¦æ·±åº¦å­¦ä¹ ã€è®¡ç®—æœºè§†è§‰ã€æ™ºèƒ½å¯¹è¯ç³»ç»Ÿç›¸å…³å†…å®¹', [('æœºå™¨', 'æœºå™¨æœºå™¨', 4, 8), ('å­¦ä¹ ', 'å­¦ä¹ å­¦ä¹ ', 8, 12), ('æ·±åº¦', 'æ·±åº¦æ·±åº¦', 13, 17)])\ndelete-0.2: ('ä¸»è¦ç ”ç©¶æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ã€è®¡ç®—æœºè§†è§‰ã€å¯¹è¯ç³»ç»Ÿç›¸å…³å†…å®¹', [('æ™ºèƒ½', '', 20, 20)])\ntfidf-0.2: ('ä¸€æ˜¯ç ”ç©¶æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ã€è®¡ç®—æœºå¬è§‰ã€æ™ºèƒ½äº¤è°ˆç³»ç»Ÿå¯†åˆ‡ç›¸å…³å†…å®¹', [('ä¸»è¦', 'ä¸€æ˜¯', 0, 2), ('è§†è§‰', 'å¬è§‰', 17, 19), ('å¯¹è¯', 'äº¤è°ˆ', 22, 24), ('ç›¸å…³', 'å¯†åˆ‡ç›¸å…³', 26, 30)])\nmix-0.2: ('ä¸»è¦ç ”ç©¶æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ã€è®¡ç®—æœºå¬è§‰ã€æ™ºèƒ½å¯¹è¯è½¯ä»¶ç³»ç»Ÿç›¸å…³å†…å®¹', [('å­¦ä¹ ', 'å­¦', 11, 12), ('è§†è§‰', 'å¬è§‰', 16, 18), ('ç³»ç»Ÿ', 'è½¯ä»¶ç³»ç»Ÿ', 23, 27)])\n```\n\n## TGLS æ¨¡å‹ï¼ˆæ— ç›‘ç£ç›¸ä¼¼æ–‡æœ¬ç”Ÿæˆæ¨¡å‹ï¼‰\n\næ— ç›‘ç£çš„ä¸­æ–‡ç”µå•†è¯„è®ºç”Ÿæˆï¼šä»**ç”µå•†è¯„è®º**ä¸­æå–ç”¨æˆ·è¡¨è¾¾è§‚ç‚¹çš„çŸ­å¥å¹¶è¿›è¡Œç»„åˆæ¥ç”Ÿæˆä»¿çœŸè¯„è®ºã€‚\n\nexample: [examples/unsup_generation_demo.py](examples/unsup_generation_demo.py)\n\n```python\nimport os\nimport sys\n\nsys.path.append('..')\nfrom textgen.unsup_generation import TglsModel, load_list\n\npwd_path = os.path.abspath(os.path.dirname(__file__))\n\nsamples = load_list(os.path.join(pwd_path, './data/ecommerce_comments.txt'))\ndocs_text = [\n    [\"æŒºå¥½çš„ï¼Œé€Ÿåº¦å¾ˆå¿«ï¼Œä¹Ÿå¾ˆå®æƒ ï¼Œä¸çŸ¥æ•ˆæœå¦‚ä½•\",\n     \"äº§å“æ²¡å¾—è¯´ï¼Œä¹°äº†ä»¥åå°±é™ä»·ï¼Œå¿ƒæƒ…ä¸ç¾ä¸½ã€‚\",\n     \"åˆšæ”¶åˆ°ï¼ŒåŒ…è£…å¾ˆå®Œæ•´ï¼Œä¸é”™\",\n     \"å‘è´§é€Ÿåº¦å¾ˆå¿«ï¼Œç‰©æµä¹Ÿä¸é”™ï¼ŒåŒä¸€æ—¶é—´ä¹°çš„ä¸¤ä¸ªä¸œä¸œï¼Œä¸€ä¸ªå…ˆåˆ°ä¸€ä¸ªè¿˜åœ¨è·¯ä¸Šã€‚è¿™ä¸ªæ°´æ°´å¾ˆå–œæ¬¢ï¼Œä¸è¿‡ç›–å­çœŸçš„å¼€äº†ã€‚ç›–ä¸ç‰¢äº†ç°åœ¨ã€‚\",\n     \"åŒ…è£…çš„å¾ˆå¥½ï¼Œæ˜¯æ­£å“\",\n     \"è¢«ç§è‰å…°è”»ç²‰æ°´ä¸‰ç™¾å…ƒä¸€å¤§ç“¶å›¤è´§ï¼Œå¸Œæœ›æ˜¯æ­£å“å¥½ç”¨ï¼Œæ”¶åˆ°çš„æ—¶å€™ç”¨ä¿é²œè†œåŒ…è£¹å¾—ä¸¥ä¸¥å®å®ï¼Œåªæ•¢ä¹°è€ƒæ‹‰è‡ªè¥çš„æŠ¤è‚¤å“\",\n     ],\n    ['å¾ˆæ¸©å’Œï¼Œæ¸…æ´—çš„ä¹Ÿå¾ˆå¹²å‡€ï¼Œä¸æ²¹è…»ï¼Œå¾ˆä¸é”™ï¼Œä¼šè€ƒè™‘å›è´­ï¼Œç¬¬ä¸€æ¬¡è€ƒæ‹‰ä¹°æŠ¤è‚¤å“ï¼Œæ»¡æ„',\n     'è¿™æ¬¾å¸å¦†æ²¹æˆ‘ä¼šæ— é™å›è´­çš„ã€‚å³ä½¿æˆ‘æ˜¯æ²¹ç—˜çš®ï¼Œä¹Ÿä¸ä¼šé—·ç—˜ï¼ŒåŒæ—¶åœ¨è„¸éƒ¨æŒ‰æ‘©æ—¶ï¼Œè¿˜èƒ½è§£å†³ç™½å¤´çš„è„‚è‚ªç²’çš„é—®é¢˜ã€‚ç”¨æ¸…æ°´æ´—å®Œè„¸åï¼Œéå¸¸çš„æ¸…çˆ½ã€‚',\n     'è‡ªä»ç”¨äº†fanclä¹‹åå°±ä¸ç”¨å…¶ä»–å¸å¦†äº†ï¼Œå¸çš„èˆ’æœåˆå¹²å‡€',\n     'ä¹°è´µäº†ï¼Œå¤§æ¶¦å‘æ‰å–79ã€‚9ã€‚',\n     ],\n    samples\n]\nm = TglsModel(docs_text)\nr = m.generate(samples[:500])\nprint('size:', len(r))\nfor review in r:\n    print('\\t' + review)\n```\n\noutput:\n\n[ç¾è¿ªæƒ å°” N.M.Fé’ˆå‰‚æ°´åº“ä¿æ¹¿é¢è†œ](https://goods.kaola.com/product/2227311.html)æœ‰å¦‚ä¸‹çš„20å¥è¯„è®ºï¼Œå…¶ä¸­æœ‰10å¥æ˜¯çœŸå®ç”¨æˆ·è¯„è®ºï¼Œ10å¥æ˜¯ç”Ÿæˆçš„è¯„è®ºï¼Œèƒ½çœ‹å‡ºæ¥ä¹ˆ?ğŸ˜‚\n\n```\nè¿˜ä¸é”™è¿˜ä¸é”™è¿˜ä¸é”™è¿˜ä¸é”™ã€‚\nä¸œè¥¿åˆ°äº†ï¼Œä¸çŸ¥é“å¥½ä¸å¥½ç”¨ã€‚è¯•ç”¨è¿‡åå†æ¥è¯„ä»·ã€‚åˆ°æ—¶çœ‹ç½‘è¯„éƒ½è¿˜å¯ä»¥ã€‚\nå“ºä¹³æœŸå”¯ä¸€ä½¿ç”¨çš„æŠ¤è‚¤å“ï¼Œæ¯å¤©éƒ½æ˜¯ç´ é¢œï¼Œè„¸é¢å…¨é é¢è†œåŠç€ğŸ˜„è¡¥æ°´ğŸ’¦ä¸ç²˜è…»ä¸€å¦‚æ—¢å¾€çš„æ”¯æŒï¼Œå–œæ¬¢ğŸ’•\nææ´»åŠ¨æ—¶ä¹°çš„é¢è†œï¼Œä¸çŸ¥é“è¿™ä¸ªé¢è†œæ˜¯çœŸæ˜¯å‡æ•·åœ¨è„¸ä¸Šé¢è†œçº¸éƒ½æœ‰å°æ°´æ³¡é¼“èµ·æ¥ã€‚\nå¾ˆä¸é”™ï¼Œéå¸¸è¡¥æ°´ï¼Œç”¨è¿‡çš„éƒ½çŸ¥é“ï¼Œæ€§ä»·æ¯”ä¹‹ç‹ï¼Œå¥½ç”¨åˆä¸è´µï¼Œæ­£å“ï¼Œç”¨ç€æ”¾å¿ƒï¼Œç‰©æµä¹Ÿå¾ˆå¿«ã€‚\né¢è†œéå¸¸å¥½ç”¨å“¦ã€‚é¢è†œè–„è–„çš„ã€‚å¥½åƒæ˜¯èš•ä¸é¢è†œå•Šã€‚ç²¾åå¾ˆå¤šå‘¢ã€‚æ•·åœ¨è„¸ä¸Šå¾ˆèˆ’æœã€‚æ„Ÿè§‰æŒºä¿æ¹¿çš„ï¼Œå‘³é“ä¹ŸæŒºå¥½é—»çš„ã€‚å°±æ˜¯é‡Œé¢åªæœ‰å•çº¯çš„é¢è†œç›´æ¥æ•·è„¸ä¸Šæœ‰ç‚¹ä¸å¥½å¼„ï¼Œå“ˆå“ˆå“ˆ\nè¿˜å¯ä»¥ä¿æ¹¿æ•ˆæœä¸é”™æ°´æ¶¦æ¶¦çš„æ¯å¤©è´´ä¸€ç‰‡è„¸ä¹Ÿä¸å¹²äº†ç”¨å®Œäº†åœ¨ä¹°ç‚¹ï¼Œä¸é”™è¿˜ä¼šç»§ç»­å›è´­çš„ã€‚\nå¿«é€’å¾ˆå¿«ï¼Œä¸œè¥¿å¾ˆèµï¼æƒ³è¦å¾—ç‚¹è€ƒæ‹‰è±†ä¸å®¹æ˜“ï¼Œè¿˜è¦ä¸‰åä¸ªå­—ã€‚æ—¶é—´å®è´µï¼ŒåºŸè¯ä¸è¯´ï¼ç”¨è¿‡äº†å°±çŸ¥é“äº†\næŒºå¥½ç”¨çš„ï¼Œæœ‹å‹æ¨èæ¥çš„\næŒºå¥½ç”¨çš„ï¼Œæ·¡æ·¡çš„ï¼Œè™½ç„¶ä¸æ˜¯å¾ˆæµ“ç²¾åçš„æ„Ÿè§‰ï¼Œä½†æ˜¯æ•ˆæœä¹Ÿè›®å¥½çš„ã€‚åˆ’ç®—\nä¸å¾—ä¸è¯´ç¾è¿ªæƒ å°”çš„é¢è†œæ˜¯æˆ‘ç”¨è¿‡çš„æœ€å¥½çš„é¢è†œä¹‹ä¸€ğŸ˜è¡¥æ°´æ•ˆæœéå¸¸å¥½ï¼Œæ²¡æƒ³åˆ°è¿™ä¹ˆä¾¿å®œçš„ä»·æ ¼ç«ŸçœŸçš„èƒ½ä¹°åˆ°çœŸå“ã€‚\nä¿æ¹¿æ•ˆæœæŒºå¥½çš„ï¼Œé¢è†œå¾ˆå¥½ç”¨ã€‚\næœŸå¾…å¥½çš„äº§å“ã€‚\nä¸€æ‰“å¼€åŒ…è£…é‡Œé¢çš„ç²¾ååˆšåˆšå¥½ï¼Œç”¨äº†è¡¥æ°´è¡¥æ°´æ•ˆæœä¸é”™ï¼Œç‰©æµéå¸¸å¿«ã€‚\nçš®è‚¤å¾ˆå…‰æ»‘ğŸ˜‡æ¯”ä¸Šå»é€Ÿåº¦å¿«ä¸‰å¤©å°±åˆ°äº†ã€‚\nå‰ä¸¤å¤©çš®è‚¤å¹²ç‡¥è¿ç»­æ•·äº†ä¸¤ä¸ªæ™šä¸Šæ„Ÿè§‰è¿˜ä¸é”™ğŸ˜‚è¡¥æ°´æ•ˆæœæ˜æ˜¾ï¼å¯æƒ³è€ŒçŸ¥ç²¾åæ¶²åˆå¤šå……è¶³ğŸ˜æ•·ä¸Šä»¥åå‡‰å‡‰çš„å¾ˆèˆ’æœã€‚\nè¡¥æ°´æ•ˆæœä¸€èˆ¬å§ï½ä½†æ˜¯æˆ‘ç”¨çš„éŸ©å›½èƒŒå›æ¥çš„é¢è†œçº¸ä¸ç®—è–„ï¼Œå¸Œæœ›å¥½ç”¨ä¼šå›è´­çš„ï¼Œæ•·ä¸Šè„¸æ„Ÿè§‰æ¯”è¾ƒæ¸…çˆ½ï½ä»·æ ¼è¿˜ä¸ä¾¿å®œã€‚\nå¸Œæœ›å¥½ç”¨ï¼Œé¢è†œç”¨è¿‡äº†å¾ˆå¥½ç”¨ï¼Œçš®è‚¤æ°´å«©å…‰æ»‘ç™½çš™ï¼Œè¡¥æ°´ä¸é”™ï¼Œä»·æ ¼ä¹Ÿåˆé€‚ã€‚\nå°±æ˜¯ç²¾åæ¶²å¤ªå°‘äº†ï¼Œä¿æ¹¿æ•ˆæœä¸é”™ã€‚\né¢è†œçš„è¡¥æ°´æ•ˆæœéå¸¸å¥½ï¼Œä¿æ¹¿æ•ˆæœç¡®å®å¾ˆèµï¼Œè¿™ä¸ªé¢è†œç›¸å¯¹äºèƒ¶åŸè›‹ç™½å’Œç¾ç™½çš„é‚£ä¸¤æ¬¾çš„é¢è†œçº¸è¦åšä¸€äº›ï¼Œçœ‹ç€ä»·æ ¼åˆé€‚ã€‚\n```\n\nå‰10å¥æ˜¯çœŸå®ç”¨æˆ·è¯„è®ºï¼Œå10å¥æ˜¯ç”Ÿæˆçš„ã€‚\n\n# Contact\n\n- Issue(å»ºè®®)\n  ï¼š[![GitHub issues](https://img.shields.io/github/issues/shibing624/textgen.svg)](https://github.com/shibing624/textgen/issues)\n- é‚®ä»¶æˆ‘ï¼šxuming: xuming624@qq.com\n- å¾®ä¿¡æˆ‘ï¼š åŠ æˆ‘*å¾®ä¿¡å·ï¼šxuming624, å¤‡æ³¨ï¼šå§“å-å…¬å¸å-NLP* è¿›NLPäº¤æµç¾¤ã€‚\n\n<img src=\"docs/wechat.jpeg\" width=\"200\" />\n\n# License\n\næˆæƒåè®®ä¸º [The Apache License 2.0](/LICENSE)ï¼Œå¯å…è´¹ç”¨åšå•†ä¸šç”¨é€”ã€‚è¯·åœ¨äº§å“è¯´æ˜ä¸­é™„åŠ textgençš„é“¾æ¥å’Œæˆæƒåè®®ã€‚\n\n# Contribute\n\né¡¹ç›®ä»£ç è¿˜å¾ˆç²—ç³™ï¼Œå¦‚æœå¤§å®¶å¯¹ä»£ç æœ‰æ‰€æ”¹è¿›ï¼Œæ¬¢è¿æäº¤å›æœ¬é¡¹ç›®ï¼Œåœ¨æäº¤ä¹‹å‰ï¼Œæ³¨æ„ä»¥ä¸‹ä¸¤ç‚¹ï¼š\n\n- åœ¨`tests`æ·»åŠ ç›¸åº”çš„å•å…ƒæµ‹è¯•\n- ä½¿ç”¨`python -m pytest`æ¥è¿è¡Œæ‰€æœ‰å•å…ƒæµ‹è¯•ï¼Œç¡®ä¿æ‰€æœ‰å•æµ‹éƒ½æ˜¯é€šè¿‡çš„\n\nä¹‹åå³å¯æäº¤PRã€‚\n\n## Reference\n\n- [PaddlePaddle/ERNIE](https://github.com/PaddlePaddle/ERNIE)\n- [minimaxir/textgenrnn](https://github.com/minimaxir/textgenrnn)\n- [minimaxir/gpt-2-simple](https://github.com/minimaxir/gpt-2-simple)\n- [asyml/texar](https://github.com/asyml/texar)\n- [yangjianxin1/GPT2-chitchat](https://github.com/yangjianxin1/GPT2-chitchat)\n- [williamSYSU/TextGAN-PyTorch](https://github.com/williamSYSU/TextGAN-PyTorch)\n- [RUCAIBox/TextBox](https://github.com/RUCAIBox/TextBox)\n- [Tiiiger/bert_score]()\n- [1YCxZ/Fake-review-generation](https://github.com/1YCxZ/Fake-review-generation)",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/shibing624/textgen",
    "keywords": "textgen,text-generation,Text Generation Tool,ernie-gen,chinese text generation",
    "license": "Apache 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "textgen",
    "package_url": "https://pypi.org/project/textgen/",
    "platform": null,
    "project_url": "https://pypi.org/project/textgen/",
    "project_urls": {
      "Homepage": "https://github.com/shibing624/textgen"
    },
    "release_url": "https://pypi.org/project/textgen/0.1.7/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "Text Generation Model",
    "version": "0.1.7",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 15909672,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "671c2e45c980177695321d03ae725ffd3a8d01ab0142debc848c02e828c4b67a",
          "md5": "4018a1e0a31a9735a32a2bc9b37cf43b",
          "sha256": "64d524c28b44baf9abdc388e56d3e041a8a281d6a682e930bb48ca9dec912982"
        },
        "downloads": -1,
        "filename": "textgen-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "4018a1e0a31a9735a32a2bc9b37cf43b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 7646,
        "upload_time": "2021-04-07T14:21:20",
        "upload_time_iso_8601": "2021-04-07T14:21:20.585094Z",
        "url": "https://files.pythonhosted.org/packages/67/1c/2e45c980177695321d03ae725ffd3a8d01ab0142debc848c02e828c4b67a/textgen-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8eec49732198778280cc49956d28b767d57a3be645ada3557a81c49731b44ee6",
          "md5": "b38dbebb15a02ea52a1cd502ccc19369",
          "sha256": "d50838f9481041d439ff6620700450482d3214e738ba6cac18d509c7fb8b31a1"
        },
        "downloads": -1,
        "filename": "textgen-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "b38dbebb15a02ea52a1cd502ccc19369",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 85917,
        "upload_time": "2021-06-23T10:06:27",
        "upload_time_iso_8601": "2021-06-23T10:06:27.390827Z",
        "url": "https://files.pythonhosted.org/packages/8e/ec/49732198778280cc49956d28b767d57a3be645ada3557a81c49731b44ee6/textgen-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ea0cbafc785f110968448cbc08e91c02222ccd5fdd2e42649e7fa51aa1de14e1",
          "md5": "2c38e26e002c7bd03cc7c15b84070956",
          "sha256": "169b5d6ab47629c16eafc8bd776b44def7615ba50334f546bf58f1f88c364df8"
        },
        "downloads": -1,
        "filename": "textgen-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "2c38e26e002c7bd03cc7c15b84070956",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 85936,
        "upload_time": "2021-06-23T12:52:43",
        "upload_time_iso_8601": "2021-06-23T12:52:43.733067Z",
        "url": "https://files.pythonhosted.org/packages/ea/0c/bafc785f110968448cbc08e91c02222ccd5fdd2e42649e7fa51aa1de14e1/textgen-0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "38bc1a1828b7f7c2f4390aeaeae7323de77987f182c495bd84317186e4463a8b",
          "md5": "df52ed52d82413dc21665b3755e2f3cf",
          "sha256": "dee14e084ebf702bcc9e5ac01078fc707183523e723a4671d38b38beb7cbb362"
        },
        "downloads": -1,
        "filename": "textgen-0.0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "df52ed52d82413dc21665b3755e2f3cf",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 105629,
        "upload_time": "2022-05-10T13:07:04",
        "upload_time_iso_8601": "2022-05-10T13:07:04.216084Z",
        "url": "https://files.pythonhosted.org/packages/38/bc/1a1828b7f7c2f4390aeaeae7323de77987f182c495bd84317186e4463a8b/textgen-0.0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6413eabacbb3b750a00871def97118a38fb6baaa808d1529a3f8f90e61e28f7e",
          "md5": "8b4b6b60bce393d4833cada231c99ec7",
          "sha256": "941d3bdc3191f29226a9bad7ad708d0f5cff19918247ecbb2b98da87a4889f9f"
        },
        "downloads": -1,
        "filename": "textgen-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "8b4b6b60bce393d4833cada231c99ec7",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 129371,
        "upload_time": "2022-06-20T06:43:47",
        "upload_time_iso_8601": "2022-06-20T06:43:47.495324Z",
        "url": "https://files.pythonhosted.org/packages/64/13/eabacbb3b750a00871def97118a38fb6baaa808d1529a3f8f90e61e28f7e/textgen-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2692a6074c5b931cc1a47387e910f04647d3d5e14b216d2424100cdeb158bc84",
          "md5": "0a668bed239f1ece3e98664426490802",
          "sha256": "39cf7943d04cf26a2fc3e7d9bc33fed1e8fad3f534449de7c6a79575828def44"
        },
        "downloads": -1,
        "filename": "textgen-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "0a668bed239f1ece3e98664426490802",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 130260,
        "upload_time": "2022-06-30T08:22:27",
        "upload_time_iso_8601": "2022-06-30T08:22:27.208021Z",
        "url": "https://files.pythonhosted.org/packages/26/92/a6074c5b931cc1a47387e910f04647d3d5e14b216d2424100cdeb158bc84/textgen-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "28e96789a758f0ecea459d625bb5984169ff55a40db2b72baca6092a7041284f",
          "md5": "67622d4e2568177272d4c4d96e7c05c9",
          "sha256": "e86327a0c7028d887bb1e6ac9b6bfbd19a0f03f5990b29fb49ac967f5a2b9ee1"
        },
        "downloads": -1,
        "filename": "textgen-0.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "67622d4e2568177272d4c4d96e7c05c9",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 130087,
        "upload_time": "2022-07-04T08:04:21",
        "upload_time_iso_8601": "2022-07-04T08:04:21.497394Z",
        "url": "https://files.pythonhosted.org/packages/28/e9/6789a758f0ecea459d625bb5984169ff55a40db2b72baca6092a7041284f/textgen-0.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bb2f0dc39f213aa8c95b343237b131d82645dbe45c822d0747e6a02ea4f7350c",
          "md5": "08a1d26afa835cba142de69bd84c43b3",
          "sha256": "41fa58a5f8296a3c189930f3b5ab23850cfacfef63d94c8300a46f3a71edddf2"
        },
        "downloads": -1,
        "filename": "textgen-0.1.3.tar.gz",
        "has_sig": false,
        "md5_digest": "08a1d26afa835cba142de69bd84c43b3",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 270884,
        "upload_time": "2022-08-05T03:06:08",
        "upload_time_iso_8601": "2022-08-05T03:06:08.296710Z",
        "url": "https://files.pythonhosted.org/packages/bb/2f/0dc39f213aa8c95b343237b131d82645dbe45c822d0747e6a02ea4f7350c/textgen-0.1.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cf0cde7aa88c495e1bf21a0c6ef726973e898d71e5b0743babada271d11246f5",
          "md5": "5546cdb2af98706638695b70918c5da2",
          "sha256": "399915dbbdf03ed87d22562c5cf8221295c6bf6f05761f7d40932e8f4c2f81b1"
        },
        "downloads": -1,
        "filename": "textgen-0.1.4.tar.gz",
        "has_sig": false,
        "md5_digest": "5546cdb2af98706638695b70918c5da2",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 267986,
        "upload_time": "2022-08-23T08:43:49",
        "upload_time_iso_8601": "2022-08-23T08:43:49.526357Z",
        "url": "https://files.pythonhosted.org/packages/cf/0c/de7aa88c495e1bf21a0c6ef726973e898d71e5b0743babada271d11246f5/textgen-0.1.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "893290f533db1889a8ec1832c885bb6015d09be0c50106e47b54e87bb01ca5e6",
          "md5": "650be0c31b53a6bbe02ae1fee5881aa4",
          "sha256": "5aab389a433482c8cf76d56af131164d9a83ab8001e917b8572f84d6a260d4ed"
        },
        "downloads": -1,
        "filename": "textgen-0.1.5.tar.gz",
        "has_sig": false,
        "md5_digest": "650be0c31b53a6bbe02ae1fee5881aa4",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 282030,
        "upload_time": "2022-09-11T08:26:36",
        "upload_time_iso_8601": "2022-09-11T08:26:36.720313Z",
        "url": "https://files.pythonhosted.org/packages/89/32/90f533db1889a8ec1832c885bb6015d09be0c50106e47b54e87bb01ca5e6/textgen-0.1.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fe104e5de391f040e65451797b022df709e1b543af7c81d724f44c263c2996db",
          "md5": "d56d2c86aa7d8aa5624af7866a7263ce",
          "sha256": "5350d2b00392675a7d0bf48f588cf91f87916826ac84a94218307a402faf22f8"
        },
        "downloads": -1,
        "filename": "textgen-0.1.6.tar.gz",
        "has_sig": false,
        "md5_digest": "d56d2c86aa7d8aa5624af7866a7263ce",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 174674,
        "upload_time": "2022-11-21T11:21:09",
        "upload_time_iso_8601": "2022-11-21T11:21:09.041799Z",
        "url": "https://files.pythonhosted.org/packages/fe/10/4e5de391f040e65451797b022df709e1b543af7c81d724f44c263c2996db/textgen-0.1.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f0425c22e9c4cb094f40c1a8316f4cf9d708291b12c19dd4156c0a1b0fc6ea62",
          "md5": "57ed4d60062027880acea228595bb976",
          "sha256": "cc4d855922bf445cedd52e4b2af92028fc8fdecbdebe132f85f3eb9ef7cfbcae"
        },
        "downloads": -1,
        "filename": "textgen-0.1.7.tar.gz",
        "has_sig": false,
        "md5_digest": "57ed4d60062027880acea228595bb976",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 175713,
        "upload_time": "2022-11-28T04:01:02",
        "upload_time_iso_8601": "2022-11-28T04:01:02.630142Z",
        "url": "https://files.pythonhosted.org/packages/f0/42/5c22e9c4cb094f40c1a8316f4cf9d708291b12c19dd4156c0a1b0fc6ea62/textgen-0.1.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "f0425c22e9c4cb094f40c1a8316f4cf9d708291b12c19dd4156c0a1b0fc6ea62",
        "md5": "57ed4d60062027880acea228595bb976",
        "sha256": "cc4d855922bf445cedd52e4b2af92028fc8fdecbdebe132f85f3eb9ef7cfbcae"
      },
      "downloads": -1,
      "filename": "textgen-0.1.7.tar.gz",
      "has_sig": false,
      "md5_digest": "57ed4d60062027880acea228595bb976",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 175713,
      "upload_time": "2022-11-28T04:01:02",
      "upload_time_iso_8601": "2022-11-28T04:01:02.630142Z",
      "url": "https://files.pythonhosted.org/packages/f0/42/5c22e9c4cb094f40c1a8316f4cf9d708291b12c19dd4156c0a1b0fc6ea62/textgen-0.1.7.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}