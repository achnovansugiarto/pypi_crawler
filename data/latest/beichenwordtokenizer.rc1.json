{
  "info": {
    "author": "",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3",
      "Topic :: Software Development :: Build Tools"
    ],
    "description": "",
    "description_content_type": "",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "MIT License",
    "maintainer": "",
    "maintainer_email": "",
    "name": "BeiChenWordtokenizer",
    "package_url": "https://pypi.org/project/BeiChenWordtokenizer/",
    "platform": "",
    "project_url": "https://pypi.org/project/BeiChenWordtokenizer/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/BeiChenWordtokenizer/2.0/",
    "requires_dist": null,
    "requires_python": ">=3.9",
    "summary": "",
    "version": "2.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 13022999,
  "releases": {
    "2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2325957c389ea43726ff85f88ceb1ec1b8d687468421f8eb65828f581e3a209b",
          "md5": "c4e08380776b168399f34547d7ae7b08",
          "sha256": "02ee44159be1107cfe0ee7038e933a4b4ca05406a4d3674330b38580621bb049"
        },
        "downloads": -1,
        "filename": "BeiChenWordtokenizer-2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "c4e08380776b168399f34547d7ae7b08",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.9",
        "size": 1343,
        "upload_time": "2022-02-27T08:36:33",
        "upload_time_iso_8601": "2022-02-27T08:36:33.551708Z",
        "url": "https://files.pythonhosted.org/packages/23/25/957c389ea43726ff85f88ceb1ec1b8d687468421f8eb65828f581e3a209b/BeiChenWordtokenizer-2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "2325957c389ea43726ff85f88ceb1ec1b8d687468421f8eb65828f581e3a209b",
        "md5": "c4e08380776b168399f34547d7ae7b08",
        "sha256": "02ee44159be1107cfe0ee7038e933a4b4ca05406a4d3674330b38580621bb049"
      },
      "downloads": -1,
      "filename": "BeiChenWordtokenizer-2.0.tar.gz",
      "has_sig": false,
      "md5_digest": "c4e08380776b168399f34547d7ae7b08",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.9",
      "size": 1343,
      "upload_time": "2022-02-27T08:36:33",
      "upload_time_iso_8601": "2022-02-27T08:36:33.551708Z",
      "url": "https://files.pythonhosted.org/packages/23/25/957c389ea43726ff85f88ceb1ec1b8d687468421f8eb65828f581e3a209b/BeiChenWordtokenizer-2.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}