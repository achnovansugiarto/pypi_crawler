{
  "info": {
    "author": "yindaheng98",
    "author_email": "yindaheng98@163.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# dblp-crawler\n\nAsynchronous high-concurrency dblp crawler, use with caution!\n\n异步高并发dblp爬虫，慎用！\n\n## Install\n\n```sh\npip install dblp-crawler\n```\n\n## Usage\n\n### Help\n\n```sh\npython -m dblp_crawler -h\nusage: __main__.py [-h] [-y YEAR] -k KEYWORD [-p PID] [-j JOURNAL] {networkx,neo4j} ...\n\npositional arguments:\n  {networkx,neo4j}      sub-command help\n    networkx            networkx help\n    neo4j               neo4j help\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -y YEAR, --year YEAR  Only crawl the paper after the specified year.\n  -k KEYWORD, --keyword KEYWORD\n                        Specify keyword rules.\n  -p PID, --pid PID     Specified author pids to start crawling.\n  -j JOURNAL, --journal JOURNAL\n                        Specify author journal keys to start crawling.\n```\n\n```sh\npython -m dblp_crawler networkx -h\nusage: __main__.py networkx [-h] --dest DEST\n\noptional arguments:\n  -h, --help   show this help message and exit\n  --dest DEST  Path to write results.\n```\n\n```sh\npython -m dblp_crawler neo4j -h   \nusage: __main__.py neo4j [-h] [--auth AUTH] --uri URI\n\noptional arguments:\n  -h, --help   show this help message and exit\n  --auth AUTH  Auth to neo4j database.\n  --uri URI    URI to neo4j database.\n```\n\n### Config environment variables\n\n* `DBLP_CRAWLER_MAX_CACHE_DAYS_PERSON`: \n  * save cache for a person page for how many days\n  * default: `30`\n* `DBLP_CRAWLER_MAX_CACHE_DAYS_JOURNAL`: \n  * save cache for a journal page for how many days\n  * default: `300`\n* `DBLP_CRAWLER_MAX_CACHE_DAYS_JOURNAL_LIST`\n  * save cache for a journal list page for how many days\n  * default: `300`\n\n### Write to a JSON file\n\ne.g. write to `summary.json`:\n\n```sh\npython -m dblp_crawler -k video -k edge -p l/JiangchuanLiu networkx --dest summary.json\n```\n\n### Write to a Neo4J database\n\ne.g. write to `neo4j://10.128.202.18:7687`:\n\n```sh\npython -m dblp_crawler -k video -k edge -p l/JiangchuanLiu neo4j --uri neo4j://10.128.202.18:7687\n```\n\n### Only crawl the paper after specified year\n\ne.g. crawl the paper after 2016 (include 2016)\n\n```sh\npython -m dblp_crawler -k video -k edge -p l/JiangchuanLiu -y 2016 networkx --dest summary.json\n```\n\n### Keywords with two or more words\n\ne.g. super resolution (publications with title contains both \"super\" and \"resolution\" will be selected)\n\n```sh\npython -m dblp_crawler -k video -k edge -p l/JiangchuanLiu -k \"'super','resolution'\" networkx --dest summary.json\n```\n\n### Init authors from journal\n\ne.g. init authors from ACM MM (`db/conf/mm` is the key for ACM MM in dblp: \"https://dblp.org/db/conf/mm/index.xml\")\n\n```sh\npython -m dblp_crawler -k video -k edge -j db/conf/fast networkx --dest summary.json\n```\n\n### Init authors from journal in some variables\n\ne.g. there is a `CCF_A` in `dblp_crawler.data` contains keys of CCF A conferences\n\n```sh\npython -m dblp_crawler -k video -k edge -j \"importlib.import_module('dblp_crawler.data').CCF_A\" networkx --dest summary.json\n```\n\n## `dblp_crawler.filter` Usage\n\n### Help\n\n```sh\npython -m dblp_crawler.filter -h                                                       \nusage: __main__.py [-h] -i INPUT -o OUTPUT -f FILTER\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -i INPUT, --input INPUT\n                        Input file path.\n  -o OUTPUT, --output OUTPUT\n                        Output file path.\n  -f FILTER, --filter FILTER\n                        Filter functions.\n```\n\n### Use internal filter\n\ne.g. `drop_old_publications` is an internal function that drop publication by year\n\n```sh\npython -m dblp_crawler.filter -i summary.json -o summary.filter.json -f \"lambda summary: drop_old_publications(summary, 2016)\"\n```\n\n### Use multiple filters\n\ne.g. `drop_old_publications` is an internal function that drop publications by year; `drop_nodes_by_all_publications` is an internal function that drop nodes by the sum of publications\n\n```sh\npython -m dblp_crawler.filter -i summary.json -o summary.filter.json \\\n  -f \"lambda summary: drop_old_publications(summary, 2016)\" \\\n  -f \"lambda summary: drop_old_person_publications(summary, 2018)\" \\\n  -f \"lambda summary: drop_old_cooperation(summary, 2018)\" \\\n  -f \"lambda summary: drop_nodes_by_all_publications(summary, 4)\" \\\n  -f \"lambda summary: drop_edges_by_all_publications(summary, 4)\"\n```\n\n### Use your own filter\n\ne.g. another method to use `-f \"lambda summary: drop_old_publications(summary, 2016)\"`\n\n```sh\npython -m dblp_crawler.filter -i summary.json -o summary.filter.json -f \"lambda summary: importlib.import_module('dblp_crawler.filter').drop_old_publications(summary, 2016)\"\n```\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/yindaheng98/dblp-crawler",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "dblp-crawler",
    "package_url": "https://pypi.org/project/dblp-crawler/",
    "platform": null,
    "project_url": "https://pypi.org/project/dblp-crawler/",
    "project_urls": {
      "Homepage": "https://github.com/yindaheng98/dblp-crawler"
    },
    "release_url": "https://pypi.org/project/dblp-crawler/1.6.2.1/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "异步高并发dblp爬虫，慎用",
    "version": "1.6.2.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17108544,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4b1149481823c6c1fa7890d0226a80b624cca567ddcb56d10aab26431ebd3ee5",
          "md5": "7c54c49b851f999ada49d1de1e65d385",
          "sha256": "c17eec806f80c1d3236aa0912492e99f594d3f1324279d5741e3bbea04b768eb"
        },
        "downloads": -1,
        "filename": "dblp_crawler-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "7c54c49b851f999ada49d1de1e65d385",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 8143,
        "upload_time": "2023-02-16T13:51:30",
        "upload_time_iso_8601": "2023-02-16T13:51:30.024890Z",
        "url": "https://files.pythonhosted.org/packages/4b/11/49481823c6c1fa7890d0226a80b624cca567ddcb56d10aab26431ebd3ee5/dblp_crawler-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b0c622e377b525b8bbf74efa7d966eb3b0f47d95e6a02f0a852c012f59800da4",
          "md5": "dd089b49c6c84ab30ac2d73d70fec035",
          "sha256": "aae887cd12325a28abd6591084813c0b5332b3fc48b66a515e5ebe8ae5f79812"
        },
        "downloads": -1,
        "filename": "dblp_crawler-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "dd089b49c6c84ab30ac2d73d70fec035",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 8138,
        "upload_time": "2023-02-17T09:18:53",
        "upload_time_iso_8601": "2023-02-17T09:18:53.144402Z",
        "url": "https://files.pythonhosted.org/packages/b0/c6/22e377b525b8bbf74efa7d966eb3b0f47d95e6a02f0a852c012f59800da4/dblp_crawler-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "95426c91d3fab0c8595a101b0286f2986727dce54ef63fe4eb429599d39ba6dc",
          "md5": "360f10b722cd694736c942604a60fbfd",
          "sha256": "b5de5dda7a7823d669632a5ea313e558ec4d260b34ad950bad2e0008536a8514"
        },
        "downloads": -1,
        "filename": "dblp_crawler-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "360f10b722cd694736c942604a60fbfd",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 8122,
        "upload_time": "2023-02-19T03:34:20",
        "upload_time_iso_8601": "2023-02-19T03:34:20.957985Z",
        "url": "https://files.pythonhosted.org/packages/95/42/6c91d3fab0c8595a101b0286f2986727dce54ef63fe4eb429599d39ba6dc/dblp_crawler-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "da543bbd10f504bb6cb5d1772453e0fffd1c4b543b1dd47020dd1cf42e8ee4d2",
          "md5": "4871e6297b2769c8e86aae2c298c0df7",
          "sha256": "a3c5c1502ac43a910168ca4337386389af2fd06e7cbcf2cd4291067a4733ab25"
        },
        "downloads": -1,
        "filename": "dblp_crawler-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "4871e6297b2769c8e86aae2c298c0df7",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 23905,
        "upload_time": "2023-02-19T06:11:04",
        "upload_time_iso_8601": "2023-02-19T06:11:04.163469Z",
        "url": "https://files.pythonhosted.org/packages/da/54/3bbd10f504bb6cb5d1772453e0fffd1c4b543b1dd47020dd1cf42e8ee4d2/dblp_crawler-0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a54fb60984843de3a008e53ee4c24f81e6f26ace0953378f08fbdf854f6c9342",
          "md5": "d234413f2245b572a865cbd3c7a6eeea",
          "sha256": "2c8acb7854b5951c6661f29b393e9821a138dc5b6b9ce83978c7758671b0d413"
        },
        "downloads": -1,
        "filename": "dblp_crawler-0.0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "d234413f2245b572a865cbd3c7a6eeea",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 25699,
        "upload_time": "2023-02-19T06:15:38",
        "upload_time_iso_8601": "2023-02-19T06:15:38.226285Z",
        "url": "https://files.pythonhosted.org/packages/a5/4f/b60984843de3a008e53ee4c24f81e6f26ace0953378f08fbdf854f6c9342/dblp_crawler-0.0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fa3da17b6807ea7b85f9be3d122678a5915457906e9c4699898be0edc0764995",
          "md5": "5e55b2a3b24a6e20cdeb89b593510310",
          "sha256": "17f7858dbc71bfb519c6b7b01f354e134a709e970790811963b5f67c70d5aae1"
        },
        "downloads": -1,
        "filename": "dblp_crawler-0.0.6.tar.gz",
        "has_sig": false,
        "md5_digest": "5e55b2a3b24a6e20cdeb89b593510310",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 26799,
        "upload_time": "2023-02-19T08:16:14",
        "upload_time_iso_8601": "2023-02-19T08:16:14.386392Z",
        "url": "https://files.pythonhosted.org/packages/fa/3d/a17b6807ea7b85f9be3d122678a5915457906e9c4699898be0edc0764995/dblp_crawler-0.0.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "51f0d9962359b92ba023ac396f3f8eac4cefd7b8c538e8d435a4d5718806a16f",
          "md5": "a32b334a98b7f5590415dc9277731660",
          "sha256": "5154c11cfdabb7f525fa8b74f0f97722c6b6dd3d70268e8a3ad40921b95cb5aa"
        },
        "downloads": -1,
        "filename": "dblp_crawler-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "a32b334a98b7f5590415dc9277731660",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 26305,
        "upload_time": "2023-02-20T12:59:20",
        "upload_time_iso_8601": "2023-02-20T12:59:20.322350Z",
        "url": "https://files.pythonhosted.org/packages/51/f0/d9962359b92ba023ac396f3f8eac4cefd7b8c538e8d435a4d5718806a16f/dblp_crawler-1.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3491b36f59fc40fc961efbbd5671f294104cdda3df23222cbaf5eb3ed16f7909",
          "md5": "2c4c9ece265ca63588c7c4f93a6bc5fc",
          "sha256": "3ddec5c3e72cba127c22dba6f11498a407a05e4d81ed36b99ae7f1dc0a99c36d"
        },
        "downloads": -1,
        "filename": "dblp_crawler-1.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "2c4c9ece265ca63588c7c4f93a6bc5fc",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 26330,
        "upload_time": "2023-02-20T13:06:24",
        "upload_time_iso_8601": "2023-02-20T13:06:24.072143Z",
        "url": "https://files.pythonhosted.org/packages/34/91/b36f59fc40fc961efbbd5671f294104cdda3df23222cbaf5eb3ed16f7909/dblp_crawler-1.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "eb0474f4b760a39cfbda09a3d4c5c236816983ed71c22e7a7f78f927dba2b83c",
          "md5": "61fd4743313a08fa70c1823be4e35da5",
          "sha256": "07b2382aa5c7a0122ea3c9a8d72c865e51d734611ac5d684ea60d1194f6d0309"
        },
        "downloads": -1,
        "filename": "dblp_crawler-1.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "61fd4743313a08fa70c1823be4e35da5",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 27940,
        "upload_time": "2023-02-20T13:54:21",
        "upload_time_iso_8601": "2023-02-20T13:54:21.956030Z",
        "url": "https://files.pythonhosted.org/packages/eb/04/74f4b760a39cfbda09a3d4c5c236816983ed71c22e7a7f78f927dba2b83c/dblp_crawler-1.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b98a2b269b11400ba21097096e1ea3bef874982fe439f8da8336e65a557e6fe1",
          "md5": "ee8f8d06f86a3a273a9d633d1f666a10",
          "sha256": "773360abfe7d715fce78f692930a64be57ea36454850b4eb67291852cd1add38"
        },
        "downloads": -1,
        "filename": "dblp_crawler-1.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "ee8f8d06f86a3a273a9d633d1f666a10",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 28217,
        "upload_time": "2023-02-20T14:19:10",
        "upload_time_iso_8601": "2023-02-20T14:19:10.319196Z",
        "url": "https://files.pythonhosted.org/packages/b9/8a/2b269b11400ba21097096e1ea3bef874982fe439f8da8336e65a557e6fe1/dblp_crawler-1.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6c55a1370383e6dc8b4cbdefcba7209c220b6774e77ece916d088ae10a95d2c9",
          "md5": "a62dd6a16240c58850e705e6c45f2c62",
          "sha256": "714f7f6392b3a7b971f83ef6daa87a6a5754089fe0d6cb5fcf4f20a6da3bf7d1"
        },
        "downloads": -1,
        "filename": "dblp_crawler-1.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "a62dd6a16240c58850e705e6c45f2c62",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 28262,
        "upload_time": "2023-02-20T14:27:21",
        "upload_time_iso_8601": "2023-02-20T14:27:21.192460Z",
        "url": "https://files.pythonhosted.org/packages/6c/55/a1370383e6dc8b4cbdefcba7209c220b6774e77ece916d088ae10a95d2c9/dblp_crawler-1.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.3.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5581d6c0a3c929f3667c24aff9d8b29ae05632861657662bf7ae688bc22150d9",
          "md5": "f80c0142cb41e73c148cc81c0d276403",
          "sha256": "08d4efb876f714953fd66f0a3056f9149858d4ba6984ba752c63a72ca442b296"
        },
        "downloads": -1,
        "filename": "dblp_crawler-1.3.0.tar.gz",
        "has_sig": false,
        "md5_digest": "f80c0142cb41e73c148cc81c0d276403",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 28238,
        "upload_time": "2023-02-23T08:43:32",
        "upload_time_iso_8601": "2023-02-23T08:43:32.078364Z",
        "url": "https://files.pythonhosted.org/packages/55/81/d6c0a3c929f3667c24aff9d8b29ae05632861657662bf7ae688bc22150d9/dblp_crawler-1.3.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.4.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "23f1cbbca093c65f723edad6228542bf83dbb6b4b20a93191761bd36fd10c379",
          "md5": "2d2192c9a9b5ecd91a1bdf38829abfb7",
          "sha256": "c0700e9c2a6b4ae7c44e8de9757b3a960dbeb0081d25a1aa2c0a3d10c285b98a"
        },
        "downloads": -1,
        "filename": "dblp_crawler-1.4.0.tar.gz",
        "has_sig": false,
        "md5_digest": "2d2192c9a9b5ecd91a1bdf38829abfb7",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 29840,
        "upload_time": "2023-02-24T12:06:53",
        "upload_time_iso_8601": "2023-02-24T12:06:53.331527Z",
        "url": "https://files.pythonhosted.org/packages/23/f1/cbbca093c65f723edad6228542bf83dbb6b4b20a93191761bd36fd10c379/dblp_crawler-1.4.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.4.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "88a62ab612b17a72ffaa3e2f50e9994c5d427e6b645599e3322d08ed448cd5ad",
          "md5": "f8d780901c8b4b76a6f4986d2e9a5367",
          "sha256": "bf2161fa2b5f8d9abe76f7eb4d2242164ef5f9862a6cd5a0d1229161750cb7f3"
        },
        "downloads": -1,
        "filename": "dblp_crawler-1.4.1.tar.gz",
        "has_sig": false,
        "md5_digest": "f8d780901c8b4b76a6f4986d2e9a5367",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 29856,
        "upload_time": "2023-02-24T12:09:24",
        "upload_time_iso_8601": "2023-02-24T12:09:24.616629Z",
        "url": "https://files.pythonhosted.org/packages/88/a6/2ab612b17a72ffaa3e2f50e9994c5d427e6b645599e3322d08ed448cd5ad/dblp_crawler-1.4.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.5.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bf4250e8e216993d76c731da12f7a23da624d9a03653c28080294c4f756f2088",
          "md5": "41e24fc332e0b692fb234472ead21194",
          "sha256": "07b152ee28191ea5f06d49dd67ac8b8e9b08a70c1c4f28034e0cde7755209f26"
        },
        "downloads": -1,
        "filename": "dblp_crawler-1.5.0.tar.gz",
        "has_sig": false,
        "md5_digest": "41e24fc332e0b692fb234472ead21194",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 30089,
        "upload_time": "2023-02-26T06:43:21",
        "upload_time_iso_8601": "2023-02-26T06:43:21.107602Z",
        "url": "https://files.pythonhosted.org/packages/bf/42/50e8e216993d76c731da12f7a23da624d9a03653c28080294c4f756f2088/dblp_crawler-1.5.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.6.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "161c8db3b4635791e71c02b09f2fec033769648b51173217a62c170dfe26a25f",
          "md5": "80e04e57b027ca68533585b95b2762ca",
          "sha256": "afe289479915bef4d46e81ba1b9119ded4b4e152c071b78b249b09022e7b29be"
        },
        "downloads": -1,
        "filename": "dblp_crawler-1.6.0.tar.gz",
        "has_sig": false,
        "md5_digest": "80e04e57b027ca68533585b95b2762ca",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 30624,
        "upload_time": "2023-03-01T08:26:45",
        "upload_time_iso_8601": "2023-03-01T08:26:45.650448Z",
        "url": "https://files.pythonhosted.org/packages/16/1c/8db3b4635791e71c02b09f2fec033769648b51173217a62c170dfe26a25f/dblp_crawler-1.6.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.6.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "dde2c493727c3e1162e87e1d9a0ba2f31f00bbd95c736db54693392b605d1790",
          "md5": "4eed35ac0fa451f2f1f535ffd0c4ad4b",
          "sha256": "701f03d1b25536a4f40641569fa2ad1c4a8b88ab0581189975ff0172f8dcd4b6"
        },
        "downloads": -1,
        "filename": "dblp_crawler-1.6.1.tar.gz",
        "has_sig": false,
        "md5_digest": "4eed35ac0fa451f2f1f535ffd0c4ad4b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 30628,
        "upload_time": "2023-03-01T08:30:23",
        "upload_time_iso_8601": "2023-03-01T08:30:23.533622Z",
        "url": "https://files.pythonhosted.org/packages/dd/e2/c493727c3e1162e87e1d9a0ba2f31f00bbd95c736db54693392b605d1790/dblp_crawler-1.6.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.6.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "22ccc21bac3285c2a3244bd0c7e322cadc0cfe401a388890fd9a2aea321f2597",
          "md5": "40508ddd1a1b566c03c0e4305d2f6d38",
          "sha256": "52a61b250e61043002e1dad3f4670c12a6d3443768e98981ec30a9f857f25f43"
        },
        "downloads": -1,
        "filename": "dblp_crawler-1.6.2.tar.gz",
        "has_sig": false,
        "md5_digest": "40508ddd1a1b566c03c0e4305d2f6d38",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 30600,
        "upload_time": "2023-03-01T08:33:46",
        "upload_time_iso_8601": "2023-03-01T08:33:46.027228Z",
        "url": "https://files.pythonhosted.org/packages/22/cc/c21bac3285c2a3244bd0c7e322cadc0cfe401a388890fd9a2aea321f2597/dblp_crawler-1.6.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.6.2.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "59ccd9402b45ea24fa4178a81e4c9204b4313f89458981bae2eed7e6c59d23f0",
          "md5": "4a9bf0407bc2e251fc9dd1881087e382",
          "sha256": "589398f6c2cc17a4ffa585405d5e065d2d612b95f5d587b7c37c3b8b715745eb"
        },
        "downloads": -1,
        "filename": "dblp_crawler-1.6.2.1.tar.gz",
        "has_sig": false,
        "md5_digest": "4a9bf0407bc2e251fc9dd1881087e382",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 30630,
        "upload_time": "2023-03-01T08:40:51",
        "upload_time_iso_8601": "2023-03-01T08:40:51.850959Z",
        "url": "https://files.pythonhosted.org/packages/59/cc/d9402b45ea24fa4178a81e4c9204b4313f89458981bae2eed7e6c59d23f0/dblp_crawler-1.6.2.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "59ccd9402b45ea24fa4178a81e4c9204b4313f89458981bae2eed7e6c59d23f0",
        "md5": "4a9bf0407bc2e251fc9dd1881087e382",
        "sha256": "589398f6c2cc17a4ffa585405d5e065d2d612b95f5d587b7c37c3b8b715745eb"
      },
      "downloads": -1,
      "filename": "dblp_crawler-1.6.2.1.tar.gz",
      "has_sig": false,
      "md5_digest": "4a9bf0407bc2e251fc9dd1881087e382",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 30630,
      "upload_time": "2023-03-01T08:40:51",
      "upload_time_iso_8601": "2023-03-01T08:40:51.850959Z",
      "url": "https://files.pythonhosted.org/packages/59/cc/d9402b45ea24fa4178a81e4c9204b4313f89458981bae2eed7e6c59d23f0/dblp_crawler-1.6.2.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}