{
  "info": {
    "author": "ZhouYang Luo",
    "author_email": "zhouyang.luo@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Topic :: Scientific/Engineering :: Artificial Intelligence"
    ],
    "description": "# smile-datasets\n\n![Python package](https://github.com/luozhouyang/smile-datasets/workflows/Python%20package/badge.svg)\n[![PyPI version](https://badge.fury.io/py/smile-datasets.svg)](https://badge.fury.io/py/smile-datasets)\n[![Python](https://img.shields.io/pypi/pyversions/smile-datasets.svg?style=plastic)](https://badge.fury.io/py/smile-datasets)\n\n\nLa**S**t **mile** Datasets: Use `tf.data` to solve the last mile data loading problem for tensorflow.\n\nIf you want to load public datasets, try:\n\n* [tensorflow/datasets](https://github.com/tensorflow/datasets)\n* [huggingface/datasets](https://github.com/huggingface/datasets)\n\nIf you want to load local, personal dataset with minimized boilerplate, use **Smile Dataset**!\n\n## Support Matrix\n\n| task                   | supported  | core abstractions |\n|:-----------------------|:-----------|:------------------|\n| question answering     | [x]        | `ExampleForQuestionAnswering`, `DatasetForQuestionAnswering`, `DatapipeForQuestionAnswering`|\n| masked language model  | [x]        | `ExampleForMaskedLanguageModel`, `DatasetForMaskedLanguageModel`, `DatapipeForMaskedLanguageModel`|\n| sequence classification| [x]        | `ExampleForSequenceClassification`, `DatasetForSequenceClassification`, `DatapipeForSequenceClassification`|\n| token classification   | [x]        | `ExampleForTokenClassification`, `DatasetForTokenClassification`, `DatapipeForTokenClassification`|\n| unsupervised simcse    | [x]        | `ExampleForUnsupervisedSimCSE`, `DatasetForUnsupervisedSimCSE`, `DatapipeForUnsupervisedSimCSE`|\n| supervised simcse      | [x]        | `ExampleForSupervisedSimCSE`, `DatasetForSupervisedSimCSE`, `DatapipeForSupervisedSimCSE`|\n| hard negative simcse   | [x]        | `ExampleForHardNegativeSimCSE`, `DatasetForHardNegativeSimCSE`, `DatapipeForHardNegativeSimCSE`|\n\n\n## Usage\n\nAll datapipes for different tasks has the same interface.\n\nHere is an example for question answering task, but you can use datapipe the same way for other tasks.\n\n### Example for Question Answering\n\n```python\n\nfrom smile_datasets import DatasetForQuestionAnswering, DatapipeForQuestionAnswering\n\n# each line is a JSON {\"sequece\": \"我喜欢自然语言处理(NLP)\"}\ntrain_input_jsonl_files = [\"data/train.jsonl\"]\ntrain_dataset = DatapipeForQuestionAnswering.from_jsonl_files(\n    input_files=train_input_jsonl_files, \n    vocab_file=\"bert/vocab.txt\",\n    batch_size=32,\n)\n\n# check dataset\nprint(next(iter(train_dataset)))\n\n# model = build_keras_model(...)\n# model.compile(...)\n# train model\nmodel.fit(train_dataset, callbacks=[...])\n\n```\n\n\nFor maximum flexibility, you can always subclass `DatasetForQuestionAnswering` to load your dataset, just like `torch.utils.data.Dataset`:\n\n```python\nfrom smile_datasets import DatasetForQuestionAnswering, DatapipeForQuestionAnswering, ParserForQuestionAnswering\n\nclass DuReaderDatasetForQuestionAnswering(DatasetForQuestionAnswering):\n    \"\"\"Dataset reader for DuReader dataset.\"\"\"\n\n    def __init__(self, input_files, vocab_file, subset=\"rubost\", **kwargs) -> None:\n        super().__init__()\n        self.parser = ParserForQuestionAnswering(tokenizer=None, vocab_file=vocab_file, **kwargs)\n        if subset == \"rubost\":\n            self.instances = list(readers.read_dureader_rubost(input_files, **kwargs))\n        else:\n            self.instances = list(readers.read_dureader_checklist(input_files, **kwargs))\n        self.examples = []\n        for instance in self.instances:\n            e = self.parser.parse(instance)\n            if not e:\n                continue\n            self.examples.append(e)\n\n    def __len__(self):\n        return len(self.examples)\n\n    def __getitem__(self, index) -> ExampleForQuestionAnswering:\n        return self.examples[index]\n\n\ndataset = DuReaderDatasetForQuestionAnswering(input_files=[\"data/trian.jsonl\"], vocab_file=\"bert/vocab.txt\")\ntrain_dataset = DatapipeForQuestionAnswering.from_dataset(dataset, batch_size=32)\n\n# check dataset\nprint(next(iter(train_dataset)))\n\n# model = build_keras_model(...)\n# model.compile(...)\n# train model\nmodel.fit(train_dataset, callbacks=[...])\n```\n\nFor better performance, you can convert `dataset` to `tfrecord` ahead of time, and then build datapipe from tfrecord files directly:\n\n```python\n# save dataset in tfrecord format\ndataset.save_tfrecord(output_files=\"data/train.tfrecord\")\n\n# build datapipe from tfrecord files\ntrain_dataset = DatapipeForQuestionAnswering.from_tfrecord_files(input_files=\"data/train.tfrecord\", batch_size=32)\n\n# check dataset\nprint(next(iter(train_dataset)))\n\n# model = build_keras_model(...)\n# model.compile(...)\n# train model\nmodel.fit(train_dataset, callbacks=[...])\n```\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/luozhouyang/smile-datasets",
    "keywords": "",
    "license": "Apache Software License",
    "maintainer": "",
    "maintainer_email": "",
    "name": "smile-datasets",
    "package_url": "https://pypi.org/project/smile-datasets/",
    "platform": "",
    "project_url": "https://pypi.org/project/smile-datasets/",
    "project_urls": {
      "Homepage": "https://github.com/luozhouyang/smile-datasets"
    },
    "release_url": "https://pypi.org/project/smile-datasets/0.0.6/",
    "requires_dist": [
      "tokenizers",
      "tensorflow"
    ],
    "requires_python": "",
    "summary": "La**S**t **mile** datasets: Use `tf.data` to solve the last mile data loading problem for tensorflow.",
    "version": "0.0.6",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12091326,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "02ba222c570459b5f59548c536a2f355d70bed760c154870983826be81fa7cea",
          "md5": "c5708948d4fdbbd85f310804cd87bb4b",
          "sha256": "03b23c0d6b956b1f6f44af08656841d00d3ad99f77941b9ebdd8e62c86709ffb"
        },
        "downloads": -1,
        "filename": "smile_datasets-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "c5708948d4fdbbd85f310804cd87bb4b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 13780,
        "upload_time": "2021-11-19T09:09:40",
        "upload_time_iso_8601": "2021-11-19T09:09:40.069644Z",
        "url": "https://files.pythonhosted.org/packages/02/ba/222c570459b5f59548c536a2f355d70bed760c154870983826be81fa7cea/smile_datasets-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "47ceca4cc3e0f98122f57b2c8467b030440cf74d5e0c778f64cac0b46aca5577",
          "md5": "af673ae4ea23c132bff96f5fc3b4d018",
          "sha256": "cd7620b462e2d6b81968f890efc613f6ebfbf6c5d5b372658b07bd99cf5deda5"
        },
        "downloads": -1,
        "filename": "smile-datasets-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "af673ae4ea23c132bff96f5fc3b4d018",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 10797,
        "upload_time": "2021-11-19T09:09:41",
        "upload_time_iso_8601": "2021-11-19T09:09:41.967987Z",
        "url": "https://files.pythonhosted.org/packages/47/ce/ca4cc3e0f98122f57b2c8467b030440cf74d5e0c778f64cac0b46aca5577/smile-datasets-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9dbb80cf421cfa7ba032d34d487b6cc2205d28a3ba55af4a5da9489c6f4557a7",
          "md5": "ac03fd615b10ed832c1e7a3a2de21df0",
          "sha256": "04b5af762bf9fd174b8c91a57819898c1e77ae11b8f70e2150a981149e1cc49d"
        },
        "downloads": -1,
        "filename": "smile_datasets-0.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ac03fd615b10ed832c1e7a3a2de21df0",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 35253,
        "upload_time": "2021-11-21T14:21:24",
        "upload_time_iso_8601": "2021-11-21T14:21:24.524267Z",
        "url": "https://files.pythonhosted.org/packages/9d/bb/80cf421cfa7ba032d34d487b6cc2205d28a3ba55af4a5da9489c6f4557a7/smile_datasets-0.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "84fe61bbb547c1accc0b669e5d5060a8bd535665ae874af8933d90c14132a954",
          "md5": "4223ad9fcdaf9e8f08467f37a22dacc5",
          "sha256": "cabf59d04617b617213c39d2eae58c0c32e1f1f8839e194e8aeb05f1797b68ba"
        },
        "downloads": -1,
        "filename": "smile-datasets-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "4223ad9fcdaf9e8f08467f37a22dacc5",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 19735,
        "upload_time": "2021-11-21T14:21:26",
        "upload_time_iso_8601": "2021-11-21T14:21:26.161328Z",
        "url": "https://files.pythonhosted.org/packages/84/fe/61bbb547c1accc0b669e5d5060a8bd535665ae874af8933d90c14132a954/smile-datasets-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3d15c62ad274059d7d45444992ac2f02417f7bcf90a837c2576fb3d2075bfd49",
          "md5": "b17cedb2ccdcf7db4585b758ada8e5c8",
          "sha256": "0953be9f1349d29bc703b35bf5bcc9f2c98f1024889d843b8b28080096c7c2f2"
        },
        "downloads": -1,
        "filename": "smile_datasets-0.0.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "b17cedb2ccdcf7db4585b758ada8e5c8",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 42060,
        "upload_time": "2021-11-21T14:57:59",
        "upload_time_iso_8601": "2021-11-21T14:57:59.309858Z",
        "url": "https://files.pythonhosted.org/packages/3d/15/c62ad274059d7d45444992ac2f02417f7bcf90a837c2576fb3d2075bfd49/smile_datasets-0.0.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "af078240aefb2a9dfccbe2fcd080b52edab76e609ffdcf820d12ca2325526dde",
          "md5": "786fcb75e5b49a46a1a4377aedffcde0",
          "sha256": "a6bf8b6b5e0d160603c34062f55807585bba54ca5f0e6761848eb2a7b8226118"
        },
        "downloads": -1,
        "filename": "smile-datasets-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "786fcb75e5b49a46a1a4377aedffcde0",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 23613,
        "upload_time": "2021-11-21T14:58:01",
        "upload_time_iso_8601": "2021-11-21T14:58:01.043067Z",
        "url": "https://files.pythonhosted.org/packages/af/07/8240aefb2a9dfccbe2fcd080b52edab76e609ffdcf820d12ca2325526dde/smile-datasets-0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0f1743668055209c38d5618e61d12cf97cb845a2220e244c8ffc78230993c431",
          "md5": "a6383f337665313921b625f7fe726ee3",
          "sha256": "297ca8ae3e76cf9b6e93484e8565930a727ceeda511a8d00b13c2f68123c4ae6"
        },
        "downloads": -1,
        "filename": "smile_datasets-0.0.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "a6383f337665313921b625f7fe726ee3",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 42145,
        "upload_time": "2021-11-22T02:28:37",
        "upload_time_iso_8601": "2021-11-22T02:28:37.279814Z",
        "url": "https://files.pythonhosted.org/packages/0f/17/43668055209c38d5618e61d12cf97cb845a2220e244c8ffc78230993c431/smile_datasets-0.0.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "31a6730dbcb0cd3646853479ca9273f775ec28e44c9bfe8110473ef98b8e1b7e",
          "md5": "ddba9f3747c6064639f454c13f4ed1ab",
          "sha256": "f3466dd43ce3bddf85e0f64ee63a5425999144838ff195b48b87cb799a0d3361"
        },
        "downloads": -1,
        "filename": "smile-datasets-0.0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "ddba9f3747c6064639f454c13f4ed1ab",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 23789,
        "upload_time": "2021-11-22T02:28:38",
        "upload_time_iso_8601": "2021-11-22T02:28:38.607192Z",
        "url": "https://files.pythonhosted.org/packages/31/a6/730dbcb0cd3646853479ca9273f775ec28e44c9bfe8110473ef98b8e1b7e/smile-datasets-0.0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a37c1ce87e87ebc2267591494e0fb3dc56f49646f069c14666e8cb7787262466",
          "md5": "515b6dd0fe79d1b44736de393dc87ab1",
          "sha256": "bb12a3f674f309c8b2841251ebc02926c7eb4aa42a82a4deb6aa1589994547f6"
        },
        "downloads": -1,
        "filename": "smile_datasets-0.0.6-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "515b6dd0fe79d1b44736de393dc87ab1",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 42158,
        "upload_time": "2021-11-22T12:12:02",
        "upload_time_iso_8601": "2021-11-22T12:12:02.718261Z",
        "url": "https://files.pythonhosted.org/packages/a3/7c/1ce87e87ebc2267591494e0fb3dc56f49646f069c14666e8cb7787262466/smile_datasets-0.0.6-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7228bdee1d8fadf99f99daea01b0a09546932871fb995e82838c6c59e5c94ffb",
          "md5": "a8d77df596e6fcf240bbb5edacf783fa",
          "sha256": "786b4fd408e02c77dda4dcf725ddc4928a73b048e453c03e56b138cae8f7059b"
        },
        "downloads": -1,
        "filename": "smile-datasets-0.0.6.tar.gz",
        "has_sig": false,
        "md5_digest": "a8d77df596e6fcf240bbb5edacf783fa",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 23777,
        "upload_time": "2021-11-22T12:12:04",
        "upload_time_iso_8601": "2021-11-22T12:12:04.105394Z",
        "url": "https://files.pythonhosted.org/packages/72/28/bdee1d8fadf99f99daea01b0a09546932871fb995e82838c6c59e5c94ffb/smile-datasets-0.0.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "a37c1ce87e87ebc2267591494e0fb3dc56f49646f069c14666e8cb7787262466",
        "md5": "515b6dd0fe79d1b44736de393dc87ab1",
        "sha256": "bb12a3f674f309c8b2841251ebc02926c7eb4aa42a82a4deb6aa1589994547f6"
      },
      "downloads": -1,
      "filename": "smile_datasets-0.0.6-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "515b6dd0fe79d1b44736de393dc87ab1",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 42158,
      "upload_time": "2021-11-22T12:12:02",
      "upload_time_iso_8601": "2021-11-22T12:12:02.718261Z",
      "url": "https://files.pythonhosted.org/packages/a3/7c/1ce87e87ebc2267591494e0fb3dc56f49646f069c14666e8cb7787262466/smile_datasets-0.0.6-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "7228bdee1d8fadf99f99daea01b0a09546932871fb995e82838c6c59e5c94ffb",
        "md5": "a8d77df596e6fcf240bbb5edacf783fa",
        "sha256": "786b4fd408e02c77dda4dcf725ddc4928a73b048e453c03e56b138cae8f7059b"
      },
      "downloads": -1,
      "filename": "smile-datasets-0.0.6.tar.gz",
      "has_sig": false,
      "md5_digest": "a8d77df596e6fcf240bbb5edacf783fa",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 23777,
      "upload_time": "2021-11-22T12:12:04",
      "upload_time_iso_8601": "2021-11-22T12:12:04.105394Z",
      "url": "https://files.pythonhosted.org/packages/72/28/bdee1d8fadf99f99daea01b0a09546932871fb995e82838c6c59e5c94ffb/smile-datasets-0.0.6.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}