{
  "info": {
    "author": "Kaiyu Li, Fulin Sun, Xudong Liu",
    "author_email": "likyoo@sdust.edu.cn",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: Implementation :: CPython",
      "Programming Language :: Python :: Implementation :: PyPy"
    ],
    "description": "\n<h1 align=\"center\">\n  <b>Change Detection Models</b><br>\n</h1>\n<p align=\"center\">\n      <b>Python library with Neural Networks for Change Detection based on PyTorch.</b>\n</p>\n\n\n<img src=\"https://raw.githubusercontent.com/likyoo/change_detection.pytorch/main/resources/model%20architecture.png\" alt=\"model architecture\" style=\"zoom:80%;\" />\n\n\nThis project is inspired by **[segmentation_models.pytorch](https://github.com/qubvel/segmentation_models.pytorch)** and built based on it. 😄\n\n### 🌱 How to use <a name=\"use\"></a>\n\nPlease refer to local_test.py temporarily.\n\n\n\n### 🔭 Models <a name=\"models\"></a>\n\n#### Architectures <a name=\"architectures\"></a>\n- [x] Unet [[paper](https://arxiv.org/abs/1505.04597)]\n\n- [x] Unet++ [[paper](https://arxiv.org/pdf/1807.10165.pdf)]\n\n- [x] MAnet [[paper](https://ieeexplore.ieee.org/abstract/document/9201310)]\n\n- [x] Linknet [[paper](https://arxiv.org/abs/1707.03718)]\n\n- [x] FPN [[paper](http://presentations.cocodataset.org/COCO17-Stuff-FAIR.pdf)]\n\n- [x] PSPNet [[paper](https://arxiv.org/abs/1612.01105)]\n\n- [x] PAN [[paper](https://arxiv.org/abs/1805.10180)]\n\n- [x] DeepLabV3 [[paper](https://arxiv.org/abs/1706.05587)]\n\n- [x] DeepLabV3+ [[paper](https://arxiv.org/abs/1802.02611)]\n\n- [x] UPerNet [[paper](https://arxiv.org/abs/1807.10221)]\n\n- [x] STANet [[paper](https://www.mdpi.com/2072-4292/12/10/1662)]\n\n#### Encoders <a name=\"encoders\"></a>\n\nThe following is a list of supported encoders in the CDP. Select the appropriate family of encoders and click to expand the table and select a specific encoder and its pre-trained weights (`encoder_name` and `encoder_weights` parameters).\n\n<details>\n<summary style=\"margin-left: 25px;\">ResNet</summary>\n<div style=\"margin-left: 25px;\">\n\n| Encoder   |        Weights        | Params, M |\n| --------- | :-------------------: | :-------: |\n| resnet18  | imagenet / ssl / swsl |    11M    |\n| resnet34  |       imagenet        |    21M    |\n| resnet50  | imagenet / ssl / swsl |    23M    |\n| resnet101 |       imagenet        |    42M    |\n| resnet152 |       imagenet        |    58M    |\n\n</div>\n</details>\n\n<details>\n<summary style=\"margin-left: 25px;\">ResNeXt</summary>\n<div style=\"margin-left: 25px;\">\n\n| Encoder           |              Weights              | Params, M |\n| ----------------- | :-------------------------------: | :-------: |\n| resnext50_32x4d   |       imagenet / ssl / swsl       |    22M    |\n| resnext101_32x4d  |            ssl / swsl             |    42M    |\n| resnext101_32x8d  | imagenet / instagram / ssl / swsl |    86M    |\n| resnext101_32x16d |      instagram / ssl / swsl       |   191M    |\n| resnext101_32x32d |             instagram             |   466M    |\n| resnext101_32x48d |             instagram             |   826M    |\n\n</div>\n</details>\n\n<details>\n<summary style=\"margin-left: 25px;\">ResNeSt</summary>\n<div style=\"margin-left: 25px;\">\n\n| Encoder                 | Weights  | Params, M |\n| ----------------------- | :------: | :-------: |\n| timm-resnest14d         | imagenet |    8M     |\n| timm-resnest26d         | imagenet |    15M    |\n| timm-resnest50d         | imagenet |    25M    |\n| timm-resnest101e        | imagenet |    46M    |\n| timm-resnest200e        | imagenet |    68M    |\n| timm-resnest269e        | imagenet |   108M    |\n| timm-resnest50d_4s2x40d | imagenet |    28M    |\n| timm-resnest50d_1s4x24d | imagenet |    23M    |\n\n</div>\n</details>\n\n<details>\n<summary style=\"margin-left: 25px;\">Res2Ne(X)t</summary>\n<div style=\"margin-left: 25px;\">\n\n| Encoder                | Weights  | Params, M |\n| ---------------------- | :------: | :-------: |\n| timm-res2net50_26w_4s  | imagenet |    23M    |\n| timm-res2net101_26w_4s | imagenet |    43M    |\n| timm-res2net50_26w_6s  | imagenet |    35M    |\n| timm-res2net50_26w_8s  | imagenet |    46M    |\n| timm-res2net50_48w_2s  | imagenet |    23M    |\n| timm-res2net50_14w_8s  | imagenet |    23M    |\n| timm-res2next50        | imagenet |    22M    |\n\n</div>\n</details>\n\n<details>\n<summary style=\"margin-left: 25px;\">RegNet(x/y)</summary>\n<div style=\"margin-left: 25px;\">\n\n| Encoder          | Weights  | Params, M |\n| ---------------- | :------: | :-------: |\n| timm-regnetx_002 | imagenet |    2M     |\n| timm-regnetx_004 | imagenet |    4M     |\n| timm-regnetx_006 | imagenet |    5M     |\n| timm-regnetx_008 | imagenet |    6M     |\n| timm-regnetx_016 | imagenet |    8M     |\n| timm-regnetx_032 | imagenet |    14M    |\n| timm-regnetx_040 | imagenet |    20M    |\n| timm-regnetx_064 | imagenet |    24M    |\n| timm-regnetx_080 | imagenet |    37M    |\n| timm-regnetx_120 | imagenet |    43M    |\n| timm-regnetx_160 | imagenet |    52M    |\n| timm-regnetx_320 | imagenet |   105M    |\n| timm-regnety_002 | imagenet |    2M     |\n| timm-regnety_004 | imagenet |    3M     |\n| timm-regnety_006 | imagenet |    5M     |\n| timm-regnety_008 | imagenet |    5M     |\n| timm-regnety_016 | imagenet |    10M    |\n| timm-regnety_032 | imagenet |    17M    |\n| timm-regnety_040 | imagenet |    19M    |\n| timm-regnety_064 | imagenet |    29M    |\n| timm-regnety_080 | imagenet |    37M    |\n| timm-regnety_120 | imagenet |    49M    |\n| timm-regnety_160 | imagenet |    80M    |\n| timm-regnety_320 | imagenet |   141M    |\n\n</div>\n</details>\n\n<details>\n<summary style=\"margin-left: 25px;\">GERNet</summary>\n<div style=\"margin-left: 25px;\">\n\n| Encoder       | Weights  | Params, M |\n| ------------- | :------: | :-------: |\n| timm-gernet_s | imagenet |    6M     |\n| timm-gernet_m | imagenet |    18M    |\n| timm-gernet_l | imagenet |    28M    |\n\n</div>\n</details>\n\n<details>\n<summary style=\"margin-left: 25px;\">SE-Net</summary>\n<div style=\"margin-left: 25px;\">\n\n| Encoder             | Weights  | Params, M |\n| ------------------- | :------: | :-------: |\n| senet154            | imagenet |   113M    |\n| se_resnet50         | imagenet |    26M    |\n| se_resnet101        | imagenet |    47M    |\n| se_resnet152        | imagenet |    64M    |\n| se_resnext50_32x4d  | imagenet |    25M    |\n| se_resnext101_32x4d | imagenet |    46M    |\n\n</div>\n</details>\n\n<details>\n<summary style=\"margin-left: 25px;\">SK-ResNe(X)t</summary>\n<div style=\"margin-left: 25px;\">\n\n| Encoder                | Weights  | Params, M |\n| ---------------------- | :------: | :-------: |\n| timm-skresnet18        | imagenet |    11M    |\n| timm-skresnet34        | imagenet |    21M    |\n| timm-skresnext50_32x4d | imagenet |    25M    |\n\n</div>\n</details>\n\n<details>\n<summary style=\"margin-left: 25px;\">DenseNet</summary>\n<div style=\"margin-left: 25px;\">\n\n| Encoder     | Weights  | Params, M |\n| ----------- | :------: | :-------: |\n| densenet121 | imagenet |    6M     |\n| densenet169 | imagenet |    12M    |\n| densenet201 | imagenet |    18M    |\n| densenet161 | imagenet |    26M    |\n\n</div>\n</details>\n\n<details>\n<summary style=\"margin-left: 25px;\">Inception</summary>\n<div style=\"margin-left: 25px;\">\n\n| Encoder           |             Weights             | Params, M |\n| ----------------- | :-----------------------------: | :-------: |\n| inceptionresnetv2 | imagenet /  imagenet+background |    54M    |\n| inceptionv4       | imagenet /  imagenet+background |    41M    |\n| xception          |            imagenet             |    22M    |\n\n</div>\n</details>\n\n<details>\n<summary style=\"margin-left: 25px;\">EfficientNet</summary>\n<div style=\"margin-left: 25px;\">\n\n| Encoder                 |              Weights               | Params, M |\n| ----------------------- | :--------------------------------: | :-------: |\n| efficientnet-b0         |              imagenet              |    4M     |\n| efficientnet-b1         |              imagenet              |    6M     |\n| efficientnet-b2         |              imagenet              |    7M     |\n| efficientnet-b3         |              imagenet              |    10M    |\n| efficientnet-b4         |              imagenet              |    17M    |\n| efficientnet-b5         |              imagenet              |    28M    |\n| efficientnet-b6         |              imagenet              |    40M    |\n| efficientnet-b7         |              imagenet              |    63M    |\n| timm-efficientnet-b0    | imagenet / advprop / noisy-student |    4M     |\n| timm-efficientnet-b1    | imagenet / advprop / noisy-student |    6M     |\n| timm-efficientnet-b2    | imagenet / advprop / noisy-student |    7M     |\n| timm-efficientnet-b3    | imagenet / advprop / noisy-student |    10M    |\n| timm-efficientnet-b4    | imagenet / advprop / noisy-student |    17M    |\n| timm-efficientnet-b5    | imagenet / advprop / noisy-student |    28M    |\n| timm-efficientnet-b6    | imagenet / advprop / noisy-student |    40M    |\n| timm-efficientnet-b7    | imagenet / advprop / noisy-student |    63M    |\n| timm-efficientnet-b8    |         imagenet / advprop         |    84M    |\n| timm-efficientnet-l2    |           noisy-student            |   474M    |\n| timm-efficientnet-lite0 |              imagenet              |    4M     |\n| timm-efficientnet-lite1 |              imagenet              |    5M     |\n| timm-efficientnet-lite2 |              imagenet              |    6M     |\n| timm-efficientnet-lite3 |              imagenet              |    8M     |\n| timm-efficientnet-lite4 |              imagenet              |    13M    |\n\n</div>\n</details>\n\n<details>\n<summary style=\"margin-left: 25px;\">MobileNet</summary>\n<div style=\"margin-left: 25px;\">\n\n| Encoder                            | Weights  | Params, M |\n| ---------------------------------- | :------: | :-------: |\n| mobilenet_v2                       | imagenet |    2M     |\n| timm-mobilenetv3_large_075         | imagenet |   1.78M   |\n| timm-mobilenetv3_large_100         | imagenet |   2.97M   |\n| timm-mobilenetv3_large_minimal_100 | imagenet |   1.41M   |\n| timm-mobilenetv3_small_075         | imagenet |   0.57M   |\n| timm-mobilenetv3_small_100         | imagenet |   0.93M   |\n| timm-mobilenetv3_small_minimal_100 | imagenet |   0.43M   |\n\n</div>\n</details>\n\n<details>\n<summary style=\"margin-left: 25px;\">DPN</summary>\n<div style=\"margin-left: 25px;\">\n\n| Encoder |   Weights   | Params, M |\n| ------- | :---------: | :-------: |\n| dpn68   |  imagenet   |    11M    |\n| dpn68b  | imagenet+5k |    11M    |\n| dpn92   | imagenet+5k |    34M    |\n| dpn98   |  imagenet   |    58M    |\n| dpn107  | imagenet+5k |    84M    |\n| dpn131  |  imagenet   |    76M    |\n\n</div>\n</details>\n\n<details>\n<summary style=\"margin-left: 25px;\">VGG</summary>\n<div style=\"margin-left: 25px;\">\n\n| Encoder  | Weights  | Params, M |\n| -------- | :------: | :-------: |\n| vgg11    | imagenet |    9M     |\n| vgg11_bn | imagenet |    9M     |\n| vgg13    | imagenet |    9M     |\n| vgg13_bn | imagenet |    9M     |\n| vgg16    | imagenet |    14M    |\n| vgg16_bn | imagenet |    14M    |\n| vgg19    | imagenet |    20M    |\n| vgg19_bn | imagenet |    20M    |\n\n</div>\n</details>\n\n\n\n### :truck: Dataset <a name=\"dataset\"></a>\n\n- [x] [LEVIR-CD](https://justchenhao.github.io/LEVIR/)\n- [x] [SVCD](https://www.researchgate.net/publication/325470033_CHANGE_DETECTION_IN_REMOTE_SENSING_IMAGES_USING_CONDITIONAL_ADVERSARIAL_NETWORKS) [[google drive](https://drive.google.com/file/d/1GX656JqqOyBi_Ef0w65kDGVto-nHrNs9/edit) | [baidu disk](https://pan.baidu.com/s/1bU9bSRxQnlfw7OkOw7hqjA) (x8gi)] \n- [ ] ...\n\n\n\n### 🏆 Competitions won with the library\n\n`change_detection.pytorch` has competitiveness and potential in the change detection competitions.\n[Here](https://github.com/likyoo/change_detection.pytorch/blob/main/COMPETITIONS.md) you can find competitions, names of the winners and links to their solutions.\n\n\n\n### :page_with_curl: Citing <a name=\"citing\"></a>\n\n```\n@misc{likyoocdp:2021,\n  Author = {Kaiyu Li, Fulin Sun, Xudong Liu},\n  Title = {Change Detection Pytorch},\n  Year = {2021},\n  Publisher = {GitHub},\n  Journal = {GitHub repository},\n  Howpublished = {\\url{https://github.com/likyoo/change_detection.pytorch}}\n}\n```\n\n\n\n### :books: Reference <a name=\"reference\"></a>\n\n- [qubvel/segmentation_models.pytorch](https://github.com/qubvel/segmentation_models.pytorch)\n- [albumentations-team/albumentations](https://github.com/albumentations-team/albumentations)\n- [open-mmlab/mmsegmentation](https://github.com/open-mmlab/mmsegmentation)\n- [wenhwu/awesome-remote-sensing-change-detection](https://github.com/wenhwu/awesome-remote-sensing-change-detection)\n\n\n\n### :mailbox: Contact<a name=\"contact\"></a>\n\n⚡⚡⚡ I am trying to build this project, if you are interested, don't hesitate to join us! \n\n👯👯👯 Contact me at likyoo@sdust.edu.cn or pull a request directly or join our WeChat group.\n<div align=center><img src=\"resources/wechat.jpg\" alt=\"wechat group\" width=\"38%\" height=\"38%\"  style=\"zoom:80%;\" /></div>\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/likyoo/change_detection.pytorch",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "change-detection-pytorch",
    "package_url": "https://pypi.org/project/change-detection-pytorch/",
    "platform": "",
    "project_url": "https://pypi.org/project/change-detection-pytorch/",
    "project_urls": {
      "Homepage": "https://github.com/likyoo/change_detection.pytorch"
    },
    "release_url": "https://pypi.org/project/change-detection-pytorch/0.1.4/",
    "requires_dist": [
      "torchvision (>=0.5.0)",
      "pretrainedmodels (==0.7.4)",
      "efficientnet-pytorch (==0.6.3)",
      "timm (==0.4.12)",
      "albumentations",
      "pytest ; extra == 'test'"
    ],
    "requires_python": ">=3.0.0",
    "summary": "Change detection models with pre-trained backbones. Inspired by segmentation_models.pytorch.",
    "version": "0.1.4",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12471198,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0afa8e3b5e525e696fa823679d79541cc2e6517ce8b7902dfb6c886e5ef5da5d",
          "md5": "9db104e3b3eb5f9d16d1637020b2e2ff",
          "sha256": "494ff2329be5677a6489cc86e868bcd6a908041a95512872ccc94639d129609b"
        },
        "downloads": -1,
        "filename": "change_detection_pytorch-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "9db104e3b3eb5f9d16d1637020b2e2ff",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0.0",
        "size": 88930,
        "upload_time": "2021-12-02T04:04:57",
        "upload_time_iso_8601": "2021-12-02T04:04:57.755617Z",
        "url": "https://files.pythonhosted.org/packages/0a/fa/8e3b5e525e696fa823679d79541cc2e6517ce8b7902dfb6c886e5ef5da5d/change_detection_pytorch-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b6fac847c046ede731c9d4db322cade6c26750cd33b94adebd12850599274dc5",
          "md5": "f73b6325e1393a8c56b127037e9737ab",
          "sha256": "b8c82fde42098300234f48aad2ea2622c26b01a4dcd5014f874794a9815d4a3a"
        },
        "downloads": -1,
        "filename": "change_detection_pytorch-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "f73b6325e1393a8c56b127037e9737ab",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0.0",
        "size": 86224,
        "upload_time": "2022-01-04T06:19:47",
        "upload_time_iso_8601": "2022-01-04T06:19:47.131757Z",
        "url": "https://files.pythonhosted.org/packages/b6/fa/c847c046ede731c9d4db322cade6c26750cd33b94adebd12850599274dc5/change_detection_pytorch-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "19c3a400bb7c6261ff06226854e87ae7fc129f364d45ac7f82735c6989a0f882",
          "md5": "e1492c78f65be1032abf79389dce6efb",
          "sha256": "248f5800d699a30ced38bb7a9eeaffdbb48970daf4139a3b24b7dc2708e5a7c5"
        },
        "downloads": -1,
        "filename": "change_detection_pytorch-0.1.4-py3.7.egg",
        "has_sig": false,
        "md5_digest": "e1492c78f65be1032abf79389dce6efb",
        "packagetype": "bdist_egg",
        "python_version": "0.1.4",
        "requires_python": ">=3.0.0",
        "size": 322342,
        "upload_time": "2022-01-04T07:25:00",
        "upload_time_iso_8601": "2022-01-04T07:25:00.832138Z",
        "url": "https://files.pythonhosted.org/packages/19/c3/a400bb7c6261ff06226854e87ae7fc129f364d45ac7f82735c6989a0f882/change_detection_pytorch-0.1.4-py3.7.egg",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "aa1639b93e49a0bb5fe055d7ed4c70a098c92407fdfbcd9331d687d81a762d8a",
          "md5": "a7c4bae3340c6a89addc10c0a2e9c0c5",
          "sha256": "4d065691b480a931f45c5f2dc6eda60df27d826dac9fb362d6123cf3e3d72e4e"
        },
        "downloads": -1,
        "filename": "change_detection_pytorch-0.1.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "a7c4bae3340c6a89addc10c0a2e9c0c5",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0.0",
        "size": 137753,
        "upload_time": "2022-01-04T07:24:58",
        "upload_time_iso_8601": "2022-01-04T07:24:58.896970Z",
        "url": "https://files.pythonhosted.org/packages/aa/16/39b93e49a0bb5fe055d7ed4c70a098c92407fdfbcd9331d687d81a762d8a/change_detection_pytorch-0.1.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7491f5089e521c29cae8f536a897457aa47692c1865d0a783d812466996ed2a2",
          "md5": "3369b17c2b29101e4b78e013a78eda70",
          "sha256": "25b1dd462d5e477bb5d3dfc424b499b365d08b1d906d1d3bbab36be506edb69b"
        },
        "downloads": -1,
        "filename": "change_detection_pytorch-0.1.4.tar.gz",
        "has_sig": false,
        "md5_digest": "3369b17c2b29101e4b78e013a78eda70",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0.0",
        "size": 86365,
        "upload_time": "2022-01-04T07:25:02",
        "upload_time_iso_8601": "2022-01-04T07:25:02.469159Z",
        "url": "https://files.pythonhosted.org/packages/74/91/f5089e521c29cae8f536a897457aa47692c1865d0a783d812466996ed2a2/change_detection_pytorch-0.1.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "19c3a400bb7c6261ff06226854e87ae7fc129f364d45ac7f82735c6989a0f882",
        "md5": "e1492c78f65be1032abf79389dce6efb",
        "sha256": "248f5800d699a30ced38bb7a9eeaffdbb48970daf4139a3b24b7dc2708e5a7c5"
      },
      "downloads": -1,
      "filename": "change_detection_pytorch-0.1.4-py3.7.egg",
      "has_sig": false,
      "md5_digest": "e1492c78f65be1032abf79389dce6efb",
      "packagetype": "bdist_egg",
      "python_version": "0.1.4",
      "requires_python": ">=3.0.0",
      "size": 322342,
      "upload_time": "2022-01-04T07:25:00",
      "upload_time_iso_8601": "2022-01-04T07:25:00.832138Z",
      "url": "https://files.pythonhosted.org/packages/19/c3/a400bb7c6261ff06226854e87ae7fc129f364d45ac7f82735c6989a0f882/change_detection_pytorch-0.1.4-py3.7.egg",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "aa1639b93e49a0bb5fe055d7ed4c70a098c92407fdfbcd9331d687d81a762d8a",
        "md5": "a7c4bae3340c6a89addc10c0a2e9c0c5",
        "sha256": "4d065691b480a931f45c5f2dc6eda60df27d826dac9fb362d6123cf3e3d72e4e"
      },
      "downloads": -1,
      "filename": "change_detection_pytorch-0.1.4-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "a7c4bae3340c6a89addc10c0a2e9c0c5",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.0.0",
      "size": 137753,
      "upload_time": "2022-01-04T07:24:58",
      "upload_time_iso_8601": "2022-01-04T07:24:58.896970Z",
      "url": "https://files.pythonhosted.org/packages/aa/16/39b93e49a0bb5fe055d7ed4c70a098c92407fdfbcd9331d687d81a762d8a/change_detection_pytorch-0.1.4-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "7491f5089e521c29cae8f536a897457aa47692c1865d0a783d812466996ed2a2",
        "md5": "3369b17c2b29101e4b78e013a78eda70",
        "sha256": "25b1dd462d5e477bb5d3dfc424b499b365d08b1d906d1d3bbab36be506edb69b"
      },
      "downloads": -1,
      "filename": "change_detection_pytorch-0.1.4.tar.gz",
      "has_sig": false,
      "md5_digest": "3369b17c2b29101e4b78e013a78eda70",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.0.0",
      "size": 86365,
      "upload_time": "2022-01-04T07:25:02",
      "upload_time_iso_8601": "2022-01-04T07:25:02.469159Z",
      "url": "https://files.pythonhosted.org/packages/74/91/f5089e521c29cae8f536a897457aa47692c1865d0a783d812466996ed2a2/change_detection_pytorch-0.1.4.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}