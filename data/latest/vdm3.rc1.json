{
  "info": {
    "author": "Esmond Chu",
    "author_email": "chuhke@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.4",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Topic :: Software Development :: Build Tools"
    ],
    "description": "# vdm3\n\nValue difference metric was introduced in 1986 to provide an appropriate distance function for symbolic attributes. It is based on the idea that the goal of finding the distance is to find the right class by looking at the following conditional probabilities. <br>\n![](https://github.com/esmondhkchu/vdm3/raw/master/equations/cond_prob.png) <br>\nThen the distance is calculated by the k-norm, for instance k=2 will be the Euclidean norm: <br>\n![](https://github.com/esmondhkchu/vdm3/raw/master/equations/distance.png) <br>\n\n# Install\n\n```\npip install vdm3\n```\n\n## Parameters:\n\n```\nValueDifferenceMetric(X=X, y=y, continuous=None)\n```\n\n  - X: ndarray, DataFrame, Series\n  - y: tuple, list, ndarray, Series\n  - continuous: tuple, list, ndarray, Series - the column index of continuous variables, if default, will assume all the columns are categorical\n\n## Attributes\ncond_proba - the learned conditional probabilities\n\n## Method\nget_distance(self, ins_1, ins_2, norm=2) - calculate the combined distance (categorical & continuous columns if any) between ins_1 and ins_2, with norm n. By default, n=2\n\n# Usage\nConsider the following example: <br>\n```python\n>>> X = pd.DataFrame({'color':['White','Red','Black','Red','Red','White'], 'mpg':[23,28,32,42,40,20]})\n>>> y = np.array(['van','sport','sport','sedan','sedan','van'])\n```\nInitiate the example by: <br>\n```python\n>>> case = ValueDifferenceMetric(X=X, y=y, continuous=[1])\n>>> case.fit()\n```\nGet the vdm distance of two points by:\n```python\n>>> one = np.array(['White',23])\n>>> two = np.array(['Red',28])\n\n>>> case.get_distance(ins_1=one, ins_2=two)\n5.153208277913436\n```\nReturn 0 if two points are the same: <br>\n```python\n>>> case.get_distance(ins_1=one, ins_2=one)\n0.0\n```\n## Work with other open-source packages\nWe can also use this package as a distance metric to work with other open-source packages, for instance scikit-learn. <br>\nIn the next section, we will demonstrate a basic modeling example to embed vdm3 into scikit-learn nearest neighbors.\n```python\n>>> from sklearn.datasets import load_boston\n>>> from sklearn.model_selection import train_test_split\n>>> from sklearn.preprocessing import StandardScaler\n```\nWe will load the Boston dataset, which contains 2 categorical features and 11 continuous features. The dependent variable is a continuous variable, in order to work with value difference metric, we will transform this problem from a regression problem to a classification problem by categorizing the dependent variable by the quantiles (0.25, 0.5, 0.75), i.e. the dependent variable will now be categorized to 1, 2, 3, and 4. Although, you may only do this process to calculate the VDM distance, and keep the overall problem as the original regression problem, to simply demonstrate the usage of this package, we will leave it as is.\n```python\n# load data\n>>> boston = load_boston(return_X_y=False)\n\n# separate the data into X and y\n>>> X = boston['data']\n>>> y = boston['target']\n\n# transform the y from continuous to categorical\n>>> quantile = np.quantile(y, [0.25,0.5,0.75])\n\n>>> def num_to_cat(quantile, input_):\n        \"\"\" use quantil to categorize continuous data\n        \"\"\"\n        if input_ <= quantile[0]:\n            return 0\n        elif input_ <= quantile[1]:\n            return 1\n        elif input_ <= quantile[2]:\n            return 2\n        else:\n            return 3\n# the categorized y\n>>> y_cat = [num_to_cat(quantile, i) for i in y]\n```\nWe will then split the data into train and test set for a simple demonstration.\n```python\n>>> X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.1)\n```\nNext, we will separate the categorical columns to normalized the continuous columns.\n```python\n# index numbers for categorical and continuous columns\n>>> cat_idx = [3,8]\n>>> cont_idx = [i for i in range(X.shape[-1]) if i not in cat_idx]\n\n# scale the continuous columns\n>>> scaler = StandardScaler().fit(X_train[:,cont_idx])\n\n>>> X_train_cont = scaler.transform(X_train[:,cont_idx])\n>>> X_test_cont = scaler.transform(X_test[:,cont_idx])\n\n# concatenate both types of data for model fitting\n>>> X_train_n = np.concatenate([X_train_cont, X_train[:,cat_idx]], 1)\n>>> X_test_n = np.concatenate([X_test_cont, X_test[:,cat_idx]], 1)\n```\nAfter processing the data, we will first need to initiate our VDM object.\n```python\n# specific the continuous columns index\n>>> vdm = ValueDifferenceMetric(X_train_n, y_train, continuous=[0,1,2,3,4,5,6,7,8,9,10])\n>>> vdm.fit()\n```\nOur vdm method `self.get_distance()` will be used as a user defined distance function for scikit-learn neaerest neighbors. <br>\nNote that, since our data format issue, we cannot use some efficient solving algorithms, such as k-d-tree or ball tree. We will need to specify our algorithm to `brute` for a brute-force search.\n```python\n>>> knn = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n>>> knn.fit(X_train_n, y_train)\nKNeighborsClassifier(algorithm='brute', leaf_size=30,\n                     metric=<bound method ValueDifferenceMetric.get_distance of <__main__.ValueDifferenceMetric object at 0x11fb38198>>,\n                     metric_params=None, n_jobs=None, n_neighbors=2, p=2,\n                     weights='uniform')\n\n>>> print(knn.score(X_test, y_test))\n0.7843137254901961\n```",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "https://github.com/esmondhkchu/vdm3/archive/v0.0.1.tar.gz",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/esmondhkchu/vdm3",
    "keywords": "statistics,machine learning,distance",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "vdm3",
    "package_url": "https://pypi.org/project/vdm3/",
    "platform": "",
    "project_url": "https://pypi.org/project/vdm3/",
    "project_urls": {
      "Download": "https://github.com/esmondhkchu/vdm3/archive/v0.0.1.tar.gz",
      "Homepage": "https://github.com/esmondhkchu/vdm3"
    },
    "release_url": "https://pypi.org/project/vdm3/0.0.1/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "Use Value Difference Metric to find distance between categorical features",
    "version": "0.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 7753667,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0e24107664970d5d8894aa3ec94628ee56e9690eac507d558bb2ba49978eb401",
          "md5": "76a844ac080dab2a2fef14773460ebfb",
          "sha256": "7feb1a297008fcfac0e43b2af5a34cc37b5a822ac349054e65ee034e7f6249c0"
        },
        "downloads": -1,
        "filename": "vdm3-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "76a844ac080dab2a2fef14773460ebfb",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 5499,
        "upload_time": "2020-07-22T02:26:26",
        "upload_time_iso_8601": "2020-07-22T02:26:26.816981Z",
        "url": "https://files.pythonhosted.org/packages/0e/24/107664970d5d8894aa3ec94628ee56e9690eac507d558bb2ba49978eb401/vdm3-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "0e24107664970d5d8894aa3ec94628ee56e9690eac507d558bb2ba49978eb401",
        "md5": "76a844ac080dab2a2fef14773460ebfb",
        "sha256": "7feb1a297008fcfac0e43b2af5a34cc37b5a822ac349054e65ee034e7f6249c0"
      },
      "downloads": -1,
      "filename": "vdm3-0.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "76a844ac080dab2a2fef14773460ebfb",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 5499,
      "upload_time": "2020-07-22T02:26:26",
      "upload_time_iso_8601": "2020-07-22T02:26:26.816981Z",
      "url": "https://files.pythonhosted.org/packages/0e/24/107664970d5d8894aa3ec94628ee56e9690eac507d558bb2ba49978eb401/vdm3-0.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}