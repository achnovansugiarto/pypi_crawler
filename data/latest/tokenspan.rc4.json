{
  "info": {
    "author": "François Konschelle - IAM CHU Bordeaux France",
    "author_email": "via.issue@only.please",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Information Technology",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: GNU General Public License v3 (GPLv3)",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Topic :: Scientific/Engineering :: Information Analysis",
      "Topic :: Text Processing"
    ],
    "description": "# Tokenization for language processing\n\nThis package contains some generic configurable tools allowing to cut a string in sub-parts (cf. [Wikipedia](https://en.wikipedia.org/wiki/Lexical_analysis#Tokenization)), called `Token`, and to group them into sequences called `Tokens`. A `Token` is a sub-string from a parent string (say the initial complete text), with associated ranges of non-overlaping characters. The number of associated ranges is arbitrary. A `Tokens` is a collection of `Token`. These two classes allow to associate to any `Token` a collection of attributes in a versatile way, and to pass these attributes from one object to the next one while cutting `Token` into sub-parts (collected as `Tokens`) and eventually re-merging them into larger `Token`.\n\n`Token` and `Tokens` classes allow basic tokenization of text, such as word splitting, n-gram splitting, char-gram splitting of arbitrary size. In addition, it allows to associate several non-overlapping sub-strings into a given `Token`, and to associate arbitrary attributes to these parts. One can compare two different `Token` objects in terms of their attributes and/or ranges. One can also apply basic mathematical operations and logic to them (+,-,*,/) corresponding to the union, difference, intersection and symmetric difference implemented by Python set ; here the sets are the ranges of position from the parent string.\n\n## Depositories, and online documentation\n\nThe different sources of informations for this packages are : \n \n - the official Python Package Installation (PyPI) repository is on [https://pypi.org/project/tokenspan](https://pypi.org/project/tokenspan)\n - the official git repository is on [https://framagit.org/nlp/tokenspan](https://framagit.org/nlp/tokenspan)\n - the official documentation is on [https://nlp.frama.io/tokenspan/](https://nlp.frama.io/tokenspan/)\n \n\n## Philosophy of this library\n\nIn `tokenspan`, one thinks of a string as a collection of integers: the position of each character in the string. For instance\n\n```python\n'Simple string for demonstration and for illustration.' # the parent string\n'01234567891123456789212345678931234567894123456789512' # the positions\n\n'       string                       for illustration ' # the Span span1\n'       789112                       678 412345678951 ' # the ranges\n\n'Simple                                               ' # the Span span2\n'012345                                               ' # the ranges\n```\n\nTo define the `Span` `'string for illustration'` consists in selecting the positions `[range(7,13),range(36,39),range(40,52)]` from the parent string, and the `Span` `'simple'` is defined by the positions `[range(0,6),]`. \n\nIn addition, one can see the above ranges as sets of positins. Then it is quite easy to perform some basic operations on the `Span`, for instance the addition of two `Span`\n\n```python\nstr(span1 + span2) = 'Simple string for illustration'\n```\n\nis interpreted as the union of their relative sets of positions.\n\nIn addition to these logical operations, there are a few utilities, like the possibility to split or slice a `Span` into `Span` objects, as long as their are all related to the same parent string.\n\n## Basic example\n\nBelow we give a simple example of usage of the `Token` and `Tokens` classes.\n\n```python\nimport re\nfrom tokenspan import Span\n\nstring = 'Simple string for demonstration and for illustration.'\ninitial_span = Span(string)\n\n# char-gram generation\nchargrams = initial_span.slice(0,len(initial_span),3)\nstr(chargrams[2])\n# return 'mpl'\n\n# each char-gram conserves a memory of the initial string\nchargrams[2].string\n# return 'Simple string for demonstration and for illustration.'\n\ncuts = [range(r.start(),r.end()) for r in re.finditer(r'\\w+',string)]\nspans = initial_span.split(cuts)\n# this returns a list of Span objects\n\n# spans conserve the cutted parts\ninteresting_spans = spans[1::2]\n# so one has to take only odd elements\n\n# an other possibility to keep only the words is to construct it explicitly\nspans = Span(string, ranges=cuts)\n\n# n-gram construction\nngram = [Span(string, ranges=[r1,r2]) for r1, r2 in zip(spans.ranges[:-1],\n                                                        spans.ranges[1:])]\nngram[2]\n# return Span('for demonstration', [(14,17),(18,31)])\nstr(ngram[2])\n# return 'for demonstration'\nngram[2].ranges\n# return [range(14, 17), range(18, 31)]\nngram[2].subSpans\n# return the Span instances composed of span 'for' and span 'demonstration'\n\n# are the two 'for' Token the same ?\ninteresting_spans[2] == interesting_spans[-2]\n# return False, because they are not at the same position\n\n# basic operations among Token\nfor_for = interesting_spans[2] + interesting_spans[-2]\nstr(for_for)\n# return 'for for'\nfor_for.ranges\n# return [range(14, 17), range(36, 39)]\nfor_for.string\n# return 'Simple string for demonstration and for illustration.'\n# to check the positions of the two 'for' Token : \n#        '01234567890...456...01234567890.....67890............'\n\n# also available : \n# span1 + span2 : union of the sets of span1.ranges and span2.ranges\n# span1 - span2 : difference of span1.ranges and span2.ranges\n# span1 * span2 : intersection of span1.ranges and span2.ranges\n# span1 / span2 : symmetric difference of span1.ranges and span2.ranges\n\n```\n\nOther examples can be found in the [documentation](https://nlp.frama.io/tokenspan/).\n\n## Comparison with other Python libraries\n\nA comparison with some other NLP librairies (nltk, gensim, spaCy, gateNLP, ...) can be found in the [documentation](https://nlp.frama.io/tokenspan/comparison_other_libraries.html)\n\n## Installation\n\nSimply run \n\n```bash\npip install tokenspan\n```\n\nshould install the library from Python Package Index (PIP). The official repository is on https://framagit.org/nlp/tokenspan. To install the package from the repository, run the following command lines \n\n```bash\ngit clone https://framagit.org/nlp/tokenspan.git\ncd tokenspan/\npip install .\n```\n\nOnce installed, one can run some tests using\n\n```bash\ncd tests/\npython3 -m unittest -v\n```\n\n(verbosity `-v` is an option).\n\n## Versions\n\nSee [CHANGES file](CHANGES.md) in this folder.\n\n## About us\n\nPackage developped for Natural Language Processing at IAM : Unité d'Informatique et d'Archivistique Médicale, Service d'Informatique Médicale, Pôle de Santé Publique, Centre Hospitalo-Universitaire (CHU) de Bordeaux, France.\n\nYou are kindly encouraged to contact the authors by issue on the [official repository](https://framagit.org/nlp/tokenspan/-/issues/), and to propose ameliorations and/or suggestions to the authors, via issue or merge requests.\n\nLast version : Jan 20, 2022\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://framagit.org/nlp/tokenspan",
    "keywords": "",
    "license": "GNU GENERAL PUBLIC LICENSE v.3",
    "maintainer": "",
    "maintainer_email": "",
    "name": "tokenspan",
    "package_url": "https://pypi.org/project/tokenspan/",
    "platform": "",
    "project_url": "https://pypi.org/project/tokenspan/",
    "project_urls": {
      "Homepage": "https://framagit.org/nlp/tokenspan"
    },
    "release_url": "https://pypi.org/project/tokenspan/0.7.1/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "Basic tools to tokenize (i.e. to construct atomic-entities/sub-strings of) a string, for Natural Language Processing (NLP). Usefull also for annotation, tree parsing, entity linking, ... (in fact, anything that links a string or its sub-parts to an other object). Key concepts are versatility to other librairies, and freedom to define many concepts on top of a string.",
    "version": "0.7.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12917182,
  "releases": {
    "0.5.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "37a8148aba1f02f3f3b9a297e1764cc694978312b922656696329f281919885c",
          "md5": "a1e716c5fb21f7fc5d8e5e8d37f2e70e",
          "sha256": "5475465f053474135ec761213c036b0ff7f5e5ed56392d94e4e310a24134e971"
        },
        "downloads": -1,
        "filename": "tokenspan-0.5.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "a1e716c5fb21f7fc5d8e5e8d37f2e70e",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 32204,
        "upload_time": "2021-08-05T15:19:13",
        "upload_time_iso_8601": "2021-08-05T15:19:13.410780Z",
        "url": "https://files.pythonhosted.org/packages/37/a8/148aba1f02f3f3b9a297e1764cc694978312b922656696329f281919885c/tokenspan-0.5.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a459cce1f97b4e0ad680d01035ef94010e6fbcdebf19db577b3e517c6b4ff3cf",
          "md5": "64e2bd8c89fdb1db0fda0204d1912c4a",
          "sha256": "7d5db76b8aae5172ea92cfc3c4be9edaa7e831b6c02e3b1daffc0efdd4024969"
        },
        "downloads": -1,
        "filename": "tokenspan-0.5.0.tar.gz",
        "has_sig": false,
        "md5_digest": "64e2bd8c89fdb1db0fda0204d1912c4a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 32354,
        "upload_time": "2021-08-05T15:19:16",
        "upload_time_iso_8601": "2021-08-05T15:19:16.481883Z",
        "url": "https://files.pythonhosted.org/packages/a4/59/cce1f97b4e0ad680d01035ef94010e6fbcdebf19db577b3e517c6b4ff3cf/tokenspan-0.5.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.6.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d5047fecf79f7efd81f8a144007d31edc79394608334873c2f064e272786c9b0",
          "md5": "bf6c347de87e2da19e6b5e3fe38dec2e",
          "sha256": "6c1d8c5fb356ef41daed296358006656225602a8258b9958f5679b0efe87b259"
        },
        "downloads": -1,
        "filename": "tokenspan-0.6.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "bf6c347de87e2da19e6b5e3fe38dec2e",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 32397,
        "upload_time": "2022-01-19T19:48:46",
        "upload_time_iso_8601": "2022-01-19T19:48:46.061687Z",
        "url": "https://files.pythonhosted.org/packages/d5/04/7fecf79f7efd81f8a144007d31edc79394608334873c2f064e272786c9b0/tokenspan-0.6.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9dcab69ae70816399303a138e9069e8e7b213ea1216fd99bbdf3d56006deacca",
          "md5": "ce0a7b4d68807a4dd63a5d23229b2d95",
          "sha256": "f963c4983c38898e8776f8e79dbd9aeebde4458ee737e7cfb65d7aeb4de7944a"
        },
        "downloads": -1,
        "filename": "tokenspan-0.6.0.tar.gz",
        "has_sig": false,
        "md5_digest": "ce0a7b4d68807a4dd63a5d23229b2d95",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 32579,
        "upload_time": "2022-01-19T19:48:48",
        "upload_time_iso_8601": "2022-01-19T19:48:48.102036Z",
        "url": "https://files.pythonhosted.org/packages/9d/ca/b69ae70816399303a138e9069e8e7b213ea1216fd99bbdf3d56006deacca/tokenspan-0.6.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.7.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2a620a99ee15b40d8609e781c440370fbf0502911dddfb1629d2497aa8cef74f",
          "md5": "7b3712a94e957ad0db5b0a6714ec0c46",
          "sha256": "44a3c4c1e5ac9ac097e4660c50c76ce36101b29bfd3badcdb5d2a40a57640a4c"
        },
        "downloads": -1,
        "filename": "tokenspan-0.7.0.linux-x86_64.tar.gz",
        "has_sig": false,
        "md5_digest": "7b3712a94e957ad0db5b0a6714ec0c46",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 38778,
        "upload_time": "2022-01-27T09:00:47",
        "upload_time_iso_8601": "2022-01-27T09:00:47.847657Z",
        "url": "https://files.pythonhosted.org/packages/2a/62/0a99ee15b40d8609e781c440370fbf0502911dddfb1629d2497aa8cef74f/tokenspan-0.7.0.linux-x86_64.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.7.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "401beef59f98db041618e8d31a9719a3d24ccf31e9d0a28708616e9347000f8e",
          "md5": "bab0c7aac4b41091502c3dc1ba7002d8",
          "sha256": "0d50b2fdd9b593ac860ddb84c79119d31176e297d27ad0f7c19866c08b4f547b"
        },
        "downloads": -1,
        "filename": "tokenspan-0.7.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "bab0c7aac4b41091502c3dc1ba7002d8",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 33183,
        "upload_time": "2022-02-17T06:18:49",
        "upload_time_iso_8601": "2022-02-17T06:18:49.364589Z",
        "url": "https://files.pythonhosted.org/packages/40/1b/eef59f98db041618e8d31a9719a3d24ccf31e9d0a28708616e9347000f8e/tokenspan-0.7.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ff9a6e846ed56b71278c38c40734dcf5b700924450aaf4d0377cf31efb125e5f",
          "md5": "e4b5da81abfd334b35f8e2f5b03bd4d5",
          "sha256": "3a687fb3bde6234149780a3befbacdfd4178fb5e4524940dd02f099bfe5d7c86"
        },
        "downloads": -1,
        "filename": "tokenspan-0.7.1.tar.gz",
        "has_sig": false,
        "md5_digest": "e4b5da81abfd334b35f8e2f5b03bd4d5",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 33253,
        "upload_time": "2022-02-17T06:18:50",
        "upload_time_iso_8601": "2022-02-17T06:18:50.753929Z",
        "url": "https://files.pythonhosted.org/packages/ff/9a/6e846ed56b71278c38c40734dcf5b700924450aaf4d0377cf31efb125e5f/tokenspan-0.7.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "401beef59f98db041618e8d31a9719a3d24ccf31e9d0a28708616e9347000f8e",
        "md5": "bab0c7aac4b41091502c3dc1ba7002d8",
        "sha256": "0d50b2fdd9b593ac860ddb84c79119d31176e297d27ad0f7c19866c08b4f547b"
      },
      "downloads": -1,
      "filename": "tokenspan-0.7.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "bab0c7aac4b41091502c3dc1ba7002d8",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 33183,
      "upload_time": "2022-02-17T06:18:49",
      "upload_time_iso_8601": "2022-02-17T06:18:49.364589Z",
      "url": "https://files.pythonhosted.org/packages/40/1b/eef59f98db041618e8d31a9719a3d24ccf31e9d0a28708616e9347000f8e/tokenspan-0.7.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "ff9a6e846ed56b71278c38c40734dcf5b700924450aaf4d0377cf31efb125e5f",
        "md5": "e4b5da81abfd334b35f8e2f5b03bd4d5",
        "sha256": "3a687fb3bde6234149780a3befbacdfd4178fb5e4524940dd02f099bfe5d7c86"
      },
      "downloads": -1,
      "filename": "tokenspan-0.7.1.tar.gz",
      "has_sig": false,
      "md5_digest": "e4b5da81abfd334b35f8e2f5b03bd4d5",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 33253,
      "upload_time": "2022-02-17T06:18:50",
      "upload_time_iso_8601": "2022-02-17T06:18:50.753929Z",
      "url": "https://files.pythonhosted.org/packages/ff/9a/6e846ed56b71278c38c40734dcf5b700924450aaf4d0377cf31efb125e5f/tokenspan-0.7.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}