{
  "info": {
    "author": "Muhammad Hadi",
    "author_email": "mhadi813@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: BSD License",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Topic :: Office/Business"
    ],
    "description": "# Tableau hyperdb\nHyperdb provides wrapper functions for working with Tableau hyper datasources and moving data between Tableau Server, Google Cloud Platform and Microsoft Azure through a common interface\n\n### Some example use cases are:\n\n - <b>Publishing SQL query results to Tableau Server with python scripts.</b> \nThis approach leverages computing power of SQL databases for ETL and improves dashboard performance\n- <b>Extracting and transforming data from noncoventional datasources such as emails and API for dashboards.</b> \nUsing cloud storage and serverless compute solutions, prototyping and development becomes easy\n- <b>Tapping hyper datasources on servers for analysis in Pandas and storing results in SQL database.</b>\nUsually hyper data sources feeding the dashboards are cleaned and enriched, why not use them instead of using the raw data?</b>\n- <b>Feeding data from ML models to published dashboards.</b>\nWith Pandas and cloud services working together possibilities are limitless. The missing link between data and insight is vizualization and this libray aims to fill that gap by feeding Tableau vizualizations what they love: <b>hyper datasources!</b>\n\n# Installation\n```pip install hyperdb```\n\n# Setting up development environment\n```\ngit clone https://github.com/mhadi813/hyperdb\ncd hyperdb\nconda env create -f hyperdb_dev.yml\n```\n\n# Authentication\n```\nimport os\n#TODO: update path to credential files\n# see ``secrets`` folder for credential tamplates\n# see functions ``doc string`` for authentication methods at run-time\nos.environ['GOOGLE_APPLICATION_CREDENTIALS'] = './secrets/dummy_gcp_service_account_credentials.json'\nos.environ[\"AZURE_CREDENTIALS\"]= './secrets/dummy_ms_azure_credentials.json' \nos.environ['TABLEAU_SERVER_CREDENTIALS']='./secrets/dummy_tableau_server_credentials.json'\n```\n\n# Usage\n### Publishing hyper extract from google bigquery SQL statement/stored procedure\n```\nimport hyperdb.gcp as gcp\nimport hyperdb.tableau_server as ts\n\nsql = \"\"\"SELECT Order_ID, Order_Date, Ship_Date, Ship_Mode, Customer_ID, Customer_Name, Segment \nFROM `composite-drive-276806.hyper_sources.sample_superstore` \"\"\"\n\nsql = \"\"\"CALL `composite-drive-276806.hyper_sources.spoc_sample_superstore`();\"\"\"\n\ndf = gcp.bq_to_df(sql)\n\nhyper_filepath = ts.df_to_hyper(df)\ndatasource_name = ts.upload_hyper_tableau_server(hyper_filepath)\n\n```\n\n### Dealing with unconvential data sources\n```\nimport hyperdb.tableau_server as ts\nimport hyperdb.ms_azure as az\nimport pandas as pd\n# TODO Azure logic app extracts excels files from email and stores on cloud storage, get url of blob\n\nblob_url = 'https://tableaupydb.blob.core.windows.net/sql-script/Sample - Superstore.xls'\nin_mem_file = az.download_blob_azure_storage(blob_url,output_option='IO')\ndf = pd.read_excel(in_mem_file)\nhyper_filepath = ts.df_to_hyper(df)\ndatasource_name = ts.upload_hyper_tableau_server(hyper_filepath)\n```\n\n### Tapping hyper datasources on Tableau servers for analysis in pandas\n```\nimport hyperdb.tableau_server as ts\nimport pandas as pd\ndatasource_name = 'Sample - Superstore'\n\nhyper_filepath = ts.download_hyper_tableau_server(datasource_name)\ndf = ts.hyper_to_df(hyper_filepath)\ndf.head()\n\n# let's write the data to azure sql table and use a non default database\nimport hyperdb.ms_azure as az\ntable_name = 'dbo.fact_sample_superstore'\nengine = az.azure_sql_engine(database='CloudAnalyticsDev')\naz.df_to_azure_sql(df,table_name, engine=engine)\n\n```\n\n### Feeding Tableau Dashboard data form ML model\n```\n# TODO train and save time series forecast model using fbProphet package on Google Cloud Storage\n# TODO serve forecast with Google Cloud functions\n# get forecasts with python requests module\n\nimport requests\nfrom pyplatform_dev import gcf_authenticated_request\n\nrequest_params = {\"startDate\": \"2020-05-01\"}\ngcf_url = 'TODO'\n\nresponse  = gcf_authenticated_request(gcf_url,method='POST',request_params)\ndf = pd.DataFrame(response.json())\nhyper_filepath = ts.df_to_hyper(df)\ndatasource_name = ts.upload_hyper_tableau_server(hyper_filepath)\n```\n### Putting everything together\n```\n# TODO deploy an app on Pivotal Cloud Foundary to abstract away data analystics infrastucture\n# this approach is to keep things serverless and work around storage dependency of Tableau Hyper Client and Tableau Server Python packages\n```\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "http://github.com/mhadi813/hyperdb",
    "keywords": "tableau hyper pandas google bigquery cloud storage azure sql database",
    "license": "BSD",
    "maintainer": "",
    "maintainer_email": "",
    "name": "hyperdb",
    "package_url": "https://pypi.org/project/hyperdb/",
    "platform": "",
    "project_url": "https://pypi.org/project/hyperdb/",
    "project_urls": {
      "Homepage": "http://github.com/mhadi813/hyperdb"
    },
    "release_url": "https://pypi.org/project/hyperdb/0.1.1/",
    "requires_dist": [
      "pandas (==1.0.3)",
      "google-cloud-bigquery (==1.24.0)",
      "google-cloud-storage (==1.24.1)",
      "gcsfs (==0.6.0)",
      "azure-storage-blob (==1.5.0)",
      "pyarrow (==0.16.0)",
      "requests (==2.23.0)",
      "requests-ntlm (==1.1.0)",
      "xlrd (==1.2.0)",
      "pyodbc (==4.0.27)",
      "sqlalchemy",
      "tableauhyperapi (==0.0.10622)",
      "tableauserverclient (==0.10)",
      "pantab (==1.1.0)"
    ],
    "requires_python": "",
    "summary": "Hyperdb provides wrapper functions for working with Tableau hyper datasources and moving data between Tableau Server, Google Cloud Platform and Microsoft Azure through a common interface",
    "version": "0.1.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 7331357,
  "releases": {
    "0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "91546caa81e6ec9a1fc0892a8b654bbc46d21a6f0d7ac74321b4e72a588c9761",
          "md5": "815429e1b06118d953cdd2537d457799",
          "sha256": "0b61098f82787e4b48b963ce63be48a5c59389493ba9b3833e7151e8a7b59777"
        },
        "downloads": -1,
        "filename": "hyperdb-0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "815429e1b06118d953cdd2537d457799",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 14374,
        "upload_time": "2020-05-26T05:41:38",
        "upload_time_iso_8601": "2020-05-26T05:41:38.328341Z",
        "url": "https://files.pythonhosted.org/packages/91/54/6caa81e6ec9a1fc0892a8b654bbc46d21a6f0d7ac74321b4e72a588c9761/hyperdb-0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "31c9c764b2593141623ba55aab0e311b15aaf61c06cf2032d8f1fc3933aee326",
          "md5": "0ff356c362a391025fd71df4b8a70501",
          "sha256": "44131340544154c0059cf6f5fdc016fc234a5817b0c7fa008cd75c4182ee722a"
        },
        "downloads": -1,
        "filename": "hyperdb-0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "0ff356c362a391025fd71df4b8a70501",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 11036,
        "upload_time": "2020-05-26T05:41:40",
        "upload_time_iso_8601": "2020-05-26T05:41:40.258189Z",
        "url": "https://files.pythonhosted.org/packages/31/c9/c764b2593141623ba55aab0e311b15aaf61c06cf2032d8f1fc3933aee326/hyperdb-0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c12e2195d993fbf12de7b51fdf09dc78d7d3de47d17a8d73d082008306a76788",
          "md5": "bc4136367e4cd54ef7187c07ea5d8bc8",
          "sha256": "ebb09ebe93809d5ac3dcdd589033c301e590ac9db2da621bb6779803241bd2c3"
        },
        "downloads": -1,
        "filename": "hyperdb-0.1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "bc4136367e4cd54ef7187c07ea5d8bc8",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 27648,
        "upload_time": "2020-05-26T23:16:39",
        "upload_time_iso_8601": "2020-05-26T23:16:39.186357Z",
        "url": "https://files.pythonhosted.org/packages/c1/2e/2195d993fbf12de7b51fdf09dc78d7d3de47d17a8d73d082008306a76788/hyperdb-0.1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2fdc080b3647c4c9c0c0877c8ac5cedc9caf1044f2262237506159172437c1ce",
          "md5": "fcc56d8c438e442008e4c7d00c953e9a",
          "sha256": "806fe4162d3c3a279bbe98373efe9ad0457f60a66b23163bbdad109aff5294e5"
        },
        "downloads": -1,
        "filename": "hyperdb-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "fcc56d8c438e442008e4c7d00c953e9a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 4518278,
        "upload_time": "2020-05-26T23:16:41",
        "upload_time_iso_8601": "2020-05-26T23:16:41.471652Z",
        "url": "https://files.pythonhosted.org/packages/2f/dc/080b3647c4c9c0c0877c8ac5cedc9caf1044f2262237506159172437c1ce/hyperdb-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "c12e2195d993fbf12de7b51fdf09dc78d7d3de47d17a8d73d082008306a76788",
        "md5": "bc4136367e4cd54ef7187c07ea5d8bc8",
        "sha256": "ebb09ebe93809d5ac3dcdd589033c301e590ac9db2da621bb6779803241bd2c3"
      },
      "downloads": -1,
      "filename": "hyperdb-0.1.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "bc4136367e4cd54ef7187c07ea5d8bc8",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 27648,
      "upload_time": "2020-05-26T23:16:39",
      "upload_time_iso_8601": "2020-05-26T23:16:39.186357Z",
      "url": "https://files.pythonhosted.org/packages/c1/2e/2195d993fbf12de7b51fdf09dc78d7d3de47d17a8d73d082008306a76788/hyperdb-0.1.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "2fdc080b3647c4c9c0c0877c8ac5cedc9caf1044f2262237506159172437c1ce",
        "md5": "fcc56d8c438e442008e4c7d00c953e9a",
        "sha256": "806fe4162d3c3a279bbe98373efe9ad0457f60a66b23163bbdad109aff5294e5"
      },
      "downloads": -1,
      "filename": "hyperdb-0.1.1.tar.gz",
      "has_sig": false,
      "md5_digest": "fcc56d8c438e442008e4c7d00c953e9a",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 4518278,
      "upload_time": "2020-05-26T23:16:41",
      "upload_time_iso_8601": "2020-05-26T23:16:41.471652Z",
      "url": "https://files.pythonhosted.org/packages/2f/dc/080b3647c4c9c0c0877c8ac5cedc9caf1044f2262237506159172437c1ce/hyperdb-0.1.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}