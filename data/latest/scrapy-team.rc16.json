{
  "info": {
    "author": "buliqioqiolibusdo",
    "author_email": "dingyeran@163.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "![016af05cdfc247a801214168e1c955](https://ryan-1307030779.cos.ap-nanjing.myqcloud.com/vscode-md016af05cdfc247a801214168e1c955.jpg)\nscrapy-team\n=========\nScrapy-team A framework for teamwork based on scrapy\n\n- Package many pipeline files\n\n- Package the Item pipeline files involved in PDF processing\n\n- A Spidermiddleware file is packaged to handle item requests \n\nscrapy-team 基于scrapy的团队合作模式框架\n\n主要：\n\n- 打包了诸多pipeline管道文件\n\n- 打包处理了涉及pdf处理的item管道文件\n\n- 打包处理了关于item请求的spidermiddleware文件\n\n\n[ContactProjectTeam](https://github.com/buliqioqiolibusdo)\n\n\nUsage：\n========\n#### 2022/10/11 scrapy-team==1.2.16\n* CHANGE : 对象存储命名规则变更成hash文件流得值\n* DEBUG : otherpdfpipeline组件 item 类筛选判断异常\n* DEBUG : otherpdfpipeline组件 空url时异常\n* DEBUG : mongopipeline组件 空dict 类型判断异常\n\n#### 2022/9/30 scrapy-team==1.2.15\n* 增加功能 : mongo管道对`all_json`/`list_json`/`raw_other_pdf_url`/`other_pdf_url`纠正数据类型\n* DEBUG : 管道继承出错,图片管道出现img转pdf情况,\n  * 注册文件中增加pdf管道选项,用于区分原先文件管道\n#### 2022/9/29 scrapy-team==1.2.14\n* DEBUG : 修复安装错误,约束依赖版本\n* DEBUG : 修改otherpdfpipeline管道中,文件是否有效的判断逻辑\n* DEBUG : `SSL.SSLv3_METHOD` 报错\n#### 2022/9/28 scrapy-team==1.2.13\n* 增加功能 : 文件管道运行过程中遇到指定位置pdf文件时, 做失效PDF处理 >> [跳转查看示例](#invalid_pdf)\n* 增加功能 : 文件管道传入图片链接后,输出转化成pdf链接 >> [跳转查看示例](#pipeline_img_to_pdf)\n* 增加功能 : otherfile转存管道 >> [跳转查看示例](#otherfilepipelines)\n* 增加功能 : 上传oss对象存储增加响应判断, 对于非200状态码的上传操作,PDF做失效处理\n* 增加功能 : etl进度提示功能 >> [跳转查看示例](#etl_progress)\n* DEBUG : 修复下载中间件引用空cfg配置\n* DEBUG : 修复item._refer 和 item._header 相关功能\n* 优化功能 : 优化pdf损坏判断 \n#### 2022/8/3 scrapy-team==1.2.12\n* 修复:下载管道检测文件不符合时返回空字符串,出现pdf_urls=\"|\".join([\"pdf_url\",\"\"])局面\n* 整合自建代理池功能,增加随机代理权重参数 >> [跳转查看示例](#proxy_random_weights)\n* 新增 prjclear 用于清理切换分支遗留的缓存文件和文件夹 >> [跳转查看示例](#prjclear)\n* 新增 etl 用于转移数据 >> [跳转查看示例](#etl)\n#### 2022/7/7 scrapy-team==1.2.11\n* 回滚:mysql管道异步存储,存在断开连接情况\n* 新增:资讯item\n* 新增:参数CLOSESPIDER_ERROR_STATUS<tuple> :: (<错误状态码>, <出现次数>)\n    * 表示出现指定多少次状态码之后主动关闭爬虫\n#### 2022/6/13 scrapy-team==1.2.10\n* 保留scrapy基础命令,将team模式命令独立出来,创建团队项目使用newteam代替startproject,创建爬虫用jointeam代替genspider,运行爬虫用runteam或者crawl\n* 新增命令辅助创建爬虫注册配置\n* 存库管道集体变更成异步存储\n#### 2022/5/31 scrapy-team==1.2.8\n* 更改mongo管道存储月表\n#### 2022/5/12 scrapy-team==1.2.5\n* 参数`ITEM_HEADER`用作配置下载字段,不同域名的文件链接使用不同的请求头下载\n     ```\n     # eg. setting中配置\n     'ITEM_HEADER' : {\n            \"4donline.ihs.com\":{\n                'Host': '4donline.ihs.com',\n                'Referer': 'https://www.findchips.com/',\n                'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36'\n                    },\n            'datasheet.datasheetarchive.com':{\n                'Host': 'datasheet.datasheetarchive.com',\n                'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36'\n                    },\n    }\n     ```\n* 修正布隆过滤器日志警告异常\n* 更新环境依赖shell\n#### 2022/5/10 scrapy-team==1.2.0\n* 新增布隆过滤器item管道,指定Data_Size(估算数据量)和Aim_Set(除重字段)后对爬虫名下整周期item进行除重过滤\n* 向下兼容scrapyer 1.5.6版本 对不存在scrapy.cfg项目进行部分兼容\n* 为避免重复引用中间件和管道,对custom_settings中引用\"scrapy.xcc_\"开头模块进行限制\n    * 示例:\n    ```python\n    # 如果以scrapy.xcc_配置中间件 DOWNLOADER_MIDDLEWARES将整体失效\n    custom_settings = dict(\n        DOWNLOADER_MIDDLEWARES = {\n            'gerapy_pyppeteer.downloadermiddlewares.PyppeteerMiddleware': 542,\n            'scrapy.xcc_downloadermiddlewares.randuamiddleware.RandownUserAgent': 543,\n        }\n    )\n    ```\n* 管道与中间件配置从cfg硬替换custom_settings模式,切换成cfg配置update补充custom_settings模式\n* 修正了双日志异常情况\n* 新增shell脚本安装更新环境,对冲突依赖进行剔除\n* 增加pdf检测损坏功能,并对eof缺失部分进行补全后检测(持续跟进pdf种类变化)\n\n#### 2022/5/6 scrapyer==1.5.11\n* 新增 spider_register 爬虫注册机制，爬虫名集中配置，爬虫类中不用name属性，组件使用开关情况也在配置中写明\n* 修改阶梯配置 spider_register未指定的取custom_settings模块管道配置\n* 默认将所有scrapy框架非基础组件关闭\n\n\n#### 2022/4/25 scrapyer==1.5.8\n* ~~设置switch_register 管道组件注册机智~~\n* ~~重新规则settings文件，默认将所有scrapy框架组件打开~~\n* scrapy.cfg中正式，测试双配置，中间件通过.bashrc IF_PROD 判断是否是正式环境\n* 爬虫随机代理修改为请求随机代理\n* 修改创建项目和爬虫命令，按人物>项目>爬虫名分层结构创建，一并生成main文件\n* 阿里云资源链接目录更改为hash方式处理\n\n### 目录结构\n```\n├─Command(命令流程)\n├─Scrapy_Prj(Scrapy物料采集项目)\n|  ├─middlewares\n|  ├─pipelines\n|  ├─items.py\n|  ├─settings\n|  └─spiders\n|      ├─xxxx(role)\n|      └─...\n├─Non_Scrapy_Prj(非Scrapy项目)\n│  ├─...(feapder/asycio/multiprocessing)\n├─.gitignore(git忽略文件)\n├─requirements.txt(依赖库)\n├─Team_Public(公共方法公共配置)\n└─....\n```\n\n* 拉代码,ide创建个人分支\n\n* 创建环境\n* 安装依赖\n    > 运行init环境依赖\n    ``` \n   $pwd$ \\Command\\_win_env_init.bat\n   eg: e:\\news\\Command\\_win_env_init.bat\n    ```\n\n\n* 创建爬虫项目\n    ```\n    scrapy newteam <someprj>\n    eg: scrapy newteam saas\n    ```\n    * 备注: 创建项目(scrapy.cfg保有单一存库方式正式和测试各一套配置,如果存在不同项目存不同mongo情况建议分出来单独项目)\n\n* 创建爬虫文件以及配置\n    ```\n    scrapy jointeam <somebody> <somewebsite> <somecrawl>\n    eg: scrapy jointeam zhizhong semiee detailcrawl\n    ```\n\n* 单项目完成后推代码到gitlab\n* 定期review合并代码,pull到DEMP中设置周期调度并监控速度及异常\n\n\n\n<p id=\"proxy_random_weights\"></p> \n\n##### 新增随机代理权重值\n\n* 用法一：在scrapy.cfg文件的代理配置的WEIGHTS中添加权重参数（scrapy.cfg为项目公用文件，不可私自配参）\n\n```\n    ## 例如：\n    [proxy_no.1_cfg]\n    # Self-built domestic tunnels\n    PROXY_USER= iceasy\n    PROXY_PASS= xcc2022\n    PROXY_SERVER= http://10.8.108.201:9900 \n    WEIGHTS = 7/10\n```\n\n\n* 用法二：项目在爬虫文件custom_settings中添加（特殊项目需要调整，询问后在爬虫文件中调参）\n```\n    ## 表示取scrapy.cfg中诸多代理隧道配置，其中如proxy_no.1_cfg配置的权重为1/<权重值合计>，例如当前表示随机到proxy_no.1_cfg代理配置的概率为1/7\n    custom_settings = dict(\n        PROXIES_WEIGHTS={\n            \"proxy_no.1_cfg\":1,\n            \"proxy_no.1.1_cfg\":1,\n            \"proxy_no.1.2_cfg\":1,\n            \"proxy_no.2_cfg\":1,\n            \"proxy_no.3_cfg\":1,\n            \"proxy_no.4_cfg\":1,\n            \"proxy_no.5_cfg\":1,\n        }\n    )\n```\n\n<p id=\"prjclear\"></p> \n\n##### scrapy prjclear 用法说明\n\n* 用法：  \"scrapy prjclear <path>\"\n\n```\n    ## 例如：\n    scrapy prjclear \n    或者：\n    scrapy prjclear Scrapy_Prj\n```\n\n\n<p id=\"etl\"></p> \n\n##### scrapy etl 用法说明\n\n* 用法：  \"scrapy etl <Set Name> <Filter Key> <Filter Value> <Aim Set Name>\"\n* 注意 可支持pymongo==3.12.0版本，高版本可能不支持\n\n```\n    ## 例如：将scrapy.cfg 中dev库筛选数据转移到prod库\n    scrapy etl ware_category_copy brand_name Winsemi\n```\n\n\n<p id=\"invalid_pdf\"></p> \n\n\n##### 对于oss文件管道\n  * 设置中指定失效的PDF路径 `FILTER_INVALID_FILE_PATHS`<list> 在爬取过程中判断并作失效PDF处理.\n\n\n<p id=\"pipeline_img_to_pdf\"></p> \n\n\n##### 对于oss文件管道\n  * 示例:传入图片地址后自行转化成pdf转存链接\n    ```\n        2022-09-28 22:46:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.baidu.com>\n        {'pdf_url': 'https://xcc2.oss-cn-shenzhen.aliyuncs.com/items/202209/31e50a13c/b68a2160bd3874a5fcb0184c0e86b7727618e10d.pdf',\n        'raw_pdf_url': 'https://pic1.zhimg.com/50/v2-eeb4193a1ac0dac9237197f7838aec6a_720w.jpg?source=b1f6dc53|https://pic2.zhimg.com/50/v2-f463d84e2fe64b7580bfaee676b003b6_720w.jpg?source=b1f6dc53'}\n        2022-09-28 22:46:25 [scrapy.core.engine] INFO: Closing spider (finished)\n    ```\n\n\n\n<p id=\"etl_progress\"></p> \n\n##### 提示\n\n```\nD:\\de-factory>scrapy etl ware_detail_dataplatform sources sexxxx  \n208263it [09:57, 348.58it/s]\ncompleted~\n```\n\n\n<p id=\"otherfilepipelines\"></p> \n\n##### ossotherfilepipelines 用法说明\n\n* 同`ossfilepipelines`,在注册文件管道tuple中添加 `other_file`或者`other_file_bak`\n* 配置参数\n\n\n- **实现功能**\n\n\\# 下载失败留空字符串\n\\# 检测文件类型不为html否则置空\n\\# 若为pdf类型则检测是否为有效文件\n\n\n\n- **spider配置文件**\n\n```python\n增加：\nFILE_PIPE_CONFIG={\n    'OssOtherFilesPipeline':\n        {'FILES_OSS_URLS_FIELD': 'raw_other_pdf_url',\n         'FILES_OSS_RESULT_FIELD': 'other_pdf_url',\n         'RESOURCE_CLASSNAME': 'FactoryMaterialItem'},\n    'OssOtherFilesPipelineBak':\n        {'FILES_OSS_URLS_FIELD': 'raw_other_pdf_url',\n         'FILES_OSS_RESULT_FIELD': 'other_pdf_url',\n         'RESOURCE_CLASSNAME': 'FactoryMaterialItem'},\n}\n```\n\n- **raw_other_pdf_url  other_pdf_url 的字段数据结构**\n\n```python\n{\n\"file_name_1\": \"url\"<string>,\n\"file_name_2\": \"url\"<string>,\n\"file_name_3\": \"url|url\"<string>,\n}\n\n示例：\nraw_other_pdf_url = {\"数据表\": \"https://xcc2.oss-cn-shenzhen.aliyuncs.com/paper/Paper_caj/b7da5fe15fce7b8b8f66d865f58c3e6c91c75c00.caj|https://xcc2.oss-cn-shenzhen.aliyuncs.com/paper/Paper_caj/5b9cd0ca29a03ba0686854a4607396ea4a9d1f071111111111.caj\",\n                     'aaa':\"https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CMFD&dbname=CMFD201801&filename=1017836624.nh&uniplatform=NZKPT&v=DklNvEDPEikIGdvw3PeDxOxJWn44i8PZJVwTj7gznh1YmjxppRdDBaf8ykoSjhNu\",\n                     'zip':\"https://xcc2.oss-cn-shenzhen.aliyuncs.com/li_pdf/Manufacturers_Pdf/143497617822cc442c2014c593c46c53f4cf5254111111.zip\",\n                     \"jpg\":\"https://xcc2.oss-cn-shenzhen.aliyuncs.com/items/7505d64a5/87dc6fd833f4eb078a63520aed2143e3abbe6057.jpeg|https://www.mouser.cn/images/lairdconnectivity/images/LI0201B800R_series_SPL.jpg\",\n                     \"环境文件\":\"https://www.mouser.com/catalog/additional/ADI_5843_RoHS_Certificate.pdf|https://www.mouser.com/catalog/additional/ADI_5843_RoHS_Certificat1111111111e.pdf\",\n                     'error':\"https://xcc2.oss-cn-shenzhen.aliyuncs.com/li_pdf/Manufacturers_Pdf/0a6474a5d3afe86d5c7ab2c17057f1e5973fc27e.pdf\",\n                     \"test\":\"https://xcc2.oss-cn-shenzhen.aliyuncs.com/ye_img/Manufacturers_Img/41ffafc006d5ad73d60851eede7ba3d3fcc296c2.bmp\"}\n```",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://scrapy.org",
    "keywords": "",
    "license": "BSD",
    "maintainer": "",
    "maintainer_email": "",
    "name": "Scrapy-Team",
    "package_url": "https://pypi.org/project/Scrapy-Team/",
    "platform": null,
    "project_url": "https://pypi.org/project/Scrapy-Team/",
    "project_urls": {
      "Documentation": "https://docs.scrapy.org/",
      "Homepage": "https://scrapy.org",
      "Source": "https://github.com/buliqioqiolibusdo/scrapyer",
      "Tracker": "https://github.com/buliqioqiolibusdo/scrapyer/issues"
    },
    "release_url": "https://pypi.org/project/Scrapy-Team/1.2.16/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "Based on scrapy framework, combined with common component tools",
    "version": "1.2.16",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 15381828,
  "releases": {
    "1.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "483d510a4b0bd05029fbb707a078339df3430ccd70cc9f0bd33151db491319c6",
          "md5": "8f201c29e262749a657d6dbc9fd3ce79",
          "sha256": "4f0682e16bfe9f58af1772cb2335f91513fb3a383be3ac491ef0916261d3aeed"
        },
        "downloads": -1,
        "filename": "Scrapy-team-1.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "8f201c29e262749a657d6dbc9fd3ce79",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 1146153,
        "upload_time": "2022-05-11T09:26:27",
        "upload_time_iso_8601": "2022-05-11T09:26:27.124126Z",
        "url": "https://files.pythonhosted.org/packages/48/3d/510a4b0bd05029fbb707a078339df3430ccd70cc9f0bd33151db491319c6/Scrapy-team-1.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ed42d972d7e53db06fbe9583d45612b5e608a5c3b419988f740349b4104f6ef6",
          "md5": "81694c9462c994148ef0d6e52f307c49",
          "sha256": "57232abfd7e4501b852af95af6b3f911643decd62f019be2b872906c034faa6d"
        },
        "downloads": -1,
        "filename": "Scrapy-Team-1.2.1.tar.gz",
        "has_sig": false,
        "md5_digest": "81694c9462c994148ef0d6e52f307c49",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 1146233,
        "upload_time": "2022-05-11T09:38:19",
        "upload_time_iso_8601": "2022-05-11T09:38:19.940652Z",
        "url": "https://files.pythonhosted.org/packages/ed/42/d972d7e53db06fbe9583d45612b5e608a5c3b419988f740349b4104f6ef6/Scrapy-Team-1.2.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.10": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "236f3ac9215d1adf1edcebbd9be73ef906c7a4062cae8bcac95a05d900e2e9ff",
          "md5": "0084d7f92dd5a9fb0e2fc09e31a14f7c",
          "sha256": "b66c406add255651117254c0034b8f505783bba7f91fd48a92420513e662117d"
        },
        "downloads": -1,
        "filename": "Scrapy-Team-1.2.10.tar.gz",
        "has_sig": false,
        "md5_digest": "0084d7f92dd5a9fb0e2fc09e31a14f7c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 1145589,
        "upload_time": "2022-06-14T02:29:02",
        "upload_time_iso_8601": "2022-06-14T02:29:02.822768Z",
        "url": "https://files.pythonhosted.org/packages/23/6f/3ac9215d1adf1edcebbd9be73ef906c7a4062cae8bcac95a05d900e2e9ff/Scrapy-Team-1.2.10.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.11": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6c31c9326c2a97707802fae474c94c0f5ce49d2f30f29dcc87fa22072118d878",
          "md5": "95cb78741c5130ea9d075711a029de2b",
          "sha256": "04271df8e2b578433039542a7f9c7f3e1d5f3e6135e36a596f2013541cfedae8"
        },
        "downloads": -1,
        "filename": "Scrapy-Team-1.2.11.tar.gz",
        "has_sig": false,
        "md5_digest": "95cb78741c5130ea9d075711a029de2b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 1146289,
        "upload_time": "2022-07-07T06:09:38",
        "upload_time_iso_8601": "2022-07-07T06:09:38.678763Z",
        "url": "https://files.pythonhosted.org/packages/6c/31/c9326c2a97707802fae474c94c0f5ce49d2f30f29dcc87fa22072118d878/Scrapy-Team-1.2.11.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.12": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c52a83068e036068a17794f1bf71288c57ed91c24d03fb2d9d446c600e7b870a",
          "md5": "a5457785ebed542192c6e34d9b19f095",
          "sha256": "aec07c1a0e0490a8c1534d17d997fff371d01099fe5c098539f98d0616ba74f2"
        },
        "downloads": -1,
        "filename": "Scrapy-Team-1.2.12.tar.gz",
        "has_sig": false,
        "md5_digest": "a5457785ebed542192c6e34d9b19f095",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 1150337,
        "upload_time": "2022-08-03T05:10:33",
        "upload_time_iso_8601": "2022-08-03T05:10:33.286951Z",
        "url": "https://files.pythonhosted.org/packages/c5/2a/83068e036068a17794f1bf71288c57ed91c24d03fb2d9d446c600e7b870a/Scrapy-Team-1.2.12.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.13": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0b6fcc39259ac54878eb6f76bfeb23d5a6426342cdb2e0c8e505fd6061b79d76",
          "md5": "b5280cef1911ab563880a72fc758b7d6",
          "sha256": "af0bf3900e0effacddb3a5a2ba8983eccbf5765c37b56fdec16bcbc73b34146e"
        },
        "downloads": -1,
        "filename": "Scrapy-Team-1.2.13.tar.gz",
        "has_sig": false,
        "md5_digest": "b5280cef1911ab563880a72fc758b7d6",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 5617314,
        "upload_time": "2022-09-29T04:10:48",
        "upload_time_iso_8601": "2022-09-29T04:10:48.935573Z",
        "url": "https://files.pythonhosted.org/packages/0b/6f/cc39259ac54878eb6f76bfeb23d5a6426342cdb2e0c8e505fd6061b79d76/Scrapy-Team-1.2.13.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.14": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7954d8b67b9ae4069b53cd8394000711c1502e82729a0b68e3d742b9335e16c9",
          "md5": "3505ee187842d64b36bffbe4313f2fd7",
          "sha256": "8175442df9a4843dfe98b244465f1f43ca112acdcdc28235da985b2737e8f7ef"
        },
        "downloads": -1,
        "filename": "Scrapy-Team-1.2.14.tar.gz",
        "has_sig": false,
        "md5_digest": "3505ee187842d64b36bffbe4313f2fd7",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 5614885,
        "upload_time": "2022-09-29T13:39:52",
        "upload_time_iso_8601": "2022-09-29T13:39:52.447261Z",
        "url": "https://files.pythonhosted.org/packages/79/54/d8b67b9ae4069b53cd8394000711c1502e82729a0b68e3d742b9335e16c9/Scrapy-Team-1.2.14.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.15": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bc6c0c9d5824cc545b7688849cba49fae597dfc17f4e17e40fa6d3b41765385d",
          "md5": "e5bc4a6ece6bfc3868ffca74d3b0e980",
          "sha256": "d03677275cc3be7829bf519c5a6d29dfb62c5c075e39f28bca5740fb972deb0a"
        },
        "downloads": -1,
        "filename": "Scrapy-Team-1.2.15.tar.gz",
        "has_sig": false,
        "md5_digest": "e5bc4a6ece6bfc3868ffca74d3b0e980",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 1061912,
        "upload_time": "2022-09-30T08:00:33",
        "upload_time_iso_8601": "2022-09-30T08:00:33.747713Z",
        "url": "https://files.pythonhosted.org/packages/bc/6c/0c9d5824cc545b7688849cba49fae597dfc17f4e17e40fa6d3b41765385d/Scrapy-Team-1.2.15.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.16": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a6ffac9e4e0660df07ae3920a78c22f78f7bd120af2661535a930c3f5931d470",
          "md5": "d265ea94db99ebff3bf9d7282b329fe0",
          "sha256": "e4dfbf8a96e1e8f67ec793ca4bc6b2fb791b23eb0287c711e30c73b92bfc520c"
        },
        "downloads": -1,
        "filename": "Scrapy-Team-1.2.16.tar.gz",
        "has_sig": false,
        "md5_digest": "d265ea94db99ebff3bf9d7282b329fe0",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 1063196,
        "upload_time": "2022-10-12T02:49:36",
        "upload_time_iso_8601": "2022-10-12T02:49:36.023581Z",
        "url": "https://files.pythonhosted.org/packages/a6/ff/ac9e4e0660df07ae3920a78c22f78f7bd120af2661535a930c3f5931d470/Scrapy-Team-1.2.16.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5259226e38ffa375f2087f03574a7fffcc1dbfbdb80e4cedde75c8e102891ae6",
          "md5": "bd4ab244b4a08a4864bccd59434fb664",
          "sha256": "872549fc81bba3f9f5c51bccc4c8fe0459ed7496950bdf196c5537e2ae4224c0"
        },
        "downloads": -1,
        "filename": "Scrapy-Team-1.2.2.tar.gz",
        "has_sig": false,
        "md5_digest": "bd4ab244b4a08a4864bccd59434fb664",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 1146251,
        "upload_time": "2022-05-11T11:26:41",
        "upload_time_iso_8601": "2022-05-11T11:26:41.358804Z",
        "url": "https://files.pythonhosted.org/packages/52/59/226e38ffa375f2087f03574a7fffcc1dbfbdb80e4cedde75c8e102891ae6/Scrapy-Team-1.2.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8f5b911ceb64c33d1d38b00c55a6ef5b797ec6a33e750408722825887a689f00",
          "md5": "e72fe96ad5d84fab24b4d42c230dabed",
          "sha256": "80fbded342334f066f839d58939e615b0869cd0565194e9cce0a9d3c0140f131"
        },
        "downloads": -1,
        "filename": "Scrapy-Team-1.2.4.tar.gz",
        "has_sig": false,
        "md5_digest": "e72fe96ad5d84fab24b4d42c230dabed",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 1146300,
        "upload_time": "2022-05-12T06:59:58",
        "upload_time_iso_8601": "2022-05-12T06:59:58.215019Z",
        "url": "https://files.pythonhosted.org/packages/8f/5b/911ceb64c33d1d38b00c55a6ef5b797ec6a33e750408722825887a689f00/Scrapy-Team-1.2.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "10310a3b6476457f5aa885db3ea02522b5a28e04c1adda684dc4db1be6e8bb0b",
          "md5": "198c1ce71e042317ee3e448ba343995f",
          "sha256": "05b945209b975a6bd26d2cbedcaa54d4d5f8978979c2e0006817141e1dcd29cf"
        },
        "downloads": -1,
        "filename": "Scrapy-Team-1.2.5.tar.gz",
        "has_sig": false,
        "md5_digest": "198c1ce71e042317ee3e448ba343995f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 1146424,
        "upload_time": "2022-05-12T12:37:37",
        "upload_time_iso_8601": "2022-05-12T12:37:37.959042Z",
        "url": "https://files.pythonhosted.org/packages/10/31/0a3b6476457f5aa885db3ea02522b5a28e04c1adda684dc4db1be6e8bb0b/Scrapy-Team-1.2.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ae9fdcb15745c1d820027012bddec4a3cc7b726e5d3d1ae46683a181ea2e1eeb",
          "md5": "de079ac7d37ded468d7be4073a59947f",
          "sha256": "e00e69d6fc442e4a7e9cb0935f9a66dc447a92d10f17606cf3fee341203f952f"
        },
        "downloads": -1,
        "filename": "Scrapy-Team-1.2.6.tar.gz",
        "has_sig": false,
        "md5_digest": "de079ac7d37ded468d7be4073a59947f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 1146428,
        "upload_time": "2022-05-13T03:10:22",
        "upload_time_iso_8601": "2022-05-13T03:10:22.230387Z",
        "url": "https://files.pythonhosted.org/packages/ae/9f/dcb15745c1d820027012bddec4a3cc7b726e5d3d1ae46683a181ea2e1eeb/Scrapy-Team-1.2.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6affda8b9a1adb6c6637288a7d7e3a43e577656ed7f0c3e7fe12cae0b12cf801",
          "md5": "79517566ea899e2790d62edcb1613d4e",
          "sha256": "a08e76bcd554afe179f5931770403ceed31333d1de6eccaa9d82b83d1dc9ee9c"
        },
        "downloads": -1,
        "filename": "Scrapy-Team-1.2.7.tar.gz",
        "has_sig": false,
        "md5_digest": "79517566ea899e2790d62edcb1613d4e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 1141483,
        "upload_time": "2022-05-25T02:15:25",
        "upload_time_iso_8601": "2022-05-25T02:15:25.583040Z",
        "url": "https://files.pythonhosted.org/packages/6a/ff/da8b9a1adb6c6637288a7d7e3a43e577656ed7f0c3e7fe12cae0b12cf801/Scrapy-Team-1.2.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e622e02b0c22506c4e10a0d1463e7ac0e61e3b31af795d9157356c5e2cb086ee",
          "md5": "704dbcb4e662871d80ae1484f0b3f846",
          "sha256": "5bd1e1811e18ba5f9c33dca54c798b87d263cd1e741707a16091b8d2cf884ba3"
        },
        "downloads": -1,
        "filename": "Scrapy-Team-1.2.8.tar.gz",
        "has_sig": false,
        "md5_digest": "704dbcb4e662871d80ae1484f0b3f846",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 1141624,
        "upload_time": "2022-05-31T19:16:03",
        "upload_time_iso_8601": "2022-05-31T19:16:03.228261Z",
        "url": "https://files.pythonhosted.org/packages/e6/22/e02b0c22506c4e10a0d1463e7ac0e61e3b31af795d9157356c5e2cb086ee/Scrapy-Team-1.2.8.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.9": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6d33dc4072971c5b25ae314f86fe7582549a3543ea60a34bcb39cd37948c6417",
          "md5": "40490e51bfb802780c35ce4a8deb4f9a",
          "sha256": "b03e85d328e339ab3a632a15ce156d0816f948e1ee4d551eea71d1dd74237c90"
        },
        "downloads": -1,
        "filename": "Scrapy-Team-1.2.9.tar.gz",
        "has_sig": false,
        "md5_digest": "40490e51bfb802780c35ce4a8deb4f9a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 1141723,
        "upload_time": "2022-06-01T09:05:27",
        "upload_time_iso_8601": "2022-06-01T09:05:27.685321Z",
        "url": "https://files.pythonhosted.org/packages/6d/33/dc4072971c5b25ae314f86fe7582549a3543ea60a34bcb39cd37948c6417/Scrapy-Team-1.2.9.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "a6ffac9e4e0660df07ae3920a78c22f78f7bd120af2661535a930c3f5931d470",
        "md5": "d265ea94db99ebff3bf9d7282b329fe0",
        "sha256": "e4dfbf8a96e1e8f67ec793ca4bc6b2fb791b23eb0287c711e30c73b92bfc520c"
      },
      "downloads": -1,
      "filename": "Scrapy-Team-1.2.16.tar.gz",
      "has_sig": false,
      "md5_digest": "d265ea94db99ebff3bf9d7282b329fe0",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 1063196,
      "upload_time": "2022-10-12T02:49:36",
      "upload_time_iso_8601": "2022-10-12T02:49:36.023581Z",
      "url": "https://files.pythonhosted.org/packages/a6/ff/ac9e4e0660df07ae3920a78c22f78f7bd120af2661535a930c3f5931d470/Scrapy-Team-1.2.16.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}