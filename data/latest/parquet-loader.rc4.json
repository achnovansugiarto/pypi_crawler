{
  "info": {
    "author": "('keyog',)",
    "author_email": "jgy206@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.2",
      "Programming Language :: Python :: 3.3",
      "Programming Language :: Python :: 3.4",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7"
    ],
    "description": "# ParquetLoader\n<a href=\"https://github.com/Keunyoung-Jung/ParquetLoader/releases\"><img alt=\"GitHub release\" src=\"https://img.shields.io/github/release/Keunyoung-Jung/ParquetLoader.svg\" /></a> \n<a href=\"https://github.com/Keunyoung-Jung/ParquetLoader/issues\"><img alt=\"Issues\" src=\"https://img.shields.io/github/issues/Keunyoung-Jung/ParquetLoader\"/></a>    \nParquet file Load and Read from minio &amp; S3 or Local\nThis repository help read parquet file, When you train model or Analysis using bigdata.\n\n## 1. Installation\n### 1.1. Install from pip\n```shell\npip install parquet-loader\n```\n### 1.2 Install from source codes\n```shell\ngit clone https://github.com/Keunyoung-Jung/ParquetLoader\ncd ParquetLoader\npip install -e .\n```\n## 2. Introduce\n**ParquetLoader** can help to read large parquet files.    \n**ParquetLoader** is built on base of pandas and fastparquet, which helps in situations where Spark clusters are not available.\n\nIt proceeds to load data into memory based on chuck size.    \nThen return it as a pandas dataframe.    \n## 3. Quick Start\n### 3.1. Local Path\nIf your file is located `local`, you can load the data this way.\n```python\nfrom ParquetLoader import DataLoader\n\ndl = DataLoader(\n    folder='parquet_data'\n    shuffle=False\n    )\nfor df in dl :\n    print(df.head())\n```\n### 3.2. S3 Path\nIf your file is located `S3` or `Minio`, you have to set \nenvironment variable.    \n```shell\nexport AWS_ACCESS_KEY_ID=my-access-key\nexport AWS_SECRET_ACCESS_KEY=my-secret-key\nexport AWS_DEFAULT_REGION=ap-northeast-2\n```\nWhen you have finished setting, you can load data this way.   \n```python\nfrom ParquetLoader import S3Loader\n\nsl = S3Loader(\n        bucket='mysterico-feature-store',\n        folder=\"mongo-sentence-token-feature\",\n        depth=2)\n\nfor df in sl :\n    print(df.head())\n```\n\n## 4. Parameters\n`ParquetLoader` can control reading data using parameters.\nThe only difference between `S3Loader` and `DataLoader` is the `root_path` parameter.\n```python\ndl = DataLoader(\n    chunk_size : int =100000,\n    root_path : str = '.', # S3Loader using \"bucket\"\n    folder : str = 'data',\n    shuffle : bool = True,\n    random_seed : int = int((time() - int(time()))*100000),\n    columns : list = None,\n    depth : int = 0,\n    std_out: bool = True,\n    filters: list = None\n    )\n```\n* `chunk_size`\n    * default : 100,000 row \n    * This parameter controls the number of rows loaded into memory when reading data.\n* `root_path` or `bucket`\n    * default : current path\n    * This parameter is used to specify the project path or datastore path.\n* `folder`\n    * default : \"data\"\n    * This parameter specifies the actual folder in which the parquet is clustered.\n* `shuffle`\n    * default : True\n    * Whether to shuffle the data.\n* `random_seed`\n    * default : `int((time() - int(time()))*100000)`\n    * You can fix the order of the shuffled data by giving it a random seed.\n* `columns`\n    * default : None\n    * When reading data, you can select columns.\n* `depth`\n    * default : 0\n    * It is used when the parquet in the folder is partitioned and there is depth.\n* `std_out`\n    * default : True\n    * You can turn off output.\n* `filters`\n    * It is used when you want get filtered dataframe, It must use 2 dim list\n    * example : `[[(\"column\",\"==\",10)]]`\n\n### 4.1. Select Columns\n`columns` param is taken as a list.\n```python\ndl = DataLoader(\n    folder='parquet_data',\n    colums=['name','age','gender']\n    )\n```\n### 4.2. Setting depth\nUse if your parquet file is partitioned and depth exists.    \n**Example**\n```\nðŸ“¦ data    \n â”£ ðŸ“¦ Year=2020     \n    â”£ ðŸ“œ part-0000-example.snappy.parquet   \n    â”— ðŸ“œ part-0001-example.snappy.parquet  \n â”£ ðŸ“¦ Year=2021     \n    â”£ ðŸ“œ part-0002-example.snappy.parquet   \n    â”— ðŸ“œ part-0003-example.snappy.parquet  \n```\nThe data path in this example has a `depth 1`.\n```python\ndl = DataLoader(\n    folder='parquet_data',\n    depth=1\n    )\n```\n\n## 5. Get Metadata\n`DataLoader` Object can get metadata your parquet\n```python\nprint(data_loader.schema) # get data schema\nprint(data_loader.columns) # get data columns\nprint(data_loader.count) # get total count\nprint(data_loader.info) # get metadata infomation\n```\n\n## 6. Customize S3 Path\nIf you use minio or other obejct storage,you will use s3 parameters\n```python\ndl = S3Loader(\n    s3_endpoint_url : str = '',\n    s3_access_key : str = '',\n    s3_secret_key : str = '',\n    bucket : str = '.',\n    folder : str = 'data',\n    )\n```\n* `s3_endpoint_url`\n    * Storage endpoint url you want to use\n    * example : \"http://mino-service.kubeflow:9000\"\n* `s3_access_key` and `s3_secret_key`\n    * you can set s3_access_key and s3_secret_key, but I don't recommend using it\n    * it is recommended to use environment variables.\n\n## 7. Get Filtered Dataframe\nIt is used when you want get filtered dataframe, It must use 2 dim list\nIt is built with a two-dimensional list construction. (Equal fastparquet filter)\n```python\ndl = S3Loader(\n    bucket = 'test',\n    folder = 'data',\n    filters = [[[(\"col1\",\">\",10)]]]\n    )\n```\nThe first list consists of an OR operation.\n```python\n# col > 10 or col2 in [\"children\",\"kids\"]\nfilters = [\n    [(\"col1\",\">\",10)],\n    [\"col2\",\"in\",[\"children\",\"kids\"]]\n    ] \n```\nThe second list consists of an AND operation.\n```python\n# col > 10 and col2 == \"male\"\nfilters = [\n    [(\"col1\",\">\",10),(\"col2\",\"==\",\"male\")]\n    ] \n```\nYou can also mix the two to make a filter.\n```python\n# (col > 10 and col2 == \"male\") or col3 in [\"children\",\"kids\"]\nfilters = [\n    [(\"col1\",\">\",10),(\"col2\",\"==\",\"male\")],\n    [\"col3\",\"in\",[\"children\",\"kids\"]]\n    ]\n```\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "https://github.com/Keunyoung-Jung/ParquetLoader",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/Keunyoung-Jung/ParquetLoader",
    "keywords": "parquet,loader,parquetloader",
    "license": "Apache License 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "parquet-loader",
    "package_url": "https://pypi.org/project/parquet-loader/",
    "platform": "",
    "project_url": "https://pypi.org/project/parquet-loader/",
    "project_urls": {
      "Download": "https://github.com/Keunyoung-Jung/ParquetLoader",
      "Homepage": "https://github.com/Keunyoung-Jung/ParquetLoader"
    },
    "release_url": "https://pypi.org/project/parquet-loader/0.0.4/",
    "requires_dist": [
      "pandas (<=1.2.0)",
      "fastparquet (==0.8.0)",
      "s3fs"
    ],
    "requires_python": ">=3",
    "summary": "Parquet file Load and Read from minio & S3",
    "version": "0.0.4",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 13077798,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "63c3e9d546b57d465435452df7bc766a0240ab526434d099ec97173aed80b94d",
          "md5": "83f11e34d867d58b3e47fd45c337c8fc",
          "sha256": "a9932da150b8d8dc679981067fed1a83bb22939f4e47fc69c7bbb4d667bc9cab"
        },
        "downloads": -1,
        "filename": "parquet_loader-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "83f11e34d867d58b3e47fd45c337c8fc",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3",
        "size": 8821,
        "upload_time": "2022-03-03T06:09:50",
        "upload_time_iso_8601": "2022-03-03T06:09:50.632781Z",
        "url": "https://files.pythonhosted.org/packages/63/c3/e9d546b57d465435452df7bc766a0240ab526434d099ec97173aed80b94d/parquet_loader-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7fed75f47f66f8908bf256ee76372b5f16c09ecd95ca7d2099045036aaf87b0a",
          "md5": "98a5873a90dffcecf48e834a9a5d391b",
          "sha256": "da20194d8a39b570d6e204453a7ca63b1e182f0fe3020141453ca29aa7f8901a"
        },
        "downloads": -1,
        "filename": "parquet_loader-0.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "98a5873a90dffcecf48e834a9a5d391b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3",
        "size": 10365,
        "upload_time": "2022-03-03T06:21:00",
        "upload_time_iso_8601": "2022-03-03T06:21:00.868540Z",
        "url": "https://files.pythonhosted.org/packages/7f/ed/75f47f66f8908bf256ee76372b5f16c09ecd95ca7d2099045036aaf87b0a/parquet_loader-0.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b45e5c8914f5cbccbbe46b5ce2b870c5f5fbae95e05176231072f3c814e2610f",
          "md5": "69d9e5db7b63b981c67e98295d9f16e4",
          "sha256": "613dbf6260c1879f78d5072b8a67baf43f69575d9eb9986376ce6a82299de2d7"
        },
        "downloads": -1,
        "filename": "parquet_loader-0.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "69d9e5db7b63b981c67e98295d9f16e4",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3",
        "size": 11176,
        "upload_time": "2022-03-04T04:24:07",
        "upload_time_iso_8601": "2022-03-04T04:24:07.575231Z",
        "url": "https://files.pythonhosted.org/packages/b4/5e/5c8914f5cbccbbe46b5ce2b870c5f5fbae95e05176231072f3c814e2610f/parquet_loader-0.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1ed67caa75f3370202805d49d04fd7935fcff35a75e6652a07a1b70476eed0c6",
          "md5": "0d4accc56e556ccb1d580ea348026790",
          "sha256": "fa22834031403684e73d0d56f0067b9a6c708542d1146448f837cc5a7c4b1af9"
        },
        "downloads": -1,
        "filename": "parquet_loader-0.0.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0d4accc56e556ccb1d580ea348026790",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3",
        "size": 12385,
        "upload_time": "2022-03-04T08:39:00",
        "upload_time_iso_8601": "2022-03-04T08:39:00.432327Z",
        "url": "https://files.pythonhosted.org/packages/1e/d6/7caa75f3370202805d49d04fd7935fcff35a75e6652a07a1b70476eed0c6/parquet_loader-0.0.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "1ed67caa75f3370202805d49d04fd7935fcff35a75e6652a07a1b70476eed0c6",
        "md5": "0d4accc56e556ccb1d580ea348026790",
        "sha256": "fa22834031403684e73d0d56f0067b9a6c708542d1146448f837cc5a7c4b1af9"
      },
      "downloads": -1,
      "filename": "parquet_loader-0.0.4-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "0d4accc56e556ccb1d580ea348026790",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3",
      "size": 12385,
      "upload_time": "2022-03-04T08:39:00",
      "upload_time_iso_8601": "2022-03-04T08:39:00.432327Z",
      "url": "https://files.pythonhosted.org/packages/1e/d6/7caa75f3370202805d49d04fd7935fcff35a75e6652a07a1b70476eed0c6/parquet_loader-0.0.4-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}