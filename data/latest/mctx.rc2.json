{
  "info": {
    "author": "DeepMind",
    "author_email": "mctx-dev@google.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: Apache Software License",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Topic :: Scientific/Engineering :: Artificial Intelligence",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "# Mctx: MCTS-in-JAX\n\nMctx is a library with a [JAX](https://github.com/google/jax)-native\nimplementation of Monte Carlo tree search (MCTS) algorithms such as\n[AlphaZero](https://deepmind.com/blog/article/alphazero-shedding-new-light-grand-games-chess-shogi-and-go),\n[MuZero](https://deepmind.com/blog/article/muzero-mastering-go-chess-shogi-and-atari-without-rules), and\n[Gumbel MuZero](https://openreview.net/forum?id=bERaNdoegnO). For computation\nspeed up, the implementation fully supports JIT-compilation. Search algorithms\nin Mctx are defined for and operate on batches of inputs, in parallel. This\nallows to make the most of the accelerators and enables the algorithms to work\nwith large learned environment models parameterized by deep neural networks.\n\n## Installation\n\nYou can install the latest released version of Mctx from PyPI via:\n\n```sh\npip install mctx\n```\n\nor you can install the latest development version from GitHub:\n\n```sh\npip install git+https://github.com/deepmind/mctx.git\n```\n\n## Motivation\n\nLearning and search have been important topics since the early days of AI\nresearch. In the words of Rich Sutton: *One thing that should be learned [...]\nis the great power of general purpose methods, of methods that continue to scale\nwith increased computation even as the available computation becomes very great.\nThe two methods that seem to scale arbitrarily in this way are search and\nlearning.*\n\nRecently, search algorithms have been successfully combined with learned models\nparameterized by deep neural networks, resulting in some of the most powerful\nand general reinforcement learning algorithms to date (e.g. MuZero).\nHowever, using search algorithms in combination with deep neural networks\nrequires efficient implementations, typically written in fast compiled\nlanguages; this can come at the expense of usability and hackability,\nespecially for researchers that are not familiar with C++. In turn this limits\nadoption and further research on this critical topic.\n\nThrough this library, we hope to help researchers everywhere to contribute to\nsuch an exciting area of research. We provide JAX-native implementations of core\nsearch algorithms such as MCTS, that we believe strike a good balance between\nperformance and usability for researchers that want to investigate search-based\nalgorithms in Python. The search methods provided by Mctx are\nheavily configurable to allow researchers to explore a variety of ideas in\nthis space, and contribute to the next generation of search based agents.\n\n## Search in Reinforcement Learning\n\nIn Reinforcement Learning the *agent* must learn to interact with the\n*environment* in order to maximize a scalar *reward* signal. On each step the\nagent must select an action and receives in exchange an observation and a\nreward. We may call whatever mechanism the agent uses to select the action the\nagent's *policy*.\n\nClassically, policies are parameterized directly by a function approximator (as\nin REINFORCE), or policies are inferred by inspecting a set of learned estimates\nof the value of each action (as in Q-learning). Alternatively, search allows to\nselect actions by constructing on the fly, in each state, a policy or a value\nfunction local to the current state, by *searching* using a learned *model* of\nthe environment.\n\nExhaustive search over all possible future courses of actions is computationally\nprohibitive in any non trivial environment, hence we need search algorithms\nthat can make the best use of a finite computational budget. Typically priors\nare needed to guide which nodes in the search tree to expand (to reduce the\n*breadth* of the tree that we construct), and value functions are used to\nestimate the value of incomplete paths in the tree that don't reach an episode\ntermination (to reduce the *depth* of the search tree).\n\n## Quickstart\n\nMctx provides a low-level generic `search` function and high-level concrete\npolicies: `muzero_policy` and `gumbel_muzero_policy`.\n\nThe user needs to provide several learned components to specify the\nrepresentation, dynamics and prediction used by [MuZero](https://deepmind.com/blog/article/muzero-mastering-go-chess-shogi-and-atari-without-rules).\nIn the context of the Mctx library, the representation of the *root* state is\nspecified by a `RootFnOutput`. The `RootFnOutput` contains the `prior_logits`\nfrom a policy network, the estimated `value` of the root state, and any\n`embedding` suitable to represent the root state for the environment model.\n\nThe dynamics environment model needs to be specified by a `recurrent_fn`.\nA `recurrent_fn(params, rng_key, action, embedding)` call takes an `action` and\na state `embedding`. The call should return a tuple `(recurrent_fn_output,\nnew_embedding)` with a `RecurrentFnOutput` and the embedding of the next state.\nThe `RecurrentFnOutput` contains the `reward` and `discount` for the transition,\nand `prior_logits` and `value` for the new state.\n\nIn [examples/visualization_demo.py](https://github.com/deepmind/mctx/blob/main/examples/visualization_demo.py)\nyou can see calls to a policy:\n\n```python\npolicy_output = mctx.gumbel_muzero_policy(params, rng_key, root, recurrent_fn,\n                                          num_simulations=32)\n```\n\nThe `policy_output.action` contains the action proposed by the search. That\naction can be passed to the environment. To improve the policy, the\n`policy_output.action_weights` contain targets usable to train the policy\nprobabilities.\n\nWe recommend to use the `gumbel_muzero_policy`.\n[Gumbel MuZero](https://openreview.net/forum?id=bERaNdoegnO) guarantees a policy\nimprovement if the action values are correctly evaluated. The policy improvement\nis demonstrated in\n[examples/policy_improvement_demo.py](https://github.com/deepmind/mctx/blob/main/examples/policy_improvement_demo.py).\n\n### Example projects\nThe following projects demonstrate the Mctx usage:\n\n- [Basic Learning Demo with Mctx](https://github.com/kenjyoung/mctx_learning_demo)\n... AlphaZero on random mazes.\n- [a0-jax](https://github.com/NTT123/a0-jax) ... AlphaZero on Connect Four,\nGomoku, and Go.\n\nTell us about your project.\n\n## Citing Mctx\n\nThis is not an officially supported Google product. Mctx is part of the\n[DeepMind JAX Ecosystem], to cite Mctx please use the [DeepMind JAX Ecosystem\ncitation].\n\n[DeepMind JAX Ecosystem]: https://deepmind.com/blog/article/using-jax-to-accelerate-our-research \"DeepMind JAX Ecosystem\"\n[DeepMind JAX Ecosystem citation]: https://github.com/deepmind/jax/blob/main/deepmind2020jax.txt \"Citation\"\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/deepmind/mctx",
    "keywords": "jax planning reinforcement-learning python machine learning",
    "license": "Apache 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "mctx",
    "package_url": "https://pypi.org/project/mctx/",
    "platform": null,
    "project_url": "https://pypi.org/project/mctx/",
    "project_urls": {
      "Homepage": "https://github.com/deepmind/mctx"
    },
    "release_url": "https://pypi.org/project/mctx/0.0.2/",
    "requires_dist": [
      "chex (>=0.0.8)",
      "jax (>=0.1.55)",
      "jaxlib (>=0.1.37)"
    ],
    "requires_python": ">=3.7",
    "summary": "Monte Carlo tree search in JAX.",
    "version": "0.0.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14551628,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "abdafa66692d7044d53da54218da49bdbc459f8d179a3a23afaef524aa3b12d4",
          "md5": "9a78f9fac3e41d905043b62f6a376032",
          "sha256": "bea882b5e1eccd888a8495e18f2b2931f9cbc8129fb48fbdac5d2ab62ff13cad"
        },
        "downloads": -1,
        "filename": "mctx-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "9a78f9fac3e41d905043b62f6a376032",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 40392,
        "upload_time": "2022-03-04T10:22:26",
        "upload_time_iso_8601": "2022-03-04T10:22:26.893542Z",
        "url": "https://files.pythonhosted.org/packages/ab/da/fa66692d7044d53da54218da49bdbc459f8d179a3a23afaef524aa3b12d4/mctx-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "60074aadc75d1355df24f8917f891aeba5e3682558dc2e80511f55fc49e1fa8f",
          "md5": "c5b1520e310c44526fcb23244ae2bee4",
          "sha256": "c71da7ea38f99e9c4be26a3271dad07fbf3768bd27fe3f0c2b4faa7a846e028f"
        },
        "downloads": -1,
        "filename": "mctx-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "c5b1520e310c44526fcb23244ae2bee4",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 31212,
        "upload_time": "2022-03-04T10:22:28",
        "upload_time_iso_8601": "2022-03-04T10:22:28.422774Z",
        "url": "https://files.pythonhosted.org/packages/60/07/4aadc75d1355df24f8917f891aeba5e3682558dc2e80511f55fc49e1fa8f/mctx-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a3e92219156402c74ec9d87ebbb820ea7eb412b24b0448db8d0030ad15490ecd",
          "md5": "081dcea13500eff21428b47cb1825597",
          "sha256": "d95362ee7b927c23a4bdf3a4ca8df3352d05db70a824f695e72f75da20a937c6"
        },
        "downloads": -1,
        "filename": "mctx-0.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "081dcea13500eff21428b47cb1825597",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 40912,
        "upload_time": "2022-07-26T10:19:23",
        "upload_time_iso_8601": "2022-07-26T10:19:23.387252Z",
        "url": "https://files.pythonhosted.org/packages/a3/e9/2219156402c74ec9d87ebbb820ea7eb412b24b0448db8d0030ad15490ecd/mctx-0.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e8d3226bc41548e81f88a9ca245a9ae2db4e8f86a35015fbe7d759aaabf25e3f",
          "md5": "1cf2c6e29025fcadf529af97ee29b324",
          "sha256": "fe62af2675f98e031f803d561aaffe141afbaf7244ee5c5831a5e128d9acd31b"
        },
        "downloads": -1,
        "filename": "mctx-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "1cf2c6e29025fcadf529af97ee29b324",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 31786,
        "upload_time": "2022-07-26T10:19:24",
        "upload_time_iso_8601": "2022-07-26T10:19:24.554620Z",
        "url": "https://files.pythonhosted.org/packages/e8/d3/226bc41548e81f88a9ca245a9ae2db4e8f86a35015fbe7d759aaabf25e3f/mctx-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "a3e92219156402c74ec9d87ebbb820ea7eb412b24b0448db8d0030ad15490ecd",
        "md5": "081dcea13500eff21428b47cb1825597",
        "sha256": "d95362ee7b927c23a4bdf3a4ca8df3352d05db70a824f695e72f75da20a937c6"
      },
      "downloads": -1,
      "filename": "mctx-0.0.2-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "081dcea13500eff21428b47cb1825597",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 40912,
      "upload_time": "2022-07-26T10:19:23",
      "upload_time_iso_8601": "2022-07-26T10:19:23.387252Z",
      "url": "https://files.pythonhosted.org/packages/a3/e9/2219156402c74ec9d87ebbb820ea7eb412b24b0448db8d0030ad15490ecd/mctx-0.0.2-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "e8d3226bc41548e81f88a9ca245a9ae2db4e8f86a35015fbe7d759aaabf25e3f",
        "md5": "1cf2c6e29025fcadf529af97ee29b324",
        "sha256": "fe62af2675f98e031f803d561aaffe141afbaf7244ee5c5831a5e128d9acd31b"
      },
      "downloads": -1,
      "filename": "mctx-0.0.2.tar.gz",
      "has_sig": false,
      "md5_digest": "1cf2c6e29025fcadf529af97ee29b324",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 31786,
      "upload_time": "2022-07-26T10:19:24",
      "upload_time_iso_8601": "2022-07-26T10:19:24.554620Z",
      "url": "https://files.pythonhosted.org/packages/e8/d3/226bc41548e81f88a9ca245a9ae2db4e8f86a35015fbe7d759aaabf25e3f/mctx-0.0.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}