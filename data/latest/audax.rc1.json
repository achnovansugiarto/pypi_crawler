{
  "info": {
    "author": "Sarthak Yadav",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# audax\n- [Sponsors](#sponsors)\n- [About](#about)\n- [Installation](#installation)\n- [Data pipeline](#data-pipeline)\n- [What's available](#whats-available)\n  - [Audio feature extraction](#audio-feature-extraction)\n  - [Network architectures](#network-architectures)\n  - [Learnable Frontends](#learnable-frontends)\n  - [Self-supervised models](#self-supervised-models)\n- [What's coming up](#whats-coming-up)\n- [On contributing](#on-contributing)\n- [References](#references)\n\n## Sponsors\nThis work would not be possible without cloud resources provided by Google's [TPU Research Cloud (TRC) program](https://sites.research.google/trc/about/). I also thank the TRC support team for quickly resolving whatever issues I had: you're awesome!\n\nWant to become a sponsor? Feel free to reach out!\n\n## About\nA home for audio ML in [JAX](https://jax.readthedocs.io/en/latest/). Has common features, popular learnable frontends, and pretrained supervised and self-supervised models.\nAs opposed to popular frameworks, the objective is not to become an end-to-end, end-all-be-all DL framework, but instead to act as a starting point for doing things the jax way, through reference implementations and recipes, using the [jax](https://jax.readthedocs.io/en/latest/) / [flax](https://flax.readthedocs.io/en/latest) / [optax](https://optax.readthedocs.io/en/latest/) stack.\n\n**PS:** I'm quite new to using Jax and it's functional-at-heart design, so I admit the code can be a bit untidy at places. \nExpect changes, restructuring, and like the official Jax repository itself says, sharp edges!\n\n## Installation\n\n```shell\npip install audax\n```\n\nTo install from the latest source use following command\n\n```shell\ngit clone https://github.com/SarthakYadav/audax.git\ncd audax\npip install -r requirements.txt\npip install .\n```\n\n## Data pipeline\n\n- All training is done on custom TFRecords. Initially tried using [tensorflow-datasets](https://www.tensorflow.org/datasets/api_docs/python/tfds), but decided against it.\n- tfrecords comprise of examples with audio file stored as an encoded `PCM_16` `flac` buffer, label info and duration, resulting in smaller `tfrecord` files and faster I/O as compared to storing audio as a sequence of floats. \n- A step-by-step guide to setup data can be found in the [recipes/data_prep](recipes/data_prep/README.md), including sample script to convert data into tfrecords.\n- More info could be found in [audax.training_utils.data_v2](audax/training_utils/data_v2)\n\n## What's available\n\n### Audio feature extraction\n\nAt the time of writing, `jax.signal` does not have a native Short-time Fourier Transform (`stft`) implementation.\n\nInstead of trying to emulate the `scipy.signal` implementation that has a lot more bells and whistles and is more feature packed,\nthe `stft` implementation in `audax.core` is designed such that it can be build upon to extract `spectrogram` and `melspectrogram` features \nas those found in [torchaudio](https://pytorch.org/audio/stable/functional.html), which are quite popular. \nThe result is a simple implementation of `stft`, `spectrogram` and `melspectrogram`, which are compatible with their torchaudio counterparts, as shown in the figure below.\n\n![audax_vs_torchaudio](misc_files/audax_vs_torchaudio.png)\n\nCurrently, `spectrogram` and `melspectrogram` features are supported. Visit [audax.core.readme](audax/core/README.md) for more info.\n\nApart from features, jax.vmap compatible [mixup](https://arxiv.org/abs/1710.09412) and [SpecAugment](https://arxiv.org/abs/1904.08779) (no TimeStretch as of now unfortunately) implementations are also provided. \n\n### Network architectures\nSeveral prominent neural network architecture reference implementations are provided, with more to come. The current release has:\n- [ResNets](audax/models/resnet.py) [1]\n- [EfficientNet](audax/models/efficientnet.py) [2]\n- [ConvNeXT](audax/models/convnext.py) [3]\n\nPretrained models can be found in respective [recipes](recipes), and expect more to be added soon.\n\n### Learnable frontends\nTwo popular learnable feature extraction frontends are available in [audax.frontends](audax/frontends) `LEAF` [4] and `SincNet` [5].\nSample recipes, as well as pretrained models ([AudioSet](https://research.google.com/audioset/) for now) can be found in the [recipes/leaf](recipes/leaf).\n\n### Self-supervised models\n- `COLA` [6] models on AudioSet for various aforementioned architectures can be found in [recipes/cola](recipes/cola). \n- A working implementation of `SimCLR` [7, 8] can be found in [recipes/simclr](recipes/simclr), and pretrained models will be added soon (experiments ongoing!).\n\n## What's coming up\n- Pretrained `COLA` models and linear probe experiments. (VERY SOON!)\n- Better documentation and walk-throughs.\n- Pretrained `SimCLR` models.\n- Recipes for Speaker Recognition on [VoxCeleb](https://www.robots.ox.ac.uk/~vgg/data/voxceleb/)\n- More `AudioSet` pretrained checkpoints for architectures already added.\n- Reference implementations for more neural architectures, esp. Transformer based networks.\n\n## On contributing\n- At the time of writing, I've been the sole person involved in development of this work, and quite frankly, would love to have help!\n- Happy to hear from open source contributore, both newbies and experienced, about their experience and needs\n- Always open to hearing about possible ways to clean up/better structure code.\n\n## References\n\n[1] He, K., Zhang, X., Ren, S. and Sun, J., 2016. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 770-778).  \n[2] Tan, M. and Le, Q., 2019, May. Efficientnet: Rethinking model scaling for convolutional neural networks. In International conference on machine learning (pp. 6105-6114). PMLR.    \n[3] Liu, Z., Mao, H., Wu, C.Y., Feichtenhofer, C., Darrell, T. and Xie, S., 2022. A ConvNet for the 2020s. arXiv preprint arXiv:2201.03545.  \n[4] Zeghidour, H., Teboul, O., Quitry, F., and Tagliasacchi, M., LEAF: A Learnable Frontend for Audio Classification, In International Conference on Learning Representations, 2021.  \n[5] Ravanelli, M. and Bengio, Y., 2018, December. Speaker recognition from raw waveform with sincnet. In 2018 IEEE Spoken Language Technology Workshop (SLT) (pp. 1021-1028). IEEE.  \n[6] Saeed, A., Grangier, D. and Zeghidour, N., 2021, June. Contrastive learning of general-purpose audio representations. In ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp. 3875-3879). IEEE.  \n[7] Chen, T., Kornblith, S., Norouzi, M. and Hinton, G., 2020, November. A simple framework for contrastive learning of visual representations. In International conference on machine learning (pp. 1597-1607). PMLR.    \n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/SarthakYadav/audio_data_utils",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "audax",
    "package_url": "https://pypi.org/project/audax/",
    "platform": "",
    "project_url": "https://pypi.org/project/audax/",
    "project_urls": {
      "Homepage": "https://github.com/SarthakYadav/audio_data_utils"
    },
    "release_url": "https://pypi.org/project/audax/0.0.3/",
    "requires_dist": null,
    "requires_python": ">=3.8",
    "summary": "audio ML for Jax",
    "version": "0.0.3",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 13029545,
  "releases": {
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5865af4aa52f8c50166c3229bf4562f8b8afe5a2ff2d24e660e4f7bba8e03478",
          "md5": "f7d82dcd6c4c18582c6ccb475e75df0d",
          "sha256": "fa033fc638e183216e94a0116160fd10492cd224d106fa1c8741ddab7c87f17d"
        },
        "downloads": -1,
        "filename": "audax-0.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f7d82dcd6c4c18582c6ccb475e75df0d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 56148,
        "upload_time": "2022-02-28T01:44:45",
        "upload_time_iso_8601": "2022-02-28T01:44:45.911878Z",
        "url": "https://files.pythonhosted.org/packages/58/65/af4aa52f8c50166c3229bf4562f8b8afe5a2ff2d24e660e4f7bba8e03478/audax-0.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "659699c7cb0401a25f103dde38d456e1ee8d40aad99c3249eda5a0d90fd10684",
          "md5": "f9da04806c24d86c2b4cf8f108d72385",
          "sha256": "569389e3346b8b8f871ecc03965bf5e57d55e251c25fb86ce5e3e4efd80031b1"
        },
        "downloads": -1,
        "filename": "audax-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "f9da04806c24d86c2b4cf8f108d72385",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 43034,
        "upload_time": "2022-02-28T01:44:47",
        "upload_time_iso_8601": "2022-02-28T01:44:47.369928Z",
        "url": "https://files.pythonhosted.org/packages/65/96/99c7cb0401a25f103dde38d456e1ee8d40aad99c3249eda5a0d90fd10684/audax-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "5865af4aa52f8c50166c3229bf4562f8b8afe5a2ff2d24e660e4f7bba8e03478",
        "md5": "f7d82dcd6c4c18582c6ccb475e75df0d",
        "sha256": "fa033fc638e183216e94a0116160fd10492cd224d106fa1c8741ddab7c87f17d"
      },
      "downloads": -1,
      "filename": "audax-0.0.3-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "f7d82dcd6c4c18582c6ccb475e75df0d",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.8",
      "size": 56148,
      "upload_time": "2022-02-28T01:44:45",
      "upload_time_iso_8601": "2022-02-28T01:44:45.911878Z",
      "url": "https://files.pythonhosted.org/packages/58/65/af4aa52f8c50166c3229bf4562f8b8afe5a2ff2d24e660e4f7bba8e03478/audax-0.0.3-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "659699c7cb0401a25f103dde38d456e1ee8d40aad99c3249eda5a0d90fd10684",
        "md5": "f9da04806c24d86c2b4cf8f108d72385",
        "sha256": "569389e3346b8b8f871ecc03965bf5e57d55e251c25fb86ce5e3e4efd80031b1"
      },
      "downloads": -1,
      "filename": "audax-0.0.3.tar.gz",
      "has_sig": false,
      "md5_digest": "f9da04806c24d86c2b4cf8f108d72385",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.8",
      "size": 43034,
      "upload_time": "2022-02-28T01:44:47",
      "upload_time_iso_8601": "2022-02-28T01:44:47.369928Z",
      "url": "https://files.pythonhosted.org/packages/65/96/99c7cb0401a25f103dde38d456e1ee8d40aad99c3249eda5a0d90fd10684/audax-0.0.3.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}