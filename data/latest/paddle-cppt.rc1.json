{
  "info": {
    "author": "Jingjing WU (吴京京)",
    "author_email": "wjmcater@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3.7"
    ],
    "description": "# paddle-cppt\n\n<div align=\"center\">\nConvert Pytorch to Paddle Toolkit\n</div>\n\n<div align=\"center\">\n\n[![wj-Mcat - paddle-cppt](https://img.shields.io/static/v1?label=wj-Mcat&message=paddle-cppt&color=blue&logo=github)](https://github.com/wj-Mcat/paddle-cppt \"Go to GitHub repo\")\n[![stars - paddle-cppt](https://img.shields.io/github/stars/wj-Mcat/paddle-cppt?style=social)](https://github.com/wj-Mcat/paddle-cppt)\n[![forks - paddle-cppt](https://img.shields.io/github/forks/wj-Mcat/paddle-cppt?style=social)](https://github.com/wj-Mcat/paddle-cppt)\n[![pypi](https://github.com/wj-Mcat/paddle-cppt/workflows/pypi/badge.svg)](https://github.com/wj-Mcat/paddle-cppt/actions?query=workflow:\"pypi\")\n[![GitHub release](https://img.shields.io/github/release/wj-Mcat/paddle-cppt?include_prereleases=&sort=semver&color=blue)](https://github.com/wj-Mcat/paddle-cppt/releases/)\n[![License](https://img.shields.io/badge/License-Apache_License_2.0-blue)](#license)\n[![issues - paddle-cppt](https://img.shields.io/github/issues/wj-Mcat/paddle-cppt)](https://github.com/wj-Mcat/paddle-cppt/issues)\n\n\n</div>\n\n\nThis Repo contains the toolkit that help you transform the pytorch model to paddle model. eg: Weight file Comparer, Weight Converter, Weight Summary, and so on ...\n\n## Features\n\n* `cppt gen_diff`: generate the diff between paddle weight and torch weight file, for more details you check out ...\n* `cppt auto_match`: auto match the names of paddle and torch occording to the name semantic, eg: torch.model.embeddings.embed_token.weight -> paddle.opt.model.word_embeddings.weight ...\n* `cppt convert`: convert the torch weight file to paddle weight file according to the diff file ...\n* `cppt summary`: summary the tensor meta info according to the weight files and diff file ...\n\n## Intro\n\nIn order to convert pytorch weight file to paddle weight file and make sure that the logits of paddle model is absolute align with pytorch, there are some steps you should follow.\n\n* first, you should get the layer names of you paddle model. In this abastract, you can init the paddle model with the same configuration as pytorch model, and save the state_dict.\n* second, in order to convert pytorch weight file to paddle weight file, you should find the name mapping between weight files, so you can load the state dict of paddle weight and pytorch weight file and find the diffs. In this abstract, you can use the command `cppt gen_diff` to find the diffs between layer names. \n* third, mapping the names between pytorch and paddle models is a boring work, so let's make it more intelligent. You can use `cppt auto_match` command to auto match the names with similarity algo. you can edit the final diff file, and make it correct. \n* fourth, you get the correct name mapping with third step, you can use the `cppt convert` command to convet the pytorch weight file to paddle weight file. In this abstract, the script will automaticly transpose the linear-weight tensor.\n* finaly, in order to checking the tensor data of paddle weight file, you can use the command `cppt summary` the generate the meta info between paddle weight file.\n\nSo, it's cool right ? these codes help me `converting` work more soft.\n\nBut, there are also some great works can be done:\n\n- [ ] compare the computing gragh between pytorch and paddle code. \n- [ ] compare the outputs of different layers, eg: embedding layer, transformer layer, lm_head layer and so on. \n- [ ] convert the pytorch code to paddle code using the ast. Objecoive： We can't convert it and make it run at onece, but you can convert it and edit it with simple works to make it run. \n\nIf you have more ideas about it, you can post [issue](https://github.com/wj-Mcat/paddle-cppt/issues/new) to discuss with us. We look forward to discussing it with you. \n\n## Quick Start\n\n### Installation\n\n```shell\npip install paddle-cppt\n```\n\nor install from the source code:\n\n```shell\ngit clone https://github.com/wj-Mcat/paddle-cppt\ncd paddle-cpp\npython setup.py install\n```\n\n### save paddle state dict\n\nIf you complete the code, you can init the paddle weight file with the following code:\n\n```python\nfrom paddlenlp.transformers.{your-model}.modeling import {YourModel}\n\n# this code will be different according to different model, but anyway the final result is to save the state dict of model which contains the layer names of your model code.\nmodel = {YourModel}(\n    model={YourModel}(\n        **{YourModel}.pretrained_init_configuration['{name-of-configuration}']\n    )\n)\nmodel.save_pretrained('/path/to/local/dir')\n```\n\n### cppt gen_diff\n\nthis command will generate the name mapping \n\n```shell\ncppt gen_diff \\\n    --torch_file=/path/to/pytorch_model.bin \\\n    --paddle_file=/path/to/model_state.pdparams \\\n    --output_file=/path/to/diff.xlsx --auto_match\n```\nwith this command, you will get the `diff.xlsx` file which contains the layer name of paddle/torch weight file, eg: \n\n|                     torch-name                    |  torch-shape |  torch-dtype  |   torch-type  |                 paddle-name                | paddle-shape |  paddle-dtype  |  paddle-type  |\n|:-------------------------------------------------:|:------------:|:-------------:|:-------------:|:------------------------------------------:|:------------:|:--------------:|:-------------:|\n| embeddings.position_ids                           | [1, 512]     | torch.int64   | embedding     | embeddings.word_embeddings.weight          | [30522, 768] | paddle.float32 | embedding     |\n| embeddings.word_embeddings.weight                 | [30522, 768] | torch.float32 | embedding     | embeddings.position_embeddings.weight      | [512, 768]   | paddle.float32 | embedding     |\n| embeddings.position_embeddings.weight             | [512, 768]   | torch.float32 | embedding     | embeddings.token_type_embeddings.weight    | [2, 768]     | paddle.float32 | embedding     |\n| embeddings.token_type_embeddings.weight           | [2, 768]     | torch.float32 | embedding     | embeddings.layer_norm.weight               | [768]        | paddle.float32 | embedding     |\n| embeddings.LayerNorm.weight                       | [768]        | torch.float32 | embedding     | embeddings.layer_norm.bias                 | [768]        | paddle.float32 | embedding     |\n| embeddings.LayerNorm.bias                         | [768]        | torch.float32 | embedding     | encoder.layers.0.self_attn.q_proj.weight   | [768, 768]   | paddle.float32 | linear-weight |\n| encoder.layer.0.attention.self.query.weight       | [768, 768]   | torch.float32 | linear-weight | encoder.layers.0.self_attn.q_proj.bias     | [768]        | paddle.float32 | linear-bias   |\n| encoder.layer.0.attention.self.query.bias         | [768]        | torch.float32 | linear-bias   | encoder.layers.0.self_attn.k_proj.weight   | [768, 768]   | paddle.float32 | linear-weight |\n| encoder.layer.0.attention.self.key.weight         | [768, 768]   | torch.float32 | linear-weight | encoder.layers.0.self_attn.k_proj.bias     | [768]        | paddle.float32 | linear-bias   |\n| encoder.layer.0.attention.self.key.bias           | [768]        | torch.float32 | linear-bias   | encoder.layers.0.self_attn.v_proj.weight   | [768, 768]   | paddle.float32 | linear-weight |\n| encoder.layer.0.attention.self.value.weight       | [768, 768]   | torch.float32 | linear-weight | encoder.layers.0.self_attn.v_proj.bias     | [768]        | paddle.float32 | linear-bias   |\n| encoder.layer.0.attention.self.value.bias         | [768]        | torch.float32 | linear-bias   | encoder.layers.0.self_attn.out_proj.weight | [768, 768]   | paddle.float32 | linear-weight |\n| encoder.layer.0.attention.output.dense.weight     | [768, 768]   | torch.float32 | linear-weight | encoder.layers.0.self_attn.out_proj.bias   | [768]        | paddle.float32 | linear-bias   |\n| encoder.layer.0.attention.output.dense.bias       | [768]        | torch.float32 | linear-bias   | encoder.layers.0.linear1.weight            | [768, 3072]  | paddle.float32 | linear-weight |\n| encoder.layer.0.attention.output.LayerNorm.weight | [768]        | torch.float32 | norm          | encoder.layers.0.linear1.bias              | [3072]       | paddle.float32 | linear-bias   |\n\n\n## cppt auto_match\n\nthis command will generate the final name mapping into the excel file.\n\n```shell\ncppt auto_match \\\n    --diff_file=/path/to/diff.xlsx \\\n    --output_file=/path/to/diff-result.xlsx\n```\n\n## cppt convert\n\nconvert torch model to paddle weight according the final diff file.\n\n```shell\ncppt convert \\\n    --torch_file=/path/to/pytorch_model.bin \\\n    --output_file=/path/to/model_state.pdparams \\\n    --diff_file=/path/to/diff-result.xlsx\n```\n\n## cppt summary\n\nprint the summary metadata info between torch and paddle model\n\n```shell\ncppt summary \\\n    --torch_file=/path/to/pytorch_model.bin \\\n    --output_file=/path/to/model_state.pdparams \\\n    --diff_file=/path/to/diff.xlsx\n```\n\n## Creators\n\n\n[![wj-Mcat - paddle-cppt](https://img.shields.io/static/v1?label=wj-Mcat&message=paddle-cppt&color=blue&logo=github)](https://github.com/wj-Mcat/paddle-cppt \"Go to GitHub repo\")\n\n\n## License\n\nReleased under [Apache License 2.0](/LICENSE) by [@wj-Mcat](https://github.com/wj-Mcat).\n\n## Copyright & License\n\n- Code & Docs © 2022 wj-Mcat <wjmcater@gmail.com>\n- Code released under the Apache-2.0 License\n- Docs released under Creative Commons\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/wj-Mcat/paddle-cppt",
    "keywords": "",
    "license": "Apache-2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "paddle-cppt",
    "package_url": "https://pypi.org/project/paddle-cppt/",
    "platform": null,
    "project_url": "https://pypi.org/project/paddle-cppt/",
    "project_urls": {
      "Homepage": "https://github.com/wj-Mcat/paddle-cppt"
    },
    "release_url": "https://pypi.org/project/paddle-cppt/0.0.1/",
    "requires_dist": [
      "dataclasses-json",
      "tabulate"
    ],
    "requires_python": "",
    "summary": "",
    "version": "0.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14330607,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "76d3e87399b7a38a84b61e2688302220d0f7f0bfe511c11e657621ed1227e921",
          "md5": "0b901335504534abf11e185736e9d67b",
          "sha256": "f685f756fb3963220944b31fdfbe6288ddde3eb98f2e72b79045cd19d0aa9bba"
        },
        "downloads": -1,
        "filename": "paddle_cppt-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0b901335504534abf11e185736e9d67b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 15088,
        "upload_time": "2022-07-04T13:32:07",
        "upload_time_iso_8601": "2022-07-04T13:32:07.798137Z",
        "url": "https://files.pythonhosted.org/packages/76/d3/e87399b7a38a84b61e2688302220d0f7f0bfe511c11e657621ed1227e921/paddle_cppt-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9f710d221907b12c37bccc49eaa4f677cbb83e1eef58abb1b76ca3e697b46609",
          "md5": "77b5446b8c26c0b5d928d6f0fa76468f",
          "sha256": "d479aaad4b860b18414306fc16ec6da7b35ad77bbd0b65d83fc8ddd5d83570b4"
        },
        "downloads": -1,
        "filename": "paddle-cppt-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "77b5446b8c26c0b5d928d6f0fa76468f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 17461,
        "upload_time": "2022-07-04T13:32:09",
        "upload_time_iso_8601": "2022-07-04T13:32:09.807621Z",
        "url": "https://files.pythonhosted.org/packages/9f/71/0d221907b12c37bccc49eaa4f677cbb83e1eef58abb1b76ca3e697b46609/paddle-cppt-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "76d3e87399b7a38a84b61e2688302220d0f7f0bfe511c11e657621ed1227e921",
        "md5": "0b901335504534abf11e185736e9d67b",
        "sha256": "f685f756fb3963220944b31fdfbe6288ddde3eb98f2e72b79045cd19d0aa9bba"
      },
      "downloads": -1,
      "filename": "paddle_cppt-0.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "0b901335504534abf11e185736e9d67b",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 15088,
      "upload_time": "2022-07-04T13:32:07",
      "upload_time_iso_8601": "2022-07-04T13:32:07.798137Z",
      "url": "https://files.pythonhosted.org/packages/76/d3/e87399b7a38a84b61e2688302220d0f7f0bfe511c11e657621ed1227e921/paddle_cppt-0.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "9f710d221907b12c37bccc49eaa4f677cbb83e1eef58abb1b76ca3e697b46609",
        "md5": "77b5446b8c26c0b5d928d6f0fa76468f",
        "sha256": "d479aaad4b860b18414306fc16ec6da7b35ad77bbd0b65d83fc8ddd5d83570b4"
      },
      "downloads": -1,
      "filename": "paddle-cppt-0.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "77b5446b8c26c0b5d928d6f0fa76468f",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 17461,
      "upload_time": "2022-07-04T13:32:09",
      "upload_time_iso_8601": "2022-07-04T13:32:09.807621Z",
      "url": "https://files.pythonhosted.org/packages/9f/71/0d221907b12c37bccc49eaa4f677cbb83e1eef58abb1b76ca3e697b46609/paddle-cppt-0.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}