{
  "info": {
    "author": "Patrick Lehmann",
    "author_email": "Paebbels@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3 :: Only",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Topic :: Utilities"
    ],
    "description": "[![Sourcecode on GitHub](https://img.shields.io/badge/Paebbels-pyTokenizer-323131.svg?logo=github&longCache=true)](https://github.com/Paebbels/pyTokenizer)\n[![License](https://img.shields.io/badge/code%20license-Apache%20License%2C%202.0-lightgrey?logo=GitHub)](LICENSE.md)\n[![GitHub tag (latest SemVer incl. pre-release)](https://img.shields.io/github/v/tag/Paebbels/pyTokenizer?logo=GitHub&include_prereleases)](https://github.com/Paebbels/pyTokenizer/tags)\n[![GitHub release (latest SemVer incl. including pre-releases)](https://img.shields.io/github/v/release/Paebbels/pyTokenizer?logo=GitHub&include_prereleases)](https://github.com/Paebbels/pyTokenizer/releases/latest)\n[![GitHub release date](https://img.shields.io/github/release-date/Paebbels/pyTokenizer?logo=GitHub&)](https://github.com/Paebbels/pyTokenizer/releases)  \n[![GitHub Workflow Status](https://img.shields.io/github/workflow/status/Paebbels/pyTokenizer/Test,%20Coverage%20and%20Release?label=Workflow&logo=GitHub)](https://github.com/Paebbels/pyTokenizer/actions?query=workflow%3A%22Test%2C+Coverage+and+Release%22)\n[![PyPI](https://img.shields.io/pypi/v/pyTokenizer?logo=PyPI)](https://pypi.org/project/pyTokenizer/)\n![PyPI - Status](https://img.shields.io/pypi/status/pyTokenizer?logo=PyPI)\n![PyPI - Python Version](https://img.shields.io/pypi/pyversions/pyTokenizer?logo=PyPI)\n[![Dependent repos (via libraries.io)](https://img.shields.io/librariesio/dependent-repos/pypi/pyTokenizer)](https://github.com/Paebbels/pyTokenizer/network/dependents)  \n[![Libraries.io status for latest release](https://img.shields.io/librariesio/release/pypi/pyTokenizer)](https://libraries.io/github/Paebbels/pyTokenizer)\n[![Requires.io](https://img.shields.io/requires/github/Paebbels/pyTokenizer)](https://requires.io/github/Paebbels/pyTokenizer/requirements/?branch=master)  \n[![Codacy - Quality](https://img.shields.io/codacy/grade/7ea6c9eea5b94493837ea55c07de3562?logo=Codacy)](https://www.codacy.com/manual/Paebbels/pyTokenizer)\n[![Codacy - Coverage](https://img.shields.io/codacy/coverage/7ea6c9eea5b94493837ea55c07de3562?logo=Codacy)](https://www.codacy.com/manual/Paebbels/pyTokenizer)\n[![Codecov - Branch Coverage](https://img.shields.io/codecov/c/github/Paebbels/pyTokenizer?logo=Codecov)](https://codecov.io/gh/Paebbels/pyTokenizer)\n[![Libraries.io SourceRank](https://img.shields.io/librariesio/sourcerank/pypi/pyTokenizer)](https://libraries.io/github/Paebbels/pyTokenizer/sourcerank)  \n[![Read the Docs](https://img.shields.io/readthedocs/pytokenizer)](https://pyTokenizer.readthedocs.io/en/latest/)\n\n# pyTokenizer\n\nA streaming tokenizer.\n\n\n## Contributors\n\n* [Patrick Lehmann](https://github.com/Paebbels) (Maintainer)\n\n\n## License\n\nThis Python package (source code) is licensed under [Apache License 2.0](LICENSE.md).\n\n<!-- The accompanying documentation is licensed under Creative Commons - Attribution-4.0 (CC-BY 4.0). -->\n\n-------------------------\n\nSPDX-License-Identifier: Apache-2.0\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/Paebbels/pyTokenizer",
    "keywords": "Python3 Token Tokenizer Streaming",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "pyTokenizer",
    "package_url": "https://pypi.org/project/pyTokenizer/",
    "platform": "",
    "project_url": "https://pypi.org/project/pyTokenizer/",
    "project_urls": {
      "Documentation": "https://pyTokenizer.readthedocs.io/en/latest/",
      "Homepage": "https://github.com/Paebbels/pyTokenizer",
      "Issue Tracker": "https://github.com/Paebbels/pyTokenizer/issues",
      "Source Code": "https://github.com/Paebbels/pyTokenizer"
    },
    "release_url": "https://pypi.org/project/pyTokenizer/1.1.4/",
    "requires_dist": null,
    "requires_python": ">=3.5",
    "summary": "A streaming tokenizer.",
    "version": "1.1.4",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8126164,
  "releases": {
    "0.1.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d9e19af20afe462a6fb06d3b1c843b9e683d08e544c42613cf3d6f4d9345f120",
          "md5": "fe86374d109f9104da264c50e6c3806b",
          "sha256": "bb4509feabca85867d6f7eafa74216b6a9b6c693dc8c69ede34d0a9df687d1e5"
        },
        "downloads": -1,
        "filename": "pyTokenizer-0.1.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "fe86374d109f9104da264c50e6c3806b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.5",
        "size": 8175,
        "upload_time": "2019-10-13T04:18:32",
        "upload_time_iso_8601": "2019-10-13T04:18:32.526118Z",
        "url": "https://files.pythonhosted.org/packages/d9/e1/9af20afe462a6fb06d3b1c843b9e683d08e544c42613cf3d6f4d9345f120/pyTokenizer-0.1.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d94a16b81038e1fd332a330ffb73a78af369000651742c2e8b4772293af7ed83",
          "md5": "a93612945512f9dbdab28b7a86e1e795",
          "sha256": "d5cd368a4cc9513a870558a0937a66250adbb86406b68933979829160b5da4ee"
        },
        "downloads": -1,
        "filename": "pyTokenizer-0.1.3.tar.gz",
        "has_sig": false,
        "md5_digest": "a93612945512f9dbdab28b7a86e1e795",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 4086,
        "upload_time": "2019-10-13T04:18:35",
        "upload_time_iso_8601": "2019-10-13T04:18:35.098900Z",
        "url": "https://files.pythonhosted.org/packages/d9/4a/16b81038e1fd332a330ffb73a78af369000651742c2e8b4772293af7ed83/pyTokenizer-0.1.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1a7f06ff34a034938510f6c8a295bdf65947ada51ef2298652d3e36941967483",
          "md5": "625b9e0c952cc7c66bbcc6c5157d173b",
          "sha256": "a8ba0bb856a525dbbbfccfb363422db178bf23d14a171d3d6bc86c9f95946154"
        },
        "downloads": -1,
        "filename": "pyTokenizer-1.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "625b9e0c952cc7c66bbcc6c5157d173b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.5",
        "size": 8175,
        "upload_time": "2019-10-13T04:19:55",
        "upload_time_iso_8601": "2019-10-13T04:19:55.606481Z",
        "url": "https://files.pythonhosted.org/packages/1a/7f/06ff34a034938510f6c8a295bdf65947ada51ef2298652d3e36941967483/pyTokenizer-1.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "afea0855b8df88f6c7d0e7a81133a6ac969f893c21b5f175e150ceb8fd8987c6",
          "md5": "586c63e8b52deff8e109f2369974cf13",
          "sha256": "27bfed3aa9e4bc501225d64103bf0582c3b5e3c84ea02b0306cd18b7ae893e5e"
        },
        "downloads": -1,
        "filename": "pyTokenizer-1.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "586c63e8b52deff8e109f2369974cf13",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 4096,
        "upload_time": "2019-10-13T04:19:58",
        "upload_time_iso_8601": "2019-10-13T04:19:58.078797Z",
        "url": "https://files.pythonhosted.org/packages/af/ea/0855b8df88f6c7d0e7a81133a6ac969f893c21b5f175e150ceb8fd8987c6/pyTokenizer-1.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a82e1bbef671260f327e464e22ee3ddfdc9de1465947bb7e771c71c9e8695dd1",
          "md5": "c6caa5f2f13fa570e85f36312b9b89b9",
          "sha256": "16b1831af36e7c2bf1d1f29bf9455afe0f4dda01dcf489d7347fadf2c233e31c"
        },
        "downloads": -1,
        "filename": "pyTokenizer-1.1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "c6caa5f2f13fa570e85f36312b9b89b9",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.5",
        "size": 8138,
        "upload_time": "2019-10-13T04:37:38",
        "upload_time_iso_8601": "2019-10-13T04:37:38.027394Z",
        "url": "https://files.pythonhosted.org/packages/a8/2e/1bbef671260f327e464e22ee3ddfdc9de1465947bb7e771c71c9e8695dd1/pyTokenizer-1.1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "82edfc340f7c35703a7733d43a8e6e782526d353a22176763b5b63bd8be40c6f",
          "md5": "f01f014f0ee64efec7d98fc86fcc79da",
          "sha256": "8b82f83ed01f2ab81eebcee1ee8d40c0c7c67e8270d026de05b19596da1b26d6"
        },
        "downloads": -1,
        "filename": "pyTokenizer-1.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "f01f014f0ee64efec7d98fc86fcc79da",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 4064,
        "upload_time": "2019-10-13T04:37:39",
        "upload_time_iso_8601": "2019-10-13T04:37:39.688874Z",
        "url": "https://files.pythonhosted.org/packages/82/ed/fc340f7c35703a7733d43a8e6e782526d353a22176763b5b63bd8be40c6f/pyTokenizer-1.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9b212e92ee3b5e26b39a2a400e8319c07c3a8df861d10ba1da32184bae7db95d",
          "md5": "f5643babd3a7a60597e717b5a1c96762",
          "sha256": "44c9bc63f482ebec8768a8d0c58cb9fc2099f8c2a1f8dd354373b2b5e699391f"
        },
        "downloads": -1,
        "filename": "pyTokenizer-1.1.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f5643babd3a7a60597e717b5a1c96762",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.5",
        "size": 8308,
        "upload_time": "2019-12-25T17:03:32",
        "upload_time_iso_8601": "2019-12-25T17:03:32.379630Z",
        "url": "https://files.pythonhosted.org/packages/9b/21/2e92ee3b5e26b39a2a400e8319c07c3a8df861d10ba1da32184bae7db95d/pyTokenizer-1.1.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a99856f61ed9d9e1c0116c4bc33ff3e5a496a0b99483c784b49b037427d0d0a1",
          "md5": "19a7f6c5a3068ae6f2b41055462055b4",
          "sha256": "4671801a957f17884cb75feef2defdd81367ad162b8e33205123924784b4e89c"
        },
        "downloads": -1,
        "filename": "pyTokenizer-1.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "19a7f6c5a3068ae6f2b41055462055b4",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 4222,
        "upload_time": "2019-12-25T17:03:33",
        "upload_time_iso_8601": "2019-12-25T17:03:33.545878Z",
        "url": "https://files.pythonhosted.org/packages/a9/98/56f61ed9d9e1c0116c4bc33ff3e5a496a0b99483c784b49b037427d0d0a1/pyTokenizer-1.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "46dd82ea601bb1a766fd35c52d1991531cec721b582416e3096b9cc2da1ca643",
          "md5": "9765e14abef031ddb99aff8327eb8ce4",
          "sha256": "b055945bc2535d6e7609f6b554f223a2d7ee52767d3d1797b3e7546f1345936c"
        },
        "downloads": -1,
        "filename": "pyTokenizer-1.1.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "9765e14abef031ddb99aff8327eb8ce4",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.5",
        "size": 8596,
        "upload_time": "2019-12-27T21:16:12",
        "upload_time_iso_8601": "2019-12-27T21:16:12.774981Z",
        "url": "https://files.pythonhosted.org/packages/46/dd/82ea601bb1a766fd35c52d1991531cec721b582416e3096b9cc2da1ca643/pyTokenizer-1.1.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "35eebd194f2c1ddc21de78b1e0304f43ed1b8ab9c214734ab785d8e39fa27dbb",
          "md5": "0681c727c1eb7e3e5f6fbe3edd123c22",
          "sha256": "8fe6f8ec566d5c9c66d92726184c6f53480653d9f6cba4213badfbae5072103c"
        },
        "downloads": -1,
        "filename": "pyTokenizer-1.1.3.tar.gz",
        "has_sig": false,
        "md5_digest": "0681c727c1eb7e3e5f6fbe3edd123c22",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 4567,
        "upload_time": "2019-12-27T21:16:13",
        "upload_time_iso_8601": "2019-12-27T21:16:13.822044Z",
        "url": "https://files.pythonhosted.org/packages/35/ee/bd194f2c1ddc21de78b1e0304f43ed1b8ab9c214734ab785d8e39fa27dbb/pyTokenizer-1.1.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "97588b6d3189bd4c10d1092763f53ed42bdba1bfea6374f5e66dd376d21cf7ed",
          "md5": "2bd4c84e30a98597b5d87ead2128075b",
          "sha256": "117de4342add39128cd38202f4af098ef6ee1938e6a7fd749f27093e6d23daca"
        },
        "downloads": -1,
        "filename": "pyTokenizer-1.1.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "2bd4c84e30a98597b5d87ead2128075b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.5",
        "size": 8972,
        "upload_time": "2020-09-06T20:58:15",
        "upload_time_iso_8601": "2020-09-06T20:58:15.249857Z",
        "url": "https://files.pythonhosted.org/packages/97/58/8b6d3189bd4c10d1092763f53ed42bdba1bfea6374f5e66dd376d21cf7ed/pyTokenizer-1.1.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c0a631c06100242c4bbc1e6e68248e1df76d9eab16524b48d9b8550405054ddf",
          "md5": "7baf37af5630aebe731140a26960bf40",
          "sha256": "d31e6e01730faae89383f32a0a4e497fb29955b291b941c556d92d43c110fd6c"
        },
        "downloads": -1,
        "filename": "pyTokenizer-1.1.4.tar.gz",
        "has_sig": false,
        "md5_digest": "7baf37af5630aebe731140a26960bf40",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 5158,
        "upload_time": "2020-09-06T20:58:16",
        "upload_time_iso_8601": "2020-09-06T20:58:16.215417Z",
        "url": "https://files.pythonhosted.org/packages/c0/a6/31c06100242c4bbc1e6e68248e1df76d9eab16524b48d9b8550405054ddf/pyTokenizer-1.1.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "97588b6d3189bd4c10d1092763f53ed42bdba1bfea6374f5e66dd376d21cf7ed",
        "md5": "2bd4c84e30a98597b5d87ead2128075b",
        "sha256": "117de4342add39128cd38202f4af098ef6ee1938e6a7fd749f27093e6d23daca"
      },
      "downloads": -1,
      "filename": "pyTokenizer-1.1.4-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "2bd4c84e30a98597b5d87ead2128075b",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.5",
      "size": 8972,
      "upload_time": "2020-09-06T20:58:15",
      "upload_time_iso_8601": "2020-09-06T20:58:15.249857Z",
      "url": "https://files.pythonhosted.org/packages/97/58/8b6d3189bd4c10d1092763f53ed42bdba1bfea6374f5e66dd376d21cf7ed/pyTokenizer-1.1.4-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "c0a631c06100242c4bbc1e6e68248e1df76d9eab16524b48d9b8550405054ddf",
        "md5": "7baf37af5630aebe731140a26960bf40",
        "sha256": "d31e6e01730faae89383f32a0a4e497fb29955b291b941c556d92d43c110fd6c"
      },
      "downloads": -1,
      "filename": "pyTokenizer-1.1.4.tar.gz",
      "has_sig": false,
      "md5_digest": "7baf37af5630aebe731140a26960bf40",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.5",
      "size": 5158,
      "upload_time": "2020-09-06T20:58:16",
      "upload_time_iso_8601": "2020-09-06T20:58:16.215417Z",
      "url": "https://files.pythonhosted.org/packages/c0/a6/31c06100242c4bbc1e6e68248e1df76d9eab16524b48d9b8550405054ddf/pyTokenizer-1.1.4.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}