{
  "info": {
    "author": "Jonas Pfeiffer, Andreas RÃ¼cklÃ©, Clifton Poth, Hannah Sterz, based on work by the HuggingFace team and community",
    "author_email": "pfeiffer@ukp.tu-darmstadt.de",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Intended Audience :: Developers",
      "Intended Audience :: Education",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Topic :: Scientific/Engineering :: Artificial Intelligence"
    ],
    "description": "<!---\nCopyright 2020 The AdapterHub Team. All rights reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n-->\n\n<p align=\"center\">\n<img style=\"vertical-align:middle\" src=\"https://raw.githubusercontent.com/Adapter-Hub/adapter-transformers/master/adapter_docs/logo.png\" />\n</p>\n<h1 align=\"center\">\n<span>adapter-transformers</span>\n</h1>\n\n<h3 align=\"center\">\nA friendly fork of HuggingFace's <i>Transformers</i>, adding Adapters to PyTorch language models\n</h3>\n\n![Tests](https://github.com/Adapter-Hub/adapter-transformers/workflows/Tests/badge.svg)\n[![GitHub](https://img.shields.io/github/license/adapter-hub/adapter-transformers.svg?color=blue)](https://github.com/adapter-hub/adapter-transformers/blob/master/LICENSE)\n[![PyPI](https://img.shields.io/pypi/v/adapter-transformers)](https://pypi.org/project/adapter-transformers/)\n\n`adapter-transformers` is an extension of [HuggingFace's Transformers](https://github.com/huggingface/transformers) library, integrating adapters into state-of-the-art language models by incorporating **[AdapterHub](https://adapterhub.ml)**, a central repository for pre-trained adapter modules.\n\n_ðŸ’¡ Important: This library can be used as a drop-in replacement for HuggingFace Transformers and regularly synchronizes new upstream changes.\nThus, most files in this repository are direct copies from the HuggingFace Transformers source, modified only with changes required for the adapter implementations._\n\n## Installation\n\n`adapter-transformers` currently supports **Python 3.7+** and **PyTorch 1.3.1+**.\nAfter [installing PyTorch](https://pytorch.org/get-started/locally/), you can install `adapter-transformers` from PyPI ...\n\n```\npip install -U adapter-transformers\n```\n\n... or from source by cloning the repository:\n\n```\ngit clone https://github.com/adapter-hub/adapter-transformers.git\ncd adapter-transformers\npip install .\n```\n\n## Getting Started\n\nHuggingFace's great documentation on getting started with _Transformers_ can be found [here](https://huggingface.co/transformers/index.html). `adapter-transformers` is fully compatible with _Transformers_.\n\nTo get started with adapters, refer to these locations:\n\n- **[Colab notebook tutorials](https://github.com/Adapter-Hub/adapter-transformers/tree/master/notebooks)**, a series notebooks providing an introduction to all the main concepts of (adapter-)transformers and AdapterHub\n- **https://docs.adapterhub.ml**, our documentation on training and using adapters with _adapter-transformers_\n- **https://adapterhub.ml** to explore available pre-trained adapter modules and share your own adapters\n- **[Examples folder](https://github.com/Adapter-Hub/adapter-transformers/tree/master/examples/pytorch)** of this repository containing HuggingFace's example training scripts, many adapted for training adapters\n\n## Implemented Methods\n\nCurrently, adapter-transformers integrates all architectures and methods listed below:\n\n| Method | Paper(s) | Quick Links |\n| --- | --- | --- |\n| Bottleneck adapters | [Houlsby et al. (2019)](https://arxiv.org/pdf/1902.00751.pdf)<br> [Bapna and Firat (2019)](https://arxiv.org/pdf/1909.08478.pdf) | [Quickstart](https://docs.adapterhub.ml/quickstart.html), [Notebook](https://colab.research.google.com/github/Adapter-Hub/adapter-transformers/blob/master/notebooks/01_Adapter_Training.ipynb) |\n| AdapterFusion | [Pfeiffer et al. (2021)](https://aclanthology.org/2021.eacl-main.39.pdf) | [Docs: Training](https://docs.adapterhub.ml/training.html#train-adapterfusion), [Notebook](https://colab.research.google.com/github/Adapter-Hub/adapter-transformers/blob/master/notebooks/03_Adapter_Fusion.ipynb) |\n| MAD-X,<br> Invertible adapters | [Pfeiffer et al. (2020)](https://aclanthology.org/2020.emnlp-main.617/) | [Notebook](https://colab.research.google.com/github/Adapter-Hub/adapter-transformers/blob/master/notebooks/04_Cross_Lingual_Transfer.ipynb) |\n| AdapterDrop | [RÃ¼cklÃ© et al. (2021)](https://arxiv.org/pdf/2010.11918.pdf) | [Notebook](https://colab.research.google.com/github/Adapter-Hub/adapter-transformers/blob/master/notebooks/05_Adapter_Drop_Training.ipynb) |\n| MAD-X 2.0,<br> Embedding training | [Pfeiffer et al. (2021)](https://arxiv.org/pdf/2012.15562.pdf) | [Docs: Embeddings](https://docs.adapterhub.ml/embeddings.html), [Notebook](https://colab.research.google.com/github/Adapter-Hub/adapter-transformers/blob/master/notebooks/08_NER_Wikiann.ipynb) |\n| Prefix Tuning | [Li and Liang (2021)](https://arxiv.org/pdf/2101.00190.pdf) | [Docs](https://docs.adapterhub.ml/overview.html#prefix-tuning) |\n| Parallel adapters,<br> Mix-and-Match adapters | [He et al. (2021)](https://arxiv.org/pdf/2110.04366.pdf) | [Docs](https://docs.adapterhub.ml/overview.html#mix-and-match-adapters) |\n| Compacter | [Mahabadi et al. (2021)](https://arxiv.org/pdf/2106.04647.pdf) | [Docs](https://docs.adapterhub.ml/overview.html#compacter) |\n| LoRA | [Hu et al. (2021)](https://arxiv.org/pdf/2106.09685.pdf) | [Docs](https://docs.adapterhub.ml/overview.html#lora) |\n| (IA)^3 | [Liu et al. (2022)](https://arxiv.org/pdf/2205.05638.pdf) | [Docs](https://docs.adapterhub.ml/overview.html#ia-3) |\n| UniPELT | [Mao et al. (2022)](https://arxiv.org/pdf/2110.07577.pdf) | [Docs](https://docs.adapterhub.ml/overview.html#unipelt) |\n\n## Supported Models\n\nWe currently support the PyTorch versions of all models listed on the **[Model Overview](https://docs.adapterhub.ml/model_overview.html) page** in our documentation.\n\n## Citation\n\nIf you use this library for your work, please consider citing our paper [AdapterHub: A Framework for Adapting Transformers](https://arxiv.org/abs/2007.07779):\n\n```\n@inproceedings{pfeiffer2020AdapterHub,\n    title={AdapterHub: A Framework for Adapting Transformers},\n    author={Pfeiffer, Jonas and\n            R{\\\"u}ckl{\\'e}, Andreas and\n            Poth, Clifton and\n            Kamath, Aishwarya and\n            Vuli{\\'c}, Ivan and\n            Ruder, Sebastian and\n            Cho, Kyunghyun and\n            Gurevych, Iryna},\n    booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations},\n    pages={46--54},\n    year={2020}\n}\n```\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/adapter-hub/adapter-transformers",
    "keywords": "NLP deep learning transformer pytorch BERT adapters",
    "license": "Apache",
    "maintainer": "",
    "maintainer_email": "",
    "name": "mw-adapter-transformers",
    "package_url": "https://pypi.org/project/mw-adapter-transformers/",
    "platform": null,
    "project_url": "https://pypi.org/project/mw-adapter-transformers/",
    "project_urls": {
      "Homepage": "https://github.com/adapter-hub/adapter-transformers"
    },
    "release_url": "https://pypi.org/project/mw-adapter-transformers/3.1.0/",
    "requires_dist": [
      "filelock",
      "huggingface-hub (<1.0,>=0.1.0)",
      "numpy (>=1.17)",
      "packaging (>=20.0)",
      "pyyaml (>=5.1)",
      "regex (!=2019.12.17)",
      "requests",
      "tokenizers (!=0.11.3,<0.13,>=0.11.1)",
      "tqdm (>=4.27)",
      "importlib-metadata ; python_version < \"3.8\"",
      "accelerate (>=0.10.0) ; extra == 'accelerate'",
      "tensorflow (>=2.3) ; extra == 'all'",
      "onnxconverter-common ; extra == 'all'",
      "tf2onnx ; extra == 'all'",
      "tensorflow-text ; extra == 'all'",
      "torch (<1.12,>=1.0) ; extra == 'all'",
      "jax (!=0.3.2,<=0.3.6,>=0.2.8) ; extra == 'all'",
      "jaxlib (<=0.3.6,>=0.1.65) ; extra == 'all'",
      "flax (>=0.4.1) ; extra == 'all'",
      "optax (>=0.0.8) ; extra == 'all'",
      "sentencepiece (!=0.1.92,>=0.1.91) ; extra == 'all'",
      "protobuf (<=3.20.1) ; extra == 'all'",
      "tokenizers (!=0.11.3,<0.13,>=0.11.1) ; extra == 'all'",
      "torchaudio ; extra == 'all'",
      "librosa ; extra == 'all'",
      "pyctcdecode (>=0.3.0) ; extra == 'all'",
      "phonemizer ; extra == 'all'",
      "resampy (<0.3.1) ; extra == 'all'",
      "Pillow ; extra == 'all'",
      "optuna ; extra == 'all'",
      "ray[tune] ; extra == 'all'",
      "sigopt ; extra == 'all'",
      "timm ; extra == 'all'",
      "codecarbon (==1.2.0) ; extra == 'all'",
      "accelerate (>=0.10.0) ; extra == 'all'",
      "librosa ; extra == 'audio'",
      "pyctcdecode (>=0.3.0) ; extra == 'audio'",
      "phonemizer ; extra == 'audio'",
      "resampy (<0.3.1) ; extra == 'audio'",
      "codecarbon (==1.2.0) ; extra == 'codecarbon'",
      "deepspeed (>=0.6.5) ; extra == 'deepspeed'",
      "accelerate (>=0.10.0) ; extra == 'deepspeed'",
      "deepspeed (>=0.6.5) ; extra == 'deepspeed-testing'",
      "accelerate (>=0.10.0) ; extra == 'deepspeed-testing'",
      "pytest ; extra == 'deepspeed-testing'",
      "pytest-xdist ; extra == 'deepspeed-testing'",
      "timeout-decorator ; extra == 'deepspeed-testing'",
      "parameterized ; extra == 'deepspeed-testing'",
      "psutil ; extra == 'deepspeed-testing'",
      "datasets ; extra == 'deepspeed-testing'",
      "dill (<0.3.5) ; extra == 'deepspeed-testing'",
      "pytest-timeout ; extra == 'deepspeed-testing'",
      "black (==22.3) ; extra == 'deepspeed-testing'",
      "sacrebleu (<2.0.0,>=1.4.12) ; extra == 'deepspeed-testing'",
      "rouge-score ; extra == 'deepspeed-testing'",
      "nltk ; extra == 'deepspeed-testing'",
      "GitPython (<3.1.19) ; extra == 'deepspeed-testing'",
      "hf-doc-builder (>=0.3.0) ; extra == 'deepspeed-testing'",
      "protobuf (<=3.20.1) ; extra == 'deepspeed-testing'",
      "sacremoses ; extra == 'deepspeed-testing'",
      "rjieba ; extra == 'deepspeed-testing'",
      "faiss-cpu ; extra == 'deepspeed-testing'",
      "cookiecutter (==1.7.3) ; extra == 'deepspeed-testing'",
      "optuna ; extra == 'deepspeed-testing'",
      "tensorflow (>=2.3) ; extra == 'dev'",
      "onnxconverter-common ; extra == 'dev'",
      "tf2onnx ; extra == 'dev'",
      "tensorflow-text ; extra == 'dev'",
      "torch (<1.12,>=1.0) ; extra == 'dev'",
      "jax (!=0.3.2,<=0.3.6,>=0.2.8) ; extra == 'dev'",
      "jaxlib (<=0.3.6,>=0.1.65) ; extra == 'dev'",
      "flax (>=0.4.1) ; extra == 'dev'",
      "optax (>=0.0.8) ; extra == 'dev'",
      "sentencepiece (!=0.1.92,>=0.1.91) ; extra == 'dev'",
      "protobuf (<=3.20.1) ; extra == 'dev'",
      "tokenizers (!=0.11.3,<0.13,>=0.11.1) ; extra == 'dev'",
      "torchaudio ; extra == 'dev'",
      "librosa ; extra == 'dev'",
      "pyctcdecode (>=0.3.0) ; extra == 'dev'",
      "phonemizer ; extra == 'dev'",
      "resampy (<0.3.1) ; extra == 'dev'",
      "Pillow ; extra == 'dev'",
      "optuna ; extra == 'dev'",
      "ray[tune] ; extra == 'dev'",
      "sigopt ; extra == 'dev'",
      "timm ; extra == 'dev'",
      "codecarbon (==1.2.0) ; extra == 'dev'",
      "accelerate (>=0.10.0) ; extra == 'dev'",
      "pytest ; extra == 'dev'",
      "pytest-xdist ; extra == 'dev'",
      "timeout-decorator ; extra == 'dev'",
      "parameterized ; extra == 'dev'",
      "psutil ; extra == 'dev'",
      "datasets ; extra == 'dev'",
      "dill (<0.3.5) ; extra == 'dev'",
      "pytest-timeout ; extra == 'dev'",
      "black (==22.3) ; extra == 'dev'",
      "sacrebleu (<2.0.0,>=1.4.12) ; extra == 'dev'",
      "rouge-score ; extra == 'dev'",
      "nltk ; extra == 'dev'",
      "GitPython (<3.1.19) ; extra == 'dev'",
      "hf-doc-builder (>=0.3.0) ; extra == 'dev'",
      "sacremoses ; extra == 'dev'",
      "rjieba ; extra == 'dev'",
      "faiss-cpu ; extra == 'dev'",
      "cookiecutter (==1.7.3) ; extra == 'dev'",
      "isort (>=5.5.4) ; extra == 'dev'",
      "flake8 (>=3.8.3) ; extra == 'dev'",
      "fugashi (>=1.0) ; extra == 'dev'",
      "ipadic (<2.0,>=1.0.0) ; extra == 'dev'",
      "unidic-lite (>=1.0.7) ; extra == 'dev'",
      "unidic (>=1.0.2) ; extra == 'dev'",
      "docutils (==0.16.0) ; extra == 'dev'",
      "myst-parser ; extra == 'dev'",
      "sphinx (==3.2.1) ; extra == 'dev'",
      "sphinx-markdown-tables ; extra == 'dev'",
      "sphinx-rtd-theme (==0.4.3) ; extra == 'dev'",
      "sphinx-copybutton ; extra == 'dev'",
      "sphinxext-opengraph (==0.4.1) ; extra == 'dev'",
      "sphinx-intl ; extra == 'dev'",
      "sphinx-multiversion ; extra == 'dev'",
      "scikit-learn ; extra == 'dev'",
      "pytest ; extra == 'dev-tensorflow'",
      "pytest-xdist ; extra == 'dev-tensorflow'",
      "timeout-decorator ; extra == 'dev-tensorflow'",
      "parameterized ; extra == 'dev-tensorflow'",
      "psutil ; extra == 'dev-tensorflow'",
      "datasets ; extra == 'dev-tensorflow'",
      "dill (<0.3.5) ; extra == 'dev-tensorflow'",
      "pytest-timeout ; extra == 'dev-tensorflow'",
      "black (==22.3) ; extra == 'dev-tensorflow'",
      "sacrebleu (<2.0.0,>=1.4.12) ; extra == 'dev-tensorflow'",
      "rouge-score ; extra == 'dev-tensorflow'",
      "nltk ; extra == 'dev-tensorflow'",
      "GitPython (<3.1.19) ; extra == 'dev-tensorflow'",
      "hf-doc-builder (>=0.3.0) ; extra == 'dev-tensorflow'",
      "protobuf (<=3.20.1) ; extra == 'dev-tensorflow'",
      "sacremoses ; extra == 'dev-tensorflow'",
      "rjieba ; extra == 'dev-tensorflow'",
      "faiss-cpu ; extra == 'dev-tensorflow'",
      "cookiecutter (==1.7.3) ; extra == 'dev-tensorflow'",
      "tensorflow (>=2.3) ; extra == 'dev-tensorflow'",
      "onnxconverter-common ; extra == 'dev-tensorflow'",
      "tf2onnx ; extra == 'dev-tensorflow'",
      "tensorflow-text ; extra == 'dev-tensorflow'",
      "sentencepiece (!=0.1.92,>=0.1.91) ; extra == 'dev-tensorflow'",
      "tokenizers (!=0.11.3,<0.13,>=0.11.1) ; extra == 'dev-tensorflow'",
      "Pillow ; extra == 'dev-tensorflow'",
      "isort (>=5.5.4) ; extra == 'dev-tensorflow'",
      "flake8 (>=3.8.3) ; extra == 'dev-tensorflow'",
      "docutils (==0.16.0) ; extra == 'dev-tensorflow'",
      "myst-parser ; extra == 'dev-tensorflow'",
      "sphinx (==3.2.1) ; extra == 'dev-tensorflow'",
      "sphinx-markdown-tables ; extra == 'dev-tensorflow'",
      "sphinx-rtd-theme (==0.4.3) ; extra == 'dev-tensorflow'",
      "sphinx-copybutton ; extra == 'dev-tensorflow'",
      "sphinxext-opengraph (==0.4.1) ; extra == 'dev-tensorflow'",
      "sphinx-intl ; extra == 'dev-tensorflow'",
      "sphinx-multiversion ; extra == 'dev-tensorflow'",
      "scikit-learn ; extra == 'dev-tensorflow'",
      "onnxruntime (>=1.4.0) ; extra == 'dev-tensorflow'",
      "onnxruntime-tools (>=1.4.2) ; extra == 'dev-tensorflow'",
      "librosa ; extra == 'dev-tensorflow'",
      "pyctcdecode (>=0.3.0) ; extra == 'dev-tensorflow'",
      "phonemizer ; extra == 'dev-tensorflow'",
      "resampy (<0.3.1) ; extra == 'dev-tensorflow'",
      "pytest ; extra == 'dev-torch'",
      "pytest-xdist ; extra == 'dev-torch'",
      "timeout-decorator ; extra == 'dev-torch'",
      "parameterized ; extra == 'dev-torch'",
      "psutil ; extra == 'dev-torch'",
      "datasets ; extra == 'dev-torch'",
      "dill (<0.3.5) ; extra == 'dev-torch'",
      "pytest-timeout ; extra == 'dev-torch'",
      "black (==22.3) ; extra == 'dev-torch'",
      "sacrebleu (<2.0.0,>=1.4.12) ; extra == 'dev-torch'",
      "rouge-score ; extra == 'dev-torch'",
      "nltk ; extra == 'dev-torch'",
      "GitPython (<3.1.19) ; extra == 'dev-torch'",
      "hf-doc-builder (>=0.3.0) ; extra == 'dev-torch'",
      "protobuf (<=3.20.1) ; extra == 'dev-torch'",
      "sacremoses ; extra == 'dev-torch'",
      "rjieba ; extra == 'dev-torch'",
      "faiss-cpu ; extra == 'dev-torch'",
      "cookiecutter (==1.7.3) ; extra == 'dev-torch'",
      "torch (<1.12,>=1.0) ; extra == 'dev-torch'",
      "sentencepiece (!=0.1.92,>=0.1.91) ; extra == 'dev-torch'",
      "tokenizers (!=0.11.3,<0.13,>=0.11.1) ; extra == 'dev-torch'",
      "torchaudio ; extra == 'dev-torch'",
      "librosa ; extra == 'dev-torch'",
      "pyctcdecode (>=0.3.0) ; extra == 'dev-torch'",
      "phonemizer ; extra == 'dev-torch'",
      "resampy (<0.3.1) ; extra == 'dev-torch'",
      "Pillow ; extra == 'dev-torch'",
      "optuna ; extra == 'dev-torch'",
      "ray[tune] ; extra == 'dev-torch'",
      "sigopt ; extra == 'dev-torch'",
      "timm ; extra == 'dev-torch'",
      "codecarbon (==1.2.0) ; extra == 'dev-torch'",
      "isort (>=5.5.4) ; extra == 'dev-torch'",
      "flake8 (>=3.8.3) ; extra == 'dev-torch'",
      "fugashi (>=1.0) ; extra == 'dev-torch'",
      "ipadic (<2.0,>=1.0.0) ; extra == 'dev-torch'",
      "unidic-lite (>=1.0.7) ; extra == 'dev-torch'",
      "unidic (>=1.0.2) ; extra == 'dev-torch'",
      "docutils (==0.16.0) ; extra == 'dev-torch'",
      "myst-parser ; extra == 'dev-torch'",
      "sphinx (==3.2.1) ; extra == 'dev-torch'",
      "sphinx-markdown-tables ; extra == 'dev-torch'",
      "sphinx-rtd-theme (==0.4.3) ; extra == 'dev-torch'",
      "sphinx-copybutton ; extra == 'dev-torch'",
      "sphinxext-opengraph (==0.4.1) ; extra == 'dev-torch'",
      "sphinx-intl ; extra == 'dev-torch'",
      "sphinx-multiversion ; extra == 'dev-torch'",
      "scikit-learn ; extra == 'dev-torch'",
      "onnxruntime (>=1.4.0) ; extra == 'dev-torch'",
      "onnxruntime-tools (>=1.4.2) ; extra == 'dev-torch'",
      "tensorflow (>=2.3) ; extra == 'docs'",
      "onnxconverter-common ; extra == 'docs'",
      "tf2onnx ; extra == 'docs'",
      "tensorflow-text ; extra == 'docs'",
      "torch (<1.12,>=1.0) ; extra == 'docs'",
      "jax (!=0.3.2,<=0.3.6,>=0.2.8) ; extra == 'docs'",
      "jaxlib (<=0.3.6,>=0.1.65) ; extra == 'docs'",
      "flax (>=0.4.1) ; extra == 'docs'",
      "optax (>=0.0.8) ; extra == 'docs'",
      "sentencepiece (!=0.1.92,>=0.1.91) ; extra == 'docs'",
      "protobuf (<=3.20.1) ; extra == 'docs'",
      "tokenizers (!=0.11.3,<0.13,>=0.11.1) ; extra == 'docs'",
      "torchaudio ; extra == 'docs'",
      "librosa ; extra == 'docs'",
      "pyctcdecode (>=0.3.0) ; extra == 'docs'",
      "phonemizer ; extra == 'docs'",
      "resampy (<0.3.1) ; extra == 'docs'",
      "Pillow ; extra == 'docs'",
      "optuna ; extra == 'docs'",
      "ray[tune] ; extra == 'docs'",
      "sigopt ; extra == 'docs'",
      "timm ; extra == 'docs'",
      "codecarbon (==1.2.0) ; extra == 'docs'",
      "accelerate (>=0.10.0) ; extra == 'docs'",
      "docutils (==0.16.0) ; extra == 'docs'",
      "myst-parser ; extra == 'docs'",
      "sphinx (==3.2.1) ; extra == 'docs'",
      "sphinx-markdown-tables ; extra == 'docs'",
      "sphinx-rtd-theme (==0.4.3) ; extra == 'docs'",
      "sphinx-copybutton ; extra == 'docs'",
      "sphinxext-opengraph (==0.4.1) ; extra == 'docs'",
      "sphinx-intl ; extra == 'docs'",
      "sphinx-multiversion ; extra == 'docs'",
      "docutils (==0.16.0) ; extra == 'docs_specific'",
      "myst-parser ; extra == 'docs_specific'",
      "sphinx (==3.2.1) ; extra == 'docs_specific'",
      "sphinx-markdown-tables ; extra == 'docs_specific'",
      "sphinx-rtd-theme (==0.4.3) ; extra == 'docs_specific'",
      "sphinx-copybutton ; extra == 'docs_specific'",
      "sphinxext-opengraph (==0.4.1) ; extra == 'docs_specific'",
      "sphinx-intl ; extra == 'docs_specific'",
      "sphinx-multiversion ; extra == 'docs_specific'",
      "fairscale (>0.3) ; extra == 'fairscale'",
      "jax (!=0.3.2,<=0.3.6,>=0.2.8) ; extra == 'flax'",
      "jaxlib (<=0.3.6,>=0.1.65) ; extra == 'flax'",
      "flax (>=0.4.1) ; extra == 'flax'",
      "optax (>=0.0.8) ; extra == 'flax'",
      "librosa ; extra == 'flax-speech'",
      "pyctcdecode (>=0.3.0) ; extra == 'flax-speech'",
      "phonemizer ; extra == 'flax-speech'",
      "resampy (<0.3.1) ; extra == 'flax-speech'",
      "ftfy ; extra == 'ftfy'",
      "optuna ; extra == 'integrations'",
      "ray[tune] ; extra == 'integrations'",
      "sigopt ; extra == 'integrations'",
      "fugashi (>=1.0) ; extra == 'ja'",
      "ipadic (<2.0,>=1.0.0) ; extra == 'ja'",
      "unidic-lite (>=1.0.7) ; extra == 'ja'",
      "unidic (>=1.0.2) ; extra == 'ja'",
      "cookiecutter (==1.7.3) ; extra == 'modelcreation'",
      "onnxconverter-common ; extra == 'onnx'",
      "tf2onnx ; extra == 'onnx'",
      "onnxruntime (>=1.4.0) ; extra == 'onnx'",
      "onnxruntime-tools (>=1.4.2) ; extra == 'onnx'",
      "onnxruntime (>=1.4.0) ; extra == 'onnxruntime'",
      "onnxruntime-tools (>=1.4.2) ; extra == 'onnxruntime'",
      "optuna ; extra == 'optuna'",
      "black (==22.3) ; extra == 'quality'",
      "isort (>=5.5.4) ; extra == 'quality'",
      "flake8 (>=3.8.3) ; extra == 'quality'",
      "GitPython (<3.1.19) ; extra == 'quality'",
      "hf-doc-builder (>=0.3.0) ; extra == 'quality'",
      "ray[tune] ; extra == 'ray'",
      "faiss-cpu ; extra == 'retrieval'",
      "datasets ; extra == 'retrieval'",
      "sagemaker (>=2.31.0) ; extra == 'sagemaker'",
      "sentencepiece (!=0.1.92,>=0.1.91) ; extra == 'sentencepiece'",
      "protobuf (<=3.20.1) ; extra == 'sentencepiece'",
      "pydantic ; extra == 'serving'",
      "uvicorn ; extra == 'serving'",
      "fastapi ; extra == 'serving'",
      "starlette ; extra == 'serving'",
      "sigopt ; extra == 'sigopt'",
      "scikit-learn ; extra == 'sklearn'",
      "torchaudio ; extra == 'speech'",
      "librosa ; extra == 'speech'",
      "pyctcdecode (>=0.3.0) ; extra == 'speech'",
      "phonemizer ; extra == 'speech'",
      "resampy (<0.3.1) ; extra == 'speech'",
      "pytest ; extra == 'testing'",
      "pytest-xdist ; extra == 'testing'",
      "timeout-decorator ; extra == 'testing'",
      "parameterized ; extra == 'testing'",
      "psutil ; extra == 'testing'",
      "datasets ; extra == 'testing'",
      "dill (<0.3.5) ; extra == 'testing'",
      "pytest-timeout ; extra == 'testing'",
      "black (==22.3) ; extra == 'testing'",
      "sacrebleu (<2.0.0,>=1.4.12) ; extra == 'testing'",
      "rouge-score ; extra == 'testing'",
      "nltk ; extra == 'testing'",
      "GitPython (<3.1.19) ; extra == 'testing'",
      "hf-doc-builder (>=0.3.0) ; extra == 'testing'",
      "protobuf (<=3.20.1) ; extra == 'testing'",
      "sacremoses ; extra == 'testing'",
      "rjieba ; extra == 'testing'",
      "faiss-cpu ; extra == 'testing'",
      "cookiecutter (==1.7.3) ; extra == 'testing'",
      "tensorflow (>=2.3) ; extra == 'tf'",
      "onnxconverter-common ; extra == 'tf'",
      "tf2onnx ; extra == 'tf'",
      "tensorflow-text ; extra == 'tf'",
      "tensorflow-cpu (>=2.3) ; extra == 'tf-cpu'",
      "onnxconverter-common ; extra == 'tf-cpu'",
      "tf2onnx ; extra == 'tf-cpu'",
      "tensorflow-text ; extra == 'tf-cpu'",
      "librosa ; extra == 'tf-speech'",
      "pyctcdecode (>=0.3.0) ; extra == 'tf-speech'",
      "phonemizer ; extra == 'tf-speech'",
      "resampy (<0.3.1) ; extra == 'tf-speech'",
      "timm ; extra == 'timm'",
      "tokenizers (!=0.11.3,<0.13,>=0.11.1) ; extra == 'tokenizers'",
      "torch (<1.12,>=1.0) ; extra == 'torch'",
      "torchaudio ; extra == 'torch-speech'",
      "librosa ; extra == 'torch-speech'",
      "pyctcdecode (>=0.3.0) ; extra == 'torch-speech'",
      "phonemizer ; extra == 'torch-speech'",
      "resampy (<0.3.1) ; extra == 'torch-speech'",
      "filelock ; extra == 'torchhub'",
      "huggingface-hub (<1.0,>=0.1.0) ; extra == 'torchhub'",
      "importlib-metadata ; extra == 'torchhub'",
      "numpy (>=1.17) ; extra == 'torchhub'",
      "packaging (>=20.0) ; extra == 'torchhub'",
      "protobuf (<=3.20.1) ; extra == 'torchhub'",
      "regex (!=2019.12.17) ; extra == 'torchhub'",
      "requests ; extra == 'torchhub'",
      "sentencepiece (!=0.1.92,>=0.1.91) ; extra == 'torchhub'",
      "torch (<1.12,>=1.0) ; extra == 'torchhub'",
      "tokenizers (!=0.11.3,<0.13,>=0.11.1) ; extra == 'torchhub'",
      "tqdm (>=4.27) ; extra == 'torchhub'",
      "Pillow ; extra == 'vision'"
    ],
    "requires_python": ">=3.7.0",
    "summary": "A friendly fork of HuggingFace's Transformers, adding Adapters to PyTorch language models",
    "version": "3.1.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 15933619,
  "releases": {
    "3.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "00142136c3cd9ef74d269354772ce5f1b3e0dc538373b77a8191e25ef6624e14",
          "md5": "6077a4ad92f609e9081234b9c99b0314",
          "sha256": "753c195116a14aadc7797eaaaa93805938606dae5f3d671a8fe087a76cb2e4ae"
        },
        "downloads": -1,
        "filename": "mw_adapter_transformers-3.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "6077a4ad92f609e9081234b9c99b0314",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6.0",
        "size": 3922227,
        "upload_time": "2022-11-01T23:33:38",
        "upload_time_iso_8601": "2022-11-01T23:33:38.227622Z",
        "url": "https://files.pythonhosted.org/packages/00/14/2136c3cd9ef74d269354772ce5f1b3e0dc538373b77a8191e25ef6624e14/mw_adapter_transformers-3.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "72d28102e9a39243ed145651fbcbb8bb38cf50ca9a6f0d0450dda635098cef74",
          "md5": "ab0ca5208fd9dd41687de0251a9651cb",
          "sha256": "a61ad5c0a5efd27a9b1ca05d569b3c65a71c9f38553dd2ac4ed27e40e126c29a"
        },
        "downloads": -1,
        "filename": "mw-adapter-transformers-3.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "ab0ca5208fd9dd41687de0251a9651cb",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6.0",
        "size": 3240315,
        "upload_time": "2022-11-01T23:33:43",
        "upload_time_iso_8601": "2022-11-01T23:33:43.280622Z",
        "url": "https://files.pythonhosted.org/packages/72/d2/8102e9a39243ed145651fbcbb8bb38cf50ca9a6f0d0450dda635098cef74/mw-adapter-transformers-3.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "3.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a06ec13cbb60f54282e114b2f9b6265c124c2a3a1c181f417725a18b55611b40",
          "md5": "7713e999b1485f382a24894e17a86e97",
          "sha256": "8a220f735322aad49b7fea44be56282ed97834304ca8c3586d572d8bff366eca"
        },
        "downloads": -1,
        "filename": "mw_adapter_transformers-3.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "7713e999b1485f382a24894e17a86e97",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7.0",
        "size": 4779017,
        "upload_time": "2022-11-28T22:06:19",
        "upload_time_iso_8601": "2022-11-28T22:06:19.866216Z",
        "url": "https://files.pythonhosted.org/packages/a0/6e/c13cbb60f54282e114b2f9b6265c124c2a3a1c181f417725a18b55611b40/mw_adapter_transformers-3.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8a830ac4eb94415f443b245b2e191733956426f2bad748631569189da68ce8b4",
          "md5": "51207dcb1ceb628232a5a38644091a94",
          "sha256": "54036378376246c6d0f4d56bc1fd207737b79b0050a214e366c0f37255c97f8c"
        },
        "downloads": -1,
        "filename": "mw-adapter-transformers-3.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "51207dcb1ceb628232a5a38644091a94",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7.0",
        "size": 3954406,
        "upload_time": "2022-11-28T22:06:22",
        "upload_time_iso_8601": "2022-11-28T22:06:22.638906Z",
        "url": "https://files.pythonhosted.org/packages/8a/83/0ac4eb94415f443b245b2e191733956426f2bad748631569189da68ce8b4/mw-adapter-transformers-3.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "a06ec13cbb60f54282e114b2f9b6265c124c2a3a1c181f417725a18b55611b40",
        "md5": "7713e999b1485f382a24894e17a86e97",
        "sha256": "8a220f735322aad49b7fea44be56282ed97834304ca8c3586d572d8bff366eca"
      },
      "downloads": -1,
      "filename": "mw_adapter_transformers-3.1.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "7713e999b1485f382a24894e17a86e97",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7.0",
      "size": 4779017,
      "upload_time": "2022-11-28T22:06:19",
      "upload_time_iso_8601": "2022-11-28T22:06:19.866216Z",
      "url": "https://files.pythonhosted.org/packages/a0/6e/c13cbb60f54282e114b2f9b6265c124c2a3a1c181f417725a18b55611b40/mw_adapter_transformers-3.1.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "8a830ac4eb94415f443b245b2e191733956426f2bad748631569189da68ce8b4",
        "md5": "51207dcb1ceb628232a5a38644091a94",
        "sha256": "54036378376246c6d0f4d56bc1fd207737b79b0050a214e366c0f37255c97f8c"
      },
      "downloads": -1,
      "filename": "mw-adapter-transformers-3.1.0.tar.gz",
      "has_sig": false,
      "md5_digest": "51207dcb1ceb628232a5a38644091a94",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7.0",
      "size": 3954406,
      "upload_time": "2022-11-28T22:06:22",
      "upload_time_iso_8601": "2022-11-28T22:06:22.638906Z",
      "url": "https://files.pythonhosted.org/packages/8a/83/0ac4eb94415f443b245b2e191733956426f2bad748631569189da68ce8b4/mw-adapter-transformers-3.1.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}