{
  "info": {
    "author": "Adrien Hadj-Salah",
    "author_email": "adrien.hadj.salah@gmail.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "[![Build status](https://travis-ci.com/Hadjubuntu/sweet-rl.svg?branch=master)](https://travis-ci.com/Hadjubuntu/sweet-rl)<br />\n![Sweet-RL](https://raw.githubusercontent.com/Hadjubuntu/sweet-rl/develop/misc/logo.png)\n\n## Why Sweet-RL\n \nIt exists dozens of Reinforcement Learning frameworks and algorithms implementations.\nYet, most of them suffer of poor modularity and ease of understanding. This is why, I started to implement my own: Sweet-RL.\nIt's so sweet that you can switch from Tensorflow 2.1 to PyTorch 1.4 with a single configuration line:  \n![Sweet-RL](https://raw.githubusercontent.com/Hadjubuntu/sweet-rl/develop/misc/ml-platform.png)\n\n\n## Getting started\n\n### Install sweet-rl  \n\nFirst, create a virtualenv:  \n```bash\npython3.x -m venv ~/.virtualenvs/sweet/ \n# or: virtualenv ~/.virtualenvs/sweet/ -p python3\nsource ~/.virtualenvs/sweet/bin/activate\n```\nAnd then, install project dependancies:  \n```bash\nmake install # or pip install -e .\n```\n\n### First execution  \n\nRun a DQN training:  \n```bash\npython -m sweet.run --env=CartPole-v0 --algo=dqn --ml=tf\n\n# Parameters:\n#   -h, --help            show this help message and exit\n#   --env ENV             Environment to play with\n#   --algo ALGO           RL agent\n#   --ml ML               ML platform (tf or torch)\n#   --model MODEL         Model (dense, pi_actor_critic)\n#   --timesteps TIMESTEPS\n#                         Number of training steps\n#   --output OUTPUT       Output directory (eg. './target/')\n```\n\n### Custom neural network\n\nIf you want to specify your own model instead of default ones, take a look to\n`sweet.agents.dqn.experiments.train_custom_model`\n\n## Features, algorithms implemented\n\n### Algorithms\n| Algorithm     | Implementation status |  ML platform  |\n| ------------- | -------------         | ------------- |\n| DQN | <g-emoji class=\"g-emoji\" alias=\"heavy_check_mark\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/2714.png\">✔️</g-emoji>  |  TF2, Torch |\n| A2C           | <g-emoji class=\"g-emoji\" alias=\"heavy_check_mark\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/2714.png\">✔️</g-emoji>  |  TF2, Torch   |\n| PPO           | Soon                  |               |\n\n\n### IO: Logs, model, tensorboard events\nOutputs are configurable in training function:\n```python\ntargets: dict = {\n        'output_dir': Path('./target/'), # Main directory to store your outputs\n        'models_dir': 'models_checkpoints', # Saving models (depending on model_checkpoint_freq)\n        'logs_dir': 'logs', # Saving logs (info, debug, errors)\n        'tb_dir': 'tb_events' # Saving tensorboard events\n}\n```\nModels are saved depending on `model_checkpoint_freq` parameter set in train function.\n\n## Benchmark\n\nTo reproduce benchmark, execute:\n```bash\npython -m sweet.benchmark.benchmark_runner\n```\n\nHere is an example of benchmark between TF 2.0 and Torch 1.4 with CartPole-v0 environment:  \n![Benchmark RL](https://raw.githubusercontent.com/Hadjubuntu/sweet-rl/develop/misc/bench-example.png)\n\n\n\n## Troubleshootings\n\n* Tensorflow 2.x doesn't work with Python 3.8 so far, so only Python versions 3.6 and 3.7 are supported\n* GPU is not used. See https://www.tensorflow.org/install/gpu\n\n## History/Author\n\nI started this open-source RL framework in january 2020, at first to take benefit of tensorflow 2.x readability without sacrifying the performance.\nBesides coding open-source project, i work for both Airbus and IRT Saint-Exupéry on Earth Observation satellites. Our team is focus on mission planning for satellites and Reinforcement Learning is an approach to solve it. Feel free to discuss with me: [Adrien HADJ-SALAH @linkedin](https://www.linkedin.com/in/adrien-hadj-salah-1b119462/)\n\n**You are welcome to participate to this project**\n\n## RL related topics\n\n* **What is Reinforcement Learning**\nIt is supposed that you have knowledge in RL, if it is not the case, take a look to the [spinningup from OpenAI](https://spinningup.openai.com/en/latest/)",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/Hadjubuntu/sweet-rl",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "sweet-rl",
    "package_url": "https://pypi.org/project/sweet-rl/",
    "platform": "",
    "project_url": "https://pypi.org/project/sweet-rl/",
    "project_urls": {
      "Homepage": "https://github.com/Hadjubuntu/sweet-rl"
    },
    "release_url": "https://pypi.org/project/sweet-rl/0.1/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "The sweetest Reinforcement Learning framework",
    "version": "0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 6712338,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2ecb3d5d1c532aa7774111a9c65d13b59fc12c0cb13bb6b0336fd7eb0af76a64",
          "md5": "d4bdc8058f276effbfc7f1528fdb3792",
          "sha256": "655abbed804f149218d7378ed103019f492d6a2d9ed9e72b18b8ad321dd23faf"
        },
        "downloads": -1,
        "filename": "sweet-rl-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "d4bdc8058f276effbfc7f1528fdb3792",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 11841,
        "upload_time": "2020-01-31T19:10:32",
        "upload_time_iso_8601": "2020-01-31T19:10:32.526375Z",
        "url": "https://files.pythonhosted.org/packages/2e/cb/3d5d1c532aa7774111a9c65d13b59fc12c0cb13bb6b0336fd7eb0af76a64/sweet-rl-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.1rc1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9d2255139c651b4614869620128b05de150ae31b93d36b27b8fdf8c6df869353",
          "md5": "76d0c5c81e5631df7b6f032129384df4",
          "sha256": "563016c3b6ca176559ece708c891f4fdf14311a68ab95f13526f2cd9ae3a51f5"
        },
        "downloads": -1,
        "filename": "sweet-rl-0.0.1rc1.tar.gz",
        "has_sig": false,
        "md5_digest": "76d0c5c81e5631df7b6f032129384df4",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 13376,
        "upload_time": "2020-02-02T22:28:16",
        "upload_time_iso_8601": "2020-02-02T22:28:16.506687Z",
        "url": "https://files.pythonhosted.org/packages/9d/22/55139c651b4614869620128b05de150ae31b93d36b27b8fdf8c6df869353/sweet-rl-0.0.1rc1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fe692f1d5ced0f81fc0fb2cc6196f2033420036ccd10e8b9ee1e94f3df4cfee2",
          "md5": "a487645da0792f1db1ba4fbf9afcbb6f",
          "sha256": "2cd6885f95b1fd7169cf11f172c102a0e5dd1c86368fc2973eb4b8e15cba7519"
        },
        "downloads": -1,
        "filename": "sweet-rl-0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "a487645da0792f1db1ba4fbf9afcbb6f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 12340,
        "upload_time": "2020-02-27T17:35:32",
        "upload_time_iso_8601": "2020-02-27T17:35:32.373701Z",
        "url": "https://files.pythonhosted.org/packages/fe/69/2f1d5ced0f81fc0fb2cc6196f2033420036ccd10e8b9ee1e94f3df4cfee2/sweet-rl-0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "fe692f1d5ced0f81fc0fb2cc6196f2033420036ccd10e8b9ee1e94f3df4cfee2",
        "md5": "a487645da0792f1db1ba4fbf9afcbb6f",
        "sha256": "2cd6885f95b1fd7169cf11f172c102a0e5dd1c86368fc2973eb4b8e15cba7519"
      },
      "downloads": -1,
      "filename": "sweet-rl-0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "a487645da0792f1db1ba4fbf9afcbb6f",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 12340,
      "upload_time": "2020-02-27T17:35:32",
      "upload_time_iso_8601": "2020-02-27T17:35:32.373701Z",
      "url": "https://files.pythonhosted.org/packages/fe/69/2f1d5ced0f81fc0fb2cc6196f2033420036ccd10e8b9ee1e94f3df4cfee2/sweet-rl-0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}