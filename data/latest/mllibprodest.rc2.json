{
  "info": {
    "author": "Instituto de Tecnologia da Informação e Comunicação do Espírito Santo (PRODEST)",
    "author_email": "\"Instituto de Tecnologia da Informação e Comunicação do Espírito Santo (PRODEST)\" <prodest@prodest.es.gov.br>",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Developers",
      "License :: OSI Approved :: GNU General Public License v3 (GPLv3)",
      "Natural Language :: Portuguese (Brazilian)",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3.8"
    ],
    "description": "# Biblioteca de ML (*Machine Learning*) - Prodest \nA finalidade desta biblioteca é prover interfaces e funções que dão suporte ao provisionamento de modelos de ML na Stack \nde ML do Prodest.\n\nAcesse a [documentação da lib](https://prodest.github.io/mllibprodest)!\n\n*Workflow* básico para construção, disponibilização e publicação de modelos:\n\n![](https://github.com/prodest/mllibprodest/blob/main/docs/workflow.png?raw=true)\n\n## Pré-requisitos\n* **Python >= 3.8.** Instruções: [Linux (Geralmente já vem instalado por padrão)](https://python.org.br/instalacao-linux) ou [Windows](https://www.python.org/downloads/windows).\n* **Git.** Instruções: [Linux](https://git-scm.com/download/linux) ou [Windows](https://git-scm.com/download/win).\n* **Venv.** Gerenciador de ambiente virtual Python adotado no tutorial. Instruções: [Linux e Windows (escolha o sistema na página)](https://packaging.python.org/en/latest/guides/installing-using-pip-and-virtual-environments/#creating-a-virtual-environment). \nOu qualquer outro gerenciador de ambiente Python que preferir.\n\n## 1. Realize experimentos e escolha o modelo \n\nEsta é uma das etapas iniciais de um projeto para o desenvolvimento de um modelo de *Machine Learning*. Neste momento é \nnecessário entender o problema a ser resolvido; levantar requisitos; obter e tratar os dados, etc. Também é nessa etapa \nque se verifica a viabilidade (ou não) da construção de um modelo.\n\nNeste passo você tem **total liberdade** para construir o seu modelo e realizar os experimentos que quiser. Entretanto, \né importante que os resultados e artefatos gerados pelos experimentos, desde já, sejam registrados para facilitar a \ncomparação dos resultados obtidos e a publicação do modelo. Esta lib utiliza o \n[MLflow](https://github.com/mlflow/mlflow) como plataforma para registro dos experimentos/modelos (no contexto da lib, o \nMLflow é chamado de *Provider*).\n\nApesar do registro dos experimentos ser importante, deixar de registrá-los agora **não** vai impedir que você construa o \nseu modelo!\n\nVocê tem duas opções: \n- Seguir com a construção do modelo e execução dos experimentos e, caso chegue à conclusão de que o modelo é viável, \najustar o código para realizar o registro; ou\n\n\n- Fazer uma pausa e entender primeiro como registrar seus experimentos no MLflow e já construir o código com a lógica\nnecessária para isso.\n\nIndependente da opção escolhida, haverá necessidade de, agora ou depois, aprender (caso não saiba) como registrar os \nexperimentos do modelo no MLflow. \nPara alcançar esse objetivo, leia a [documentação oficial do MLflow](https://mlflow.org/docs/latest/index.html).\n\nSegue abaixo, um exemplo simples de como registrar os experimentos de um modelo construído com o [scikit-learn](https://scikit-learn.org) \nutilizando o MLflow.\n\n```python\nimport os\nimport mlflow.sklearn  # Importa o sklearn através do MLflow\nimport pickle  # Para gerar um artefato de exemplo\n\n# Obs.: Utilize as duas linhas abaixo, exatamente como apresentadas, para configurar o parâmetro 'Tracking URI' do MLflow \n# nos seus códigos de testes. Dessa forma, quando subir para produção não haverá necessidade de modificá-las, pois lá\n# o parâmetro 'Tracking URI' será obtido diretamente através da variável de ambiente 'MLFLOW_TRACKING_URI'.\nif os.environ.get('MLFLOW_TRACKING_URI') is None:\n    mlflow.set_tracking_uri('sqlite:///teste_mlflow.db')\n\n# Configura o experimento (se não existir, cria)\nmlflow.set_experiment(experiment_name=\"Teste sklearn\")\n\n# Inicia uma execução do experimento (um experimento pode possuir várias execuções)\nmlflow.start_run(run_name=\"t1\", description=\"teste 1\")\n\n# Registra algumas informações adicionais no experimento (coloque as informações que julgar necessárias, no formato dict)\ntags = {\"Projeto\": \"Teste\", \"team\": \"ML\", \"util\": \"Informação útil\"}\nmlflow.set_tags(tags)\n\n# Inicia o registro dos logs da execução do sklearn\nmlflow.sklearn.autolog()\n\n# TODO: Inclua aqui a lógica para fazer o fit do modelo\n\n'''Exemplo de modelo, somente para o propósito de testes!'''\n# Adaptado de https://scikit-learn.org/stable/modules/tree.html#classification\nimport matplotlib\nimport numpy as np\nfrom sklearn import tree\nX = np.array([[0, 0], [1, 1]])\nY = np.array([0, 1]).reshape(-1)\nclf = tree.DecisionTreeClassifier()\nclf = clf.fit(X, Y)\n'''Fim do exemplo de modelo.'''\n\n'''\nSalva um artefato de seu interesse no MLflow (podem ser arquivos em diversos formatos: txt, pkl, png, jpeg, etc.).\nExemplos de artefato: gráficos, objetos persistidos com pickle, enfim, tudo que for relevante e/ou necessário para\nque o modelo funcione e/ou para análise das execuções.\n'''\n# Cria um aterfato de teste no formato pickle (obs.: todas as classes da lib tem os métodos \n# 'convert_artifact_to_pickle' e 'convert_artifact_to_object' para auxiliar na persistência dos artefatos)\nartefato = {\"t\": 1}\ncaminho_artefato = \"artefato.pkl\"\nwith open(caminho_artefato, 'wb') as arq:\n    pickle.dump(artefato, arq)\n\n# Salva o artefato criado\nmlflow.log_artifact(caminho_artefato)\n\n# Finaliza o experimento\nmlflow.end_run()\n\nprint(\"\\nTeste finalizado!\\n\")\n```\n\nSe você quiser testar um registro de experimento através do código acima, faça o seguinte:\n\n- Crie uma pasta para testes;\n- Copie e cole o código acima em um editor de texto simples e salve com o nome 'testeml.py' dentro da pasta criada;\n- Abra um prompt de comando ou terminal e entre na pasta criada;\n- Crie e ative um ambiente virtual Python, conforme instruções: [Linux e Windows (escolha o sistema na página)](https://packaging.python.org/en/latest/guides/installing-using-pip-and-virtual-environments/#creating-a-virtual-environment);\n- Instale os pacotes mlflow, sklearn, matplotlib e numpy;\n\n```bash\npip install mlflow sklearn matplotlib numpy\n```\n- Rode o teste (ignore as mensagens do tipo 'INFO' de criação do banco de dados);\n```bash\npython testeml.py\n```\nCabe observar que: depois de rodar o código de teste, foi criada uma pasta chamada '**mlruns**', dentro da pasta de \ntestes, que serve para armazenar os artefatos gerados pelo código e que são apresentados na interface do MLflow. \nAbaixo segue uma listagem do conteúdo gerado pelo código de teste (obs.: essa parte do caminho vai ser diferente de \nacordo com cada experimento/execução realizados: '1/f454220e01bd43e7b66c2354c20f0085'. O conteúdo da pasta também será \ndiferente de acordo com cada modelo).\n```bash\n(env) user:~/testes/mlruns/1/f454220e01bd43e7b66c2354c20f0085/artifacts$ dir\nartefato.pkl  model  training_confusion_matrix.png  training_precision_recall_curve.png  training_roc_curve.png\n```\nDentro da pasta criada para testes também foi gerado um arquivo chamado '**teste_mlflow.db**', que é um pequeno banco \nde dados [SQlite](https://www.sqlite.org), que serve para armazenar os modelos que foram registrados.\n\n- Inicie o servidor do MLflow;\n\nPerceba que a pasta '**mlruns**' e o arquivo '**teste_mlflow.db**' foram passados como parâmetros na hora de iniciar o \nservidor, para que o experimento de teste possa ser visualizado. Portanto, é **mandatório** sempre iniciar o servidor do\nMLflow **de dentro da pasta** onde se encontra o código que fará o registro dos artefatos e dos experimentos/modelos.\n\n**DICA**: Abra um outro prompt de comando ou terminal diferente; entre na pasta onde se encontra o código para registro \ndos experimentos/modelo; execute o comando para iniciar o servidor do MLflow de dentro desta pasta. Pois assim, você \nconseguirá rodar o código e já observar os resultados sem ter que parar o servidor para liberar o prompt ou terminal.\n```bash\nmlflow server --backend-store-uri sqlite:///teste_mlflow.db --host 0.0.0.0 -p 5000 --default-artifact-root mlruns\n```\n\n- Verifique se o experimento foi registrado. Acesse o MLFlow: [http://localhost:5000](http://localhost:5000) e procure \npelo experimento/execução '**Teste sklearn**' na seção **Experiments** (se o experimento não estiver listado, verifique \nse o servidor foi iniciado de dentro da pasta correta);\n\n\n- Clique na execução do experimento que se encontra na coluna '**Created**' (destaque em verde);\n\n![](https://github.com/prodest/mllibprodest/blob/main/docs/experiments-mlflow.png?raw=true)\n- Verifique se os artefatos foram gravados;\n\n![](https://github.com/prodest/mllibprodest/blob/main/docs/artifacts-mlflow.png?raw=true)\n\n- Finalize o servidor do MLflow. Faça 'CTRL+c' no prompt de comando ou terminal onde ele foi iniciado;\n- Apague a pasta criada para realização dos testes.\n\n**NOTA**: Existem vários outros *frameworks* suportados: TensorFlow, Keras, Pytorch, etc. (veja a lista completa para \nPython em [MLflow Python API](https://mlflow.org/docs/latest/python_api/index.html)), inclusive é possível registrar \nmodelos que **não são suportados nativamente** pelo MLflow utilizando a função \n[mlflow.pyfunc](https://mlflow.org/docs/latest/python_api/mlflow.pyfunc.html).\n\n**ATENÇÃO**: Sua interação direta com o MLflow será somente para registro dos experimentos/modelo. Essa interação é \nessencial porque dá liberdade ao desenvolvedor para escolher o *framework* que achar mais adequado para construção\ndo seu modelo. A lib disponibiliza funções para obtenção do modelo registrado e dos seus artefatos, além de \noutras funções relacionadas à carga de *datasets*. Leia a documentação das interfaces, classes e funções da lib para \nmais detalhes.\n\n### Antes de ir para os próximos passos...\nQuando você já tiver realizado vários experimentos utilizando o MLflow e decidido por colocar o modelo em produção, \nserá preciso registrar o modelo treinado para que o mesmo seja carregado e usado na construção dos *workers*, conforme \ndescrito no passo 3. Siga as instruções abaixo para registrar o modelo:\n\n- Caso o servidor do MLflow não esteja rodando, entre na pasta onde o **script que salvará o experimento** (código \ndesenvolvido para criação do modelo) se encontra; \n- Ative o ambiente virtual Python. Instruções: [Linux e Windows (escolha o sistema na página)](https://packaging.python.org/en/latest/guides/installing-using-pip-and-virtual-environments/#creating-a-virtual-environment); \n- Inicie o servidor do MLflow;\n```bash\nmlflow server --backend-store-uri sqlite:///teste_mlflow.db --host 0.0.0.0 -p 5000 --default-artifact-root mlruns\n```\n- Acesse o MLflow ([http://localhost:5000](http://localhost:5000)) e clique no experimento que foi criado por você (se \no experimento não estiver listado, verifique se o servidor do MLflow foi iniciado de dentro da pasta correta);\n- Clique no link (que está na coluna **'Created'**) para a rodada do experimento que deseja registrar;\n- Clique no botão **'Register Model'** e escolha a opção **'Create New Model'**;\n- Dê um nome para o modelo e clique em **'Register'**;\n- Na barra superior clique em **'Models'**;\n- Clique no link para a última versão do modelo que está em **'Latest Version'**;\n- Na opção **'Stage'** troque de **'None'** para **'Production'** e clique em OK.\n\nQuando for testar a implementação dos *workers* (passo 3), lembre de deixar o servidor do MLflow rodando para que seja \npossível carregar o modelo.\n\n## 2. Organize o código de acordo com o *template*\nUma vez que o modelo foi desenvolvido e testado, agora é o momento de iniciar as tratativas para publicá-lo na *stack* de ML do \nProdest. Porém, antes, é oporturno mostrar como o modelo será integrado à *stack*. Esta integração se dará através de \ncomponentes denominados *workers*, cuja codificação é de responsabilidade de quem está construindo o modelo. Na \nilustração abaixo é possível observar que os *workers* são acessados pelos componentes de apoio da *stack* para \npermitir a publicação dos modelos. Caso seja necessário, uma mesma stack poderá publicar mais de um modelo, desde que \nsejam construídos *workers* dedicados para cada um deles.\n\n![](https://github.com/prodest/mllibprodest/blob/main/docs/stack-ml.png?raw=true)\n\nExistem dois tipos de *workers*:\n- **worker_pub**: Fornece os métodos necessários para publicação do modelo.\n- **worker_retrain**: Responsável pela avaliação do desempenho do modelo e retreinamento, se for preciso.\n\nPara que o modelo possa ser publicado, é imprescindível que a organização do código seja conforme especificado na pasta\n'**templates**' (esta pasta vem junto com repositório da lib). \n\n![](https://github.com/prodest/mllibprodest/blob/main/docs/estrutura-pastas.png?raw=true)\n\nAs regras são simples mas precisam ser seguidas, caso contrário a publicação do modelo falhará.\n- Os nomes das pastas '**worker_pub**' e '**worker_retrain**' não podem ser alterados;\n- Os nomes dos scripts padrões contidos nestas pastas não podem ser alterados;\n- (Opcional, mas recomendável). Separe as funções utilitárias para o funcionamento dos *workers* nos arquivos '**utils.py**';\n- Gere um arquivo de *requirements* para cada um dos *workers* **separadamente**. Dica: Use um ambiente virtual Python \nseparado para cada *worker*, instale os pacotes requeridos para o funcionamento deles e no final gere um arquivo \n'**requirements.txt**' para cada *worker*;\n- Não importe código de fora destas pastas. Se os dois *workers* precisarem de uma mesma função, faça uma cópia desta em \ncada pasta (o arquivo 'utils.py' pode ajudar a organizar estas funções!);\n- Cuide para que os importes funcionem corretamente, dentro de cada pasta, **sem precisar** configurar a variável de \nambiente PYTHONPATH;\n- Utilize a pasta '**temp_area**' para salvar e ler os arquivos temporários que forem criados.\n\n**NOTA**: Os scripts '**mytest_pub.py**' e '**mytest_retrain.py**' podem ser utilizados por você para criação de testes\npersonalizados, para isso basta implementar a função '**test**' em cada um deles. Já os scripts '**test_pub.py**' e \n'**test_retrain.py**' podem ser usados para testar se algumas premissas foram atendidas, através de testes padrões \nda lib e a execução automática dos testes personalizados que foram implementados pelo usuário. No passo 3 é mostrado \ncomo rodar os scripts '**test_pub.py**' e '**test_retrain.py**'.\n\nCaso queira, você pode criar pastas ou arquivos de apoio dentro das pastas dos *workers* para organizar seu código, \ndesde que não modique a localização dos arquivos especificada pelos *templates*.\n\nPara obter e utilizar a pasta com os *templates*:\n- Clone o repositório da lib;\n```bash\ngit clone https://github.com/prodest/mllibprodest.git\n```\n\n- Entre na pasta gerada no processo de clonagem do repositório e copie o conteúdo da pasta '**templates**' para outro local \nde sua preferência (não trabalhe na pasta do repositório).\n\n## 3. Implemente as interfaces da biblioteca\n\nAntes de iniciar a implementação das interfaces, é importante criar um ambiente virtual Python **separadamente** para cada \n*worker*. Dessa forma você conseguirá gerar os arquivos de *requirements* sem maiores problemas. Siga as instruções abaixo:\n\n**Para o worker_pub**:\n- Abra um prompt de comando ou terminal;\n- Entre na pasta para onde você copiou o conteúdo da pasta '**templates**'; \n- Entre na pasta '**worker_pub**', crie e ative um ambiente virtual Python, conforme instruções: [Linux e Windows (escolha o sistema na página)](https://packaging.python.org/en/latest/guides/installing-using-pip-and-virtual-environments/#creating-a-virtual-environment); \n- Instale a lib para o worker_pub;\n```bash\npip install mllibprodest\n```\n- Feche o prompt de comando ou terminal.\n\n**Para o worker_retrain**:\n\n- Abra **outro** prompt de comando ou terminal (**Não** aproveite o anterior de forma alguma, pois dará errado!);\n- Entre na pasta para onde você copiou o conteúdo da pasta '**templates**'; \n- Entre na pasta '**worker_retrain**', crie e ative **outro** ambiente virtual Python;\n- Instale a lib para o worker_retrain;\n```bash\npip install mllibprodest\n```\n- Feche o prompt de comando ou terminal.\n\nPronto. Agora você tem um ambiente virtual Python para cada *worker*. Quando for utilizar uma IDE ou editor de código \npara implementar as interfaces, configure para que eles utilizem os ambientes virtuais criados para os respectivos \n*workers*. Dessa forma, à medida que você for produzindo o código e necessitar de instalar pacotes, esses serão \ninstalados nos ambientes virtuais criados. Quando terminar a implementação, basta você gerar os arquivos de \n*requirements* com base no ambiente virtual de cada *worker* separadamente. Acredite, isso vai te ajudar bastante!\n\nOutro ponto importante antes de implementar as interfaces é saber que: para publicar o modelo será necessário a criação \nde três artefatos obrigatórios, inclusive seguindo o mesmo nome (*case sensitive*). Estes artefatos devem ser \ndicionários (dict) salvos com o [Pickle](https://docs.python.org/3/library/pickle.html) (utilize a função \n'convert_artifact_to_pickle' quando estiver implementando as intefaces):\n\n- **TrainingParams.pkl**: Deve conter os parâmetros que você escolheu utilizar no treinamento do modelo. Não há \nnecessidade de colocar os parâmetros nos quais você manteve os valores *default*. Você pode colocar outros parâmetros \ncriados por você necessários para que o modelo funcione. Coloque o nome \ndo parâmetro como nome da chave e o valor do parâmetro como valor da chave. Ex. baseado no *DecisionTreeClassifier*: \n{'criterion': 'entropy', 'max_depth': '20', 'random_state': '77', 'meu_parametro_personalizado': 'teste'}. \n\n\n- **TrainingDatasetsNames.pkl**: Deve conter os tipos de datasets e os nomes dos respectivos arquivos utilizados no\ntreinamento do modelo. Exemplo: {'features': 'nome_arquivo_features', 'targets': 'nome_arquivo_targets'}.\n\n\n- **BaselineMetrics.pkl**: Deve conter as métricas que você achar relevantes para decidir se o modelo precisa ser \nretreinado. Por exemplo, você poderia definir a métrica acurácia mínima e caso o modelo que estiver em produção, ao ser \navaliado, não estiver atingindo o valor dessa métrica, será um indicativo de que ele precisa ser retreinado. Outro exemplo \nclaro da necessidade de retreinamento é quando um modelo de classificação é treinado para predizer um conjunto de *labels* \ne por um motivo qualquer surgem novos *labels*, nesse caso o modelo não saberá predizer estes *labels* e necessitará \nser retreinado em um dataset atualizado com os novos *labels*. Exemplo: {'acuracia_minima': 0.94, \n'labels_presentes_no_treino': ['gato', 'cachorro']}.\n\n**NOTA**: Estes artefatos deverão ser criados pelo script utilizado para registro dos experimentos no processo de \ntreinamento do modelo e salvos através da função '**mlflow.log_artifact**', no momento da realização dos experimentos. Os \nartefatos salvos junto com o modelo devem ser utilizados na implementação das funcionalidades das interfaces no momento \nda construção dos *workers*. A única maneira de obter parâmetros e informações acerca do modelo registrado será por \nintermédio destes artefatos. Por favor, não persista nada localmente, pois os *workers* não trocarão mensagens nem \ncompartilharão acesso à dados entre si.\n\nPara implementar as interfaces e construir os *workers* basta editar os *templates* conforme abaixo:\n\n**REGRAS**: Implemente todos os métodos solicitados respeitando os tipos dos parâmetros e de retorno. Não troque os \nnomes dos parâmetros.\n\n**worker_pub**:\n\n- Abra o arquivo '**pub.py**', que se encontra na pasta '**worker_pub**', e implemente os métodos da interface \n**ModelPublicationInterfaceCLF** através da classe **ModeloCLF**. Leia os comentários, eles te guiarão na implementação.\n\n**worker_retrain**:\n\n- Abra o arquivo '**retrain.py**', que se encontra na pasta '**worker_retrain**', e implemente os métodos da interface \n**ModelPublicationInterfaceRETRAIN** através da classe **ModeloRETRAIN**. Leia os comentários, eles te guiarão na \nimplementação.\n\nA lib disponibiliza vários métodos úteis que auxiliarão na implementação das interfaces. \nTodos os métodos estão documentados via [docstrings](https://peps.python.org/pep-0257/) que, geralmente, são \nrenderizadas pelas IDEs ou editores de código facilitando a leitura da documentação. Veja alguns métodos úteis disponíveis:\n\n- **make_log** - Criação do arquivo para geração de logs.\n- **load_datasets** - Carga de datasets.\n- **load_model** - Carga de modelos salvos.\n- **load_production_params**, **load_production_datasets_names**, **load_production_baseline** - Carga das informações \ndos modelos publicados, salvas através dos artefatos obrigatórios.\n- **convert_artifact_to_pickle** - Conversão de um artefato para o formato pickle.\n- **convert_artifact_to_object** - Conversão de um artefato que está no formato pickle para o objeto de origem.\n\nExplore a documentação para saber das possibilidades de uso da lib.\n\n### Teste o código produzido!\nO repositório da lib disponibiliza os scripts '**test_pub.py**' e '**test_retrain.py**' para realização de testes para \nverificar se alguns requisitos solicitados estão sendo atendidos. Também é possível criar testes personalizados através da \nimplementação da função '**test**' que se encontra nos scripts '**mytest_pub.py**' e '**mytest_retrain.py**'. Todos \nestes scripts estão nas pastas **worker_pub** e **worker_retrain**.\n\nPara testar o seu código siga as instruções abaixo:\n\n- Caso o servidor do MLflow não esteja rodando, entre na pasta onde o código/script para registro dos experimentos/modelo \nse encontra; ative o ambiente virtual Python, instruções: [Linux e Windows (escolha o sistema na página)](https://packaging.python.org/en/latest/guides/installing-using-pip-and-virtual-environments/#creating-a-virtual-environment),\ne inicie o servidor do MLflow:\n```bash\nmlflow server --backend-store-uri sqlite:///teste_mlflow.db --host 0.0.0.0 -p 5000 --default-artifact-root mlruns\n```\n- Obtenha o caminho completo da pasta '**mlruns**' (ela é criada dentro da pasta onde o script para geração dos \nexperimentos/modelo foi executado);\n\n\n- Se for testar o *worker* pub, entre na pasta '**worker_pub**' e execute o comando abaixo. Lembre-se de informar o \ncaminho completo da pasta '**mlruns**' através do parâmetro '**--mlruns_path**';\n```bash\npython test_pub.py --mlruns_path=\"caminho completo para a pasta mlruns\"\n```\n- Se for testar o *worker* retrain, entre na pasta '**worker_retrain**' e execute o comando abaixo. Lembre-se de \ninformar o caminho completo da pasta '**mlruns**' através do parâmetro '**--mlruns_path**';\n```bash\npython test_retrain.py --mlruns_path=\"caminho completo para a pasta mlruns\"\n```\n\nLeia atentamente as mensagens e caso exista alguma inconsistência no teste, atenda ao que for solicitado pelo script.\n\n## 4. Disponibilize o código para publicação do modelo\n\nAntes de enviar os códigos, certifique-se que eles estão funcionando de acordo com as regras estabelecidas e que os \narquivos com os *requirements* foram gerados corretamente. Se ocorrer algum erro que impeça a publicação, entraremos \nem contato para informar o ocorrido e fornecer as informações sobre o erro. \n\nPara disponibilizar o modelo para publicação:\n\n- Crie uma pasta chamada '**publicar**';\n- Copie as pastas '**worker_pub**' e '**worker_retrain**' para a pasta '**publicar**' (**não** incluir a pasta \n'**env**', que é do ambiente virtual Python, nem a pasta '**temp_area**', que é utilizada para guardar arquivos \ntemporários) ;\n- Gere um arquivo de *requirements.txt* para o código responsável pelo registro dos experimentos/modelo;\n- Copie a pasta que contém o código responsável pelo registro dos experimentos/modelo para a pasta publicar (**não** \nincluir a pasta '**env**' e arquivos desnecessários);\n- Compacte a pasta '**publicar**' utilizando o formato '.zip';\n- Envie o arquivo '**publicar.zip**' para o Prodest, conforme alinhamento prévio realizado em reunião ou qualquer \noutro meio de contato.\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/prodest/mllibprodest",
    "keywords": "Prodest,ML,lib,stack",
    "license": "GPLv3",
    "maintainer": "",
    "maintainer_email": "",
    "name": "mllibprodest",
    "package_url": "https://pypi.org/project/mllibprodest/",
    "platform": null,
    "project_url": "https://pypi.org/project/mllibprodest/",
    "project_urls": {
      "Bug Tracker": "https://github.com/prodest/mllibprodest/issues",
      "Documentation": "https://prodest.github.io/mllibprodest",
      "Homepage": "https://github.com/prodest/mllibprodest"
    },
    "release_url": "https://pypi.org/project/mllibprodest/1.5.1/",
    "requires_dist": [
      "minio (==7.1.12)",
      "python-dotenv (==0.21.0)",
      "mlflow (==1.29.0)",
      "boto3 (==1.24.89)"
    ],
    "requires_python": ">=3.8",
    "summary": "Biblioteca de Machine Learning (ML) do Prodest.",
    "version": "1.5.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 15352198,
  "releases": {
    "1.5.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "458e2f1ab748aad236f5682d988d03e8f2caa099ed4fee700c206673f67a2082",
          "md5": "294f3633a506fc2030290a9f46de2a12",
          "sha256": "4d60e06da0f5791e07722ef5e3c4ff9e59899144a2154d74a509da2255fa429d"
        },
        "downloads": -1,
        "filename": "mllibprodest-1.5.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "294f3633a506fc2030290a9f46de2a12",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 39106,
        "upload_time": "2022-10-09T04:22:32",
        "upload_time_iso_8601": "2022-10-09T04:22:32.240232Z",
        "url": "https://files.pythonhosted.org/packages/45/8e/2f1ab748aad236f5682d988d03e8f2caa099ed4fee700c206673f67a2082/mllibprodest-1.5.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d7cedd747df17561a3bfd062f94e831dc69730c5b9a81615b44c36bdd1af4acb",
          "md5": "479b950abc20d58e555c63668c91cb70",
          "sha256": "82ff3083474a25f9dd7d23474459c2dfc4ddf067037b888fc8e23902248eea72"
        },
        "downloads": -1,
        "filename": "mllibprodest-1.5.0.tar.gz",
        "has_sig": false,
        "md5_digest": "479b950abc20d58e555c63668c91cb70",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 42076,
        "upload_time": "2022-10-09T04:22:34",
        "upload_time_iso_8601": "2022-10-09T04:22:34.918554Z",
        "url": "https://files.pythonhosted.org/packages/d7/ce/dd747df17561a3bfd062f94e831dc69730c5b9a81615b44c36bdd1af4acb/mllibprodest-1.5.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.5.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f3a77ba57bbdc22edd279666c203833b1b124595be38ef6e2a6842fd2742fc57",
          "md5": "f6fd6008c03a3687f2c0510864fbec92",
          "sha256": "d0715c7d4d7f9d78d7added7b8407eb7ece9fead65545c1ddfa5c665fe63277e"
        },
        "downloads": -1,
        "filename": "mllibprodest-1.5.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f6fd6008c03a3687f2c0510864fbec92",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 39114,
        "upload_time": "2022-10-09T15:18:45",
        "upload_time_iso_8601": "2022-10-09T15:18:45.906878Z",
        "url": "https://files.pythonhosted.org/packages/f3/a7/7ba57bbdc22edd279666c203833b1b124595be38ef6e2a6842fd2742fc57/mllibprodest-1.5.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ffd03c9840f900c755f53502637036b72f06c10639c219498738c96b1e6973d9",
          "md5": "c14522cd4841429d5e4610e4b4c020db",
          "sha256": "dbd10b815f5b7d2a978d41525e108d074721ee85035a9b2c5e503d86e11f8107"
        },
        "downloads": -1,
        "filename": "mllibprodest-1.5.1.tar.gz",
        "has_sig": false,
        "md5_digest": "c14522cd4841429d5e4610e4b4c020db",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 42097,
        "upload_time": "2022-10-09T15:18:48",
        "upload_time_iso_8601": "2022-10-09T15:18:48.871455Z",
        "url": "https://files.pythonhosted.org/packages/ff/d0/3c9840f900c755f53502637036b72f06c10639c219498738c96b1e6973d9/mllibprodest-1.5.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "f3a77ba57bbdc22edd279666c203833b1b124595be38ef6e2a6842fd2742fc57",
        "md5": "f6fd6008c03a3687f2c0510864fbec92",
        "sha256": "d0715c7d4d7f9d78d7added7b8407eb7ece9fead65545c1ddfa5c665fe63277e"
      },
      "downloads": -1,
      "filename": "mllibprodest-1.5.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "f6fd6008c03a3687f2c0510864fbec92",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.8",
      "size": 39114,
      "upload_time": "2022-10-09T15:18:45",
      "upload_time_iso_8601": "2022-10-09T15:18:45.906878Z",
      "url": "https://files.pythonhosted.org/packages/f3/a7/7ba57bbdc22edd279666c203833b1b124595be38ef6e2a6842fd2742fc57/mllibprodest-1.5.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "ffd03c9840f900c755f53502637036b72f06c10639c219498738c96b1e6973d9",
        "md5": "c14522cd4841429d5e4610e4b4c020db",
        "sha256": "dbd10b815f5b7d2a978d41525e108d074721ee85035a9b2c5e503d86e11f8107"
      },
      "downloads": -1,
      "filename": "mllibprodest-1.5.1.tar.gz",
      "has_sig": false,
      "md5_digest": "c14522cd4841429d5e4610e4b4c020db",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.8",
      "size": 42097,
      "upload_time": "2022-10-09T15:18:48",
      "upload_time_iso_8601": "2022-10-09T15:18:48.871455Z",
      "url": "https://files.pythonhosted.org/packages/ff/d0/3c9840f900c755f53502637036b72f06c10639c219498738c96b1e6973d9/mllibprodest-1.5.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}