{
  "info": {
    "author": "Phil Wang",
    "author_email": "lucidrains@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3.6",
      "Topic :: Scientific/Engineering :: Artificial Intelligence"
    ],
    "description": "",
    "description_content_type": "",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/lucidrains/linear-attention",
    "keywords": "transformers,attention,artificial intelligence",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "linear-attention",
    "package_url": "https://pypi.org/project/linear-attention/",
    "platform": "",
    "project_url": "https://pypi.org/project/linear-attention/",
    "project_urls": {
      "Homepage": "https://github.com/lucidrains/linear-attention"
    },
    "release_url": "https://pypi.org/project/linear-attention/0.2.0/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "Linear Attention Transformer",
    "version": "0.2.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 7419850,
  "releases": {
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6a3137bbe8a9af0552eed94d9df9aa9b0d15831d81a23239dd66f668244e99a1",
          "md5": "a75c4cc86a03b89bd1694518c2d302bf",
          "sha256": "2107b3b07918bc519c9546d0d76cd89d6818c24ed0264ee05200ddefc74ab464"
        },
        "downloads": -1,
        "filename": "linear_attention-0.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "a75c4cc86a03b89bd1694518c2d302bf",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 3399,
        "upload_time": "2020-06-07T23:30:23",
        "upload_time_iso_8601": "2020-06-07T23:30:23.292037Z",
        "url": "https://files.pythonhosted.org/packages/6a/31/37bbe8a9af0552eed94d9df9aa9b0d15831d81a23239dd66f668244e99a1/linear_attention-0.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "6a3137bbe8a9af0552eed94d9df9aa9b0d15831d81a23239dd66f668244e99a1",
        "md5": "a75c4cc86a03b89bd1694518c2d302bf",
        "sha256": "2107b3b07918bc519c9546d0d76cd89d6818c24ed0264ee05200ddefc74ab464"
      },
      "downloads": -1,
      "filename": "linear_attention-0.2.0.tar.gz",
      "has_sig": false,
      "md5_digest": "a75c4cc86a03b89bd1694518c2d302bf",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 3399,
      "upload_time": "2020-06-07T23:30:23",
      "upload_time_iso_8601": "2020-06-07T23:30:23.292037Z",
      "url": "https://files.pythonhosted.org/packages/6a/31/37bbe8a9af0552eed94d9df9aa9b0d15831d81a23239dd66f668244e99a1/linear_attention-0.2.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}