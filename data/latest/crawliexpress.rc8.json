{
  "info": {
    "author": "ToucanTocard",
    "author_email": "contact@robin.ninja",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Crawliexpress\n\n- [Crawliexpress](#crawliexpress)\n  - [Description](#description)\n  - [Usage](#usage)\n    - [Install](#install)\n    - [Item](#item)\n    - [Feedbacks](#feedbacks)\n    - [Search / Category](#search--category)\n  - [API](#api)\n\n## Description\n\nAllows to fetch various resources from Aliexpress, such as category, text search, product, feedbacks.\n\nIt does not use official API nor a headless browser, but parses page source.\n\nObviously, it is very vulnerable to DOM changes.\n\n## Usage\n\n### Install\n\n```bash\npip install crawliexpress\n```\n\n### Item\n\n```python\nfrom crawliexpress import Client\n\nclient = Client(\"https://www.aliexpress.com\")\nclient.get_item(\"4000505787173\")\n```\n\n### Feedbacks\n\n```python\nfrom crawliexpress import Client\n\nfrom pprint import pprint\nfrom time import sleep\n\nclient = Client(\"https://www.aliexpress.com\")\nitem = client.get_item(\"20000001708485\")\n\npage = 1\npages = list()\nwhile True:\n    feedback_page = client.get_feedbacks(\n        item.product_id,\n        item.owner_member_id,\n        item.company_id,\n        with_picture=True,\n        page=page,\n    )\n    print(feedback_page.page)\n    if feedback_page.has_next_page() is False:\n        break\n    page += 1\n    sleep(1)\n```\n\n### Category\n\n```python\nfrom crawliexpress import Client\n\nfrom time import sleep\n\nclient = Client(\n    \"https://www.aliexpress.com\",\n    # copy it from your browser cookies\n    \"xxxx\",\n)\n\npage = 1\nwhile True:\n    search_page = client.get_category(205000314, \"t-shirts\", page=page)\n    print(search_page.page)\n    if search_page.has_next_page() is False:\n        break\n    page += 1\n    sleep(1)\n```\n\n- Cookies must be taken from your browser cookies, to avoid captcha and empty results. I usually login then copy as cURL a request made by my browser on a category or a text search. Make sure to remove the `Cookie: ` prefix to keep only cookie values.\n\n### Search\n\n```python\nfrom crawliexpress import Client\n\nfrom time import sleep\n\nclient = Client(\n    \"https://www.aliexpress.com\",\n    # copy it from your browser cookies\n    \"xxxx\",\n)\n\npage = 1\nwhile True:\n    search_page = client.get_search(\"akame ga kill\", page=page)\n    print(search_page.page)\n    if search_page.has_next_page() is False:\n        break\n    page += 1\n    sleep(1)\n```\n\n- Cookies must be taken from your browser cookies, to avoid captcha and empty results. I usually login then copy as cURL a request made by my browser on a category or a text search. Make sure to remove the `Cookie: ` prefix to keep only cookie values.\n\n## API\n\n### class crawliexpress.Category(client, category_id, category_name, sort_by='default')\nA category\n\n\n* **Parameters**\n\n\n    * **category_id** – id of the category, category id of [https://www.aliexpress.com/category/205000221/t-shirts.html](https://www.aliexpress.com/category/205000221/t-shirts.html) is 205000220\n\n\n    * **category_name** – name of the category, category name of [https://www.aliexpress.com/category/205000221/t-shirts.html](https://www.aliexpress.com/category/205000221/t-shirts.html) is t-shirts\n\n\n    * **sort_by** (**default**: best match\n    **total_tranpro_desc**: number of orders) – indeed\n\n\n\n### class crawliexpress.Client(base_url, cookies=None)\nExposes methods to fetch various resources.\n\n\n* **Parameters**\n\n\n    * **base_url** – allows to change locale (not sure about this one)\n\n\n    * **cookies** – must be taken from your browser cookies, to avoid captcha and empty results. I usually login then copy as cURL a request made by my browser on a category or a text search. Make sure to remove the **Cookie:** prefix to keep only cookie values.\n\n\n\n#### get_category(category_id, category_name, page=1, sort_by='default')\nFetches a category page\n\n\n* **Parameters**\n\n\n    * **category_id** – id of the category, category id of [https://www.aliexpress.com/category/205000221/t-shirts.html](https://www.aliexpress.com/category/205000221/t-shirts.html) is 205000220\n\n\n    * **category_name** – name of the category, category name of [https://www.aliexpress.com/category/205000221/t-shirts.html](https://www.aliexpress.com/category/205000221/t-shirts.html) is t-shirts\n\n\n    * **page** – page number\n\n\n    * **sort_by** (**default**: best match\n    **total_tranpro_desc**: number of orders) – indeed\n\n\n\n* **Returns**\n\n    a search page\n\n\n\n* **Return type**\n\n    Crawliexpress.SearchPage\n\n\n\n* **Raises**\n\n\n    * **CrawliexpressException** – if there was an error fetching the dataz\n\n\n    * **CrawliexpressCaptchaException** – if there is a captcha, make sure to use valid cookies to avoid this\n\n\n\n#### get_feedbacks(product_id, owner_member_id, company_id=None, v=2, member_type='seller', page=1, with_picture=False)\nFetches a product feedback page\n\n\n* **Parameters**\n\n\n    * **product_id** – id of the product, item id of [https://www.aliexpress.com/item/20000001708485.html](https://www.aliexpress.com/item/20000001708485.html) is 20000001708485\n\n\n    * **owner_member_id** – member id of the product owner, as stored in **Crawliexpress.Item.owner_member_id**\n\n\n    * **page** – page number\n\n\n    * **with_picture** – limit to feedbacks with a picture\n\n\n\n* **Returns**\n\n    a feedback page\n\n\n\n* **Return type**\n\n    Crawliexpress.FeedbackPage\n\n\n\n* **Raises**\n\n    **CrawliexpressException** – if there was an error fetching the dataz\n\n\n\n#### get_item(item_id)\nFetches a product informations from its id\n\n\n* **Parameters**\n\n    **item_id** – id of the product to fetch, item id of [https://www.aliexpress.com/item/20000001708485.html](https://www.aliexpress.com/item/20000001708485.html) is 20000001708485\n\n\n\n* **Returns**\n\n    a product\n\n\n\n* **Return type**\n\n    Crawliexpress.Item\n\n\n\n* **Raises**\n\n    **CrawliexpressException** – if there was an error fetching the dataz\n\n\n\n#### get_search(text, page=1, sort_by='default')\nFetches a search page\n\n\n* **Parameters**\n\n\n    * **text** – text search\n\n\n    * **page** – page number\n\n\n    * **sort_by** (**default**: best match\n    **total_tranpro_desc**: number of orders) – indeed\n\n\n\n* **Returns**\n\n    a search page\n\n\n\n* **Return type**\n\n    Crawliexpress.SearchPage\n\n\n\n* **Raises**\n\n\n    * **CrawliexpressException** – if there was an error fetching the dataz\n\n\n    * **CrawliexpressCaptchaException** – if there is a captcha, make sure to use valid cookies to avoid this\n\n\n\n### exception crawliexpress.CrawliexpressCaptchaException()\n\n### exception crawliexpress.CrawliexpressException()\n\n### class crawliexpress.Feedback()\nA user feedback\n\n\n#### comment( = None)\nReview\n\n\n#### country( = None)\nCountry code\n\n\n#### datetime( = None)\nRaw datetime from DOM\n\n\n#### images( = None)\nList of image links\n\n\n#### profile( = None)\nProfile link\n\n\n#### rating( = None)\nRating out of 100\n\n\n#### user( = None)\nName\n\n\n### class crawliexpress.FeedbackPage()\nA feedback page\n\n\n#### feedbacks( = None)\nList of **Crawliexpress.Feedback** objects\n\n\n#### has_next_page()\nReturns true if there is a following page, useful for crawling\n\n\n* **Return type**\n\n    bool\n\n\n\n#### known_pages( = None)\nSibling pages\n\n\n#### page( = None)\nPage number\n\n\n### class crawliexpress.Search(client, text, sort_by='default')\nA search\n\n\n* **Parameters**\n\n\n    * **text** – text search\n\n\n    * **sort_by** (**default**: best match\n    **total_tranpro_desc**: number of orders) – indeed\n\n\n\n### class crawliexpress.SearchPage()\nA search page\n\n\n#### has_next_page()\nReturns true if there is a following page, useful for crawling\n\n\n* **Return type**\n\n    bool\n\n\n\n#### items( = None)\nList of products, raw from JS parsing\n\n\n#### page( = None)\npage number\n\n\n#### result_count( = None)\nNumber of result for the whole search\n\n\n#### size_per_page( = None)\nNumber of result per page\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/toucantocard/crawliexpress",
    "keywords": "aliexpress",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "crawliexpress",
    "package_url": "https://pypi.org/project/crawliexpress/",
    "platform": "",
    "project_url": "https://pypi.org/project/crawliexpress/",
    "project_urls": {
      "Homepage": "https://github.com/toucantocard/crawliexpress"
    },
    "release_url": "https://pypi.org/project/crawliexpress/0.1.7/",
    "requires_dist": [
      "requests",
      "jsonnet",
      "bs4",
      "lxml",
      "sphinx-rtd-theme",
      "sphinx-markdown-builder"
    ],
    "requires_python": ">=3.6",
    "summary": "Python3 library to ease Aliexpress crawling",
    "version": "0.1.7",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8374911,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d0cf56e7efdbb9e8f262b8e850674b4ee0f8471e9e988f87d87b9008ad2b7bd2",
          "md5": "3f97f97a97658b6e446e8cab31459e3e",
          "sha256": "44179f6125d8f61157b3d41f0a7431f6942245a8c1f23f57eb65cb473f338ab5"
        },
        "downloads": -1,
        "filename": "crawliexpress-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "3f97f97a97658b6e446e8cab31459e3e",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 8666,
        "upload_time": "2020-09-30T16:05:25",
        "upload_time_iso_8601": "2020-09-30T16:05:25.577596Z",
        "url": "https://files.pythonhosted.org/packages/d0/cf/56e7efdbb9e8f262b8e850674b4ee0f8471e9e988f87d87b9008ad2b7bd2/crawliexpress-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "22d02ad168c3475908cf275633f7e0f2b84f3fd4c01c5008ffddbc8934dced9a",
          "md5": "4fc3feb332e718638f9b7788902955f1",
          "sha256": "fa72b912b98c87686272f6446743e9d59869eeaa8f1d81f38a7c95f7de1e7e48"
        },
        "downloads": -1,
        "filename": "crawliexpress-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "4fc3feb332e718638f9b7788902955f1",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 8969,
        "upload_time": "2020-09-30T16:05:28",
        "upload_time_iso_8601": "2020-09-30T16:05:28.401965Z",
        "url": "https://files.pythonhosted.org/packages/22/d0/2ad168c3475908cf275633f7e0f2b84f3fd4c01c5008ffddbc8934dced9a/crawliexpress-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "43bcf83dce26942cbf8d23f0927b616c32594e2ff51ac93c12f0841b3bc78f22",
          "md5": "53623459b79859f5cdff500ff17c4584",
          "sha256": "3e7bd7542fce8fbd551a5ce3087988b3ce2609d948829814f59f3c73d995ebbe"
        },
        "downloads": -1,
        "filename": "crawliexpress-0.1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "53623459b79859f5cdff500ff17c4584",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 8802,
        "upload_time": "2020-10-02T12:25:36",
        "upload_time_iso_8601": "2020-10-02T12:25:36.825844Z",
        "url": "https://files.pythonhosted.org/packages/43/bc/f83dce26942cbf8d23f0927b616c32594e2ff51ac93c12f0841b3bc78f22/crawliexpress-0.1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d3ea25b3c9d065b1641eb3cf1fe1c8078f3adc03965b1a7f32822a1803827206",
          "md5": "047240dd404de415a59f3e43aa5aed32",
          "sha256": "8fd6312e74191b1a9001f1ee60db9eb7b8f04b8fae33dfc16985cf7515871293"
        },
        "downloads": -1,
        "filename": "crawliexpress-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "047240dd404de415a59f3e43aa5aed32",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 9127,
        "upload_time": "2020-10-02T12:25:38",
        "upload_time_iso_8601": "2020-10-02T12:25:38.902444Z",
        "url": "https://files.pythonhosted.org/packages/d3/ea/25b3c9d065b1641eb3cf1fe1c8078f3adc03965b1a7f32822a1803827206/crawliexpress-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "522dd0f0e59bb3a6e8f3767d8e33322bc7226603201e3ea3c5a8ed0c5853a022",
          "md5": "a97ce258f07947710a2bf1223d2d568d",
          "sha256": "07e90567a0173d2578824ddd9e4ade4a8f09dc13580092d6567427d199f07bd0"
        },
        "downloads": -1,
        "filename": "crawliexpress-0.1.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "a97ce258f07947710a2bf1223d2d568d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 9394,
        "upload_time": "2020-10-06T11:15:11",
        "upload_time_iso_8601": "2020-10-06T11:15:11.063726Z",
        "url": "https://files.pythonhosted.org/packages/52/2d/d0f0e59bb3a6e8f3767d8e33322bc7226603201e3ea3c5a8ed0c5853a022/crawliexpress-0.1.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "97714c7a5aa67c188015678a90dc7a6877d25073ac643dd7294c4970e534d43a",
          "md5": "653f85d3431f8d353fcf7589151bbc3a",
          "sha256": "885aa7d3a2bcc049a9dd556be6f5d0780e531765653b3e75da18edde46ae99cc"
        },
        "downloads": -1,
        "filename": "crawliexpress-0.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "653f85d3431f8d353fcf7589151bbc3a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 8459,
        "upload_time": "2020-10-06T11:15:12",
        "upload_time_iso_8601": "2020-10-06T11:15:12.366730Z",
        "url": "https://files.pythonhosted.org/packages/97/71/4c7a5aa67c188015678a90dc7a6877d25073ac643dd7294c4970e534d43a/crawliexpress-0.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c9688db66a05c2a7e66ac2f9fe24276b3e98a6a23aa739287f3369f98fa2bb79",
          "md5": "8da63217c5ac9208a27ce137ddb67fb9",
          "sha256": "c5b544da5a210316b78ca848a8f42ce418af380a71d28974493f5f9727cfa2db"
        },
        "downloads": -1,
        "filename": "crawliexpress-0.1.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "8da63217c5ac9208a27ce137ddb67fb9",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 10316,
        "upload_time": "2020-10-06T15:22:13",
        "upload_time_iso_8601": "2020-10-06T15:22:13.627636Z",
        "url": "https://files.pythonhosted.org/packages/c9/68/8db66a05c2a7e66ac2f9fe24276b3e98a6a23aa739287f3369f98fa2bb79/crawliexpress-0.1.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5ec459ee1053b4c48bd0f5814fa8d48dbfaf65f53d482e14883561fe9249dbd2",
          "md5": "a81d5a4f9011f346659bf97d64bdb09d",
          "sha256": "a209394a5f1a9ce806c7f97248ee010fba1fcaaaa2213b4c6dde1ddecee5242d"
        },
        "downloads": -1,
        "filename": "crawliexpress-0.1.3.tar.gz",
        "has_sig": false,
        "md5_digest": "a81d5a4f9011f346659bf97d64bdb09d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 8796,
        "upload_time": "2020-10-06T15:22:15",
        "upload_time_iso_8601": "2020-10-06T15:22:15.008754Z",
        "url": "https://files.pythonhosted.org/packages/5e/c4/59ee1053b4c48bd0f5814fa8d48dbfaf65f53d482e14883561fe9249dbd2/crawliexpress-0.1.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4512b9a8763bd9da871aae3b16efdd6fa4e758a1560d7872a09eaf3315988f0c",
          "md5": "e51a4185108b9db69e57b673920bc33d",
          "sha256": "e0bfb33f5a7d08b455ecd05240c994d2b4d765c43d2c942fc8e81f28a04599bd"
        },
        "downloads": -1,
        "filename": "crawliexpress-0.1.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "e51a4185108b9db69e57b673920bc33d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 10308,
        "upload_time": "2020-10-06T16:34:45",
        "upload_time_iso_8601": "2020-10-06T16:34:45.665018Z",
        "url": "https://files.pythonhosted.org/packages/45/12/b9a8763bd9da871aae3b16efdd6fa4e758a1560d7872a09eaf3315988f0c/crawliexpress-0.1.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1308340b3d11668707ecb48b00426f16fbeaf057868d7675bce485813d6adfa7",
          "md5": "0391cebab896942cab6e715d93950655",
          "sha256": "4799a3eda8f43bb883ed07b670cbd89014244f87269dd0a876b7068147cee1fd"
        },
        "downloads": -1,
        "filename": "crawliexpress-0.1.4.tar.gz",
        "has_sig": false,
        "md5_digest": "0391cebab896942cab6e715d93950655",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 8812,
        "upload_time": "2020-10-06T16:34:46",
        "upload_time_iso_8601": "2020-10-06T16:34:46.984062Z",
        "url": "https://files.pythonhosted.org/packages/13/08/340b3d11668707ecb48b00426f16fbeaf057868d7675bce485813d6adfa7/crawliexpress-0.1.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a971effcde496058bd232ff09cef1c3ebb538ff42903e8aa89f650765fbf92ca",
          "md5": "6a1821f210239812ada41f1127f5c6b9",
          "sha256": "c2036486d4e346e0eb9e1735b53c8f21c0bcf0fa5b0a18029f2a3a884bef8175"
        },
        "downloads": -1,
        "filename": "crawliexpress-0.1.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "6a1821f210239812ada41f1127f5c6b9",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 10397,
        "upload_time": "2020-10-08T13:06:07",
        "upload_time_iso_8601": "2020-10-08T13:06:07.714783Z",
        "url": "https://files.pythonhosted.org/packages/a9/71/effcde496058bd232ff09cef1c3ebb538ff42903e8aa89f650765fbf92ca/crawliexpress-0.1.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2f06e2ac6157e4e5e492b1d647ed55ad5ebe9a055a03fbf556aa2849a834b8d8",
          "md5": "a900ac0aba29ec02fdb326064455ee19",
          "sha256": "f955ba15222a69036ac85c22f34389954500672ba6b71775e2556841c5dffacb"
        },
        "downloads": -1,
        "filename": "crawliexpress-0.1.5.tar.gz",
        "has_sig": false,
        "md5_digest": "a900ac0aba29ec02fdb326064455ee19",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 8972,
        "upload_time": "2020-10-08T13:06:08",
        "upload_time_iso_8601": "2020-10-08T13:06:08.988673Z",
        "url": "https://files.pythonhosted.org/packages/2f/06/e2ac6157e4e5e492b1d647ed55ad5ebe9a055a03fbf556aa2849a834b8d8/crawliexpress-0.1.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d706cbfdbdb34c0819debc9ff8c148abfa6af0674d6c6dc28a914f02b0fb04dd",
          "md5": "7c6ae227fd2c629dae6b4ddcbec6c870",
          "sha256": "b5741f7179fec6c68023a9431aa38cc51efa1000e87b93dd9ccb4b2d60fc54d1"
        },
        "downloads": -1,
        "filename": "crawliexpress-0.1.6-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "7c6ae227fd2c629dae6b4ddcbec6c870",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 10428,
        "upload_time": "2020-10-08T13:18:25",
        "upload_time_iso_8601": "2020-10-08T13:18:25.625161Z",
        "url": "https://files.pythonhosted.org/packages/d7/06/cbfdbdb34c0819debc9ff8c148abfa6af0674d6c6dc28a914f02b0fb04dd/crawliexpress-0.1.6-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b54505b7b19e7e42b03588c1f37ddef3758b183fd0a53a74cf4be4ec57c70105",
          "md5": "07388b0bd71c06b55f445cdb038cf31d",
          "sha256": "405fa2b34b363bdccb0ab56ad345fa075cdf39be22913332283e5adc5e841aaa"
        },
        "downloads": -1,
        "filename": "crawliexpress-0.1.6.tar.gz",
        "has_sig": false,
        "md5_digest": "07388b0bd71c06b55f445cdb038cf31d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 9029,
        "upload_time": "2020-10-08T13:18:26",
        "upload_time_iso_8601": "2020-10-08T13:18:26.772143Z",
        "url": "https://files.pythonhosted.org/packages/b5/45/05b7b19e7e42b03588c1f37ddef3758b183fd0a53a74cf4be4ec57c70105/crawliexpress-0.1.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a1306b0f7d5135ade0f358dea941e16633317c560a730e6e4cb68305be7074c8",
          "md5": "41df33f9b19a08d198a3cf6b45c06c7f",
          "sha256": "7146a70f29a81541a4e51a44d8e29d16a7515e726410669f82681d9c57ef37e7"
        },
        "downloads": -1,
        "filename": "crawliexpress-0.1.7-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "41df33f9b19a08d198a3cf6b45c06c7f",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 10427,
        "upload_time": "2020-10-09T10:26:25",
        "upload_time_iso_8601": "2020-10-09T10:26:25.554864Z",
        "url": "https://files.pythonhosted.org/packages/a1/30/6b0f7d5135ade0f358dea941e16633317c560a730e6e4cb68305be7074c8/crawliexpress-0.1.7-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4088a29336361568e093ff94a60ea336771c3b6d4c35eb758f12af43adb31678",
          "md5": "a8629de4968359a9e964b0f536c21a51",
          "sha256": "380b0a45716a34aa87afc33b2c92597285b5f8520268a7179164e30c5dceb9f9"
        },
        "downloads": -1,
        "filename": "crawliexpress-0.1.7.tar.gz",
        "has_sig": false,
        "md5_digest": "a8629de4968359a9e964b0f536c21a51",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 9035,
        "upload_time": "2020-10-09T10:26:26",
        "upload_time_iso_8601": "2020-10-09T10:26:26.660684Z",
        "url": "https://files.pythonhosted.org/packages/40/88/a29336361568e093ff94a60ea336771c3b6d4c35eb758f12af43adb31678/crawliexpress-0.1.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "a1306b0f7d5135ade0f358dea941e16633317c560a730e6e4cb68305be7074c8",
        "md5": "41df33f9b19a08d198a3cf6b45c06c7f",
        "sha256": "7146a70f29a81541a4e51a44d8e29d16a7515e726410669f82681d9c57ef37e7"
      },
      "downloads": -1,
      "filename": "crawliexpress-0.1.7-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "41df33f9b19a08d198a3cf6b45c06c7f",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 10427,
      "upload_time": "2020-10-09T10:26:25",
      "upload_time_iso_8601": "2020-10-09T10:26:25.554864Z",
      "url": "https://files.pythonhosted.org/packages/a1/30/6b0f7d5135ade0f358dea941e16633317c560a730e6e4cb68305be7074c8/crawliexpress-0.1.7-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "4088a29336361568e093ff94a60ea336771c3b6d4c35eb758f12af43adb31678",
        "md5": "a8629de4968359a9e964b0f536c21a51",
        "sha256": "380b0a45716a34aa87afc33b2c92597285b5f8520268a7179164e30c5dceb9f9"
      },
      "downloads": -1,
      "filename": "crawliexpress-0.1.7.tar.gz",
      "has_sig": false,
      "md5_digest": "a8629de4968359a9e964b0f536c21a51",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 9035,
      "upload_time": "2020-10-09T10:26:26",
      "upload_time_iso_8601": "2020-10-09T10:26:26.660684Z",
      "url": "https://files.pythonhosted.org/packages/40/88/a29336361568e093ff94a60ea336771c3b6d4c35eb758f12af43adb31678/crawliexpress-0.1.7.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}