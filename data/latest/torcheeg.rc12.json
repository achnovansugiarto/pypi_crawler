{
  "info": {
    "author": "TorchEEG Team",
    "author_email": "tczhangzhi@gmail.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "TorchEEG\n========\n\n|PyPI Version| |Docs Status| |Downloads| |Join the Chat|\n\n`Documentation <https://torcheeg.readthedocs.io/>`__ \\| `TorchEEG\nExamples <https://github.com/tczhangzhi/torcheeg/tree/main/examples>`__\n\nTorchEEG is a library built on PyTorch for EEG signal analysis. TorchEEG\naims to provide a plug-and-play EEG analysis tool, so that researchers\ncan quickly reproduce EEG analysis work and start new EEG analysis\nresearch without paying attention to technical details unrelated to the\nresearch focus.\n\nTorchEEG specifies a unified data input-output format (IO) and implement\ncommonly used EEG databases, allowing users to quickly access benchmark\ndatasets and define new custom datasets. The datasets that have been\ndefined so far include emotion recognition and so on. According to\npapers published in the field of EEG analysis, TorchEEG provides data\npreprocessing methods commonly used for EEG signals, and provides\nplug-and-play API for both offline and online pre-proocessing. Offline\nprocessing allow users to process once and use any times, speeding up\nthe training process. Online processing allows users to save time when\ncreating new data processing methods. TorchEEG also provides deep\nlearning models following published papers for EEG analysis, including\nconvolutional neural networks, graph convolutional neural networks, and\nTransformers.\n\nInstallation\n------------\n\nTorchEEG depends on PyTorch, please complete the installation of PyTorch\naccording to the system, CUDA version and other information:\n\n.. code:: shell\n\n   # Conda\n   # please refer to https://pytorch.org/get-started/locally/\n   # e.g. CPU version\n   conda install pytorch==1.11.0 torchvision torchaudio cpuonly -c pytorch\n   # e.g. GPU version\n   conda install pytorch==1.11.0 torchvision torchaudio cudatoolkit=11.3 -c pytorch\n\n   # Pip\n   # please refer to https://pytorch.org/get-started/previous-versions/\n   # e.g. CPU version\n   pip install torch==1.11.0+cpu torchvision==0.12.0+cpu torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cpu\n   # e.g. GPU version\n   pip install torch==1.11.0+cu102 torchvision==0.12.0+cu102 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu102\n\nAnaconda\n~~~~~~~~\n\nSince version v1.0.10, torcheeg supports installing with conda! You can\nsimply install TorchEEG using Anaconda, just run the following command:\n\n.. code:: shell\n\n   conda install -c tczhangzhi -c conda-forge torcheeg\n\nPip\n~~~\n\nTorchEEG allows pip-based installation, please use the following\ncommand:\n\n.. code:: shell\n\n   pip install torcheeg\n\nNightly\n~~~~~~~\n\nIn case you want to experiment with the latest TorchEEG features which\nare not fully released yet, please run the following command to install\nfrom the main branch on github:\n\n.. code:: shell\n\n   pip install git+https://github.com/tczhangzhi/torcheeg.git\n\nPlugin\n~~~~~~\n\nTorchEEG provides plugins related to graph algorithms for converting EEG\nin datasets into graph structures and analyzing them using graph neural\nnetworks. This part of the implementation relies on PyG.\n\nIf you do not use graph-related algorithms, you can skip this part of\nthe installation.\n\n.. code:: shell\n\n   # Conda\n   # please refer to https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html\n   conda install pyg -c pyg\n\n   # Pip\n   # please refer to https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html\n   # e.g. CPU version\n   pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.11.0+cpu.html\n   # e.g. GPU version\n   pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.11.0+cu102.html\n\nMore About TorchEEG\n-------------------\n\nAt a granular level, PyTorch is a library that consists of the following\ncomponents:\n\n+----------------------------------------+-----------------------------+\n| Component                              | Description                 |\n+========================================+=============================+\n| `torcheeg.io <https://torcheeg.readthe | A set of unified input and  |\n| docs.io/en/latest/torcheeg.io.html>`__ | output API is used to store |\n|                                        | the processing results of   |\n|                                        | various EEG databases for   |\n|                                        | more efficient and          |\n|                                        | convenient use.             |\n+----------------------------------------+-----------------------------+\n| `torcheeg.da                           | The packaged benchmark      |\n| tasets <https://torcheeg.readthedocs.i | dataset implementation      |\n| o/en/latest/torcheeg.datasets.html>`__ | provides a multi-process    |\n|                                        | preprocessing interface.    |\n+----------------------------------------+-----------------------------+\n| `torcheeg.transf                       | Extensive EEG preprocessing |\n| orms <https://torcheeg.readthedocs.io/ | methods help users extract  |\n| en/latest/torcheeg.transforms.html>`__ | features, construct EEG     |\n|                                        | signal representations, and |\n|                                        | connect to commonly used    |\n|                                        | deep learning libraries.    |\n+----------------------------------------+-----------------------------+\n| `torcheeg.model_selection              | Extensive dataset           |\n| <https://torcheeg.readthedocs.io/en/la | partitioning methods for    |\n| test/torcheeg.model_selection.html>`__ | users to experiment with    |\n|                                        | different settings.         |\n+----------------------------------------+-----------------------------+\n| `torchee                               | Extensive baseline method   |\n| g.models <https://torcheeg.readthedocs | reproduction.               |\n| .io/en/latest/torcheeg.models.html>`__ |                             |\n+----------------------------------------+-----------------------------+\n\nImplemented Modules\n-------------------\n\nWe list currently supported datasets, transforms, data splitting, and\ndeep learning models by category.\n\n**Datasets:** All datasets rely on a set of efficient IO APIs,\n`torcheeg.io <https://torcheeg.readthedocs.io/en/latest/torcheeg.io.html>`__,\nto store data preprocessing results on disk and read them quickly during\ntraining. Data preprocessing and storage support multiprocessing (speed\nup!).\n\n-  `AMIGOS\n   dataset <https://torcheeg.readthedocs.io/en/latest/torcheeg.datasets.html#amigosdataset>`__\n   from Miranda-Correa et al.: `AMIGOS: A dataset for affect,\n   personality and mood research on individuals and\n   groups <https://ieeexplore.ieee.org/abstract/document/8554112/>`__.\n-  `DREAMER\n   dataset <https://torcheeg.readthedocs.io/en/latest/torcheeg.datasets.html#dreamerdataset>`__\n   from Katsigiannis et al.: `DREAMER: A database for emotion\n   recognition through EEG and ECG signals from wireless low-cost\n   off-the-shelf\n   devices <https://ieeexplore.ieee.org/abstract/document/7887697>`__.\n-  `SEED\n   dataset <https://torcheeg.readthedocs.io/en/latest/torcheeg.datasets.html#seeddataset>`__\n   from Zheng et al.: `Investigating critical frequency bands and\n   channels for EEG-based emotion recognition with deep neural\n   networks <https://ieeexplore.ieee.org/abstract/document/7104132>`__.\n-  `DEAP\n   dataset <https://torcheeg.readthedocs.io/en/latest/torcheeg.datasets.html#deapdataset>`__\n   from Koelstra et al.: `DEAP: A database for emotion analysis; using\n   physiological\n   signals <https://ieeexplore.ieee.org/abstract/document/5871728>`__.\n-  `MAHNOB\n   dataset <https://torcheeg.readthedocs.io/en/latest/torcheeg.datasets.html#mahnobdataset>`__\n   from Soleymani et al.: `A multimodal database for affect recognition\n   and implicit\n   tagging <https://ieeexplore.ieee.org/abstract/document/5975141>`__.\n\n**Transforms:** TorchEEG provides extensive data transformation tools to\nhelp users build EEG data representations suitable for a variety of task\nformulation and a variety of model structures.\n\n-  Feature Engineering:\n   `BandDifferentialEntropy <https://torcheeg.readthedocs.io/en/latest/torcheeg.transforms.numpy.html#transforms-banddifferentialentropy>`__,\n   `BandPowerSpectralDensity <https://torcheeg.readthedocs.io/en/latest/torcheeg.transforms.numpy.html#transforms-bandpowerspectraldensity>`__,\n   `BandMeanAbsoluteDeviation <https://torcheeg.readthedocs.io/en/latest/torcheeg.transforms.numpy.html#transforms-bandmeanabsolutedeviation>`__,\n   `BandKurtosis <https://torcheeg.readthedocs.io/en/latest/torcheeg.transforms.numpy.html#transforms-bandkurtosis>`__,\n   `BandSkewness <https://torcheeg.readthedocs.io/en/latest/torcheeg.transforms.numpy.html#transforms-bandskewness>`__,\n   `Concatenate <https://torcheeg.readthedocs.io/en/latest/torcheeg.transforms.numpy.html#transforms-concatenate>`__\n-  General Operation:\n   `PickElectrode <https://torcheeg.readthedocs.io/en/latest/torcheeg.transforms.numpy.html#transforms-pickelectrode>`__,\n   `MeanStdNormalize <https://torcheeg.readthedocs.io/en/latest/torcheeg.transforms.numpy.html#transforms-meanstdnormalize>`__,\n   `MinMaxNormalize <https://torcheeg.readthedocs.io/en/latest/torcheeg.transforms.numpy.html#transforms-minmaxnormalize>`__\n-  For CNN:\n   `To2d <https://torcheeg.readthedocs.io/en/latest/torcheeg.transforms.numpy.html#transforms-to2d>`__,\n   `ToGrid <https://torcheeg.readthedocs.io/en/latest/torcheeg.transforms.numpy.html#transforms-togrid>`__,\n   `ToInterpolatedGrid <https://torcheeg.readthedocs.io/en/latest/torcheeg.transforms.numpy.html#transforms-tointerpolatedgrid>`__\n-  For GNN:\n   `ToG <https://torcheeg.readthedocs.io/en/latest/torcheeg.transforms.pyg.html#transforms-tog>`__\n-  For Augmentation:\n   `Resize <https://torcheeg.readthedocs.io/en/latest/torcheeg.transforms.torch.html#transforms-resize>`__,\n   `RandomNoise <https://torcheeg.readthedocs.io/en/latest/torcheeg.transforms.torch.html#transforms-randomnoise>`__,\n   `RandomMask <https://torcheeg.readthedocs.io/en/latest/torcheeg.transforms.torch.html#transforms-randommask>`__\n-  For Label Construction:\n   `Select <https://torcheeg.readthedocs.io/en/latest/torcheeg.transforms.label.html#transforms-select>`__,\n   `Binary <https://torcheeg.readthedocs.io/en/latest/torcheeg.transforms.label.html#transforms-binary>`__,\n   `BinariesToCategory <https://torcheeg.readthedocs.io/en/latest/torcheeg.transforms.label.html#transforms-binariestocategory>`__\n\n**Data Splitting:** In current research in the field of EEG analysis,\nthere are various settings based on different considerations for data\npartitioning. Please choose a reasonable data division method according\nto the research focus:\n\n-  Subject Dependent:\n   `KFoldPerSubjectGroupbyTrial <https://torcheeg.readthedocs.io/en/latest/torcheeg.model_selection.html#kfoldpersubjectgroupbytrial>`__,\n   `train_test_split_per_subject_groupby_trial <https://torcheeg.readthedocs.io/en/latest/torcheeg.model_selection.html#train-test-split-per-subject-groupby-trial>`__\n-  Subject Independent:\n   `LeaveOneSubjectOut <https://torcheeg.readthedocs.io/en/latest/torcheeg.model_selection.html#leaveonesubjectout>`__\n-  Conventional:\n   `KFold <https://torcheeg.readthedocs.io/en/latest/torcheeg.model_selection.html#kfold>`__,\n   `train_test_split <https://torcheeg.readthedocs.io/en/latest/torcheeg.model_selection.html#train-test-split>`__,\n   `KFoldGroupbyTrial <https://torcheeg.readthedocs.io/en/latest/torcheeg.model_selection.html#kfoldgroupbytrial>`__,\n   `train_test_split_groupby_trial <https://torcheeg.readthedocs.io/en/latest/torcheeg.model_selection.html#train-test-split-groupby-trial>`__\n\n**Models:** Coming soon after pushing to align with the official\nimplementation or description. If the current version of\n`CNNs <https://torcheeg.readthedocs.io/en/latest/torcheeg.models.cnn.html>`__,\n`GNNs <https://torcheeg.readthedocs.io/en/latest/torcheeg.models.gnn.html>`__\nand\n`Transformers <https://torcheeg.readthedocs.io/en/latest/torcheeg.models.transformer.html>`__\nis to be used, please refer to the implementation in\n`torcheeg.models <https://torcheeg.readthedocs.io/en/latest/torcheeg.models.html>`__.\n\nQuickstart\n----------\n\nIn this quick tour, we highlight the ease of starting an EEG analysis\nresearch with only modifying a few lines of `PyTorch\ntutorial <https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html>`__.\n\nThe ``torcheeg.datasets`` module contains dataset classes for many\nreal-world EEG datasets. In this tutorial, we use the ``DEAP`` dataset.\nWe first go to the official website to apply for data download\npermission according to the introduction of `DEAP\ndataset <https://www.eecs.qmul.ac.uk/mmv/datasets/deap/>`__, and\ndownload the dataset. Next, we need to specify the download location of\nthe dataset in the ``root_path`` parameter. For the DEAP dataset, we\nspecify the path to the ``data_preprocessed_python`` folder,\ne.g. ``./tmp_in/data_preprocessed_python``.\n\n.. code:: python\n\n   from torcheeg.datasets import DEAPDataset\n   from torcheeg.datasets.constants.emotion_recognition.deap import DEAP_CHANNEL_LOCATION_DICT\n\n   dataset = DEAPDataset(io_path=f'./tmp_out/deap',\n                         root_path='./tmp_in/data_preprocessed_python',\n                         offline_transform=transforms.Compose(\n                             [transforms.BandDifferentialEntropy(),\n                              transforms.ToGrid(DEAP_CHANNEL_LOCATION_DICT)]),\n                         online_transform=transforms.Compose([transforms.BaselineRemoval(),\n                                                              transforms.ToTensor()]),\n                         label_transform=transforms.Compose([\n                             transforms.Select('valence'),\n                             transforms.Binary(5.0),\n                         ]), num_worker=4)\n\nThe ``DEAPDataset`` API further contains three parameters:\n``online_transform``, ``offline_transform``, and ``label_transform``,\nwhich are used to modify samples and labels, respectively.\n\nHere, ``offline_transform`` will only be called once when the dataset is\ninitialized to preprocess all samples in the dataset, and the processed\ndataset will be stored in ``io_path`` to avoid time-consuming repeated\ntransformations in subsequent use. If offline preprocessing is a\ncomputationally intensive operation, we also recommend setting multi-CPU\nparallelism for offline_transform, e.g., set ``num_worker`` to 4.\n\n``online_transform`` is used to transform samples on the fly. Please use\n``online_transform`` if you don't want to wait for the preprocessing of\nthe entire dataset (suitable for scenarios where new ``transform``\nalgorithms are designed) or expect data transformation with randomness\neach time a sample is indexed.\n\nNext, we need to divide the dataset into a training set and a test set.\nIn the field of EEG analysis, commonly used data partitioning methods\ninclude k-fold cross-validation and leave-one-out cross-validation. In\nthis tutorial, we use k-fold cross-validation on the entire dataset\n(``KFold``) as an example of dataset splitting.\n\n.. code:: python\n\n   from torcheeg.model_selection import KFold\n\n   k_fold = KFold(n_splits=10,\n                         split_path=f'./tmp_out/split',\n                         shuffle=True,\n                         random_state=42)\n\nLet's define a simple but effective CNN model according to\n`CCNN <https://link.springer.com/chapter/10.1007/978-3-030-04239-4_39>`__:\n\n.. code:: python\n\n   class CNN(torch.nn.Module):\n       def __init__(self, in_channels=4, num_classes=3):\n           super().__init__()\n           self.conv1 = nn.Sequential(\n               nn.ZeroPad2d((1, 2, 1, 2)),\n               nn.Conv2d(in_channels, 64, kernel_size=4, stride=1),\n               nn.ReLU()\n           )\n           self.conv2 = nn.Sequential(\n               nn.ZeroPad2d((1, 2, 1, 2)),\n               nn.Conv2d(64, 128, kernel_size=4, stride=1),\n               nn.ReLU()\n           )\n           self.conv3 = nn.Sequential(\n               nn.ZeroPad2d((1, 2, 1, 2)),\n               nn.Conv2d(128, 256, kernel_size=4, stride=1),\n               nn.ReLU()\n           )\n           self.conv4 = nn.Sequential(\n               nn.ZeroPad2d((1, 2, 1, 2)),\n               nn.Conv2d(256, 64, kernel_size=4, stride=1),\n               nn.ReLU()\n           )\n\n           self.lin1 = nn.Linear(9 * 9 * 64, 1024)\n           self.lin2 = nn.Linear(1024, num_classes)\n\n       def forward(self, x):\n           x = self.conv1(x)\n           x = self.conv2(x)\n           x = self.conv3(x)\n           x = self.conv4(x)\n\n           x = x.flatten(start_dim=1)\n           x = self.lin1(x)\n           x = self.lin2(x)\n           return x\n\nSpecify the device and loss function used during training and test.\n\n.. code:: python\n\n   device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n   loss_fn = nn.CrossEntropyLoss()\n   batch_size = 64\n\nThe training and validation scripts for the model are taken from the\n`PyTorch\ntutorial <https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html>`__\nwithout much modification. Usually, the value of ``batch`` contains two\nparts; the first part refers to the result of ``online_transform``,\nwhich generally corresponds to the ``Tensor`` sequence representing EEG\nsignals. The second part refers to the result of ``label_transform``, a\nsequence of integers representing the label.\n\n.. code:: python\n\n   def train(dataloader, model, loss_fn, optimizer):\n       size = len(dataloader.dataset)\n       model.train()\n       for batch_idx, batch in enumerate(dataloader):\n           X = batch[0].to(device)\n           y = batch[1].to(device)\n\n           # Compute prediction error\n           pred = model(X)\n           loss = loss_fn(pred, y)\n\n           # Backpropagation\n           optimizer.zero_grad()\n           loss.backward()\n           optimizer.step()\n\n           if batch_idx % 100 == 0:\n               loss, current = loss.item(), batch_idx * len(X)\n               print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n\n\n   def valid(dataloader, model, loss_fn):\n       size = len(dataloader.dataset)\n       num_batches = len(dataloader)\n       model.eval()\n       val_loss, correct = 0, 0\n       with torch.no_grad():\n           for batch in dataloader:\n               X = batch[0].to(device)\n               y = batch[1].to(device)\n\n               pred = model(X)\n               val_loss += loss_fn(pred, y).item()\n               correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n       val_loss /= num_batches\n       correct /= size\n       print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {val_loss:>8f} \\n\")\n\nTraverse ``k`` folds and train the model separately for testing. It is\nworth noting that, in general, we need to specify ``shuffle=True`` for\nthe ``DataLoader`` of the training data set to avoid the deviation of\nthe model training caused by consecutive labels of the same category.\n\n.. code:: python\n\n   for i, (train_dataset, val_dataset) in enumerate(k_fold.split(dataset)):\n\n       model = CNN().to(device)\n       optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n\n       train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n       val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n\n       epochs = 50\n       for t in range(epochs):\n           print(f\"Epoch {t+1}\\n-------------------------------\")\n           train(train_loader, model, loss_fn, optimizer)\n           valid(val_loader, model, loss_fn)\n       print(\"Done!\")\n\nFor more specific usage of each module, please refer to `the\ndocumentation <(https://torcheeg.readthedocs.io/)>`__.\n\nReleases and Contributing\n-------------------------\n\nTorchEEG is currently in beta; Please let us know if you encounter a bug\nby filing an issue. We also appreciate all contributions.\n\nIf you would like to contribute new datasets, deep learning methods, and\nextensions to the core, please first open an issue and then send a PR.\nIf you are planning to contribute back bug fixes, please do so without\nany further discussion.\n\nLicense\n-------\n\nTorchEEG has a MIT license, as found in the\n`LICENSE <https://github.com/tczhangzhi/torcheeg/blob/main/LICENSE>`__\nfile.\n\n.. |PyPI Version| image:: https://badge.fury.io/py/torcheeg.svg\n   :target: https://pypi.python.org/pypi/torcheeg\n.. |Docs Status| image:: https://readthedocs.org/projects/torcheeg/badge/?version=latest\n   :target: https://torcheeg.readthedocs.io/en/latest/?badge=latest\n.. |Downloads| image:: https://pepy.tech/badge/torcheeg\n   :target: https://pepy.tech/project/torcheeg\n.. |Join the Chat| image:: https://badges.gitter.im/torcheeg/community.svg\n   :target: https://gitter.im/torcheeg/community?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge\n",
    "description_content_type": "",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/tczhangzhi/torcheeg",
    "keywords": "PyTorch,EEG",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "torcheeg",
    "package_url": "https://pypi.org/project/torcheeg/",
    "platform": null,
    "project_url": "https://pypi.org/project/torcheeg/",
    "project_urls": {
      "Homepage": "https://github.com/tczhangzhi/torcheeg"
    },
    "release_url": "https://pypi.org/project/torcheeg/1.0.11/",
    "requires_dist": null,
    "requires_python": ">=3.7",
    "summary": "TorchEEG is a library built on PyTorch for EEG signal analysis. TorchEEG aims to provide a plug-and-play EEG analysis tool, so that researchers can quickly reproduce EEG analysis work and start new EEG analysis research without paying attention to technical details unrelated to the research focus.",
    "version": "1.0.11",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16086261,
  "releases": {
    "1.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3b2b6b6914f30b1e35399623f31a8527cb992bc5f7fa3faa870845da56f276c8",
          "md5": "312d5c68abdb1977e6c3f9674bd3274c",
          "sha256": "1b0c7361c0332d673ae67c1b4b9ff2f9128e8f119664c2766532eac5cd6ef2b4"
        },
        "downloads": -1,
        "filename": "torcheeg-1.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "312d5c68abdb1977e6c3f9674bd3274c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 46428,
        "upload_time": "2022-06-06T10:45:12",
        "upload_time_iso_8601": "2022-06-06T10:45:12.016249Z",
        "url": "https://files.pythonhosted.org/packages/3b/2b/6b6914f30b1e35399623f31a8527cb992bc5f7fa3faa870845da56f276c8/torcheeg-1.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.10": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cbc710430164068c4a043d2daeda7dd1c9f6b66427b9a4d13d5eef56260a33b8",
          "md5": "337aec7b3b5e07a8f477718f02c5cea9",
          "sha256": "84e6c3ab8553a8df746786faf6cbd1cadde43551209dee054a08b37cc76f970b"
        },
        "downloads": -1,
        "filename": "torcheeg-1.0.10.tar.gz",
        "has_sig": false,
        "md5_digest": "337aec7b3b5e07a8f477718f02c5cea9",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 159377,
        "upload_time": "2022-11-13T05:05:53",
        "upload_time_iso_8601": "2022-11-13T05:05:53.715611Z",
        "url": "https://files.pythonhosted.org/packages/cb/c7/10430164068c4a043d2daeda7dd1c9f6b66427b9a4d13d5eef56260a33b8/torcheeg-1.0.10.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.11": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "385a2284ebeb9cb337f96685ce6fea9ab1fec68df16d87f4405b72a7c5936040",
          "md5": "cbb11bc176b4a44ec976bcb9f2ac9490",
          "sha256": "56247fec6b6cb802297c9ac2a861b09f4c14f8f22fac0d154bc2bf303440296f"
        },
        "downloads": -1,
        "filename": "torcheeg-1.0.11.tar.gz",
        "has_sig": false,
        "md5_digest": "cbb11bc176b4a44ec976bcb9f2ac9490",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 161131,
        "upload_time": "2022-12-13T13:04:41",
        "upload_time_iso_8601": "2022-12-13T13:04:41.462180Z",
        "url": "https://files.pythonhosted.org/packages/38/5a/2284ebeb9cb337f96685ce6fea9ab1fec68df16d87f4405b72a7c5936040/torcheeg-1.0.11.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "26ae5cfdc4446fd59545d35c3dd86d1431529c04bf8713375a82a97d40f932ac",
          "md5": "dd58e995b0b3f7e54e86f622eb76d289",
          "sha256": "313bc33f48dc330525d662e0c2d5e27270f32fa63869c3d7df2908baca948d01"
        },
        "downloads": -1,
        "filename": "torcheeg-1.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "dd58e995b0b3f7e54e86f622eb76d289",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 57702,
        "upload_time": "2022-06-10T08:24:20",
        "upload_time_iso_8601": "2022-06-10T08:24:20.478708Z",
        "url": "https://files.pythonhosted.org/packages/26/ae/5cfdc4446fd59545d35c3dd86d1431529c04bf8713375a82a97d40f932ac/torcheeg-1.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "909d15f38e77abfec6e9ef318de4d45ca71b4d88f2ff52afcffea155cb459a92",
          "md5": "bfeb7b900b397739b755607543e54667",
          "sha256": "43349b120676cc865c1e757520c7a5c85e4514509bdc9f840c28df8efab0f524"
        },
        "downloads": -1,
        "filename": "torcheeg-1.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "bfeb7b900b397739b755607543e54667",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 61655,
        "upload_time": "2022-06-13T08:58:34",
        "upload_time_iso_8601": "2022-06-13T08:58:34.027916Z",
        "url": "https://files.pythonhosted.org/packages/90/9d/15f38e77abfec6e9ef318de4d45ca71b4d88f2ff52afcffea155cb459a92/torcheeg-1.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "758a1664210cf07393dd2f60b22fb9e82c112e63a287d7ab80bf39c8a4eccb91",
          "md5": "40748b277e375c7ff4955d6ededff9de",
          "sha256": "bfcc01808c61f0712ac82253d16bade4a7c5c71ea3a3365a7ac9b60a78938266"
        },
        "downloads": -1,
        "filename": "torcheeg-1.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "40748b277e375c7ff4955d6ededff9de",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 61263,
        "upload_time": "2022-06-19T15:22:05",
        "upload_time_iso_8601": "2022-06-19T15:22:05.130059Z",
        "url": "https://files.pythonhosted.org/packages/75/8a/1664210cf07393dd2f60b22fb9e82c112e63a287d7ab80bf39c8a4eccb91/torcheeg-1.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d1cc932872d890712a6b19cb9dce1cfee855e1f99d8a4c07c2302bbbdb8642f5",
          "md5": "41f268466eeaaa240b403df96464f4cc",
          "sha256": "76051b6446c22487110b05a089f8ce03c78008d0fe2782bf685c11ed07116a54"
        },
        "downloads": -1,
        "filename": "torcheeg-1.0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "41f268466eeaaa240b403df96464f4cc",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 68449,
        "upload_time": "2022-06-19T15:27:28",
        "upload_time_iso_8601": "2022-06-19T15:27:28.766209Z",
        "url": "https://files.pythonhosted.org/packages/d1/cc/932872d890712a6b19cb9dce1cfee855e1f99d8a4c07c2302bbbdb8642f5/torcheeg-1.0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9ccb2e651276909e96261c5ac1816476010dce12461a7eff93aa5f1f5e1f5f30",
          "md5": "84f07c60d2a6ebc7df79168138668fcf",
          "sha256": "590d501674852c22762e451a999e1ce7335742abac726311752df303c9668009"
        },
        "downloads": -1,
        "filename": "torcheeg-1.0.6.tar.gz",
        "has_sig": false,
        "md5_digest": "84f07c60d2a6ebc7df79168138668fcf",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 68922,
        "upload_time": "2022-06-20T16:34:17",
        "upload_time_iso_8601": "2022-06-20T16:34:17.386194Z",
        "url": "https://files.pythonhosted.org/packages/9c/cb/2e651276909e96261c5ac1816476010dce12461a7eff93aa5f1f5e1f5f30/torcheeg-1.0.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0c51579874283a5591b7a75250164b9979a64858ce3e1456fb256d84a5b0b054",
          "md5": "e71ad7b9cd3574e70b432a5f4db4e90a",
          "sha256": "9ec0e9c5e9f69759273b3cb37de8711281dd07118c016dd6988fa47c2eae5040"
        },
        "downloads": -1,
        "filename": "torcheeg-1.0.7.tar.gz",
        "has_sig": false,
        "md5_digest": "e71ad7b9cd3574e70b432a5f4db4e90a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 79916,
        "upload_time": "2022-06-23T17:00:51",
        "upload_time_iso_8601": "2022-06-23T17:00:51.457694Z",
        "url": "https://files.pythonhosted.org/packages/0c/51/579874283a5591b7a75250164b9979a64858ce3e1456fb256d84a5b0b054/torcheeg-1.0.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "594f1fc1755764dd33fa7bc4c0ae8f79f7e8ceef03b6bac73498dd912c3a711b",
          "md5": "306cc5a73cae9c5edf0e24c73f9212e1",
          "sha256": "598f4ee8c1b28a45ad01b74d59db4fc7559b191fe547285b135edc835565c95a"
        },
        "downloads": -1,
        "filename": "torcheeg-1.0.8.tar.gz",
        "has_sig": false,
        "md5_digest": "306cc5a73cae9c5edf0e24c73f9212e1",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 92919,
        "upload_time": "2022-07-20T10:55:32",
        "upload_time_iso_8601": "2022-07-20T10:55:32.015415Z",
        "url": "https://files.pythonhosted.org/packages/59/4f/1fc1755764dd33fa7bc4c0ae8f79f7e8ceef03b6bac73498dd912c3a711b/torcheeg-1.0.8.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.8.post1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "46cf90ba2b87b0d4e4409b54c3f64fe8c0f761c355cf9001bdfb4bb56d8e2731",
          "md5": "9b1d114852f93d2aba0f5b049085ac69",
          "sha256": "17a00f0ea8068f3cdc66ef379efe5c2fc01a7ddc24d691f90317f2c40f52aa01"
        },
        "downloads": -1,
        "filename": "torcheeg-1.0.8.post1.tar.gz",
        "has_sig": false,
        "md5_digest": "9b1d114852f93d2aba0f5b049085ac69",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 92939,
        "upload_time": "2022-07-20T11:00:58",
        "upload_time_iso_8601": "2022-07-20T11:00:58.401206Z",
        "url": "https://files.pythonhosted.org/packages/46/cf/90ba2b87b0d4e4409b54c3f64fe8c0f761c355cf9001bdfb4bb56d8e2731/torcheeg-1.0.8.post1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.9": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c14e4f4626672994f80cdcd42e1ff4963734d53d22f79c2849067264a585186d",
          "md5": "0988b5c862fb595c10e2886bfb922ba6",
          "sha256": "beecb33f22b9ab185c3a8383c6307fe3988f07b77923c1d2bacab590cdfff25d"
        },
        "downloads": -1,
        "filename": "torcheeg-1.0.9.tar.gz",
        "has_sig": false,
        "md5_digest": "0988b5c862fb595c10e2886bfb922ba6",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 104416,
        "upload_time": "2022-08-30T02:52:24",
        "upload_time_iso_8601": "2022-08-30T02:52:24.774757Z",
        "url": "https://files.pythonhosted.org/packages/c1/4e/4f4626672994f80cdcd42e1ff4963734d53d22f79c2849067264a585186d/torcheeg-1.0.9.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "385a2284ebeb9cb337f96685ce6fea9ab1fec68df16d87f4405b72a7c5936040",
        "md5": "cbb11bc176b4a44ec976bcb9f2ac9490",
        "sha256": "56247fec6b6cb802297c9ac2a861b09f4c14f8f22fac0d154bc2bf303440296f"
      },
      "downloads": -1,
      "filename": "torcheeg-1.0.11.tar.gz",
      "has_sig": false,
      "md5_digest": "cbb11bc176b4a44ec976bcb9f2ac9490",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 161131,
      "upload_time": "2022-12-13T13:04:41",
      "upload_time_iso_8601": "2022-12-13T13:04:41.462180Z",
      "url": "https://files.pythonhosted.org/packages/38/5a/2284ebeb9cb337f96685ce6fea9ab1fec68df16d87f4405b72a7c5936040/torcheeg-1.0.11.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}