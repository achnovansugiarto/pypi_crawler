{
  "info": {
    "author": "Sweta",
    "author_email": "sweta.swami@decisionpoint.in",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "### dq-module\ndq-module is a tool which can be used to perform validations and profiling on the datasets.This tool is compatible with two run_engines `pyspark` and `polars`.\n### Features\n## 1. Data Validation \nThis library contains a `SingleDatasetQualityCheck()` class which can used to validate the dataset against a defined set of rules.\nThis class contains the following rules which can be used to validate the dataset: \n - null_check\n - schema_check\n - range_min_check\n - range_max_check\n - length_check\n - unique_records_check\n - unique_keys_check\n - allowed_values_check\n - min_length_check\n - column_count_check\n - not_allowed_values_check\n -  date_range_check\n - regex_check\n - row_count_check\n\n### How To Use\n\n```sh\nimport dataqualitycheck as dq\nfrom datetime import date\nimport time\n```\n##### Step 1: Adding a datasource\nWe have 4 classes which can be used to connect to a datasource:\n1. `AzureBlobDF()` - This class can be used to interact with the datasources on azure blob storage . \n2. `DatabricksFileSystemDF()` - This class can be used to interect with the datasources on  databricks filesystem.\n3. `DatabricksSqlDF()` - This class can be used to interact with the datasources on  databricks databases.\n4. `LocalFileSystemDF()` - This class can be used to interact with the datasources on your local filesystem.\n\nEach of the above class provides the functionalities to read and write from the respective datasources.\n\n\n**Example:**\nPass the configuration of the  blob connector  in `blob_connector_config`and \nadd a datasource by defining a `data_read_ob` and `data_write_ob`.\n```sh\nblob_connector_config = {\"storage_account_name\" : \"rgmdemostorage\", \"container_name\" : \"cooler-images\", \"sas_token\" : <vaild-sas-token>}\n```\n```sh\ndata_read_ob = dq.AzureBlobDF(storage_name=blob_connector_config[\"storage_account_name\"], sas_token=blob_connector_config[\"sas_token\"])\ndata_write_ob = dq.DatabricksFileSystemDF()\n```\n\n `tables_list` is a dictionary that contains the list of sources along with the container_name , source_type , layer , source_name , filename , read_connector_method and latest_file_path  for the tables on which the validations has to be applied . \n```sh\n#This is optional.It is required when you are calling individual rules.\ntables_list={}\n```\n##### Step 2: Add a DataContext \nInstantiate a DataContext by passing `tables_list`,`interaction_between_tables`,`data_read_ob`,`data_write_ob`, `data_right_structure`,`job_id`,`time_zone`,`no_of_partition` and `output_db_name `.\nYou can also pass the `run_engine` with which you want to apply the quality checks. By default, the run_engine is `pyspark`.\n\n```sh\ndq_ob = dq.SingleDatasetQualityCheck(tables_list={}, \n                                  interaction_between_tables=[],  \n                                  data_read_ob=data_read_ob, \n                                  data_write_ob=data_write_ob, \n                                  data_right_structure='file',\n                                  job_id=<pipeline_run_id>,\n                                  time_zone=None,\n            output_db_name=<database_name_where_report_has_to_be_written>,\n                                  no_of_partition=4)\n```\n\n##### Step 3:\nPassing a `rules_diagnosys_summery_file_path` and `config_df` as an input and apply validations on various columns of respective table defined in the `config_df`.\n\nHere is an sample of the `config_df`.\n| container_name   | source_type | layer     | source_name         | filename     | rule_name       | column_to_be_checked | value | date_column_config | date_format_dictionary | ruletype      | active | read_connector_method | latest_file_path                                                                                  | output_folder_structure | failed_schema_source_list |\n|------------------|-------------|-----------|---------------------|--------------|-----------------|----------------------|-------|--------------------|------------------------|---------------|--------|-----------------------|---------------------------------------------------------------------------------------------------|-------------------------|---------------------------|\n| rgm-data-quality | sharepoint  | processed | neilsen_data_folder | neilsen_data | null_check      | prod_brand           | null  | null               | null                   | Mandatory     | 1      | blob                  | path-to-file | processed/              |                           |\n| rgm-data-quality | sharepoint  | processed | neilsen_data_folder | neilsen_data | range_min_check | inventory_kg_avg     | 10    | null               | null                   | Not Mandatory | 1      | blob                  | path-to-file | processed/              |                           |\n| rgm-data-quality | sharepoint  | processed | neilsen_data_folder | neilsen_data | range_max_check | inventory_kg_avg     | 1000  | null               | null                   | Not Mandatory | 1      | blob                  | path-to-file | processed/              |                           |\n\n**Example:**\n```sh\nrules_diagnosys_summery_folder_path = <folder-path-for-the-output-report>\n \nconfig_df = spark.read.option(\"header\",True).csv(<path-to-the-config>)\n\ndq_ob.apply_validation(config_df, write_summary_on_database=True, failed_schema_source_list=[], output_summary_folder_path=rules_diagnosys_summery_folder_path)\n```\n## 2. Data Profiling\n- We can generate a detailed summary statistics such as mean, median, mode, list of uniques, missing count etc. of a dataset using the `DataProfile()` class.\n- This class can also be used to recommend some  data quality rules  based on the profiling report generated on the dataset.\n### How To Use\n\n**Step 1: Add a Datasource**\n```sh\ndata_write_ob = dq.DatabricksSqlDF()\ndata_write_ob = dq.DatabricksSqlDF()\n```\n**Step 2: Add a DataContext**\n```sh\nimport pytz\ntime_zone = pytz.timezone('US/Central')\ndq_ob = dq.DataProfile(tables_list=tables_list,\n                     interaction_between_tables=[],\n                     data_read_ob=data_read_ob,\n                     data_write_ob=data_write_ob,\n                     data_right_structure='table',\n                     job_id=<pipeline_run_id>,\n                     time_zone=time_zone,\n                     no_of_partition=4,\n            output_db_name=<database_name_where_report_has_to_be_written>,\n                     run_engine='polars')\n```\n**Step 3:**\nPass `config_df` as an input and apply data profiling on various columns of respective table defined in the `config_df`.\n``` sh\n# You can create a config_df in pyspark/polars run_engine directly also rather than reading as a csv.\nconfig_df = spark.createDataFrame([{\"container_name\" : \"rgm-data-quality\",\n                                 \"source_type\" : \"sharepoint\",\n                                 \"layer\" : \"raw\",\n                                 \"source_name\" : \"data_quality_db\",\n                                 \"filename\" : \"neilsen_data_parquet\",\n            \"latest_file_path\" : \"data_quality_db.neilsen_data_parquet\",  \n                            \"read_connector_method\" : \"databricks sql\",\n         \"output_folder_structure\" : \"processed/data_profiling_test/\"}])\n```\n```sh\n# Generating a data profiling report.\ndq_ob.apply_data_profiling(source_config_df=config_df,\n                           write_consolidated_report=True)\n```\n```sh\n# Generating a data profiling report as well as recommending the quality rules based on the profiling report.\nrules_config = dq_ob.data_profiling_based_quality_rules(config_df, list_of_columns_to_be_ignored)\n```\n\n## 3. Consistency Check\n You can check the consistency of common columns between two tables using the `ConsistencyCheck()` class.\n### How To Use\n\n**Step 1: Add a datasource.**\n```sh\ndata_read_ob = dq.DatabricksFileSystemDF()\ndata_write_ob = dq.AzureBlobDF(storage_name=blob_connector_config[\"storage_account_name\"], sas_token=blob_connector_config[\"sas_token\"])\n```\n**Step 2: Add a DataContext**\n```sh\ndq_ob = dq.ConsistencyCheck(tables_list={}, \n                   interaction_between_tables=[],\n                   data_read_ob=data_read_ob,\n                   data_write_ob=data_write_ob, \n                   data_right_structure='file',\n                   job_id=<pipeline_run_id>,\n                   time_zone=None,\n                   no_of_partition=4,\n         output_db_name=<database_name_where_report_has_to_be_written>)\n```\n**Step 3:**\n Pass `config_df` and `output_report_folder_path` as an input and apply consistency check.\nHere is a sample consistency check config.\n| container_name   | base_table_source_type | base_table_layer | base_table_source_name | base_table_filename    | base_table_col_name | base_table_file_path                                                                                                | mapped_table_source_type | mapped_table_layer | mapped_table_source_name | mapped_table_filename    | mapped_table_col_name | mapped_table_file_path                                                                                                  | read_connector_method | output_folder_structure          |\n|------------------|------------------------|------------------|------------------------|------------------------|---------------------|---------------------------------------------------------------------------------------------------------------------|--------------------------|--------------------|--------------------------|--------------------------|-----------------------|-------------------------------------------------------------------------------------------------------------------------|-----------------------|----------------------------------|\n| rgm-data-quality | sharepoint             | processed        | scantrack              | butters_margarins_base | BARCODE             | dbfs:/FileStore/Tables/sharepoint/scantrack/butters_margarins_base/2023/01/12/butters_margarins_base_01_12_2023.csv | sharepoint               | processed          | scantrack                | butters_margarins_master | BARCODE               | dbfs:/FileStore/Tables/sharepoint/scantrack/butters_margarins_master/2023/01/12/butters_margarins_master_01_12_2023.csv | dbfs                  | processed/data_consistenct_test/ |\n| rgm-data-quality | sharepoint             | processed        | scantrack              | cheese_base            | BARCODE             | dbfs:/FileStore/Tables/sharepoint/scantrack/cheese_base/2023/01/12/cheese_base_01_12_2023.csv                       | sharepoint               | processed          | scantrack                | cheese_master            | BARCODE               | dbfs:/FileStore/Tables/sharepoint/scantrack/cheese_master/2023/01/12/cheese_master_01_12_2023.csv                       | dbfs                  | processed/data_consistenct_test/ |\n\n\n```sh\nconfig_df = spark.read.option(\"header\",True).csv(<path-to-the-consistency-check-config>)\n\noutput_report_folder_path = <folder-path-for-the-output-report>\n\ndq_ob.apply_consistency_check(config_df, output_report_folder_path)\n\n```\n\n\n        \n                          \n                           \n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "module-dataquality",
    "package_url": "https://pypi.org/project/module-dataquality/",
    "platform": null,
    "project_url": "https://pypi.org/project/module-dataquality/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/module-dataquality/1.0.8/",
    "requires_dist": [
      "polars"
    ],
    "requires_python": ">=3.8",
    "summary": "data profiling and basic data quality rules check",
    "version": "1.0.8",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17299622,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d2a6887c44a61ecae79023016c8e18c6e92e10448c0b78ae29a0b5d2c86c85b0",
          "md5": "489e0d6db706ecc5e6b0fa2c3f6668ca",
          "sha256": "36de70728c5a1debac985d09de7d5062e9c3ba6b6763736c9de23b61ef82e0b0"
        },
        "downloads": -1,
        "filename": "module_dataquality-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "489e0d6db706ecc5e6b0fa2c3f6668ca",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 28684,
        "upload_time": "2023-03-13T09:59:49",
        "upload_time_iso_8601": "2023-03-13T09:59:49.356758Z",
        "url": "https://files.pythonhosted.org/packages/d2/a6/887c44a61ecae79023016c8e18c6e92e10448c0b78ae29a0b5d2c86c85b0/module_dataquality-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9451f1f7cd5b700ec6388690b81216271000a32dfa57cafe8b7cc75d6c12cddd",
          "md5": "5a65b81df52da779b408e1d871870923",
          "sha256": "e76e8c06aaca3c405d238fb44469cb704127d86ffdedec00e42c3d87beaa7ee9"
        },
        "downloads": -1,
        "filename": "module_dataquality-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "5a65b81df52da779b408e1d871870923",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 23620,
        "upload_time": "2023-03-13T09:59:52",
        "upload_time_iso_8601": "2023-03-13T09:59:52.674500Z",
        "url": "https://files.pythonhosted.org/packages/94/51/f1f7cd5b700ec6388690b81216271000a32dfa57cafe8b7cc75d6c12cddd/module_dataquality-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e1bc071f6501c2c2fddac1b113bfc79822a29084bee65241bc053dd8574f0ed2",
          "md5": "a22b6754f24c54aab39e3d097d67d4a0",
          "sha256": "7e4fe238b869765d780d61505e171ed7de11dfce22e58d55be9b65619440253b"
        },
        "downloads": -1,
        "filename": "module_dataquality-1.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "a22b6754f24c54aab39e3d097d67d4a0",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 27414,
        "upload_time": "2023-03-13T13:58:23",
        "upload_time_iso_8601": "2023-03-13T13:58:23.161094Z",
        "url": "https://files.pythonhosted.org/packages/e1/bc/071f6501c2c2fddac1b113bfc79822a29084bee65241bc053dd8574f0ed2/module_dataquality-1.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "10733f3052d9bf21f9d450ab7b518f25ad38ea4a7436b5ebdcec1fbdc78d2eaa",
          "md5": "eee9d32ba7d475f7d134270da901756c",
          "sha256": "eb6b2e414139decef525480a59d64aa492522ef3b4f9c7f9cd356d529fe5071e"
        },
        "downloads": -1,
        "filename": "module_dataquality-1.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "eee9d32ba7d475f7d134270da901756c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 21152,
        "upload_time": "2023-03-13T13:58:25",
        "upload_time_iso_8601": "2023-03-13T13:58:25.905279Z",
        "url": "https://files.pythonhosted.org/packages/10/73/3f3052d9bf21f9d450ab7b518f25ad38ea4a7436b5ebdcec1fbdc78d2eaa/module_dataquality-1.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3f5129bb2dab5c6162ebb925e1197416ac28527a21d5c93f2f95519c6a2af44d",
          "md5": "1878c5a521f2657139d732537ddbd110",
          "sha256": "f313e7cffbe732c7b97859158978a83225951fd5d73bdb420bbd5a12e20095e2"
        },
        "downloads": -1,
        "filename": "module_dataquality-1.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "1878c5a521f2657139d732537ddbd110",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 28697,
        "upload_time": "2023-03-13T14:01:28",
        "upload_time_iso_8601": "2023-03-13T14:01:28.061568Z",
        "url": "https://files.pythonhosted.org/packages/3f/51/29bb2dab5c6162ebb925e1197416ac28527a21d5c93f2f95519c6a2af44d/module_dataquality-1.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ee55858f0ab5cda3e6f9a8030e3b4299cd717f2765f2fcb0555f5083d2545af5",
          "md5": "9ae1b82ef0f7a454d1460d6332136e44",
          "sha256": "d321df6986b0f6bb26d9e7cf2751c16f039db12355ef995321770a7df6bf26d7"
        },
        "downloads": -1,
        "filename": "module_dataquality-1.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "9ae1b82ef0f7a454d1460d6332136e44",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 23761,
        "upload_time": "2023-03-13T14:01:31",
        "upload_time_iso_8601": "2023-03-13T14:01:31.134282Z",
        "url": "https://files.pythonhosted.org/packages/ee/55/858f0ab5cda3e6f9a8030e3b4299cd717f2765f2fcb0555f5083d2545af5/module_dataquality-1.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "494c6f59e82c2a8587e786fb0e5b6b2610fedcd9c4243ec90f9399bcf4f20765",
          "md5": "6550c013069844b389f14a2d1c670fb3",
          "sha256": "d4cbe03e4b1d112442ddeef84b6bebcd263a0177492099ed88756dfee47250f2"
        },
        "downloads": -1,
        "filename": "module_dataquality-1.0.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "6550c013069844b389f14a2d1c670fb3",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 32338,
        "upload_time": "2023-03-14T07:41:20",
        "upload_time_iso_8601": "2023-03-14T07:41:20.134088Z",
        "url": "https://files.pythonhosted.org/packages/49/4c/6f59e82c2a8587e786fb0e5b6b2610fedcd9c4243ec90f9399bcf4f20765/module_dataquality-1.0.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "105d040ff6819e6de6917e82682d0729b6f08750d6c9f57381cb4306ba1dedf5",
          "md5": "ea472804efc861bb872b3eb6937a4967",
          "sha256": "f7a8a850a2df773926936f70a850afeb6d975dce96eef996a5f6288b26fd8fa7"
        },
        "downloads": -1,
        "filename": "module_dataquality-1.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "ea472804efc861bb872b3eb6937a4967",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 28388,
        "upload_time": "2023-03-14T07:41:22",
        "upload_time_iso_8601": "2023-03-14T07:41:22.823467Z",
        "url": "https://files.pythonhosted.org/packages/10/5d/040ff6819e6de6917e82682d0729b6f08750d6c9f57381cb4306ba1dedf5/module_dataquality-1.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6c05a70298ae2f1db63d9d8311f7445212913343197e0080fea1071283a73a9b",
          "md5": "d27d794b3f63818de30c87cb350fb975",
          "sha256": "824a0b0b376be78167b18e8f269e6328883faa0fb53e042f1335cbe869d9f9ae"
        },
        "downloads": -1,
        "filename": "module_dataquality-1.0.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d27d794b3f63818de30c87cb350fb975",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 32321,
        "upload_time": "2023-03-14T11:31:31",
        "upload_time_iso_8601": "2023-03-14T11:31:31.210813Z",
        "url": "https://files.pythonhosted.org/packages/6c/05/a70298ae2f1db63d9d8311f7445212913343197e0080fea1071283a73a9b/module_dataquality-1.0.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "484dd496411ef75dd3232f79900046efb2a1bfb84e0d677886d1e7b8e7d5e622",
          "md5": "beb042ac72dbc9a2c72361da5d6f7063",
          "sha256": "ed88e8b424d994497d1ce84c99ec72121aa8b66a664d0fd030bb8c4867454f10"
        },
        "downloads": -1,
        "filename": "module_dataquality-1.0.6-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "beb042ac72dbc9a2c72361da5d6f7063",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 31814,
        "upload_time": "2023-03-14T12:39:22",
        "upload_time_iso_8601": "2023-03-14T12:39:22.707977Z",
        "url": "https://files.pythonhosted.org/packages/48/4d/d496411ef75dd3232f79900046efb2a1bfb84e0d677886d1e7b8e7d5e622/module_dataquality-1.0.6-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "27df0f1f2138c7aaeed1c4eda5f1afff1be6bdcf7157b01a998445b89ed9036e",
          "md5": "2c8a28e39c4824aac025a279742ffbc0",
          "sha256": "718fa36e2d2dfd1eb04cba76dba1eddf047968b85609be2b74811dfbdab8853a"
        },
        "downloads": -1,
        "filename": "module_dataquality-1.0.7-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "2c8a28e39c4824aac025a279742ffbc0",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 32328,
        "upload_time": "2023-03-14T15:40:46",
        "upload_time_iso_8601": "2023-03-14T15:40:46.043148Z",
        "url": "https://files.pythonhosted.org/packages/27/df/0f1f2138c7aaeed1c4eda5f1afff1be6bdcf7157b01a998445b89ed9036e/module_dataquality-1.0.7-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "077e85b25c3942933e1c6ccdb121fc49f80073d45d1ec431f236605b40cf3680",
          "md5": "509ac7a8e0a2c4fa8855f6cef08d5fe7",
          "sha256": "5885af53b96ae5b79f909e741d12906a2b88a521b9798e9857453bdaa1291353"
        },
        "downloads": -1,
        "filename": "module_dataquality-1.0.7.tar.gz",
        "has_sig": false,
        "md5_digest": "509ac7a8e0a2c4fa8855f6cef08d5fe7",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 28342,
        "upload_time": "2023-03-14T15:40:48",
        "upload_time_iso_8601": "2023-03-14T15:40:48.837291Z",
        "url": "https://files.pythonhosted.org/packages/07/7e/85b25c3942933e1c6ccdb121fc49f80073d45d1ec431f236605b40cf3680/module_dataquality-1.0.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4cd4f237a64c1d02081b0e97b4a8222b4b1a9b81a0b8e25449ee42abafcb1a21",
          "md5": "d89dc41508b809b5dfb7ac9669685703",
          "sha256": "a2b07ba16890159539141381289f9a2d9723bba64ee109b121f6cc5f203dea30"
        },
        "downloads": -1,
        "filename": "module_dataquality-1.0.8-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d89dc41508b809b5dfb7ac9669685703",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 5624,
        "upload_time": "2023-03-15T06:00:57",
        "upload_time_iso_8601": "2023-03-15T06:00:57.892732Z",
        "url": "https://files.pythonhosted.org/packages/4c/d4/f237a64c1d02081b0e97b4a8222b4b1a9b81a0b8e25449ee42abafcb1a21/module_dataquality-1.0.8-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "07e4603bdb8bf7234901891f59cc189145b04e5457dfd3b2680237532bcbcb3f",
          "md5": "8819a6080ff501f5bc4b5deb250b6049",
          "sha256": "1857e24ed240bc90284f19340b63ef0ce2637b13ed41d604a0d652cbadffee8f"
        },
        "downloads": -1,
        "filename": "module_dataquality-1.0.8.tar.gz",
        "has_sig": false,
        "md5_digest": "8819a6080ff501f5bc4b5deb250b6049",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 5387,
        "upload_time": "2023-03-15T06:01:00",
        "upload_time_iso_8601": "2023-03-15T06:01:00.898579Z",
        "url": "https://files.pythonhosted.org/packages/07/e4/603bdb8bf7234901891f59cc189145b04e5457dfd3b2680237532bcbcb3f/module_dataquality-1.0.8.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "4cd4f237a64c1d02081b0e97b4a8222b4b1a9b81a0b8e25449ee42abafcb1a21",
        "md5": "d89dc41508b809b5dfb7ac9669685703",
        "sha256": "a2b07ba16890159539141381289f9a2d9723bba64ee109b121f6cc5f203dea30"
      },
      "downloads": -1,
      "filename": "module_dataquality-1.0.8-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "d89dc41508b809b5dfb7ac9669685703",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.8",
      "size": 5624,
      "upload_time": "2023-03-15T06:00:57",
      "upload_time_iso_8601": "2023-03-15T06:00:57.892732Z",
      "url": "https://files.pythonhosted.org/packages/4c/d4/f237a64c1d02081b0e97b4a8222b4b1a9b81a0b8e25449ee42abafcb1a21/module_dataquality-1.0.8-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "07e4603bdb8bf7234901891f59cc189145b04e5457dfd3b2680237532bcbcb3f",
        "md5": "8819a6080ff501f5bc4b5deb250b6049",
        "sha256": "1857e24ed240bc90284f19340b63ef0ce2637b13ed41d604a0d652cbadffee8f"
      },
      "downloads": -1,
      "filename": "module_dataquality-1.0.8.tar.gz",
      "has_sig": false,
      "md5_digest": "8819a6080ff501f5bc4b5deb250b6049",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.8",
      "size": 5387,
      "upload_time": "2023-03-15T06:01:00",
      "upload_time_iso_8601": "2023-03-15T06:01:00.898579Z",
      "url": "https://files.pythonhosted.org/packages/07/e4/603bdb8bf7234901891f59cc189145b04e5457dfd3b2680237532bcbcb3f/module_dataquality-1.0.8.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}