{
  "info": {
    "author": "Devon Connors",
    "author_email": "<dconns1@outlook.com>",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Developers",
      "Operating System :: MacOS :: MacOS X",
      "Operating System :: Microsoft :: Windows",
      "Operating System :: Unix",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Pro-Football-Talk Web Scraper\n\nDeveloped by Devon Connors (c) 2022\n\n## Before Continuing:\n<strong>Out of respect for Pro Football Reference</strong> each instance of scraping will have a 5-10 second delay as to not spam their server.  So in the instances where you obtain a list of URLs of players to scrape you will need to understand it could take some time to process that list.\n\n##### Example: 400 players could take up to 1 hour to scrape.\n\nI am working through updating this tool to use asyncronous request while also being respectful so for the time being please be patient.\n\n## Examples of How To Use (Alpha Version)\n\n### Scraping Team Data\n#### Creating Team Data Scraper and Method Usage\n```python\nfrom PFRWebScraper import ScrapeTeamData\n\n# Creates an instance of Team Data Scraper\nteam_data_scraper = ScrapeTeamData()\n\n# Obtains the abbreviation for the team you wish to scrape\nteam_abbreviation = team_data_scraper.get_team_abbreviation(\"Las Vegas Raiders\")\n\n# Scrapes defensive data for the team for a number of years back.  \n#   Uses 4 years by default.\ndefault_defensive_data = team_data_scraper.scrape_defense(team_abbreviation)\n\n# Scrapes defensive data for the team's last 2 years\nlast_two_years_defense_data = team_data_scraper.scrape_defense(team_abbreviation, 2)\n\n# # Scrapes offensive data for the team for a number of years back.  \n#   Uses 4 years by default.\ndefault_offensive_data = team_data_scraper.scrape_offense(team_abbreviation)\n\n# Scrapes offensive data for the team's last 2 years\nlast_two_years_offensive_data = team_data_scraper.scrape_offense(team_abbreviation, 2)\n```\n\n#### Obtaining Specific Data From The Team Data Object\n```python\nfrom PFRWebScraper import ScrapeTeamData\n\n# Creates an instance of Team Data Scraper\nteam_data_scraper = ScrapeTeamData()\n\n# Obtains the abbreviation for the team you wish to scrape\nteam_abbreviation = team_data_scraper.get_team_abbreviation(\"Las Vegas Raiders\")\n\n# Scrapes offensive data for the team's last 2 years\noffensive_data = team_data_scraper.scrape_offense(team_abbreviation, 2)\n\n# Obtains the years that returned data if you are unsure\n# In this instance you will receive a list: \n#   [2021, 2022]\nvalid_years_with_data = offensive_data.get_list_of_years()\n\n# You will then need to set the year from which you will like data\noffensive_data.set_reference_year(2022)\n\n# After you have set the reference year you can begin pulling stats\nteam_points = offensive_data.get_points()\nteam_total_yards = offensive_data.get_total_yards()\n```\n\n#### Obtaining Whole Data Sets\n```python\nfrom PFRWebScraper import ScrapeTeamData\n\n# Creates an instance of Team Data Scraper\nteam_data_scraper = ScrapeTeamData()\n\n# Obtains the abbreviation for the team you wish to scrape\nteam_abbreviation = team_data_scraper.get_team_abbreviation(\"Las Vegas Raiders\")\n\n# Scrapes offensive data for the team's last 2 years\noffensive_data = team_data_scraper.scrape_offense(team_abbreviation, 2)\n\n# Obtains the raw data as a Pandas Dataframe\noffensive_dataframe = team_data_scraper.get_dataframe_of_stats()\n\n# Obtains the raw data as a dictionary\noffensive_dictionary = team_data_scraper.get_dictionary_of_stats()\n```\n\n### Scraping Player Data\n#### Create Player Scraper and Method Usage\n##### Scraping Passing Data\n```python\nfrom PFRWebScraper import ScrapePlayerData\n\n# Creates an instance of the Player Scraper Object\nplayer_scraper = ScrapePlayerData()\n\n# Scrapes for all passing data on a player's page\npassing_data = player_scraper.scrape_passing(\"https://www.pro-football-reference.com/players/C/CarrDe02.htm\")\n\n# You can also specify the sections of data you would like. You pass them in as a list.\n# This is set to all data by default. \n# Different Input: \n#   1. 'passing' - Scrapes Regular Season and Playoff data on a passer.\n#   2. 'advanced' - Scrapes Air Yards, Accuracy, Pressure, and Play Type data on a passer.\n#   3. 'adjusted' - Scrapes Adjusted data on a passer.\n\n# Example of only passsing and advanced data\npassing_advanced_data = player_scraper.scrape_passing(\"https://www.pro-football-reference.com/players/C/CarrDe02.htm\", ['passing', 'advanced'])\n\n# Example of only adjusted data\nadjusted_data = player_scraper.scrape_passing(\"https://www.pro-football-reference.com/players/C/CarrDe02.htm\", ['adjusted'])\n```\n\n##### Scrape Rushing and Receiving Data\n```python\nfrom PFRWebScraper import ScrapePlayerData\n\n# Creates an instance of the Player Scraper Object\nplayer_scraper = ScrapePlayerData()\n\n# Scrapes for all rushing and receiving data on a player's page\nrushing_receiving_data = player_scraper.scrape_rushing_receiving(\"https://www.pro-football-reference.com/players/J/JacoJo01.htm\")\n```\n\n##### Scrape Scoring Data\n```python\nfrom PFRWebScraper import ScrapePlayerData\n\n# Creates an instance of the Player Scraper Object\nplayer_scraper = ScrapePlayerData()\n\n# Scrapes for all scoring data on a player's page\nscoring_data = player_scraper.scrape_scoring(\"https://www.pro-football-reference.com/players/R/RenfHu00.htm\")\n```\n\n##### Scrape Snap Counts Data\n```python\nfrom PFRWebScraper import ScrapePlayerData\n\n# Creates an instance of the Player Scraper Object\nplayer_scraper = ScrapePlayerData()\n\n# Scrapes for all snap counts data on a player's page\nsnap_counts_data = player_scraper.scrape_snap_counts(\"https://www.pro-football-reference.com/players/W/WallDa01.htm\")\n```\n\n##### Scrape Defense and Fumbles Data\n```python\nfrom PFRWebScraper import ScrapePlayerData\n\n# Creates an instance of the Player Scraper Object\nplayer_scraper = ScrapePlayerData()\n\n# Scrapes for all defense and fumbles data on a player's page\ndefense_and_fumbles_data = player_scraper.scrape_defense_and_fumbles(\"https://www.pro-football-reference.com/players/A/AdamDa01.htm\")\n```\n\n##### Scrape Kick and Punt Returns Data\n```python\nfrom PFRWebScraper import ScrapePlayerData\n\n# Creates an instance of the Player Scraper Object\nplayer_scraper = ScrapePlayerData()\n\n# Scrapes for all kick and punt returns data on a player's page\nreturns_data = player_scraper.scrape_kick_and_punt_returns(\"https://www.pro-football-reference.com/players/A/AbduAm00.htm\")\n```\n\n##### Scrape Kicking Data\n```python\nfrom PFRWebScraper import ScrapePlayerData\n\n# Creates an instance of the Player Scraper Object\nplayer_scraper = ScrapePlayerData()\n\n# Scrapes for all kicking data on a player's page\nkicking_data = player_scraper.scrape_kicking(\"https://www.pro-football-reference.com/players/C/CarlDa00.htm\")\n```\n\n#### Utilizing Player Data Objects\n##### Passing Data Object Usage\n```python\nfrom PFRWebScraper import ScrapePlayerData\n\n# Creates an instance of the Player Scraper Object\nplayer_scraper = ScrapePlayerData()\n\n# Scrapes for all passing data on a player's page\npassing_data = player_scraper.scrape_passing(\"https://www.pro-football-reference.com/players/C/CarrDe02.htm\")\n\n# passing_data is now a passing object that has all the information stored within sub-objects\n# Methods will need to be called to obtain the relevant data to work with it\n\n# Passing Data Regular Season\nregular_season_passing_data = passing_data.get_passing_data_regular_season()\n\n# Passing Data Playoffs\nplayoffs_passing_data = passing_data.get_passing_data_playoffs()\n\n# Passing Data Advanced (Air Yards)\nair_yards_passing_data = passing_data.get_passing_data_advanced_air_yards()\n\n# Passing Data Advanced (Accuracy)\naccuracy_passing_data = passing_data.get_passing_data_advanced_accuracy()\n\n# Passing Data Advanced (Pressure)\npressure_passing_data = passing_data.get_passing_data_advanced_pressure()\n\n# Passing Data Advanced (Play Type)\nplay_type_passing_data = passing_data.get_passing_data_advanced_play_type()\n\n# Passing Data Adjusted\nadjusted_passing_data = passing_data.get_passing_data_adjusted()\n\n# Once you have decided which data object you would like you can then utilize them the same way as Team Data.\n\n# Example: Regular Season Passing Data\n\n# Obtain the whole data set\nregular_season_passing_dataframe = regular_season_passing_data.get_dataframe_of_stats()\nregular_season_passing_dictionary = regular_season_passing_data.get_dictionary_of_stats()\n\n# Obtain specific data points\n# Set the reference year\nregular_season_passing_data.set_reference_year(2022)\n\n# Call the methods for specific data points\nplayers_age = regular_season_passing_data.get_age()\ngames_played = regular_season_passing_data.get_games_played()\ngames_started = regular_season_passing_data.get_games_started()\n```\n\n##### Rushing and Receiving Data Object Usage\n```python\nfrom PFRWebScraper import ScrapePlayerData\n\n# Creates an instance of the Player Scraper Object\nplayer_scraper = ScrapePlayerData()\n\n# Scrapes for all rushing and receiving data on a player's page\nrushing_receiving_data = player_scraper.scrape_rushing_receiving(\"https://www.pro-football-reference.com/players/J/JacoJo01.htm\")\n\n# rushing_receiving_data is now a rushing and receiving object that has all the information stored within sub-objects\n# Methods will need to be called to obtain the relevant data to work with it\n\n# Rushing and Receiving Data Regular Season\nregular_season_rushing_receiving = rushing_receiving_data.get_rushing_receiving_data_regular_season()\n\n# Rushing and Receiving Data Playoffs\nplayoffs_rushing_receiving = rushing_receiving_data.get_rushing_receiving_data_playoffs()\n\n# Rushing and Receiving Data Advanced\nadvanced_rushing_receiving = rushing_receiving_data.get_rushing_receiving_data_advanced()\n\n# Once you have decided which data object you would like you can then utilize them the same way as Team Data.\n\n# Example: Regular Season Rushing and Receiving Data\n\n# Obtain the whole data set\nregular_season_rushing_receiving_dataframe = regular_season_rushing_receiving.get_dataframe_of_stats()\nregular_season_rushing_receiving_dictionary = regular_season_rushing_receiving.get_dictionary_of_stats()\n\n# Obtain specific data points\n# Set the reference year\nregular_season_rushing_receiving.set_reference_year(2022)\n\n# Call the methods for specific data points\nplayers_age = regular_season_rushing_receiving.get_age()\ngames_played = regular_season_rushing_receiving.get_games_played()\ngames_started = regular_season_rushing_receiving.get_games_started()\n```\n\n##### Scoring Data Object Usage\n```python\nfrom PFRWebScraper import ScrapePlayerData\n\n# Creates an instance of the Player Scraper Object\nplayer_scraper = ScrapePlayerData()\n\n# Scrapes for all scoring data on a player's page\nscoring_data = player_scraper.scrape_scoring(\"https://www.pro-football-reference.com/players/R/RenfHu00.htm\")\n\n# scoring_data is now a scoring object that has all the information stored within sub-objects\n# Methods will need to be called to obtain the relevant data to work with it\n\n# Scoring Data Regular Season\nregular_season_scoring = scoring_data.get_scoring_data_regular_season()\n\n# Scoring Data Playoffs\nplayoffs_scoring = scoring_data.get_scoring_data_playoffs()\n\n# Once you have decided which data object you would like you can then utilize them the same way as Team Data.\n\n# Example: Regular Season Scoring Data\n\n# Obtain the whole data set\nregular_season_scoring_dataframe = regular_season_scoring.get_dataframe_of_stats()\nregular_season_scoring_dictionary = regular_season_scoring.get_dictionary_of_stats()\n\n# Obtain specific data points\n# Set the reference year\nregular_season_scoring.set_reference_year(2022)\n\n# Call the methods for specific data points\nplayers_age = regular_season_scoring.get_age()\ngames_played = regular_season_scoring.get_games_played()\ngames_started = regular_season_scoring.get_games_started()\n```\n\n##### Snap Counts Data Object Usage\n```python\nfrom PFRWebScraper import ScrapePlayerData\n\n# Creates an instance of the Player Scraper Object\nplayer_scraper = ScrapePlayerData()\n\n# Scrapes for all snap counts data on a player's page\nsnap_counts_data = player_scraper.scrape_snap_counts(\"https://www.pro-football-reference.com/players/W/WallDa01.htm\")\n\n# snap_counts_data is now a snap counts object that has all the information stored within sub-objects\n# Methods will need to be called to obtain the relevant data to work with it\n\n# Snap Counts Data Regular Season\nregular_season_snap_counts = snap_counts_data.get_snap_counts_data_regular_season()\n\n# Once you have decided which data object you would like you can then utilize them the same way as Team Data.\n\n# Example: Regular Season Snap Counts Data\n\n# Obtain the whole data set\nregular_season_snap_counts_dataframe = regular_season_snap_counts.get_dataframe_of_stats()\nregular_season_snap_counts_dictionary = regular_season_snap_counts.get_dictionary_of_stats()\n\n# Obtain specific data points\n# Set the reference year\nregular_season_snap_counts.set_reference_year(2022)\n\n# Call the methods for specific data points\nplayers_age = regular_season_snap_counts.get_age()\ngames_played = regular_season_snap_counts.get_games_played()\ngames_started = regular_season_snap_counts.get_games_started()\n```\n\n##### Defense and Fumbles Data Object Usage\n```python\nfrom PFRWebScraper import ScrapePlayerData\n\n# Creates an instance of the Player Scraper Object\nplayer_scraper = ScrapePlayerData()\n\n# Scrapes for all defense and fumbles data on a player's page\ndefense_and_fumbles_data = player_scraper.scrape_defense_and_fumbles(\"https://www.pro-football-reference.com/players/A/AdamDa01.htm\")\n\n# defense_and_fumbles_data is now a defense and fumbles object that has all the information stored within sub-objects\n# Methods will need to be called to obtain the relevant data to work with it\n\n# Defense and Fumbles Data Regular Season\nregular_season_defense_and_fumbles = defense_and_fumbles_data.get_defense_and_fumbles_data_regular_season()\n\n# Defense and Fumbles Data Playoffs\nplayoffs_defense_and_fumbles = defense_and_fumbles_data.get_defense_and_fumbles_data_playoffs()\n\n# Once you have decided which data object you would like you can then utilize them the same way as Team Data.\n\n# Example: Regular Season Defense and Fumbles Data\n\n# Obtain the whole data set\nregular_season_defense_and_fumbles_dataframe = regular_season_defense_and_fumbles.get_dataframe_of_stats()\nregular_season_defense_and_fumbles_dictionary = regular_season_defense_and_fumbles.get_dictionary_of_stats()\n\n# Obtain specific data points\n# Set the reference year\nregular_season_defense_and_fumbles.set_reference_year(2022)\n\n# Call the methods for specific data points\nplayers_age = regular_season_defense_and_fumbles.get_age()\ngames_played = regular_season_defense_and_fumbles.get_games_played()\ngames_started = regular_season_defense_and_fumbles.get_games_started()\n```\n\n##### Kick and Punt Returns Data Object Usage\n```python\nfrom PFRWebScraper import ScrapePlayerData\n\n# Creates an instance of the Player Scraper Object\nplayer_scraper = ScrapePlayerData()\n\n# Scrapes for all kick and punt returns data on a player's page\nreturns_data = player_scraper.scrape_kick_and_punt_returns(\"https://www.pro-football-reference.com/players/A/AbduAm00.htm\")\n\n# returns_data is now a kick and punt returns object that has all the information stored within sub-objects\n# Methods will need to be called to obtain the relevant data to work with it\n\n# Kick and Punt Returns Data Regular Season\nregular_season_returns = returns_data.get_returns_data_regular_season()\n\n# Kick and Punt Returns Data Playoffs\nplayoffs_returns = returns_data.get_returns_data_playoffs()\n\n# Once you have decided which data object you would like you can then utilize them the same way as Team Data.\n\n# Example: Regular Season Kick and Punt Returns Data\n\n# Obtain the whole data set\nregular_season_returns_dataframe = regular_season_returns.get_dataframe_of_stats()\nregular_season_returns_dictionary = regular_season_returns.get_dictionary_of_stats()\n\n# Obtain specific data points\n# Set the reference year\nregular_season_returns.set_reference_year(2022)\n\n# Call the methods for specific data points\nplayers_age = regular_season_returns.get_age()\ngames_played = regular_season_returns.get_games_played()\ngames_started = regular_season_returns.get_games_started()\n```\n\n##### Kicking Data Object Usage\n```python\nfrom PFRWebScraper import ScrapePlayerData\n\n# Creates an instance of the Player Scraper Object\nplayer_scraper = ScrapePlayerData()\n\n# Scrapes for all kicking data on a player's page\nkicking_data = player_scraper.scrape_kicking(\"https://www.pro-football-reference.com/players/C/CarlDa00.htm\")\n\n# kicking_data is now a kicking object that has all the information stored within sub-objects\n# Methods will need to be called to obtain the relevant data to work with it\n\n# Kicking Data Regular Season\nregular_season_kicking = kicking_data.get_kicking_data_regular_season()\n\n# Kicking Data Playoffs\nplayoffs_kicking = kicking_data.get_kicking_data_playoffs()\n\n# Once you have decided which data object you would like you can then utilize them the same way as Team Data.\n\n# Example: Regular Season Kicking Data\n\n# Obtain the whole data set\nregular_season_returns_dataframe = regular_season_kicking.get_dataframe_of_stats()\nregular_season_returns_dictionary = regular_season_kicking.get_dictionary_of_stats()\n\n# Obtain specific data points\n# Set the reference year\nregular_season_kicking.set_reference_year(2022)\n\n# Call the methods for specific data points\nplayers_age = regular_season_kicking.get_age()\ngames_played = regular_season_kicking.get_games_played()\ngames_started = regular_season_kicking.get_games_started()\n```\n\n### Scraping URL Data\n#### Create URL Scraper and Method Usage\n##### Scraping Team for Player URLs\n```python\nfrom PFRWebScraper import ScrapeURLs\n\n# Creates an instance of the URL Scraper Object\nurl_scraper = ScrapeURLs()\n\n# Scrapes for Player's URLs that are on the specified team\n# You can set the specific year BUT if you dont want to it is always set \n#   to the current year\nplayer_url_data = url_scraper.scrape_team_for_player_urls(\"Las Vegas Raiders\")\n\n# Example on how to scrape for specific year\nplayer_url_data = url_scraper.scrape_team_for_player_urls(\"Las Vegas Raiders\", 2021)\n\n# player_url_data will now be an object containing the player's URLs\n# Methods can be called on that object to access the information\n\n# Examples:\n\n# Obtain a dictionary of all the players with the position as the KEY \n#   and the VALUE will be a list of dictionaries containing the player's \n#   name and URL\nteam_players_urls_dict = player_url_data.get_dictionaries_of_urls()\n\n# Example Data from get_dictionaries_of_urls(): \n#   {\n#     \"QB\": \n#          [\n#            {\n#              \"name\": \"Derek Carr\", \n#              \"url\": \"https://www.pro-football-reference.com/players/C/CarrDe02.htm\"\n#            }, \n#            { \n#              \"name\": \"Jarrett Stidham\", \n#              \"url\": \"https://www.pro-football-reference.com/players/S/StidJa00.htm\"\n#            }\n#          ], \n#     \"RB\": \n#          [\n#            { \n#              \"name\": \"Josh Jacobs\", \n#              \"url\": \"https://www.pro-football-reference.com/players/J/JacoJo01.htm\"\n#            }\n#          ]\n#   }\n\n# Obtaining the URLs of players listed as a Quarterback in the form of a list of dictionaries\nquarterback_urls = player_url_data.get_quarterbacks()\n\n# Obtaining the URLs of players listed as a Running Back in the form of a list of dictionaries\nrunning_back_urls = player_url_data.get_running_backs()\n\n# Obtaining the URLs of players listed as a Fullback in the form of a list of dictionaries\nfullback_urls = player_url_data.get_fullbacks()\n\n# Obtaining the URLs of players listed as a Wide Receiver in the form of a list of dictionaries\nwide_receiver_urls = player_url_data.get_wide_receivers()\n\n# Obtaining the URLs of players listed as a Tight End in the form of a list of dictionaries\ntight_end_urls = player_url_data.get_tight_ends()\n\n# Obtaining the URLs of players listed as a Kicker in the form of a list of dictionaries\nkicker_urls = player_url_data.get_kickers()\n\n# Example Data from get_quarterbacks():\n# [\n#   {\n#     \"name\": \"Derek Carr\", \n#     \"url\": \"https://www.pro-football-reference.com/players/C/CarrDe02.htm\"\n#   }, \n#   { \n#     \"name\": \"Jarrett Stidham\", \n#     \"url\": \"https://www.pro-football-reference.com/players/S/StidJa00.htm\"\n#   }\n# ]\n```\n\n##### Scraping Stat Type for Player URLs\n```python\nfrom PFRWebScraper import ScrapeURLs\n\n# Creates an instance of the URL Scraper Object\nurl_scraper = ScrapeURLs()\n\n# Scrapes for Player's URLs that are listed within that specific stat type list\n# You can set the specific year BUT if you dont want to it is always set \n#   to the current year\n\n# Example on how to scrape for current year and passing list\npassing_player_url_data = url_scraper.scrape_stat_type_for_player_urls(\"passing\")\n\n# Example on how to scrape for 2021 and rushing list\nrushing_player_url_data = url_scraper.scrape_stat_type_for_player_urls(\"rushing\", 2021)\n\n# Example on how to scrape for 2020 and receiving list\nreceiving_player_url_data = url_scraper.scrape_stat_type_for_player_urls(\"receiving\", 2020)\n\n# Example on how to scrape for current year and kicking list\nkicking_player_url_data = url_scraper.scrape_stat_type_for_player_urls(\"kicking\")\n\n# Example on how to scrape for current year and returns list\nreturns_player_url_data = url_scraper.scrape_stat_type_for_player_urls(\"returns\")\n\n# Example on how to scrape for current year and scoring list\nscoring_player_url_data = url_scraper.scrape_stat_type_for_player_urls(\"scoring\")\n\n# Obtain a list of dictionaries containing the player's name and url\npassing_players_urls_list = passing_player_url_data.get_list_of_urls()\n\n# Example Data from get_list_of_urls():\n# [\n#   {\n#     \"name\": \"Derek Carr\", \n#     \"url\": \"https://www.pro-football-reference.com/players/C/CarrDe02.htm\"\n#   }, \n#   { \n#     \"name\": \"Patrick Mahomes\", \n#     \"url\": \"https://www.pro-football-reference.com/players/M/MahoPa00.htm\"\n#   }, \n#   { \n#     \"name\": \"Joe Burrow\", \n#     \"url\": \"https://www.pro-football-reference.com/players/B/BurrJo01.htm\"\n#   }, \n#   { \n#     \"name\": \"Justin Herbert\", \n#     \"url\": \"https://www.pro-football-reference.com/players/H/HerbJu00.htm\"\n#   }, \n#   { \n#     \"name\": \"Tom Brady\", \n#     \"url\": \"https://www.pro-football-reference.com/players/B/BradTo00.htm\"\n#   }\n# ]\n\n# Obtain the number of dictionaries within the list\ncount_of_passing_players_urls_list = passing_player_url_data.get_count_of_urls()\n\n# Using the sample data the method get_count_of_urls() would return 5\n\n# Obtain a list of dictionaries, to the specified range, containing the player's name and url\nrange_of_passing_players_urls_list = passing_player_url_data.get_range_of_urls(1, 3)\n\n# Example Data from get_range_of_urls(1, 3):\n# [\n#   {\n#     \"name\": \"Derek Carr\", \n#     \"url\": \"https://www.pro-football-reference.com/players/C/CarrDe02.htm\"\n#   }, \n#   { \n#     \"name\": \"Patrick Mahomes\", \n#     \"url\": \"https://www.pro-football-reference.com/players/M/MahoPa00.htm\"\n#   }, \n#   { \n#     \"name\": \"Joe Burrow\", \n#     \"url\": \"https://www.pro-football-reference.com/players/B/BurrJo01.htm\"\n#   }\n# ]\n```",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "python,pro-football-reference,football,fantasy football,american football,pro football reference,web scraper,scraper",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "PFRWebScraper",
    "package_url": "https://pypi.org/project/PFRWebScraper/",
    "platform": null,
    "project_url": "https://pypi.org/project/PFRWebScraper/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/PFRWebScraper/1.0.2/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "Scrapes statistics from https://www.pro-football-reference.com/",
    "version": "1.0.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16246144,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ac98de6db14b7de977caa5eb0117b501720ba09bec7f98fc317c893d67d3538d",
          "md5": "0145e0785f260918e8b05e66f48fad64",
          "sha256": "0fab350c3d6dfb9a0c83076adf783f640ee0979d9381adaf3c3030826f53c815"
        },
        "downloads": -1,
        "filename": "PFRWebScraper-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0145e0785f260918e8b05e66f48fad64",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 7382,
        "upload_time": "2022-12-27T23:22:34",
        "upload_time_iso_8601": "2022-12-27T23:22:34.788741Z",
        "url": "https://files.pythonhosted.org/packages/ac/98/de6db14b7de977caa5eb0117b501720ba09bec7f98fc317c893d67d3538d/PFRWebScraper-0.0.1-py3-none-any.whl",
        "yanked": true,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "918a7370efba6216933c20f75d3aa11d0290edbb8ff57ee5c4e4d3aa7380980e",
          "md5": "b8905f83d4ebe268977bfde7ec404571",
          "sha256": "a955a6ce69b91b6cf47cdf25cb564d891af78ad91e0f92c69870e8cf2958d1a0"
        },
        "downloads": -1,
        "filename": "PFRWebScraper-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "b8905f83d4ebe268977bfde7ec404571",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 8596,
        "upload_time": "2022-12-27T23:22:36",
        "upload_time_iso_8601": "2022-12-27T23:22:36.252479Z",
        "url": "https://files.pythonhosted.org/packages/91/8a/7370efba6216933c20f75d3aa11d0290edbb8ff57ee5c4e4d3aa7380980e/PFRWebScraper-0.0.1.tar.gz",
        "yanked": true,
        "yanked_reason": null
      }
    ],
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "10e59a963b22c8a9a0886b0f5b6591bb40a3fbe0119e236ce8fec085b4ad509e",
          "md5": "84b8bbf6168deda5be47934b3798ddab",
          "sha256": "3e96bd8256b006c48ab0e44d00b199830fe05e7f75c3916054f7015ed363ba40"
        },
        "downloads": -1,
        "filename": "PFRWebScraper-1.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "84b8bbf6168deda5be47934b3798ddab",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 96175,
        "upload_time": "2022-12-28T05:57:21",
        "upload_time_iso_8601": "2022-12-28T05:57:21.485167Z",
        "url": "https://files.pythonhosted.org/packages/10/e5/9a963b22c8a9a0886b0f5b6591bb40a3fbe0119e236ce8fec085b4ad509e/PFRWebScraper-1.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "517aa3b63f76e8c19d237d7ad36f6ce79672c9f93b4454b51933122d0853d112",
          "md5": "3ae6ad30eaedd9b572891060e79699ab",
          "sha256": "ac22807e002cd8bccbb39d73b05881aad5b553871a7cf565068cdd73e3482612"
        },
        "downloads": -1,
        "filename": "PFRWebScraper-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "3ae6ad30eaedd9b572891060e79699ab",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 56621,
        "upload_time": "2022-12-28T05:57:23",
        "upload_time_iso_8601": "2022-12-28T05:57:23.030515Z",
        "url": "https://files.pythonhosted.org/packages/51/7a/a3b63f76e8c19d237d7ad36f6ce79672c9f93b4454b51933122d0853d112/PFRWebScraper-1.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7285495bb6e0e0e4080d5690accce241f5581fb6766789c450399afa25d32888",
          "md5": "0f68177a20565cadf4e37913cbad76a3",
          "sha256": "adf4f00f77de02f9f6f4ea7223cf5ceaa0feb75a9c4ce8254eda95698c8ac4d5"
        },
        "downloads": -1,
        "filename": "PFRWebScraper-1.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0f68177a20565cadf4e37913cbad76a3",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 99441,
        "upload_time": "2022-12-28T06:05:27",
        "upload_time_iso_8601": "2022-12-28T06:05:27.087727Z",
        "url": "https://files.pythonhosted.org/packages/72/85/495bb6e0e0e4080d5690accce241f5581fb6766789c450399afa25d32888/PFRWebScraper-1.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c68ab9d4048d60b0d7d2d7caccb0403472f969b2430f6806eb223004530cef8c",
          "md5": "0ce68e97ce112c080e1921a72fef31d5",
          "sha256": "9a4b5fc0bee2c44539249a41afc66c2678a9e8c152effc6078c6685a9298323c"
        },
        "downloads": -1,
        "filename": "PFRWebScraper-1.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "0ce68e97ce112c080e1921a72fef31d5",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 61368,
        "upload_time": "2022-12-28T06:05:28",
        "upload_time_iso_8601": "2022-12-28T06:05:28.868268Z",
        "url": "https://files.pythonhosted.org/packages/c6/8a/b9d4048d60b0d7d2d7caccb0403472f969b2430f6806eb223004530cef8c/PFRWebScraper-1.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d505d5f6256ce21d4a0ac9c8d73057d186c05cdef9e25e30fc13aab9e6d7ae86",
          "md5": "ce1a5111fe41c145fc7849513b52dc09",
          "sha256": "0cf700ce4301dab9b493756592762f3bff2876639fb8b9a3e3c7813c259a409f"
        },
        "downloads": -1,
        "filename": "PFRWebScraper-1.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "ce1a5111fe41c145fc7849513b52dc09",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 60983,
        "upload_time": "2022-12-29T06:49:31",
        "upload_time_iso_8601": "2022-12-29T06:49:31.755056Z",
        "url": "https://files.pythonhosted.org/packages/d5/05/d5f6256ce21d4a0ac9c8d73057d186c05cdef9e25e30fc13aab9e6d7ae86/PFRWebScraper-1.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "d505d5f6256ce21d4a0ac9c8d73057d186c05cdef9e25e30fc13aab9e6d7ae86",
        "md5": "ce1a5111fe41c145fc7849513b52dc09",
        "sha256": "0cf700ce4301dab9b493756592762f3bff2876639fb8b9a3e3c7813c259a409f"
      },
      "downloads": -1,
      "filename": "PFRWebScraper-1.0.2.tar.gz",
      "has_sig": false,
      "md5_digest": "ce1a5111fe41c145fc7849513b52dc09",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 60983,
      "upload_time": "2022-12-29T06:49:31",
      "upload_time_iso_8601": "2022-12-29T06:49:31.755056Z",
      "url": "https://files.pythonhosted.org/packages/d5/05/d5f6256ce21d4a0ac9c8d73057d186c05cdef9e25e30fc13aab9e6d7ae86/PFRWebScraper-1.0.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}