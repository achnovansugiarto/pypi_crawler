{
  "info": {
    "author": "",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 2 - Pre-Alpha",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Natural Language :: English",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3 :: Only",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: Implementation :: CPython",
      "Programming Language :: Python :: Implementation :: PyPy"
    ],
    "description": "# os-scrapy-rq-crawler\n\n[![Build Status](https://www.travis-ci.org/cfhamlet/os-scrapy-rq-crawler.svg?branch=master)](https://www.travis-ci.org/cfhamlet/os-scrapy-rq-crawler)\n[![codecov](https://codecov.io/gh/cfhamlet/os-scrapy-rq-crawler/branch/master/graph/badge.svg)](https://codecov.io/gh/cfhamlet/os-scrapy-rq-crawler)\n[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/os-scrapy-rq-crawler.svg)](https://pypi.python.org/pypi/os-scrapy-rq-crawler)\n[![PyPI](https://img.shields.io/pypi/v/os-scrapy-rq-crawler.svg)](https://pypi.python.org/pypi/os-scrapy-rq-crawler)\n\nThis project provide Crawler for RQ mode. Based on Scrapy 2.0+, require Python 3.6+\n\nThe [Scrapy](https://scrapy.org/) framework is used for crawling specific sites. It is not good for [\"Broad Crawls\"](https://docs.scrapy.org/en/latest/topics/broad-crawls.html). The Scrapy built-in schedule mechanism is not for many domains, it use one channel queue for requests of all different domains. The scheduler can not decide to crawl request of the specified domain.\n\nThe RQ mode is the key mechanism/concept for broad crawls. The key point is RQ(request queue), actually it is a banch of queues, requests of different domains in the different sub-queues. \n\nDeploy with the [os-rq-pod](https://github.com/cfhamlet/os-rq-pod) and [os-rq-hub](https://github.com/cfhamlet/os-rq-hub) you can build a large scalable distributed \"Broad Crawls\" system.\n\n## Quick Start\n\nWe offer Crawler for RQ mode. Because the Scrapy framework can not custom Crawler class, so you can use [os-scrapy](https://github.com/cfhamlet/os-scrapy)(installed with this project) to start crawling. \n\n* install\n\n    ```\n    pip install os-scrapy-rq-crawler\n    ```\n\n* start your project \n\n    ```\n    os-scrapy startproject <your_project>\n    ```\n\n* set Crawler class and [enable asyncio reactor](https://docs.scrapy.org/en/latest/topics/asyncio.html) in project setting.py\n\n    ```\n    CRAWLER_CLASS = \"os_scrapy_rq_crawler.asyncio.Crawler\"\n    TWISTED_REACTOR = \"twisted.internet.asyncioreactor.AsyncioSelectorReactor\"\n    ```\n\n* start crawling example spider\n\n    ```\n    os-scrapy crawl example\n    ```\n\n## Install\n\n```\npip install os-scrapy-rq-crawler\n```\n\nWhen you already installed os-scrapy, you can run example spider directly in this project root path\n\n```\nos-scrapy crawl example\n```\n\n\n## Usage\n\nThis project offer Crawler class can be used in your project by config in settings.py file. And it can also be used as a scrapy project directly.\n\n### Crawler Class\n\nThis project provide Crawler to enable RQ mode. The Scrapy framework can not config Crawler class, so you can use [os-scrapy](https://github.com/cfhamlet/os-scrapy) to specify\n\n* in the settings.py\n\n    ```\n    CRAWLER_CLASS = \"os_scrapy_rq_crawler.asyncio.Crawler\"\n    ```\n\n* or with ``-c`` command line option\n\n    ```\n    os-scrapy crawl -c os_scrapy_rq_crawler.asyncio.Crawler example\n    ```\n\nBecause the Crawler deponds on asyncio reactor, so you need to enable it\n\n* in the settings.py\n\n    ```\n    TWISTED_REACTOR = \"twisted.internet.asyncioreactor.AsyncioSelectorReactor\"\n    ```\n\n* or with ``-r`` command line option\n\n    ```\n    os-scrapy crawl -r asyncio example\n    ```\n\n### Request Queue\n\nRQ is just a conception can be implements in different ways.\n\n* config in the settings.py file\n\n    ```\n    SCHEDULER_REQUEST_QUEUE = \"os_scrapy_rq_crawler.AsyncRequestQueue\"\n    ```\n\n* ``os_scrapy_rq_crawler.MemoryRequestQueue``\n\n    - the default requet queue\n    - all requests in memory\n    - the spider closed when no requests in the queue and [spider is idle](https://docs.scrapy.org/en/latest/topics/signals.html?highlight=idle#spider-idle)\n\n* ``os_scrapy_rq_crawler.AsyncRequestQueue``\n\n    - can be used with [os-rq-pod](https://github.com/cfhamlet/os-rq-pod) or [os-rq-hub](https://github.com/cfhamlet/os-rq-hub) as external request queue\n    - the spider will not closed even if no requests to crawl\n    - config the pod/hub http api in the settings.py\n\n        ```\n        RQ_API = \"http://localhost:6789/api/\"\n        ```\n\n    - config the api timeout\n\n        ```\n        RQ_API_TIMEOUT = 3.0\n        ```\n\n* ``os_scrapy_rq_crawler.MultiUpstreamRequestQueue``\n\n    - same as ``os_scrapy_rq_crawler.AsyncRequestQueue``, can configure multi upstreams request queues\n\n    - config the pod/hub http apis in the settings.py\n\n        ```\n        RQ_API = [\"http://server01:6789/api/\", \"http://server02:6789/api/\"]\n        ```\n\n### FYI\n\nOur RQ mode Crawler is a substitute of the Scrapy built-in Crawler. Most of the Scrapy functionalities(middleware/extension) can also be used as normal.\n\nThere are some tips:\n\n* the request queue is fifo, priority is not supported yet\n* the requests come from downloader middlewares will push to the head of the request queue\n* the request of the same domain will not crawl concurrently, ``CONCURRENT_REQUESTS`` control the max concurrency and ``DOWNLOAD_DELAY`` control the download dely\n* you can set request delay: request.meta[\"download_delay\"] = 3.0\n\n\n## Unit Tests\n\n```\nsh scripts/test.sh\n```\n\n## License\n\nMIT licensed.",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "MIT License",
    "maintainer": "",
    "maintainer_email": "",
    "name": "os-scrapy-rq-crawler",
    "package_url": "https://pypi.org/project/os-scrapy-rq-crawler/",
    "platform": "",
    "project_url": "https://pypi.org/project/os-scrapy-rq-crawler/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/os-scrapy-rq-crawler/0.0.12/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "Scrapy Crawler for RQ",
    "version": "0.0.12",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8901710,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "29490618aa48303eb5706f5eaf5ca9965f71452b6b145508dfbe630b908437a7",
          "md5": "76da810e8e91f373570e7215ae9c0f06",
          "sha256": "62187fff0bf548496804c2e6d6c8a1cdd1ecc5c7beb6c800767f3fac5a586c1a"
        },
        "downloads": -1,
        "filename": "os-scrapy-rq-crawler-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "76da810e8e91f373570e7215ae9c0f06",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 13541,
        "upload_time": "2020-05-26T08:41:27",
        "upload_time_iso_8601": "2020-05-26T08:41:27.002812Z",
        "url": "https://files.pythonhosted.org/packages/29/49/0618aa48303eb5706f5eaf5ca9965f71452b6b145508dfbe630b908437a7/os-scrapy-rq-crawler-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.10": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "35df8c32b0535619cb88ad07e97ff2f62636ce93e080e5edad4e1e868489bd93",
          "md5": "bb3e2396426285e2a4e2ff83af81b522",
          "sha256": "88b2b4d8fd79606c840fc5f0683ab10d457176059d8477524c2d142b5c3b4a47"
        },
        "downloads": -1,
        "filename": "os-scrapy-rq-crawler-0.0.10.tar.gz",
        "has_sig": false,
        "md5_digest": "bb3e2396426285e2a4e2ff83af81b522",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 13565,
        "upload_time": "2020-10-12T12:02:11",
        "upload_time_iso_8601": "2020-10-12T12:02:11.200492Z",
        "url": "https://files.pythonhosted.org/packages/35/df/8c32b0535619cb88ad07e97ff2f62636ce93e080e5edad4e1e868489bd93/os-scrapy-rq-crawler-0.0.10.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.11": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c871247bdd9ebb5da2aa6aa053f263f75ff211d68489deeff97c2c02aabcff28",
          "md5": "c2f431acc602e552b05698903b8e631a",
          "sha256": "e8cecaaa56288b1eb5bff9ea96693e94cb3ec5c998b9214ad3085a0c6b94692a"
        },
        "downloads": -1,
        "filename": "os-scrapy-rq-crawler-0.0.11.tar.gz",
        "has_sig": false,
        "md5_digest": "c2f431acc602e552b05698903b8e631a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 14570,
        "upload_time": "2020-12-14T13:12:21",
        "upload_time_iso_8601": "2020-12-14T13:12:21.320707Z",
        "url": "https://files.pythonhosted.org/packages/c8/71/247bdd9ebb5da2aa6aa053f263f75ff211d68489deeff97c2c02aabcff28/os-scrapy-rq-crawler-0.0.11.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.12": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e336a4df1ab4d89ff0d44b890cf2c2487620d14ca840c3ac71975ad72aba2551",
          "md5": "916b7f4f25f4caa2df43d8bd7a8049ba",
          "sha256": "5ab1e21535172107fc9b09ef70116a49ad5e6fbca28e8f10a01dbacd8430075f"
        },
        "downloads": -1,
        "filename": "os-scrapy-rq-crawler-0.0.12.tar.gz",
        "has_sig": false,
        "md5_digest": "916b7f4f25f4caa2df43d8bd7a8049ba",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 14638,
        "upload_time": "2020-12-15T04:59:23",
        "upload_time_iso_8601": "2020-12-15T04:59:23.847464Z",
        "url": "https://files.pythonhosted.org/packages/e3/36/a4df1ab4d89ff0d44b890cf2c2487620d14ca840c3ac71975ad72aba2551/os-scrapy-rq-crawler-0.0.12.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "be5915c2938dc2923f32a8288521612b181827290995889e785727d81b9d5bc6",
          "md5": "4234a4ef0085099cbfb013f7a79be1b7",
          "sha256": "c1e4349332e8ef942ab6d38694157df2e442bb410e51fc02e580ec377651e1f0"
        },
        "downloads": -1,
        "filename": "os-scrapy-rq-crawler-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "4234a4ef0085099cbfb013f7a79be1b7",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 13583,
        "upload_time": "2020-06-03T06:26:33",
        "upload_time_iso_8601": "2020-06-03T06:26:33.574493Z",
        "url": "https://files.pythonhosted.org/packages/be/59/15c2938dc2923f32a8288521612b181827290995889e785727d81b9d5bc6/os-scrapy-rq-crawler-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1fc88e45dcc7f095c5e9da60563c68765c1f10d1a624aad205ee5bf04db1d8bf",
          "md5": "36272cc18975284b0916a2a459f86f38",
          "sha256": "3f975897b04acd4bdb99f30a7fda424ebd7a1f898f4c237fec0dfb7102016401"
        },
        "downloads": -1,
        "filename": "os-scrapy-rq-crawler-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "36272cc18975284b0916a2a459f86f38",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 13590,
        "upload_time": "2020-07-14T13:14:43",
        "upload_time_iso_8601": "2020-07-14T13:14:43.370265Z",
        "url": "https://files.pythonhosted.org/packages/1f/c8/8e45dcc7f095c5e9da60563c68765c1f10d1a624aad205ee5bf04db1d8bf/os-scrapy-rq-crawler-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e39213268242044a073b6ec191d8da182962762c7979842566d77247ca80eba6",
          "md5": "dfeac57d06618bd7603f0614606d73bd",
          "sha256": "9582cf272a3b1e967ac172f4494516821366e105a9c5fad9d84ce2905894644c"
        },
        "downloads": -1,
        "filename": "os-scrapy-rq-crawler-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "dfeac57d06618bd7603f0614606d73bd",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 13728,
        "upload_time": "2020-07-22T08:41:35",
        "upload_time_iso_8601": "2020-07-22T08:41:35.785462Z",
        "url": "https://files.pythonhosted.org/packages/e3/92/13268242044a073b6ec191d8da182962762c7979842566d77247ca80eba6/os-scrapy-rq-crawler-0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8657124f77e36b988f98635039bce4d59ab32420736ff608f12efbc924a69d84",
          "md5": "818c65f6a8afc20baebb177fac10ffcc",
          "sha256": "d8b787c3e4d079b8077afb16968cd6c65e203ff5d3b280c53260301d0bbcba16"
        },
        "downloads": -1,
        "filename": "os-scrapy-rq-crawler-0.0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "818c65f6a8afc20baebb177fac10ffcc",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 13766,
        "upload_time": "2020-07-24T15:27:42",
        "upload_time_iso_8601": "2020-07-24T15:27:42.791616Z",
        "url": "https://files.pythonhosted.org/packages/86/57/124f77e36b988f98635039bce4d59ab32420736ff608f12efbc924a69d84/os-scrapy-rq-crawler-0.0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c3c7bc08d508c708775439e5fc9bde7848125212a4cc0a01a0ed76599b65f0d9",
          "md5": "66d5b37f0a352448341c9564ef969577",
          "sha256": "30e928e83d5fd3b64237ab2349f3cbb24d993661528f202fff64f7c46affa2d7"
        },
        "downloads": -1,
        "filename": "os-scrapy-rq-crawler-0.0.6.tar.gz",
        "has_sig": false,
        "md5_digest": "66d5b37f0a352448341c9564ef969577",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 13420,
        "upload_time": "2020-07-26T11:46:20",
        "upload_time_iso_8601": "2020-07-26T11:46:20.602872Z",
        "url": "https://files.pythonhosted.org/packages/c3/c7/bc08d508c708775439e5fc9bde7848125212a4cc0a01a0ed76599b65f0d9/os-scrapy-rq-crawler-0.0.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b4ec22e792f7baace974b7840339d4a3a9134b9cc2eff9613e02ef4881568dcc",
          "md5": "4fdf261bba4dabd545cc59f4a81e3fe6",
          "sha256": "9a24d609f6f8a73e7620163bdf56542296189eeeebcd161e6fad9293e4f53f2c"
        },
        "downloads": -1,
        "filename": "os-scrapy-rq-crawler-0.0.7.tar.gz",
        "has_sig": false,
        "md5_digest": "4fdf261bba4dabd545cc59f4a81e3fe6",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 13423,
        "upload_time": "2020-08-19T07:37:45",
        "upload_time_iso_8601": "2020-08-19T07:37:45.950154Z",
        "url": "https://files.pythonhosted.org/packages/b4/ec/22e792f7baace974b7840339d4a3a9134b9cc2eff9613e02ef4881568dcc/os-scrapy-rq-crawler-0.0.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "58873e3ce3cc94c3d01917bee37c14021efb2f3ee31d731f7d1968ac235c1c13",
          "md5": "0c8fca23c8e8de8ea1a792d44230a2d2",
          "sha256": "6000fcaf959f18693c5f390fe4a986952b4562108f319368fa6b79f1707703c1"
        },
        "downloads": -1,
        "filename": "os-scrapy-rq-crawler-0.0.8.tar.gz",
        "has_sig": false,
        "md5_digest": "0c8fca23c8e8de8ea1a792d44230a2d2",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 13488,
        "upload_time": "2020-08-20T04:40:46",
        "upload_time_iso_8601": "2020-08-20T04:40:46.052418Z",
        "url": "https://files.pythonhosted.org/packages/58/87/3e3ce3cc94c3d01917bee37c14021efb2f3ee31d731f7d1968ac235c1c13/os-scrapy-rq-crawler-0.0.8.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.9": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "674272eeabf825c213a3166b4e8681cebf04b25ef77ed03840064c2826695d71",
          "md5": "9979a64afc1570e966b51134070a3856",
          "sha256": "f1979a348fec0cb7d76ae77211eba189e6fbd3f9ed5c0b4139a1f4f1b20f8775"
        },
        "downloads": -1,
        "filename": "os-scrapy-rq-crawler-0.0.9.tar.gz",
        "has_sig": false,
        "md5_digest": "9979a64afc1570e966b51134070a3856",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 13553,
        "upload_time": "2020-09-02T06:02:29",
        "upload_time_iso_8601": "2020-09-02T06:02:29.317307Z",
        "url": "https://files.pythonhosted.org/packages/67/42/72eeabf825c213a3166b4e8681cebf04b25ef77ed03840064c2826695d71/os-scrapy-rq-crawler-0.0.9.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "e336a4df1ab4d89ff0d44b890cf2c2487620d14ca840c3ac71975ad72aba2551",
        "md5": "916b7f4f25f4caa2df43d8bd7a8049ba",
        "sha256": "5ab1e21535172107fc9b09ef70116a49ad5e6fbca28e8f10a01dbacd8430075f"
      },
      "downloads": -1,
      "filename": "os-scrapy-rq-crawler-0.0.12.tar.gz",
      "has_sig": false,
      "md5_digest": "916b7f4f25f4caa2df43d8bd7a8049ba",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 14638,
      "upload_time": "2020-12-15T04:59:23",
      "upload_time_iso_8601": "2020-12-15T04:59:23.847464Z",
      "url": "https://files.pythonhosted.org/packages/e3/36/a4df1ab4d89ff0d44b890cf2c2487620d14ca840c3ac71975ad72aba2551/os-scrapy-rq-crawler-0.0.12.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}