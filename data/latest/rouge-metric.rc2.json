{
  "info": {
    "author": "Jiahao Li",
    "author_email": "liplus17@163.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 2",
      "Programming Language :: Python :: 3",
      "Topic :: Text Processing :: Linguistic"
    ],
    "description": "# ROUGE Metric\n\n[![PyPI](https://img.shields.io/pypi/v/rouge-metric)](https://pypi.org/project/rouge-metric/)\n[![UnitTest](https://github.com/li-plus/rouge-metric/workflows/UnitTest/badge.svg?branch=master)](https://github.com/li-plus/rouge-metric/actions)\n[![codecov](https://codecov.io/gh/li-plus/rouge-metric/branch/master/graph/badge.svg)](https://codecov.io/gh/li-plus/rouge-metric)\n[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://github.com/li-plus/rouge-metric/blob/master/LICENSE)\n\nA fast Python implementation of full [ROUGE](https://www.aclweb.org/anthology/W04-1013/) metric for automatic summarization evaluation. A Python wrapper of the official `ROUGE-1.5.5.pl` Perl script is also available.\n\n## Features\n\nFor the Perl script wrapper:\n\n+ Easy to install: No need to manually download and configure the Perl scripts. It works as long as Perl is installed.\n+ Cross platform: Support Linux, macOS and Windows machines.\n+ Elegant CLI and API: A user-friendly API and a command line tool are available\n\nFor the Python implementation:\n\n+ Full ROUGE support: Implemented ROUGE-N, ROUGE-L, ROUGE-W, ROUGE-S and ROUGE-SU metrics, with multi-reference evaluation support.\n+ High speed: Pure Python implementation without invoking another process.\n+ Correctness: Produce the same results as `ROUGE-1.5.5.pl` on all ROUGE scores on single document scenarios. The multi-document results might be slightly different, since we do not adopt bootstrap resampling.\n+ Flexible and multi-lingual: We only focus on the language-agnostic tokens, and treat a sentence as a list of tokens. The language-aware pre-processing and tokenization are the freedom of user implementation. You may use different method to tokenize different languages, such as `nltk` for English and `jieba` for Chinese.\n\n## Installation\n\nInstall a stable version from PyPI.\n\n```sh\npip install rouge-metric\n```\n\nOr install the latest version from GitHub.\n\n```sh\npip install git+https://github.com/li-plus/rouge-metric.git@master\n```\n\nFor Windows users who want to use the `ROUGE-1.5.5.pl` script, please install [Strawberry Perl](http://strawberryperl.com/) and add its binary folder to `PATH`.\n\n## Quick Start\n\n### With Command Line Tool\n\nBasic usage:\n\n```sh\nrouge-metric [options] hypothesis reference [reference ...]\n```\n\nwhere the options are almost the same as the `ROUGE-1.5.5.pl` script. Run `rouge-metric -h` for more details.\n\nFor single document with single reference, specify two files.\n\n```sh\nrouge-metric sample/hypotheses/summary1.txt sample/references/summary1.1.txt -n 2 -w 1.2 -U -2 4\n```\n\nFor single document with multiple references, specify a hypothesis file and several reference files.\n\n```sh\nrouge-metric sample/hypotheses/summary1.txt sample/references/summary1.1.txt sample/references/summary1.2.txt -n 2 -w 1.2 -U -2 4\n```\n\nFor multiple documents with multiple references, specify two folders.\n\n```sh\nrouge-metric sample/hypotheses/ sample/references/ -n 2 -w 1.2 -U -2 4\n```\n\nIt directly calls the `ROUGE-1.5.5.pl` script and you get the original output.\n\n```\n---------------------------------------------\nA ROUGE-1 Average_R: 0.51822 (95%-conf.int. 0.42105 - 0.61538)\nA ROUGE-1 Average_P: 0.55556 (95%-conf.int. 0.44444 - 0.66667)\nA ROUGE-1 Average_F: 0.53622 (95%-conf.int. 0.43243 - 0.64000)\n---------------------------------------------\nA ROUGE-2 Average_R: 0.19519 (95%-conf.int. 0.11765 - 0.27273)\nA ROUGE-2 Average_P: 0.21250 (95%-conf.int. 0.12500 - 0.30000)\nA ROUGE-2 Average_F: 0.20346 (95%-conf.int. 0.12121 - 0.28572)\n---------------------------------------------\nA ROUGE-L Average_R: 0.51822 (95%-conf.int. 0.42105 - 0.61538)\nA ROUGE-L Average_P: 0.55556 (95%-conf.int. 0.44444 - 0.66667)\nA ROUGE-L Average_F: 0.53622 (95%-conf.int. 0.43243 - 0.64000)\n---------------------------------------------\nA ROUGE-W-1.2 Average_R: 0.33608 (95%-conf.int. 0.26618 - 0.40599)\nA ROUGE-W-1.2 Average_P: 0.47348 (95%-conf.int. 0.38525 - 0.56172)\nA ROUGE-W-1.2 Average_F: 0.39308 (95%-conf.int. 0.31483 - 0.47132)\n---------------------------------------------\nA ROUGE-S4 Average_R: 0.25495 (95%-conf.int. 0.13846 - 0.37143)\nA ROUGE-S4 Average_P: 0.29167 (95%-conf.int. 0.15000 - 0.43333)\nA ROUGE-S4 Average_F: 0.27200 (95%-conf.int. 0.14400 - 0.40000)\n---------------------------------------------\nA ROUGE-SU4 Average_R: 0.31495 (95%-conf.int. 0.19512 - 0.43478)\nA ROUGE-SU4 Average_P: 0.35527 (95%-conf.int. 0.21053 - 0.50000)\nA ROUGE-SU4 Average_F: 0.33382 (95%-conf.int. 0.20253 - 0.46511)\n```\n\n### With Perl Script API\n\nBesides the command line tool, you may also use `ROUGE-1.5.5.pl` programmatically. Note that it is only for English corpus. For non-English summaries, use the Python implementation instead, or convert the tokens to integers separated by space before evaluation.\n\n```python\nfrom rouge_metric import PerlRouge\n\nrouge = PerlRouge(rouge_n_max=3, rouge_l=True, rouge_w=True,\n    rouge_w_weight=1.2, rouge_s=True, rouge_su=True, skip_gap=4)\n\n# Load summary results and evaluate\nhypotheses = [\n    'how are you\\ni am fine',                       # document 1: hypothesis\n    'it is fine today\\nwe won the football game',   # document 2: hypothesis\n]\nreferences = [[\n    'how do you do\\nfine thanks',   # document 1: reference 1\n    'how old are you\\ni am three',  # document 1: reference 2\n], [\n    'it is sunny today\\nlet us go for a walk',  # document 2: reference 1\n    'it is a terrible day\\nwe lost the game',   # document 2: reference 2\n]]\n\nscores = rouge.evaluate(hypotheses, references)\nprint(scores)\n```\n\nThe output is like\n\n```\n{\n    'rouge-1': {\n        'r': 0.51822, 'r_conf_int': (0.42105, 0.61538),\n        'p': 0.55556, 'p_conf_int': (0.44444, 0.66667),\n        'f': 0.53622, 'f_conf_int': (0.43243, 0.64)\n    },\n    'rouge-2': {...}, 'rouge-3': {...}, 'rouge-l': {...},\n    'rouge-w-1.2': {...}, 'rouge-s4': {...}, 'rouge-su4': {...}\n}\n```\n\nYou may also evaluate summaries from existing files.\n\n```python\nfrom rouge_metric import PerlRouge\n\nhypothesis_dir = 'sample/hypotheses'\nreference_dir = 'sample/references'\nscores = PerlRouge().evaluate_from_files(hypothesis_dir, reference_dir)\nprint(scores)\n```\n\n### With Python Implementation\n\nA fast Python implementation is also available. It has similar API and supports multiple languages.\n\n```python\nfrom rouge_metric import PyRouge\n\n# Load summary results\nhypotheses = [\n    'how are you\\ni am fine',  # document 1: hypothesis\n    'it is fine today\\nwe won the football game',  # document 2: hypothesis\n]\nreferences = [[\n    'how do you do\\nfine thanks',  # document 1: reference 1\n    'how old are you\\ni am three',  # document 1: reference 2\n], [\n    'it is sunny today\\nlet us go for a walk',  # document 2: reference 1\n    'it is a terrible day\\nwe lost the game',  # document 2: reference 2\n]]\n\n# Evaluate document-wise ROUGE scores\nrouge = PyRouge(rouge_n=(1, 2, 4), rouge_l=True, rouge_w=True,\n                rouge_w_weight=1.2, rouge_s=True, rouge_su=True, skip_gap=4)\nscores = rouge.evaluate(hypotheses, references)\nprint(scores)\n```\n\nThe output is like\n\n```\n{\n    'rouge-1': {\n        'r': 0.5182186234817814,\n        'p': 0.5555555555555556,\n        'f': 0.5362379555927943\n    },\n    'rouge-2': {...}, 'rouge-4': {...}, 'rouge-l': {...},\n    'rouge-w-1.2': {...}, 'rouge-s4': {...}, 'rouge-su4': {...}\n}\n```\n\nBy default, sentences are separated by `'\\n'` and tokens are separated by white space in a document. This tokenization process can be further customized. For example,\n\n```python\nfrom rouge_metric import PyRouge\n\n# Pre-process and tokenize the summaries as you like\nhypotheses = [\n    ['how are you'.split(), 'i am fine'.split()],                       # document 1: hypothesis\n    ['it is fine today'.split(), 'we won the football game'.split()],   # document 2: hypothesis\n]\nreferences = [[\n    ['how do you do'.split(), 'fine thanks'.split()],   # document 1: reference 1\n    ['how old are you'.split(), 'i am three'.split()],  # document 1: reference 2\n], [\n    ['it is sunny today'.split(), 'let us go for a walk'.split()],  # document 2: reference 1\n    ['it is a terrible day'.split(), 'we lost the game'.split()],   # document 2: reference 2\n]]\n\n# Evaluate on tokenized documents\nrouge = PyRouge(rouge_n=(1, 2, 4), rouge_l=True, rouge_w=True,\n                rouge_w_weight=1.2, rouge_s=True, rouge_su=True, skip_gap=4)\nscores = rouge.evaluate_tokenized(hypotheses, references)\nprint(scores)\n```\n\n## License\n\nThis project is under [MIT License](https://github.com/li-plus/rouge-metric/blob/master/LICENSE).\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/li-plus/rouge-metric",
    "keywords": "rouge,summarization,natural language processing,computational linguistics",
    "license": "MIT",
    "maintainer": "Jiahao Li",
    "maintainer_email": "liplus17@163.com",
    "name": "rouge-metric",
    "package_url": "https://pypi.org/project/rouge-metric/",
    "platform": "",
    "project_url": "https://pypi.org/project/rouge-metric/",
    "project_urls": {
      "Homepage": "https://github.com/li-plus/rouge-metric"
    },
    "release_url": "https://pypi.org/project/rouge-metric/1.0.1/",
    "requires_dist": [
      "typing ; python_version < \"3.5\"",
      "pytest ; extra == 'dev'",
      "pytest-cov ; extra == 'dev'",
      "flake8 ; extra == 'dev'"
    ],
    "requires_python": ">=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*",
    "summary": "A fast python implementation of full ROUGE metrics for automatic summarization.",
    "version": "1.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8462803,
  "releases": {
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ecaedeb04e1a1d83216f0123221248a2526de0903770b51244494fc2cfc4cf2b",
          "md5": "3cfc4e509892b59e4ac33691fb2d2a8e",
          "sha256": "2b59480fecb30f93b3acfd43bcd520b9b0dafaece81f1d69777f6b22ba4847e9"
        },
        "downloads": -1,
        "filename": "rouge_metric-1.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "3cfc4e509892b59e4ac33691fb2d2a8e",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*",
        "size": 147668,
        "upload_time": "2020-09-15T03:14:37",
        "upload_time_iso_8601": "2020-09-15T03:14:37.232503Z",
        "url": "https://files.pythonhosted.org/packages/ec/ae/deb04e1a1d83216f0123221248a2526de0903770b51244494fc2cfc4cf2b/rouge_metric-1.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "759418711aeed3890197af91d2af8fef66037cbf2230aadf78ceb703910787cb",
          "md5": "adb7168888cbbead34a513e660ad2472",
          "sha256": "26ebe5ca299193371b3c6e053f8313ecec38aeb83eaeb7048561b8cb953253f7"
        },
        "downloads": -1,
        "filename": "rouge-metric-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "adb7168888cbbead34a513e660ad2472",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*",
        "size": 129947,
        "upload_time": "2020-09-15T03:14:46",
        "upload_time_iso_8601": "2020-09-15T03:14:46.978847Z",
        "url": "https://files.pythonhosted.org/packages/75/94/18711aeed3890197af91d2af8fef66037cbf2230aadf78ceb703910787cb/rouge-metric-1.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bb3418ddbc94f65e8b45220b373b2ad2db6bef7549f4b00b4baaaaa47204be1a",
          "md5": "c6a157976b1e1b5a5ec70912c3823bf8",
          "sha256": "0818e48ec4aa66086ab18721f8ea313e57fe5065181268884b86935a3daac551"
        },
        "downloads": -1,
        "filename": "rouge_metric-1.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "c6a157976b1e1b5a5ec70912c3823bf8",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*",
        "size": 151695,
        "upload_time": "2020-10-21T03:15:54",
        "upload_time_iso_8601": "2020-10-21T03:15:54.657896Z",
        "url": "https://files.pythonhosted.org/packages/bb/34/18ddbc94f65e8b45220b373b2ad2db6bef7549f4b00b4baaaaa47204be1a/rouge_metric-1.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "42d1a87e9971e565f9c081f6772576b6e47b917096e9cd7d1f525f777f260e70",
          "md5": "5cb42aeb76df66190fcd893469f9c9af",
          "sha256": "a605e410c41f26e748bbccb632e14b619d52aa1037b41d2adde8a2cff9472df2"
        },
        "downloads": -1,
        "filename": "rouge-metric-1.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "5cb42aeb76df66190fcd893469f9c9af",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*",
        "size": 133605,
        "upload_time": "2020-10-21T03:16:05",
        "upload_time_iso_8601": "2020-10-21T03:16:05.038352Z",
        "url": "https://files.pythonhosted.org/packages/42/d1/a87e9971e565f9c081f6772576b6e47b917096e9cd7d1f525f777f260e70/rouge-metric-1.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "bb3418ddbc94f65e8b45220b373b2ad2db6bef7549f4b00b4baaaaa47204be1a",
        "md5": "c6a157976b1e1b5a5ec70912c3823bf8",
        "sha256": "0818e48ec4aa66086ab18721f8ea313e57fe5065181268884b86935a3daac551"
      },
      "downloads": -1,
      "filename": "rouge_metric-1.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "c6a157976b1e1b5a5ec70912c3823bf8",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*",
      "size": 151695,
      "upload_time": "2020-10-21T03:15:54",
      "upload_time_iso_8601": "2020-10-21T03:15:54.657896Z",
      "url": "https://files.pythonhosted.org/packages/bb/34/18ddbc94f65e8b45220b373b2ad2db6bef7549f4b00b4baaaaa47204be1a/rouge_metric-1.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "42d1a87e9971e565f9c081f6772576b6e47b917096e9cd7d1f525f777f260e70",
        "md5": "5cb42aeb76df66190fcd893469f9c9af",
        "sha256": "a605e410c41f26e748bbccb632e14b619d52aa1037b41d2adde8a2cff9472df2"
      },
      "downloads": -1,
      "filename": "rouge-metric-1.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "5cb42aeb76df66190fcd893469f9c9af",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*",
      "size": 133605,
      "upload_time": "2020-10-21T03:16:05",
      "upload_time_iso_8601": "2020-10-21T03:16:05.038352Z",
      "url": "https://files.pythonhosted.org/packages/42/d1/a87e9971e565f9c081f6772576b6e47b917096e9cd7d1f525f777f260e70/rouge-metric-1.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}