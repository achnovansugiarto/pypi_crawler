{
  "info": {
    "author": "LabeliaLabs",
    "author_email": "contact@labelia.org",
    "bugtrack_url": null,
    "classifiers": [
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "[![Build Status](https://github.com/LabeliaLabs/distributed-learning-contributivity/workflows/Build/badge.svg)](https://github.com/LabeliaLabs/distributed-learning-contributivity/actions?query=branch%3Amaster)\n[![Code Coverage](https://codecov.io/gh/LabeliaLabs/distributed-learning-contributivity/branch/master/graphs/badge.svg)](https://codecov.io/gh/LabeliaLabs/distributed-learning-contributivity)\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LabeliaLabs/distributed-learning-contributivity/blob/master/run_experiment_on_google_collab.ipynb)\n[![Discuss on Slack](https://img.shields.io/badge/chat-on%20slack-orange)](https://labelia.slack.com/messages/workgroup-mpl-contributivity)\n\n# MPLC: Multi-Partner Learning and Contributivity\n\nIn short, MPLC enables to:\n\n- simulate collaborative multi-partner ML scenarios\n- experiment and benchmark multi-partner learning approaches\n- experiment and benchmark contributivity measurement approaches\n\n## Table of content\n\n- [Introduction](#introduction)\n  - [Context of this work](#context-of-this-work)\n  - [How to interact with this project?](#how-to-interact-with-this-project)\n- [About this repository](#about-this-repository)\n  - [Structure of the library](#structure-of-the-library)\n    - [Scenarios](#scenarios)\n    - [Multi-partner learning approaches](#multi-partner-learning-approaches)\n    - [Contributivity measurement approaches](#contributivity-measurement-approaches)\n  - [Installation](#installation)\n  - [Run an experiment](#run-an-experiment)\n  - [Reference scenarios](#reference-scenarios)\n  - [Ongoing work and improvement plan](#ongoing-work-and-improvement-plan)\n- [Contacts, contributions, collaborations](#contacts,-contributions,-collaborations)\n\n___\n\n## Introduction\n\nThis work focuses on collaborative data science projects where multiple partners want to train a model on multiple datasets, contributed by different data providing partners. Such scenarios are sometimes referenced as *cross-silos federated learning* (see for example the reference paper [Advances and Open Problems in Federated Learning](https://arxiv.org/abs/1912.04977)).\n\nIn the context of cross-silos federated learning scenarios, it addresses the following questions:\n\n- how to train and test a predictive model, what *federated learning strategies* could be considered? *Federated averaging* seems to have become the default approach, but other could be explored.\n- how to measure how much each dataset contributed to the performance of the collective model? This question can be of interest in some cases, for example as a basis to agree on how to share the reward of the ML challenge or the future revenues derived from the predictive model, or to detect possible corrupted datasets or partners not playing by the rules.\n\nThis library aims to help researchers and practitioners to explore these questions.\n\n### Context of this work\n\nThis work is being carried out in the context of collaborative research projects, open science and open source software. It is work in progress.\n\n### How to interact with this project?\n\nIt depends in what capacity you are interested! For example:\n\n- If you'd like to experiment right now by yourself multi-partner learning approaches and contributivity measurement methods, jump to section **[Run an experiment](#run-an-experiment)**.\n- If you'd like to get in touch with active members of the workgroup, jump to section **[Contacts, contributions, collaborations](#contacts-contributions-collaborations)**. If you are a student or a teacher, we are used to discuss student projects related to the `mplc` library.\n- If you are already familiar with this type of projects, you can either have a look at section **[Ongoing work and improvement plan](#ongoing-work-and-improvement-plan)** or head towards [issues](https://github.com/LabeliaLabs/distributed-learning-contributivity/issues) and [PRs](https://github.com/LabeliaLabs/distributed-learning-contributivity/pulls) to see what's going on these days. We use the `help wanted` tag to flag issues on which help is particularly wanted, but other open issues would also very much welcome contributions. There is also a [`CONTRIBUTING.md`](./CONTRIBUTING.md) with indications and best practices we recommend.\n\nShould you have any question, don't hesitate [reach out](#contacts-contributions-collaborations), we'll be happy to discuss how we could help.\n\n## About this repository\n\nIn this repository, we benchmark different distributed learning and contributivity measurement approaches on public datasets artificially partitioned in a number of individual datasets, to mock a collaborative ML project (*a cross-silos federated learning project*).\n\nThe public datasets currently supported are: MNIST, CIFAR10, TITANIC, ESC50 and IMDB. They also act as templates for using the library on custom datasets.\n\nThe documentation is [here](mplc/doc/documentation.md)\n\n### Structure of the library\n\nThis library can be schematically broken down into 3 blocks:\n\n1. [Scenarios](#scenarios)\n1. [Multi-partner learning approaches](#multi-partner-learning-approaches)\n1. [Contributivity measurement approaches](#contributivity-measurement-approaches)\n\n#### Scenarios\n\nA key capability is to easily define and simulate different multi-partner settings to be able to experiment on them. For that, the library enables to configure scenarios by specifying the number of partners, how the dataset is partitioned among them, etc. See the [first tutorial](https://github.com/LabeliaLabs/distributed-learning-contributivity/blob/master/notebooks/tutorials/Tutorial-1_Run_your_first_scenario.ipynb), and the related documentation's section [Definition of collaborative scenarios](mplc/doc/documentation.md#definition-of-collaborative-scenarios) for all available parameters.\n\n#### Multi-partner learning approaches\n\nOnce a given scenario is configured, it is then possible to configure the multi-partner learning approach. So far, 3 different approaches are implemented (federated averaging, sequential, sequential averaging). See the related documentation section [Configuration of the collaborative and distributed learning](mplc/doc/documentation.md#configuration-of-the-collaborative-and-distributed-learning) for descriptive schemas and additional ML-related parameters.\n\n#### Contributivity measurement approaches\n\nFinally, with a given scenario and selected multi-partner learning approaches, it becomes possible to address contributivity measurement approaches. See the related documentation's sections [Configuration of contributivity measurement methods to be tested](mplc/doc/documentation.md#scenario-parameters) and [Contributivity measurement approaches studied and implemented](mplc/doc/documentation.md#configuration-of-contributivity-measurement-methods-to-be-tested).\n\n### Installation\n\n#### Using pip\n\n```sh\npip install mplc\n```\n\nThis installs the last packaged version available on PyPI.\n\n#### Build from Source\n\nIf you want to install mplc from the repository, make sure that you got the latest version of `pip`.\n\nThen clone the repository, and trigger the installation from local sources.\n\n```sh\ngit clone https://github.com/LabeliaLabs/distributed-learning-contributivity.git\ncd distributed-learning-contributivity\npip install -e . \n```\n\n### Run an experiment\n\nThere are two ways to run an experiment of multi-partner learning approaches and/or contributivity methods.\n\n#### (Recommended) Defining an Experiment in the code\n\nYou can first use the mplc library in a notebook, or regular python script, as it is demonstrated in the [tutorials](./notebooks/tutorials) and in the below code snippet.\n\n```python\nimport mplc\n\nfrom mplc.experiment import Experiment\nfrom mplc.scenario import Scenario\n\n# Let's configure different multi-partner scenarios\nscenario1 = Scenario(partners_count=3,\n                     amounts_per_partner=[0.2, 0.3, 0.5],\n                     dataset_name='cifar10',\n                     epoch_count=10,\n                     minibatch_count=3,\n                     contributivity_methods=[\"Shapley values\", \"S-Model\"]\n                     )\nscenario2 = Scenario(4, [0.25]*4)  # Here attributes (e.g. dataset, epochs...) will be default values \nscenario3 = Scenario(4, [0.8, 0.1, 0.05, 0.05])\n\n# Now let's instantiate an Experiment and add the above scenarios\nmy_exp = Experiment(experiment_name='my_first_experiment',\n                    nb_repeats=10,\n                    scenarios_list=[scenario1, scenario3],\n                    )\nmy_exp.add_scenario(scenario2)\n\n# Everything is now set to run the Experiment\nmy_exp.run()\n```\n\n#### (Alternative) Defining an Experiment with a config file\n\nAlternatively, you can also use the `main.py` provided in the repository together with a `.yml` config file.\n\n1. Define your scenario(s) in the `config.yml` file by changing the values of the suggested parameters of the example scenario (you can browse more available parameters in [the documentation](mplc/doc/documentation.md)). For example:\n\n```yaml\nexperiment_name: my_custom_experiment\nn_repeats: 5\nscenario_params_list:\n  - dataset:\n    'mnist':\n    - 'random_initialization'\n    'cifar10':\n    - 'random_initialization'\n    dataset_proportion:\n      - 0.5\n    partners_count: \n      - 3\n    amounts_per_partner:\n      - [0.4, 0.3, 0.3]\n    samples_split_option:\n      - 'random'\n      - ['advanced', [[7, 'shared'], [6, 'shared'], [2, 'specific']]]\n    multi_partner_learning_approach:\n      - 'fedavg'\n    aggregation:\n      - 'data-volume'\n      - 'uniform'\n    contributivity_methods:\n      - [\"Shapley values\", \"Independent scores\", \"TMCS\"]\n    epoch_count:\n      - 20\n    minibatch_count:\n      - 20\n    gradient_updates_per_pass_count:\n      - 8\n```\n\nUnder `scenario_params_list`, enter a list of sets of scenario(s). Each set starts with `- dataset:` and must have only one `partners_count` value. The length of `amount_per_partners`, `corrupted_datasets` (and `samples_split_option` when the advanced definition is used) must match the `partner_counts` value. If for a given parameter multiple values are specified, e.g. like for `aggregation` in the example scenario above, all possible combinations of parameters will be assembled as separate scenarios and run.\n\n2. Then execute `main.py -f config.yml`. Add the `-v` argument if you want a more verbose output.\n\n3. A `results.csv` file will be generated in a new folder for your experiment under `/experiments/<your_experiment>`. You can read this raw `results.csv` file or use the notebooks in `/notebooks`.  \n\n**Note**: example experiment(s) are stored in folder `/saved_experiments` to illustrate the use of the library. The notebooks include graphs, like for example the following:\n\n![Example graphs](./img/results_graphs_example.png)\n\n### Reference scenarios\n\n#### Description of the reference scenarios\n\nWe defined 5 reference scenarios on which we propose to test and benchmark the different multi-partner learning approaches and contributivity measurement methods.\n\nThe 5 reference scenarios are described on the following schema ([link](https://docs.google.com/drawings/d/1_ovwpBTx_Rno5FO1AcODM7cJ6a_EPaBOh9OYl952J-4/edit?usp=sharing) to editable version):\n\n![Reference scenarios](./img/reference_scenarios.png)\n\nIn brief:\n\n- Scenarios 1 and 2 with 2 partners only enable simple baselines, with different data splits (each partner having samples of different classes in the first scenario, of all classes both in the second one), and introducing corrupted data;\n\n- Scenario 3 proposes a more realistic configuration, with partners having both samples of common classes and samples of different classes each;\n\n- Scenario 4 offers a case with 5 partners, and an identical distribution of data samples of all classes, but with 1 partner having its data entirely corrupted;\n\n- Scenario 5 is more complex, with 11 partners and a mix of identical distribution of data samples of several classes for a majority of partners, data samples of different classes for certain other partners, and corrupted data also.\n\n#### Results and benchmarks\n\nResults of experiments and benchmarks of multi-partner learning approaches and contributivity methods on the reference scenarios will be summarised in this section in the upcoming months. Associated notebooks and full results will be shared on [Open Science Framework](https://osf.io/89qbt/). \n\n### Ongoing work and improvement plan\n\nThe current work focuses on the following 4 priorities:\n\n1. Design and implement new **[multi-partner learning approaches](https://github.com/LabeliaLabs/distributed-learning-contributivity/projects/4)**\n1. Design and implement new **[contributivity measurement methods](https://github.com/LabeliaLabs/distributed-learning-contributivity/projects/3)**\n1. Perform **[experiments](https://github.com/LabeliaLabs/distributed-learning-contributivity/projects/1)** and gain experience about best-suited multi-partner learning approaches and contributivity measurement methods in different situations\n1. Make the library **[agnostic/compatible with other datasets and model architectures](https://github.com/LabeliaLabs/distributed-learning-contributivity/projects/2)**\n\nThere is also a transverse, continuous improvement effort on **[code quality, readability, optimization](https://github.com/LabeliaLabs/distributed-learning-contributivity/projects/5)**.\n\nThis work is collaborative, enthusiasts are welcome to comment open issues and PRs or open new ones.\n\n## Contacts, contributions, collaborations\n\nShould you be interested in this open effort and would like to share any question, suggestion or input, you can use the following channels:\n\n- This Github repository (issues or PRs)\n- Labelia Labs' (ex- Substra Foundation) [Slack workspace](https://join.slack.com/t/labelia/shared_invite/zt-cpyedcab-FHYgpy08efKJ2FCadE2yCA), channel `#workgroup-mpl-contributivity`\n- Email: <contact@labelia.org>\n\n ![logo Labelia Labs](./img/labelia_substra_logo_rvb_w350px.png)\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/LabeliaLabs/distributed-learning-contributivity.git",
    "keywords": "library,substra,labelia,machine learning,contributivity,multi-partner learning,distributed learning",
    "license": "Apache 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "mplc",
    "package_url": "https://pypi.org/project/mplc/",
    "platform": "",
    "project_url": "https://pypi.org/project/mplc/",
    "project_urls": {
      "Homepage": "https://github.com/LabeliaLabs/distributed-learning-contributivity.git"
    },
    "release_url": "https://pypi.org/project/mplc/0.4.2/",
    "requires_dist": [
      "h5py (~=3.1.0)",
      "joblib (==1.0.0)",
      "librosa (==0.8.1)",
      "matplotlib (==3.3.3)",
      "numpy (==1.19.5)",
      "scipy (==1.5.4)",
      "scikit-learn (==0.23.2)",
      "pandas (==1.1.5)",
      "seaborn (==0.11.0)",
      "loguru (==0.5.3)",
      "tensorflow (==2.5.1)",
      "ruamel.yaml (==0.16.12)"
    ],
    "requires_python": ">=3.6",
    "summary": "A distributed-learning package for the study of multi-partner learning approaches and contributivity measurement methods",
    "version": "0.4.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12101232,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "23e5e44fca3388404c66a441a49df44059722043cdae195f51c86dead12636c8",
          "md5": "5dd3cbce82e9e04957a694d949a505aa",
          "sha256": "6ac7aa62b06d4d3ba59410684101f33ff1cff62c6cf943ab906d622612e3a208"
        },
        "downloads": -1,
        "filename": "mplc-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "5dd3cbce82e9e04957a694d949a505aa",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 81452,
        "upload_time": "2020-09-28T13:48:13",
        "upload_time_iso_8601": "2020-09-28T13:48:13.008918Z",
        "url": "https://files.pythonhosted.org/packages/23/e5/e44fca3388404c66a441a49df44059722043cdae195f51c86dead12636c8/mplc-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "eba5be7ebb028f969d3de3a325ebcaf007fa19a20b4420ce2b38574e4a34daaa",
          "md5": "e740ed4abe6788f7d52308f381ffecbe",
          "sha256": "7d9a39a635b72e718818a8d68e0965d9fadc5e315a22d13ee4a26dc0b5166ae1"
        },
        "downloads": -1,
        "filename": "mplc-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "e740ed4abe6788f7d52308f381ffecbe",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 40526,
        "upload_time": "2020-09-28T13:48:16",
        "upload_time_iso_8601": "2020-09-28T13:48:16.890779Z",
        "url": "https://files.pythonhosted.org/packages/eb/a5/be7ebb028f969d3de3a325ebcaf007fa19a20b4420ce2b38574e4a34daaa/mplc-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d3ea63126b4b2e78b81d7d630e09f4922c99052d2687ff0a4c54b433113f20a3",
          "md5": "232351a65587f211e15d98ca5413714d",
          "sha256": "f69a4d9b968451f464ee5452889553a1db571b6e469d5e480cc2ed1a214f9c08"
        },
        "downloads": -1,
        "filename": "mplc-0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "232351a65587f211e15d98ca5413714d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 85966,
        "upload_time": "2020-11-03T13:25:14",
        "upload_time_iso_8601": "2020-11-03T13:25:14.550864Z",
        "url": "https://files.pythonhosted.org/packages/d3/ea/63126b4b2e78b81d7d630e09f4922c99052d2687ff0a4c54b433113f20a3/mplc-0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "767156ebc4fb67b8dc4f4e260debce5ec99b5a325fc97bc9c47036893b11f3a9",
          "md5": "6774a3e40038c10b922de53f388bfff3",
          "sha256": "eed17054555be758a3e7ab5273509731ceafa865ab19e13b39f12075a3cce0fa"
        },
        "downloads": -1,
        "filename": "mplc-0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "6774a3e40038c10b922de53f388bfff3",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 44278,
        "upload_time": "2020-11-03T13:25:19",
        "upload_time_iso_8601": "2020-11-03T13:25:19.290779Z",
        "url": "https://files.pythonhosted.org/packages/76/71/56ebc4fb67b8dc4f4e260debce5ec99b5a325fc97bc9c47036893b11f3a9/mplc-0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d23c8fc1fecf0a3e542c2c7746b90ed817ba30c6dfe80844492f94a16d9680b2",
          "md5": "7a1eb2708a11dcbf3e6ea2d858a9fdbc",
          "sha256": "233176a5d18f70666f33987aacb73ef0897c3fda9514a7d25145c70ffaaf0ec4"
        },
        "downloads": -1,
        "filename": "mplc-0.3.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "7a1eb2708a11dcbf3e6ea2d858a9fdbc",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 58338,
        "upload_time": "2021-01-07T11:25:32",
        "upload_time_iso_8601": "2021-01-07T11:25:32.483759Z",
        "url": "https://files.pythonhosted.org/packages/d2/3c/8fc1fecf0a3e542c2c7746b90ed817ba30c6dfe80844492f94a16d9680b2/mplc-0.3.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5ab758f51d451a2410fcd314e4cea38b1673c29cb2a24062eaffc5e8de4d6f33",
          "md5": "4a68422a78b2c6513ae4df1ad3750883",
          "sha256": "17735ff1f3db486e14600b5d1e9730bed905f5f04a286e3be5c7bd19cebfcc8c"
        },
        "downloads": -1,
        "filename": "mplc-0.3.0.tar.gz",
        "has_sig": false,
        "md5_digest": "4a68422a78b2c6513ae4df1ad3750883",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 52182,
        "upload_time": "2021-01-07T11:25:33",
        "upload_time_iso_8601": "2021-01-07T11:25:33.927939Z",
        "url": "https://files.pythonhosted.org/packages/5a/b7/58f51d451a2410fcd314e4cea38b1673c29cb2a24062eaffc5e8de4d6f33/mplc-0.3.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "201589de8f87e822c6073801a284ade47a8126c3b83f8bdaf642ac11234f5b6a",
          "md5": "82641c4734e5a51770f6e8d4e2fb2288",
          "sha256": "c4142cf794cc5832c357c8a8ee88c82a458b4e37dc762c27edafd5ab2b99ea02"
        },
        "downloads": -1,
        "filename": "mplc-0.3.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "82641c4734e5a51770f6e8d4e2fb2288",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 57977,
        "upload_time": "2021-01-08T12:40:52",
        "upload_time_iso_8601": "2021-01-08T12:40:52.052714Z",
        "url": "https://files.pythonhosted.org/packages/20/15/89de8f87e822c6073801a284ade47a8126c3b83f8bdaf642ac11234f5b6a/mplc-0.3.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "65c3ddd8ef8858e0b9c38123f81d5be6dbb025520e9b7e473b89cc36086b0eff",
          "md5": "3e3b9ebf01911d69201b1d12ddf86752",
          "sha256": "f8f8db493f440119e1bdcbafa8c4d61749d5f59aff365328948e82ddd19b0d71"
        },
        "downloads": -1,
        "filename": "mplc-0.3.1.tar.gz",
        "has_sig": false,
        "md5_digest": "3e3b9ebf01911d69201b1d12ddf86752",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 51791,
        "upload_time": "2021-01-08T12:40:53",
        "upload_time_iso_8601": "2021-01-08T12:40:53.678869Z",
        "url": "https://files.pythonhosted.org/packages/65/c3/ddd8ef8858e0b9c38123f81d5be6dbb025520e9b7e473b89cc36086b0eff/mplc-0.3.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0a5865f2282148f6d020c71571a73ab3f98972c6ea7ad054bef4200bb0375bee",
          "md5": "f1d7fbe522b9c3a44e66fa8dfd2b5ac2",
          "sha256": "1796312d3dc0c690946747d6f535a902c61de02b7b21d6c42aeb7e98021c8c84"
        },
        "downloads": -1,
        "filename": "mplc-0.4.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f1d7fbe522b9c3a44e66fa8dfd2b5ac2",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 73241,
        "upload_time": "2021-11-23T11:27:09",
        "upload_time_iso_8601": "2021-11-23T11:27:09.607265Z",
        "url": "https://files.pythonhosted.org/packages/0a/58/65f2282148f6d020c71571a73ab3f98972c6ea7ad054bef4200bb0375bee/mplc-0.4.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ae7da45e5f729cd49004e74b7eeb0b8f890949ddca0b170814a73c1341a78085",
          "md5": "d40a165e276f2a7ae5e97717dc22641f",
          "sha256": "11fcdb504b2c0a05fb6757650b189ba5da04a797d009acc02bb21eb92065ced0"
        },
        "downloads": -1,
        "filename": "mplc-0.4.2.tar.gz",
        "has_sig": false,
        "md5_digest": "d40a165e276f2a7ae5e97717dc22641f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 69594,
        "upload_time": "2021-11-23T11:27:11",
        "upload_time_iso_8601": "2021-11-23T11:27:11.068913Z",
        "url": "https://files.pythonhosted.org/packages/ae/7d/a45e5f729cd49004e74b7eeb0b8f890949ddca0b170814a73c1341a78085/mplc-0.4.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "0a5865f2282148f6d020c71571a73ab3f98972c6ea7ad054bef4200bb0375bee",
        "md5": "f1d7fbe522b9c3a44e66fa8dfd2b5ac2",
        "sha256": "1796312d3dc0c690946747d6f535a902c61de02b7b21d6c42aeb7e98021c8c84"
      },
      "downloads": -1,
      "filename": "mplc-0.4.2-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "f1d7fbe522b9c3a44e66fa8dfd2b5ac2",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 73241,
      "upload_time": "2021-11-23T11:27:09",
      "upload_time_iso_8601": "2021-11-23T11:27:09.607265Z",
      "url": "https://files.pythonhosted.org/packages/0a/58/65f2282148f6d020c71571a73ab3f98972c6ea7ad054bef4200bb0375bee/mplc-0.4.2-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "ae7da45e5f729cd49004e74b7eeb0b8f890949ddca0b170814a73c1341a78085",
        "md5": "d40a165e276f2a7ae5e97717dc22641f",
        "sha256": "11fcdb504b2c0a05fb6757650b189ba5da04a797d009acc02bb21eb92065ced0"
      },
      "downloads": -1,
      "filename": "mplc-0.4.2.tar.gz",
      "has_sig": false,
      "md5_digest": "d40a165e276f2a7ae5e97717dc22641f",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 69594,
      "upload_time": "2021-11-23T11:27:11",
      "upload_time_iso_8601": "2021-11-23T11:27:11.068913Z",
      "url": "https://files.pythonhosted.org/packages/ae/7d/a45e5f729cd49004e74b7eeb0b8f890949ddca0b170814a73c1341a78085/mplc-0.4.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}