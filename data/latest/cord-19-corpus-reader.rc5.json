{
  "info": {
    "author": "Alex Morehead",
    "author_email": "alex.morehead@gmail.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "\n# Table of Contents\n\n1.  [CORD-19 Corpus Reader](#cord-19-corpus-reader)\n    1.  [About](#about)\n    2.  [Dataset Format](#dataset-format)\n    3.  [Examples](#examples)\n        1.  [Creating a Corpus Reader](#creating-a-corpus-reader)\n        2.  [Creating a Corpus Reader to Read Only Bodies of Papers](#creating-a-corpus-reader-to-read-only-bodies-of-papers)\n        3.  [Creating a Corpus Reader Preferring PMC Parses of Papers](#creating-a-corpus-reader-preferring-pmc-parses-of-papers)\n        4.  [Getting a List of Documents in the Corpus](#getting-a-list-of-documents-in-the-corpus)\n        5.  [Getting All the Words in the Corpus](#getting-all-the-words-in-the-corpus)\n        6.  [Getting All the Words From Specific Documents in the Corpus](#getting-all-the-words-from-specific-documents-in-the-corpus)\n        7.  [Getting Metadata for Specific Documents in the Corpus](#getting-metadata-for-specific-documents-in-the-corpus)\n        8.  [Display Statistics About the Corpus](#display-statistics-about-the-corpus)\n        9.  [Plotting 50 Most Common Words from 10000 Documents](#plotting-50-most-common-words-from-10000-documents)\n        10. [Plotting 50 Most Popular Days to Publish](#plotting-50-most-popular-days-to-publish)\n    4.  [Tasks](#tasks)\n        1.  [To Do](#to-do)\n        2.  [In Progress](#in-progress)\n        3.  [Done](#done)\n    5.  [Questions](#questions)\n    6.  [Issues](#issues)\n\n\n<a id=\"cord-19-corpus-reader\"></a>\n\n# CORD-19 Corpus Reader\n\n\n<a id=\"about\"></a>\n\n## About\n\nThe `CORD19CorpusReader` class is a corpus reader for the CORD-19 corpus\n(<https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge>).\nThe idea is to be able to load the CORD-19 corpus into NLTK. This project\nwas originally created for Natural Language Processing (NLP) coursework\nat the University of Missouri by Jason James, Alex Morehead, and others.\n\nDocuments in the CORD-19 corpus are stored as JSON files. Since the\ndocuments are in JSON, the parts of the paper are separated out.\nCurrently, when setting up the corpus reader, you can specify which\nparts of the papers you want to access: titles, abstracts, and / or\nbodies with the flags `include_titles`, `include_abstracts`, and\n`include_bodies`. For example, in some situations, you might really only\ncare about the body of the paper, which contains most of the text. In\nother situations, you might just want the abstracts. By default, titles,\nabstracts, and bodies are included.\n\nFor some papers, there are both PDF parses and PMC parses. To indicate\nwhich is preferred, the corpus reader has a `prefer_pdf_parses`\nparameter and a `prefer_pmc_parses` parameter. In cases where both\nparses are available, the `prefer_pdf_parses` tells the reader to choose\nthe PDF parses when set to `True` and the `prefer_pmc_parses` parameter\ntells the corpus reader to choose the PMC parse when set to `True`. If\nboth are set to `True`, it just uses all the JSON files, which is\nactually a bit faster since it does not have to perform deduplication.\nIf both are set to `False` (which is not something you would probably\nwant to do in actuality), it would basically exclude either parse of a\npaper when there&rsquo;s a duplicate. By default, `prefer_pdf_parses` is set\nto `True` and `prefer_pmc_parses` is set to `False`.\n\nCurrently, `raw()`, `words()`, `sents()`, and `paras()` have\nimplementations and basically work like would be expected using NLTK.\nRight now, these functions are just returning the text body of the\npapers, but the intent is to be able to specify in the reader which\nparts of the paper to return (title, abstract, body, and bibliography).\nIn fair warning, it should also be noted that currently `paras()` is\ntreating a section of the paper as a paragraph, which may or may not be\nan acceptable treatment of paragraphs, so if we really need to work at\nthe paragraph level, we may want to revisit the implementation details\nof `paras()`.\n\nThere&rsquo;s a few options for inputs into `raw()`, `words()`, `sents()`, and\n`paras()`: a file ID as a string does the operation on just the\ncorresponding document, a list of file IDs does the operation on just\nthe corresponding documents, and no arguments performs the operation on\nall the documents in the corpus.\n\nThe corpus is very large, so operations can take a while to complete\nwhen performed on the entire corpus. For example, it took about 30\nminutes to store the output from `words()` to a list and print the\nlength of the list. To convert the list to a set and print the length of\nthe set took about another 10 minutes.\n\nMetadata for papers is stored in a file called `metadata.csv` in the\nroot directory of the corpus. Basically, each row of the file is the\nmetadata for a particular paper. So far, there&rsquo;s an initial\nimplementation of `metadata()` that can be used to retrieve the metadata\nfor papers. Similar to the above methods, either a string of a file ID\nor a list of file IDs can be input to `metadata()` to retrieve the\ncorresponding metadata for those documents. Additionally, passing in no\narguments returns the metadata for all the documents in the corpus.\nThere&rsquo;s also a parameter `fileids_only` that specifies whether to return\nmetadata for only papers actually in the corpus when set to `True` or\nall the metadata available (even for papers whose parses aren&rsquo;t in the\ncorpus) when set to `False`. The default value for `fileids_only` is\n`True`. When `fileids_only` is `True`, the metadata is returned as a\ndictionary, with the fileids as keys, of lists, where an entry in the\nlist is itself a dictionary representing a row from `metadata.csv`.\nHowever, when `fileids_only` is set to `False`, the metadata returned is\na dictionary, with the cord<sub>uid</sub> as the keys, of lists, where each entry\nin the list is itself a dictionary representing a row from\n`metadata.csv`. The reason for the discrepency is that there might be a\nwant to correlate metadata with its corresponding paper, in which case\nindexing into the metadata with the paper&rsquo;s fileid seems intuitive. On\nthe other hand, for metadata for papers for which there is no\ncorresponding fileid, there&rsquo;s not really a lot of options for what to\nindex into it with, so teh cord<sub>uid</sub> is used.\n\n`test_coord19.py` contains some rudimentary tests using methods in the\n`CORD19CorpusReader` class to display the output of the methods.\n\n\n<a id=\"dataset-format\"></a>\n\n## Dataset Format\n\nThe dataset is updated pretty regularly on Kaggle. So, the exact number\nof papers can change on a daily basis.\n\nInside the root directory of the dataset is a metadata file called\n`metadata.csv`. Each row represents a particular paper and has a\n`cord_uid` that serves as a sort of key for that paper. Note that the\n`cord_uid=s are not unique in =metadata.csv`: multiple rows might have\nthe same `cord_uid`, but contain differening data (it usually looks like\none of the entries is more complete than the other). If a paper has a\nPMC parse, there will be an entry for the filename in the\n`pmc_json_files` column. Similarly, if the paper has a PDF parse, there\nwill be an entry for its filename in the `pdf_json_files` column.\nHowever, sometimes multiple files might be listed in the\n`pdf_json_files` column: apparently, one corresponds to the main article\nand the others contain related matter and so these types of entries are\nrepresented as a `;` separated list (semicolon and space).\n\nInside the directory for the dataset, there is a directory called\n`document_parses`. Inside of `document_parses`, there are two folders\ncalled `pdf_json` and `pmc_json`. The files in these folders are the\nactual data from the papers in JSON format. Some papers only have a PDF\nparse and some papers only have a PMC parse and some papers have both a\nPDF and a PMC parse and some papers have neither a PDF parse nor a PMC\nparse.\n\n\n<a id=\"examples\"></a>\n\n## Examples\n\n\n<a id=\"creating-a-corpus-reader\"></a>\n\n### Creating a Corpus Reader\n\n    # Import the CORD19CorpusReader class.\n    from cord19 import CORD19CorpusReader\n    \n    # Directory of the CORD-19 corpus.\n    # Assumes the repository directory is sibling to / at the same level as the corpus directory.\n    # Also assumes in the same directory as cord19.py.\n    root = '../../../../551982-1490480-bundle-archive/'\n    \n    # Make a corpus reader on everything that is a .json file in the directory.\n    reader = CORD19CorpusReader(root, '.*\\.json')\n\n\n<a id=\"creating-a-corpus-reader-to-read-only-bodies-of-papers\"></a>\n\n### Creating a Corpus Reader to Read Only Bodies of Papers\n\n    # Assume CORD19CorpusReader has been imported and root has been specified.\n    \n    # By default include_titles, include_abstracts, and include_bodies are all True.\n    reader = CORD19CorpusReader(root, '.*\\.json', include_titles = False, include_abstracts = False, include_bodies = True)\n\n\n<a id=\"creating-a-corpus-reader-preferring-pmc-parses-of-papers\"></a>\n\n### Creating a Corpus Reader Preferring PMC Parses of Papers\n\n    # Assume CORD19CorpusReader has been imported and root has been specified.\n    \n    # When there's both a PDF parse and a PMC parse available for a paper, choose the PMC parse.\n    reader = CORD19CorpusReader(root, '.*\\.json', prefer_pmc_parses = True, prefer_pdf_parses = False)\n\n\n<a id=\"getting-a-list-of-documents-in-the-corpus\"></a>\n\n### Getting a List of Documents in the Corpus\n\n    document_list = reader.fileids()\n\n\n<a id=\"getting-all-the-words-in-the-corpus\"></a>\n\n### Getting All the Words in the Corpus\n\n    # Note that this could take a while since the corpus is quite large.\n    word_list = reader.words()\n\n\n<a id=\"getting-all-the-words-from-specific-documents-in-the-corpus\"></a>\n\n### Getting All the Words From Specific Documents in the Corpus\n\n    # Make a list of documents of interest.\n    document_list = ['document_parses/pdf_json/0000028b5cc154f68b8a269f6578f21e31f62977.json',\n    'document_parses/pmc_json/PMC7480786.xml.json']\n    \n    # Retrieves words from only the specified documents.\n    word_list = reader.words(document_list)\n\n\n<a id=\"getting-metadata-for-specific-documents-in-the-corpus\"></a>\n\n### Getting Metadata for Specific Documents in the Corpus\n\n    # Make a list of documents of interest.\n    document_list = ['document_parses/pdf_json/0000028b5cc154f68b8a269f6578f21e31f62977.json',\n    'document_parses/pmc_json/PMC7480786.xml.json']\n    \n    # Retrieves metadata from metadata.csv for only the specified documents.\n    metadata_dictionary = reader.metadata(document_list)\n\n\n<a id=\"display-statistics-about-the-corpus\"></a>\n\n### Display Statistics About the Corpus\n\n    # Displays information about rows in metadata.csv and counts of document parse folders.\n    reader.statistics()\n\n\n<a id=\"plotting-50-most-common-words-from-10000-documents\"></a>\n\n### Plotting 50 Most Common Words from 10000 Documents\n\n    # Grab a list of stopwords.\n    stopword_list = nltk.corpus.stopwords.words('english')\n    \n    # Make a list of punctuation and uninteresting items that might show up in a paper.\n    ignore_list = ['.', ',', '!', '?', '[', ']', '(', ')', '`', '\"', '\\'', ';', ':', '%', '-', '+', '=', '_', '),', ').', '],', '/', '\\\\', '.,', 'et', 'al']\n    \n    # Concatenate the lists.\n    ignore_list = ignore_list + stopword_list\n    \n    # Grab 10k documents.\n    document_list = reader.fileids()[0:10000]\n    \n    # Make a word list of words in the documents, but not in the ignore list.\n    word_list = [word.lower() for word in reader.words(document_list) if word.lower() not in ignore_list]\n    \n    # Create a frequency distribution of th words.\n    frequency_distribution = nltk.FreqDist(word_list)\n    \n    # Plot the distribution of the 50 most common words.\n    frequency_distribution.plot(50)\n\n![img](images/freqdist_top50words.png \"Frequency Distribution of Most Common 50 Dates\")\n\n\n<a id=\"plotting-50-most-popular-days-to-publish\"></a>\n\n### Plotting 50 Most Popular Days to Publish\n\n    # Grab the metadata.\n    metadata = reader.metadata()\n    \n    # Make an empty list of publish times.\n    publish_times = []\n    \n    # Go through each item in the metadata.\n    for (key, entry_list) in metadata.items():\n    \n        # Go through each entry in the list.\n        for entry in entry_list:\n    \n            # Add the publish time to the list.\n            publish_times.append(entry['publish_time'])\n    \n    # Make a frequency distribution on the list of publish times.\n    frequency_distribution = nltk.FreqDist(publish_times)\n    \n    # Plot the 50 most popular days to publish on.\n    frequency_distribution.plot(50)\n\n![img](images/freqdist_top50days.png \"Frequency Distribution of Most Common 50 Dates\")\n\n\n<a id=\"tasks\"></a>\n\n## Tasks\n\n\n<a id=\"to-do\"></a>\n\n### To Do\n\n-   Add functions to retrieve specific pieces of metadata\n    -   Implement `journals()` to pull journals metadata\n    -   Implement `authors()` to pull authors metadata\n    -   Implement `publish_times()` to pull publish times metadata\n    -   Implement `countries()` to pull countries (from authors metadata)\n        metadata\n    -   Implement `institutions()` to pull pull institutions (from authors\n        metadata) metadata\n\n-   Add ability to specify which parts of paper to read (title, abstract,\n    body, bibliography)\n    -   Add `include_bibliographies` flag to indicate whether to include\n        bibiliographies at the end of papers\n        -   Is this needed and what parts of the bibliographies to include?\n\n\n<a id=\"in-progress\"></a>\n\n### In Progress\n\n\n<a id=\"done\"></a>\n\n### Done\n\n-   Do initial implementation of `CORD19CorpusReader` class :jason:\n    -   Implement `raw()` :jason:\n    -   Implement `words()` :jason:\n    -   Implement `sents()` :jason:\n    -   Implement `paras()` :jason:\n\n-   Add ability to specify which parts of paper to read (title, abstract,\n    and body) :jason:\n    -   Add `include_titles` flag to indicate whether to include paper\n        titles :jason:\n    -   Add `include_abstracts` flag to indicate whether to include paper\n        abstracts :jason:\n    -   Add `include_bodies` flag to indicate whether to include the actual\n        text bodies of papers :jason:\n\n-   Implement `metadata()` to pull entire metadata blocks from\n    `metadata.csv` :jason:\n-   Implement `statistics()` to display some simple statistics about the\n    corpus :jason:\n-   Add preferences for deduplication of papers (i.e., don&rsquo;t include both\n    PDF parse and PMC parse of the same paper) :jason:\n\n\n<a id=\"questions\"></a>\n\n## Questions\n\n-   Why do some papers have both PDF and PMC parses?\n-   Are PDF and PMC parses of the same paper the same?\n-   If a JSON file has an abstract, authors, etc., is that metadata also\n    in metadata.csv and vice versa?\n-   Is the overlapping metadata (e.g., abstracts) in the JSON files and\n    metadata.csv the same?\n\n<div class=\"rmk\" id=\"org2beec82\">\n<p>\nBoy, I wish I knew.  We would need to compare each pair point by point to\nbe sure.\n</p>\n\n<p>\nI suspect it really just reflects the origin of the papers &#x2014; scooped from\nopen access journals or from PubMed&rsquo;s free text links.  I&rsquo;m surprised there\naren&rsquo;t any notes about methodoloy in the CORD-19 data set itself.\n</p>\n\n</div>\n\n\n<a id=\"issues\"></a>\n\n## Issues\n\n-   Operations can take a long time because of the size of the corpus\n-   Metadata availability seems to vary between files\n-   Corpus is updated frequently, so different versions may give different\n    results\n-   Some papers seem to appear twice, as both a PDF parse and a PMC parse\n\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/amorehead/cord19_corpus_reader",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "CORD-19-Corpus-Reader",
    "package_url": "https://pypi.org/project/CORD-19-Corpus-Reader/",
    "platform": "",
    "project_url": "https://pypi.org/project/CORD-19-Corpus-Reader/",
    "project_urls": {
      "Homepage": "https://github.com/amorehead/cord19_corpus_reader"
    },
    "release_url": "https://pypi.org/project/CORD-19-Corpus-Reader/0.0.4/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "A corpus reader for the CORD-19 dataset, compatible with NLTK",
    "version": "0.0.4",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 10617690,
  "releases": {
    "0.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9f0e8bddc7487c6c7e3ae66befb40bb1e3c3627866a9a5ef0d975fdf2fcddad1",
          "md5": "816127fc7c78dc56aec65f92e7cfd55f",
          "sha256": "284921cc18f2d68cd7998eca7aa485a2f9b72c4a80103934c6ac1a5c224107e3"
        },
        "downloads": -1,
        "filename": "CORD_19_Corpus_Reader-0.0.0-py3.8.egg",
        "has_sig": false,
        "md5_digest": "816127fc7c78dc56aec65f92e7cfd55f",
        "packagetype": "bdist_egg",
        "python_version": "0.0.0",
        "requires_python": null,
        "size": 1070,
        "upload_time": "2021-04-11T19:57:31",
        "upload_time_iso_8601": "2021-04-11T19:57:31.197664Z",
        "url": "https://files.pythonhosted.org/packages/9f/0e/8bddc7487c6c7e3ae66befb40bb1e3c3627866a9a5ef0d975fdf2fcddad1/CORD_19_Corpus_Reader-0.0.0-py3.8.egg",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7df527b08764adbe8541af73f0dfedfac6d6c923acadd5c6e7df42996233e92d",
          "md5": "305aa87f4afdb2fccdc598a8cef269d6",
          "sha256": "7ffcd6a8c174c0963d1cfdbded9b4c00846f4697111603264da1599dd1954228"
        },
        "downloads": -1,
        "filename": "CORD_19_Corpus_Reader-0.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "305aa87f4afdb2fccdc598a8cef269d6",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 5086,
        "upload_time": "2021-04-11T19:57:32",
        "upload_time_iso_8601": "2021-04-11T19:57:32.686994Z",
        "url": "https://files.pythonhosted.org/packages/7d/f5/27b08764adbe8541af73f0dfedfac6d6c923acadd5c6e7df42996233e92d/CORD_19_Corpus_Reader-0.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2dca0ef202d40209d42999296e86024ba79c6723a29e546f3bf5334e50e2cf42",
          "md5": "438fa7bbec6266563034d82c5d87752e",
          "sha256": "bf0390ba29dcfcc8cbaa2c14441dcc3eedf41324e4cc06c9fd321c1f08a6903e"
        },
        "downloads": -1,
        "filename": "CORD_19_Corpus_Reader-0.0.1-py3.8.egg",
        "has_sig": false,
        "md5_digest": "438fa7bbec6266563034d82c5d87752e",
        "packagetype": "bdist_egg",
        "python_version": "0.0.1",
        "requires_python": null,
        "size": 1077,
        "upload_time": "2021-04-11T20:06:06",
        "upload_time_iso_8601": "2021-04-11T20:06:06.492041Z",
        "url": "https://files.pythonhosted.org/packages/2d/ca/0ef202d40209d42999296e86024ba79c6723a29e546f3bf5334e50e2cf42/CORD_19_Corpus_Reader-0.0.1-py3.8.egg",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fc4fd2c6288423f915f01f8d2be9cf1cc7d61872f64a1d4d79e9c1bc31cfb9a2",
          "md5": "f66d6e7c596d521ee059fa40104bf66a",
          "sha256": "eea43e28ec7feaff0f05852f2f04cd75bc4d44da94e004e8214952c244e546a4"
        },
        "downloads": -1,
        "filename": "CORD_19_Corpus_Reader-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "f66d6e7c596d521ee059fa40104bf66a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 5103,
        "upload_time": "2021-04-11T20:06:07",
        "upload_time_iso_8601": "2021-04-11T20:06:07.560763Z",
        "url": "https://files.pythonhosted.org/packages/fc/4f/d2c6288423f915f01f8d2be9cf1cc7d61872f64a1d4d79e9c1bc31cfb9a2/CORD_19_Corpus_Reader-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "48fc602df73815d87ef32d2c60681e45a63ca64200fb7529c5ee6e9e444d0bb4",
          "md5": "6b23bd48d6a9d0d9286cca87006d963a",
          "sha256": "482f1fe27d3c8885612ec71880ad8999ee872f9dbffed58987afba5d87e7d9d1"
        },
        "downloads": -1,
        "filename": "CORD_19_Corpus_Reader-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "6b23bd48d6a9d0d9286cca87006d963a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 6015,
        "upload_time": "2021-04-12T18:21:10",
        "upload_time_iso_8601": "2021-04-12T18:21:10.683400Z",
        "url": "https://files.pythonhosted.org/packages/48/fc/602df73815d87ef32d2c60681e45a63ca64200fb7529c5ee6e9e444d0bb4/CORD_19_Corpus_Reader-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e34f70700bff3b27ccd6c6b82191dabd404e6442995f95d1c51e09af1f843635",
          "md5": "f560db0abb8d48de31556dd0754a4e0b",
          "sha256": "f4c6cf6c8bb591c520f6b2d6a5428a1b6f0703ef079b03eb7576450eea2610a8"
        },
        "downloads": -1,
        "filename": "CORD_19_Corpus_Reader-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "f560db0abb8d48de31556dd0754a4e0b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 6023,
        "upload_time": "2021-04-17T22:15:53",
        "upload_time_iso_8601": "2021-04-17T22:15:53.995966Z",
        "url": "https://files.pythonhosted.org/packages/e3/4f/70700bff3b27ccd6c6b82191dabd404e6442995f95d1c51e09af1f843635/CORD_19_Corpus_Reader-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bf253b4fdd4013e37ddb2ed21ea78df9e227618bb2c1c12284db13a1f0444f8b",
          "md5": "379a79778c6337f563b4f67e0d2b5694",
          "sha256": "469c1121a8a7e95b16f8e4d9b6497e63c7dd908f2b1ec7e9f3f64d49e92c5c07"
        },
        "downloads": -1,
        "filename": "CORD_19_Corpus_Reader-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "379a79778c6337f563b4f67e0d2b5694",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 7226,
        "upload_time": "2021-06-11T00:58:04",
        "upload_time_iso_8601": "2021-06-11T00:58:04.691559Z",
        "url": "https://files.pythonhosted.org/packages/bf/25/3b4fdd4013e37ddb2ed21ea78df9e227618bb2c1c12284db13a1f0444f8b/CORD_19_Corpus_Reader-0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "bf253b4fdd4013e37ddb2ed21ea78df9e227618bb2c1c12284db13a1f0444f8b",
        "md5": "379a79778c6337f563b4f67e0d2b5694",
        "sha256": "469c1121a8a7e95b16f8e4d9b6497e63c7dd908f2b1ec7e9f3f64d49e92c5c07"
      },
      "downloads": -1,
      "filename": "CORD_19_Corpus_Reader-0.0.4.tar.gz",
      "has_sig": false,
      "md5_digest": "379a79778c6337f563b4f67e0d2b5694",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 7226,
      "upload_time": "2021-06-11T00:58:04",
      "upload_time_iso_8601": "2021-06-11T00:58:04.691559Z",
      "url": "https://files.pythonhosted.org/packages/bf/25/3b4fdd4013e37ddb2ed21ea78df9e227618bb2c1c12284db13a1f0444f8b/CORD_19_Corpus_Reader-0.0.4.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}