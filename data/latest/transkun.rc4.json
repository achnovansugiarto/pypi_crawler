{
  "info": {
    "author": "Yujia Yan",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Piano Transcription with Neural Semi-CRF\n\nThis repo contains code for the paper\n\nYujia Yan, Frank Cwitkowitz, Zhiyao Duan, Skipping the Frame-Level: Event-Based Piano Transcription With Neural Semi-CRFs, Advances in Neural Information Processing Systems, 2021, \n\n[OpenReview](https://openreview.net/forum?id=AzB2Pq7UFsA), [paper](https://openreview.net/pdf?id=AzB2Pq7UFsA), [appendix](https://openreview.net/attachment?id=AzB2Pq7UFsA&name=supplementary_material)\n\n\n## pip installation\n\n```bash\npip3 install transkun\n```\n\nThe pip package provides a quick command for transcribing piano performance audio into midi:\n\n```bash\n$ transkun input.mp3 output.mid\n```\n\nwith cuda:\n\n```bash\n$ transkun input.mp3 output.mid --device cuda\n```\n\n\n## Overview\n<img width=\"1405\" alt=\"image\" src=\"https://user-images.githubusercontent.com/1996534/183318064-db32dbef-500d-4710-93a1-10acd3eb8825.png\">\n\nThis system works as follows: \n1. A score tensor is computed from the input audio that scores every possible intervals for whether or not being an event.\n2. The score tensor computed in (1) is then decoded by the proposed semi-CRF layer to obtain event intervals directly via dynamic programming (viterbi).\n3. Attributes, e.g., velocity and refined onset/offset position, associated with each interval are then predicted from the extracted event intervals from (2).\n\n## Basic Usage\n\n### The Semi-CRF Layer\n\nThis code includes an neural semi-CRF module that is optimized for the problem domain.  \n\nHere is a minimal example for using this module:\n\n```python\nimport CRF\nimport torch\n\nT = 200\nNBatch = 4\n\n# representing the score for the interval [TBegin, TEnd]\n# dimensions: [TEnd, TBegin, NBatch]\n# only the lower triangular part is used\nscore = ((torch.randn(T,  T, NBatch))).cuda()\n\n# representing the score for being not an interval, dimensions [TBegin, TBegin+1]\nnoiseScore= ((torch.randn(T-1,  NBatch))).cuda()\n\n# a list of list of non-overlapping intervals\nintervals = [\n        [(0,2), (4,6),(6,6), (7,8)],\n        [(1,2), (3,5), (19,19)],\n        [(0,0),(4,7)],\n        [],\n        ]\n\ncrf = CRF.NeuralSemiCRFInterval(score, noiseScore)\n\n## log probability\nlogP = crf.logProb(intervals)\n\n## decoding\ndecoded = crf.decode()\n\n## decoding starting from a given position, useful for segment based processing\ndecoded = crf.decode(forcedStartPos = [4]*NBatch)\n```\n\n### Transcribing piano performance into a MIDI file\n\n```bash\npython3 -m transkun.transcribe -h\n\nusage: transkun [-h] [--weight WEIGHT] [--device [DEVICE]] [--segmentHopSize SEGMENTHOPSIZE] [--segmentSize SEGMENTSIZE] audioPath outPath\n\npositional arguments:\n  audioPath             path to the input audio file\n  outPath               path to the output MIDI file\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --weight WEIGHT       path to the pretrained weight\n  --device [DEVICE]     The device used to perform the most computations (optional), DEFAULT: cpu\n  --segmentHopSize SEGMENTHOPSIZE\n                        The segment hopsize for processing the entire audio file (s), DEFAULT: 10\n  --segmentSize SEGMENTSIZE\n                        The segment size for processing the entire audio file (s), DEFAULT: 20\n```\n\nPlease note that segmentHopSize and segmentSize should be chosen such that there is an overlap between consecutive segments. \nThe included weight is trained under segmentHopSize = 10 and segmentSize = 20.\n\nThis script can also be used directly as the command line command 'transkun' if the pip package is installed, e.g., \n\n```bash\n$ transkun input.mp3 output.mid\n```\n\n\n## Handling the dataset\n\n### Converting to the same sampling rate\n\nWe assume the data contains only the same sampling rate 44100hz. Therefore for the maestro dataset it is necessary to perform sampling rate conversion to 44100hz for the last two years (2017 and 2018) .  \n\n#### Justification for using the original sample rate\n\nMany exisiting works downsample the original audio files to a smaller sampling rate. And it seems quite \"conventional\" to do downsampling. However, from our perspective, this step is unnecessary:\n\n1. Spectral processing for getting the mel spectrum only incurs a small computation cost. However, a good quality downsampling algorithm is more expensive than computing the mel spectrum.\n\n2. Whether or not compute the spectrum from the downsampled version, the size of the input to the neural network is at the same range. \n\n3. There is no need to load all data into memory as the wav file is random accessible. This work directly random acesses the wav file instead of using a specific file format. \n\n### Generating metadata files\n\nAssuming all audio files have already been converted to the same sampling rate, we iterate the entire dataset to combine the groundtruth midi and metadata into a single file.\n\nThe following script will generate train.pt, val.pt and test.pt\n\n```bash\npython3 -m transkun.createDatasetMaestro -h\nusage: createDatasetMaestro.py [-h] [--noPedalExtension] datasetPath metadataCSVPath outputPath\n\npositional arguments:\n  datasetPath         folder path to the maestro dataset\n  metadataCSVPath     path to the metadata file of the maestro dataset (csv)\n  outputPath          path to the output folder\n\noptional arguments:\n  -h, --help          show this help message and exit\n  --noPedalExtension  Do not perform pedal extension according to the sustain pedal\n```\n\nThis command will generate train.pt, dev.pt, test.pt in the outputPath.\n\n## Training\n\nAfter generating the medata files, we can perform training using the dataset. During training, the audio waveforms will be fetched directly from the original .wav files.\n\nFirstly, generate a config template file for the model:\n\n```bash\nmkdir testcheckpoint\npython3 -m transkun.generateConfig transkun.Model_ablation > checkpoint/conf.json\n```\n\nThen we call the training script.\n\n```bash\npython3 -m transkun.train -h\n```\n\n## The Evaluation Module\n\n### Comparing the output MIDI files and the groundtruth MIDI files\n\nWe also provide an out-of-box tool for computing metrics directly from output midi files.\n\n```bash\nusage: computeMetrics.py [-h] [--outputJSON OUTPUTJSON] [--noPedalExtension] [--nProcess [NPROCESS]] [--computeDeviations] estDIR groundTruthDIR\n\ncompute metrics directly from MIDI files.\nNote that estDIR should have the same folder structure as the groundTruthDIR.\nThe MIDI files to evaluate should have the same extension as the ground truth.\nMetrics outputed are ordered by precision, recall, f1, overlap.\n\npositional arguments:\n  estDIR\n  groundTruthDIR\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --outputJSON OUTPUTJSON\n                        path to save the output file for detailed metrics per audio file\n  --noPedalExtension    Do not perform pedal extension according to the sustain pedal for the ground truch\n  --nProcess [NPROCESS]\n                        number of workers for multiprocessing\n  --computeDeviations   output detailed onset/offset deviations for each matched note.\n```\n\nCurrently, we do not support evaluation of multitrack MIDIs.\n\nThis command can also be used directly as the command line script 'transkunEval' if the pip package is installed.\n\n### Ploting the empirical cumulative distribution function to visualize the onset/offset accuracy\n\nUse the following script to plot the ECDF curve for onset/offset deviations:\n\n```bash\nusage: plotDeviation.py [-h] [--labels [LABELS [LABELS ...]]] [--offset] [--T T] [--output [OUTPUT]] [--noDisplay] evalJsons [evalJsons ...]\n\nplot the empirical cumulative distribution function on onset/offset deviations\n\npositional arguments:\n  evalJsons             a seqeunce of the output json files from the computeMetrics script, the deviation output should be enabled\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --labels [LABELS [LABELS ...]]\n                        specify labels to show on the legend\n  --offset              plot the offset deviation curve. If not specified, onset deviation curve will be plotted\n  --T T                 time limit(ms), default: 50ms\n  --output [OUTPUT]     filename to save\n  --noDisplay           Do not show the figure.\n```\n\n![loading-ag-1328](./assets/exampleDev.png)\n\n### Citation\n\nIf you find this repository helpful, please consider citing:\n\n\nBibtex:\n\n```bibtex\n@inproceedings{\nyan2021skipping,\ntitle={Skipping the Frame-Level: Event-Based Piano Transcription With Neural Semi-{CRF}s},\nauthor={Yujia Yan and Frank Cwitkowitz and Zhiyao Duan},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=AzB2Pq7UFsA}\n}\n```\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/Yujia-Yan/Skipping-The-Frame-Level",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "transkun",
    "package_url": "https://pypi.org/project/transkun/",
    "platform": null,
    "project_url": "https://pypi.org/project/transkun/",
    "project_urls": {
      "Homepage": "https://github.com/Yujia-Yan/Skipping-The-Frame-Level"
    },
    "release_url": "https://pypi.org/project/transkun/0.1.4/",
    "requires_dist": [
      "ncls",
      "pretty-midi",
      "scipy",
      "torchaudio",
      "torch",
      "mir-eval",
      "pydub",
      "seaborn",
      "matplotlib",
      "tensorboard",
      "tqdm",
      "torch-optimizer",
      "sox",
      "soxr"
    ],
    "requires_python": ">=3.6",
    "summary": "Yet another tool for automatic piano transcription",
    "version": "0.1.4",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14698663,
  "releases": {
    "0.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2aafdb364b427a7a8acc2b7a51d0f1ef9a2ebff203add5d3a971472cde6897f7",
          "md5": "37a06b02603e10767788e68c3f9ec8f6",
          "sha256": "31ca04978bb406b24d1c21e3486a8092e3b43f3334c570bb27f450d93427be62"
        },
        "downloads": -1,
        "filename": "transkun-0.1.2a-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "37a06b02603e10767788e68c3f9ec8f6",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 36729954,
        "upload_time": "2022-08-08T00:55:15",
        "upload_time_iso_8601": "2022-08-08T00:55:15.659251Z",
        "url": "https://files.pythonhosted.org/packages/2a/af/db364b427a7a8acc2b7a51d0f1ef9a2ebff203add5d3a971472cde6897f7/transkun-0.1.2a-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8f445d20d7b5b8bc43f76a385e8037b1ee7c213456207464f015d2e7fc774c51",
          "md5": "7a5f71045541ec5de64b7ee3dea2db16",
          "sha256": "5ab747f7e64745002085f944a27f34ade13b027cb9eba8477dc9cfed096ec48e"
        },
        "downloads": -1,
        "filename": "transkun-0.1.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "7a5f71045541ec5de64b7ee3dea2db16",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 36729953,
        "upload_time": "2022-08-08T16:56:41",
        "upload_time_iso_8601": "2022-08-08T16:56:41.982010Z",
        "url": "https://files.pythonhosted.org/packages/8f/44/5d20d7b5b8bc43f76a385e8037b1ee7c213456207464f015d2e7fc774c51/transkun-0.1.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.3a0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "442ab628fc8982936bced80ea46bba6e2274b0d17eac1c6de57e41c240f6fe1e",
          "md5": "7fea49a051b039c0041bd62dea6b1af9",
          "sha256": "54f3f105e747564490812c1a4804a18bbd599a383012977c8b2b885c79963fc1"
        },
        "downloads": -1,
        "filename": "transkun-0.1.3a0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "7fea49a051b039c0041bd62dea6b1af9",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 36730291,
        "upload_time": "2022-08-09T05:24:32",
        "upload_time_iso_8601": "2022-08-09T05:24:32.631371Z",
        "url": "https://files.pythonhosted.org/packages/44/2a/b628fc8982936bced80ea46bba6e2274b0d17eac1c6de57e41c240f6fe1e/transkun-0.1.3a0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d4615eccc80a0c068ce52a0920c238d31dc702cbb6642889c0b576559678ebae",
          "md5": "9222f8aa65075a2a4eb36ade4f9e40f9",
          "sha256": "76bb7fb8a8d32f8869f9e1144a08676ad57b63d40cddcb8c34a52e22577ee008"
        },
        "downloads": -1,
        "filename": "transkun-0.1.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "9222f8aa65075a2a4eb36ade4f9e40f9",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 36730264,
        "upload_time": "2022-08-09T05:28:16",
        "upload_time_iso_8601": "2022-08-09T05:28:16.840731Z",
        "url": "https://files.pythonhosted.org/packages/d4/61/5eccc80a0c068ce52a0920c238d31dc702cbb6642889c0b576559678ebae/transkun-0.1.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "d4615eccc80a0c068ce52a0920c238d31dc702cbb6642889c0b576559678ebae",
        "md5": "9222f8aa65075a2a4eb36ade4f9e40f9",
        "sha256": "76bb7fb8a8d32f8869f9e1144a08676ad57b63d40cddcb8c34a52e22577ee008"
      },
      "downloads": -1,
      "filename": "transkun-0.1.4-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "9222f8aa65075a2a4eb36ade4f9e40f9",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 36730264,
      "upload_time": "2022-08-09T05:28:16",
      "upload_time_iso_8601": "2022-08-09T05:28:16.840731Z",
      "url": "https://files.pythonhosted.org/packages/d4/61/5eccc80a0c068ce52a0920c238d31dc702cbb6642889c0b576559678ebae/transkun-0.1.4-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}