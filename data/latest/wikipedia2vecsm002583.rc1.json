{
  "info": {
    "author": "Samiksha Manjunath",
    "author_email": "samiksha.manjunath@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: Apache Software License",
      "Natural Language :: English",
      "Programming Language :: Python",
      "Programming Language :: Python :: 2.7",
      "Programming Language :: Python :: 3.3",
      "Programming Language :: Python :: 3.4",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6"
    ],
    "description": "Wikipedia2Vec\n=============\n\n[![Fury badge](https://badge.fury.io/py/wikipedia2vec.png)](http://badge.fury.io/py/wikipedia2vec)\n[![CircleCI](https://circleci.com/gh/wikipedia2vec/wikipedia2vec.svg?style=svg)](https://circleci.com/gh/wikipedia2vec/wikipedia2vec)\n\nWikipedia2Vec is a tool used for obtaining embeddings (or vector representations) of words and entities (i.e., concepts that have corresponding pages in Wikipedia) from Wikipedia.\nIt is developed and maintained by [Studio Ousia](http://www.ousia.jp).\n\nThis tool enables you to learn embeddings of words and entities simultaneously, and places similar words and entities close to one another in a continuous vector space.\nEmbeddings can be easily trained by a single command with a publicly available Wikipedia dump as input.\n\nThis tool implements the [conventional skip-gram model](https://en.wikipedia.org/wiki/Word2vec) to learn the embeddings of words, and its extension proposed in [Yamada et al. (2016)](https://arxiv.org/abs/1601.01343) to learn the embeddings of entities.\nThis tool has been used in several state-of-the-art NLP models such as [entity linking](https://arxiv.org/abs/1601.01343), [named entity recognition](http://www.aclweb.org/anthology/I17-2017), [knowledge graph completion](https://www.aaai.org/Papers/AAAI/2019/AAAI-ShahH.6029.pdf), [entity relatedness](https://arxiv.org/abs/1601.01343), and [question answering](https://arxiv.org/abs/1803.08652).\n\nThis tool has been tested on Linux, Windows, and macOS.\n\nAn empirical comparison between Wikipedia2Vec and existing embedding tools (i.e., FastText, Gensim, RDF2Vec, and Wiki2vec) is available [here](https://arxiv.org/abs/1812.06280).\n\nDocumentation and pretrained embeddings for 12 languages (English, Arabic, Chinese, Dutch, French, German, Italian, Japanese, Polish, Portuguese, Russian, and Spanish) are available online at [http://wikipedia2vec.github.io/](http://wikipedia2vec.github.io/).\n\nBasic Usage\n-----------\n\nWikipedia2Vec can be installed via PyPI:\n\n```bash\n% pip install wikipedia2vec\n```\n\nWith this tool, embeddings can be learned by running a *train* command with a Wikipedia dump as input.\nFor example, the following commands download the latest English Wikipedia dump and learn embeddings from this dump:\n\n```bash\n% wget https://dumps.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2\n% wikipedia2vec train enwiki-latest-pages-articles.xml.bz2 MODEL_FILE\n```\n\nThen, the learned embeddings are written to *MODEL\\_FILE*.\nNote that this command can take many optional parameters.\nPlease refer to [our documentation](https://wikipedia2vec.github.io/wikipedia2vec/commands/) for further details.\n\nReference\n---------\n\nIf you use Wikipedia2Vec in a scientific publication, please cite the following paper:\n\nIkuya Yamada, Akari Asai, Hiroyuki Shindo, Hideaki Takeda, Yoshiyasu Takefuji, [Wikipedia2Vec: An Optimized Tool for Learning Embeddings of Words and Entities from Wikipedia](https://arxiv.org/abs/1812.06280).\n\n```text\n@article{yamada2018wikipedia2vec,\n  title={Wikipedia2Vec: An Optimized Tool for Learning Embeddings of Words and Entities from Wikipedia},\n  author={Yamada, Ikuya and Asai, Akari and Shindo, Hiroyuki and Takeda, Hideaki and Takefuji, Yoshiyasu},\n  journal={arXiv preprint 1812.06280},\n  year={2018}\n}\n```\n\nLicense\n-------\n\n[Apache License 2.0](http://www.apache.org/licenses/LICENSE-2.0)",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "https://github.com/samikshm/wikipedia2vecSM002583/archive/0.1.tar.gz",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/samikshm/wikipedia2vecSM002583",
    "keywords": "wikipedia,embedding,wikipedia2vec",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "wikipedia2vecSM002583",
    "package_url": "https://pypi.org/project/wikipedia2vecSM002583/",
    "platform": "",
    "project_url": "https://pypi.org/project/wikipedia2vecSM002583/",
    "project_urls": {
      "Download": "https://github.com/samikshm/wikipedia2vecSM002583/archive/0.1.tar.gz",
      "Homepage": "https://github.com/samikshm/wikipedia2vecSM002583"
    },
    "release_url": "https://pypi.org/project/wikipedia2vecSM002583/0.1/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "A tool for learning vector representations of words and entities from Wikipedia",
    "version": "0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 5147406,
  "releases": {
    "0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b8e2c8bdf4c5656989d1d30f1d7107fd6460c9f6d36cd5ccb08bbb65ca491f28",
          "md5": "2280a1893d412510256f3232418e3c9d",
          "sha256": "ea1c84dfac0e7c26da8b02c53e03dc235913cb67541e682b090e2aa616d1f8c0"
        },
        "downloads": -1,
        "filename": "wikipedia2vecSM002583-0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "2280a1893d412510256f3232418e3c9d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 1178976,
        "upload_time": "2019-04-16T00:31:41",
        "upload_time_iso_8601": "2019-04-16T00:31:41.114533Z",
        "url": "https://files.pythonhosted.org/packages/b8/e2/c8bdf4c5656989d1d30f1d7107fd6460c9f6d36cd5ccb08bbb65ca491f28/wikipedia2vecSM002583-0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "b8e2c8bdf4c5656989d1d30f1d7107fd6460c9f6d36cd5ccb08bbb65ca491f28",
        "md5": "2280a1893d412510256f3232418e3c9d",
        "sha256": "ea1c84dfac0e7c26da8b02c53e03dc235913cb67541e682b090e2aa616d1f8c0"
      },
      "downloads": -1,
      "filename": "wikipedia2vecSM002583-0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "2280a1893d412510256f3232418e3c9d",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 1178976,
      "upload_time": "2019-04-16T00:31:41",
      "upload_time_iso_8601": "2019-04-16T00:31:41.114533Z",
      "url": "https://files.pythonhosted.org/packages/b8/e2/c8bdf4c5656989d1d30f1d7107fd6460c9f6d36cd5ccb08bbb65ca491f28/wikipedia2vecSM002583-0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}