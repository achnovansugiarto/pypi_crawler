{
  "info": {
    "author": "WAX-ML Authors",
    "author_email": "eserie@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Topic :: Scientific/Engineering"
    ],
    "description": "<div align=\"center\">\n<img src=\"https://github.com/eserie/wax-ml/blob/main/docs/_static/wax_logo.png\" alt=\"logo\" width=\"40%\"></img>\n</div>\n\n# WAX-ML: A Python library for machine-learning and feedback loops on streaming data\n\n![Continuous integration](https://github.com/eserie/wax-ml/actions/workflows/tests.yml/badge.svg)\n[![Documentation Status](https://readthedocs.org/projects/wax-ml/badge/?version=latest)](https://wax-ml.readthedocs.io/en/latest/)\n[![PyPI version](https://badge.fury.io/py/wax-ml.svg)](https://badge.fury.io/py/wax-ml)\n[![Codecov](https://codecov.io/gh/eserie/wax-ml/branch/main/graph/badge.svg)](https://codecov.io/gh/eserie/wax-ml)\n[![Black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/ambv/black)\n\n\n\n[**Quickstart**](#quickstart-colab-in-the-cloud)\n| [**Install guide**](#installation)\n| [**Change logs**](https://wax-ml.readthedocs.io/en/latest/changelog.html)\n| [**Reference docs**](https://wax-ml.readthedocs.io/en/latest/)\n\n## Introduction\n\nüåä Wax is what you put on a surfboard to avoid slipping. It is an essential tool to go\nsurfing ... üåä\n\nWAX-ML is a research-oriented [Python](https://www.python.org/)  library\nproviding tools to design powerful machine learning algorithms and feedback loops\nworking on streaming data.\n\nIt strives to complement [JAX](https://jax.readthedocs.io/en/latest/)\nwith tools dedicated to time series.\n\nWAX-ML makes JAX-based programs easy to use for end-users working\nwith\n[pandas](https://pandas.pydata.org/) and [xarray](http://xarray.pydata.org/en/stable/)\nfor data manipulation.\n\nWAX-ML provides a simple mechanism for implementing feedback loops, allows the implementation of\n reinforcement learning algorithms with functions, and makes them easy to integrate by\nend-users working with the object-oriented reinforcement learning framework from the\n[Gym](https://gym.openai.com/) library.\n\nTo learn more, you can read our [article on ArXiv](http://arxiv.org/abs/2106.06524)\nor simply access the code in this repository.\n\n## WAX-ML Goal\n\nWAX-ML's goal is to expose \"traditional\" algorithms that are often difficult to find in standard\nPython ecosystem and are related to time-series and more generally to streaming data.\n\nIt aims to make it easy to work with algorithms from very various computational domains such as\nmachine learning, online learning, reinforcement learning, optimal control, time-series analysis,\noptimization, statistical modeling.\n\nFor now, WAX-ML focuses on **time-series** algorithms as this is one of the areas of machine learning\nthat lacks the most dedicated tools.  Working with time series is notoriously known to be difficult\nand often requires very specific algorithms (statistical modeling, filtering, optimal control).\n\n\nEven though some of the modern machine learning methods such as RNN, LSTM, or reinforcement learning\ncan do an excellent job on some specific time-series problems, most of the problems require using\nmore traditional algorithms such as linear and non-linear filters, FFT,\nthe eigendecomposition of matrices (e.g. [[7]](#references)),\nprincipal component analysis (PCA) (e.g. [[8]](#references)), Riccati solvers for\noptimal control and filtering, ...\n\n\nBy adopting a functional approach, inherited from JAX, WAX-ML aims to be an efficient tool to\ncombine modern machine learning approaches with more traditional ones.\n\n\nSome work has been done in this direction in [[2] in References](#references) where transformer encoder\narchitectures are massively accelerated, with limited accuracy costs, by replacing the\nself-attention sublayers with a standard, non-parameterized Fast Fourier Transform (FFT).\n\n\nWAX-ML may also be useful for developing research ideas in areas such as online machine learning\n(see [[1] in References](#references)) and development of control, reinforcement learning,\nand online optimization methods.\n\n## What does WAX-ML do?\n\nWell, building WAX-ML, we have some pretty ambitious design and implementation goals.\n\nTo do things right, we decided to start small and in an open-source design from the beginning.\n\n\nFor now, WAX-ML contains:\n- transformation tools that we call \"unroll\" transformations allowing us to\n  apply any transformation, possibly stateful, on sequential data.  It generalizes the RNN\n  architecture to any stateful transformation allowing the implementation of any kind of \"filter\".\n\n- a \"stream\" module, described in [üåä Streaming Data üåä](#-streaming-data-), permitting us to\n  synchronize data streams with different time resolutions.\n\n- some general pandas and xarray \"accessors\" permitting the application of any\n  JAX-functions on pandas and xarray data containers:\n  `DataFrame`, `Series`, `Dataset`, and `DataArray`.\n\n- ready-to-use exponential moving average filter that we exposed with two APIs:\n    - one for JAX users: as Haiku modules (`EWMA`, ... see the complete list in our\n    [API documentation](https://wax-ml.readthedocs.io/en/latest/wax.modules.html)\n    ).\n    - a second one for pandas and xarray users: with drop-in replacement of pandas\n      `ewm` accessor.\n\n- a simple module `OnlineSupervisedLearner` to implement online learning algorithms\n  for supervised machine learning problems.\n\n- building blocks for designing feedback loops in reinforcement learning, and have\n  provided a module called `GymFeedback` allowing the implementation of feedback loop as the\n  introduced in the library [Gym](https://gym.openai.com/), and illustrated this figure:\n\n  <div align=\"center\">\n  <img src=\"docs/tikz/gymfeedback.png\" alt=\"logo\" width=\"60%\"></img>\n  </div>\n\n### What is JAX?\n\nJAX is a research-oriented computational system implemented in Python that leverages the\nXLA optimization framework for machine learning computations.  It makes XLA usable with\nthe NumPy API and some functional primitives for just-in-time compilation,\ndifferentiation, vectorization, and parallelization.  It allows building higher-level\ntransformations or \"programs\" in a functional programming approach.\nSee  [JAX's page](https://github.com/google/jax) for more details.\n\n\n## Why to use WAX-ML?\n\nIf you deal with time-series and are a pandas or xarray user, b\nut you want to use the impressive\ntools of the JAX ecosystem, then WAX-ML might be the right tool for you,\nas it implements pandas and\nxarray accessors to apply JAX functions.\n\nIf you are a user of JAX, you may be interested in adding WAX-ML to your toolbox to address\ntime-series problems.\n\n## Design\n\n### Research oriented\nWAX-ML is a research-oriented library.  It relies on\n[JAX](https://jax.readthedocs.io/en/latest/notebooks/quickstart.html) and\n[Haiku](https://github.com/deepmind/dm-haiku) functional programming paradigm to ease the\ndevelopment of research ideas.\n\nWAX-ML is a bit like [Flux](https://fluxml.ai/Flux.jl/stable/)\nin [Julia](https://julialang.org/) programming language.\n\n### Functional programming\nIn WAX-ML, we pursue a functional programming approach inherited from JAX.\n\nIn this sense, WAX-ML is not a framework, as most object-oriented libraries offer.  Instead, we\nimplement \"functions\" that must be pure to exploit the JAX ecosystem.\n\n### Haiku modules\nWe use the \"module\" mechanism proposed by the Haiku library to easily generate pure function pairs,\ncalled `init` and `apply` in Haiku, to implement programs that require the management of\nparameters and/or state variables.\nYou can see\n[the Haiku module API](https://dm-haiku.readthedocs.io/en/latest/api.html#modules-parameters-and-state)\nand\n[Haiku transformation functions](https://dm-haiku.readthedocs.io/en/latest/api.html#haiku-transforms)\nfor more details.\n\nIn this way, we can recover all the advantages of\nobject-oriented programming but exposed in the functional programming approach.\nIt permits to ease the development of robust and reusable features and to\ndevelop \"mini-languages\" tailored to specific scientific domains.\n\n\n### WAX-ML works with other libraries\n\nWe want existing machine learning libraries to work well together while trying to leverage their strength.\nThis is facilitated with a functional programming approach.\n\nWAX-ML is not a framework but either a set of tools that aim to complement\n[JAX Ecosystem](https://moocaholic.medium.com/jax-a13e83f49897).\n\n\n# Contents\n* [üöÄ Quickstart: Colab in the Cloud üöÄ](#-quicksart-colab-in-the-cloud-)\n* [‚è± Synchronize streams ‚è±](#-synchronize-streams-)\n* [üåä Streaming Data üåä](#-streaming-data-)\n* [Implemented modules](#-implemented-modules-)\n* [‚ôª Feedback loops ‚ôª](#-feedback-loops-)\n* [Future plans](#future-plans)\n* [‚öí Installation ‚öí](#installation)\n* [Disclaimer](#disclaimer)\n* [Development](#development)\n* [References](#references)\n* [License](#license)\n* [Citing WAX-ML](#citing-wax)\n* [Reference documentation](#reference-documentation)\n\n\n## üöÄ Quickstart üöÄ\n\nJump right in using a notebook in your browser, connected to a Google Cloud GPU or\nsimply read our notebook in the\n[documentation](https://wax-ml.readthedocs.io/en/latest/).\n\nHere are some starter notebooks:\n- „Ä∞ Compute exponential moving averages with xarray and pandas accessors „Ä∞ : [![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/eserie/wax-ml/blob/main/docs/notebooks/01_demo_EWMA.ipynb),\n  [Open in Documentation](https://wax-ml.readthedocs.io/en/latest/notebooks/01_demo_EWMA.html)\n- ‚è± Synchronize data streams ‚è± : [![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/eserie/wax-ml/blob/main/docs/notebooks/02_Synchronize_data_streams.ipynb),\n  [Open in Documentation](https://wax-ml.readthedocs.io/en/latest/notebooks/02_Synchronize_data_streams.html)\n- üå° Binning temperatures üå° : [![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/eserie/wax-ml/blob/main/docs/notebooks/03_ohlc_temperature.ipynb),\n  [Open in Documentation](https://wax-ml.readthedocs.io/en/latest/notebooks/03_ohlc_temperature.html)\n- üéõ The three steps workflow üéõ : [![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/eserie/wax-ml/blob/main/docs/notebooks/04_The_three_steps_workflow.ipynb),\n  [Open in Documentation](https://wax-ml.readthedocs.io/en/latest/notebooks/04_The_three_steps_workflow.html)\n- üî≠ Reconstructing the light curve of stars with LSTM üî≠: [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/eserie/wax-ml/blob/main/docs/notebooks/05_reconstructing_the_light_curve_of_stars.ipynb),\n  [Open in Documentation](https://wax-ml.readthedocs.io/en/latest/notebooks/05_reconstructing_the_light_curve_of_stars.html)\n- ü¶é Online linear regression with a non-stationary environment ü¶é: [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/eserie/wax-ml/blob/main/docs/notebooks/06_Online_Linear_Regression.ipynb),\n  [Open in Documentation](https://wax-ml.readthedocs.io/en/latest/notebooks/06_Online_Linear_Regression.html)\n\n\n## ‚è± Synchronize streams ‚è±\n\nPhysicists have brought a solution to the synchronization problem called the Poincar√©‚ÄìEinstein\nsynchronization (See [Poincar√©-Einstein synchronization Wikipedia\npage](https://en.wikipedia.org/wiki/Einstein_synchronisation)).  In WAX-ML we have implemented a similar\nmechanism by defining a \"local time\", borrowing Henri Poincar√© terminology, to denominate the\ntimestamps of the stream (the \"local stream\") in which the user wants to apply transformations and\nunravel all other streams.  The other streams, which we have called \"secondary streams\", are pushed\nback in the local stream using embedding maps which specify how to convert timestamps from a\nsecondary stream into timestamps in the local stream.\n\nThis synchronization mechanism permits to work with secondary streams having timestamps at\nfrequencies that can be lower or higher than the local stream. The data from these secondary streams\nare represented in the \"local stream\" either with the use of a forward filling mechanism for lower\nfrequencies or with a buffering mechanism for higher frequencies.\n\nNote that this simple synchronization scheme assumes that the different event streams have fixed\nlatencies.\n\nWe have implemented a \"data tracing\" mechanism to optimize access to out-of-sync streams.  This\nmechanism works on in-memory data.  We perform the first pass on the data, without actually\naccessing it, and determine the indices necessary to later access the data. Doing so we are vigilant\nto not let any \"future\" information pass through and thus guaranty a data processing that respects\ncausality.\n\nThe buffering mechanism used in the case of higher frequencies works with a fixed buffer size\n(see the WAX-ML module [`wax.modules.Buffer`](https://wax-ml.readthedocs.io/en/latest/_autosummary/wax.modules.buffer.html#module-wax.modules.buffer)\nto allow the use of JAX / XLA optimizations and efficient processing.\n\n### Example\n\nLet's illustrate with a small example how `wax.stream.Stream` synchronizes data streams.\n\nLet's use the dataset \"air temperature\" with :\n- An air temperature is defined with hourly resolution.\n- A \"fake\" ground temperature is defined with a daily resolution as the air temperature minus 10 degrees.\n\n\n```python\n\nfrom wax.accessors import register_wax_accessors\n\nregister_wax_accessors()\n```\n\n```python\n\nfrom wax.modules import EWMA\n\n\ndef my_custom_function(dataset):\n    return {\n        \"air_10\": EWMA(1.0 / 10.0)(dataset[\"air\"]),\n        \"air_100\": EWMA(1.0 / 100.0)(dataset[\"air\"]),\n        \"ground_100\": EWMA(1.0 / 100.0)(dataset[\"ground\"]),\n    }\n```\n\n```python\nresults, state = dataset.wax.stream(\n    local_time=\"time\", ffills={\"day\": 1}, pbar=True\n).apply(my_custom_function, format_dims=dataset.air.dims)\n```\n\n```python\n_ = results.isel(lat=0, lon=0).drop([\"lat\", \"lon\"]).to_pandas().plot(figsize=(12, 8))\n```\n\n<div align=\"center\">\n<img src=\"docs/_static/synchronize_data_streams.png\" alt=\"logo\" width=\"60%\"></img>\n</div>\n\n## üåä Streaming Data üåä\n\nWAX-ML may complement JAX ecosystem by adding support for **streaming data**.\n\nTo do this, WAX-ML implements a unique **data tracing** mechanism that prepares for fast\naccess to in-memory data and allows the execution of JAX tractable functions such as\n`jit`, `grad`, `vmap`, or `pmap`.\n\nThis mechanism is somewhat special in that it works with time-series data.\n\nThe `wax.stream.Stream` object implements this idea.  It uses Python generators to\n**synchronize multiple streaming data streams** with potentially different temporal\nresolutions.\n\nThe `wax.stream.Stream` object works on in-memory data stored in\n[`xarray.Dataset`](http://xarray.pydata.org/en/stable/generated/xarray.Dataset.html).\n\nTo work with \"real\" streaming data, it should be possible to implement a buffer\nmechanism running on any Python generator and to use the synchronization and data\ntracing mechanisms implemented in WAX-ML to apply JAX transformations on batches of data\nstored in memory. (See our WEP4 enhancement proposal)\n\n### ‚åõ Adding support for time dtypes in JAX ‚åõ\n\nAt the moment `datetime64` and `string_` dtypes are not supported in JAX.\n\nWAX-ML add support for `datetime64` and `string_` NumPy dtypes in JAX.\nTo do so, WAX-ML implements:\n- an encoding scheme for `datetime64` relying on pairs of 32-bit integers similar to `PRNGKey` in JAX.\n- an encoding scheme for `string_` relying on `LabelEncoder` of [Scikit-learn](https://scikit-learn.org/stable/).\n\nBy providing these two encoding schemes, WAX-ML makes it easy to use JAX algorithms on data of these types.\n\nCurrently, the types of time offsets supported by WAX-ML are quite limited and we\ncollaborate with the pandas, xarray, and [Astropy](https://www.astropy.org/) teams\nto further develop the time manipulation tools in WAX-ML (see \"WEP1\" in `WEP.md`).\n\n### pandas and xarray accessors\n\nWAX-ML implements pandas and xarray accessors to ease the usage of machine-learning\nalgorithms implemented with functions implemented with Haiku modules on high-level data APIs :\n- pandas's `DataFrame` and `Series`\n- xarray's `Dataset` and `DataArray`.\n\nTo load the accessors, run:\n```python\nfrom wax.accessors import register_wax_accessors\nregister_wax_accessors()\n```\n\nThen run the \"one-liner\" syntax:\n```python\n<data-container>.stream(‚Ä¶).apply(‚Ä¶)\n```\n\n## Implemented modules\n\nWe have some modules (inherited from Haiku modules) ready to be used in `wax.modules`\n(see our [api documentation](https://wax-ml.readthedocs.io/en/latest/wax.modules.html)).\n\nThey can be considered as \"building blocks\" that can be reused to build more advanced programs to run on streaming data.\n\n### Fundamental modules\n\nWe have some \"fundamental\" modules that are specific to time series management,\n- the `Buffer` module which implements the buffering mechanism\n- the `UpdateOnEvent` module which allows to \"freeze\" the computation of a program and\n  to update it on some events in the \"local flow\".\n  To illustrate the use of this module we show how it can be used to compute the opening,\n  high and closing quantities of temperatures recorded during a day,\n  the binning process being reset at each day change.  We show an illustrative graph of the final result:\n\n\n<div align=\"center\">\n<img src=\"docs/_static/trailing_ohlc.png\" alt=\"logo\" width=\"60%\"></img>\n</div>\n\n### pandas modules\n\nWe have a few more specific modules that aim to reproduce some of the logic that **pandas** users may be familiar with,\nsuch as:\n- `Lag` to implement a delay on the input data\n- `Diff` to compute differences between values over time\n- `PctChange` to compute the relative difference between values over time.\n- `RollingMean` to compute the moving average over time.\n- `EWMA`, `EWMVar`, `EWMCov`, to compute the exponential moving average, variance, covariance of the input data.\n\n### Online learning and reinforcement learning modules\n\nFinally, we implement domain-specific modules for online learning and reinforcement\nlearning such as `OnlineSupervisedLearner` and `GymFeedback` (see dedicated sections).\n\n### accessors\n\nFor now, WAX-ML offers direct access to some modules through specific accessors for pandas and xarray users.\nFor instance, we have an implementation of the \"exponential moving average\" directly\naccessible through the accessor `<data-container>.ewm(...).mean()` which provides a\ndrop-in replacement for the exponential moving average of pandas.\n\nFor now, WAX-ML offers direct access to some modules through specific accessors for pandas and xarray users.\n\nFor instance, you can see our implementation of the \"exponential moving average\".  This\nis a drop-in replacement for the exponential moving average of pandas.\n\nLet's show how it works on the \"air temperature\" dataset from `xarray.tutorials`:\n\n```python\nimport xarray as xr\nda = xr.tutorial.open_dataset(\"air_temperature\")\ndataframe = da.air.to_series().unstack([\"lon\", \"lat\"])\n```\n\nPandas ewma:\n```python\nair_temp_ewma = dataframe.ewm(alpha=1.0 / 10.0).mean()\n```\n\nWAX-ML ewma:\n```python\nair_temp_ewma = dataframe.wax.ewm(alpha=1.0 / 10.0).mean()\n```\n\n\n### Apply a custom function to a Dataset\n\nNow let's illustrate how WAX-ML accessors work on [xarray datasets](http://xarray.pydata.org/en/stable/generated/xarray.Dataset.html).\n\n```python\nfrom wax.modules import EWMA\n\n\ndef my_custom_function(dataset):\n    return {\n        \"air_10\": EWMA(1.0 / 10.0)(dataset[\"air\"]),\n        \"air_100\": EWMA(1.0 / 100.0)(dataset[\"air\"]),\n    }\n\n\ndataset = xr.tutorial.open_dataset(\"air_temperature\")\noutput, state = dataset.wax.stream().apply(\n    my_custom_function, format_dims=dataset.air.dims\n)\n\n_ = output.isel(lat=0, lon=0).drop([\"lat\", \"lon\"]).to_pandas().plot(figsize=(12, 8))\n```\n\n<div align=\"center\">\n<img src=\"docs/_static/my_custom_function_on_dataset.png\" alt=\"logo\" width=\"60%\"></img>\n</div>\n\nYou can see our [Documentation](https://wax-ml.readthedocs.io/en/latest/) for examples with\nEWMA or Binning on the air temperature dataset.\n\n\n### ‚ö° Performance on big dataframes ‚ö°\n\nCheck out our [Documentation](https://wax-ml.readthedocs.io/en/latest/) to\nsee how you can use our \"3-step workflow\" to speed things up!\n\n\n### üî• Speed üî•\n\nWAX-ML algorithms are implemented in JAX, so they are fast!\n\nThe use of JAX allows for leveraging hardware accelerators that optimize programs for the CPU, GPU, and TPU.\n\nWith WAX-ML, you can already compute an exponential moving average on a dataframe with 1 million rows with a 3x to 100x speedup\n(depending on the data container you use and speed measurement methodology) compared to\npandas implementation.  (See our notebook in the\n[Quick Start Documentation](https://wax-ml.readthedocs.io/en/latest/notebooks/04_The_three_steps_workflow.html)\nor in\n[Colaboratory](https://colab.research.google.com/github/eserie/wax-ml/blob/main/docs/notebooks/04_The_three_steps_workflow.ipynb)\n).\n\n## ‚ôª Feedback loops ‚ôª\n\nFeedback is a fundamental notion in time-series analysis and has a wide history\n(see [Feedback Wikipedia page](https://en.wikipedia.org/wiki/Feedback)  for instance).\nSo, we believe it is important to be able to implement them well in WAX-ML.\n\n\nA fundamental piece in the implementation of feedback loops is the delay operator. We implement it\nwith the delay module `Lag` which is itself implemented with the `Buffer` module, a module\nimplementing the buffering mechanism.\n\nThe linear state-space models used to model linear time-invariant systems in signal theory are a\nwell-known place where feedbacks are used to implement for instance infinite impulse response\nfilters.  This is easily implemented with the WAX-ML tools and will be implemented at\na later time.\n\n\nAnother example is control theory or reinforcement learning.\nIn reinforcement learning setup, an agent and an environment interact with a feedback loop.\nThis generally results in a non-trivial global dynamic.\nIn WAX-ML, we propose a simple module called\n`GymFeedBack` that allows the implementation of reinforcement learning experiments.\nThis is built from an agent and an environment, both possibly having parameters and state:\n\n<div align=\"center\">\n<img src=\"docs/tikz/agent_env.png\" alt=\"logo\" width=\"60%\"></img>\n</div>\n\n- The agent is in charge of generating an action from observations.\n- The environment is in charge of calculating a reward associated with the agent's action and preparing\n  the next observation from some \"raw observations\" and the agent's action, which it gives back to the\n  agent.\n\nA feedback instance `GymFeedback(agent, env)` is a function that processes the\n\"raw observations\" and returns a reward as represented here:\n\n<div align=\"center\">\n<img src=\"docs/tikz/gymfeedback.png\" alt=\"logo\" width=\"60%\"></img>\n</div>\n\nEquivalently, we can describe the function `GymFeedback(agent, env)`,\nafter transformation by Haiku transformation, by a pair of pure functions\n`init` and `apply` that we describe here:\n\n<div align=\"center\">\n<img src=\"docs/tikz/gymfeedback_init_apply.png\" alt=\"logo\" width=\"100%\"></img>\n</div>\n\nWe have made concrete use of this feedback mechanism in this notebook where\nwe give an example of online linear regression in a non-stationary environment:\n- ü¶é: [online learning example ![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/eserie/wax-ml/blob/main/docs/notebooks/06_Online_Linear_Regression.ipynb),\n  [Open in Documentation](https://wax-ml.readthedocs.io/en/latest/notebooks/06_Online_Linear_Regression.html) ü¶é\n\nHere is an illustrative plot of the final result of the study:\n\n<div align=\"center\">\n<img src=\"docs/_static/online_linear_regression_regret.png\" alt=\"logo\" width=\"100%\"></img>\n</div>\n\n- Left: The regret (cumulative sum of losses) first becomes concave, which means that the agent \"learns something\".\n  Then, the regret curve has a bump at step 2000 where it becomes locally linear.\n  It finally ends in a concave regime concave regime, which means that the agent has adapted to the new regime.\n- Right: We see that the weights converge to the correct values in both regimes\n\n### Compatibility with other reinforcement learning frameworks\n\nIn addition, to ensure compatibility with other tools in the Gym ecosystem, we propose a\n*transformation* mechanism to transform functions into standard stateful Python objects\nfollowing the Gym API for *agents* and *environments* implemented in\n[deluca](https://github.com/google/deluca).  These wrappers are in the `wax.gym` package.\n\nWAX-ML implements *callbacks* in the `wax.gym` package.  The callback API was inspired by\nthe one in the one in [dask](https://github.com/dask/dask).\n\nWAX-ML should provide tools for reinforcement learning that should complement well those\nalready existing such as [RLax](https://github.com/deepmind/rlax) or [deluca](https://github.com/google/deluca).\n\n## Future plans\n\n### Feedback loops and control theory\n\nWe would like to implement other types of feedback loops in WAX-ML.\nFor instance, those of the standard control theory toolboxes,\nsuch as those implemented in the SLICOT [SLICOT](http://slicot.org/) library.\n\nMany algorithms in this space are absent from the Python ecosystem and\nwe aim to provide JAX-based implementations and expose them with a simple API.\n\nAn idiomatic example in this field is the\n[Kalman filter](https://fr.wikipedia.org/wiki/Filtre_de_Kalman),\na now-standard algorithm that dates back to the 1950s.\nAfter 30 years of existence, the Python ecosystem has still not integrated\nthis algorithm into widely adopted libraries!\nSome implementations can be found in Python libraries such as\n[python-control](https://github.com/python-control/python-control),\n[stats-models](https://www.statsmodels.org/stable/index.html),\n[SciPy Cookbook](https://scipy-cookbook.readthedocs.io/items/KalmanFiltering.html#).\nAlso, some machine learning libraries have some closed and non-solved issues on this subject\n, see [Scikit-learn#862 issue](https://github.com/scikit-learn/scikit-learn/pull/862)\nor [River#355 issue](https://github.com/online-ml/river/pull/355).\nWhy has the Kalman filter not found its place in these libraries?\nWe think it may be because they have an object-oriented API, which makes\nthem very well suited to the specific problems of modern machine learning but,\non the other hand, prevents them from accommodating additional features such as Kalman filtering.\nWe think the functional approach of WAX-ML, inherited from JAX, could well\nhelp to integrate a Kalman filter implementation in a machine learning ecosystem.\n\nIt turns out that Python code written with JAX is not very far from\n[Fortran](https://fr.wikipedia.org/wiki/Fortran), a mathematical FORmula TRANslating\nsystem.  It should therefore be quite easy and natural to reimplement standard\nalgorithms implemented in Fortran, such as those in the\n[SLICOT](http://slicot.org/) library with JAX.\nIt seems that some questions about the integration of Fortran into\nJAX has already been raised.\nAs noted in\n[this discussion on JAX's Github page](https://github.com/google/jax/discussions/3950),\nit might even be possible to simply wrap Fortran code in JAX.\nThis would avoid a painful rewriting process!\n\n\nAlong with the implementation of good old algorithms,\nwe would like to implement more recent ones from the online learning\nliterature that somehow revisits the filtering and control problems.\nIn particular, we would like to implement the online learning version of the\nARMA model developed in [[3]](#references)\nand some online-learning versions of control theory algorithms,\nan approach called \"the non-stochastic control problem\",\nsuch as the linear quadratic regulator (see [[4]](#references)).\n\n### Optimization\n\n\nThe JAX ecosystem already has a library dedicated to optimization:\n[Optax](https://github.com/deepmind/optax), which we use in WAX-ML.\nWe could complete it by offering\nother first-order algorithms such as the Alternating Direction Multiplier Method\n[(ADMM)](https://stanford.edu/~boyd/admm.html).\nOne can find \"functional\" implementations of proximal algorithms in libraries such\nas\n[proxmin](https://github.com/pmelchior/proxmin)),\n[ProximalOperators](https://kul-forbes.github.io/ProximalOperators.jl/latest/),\nor [COSMO](https://github.com/oxfordcontrol/COSMO.jl),\nwhich could give good reference implementations to start the work.\n\n\nAnother type of work took place around automatic differentiation and optimization.\nIn [[5]](#references) the authors implement differentiable layers based on\nconvex optimization in the library\n[cvxpylayers](https://github.com/cvxgrp/cvxpylayers).\nThey have implemented a JAX API but, at the moment, they cannot use the\n`jit` compilation of JAX yet\n(see [this issue](https://github.com/cvxgrp/cvxpylayers/issues/103)).\nWe would be interested in helping to solve this issue.\n\nFurthermore, in the recent paper [[9]](#references), the authors propose a new\nefficient and modular implicit differentiation technique with a JAX-based implementation that should\nlead to a new open-source optimization library in the JAX ecosystem.\n\n### Other algorithms\n\nThe machine learning libraries [Scikit-learn](https://scikit-learn.org/stable/),\n[River](https://github.com/online-ml/river),\n[ml-numpy](https://github.com/ddbourgin/numpy-ml) implement many \"traditional\" machine\nlearning algorithms that should provide an excellent basis for linking or reimplementing\nin JAX.  WAX-ML could help to build a repository for JAX versions of these algorithms.\n\n### Other APIS\n\n\n\nAs it did for the Gym API, WAX-ML could add support for other high-level object-oriented APIs like\nKeras, Scikit-learn, River ...\n\n\n### Collaborations\n\nThe WAX-ML team is open to discussion and collaboration with contributors from any field who are\n interested in using WAX-ML for their problems on streaming data.  We are looking for use cases\n around data streaming in audio processing, natural language processing, astrophysics, biology,\n finance, engineering ...\n\n We believe that good software design, especially in the scientific domain, requires practical use\n cases and that the more diversified these use cases are, the more the developed functionalities\n will be guaranteed to be well implemented.\n\n By making this software public, we hope to find enthusiasts who aim to develop WAX-ML further!\n\n\n## ‚öí Installation ‚öí\n\nYou can install WAX-ML with the command:\n\n```bash\npip install wax-ml\n```\n\nTo install the latest version from source, you can use the command :\n\n```bash\npip install \"wax-ml[dev,complete] @ git+https://github.com/eserie/wax-ml.git\"\n```\n\n## Disclaimer\n\nWAX-ML is in its early stages of development and its features and API are very likely to\nevolve.\n\n\n## Development\n\nYou can contribute to WAX-ML by asking questions, proposing practical use cases, or by contributing to the code or the documentation.  You can have a look at our [Contributing\nGuidelines](https://github.com/eserie/wax-ml/CONTRIBUTING.md) and [Developer\nDocumentation](https://wax-ml.readthedocs.io/en/latest/developer.html) .\n\nWe maintain a \"WAX-ML Enhancement Proposals\" in\n[WEP.md](https://github.com/eserie/wax-ml/WEP.md) file.\n\n\n## References\n\n[1] [Google Princeton AI and Hazan Lab @ Princeton University](https://www.minregret.com/research/)\n\n[2] [FNet: Mixing Tokens with Fourier Transforms, James Lee-Thorp, Joshua Ainslie, Ilya Eckstein, Santiago Ontanon](https://arxiv.org/abs/2105.03824)\n\n[3] [Online Learning for Time Series Prediction, Oren Anava, Elad Hazan, Shie Mannor, Ohad Shamir](http://proceedings.mlr.press/v30/Anava13.html)\n\n[4] [The Nonstochastic Control Problem, Elad Hazan, Sham M. Kakade, Karan Singh](https://arxiv.org/abs/1911.12178)\n\n[5] [Differentiable Convex Optimization Layers, Akshay Agrawal, Brandon Amos, Shane Barratt, Stephen Boyd, Steven Diamond, Zico Kolter](https://arxiv.org/abs/1910.12430)\n\n[6] [Machine learning accelerated computational fluid dynamics, Dmitrii Kochkov, Jamie A. Smith, Ayya Alieva, Qing Wang, Michael P. Brenner, Stephan Hoyer](https://arxiv.org/abs/2102.01010)\n\n[7] [Large dimension forecasting models and random singular value spectra, Jean-Philippe Bouchaud, Laurent Laloux, M. Augusta Miceli, Marc Potters](https://arxiv.org/abs/physics/0512090)\n\n[8] [A novel dynamic PCA algorithm for dynamic data modeling and process monitoring, Yining Dongac and S. JoeQina](https://www.sciencedirect.com/science/article/pii/S095915241730094X)\n\n[9] [Efficient and Modular Implicit Differentiation, Mathieu Blondel, Quentin Berthet, Marco Cuturi, Roy Frostig, Stephan Hoyer, Felipe Llinares-L√≥pez, Fabian Pedregosa, Jean-Philippe Vert](https://arxiv.org/abs/2105.15183)\n\n## License\n\n```\nCopyright 2021 The WAX-ML Authors\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    https://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n```\n\nWAX-ML bundles portions of astropy, dask, deluca, haiku, jax, xarray.\n\nastropy, dask are available under a \"3-clause BSD\" license:\n- dask: `wax/gym/callbacks/callbacks.py`\n- astropy: `CONTRIBUTING.md`\n\ndeluca, haiku, jax and xarray are available under a \"Apache\" license:\n- deluca: `wax/gym/entity.py`\n- haiku: `docs/notebooks/05_reconstructing_the_light_curve_of_stars.*`\n- jax: `docs/conf.py`, `docs/developer.md`\n- xarray: `wax/datasets/generate_temperature_data.py`\n\nThe full text of these `licenses` is included in the licenses directory.\n\n\n## Citing WAX-ML\n\nIf you use WAX-ML, please cite our [paper](http://arxiv.org/abs/2106.06524) using the BibTex entry:\n\n```\n@misc{s√©ri√©2021waxml,\n      title={{WAX-ML}: {A} {P}ython library for machine learning and feedback loops on streaming data},\n      author={Emmanuel S√©ri√©},\n      year={2021},\n      eprint={2106.06524},\n      archivePrefix={arXiv},\n      primaryClass={cs.LG},\n      url = {http://arxiv.org/abs/2106.06524},\n}\n```\n\n\n## Reference documentation\n\nFor details about the WAX-ML API, see the\n[reference documentation](https://wax-ml.readthedocs.io/en/latest/).\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/eserie/wax-ml",
    "keywords": "time series,machine learning,optimization,optimal control,online learning,reinforcement learning",
    "license": "Apache",
    "maintainer": "",
    "maintainer_email": "",
    "name": "wax-ml",
    "package_url": "https://pypi.org/project/wax-ml/",
    "platform": null,
    "project_url": "https://pypi.org/project/wax-ml/",
    "project_urls": {
      "Homepage": "https://github.com/eserie/wax-ml"
    },
    "release_url": "https://pypi.org/project/wax-ml/0.6.3/",
    "requires_dist": [
      "numpy (<1.22,>=1.18)",
      "pandas",
      "seaborn",
      "xarray (>=0.18.0)",
      "scikit-learn",
      "tqdm",
      "jaxlib",
      "jax",
      "dm-haiku (>=0.0.4)",
      "optax ; extra == 'complete'",
      "plotnine ; extra == 'complete'",
      "pyarrow ; extra == 'complete'",
      "pooch ; extra == 'complete'",
      "graphviz ; extra == 'complete'",
      "numba ; extra == 'complete'",
      "mypy ; extra == 'complete'",
      "ipykernel ; extra == 'complete'",
      "ipywidgets ; extra == 'complete'",
      "nbconvert ; extra == 'complete'",
      "pytest ; extra == 'complete'",
      "pytest-cov ; extra == 'complete'",
      "pytest-xdist ; extra == 'complete'",
      "pytest-benchmark ; extra == 'complete'",
      "flaky ; extra == 'complete'",
      "coverage ; extra == 'complete'",
      "flake8 ; extra == 'complete'",
      "autopep8 ; extra == 'complete'",
      "autoflake ; extra == 'complete'",
      "black ; extra == 'complete'",
      "isort (>=5.3.0) ; extra == 'complete'",
      "jupytext (<=1.13.3) ; extra == 'complete'",
      "papermill ; extra == 'complete'",
      "line-profiler ; extra == 'complete'",
      "mypy ; extra == 'dev'",
      "ipykernel ; extra == 'dev'",
      "ipywidgets ; extra == 'dev'",
      "nbconvert ; extra == 'dev'",
      "pytest ; extra == 'dev'",
      "pytest-cov ; extra == 'dev'",
      "pytest-xdist ; extra == 'dev'",
      "pytest-benchmark ; extra == 'dev'",
      "flaky ; extra == 'dev'",
      "coverage ; extra == 'dev'",
      "flake8 ; extra == 'dev'",
      "autopep8 ; extra == 'dev'",
      "autoflake ; extra == 'dev'",
      "black ; extra == 'dev'",
      "isort (>=5.3.0) ; extra == 'dev'",
      "jupytext (<=1.13.3) ; extra == 'dev'",
      "papermill ; extra == 'dev'",
      "line-profiler ; extra == 'dev'",
      "optax ; extra == 'docs'",
      "plotnine ; extra == 'docs'",
      "pyarrow ; extra == 'docs'",
      "pooch ; extra == 'docs'",
      "graphviz ; extra == 'docs'",
      "numba ; extra == 'docs'",
      "mypy ; extra == 'docs'",
      "ipykernel ; extra == 'docs'",
      "ipywidgets ; extra == 'docs'",
      "nbconvert ; extra == 'docs'",
      "pytest ; extra == 'docs'",
      "pytest-cov ; extra == 'docs'",
      "pytest-xdist ; extra == 'docs'",
      "pytest-benchmark ; extra == 'docs'",
      "flaky ; extra == 'docs'",
      "coverage ; extra == 'docs'",
      "flake8 ; extra == 'docs'",
      "autopep8 ; extra == 'docs'",
      "autoflake ; extra == 'docs'",
      "black ; extra == 'docs'",
      "isort (>=5.3.0) ; extra == 'docs'",
      "jupytext (<=1.13.3) ; extra == 'docs'",
      "papermill ; extra == 'docs'",
      "line-profiler ; extra == 'docs'",
      "sphinx ; extra == 'docs'",
      "sphinxcontrib-napoleon ; extra == 'docs'",
      "sphinx-rtd-theme ; extra == 'docs'",
      "sphinx-autodoc-typehints ; extra == 'docs'",
      "sphinx-autosummary-accessors ; extra == 'docs'",
      "ipython ; extra == 'docs'",
      "jupyter-client ; extra == 'docs'",
      "jupyter-sphinx ; extra == 'docs'",
      "myst-nb ; extra == 'docs'",
      "nbsphinx ; extra == 'docs'",
      "scanpydoc ; extra == 'docs'",
      "matplotlib ; extra == 'docs'",
      "sklearn ; extra == 'docs'",
      "optax ; extra == 'optional'",
      "plotnine ; extra == 'optional'",
      "pyarrow ; extra == 'optional'",
      "pooch ; extra == 'optional'",
      "graphviz ; extra == 'optional'",
      "numba ; extra == 'optional'"
    ],
    "requires_python": "",
    "summary": "A Python library for machine-learning and feedback loops on streaming data",
    "version": "0.6.3",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 15819502,
  "releases": {
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d2d4ebff6b825efaaf03e58ca90181c7bbe42ad0627b3c2f68744c5ea24eb12f",
          "md5": "f3b705eb9e9a2e32f1a25d0d7b8a9f03",
          "sha256": "56da7186cc57babb9b1cb0505f2fcb2e57928f1480f009c52fbf4f1d92c4feee"
        },
        "downloads": -1,
        "filename": "wax_ml-0.0.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f3b705eb9e9a2e32f1a25d0d7b8a9f03",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 185577,
        "upload_time": "2021-06-08T23:16:31",
        "upload_time_iso_8601": "2021-06-08T23:16:31.347323Z",
        "url": "https://files.pythonhosted.org/packages/d2/d4/ebff6b825efaaf03e58ca90181c7bbe42ad0627b3c2f68744c5ea24eb12f/wax_ml-0.0.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "07543a21735950b1469b09b75b37ee5172d10bb062d514c137e5d3a2f0ff88f5",
          "md5": "168251e81ffc7b4b708976cb5da78bc3",
          "sha256": "2c6ded8df8fe481b79c3df619b85e9990918e30a668111fd485721cbfefc1a7f"
        },
        "downloads": -1,
        "filename": "wax-ml-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "168251e81ffc7b4b708976cb5da78bc3",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 131578,
        "upload_time": "2021-06-08T23:16:33",
        "upload_time_iso_8601": "2021-06-08T23:16:33.449962Z",
        "url": "https://files.pythonhosted.org/packages/07/54/3a21735950b1469b09b75b37ee5172d10bb062d514c137e5d3a2f0ff88f5/wax-ml-0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e91d100cae439fc863c47f6598d1f550d4bad3d5dd3b0a12da01c67b3a139f25",
          "md5": "5075a6d5caddef93bad08c4265e83b94",
          "sha256": "24346c8e403e6a1679fd87bc87f220dd3b2051a52353f5eba4a1a79c35361410"
        },
        "downloads": -1,
        "filename": "wax_ml-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "5075a6d5caddef93bad08c4265e83b94",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 186259,
        "upload_time": "2021-06-14T05:34:14",
        "upload_time_iso_8601": "2021-06-14T05:34:14.356829Z",
        "url": "https://files.pythonhosted.org/packages/e9/1d/100cae439fc863c47f6598d1f550d4bad3d5dd3b0a12da01c67b3a139f25/wax_ml-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7ee81b158e5fcc96f7a2f88ea7eadb098f4d0225242845a1c8788ea62ed491e7",
          "md5": "89aa4758e684094eb6c8c077f4367080",
          "sha256": "2d3b92e2b4c89d07c0fc68f97c576c8d6e19107db2642f94e1eb9cd0544cf4b0"
        },
        "downloads": -1,
        "filename": "wax-ml-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "89aa4758e684094eb6c8c077f4367080",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 133164,
        "upload_time": "2021-06-14T05:34:16",
        "upload_time_iso_8601": "2021-06-14T05:34:16.092015Z",
        "url": "https://files.pythonhosted.org/packages/7e/e8/1b158e5fcc96f7a2f88ea7eadb098f4d0225242845a1c8788ea62ed491e7/wax-ml-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "46cd26307d8cfd56fe0e3ba538af4dbb5a55e72a176973f4af03b6b9dfe1401c",
          "md5": "7a8abb05dd41aa29736531476a35b9a9",
          "sha256": "b8f04d9766f3403e665e1f93d485270da6669e11c18b891120a23cbbdafd71bf"
        },
        "downloads": -1,
        "filename": "wax_ml-0.2.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "7a8abb05dd41aa29736531476a35b9a9",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 215588,
        "upload_time": "2021-10-20T08:32:07",
        "upload_time_iso_8601": "2021-10-20T08:32:07.515321Z",
        "url": "https://files.pythonhosted.org/packages/46/cd/26307d8cfd56fe0e3ba538af4dbb5a55e72a176973f4af03b6b9dfe1401c/wax_ml-0.2.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2c7b06645e5c3f97bc27f3526cce011fe9cf5e3d9f3ebe703ae63adc7b163826",
          "md5": "3ee042220e1fd3a2d65eb13c34a378fb",
          "sha256": "c0d329654a8ee64891ffc45d6ebb0bab4d29f6b00fe1dda53b1364751842a697"
        },
        "downloads": -1,
        "filename": "wax-ml-0.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "3ee042220e1fd3a2d65eb13c34a378fb",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 149048,
        "upload_time": "2021-10-20T08:32:09",
        "upload_time_iso_8601": "2021-10-20T08:32:09.278870Z",
        "url": "https://files.pythonhosted.org/packages/2c/7b/06645e5c3f97bc27f3526cce011fe9cf5e3d9f3ebe703ae63adc7b163826/wax-ml-0.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a3345caa21a545a937a4628abb69efb4ebc101a3f86aaa74609d767949c47f94",
          "md5": "bd87dd8bcb6bee174a9d1cb05e668c4c",
          "sha256": "954ee5234fd961682fd6d48f871469b08b582e906efeaa1cb917cec842819431"
        },
        "downloads": -1,
        "filename": "wax_ml-0.3.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "bd87dd8bcb6bee174a9d1cb05e668c4c",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 217703,
        "upload_time": "2021-12-16T15:31:33",
        "upload_time_iso_8601": "2021-12-16T15:31:33.730693Z",
        "url": "https://files.pythonhosted.org/packages/a3/34/5caa21a545a937a4628abb69efb4ebc101a3f86aaa74609d767949c47f94/wax_ml-0.3.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e65fa34ec962ae271b6c159f0580269dc2669b46eb938582a4197e62108b5cf8",
          "md5": "0299d54d80da8b15a7fa43161d898c39",
          "sha256": "464a21640b76dbc3c10e4e62b1333d95587a59cd6b66bd0200e89df29939727c"
        },
        "downloads": -1,
        "filename": "wax-ml-0.3.0.tar.gz",
        "has_sig": false,
        "md5_digest": "0299d54d80da8b15a7fa43161d898c39",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 154030,
        "upload_time": "2021-12-16T15:31:35",
        "upload_time_iso_8601": "2021-12-16T15:31:35.294727Z",
        "url": "https://files.pythonhosted.org/packages/e6/5f/a34ec962ae271b6c159f0580269dc2669b46eb938582a4197e62108b5cf8/wax-ml-0.3.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a3e480c6c3a9b8d5703ab15485e531f9b82eb7ad01f6e6b7d873a7be02b4eaf3",
          "md5": "a68e9e91f922638522fe2ee04af0c420",
          "sha256": "1bb14ad121a7c18b9eda72d1eec2cb42594c8b73181caed9bac16d124a40422b"
        },
        "downloads": -1,
        "filename": "wax_ml-0.3.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "a68e9e91f922638522fe2ee04af0c420",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 217725,
        "upload_time": "2022-01-04T13:48:34",
        "upload_time_iso_8601": "2022-01-04T13:48:34.652087Z",
        "url": "https://files.pythonhosted.org/packages/a3/e4/80c6c3a9b8d5703ab15485e531f9b82eb7ad01f6e6b7d873a7be02b4eaf3/wax_ml-0.3.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6e5e264f103db6057d351187b3283b52714ec37c0c0c693b24caf3bbe645e0a9",
          "md5": "336b4b4477f1a314507f3f9e7df4fdf9",
          "sha256": "85edbd1c89c886a6ce5c948297d48c1c0b3e6522c1016a7125d72b0a414dce6b"
        },
        "downloads": -1,
        "filename": "wax-ml-0.3.1.tar.gz",
        "has_sig": false,
        "md5_digest": "336b4b4477f1a314507f3f9e7df4fdf9",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 154066,
        "upload_time": "2022-01-04T13:48:36",
        "upload_time_iso_8601": "2022-01-04T13:48:36.386436Z",
        "url": "https://files.pythonhosted.org/packages/6e/5e/264f103db6057d351187b3283b52714ec37c0c0c693b24caf3bbe645e0a9/wax-ml-0.3.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b4cba5cbb8a00e5440f8f5e1a45c0a7cdfece33a1274d6b008a81e992ba7a386",
          "md5": "209b2731965c3bfa71151fc3ecb4fff5",
          "sha256": "389f4c06bf9dbd65568ed6a1810cae1ba13d68ff435e5fe60e47e4d941ffe0d8"
        },
        "downloads": -1,
        "filename": "wax_ml-0.3.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "209b2731965c3bfa71151fc3ecb4fff5",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 217771,
        "upload_time": "2022-02-25T13:42:49",
        "upload_time_iso_8601": "2022-02-25T13:42:49.849319Z",
        "url": "https://files.pythonhosted.org/packages/b4/cb/a5cbb8a00e5440f8f5e1a45c0a7cdfece33a1274d6b008a81e992ba7a386/wax_ml-0.3.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6c55e2614f5ff4fdbca8b5ef8bfcb0fb890a1ebeca7ed00c6efa42193b4192d1",
          "md5": "4243f5d89dc9c56850661311672101f4",
          "sha256": "93d5e87d73b2516ca584d4a498ca01281eb5477c0d4e26af97be16fa928e5298"
        },
        "downloads": -1,
        "filename": "wax-ml-0.3.2.tar.gz",
        "has_sig": false,
        "md5_digest": "4243f5d89dc9c56850661311672101f4",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 154138,
        "upload_time": "2022-02-25T13:42:51",
        "upload_time_iso_8601": "2022-02-25T13:42:51.488612Z",
        "url": "https://files.pythonhosted.org/packages/6c/55/e2614f5ff4fdbca8b5ef8bfcb0fb890a1ebeca7ed00c6efa42193b4192d1/wax-ml-0.3.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cbfcf3c8e49b6e06c6e455dd2670d730375551cc76097880e387206cd32b46eb",
          "md5": "6d99bce52e62b5a51d29270b4d1ad6b5",
          "sha256": "14cb7af624795f2c687540e7fcb45c3d4dd43824344eede04a45e809342a9652"
        },
        "downloads": -1,
        "filename": "wax_ml-0.4.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "6d99bce52e62b5a51d29270b4d1ad6b5",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 226501,
        "upload_time": "2022-04-05T07:47:47",
        "upload_time_iso_8601": "2022-04-05T07:47:47.292366Z",
        "url": "https://files.pythonhosted.org/packages/cb/fc/f3c8e49b6e06c6e455dd2670d730375551cc76097880e387206cd32b46eb/wax_ml-0.4.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b5df6c30a915282d5d6498cc955d9140f2a1155409ae5f08ce5fcee87872ebbd",
          "md5": "45c2262824945030f127d2b3181795a8",
          "sha256": "b00c74f296f20a685d09d29151e7d6420e4fad4950c0fb533dd33aeb5169dc71"
        },
        "downloads": -1,
        "filename": "wax-ml-0.4.0.tar.gz",
        "has_sig": false,
        "md5_digest": "45c2262824945030f127d2b3181795a8",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 160196,
        "upload_time": "2022-04-05T07:47:49",
        "upload_time_iso_8601": "2022-04-05T07:47:49.631565Z",
        "url": "https://files.pythonhosted.org/packages/b5/df/6c30a915282d5d6498cc955d9140f2a1155409ae5f08ce5fcee87872ebbd/wax-ml-0.4.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.5.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "80f80b6eff825ed3e92936b83463fdda3adb4fc9602becb126f28a338ecd7085",
          "md5": "42415e0e62061b7360b5c56e738c3058",
          "sha256": "d108ba3e8674693324284f737338ddae707e9acfe85f4d5093f39c7619ca1a3b"
        },
        "downloads": -1,
        "filename": "wax_ml-0.5.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "42415e0e62061b7360b5c56e738c3058",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 230451,
        "upload_time": "2022-05-16T13:34:59",
        "upload_time_iso_8601": "2022-05-16T13:34:59.561639Z",
        "url": "https://files.pythonhosted.org/packages/80/f8/0b6eff825ed3e92936b83463fdda3adb4fc9602becb126f28a338ecd7085/wax_ml-0.5.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fc5e202a7933ea4a29a25eef9ac764e9f9a33fae375065913223d01016807d87",
          "md5": "9780fab32acc0aa502fc7b61d1e24254",
          "sha256": "097dccdb0ca93a2c44096e40c9942ab44267fd0977edc362ff5fead8b7c03db9"
        },
        "downloads": -1,
        "filename": "wax-ml-0.5.0.tar.gz",
        "has_sig": false,
        "md5_digest": "9780fab32acc0aa502fc7b61d1e24254",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 161844,
        "upload_time": "2022-05-16T13:35:01",
        "upload_time_iso_8601": "2022-05-16T13:35:01.813891Z",
        "url": "https://files.pythonhosted.org/packages/fc/5e/202a7933ea4a29a25eef9ac764e9f9a33fae375065913223d01016807d87/wax-ml-0.5.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.6.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "11f3fa783f8f168e45afb8238dfd86d85c1e6e41205bb0230dc829b09edcd97a",
          "md5": "f7af7dceddea4cda5fe46dc3c7677fab",
          "sha256": "ed7f050d709bff1613e6b5adb0b25161a562bcece427eab8bb30e23d3685c982"
        },
        "downloads": -1,
        "filename": "wax_ml-0.6.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f7af7dceddea4cda5fe46dc3c7677fab",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 182005,
        "upload_time": "2022-11-13T15:15:23",
        "upload_time_iso_8601": "2022-11-13T15:15:23.362317Z",
        "url": "https://files.pythonhosted.org/packages/11/f3/fa783f8f168e45afb8238dfd86d85c1e6e41205bb0230dc829b09edcd97a/wax_ml-0.6.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "98ab9dcd3cd3496648be7f99d3071df09ea6475222b625b92b12173a56302fee",
          "md5": "a6674ebf9c41d495783c422bc8b9dd17",
          "sha256": "198e397d60d5433b7d6d3f5df9c8fc4b922261a3a04f7587f4b28f3e2f89bfa9"
        },
        "downloads": -1,
        "filename": "wax-ml-0.6.0.tar.gz",
        "has_sig": false,
        "md5_digest": "a6674ebf9c41d495783c422bc8b9dd17",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 134046,
        "upload_time": "2022-11-13T15:15:25",
        "upload_time_iso_8601": "2022-11-13T15:15:25.554058Z",
        "url": "https://files.pythonhosted.org/packages/98/ab/9dcd3cd3496648be7f99d3071df09ea6475222b625b92b12173a56302fee/wax-ml-0.6.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.6.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "21cba9e5693a248f076698a23ac70a6a3a5f1d6a3f3549a94d7d216116802b2b",
          "md5": "2ff5ab43ac8a12211bb7261d0ad67eeb",
          "sha256": "cecfccd4272d0a3fdb3a86e75d67c8744b63843e40376754a9dffdb9651afff9"
        },
        "downloads": -1,
        "filename": "wax_ml-0.6.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "2ff5ab43ac8a12211bb7261d0ad67eeb",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 181040,
        "upload_time": "2022-11-14T09:35:00",
        "upload_time_iso_8601": "2022-11-14T09:35:00.413641Z",
        "url": "https://files.pythonhosted.org/packages/21/cb/a9e5693a248f076698a23ac70a6a3a5f1d6a3f3549a94d7d216116802b2b/wax_ml-0.6.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3a8792ea981f7b281c1437c8177a8b649ffb92c0678504afdad52929292a0924",
          "md5": "6b22fd670d302cb49bc397c0d2be0b36",
          "sha256": "439d8dce16cd27b6517b8c46b88bf518ae124a9a93743e2b2b8b402b43a4bcf3"
        },
        "downloads": -1,
        "filename": "wax-ml-0.6.1.tar.gz",
        "has_sig": false,
        "md5_digest": "6b22fd670d302cb49bc397c0d2be0b36",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 133142,
        "upload_time": "2022-11-14T09:35:02",
        "upload_time_iso_8601": "2022-11-14T09:35:02.832237Z",
        "url": "https://files.pythonhosted.org/packages/3a/87/92ea981f7b281c1437c8177a8b649ffb92c0678504afdad52929292a0924/wax-ml-0.6.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.6.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fa3c1d84d6df53c3fcde96ed0000c3b8ec87e7a946ba7171a56c8892bdc5b95f",
          "md5": "150a983d5c1984ebc7ac03ef007eb3d4",
          "sha256": "1e5394ee67104cd4966d102ff071d65b151b790fadb56a7380d95fe7e974cd30"
        },
        "downloads": -1,
        "filename": "wax_ml-0.6.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "150a983d5c1984ebc7ac03ef007eb3d4",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 181040,
        "upload_time": "2022-11-14T12:29:09",
        "upload_time_iso_8601": "2022-11-14T12:29:09.244284Z",
        "url": "https://files.pythonhosted.org/packages/fa/3c/1d84d6df53c3fcde96ed0000c3b8ec87e7a946ba7171a56c8892bdc5b95f/wax_ml-0.6.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4e194ef537da5467faf5989315dbe699828b9165e99e2251d1abe9958cb4a995",
          "md5": "8619065be7412f57ad196bf99cdd9acc",
          "sha256": "02c8f8083375508afbf0d28d4d3cc8e6aa0adac34ab73bf0ed7f71db414743ad"
        },
        "downloads": -1,
        "filename": "wax-ml-0.6.2.tar.gz",
        "has_sig": false,
        "md5_digest": "8619065be7412f57ad196bf99cdd9acc",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 133125,
        "upload_time": "2022-11-14T12:29:11",
        "upload_time_iso_8601": "2022-11-14T12:29:11.324309Z",
        "url": "https://files.pythonhosted.org/packages/4e/19/4ef537da5467faf5989315dbe699828b9165e99e2251d1abe9958cb4a995/wax-ml-0.6.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.6.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1acc27d78cae3a7070ed44ba73707508eff8beb0cc028a556672ee9e47fda991",
          "md5": "69de8a0a4b600ab53493ee6779652880",
          "sha256": "958d1849e944b15fd9f44d7439c0d8accd3fe668790fba03a92f9c1d71e3dfbe"
        },
        "downloads": -1,
        "filename": "wax_ml-0.6.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "69de8a0a4b600ab53493ee6779652880",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 181226,
        "upload_time": "2022-11-18T21:26:12",
        "upload_time_iso_8601": "2022-11-18T21:26:12.135607Z",
        "url": "https://files.pythonhosted.org/packages/1a/cc/27d78cae3a7070ed44ba73707508eff8beb0cc028a556672ee9e47fda991/wax_ml-0.6.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ccfa0ae88d0a6b46d9f8cb706f2b95aa0407ea124a01195ff78d3b37c94a6782",
          "md5": "3758050b1f69468cd710f91d45affb25",
          "sha256": "da08bd5fd662adc446451883d44fa6330d86c1edf246f16a989e8ac7795487c7"
        },
        "downloads": -1,
        "filename": "wax-ml-0.6.3.tar.gz",
        "has_sig": false,
        "md5_digest": "3758050b1f69468cd710f91d45affb25",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 133345,
        "upload_time": "2022-11-18T21:26:14",
        "upload_time_iso_8601": "2022-11-18T21:26:14.070102Z",
        "url": "https://files.pythonhosted.org/packages/cc/fa/0ae88d0a6b46d9f8cb706f2b95aa0407ea124a01195ff78d3b37c94a6782/wax-ml-0.6.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "1acc27d78cae3a7070ed44ba73707508eff8beb0cc028a556672ee9e47fda991",
        "md5": "69de8a0a4b600ab53493ee6779652880",
        "sha256": "958d1849e944b15fd9f44d7439c0d8accd3fe668790fba03a92f9c1d71e3dfbe"
      },
      "downloads": -1,
      "filename": "wax_ml-0.6.3-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "69de8a0a4b600ab53493ee6779652880",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 181226,
      "upload_time": "2022-11-18T21:26:12",
      "upload_time_iso_8601": "2022-11-18T21:26:12.135607Z",
      "url": "https://files.pythonhosted.org/packages/1a/cc/27d78cae3a7070ed44ba73707508eff8beb0cc028a556672ee9e47fda991/wax_ml-0.6.3-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "ccfa0ae88d0a6b46d9f8cb706f2b95aa0407ea124a01195ff78d3b37c94a6782",
        "md5": "3758050b1f69468cd710f91d45affb25",
        "sha256": "da08bd5fd662adc446451883d44fa6330d86c1edf246f16a989e8ac7795487c7"
      },
      "downloads": -1,
      "filename": "wax-ml-0.6.3.tar.gz",
      "has_sig": false,
      "md5_digest": "3758050b1f69468cd710f91d45affb25",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 133345,
      "upload_time": "2022-11-18T21:26:14",
      "upload_time_iso_8601": "2022-11-18T21:26:14.070102Z",
      "url": "https://files.pythonhosted.org/packages/cc/fa/0ae88d0a6b46d9f8cb706f2b95aa0407ea124a01195ff78d3b37c94a6782/wax-ml-0.6.3.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}