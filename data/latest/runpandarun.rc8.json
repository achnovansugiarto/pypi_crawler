{
  "info": {
    "author": "Simon Wörpel",
    "author_email": "simon.woerpel@medienrevolte.de",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Developers",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3",
      "Topic :: Utilities"
    ],
    "description": "Run Panda Run\n=============\n\n\n\n\nA simple interface written in python for reproducible & persistent data\nwarehousing around small data analysis / processing projects with\n```pandas`` <https://pandas.pydata.org/>`__.\n\nCurrently supports ``csv`` and ``json`` resources.\n\nUseful to build an automated workflow like this:\n\n**1. Download** fetch datasets from different remote or local sources,\nstore them somewhere (with respect to versioning / incremental updates),\ndo some general cleaning, `processing <#operations>`__ and get a nice\n```pandas.DataFrame`` <https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html>`__\nfor each dataset and\n\n**2. Wrangle** your data somehow, store and load\n`revisions <#revisions>`__ to share *source of truth* between notebooks\nor scripts.\n\n`3. Publish <#publish>`__ some of the wrangled data somewhere where\nother services (Google Spreadsheet, Datawrapper, even another\n``Datastore``) can work on further\n\nIt includes a simple command-line interface, e.g. for automated\nprocessing via cronjobs.\n\nQuickstart\n----------\n\n`Install via pip <#installation>`__\n\nSpecify your datasets via ``yaml`` syntax:\n\n.. code:: yaml\n\n   datasets:\n     my_dataset:\n       csv_url: http://example.org/data.csv  # url to fetch csv file from\n       columns:                              # only use specified columns\n         - id: identifier                    # rename original column `identifier` to `id`\n         - name\n         - date\n       dt_index: date                        # set date-based index\n     another_dataset:\n       json_url: !ENV ${SECRET_URL}          # see below for env vars\n       ...\n\nstore this as a file, and set the env var ``CONFIG`` to the path:\n\n::\n\n       export CONFIG=./path/to/config.yml\n\n.. code:: python\n\n   from runpandarun.datasets import my_dataset, another_dataset\n\n   df = my_dataset.get_df()\n   df['name'].plot.hist()\n\n   another_dataset.daily.mean().plot()  # some handy shorthands for pandas\n\nHandle data persistence and state of datasets:\n\n.. code:: python\n\n   from runpandarun.datasets import my_dataset\n\n   # update data from remote source:\n   my_dataset = my_dataset.update()\n\n   # update complete store:\n   from runpandarun import Datastore\n\n   store = Datastore()\n   store.update()\n\n   # save a revision\n   df = my_dataset.get_df()\n   df = wrangle(df)\n   my_dataset.save(df, 'wrangled')\n\n   # get this revision (in another script)\n   df = my_dataset['wrangled']\n\n   # publish\n   df = my_dataset.get_df()\n   clean(df)\n   my_dataset.publish(df, name='cleaned', overwrite=True)\n\nUpdate your datastore from the command-line (for use in cronjobs e.g.)\n\nSpecify config path either via ``--config`` or env var ``CONFIG``\n\nUpdate all:\n\n::\n\n   runpandarun update --config /path/to/config.yml\n\nOnly specific datasets and with env var:\n\n::\n\n   CONFIG=/path/to/config.yml runpandarun update my_dataset my_other_dataset ...\n\nInstallation\n------------\n\nRequires python3. Virtualenv use recommended.\n\nAdditional dependencies (``pandas`` et. al.) will be installed\nautomatically:\n\n::\n\n   pip install runpandarun\n\nAfter this, you should be able to execute in your terminal:\n\n::\n\n   runpandarun -h\n\nYou should as well be able to import it in your python scripts:\n\n.. code:: python\n\n   from runpandarun import Datastore\n\n   # start the party...\n\nConfig\n------\n\n**Easy**\n\nSet an environment variable ``CONFIG`` pointing to your yaml file.\n\n``runpandarun`` will find your config and you are all set (see\n`quickstart <#quickstart>`__)\n\n**Manually**\n\nOf course you can initialize the config manually:\n\n-  from a file\n-  as yaml string\n-  as a python dict\n\n.. code:: python\n\n   from runpandarun import Datastore\n\n   store = Datastore('./path/to/config.yml')\n   store = Datastore(config_dict)\n   store = Datastore(\"\"\"\n       datasets:\n         my_dataset:\n         ...\n   \"\"\")\n\nTo quickly test your config for a dataset named ``my_dataset``, you can\nuse the command-line (this will print the generated csv to stdout):\n\n::\n\n   CONFIG=config.yml runpandarun print my_dataset\n\nexamples\n~~~~~~~~\n\nSee the yaml files in `./example/ <./example/>`__\n\ntop-level options\n~~~~~~~~~~~~~~~~~\n\n.. code:: yaml\n\n   storage:\n     data_root: ./path/                    # absolute or relative path where to store the files\n   publish:\n     handlers:\n       filesystem:\n         public_root: !ENV ${PUBLIC_ROOT}  # where to store published data, e.g. a path to a webserver root via env var\n         enabled: true\n       gcloud:\n         bucket: !ENV ${GOOGLE_BUCKET}     # or in a google cloud storage bucket...\n         enabled: !ENV ${GOOGLE_PUBLISH}   # enable or disable a publish handler based on environment\n   combine:\n     - dataset1                            # keys of defined datasets for quick merging\n     - dataset2\n   datasets:                               # definition for datasets\n     dataset1:\n       csv_url: ...\n\ndataset options\n~~~~~~~~~~~~~~~\n\n**Source link**\n\n-  *required*\n-  any of:\n\n.. code:: yaml\n\n       csv_url:            # url to remote csv, the response must be the direct csv content\n                           # this can also be a Google Spreadsheet \"published to the web\" in csv format\n       csv_local:          # absolute or relative path to a file on disk\n       json_url:           # url to remote json, the response should be text or application/json\n       json_local:         # absolute or relative path to a file on disk\n\n**Request params**\n\n-  *optional*\n-  for each source url, you can pass ``params`` and ``headers`` that\n   will feed into\n   ```requests.get()`` <https://requests.readthedocs.io/en/master/user/quickstart/#make-a-request>`__\n\n.. code:: yaml\n\n       csv_url: https://example.org\n       request:\n         params:\n           format: csv\n         header:\n           \"api-key\": 123abc\n\n**Incremental**\n\n-  *optional*\n-  instead of versioning the downloaded datasets and only use the latest\n   one, this flag allows to combine all the downloaded data over time to\n   one dataset. Use case example: A publisher releases updated data each\n   day under the same url\n\n.. code:: yaml\n\n       incremental: true\n\n**Columns**\n\n-  *optional*\n-  specify list of subset columns to use\n\n.. code:: yaml\n\n       columns:\n         - column1\n         - column2: origColumnName     # optional renaming mapping (rename `origColumnName` to `column2`)\n\n**Index**\n\n-  *optional*\n-  specify which column (after renaming was applied) should be the index\n-  default: ``id``\n\n.. code:: yaml\n\n       index: person_id                # set column `person_id` as index\n\n.. code:: yaml\n\n       dt_index: event_date            # specify a date/time-based index instead\n\n.. code:: yaml\n\n       dt_index:\n         column: event_date\n         format: \"%d.%m.%Y\"\n\nOperations\n~~~~~~~~~~\n\n-  *optional*\n\nApply `any valid operation that is a function attribute of\n``pandas.DataFrame`` <https://pandas.pydata.org/pandas-docs/stable/reference/frame.html>`__\n(like ``drop_duplicates``, ``sort_values``, ``fillna`` …) in the given\norder with optional function arguments that will be passed to the call.\n\nDefault operations: ``['drop_duplicates', 'sort_index']``\n\nDisable:\n\n.. code:: yaml\n\n       ...\n       ops: false\n\nHere are examples:\n\n**Sort**\n\n```pandas.DataFrame.sort_values()`` <https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_values.html>`__\n\n.. code:: yaml\n\n       ...\n       ops:\n         sort_values:                    # pass parameters for pandas function `sort_values`\n           by:\n             - column1\n             - column2\n           ascending: false\n\n**De-duplicate**\n\n```pandas.DataFrame.drop_duplicates()`` <https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop_duplicates.html>`__\n- when using a subset, use in conjunction with ``sort_values`` to make\nsure to keep the right records\n\n.. code:: yaml\n\n       ...\n       ops:\n         drop_duplicates:              # pass parameters for pandas function `drop_duplicates`\n           subset:\n             - column1\n             - column2\n           keep: last\n\ncombining\n~~~~~~~~~\n\nA quick top-level option for easy combining datasets from different\nsources.\n\nThis happens via\n```pandas.concat`` <https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html>`__\nand decides if it should concat *long* or *wide* (aka\n``pandas.concat(..., axis=1)``)\n\n-  **long**: if index name and column names accross the specified\n   datasets in config ``combine`` are the same\n-  **wide**: if index is the same accross the specified datasets in\n   config ``combine``\n\nTODO: *more to come… (aka merging)*\n\nenv vars\n~~~~~~~~\n\nFor api keys or other secrets, you can put environment variables into\nthe config:\n\n.. code:: yaml\n\n   storage:\n     data_root: !ENV '${DATA_ROOT}/data/'\n   datasets:\n     google_places:\n       json_url: https://maps.googleapis.com/maps/api/place/findplacefromtext/json\n       request:\n         params:\n           key: !ENV ${GOOGLE_APY_KEY}\n       ...\n\nUsage in your scripts\n---------------------\n\nOnce set up, you can start moving the data warehousing out of your\nanalysis scripts and focus on the analysis itself…\n\n.. code:: python\n\n   from runpandarun import Datastore\n\n   store = Datastore(config)\n\n   # all your datasets become direct attributes of the store:\n   ds = store.my_dataset\n\n   # all your datasets have their computed (according to your config) `pandas.DataFrame` as attribute:\n   df = store.my_dataset.get_df()\n\n   # get combined df (if specified in the config)\n   df = store.combined\n\nresampling\n~~~~~~~~~~\n\nsome time-based shorthands (if you have a ``dt_index: true`` in your\nconfig) based on\n```pandas.DataFrame.resample`` <https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.resample.html>`__\n\nThe resulting ``pandas.DataFrame`` will only have columns with numeric\ndata in it.\n\n.. code:: python\n\n   dataset = store.my_time_based_dataset\n\n   s = dataset.daily.mean()\n   s.plot()\n\n   s = dataset.yearly.count().cumsum()\n   s.plot()\n\nAvailable time aggregations: - minutely - hourly - daily - weekly -\nmonthly - yearly\n\nAvailable aggregation methods: - sum - mean - max - min - count\n\nFor more advanced resampling, just work on your dataframes directly…\n\nPublish\n-------\n\nAfter the workflow is done, you can publish some (or all) results.\n\n.. code:: python\n\n   dataset = store.my_dataset\n   df1 = do_something_with(dataset.get_df())\n   dataset.publish(df1, overwrite=True, include_source=True)\n   df2 = do_something_else_with(dataset.get_df())\n   dataset.publish(df2, name='filtered_for_europe', format='json')\n\nFor behaviour reasons the ``overwrite``-flag must be set explicitly\n(during function execution or in config, see below), otherwise it will\nraise if a public file already exists. To avoid overwriting, set a\ndifferent name.\n\nThe ``publish()`` parameters can be set in the config as well, either\nglobally or per dataset, specified for each handler (currently\n``filesystem`` or ``gcloud``). Dataset-specific settings overwrite\nglobal ones for the storage handler.\n\n.. code:: yaml\n\n   publish:\n     overwrite: true               # global option for all handlers: always overwrite existing files\n     with_timestamp: true          # include current timestamp in filename\n     handlers:\n       filesystem:\n         public_root: /path/to/a/dir/a/webserver/can/serve/\n         include_source: true\n       gcloud:\n         bucket: my-bucket-name\n         include_source: false\n   ...\n   datasets:\n     my_dataset:\n       ...\n       publish:\n         gcloud:\n           bucket: another-bucket\n           include_source: true\n           format: json\n           name: something\n\n**TODO**: currently only storing to a filesystem or google cloud storage\nimplemented.\n\nBut features could be: - goolge spreadsheet - ftp - s3 - …\n\nRevisions\n---------\n\nAt any time between reading data in and publishing you can store and get\nrevisions of a dataset. This is usually a ``pd.DataFrame`` in an\nintermediate state, e.g. after date enriching but before analysis.\n\nThis feature can be used in an automated processing workflow consisting\nof multiple notebooks to share DataFrames between each other. The\nunderlying storage mechanism is\n`pickle <https://docs.python.org/3/library/pickle.html>`__ to make sure\na DataFrame revision behaves as expected. This comes with the downside\nthat pickle’s are not safe to share between different systems, but to\nre-create them in another environment, that’s what a reproducible\nworkflow is for, right?\n\n**store a revision**\n\n.. code:: python\n\n   ds = store.my_dataset\n   df = ds.get_df()\n   ds.revisions.save('tansformed', df.T)\n\n**load a revision**\n\n.. code:: python\n\n   ds = store.my_dataset\n   df = ds['transformed']\n\n**show available revisions**\n\n.. code:: python\n\n   ds = store.my_dataset\n   ds.revisions.show()\n\n**iterate through revisions**\n\n.. code:: python\n\n   ds = store.my_dataset\n   for df in ds.revisions:\n     do_something(df)\n\n*Pro tip* you can go crazy and use this mechanism to store & retrieve\n*any* object that is serializable via\n`pickle <https://docs.python.org/3/library/pickle.html>`__\n\ncli\n---\n\n.. code:: bash\n\n   usage: runpandarun [-h] [--loglevel LOGLEVEL] {update,print,publish} ...\n\n   positional arguments:\n     {update,print,publish}\n                           commands help: run `runpandarun <command> -h`\n\n   optional arguments:\n     -h, --help            show this help message and exit\n     --loglevel LOGLEVEL\n\ndevelopement\n------------\n\nInstall testing requirements:\n\n::\n\n   make install\n\nTest:\n\n::\n\n   make test\n\n",
    "description_content_type": "",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/simonwoerpel/runpandarun",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "runpandarun",
    "package_url": "https://pypi.org/project/runpandarun/",
    "platform": "",
    "project_url": "https://pypi.org/project/runpandarun/",
    "project_urls": {
      "Homepage": "https://github.com/simonwoerpel/runpandarun"
    },
    "release_url": "https://pypi.org/project/runpandarun/0.1.4/",
    "requires_dist": [
      "banal",
      "pyyaml",
      "pandas",
      "requests",
      "awesome-slugify",
      "python-dateutil",
      "google-cloud-storage"
    ],
    "requires_python": "",
    "summary": "A simple toolkit for managing data from different sources.",
    "version": "0.1.4",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 7126330,
  "releases": {
    "0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4c01a99647d7daba8533b4f5bda816b0510b3727ba4494c60b8603ea55709ef3",
          "md5": "d253909cea237e20d3c35864cdfe0bbf",
          "sha256": "4b0ea22dcabb6bd67255d8435aa7905149ef2d4e04f6624133438c21f70849c0"
        },
        "downloads": -1,
        "filename": "runpandarun-0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d253909cea237e20d3c35864cdfe0bbf",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 23537,
        "upload_time": "2020-04-08T13:08:56",
        "upload_time_iso_8601": "2020-04-08T13:08:56.898684Z",
        "url": "https://files.pythonhosted.org/packages/4c/01/a99647d7daba8533b4f5bda816b0510b3727ba4494c60b8603ea55709ef3/runpandarun-0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "60ee9febb43e43f6f1bd1be9ec5974770d450d650b725e0f5bcb8206f3b8a253",
          "md5": "0fa20a462949c92c0ef05a75de59a2e1",
          "sha256": "306be875987cc6aea3b2966f9d5e7e0ed289bd35fb7bafda1dfe7527550e2ea7"
        },
        "downloads": -1,
        "filename": "runpandarun-0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "0fa20a462949c92c0ef05a75de59a2e1",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 24007,
        "upload_time": "2020-04-08T13:08:58",
        "upload_time_iso_8601": "2020-04-08T13:08:58.090645Z",
        "url": "https://files.pythonhosted.org/packages/60/ee/9febb43e43f6f1bd1be9ec5974770d450d650b725e0f5bcb8206f3b8a253/runpandarun-0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "dbe12195795eae23f6936ee9b41fca883ce71af32fd729a9e0aa11668c1e1a7a",
          "md5": "53070febbd9aaf4d87b9dc41c6e43e24",
          "sha256": "d8dd4e3095f4f9b46284f5919431c77b97efef2ffed3be558dea3ea000ca23c6"
        },
        "downloads": -1,
        "filename": "runpandarun-0.1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "53070febbd9aaf4d87b9dc41c6e43e24",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 23568,
        "upload_time": "2020-04-08T15:11:15",
        "upload_time_iso_8601": "2020-04-08T15:11:15.674686Z",
        "url": "https://files.pythonhosted.org/packages/db/e1/2195795eae23f6936ee9b41fca883ce71af32fd729a9e0aa11668c1e1a7a/runpandarun-0.1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8b5f2cf13bdd8e346d44bf482a3bef482109a57f52ad102a3602e2f3cf30a018",
          "md5": "e884009af21259a5a18ad3f2aeb3c4ed",
          "sha256": "6eaf74944b40d0afa72416314647056348a843e58a478fff47968aecee179ef7"
        },
        "downloads": -1,
        "filename": "runpandarun-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "e884009af21259a5a18ad3f2aeb3c4ed",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 24030,
        "upload_time": "2020-04-08T15:11:16",
        "upload_time_iso_8601": "2020-04-08T15:11:16.968351Z",
        "url": "https://files.pythonhosted.org/packages/8b/5f/2cf13bdd8e346d44bf482a3bef482109a57f52ad102a3602e2f3cf30a018/runpandarun-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bd436e78e510e8f7eeb745b39a467c96bc3290d88c905dd22b7a5c2814fa8e77",
          "md5": "324e2ed7faea912680030d1ec5bac1e3",
          "sha256": "ae3c3020491cb28a7ee47199349ce96c3ddc155859c100bca2e262a0fdf96003"
        },
        "downloads": -1,
        "filename": "runpandarun-0.1.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "324e2ed7faea912680030d1ec5bac1e3",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 24778,
        "upload_time": "2020-04-17T15:26:35",
        "upload_time_iso_8601": "2020-04-17T15:26:35.727120Z",
        "url": "https://files.pythonhosted.org/packages/bd/43/6e78e510e8f7eeb745b39a467c96bc3290d88c905dd22b7a5c2814fa8e77/runpandarun-0.1.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d48a68d78c9628ed19ae0e2c099d1d22759874b15f252ae36cc17451d7563cfb",
          "md5": "d72ac9613fbc3de27628d875b5732d30",
          "sha256": "4d7089f83db8c103408702a07bcdcc59f4c30767e4aaeb3384edde655ffe633e"
        },
        "downloads": -1,
        "filename": "runpandarun-0.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "d72ac9613fbc3de27628d875b5732d30",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 24898,
        "upload_time": "2020-04-17T15:26:37",
        "upload_time_iso_8601": "2020-04-17T15:26:37.333635Z",
        "url": "https://files.pythonhosted.org/packages/d4/8a/68d78c9628ed19ae0e2c099d1d22759874b15f252ae36cc17451d7563cfb/runpandarun-0.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c4e342fe1403d59c1810d51cac4595c5fc6208650700dae8599c6ba3f8f8c2da",
          "md5": "f8bf7fad96d91ede600bddbbdb5ed833",
          "sha256": "1e2b40dd18d8b1f49e70291024d72e7535b5ae7638f7c047d0ec31cf695f8cb3"
        },
        "downloads": -1,
        "filename": "runpandarun-0.1.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f8bf7fad96d91ede600bddbbdb5ed833",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 25166,
        "upload_time": "2020-04-29T05:30:08",
        "upload_time_iso_8601": "2020-04-29T05:30:08.551853Z",
        "url": "https://files.pythonhosted.org/packages/c4/e3/42fe1403d59c1810d51cac4595c5fc6208650700dae8599c6ba3f8f8c2da/runpandarun-0.1.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "feed7de93b327b064fffac2ca9d6f7ec153018521e587399ca16844c1ea251c3",
          "md5": "fab9ea73b82ed24c14a4cadb16eaf852",
          "sha256": "b1f05eb81ca4e9d085862f7d5b950389b3267c0838f3933cf065e6d315216584"
        },
        "downloads": -1,
        "filename": "runpandarun-0.1.3.tar.gz",
        "has_sig": false,
        "md5_digest": "fab9ea73b82ed24c14a4cadb16eaf852",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 25222,
        "upload_time": "2020-04-29T05:30:09",
        "upload_time_iso_8601": "2020-04-29T05:30:09.771542Z",
        "url": "https://files.pythonhosted.org/packages/fe/ed/7de93b327b064fffac2ca9d6f7ec153018521e587399ca16844c1ea251c3/runpandarun-0.1.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "07b440983b1b3a401eeee6fcb727426685cc59bf1ff13dd7c14302dfacfcfe21",
          "md5": "b13595e1ac9453d0a1effd7ca4db0023",
          "sha256": "4ff3fb11a7ee63b9a5081d656d295c125c2ed5e3432c889b26fd1a8d0c99f388"
        },
        "downloads": -1,
        "filename": "runpandarun-0.1.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "b13595e1ac9453d0a1effd7ca4db0023",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 25283,
        "upload_time": "2020-04-29T06:14:18",
        "upload_time_iso_8601": "2020-04-29T06:14:18.450510Z",
        "url": "https://files.pythonhosted.org/packages/07/b4/40983b1b3a401eeee6fcb727426685cc59bf1ff13dd7c14302dfacfcfe21/runpandarun-0.1.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b1ca7c1b2294c5ee56c3744ebed1c6933ed88805b1ca5ae46cb5f685a44bd454",
          "md5": "70178d62e5bf1668b34b5c4e65fb47fc",
          "sha256": "e52f82289e481e0caf1db24299178d7ef97817e6af7c67184d22df2f6c332225"
        },
        "downloads": -1,
        "filename": "runpandarun-0.1.4.tar.gz",
        "has_sig": false,
        "md5_digest": "70178d62e5bf1668b34b5c4e65fb47fc",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 25314,
        "upload_time": "2020-04-29T06:14:19",
        "upload_time_iso_8601": "2020-04-29T06:14:19.843419Z",
        "url": "https://files.pythonhosted.org/packages/b1/ca/7c1b2294c5ee56c3744ebed1c6933ed88805b1ca5ae46cb5f685a44bd454/runpandarun-0.1.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1rc1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "06de6b7dc5af3279fd0a2c229cefab98cfea12bec01dba7e937c5980ba306743",
          "md5": "ed48a8d3b3f5a26cb5d6ce54826a9132",
          "sha256": "d2a51461520fc6c1c380557a3825fe8590a00e7512b4f9f29b4a17538483b0d6"
        },
        "downloads": -1,
        "filename": "runpandarun-0.1rc1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ed48a8d3b3f5a26cb5d6ce54826a9132",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 18726,
        "upload_time": "2020-04-08T11:48:30",
        "upload_time_iso_8601": "2020-04-08T11:48:30.822924Z",
        "url": "https://files.pythonhosted.org/packages/06/de/6b7dc5af3279fd0a2c229cefab98cfea12bec01dba7e937c5980ba306743/runpandarun-0.1rc1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "097e2eceb4a68563e58b5525b51d73e855e240691e55eaba2b83558039c139dd",
          "md5": "ab871a9fc189cbfa88e60de685148c76",
          "sha256": "a4839453756ee0ca3999d936b800e1d1281e9c4ffc9f79b448ee1a382db30bc2"
        },
        "downloads": -1,
        "filename": "runpandarun-0.1rc1.tar.gz",
        "has_sig": false,
        "md5_digest": "ab871a9fc189cbfa88e60de685148c76",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 20857,
        "upload_time": "2020-04-08T11:48:32",
        "upload_time_iso_8601": "2020-04-08T11:48:32.892223Z",
        "url": "https://files.pythonhosted.org/packages/09/7e/2eceb4a68563e58b5525b51d73e855e240691e55eaba2b83558039c139dd/runpandarun-0.1rc1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1rc3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7fd127e38c25675f29a465a7bed1aed196b02627a4f18fc444067f0420fb6b90",
          "md5": "0e87aad4f18cf7cf670385a1be303273",
          "sha256": "25631f7121b0dd5d35b649e687d7ddd3c763c48d88665bedd2593c084184bdc7"
        },
        "downloads": -1,
        "filename": "runpandarun-0.1rc3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0e87aad4f18cf7cf670385a1be303273",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 18727,
        "upload_time": "2020-04-08T12:24:58",
        "upload_time_iso_8601": "2020-04-08T12:24:58.728844Z",
        "url": "https://files.pythonhosted.org/packages/7f/d1/27e38c25675f29a465a7bed1aed196b02627a4f18fc444067f0420fb6b90/runpandarun-0.1rc3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a8fd5efd4e39bd6d2780e2140a6231d08dce7048fc9c49c8cdab1e793485522f",
          "md5": "690e2ba1e0abd984b24f2c7447d07e94",
          "sha256": "c85da8abe3dfb5cf81ec7cbea665b0db7d7a187d81304ad9a29f628afae3c80c"
        },
        "downloads": -1,
        "filename": "runpandarun-0.1rc3.tar.gz",
        "has_sig": false,
        "md5_digest": "690e2ba1e0abd984b24f2c7447d07e94",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 20851,
        "upload_time": "2020-04-08T12:24:59",
        "upload_time_iso_8601": "2020-04-08T12:24:59.912869Z",
        "url": "https://files.pythonhosted.org/packages/a8/fd/5efd4e39bd6d2780e2140a6231d08dce7048fc9c49c8cdab1e793485522f/runpandarun-0.1rc3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1rc4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b55a509399713d327d6ff4a36786895af1c36bd480734e3eba7fb4170abae2c9",
          "md5": "ed44d759908919e58bb534de1d516500",
          "sha256": "9d56ad59dcd7914070e851f7bdb4c3d4586017f446bb9852bc9eeb4bc0f071c4"
        },
        "downloads": -1,
        "filename": "runpandarun-0.1rc4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ed44d759908919e58bb534de1d516500",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 23583,
        "upload_time": "2020-04-08T13:04:09",
        "upload_time_iso_8601": "2020-04-08T13:04:09.809835Z",
        "url": "https://files.pythonhosted.org/packages/b5/5a/509399713d327d6ff4a36786895af1c36bd480734e3eba7fb4170abae2c9/runpandarun-0.1rc4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f59e4199d1cca22c9774a4aff40b3921e64e4da7977e3a7ed411afdd62f83232",
          "md5": "a84d6f97cd162242ea466418845051d8",
          "sha256": "7cd783c1219b293be221a4217c0cc6011268f3b2e9c2753edbfa87eafb082af4"
        },
        "downloads": -1,
        "filename": "runpandarun-0.1rc4.tar.gz",
        "has_sig": false,
        "md5_digest": "a84d6f97cd162242ea466418845051d8",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 24034,
        "upload_time": "2020-04-08T13:04:11",
        "upload_time_iso_8601": "2020-04-08T13:04:11.550023Z",
        "url": "https://files.pythonhosted.org/packages/f5/9e/4199d1cca22c9774a4aff40b3921e64e4da7977e3a7ed411afdd62f83232/runpandarun-0.1rc4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "07b440983b1b3a401eeee6fcb727426685cc59bf1ff13dd7c14302dfacfcfe21",
        "md5": "b13595e1ac9453d0a1effd7ca4db0023",
        "sha256": "4ff3fb11a7ee63b9a5081d656d295c125c2ed5e3432c889b26fd1a8d0c99f388"
      },
      "downloads": -1,
      "filename": "runpandarun-0.1.4-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "b13595e1ac9453d0a1effd7ca4db0023",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 25283,
      "upload_time": "2020-04-29T06:14:18",
      "upload_time_iso_8601": "2020-04-29T06:14:18.450510Z",
      "url": "https://files.pythonhosted.org/packages/07/b4/40983b1b3a401eeee6fcb727426685cc59bf1ff13dd7c14302dfacfcfe21/runpandarun-0.1.4-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "b1ca7c1b2294c5ee56c3744ebed1c6933ed88805b1ca5ae46cb5f685a44bd454",
        "md5": "70178d62e5bf1668b34b5c4e65fb47fc",
        "sha256": "e52f82289e481e0caf1db24299178d7ef97817e6af7c67184d22df2f6c332225"
      },
      "downloads": -1,
      "filename": "runpandarun-0.1.4.tar.gz",
      "has_sig": false,
      "md5_digest": "70178d62e5bf1668b34b5c4e65fb47fc",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 25314,
      "upload_time": "2020-04-29T06:14:19",
      "upload_time_iso_8601": "2020-04-29T06:14:19.843419Z",
      "url": "https://files.pythonhosted.org/packages/b1/ca/7c1b2294c5ee56c3744ebed1c6933ed88805b1ca5ae46cb5f685a44bd454/runpandarun-0.1.4.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}