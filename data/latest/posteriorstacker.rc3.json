{
  "info": {
    "author": "Johannes Buchner",
    "author_email": "johannes.buchner.acad@gmx.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 2 - Pre-Alpha",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: GNU General Public License v3 (GPLv3)",
      "Natural Language :: English",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9"
    ],
    "description": "PosteriorStacker\n==================\n\nCombines Bayesian analyses from many datasets.\n\n* `Introduction <#introduction>`_\n* `Method <#method>`_\n* `Tutorial <#tutorial>`_\n* `Output plot <#visualising-the-results>`_ and files\n\nIntroduction\n-------------------\n\nFitting a model to a data set gives \nposterior probability distributions for a parameter of \ninterest. But how do you combine such probability\ndistributions if you have many datasets?\n\nThis question arises frequently in astronomy when\nanalysing samples, and trying to infer sample\ndistributions of some quantity.\n\nPosteriorStacker allows deriving sample\ndistributions from posterior distributions from a number of objects.\n\nMethod\n-------------------\n\nThe method is described in Appendix A of\n`Baronchelli, Nandra & Buchner (2020) <https://ui.adsabs.harvard.edu/abs/2020MNRAS.498.5284B/abstract>`_.\n\n.. image:: hbm.png\n\nThe inputs are posterior samples of a single parameter,\nfor a number of objects. These need to come from pre-existing analyses,\nunder a flat parameter prior.\n\nThe hierarchical Bayesian model (illustrated above) models the sample distribution\nas a Gaussian with unknown mean and standard deviation. The per-object\nparameters are also unknown, but integrated out numerically using\nthe posterior samples.\n\nAdditional to the Gaussian model (as in the paper), \na histogram model (using a flat Dirichlet prior distribution) is computed,\nwhich is non-parametric and more flexible.\nBoth models are inferred using `UltraNest <https://johannesbuchner.github.io/UltraNest/>`_.\n\nThe output is visualised in a publication-ready plot.\n\nSynopsis of the program::\n\n\t$ posteriorstacker.py --help\n\tusage: posteriorstacker.py [-h] [--verbose VERBOSE] [--name NAME]\n\t                           filename low high nbins\n\t\n\tPosterior stacking tool.\n\t\n\tJohannes Buchner (C) 2020-2021\n\t\n\tGiven posterior distributions of some parameter from many objects,\n\tcomputes the sample distribution, using a simple hierarchical model.\n\t\n\tThe method is described in Baronchelli, Nandra & Buchner (2020)\n\thttps://ui.adsabs.harvard.edu/abs/2020MNRAS.498.5284B/abstract\n\tTwo computations are performed with this tool:\n\t\n\t- Gaussian model (as in the paper)\n\t- Histogram model (using a Dirichlet prior distribution)\n\t\n\tThe histogram model is non-parametric and more flexible.\n\tBoth models are computed using UltraNest.\n\tThe output is plotted.\n\t\n\tpositional arguments:\n\t  filename           Filename containing posterior samples, one object per line\n\t  low                Lower end of the distribution\n\t  high               Upper end of the distribution\n\t  nbins              Number of histogram bins\n\t\n\toptional arguments:\n\t  -h, --help         show this help message and exit\n\t  --verbose VERBOSE  Show progress\n\t  --name NAME        Parameter name (for plot)\n\t\n\tJohannes Buchner (C) 2020-2021 <johannes.buchner.acad@gmx.com>\n\nLicence\n--------\nAGPLv3 (see COPYING file). Contact me if you need a different licence.\n\nInstall\n--------\n\n.. image:: https://img.shields.io/pypi/v/PosteriorStacker.svg\n        :target: https://pypi.python.org/pypi/PosteriorStacker\n\n.. image:: https://travis-ci.com/JohannesBuchner/PosteriorStacker.svg?branch=main\n    :target: https://travis-ci.com/JohannesBuchner/PosteriorStacker\n\nInstall as usual::\n\n\tpip install posteriorstacker\n\nThis also installs the required `ultranest <https://johannesbuchner.github.io/UltraNest/>`_\npython package.\n\nTutorial\n=================================\n\nIn this tutorial you will learn:\n\n* How to find a intrinsic distribution from data with asymmetric error bars and upper limits\n* How to use PosteriorStacker\n\nLets say we want to find the intrinsic velocity dispersion given some noisy data points.\n\nOur data are velocity measurements of a few globular cluster velocities in a dwarf galaxy,\nfitted with some model.\n\nPreparing the inputs\n---------------------\n\nFor generating the demo input files and plots, run::\n\n\t$ python3 tutorial/gendata.py\n\nYou can also import posterior points from ultranest output folders::\n\n\t$ load_ultranest_outputs.py --help\n\tusage: load_ultranest_outputs.py [-h] [--samples SAMPLES] --parameter\n\t                                 PARAMETER --out OUT [--verbose]\n\t                                 paths [paths ...]\n\t\n\tBuilt-in functions, exceptions, and other objects.\n\t\n\tNoteworthy: None is the `nil' object; Ellipsis represents `...' in slices.\n\t\n\tpositional arguments:\n\t  paths                 Folders of UltraNest runs\n\t\n\toptional arguments:\n\t  -h, --help            show this help message and exit\n\t  --samples SAMPLES     Number of samples to use\n\t  --parameter PARAMETER\n\t                        Name of the fitting parameter to extract\n\t  --out OUT, -o OUT     Output file name\n\t  --verbose, -v         Show progress\n\t\n\tJohannes Buchner (C) 2020-2021 <johannes.buchner.acad@gmx.com>\n\nVisualise the data\n----------------------\n\nLets plot the data first to see what is going on:\n\n.. image:: example.png\n\n**Caveat on language**: These are not actually \"the data\" (which are counts on a CCD).\nInstead, this is a intermediate representation of a posterior/likelihood,\nassuming flat priors on velocity.\n\nData properties\n-----------------\n\nThis scatter plot shows:\n\n* large, sometimes asymmetric error bars\n* intrinsic scatter\n\nResampling the data\n--------------------\n\nWe could also represent each data point by a cloud of samples. Each point represents a possible true solution of that galaxy.\n\n.. image:: example-samples.png\n\nRunning PosteriorStacker\n=========================\n\nWe run the script with a range limit of +-100 km/s::\n\n\t$ python3 posteriorstacker.py posteriorsamples.txt -80 +80 11 --name=\"Velocity [km/s]\"\n\tfitting histogram model...\n\t[ultranest] Sampling 400 live points from prior ...\n\t[ultranest] Explored until L=-1e+01  \n\t[ultranest] Likelihood function evaluations: 112359\n\t[ultranest] Writing samples and results to disk ...\n\t[ultranest] Writing samples and results to disk ... done\n\t[ultranest]   logZ = -20.46 +- 0.06632\n\t[ultranest] Effective samples strategy satisfied (ESS = 779.4, need >400)\n\t[ultranest] Posterior uncertainty strategy is satisfied (KL: 0.46+-0.06 nat, need <0.50 nat)\n\t[ultranest] Evidency uncertainty strategy is satisfied (dlogz=0.15, need <0.5)\n\t[ultranest]   logZ error budget: single: 0.08 bs:0.07 tail:0.41 total:0.41 required:<0.50\n\t[ultranest] done iterating.\n\t\n\tlogZ = -20.442 +- 0.431\n\t  single instance: logZ = -20.442 +- 0.075\n\t  bootstrapped   : logZ = -20.458 +- 0.146\n\t  tail           : logZ = +- 0.405\n\tinsert order U test : converged: False correlation: 394.0 iterations\n\t\n\t    bin1                0.047 +- 0.045\n\t    bin2                0.056 +- 0.051\n\t    bin3                0.067 +- 0.056\n\t    bin4                0.061 +- 0.058\n\t    bin5                0.105 +- 0.083\n\t    bin6                0.32 +- 0.14\n\t    bin7                0.16 +- 0.10\n\t    bin8                0.052 +- 0.051\n\t    bin9                0.045 +- 0.043\n\t    bin10               0.046 +- 0.046\n\t    bin11               0.044 +- 0.043\n\tfitting gaussian model...\n\t[ultranest] Sampling 400 live points from prior ...\n\t[ultranest] Explored until L=-4e+01  \n\t[ultranest] Likelihood function evaluations: 4584\n\t[ultranest] Writing samples and results to disk ...\n\t[ultranest] Writing samples and results to disk ... done\n\t[ultranest]   logZ = -47.35 +- 0.1094\n\t[ultranest] Effective samples strategy satisfied (ESS = 1026.2, need >400)\n\t[ultranest] Posterior uncertainty strategy is satisfied (KL: 0.46+-0.06 nat, need <0.50 nat)\n\t[ultranest] Evidency uncertainty strategy is satisfied (dlogz=0.28, need <0.5)\n\t[ultranest]   logZ error budget: single: 0.13 bs:0.11 tail:0.41 total:0.42 required:<0.50\n\t[ultranest] done iterating.\n\t\n\tlogZ = -47.358 +- 0.491\n\t  single instance: logZ = -47.358 +- 0.125\n\t  bootstrapped   : logZ = -47.351 +- 0.276\n\t  tail           : logZ = +- 0.405\n\tinsert order U test : converged: False correlation: 3.0 iterations\n\t\n\t    mean                -0.5 +- 4.8\n\t    std                 11.9 +- 5.2\n\t\n\tVary the number of samples to check numerical stability!\n\tplotting results ...\n\nNotice the parameters of the fitted gaussian distribution above.\nThe standard deviation is quite small (which was the point of the original paper).\nA corner plot is at posteriorsamples.txt_out_gauss/plots/corner.pdf\n\n\nVisualising the results\n-----------------------\n\nHere is the output plot, converted to png for this tutorial with::\n\n\t$ convert -density 100 posteriorsamples.txt_out.pdf out.png\n\n.. image:: out.png\n\nIn black, we see the non-parametric fit.\nThe red curve shows the gaussian model.\n\nThe histogram model indicates that a more heavy-tailed distribution\nmay be better.\n\nThe error bars in gray is the result of naively averaging the posteriors.\nThis is not a statistically meaningful procedure,\nbut it can give you ideas what models \nyou may want to try for the sample distribution.\n\nOutput files\n------------\n\n* posteriorsamples.txt_out.pdf contains a plot, \n* posteriorsamples.txt_out_gauss contain the ultranest analyses output assuming a Gaussian distribution.\n* posteriorsamples.txt_out_flexN contain the ultranest analyses output assuming a histogram model.\n* The directories include diagnostic plots, corner plots and posterior samples of the distribution parameters.\n* posteriorsamples.txt_hists.pdf shows the input histograms, and highlights the most informative ones.\n\nWith these output files, you can:\n\n* plot the sample parameter distribution\n* report the mean and spread, and their uncertainties\n* split the sample by some parameter, and plot the sample mean as a function of that parameter.\n\nIf you want to adjust the plot, just edit the script.\n\nIf you want to try a different distribution, adapt the script.\nIt uses `UltraNest <https://johannesbuchner.github.io/UltraNest/>`_\nfor the inference.\n\nTake-aways\n-----------\n\n* PosteriorStacker computed a intrinsic distribution from a set of uncertain measurements\n* This tool can combine arbitrarily pre-existing analyses.\n* No assumptions about the posterior shapes were necessary -- multi-modal and asymmetric works fine.\n\n\nChangelog\n----------",
    "description_content_type": "",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/JohannesBuchner/PosteriorStacker",
    "keywords": "posteriorstacker",
    "license": "GNU General Public License v3",
    "maintainer": "",
    "maintainer_email": "",
    "name": "posteriorstacker",
    "package_url": "https://pypi.org/project/posteriorstacker/",
    "platform": "",
    "project_url": "https://pypi.org/project/posteriorstacker/",
    "project_urls": {
      "Homepage": "https://github.com/JohannesBuchner/PosteriorStacker"
    },
    "release_url": "https://pypi.org/project/posteriorstacker/0.6.1/",
    "requires_dist": null,
    "requires_python": ">=3.5.*",
    "summary": "Combine Bayesian analyses from many datasets. Easy sample parameter distributions.",
    "version": "0.6.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 10536572,
  "releases": {
    "0.5.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "52632c72268311f3645d2b059e5afbec0962ae5d214a2aae64770185bff50050",
          "md5": "1771f6427c98b6c9c9a79fd4eb0fcd06",
          "sha256": "0831b22fdc719347fd645d3ec03d83d4a32cdfeaae1e04b47ceb75d088d4a409"
        },
        "downloads": -1,
        "filename": "posteriorstacker-0.5.1.tar.gz",
        "has_sig": true,
        "md5_digest": "1771f6427c98b6c9c9a79fd4eb0fcd06",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5.*",
        "size": 90047,
        "upload_time": "2021-05-31T21:02:10",
        "upload_time_iso_8601": "2021-05-31T21:02:10.919155Z",
        "url": "https://files.pythonhosted.org/packages/52/63/2c72268311f3645d2b059e5afbec0962ae5d214a2aae64770185bff50050/posteriorstacker-0.5.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.6.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9bbcb4ac4672fd16c6fd1fde3faadbd2fa6af8cbddd2c7feb24701df70c7c2e8",
          "md5": "e362d21d0a8ada7d2526308ff1068620",
          "sha256": "48229cc8514f44fbe95af57ca735189b2ad411f668592f79c56d004197b2017e"
        },
        "downloads": -1,
        "filename": "posteriorstacker-0.6.0.tar.gz",
        "has_sig": true,
        "md5_digest": "e362d21d0a8ada7d2526308ff1068620",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5.*",
        "size": 91005,
        "upload_time": "2021-05-31T21:23:23",
        "upload_time_iso_8601": "2021-05-31T21:23:23.819541Z",
        "url": "https://files.pythonhosted.org/packages/9b/bc/b4ac4672fd16c6fd1fde3faadbd2fa6af8cbddd2c7feb24701df70c7c2e8/posteriorstacker-0.6.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.6.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "35506275693d50659e1807c3d61ce6f694849de4c24899f3046ca4005f4c4115",
          "md5": "0f2edfee76e5f676cd78c876f9ecff24",
          "sha256": "e413a1ba0ebd88fc1958755b7fc7272bab0627bf80bf3994c4df978997d68cbe"
        },
        "downloads": -1,
        "filename": "posteriorstacker-0.6.1.tar.gz",
        "has_sig": true,
        "md5_digest": "0f2edfee76e5f676cd78c876f9ecff24",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5.*",
        "size": 77492,
        "upload_time": "2021-06-02T10:09:52",
        "upload_time_iso_8601": "2021-06-02T10:09:52.018812Z",
        "url": "https://files.pythonhosted.org/packages/35/50/6275693d50659e1807c3d61ce6f694849de4c24899f3046ca4005f4c4115/posteriorstacker-0.6.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "35506275693d50659e1807c3d61ce6f694849de4c24899f3046ca4005f4c4115",
        "md5": "0f2edfee76e5f676cd78c876f9ecff24",
        "sha256": "e413a1ba0ebd88fc1958755b7fc7272bab0627bf80bf3994c4df978997d68cbe"
      },
      "downloads": -1,
      "filename": "posteriorstacker-0.6.1.tar.gz",
      "has_sig": true,
      "md5_digest": "0f2edfee76e5f676cd78c876f9ecff24",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.5.*",
      "size": 77492,
      "upload_time": "2021-06-02T10:09:52",
      "upload_time_iso_8601": "2021-06-02T10:09:52.018812Z",
      "url": "https://files.pythonhosted.org/packages/35/50/6275693d50659e1807c3d61ce6f694849de4c24899f3046ca4005f4c4115/posteriorstacker-0.6.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}