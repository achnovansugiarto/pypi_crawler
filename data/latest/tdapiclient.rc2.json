{
  "info": {
    "author": "Teradata Corporation",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "License :: Other/Proprietary License",
      "Operating System :: MacOS :: MacOS X",
      "Operating System :: Microsoft :: Windows",
      "Operating System :: POSIX :: Linux",
      "Programming Language :: Python :: 3 :: Only",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Topic :: Database :: Front-Ends"
    ],
    "description": "## tdapiclient - Teradata Third Party Analytics Integration Python Library\n\n tdapiclient Python library allows AWS SageMaker and Teradata users to use AWS SageMaker Python library's interface to train/predict using teradataml DataFrame. tdapiclient will transparantly convert teradataml DataFrame in S3 address to be used for training and it will also allow user to use teradataml DataFrame as input for inference.\n\n tdapiclient also allows Azure-ML and Teradata Users to use easier interface to train/predict using teradataml DataFrame. tdapiclient will transparantly convert teradataml DataFrame to azure-ml dataset or blob store to be used for training and it will allow users to use teradataml DataFrame as input for inference.\n Additinally, tdapiclient also allows to deploy azure-ml trained models in Teradata Vantage system for in-database scoring using BYOM functionality.\n\nFor community support, please visit the [Connectivity Forum](http://community.teradata.com/t5/Tools/bd-p/DevXToolsBoard).\nFor Teradata customer support, please visit [Teradata Access](https://access.teradata.com/).\n\nCopyright 2022, Teradata. All Rights Reserved.\n\n### Table of Contents\n- [tdapiclient - Teradata Third Party Analytics Integration Python Library](#tdapiclient---teradata-third-party-analytics-integration-python-library)\n- [Release Notes](#release-notes)\n- [Installation and Requirements](#installation-and-requirements)\n- [Using the tdapiclient Python Package with Sagemaker](#using-the-tdapiclient-python-package-with-sagemaker)\n- [Using the tdapiclient Python Package with Azure-ML](#using-the-tdapiclient-python-package-with-azure-ml)\n- [Documentation](#documentation)\n- [License](#license)\n\n## Release Notes\n#### tdapiclient 1.1.1.0\n* `tdapiclient 1.1.1.00` is the second release version. This release adds a support for AzureML integration with Teradata vantage. Please refer to the _API Integration Guide for Cloud Machine Learning_ for a list of Limitations and Usage Considerations.\n\n#### tdapiclient 1.0.0.0\n* `tdapiclient 1.00.00.00` is the first release version. Please refer to the _API Integration Guide for Cloud Machine Learning_ for a list of Limitations and Usage Considerations.\n\n## Installation and Requirements\n\n### Package Requirements\n* Python 3.6 or later\n\nNote: 32-bit Python is not supported.\n\n### Minimum System Requirements\n* Windows 7 (64Bit) or later\n* macOS 10.9 (64Bit) or later\n* Red Hat 7 or later versions\n* Ubuntu 16.04 or later versions\n* CentOS 7 or later versions\n* SLES 12 or later versions\n* Teradata Vantage Advanced SQL Engine:\n    * Advanced SQL Engine 17.05 Feature Update 1 or later\n\n### Installation\n\nUse pip to install the tdapiclient - Teradata Sagemaker Python Library\n\nPlatform       | Command\n-------------- | ---\nmacOS/Linux    | `pip install tdapiclient`\nWindows        | `py -3 -m pip install tdapiclient`\n\n## Using the tdapiclient Python Package with Sagemaker\n\nYour Python script must import the `tdapiclient` package in order to use the tdapiclient Python Library\n```\n>>> from tdapiclient import create_aws_context,TDApiClient\n>>> from teradataml import create_context, DataFrame, copy_to_sql\n\n>>> # Create connection to Teradata Vantage System\n>>> host = input(\"Host: \")\n>>> username = input(\"Username: \")\n>>> password = getpass.getpass(\"Password: \")\n>>> td_context = create_context(host=host, username=username, password=password)\n\n# Create AWS Context to be used in TDApiClient\n>>> s3_bucket = input(\"S3 Bucket(Please give just the bucket name) :\")\n>>> access_id = input(\"Access ID:\")\n>>> access_key = getpass.getpass(\"Acess Key: \")\n>>> region = input(\"AWS Region: \")\n\n>>>   os.environ[\"AWS_ACCESS_KEY_ID\"] = access_id\n>>>   os.environ[\"AWS_SECRET_ACCESS_KEY\"] = access_key\n>>>   os.environ[\"AWS_REGION\"] = region\n\n>>> aws_context = create_tdapi_context(\"aws\", bucket_name=s3_bucket)\n# Create TDApiClient Instance\n>>> td_apiclient = TDApiClient(aws_context)\n\n# Load data in teradata tables\n>>> from sklearn.model_selection import train_test_split\n>>> from sklearn.datasets import fetch_california_housing\n\n>>> data = fetch_california_housing()\n>>> X_train, X_test, y_train, y_test = train_test_split(\n     data.data, data.target, test_size=0.25, random_state=42)\n\n>>> trainX = pd.DataFrame(X_train, columns=data.feature_names)\n>>> trainX[\"target\"] = y_train\n\n>>> testX = pd.DataFrame(X_test, columns=data.feature_names)\n>>> testX[\"target\"] = y_test\n\n>>> train_table = \"housing_data_train\"\n>>> test_table = \"housing_data_test\"\n\n>>> column_types = {\"MedInc\": FLOAT, \"HouseAge\": FLOAT,\n                \"AveRooms\": FLOAT, \"AveBedrms\": FLOAT, \"Population\": FLOAT,\n                \"AveOccup\": FLOAT, \"Latitude\": FLOAT, \"Longitude\": FLOAT,\n                \"target\" : FLOAT}\n\n>>> copy_to_sql(df=trainX, table_name=train_table, if_exists=\"replace\", types=column_types)\n>>> copy_to_sql(df=testX, table_name=test_table, if_exists=\"replace\", types=column_types)\n\n# Create teradataml DataFrame for input tables\n\n>>> test_df = DataFrame(table_name=test_table)\n>>> train_df = DataFrame(table_name=train_table)\n\n>>> exec_role_arn = \"arn:aws:iam::XX:role/service-role/AmazonSageMaker-ExecutionRole-20210112T215668\"\n>>> FRAMEWORK_VERSION = \"0.23-1\"\n# Create an estimator object based on sklearn sagemaker class\n>>> sklearn_estimator = td_apiclient.SKLearn(\n    entry_point=\"sklearn-script.py\",\n    role=exec_role_arn,\n    instance_count=1,\n    instance_type=\"ml.m5.large\",\n    framework_version=FRAMEWORK_VERSION,\n    base_job_name=\"rf-scikit\",\n    metric_definitions=[{\"Name\": \"median-AE\", \"Regex\": \"AE-at-50th-percentile: ([0-9.]+).*$\"}],\n    hyperparameters={\n        \"n-estimators\": 100,\n        \"min-samples-leaf\": 3,\n        \"features\": \"MedInc HouseAge AveRooms AveBedrms Population AveOccup Latitude Longitude\",\n        \"target\": \"target\",\n    },\n)\n>>> # Start training using DataFrame objects\n>>> sklearn_estimator.fit({\"train\": test_df, \"test\": train_df}, content_type=\"csv\", wait=True)\n\n>>> from sagemaker.serializers import CSVSerializer\n>>> from sagemaker.deserializers import CSVDeserializer\n>>> csv_ser = CSVSerializer()\n>>> csv_dser = CSVDeserializer()\n>>> predictor = sklearn_estimator.deploy(instance_type=\"ml.m5.large\", initial_instance_count=1,serializer=csv_ser,  deserializer=csv_dser)\n\n>>> # Now let's try prediction with UDF and Client options.\n>>> input = DataFrame(table_name='housing_data_test')\n>>> column_list = [\"MedInc\",\"HouseAge\",\"AveRooms\",\"AveBedrms\",\"Population\",\"AveOccup\",\"Latitude\",\"Longitude\"]\n>>> input = input.sample(n=5).select(column_list)\n\n>>> output = predictor.predict(input, mode=\"UDF\",content_type='csv')\n\n```\n\n## Using the tdapiclient Python Package with Azure-ML\nYour Python script must import the `tdapiclient` package in order to use the tdapiclient Python Library\n```\n>>> import os\n>>> import getpass\n>>> from teradataml import create_context, DataFrame, read_csv\n>>> import pandas as pd\n>>> from teradatasqlalchemy.types import  *\n>>> from tdapiclient import create_tdapi_context,TDApiClient, remove_tdapi_context\n>>> # Create the connection.\n>>> host = input(\"Host: \")\n>>> username = input(\"Username: \")\n>>> password = getpass.getpass(\"Password: \")\n>>> # Create Azure Context and TDApiClient object.\n\n>>> datastore_path = input(\n>>>    \"DataStore path : Please give path within data store of azure-ml workspace.\")\n>>> tenant_id = input(\"Azure Tenant ID:\")\n>>> client_id = getpass.getpass(\"Azure Client ID: \")\n>>> client_secret = input(\"Azure Client Secret: \")\n>>>\n>>> azure_sub = input(\"Azure Subscription id: \")\n>>> azure_rg = input(\"Azure resource group: \")\n>>> azureml_ws = input(\"Azure-ML workspace: \")\n>>> azure_region = input(\"Azure region: \")\n\n>>> os.environ[\"AZURE_TENANT_ID\"] = tenant_id\n>>> os.environ[\"AZURE_CLIENT_ID\"] = client_id\n>>> os.environ[\"AZURE_CLIENT_SECRET\"] = client_secret\n>>>\n>>> os.environ[\"AZURE_SUB_ID\"] = azure_sub\n>>> os.environ[\"AZURE_RG\"] = azure_rg\n>>> os.environ[\"AZURE_WS\"] = azureml_ws\n>>> os.environ[\"AZURE_REGION\"] = azure_region\n\n>>> tdapi_context = create_tdapi_context(\"azure\", datastore_path=\"td-tables\")\n>>> td_apiclient = TDApiClient(tdapi_context)\n>>> from collections import OrderedDict\n>>>\n>>> from collections import OrderedDict\n>>>\n>>> types = OrderedDict(bustout=INTEGER, rec_id=INTEGER, acct_no=INTEGER, as_of_dt_day=DATE, avg_pmt_05_mth=FLOAT,>>> days_since_lstcash=INTEGER, max_utilization_05_mth=INTEGER, maxamt_epmt_v7day=INTEGER, times_nsf=INTEGER,\n>>>  totcash_to_line_v7day=INTEGER,totpmt_to_line_v7day=INTEGER,totpur_to_line_v7day=INTEGER,  totpurcash_to_line_v7day=INTEGER, credit_util_cur_mth=FLOAT, credit_util_prior_5_mth=FLOAT, credit_util_cur_to_prior_ratio=FLOAT, days_since_lst_pymnt=INTEGER, num_pymnt_lst_7_days=INTEGER, num_pymnt_lst_60_days=INTEGER,\n>>>     pct_line_paid_lst_7_days=INTEGER, pct_line_paid_lst_30_days=INTEGER, num_pur_lst_7_days=INTEGER, num_pur_lst_60_days=INTEGER,\n>>>     pct_line_pur_lst_7_days=INTEGER, pct_line_pur_lst_30_days=INTEGER, tot_pymnt_chnl=INTEGER, tot_pymnt=INTEGER, tot_pymnt_am=INTEGER, pay_by_phone=CHAR, elec_pymnt=CHAR,\n>>>     pay_in_bank=CHAR, pay_by_check=CHAR, pay_by_othr=CHAR, last_12m_trans_ct=INTEGER, Sample_ID=INTEGER)\n\n>>> # Check this csv file in Teradata Vantage Documentation site under azureml-usercases.zip\n>>> df:DataFrame = read_csv(r'financial_data.csv', table_name=\"financial_data\", types=types, use_fastload=False)\n>>> # training dataframe.\n>>> selected_df = df.select([\"bustout\", \"rec_id\", \"avg_pmt_05_mth\", \"max_utilization_05_mth\",\"times_nsf\"\n,\"credit_util_cur_mth\",\"credit_util_prior_5_mth\",\"num_pur_lst_7_days\",\"num_pur_lst_60_days\",\"tot_pymnt_chnl\",\"last_12m_trans_ct\"])\n>>> # Setup compute target for Azure ML.\n>>> from azureml.core.compute import AmlCompute, ComputeTarget\n>>> from azureml.core.authentication import ServicePrincipalAuthentication\n>>> from azureml.core import Workspace, Environment\n\n>>> credential = ServicePrincipalAuthentication(\n>>>         tenant_id=tenant_id,\n>>>         service_principal_id=client_id, service_principal_password=client_secret)\n\n>>> ws = Workspace(subscription_id=azure_sub, resource_group=azure_rg, workspace_name=azureml_ws, auth=credential)\n\n>>> vm_size = \"Standard_DS3_v2\"\n>>> min_node = 1\n>>> max_node = 1\n>>> cluster_name = \"test-td-cluster-new\"\n>>> provisioning_config = AmlCompute.provisioning_configuration(\n>>>         vm_size=vm_size, min_nodes=min_node,\n>>>         max_nodes=max_node)\n\n>>> # Creating Compute cluster in Azure ML.\n>>> compute_target = ComputeTarget.create(\n>>>         ws, cluster_name, provisioning_config)\n>>> compute_target.wait_for_completion(show_output=True)\n\n>>> compute_target = ws.compute_targets[\"test-td-cluster-new\"]\n>>> from azureml.automl.core.featurization import FeaturizationConfig\n>>> import logging\n\n>>> # Selecting the target column.\n>>> target_column_name = \"bustout\"\n\n>>> forecast_horizon=14\n\n>>> featurization_config = FeaturizationConfig()\n>>> # Force the target column, to be integer type.\n>>> featurization_config.add_prediction_transform_type(\"Integer\")\n\n>>> automl_config = td_apiclient.AutoMLConfig(\n>>>     task=\"classification\",\n>>>     primary_metric=\"accuracy\",\n>>>     featurization=featurization_config,\n>>>     blocked_models=[\"ExtremeRandomTrees\"],\n>>>     experiment_timeout_hours=0.3,\n>>>     training_data=selected_df,\n>>>     label_column_name=target_column_name,\n>>>     compute_target=compute_target,\n>>>     enable_early_stopping=True,\n>>>     n_cross_validations=3,\n>>>     max_concurrent_iterations=4,\n>>>     max_cores_per_iteration=-1,\n>>>     verbosity=logging.INFO\n>>> )\n\n>>> # Execute Azure ML training API with teradataml DataFrame as input which returns Azure ML Run Object.\n>>> run = automl_config.fit(mount=False)\n>>> # Get the best run after Auto ML job has completed.\n>>> run_best = run.get_best_child()\n>>> from azureml.core.environment import Environment\n>>>\n>>> # Creating an Azure ML Environment from a Dockerfile and requirements.txt.\n>>> # myenv = Environment.from_dockerfile(name=\"new_project_env_7\", dockerfile=\"./Dockerfile\", pip_requirements=\"./>>> requirements.txt\")\n>>> myenv = Environment.from_dockerfile(name=\"new_project_env_18\", >>> dockerfile=r'C:\\Projects\\AzureML-jupyter-notebooks\\test-ignite-azureml-api-demo\\Dockerfile', pip_requirements=r'C:\\Projects\\AzureML-jupyter-notebooks\\test-ignite-azureml-api-demo\\requirements.txt')\n>>> myenv_b = myenv.build(workspace=ws)\n>>> myenv_b.wait_for_completion(show_output=True)\n>>> # curated_env_name = \"AzureML-sklearn-0.24.1-ubuntu18.04-py37-cpu-inference\"\n>>> # myenv = Environment.get(workspace=ws, name=curated_env_name)\n>>> myenv = Environment.get(workspace=ws, name=\"new_project_env_18\")\n>>> # Register an Azure ML model from the best run.\n>>> from azureml.core import Model\n>>> model:Model = run_best.register_model(model_name='voting_ensemble_model_1', model_path='outputs/model.pkl',>>> model_framework=Model.Framework.SCIKITLEARN)\n>>> from azureml.core.model import Model\n>>> model = Model(workspace=ws, name=\"voting_ensemble_model_1\", version=1)\n\n>>> from enum import auto\n>>> from operator import mod\n>>> from platform import platform\n>>> from azureml.core import Model\n>>> from azureml.core.model import InferenceConfig, Model\n>>> from azureml.core.webservice import AciWebservice, Webservice\n>>> from azureml.core.environment import Environment\n>>> print(myenv)\n>>> # Combine scoring script & environment in Inference configuration\n>>> # inference_config = InferenceConfig(entry_script=\"scoring.py\",\n>>> #                                    environment=myenv)\n>>> myenv.inferencing_stack_version = 'latest'\n>>> inference_config = InferenceConfig(entry_script=r'C:\\Projects\\test-tdapiclient\\tdapiclient\\notebooks\\azureml-az-webservice\\scoring.py',\n                                   environment=myenv)\n>>> # Set deployment configuration\n>>> deployment_config = AciWebservice.deploy_configuration(cpu_cores = 2,\n>>>                                                        memory_gb = 4, auth_enabled=True)\n\n>>> # Creating azmodel_deploy_kwargs dictionary to pass as a keyword argument for deploy method.\n>>> azmodel_deploy_kwargs = {}\n>>> azmodel_deploy_kwargs[\"name\"] = \"tdapiclient-endpoint-29\"\n>>> azmodel_deploy_kwargs[\"models\"] = [model]\n>>> azmodel_deploy_kwargs[\"workspace\"] = ws\n>>> azmodel_deploy_kwargs[\"inference_config\"] = inference_config\n>>> azmodel_deploy_kwargs[\"deployment_config\"] = deployment_config\n>>> azmodel_deploy_kwargs[\"overwrite\"] = True\n\n>>> # Deploying the model to Azure ML Compute cluster if the platform is az-webservice.\n>>> webservice = automl_config.deploy(platform=\"az-webservice\", model=model, model_type=\"\",\n>>>                         model_deploy_kwargs=azmodel_deploy_kwargs)\n>>> webservice.wait_for_deployment(show_output=True)\n>>> # Creating an options dictionary to pass the content_format for scoring.\n>>> options = {}\n>>> content_format = {}\n>>> content_format[\"Inputs\"] = [[\"%row\"]]\n>>> options[\"content_format\"] = content_format\n>>> print(webservice.predict(test_df, **options, mode=\"udf\", content_type='json'))\n......\n......\n```\n\n## Documentation\n\nGeneral product information, including installation instructions, is available in the [Teradata Documentation website](https://docs.teradata.com/)\n\n## License\n\nUse of the Teradata Python Package is governed by the *License Agreement for the Teradata Sagemaker Python Library*.\nAfter installation, the `LICENSE` and `LICENSE-3RD-PARTY` files are located in the `tdapiclient` directory of the Python installation directory.\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "http://www.teradata.com/",
    "keywords": "Teradata",
    "license": "Teradata License Agreement",
    "maintainer": "",
    "maintainer_email": "",
    "name": "tdapiclient",
    "package_url": "https://pypi.org/project/tdapiclient/",
    "platform": "MacOS X, Windows, Linux",
    "project_url": "https://pypi.org/project/tdapiclient/",
    "project_urls": {
      "Homepage": "http://www.teradata.com/"
    },
    "release_url": "https://pypi.org/project/tdapiclient/1.1.1.0/",
    "requires_dist": [
      "teradataml (>=17.10.00.01)",
      "sagemaker (>=2.75.00)",
      "azure-mgmt-storage (>=19.0.0)",
      "azure-storage-blob (>=12.14.0)",
      "azureml-core (>=1.42.0)"
    ],
    "requires_python": ">=3.0",
    "summary": "Teradata API Client Python package",
    "version": "1.1.1.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 15711518,
  "releases": {
    "1.0.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d0ddf90db6453d120d49d168fcb7caf268bef0a94105404f5c0d65d83da69277",
          "md5": "3ffd9fd04b57f1c4475f4f75f85b383d",
          "sha256": "4c0b807d81ce77a9eba971ee2db88aaa636783eaf82cd5fdb8cb2b0fafcce85c"
        },
        "downloads": -1,
        "filename": "tdapiclient-1.0.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "3ffd9fd04b57f1c4475f4f75f85b383d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 41239,
        "upload_time": "2022-05-03T05:28:15",
        "upload_time_iso_8601": "2022-05-03T05:28:15.653884Z",
        "url": "https://files.pythonhosted.org/packages/d0/dd/f90db6453d120d49d168fcb7caf268bef0a94105404f5c0d65d83da69277/tdapiclient-1.0.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7889c7beaef6377f565bda8c1aa2abe489367db7abad06326d3337f3884ea545",
          "md5": "a1528f3d382fafd477c50561ceaf4be0",
          "sha256": "0feb50648496d33c581acf9bb8b978483be9e09d35a59cc0b718b6231671443a"
        },
        "downloads": -1,
        "filename": "tdapiclient-1.1.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "a1528f3d382fafd477c50561ceaf4be0",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.0",
        "size": 81784,
        "upload_time": "2022-11-09T13:09:28",
        "upload_time_iso_8601": "2022-11-09T13:09:28.908091Z",
        "url": "https://files.pythonhosted.org/packages/78/89/c7beaef6377f565bda8c1aa2abe489367db7abad06326d3337f3884ea545/tdapiclient-1.1.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "7889c7beaef6377f565bda8c1aa2abe489367db7abad06326d3337f3884ea545",
        "md5": "a1528f3d382fafd477c50561ceaf4be0",
        "sha256": "0feb50648496d33c581acf9bb8b978483be9e09d35a59cc0b718b6231671443a"
      },
      "downloads": -1,
      "filename": "tdapiclient-1.1.1.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "a1528f3d382fafd477c50561ceaf4be0",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.0",
      "size": 81784,
      "upload_time": "2022-11-09T13:09:28",
      "upload_time_iso_8601": "2022-11-09T13:09:28.908091Z",
      "url": "https://files.pythonhosted.org/packages/78/89/c7beaef6377f565bda8c1aa2abe489367db7abad06326d3337f3884ea545/tdapiclient-1.1.1.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}