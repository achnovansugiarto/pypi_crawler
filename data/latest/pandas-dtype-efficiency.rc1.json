{
  "info": {
    "author": "Kieran O'Sullivan",
    "author_email": "osullivank3@hotmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Developers",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.7",
      "Topic :: Scientific/Engineering :: Information Analysis"
    ],
    "description": "# pandas_dtype_efficiency\n\n- [About](#About)\n- [Installation](#installation)\n- [Example Usage](#example-usage)\n  * [Watch-outs](#watch-outs)\n- [Contributing](#contributing)\n  * [Development environment](#development-environment)\n- [License](#license)\n\n\n## About\n\npandas_dtype_efficiency is a Python package to help reduce the memory size of pandas DataFrames without changing the \nunderlying data (lossless compression). It is intended to make your code more efficient and reduce the likelihood of \nrunning out of memory.\n\nThis is achieved by checking every column to see whether it fits one of the following criteria:\n\n* Float values where the user is comfortable with lower precision e.g. a numpy.float16 vs the pandas default of \nnumpy.float64\n* Integer values which can be represented by a smaller integer types e.g. values which fall between -128 and 127 can \nbe accommodated with a numpy.int8\n* String values which fall within a small list of set values and could be represented by the pandas.Categorical data \ntype instead\n\n![Demo](https://github.com/osulki01/pandas_dtype_efficiency/blob/main/Demo.gif?raw=true)\n\n\n## Installation\n\nYou will need [Python 3.7](https://www.python.org/downloads/) or higher, which comes with pip included in the \ninstallation.\n\nThe simplest method of installation is via pip:\n\n```shell script\npip install pandas_dtype_efficiency\n```\n\nHowever, the package can also be installed directly from GitHub:\n\n```shell script\n# Option 1: HTTPS\npip install git+https://github.com/osulki01/pandas_dtype_efficiency#egg=pandas_dtype_efficiency\n\n# Option 2: SSH\npip install git+ssh://github.com/osulki01/pandas_dtype_efficiency#egg=pandas_dtype_efficiency\n\n# Option 3: HTTP, discouraged because HTTP is insecure due to lack of TLS based encryption\npip install git+http://github.com/osulki01/pandas_dtype_efficiency#egg=pandas_dtype_efficiency\n```\n\n\n## Example Usage\n\nFirst, let's create a pandas DataFrame made up of various data types. All of the code in this section is Python.\n\n```python\nimport numpy as np\nimport pandas as pd\n\nnum_rows = 100000\n\ndf_original = pd.DataFrame(\n    data={\n        'small_integers': np.random.randint(low=-128, high=128, size=num_rows),\n        'medium_integers': np.random.randint(low=-32768, high=32768, size=num_rows),\n        'large_integers': np.random.randint(low=-9223372036854775808, high=9223372036854775808, size=num_rows),\n        'floats': np.random.rand(size=num_rows),\n        'categorical_strings': np.random.choice(a=['Cat_1', 'Cat_2', 'Cat_3'], size=num_rows),\n        'bools': np.random.choice(a=[True, False], size=num_rows)\n    }\n)\n```\n\nNext, we create a DataFrameChecker that can analyse the DataFrame for potential memory improvements.\n\nThe optional arguments are:\n\n* **categorical_threshold**; the maximum number of distinct values in a column of strings to suggest transforming it into \na categorical column. In this case, if a column made up of strings has less than or equal to 10 distinct values, it \nwill be flagged as a potential [categorical](https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html) \ncolumn.\n* **float_size**; the desired numpy float type; 16: numpy float16, 32: numpy float23, 64: numpy float64 \n(the pandas default). If this argument is set to 64, then float columns are not analysed. If you do not need decimals \nstored to the level of precision in the pandas default of numpy.float64, then make use of this compression.\n\n```python\nimport pandas_dtype_efficiency as pd_eff\n\nchecker = pd_eff.DataFrameChecker(\n    df=df_original,\n    categorical_threshold=10,  # Optional argument\n    float_size=16  # Optional argument\n)\n```\n\nThe checker can then be used to evaluate the DataFrame and find any columns with potential for reduced memory:\n\n```python\n# Analyse DataFrame\nchecker.identify_possible_improvements()\n\n# Retrieve the suggested dtypes for columns where their memory footprint could be reduced\n# If no improvements are found, this will return an empty dictionary\npotential_improvements = checker.get_possible_dtypes()\n```\n\nThe suggested improvements can be used to produce a new DataFrame with reduced memory usage:\n\n```python\ndf_reduced_memory = checker.cast_dataframe_to_lower_memory_version()\n\n# The checker will tell you how much memory has been saved overall but you can view this at a column level too\ndf_original.memory_usage(deep=True)\ndf_reduced_memory.memory_usage(deep=True)\n```\n\nThe potential improvements indicated by checker.get_possible_dtypes() can also used at the point of reading in \ndata from a local file rather than loading it all into memory and then transforming the data.\n\n```python\ndf_reduced_memory_on_load = pd.read_csv('my_data.csv', dtype=potential_improvements)\n```\n\n\n### Watch-outs\n\n1. If you are preparing data for a machine learning algorithm, the machine learning library may cast the data to fixed \ndata type regardless of how it has been provided, so this exercise would redundant in these cases if the next step will\nundo the compression performed.\n2. The method cast_dataframe_to_lower_memory_version creates a whole new DataFrame rather than updating the existing \none (to avoid unwanted mutation). If your DataFrame is already close to the memory limit for your machine then you \ncould run out of memory by having two large DataFrames, even if one of them has been compressed.\n\n## Contributing\n\nAny suggestions or contributions are welcome via email or pull request.\n\n\n### Development environment\nIf you would like to experiment with the code or make changes, you can set up the development environment as per the \nsteps below. In advance, you will need [Docker](https://docs.docker.com/get-docker/) and \n[Docker Compose](https://docs.docker.com/compose/install/) installed on your machine.\n\n```shell script\n# Build the Docker image (if running for the first time)\ndocker-compose build\n\n# Create container\ndocker-compose up -d\n\n# Run tests to make sure code is functional\ndocker exec pandas_dtype_efficiency_dev pytest --verbose tests/\n```\n\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/osulki01/pandas_dtype_efficiency",
    "keywords": "data,science,pandas,memory,efficiency",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "pandas-dtype-efficiency",
    "package_url": "https://pypi.org/project/pandas-dtype-efficiency/",
    "platform": "",
    "project_url": "https://pypi.org/project/pandas-dtype-efficiency/",
    "project_urls": {
      "Homepage": "https://github.com/osulki01/pandas_dtype_efficiency"
    },
    "release_url": "https://pypi.org/project/pandas-dtype-efficiency/0.0.1/",
    "requires_dist": [
      "pandas"
    ],
    "requires_python": ">=3.7",
    "summary": "Evaluate pandas DataFrames to see whether their memory usage can be reduced without losing information",
    "version": "0.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 10259686,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ddd744305d703ef2ab3f8c5bb48db8ed7b1fddb1bdba73a2ea86805d4d4b6aaf",
          "md5": "292835a83e4b9b689ef731e6ff13a607",
          "sha256": "8d0404d8c07d7eadeecafbb811d96bdfe08132037efe354132a86d6d265de642"
        },
        "downloads": -1,
        "filename": "pandas_dtype_efficiency-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "292835a83e4b9b689ef731e6ff13a607",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 7108,
        "upload_time": "2021-05-04T21:23:42",
        "upload_time_iso_8601": "2021-05-04T21:23:42.314864Z",
        "url": "https://files.pythonhosted.org/packages/dd/d7/44305d703ef2ab3f8c5bb48db8ed7b1fddb1bdba73a2ea86805d4d4b6aaf/pandas_dtype_efficiency-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d96aad4c8bab8dab4afe9c74b29148bbaf458a76caf87339e060aa9fba23e828",
          "md5": "d6c37b2c723c3a7c35cf3395ed7d9aa7",
          "sha256": "7ddc7b8b050f5f984f7a815b5daf76c7dafe83535d532af2370bc536038ccebc"
        },
        "downloads": -1,
        "filename": "pandas_dtype_efficiency-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "d6c37b2c723c3a7c35cf3395ed7d9aa7",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 6153,
        "upload_time": "2021-05-04T21:23:45",
        "upload_time_iso_8601": "2021-05-04T21:23:45.667452Z",
        "url": "https://files.pythonhosted.org/packages/d9/6a/ad4c8bab8dab4afe9c74b29148bbaf458a76caf87339e060aa9fba23e828/pandas_dtype_efficiency-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "ddd744305d703ef2ab3f8c5bb48db8ed7b1fddb1bdba73a2ea86805d4d4b6aaf",
        "md5": "292835a83e4b9b689ef731e6ff13a607",
        "sha256": "8d0404d8c07d7eadeecafbb811d96bdfe08132037efe354132a86d6d265de642"
      },
      "downloads": -1,
      "filename": "pandas_dtype_efficiency-0.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "292835a83e4b9b689ef731e6ff13a607",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 7108,
      "upload_time": "2021-05-04T21:23:42",
      "upload_time_iso_8601": "2021-05-04T21:23:42.314864Z",
      "url": "https://files.pythonhosted.org/packages/dd/d7/44305d703ef2ab3f8c5bb48db8ed7b1fddb1bdba73a2ea86805d4d4b6aaf/pandas_dtype_efficiency-0.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "d96aad4c8bab8dab4afe9c74b29148bbaf458a76caf87339e060aa9fba23e828",
        "md5": "d6c37b2c723c3a7c35cf3395ed7d9aa7",
        "sha256": "7ddc7b8b050f5f984f7a815b5daf76c7dafe83535d532af2370bc536038ccebc"
      },
      "downloads": -1,
      "filename": "pandas_dtype_efficiency-0.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "d6c37b2c723c3a7c35cf3395ed7d9aa7",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 6153,
      "upload_time": "2021-05-04T21:23:45",
      "upload_time_iso_8601": "2021-05-04T21:23:45.667452Z",
      "url": "https://files.pythonhosted.org/packages/d9/6a/ad4c8bab8dab4afe9c74b29148bbaf458a76caf87339e060aa9fba23e828/pandas_dtype_efficiency-0.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}