{
  "info": {
    "author": "qichun tang",
    "author_email": "tqichun@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Environment :: Console",
      "Intended Audience :: Developers",
      "Intended Audience :: Education",
      "Intended Audience :: Information Technology",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: BSD License",
      "Natural Language :: English",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Topic :: Scientific/Engineering :: Artificial Intelligence",
      "Topic :: Scientific/Engineering :: Information Analysis"
    ],
    "description": "==========\nAutoFlow\n==========\n\n``AutoFlow`` : **Automatic machine learning workflow modeling platform**\n\n\nIntroduction\n--------------\n\nIn the problem of data mining and machine learning of tabular data,\ndata scientists usually group the features, construct a directed acyclic graph (DAG),\nand form a machine learning workflow.\n\nIn each directed edge of this directed acyclic graph, \nthe tail node represents the feature group before preprocessing, \nand the head node represents the feature group after preprocessing. \nEdge representation data processing or feature engineering algorithms, \nin each edge algorithm selection and hyper-parameter optimization are doing.\n\nUnfortunately, if data scientists want to manually select algorithms and \nhyper-parameters for such a workflow, \nit will be a very tedious task. In order to solve this problem, \nwe developed the ``Hyperflow``, \nwhich can automatically select algorithm and optimize the parameters of \nmachine learning workflow. \nIn other words, it can implement AutoML for tabular data.\n\n.. image:: docs/images/workflow_space.png\n\n\nDocumentation\n--------------\n\nThe documentation can be found `here <https://auto-flow.github.io/autoflow/>`_.\n\nInstallation\n--------------\n\nRequirements\n~~~~~~~~~~~~~~\n\nThis project is built and test on Linux system, so Linux platform is required. \nIf you are using Windows system, `WSL <https://docs.microsoft.com/en-us/windows/wsl/install-win10>`_ is worthy of considerarion.\n\nBesides the listed requirements (see requirements.txt), the `random forest <https://github.com/automl/random_forest_run>`_ \nused in `SMAC3 <https://github.com/automl/SMAC3>`_ requires \n`SWIG <http://www.swig.org/>`_ (>= 3.0, <4.0) as a build dependency. \nIf you are using Ubuntu or another Debain Linux, you can enter following command :\n\n::\n\n    apt-get install swig\n\nOn Arch Linux (or any distribution with swig4 as default implementation):\n\n::\n\n    pacman -Syu swig3\n    ln -s /usr/bin/swig-3 /usr/bin/swig\n\nAutoFlow requires `Python <https://www.python.org/>`_ 3.6 or higher.\n\nInstallation via pip\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n::\n\n    pip install auto-flow\n\n\nManual Installation\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n::\n\n    git clone https://github.com/auto-flow/autoflow.git && cd autoflow\n    python setup.py install\n\nQuick Start\n--------------\n\n`Titanic <https://www.kaggle.com/c/titanic>`_ is perhaps the most familiar machine learning task for data scientists. \nFor tutorial purposes, you can find titanic dataset in ``examples/data/train_classification.csv`` and\n``examples/data/test_classification.csv`` . \nYou can use AutoFlow to finish this ML task instead of manually exploring all the features of the dataset. DO IT !\n\n.. code-block:: bash\n\n   $ cd examples/classification\n\n.. code-block:: python\n\n    import os\n\n    import joblib\n    import pandas as pd\n    from sklearn.model_selection import KFold\n\n    from autoflow import AutoFlowClassifier\n\n    # load data from csv file\n    train_df = pd.read_csv(\"../data/train_classification.csv\")\n    test_df = pd.read_csv(\"../data/test_classification.csv\")\n    # initial_runs  -- initial runs are totally random search, to provide experience for SMAC algorithm.\n    # run_limit     -- is the maximum number of runs.\n    # n_jobs        -- defines how many search processes are started.\n    # included_classifiers -- restrict the search space . lightgbm is the only classifier that needs to be selected\n    # per_run_time_limit -- restrict the run time. if a trial during 60 seconds, it is expired, should be killed.\n    trained_pipeline = AutoFlowClassifier(initial_runs=5, run_limit=10, n_jobs=1, included_classifiers=[\"lightgbm\"],\n                                        per_run_time_limit=60)\n    # describing meaning of columns. `id`, `target` and `ignore` all has specific meaning\n    # `id` is a column name means unique descriptor of each rows,\n    # `target` column in the dataset is what your model will learn to predict\n    # `ignore` is some columns which contains irrelevant information\n    column_descriptions = {\n        \"id\": \"PassengerId\",\n        \"target\": \"Survived\",\n        \"ignore\": \"Name\"\n    }\n    if not os.path.exists(\"autoflow_classification.bz2\"):\n        # pass `train_df`, `test_df` and `column_descriptions` to classifier,\n        # if param `fit_ensemble_params` set as \"auto\", Stack Ensemble will be used\n        # ``splitter`` is train-valid-dataset splitter, in here it is set as 3-Fold Cross Validation\n        trained_pipeline.fit(\n            X_train=train_df, X_test=test_df, column_descriptions=column_descriptions,\n            fit_ensemble_params=False,\n            splitter=KFold(n_splits=3, shuffle=True, random_state=42),\n        )\n        # finally , the best model will be serialize and store in local file system for subsequent use\n        joblib.dump(trained_pipeline, \"autoflow_classification.bz2\")\n        # if you want to see what the workflow AutoFlow is searching, you can use `draw_workflow_space` to visualize\n        hdl_constructor = trained_pipeline.hdl_constructors[0]\n        hdl_constructor.draw_workflow_space()\n    # suppose you are processing predict procedure, firstly, you should load serialized model from file system\n    predict_pipeline = joblib.load(\"autoflow_classification.bz2\")\n    # secondly, use loaded model to do predicting\n    result = predict_pipeline.predict(test_df)\n    print(result)",
    "description_content_type": "text/x-rst",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/auto-flow/autoflow",
    "keywords": "",
    "license": "BSD",
    "maintainer": "",
    "maintainer_email": "",
    "name": "auto-flow",
    "package_url": "https://pypi.org/project/auto-flow/",
    "platform": "Linux",
    "project_url": "https://pypi.org/project/auto-flow/",
    "project_urls": {
      "Homepage": "https://github.com/auto-flow/autoflow"
    },
    "release_url": "https://pypi.org/project/auto-flow/0.1.1/",
    "requires_dist": null,
    "requires_python": ">=3.6.*",
    "summary": "AutoFlow: Automatic machine learning workflow modeling platform.",
    "version": "0.1.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 7031808,
  "releases": {
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fdc10eaa7dc382458e6a29d7883394d28aae5fd2615d59747b6d4278438950ba",
          "md5": "92296da1bbd06e4de489c06833c24a79",
          "sha256": "3dd795cdc984b282a412c92862ef2c91a96d2670b8d1db6e51207bb64cf6f18a"
        },
        "downloads": -1,
        "filename": "auto-flow-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "92296da1bbd06e4de489c06833c24a79",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6.*",
        "size": 193200,
        "upload_time": "2020-04-16T12:24:45",
        "upload_time_iso_8601": "2020-04-16T12:24:45.694618Z",
        "url": "https://files.pythonhosted.org/packages/fd/c1/0eaa7dc382458e6a29d7883394d28aae5fd2615d59747b6d4278438950ba/auto-flow-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "fdc10eaa7dc382458e6a29d7883394d28aae5fd2615d59747b6d4278438950ba",
        "md5": "92296da1bbd06e4de489c06833c24a79",
        "sha256": "3dd795cdc984b282a412c92862ef2c91a96d2670b8d1db6e51207bb64cf6f18a"
      },
      "downloads": -1,
      "filename": "auto-flow-0.1.1.tar.gz",
      "has_sig": false,
      "md5_digest": "92296da1bbd06e4de489c06833c24a79",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6.*",
      "size": 193200,
      "upload_time": "2020-04-16T12:24:45",
      "upload_time_iso_8601": "2020-04-16T12:24:45.694618Z",
      "url": "https://files.pythonhosted.org/packages/fd/c1/0eaa7dc382458e6a29d7883394d28aae5fd2615d59747b6d4278438950ba/auto-flow-0.1.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}