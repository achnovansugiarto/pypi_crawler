{
  "info": {
    "author": "Intel AIA/AIPC Team",
    "author_email": "feng.tian@intel.com, haihao.shen@intel.com,hanwen.chang@intel.com, penghui.cheng@intel.com",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: Apache Software License",
      "Programming Language :: Python :: 3",
      "Topic :: Scientific/Engineering :: Artificial Intelligence"
    ],
    "description": "# Intel® Extension for Transformers: Accelerating Transformer-based Models on Intel Platforms\nIntel® Extension for Transformers is an innovative toolkit to accelerate Transformer-based models on Intel platforms. The toolkit helps developers to improve the productivity through ease-of-use model compression APIs by extending Hugging Face transformers APIs. The compression infrastructure leverages Intel® Neural Compressor which provides a rich set of model compression techniques: quantization, pruning, distillation and so on. The toolkit provides Transformers-accelerated Libraries and Neural Engine to demonstrate the performance of extremely compressed models, and therefore significantly improve the inference efficiency on Intel platforms. Some of the key features have been published in NeurIPS 2021 and 2022.\n\n## What does Intel® Extension for Transformers offer?\nThis toolkit helps developers to improve the productivity of inference deployment by extending Hugging Face transformers APIs for Transformer-based models in natural language processing (NLP) domain. With extremely compressed models, the toolkit can greatly improve the inference efficiency on Intel platforms.\n\n- Model Compression\n\n    |Framework          |Quantization |Pruning/Sparsity |Distillation |Neural Architecture Search |\n    |-------------------|:-----------:|:---------------:|:-----------:|:-------------------------:|\n    |PyTorch            |&#10004;     |&#10004;         |&#10004;     |&#10004;                   |\n    |TensorFlow         |&#10004;     |&#10004;         |&#10004;     |Stay tuned :star:          |\n\n- Data Augmentation for NLP Datasets\n- Transformers-accelerated Neural Engine\n- Transformers-accelerated Libraries\n- Domain Algorithms\n    |Length Adaptive Transformer |\n    |:--------------------------:|\n    |PyTorch &#10004;            |\n\n- Architecture of Intel® Extension for Transformers\n<img src=\"docs/imgs/arch.png\" width=691 height=444 alt=\"arch\">\n</br>\n\n\n## Documentation\n<table>\n<thead>\n  <tr>\n    <th colspan=\"6\" align=\"center\">OVERVIEW</th>\n  </tr>\n</thead>\n<tbody>\n  <tr>\n    <td align=\"center\"><a href=\"https://github.com/intel/intel-extension-for-transformers/tree/main/docs\">Model&nbsp;&nbsp;&nbsp;Compression</a></td>\n    <td colspan=\"2\" align=\"center\"><a href=\"https://github.com/intel/intel-extension-for-transformers/tree/main/intel_extension_for_transformers/backends/neural_engine/docs\">Transformers-accelerated&nbsp;&nbsp;&nbsp;Neural Engine</a></td>\n    <td colspan=\"2\" align=\"center\"><a href=\"intel_extension_for_transformers/backends/neural_engine/kernels/README.md\">Transformers-accelerated&nbsp;&nbsp;&nbsp;Libraries</a></td>\n    <td align=\"center\"><a href=\"https://github.com/intel/intel-extension-for-transformers/tree/main/examples\">Examples</a></td>\n  </tr>\n  <tr>\n    <th colspan=\"6\" align=\"center\">BASIC API</th>\n  </tr>\n  <tr>\n    <td align=\"center\"><a href=\"docs/export.md\">Export</a></td>\n    <td align=\"center\"><a href=\"docs/metrics.md\">Metric</a></td>\n    <td align=\"center\"><a href=\"docs/pipeline.md\">Pipeline</a></td>\n    <td align=\"center\"><a href=\"docs/objectives.md\">Objective</a></td>\n    <td align=\"center\" colspan=\"2\"><a href=\"docs/data_augmentation.md\">Data Augmentation</a></td>\n  </tr>\n  <tr>\n    <td colspan=\"2\" align=\"center\"><a href=\"intel_extension_for_transformers/backends/neural_engine/docs/onnx_compile.md\">Compile (ONNX/TensorFlow)</a></td>\n    <td colspan=\"2\" align=\"center\"><a href=\"intel_extension_for_transformers/backends/neural_engine/docs/Deploy and Integration.md\">Deploy and Integration</a></td>\n    <td colspan=\"2\" align=\"center\"><a href=\"intel_extension_for_transformers/backends/neural_engine/docs/add_customized_pattern.md\">Add Customize pattern</a></td>\n  </tr>\n  <tr>\n    <th colspan=\"6\" align=\"center\">DEEP DIVE</th>\n  </tr>\n  <tr>\n    <td align=\"center\"><a href=\"docs/quantization.md\">Quantization</a></td>\n    <td align=\"center\"><a href=\"docs/pruning.md\">Pruning</a></td>\n    <td align=\"center\" colspan=\"2\"><a href=\"docs/distillation.md\">Distillation</a></td>\n    <td align=\"center\" colspan=\"2\"><a href=\"https://github.com/intel/intel-extension-for-transformers/blob/main/examples/optimization/pytorch/huggingface/text-classification/orchestrate_optimizations/README.md\">Orchestration</a></td>\n  </tr>\n  <tr>\n    <td align=\"center\" colspan=\"3\"><a href=\"intel_extension_for_transformers/backends/neural_engine\">Transformers-accelerated&nbsp;Neural Engine</a></td>\n    <td align=\"center\" colspan=\"3\"><a href=\"https://github.com/intel/intel-extension-for-transformers/tree/main/intel_extension_for_transformers/backends/neural_engine/kernels/docs/kernel_desc\">Kernels (AMX/AVX/VNNI)</a></td>\n  </tr>\n  <tr>\n    <th colspan=\"6\" align=\"center\">ADVANCED ALGORITHM</th>\n  </tr>\n  <tr>\n    <td align=\"center\" colspan=\"2\"><a href=\"https://github.com/intel/intel-extension-for-transformers/blob/main/examples/optimization/pytorch/huggingface/question-answering/dynamic/README.md\">Length Adaptive</a></td>\n    <td align=\"center\" colspan=\"2\"><a href=\"https://github.com/intel/intel-extension-for-transformers/tree/main/examples/optimization/pytorch/huggingface/language-modeling/auto_distillation\">NAS (Auto Distillation)</a></td>\n    <td align=\"center\" colspan=\"2\"><a href=\"\">Set Fit</a></td>\n  </tr>\n  <tr>\n    <th colspan=\"3\" align=\"center\">PROFILING AND BENCHMARK</a></th>\n    <th colspan=\"3\" align=\"center\">VALIDATED MODELS AND DATA</th>\n  </tr>\n  <tr>\n    <td align=\"center\"><a href=\"docs/benchmark.md\">Model Compression</a></td>\n    <td align=\"center\"><a href=\"intel_extension_for_transformers/backends/neural_engine/docs/profiling.md\">Transformers-accelerated&nbsp;Neural Engine</a></td>\n    <td align=\"center\">Transformers-accelerated&nbsp;Libraries <a href=\"https://github.com/intel/intel-extension-for-transformers/tree/main/  intel_extension_for_transformers/backends/neural_engine/kernels/docs/\">Profiling</a>/ <a href=\"https://github.com/intel/intel-extension-for-transformers/tree/main/  intel_extension_for_transformers/backends/neural_engine/kernels/docs/\">Benchmark</  a></td>\n    <td align=\"center\"><a href=\"docs/examples.md\">Supported Models</a></td>\n    <td align=\"center\"><a href=\"intel_extension_for_transformers/backends/neural_engine/docs/validated_model.md\">Sparse Aware Inference</a></td>\n    <td align=\"center\"><a href=\"intel_extension_for_transformers/backends/neural_engine/kernels/docs/validated_data.md\">Sparse Kernel Data</a></td>\n  </tr>\n  <tr>\n    <td colspan=\"6\" align=\"center\"><a href=\"https://github.com/intel/intel-extension-for-transformers/tree/main/docs/tutorials/pytorch\">TUTORIALS</a></td>\n  </tr>\n</tbody>\n</table>\n\n\n## Installation\n### Release Binary Install\n```bash\npip install intel-extension-for-transformers\n```\n\n### Install From Source\n#### Install Intel® Extension for Transformers\n```bash\ngit clone https://github.com/intel/intel-extension-for-transformers.git intel_extension_for_transformers\ncd intel_extension_for_transformers\n# Install Dependency\npip install -r requirements.txt\ngit submodule update --init --recursive\n# Install intel_extension_for_transformers\npython setup.py install\n```\n\n## Getting Started\n### Quantization\n```python\nfrom intel_extension_for_transformers import QuantizationConfig, metric, objectives\nfrom intel_extension_for_transformers.optimization.trainer import NLPTrainer\n\n# Replace transformers.Trainer with NLPTrainer\n# trainer = transformers.Trainer(...)\ntrainer = NLPTrainer(...)\nmetric = metrics.Metric(name=\"eval_f1\", is_relative=True, criterion=0.01)\nq_config = QuantizationConfig(\n    approach=\"PostTrainingStatic\",\n    metrics=[metric],\n    objectives=[objectives.performance]\n)\nmodel = trainer.quantize(quant_config=q_config)\n```\n\nPlease refer to [quantization document](docs/quantization.md) for more details.\n\n### Pruning\n```python\nfrom intel_extension_for_transformers import PrunerConfig, PruningConfig\nfrom intel_extension_for_transformers.optimization.trainer import NLPTrainer\n\n# Replace transformers.Trainer with NLPTrainer\n# trainer = transformers.Trainer(...)\ntrainer = NLPTrainer(...)\nmetric = metrics.Metric(name=\"eval_accuracy\")\npruner_config = PrunerConfig(prune_type='BasicMagnitude', target_sparsity_ratio=0.9)\np_conf = PruningConfig(pruner_config=[pruner_config], metrics=metric)\nmodel = trainer.prune(pruning_config=p_conf)\n```\n\nPlease refer to [pruning document](docs/pruning.md) for more details.\n\n### Distillation\n```python\nfrom intel_extension_for_transformers import DistillationConfig, Criterion\nfrom intel_extension_for_transformers.optimization.trainer import NLPTrainer\n\n# Replace transformers.Trainer with NLPTrainer\n# trainer = transformers.Trainer(...)\nteacher_model = ... # exist model\ntrainer = NLPTrainer(...)\nmetric = metrics.Metric(name=\"eval_accuracy\")\nd_conf = DistillationConfig(metrics=metric)\nmodel = trainer.distill(distillation_config=d_conf, teacher_model=teacher_model)\n```\n\nPlease refer to [distillation document](docs/distillation.md) for more details.\n\n### Data Augmentation\nData augmentation provides the facilities to generate synthesized NLP dataset for further model optimization. The data augmentation supports text generation on popular fine-tuned models like GPT, GPT2, and other text synthesis approaches from [nlpaug](https://github.com/makcedward/nlpaug).\n\n```python\nfrom intel_extension_for_transformers.preprocessing.data_augmentation import DataAugmentation\naug = DataAugmentation(augmenter_type=\"TextGenerationAug\")\naug.input_dataset = \"original_dataset.csv\" # example: https://huggingface.co/datasets/glue/viewer/sst2/train\naug.column_names = \"sentence\"\naug.output_path = os.path.join(self.result_path, \"test2.cvs\")\naug.augmenter_arguments = {'model_name_or_path': 'gpt2-medium'}\naug.data_augment()\nraw_datasets = load_dataset(\"csv\", data_files=aug.output_path, delimiter=\"\\t\", split=\"train\")\n```\n\nPlease refer to [data augmentation document](docs/data_augmentation.md) for more details.\n\n### Neural Engine\nNeural Engine is one of reference deployments that Intel Extension for Transformers provides. Neural Engine aims to demonstrate the optimal performance of extremely compressed NLP models by exploring the optimization opportunities from both HW and SW.\n\n```python\nfrom intel_extension_for_transformers.backends.neural_engine.compile import compile\n# /path/to/your/model is a TensorFlow pb model or ONNX model\nmodel = compile('/path/to/your/model')\ninputs = ... # [input_ids, segment_ids, input_mask]\nmodel.inference(inputs)\n```\n\nPlease refer to [Neural Engine](examples/deployment/) for more details.\n\n### Quantized Length Adaptive Transformer\nQuantized Length Adaptive Transformer leverages sequence-length reduction and low-bit representation techniques to further enhance model inference performance, enabling adaptive sequence-length sizes to accommodate different computational budget requirements with an optimal accuracy efficiency tradeoff.\n```python\nfrom intel_extension_for_transformers import QuantizationConfig, DynamicLengthConfig, metric, objectives\nfrom intel_extension_for_transformers.optimization.trainer import NLPTrainer\n\n# Replace transformers.Trainer with NLPTrainer\n# trainer = transformers.Trainer(...)\ntrainer = NLPTrainer(...)\nmetric = metrics.Metric(name=\"eval_f1\", is_relative=True, criterion=0.01)\nq_config = QuantizationConfig(\n    approach=\"PostTrainingStatic\",\n    metrics=[metric],\n    objectives=[objectives.performance]\n)\n# Apply the length config\ndynamic_length_config = DynamicLengthConfig(length_config=length_config)\ntrainer.set_dynamic_config(dynamic_config=dynamic_length_config)\n# Quantization\nmodel = trainer.quantize(quant_config=q_config)\n```\n\nPlease refer to paper [QuaLA-MiniLM](https://arxiv.org/pdf/2210.17114.pdf) and [code](examples/optimization/pytorch/huggingface/question-answering/dynamic) for details\n\n\n### Transformers-accelerated Neural Engine\nTransformers-accelerated Neural Engine is one of reference deployments that Intel® Extension for Transformers provides. Neural Engine aims to demonstrate the optimal performance of extremely compressed NLP models by exploring the optimization opportunities from both HW and SW.\n\n```python\nfrom intel_extension_for_transformers.backends.neural_engine.compile import compile\n# /path/to/your/model is a TensorFlow pb model or ONNX model\nmodel = compile('/path/to/your/model')\ninputs = ... # [input_ids, segment_ids, input_mask]\nmodel.inference(inputs)\n```\n\nPlease refer to [example](examples/deployment/neural_engine/sparse/distilbert_base_uncased/) in [Transformers-accelerated Neural Engine](examples/deployment/) and paper [Fast Distilbert on CPUs](https://arxiv.org/abs/2211.07715) for more details.\n\n### Transformers-accelerated Libraries\nTransformers-accelerated Libraries is a high-performance operator computing library implemented by assembly. Transformers-accelerated Libraries contains a JIT domain, a kernel domain, and a scheduling proxy framework.\n\n```C++\n#include \"interface.hpp\"\n  ...\n  operator_desc op_desc(ker_kind, ker_prop, eng_kind, ts_descs, op_attrs);\n  sparse_matmul_desc spmm_desc(op_desc);\n  sparse_matmul spmm_kern(spmm_desc);\n  std::vector<const void*> rt_data = {data0, data1, data2, data3, data4};\n  spmm_kern.execute(rt_data);\n```\nPlease refer to [Transformers-accelerated Libraries](intel_extension_for_transformers/backends/neural_engine/kernels/README.md) for more details.\n\n\n## System Requirements\n### Validated Hardware Environment\nIntel® Extension for Transformers supports systems based on [Intel 64 architecture or compatible processors](https://en.wikipedia.org/wiki/X86-64) that are specifically optimized for the following CPUs:\n\n* Intel Xeon Scalable processor (formerly Cascade Lake, Icelake)\n* Future Intel Xeon Scalable processor (code name Sapphire Rapids)\n\n### Validated Software Environment\n\n* OS version: CentOS 8.4, Ubuntu 20.04  \n* Python version: 3.7, 3.8, 3.9, 3.10  \n\n<table class=\"docutils\">\n<thead>\n  <tr>\n    <th>Framework</th>\n    <th>TensorFlow</th>\n    <th>Intel TensorFlow</th>\n    <th>PyTorch</th>\n    <th>IPEX</th>\n  </tr>\n</thead>\n<tbody>\n  <tr align=\"center\">\n    <th>Version</th>\n    <td class=\"tg-7zrl\"><a href=https://github.com/tensorflow/tensorflow/tree/v2.10.0>2.10.0</a><br>\n    <a href=https://github.com/tensorflow/tensorflow/tree/v2.9.1>2.9.1</a><br>\n    <td class=\"tg-7zrl\"><a href=https://github.com/Intel-tensorflow/tensorflow/tree/v2.10.0>2.10.0</a><br>\n    <a href=https://github.com/Intel-tensorflow/tensorflow/tree/v2.9.1>2.9.1</a><br>\n    <td class=\"tg-7zrl\"><a href=https://download.pytorch.org/whl/torch_stable.html>1.13.0+cpu</a><br>\n    <a href=https://download.pytorch.org/whl/torch_stable.html>1.12.0+cpu</a><br>\n    <td class=\"tg-7zrl\"><a href=https://github.com/intel/intel-extension-for-pytorch/tree/1.11.0>1.13.0</a><br>\n    <a href=https://github.com/intel/intel-extension-for-pytorch/tree/v1.10.0>1.12.0</a></td>\n  </tr>\n</tbody>\n</table>\n\n\n## Selected Publications/Events\n* NeurIPS'2022: [Fast Distilbert on CPUs](https://arxiv.org/abs/2211.07715) (Nov 2022)\n* NeurIPS'2022: [QuaLA-MiniLM: a Quantized Length Adaptive MiniLM](https://arxiv.org/abs/2210.17114) (Nov 2022)\n* Blog published by Cohere: [Top NLP Papers—November 2022](https://txt.cohere.ai/top-nlp-papers-november-2022/) (Nov 2022)\n* Blog published by Alibaba: [Deep learning inference optimization for Address Purification](https://zhuanlan.zhihu.com/p/552484413) (Aug 2022)\n* NeurIPS'2021: [Prune Once for All: Sparse Pre-Trained Language Models](https://arxiv.org/abs/2111.05754) (Nov 2021)\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/intel/",
    "keywords": "quantization,auto-tuning,post-training static quantization,post-training dynamic quantization,quantization-aware training,tuning strategy",
    "license": "Apache 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "intel-extension-for-transformers",
    "package_url": "https://pypi.org/project/intel-extension-for-transformers/",
    "platform": null,
    "project_url": "https://pypi.org/project/intel-extension-for-transformers/",
    "project_urls": {
      "Homepage": "https://github.com/intel/"
    },
    "release_url": "https://pypi.org/project/intel-extension-for-transformers/1.0b0/",
    "requires_dist": [
      "numpy",
      "transformers (>=4.12.0)",
      "packaging"
    ],
    "requires_python": ">=3.7.0",
    "summary": "Repository of Intel® Intel Extension for Transformers",
    "version": "1.0b0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16063269,
  "releases": {
    "1.0a0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ce71f5afa8fb9c1f649dc2515b1bceeb2e9652afdb5141e8fce0cf320a4b8b2a",
          "md5": "d071e37c207760f317ff50c517ce9e91",
          "sha256": "ef837615978662a907f9ed032a8019070df048ac8ce0f2ccb4f122975d4949b4"
        },
        "downloads": -1,
        "filename": "intel_extension_for_transformers-1.0a0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl",
        "has_sig": false,
        "md5_digest": "d071e37c207760f317ff50c517ce9e91",
        "packagetype": "bdist_wheel",
        "python_version": "cp310",
        "requires_python": ">=3.7.0",
        "size": 37373687,
        "upload_time": "2022-11-24T02:45:28",
        "upload_time_iso_8601": "2022-11-24T02:45:28.352620Z",
        "url": "https://files.pythonhosted.org/packages/ce/71/f5afa8fb9c1f649dc2515b1bceeb2e9652afdb5141e8fce0cf320a4b8b2a/intel_extension_for_transformers-1.0a0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "55139f345f716a00fd32a03aa6a684a09a6af987833204fc91c78ed5ea382a39",
          "md5": "0110eb343aa6efbdbe8fdc1e73471db9",
          "sha256": "ac4f75446b9aefeb1829b3d57a00d040da9b73a3fcab0fb032571c94caaad738"
        },
        "downloads": -1,
        "filename": "intel_extension_for_transformers-1.0a0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl",
        "has_sig": false,
        "md5_digest": "0110eb343aa6efbdbe8fdc1e73471db9",
        "packagetype": "bdist_wheel",
        "python_version": "cp37",
        "requires_python": ">=3.7.0",
        "size": 37375926,
        "upload_time": "2022-11-24T02:24:34",
        "upload_time_iso_8601": "2022-11-24T02:24:34.332544Z",
        "url": "https://files.pythonhosted.org/packages/55/13/9f345f716a00fd32a03aa6a684a09a6af987833204fc91c78ed5ea382a39/intel_extension_for_transformers-1.0a0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "86ea8b79326381a03c32ead4a8ff4669a193a3358a8f2fca5709b22d50a4f7e7",
          "md5": "630df57e14bef2713d1c68dc4a5b9492",
          "sha256": "7c83d538e4f719a92a01a5cbd113a51cb8050de10f2cd79936ba4962918ec33f"
        },
        "downloads": -1,
        "filename": "intel_extension_for_transformers-1.0a0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl",
        "has_sig": false,
        "md5_digest": "630df57e14bef2713d1c68dc4a5b9492",
        "packagetype": "bdist_wheel",
        "python_version": "cp38",
        "requires_python": ">=3.7.0",
        "size": 37657345,
        "upload_time": "2022-11-23T15:53:03",
        "upload_time_iso_8601": "2022-11-23T15:53:03.253630Z",
        "url": "https://files.pythonhosted.org/packages/86/ea/8b79326381a03c32ead4a8ff4669a193a3358a8f2fca5709b22d50a4f7e7/intel_extension_for_transformers-1.0a0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6f12603ac40e63bbb10723d120d2627ad1c88ed068ac252b5c965981d9d421af",
          "md5": "8f7e7700aaed43ed8b8dfbf62fa50daf",
          "sha256": "87f6a38df6d809dcd727dbf5b0481b427b608fa1e580131e4cb929d2fd618ea7"
        },
        "downloads": -1,
        "filename": "intel_extension_for_transformers-1.0a0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl",
        "has_sig": false,
        "md5_digest": "8f7e7700aaed43ed8b8dfbf62fa50daf",
        "packagetype": "bdist_wheel",
        "python_version": "cp39",
        "requires_python": ">=3.7.0",
        "size": 37373666,
        "upload_time": "2022-11-24T02:37:03",
        "upload_time_iso_8601": "2022-11-24T02:37:03.976188Z",
        "url": "https://files.pythonhosted.org/packages/6f/12/603ac40e63bbb10723d120d2627ad1c88ed068ac252b5c965981d9d421af/intel_extension_for_transformers-1.0a0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c1cc4f7d1fe237f2fc0f67719e627a6a13805d17f7a74bb6b1b573dcd96fa422",
          "md5": "cfef24c03f580d18e0de71c4ca748981",
          "sha256": "4788e5bb3537daadfb04b8910b1fd6e5e28c8b7b919be7c63f58d354e7e7d8d1"
        },
        "downloads": -1,
        "filename": "intel_extension_for_transformers-1.0a0.tar.gz",
        "has_sig": false,
        "md5_digest": "cfef24c03f580d18e0de71c4ca748981",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7.0",
        "size": 151586,
        "upload_time": "2022-11-23T15:53:06",
        "upload_time_iso_8601": "2022-11-23T15:53:06.165181Z",
        "url": "https://files.pythonhosted.org/packages/c1/cc/4f7d1fe237f2fc0f67719e627a6a13805d17f7a74bb6b1b573dcd96fa422/intel_extension_for_transformers-1.0a0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0b0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4ecbafd4784c0bcd73b0e029fa3e03c85f9feaea15e222d6d5e78ee9fea56172",
          "md5": "733280ebbfaff6c0ce43b8d603bd9e9c",
          "sha256": "93d328db15a5483c62e21b3ebf2ca94ec50474ac37e3037db904529ebf32b53c"
        },
        "downloads": -1,
        "filename": "intel_extension_for_transformers-1.0b0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl",
        "has_sig": false,
        "md5_digest": "733280ebbfaff6c0ce43b8d603bd9e9c",
        "packagetype": "bdist_wheel",
        "python_version": "cp37",
        "requires_python": ">=3.7.0",
        "size": 50068384,
        "upload_time": "2022-12-11T05:53:32",
        "upload_time_iso_8601": "2022-12-11T05:53:32.642636Z",
        "url": "https://files.pythonhosted.org/packages/4e/cb/afd4784c0bcd73b0e029fa3e03c85f9feaea15e222d6d5e78ee9fea56172/intel_extension_for_transformers-1.0b0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9d0c1fa3b030045bf7d985491d2b35b3ca644a685edbc8c031fcd3a7fbfe230d",
          "md5": "be6ed2fb256e2b31aa9d22c35bf43108",
          "sha256": "8146958214f117f4a060f4da6581701cfba93a3f16508fdc3a04d2015efd4619"
        },
        "downloads": -1,
        "filename": "intel_extension_for_transformers-1.0b0-cp37-cp37m-win_amd64.whl",
        "has_sig": false,
        "md5_digest": "be6ed2fb256e2b31aa9d22c35bf43108",
        "packagetype": "bdist_wheel",
        "python_version": "cp37",
        "requires_python": ">=3.7.0",
        "size": 8471294,
        "upload_time": "2022-12-11T08:06:05",
        "upload_time_iso_8601": "2022-12-11T08:06:05.783828Z",
        "url": "https://files.pythonhosted.org/packages/9d/0c/1fa3b030045bf7d985491d2b35b3ca644a685edbc8c031fcd3a7fbfe230d/intel_extension_for_transformers-1.0b0-cp37-cp37m-win_amd64.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0bd2ac4ebb62cbc3d568b4fc09af0326a5d87dacfeb5688fcdf4755fcfb301c8",
          "md5": "195af2884c45bc1f96a3833228e3e38b",
          "sha256": "1c0d8681add93df29c88752e9bf994c37c529f8dc0b422ed83618707107f75a8"
        },
        "downloads": -1,
        "filename": "intel_extension_for_transformers-1.0b0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl",
        "has_sig": false,
        "md5_digest": "195af2884c45bc1f96a3833228e3e38b",
        "packagetype": "bdist_wheel",
        "python_version": "cp38",
        "requires_python": ">=3.7.0",
        "size": 50062159,
        "upload_time": "2022-12-11T05:29:12",
        "upload_time_iso_8601": "2022-12-11T05:29:12.176662Z",
        "url": "https://files.pythonhosted.org/packages/0b/d2/ac4ebb62cbc3d568b4fc09af0326a5d87dacfeb5688fcdf4755fcfb301c8/intel_extension_for_transformers-1.0b0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "20dadd7b867e096a90703cc7edafab07bd89af90972db9a7577abc9b4f6f5c74",
          "md5": "71b1a79dd80d9c25b2875054b6f33159",
          "sha256": "1da84b1d7e6900dc0311f09a159748e8a44aa484b2f83d8a02835ada6340d839"
        },
        "downloads": -1,
        "filename": "intel_extension_for_transformers-1.0b0-cp38-cp38-win_amd64.whl",
        "has_sig": false,
        "md5_digest": "71b1a79dd80d9c25b2875054b6f33159",
        "packagetype": "bdist_wheel",
        "python_version": "cp38",
        "requires_python": ">=3.7.0",
        "size": 8471793,
        "upload_time": "2022-12-11T07:52:15",
        "upload_time_iso_8601": "2022-12-11T07:52:15.478234Z",
        "url": "https://files.pythonhosted.org/packages/20/da/dd7b867e096a90703cc7edafab07bd89af90972db9a7577abc9b4f6f5c74/intel_extension_for_transformers-1.0b0-cp38-cp38-win_amd64.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "75fc1b65ecd8ea903eaad7dd50e55857c9d3e859e215f637eaee2e7ce4fbf99b",
          "md5": "86aab87419171f279a9a8622018ac79d",
          "sha256": "48d85d4ec3af6f7d58b7762dea3c653acaf465911574958a2f3f24f5bb7c9d08"
        },
        "downloads": -1,
        "filename": "intel_extension_for_transformers-1.0b0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl",
        "has_sig": false,
        "md5_digest": "86aab87419171f279a9a8622018ac79d",
        "packagetype": "bdist_wheel",
        "python_version": "cp39",
        "requires_python": ">=3.7.0",
        "size": 50064881,
        "upload_time": "2022-12-11T06:10:53",
        "upload_time_iso_8601": "2022-12-11T06:10:53.360520Z",
        "url": "https://files.pythonhosted.org/packages/75/fc/1b65ecd8ea903eaad7dd50e55857c9d3e859e215f637eaee2e7ce4fbf99b/intel_extension_for_transformers-1.0b0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7b42a0be821b4e626a666151e207e8e577c28603411d843d0e9e192731bd78e5",
          "md5": "f1cb00b652cf21191ba3f9a1d57ed388",
          "sha256": "0b0645fc5047230aef9b42f14e0b570889019d204481bef40a42810129ac21d3"
        },
        "downloads": -1,
        "filename": "intel_extension_for_transformers-1.0b0-cp39-cp39-win_amd64.whl",
        "has_sig": false,
        "md5_digest": "f1cb00b652cf21191ba3f9a1d57ed388",
        "packagetype": "bdist_wheel",
        "python_version": "cp39",
        "requires_python": ">=3.7.0",
        "size": 8471942,
        "upload_time": "2022-12-11T08:01:19",
        "upload_time_iso_8601": "2022-12-11T08:01:19.191181Z",
        "url": "https://files.pythonhosted.org/packages/7b/42/a0be821b4e626a666151e207e8e577c28603411d843d0e9e192731bd78e5/intel_extension_for_transformers-1.0b0-cp39-cp39-win_amd64.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fa8d019475c55d457e305ccbdb608d4af00f08bac60120fe6dfc53bac19f9e47",
          "md5": "17c0130c1329b8d4419862a2c7710d3f",
          "sha256": "2022027c4f5db1335266a802528102fe2126141d37f4d0a191d8cd7a18cbf4a4"
        },
        "downloads": -1,
        "filename": "intel_extension_for_transformers-1.0b0.tar.gz",
        "has_sig": false,
        "md5_digest": "17c0130c1329b8d4419862a2c7710d3f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7.0",
        "size": 179885,
        "upload_time": "2022-12-11T05:29:15",
        "upload_time_iso_8601": "2022-12-11T05:29:15.238257Z",
        "url": "https://files.pythonhosted.org/packages/fa/8d/019475c55d457e305ccbdb608d4af00f08bac60120fe6dfc53bac19f9e47/intel_extension_for_transformers-1.0b0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "4ecbafd4784c0bcd73b0e029fa3e03c85f9feaea15e222d6d5e78ee9fea56172",
        "md5": "733280ebbfaff6c0ce43b8d603bd9e9c",
        "sha256": "93d328db15a5483c62e21b3ebf2ca94ec50474ac37e3037db904529ebf32b53c"
      },
      "downloads": -1,
      "filename": "intel_extension_for_transformers-1.0b0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl",
      "has_sig": false,
      "md5_digest": "733280ebbfaff6c0ce43b8d603bd9e9c",
      "packagetype": "bdist_wheel",
      "python_version": "cp37",
      "requires_python": ">=3.7.0",
      "size": 50068384,
      "upload_time": "2022-12-11T05:53:32",
      "upload_time_iso_8601": "2022-12-11T05:53:32.642636Z",
      "url": "https://files.pythonhosted.org/packages/4e/cb/afd4784c0bcd73b0e029fa3e03c85f9feaea15e222d6d5e78ee9fea56172/intel_extension_for_transformers-1.0b0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "9d0c1fa3b030045bf7d985491d2b35b3ca644a685edbc8c031fcd3a7fbfe230d",
        "md5": "be6ed2fb256e2b31aa9d22c35bf43108",
        "sha256": "8146958214f117f4a060f4da6581701cfba93a3f16508fdc3a04d2015efd4619"
      },
      "downloads": -1,
      "filename": "intel_extension_for_transformers-1.0b0-cp37-cp37m-win_amd64.whl",
      "has_sig": false,
      "md5_digest": "be6ed2fb256e2b31aa9d22c35bf43108",
      "packagetype": "bdist_wheel",
      "python_version": "cp37",
      "requires_python": ">=3.7.0",
      "size": 8471294,
      "upload_time": "2022-12-11T08:06:05",
      "upload_time_iso_8601": "2022-12-11T08:06:05.783828Z",
      "url": "https://files.pythonhosted.org/packages/9d/0c/1fa3b030045bf7d985491d2b35b3ca644a685edbc8c031fcd3a7fbfe230d/intel_extension_for_transformers-1.0b0-cp37-cp37m-win_amd64.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "0bd2ac4ebb62cbc3d568b4fc09af0326a5d87dacfeb5688fcdf4755fcfb301c8",
        "md5": "195af2884c45bc1f96a3833228e3e38b",
        "sha256": "1c0d8681add93df29c88752e9bf994c37c529f8dc0b422ed83618707107f75a8"
      },
      "downloads": -1,
      "filename": "intel_extension_for_transformers-1.0b0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl",
      "has_sig": false,
      "md5_digest": "195af2884c45bc1f96a3833228e3e38b",
      "packagetype": "bdist_wheel",
      "python_version": "cp38",
      "requires_python": ">=3.7.0",
      "size": 50062159,
      "upload_time": "2022-12-11T05:29:12",
      "upload_time_iso_8601": "2022-12-11T05:29:12.176662Z",
      "url": "https://files.pythonhosted.org/packages/0b/d2/ac4ebb62cbc3d568b4fc09af0326a5d87dacfeb5688fcdf4755fcfb301c8/intel_extension_for_transformers-1.0b0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "20dadd7b867e096a90703cc7edafab07bd89af90972db9a7577abc9b4f6f5c74",
        "md5": "71b1a79dd80d9c25b2875054b6f33159",
        "sha256": "1da84b1d7e6900dc0311f09a159748e8a44aa484b2f83d8a02835ada6340d839"
      },
      "downloads": -1,
      "filename": "intel_extension_for_transformers-1.0b0-cp38-cp38-win_amd64.whl",
      "has_sig": false,
      "md5_digest": "71b1a79dd80d9c25b2875054b6f33159",
      "packagetype": "bdist_wheel",
      "python_version": "cp38",
      "requires_python": ">=3.7.0",
      "size": 8471793,
      "upload_time": "2022-12-11T07:52:15",
      "upload_time_iso_8601": "2022-12-11T07:52:15.478234Z",
      "url": "https://files.pythonhosted.org/packages/20/da/dd7b867e096a90703cc7edafab07bd89af90972db9a7577abc9b4f6f5c74/intel_extension_for_transformers-1.0b0-cp38-cp38-win_amd64.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "75fc1b65ecd8ea903eaad7dd50e55857c9d3e859e215f637eaee2e7ce4fbf99b",
        "md5": "86aab87419171f279a9a8622018ac79d",
        "sha256": "48d85d4ec3af6f7d58b7762dea3c653acaf465911574958a2f3f24f5bb7c9d08"
      },
      "downloads": -1,
      "filename": "intel_extension_for_transformers-1.0b0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl",
      "has_sig": false,
      "md5_digest": "86aab87419171f279a9a8622018ac79d",
      "packagetype": "bdist_wheel",
      "python_version": "cp39",
      "requires_python": ">=3.7.0",
      "size": 50064881,
      "upload_time": "2022-12-11T06:10:53",
      "upload_time_iso_8601": "2022-12-11T06:10:53.360520Z",
      "url": "https://files.pythonhosted.org/packages/75/fc/1b65ecd8ea903eaad7dd50e55857c9d3e859e215f637eaee2e7ce4fbf99b/intel_extension_for_transformers-1.0b0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "7b42a0be821b4e626a666151e207e8e577c28603411d843d0e9e192731bd78e5",
        "md5": "f1cb00b652cf21191ba3f9a1d57ed388",
        "sha256": "0b0645fc5047230aef9b42f14e0b570889019d204481bef40a42810129ac21d3"
      },
      "downloads": -1,
      "filename": "intel_extension_for_transformers-1.0b0-cp39-cp39-win_amd64.whl",
      "has_sig": false,
      "md5_digest": "f1cb00b652cf21191ba3f9a1d57ed388",
      "packagetype": "bdist_wheel",
      "python_version": "cp39",
      "requires_python": ">=3.7.0",
      "size": 8471942,
      "upload_time": "2022-12-11T08:01:19",
      "upload_time_iso_8601": "2022-12-11T08:01:19.191181Z",
      "url": "https://files.pythonhosted.org/packages/7b/42/a0be821b4e626a666151e207e8e577c28603411d843d0e9e192731bd78e5/intel_extension_for_transformers-1.0b0-cp39-cp39-win_amd64.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "fa8d019475c55d457e305ccbdb608d4af00f08bac60120fe6dfc53bac19f9e47",
        "md5": "17c0130c1329b8d4419862a2c7710d3f",
        "sha256": "2022027c4f5db1335266a802528102fe2126141d37f4d0a191d8cd7a18cbf4a4"
      },
      "downloads": -1,
      "filename": "intel_extension_for_transformers-1.0b0.tar.gz",
      "has_sig": false,
      "md5_digest": "17c0130c1329b8d4419862a2c7710d3f",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7.0",
      "size": 179885,
      "upload_time": "2022-12-11T05:29:15",
      "upload_time_iso_8601": "2022-12-11T05:29:15.238257Z",
      "url": "https://files.pythonhosted.org/packages/fa/8d/019475c55d457e305ccbdb608d4af00f08bac60120fe6dfc53bac19f9e47/intel_extension_for_transformers-1.0b0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}