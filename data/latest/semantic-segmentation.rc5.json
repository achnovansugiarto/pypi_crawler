{
  "info": {
    "author": "Yang Lu",
    "author_email": "luyanger1799@outlook.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# Amazing-Semantic-Segmentation\n[![python](https://img.shields.io/badge/Python-3.x-ff69b4.svg)](https://github.com/luyanger1799/Amazing-Semantic-Segmentation.git)\n[![tensorflow](https://img.shields.io/badge/Tensorflow-1.1x%7C2.0-brightgreen.svg)](https://github.com/luyanger1799/Amazing-Semantic-Segmentation.git)\n[![OpenCV](https://img.shields.io/badge/OpenCV-3.x%7C4.x-orange.svg)](https://github.com/luyanger1799/Amazing-Semantic-Segmentation.git)\n[![Apache](https://img.shields.io/badge/Apache-2.0-blue.svg)](https://github.com/luyanger1799/Amazing-Semantic-Segmentation.git)\n\n>Amazing Semantic Segmentation on Tensorflow && Keras (include FCN, UNet, SegNet, PSPNet, PAN, RefineNet, DeepLabV3, DeepLabV3+, DenseASPP, BiSegNet ...)\n***\n## Models\nThe project supports these semantic segmentation models as follows:\n\n>1. FCN-8s/16s/32s - [Fully Convolutional Networks for Semantic Segmentation](https://arxiv.org/pdf/1411.4038.pdf)\n>2. UNet - [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/pdf/1505.04597.pdf)\n>3. SegNet - [SegNet:A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation](https://arxiv.org/pdf/1511.00561.pdf)\n>4. Bayesian-SegNet - [Bayesian SegNet: Model Uncertainty in Deep Convolutional Encoder-Decoder Architectures for Scene Understanding](https://arxiv.org/pdf/1511.02680v2.pdf)\n>5. PSPNet - [Pyramid Scene Parsing Network](https://arxiv.org/pdf/1612.01105.pdf)\n>6. RefineNet - [RefineNet: Multi-Path Refinement Networks for High-Resolution Semantic Segmentation](https://arxiv.org/pdf/1611.06612.pdf)\n>7. PAN - [Pyramid Attention Network for Semantic Segmentation](https://arxiv.org/pdf/1805.10180.pdf)\n>8. DeepLabV3 - [Rethinking Atrous Convolution for Semantic Image Segmentation](https://arxiv.org/pdf/1706.05587.pdf)\n>9. DeepLabV3Plus - [Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation](https://arxiv.org/pdf/1802.02611.pdf)\n>10. DenseASPP - [DenseASPP for Semantic Segmentation in Street Scenes](http://openaccess.thecvf.com/content_cvpr_2018/papers/Yang_DenseASPP_for_Semantic_CVPR_2018_paper.pdf)\n>11. BiSegNet - [BiSeNet: Bilateral Segmentation Network for Real-time Semantic Segmentation](https://arxiv.org/pdf/1808.00897.pdf)\n\n\n***\n## Base Models\nThe project supports these backbone models as follows, and your can choose suitable base model according to your needs.\n\n>1. VGG16/19 - [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/pdf/1409.1556.pdf)\n>2. ResNet50/101/152 - [Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf)\n>3. DenseNet121/169/201/264 - [Densely Connected Convolutional Networks](https://arxiv.org/pdf/1608.06993.pdf)\n>4. MobileNetV1 - [MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications](https://arxiv.org/pdf/1704.04861.pdf)\n>5. MobileNetV2 - [MobileNetV2: Inverted Residuals and Linear Bottlenecks](https://arxiv.org/pdf/1801.04381.pdf)\n>6. Xception - [Xception: Deep Learning with Depthwise Separable Convolutions](https://arxiv.org/pdf/1610.02357.pdf)\n>7. Xception-DeepLab - [Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation](https://arxiv.org/pdf/1802.02611.pdf)\n\n\n\n***\n## Dataset Setting\nThe folds of your dataset must satisfy the following structures:\n```buildoutcfg\n|-- dataset\n|  |-- train\n|  |  |-- images\n|  |  |-- labels\n|  |-- valid\n|  |  |-- images\n|  |  |-- labels\n|  |-- test\n|  |  |-- images\n|  |  |-- labels\n```\n***\n## Installation\n- Numpy `pip install numpy`\n- Pillow `pip install pillow`\n- OpenCV `pip install opencv-python`\n- Tensorflow `pip install tensorflow-gpu`  \n\n**Note:** The recommended version of tensorflow-gpu is 1.14 or 2.0. And if your tensorflow version is lower, you \nneed to modify some API or upgrade your tensorflow. \n***\n## Usage\n**Download:**\nYou can download the project through this command:  \n`git clone git@github.com:luyanger1799/Amazing-Semantic-Segmentation.git`  \n\n**Training:** \nThe project contains complete codes for training, testing and predicting. \nAnd you can perform a simple command as this to build a model on your dataset:\n```buildoutcfg\npython train.py --model FCN-8s --base_model ResNet50 --dataset \"dataset_path\" --num_classes \"num_classes\"\n```\nThe detailed command line parameters are as follows:\n```buildoutcfg\nusage: train.py [-h] --model MODEL [--base_model BASE_MODEL] --dataset DATASET\n                --num_classes NUM_CLASSES [--random_crop RANDOM_CROP]\n                [--crop_height CROP_HEIGHT] [--crop_width CROP_WIDTH]\n                [--batch_size BATCH_SIZE]\n                [--valid_batch_size VALID_BATCH_SIZE]\n                [--num_epochs NUM_EPOCHS] [--initial_epoch INITIAL_EPOCH]\n                [--h_flip H_FLIP] [--v_flip V_FLIP]\n                [--brightness BRIGHTNESS [BRIGHTNESS ...]]\n                [--rotation ROTATION]\n                [--zoom_range ZOOM_RANGE [ZOOM_RANGE ...]]\n                [--channel_shift CHANNEL_SHIFT]\n                [--data_aug_rate DATA_AUG_RATE]\n                [--checkpoint_freq CHECKPOINT_FREQ]\n                [--validation_freq VALIDATION_FREQ]\n                [--num_valid_images NUM_VALID_IMAGES]\n                [--data_shuffle DATA_SHUFFLE] [--random_seed RANDOM_SEED]\n                [--weights WEIGHTS]\n\n```\n```buildoutcfg\noptional arguments:\n  -h, --help            show this help message and exit\n  --model MODEL         Choose the semantic segmentation methods.\n  --base_model BASE_MODEL\n                        Choose the backbone model.\n  --dataset DATASET     The path of the dataset.\n  --num_classes NUM_CLASSES\n                        The number of classes to be segmented.\n  --random_crop RANDOM_CROP\n                        Whether to randomly crop the image.\n  --crop_height CROP_HEIGHT\n                        The height to crop the image.\n  --crop_width CROP_WIDTH\n                        The width to crop the image.\n  --batch_size BATCH_SIZE\n                        The training batch size.\n  --valid_batch_size VALID_BATCH_SIZE\n                        The validation batch size.\n  --num_epochs NUM_EPOCHS\n                        The number of epochs to train for.\n  --initial_epoch INITIAL_EPOCH\n                        The initial epoch of training.\n  --h_flip H_FLIP       Whether to randomly flip the image horizontally.\n  --v_flip V_FLIP       Whether to randomly flip the image vertically.\n  --brightness BRIGHTNESS [BRIGHTNESS ...]\n                        Randomly change the brightness (list).\n  --rotation ROTATION   The angle to randomly rotate the image.\n  --zoom_range ZOOM_RANGE [ZOOM_RANGE ...]\n                        The times for zooming the image.\n  --channel_shift CHANNEL_SHIFT\n                        The channel shift range.\n  --data_aug_rate DATA_AUG_RATE\n                        The rate of data augmentation.\n  --checkpoint_freq CHECKPOINT_FREQ\n                        How often to save a checkpoint.\n  --validation_freq VALIDATION_FREQ\n                        How often to perform validation.\n  --num_valid_images NUM_VALID_IMAGES\n                        The number of images used for validation.\n  --data_shuffle DATA_SHUFFLE\n                        Whether to shuffle the data.\n  --random_seed RANDOM_SEED\n                        The random shuffle seed.\n  --weights WEIGHTS     The path of weights to be loaded.\n\n```\nIf you only want to use the model in your own training code, you can do as this:\n```buildoutcfg\nfrom builders.model_builder import builder\n\nmodel, base_model = builder(num_classes, input_size, model='SegNet', base_model=None)\n```\n**Note:** If you don't give the parameter \"base_model\", the default backbone will be used.\n\n**Testing:** \nSimilarly, you can evaluate the model on your own dataset:\n```buildoutcfg\npython test.py --model FCN-8s --base_model ResNet50 --dataset \"dataset_path\" --num_classes \"num_classes\" --weights \"weights_path\"\n```\n**Note:** If the parameter \"weights\" is None, the weigths saved in default path will be loaded.  \n\n**Predicting:** \nYou can get the prediction of a single RGB image as this:\n```buildoutcfg\npython predict.py --model FCN-8s --base_model ResNet50 --num_classes \"num_classes\" --weights \"weights_path\" --image_path \"image_path\"\n``` \n***\n## PyPI\nAlternatively, you can install the project through PyPI.\n```\npip install semantic-segmentation\n```\nAnd you can use model_builders to build different models or directly call the class of semantic segmentation.\n```\nfrom semantic_segmentation import model_builders\nnet, base_net = model_builders(num_classes, input_size, model='SegNet', base_model=None)\n```\nor\n```\nfrom semantic_segmentation import models\nnet = models.FCN(num_classes, version='FCN-8s')(input_size=input_size)\n```\n***\n## Pre-trained\nDue to my limited computing resources, there is no pre-training model yet. And maybe it will be added in the future.\n***\n## Feedback\nIf you like this work, please give me a star! And if you find\nany errors or have any suggestions, please contact me.  \n\n**GitHub:** `luyanger1799`\\\n**Email:** `luyanger1799@outlook.com`",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/luyanger1799/Amazing-Semantic-Segmentation.git",
    "keywords": "",
    "license": "Apache 2,0 License",
    "maintainer": "",
    "maintainer_email": "",
    "name": "semantic-segmentation",
    "package_url": "https://pypi.org/project/semantic-segmentation/",
    "platform": "all",
    "project_url": "https://pypi.org/project/semantic-segmentation/",
    "project_urls": {
      "Homepage": "https://github.com/luyanger1799/Amazing-Semantic-Segmentation.git"
    },
    "release_url": "https://pypi.org/project/semantic-segmentation/0.1.0/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "Semantic Segmentation on Tensorflow && Keras",
    "version": "0.1.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 5740393,
  "releases": {
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ca43ebfc16eb1c6c5628ee53cb095cb3517da3987750228474fbbadfaa5e7cd9",
          "md5": "acd564bc1e2d9d819cbfd38ce67b7238",
          "sha256": "77760a65577a7c0ffbeb271e06a7d71d04b5a749fe6ddeb12d8254491d5f77b1"
        },
        "downloads": -1,
        "filename": "semantic_segmentation-0.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "acd564bc1e2d9d819cbfd38ce67b7238",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 39730,
        "upload_time": "2019-07-25T16:01:57",
        "upload_time_iso_8601": "2019-07-25T16:01:57.423699Z",
        "url": "https://files.pythonhosted.org/packages/ca/43/ebfc16eb1c6c5628ee53cb095cb3517da3987750228474fbbadfaa5e7cd9/semantic_segmentation-0.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8dbb64c75581ed5be1fdc844ccb6d5e5e24d579b5f51a2537dcf464d456798db",
          "md5": "a450a384dc1a3a0d3c02ace2ca57b9d3",
          "sha256": "03eafff6a9d4b84b1d9b3661ce3b1e6b6916f6dc7180871559da9a18f4370b7c"
        },
        "downloads": -1,
        "filename": "semantic_segmentation-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "a450a384dc1a3a0d3c02ace2ca57b9d3",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 21915,
        "upload_time": "2019-07-25T16:02:00",
        "upload_time_iso_8601": "2019-07-25T16:02:00.816489Z",
        "url": "https://files.pythonhosted.org/packages/8d/bb/64c75581ed5be1fdc844ccb6d5e5e24d579b5f51a2537dcf464d456798db/semantic_segmentation-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d82b5b630318fa9a6d65b362e263966d55c6662f3e3a03155c7d1153fb1caade",
          "md5": "ae04f20090121fdf58c2192f6e4a86db",
          "sha256": "b8e9c4ee93f91071326b69f73097ae58b7214c7ff992659115fc77e72c071b67"
        },
        "downloads": -1,
        "filename": "semantic_segmentation-0.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ae04f20090121fdf58c2192f6e4a86db",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 39887,
        "upload_time": "2019-07-25T16:29:50",
        "upload_time_iso_8601": "2019-07-25T16:29:50.831227Z",
        "url": "https://files.pythonhosted.org/packages/d8/2b/5b630318fa9a6d65b362e263966d55c6662f3e3a03155c7d1153fb1caade/semantic_segmentation-0.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0bf6ca0e85ce4ff325ae8c50ba61ef685817489b1164a70bc5e1b874c7239116",
          "md5": "a801d2b8985bd7ce1170c6b0d8dca353",
          "sha256": "743aa74d9e41efd4d576f2771a8dd667f1d76c9078b96aba56ad18d9ccf5f1c3"
        },
        "downloads": -1,
        "filename": "semantic_segmentation-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "a801d2b8985bd7ce1170c6b0d8dca353",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 22222,
        "upload_time": "2019-07-25T16:29:53",
        "upload_time_iso_8601": "2019-07-25T16:29:53.014579Z",
        "url": "https://files.pythonhosted.org/packages/0b/f6/ca0e85ce4ff325ae8c50ba61ef685817489b1164a70bc5e1b874c7239116/semantic_segmentation-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d97195f9482769a22d940f93de419fa3c70df33f856d5498780697c4b87d1857",
          "md5": "3182e7b91cb887537ae49e6c8c4ae545",
          "sha256": "5e402b87316d11aa02e9510827ede0d8c84418e3cbc963c746524706acf1d419"
        },
        "downloads": -1,
        "filename": "semantic_segmentation-0.0.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "3182e7b91cb887537ae49e6c8c4ae545",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 39952,
        "upload_time": "2019-07-28T02:46:35",
        "upload_time_iso_8601": "2019-07-28T02:46:35.724522Z",
        "url": "https://files.pythonhosted.org/packages/d9/71/95f9482769a22d940f93de419fa3c70df33f856d5498780697c4b87d1857/semantic_segmentation-0.0.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6033107850a361934fbbfa18afc8422eaa1a8313c9bd07d2964f6195420fe12d",
          "md5": "206ae5c867085692453bc75e38a1096b",
          "sha256": "baab5980a0264a6fb1802afdc0fe3648606e2a625ef73cd6b5b747d33ded75e8"
        },
        "downloads": -1,
        "filename": "semantic_segmentation-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "206ae5c867085692453bc75e38a1096b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 22448,
        "upload_time": "2019-07-28T02:46:37",
        "upload_time_iso_8601": "2019-07-28T02:46:37.768026Z",
        "url": "https://files.pythonhosted.org/packages/60/33/107850a361934fbbfa18afc8422eaa1a8313c9bd07d2964f6195420fe12d/semantic_segmentation-0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "44d0eb92ecea05dd7d4972280b382a595603722d8e7e229cfea68a9d0c441a56",
          "md5": "01a227a6063e9898b2c1b97e7ad45b0a",
          "sha256": "56c52489c6633d985670150301b9890e2f56cc03f3d9f306d9a772390c13a060"
        },
        "downloads": -1,
        "filename": "semantic_segmentation-0.0.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "01a227a6063e9898b2c1b97e7ad45b0a",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 40211,
        "upload_time": "2019-08-26T02:44:27",
        "upload_time_iso_8601": "2019-08-26T02:44:27.015107Z",
        "url": "https://files.pythonhosted.org/packages/44/d0/eb92ecea05dd7d4972280b382a595603722d8e7e229cfea68a9d0c441a56/semantic_segmentation-0.0.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "60bf5a8443077e8bdff2df83c440c70f2bd4a4ba67f60db1a01ffb4f9dc90c81",
          "md5": "1972aea8b62dd0b7cd5bf7b14d081616",
          "sha256": "b8f5a097fa65ef5e8e29e58786a9f218063471847fed3af703ecf7961dfd6451"
        },
        "downloads": -1,
        "filename": "semantic_segmentation-0.0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "1972aea8b62dd0b7cd5bf7b14d081616",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 22687,
        "upload_time": "2019-08-26T02:44:29",
        "upload_time_iso_8601": "2019-08-26T02:44:29.270780Z",
        "url": "https://files.pythonhosted.org/packages/60/bf/5a8443077e8bdff2df83c440c70f2bd4a4ba67f60db1a01ffb4f9dc90c81/semantic_segmentation-0.0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d9842c71e0c4901f61012919f2dbb64ce23d709a20425f3cffbcd9e497b0361a",
          "md5": "b7b05fb8186c66c2d08e46115deeff48",
          "sha256": "a25412f79c962c9d2ef429b114778f896604c8e823c1d1a42de65f8f262767ef"
        },
        "downloads": -1,
        "filename": "semantic_segmentation-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "b7b05fb8186c66c2d08e46115deeff48",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 22736,
        "upload_time": "2019-08-28T02:51:25",
        "upload_time_iso_8601": "2019-08-28T02:51:25.173698Z",
        "url": "https://files.pythonhosted.org/packages/d9/84/2c71e0c4901f61012919f2dbb64ce23d709a20425f3cffbcd9e497b0361a/semantic_segmentation-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "d9842c71e0c4901f61012919f2dbb64ce23d709a20425f3cffbcd9e497b0361a",
        "md5": "b7b05fb8186c66c2d08e46115deeff48",
        "sha256": "a25412f79c962c9d2ef429b114778f896604c8e823c1d1a42de65f8f262767ef"
      },
      "downloads": -1,
      "filename": "semantic_segmentation-0.1.0.tar.gz",
      "has_sig": false,
      "md5_digest": "b7b05fb8186c66c2d08e46115deeff48",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 22736,
      "upload_time": "2019-08-28T02:51:25",
      "upload_time_iso_8601": "2019-08-28T02:51:25.173698Z",
      "url": "https://files.pythonhosted.org/packages/d9/84/2c71e0c4901f61012919f2dbb64ce23d709a20425f3cffbcd9e497b0361a/semantic_segmentation-0.1.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}