{
  "info": {
    "author": "ROSS developers",
    "author_email": "raphaelts@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: Implementation :: CPython"
    ],
    "description": "\n#### Q: What is a Pipeline?\n\nA: Is a set of data processing elements connected in series, where the output of one element is the input of the next one\n\n#### Q: How to use this Pipeline?\n\nA: First of all, you should pass to the Pipeline class a DataFrame, ie, a structured data format from pandas. This is quite easy to obtain if your file results\nare a \".csv\" or a \".xls\" file. In order to do that, use the comand:\n```python\ndf = pandas.read_csv('your_file.csv/xls')\n```\nAfter obtaining a DataFrame file, pass it to the Pipeline by using the command:\n```python\nD = pipeline(df)\n```\nthis will instantiate a pipeline object. After that, you must inform the program which columns will be your features and which ones will be your labels.\nTo do that, use the commands:\n```python\nD.set_features(start, end)\nD.set_labels(start, end)\n```\nQuite self-explanatory, isn't it?\n\nOk. Now you have informed the program about your labels and features. What's next? The next step is to use a scalers in your input, output or both.\nThere are plenty of them on scikit-learn. [scikit-learn](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html).\nGive yourself a time to read it. Since your results depends on how well you scale your data. To scale your data, you should use the command:\n```python\ndata_scaling(test_size, scalers=[scaler1, scaler2], scaling=True)\n```\n\n`test_size` variable tells the program how great will be your cross validation data in %. In Machine Learning communities, 30% is considered a good\namount of data for cross-validation. `scalers` are a list with the input scaler and the output one, respectively.\n\nAfter proper scaling, it is time to build your Artificial Neural Networks (ANN). For this, use the following command:\n```python\nD.build_Sequential_ANN(number_of_layers, neurons_per_layer).\n```\n\nIt is also possible to add dropout layers on your model by using:\n```python\nD.build_Sequential_ANN(number_of_layers, neurons_per_layer, dropout_layers, dropout_values).\n```\n`number_of_layers` tells the program how many layers will be used;\n`neurons_per_layer` tells how many neurons will be used in each layer. So, it is clear that `neurons_per_layer` is a list data structure.\n\nFor dropout insertion, the idea is analogous: you need to inform the program the dropout layer positions and how much dropout you will add to those layers.\nSo, both `dropout_layers` and `dropout_values` are lists. The next step is to run your model. To do that use the command:\n```python\nD.run_model(optimizer, loss, batch_size, epochs).\n```\n`optimizer` inform the program which optmizer will be used, `loss` is the loss function that will be used in optmization process,\n`batch_size` tells the program how many batches will be used and epochs informs the how many epochs will take the training.\nThe syntax here is the same used on Keras.\n\nNow, it's time to check your results. Firstly, you should check if your model presents overfit. Overfit, in simple terms, is when model focus more on\nfitting the given points than recognizing the \"big picture\" of your data. Because of that, overfited models suffers from generalization.\nTo check your model, use\n```python\nD.model_history().\n```\nThis will plot a graph of both `val_loss` and `loss`. To a better understanding what each one means, please [check here](https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/62261) or cross-validation forums.\n\nAfter checking your loss, if you want to quantify how good your model is, it is recommended using:\n```python\nD.validation() \n```\nand\n```python\nD.metrics()\n```\nwhich returns several metrics commonly used on Machine Learning community. Here, a piece of advice is needed: the metrics used varies according to your problem.\nThe most straightfoward way to choose a proper metric is to check if your understanding of problem is adequate and then rethink the problem if it is necessary.\nIt is also recommended to check if anyone else has the same problem as you, what is the most common scenario.\nRecommended foruns are [stats.stackexchange](https://stats.stackexchange.com/) and [Quora](www.quora.com).\n\nIt is also provided hypothesis tests to check your model. However, you should check if the following tests has enough power to be conclusive.\nHere, it is proposed two hypothesis test: ks-test and welch test. The former tries to verify if both test and train comes from the same distribution,\nwhich could mean that both are samples from the same distribution which describes your phenomenon. The last tries to check if the trained model has the same mean\nas the test set, which indicate if your model are accurate or not. Again, you should get the power of both hypothesis to properly make conclusions out of\nhypothesis tests.\n\nIf your model is adequate, you can save it using the command:\n```python\nD.save_model().\n```\n\n#### Q: Is there a way to visualize all the results?\n\nA: Yes! There is a postprocessing class to that purpose, in which you inform your trained data and validation one. To do so you should use\n```python\npostproc = postprocessing(D.train, D.test)\n```\nwhere `D.train` and `D.test` are obtaining after instatiating `Pipeline` class. After that you are able to plot the following graphics:\n\n- quantile-quantile plot\n- confidence intervals of your predictions, using DKW-inequality\n- standardized error plot\n- resume of residuals.\n\n#### Q: Is it possible to reuse the model?\n\nA: Surely! You can load your model by using the following commands:\n```python\nmodel = Model('filename')\n```\nand\n```python\nmodel.load_model()\n```\nThe first command searches for the saved file while the second loads it.\nTo make predictions with your loaded model, use:\n```python\nmodel.predict(x),\n```\nwhere `x` are the features that you want to predict. Make sure that `x` has the same shape that your former features in order to guarantee proper results.\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/ross-rotordynamics/ross-ml",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "ross-ml",
    "package_url": "https://pypi.org/project/ross-ml/",
    "platform": "",
    "project_url": "https://pypi.org/project/ross-ml/",
    "project_urls": {
      "Homepage": "https://github.com/ross-rotordynamics/ross-ml"
    },
    "release_url": "https://pypi.org/project/ross-ml/0.0.1/",
    "requires_dist": [
      "numpy",
      "scipy",
      "pandas (>=0.23)",
      "plotly (>=4.7.0)",
      "statsmodels",
      "sklearn",
      "tensorflow",
      "pytest (>=4.6) ; extra == 'dev'",
      "pytest-cov ; extra == 'dev'",
      "coverage ; extra == 'dev'",
      "codecov ; extra == 'dev'",
      "sphinx ; extra == 'dev'",
      "sphinx-bootstrap-theme ; extra == 'dev'",
      "nbsphinx ; extra == 'dev'",
      "numpydoc ; extra == 'dev'",
      "sphinxcontrib-bibtex ; extra == 'dev'",
      "isort ; extra == 'dev'"
    ],
    "requires_python": ">=3.6.0",
    "summary": "ross-machine-learning",
    "version": "0.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8535183,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3e56a259a04a00d293293a020284737b68555f1bf468beed49545944208ae201",
          "md5": "ad917acdd502de3c4d0d032c267c1a27",
          "sha256": "10ade2d8c0f2747c3a47a71f00fa46f2debf858c61f11bfee60b79895979afbb"
        },
        "downloads": -1,
        "filename": "ross_ml-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ad917acdd502de3c4d0d032c267c1a27",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6.0",
        "size": 13744,
        "upload_time": "2020-10-29T19:20:49",
        "upload_time_iso_8601": "2020-10-29T19:20:49.250990Z",
        "url": "https://files.pythonhosted.org/packages/3e/56/a259a04a00d293293a020284737b68555f1bf468beed49545944208ae201/ross_ml-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ba3f41a982158f2ce2fa334708d8de608ba40d38e7780d1eeea1c01211e54270",
          "md5": "471ab6707a99cadf720819d0d79c524c",
          "sha256": "c6332de297a6b419b89a818333f5eafd235ec1db1d547572b6a7238c6cee205a"
        },
        "downloads": -1,
        "filename": "ross-ml-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "471ab6707a99cadf720819d0d79c524c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6.0",
        "size": 14718,
        "upload_time": "2020-10-29T19:20:51",
        "upload_time_iso_8601": "2020-10-29T19:20:51.669685Z",
        "url": "https://files.pythonhosted.org/packages/ba/3f/41a982158f2ce2fa334708d8de608ba40d38e7780d1eeea1c01211e54270/ross-ml-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "3e56a259a04a00d293293a020284737b68555f1bf468beed49545944208ae201",
        "md5": "ad917acdd502de3c4d0d032c267c1a27",
        "sha256": "10ade2d8c0f2747c3a47a71f00fa46f2debf858c61f11bfee60b79895979afbb"
      },
      "downloads": -1,
      "filename": "ross_ml-0.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "ad917acdd502de3c4d0d032c267c1a27",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6.0",
      "size": 13744,
      "upload_time": "2020-10-29T19:20:49",
      "upload_time_iso_8601": "2020-10-29T19:20:49.250990Z",
      "url": "https://files.pythonhosted.org/packages/3e/56/a259a04a00d293293a020284737b68555f1bf468beed49545944208ae201/ross_ml-0.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "ba3f41a982158f2ce2fa334708d8de608ba40d38e7780d1eeea1c01211e54270",
        "md5": "471ab6707a99cadf720819d0d79c524c",
        "sha256": "c6332de297a6b419b89a818333f5eafd235ec1db1d547572b6a7238c6cee205a"
      },
      "downloads": -1,
      "filename": "ross-ml-0.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "471ab6707a99cadf720819d0d79c524c",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6.0",
      "size": 14718,
      "upload_time": "2020-10-29T19:20:51",
      "upload_time_iso_8601": "2020-10-29T19:20:51.669685Z",
      "url": "https://files.pythonhosted.org/packages/ba/3f/41a982158f2ce2fa334708d8de608ba40d38e7780d1eeea1c01211e54270/ross-ml-0.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}