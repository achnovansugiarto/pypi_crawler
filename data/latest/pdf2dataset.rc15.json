{
  "info": {
    "author": "Ícaro Pires",
    "author_email": "icaropsa@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: Apache Software License",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8"
    ],
    "description": "# pdf2dataset\n\n[![pdf2dataset](https://github.com/icaropires/pdf2dataset/workflows/pdf2dataset/badge.svg?branch=master)](https://github.com/icaropires/pdf2dataset)\n[![pypi](https://img.shields.io/pypi/v/pdf2dataset.svg)](https://pypi.python.org/pypi/pdf2dataset)\n[![Maintainability](https://api.codeclimate.com/v1/badges/cbe90c3043b038f52b18/maintainability)](https://codeclimate.com/github/icaropires/pdf2dataset/maintainability)\n[![codecov](https://codecov.io/gh/icaropires/pdf2dataset/branch/master/graph/badge.svg)](https://codecov.io/gh/icaropires/pdf2dataset)\n[![pypi-stats](https://img.shields.io/pypi/dm/pdf2dataset)](https://pypistats.org/packages/pdf2dataset)\n\nConverts a whole subdirectory with any volume (small or huge) of PDF documents to a dataset (pandas DataFrame).\nNo need to setup any external service (no database, brokers, etc). Just install and run it!\n\n\n## Main features\n\n* Conversion of a whole subdirectory with PDFs documents into a pandas DataFrame\n* Support for parallel and distributed processing through [ray](https://github.com/ray-project/ray)\n* Extractions are performed by page, making tasks distribution more uniform for handling documents with big differences in number of pages\n* Incremental writing of resulting DataFrame, making possible to process data bigger than memory\n* Error tracking of faulty documents\n* Resume interrupted processing\n* Extract text through [pdftotext](https://github.com/jalan/pdftotext)\n* Use OCR for extracting text through [pytesseract](https://github.com/madmaze/pytesseract)\n* Extract images through [pdf2image](https://github.com/Belval/pdf2image)\n* Support to implement custom features extraction\n* Highly customizable behavior through params\n\n\n## Installation\n\n### Install Dependencies\n\n#### Fedora\n\n``` bash\n# \"-por\" for portuguese, use the documents language\n$ sudo dnf install -y gcc-c++ poppler-utils pkgconfig poppler-cpp-devel python3-devel tesseract-langpack-por\n```\n\n#### Ubuntu (or debians)\n\n``` bash\n$ sudo apt update\n\n# \"-por\" for portuguese, use the documents language\n$ sudo apt install -y build-essential poppler-utils libpoppler-cpp-dev pkg-config python3-dev tesseract-ocr-por\n```\n\n### Install pdf2dataset\n\n#### For usage\n\n``` bash\n$ pip3 install pdf2dataset --user  # Please, isolate the environment\n```\n\n#### For development\n\n``` bash\n# First, install poetry, clone repository and cd into it\n$ poetry install\n```\n\n\n## Usage\n\n### Simple - CLI\n\n``` bash\n# Note: path, page and error will always be present in resulting DataFrame\n\n# Reads all PDFs from my_pdfs_dir and saves the resultant dataframe to my_df.parquet.gzip\n$ pdf2dataset my_pdfs_dir my_df.parquet.gzip  # Most basic, extract all possible features\n$ pdf2dataset my_pdfs_dir my_df.parquet.gzip --features=text  # Extract just text\n$ pdf2dataset my_pdfs_dir my_df.parquet.gzip --features=image  # Extract just image\n$ pdf2dataset my_pdfs_dir my_df.parquet.gzip --num-cpus 1  # Maximum reducing of parallelism\n$ pdf2dataset my_pdfs_dir my_df.parquet.gzip --ocr true  # For scanned PDFs\n$ pdf2dataset my_pdfs_dir my_df.parquet.gzip --ocr true --lang eng  # For scanned documents with english text\n```\n\n### Resume processing\n\nIn case of any interruption, to resume the processing, just use the same path as output and the\nprocessing will be resumed automatically. The flag `--saving-interval` (or the param `saving_interval`)\ncontrols the frequency the output path will be updated, and so, the processing \"checkpoints\".\n\n\n### Using as a library\n\n#### Main functions\n\nThere're some helper functions to facilitate pdf2dataset usage:\n\n* **extract:** function can be used analogously to the CLI\n* **extract_text**: `extract` wrapper with `features=text`\n* **extract_image**: `extract` wrapper with `features=image`\n* **image_from_bytes:** (pdf2image.utils) get a Pillow `Image` object given the image bytes\n* **image_to_bytes:** (pdf2image.utils) get the image bytes given the a Pillow `Image` object\n\n#### Basic example\n``` python\nfrom pdf2dataset import extract\n\nextract('my_pdfs_dir', 'all_features.parquet.gzip')\n```\n\n#### Small data\n\nOne feature, not available to the CLI, is the custom behavior for handling small volumes of data (small can\nbe understood as that: the extraction won't run for hours or days and won't be distributed).\n\nThe complete list of differences are:\n\n* Faster initialization (use multiprocessing instead of ray)\n* Don't save processing progress\n* Distributed processing not supported\n* Don't write dataframe to disk\n* Returns the dataframe\n\n##### Example:\n``` python\nfrom pdf2dataset import extract_text\n\ndf = extract_text('my_pdfs_dir', small=True)\n# ...\n```\n\n#### Pass list of files paths\n\nInstead of specifying a directory, one can specify a list of files to be processed.\n\n##### Example:\n\n``` python\nfrom pdf2dataset import extract\n\n\nmy_files = [\n    './tests/samples/single_page1.pdf',\n    './tests/samples/invalid1.pdf',\n]\n\ndf = extract(my_files, small=True)\n# ...\n```\n\n#### Pass files from memory\n\nIf you don't want to specify a directory for the documents, you can specify the tasks that\nwill be processed.\n\nThe tasks can be of the form `(document_name, document_bytes, page_number)`\nor just `(document_name, document_bytes)`, **document_name** must ends with `.pdf` but \ndon't need to be a real file, **document_bytes** are the bytes of the pdf document and\n**page_number** is the number of the page to process (all pages, if not specified).\n\n##### Example:\n\n``` python\nfrom pdf2dataset import extract_text\n\ntasks = [\n    ('a.pdf', a_bytes),  # Processing all pages of this document\n    ('b.pdf', b_bytes, 1),\n    ('b.pdf', b_bytes, 2),\n]\n\n# 'df' will contain results from all pages from 'a.pdf' and page 1 and 2 from 'b.pdf'\ndf = extract_text(tasks, 'my_df.parquet.gzip', small=True)\n\n# ...\n```\n\n#### Returning a list\n\nIf you don't want to handle the DataFrame, is possible to return a nested list with the features values.\nThe structure for the resulting list is:\n```\nresult = List[documents]\ndocuments = List[pages]\npages = List[features]\nfeatures = List[feature]\nfeature = any\n```\n\n* `any` is any type supported by pyarrow.\n* features are ordered by the feature name (`text`, `image`, etc)\n\n##### Example:\n\n``` python\n>>> from pdf2dataset import extract_text\n>>> extract_text('tests/samples', return_list=True)\n[[[None]],\n [['First page'], ['Second page'], ['Third page']],\n [['My beautiful sample!']],\n [['First page'], ['Second page'], ['Third page']],\n [['My beautiful sample!']]]\n```\n\n* Features with error will have `None` value as result\n* Here, `extract_text` was used, so the only feature is `text`\n\n#### Custom Features\n\nWith version >= 0.4.0, is also possible to easily implement extraction of custom features:\n\n##### Example:\n\nThis is the structure:\n\n``` python\nfrom pdf2dataset import extract, feature, PdfExtractTask\n\n\nclass MyCustomTask(PdfExtractTask):\n\n    @feature('bool_')\n    def get_is_page_even(self):\n        return self.page % 2 == 0\n\n    @feature('binary')\n    def get_doc_first_bytes(self):\n        return self.file_bin[:10]\n\n    @feature('string', exceptions=[ValueError])\n    def get_wrong(self):\n        raise ValueError(\"There was a problem!\")\n\n\nif __name__ == '__main__':\n    df = extract('tests/samples', small=True, task_class=MyCustomTask)\n    print(df)\n\n    df.dropna(subset=['text'], inplace=True)  # Discard invalid documents\n    print(df.iloc[0].error)\n```\n\n* First print:\n```\n                         path  page doc_first_bytes  ...                  text  wrong                                              error\n0                invalid1.pdf    -1   b\"I'm invali\"  ...                  None   None  image_original:\\nTraceback (most recent call l...\n1             multi_page1.pdf     2  b'%PDF-1.5\\n%'  ...           Second page   None  wrong:\\nTraceback (most recent call last):\\n  ...\n2             multi_page1.pdf     3  b'%PDF-1.5\\n%'  ...            Third page   None  wrong:\\nTraceback (most recent call last):\\n  ...\n3   sub1/copy_multi_page1.pdf     1  b'%PDF-1.5\\n%'  ...            First page   None  wrong:\\nTraceback (most recent call last):\\n  ...\n4   sub1/copy_multi_page1.pdf     3  b'%PDF-1.5\\n%'  ...            Third page   None  wrong:\\nTraceback (most recent call last):\\n  ...\n5             multi_page1.pdf     1  b'%PDF-1.5\\n%'  ...            First page   None  wrong:\\nTraceback (most recent call last):\\n  ...\n6  sub2/copy_single_page1.pdf     1  b'%PDF-1.5\\n%'  ...  My beautiful sample!   None  wrong:\\nTraceback (most recent call last):\\n  ...\n7   sub1/copy_multi_page1.pdf     2  b'%PDF-1.5\\n%'  ...           Second page   None  wrong:\\nTraceback (most recent call last):\\n  ...\n8            single_page1.pdf     1  b'%PDF-1.5\\n%'  ...  My beautiful sample!   None  wrong:\\nTraceback (most recent call last):\\n  ...\n\n[9 rows x 8 columns]\n```\n\n* Second print:\n```\nwrong:\nTraceback (most recent call last):\n  File \"/home/icaro/Desktop/pdf2dataset/pdf2dataset/extract_task.py\", line 32, in inner\n    result = feature_method(*args, **kwargs)\n  File \"example.py\", line 16, in get_wrong\n    raise ValueError(\"There was a problem!\")\nValueError: There was a problem!\n\n```\n\nNotes:\n* `@feature` is the decorator used to define new features.\n* The extraction method name must start with the prefix `get_` (avoids collisions with attribute names and increases readability)\n* First argument to `@feature` must be a valid PyArrow type, complete list [here](https://arrow.apache.org/docs/python/api/datatypes.html)\n* `exceptions` param specify a list of exceptions to be recorded on DataFrame, otherwise they are raised\n* For this example, all available features plus the custom ones are extracted\n\n\n### Results File\n\nThe resulting \"file\" is a directory with structure specified by dask with pyarrow engine,\nit can be easily read with pandas or dask:\n\n#### Example with pandas\n``` python\n>>> import pandas as pd\n>>> df = pd.read_parquet('my_df.parquet.gzip', engine='pyarrow')\n>>> df\n                             path  page                  text                                              error\nindex                                                                                                           \n0                single_page1.pdf     1  My beautiful sample!                                                   \n1       sub1/copy_multi_page1.pdf     2           Second page                                                   \n2      sub2/copy_single_page1.pdf     1  My beautiful sample!                                                   \n3       sub1/copy_multi_page1.pdf     3            Third page                                                   \n4                 multi_page1.pdf     1            First page                                                   \n5                 multi_page1.pdf     3            Third page                                                   \n6       sub1/copy_multi_page1.pdf     1            First page                                                   \n7                 multi_page1.pdf     2           Second page                                                   \n0                    invalid1.pdf    -1                        Traceback (most recent call last):\\n  File \"/h...\n```\n\nThere is no guarantee about the uniqueness or order of `index`, you might need to create a new index with\nthe whole data in memory.\n\nThe `-1` page number means that was not possible of even parsing the document.\n\n### Run on a Cluster\n\n#### Setup the Cluster\n\nFollow ray documentation for [manual](https://docs.ray.io/en/latest/using-ray-on-a-cluster.html?setup#manual-cluster-setup) or [automatic](https://docs.ray.io/en/latest/autoscaling.html?setup#automatic-cluster-setup)\nsetup.\n\n#### Run it\n\nTo go distributed you can run it just like local, but using the `--address` and `--redis-password` flags to point to your cluster ([More information](https://docs.ray.io/en/latest/multiprocessing.html)).\n\nWith version >= 0.2.0, only the head node needs to have access to the documents in disk.\n\n\n### CLI Help\n\n```\nusage: pdf2dataset [-h] [--features FEATURES]\n                   [--saving-interval SAVING_INTERVAL] [--ocr-lang OCR_LANG]\n                   [--ocr OCR] [--chunksize CHUNKSIZE]\n                   [--image-size IMAGE_SIZE] [--ocr-image-size OCR_IMAGE_SIZE]\n                   [--image-format IMAGE_FORMAT] [--num-cpus NUM_CPUS]\n                   [--address ADDRESS] [--dashboard-host DASHBOARD_HOST]\n                   [--redis-password REDIS_PASSWORD]\n                   input_dir out_file\n\nExtract text from all PDF files in a directory\n\npositional arguments:\n  input_dir             The folder to lookup for PDF files recursively\n  out_file              File to save the resultant dataframe\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --features FEATURES   Specify a comma separated list with the features you\n                        want to extract. 'path' and 'page' will always be\n                        added. Available features to add: image, page, path,\n                        text Examples: '--features=text,image' or '--\n                        features=all'\n  --saving-interval SAVING_INTERVAL\n                        Results will be persisted to results folder every\n                        saving interval of pages\n  --ocr-lang OCR_LANG   Tesseract language\n  --ocr OCR             'pytesseract' if true, else 'pdftotext'. default:\n                        false\n  --chunksize CHUNKSIZE\n                        Chunksize to use while processing pages, otherwise is\n                        calculated\n  --image-size IMAGE_SIZE\n                        If adding image feature, image will be resized to this\n                        size. Provide two integers separated by 'x'. Example:\n                        --image-size 1000x1414\n  --ocr-image-size OCR_IMAGE_SIZE\n                        The height of the image OCR will be applied. Width\n                        will be adjusted to keep the ratio.\n  --image-format IMAGE_FORMAT\n                        Format of the image generated from the PDF pages\n  --num-cpus NUM_CPUS   Number of cpus to use\n  --address ADDRESS     Ray address to connect\n  --dashboard-host DASHBOARD_HOST\n                        Which IP ray webui will try to listen on\n  --redis-password REDIS_PASSWORD\n                        Redis password to use to connect with ray\n```\n\n\n## Troubleshooting\n\n1. **Troubles with high memory usage**\n\n* Decrease the number of CPUs in use, reducing the level of parallelism, test it with `--num-cpus 1` flag and then increase according to your hardware.\n\n* Use smaller chunksize, so less documents will be put in memory at once. Use `--chunksize 1` for having `1 * num_cpus` documents in memory at once.\n\n\n## How to Contribute\n\nJust open your [issues](https://github.com/icaropires/pdf2dataset/issues) and/or [pull requests](https://github.com/icaropires/pdf2dataset/pulls), all are welcome :smiley:!\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/icaropires/pdf2dataset",
    "keywords": "",
    "license": "Apache-2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "pdf2dataset",
    "package_url": "https://pypi.org/project/pdf2dataset/",
    "platform": "",
    "project_url": "https://pypi.org/project/pdf2dataset/",
    "project_urls": {
      "Homepage": "https://github.com/icaropires/pdf2dataset",
      "Repository": "https://github.com/icaropires/pdf2dataset"
    },
    "release_url": "https://pypi.org/project/pdf2dataset/0.5.3/",
    "requires_dist": [
      "dask[dataframe] (==2.23.0)",
      "more-itertools (>=8.4.0,<9.0.0)",
      "opencv-python (==4.4.0.42)",
      "packaging (>=20.4,<21.0)",
      "pandas (>=0.25.0,<0.26.0)",
      "pdf2image (>=1.13.1,<2.0.0)",
      "pdftotext (==2.1.5)",
      "pyarrow (==1.0.0)",
      "pytesseract (==0.3.5)",
      "ray (==0.8.7)",
      "tqdm (>=4.41.0,<5.0.0)"
    ],
    "requires_python": ">=3.6,<4.0",
    "summary": "Easily convert a subdirectory with big volume of PDF documents into a dataset, supports extracting text and images",
    "version": "0.5.3",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8173825,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "af34b03e07c37ebf140c2d98412ae01ee08553ecd9e44ad933f1bc7167c72d6c",
          "md5": "aff09e6b1b590b9fae3ffba2d56154a6",
          "sha256": "c3618ddc522785baf91ba955b8710e7a6fa5025dbc7f14d43723aa334db0ab68"
        },
        "downloads": -1,
        "filename": "pdf2dataset-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "aff09e6b1b590b9fae3ffba2d56154a6",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6,<4.0",
        "size": 6826,
        "upload_time": "2020-07-15T19:51:04",
        "upload_time_iso_8601": "2020-07-15T19:51:04.778946Z",
        "url": "https://files.pythonhosted.org/packages/af/34/b03e07c37ebf140c2d98412ae01ee08553ecd9e44ad933f1bc7167c72d6c/pdf2dataset-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "67ee0bbbfe6fcba178862bb9311b9993f71e3085c8614afa2a43e1dfe248003f",
          "md5": "95d238b1f94f1dbd59753b2aed01e187",
          "sha256": "03956d5a9f7a8dcefbaf699c24e5a4e1e6d7251b3e56dca0c8ea2b8150c366cf"
        },
        "downloads": -1,
        "filename": "pdf2dataset-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "95d238b1f94f1dbd59753b2aed01e187",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6,<4.0",
        "size": 6156,
        "upload_time": "2020-07-15T19:51:07",
        "upload_time_iso_8601": "2020-07-15T19:51:07.104824Z",
        "url": "https://files.pythonhosted.org/packages/67/ee/0bbbfe6fcba178862bb9311b9993f71e3085c8614afa2a43e1dfe248003f/pdf2dataset-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "53ce0f468357a7f95f22761bc16cd583c3de0a48fddb9929369d52b54263ea96",
          "md5": "d89cdc2812487657214ac23abe59effc",
          "sha256": "150b12d230bd564e1f79482b59c71cba4c47507f3b6bc885563ab4c78f9a6c62"
        },
        "downloads": -1,
        "filename": "pdf2dataset-0.1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d89cdc2812487657214ac23abe59effc",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6,<4.0",
        "size": 7813,
        "upload_time": "2020-07-16T15:21:11",
        "upload_time_iso_8601": "2020-07-16T15:21:11.969948Z",
        "url": "https://files.pythonhosted.org/packages/53/ce/0f468357a7f95f22761bc16cd583c3de0a48fddb9929369d52b54263ea96/pdf2dataset-0.1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a474eb97d23910e790353def9e8e966917969d28634936aaa5bfec29b0883174",
          "md5": "ae85223ba883ca1e4711a33cc4d2326f",
          "sha256": "9aed5fe8fa17316d5b1b9187c051129c946c38434ee0ecb0139937e4caa0d88b"
        },
        "downloads": -1,
        "filename": "pdf2dataset-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "ae85223ba883ca1e4711a33cc4d2326f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6,<4.0",
        "size": 7653,
        "upload_time": "2020-07-16T15:21:13",
        "upload_time_iso_8601": "2020-07-16T15:21:13.229863Z",
        "url": "https://files.pythonhosted.org/packages/a4/74/eb97d23910e790353def9e8e966917969d28634936aaa5bfec29b0883174/pdf2dataset-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e00005da9ff90b91c72ee7c08ef97df1aaedc84b7ab00a6c27081611532ad78e",
          "md5": "187d935434deb4d21a38cc8e57709f8b",
          "sha256": "d50af7e4ca7c591de7593d13dd6ae49bbc2d76205dfce0fd8d2fad89ecb1cef4"
        },
        "downloads": -1,
        "filename": "pdf2dataset-0.2.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "187d935434deb4d21a38cc8e57709f8b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6,<4.0",
        "size": 13269,
        "upload_time": "2020-07-21T19:02:02",
        "upload_time_iso_8601": "2020-07-21T19:02:02.249716Z",
        "url": "https://files.pythonhosted.org/packages/e0/00/05da9ff90b91c72ee7c08ef97df1aaedc84b7ab00a6c27081611532ad78e/pdf2dataset-0.2.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "610798ccd4fbecd8411233ae482eabd375f133210ca28918ef21435b39ded309",
          "md5": "6e73d20fa8a9cb8168bb5acec4921b42",
          "sha256": "bca2ed517c4478e10ede3551d1f507067ed426b17d29fdf2ff393052c3ba953d"
        },
        "downloads": -1,
        "filename": "pdf2dataset-0.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "6e73d20fa8a9cb8168bb5acec4921b42",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6,<4.0",
        "size": 14670,
        "upload_time": "2020-07-21T19:02:03",
        "upload_time_iso_8601": "2020-07-21T19:02:03.966469Z",
        "url": "https://files.pythonhosted.org/packages/61/07/98ccd4fbecd8411233ae482eabd375f133210ca28918ef21435b39ded309/pdf2dataset-0.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "45621a4d5770828539d69ea41ed6720a204b9f3e557ec50473b7b85379f75868",
          "md5": "d1f38fb31b225c30e7e53a7be891c512",
          "sha256": "5d43c30bff341da7fe368452fca63298e6b2234149e8a5ab7f8369c370318f8d"
        },
        "downloads": -1,
        "filename": "pdf2dataset-0.3.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d1f38fb31b225c30e7e53a7be891c512",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6,<4.0",
        "size": 15752,
        "upload_time": "2020-07-29T02:01:30",
        "upload_time_iso_8601": "2020-07-29T02:01:30.566314Z",
        "url": "https://files.pythonhosted.org/packages/45/62/1a4d5770828539d69ea41ed6720a204b9f3e557ec50473b7b85379f75868/pdf2dataset-0.3.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "431083cf5aad19f5a20746f8ae4f39f6dd459dc17cdd2625898fd0da4db3bc73",
          "md5": "2b225fe8558674e35e25bb36789b64e1",
          "sha256": "54c0f964fd4d6b9bde71491a4901faebb790e0aa935b5555ab9416a07761b16a"
        },
        "downloads": -1,
        "filename": "pdf2dataset-0.3.0.tar.gz",
        "has_sig": false,
        "md5_digest": "2b225fe8558674e35e25bb36789b64e1",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6,<4.0",
        "size": 17268,
        "upload_time": "2020-07-29T02:01:33",
        "upload_time_iso_8601": "2020-07-29T02:01:33.255353Z",
        "url": "https://files.pythonhosted.org/packages/43/10/83cf5aad19f5a20746f8ae4f39f6dd459dc17cdd2625898fd0da4db3bc73/pdf2dataset-0.3.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ff5892b560a931a26c494b84b82f70880191944cc7a2f54a82231f1eec61a1a1",
          "md5": "ab27c634ad8c609b4e17f1c8fc07f3e2",
          "sha256": "53f2717b229dfbeb6d3435afd6e3a63bbb6de3c1d1f1bb4659252139ba36d3fc"
        },
        "downloads": -1,
        "filename": "pdf2dataset-0.3.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ab27c634ad8c609b4e17f1c8fc07f3e2",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6,<4.0",
        "size": 15836,
        "upload_time": "2020-07-29T02:09:19",
        "upload_time_iso_8601": "2020-07-29T02:09:19.281630Z",
        "url": "https://files.pythonhosted.org/packages/ff/58/92b560a931a26c494b84b82f70880191944cc7a2f54a82231f1eec61a1a1/pdf2dataset-0.3.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "051ab11ef980a9601a6e460dde077d7adddfa31404fe80b54fd83e0eda3838b8",
          "md5": "a323d3db68602708fb3f15745c110098",
          "sha256": "f753419c82168f917f65007814e3af0dbce92682b4552fc24571e92eae8368de"
        },
        "downloads": -1,
        "filename": "pdf2dataset-0.3.1.tar.gz",
        "has_sig": false,
        "md5_digest": "a323d3db68602708fb3f15745c110098",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6,<4.0",
        "size": 17352,
        "upload_time": "2020-07-29T02:09:22",
        "upload_time_iso_8601": "2020-07-29T02:09:22.760792Z",
        "url": "https://files.pythonhosted.org/packages/05/1a/b11ef980a9601a6e460dde077d7adddfa31404fe80b54fd83e0eda3838b8/pdf2dataset-0.3.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "54eb1eae9b1d41365c205f64e9af74f54c8421cbe21f34efa03d1424cdec23b5",
          "md5": "4145b31eab9e96e2ebd6da144ff6cb87",
          "sha256": "f0b6d2a713324f1ed0cfc7e3922c2894fad259760e66ba2d67f4d3917725eb4a"
        },
        "downloads": -1,
        "filename": "pdf2dataset-0.3.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "4145b31eab9e96e2ebd6da144ff6cb87",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6,<4.0",
        "size": 16090,
        "upload_time": "2020-08-02T01:26:24",
        "upload_time_iso_8601": "2020-08-02T01:26:24.186588Z",
        "url": "https://files.pythonhosted.org/packages/54/eb/1eae9b1d41365c205f64e9af74f54c8421cbe21f34efa03d1424cdec23b5/pdf2dataset-0.3.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a4405a3421e494a118650506da65d10dc31f630f7570102e0f66364a77b4d654",
          "md5": "70f60ee5ce3b581ae71a7cf4559911ac",
          "sha256": "6ee0f68d5fe6e19e96da05a9b5c2547a4e4c59b5a753a9d3b7e1b4243539bd8b"
        },
        "downloads": -1,
        "filename": "pdf2dataset-0.3.2.tar.gz",
        "has_sig": false,
        "md5_digest": "70f60ee5ce3b581ae71a7cf4559911ac",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6,<4.0",
        "size": 17709,
        "upload_time": "2020-08-02T01:26:25",
        "upload_time_iso_8601": "2020-08-02T01:26:25.721441Z",
        "url": "https://files.pythonhosted.org/packages/a4/40/5a3421e494a118650506da65d10dc31f630f7570102e0f66364a77b4d654/pdf2dataset-0.3.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "39bcdae12c9644ff8fd16a9b07c862dca4da0114046aad73f3d40e0d3e11771e",
          "md5": "6c9359b2c38cf4463907f717b7b0f8f4",
          "sha256": "ebbc7f0fdb38c30662bf85dd2495d72ab7ab8f54164ac94baedfff480bc1599b"
        },
        "downloads": -1,
        "filename": "pdf2dataset-0.4.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "6c9359b2c38cf4463907f717b7b0f8f4",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6,<4.0",
        "size": 21139,
        "upload_time": "2020-08-23T21:45:17",
        "upload_time_iso_8601": "2020-08-23T21:45:17.551332Z",
        "url": "https://files.pythonhosted.org/packages/39/bc/dae12c9644ff8fd16a9b07c862dca4da0114046aad73f3d40e0d3e11771e/pdf2dataset-0.4.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5904edac5e524fd2a0ee63481c31140b1222a27a081263a9bd3fe721dc2a306c",
          "md5": "6f4ea3f97804d704fdd3f8f2a5cac828",
          "sha256": "95d550d883703e0cd90bdee1c4b904dd522d515fb2a61a8d74c9b6aa76661208"
        },
        "downloads": -1,
        "filename": "pdf2dataset-0.4.0.tar.gz",
        "has_sig": false,
        "md5_digest": "6f4ea3f97804d704fdd3f8f2a5cac828",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6,<4.0",
        "size": 23990,
        "upload_time": "2020-08-23T21:45:19",
        "upload_time_iso_8601": "2020-08-23T21:45:19.438151Z",
        "url": "https://files.pythonhosted.org/packages/59/04/edac5e524fd2a0ee63481c31140b1222a27a081263a9bd3fe721dc2a306c/pdf2dataset-0.4.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.0a0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3c02164e9d6e874ac5fde769d1eb27bcbed8df8299cfb02c2c6a2ecaaf47e70b",
          "md5": "3317ce9fe8c6f7123955e53c8f549f9e",
          "sha256": "dc38921b541de89ea37e2d8bad6f07e9a587801ea064e127aca33169ef2765c1"
        },
        "downloads": -1,
        "filename": "pdf2dataset-0.4.0a0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "3317ce9fe8c6f7123955e53c8f549f9e",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6,<4.0",
        "size": 18279,
        "upload_time": "2020-08-20T18:37:50",
        "upload_time_iso_8601": "2020-08-20T18:37:50.456163Z",
        "url": "https://files.pythonhosted.org/packages/3c/02/164e9d6e874ac5fde769d1eb27bcbed8df8299cfb02c2c6a2ecaaf47e70b/pdf2dataset-0.4.0a0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "25c0f5a4ed93280ea4a277b1e99c95aa7584f5e45330ea1ae1fa21e10a00adc1",
          "md5": "035f8c30343f50136052bd8c83fe6b87",
          "sha256": "86c32e722a746a56007ceea84027f9452b13c5acafe4ab482665d9083809af02"
        },
        "downloads": -1,
        "filename": "pdf2dataset-0.4.0a0.tar.gz",
        "has_sig": false,
        "md5_digest": "035f8c30343f50136052bd8c83fe6b87",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6,<4.0",
        "size": 19741,
        "upload_time": "2020-08-20T18:37:52",
        "upload_time_iso_8601": "2020-08-20T18:37:52.381906Z",
        "url": "https://files.pythonhosted.org/packages/25/c0/f5a4ed93280ea4a277b1e99c95aa7584f5e45330ea1ae1fa21e10a00adc1/pdf2dataset-0.4.0a0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.0a1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "41f6e686a11d88a4bb8ff5daebe2d421b482b2f84375b556620a0967947722d1",
          "md5": "78b396f252002c92095ee5bf54ab60db",
          "sha256": "7ad54a9b2544438e146157a65dc4be81fd17f3f07f49a75a76b2cfb1346c1df7"
        },
        "downloads": -1,
        "filename": "pdf2dataset-0.4.0a1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "78b396f252002c92095ee5bf54ab60db",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6,<4.0",
        "size": 18301,
        "upload_time": "2020-08-20T19:18:24",
        "upload_time_iso_8601": "2020-08-20T19:18:24.282389Z",
        "url": "https://files.pythonhosted.org/packages/41/f6/e686a11d88a4bb8ff5daebe2d421b482b2f84375b556620a0967947722d1/pdf2dataset-0.4.0a1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "419288fa00e1915603ddf366e51fb720fee5bd8f69f8a4d1700c05e1604fcec5",
          "md5": "6cbf7910de802cbc0f7844b6dd2af85d",
          "sha256": "f0fa5c6e1ff60239da030c9dbf889b09bd886e96938c05c6702a260ab76c1e9a"
        },
        "downloads": -1,
        "filename": "pdf2dataset-0.4.0a1.tar.gz",
        "has_sig": false,
        "md5_digest": "6cbf7910de802cbc0f7844b6dd2af85d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6,<4.0",
        "size": 19771,
        "upload_time": "2020-08-20T19:18:26",
        "upload_time_iso_8601": "2020-08-20T19:18:26.422211Z",
        "url": "https://files.pythonhosted.org/packages/41/92/88fa00e1915603ddf366e51fb720fee5bd8f69f8a4d1700c05e1604fcec5/pdf2dataset-0.4.0a1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "23c9efc0d47e6884d8f617920de2ea8383710e4b1ea6abd0a12a8aa70cdab764",
          "md5": "9954e7d3e265636dbd9f23c38de59e4c",
          "sha256": "b251fe21370dea42a0a813e20342eeddd43fd109201203d5983597010f58881e"
        },
        "downloads": -1,
        "filename": "pdf2dataset-0.4.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "9954e7d3e265636dbd9f23c38de59e4c",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6,<4.0",
        "size": 21112,
        "upload_time": "2020-08-24T03:49:53",
        "upload_time_iso_8601": "2020-08-24T03:49:53.605178Z",
        "url": "https://files.pythonhosted.org/packages/23/c9/efc0d47e6884d8f617920de2ea8383710e4b1ea6abd0a12a8aa70cdab764/pdf2dataset-0.4.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f5997205d1d999d1f4e8ea4b89dba57527f947ec9d1953fa49563fde79203e89",
          "md5": "39d7a8394550aeda6823ec2823139831",
          "sha256": "2bef75f04851d640b0f6bb3388ef0ad29710ec1366079df0e2556f63559df2fd"
        },
        "downloads": -1,
        "filename": "pdf2dataset-0.4.1.tar.gz",
        "has_sig": false,
        "md5_digest": "39d7a8394550aeda6823ec2823139831",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6,<4.0",
        "size": 23976,
        "upload_time": "2020-08-24T03:49:55",
        "upload_time_iso_8601": "2020-08-24T03:49:55.796232Z",
        "url": "https://files.pythonhosted.org/packages/f5/99/7205d1d999d1f4e8ea4b89dba57527f947ec9d1953fa49563fde79203e89/pdf2dataset-0.4.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.5.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7fff7e763aaf5f4d115627f1cf8112487ecea99857c2efc5a358e261f40c39f2",
          "md5": "a31b517118449cd011ae7841e07841d7",
          "sha256": "b8cf616ebfc337902cdeb1cff9e23518f2d8d074bfe9c92085dc0189f03ccfd2"
        },
        "downloads": -1,
        "filename": "pdf2dataset-0.5.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "a31b517118449cd011ae7841e07841d7",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6,<4.0",
        "size": 21819,
        "upload_time": "2020-08-29T03:34:38",
        "upload_time_iso_8601": "2020-08-29T03:34:38.406145Z",
        "url": "https://files.pythonhosted.org/packages/7f/ff/7e763aaf5f4d115627f1cf8112487ecea99857c2efc5a358e261f40c39f2/pdf2dataset-0.5.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f35be057e7773f38b04459cf39f6fb6fd7213a5c7b3d23b9780a82bf11751e33",
          "md5": "096ff1ce0adfeee171be7fc1faf96d27",
          "sha256": "f56af04745340d5007815c4cde6a5fa8c17cb3c27a2735f5e0a49e7fbd55ffdb"
        },
        "downloads": -1,
        "filename": "pdf2dataset-0.5.0.tar.gz",
        "has_sig": false,
        "md5_digest": "096ff1ce0adfeee171be7fc1faf96d27",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6,<4.0",
        "size": 24585,
        "upload_time": "2020-08-29T03:34:40",
        "upload_time_iso_8601": "2020-08-29T03:34:40.451636Z",
        "url": "https://files.pythonhosted.org/packages/f3/5b/e057e7773f38b04459cf39f6fb6fd7213a5c7b3d23b9780a82bf11751e33/pdf2dataset-0.5.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.5.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3aee2b186de7fc60609ce18384b686191072ce3c8baafd604a247162841d0151",
          "md5": "a7f04ec56b24bfdb3cc0942878a9c56f",
          "sha256": "2451a85c7d9c814f96ef1e5f45dcc167d683549a33b3ac46cfc8b681b9766e2b"
        },
        "downloads": -1,
        "filename": "pdf2dataset-0.5.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "a7f04ec56b24bfdb3cc0942878a9c56f",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6,<4.0",
        "size": 21871,
        "upload_time": "2020-09-01T03:44:25",
        "upload_time_iso_8601": "2020-09-01T03:44:25.241836Z",
        "url": "https://files.pythonhosted.org/packages/3a/ee/2b186de7fc60609ce18384b686191072ce3c8baafd604a247162841d0151/pdf2dataset-0.5.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "17e17963ed6dac1967d96bdcc937f79e908d2b8acd8d3a0aaf8d4bd633895551",
          "md5": "c47a54bc9cf863aca44348d84ee280ec",
          "sha256": "5366156fec79f6728781638b6fb1691b04a71a48d6f8b351fa0d4a60b013df88"
        },
        "downloads": -1,
        "filename": "pdf2dataset-0.5.1.tar.gz",
        "has_sig": false,
        "md5_digest": "c47a54bc9cf863aca44348d84ee280ec",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6,<4.0",
        "size": 24660,
        "upload_time": "2020-09-01T03:44:27",
        "upload_time_iso_8601": "2020-09-01T03:44:27.222783Z",
        "url": "https://files.pythonhosted.org/packages/17/e1/7963ed6dac1967d96bdcc937f79e908d2b8acd8d3a0aaf8d4bd633895551/pdf2dataset-0.5.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.5.1a0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0e7d5610b9564019c4565ec8272237d649aa479b4a7e6b44f39d516c2284bdb5",
          "md5": "27c1ac19025166a4543199af3afe3c51",
          "sha256": "af5a7fb876e8ae3e72605e2f065a14ad8701e257d8724e0babad50fd36165ddd"
        },
        "downloads": -1,
        "filename": "pdf2dataset-0.5.1a0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "27c1ac19025166a4543199af3afe3c51",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6,<4.0",
        "size": 21892,
        "upload_time": "2020-09-01T03:27:43",
        "upload_time_iso_8601": "2020-09-01T03:27:43.892926Z",
        "url": "https://files.pythonhosted.org/packages/0e/7d/5610b9564019c4565ec8272237d649aa479b4a7e6b44f39d516c2284bdb5/pdf2dataset-0.5.1a0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d320d6e1f90a5062c8ecfb8d90033f4a93e6011295f172f7f5a3c4679e7c90b9",
          "md5": "557b1785f619646b3eb256a4ed9b0572",
          "sha256": "eb6e7f96b2341439c86131fa6d6dfc4d9386fe68875aa9835e3a0488240770ad"
        },
        "downloads": -1,
        "filename": "pdf2dataset-0.5.1a0.tar.gz",
        "has_sig": false,
        "md5_digest": "557b1785f619646b3eb256a4ed9b0572",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6,<4.0",
        "size": 24710,
        "upload_time": "2020-09-01T03:27:45",
        "upload_time_iso_8601": "2020-09-01T03:27:45.516926Z",
        "url": "https://files.pythonhosted.org/packages/d3/20/d6e1f90a5062c8ecfb8d90033f4a93e6011295f172f7f5a3c4679e7c90b9/pdf2dataset-0.5.1a0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.5.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "97f2cd289d344f2978577472cffc45f7b6fa32bd37e45d6d2cfab176fed4bfce",
          "md5": "f2e9ccc7928bd43aac1d7544e0fdb20a",
          "sha256": "a44e81a0a02c465c987187ecbd3ae45add84c06dc098d32b1650166812ed3443"
        },
        "downloads": -1,
        "filename": "pdf2dataset-0.5.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f2e9ccc7928bd43aac1d7544e0fdb20a",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6,<4.0",
        "size": 22024,
        "upload_time": "2020-09-08T20:25:01",
        "upload_time_iso_8601": "2020-09-08T20:25:01.028044Z",
        "url": "https://files.pythonhosted.org/packages/97/f2/cd289d344f2978577472cffc45f7b6fa32bd37e45d6d2cfab176fed4bfce/pdf2dataset-0.5.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a3e22f6a620bd5fbf320d10d51bec63c9f445f4f585473a49c2bb0f33895faf6",
          "md5": "13678e81454c6113ada382cc5d858ddb",
          "sha256": "8dfd1939d46c27d98c0bfdc5f1fd45767a6b17faabc69421b22ddc1656e23c04"
        },
        "downloads": -1,
        "filename": "pdf2dataset-0.5.2.tar.gz",
        "has_sig": false,
        "md5_digest": "13678e81454c6113ada382cc5d858ddb",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6,<4.0",
        "size": 24860,
        "upload_time": "2020-09-08T20:25:03",
        "upload_time_iso_8601": "2020-09-08T20:25:03.183531Z",
        "url": "https://files.pythonhosted.org/packages/a3/e2/2f6a620bd5fbf320d10d51bec63c9f445f4f585473a49c2bb0f33895faf6/pdf2dataset-0.5.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.5.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0a58f23e05aeecefe23557cbf2a7dd7c2b10756ca1e0b92418151bc0b716d509",
          "md5": "07d9c828d0ab5b588ad27018e77138ee",
          "sha256": "e621254be6193c34e41081b5762c6d0ceda34d26636f69e20196698e3930ecbe"
        },
        "downloads": -1,
        "filename": "pdf2dataset-0.5.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "07d9c828d0ab5b588ad27018e77138ee",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6,<4.0",
        "size": 22037,
        "upload_time": "2020-09-13T04:35:50",
        "upload_time_iso_8601": "2020-09-13T04:35:50.041813Z",
        "url": "https://files.pythonhosted.org/packages/0a/58/f23e05aeecefe23557cbf2a7dd7c2b10756ca1e0b92418151bc0b716d509/pdf2dataset-0.5.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e3b16e4594ecf1dac7036e5e3e29ad8eb946c771156d6a87917e7ade2dc7c904",
          "md5": "6d4e144a7d84dec547ff5bac61d320d1",
          "sha256": "af9f204f6fff5d60c090aa2db362adb4b6e5a7215f0cfea654ee601b273e3c19"
        },
        "downloads": -1,
        "filename": "pdf2dataset-0.5.3.tar.gz",
        "has_sig": false,
        "md5_digest": "6d4e144a7d84dec547ff5bac61d320d1",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6,<4.0",
        "size": 24877,
        "upload_time": "2020-09-13T04:35:51",
        "upload_time_iso_8601": "2020-09-13T04:35:51.788839Z",
        "url": "https://files.pythonhosted.org/packages/e3/b1/6e4594ecf1dac7036e5e3e29ad8eb946c771156d6a87917e7ade2dc7c904/pdf2dataset-0.5.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "0a58f23e05aeecefe23557cbf2a7dd7c2b10756ca1e0b92418151bc0b716d509",
        "md5": "07d9c828d0ab5b588ad27018e77138ee",
        "sha256": "e621254be6193c34e41081b5762c6d0ceda34d26636f69e20196698e3930ecbe"
      },
      "downloads": -1,
      "filename": "pdf2dataset-0.5.3-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "07d9c828d0ab5b588ad27018e77138ee",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6,<4.0",
      "size": 22037,
      "upload_time": "2020-09-13T04:35:50",
      "upload_time_iso_8601": "2020-09-13T04:35:50.041813Z",
      "url": "https://files.pythonhosted.org/packages/0a/58/f23e05aeecefe23557cbf2a7dd7c2b10756ca1e0b92418151bc0b716d509/pdf2dataset-0.5.3-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "e3b16e4594ecf1dac7036e5e3e29ad8eb946c771156d6a87917e7ade2dc7c904",
        "md5": "6d4e144a7d84dec547ff5bac61d320d1",
        "sha256": "af9f204f6fff5d60c090aa2db362adb4b6e5a7215f0cfea654ee601b273e3c19"
      },
      "downloads": -1,
      "filename": "pdf2dataset-0.5.3.tar.gz",
      "has_sig": false,
      "md5_digest": "6d4e144a7d84dec547ff5bac61d320d1",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6,<4.0",
      "size": 24877,
      "upload_time": "2020-09-13T04:35:51",
      "upload_time_iso_8601": "2020-09-13T04:35:51.788839Z",
      "url": "https://files.pythonhosted.org/packages/e3/b1/6e4594ecf1dac7036e5e3e29ad8eb946c771156d6a87917e7ade2dc7c904/pdf2dataset-0.5.3.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}