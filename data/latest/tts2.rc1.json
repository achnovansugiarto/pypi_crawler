{
  "info": {
    "author": "Eren G√∂lge",
    "author_email": "egolge@coqui.ai",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Developers",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: Mozilla Public License 2.0 (MPL 2.0)",
      "Operating System :: POSIX :: Linux",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Topic :: Multimedia",
      "Topic :: Multimedia :: Sound/Audio",
      "Topic :: Multimedia :: Sound/Audio :: Speech",
      "Topic :: Scientific/Engineering :: Artificial Intelligence",
      "Topic :: Software Development",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "# <img src=\"https://raw.githubusercontent.com/coqui-ai/TTS/main/images/coqui-log-green-TTS.png\" height=\"56\"/>\n\nüê∏TTS is a library for advanced Text-to-Speech generation. It's built on the latest research, was designed to achieve the best trade-off among ease-of-training, speed and quality.\nüê∏TTS comes with pretrained models, tools for measuring dataset quality and already used in **20+ languages** for products and research projects.\n\n[![Gitter](https://badges.gitter.im/coqui-ai/TTS.svg)](https://gitter.im/coqui-ai/TTS?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge)\n[![License](<https://img.shields.io/badge/License-MPL%202.0-brightgreen.svg>)](https://opensource.org/licenses/MPL-2.0)\n[![PyPI version](https://badge.fury.io/py/TTS.svg)](https://badge.fury.io/py/TTS)\n[![Covenant](https://camo.githubusercontent.com/7d620efaa3eac1c5b060ece5d6aacfcc8b81a74a04d05cd0398689c01c4463bb/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f436f6e7472696275746f72253230436f76656e616e742d76322e3025323061646f707465642d6666363962342e737667)](https://github.com/coqui-ai/TTS/blob/master/CODE_OF_CONDUCT.md)\n[![Downloads](https://pepy.tech/badge/tts)](https://pepy.tech/project/tts)\n[![DOI](https://zenodo.org/badge/265612440.svg)](https://zenodo.org/badge/latestdoi/265612440)\n\n![GithubActions](https://github.com/coqui-ai/TTS/actions/workflows/aux_tests.yml/badge.svg)\n![GithubActions](https://github.com/coqui-ai/TTS/actions/workflows/data_tests.yml/badge.svg)\n![GithubActions](https://github.com/coqui-ai/TTS/actions/workflows/docker.yaml/badge.svg)\n![GithubActions](https://github.com/coqui-ai/TTS/actions/workflows/inference_tests.yml/badge.svg)\n![GithubActions](https://github.com/coqui-ai/TTS/actions/workflows/style_check.yml/badge.svg)\n![GithubActions](https://github.com/coqui-ai/TTS/actions/workflows/text_tests.yml/badge.svg)\n![GithubActions](https://github.com/coqui-ai/TTS/actions/workflows/tts_tests.yml/badge.svg)\n![GithubActions](https://github.com/coqui-ai/TTS/actions/workflows/vocoder_tests.yml/badge.svg)\n![GithubActions](https://github.com/coqui-ai/TTS/actions/workflows/zoo_tests.yml/badge.svg)\n[![Docs](<https://readthedocs.org/projects/tts/badge/?version=latest&style=plastic>)](https://tts.readthedocs.io/en/latest/)\n\nüì∞ [**Subscribe to üê∏Coqui.ai Newsletter**](https://coqui.ai/?subscription=true)\n\nüì¢ [English Voice Samples](https://erogol.github.io/ddc-samples/) and [SoundCloud playlist](https://soundcloud.com/user-565970875/pocket-article-wavernn-and-tacotron2)\n\nüìÑ [Text-to-Speech paper collection](https://github.com/erogol/TTS-papers)\n\n<img src=\"https://static.scarf.sh/a.png?x-pxid=cf317fe7-2188-4721-bc01-124bb5d5dbb2\" />\n\n## üí¨ Where to ask questions\nPlease use our dedicated channels for questions and discussion. Help is much more valuable if it's shared publicly so that more people can benefit from it.\n\n| Type                            | Platforms                               |\n| ------------------------------- | --------------------------------------- |\n| üö® **Bug Reports**              | [GitHub Issue Tracker]                  |\n| üéÅ **Feature Requests & Ideas** | [GitHub Issue Tracker]                  |\n| üë©‚Äçüíª **Usage Questions**          | [Github Discussions]                    |\n| üóØ **General Discussion**       | [Github Discussions] or [Gitter Room]   |\n\n[github issue tracker]: https://github.com/coqui-ai/tts/issues\n[github discussions]: https://github.com/coqui-ai/TTS/discussions\n[gitter room]: https://gitter.im/coqui-ai/TTS?utm_source=share-link&utm_medium=link&utm_campaign=share-link\n[Tutorials and Examples]: https://github.com/coqui-ai/TTS/wiki/TTS-Notebooks-and-Tutorials\n\n\n## üîó Links and Resources\n| Type                            | Links                               |\n| ------------------------------- | --------------------------------------- |\n| üíº **Documentation**              | [ReadTheDocs](https://tts.readthedocs.io/en/latest/)\n| üíæ **Installation**               | [TTS/README.md](https://github.com/coqui-ai/TTS/tree/dev#install-tts)|\n| üë©‚Äçüíª **Contributing**               | [CONTRIBUTING.md](https://github.com/coqui-ai/TTS/blob/main/CONTRIBUTING.md)|\n| üìå **Road Map**                   | [Main Development Plans](https://github.com/coqui-ai/TTS/issues/378)\n| üöÄ **Released Models**            | [TTS Releases](https://github.com/coqui-ai/TTS/releases) and [Experimental Models](https://github.com/coqui-ai/TTS/wiki/Experimental-Released-Models)|\n\n## ü•á TTS Performance\n<p align=\"center\"><img src=\"https://raw.githubusercontent.com/coqui-ai/TTS/main/images/TTS-performance.png\" width=\"800\" /></p>\n\nUnderlined \"TTS*\" and \"Judy*\" are üê∏TTS models\n<!-- [Details...](https://github.com/coqui-ai/TTS/wiki/Mean-Opinion-Score-Results) -->\n\n## Features\n- High-performance Deep Learning models for Text2Speech tasks.\n    - Text2Spec models (Tacotron, Tacotron2, Glow-TTS, SpeedySpeech).\n    - Speaker Encoder to compute speaker embeddings efficiently.\n    - Vocoder models (MelGAN, Multiband-MelGAN, GAN-TTS, ParallelWaveGAN, WaveGrad, WaveRNN)\n- Fast and efficient model training.\n- Detailed training logs on the terminal and Tensorboard.\n- Support for Multi-speaker TTS.\n- Efficient, flexible, lightweight but feature complete `Trainer API`.\n- Released and ready-to-use models.\n- Tools to curate Text2Speech datasets under```dataset_analysis```.\n- Utilities to use and test your models.\n- Modular (but not too much) code base enabling easy implementation of new ideas.\n\n## Implemented Models\n### Text-to-Spectrogram\n- Tacotron: [paper](https://arxiv.org/abs/1703.10135)\n- Tacotron2: [paper](https://arxiv.org/abs/1712.05884)\n- Glow-TTS: [paper](https://arxiv.org/abs/2005.11129)\n- Speedy-Speech: [paper](https://arxiv.org/abs/2008.03802)\n- Align-TTS: [paper](https://arxiv.org/abs/2003.01950)\n- FastPitch: [paper](https://arxiv.org/pdf/2006.06873.pdf)\n- FastSpeech: [paper](https://arxiv.org/abs/1905.09263)\n\n### End-to-End Models\n- VITS: [paper](https://arxiv.org/pdf/2106.06103)\n\n### Attention Methods\n- Guided Attention: [paper](https://arxiv.org/abs/1710.08969)\n- Forward Backward Decoding: [paper](https://arxiv.org/abs/1907.09006)\n- Graves Attention: [paper](https://arxiv.org/abs/1910.10288)\n- Double Decoder Consistency: [blog](https://erogol.com/solving-attention-problems-of-tts-models-with-double-decoder-consistency/)\n- Dynamic Convolutional Attention: [paper](https://arxiv.org/pdf/1910.10288.pdf)\n- Alignment Network: [paper](https://arxiv.org/abs/2108.10447)\n\n### Speaker Encoder\n- GE2E: [paper](https://arxiv.org/abs/1710.10467)\n- Angular Loss: [paper](https://arxiv.org/pdf/2003.11982.pdf)\n\n### Vocoders\n- MelGAN: [paper](https://arxiv.org/abs/1910.06711)\n- MultiBandMelGAN: [paper](https://arxiv.org/abs/2005.05106)\n- ParallelWaveGAN: [paper](https://arxiv.org/abs/1910.11480)\n- GAN-TTS discriminators: [paper](https://arxiv.org/abs/1909.11646)\n- WaveRNN: [origin](https://github.com/fatchord/WaveRNN/)\n- WaveGrad: [paper](https://arxiv.org/abs/2009.00713)\n- HiFiGAN: [paper](https://arxiv.org/abs/2010.05646)\n- UnivNet: [paper](https://arxiv.org/abs/2106.07889)\n\nYou can also help us implement more models.\n\n## Install TTS\nüê∏TTS is tested on Ubuntu 18.04 with **python >= 3.7, < 3.11.**.\n\nIf you are only interested in [synthesizing speech](https://tts.readthedocs.io/en/latest/inference.html) with the released üê∏TTS models, installing from PyPI is the easiest option.\n\n```bash\npip install TTS\n```\n\nIf you plan to code or train models, clone üê∏TTS and install it locally.\n\n```bash\ngit clone https://github.com/coqui-ai/TTS\npip install -e .[all,dev,notebooks]  # Select the relevant extras\n```\n\nIf you are on Ubuntu (Debian), you can also run following commands for installation.\n\n```bash\n$ make system-deps  # intended to be used on Ubuntu (Debian). Let us know if you have a diffent OS.\n$ make install\n```\n\nIf you are on Windows, üëë@GuyPaddock wrote installation instructions [here](https://stackoverflow.com/questions/66726331/how-can-i-run-mozilla-tts-coqui-tts-training-with-cuda-on-a-windows-system).\n\n## Use TTS\n\n### Single Speaker Models\n\n- List provided models:\n\n    ```\n    $ tts --list_models\n    ```\n\n- Run TTS with default models:\n\n    ```\n    $ tts --text \"Text for TTS\"\n    ```\n\n- Run a TTS model with its default vocoder model:\n\n    ```\n    $ tts --text \"Text for TTS\" --model_name \"<language>/<dataset>/<model_name>\n    ```\n\n- Run with specific TTS and vocoder models from the list:\n\n    ```\n    $ tts --text \"Text for TTS\" --model_name \"<language>/<dataset>/<model_name>\" --vocoder_name \"<language>/<dataset>/<model_name>\" --output_path\n    ```\n\n- Run your own TTS model (Using Griffin-Lim Vocoder):\n\n    ```\n    $ tts --text \"Text for TTS\" --model_path path/to/model.pth --config_path path/to/config.json --out_path output/path/speech.wav\n    ```\n\n- Run your own TTS and Vocoder models:\n    ```\n    $ tts --text \"Text for TTS\" --model_path path/to/config.json --config_path path/to/model.pth --out_path output/path/speech.wav\n        --vocoder_path path/to/vocoder.pth --vocoder_config_path path/to/vocoder_config.json\n    ```\n\n### Multi-speaker Models\n\n- List the available speakers and choose as <speaker_id> among them:\n\n    ```\n    $ tts --model_name \"<language>/<dataset>/<model_name>\"  --list_speaker_idxs\n    ```\n\n- Run the multi-speaker TTS model with the target speaker ID:\n\n    ```\n    $ tts --text \"Text for TTS.\" --out_path output/path/speech.wav --model_name \"<language>/<dataset>/<model_name>\"  --speaker_idx <speaker_id>\n    ```\n\n- Run your own multi-speaker TTS model:\n\n    ```\n    $ tts --text \"Text for TTS\" --out_path output/path/speech.wav --model_path path/to/config.json --config_path path/to/model.pth --speakers_file_path path/to/speaker.json --speaker_idx <speaker_id>\n    ```\n\n## Directory Structure\n```\n|- notebooks/       (Jupyter Notebooks for model evaluation, parameter selection and data analysis.)\n|- utils/           (common utilities.)\n|- TTS\n    |- bin/             (folder for all the executables.)\n      |- train*.py                  (train your target model.)\n      |- distribute.py              (train your TTS model using Multiple GPUs.)\n      |- compute_statistics.py      (compute dataset statistics for normalization.)\n      |- ...\n    |- tts/             (text to speech models)\n        |- layers/          (model layer definitions)\n        |- models/          (model definitions)\n        |- utils/           (model specific utilities.)\n    |- speaker_encoder/ (Speaker Encoder models.)\n        |- (same)\n    |- vocoder/         (Vocoder models.)\n        |- (same)\n```\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/coqui-ai/TTS",
    "keywords": "",
    "license": "MPL-2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "TTS2",
    "package_url": "https://pypi.org/project/TTS2/",
    "platform": null,
    "project_url": "https://pypi.org/project/TTS2/",
    "project_urls": {
      "Discussions": "https://github.com/coqui-ai/TTS/discussions",
      "Documentation": "https://github.com/coqui-ai/TTS/wiki",
      "Homepage": "https://github.com/coqui-ai/TTS",
      "Repository": "https://github.com/coqui-ai/TTS",
      "Tracker": "https://github.com/coqui-ai/TTS/issues"
    },
    "release_url": "https://pypi.org/project/TTS2/0.7.0.1/",
    "requires_dist": [
      "numpy",
      "cython (==0.29.28)",
      "scipy (>=1.4.0)",
      "torch (>=1.7)",
      "torchaudio",
      "soundfile",
      "librosa (==0.8.0)",
      "numba (==0.53.1)",
      "inflect",
      "tqdm",
      "anyascii",
      "pyyaml",
      "fsspec (>=2021.04.0)",
      "flask",
      "pysbd",
      "umap-learn (==0.5.1)",
      "pandas",
      "matplotlib",
      "pyworld (==0.2.10)",
      "trainer",
      "coqpit (>=0.0.16)",
      "jieba",
      "pypinyin",
      "mecab-python3 (==1.0.5)",
      "unidic-lite (==1.0.8)",
      "gruut[cs,de,es,fr,it,nl,pt,ru,sv] (==2.2.3)",
      "black ; extra == 'all'",
      "coverage ; extra == 'all'",
      "isort ; extra == 'all'",
      "nose2 ; extra == 'all'",
      "pylint (==2.10.2) ; extra == 'all'",
      "bokeh (==1.4.0) ; extra == 'all'",
      "black ; extra == 'dev'",
      "coverage ; extra == 'dev'",
      "isort ; extra == 'dev'",
      "nose2 ; extra == 'dev'",
      "pylint (==2.10.2) ; extra == 'dev'",
      "bokeh (==1.4.0) ; extra == 'notebooks'"
    ],
    "requires_python": ">=3.7.0, <3.11",
    "summary": "Deep learning for Text to Speech by Coqui.",
    "version": "0.7.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14530409,
  "releases": {
    "0.7.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "abadc6e6f09a6cff60ccf59ff179908d951cdad899b8635a8d2d7f223813d1df",
          "md5": "78daae4c3e5e7415f5eab1a5bbd36b10",
          "sha256": "e96d03a1adf4b2070dfa4c87dd95256c8af5af2875f5f0cdcd29bc5233231cbd"
        },
        "downloads": -1,
        "filename": "TTS2-0.7.0.1-cp39-cp39-manylinux1_x86_64.whl",
        "has_sig": false,
        "md5_digest": "78daae4c3e5e7415f5eab1a5bbd36b10",
        "packagetype": "bdist_wheel",
        "python_version": "cp39",
        "requires_python": ">=3.7.0, <3.11",
        "size": 546482,
        "upload_time": "2022-07-24T07:09:28",
        "upload_time_iso_8601": "2022-07-24T07:09:28.669748Z",
        "url": "https://files.pythonhosted.org/packages/ab/ad/c6e6f09a6cff60ccf59ff179908d951cdad899b8635a8d2d7f223813d1df/TTS2-0.7.0.1-cp39-cp39-manylinux1_x86_64.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d1dade13f5b6134c37bd73ee4ebc000182b22306d7d6c33f1c6de18438120c0f",
          "md5": "c497905a6617e85c3fdb70e756f1442c",
          "sha256": "fafb00ba2dff786eafb35d2f632d6332a1cfcaee192d392c9cfed44385a9aee2"
        },
        "downloads": -1,
        "filename": "TTS2-0.7.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "c497905a6617e85c3fdb70e756f1442c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7.0, <3.11",
        "size": 1344921,
        "upload_time": "2022-07-24T07:09:32",
        "upload_time_iso_8601": "2022-07-24T07:09:32.096223Z",
        "url": "https://files.pythonhosted.org/packages/d1/da/de13f5b6134c37bd73ee4ebc000182b22306d7d6c33f1c6de18438120c0f/TTS2-0.7.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "abadc6e6f09a6cff60ccf59ff179908d951cdad899b8635a8d2d7f223813d1df",
        "md5": "78daae4c3e5e7415f5eab1a5bbd36b10",
        "sha256": "e96d03a1adf4b2070dfa4c87dd95256c8af5af2875f5f0cdcd29bc5233231cbd"
      },
      "downloads": -1,
      "filename": "TTS2-0.7.0.1-cp39-cp39-manylinux1_x86_64.whl",
      "has_sig": false,
      "md5_digest": "78daae4c3e5e7415f5eab1a5bbd36b10",
      "packagetype": "bdist_wheel",
      "python_version": "cp39",
      "requires_python": ">=3.7.0, <3.11",
      "size": 546482,
      "upload_time": "2022-07-24T07:09:28",
      "upload_time_iso_8601": "2022-07-24T07:09:28.669748Z",
      "url": "https://files.pythonhosted.org/packages/ab/ad/c6e6f09a6cff60ccf59ff179908d951cdad899b8635a8d2d7f223813d1df/TTS2-0.7.0.1-cp39-cp39-manylinux1_x86_64.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "d1dade13f5b6134c37bd73ee4ebc000182b22306d7d6c33f1c6de18438120c0f",
        "md5": "c497905a6617e85c3fdb70e756f1442c",
        "sha256": "fafb00ba2dff786eafb35d2f632d6332a1cfcaee192d392c9cfed44385a9aee2"
      },
      "downloads": -1,
      "filename": "TTS2-0.7.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "c497905a6617e85c3fdb70e756f1442c",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7.0, <3.11",
      "size": 1344921,
      "upload_time": "2022-07-24T07:09:32",
      "upload_time_iso_8601": "2022-07-24T07:09:32.096223Z",
      "url": "https://files.pythonhosted.org/packages/d1/da/de13f5b6134c37bd73ee4ebc000182b22306d7d6c33f1c6de18438120c0f/TTS2-0.7.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}