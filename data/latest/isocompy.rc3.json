{
  "info": {
    "author": null,
    "author_email": "IDAEA-CSIC / Ashkan Hassanzadeh <ashkan.hassanzadeh@gmail.com>",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "License :: OSI Approved :: GNU Affero General Public License v3 or later (AGPLv3+)",
      "Programming Language :: Python :: 3"
    ],
    "description": "# ***Isocompy***\n\nThis library contains an open source Python library that focuses on user defined (such as meteorological, spatial, etc.) and isotopic composition variables analysis and generating the regression â€“ statistical estimation models using machine-learning techniques\n\n---\n---\n\n## ***Package information:***\n\\\nName: Isocompy\n\nversion: 1.0.0\n\nAuthor: Ashkan Hassanzadeh   \n\nEmail: ashkan.hassanzadeh@gmail.com\n\npython: 3.*\n\nLicense: agpl-3.0\n\n---\n---\n\n## ***Installation:***\n\\\npip can be used for the installation:\n\n`pip install isocompy`\n\nAlternatively, download the isocompy folder and add it to lib folder in python path alongside other python libraries.\n\n---\n---\n\n## ***Jupyter Notebook:***\n\\\nThere is a notebook that explains an example of implementing isocompy on spatial and isotopic data\n\n***Instruction manual:***\n\n\n# class preprocess( ):\n\nThe class to preprocess the input variables of each model group and initiate\nthe models properties such as cross-validation and  brute-force searching.\n\n---\n---\n## **Parameters:**\n\n(\\_\\_init__ method of preprocess class)\n\n**tunedpars_rfr** dic, default= `{\"min_weight_fraction_leaf\":[0,0.02,0.04],\"n_estimators\":[50,100,150,2'00,250,300],\"criterion\": [\"mse\",\"mae\"],\"min_samples_split\":[2,5] }`\n\nThe dictionary that determines brute-force searching parameters of Random Forest regression. For more details on the regression method inputs, refer to sklearn library.\n\n---        \n**tunedpars_svr** dic default=`{\"kernel\":[ \"poly\", \"rbf\", \"sigmoid\"],\"C\":np.logspace(-1, 1, 3),\"gamma\":np.logspace(-3, 1, 3) }`\n\nThe dictionary that determines brute-force searching parameters of Support Vector regression. For more details on the regression method inputs, refer to sklearn library.\n\n---        \n**tunedpars_nusvr** dic default=`{\"kernel\":[\"linear\", \"poly\", \"rbf\", \"sigmoid\"] }`\n\nThe dictionary that determines brute-force searching parameters of Nu Support Vector Regression. For more details on the regression method inputs, refer to sklearn library.\n\n---    \n**tunedpars_mlp** dic default=`{\"activation\" : [ \"logistic\", \"tanh\"],\"solver\" : [\"lbfgs\", \"sgd\", \"adam\"],\"alpha\":[0.0001,0.0003],\"hidden_layer_sizes\":[(50,)*2,(50,)*3,(50,)*4,(100,)*2,(100,)*3,(100,)*4],\"max_iter\":[1000],\"n_iter_no_change\":[10]}`\n\nThe dictionary that determines brute-force searching parameters of Multilayer Perceptron regression. For more details on the regression method inputs, refer to sklearn library.\n\n---\n**tunedpars_lr** dic default=`{}`\n\nThe dictionary that determines brute-force searching parameters of Linear regression. For more details on the regression method inputs, refer to sklearn library.\n\n---\n**tunedpars_br** dic default=`{}`\n\nThe dictionary that determines brute-force searching parameters of Bayesian Ridge regression. For more details on the regression method inputs, refer to sklearn library.\n\n---\n**tunedpars_ard** dic default=`{}`\n\nThe dictionary that determines brute-force searching parameters of Bayesian ARD regression. For more details on the regression method inputs, refer to sklearn library.\n\n---\n**tunedpars_omp** dic default=`{}`\n\nThe dictionary that determines brute-force searching parameters of Orthogonal Matching Pursuit regression. For more details on the regression method inputs, refer to sklearn library.\n\n---\n**tunedpars_elnet** dic default=`{\"l1_ratio\":[.1, .5, .7,.9,.99]}`\n\nThe dictionary that determines brute-force searching parameters of ElasticNet (Linear regression with combined L1 and L2 priors as regularizer) regression. For more details on the regression method inputs, refer to sklearn library.\n\n---\n**tunedpars_muelnet** dic default= `{\"l1_ratio\":[.1, .5, .7,.9,.99]}`\n\nThe dictionary that determines brute-force searching parameters of Multi-task ElasticNet (trained with L1/L2 mixed-norm as regularizer) regression. For more details on the regression method inputs, refer to sklearn library.\n\n---\n**which_regs** dic default= `{\"muelnet\":True, \"rfr\":True, \"mlp\":True, \"elnet\":True, \"omp\":True, \"br\":True, \"ard\":True, \"svr\":True, \"nusvr\":False}`\n\nThe dictionary that determines which regression models have to be included in cross-validation and  brute-force searching process\n\n---\n**apply_on_log** Boolean default=`True`\n\nIf `True`, Apart from the main values, fits the models to log(1 + x) (Natural logarithm) of data. If the scores of the regression on logarithm of the data is higher\nthan the real values, The chosen method will always calculate the log(1 + x) of the data before fitting the models. Note that if this is the case, to have the real\noutputs, exp(x) - 1 (the inverse of log(1 + x)) will be calculated.\n\n---\n**cv** int or Boolean default=`\"auto\"`\n\nIf cv=\"auto\", the cross-validation number of folds will be calculated automatically. It is beneficial when there is few data available (max=10, min=2). If cv is an integer values,\nit determines number of folds of the cross-validation.\n\n---\n---\n\n## **Methods:**\n\n* \\_\\_init__ (self)\n\n* fit()\n\n* model_pars()\n\n---\n---\n## **Attributes:**\n\n**model_pars_name_dic** dic\n\nA dictionary that stores brute-force searching parameters of all models. The keys and values are dictionary names and parameters dictionaries respectively\n    \n*EXAMPLE:*\n\n```python\n\nkey: \"tunedpars_rfr\"\n\nValue: tunedpars_rfr= {\"min_weight_fraction_leaf\":[0,0.04],\"n_estimators\":[150,200],\"criterion\": [\"mse\"] }\n\n```\n\n*IMPORTANT NOTE*: `'model_pars'` method have to be used to change the brute-force searching parameters\n    \n\n---\n**db_input_args_dics** dic \n\nA dictionary that stores input parameters of the fit method\n\n---\n**direc** str\n\nThe directory of the data preprocessing class output\n\n---\n**month_grouped_inp_var** list\n\nA list of monthly grouped data. Each element of the list is a dataframe containing the grouped data of an specific month \n\n---\n---\n---\n# preprocess.fit( )\n\npreprocess.fit(self, inp_var, var_name, fields, direc, remove_outliers=True,write_outliers_input=True, year_type=\"all\", inc_zeros_inp_var=False, write_integrated_data=True, q1=0.05, q3=0.95, IQR_inp_var=True, IQR_rat_inp_var=3, mean_mode_inp_var=\"arithmetic\", elnino=None, lanina=None)\n\n\nThe method to preprocess the input data of the models\n\n---\n---\n## Parameters:\n\n**inp_var** Pandas dataframe\n\nInput pandas dataframe containing the dependent value, unique IDs\nfor each sample, and date. (The columns \"Value\", \"ID\" and \"Date\" have to be found in the dataframe)\n\n---\n**var_name** str\n\nName of the dependent variable.\n\n---\n**fields** list of strings\n\nList of independent variable names that have to be existed in the inp_var dataframe\n\n---\n**direc** str\n\nThe directory of the data preprocessing class output\n\n---\n**remove_outliers** Boolean default=`True`\n\nTo remove outliers based on the introduced variables. If False, the variables related to removing outliers will be ignored.\n\n---\n**write_outliers_input** Boolean default=`True`\n\nEffective if remove_outliers=True. To generate .xls file in directory folders of the class after removing outliers\n\n---\n**year_type** str default=`\"all\"`\n\n`\"all\"`, `\"elnino\"` or `\"lanina\"`. In case elnino or lanina years have to be selected from the database\n\n---\n**inc_zeros_inp_var** Boolean default=`False`\n\nEffective if remove_outliers=`True`. Removing outliers could be done not considering the zero values in the database.\n(The zero values will be seperated, outliers will be removed, then zero values will be added to database)\n\n---\n**write_integrated_data** Boolean default=`True`\n\nGenerate two .xls outputs consisting of integrated data, and the quantity of data in each month\n\n---\n**q1** float default=`0.05`\n\nEffective if remove_outliers=True and IQR_inp_var=False. Lower percentile limit to determine the outliers.\n\n---\n**q3** float default=`0.95`\n\nEffective if remove_outliers=True  and IQR_inp_var=False. Upper percentile limit to determine the outliers\n\n---\n**IQR_inp_var** Boolean default=`True`\n\nEffective if remove_outliers=True. Determining the upper limit of the outliers using this \nformula: $X*q_{0.75} + IQR_{rat}*abs(X*  q{0.25} - X * q_{0.75})$\n\nLower limit = q1\n\n---\n**IQR_rat_inp_var** float default=`3`\n\nEffective if remove_outliers=True and IQR_inp_var=True. This parameter used in  X*q_0.75 + IQR_rat*abs(X*q_0.25 - X*q_0.75) \nto determine upper boundary limit.\n\n---\n**mean_mode_inp_var** str default=`\"arithmetic\"`\n\nData averaging method. available options are `\"arithmetic\"`  or `\"geometric\"`\n\n---\n**elnino** None type or list of integers default=`None`\n\nList of elnino years\n\n---\n**lanina** None type or list of integers default=`None`\n\nList of lanina years\n\n---\n---\n## Attributes:\n\n**db_input_args_dics** dic \n\nA dictionary that stores input parameters of the fit method\n\n---\n**direc** str\n\nThe directory of the data preprocessing class output\n\n---\n**month_grouped_inp_var** list\n\nA list of monthly grouped data. Each element of the list is a dataframe containing the grouped data of an specific month \n\n---\n---\n---\n# preprocess.model_pars( )\n\npreprocess.model_pars(self,**kwargs):\n\nTo change the brute-force searching parameters that is already determined in a class. \n\n---\n*EXAMPLE:*\n```python\n#Define the new brute-force searching parameters dictionaries:\n\n#brute-force searching parameters for random forest\nbrutesearch_ran_for_dic={\"min_weight_fraction_leaf\":[0,0.04],\"n_estimators\":[150,200],\"criterion\": [\"mse\"] }\n\n#brute-force searching parameters for elastic net\nbrutesearch_elasticnet_dic={\"l1_ratio\":[ .5, .9]}\n\n#change the brute-force searching parameters\nprep_class.model_pars( \"tunedpars_rfr\" = brutesearch_ran_for_dic, \"tunedpars_elnet\" = brutesearch_elasticnet_dic )\n\n```\n---\n---\n---\n# class model ( ):\n\nThe class to fit the regression models in stage one, predict the stage one results and fit stage two regresison models\n\n---\n---\n## **Methods:**\n\n* \\_\\_init__(self)\n\n* st1_fit()\n\n* st1_predict()\n\n* st2_fit()\n\n* choose_estimator_by_meteo_line()\n\n* stage2_output_report()\n\n---\n---\n## **Attributes:**\n\n(\\_\\_init__ method of model class)\n\n\n**direc** str\n\nDirectory of the class\n\n---\n**st1_model_results_dic** dict\n\nA dictionary consist of st1 model results\n\n---\n**st1_varname_list** list\n\nList of the names of independent variables in st1\n\n---\n**st1_model_month_list** list\n\nList of desired months to model in st1\n\n---\n**used_feature_list** list\n\nList of all used features (strings) in st1\n\n---\n**cls_list** list\n\nA list of preprocess class objects that we wish to model in st2\n\n---\n**all_pred** Pandas Dataframe\n\nA dataframe of all st1 predictions\n\n---\n**predictions_monthly_list** list\n\nDataframes of predictions of stage one, seperated monthly as list elements \n\n---\n**st2_model_month_list** list\n\nList of desired months to model in st1. Indicated months have to exist in st1_model_month_list\n\n---\n**dic_second_stage_names** dict\n\nHelps in generating model_var_dict in st2_fit\n\n---\n**st2_model_results_dic** dict\n\nA dictionary consist of st2 model results\n\n---\n**dependent_model_selection** boolean\n\nTo select the best model based on meteorological line. only useful if there is a linear refrence line (EX:Isotopes)\n\n---\n**meteo_coef** float \n\nIf dependent_model_selection=`True`,global_line, coefficient of the line\n\n---\n**meteo_intercept** float\n\nIf dependent_model_selection=`True`,global_line, intercept of the line\n\n---\n**selection_method** str\n\nIf dependent_model_selection=`True`, selection_method: `independent`,`local_line`,`global_line`, `point_to_point`\n\n---\n**thresh_meteoline_high_scores** None type or float\n\nA threshold to just consider models with scores higher than that value. if none, equal to mean of scores+std of scores/3\n\n---\n**model_selection_report** boolean\n\n`True` or `False`, to determine if there is a need to model selection method report\n\n---\n---\n---\n# model.st1_fit ( )\n\nmodel.st1_fit (`self,var_cls_list,direc,st1_model_month_list=\"all\",args_dic= { \"feature_selection\" : \"auto\" , \"vif_threshold\" : 5, \"vif_selection_pairs\":[],\"correlation_threshold\":0.87,\"vif_corr\":True,\"p_val\":0.05}`)\n\nThe method to fit regression models to identified preprocess class objects in stage one \n\n---\n---\n## **Parameters:**\n\n**var_cls_list** list\n\nA list of preprocess class objects to to fit regression models. Regression models will be fitted to each elemnt of the list (a preprocess class object).\n\n---\n**direc** str\n\nDirectory of the class\n\n---\nst1_model_month_list str or list of integers default=`\"all\"`\n\nList of desired months to model in st1\n\n---\n**args_dic** dict default={`\"feature_selection\":\"auto\",\"vif_threshold\":5, \"vif_selection_pairs\":[],\"correlation_threshold\":0.87,\"vif_corr\":True,\"p_val\":0.05}`\n\nA dictionary of parameters that identifies the behaviour of feature selection prior to regressions:    \n    \n* args_dic[`\"feature_selection\"`] =\"manual\": Statistical information will be shown to the user, and the desired features will be\nchosen by the user\n\n* args_dic[`\"feature_selection\"`] =\"auto\": Feature selection will be done automatically\n\n* args_dic[`\"vif_threshold\"`] =None: VIF (Variation Inflation Factor) will not be considered as a factor in feature selection\n\n* args_dic[`\"vif_threshold\"`] = float type: A threshold to identify high VIF values\n\n* args_dic[`\"vif_corr\"`] = True: If True, use correlation coefficient values to identify multicolinearity in features with high vif value\n\n* args_dic[`\"correlation_threshold\"`] = 0.87 A threshold to identify high correlation coefficient values\n\n* args_dic[`\"vif_selection_pairs\"`] = empty list or list of list(s): If empty: feature elimination based on vif will be automatic\n\nif  args_dic[`\"vif_selection_pairs\"`] =[ [`\"a\",\"b\"`] ], in case both `\"a\"` and `\"b\"` have high vif values and high correlations, the b values will be eliminated\n\n---\n---\n## **Attributes:**\n\n**direc** str\n\nDirectory of the class\n\n---\n**st1_model_results_dic** dict\n\nA dictionary consist of st1 model results\n\n---\n**st1_varname_list** list\n\nList of the names of independent variables in st1\n\n---\n**st1_model_month_list** list\n\nList of desired months to model in st1\n\n---\n---\n---\n# model.st1_predict()\n    \nmodel.st1_predict(`self, cls_list, st2_model_month_list=None, trajectories=False, daily_rain_data_for_trajs=None`)\n\nThe method to estimate the independent features that modeled in st1 using the new observations that are in a new list (cls_list) which each element is a preprocess class objects \n\n---\n---\n## **Parameters:**\n\n**cls_list** list\n\nA list of preprocess class objects that we wish to model in st2\n\n---\n**st2_model_month_list** list or None type default=`None`\n\nList of desired months to model in st1. Indicated months have to exist in st1_model_month_list. If None, it will be equal to st1_model_month_list\n\n---\n---\n## **Attributes:**\n\n**used_feature_list** list\n\nList of all used features (strings) in st1\n\n---\n**cls_list** list\n\nA list of preprocess class objects that we wish to model in st2\n\n---\n**all_pred Pandas** Dataframe\n\nA dataframe of all st1 predictions in observed samples\n\n---\n**predictions_monthly_list** list\n\nDataframes of predictions of stage one, seperated monthly as list elements \n\n---\ns**t2_model_month_list** list\n\nList of desired months to model in st1. Indicated months have to exist in st1_model_month_list\n\n---\n---\n---\n# model.st2_fit ( )\n\nmodel.st2_fit (`self,model_var_dict=None, output_report=True, dependent_model_selection=False, dependent_model_selection_list=None, meteo_coef=8, meteo_intercept=10, selection_method=\"point_to_point\", thresh_meteoline_high_scores=None, model_selection_report=True, args_dic={\"feature_selection\":\"auto\", \"vif_threshold\":5, \"vif_selection_pairs\":[], \n\"correlation_threshold\":0.87, \"vif_corr\":True,\"p_val\":0.05}`):\n  \nThe method to fit regression models to identified preprocess class objects in stage one\n\n---\n---\n\n## **Parameters:**\n\n**model_var_dict** None type or dict  default=`None`\n\nA dictionary that determines dependent (key - string) and independent (value) features of the second stage regression models.\nIndependent features (value) have to be a list of feature names (string).\n\nIf `None`, all features (independent st1 features and dependent st1 features) will be\nconsidered as independent features of second stage models.\n\n* *EXAMPLE:*\n```pyhton\nmodel_var_dict = {\"is1\":[\"CooZ\",\"hmd\"],\"is2\":[\"prc\",\"hmd\"],}\n```\n---\n**output_report** boolean default=`True`\n\nTo generate output reports\n\n---\n*Parameters used in choose_estimator_by_meteo_line* \n\n**dependent_model_selection** boolean default=`False`\nTo select the best model based on a (meteorological) line. only useful if there is a linear refrence line (EX:Isotopes)\n\n---\n**dependent_model_selection_list** default=`None`\n\nUsed if dependent_model_selection=`True`. List of two features that have to be used in `dependent_model_selection`\n\n---\n**meteo_coef** default=`8`\n\nUsed if dependent_model_selection=`True` and selection_method=`\"global_line\"`. Coefficient of the line\n\n---\n**meteo_intercept** default=`10`\n\nUsed if dependent_model_selection=`True` and selection_method=`\"global_line\"`. Intercept of the line\n\n---\n**selection_method** default=\"point_to_point\"\n\nUsed if `dependent_model_selection`=`True`. `selection_method` could be:\n\n* `independent`\n* `local_line`: coef and intercept derived from a linear regression of observed data\n* `global_line`\n* `point_to_point`: find the models pair with shortest average distance between observed and predicted data  \n\n---\n**thresh_meteoline_high_scores** None type or float default=`None`\n\nA threshold to just consider models with scores higher than that value. if `None`, equal to mean of scores+std of scores/3\n\n---\n**model_selection_report** boolean default =`True`\n\nTo determine if there is a need to model selection method report\n\n---\n**args_dic** dict default=`{\"feature_selection\":\"auto\",\"vif_threshold\":5, \"vif_selection_pairs\":[], \"correlation_threshold\": 0.87, \"vif_corr\": True, \"p_val\":0.05}`\n\nA dictionary of parameters that identifies the behaviour of feature selection prior to regressions:    \n    \n* args_dic[`\"feature_selection\"`] =`\"manual\"`: Statistical information will be shown to the user, and the desired features will be\nchosen by the user\n\n* args_dic[`\"feature_selection\"`] =`\"auto\"`: Feature selection will be done automatically\n\n* args_dic[`\"vif_threshold\"`] =None: VIF (Variation Inflation Factor) will not be considered as a factor in feature selection\n\n* args_dic[`\"vif_threshold\"`] = float type: A threshold to identify high VIF values\n\n* args_dic[`\"vif_corr\"`] = `True`: If True, use correlation coefficient values to identify multicolinearity in features with high vif value\n\n* args_dic[`\"correlation_threshold\"`] = `0.87` A threshold to identify high correlation coefficient values\n\n* args_dic[`\"vif_selection_pairs\"`] = empty list or list of list(s): If empty: feature elimination based on vif will be automatic\n\nif  args_dic[`\"vif_selection_pairs\"`] =[ [`\"a\",\"b\"`] ], in case both `\"a\"` and `\"b\"` have high vif values and high correlations, the b values will be eliminated\n\n---\n---\n## **Attributes:**\n\n**st2_model_results_dic** dict\n\nA dictionary consist of st2 model results\n\n---\n*Attributes used in choose_estimator_by_meteo_line* \n\n**dependent_model_selection** boolean\n\nTo select the best model based on meteorological line. only useful if there is a linear refrence line (EX:Isotopes)\n\n---\n**meteo_coef** float \n\nIf dependent_model_selection=`True`, global_line, coefficient of the line\n\n---\n**meteo_intercept** float\n\nIf dependent_model_selection=`True`, global_line, intercept of the line\n\n---\n**selection_method** str\n\nIf dependent_model_selection=`True`, selection_method: `\"independent\", \"local_line\", \"global_line\", \"point_to_point\"`\n\n---\n**thresh_meteoline_high_scores None type or float\n\nA threshold to just consider models with scores higher than that value. if `None`, equal to mean of scores+std of scores/3\n\n---\n**model_selection_report** boolean\n\nTo determine if there is a need to model selection method report\n\n---\n---\n---\n# model.choose_estimator_by_meteo_line ( )\n\n\nmodel.choose_estimator_by_meteo_line( `self, dependent_model_selection_list, selection_method=\"point_to_point\", model_selection_report=True, thresh_meteoline_high_scores=None, meteo_coef=8, meteo_intercept=10` ):\n\nThe method to select the best model based on a (meteorological) line. only useful if there is a linear refrence line (EX:Isotopes).\nThis method could be called automatically in st2_fit if dependent_model_selection=True. or it can be called after st2_fit execution\nto see the changes in best regression models based on different criterias.\n\n*IMPORTANT NOTE:*  Executing this method will update the st2_model_results_dic to match the latest chosen selection_method. st2_model_results_dic stores the second stage results.\n\n---\n---\n\n## Parameters:\n\n**dependent_model_selection_list** default=`None`\n\nUsed if dependent_model_selection=True. List of two features that have to be used in dependent_model_selection\n\n---\n**meteo_coef** default=8\n\nUsed if dependent_model_selection=`True` and selection_method=`\"global_line\"`. Coefficient of the line\n\n---\n**meteo_intercept** default=10\n\nUsed if dependent_model_selection=`True` and selection_method=`\"global_line\"`. Intercept of the line\n\n---\n**selection_method** default=`\"point_to_point\"`\n\nUsed if dependent_model_selection=`True`. Selection_method could be:\n\n* `\"independent\"`\n* `\"local_line\"`: coef and intercept derived from a linear regression of observed data\n* `\"global_line\"`\n* `\"point_to_point\"`: find the models pair with shortest average distance between observed and predicted data  \n\n---\n**thresh_meteoline_high_scores** None type or float default=None\n\nA threshold to just consider models with scores higher than that value. if none, equal to mean of scores+std of scores/3\n\n---\n**model_selection_report** boolean default =`True`\n\n`True` or `False`, to determine if there is a need to model selection method report\n\n---\n---\n## Attributes:\n\n**st2_model_results_dic** dict\n\nUpdated dictionary of st2 model results\n\n---\n**dependent_model_selection** boolean\n\nTo select the best model based on meteorological line. only useful if there is a linear refrence line (EX:Isotopes)\n\n---\n**meteo_coef** float \n\nIf dependent_model_selection=True,global_line, coefficient of the line\n\n---\n**meteo_intercept** float\n\nIf dependent_model_selection=True,global_line, intercept of the line\n\n---\n**selection_method** str\n\nIf dependent_model_selection=`True`, selection_method: `\"independent\",\"local_line\",\"global_line\", \"point_to_point\"`\n\n---\n**thresh_meteoline_high_scores** None type or float\n\nA threshold to just consider models with scores higher than that value. if none, equal to mean of scores+std of scores/3\n\n---\n**model_selection_report** boolean\n\nTrue or False, to determine if there is a need to model selection method report\n\n---\n---\n---\n# model.stage2_output_report ( )\n\nmodel.stage2_output_report(self,direc=None):\n\nThis method is useful to update st2_fit output files results in case they are changed.\n(Normally the change can happen if choose_estimator_by_meteo_line method is executed)\n\n---\n---\n## Parameters:\n\n**direc** str default=`None`\n\nDirectory of the output \n\n---\n---\n---\n# class session ( ):\n\nThe class to save and load the objects and sessions\n\n---\n---\n## **Methods:**\n\n* save()\n\n* load()\n\n* save_session()\n\n* load_session()\n\n---\n---\n---\n# session.save ( )\n\nsession.save(self,name=\"isocompy_saved_object\")\n\nThe method to save an object\n\n---\n---\n## **Parameters:**\n\n**name** str default=`\"isocompy_saved_object\"`\n\nThe output name string\n\n---\n---\n## **Returns:**\n\n**filename** string\n\nDirectory of the saved object\n\n---\n---\n---\n# session.load ( )\n\nsession.load(direc)\n\nThe method to load a pkl object. `direc` is the directory of the object to be loaded.\n\n---\n---\n## **Returns:**\n\n**obj** object\n\nThe loaded object\n\n---\n---\n---\n# session.save_session( )\n\nsave_session(direc,name=\"isocompy_saved_session\", *argv):\n\nThe method to save a session\n\n---\n---\n## **Parameters:**\n\nname: str default=\"isocompy_saved_object\"\n\nThe output name string\n\n---\n**\\*argv**\n\nThe objects that wanted to be stored in the session\n\n---\n---\n## **Returns:**\n\n**filename** string \n\nDirectory of the saved session\n\n---\n---\n---\n# session.load_session ( )\n\nsession.load_session(dir)\n\nThe method to load a session\n\n---\n---\n## **Parameters:**\n\n**\\*argv**\n\nThe objects that wanted to be stored in the session\n\n---\n---\n## **Returns:**\n\nLoads the session\n\n---\n---\n---\n# class evaluation ( )\n\nThe class to predict the second stage regression models\n\n---\n---\n\n## **Methods:**\n\n* \\_\\_init__ (self)  \n\n* predict ( )\n\n---\n---\n## **Attributes:**\n\n**direc** str\n\ndirectory of the class\n\n---\n**monthly_st2_output_list_all_vars** list\n\nlist of stage two models outputs, seperated by month\n\n---\n**monthly_st2_output_dic_all_vars_df** dict\n\ndictionary of stage two models outputs, seperated by month. key is the month, and value is the output df of that specific month\n\n---\n**pred_inputs** Pandas Dataframe\n\nA Dataframe, that have to be contain of features that is used in stage one, that is going to be used to estimate the stage one and two models\n\n---\n**st2_predicted_month_list** list\n\nList of the months that have stage two regression models\n\n---\n---\n---\n# evaluation.predict( )\n\nevaluation.predict(`self, cls, pred_inputs, stage2_vars_to_predict=None, direc=None, write_to_file=True` )\n\nThe method to predict the second stage regression models\n\n---\n---\n## **Parameters:**\n\n**cls ** model class\n\nThe model class that contains st1 and st2 models\n\n---\n**pred_inputs ** Pandas dataframe\n\nA Dataframe, that have to be contain of features that is used in stage one, that is going to be used to estimate the stage one and two models.\n\nIt can contain `\"month\"` field which could be used in evaluating the stage two predictions in observed data.\n\n* *EXAMPLE:*\n    ```python\n\n    pred_inputs=model_class.all_preds[[\"CooX\",\"CooY\",\"CooZ\",\"month\",\"ID\"]].reset_index()\n\n    ```\n\n---\n**stage2_vars_to_predict ** None type or list of strs default=`None`\n\nList of stage two dependent features to predict the outputs. If `None`, The results will be predicted for all two dependent features\n\n---\n**direc ** None type or str default=None\n\nDirectory of the class. If `None`, it is the same directory as the model class.\n\n---\n**write_to_file ** boolean default=`True`\n\nTo write the outputs in .xls files, seperated by the month\n\n---\n---\n## **Attributes:**\n\n**direc** str\n\ndirectory of the class\n\n---\n**monthly_st2_output_list_all_vars** list\n\nlist of stage two models outputs, seperated by month\n\n---\n**monthly_st2_output_dic_all_vars_df** dict\n\ndictionary of stage two models outputs, seperated by month. key is the month, and value is the output df of that specific month\n\n---\n**pred_inputs** Pandas Dataframe\n\nA Dataframe, that have to be contain of features that is used in stage one, that is going to be used to estimate the stage one and two models\n\n---\n**st2_predicted_month_list** list\n\nList of the months that have stage two regression models\n\n---\n---\n---\n# class stats( )   \n\nThe class to calculate and generate statistical reports for the second stage models\n\n---\n---\n\n## **Methods:**\n\n* annual_stats( )\n\n* mensual_stats( )\n\n---\n---\n---\n\n# stats.seasonal_stats( )\n\nstats.seasonal_stats(model_cls_obj)\n\nThe method to generate statistical reports for the second stage models based on  all specified month in second stage data\n\n---\n---\n## Parameters:\n\n**model_cls_obj**\n\nInput model class object\n\n---\n---\n---\n# stats.mensual_stats()\n\nstats.mensual_stats(model_cls_obj)\n\nThe method to generate statistical reports for the second stage models based on  each specified month in second stage data\n\n---\n---\n## Parameters:\n\n**model_cls_obj**\n\nInput model class object\n\n---\n---\n---\n# class plots ( )\n\nThe method to generate the model class plots\n\n---\n---\n## Methods:\n\n* best_estimator_plots ( )\n\n* partial_dep_plots ( )\n\n* isotopes_meteoline_plot ( )\n\n---\n---\n---\n# plots.best_estimator_plots()\n\nplots.best_estimator_plots( `cls, st1=True, st2=True` )\n\nThe method to plot the model class best estimators \n\n---\n---\n## **Parameters:**\n\n**st1** boolean default=`True`\n\nGenerate plots for stage one regression models of the model class\n\n\n**st2** boolean default=`True`\n\nGenerate plots for stage one regression models of the model class\n\n---\n---\n---\n# plots.partial_dep_plots( )\n\nplots. partial_dep_plots(`cls,st1=True,st2=True`)\n\nThe method to plot the partial dependency of the features of the model class\n\n---\n---\n## **Parameters:**\n\n**st1** boolean default=`True`\n\nGenerate plots for stage one regression models of the model class\n\n\n**st2** boolean default=`True`\n\nGenerate plots for stage two regression models of the model class\n\n---\n---\n---\n# plots.isotopes_meteoline_plot ( )\n\nplots.isotopes_meteoline_plot( `ev_class, iso_class, var_list, iso_18=None, iso_2h=None, a=8, b=10, obs_data=False, residplot=False` )\n\nThe method to plot the (meteorological) line between  two features (isotopes) that are determined in var_list\n\n---\n---\n## **Parameters:**\n\n**ev_class** evaluation class\n\nevaluation class that contains the second stage models predictions\n\n---\n**iso_class** model class\n\nmodel class that contains the second stage models\n\n---\n**iso_18** none type or Pandas Dataframe default=`None`\n\nFirst feature (isotope) observed raw data. Ignored if obs_data=`False`\n\n---\n**iso_2h** none type or Pandas Dataframe default=`None`\n\nSecond feature (isotope) observed raw data. Ignored if obs_data=`False`\n\n---\n**var_list** list of strings\n\nList of strings that identifies the names of two features in the evaluation and model class (in stage two)\n\n---\n**a** float default=`8`\n\nCoefficient of the line\n\n---\n**b** float default=`10`\n\nIntercept of the line\n\n---\n**obs_data** boolean default=`False`\n\n`False` if iso_18 and iso_2h are not observed data.\n`True` if the predictions in evaluation class have an specified date, in `\"month\"` field.\n\n* *EXAMPLE:*\n\n    ```python\n    pred_inputs=model_class.all_preds[[\"CooX\",\"CooY\",\"CooZ\",\"month\",\"ID\"]].reset_index()\n    ev_class_obs=tools_copy.evaluation()\n    ev_class_obs.predict(model_class,pred_inputs,direc=direc)\n    tools_copy.plots.isotopes_meteoline_plot(ev_class_obs,model_class,var_list=['is1','is2'],obs_data=True)\n    ```\n---\n**residplot** boolean default=`False`\n\nIgnored if obs_data=`False`. It create residual plots in each month for each ID.\n\n#------------------",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": null,
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": null,
    "keywords": null,
    "license": null,
    "maintainer": null,
    "maintainer_email": null,
    "name": "isocompy",
    "package_url": "https://pypi.org/project/isocompy/",
    "platform": null,
    "project_url": "https://pypi.org/project/isocompy/",
    "project_urls": {
      "home-page": "https://github.com/IDAEA-EVS/Isocompy"
    },
    "release_url": "https://pypi.org/project/isocompy/1.0.2/",
    "requires_dist": [
      "pandas",
      "pylr2",
      "dill",
      "geopandas",
      "bokeh",
      "statsmodels",
      "numpy",
      "tabulate",
      "matplotlib",
      "Shapely",
      "scikit_learn"
    ],
    "requires_python": ">=3.3",
    "summary": "An open source library for environmental isotopic modelling ",
    "version": "1.0.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16621945,
  "releases": {
    "1.0.0.1": [
      {
        "comment_text": null,
        "digests": {
          "blake2b_256": "e7f81dad866c5883513c340d082d4f1b958020d233ac0b8f5b885896bd3323de",
          "md5": "1c21945377281c19c1a19f5191ca37ba",
          "sha256": "046fa68757e8b60aebd67f42ee36dfbef6c50b5a0e53ad53986ab6b3a5dd4386"
        },
        "downloads": -1,
        "filename": "isocompy-1.0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "1c21945377281c19c1a19f5191ca37ba",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.3",
        "size": 61697,
        "upload_time": "2022-12-29T13:41:29",
        "upload_time_iso_8601": "2022-12-29T13:41:29.557311Z",
        "url": "https://files.pythonhosted.org/packages/e7/f8/1dad866c5883513c340d082d4f1b958020d233ac0b8f5b885896bd3323de/isocompy-1.0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": null,
        "digests": {
          "blake2b_256": "7a34e2c278d3d9864e83d48f8c98e8140322e7bfb25a8301079aa1da4ae53afe",
          "md5": "a3fbd38f4208bfde0a0a603246832690",
          "sha256": "cce4eeb94adb5a05afbde4112aa695c9b8a6bc53f892f6b5bc5da7b7bdf2e269"
        },
        "downloads": -1,
        "filename": "isocompy-1.0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "a3fbd38f4208bfde0a0a603246832690",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.3",
        "size": 67915,
        "upload_time": "2022-12-29T13:41:34",
        "upload_time_iso_8601": "2022-12-29T13:41:34.663810Z",
        "url": "https://files.pythonhosted.org/packages/7a/34/e2c278d3d9864e83d48f8c98e8140322e7bfb25a8301079aa1da4ae53afe/isocompy-1.0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.1": [
      {
        "comment_text": null,
        "digests": {
          "blake2b_256": "dd3c95964d9b389ce70ff9ce5ec6aaecdb1154d7dd775c035881e28bf00197b2",
          "md5": "0a528f94ee9408b3714b92f9ad15c19f",
          "sha256": "2f11b2a609537ea7c520e3cbc086274b14a47b755cbb200e652791c756411469"
        },
        "downloads": -1,
        "filename": "isocompy-1.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0a528f94ee9408b3714b92f9ad15c19f",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.3",
        "size": 61605,
        "upload_time": "2022-12-29T13:33:11",
        "upload_time_iso_8601": "2022-12-29T13:33:11.447904Z",
        "url": "https://files.pythonhosted.org/packages/dd/3c/95964d9b389ce70ff9ce5ec6aaecdb1154d7dd775c035881e28bf00197b2/isocompy-1.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": null,
        "digests": {
          "blake2b_256": "2ed15a5b466d0a58446446cc6c209e7e0f9683e780843d996d93922b8c75eeff",
          "md5": "913ec406c81903dd13410561b876bf34",
          "sha256": "65ce9f1191da653bca71d34179fada9b93d07975c73b40d61a53a8aab38420ac"
        },
        "downloads": -1,
        "filename": "isocompy-1.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "913ec406c81903dd13410561b876bf34",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.3",
        "size": 67782,
        "upload_time": "2022-12-29T13:33:17",
        "upload_time_iso_8601": "2022-12-29T13:33:17.555730Z",
        "url": "https://files.pythonhosted.org/packages/2e/d1/5a5b466d0a58446446cc6c209e7e0f9683e780843d996d93922b8c75eeff/isocompy-1.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.2": [
      {
        "comment_text": null,
        "digests": {
          "blake2b_256": "455f5f2a3f70437162c464de34f5dfd6a42495169085b1c79accb834bb70a7d2",
          "md5": "63ee62bab8915d544bd7ef00f09e6b66",
          "sha256": "b2abbb8d5a2d12b0d98710b92224b06b31cb33b40cf80c4c76fe78476886f5f6"
        },
        "downloads": -1,
        "filename": "isocompy-1.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "63ee62bab8915d544bd7ef00f09e6b66",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.3",
        "size": 61693,
        "upload_time": "2023-01-30T16:50:04",
        "upload_time_iso_8601": "2023-01-30T16:50:04.282575Z",
        "url": "https://files.pythonhosted.org/packages/45/5f/5f2a3f70437162c464de34f5dfd6a42495169085b1c79accb834bb70a7d2/isocompy-1.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": null,
        "digests": {
          "blake2b_256": "2269847affa9eadec1a0929d1f2413a78cc636f97667efa0f3eb912e28dba8d9",
          "md5": "d106e4f9538f98b5f579e7d244d43da2",
          "sha256": "7458f3dfcbe73ee29b56a463e4dc96b8173432f174531f5dff7b597c46655d62"
        },
        "downloads": -1,
        "filename": "isocompy-1.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "d106e4f9538f98b5f579e7d244d43da2",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.3",
        "size": 68107,
        "upload_time": "2023-01-30T16:56:17",
        "upload_time_iso_8601": "2023-01-30T16:56:17.558904Z",
        "url": "https://files.pythonhosted.org/packages/22/69/847affa9eadec1a0929d1f2413a78cc636f97667efa0f3eb912e28dba8d9/isocompy-1.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": null,
      "digests": {
        "blake2b_256": "455f5f2a3f70437162c464de34f5dfd6a42495169085b1c79accb834bb70a7d2",
        "md5": "63ee62bab8915d544bd7ef00f09e6b66",
        "sha256": "b2abbb8d5a2d12b0d98710b92224b06b31cb33b40cf80c4c76fe78476886f5f6"
      },
      "downloads": -1,
      "filename": "isocompy-1.0.2-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "63ee62bab8915d544bd7ef00f09e6b66",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.3",
      "size": 61693,
      "upload_time": "2023-01-30T16:50:04",
      "upload_time_iso_8601": "2023-01-30T16:50:04.282575Z",
      "url": "https://files.pythonhosted.org/packages/45/5f/5f2a3f70437162c464de34f5dfd6a42495169085b1c79accb834bb70a7d2/isocompy-1.0.2-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": null,
      "digests": {
        "blake2b_256": "2269847affa9eadec1a0929d1f2413a78cc636f97667efa0f3eb912e28dba8d9",
        "md5": "d106e4f9538f98b5f579e7d244d43da2",
        "sha256": "7458f3dfcbe73ee29b56a463e4dc96b8173432f174531f5dff7b597c46655d62"
      },
      "downloads": -1,
      "filename": "isocompy-1.0.2.tar.gz",
      "has_sig": false,
      "md5_digest": "d106e4f9538f98b5f579e7d244d43da2",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.3",
      "size": 68107,
      "upload_time": "2023-01-30T16:56:17",
      "upload_time_iso_8601": "2023-01-30T16:56:17.558904Z",
      "url": "https://files.pythonhosted.org/packages/22/69/847affa9eadec1a0929d1f2413a78cc636f97667efa0f3eb912e28dba8d9/isocompy-1.0.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}