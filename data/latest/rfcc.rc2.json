{
  "info": {
    "author": "Ingo Marquart",
    "author_email": "ingo.marquart@esmt.org",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# Python RFCC - Data understanding, clustering and outlier detection for regression and classification tasks\n\nRandom forests are invariant and robust estimators that can fit complex interactions between input data of different types and binary, categorical, or continuous outcome variables, including those with multiple dimensions. In addition to these desirable properties, random forests impose a structure on the observations from which researchers and data analysts can infer clusters or groups of interest. \n\nYou can use these clusters to:\n\n- structure your data,\n\n- elucidate new patterns of how features influence outcomes,\n\n- define subgroups for further analysis, \n\n- derive prototypical observations, \n\n- identify outlier observations, \n\n- catch mislabeled data, \n\n- evaluate the performance of the estimation model in more detail.\n\nRandom Forest Consensus Clustering and implement is implemented in the Scikit-Learn / SciPy data science ecosystem. This algorithm differs from prior approaches by making use of the entire tree structure. Observations become proximate if they follow similar decision paths across trees of a random forest.\n\nMore info in here:\n\n```\nMarquart, Ingo and Koca Marquart, Ebru, RFCC: Random Forest Consensus Clustering for Regression and Classification (March 19, 2021). Available at SSRN: https://ssrn.com/abstract=3807828 or http://dx.doi.org/10.2139/ssrn.3807828\n```\n\n# Installation\n\nInstall via pip!\n```python\npip install rfcc\n```\n\n# Usage\n\nLet's illustrate the approach with a simple example. We will be regression the miles-per-gallon in the city (__cty__) performance of a set of\ncars on the class (compact, pick-up etc.), the number of cylinders and the engine displacement.\n\nThe data is available in the pydataset package\n```python\ndataset=data(\"mpg\")\ny_col=[\"cty\"]\nx_col=['displ', 'class' , 'cyl']\nY=dataset[y_col]\nX=dataset[x_col]\nprint(X.head(5))\n```\n\n```python\n   displ    class  cyl\n1    1.8  compact    4\n2    1.8  compact    4\n3    2.0  compact    4\n4    2.0  compact    4\n5    2.8  compact    6\n```\n\nWe want __class__ and __cyl__ to be treated as categorical variable, so we'll keep track of these columns.\n\n## Initialization and model choice\n\nThe first step is to initialize the model, much like one would initialize an scikit-learn model.\nThe main class is __cluster_model__ from the rfcc package.\nWe only need to pass an appropriate ensemble model (RandomForestClassifier, RandomForestRegressor) and specify the options we'd like to use.\n\n\nSince miles-per-gallon is a continuous measure, we'll be using a random forest regression.\n\n```python\nfrom sklearn.ensemble import RandomForestRegressor\nfrom rfcc.model import cluster_model\nmodel=cluster_model(model=RandomForestRegressor,max_clusters=20,random_state=1)\n```\n\nWe have two options to specify the size and number of clusters to be returned.\n\nThe parameter __max_clusters__ sets the maximum amount of leafs in each decision tree. It ensures that the model does not return too many or too few clusters, but it does change the estimation of the random forest.\n\nAnother option is to set __max_clusters__ to a high value, or leave it unspecified, and use the hierarchical clustering algorithm to extract clusters of the desired size. See below for __t_param__ in the fit method.\n\n\n## Fitting and optional parameters\n\nNow we need to fit our model to the data.\n\n```python\nmodel.fit(X,Y)\n```\n\n\n\nThe following optional parameters can be passed\n\n- **encode** (list): A list of columns that we'd like to encode before fitting the model. Note that all non-numerical columns will be encoded automatically. However, you can also encode numerical data by passing it in the __encode__ parameter.\n\n- **encode_y** (bool): You can choose to ordinally encode the outcome variables. If you do a classification, scikit learn will choose how to encode the outcome variables. If the variable is continuous, this will usually lead to a rather bad fit, in which case you may want to encode.\n\n- **linkage_method** (str): Linkage method used in the clustering algorithm (average, single, complete, ward)\n\n- **clustering_type** (str): \"rfcc\" (default) our path based clustering, or \"binary\" as in prior approaches\n\n- **t_param** (float): If None, number of clusters corresponds to average number of leafs. If __t_param__ is specified,\npick that level of clustering hierarchy where distance between members of the group is less than __t_param__. The higher the value, the larger average size of a cluster. \n\nLet's check how well our model does on our training set\n\n```python\nmodel.score(X,Y)\n```\n\n```python\n0.9231321010907177\n```\n\n## Cluster compositions\n\nOnce the model is fit, we can extract the composition of clusters.\nLet's see which car types and cylinders have the best and worst miles-per-gallon performance.\n\nFirst, we use the cluster_descriptions method to return the compositions for each cluster.\n\n```python\nclusters=model.cluster_descriptions(variables_to_consider=['class','manufacturer'], continuous_measures=\"mean\")\n```\n\nThe optional parameters are:\n\n- **variables_to_consider** (list): List of columns in X to take into account.\n\n- **continuous_measures** (str, list): Measures to compute for each continuous feature (mean, std, median, max, min, skew)\n\nWe will sort our clusters by the average mpg and return the clusters with the two highest and two lowest mpg performances.\n\n```python\nclusters=clusters.sort_values(by=\"cty-mean\")\nprint(clusters.head(2))\nprint(clusters.tail(2))\n```\n\n```python\nNr_Obs\tcty-mean\tclass\t                    manufacturer\n7\t    11.85\t    suv: 1.0%\t                ford: 0.29%, land rover: 0.57%, mercury: 0.14%\n49\t    12.02\t    pickup: 0.35%, suv: 0.63%\tchevrolet: 0.18%, dodge: 0.43%, ford: 0.12%, jeep: 0.1%, lincoln: 0.06%, mercury: 0.02%, nissan: 0.02%, toyota: 0.06%\n```\n\n```python\nNr_Obs\tcty-mean\tclass\t                                            manufacturer\n15\t    24.4\t    compact: 0.33%, midsize: 0.13%, subcompact: 0.53%\thonda: 0.53%, toyota: 0.33%, volkswagen: 0.13%\n3\t    32.3\t    compact: 0.33%, subcompact: 0.67%\t                volkswagen: 1.0%\n```\n\n\n## Decision Path Analysis\n\nCluster descriptions return the proportions of values for any feature we are interested in. However, we also may want to know how a decision tree classifies an observation. For example, it may be that the feature __manufacturer__  has\nno predictive value, whereas the number of cylinders or the displacement does.\n\nAnother reason to do a decision path analysis is to check whether \n\nCurrently, path analyses are queried for each estimator in the random forest. \nIn the future patch, the path analysis will be available for the entire random forest.\n\nLet's see how the first decision tree (index 0) classifies the observations with the lowest miles-per-gallon performance\n\n```python\npaths=model.path_analysis(estimator_id=0)\npaths.sort_values(by=\"Output_cty\")\nprint(paths.head(5))\n```\n\n```python\nNr_Obs\tOutput_cty\tclass\t                        displ\t                    manufacturer\n17\t    [11.4]\t    class is not: 2seater, compact\tdispl between 5.25 and 4.4\tmanufacturer: audi, chevrolet, dodge\n21\t    [12.4]\t    class: suv\t                    displ larger than: 4.4\t    manufacturer is not: audi, chevrolet, dodge\n5\t    [12.6]\t    class: midsize, minivan, pickup\tdispl larger than: 4.4\t    manufacturer is not: audi, chevrolet, dodge\n13\t    [12.6]\t    class is not: 2seater, compact\tdispl larger than: 5.25\t    manufacturer: audi, chevrolet, dodge\n5\t    [13.4]\t    class: minivan\t                displ between 3.75 and 3.15\t-\n22\t    [14.1]\t-\t                                displ between 4.4 and 3.85\t-\n```\n\n## Detection of outliers and mislabelled data\n\nOutliers are observations that are unusual - not necessarily because their features differ, but rather because their implications for the outcome variable are different from other comparable observations. Mislabelled data may appear as\noutlier, since the relationships between outcome and feature values may not make much sense.\n\nSince outliers follow distinct decision paths in the random forest, RFCC does not cluster them with other observations.\nWe can therefore find outliers by analyzing clusters that have very few observations.\n\nLet's see what outliers exist in the mpg data.\n```python\nclusters=model.cluster_descriptions(continuous_measures=\"mean\")\nclusters=clusters.sort_values(by=\"Nr_Obs\")\noutliers=clusters.head(2)\nprint(outliers)\n```\n\n```python\nCluster_ID\tNr_Obs\tcty-mean\tclass\t        cyl\t        manufacturer\t    displ-mean\n16\t        1\t    16.0\t    minivan: 1.0%\t6: 1.0%\t    dodge: 1.0%\t        4.0\n3\t        2\t    18.0\t    midsize: 1.0%\t6: 1.0%\t    hyundai: 1.0%\t    2.5\n```\n\nIt seems we have one cluster (id=16) with a dodge minivan, and a cluster (id=3) with two observations.\nWe can get the constituent observations directly from our model.\n\n\n```python\nids=model.get_observations(cluster_id=16)\nprint(dataset.iloc[ids,:])\nids=model.get_observations(cluster_id=3)\nprint(dataset.iloc[ids,:])\n```\n\n```python\n\tmanufacturer\tmodel\t       displ\tyear\tcyl\t    trans\n48  dodge           caravan 2wd    4.0      2008    6       auto(l6)\n\n\tmanufacturer\tmodel\tdispl\tyear\tcyl\t    trans\n113\thyundai\t        sonata\t2.5\t    1999\t6\t    auto(l4)\n114\thyundai\t        sonata\t2.5\t    1999\t6\t    manual(m5)\n```\n\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/IngoMarquart/RFCC",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "rfcc",
    "package_url": "https://pypi.org/project/rfcc/",
    "platform": "",
    "project_url": "https://pypi.org/project/rfcc/",
    "project_urls": {
      "Homepage": "https://github.com/IngoMarquart/RFCC"
    },
    "release_url": "https://pypi.org/project/rfcc/1.0.1/",
    "requires_dist": [
      "pandas",
      "scipy"
    ],
    "requires_python": "",
    "summary": "RFCC: Random Forest Consensus Clustering for Regression and Classification",
    "version": "1.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 9945509,
  "releases": {
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2bcea30b669066d704becd95c3991eb7126272ebecb49d2a74a23bb97dde72ea",
          "md5": "d5bc78f08a99babd5596f8f2258dbac4",
          "sha256": "5a75cbd6ecfa006a30b15922c7564030f5b8579e313021b1860db0aa9c7a8f2d"
        },
        "downloads": -1,
        "filename": "rfcc-1.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d5bc78f08a99babd5596f8f2258dbac4",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 14501,
        "upload_time": "2021-03-22T14:43:50",
        "upload_time_iso_8601": "2021-03-22T14:43:50.765923Z",
        "url": "https://files.pythonhosted.org/packages/2b/ce/a30b669066d704becd95c3991eb7126272ebecb49d2a74a23bb97dde72ea/rfcc-1.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "381d2f3fbf2d27e1b9b794169a54a0b67f7b1f657a3623618b3db2f8e6ce7634",
          "md5": "537ea58daf876580c945fcfbd2f4bee6",
          "sha256": "40a76b273cd65d14a6f41178f997c61d4db822fa12a832841d089d326a52658b"
        },
        "downloads": -1,
        "filename": "RFCC-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "537ea58daf876580c945fcfbd2f4bee6",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 16932,
        "upload_time": "2021-03-22T14:43:51",
        "upload_time_iso_8601": "2021-03-22T14:43:51.994856Z",
        "url": "https://files.pythonhosted.org/packages/38/1d/2f3fbf2d27e1b9b794169a54a0b67f7b1f657a3623618b3db2f8e6ce7634/RFCC-1.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "93a18a60486f411d2dca90e69e08303e73eac4bcead32578a012a4937bf30897",
          "md5": "54d01dc66922fcb56713c10522a6813f",
          "sha256": "173ad2feaf4e370b77a7b22906b1a86b81021eab68710741f96373c133bf9922"
        },
        "downloads": -1,
        "filename": "rfcc-1.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "54d01dc66922fcb56713c10522a6813f",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 14535,
        "upload_time": "2021-04-01T10:27:37",
        "upload_time_iso_8601": "2021-04-01T10:27:37.547478Z",
        "url": "https://files.pythonhosted.org/packages/93/a1/8a60486f411d2dca90e69e08303e73eac4bcead32578a012a4937bf30897/rfcc-1.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6aa53768b57fe7c72ef9ddfe358437ee3838f4076e9aa5fc681d0fb81668b471",
          "md5": "5079f9ca46aeb6e3ede9ced67e7ff25c",
          "sha256": "8f64d37fe6d7c1a95b9f8db4e12b56ad4a3e57855436c765213c0c3506e1022a"
        },
        "downloads": -1,
        "filename": "rfcc-1.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "5079f9ca46aeb6e3ede9ced67e7ff25c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 16986,
        "upload_time": "2021-04-01T10:27:39",
        "upload_time_iso_8601": "2021-04-01T10:27:39.609456Z",
        "url": "https://files.pythonhosted.org/packages/6a/a5/3768b57fe7c72ef9ddfe358437ee3838f4076e9aa5fc681d0fb81668b471/rfcc-1.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "93a18a60486f411d2dca90e69e08303e73eac4bcead32578a012a4937bf30897",
        "md5": "54d01dc66922fcb56713c10522a6813f",
        "sha256": "173ad2feaf4e370b77a7b22906b1a86b81021eab68710741f96373c133bf9922"
      },
      "downloads": -1,
      "filename": "rfcc-1.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "54d01dc66922fcb56713c10522a6813f",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 14535,
      "upload_time": "2021-04-01T10:27:37",
      "upload_time_iso_8601": "2021-04-01T10:27:37.547478Z",
      "url": "https://files.pythonhosted.org/packages/93/a1/8a60486f411d2dca90e69e08303e73eac4bcead32578a012a4937bf30897/rfcc-1.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "6aa53768b57fe7c72ef9ddfe358437ee3838f4076e9aa5fc681d0fb81668b471",
        "md5": "5079f9ca46aeb6e3ede9ced67e7ff25c",
        "sha256": "8f64d37fe6d7c1a95b9f8db4e12b56ad4a3e57855436c765213c0c3506e1022a"
      },
      "downloads": -1,
      "filename": "rfcc-1.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "5079f9ca46aeb6e3ede9ced67e7ff25c",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 16986,
      "upload_time": "2021-04-01T10:27:39",
      "upload_time_iso_8601": "2021-04-01T10:27:39.609456Z",
      "url": "https://files.pythonhosted.org/packages/6a/a5/3768b57fe7c72ef9ddfe358437ee3838f4076e9aa5fc681d0fb81668b471/rfcc-1.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}