{
  "info": {
    "author": "Jieyu Zhang",
    "author_email": "jieyuzhang97@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: Apache Software License",
      "Programming Language :: Python :: 3",
      "Topic :: Scientific/Engineering :: Information Analysis"
    ],
    "description": "<h1 style=\"text-align:center\">\n<img style=\"vertical-align:middle\" width=\"500\" height=\"180\" src=\"./images/wrench_logo.png\" />\n</h1>\n\n[![made-with-python](https://img.shields.io/badge/Made%20with-Python3-1f425f.svg?color=purple)](https://www.python.org/)\n[![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](https://github.com/JieyuZ2/wrench/commits/main)\n[![license](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n[![repo size](https://img.shields.io/github/repo-size/JieyuZ2/wrench.svg)](https://github.com/JieyuZ2/wrench/archive/master.zip)\n[![Total lines](https://img.shields.io/tokei/lines/github/JieyuZ2/wrench?color=red)](https://github.com/JieyuZ2/wrench)\n![visitors](https://visitor-badge.glitch.me/badge?page_id=JieyuZ2/wrench)\n![GitHub stars](https://img.shields.io/github/stars/JieyuZ2/wrench.svg?color=green)\n![GitHub forks](https://img.shields.io/github/forks/JieyuZ2/wrench?color=9cf)\n[![Arxiv](https://img.shields.io/badge/ArXiv-2109.11377-orange.svg)](https://arxiv.org/abs/2109.11377) \n\n\n## ðŸ”§ New\n\n**2/13/22** \n\n1. Add [script](https://github.com/JieyuZ2/wrench/tree/main/datasets/tabular_data) to generate LFs for any tabular dataset as well as 5 new tabular datasets, namely, mushroom, spambase, PhishingWebsites, Bioresponse, and bank-marketing.\n\n**11/04/21** \n\n1. (beta) Add `parallel_fit` for torch model to support pytorch DistributedDataParallel-[example](https://github.com/JieyuZ2/wrench/blob/main/examples/run_torch_ddp.py)\n\n**10/15/21** \n\n1. A branch of new methods: WeaSEL, ImplyLoss, ASTRA, MeanTeacher, Meta-Weight-Net, Learning-to-Reweight\n2. Support image classification (dataset class / torchvision backbone) as well as DomainNet/Animals-with-Attributes2 datasets (check out the `datasets` folder)\n\n## ðŸ”§ What is it?\n\n**Wrench** is a **benchmark platform** containing diverse weak supervision tasks. It also provides a **common and easy framework** for development and evaluation of your own weak supervision models within the benchmark.\n\nFor more information, checkout our publications: \n- [WRENCH: A Comprehensive Benchmark for Weak Supervision](https://arxiv.org/abs/2109.11377) (NeurIPS 2021)\n\nIf you find this repository helpful, feel free to cite our publication:\n\n```\n@inproceedings{\nzhang2021wrench,\ntitle={{WRENCH}: A Comprehensive Benchmark for Weak Supervision},\nauthor={Jieyu Zhang and Yue Yu and Yinghao Li and Yujing Wang and Yaming Yang and Mao Yang and Alexander Ratner},\nbooktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track},\nyear={2021},\nurl={https://openreview.net/forum?id=Q9SKS5k8io}\n}\n```\n\n## ðŸ”§ What is weak supervision?\n\n**Weak Supervision** is a paradigm for automated training data creation without manual annotations. \n\nFor a brief overview, please check out this [blog](https://www.snorkel.org/blog/weak-supervision).\n\nFor more context, please check out this [survey](https://arxiv.org/abs/2202.05433).\n\nTo track recent advances in weak supervision, please follow this [repo](https://github.com/JieyuZ2/Awesome-Weak-Supervision).\n\n## ðŸ”§ Installation\n[1] Install anaconda:\nInstructions here: https://www.anaconda.com/download/\n\n[2] Clone the repository:\n```\ngit clone https://github.com/JieyuZ2/wrench.git\ncd wrench\n```\n\n[3] Create virtual environment:\n```\nconda env create -f environment.yml\nsource activate wrench\n```\nIf this not working or you want to use only a subset of modules of Wrench, check out this [wiki page](https://github.com/JieyuZ2/wrench/wiki/Environment-Installation)\n\n## ðŸ”§ Available Datasets\n\nThe datasets can be downloaded via [this](https://drive.google.com/drive/folders/1v55IKG2JN9fMtKJWU48B_5_DcPWGnpTq?usp=sharing).\n\n**Note that some datasets may have more training examples than what is reported in README/paper because we include the dev set, whose indices can be found in labeled_id.json if exists.**\n\nA documentation of dataset format and usage can be found in this [wiki-page](https://github.com/JieyuZ2/wrench/wiki/Dataset:-Format-and-Usage)\n\n### classification:\n| Name | Task | # class | # LF | # train | # validation | # test | data source | LF source |\n|:--------|:---------|:------|:------|:------|:------|:------|:------|:------|\n| Census | income clasification | 2 | 83 | 10083 | 5561 | 16281 | [link](http://archive.ics.uci.edu/ml/datasets/Census+Income) |[link](https://openreview.net/forum?id=SkeuexBtDr) |\n| Youtube | spam clasification | 2 | 10 | 1586 | 120 | 250 | [link](https://archive.ics.uci.edu/ml/datasets/YouTube+Spam+Collection) | [link](https://github.com/snorkel-team/snorkel-tutorials/tree/master/spam) |\n| SMS | spam clasification | 2 | 73 | 4571 | 500 | 500 | [link](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection) | [link](https://openreview.net/forum?id=SkeuexBtDr) |\n| IMDB | sentiment clasification | 2 | 8 | 20000 | 2500 | 2500 | [link](https://dl.acm.org/doi/10.5555/2002472.2002491) | [link](https://arxiv.org/abs/2010.04582) |\n| Yelp | sentiment clasification | 2 | 8 | 30400 | 3800 | 3800 | [link](https://arxiv.org/abs/1509.01626) | [link](https://arxiv.org/abs/2010.04582) |\n| AGNews | topic clasification | 4 | 9 | 96000 | 12000 | 12000 | [link](https://arxiv.org/abs/1509.01626) | [link](https://arxiv.org/abs/2010.04582) |\n| TREC | question classification | 6 | 68 | 4965 | 500 | 500 | [link](https://aclanthology.org/C02-1150.pdf) | [link](https://openreview.net/forum?id=SkeuexBtDr) |\n| Spouse | relation classification | 2 | 9 | 22254 | 2801 | 2701 | [link](http://ceur-ws.org/Vol-1568/paper8.pdf) | [link](https://arxiv.org/abs/1711.10160) |\n| SemEval | relation classification | 9 | 164 | 1749 | 200 | 692 | [link](https://aclanthology.org/S10-1006/) | [link](https://arxiv.org/abs/1909.02177) |\n| CDR | bio relation classification | 2 | 33 | 8430 | 920 | 4673 | [link](https://pubmed.ncbi.nlm.nih.gov/27651457/) | [link](https://arxiv.org/abs/1711.10160) |\n| Chemprot | chemical relation classification | 10 | 26 | 12861 | 1607 | 1607 | [link](https://www.semanticscholar.org/paper/Overview-of-the-BioCreative-VI-chemical-protein-Krallinger-Rabal/eed781f498b563df5a9e8a241c67d63dd1d92ad5) | [link](https://arxiv.org/abs/2010.07835) |\n| Commercial | video frame classification | 2 | 4 | 64130 | 9479 | 7496 | [link](https://arxiv.org/pdf/2002.11955.pdf) | [link](https://arxiv.org/abs/2002.11955) |\n| Tennis Rally | video frame classification | 2 | 6 | 6959 | 746 | 1098 | [link](https://arxiv.org/pdf/2002.11955.pdf) | [link](https://arxiv.org/abs/2002.11955) |\n| Basketball | video frame classification | 2 | 4 | 17970 | 1064 | 1222 | [link](https://arxiv.org/pdf/2002.11955.pdf) | [link](https://arxiv.org/abs/2002.11955) |\n| [DomainNet](https://github.com/JieyuZ2/wrench/tree/main/datasets/domainnet) | image classification | - | - | - | - | - | [link](https://arxiv.org/pdf/1812.01754.pdf) | [link](http://cs.brown.edu/people/sbach/files/mazzetto-icml21.pdf) |\n\n### sequence tagging:\n| Name | # class | # LF | # train | # validation | # test | data source | LF source |\n|:--------|:---------|:------|:------|:------|:------|:------|:------|\n| CoNLL-03 | 4 | 16 | 14041 | 3250 | 3453 | [link](https://arxiv.org/abs/cs/0306050) | [link](https://arxiv.org/abs/2004.14723) |\n| WikiGold | 4 | 16 | 1355 | 169 | 170 | [link](https://dl.acm.org/doi/10.5555/1699765.1699767) | [link](https://arxiv.org/abs/2004.14723) |\n| OntoNotes 5.0 | 18 | 17 | 115812 | 5000 | 22897 | [link](https://catalog.ldc.upenn.edu/LDC2013T19) | [link]() |\n| BC5CDR | 2 | 9 | 500 | 500 | 500 | [link](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4860626/) | [link](https://arxiv.org/abs/2105.12848) |\n| NCBI-Disease  | 1 | 5 | 592 | 99 | 99 | [link](https://pubmed.ncbi.nlm.nih.gov/24393765/) | [link](https://arxiv.org/abs/2105.12848) |\n| Laptop-Review | 1 | 3 | 2436 | 609 | 800 | [link](https://aclanthology.org/S14-2004/) | [link](https://arxiv.org/abs/2105.12848) |\n| MIT-Restaurant | 8 | 16 | 7159 | 500 | 1521 | [link](https://groups.csail.mit.edu/sls/publications/2013/Liu_ASRU_2013.pdf) | [link]() |\n| MIT-Movies | 12 | 7 | 9241 | 500 | 2441 | [link](http://people.csail.mit.edu/jrg/2013/liu-icassp13.pdf) | [link]() |\n\n\nThe detailed documentation is coming soon.\n\n## ðŸ”§ Available Models\n\n**If you find any of the implementations is wrong/problematic, don't hesitate to raise issue/pull request, we really appreciate it!**\n\nTODO-list: check [this](https://github.com/JieyuZ2/wrench/wiki/TODO-List) out! \n\n### classification:\n| Model | Model Type | Reference | Link to Wrench |\n|:--------|:---------|:------|:------|\n| Majority Voting | Label Model | -- | [link](https://github.com/JieyuZ2/wrench/blob/main/wrench/labelmodel/majority_voting.py#L44) |\n| Weighted Majority Voting | Label Model | -- | [link](https://github.com/JieyuZ2/wrench/blob/main/wrench/labelmodel/majority_voting.py#L14) |\n| Dawid-Skene | Label Model | [link](https://www.jstor.org/stable/2346806) | [link](https://github.com/JieyuZ2/wrench/blob/main/wrench/labelmodel/dawid_skene.py#L15) |\n| Data Progamming | Label Model | [link](https://arxiv.org/abs/1605.07723) | [link](https://github.com/JieyuZ2/wrench/blob/main/wrench/labelmodel/generative_model.py#L18) |\n| MeTaL | Label Model | [link](https://arxiv.org/abs/1810.02840) | [link](https://github.com/JieyuZ2/wrench/blob/main/wrench/labelmodel/snorkel.py#L17) |\n| FlyingSquid | Label Model | [link](https://arxiv.org/pdf/2002.11955) | [link](https://github.com/JieyuZ2/wrench/blob/main/wrench/labelmodel/flyingsquid.py#L16) |\n| Logistic Regression | End Model | -- | [link](https://github.com/JieyuZ2/wrench/blob/main/wrench/endmodel/linear_model.py#L52) |\n| MLP | End Model | -- | [link](https://github.com/JieyuZ2/wrench/blob/main/wrench/endmodel/neural_model.py#L21) |\n| BERT | End Model | [link](https://huggingface.co/models) | [link](https://github.com/JieyuZ2/wrench/blob/main/wrench/endmodel/bert_model.py#L23) |\n| COSINE | End Model | [link](https://arxiv.org/abs/2010.07835) | [link](https://github.com/JieyuZ2/wrench/blob/main/wrench/endmodel/cosine.py#L68) |\n| Denoise | Joint Model | [link](https://arxiv.org/abs/2010.04582) | [link](https://github.com/JieyuZ2/wrench/blob/main/wrench/classification/denoise.py#L72) |\n| WeaSEL | Joint Model | [link](https://arxiv.org/abs/2107.02233) | [link](https://github.com/JieyuZ2/wrench/blob/main/wrench/classification/weasel.py#L72) |\n\n### sequence tagging:\n| Model | Model Type | Reference | Link to Wrench |\n|:--------|:---------|:------|:------|\n| Hidden Markov Model | Label Model | [link](https://arxiv.org/abs/2004.14723) | [link](https://github.com/JieyuZ2/wrench/blob/main/wrench/seq_labelmodel/hmm.py#L81) |\n| Conditional Hidden Markov Model | Label Model | [link](https://arxiv.org/abs/2105.12848) | [link](https://github.com/JieyuZ2/wrench/blob/main/wrench/seq_labelmodel/chmm.py#L33) |\n| LSTM-CNNs-CRF | End Model | [link](https://arxiv.org/abs/1603.01354) | [link](https://github.com/JieyuZ2/wrench/blob/main/wrench/seq_endmodel/lstm_crf_model.py#L86) |\n| BERT-CRF | End Model | [link](https://huggingface.co/models) | [link](https://github.com/JieyuZ2/wrench/blob/main/wrench/seq_endmodel/bert_crf_model.py#L23) |\n| LSTM-ConNet | Joint Model | [link](https://arxiv.org/abs/1910.04289) | [link](https://github.com/JieyuZ2/wrench/blob/main/wrench/seqtagging/connet.py#L45) |\n| BERT-ConNet | Joint Model | [link](https://arxiv.org/abs/1910.04289) | [link](https://github.com/JieyuZ2/wrench/blob/main/wrench/seqtagging/connet.py#L210) |\n\n### classification-to-sequence-tagging wrapper:\nWrench also provides a [`SeqLabelModelWrapper`](https://github.com/JieyuZ2/wrench/blob/main/wrench/seq_labelmodel/seq_wrapper.py#L43) that adaptes label model for classification task to sequence tagging task.\n\n### methods from related domains:\n\n#### Robust Learning methods as end model:\n\n| Model | Model Type | Reference | Link to Wrench |\n|:--------|:---------|:------|:------|\n| Meta-Weight-Net | End Model | [link](https://arxiv.org/abs/1902.07379) | [link](https://github.com/JieyuZ2/wrench/blob/main/wrench/metalearning/meta_weight_net.py#L34) |\n| Learning2ReWeight | End Model | [link](https://arxiv.org/abs/1803.09050) | [link](https://github.com/JieyuZ2/wrench/blob/main/wrench/metalearning/learn_to_reweight.py#L20) |\n\n#### Semi-Supervised Learning methods as end model:\n\n| Model | Model Type | Reference | Link to Wrench |\n|:--------|:---------|:------|:------|\n| MeanTeacher | End Model | [link](https://arxiv.org/abs/1703.01780) | [link](https://github.com/JieyuZ2/wrench/blob/main/wrench/semisupervisedlearning/meanteacher.py#L61) |\n\n#### Weak Supervision with cleaned labels (Semi-Weak Supervision):\n\n| Model | Model Type | Reference | Link to Wrench |\n|:--------|:---------|:------|:------|\n| ImplyLoss | Joint Model | [link](https://arxiv.org/abs/2004.06025) | [link](https://github.com/JieyuZ2/wrench/blob/main/wrench/classification/implyloss.py#L42) |\n| ASTRA | Joint Model | [link](https://www.microsoft.com/en-us/research/publication/self-training-weak-supervision-astra/) | [link](https://github.com/JieyuZ2/wrench/blob/main/wrench/classification/astra.py#L87) |\n\n# ðŸ”§  Quick examples\n\n\n## ðŸ”§  Label model with parallel grid search for hyper-parameters\n\n```python\nimport logging\nimport numpy as np\nimport pprint\n\nfrom wrench.dataset import load_dataset\nfrom wrench.logging import LoggingHandler\nfrom wrench.search import grid_search\nfrom wrench import labelmodel \nfrom wrench.evaluation import AverageMeter\n\n#### Just some code to print debug information to stdout\nlogging.basicConfig(format='%(asctime)s - %(message)s',\n                    datefmt='%Y-%m-%d %H:%M:%S',\n                    level=logging.INFO,\n                    handlers=[LoggingHandler()])\nlogger = logging.getLogger(__name__)\n\n#### Load dataset \ndataset_home = '../datasets'\ndata = 'youtube'\ntrain_data, valid_data, test_data = load_dataset(dataset_home, data, extract_feature=False)\n\n\n#### Specify the hyper-parameter search space for grid search\nsearch_space = {\n    'Snorkel': {\n        'lr': np.logspace(-5, -1, num=5, base=10),\n        'l2': np.logspace(-5, -1, num=5, base=10),\n        'n_epochs': [5, 10, 50, 100, 200],\n    }\n}\n\n#### Initialize label model\nlabel_model_name = 'Snorkel'\nlabel_model = getattr(labelmodel, label_model_name)\n\n#### Search best hyper-parameters using validation set in parallel\nn_trials = 100\nn_repeats = 5\ntarget = 'acc'\nsearched_paras = grid_search(label_model(), dataset_train=train_data, dataset_valid=valid_data,\n                             metric=target, direction='auto', search_space=search_space[label_model_name],\n                             n_repeats=n_repeats, n_trials=n_trials, parallel=True)\n\n#### Evaluate the label model with searched hyper-parameters and average meter\nmeter = AverageMeter(names=[target])\nfor i in range(n_repeats):\n    model = label_model(**searched_paras)\n    history = model.fit(dataset_train=train_data, dataset_valid=valid_data)\n    metric_value = model.test(test_data, target)\n    meter.update(target=metric_value)\n\nmetrics = meter.get_results()\npprint.pprint(metrics)\n```\n\nFor detailed guidance of `grid_search`, please check out [this wiki page](https://github.com/JieyuZ2/wrench/wiki/Hyperparameter-Search).\n\n\n## ðŸ”§  Run a standard supervised learning pipeline\n\n```python\nimport logging\nimport torch\n\nfrom wrench.dataset import load_dataset\nfrom wrench.logging import LoggingHandler\nfrom wrench.endmodel import MLPModel\n\n#### Just some code to print debug information to stdout\nlogging.basicConfig(format='%(asctime)s - %(message)s',\n                    datefmt='%Y-%m-%d %H:%M:%S',\n                    level=logging.INFO,\n                    handlers=[LoggingHandler()])\nlogger = logging.getLogger(__name__)\n\n#### Load dataset \ndataset_home = '../datasets'\ndata = 'youtube'\n\n#### Extract data features using pre-trained BERT model and cache it\nextract_fn = 'bert'\nmodel_name = 'bert-base-cased'\ntrain_data, valid_data, test_data = load_dataset(dataset_home, data, extract_feature=True, extract_fn=extract_fn,\n                                                 cache_name=extract_fn, model_name=model_name)\n\n\n#### Train a MLP classifier\ndevice = torch.device('cuda:0')\nn_steps = 100000\nbatch_size = 128\ntest_batch_size = 1000 \npatience = 200\nevaluation_step = 50\ntarget='acc'\n\nmodel = MLPModel(n_steps=n_steps, batch_size=batch_size, test_batch_size=test_batch_size)\nhistory = model.fit(dataset_train=train_data, dataset_valid=valid_data, device=device, metric=target, \n                    patience=patience, evaluation_step=evaluation_step)\n\n#### Evaluate the trained model\nmetric_value = model.test(test_data, target)\n```\n\n## ðŸ”§  Build a two-stage weak supervision pipeline\n\n```python\nimport logging\nimport torch\n\nfrom wrench.dataset import load_dataset\nfrom wrench.logging import LoggingHandler\nfrom wrench.endmodel import MLPModel\nfrom wrench.labelmodel import MajorityVoting\n\n#### Just some code to print debug information to stdout\nlogging.basicConfig(format='%(asctime)s - %(message)s',\n                    datefmt='%Y-%m-%d %H:%M:%S',\n                    level=logging.INFO,\n                    handlers=[LoggingHandler()])\nlogger = logging.getLogger(__name__)\n\n#### Load dataset \ndataset_home = '../datasets'\ndata = 'youtube'\n\n#### Extract data features using pre-trained BERT model and cache it\nextract_fn = 'bert'\nmodel_name = 'bert-base-cased'\ntrain_data, valid_data, test_data = load_dataset(dataset_home, data, extract_feature=True, extract_fn=extract_fn,\n                                                 cache_name=extract_fn, model_name=model_name)\n\n#### Generate soft training label via a label model\n#### The weak labels provided by supervision sources are alreadly encoded in dataset object\nlabel_model = MajorityVoting()\nlabel_model.fit(train_data, valid_data)\nsoft_label = label_model.predict_proba(train_data)\n\n\n#### Train a MLP classifier with soft label\ndevice = torch.device('cuda:0')\nn_steps = 100000\nbatch_size = 128\ntest_batch_size = 1000 \npatience = 200\nevaluation_step = 50\ntarget='acc'\n\nmodel = MLPModel(n_steps=n_steps, batch_size=batch_size, test_batch_size=test_batch_size)\nhistory = model.fit(dataset_train=train_data, dataset_valid=valid_data, y_train=soft_label, \n                    device=device, metric=target, patience=patience, evaluation_step=evaluation_step)\n\n#### Evaluate the trained model\nmetric_value = model.test(test_data, target)\n\n#### We can also train a MLP classifier with hard label\nfrom snorkel.utils import probs_to_preds\nhard_label = probs_to_preds(soft_label)\nmodel = MLPModel(n_steps=n_steps, batch_size=batch_size, test_batch_size=test_batch_size)\nmodel.fit(dataset_train=train_data, dataset_valid=valid_data, y_train=hard_label, \n          device=device, metric=target, patience=patience, evaluation_step=evaluation_step)\n```\n\n## ðŸ”§  Procedural labeling function generator\n\n```python\nimport logging\nimport torch\n\nfrom wrench.dataset import load_dataset\nfrom wrench.logging import LoggingHandler\nfrom wrench.synthetic import ConditionalIndependentGenerator, NGramLFGenerator\nfrom wrench.labelmodel import FlyingSquid\n\n#### Just some code to print debug information to stdout\nlogging.basicConfig(format='%(asctime)s - %(message)s',\n                    datefmt='%Y-%m-%d %H:%M:%S',\n                    level=logging.INFO,\n                    handlers=[LoggingHandler()])\nlogger = logging.getLogger(__name__)\n\n\n#### Generate synthetic dataset\ngenerator = ConditionalIndependentGenerator(\n    n_class=2,\n    n_lfs=10,\n    alpha=0.75, # mean accuracy\n    beta=0.1, # mean propensity\n    alpha_radius=0.2, # radius of accuracy\n    beta_radius=0.1 # radius of propensity\n)\ntrain_data = generator.generate_split('train', 10000)\nvalid_data = generator.generate_split('valid', 1000)\ntest_data = generator.generate_split('test', 1000)\n\n#### Evaluate label model on synthetic dataset\nlabel_model = FlyingSquid()\nlabel_model.fit(dataset_train=train_data, dataset_valid=valid_data)\ntarget_value = label_model.test(test_data, metric_fn='auc')\n\n#### Load dataset \ndataset_home = '../datasets'\ndata = 'youtube'\n\n#### Load real-world dataset\ntrain_data, valid_data, test_data = load_dataset(dataset_home, data, extract_feature=False)\n\n#### Generate procedural labeling functions\ngenerator = NGramLFGenerator(dataset=train_data, min_acc_gain=0.1, min_support=0.01, ngram_range=(1, 2))\napplier = generator.generate(mode='correlated', n_lfs=10)\nL_test = applier.apply(test_data)\nL_train = applier.apply(train_data)\n\n\n#### Evaluate label model on real-world dataset with semi-synthetic labeling functions\nlabel_model = FlyingSquid()\nlabel_model.fit(dataset_train=L_train, dataset_valid=valid_data)\ntarget_value = label_model.test(L_test, metric_fn='auc')\n```\n\n## ðŸ”§  Contact\n\nContact person: Jieyu Zhang, [jieyuzhang97@gmail.com](mailto:jieyuzhang97@gmail.com)\n\nDon't hesitate to send us an e-mail if you have any question.\n\nWe're also open to any collaboration!\n\n## ðŸ”§  Contributing Dataset and Model\n\nWe sincerely welcome any contribution to the datasets or models!\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/JieyuZ2/wrench",
    "keywords": "machine-learning ai weak-supervision",
    "license": "Apache License 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "ws-benchmark",
    "package_url": "https://pypi.org/project/ws-benchmark/",
    "platform": null,
    "project_url": "https://pypi.org/project/ws-benchmark/",
    "project_urls": {
      "Homepage": "https://github.com/JieyuZ2/wrench"
    },
    "release_url": "https://pypi.org/project/ws-benchmark/1.1.1/",
    "requires_dist": [
      "cytoolz (==0.11.0)",
      "dill (==0.3.4)",
      "flyingsquid (==0.0.0a0)",
      "future (>=0.18.2)",
      "higher (>=0.2.1)",
      "typing-extensions (<=3.10.0.2,>=3.10.0.0)",
      "torch (==1.9.0)",
      "torchvision (==0.10.0)",
      "tqdm (>=4.62.1)",
      "transformers (<=4.7.0,>=4.6.1)",
      "numpy (<=1.19.5,>=1.19.2)",
      "snorkel (==0.9.7)",
      "seqeval (==1.2.2)",
      "scikit-learn (==0.24.2)",
      "optuna (<=2.8.0,>=2.7.0)",
      "pandas (>=1.1.5)",
      "pillow (>=8.3.2)",
      "sentence-transformers (==1.1.1)",
      "openml (>=0.12.2)",
      "cvxpy (<=1.1.15,>=1.1.13)",
      "scipy (<=1.5.4,>=1.5.2)",
      "faiss-gpu (>=1.7.1)",
      "numbskull (==0.1.1)",
      "numba (==0.43.0)",
      "snorkel-metal (>=0.5.0)",
      "spacy (<=3.1.5,>=3.1.2)",
      "skweak (>=0.2.13)",
      "networkx (==2.7)"
    ],
    "requires_python": ">=3.6",
    "summary": "a weak supervision learning benchmark",
    "version": "1.1.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 13573812,
  "releases": {
    "1.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "784ecd587d8b8ff6283302f0769e06fc790426c1a9a896286eb58cea241ce9e4",
          "md5": "85e3fd242ca6d1304dca2a63689f5576",
          "sha256": "efe7512939c702b8332229f4cb01e3cf1eeb6ce7aff21c06bcb59f182a979a41"
        },
        "downloads": -1,
        "filename": "ws_benchmark-1.1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "85e3fd242ca6d1304dca2a63689f5576",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 149405,
        "upload_time": "2022-03-19T02:36:17",
        "upload_time_iso_8601": "2022-03-19T02:36:17.082001Z",
        "url": "https://files.pythonhosted.org/packages/78/4e/cd587d8b8ff6283302f0769e06fc790426c1a9a896286eb58cea241ce9e4/ws_benchmark-1.1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7fcda2e92527ff63fb5d9f18f5e39f2dedf832aa3c00cfc3984d0c290c1f3b9c",
          "md5": "04221bf8562de19a49caa87ddcc17268",
          "sha256": "d17a3f14871909b70be15e0b368e7429887dc1aa2702e3b1370c4e6bd7541151"
        },
        "downloads": -1,
        "filename": "ws-benchmark-1.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "04221bf8562de19a49caa87ddcc17268",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 109346,
        "upload_time": "2022-03-19T02:36:19",
        "upload_time_iso_8601": "2022-03-19T02:36:19.342804Z",
        "url": "https://files.pythonhosted.org/packages/7f/cd/a2e92527ff63fb5d9f18f5e39f2dedf832aa3c00cfc3984d0c290c1f3b9c/ws-benchmark-1.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.2rc0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8eda2146662a060495453b952a84a32cd15a0566e4d136d78c9e6e6ca45a0021",
          "md5": "915d3ba643a2f61653622a542ad7ca9f",
          "sha256": "d5cd0055f370c0749867de33de4a76347461f28be3a3321243746c23991b0817"
        },
        "downloads": -1,
        "filename": "ws_benchmark-1.1.2rc0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "915d3ba643a2f61653622a542ad7ca9f",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 149589,
        "upload_time": "2022-04-21T00:22:46",
        "upload_time_iso_8601": "2022-04-21T00:22:46.824995Z",
        "url": "https://files.pythonhosted.org/packages/8e/da/2146662a060495453b952a84a32cd15a0566e4d136d78c9e6e6ca45a0021/ws_benchmark-1.1.2rc0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "eddfdff42650ac88b01354873647765647506d1ea9af0381aaacb8ad533ec58f",
          "md5": "08a489b8299217667228a7b254e1f852",
          "sha256": "5fccbcb291cfee6e1e45bb8988bb78f3f0aaeb99092a9f7cb4515d4932c893e4"
        },
        "downloads": -1,
        "filename": "ws-benchmark-1.1.2rc0.tar.gz",
        "has_sig": false,
        "md5_digest": "08a489b8299217667228a7b254e1f852",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 116472,
        "upload_time": "2022-04-21T00:22:49",
        "upload_time_iso_8601": "2022-04-21T00:22:49.047732Z",
        "url": "https://files.pythonhosted.org/packages/ed/df/dff42650ac88b01354873647765647506d1ea9af0381aaacb8ad533ec58f/ws-benchmark-1.1.2rc0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "784ecd587d8b8ff6283302f0769e06fc790426c1a9a896286eb58cea241ce9e4",
        "md5": "85e3fd242ca6d1304dca2a63689f5576",
        "sha256": "efe7512939c702b8332229f4cb01e3cf1eeb6ce7aff21c06bcb59f182a979a41"
      },
      "downloads": -1,
      "filename": "ws_benchmark-1.1.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "85e3fd242ca6d1304dca2a63689f5576",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 149405,
      "upload_time": "2022-03-19T02:36:17",
      "upload_time_iso_8601": "2022-03-19T02:36:17.082001Z",
      "url": "https://files.pythonhosted.org/packages/78/4e/cd587d8b8ff6283302f0769e06fc790426c1a9a896286eb58cea241ce9e4/ws_benchmark-1.1.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "7fcda2e92527ff63fb5d9f18f5e39f2dedf832aa3c00cfc3984d0c290c1f3b9c",
        "md5": "04221bf8562de19a49caa87ddcc17268",
        "sha256": "d17a3f14871909b70be15e0b368e7429887dc1aa2702e3b1370c4e6bd7541151"
      },
      "downloads": -1,
      "filename": "ws-benchmark-1.1.1.tar.gz",
      "has_sig": false,
      "md5_digest": "04221bf8562de19a49caa87ddcc17268",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 109346,
      "upload_time": "2022-03-19T02:36:19",
      "upload_time_iso_8601": "2022-03-19T02:36:19.342804Z",
      "url": "https://files.pythonhosted.org/packages/7f/cd/a2e92527ff63fb5d9f18f5e39f2dedf832aa3c00cfc3984d0c290c1f3b9c/ws-benchmark-1.1.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}