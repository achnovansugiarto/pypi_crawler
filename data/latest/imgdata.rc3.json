{
  "info": {
    "author": "Arohan Ajit",
    "author_email": "arohanajit232@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python"
    ],
    "description": "# img-data - PyPi package to make image datasets\nimg-data is a small python package which will help you gather images from popular stock images sites and process them into image datasets. It can be incredibly easy to make a new image dataset for your deep learning project using img-data.\n\n## Overview\nimg-data provides 2 major functions :-\n- Gather images from some of the most popular stock image websites using the API - No need to write the whole Python code to extract all the images yourself!\n- It also conveniently divides those image into train, test and validation directories, so you have a dataset ready to use\n\n## Installation\nYou can PyPi repositiory to install img-data\n```\n$ pip install imgdata\n```\n## Usage\nI am working on simplifying it further but as of now, using imgdata involves 3 steps\n1. importing the library\n2. creating the object\n3. calling requisite function\n\n## Functions\nFollowing functions are available for use in the library:\n1. **pexels()** -> Download data from pexels API\n2. **unsplash()** -> Download data from unsplash API\n3. **transform_data()** -> Divide data at a provided path into train/test/validation\n\n### Downloading Images and Making Dataset\n```\n$ import imgdata\n$ obj = imgdata.Api()\n$ obj.pexels(query = query,\n            api_key = api_key,\n            count = count,\n            ratio = ratio,\n            divide = True/False,\n            validation = True/False)\n```\n\n#### Arguments for Data Download functions\n- **query**: You need to specify topic of image dataset. It can be a one word or multi word query. This will be the search query for API to work on.\n- **api_key**: You need to provide API key through which to access website's data. Keep in mind, some sites limit use of API. Program may generate an error if limits exceed. I'll try to generate a warning beforehand for such sites when they are used.\n- **count**: Total number of images needed. Again please check with site regarding the limit.\n- **ratio**: Ratio in which you needed images divided into train and test. Default ratio is 0.2.\n- **divide**: Setting this argument to `True` will automatically divide the downloaded images in train and test category\n- **validation**: Only applicable if `divide` is set to `True`. Separates data into train/test/validation instead of train/test.\n\n#### File Structure for Data Download Functions\n```bash\n- if `divide` is set to `True`:\nâ””â”€â”€ dataset\n    â”œâ”€â”€ train\n    â”‚   â””â”€â”€ *.jpg\n    â”œâ”€â”€ test\n    â”‚   â””â”€â”€ *.jpg\n    â””â”€â”€ val (if validation set to `True`)\n        â””â”€â”€ *.jpg\n\n- if `divide` is set to `False`\n\nâ””â”€â”€ dataset\n    â””â”€â”€ *.jpg\n\n\n```\n\n### Transforming Available Dataset into Train, Test, Validation\nShuffles the data converts them into train/test/val modules.\n\n```\n$ import imgdata\n$ obj = imgdata.Api()\n$ obj.transform_data(path = data path\n                    ratio = ratio,\n                    validation = True/False)\n```\n\n#### Arguments:\n- **path**: The path to the dataset.\n- **ratio**: Ratio of data for test and validation sets. (Default: 0.2)\n- **validation**: If set to true, files will be divided into train/test/val instead of train/test\n\n#### File Structure for Transforming data\n```bash\n- Initial File Structure\n\nâ””â”€â”€ dataset\n    â”œâ”€â”€ Class A\n    â””â”€â”€  Class B\n\n\n\n\n- Structure after transforming:\nâ””â”€â”€ dataset\n    â”œâ”€â”€ train\n    â”‚   â”œâ”€â”€ Class A\n    â”‚   â””â”€â”€ Class B\n    â”œâ”€â”€ test\n    â”‚   â”œâ”€â”€ Class A\n    â”‚   â””â”€â”€ Class B\n    â””â”€â”€ validation (if set to True)\n        â”œâ”€â”€ Class A\n        â””â”€â”€ Class B\n\n```\n\n## Keypoints\n- The ratio is mentioned is total count of files for test and validation individually. Eg. Assuming a ratio of 0.2 and a total of 10 files, test will have 2, validation will have 2 and train will have 6 files.\n- The path for transforming data should be to folder containing the classes\n\n\n## License\nMIT License\n\nCopyright (c) 2020 Arohan Ajit\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/arohanajit/img-data",
    "keywords": "data api images photos",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "imgdata",
    "package_url": "https://pypi.org/project/imgdata/",
    "platform": "",
    "project_url": "https://pypi.org/project/imgdata/",
    "project_urls": {
      "Homepage": "https://github.com/arohanajit/img-data"
    },
    "release_url": "https://pypi.org/project/imgdata/0.0.3/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "Use Stock Images APIs to make image dataset",
    "version": "0.0.3",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8209694,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7f0cb0f9817da384420468972fe11fe82a5629adbb27d69c779e2d9ca5512351",
          "md5": "60c56fcf0af22f6dc21898eb14b35750",
          "sha256": "37236f07710b2bd7b7cc94e7034ec02f6bbbe768045db0531c0ad8e06e933099"
        },
        "downloads": -1,
        "filename": "imgdata-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "60c56fcf0af22f6dc21898eb14b35750",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 2480,
        "upload_time": "2020-09-16T16:43:52",
        "upload_time_iso_8601": "2020-09-16T16:43:52.658933Z",
        "url": "https://files.pythonhosted.org/packages/7f/0c/b0f9817da384420468972fe11fe82a5629adbb27d69c779e2d9ca5512351/imgdata-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "593bc335202b371938203f99237ac5bf07d67c3b7962a26c932f5b9f8cf07b28",
          "md5": "a5986959ac74dd50c7cd96b18085e85e",
          "sha256": "1c1f25fc26a8739b0ed93826dae51b01efc69c890fceeaa91e430e3c690cb036"
        },
        "downloads": -1,
        "filename": "imgdata-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "a5986959ac74dd50c7cd96b18085e85e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 5522,
        "upload_time": "2020-09-17T16:11:39",
        "upload_time_iso_8601": "2020-09-17T16:11:39.261256Z",
        "url": "https://files.pythonhosted.org/packages/59/3b/c335202b371938203f99237ac5bf07d67c3b7962a26c932f5b9f8cf07b28/imgdata-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e7e472d26f7174891ac4072c994ffab0698f9285ee65b82202ac13cf8aba9bfc",
          "md5": "0922120cf71ddf49698ad85f6cbce6e5",
          "sha256": "b94173832c74464626eda5141175b484388f9eb498ecb51cc28056968704904e"
        },
        "downloads": -1,
        "filename": "imgdata-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "0922120cf71ddf49698ad85f6cbce6e5",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 5624,
        "upload_time": "2020-09-17T16:22:21",
        "upload_time_iso_8601": "2020-09-17T16:22:21.617121Z",
        "url": "https://files.pythonhosted.org/packages/e7/e4/72d26f7174891ac4072c994ffab0698f9285ee65b82202ac13cf8aba9bfc/imgdata-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "e7e472d26f7174891ac4072c994ffab0698f9285ee65b82202ac13cf8aba9bfc",
        "md5": "0922120cf71ddf49698ad85f6cbce6e5",
        "sha256": "b94173832c74464626eda5141175b484388f9eb498ecb51cc28056968704904e"
      },
      "downloads": -1,
      "filename": "imgdata-0.0.3.tar.gz",
      "has_sig": false,
      "md5_digest": "0922120cf71ddf49698ad85f6cbce6e5",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 5624,
      "upload_time": "2020-09-17T16:22:21",
      "upload_time_iso_8601": "2020-09-17T16:22:21.617121Z",
      "url": "https://files.pythonhosted.org/packages/e7/e4/72d26f7174891ac4072c994ffab0698f9285ee65b82202ac13cf8aba9bfc/imgdata-0.0.3.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}