{
  "info": {
    "author": "Kowsher",
    "author_email": "ga.kowsher@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# SklTransformer: Sci-Kit Learn Transformer\n\n\n## Sci-Kit Learn Transformer\nSklTransformer or SklT is a sentence or document embedding based on transformers, supervised fine-tuning/transfer learning, and showed the state of the art result for the Sklearn classifier(Logistic Regression, SVM, Naive Bayes, KNN, Decision Tree). An extra exponential function has been added to the final pooling output layer of bert and it gives state-of-the-art results than the previous models proposed. The architecture of Google BERT shows the [CLS] layer uses a softmax function on the pooling layer to predict the output and Huggingface uses a tanh function. Both of these methods have complications because values can be negative or too small. Adding an exponential layer converts values of the pooling layer into a positive range from 0.3 to 2.7. Consequently, every vector get a positive and non-zero unit which helps to keep significance of every single vector in every mathematical operation. Besides it extent the vector distance, which is good for decision making. SklTransformer has been applied to fine-tune the features for further classification using machine learning.\n\n\n\n## Installation\nTo install the latest release, we can do :\n\n``` python\n!pip install SklTransformer\n```\n\n\n## Getting started\n\n\nIn order to apply SklTransformer, as described here, `SklTransformer` function like this:\n``` python\nimport SklTransformer\n```\n\n## With fine tuning\nIt's a good idea to fine tuning the BERT model according to your dataset before getting sentnence embedding for the use of sklearn classifier.\nIf we have already model then we can simply read and load the model as :\n\n``` python\nimport SklTransformer\n\nsklt =SklTransformer.SklT(tokenizer_name=\"bert-base-uncased\", model_name=\"bert-base-uncased\", fine_tuning=True, X_train=X_train, y_train=y_train,X_val=X_test, y_val=y_test, nub_epoch=10,save_steps=500, save_path = '/content/drive/MyDrive/spam/')\n```\n'sklt' will carray a object of SklTransformer\nIn order to fine-tuning, we have to check the parameter 'fine-tuning' as true. By default it's false.\n\n-> For supervised fine tuning we have to check some parameters \n\n-> tokenizer_name (Need to pass model name or path),\n\n-> model_name (Need to pass tokenizer_nameor path),\n\n-> fine_tuning=False (Need to pass as true),\n\n-> X_train (Need to pass traing text, it can be array, list),\n\n-> y_train (Need to pass traing labels, it can be array, list),\n\n-> X_val (Need to pass validation text, it can be array, list),\n\n-> y_val (Need to pass validation labels, it can be array, list,\nnub_epoch (Number of epochs, by default 10),\n\n-> batch_size (Number of batch sizes, by default 8),\n\n-> save_steps (Number of saving checkpoint and evaluation, by default 5000),\n\n-> save_total_limit (Number of saving checkpoint, by default 1 that means, it will only save the best checkpoint)\n\n-> stopping_callback (Early stopping callback of traing, by default 4)\n\n-> save_path (Model saving path),\n\n-> max_length (Maximum length of every sample, by default 512)\n\n-> device (In which device, we want to traing model, default automatic choose of device according to environment)\n\n## Playing with Device selection\nDevice selection is a very important step in SklTransformer. In general, the training device can be automatically selected \n\n-> If we set up our machine with TPU, it will select as XLA\n\n-> If we set up our machine with GPU, it will select as CUDA\n\n-> If we set up our machine with CPU, it will select as CPU\n\nIn general, we want to pass particularly suitable device we can pass it as parameter such as xla, cuda, cpu\n\nIn order to training with TPU, it may be required 'torch_xla-1.9'. In this case, before importing SklTransformer, we need to install torch_xla-1.9\n\n``` python\n!pip install https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl\n```\n\n## Without fine tuning\n\nIf we have a fine tuned model or we do not want to fine tuning then we can just go with simple way (It's recommodeation for supervised fine-tuning of lanague model for better result)\n\n``` python\nimport SklTransformer\n\nsklt =SklTransformer.SklT(tokenizer_name=\"bert-base-uncased\", model_name=\"bert-base-uncased\")\n```\n## Playing with sentence or document embedding\nThe primary purpose of SklTransformer is the fixed-length (768) of single dimension of word embedding for every sentence or document so that the masked language model such as bert can be used as the embedding of sklearn machine learning classifiers.\n\nif 'sklt' is the object of SklTransformer after fine-tuned \n\n``` python\nX_train = sklt.fit_transform(X_train)\nX_test = sklt.transform(X_test)\n......\n```\nIt will return as numpy array which is suitable for any sklearn classifier\n\n## For better uses\nFor better use, it will be good if we remove TensorFlow. In very few cases TensorFlow can make issues. But in our experiment, we did not get any issues yet. \nTo uninstall TensorFlow we can just write a simple code\n``` python\n!pip uninstall -y tensorflow\n```\nIn the training time of the TPU machine, it's better to use torch_xla-1.9 which has been described above\nBut when a model is running on CPU, it is highly suggested to remove torch_xla-1.9 \nTo uninstall torch_xla-1.9\n\n``` python\n!pip uninstall -y https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl\n```\n## Development\ninstall_requires=[\n\t\t'transformers==4.8.2',\n\t\t'torch==1.9.0',\n\t\t'tqdm==4.41.1',\n\t\t'numpy==1.19.5',\n\t\t'sklearn',],",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/Kowsher/SklTransformer",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "SklTransformer",
    "package_url": "https://pypi.org/project/SklTransformer/",
    "platform": "",
    "project_url": "https://pypi.org/project/SklTransformer/",
    "project_urls": {
      "Homepage": "https://github.com/Kowsher/SklTransformer"
    },
    "release_url": "https://pypi.org/project/SklTransformer/0.5/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "",
    "version": "0.5",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 11647404,
  "releases": {
    "0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "90cee43adc246b3cde41f40ba1fb6d3fcb68defccec741b7c0008da5c4581cee",
          "md5": "4953737512d6441e9d84347549c44484",
          "sha256": "4936a299964e7f52ef1c38536bd58d784dcf4d2fdcc4a0bf6f1da0997c5bed7e"
        },
        "downloads": -1,
        "filename": "SklTransformer-0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "4953737512d6441e9d84347549c44484",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 6443,
        "upload_time": "2021-05-31T18:26:16",
        "upload_time_iso_8601": "2021-05-31T18:26:16.782772Z",
        "url": "https://files.pythonhosted.org/packages/90/ce/e43adc246b3cde41f40ba1fb6d3fcb68defccec741b7c0008da5c4581cee/SklTransformer-0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7d37bd149c2a5afad97887f80cf5de50e37b17e3a64f511465c1a497fa11d845",
          "md5": "00c10b3c4422abddf954ffcbd667f6a9",
          "sha256": "a14822b45827a0bf7fd08f041101212ff3052a6a71eb670ac3591f34aed07026"
        },
        "downloads": -1,
        "filename": "SklTransformer-0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "00c10b3c4422abddf954ffcbd667f6a9",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 6793,
        "upload_time": "2021-07-08T09:20:21",
        "upload_time_iso_8601": "2021-07-08T09:20:21.075026Z",
        "url": "https://files.pythonhosted.org/packages/7d/37/bd149c2a5afad97887f80cf5de50e37b17e3a64f511465c1a497fa11d845/SklTransformer-0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "092a380b71866beeb9f34e5be24057d1c4a4b30917d5e3bfd220f5bd5e8cfdba",
          "md5": "486bad682545e24a65138898aaf6cacb",
          "sha256": "1d01df522049d1e5ccb0d42399303f480d0d8b3d5a9ed6b6836ef9f68533ca51"
        },
        "downloads": -1,
        "filename": "SklTransformer-0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "486bad682545e24a65138898aaf6cacb",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 8875,
        "upload_time": "2021-07-08T18:11:50",
        "upload_time_iso_8601": "2021-07-08T18:11:50.686684Z",
        "url": "https://files.pythonhosted.org/packages/09/2a/380b71866beeb9f34e5be24057d1c4a4b30917d5e3bfd220f5bd5e8cfdba/SklTransformer-0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7376f68c046b2604e036c4aab420a9bf1f50708d74e188008713058cb100bcda",
          "md5": "42122c130e421e4961a2fc6cfeca8292",
          "sha256": "a6f863d93415888f567d99f1eca699fe0086bb2feb0ed2deae77dc8153d35c8c"
        },
        "downloads": -1,
        "filename": "SklTransformer-0.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "42122c130e421e4961a2fc6cfeca8292",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 8892,
        "upload_time": "2021-07-08T18:19:33",
        "upload_time_iso_8601": "2021-07-08T18:19:33.752423Z",
        "url": "https://files.pythonhosted.org/packages/73/76/f68c046b2604e036c4aab420a9bf1f50708d74e188008713058cb100bcda/SklTransformer-0.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "639bc14b80959aea95a2a7fdb3757b99295ad9c32383f9000d56625191c12321",
          "md5": "fc530e221a4c6b463a865da409422bd8",
          "sha256": "54d40585ecd81882d86459893e3e199cc32d6c54fad1e5cf9ef45bc5d6a2085c"
        },
        "downloads": -1,
        "filename": "SklTransformer-0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "fc530e221a4c6b463a865da409422bd8",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 8848,
        "upload_time": "2021-10-06T19:19:13",
        "upload_time_iso_8601": "2021-10-06T19:19:13.917402Z",
        "url": "https://files.pythonhosted.org/packages/63/9b/c14b80959aea95a2a7fdb3757b99295ad9c32383f9000d56625191c12321/SklTransformer-0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "639bc14b80959aea95a2a7fdb3757b99295ad9c32383f9000d56625191c12321",
        "md5": "fc530e221a4c6b463a865da409422bd8",
        "sha256": "54d40585ecd81882d86459893e3e199cc32d6c54fad1e5cf9ef45bc5d6a2085c"
      },
      "downloads": -1,
      "filename": "SklTransformer-0.5.tar.gz",
      "has_sig": false,
      "md5_digest": "fc530e221a4c6b463a865da409422bd8",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 8848,
      "upload_time": "2021-10-06T19:19:13",
      "upload_time_iso_8601": "2021-10-06T19:19:13.917402Z",
      "url": "https://files.pythonhosted.org/packages/63/9b/c14b80959aea95a2a7fdb3757b99295ad9c32383f9000d56625191c12321/SklTransformer-0.5.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}