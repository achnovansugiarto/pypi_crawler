{
  "info": {
    "author": "Ryan Turner",
    "author_email": "rdturnermtl@github.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "***************\nGetting Started\n***************\n\nThe Twiser package implements a Python library for variance reduction in A/B tests using pre-experiment covariates supporting publication [1]_.\nThese functions extend the idea of using pre-experiment data for variance reduction previously proposed in publication [2]_.\n\nInstallation\n============\n\nOnly ``Python>=3.7`` is officially supported, but older versions of Python likely work as well.\n\nThe package is installed with:\n\n.. code-block:: bash\n\n   pip install twiser\n\nSee `GitHub <https://github.com/twitter-research/twiser>`_, `PyPI <https://pypi.org/project/twiser/>`_, and `Read the Docs <https://twiser.readthedocs.io/en/latest/>`_.\n\nExample Usage\n=============\n\nA full demo notebook of the package is given in ``demo/survey_loan.ipynb``.\nHere is a snippet of the different methods from the notebook:\n\nSetup a predictor as a control variate\n--------------------------------------\n\nFirst, we need to define a regression model.\nWe can use anything that fits the sklearn idiom of ``fit`` and ``predict`` methods.\nThis predictor is used to take the ``n x d`` array of treatment unit covariates ``x_covariates`` and predict the treatment outcomes ``n``-length outcome array ``x``.\nLikewise, it makes predictions from the ``m x d`` array of control unit covariates ``y_covariates`` to the control ``m``-length outcome array ``y``.\n\n.. code:: python3\n\n    predictor = RandomForestRegressor(criterion=\"squared_error\", random_state=0)\n\nBasic z-test\n--------------------\n\nFirst, we apply the basic two-sample z-test included in Twiser.\nThis works basically the same as ``scipy.stats.ttest_ind``.\n\n.. code:: python3\n\n    estimate, (lb, ub), pval = twiser.ztest(x, y, alpha=0.05)\n    show_output(estimate, (lb, ub), pval)\n\n\n.. parsed-literal::\n\n    ATE estimate: 0.80 in (-0.14, 1.75), CI width of 1.89, p = 0.0954\n\n\nVariance reduction with held out data\n-------------------------------------\n\nNext, we apply variance reduction where the predictor was trained on a\nheld out 30% of the data. This is the easiest to show validity, but some\nof the added power is lost because not all data is used in the test.\n\n.. code:: python3\n\n    estimate, (lb, ub), pval = twiser.ztest_held_out_train(\n      x,\n      x_covariates,\n      y,\n      y_covariates,\n      alpha=0.05,\n      train_frac=0.3,\n      predictor=predictor,\n      random=np.random.RandomState(123),\n    )\n    show_output(estimate, (lb, ub), pval)\n\n\n.. parsed-literal::\n\n    ATE estimate: 1.40 in (0.20, 2.59), CI width of 2.39, p = 0.0217*\n\n\nVariance reduction with cross validation\n----------------------------------------\n\nTo be more statistically efficient we train and predict using 10-fold\ncross validation. Here, no data is wasted. As we can see it is a more\nsignificant result.\n\n.. code:: python3\n\n    estimate, (lb, ub), pval = twiser.ztest_cross_val_train(\n      x,\n      x_covariates,\n      y,\n      y_covariates,\n      alpha=0.05,\n      k_fold=10,\n      predictor=predictor,\n      random=np.random.RandomState(123),\n    )\n    show_output(estimate, (lb, ub), pval)\n\n\n.. parsed-literal::\n\n    ATE estimate: 1.38 in (0.51, 2.25), CI width of 1.74, p = 0.0019*\n\n\nVariance reduction in-sample\n----------------------------\n\nIn the literature it is popular to train the predictor in the same\nsample as the test. This often gives the most power. However, any\noverfitting in the predictor can also invalidate the results.\n\n.. code:: python3\n\n    estimate, (lb, ub), pval = twiser.ztest_in_sample_train(\n      x,\n      x_covariates,\n      y,\n      y_covariates,\n      alpha=0.05,\n      predictor=predictor,\n      random=np.random.RandomState(123),\n    )\n    show_output(estimate, (lb, ub), pval)\n\n\n.. parsed-literal::\n\n    ATE estimate: 0.86 in (0.24, 1.49), CI width of 1.24, p = 0.0065*\n\nOther interfaces\n----------------\n\nIt is also possible to call these methods using raw control predictions instead of training the predictor in the Twiser method.\nIt also supports a sufficient statistics interface for working with large datasets.\nSee the `documentation <https://twiser.readthedocs.io/en/latest/>`_ for details.\n\nSupport\n=======\n\nCreate a `new issue <https://github.com/twitter-research/twiser/issues/new/choose>`_.\n\nLinks\n=====\n\nThe `source <https://github.com/twitter-research/twiser>`_ is hosted on GitHub.\n\nThe `documentation <https://twiser.readthedocs.io/en/latest/>`_ is hosted at Read the Docs.\n\nInstallable from `PyPI <https://pypi.org/project/twiser/>`_.\n\nReferences\n==========\n\n.. [1] `R. Turner, U. Pavalanathan, S. Webb, N. Hammerla, B. Cohn, and A. Fu. Isotonic regression\n   adjustment for variance reduction. In CODE@MIT, 2021\n   <https://ide.mit.edu/events/2021-conference-on-digital-experimentation-mit-codemit/>`_.\n.. [2] `A. Deng, Y. Xu, R. Kohavi, and T. Walker. Improving the sensitivity of online controlled\n   experiments by utilizing pre-experiment data. In Proceedings of the Sixth ACM International\n   Conference on Web Search and Data Mining, pages 123--132, 2013\n   <https://www.exp-platform.com/Documents/2013-02-CUPED-ImprovingSensitivityOfControlledExperiments.pdf>`_.\n.. [3] `A. Poyarkov, A. Drutsa, A. Khalyavin, G. Gusev, and P. Serdyukov. Boosted decision tree\n   regression adjustment for variance reduction in online controlled experiments. In Proceedings of\n   the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages\n   235--244, 2016 <https://www.kdd.org/kdd2016/papers/files/adf0653-poyarkovA.pdf>`_.\n.. [4] `I. Barr. Reducing the variance of A/B tests using prior information. Degenerate State, Jun\n   2018\n   <https://www.degeneratestate.org/posts/2018/Jan/04/reducing-the-variance-of-ab-test-using-prior-information/>`_.\n\nLicense\n=======\n\nThis project is licensed under the Apache 2 License - see the LICENSE file for details.\n\n\n",
    "description_content_type": "text/x-rst",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/twitter/twiser/",
    "keywords": "",
    "license": "Apache v2",
    "maintainer": "",
    "maintainer_email": "",
    "name": "twiser",
    "package_url": "https://pypi.org/project/twiser/",
    "platform": "any",
    "project_url": "https://pypi.org/project/twiser/",
    "project_urls": {
      "Homepage": "https://github.com/twitter/twiser/"
    },
    "release_url": "https://pypi.org/project/twiser/0.0.1/",
    "requires_dist": null,
    "requires_python": ">=3.7",
    "summary": "Advanced variance reduction methods.",
    "version": "0.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 13559831,
  "releases": {
    "0.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6942266f8568fe7229f29c8ee4cb41097fab2333ff513fadf51a6faac9ac15da",
          "md5": "4ae3cd2ae36bb1fda85bdc40fa4dfcbe",
          "sha256": "992fc5f6b9337c61a048ac0d7a788024bfb8cc7d77528508e334d1e670a1d10a"
        },
        "downloads": -1,
        "filename": "twiser-0.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "4ae3cd2ae36bb1fda85bdc40fa4dfcbe",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 16696,
        "upload_time": "2022-04-15T00:27:33",
        "upload_time_iso_8601": "2022-04-15T00:27:33.567356Z",
        "url": "https://files.pythonhosted.org/packages/69/42/266f8568fe7229f29c8ee4cb41097fab2333ff513fadf51a6faac9ac15da/twiser-0.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4958b68db6ad2454eb3a39608d93dbd8d15f37bf9c23b3475f68e1398ce317b4",
          "md5": "a8c3ce901fad5e8b5df4a57c133e2b98",
          "sha256": "a04b9b98d7a14b046f1568b485a39306dc4d22468fdb7d23b1ee1dad6b1f63aa"
        },
        "downloads": -1,
        "filename": "twiser-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "a8c3ce901fad5e8b5df4a57c133e2b98",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 16775,
        "upload_time": "2022-04-19T18:38:20",
        "upload_time_iso_8601": "2022-04-19T18:38:20.364538Z",
        "url": "https://files.pythonhosted.org/packages/49/58/b68db6ad2454eb3a39608d93dbd8d15f37bf9c23b3475f68e1398ce317b4/twiser-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "4958b68db6ad2454eb3a39608d93dbd8d15f37bf9c23b3475f68e1398ce317b4",
        "md5": "a8c3ce901fad5e8b5df4a57c133e2b98",
        "sha256": "a04b9b98d7a14b046f1568b485a39306dc4d22468fdb7d23b1ee1dad6b1f63aa"
      },
      "downloads": -1,
      "filename": "twiser-0.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "a8c3ce901fad5e8b5df4a57c133e2b98",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 16775,
      "upload_time": "2022-04-19T18:38:20",
      "upload_time_iso_8601": "2022-04-19T18:38:20.364538Z",
      "url": "https://files.pythonhosted.org/packages/49/58/b68db6ad2454eb3a39608d93dbd8d15f37bf9c23b3475f68e1398ce317b4/twiser-0.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}