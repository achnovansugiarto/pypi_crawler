{
  "info": {
    "author": "Rafihatu Bello",
    "author_email": "rafibella101@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# eBay Web Scraper\n\n## Description\nThis is a web scraper that extracts info about listings from popular e-commerce site, eBay. \nCollects info about the category the listing belongs to, title of listing, link to the listing, link to the listing's image and price of each listing.\n\n## Technologies\n\n* [Python 3.9](https://python.org) : Base programming language for development. The latest version of python.\n* [Docker Engine and Docker Compose](https://www.docker.com/) : Containerization of the application and services orchestration\n* [Postgres Database](https://www.postgresql.org) : Database where scraped listings are stored.\n\n\n## Getting Started\n\nUsing this scraper is very simple, all you need is to have Git and Docker Engine installed on your machine. \nIf you do not wish to use docker, simply create your own virtual environment and run `pip install -r requirements.txt` from the root directory to\ninstall the requirements stated in the `requirements.txt` file\nDon't forget to add your postgres database connection variables in the `.env` file in the root folder.\nExample of what the `.env` file should look like\n```\nDB_PORT = XXXX\nDB_HOST = your_database_host\nDB_USER = your_username\nDB_NAME = the_name_of_your_database_here\nDB_PASSWORD = your_password_here\n\n```\n\n\nThe scraper can be found in src/scraper\neBay contains 3 methods which are `scrape()`, `add_category_to_database()`, `add_listing_to_database()`. \nThe methods are self-explanatory. \nscrape takes in the category/keyword, and the number/quantity of listings to be scraped while `add_category_to_database()` and `add_listing_to_database()` adds categories and listings to their \nrespective databases.\n\nExample:\n```\n    from src.scraper import eBay\n    ebay = eBay()\n    ebay.scrape(keyword=\"book\", quantity=200)\n    ebay.add_category_to_database()\n    ebay.add_listings_to_database()\n```\n\n## Testing\n\n\nThis project has pytest embedded in it and can be run with the following command `python -m pytest tests/` from the root directory.\nNote: This should be run after after all necessary database connection variables have been declared in the.env file\n\n\n## License\n\nThe MIT License - Copyright (c) 2021 - Rafihatu Bello\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/Rafiatu/eBay-scraper",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "scraper-Rafihatu",
    "package_url": "https://pypi.org/project/scraper-Rafihatu/",
    "platform": "",
    "project_url": "https://pypi.org/project/scraper-Rafihatu/",
    "project_urls": {
      "Bug Tracker": "https://github.com/Rafiatu/eBay-scraper/issues",
      "Homepage": "https://github.com/Rafiatu/eBay-scraper"
    },
    "release_url": "https://pypi.org/project/scraper-Rafihatu/0.0.3/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "A small eBay web scraper package",
    "version": "0.0.3",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 11109374,
  "releases": {
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cee9d83dcd569f3c8b5bc3052852a3aaf3a65b959288af891dc8fd0f89724432",
          "md5": "6c9de559c810335dc2ff706073acc45e",
          "sha256": "0f603da71a147ca84ffafffc8e0923b094f076c45dd0a6c9261e2754a05f0cb5"
        },
        "downloads": -1,
        "filename": "scraper_Rafihatu-0.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "6c9de559c810335dc2ff706073acc45e",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 4536,
        "upload_time": "2021-08-06T10:13:49",
        "upload_time_iso_8601": "2021-08-06T10:13:49.734477Z",
        "url": "https://files.pythonhosted.org/packages/ce/e9/d83dcd569f3c8b5bc3052852a3aaf3a65b959288af891dc8fd0f89724432/scraper_Rafihatu-0.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bdf4f3081590364b2cd7ec4dceb13ec43640f58ddb924fe48072cde090a8f417",
          "md5": "b06e624cca53a08ae52cfeded5aa8049",
          "sha256": "4ff16f60268fdf0ede9c48bd96b407d7b21c5fb73cb1db472b1f45883d521ae6"
        },
        "downloads": -1,
        "filename": "scraper-Rafihatu-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "b06e624cca53a08ae52cfeded5aa8049",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 4122,
        "upload_time": "2021-08-06T10:13:51",
        "upload_time_iso_8601": "2021-08-06T10:13:51.546176Z",
        "url": "https://files.pythonhosted.org/packages/bd/f4/f3081590364b2cd7ec4dceb13ec43640f58ddb924fe48072cde090a8f417/scraper-Rafihatu-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "cee9d83dcd569f3c8b5bc3052852a3aaf3a65b959288af891dc8fd0f89724432",
        "md5": "6c9de559c810335dc2ff706073acc45e",
        "sha256": "0f603da71a147ca84ffafffc8e0923b094f076c45dd0a6c9261e2754a05f0cb5"
      },
      "downloads": -1,
      "filename": "scraper_Rafihatu-0.0.3-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "6c9de559c810335dc2ff706073acc45e",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 4536,
      "upload_time": "2021-08-06T10:13:49",
      "upload_time_iso_8601": "2021-08-06T10:13:49.734477Z",
      "url": "https://files.pythonhosted.org/packages/ce/e9/d83dcd569f3c8b5bc3052852a3aaf3a65b959288af891dc8fd0f89724432/scraper_Rafihatu-0.0.3-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "bdf4f3081590364b2cd7ec4dceb13ec43640f58ddb924fe48072cde090a8f417",
        "md5": "b06e624cca53a08ae52cfeded5aa8049",
        "sha256": "4ff16f60268fdf0ede9c48bd96b407d7b21c5fb73cb1db472b1f45883d521ae6"
      },
      "downloads": -1,
      "filename": "scraper-Rafihatu-0.0.3.tar.gz",
      "has_sig": false,
      "md5_digest": "b06e624cca53a08ae52cfeded5aa8049",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 4122,
      "upload_time": "2021-08-06T10:13:51",
      "upload_time_iso_8601": "2021-08-06T10:13:51.546176Z",
      "url": "https://files.pythonhosted.org/packages/bd/f4/f3081590364b2cd7ec4dceb13ec43640f58ddb924fe48072cde090a8f417/scraper-Rafihatu-0.0.3.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}