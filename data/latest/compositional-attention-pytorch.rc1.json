{
  "info": {
    "author": "Phil Wang",
    "author_email": "lucidrains@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3.6",
      "Topic :: Scientific/Engineering :: Artificial Intelligence"
    ],
    "description": "",
    "description_content_type": "",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/lucidrains/compositional-attention-pytorch",
    "keywords": "artificial intelligence,deep learning,attention mechanism",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "compositional-attention-pytorch",
    "package_url": "https://pypi.org/project/compositional-attention-pytorch/",
    "platform": null,
    "project_url": "https://pypi.org/project/compositional-attention-pytorch/",
    "project_urls": {
      "Homepage": "https://github.com/lucidrains/compositional-attention-pytorch"
    },
    "release_url": "https://pypi.org/project/compositional-attention-pytorch/0.0.1/",
    "requires_dist": [
      "einops (>=0.4)",
      "einops-exts",
      "torch (>=1.6)"
    ],
    "requires_python": "",
    "summary": "Compositional Attention - Pytorch",
    "version": "0.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 13764577,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "85a02511319c5d2c7da215e9533a8617f9d37c51fb02752ee68205630f5725a5",
          "md5": "4bc6b2eb53c085e23fa578e09161f36a",
          "sha256": "937807fd1e04a481aaf9f56e8b14234a6bf6a4ff2053adafef03bcf78121b64e"
        },
        "downloads": -1,
        "filename": "compositional_attention_pytorch-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "4bc6b2eb53c085e23fa578e09161f36a",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 3964,
        "upload_time": "2022-05-09T23:40:47",
        "upload_time_iso_8601": "2022-05-09T23:40:47.308416Z",
        "url": "https://files.pythonhosted.org/packages/85/a0/2511319c5d2c7da215e9533a8617f9d37c51fb02752ee68205630f5725a5/compositional_attention_pytorch-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "51e13fd7bc4c89b7a0aa10cf7ab444e5eec5044b5dad702cfdaa6f29b847b473",
          "md5": "7e6661cc39a29ccc8a0ebd6ccc35ee67",
          "sha256": "82f865b970e59bf99c90ce1b765f843bad4c3bf3cb8b1484272bd534e7eb1d39"
        },
        "downloads": -1,
        "filename": "compositional-attention-pytorch-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "7e6661cc39a29ccc8a0ebd6ccc35ee67",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 3892,
        "upload_time": "2022-05-09T23:40:48",
        "upload_time_iso_8601": "2022-05-09T23:40:48.430095Z",
        "url": "https://files.pythonhosted.org/packages/51/e1/3fd7bc4c89b7a0aa10cf7ab444e5eec5044b5dad702cfdaa6f29b847b473/compositional-attention-pytorch-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "85a02511319c5d2c7da215e9533a8617f9d37c51fb02752ee68205630f5725a5",
        "md5": "4bc6b2eb53c085e23fa578e09161f36a",
        "sha256": "937807fd1e04a481aaf9f56e8b14234a6bf6a4ff2053adafef03bcf78121b64e"
      },
      "downloads": -1,
      "filename": "compositional_attention_pytorch-0.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "4bc6b2eb53c085e23fa578e09161f36a",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 3964,
      "upload_time": "2022-05-09T23:40:47",
      "upload_time_iso_8601": "2022-05-09T23:40:47.308416Z",
      "url": "https://files.pythonhosted.org/packages/85/a0/2511319c5d2c7da215e9533a8617f9d37c51fb02752ee68205630f5725a5/compositional_attention_pytorch-0.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "51e13fd7bc4c89b7a0aa10cf7ab444e5eec5044b5dad702cfdaa6f29b847b473",
        "md5": "7e6661cc39a29ccc8a0ebd6ccc35ee67",
        "sha256": "82f865b970e59bf99c90ce1b765f843bad4c3bf3cb8b1484272bd534e7eb1d39"
      },
      "downloads": -1,
      "filename": "compositional-attention-pytorch-0.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "7e6661cc39a29ccc8a0ebd6ccc35ee67",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 3892,
      "upload_time": "2022-05-09T23:40:48",
      "upload_time_iso_8601": "2022-05-09T23:40:48.430095Z",
      "url": "https://files.pythonhosted.org/packages/51/e1/3fd7bc4c89b7a0aa10cf7ab444e5eec5044b5dad702cfdaa6f29b847b473/compositional-attention-pytorch-0.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}