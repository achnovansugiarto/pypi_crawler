{
  "info": {
    "author": "Souvik Pratiher",
    "author_email": "spratiher9@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Intended Audience :: Developers",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.8",
      "Topic :: Software Development"
    ],
    "description": "## SparkDataset\n\n[comment]: <> ( [![PyPI version]&#40;https://badge.fury.io/py/pydataset.svg&#41;]&#40;http://badge.fury.io/py/pydataset&#41;)\n\nProvides instant access to many datasets right from Pyspark (in Spark DataFrame structure).\n\n### What?\n\nThe idea is simple. There are various datasets available out there, but they are scattered in different places over the web.\nIs there a quick way (in Pyspark) to access them instantly without going through the hassle of searching, downloading, and reading ... etc?\nSparkDataset tries to address that question :)\n\n\n### Usage:\n\nStart with importing `data()`:\n```python\nfrom sparkdataset import data\n```\n- To load a dataset:\n```python\ntitanic = data('titanic')\n```\n- To display the documentation of a dataset:\n```python\ndata('titanic', show_doc=True)\n```\n- To see the available datasets:\n```python\ndata()\n```\n\nThat's it.\n\n\n### Why?\n\nIn `R`, there is a very easy and immediate way to access multiple statistical datasets,\nin almost no effort. All it takes is one line ` > data(dataset_name)`.\nThis makes the life easier for quick prototyping and testing.\nWell, I am jealous that Pyspark does not have a similar functionality.\nThus, the aim of `sparkdataset` is to fill that gap.\n\nCurrently, `sparkdataset` has about 757 (mostly numerical-based) datasets, that are based on `RDatasets`.\nIn the future, I plan to scale it to include a larger set of datasets.\nFor example,\n1) include textual data for NLP-related tasks, and\n2) allow adding a new dataset to the in-module repository.\n\n\n### Installation:\n\n`$ pip install sparkdataset`\n\n#### Uninstall:\n\n- `$ pip uninstall sparkdataset`\n- `$ rm -rf $HOME/.sparkdataset`\n\n### Changelog\n\n**1.0.0**\n\n- Added search dataset by name similarity.\n- Example:\n\n```python\n>>> data('heat')\nDid you mean:\nWheat, heart, Heating, Yeast, eidat, badhealth, deaths, agefat, hla, heptathlon, azt\n```\n\n- Added support to Windows.\n\n### Dependency:\n- pandas\n- pyspark :: 3.1.2\n\n### Miscellaneous:\n\n- Tested on OSX and Linux (debian).\n- Supports both Python 3 (3.8.8 and above).\n\n\n#### TODO:\n- add textual datasets (e.g. NLTK stuff).\n- add samples generators.\n\n\n#### Thanks to:\n\n- [RDatasets](https://github.com/vincentarelbundock/Rdatasets): R's datasets collection.  \n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "https://github.com/Spratiher9/SparkDataset/archive/refs/tags/1.0.0.tar.gz",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/Spratiher9/SparkDataset",
    "keywords": "Spark,Apache Spark,benchmarking,data,datasets,standard data",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "sparkdataset",
    "package_url": "https://pypi.org/project/sparkdataset/",
    "platform": "",
    "project_url": "https://pypi.org/project/sparkdataset/",
    "project_urls": {
      "Download": "https://github.com/Spratiher9/SparkDataset/archive/refs/tags/1.0.0.tar.gz",
      "Homepage": "https://github.com/Spratiher9/SparkDataset"
    },
    "release_url": "https://pypi.org/project/sparkdataset/1.0.0/",
    "requires_dist": [
      "pandas",
      "pyspark (==3.1.2)"
    ],
    "requires_python": "",
    "summary": "Provides instant access to many popular datasets right from Pyspark (in dataframe structure).",
    "version": "1.0.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 11892131,
  "releases": {
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "59600d56e3f4135bc0c7697dd8cb902c9166c5f0154fe2feaaa6013f7fba526f",
          "md5": "1795bff1cc72307a04465ca88f28d645",
          "sha256": "8de8d425a414992fb016ec089a62a76c38e9aa20a88aad61859547a9e0c35b1b"
        },
        "downloads": -1,
        "filename": "sparkdataset-1.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "1795bff1cc72307a04465ca88f28d645",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 15941505,
        "upload_time": "2021-11-01T13:26:27",
        "upload_time_iso_8601": "2021-11-01T13:26:27.487500Z",
        "url": "https://files.pythonhosted.org/packages/59/60/0d56e3f4135bc0c7697dd8cb902c9166c5f0154fe2feaaa6013f7fba526f/sparkdataset-1.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6a1e8abca2627b3bb785f2a60a092bc6eeb1b334d70577c5f9dbc67f82a08224",
          "md5": "5775c9459abf1e09771a249ba1a80c00",
          "sha256": "fd0d996abc2c9051b97354036b4cbf3b006e7febbcdaf8638a9140d2ce7221d8"
        },
        "downloads": -1,
        "filename": "sparkdataset-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "5775c9459abf1e09771a249ba1a80c00",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 15943671,
        "upload_time": "2021-11-01T13:26:32",
        "upload_time_iso_8601": "2021-11-01T13:26:32.402011Z",
        "url": "https://files.pythonhosted.org/packages/6a/1e/8abca2627b3bb785f2a60a092bc6eeb1b334d70577c5f9dbc67f82a08224/sparkdataset-1.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "59600d56e3f4135bc0c7697dd8cb902c9166c5f0154fe2feaaa6013f7fba526f",
        "md5": "1795bff1cc72307a04465ca88f28d645",
        "sha256": "8de8d425a414992fb016ec089a62a76c38e9aa20a88aad61859547a9e0c35b1b"
      },
      "downloads": -1,
      "filename": "sparkdataset-1.0.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "1795bff1cc72307a04465ca88f28d645",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 15941505,
      "upload_time": "2021-11-01T13:26:27",
      "upload_time_iso_8601": "2021-11-01T13:26:27.487500Z",
      "url": "https://files.pythonhosted.org/packages/59/60/0d56e3f4135bc0c7697dd8cb902c9166c5f0154fe2feaaa6013f7fba526f/sparkdataset-1.0.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "6a1e8abca2627b3bb785f2a60a092bc6eeb1b334d70577c5f9dbc67f82a08224",
        "md5": "5775c9459abf1e09771a249ba1a80c00",
        "sha256": "fd0d996abc2c9051b97354036b4cbf3b006e7febbcdaf8638a9140d2ce7221d8"
      },
      "downloads": -1,
      "filename": "sparkdataset-1.0.0.tar.gz",
      "has_sig": false,
      "md5_digest": "5775c9459abf1e09771a249ba1a80c00",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 15943671,
      "upload_time": "2021-11-01T13:26:32",
      "upload_time_iso_8601": "2021-11-01T13:26:32.402011Z",
      "url": "https://files.pythonhosted.org/packages/6a/1e/8abca2627b3bb785f2a60a092bc6eeb1b334d70577c5f9dbc67f82a08224/sparkdataset-1.0.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}