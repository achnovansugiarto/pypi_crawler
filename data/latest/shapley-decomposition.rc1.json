{
  "info": {
    "author": "Can Itez",
    "author_email": "<canitez01@hotmail.com>",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.11",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9"
    ],
    "description": "# Shapley Decomposition\n\nThis package consists of two applications of shapley values in descriptive analysis: 1) a generalized module for decomposing change over time, using shapley values[^1] (initially influenced by the World Bank's Job Structure tool[^2]) and 2) shapley and owen values based decomposition of R^2 (contribution of independent variables to a goodness of fit metric -R^2 in this case-) for linear regression models[^3].\n\n## Notes\n\nIdentities or functions with independently moving variables have independent contributions to the result as well. Therefore this module is better useful for functions or identities with dependently moving variables (though it works as well for the independent movements). It should be noted that being able to decompose the contribution of variables doesn't mean that the results are always clearly interpretable. Many features of variables like; scale, dependency mode, change dynamics (slow paced/fast paced, instant/lagged), etc. deserves attention when interpreting their individual contribution to the change or result.   \n\nBoth for the first and second application, the computation time increases exponentially as the number of variables increase. This is the result of powersets and so 2^n  calculations.\n\nShapley value:\n\n$v(i) = \\sum \\limits _{S \\subseteq M \\setminus i} \\phi(s) \\cdot [V(S \\cup \\{i\\})-V(S)]$\n\n$\\phi(s) = (m-1-s)! \\cdot s!/m!$\n\nwhere $i \\in M$ and M is the main set of variables and $m=|M|, s=|S|$. For shapley change decomposition, $[V(S \\cup \\{i_{t_1} \\})-V(S\\cup \\{i_{t_0} \\})]$ and s is the number of variables with $t_1$ instance.  \n\nOwen value:\n\n$o(i) = \\sum \\limits _{R \\subseteq N \\setminus k} \\sum \\limits _{T \\subseteq B_k \\setminus i} \\phi(r) \\cdot \\omega(t) \\cdot [V(Q \\cup T \\cup \\{i\\})-V(Q \\cup T)]$\n\n$\\phi(r) = (n-1-r)! \\cdot r!/n!$\n\n$\\phi(t) = (b_k-1-t)! \\cdot t!/b_k!$\n\nwhere $i \\in M$ and M is the main set of variables. N is the powerset of coalition/group set composed of i individuals.  $Q = \\bigcup_{r \\in R}B_r$ and $n=|N|, r=|R|, b_k=|B_k|, t=|T|$.\n\n## Installation\n\nRun the following to install\n\n```python\npip install shapley_decomposition\n```\n\n## Workings\n\n`shapley_decomposition.shapley_change` module consists of three functions: `samples()`, `shapley_values()` and `decomposition()`. `shapley_change.samples(dataframe)` returns powerset pairs that model uses. `shapley_change.shapley_values(dataframe, \"your function\")` returns weighted differences for each variable, sum of which gives the shapley value. `shapley_change.decomposition(dataframe, \"your function\")` returns decomposed total change by variable contributions. These functions of shapley_change module accepts either or both of the **data** and **function** inputs:\n\n1. The structure of input data is **important**. Module accepts pandas dataframes or 2d arrays:\n  * If pandas dataframe is used as input, both the dependent variable and the independent variables should be presented in the given format (variable names as index and years as columns):\n\n    |  | year1 | year2 |\n    | --- | ----------- | ----|\n    | **y** | y_value | y_value |\n    | **x1** | x1_value | x1_value |\n    | **x2** | x2_value | x2_value |\n    | **...** | ... | ... |\n    | **xn** | xn_value | xn_value |\n\n  * If an array is preferred, note that module will convert it to a pandas dataframe format and expects y and xs in the following order:\n    ```\n    [[y_value,y_value],\n      [x1_value,x1_value],\n      [x2_value,x2_value]]\n      ...\n    ```\n2. Identity or function defines the relation between xs and y. Due to the characteristic of shapley decomposition the sum of xs' contributions should be equal to y, i.e. exact (with plus minus 0.0001 freedom in this module due to the residue of arithmetic operations), therefore no place for residuals, or an input relation that fails to create the given y will shoot a specific error. Function input is expected in text format. It is evaluated by a custom syntax parser (as the eval() function has its security risks). Expected format for the function input is the right hand side of the equation:\n\n    * `\"x1+x2*(x3/x4)**x5\"`\n    * `\"(x1+x2)*x3+x4\"`\n    * `\"x1*x2**2\"`\n\n    All arithmetic operators and paranthesis operations are usable:\n    * `\"+\" , \"-\" , \"*\" , \"/\" or \"Ã·\", \"**\" or \"^\"`\n\n3. If `shapley_change.decomposition(df,\"your function\", cagr=True)` is called, a yearly_growth (using compound annual growth rate - cagr) column will be added, which will index the decomposition to cagr of the y. Default is `cagr=False`.   \n\nThe `shapley_decomposition.shapley_r2` module consists of three functions as well: `samples()`, `shapley_decomposition()` and `owen_decomposition`. `shapley_r2.samples(dataframe)` returns powerset variable pairs that model uses. `shapley_r2.shapley_decomposition(dataframe)` returns the decomposition of model r^2 to the contributions of variables. `shapley_r2.owen_decomposition(dataframe, [[\"x1\",\"x2\"],[..]])` returns the owen decomposition of model r^2 to the contributions of variables and groups/coalitions. Input features expected by shapley_r2 functions are as:\n\n  1. The expected format for the input dataframe or array is:\n\n  |  | x1 | x2 | ... | xn | y |  \n  | --- | --- | --- | --- | --- | --- |\n  | **0** | x1_value | x2_value | ... | xn_value | y_value |\n  | **1** | x1_value | x2_value | ... | xn_value | y_value |\n  | **2** | x1_value | x2_value | ... | xn_value | y_value |\n  | **...** | ... | ... | ... | ... | ... |\n  | **n** | x1_value | x2_value | ... | xn_value | y_value |\n\n\n  2. `shapley_r2.owen_decomposition` expects the group/coalition structure as the second input. This input should be a list of list showing the variables grouped within coalition/group lists. For example a model of 8 variables, x1,x2,...,x8 has three groups/coalitions which are formed as group1:(x1,x2,x3), group2:(x4) and group3:(x5,x6,x7,x8). Then the second input of owen_decomposition should be `[[\"x1\",\"x2\",\"x3\"],[\"x4\"],[\"x5\",\"x6\",\"x7\",\"x8\"]]`. Even if it is a singleton like group2 which has only x4, variable name should be in a list. If every group is a singleton, then the owen values will be equal to shapley values.\n\n  3. As the computation time increases exponentially with the number of variables. For the shapley_decomposition function a default upper variable limit of 10 variables has been set. Same limit applies for owen_decomposition but as the number of groups, not individual variables. However in users' own discretion more variables can be forced by calling the function as `shapley_r2.shapley_decomposition(df, force=True)` or `shapley_r2.owen_decomposition(df, [groups], force=True)`.\n\n## Examples\n\n1. As the first influence for the model was from WB's Job Structure, accordingly first example is decomposition of change in value added per capita of Turkey from 2000 to 2018 according to `\"x1*x2*x3*x4\"` where x1 is value added per worker, x2 is employment rate, x3 is participation rate, x4 is share of 15-64 population in total population. This is an identity.\n\n  ```python\n  import pandas\n  from shapley_decomposition import shapley_change\n\n  df=pandas.DataFrame([[8237.599210,15026.707520],[27017.637990,43770.525560],[0.935050,0.891050],[0.515090,0.57619],[0.633046,0.668674]],index=[\"val_ad_pc\",\"val_ad_pw\",\"emp_rate\",\"part_rate\",\"working_age\"], columns=[2000,2018])\n  print(df)\n  ```\n  |  | 2000 | 2018 |\n  | --- | ----------- | ----|\n  | **val_ad_pc** | 8237.599210 | 15026.707520 |\n  | **val_ad_pw** | 27017.637990 | 43770.525560 |\n  | **emp_rate** | 0.935050 | 0.891050 |\n  | **part_rate** | 0.515090 | 0.57619 |\n  | **part_rate** | 0.633046 | 0.668674 |\n\n  ```python\n  shapley_change.decomposition(df,\"x1*x2*x3*x4\")\n  ```\n  |  | 2000 | 2018 | dif | shapley | contribution |\n  | --- | --- | --- | --- | --- | --- |\n  | **val_ad_pc** |\t8237.599210 |\t15026.707520 |\t6789.108310 |\t6789.108310 |\t1.000000 |\n  | **val_ad_pw** |\t27017.637990 | 43770.525560 |\t16752.887570 | 5431.365538 | 0.800012 |\n  | **emp_rate** | 0.935050 |\t0.891050 | -0.044000 | -556.985657 | -0.082041 |\n  | **part_rate** |\t0.515090 | 0.576190 | 0.061100 | 1285.200011 | 0.189303 |\n  | **working_age** |\t0.633046 | 0.668674 |\t0.035628 | 629.528410 |\t0.092726 |\n\n2. Second example is the decomposition of change in non-parametric skewness of a normally distributed sample, after the sample is altered with additional data. We are trying to understand how the change in mean, median and standard deviation contributed to the change in skewness parameter. Non parametric skewness is calculated by `\"(x1-x2)/x3\"`, (mean-median)/standard deviation.\n\n  ```python\n  import numpy as np\n  import pandas\n  from shapley_decomposition import shapley_change\n\n  np.random.seed(210)\n\n  data = np.random.normal(loc=0, scale=1, size=100)\n\n  add = [np.random.uniform(min(data), max(data)) for m in range(5,10)]\n\n  altered_data = np.concatenate([data,add])\n\n  med1, med2 = np.median(data), np.median(altered_data)\n  mean1, mean2 = np.mean(data), np.mean(altered_data)\n  std1, std2 = np.std(data, ddof=1), np.std(altered_data, ddof=1)\n  sk1 = (np.mean(data)-np.median(data))/np.std(data, ddof=1)\n  sk2 = (np.mean(altered_data)-np.median(altered_data))/np.std(altered_data, ddof=1)\n\n  df=pandas.DataFrame([[sk1,sk2],[mean1,mean2],[med1,med2],[std1,std2]], columns=[\"0\",\"1\"], index=[\"non_par_skew\",\"mean\",\"median\",\"std\"])\n\n  shapley_change.decomposition(df,\"(x1-x2)/x3\")\n  ```\n  |  | 0 | 1 | dif | shapley | contribution |\n  | --- | --- | --- | --- | --- | --- |\n  | **non_par_skew** |\t0.065803 |\t0.044443 |\t-0.021359 |\t-0.021359 |\t1.000000 |\n  | **mean** |\t-0.247181 | -0.285440 \t |\t-0.038259 | -0.036146 | 1.692288 |\n  | **median** | -0.315957 |\t-0.333088 | -0.017131 | 0.016184 | -0.757719 |\n  | **std** |\t1.045188 | 1.072090 | 0.026902 | -0.001398 | 0.065432 |\n\n3. Third example uses shapley_r2 decomposition with the fish market database from kaggle[^4]:\n\n  ```python\n  import numpy as np\n  import pandas\n  from shapley_decomposition import shapley_r2\n\n  df=pandas.read_csv(\"Fish.csv\")\n  #ignoring the species column\n  shapley_r2.shapley_decomposition(df.iloc[:,1:])\n  ```\n  | |shapley_values | contribution |\n  | --| -- | --|\n  | **Length1** |\t0.194879 |\t0.220131 |\n  | **Length2** |\t0.195497 |\t0.220829 |\n  | **Length3** |\t0.198097 |\t0.223766 |\n  | **Height** |\t0.116893 |\t0.132040 |\n  | **Width** |\t0.179920 |\t0.203233 |\n\n  ```python\n  #using the same dataframe\n\n  groups = [[\"Length1\",\"Length2\",\"Length3\"],[\"Height\",\"Width\"]]\n\n  shapley_r2.owen_decomposition(df.iloc[:,1:], groups)\n  ```\n\n\n\n  | | owen_values | contribution | group_owen |\n  | --- | --- | --- | --- |\n  | **Length1** |\t0.157523 | 0.177934 | b1 |\n  | **Length2** |\t0.158178 | 0.178674 | b1 |\n  | **Length3** |\t0.160276 | 0.181045 | b1 |\n  | **Height** |\t0.141092 | 0.159374 | b2 |\n  | **Width** |\t0.268218 | 0.302972 | b2 |\n\n\n  | | owen_values | contribution |\n  | -- | -- | -- |                         \n  | **b1** | 0.475977 | 0.537653 |\n  | **b2** | 0.409309 | 0.462347 |\n\n  ```python\n  # if the species are included as categorical variables\n\n  from sklearn.preprocessing import OneHotEncoder\n\n  enc = OneHotEncoder(handle_unknown=\"ignore\")\n  encti = enc.fit_transform(df[[\"Species\"]]).toarray()\n\n  df2 = pandas.concat([pandas.DataFrame(encti,columns=[\"Species\"+str(n) for n in range(len(encti[0]+1))]),df.iloc[:,1:]],axis=1)\n  shapley_r2.shapley_decomposition(df2, force=True) # as the number of variables bigger than 10, force=True\n\n  groups=[[\"Species0\",\"Species1\",\"Species2\",\"Species3\",\"Species4\",\"Species5\",\"Species6\"],[\"Length1\",\"Length2\",\"Length3\"],[\"Height\",\"Width\"]]\n\n  shapley_r2.owen_decomposition(df2, groups) #no need for force as the number of groups does not exceed 10\n  ```\n\n[^1]: https://www.rand.org/content/dam/rand/pubs/papers/2021/P295.pdf\n[^2]: https://datatopics.worldbank.org/jobsdiagnostics/jobs-tools.html\n[^3]: https://www.scitepress.org/papers/2017/61137/\n[^4]: https://www.kaggle.com/datasets/aungpyaeap/fish-market?resource=download\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/canitez01/shapley_decomposition",
    "keywords": "python,data analysis,descriptive analysis,shapley values,owen values,decomposition",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "shapley-decomposition",
    "package_url": "https://pypi.org/project/shapley-decomposition/",
    "platform": null,
    "project_url": "https://pypi.org/project/shapley-decomposition/",
    "project_urls": {
      "Homepage": "https://github.com/canitez01/shapley_decomposition"
    },
    "release_url": "https://pypi.org/project/shapley-decomposition/0.0.1/",
    "requires_dist": [
      "pandas (>=1.1)",
      "numpy (>=1.3)",
      "scikit-learn (>=0.24)",
      "pytest (>=6.2.4) ; extra == 'dev'"
    ],
    "requires_python": "",
    "summary": "Decomposition using shapley values",
    "version": "0.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16668420,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "101e48c6ad74bfd8b7645fdb8606d4d0b45c5b86ab16b034f74e61660fc2dd5a",
          "md5": "72d6458aa4e7cc4c97bec2cad34ada76",
          "sha256": "f3ee94dc2858648af3bb0b0223ff1b2642b032367e9d09914d783e790dd8d529"
        },
        "downloads": -1,
        "filename": "shapley_decomposition-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "72d6458aa4e7cc4c97bec2cad34ada76",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 16915,
        "upload_time": "2023-02-02T16:25:33",
        "upload_time_iso_8601": "2023-02-02T16:25:33.227724Z",
        "url": "https://files.pythonhosted.org/packages/10/1e/48c6ad74bfd8b7645fdb8606d4d0b45c5b86ab16b034f74e61660fc2dd5a/shapley_decomposition-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f2b0ee152872339bef0213e3e693fd1faf1e9a709e2dbb42207ccacb56e9c8fc",
          "md5": "030b644455431049f70f6fc1b3035ec0",
          "sha256": "3da71c1a0e2db25314e82105c3ffdf22505ccd825b228afa7a601681f02c1bd2"
        },
        "downloads": -1,
        "filename": "shapley_decomposition-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "030b644455431049f70f6fc1b3035ec0",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 18422,
        "upload_time": "2023-02-02T16:25:35",
        "upload_time_iso_8601": "2023-02-02T16:25:35.613129Z",
        "url": "https://files.pythonhosted.org/packages/f2/b0/ee152872339bef0213e3e693fd1faf1e9a709e2dbb42207ccacb56e9c8fc/shapley_decomposition-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "101e48c6ad74bfd8b7645fdb8606d4d0b45c5b86ab16b034f74e61660fc2dd5a",
        "md5": "72d6458aa4e7cc4c97bec2cad34ada76",
        "sha256": "f3ee94dc2858648af3bb0b0223ff1b2642b032367e9d09914d783e790dd8d529"
      },
      "downloads": -1,
      "filename": "shapley_decomposition-0.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "72d6458aa4e7cc4c97bec2cad34ada76",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 16915,
      "upload_time": "2023-02-02T16:25:33",
      "upload_time_iso_8601": "2023-02-02T16:25:33.227724Z",
      "url": "https://files.pythonhosted.org/packages/10/1e/48c6ad74bfd8b7645fdb8606d4d0b45c5b86ab16b034f74e61660fc2dd5a/shapley_decomposition-0.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "f2b0ee152872339bef0213e3e693fd1faf1e9a709e2dbb42207ccacb56e9c8fc",
        "md5": "030b644455431049f70f6fc1b3035ec0",
        "sha256": "3da71c1a0e2db25314e82105c3ffdf22505ccd825b228afa7a601681f02c1bd2"
      },
      "downloads": -1,
      "filename": "shapley_decomposition-0.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "030b644455431049f70f6fc1b3035ec0",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 18422,
      "upload_time": "2023-02-02T16:25:35",
      "upload_time_iso_8601": "2023-02-02T16:25:35.613129Z",
      "url": "https://files.pythonhosted.org/packages/f2/b0/ee152872339bef0213e3e693fd1faf1e9a709e2dbb42207ccacb56e9c8fc/shapley_decomposition-0.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}