{
  "info": {
    "author": "Abdullah Al Imran",
    "author_email": "abdalimran@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# PyKoTokenizer\nPyKoTokenizer is a Korean text tokenizer for Korean Natural Language Processing tasks. It includes deep learning (RNN) model-based word tokenizers as well as morphological analyzer based word tokenizers for Korean language.\n\n## Segmentation of Korean Words\nWritten Korean texts do employ white space characters. However, more often than not,\nKorean words occur in a text concatenated immediately to adjacent words without\nan intervening space character. This low degree of separation of words from\neach other in writing is due somewhat to an abundance of what linguists call \"endoclitics\" \nin the language.\n\nAs the language has been subjected to principled and rigorous study for a few\ndecades, the issue of which strings of sounds, or letters, are words and which are\nnot, has been settled among a small group of selected linguists. This kind of\nadvancement has not been propagated to the general public yet, and nlp\nengineers working on Korean cannot but make do with whatever inconsistent\ngrammars they happen to have access to. Thus, a major source of difficulty in\ndeveloping competent Korean text processors has been, and still is, the notion of a word\nas the smallest syntactic unit.\n\n## How to install\nBefore using this package please make sure you have the following dependencies installed in your system.\n* **Python >= 3.6**\n* **numpy >= 1.19.0**\n* **pandas >= 1.1.5**\n* **tensorflow >= 2.6.2**\n* **h5py >= 3.1.0**\n* **konlpy >= 0.5.2**\n\nUse the following command to install the package:\n```python\npip install pykotokenizer\n```\n\n## How to Use\n\n## Model-based Tokenizers\nBelow, we show examples of using model-based tokenizers.\n\n### Using KoTokenizer\n\n```python\nfrom pykotokenizer import KoTokenizer\n\ntokenizer = KoTokenizer()\n\nkorean_text = \"김형호영화시장분석가는'1987'의네이버영화정보네티즌10점평에서언급된단어들을지난해12월27일부터올해1월10일까지통계프로그램R과KoNLP패키지로텍스트마이닝하여분석했다.\"\n\ntokenizer(korean_text)\n```\n\n**Output:**\n```\n\"김 형호 영화 시장 분석가 는 ' 1987 ' 의 네이버 영화 정보 네티즌 10 점평 에서 언급 된 단어 들 을 지난 해 12 월 27 일 부터 올해 1 월 10 일 까지 통계 프로그램 R 과 KoNLP 패키지 로 텍스트 마이닝 하여 분석 했다 .\"\n```\n\n### Using KoSpacing\n\n```python\nfrom pykotokenizer import KoSpacing\n\nspacing = KoSpacing()\n\nkorean_text = \"김형호영화시장분석가는'1987'의네이버영화정보네티즌10점평에서언급된단어들을지난해12월27일부터올해1월10일까지통계프로그램R과KoNLP패키지로텍스트마이닝하여분석했다.\"\n\nspacing(korean_text)\n```\n\n**Output:**\n```\n\"김형호 영화시장 분석가는 '1987'의 네이버 영화 정보 네티즌 10점 평에서 언급된 단어들을 지난해 12월 27일부터 올해 1월 10일까지 통계 프로그램 R과 KoNLP 패키지로 텍스트마이닝하여 분석했다.\"\n```\n\n## Morphological analyzer based Tokenizers\n\nBelow, we show examples of using morphological analyzer based tokenizers. These tokenizers has ***dependency*** on **[KoNLPy](https://konlpy.org/en/latest/)**. So, please install KoNLPy before using these. To install KoNLPy please visit this link - [https://konlpy.org/en/latest/install/](https://konlpy.org/en/latest/install/) and follow the procedure. KoNLPy requires Java in your system.\n\n### Using KoKkma\n\n```python\nfrom pykotokenizer import KoKkma\n\nkokkma = KoKkma()\n\nkorean_text = \"김형호영화시장분석가는'1987'의네이버영화정보네티즌10점평에서언급된단어들을지난해12월27일부터올해1월10일까지통계프로그램R과KoNLP패키지로텍스트마이닝하여분석했다.\"\n\nkokkma(korean_text)\n```\n\n**Output:**\n```\n\"김 형 호 영화 시장 분석가 는 ' 1987 ' 의 네이버 영화 정보 네티즌 10 점 평 에서 언급 되 ㄴ 단어 들 을 지난해 12 월 27 일 부터 올해 1 월 10 일 까지 통계 프로그램 R 과 KoNLP 패키지 로 텍스트 마이닝 하 여 분석 하 었 다 .\"\n```\n\n### Using KoKomoran\n\n```python\nfrom pykotokenizer import KoKomoran\n\nkokomoran = KoKomoran()\n\nkorean_text = \"김형호영화시장분석가는'1987'의네이버영화정보네티즌10점평에서언급된단어들을지난해12월27일부터올해1월10일까지통계프로그램R과KoNLP패키지로텍스트마이닝하여분석했다.\"\n\nkokomoran(korean_text)\n```\n\n**Output:**\n```\n\"김형호 영화 시장 분석가 는 ' 1987 ' 의 네이버 영화 정보 네티즌 10 점 평 에서 언급 되 ㄴ 단어 들 을 지난해 12월 27 일 부터 올해 1월 10 일 까지 통계 프로그램 R 과 KoNLP 패키지 로 텍스트 마 이닝 하 아 분석 하 았 다 .\"\n```\n\n## Credits\nThis package is a revamped and customized version of the following two sources:\n* KoTokenizer: https://pypi.org/project/hangul-korean/\n* KoSpacing: https://github.com/haven-jeon/PyKoSpacing\n* KoNLPy: https://konlpy.org/en/latest/\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/abdalimran/pykotokenizer",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "pykotokenizer",
    "package_url": "https://pypi.org/project/pykotokenizer/",
    "platform": "",
    "project_url": "https://pypi.org/project/pykotokenizer/",
    "project_urls": {
      "Bug Tracker": "https://github.com/pypa/pykotokenizer/issues",
      "Homepage": "https://github.com/abdalimran/pykotokenizer"
    },
    "release_url": "https://pypi.org/project/pykotokenizer/0.0.3/",
    "requires_dist": null,
    "requires_python": "<3.9,>=3.6",
    "summary": "Model-based Korean Text Tokenizer in Python",
    "version": "0.0.3",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12425072,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6159d583599835531cdc4cb387c68532beb3543642d3e39e5bfb0577cee306ce",
          "md5": "4c094142f035fe7f02d28ab968f9fddc",
          "sha256": "6813f34d149e2d77c51df3f53f18ab3f9fd05d8a2bc19f0851e59769435e9833"
        },
        "downloads": -1,
        "filename": "pykotokenizer-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "4c094142f035fe7f02d28ab968f9fddc",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": "<3.9,>=3.7",
        "size": 11323075,
        "upload_time": "2021-12-14T14:32:26",
        "upload_time_iso_8601": "2021-12-14T14:32:26.061142Z",
        "url": "https://files.pythonhosted.org/packages/61/59/d583599835531cdc4cb387c68532beb3543642d3e39e5bfb0577cee306ce/pykotokenizer-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f022328499cefbcfc205654e0d51a3b7676a699268a5444641b97171b92f7649",
          "md5": "9e41bfe63bdbec6a65491ce9326a6bfe",
          "sha256": "7d4d1071a4a305e5600683670071af26577856da118be0209c6e8fc0d9371ec6"
        },
        "downloads": -1,
        "filename": "pykotokenizer-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "9e41bfe63bdbec6a65491ce9326a6bfe",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": "<3.9,>=3.7",
        "size": 11317638,
        "upload_time": "2021-12-14T14:32:30",
        "upload_time_iso_8601": "2021-12-14T14:32:30.160830Z",
        "url": "https://files.pythonhosted.org/packages/f0/22/328499cefbcfc205654e0d51a3b7676a699268a5444641b97171b92f7649/pykotokenizer-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "26a09423e1f1348f50357297a363a499eebfc37945a5b29d2f6ef5a707734ada",
          "md5": "0937da595b1d5a098da4516ffffad72d",
          "sha256": "0ee06322920f3769dcb563a809579cb8875b7a0871d8d1f1ea7d49bff90e20d6"
        },
        "downloads": -1,
        "filename": "pykotokenizer-0.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0937da595b1d5a098da4516ffffad72d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": "<3.9,>=3.6",
        "size": 11323067,
        "upload_time": "2021-12-21T06:32:50",
        "upload_time_iso_8601": "2021-12-21T06:32:50.642828Z",
        "url": "https://files.pythonhosted.org/packages/26/a0/9423e1f1348f50357297a363a499eebfc37945a5b29d2f6ef5a707734ada/pykotokenizer-0.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "79d91384a7baf7c02f83c1569a1d5767020654b5a27a5f51e66a29f3d7c13e4a",
          "md5": "a813e7e79409370fb8c51c781effee01",
          "sha256": "752cb23ea25988e5e1cb2ecc3324e0a0d16452e775a0479804dd7e6fa74df78b"
        },
        "downloads": -1,
        "filename": "pykotokenizer-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "a813e7e79409370fb8c51c781effee01",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": "<3.9,>=3.6",
        "size": 11316615,
        "upload_time": "2021-12-21T06:32:54",
        "upload_time_iso_8601": "2021-12-21T06:32:54.898128Z",
        "url": "https://files.pythonhosted.org/packages/79/d9/1384a7baf7c02f83c1569a1d5767020654b5a27a5f51e66a29f3d7c13e4a/pykotokenizer-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3b51c94b1251fe8786644242a5b766724620778c6d0e9d6355095676e6468a00",
          "md5": "73c773b9b583948b9116e3c3fc51c7c1",
          "sha256": "4e20e6d0afe168530102b005973f0e78a4385abd4c9d6bc9a4713baadd0a7dc1"
        },
        "downloads": -1,
        "filename": "pykotokenizer-0.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "73c773b9b583948b9116e3c3fc51c7c1",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": "<3.9,>=3.6",
        "size": 11325642,
        "upload_time": "2021-12-28T19:34:55",
        "upload_time_iso_8601": "2021-12-28T19:34:55.852799Z",
        "url": "https://files.pythonhosted.org/packages/3b/51/c94b1251fe8786644242a5b766724620778c6d0e9d6355095676e6468a00/pykotokenizer-0.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3b2e121126022e2f5f857609dcb5963290ccbb3844f6fc6c083a071a9c3ed305",
          "md5": "317894e4b7e6381375b9ed326e7b3c99",
          "sha256": "da787f7be36c50b459b6735a3fc76a63bbb68f093ddbf25b534bce0ec5efddd1"
        },
        "downloads": -1,
        "filename": "pykotokenizer-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "317894e4b7e6381375b9ed326e7b3c99",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": "<3.9,>=3.6",
        "size": 11318177,
        "upload_time": "2021-12-28T19:34:59",
        "upload_time_iso_8601": "2021-12-28T19:34:59.763523Z",
        "url": "https://files.pythonhosted.org/packages/3b/2e/121126022e2f5f857609dcb5963290ccbb3844f6fc6c083a071a9c3ed305/pykotokenizer-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "3b51c94b1251fe8786644242a5b766724620778c6d0e9d6355095676e6468a00",
        "md5": "73c773b9b583948b9116e3c3fc51c7c1",
        "sha256": "4e20e6d0afe168530102b005973f0e78a4385abd4c9d6bc9a4713baadd0a7dc1"
      },
      "downloads": -1,
      "filename": "pykotokenizer-0.0.3-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "73c773b9b583948b9116e3c3fc51c7c1",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": "<3.9,>=3.6",
      "size": 11325642,
      "upload_time": "2021-12-28T19:34:55",
      "upload_time_iso_8601": "2021-12-28T19:34:55.852799Z",
      "url": "https://files.pythonhosted.org/packages/3b/51/c94b1251fe8786644242a5b766724620778c6d0e9d6355095676e6468a00/pykotokenizer-0.0.3-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "3b2e121126022e2f5f857609dcb5963290ccbb3844f6fc6c083a071a9c3ed305",
        "md5": "317894e4b7e6381375b9ed326e7b3c99",
        "sha256": "da787f7be36c50b459b6735a3fc76a63bbb68f093ddbf25b534bce0ec5efddd1"
      },
      "downloads": -1,
      "filename": "pykotokenizer-0.0.3.tar.gz",
      "has_sig": false,
      "md5_digest": "317894e4b7e6381375b9ed326e7b3c99",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": "<3.9,>=3.6",
      "size": 11318177,
      "upload_time": "2021-12-28T19:34:59",
      "upload_time_iso_8601": "2021-12-28T19:34:59.763523Z",
      "url": "https://files.pythonhosted.org/packages/3b/2e/121126022e2f5f857609dcb5963290ccbb3844f6fc6c083a071a9c3ed305/pykotokenizer-0.0.3.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}