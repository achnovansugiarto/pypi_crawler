{
  "info": {
    "author": "Ailln",
    "author_email": "kinggreenhall@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Simple Jieba\n\n[![Pypi](https://img.shields.io/pypi/v/simjb.svg)](https://pypi.org/project/simjb/)\n[![MIT License](https://img.shields.io/badge/license-MIT-green.svg)](https://github.com/Ailln/simple-jieba/blob/master/LICENSE)\n[![stars](https://img.shields.io/github/stars/Ailln/simple-jieba.svg)](https://github.com/Ailln/simple-jieba/stargazers)\n\n✂️ 用 [100](simjb/token.py) 行实现简单版本的 [jieba](https://github.com/fxsjy/jieba) 分词。\n\n> 新版本而外增加了 `add_word` 和 `del_word` 方法，用于添加和删除词频字典中的词，因此总体行数略超 100。\n\n## 1 快速上手\n\n### 1.1 安装\n\n```bash\npip install simjb\n\n# 或者\ngit clone https://github.com/Ailln/simple-jieba.git\ncd simple-jieba && python setup.py install\n```\n\n### 1.2 分词\n\n```python\nfrom simjb import cut\n\nresult = cut(\"为中华之崛起而读书！\")\n# result: ['为', '中华', '之', '崛起', '而', '读书', '！']\n```\n\n### 1.3 添加词\n\n```python\nfrom simjb import cut, add_word\n\nadd_word(\"中华之\")\nresult = cut(\"为中华之崛起而读书！\")\n# result: ['为', '中华之', '崛起', '而', '读书', '！']\n```\n\n### 1.4 删除词\n\n```python\nfrom simjb import cut, del_word\n\ndel_word(\"读书\")\nresult = cut(\"为中华之崛起而读书！\")\n# result: ['为', '中华', '崛起', '而', '读'， '书', '！']\n```\n\n## 2 性能对比\n\n由于该简单版本代码只实现了 jieba 分词的核心功能，可以预期的结果是：**分词正确率下降，分词速度上升。**\n\n我使用了 [bakeoff2005](http://sighan.cs.uchicago.edu/bakeoff2005/) 的数据集中的 `Peking University` 训练集和\n`Microsoft Research` 训练集进行性能对比，得到的结果如下：\n\n> 测试设备：MacBook Pro (13-inch, M1, 2020)\n\n| Peking University(pku) |       正确率（正确词数/所有词数）        |      速度（所有词数/花费时间）       |\n|:----------------------:|:---------------------------:|:------------------------:|\n|         jieba          |   78.54% (871705/1109949)   |   172k (1109949/6.44s)   |\n|         simjb          | **80.58%** (894347/1109949) | **184k** (1109949/6.02s) |\n\n\n| Microsoft Research(msr) |        正确率（正确词数/所有词数）        |       速度（所有词数/花费时间）       |\n|:-----------------------:|:----------------------------:|:-------------------------:|\n|          jieba          |   80.60% (1908851/2368422)   |   217k (2368422/10.92s)   |\n|          simjb          | **81.61%** (1932899/2368422) | **218k** (2368422/10.88s) |\n\n然鹅，这两份不同数据集的结果都有些诡异！居然在分词正确率和分词速度都有小幅度提升～\n\n我最初从 jieba 的源码中整理出这部分的核心代码，仅仅是希望后人想要学习时，有一份简明易懂地学习资料。从上文的结果来看，这个简单版本似乎是可用的！\n\n具体的测试方法见[这里](test/README.md)。（欢迎大家可以做更多的测试来打脸，哈哈哈）\n\n## 3 源码解析\n\n![](./simjb/src/simple-jieba_flow_v1_20191016-0347.png)\n\n### 3.1 根据正则规则切分出区块\n\n首先将输入的句子以规则进行分割，其中标点符号会被独立的切分开来，得到了一个切分区块的列表。\n\n```python\nimport re\n\n\nclass Tokenizer(object):\n    def __init__(self) -> None:\n        self.normal_ptn = re.compile(r\"([\\u4E00-\\u9FD5a-zA-Z\\d+#&._%-]+)\", re.U)\n\n    def cut(self, sentence: str) -> list:\n        if type(sentence) != str:\n            raise TypeError(\"sentence must be str!\")\n\n        # 以非标点符号分割句子\n        text_blocks = self.normal_ptn.split(sentence)\n        cut_result = []\n        for index, block in enumerate(text_blocks):\n            if len(block) > 0:\n                if index % 2 == 0:\n                    cut_result.append(block)\n                else:\n                    cut_result.extend(self.__cut_util(block))\n        return cut_result\n```\n\n例子：`快看，是武汉市长江大桥！` => `[\"快看\", \"，\", \"是武汉市长江大桥\", \"！\"]`\n\n下一步，我们会将文本区块 `快看` 和 `是武汉市长江大桥` 进行处理。\n\n### 3.2 根据词典生成有向无环图\n\n对于每一个区块，使用一个巨大的词频词典对其进行切分，构建出一个有向无环图。 词典的格式如下所示：\n\n```\nAT&T 3 nz\nB超 3 n\nc# 3 nz\nC# 3 nz\nc++ 3 nz\n...\n```\n\n词典每一行有三个值，分别为：`词 词频 词性`。 \n\n> 词典数据来自 jieba 分词，据说是统计了 98 年人民日报语料和一些小说的分词结果所得。\n\n原来的词典不能直接使用，需要先进行预处理，得到一个包含「词」和「词前缀」的词频字典。\n词前缀就是一个词前面的字构成词，比如我们有个词叫`长江大桥`，那么它的词前缀就是`长`，`长江`，`长江大`。\n添加它为了在下文中匹配词语的时候可以匹配到长词，如果没有前缀，那么`长江大桥`就只能被匹配成`长江`和`大桥`。\n前缀的词频被设置为 0，这样它只起到匹配作用，不会影响分词结果。 下面的代码描述了详细的构建词频字典的过程：\n\n```python\nfrom time import perf_counter\nfrom pkg_resources import resource_stream\n\n\nclass Tokenizer(object):\n    def __init__(self) -> None:\n        self.dict_path = [\"simjb\", \"src/dict.txt\"]\n        self.freq_dict = {}\n        self.freq_total = 0\n\n        self.__init_freq_dict()\n\n    def __init_freq_dict(self) -> None:\n        start_time = perf_counter()\n        with resource_stream(*self.dict_path) as stream:\n            for line in stream.readlines():\n                word, freq, _ = line.decode(\"utf-8\").split(\" \")\n                self.freq_dict[word] = int(freq)\n                self.freq_total += int(freq)\n                self.__add_prefix_word_to_dict(word)\n        end_time = perf_counter()\n        print(f\"load freq_dict cost: {end_time - start_time:.2f}s\")\n\n    def __add_prefix_word_to_dict(self, word: str) -> None:\n        for word_index in range(len(word)-1):\n            word_frag = word[:word_index + 1]\n            if word_frag not in self.freq_dict.keys():\n                self.freq_dict[word_frag] = 0\n```\n\n现在我们要来构建「有向无环图」`Directed Acyclic Graphs` 了：\n\n```python\nfrom typing import Dict, List\n\n\nclass Tokenizer(object):\n    def __init__(self) -> None:\n        self.freq_dict = {}\n        self.freq_total = 0\n\n    def __build_dag(self, sentence: str) -> Dict[int, List[int]]:\n        dag = {}\n        sen_len = len(sentence)\n        for i in range(sen_len):\n            temp_list = []\n            j = i\n            fragment = sentence[i]\n            while j < sen_len and fragment in self.freq_dict.keys():\n                if self.freq_dict[fragment] > 0:\n                    temp_list.append(j)\n                j += 1\n                fragment = sentence[i:j+1]\n            if not temp_list:\n                temp_list.append(i)\n            dag[i] = temp_list\n        return dag\n```\n\n从头遍历所有可能的词（上文中的前缀的作用就在这里），如果它在词频字典中就记录下来，最后构成了一个有向无环图。\n\n有向无环图的存储形式是 `Dict[int, List[int]]`，每个索引位置存储的是以当前字开始可能形成的词语索引，举例如下：\n\n```python\n# 快看\n{0: [0], 1: [1]}\n# 是武汉市长江大桥\n{0: [0], 1: [1, 2, 3], 2: [2], 3: [3, 4], 4: [4, 5, 7], 5: [5], 6: [6, 7], 7: [7]}\n```\n\n我们来看第 2 句的第 5 个元素 `4: [4, 5, 7]`，它表示的是 `(4, 4) (4, 5) (4, 7)`，即 `长 长江 长江大桥`。\n\n### 3.3 使用动态规划求解最大概率路径\n\n有了区块的有向无环图之后，我们就要想办法求解出最大概率路径了。\n\n使用动态规划反向递推出基于词频的最大切分组合，具体的公式和详细过程参考文末给出资料。代码如下：\n\n```python\nimport math\nfrom typing import Dict\n\nclass Tokenizer(object):\n    def __init__(self) -> None:\n        self.freq_dict = {}\n        self.freq_total = 0\n\n    def __calc_route_with_dp(self, sentence: str) -> Dict[int, tuple]:\n        dag = self.__build_dag(sentence)\n        sen_len = len(sentence)\n        route = {sen_len: (0, 0)}\n        # 取 log 防止数值下溢；取 log(1)=0 解决 log(0) 无定义问题\n        log_total = math.log(self.freq_total or 1)\n        for sen_index in reversed(range(sen_len)):\n            freq_score = {}\n            for word_index in dag[sen_index]:\n                word_freq = self.freq_dict.get(sentence[sen_index:word_index + 1])\n                freq_score[word_index] = round(math.log(word_freq or 1) - log_total + route[word_index+1][1], 4)\n            route[sen_index] = max(freq_score.items(), key=lambda x: x[1])\n        return route\n```\n\n> trick: 使用 log 进行计算来防止 python 产生数值下溢。\n\n最大切分组合的结果如下：\n\n```python\n# 是武汉市长江大桥\n{8: (0, 0), 7: (7, -8.8638), 6: (7, -9.8135), 5: (5, -19.0118), 4: (7, -9.6536), 3: (3, -16.965), 2: (2, -25.7804), 1: (3, -17.5314), 0: (0, -21.8544)}\n```\n\n### 3.4 合并所有区块切分结果\n\n得到区块的切分后，还需要处理一些细节，比如英语单词，应该将连续英文字母作为一个整体的英文单词切分。\n\n```python\nimport re\n\n\nclass Tokenizer(object):\n    def __init__(self) -> None:\n        self.en_ptn = re.compile(r\"[a-zA-Z\\d]\", re.U)\n\n    def __cut_util(self, sentence: str) -> list:\n        route = self.__calc_route_with_dp(sentence)\n        result = []\n        word_buf = \"\"\n        word_index = 0\n        while word_index < len(sentence):\n            word_index_end = route[word_index][0] + 1\n            word = sentence[word_index:word_index_end]\n            # 匹配出英文\n            if self.en_ptn.match(word) and len(word) == 1:\n                word_buf += word\n                word_index = word_index_end\n            else:\n                if word_buf:\n                    result.append(word_buf)\n                    word_buf = \"\"\n                else:\n                    result.append(word)\n                    word_index = word_index_end\n        if word_buf:\n            result.append(word_buf)\n        return result\n```\n\n最后把所有结果汇总，分词就完成了！\n\n```python\n# 输入\n\"快看，是武汉市长江大桥！\"\n# 输出\n[\"快\", \"看\", \"，\", \"是\", \"武汉市\", \"长江大桥\", \"！\"]\n```\n\njieba 分词本身要比这个更复杂，除了上文用到的技术，它还使用了许多其他技术，比如使用 HMM 对「未登录词」进行处理，感兴趣的可以去阅读[源码](https://github.com/fxsjy/jieba)。\n\n## 4 许可证\n\n[![](https://award.dovolopor.com?lt=License&rt=MIT&rbc=green)](./LICENSE)\n\n## 5 参考资料\n\n- [jieba源码解析（一）：分词之前](https://www.cnblogs.com/aloiswei/p/11507763.html)\n- [jieba源码解析（二）：jieba.cut](https://www.cnblogs.com/aloiswei/p/11567616.html)\n- [中文分词工具探析（二）：Jieba](https://www.cnblogs.com/en-heng/p/6234006.html)\n- [结巴分词2--基于前缀词典及动态规划实现分词](https://www.cnblogs.com/zhbzz2007/p/6084196.html)\n- [不用Trie，减少内存加快速度；优化代码细节](https://github.com/fxsjy/jieba/pull/187)\n- [中文分词相关资料](https://github.com/Ailln/nlp-roadmap#1-%E5%88%86%E8%AF%8D-word-segmentation)\n- [如何从模板创建仓库？](https://help.github.com/cn/articles/creating-a-repository-from-a-template)\n- [如何发布自己的包到 pypi ？](https://www.v2ai.cn/python/2018/07/30/PY-1.html)\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/Ailln/simple-jieba",
    "keywords": "",
    "license": "MIT License",
    "maintainer": "",
    "maintainer_email": "",
    "name": "simjb",
    "package_url": "https://pypi.org/project/simjb/",
    "platform": null,
    "project_url": "https://pypi.org/project/simjb/",
    "project_urls": {
      "Homepage": "https://github.com/Ailln/simple-jieba"
    },
    "release_url": "https://pypi.org/project/simjb/0.2.0/",
    "requires_dist": [
      "setuptools (>=40.6.3)"
    ],
    "requires_python": ">=3.6",
    "summary": "A simple version of jieba.",
    "version": "0.2.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14384902,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "940fa4b0ed3db98ae73aebfcaa0abd792280955d2e85fa014718a488e4316972",
          "md5": "3ab7414c3f7afde3b3c09dd1a45d82f5",
          "sha256": "975b8d28e6580bac90f74abc32cc3ba85b401b48d2495d6497ec9a98dfd97ddb"
        },
        "downloads": -1,
        "filename": "simjb-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "3ab7414c3f7afde3b3c09dd1a45d82f5",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 7325,
        "upload_time": "2019-10-15T21:57:16",
        "upload_time_iso_8601": "2019-10-15T21:57:16.386709Z",
        "url": "https://files.pythonhosted.org/packages/94/0f/a4b0ed3db98ae73aebfcaa0abd792280955d2e85fa014718a488e4316972/simjb-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "598d1019ee17daf8e62798b2d556e16e2fb816f2357e41119be4f927c7fe1317",
          "md5": "8aa68652f7abed6b34459e4a69506efe",
          "sha256": "180a7c878c17008f4bcdd7aa71ee5e5686ef85a1db36315183e9ee4cdfa5ac25"
        },
        "downloads": -1,
        "filename": "simjb-0.1.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "8aa68652f7abed6b34459e4a69506efe",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 1995888,
        "upload_time": "2020-09-23T22:36:39",
        "upload_time_iso_8601": "2020-09-23T22:36:39.776355Z",
        "url": "https://files.pythonhosted.org/packages/59/8d/1019ee17daf8e62798b2d556e16e2fb816f2357e41119be4f927c7fe1317/simjb-0.1.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4f33e4bd095bb19bd1b09a31ce3b83c27a93373ada8fa70e98747055dfbe3c3a",
          "md5": "2d1777ee9fa0d8d870a27300104a0484",
          "sha256": "3918e47be5c4f464343ded5ad0aee53fd83ff08de24a45afe0c581efe1307632"
        },
        "downloads": -1,
        "filename": "simjb-0.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "2d1777ee9fa0d8d870a27300104a0484",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 2000842,
        "upload_time": "2020-09-23T22:36:42",
        "upload_time_iso_8601": "2020-09-23T22:36:42.215468Z",
        "url": "https://files.pythonhosted.org/packages/4f/33/e4bd095bb19bd1b09a31ce3b83c27a93373ada8fa70e98747055dfbe3c3a/simjb-0.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "877eb4e0decc337de034eca30597f3e18f9670f284fe6b993f216a1886d1d821",
          "md5": "0b2585615fc666e77733a4cbc82e0729",
          "sha256": "edff617a94e1a0d4e9888e5d10abe96a70789a77f02735f1225c452d356275e9"
        },
        "downloads": -1,
        "filename": "simjb-0.2.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0b2585615fc666e77733a4cbc82e0729",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 1997035,
        "upload_time": "2022-07-09T15:03:40",
        "upload_time_iso_8601": "2022-07-09T15:03:40.910033Z",
        "url": "https://files.pythonhosted.org/packages/87/7e/b4e0decc337de034eca30597f3e18f9670f284fe6b993f216a1886d1d821/simjb-0.2.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "38d36e36ec41215485f05c7816fa482c6415dd3e107d03b6186f73785907e540",
          "md5": "2b8620b2dcfc240e130e3efb7ca27096",
          "sha256": "f54f8f6bea69331d7ff2c91e3ba9992c7ae8fb33efe6a897ab85c4fc70c845f5"
        },
        "downloads": -1,
        "filename": "simjb-0.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "2b8620b2dcfc240e130e3efb7ca27096",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 2001946,
        "upload_time": "2022-07-09T15:03:44",
        "upload_time_iso_8601": "2022-07-09T15:03:44.562279Z",
        "url": "https://files.pythonhosted.org/packages/38/d3/6e36ec41215485f05c7816fa482c6415dd3e107d03b6186f73785907e540/simjb-0.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "877eb4e0decc337de034eca30597f3e18f9670f284fe6b993f216a1886d1d821",
        "md5": "0b2585615fc666e77733a4cbc82e0729",
        "sha256": "edff617a94e1a0d4e9888e5d10abe96a70789a77f02735f1225c452d356275e9"
      },
      "downloads": -1,
      "filename": "simjb-0.2.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "0b2585615fc666e77733a4cbc82e0729",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 1997035,
      "upload_time": "2022-07-09T15:03:40",
      "upload_time_iso_8601": "2022-07-09T15:03:40.910033Z",
      "url": "https://files.pythonhosted.org/packages/87/7e/b4e0decc337de034eca30597f3e18f9670f284fe6b993f216a1886d1d821/simjb-0.2.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "38d36e36ec41215485f05c7816fa482c6415dd3e107d03b6186f73785907e540",
        "md5": "2b8620b2dcfc240e130e3efb7ca27096",
        "sha256": "f54f8f6bea69331d7ff2c91e3ba9992c7ae8fb33efe6a897ab85c4fc70c845f5"
      },
      "downloads": -1,
      "filename": "simjb-0.2.0.tar.gz",
      "has_sig": false,
      "md5_digest": "2b8620b2dcfc240e130e3efb7ca27096",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 2001946,
      "upload_time": "2022-07-09T15:03:44",
      "upload_time_iso_8601": "2022-07-09T15:03:44.562279Z",
      "url": "https://files.pythonhosted.org/packages/38/d3/6e36ec41215485f05c7816fa482c6415dd3e107d03b6186f73785907e540/simjb-0.2.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}