{
  "info": {
    "author": "Kamil Smolak",
    "author_email": "kamil.smolak@upwr.edu.pl",
    "bugtrack_url": null,
    "classifiers": [
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# HuMobi\r\n \r\n ## Table of contents\r\n* [General info](#General-info)\r\n* [Installing HuMobi](#Installing-HuMobi)\r\n* [Data reading](#Data-reading)\r\n* [Data preprocessing](#Data-preprocessing)\r\n* [Metrics](#Metrics)\r\n* [Data generation routines](#Data-generation-routines)\r\n* [Next location predictions](#Next-location-predictions)\r\n* [Paper: Explaining human mobility predictions through pattern matching algorithm](#Paper-Explaining-human-mobility-predictions-through-pattern-matching-algorithm)\r\n* [Known issues](#Known-issues)\r\n \r\n## General Info\r\nThis is the HuMobi library. It is a dedicated Python library for human mobility data processing, which mostly extends Pandas\r\nDataFrames and Geopandas GeoDataFrames and facilitates operating on a very specific data structure of individual mobility trajectories. Below you will find info on how to install HuMobi library on your computer and a set of demos covering most of the library functionalities.\r\n\r\nThis library is mainly devoted to processing individual mobility trajectories and focuses on human mobility prediction and modelling. Initially, it was implemented during PhD studies of Kamil Smolak, a PhD candidate at the Wrocław University of Environmental and Life Sciences.\r\n\r\nIf you use this library please cite the below work:\r\n```\r\nSmolak, K., Siła-Nowicka, K., Delvenne, J. C., Wierzbiński, M., & Rohm, W. (2021). The impact of human mobility data scales and processing on movement predictability. Scientific Reports, 11(1), 1-10.\r\n```\r\n\r\nIt is a constantly expanding project, and new functionalities are added as you read that text. Currently, I am implementing human mobility models - these are not functioning properly yet and are not covered in the documentation.\r\n\r\nCurrent functionalities of HuMobi library cover:\r\n* The basic class of TrajectoriesFrame which is used to load and store the mobility data. You will find that class in the\r\n`structures` directory;\r\n* Measures for individual and collective statistics in human mobility;\r\n* Useful functions for data processing;\r\n* Next-place and next time-bin prediction methods, including Markov Chains, deep-learning and shallow-learning models;\r\n* Preprocessing methods for data aggregation and filtering;\r\n* Other useful tools for data processing.\r\n\r\n## Installing HuMobi\r\n\r\nTo install HuMobi and all dependencies simply use:\r\n\r\n```\r\n$ pip install HuMobi\r\n```\r\n\r\nSetting a proper working environment for this library can be tricky through the combination of specific libraries. Therefore, setting up virtualenv is recommended. Required dependencies for this library are:\r\n* pandas >=1.1.5\r\n* geopandas >=0.8.1\r\n* tqdm >=4.59.0\r\n* scipy >=1.5.2\r\n* numpy >=0.19.5\r\n* scikit-learn >=0.23.2\r\n* biopython >=1.78\r\n* shapely >=1.7.1\r\n* numba >= 0.51.2\r\n* tensorflow-gpu >= 2.4.1\r\n* geofeather >=0.3.0\r\n\r\n# Getting started\r\n\r\nBelow are the demos of various functionalities of this library. These cover most of the abilities of the current status of HuMobi. Note that this will be expanded in the future - including this documentation. For the method attributes and functions see the documentation in the HTML folder.\r\n\r\nSome methods and functions need some time to execute. The `tqdm` library enables progress bars, which will estimate the remaining computation time.\r\n\r\n## Data reading\r\n\r\nData loading, storing and reading are done within a special TrajectoriesFrame class. This is a pandas DataFrame-based data structure with MultiIndex, which consists of user id (upper level) and timestamp (lower level). Also, it contains a `geometry` column, identical to the GeoPandas GeoDataFrame geometry column.\r\n\r\nFirst, let's import the necessary modules. We will import the trajectory module from humobi.structures and also pandas for the sake of this demo.\r\n```\r\nfrom humobi.structures import trajectory as tr\r\nimport pandas as pd\r\n```\r\n\r\n`TrajectoriesFrame` class is available in the trajectory module. `TrajectoriesFrame` is a smart class that will adjust to many data loading methods. For example, we can read a file given the path to it:\r\n```\r\n# READ FROM PATH\r\nin_path = \"\"\"brightkite_sample.tsv\"\"\" # PATH TO FILE\r\ndf = tr.TrajectoriesFrame(in_path, {'names': ['id', 'datetime', 'lat', 'lon', 'place'], 'delimiter': '\\t',\r\n                                    'crs': 4326})  # LOAD DATA\r\n```\r\nAs you can see:\r\n* the first positional argument is a file path.\r\n* Apart from it, `**kwargs` of `pd.read_csv` function can be given. \r\n \r\nAdditionally, `TrajectoriesFrame` accepts two metadata arguments:\r\n* `crs` - Coordinate Reference System number according to EPSG classification \r\n* `geom_cols` - indicating two columns with coordinates.\r\n\r\nNote that it is important to provide the `delimiter` keyword when it is other than a comma. \r\nGiving column names is useful, but `TrajectoriesFrame` will try to figure out which column has a timestamp and which has coordinates. However, to avoid errors provide columns with a timestamp as `time` or `datetime` and columns with geometry as `lat` and `lon`.\r\n\r\nThe first two lines of the file will look like that:\r\n```\r\n                                  id  ...                     geometry\r\nuser_id datetime                       ...                             \r\n0       2010-10-17 01:48:53+00:00   0  ...  POINT (-104.99251 39.74765)\r\n        2010-10-17 01:54:32+00:00   0  ...  POINT (-104.99251 39.74765)\r\n```\r\n> **_NOTE:_**  In debugging mode in some IDEs you can access a DataFrame view of TrajectoriesFrame through the `_base_class_view` protected attribute.\r\n\r\nAnother way to obtain a `TrajectoriesFrame` instance is to convert a standard DataFrame to it:\r\n```\r\n# CONVERT FROM DATAFRAME\r\ndf = pd.read_csv(in_path, names=['id', 'datetime', 'lat', 'lon', 'place'], delimiter='\\t')  # LOAD DATA USING pd.read_csv\r\ndf = tr.TrajectoriesFrame(df)  # CONVERT TO TRAJECTORIESFRAME\r\n```\r\n\r\nReading without column names will work, but is not recommended:\r\n```\r\n# CONVERT FROM DATAFRAME WITHOUT COLUMNS NAMES (NOT RECOMMENDED)\r\ndf = pd.read_csv(in_path, delimiter='\\t', header=None)  # LOAD WITHOUT INFO ABOUT COLUMNS\r\ndf = tr.TrajectoriesFrame(df)\r\n```\r\n\r\nAlso, you can read the file from geofeather file:\r\n```\r\n# READ FROM GEOFEATHER\r\ndf.from_geofeather(\"feather_path\")\r\n```\r\n\r\n`TrajectoriesFrame` can be saved to CSV, geofeather or Shapefile using the below methods:\r\n```\r\ndf.to_csv(\"csv_path\")\r\ndf.to_geofeather(\"feather_path\")\r\ndf.to_shapefile(\"shape_path\")\r\n```\r\n\r\n`TrajectoriesFrame` overrides also the data spatial transformation method `to_crs`, which can be used to reproject the data. To do that, simply call:\r\n```\r\ndf.to_csr(dest_crs = 3857, cur_crs = 4326)\r\n```\r\nThis will reproject TrajectoriesFrame from `EPSG:4326` to `EPSG:3857`. If `cur_crs` is not given, TrajectoriesFrame will used `crs` metadata.\r\n\r\n> **_NOTE:_**  `TrajectoriesFrame` is based on pandas DataFrame, hence it is possible to apply any pandas function - such as filtering and data selecting - on it.\r\n\r\n## Data preprocessing\r\n\r\nRaw movement data should be preprocessed to remove noise, remove unimportant stops and extract necessary information. HuMobi library offers methods for data preprocessing, analyses, and filtering. This process consists of two steps. First, noisy data is removed and stop locations are detected. In the second step, stop locations are aggregated into stay-regions and converted to movement sequence. For methodology details see publication:\r\n```\r\nSmolak, K., Siła-Nowicka, K., Delvenne, J. C., Wierzbiński, M., & Rohm, W. (2021). The impact of human mobility data scales and processing on movement predictability. Scientific Reports, 11(1), 1-10.\r\n```\r\n\r\nData preprocessing tools are available in the `preprocessing` module. Some statistics and data compression methods are available in the `tools` module.\r\nFirst, let's import necessary functions and read our data example saved with the `to_csv` method from the previous subsection of this readme.\r\n```\r\nfrom humobi.structures import trajectory as tr\r\nfrom humobi.preprocessing.filters import stop_detection\r\nfrom humobi.tools.user_statistics import *\r\nfrom humobi.tools.processing import start_end\r\n\r\nin_path = \"\"\"converted_sample.csv\"\"\"\r\ndf_sel = tr.TrajectoriesFrame(in_path, {'crs': 4326})  # ALREADY CONVERTED - WITH GEOMETRY AND MULTIINDEX, SAVED TO CSV (SEE data_reading.py demo)\r\ngeom_cols = df_sel.geom_cols  # STORE GEOMETRY COLUMN\r\ncrs = df_sel.crs  # STORE CRS\r\n```\r\n\r\n### Data (users) selection\r\n\r\nFirst, let's cover how to select particular movement trajectories to be able to filter the data later. `TrajectoriesFrame` offers the `uloc` method which allows you to select a user or users using their id. For example, let's select user of id `0`:\r\n```\r\none_user = df_sel.uloc(0)\r\n```\r\n\r\nTo get a list of all user ids, use `get_users()` method:\r\n```\r\nusers_list = df_sel.get_users()  # LIST OF ALL IDS\r\n```\r\n\r\nThen, passing that list to `uloc` will result in selecting all users from the data (so the result will be unchanged):\r\n```\r\nmany_users = df_sel.uloc(users_list)\r\n```\r\n\r\nYou can use standard `loc` and `iloc` pandas commends, too.\r\n\r\n### Users statistics\r\n\r\nMany data selection methods are based on choosing users who have certain global statistics, like data completeness or trajectory duration. Module `tools.user_statistics` contains some metrics which can be used to calculate them. All results are returned as pandas `Series` with user id as index and statistics as values. Available statistics include:\r\n\r\n#### Fraction of empty records\r\nThe fraction of empty records is expressed in a given temporal resolution. This is calculated globally - you can limit the timeframe using selection methods or use it together with `pd.rolling` to have a moving value.\r\n```\r\nfrac = fraction_of_empty_records(df_sel, resolution='1H')  # FRACTION OF MISSING RECORDS\r\n```\r\n#### Total number of records\r\nA total number of records:\r\n```\r\ncount = count_records(df_sel)  # TOTAL NUMBER OF RECORDS\r\n```\r\n#### Total number of records calculated per time frame\r\nA total number of records calculated per time frame:\r\n```\r\ncount_per_time_frame = count_records_per_time_frame(df_sel, resolution='1D')  # TOTAL NUMBER OF RECORDS PER TIME FRAME\r\n```\r\n\r\nThe total length of trajectories expressed in a time unit. `count_empty` determines whether empty records should be considered or excluded. If excluded, the value will be decreased by the number of empty records timeframes.\r\n```\r\ntrajectories_duration = user_trajectories_duration(df_sel, resolution='1H', count_empty=False)  # TOTAL LENGTH OF TRAJECTORIES\r\n```\r\n#### The number of consecutive records\r\nThe highest number of consecutive records expressed in the given time unit.\r\n```\r\nconsecutive = consecutive_record(df_sel, resolution='1H')\r\n```\r\n\r\n#### Filtering with statistics\r\nNow, let's see how to use these statistics to filter some data. For example, we want to select only users with a fraction of empty records lower than 90%, whose trajectories are longer than 6 days and have at least 100 records of data. We will use sets intersection to find all the users that satisfy all these three requirements.\r\n```\r\n# FILTRATION WITH USER STATISTICS\r\nfrac = fraction_of_empty_records(df_sel, '1H')\r\nlevel1 = set(frac[frac < 0.9].index)  # FRACTION OF MISSING RECORDS < 0.6\r\n\r\ntraj_dur = user_trajectories_duration(df_sel, '1D')\r\nlevel2 = set(traj_dur[traj_dur > 6].index)  # MORE THAN 6 DAYS OF DATA\r\n\r\ncounted_records = count_records(df_sel)\r\nlevel3 = set(counted_records[counted_records >= 100].index)  # AT LEAST 100 RECORDS IN TOTAL\r\n\r\n# INDICES SELECTION\r\nselection = level1.intersection(level2)\r\nselection = selection.intersection(level3)\r\ndf_sel = df_sel.uloc(list(selection))  # USER FILTRATION WITH ULOC METHOD\r\n\r\n# SORT BY TIMESTAMP (JUST IN CASE)\r\ndf_sel = df_sel.sort_index(level=1)\r\n\r\n# REREAD STRUCTURE\r\ndf_sel = tr.TrajectoriesFrame(df_sel, {'crs': crs, 'geom_cols': geom_cols})\r\n```\r\n\r\n### Stop detection \r\n\r\nStop detection algorithm is simple to use. `preprocessing.filters.stop_detection` function allows to quickly detect stay-points, by simply:\r\n```\r\nstops = stop_detection(df_sel, distance_condition=300, time_condition='10min')\r\n```\r\nFor details on the algorithm see mentioned publication. There are two parameters to adjust:\r\n* `distance_condition` (here it is 300 metres) - always expressed in metres\r\n* `time_condition` (here it is 10 minutes).\r\n\r\nFunction temporally converts data to `EPSG:3857`. Note that it uses multithreading, so having multiple cores helps.\r\n\r\n`stop_detection` function adds a new boolean column `is_stop`. You can filter only stops using:\r\n```\r\ndf_sel = stops[stops['is_stop'] == True]\r\n```\r\n\r\nIt is also good to drop duplicates, as sometimes these may be created:\r\n```\r\ndf_sel = df_sel.drop_duplicates()\r\n```\r\n\r\nFurthermore, to decrease data size, let's compress stops to a single row of data by adding `start` and `end` times of visits in these locations. To do that, call:\r\n```\r\ndf_sel = start_end(df_sel)\r\n```\r\nFinally, resulting `TrajectoriesFrame` will look like this:\r\n```\r\n                                 id        lat         lon                                     place                     geometry  is_stop                      date                     start                       end\r\nuser_id datetime                                                                                                                                                                                                          \r\n0       2009-05-29 00:04:23+00:00   0  39.759608 -104.984862          6346d66a3aa011de83f8003048c0801e  POINT (-104.98486 39.75961)     True 2009-05-29 00:04:23+00:00 2009-05-29 00:04:23+00:00 2009-05-29 02:29:20+00:00\r\n        2009-05-30 02:12:30+00:00   0  39.890648 -105.068872          dd7cd3d264c2d063832db506fba8bf79  POINT (-105.06887 39.89065)     True 2009-05-30 02:12:30+00:00 2009-05-30 02:12:30+00:00 2009-05-30 07:28:16+00:00\r\n```\r\n\r\n### Data aggregation\r\n\r\nAfter stay-point detection, data can be finally converted to movement sequences by, first, spatial (stay-regions detection), and then, temporal aggregation. \r\n\r\nStay-regions detection can be done using various approaches, the most commonly used are the grid-based approach or clustering method. Also, there are two approaches to temporal aggregation: next time-bin and next place. Let's see how to convert our data to various movement sequences. First, let's import necessary functions.\r\n```\r\nfrom humobi.structures import trajectory as tr\r\nfrom humobi.preprocessing.temporal_aggregation import TemporalAggregator\r\nfrom humobi.preprocessing.spatial_aggregation import GridAggregation, ClusteringAggregator, LayerAggregation\r\nfrom humobi.preprocessing.filters import next_location_sequence\r\n```\r\n#### Spatial aggregation\r\n\r\nSpatial aggregation (stay-regions detection) should be done first. This process will add a new `labels` column which will identify unique stay-regions.\r\n\r\n> **__NOTE:__** If you already have aggregated data and want to add unique labels per each geometry only, use `to_labels()` function from the `humobi.misc.utils` module.\r\n\r\n`humobi.preprocessing.spatial_aggregation` module offers following spatial aggregation classes:\r\n* `GridAggregator`, \r\n* `ClusteringAggregator`, \r\n* `LayerAggregator` \r\n\r\nTo perform aggregation, an aggregator class has to be defined first. When an aggregator is created, the data and arguments controlling aggregation behaviour are passed first. After that, the `aggregate` method can be called to perform data aggregation.\r\n\r\n##### Grid Aggregator\r\n\r\n`GridAggregator` is a quick data aggregation to a regular grid of defined resolution. There are some implemented behaviours. For example, you can pass only the `resolution` argument, and the grid will fit into the data extent.\r\n```\r\ngird_resolution = 1000  # DEFINE SPATIAL UNIT (GRID)\r\ngrid_agg = GridAggregation(gird_resolution)  # DEFINE GRID AGGREGATION ALGORITHM\r\ndf_sel_grid = grid_agg.aggregate(df_sel, parralel=False)  # CALL AGGREGATION\r\n```\r\n* When you want to set the grid extent yourself, you can pass `x_min`, `x_max`, `y_min`, `y_max` parameters to set the extent of the aggregation grid. \r\n* You can pass an `origin` parameter to tell whether the grid should be centred at the data.\r\n* `parallel` parameter of the `aggregate()` method calls multithread processing, but this is not necessarily faster than the single-core method, due to its overheads.\r\n\r\n##### Clustering Aggregator\r\n\r\n`ClusteringAggregator` allows you to pass any scikit-learn clustering algorithm to perform clusterisation of the stay-points. In the below example we use the `DBSCAN` class to perform clustering:\r\n```\r\nfrom sklearn.cluster import DBSCAN\r\neps = 300  # DEFINE SPATIAL UNIT\r\nmin_pts = 2  # OTHER HYPERPARAMETERS\r\nclust_agg = ClusteringAggregator(DBSCAN, **{\"eps\": eps, \"min_samples\": min_pts})  # DEFINE SPATIAL AGGREGATION ALGORITHM\r\ndf_sel_dbscan = clust_agg.aggregate(df_sel)  # SPATIAL AGGREGATION CALL\r\n```\r\nAs you see, all the arguments for the clustering method can be passed as `**kwargs`. This class uses multithreading implemented within the scikit-learn library.\r\n\r\n##### Layer Aggregator\r\n\r\nThe third class is `LayerAggregator`. This class uses an external file to perform aggregation. Its functionality is based on the GeoPandas function of spatial join. To perform it, just call:\r\n```\r\nlayer_agg = LayerAggregator('path_to_outer_layer',**kwargs)\r\ndf_sel_layer = layer_agg.aggregate(df_sel)\r\n```\r\n\r\n#### Temporal aggregation\r\n\r\nTemporal aggregation functionalities are available in the `humobi.preprocessing.temporal_aggregation` module, which contains the `TemporalAggregator` class. There are two approaches to temporal aggregation: next time-bin and next place.\r\n\r\n##### Next time-bin\r\nThe next time-bin approach converts sequences of visited locations into evenly spaced time-bins. To perform the next time-bin aggregation, simply instantiate TemporalAggregator class and pass time unit which will be used to perform aggregation:\r\n```\r\ntime_unit = '1H'  # DEFINE TEMPORAL UNIT\r\ntime_agg = TemporalAggregator(time_unit)  # DEFINE TEMPORAL AGGREGATION ALGORITHM\r\n````\r\nIn the above example, we chose time-bins to have an hourly resolution. Now we can call the aggregation of our data:\r\n```\r\ndf_sel_dbscan_time = time_agg.aggregate(df_sel_dbscan, parallel=True) \r\n```\r\nThe above line of code will perform the time-bin aggregation according to the methodology presented in the literature. Three cases may occur:\r\n* No data was found for the time-bin -> In that case, the time-bin will be empty\r\n* There was more than one stay-region visited during a time-bin -> Stay-region, where the user spent more time, is selected\r\n* There was more than one stay-region visited during a time-bin and the user spent an identical amount of time in them -> Stay-region, where the user spent more time in the past, is selected\r\n\r\n* Temporal aggregation can be run using the `parallel` setting, which is a bit faster than its single-core variant. \r\n* `aggregate()` method has a `fill_method` argument, which can be set to `ffill` or `bfill` to fill missing data or a `drop_empty` argument, which can be used to remove missing time-bins.\r\n\r\nTemporal aggregation is computationally heavy and can take some time.\r\n\r\n> **_NOTE:_** Time-bins always start at midnight.\r\n\r\n##### Next place\r\n\r\nIn the next place approach, all the consecutive records of visits in the same stay-region are removed. This can be done using `next_location_sequence` function from the `humobi.preprocessing.filters` module.\r\n```\r\ndf_sel_time_seq = next_location_sequence(df_sel_dbscan_time)  # CREATE NEXT LOCATION SEQUENCES\r\n```\r\n\r\n## Metrics\r\n\r\nOnce processed, various metrics can be calculated on movement sequences. We divide them into individual and collective. Individual metrics are calculated separately for each id in the `TrajectoriesFrame`. Collective metrics are presented in the form of distributions or are referred to as stay-regions.\r\n\r\nFirst, let's import all the metrics:\r\n```\r\nfrom humobi.structures import trajectory as tr\r\nfrom humobi.measures.individual import *\r\nfrom humobi.measures.collective import *\r\n```\r\n\r\nWe assume our processed data are stored under the `df_sel` variable.\r\n\r\n### Individual metrics\r\n\r\n#### Number of distinct locations\r\n\r\nThis metric calculates the number of distinct locations visited by each individual. To calculate it, call `num_of_distinct_locations()` function from `humobi.measures.individual` module.\r\n```\r\ndistinct_total = num_of_distinct_locations(df_sel)\r\n```\r\n\r\n#### Visitation frequency\r\n\r\nThis metric calculates the frequency of visits in each stay-region visited by users. Execute:\r\n```\r\nvfreq = visitation_frequency(df_sel)\r\n```\r\n\r\n#### Number of distinct locations over time\r\n\r\nThis is a variant of the number of distinct locations metric and calculates the number of distinct locations visited from the start of the movement trajectory at each time step. This function requires two additional parameters. \r\n* `resolution` determines the size of a time step. \r\n* `reaggregate` is a boolean parameter, which will run TemporalAggregator to convert data into a new time-bin size if needed. \r\n\r\nExecution:\r\n```\r\ndistinct_over_time = distinct_locations_over_time(df_sel, resolution='1H', reaggregate=False)\r\n```\r\n\r\n#### Jump lengths\r\nThis function calculates the length of all trips between locations in the movement sequence.\r\n```\r\njump = jump_lengths(df_sel)\r\n```\r\n\r\n#### Nonzero trips\r\nThis function calculates the number of all trips (which covered distance > 0)\r\n```\r\ntrips = nonzero_trips(df_sel)\r\n```\r\n\r\n#### Self-transtition\r\nThis function calculates the number of situations when the user stayed in the same location for the next time-bin (in the next place it will always be equal to 0).\r\n```\r\nst = self_transitions(df_sel)\r\n```\r\n\r\n#### Waiting times\r\nThis function calculates waiting times for each transition in `TrajectoriesFrame`. \r\n* This function requires `time_unit` to be specified, which will control the unit in which waiting time will be expressed.\r\n```\r\nwt = waiting_times(df_sel, time_unit = 'H')\r\n```\r\n\r\n#### Center of mass\r\nCalculates a centre of mass for each user's trajectory.\r\n```\r\nmc = center_of_mass(df_sel)\r\n```\r\n\r\n#### Radius of gyration\r\nCalculates radii of gyration for each user. \r\n* Optionally `time_evolution` argument can be used to express this metric evolution in time.\r\n```\r\nrog = radius_of_gyration(df_sel, time_evolution=False)\r\nrog_time = radius_of_gyration(df_sel, time_evolution=True)\r\n```\r\n\r\n#### Mean square displacement\r\nCalculates mean square displacements (MSD) for each user. \r\n* Optionally `time_evolution` argument can be used to express this metric evolution in time.\r\n```\r\nmsd = mean_square_displacement(df_sel, time_evolution=False)\r\nmsd_time = mean_square_displacement(df_sel, time_evolution=True)\r\n```\r\n* The `from_center` argument can be used to calculate MSD in reference to the centre of trajectory mass (if False it is calculated from the first point). \r\n* `reference_locs` can be passed to determine custom reference points for each person. This has to be a series with users' id as index and point geometry as values.\r\n\r\n#### Return time\r\nCalculates return times for each unique location in each user's trajectory. \r\n* `time_unit` specifies the unit in which return times will be expressed.\r\n```\r\nrt = return_time(df_sel, time_unit = 'H')\r\n```\r\nOptionally this metric can be calculated in relation to places, which will express how long it takes any person to return to that location on average. This will produce a DataFrame with the count of returns and mean time to return.\r\n```\r\nrt_place = return_time(df_sel, by_place=True)\r\n```\r\n\r\n#### Random entropy and predictability\r\nCalculates random entropy for each user in TrajectoriesFrame using equation defined in \r\n`Song, C., Qu, Z., Blumm, N., & Barabási, A. L. (2010). Limits of predictability in human mobility. Science, 327(5968), 1018–1021. https://doi.org/10.1126/science.1177170`. Similarly, predictability is calculated using entropy and Fano's inequality as presented in the above paper.\r\n```\r\nran_ent = random_entropy(df_sel)\r\nrandom_pred = random_predictability(df_sel)\r\n```\r\n> **__NOTE:__** `random_predictability` returns entropy and predictability in a DataFrame.\r\n\r\n#### Uncorrelated entropy and predictability\r\nCalculates uncorrelated entropy for each user in TrajectoriesFrame using equation defined in \r\n`Song, C., Qu, Z., Blumm, N., & Barabási, A. L. (2010). Limits of predictability in human mobility. Science, 327(5968), 1018–1021. https://doi.org/10.1126/science.1177170`. Similarly, predictability is calculated using entropy and Fano's inequality as presented in the above paper.\r\n```\r\nunc_ent = unc_entropy(df_sel)\r\nunc_pred = unc_predictability(df_sel)\r\n```\r\n> **__NOTE:__** `unc_predictability` returns entropy and predictability in a DataFrame.\r\n\r\n#### Real entropy and predictability\r\nCalculates real entropy for each user in TrajectoriesFrame using the Lempel-Ziv compression algorithm, using approach defined in\r\n`Song, C., Qu, Z., Blumm, N., & Barabási, A. L. (2010). Limits of predictability in human mobility. Science, 327(5968), 1018–1021. https://doi.org/10.1126/science.1177170`, and corrected using findings from\r\n`Xu, P., Yin, L., Yue, Z., & Zhou, T. (2019). On predictability of time series. Physica A: Statistical Mechanics and Its Applications, 523, 345–351. https://doi.org/10.1016/j.physa.2019.02.006`\r\nand\r\n`Smolak, K., Siła-Nowicka, K., Delvenne, J. C., Wierzbiński, M., & Rohm, W. (2021). The impact of human mobility data scales and processing on movement predictability. Scientific Reports, 11(1), 1–10. https://doi.org/10.1038/s41598-021-94102-x`\r\nAdditionally, when fraction of missing data is higher than 15%, entropy is estimated using an approach from `Ikanovic, E. L., & Mollgaard, A. (2017). An alternative approach to the limits of predictability in human mobility. EPJ Data Science, 6(1). https://doi.org/10.1140/epjds/s13688-017-0107-7`.\r\n\r\nPredictability is calculated using entropy and Fano's inequality as presented in the Song et al. (2010) paper.\r\n\r\n> **__NOTE:__** Real entropy __cannot__ be calculated when fraction of missing data is >90%.\r\n\r\n> **__NOTE:__** These function are using GPU to perform calculations. Be sure to have CUDA configured on your machine. CPU variant is not accessible, because calculations on the CPU take an unreasonable long time to execute.\r\n```\r\nreal_ent = real_entropy(df_sel)\r\nreal_pred = real_predictability(df_sel)\r\n```\r\n> **__NOTE:__** `real_predictability` returns entropy and predictability in a DataFrame.\r\n\r\n#### Stationarity\r\nCalculates the stationarity according to Teixeira et al. (2019) as the average stay length in the location. See `Teixeira, D., Almeida, J., Viana, A. C., Teixeira, D., Almeida, J., Carneiro, A., … Viana, A. C. (2021). Understanding routine impact on the predictability estimation of human mobility To cite this version : HAL Id : hal-03128624 Understanding routine impact on the predictability estimation of human mobility.` for details.\r\n\r\n```\r\nstat = stationarity(df_sel)\r\n```\r\n\r\n#### Regularity\r\nCalculates the regularity according to Teixeira et al. (2019) as the ratio of sequence length and the number of unique symbols. See `Teixeira, D., Almeida, J., Viana, A. C., Teixeira, D., Almeida, J., Carneiro, A., … Viana, A. C. (2021). Understanding routine impact on the predictability estimation of human mobility To cite this version : HAL Id : hal-03128624 Understanding routine impact on the predictability estimation of human mobility.` for details.\r\n\r\n```\r\nregul = regularity(df_sel)\r\n```\r\n\r\n### Collective metrics\r\n\r\n#### Distribution of travelling distances\r\nCalculates the distribution of travelling distances for each user. Two mutually exclusive parameters can be defined:\r\n* `bin_size` - determines the size of a bin in an output histogram,\r\n* `n_bins` - determines the number of bins in an output histogram. (default = 20)\r\n```\r\ndist = dist_travelling_distance(df_sel)\r\n```\r\n\r\n#### Pairwise comparison of flows\r\nCalculates the number of flows for each aggregation cell. \r\n* Using `flows_type` - `all` flows, only `incoming`, or only `outgoing` flows can be counted.\r\n```\r\npairwise_flows = flows(df_sel, flows_type='all')\r\n```\r\n\r\n## Data generation routines\r\n\r\nGenerating synthetic data might be useful to verify algorithms and assumptions on sequences of known statistical properties. There are few generation routines available in the `humobi.misc.generators` module. The output is a DataFrame with `labels` columns, which identify unique locations:\r\n```\r\n                             labels\r\nuser_id datetime                                                      \r\n0       1970-01-01 00:00:00       0 \r\n        1970-01-01 01:00:00       0\r\n```\r\n\r\nEach routine has available parameters:\r\n* `users` - which is the number of unique sequences to generate\r\n* `places` - which is the size of vocabulary for generation\r\nFixed values or a list of values can be passed to these arguments. If the latter is used, each sequence will be generated using a randomly picked value from the list. Some routines have more parameters. See details below.\r\n\r\nTo import module:\r\n```\r\nfrom src.humobi.misc.generators import *\r\n```\r\n\r\n### Random sequences\r\n\r\n\r\nRandom sequences, where each symbol is randomly generated from the available vocabulary. Additional `length` parameters can be determined. It can be a single value or a list of values to randomly pick from.\r\n```\r\nrandom_seq = random_sequences_generator(users=10, places=10, length=100)\r\n```\r\n\r\n### Deterministic sequences\r\n\r\nDeterministic sequences follow a series of incrementing symbols up to the size of the vocabulary. At the end of vocabulary, series are repeated. For example, when vocabulary size is 4, then sequence will follow routine `[0, 1, 2, 3, 0, 1, 2, 3, 1, ...]`. Additional `repeats` parameters can be determined. It can be a single value or a list of values to randomly pick from.\r\n```\r\ndeter_seq = deterministic_sequences_generator(users=10, places=10, repeats=10)\r\n```\r\n\r\n### Markovian sequences\r\n\r\nMarkovian sequences follow a deterministic sequence, but at each step with probability `prob`, a random symbol is inserted.\r\n```\r\nmarkovian_seq = markovian_sequences_generator(users=10, places=10, length=500, prob=.3)\r\n```\r\n### Exploratory sequences\r\nExploratory sequences generate a sequence of unique, non-repeating symbols.\r\n\r\n```\r\nex_seq = exploratory_sequences_generator(users=10, places=10)\r\n```\r\n### Self-transition sequences\r\nSelf-transitions sequences are similar to deterministic sequences, but each symbol is repeated multiple times before moving to the next one. The number of self-transitions repeating after each other is determined by the number of symbols and the length of the sequence.\r\n```\r\nst_seq = self_transitions_sequences_generator(users=10, places=10, length=100)\r\n```\r\n\r\n### Non-stationary sequences\r\nNon-stationary sequences generate symbols using `states`, where each state has its routine of symbols generation. Probabilities for each state are assigned randomly at the beginning of the process.\r\n```\r\nnon_st_seq = non_stationary_sequences_generator(users=10, places=10, states=5, length=100)\r\n```\r\n## Next location predictions\r\n\r\nFinally, let's do some predictions. There are multiple algorithms available, including:\r\n* Naive approaches\r\n* Markov chains\r\n* Shallow learning classification algorithms\r\n* Deep learning networks\r\n\r\nFirst, let's import the necessary modules:\r\n```\r\nfrom src.humobi.predictors.wrapper import *\r\nfrom src.humobi.predictors.deep import *\r\n```\r\n> **__NOTE:__** This module is under development, there are some still inconsistencies in the structure. This will be adjusted in the future, to facilitate pipeline creation.\r\n\r\n### Data split\r\n\r\nTo perform predictions, we need to split data into training and testing sets.  We will use the `Splitter` class from the `humobi.predictors.wrapper` module. This class allows splitting the whole TrajectoriesFrame at once by splitting each users' trajectory in the determined ratio (determined by the `split_ratio` argument which expresses the test set size). \r\nFor example, let's split generated Markovian sequences:\r\n```\r\nsplit = Splitter(markovian_seq, split_ratio=.2)\r\n```\r\nSplit data will be accessible as `split` instance attributes.\r\n* `split.data` gives access to the input data\r\n* `split.cv_data` yields a list of training-validation sets pairs. An additional parameter `n_splits` can be passed to the `Splitter`, which will generate more pairs of training-validation datasets pairs using the KFold approach. Each pair consists of training set features (index 0), training set labels (index 1), validation set features (index 2), and validation set labels (index 3).\r\n* `split.test_frame_X` gives access to the test set features\r\n* `split.text_frame_Y` gives access to the test set labels\r\n\r\n* a `horizon` parameter can be set on the `Splitter` class. If `horizon > 1` all the generated datasets of features (X sets) will contain additional columns with all previous time steps, up to the horizon length. Moreover, training/validation and testing sets will overlap with the `horizon` size.\r\n\r\nLet's assign our datasets to some variables:\r\n```\r\ntest_frame_X = data_splitter.test_frame_X\r\ntest_frame_Y = data_splitter.test_frame_Y\r\ncv_data = data_splitter.cv_data\r\n```\r\n\r\nOnce data is split, now we can make predictions.\r\n\r\n### TopLoc\r\n\r\nThe TopLoc algorithm is a naive algorithm adapted from `Cuttone, A., Lehmann, S., & González, M. C. (2018). Understanding predictability and exploration in human mobility. EPJ Data Science, 7(1). https://doi.org/10.1140/epjds/s13688-017-0129-1`. When doing prediction, it assumes that the next visited place is the most visited place in the training set. `TopLoc()` class is available in the `humobi.predictors.wrapper` module. To perform prediction on the datasets call:\r\n```\r\nTopLoc(train_data=cv_data, test_data=[data_splitter.test_frame_X, data_splitter.test_frame_Y]).predict()\r\n```\r\nCalling `predict()` will return predictions (DataFrame, where the first columns are test set labels and the second column are predictions) and the accuracy score.\r\n\r\n### MarkovChain\r\n\r\nN-th Markov Chain can be called through wrapper function `markov_wrapper`. This wrapper accepts the whole dataset at once and performs a data split inside.  Test-train ratio is defined by the `test_size` parameter. The order of the Markov Chain is defined by the `state_size` parameter. For example, to call 2nd-order Markov Chain, execute the following line:\r\n```\r\nMC2 = markov_wrapper(markovian_seq, test_size=.2, state_size=2)\r\n```\r\nAdditionally, this function accepts two arguments: `update` - if True, with each predicted symbol chain is rebuilt, and `online` - which if True, allows the algorithm to see the last `state_size` symbols from the test set when predicting. This function returns the prediction and the accuracy score.\r\n\r\n### Shallow learning methods\r\n\r\nIt is possible to use scikit-learn library classification methods to perform predictions. `humobi.predictors.wrapper` module allows to use `SKLearnPred()` class to apply any algorithm to perform the next location prediction. To do that, first, let's import a prediction algorithm:\r\n```\r\nfrom sklearn.ensemble import RandomForestClassifier\r\nclf = RandomForestClassifier\r\n```\r\nAfter we instantiate the `SKLearnPred` class in the following way:\r\n```\r\npredic = SKLearnPred(algorithm=clf, training_data=split.cv_data, test_data=[split.test_frame_X, split.test_frame_Y], param_dist={'n_estimators': [x for x in range(500, 5000, 500)], 'max_depth': [None, 2, 4, 6, 8]}, search_size=5, cv_size=5, parallel=False)\r\n```\r\n* The algorithm has to be passed as an `algorithm` argument. \r\n* `training_data` and `test_data` have to be passed from the `Splitter()` class.\r\n* `param_dist` allows passing a dictionary of candidate hyperparameters of prediction algorithms. These will be tested to find the best solution during RandomizedSearch with cross-validation. \r\n* The number of cross-validations is determined by the `cv_size` parameter.\r\n* The number of tested combinations is determined by the `search_size` parameter. As of now `parallel` computing is not possible.\r\n\r\nTo perform predictions, first, we need to train prediction algorithms. Calling\r\n```\r\npredic.learn()\r\n```\r\nwill train a set of algorithms, each for each trajectory in the dataset. Then calling\r\n```\r\npredic.test()\r\n```\r\nwill perform prediction on the test set. Accuracy can be accessed through `predic.scores` attributes, predictions can be accessed through `predic.predictions` attribute.\r\n\r\n### Deep learning methods\r\n\r\nAs of now, the HuMobi library offers two network architectures for mobility predictions. This will be extended in the future. These are single- and double-layer Gated Recurrent Unit (GRU) networks with embedding and dropout. These are accessible in the `humobi.predictors.deep` module.\r\nTo perform predictions with a deep learning network, first, call the `DeepPred` class. This class accepts the following arguments at initialisation:\r\n* `model` - to use single-layer GRU call `'GRU'`, to use double-layer GRU call `'GRU2'`\r\n* `data` - TrajectoriesFrame (not from Splitter)\r\n* `test_size` - size of the test set\r\n* `folds` - number of folds in cross-validation to use\r\n* `batch_size` - the size of batches for the network.\r\n* `embedding_dim` - the dimensionality of embedding vector fit at the first layer of the network\r\n* `rnn_units` - the number of neurons in the GRU layers\r\n\r\nExample of usage:\r\n```\r\nGRU = DeepPred(\"GRU\", markovian_seq, test_size=.2, folds=5, window_size=5, batch_size=50, embedding_dim=512, rnn_units=1024)\r\n```\r\nTo perform prediction, call:\r\n```\r\nGRU.learn_predict()\r\n```\r\nTo access predictions call `GRU.predictions`, to access accuracy scores call `GRU.scores`.\r\n\r\n## Paper: Explaining human mobility predictions through pattern matching algorithm\r\n\r\nPublication `Explaining human mobility predictions through a pattern matching algorithm` by `Kamil Smolak, Witold Rohm, and Katarzyna Siła-Nowicka` presents and evaluate five new metrics which measure the actual predictability of mobility data and explain the variability in accuracy of the actual predictions. These are:\r\n* Dense Repeatability (DR)\r\n* Sparse Repeatability (SR)\r\n* Equally Sparse Repeatability (ESR)\r\n* Global Alignment (GA)\r\n* Iterative Global Alignment (IGA)\r\n\r\nThese metrics are implemented within the HuMobi library and are available in the `humobi.measures.individual` module. Apart from the above metrics, all the works performed in this paper were done using this library. This includes data filtration and preprocessing (see [Data preprocessing](#Data-preprocessing)) some of the calculated metrics (especially real predictability, stationarity, and regularity, see [Metrics](#Metrics) for details). Predictions and their accuracy were done as shown in the [Next location predictions](#Next-location-predictions) section.\r\n\r\nThese metrics are based on the training and test sets. These can be achieved from `Splitter()`:\r\n```\r\ntraining = pd.concat([split.cv_data[0][0], split.cv_data[0][2]])\r\ntest = split.test_frame_X\r\n```\r\n\r\nAny of the above metrics can be simply calculated by passing `train_frame` and `test_frame` arguments:\r\n```\r\nDR = repeatability_dense(train_frame=X, test_frame=Y)\r\nSR = repeatability_sparse(train_frame=X, test_frame=Y)\r\nESR = repeatability_equally_sparse(train_frame=X, test_frame=Y)\r\nGA = global_alignment(train_frame=X, test_frame=Y)\r\nIGA = iterative_global_alignment(train_frame=X, test_frame=Y)\r\n```\r\nThis will return pd.Series with values calculated for each user in the data.\r\n\r\n## Known issues\r\n\r\nOne of the known issues is related to crs metadata setting. It may happen, that giving the `crs` argument to `TrajectoriesFrame` does not assign it to the dataset. This is a well known GeoPandas library and Anaconda issue. Proper setting of the proj4 library solves this problem.\r\n\r\nBased on Dorregaray's answer from here: [StackOverflow question](#https://stackoverflow.com/questions/55390492/runtimeerror-bno-arguments-in-initialization-list/58009620#58009620), a solution is to edit the path in the `datadir.py` file located in `...\\Anaconda3\\Lib\\site-packages\\pyproj`. It should renamed to `.../Anaconda3/Library/share`.\r\n\r\n\r\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/SmolakK/HuMobi",
    "keywords": "",
    "license": "BSD 3-Clause License",
    "maintainer": "",
    "maintainer_email": "",
    "name": "HuMobi",
    "package_url": "https://pypi.org/project/HuMobi/",
    "platform": null,
    "project_url": "https://pypi.org/project/HuMobi/",
    "project_urls": {
      "Bug Tracker": "https://github.com/SmolakK/HuMobi/issues",
      "Homepage": "https://github.com/SmolakK/HuMobi"
    },
    "release_url": "https://pypi.org/project/HuMobi/0.1.10/",
    "requires_dist": null,
    "requires_python": ">=3.7",
    "summary": "A library dedicated to human mobility data processing",
    "version": "0.1.10",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14329833,
  "releases": {
    "0.1.10": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "13b6d55bc26bb117bed815d8746de65b7484e1e073ab69367ce73d8591d928d4",
          "md5": "b6b33d9facac7a5e5122cfb49b20e100",
          "sha256": "f4b86b9909411bc4a427ee58faff1b84be2c955fdf8dea79190801cfa029af32"
        },
        "downloads": -1,
        "filename": "HuMobi-0.1.10.tar.gz",
        "has_sig": false,
        "md5_digest": "b6b33d9facac7a5e5122cfb49b20e100",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 76287,
        "upload_time": "2022-07-04T12:14:07",
        "upload_time_iso_8601": "2022-07-04T12:14:07.675563Z",
        "url": "https://files.pythonhosted.org/packages/13/b6/d55bc26bb117bed815d8746de65b7484e1e073ab69367ce73d8591d928d4/HuMobi-0.1.10.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b7b83957b750317646306cbec5e6fe554861e25e599883238dd9d6c292664657",
          "md5": "b1cfbf5439f3226091fa3767fd23a725",
          "sha256": "dc1c1d9e52586231fc99bcb261452b51f24f599574bd6e9e00042e0a0e506ac1"
        },
        "downloads": -1,
        "filename": "HuMobi-0.1.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "b1cfbf5439f3226091fa3767fd23a725",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 61893,
        "upload_time": "2022-04-19T08:00:58",
        "upload_time_iso_8601": "2022-04-19T08:00:58.880192Z",
        "url": "https://files.pythonhosted.org/packages/b7/b8/3957b750317646306cbec5e6fe554861e25e599883238dd9d6c292664657/HuMobi-0.1.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bbefda827a5568da684a2c05f2b0eb640f2e874dd0c358aff98c73f2f663a7b7",
          "md5": "b9e8d69628092231fa7bb12f96dee0ff",
          "sha256": "a048cc4357adea4e2d0a9366f5f58462ab63c7e81779bb85151617f3d6424d5c"
        },
        "downloads": -1,
        "filename": "HuMobi-0.1.4.tar.gz",
        "has_sig": false,
        "md5_digest": "b9e8d69628092231fa7bb12f96dee0ff",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 75542,
        "upload_time": "2022-04-19T08:01:00",
        "upload_time_iso_8601": "2022-04-19T08:01:00.820682Z",
        "url": "https://files.pythonhosted.org/packages/bb/ef/da827a5568da684a2c05f2b0eb640f2e874dd0c358aff98c73f2f663a7b7/HuMobi-0.1.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2d1593f8e4ad5dd9036073b06c28973e3ddd23e500520e2acf46cad49f7dbca4",
          "md5": "f9ed0518b2838940293eaafe4785fa50",
          "sha256": "2d13db31b0416d2a46c86fe938a08e625035e59c7c095ee6f0ba4e60920796c6"
        },
        "downloads": -1,
        "filename": "HuMobi-0.1.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f9ed0518b2838940293eaafe4785fa50",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 61846,
        "upload_time": "2022-04-25T18:04:02",
        "upload_time_iso_8601": "2022-04-25T18:04:02.388906Z",
        "url": "https://files.pythonhosted.org/packages/2d/15/93f8e4ad5dd9036073b06c28973e3ddd23e500520e2acf46cad49f7dbca4/HuMobi-0.1.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "62dd7fd08b9a7df6554a9a199f35c17f2eb21b22c56b7de9cade13db93163770",
          "md5": "ba07ffc8f5ca7e31a4646dce2e7618ec",
          "sha256": "e0915aab44f9b24d15e2bff0f1b0c345056841ce9580f37e30a6aeaf502b0f18"
        },
        "downloads": -1,
        "filename": "HuMobi-0.1.5.tar.gz",
        "has_sig": false,
        "md5_digest": "ba07ffc8f5ca7e31a4646dce2e7618ec",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 75602,
        "upload_time": "2022-04-25T18:04:04",
        "upload_time_iso_8601": "2022-04-25T18:04:04.312197Z",
        "url": "https://files.pythonhosted.org/packages/62/dd/7fd08b9a7df6554a9a199f35c17f2eb21b22c56b7de9cade13db93163770/HuMobi-0.1.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a16ae2f31b9f904f8a7cdfb6454506e08e6f6a801f330f9757690e2a3311227b",
          "md5": "8edc322f9023f5d7beff7447978066bb",
          "sha256": "b0582f2297b312b41e68aa56e5a9578ec93dd0b2c8c5fedf6ab96e9e13e1e981"
        },
        "downloads": -1,
        "filename": "HuMobi-0.1.6-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "8edc322f9023f5d7beff7447978066bb",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 62747,
        "upload_time": "2022-04-30T19:58:12",
        "upload_time_iso_8601": "2022-04-30T19:58:12.443318Z",
        "url": "https://files.pythonhosted.org/packages/a1/6a/e2f31b9f904f8a7cdfb6454506e08e6f6a801f330f9757690e2a3311227b/HuMobi-0.1.6-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3651f3ba0f4c18ff91d4c59127bf51329189a26dc2414f557bb0bdaaeee31934",
          "md5": "961cab3a6d562a30a1ff6cdec59d535e",
          "sha256": "7be8df58225e0ee2a861d0eb26b2a954969a396856877a860fdfa8659a5ddb23"
        },
        "downloads": -1,
        "filename": "HuMobi-0.1.6.tar.gz",
        "has_sig": false,
        "md5_digest": "961cab3a6d562a30a1ff6cdec59d535e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 75621,
        "upload_time": "2022-04-30T19:58:14",
        "upload_time_iso_8601": "2022-04-30T19:58:14.578216Z",
        "url": "https://files.pythonhosted.org/packages/36/51/f3ba0f4c18ff91d4c59127bf51329189a26dc2414f557bb0bdaaeee31934/HuMobi-0.1.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ab80d57563cb0ee6d582b47a06ef1b2b962a5de9c3c4f6a1815c512a62b1479f",
          "md5": "a15a4c7ca0bf466ce4bc0ee642805b8d",
          "sha256": "859b3cbfac5518da3ee12e01dd2bbdcce33e9b87d831d8c397395732201c54a6"
        },
        "downloads": -1,
        "filename": "HuMobi-0.1.7.tar.gz",
        "has_sig": false,
        "md5_digest": "a15a4c7ca0bf466ce4bc0ee642805b8d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 76231,
        "upload_time": "2022-07-04T09:30:00",
        "upload_time_iso_8601": "2022-07-04T09:30:00.811355Z",
        "url": "https://files.pythonhosted.org/packages/ab/80/d57563cb0ee6d582b47a06ef1b2b962a5de9c3c4f6a1815c512a62b1479f/HuMobi-0.1.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "774c807914adc517f5fc07c6c29badafd6eb97c8e720238287164658873bad73",
          "md5": "b2c6393dca506cc5e47e4b603904f64f",
          "sha256": "016276b3dee20df281622a0475bab04d1d63594b6b196f9c509d09417879eff3"
        },
        "downloads": -1,
        "filename": "HuMobi-0.1.8.tar.gz",
        "has_sig": false,
        "md5_digest": "b2c6393dca506cc5e47e4b603904f64f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 76263,
        "upload_time": "2022-07-04T11:19:33",
        "upload_time_iso_8601": "2022-07-04T11:19:33.436641Z",
        "url": "https://files.pythonhosted.org/packages/77/4c/807914adc517f5fc07c6c29badafd6eb97c8e720238287164658873bad73/HuMobi-0.1.8.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.9": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5e8e8fdb075b43bdfc9f08e68e0c6788c286f0f407479c1dd423c93d8a2c1cc6",
          "md5": "4555e41cd75af9139c05fca33cbc47da",
          "sha256": "f3d54c447db6a79da4cb7634199960b2665d976f9bc862c2d5513c34523dc012"
        },
        "downloads": -1,
        "filename": "HuMobi-0.1.9.tar.gz",
        "has_sig": false,
        "md5_digest": "4555e41cd75af9139c05fca33cbc47da",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 76302,
        "upload_time": "2022-07-04T11:25:01",
        "upload_time_iso_8601": "2022-07-04T11:25:01.627276Z",
        "url": "https://files.pythonhosted.org/packages/5e/8e/8fdb075b43bdfc9f08e68e0c6788c286f0f407479c1dd423c93d8a2c1cc6/HuMobi-0.1.9.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "13b6d55bc26bb117bed815d8746de65b7484e1e073ab69367ce73d8591d928d4",
        "md5": "b6b33d9facac7a5e5122cfb49b20e100",
        "sha256": "f4b86b9909411bc4a427ee58faff1b84be2c955fdf8dea79190801cfa029af32"
      },
      "downloads": -1,
      "filename": "HuMobi-0.1.10.tar.gz",
      "has_sig": false,
      "md5_digest": "b6b33d9facac7a5e5122cfb49b20e100",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 76287,
      "upload_time": "2022-07-04T12:14:07",
      "upload_time_iso_8601": "2022-07-04T12:14:07.675563Z",
      "url": "https://files.pythonhosted.org/packages/13/b6/d55bc26bb117bed815d8746de65b7484e1e073ab69367ce73d8591d928d4/HuMobi-0.1.10.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}