{
  "info": {
    "author": "Neelay Shah",
    "author_email": "nstraum1@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 2 - Pre-Alpha",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Natural Language :: English",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8"
    ],
    "description": "<h1 align=\"center\">VFormer</h1>\n<h3 align=\"center\">A modular PyTorch library for vision transformers models</h3>\n\n<div align='center'>\n\n[![Tests](https://github.com/SforAiDl/vformer/actions/workflows/package-test.yml/badge.svg)](https://github.com/SforAiDl/vformer/actions/workflows/package-test.yml)\n[![Docs](https://readthedocs.org/projects/vformer/badge/?version=latest)](https://vformer.readthedocs.io/en/latest/?badge=latest)\n[![codecov](https://codecov.io/gh/SforAiDl/vformer/branch/main/graph/badge.svg?token=5QKCZ67CM2)](https://codecov.io/gh/SforAiDl/vformer)\n[![Downloads](https://pepy.tech/badge/vformer)](https://pepy.tech/project/vformer)\n\n**[Documentation](https://vformer.readthedocs.io/en/latest/)**\n\n</div>\n\n## Library Features\n\n- Contains implementations of prominent ViT architectures broken down into modular components like encoder, attention mechanism, and decoder\n- Makes it easy to develop custom models by composing components of different architectures\n- Utilities for visualizing attention using techniques such as gradient rollout\n\n## Installation\n\n### From source (recommended)\n\n```shell\n\ngit clone https://github.com/SforAiDl/vformer.git\ncd vformer/\npython setup.py install\n\n```\n\n### From PyPI\n\n```shell\n\npip install vformer\n\n```\n\n## Models supported\n\n- [x] [Vanilla ViT](https://arxiv.org/abs/2010.11929)\n- [x] [Swin Transformer](https://arxiv.org/abs/2103.14030)\n- [x] [Pyramid Vision Transformer](https://arxiv.org/abs/2102.12122)\n- [x] [CrossViT](https://arxiv.org/abs/2103.14899)\n- [x] [Compact Vision Transformer](https://arxiv.org/abs/2104.05704)\n- [x] [Compact Convolutional Transformer](https://arxiv.org/abs/2104.05704)\n- [x] [Visformer](https://arxiv.org/abs/2104.12533)\n- [x] [Vision Transformers for Dense Prediction](https://arxiv.org/abs/2103.13413)\n- [x] [CvT](https://arxiv.org/abs/2103.15808)\n- [x] [ConViT](https://arxiv.org/abs/2103.10697)\n- [x] [ViViT](https://arxiv.org/abs/2103.15691)\n- [x] [Perceiver IO](https://arxiv.org/abs/2107.14795)\n- [x] [Memory Efficient Attention](https://arxiv.org/abs/2112.05682)\n\n## Example usage\n\nTo instantiate and use a Swin Transformer model -\n\n```python\n\nimport torch\nfrom vformer.models.classification import SwinTransformer\n\nimage = torch.randn(1, 3, 224, 224)       # Example data\nmodel = SwinTransformer(\n        img_size=224,\n        patch_size=4,\n        in_channels=3,\n        n_classes=10,\n        embed_dim=96,\n        depths=[2, 2, 6, 2],\n        num_heads=[3, 6, 12, 24],\n        window_size=7,\n        drop_rate=0.2,\n    )\nlogits = model(image)\n```\n\n`VFormer` has a modular design and allows for easy experimentation using blocks/modules of different architectures. For example, if desired, you can use just the encoder or the windowed attention layer of the Swin Transformer model.\n\n```python\n\nfrom vformer.attention import WindowAttention\n\nwindow_attn = WindowAttention(\n        dim=128,\n        window_size=7,\n        num_heads=2,\n        **kwargs,\n    )\n\n```\n\n```python\n\nfrom vformer.encoder import SwinEncoder\n\nswin_encoder = SwinEncoder(\n        dim=128,\n        input_resolution=(224, 224),\n        depth=2,\n        num_heads=2,\n        window_size=7,\n        **kwargs,\n    )\n\n```\n\nPlease refer to our [documentation](https://vformer.readthedocs.io/en/latest/) to know more.\n\n<br>\n\n### References\n\n- [vit-pytorch](https://github.com/lucidrains/vit-pytorch)\n- [Swin-Transformer](https://github.com/microsoft/Swin-Transformer)\n- [PVT](https://github.com/whai362/PVT)\n- [vit-explain](https://github.com/jacobgil/vit-explain)\n- [CrossViT](https://github.com/IBM/CrossViT)\n- [Compact-Transformers](https://github.com/SHI-Labs/Compact-Transformers)\n- [Visformer](https://github.com/danczs/Visformer)\n- [DPT](https://github.com/isl-org/DPT)\n- [CvT](https://github.com/microsoft/CvT)\n- [convit](https://github.com/facebookresearch/convit)\n- [ViViT-pytorch](https://github.com/rishikksh20/ViViT-pytorch)\n- [perceiver-pytorch](https://github.com/lucidrains/perceiver-pytorch)\n- [memory-efficient-attention](https://github.com/AminRezaei0x443/memory-efficient-attention)\n<!-- <br>\n\n<details>\n  <summary><strong>Citations</strong> (click to expand)</summary>\n\n<br>\n\n<b>An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</b>\n```bibtex\n@article{dosovitskiy2020vit,\n  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},\n  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and  Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},\n  journal={ICLR},\n  year={2021}\n}\n```\n\n<b>Swin Transformer: Hierarchical Vision Transformer using Shifted Windows</b>\n```bibtex\n@article{liu2021Swin,\n  title={Swin Transformer: Hierarchical Vision Transformer using Shifted Windows},\n  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},\n  journal={arXiv preprint arXiv:2103.14030},\n  year={2021}\n}\n```\n\n<b>Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions</b>\n```bibtex\n@misc{wang2021pyramid,\n      title={Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions},\n      author={Wenhai Wang and Enze Xie and Xiang Li and Deng-Ping Fan and Kaitao Song and Ding Liang and Tong Lu and Ping Luo and Ling Shao},\n      year={2021},\n      eprint={2102.12122},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV}\n}\n```\n<b> CrossViT: Cross-Attention Multi-Scale Vision Transformer for Image Classification </b>\n\n```bibtex\n@inproceedings{chen2021crossvit,\n    title={{CrossViT: Cross-Attention Multi-Scale Vision Transformer for Image Classification}},\n    author={Chun-Fu (Richard) Chen and Quanfu Fan and Rameswar Panda},\n    booktitle={International Conference on Computer Vision (ICCV)},\n    year={2021}\n}\n```\n\n<b> Escaping the Big Data Paradigm with Compact Transformers </b>\n\n```bibtex\n@article{hassani2021escaping,\n\ttitle        = {Escaping the Big Data Paradigm with Compact Transformers},\n\tauthor       = {Ali Hassani and Steven Walton and Nikhil Shah and Abulikemu Abuduweili and Jiachen Li and Humphrey Shi},\n\tyear         = 2021,\n\turl          = {https://arxiv.org/abs/2104.05704},\n\teprint       = {2104.05704},\n\tarchiveprefix = {arXiv},\n\tprimaryclass = {cs.CV}\n}\n```\n\n<b>Visformer: The Vision-friendly Transformer</b>\n\n```bibtex\n@misc{chen2021visformer,\n      title={Visformer: The Vision-friendly Transformer},\n      author={Zhengsu Chen and Lingxi Xie and Jianwei Niu and Xuefeng Liu and Longhui Wei and Qi Tian},\n      year={2021},\n      eprint={2104.12533},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV}\n}\n```\n\n<b>Vision Transformers for Dense Prediction</b>\n\n```bibtex\n@misc{ranftl2021vision,\n      title={Vision Transformers for Dense Prediction},\n      author={Ren√© Ranftl and Alexey Bochkovskiy and Vladlen Koltun},\n      year={2021},\n      eprint={2103.13413},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV}\n}\n```\n</details> -->\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/SforAiDl/vformer",
    "keywords": "vision transformers,pytorch,computer vision,machine learning,deep learning",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "vformer",
    "package_url": "https://pypi.org/project/vformer/",
    "platform": null,
    "project_url": "https://pypi.org/project/vformer/",
    "project_urls": {
      "Homepage": "https://github.com/SforAiDl/vformer",
      "Source": "https://github.com/SforAiDl/vformer"
    },
    "release_url": "https://pypi.org/project/vformer/0.1.3/",
    "requires_dist": [
      "typing-extensions",
      "arrow (==1.1.1)",
      "attrs (==21.2.0)",
      "backports.entry-points-selectable (==1.1.0)",
      "binaryornot (==0.4.4)",
      "certifi (==2021.5.30)",
      "cfgv (==3.3.1)",
      "chardet (==4.0.0)",
      "charset-normalizer (==2.0.4)",
      "click (==8.0.1)",
      "cookiecutter (==1.7.3)",
      "distlib (==0.3.2)",
      "einops (==0.3.2)",
      "filelock (==3.0.12)",
      "identify (==2.2.13)",
      "idna (==3.2)",
      "iniconfig (==1.1.1)",
      "Jinja2 (==3.0.1)",
      "jinja2-time (==0.2.0)",
      "MarkupSafe (==2.0.1)",
      "nodeenv (==1.6.0)",
      "olefile",
      "packaging (==21.0)",
      "Pillow",
      "platformdirs (==2.3.0)",
      "pluggy (==1.0.0)",
      "poyo (==0.5.0)",
      "pre-commit (==2.15.0)",
      "py (==1.10.0)",
      "pyparsing (==2.4.7)",
      "pytest (>=6.2.5)",
      "python-dateutil (==2.8.2)",
      "python-slugify (==5.0.2)",
      "PyYAML (==5.4.1)",
      "requests (==2.26.0)",
      "six (==1.16.0)",
      "text-unidecode (==1.3)",
      "toml (==0.10.2)",
      "torch (>=1.10.0)",
      "torchvision (>=0.11.0)",
      "urllib3 (==1.26.6)",
      "virtualenv (==20.7.2)"
    ],
    "requires_python": ">=3.6",
    "summary": "A modular PyTorch library for vision transformer models",
    "version": "0.1.3",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14323215,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "73f0f9943b8b9ba62e81d29ad08ed4ef6f659a45463e9e542632da541f660a88",
          "md5": "038f53153a91c1d056c8c60402dcb33f",
          "sha256": "db4e8f4a50911dbb5708c4ced10d662110a9f6d9b11036545773007d54fa475e"
        },
        "downloads": -1,
        "filename": "vformer-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "038f53153a91c1d056c8c60402dcb33f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 57369,
        "upload_time": "2022-02-09T12:35:53",
        "upload_time_iso_8601": "2022-02-09T12:35:53.291393Z",
        "url": "https://files.pythonhosted.org/packages/73/f0/f9943b8b9ba62e81d29ad08ed4ef6f659a45463e9e542632da541f660a88/vformer-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d6df1f00d1dc554ccf1313dfda6f7f4ab8709e9447969b52645aba086f5a2aa5",
          "md5": "5b8d01b789d3c39c9425ce8329e94fa2",
          "sha256": "d9fc413cc58fb70a15a227037ae92fe0e87d5e2b56616d05db2a8e236e4dc216"
        },
        "downloads": -1,
        "filename": "vformer-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "5b8d01b789d3c39c9425ce8329e94fa2",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 57312,
        "upload_time": "2022-02-11T04:59:37",
        "upload_time_iso_8601": "2022-02-11T04:59:37.740178Z",
        "url": "https://files.pythonhosted.org/packages/d6/df/1f00d1dc554ccf1313dfda6f7f4ab8709e9447969b52645aba086f5a2aa5/vformer-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4d2a20fb929e8beb9b3f12a690cd61bcc45a5aa453bf50a9d3ee01833c551b76",
          "md5": "d608441530ab74bc860b06ffade3c64e",
          "sha256": "07b62b0a59fc6c663cef890eedc3f4c83a788349e186a8e2536f4c02e83e3ab1"
        },
        "downloads": -1,
        "filename": "vformer-0.1.2-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d608441530ab74bc860b06ffade3c64e",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": ">=3.6",
        "size": 75119,
        "upload_time": "2022-04-07T19:22:13",
        "upload_time_iso_8601": "2022-04-07T19:22:13.653303Z",
        "url": "https://files.pythonhosted.org/packages/4d/2a/20fb929e8beb9b3f12a690cd61bcc45a5aa453bf50a9d3ee01833c551b76/vformer-0.1.2-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0f07f13570a64bd7cbfd3e3a64000ad58eed8af64f154b77db3d3cd5a25e668d",
          "md5": "86f310818c8667f5522b2925323a989d",
          "sha256": "e0b6159c1f179ba84e7a0bbfb7aa032fadde24563f4b4e958181a7d01559d652"
        },
        "downloads": -1,
        "filename": "vformer-0.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "86f310818c8667f5522b2925323a989d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 60970,
        "upload_time": "2022-04-07T19:22:15",
        "upload_time_iso_8601": "2022-04-07T19:22:15.279868Z",
        "url": "https://files.pythonhosted.org/packages/0f/07/f13570a64bd7cbfd3e3a64000ad58eed8af64f154b77db3d3cd5a25e668d/vformer-0.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "29e8b156db70933b2d166f6096e2e3d1ffc0f0ff984d9ac8567e43c8aaabe0a9",
          "md5": "dc2f0487625fee1a63c8fbfd38389cb3",
          "sha256": "198ad9ee15c0b09ea1d68fc181c022697eaf1fa7903bcee19a1e3f1f90676fc6"
        },
        "downloads": -1,
        "filename": "vformer-0.1.3-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "dc2f0487625fee1a63c8fbfd38389cb3",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": ">=3.6",
        "size": 73864,
        "upload_time": "2022-07-03T17:23:04",
        "upload_time_iso_8601": "2022-07-03T17:23:04.263823Z",
        "url": "https://files.pythonhosted.org/packages/29/e8/b156db70933b2d166f6096e2e3d1ffc0f0ff984d9ac8567e43c8aaabe0a9/vformer-0.1.3-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f58b511ece4f144d8bb2f84588702dd7a661446b970d8a24bb6f2fd13f0f8327",
          "md5": "179d229e78b5b846232f109da737f44b",
          "sha256": "ee43cb736e9cc155ea470f58241f6d15b3c21df8410a4fa01f9f053f0733e750"
        },
        "downloads": -1,
        "filename": "vformer-0.1.3.tar.gz",
        "has_sig": false,
        "md5_digest": "179d229e78b5b846232f109da737f44b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 60295,
        "upload_time": "2022-07-03T17:23:06",
        "upload_time_iso_8601": "2022-07-03T17:23:06.050479Z",
        "url": "https://files.pythonhosted.org/packages/f5/8b/511ece4f144d8bb2f84588702dd7a661446b970d8a24bb6f2fd13f0f8327/vformer-0.1.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "29e8b156db70933b2d166f6096e2e3d1ffc0f0ff984d9ac8567e43c8aaabe0a9",
        "md5": "dc2f0487625fee1a63c8fbfd38389cb3",
        "sha256": "198ad9ee15c0b09ea1d68fc181c022697eaf1fa7903bcee19a1e3f1f90676fc6"
      },
      "downloads": -1,
      "filename": "vformer-0.1.3-py2.py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "dc2f0487625fee1a63c8fbfd38389cb3",
      "packagetype": "bdist_wheel",
      "python_version": "py2.py3",
      "requires_python": ">=3.6",
      "size": 73864,
      "upload_time": "2022-07-03T17:23:04",
      "upload_time_iso_8601": "2022-07-03T17:23:04.263823Z",
      "url": "https://files.pythonhosted.org/packages/29/e8/b156db70933b2d166f6096e2e3d1ffc0f0ff984d9ac8567e43c8aaabe0a9/vformer-0.1.3-py2.py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "f58b511ece4f144d8bb2f84588702dd7a661446b970d8a24bb6f2fd13f0f8327",
        "md5": "179d229e78b5b846232f109da737f44b",
        "sha256": "ee43cb736e9cc155ea470f58241f6d15b3c21df8410a4fa01f9f053f0733e750"
      },
      "downloads": -1,
      "filename": "vformer-0.1.3.tar.gz",
      "has_sig": false,
      "md5_digest": "179d229e78b5b846232f109da737f44b",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 60295,
      "upload_time": "2022-07-03T17:23:06",
      "upload_time_iso_8601": "2022-07-03T17:23:06.050479Z",
      "url": "https://files.pythonhosted.org/packages/f5/8b/511ece4f144d8bb2f84588702dd7a661446b970d8a24bb6f2fd13f0f8327/vformer-0.1.3.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}