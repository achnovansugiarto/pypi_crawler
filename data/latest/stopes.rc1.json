{
  "info": {
    "author": "Facebook AI Research",
    "author_email": null,
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "License :: OSI Approved :: MIT License",
      "Topic :: Scientific/Engineering"
    ],
    "description": "![stopes](/website/static/img/banner.png?raw=true \"stopes by NLLB.\")\n\n\n# `stopes`: A library for preparing data for machine translation research\n\nAs part of the FAIR No Language Left Behind (NLLB) ([Paper](https://research.facebook.com/publications/no-language-left-behind/), [Website](https://ai.facebook.com/research/no-language-left-behind/), [Blog](https://ai.facebook.com/blog/nllb-200-high-quality-machine-translation/))\nproject to drive inclusion through machine translation, a large amount of data was processed to create training data. We provide the libraries and tools we used to:\n\n1. create clean monolingual data from web data\n2. mine bitext\n3. easily write scalable pipelines for processing data for machine translation\n\nFull documentation on https://facebookresearch.github.io/stopes\n\n## Examples\n\ncheckout the `demo` directory for an example usage with the [WMT22 Shared Task: Large-Scale Machine Translation Evaluation for African\nLanguages](https://statmt.org/wmt22/large-scale-multilingual-translation-task.html) data.\n\n## Requirements\n`stopes` relies on:\n* submitit to schedule jobs when ran on clusters\n* hydra-core version >= 1.2.0 for configuration\n* fairseq to use LASER encoders\n* PyTorch version >= 1.5.0\n* Python version >= 3.8\n\n## Installing stopes\n\nstopes uses [flit](https://flit.pypa.io/) to manage its setup, you will need a recent version of\npip for the install to work. We recommend that you first upgrade pip:\n`python -m pip install --upgrade pip`\n\nYou can install stopes with pip:\n`pip install -e '.[dev,mono,mining]'`\n\nYou can choose what to install. If you are only interested in `mining`, you do not need to install `dev`, and `mono`.\n\nThe mining pipeline relies on fairseq to run LASER encoders, pip cannot install fairseq currently, so you will have to do this manually. Check the [fairseq](https://github.com/facebookresearch/fairseq) repo for up to date instructions and requirements:\n```\ngit clone https://github.com/pytorch/fairseq\ncd fairseq\npip install --editable ./\n```\n\nIf you plan to train a lot of NMT model you will also want to setup apex to get a faster training.\n```\ngit clone https://github.com/NVIDIA/apex\ncd apex\npip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" \\\n  --global-option=\"--deprecated_fused_adam\" --global-option=\"--xentropy\" \\\n  --global-option=\"--fast_multihead_attn\" ./\n```\n\n## How `stopes` works\n\n`stopes` is made of a few different parts:\n1. `core` provides a library to write readable piplines\n2. `modules` provides a set of modules using the core library and implementing\n   common steps in our mining and evaluation pipelines\n3. `pipelines` provides pipeline implementation for the data pipelines we use in\n   NLLB:\n- `monolingual` to preprocess and clean single language data\n- `bitext` to run the \"global mining\" pipeline and extract aligned sentences\n  from two monolingual datasets. (inspired by\n  [CCMatric](https://ai.facebook.com/blog/ccmatrix-a-billion-scale-bitext-data-set-for-training-translation-models/))\n\n**Full documentation**: see https://facebookresearch.github.io/stopes\nor the `websites/docs` folder.\n\n## Contributing\n\nSee the [CONTRIBUTING](CONTRIBUTING.md) file for how to help out.\n\n## Contributors\n\n- [Pierre Andrews](https://github.com/Mortimerp9)\n- [Onur Çelebi](https://github.com/Celebio)\n- [Angela Fan](https://github.com/huihuifan)\n- [Vedanuj Goswami](https://github.com/vedanuj)\n- [Kevin Heffernan](https://github.com/heffernankevin)\n- [Ammar Kamran](https://github.com/AmmarKamran)\n- [Jean Maillard](https://github.com/jeanm)\n- [Alexandre Mourachko](https://github.com/alexmourachko)\n- [Kaushik Ram Sadagopan](https://github.com/kauterry)\n- [Holger Schwenk](https://github.com/hoschwenk)\n- [Guillaume Wenzek](https://github.com/gwenzek)\n\n(in alphabetical order)\n\n## Citation\nIf you use `stopes` in your work or any models/datasets/artifacts published in NLLB, please cite :\n\n```bibtex\n@article{nllb2022,\n  title={No Language Left Behind: Scaling Human-Centered Machine Translation},\n  author={{NLLB Team} and Costa-jussà, Marta R. and Cross, James and Çelebi, Onur and Elbayad, Maha and Heafield, Kenneth and Heffernan, Kevin and Kalbassi, Elahe and Lam, Janice and Licht, Daniel and Maillard, Jean and Sun, Anna and Wang, Skyler and Wenzek, Guillaume and Youngblood, Al and Akula, Bapi and Barrault, Loic and Mejia-Gonzalez, Gabriel and Hansanti, Prangthip and Hoffman, John and Jarrett, Semarley and Sadagopan, Kaushik Ram and Rowe, Dirk and Spruit, Shannon and Tran, Chau and Andrews, Pierre and Ayan, Necip Fazil and Bhosale, Shruti and Edunov, Sergey and Fan, Angela and Gao, Cynthia and Goswami, Vedanuj and Guzmán, Francisco and Koehn, Philipp and Mourachko, Alexandre and Ropers, Christophe and Saleem, Safiyyah and Schwenk, Holger and Wang, Jeff},\n  year={2022}\n}\n```\n\n## License\n`stopes` is MIT licensed, as found in the LICENSE file.\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": null,
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": null,
    "keywords": null,
    "license": null,
    "maintainer": null,
    "maintainer_email": null,
    "name": "stopes",
    "package_url": "https://pypi.org/project/stopes/",
    "platform": null,
    "project_url": "https://pypi.org/project/stopes/",
    "project_urls": {
      "Source": "https://github.com/facebookresearch/stopes",
      "Tracker": "https://github.com/facebookresearch/stopes/issues"
    },
    "release_url": "https://pypi.org/project/stopes/1.0.1/",
    "requires_dist": [
      "hydra-core>=1.2.0",
      "submitit>=1.4.2",
      "tqdm",
      "joblib",
      "pytest>=4.3.0 ; extra == \"dev\"",
      "pytest-asyncio>=0.15.0 ; extra == \"dev\"",
      "pytest-cov>=2.6.1 ; extra == \"dev\"",
      "coverage[toml]>=5.1 ; extra == \"dev\"",
      "black==22.3.0 ; extra == \"dev\"",
      "isort>=5.10.1 ; extra == \"dev\"",
      "mypy>=0.782 ; extra == \"dev\"",
      "types-emoji ; extra == \"dev\"",
      "pylint>=2.8.0 ; extra == \"dev\"",
      "flit>=3.5.1 ; extra == \"dev\"",
      "fairscale ; extra == \"mining\"",
      "faiss-gpu ; extra == \"mining\"",
      "sentencepiece ; extra == \"mining\"",
      "numpy ; extra == \"mining\"",
      "xxhash ; extra == \"mono\"",
      "fasttext ; extra == \"mono\"",
      "sentence_splitter ; extra == \"mono\"",
      "sentencepiece ; extra == \"mono\"",
      "indic-nlp-library ; extra == \"mono\"",
      "emoji ; extra == \"mono\""
    ],
    "requires_python": ">=3.8",
    "summary": "Large-Scale Translation Data Mining.",
    "version": "1.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14353532,
  "releases": {
    "1.0.1": [
      {
        "comment_text": null,
        "digests": {
          "blake2b_256": "10ab1519873ec14ecfd7779696639c672103432212b9a88ba175032ceb059dff",
          "md5": "f6183aa32ca47411e968573d72c73020",
          "sha256": "b8646f70af05000617294bc9dc0ee8e187a31e451e1ff05933c53b899cc7767f"
        },
        "downloads": -1,
        "filename": "stopes-1.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f6183aa32ca47411e968573d72c73020",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 202741,
        "upload_time": "2022-07-06T15:54:15",
        "upload_time_iso_8601": "2022-07-06T15:54:15.173287Z",
        "url": "https://files.pythonhosted.org/packages/10/ab/1519873ec14ecfd7779696639c672103432212b9a88ba175032ceb059dff/stopes-1.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": null,
        "digests": {
          "blake2b_256": "b4201f2c93dc1a3113a864797a9bfe21b956aa620e7d7be4948d1fcb71aaaf29",
          "md5": "d0f9db9f22fe061765844c101898991c",
          "sha256": "6e0171b30ebc846ba7d4f53e2f195533cc3131dc304fa31b6e61483e60076ee9"
        },
        "downloads": -1,
        "filename": "stopes-1.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "d0f9db9f22fe061765844c101898991c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 736573,
        "upload_time": "2022-07-06T15:54:24",
        "upload_time_iso_8601": "2022-07-06T15:54:24.334103Z",
        "url": "https://files.pythonhosted.org/packages/b4/20/1f2c93dc1a3113a864797a9bfe21b956aa620e7d7be4948d1fcb71aaaf29/stopes-1.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": null,
      "digests": {
        "blake2b_256": "10ab1519873ec14ecfd7779696639c672103432212b9a88ba175032ceb059dff",
        "md5": "f6183aa32ca47411e968573d72c73020",
        "sha256": "b8646f70af05000617294bc9dc0ee8e187a31e451e1ff05933c53b899cc7767f"
      },
      "downloads": -1,
      "filename": "stopes-1.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "f6183aa32ca47411e968573d72c73020",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.8",
      "size": 202741,
      "upload_time": "2022-07-06T15:54:15",
      "upload_time_iso_8601": "2022-07-06T15:54:15.173287Z",
      "url": "https://files.pythonhosted.org/packages/10/ab/1519873ec14ecfd7779696639c672103432212b9a88ba175032ceb059dff/stopes-1.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": null,
      "digests": {
        "blake2b_256": "b4201f2c93dc1a3113a864797a9bfe21b956aa620e7d7be4948d1fcb71aaaf29",
        "md5": "d0f9db9f22fe061765844c101898991c",
        "sha256": "6e0171b30ebc846ba7d4f53e2f195533cc3131dc304fa31b6e61483e60076ee9"
      },
      "downloads": -1,
      "filename": "stopes-1.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "d0f9db9f22fe061765844c101898991c",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.8",
      "size": 736573,
      "upload_time": "2022-07-06T15:54:24",
      "upload_time_iso_8601": "2022-07-06T15:54:24.334103Z",
      "url": "https://files.pythonhosted.org/packages/b4/20/1f2c93dc1a3113a864797a9bfe21b956aa620e7d7be4948d1fcb71aaaf29/stopes-1.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}