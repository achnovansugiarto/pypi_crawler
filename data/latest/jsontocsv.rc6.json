{
  "info": {
    "author": "Tim Savannah",
    "author_email": "kata198@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "License :: OSI Approved :: GNU Lesser General Public License v3 (LGPLv3)",
      "Programming Language :: Python",
      "Programming Language :: Python :: 2",
      "Programming Language :: Python :: 2.7",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.4",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Topic :: Internet :: WWW/HTTP",
      "Topic :: Software Development :: Libraries :: Python Modules",
      "Topic :: Text Processing :: Markup :: HTML"
    ],
    "description": "jsonToCsv\n=========\n\nConverts json data to csv via a meta language (format string)\n\nThe output csv is RFC 4180 compliant by default (behaviour can be changed with options).\n\n\nThe Problem\n-----------\n\nThe problem with converting json to csv is that json is a dynamic, multi-typed, nested format. Csv on the other hand is a fixed single-type format.\n\nJsonToCsv solves this by defining a meta language (format string) which can be used to define repeatable and fixed-format steps, allowing the flattening of the wide json domain space into the slim csv space.\n\n\n\nFormat String\n=============\n\nBecause csv is a fixed-format field and json is free-format, a meta language had to be developed to describe the various movements to find and output values into a fixerd format. This section describes that format.\n\n**Format str:**\n\n\tThe format str is a series of operations and keys, plus zero or more \"line item\"s.\n\n**Keys:**\n\n\t\n\tEvery key name listed in the format string is quoted with double-quotes.\n\n\tIf the key is prefixed with an operation, it is used to REACH a value.\n\n\tIf a key is NOT prefixed with an operation, it becomes a value printed.\n\n\tUnless you are using an op to change level, the quoted key should be followed\n\t by a comma to separate.\n\n\tA key may be anywhere before, after, or inside a line item,\n\tand the keys will be output in the order they appear.\n\n\tExamples:\n\n\t\t\"hostname\"   # Print key hostname at current level\n\n\t\t.\"hostname\"[ # The . (map access) operator applied on the \"hostname\" key\n\n\t\t\"hostname\", \"cheese\" # Two keys at this current level\n\t\n\n**Line Item:**\n\n\tA \"line item\" is the key iterated-over to produce each line of the csv.\n\n\tA line item is given with the '+' sign before a key.\n\n\tYou may have multiple line items (so iterate over multiple keys), and you will have\n\n\t  one line of output per each innermost line item found.\n\n\tYou may not close a line item and then try to open another one at another level.\n\n\tIf you have no line items defined (like a single record), one csv line will be produced.\n\n\n\n\tExamples:\n\n\t\t+\"instances\"[  # For each item in the array at current level given by key \n\t                 #   \"instances\", we will generate a csv line.\n\n\t\t.\"Something\"[  # Go into key at root named 'Something'\n\t\t+\"Data\"[     # Iterate over each element in the array found at \"Data\"\n\t\t+\"instances\" # Iterate again over each element in the array found at \"instances\" within each \"Data\"\n\n\n**Map Access:**\n\n\tThe \"map access\" operator means to access a key at the current level\n\n\tand progresses the 'current level' to include this key access.\n\n\tA map access is given with the '.' operator before a key\n\n\n\tExample:\n\n\t\t.\"Data\"[   # Descend the 'current level' by the key \"Data\"\n\n**List-Map Access:**\n\n\tThe \"list-map access\" operator means to search a list of maps at the current level,\n\t  found under the given key, until a key in that map matches a given value.\n\n\tYou use the \"/\" operator prefix to the key, and within the square bracket define a comparitive op.\n\n\tIt will stop on the FIRST match that it finds. Duplicates are not supported because it would create\n\t  an arbitrary number of fields (and csv is fixed-field)\n\n\tFor example, if you had a key \"attributes\" which held a bunch of maps like {\"key\" : ... , \"value\" : ... }\n\n\t  and you want select the map where \"key\" == \"color\", it would look like this:\n\n\t  /\"attributes\"[\"key\"=\"color\"\n\n\n**Moving Between Levels:**\n\n\tYou'll notice that every op descends a level, represented by being followed by a square bracket, \"[\".\n\n\tIf you want to ascend back up to the previous level, simply close the square bracket \"]\".\n\n\tAll open brackets must be closed before the format string ends.\n\n\n**Whitespace Characters:**\n\n\tSpaces and newlines are generally ignored, and can be used to make things look nice.\n\n**Comments:**\n\n\tYou can comment directly in the format string by using the hash [ '#' ] character.\n\n\tEverything following the hash character to the end-of-line will be ignored.\n\n\tThis is useful in conjunction with mulit-line patterns to document what each line is doing.\n\n\tSee the \"Example with inline comments\" section for an example of both.\n\nCommas:\n\n\tCommas should be used to separate items on the same level, so after a quoted-key for printing,\n\tand after a close-bracket \"]\" if more items follow on that upper level.\n\nOrder:\n\n\tKeys are printed as found left-to-right in the format string.\n\n\tYou can descend into levels, back up, print keys, then descend back into those levels as many\n\t  times as you like.\n\n\nNulls:\n\n\t If a value in the json map is \"null\" or undefined,\n\n\t an empty string is given for the value (by default, can be changed to any string).\n\n\t If there is an error following the format string to a key (like a missing key, or bad type),\n\n\t you can pass the '--debug' flag to print on stderr WHY it returned null, each time that it does.\n\nCase sensitive:\n\n\tAll keys are case sensitive.\n\nMulti-Line:\n\n\tBecause non-quoted whitespace is ignored, you can use newlines, spaces, and tabs to make long patterns more readable.\n\n\nTool\n====\n\nThis module ships with a script, jsonToCsv, which can be used standalone to perform the operations.\n\n\tUsage: jsonToCsv [format str]\n\n\t\tFormats a json string ( delivered via stdin ) to csv, based on provided format str.\n\n\t\t\n\t\tOptions:\n\n\n\t\t\t--null-value=XXX          Use \"XXX\" instead of an empty string as the null value\n\n\t\t\t--quote-fields=X          Defaults to \"Smart quoting\", i.e. fields will be quoted\n\n\t\t\t\t\t\t\t\t\t\taccording to RFC 4180 as-needed. You can specify \"true\" or \"false\"\n\n\t\t\t\t\t\t\t\t\t\there explicitly to force a behaviour\n\n\n\n\t\t\t--help                    Show this message\n\n\t\t\t--format-help             Show usage on format string representation\n\n\n\t\t\t--version                 Print the version\n\n\tExample:\n\n\t\tcat myFile.json | jsonToCsv '+\"Results\"[\"name\", \"org\"]'\n\n\n\nModule\n======\n\nThe primary public module is json_to_csv.JsonToCsv\n\nThe constructor requires only the format string [formatStr] ( a string written in a simple specific meta-language used to define the pattern for extraction ).\n\nYou may, however, choose to define an alternate value to represent unreachable or defined-as-null fields [nullValue]\n\n\nModule PyDoc\n------------\n\nYou can access the pydoc here: http://htmlpreview.github.io/?https://github.com/kata198/jsonToCsv/blob/master/doc/index.html\n\n\n\nModule Usage Example\n--------------------\n\nSee: https://github.com/kata198/jsonToCsv/blob/master/example.py and https://github.com/kata198/jsonToCsv/blob/master/example_mutli.py.\n\nFor a basic example of using the module directly for extraction and reformatting into various formats (CSV, TSV, a text table)\n\n\nExtracting Data\n---------------\n\nOnce you've written your formatStr and created the JsonToCsv object, you're ready to start parsing!\n\n\n**extractData**\n\nextractData is the \"core\" method of JsonToCsv. It performs the actual work of taking the json and following the format string to create a series of lines.\n\nThe output of this method is a list of lists, the outer list is each line, and each line is a list where each element represents a field.\n\nSome more complicated use-cases where \"extractData\" is required are:\n\n* Creating alternate formats of output (like TSV or a text table, or plugging into a GUI)\n\n* Analysis of the data, i.e. filtering or modifying\n\n* Joining data from multiple JSON entries (see that section for more info)\n\n* Whatever you need to do\n\nYou can pass the output of this function to the \"dataToStr\" method to convert it into a printable string.\n\n**dataToStr**\n\ndataToStr provides the means to convert data (from extractData) to a printable string.\n\nThe first argument is the list-of-lists that extractData provides\n\nIt then has the following optional arguments:\n\n* separator - Defaults to comma, may use tab for TSV, or whatever you want\n\n* lineSeparator - Defaults to CRLF (\\\\r\\\\n) which is the RFC4180 standard, but you may use something else (like \\\\n).\n\n* quoteFields - This you can set to True or False to explicitly quote or not quote data per RFC4180 standards. The default is the string \"smart\", which means the data will be scanned to see if it needs quoting, and if so, it will quote the data. Otherwise, it will not. Generally you will want to keep this at the default.\n\n\n**convertToCsv**\n\nThe most basic and direct method is the \"convertToCsv\" function. You can pass in a string (raw data) or a dict (already parsed e.g. by 'json' module ), and you'll be output the csv lines, ready to be passed to the \"print\" function. \n\nThis is the same as calling extractData and passing it to dataToStr, except you can only use comma as a separator through this function.\n\nThis function takes the same \"lineSeparator\" and \"quoteFields\" arguments described in \"dataToStr\" above.\n\n\n**findDuplicates**\n\nThis function can help you identify when multiple lines contain the same data in the same field. \n\nYou pass in the data extracted by *extractData*, pick a zero-origin \"fieldNum\", which dictates which field to check on each line for duplicate values.\n\nIf the \"flat\" argument is False (default), the output is a map where the keys are all the field values which had duplicate entries.\n\nIf \"flat\" is True, the output is just a list of list-of field values. Basically, the data from extractData, but ONLY included if it has a duplicate in the chosen field.\n\n\n**joinCsv**\n\njoinCsv will take in two sets of list<list<str>> (i.e. returned frmo \"extractData\"), and two 0-origin numbers, joinFieldNum1 (what is the index of the \"join field\" in the first dataset) and joinFieldNum2.\n\nSo for example, you may have two sets of data, both describing people. \"Social Security Number\" could be the 4th field from zero on one of them, and the 0th on another dataset. So if you want to combine these two datasets, you can use this method to do so, bt joining those fields (i.e. any instances where there's a field match between the two joinFieldNum columns, that index is removed from the second dataset, sand the second dataset is appended to the first.\n\n**multiJoinCsv**\n\nSame as joinCsv, but joinCsv allows no duplicates within a dataset itself. So going with the data above, imagine if the same social security number had two people's names in one dataset.... well which one is rght? A computer can't determine that.\n\nSo this function will give a \"best effort\", in the above example, you'd get person X's dataset attached to whoemver had that social security number listed. So if you have a field duplicated twice in both csvData1 and csvData2, you'll end up with 4 lines total:\n\n\n* A1 B1\n* A2 B1\n* A1 B2\n* A2 B3\n\nThis matches very eagerly, but you may start to get some invalid data at this point.\n\n\n\n\nFULL EXAMPLE:\n--------------\n\n\t.\"Data\"[ +\"Instances\"[ \"hostname\", /\"attrs\"[\"key\"=\"role\" \"value\"], /\"attrs\"[\"key\"=\"created_at\" \"value\", \"who_set\"], .\"Performance\"[ \"cpus\", \"memory\" ] ] ]\n\n\n**Explanation:**\n\n\nThe given json object will first be descended by the \"Data\" key, where a map is expected.\n\nIn this map, \"Instances\" will be the \"line item\", i.e. we will iterate over each item in the \"Instances\" list to generate each line of the csv.\n\nSo, for each map in \"Instances\":\n\n   * We print the \"hostname\" key as the first csv element\n\n   * We descend into a list of maps under the key \"attrs\",\n   \n   * Search for where one of those maps has an entry \"key\" with the value \"role\", and we print the value of the \"value\" key of that map as the second csv element.\n\nThen, we return to previous level.\n\nWe descend again into that list of maps under the key \"attrs\",\n\n   * Search for where one of those maps has an entry \"key\" with the value \"created_at\",\n     and we print the value of the \"value\" key of that map as the third csv element.\n\n   * We then print value of the \"who_set\" key of that same map as the fourth csv element.\n\nThen, we return to the previous level\n\nWe then descend into a map under the key 'Performance'\n\n   * we print the value of the key \"cpus\" at this level as the fifth csv element.\n   * we print the value of the key \"memory\" at this level as the sixth csv element.\n\nThen, we return to the previous level\n\nWe return to the previous level\n\n(we are done iterating at this point)\n\nWe return to the previous level\n\n**Example with inline comments:**\n\nThe following is the meant to parse the following json: https://github.com/kata198/jsonToCsv/blob/master/example_multi.json\n\n\n\tPARSE_STR = '''\n\n\t\t\t\"date\",             # First element of every line will be the value of\n\n\n\n\t\t\t\t\t\t\t\t#  \"date\" at the top level\n\n\t\t\t+\"results\"[         # Iterate over each member of the list under \"results\"\n\n\t\t\t  \"myBeforeKey\",    # Include \"myBeforeKey\" as the next item in every line\n\n\t\t\t\t+\"instances\"[   # Iterate over each member of the list under \"instances\"\n\n\t\t\t\t\t\"hostname\", # Include \"hostname\" under \"instances\" in each line\n\n\t\t\t\t\t\"ip\"        # Next key to add is \"ip\"\n\n\t\t\t\t\t/\"attributes\"[\"name\"=\"status\"  # Descend into a list-of-maps under \"attributes\" and look\n\n\t\t\t\t\t\t\t\t\t\t\t\t   #  for where the key \"name\" has the value \"status\"\n\n\t\t\t\t\t\t\"value\"                    # In the matched-map, print the value of the key \"value\"\n\n\t\t\t\t\t],                             # Leave this matched map, return to one level up\n\n\t\t\t\t\t.\"puppet_data\"[                # Descend into map found at \"puppet_data\" key\n\n\t\t\t\t\t\t\"hostgroup\"                # Print the \"hostgroup\" key at this level\n\n\t\t\t\t\t],                             # Return to previous level\n\n\t\t\t\t\t/\"attributes\"[\"name\"=\"domain\"  # Descend into a list-of-maps under \"attributes\" and look\n\n\t\t\t\t\t\t\t\t\t\t\t\t   #  for where the key \"name\" has the value \"domain\"\n\n\t\t\t\t\t\t\"value\"                    # Print the \"value\" key in this matched map\n\n\t\t\t\t\t],                             # Go back up to previous level\n\n\t\t\t\t\t/\"attributes\"[\"name\"=\"owner\"   # Descend into a list-of-maps at \"attributes\" and look\n\n\t\t\t\t\t\t\t\t\t\t\t\t   #  for where the key \"name\" has the value \"owner\"\n\n\t\t\t\t\t\t\"value\"                    # Print the key \"value\" at this level\n\n\t\t\t\t\t]                              # Go back to previous level\n\n\t\t\t\t]                                  # Go back to previous level\n\n\t\t\t\t\"myAfterKey\"                       # Append to all previous lines the value of key \"myAfterKey\"\n\n\t\t\t],                                     # Go back up a level\n\n\t\t\t\"name\"                                # Append to all previous lines the value of key \"name\"\n\n\t'''",
    "description_content_type": null,
    "docs_url": "https://pythonhosted.org/jsonToCsv/",
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/kata198/jsonToCsv",
    "keywords": "json,to,csv,convert,extract,parse,rfc4180,text/csv,jsonToCsv",
    "license": "LGPLv3",
    "maintainer": "",
    "maintainer_email": "",
    "name": "jsonToCsv",
    "package_url": "https://pypi.org/project/jsonToCsv/",
    "platform": "",
    "project_url": "https://pypi.org/project/jsonToCsv/",
    "project_urls": {
      "Homepage": "https://github.com/kata198/jsonToCsv"
    },
    "release_url": "https://pypi.org/project/jsonToCsv/1.0.1/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "Extract data from json and convert to CSV",
    "version": "1.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 2705388,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "297fcfbe3bcdd2ef5b6d3d55fcc7d3b767d45b5609c2ac71083ed04f7479e762",
          "md5": "2b2d698051b634e7fca0e09aa29b8c87",
          "sha256": "9466228bc8e854e457b083dffaf9c0d8de0a72aedaade16d40d53e61c6971f6f"
        },
        "downloads": -1,
        "filename": "jsonToCsv-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "2b2d698051b634e7fca0e09aa29b8c87",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 13678,
        "upload_time": "2017-02-19T06:18:00",
        "upload_time_iso_8601": "2017-02-19T06:18:00.819575Z",
        "url": "https://files.pythonhosted.org/packages/29/7f/cfbe3bcdd2ef5b6d3d55fcc7d3b767d45b5609c2ac71083ed04f7479e762/jsonToCsv-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2f4f4e160f9a1b1f10001d986463498e5f85db8d7feaad04973ae9e560b64539",
          "md5": "e7c44a6f78ced1e0698dfad97231944c",
          "sha256": "aec53162df2c53141c25a6296101b4aa0dfa99af5e9ab250fccf3a33625bce2c"
        },
        "downloads": -1,
        "filename": "jsonToCsv-0.1.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "e7c44a6f78ced1e0698dfad97231944c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 22511,
        "upload_time": "2017-02-19T06:42:15",
        "upload_time_iso_8601": "2017-02-19T06:42:15.394440Z",
        "url": "https://files.pythonhosted.org/packages/2f/4f/4e160f9a1b1f10001d986463498e5f85db8d7feaad04973ae9e560b64539/jsonToCsv-0.1.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6ebbdc9ca47df4412dc8b735525dbed399d3567ee5d21bab54081874792da56d",
          "md5": "49b535608bd036086222bd9bd5281847",
          "sha256": "e7b99169790a21a448ed1acbf05518e099d6efd689562aa9b15384b4903007f8"
        },
        "downloads": -1,
        "filename": "jsonToCsv-0.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "49b535608bd036086222bd9bd5281847",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 24316,
        "upload_time": "2017-02-28T20:11:06",
        "upload_time_iso_8601": "2017-02-28T20:11:06.880238Z",
        "url": "https://files.pythonhosted.org/packages/6e/bb/dc9ca47df4412dc8b735525dbed399d3567ee5d21bab54081874792da56d/jsonToCsv-0.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e4d59a6499007a2d5cb7644e168c832cc8a06823a17eba35d3195dbacef47ac7",
          "md5": "4bd1c1cde896aaba5990a9c4e406699d",
          "sha256": "fef6fec334d96822adde6d9a10f50c261fc6b9d6adf306f266c4a68c8635d6a5"
        },
        "downloads": -1,
        "filename": "jsonToCsv-0.2.1.tar.gz",
        "has_sig": false,
        "md5_digest": "4bd1c1cde896aaba5990a9c4e406699d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 24592,
        "upload_time": "2017-03-13T20:19:48",
        "upload_time_iso_8601": "2017-03-13T20:19:48.498897Z",
        "url": "https://files.pythonhosted.org/packages/e4/d5/9a6499007a2d5cb7644e168c832cc8a06823a17eba35d3195dbacef47ac7/jsonToCsv-0.2.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f84481f6b678156e413d578fe4381ff930b715ee12cc9dd94c1fbfb0b3125f47",
          "md5": "2a65c6ceabadbbc0dca7b18455c77a32",
          "sha256": "2aeccfb1c63c919bbdaf592467772ad861048df39a9750bba112482e384737f4"
        },
        "downloads": -1,
        "filename": "jsonToCsv-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "2a65c6ceabadbbc0dca7b18455c77a32",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 38380,
        "upload_time": "2017-03-14T03:16:19",
        "upload_time_iso_8601": "2017-03-14T03:16:19.859590Z",
        "url": "https://files.pythonhosted.org/packages/f8/44/81f6b678156e413d578fe4381ff930b715ee12cc9dd94c1fbfb0b3125f47/jsonToCsv-1.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2cc701a57cbd710c7e7ccd8443dd033162be528a5319cb54966dd72d4359611f",
          "md5": "dc29cc178c96133a574619fac650d3a7",
          "sha256": "062aeeb809bd155121c43658043b001b0d477332d4f562ae3b379d6f078c1972"
        },
        "downloads": -1,
        "filename": "jsonToCsv-1.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "dc29cc178c96133a574619fac650d3a7",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 40223,
        "upload_time": "2017-03-14T17:09:08",
        "upload_time_iso_8601": "2017-03-14T17:09:08.678146Z",
        "url": "https://files.pythonhosted.org/packages/2c/c7/01a57cbd710c7e7ccd8443dd033162be528a5319cb54966dd72d4359611f/jsonToCsv-1.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "2cc701a57cbd710c7e7ccd8443dd033162be528a5319cb54966dd72d4359611f",
        "md5": "dc29cc178c96133a574619fac650d3a7",
        "sha256": "062aeeb809bd155121c43658043b001b0d477332d4f562ae3b379d6f078c1972"
      },
      "downloads": -1,
      "filename": "jsonToCsv-1.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "dc29cc178c96133a574619fac650d3a7",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 40223,
      "upload_time": "2017-03-14T17:09:08",
      "upload_time_iso_8601": "2017-03-14T17:09:08.678146Z",
      "url": "https://files.pythonhosted.org/packages/2c/c7/01a57cbd710c7e7ccd8443dd033162be528a5319cb54966dd72d4359611f/jsonToCsv-1.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}