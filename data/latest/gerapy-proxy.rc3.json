{
  "info": {
    "author": "Germey",
    "author_email": "cqc@cuiqingcai.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: Implementation :: CPython",
      "Programming Language :: Python :: Implementation :: PyPy"
    ],
    "description": "\n# Gerapy Proxy\n\nThis is a package for supporting proxy with async mechanism in Scrapy, also this\npackage is a module in [Gerapy](https://github.com/Gerapy/Gerapy).\n\n## Installation\n\n```shell script\npip3 install gerapy-proxy\n```\n\n## Usage\n\nIf you have a ProxyPool which can provide a random proxy for every request, you can use this package\nto integrate proxy into your Scrapy/Gerapy Project.\n\nFor example, there is a [ProxyPool API](https://proxypool.scrape.center/random) which can return a random proxy \nper time, we can configure `GERAPY_PROXY_POOL_URL` setting provided by this package to enable proxy for every Scrapy Request.\n\nTo use this package, firstly install it and then enable it in DownloadMiddleware:\n\n```python\nDOWNLOADER_MIDDLEWARES = {\n    'gerapy_proxy.middlewares.ProxyPoolMiddleware': 543,\n}\n```\n\nand add proxy url in settings:\n\n```shell script\nGERAPY_PROXY_POOL_URL = 'https://proxypool.scrape.center/random'\n```\n\nThis ProxyPool is configured based on this [ProxyPool](https://github.com/Python3WebSpider/ProxyPool) repo, you can\nalso build your own ProxyPool service.\n\nNow, you've finished it.\n\nThe `ProxyPoolMiddleware` will firstly fetch a proxy from `GERAPY_PROXY_POOL_URL` and set `meta.proxy` attribute\nto Scrapy Reqeust.\n\n## Configuration\n\n### Basic Auth\n\nIf your ProxyPool has Basic Auth, you can enable it by configuring these settings:\n\n```shell script\nGERAPY_PROXY_POOL_AUTH = True\nGERAPY_PROXY_POOL_USERNAME = <username>\nGERAPY_PROXY_POOL_PASSWORD = <password>\n```\n\n### Min Retry Times\n\nIf you want to enable Proxy depends on the retry times, you can configure this settings:\n\n```shell script\nGERAPY_PROXY_POOL_MIN_RETRY_TIMES = 2\n```\n\nThen proxy will only work if the retry times of Request greater or equal than 2.\n\n### Random Enabled\n\nIf you want to enable the proxy randomly, you can configure the probability of enabling it:\n\n```shell script\nGERAPY_PROXY_POOL_RANDOM_ENABLE_RATE = 0.8\n```\n\nThen probability of enabling the proxy is 80%, if you configure it to 1, proxy will always be enabled.\n\n### Fetch Timeout\n\nYou can also configure the max time of fetching proxy from ProxyPool:\n\n```shell script\nGERAPY_PROXY_POOL_TIMEOUT = 5\n```\n\nAfter configuring this, if Proxy Pool does not return result in 5s, proxy will not be used.\n\n### ProxyPool Response Parser\n\nYour ProxyPool may not return the same format as [this](https://github.com/Python3WebSpider/ProxyPool) in plain text,\nyou can also define a parser to extract proxy from your ProxyPool.\n\nFor example, if your ProxyPool return this for every request:\n\n```json\n{\n  \"host\": \"111.222.223.224\",\n  \"port\": 3128\n}\n```\n\nYou can define a method like:\n\n```python\nimport json\ndef parse_result(text):\n    data = json.loads(text)\n    return f'{data.get(\"host\")}:{data.get(\"port\")}'\n\nGERAPY_PROXY_EXTRACT_FUNC = parse_result \n```\n\nThen you will get the proxy with correct format.\n\n## Example\n\nFor more detail, please see [example](./example).\n\nAlso you can directly run with Docker:\n\n```\ndocker run germey/gerapy-proxy-example\n```\n\nOutputs:\n\n```shell script\n2020-07-15 19:17:34 [scrapy.utils.log] INFO: Scrapy 2.2.0 started (bot: example)\n2020-07-15 19:17:34 [scrapy.utils.log] INFO: Versions: lxml 4.3.3.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.7.7 (default, May  6 2020, 04:59:01) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.4.0-x86_64-i386-64bit\n2020-07-15 19:17:34 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor\n2020-07-15 19:17:34 [scrapy.crawler] INFO: Overridden settings:\n{'BOT_NAME': 'example',\n 'CONCURRENT_REQUESTS': 3,\n 'DOWNLOAD_TIMEOUT': 10,\n 'NEWSPIDER_MODULE': 'example.spiders',\n 'RETRY_TIMES': 10,\n 'SPIDER_MODULES': ['example.spiders']}\n2020-07-15 19:17:34 [scrapy.extensions.telnet] INFO: Telnet Password: 33299ca0ce64f215\n2020-07-15 19:17:34 [scrapy.middleware] INFO: Enabled extensions:\n['scrapy.extensions.corestats.CoreStats',\n 'scrapy.extensions.telnet.TelnetConsole',\n 'scrapy.extensions.memusage.MemoryUsage',\n 'scrapy.extensions.logstats.LogStats']\n2020-07-15 19:17:34 [asyncio] DEBUG: Using selector: KqueueSelector\n2020-07-15 19:17:34 [scrapy.middleware] INFO: Enabled downloader middlewares:\n['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n 'gerapy_proxy.middlewares.ProxyPoolMiddleware',\n 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n2020-07-15 19:17:34 [scrapy.middleware] INFO: Enabled spider middlewares:\n['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n2020-07-15 19:17:34 [scrapy.middleware] INFO: Enabled item pipelines:\n[]\n2020-07-15 19:17:34 [scrapy.core.engine] INFO: Spider opened\n2020-07-15 19:17:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n2020-07-15 19:17:34 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n2020-07-15 19:17:34 [gerapy_proxy.middlewares] DEBUG: start to get proxy from proxy pool\n2020-07-15 19:17:34 [gerapy_proxy.middlewares] DEBUG: get proxy using kwargs {'timeout': 5, 'url': 'https://proxypool.scrape.center/random'}\n2020-07-15 19:17:35 [gerapy_proxy.middlewares] DEBUG: start to get proxy from proxy pool\n2020-07-15 19:17:35 [gerapy_proxy.middlewares] DEBUG: get proxy using kwargs {'timeout': 5, 'url': 'https://proxypool.scrape.center/random'}\n2020-07-15 19:17:35 [gerapy_proxy.middlewares] DEBUG: start to get proxy from proxy pool\n2020-07-15 19:17:35 [gerapy_proxy.middlewares] DEBUG: get proxy using kwargs {'timeout': 5, 'url': 'https://proxypool.scrape.center/random'}\n2020-07-15 19:17:35 [gerapy_proxy.middlewares] DEBUG: get proxy 113.124.94.189:9999\n2020-07-15 19:17:35 [gerapy_proxy.middlewares] DEBUG: get proxy 84.53.238.49:23500\n2020-07-15 19:17:35 [gerapy_proxy.middlewares] DEBUG: get proxy 217.150.77.31:53281\n2020-07-15 19:17:40 [scrapy.core.engine] DEBUG: Crawled (200) <POST https://httpbin.org/delay/3> (referer: None)\n2020-07-15 19:17:40 [gerapy_proxy.middlewares] DEBUG: start to get proxy from proxy pool\n2020-07-15 19:17:40 [gerapy_proxy.middlewares] DEBUG: get proxy using kwargs {'timeout': 5, 'url': 'https://proxypool.scrape.center/random'}\n2020-07-15 19:17:40 [example.spiders.httpbin] INFO: got request from 113.124.94.189 successfully, current page 1\n2020-07-15 19:17:40 [gerapy_proxy.middlewares] DEBUG: get proxy 144.52.244.3:9999\n2020-07-15 19:17:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <POST https://httpbin.org/delay/3> (failed 1 times): User timeout caused connection failure: Getting https://httpbin.org/delay/3 took longer than 10.0 seconds..\n2020-07-15 19:17:45 [gerapy_proxy.middlewares] DEBUG: start to get proxy from proxy pool\n2020-07-15 19:17:45 [gerapy_proxy.middlewares] DEBUG: get proxy using kwargs {'timeout': 5, 'url': 'https://proxypool.scrape.center/random'}\n2020-07-15 19:17:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <POST https://httpbin.org/delay/3> (failed 1 times): User timeout caused connection failure: Getting https://httpbin.org/delay/3 took longer than 10.0 seconds..\n2020-07-15 19:17:45 [gerapy_proxy.middlewares] DEBUG: start to get proxy from proxy pool\n2020-07-15 19:17:45 [gerapy_proxy.middlewares] DEBUG: get proxy using kwargs {'timeout': 5, 'url': 'https://proxypool.scrape.center/random'}\n2020-07-15 19:17:45 [gerapy_proxy.middlewares] DEBUG: get proxy 1.20.101.149:44778\n2020-07-15 19:17:45 [gerapy_proxy.middlewares] DEBUG: get proxy 105.27.116.46:56792\n```\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/Gerapy/GerapyProxy",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "gerapy-proxy",
    "package_url": "https://pypi.org/project/gerapy-proxy/",
    "platform": "",
    "project_url": "https://pypi.org/project/gerapy-proxy/",
    "project_urls": {
      "Homepage": "https://github.com/Gerapy/GerapyProxy"
    },
    "release_url": "https://pypi.org/project/gerapy-proxy/0.0.3/",
    "requires_dist": [
      "scrapy (>=2.0.0)",
      "aiohttp (>=3.6.2)"
    ],
    "requires_python": ">=3.6.0",
    "summary": "Proxy Components for Scrapy & Gerapy",
    "version": "0.0.3",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 7706392,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cb157b467440cb607647ec1bf99cfa12cc0308335e307542f6603535f28632c8",
          "md5": "465cf906e5f17b6bc4b112084970e8f5",
          "sha256": "5134dfa70f39d8108f5d2970d39c3d0a5e011913d77a38c7d68cef609589e3c5"
        },
        "downloads": -1,
        "filename": "gerapy_proxy-0.0.1-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "465cf906e5f17b6bc4b112084970e8f5",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": ">=3.6.0",
        "size": 3697,
        "upload_time": "2020-07-15T10:13:04",
        "upload_time_iso_8601": "2020-07-15T10:13:04.609631Z",
        "url": "https://files.pythonhosted.org/packages/cb/15/7b467440cb607647ec1bf99cfa12cc0308335e307542f6603535f28632c8/gerapy_proxy-0.0.1-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ac40d82581daf06d1a7b2d608e0981d313a7f62506aa254785f8f366da57f55f",
          "md5": "ae8b18d70b4d3a732c4b868efef684f4",
          "sha256": "0abf29bfa5ffe0b8e4d649eb1eeb2500997a68e921d203d7ba278c5c97797a99"
        },
        "downloads": -1,
        "filename": "gerapy-proxy-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "ae8b18d70b4d3a732c4b868efef684f4",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6.0",
        "size": 3532,
        "upload_time": "2020-07-15T10:13:07",
        "upload_time_iso_8601": "2020-07-15T10:13:07.108749Z",
        "url": "https://files.pythonhosted.org/packages/ac/40/d82581daf06d1a7b2d608e0981d313a7f62506aa254785f8f366da57f55f/gerapy-proxy-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b453ceedb0281cff8869a6e3bad03867403dbfdba9dcf27af07b8336bda9701a",
          "md5": "ed2c0b5ae0912476567858e32e592fee",
          "sha256": "15c0f4006f0b0806ccf88390fa4db8fb8596c68ce3ac61fd3ee19b9bb2c2b966"
        },
        "downloads": -1,
        "filename": "gerapy_proxy-0.0.2-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ed2c0b5ae0912476567858e32e592fee",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": ">=3.6.0",
        "size": 6572,
        "upload_time": "2020-07-15T11:15:36",
        "upload_time_iso_8601": "2020-07-15T11:15:36.298782Z",
        "url": "https://files.pythonhosted.org/packages/b4/53/ceedb0281cff8869a6e3bad03867403dbfdba9dcf27af07b8336bda9701a/gerapy_proxy-0.0.2-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1b982179b649377c35f38bfa591aa452bdeeb35e771a8c6a2c2f15009380fcb4",
          "md5": "593b928d8554a464f9ea44b5ec5131bf",
          "sha256": "0fa86977c36b9efeee636214301c11263cae991c862211e848a07236c71656d2"
        },
        "downloads": -1,
        "filename": "gerapy-proxy-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "593b928d8554a464f9ea44b5ec5131bf",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6.0",
        "size": 7912,
        "upload_time": "2020-07-15T11:15:37",
        "upload_time_iso_8601": "2020-07-15T11:15:37.694003Z",
        "url": "https://files.pythonhosted.org/packages/1b/98/2179b649377c35f38bfa591aa452bdeeb35e771a8c6a2c2f15009380fcb4/gerapy-proxy-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0dda4a18d37737e1149f9c76bb8a964a163b754ca1965025c3cbfeb73106089a",
          "md5": "ad75d81d198e360f30da6e5cb8756175",
          "sha256": "82aaa44a59e962f2ed2c11fb08a15cffc1de7fec5739892ca98746acfbc2652c"
        },
        "downloads": -1,
        "filename": "gerapy_proxy-0.0.3-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ad75d81d198e360f30da6e5cb8756175",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": ">=3.6.0",
        "size": 6518,
        "upload_time": "2020-07-15T15:31:09",
        "upload_time_iso_8601": "2020-07-15T15:31:09.989047Z",
        "url": "https://files.pythonhosted.org/packages/0d/da/4a18d37737e1149f9c76bb8a964a163b754ca1965025c3cbfeb73106089a/gerapy_proxy-0.0.3-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c1d92578b2ec60309e87d0c7c30e7a788a8693b54620864615e0fda5a7dfba6b",
          "md5": "116b4b6569eee30779848ff76dccb9fc",
          "sha256": "cd8582a34edef97bfa3aa9113e1f736e2ca78e6c91539c5aa6a16ca28c1ab2d5"
        },
        "downloads": -1,
        "filename": "gerapy-proxy-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "116b4b6569eee30779848ff76dccb9fc",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6.0",
        "size": 7485,
        "upload_time": "2020-07-15T15:31:11",
        "upload_time_iso_8601": "2020-07-15T15:31:11.418786Z",
        "url": "https://files.pythonhosted.org/packages/c1/d9/2578b2ec60309e87d0c7c30e7a788a8693b54620864615e0fda5a7dfba6b/gerapy-proxy-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "0dda4a18d37737e1149f9c76bb8a964a163b754ca1965025c3cbfeb73106089a",
        "md5": "ad75d81d198e360f30da6e5cb8756175",
        "sha256": "82aaa44a59e962f2ed2c11fb08a15cffc1de7fec5739892ca98746acfbc2652c"
      },
      "downloads": -1,
      "filename": "gerapy_proxy-0.0.3-py2.py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "ad75d81d198e360f30da6e5cb8756175",
      "packagetype": "bdist_wheel",
      "python_version": "py2.py3",
      "requires_python": ">=3.6.0",
      "size": 6518,
      "upload_time": "2020-07-15T15:31:09",
      "upload_time_iso_8601": "2020-07-15T15:31:09.989047Z",
      "url": "https://files.pythonhosted.org/packages/0d/da/4a18d37737e1149f9c76bb8a964a163b754ca1965025c3cbfeb73106089a/gerapy_proxy-0.0.3-py2.py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "c1d92578b2ec60309e87d0c7c30e7a788a8693b54620864615e0fda5a7dfba6b",
        "md5": "116b4b6569eee30779848ff76dccb9fc",
        "sha256": "cd8582a34edef97bfa3aa9113e1f736e2ca78e6c91539c5aa6a16ca28c1ab2d5"
      },
      "downloads": -1,
      "filename": "gerapy-proxy-0.0.3.tar.gz",
      "has_sig": false,
      "md5_digest": "116b4b6569eee30779848ff76dccb9fc",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6.0",
      "size": 7485,
      "upload_time": "2020-07-15T15:31:11",
      "upload_time_iso_8601": "2020-07-15T15:31:11.418786Z",
      "url": "https://files.pythonhosted.org/packages/c1/d9/2578b2ec60309e87d0c7c30e7a788a8693b54620864615e0fda5a7dfba6b/gerapy-proxy-0.0.3.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}