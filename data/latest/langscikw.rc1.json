{
  "info": {
    "author": "Noel Simmel",
    "author_email": "noelsimmel@protonmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Developers",
      "Intended Audience :: End Users/Desktop",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: GNU General Public License v3 (GPLv3)",
      "License :: OSI Approved :: MIT License",
      "Natural Language :: English",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3 :: Only",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Topic :: Scientific/Engineering :: Information Analysis",
      "Topic :: Software Development :: Libraries :: Python Modules",
      "Topic :: Text Processing :: Indexing",
      "Topic :: Text Processing :: Linguistic"
    ],
    "description": "# Keyword extraction from langsci publications\n\n```langscikw``` is a Python package and command line tool for bigram keyterm extraction. It is optimized for long, English, linguistic publications and can also be applied to TeX code.\n\nKeyword extraction is done in three steps. No preprocessing is needed.\n* **Step 1:** KWE from the input document using [YAKE](https://pypi.org/project/yake/). This is the simplest step as it doesn't need a corpus and should extract the most important keywords.\n* **Step 2:** KWE using [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) trained on a raw TeX corpus. This step yields some more general keywords relevant to the linguistic discipline.\n* **Step 3:** KWE using TF-IDF trained on a detexed corpus. This step fills in some missing keywords that also appear in a reference corpus of 10,000 previously accepted keywords, ```keywordslist.txt```.\n\nThe number of steps can be controlled by (not) providing the relevant corpora during training. The result needs some manual correction and supplementation of relevant unigrams or trigrams.\n\n\n# Installation\n```cmd\npip3 install langscikw\n```\n\nDeveloped in Python 3.7.3 32-bit. Needs at least Python 3.7 and the following packages: jellyfish, joblib, networkx, scikit-learn, segtok, regex.\n\nDownload the langsci corpus files from [here](https://github.com/langsci/langscikw-corpus/releases/tag/v1.0.1) or use your own.\n\n\n# Usage\n## Command line \nThe command line tool provides only a simple interface. If you'd like to customize the model parameters or the number of steps, please see below.\n\n```cmd\nlangscikw inputfile [n] [corpus1] [corpus2] [keywordslist] [--silent]\n```\n\nThe keywords are printed to the console and can be redirected to a text file.\n\n### Arguments\n* ```inputfile```: Path to a .txt or .tex file or directory from which to extract keywords.\n* ```n```: *Optional* Number of keywords to extract. Defaults to 300.\n* ```corpus1```: *Optional* Path to corpus for step 2, usually raw TeX files or a [joblib-compressed](https://joblib.readthedocs.io/en/latest/generated/joblib.dump.html#joblib.dump) file. If not provided, looks for corpus_tex.gz in the current directory.\n* ```corpus2```: *Optional* Path to corpus for step 3, usually detexed files or a [joblib-compressed](https://joblib.readthedocs.io/en/latest/generated/joblib.dump.html#joblib.dump) file. If not provided, looks for corpus_detexed.gz in the current directory.\n* ```keywordslist```: *Optional* Path to a list of gold keywords for step 3. A default list based on langsci publications is installed with the package.\n* ```--silent```: *Optional* Only print the result to the console, no progress updates.\n\n## KWE class\n```python\nimport langscikw\ninput_path = \"my_book\"              # File/directory to extract keywords from\nkeywords_path = \"keywords.txt\"      # File to save keywords to\n\nkwe = langscikw.KWE()\nkwe.train(\"corpus_tex.gz\", \"corpus_detexed.gz\")\nkws = kwe.extract_keywords(input_path, n=300, dedup_lim=0.85)\nfor kw in kws:\n    print(kw)                       # Keywords are alphabetically sorted strings\n```\n\n### Keyword arguments\n* ```n```: *Optional* Number of keywords to extract. Defaults to 300.\n* ```dedup_lim```: *Optional* Deduplication limit. Keywords that have a Jaro-Winkler Similarity of >dedup_lim are not added to the final list. Defaults to 0.85.\n\n\n## Stand-alone models\nThe YAKE and TF-IDF models may also be used on their own. Please consult the docstrings for more information.\n\n```python\nimport langscikw\nyake = langscikw.yakemodel.YakeExtractor()      # -> extract_keywords()\ntfidf = langscikw.tfidfmodel.TfidfExtractor()   # -> train() -> extract_keywords()\n```\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://pypi.python.org/pypi/langscikw",
    "keywords": "langsci keywordextraction indexing keywords naturallanguageprocessing nlp",
    "license": "LGPLv3",
    "maintainer": "",
    "maintainer_email": "",
    "name": "langscikw",
    "package_url": "https://pypi.org/project/langscikw/",
    "platform": "",
    "project_url": "https://pypi.org/project/langscikw/",
    "project_urls": {
      "Bug Reports": "https://github.com/langsci/langscikw/issues",
      "Homepage": "https://pypi.python.org/pypi/langscikw",
      "Language Science Press": "https://langsci-press.org/",
      "Source": "https://github.com/langsci/langscikw"
    },
    "release_url": "https://pypi.org/project/langscikw/0.0.1/",
    "requires_dist": [
      "scikit-learn (==0.24.2)",
      "regex (==2021.4.4)",
      "jellyfish",
      "joblib",
      "networkx (==2.5.1)",
      "segtok"
    ],
    "requires_python": ">=3.7, <4",
    "summary": "Keyword extraction from linguistic publications",
    "version": "0.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 10611562,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f9401079ae7fdce1cbab50b8f64b7d63ad2e8c50ec62dd0a0471edff6e5363fc",
          "md5": "0a914afed6383cfdd1c893f3521a04c8",
          "sha256": "b3f87092ca9668c8c050863d9ec84a9b46861b96ac04c595930bf071f40e4d9a"
        },
        "downloads": -1,
        "filename": "langscikw-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0a914afed6383cfdd1c893f3521a04c8",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7, <4",
        "size": 90316,
        "upload_time": "2021-06-10T12:30:30",
        "upload_time_iso_8601": "2021-06-10T12:30:30.503129Z",
        "url": "https://files.pythonhosted.org/packages/f9/40/1079ae7fdce1cbab50b8f64b7d63ad2e8c50ec62dd0a0471edff6e5363fc/langscikw-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cadd9d6ef126837b7c5857ccaa07a0b1fa7e16b24fbaa9583e08feddb58ac455",
          "md5": "27e6435aca42e7db2176deedea406c74",
          "sha256": "999fc399e47335fb6c2fe813896f55ebfc5accbbe313890bdc754d94167adb4c"
        },
        "downloads": -1,
        "filename": "langscikw-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "27e6435aca42e7db2176deedea406c74",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7, <4",
        "size": 90052,
        "upload_time": "2021-06-10T12:30:32",
        "upload_time_iso_8601": "2021-06-10T12:30:32.199546Z",
        "url": "https://files.pythonhosted.org/packages/ca/dd/9d6ef126837b7c5857ccaa07a0b1fa7e16b24fbaa9583e08feddb58ac455/langscikw-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "f9401079ae7fdce1cbab50b8f64b7d63ad2e8c50ec62dd0a0471edff6e5363fc",
        "md5": "0a914afed6383cfdd1c893f3521a04c8",
        "sha256": "b3f87092ca9668c8c050863d9ec84a9b46861b96ac04c595930bf071f40e4d9a"
      },
      "downloads": -1,
      "filename": "langscikw-0.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "0a914afed6383cfdd1c893f3521a04c8",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7, <4",
      "size": 90316,
      "upload_time": "2021-06-10T12:30:30",
      "upload_time_iso_8601": "2021-06-10T12:30:30.503129Z",
      "url": "https://files.pythonhosted.org/packages/f9/40/1079ae7fdce1cbab50b8f64b7d63ad2e8c50ec62dd0a0471edff6e5363fc/langscikw-0.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "cadd9d6ef126837b7c5857ccaa07a0b1fa7e16b24fbaa9583e08feddb58ac455",
        "md5": "27e6435aca42e7db2176deedea406c74",
        "sha256": "999fc399e47335fb6c2fe813896f55ebfc5accbbe313890bdc754d94167adb4c"
      },
      "downloads": -1,
      "filename": "langscikw-0.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "27e6435aca42e7db2176deedea406c74",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7, <4",
      "size": 90052,
      "upload_time": "2021-06-10T12:30:32",
      "upload_time_iso_8601": "2021-06-10T12:30:32.199546Z",
      "url": "https://files.pythonhosted.org/packages/ca/dd/9d6ef126837b7c5857ccaa07a0b1fa7e16b24fbaa9583e08feddb58ac455/langscikw-0.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}