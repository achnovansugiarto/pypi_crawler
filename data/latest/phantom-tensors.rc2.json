{
  "info": {
    "author": "",
    "author_email": "Ryan Soklaski <rsoklaski@gmail.com>, Justin Goodwin <jgoodwin@ll.mit.edu>",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3 :: Only",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.11",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Topic :: Scientific/Engineering"
    ],
    "description": "# Phantom Tensors\n> Tensor types with variadic shapes, for any array-based library, that work with both static and runtime type checkers\n\n<p align=\"center\">\n  <a href=\"https://pypi.python.org/pypi/phantom-tensors\">\n    <img src=\"https://img.shields.io/pypi/v/phantom-tensors.svg\" alt=\"PyPI\" />\n  </a>\n</p>\n\n\n**This project is currently just a rough prototype! Inspired by: [phantom-types](https://github.com/antonagestam/phantom-types)**\n\nThe goal of this project is to let users write tensor-like types with variadic shapes (via [PEP 646](https://peps.python.org/pep-0646/)) that are: \n- Amendable to **static type checking (without mypy plugins)**. \n    > E.g., pyright can tell the difference between `Tensor[Batch, Channel]` and `Tensor[Batch, Feature]`\n- Useful for performing **runtime checks of tensor types and shapes**. \n    > E.g.,  can validate -- at runtime -- that arrays of types `NDArray[A, B]` and `NDArray[B, A]` indeed have transposed shapes with respect with each other.\n- Compatible with *any* array-based library (numpy, pytorch, xarray, cupy, mygrad, etc.)\n    > E.g. A function annotated with `x: torch.Tensor` can be passed `phantom_tensors.torch.Tensor[N, B, D]`. It is trivial to write custom phantom-tensor flavored types for any array-based library.\n\n`phantom_tensors.parse` makes it easy to declare shaped tensor types in a way that static type checkers understand, and that are validated at runtime:\n\n```python\nfrom typing import NewType\n\nimport numpy as np\n\nfrom phantom_tensors import parse\nfrom phantom_tensors.numpy import NDArray\n\nA = NewType(\"A\", int)\nB = NewType(\"B\", int)\n\n# static: declare that x is of type NDArray[A, B]\n#         declare that y is of type NDArray[B, A]\n# runtime: check that shapes (2, 3) and (3, 2)\n#          match (A, B) and (B, A) pattern across\n#          tensors\nx, y = parse(\n    (np.ones((2, 3)), NDArray[A, B]),\n    (np.ones((3, 2)), NDArray[B, A]),\n)\n\nx  # static type checker sees: NDArray[A, B]\ny  # static type checker sees: NDArray[B, A]\n\n```\n\nPassing inconsistent types to `parse` will result in a runtime validation error.\n```python\n# Runtime: Raises `ParseError` A=10 and A=2 do not match\nz, w = parse(\n    (np.ones((10, 3)), NDArray[A, B]),\n    (np.ones((3, 2)), NDArray[B, A]),\n)\n```\n\nThese shaped tensor types are amenable to static type checking:\n\n```python\nfrom typing import Any\n\nimport numpy as np\n\nfrom phantom_tensors import parse\nfrom phantom_tensors.numpy import NDArray\nfrom phantom_tensors.alphabet import A, B  # these are just NewType(..., int) types\n\ndef func_on_2d(x: NDArray[Any, Any]): ...\ndef func_on_3d(x: NDArray[Any, Any, Any]): ...\ndef func_on_any_arr(x: np.ndarray): ...\n\n# runtime: ensures shape of arr_3d matches (A, B, A) patterns\narr_3d = parse(np.ones((3, 5, 3)), NDArray[A, B, A])\n\nfunc_on_2d(arr_3d)  # static type checker: Error!  # expects 2D arr, got 3D\n\nfunc_on_3d(arr_3d)  # static type checker: OK\nfunc_on_any_arr(arr_3d)  # static type checker: OK\n```\n\n\nWrite easy-to-understand interfaces using common dimension names (or make up your own):\n\n```python\nfrom phantom_tensors.torch import Tensor\nfrom phantom_tensors.words import Batch, Embed, Vocab\n\ndef embedder(x: Tensor[Batch, Vocab]) -> Tensor[Batch, Embed]:\n    ...\n```\n\n\nUsing a runtime type checker, such as [beartype](https://github.com/beartype/beartype) or [typeguard](https://github.com/agronholm/typeguard), in conjunction with `phantom_tensors` means that the typed shape information will be validated at runtime across a function's inputs and outputs, whenever that function is called.\n\n```python\nfrom typing import TypeVar, cast\nfrom typing_extensions import assert_type\n\nimport torch as tr\nfrom beartype import beartype\n\nfrom phantom_tensors import dim_binding_scope, parse\nfrom phantom_tensors.torch import Tensor\nfrom phantom_tensors.alphabet import A, B, C\n\nT1 = TypeVar(\"T1\")\nT2 = TypeVar(\"T2\")\nT3 = TypeVar(\"T3\")\n\n\n@dim_binding_scope\n@beartype  # <- adds runtime type checking to function's interfaces\ndef buggy_matmul(x: Tensor[T1, T2], y: Tensor[T2, T3]) -> Tensor[T1, T3]:\n    # This is the wrong operation!\n    # Will return shape-(T1, T1) tensor, not (T1, T3)\n    out = x @ x.T\n    \n    # We lie to the static type checker to try to get away with it\n    return cast(Tensor[T1, T3], out)\n\nx, y = parse(\n    (tr.ones(3, 4), Tensor[A, B]),\n    (tr.ones(4, 5), Tensor[B, C]),\n)\n\n# At runtime beartype raises:\n#   Function should return shape-(A, C) but returned shape-(A, A)\nz = buggy_matmul(x, y)  # Runtime validation error!\n\n```\n\n## Installation\n\n```shell\npip install phantom-tensors\n```\n\n`typing-extensions` is the only strict dependency. Using features from `phantom_tensors.torch(numpy)` requires that `torch`(`numpy`) is installed too. \n\n## Some Lower-Level Details and Features\n\nEverything on display here is achieved using relatively minimal hacks (no mypy plugin necessary, no monkeypatching). Presently, `torch.Tensor` and `numpy.ndarray` are explicitly supported by phantom-tensors, but it is trivial to add support for other array-like classes.\n\n> Note that mypy does not support PEP 646 yet, but pyright does. You can run pyright on the following examples to see that they do, indeed type-check as expected! \n\n\n### Dimension-Binding Contexts\n\n`phantom_tensors.parse` validates inputs against types-with-shapes and performs [type narrowing](https://mypy.readthedocs.io/en/latest/type_narrowing.html) so that static type checkers are privy to the newly proven type information about those inputs. It performs inter-tensor shape consistency checks within a \"dimension-binding context\". Tensor-likes that are parsed simultaneously are automatically checked within a common dimension-binding context.\n\n\n```python\nimport numpy as np\nimport torch as tr\n\nfrom phantom_tensors import parse\nfrom phantom_tensors.alphabet import A, B, C\nfrom phantom_tensors.numpy import NDArray\nfrom phantom_tensors.torch import Tensor\n\nt1, arr, t2 = parse(\n    # <- Runtime: enter dimension-binding context\n    (tr.rand(9, 2, 9), Tensor[B, A, B]),  # <-binds A=2 & B=9\n    (np.ones((2,)), NDArray[A]),  # <- checks A==2\n    (tr.rand(9), Tensor[B]),  # <- checks B==9\n)  # <- Runtime: exit dimension-binding scope \n   #    Statically: casts t1, arr, t2 to shape-typed Tensors\n\n# static type checkers now see\n# t1: Tensor[B, A, B] \n# arr: NDArray[A]\n# t2: Tensor[B]\n\nw = parse(tr.rand(78), Tensor[A]);  # <- binds A=78 within this context\n```\n\nAs indicated above, the type-checker sees the shaped-tensor/array types. Additionally, these are subclasses of their rightful parents, so we can pass these to functions typed with vanilla `torch.Tensor` and `numpy.ndarry` annotations, and type checkers will be a-ok with that.\n\n```python\ndef vanilla_numpy(x: np.ndarray): ...\ndef vanilla_torch(x: tr.Tensor): ...\n\nvanilla_numpy(arr)  # type checker: OK\nvanilla_torch(arr)  # type checker: Error! \nvanilla_torch(t1)  # type checker: OK \n```\n\n#### Basic forms of runtime validation performed by `parse`\n\n```python\n# runtime type checking\n>>> parse(1, Tensor[A])\n---------------------------------------------------------------------------\nParseError: Expected <class 'torch.Tensor'>, got: <class 'int'>\n\n# dimensionality mismatch\n>>> parse(tr.ones(3), Tensor[A, A, A])\n---------------------------------------------------------------------------\nParseError: shape-(3,) doesn't match shape-type (A=?, A=?, A=?)\n\n# unsatisfied shape pattern\n>>> parse(tr.ones(1, 2), Tensor[A, A])\n---------------------------------------------------------------------------\nParseError: shape-(1, 2) doesn't match shape-type (A=1, A=1)\n\n# inconsistent dimension sizes across tensors\n>>> x, y = parse(\n...     (tr.ones(1, 2), Tensor[A, B]),\n...     (tr.ones(4, 1), Tensor[B, A]),\n... )\n\n---------------------------------------------------------------------------\nParseError: shape-(4, 1) doesn't match shape-type (B=2, A=1)\n```\n\nTo reiterate, `parse` is able to compare shapes across multiple tensors by entering into a \"dimension-binding scope\".\nOne can enter into this context explicitly:\n\n```python\n>>> from phantom_tensors import dim_binding_scope\n\n>>> x = parse(np.zeros((2,)), NDArray[B])  # binds B=2\n>>> y = parse(np.zeros((3,)), NDArray[B])  # binds B=3\n>>> with dim_binding_scope:\n...     x = parse(np.zeros((2,)), NDArray[B])  # binds B=2\n...     y = parse(np.zeros((3,)), NDArray[B])  # raises!\n---------------------------------------------------------------------------\nParseError: shape-(3,) doesn't match shape-type (B=2,)\n```\n\n#### Support for `Literal` dimensions:\n\n```python\nfrom phantom_tensors import parse\nfrom phantom_tensors.torch import Tensor\n\nimport torch as tr\nfrom typing_extensions import Literal as L\n\nparse(tr.zeros(1, 3), Tensor[L[1], L[3]])  # static + runtime: OK\nparse(tr.zeros(2, 3), Tensor[L[1], L[3]])  #  # Runtime: ParseError - mismatch at dim 0\n```\n\n#### Support for `Literal` dimensions and variadic shapes:\n\nIn Python 3.11 you can write shape types like `Tensor[int, *Ts, int]`, where `*Ts` represents 0 or more optional entries between two required dimensions. phantom-tensor supports this \"unpack\" dimension. In this README we opt for `typing_extensions.Unpack[Ts]` instead of `*Ts` for the sake of backwards compatibility.\n\n```python\nfrom phantom_tensors import parse\nfrom phantom_tensors.torch import Tensor\n\nimport torch as tr\nfrom typing_extensions import Unpack as U, TypeVarTuple\n\nTs = TypeVarTuple(\"Ts\")\n\n# U[Ts] represents an arbitrary number of entries\nparse(tr.ones(1, 3), Tensor[int, U[Ts], int)  # static + runtime: OK\nparse(tr.ones(1, 0, 0, 0, 3), Tensor[int, U[Ts], int])  # static + runtime: OK\n\nparse(tr.ones(1, ), Tensor[int, U[Ts], int])  # Runtime: Not enough dimensions\n```\n\n#### Support for [phantom types](https://github.com/antonagestam/phantom-types):\n\nSupports phatom type dimensions (i.e. `int` subclasses that override `__isinstance__` checks):\n\n```python\nfrom phantom_tensors import parse\nfrom phantom_tensors.torch import Tensor\n\nimport torch as tr\nfrom phantom import Phantom\n\nclass EvenOnly(int, Phantom, predicate=lambda x: x%2 == 0): ...\n\nparse(tr.ones(1, 0), Tensor[int, EvenOnly])  # static return type: Tensor[int, EvenOnly] \nparse(tr.ones(1, 2), Tensor[int, EvenOnly])  # static return type: Tensor[int, EvenOnly] \nparse(tr.ones(1, 4), Tensor[int, EvenOnly])  # static return type: Tensor[int, EvenOnly] \n\nparse(tr.ones(1, 3), Tensor[int, EvenOnly])  # runtime: ParseError (3 is not an even number)\n```\n\n\n\n## Compatibility with Runtime Type Checkers\n\n`parse` is not the only way to perform runtime validation using phantom tensors – they work out of the box with 3rd party runtime type checkers like [beartype](https://github.com/beartype/beartype)! How is this possible?\n\n...We do something tricky here! At, runtime `Tensor[A, B]` actually returns a [phantom type](https://github.com/antonagestam/phantom-types). This means that `isinstance(arr, NDArray[A, B])` is, at runtime, *actually* performing `isinstance(arr, PhantomNDArrayAB)`, which dynamically generated and is able to perform the type and shape checks.\n\nThanks to the ability bind dimensions within a specified context, all `beartype` needs to do is faithfully call `isinstance(...)` within said context and we can have the inputs and ouputs of a phantom-tensor-annotated function get checked!\n\n```python\nfrom typing import Any\n\nfrom beartype import beartype  # type: ignore\nimport pytest\nimport torch as tr\n\nfrom phantom_tensors.alphabet import A, B, C\nfrom phantom_tensors.torch import Tensor\nfrom phantom_tensors import dim_binding_scope, parse\n\n# @dim_binding_scope:\n#   ensures A, B, C consistent across all input/output tensor shapes\n#   within scope of function\n@dim_binding_scope \n@beartype  # <-- adds isinstance checks on inputs & outputs\ndef matrix_multiply(x: Tensor[A, B], y: Tensor[B, C]) -> Tensor[A, C]:\n    a, _ = x.shape\n    _, c = y.shape\n    return parse(tr.rand(a, c), Tensor[A, C])\n\n@beartype\ndef needs_vector(x: Tensor[Any]): ...\n\nx, y = parse(\n    (tr.rand(3, 4), Tensor[A, B]),\n    (tr.rand(4, 5), Tensor[B, C]),\n)\n\nz = matrix_multiply(x, y)\nz  # type revealed: Tensor[A, C]\n\nwith pytest.raises(Exception):\n    # beartype raises error: input Tensor[A, C] doesn't match Tensor[A]\n    needs_vector(z)  # <- pyright also raises an error!\n\nwith pytest.raises(Exception):\n    # beartype raises error: inputs Tensor[A, B], Tensor[A, B] don't match signature\n    matrix_multiply(x, x)  # <- pyright also raises an error!\n```\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "machine learning,research,configuration,scalable,reproducible,yaml,Hydra,dataclass",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "Justin Goodwin <jgoodwin@ll.mit.edu>",
    "name": "phantom-tensors",
    "package_url": "https://pypi.org/project/phantom-tensors/",
    "platform": null,
    "project_url": "https://pypi.org/project/phantom-tensors/",
    "project_urls": {
      "Bug Reports": "https://github.com/rsokl/phantom-tensors/issues",
      "Homepage": "https://github.com/rsokl/phantom-tensors/",
      "Source": "https://github.com/rsokl/phantom-tensors"
    },
    "release_url": "https://pypi.org/project/phantom-tensors/0.2.0/",
    "requires_dist": [
      "typing-extensions (>=4.1.0)",
      "beartype (>=0.10.4) ; extra == 'test'",
      "pytest (>=3.8) ; extra == 'test'",
      "hypothesis (>=6.28.0) ; extra == 'test'"
    ],
    "requires_python": ">=3.7",
    "summary": "Configurable, reproducible, and scalable workflows in Python, via Hydra",
    "version": "0.2.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17209322,
  "releases": {
    "0.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4266ac7d6005098e73641eadd5ec9308e1c1a41482e65354741c78187d25383d",
          "md5": "a3648523b36767bb86ce5acd65576f41",
          "sha256": "bea21830a21a56879bece7d084bb24ef7c1c957c06ee522db3bc74a75ae2fac5"
        },
        "downloads": -1,
        "filename": "phantom_tensors-0.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "a3648523b36767bb86ce5acd65576f41",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 11283,
        "upload_time": "2022-10-01T19:08:27",
        "upload_time_iso_8601": "2022-10-01T19:08:27.994974Z",
        "url": "https://files.pythonhosted.org/packages/42/66/ac7d6005098e73641eadd5ec9308e1c1a41482e65354741c78187d25383d/phantom_tensors-0.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "57d167d9037d01bf43ec7a7080218a1e4796cd25da23974770fc98e28080ccac",
          "md5": "3fecfa8dcc98afe21a246ce56844e4bb",
          "sha256": "2efabc6863ac5eff94cfbb2225bf72d2384c84690c94e32abe355dc0ce6a46f4"
        },
        "downloads": -1,
        "filename": "phantom_tensors-0.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "3fecfa8dcc98afe21a246ce56844e4bb",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 30647,
        "upload_time": "2022-10-01T19:08:31",
        "upload_time_iso_8601": "2022-10-01T19:08:31.304328Z",
        "url": "https://files.pythonhosted.org/packages/57/d1/67d9037d01bf43ec7a7080218a1e4796cd25da23974770fc98e28080ccac/phantom_tensors-0.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "36ec46ca8b2bb5eb490c3b29c05577461e2fe2b48875696a8717a38927a7a265",
          "md5": "bd65d61bf4d5785d5bcb197c86bb3265",
          "sha256": "d9946929342a7ed7ad5d606c778ea21b0120f6e1843541335a2a1e94c96bec40"
        },
        "downloads": -1,
        "filename": "phantom_tensors-0.2.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "bd65d61bf4d5785d5bcb197c86bb3265",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 16517,
        "upload_time": "2023-03-08T16:25:34",
        "upload_time_iso_8601": "2023-03-08T16:25:34.929785Z",
        "url": "https://files.pythonhosted.org/packages/36/ec/46ca8b2bb5eb490c3b29c05577461e2fe2b48875696a8717a38927a7a265/phantom_tensors-0.2.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a033a34f6dac196e132e239d3b43596ba7fc06096dd2a1712c492497f24b47d5",
          "md5": "6ef2556e43564cf2525095fdc700b502",
          "sha256": "ff42494fbbb8892ce079354caded043e6e44f1c03723a20a61364a8ee2c156e6"
        },
        "downloads": -1,
        "filename": "phantom_tensors-0.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "6ef2556e43564cf2525095fdc700b502",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 26076,
        "upload_time": "2023-03-08T16:25:36",
        "upload_time_iso_8601": "2023-03-08T16:25:36.773439Z",
        "url": "https://files.pythonhosted.org/packages/a0/33/a34f6dac196e132e239d3b43596ba7fc06096dd2a1712c492497f24b47d5/phantom_tensors-0.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "36ec46ca8b2bb5eb490c3b29c05577461e2fe2b48875696a8717a38927a7a265",
        "md5": "bd65d61bf4d5785d5bcb197c86bb3265",
        "sha256": "d9946929342a7ed7ad5d606c778ea21b0120f6e1843541335a2a1e94c96bec40"
      },
      "downloads": -1,
      "filename": "phantom_tensors-0.2.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "bd65d61bf4d5785d5bcb197c86bb3265",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 16517,
      "upload_time": "2023-03-08T16:25:34",
      "upload_time_iso_8601": "2023-03-08T16:25:34.929785Z",
      "url": "https://files.pythonhosted.org/packages/36/ec/46ca8b2bb5eb490c3b29c05577461e2fe2b48875696a8717a38927a7a265/phantom_tensors-0.2.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "a033a34f6dac196e132e239d3b43596ba7fc06096dd2a1712c492497f24b47d5",
        "md5": "6ef2556e43564cf2525095fdc700b502",
        "sha256": "ff42494fbbb8892ce079354caded043e6e44f1c03723a20a61364a8ee2c156e6"
      },
      "downloads": -1,
      "filename": "phantom_tensors-0.2.0.tar.gz",
      "has_sig": false,
      "md5_digest": "6ef2556e43564cf2525095fdc700b502",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 26076,
      "upload_time": "2023-03-08T16:25:36",
      "upload_time_iso_8601": "2023-03-08T16:25:36.773439Z",
      "url": "https://files.pythonhosted.org/packages/a0/33/a34f6dac196e132e239d3b43596ba7fc06096dd2a1712c492497f24b47d5/phantom_tensors-0.2.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}