{
  "info": {
    "author": "Tommy",
    "author_email": "tooooommy@163.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: Implementation :: CPython",
      "Programming Language :: Python :: Implementation :: PyPy"
    ],
    "description": "<div align=center>\n<img src=\"./spider.png\">\n</div>\n\n## 描述\nrequests_spider 是一个轻量级的异步爬虫框架，基于requests_html进行二次开发，类似flask\n\n## 安装\npip install requests_spider\n\n## 依赖\npython: > 3.6\nuvloop\nrequests_html\n\n## 用法\n##### 基础例子\n```python3\nimport json\nfrom spider import XField, Spider, Model, Response, Request\n\n\nclass Proxy(Model):\n    ip = XField(rule='//tr[contains(@class, \"odd\")]/td[2]', first=False)\n    port = XField(rule='//tr[contains(@class, \"odd\")]/td[3]', first=False)\n\n    async def process(self, response: Response):\n        with open('proxy1.txt', 'a+') as file:\n            for result in self.merge():\n                file.write(json.dumps(result) + '\\n')\n\n\nspider = Spider('proxy', workers=15)\nspider.domains = ['www.xicidaili.com']\nspider.init_requests = [\n    Request(url='http://www.xicidaili.com/nn/{}'.format(x), model=Proxy) for x in range(1, 10)\n]\n\nspider.async_limit = 5\n\nif __name__ == '__main__':\n    spider.run()\n\n```\n爬取代理网站ip\n\n##### 中间组件\n```python3\nimport random\nimport re\n\nfrom spider import Spider, Request, XRequest, Model, XField, RField, Response, Field, asyncio\n\n# 获取某个用户的所有的视频信息 ===> 获取aid / page\nvideos_url = \"https://space.bilibili.com/ajax/member/getSubmitVideos?mid={mid}\" \\\n             \"&pagesize=30&tid=0&page={page}&keyword=&order=pubdate\"\n\n# 某个视频推荐的视频  ===> 获取aid\nrecommend_url = \"https://comment.bilibili.com/playtag,{cid}-{aid}?html5=1\"\n\n# 用户信息 post csrf/mid\nuser_url = \"https://space.bilibili.com/ajax/member/GetInfo\"\n\n# av页面，====> 获取下载视频的url、cid-aid, mid\nav_url = \"https://www.bilibili.com/video/av{aid}\"\n\n\nclass AV(Model):\n    urls = RField(rule='\"url\":\"(.*?)\",\"backup_url\"', first=False)\n    cid = RField(rule='cid=(.*?)&aid=')\n    aid = RField(rule='&aid=(.*?)&pre_ad=')\n    mid = RField(rule='\"owner\":{\"mid\":(.*?),')\n\n    async def process(self, response: Response):\n        print(self['urls'])\n        print(self['cid'])\n        print(self['aid'])\n        print(self['mid'])\n        print(self.json())\n        if self['mid'] and self['aid'] and self['urls'] and self['cid']:\n            # 推荐视频\n            yield Request(url=recommend_url.format(cid=self['cid'], aid=self['aid']), model=Recommend)\n\n            # 用户信息\n            yield Request(url=user_url, method='POST', data={'csrf': '', 'mid': self['mid']},\n                          model=UserInfo, not_filter=True)\n\n            # 下载视频\n            for order, url in enumerate(self['urls']):\n                yield Request(url=url.replace('http', 'https'),\n                              meta={'name': self['aid'] + '_' + str(order)}, model=Video)\n\n\nclass UserInfo(Model):\n    mid = Field()\n    name = Field()\n    sex = Field()\n    rank = Field()\n    face = Field()\n    regtime = Field()\n    birthday = Field()\n    sign = Field()\n    level_info = Field()\n\n    async def process(self, response: Response):\n        status = response.json().get('status')\n        if status:\n            data = response.json().get('data')\n            for k in self.keys():\n                if k in data:\n                    self[k] = data[k]\n            with open('user_' + str(self['mid']) + '.txt', 'w') as f:\n                f.write(self.dumps() + '\\n')\n\n\nclass Recommend(Model):\n\n    async def process(self, response: Response):\n        for data in response.json():\n            yield Request(av_url.format(aid=data[1]), model=AV)\n\n\nclass VideoInfo(Model):\n\n    async def process(self, response: Response):\n        status = response.json().get('status')\n        if status:\n            data = response.json().get('data')\n            pattern = 'mid=(\\d+?)&pagesize=30&tid=0&page=(\\d+?)&keyword=&order=pubdate'\n            patn = re.findall(pattern, response.url)[0]\n            print(patn)\n            yield Request(url=videos_url.format(mid=patn[0], page=int(patn[1]) + 1), model=VideoInfo),\n            for v in data['vlist']:\n                yield Request(url=av_url.format(aid=v.get('aid')), model=AV)\n\n\nclass Video(Model):\n\n    async def process(self, response: Response):\n        file_name = response.current_request.meta.get('name')\n        if file_name and response.status_code == 200:\n            with open(file_name + '.mp4', 'wb') as f:\n                for content in response.iter_content(chunk_size=512):\n                    f.write(content)\n                    f.flush()\n\n\nspider = Spider('bilibili', workers=5)\n\nspider.init_requests = [\n    Request(url=videos_url.format(mid='35789774', page=1), model=VideoInfo),\n]\nspider.async_limit = 5\n\n\n@spider.Middleware('request')\nasync def test(request):\n    print(request.url)\n    if request.url.startswith('https://space.bilibili.com/'):\n        request.info.update({'headers': {'Referer': 'https://space.bilibili.com/'}})\n    else:\n        request.info.update({'headers': {'Referer': 'https://bilibili.com/'}})\n\n    asyncio.sleep(round(random.random() * 5))\n    return request\n\n\nif __name__ == '__main__':\n    spider.run()\n```\n爬取bilibili用户视频，用户资料，视频资料，利用中间组件进行切换headers\n\n## API\n#### Spider\n继承requests_html的HTMLSession\n\n- **Spider.async_limit**\n\n    利用asyncio.Semaphore限制并发数量\n\n\n- **Spider.queue_timeout**\n\n    从队列获取数据时候超时设置\n\n- **Spider.request_depth**\n\n    请求的深度\n\n- **Spider.init_requests**\n\n    初始化请求\n\n- **Spider.domains**\n\n    爬取域名设置\n\n- **Spider.rules**\n\n    从响应的数据中获取下次请求的信息，并加入队列\n\n- **Spider.Middleware**\n\n    中间组件\n    Middleware('request'), request入队之前执行，返回request, response, None\n    Middleware('response'), response入队之前，返回request, response, None\n\n\n##### Model\nModel类似一个字典的数据模型\n\n- **Model.keys**\n\n    类似字典的keys\n\n- **Model.values**\n\n    类似字典的values\n\n- **Model.items**\n\n    类似字典的items\n\n- **Model.json**\n\n    获取所有Field的字典形式\n\n- **Model.dumps**\n\n    获取所有的Field的字符串\n\n- **Model.merge**\n\n    当所有的Field从响应数据获取的数据是列表的时候，将获取的列表合并成为json数据\n\n- **Model.process**\n\n    处理响应数据\n\n\n##### Field\n\n- **Field**\n\n    不处理或待处理数据项\n\n- **XField**\n\n    利用xpath从响应数据中获取数据\n\n- **CField**\n\n    利用css获取数据\n\n- **RField**\n\n    利用正则获取数据\n\n##### Request\n\n- **Request**\n    正常的请求\n\n- **XRequest**\n\n    利用xpath, 用于Spider.rules\n\n- **RRequest**\n\n    利用正则，用于Spider.rules\n\n\n\n## 例子\nexamples目录下\nbilibili.py 爬取哔哩哔哩用户信息、视频信息和视频\nqidian.py 爬取起点小说月票排行包括评分\nproxy.py 爬取代理ip网站代理\npearvideo.py 爬取梨视频网站的视频\n\n# License\nMIT",
    "description_content_type": "",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/Tooooomy/requests_spider",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "requests_spider",
    "package_url": "https://pypi.org/project/requests_spider/",
    "platform": "all",
    "project_url": "https://pypi.org/project/requests_spider/",
    "project_urls": {
      "Homepage": "https://github.com/Tooooomy/requests_spider"
    },
    "release_url": "https://pypi.org/project/requests_spider/0.0.8/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "Web crawling framework like flask.",
    "version": "0.0.8",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 4260355,
  "releases": {
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "00bfe07d82bbfbdbe49e5d08f4c53684a95fe4b9dae671972f330d2a9768d07e",
          "md5": "df96cb9eecd0f428c33b90ce87ff0d47",
          "sha256": "03223fdf6bc21bbf1e5bfb9758495249deca10149e37e85830195535fb374939"
        },
        "downloads": -1,
        "filename": "requests_spider-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "df96cb9eecd0f428c33b90ce87ff0d47",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 12612,
        "upload_time": "2018-09-07T08:09:56",
        "upload_time_iso_8601": "2018-09-07T08:09:56.647047Z",
        "url": "https://files.pythonhosted.org/packages/00/bf/e07d82bbfbdbe49e5d08f4c53684a95fe4b9dae671972f330d2a9768d07e/requests_spider-0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0cd7fbb9ee4d5df258156458c58bb2d677d1c1354b5b0637ab91199a4a860403",
          "md5": "04f1f1303c2fdda0ece325481d1af1ca",
          "sha256": "3f3b19131ab9833fc609003fa034d8994f47c4f68235e43533307cd5768db86e"
        },
        "downloads": -1,
        "filename": "requests_spider-0.0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "04f1f1303c2fdda0ece325481d1af1ca",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 12648,
        "upload_time": "2018-09-09T06:08:02",
        "upload_time_iso_8601": "2018-09-09T06:08:02.718306Z",
        "url": "https://files.pythonhosted.org/packages/0c/d7/fbb9ee4d5df258156458c58bb2d677d1c1354b5b0637ab91199a4a860403/requests_spider-0.0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c3c17c1da76db49bf4ef6df90fc6eda8c2f1bfc87106bdf342381ec9c43fbb47",
          "md5": "931ca90b4e2c9e0b14c35c58366b6fd2",
          "sha256": "67c99c61583c860a848cd8060c07d51b6b0952ebb83ca53b77206cf3e7a27598"
        },
        "downloads": -1,
        "filename": "requests_spider-0.0.6.tar.gz",
        "has_sig": false,
        "md5_digest": "931ca90b4e2c9e0b14c35c58366b6fd2",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 12486,
        "upload_time": "2018-09-10T10:06:20",
        "upload_time_iso_8601": "2018-09-10T10:06:20.116188Z",
        "url": "https://files.pythonhosted.org/packages/c3/c1/7c1da76db49bf4ef6df90fc6eda8c2f1bfc87106bdf342381ec9c43fbb47/requests_spider-0.0.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1f5775e41ffe80fb003ac0a319305327b8e2cad64d8f7c59a8885c87c8616a6c",
          "md5": "248acdffd39e3f7116aae5b8ef30c3d1",
          "sha256": "b629aba23c4f4c5d1ddf5a28824cc7add3873b4d964baa0302f9fedafd5e4356"
        },
        "downloads": -1,
        "filename": "requests_spider-0.0.7.tar.gz",
        "has_sig": false,
        "md5_digest": "248acdffd39e3f7116aae5b8ef30c3d1",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 12333,
        "upload_time": "2018-09-11T07:50:12",
        "upload_time_iso_8601": "2018-09-11T07:50:12.538630Z",
        "url": "https://files.pythonhosted.org/packages/1f/57/75e41ffe80fb003ac0a319305327b8e2cad64d8f7c59a8885c87c8616a6c/requests_spider-0.0.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6bdb9db353c19606b2aefb3c876f14fe9abd69b93c9dbd8c2f6e08f2c18c902b",
          "md5": "752bd64c80de32d4a25fc14793ca2056",
          "sha256": "4133cc986b7afd9e88258bdd89073b5fa9c0ce6344df40647e4b9b625461d012"
        },
        "downloads": -1,
        "filename": "requests_spider-0.0.8.tar.gz",
        "has_sig": false,
        "md5_digest": "752bd64c80de32d4a25fc14793ca2056",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 12346,
        "upload_time": "2018-09-11T08:02:07",
        "upload_time_iso_8601": "2018-09-11T08:02:07.863978Z",
        "url": "https://files.pythonhosted.org/packages/6b/db/9db353c19606b2aefb3c876f14fe9abd69b93c9dbd8c2f6e08f2c18c902b/requests_spider-0.0.8.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "6bdb9db353c19606b2aefb3c876f14fe9abd69b93c9dbd8c2f6e08f2c18c902b",
        "md5": "752bd64c80de32d4a25fc14793ca2056",
        "sha256": "4133cc986b7afd9e88258bdd89073b5fa9c0ce6344df40647e4b9b625461d012"
      },
      "downloads": -1,
      "filename": "requests_spider-0.0.8.tar.gz",
      "has_sig": false,
      "md5_digest": "752bd64c80de32d4a25fc14793ca2056",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 12346,
      "upload_time": "2018-09-11T08:02:07",
      "upload_time_iso_8601": "2018-09-11T08:02:07.863978Z",
      "url": "https://files.pythonhosted.org/packages/6b/db/9db353c19606b2aefb3c876f14fe9abd69b93c9dbd8c2f6e08f2c18c902b/requests_spider-0.0.8.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}