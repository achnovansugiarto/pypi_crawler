{
  "info": {
    "author": "Karl Lehenbauer",
    "author_email": "Karl <support@lehenbauer.com>",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: BSD License",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9"
    ],
    "description": "# Mudflap / GPTerminator / Karl's ChatGPT helpers\n\nSorry we don't have a good name yet.  We're workshopping it with gpt-4 but we're not rushing it.\n\n## What is this shit?\n\nIt's a couple-three things.\n\n1. chatgpt program for use in shell scripts, batch workflows, etc.  (Forty years of Unix is something one wants to embrace, not fight. -- Mark Diekhans)\n2. gptshell - command-line tool for interacting with chatGPT that streams and saves.\n3. Python package for interacting with the ChatGPT API that maintains session history to permit a context-maintaining dialog, loading, saving, etc.\n\n## For any of this to work\n\nYou gotta have an OpenAI API key. Get one and set the `OPENAI_API_KEY` environment variable to have it, or use `openai api_key set <YOUR_API_KEY>`, or some other method to set your API key before proceeding.\n\n## The ChatGPT command line tool\n\n'chatgpt' is a unix/linux/macos command line tool for use in normal automated Unix workflows, for example, shell scripts.\n\nIt can read prompts from stdin, command line arguments, a file, etc.  It has a robust set of command line arguments.\n\nYou can use it in a Unix pipeline where you pipe the output of a program into it and you pipe its output to another program.\n\nA simple example use might be to translate and summarize the text of all the files in a certain directory, creating corresponding files in another directory.\n\n### Examples\n\n```bash\nchatgpt 'what is the capital of texas'\n```\n```plaintext\nThe capital of Texas is Austin.\n```\n\n```bash\nchatgpt what is the capital of indiana\n```\n```plaintext\nThe capital of Indiana is Indianapolis.\n```\n\n```bash\necho \"did mrs. o'leary's cow really kick over a lantern?\" | chatgpt\n```\n\n```bash\nchatgpt --system-prompt 'you are a computer expert and an expert russian translator' \\\n    'please give me a commented python code fragment to read the contents of stdin to a string variable, in russian'\n```\n```plaintext\n# Этот код фрагмент считывает содержимое стандартного ввода в строковую переменную\n\nimport sys\n\n# Читаем все введенные данные из стандартного ввода\ninput_data = sys.stdin.read()\n\n# Выводим считанные данные на экран\nprint(input_data)\n\n```\n\n### system prompts and user prompts\n\nA system prompt is designed to guide users or solicit specific information. It often sets the context for a conversation or interaction.\n\nSystem prompts can be specified from the command line with the `--system-prompt` argument, followed by a system prompt string, and also from a file using `--system-prompt-file`.  If both are specified both are used, with the command line prompt sent before the prompt file.\n\nA user prompt, on the other hand, is an input or question posed by an end-user to the model, seeking information, assistance, or a specific action. It reflects the user's needs or intentions.\n\nUser prompts can be specified from the command line in that whatever is on the command line that isn't a command line argument becomes the initial part of the user prompt.\n\nIf `--user-prompt-file` is specified, the named file is added to the user prompt.\n\nFinally, if `--stdin` is specified or no user prompt file argument was specified and no user prompt argument was specified on the command line, stdin is read for the user prompt and added to any user prompt that already exists.\n\nIf no user prompt is specified, the program exits without producing any output.\n\nIf a user prompt is specified, the system prompts, if any, are sent to chatGPT, and the user prompt is sent, and the reply from the assistant is sent to stdout.\n\n\n### usage\n\nusage: chatgpt [-h] [--system-prompt SYSTEM_PROMPT] [--system-prompt-file SYSTEM_PROMPT_FILE]\n               [--user-prompt-file USER_PROMPT_FILE] [--temperature TEMPERATURE] [--max-tokens MAX_TOKENS]\n               [--model MODEL] [--stdin]\n\nChatGPT shell command\n\noptions:\n  -h, --help            show this help message and exit\n  --system-prompt SYSTEM_PROMPT\n                        System prompt content\n  --system-prompt-file SYSTEM_PROMPT_FILE\n                        File containing system prompt content\n  --user-prompt-file USER_PROMPT_FILE\n                        File containing user prompt content\n  --temperature TEMPERATURE\n                        Temperature for response generation\n  --max-tokens MAX_TOKENS\n                        Maximum tokens in generated response\n  --model MODEL         Model used for response generation\n  --stdin               Read prompt from standard input\n\n\n## gptshell\n\ngptshell is an interactive program that solicits user input and enables an interactive conversation with ChatGPT.  You might think of it as a command line equivalent of the ChatGPT dialog page at https://chat.openai.com/.\n\nWhen you fire up gptshell, you get a prompt:\n```\ngpt>\n```\n\nAt this point you can type something and when you press enter it will be sent to OpenAI's chat completion API.  Like the webpage, the results will be streamed back.  If you decide you don't want to see the rest of the result, i.e. you want it to stop generating, hit control-C.\n\n```bash\n% gptshell sesh\n`gpt> was basketball originally played with a wicker basket or something?`\n\nYes, basketball was originally played with a peach basket or a woven wicker basket placed on a 10-foot-high pole. The game was invented by James Naismith in 1891, and the first basketball game was played with a soccer ball and two peach baskets as the goals. The baskets had no bottom, so players had to retrieve the ball after each score by climbing a ladder or using a stick to poke it out. The modern basketball hoop with a net was not introduced until the 1900s.\n`gpt> did they at one point have a pullstring to release the ball from the net?`\n\nYes, basketball hoops with pullstrings to release the ball from the net were used in the early 1900s. The pullstring mechanism was invented by a Canadian physical education teacher named Dr. Luther Gulick in 1906. The design featured a cord attached to the bottom of the net that ran through a pulley system and down to the ground. When a player scored a basket, they could pull the cord to release the ball from the net without having to climb up and retrieve it. The pullstring mechanism was eventually replaced by a simpler design that used a metal ring attached to the bottom of the net to allow the ball to pass through.\n```bash\ngpt>\n```\n\nApparently you can get better answers if you provide some system prompts.  Like telling it it's an expert programmer before asking it coding questions.  Here's a possible example:\n\n_You are an expert software developer. Functions should generally be limited to about 20 lines.  If longer, a subroutine should be factored.  If there is a function that processes many rows, like lines from a file, results from a SQLite SQL select, etc, and the function body is more than a few lines, factor a function that processes a single row and call it from the function that processes many rows.  The main function should handle command line arguments and set things up but it should call a function to do the work._\n\nThat's a bit of a pain to copy and paste every session, so you can specify a file containing a system prompt on the command line using `-s` or `--system-file`.\n\nIf the first character you enter at the command prompt is a percent sign, the percent sign is a command prefix that should be followed by one of our meta commands:\n\n### gptshell meta commands\n\n* %load filename - load a previous or pre-prepared conversation in RFC822 format.\n* %save filename  - save the current conversation in RFC822 format.  This is preferred for human readability.\n* %yload filename - load a previous or pre-prepared conversation in YAML format.\n* %ysave filename - save a previous or pre-prepared conversation in YAML format.\n* %jload filename - load a previous or pre-prepared conversation in JSON format.\n* %jsave filename - save a previous or pre-prepared conversation in JSON format.\n* %list - lists the conversation history, zero or more rows containing a role (user, system, or assistant) and content.\n* %history - list the conversation history in a pleasing human-readable form.\n* #! - execute remainder of input in a shell.  `#!bash` will create an interactive bash shell.  EOF will return you to gptshell.\n* #interact - interactively enter the python interpreter that is currently running gptshell.  if you control-D you will be back in gptshell.\n\n### gptshell command line arguments\n\n```\nusage: gptshell [-h] [-s SYSTEM_FILE] [-i LOAD] [-w SAVE] [-m MODEL]\n\noptions:\n  -h, --help            show this help message and exit\n  -s SYSTEM_FILE, --system-file SYSTEM_FILE\n                        the system prompt file to use\n  -i LOAD, --load LOAD  load a session from a file\n  -w SAVE, --save SAVE  save the session to a session file\n  -m MODEL, --model MODEL\n                        Model used for response generation\n```\n\nIf you say `gptshell -load sesh -save sesh`, gptshell will read in the session and save it back out after you do what you do.\n\n## python package\n\nContext-maintaining chatGPT session class\n\nThe thing where you have a conversation with ChatGPT and it has the context of what you've already been talking about as you say new things, the entire conversation is sent to the AI for each new user message.  (Sytem messages are recorded but aren't sent until there's also a user message, as system messages aren't replied to by the AI.)\n\nConsequently if you're using the openai stuff directoy, you have to do that.  GPTChatSession does that for you.  Any session can be saved or retrieved to a file, in either RFC-822, JSON or YAML format.\n\nWe find that RFC-822 is preferred because the reply text gets munged the least that way.  So if it gave you some source code or whatever, it's fit for copypasta without converstion, whereas multiline text gets sort of mangled when stored as JSON or YAML and requires conversion before use.\n\n```python\nimport karls_chatgpt_helpers\n\ng = karls_chatgpt_helpers.GPTChatSession()\n\nreply = g.chat('Please give me a paragraph of gibberish so I can test my API.')\nprint(reply)\n\nreply = g.chat('Another one, please.')\nprint(reply)\n\ng.save('mysession.txt')\n\n```\n\n* g.chat(content) - append content to history as a user or system prompt (role='user' or 'system', default 'user') and send to open.ChatCompletion.create() and return the reply.\n* g.streaming_chat(content) - same as chat except the output is streamed.  the chunks are written and flushed to stdout as they are received, as well as being accumulated into a reply content string.  When the entire response has been received, or a keyboard interrupt has occurred, the content string is appended to the history with the role set to 'assistant', and the assembled content string is returned.\n* g.load(filename) - load a conversation in RFC822 format.\n* g.save(filename) - save a conversation in RFC822 format.\n* g.load_json(filename) - load a conversation in JSON format.\n* g.save_json(filename) - save a conversation in JSON format.\n* g.load_yaml(filename) - load a conversation in YAML format.\n* g.save_yaml(filename) - save a conversation in YAML format.\n\n\n### example\n\n```python\nimport karls_chatgpt_helpers\n\n\n    g = karls_chatgpt_helpers.GPTChatSession(\n        model='gpt-3.5-turbo',\n\tmax_tokens=1000,\n\tstop=None,\n\ttemperature=0.5,\n        debug=False\n    )\n\n    reply = g.chat(\"You think I'm a replicant, don't you?\")\n\n```\n\n### Usage\n\n```\ngptshell [-h] [-s SYSTEM_FILE] [-i LOAD] [-m MODEL]\n\noptions:\n  -h, --help            show this help message and exit\n  -s SYSTEM_FILE, --system-file SYSTEM_FILE\n                        the system prompt file to use\n  -i LOAD, --load LOAD  load a file\n  -m MODEL, --model MODEL\n                        Model used for response generation\n```\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/lehenbauer/karls_chatgpt_helpers",
    "keywords": "",
    "license": "Copyright © 2023 Karl Lehenbauer  Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:  The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.  the software is provided “AS IS”, without warranty of any kind, express or implied, including but not limited to the warranties of merchantability, fitness for a particular purpose and noninfringement. In no event shall the authors or copyright holders be liable for any claim, damages or other liability, whether in an action of contract, tort or otherwise, arising from, out of or in connection with the software or the use or other dealings in the software. ",
    "maintainer": "",
    "maintainer_email": "",
    "name": "karls-chatgpt-helpers",
    "package_url": "https://pypi.org/project/karls-chatgpt-helpers/",
    "platform": null,
    "project_url": "https://pypi.org/project/karls-chatgpt-helpers/",
    "project_urls": {
      "Bug Tracker": "https://github.com/lehenbauer/karls-chatgpt-helpers/issues",
      "Homepage": "https://github.com/lehenbauer/karls-chatgpt-helpers"
    },
    "release_url": "https://pypi.org/project/karls-chatgpt-helpers/0.0.3/",
    "requires_dist": [
      "openai",
      "pyyaml"
    ],
    "requires_python": ">=3.7",
    "summary": "Helper functions for chatgpt",
    "version": "0.0.3",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17521202,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "264bf06470dd0b1c8f7e664309ae2779f286fa8e6068213573d7b61c272d888b",
          "md5": "5350642e779cdfbb8b12e9d38c4209e8",
          "sha256": "f809f100b4391f801779e3c5cad989e0d53b9fc38f7de12f4a34bb4fab0d9f72"
        },
        "downloads": -1,
        "filename": "karls_chatgpt_helpers-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "5350642e779cdfbb8b12e9d38c4209e8",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7.1",
        "size": 8909,
        "upload_time": "2023-03-30T20:49:15",
        "upload_time_iso_8601": "2023-03-30T20:49:15.789669Z",
        "url": "https://files.pythonhosted.org/packages/26/4b/f06470dd0b1c8f7e664309ae2779f286fa8e6068213573d7b61c272d888b/karls_chatgpt_helpers-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "30c9234e38a1847e93edadd12fc8b0d5e561fefd59d4a3185fab3bdd6695bace",
          "md5": "e6bcfedb3d151a2464fd60f6692ba3ac",
          "sha256": "47c3943641d6a53f5e26c9bc80e428475b7b1acf8a3f47280cb870b4921fccb0"
        },
        "downloads": -1,
        "filename": "karls_chatgpt_helpers-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "e6bcfedb3d151a2464fd60f6692ba3ac",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7.1",
        "size": 8407,
        "upload_time": "2023-03-30T20:49:17",
        "upload_time_iso_8601": "2023-03-30T20:49:17.815243Z",
        "url": "https://files.pythonhosted.org/packages/30/c9/234e38a1847e93edadd12fc8b0d5e561fefd59d4a3185fab3bdd6695bace/karls_chatgpt_helpers-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "951e67cc5ca441702c9beb7e7bfa01a2603b0f7d9dd32de3e44404bad431ed2e",
          "md5": "bea7f3e97c200931c22b3b92c9d9890a",
          "sha256": "3906361cbb28860140a6c101dbb8a5ac1bb4413f10e392fd066c97ab35a58685"
        },
        "downloads": -1,
        "filename": "karls_chatgpt_helpers-0.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "bea7f3e97c200931c22b3b92c9d9890a",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 9041,
        "upload_time": "2023-03-30T21:51:55",
        "upload_time_iso_8601": "2023-03-30T21:51:55.644351Z",
        "url": "https://files.pythonhosted.org/packages/95/1e/67cc5ca441702c9beb7e7bfa01a2603b0f7d9dd32de3e44404bad431ed2e/karls_chatgpt_helpers-0.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6291912b9393f23fc6e216497d2a7c65c598866c1ad9f567dbd48490e453b6f5",
          "md5": "060951d683c267e36e2bad79ae1eaf7e",
          "sha256": "fca8f3f548877c8ce6ebe3fa88157d9526d19ad87a5dc9cdbd7d0047733e282a"
        },
        "downloads": -1,
        "filename": "karls_chatgpt_helpers-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "060951d683c267e36e2bad79ae1eaf7e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 8721,
        "upload_time": "2023-03-30T21:51:57",
        "upload_time_iso_8601": "2023-03-30T21:51:57.809477Z",
        "url": "https://files.pythonhosted.org/packages/62/91/912b9393f23fc6e216497d2a7c65c598866c1ad9f567dbd48490e453b6f5/karls_chatgpt_helpers-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2e6f2b9f809674f0ef73f528d9a2569762ccf1c5cc426b287f0b690f58ad8531",
          "md5": "80deea3bc006889b8051fd51ce8cdf0d",
          "sha256": "8edb47c7101eeac75045906c6cf245728e19bf229cb78085a4e11eaaf69185b6"
        },
        "downloads": -1,
        "filename": "karls_chatgpt_helpers-0.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "80deea3bc006889b8051fd51ce8cdf0d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 12217,
        "upload_time": "2023-03-31T04:16:22",
        "upload_time_iso_8601": "2023-03-31T04:16:22.716914Z",
        "url": "https://files.pythonhosted.org/packages/2e/6f/2b9f809674f0ef73f528d9a2569762ccf1c5cc426b287f0b690f58ad8531/karls_chatgpt_helpers-0.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ed607f50c72630a5948e6c5991df347d38940ee4380e1228587a72ef9c5a1dc3",
          "md5": "ef96d663a151049bbeae32eec4561c94",
          "sha256": "9bb23d9af6a5466827736af468ee9fb0e1b531d129227b634c3eea4d05d1389f"
        },
        "downloads": -1,
        "filename": "karls_chatgpt_helpers-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "ef96d663a151049bbeae32eec4561c94",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 15228,
        "upload_time": "2023-03-31T04:16:24",
        "upload_time_iso_8601": "2023-03-31T04:16:24.961812Z",
        "url": "https://files.pythonhosted.org/packages/ed/60/7f50c72630a5948e6c5991df347d38940ee4380e1228587a72ef9c5a1dc3/karls_chatgpt_helpers-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "2e6f2b9f809674f0ef73f528d9a2569762ccf1c5cc426b287f0b690f58ad8531",
        "md5": "80deea3bc006889b8051fd51ce8cdf0d",
        "sha256": "8edb47c7101eeac75045906c6cf245728e19bf229cb78085a4e11eaaf69185b6"
      },
      "downloads": -1,
      "filename": "karls_chatgpt_helpers-0.0.3-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "80deea3bc006889b8051fd51ce8cdf0d",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 12217,
      "upload_time": "2023-03-31T04:16:22",
      "upload_time_iso_8601": "2023-03-31T04:16:22.716914Z",
      "url": "https://files.pythonhosted.org/packages/2e/6f/2b9f809674f0ef73f528d9a2569762ccf1c5cc426b287f0b690f58ad8531/karls_chatgpt_helpers-0.0.3-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "ed607f50c72630a5948e6c5991df347d38940ee4380e1228587a72ef9c5a1dc3",
        "md5": "ef96d663a151049bbeae32eec4561c94",
        "sha256": "9bb23d9af6a5466827736af468ee9fb0e1b531d129227b634c3eea4d05d1389f"
      },
      "downloads": -1,
      "filename": "karls_chatgpt_helpers-0.0.3.tar.gz",
      "has_sig": false,
      "md5_digest": "ef96d663a151049bbeae32eec4561c94",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 15228,
      "upload_time": "2023-03-31T04:16:24",
      "upload_time_iso_8601": "2023-03-31T04:16:24.961812Z",
      "url": "https://files.pythonhosted.org/packages/ed/60/7f50c72630a5948e6c5991df347d38940ee4380e1228587a72ef9c5a1dc3/karls_chatgpt_helpers-0.0.3.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}