{
  "info": {
    "author": "Szymon Maszke",
    "author_email": "szymon.maszke@protonmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 2 - Pre-Alpha",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Topic :: Scientific/Engineering",
      "Topic :: Scientific/Engineering :: Artificial Intelligence",
      "Topic :: Software Development :: Libraries",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "<img align=\"left\" width=\"256\" height=\"256\" src=\"https://github.com/szymonmaszke/torchdata/blob/master/assets/logos/medium.png\">\n\n* Use `map`, `apply`, `reduce` or `filter` directly on `Dataset` objects\n* `cache` data in RAM/disk or via your own method (partial caching supported)\n* Full PyTorch's [`Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) and [`IterableDataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset>) support\n* General `torchdata.maps` like `Flatten` or `Select`\n* Extensible interface (your own cache methods, cache modifiers, maps etc.)\n* Useful `torchdata.datasets` classes designed for general tasks (e.g. file reading)\n* Support for `torchvision` datasets (e.g. `ImageFolder`, `MNIST`, `CIFAR10`) via `td.datasets.WrapDataset`\n* Minimal overhead (single call to `super().__init__()`)\n\n| Version | Docs | Tests | Coverage | Style | PyPI | Python | PyTorch | Docker | Roadmap |\n|---------|------|-------|----------|-------|------|--------|---------|--------|---------|\n| [![Version](https://img.shields.io/static/v1?label=&message=0.2.0&color=377EF0&style=for-the-badge)](https://github.com/szymonmaszke/torchdata/releases) | [![Documentation](https://img.shields.io/static/v1?label=&message=docs&color=EE4C2C&style=for-the-badge)](https://szymonmaszke.github.io/torchdata/)  | ![Tests](https://github.com/szymonmaszke/torchdata/workflows/test/badge.svg) | ![Coverage](https://img.shields.io/codecov/c/github/szymonmaszke/torchdata?label=%20&logo=codecov&style=for-the-badge) | [![codebeat](https://img.shields.io/static/v1?label=&message=CB&color=27A8E0&style=for-the-badge)](https://codebeat.co/projects/github-com-szymonmaszke-torchdata-master) | [![PyPI](https://img.shields.io/static/v1?label=&message=PyPI&color=377EF0&style=for-the-badge)](https://pypi.org/project/torchdata/) | [![Python](https://img.shields.io/static/v1?label=&message=3.6&color=377EF0&style=for-the-badge&logo=python&logoColor=F8C63D)](https://www.python.org/) | [![PyTorch](https://img.shields.io/static/v1?label=&message=>=1.2.0&color=EE4C2C&style=for-the-badge)](https://pytorch.org/) | [![Docker](https://img.shields.io/static/v1?label=&message=docker&color=309cef&style=for-the-badge)](https://hub.docker.com/r/szymonmaszke/torchdata) | [![Roadmap](https://img.shields.io/static/v1?label=&message=roadmap&color=009688&style=for-the-badge)](https://github.com/szymonmaszke/torchdata/blob/master/ROADMAP.md) |\n\n# :bulb: Examples\n\n__Check documentation here:__\n[https://szymonmaszke.github.io/torchdata](https://szymonmaszke.github.io/torchdata)\n\n## General example\n\n- Create image dataset, convert it to Tensors, cache and concatenate with smoothed labels:\n\n```python\nimport torchdata as td\nimport torchvision\n\nclass Images(td.Dataset): # Different inheritance\n    def __init__(self, path: str):\n        super().__init__() # This is the only change\n        self.files = [file for file in pathlib.Path(path).glob(\"*\")]\n\n    def __getitem__(self, index):\n        return Image.open(self.files[index])\n\n    def __len__(self):\n        return len(self.files)\n\n\nimages = Images(\"./data\").map(torchvision.transforms.ToTensor()).cache()\n```\n\nYou can concatenate above dataset with another (say `labels`) and iterate over them as per usual:\n\n```python\nfor data, label in images | labels:\n    # Do whatever you want with your data\n```\n\n- Cache first `1000` samples in memory, save the rest on disk in folder `./cache`:\n\n```python\nimages = (\n    ImageDataset.from_folder(\"./data\").map(torchvision.transforms.ToTensor())\n    # First 1000 samples in memory\n    .cache(td.modifiers.UpToIndex(1000, td.cachers.Memory()))\n    # Sample from 1000 to the end saved with Pickle on disk\n    .cache(td.modifiers.FromIndex(1000, td.cachers.Pickle(\"./cache\")))\n    # You can define your own cachers, modifiers, see docs\n)\n```\nTo see what else you can do please check [**torchdata documentation**](https://szymonmaszke.github.io/torchdata/)\n\n## Integration with `torchvision`\n\nUsing `torchdata` you can easily split `torchvision` datasets and apply augmentation\nonly to the training part of data without any troubles:\n\n```python\nimport torchvision\n\nimport torchdata as td\n\n# Wrap torchvision dataset with WrapDataset\ndataset = td.datasets.WrapDataset(torchvision.datasets.ImageFolder(\"./images\"))\n\n# Split dataset\ntrain_dataset, validation_dataset, test_dataset = torch.utils.data.random_split(\n    model_dataset,\n    (int(0.6 * len(dataset)), int(0.2 * len(dataset)), int(0.2 * len(dataset))),\n)\n\n# Apply torchvision mappings ONLY to train dataset\ntrain_dataset.map(\n    td.maps.To(\n        torchvision.transforms.Compose(\n            [\n                torchvision.transforms.RandomResizedCrop(224),\n                torchvision.transforms.RandomHorizontalFlip(),\n                torchvision.transforms.ToTensor(),\n                torchvision.transforms.Normalize(\n                    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n                ),\n            ]\n        )\n    ),\n    # Apply this transformation to zeroth sample\n    # First sample is the label\n    0,\n)\n```\n\nPlease notice you can use `td.datasets.WrapDataset` with any existing `torch.utils.data.Dataset`\ninstance to give it additional `caching` and `mapping` powers!\n\n# :wrench: Installation\n\n## :snake: [pip](<https://pypi.org/project/torchdata/>)\n\n### Latest release:\n\n```shell\npip install --user torchdata\n```\n\n### Nightly:\n\n```shell\npip install --user torchdata-nightly\n```\n\n## :whale2: [Docker](https://hub.docker.com/r/szymonmaszke/torchdata)\n\n__CPU standalone__ and various versions of __GPU enabled__ images are available\nat [dockerhub](https://hub.docker.com/r/szymonmaszke/torchdata/tags).\n\nFor CPU quickstart, issue:\n\n```shell\ndocker pull szymonmaszke/torchdata:18.04\n```\n\nNightly builds are also available, just prefix tag with `nightly_`. If you are going for `GPU` image make sure you have\n[nvidia/docker](https://github.com/NVIDIA/nvidia-docker) installed and it's runtime set.\n\n# :question: Contributing\n\nIf you find any issue or you think some functionality may be useful to others and fits this library, please [open new Issue](https://help.github.com/en/articles/creating-an-issue) or [create Pull Request](https://help.github.com/en/articles/creating-a-pull-request-from-a-fork).\n\nTo get an overview of thins one can do to help this project, see [Roadmap](https://github.com/szymonmaszke/torchdata/blob/master/ROADMAP.md)\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/szymonmaszke/torchdatasets",
    "keywords": "pytorch torch data datasets map cache memory disk apply database",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "torchdatasets",
    "package_url": "https://pypi.org/project/torchdatasets/",
    "platform": "",
    "project_url": "https://pypi.org/project/torchdatasets/",
    "project_urls": {
      "Documentation": "https://szymonmaszke.github.io/torchdatasets/#torchdatasets",
      "Homepage": "https://github.com/szymonmaszke/torchdatasets",
      "Issues": "https://github.com/szymonmaszke/torchdatasets/issues?q=is%3Aissue+is%3Aopen+sort%3Aupdated-desc",
      "Website": "https://szymonmaszke.github.io/torchdatasets"
    },
    "release_url": "https://pypi.org/project/torchdatasets/0.2.0/",
    "requires_dist": [
      "torch (>=1.2.0)"
    ],
    "requires_python": ">=3.6",
    "summary": "PyTorch based library focused on data processing and input pipelines in general.",
    "version": "0.2.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12187295,
  "releases": {
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "55d8640f1b2415b5b3c4b656e3f162d439aeac7130fd48141ca2d83e3493b60b",
          "md5": "5381b9cb08039b335303f2dc6e58e4b7",
          "sha256": "6a96f8628c25d308642252d4eb80249345d8c9e6501deae015b116776ff91385"
        },
        "downloads": -1,
        "filename": "torchdatasets-0.2.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "5381b9cb08039b335303f2dc6e58e4b7",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 29470,
        "upload_time": "2021-12-02T09:49:26",
        "upload_time_iso_8601": "2021-12-02T09:49:26.956259Z",
        "url": "https://files.pythonhosted.org/packages/55/d8/640f1b2415b5b3c4b656e3f162d439aeac7130fd48141ca2d83e3493b60b/torchdatasets-0.2.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2aa8dea414bf0de7e48167722d0133d6f4b4d27813f11b457f83f15b0076161d",
          "md5": "ca73bf1066c9cafae78a1b8a26154bfe",
          "sha256": "3a6f51c3cc89b190a0745bb2dfa7723394c4605d45a3f78d98e806b3618b433c"
        },
        "downloads": -1,
        "filename": "torchdatasets-0.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "ca73bf1066c9cafae78a1b8a26154bfe",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 26263,
        "upload_time": "2021-12-02T09:49:28",
        "upload_time_iso_8601": "2021-12-02T09:49:28.360894Z",
        "url": "https://files.pythonhosted.org/packages/2a/a8/dea414bf0de7e48167722d0133d6f4b4d27813f11b457f83f15b0076161d/torchdatasets-0.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "55d8640f1b2415b5b3c4b656e3f162d439aeac7130fd48141ca2d83e3493b60b",
        "md5": "5381b9cb08039b335303f2dc6e58e4b7",
        "sha256": "6a96f8628c25d308642252d4eb80249345d8c9e6501deae015b116776ff91385"
      },
      "downloads": -1,
      "filename": "torchdatasets-0.2.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "5381b9cb08039b335303f2dc6e58e4b7",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 29470,
      "upload_time": "2021-12-02T09:49:26",
      "upload_time_iso_8601": "2021-12-02T09:49:26.956259Z",
      "url": "https://files.pythonhosted.org/packages/55/d8/640f1b2415b5b3c4b656e3f162d439aeac7130fd48141ca2d83e3493b60b/torchdatasets-0.2.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "2aa8dea414bf0de7e48167722d0133d6f4b4d27813f11b457f83f15b0076161d",
        "md5": "ca73bf1066c9cafae78a1b8a26154bfe",
        "sha256": "3a6f51c3cc89b190a0745bb2dfa7723394c4605d45a3f78d98e806b3618b433c"
      },
      "downloads": -1,
      "filename": "torchdatasets-0.2.0.tar.gz",
      "has_sig": false,
      "md5_digest": "ca73bf1066c9cafae78a1b8a26154bfe",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 26263,
      "upload_time": "2021-12-02T09:49:28",
      "upload_time_iso_8601": "2021-12-02T09:49:28.360894Z",
      "url": "https://files.pythonhosted.org/packages/2a/a8/dea414bf0de7e48167722d0133d6f4b4d27813f11b457f83f15b0076161d/torchdatasets-0.2.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}