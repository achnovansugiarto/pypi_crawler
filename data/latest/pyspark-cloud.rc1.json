{
  "info": {
    "author": "tekumara",
    "author_email": "tekumara.codes@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "License :: OSI Approved :: Apache Software License",
      "Programming Language :: Python :: 2.7",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.4",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: Implementation :: CPython",
      "Programming Language :: Python :: Implementation :: PyPy"
    ],
    "description": "# Tekumara build of Apache PySpark with Hadoop 3.x\n\nA build of Apache PySpark that uses the hadoop-cloud maven profile to bundle [hadoop-aws 3.x](https://hadoop.apache.org/docs/r3.2.0/hadoop-aws/tools/hadoop-aws/index.html) which contains S3A. \n\n## Install\n\nSee [Releases](https://github.com/tekumara/spark/releases)\n\n## Usage\n \nTo use pyspark with temporary STS credentials:\n\n```\npyspark --driver-java-options \"-Dspark.hadoop.fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.TemporaryAWSCredentialsProvider\"\n```\n\nTo modify an existing spark session to use S3A for S3 urls, for example `spark` in the pyspark shell:\n\n```\nspark.sparkContext._jsc.hadoopConfiguration().set(\"fs.s3.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n```\n\nSee [test_s3a.py](https://github.com/tekumara/spark/blob/spark-cloud/python/test_dist/test_s3a.py#L43) for an example of using the staging committers.\n\n## Rationale\n\nThe [pyspark distribution on pypi](https://pypi.org/project/pyspark/) ships with hadoop 2.7 and no cloud jars (ie: hadoop-aws).\nSo common practice is to use hadoop-aws 2.7.3 as follows:\n\n```\npyspark --packages \"org.apache.hadoop:hadoop-aws:2.7.3\" --driver-java-options \"-Dspark.hadoop.fs.s3.impl=org.apache.hadoop.fs.s3a.S3AFileSystem\"\n```\n\nHowever, later versions of hadoop-aws cannot be used this way without errors.\n\nThis project [builds a pyspark distribution](https://github.com/tekumara/spark/blob/spark-cloud/.github/workflows/spark-cloud.yml#L59) from source with Hadoop 3.x.\n\nLater versions of hadoop-aws contain the following new features:\n\n* [2.8 release line](http://hadoop.apache.org/docs/r2.8.0/index.html) contains S3A improvements to support any AWSCredentialsProvider\n* [2.9 release line](http://hadoop.apache.org/docs/r2.9.0/index.html) contains [S3Guard](http://hadoop.apache.org/docs/r2.9.0/hadoop-aws/tools/hadoop-aws/s3guard.html) which provides consistency and metadata caching for S3A via a backing DynamoDB metadata store.\n* [3.1 release line](http://hadoop.apache.org/docs/r3.1.0/index.html) incorporates HADOOP-13786 which contains optimised job committers including the Netflix staging committers (Directory and Partitioned) and the Magic committers. See [committers](https://github.com/apache/hadoop/blob/branch-3.1/hadoop-tools/hadoop-aws/src/site/markdown/tools/hadoop-aws/committers.md) and [committer architecture](https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-aws/src/site/markdown/tools/hadoop-aws/committer_architecture.md).\n* [3.2 release line](http://hadoop.apache.org/docs/r3.2.0/index.html) an [enhanced S3A connector and S3Guard](https://issues.apache.org/jira/browse/HADOOP-15226?jql=project%20%3D%20HADOOP%20AND%20component%20%3D%20%22fs%2Fs3%22%20AND%20fixVersion%20%3D%203.2.0), including better resilience to throttled AWS S3 and DynamoDB IO.\n\nTo take advantage of the 3.x release line committers in Spark you also need the binding classes introduced into Spark 3.0.0 by [SPARK-23977](https://issues.apache.org/jira/browse/SPARK-23977). For Spark 2.4, the [HortonWorks backport](https://github.com/hortonworks-spark/cloud-integration/blob/master/spark-cloud-integration/src/main/site/markdown/index.md) is used from the [Hortonworks repo](https://mvnrepository.com/artifact/org.apache.spark/spark-hadoop-cloud_2.11/2.3.2.3.1.0.6-1).",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/tekumara/spark",
    "keywords": "",
    "license": "http://www.apache.org/licenses/LICENSE-2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "pyspark-cloud",
    "package_url": "https://pypi.org/project/pyspark-cloud/",
    "platform": "",
    "project_url": "https://pypi.org/project/pyspark-cloud/",
    "project_urls": {
      "Homepage": "https://github.com/tekumara/spark"
    },
    "release_url": "https://pypi.org/project/pyspark-cloud/0.0.0/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "Tekumara build of Apache Spark with Hadoop 3.1",
    "version": "0.0.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8743966,
  "releases": {
    "0.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4beb52b50d6cb59a6a71d9e091f06b8f3157a20ba4c6050fc2717743866eb9b6",
          "md5": "3b43ff7f1fc3b06c4df2da76835e3bf4",
          "sha256": "8962d07504fdc8939a2944a7d8ca5971c82400b068326427b5bb795e60d242eb"
        },
        "downloads": -1,
        "filename": "pyspark-cloud-0.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "3b43ff7f1fc3b06c4df2da76835e3bf4",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 463473,
        "upload_time": "2020-11-25T04:39:29",
        "upload_time_iso_8601": "2020-11-25T04:39:29.466739Z",
        "url": "https://files.pythonhosted.org/packages/4b/eb/52b50d6cb59a6a71d9e091f06b8f3157a20ba4c6050fc2717743866eb9b6/pyspark-cloud-0.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "4beb52b50d6cb59a6a71d9e091f06b8f3157a20ba4c6050fc2717743866eb9b6",
        "md5": "3b43ff7f1fc3b06c4df2da76835e3bf4",
        "sha256": "8962d07504fdc8939a2944a7d8ca5971c82400b068326427b5bb795e60d242eb"
      },
      "downloads": -1,
      "filename": "pyspark-cloud-0.0.0.tar.gz",
      "has_sig": false,
      "md5_digest": "3b43ff7f1fc3b06c4df2da76835e3bf4",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 463473,
      "upload_time": "2020-11-25T04:39:29",
      "upload_time_iso_8601": "2020-11-25T04:39:29.466739Z",
      "url": "https://files.pythonhosted.org/packages/4b/eb/52b50d6cb59a6a71d9e091f06b8f3157a20ba4c6050fc2717743866eb9b6/pyspark-cloud-0.0.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}