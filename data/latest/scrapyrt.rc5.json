{
  "info": {
    "author": "Scrapinghub",
    "author_email": "info@scrapinghub.com",
    "bugtrack_url": null,
    "classifiers": [
      "Environment :: Console",
      "Environment :: No Input/Output (Daemon)",
      "License :: OSI Approved :: BSD License",
      "Operating System :: OS Independent",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Topic :: Internet :: WWW/HTTP"
    ],
    "description": ".. image:: https://raw.githubusercontent.com/scrapinghub/scrapyrt/master/artwork/logo.gif\n   :width: 400px\n   :align: center\n\n==========================\nScrapyRT (Scrapy realtime)\n==========================\n\n.. image:: https://github.com/scrapinghub/scrapyrt/workflows/CI/badge.svg\n   :target: https://github.com/scrapinghub/scrapyrt/actions\n\n.. image:: https://img.shields.io/pypi/pyversions/scrapyrt.svg\n    :target: https://pypi.python.org/pypi/scrapyrt\n\n.. image:: https://img.shields.io/pypi/v/scrapyrt.svg\n    :target: https://pypi.python.org/pypi/scrapyrt\n\n.. image:: https://img.shields.io/pypi/l/scrapyrt.svg\n    :target: https://pypi.python.org/pypi/scrapyrt\n\n.. image:: https://img.shields.io/pypi/dm/scrapyrt.svg\n   :target: https://pypistats.org/packages/scrapyrt\n   :alt: Downloads count\n\n.. image:: https://readthedocs.org/projects/scrapyrt/badge/?version=latest\n   :target: https://scrapyrt.readthedocs.io/en/latest/api.html\n\nAdd HTTP API for your `Scrapy <https://scrapy.org/>`_ project in minutes.\n\nYou send a request to ScrapyRT with spider name and URL, and in response, you get items collected by a spider\nvisiting this URL. \n\n* All Scrapy project components (e.g. middleware, pipelines, extensions) are supported\n* You run Scrapyrt in Scrapy project directory. It starts HTTP server allowing you to schedule spiders and get spider output in JSON.\n\n\nQuickstart\n===============\n\n**1. install**\n\n.. code-block:: shell\n\n    > pip install scrapyrt\n\n**2. switch to Scrapy project (e.g. quotesbot project)**\n\n.. code-block:: shell\n\n    > cd my/project_path/is/quotesbot\n\n**3. launch ScrapyRT**\n\n.. code-block:: shell\n\n    > scrapyrt\n\n**4. run your spiders**\n\n.. code-block:: shell\n\n    > curl \"localhost:9080/crawl.json?spider_name=toscrape-css&url=http://quotes.toscrape.com/\"\n\n**5. run more complex query, e.g. specify callback for Scrapy request and zipcode argument for spider**\n\n.. code-block:: shell\n\n    >  curl --data '{\"request\": {\"url\": \"http://quotes.toscrape.com/page/2/\", \"callback\":\"some_callback\"}, \"spider_name\": \"toscrape-css\", \"crawl_args\": {\"zipcode\":\"14000\"}}' http://localhost:9080/crawl.json -v\n\nScrapyrt will look for ``scrapy.cfg`` file to determine your project settings,\nand will raise error if it won't find one.  Note that you need to have all\nyour project requirements installed.\n\nNote\n====\n* Project is not a replacement for `Scrapyd <https://scrapyd.readthedocs.io/en/stable/>`_ or `Scrapy Cloud <https://www.zyte.com/scrapy-cloud/>`_ or other infrastructure to run long running crawls\n* Not suitable for long running spiders, good for spiders that will fetch one response from some website and return items quickly\n\n\nDocumentation\n=============\n\n`Documentation is available on readthedocs <http://scrapyrt.readthedocs.org/en/latest/index.html>`_.\n\nSupport\n=======\n\nOpen source support is provided here in Github. Please `create a question\nissue`_ (ie. issue with \"question\" label).\n\nCommercial support is also available by `Zyte`_.\n\n.. _create a question issue: https://github.com/scrapinghub/scrapyrt/issues/new?labels=question\n.. _Zyte: http://zyte.com\n\nLicense\n=======\nScrapyRT is offered under `BSD 3-Clause license <https://en.wikipedia.org/wiki/BSD_licenses#3-clause_license_(%22BSD_License_2.0%22,_%22Revised_BSD_License%22,_%22New_BSD_License%22,_or_%22Modified_BSD_License%22)>`_.\n\n\nDevelopment\n===========\nDevelopment taking place on `Github <https://github.com/scrapinghub/scrapyrt>`_.\n\n\n",
    "description_content_type": "",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/scrapinghub/scrapyrt",
    "keywords": "",
    "license": "BSD",
    "maintainer": "Scrapinghub",
    "maintainer_email": "info@scrapinghub.com",
    "name": "scrapyrt",
    "package_url": "https://pypi.org/project/scrapyrt/",
    "platform": "",
    "project_url": "https://pypi.org/project/scrapyrt/",
    "project_urls": {
      "Documentation": "https://scrapyrt.readthedocs.io/en/latest/index.html",
      "Homepage": "https://github.com/scrapinghub/scrapyrt",
      "Source": "https://github.com/scrapinghub/scrapyrt",
      "Tracker": "https://github.com/scrapinghub/scrapyrt/issues"
    },
    "release_url": "https://pypi.org/project/scrapyrt/0.13.0/",
    "requires_dist": [
      "Scrapy (>=1.0.0)"
    ],
    "requires_python": ">=3.6",
    "summary": "Put Scrapy spiders behind an HTTP API",
    "version": "0.13.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12266093,
  "releases": {
    "0.10": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cccae04513d8a7f900ed09d5558b7ef0768197ecd519c7359815b4b744ff4bab",
          "md5": "2fa44db94e6286e653dc37bbdf9d9231",
          "sha256": "2b439cba2d96cce88a1d47a0b3a8cf8bdbe8312e0b1bc97c8e64e20cea840d40"
        },
        "downloads": -1,
        "filename": "scrapyrt-0.10.tar.gz",
        "has_sig": false,
        "md5_digest": "2fa44db94e6286e653dc37bbdf9d9231",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 23544,
        "upload_time": "2017-04-18T10:36:53",
        "upload_time_iso_8601": "2017-04-18T10:36:53.373491Z",
        "url": "https://files.pythonhosted.org/packages/cc/ca/e04513d8a7f900ed09d5558b7ef0768197ecd519c7359815b4b744ff4bab/scrapyrt-0.10.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.11.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ecf3e6010c5cc59c7acdce8589e696d3d8546985155107294f2a92ee3086da5b",
          "md5": "bc7a99a624366bfbead69979763ee8c0",
          "sha256": "5fb05b27bda1b6b270aac40bc827ed31da5b17a92864069cbcda6dc489ceb90b"
        },
        "downloads": -1,
        "filename": "scrapyrt-0.11.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "bc7a99a624366bfbead69979763ee8c0",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 33299,
        "upload_time": "2019-09-20T11:55:03",
        "upload_time_iso_8601": "2019-09-20T11:55:03.250063Z",
        "url": "https://files.pythonhosted.org/packages/ec/f3/e6010c5cc59c7acdce8589e696d3d8546985155107294f2a92ee3086da5b/scrapyrt-0.11.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "402e2bae97fe4e05878c44f4ba3763fce142693c84cfda405b8ca5afa60a8287",
          "md5": "f6bf1376f9c8a910271bef6a9aa4b451",
          "sha256": "4ad45c6f35f2ccaab4ef8d0c8f0a54bfe598f4c4162d0b89af8255703a2d7573"
        },
        "downloads": -1,
        "filename": "scrapyrt-0.11.0.tar.gz",
        "has_sig": false,
        "md5_digest": "f6bf1376f9c8a910271bef6a9aa4b451",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 24156,
        "upload_time": "2019-09-20T11:55:04",
        "upload_time_iso_8601": "2019-09-20T11:55:04.672624Z",
        "url": "https://files.pythonhosted.org/packages/40/2e/2bae97fe4e05878c44f4ba3763fce142693c84cfda405b8ca5afa60a8287/scrapyrt-0.11.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.12.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6d20d7eed0c0ecb10533a3bcd6c7705d17a04fa4a37a3662f5f84bc289c03b7a",
          "md5": "efae64ad475e36c44a24b1800c44d25c",
          "sha256": "e69691dc883bd628b331b0112637170f21de6ca13ac08a415f83a288edf150d1"
        },
        "downloads": -1,
        "filename": "scrapyrt-0.12.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "efae64ad475e36c44a24b1800c44d25c",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 35090,
        "upload_time": "2021-03-08T12:56:26",
        "upload_time_iso_8601": "2021-03-08T12:56:26.675634Z",
        "url": "https://files.pythonhosted.org/packages/6d/20/d7eed0c0ecb10533a3bcd6c7705d17a04fa4a37a3662f5f84bc289c03b7a/scrapyrt-0.12.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "356499f0414577b690145861efa33f7c968b34d5a36d48ab0c755a437e8d902b",
          "md5": "a85b2be202cd7a9ffabc2d15206b9e1c",
          "sha256": "e73687dbadd05aa7403c9762f9a487b1e88e4aa701a6087416ceffe61cad7d45"
        },
        "downloads": -1,
        "filename": "scrapyrt-0.12.0.tar.gz",
        "has_sig": false,
        "md5_digest": "a85b2be202cd7a9ffabc2d15206b9e1c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 27765,
        "upload_time": "2021-03-08T12:56:27",
        "upload_time_iso_8601": "2021-03-08T12:56:27.938346Z",
        "url": "https://files.pythonhosted.org/packages/35/64/99f0414577b690145861efa33f7c968b34d5a36d48ab0c755a437e8d902b/scrapyrt-0.12.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.13.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2d3c6a43502e67ddfa7f4e62604de7a3d793dc9b1d6106db60e705510837f9b0",
          "md5": "bc76888be29f3d3e2fbb6b7821ac4de7",
          "sha256": "2d033650535c8c0ee9474657e97fc78eb50642fa7e1be0c61420a1b38c81181c"
        },
        "downloads": -1,
        "filename": "scrapyrt-0.13.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "bc76888be29f3d3e2fbb6b7821ac4de7",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": ">=3.6",
        "size": 36266,
        "upload_time": "2021-12-10T10:54:00",
        "upload_time_iso_8601": "2021-12-10T10:54:00.583574Z",
        "url": "https://files.pythonhosted.org/packages/2d/3c/6a43502e67ddfa7f4e62604de7a3d793dc9b1d6106db60e705510837f9b0/scrapyrt-0.13.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "eeb66b783c8a997a7c8217165445e04a3f68678595e7d3e5b158bb68f07aaebb",
          "md5": "6217dae175f32f7cade86005cb07bd3c",
          "sha256": "cd193a887199ef253a19d902acd8ea99c13fc889fae41b3e3ee63d4449e6cc08"
        },
        "downloads": -1,
        "filename": "scrapyrt-0.13.0.tar.gz",
        "has_sig": false,
        "md5_digest": "6217dae175f32f7cade86005cb07bd3c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 29443,
        "upload_time": "2021-12-10T10:54:01",
        "upload_time_iso_8601": "2021-12-10T10:54:01.508865Z",
        "url": "https://files.pythonhosted.org/packages/ee/b6/6b783c8a997a7c8217165445e04a3f68678595e7d3e5b158bb68f07aaebb/scrapyrt-0.13.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.9": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "28095fb168ded6859305297f276fb0ef0b4b5c626afed57ea6bc0bad4d7cc698",
          "md5": "8b128cf59b7629c88573792b7e7b3059",
          "sha256": "66e93fb22f3e8ee246be34a6f136ca8810ad202f5cfd4f550633c5c427c7e4c7"
        },
        "downloads": -1,
        "filename": "scrapyrt-0.9.tar.gz",
        "has_sig": false,
        "md5_digest": "8b128cf59b7629c88573792b7e7b3059",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 19897,
        "upload_time": "2016-05-11T15:29:41",
        "upload_time_iso_8601": "2016-05-11T15:29:41.818182Z",
        "url": "https://files.pythonhosted.org/packages/28/09/5fb168ded6859305297f276fb0ef0b4b5c626afed57ea6bc0bad4d7cc698/scrapyrt-0.9.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "2d3c6a43502e67ddfa7f4e62604de7a3d793dc9b1d6106db60e705510837f9b0",
        "md5": "bc76888be29f3d3e2fbb6b7821ac4de7",
        "sha256": "2d033650535c8c0ee9474657e97fc78eb50642fa7e1be0c61420a1b38c81181c"
      },
      "downloads": -1,
      "filename": "scrapyrt-0.13.0-py2.py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "bc76888be29f3d3e2fbb6b7821ac4de7",
      "packagetype": "bdist_wheel",
      "python_version": "py2.py3",
      "requires_python": ">=3.6",
      "size": 36266,
      "upload_time": "2021-12-10T10:54:00",
      "upload_time_iso_8601": "2021-12-10T10:54:00.583574Z",
      "url": "https://files.pythonhosted.org/packages/2d/3c/6a43502e67ddfa7f4e62604de7a3d793dc9b1d6106db60e705510837f9b0/scrapyrt-0.13.0-py2.py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "eeb66b783c8a997a7c8217165445e04a3f68678595e7d3e5b158bb68f07aaebb",
        "md5": "6217dae175f32f7cade86005cb07bd3c",
        "sha256": "cd193a887199ef253a19d902acd8ea99c13fc889fae41b3e3ee63d4449e6cc08"
      },
      "downloads": -1,
      "filename": "scrapyrt-0.13.0.tar.gz",
      "has_sig": false,
      "md5_digest": "6217dae175f32f7cade86005cb07bd3c",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 29443,
      "upload_time": "2021-12-10T10:54:01",
      "upload_time_iso_8601": "2021-12-10T10:54:01.508865Z",
      "url": "https://files.pythonhosted.org/packages/ee/b6/6b783c8a997a7c8217165445e04a3f68678595e7d3e5b158bb68f07aaebb/scrapyrt-0.13.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}