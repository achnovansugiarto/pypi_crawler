{
  "info": {
    "author": "Marc Escandell Mari",
    "author_email": "marcescandellmari@gmail.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n\n# ALPypeRL\n\n**ALPypeRL** or _AnyLogic Python Pipe for Reinforcement Learning_ is an open source library for connecting **AnyLogic** simulation models with **reinforcement learning** frameworks that are compatible with _OpenAI Gymnasium_ interface (single agent).\n\n![ALPypeRL GIF](resources/images/alpyperl_gif.gif)\n\nWith ALPypeRL you will be able to:\n* Connect your AnyLogic model to a reinforcement learning framework of your choise (e.g. ray `rllib`).\n* Scale your training by launching many AnyLogic models simultaneously (requires an exported model).\n* Deploy and evaluate your trained policy.\n* Debug your AnyLogic models during training.\n* Leverage on the AnyLogic rich visualization while training or evaluating.\n\nThere is a more detailed [documentation](https://github.com/MarcEscandell/ALPypeRL/wiki) that includes multiple examples to understand most the basic functionalities.\n\n_NOTE: ALPypeRL has been developed using **ray rllib** as the base RL framework. Ray rllib is an industry leading open source package for Reinforcement Learning. Because of that, ALPypeRL has certain dependencies to it (e.g. trained policy deployment and evaluation)._\n\n## Environments\n\nALPypeRL inculdes 2 environments that make the connection between AnyLogic and your python scrip possible:\n* [ALPypeRLConnector](https://github.com/MarcEscandell/ALPypeRL/wiki/AnyLogicConnector) - The AnyLogic connector ('agent') library to be dropped into your simulation model.\n* [alpyperl](https://github.com/MarcEscandell/ALPypeRL/wiki/CartPoleV0) - This environment includes functionalities to _train_ and _evaluate_ RL policies in python. \n\n## Installation\n\nTo install the base **ALPypeRL** library in python, use `pip install alpyperl`.\n\nTo use **ALPypeRLConnector** in AnyLogic, you can add the [library](https://github.com/MarcEscandell/ALPypeRL/tree/main/bin) to your _Palette_. That will allow you to drag and drop the connector into your model. _Note that further [instructions](https://github.com/MarcEscandell/ALPypeRL/wiki/AnyLogicConnector) are required to be followed in order for the connector to work_.\n\n![ALPypeRL Library](resources/images/alpyperl_library.png)\n\n## Requirements\n\nThe **ALPypeRL** requires you to have the AnyLogic software (or a valid exported model). AnyLogic is a licensed software for building simulations that includes an ample variety of libraries for modelling many industry challenges. At the moment, AnyLogic provides a _free_ license under the name PLE (Personal Learning Edition). There are other options available. For more information, you can visit the [AnyLogic website](https://www.anylogic.com/).\n\n_Note that this is not a package that is currently backed by the AnyLogic support team_.\n\n## API basics\n\n### Training\n\nTo be able to train your policy, you must have the following:\n\n* An **AnyLogic model** that requires decisions to be taken as the simulation runs. Using the [CartPole-v0](https://github.com/MarcEscandell/alpyperl/wiki) example, a decision must be taken on the direction of the force to be applied so the pole can be kept straight for as long as possible. For that, the AnyLogic model will be making requests to the **ALPypeRLConnector** and consuming the returned/suggested action.\n\n![ALPypeRL Connector](resources/images/alpyperl_train_api.png)\n\n* A **python script** that contains the RL framework. Here is where the policy is going to be trained. For that, you will need to create your _custom environment_ taking into consideration what your AnyLogic model expects to return and receive. By default, you must define the _action_ and _observation_ spaces. Please visit the [CartPole-v0](https://github.com/MarcEscandell/alpyperl/wiki) example for a more detailed explanation.\n\n```python\nfrom alpyperl.examples.cartpole_v0 import CartPoleEnv\nfrom ray.rllib.algorithms.ppo import PPOConfig\n\n# Initialise policy configuration (e.g. PPOConfig), rollouts and environment\npolicy = (\n    PPOConfig()\n    .rollouts(\n        num_rollout_workers=2,\n        num_envs_per_worker=2,\n    )\n    .environment(\n        CartPoleEnv,    # Or call `create_custom_env(action_space, observation_space)`\n        env_config={\n            'run_exported_model': True,\n            'exported_model_loc': './resources/exported_models/cartpole_v0',\n            'show_terminals': False,\n            'verbose': False\n        }\n    )\n    .build()\n)\n\n# Create training loop\nfor _ in range(10):\n    result = policy.train()\n\n# Save policy at known location\ncheckpoint_dir = policy.save(\"./resources/trained_policies/cartpole_v0\")\nprint(f\"Checkpoint saved in directory '{checkpoint_dir}'\")\n\n# Close all enviornments (otherwise AnyLogic model will be hanging)\npolicy.stop()\n```\n\n### Evaluation\n\nThe evaluation of your _trained policy_ is made simple in **alpyperl**. See the example:\n\n```python\nfrom alpyperl.serve.rllib import launch_policy_server\nfrom alpyperl.examples.cartpole_v0 import CartPoleEnv\nfrom ray.rllib.algorithms.ppo import PPOConfig\n\n\nlaunch_policy_server(\n    policy_config=PPOConfig(),\n    env=CartPoleEnv,\n    trained_policy_loc='./resources/trained_policies/cartpole_v0/checkpoint_000010',\n    port=3000\n)\n```\n\nOnce the server is on, you can run your AnyLogic model and test your trained policy. You are expected to select mode _EVALUATE_ and specify the server _url_.\n\n## Bugs and/or development roadmap\n\nAt the moment, ALPypeRL is at its earliest stage. You can join the [alpyperl project](https://github.com/users/MarcEscandell/projects/1) and raise bugs, feature requests or submit code enhancements via pull request.\n\n## Support ALPypeRL's development\n\nIf you are financially able to do so and would like to support the development of **ALPypeRL**, please reach out to marcescandellmari@gmail.com.\n\n## License\n\nThe ALPypeRL software suite is licensed under the terms of the Apache License 2.0. See [LICENSE](https://github.com/MarcEscandell/ALPypeRL/blob/main/LICENSE.txt) for more information.\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/MarcEscandell/ALPypeRL",
    "keywords": "alpyperl",
    "license": "Apache License, Version 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "alpyperl",
    "package_url": "https://pypi.org/project/alpyperl/",
    "platform": null,
    "project_url": "https://pypi.org/project/alpyperl/",
    "project_urls": {
      "Homepage": "https://github.com/MarcEscandell/ALPypeRL"
    },
    "release_url": "https://pypi.org/project/alpyperl/0.0.17/",
    "requires_dist": null,
    "requires_python": ">=3.9, <3.11",
    "summary": "An open source library for connecting AnyLogic models with Reinforcement Learning frameworks through OpenAI Gymnasium",
    "version": "0.0.17",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17299527,
  "releases": {
    "0.0.17": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1fb25b87311a26b1c16972bea152b9cf86857e2f3738e75643a355755bf5e21c",
          "md5": "0966f962ec4c2e59c90e4948b7c6644f",
          "sha256": "827f000183198ccf0235a73948fed890991f766ff9d53d4fe56bc2dd7ffb7162"
        },
        "downloads": -1,
        "filename": "alpyperl-0.0.17.tar.gz",
        "has_sig": false,
        "md5_digest": "0966f962ec4c2e59c90e4948b7c6644f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.9, <3.11",
        "size": 16314,
        "upload_time": "2023-03-15T05:50:12",
        "upload_time_iso_8601": "2023-03-15T05:50:12.839069Z",
        "url": "https://files.pythonhosted.org/packages/1f/b2/5b87311a26b1c16972bea152b9cf86857e2f3738e75643a355755bf5e21c/alpyperl-0.0.17.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "1fb25b87311a26b1c16972bea152b9cf86857e2f3738e75643a355755bf5e21c",
        "md5": "0966f962ec4c2e59c90e4948b7c6644f",
        "sha256": "827f000183198ccf0235a73948fed890991f766ff9d53d4fe56bc2dd7ffb7162"
      },
      "downloads": -1,
      "filename": "alpyperl-0.0.17.tar.gz",
      "has_sig": false,
      "md5_digest": "0966f962ec4c2e59c90e4948b7c6644f",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.9, <3.11",
      "size": 16314,
      "upload_time": "2023-03-15T05:50:12",
      "upload_time_iso_8601": "2023-03-15T05:50:12.839069Z",
      "url": "https://files.pythonhosted.org/packages/1f/b2/5b87311a26b1c16972bea152b9cf86857e2f3738e75643a355755bf5e21c/alpyperl-0.0.17.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}