{
  "info": {
    "author": "Simon Blanke",
    "author_email": "simon.blanke@yahoo.com",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Developers",
      "Intended Audience :: Information Technology",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Topic :: Scientific/Engineering :: Information Analysis",
      "Topic :: Scientific/Engineering :: Mathematics",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "<H1 align=\"center\">\n    Search Data Collector\n</H1>\n\n\n<p align=\"center\">\n  <a href=\"https://github.com/SimonBlanke/search-data-collector/actions\">\n    <img src=\"https://github.com/SimonBlanke/search-data-collector/actions/workflows/tests.yml/badge.svg?branch=main\" alt=\"img not loaded: try F5 :)\">\n  </a>\n  <a href=\"https://app.codecov.io/gh/SimonBlanke/search-data-collector\">\n    <img src=\"https://img.shields.io/codecov/c/github/SimonBlanke/search-data-collector/main&logo=codecov\" alt=\"img not loaded: try F5 :)\">\n  </a>\n</p>\n\n\n<H2 align=\"center\">\n    Thread-safe and atomic collection of tabular data into csv-files.\n</H2>\n\n<br>\n\nThe search-data-collector provides a single class with following methods to manage data:\n - save\n - append\n - load\n - remove\n\nThe Search-Data-Collector was created as a utility function for the [Gradient-Free-Optimizers](https://github.com/SimonBlanke/Gradient-Free-Optimizers)- and [Hyperactive](https://github.com/SimonBlanke/Hyperactive)-package. It is intended to be used as a tool to collect search-data from the optimization run. The search-data can be collected during the optimization run as a dictionary via `append` or after the run as a dataframe with the `save`-method. <br>\nThe `append`-method is thread-safe to work with hyperactive-multiprocessing. The `save`-method is atomic to avoid accidental data-loss, when interupting the save-process. <br>\nFor the Hyperactive-package the search-data-collector handles functions in the data by converting them to strings. If the data is loaded you can pass the search-space to convert the strings back to functions. \n\n\n\n<br>\n\n## Disclaimer\n\nThis project is in an early development stage and is sparsely tested. If you encounter bugs or have suggestions for improvements, then please open an issue.\n\n\n<br>\n\n## Installation\n\n```console\npip install search-data-collector \n```\n\n\n<br>\n\n## Examples\n\n\n<br>\n\n### Append search-data\n\n```python\nimport numpy as np\nfrom hyperactive import Hyperactive\nfrom search_data_collector import SearchDataCollector\n\ncollector = SearchDataCollector(\"./search_data.csv\")  # the csv is created automatically\n\n\ndef parabola_function(para):\n    loss = para[\"x\"] * para[\"x\"] + para[\"y\"] * para[\"y\"]\n\n    data_dict = dict(para)  # copy the parameter dictionary\n    data_dict[\"score\"] = -loss  # add the score to the dictionary\n    collector.append(data_dict)  # you can append a dictionary to the csv\n\n    return -loss\n\n\nsearch_space = {\n    \"x\": list(np.arange(-10, 10, 0.1)),\n    \"y\": list(np.arange(-10, 10, 0.1)),\n}\n\n\nhyper = Hyperactive()\nhyper.add_search(parabola_function, search_space, n_iter=1000)\nhyper.run()\nsearch_data = hyper.search_data(parabola_function)\n\nsearch_data = collector.load(search_space)  # load data\n\nprint(\"\\n search_data \\n\", search_data)\n```\n\n\n<br>\n\n### Save search-data\n\n```python\nimport numpy as np\nfrom hyperactive import Hyperactive\nfrom search_data_collector import SearchDataCollector\n\ncollector = SearchDataCollector(\"./search_data.csv\")  # the csv is created automatically\n\n\ndef parabola_function(para):\n    loss = para[\"x\"] * para[\"x\"] + para[\"y\"] * para[\"y\"]\n\n    return -loss\n\n\nsearch_space = {\n    \"x\": list(np.arange(-10, 10, 0.1)),\n    \"y\": list(np.arange(-10, 10, 0.1)),\n}\n\n\nhyper = Hyperactive()\nhyper.add_search(parabola_function, search_space, n_iter=1000)\nhyper.run()\nsearch_data = hyper.search_data(parabola_function)\n\ncollector.save(search_data)  # save a dataframe instead\n\nsearch_data = collector.load(search_space)  # load data\n\nprint(\"\\n search_data \\n\", search_data)\n```\n\n\n\n<br>\n\n### Functions in the search-space/search-data\n\n```python\nimport numpy as np\nfrom hyperactive import Hyperactive\nfrom search_data_collector import SearchDataCollector\n\ncollector = SearchDataCollector(\"./search_data.csv\")  # the csv is created automatically\n\n\ndef parabola_function(para):\n    loss = para[\"x\"] * para[\"x\"] + para[\"y\"] * para[\"y\"]\n\n    return -loss\n\n\n# just some dummy functions to show how this works\n\n\ndef function1():\n    print(\"this is function1\")\n\n\ndef function2():\n    print(\"this is function2\")\n\n\ndef function3():\n    print(\"this is function3\")\n\n\nsearch_space = {\n    \"x\": list(np.arange(-10, 10, 0.1)),\n    \"y\": list(np.arange(-10, 10, 0.1)),\n    \"string.example\": [\"string1\", \"string2\", \"string3\"],\n    \"function.example\": [function1, function2, function3],\n}\n\n\nhyper = Hyperactive()\nhyper.add_search(parabola_function, search_space, n_iter=30)\nhyper.run()\nsearch_data = hyper.search_data(parabola_function)\n\ncollector.save(search_data)  # save a dataframe instead of appending a dictionary\n\nsearch_data = collector.load()  # load data\n\nprint(\n    \"\\n In this dataframe the 'function.example'-column contains strings, which are the '__name__' of the functions. \\n search_data \\n \",\n    search_data,\n    \"\\n\",\n)\n\nsearch_data = collector.load(search_space)  # load data with search-space\n\nprint(\n    print(\n        \"\\n In this dataframe the 'function.example'-column contains the functions again. \\n search_data \\n \",\n        search_data,\n        \"\\n\",\n    )\n)\n```\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/SimonBlanke/search-data-collector",
    "keywords": "data-science",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "search-data-collector",
    "package_url": "https://pypi.org/project/search-data-collector/",
    "platform": null,
    "project_url": "https://pypi.org/project/search-data-collector/",
    "project_urls": {
      "Homepage": "https://github.com/SimonBlanke/search-data-collector"
    },
    "release_url": "https://pypi.org/project/search-data-collector/0.4.0/",
    "requires_dist": null,
    "requires_python": ">=3.5",
    "summary": "Thread safe and atomic data collection into csv-files",
    "version": "0.4.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17046531,
  "releases": {
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8313c2630e4969e8176081c9b7be220f5684680f93b158b89d93e9d03bdf3fba",
          "md5": "ff2ad7de1c3e4144c6587f520c97a1eb",
          "sha256": "f2b3a98432d92a8d566d864f1c8a5761255bcdda7826e4d14064c175551489a6"
        },
        "downloads": -1,
        "filename": "search_data_collector-0.2.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ff2ad7de1c3e4144c6587f520c97a1eb",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.5",
        "size": 12523,
        "upload_time": "2023-01-02T16:14:44",
        "upload_time_iso_8601": "2023-01-02T16:14:44.092730Z",
        "url": "https://files.pythonhosted.org/packages/83/13/c2630e4969e8176081c9b7be220f5684680f93b158b89d93e9d03bdf3fba/search_data_collector-0.2.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5b2188a134970241c1a1a1261a24927ad59d7b7247b4f50bfc9936e4d67f1233",
          "md5": "86dfba0a6d5c0dc03078c607f96d385a",
          "sha256": "4a1c3cbf26fbdc773b5d23d4bf3128ea8376e7c6153ff0db5989a87379ebbc8b"
        },
        "downloads": -1,
        "filename": "search_data_collector-0.3.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "86dfba0a6d5c0dc03078c607f96d385a",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.5",
        "size": 12577,
        "upload_time": "2023-01-06T17:30:26",
        "upload_time_iso_8601": "2023-01-06T17:30:26.029289Z",
        "url": "https://files.pythonhosted.org/packages/5b/21/88a134970241c1a1a1261a24927ad59d7b7247b4f50bfc9936e4d67f1233/search_data_collector-0.3.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f855d0e2b0fa914d46a6199279d22d0357ba72e69c6c1b431c997c036ea76e8c",
          "md5": "18b3523c5f8c741be42a96209ce24689",
          "sha256": "adf6554bb7dd8fb955ce7cf2193f173fecbdf42d9df7ea8136225f7964de2f75"
        },
        "downloads": -1,
        "filename": "search_data_collector-0.4.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "18b3523c5f8c741be42a96209ce24689",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.5",
        "size": 12936,
        "upload_time": "2023-02-26T07:58:17",
        "upload_time_iso_8601": "2023-02-26T07:58:17.685183Z",
        "url": "https://files.pythonhosted.org/packages/f8/55/d0e2b0fa914d46a6199279d22d0357ba72e69c6c1b431c997c036ea76e8c/search_data_collector-0.4.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "f855d0e2b0fa914d46a6199279d22d0357ba72e69c6c1b431c997c036ea76e8c",
        "md5": "18b3523c5f8c741be42a96209ce24689",
        "sha256": "adf6554bb7dd8fb955ce7cf2193f173fecbdf42d9df7ea8136225f7964de2f75"
      },
      "downloads": -1,
      "filename": "search_data_collector-0.4.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "18b3523c5f8c741be42a96209ce24689",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.5",
      "size": 12936,
      "upload_time": "2023-02-26T07:58:17",
      "upload_time_iso_8601": "2023-02-26T07:58:17.685183Z",
      "url": "https://files.pythonhosted.org/packages/f8/55/d0e2b0fa914d46a6199279d22d0357ba72e69c6c1b431c997c036ea76e8c/search_data_collector-0.4.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}