{
  "info": {
    "author": "\"Yangsibo Huang <yangsibo@princeton.edu>, Samyak Gupta <samyakg@princeton.edu\"",
    "author_email": "\"samyakg@princeton.edu\"",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "![GradAttack](assets/GradAttack_logo.gif)\n\n[![Python Package using Conda](https://github.com/Princeton-SysML/GradAttack/actions/workflows/python-test.yml/badge.svg)](https://github.com/Princeton-SysML/GradAttack/actions/workflows/python-test.yml)\n\nGradAttack is a Python library for easy evaluation of privacy risks in public gradients in Federated Learning, as well as corresponding mitigation strategies. The current version focuses on the gradient inversion attack in the image classification task, which recovers *private* images from *public* gradients. \n\n\n## Motivation\n\nRecent research shows that sending gradients instead of data in Federated Learning can leak private information  (see [this growing list of attack paper](papers/gradient_inversion.md#papers-for-attacks)). These attacks demonstrate that an adversary eavesdropping on a client’s communications (i.e. observing the global modelweights and client update) can accurately reconstruct a client’s private data using a class of techniques known as “gradient inversion attacks\", which raise serious concerns about such privacy leakage.\n\n\nTo counter these attacks, researchers have proposed defense mechanisms (see [this growing list of defense paper](papers/gradient_inversion.md#papers-for-defenses)). We are developing this framework to evaluate different defense mechanisms against state-of-the-art attacks. \n\n\n## Why GradAttack?\n\nThere are lots of reasons to use GradAttack:\n\n- :smiling_imp:&nbsp; **Evaluate the privacy risk of your Federated Learning pipeline** by running on it various attacks supported by GradAttack \n\n- :pill:&nbsp; **Enhance the privacy of your Federated Learning pipeline** by applying defenses supported by GradAttack in a plug-and-play fashion\n\n- :wrench:&nbsp; **Research and develop new gradient attacks and defenses** by reusing the simple and extensible APIs in GradAttack\n\n### Slack Channel\n\nFor help and realtime updates related to GradAttack, please join [the GradAttack Slack](https://join.slack.com/t/gradattack/shared_invite/zt-yrbi6lf9-VRrzQcJUeGf185xDr4J~4A)!\n\n\n## Installation\n\nYou may install GradAttack directly from PyPi using `pip`:\n\n```\npip install gradattack\n```\n\nYou can also install directly from the source for the latest features:\n```\ngit clone https://github.com/Princeton-SysML/GradAttack\ncd GradAttack\npip install -e .\n```\n\n## Getting started\n\nTo evaluate your model's privacy leakage against the gradient inversion attack, all you need to do is to:\n\n1. Define your deep learning pipeline\n```python\ndatamodule = CIFAR10DataModule()\nmodel = create_lightning_module(\n        'ResNet18',\n        training_loss_metric=loss,\n        **hparams,\n    )\ntrainer = pl.Trainer(\n        gpus=devices,\n        check_val_every_n_epoch=1,\n        logger=logger,\n        max_epochs=args.n_epoch,\n        callbacks=[early_stop_callback],\n    )\npipeline = TrainingPipeline(model, datamodule, trainer)\n```\n2. (Optional) Apply defenses to the pipeline\n```python\ndefense_pack = DefensePack(args, logger)\ndefense_pack.apply_defense(pipeline)\n```\n3. Run training with the pipeline (see detailed example scripts and bashes in [examples](examples/bashes/train_cifar10_bashes.md))\n```\npipeline.run()\npipeline.test()\n```\n\nYou may use the tensorboard logs to track your training and to compare results of different runs:\n```\ntensorboard --logdir PATH_TO_TRAIN_LOGS\n```\n![Example of training logs](assets/train_log.png)\n\n4. Run attack on the pipeline (see detailed example scripts and bashes in [examples](examples/bashes/attack_cifar10_bashes.md))\n```python\n# Fetch a victim batch and define an attack instance\nexample_batch = pipeline.get_datamodule_batch()\nbatch_gradients, step_results = pipeline.model.get_batch_gradients(\n        example_batch, 0)\nbatch_inputs_transform, batch_targets_transform = step_results[\n    \"transformed_batch\"]\nattack_instance = GradientReconstructor(\n    pipeline,\n    ground_truth_inputs=batch_inputs_transform,\n    ground_truth_gradients=batch_gradients,\n    ground_truth_labels=batch_targets_transform,\n)\n\n# Define the attack instance and launch the attack\nattack_trainer = pl.Trainer(\n    max_epochs=10000,\n)\nattack_trainer.fit(attack_instance,)\n```\n\nYou may use the tensorboard logs to track your attack and to compare results of different runs:\n```\ntensorboard --logdir PATH_TO_ATTACK_LOGS\n```\n![Example of training logs](assets/attack_log.png)\n\n5. Evalute the attack results (see [examples](examples/bashes/calc_metric_bashes.md))\n```shell\npython examples/calc_metric.py --dir PATH_TO_ATTACK_RESULTS\n```\n\n## Contributing to GradAttack\n\nGradAttack is currently in an \"alpha\" stage in which we are working to improve its capabilities and design.\n\nContributions are welcome! See [the contributing guide](CONTRIBUTE.md) for detailed instructions on how to contribute to our project.\n\n## Citing GradAttack\n\nIf you want to use GradAttack for your research (much appreciated!), you can cite it as follows:\n\n```bibtex\n@inproceedings{huang2021evaluating,\n  title={Evaluating Gradient Inversion Attacks and Defenses in Federated Learning},\n  author={Huang, Yangsibo and Gupta, Samyak and Song, Zhao and Li, Kai and Arora, Sanjeev},\n  booktitle={NeurIPS},\n  year={2021}\n}\n```\n\n## Acknowledgement\n\nThis project is supported in part by Ma Huateng Foundation, Schmidt Foundation, NSF, Simons Foundation, ONR and DARPA/SRC. Yangsibo Huang and Samyak Gupta are supported in part by the Princeton Graduate Fellowship.\nWe would like to thank Quanzheng Li, Xiaoxiao Li, Hongxu Yin and Aoxiao Zhong for helpful discussions, and members of Kai Li’s and Sanjeev Arora’s research groups for comments on early versions of this library.\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/Princeton-SysML/GradAttack",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "GradAttack",
    "package_url": "https://pypi.org/project/GradAttack/",
    "platform": "",
    "project_url": "https://pypi.org/project/GradAttack/",
    "project_urls": {
      "Bug Tracker": "https://github.com/Princeton-SysML/GradAttack/issues",
      "Homepage": "https://github.com/Princeton-SysML/GradAttack"
    },
    "release_url": "https://pypi.org/project/GradAttack/0.1.2/",
    "requires_dist": [
      "colorama (==0.4.4)",
      "matplotlib (==3.4.3)",
      "numpy (==1.21.4)",
      "opacus (==0.14.0)",
      "pytorch-lightning (==1.3.1)",
      "scikit-learn (==1.0.1)",
      "torch (==1.8.1)",
      "torchcsprng (==0.2.1)",
      "torchmetrics (==0.6.0)",
      "torchvision (==0.9.1)"
    ],
    "requires_python": ">=3.8",
    "summary": "A small example package",
    "version": "0.1.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12169098,
  "releases": {
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9e1a207da05ae35be693316c4265da20b87fbc628319e2525c8067114e29c03b",
          "md5": "c84210a4593d74692d46156970ec31dd",
          "sha256": "70a6fc46a47faf53f495a0af6f2dbb61589b7e0b9da744c8dce1a2625aa7987d"
        },
        "downloads": -1,
        "filename": "GradAttack-0.1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "c84210a4593d74692d46156970ec31dd",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 51344,
        "upload_time": "2021-11-30T18:00:33",
        "upload_time_iso_8601": "2021-11-30T18:00:33.452241Z",
        "url": "https://files.pythonhosted.org/packages/9e/1a/207da05ae35be693316c4265da20b87fbc628319e2525c8067114e29c03b/GradAttack-0.1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fe3386ff29fa5bfa0e98e56bcc24a314c957e55b94fe71b06c5ecca183fce853",
          "md5": "54290f2f6ae8b594020cee511b666d0c",
          "sha256": "791d05569bbab0953c819727789e7452f4b1790a8dcdd7e6a537acad61d4cdee"
        },
        "downloads": -1,
        "filename": "GradAttack-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "54290f2f6ae8b594020cee511b666d0c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 38508,
        "upload_time": "2021-11-30T18:00:34",
        "upload_time_iso_8601": "2021-11-30T18:00:34.827185Z",
        "url": "https://files.pythonhosted.org/packages/fe/33/86ff29fa5bfa0e98e56bcc24a314c957e55b94fe71b06c5ecca183fce853/GradAttack-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8b02247b12d4ad9f2745a48e8598616c5315a76b073520ea6ede95b987e91aff",
          "md5": "3e7d75231a9eaec56c56ac1fbc367fba",
          "sha256": "447826635f835d20c2125d011d9badd992fefd2fb7ac77310785d695fa4755ca"
        },
        "downloads": -1,
        "filename": "GradAttack-0.1.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "3e7d75231a9eaec56c56ac1fbc367fba",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 52128,
        "upload_time": "2021-11-30T19:08:14",
        "upload_time_iso_8601": "2021-11-30T19:08:14.194673Z",
        "url": "https://files.pythonhosted.org/packages/8b/02/247b12d4ad9f2745a48e8598616c5315a76b073520ea6ede95b987e91aff/GradAttack-0.1.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "27688e8f3c076474ca5b765246bb40f8442376a74fc59a6f08f8f21f005fb4d7",
          "md5": "d48e7c17aba43655ff9976acc1febe86",
          "sha256": "2b6ad8c9c874948c036dc87700a6b310f5ffcc5d8916a6aa659f899f311f4452"
        },
        "downloads": -1,
        "filename": "GradAttack-0.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "d48e7c17aba43655ff9976acc1febe86",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 39194,
        "upload_time": "2021-11-30T19:08:15",
        "upload_time_iso_8601": "2021-11-30T19:08:15.984703Z",
        "url": "https://files.pythonhosted.org/packages/27/68/8e8f3c076474ca5b765246bb40f8442376a74fc59a6f08f8f21f005fb4d7/GradAttack-0.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "8b02247b12d4ad9f2745a48e8598616c5315a76b073520ea6ede95b987e91aff",
        "md5": "3e7d75231a9eaec56c56ac1fbc367fba",
        "sha256": "447826635f835d20c2125d011d9badd992fefd2fb7ac77310785d695fa4755ca"
      },
      "downloads": -1,
      "filename": "GradAttack-0.1.2-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "3e7d75231a9eaec56c56ac1fbc367fba",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.8",
      "size": 52128,
      "upload_time": "2021-11-30T19:08:14",
      "upload_time_iso_8601": "2021-11-30T19:08:14.194673Z",
      "url": "https://files.pythonhosted.org/packages/8b/02/247b12d4ad9f2745a48e8598616c5315a76b073520ea6ede95b987e91aff/GradAttack-0.1.2-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "27688e8f3c076474ca5b765246bb40f8442376a74fc59a6f08f8f21f005fb4d7",
        "md5": "d48e7c17aba43655ff9976acc1febe86",
        "sha256": "2b6ad8c9c874948c036dc87700a6b310f5ffcc5d8916a6aa659f899f311f4452"
      },
      "downloads": -1,
      "filename": "GradAttack-0.1.2.tar.gz",
      "has_sig": false,
      "md5_digest": "d48e7c17aba43655ff9976acc1febe86",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.8",
      "size": 39194,
      "upload_time": "2021-11-30T19:08:15",
      "upload_time_iso_8601": "2021-11-30T19:08:15.984703Z",
      "url": "https://files.pythonhosted.org/packages/27/68/8e8f3c076474ca5b765246bb40f8442376a74fc59a6f08f8f21f005fb4d7/GradAttack-0.1.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}