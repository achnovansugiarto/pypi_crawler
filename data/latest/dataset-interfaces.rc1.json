{
  "info": {
    "author": "MadryLab",
    "author_email": "jvendrow@mit.edu",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# Dataset Interfaces\n\nThis repository contains the code for our recent work:\n\n**Dataset Interfaces: Diagnosing Model Failures Using Controllable Counterfactual Generation** <br>\n*Joshua Vendrow\\*, Saachi Jain\\*, Logan Engstrom, Aleksander Madry* <br>\nPaper: [https://arxiv.org/abs/2302.07865](https://arxiv.org/abs/2302.07865) <br>\nBlog post: [https://gradientscience.org/dataset-interfaces/](https://gradientscience.org/dataset-interfaces/)\n\n<p>\n<img src=\"dogs.png\" width=\"1000\" >\n</p>\n\n## Getting started\nInstall using pip, or clone our repository.\n```\npip install dataset-interfaces\n```\n\n**Example:** For a walkthrough of codebase, check out our [example notebook](notebooks/Example.ipynb). This notebook shows how to\nconstruct a dataset interface for a subset of ImageNet and generate counterfactual examples. \n\nBefore running `run_textual_inverson`, initialize an [ðŸ¤—Accelerate](https://github.com/huggingface/accelerate/) environment with:\n\n```bash\naccelerate config\n```\n\n## Constructing a Dataset Interface\nConstructing a dataset interface consists or learning a *class token* for each class in a datset, which can then be included in textual prompts. \n\nTo learn a single token, we use the following function:\n```python\nfrom dataset_interfaces import run_textual_inversion\n\nembed = run_textual_inversion (\n    train_path=train_path,  # path to directory with training set for a single class\n    token=token,            # text to use for new token, e.g \"<plate>\"\n    class_name=class_name,  # natrual language class description, e.g., \"plate\"\n)\n```\n\nOnce all the class tokens are learned, we can create a custom tokenizer and text encoder with these tokens:\n\n```python\nimport inference_utils as infer_utils\n\ninfer_utils.create_encoder (\n    embeds=embeds,             # list of learned embeddings (from the code block above)\n    tokens=tokens,             # list of token strings\n    class_names=class_names,   # list of natural language class descriptions\n    encoder_root=encoder_root  # path where to store the tokenizer and encoder\n)\n```\n\n## Generating Counterfactual Examples\n\nWe can now generate counterfactual examples by incorporating our learned tokens in textual prompts. The ``generate`` function generates images for a specific class in the dataset (indexed in the order that classes are passed when constructing the encoder). When specifying the text prompt, \"<TOKEN>\" acts as a placeholder for the class token.\n```python\nfrom dataset_interfaces import generate\n\ngenerate (\n    encoder_root=encoder_root,\n    c=c,                                          # index of a specific class\n    prompts=\"a photo of a <TOKEN> in the grass\",  # can be a single prompt or a list of prompts\n    num_samples=10, \n    random_seed=0                                 # no seed by default\n)\n```\n\n## CLIP Metric\n\nTo directly evaluate the quality of the generated image, we use *CLIP similarity* to quantify the presence of the object of interest and desired distribution shift in the image.\n\nWe can measure CLIP similarity between a set of generated images and a given caption as follows:\n\n```\nsim_class = infer_utils.clip_similarity(imgs, \"a photo of a dog\")\nsim_shift = infer_utils.clip_similarity(imgs, \"a photo in the grass\")\n```\n\n\n## ImageNet* Benchmark\nOur benchmark for the ImageNet dataset consists of two components: our 1,000 learned class tokens for ImageNet, and the images generated by these tokens in 23 distribution shifts. \n\n### ImageNet* Tokens\n\nThe 1,000 learned tokens are avaiable on [HuggingFace](https://huggingface.co/datasets/madrylab/imagenet-star-tokens) and can be downloaded with:\n```\nwget https://huggingface.co/datasets/madrylab/imagenet-star-tokens/resolve/main/tokens.zip\n```\nTo generate images with these tokens, we first create a text encoder with the tokens, which we use to seamlessly integrate the tokens in text prompts:\n\n```python\ntoken_path = \"./tokens\". # path to the tokens from HuggingFace\ninfer_utils.create_imagenet_star_encoder(token_path, encoder_root=\"./encoder_root_imagenet\")\n```\nNow, we can generate counterfactual examples of ImageNet from a textual prompt (See the [example notebook](notebooks/Example.ipynb) for a walk-through):\n```python\nfrom dataset_interfaces import generate\n\nencoder_root = \"./encoder_root_imagenet\"\nc = 207  # the class for golden retriever\nprompt = \"a photo of a <TOKEN> wearing a hat\"\ngenerate(encoder_root, c, prompt, num_samples=10)\n```\n\n### ImageNet* Images\nOur benchmark contains images in 23 distribution shifts, with 50k images per shift (50 per class for 1000 classes). These images are also available on [HuggingFace](https://huggingface.co/datasets/madrylab/imagenet-star). In this repo we also provide masks for each distribution shift indicating which images we filter out with our CLIP metrics, at `masks.npy`.\n\nWe provide a wrapper on top `torchvision.datasets.ImageFolder` to construct a dataset object that filters the images o=un the benchmark using this mask. So, we can make a dataset object for a shift as follows:\n\n```python\nfrom dataset_interfaces import utils\n\nroot = \"./imagenet-star\"     # the path where the dataset from HuggingFace\nmask_path = \"./masks.npy\"    # the path to the mask file\nshift = \"in_the_snow\"        # the distribution shift of interest\n\nds = utils.ImageNet_Star_Dataset(\n    root, \n    shift=shift,\n    mask_path=mask_path\n)\n```\n\n## Citation\nTo cite this paper, please use the following BibTex entry:\n```\n@inproceedings{vendrow2023dataset,\n   title = {Dataset Interfaces: Diagnosing Model Failures Using Controllable Counterfactual Generation},\n   author = {Joshua Vendrow and Saachi Jain and Logan Engstrom and Aleksander Madry}, \n   booktitle = {ArXiv preprint arXiv:2302.07865},\n   year = {2023}\n}\n```\n\n## Maintainers:\n[Josh Vendrow](https://twitter.com/josh_vendrow)<br>\n[Saachi Jain](https://twitter.com/saachi_jain_)\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/MadryLab/dataset-interfaces",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "dataset-interfaces",
    "package_url": "https://pypi.org/project/dataset-interfaces/",
    "platform": null,
    "project_url": "https://pypi.org/project/dataset-interfaces/",
    "project_urls": {
      "Homepage": "https://github.com/MadryLab/dataset-interfaces"
    },
    "release_url": "https://pypi.org/project/dataset-interfaces/0.1.0/",
    "requires_dist": [
      "torch",
      "numpy",
      "torchvision",
      "diffusers",
      "transformers",
      "accelerate"
    ],
    "requires_python": "",
    "summary": "Dataset Interfaces",
    "version": "0.1.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17071945,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6df40ac632d224791b1c3cdf9b5b1aa61bdbb1e69f8053ba26a15056bb44b871",
          "md5": "a4873797febeef4b3865583c770280b4",
          "sha256": "fd5402215195e3f8c27f7f94e533f59df6f70b5805c5b56ff4b8b45b3ea52e8f"
        },
        "downloads": -1,
        "filename": "dataset_interfaces-0.1.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "a4873797febeef4b3865583c770280b4",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 40666,
        "upload_time": "2023-02-27T20:23:25",
        "upload_time_iso_8601": "2023-02-27T20:23:25.833454Z",
        "url": "https://files.pythonhosted.org/packages/6d/f4/0ac632d224791b1c3cdf9b5b1aa61bdbb1e69f8053ba26a15056bb44b871/dataset_interfaces-0.1.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9d71c9c5ba1c7ad15c0a20c691d1ca825f4ad4f60658da3a9f9e309e31adc5eb",
          "md5": "36f0b4ec08c13da3e919eb6056e33b9b",
          "sha256": "40ca0a8aef1c7153109a706b0e77d9d5d4e782b0640baebe4935189f66b52106"
        },
        "downloads": -1,
        "filename": "dataset_interfaces-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "36f0b4ec08c13da3e919eb6056e33b9b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 41372,
        "upload_time": "2023-02-27T20:23:28",
        "upload_time_iso_8601": "2023-02-27T20:23:28.132654Z",
        "url": "https://files.pythonhosted.org/packages/9d/71/c9c5ba1c7ad15c0a20c691d1ca825f4ad4f60658da3a9f9e309e31adc5eb/dataset_interfaces-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "6df40ac632d224791b1c3cdf9b5b1aa61bdbb1e69f8053ba26a15056bb44b871",
        "md5": "a4873797febeef4b3865583c770280b4",
        "sha256": "fd5402215195e3f8c27f7f94e533f59df6f70b5805c5b56ff4b8b45b3ea52e8f"
      },
      "downloads": -1,
      "filename": "dataset_interfaces-0.1.0-py2.py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "a4873797febeef4b3865583c770280b4",
      "packagetype": "bdist_wheel",
      "python_version": "py2.py3",
      "requires_python": null,
      "size": 40666,
      "upload_time": "2023-02-27T20:23:25",
      "upload_time_iso_8601": "2023-02-27T20:23:25.833454Z",
      "url": "https://files.pythonhosted.org/packages/6d/f4/0ac632d224791b1c3cdf9b5b1aa61bdbb1e69f8053ba26a15056bb44b871/dataset_interfaces-0.1.0-py2.py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "9d71c9c5ba1c7ad15c0a20c691d1ca825f4ad4f60658da3a9f9e309e31adc5eb",
        "md5": "36f0b4ec08c13da3e919eb6056e33b9b",
        "sha256": "40ca0a8aef1c7153109a706b0e77d9d5d4e782b0640baebe4935189f66b52106"
      },
      "downloads": -1,
      "filename": "dataset_interfaces-0.1.0.tar.gz",
      "has_sig": false,
      "md5_digest": "36f0b4ec08c13da3e919eb6056e33b9b",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 41372,
      "upload_time": "2023-02-27T20:23:28",
      "upload_time_iso_8601": "2023-02-27T20:23:28.132654Z",
      "url": "https://files.pythonhosted.org/packages/9d/71/c9c5ba1c7ad15c0a20c691d1ca825f4ad4f60658da3a9f9e309e31adc5eb/dataset_interfaces-0.1.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}