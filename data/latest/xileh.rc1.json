{
  "info": {
    "author": "",
    "author_email": "Matthias Dold <matthias.dold@gmx.net>",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Xileh\nModule for optimizing pipeline with genetic algorithms\n\n![xileh_gif](./assets/xileh_2022-05-02_16-35_small.gif)\n\n# General structure\nThe idea of this is to abstract complex processing pipelines based of the `scipy.pipeline` setup,\nbut with extended data capacities going beyond a feature matrix `X` and potential labels / regression\ntargets `y`.\nFor this end, the abstraction is based of two main components, the `pipeline` and the `pipelinedata`.\nThe pipeline consists of functions acting upon the pipeline data. Functions are added to the pipeline\nduring initialization and the pipeline is later evaluated given a `pipelinedata` entity.\n\n## Schematic\n![schematic](assets/schematic.png)\n\n## Why build something new?\nAs with every project, the first question should be, if there is anything already available which serves the purpose...\nIf looking at libraries in two main dimensions, i.e. `builting functionality` and `specificity / restrictions`, we would end up with the following graph IMHO.\n![func_spec_landscape](./assets/func_spec_landscape.svg)\n\nUsually one would not want to end up in the lower left quadrant of such a split, but here `xileh` aims to be exactly there. I.e. provide only a very limited scope of functionality built-in, but allow for maximal freedom of customization by being as general as possible.\n\nTake for example the `sklearn.Pipeline` which `xileh` is motivated on. It is great to build, store and evalute all kind of machine learning piplines, but it is very specific in which type (shape) of data it can process and how it its doing it (`fit` / `transform`). Of course `sklearn` as a whole has a huge bunch of functionaly implemented but then would need to have different processing steps glued together by custom code, no longer allowing for this single object describing the full pipeline.\n\nOther libraries like `hydra` are based of (a single) config file(s) which provide a good overview and single point of truth for the processing, but hence this again requires a quite specific format and might thus hinder rapid prototyping.\n\nSo xileh deliberatly wants to:\n* impose as little restrictions to you workflow as possible (dealing with arbitrary data objects and python functions)\n* integrate easily with a function's based workflow during development\n* provide a single source of truth for the processing\n* enable reuseabilty of whole pipelines by strongly motivating composition\n\n\n# Getting Started\n\n## Installation\nClone the `master` branch, or for compatebility of storing basic `mne` data entities, use the `mne` branch\n```bash\ngit clone git@github.com:bsdlab/xileh.git\n```\n\nFrom within the folder, install to your pip repo or just link, depeding on your liking.\n```bash\npip install .\n# or \npip install develop\n```\n\n## Pipelinedata\nThe `xileh.core.pipelinedata.xPData` implements the pipelinedata container, which contains of three elements:\n1.  A data entity, usually an array or array-like. Possible also a list of other `xPData` entities.\n2.  Header information as a dictionary containing information about the whole data set used to describe the data in 1.\n3.  Meta information as a dictionary containing meta data about 1., such as configuration info for the processing, aggregated measure, or per record meta data. Note that if a dictionary value has a shape property, it is assumed that it should contain a per record (i.e. 1 meta elements per value) info and is thus checked for its length upon initialization. So to provide an array which does not match the length of 1. you have to pack it into an object without shape property first.\n\nAll 1.-3. are potentially extended by processing steps within the pipeline. However, processing should in general not change any entities provided during initialization, but create new copies. There might be reasons however, where a change is required (e.g. memory constraint). Overwriting is thus not restricted.\n\n### Initializing a container\n\n```python\nfrom xileh import xPData\n\n# single data container -> nothing can be added\npdata = xPData(\"somedata\", name='mycontainer')\n\n# a container which can be dynamically extended, if the data arg is of type list\npdata = xPData([], name='mycontainer')\n\n# with header or meta data\npdata = xPData([], name='cont1',\n    header={'description': 'some useful container'}\n)\n\n# nested initialization\npdata = xPData(\n    [\n        xPData([1, 2, 3, 4], name='array_1')\n    ],\n    name='outer_container_1'\n)\n  \n\n#### Get and set\n`pytho \n# those getters are e \npdata.get_by_name('array_1') == pdata['array_1'] == pdata.array_1 \n\n# setting can be done accordingly\npdata.get_by_name('array_1').data = np.ones(3)\npdata['array_1'].data = np.ones(3)\npdata.array_1.data = np.ones(3)\n\n# or overwriting whole containers\ntd = xPData(np.ones(3), name='new_array')\npdata.get_by_name('array_1') = td\npdata['array_1'] = td\npdata.array_1 = td\n```\n\n### Add \n```python\n# basic way of adding a new container via get by name. Without the\n# create_if_missing=True, a None value would be returned\nnewc = pdata.get_by_name('newcont', create_if_missing=True)\nnewc.data = np.ones(123)\nnewc.header['description'] = 'A few ones for important reasons'\n\n# or more concise\npdata.add(np.ones, 'newcont', header={'description': 'A few ones for important reasons'})\n```\n\n### Delete \n```python\npdata.delete_by_name('newcont')\n```\n\n#### Some Utility\nSimply calling the container prints some overview info reflecting the hierarchy of stored data and indicating <name>: <type> if it is a *leaf-container*.\n\n```python\nIn [10]: pdata = xPData(\n    ...:     [\n    ...:         xPData([1, 2, 3, 4], name='array_1'),\n    ...:         xPData('string', name='string_1'), \n    ...:         xPData(pd.DataFrame(), name='df1')\n    ...:     ],\n    ...:     name='outer_container_1'\n    ...: )\n\nIn [11]: pdata\nOut[11]:\nxPData object at 0x7f8b023b3880 - with size 32\nouter_container_1:\n|   array_1:    list\n|   string_1:   <class 'str'>\n|   df1:        <class 'pandas.core.frame.DataFrame'>\n'--------------------\n```\n\nOnly container names:\n```python\nIn [12]: pdata.get_container_names()\nOut[12]: ['outer_container_1', 'array_1', 'string_1', 'df1']\n```\nDict of containers and types:\n```python\nIn [15]: pdata.get_containers()\nOut[15]:\n{'outer_container_1': [{'array_1': []},\n  {'string_1': str},\n  {'df1': pandas.core.frame.DataFrame}]}\n\nIn [14]: pdata.gc()\nOut[14]:\n{'outer_container_1': [{'array_1': []},\n  {'string_1': str},\n  {'df1': pandas.core.frame.DataFrame}]}\n```\n\n### Save and load\n```python\nIn [16]: pdata.save('./test_container')\n\nIn [17]: from xileh.core.pipelinedata import from_container\n\nIn [18]: newc = from_container('./test_container/')\n\nIn [19]: newc\nOut[19]:\nxPData object at 0x7f8b024e71c0 - with size 32\nouter_container_1:\n|   array_1:    list\n|   string_1:   <class 'str'>\n|   df1:        <class 'pandas.core.frame.DataFrame'>\n'--------------------\n```\n\n\n## Pipelines\nPipelines are concatenations of functions operating on `xPData` objects. Therefore, all pipeline functions shoud follow the pattern outlined below\n### Functions signature\n\n```python\ndef add_data_entity(pdata, name='myname', **kwargs):\n    \"\"\" \n    Add a simply data entity to the container \n\n    NOTE: A valid function for processing within a pipeline will have only\n    one arg, which is the xPData objects that is processed, but can have\n    any number of kwargs, which will also be logged with the pipeline object\n    \"\"\"\n    pdata.add([1, 2, 3] * size, name)\n\n    # Note, every function used in a pipeline needs to return the pdata object\n    # --> this is to make explicit, that the function modifies the pdata object\n    return pdata\n```\n\n### Initialization\n```python\npl = xPipeline('test_pipeline', log_eval=False)\npl.add_steps(\n    ('add_to_data', add_data_entity),\n    ('add_to_data_2', add_data_entity, {'name': 'another_test'}),\n)\n```\n\n### Representation\nCalling the pipeline object will list on the steps \n```python\nIn [5]: pl\nOut[5]:\n<xileh.core.pipeline.xPipeline object at 0x7f877d135cf0>\nPipeline name: test_pipeline\nSteps:\n        -> 'add_to_data'\n        -> 'add_to_data_2'\n\n```\nCalling for the `.steps` attribute will also show the internal list of tuples (`<name>`, `<function>`, `<kwargs_dict>`)\n```python\nIn [12]: pl.steps\nOut[12]:\n[('add_to_data',\n  <function __main__.add_data_entity(pdata, name='myname', **kwargs)>,\n  {}),\n ('add_to_data_2',\n  <function __main__.add_data_entity(pdata, name='myname', **kwargs)>,\n  {'name': 'another_test'})]\n\n```\n\nIt is also possible to look just at a specific step by looking for its name\n```python\nIn [14]: pl.get_step('add_to_data_2')\nOut[14]:\n(('add_to_data_2',\n  <function __main__.add_data_entity(pdata, name='myname', **kwargs)>,\n  {'name': 'another_test'}),\n 1)\n```\n\n\n### Evaluating the pipeline\nPipelines use the `.eval()` method to process data\n```python\npdata = xPData([], name='outercontainer')\npl.eval(pdata)          # will process the steps 'add_to_data' and 'add_to_data_2'\n```\n\n### Reuse in other modules\n\nIf pipelines are defined on a global scope in a script or module, you can simple import it:\n```python\nfrom xileh import xPData, xPipeline\nfrom my_module.my_script import my_pl as pre_pl\n\n# ================================= Functions =================================\ndef print_foo(pdata):\n    for name in pdata.get_container_names():\n        print(f\"{name} - {pdata[name].data}\")\n\n# ================================= Pipeline ==================================\npl = xPipeline('test_pipeline', log_eval=False)\n\npl.add_steps(\n    ('print_before', print_foo),\n    *pre_pl.steps,\n    ('print_after', print_foo)\n    )\n```\n\n### Modification\nSteps can either be replaced completely \n```python\nIn [17]: def foo(pdata, k='abc'):\n    ...:     return pdata\n    ...:\n\nIn [18]: pl.replace_step('add_to_data', ('new_step', foo))\n\nIn [19]: pl\nOut[19]:\n<xileh.core.pipeline.xPipeline object at 0x7f877d135cf0>\nPipeline name: test_pipeline\nSteps:\n        -> 'new_step'\n        -> 'add_to_data_2'\n        -> 'test_step'\n```\n\nor their kwargs can be modified\n```python\nIn [20]: pl.add_steps(('test_step', foo))\n\nIn [21]: pl.set_step_kwargs('test_step', k='cde')\n\nIn [22]: pl.steps\nOut[22]:\n[('add_to_data',\n  <function __main__.add_data_entity(pdata, name='myname', **kwargs)>,\n  {}),\n ('add_to_data_2',\n  <function __main__.add_data_entity(pdata, name='myname', **kwargs)>,\n  {'name': 'another_test'}),\n ('test_step', <function __main__.foo(pdata, k='abc')>, {'k': 'cde'})]\n\n```\n\nand of course they can be deleted\n```python\nIn [23]: pl.remove_step('new_step')\n\nIn [24]: pl\nOut[24]:\n<xileh.core.pipeline.xPipeline object at 0x7f877d135cf0>\nPipeline name: test_pipeline\nSteps:\n        -> 'add_to_data_2'\n        -> 'test_step'\nIn [25]: pl.remove_steps(['add_to_data_2', 'test_step'])\n\nIn [26]: pl\nOut[26]:\n<xileh.core.pipeline.xPipeline object at 0x7f877d135cf0>\nPipeline name: test_pipeline\nSteps:\n        ->\n```\n\n#### Early Stopping\nStopping an evaluation early can be achieved by setting `early_stop` parameter\nwithin the `pdata.header`. This would be done in any pipeline function\nwhich you would want to trigger an early stop (e.g. you load data and nothing\nis found -> skip all processing).\n\n```python\npdata.header['early_stop'] = True\n```\n\n## Working with xileh\nA general example of how a script could be structured is provided in this template\n#### Template\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "xileh",
    "package_url": "https://pypi.org/project/xileh/",
    "platform": null,
    "project_url": "https://pypi.org/project/xileh/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/xileh/0.0.1/",
    "requires_dist": [
      "pandas (>=1.5)",
      "pyyaml (>=6)",
      "tqdm (>=4.64)",
      "toml (>=0.10)"
    ],
    "requires_python": ">=3.6",
    "summary": "A pipeline abstraction tool helping you organise and reuse processing pipelines",
    "version": "0.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 15829985,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fff7ab82e91e66820568c0595f9fd82cc348ff505922abf1ba37f8ae72da56ea",
          "md5": "d19e143308c30fce21d9b8de3027b61f",
          "sha256": "4f9621ac9b1f8e9757c1eed89b7381e7b904c10b94bed95297e356d150de0183"
        },
        "downloads": -1,
        "filename": "xileh-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d19e143308c30fce21d9b8de3027b61f",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 32948,
        "upload_time": "2022-11-20T10:17:08",
        "upload_time_iso_8601": "2022-11-20T10:17:08.812148Z",
        "url": "https://files.pythonhosted.org/packages/ff/f7/ab82e91e66820568c0595f9fd82cc348ff505922abf1ba37f8ae72da56ea/xileh-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "db48358e160d9fca7037a73e2c662dbe526463b82354835ae53deb77af2be605",
          "md5": "5a18c886cd02fd1d0b05aabe72966977",
          "sha256": "60ee4b1cf89f8ddbc10484fdef9560043cbf384f6322aea453abd7d052b5dbc8"
        },
        "downloads": -1,
        "filename": "xileh-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "5a18c886cd02fd1d0b05aabe72966977",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 1922289,
        "upload_time": "2022-11-20T10:24:43",
        "upload_time_iso_8601": "2022-11-20T10:24:43.279898Z",
        "url": "https://files.pythonhosted.org/packages/db/48/358e160d9fca7037a73e2c662dbe526463b82354835ae53deb77af2be605/xileh-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "fff7ab82e91e66820568c0595f9fd82cc348ff505922abf1ba37f8ae72da56ea",
        "md5": "d19e143308c30fce21d9b8de3027b61f",
        "sha256": "4f9621ac9b1f8e9757c1eed89b7381e7b904c10b94bed95297e356d150de0183"
      },
      "downloads": -1,
      "filename": "xileh-0.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "d19e143308c30fce21d9b8de3027b61f",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 32948,
      "upload_time": "2022-11-20T10:17:08",
      "upload_time_iso_8601": "2022-11-20T10:17:08.812148Z",
      "url": "https://files.pythonhosted.org/packages/ff/f7/ab82e91e66820568c0595f9fd82cc348ff505922abf1ba37f8ae72da56ea/xileh-0.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "db48358e160d9fca7037a73e2c662dbe526463b82354835ae53deb77af2be605",
        "md5": "5a18c886cd02fd1d0b05aabe72966977",
        "sha256": "60ee4b1cf89f8ddbc10484fdef9560043cbf384f6322aea453abd7d052b5dbc8"
      },
      "downloads": -1,
      "filename": "xileh-0.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "5a18c886cd02fd1d0b05aabe72966977",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 1922289,
      "upload_time": "2022-11-20T10:24:43",
      "upload_time_iso_8601": "2022-11-20T10:24:43.279898Z",
      "url": "https://files.pythonhosted.org/packages/db/48/358e160d9fca7037a73e2c662dbe526463b82354835ae53deb77af2be605/xileh-0.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}