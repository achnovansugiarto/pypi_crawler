{
  "info": {
    "author": "C3 Lab",
    "author_email": "cameron.barrie@u.northwestern.edu",
    "bugtrack_url": null,
    "classifiers": [
      "Environment :: Console",
      "Intended Audience :: Developers",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Cython",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3.6"
    ],
    "description": "# Spacy Canonicalizer\n\n## Introduction\n\nSpacy Canonicalizer is a pipeline for spaCy that performs Linked Entity Extraction with Wikidata on a given Document.\nThe Entity Linking System operates by matching potential candidates from each sentence\n(subject, object, prepositional phrase, compounds, etc.) to aliases from Wikidata. The package allows to easily find the\ncategory behind each entity (e.g. \"banana\" is type \"food\" OR \"Microsoft\" is type \"company\"). It can is therefore useful\nfor information extraction tasks and labeling tasks.\n\nThe package was written before a working Linked Entity Solution existed inside spaCy. In comparison to spaCy's linked\nentity system, it has the following advantages:\n\n- no extensive training required (entity-matching via database)\n- knowledge base can be dynamically updated without retraining\n- entity categories can be easily resolved\n- grouping entities by category\n\nIt also comes along with a number of disadvantages:\n\n- it is slower than the spaCy implementation due to the use of a database for finding entities\n- no context sensitivity due to the implementation of the \"max-prior method\" for entitiy disambiguation (an improved\n  method for this is in progress)\n\n## Use\n\n```python\nimport spacy  # version 3.0.6'\n\n# initialize language model\nnlp = spacy.load(\"en_core_web_md\")\n\n# add pipeline (declared through entry_points in setup.py)\nnlp.add_pipe(\"entityLinker\", last=True)\n\ndoc = nlp(\"I watched the Pirates of the Caribbean last silvester\")\n\n# returns all entities in the whole document\nall_linked_entities = doc._.linkedEntities\n# iterates over sentences and prints linked entities\nfor sent in doc.sents:\n    sent._.linkedEntities.pretty_print()\n\n# OUTPUT:\n# https://www.wikidata.org/wiki/Q194318     Pirates of the Caribbean        Series of fantasy adventure films                                                                   \n# https://www.wikidata.org/wiki/Q12525597   Silvester                       the day celebrated on 31 December (Roman Catholic Church) or 2 January (Eastern Orthodox Churches)  \n\n```\n\n### EntityCollection\n\ncontains an array of entity elements. It can be accessed like an array but also implements the following helper\nfunctions:\n\n- <code>pretty_print()</code> prints out information about all contained entities\n- <code>print_super_classes()</code> groups and prints all entites by their super class\n\n```python\ndoc = nlp(\"Elon Musk was born in South Africa. Bill Gates and Steve Jobs come from the United States\")\ndoc._.linkedEntities.print_super_entities()\n# OUTPUT:\n# human (3) : Elon Musk,Bill Gates,Steve Jobs\n# country (2) : South Africa,United States of America\n# sovereign state (2) : South Africa,United States of America\n# federal state (1) : United States of America\n# constitutional republic (1) : United States of America\n# democratic republic (1) : United States of America\n```\n\n### EntityElement\n\neach linked Entity is an object of type <code>EntityElement</code>. Each entity contains the methods\n\n- <code>get_description()</code> returns description from Wikidata\n- <code>get_id()</code> returns Wikidata ID\n- <code>get_label()</code> returns Wikidata label\n- <code>get_span()</code> returns the span from the spacy document that contains the linked entity\n- <code>get_url()</code> returns the url to the corresponding Wikidata item\n- <code>pretty_print()</code> prints out information about the entity element\n- <code>get_sub_entities(limit=10)</code> returns EntityCollection of all entities that derive from the current\n  entityElement (e.g. fruit -> apple, banana, etc.)\n- <code>get_super_entities(limit=10)</code> returns EntityCollection of all entities that the current entityElement\n  derives from (e.g. New England Patriots -> Football Team))\n\n## Example\n\nIn the following example we will use SpacyEntityLinker to find find the mentioned Football Team in our text and explore\nother football teams of the same type\n\n```python\n\ndoc = nlp(\"I follow the New England Patriots\")\n\npatriots_entity = doc._.linkedEntities[0]\npatriots_entity.pretty_print()\n# OUTPUT:\n# https://www.wikidata.org/wiki/Q193390     \n# New England Patriots            \n# National Football League franchise in Foxborough, Massachusetts                    \n\nfootball_team_entity = patriots_entity.get_super_entities()[0]\nfootball_team_entity.pretty_print()\n# OUTPUT:\n# https://www.wikidata.org/wiki/Q17156793 \n# American football team          \n# organization, in which a group of players are organized to compete as a team in American football   \n\n\nfor child in football_team_entity.get_sub_entities(limit=32):\n    print(child)\n    # OUTPUT:\n    # New Orleans Saints\n    # New York Giants\n    # Pittsburgh Steelers\n    # New England Patriots\n    # Indianapolis Colts\n    # Miami Seahawks\n    # Dallas Cowboys\n    # Chicago Bears\n    # Washington Redskins\n    # Green Bay Packers\n    # ...\n```\n\n### Entity Linking Policy\n\nCurrently the only method for choosing an entity given different possible matches (e.g. Paris - city vs Paris -\nfirstname) is max-prior. This method achieves around 70% accuracy on predicting the correct entities behind link\ndescriptions on wikipedia.\n\n## Note\n\nThe Entity Linker at the current state is still experimental and should not be used in production mode.\n\n## Performance\n\nThe current implementation supports only Sqlite. This is advantageous for development because it does not requirement\nany special setup and configuration. However, for more performance critical usecases, a different database with\nin-memory access (e.g. Redis) should be used. This may be implemented in the future.\n\n## Installation\n\nTo install the package run: <code>pip install spacy-canonicalizer</code>\n\n## Versions:\n\n- <code>spacy_entity_linker>=0.0</code> (requires <code>spacy>=2.2,<3.0</code>)\n- <code>spacy_entity_linker>=1.0</code> (requires <code>spacy>=3.0</code>)\n\n## TODO\n\n- [ ] implement Entity Classifier based on sentence embeddings for improved accuracy\n- [ ] implement get_picture_urls() on EntityElement\n- [ ] retrieve statements for each EntityElement (inlinks + outlinks)",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/nu-c3lab/spaCy-canonicalizer",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "spacy-canonicalizer",
    "package_url": "https://pypi.org/project/spacy-canonicalizer/",
    "platform": null,
    "project_url": "https://pypi.org/project/spacy-canonicalizer/",
    "project_urls": {
      "Homepage": "https://github.com/nu-c3lab/spaCy-canonicalizer"
    },
    "release_url": "https://pypi.org/project/spacy-canonicalizer/1.0.2/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "Entity and Relationship Caninicalization Pipeline for spaCy",
    "version": "1.0.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 15919601,
  "releases": {
    "1.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8c4a8ab95863ef0a17b8c993c8db606d2e0e79cdb26b82785454b533e07269b1",
          "md5": "1610b10548e847f1db7d3cf8c19dbc9d",
          "sha256": "d2f46c429ed2a15c1e6fdc7b5a0d73e93f38523741fd04b3e21c5526f475fef7"
        },
        "downloads": -1,
        "filename": "spacy-canonicalizer-1.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "1610b10548e847f1db7d3cf8c19dbc9d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 15383,
        "upload_time": "2022-11-28T21:59:06",
        "upload_time_iso_8601": "2022-11-28T21:59:06.807918Z",
        "url": "https://files.pythonhosted.org/packages/8c/4a/8ab95863ef0a17b8c993c8db606d2e0e79cdb26b82785454b533e07269b1/spacy-canonicalizer-1.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "8c4a8ab95863ef0a17b8c993c8db606d2e0e79cdb26b82785454b533e07269b1",
        "md5": "1610b10548e847f1db7d3cf8c19dbc9d",
        "sha256": "d2f46c429ed2a15c1e6fdc7b5a0d73e93f38523741fd04b3e21c5526f475fef7"
      },
      "downloads": -1,
      "filename": "spacy-canonicalizer-1.0.2.tar.gz",
      "has_sig": false,
      "md5_digest": "1610b10548e847f1db7d3cf8c19dbc9d",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 15383,
      "upload_time": "2022-11-28T21:59:06",
      "upload_time_iso_8601": "2022-11-28T21:59:06.807918Z",
      "url": "https://files.pythonhosted.org/packages/8c/4a/8ab95863ef0a17b8c993c8db606d2e0e79cdb26b82785454b533e07269b1/spacy-canonicalizer-1.0.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}