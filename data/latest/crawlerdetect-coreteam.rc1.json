{
  "info": {
    "author": "Vitalii - DoryZi",
    "author_email": "moskrc@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Environment :: Console",
      "Environment :: Web Environment",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: BSD License",
      "Operating System :: OS Independent",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3 :: Only",
      "Programming Language :: Python :: 3.4",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Topic :: Internet",
      "Topic :: Internet :: WWW/HTTP :: Indexing/Search",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "## About CrawlerDetect\n\n**CrawlerDetect** is a Python version of PHP class @[CrawlerDetect](https://github.com/JayBizzle/Crawler-Detect).\n\nIt helps to detect  bots/crawlers/spiders via the user agent and other HTTP-headers. Currently able to detect 1,000's of bots/spiders/crawlers.\n\n### Installation\nRun `pip install crawlerdetect`\n\n### Usage\n\n#### Variant 1\n```Python\nfrom crawlerdetect import CrawlerDetect\ncrawler_detect = CrawlerDetect()\ncrawler_detect.isCrawler('Mozilla/5.0 (compatible; Sosospider/2.0; +http://help.soso.com/webspider.htm)')\n# true if crawler user agent detected\n```\n\n#### Variant 2\n```Python\nfrom crawlerdetect import CrawlerDetect\ncrawler_detect = CrawlerDetect(user_agent='Mozilla/5.0 (iPhone; CPU iPhone OS 7_1 like Mac OS X) AppleWebKit (KHTML, like Gecko) Mobile (compatible; Yahoo Ad monitoring; https://help.yahoo.com/kb/yahoo-ad-monitoring-SLN24857.html)')\ncrawler_detect.isCrawler()\n# true if crawler user agent detected\n```\n\n#### Variant 3\n```Python\nfrom crawlerdetect import CrawlerDetect\ncrawler_detect = CrawlerDetect(headers={'DOCUMENT_ROOT': '/home/test/public_html', 'GATEWAY_INTERFACE': 'CGI/1.1', 'HTTP_ACCEPT': '*/*', 'HTTP_ACCEPT_ENCODING': 'gzip, deflate', 'HTTP_CACHE_CONTROL': 'no-cache', 'HTTP_CONNECTION': 'Keep-Alive', 'HTTP_FROM': 'googlebot(at)googlebot.com', 'HTTP_HOST': 'www.test.com', 'HTTP_PRAGMA': 'no-cache', 'HTTP_USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/28.0.1500.71 Safari/537.36', 'PATH': '/bin:/usr/bin', 'QUERY_STRING': 'order=closingDate', 'REDIRECT_STATUS': '200', 'REMOTE_ADDR': '127.0.0.1', 'REMOTE_PORT': '3360', 'REQUEST_METHOD': 'GET', 'REQUEST_URI': '/?test=testing', 'SCRIPT_FILENAME': '/home/test/public_html/index.php', 'SCRIPT_NAME': '/index.php', 'SERVER_ADDR': '127.0.0.1', 'SERVER_ADMIN': 'webmaster@test.com', 'SERVER_NAME': 'www.test.com', 'SERVER_PORT': '80', 'SERVER_PROTOCOL': 'HTTP/1.1', 'SERVER_SIGNATURE': '', 'SERVER_SOFTWARE': 'Apache', 'UNIQUE_ID': 'Vx6MENRxerBUSDEQgFLAAAAAS', 'PHP_SELF': '/index.php', 'REQUEST_TIME_FLOAT': 1461619728.0705, 'REQUEST_TIME': 1461619728})\ncrawler_detect.isCrawler()\n# true if crawler user agent detected\n```\n#### Output the name of the bot that matched (if any)\n```Python\nfrom crawlerdetect import CrawlerDetect\ncrawler_detect = CrawlerDetect()\ncrawler_detect.isCrawler('Mozilla/5.0 (compatible; Sosospider/2.0; +http://help.soso.com/webspider.htm)')\n# true if crawler user agent detected\ncrawler_detect.getMatches()\n# Sosospider\n```\n\n### Contributing\nIf you find a bot/spider/crawler user agent that CrawlerDetect fails to detect, please submit a pull request with the regex pattern added to the array in `providers/crawlers.py` and add the failing user agent to `tests/crawlers.txt`.\n\nFailing that, just create an issue with the user agent you have found, and we'll take it from there :)\n\n### ES6 Library\nTo use this library with NodeJS or any ES6 application based, check out [es6-crawler-detect](https://github.com/JefferyHus/es6-crawler-detect).\n\n### .NET Library\nTo use this library in a .net standard (including .net core) based project, check out [NetCrawlerDetect](https://github.com/gplumb/NetCrawlerDetect).\n\n### Nette Extension\nTo use this library with the Nette framework, checkout [NetteCrawlerDetect](https://github.com/JanGalek/Crawler-Detect).\n\n### Ruby Gem\n\nTo use this library with Ruby on Rails or any Ruby-based application, check out [crawler_detect](https://github.com/loadkpi/crawler_detect) gem.\n\n_Parts of this class are based on the brilliant [MobileDetect](https://github.com/serbanghita/Mobile-Detect)_\n\n[![Analytics](https://ga-beacon.appspot.com/UA-72430465-1/Crawler-Detect/readme?pixel)](https://github.com/JayBizzle/Crawler-Detect)\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "https://github.com/CoreTeamIO/crawlerdetect/tarball/0.1.5",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/CoreTeamIO/crawlerdetect",
    "keywords": "crawler,crawler detect,crawler detector,crawlerdetect,python crawler detect",
    "license": "BSD",
    "maintainer": "",
    "maintainer_email": "",
    "name": "crawlerdetect-coreteam",
    "package_url": "https://pypi.org/project/crawlerdetect-coreteam/",
    "platform": "any",
    "project_url": "https://pypi.org/project/crawlerdetect-coreteam/",
    "project_urls": {
      "Documentation": "https://crawlerdetect.readthedocs.io",
      "Download": "https://github.com/CoreTeamIO/crawlerdetect/tarball/0.1.5",
      "Homepage": "https://github.com/CoreTeamIO/crawlerdetect"
    },
    "release_url": "https://pypi.org/project/crawlerdetect-coreteam/0.1.5/",
    "requires_dist": null,
    "requires_python": ">=3.4, <4",
    "summary": "CrawlerDetect is a Python class for detecting bots/crawlers/spiders via the user agent.",
    "version": "0.1.5",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8416291,
  "releases": {
    "0.1.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "03f4d3e72284794c634b8293e4e5616a0b471eff851187cbed39ab9909e21c8f",
          "md5": "31075a2e15750d7aa5d220f7fa32e4c3",
          "sha256": "d655966bcc348d913ac9f14c8e9b7afceac5187487019026e06064d3dd375f3c"
        },
        "downloads": -1,
        "filename": "crawlerdetect_coreteam-0.1.5-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "31075a2e15750d7aa5d220f7fa32e4c3",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": ">=3.4, <4",
        "size": 17167,
        "upload_time": "2020-10-15T06:52:24",
        "upload_time_iso_8601": "2020-10-15T06:52:24.857908Z",
        "url": "https://files.pythonhosted.org/packages/03/f4/d3e72284794c634b8293e4e5616a0b471eff851187cbed39ab9909e21c8f/crawlerdetect_coreteam-0.1.5-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "25bdf8c19076101ffe40b92f65962b48c16b8e0aa349d406785db793bac2cea4",
          "md5": "d893536ed157ef5f66f76ddf36a36c70",
          "sha256": "b1220d573409861abab40a01ce09a5780744d16667438071d7bbc3e21e1bf87e"
        },
        "downloads": -1,
        "filename": "crawlerdetect-coreteam-0.1.5.tar.gz",
        "has_sig": false,
        "md5_digest": "d893536ed157ef5f66f76ddf36a36c70",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.4, <4",
        "size": 17588,
        "upload_time": "2020-10-15T06:52:28",
        "upload_time_iso_8601": "2020-10-15T06:52:28.210782Z",
        "url": "https://files.pythonhosted.org/packages/25/bd/f8c19076101ffe40b92f65962b48c16b8e0aa349d406785db793bac2cea4/crawlerdetect-coreteam-0.1.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "03f4d3e72284794c634b8293e4e5616a0b471eff851187cbed39ab9909e21c8f",
        "md5": "31075a2e15750d7aa5d220f7fa32e4c3",
        "sha256": "d655966bcc348d913ac9f14c8e9b7afceac5187487019026e06064d3dd375f3c"
      },
      "downloads": -1,
      "filename": "crawlerdetect_coreteam-0.1.5-py2.py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "31075a2e15750d7aa5d220f7fa32e4c3",
      "packagetype": "bdist_wheel",
      "python_version": "py2.py3",
      "requires_python": ">=3.4, <4",
      "size": 17167,
      "upload_time": "2020-10-15T06:52:24",
      "upload_time_iso_8601": "2020-10-15T06:52:24.857908Z",
      "url": "https://files.pythonhosted.org/packages/03/f4/d3e72284794c634b8293e4e5616a0b471eff851187cbed39ab9909e21c8f/crawlerdetect_coreteam-0.1.5-py2.py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "25bdf8c19076101ffe40b92f65962b48c16b8e0aa349d406785db793bac2cea4",
        "md5": "d893536ed157ef5f66f76ddf36a36c70",
        "sha256": "b1220d573409861abab40a01ce09a5780744d16667438071d7bbc3e21e1bf87e"
      },
      "downloads": -1,
      "filename": "crawlerdetect-coreteam-0.1.5.tar.gz",
      "has_sig": false,
      "md5_digest": "d893536ed157ef5f66f76ddf36a36c70",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.4, <4",
      "size": 17588,
      "upload_time": "2020-10-15T06:52:28",
      "upload_time_iso_8601": "2020-10-15T06:52:28.210782Z",
      "url": "https://files.pythonhosted.org/packages/25/bd/f8c19076101ffe40b92f65962b48c16b8e0aa349d406785db793bac2cea4/crawlerdetect-coreteam-0.1.5.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}