{
  "info": {
    "author": "Filippos Christianos",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Intended Audience :: Developers",
      "Programming Language :: Python :: 3.7"
    ],
    "description": "<p align=\"center\">\n <img width=\"350px\" src=\"docs/img/rware.png\" align=\"center\" alt=\"Multi-Robot Warehouse (RWARE)\" />\n <p align=\"center\">A multi-agent reinforcement learning environment</p>\n</p>\n\n[![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](https://GitHub.com/Naereen/StrapDown.js/graphs/commit-activity)\n[![GitHub license](https://img.shields.io/github/license/Naereen/StrapDown.js.svg)](https://github.com/Naereen/StrapDown.js/blob/master/LICENSE)\n\n<h1>Table of Contents</h1>\n\n- [Environment Description](#environment-description)\n  - [What does it look like?](#what-does-it-look-like)\n  - [Action Space](#action-space)\n  - [Observation Space](#observation-space)\n  - [Dynamics: Collisions](#dynamics-collisions)\n  - [Rewards](#rewards)\n- [Environment Parameters](#environment-parameters)\n  - [Naming Scheme](#naming-scheme)\n  - [Custom layout](#custom-layout)\n- [Installation](#installation)\n- [Getting Started](#getting-started)\n- [Please Cite](#please-cite)\n\n\n# Environment Description\n\nThe multi-robot warehouse (RWARE) environment simulates a warehouse with robots moving and delivering requested goods. The simulator is inspired by real-world applications, in which robots pick-up shelves and deliver them to a workstation. Humans access the content of a shelf, and then robots can return them to empty shelf locations.\n\nThe environment is configurable: it allows for different sizes (difficulty), number of agents, communication capabilities, and reward settings (cooperative/individual). Of course, the parameters used in each experiment must be clearly reported to allow for fair comparisons between algorithms.\n\n## What does it look like?\n\nBelow is an illustration of a small (10x20) warehouse with four trained agents. Agents have been trained with the SEAC algorithm [[2](#please-cite)]. This visualisation can be achieved using the `env.render()` function as described later.\n\n<p align=\"center\">\n <img width=\"450px\" src=\"docs/img/rware.gif\" align=\"center\" alt=\"Multi-Robot Warehouse (RWARE) illustration\" />\n</p>\n\n\n## Action Space\nIn this simulation, robots have the following discrete action space:\n\nA={ Turn Left, Turn Right, Forward, Load/Unload Shelf }\n\nThe first three actions allow each robot only to rotate and move forward. Loading/Unloading only works when an agent is beneath a shelf on one of the predesignated locations.\n\n## Observation Space\nThe observation of an agent is partially observable and consists of a 3x3 (configurable) square centred on the agent. Inside this limited grid, all entities are observable:\n- The location, the rotation and whether the agent is carrying a shelf.\n- The location and rotation of other robots.\n- Shelves and whether they are currently in the request queue.\n\n## Dynamics: Collisions\nThe dynamics of the environment are also of particular interest. Like a real, 3-dimensional warehouse, the robots can move beneath the shelves. Of course, when the robots are loaded, they must use the corridors, avoiding any standing shelves.\n\nAny collisions are resolved in a way that allows for maximum mobility. When two or more agents attempt to move to the same location, we prioritise the one that also blocks others. Otherwise, the selection is done arbitrarily. The visuals below demonstrate the resolution of various collisions.\n\n Example 1                 |   Example 2               | Example 3\n:-------------------------:|:-------------------------:|:-------------------------:\n![](docs/img/collision1.gif)  |  ![](docs/img/collision2.gif)  |  ![](docs/img/collision3.gif)\n\n## Rewards\nAt each time a set number of shelves R is requested. When a requested shelf is brought to a goal location, another shelf is uniformly sampled and added to the current requests. Agents are rewarded for successfully delivering a requested shelf to a goal location, with a reward of 1. A significant challenge in these environments is for agents to deliver requested shelves but also finding an empty location to return the previously delivered shelf. Having multiple steps between deliveries leads a very sparse reward signal.\n\n# Environment Parameters\n\nThe multi-robot warehouse task is parameterised by:\n\n- The size of the warehouse which is preset to either tiny (10x11), small (10x20), medium (16x20), or large (16x29).\n- The number of agents N.\n- The number of requested shelves R. By default R=N, but easy and hard variations of the environment use R = 2N and R = N/2, respectively.\n\nNote that R directly affects the difficulty of the environment. A small R, especially on a larger grid, dramatically affects the sparsity of the reward and thus exploration: randomly bringing the correct shelf becomes increasingly improbable.\n\n## Naming Scheme\n\nWhile RWARE allows fine tuning of multiple parameters when using the Warehouse class, it also registers multiple default environments with Gym for simplicity.\n\nThe registered names look like `rware-tiny-2ag-v1` and might cryptic in the beginning, but it is not actually complicated. Every name always starts with rware. Next, the map size is appended as -tiny, -small, -medium, or -large. The number of robots in the map is selected as Xag with X being a number larger than one (e.g. -4ag for 4 agents). A difficulty modifier is optionally appended in the form of -easy or -hard, making requested shelves twice or half the number of agents (see section Rewards). Finally -v1 is the version as required by OpenAI Gym. In the time of writing all environments are v1, but we will increase it during changes or bugfixes.\n\nA few examples:\n```python\nenv = gym.make(\"rware-tiny-2ag-v1\")\nenv = gym.make(\"rware-small-4ag-v1\")\nenv = gym.make(\"rware-medium-6ag-hard-v1\")\n```\n\n\nOf course, more settings are available, but have to be changed during environment creation. For example:\n```python\nenv = gym.make(\"rware-tiny-2ag-v1\", sensor_range=3, request_queue_size=6)\n```\n\n## Custom layout\nYou can design a custom warehouse layout with the following:\n```python\nlayout = \"\"\"\n........\n...x....\n..x.x...\n.x...x..\n..x.x...\n...x....\n.g....g.\n\"\"\"\ngym = env.make(\"rware:rware-tiny-2ag-v1\", layout=layout)\n```\nThis will transform \"X\"s to shelves and \"G\"s to goal locations with a result like the one below:\n<p align=\"center\">\n <img width=\"300px\" src=\"docs/img/rware_round.png\" align=\"center\" alt=\"Multi-Robot Warehouse (RWARE) illustration\" />\n</p>\n\n\n\nA detailed explanation of all parameters can be found [here](https://github.com/semitable/robotic-warehouse/blob/4307b1fe3afa26de4ca4003fd04ab1319879832a/robotic_warehouse/warehouse.py#L132)\n\n# Installation\n\nAssuming you have Python3 (preferably on a virtual environment: venv or Anaconda) installed, you can use PyPI:\n```sh\npip install rware\n```\n\nIf you prefer to have the code available and be able to edit it, you can use Git to download and install it:\n```sh\ngit clone git@github.com:uoe-agents/robotic-warehouse.git\ncd robotic-warehouse\npip install -e .\n```\n\n# Getting Started\n\nRWARE was designed to be compatible with Open AI's Gym framework.\n\nCreating the environment is done exactly as one would create a Gym environment:\n\n```python\nimport gym\nimport rware\nenv = gym.make(\"rware-tiny-2ag-v1\")\n```\n\nYou can even bypass the `import` statement with Gym, and directly use:\n```python\nimport gym\nenv = gym.make(\"rware:rware-tiny-2ag-v1\")\n```\nThe `rware:` in the beginning of the environment name tells Gym to import the respective package.\n\nThe number of agents, the observation space, and the action space are accessed using:\n```python\nenv.n_agents  # 2\nenv.action_space  # Tuple(Discrete(5), Discrete(5))\nenv.observation_space  # Tuple(Box(XX,), Box(XX,))\n```\n\nThe returned spaces are from the Gym library (`gym.spaces`) Each element of the tuple corresponds to an agent, meaning that `len(env.action_space) == env.n_agents` and `len(env.observation_space) == env.n_agents` are always true.\n\nThe reset and step functions again are identical to Gym:\n\n```python\nobs = env.reset()  # a tuple of observations\n\nactions = env.action_space.sample()  # the action space can be sampled\nprint(actions)  # (1, 0)\nn_obs, reward, done, info = env.step(actions)\n\nprint(done)    # [False, False]\nprint(reward)  # [0.0, 0.0]\n```\nwhich leaves as to the only difference with Gym: the rewards and the done flag are lists, and each element corresponds to the respective agent.\n\nFinally, the environment can be rendered for debugging purposes:\n```python\nenv.render()\n```\nand should be closed before terminating:\n```python\nenv.close()\n```\n\n\n# Please Cite\nIf you use this environment, consider citing\n1. A comperative evaluation of MARL algorithms that includes this environment\n```\n@inproceedings{papoudakis2021benchmarking,\n   title={Benchmarking Multi-Agent Deep Reinforcement Learning Algorithms in Cooperative Tasks},\n   author={Georgios Papoudakis and Filippos Christianos and Lukas Sch√§fer and Stefano V. Albrecht},\n   booktitle = {Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks (NeurIPS)},\n   year={2021},\n   url = {http://arxiv.org/abs/2006.07869},\n   openreview = {https://openreview.net/forum?id=cIrPX-Sn5n},\n   code = {https://github.com/uoe-agents/epymarl},\n}\n```\n2. A method that achieves state-of-the-art performance in the robotic warehouse task\n```\n@inproceedings{christianos2020shared,\n author = {Christianos, Filippos and Sch\\\"{a}fer, Lukas and Albrecht, Stefano},\n booktitle = {Advances in Neural Information Processing Systems},\n editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},\n pages = {10707--10717},\n publisher = {Curran Associates, Inc.},\n title = {Shared Experience Actor-Critic for Multi-Agent Reinforcement Learning},\n url = {https://proceedings.neurips.cc/paper/2020/file/7967cc8e3ab559e68cc944c44b1cf3e8-Paper.pdf},\n volume = {33},\n year = {2020}\n}\n\n```",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/semitable/robotic-warehouse",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "rware",
    "package_url": "https://pypi.org/project/rware/",
    "platform": "",
    "project_url": "https://pypi.org/project/rware/",
    "project_urls": {
      "Homepage": "https://github.com/semitable/robotic-warehouse"
    },
    "release_url": "https://pypi.org/project/rware/1.0.3/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "Multi-Robot Warehouse environment for reinforcement learning",
    "version": "1.0.3",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12550402,
  "releases": {
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a27199280acd514d77aec0bab11e6989f5fe82f7cf69b137f61d06220dd0ef5d",
          "md5": "9db9b2dfc2961990b2c9e9d119d5d05d",
          "sha256": "2b6c922d665a46e850c60ed78e82d5c5262fa3607963a80c4f677b0c10af1e38"
        },
        "downloads": -1,
        "filename": "rware-1.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "9db9b2dfc2961990b2c9e9d119d5d05d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 13047,
        "upload_time": "2021-09-11T19:58:10",
        "upload_time_iso_8601": "2021-09-11T19:58:10.261951Z",
        "url": "https://files.pythonhosted.org/packages/a2/71/99280acd514d77aec0bab11e6989f5fe82f7cf69b137f61d06220dd0ef5d/rware-1.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6ce6ad05f2b50a7ce922a1675bda0a6eceb7e223423de0cba065af3851d1138e",
          "md5": "f1d44a99ec84315569b73f548ecd3618",
          "sha256": "34eb65fed4e63f4cd927d334279f0913b24cfa4a064d298983cfe7f9ea01dac1"
        },
        "downloads": -1,
        "filename": "rware-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "f1d44a99ec84315569b73f548ecd3618",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 14779,
        "upload_time": "2021-09-11T19:46:25",
        "upload_time_iso_8601": "2021-09-11T19:46:25.378784Z",
        "url": "https://files.pythonhosted.org/packages/6c/e6/ad05f2b50a7ce922a1675bda0a6eceb7e223423de0cba065af3851d1138e/rware-1.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9f0231740bcc03ec4aedf112335327d63e113df5e5c0f928c7e472561d48dcf4",
          "md5": "84b57e3feea8aeca941b6aa34f209398",
          "sha256": "5a33b7347bd224a44372be6d8f53ecee8f29cbf1fac306bd2479c43a75bb2c06"
        },
        "downloads": -1,
        "filename": "rware-1.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "84b57e3feea8aeca941b6aa34f209398",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 16738,
        "upload_time": "2021-09-11T20:01:38",
        "upload_time_iso_8601": "2021-09-11T20:01:38.561067Z",
        "url": "https://files.pythonhosted.org/packages/9f/02/31740bcc03ec4aedf112335327d63e113df5e5c0f928c7e472561d48dcf4/rware-1.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c5047a05a82f59308846e0928a86c8d2039f8e2c812003d81d3b02978428cd11",
          "md5": "9f050bcac94bf27524da365a6cf8df5c",
          "sha256": "cb3c0365b9fb5d77408e7e4c2ef5553bf4eff996e653adddca9175ee62d2c25f"
        },
        "downloads": -1,
        "filename": "rware-1.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "9f050bcac94bf27524da365a6cf8df5c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 19650,
        "upload_time": "2021-09-11T20:01:39",
        "upload_time_iso_8601": "2021-09-11T20:01:39.795300Z",
        "url": "https://files.pythonhosted.org/packages/c5/04/7a05a82f59308846e0928a86c8d2039f8e2c812003d81d3b02978428cd11/rware-1.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e374113db3f6b411edf7e21bdb0cd18da74120c687a8c46f8897e0498447bf67",
          "md5": "b8f5c4ad55692f2b155b843df31400ee",
          "sha256": "8eefa43540b02d1d5fc0b674e82135c6fae8a7b0cbb4817a01079aa04d98ae92"
        },
        "downloads": -1,
        "filename": "rware-1.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "b8f5c4ad55692f2b155b843df31400ee",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 17699,
        "upload_time": "2022-01-12T12:05:54",
        "upload_time_iso_8601": "2022-01-12T12:05:54.329003Z",
        "url": "https://files.pythonhosted.org/packages/e3/74/113db3f6b411edf7e21bdb0cd18da74120c687a8c46f8897e0498447bf67/rware-1.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "374e5baba0b4283852fc41654848fb42c5175e28b3884a7245a233801115fc23",
          "md5": "3e29a00c21454d68120789741c24dcb2",
          "sha256": "5e3876f35692ff1f283bee2bcb5c142ad32809427e3055911d44ca94cc9e8ca2"
        },
        "downloads": -1,
        "filename": "rware-1.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "3e29a00c21454d68120789741c24dcb2",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 20607,
        "upload_time": "2022-01-12T12:00:52",
        "upload_time_iso_8601": "2022-01-12T12:00:52.620801Z",
        "url": "https://files.pythonhosted.org/packages/37/4e/5baba0b4283852fc41654848fb42c5175e28b3884a7245a233801115fc23/rware-1.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "e374113db3f6b411edf7e21bdb0cd18da74120c687a8c46f8897e0498447bf67",
        "md5": "b8f5c4ad55692f2b155b843df31400ee",
        "sha256": "8eefa43540b02d1d5fc0b674e82135c6fae8a7b0cbb4817a01079aa04d98ae92"
      },
      "downloads": -1,
      "filename": "rware-1.0.3-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "b8f5c4ad55692f2b155b843df31400ee",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 17699,
      "upload_time": "2022-01-12T12:05:54",
      "upload_time_iso_8601": "2022-01-12T12:05:54.329003Z",
      "url": "https://files.pythonhosted.org/packages/e3/74/113db3f6b411edf7e21bdb0cd18da74120c687a8c46f8897e0498447bf67/rware-1.0.3-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "374e5baba0b4283852fc41654848fb42c5175e28b3884a7245a233801115fc23",
        "md5": "3e29a00c21454d68120789741c24dcb2",
        "sha256": "5e3876f35692ff1f283bee2bcb5c142ad32809427e3055911d44ca94cc9e8ca2"
      },
      "downloads": -1,
      "filename": "rware-1.0.3.tar.gz",
      "has_sig": false,
      "md5_digest": "3e29a00c21454d68120789741c24dcb2",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 20607,
      "upload_time": "2022-01-12T12:00:52",
      "upload_time_iso_8601": "2022-01-12T12:00:52.620801Z",
      "url": "https://files.pythonhosted.org/packages/37/4e/5baba0b4283852fc41654848fb42c5175e28b3884a7245a233801115fc23/rware-1.0.3.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}