{
  "info": {
    "author": "Antoine Amend",
    "author_email": "antoine.amend@databricks.com",
    "bugtrack_url": null,
    "classifiers": [
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Geoscan\n\n[![build](https://github.com/databrickslabs/geoscan/actions/workflows/push.yml/badge.svg?style=for-the-badge)](https://github.com/databrickslabs/geoscan/actions/workflows/push.yml) \n[![codecov](https://codecov.io/gh/databrickslabs/geoscan/branch/master/graph/badge.svg?token=0UKFCOO9OM&style=for-the-badge)](https://codecov.io/gh/databrickslabs/geoscan)\n\n*DBSCAN (density-based spatial clustering of applications with noise) is a clustering technique used to group points that\nare closely packed together. Compared to other clustering methodologies, it doesn't require you to indicate the number\nof clusters beforehand, can detect clusters of varying shapes and sizes and is strong at finding outliers that don't\nbelong to any cluster, hence a great candidate for geospatial analysis of card transactions and fraud detection.\nThis, however, comes with a serious price tag: DBSCAN requires all points to be compared\nto every other points in order to find dense neighborhoods where at least `minPts` points can be found within a\n`epsilon` radius.* \n\nHere comes **GEOSCAN**, our novel approach to DBSCAN algorithm for geospatial clustering, \nleveraging uber [H3](https://eng.uber.com/h3/) library to only group points we know are in close vicinity (according \nto H3 precision) and relying on [GraphX](https://spark.apache.org/docs/latest/graphx-programming-guide.html) to detect \ndense areas at massive scale. With such a framework, Financial services institutions can better understand user \nshopping behaviours and detect anomalous transactions in real time.\n\n### Usage\n\nThere are 2 modes our framework can be executed, **distributed** and **pseudo-distributed**.\n\n#### Distributed\n\nWorking **fully distributed**, we retrieve clusters from an entire dataframe using the Spark `Estimator` interface, \nhence fully compliant with the Spark Pipeline framework (model can be serialized / deserialized). \nIn this mode, the core of GEOSCAN algorithm relies on `GraphX` to detect points having `distance < epsilon` and a `degree > minPoints`. \nSee the next section for an explanation of our algorithm.\n\n#### Usage\n\n```python\nfrom geoscan import Geoscan\n\ngeoscan = Geoscan() \\\n    .setLatitudeCol(\"latitude\") \\\n    .setLongitudeCol(\"longitude\") \\\n    .setPredictionCol(\"cluster\") \\\n    .setEpsilon(100) \\\n    .setMinPts(3)\n\nmodel = geoscan.fit(points_df)\n```\n\n\n| parameter     | description                                     | default   |\n|---------------|-------------------------------------------------|-----------|\n| epsilon       | the minimum distance in meters between 2 points | 50        |\n| minPts        | the minimum number of neighbours within epsilon | 3         |\n| latitudeCol   | the latitude column                             | latitude  |\n| longitudeCol  | the longitude column                            | longitude |\n| predictionCol | the resulted prediction column                  | predicted |\n\n\nAs the core of GEOSCAN logic relies on the use of H3 polygons, it becomes natural to leverage the same for model \ninference instead of bringing in extra GIS dependencies for expensive point in polygons queries. Our model consists \nin clusters tiled with hexagons of a given resolution (driven by the `epsilon` parameter) that can easily be joined to our original dataframe. \nModel inference is fully supported as per the `Estimator` interface\n\n```python\nmodel.transform(points_df)\n```\n\nNote that when saving model to distributed file system, we converted our shapes into [GeoJson](https://tools.ietf.org/html/rfc7946) RFC 7946 \nformat so that clusters could be loaded as-is into GIS databases or any downstream application or libraries. \n\n```python\nfrom geoscan import GeoscanModel\nmodel.save('/tmp/geoscan_model/distributed')\nmodel = GeoscanModel.load('/tmp/geoscan_model/distributed')\n```\n\nModel can always be returned as a GeoJson object directly\n\n```python\nmodel.toGeoJson()\n```\n\nFinally, it may be useful to extract clusters as a series of H3 tiles that could be used outside a spark environment or outside GEOSCAN library.\nWe expose a `getTiles` method that fills all our polygons with H3 tiles of a given dimension, allowing shapes to spill over additional layers should\nwe want to also \"capture\" neighbours points.\n\n```python\nmodel.getTiles(precision, additional_layers)\n```\n\nThis process can be summarized with below picture. Note that although a higher granularity would\nfit a polygon better, the number of tiles it generates will grow exponentially.\n\n![tiling](https://raw.githubusercontent.com/databrickslabs/geoscan/master/images/tiling.png)\n\n#### Pseudo Distributed\n\nIt is fairly common to extract personalized clusters (e.g. for each user), and doing so sequentially would be terribly inefficient.\nFor that purpose, we extended our GEOSCAN class to support `RelationalGroupedDataset` and train multiple models in parallel, one for each group attribute. \nAlthough the implementation is different (using in-memory `scalax.collection.Graph` instead of distributed `GraphX`), \nthe core logic remains the same as explained in the next section and should yield the same clusters given a same user.\n\n#### Usage\n\nOne must provide a new parameter `groupedCol` to indicate our framework how to group dataframe and train multiple models in parallel.\n\n```python\nfrom geoscan import GeoscanPersonalized\n\ngeoscan = Geoscan() \\\n    .setLatitudeCol(\"latitude\") \\\n    .setLongitudeCol(\"longitude\") \\\n    .setPredictionCol(\"cluster\") \\\n    .setGroupedCol(\"user\") \\\n    .setEpsilon(100) \\\n    .setMinPts(3)\n\nmodel = geoscan.fit(points_df)\n```\n\nNote that the output signature differs from the distributed approach since we cannot return a single model but a collection of GEOJSON objects\n\n```python\nmodel.toGeoJson().show()\n```\n\n```\n+--------------------+--------------------+\n|                user|             cluster|\n+--------------------+--------------------+\n|72fc865a-0c34-409...|{\"type\":\"FeatureC...|\n|cc227e67-c6d1-40a...|{\"type\":\"FeatureC...|\n|9cafdb6d-9134-4ee...|{\"type\":\"FeatureC...|\n|804c7fa2-8063-4ba...|{\"type\":\"FeatureC...|\n|65bd17be-b030-44a...|{\"type\":\"FeatureC...|\n+--------------------+--------------------+\n```\n\nNote that standard `transform` and `getTiles` methods also apply in that mode. By tracking how tiles change overtime, \nthis framework can be used to detect user changing behaviour as represented in below animation using synthetic data.\n\n![trend](https://raw.githubusercontent.com/databrickslabs/geoscan/master/images/geoscan_window.gif)\n\n### Installation\n\nCompile GEOSCAN scala library that can be uploaded onto a Databricks cluster (DBR > 9.1). Activate `shaded` profile \nto include GEOSCAN dependencies as an assembly jar if needed\n\n```shell\nmvn clean package -Pshaded\n```\n\nAlternatively (preferred), install dependency from maven central directly in your spark based environment.\n\n```xml\n<dependency>\n    <groupId>com.databricks.labs</groupId>\n    <artifactId>geoscan</artifactId>\n    <version>0.1</version>\n</dependency>\n```\n\nFor python users, install the dependencies from pypi in addition to the above scala dependency.\n\n```shell script\npip install geoscan==0.1\n```\n\n### Release process\n\nOnce a change is approved, peer reviewed and merged back to `master` branch, a project admin will be able to promote \na new version to both maven central and pypi repo as a manual github action.\nSee `release.yaml` github action.\n\n### Project support\n\nPlease note that all projects in the /databrickslabs github account are provided for your exploration only, and are \nnot formally supported by Databricks with Service Level Agreements (SLAs). They are provided AS-IS and we do not make \nany guarantees of any kind. Please do not submit a support ticket relating to any issues arising from the use of these projects.\n\nAny issues discovered through the use of this project should be filed as GitHub Issues on the Repo. They will be reviewed \nas time permits, but there are no formal SLAs for support.\n\n### Author\n\n<antoine.amend@databricks.com>\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/aamend/geoscan",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "geoscan",
    "package_url": "https://pypi.org/project/geoscan/",
    "platform": null,
    "project_url": "https://pypi.org/project/geoscan/",
    "project_urls": {
      "Homepage": "https://github.com/aamend/geoscan"
    },
    "release_url": "https://pypi.org/project/geoscan/0.2.8/",
    "requires_dist": [
      "pytest ; extra == 'tests'"
    ],
    "requires_python": "",
    "summary": "Geoclustering using H3 hexagons",
    "version": "0.2.8",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14658137,
  "releases": {
    "0.2.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4d471009f7dba3708d7087b403ae28aec57ca0eee363d7f2f6a53450f959b781",
          "md5": "8f0d3b239908010949f0a7c2449e500f",
          "sha256": "52dd91aec6aa021388b48eb88ef1607f9aa371c0bb9cbb4505c74399bb5994b0"
        },
        "downloads": -1,
        "filename": "geoscan-0.2.6-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "8f0d3b239908010949f0a7c2449e500f",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 6581,
        "upload_time": "2022-07-14T21:06:45",
        "upload_time_iso_8601": "2022-07-14T21:06:45.566662Z",
        "url": "https://files.pythonhosted.org/packages/4d/47/1009f7dba3708d7087b403ae28aec57ca0eee363d7f2f6a53450f959b781/geoscan-0.2.6-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8cae2be37f3a7bb6451397e591a296c44a578aea08a96618f94f8b08ed9cc179",
          "md5": "b806e3b6b2f69abaa7948c9fcf4038d9",
          "sha256": "99c2d835e0c6054bd363bc765f280bc496247d46ba8a50f58f091fd31cfc6c46"
        },
        "downloads": -1,
        "filename": "geoscan-0.2.8-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "b806e3b6b2f69abaa7948c9fcf4038d9",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 6619,
        "upload_time": "2022-08-04T21:10:56",
        "upload_time_iso_8601": "2022-08-04T21:10:56.605459Z",
        "url": "https://files.pythonhosted.org/packages/8c/ae/2be37f3a7bb6451397e591a296c44a578aea08a96618f94f8b08ed9cc179/geoscan-0.2.8-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "8cae2be37f3a7bb6451397e591a296c44a578aea08a96618f94f8b08ed9cc179",
        "md5": "b806e3b6b2f69abaa7948c9fcf4038d9",
        "sha256": "99c2d835e0c6054bd363bc765f280bc496247d46ba8a50f58f091fd31cfc6c46"
      },
      "downloads": -1,
      "filename": "geoscan-0.2.8-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "b806e3b6b2f69abaa7948c9fcf4038d9",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 6619,
      "upload_time": "2022-08-04T21:10:56",
      "upload_time_iso_8601": "2022-08-04T21:10:56.605459Z",
      "url": "https://files.pythonhosted.org/packages/8c/ae/2be37f3a7bb6451397e591a296c44a578aea08a96618f94f8b08ed9cc179/geoscan-0.2.8-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}