{
  "info": {
    "author": "David Alami",
    "author_email": "davidalami@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Conversational Sentence Encoder \n[![GitHub license](https://img.shields.io/github/license/davidalami/ConveRT)](https://github.com/davidalami/ConveRT/blob/main/LICENSE)\n[![GitHub issues](https://img.shields.io/github/issues/davidalami/ConveRT)](https://github.com/davidalami/ConveRT/issues)\n[![GitHub forks](https://img.shields.io/github/forks/davidalami/ConveRT)](https://github.com/davidalami/ConveRT/network)\n[![GitHub stars](https://img.shields.io/github/stars/davidalami/ConveRT)](https://github.com/davidalami/ConveRT/stargazers)\n\nThis project features the ConveRT dual-encoder model, using subword representations \nand lighter-weight more efficient transformer-style blocks to encode text, \nas described in the [ConveRT paper](https://arxiv.org/abs/1911.03688). \nIt provides powerful representations for conversational data, \nand can also be used as a response ranker. \nAlso it features the multi-context ConveRT model, that uses extra contexts \nfrom the conversational history to refine the context representations. \nThe extra contexts are the previous messages in the dialogue \n(typically at most 10) prior to the immediate context.\n\n# Installation \nJust pip install the package (works for python 3.6.* and 3.7.*) and you are ready to go!\n```\npip install conversational-sentence-encoder\n```\n\n# Usage examples\nThe entry point of the package is SentenceEncoder class:\n```\nfrom conversational_sentence_encoder.vectorizers import SentenceEncoder\n```\nTo run the examples you will also need to \n```\npip install scikit-learn\n```\n## Text Classification / Intent Recognition / Sentiment Classification [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/davidalami/ConveRT/blob/main/examples/text_classification.ipynb)\nThe ConveRT model encodes sentences to a meaningful semantic space. Sentences can be compared for semantic similarity in this space, and NLP classifiers can be trained on top of these encodings\n```\nfrom sklearn import preprocessing\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# texts\nX = [\"hello ? can i speak to a actual person ?\",\n\"i ll wait for a human to talk to me\",\n\"i d prefer to be speaking with a human .\",\n\"ok i m not talking to a real person so\",\n\"ok . this is an automated message . i need to speak with a real human\",\n\"hello . i m so sorry but i d like to return . can you send me instructions . thank you\",\n\"im sorry i m not sure you understand what i need but i need to return a package i got from you guys\",\n\"how can i return my order ? no one has gotten back to me on here or emails i sent !\",\n\"i can t wait that long . even if the order arrives i will send it back !\",\n\"i have a question what is your return policy ? i ordered the wrong size\"]\n\n# labels\ny = [\"SPEAK_HUMAN\"]*5+[\"RETURN\"]*5\n\n# initialize the ConveRT dual-encoder model\nsentence_encoder = SentenceEncoder(multiple_contexts=False)\n\n# output 1024 dimensional vectors, giving a representation for each sentence. \nX_encoded = sentence_encoder.encode_sentences(X)\n\n# encode labels\nle = preprocessing.LabelEncoder()\ny_encoded = le.fit_transform(y)\n\n# fit the KNN classifier on the toy dataset\nclf = KNeighborsClassifier(n_neighbors=3).fit(X_encoded, y_encoded)\n\n\ntest = sentence_encoder.encode_sentences([\"are you all bots???\", \n                                          \"i will send this trash back!\"])\n\nprediction = clf.predict(test)\n\n# this will give the intents ['SPEAK_HUMAN' 'RETURN']\nprint(le.inverse_transform(prediction))\n```\n## Response Selection (Neural Ranking) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/davidalami/ConveRT/blob/main/examples/response_selection.ipynb)\nConveRT is trained on the response ranking task, so it can be used to find good responses to a given conversational context.\n\nThis section demonstrates how to rank responses, by computing cosine similarities of context and response representations in the shared response ranking space. Response representations for a fixed candidate list are first pre-computed. When a new context is provided, it is encoded and then compared to the pre-computed response representations.\n```\nimport numpy as np\n\n# initialize the ConveRT dual-encoder model\nsentence_encoder = SentenceEncoder(multiple_contexts=False)\n\nquestions = np.array([\"where is my order?\", \n                      \"what is the population of London?\",\n                      \"will you pay me for collaboration?\"])\n\n# outputs 512 dimensional vectors, giving the context representation of each input. \n#These are trained to have a high cosine-similarity with the response representations of good responses\nquestions_encoded = sentence_encoder.encode_contexts(questions)\n\n\nresponses = np.array([\"we expect you to work for free\",\n                      \"there are a lot of people\",\n                      \"its on your way\"])\n\n# outputs 512 dimensional vectors, giving the response representation of each input. \n#These are trained to have a high cosine-similarity with the context representations of good corresponding contexts\nresponses_encoded = sentence_encoder.encode_responses(responses)\n\n# computing pairwise similarities as a dot product\nsimilarity_matrix = questions_encoded.dot(responses_encoded.T)\n\n# indices of best answers to given questions\nbest_idx = np.argmax(similarity_matrix, axis=1)\n\n# will output answers in the right order\n# ['its on your way', 'there are a lot of people', 'we expect you to work for free']\nprint(np.array(responses)[best_idx])\n```\n## Multi-context response ranking/similarity/classification [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/davidalami/ConveRT/blob/main/examples/multi_context.ipynb)\nThis model takes extra dialogue history into account allowing to create smart conversational agents\n```\nimport numpy as np\nfrom conversational_sentence_encoder.vectorizers import SentenceEncoder\n\n# initialize the multi-context ConveRT model, that uses extra contexts from the conversational history to refine the context representations\nmulticontext_encoder = SentenceEncoder(multiple_contexts=True)\n\ndialogue = np.array([\"hello\", \"hey\", \"how are you?\"])\n\nresponses = np.array([\"where do you live?\", \"i am fine. you?\", \"i am glad to see you!\"])\n\n# outputs 512 dimensional vectors, giving the whole dialogue representation\ndialogue_encoded = multicontext_encoder.encode_multicontext(dialogue)\n\n# encode response candidates using the same model\nresponses_encoded = multicontext_encoder.encode_responses(responses)\n\n# get the degree of response fit to the existing dialogue\nsimilarities = dialogue_encoded.dot(responses_encoded.T)\n\n# find the best response\nbest_idx = np.argmax(similarities)\n\n# will output \"i am fine. you?\"\nprint(responses[best_idx])\n```\n# Notes\nThis project is a continuation of the abandoned https://github.com/PolyAI-LDN/polyai-models,\nit is distributed under the same license. \n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/davidalami/ConveRT",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "conversational-sentence-encoder",
    "package_url": "https://pypi.org/project/conversational-sentence-encoder/",
    "platform": null,
    "project_url": "https://pypi.org/project/conversational-sentence-encoder/",
    "project_urls": {
      "Homepage": "https://github.com/davidalami/ConveRT"
    },
    "release_url": "https://pypi.org/project/conversational-sentence-encoder/0.0.6/",
    "requires_dist": [
      "tensorflow (==2.8.0)",
      "tensorflow-hub (==0.12.0)",
      "tensorflow-text (==2.8.2)",
      "tf-sentencepiece (==0.1.90)",
      "tqdm (==4.64.0)"
    ],
    "requires_python": ">=3.7.0",
    "summary": "Dual sentence encoder package",
    "version": "0.0.6",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14678563,
  "releases": {
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4b8de74736c79f7a938f79fc2cb0639f16c373fe2ef64b78aa2426b41117490b",
          "md5": "2d0d344c2ee9e9239f789be6884eda31",
          "sha256": "81a270f793fb03c51ad8ddbc5837a0fe81dcf87066ed629662bc423e865ec801"
        },
        "downloads": -1,
        "filename": "conversational_sentence_encoder-0.0.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "2d0d344c2ee9e9239f789be6884eda31",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": "==3.6.*",
        "size": 9702,
        "upload_time": "2021-02-06T14:46:13",
        "upload_time_iso_8601": "2021-02-06T14:46:13.442974Z",
        "url": "https://files.pythonhosted.org/packages/4b/8d/e74736c79f7a938f79fc2cb0639f16c373fe2ef64b78aa2426b41117490b/conversational_sentence_encoder-0.0.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8f7574373ac18beb7dac112f3dd75c093f2f7f00fe6edd6cf9aa7ba76ae4fbad",
          "md5": "066b83918bdc950f3ee3df8a3ccb4d0c",
          "sha256": "f9bee36cc6ea4107b1450700a5423bf7f33a469fde592c4f57107bc718d21e83"
        },
        "downloads": -1,
        "filename": "conversational-sentence-encoder-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "066b83918bdc950f3ee3df8a3ccb4d0c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": "==3.6.*",
        "size": 5105,
        "upload_time": "2021-02-06T14:46:14",
        "upload_time_iso_8601": "2021-02-06T14:46:14.990783Z",
        "url": "https://files.pythonhosted.org/packages/8f/75/74373ac18beb7dac112f3dd75c093f2f7f00fe6edd6cf9aa7ba76ae4fbad/conversational-sentence-encoder-0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d6c0055657263d4ce4a2f1c3a286fa3730359c7e7042da3aceb8ee65ff294361",
          "md5": "e98f0b8ba8d1f8379301386fbeff2e67",
          "sha256": "9896723d71faaf55c9fcd9ab209cc7c2e1d9efc5bd17e0e54e367701f3ee135d"
        },
        "downloads": -1,
        "filename": "conversational_sentence_encoder-0.0.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "e98f0b8ba8d1f8379301386fbeff2e67",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6.0, <3.8.0",
        "size": 9944,
        "upload_time": "2021-02-20T07:48:19",
        "upload_time_iso_8601": "2021-02-20T07:48:19.738386Z",
        "url": "https://files.pythonhosted.org/packages/d6/c0/055657263d4ce4a2f1c3a286fa3730359c7e7042da3aceb8ee65ff294361/conversational_sentence_encoder-0.0.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "270feb26e99f1249fe726aa00ad4daf5bff322cde2fb0cc977074066513a65b8",
          "md5": "d178f92d0d92edf91b2b0408c11f4d87",
          "sha256": "cb2fd53a28ed4db1126cfa06982c90cda60038d96a3492f85fbadbad70a449f9"
        },
        "downloads": -1,
        "filename": "conversational-sentence-encoder-0.0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "d178f92d0d92edf91b2b0408c11f4d87",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6.0, <3.8.0",
        "size": 5572,
        "upload_time": "2021-02-20T07:48:20",
        "upload_time_iso_8601": "2021-02-20T07:48:20.921274Z",
        "url": "https://files.pythonhosted.org/packages/27/0f/eb26e99f1249fe726aa00ad4daf5bff322cde2fb0cc977074066513a65b8/conversational-sentence-encoder-0.0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e5cdc54041385b46b81a2884c4fd74b1a7b7f8b36b33320b81322ac157f65e73",
          "md5": "7f73836b101d471ff947237389e2d87b",
          "sha256": "1392b63308038d36c0ff398eab05fab62a1eb8c9222fa21fc9da512780141956"
        },
        "downloads": -1,
        "filename": "conversational_sentence_encoder-0.0.6-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "7f73836b101d471ff947237389e2d87b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7.0",
        "size": 9969,
        "upload_time": "2022-08-07T07:53:02",
        "upload_time_iso_8601": "2022-08-07T07:53:02.060290Z",
        "url": "https://files.pythonhosted.org/packages/e5/cd/c54041385b46b81a2884c4fd74b1a7b7f8b36b33320b81322ac157f65e73/conversational_sentence_encoder-0.0.6-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "dfae4e3d3a9f9c0c89505aaaeb3d7602cf40c42ef1624985afcab9371ecc8bef",
          "md5": "f4e28d8f170833215b5f3b2e50c0450d",
          "sha256": "0709262b664983346f57e75bcfed0901724246ba27c6083ce22d9684e5e53a3c"
        },
        "downloads": -1,
        "filename": "conversational-sentence-encoder-0.0.6.tar.gz",
        "has_sig": false,
        "md5_digest": "f4e28d8f170833215b5f3b2e50c0450d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7.0",
        "size": 9092,
        "upload_time": "2022-08-07T07:53:04",
        "upload_time_iso_8601": "2022-08-07T07:53:04.565861Z",
        "url": "https://files.pythonhosted.org/packages/df/ae/4e3d3a9f9c0c89505aaaeb3d7602cf40c42ef1624985afcab9371ecc8bef/conversational-sentence-encoder-0.0.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "e5cdc54041385b46b81a2884c4fd74b1a7b7f8b36b33320b81322ac157f65e73",
        "md5": "7f73836b101d471ff947237389e2d87b",
        "sha256": "1392b63308038d36c0ff398eab05fab62a1eb8c9222fa21fc9da512780141956"
      },
      "downloads": -1,
      "filename": "conversational_sentence_encoder-0.0.6-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "7f73836b101d471ff947237389e2d87b",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7.0",
      "size": 9969,
      "upload_time": "2022-08-07T07:53:02",
      "upload_time_iso_8601": "2022-08-07T07:53:02.060290Z",
      "url": "https://files.pythonhosted.org/packages/e5/cd/c54041385b46b81a2884c4fd74b1a7b7f8b36b33320b81322ac157f65e73/conversational_sentence_encoder-0.0.6-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "dfae4e3d3a9f9c0c89505aaaeb3d7602cf40c42ef1624985afcab9371ecc8bef",
        "md5": "f4e28d8f170833215b5f3b2e50c0450d",
        "sha256": "0709262b664983346f57e75bcfed0901724246ba27c6083ce22d9684e5e53a3c"
      },
      "downloads": -1,
      "filename": "conversational-sentence-encoder-0.0.6.tar.gz",
      "has_sig": false,
      "md5_digest": "f4e28d8f170833215b5f3b2e50c0450d",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7.0",
      "size": 9092,
      "upload_time": "2022-08-07T07:53:04",
      "upload_time_iso_8601": "2022-08-07T07:53:04.565861Z",
      "url": "https://files.pythonhosted.org/packages/df/ae/4e3d3a9f9c0c89505aaaeb3d7602cf40c42ef1624985afcab9371ecc8bef/conversational-sentence-encoder-0.0.6.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}