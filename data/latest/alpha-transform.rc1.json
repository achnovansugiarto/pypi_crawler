{
  "info": {
    "author": "Felix Voigtlaender",
    "author_email": "felix@voigtlaender.xyz",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# Adaptive transform for manifold-valued data\n\nThis package contains all software developed as part of Workpackage 2.1 (Adaptive transform for manifold-valued data)\nof the DEDALE project. For an in-depth description of this workpackage, we refer to the associated technical report.\n\nThe software consists of three main parts:\n\n1. An implementation of the (bandlimited) **α-shearlet transform** (in [AlphaTransform.py](../AlphaTransform.py),\n   in three versions:\n   * A *fully sampled* (non-decimated), translation invariant, fast, but memory-*consuming* implementation\n   * A fully sampled, translation invariant, slightly slower, but memory-*efficient* implementation\n   * A *subsampled* (decimated), *not* translation invariant, but fast and memory-efficient implementation.\n2. Implementations (in [AdaptiveAlpha.py](../AdaptiveAlpha.py)) of three criteria that can be used to adaptively choose\n   the value of α, namely:\n   * The [*asymptotic approximation rate*](#aar) (**AAR**),\n   * the [*mean approximation error*](#mae) (**MAE**),\n   * the [*thresholding denoising performance*](#tdp) (**TDP**).\n3. A [chart-based implementation](#sphere-valued) (in [SphereTransform.py](../SphereTransform.py)) of the α-shearlet transform for\n   functions defined on the sphere.\n\n\nIn the following, we provide brief explanations and hands-on experiments for all of these aspects. The following\ntable of content can be used for easy navigation:\n\n## Table of Contents\n1. [The α-shearlet transform: A crash course](#shearlet-trafo-crash-course)\n\n2. [Adaptively choosing α](#adaptivity)\n\n     a) [Asymptotic approximation rate (AAR)](#aar)\n\n     b) [Mean approximation error (MAE)](#mae)\n\n     c) [Thresholding denoising performance (TDP)](#tdp)\n\n3. [The α-shearlet transform for functions defined on the sphere](#sphere-valued)\n\n\n## <a name=\"shearlet-trafo-crash-course\"></a>The α-shearlet transform: A crash course\n\nThe following demonstrates a very simple use case of the α-shearlet transform: We compute the transform of an example image,\nthreshold the coefficients, reconstruct and compute the error. The code is longer than strictly necessary, since\nalong the way give a demonstration of the general usage of the transform.\n\n```python\n>>> # Importing necessary packages\n>>> from AlphaTransform import AlphaShearletTransform as AST\n>>> import numpy as np\n>>> import matplotlib.pyplot as plt\n>>> from scipy import misc\n\n>>> im = misc.face(gray=True)\n>>> im.shape\n(768, 1024)\n\n>>> # Setting up the transform\n>>> trafo = AST(im.shape[1], im.shape[0], [0.5]*3) # 1\nPrecomputing shearlet system: 100%|███████████████████████████████████████| 52/52 [00:05<00:00,  8.83it/s]\n\n>>> # Computing and understanding the α-shearlet coefficients\n>>> coeff = trafo.transform(im) # 2\n>>> coeff.shape # 3\n(53, 768, 1024)\n>>> trafo.indices # 4\n[-1,\n (0, -1, 'r'), (0, 0, 'r'), (0, 1, 'r'),\n (0, 1, 't'), (0, 0, 't'), (0, -1, 't'),\n (0, -1, 'l'), (0, 0, 'l'), (0, 1, 'l'),\n (0, 1, 'b'), (0, 0, 'b'), (0, -1, 'b'),\n (1, -2, 'r'), (1, -1, 'r'), (1, 0, 'r'), (1, 1, 'r'), (1, 2, 'r'),\n (1, 2, 't'), (1, 1, 't'), (1, 0, 't'), (1, -1, 't'), (1, -2, 't'),\n (1, -2, 'l'), (1, -1, 'l'), (1, 0, 'l'), (1, 1, 'l'), (1, 2, 'l'),\n (1, 2, 'b'), (1, 1, 'b'), (1, 0, 'b'), (1, -1, 'b'), (1, -2, 'b'),\n (2, -2, 'r'), (2, -1, 'r'), (2, 0, 'r'), (2, 1, 'r'), (2, 2, 'r'),\n (2, 2, 't'), (2, 1, 't'), (2, 0, 't'), (2, -1, 't'), (2, -2, 't'),\n (2, -2, 'l'), (2, -1, 'l'), (2, 0, 'l'), (2, 1, 'l'), (2, 2, 'l'),\n (2, 2, 'b'), (2, 1, 'b'), (2, 0, 'b'), (2, -1, 'b'), (2, -2, 'b')]\n\n>>> # Thresholding the coefficients and reconstructing\n>>> np.max(np.abs(coeff)) # 5\n2041.1017181588547\n>>> np.sum(np.abs(coeff) > 200) / coeff.size # 6\n0.020679905729473761\n>>> thresh_coeff = coeff * (np.abs(coeff) > 200) # 7\n>>> recon = trafo.inverse_transform(thresh_coeff, real=True) # 8\n>>> np.linalg.norm(im - recon) / np.linalg.norm(im) # 9\n0.13912540983541383\n\n>>> plt.imshow(recon, cmap='gray')\n<matplotlib.image.AxesImage object at 0x2b0f568c25c0>\n>>> plt.show()\n```\n\n### Importing necessary packages\n\nThe first few (unnumbered) lines import relevant packages and load (a gray scale version of) the following\ntest image, which has a resolution of 1024 x 768 pixels:\n<p align=\"center\">\n<img src=\"http://www.scipy-lectures.org/_images/face.png\" width=\"512\"/>\n</p>\n\n\n### Setting up the transform\n\nThen, in line 1, we create an instance `trafo` of the class `AlphaShearletTransform` (which is\ncalled `AST` above for brevity).\nDuring construction of this object, the necessary shearlet filters are precomputed. This may take some time\n(5 seconds in the example above), but speeds up later computations.\n\nThe three parameters passed to the constructor of `trafo` require some explanation:\n* The first parameter is the *width* of the images which can be analyzed using the `trafo` object.\n* Similarly, the second parameter determines the *height*.\n* The third parameter is of the form `[alpha] * N`, where `N` determines the number of scales of the transform and `alpha`\n  determines the value of α.\n\n  The reason for this notation is that in principle, one can choose a\n  different value of α on each scale. Since `[0.5] * 3 = [0.5, 0.5, 0.5]`, one can use this notation to obtain a\n  system using a single value of α across all scales.\n\nAll in all, we see that line 1 creates a shearlet system (i.e., α = 0.5) with 3 scale (plus a low-pass)\nfor images of dimension 1024 x 768.\n\n### Computing and understanding the α-shearlet coefficients\n\nLine 2 shows that the α-shearlet coefficients of the image `im` can be readily computed using the `transform` method of `trafo`.\nAs seen in line 3, this results in an array of size `53`, where each of the elements of the array is an array (an image) of\nsize 1024 x 768, i.e., of the same size as the input image.\n\nTo help understand the meaning of each of these **coefficient images** `coeff[i]`, for `i = 0, ..., 52`, the output of line 4\nis helpful: Associated to each coefficient image `coeff[i]`, there is an **index** `trafo.indices[i]` which encodes the *meaning*\nof the coefficient image, i.e., the shearlet used to compute it.\n\nThe special index `-1` stands for the **low-pass part**. All other indices are of the form `(j, k, c)`, where\n* `j` encodes the **scale**. In the present case, `j` ranges from `0` to `2`, since we have 3 scales.\n* `k` encodes the **amount of shearing**, ranging from -⌈2<sup>j(1 - α)</sup>⌉ to ⌈2<sup>j(1 - α)</sup>⌉ on scale ``j``.\n* `c` encodes the **cone** to which the shearlet belongs (in the Fourier domain). Precisely, we have the following correspondence\n  between the value of `c` and the corresponding frequency cones:\n\n  | value of `c`   | `'r'` | `'t'` | `'l'` | `'b'`  |\n  | -------------- |:-----:|:-----:|:-----:|:------:|\n  | Frequency cone | right |  top  | left  | bottom |\n\n\nNote that if we divide the frequency plane into four cones, such that each shearlet has a real-valued Fourier transform\nwhich is supported in one of these cones, then the shearlets themselves (i.e., in space) *can not* be real-valued.\nHence, if real-valued shearlets are desired, one can pass the constructor of the class `AlphaShearletTransform` the\nadditional argument `real=True`. In this case, the frequency plane is split into a horizontal (encoded by `'h'`) and\na vertical (encoded by `'v'`) cone, as is indicated by the following example:\n```python\n>>> trafo_real = AST(im.shape[1], im.shape[0], [0.5]*3, real=True)\nPrecomputing shearlet system: 100%|██████████████████████████████████████| 26/26 [00:03<00:00,  5.62it/s]\n>>> trafo_real.indices\n[-1,\n (0, -1, 'h'), (0, 0, 'h'), (0, 1, 'h'),\n (0, 1, 'v'), (0, 0, 'v'), (0, -1, 'v'),\n (1, -2, 'h'), (1, -1, 'h'), (1, 0, 'h'), (1, 1, 'h'), (1, 2, 'h'),\n (1, 2, 'v'), (1, 1, 'v'), (1, 0, 'v'), (1, -1, 'v'), (1, -2, 'v'),\n (2, -2, 'h'), (2, -1, 'h'), (2, 0, 'h'), (2, 1, 'h'), (2, 2, 'h'),\n (2, 2, 'v'), (2, 1, 'v'), (2, 0, 'v'), (2, -1, 'v'), (2, -2, 'v')]\n```\n\n### Thresholding the coefficients & reconstructing\n\nWhen called without further parameters, the method `trafo.transform` computes a *normalized* transform,\nso that effectively all shearlets are normalized to have L² norm 1. With this normalization, line 5 shows\nthat the largest coefficient has size about 2041. We now (arbitrarily) pick a threshold of 200 and see (in line 6)\nthat only about 2% of the coefficients are larger than this threshold. Next, we set all coefficients which are smaller\n(in absolute value) than 200 to zero and save the resulting thresholded coefficients as `thresh_coeff`, in line 7.\n\nIn line 8, we then use the method `inverse_transform` of the `trafo` object to compute the inverse transform.\nSince we know that the original image was real-valued, we pass the additional argument `real=True`.\nThis has the same effect as reconstructing without this additional argument and then taking the real part.\nLine 9 shows that the relative error is about 13.9%.\n\nFinally, the last two lines display the reconstructed image.\n\n### Changes for the subsampled transform\n\nAbove, we showed how our implementation of the *fully sampled* α-shearlet transform can be used to compute the α-shearlet\ntransform of an image and reconstruct (with thresholded coefficients). For the *subsampled* transform, this can be\ndone very similarly; the main difference one has to keep in mind is that for the fully sampled transform,\none obtains an array of \"coefficient images\" which are all of the same size. In contrast, due to the subsampling,\nthe \"coefficient images\" for the subsampled transform are all of different sizes:\n\n```python\n>>> from AlphaTransform import AlphaShearletTransform as AST\n>>> import matplotlib.pyplot as plt\n>>> import numpy as np\n>>> from scipy import misc\n\n>>> im = misc.face(gray=True)\n>>> trafo = AST(im.shape[1], im.shape[0], [0.5]*3, subsampled=True) # 1\nPrecomputing shearlets: 100%|████████████████████████████████████████████| 52/52 [00:00<00:00, 69.87it/s]\n>>> coeff = trafo.transform(im) # 2\n\n>>> type(coeff).__name__ # 3\n'list'\n>>> [c.shape for c in coeff] # 4\n[(129, 129),\n (364, 161), (364, 161), (364, 161),\n (97, 257), (97, 257), (97, 257),\n (364, 161), (364, 161), (364, 161),\n (97, 257), (97, 257), (97, 257),\n (514, 321), (514, 321), (514, 321), (514, 321), (514, 321),\n (193, 364), (193, 364), (193, 364), (193, 364), (193, 364),\n (514, 321), (514, 321), (514, 321), (514, 321), (514, 321),\n (193, 364), (193, 364), (193, 364), (193, 364), (193, 364),\n (727, 641), (727, 641), (727, 641), (727, 641), (727, 641),\n (385, 513), (385, 513), (385, 513), (385, 513), (385, 513),\n (727, 641), (727, 641), (727, 641), (727, 641), (727, 641),\n (385, 513), (385, 513), (385, 513), (385, 513), (385, 513)]\n\n>>> np.max([np.max(np.abs(c)) for c in coeff]) # 5\n2031.0471969998314\n>>> np.sum([np.sum(np.abs(c) > 200) for c in coeff]) # 6\n22357\n>>> np.sum([np.sum(np.abs(c) > 200) for c in coeff]) / np.sum([c.size for c in coeff]) # 7\n0.0023520267754635542\n>>> thresh_coeff = [c * (np.abs(c) > 200) for c in coeff] # 8\n>>> recon = trafo.inverse_transform(thresh_coeff, real=True) # 9\n>>> np.linalg.norm(im - recon) / np.linalg.norm(im)\n0.13945789596375507\n```\n\nUp to the first marked line, everything is identical to the code for the fully sampled transform.\nThe only difference in line 1 is the additional argument `subsampled=True` to obtain a subsampled transform.\nThen, in line 2, the transform of the image `im` is computed just as for the fully sampled case.\n\nThe main difference to the fully sampled transform becomes visible in lines 3 and 4:\nIn contrast to the fully sampled transform, where the coefficients are a 3-dimensional numpy *array*,\nthe subsampled transform yields a *list* of 2-dimensional numpy arrays, with **varying shapes**.\nThis shape is constant with respect to the shear `k` as long as the scale `j` and the cone `c` are kept fixed,\nbut varies strongly with `j` and `c`. In face, for a *quadratic* image, the shape would only depend on the scale `j`.\n\nSince we have a list of numpy arrays instead of a single numpy array, all operations on the coefficients are more\ncumbersome to write down (using list comprehensions), but are identical in spirit to the case of the fully sampled\ntransform, cf. lines 5-8.\n\nThe actual reconstruction (in line 9) is exactly identical to the fully sampled case. It is interesting to note that\nonly about 0.24% of the coefficients - and thus much less than the 2% for the fully sampled transform - are larger than\nthe threshold. Nevertheless, the relative error is essentially the same.\n\n## <a name=\"adaptivity\"></a>Adaptively choosing α\n\nIn the following, we show for each of the three optimality criteria ([AAR](#aar), [MAE](#mae) and [TDP](#tdp)) how our\nimplementation can be used to determine the optimal value of α for a given set of images.\n\n### <a name=\"aar\"></a>Asymptotic approximation rate (AAR)\n\nThe following code uses a grid search to determine the value of α which yields the best *asymptotic approximation rate*\n(as described in the technical report) for the given set of images:\n\n<a name=\"aar-session\"></a>\n```python\n>>> from AdaptiveAlpha import optimize_AAR\n\n>>> shearlet_args = {'real' : True, 'verbose' : False} # 1\n>>> images = ['./Review/log_dust_test.npy'] # 2\n>>> num_scales = 4 # 3\n>>> num_alphas = 3 # 4\n\n>>> optimize_AAR(images, num_scales, 1 / (num_alphas - 1), shearlet_args=shearlet_args)\nFirst step: Determine the maximum relevant value...\nalpha loop: 100%|████████████████████████████████████████████████████████| 3/3 [00:10<00:00,  3.48s/it]\nimage loop: 100%|████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.60s/it]\nMaximum relevant value: 0.04408709120918954\n\nSecond step: Computing the approximation errors...\nalpha loop: 100%|████████████████████████████████████████████████████████| 3/3 [01:40<00:00, 30.99s/it]\nImage loop: 100%|████████████████████████████████████████████████████████| 1/1 [00:46<00:00, 46.89s/it]\nThresh. loop: 100%|██████████████████████████████████████████████████████| 50/50 [00:45<00:00,  1.10it/s]\n\nThird step: Computing the approximation rates...\nCommon breakpoints: [0, 4, 34, 50]\nLast common linear part: [34, 50)\n\nlast slopes:\n   alpha = 1.00 : -0.161932 + 0.012791\n   alpha = 0.50 : -0.161932 + 0.000108\n * alpha = 0.00 : -0.161932 - 0.012900\n\nOptimal value: alpha = 0.00\n```\nIn addition to the output shown above, executing this code will display the following plot:\n<p align=\"center\">\n<a name=\"aar-plot\"></a>\n<img src=\"./Review/AAR_dust_example_plot.png\" width=\"900\"/>\n</p>\n\n\nWe now briefly explain the above [code](#aar-session) and output:\nIn the short program above, we first import the function `optimize_AAR` which will do the actual work.\nThen, we define the parameters to be passed to this function:\n\n1. In line 1, we determine the properties of the α-shearlet systems that will be used:\n    * `'real': True` ensures that real-valued shearlets are used.\n    * `'verbose': False` suppresses some output, e.g. the progress bar for precomputing the shearlet system.\n\n   Another possible option would be `'subsampled': True` if one wants to use the subsampled transform. Note though\n   that this is incompatible with the `'real': True` option.\n\n2. In line 2, we determine the set of images that is to be used. To ensure fast computations, we only take\n   a single image for this example. Specifically, the used image is the logarithm of one of the 12 faces of cosmic\n   dust data provided by CEA, as depicted in the following figure:\n\n   <p align=\"center\">\n   <a name=\"log-dust-image\"></a>\n   <img src=\"./Review/log_dust_graphic.png\" width=\"400\"/>\n   </p>\n\n3. The variable `num_scales` determines how many scales the α-shearlet systems should use.\n\n4. Since we are using a grid search (i.e., we are only considering finitely many values of α), the\n   variable `num_alphas` is used to determine how many different values of α should be distinguished.\n   These are then uniformly spread in the interval [0,1]. Again, to ensure fast computations, we only consider\n   three different values, namely α=0, α=0.5 and α=1.\n\nFinally, we invoke the function `optimize_AAR` with the chosen parameters. As described in the technical report,\nthis function does the following:\n\n1. It determines a range [0, c<sub>0</sub>] such that for c≥c<sub>0</sub>, all α-shearlet transforms yield the\n   *same error* when all coefficients of absolute value ≤c are set to zero (\"thresholded\").\n\n2. It computes the reconstruction errors for the different values of α after thresholding the coefficients with\n   a threshold of c<sub>0</sub>·b<sup>k</sup> for k=0,...,K-1.\n\n   The default value is K=50. This can be adjusted by passing e.g. the argument `num_x_values=40` as an\n   additional argument to `optimize_AAR`. Likewise, the base `b` (with default value `b=1.25`) can be adjusted\n   by passing e.g. `base=1.3` as a further argument.\n\n3. It determines a partition of {0, ..., K-1} into at most 4 intervals such that on each of these intervals,\n   each of the (logarithmic) error curves is almost linear.\n\n   In the example run above, the end points of the\n   resulting partition are given by `Common breakpoints: [0, 4, 34, 50]`. In this case, the resulting\n   partition has only three intervals instead of 4, since on each of these intervals, the best linear approximation\n   is already sufficiently good.\n\n4. For each value of α, the function then determines the *slopes* of the (logarithmic) error curve on the\n   last of these intervals and compares these slopes.\n\n   The optimal value of α (in this case α=0) is the one with the smallest slope, i.e., with the highest\n   decay of the error. To allow for a visual comparison, `optimize_AAR` also displays a [plot](#aar-plot) of the\n   (logarithmic) error curves, including the partition into the almost linear parts.\n\n### <a name=\"mae\"></a>Mean approximation error (MAE)\n\nThe following code uses a grid search to determine the value of α which yields the best *mean approximation error*\n(as described in the technical report) for the given set of images:\n\n<a name=\"mae-session\"></a>\n```python\n>>> from AdaptiveAlpha import optimize_MAE\n>>> shearlet_args = {'real' : True, 'verbose' : False} # 1\n>>> images = ['./Review/log_dust_test.npy'] # 2\n>>> num_scales = 4\n>>> num_alphas = 3\n>>> optimize_MAE(images, num_scales, 1 / (num_alphas - 1), shearlet_args=shearlet_args)\nFirst step: Determine the maximum relevant value...\nalpha loop: 100%|████████████████████████████████████████████████████████| 3/3 [00:11<00:00,  3.61s/it]\nimage loop: 100%|████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.61s/it]\nMaximum relevant value: 0.006053772894213893\n\nSecond step: Computing the approximation errors...\nalpha loop: 100%|████████████████████████████████████████████████████████| 3/3 [01:40<00:00, 31.13s/it]\nimage loop: 100%|████████████████████████████████████████████████████████| 1/1 [00:48<00:00, 48.25s/it]\nthresholding loop: 100%|█████████████████████████████████████████████████| 50/50 [00:46<00:00,  1.08it/s]\n\nFinal step: Computing optimal value of alpha...\nmean errors:\n   alpha = 1.00 : +0.024105 + 0.000258\n   alpha = 0.50 : +0.024105 + 0.000015\n * alpha = 0.00 : +0.024105 - 0.000273\n\nOptimal value: alpha = 0.00\n```\n\nIn addition to the output shown above, executing this code will display the following plot:\n<p align=\"center\">\n<a name=\"mae-plot\"></a>\n<img src=\"./Review/MAE_example_plot.png\" width=\"800\"/>\n</p>\n\nWe now briefly explain the above [code](#mae-session) and output:\nIn the short program above, we first import the function `optimize_MAE` which will do the actual work.\nThen, we define the parameters to be passed to this function:\n\n1. In line 1, we determine the properties of the α-shearlet systems that will be used:\n    * `'real': True` ensures that real-valued shearlets are used.\n    * `'verbose': False` suppresses some output, e.g. the progress bar for precomputing the shearlet system.\n\n   Another possible option would be `'subsampled': True` if one wants to use the subsampled transform. Note though\n   that this is incompatible with the `'real': True` option.\n\n2. In line 2, we determine the set of images that is to be used. To ensure fast computations, we only take\n   a single image for this example. Specifically, the used image is the logarithm of one of the 12 faces of cosmic\n   dust data provided by CEA, as depicted in the [figure](#log-dust-image) above.\n\n3. The variable `num_scales` determines how many scales the α-shearlet systems should use.\n\n4. Since we are using a grid search (i.e., we are only considering finitely many values of α), the\n   variable `num_alphas` is used to determine how many different values of α should be distinguished.\n   These are then uniformly spread in the interval [0,1]. Again, to ensure fast computations, we only consider\n   three different values, namely α=0, α=0.5 and α=1.\n\nFinally, we invoke the function `optimize_MAE` with the chosen parameters. As described in the technical report,\nthis function does the following:\n\n1. It determines a range [0, c<sub>0</sub>] such that for c≥c<sub>0</sub>, all α-shearlet transforms yield the\n   *same error* when all coefficients of absolute value ≤c are set to zero (\"thresholded\").\n\n2. It computes the reconstruction errors for the different values of α after thresholding the coefficients with\n   a threshold of c = c<sub>0</sub>·i / K for i = 0, ..., K-1.\n\n   The default value is K=50. This can be adjusted by passing e.g. the argument `num_x_values=40` as an additional\n   argument to `optimize_MAE`.\n\n3. For each value of α, the function then determines the *mean* of all these approximation errors. The optimal\n   value of α (in this case α=0) is the one with the smallest mean approximation error.\n\n   To allow for a visual comparison, `optimize_MAE` also displays a [plot](#mae-plot) of the error curves.\n\n\n\n### <a name=\"tdp\"></a>Thresholding Denoising Performance (TDP)\n\nIn the following, we show how the denoising performance of an α-shearlet system can be used as an optimality\ncriterion for adaptively choosing the correct value of α.\n\nSince the [(logarithmic) dust data](#log-dust-image) used for the previous experiments does not allow for an\neasy visual comparison between the original image and the different denoised versions, we decided to instead\nuse the following 684 x 684 cartoon image (taken from [SMBC](http://smbc-comics.com)) as a toy example:\n<p align=\"center\">\n<a name=cartoon-example></a>\n<img src=\"./Review/cartoon_example.png\" width=\"400\" height=\"400\" />\n</p>\n\n\nThe following code uses a grid search over different values of α to determine the value with the\noptimal denoising performance:\n<a name=\"tdp-session\"></a>\n```python\n>>> from AdaptiveAlpha import optimize_denoising\n\n>>> image_paths=['./Review/cartoon_example.png']       # 1\n>>> num_alphas = 3                                     # 2\n>>> num_scales = 5                                     # 3\n>>> num_noise_levels = 5                               # 4\n>>> shearlet_args = {'real' : True, 'verbose' : False} # 5\n\n>>> optimize_denoising(image_paths,\n                       num_scales,\n                       1 / (num_alphas - 1),\n                       num_noise_levels,\n                       shearlet_args=shearlet_args)\nimage loop: 100%|██████████████████████████████████████████████████████████| 1/1 [01:33<00:00, 93.16s/it]\nalpha loop: 100%|██████████████████████████████████████████████████████████| 3/3 [01:33<00:00, 28.44s/it]\nnoise loop: 100%|██████████████████████████████████████████████████████████| 5/5 [00:46<00:00,  9.38s/it]\n\nAveraged error over all images and all noise levels:\nalpha = 1.00: 0.0961\nalpha = 0.50: 0.0900\nalpha = 0.00: 0.0948\n\nOptimal value on whole set: alpha = 0.50\n```\n\nIn addition to the output shown above, executing the sample code also displays the following plot:\n<p align=\"center\">\n<a name=\"tdp-plot\"></a>\n<img src=\"./Review/TDP_example_plot.png\" width=\"900\"/>\n</p>\n\nWe now briefly explain the above [code](#tdp-session) and output:\nFirst, we import from `AdaptiveAlpha.py` the function `optimize_denoising` which will do the actual work.\nWe then set the parameters to this function. In the present case, we want to\n* analyze the [cartoon image](#cartoon-example) shown above,\n* use α-shearlet transforms with *real-valued* shearlets (cf. line 5, the second part of that line suppresses some output),\n* use α-shearlet transforms with 5 scales (line 4),\n* use 5 different noise levels λ (line 4) which are uniformly spaced in [0.02, 0.4],\n* compare three different values of α, which are uniformly spaced in [0,1], i.e, α=1, α=0.5 and α=0.\n\nIn more realistic experiment, one would of course use a larger set of test images and consider more different values of\nα, possibly also with a larger number of different noise levels. But here, we are mainly interested in a quick\nexecution time, so we keep everything small.\n\nFinally, we invoke the function `optimize_denoising` which - briefly summarized - does the following:\n1. It normalizes each of the K x K input images to have L² norm equal to 1.\n   Then, for each image, each value of α  and each noise level λ in [0.02,0.4], a distorted image is calculated\n   by adding artificial Gaussian noise with standard deviation σ=λ/K to the image.\n\n   This standard deviation is chosen in such a way that the expected squared L² norm of the noise is λ².\n\n   One can specify other ranges for the noise level than the default range [0.02, 0.4] by using the paramters\n   `noise_min` and `noise_max`.\n\n2. The α-shearlet transform of the distorted image is determined. \n\n3. Hard thresholding is performed on the set of α-shearlet coefficients. The thresholding parameter (i.e., the cutoff value)\n   c is chosen scale- and noise dependent via c = mσ, with m being a scale-dependent *multiplier*.\n\n   Numerical experiments showed that good results are obtained by taking m=3 for all scales except the highest and m=4\n   for the highest scale. This is the default choice made in `optimize_denoising`. If desired, this default choice can be\n   modified using the parameter `thresh_multiplier`.\n\n4. The inverse α-shearlet transform of the thresholded coefficients is determined and the L²-error between this\n   reconstruction and the original image is calculated. \n\n5. The optimal value of α is the one for which the L²-error averaged over all images and all noise levels is the smallest. \n\nThe [plot](#tdp-plot) which is displayed by `optimize_denoising` depicts the mean error over all images as a function of\nthe employed noise level λ for different values of α. In the present case, we are only considering one image (N=1).\nClearly, shearlets (i.e., α=0.5) turn out to be optimal for our toy example.\n\nFor an eye inspection, `optimize_denoising` also saves the noisy image and the reconstructions for the largest noise level\n(λ=0.4) and the different α values to the current working directory.\nA small zoomed part of these reconstructions - together with the same part of the original image and the noisy image - can\nbe seen below: \n\n<p align=\"center\">\n<table>\n    <tr>\n        <td>\n            <p align=\"center\">\n                <img src=\"./Review/OriginalImage.png\" width=\"250\" height=\"250\" />\n            </p>\n            <p align=\"center\">original image</p>\n        </td>\n        <td>\n            <p align=\"center\">\n                <img src=\"./Review/NoisyImage.png\" width=\"250\" height=\"250\" />\n            </p>\n            <p align=\"center\">\n                noisy image\n            </p>\n        </td>\n    </tr>\n</table>\n</p>\n\n<p align=\"center\">\n<table> \n<tr>\n    <td>\n        <p align=\"center\">\n            <img src=\"./Review/ReconstructionRidgelet.png\" width=\"250\" height=\"250\" />\n        </p>\n        <p align=\"center\">\n            α=0\n        </p>\n    </td>\n    <td>\n        <p align=\"center\">\n            <img src=\"./Review/ReconstructionShearlet.png\" width=\"250\" height=\"250\" />\n        </p>\n        <p align=\"center\">\n            α=0.5\n        </p>\n    </td>\n    <td>\n        <p align=\"center\">\n            <img src=\"./Review/ReconstructionWavelet.png\" width=\"250\" height=\"250\" />\n        </p>\n        <p align=\"center\">\n            α=1\n        </p>\n    </td>\n</tr> \n</table>\n</p>\n\n\n## <a name=\"sphere-valued\"></a>The α-shearlet transform for functions defined on the sphere\n\nAs described in the technical report, we use a *chart-based* approach for computing the\nα-shearlet transform of functions defined on the sphere. Precisely, we use the charts provided\nby the [HEALPix](http://healpix.jpl.nasa.gov/) [pixelization](https://en.wikipedia.org/wiki/HEALPix) of the sphere,\nwhich divides the sphere into 12 faces and provides cartesian charts for each of these faces. The crucial property\nof this pixelization is that each pixel has exactly the same spherical area.\n\nNow, given a function `f` defined on the sphere (in a discretized version, as a so-called **HEALPix map**), one can use\nthe function `get_all_faces()` from `SphereTransform.py` to obtain a family of 12 cartesian images, each of which\nrepresents the function `f` restricted to one of the 12 faces of the sphere. As detailed in the technical report, analyzing\neach of these 12 cartesian images and concatenating the coefficients is equivalent to analyzing `f` using the sphere-based\nα-shearlets.\n\nConversely, one needs a way to reconstruct (a slightly modified version of) `f`, given the (possibly thresholded or\notherwise modified) α-shearlet coefficients. To this end, one first reconstructs each of the 12 cartesian images using\nthe usual α-shearlet transform and then concatenates these to obtain a function `g` defined on the sphere, via the\nfunction `put_all_faces` defined in `SphereTransform.py`.\n\nHere, we just briefly indicate how `put_all_faces` can be used to obtain a plot of certain (randomly selected)\nα-shearlets on the sphere. Below, we use an alpha-shearlet system with 6 scales, but only use alpha-shearlets\nfrom the first three scales for plotting, since the alpha-shearlets on higher scales are very small/short\nand thus unsuitable for producing a nice plot.\n```python\n>>> import healpy as hp\n>>> import numpy as np\n>>> import matplotlib.pyplot as plt\n>>> from SphereTransform import put_all_faces as Cartesian2Sphere\n>>> from AlphaTransform import AlphaShearletTransform as AST\n\n>>> width = height = 512\n>>> alpha = 0.5\n>>> num_scales = 6 # we use six scales, so that the shearlets on lower scales are big (good for plotting)\n\n>>> trafo = AST(width, height, [alpha] * num_scales, real=True)\n>>> all_shearlets = trafo.shearlets # get a list of all shearlets\n\n>>> cartesian_faces = np.empty((12, height, width))\n>>> # for each of the 12 faces, select a random shearlet from one of the first three scales\n>>> upper_bound = trafo.scale_slice(3).start\n>>> shearlet_indices = np.random.choice(np.arange(upper_bound), size=12, replace=False)\n>>> for i, index in enumerate(shearlet_indices):\n        cartesian_faces[i] = all_shearlets[index]\n        # normalize, so that the different shearlets are comparable in size\n        max_val = np.max(np.abs(cartesian_faces[i]))\n        cartesian_faces[i] /= max_val\n\n>>> # use HEALPix charts to push the 12 cartesian faces onto the sphere\n>>> sphere_shearlets = Cartesian2Sphere(cartesian_faces)\n>>> hp.mollview(sphere_shearlets, cbar=False, hold=True)\n>>> plt.title(r\"Random $\\alpha$-shearlets on the sphere\", fontsize=20)\n>>> plt.show()\n```\n\nThe above code produces a plot similar to the following:\n<p align=\"center\">\n<a name=\"sphere-plot\"></a>\n<img src=\"./Review/sphere_alpha_shearlets.png\" width=\"900\"/>\n</p>\n\n\n\n## Required packages\n\nIn addition to Python 3, the software requires the following Python packages:\n\n* [numpy](http://www.numpy.org/)\n* [matplotlib](http://matplotlib.org/)\n* [numexpr](https://github.com/pydata/numexpr)\n* [pyfftw](https://github.com/pyFFTW/pyFFTW)\n* [tqdm](https://github.com/tqdm/tqdm)\n* [healpy](https://github.com/healpy/healpy) (only required for [SphereTransform.py](./SphereTransform.py))\n* [PIL](http://www.pythonware.com/products/pil/), the Python Imaging Library\n* [scipy.ndimage](https://www.scipy.org/)\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/dedale-fet/alpha-transform",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "alpha-transform",
    "package_url": "https://pypi.org/project/alpha-transform/",
    "platform": "",
    "project_url": "https://pypi.org/project/alpha-transform/",
    "project_urls": {
      "Homepage": "https://github.com/dedale-fet/alpha-transform"
    },
    "release_url": "https://pypi.org/project/alpha-transform/0.0.1/",
    "requires_dist": [
      "numpy",
      "matplotlib",
      "numexpr",
      "pyfftw",
      "tqdm",
      "healpy",
      "Pillow",
      "scipy"
    ],
    "requires_python": "",
    "summary": "Adaptive alpha shearlet transform for manifold-valued data",
    "version": "0.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 7882567,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7631cf309590e5a55bc8c9c0ab39870a8ceed55ddbc80fd3c23fe6717a1911e0",
          "md5": "26790f7b0b3902a81463d671d3b39ef6",
          "sha256": "40e5d87c40e4c95bd9c3561aaee78f0aeb0b5fbe872d4742e9bdaa73d4192878"
        },
        "downloads": -1,
        "filename": "alpha_transform-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "26790f7b0b3902a81463d671d3b39ef6",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 55913,
        "upload_time": "2020-08-04T15:39:19",
        "upload_time_iso_8601": "2020-08-04T15:39:19.510785Z",
        "url": "https://files.pythonhosted.org/packages/76/31/cf309590e5a55bc8c9c0ab39870a8ceed55ddbc80fd3c23fe6717a1911e0/alpha_transform-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "240c5153fda43185128d57f073c010538467c6935bbbce238551bf4d5ef98d61",
          "md5": "e902b8a1a6585d0350a4bbdb38e469bd",
          "sha256": "ab0433d98bda1273a92d30ddf6ac19e63936bf0c8db01c2362f571b448169e13"
        },
        "downloads": -1,
        "filename": "alpha_transform-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "e902b8a1a6585d0350a4bbdb38e469bd",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 69225,
        "upload_time": "2020-08-04T15:39:22",
        "upload_time_iso_8601": "2020-08-04T15:39:22.788535Z",
        "url": "https://files.pythonhosted.org/packages/24/0c/5153fda43185128d57f073c010538467c6935bbbce238551bf4d5ef98d61/alpha_transform-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "7631cf309590e5a55bc8c9c0ab39870a8ceed55ddbc80fd3c23fe6717a1911e0",
        "md5": "26790f7b0b3902a81463d671d3b39ef6",
        "sha256": "40e5d87c40e4c95bd9c3561aaee78f0aeb0b5fbe872d4742e9bdaa73d4192878"
      },
      "downloads": -1,
      "filename": "alpha_transform-0.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "26790f7b0b3902a81463d671d3b39ef6",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 55913,
      "upload_time": "2020-08-04T15:39:19",
      "upload_time_iso_8601": "2020-08-04T15:39:19.510785Z",
      "url": "https://files.pythonhosted.org/packages/76/31/cf309590e5a55bc8c9c0ab39870a8ceed55ddbc80fd3c23fe6717a1911e0/alpha_transform-0.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "240c5153fda43185128d57f073c010538467c6935bbbce238551bf4d5ef98d61",
        "md5": "e902b8a1a6585d0350a4bbdb38e469bd",
        "sha256": "ab0433d98bda1273a92d30ddf6ac19e63936bf0c8db01c2362f571b448169e13"
      },
      "downloads": -1,
      "filename": "alpha_transform-0.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "e902b8a1a6585d0350a4bbdb38e469bd",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 69225,
      "upload_time": "2020-08-04T15:39:22",
      "upload_time_iso_8601": "2020-08-04T15:39:22.788535Z",
      "url": "https://files.pythonhosted.org/packages/24/0c/5153fda43185128d57f073c010538467c6935bbbce238551bf4d5ef98d61/alpha_transform-0.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}