{
  "info": {
    "author": "Daniel Hopp",
    "author_email": "daniel.hopp1@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# nlp_pipeline\nCollection of NLP tools for processing and analyzing text data.\n\n## Introduction\nThe fundamental input of the library is a metadata file. By default this will contain the columns `[\"text_id\", \"web_filepath\", \"local_raw_filepath\", \"local_txt_filepath\", \"detected_language\"]`. The only one that needs to be provided by the user is `\"web_filepath\"`. Ergo, a list of URLs containing text documents is all that is required to use the library. If the corpus had additional columns of interest, like titles, etc., those can be passed via the `metadata_addt_column_names` argument when instantiating the initial `nlp_processor` function. More information below.\n\nFundamentally the library takes the list of documents and downloads, transforms, and organizes them according to a specific filestructure. These files can then be used to generate insights, such as word counts, etc.\n\n## Example code\n```py\nfrom nlp_pipeline.nlp_pipeline import nlp_processor\n\n# additional columns I want to track in the metadata\nmetadata_addt_column_names = [\"title\", \"year\"] \n\n# instantiating the processor object\nprocessor = nlp_processor(\n\tdata_path = \"path_to_store_text_documents/\",\n\tmetadata_addt_column_names = metadata_addt_column_names,\n\twindows_tesseract_path = \"path_to_tesseract.exe\", # if on Windows, otherwise leave blank and have it installed in your path\n\twindows_poppler_path = \"path_to_poppler/bin\" # if on Windows, otherwise leave blank and have it installed in your path\n)\n\n# this will generate a metadata file and create the directory structure\n# you can now add additional data to the metadata file, (titles, etc.). When finished, run the following so the metadata in the processor object will reflect the local file\nprocessor.refresh_object_metadata()\n\n# if you ever make changes to the local files, e.g., delete a PDF, run the following to make sure the metadata file reflects that\nprocessor.sync_local_metadata()\n\n# download some documents with metadat IDs 1, 2, and 3\ntext_ids = [1,2,3]\nprocessor.download_text_id(text_ids)\n\n# convert the PDFs or HTMLs to .txt\nprocessor.convert_to_text(text_ids)\n\n# transform the text (stemming, etc.)\n# run help(processor.transform_text) for more information\nprocessor.transform_text(\n        text_ids = text_ids,\n        path_prefix = \"all_transformed\", # what to prefix the files with this transformation\n        perform_lower = True, # lower case the text\n        perform_replace_newline_period = True, # replace periods and newline characters with |\n        perform_remove_punctuation = True, # remove punctuation marks\n        perform_remove_stopwords = True, # remove stopwords (the, and, etc.)\n        perform_stemming = True, # stem the words (run = runs, etc.)\n        stemmer = \"snowball\" # which stemmer to use. If in doubt, use snowball\n)\n\n# from the transformed text, generate a CSV with word counts in each document\nprocessor.gen_word_count_csv(\n        text_ids = text_ids, \n        path_prefix = \"all_transformed\", # prefix used previously for the transformation\n        exclude_words = [\"for\"] # list of words to not include in the word counts\n)\n\n# get sentiment of a group of texts\nprocessor.gen_sentiment_csv(text_ids, \"all_transformed\")\n\n# get n_words, sentences, and pages of texts\nprocessor.gen_summary_stats_csv(text_ids, \"all_transformed\")\n\n# bar plot of most common words in a document or group of documents\np, plot_df = processor.bar_plot_word_count(\n\ttext_ids = text_ids, \n\tpath_prefix = \"all_transformed\", # prefix used previously for the transformation\n\tn_words = 10, # top n words to show\n\ttitle = \"Plot Title\"\n)\n\n# word cloud of most common words in a document or group of documents\np, plot_df = processor.word_cloud(\n\ttext_ids = text_ids, \n\tpath_prefix = \"all_transformed\", # prefix used previously for the transformation\n\tn_words = 10 # top n words to show\n)\n\n# plot of word occurrences over time\np, plot_df = processor.plot_word_occurrences(\n    text_ids_list = text_ids, # can be a list of lists, [[1,2,3], [4,5,6]], for counts by decade e.g.\n    word = \"green\", \n    path_prefix = \"all_transformed\", \n    x_labels = [1,2,3],\n    title = \"Plot Title\"\n)\n\n# plot average sentiment or neutral proportion in documents\np, plot_df = processor.plot_sentiment(\n    text_ids_list = text_ids, \n    path_prefix = \"all_transformed\", \n    x_labels = [1,2,3],\n    sentiment_col = \"neutral_proportion\",\n    title = \"Plot Title\"\n)\n\n# plot various summary stats in documents\np, plot_df = processor.plot_summary_stats(\n    text_ids_list = text_ids, \n    path_prefix = \"all_transformed\", \n    x_labels = [1,2,3],\n    summary_stat_col = \"n_words\", # one of: n_words, n_unique_words, n_sentences, n_pages, avg_word_length, avg_word_incidence\n    title = \"Plot Title\"\n)\n\n# get sentence-by-sentence sentiment report for a string or text_id\nsentiment_report = processor.gen_sentiment_report(text_id = 1) # to generate for a text_id\nsentiment_report = processor.gen_sentiment_report(stringx = \"a new string.\") # to generate for a new string\n```",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/dhopp1/nlp_pipeline",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "nlp-pipeline",
    "package_url": "https://pypi.org/project/nlp-pipeline/",
    "platform": null,
    "project_url": "https://pypi.org/project/nlp-pipeline/",
    "project_urls": {
      "Homepage": "https://github.com/dhopp1/nlp_pipeline"
    },
    "release_url": "https://pypi.org/project/nlp-pipeline/0.0.13/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "Pipelines and management structure for NLP analysis of a corpus of texts",
    "version": "0.0.13",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17141826,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ccb60e005ea161ddef2a4b16e9179f441afd422b3ea9c04ac2ea241e1d5c68b3",
          "md5": "b56b6053105598250f406d1507cadbec",
          "sha256": "3bcfb07cebab26b68305da821e72dffb0391945c1d7d1e4f9bfe87b0d91fd758"
        },
        "downloads": -1,
        "filename": "nlp_pipeline-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "b56b6053105598250f406d1507cadbec",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 14034,
        "upload_time": "2023-02-16T11:04:33",
        "upload_time_iso_8601": "2023-02-16T11:04:33.723770Z",
        "url": "https://files.pythonhosted.org/packages/cc/b6/0e005ea161ddef2a4b16e9179f441afd422b3ea9c04ac2ea241e1d5c68b3/nlp_pipeline-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.10": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "631f838c0a6771baf3d21cc6a580ba535c68fcfd15be8aa0992806d636e738d4",
          "md5": "2cd9b85a300fe8c9fd4c1d33dc4aeaac",
          "sha256": "cd0177f2dedefec612661a427153cda92ec5bea4988483d598d4671f765cae0f"
        },
        "downloads": -1,
        "filename": "nlp_pipeline-0.0.10.tar.gz",
        "has_sig": false,
        "md5_digest": "2cd9b85a300fe8c9fd4c1d33dc4aeaac",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 14917,
        "upload_time": "2023-02-23T08:24:57",
        "upload_time_iso_8601": "2023-02-23T08:24:57.641898Z",
        "url": "https://files.pythonhosted.org/packages/63/1f/838c0a6771baf3d21cc6a580ba535c68fcfd15be8aa0992806d636e738d4/nlp_pipeline-0.0.10.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.11": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "19e43db9780e69b70f835fabba45f9b98c4f97bf1ee51d0b20c558776c8abbba",
          "md5": "509bd39174462a29bda187e5cd827693",
          "sha256": "2981cde10c4670200b43dcae5c368f48900b865d3c429079979693106de84113"
        },
        "downloads": -1,
        "filename": "nlp_pipeline-0.0.11.tar.gz",
        "has_sig": false,
        "md5_digest": "509bd39174462a29bda187e5cd827693",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 14964,
        "upload_time": "2023-02-28T13:08:24",
        "upload_time_iso_8601": "2023-02-28T13:08:24.650334Z",
        "url": "https://files.pythonhosted.org/packages/19/e4/3db9780e69b70f835fabba45f9b98c4f97bf1ee51d0b20c558776c8abbba/nlp_pipeline-0.0.11.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.12": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8b258dffa0e7464477f0169a62b53ff4e0481f52cd81ea7bad7b6e6a2724ad2c",
          "md5": "e734db6ab27957791f304629adb02b20",
          "sha256": "907fed6fa4f0d4e73869aa21f05b8d797d4cf6f000f481e6dcfe361599180fe8"
        },
        "downloads": -1,
        "filename": "nlp_pipeline-0.0.12.tar.gz",
        "has_sig": false,
        "md5_digest": "e734db6ab27957791f304629adb02b20",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 14979,
        "upload_time": "2023-03-01T15:11:21",
        "upload_time_iso_8601": "2023-03-01T15:11:21.469150Z",
        "url": "https://files.pythonhosted.org/packages/8b/25/8dffa0e7464477f0169a62b53ff4e0481f52cd81ea7bad7b6e6a2724ad2c/nlp_pipeline-0.0.12.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.13": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2d09c76f8a997e66fbde3b91e5f8175ab9bfe839467a1bb34d4d9e072f19dad2",
          "md5": "79c2ed8ab55d8d098276418ed6380e0f",
          "sha256": "a9a2740fe67fa352e1299d4e16835c65612a98f6268170d1e1370d5826972a8d"
        },
        "downloads": -1,
        "filename": "nlp_pipeline-0.0.13.tar.gz",
        "has_sig": false,
        "md5_digest": "79c2ed8ab55d8d098276418ed6380e0f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 14992,
        "upload_time": "2023-03-03T09:19:00",
        "upload_time_iso_8601": "2023-03-03T09:19:00.687852Z",
        "url": "https://files.pythonhosted.org/packages/2d/09/c76f8a997e66fbde3b91e5f8175ab9bfe839467a1bb34d4d9e072f19dad2/nlp_pipeline-0.0.13.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "05d20082850a9a8e92a260f3dc48092991b08d74175317c202f003767fd98f5d",
          "md5": "edca3e63dff34616c0a5352f05146553",
          "sha256": "93442922dce65c2ea746332cd56c09812b1c472d088bab97c3a69e583f46cb08"
        },
        "downloads": -1,
        "filename": "nlp_pipeline-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "edca3e63dff34616c0a5352f05146553",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 14199,
        "upload_time": "2023-02-17T09:57:39",
        "upload_time_iso_8601": "2023-02-17T09:57:39.954139Z",
        "url": "https://files.pythonhosted.org/packages/05/d2/0082850a9a8e92a260f3dc48092991b08d74175317c202f003767fd98f5d/nlp_pipeline-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8bc683b652c555666911d34d32ad1fd1e61e2c1da9a1af68c7db83c2aff37492",
          "md5": "0a3f35548302982dd8d7db0f35e90055",
          "sha256": "412a9841544c4769d6896b3845ceb49f8b38981f7d97830210bd241bfec3cc13"
        },
        "downloads": -1,
        "filename": "nlp_pipeline-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "0a3f35548302982dd8d7db0f35e90055",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 14713,
        "upload_time": "2023-02-17T14:22:40",
        "upload_time_iso_8601": "2023-02-17T14:22:40.590662Z",
        "url": "https://files.pythonhosted.org/packages/8b/c6/83b652c555666911d34d32ad1fd1e61e2c1da9a1af68c7db83c2aff37492/nlp_pipeline-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5ba0ca5fbb22ca04b5778b7eaa678ac29f857062d463552d40de2ceaeb1e93f6",
          "md5": "8c0b16134969aff0de1eae7fe7a0881b",
          "sha256": "704cc772c7f384dd2b0bd89e1917f4c08e5e2c008ea41f310818bf1f2c4f81d5"
        },
        "downloads": -1,
        "filename": "nlp_pipeline-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "8c0b16134969aff0de1eae7fe7a0881b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 14738,
        "upload_time": "2023-02-19T08:18:40",
        "upload_time_iso_8601": "2023-02-19T08:18:40.306397Z",
        "url": "https://files.pythonhosted.org/packages/5b/a0/ca5fbb22ca04b5778b7eaa678ac29f857062d463552d40de2ceaeb1e93f6/nlp_pipeline-0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f7de36093f4819d36baf75aba0190e9d7f1eca8cba9815c7b97173a76eac16ba",
          "md5": "22e04b70d6923b57c0a8795d9486debe",
          "sha256": "7ab1f0e8a1aac5080ff5f3882ad86cfeacd3eafe9e30af00a32f0daa12b46f5e"
        },
        "downloads": -1,
        "filename": "nlp_pipeline-0.0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "22e04b70d6923b57c0a8795d9486debe",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 14763,
        "upload_time": "2023-02-19T14:24:23",
        "upload_time_iso_8601": "2023-02-19T14:24:23.088901Z",
        "url": "https://files.pythonhosted.org/packages/f7/de/36093f4819d36baf75aba0190e9d7f1eca8cba9815c7b97173a76eac16ba/nlp_pipeline-0.0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0e2447fed3417f4d309e1a536baa6904280570260dd39c71ae8f6c780531909c",
          "md5": "51b2fb2a942c961f43785f4647b927f3",
          "sha256": "2c7195dfd81344afa3830e882cb94a194494cad65205ae58bcc325cefca0adc5"
        },
        "downloads": -1,
        "filename": "nlp_pipeline-0.0.6.tar.gz",
        "has_sig": false,
        "md5_digest": "51b2fb2a942c961f43785f4647b927f3",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 14304,
        "upload_time": "2023-02-20T16:33:51",
        "upload_time_iso_8601": "2023-02-20T16:33:51.844792Z",
        "url": "https://files.pythonhosted.org/packages/0e/24/47fed3417f4d309e1a536baa6904280570260dd39c71ae8f6c780531909c/nlp_pipeline-0.0.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ef84a882a055e44c98144b7ae77db448fac2a630d6450f67e843a9c0ba28fe03",
          "md5": "0b0ff44f62d5a73909ca68f4761af727",
          "sha256": "49936e3a02c6befcbf08bddda08990d043ca97b8f843b694e75d32899f2a32cc"
        },
        "downloads": -1,
        "filename": "nlp_pipeline-0.0.7.tar.gz",
        "has_sig": false,
        "md5_digest": "0b0ff44f62d5a73909ca68f4761af727",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 14380,
        "upload_time": "2023-02-21T17:22:55",
        "upload_time_iso_8601": "2023-02-21T17:22:55.941077Z",
        "url": "https://files.pythonhosted.org/packages/ef/84/a882a055e44c98144b7ae77db448fac2a630d6450f67e843a9c0ba28fe03/nlp_pipeline-0.0.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6d68f423cb7b4c6c7b84145cef4b2d5e75f6ace46e0c9c03a55b21276f0233b4",
          "md5": "6a4e622faa23840a9dd80dc5da6e8959",
          "sha256": "5144f0817b053017bf799937f8133c1049feec01238c5d7fa4d42e2fb51c30fc"
        },
        "downloads": -1,
        "filename": "nlp_pipeline-0.0.8.tar.gz",
        "has_sig": false,
        "md5_digest": "6a4e622faa23840a9dd80dc5da6e8959",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 14895,
        "upload_time": "2023-02-22T13:25:13",
        "upload_time_iso_8601": "2023-02-22T13:25:13.114901Z",
        "url": "https://files.pythonhosted.org/packages/6d/68/f423cb7b4c6c7b84145cef4b2d5e75f6ace46e0c9c03a55b21276f0233b4/nlp_pipeline-0.0.8.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.9": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "28b82312ab3f5ddcbd5f394f72746eb42cb63db9ffbe24458ac13b4c189c4d94",
          "md5": "8bdd1aba0dfc0bf3bf277d60a9a922e4",
          "sha256": "77309e50627c0518420f41523e8c990372f690b9a897eda3a5678fddd3c44f55"
        },
        "downloads": -1,
        "filename": "nlp_pipeline-0.0.9.tar.gz",
        "has_sig": false,
        "md5_digest": "8bdd1aba0dfc0bf3bf277d60a9a922e4",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 14930,
        "upload_time": "2023-02-22T14:29:31",
        "upload_time_iso_8601": "2023-02-22T14:29:31.997609Z",
        "url": "https://files.pythonhosted.org/packages/28/b8/2312ab3f5ddcbd5f394f72746eb42cb63db9ffbe24458ac13b4c189c4d94/nlp_pipeline-0.0.9.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "2d09c76f8a997e66fbde3b91e5f8175ab9bfe839467a1bb34d4d9e072f19dad2",
        "md5": "79c2ed8ab55d8d098276418ed6380e0f",
        "sha256": "a9a2740fe67fa352e1299d4e16835c65612a98f6268170d1e1370d5826972a8d"
      },
      "downloads": -1,
      "filename": "nlp_pipeline-0.0.13.tar.gz",
      "has_sig": false,
      "md5_digest": "79c2ed8ab55d8d098276418ed6380e0f",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 14992,
      "upload_time": "2023-03-03T09:19:00",
      "upload_time_iso_8601": "2023-03-03T09:19:00.687852Z",
      "url": "https://files.pythonhosted.org/packages/2d/09/c76f8a997e66fbde3b91e5f8175ab9bfe839467a1bb34d4d9e072f19dad2/nlp_pipeline-0.0.13.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}