{
  "info": {
    "author": "Leondgarse",
    "author_email": "leondgarse@google.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Developers",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: Apache Software License",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Topic :: Scientific/Engineering",
      "Topic :: Scientific/Engineering :: Artificial Intelligence",
      "Topic :: Software Development",
      "Topic :: Software Development :: Libraries",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "# Keras_cv_attention_models\n- **coco_train_script.py is under testing. Still struggling for this...**\n<!-- TOC depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 -->\n\n- [General Usage](#general-usage)\n  - [Basic](#basic)\n  - [Layers](#layers)\n  - [Model surgery](#model-surgery)\n  - [ImageNet training and evaluating](#imagenet-training-and-evaluating)\n  - [COCO training and evaluating](#coco-training-and-evaluating)\n  - [Visualizing](#visualizing)\n  - [TFLite Conversion](#tflite-conversion)\n  - [Using PyTorch as backend](#using-pytorch-as-backend)\n- [Recognition Models](#recognition-models)\n  - [AotNet](#aotnet)\n  - [BEiT](#beit)\n  - [BEiTV2](#beitv2)\n  - [BotNet](#botnet)\n  - [CAFormer](#caformer)\n  - [CMT](#cmt)\n  - [CoaT](#coat)\n  - [CoAtNet](#coatnet)\n  - [ConvNeXt](#convnext)\n  - [ConvNeXtV2](#convnextv2)\n  - [CoTNet](#cotnet)\n  - [DaViT](#davit)\n  - [EdgeNeXt](#edgenext)\n  - [EfficientFormer](#efficientformer)\n  - [EfficientFormerV2](#efficientformerv2)\n  - [EfficientNet](#efficientnet)\n  - [EfficientNetV2](#efficientnetv2)\n  - [EVA](#eva)\n  - [FasterNet](#fasternet)\n  - [FBNetV3](#fbnetv3)\n  - [FlexiViT](#flexivit)\n  - [GCViT](#gcvit)\n  - [GhostNet](#ghostnet)\n  - [GhostNetV2](#ghostnetv2)\n  - [GMLP](#gmlp)\n  - [GPViT](#gpvit)\n  - [HaloNet](#halonet)\n  - [HorNet](#hornet)\n  - [IFormer](#iformer)\n  - [LCNet](#lcnet)\n  - [LeViT](#levit)\n  - [MaxViT](#maxvit)\n  - [MLP mixer](#mlp-mixer)\n  - [MobileNetV3](#mobilenetv3)\n  - [MobileViT](#mobilevit)\n  - [MobileViT_V2](#mobilevit_v2)\n  - [MogaNet](#moganet)\n  - [NAT](#nat)\n  - [NFNets](#nfnets)\n  - [PVT_V2](#pvt_v2)\n  - [RegNetY](#regnety)\n  - [RegNetZ](#regnetz)\n  - [ResMLP](#resmlp)\n  - [ResNeSt](#resnest)\n  - [ResNetD](#resnetd)\n  - [ResNetQ](#resnetq)\n  - [ResNeXt](#resnext)\n  - [SwinTransformerV2](#swintransformerv2)\n  - [TinyNet](#tinynet)\n  - [TinyViT](#tinyvit)\n  - [UniFormer](#uniformer)\n  - [VOLO](#volo)\n  - [WaveMLP](#wavemlp)\n- [Detection Models](#detection-models)\n  - [EfficientDet](#efficientdet)\n  - [YOLOR](#yolor)\n  - [YOLOV7](#yolov7)\n  - [YOLOX](#yolox)\n- [Licenses](#licenses)\n- [Citing](#citing)\n\n<!-- /TOC -->\n***\n\n# [Roadmap and todo list](https://github.com/leondgarse/keras_cv_attention_models/wiki/Roadmap)\n***\n\n# General Usage\n## Basic\n  - **Currently recommended TF version is `tensorflow==2.10.0`. Expecially for training or TFLite conversion**.\n  - **Default import** will not specific these while using them in READMEs.\n    ```py\n    import os\n    import sys\n    import tensorflow as tf\n    import numpy as np\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    from tensorflow import keras\n    ```\n  - Install as pip package. `kecam` is a short alias name of this package. **Note**: the pip package `kecam` doesn't set any requirement, make sure either Tensorflow or PyTorch installed before hand. For PyTorch backend usage, refer [Keras PyTorch Backend](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/pytorch_backend).\n    ```sh\n    pip install -U keras-cv-attention-models\n    # Or\n    pip install -U kecam\n    # Or\n    pip install -U git+https://github.com/leondgarse/keras_cv_attention_models\n    ```\n    Refer to each sub directory for detail usage.\n  - **Basic model prediction**\n    ```py\n    from keras_cv_attention_models import volo\n    mm = volo.VOLO_d1(pretrained=\"imagenet\")\n\n    \"\"\" Run predict \"\"\"\n    import tensorflow as tf\n    from tensorflow import keras\n    from skimage.data import chelsea\n    img = chelsea() # Chelsea the cat\n    imm = keras.applications.imagenet_utils.preprocess_input(img, mode='torch')\n    pred = mm(tf.expand_dims(tf.image.resize(imm, mm.input_shape[1:3]), 0)).numpy()\n    pred = tf.nn.softmax(pred).numpy()  # If classifier activation is not softmax\n    print(keras.applications.imagenet_utils.decode_predictions(pred)[0])\n    # [('n02124075', 'Egyptian_cat', 0.9692954),\n    #  ('n02123045', 'tabby', 0.020203391),\n    #  ('n02123159', 'tiger_cat', 0.006867502),\n    #  ('n02127052', 'lynx', 0.00017674894),\n    #  ('n02123597', 'Siamese_cat', 4.9493494e-05)]\n    ```\n    Or just use model preset `preprocess_input` and `decode_predictions`\n    ```py\n    from keras_cv_attention_models import coatnet\n    from skimage.data import chelsea\n    mm = coatnet.CoAtNet0()\n    preds = mm(mm.preprocess_input(chelsea()))\n    print(mm.decode_predictions(preds))\n    # [[('n02124075', 'Egyptian_cat', 0.9653769), ('n02123159', 'tiger_cat', 0.018427467), ...]\n    ```\n  - **`num_classes={custom output classes}`** others than `1000` or `0` will just skip loading the header Dense layer weights. As `model.load_weights(weight_file, by_name=True, skip_mismatch=True)` is used for loading weights.\n    ```py\n    from keras_cv_attention_models import swin_transformer_v2\n\n    mm = swin_transformer_v2.SwinTransformerV2Tiny_window8(num_classes=64)\n    # >>>> Load pretrained from: ~/.keras/models/swin_transformer_v2_tiny_window8_256_imagenet.h5\n    # WARNING:tensorflow:Skipping loading weights for layer #601 (named predictions) due to mismatch in shape for weight predictions/kernel:0. Weight expects shape (768, 64). Received saved weight with shape (768, 1000)\n    # WARNING:tensorflow:Skipping loading weights for layer #601 (named predictions) due to mismatch in shape for weight predictions/bias:0. Weight expects shape (64,). Received saved weight with shape (1000,)\n    ```\n  - **`num_classes=0`** set for excluding model top `GlobalAveragePooling2D + Dense` layers.\n    ```py\n    from keras_cv_attention_models import resnest\n    mm = resnest.ResNest50(num_classes=0)\n    print(mm.output_shape)\n    # (None, 7, 7, 2048)\n    ```\n  - **Reload own model weights by set `pretrained=\"xxx.h5\"`**. Better than calling `model.load_weights` directly, if reloading model with different `input_shape` and with weights shape not matching.\n    ```py\n    import os\n    from keras_cv_attention_models import coatnet\n    pretrained = os.path.expanduser('~/.keras/models/coatnet0_224_imagenet.h5')\n    mm = coatnet.CoAtNet1(input_shape=(384, 384, 3), pretrained=pretrained)  # No sense, just showing usage\n    ```\n  - **Alias name `kecam`** can be used instead of `keras_cv_attention_models`. It's `__init__.py` only with `from keras_cv_attention_models import *`.\n    ```py\n    import kecam\n    mm = kecam.yolor.YOLOR_CSP()\n    imm = kecam.test_images.dog_cat()\n    preds = mm(mm.preprocess_input(imm))\n    bboxs, lables, confidences = mm.decode_predictions(preds)[0]\n    kecam.coco.show_image_with_bboxes(imm, bboxs, lables, confidences)\n    ```\n  - **Calculate flops** method from [TF 2.0 Feature: Flops calculation #32809](https://github.com/tensorflow/tensorflow/issues/32809#issuecomment-849439287).\n    ```py\n    from keras_cv_attention_models import coatnet, resnest, model_surgery\n\n    model_surgery.get_flops(coatnet.CoAtNet0())\n    # >>>> FLOPs: 4,221,908,559, GFLOPs: 4.2219G\n    model_surgery.get_flops(resnest.ResNest50())\n    # >>>> FLOPs: 5,378,399,992, GFLOPs: 5.3784G\n    ```\n  - **`tensorflow_addons`** is not imported by default. While reloading model depending on `GroupNormalization` like `MobileViTV2` from `h5` directly, needs to import `tensorflow_addons` manually first.\n    ```py\n    import tensorflow_addons as tfa\n\n    model_path = os.path.expanduser('~/.keras/models/mobilevit_v2_050_256_imagenet.h5')\n    mm = keras.models.load_model(model_path)\n    ```\n  - **Code format** is using `line-length=160`:\n    ```sh\n    find ./* -name \"*.py\" | grep -v __init__ | grep -v setup.py | xargs -I {} black -l 160 {}\n    ```\n## Layers\n  - [attention_layers](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/attention_layers) is `__init__.py` only, which imports core layers defined in model architectures. Like `RelativePositionalEmbedding` from `botnet`, `outlook_attention` from `volo`, and many other `Positional Embedding Layers` / `Attention Blocks`.\n  ```py\n  from keras_cv_attention_models import attention_layers\n  aa = attention_layers.RelativePositionalEmbedding()\n  print(f\"{aa(tf.ones([1, 4, 14, 16, 256])).shape = }\")\n  # aa(tf.ones([1, 4, 14, 16, 256])).shape = TensorShape([1, 4, 14, 16, 14, 16])\n  ```\n## Model surgery\n  - [model_surgery](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/model_surgery) including functions used to change model parameters after built.\n  ```py\n  from keras_cv_attention_models import model_surgery\n  mm = keras.applications.ResNet50()  # Trainable params: 25,583,592\n\n  # Replace all ReLU with PReLU. Trainable params: 25,606,312\n  mm = model_surgery.replace_ReLU(mm, target_activation='PReLU')\n\n  # Fuse conv and batch_norm layers. Trainable params: 25,553,192\n  mm = model_surgery.convert_to_fused_conv_bn_model(mm)\n  ```\n## ImageNet training and evaluating\n  - [ImageNet](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/imagenet) contains more detail usage and some comparing results.\n  - [Init Imagenet dataset using tensorflow_datasets #9](https://github.com/leondgarse/keras_cv_attention_models/discussions/9).\n  - For custom dataset, `custom_dataset_script.py` can be used creating a `json` format file, which can be used as `--data_name xxx.json` for training, detail usage can be found in [Custom recognition dataset](https://github.com/leondgarse/keras_cv_attention_models/discussions/52#discussion-3971513).\n  - Another method creating custom dataset is using `tfds.load`, refer [Writing custom datasets](https://www.tensorflow.org/datasets/add_dataset) and [Creating private tensorflow_datasets from tfds #48](https://github.com/leondgarse/keras_cv_attention_models/discussions/48) by @Medicmind.\n  - Running an AWS Sagemaker estimator job using `keras_cv_attention_models` can be found in [AWS Sagemaker script example](https://github.com/leondgarse/keras_cv_attention_models/discussions/107) by @Medicmind.\n  - `aotnet.AotNet50` default parameters set is a typical `ResNet50` architecture with `Conv2D use_bias=False` and `padding` like `PyTorch`.\n  - Default parameters for `train_script.py` is like `A3` configuration from [ResNet strikes back: An improved training procedure in timm](https://arxiv.org/pdf/2110.00476.pdf) with `batch_size=256, input_shape=(160, 160)`.\n    ```sh\n    # `antialias` is default enabled for resize, can be turned off be set `--disable_antialias`.\n    CUDA_VISIBLE_DEVICES='0' TF_XLA_FLAGS=\"--tf_xla_auto_jit=2\" ./train_script.py --seed 0 -s aotnet50\n    ```\n    ```sh\n    # Evaluation using input_shape (224, 224).\n    # `antialias` usage should be same with training.\n    CUDA_VISIBLE_DEVICES='1' ./eval_script.py -m aotnet50_epoch_103_val_acc_0.7674.h5 -i 224 --central_crop 0.95\n    # >>>> Accuracy top1: 0.78466 top5: 0.94088\n    ```\n    ![aotnet50_imagenet](https://user-images.githubusercontent.com/5744524/163795114-b2441e5d-94d5-4310-826a-958426f1343e.png)\n  - **Restore from break point** by setting `--restore_path` and `--initial_epoch`, and keep other parameters same. `restore_path` is higher priority than `model` and `additional_model_kwargs`, also restore `optimizer` and `loss`. `initial_epoch` is mainly for learning rate scheduler. If not sure where it stopped, check `checkpoints/{save_name}_hist.json`.\n    ```py\n    import json\n    with open(\"checkpoints/aotnet50_hist.json\", \"r\") as ff:\n        aa = json.load(ff)\n    len(aa['lr'])\n    # 41 ==> 41 epochs are finished, initial_epoch is 41 then, restart from epoch 42\n    ```\n    ```sh\n    CUDA_VISIBLE_DEVICES='0' TF_XLA_FLAGS=\"--tf_xla_auto_jit=2\" ./train_script.py --seed 0 -r checkpoints/aotnet50_latest.h5 -I 41\n    # >>>> Restore model from: checkpoints/aotnet50_latest.h5\n    # Epoch 42/105\n    ```\n  - **`eval_script.py`** is used for evaluating model accuracy. [EfficientNetV2 self tested imagenet accuracy #19](https://github.com/leondgarse/keras_cv_attention_models/discussions/19) just showing how different parameters affecting model accuracy.\n    ```sh\n    # evaluating pretrained builtin model\n    CUDA_VISIBLE_DEVICES='1' ./eval_script.py -m regnet.RegNetZD8\n    # evaluating pretrained timm model\n    CUDA_VISIBLE_DEVICES='1' ./eval_script.py -m timm.models.resmlp_12_224 --input_shape 224\n\n    # evaluating specific h5 model\n    CUDA_VISIBLE_DEVICES='1' ./eval_script.py -m checkpoints/xxx.h5\n    # evaluating specific tflite model\n    CUDA_VISIBLE_DEVICES='1' ./eval_script.py -m xxx.tflite\n    ```\n  - **Progressive training** refer to [PDF 2104.00298 EfficientNetV2: Smaller Models and Faster Training](https://arxiv.org/pdf/2104.00298.pdf). AotNet50 A3 progressive input shapes `96 128 160`:\n    ```sh\n    CUDA_VISIBLE_DEVICES='1' TF_XLA_FLAGS=\"--tf_xla_auto_jit=2\" ./progressive_train_script.py \\\n    --progressive_epochs 33 66 -1 \\\n    --progressive_input_shapes 96 128 160 \\\n    --progressive_magnitudes 2 4 6 \\\n    -s aotnet50_progressive_3_lr_steps_100 --seed 0\n    ```\n    ![aotnet50_progressive_160](https://user-images.githubusercontent.com/5744524/151286851-221ff8eb-9fe9-4685-aa60-4a3ba98c654e.png)\n  - Transfer learning with `freeze_backbone` or `freeze_norm_layers`: [EfficientNetV2B0 transfer learning on cifar10 testing freezing backbone #55](https://github.com/leondgarse/keras_cv_attention_models/discussions/55).\n  - [Token label train test on CIFAR10 #57](https://github.com/leondgarse/keras_cv_attention_models/discussions/57). **Currently not working as well as expected**. `Token label` is implementation of [Github zihangJiang/TokenLabeling](https://github.com/zihangJiang/TokenLabeling), paper [PDF 2104.10858 All Tokens Matter: Token Labeling for Training Better Vision Transformers](https://arxiv.org/pdf/2104.10858.pdf).\n## COCO training and evaluating\n  - **Currently still under testing**.\n  - [COCO](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/coco) contains more detail usage.\n  - `custom_dataset_script.py` can be used creating a `json` format file, which can be used as `--data_name xxx.json` for training, detail usage can be found in [Custom detection dataset](https://github.com/leondgarse/keras_cv_attention_models/discussions/52#discussioncomment-2460664).\n  - Default parameters for `coco_train_script.py` is `EfficientDetD0` with `input_shape=(256, 256, 3), batch_size=64, mosaic_mix_prob=0.5, freeze_backbone_epochs=32, total_epochs=105`. Technically, it's any `pyramid structure backbone` + `EfficientDet / YOLOX header / YOLOR header` + `anchor_free / yolor / efficientdet anchors` combination supported.\n  - Currently 3 types anchors supported, parameter **`anchors_mode`** controls which anchor to use, value in `[\"efficientdet\", \"anchor_free\", \"yolor\"]`. Default `None` for `det_header` presets.\n\n    | anchors_mode | use_object_scores | num_anchors | anchor_scale | aspect_ratios | num_scales | grid_zero_start |\n    | ------------ | ----------------- | ----------- | ------------ | ------------- | ---------- | --------------- |\n    | efficientdet | False             | 9           | 4            | [1, 2, 0.5]   | 3          | False           |\n    | anchor_free  | True              | 1           | 1            | [1]           | 1          | True            |\n    | yolor        | True              | 3           | None         | presets       | None       | offset=0.5      |\n\n    ```sh\n    # Default EfficientDetD0\n    CUDA_VISIBLE_DEVICES='0' ./coco_train_script.py\n    # Default EfficientDetD0 using input_shape 512, optimizer adamw, freezing backbone 16 epochs, total 50 + 5 epochs\n    CUDA_VISIBLE_DEVICES='0' ./coco_train_script.py -i 512 -p adamw --freeze_backbone_epochs 16 --lr_decay_steps 50\n\n    # EfficientNetV2B0 backbone + EfficientDetD0 detection header\n    CUDA_VISIBLE_DEVICES='0' ./coco_train_script.py --backbone efficientnet.EfficientNetV2B0 --det_header efficientdet.EfficientDetD0\n    # ResNest50 backbone + EfficientDetD0 header using yolox like anchor_free anchors\n    CUDA_VISIBLE_DEVICES='0' ./coco_train_script.py --backbone resnest.ResNest50 --anchors_mode anchor_free\n    # UniformerSmall32 backbone + EfficientDetD0 header using yolor anchors\n    CUDA_VISIBLE_DEVICES='0' ./coco_train_script.py --backbone uniformer.UniformerSmall32 --anchors_mode yolor\n\n    # Typical YOLOXS with anchor_free anchors\n    CUDA_VISIBLE_DEVICES='0' ./coco_train_script.py --det_header yolox.YOLOXS --freeze_backbone_epochs 0\n    # YOLOXS with efficientdet anchors\n    CUDA_VISIBLE_DEVICES='0' ./coco_train_script.py --det_header yolox.YOLOXS --anchors_mode efficientdet --freeze_backbone_epochs 0\n    # CoAtNet0 backbone + YOLOX header with yolor anchors\n    CUDA_VISIBLE_DEVICES='0' ./coco_train_script.py --backbone coatnet.CoAtNet0 --det_header yolox.YOLOX --anchors_mode yolor\n\n    # Typical YOLOR_P6 with yolor anchors\n    CUDA_VISIBLE_DEVICES='0' ./coco_train_script.py --det_header yolor.YOLOR_P6 --freeze_backbone_epochs 0\n    # YOLOR_P6 with anchor_free anchors\n    CUDA_VISIBLE_DEVICES='0' ./coco_train_script.py --det_header yolor.YOLOR_P6 --anchors_mode anchor_free  --freeze_backbone_epochs 0\n    # ConvNeXtTiny backbone + YOLOR header with efficientdet anchors\n    CUDA_VISIBLE_DEVICES='0' ./coco_train_script.py --backbone convnext.ConvNeXtTiny --det_header yolor.YOLOR --anchors_mode yolor\n    ```\n    **Note: COCO training still under testing, may change parameters and default behaviors. Take the risk if would like help developing.**\n  - **`coco_eval_script.py`** is used for evaluating model AP / AR on COCO validation set. It has a dependency `pip install pycocotools` which is not in package requirements. More usage can be found in [COCO Evaluation](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/coco#evaluation).\n    ```sh\n    # EfficientDetD0 using resize method bilinear w/o antialias\n    CUDA_VISIBLE_DEVICES='1' ./coco_eval_script.py -m efficientdet.EfficientDetD0 --resize_method bilinear --disable_antialias\n    # >>>> [COCOEvalCallback] input_shape: (512, 512), pyramid_levels: [3, 7], anchors_mode: efficientdet\n\n    # YOLOX using BGR input format\n    CUDA_VISIBLE_DEVICES='1' ./coco_eval_script.py -m yolox.YOLOXTiny --use_bgr_input --nms_method hard --nms_iou_or_sigma 0.65\n    # >>>> [COCOEvalCallback] input_shape: (416, 416), pyramid_levels: [3, 5], anchors_mode: anchor_free\n\n    # YOLOR / YOLOV7 using letterbox_pad and other tricks.\n    CUDA_VISIBLE_DEVICES='1' ./coco_eval_script.py -m yolor.YOLOR_CSP --nms_method hard --nms_iou_or_sigma 0.65 \\\n    --nms_max_output_size 300 --nms_topk -1 --letterbox_pad 64 --input_shape 704\n    # >>>> [COCOEvalCallback] input_shape: (704, 704), pyramid_levels: [3, 5], anchors_mode: yolor\n\n    # Specify h5 model\n    CUDA_VISIBLE_DEVICES='1' ./coco_eval_script.py -m checkpoints/yoloxtiny_yolor_anchor.h5\n    # >>>> [COCOEvalCallback] input_shape: (416, 416), pyramid_levels: [3, 5], anchors_mode: yolor\n    ```\n## Visualizing\n  - [Visualizing](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/visualizing) is for visualizing convnet filters or attention map scores.\n  - **make_and_apply_gradcam_heatmap** is for Grad-CAM class activation visualization.\n    ```py\n    from keras_cv_attention_models import visualizing, test_images, resnest\n    mm = resnest.ResNest50()\n    img = test_images.dog()\n    superimposed_img, heatmap, preds = visualizing.make_and_apply_gradcam_heatmap(mm, img, layer_name=\"auto\")\n    ```\n    ![](https://user-images.githubusercontent.com/5744524/148199374-4944800e-a1fb-4df2-b9ba-43ce3dde88f2.png)\n  - **plot_attention_score_maps** is model attention score maps visualization.\n    ```py\n    from keras_cv_attention_models import visualizing, test_images, botnet\n    img = test_images.dog()\n    _ = visualizing.plot_attention_score_maps(botnet.BotNetSE33T(), img)\n    ```\n    ![](https://user-images.githubusercontent.com/5744524/147209511-f5194d73-9e4c-457e-a763-45a4025f452b.png)\n## TFLite Conversion\n  - Currently `TFLite` not supporting `Conv2D with groups>1` / `gelu` / `tf.image.extract_patches` / `tf.transpose with len(perm) > 4`. Some operations could be supported in `tf-nightly` version. May try if encountering issue. More discussion can be found [Converting a trained keras CV attention model to TFLite #17](https://github.com/leondgarse/keras_cv_attention_models/discussions/17). Some speed testing results can be found [How to speed up inference on a quantized model #44](https://github.com/leondgarse/keras_cv_attention_models/discussions/44#discussioncomment-2348910).\n  - `tf.nn.gelu(inputs, approximate=True)` activation works for TFLite. Define model with `activation=\"gelu/approximate\"` or `activation=\"gelu/app\"` will set `approximate=True` for `gelu`. **Should better decide before training, or there may be accuracy loss**.\n  - Not supporting `VOLO` / `HaloNet` models converting, cause they need a longer `tf.transpose` `perm`.\n  - **model_surgery.convert_groups_conv2d_2_split_conv2d** converts model `Conv2D with groups>1` layers to `SplitConv` using `split -> conv -> concat`:\n    ```py\n    from keras_cv_attention_models import regnet, model_surgery\n    from keras_cv_attention_models.imagenet import eval_func\n\n    bb = regnet.RegNetZD32()\n    mm = model_surgery.convert_groups_conv2d_2_split_conv2d(bb)  # converts all `Conv2D` using `groups` to `SplitConv2D`\n    test_inputs = np.random.uniform(size=[1, *mm.input_shape[1:]])\n    print(np.allclose(mm(test_inputs), bb(test_inputs)))\n    # True\n\n    converter = tf.lite.TFLiteConverter.from_keras_model(mm)\n    open(mm.name + \".tflite\", \"wb\").write(converter.convert())\n    print(np.allclose(mm(test_inputs), eval_func.TFLiteModelInterf(mm.name + '.tflite')(test_inputs), atol=1e-7))\n    # True\n    ```\n  - **model_surgery.convert_gelu_and_extract_patches_for_tflite** converts model `gelu` activation to `gelu approximate=True`, and `tf.image.extract_patches` to a `Conv2D` version:\n    ```py\n    from keras_cv_attention_models import cotnet, model_surgery\n    from keras_cv_attention_models.imagenet import eval_func\n\n    mm = cotnet.CotNetSE50D()\n    mm = model_surgery.convert_groups_conv2d_2_split_conv2d(mm)\n    mm = model_surgery.convert_gelu_and_extract_patches_for_tflite(mm)\n    converter = tf.lite.TFLiteConverter.from_keras_model(mm)\n    open(mm.name + \".tflite\", \"wb\").write(converter.convert())\n    test_inputs = np.random.uniform(size=[1, *mm.input_shape[1:]])\n    print(np.allclose(mm(test_inputs), eval_func.TFLiteModelInterf(mm.name + '.tflite')(test_inputs), atol=1e-7))\n    # True\n    ```\n  - **model_surgery.prepare_for_tflite** is just a combination of above 2 functions:\n    ```py\n    from keras_cv_attention_models import beit, model_surgery\n\n    mm = beit.BeitBasePatch16()\n    mm = model_surgery.prepare_for_tflite(mm)\n    converter = tf.lite.TFLiteConverter.from_keras_model(mm)\n    open(mm.name + \".tflite\", \"wb\").write(converter.convert())\n    ```\n  - **Detection models** including `efficinetdet` / `yolox` / `yolor`, model can be converted a TFLite format directly. If need [DecodePredictions](https://github.com/leondgarse/keras_cv_attention_models/blob/main/keras_cv_attention_models/coco/eval_func.py#L8) also included in TFLite model, need to set `use_static_output=True` for `DecodePredictions`, as TFLite requires a more static output shape. Model output shape will be fixed as `[batch, max_output_size, 6]`. The last dimension `6` means `[bbox_top, bbox_left, bbox_bottom, bbox_right, label_index, confidence]`, and those valid ones are where `confidence > 0`.\n    ```py\n    \"\"\" Init model \"\"\"\n    from keras_cv_attention_models import efficientdet\n    model = efficientdet.EfficientDetD0(pretrained=\"coco\")\n\n    \"\"\" Create a model with DecodePredictions using `use_static_output=True` \"\"\"\n    model.decode_predictions.use_static_output = True\n    # parameters like score_threshold / iou_or_sigma can be set another value if needed.\n    nn = model.decode_predictions(model.outputs[0], score_threshold=0.5)\n    bb = keras.models.Model(model.inputs[0], nn)\n\n    \"\"\" Convert TFLite \"\"\"\n    converter = tf.lite.TFLiteConverter.from_keras_model(bb)\n    open(bb.name + \".tflite\", \"wb\").write(converter.convert())\n\n    \"\"\" Inference test \"\"\"\n    from keras_cv_attention_models.imagenet import eval_func\n    from keras_cv_attention_models import test_images\n\n    dd = eval_func.TFLiteModelInterf(bb.name + \".tflite\")\n    imm = test_images.cat()\n    inputs = tf.expand_dims(tf.image.resize(imm, dd.input_shape[1:-1]), 0)\n    inputs = keras.applications.imagenet_utils.preprocess_input(inputs, mode='torch')\n    preds = dd(inputs)[0]\n    print(f\"{preds.shape = }\")\n    # preds.shape = (100, 6)\n\n    pred = preds[preds[:, -1] > 0]\n    bboxes, labels, confidences = pred[:, :4], pred[:, 4], pred[:, -1]\n    print(f\"{bboxes = }, {labels = }, {confidences = }\")\n    # bboxes = array([[0.22825494, 0.47238672, 0.816262  , 0.8700745 ]], dtype=float32),\n    # labels = array([16.], dtype=float32),\n    # confidences = array([0.8309707], dtype=float32)\n\n    \"\"\" Show result \"\"\"\n    from keras_cv_attention_models.coco import data\n    data.show_image_with_bboxes(imm, bboxes, labels, confidences, num_classes=90)\n    ```\n## Using PyTorch as backend\n  - **Experimental** [Keras PyTorch Backend](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/pytorch_backend).\n  - **Set os environment `export KECAM_BACKEND='torch'` to enable this PyTorch backend.**\n  - Currently supports most recognition and detection models except cotnet / halonet / hornet / nat / nfnets / volo. For detection models, still using `tf.image.non_max_suppression_with_scores` while running prediction.\n  - **Basic model build and prediction**.\n    - Will load same `h5` weights as TF one if available.\n    - Note: `input_shape` will auto fit image data format. Given `input_shape=(224, 224, 3)` or `input_shape=(3, 224, 224)`, will both set to `(3, 224, 224)` if `channels_first`.\n    - Note: model is default set to `eval` mode.\n    ```py\n    from keras_cv_attention_models import res_mlp\n    mm = res_mlp.ResMLP12()\n    # >>>> Load pretrained from: ~/.keras/models/resmlp12_imagenet.h5\n    print(f\"{mm.input_shape = }\")\n    # mm.input_shape = [None, 3, 224, 224]\n\n    import torch\n    print(f\"{isinstance(mm, torch.nn.Module) = }\")\n    # isinstance(mm, torch.nn.Module) = True\n\n    # Run prediction\n    from skimage.data import chelsea # Chelsea the cat\n    print(mm.decode_predictions(mm(mm.preprocess_input(chelsea())))[0])\n    # [('n02124075', 'Egyptian_cat', 0.86188155), ('n02123159', 'tiger_cat', 0.05125639), ...]\n    ```\n  - **Export typical PyTorch onnx / pth**.\n    ```py\n    import torch\n    torch.onnx.export(mm, torch.randn(1, 3, *mm.input_shape[2:]), mm.name + \".onnx\")\n\n    # Or by export_onnx\n    mm.export_onnx()\n    # Exported onnx: resmlp12.onnx\n\n    mm.export_pth()\n    # Exported pth: resmlp12.pth\n    ```\n  - **Save weights as h5**. This `h5` can also be loaded in typical TF backend model. Currently it's only weights without model structure supported.\n    ```py\n    mm.save_weights(\"foo.h5\")\n    ```\n***\n\n# Recognition Models\n## AotNet\n  - [Keras AotNet](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/aotnet) is just a `ResNet` / `ResNetV2` like framework, that set parameters like `attn_types` and `se_ratio` and others, which is used to apply different types attention layer. Works like `byoanet` / `byobnet` from `timm`.\n  - Default parameters set is a typical `ResNet` architecture with `Conv2D use_bias=False` and `padding` like `PyTorch`.\n  ```py\n  from keras_cv_attention_models import aotnet\n  # Mixing se and outlook and halo and mhsa and cot_attention, 21M parameters.\n  # 50 is just a picked number that larger than the relative `num_block`.\n  attn_types = [None, \"outlook\", [\"bot\", \"halo\"] * 50, \"cot\"],\n  se_ratio = [0.25, 0, 0, 0],\n  model = aotnet.AotNet50V2(attn_types=attn_types, se_ratio=se_ratio, stem_type=\"deep\", strides=1)\n  model.summary()\n  ```\n## BEiT\n  - [Keras BEiT](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/beit) includes models from [PDF 2106.08254 BEiT: BERT Pre-Training of Image Transformers](https://arxiv.org/pdf/2106.08254.pdf).\n\n  | Model                 | Params  | FLOPs   | Input | Top1 Acc | Download                         |\n  | --------------------- | ------- | ------- | ----- | -------- | -------------------------------- |\n  | BeitBasePatch16, 21k  | 86.53M  | 17.61G  | 224   | 85.240   | [beit_base_patch16_224.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/beit/beit_base_patch16_224_imagenet21k-ft1k.h5)  |\n  |                       | 86.74M  | 55.70G  | 384   | 86.808   | [beit_base_patch16_384.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/beit/beit_base_patch16_384_imagenet21k-ft1k.h5)  |\n  | BeitLargePatch16, 21k | 304.43M | 61.68G  | 224   | 87.476   | [beit_large_patch16_224.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/beit/beit_large_patch16_224_imagenet21k-ft1k.h5) |\n  |                       | 305.00M | 191.65G | 384   | 88.382   | [beit_large_patch16_384.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/beit/beit_large_patch16_384_imagenet21k-ft1k.h5) |\n  |                       | 305.67M | 363.46G | 512   | 88.584   | [beit_large_patch16_512.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/beit/beit_large_patch16_512_imagenet21k-ft1k.h5) |\n## BEiTV2\n  - [Keras BEiT](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/beit) includes models from BeitV2 Paper [PDF 2208.06366 BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers](https://arxiv.org/pdf/2208.06366.pdf).\n\n  | Model              | Params  | FLOPs  | Input | Top1 Acc | Download |\n  | ------------------ | ------- | ------ | ----- | -------- | -------- |\n  | BeitV2BasePatch16  | 86.53M  | 17.61G | 224   | 85.5     |          |\n  | - imagenet21k-ft1k | 86.53M  | 17.61G | 224   | 86.5     | [beit_v2_base_patch16_224.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/beit/beit_v2_base_patch16_224_imagenet21k-ft1k.h5)  |\n  | BeitV2BasePatch16  | 304.43M | 61.68G | 224   | 87.3     |          |\n  | - imagenet21k-ft1k | 304.43M | 61.68G | 224   | 88.4     | [beit_v2_large_patch16_224.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/beit/beit_v2_large_patch16_224_imagenet21k-ft1k.h5)  |\n## BotNet\n  - [Keras BotNet](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/botnet) is for [PDF 2101.11605 Bottleneck Transformers for Visual Recognition](https://arxiv.org/pdf/2101.11605.pdf).\n\n  | Model         | Params | FLOPs  | Input | Top1 Acc | Download |\n  | ------------- | ------ | ------ | ----- | -------- | -------- |\n  | BotNet50      | 21M    | 5.42G  | 224   |          |          |\n  | BotNet101     | 41M    | 9.13G  | 224   |          |          |\n  | BotNet152     | 56M    | 12.84G | 224   |          |          |\n  | BotNet26T     | 12.5M  | 3.30G  | 256   | 79.246   | [botnet26t_256_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/botnet/botnet26t_256_imagenet.h5) |\n  | BotNextECA26T | 10.59M | 2.45G  | 256   | 79.270   | [botnext_eca26t_256_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/botnet/botnext_eca26t_256_imagenet.h5) |\n  | BotNetSE33T   | 13.7M  | 3.89G  | 256   | 81.2     | [botnet_se33t_256_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/botnet/botnet_se33t_256_imagenet.h5) |\n## CAFormer\n  - [Keras CAFormer](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/caformer) is for [PDF 2210.13452 MetaFormer Baselines for Vision](https://arxiv.org/pdf/2210.13452.pdf). `CAFormer` is using 2 transformer stacks, while `ConvFormer` is all conv blocks.\n\n  | Model              | Params | FLOPs | Input | Top1 Acc | Download |\n  | ------------------ | ------ | ----- | ----- | -------- | -------- |\n  | CAFormerS18        | 26M    | 4.1G  | 224   | 83.6     | [caformer_s18_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/caformer/caformer_s18_224_imagenet.h5) |\n  | - imagenet21k-ft1k | 26M    | 4.1G  | 224   | 84.1     | [caformer_s18_224_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/caformer/caformer_s18_224_imagenet21k-ft1k.h5) |\n  |                    | 26M    | 13.4G | 384   | 85.0     | [caformer_s18_384_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/caformer/caformer_s18_384_imagenet.h5) |\n  | - imagenet21k-ft1k | 26M    | 13.4G | 384   | 85.4     | [caformer_s18_384_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/caformer/caformer_s18_384_imagenet21k-ft1k.h5) |\n  | CAFormerS36        | 39M    | 8.0G  | 224   | 84.5     | [caformer_s36_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/caformer/caformer_s36_224_imagenet.h5) |\n  | - imagenet21k-ft1k | 39M    | 8.0G  | 224   | 85.8     | [caformer_s36_224_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/caformer/caformer_s36_224_imagenet21k-ft1k.h5) |\n  |                    | 39M    | 26.0G | 384   | 85.7     | [caformer_s36_384_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/caformer/caformer_s36_384_imagenet.h5) |\n  | - imagenet21k-ft1k | 39M    | 26.0G | 384   | 86.9     | [caformer_s36_384_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/caformer/caformer_s36_384_imagenet21k-ft1k.h5) |\n  | CAFormerM36        | 56M    | 13.2G | 224   | 85.2     | [caformer_m36_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/caformer/caformer_m36_224_imagenet.h5) |\n  | - imagenet21k-ft1k | 56M    | 13.2G | 224   | 86.6     | [caformer_m36_224_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/caformer/caformer_m36_224_imagenet21k-ft1k.h5) |\n  |                    | 56M    | 42.0G | 384   | 86.2     | [caformer_m36_384_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/caformer/caformer_m36_384_imagenet.h5) |\n  | - imagenet21k-ft1k | 56M    | 42.0G | 384   | 87.5     | [caformer_m36_384_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/caformer/caformer_m36_384_imagenet21k-ft1k.h5) |\n  | CAFormerB36        | 99M    | 23.2G | 224   | 85.5     | [caformer_b36_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/caformer/caformer_b36_224_imagenet.h5) |\n  | - imagenet21k-ft1k | 99M    | 23.2G | 224   | 87.4     | [caformer_b36_224_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/caformer/caformer_b36_224_imagenet21k-ft1k.h5) |\n  |                    | 99M    | 72.2G | 384   | 86.4     | [caformer_b36_384_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/caformer/caformer_b36_384_imagenet.h5) |\n  | - imagenet21k-ft1k | 99M    | 72.2G | 384   | 88.1     | [caformer_b36_384_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/caformer/caformer_b36_384_imagenet21k-ft1k.h5) |\n\n  | Model              | Params | FLOPs | Input | Top1 Acc | Download |\n  | ------------------ | ------ | ----- | ----- | -------- | -------- |\n  | ConvFormerS18      | 27M    | 3.9G  | 224   | 83.0     | [convformer_s18_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/caformer/convformer_s18_224_imagenet.h5) |\n  | - imagenet21k-ft1k | 27M    | 3.9G  | 224   | 83.7     | [convformer_s18_224_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/caformer/convformer_s18_224_imagenet21k-ft1k.h5) |\n  |                    | 27M    | 11.6G | 384   | 84.4     | [convformer_s18_384_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/caformer/convformer_s18_384_imagenet.h5) |\n  | - imagenet21k-ft1k | 27M    | 11.6G | 384   | 85.0     | [convformer_s36_384_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/caformer/convformer_s36_384_imagenet21k-ft1k.h5) |\n  | ConvFormerS36      | 40M    | 7.6G  | 224   | 84.1     | [convformer_s36_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/caformer/convformer_s36_224_imagenet.h5) |\n  | - imagenet21k-ft1k | 40M    | 7.6G  | 224   | 85.4     | [convformer_s36_224_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/caformer/convformer_s36_224_imagenet21k-ft1k.h5) |\n  |                    | 40M    | 22.4G | 384   | 85.4     | [convformer_s36_384_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/caformer/convformer_s36_384_imagenet.h5) |\n  | - imagenet21k-ft1k | 40M    | 22.4G | 384   | 86.4     | [convformer_s36_384_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/caformer/convformer_s36_384_imagenet21k-ft1k.h5) |\n  | ConvFormerM36      | 57M    | 12.8G | 224   | 84.5     | [convformer_m36_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/caformer/convformer_m36_224_imagenet.h5) |\n  | - imagenet21k-ft1k | 57M    | 12.8G | 224   | 86.1     | [convformer_m36_224_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/caformer/convformer_m36_224_imagenet21k-ft1k.h5) |\n  |                    | 57M    | 37.7G | 384   | 85.6     | [convformer_m36_384_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/caformer/convformer_m36_384_imagenet.h5) |\n  | - imagenet21k-ft1k | 57M    | 37.7G | 384   | 86.9     | [convformer_m36_384_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/caformer/convformer_m36_384_imagenet21k-ft1k.h5) |\n  | ConvFormerB36      | 100M   | 22.6G | 224   | 84.8     | [convformer_b36_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/caformer/convformer_b36_224_imagenet.h5) |\n  | - imagenet21k-ft1k | 100M   | 22.6G | 224   | 87.0     | [convformer_b36_224_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/caformer/convformer_b36_224_imagenet21k-ft1k.h5) |\n  |                    | 100M   | 66.5G | 384   | 85.7     | [convformer_b36_384_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/caformer/convformer_b36_384_imagenet.h5) |\n  | - imagenet21k-ft1k | 100M   | 66.5G | 384   | 87.6     | [convformer_b36_384_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/caformer/convformer_b36_384_imagenet21k-ft1k.h5) |\n## CMT\n  - [Keras CMT](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/cmt) is for [PDF 2107.06263 CMT: Convolutional Neural Networks Meet Vision Transformers](https://arxiv.org/pdf/2107.06263.pdf).\n\n  | Model                              | Params | FLOPs | Input | Top1 Acc | Download |\n  | ---------------------------------- | ------ | ----- | ----- | -------- | -------- |\n  | CMTTiny, (Self trained 105 epochs) | 9.5M   | 0.65G | 160   | 77.4     |          |\n  | - 305 epochs                       | 9.5M   | 0.65G | 160   | 78.94    | [cmt_tiny_160_imagenet](https://github.com/leondgarse/keras_cv_attention_models/releases/download/cmt/cmt_tiny_160_imagenet.h5) |\n  | - fine-tuned 224 (69 epochs)       | 9.5M   | 1.32G | 224   | 80.73    | [cmt_tiny_224_imagenet](https://github.com/leondgarse/keras_cv_attention_models/releases/download/cmt/cmt_tiny_224_imagenet.h5) |\n  | CMTTiny_torch, 1000 epochs         | 9.5M   | 0.65G | 160   | 79.2     | [cmt_tiny_torch_160](https://github.com/leondgarse/keras_cv_attention_models/releases/download/cmt/cmt_tiny_torch_160_imagenet.h5) |\n  | CMTXS_torch                        | 15.2M  | 1.58G | 192   | 81.8     | [cmt_xs_torch_192](https://github.com/leondgarse/keras_cv_attention_models/releases/download/cmt/cmt_xs_torch_192_imagenet.h5) |\n  | CMTSmall_torch                     | 25.1M  | 4.09G | 224   | 83.5     | [cmt_small_torch_224](https://github.com/leondgarse/keras_cv_attention_models/releases/download/cmt/cmt_small_torch_224_imagenet.h5) |\n  | CMTBase_torch                      | 45.7M  | 9.42G | 256   | 84.5     | [cmt_base_torch_256](https://github.com/leondgarse/keras_cv_attention_models/releases/download/cmt/cmt_base_torch_256_imagenet.h5) |\n## CoaT\n  - [Keras CoaT](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/coat) is for [PDF 2104.06399 CoaT: Co-Scale Conv-Attentional Image Transformers](http://arxiv.org/abs/2104.06399).\n\n  | Model         | Params | FLOPs | Input | Top1 Acc | Download |\n  | ------------- | ------ | ----- | ----- | -------- | -------- |\n  | CoaTLiteTiny  | 5.7M   | 1.60G | 224   | 77.5     | [coat_lite_tiny_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/coat/coat_lite_tiny_imagenet.h5) |\n  | CoaTLiteMini  | 11M    | 2.00G | 224   | 79.1     | [coat_lite_mini_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/coat/coat_lite_mini_imagenet.h5) |\n  | CoaTLiteSmall | 20M    | 3.97G | 224   | 81.9     | [coat_lite_small_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/coat/coat_lite_small_imagenet.h5) |\n  | CoaTTiny      | 5.5M   | 4.33G | 224   | 78.3     | [coat_tiny_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/coat/coat_tiny_imagenet.h5) |\n  | CoaTMini      | 10M    | 6.78G | 224   | 81.0     | [coat_mini_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/coat/coat_mini_imagenet.h5) |\n## CoAtNet\n  - [Keras CoAtNet](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/coatnet) is for [PDF 2106.04803 CoAtNet: Marrying Convolution and Attention for All Data Sizes](https://arxiv.org/pdf/2106.04803.pdf).\n\n  | Model                               | Params | FLOPs  | Input | Top1 Acc | Download |\n  | ----------------------------------- | ------ | ------ | ----- | -------- | -------- |\n  | CoAtNet0 (Self trained 105 epochs)  | 23.3M  | 2.09G  | 160   | 80.48    | [coatnet0_160_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/coatnet/coatnet0_160_imagenet.h5) |\n  | CoAtNet0 (Self trained 305 epochs)  | 23.8M  | 4.22G  | 224   | 82.79    | [coatnet0_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/coatnet/coatnet0_224_imagenet.h5) |\n  | CoAtNet0                            | 25M    | 4.2G   | 224   | 81.6     |          |\n  | CoAtNet0, Stride-2 DConv2D          | 25M    | 4.6G   | 224   | 82.0     |          |\n  | CoAtNet1                            | 42M    | 8.4G   | 224   | 83.3     |          |\n  | CoAtNet1, Stride-2 DConv2D          | 42M    | 8.8G   | 224   | 83.5     |          |\n  | CoAtNet2                            | 75M    | 15.7G  | 224   | 84.1     |          |\n  | CoAtNet2, Stride-2 DConv2D          | 75M    | 16.6G  | 224   | 84.1     |          |\n  | CoAtNet2, ImageNet-21k pretrain     | 75M    | 16.6G  | 224   | 87.1     |          |\n  | CoAtNet3                            | 168M   | 34.7G  | 224   | 84.5     |          |\n  | CoAtNet3, ImageNet-21k pretrain     | 168M   | 34.7G  | 224   | 87.6     |          |\n  | CoAtNet3, ImageNet-21k pretrain     | 168M   | 203.1G | 512   | 87.9     |          |\n  | CoAtNet4, ImageNet-21k pretrain     | 275M   | 360.9G | 512   | 88.1     |          |\n  | CoAtNet4, ImageNet-21K + PT-RA-E150 | 275M   | 360.9G | 512   | 88.56    |          |\n\n  **JFT pre-trained models accuracy**\n\n  | Model                      | Input | Reported Params    | self-defined Params    | Top1 Acc |\n  | -------------------------- | ----- | ------------------ | ---------------------- | -------- |\n  | CoAtNet3, Stride-2 DConv2D | 384   | 168M, FLOPs 114G   | 160.64M, FLOPs 109.67G | 88.52    |\n  | CoAtNet3, Stride-2 DConv2D | 512   | 168M, FLOPs 214G   | 161.24M, FLOPs 205.06G | 88.81    |\n  | CoAtNet4                   | 512   | 275M, FLOPs 361G   | 270.69M, FLOPs 359.77G | 89.11    |\n  | CoAtNet5                   | 512   | 688M, FLOPs 812G   | 676.23M, FLOPs 807.06G | 89.77    |\n  | CoAtNet6                   | 512   | 1.47B, FLOPs 1521G | 1.336B, FLOPs 1470.56G | 90.45    |\n  | CoAtNet7                   | 512   | 2.44B, FLOPs 2586G | 2.413B, FLOPs 2537.56G | 90.88    |\n## ConvNeXt\n  - [Keras ConvNeXt](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/convnext) is for [PDF 2201.03545 A ConvNet for the 2020s](https://arxiv.org/pdf/2201.03545.pdf).\n\n  | Model               | Params | FLOPs   | Input | Top1 Acc | Download |\n  | ------------------- | ------ | ------- | ----- | -------- | -------- |\n  | ConvNeXtTiny        | 28M    | 4.49G   | 224   | 82.1     | [tiny_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/convnext/convnext_tiny_imagenet.h5) |\n  | - ImageNet21k-ft1k  | 28M    | 4.49G   | 224   | 82.9     | [tiny_224_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/convnext/convnext_tiny_224_imagenet21k-ft1k.h5) |\n  | - ImageNet21k-ft1k  | 28M    | 13.19G  | 384   | 84.1     | [tiny_384_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/convnext/convnext_tiny_384_imagenet21k-ft1k.h5) |\n  | ConvNeXtSmall       | 50M    | 8.73G   | 224   | 83.1     | [small_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/convnext/convnext_small_imagenet.h5) |\n  | - ImageNet21k-ft1k  | 50M    | 8.73G   | 224   | 84.6     | [small_224_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/convnext/convnext_small_224_imagenet21k-ft1k.h5) |\n  | - ImageNet21k-ft1k  | 50M    | 25.67G  | 384   | 85.8     | [small_384_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/convnext/convnext_small_384_imagenet21k-ft1k.h5) |\n  | ConvNeXtBase        | 89M    | 15.42G  | 224   | 83.8     | [base_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/convnext/convnext_base_224_imagenet.h5) |\n  | ConvNeXtBase        | 89M    | 45.32G  | 384   | 85.1     | [base_384_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/convnext/convnext_base_384_imagenet.h5) |\n  | - ImageNet21k-ft1k  | 89M    | 15.42G  | 224   | 85.8     | [base_224_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/convnext/convnext_base_224_imagenet21k-ft1k.h5) |\n  | - ImageNet21k-ft1k  | 89M    | 45.32G  | 384   | 86.8     | [base_384_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/convnext/convnext_base_384_imagenet21k-ft1k.h5) |\n  | ConvNeXtLarge       | 198M   | 34.46G  | 224   | 84.3     | [large_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/convnext/convnext_large_224_imagenet.h5) |\n  | ConvNeXtLarge       | 198M   | 101.28G | 384   | 85.5     | [large_384_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/convnext/convnext_large_384_imagenet.h5) |\n  | - ImageNet21k-ft1k  | 198M   | 34.46G  | 224   | 86.6     | [large_224_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/convnext/convnext_large_224_imagenet21k-ft1k.h5) |\n  | - ImageNet21k-ft1k  | 198M   | 101.28G | 384   | 87.5     | [large_384_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/convnext/convnext_large_384_imagenet21k-ft1k.h5) |\n  | ConvNeXtXLarge, 21k | 350M   | 61.06G  | 224   | 87.0     | [xlarge_224_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/convnext/convnext_xlarge_224_imagenet21k-ft1k.h5) |\n  | ConvNeXtXLarge, 21k | 350M   | 179.43G | 384   | 87.8     | [xlarge_384_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/convnext/convnext_xlarge_384_imagenet21k-ft1k.h5) |\n## ConvNeXtV2\n  - [Keras ConvNeXt](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/convnext) includes implementation of [PDF 2301.00808 ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders](https://arxiv.org/pdf/2301.00808.pdf). **Please note the CC-BY-NC 4.0 license on theses weights, non-commercial use only**.\n\n  | Model              | Params | FLOPs  | Input | Top1 Acc | Download |\n  | ------------------ | ------ | ------ | ----- | -------- | -------- |\n  | ConvNeXtV2Atto     | 3.7M   | 0.55G  | 224   | 76.7     | [v2_atto_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/convnext/convnext_v2_atto_imagenet.h5) |\n  | ConvNeXtV2Femto    | 5.2M   | 0.78G  | 224   | 78.5     | [v2_femto_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/convnext/convnext_v2_femto_imagenet.h5) |\n  | ConvNeXtV2Pico     | 9.1M   | 1.37G  | 224   | 80.3     | [v2_pico_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/convnext/convnext_v2_pico_imagenet.h5) |\n  | ConvNeXtV2Nano     | 15.6M  | 2.45G  | 224   | 81.9     | [v2_nano_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/convnext/convnext_v2_nano_imagenet.h5) |\n  | - ImageNet21k-ft1k | 15.6M  | 2.45G  | 224   | 82.1     | [v2_nano_224_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/convnext/convnext_v2_nano_224_imagenet21k-ft1k.h5) |\n  | - ImageNet21k-ft1k | 15.6M  | 7.21G  | 384   | 83.4     | [v2_nano_384_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/convnext/convnext_v2_nano_384_imagenet21k-ft1k.h5) |\n  | ConvNeXtV2Tiny     | 28.6M  | 4.47G  | 224   | 83.0     | [v2_tiny_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/convnext/convnext_v2_tiny_imagenet.h5) |\n  | - ImageNet21k-ft1k | 28.6M  | 4.47G  | 224   | 83.9     | [v2_tiny_224_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/convnext/convnext_v2_tiny_224_imagenet21k-ft1k.h5) |\n  | - ImageNet21k-ft1k | 28.6M  | 13.1G  | 384   | 85.1     | [v2_tiny_384_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/convnext/convnext_v2_tiny_384_imagenet21k-ft1k.h5) |\n  | ConvNeXtV2Base     | 89M    | 15.4G  | 224   | 84.9     | [v2_base_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/convnext/convnext_v2_base_imagenet.h5) |\n  | - ImageNet21k-ft1k | 89M    | 15.4G  | 224   | 86.8     | [v2_base_224_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/convnext/convnext_v2_base_224_imagenet21k-ft1k.h5) |\n  | - ImageNet21k-ft1k | 89M    | 45.2G  | 384   | 87.7     | [v2_base_224_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/convnext/convnext_v2_base_384_imagenet21k-ft1k.h5) |\n  | ConvNeXtV2Large    | 198M   | 34.4G  | 224   | 85.8     | [v2_large_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/convnext/convnext_v2_large_imagenet.h5) |\n  | - ImageNet21k-ft1k | 198M   | 34.4G  | 224   | 87.3     | [v2_large_224_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/convnext/convnext_v2_large_224_imagenet21k-ft1k.h5) |\n  | - ImageNet21k-ft1k | 198M   | 101.1G | 384   | 88.2     | [v2_large_384_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/convnext/convnext_v2_large_384_imagenet21k-ft1k.h5) |\n  | ConvNeXtV2Huge     | 660M   | 115G   | 224   | 86.3     | [v2_huge_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/convnext/convnext_v2_huge_imagenet.h5) |\n  | - ImageNet21k-ft1k | 660M   | 337.9G | 384   | 88.7     | [v2_huge_384_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/convnext/convnext_v2_huge_384_imagenet21k-ft1k.h5) |\n  | - ImageNet21k-ft1k | 660M   | 600.8G | 512   | 88.9     | [v2_huge_512_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/convnext/convnext_v2_huge_512_imagenet21k-ft1k.h5) |\n## CoTNet\n  - [Keras CoTNet](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/cotnet) is for [PDF 2107.12292 Contextual Transformer Networks for Visual Recognition](https://arxiv.org/pdf/2107.12292.pdf).\n\n  | Model        | Params | FLOPs  | Input | Top1 Acc | Download            |\n  | ------------ |:------:| ------ | ----- |:--------:| ------------------- |\n  | CotNet50     | 22.2M  | 3.25G  | 224   |   81.3   | [cotnet50_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/cotnet/cotnet50_224_imagenet.h5) |\n  | CotNeXt50    | 30.1M  | 4.3G   | 224   |   82.1   |  |\n  | CotNetSE50D  | 23.1M  | 4.05G  | 224   |   81.6   | [cotnet_se50d_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/cotnet/cotnet_se50d_224_imagenet.h5) |\n  | CotNet101    | 38.3M  | 6.07G  | 224   |   82.8   | [cotnet101_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/cotnet/cotnet101_224_imagenet.h5) |\n  | CotNeXt101   | 53.4M  | 8.2G   | 224   |   83.2   |  |\n  | CotNetSE101D | 40.9M  | 8.44G  | 224   |   83.2   | [cotnet_se101d_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/cotnet/cotnet_se101d_224_imagenet.h5) |\n  | CotNetSE152D | 55.8M  | 12.22G | 224   |   84.0   | [cotnet_se152d_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/cotnet/cotnet_se152d_224_imagenet.h5) |\n  | CotNetSE152D | 55.8M  | 24.92G | 320   |   84.6   | [cotnet_se152d_320_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/cotnet/cotnet_se152d_320_imagenet.h5) |\n## DaViT\n  - [Keras DaViT](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/davit) is for [PDF 2204.03645 DaViT: Dual Attention Vision Transformers](https://arxiv.org/pdf/2204.03645.pdf).\n\n  | Model         | Params | FLOPs  | Input | Top1 Acc | Download |\n  | ------------- | ------ | ------ | ----- | -------- | -------- |\n  | DaViT_T       | 28.36M | 4.56G  | 224   | 82.8     | [davit_t_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/davit/davit_t_imagenet.h5) |\n  | DaViT_S       | 49.75M | 8.83G  | 224   | 84.2     | [davit_s_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/davit/davit_s_imagenet.h5) |\n  | DaViT_B       | 87.95M | 15.55G | 224   | 84.6     | [davit_b_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/davit/davit_b_imagenet.h5) |\n  | DaViT_L, 21k  | 196.8M | 103.2G | 384   | 87.5     |          |\n  | DaViT_H, 1.5B | 348.9M | 327.3G | 512   | 90.2     |          |\n  | DaViT_G, 1.5B | 1.406B | 1.022T | 512   | 90.4     |          |\n## EdgeNeXt\n  - [Keras EdgeNeXt](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/edgenext) is for [PDF 2206.10589 EdgeNeXt: Efficiently Amalgamated CNN-Transformer Architecture for Mobile Vision Applications](https://arxiv.org/pdf/2206.10589.pdf).\n\n  | Model             | Params | FLOPs  | Input | Top1 Acc | Download |\n  | ----------------- | ------ | ------ | ----- | -------- | -------- |\n  | EdgeNeXt_XX_Small | 1.33M  | 266M   | 256   | 71.23    | [edgenext_xx_small_256_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/edgenext/edgenext_xx_small_256_imagenet.h5) |\n  | EdgeNeXt_X_Small  | 2.34M  | 547M   | 256   | 74.96    | [edgenext_x_small_256_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/edgenext/edgenext_x_small_256_imagenet.h5) |\n  | EdgeNeXt_Small    | 5.59M  | 1.27G  | 256   | 79.41    | [edgenext_small_256_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/edgenext/edgenext_small_256_imagenet.h5) |\n  | - usi             | 5.59M  | 1.27G  | 256   | 81.07    | [edgenext_small_256_usi.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/edgenext/edgenext_small_256_usi.h5) |\n## EfficientFormer\n  - [Keras EfficientFormer](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/efficientformer) is for [PDF 2206.01191 EfficientFormer: Vision Transformers at MobileNet Speed](https://arxiv.org/pdf/2206.01191.pdf).\n\n  | Model                      | Params | FLOPs | Input | Top1 Acc | Download |\n  | -------------------------- | ------ | ----- | ----- | -------- | -------- |\n  | EfficientFormerL1, distill | 12.3M  | 1.31G | 224   | 79.2     | [l1_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/levit/efficientformer_l1_224_imagenet.h5) |\n  | EfficientFormerL3, distill | 31.4M  | 3.95G | 224   | 82.4     | [l3_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/levit/efficientformer_l3_224_imagenet.h5) |\n  | EfficientFormerL7, distill | 74.4M  | 9.79G | 224   | 83.3     | [l7_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/levit/efficientformer_l7_224_imagenet.h5) |\n## EfficientFormerV2\n  - [Keras EfficientFormer](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/efficientformer) includes implementation of [PDF 2212.08059 Rethinking Vision Transformers for MobileNet Size and Speed](https://arxiv.org/pdf/2212.08059.pdf).\n\n  | Model                        | Params | FLOPs  | Input | Top1 Acc | Download |\n  | ---------------------------- | ------ | ------ | ----- | -------- | -------- |\n  | EfficientFormerV2S0, distill | 3.60M  | 405.2M | 224   | 76.2     | [v2_s0_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/efficientformer/efficientformer_v2_s0_224_imagenet.h5) |\n  | EfficientFormerV2S1, distill | 6.19M  | 665.6M | 224   | 79.7     | [v2_s1_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/efficientformer/efficientformer_v2_s1_224_imagenet.h5) |\n  | EfficientFormerV2S2, distill | 12.7M  | 1.27G  | 224   | 82.0     | [v2_s2_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/efficientformer/efficientformer_v2_s2_224_imagenet.h5) |\n  | EfficientFormerV2L, distill  | 26.3M  | 2.59G  | 224   | 83.5     | [v2_l_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/efficientformer/efficientformer_v2_l_224_imagenet.h5) |\n## EfficientNet\n  - [Keras EfficientNet](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/efficientnet) includes implementation of [PDF 1911.04252 Self-training with Noisy Student improves ImageNet classification](https://arxiv.org/pdf/1911.04252.pdf).\n\n  | V1 Model                       | Params | FLOPs   | Input | Top1 Acc | Download |\n  | ------------------------------ | ------ | ------- | ----- | -------- | -------- |\n  | EfficientNetV1B0               | 5.3M   | 0.39G   | 224   | 77.6     | [effv1-b0-imagenet.h5](https://github.com/leondgarse/keras_efficientnet_v2/releases/download/effnetv1_pretrained/efficientnetv1-b0-imagenet.h5)           |\n  | - NoisyStudent                 | 5.3M   | 0.39G   | 224   | 78.8     | [effv1-b0-noisy_student.h5](https://github.com/leondgarse/keras_efficientnet_v2/releases/download/effnetv1_pretrained/efficientnetv1-b0-noisy_student.h5) |\n  | EfficientNetV1B1               | 7.8M   | 0.70G   | 240   | 79.6     | [effv1-b1-imagenet.h5](https://github.com/leondgarse/keras_efficientnet_v2/releases/download/effnetv1_pretrained/efficientnetv1-b1-imagenet.h5)           |\n  | - NoisyStudent                 | 7.8M   | 0.70G   | 240   | 81.5     | [effv1-b1-noisy_student.h5](https://github.com/leondgarse/keras_efficientnet_v2/releases/download/effnetv1_pretrained/efficientnetv1-b1-noisy_student.h5) |\n  | EfficientNetV1B2               | 9.1M   | 1.01G   | 260   | 80.5     | [effv1-b2-imagenet.h5](https://github.com/leondgarse/keras_efficientnet_v2/releases/download/effnetv1_pretrained/efficientnetv1-b2-imagenet.h5)           |\n  | - NoisyStudent                 | 9.1M   | 1.01G   | 260   | 82.4     | [effv1-b2-noisy_student.h5](https://github.com/leondgarse/keras_efficientnet_v2/releases/download/effnetv1_pretrained/efficientnetv1-b2-noisy_student.h5) |\n  | EfficientNetV1B3               | 12.2M  | 1.86G   | 300   | 81.9     | [effv1-b3-imagenet.h5](https://github.com/leondgarse/keras_efficientnet_v2/releases/download/effnetv1_pretrained/efficientnetv1-b3-imagenet.h5)           |\n  | - NoisyStudent                 | 12.2M  | 1.86G   | 300   | 84.1     | [effv1-b3-noisy_student.h5](https://github.com/leondgarse/keras_efficientnet_v2/releases/download/effnetv1_pretrained/efficientnetv1-b3-noisy_student.h5) |\n  | EfficientNetV1B4               | 19.3M  | 4.46G   | 380   | 83.3     | [effv1-b4-imagenet.h5](https://github.com/leondgarse/keras_efficientnet_v2/releases/download/effnetv1_pretrained/efficientnetv1-b4-imagenet.h5)           |\n  | - NoisyStudent                 | 19.3M  | 4.46G   | 380   | 85.3     | [effv1-b4-noisy_student.h5](https://github.com/leondgarse/keras_efficientnet_v2/releases/download/effnetv1_pretrained/efficientnetv1-b4-noisy_student.h5) |\n  | EfficientNetV1B5               | 30.4M  | 10.40G  | 456   | 84.3     | [effv1-b5-imagenet.h5](https://github.com/leondgarse/keras_efficientnet_v2/releases/download/effnetv1_pretrained/efficientnetv1-b5-imagenet.h5)           |\n  | - NoisyStudent                 | 30.4M  | 10.40G  | 456   | 86.1     | [effv1-b5-noisy_student.h5](https://github.com/leondgarse/keras_efficientnet_v2/releases/download/effnetv1_pretrained/efficientnetv1-b5-noisy_student.h5) |\n  | EfficientNetV1B6               | 43.0M  | 19.29G  | 528   | 84.8     | [effv1-b6-imagenet.h5](https://github.com/leondgarse/keras_efficientnet_v2/releases/download/effnetv1_pretrained/efficientnetv1-b6-imagenet.h5)           |\n  | - NoisyStudent                 | 43.0M  | 19.29G  | 528   | 86.4     | [effv1-b6-noisy_student.h5](https://github.com/leondgarse/keras_efficientnet_v2/releases/download/effnetv1_pretrained/efficientnetv1-b6-noisy_student.h5) |\n  | EfficientNetV1B7               | 66.3M  | 38.13G  | 600   | 85.2     | [effv1-b7-imagenet.h5](https://github.com/leondgarse/keras_efficientnet_v2/releases/download/effnetv1_pretrained/efficientnetv1-b7-imagenet.h5)           |\n  | - NoisyStudent                 | 66.3M  | 38.13G  | 600   | 86.9     | [effv1-b7-noisy_student.h5](https://github.com/leondgarse/keras_efficientnet_v2/releases/download/effnetv1_pretrained/efficientnetv1-b7-noisy_student.h5) |\n  | EfficientNetV1L2, NoisyStudent | 480.3M | 477.98G | 800   | 88.4     | [effv1-l2-noisy_student.h5](https://github.com/leondgarse/keras_efficientnet_v2/releases/download/effnetv1_pretrained/efficientnetv1-l2-noisy_student.h5) |\n## EfficientNetV2\n  - [Keras EfficientNet](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/efficientnet) includes implementation of [PDF 2104.00298 EfficientNetV2: Smaller Models and Faster Training](https://arxiv.org/abs/2104.00298).\n\n  | V2 Model                   | Params | FLOPs  | Input | Top1 Acc | Download |\n  | -------------------------- | ------ | ------ | ----- | -------- | -------- |\n  | EfficientNetV2B0           | 7.1M   | 0.72G  | 224   | 78.7     | [effv2b0-imagenet.h5](https://github.com/leondgarse/keras_efficientnet_v2/releases/download/effnetv2_pretrained/efficientnetv2-b0-imagenet.h5) |\n  | - ImageNet21k-ft1k         | 7.1M   | 0.72G  | 224   | 77.55?   | [effv2b0-21k-ft1k.h5](https://github.com/leondgarse/keras_efficientnet_v2/releases/download/effnetv2_pretrained/efficientnetv2-b0-21k-ft1k.h5) |\n  | EfficientNetV2B1           | 8.1M   | 1.21G  | 240   | 79.8     | [effv2b1-imagenet.h5](https://github.com/leondgarse/keras_efficientnet_v2/releases/download/effnetv2_pretrained/efficientnetv2-b1-imagenet.h5) |\n  | - ImageNet21k-ft1k         | 8.1M   | 1.21G  | 240   | 79.03?   | [effv2b1-21k-ft1k.h5](https://github.com/leondgarse/keras_efficientnet_v2/releases/download/effnetv2_pretrained/efficientnetv2-b1-21k-ft1k.h5) |\n  | EfficientNetV2B2           | 10.1M  | 1.71G  | 260   | 80.5     | [effv2b2-imagenet.h5](https://github.com/leondgarse/keras_efficientnet_v2/releases/download/effnetv2_pretrained/efficientnetv2-b2-imagenet.h5) |\n  | - ImageNet21k-ft1k         | 10.1M  | 1.71G  | 260   | 79.48?   | [effv2b2-21k-ft1k.h5](https://github.com/leondgarse/keras_efficientnet_v2/releases/download/effnetv2_pretrained/efficientnetv2-b2-21k-ft1k.h5) |\n  | EfficientNetV2B3           | 14.4M  | 3.03G  | 300   | 82.1     | [effv2b3-imagenet.h5](https://github.com/leondgarse/keras_efficientnet_v2/releases/download/effnetv2_pretrained/efficientnetv2-b3-imagenet.h5) |\n  | - ImageNet21k-ft1k         | 14.4M  | 3.03G  | 300   | 82.46?   | [effv2b3-21k-ft1k.h5](https://github.com/leondgarse/keras_efficientnet_v2/releases/download/effnetv2_pretrained/efficientnetv2-b3-21k-ft1k.h5) |\n  | EfficientNetV2T            | 13.6M  | 3.18G  | 288   | 82.34    | [effv2t-imagenet.h5](https://github.com/leondgarse/keras_efficientnet_v2/releases/download/effnetv2_pretrained/efficientnetv2-t-imagenet.h5)   |\n  | EfficientNetV2T_GC         | 13.7M  | 3.19G  | 288   | 82.46    | [effv2t-gc-imagenet.h5](https://github.com/leondgarse/keras_efficientnet_v2/releases/download/effnetv2_pretrained/efficientnetv2-t-gc-imagenet.h5)   |\n  | EfficientNetV2S            | 21.5M  | 8.41G  | 384   | 83.9     | [effv2s-imagenet.h5](https://github.com/leondgarse/keras_efficientnet_v2/releases/download/effnetv2_pretrained/efficientnetv2-s-imagenet.h5)   |\n  | - ImageNet21k-ft1k         | 21.5M  | 8.41G  | 384   | 84.9     | [effv2s-21k-ft1k.h5](https://github.com/leondgarse/keras_efficientnet_v2/releases/download/effnetv2_pretrained/efficientnetv2-s-21k-ft1k.h5)   |\n  | EfficientNetV2M            | 54.1M  | 24.69G | 480   | 85.2     | [effv2m-imagenet.h5](https://github.com/leondgarse/keras_efficientnet_v2/releases/download/effnetv2_pretrained/efficientnetv2-m-imagenet.h5)   |\n  | - ImageNet21k-ft1k         | 54.1M  | 24.69G | 480   | 86.2     | [effv2m-21k-ft1k.h5](https://github.com/leondgarse/keras_efficientnet_v2/releases/download/effnetv2_pretrained/efficientnetv2-m-21k-ft1k.h5)   |\n  | EfficientNetV2L            | 119.5M | 56.27G | 480   | 85.7     | [effv2l-imagenet.h5](https://github.com/leondgarse/keras_efficientnet_v2/releases/download/effnetv2_pretrained/efficientnetv2-l-imagenet.h5)   |\n  | - ImageNet21k-ft1k         | 119.5M | 56.27G | 480   | 86.9     | [effv2l-21k-ft1k.h5](https://github.com/leondgarse/keras_efficientnet_v2/releases/download/effnetv2_pretrained/efficientnetv2-l-21k-ft1k.h5)   |\n  | EfficientNetV2XL, 21k-ft1k | 206.8M | 93.66G | 512   | 87.2     | [effv2xl-21k-ft1k.h5](https://github.com/leondgarse/keras_efficientnet_v2/releases/download/effnetv2_pretrained/efficientnetv2-xl-21k-ft1k.h5) |\n## EVA\n  - [Keras EVA](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/beit) includes models from [PDF 2211.07636 EVA: Exploring the Limits of Masked Visual Representation Learning at Scale](https://arxiv.org/pdf/2211.07636.pdf).\n\n  | Model                 | Params  | FLOPs    | Input | Top1 Acc | Download |\n  | --------------------- | ------- | -------- | ----- | -------- | -------- |\n  | EvaLargePatch14, 22k  | 304.14M | 61.65G   | 196   | 88.59    | [eva_large_patch14_196.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/beit/eva_large_patch14_196_imagenet21k-ft1k.h5) |\n  |                       | 304.53M | 191.55G  | 336   | 89.20    | [eva_large_patch14_336.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/beit/eva_large_patch14_336_imagenet21k-ft1k.h5) |\n  | EvaGiantPatch14, clip | 1012.6M | 267.40G  | 224   | 89.10    | [eva_giant_patch14_224.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/beit/eva_giant_patch14_224_imagenet21k-ft1k.h5) |\n  | - m30m                | 1013.0M | 621.45G  | 336   | 89.57    | [eva_giant_patch14_336.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/beit/eva_giant_patch14_336_imagenet21k-ft1k.h5) |\n  | - m30m                | 1014.4M | 1911.61G | 560   | 89.80    | [eva_giant_patch14_560.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/beit/eva_giant_patch14_560_imagenet21k-ft1k.h5) |\n## FasterNet\n  - [Keras FasterNet](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/fasternet) includes implementation of [PDF 2303.03667 Run, Dont Walk: Chasing Higher FLOPS for Faster Neural Networks ](https://arxiv.org/pdf/2303.03667.pdf).\n\n  | Model       | Params | FLOPs  | Input | Top1 Acc | Download |\n  | ----------- | ------ | ------ | ----- | -------- | -------- |\n  | FasterNetT0 | 3.9M   | 0.34G  | 224   | 71.9     | [fasternet_t0_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/fasternet/fasternet_t0_imagenet.h5) |\n  | FasterNetT1 | 7.6M   | 0.85G  | 224   | 76.2     | [fasternet_t1_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/fasternet/fasternet_t1_imagenet.h5) |\n  | FasterNetT2 | 15.0M  | 1.90G  | 224   | 78.9     | [fasternet_t2_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/fasternet/fasternet_t2_imagenet.h5) |\n  | FasterNetS  | 31.1M  | 4.55G  | 224   | 81.3     | [fasternet_s_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/fasternet/fasternet_s_imagenet.h5)   |\n  | FasterNetM  | 53.5M  | 8.72G  | 224   | 83.0     | [fasternet_m_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/fasternet/fasternet_m_imagenet.h5)   |\n  | FasterNetL  | 93.4M  | 15.49G | 224   | 83.5     | [fasternet_l_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/fasternet/fasternet_l_imagenet.h5)   |\n## FBNetV3\n  - [Keras FBNetV3](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/mobilenetv3_family#fbnetv3) includes implementation of [PDF 2006.02049 FBNetV3: Joint Architecture-Recipe Search using Predictor Pretraining](https://arxiv.org/pdf/2006.02049.pdf).\n\n  | Model    | Params | FLOPs    | Input | Top1 Acc | Download |\n  | -------- | ------ | -------- | ----- | -------- | -------- |\n  | FBNetV3B | 5.57M  | 539.82M  | 256   | 79.15    | [fbnetv3_b_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mobilenetv3_family/fbnetv3_b_imagenet.h5) |\n  | FBNetV3D | 10.31M | 665.02M  | 256   | 79.68    | [fbnetv3_d_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mobilenetv3_family/fbnetv3_d_imagenet.h5) |\n  | FBNetV3G | 16.62M | 1379.30M | 256   | 82.05    | [fbnetv3_g_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mobilenetv3_family/fbnetv3_g_imagenet.h5) |\n## FlexiViT\n  - [Keras FlexiViT](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/beit) includes models from [PDF 2212.08013 FlexiViT: One Model for All Patch Sizes](https://arxiv.org/pdf/2212.08013.pdf).\n\n  | Model         | Params  | FLOPs  | Input | Top1 Acc | Download |\n  | ------------- | ------- | ------ | ----- | -------- | -------- |\n  | FlexiViTSmall | 22.06M  | 5.36G  | 240   | 82.53    | [flexivit_small_240.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/beit/flexivit_small_240_imagenet.h5) |\n  | FlexiViTBase  | 86.59M  | 20.33G | 240   | 84.66    | [flexivit_base_240.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/beit/flexivit_base_240_imagenet.h5) |\n  | FlexiViTLarge | 304.47M | 71.09G | 240   | 85.64    | [flexivit_large_240.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/beit/flexivit_large_240_imagenet.h5) |\n## GCViT\n  - [Keras GCViT](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/gcvit) includes implementation of [PDF 2206.09959 Global Context Vision Transformers](https://arxiv.org/pdf/2206.09959.pdf).\n\n  | Model        | Params | FLOPs | Input | Top1 Acc | Download |\n  | ------------ | ------ | ----- | ----- | -------- | -------- |\n  | GCViT_XXTiny | 12.0M  | 2.15G | 224   | 79.8     | [gcvit_xx_tiny_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/gcvit/gcvit_xx_tiny_224_imagenet.h5) |\n  | GCViT_XTiny  | 20.0M  | 2.96G | 224   | 82.04    | [gcvit_x_tiny_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/gcvit/gcvit_x_tiny_224_imagenet.h5) |\n  | GCViT_Tiny   | 28.2M  | 4.83G | 224   | 83.4     | [gcvit_tiny_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/gcvit/gcvit_tiny_224_imagenet.h5) |\n  | GCViT_Small  | 51.1M  | 8.63G | 224   | 83.95    | [gcvit_small_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/gcvit/gcvit_small_224_imagenet.h5) |\n  | GCViT_Base   | 90.3M  | 14.9G | 224   | 84.47    | [gcvit_base_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/gcvit/gcvit_base_224_imagenet.h5) |\n## GhostNet\n  - [Keras GhostNet](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/ghostnet) includes implementation of [PDF 1911.11907 GhostNet: More Features from Cheap Operations](https://arxiv.org/pdf/1911.11907.pdf).\n\n  | Model        | Params | FLOPs  | Input | Top1 Acc | Download |\n  | ------------ | ------ | ------ | ----- | -------- | -------- |\n  | GhostNet_050 | 2.59M  | 42.6M  | 224   | 66.88    | [ghostnet_050_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/ghostnetv2/ghostnet_050_imagenet.h5) |\n  | GhostNet_100 | 5.18M  | 141.7M | 224   | 74.16    | [ghostnet_100_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/ghostnetv2/ghostnet_100_imagenet.h5) |\n  | GhostNet_130 | 7.36M  | 227.7M | 224   | 75.79    | [ghostnet_130_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/ghostnetv2/ghostnet_130_imagenet.h5) |\n  | - ssld       | 7.36M  | 227.7M | 224   | 79.38    | [ghostnet_130_ssld.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/ghostnetv2/ghostnet_130_ssld.h5) |\n## GhostNetV2\n  - [Keras GhostNet](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/ghostnet) includes implementation of [PDF GhostNetV2: Enhance Cheap Operation with Long-Range Attention](https://openreview.net/pdf/6db544c65bbd0fa7d7349508454a433c112470e2.pdf).\n\n  | Model             | Params | FLOPs  | Input | Top1 Acc | Download |\n  | ----------------- | ------ | ------ | ----- | -------- | -------- |\n  | GhostNetV2_100    | 6.12M  | 168.5M | 224   | 74.41    | [ghostnetv2_100_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/ghostnetv2/ghostnetv2_100_imagenet.h5) |\n  | GhostNetV2 (1.0x) | 6.12M  | 168.5M | 224   | 75.3     |          |\n  | GhostNetV2 (1.3x) | 8.96M  | 271.1M | 224   | 76.9     |          |\n  | GhostNetV2 (1.6x) | 12.39M | 400.9M | 224   | 77.8     |          |\n## GMLP\n  - [Keras GMLP](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/mlp_family#gmlp) includes implementation of [PDF 2105.08050 Pay Attention to MLPs](https://arxiv.org/pdf/2105.08050.pdf).\n\n  | Model      | Params | FLOPs  | Input | Top1 Acc | Download |\n  | ---------- | ------ | ------ | ----- | -------- | -------- |\n  | GMLPTiny16 | 6M     | 1.35G  | 224   | 72.3     |          |\n  | GMLPS16    | 20M    | 4.44G  | 224   | 79.6     | [gmlp_s16_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mlp_family/gmlp_s16_imagenet.h5) |\n  | GMLPB16    | 73M    | 15.82G | 224   | 81.6     |          |\n## GPViT\n  - [Keras GPViT](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/gpvit) includes implementation of [PDF 2212.06795 GPVIT: A HIGH RESOLUTION NON-HIERARCHICAL VISION TRANSFORMER WITH GROUP PROPAGATION](https://arxiv.org/pdf/2212.06795.pdf).\n\n  | Model    | Params | FLOPs  | Input | Top1 Acc | Download |\n  | -------- | ------ | ------ | ----- | -------- | -------- |\n  | GPViT_L1 | 9.59M  | 6.15G  | 224   | 80.5     | [gpvit_l1_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/gpvit/gpvit_l1_224_imagenet.h5) |\n  | GPViT_L2 | 24.2M  | 15.74G | 224   | 83.4     | [gpvit_l2_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/gpvit/gpvit_l2_224_imagenet.h5) |\n  | GPViT_L3 | 36.7M  | 23.54G | 224   | 84.1     | [gpvit_l3_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/gpvit/gpvit_l3_224_imagenet.h5) |\n  | GPViT_L4 | 75.5M  | 48.29G | 224   | 84.3     | [gpvit_l4_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/gpvit/gpvit_l4_224_imagenet.h5) |\n## HaloNet\n  - [Keras HaloNet](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/halonet) is for [PDF 2103.12731 Scaling Local Self-Attention for Parameter Efficient Visual Backbones](https://arxiv.org/pdf/2103.12731.pdf).\n\n  | Model          | Params | FLOPs   | Input | Top1 Acc | Download |\n  | -------------- | ------ | ------- | ----- | -------- | -------- |\n  | HaloNetH0      | 5.5M   | 2.40G   | 256   | 77.9     |          |\n  | HaloNetH1      | 8.1M   | 3.04G   | 256   | 79.9     |          |\n  | HaloNetH2      | 9.4M   | 3.37G   | 256   | 80.4     |          |\n  | HaloNetH3      | 11.8M  | 6.30G   | 320   | 81.9     |          |\n  | HaloNetH4      | 19.1M  | 12.17G  | 384   | 83.3     |          |\n  | - 21k          | 19.1M  | 12.17G  | 384   | 85.5     |          |\n  | HaloNetH5      | 30.7M  | 32.61G  | 448   | 84.0     |          |\n  | HaloNetH6      | 43.4M  | 53.20G  | 512   | 84.4     |          |\n  | HaloNetH7      | 67.4M  | 119.64G | 600   | 84.9     |          |\n  | HaloNextECA26T | 10.7M  | 2.43G   | 256   | 79.50    | [halonext_eca26t_256_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/halonet/halonext_eca26t_256_imagenet.h5) |\n  | HaloNet26T     | 12.5M  | 3.18G   | 256   | 79.13    | [halonet26t_256_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/halonet/halonet26t_256_imagenet.h5) |\n  | HaloNetSE33T   | 13.7M  | 3.55G   | 256   | 80.99    | [halonet_se33t_256_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/halonet/halonet_se33t_256_imagenet.h5) |\n  | HaloRegNetZB   | 11.68M | 1.97G   | 224   | 81.042   | [haloregnetz_b_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/halonet/haloregnetz_b_224_imagenet.h5) |\n  | HaloNet50T     | 22.7M  | 5.29G   | 256   | 81.70    | [halonet50t_256_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/halonet/halonet50t_256_imagenet.h5) |\n  | HaloBotNet50T  | 22.6M  | 5.02G   | 256   | 82.0     | [halobotnet50t_256_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/halonet/halobotnet50t_256_imagenet.h5) |\n## HorNet\n  - [Keras HorNet](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/hornet) is for [PDF 2207.14284 HorNet: Efficient High-Order Spatial Interactions with Recursive Gated Convolutions](https://arxiv.org/pdf/2207.14284.pdf).\n\n  | Model         | Params | FLOPs  | Input | Top1 Acc | Download |\n  | ------------- | ------ | ------ | ----- | -------- | -------- |\n  | HorNetTiny    | 22.4M  | 4.01G  | 224   | 82.8     | [hornet_tiny_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/hornet/hornet_tiny_224_imagenet.h5) |\n  | HorNetTinyGF  | 23.0M  | 3.94G  | 224   | 83.0     | [hornet_tiny_gf_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/hornet/hornet_tiny_gf_224_imagenet.h5) |\n  | HorNetSmall   | 49.5M  | 8.87G  | 224   | 83.8     | [hornet_small_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/hornet/hornet_small_224_imagenet.h5) |\n  | HorNetSmallGF | 50.4M  | 8.77G  | 224   | 84.0     | [hornet_small_gf_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/hornet/hornet_small_gf_224_imagenet.h5) |\n  | HorNetBase    | 87.3M  | 15.65G | 224   | 84.2     | [hornet_base_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/hornet/hornet_base_224_imagenet.h5) |\n  | HorNetBaseGF  | 88.4M  | 15.51G | 224   | 84.3     | [hornet_base_gf_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/hornet/hornet_base_gf_224_imagenet.h5) |\n  | HorNetLarge   | 194.5M | 34.91G | 224   | 86.8     | [hornet_large_224_imagenet22k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/hornet/hornet_large_224_imagenet22k.h5) |\n  | HorNetLargeGF | 196.3M | 34.72G | 224   | 87.0     | [hornet_large_gf_224_imagenet22k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/hornet/hornet_large_gf_224_imagenet22k.h5) |\n  | HorNetLargeGF | 201.8M | 102.0G | 384   | 87.7     | [hornet_large_gf_384_imagenet22k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/hornet/hornet_large_gf_384_imagenet22k.h5) |\n## IFormer\n  - [Keras IFormer](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/iformer) is for [PDF 2205.12956 Inception Transformer](https://arxiv.org/pdf/2205.12956.pdf).\n\n  | Model        | Params | FLOPs  | Input | Top1 Acc | Download |\n  | ------------ | ------ | ------ | ----- | -------- | -------- |\n  | IFormerSmall | 19.9M  | 4.88G  | 224   | 83.4     | [iformer_small_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/iformer/iformer_small_224_imagenet.h5) |\n  |              | 20.9M  | 16.29G | 384   | 84.6     | [iformer_small_384_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/iformer/iformer_small_384_imagenet.h5) |\n  | IFormerBase  | 47.9M  | 9.44G  | 224   | 84.6     | [iformer_base_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/iformer/iformer_base_224_imagenet.h5) |\n  |              | 48.9M  | 30.86G | 384   | 85.7     | [iformer_base_384_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/iformer/iformer_base_384_imagenet.h5) |\n  | IFormerLarge | 86.6M  | 14.12G | 224   | 84.6     | [iformer_large_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/iformer/iformer_largel_224_imagenet.h5) |\n  |              | 87.7M  | 45.74G | 384   | 85.8     | [iformer_large_384_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/iformer/iformer_largel_384_imagenet.h5) |\n## LCNet\n  - [Keras LCNet](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/mobilenetv3_family#lcnet) includes implementation of [PDF 2109.15099 PP-LCNet: A Lightweight CPU Convolutional Neural Network](https://arxiv.org/pdf/2109.15099.pdf).\n\n  | Model    | Params | FLOPs   | Input | Top1 Acc | Download |\n  | -------- | ------ | ------- | ----- | -------- | -------- |\n  | LCNet050 | 1.88M  | 46.02M  | 224   | 63.10    | [lcnet_050_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mobilenetv3_family/lcnet_050_imagenet.h5) |\n  | - ssld   | 1.88M  | 46.02M  | 224   | 66.10    | [lcnet_050_ssld.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mobilenetv3_family/lcnet_050_ssld.h5) |\n  | LCNet075 | 2.36M  | 96.82M  | 224   | 68.82    | [lcnet_075_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mobilenetv3_family/lcnet_075_imagenet.h5) |\n  | LCNet100 | 2.95M  | 158.28M | 224   | 72.10    | [lcnet_100_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mobilenetv3_family/lcnet_100_imagenet.h5) |\n  | - ssld   | 2.95M  | 158.28M | 224   | 74.39    | [lcnet_100_ssld.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mobilenetv3_family/lcnet_100_ssld.h5) |\n  | LCNet150 | 4.52M  | 338.05M | 224   | 73.71    | [lcnet_150_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mobilenetv3_family/lcnet_150_imagenet.h5) |\n  | LCNet200 | 6.54M  | 585.35M | 224   | 75.18    | [lcnet_200_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mobilenetv3_family/lcnet_200_imagenet.h5) |\n  | LCNet250 | 9.04M  | 900.16M | 224   | 76.60    | [lcnet_250_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mobilenetv3_family/lcnet_250_imagenet.h5) |\n  | - ssld   | 9.04M  | 900.16M | 224   | 80.82    | [lcnet_250_ssld.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mobilenetv3_family/lcnet_250_ssld.h5) |\n## LeViT\n  - [Keras LeViT](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/levit) is for [PDF 2104.01136 LeViT: a Vision Transformer in ConvNets Clothing for Faster Inference](https://arxiv.org/pdf/2104.01136.pdf).\n\n  | Model                   | Params | FLOPs | Input | Top1 Acc | Download |\n  | ----------------------- | ------ | ----- | ----- | -------- | -------- |\n  | LeViT128S, distillation | 7.8M   | 0.31G | 224   | 76.6     | [levit128s_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/levit/levit128s_imagenet.h5) |\n  | LeViT128, distillation  | 9.2M   | 0.41G | 224   | 78.6     | [levit128_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/levit/levit128_imagenet.h5) |\n  | LeViT192, distillation  | 11M    | 0.66G | 224   | 80.0     | [levit192_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/levit/levit192_imagenet.h5) |\n  | LeViT256, distillation  | 19M    | 1.13G | 224   | 81.6     | [levit256_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/levit/levit256_imagenet.h5) |\n  | LeViT384, distillation  | 39M    | 2.36G | 224   | 82.6     | [levit384_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/levit/levit384_imagenet.h5) |\n## MaxViT\n  - [Keras MaxViT](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/maxvit) is for [PDF 2204.01697 MaxViT: Multi-Axis Vision Transformer](https://arxiv.org/pdf/2204.01697.pdf).\n\n  | Model                           | Params | FLOPs  | Input | Top1 Acc | Download |\n  | ------------------------------- | ------ | ------ | ----- | -------- | -------- |\n  | MaxViT_Tiny                     | 31M    | 5.6G   | 224   | 83.62    | [tiny_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/maxvit/maxvit_tiny_224_imagenet.h5) |\n  | MaxViT_Tiny                     | 31M    | 17.7G  | 384   | 85.24    | [tiny_384_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/maxvit/maxvit_tiny_384_imagenet.h5) |\n  | MaxViT_Tiny                     | 31M    | 33.7G  | 512   | 85.72    | [tiny_512_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/maxvit/maxvit_tiny_512_imagenet.h5) |\n  | MaxViT_Small                    | 69M    | 11.7G  | 224   | 84.45    | [small_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/maxvit/maxvit_small_224_imagenet.h5) |\n  | MaxViT_Small                    | 69M    | 36.1G  | 384   | 85.74    | [small_384_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/maxvit/maxvit_small_384_imagenet.h5) |\n  | MaxViT_Small                    | 69M    | 67.6G  | 512   | 86.19    | [small_512_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/maxvit/maxvit_small_512_imagenet.h5) |\n  | MaxViT_Base                     | 119M   | 24.2G  | 224   | 84.95    | [base_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/maxvit/maxvit_base_224_imagenet.h5) |\n  | - imagenet21k                   | 135M   | 24.2G  | 224   |          | [base_224_imagenet21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/maxvit/maxvit_base_224_imagenet21k.h5) |\n  | MaxViT_Base                     | 119M   | 74.2G  | 384   | 86.34    | [base_384_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/maxvit/maxvit_base_384_imagenet.h5) |\n  | - imagenet21k-ft1k              | 119M   | 74.2G  | 384   | 88.24    | [base_384_21k-ft1k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/maxvit/maxvit_base_384_imagenet21k-ft1k.h5) |\n  | MaxViT_Base                     | 119M   | 138.5G | 512   | 86.66    | [base_512_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/maxvit/maxvit_base_512_imagenet.h5) |\n  | - imagenet21k-ft1k              | 119M   | 138.5G | 512   | 88.38    | [base_512_21k-ft1k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/maxvit/maxvit_base_512_imagenet21k-ft1k.h5) |\n  | MaxViT_Large                    | 212M   | 43.9G  | 224   | 85.17    | [large_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/maxvit/maxvit_large_224_imagenet.h5) |\n  | - imagenet21k                   | 233M   | 43.9G  | 224   |          | [large_224_imagenet21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/maxvit/maxvit_large_224_imagenet21k.h5) |\n  | MaxViT_Large                    | 212M   | 133.1G | 384   | 86.40    | [large_384_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/maxvit/maxvit_large_384_imagenet.h5) |\n  | - imagenet21k-ft1k              | 212M   | 133.1G | 384   | 88.32    | [large_384_21k-ft1k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/maxvit/maxvit_large_384_imagenet21k-ft1k.h5) |\n  | MaxViT_Large                    | 212M   | 245.4G | 512   | 86.70    | [large_512_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/maxvit/maxvit_large_512_imagenet.h5) |\n  | - imagenet21k-ft1k              | 212M   | 245.4G | 512   | 88.46    | [large_512_21k-ft1k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/maxvit/maxvit_large_512_imagenet21k-ft1k.h5) |\n  | MaxViT_XLarge, imagenet21k      | 507M   | 97.7G  | 224   |          | [xlarge_224_imagenet21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/maxvit/maxvit_xlarge_224_imagenet21k.h5) |\n  | MaxViT_XLarge, imagenet21k-ft1k | 475M   | 293.7G | 384   | 88.51    | [xlarge_384_21k-ft1k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/maxvit/maxvit_xlarge_384_imagenet21k-ft1k.h5) |\n  | MaxViT_XLarge, imagenet21k-ft1k | 475M   | 535.2G | 512   | 88.70    | [xlarge_512_21k-ft1k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/maxvit/maxvit_xlarge_512_imagenet21k-ft1k.h5) |\n## MLP mixer\n  - [Keras MLP mixer](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/mlp_family#mlp-mixer) includes implementation of [PDF 2105.01601 MLP-Mixer: An all-MLP Architecture for Vision](https://arxiv.org/pdf/2105.01601.pdf).\n\n  | Model            | Params | FLOPs   | Input | Top1 Acc | Download |\n  | ---------------- | ------ | ------- | ----- | -------- | -------- |\n  | MLPMixerS32, JFT | 19.1M  | 1.01G   | 224   | 68.70    |          |\n  | MLPMixerS16, JFT | 18.5M  | 3.79G   | 224   | 73.83    |          |\n  | MLPMixerB32, JFT | 60.3M  | 3.25G   | 224   | 75.53    |          |\n  | - imagenet_sam   | 60.3M  | 3.25G   | 224   | 72.47    | [b32_imagenet_sam.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mlp_family/mlp_mixer_b32_imagenet_sam.h5) |\n  | MLPMixerB16      | 59.9M  | 12.64G  | 224   | 76.44    | [b16_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mlp_family/mlp_mixer_b16_imagenet.h5) |\n  | - imagenet21k    | 59.9M  | 12.64G  | 224   | 80.64    | [b16_imagenet21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mlp_family/mlp_mixer_b16_imagenet21k.h5) |\n  | - imagenet_sam   | 59.9M  | 12.64G  | 224   | 77.36    | [b16_imagenet_sam.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mlp_family/mlp_mixer_b16_imagenet_sam.h5) |\n  | - JFT            | 59.9M  | 12.64G  | 224   | 80.00    |          |\n  | MLPMixerL32, JFT | 206.9M | 11.30G  | 224   | 80.67    |          |\n  | MLPMixerL16      | 208.2M | 44.66G  | 224   | 71.76    | [l16_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mlp_family/mlp_mixer_l16_imagenet.h5) |\n  | - imagenet21k    | 208.2M | 44.66G  | 224   | 82.89    | [l16_imagenet21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mlp_family/mlp_mixer_l16_imagenet21k.h5) |\n  | - input 448      | 208.2M | 178.54G | 448   | 83.91    |          |\n  | - input 224, JFT | 208.2M | 44.66G  | 224   | 84.82    |          |\n  | - input 448, JFT | 208.2M | 178.54G | 448   | 86.78    |          |\n  | MLPMixerH14, JFT | 432.3M | 121.22G | 224   | 86.32    |          |\n  | - input 448, JFT | 432.3M | 484.73G | 448   | 87.94    |          |\n## MobileNetV3\n  - [Keras MobileNetV3](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/mobilenetv3_family#mobilenetv3) includes implementation of [PDF 1905.02244 Searching for MobileNetV3](https://arxiv.org/pdf/1905.02244.pdf).\n\n  | Model               | Params | FLOPs   | Input | Top1 Acc | Download |\n  | ------------------- | ------ | ------- | ----- | -------- | -------- |\n  | MobileNetV3Small050 | 1.29M  | 24.92M  | 224   | 57.89    | [small_050_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mobilenetv3_family/mobilenetv3_small_050_imagenet.h5) |\n  | MobileNetV3Small075 | 2.04M  | 44.35M  | 224   | 65.24    | [small_075_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mobilenetv3_family/mobilenetv3_small_075_imagenet.h5) |\n  | MobileNetV3Small100 | 2.54M  | 57.62M  | 224   | 67.66    | [small_100_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mobilenetv3_family/mobilenetv3_small_100_imagenet.h5) |\n  | MobileNetV3Large075 | 3.99M  | 156.30M | 224   | 73.44    | [large_075_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mobilenetv3_family/mobilenetv3_large_075_imagenet.h5) |\n  | MobileNetV3Large100 | 5.48M  | 218.73M | 224   | 75.77    | [large_100_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mobilenetv3_family/mobilenetv3_large_100_imagenet.h5) |\n  | - miil              | 5.48M  | 218.73M | 224   | 77.92    | [large_100_miil.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mobilenetv3_family/mobilenetv3_large_100_mill.h5) |\n## MobileViT\n  - [Keras MobileViT](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/mobilevit) is for [PDF 2110.02178 MOBILEVIT: LIGHT-WEIGHT, GENERAL-PURPOSE, AND MOBILE-FRIENDLY VISION TRANSFORMER](https://arxiv.org/pdf/2110.02178.pdf).\n\n  | Model         | Params | FLOPs | Input | Top1 Acc | Download |\n  | ------------- | ------ | ----- | ----- | -------- | -------- |\n  | MobileViT_XXS | 1.3M   | 0.42G | 256   | 69.0     | [mobilevit_xxs_imagenet](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mobilevit/mobilevit_xxs_imagenet.h5) |\n  | MobileViT_XS  | 2.3M   | 1.05G | 256   | 74.7     | [mobilevit_xs_imagenet](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mobilevit/mobilevit_xs_imagenet.h5) |\n  | MobileViT_S   | 5.6M   | 2.03G | 256   | 78.3     | [mobilevit_s_imagenet](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mobilevit/mobilevit_s_imagenet.h5) |\n## MobileViT_V2\n  - [Keras MobileViT_V2](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/mobilevit) is for [PDF 2206.02680 Separable Self-attention for Mobile Vision Transformers](https://arxiv.org/pdf/2206.02680.pdf).\n\n  | Model              | Params | FLOPs | Input | Top1 Acc | Download |\n  | ------------------ | ------ | ----- | ----- | -------- | -------- |\n  | MobileViT_V2_050   | 1.37M  | 0.47G | 256   | 70.18    | [v2_050_256_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mobilevit/mobilevit_v2_050_256_imagenet.h5) |\n  | MobileViT_V2_075   | 2.87M  | 1.04G | 256   | 75.56    | [v2_075_256_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mobilevit/mobilevit_v2_075_256_imagenet.h5) |\n  | MobileViT_V2_100   | 4.90M  | 1.83G | 256   | 78.09    | [v2_100_256_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mobilevit/mobilevit_v2_100_256_imagenet.h5) |\n  | MobileViT_V2_125   | 7.48M  | 2.84G | 256   | 79.65    | [v2_125_256_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mobilevit/mobilevit_v2_125_256_imagenet.h5) |\n  | MobileViT_V2_150   | 10.6M  | 4.07G | 256   | 80.38    | [v2_150_256_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mobilevit/mobilevit_v2_150_256_imagenet.h5) |\n  | - imagenet22k      | 10.6M  | 4.07G | 256   | 81.46    | [v2_150_256_imagenet22k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mobilevit/mobilevit_v2_150_256_imagenet22k.h5) |\n  | - imagenet22k, 384 | 10.6M  | 9.15G | 384   | 82.60    | [v2_150_384_imagenet22k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mobilevit/mobilevit_v2_150_384_imagenet22k.h5) |\n  | MobileViT_V2_175   | 14.3M  | 5.52G | 256   | 80.84    | [v2_175_256_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mobilevit/mobilevit_v2_175_256_imagenet.h5) |\n  | - imagenet22k      | 14.3M  | 5.52G | 256   | 81.94    | [v2_175_256_imagenet22k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mobilevit/mobilevit_v2_175_256_imagenet22k.h5) |\n  | - imagenet22k, 384 | 14.3M  | 12.4G | 384   | 82.93    | [v2_175_384_imagenet22k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mobilevit/mobilevit_v2_175_384_imagenet22k.h5) |\n  | MobileViT_V2_200   | 18.4M  | 7.12G | 256   | 81.17    | [v2_200_256_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mobilevit/mobilevit_v2_200_256_imagenet.h5) |\n  | - imagenet22k      | 18.4M  | 7.12G | 256   | 82.36    | [v2_200_256_imagenet22k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mobilevit/mobilevit_v2_200_256_imagenet22k.h5) |\n  | - imagenet22k, 384 | 18.4M  | 16.2G | 384   | 83.41    | [v2_200_384_imagenet22k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mobilevit/mobilevit_v2_200_384_imagenet22k.h5) |\n## MogaNet\n  - [Keras MogaNet](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/moganet) is for [PDF 2211.03295 Efficient Multi-order Gated Aggregation Network](https://arxiv.org/pdf/2211.03295.pdf).\n\n  | Model        | Params | FLOPs  | Input | Top1 Acc | Download |\n  | ------------ | ------ | ------ | ----- | -------- | -------- |\n  | MogaNetXtiny | 2.96M  | 806M   | 224   | 76.5     | [moganet_xtiny_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/moganet/moganet_xtiny_imagenet.h5) |\n  | MogaNetTiny  | 5.20M  | 1.11G  | 224   | 79.0     | [moganet_tiny_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/moganet/moganet_tiny_224_imagenet.h5) |\n  |              | 5.20M  | 1.45G  | 256   | 79.6     | [moganet_tiny_256_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/moganet/moganet_tiny_256_imagenet.h5) |\n  | MogaNetSmall | 25.3M  | 4.98G  | 224   | 83.4     | [moganet_small_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/moganet/moganet_small_imagenet.h5) |\n  | MogaNetBase  | 43.7M  | 9.96G  | 224   | 84.2     | [moganet_base_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/moganet/moganet_base_imagenet.h5) |\n  | MogaNetLarge | 82.5M  | 15.96G | 224   | 84.6     | [moganet_large_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/moganet/moganet_large_imagenet.h5) |\n## NAT\n  - [Keras NAT](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/nat) is for [PDF 2204.07143 Neighborhood Attention Transformer](https://arxiv.org/pdf/2204.07143.pdf).\n\n  | Model     | Params | FLOPs  | Input | Top1 Acc | Download |\n  | --------- | ------ | ------ | ----- | -------- | -------- |\n  | NAT_Mini  | 20.0M  | 2.73G  | 224   | 81.8     | [nat_mini_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/nat/nat_mini_imagenet.h5) |\n  | NAT_Tiny  | 27.9M  | 4.34G  | 224   | 83.2     | [nat_tiny_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/nat/nat_tiny_imagenet.h5) |\n  | NAT_Small | 50.7M  | 7.84G  | 224   | 83.7     | [nat_small_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/nat/nat_small_imagenet.h5) |\n  | NAT_Base  | 89.8M  | 13.76G | 224   | 84.3     | [nat_base_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/nat/nat_base_imagenet.h5) |\n## NFNets\n  - [Keras NFNets](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/nfnets) is for [PDF 2102.06171 High-Performance Large-Scale Image Recognition Without Normalization](https://arxiv.org/pdf/2102.06171.pdf).\n\n  | Model       | Params | FLOPs   | Input | Top1 Acc | Download |\n  | ----------- | ------ | ------- | ----- | -------- | -------- |\n  | NFNetL0     | 35.07M | 7.13G   | 288   | 82.75    | [nfnetl0_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/nfnets/nfnetl0_imagenet.h5) |\n  | NFNetF0     | 71.5M  | 12.58G  | 256   | 83.6     | [nfnetf0_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/nfnets/nfnetf0_imagenet.h5) |\n  | NFNetF1     | 132.6M | 35.95G  | 320   | 84.7     | [nfnetf1_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/nfnets/nfnetf1_imagenet.h5) |\n  | NFNetF2     | 193.8M | 63.24G  | 352   | 85.1     | [nfnetf2_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/nfnets/nfnetf2_imagenet.h5) |\n  | NFNetF3     | 254.9M | 115.75G | 416   | 85.7     | [nfnetf3_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/nfnets/nfnetf3_imagenet.h5) |\n  | NFNetF4     | 316.1M | 216.78G | 512   | 85.9     | [nfnetf4_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/nfnets/nfnetf4_imagenet.h5) |\n  | NFNetF5     | 377.2M | 291.73G | 544   | 86.0     | [nfnetf5_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/nfnets/nfnetf5_imagenet.h5) |\n  | NFNetF6 SAM | 438.4M | 379.75G | 576   | 86.5     | [nfnetf6_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/nfnets/nfnetf6_imagenet.h5) |\n  | NFNetF7     | 499.5M | 481.80G | 608   |          |          |\n  | ECA_NFNetL0 | 24.14M | 7.12G   | 288   | 82.58    | [eca_nfnetl0_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/nfnets/eca_nfnetl0_imagenet.h5) |\n  | ECA_NFNetL1 | 41.41M | 14.93G  | 320   | 84.01    | [eca_nfnetl1_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/nfnets/eca_nfnetl1_imagenet.h5) |\n  | ECA_NFNetL2 | 56.72M | 30.12G  | 384   | 84.70    | [eca_nfnetl2_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/nfnets/eca_nfnetl2_imagenet.h5) |\n  | ECA_NFNetL3 | 72.04M | 52.73G  | 448   |          |          |\n## PVT_V2\n  - [Keras PVT_V2](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/pvt) is for [PDF 2106.13797 PVTv2: Improved Baselines with Pyramid Vision Transformer](https://arxiv.org/pdf/2106.13797.pdf).\n\n  | Model           | Params | FLOPs  | Input | Top1 Acc | Download |\n  | --------------- | ------ | ------ | ----- | -------- | -------- |\n  | PVT_V2B0        | 3.7M   | 580.3M | 224   | 70.5     | [pvt_v2_b0_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/pvt/pvt_v2_b0_imagenet.h5) |\n  | PVT_V2B1        | 14.0M  | 2.14G  | 224   | 78.7     | [pvt_v2_b1_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/pvt/pvt_v2_b1_imagenet.h5) |\n  | PVT_V2B2        | 25.4M  | 4.07G  | 224   | 82.0     | [pvt_v2_b2_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/pvt/pvt_v2_b2_imagenet.h5) |\n  | PVT_V2B2_linear | 22.6M  | 3.94G  | 224   | 82.1     | [pvt_v2_b2_linear.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/pvt/pvt_v2_b2_linear_imagenet.h5) |\n  | PVT_V2B3        | 45.2M  | 6.96G  | 224   | 83.1     | [pvt_v2_b3_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/pvt/pvt_v2_b3_imagenet.h5) |\n  | PVT_V2B4        | 62.6M  | 10.19G | 224   | 83.6     | [pvt_v2_b4_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/pvt/pvt_v2_b4_imagenet.h5) |\n  | PVT_V2B5        | 82.0M  | 11.81G | 224   | 83.8     | [pvt_v2_b5_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/pvt/pvt_v2_b5_imagenet.h5) |\n## RegNetY\n  - [Keras RegNetY](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/resnet_family#regnety) is for [PDF 2003.13678 Designing Network Design Spaces](https://arxiv.org/pdf/2003.13678.pdf).\n\n  | Model      | Params  | FLOPs  | Input | Top1 Acc | Download |\n  | ---------- | ------- | ------ | ----- | -------- | -------- |\n  | RegNetY040 | 20.65M  | 3.98G  | 224   | 82.3     | [regnety_040_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/resnet_family/regnety_040_imagenet.h5) |\n  | RegNetY064 | 30.58M  | 6.36G  | 224   | 83.0     | [regnety_064_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/resnet_family/regnety_064_imagenet.h5) |\n  | RegNetY080 | 39.18M  | 7.97G  | 224   | 83.17    | [regnety_080_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/resnet_family/regnety_080_imagenet.h5) |\n  | RegNetY160 | 83.59M  | 15.92G | 224   | 82.0     | [regnety_160_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/resnet_family/regnety_160_imagenet.h5) |\n  | RegNetY320 | 145.05M | 32.29G | 224   | 82.5     | [regnety_320_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/resnet_family/regnety_320_imagenet.h5) |\n## RegNetZ\n  - [Keras RegNetZ](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/resnet_family#regnetz) includes implementation of [Github timm/models/byobnet.py](https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/byobnet.py).\n  - Related paper [PDF 2004.02967 Evolving Normalization-Activation Layers](https://arxiv.org/pdf/2004.02967.pdf)\n\n  | Model          | Params | FLOPs | Input | Top1 Acc | Download |\n  | -------------- | ------ | ----- | ----- | -------- | -------- |\n  | RegNetZB16     | 9.72M  | 1.44G | 224   | 79.868   | [regnetz_b16_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/resnet_family/regnetz_b16_imagenet.h5) |\n  | RegNetZC16     | 13.46M | 2.50G | 256   | 82.164   | [regnetz_c16_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/resnet_family/regnetz_c16_imagenet.h5) |\n  | RegNetZC16_EVO | 13.49M | 2.55G | 256   | 81.9     | [regnetz_c16_evo_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/resnet_family/regnetz_c16_evo_imagenet.h5) |\n  | RegNetZD32     | 27.58M | 5.96G | 256   | 83.422   | [regnetz_d32_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/resnet_family/regnetz_d32_imagenet.h5) |\n  | RegNetZD8      | 23.37M | 3.95G | 256   | 83.5     | [regnetz_d8_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/resnet_family/regnetz_d8_imagenet.h5)   |\n  | RegNetZD8_EVO  | 23.46M | 4.61G | 256   | 83.42    | [regnetz_d8_evo_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/resnet_family/regnetz_d8_evo_imagenet.h5)   |\n  | RegNetZE8      | 57.70M | 9.88G | 256   | 84.5     | [regnetz_e8_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/resnet_family/regnetz_e8_imagenet.h5)   |\n## ResMLP\n  - [Keras ResMLP](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/mlp_family#resmlp) includes implementation of [PDF 2105.03404 ResMLP: Feedforward networks for image classification with data-efficient training](https://arxiv.org/pdf/2105.03404.pdf).\n\n  | Model         | Params | FLOPs   | Input | Top1 Acc | Download |\n  | ------------- | ------ | ------- | ----- | -------- | -------- |\n  | ResMLP12      | 15M    | 3.02G   | 224   | 77.8     | [resmlp12_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mlp_family/resmlp12_imagenet.h5) |\n  | ResMLP24      | 30M    | 5.98G   | 224   | 80.8     | [resmlp24_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mlp_family/resmlp24_imagenet.h5) |\n  | ResMLP36      | 116M   | 8.94G   | 224   | 81.1     | [resmlp36_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mlp_family/resmlp36_imagenet.h5) |\n  | ResMLP_B24    | 129M   | 100.39G | 224   | 83.6     | [resmlp_b24_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mlp_family/resmlp_b24_imagenet.h5) |\n  | - imagenet22k | 129M   | 100.39G | 224   | 84.4     | [resmlp_b24_imagenet22k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mlp_family/resmlp_b24_imagenet22k.h5) |\n## ResNeSt\n  - [Keras ResNeSt](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/resnest) is for [PDF 2004.08955 ResNeSt: Split-Attention Networks](https://arxiv.org/pdf/2004.08955.pdf).\n\n  | Model          | Params | FLOPs  | Input | Top1 Acc | Download |\n  | -------------- | ------ | ------ | ----- | -------- | -------- |\n  | resnest50      | 28M    | 5.38G  | 224   | 81.03    | [resnest50.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/resnest/resnest50_imagenet.h5) |\n  | resnest101     | 49M    | 13.33G | 256   | 82.83    | [resnest101.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/resnest/resnest101_imagenet.h5) |\n  | resnest200     | 71M    | 35.55G | 320   | 83.84    | [resnest200.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/resnest/resnest200_imagenet.h5) |\n  | resnest269     | 111M   | 77.42G | 416   | 84.54    | [resnest269.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/resnest/resnest269_imagenet.h5) |\n## ResNetD\n  - [Keras ResNetD](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/resnet_family#resnetd) includes implementation of [PDF 1812.01187 Bag of Tricks for Image Classification with Convolutional Neural Networks](https://arxiv.org/pdf/1812.01187.pdf)\n\n  | Model      | Params | FLOPs  | Input | Top1 Acc | Download |\n  | ---------- | ------ | ------ | ----- | -------- | -------- |\n  | ResNet50D  | 25.58M | 4.33G  | 224   | 80.530   | [resnet50d.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/resnet_family/resnet50d_imagenet.h5) |\n  | ResNet101D | 44.57M | 8.04G  | 224   | 83.022   | [resnet101d.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/resnet_family/resnet101d_imagenet.h5) |\n  | ResNet152D | 60.21M | 11.75G | 224   | 83.680   | [resnet152d.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/resnet_family/resnet152d_imagenet.h5) |\n  | ResNet200D | 64.69M | 15.25G | 224   | 83.962   | [resnet200d.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/resnet_family/resnet200d_imagenet.h5) |\n## ResNetQ\n  - [Keras ResNetQ](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/resnet_family#resnetq) includes implementation of [Github timm/models/resnet.py](https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/resnet.py)\n\n  | Model     | Params | FLOPs | Input | Top1 Acc | Download |\n  | --------- | ------ | ----- | ----- | -------- | -------- |\n  | ResNet51Q | 35.7M  | 4.87G | 224   | 82.36    | [resnet51q.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/resnet_family/resnet51q_imagenet.h5) |\n  | ResNet61Q | 36.8M  | 5.96G | 224   |          |          |\n## ResNeXt\n  - [Keras ResNeXt](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/resnet_family#resnext) includes implementation of [PDF 1611.05431 Aggregated Residual Transformations for Deep Neural Networks](https://arxiv.org/pdf/1611.05431.pdf).\n  - `SWSL` means `Semi-Weakly Supervised ResNe*t` from [Github facebookresearch/semi-supervised-ImageNet1K-models](https://github.com/facebookresearch/semi-supervised-ImageNet1K-models). **Please note the CC-BY-NC 4.0 license on theses weights, non-commercial use only**.\n\n  | Model                     | Params | FLOPs  | Input | Top1 Acc | Download            |\n  | ------------------------- | ------ | ------ | ----- | -------- | ------------------- |\n  | ResNeXt50 (32x4d)         | 25M    | 4.23G  | 224   | 79.768   | [resnext50_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/resnet_family/resnext50_imagenet.h5)  |\n  | - SWSL                    | 25M    | 4.23G  | 224   | 82.182   | [resnext50_swsl.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/resnet_family/resnext50_swsl.h5)  |\n  | ResNeXt50D (32x4d + deep) | 25M    | 4.47G  | 224   | 79.676   | [resnext50d_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/resnet_family/resnext50d_imagenet.h5)  |\n  | ResNeXt101 (32x4d)        | 42M    | 7.97G  | 224   | 80.334   | [resnext101_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/resnet_family/resnext101_imagenet.h5)  |\n  | - SWSL                    | 42M    | 7.97G  | 224   | 83.230   | [resnext101_swsl.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/resnet_family/resnext101_swsl.h5)  |\n  | ResNeXt101W (32x8d)       | 89M    | 16.41G | 224   | 79.308   | [resnext101_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/resnet_family/resnext101_imagenet.h5)  |\n  | - SWSL                    | 89M    | 16.41G | 224   | 84.284   | [resnext101w_swsl.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/resnet_family/resnext101w_swsl.h5)  |\n  | ResNeXt101W_64 (64x4d)    | 83.46M | 15.46G | 224   | 82.46    | [resnext101w_64_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/resnet_family/resnext101w_64_imagenet.h5)  |\n## SwinTransformerV2\n  - [Keras SwinTransformerV2](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/swin_transformer_v2) includes implementation of [PDF 2111.09883 Swin Transformer V2: Scaling Up Capacity and Resolution](https://arxiv.org/pdf/2111.09883.pdf).\n\n  | Model                                | Params | FLOPs  | Input | Top1 Acc | Download |\n  | ------------------------------------ | ------ | ------ | ----- | -------- | -------- |\n  | SwinTransformerV2Tiny_ns             | 28.3M  | 4.69G  | 224   | 81.8     | [tiny_ns_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/swin_transformer_v2/swin_transformer_v2_tiny_ns_224_imagenet.h5) |\n  | SwinTransformerV2Small_ns            | 49.7M  | 9.12G  | 224   | 83.5     | [small_ns_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/swin_transformer_v2/swin_transformer_v2_small_ns_224_imagenet.h5) |\n  |                                      |        |        |       |          |          |\n  | SwinTransformerV2Tiny_window8        | 28.3M  | 5.99G  | 256   | 81.8     | [tiny_window8_256.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/swin_transformer_v2/swin_transformer_v2_tiny_window8_256_imagenet.h5) |\n  | SwinTransformerV2Tiny_window16       | 28.3M  | 6.75G  | 256   | 82.8     | [tiny_window16_256.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/swin_transformer_v2/swin_transformer_v2_tiny_window16_256_imagenet.h5) |\n  | SwinTransformerV2Small_window8       | 49.7M  | 11.63G | 256   | 83.7     | [small_window8_256.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/swin_transformer_v2/swin_transformer_v2_small_window8_256_imagenet.h5) |\n  | SwinTransformerV2Small_window16      | 49.7M  | 12.93G | 256   | 84.1     | [small_window16_256.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/swin_transformer_v2/swin_transformer_v2_small_window16_256_imagenet.h5) |\n  | SwinTransformerV2Base_window8        | 87.9M  | 20.44G | 256   | 84.2     | [base_window8_256.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/swin_transformer_v2/swin_transformer_v2_base_window8_256_imagenet.h5) |\n  | SwinTransformerV2Base_window16       | 87.9M  | 22.17G | 256   | 84.6     | [base_window16_256.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/swin_transformer_v2/swin_transformer_v2_base_window16_256_imagenet.h5) |\n  | SwinTransformerV2Base_window16, 22k  | 87.9M  | 22.17G | 256   | 86.2     | [base_window16_256_22k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/swin_transformer_v2/swin_transformer_v2_base_window16_256_imagenet22k.h5) |\n  | SwinTransformerV2Base_window24, 22k  | 87.9M  | 55.89G | 384   | 87.1     | [base_window24_384_22k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/swin_transformer_v2/swin_transformer_v2_base_window24_384_imagenet22k.h5) |\n  | SwinTransformerV2Large_window16, 22k | 196.7M | 48.03G | 256   | 86.9     | [large_window16_256_22k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/swin_transformer_v2/swin_transformer_v2_large_window16_256_imagenet22k.h5) |\n  | SwinTransformerV2Large_window24, 22k | 196.7M | 117.1G | 384   | 87.6     | [large_window24_384_22k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/swin_transformer_v2/swin_transformer_v2_large_window24_384_imagenet22k.h5) |\n## TinyNet\n  - [Keras TinyNet](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/mobilenetv3_family#tinynet) includes implementation of [PDF 2010.14819 Model Rubiks Cube: Twisting Resolution, Depth and Width for TinyNets](https://arxiv.org/pdf/2010.14819.pdf).\n\n  | Model    | Params | FLOPs   | Input | Top1 Acc | Download |\n  | -------- | ------ | ------- | ----- | -------- | -------- |\n  | TinyNetE | 2.04M  | 25.22M  | 106   | 59.86    | [tinynet_e_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mobilenetv3_family/tinynet_e_imagenet.h5) |\n  | TinyNetD | 2.34M  | 53.35M  | 152   | 66.96    | [tinynet_d_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mobilenetv3_family/tinynet_d_imagenet.h5) |\n  | TinyNetC | 2.46M  | 103.22M | 184   | 71.23    | [tinynet_c_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mobilenetv3_family/tinynet_c_imagenet.h5) |\n  | TinyNetB | 3.73M  | 206.28M | 188   | 74.98    | [tinynet_b_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mobilenetv3_family/tinynet_b_imagenet.h5) |\n  | TinyNetA | 6.19M  | 343.74M | 192   | 77.65    | [tinynet_a_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mobilenetv3_family/tinynet_a_imagenet.h5) |\n## TinyViT\n  - [Keras TinyViT](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/tinyvit) includes implementation of [PDF 2207.10666 TinyViT: Fast Pretraining Distillation for Small Vision Transformers](https://arxiv.org/pdf/2207.10666.pdf).\n\n  | Model                | Params | FLOPs | Input | Top1 Acc | Download |\n  | -------------------- | ------ | ----- | ----- | -------- | -------- |\n  | TinyViT_5M, distill  | 5.4M   | 1.3G  | 224   | 79.1     | [tiny_vit_5m_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/tinyvit/tiny_vit_5m_224_imagenet.h5) |\n  | - imagenet21k-ft1k   | 5.4M   | 1.3G  | 224   | 80.7     | [tiny_vit_5m_224_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/tinyvit/tiny_vit_5m_224_imagenet21k-ft1k.h5) |\n  | TinyViT_11M, distill | 11M    | 2.0G  | 224   | 81.5     | [tiny_vit_11m_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/tinyvit/tiny_vit_11m_224_imagenet.h5) |\n  | - imagenet21k-ft1k   | 11M    | 2.0G  | 224   | 83.2     | [tiny_vit_11m_224_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/tinyvit/tiny_vit_11m_224_imagenet21k-ft1k.h5) |\n  | TinyViT_21M, distill | 21M    | 4.3G  | 224   | 83.1     | [tiny_vit_21m_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/tinyvit/tiny_vit_21m_224_imagenet.h5) |\n  | - imagenet21k-ft1k   | 21M    | 4.3G  | 224   | 84.8     | [tiny_vit_21m_224_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/tinyvit/tiny_vit_21m_224_imagenet21k-ft1k.h5) |\n  |                      | 21M    | 13.8G | 384   | 86.2     | [tiny_vit_21m_384_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/tinyvit/tiny_vit_21m_384_imagenet21k-ft1k.h5) |\n  |                      | 21M    | 27.0G | 512   | 86.5     | [tiny_vit_21m_512_21k.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/tinyvit/tiny_vit_21m_512_imagenet21k-ft1k.h5) |\n## UniFormer\n  - [Keras UniFormer](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/uniformer) includes implementation of [PDF 2201.09450 UniFormer: Unifying Convolution and Self-attention for Visual Recognition](https://arxiv.org/pdf/2201.09450.pdf).\n\n  | Model                 | Params | FLOPs  | Input | Top1 Acc | Download |\n  | --------------------- | ------ | ------ | ----- | -------- | -------- |\n  | UniformerSmall32 + TL | 22M    | 3.66G  | 224   | 83.4     | [small_32_224_token_label](https://github.com/leondgarse/keras_cv_attention_models/releases/download/uniformer/uniformer_small_32_224_token_label.h5) |\n  | UniformerSmall64      | 22M    | 3.66G  | 224   | 82.9     | [small_64_imagenet](https://github.com/leondgarse/keras_cv_attention_models/releases/download/uniformer/uniformer_small_64_224_imagenet.h5) |\n  | - Token Labeling      | 22M    | 3.66G  | 224   | 83.4     | [small_64_token_label](https://github.com/leondgarse/keras_cv_attention_models/releases/download/uniformer/uniformer_small_64_224_token_label.h5) |\n  | UniformerSmallPlus32  | 24M    | 4.24G  | 224   | 83.4     | [small_plus_32_imagenet](https://github.com/leondgarse/keras_cv_attention_models/releases/download/uniformer/uniformer_small_plus_32_224_imagenet.h5) |\n  | - Token Labeling      | 24M    | 4.24G  | 224   | 83.9     | [small_plus_32_token_label](https://github.com/leondgarse/keras_cv_attention_models/releases/download/uniformer/uniformer_small_plus_32_224_token_label.h5) |\n  | UniformerSmallPlus64  | 24M    | 4.23G  | 224   | 83.4     | [small_plus_64_imagenet](https://github.com/leondgarse/keras_cv_attention_models/releases/download/uniformer/uniformer_small_plus_64_224_imagenet.h5) |\n  | - Token Labeling      | 24M    | 4.23G  | 224   | 83.6     | [small_plus_64_token_label](https://github.com/leondgarse/keras_cv_attention_models/releases/download/uniformer/uniformer_small_plus_64_224_token_label.h5) |\n  | UniformerBase32 + TL  | 50M    | 8.32G  | 224   | 85.1     | [base_32_224_token_label](https://github.com/leondgarse/keras_cv_attention_models/releases/download/uniformer/uniformer_base_32_224_token_label.h5) |\n  | UniformerBase64       | 50M    | 8.31G  | 224   | 83.8     | [base_64_imagenet](https://github.com/leondgarse/keras_cv_attention_models/releases/download/uniformer/uniformer_base_64_224_imagenet.h5) |\n  | - Token Labeling      | 50M    | 8.31G  | 224   | 84.8     | [base_64_224_token_label](https://github.com/leondgarse/keras_cv_attention_models/releases/download/uniformer/uniformer_base_64_224_token_label.h5) |\n  | UniformerLarge64 + TL | 100M   | 19.79G | 224   | 85.6     | [large_64_224_token_label](https://github.com/leondgarse/keras_cv_attention_models/releases/download/uniformer/uniformer_large_64_224_token_label.h5) |\n  | UniformerLarge64 + TL | 100M   | 63.11G | 384   | 86.3     | [large_64_384_token_label](https://github.com/leondgarse/keras_cv_attention_models/releases/download/uniformer/uniformer_large_64_384_token_label.h5) |\n## VOLO\n  - [Keras VOLO](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/volo) is for [PDF 2106.13112 VOLO: Vision Outlooker for Visual Recognition](https://arxiv.org/pdf/2106.13112.pdf).\n\n  | Model   | Params | FLOPs   | Input | Top1 Acc | Download            |\n  | ------- | ------ | ------- | ----- | -------- | ------------------- |\n  | VOLO_d1 | 27M    | 4.82G   | 224   | 84.2     | [volo_d1_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/volo/volo_d1_224_imagenet.h5) |\n  | - 384   | 27M    | 14.22G  | 384   | 85.2     | [volo_d1_384_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/volo/volo_d1_384_imagenet.h5) |\n  | VOLO_d2 | 59M    | 9.78G   | 224   | 85.2     | [volo_d2_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/volo/volo_d2_224_imagenet.h5) |\n  | - 384   | 59M    | 28.84G  | 384   | 86.0     | [volo_d2_384_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/volo/volo_d2_384_imagenet.h5) |\n  | VOLO_d3 | 86M    | 13.80G  | 224   | 85.4     | [volo_d3_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/volo/volo_d3_224_imagenet.h5) |\n  | - 448   | 86M    | 55.50G  | 448   | 86.3     | [volo_d3_448_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/volo/volo_d3_448_imagenet.h5) |\n  | VOLO_d4 | 193M   | 29.39G  | 224   | 85.7     | [volo_d4_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/volo/volo_d4_224_imagenet.h5) |\n  | - 448   | 193M   | 117.81G | 448   | 86.8     | [volo_d4_448_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/volo/volo_d4_448_imagenet.h5) |\n  | VOLO_d5 | 296M   | 53.34G  | 224   | 86.1     | [volo_d5_224_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/volo/volo_d5_224_imagenet.h5) |\n  | - 448   | 296M   | 213.72G | 448   | 87.0     | [volo_d5_448_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/volo/volo_d5_448_imagenet.h5) |\n  | - 512   | 296M   | 279.36G | 512   | 87.1     | [volo_d5_512_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/volo/volo_d5_512_imagenet.h5) |\n## WaveMLP\n  - [Keras WaveMLP](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/mlp_family#wavemlp) includes implementation of [PDF 2111.12294 An Image Patch is a Wave: Quantum Inspired Vision MLP](https://arxiv.org/pdf/2111.12294.pdf).\n\n  | Model     | Params | FLOPs  | Input | Top1 Acc | Download |\n  | --------- | ------ | ------ | ----- | -------- | -------- |\n  | WaveMLP_T | 17M    | 2.47G  | 224   | 80.9     | [wavemlp_t_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mlp_family/wavemlp_t_imagenet.h5) |\n  | WaveMLP_S | 30M    | 4.55G  | 224   | 82.9     | [wavemlp_s_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mlp_family/wavemlp_s_imagenet.h5) |\n  | WaveMLP_M | 44M    | 7.92G  | 224   | 83.3     | [wavemlp_m_imagenet.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/mlp_family/wavemlp_m_imagenet.h5) |\n  | WaveMLP_B | 63M    | 10.26G | 224   | 83.6     |          |\n***\n\n# Detection Models\n## EfficientDet\n  - [Keras EfficientDet](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/efficientdet) includes implementation of [Paper 1911.09070 EfficientDet: Scalable and Efficient Object Detection](https://arxiv.org/pdf/1911.09070.pdf).\n  - `Det-AdvProp + AutoAugment` [Paper 2103.13886 Robust and Accurate Object Detection via Adversarial Learning](https://arxiv.org/pdf/2103.13886.pdf).\n\n  | Model              | Params | FLOPs   | Input | COCO val AP | test AP | Download |\n  | ------------------ | ------ | ------- | ----- | ----------- | ------- | -------- |\n  | EfficientDetD0     | 3.9M   | 2.55G   | 512   | 34.3        | 34.6    | [efficientdet_d0.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/efficientdet/efficientdet_d0_512_coco.h5)         |\n  | - Det-AdvProp      | 3.9M   | 2.55G   | 512   | 35.1        | 35.3    |          |\n  | EfficientDetD1     | 6.6M   | 6.13G   | 640   | 40.2        | 40.5    | [efficientdet_d1.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/efficientdet/efficientdet_d1_640_coco.h5)         |\n  | - Det-AdvProp      | 6.6M   | 6.13G   | 640   | 40.8        | 40.9    |          |\n  | EfficientDetD2     | 8.1M   | 11.03G  | 768   | 43.5        | 43.9    | [efficientdet_d2.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/efficientdet/efficientdet_d2_768_coco.h5)         |\n  | - Det-AdvProp      | 8.1M   | 11.03G  | 768   | 44.3        | 44.3    |          |\n  | EfficientDetD3     | 12.0M  | 24.95G  | 896   | 46.8        | 47.2    | [efficientdet_d3.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/efficientdet/efficientdet_d3_896_coco.h5)         |\n  | - Det-AdvProp      | 12.0M  | 24.95G  | 896   | 47.7        | 48.0    |          |\n  | EfficientDetD4     | 20.7M  | 55.29G  | 1024  | 49.3        | 49.7    | [efficientdet_d4.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/efficientdet/efficientdet_d4_1024_coco.h5)        |\n  | - Det-AdvProp      | 20.7M  | 55.29G  | 1024  | 50.4        | 50.4    |          |\n  | EfficientDetD5     | 33.7M  | 135.62G | 1280  | 51.2        | 51.5    | [efficientdet_d5.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/efficientdet/efficientdet_d5_1280_coco.h5)        |\n  | - Det-AdvProp      | 33.7M  | 135.62G | 1280  | 52.2        | 52.5    |          |\n  | EfficientDetD6     | 51.9M  | 225.93G | 1280  | 52.1        | 52.6    | [efficientdet_d6.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/efficientdet/efficientdet_d6_1280_coco.h5)        |\n  | EfficientDetD7     | 51.9M  | 325.34G | 1536  | 53.4        | 53.7    | [efficientdet_d7.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/efficientdet/efficientdet_d7_1536_coco.h5)        |\n  | EfficientDetD7X    | 77.0M  | 410.87G | 1536  | 54.4        | 55.1    | [efficientdet_d7x.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/efficientdet/efficientdet_d7x_1536_coco.h5)      |\n  | EfficientDetLite0  | 3.2M   | 0.98G   | 320   | 27.5        | 26.41   | [efficientdet_lite0.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/efficientdet/efficientdet_lite0_320_coco.h5)   |\n  | EfficientDetLite1  | 4.2M   | 1.97G   | 384   | 32.6        | 31.50   | [efficientdet_lite1.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/efficientdet/efficientdet_lite1_384_coco.h5)   |\n  | EfficientDetLite2  | 5.3M   | 3.38G   | 448   | 36.2        | 35.06   | [efficientdet_lite2.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/efficientdet/efficientdet_lite2_448_coco.h5)   |\n  | EfficientDetLite3  | 8.4M   | 7.50G   | 512   | 39.9        | 38.77   | [efficientdet_lite3.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/efficientdet/efficientdet_lite3_512_coco.h5)   |\n  | EfficientDetLite3X | 9.3M   | 14.01G  | 640   | 44.0        | 42.64   | [efficientdet_lite3x.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/efficientdet/efficientdet_lite3x_640_coco.h5) |\n  | EfficientDetLite4  | 15.1M  | 20.20G  | 640   | 44.4        | 43.18   | [efficientdet_lite4.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/efficientdet/efficientdet_lite4_640_coco.h5)   |\n## YOLOR\n  - [Keras YOLOR](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/yolor) includes implementation of [Paper 2105.04206 You Only Learn One Representation: Unified Network for Multiple Tasks](https://arxiv.org/pdf/2105.04206.pdf).\n\n  | Model      | Params | FLOPs   | Input | COCO val AP | test AP | Download |\n  | ---------- | ------ | ------- | ----- | ----------- | ------- | -------- |\n  | YOLOR_CSP  | 52.9M  | 60.25G  | 640   | 50.0        | 52.8    | [yolor_csp_coco.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/yolor/yolor_csp_coco.h5)     |\n  | YOLOR_CSPX | 99.8M  | 111.11G | 640   | 51.5        | 54.8    | [yolor_csp_x_coco.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/yolor/yolor_csp_x_coco.h5) |\n  | YOLOR_P6   | 37.3M  | 162.87G | 1280  | 52.5        | 55.7    | [yolor_p6_coco.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/yolor/yolor_p6_coco.h5)       |\n  | YOLOR_W6   | 79.9M  | 226.67G | 1280  | 53.6 ?      | 56.9    | [yolor_w6_coco.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/yolor/yolor_w6_coco.h5)       |\n  | YOLOR_E6   | 115.9M | 341.62G | 1280  | 50.3 ?      | 57.6    | [yolor_e6_coco.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/yolor/yolor_e6_coco.h5)       |\n  | YOLOR_D6   | 151.8M | 467.88G | 1280  | 50.8 ?      | 58.2    | [yolor_d6_coco.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/yolor/yolor_d6_coco.h5)       |\n## YOLOV7\n  - [Keras YOLOV7](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/yolov7) includes implementation of [Paper 2207.02696 YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors](https://arxiv.org/pdf/2207.02696.pdf).\n\n  | Model       | Params | FLOPs  | Input | COCO val AP | test AP | Download |\n  | ----------- | ------ | ------ | ----- | ----------- | ------- | -------- |\n  | YOLOV7_Tiny | 6.23M  | 2.90G  | 416   | 33.3        |         | [yolov7_tiny_coco.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/yolov7/yolov7_tiny_coco.h5) |\n  | YOLOV7_CSP  | 37.67M | 53.0G  | 640   | 51.4        |         | [yolov7_csp_coco.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/yolov7/yolov7_csp_coco.h5) |\n  | YOLOV7_X    | 71.41M | 95.0G  | 640   | 53.1        |         | [yolov7_x_coco.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/yolov7/yolov7_x_coco.h5) |\n  | YOLOV7_W6   | 70.49M | 180.1G | 1280  | 54.9        |         | [yolov7_w6_coco.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/yolov7/yolov7_w6_coco.h5) |\n  | YOLOV7_E6   | 97.33M | 257.6G | 1280  | 56.0        |         | [yolov7_e6_coco.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/yolov7/yolov7_e6_coco.h5) |\n  | YOLOV7_D6   | 133.9M | 351.4G | 1280  | 56.6        |         | [yolov7_d6_coco.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/yolov7/yolov7_d6_coco.h5) |\n  | YOLOV7_E6E  | 151.9M | 421.7G | 1280  | 56.8        |         | [yolov7_e6e_coco.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/yolov7/yolov7_e6e_coco.h5) |\n## YOLOX\n  - [Keras YOLOX](https://github.com/leondgarse/keras_cv_attention_models/tree/main/keras_cv_attention_models/yolox) includes implementation of [Paper 2107.08430 YOLOX: Exceeding YOLO Series in 2021](https://arxiv.org/pdf/2107.08430.pdf).\n\n  | Model     | Params | FLOPs   | Input | COCO val AP | test AP | Download |\n  | --------- | ------ | ------- | ----- | ----------- | ------- | -------- |\n  | YOLOXNano | 0.91M  | 0.53G   | 416   | 25.8        |         | [yolox_nano_coco.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/yolox/yolox_nano_coco.h5) |\n  | YOLOXTiny | 5.06M  | 3.22G   | 416   | 32.8        |         | [yolox_tiny_coco.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/yolox/yolox_tiny_coco.h5) |\n  | YOLOXS    | 9.0M   | 13.39G  | 640   | 40.5        | 40.5    | [yolox_s_coco.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/yolox/yolox_s_coco.h5)       |\n  | YOLOXM    | 25.3M  | 36.84G  | 640   | 46.9        | 47.2    | [yolox_m_coco.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/yolox/yolox_m_coco.h5)       |\n  | YOLOXL    | 54.2M  | 77.76G  | 640   | 49.7        | 50.1    | [yolox_l_coco.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/yolox/yolox_l_coco.h5)       |\n  | YOLOXX    | 99.1M  | 140.87G | 640   | 51.5        | 51.5    | [yolox_x_coco.h5](https://github.com/leondgarse/keras_cv_attention_models/releases/download/yolox/yolox_x_coco.h5)       |\n***\n\n# Licenses\n  - This part is copied and modified according to [Github rwightman/pytorch-image-models](https://github.com/rwightman/pytorch-image-models).\n  - **Code**. The code here is licensed MIT. It is your responsibility to ensure you comply with licenses here and conditions of any dependent licenses. Where applicable, I've linked the sources/references for various components in docstrings. If you think I've missed anything please create an issue. So far all of the pretrained weights available here are pretrained on ImageNet and COCO with a select few that have some additional pretraining.\n  - **ImageNet Pretrained Weights**. ImageNet was released for non-commercial research purposes only (https://image-net.org/download). It's not clear what the implications of that are for the use of pretrained weights from that dataset. Any models I have trained with ImageNet are done for research purposes and one should assume that the original dataset license applies to the weights. It's best to seek legal advice if you intend to use the pretrained weights in a commercial product.\n  - **COCO Pretrained Weights**. Should follow [cocodataset termsofuse](https://cocodataset.org/#termsofuse). The annotations in COCO dataset belong to the COCO Consortium and are licensed under a [Creative Commons Attribution 4.0 License](https://creativecommons.org/licenses/by/4.0/legalcode). The COCO Consortium does not own the copyright of the images. Use of the images must abide by the [Flickr Terms of Use](https://www.flickr.com/creativecommons/). The users of the images accept full responsibility for the use of the dataset, including but not limited to the use of any copies of copyrighted images that they may create from the dataset.\n  - **Pretrained on more than ImageNet and COCO**. Several weights included or references here were pretrained with proprietary datasets that I do not have access to. These include the Facebook WSL, SSL, SWSL ResNe(Xt) and the Google Noisy Student EfficientNet models. The Facebook models have an explicit non-commercial license (CC-BY-NC 4.0, https://github.com/facebookresearch/semi-supervised-ImageNet1K-models, https://github.com/facebookresearch/WSL-Images). The Google models do not appear to have any restriction beyond the Apache 2.0 license (and ImageNet concerns). In either case, you should contact Facebook or Google with any questions.\n***\n\n# Citing\n  - **BibTeX**\n    ```bibtex\n    @misc{leondgarse,\n      author = {Leondgarse},\n      title = {Keras CV Attention Models},\n      year = {2022},\n      publisher = {GitHub},\n      journal = {GitHub repository},\n      doi = {10.5281/zenodo.6506947},\n      howpublished = {\\url{https://github.com/leondgarse/keras_cv_attention_models}}\n    }\n    ```\n  - **Latest DOI**: [![DOI](https://zenodo.org/badge/391777965.svg)](https://zenodo.org/badge/latestdoi/391777965)\n***\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/leondgarse/keras_cv_attention_models",
    "keywords": "tensorflow keras cv attention pretrained models kecam",
    "license": "Apache 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "keras-cv-attention-models",
    "package_url": "https://pypi.org/project/keras-cv-attention-models/",
    "platform": null,
    "project_url": "https://pypi.org/project/keras-cv-attention-models/",
    "project_urls": {
      "Homepage": "https://github.com/leondgarse/keras_cv_attention_models"
    },
    "release_url": "https://pypi.org/project/keras-cv-attention-models/1.3.13/",
    "requires_dist": [
      "tensorflow-addons ; platform_machine != \"aarch64\" and platform_machine != \"aarch32\"",
      "tensorflow-datasets ; platform_machine != \"aarch64\" and platform_machine != \"aarch32\"",
      "tensorflow ; platform_system != \"Darwin\""
    ],
    "requires_python": ">=3.6",
    "summary": "Tensorflow keras computer vision attention models. Alias kecam. https://github.com/leondgarse/keras_cv_attention_models",
    "version": "1.3.13",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17544727,
  "releases": {
    "1.0.10": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "92b8b83680342f23a870d25b8ff8f6c8fa4e78adf265c5dc384c3c94caf86e45",
          "md5": "b3066f5c63adc3df2c6cccadf1dc4bb5",
          "sha256": "c47839edae8324612ed22d4c759a797f722a0279b282efdcef5e8d389f759109"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.0.10-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "b3066f5c63adc3df2c6cccadf1dc4bb5",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 112439,
        "upload_time": "2021-09-26T11:09:45",
        "upload_time_iso_8601": "2021-09-26T11:09:45.431652Z",
        "url": "https://files.pythonhosted.org/packages/92/b8/b83680342f23a870d25b8ff8f6c8fa4e78adf265c5dc384c3c94caf86e45/keras_cv_attention_models-1.0.10-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2c74f5888be965fbc654348159570d9f6fbc46d2e6c5392069b2386c38bc83ff",
          "md5": "611d030f815692c6ef0eac6a3788ee3c",
          "sha256": "2a33bc7bdfa4a002cf30156d7cc4e60b91d95a239f8a61ce61ae5c438ad38008"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.0.10.tar.gz",
        "has_sig": false,
        "md5_digest": "611d030f815692c6ef0eac6a3788ee3c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 92553,
        "upload_time": "2021-09-26T11:09:47",
        "upload_time_iso_8601": "2021-09-26T11:09:47.040616Z",
        "url": "https://files.pythonhosted.org/packages/2c/74/f5888be965fbc654348159570d9f6fbc46d2e6c5392069b2386c38bc83ff/keras-cv-attention-models-1.0.10.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.11": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bc0cd01012d76e74386b191f1ab601dfed2bdcfcc70560bd3e6c69099da7fdcc",
          "md5": "a4204d8f35ae470c89415ee69532956b",
          "sha256": "9cee05e2ba01da70b782ed2fe9666c2daff3d1405281d15a078dd2358374aed7"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.0.11-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "a4204d8f35ae470c89415ee69532956b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 116129,
        "upload_time": "2021-09-28T08:33:56",
        "upload_time_iso_8601": "2021-09-28T08:33:56.251953Z",
        "url": "https://files.pythonhosted.org/packages/bc/0c/d01012d76e74386b191f1ab601dfed2bdcfcc70560bd3e6c69099da7fdcc/keras_cv_attention_models-1.0.11-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "36cdefe9db9e6638e51e0409b4e614dff50bcae505cbea0752b0a76473544d7f",
          "md5": "631399ea02e63ac87d866013b4912400",
          "sha256": "cc8a8eb4f87931a1003d048c9647f7fdc48e6266a1035f5a5efae2afa058253c"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.0.11.tar.gz",
        "has_sig": false,
        "md5_digest": "631399ea02e63ac87d866013b4912400",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 95605,
        "upload_time": "2021-09-28T08:33:57",
        "upload_time_iso_8601": "2021-09-28T08:33:57.534781Z",
        "url": "https://files.pythonhosted.org/packages/36/cd/efe9db9e6638e51e0409b4e614dff50bcae505cbea0752b0a76473544d7f/keras-cv-attention-models-1.0.11.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.12": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7a3f80f754c2c2d9606187a8b52a510d5ee9bc615e9c3381366e969f8f0cd09c",
          "md5": "8b8fa682d665256789e340575b00ab07",
          "sha256": "c2030fd37c42a282d4024caecd0cc7c7f69a67137d4d7a174cafe33e73e99107"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.0.12-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "8b8fa682d665256789e340575b00ab07",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 116200,
        "upload_time": "2021-09-29T12:45:14",
        "upload_time_iso_8601": "2021-09-29T12:45:14.009001Z",
        "url": "https://files.pythonhosted.org/packages/7a/3f/80f754c2c2d9606187a8b52a510d5ee9bc615e9c3381366e969f8f0cd09c/keras_cv_attention_models-1.0.12-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c86d757581289d44b20df1b3ae2b17e25841cf7341be98d2619edca061674289",
          "md5": "3fe486a4624d230de14d459b00d3336c",
          "sha256": "8ed1b7125d5ba3ae4fc465af909e31f37e4b4200ceb925d65d244ce412e2f41d"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.0.12.tar.gz",
        "has_sig": false,
        "md5_digest": "3fe486a4624d230de14d459b00d3336c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 95694,
        "upload_time": "2021-09-29T12:45:15",
        "upload_time_iso_8601": "2021-09-29T12:45:15.660002Z",
        "url": "https://files.pythonhosted.org/packages/c8/6d/757581289d44b20df1b3ae2b17e25841cf7341be98d2619edca061674289/keras-cv-attention-models-1.0.12.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.13": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c7d924f8e9798822fe034db3a44898bb18ef551b409ec50375b54d66083d4514",
          "md5": "1596f35f16a0da54eb1c2359a3662f23",
          "sha256": "ce103b1164e25bc044fb6666c3ac5e213ace31e2cfb9670825aae4477cc4db21"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.0.13-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "1596f35f16a0da54eb1c2359a3662f23",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 118680,
        "upload_time": "2021-09-30T10:39:40",
        "upload_time_iso_8601": "2021-09-30T10:39:40.353578Z",
        "url": "https://files.pythonhosted.org/packages/c7/d9/24f8e9798822fe034db3a44898bb18ef551b409ec50375b54d66083d4514/keras_cv_attention_models-1.0.13-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6e57f4bb42ea11259bbdc17c30eaecaaf140f224914b355b143ff1a2f08c1622",
          "md5": "c8a8040f50278b4920c59383ecd29b3b",
          "sha256": "e114f99b8383b7b7dfcb21c160d8dfa4c7fafee06f436e2f3f72f4e75b3352fd"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.0.13.tar.gz",
        "has_sig": false,
        "md5_digest": "c8a8040f50278b4920c59383ecd29b3b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 97717,
        "upload_time": "2021-09-30T10:39:41",
        "upload_time_iso_8601": "2021-09-30T10:39:41.869436Z",
        "url": "https://files.pythonhosted.org/packages/6e/57/f4bb42ea11259bbdc17c30eaecaaf140f224914b355b143ff1a2f08c1622/keras-cv-attention-models-1.0.13.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.14": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "55d40a1e52d00bcdb7c908a25481d359f0b94095139d4fabc06b32f4443d7ad0",
          "md5": "8ef4db888746214c7346f196724bbdd4",
          "sha256": "253ceca641bf8ed3b5d4c3f2d06a0b56e58dd307af384749a5225e63d4a6cc65"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.0.14-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "8ef4db888746214c7346f196724bbdd4",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 119616,
        "upload_time": "2021-10-08T10:51:46",
        "upload_time_iso_8601": "2021-10-08T10:51:46.976386Z",
        "url": "https://files.pythonhosted.org/packages/55/d4/0a1e52d00bcdb7c908a25481d359f0b94095139d4fabc06b32f4443d7ad0/keras_cv_attention_models-1.0.14-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "68adb71d0f3f18178ade3c992eab19c12d00dfdf3683a3c1c37484bc961c6244",
          "md5": "05875c7ddc6dc872708835d4b010d5a7",
          "sha256": "54d74b1be9ace4af3102655b5b08ffae76a25572cf366c72d7bb7e1e0c549219"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.0.14.tar.gz",
        "has_sig": false,
        "md5_digest": "05875c7ddc6dc872708835d4b010d5a7",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 98730,
        "upload_time": "2021-10-08T10:51:50",
        "upload_time_iso_8601": "2021-10-08T10:51:50.000989Z",
        "url": "https://files.pythonhosted.org/packages/68/ad/b71d0f3f18178ade3c992eab19c12d00dfdf3683a3c1c37484bc961c6244/keras-cv-attention-models-1.0.14.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.15": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "62153163ee0d92a0f1fe1beb92bc586357a9a35b244d0be5de8cf90aa8ebc8b7",
          "md5": "566e07cdf7b2b0e84154776f5eb944d8",
          "sha256": "28264fd4366959a2979744be8e7a137ff29f57efc72cf756ee1ccef0db1d6df8"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.0.15-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "566e07cdf7b2b0e84154776f5eb944d8",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 119899,
        "upload_time": "2021-10-09T10:03:30",
        "upload_time_iso_8601": "2021-10-09T10:03:30.152356Z",
        "url": "https://files.pythonhosted.org/packages/62/15/3163ee0d92a0f1fe1beb92bc586357a9a35b244d0be5de8cf90aa8ebc8b7/keras_cv_attention_models-1.0.15-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1d02c4c644c0d9c37d826fa19694e8b95968b9f3de735036be9c075742afa5df",
          "md5": "5e3d4b0db0851a092d6482e3698d4696",
          "sha256": "9e3fbaf806294a435bab61801fdd28501b143ef4f0364aea7e31cacead4b3389"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.0.15.tar.gz",
        "has_sig": false,
        "md5_digest": "5e3d4b0db0851a092d6482e3698d4696",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 99104,
        "upload_time": "2021-10-09T10:03:31",
        "upload_time_iso_8601": "2021-10-09T10:03:31.704360Z",
        "url": "https://files.pythonhosted.org/packages/1d/02/c4c644c0d9c37d826fa19694e8b95968b9f3de735036be9c075742afa5df/keras-cv-attention-models-1.0.15.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.16": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "156a019fdb07b70b9914d179e2c6b02d0d91d824f6b854dae6b17d5800df01ec",
          "md5": "71a8a45b0211e213a00034029f23f169",
          "sha256": "f19b92910538eeac57c23307b539327afdec0ca6ae254502abf9639c1a96d498"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.0.16-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "71a8a45b0211e213a00034029f23f169",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 117955,
        "upload_time": "2021-10-14T10:45:20",
        "upload_time_iso_8601": "2021-10-14T10:45:20.087945Z",
        "url": "https://files.pythonhosted.org/packages/15/6a/019fdb07b70b9914d179e2c6b02d0d91d824f6b854dae6b17d5800df01ec/keras_cv_attention_models-1.0.16-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "968f27a20dfe454a2df1e4d8939b58c9ecd6a9084820bf6bc3403fdfa4416936",
          "md5": "8408ada1ee20d694d15c97f058bd940d",
          "sha256": "c1db70a3e0991e90bd67660a64ff11aad0897e7873e871fe590b45d1f19cacb1"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.0.16.tar.gz",
        "has_sig": false,
        "md5_digest": "8408ada1ee20d694d15c97f058bd940d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 97752,
        "upload_time": "2021-10-14T10:45:22",
        "upload_time_iso_8601": "2021-10-14T10:45:22.600884Z",
        "url": "https://files.pythonhosted.org/packages/96/8f/27a20dfe454a2df1e4d8939b58c9ecd6a9084820bf6bc3403fdfa4416936/keras-cv-attention-models-1.0.16.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.17": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e7f14f065a5892504f9e1c959a10ac5f75fa4fe9dd2b3ef390c010f59b772330",
          "md5": "d61a6482bc3b36c901b1bce77b327add",
          "sha256": "1e54bbfc268312a03066f4f4f623f93a8ea6aea42b9664767d74a929d67357a8"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.0.17-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d61a6482bc3b36c901b1bce77b327add",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 121803,
        "upload_time": "2021-10-22T06:46:19",
        "upload_time_iso_8601": "2021-10-22T06:46:19.872651Z",
        "url": "https://files.pythonhosted.org/packages/e7/f1/4f065a5892504f9e1c959a10ac5f75fa4fe9dd2b3ef390c010f59b772330/keras_cv_attention_models-1.0.17-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bc482fd924cc730299bac4f0667dc945af0f73b24868e63867e70e6e90a161c1",
          "md5": "df408e7cff8cebc33f0687ec2d486b35",
          "sha256": "674d8a7f1628a813be641e3d32a374fb3eeea9b00c26cd7728b3f94f2288dff7"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.0.17.tar.gz",
        "has_sig": false,
        "md5_digest": "df408e7cff8cebc33f0687ec2d486b35",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 101631,
        "upload_time": "2021-10-22T06:46:21",
        "upload_time_iso_8601": "2021-10-22T06:46:21.526429Z",
        "url": "https://files.pythonhosted.org/packages/bc/48/2fd924cc730299bac4f0667dc945af0f73b24868e63867e70e6e90a161c1/keras-cv-attention-models-1.0.17.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.18": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1086b575b163e91e432f2abe3179dcb63f4f7be9459438233d82ee36fa3e1e20",
          "md5": "c8dc8f9ac1f7cd15f4adf9a16929ab28",
          "sha256": "ae8c691bcc86802a0f21913bab73b5160c30cf816976af1ff33ce74c135a4a9b"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.0.18-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "c8dc8f9ac1f7cd15f4adf9a16929ab28",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 123351,
        "upload_time": "2021-10-22T11:27:45",
        "upload_time_iso_8601": "2021-10-22T11:27:45.970807Z",
        "url": "https://files.pythonhosted.org/packages/10/86/b575b163e91e432f2abe3179dcb63f4f7be9459438233d82ee36fa3e1e20/keras_cv_attention_models-1.0.18-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e18b92b46d3d47d1f3d9380ba35379ab5cab1ac0d61079c732596cd4d94d0313",
          "md5": "016fe094eb10efdb8db8384cd135b907",
          "sha256": "d995c00eb28c4d22ec8de50398178ff6359f099a2895f6e20418affa7f50d1c0"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.0.18.tar.gz",
        "has_sig": false,
        "md5_digest": "016fe094eb10efdb8db8384cd135b907",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 103253,
        "upload_time": "2021-10-22T11:27:47",
        "upload_time_iso_8601": "2021-10-22T11:27:47.278809Z",
        "url": "https://files.pythonhosted.org/packages/e1/8b/92b46d3d47d1f3d9380ba35379ab5cab1ac0d61079c732596cd4d94d0313/keras-cv-attention-models-1.0.18.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.19": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7104f80c2263adf89afdbf7064185be3c63625d9ac661f4481e311bf21f551a5",
          "md5": "320506dfe6f9f8a33607698e16a6d227",
          "sha256": "f634f29dfb94f7e0c405469755de6c2ebf7f88cd175542ccd5d2aa61a8272542"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.0.19-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "320506dfe6f9f8a33607698e16a6d227",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 123366,
        "upload_time": "2021-10-26T06:12:56",
        "upload_time_iso_8601": "2021-10-26T06:12:56.110572Z",
        "url": "https://files.pythonhosted.org/packages/71/04/f80c2263adf89afdbf7064185be3c63625d9ac661f4481e311bf21f551a5/keras_cv_attention_models-1.0.19-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "60e79d399997a4e6b533eedee9f3c37e7b6df9aaaed888b597eb75a031f7ff12",
          "md5": "fa96a6324b23d0952cc5da812b0d120b",
          "sha256": "93abbc8c4d6b3b90db450c89020d4258594f2f336ac4db13b8edfa65ed49fe0c"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.0.19.tar.gz",
        "has_sig": false,
        "md5_digest": "fa96a6324b23d0952cc5da812b0d120b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 103284,
        "upload_time": "2021-10-26T06:12:58",
        "upload_time_iso_8601": "2021-10-26T06:12:58.077742Z",
        "url": "https://files.pythonhosted.org/packages/60/e7/9d399997a4e6b533eedee9f3c37e7b6df9aaaed888b597eb75a031f7ff12/keras-cv-attention-models-1.0.19.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.20": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4ef8e033b1657c3b6eddc61ef5d3e4a5c22aeb767d0b15ffb166d09dd0300eef",
          "md5": "9f1d6ee987725308594094a747eb4ee9",
          "sha256": "d0baf7653b68780026acd6e6835cd8a1b1cb5af79c1848095bff7c3ef6314a13"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.0.20-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "9f1d6ee987725308594094a747eb4ee9",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 129832,
        "upload_time": "2021-10-26T07:57:09",
        "upload_time_iso_8601": "2021-10-26T07:57:09.424630Z",
        "url": "https://files.pythonhosted.org/packages/4e/f8/e033b1657c3b6eddc61ef5d3e4a5c22aeb767d0b15ffb166d09dd0300eef/keras_cv_attention_models-1.0.20-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2e9488f5df37d427084640e1470b24d94da4afaac7300f7d7d1b9ed2379639b7",
          "md5": "82efb166931f4d50569827d2d09e9a7f",
          "sha256": "d9e92d1c4cccdb6c2d81ca29aa31e59629c71d313d536101bfcb5ffc7ad8a8d0"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.0.20.tar.gz",
        "has_sig": false,
        "md5_digest": "82efb166931f4d50569827d2d09e9a7f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 108133,
        "upload_time": "2021-10-26T07:57:10",
        "upload_time_iso_8601": "2021-10-26T07:57:10.554398Z",
        "url": "https://files.pythonhosted.org/packages/2e/94/88f5df37d427084640e1470b24d94da4afaac7300f7d7d1b9ed2379639b7/keras-cv-attention-models-1.0.20.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.21": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "20565ff83719f034f98cdeb6aac7cd65449ac59377949648918970371a111041",
          "md5": "06d0607418f36238cffc8a8493eccc45",
          "sha256": "4516095722729b9c94eb7f7096624dfdc77dc3b3dd94969a0f484f771341df6c"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.0.21-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "06d0607418f36238cffc8a8493eccc45",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 130937,
        "upload_time": "2021-11-02T08:36:42",
        "upload_time_iso_8601": "2021-11-02T08:36:42.692410Z",
        "url": "https://files.pythonhosted.org/packages/20/56/5ff83719f034f98cdeb6aac7cd65449ac59377949648918970371a111041/keras_cv_attention_models-1.0.21-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a3d65ace0df0c31067df6ee670d7dfb797a4b1455adda8d3339c8ee63be78df0",
          "md5": "3a4bbed549866984ce5972fc05d87f54",
          "sha256": "f862a3695e664ae146e786dcef4688744d6d845639ba3bbf752679318ac02911"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.0.21.tar.gz",
        "has_sig": false,
        "md5_digest": "3a4bbed549866984ce5972fc05d87f54",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 115163,
        "upload_time": "2021-11-02T08:36:43",
        "upload_time_iso_8601": "2021-11-02T08:36:43.968962Z",
        "url": "https://files.pythonhosted.org/packages/a3/d6/5ace0df0c31067df6ee670d7dfb797a4b1455adda8d3339c8ee63be78df0/keras-cv-attention-models-1.0.21.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.22": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "78acf76a3a5a002db20a31bc181c7f981cd9ac7959f50609a08145d29a43adf9",
          "md5": "80a2f8b8dd856d95734854d1c3a78f16",
          "sha256": "56342ff7540e63f86df339d1886c51377fb53edd5896ed6bea35a2cc3052ca77"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.0.22-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "80a2f8b8dd856d95734854d1c3a78f16",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 130829,
        "upload_time": "2021-11-02T08:48:26",
        "upload_time_iso_8601": "2021-11-02T08:48:26.809172Z",
        "url": "https://files.pythonhosted.org/packages/78/ac/f76a3a5a002db20a31bc181c7f981cd9ac7959f50609a08145d29a43adf9/keras_cv_attention_models-1.0.22-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0bd31d8583a0d1214a6f4a4ff55748ee6c539319e73167b2c21b600d5cec2891",
          "md5": "50638e2b6a2e069b4559517f3c57aee1",
          "sha256": "41e24427d06ebfe604f8ef2540b1819987f14d9052f51e99723821696e18020d"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.0.22.tar.gz",
        "has_sig": false,
        "md5_digest": "50638e2b6a2e069b4559517f3c57aee1",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 114788,
        "upload_time": "2021-11-02T08:48:28",
        "upload_time_iso_8601": "2021-11-02T08:48:28.143364Z",
        "url": "https://files.pythonhosted.org/packages/0b/d3/1d8583a0d1214a6f4a4ff55748ee6c539319e73167b2c21b600d5cec2891/keras-cv-attention-models-1.0.22.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "268096a2aa6a6708cb84fb3f172b7acfa9bb85db462ad99aefd141d2409ee7a4",
          "md5": "608103e8cf7b7dbc8c26d53cfcc47529",
          "sha256": "148c6fe06359602de7f555627d068b59e4c01090e84489f12c7fb33f0a29f241"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "608103e8cf7b7dbc8c26d53cfcc47529",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 84792,
        "upload_time": "2021-09-01T04:59:59",
        "upload_time_iso_8601": "2021-09-01T04:59:59.839330Z",
        "url": "https://files.pythonhosted.org/packages/26/80/96a2aa6a6708cb84fb3f172b7acfa9bb85db462ad99aefd141d2409ee7a4/keras_cv_attention_models-1.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c898f08d145b11d29de609b817db7a981c90eed7d2521d433dbab83e1a3697d5",
          "md5": "4dda481ffd3cadd82c2e4110bb2fc6d8",
          "sha256": "a31b37abf4dab399fffc2d50eed0a0b98e9985103b36a6ae64b6cf71bc53c521"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "4dda481ffd3cadd82c2e4110bb2fc6d8",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 67440,
        "upload_time": "2021-09-01T05:00:02",
        "upload_time_iso_8601": "2021-09-01T05:00:02.095247Z",
        "url": "https://files.pythonhosted.org/packages/c8/98/f08d145b11d29de609b817db7a981c90eed7d2521d433dbab83e1a3697d5/keras-cv-attention-models-1.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "48ca5fb7ecd1f25710ae98d2705d634858c7c765a6e6971736617f011beeee91",
          "md5": "0696b7f29bd82efd5d61d27a0808ba20",
          "sha256": "e9ac6726f8ab3aa6655412a97b0b5eb955fe7a1edc77315441bb3cc677b424d7"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.0.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0696b7f29bd82efd5d61d27a0808ba20",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 99840,
        "upload_time": "2021-09-01T08:34:09",
        "upload_time_iso_8601": "2021-09-01T08:34:09.379907Z",
        "url": "https://files.pythonhosted.org/packages/48/ca/5fb7ecd1f25710ae98d2705d634858c7c765a6e6971736617f011beeee91/keras_cv_attention_models-1.0.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bb33c7b1ea21282ad3902a59acf275ff4f4cd5021760251e709224c7458c558b",
          "md5": "fade9b1bb627bd1476e54fdfdd4a426b",
          "sha256": "b76b758c667ef2511e191f2e7fbcd3c1dcb9842a12525fbcf92b7aa44de53b5c"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "fade9b1bb627bd1476e54fdfdd4a426b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 81931,
        "upload_time": "2021-09-01T08:34:11",
        "upload_time_iso_8601": "2021-09-01T08:34:11.330783Z",
        "url": "https://files.pythonhosted.org/packages/bb/33/c7b1ea21282ad3902a59acf275ff4f4cd5021760251e709224c7458c558b/keras-cv-attention-models-1.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "abb7ba64682d6853dd372c0fbbb6f3b5fc0b94d763f315ffa1eefba8fb821572",
          "md5": "63a43c3667f3f9b57e50067b288b2ac7",
          "sha256": "a5581541008be9e4a00451696aab83e6e0995b8eba7414882742712d7c07bd35"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.0.6-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "63a43c3667f3f9b57e50067b288b2ac7",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 98551,
        "upload_time": "2021-09-02T11:25:35",
        "upload_time_iso_8601": "2021-09-02T11:25:35.174775Z",
        "url": "https://files.pythonhosted.org/packages/ab/b7/ba64682d6853dd372c0fbbb6f3b5fc0b94d763f315ffa1eefba8fb821572/keras_cv_attention_models-1.0.6-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cd3c5ce09163f0f0fef46511b1b081a1b38ab77709fea28ba2e41bc6ed04226e",
          "md5": "ae637faa5d1b474625031bf0e80eb026",
          "sha256": "0adb21a999bcad726eceb9c8cc1ad5c010411da2c333ae23aebc53b4243d11e0"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.0.6.tar.gz",
        "has_sig": false,
        "md5_digest": "ae637faa5d1b474625031bf0e80eb026",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 80610,
        "upload_time": "2021-09-02T11:25:36",
        "upload_time_iso_8601": "2021-09-02T11:25:36.540644Z",
        "url": "https://files.pythonhosted.org/packages/cd/3c/5ce09163f0f0fef46511b1b081a1b38ab77709fea28ba2e41bc6ed04226e/keras-cv-attention-models-1.0.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b9665b2bb2de6cba5fa4aad19f6332fec57c1ba4b3ec2ba8e9fb817cd55bb35c",
          "md5": "50902a48e5ab78817253d98c896e8567",
          "sha256": "d669e1bb022d87cb5b0a967ae88f56c13fcebac6a4454c8fff58b09fc8b8a18f"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.0.7-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "50902a48e5ab78817253d98c896e8567",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 102568,
        "upload_time": "2021-09-06T09:16:57",
        "upload_time_iso_8601": "2021-09-06T09:16:57.581001Z",
        "url": "https://files.pythonhosted.org/packages/b9/66/5b2bb2de6cba5fa4aad19f6332fec57c1ba4b3ec2ba8e9fb817cd55bb35c/keras_cv_attention_models-1.0.7-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ca5113a8d1b70bc6384979ab5f8fcbdc7bc4dd0a62fc760b5b2fa8c23bc4fdd2",
          "md5": "9b728288745c257376978c382865af2d",
          "sha256": "e387b45b34b363a1bdf817b3c508119bf247830d49934499e2157836382bb0ed"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.0.7.tar.gz",
        "has_sig": false,
        "md5_digest": "9b728288745c257376978c382865af2d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 83162,
        "upload_time": "2021-09-06T09:16:59",
        "upload_time_iso_8601": "2021-09-06T09:16:59.003209Z",
        "url": "https://files.pythonhosted.org/packages/ca/51/13a8d1b70bc6384979ab5f8fcbdc7bc4dd0a62fc760b5b2fa8c23bc4fdd2/keras-cv-attention-models-1.0.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f1044988116b39902976f900aef49eaf784f891afa377eab30059487c7a819ed",
          "md5": "ff1cad0c9e7e73a8327e1557cd8b18c9",
          "sha256": "aef8dddf025271b815c1bdd69209e0127fe6d1165faf13a2ccaa98a64c492a61"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.0.8-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ff1cad0c9e7e73a8327e1557cd8b18c9",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 107954,
        "upload_time": "2021-09-14T02:59:00",
        "upload_time_iso_8601": "2021-09-14T02:59:00.938945Z",
        "url": "https://files.pythonhosted.org/packages/f1/04/4988116b39902976f900aef49eaf784f891afa377eab30059487c7a819ed/keras_cv_attention_models-1.0.8-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ee7ba11fdc16ce9db636f419f7ed0b78af3e8dcd80b6d3748813b37a122b13c3",
          "md5": "2613341b8741a50099df204adcd767f7",
          "sha256": "37a72ebd70a22b9937664ada2bd94b2054d8f319fea6ebdc87bf36db90626398"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.0.8.tar.gz",
        "has_sig": false,
        "md5_digest": "2613341b8741a50099df204adcd767f7",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 88759,
        "upload_time": "2021-09-14T02:59:02",
        "upload_time_iso_8601": "2021-09-14T02:59:02.330982Z",
        "url": "https://files.pythonhosted.org/packages/ee/7b/a11fdc16ce9db636f419f7ed0b78af3e8dcd80b6d3748813b37a122b13c3/keras-cv-attention-models-1.0.8.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.9": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a1342c1bef16a17cb9c6f706c7715df55e0bf6de526a15f1f6cc4a14da3dfe51",
          "md5": "6a6144466cfbbc4a5967a405fe773778",
          "sha256": "9dcb6918ddca2a14bf7109da3911461afdbf6017b1d1fa721511a353fbebc127"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.0.9-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "6a6144466cfbbc4a5967a405fe773778",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 111957,
        "upload_time": "2021-09-26T10:25:23",
        "upload_time_iso_8601": "2021-09-26T10:25:23.536819Z",
        "url": "https://files.pythonhosted.org/packages/a1/34/2c1bef16a17cb9c6f706c7715df55e0bf6de526a15f1f6cc4a14da3dfe51/keras_cv_attention_models-1.0.9-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "770d6fcd02793edd41ac4f3132176e28af0956394735a411b7d0c8878dbf615a",
          "md5": "9b81f61a09fb026e683f5f8efee3ae28",
          "sha256": "541f252c6d98ece51513abf2fb23970dc431394df2d4e9a6dfdd1da33a074cdc"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.0.9.tar.gz",
        "has_sig": false,
        "md5_digest": "9b81f61a09fb026e683f5f8efee3ae28",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 92116,
        "upload_time": "2021-09-26T10:25:24",
        "upload_time_iso_8601": "2021-09-26T10:25:24.868789Z",
        "url": "https://files.pythonhosted.org/packages/77/0d/6fcd02793edd41ac4f3132176e28af0956394735a411b7d0c8878dbf615a/keras-cv-attention-models-1.0.9.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "05d9caabf9ae0dbc4526efccc02895429a5e139af4a030859906a112a1722235",
          "md5": "965e411d3bc0bc3a2b9e1a5cc0b7a398",
          "sha256": "3d9d44672ea93c62833d90857070a63154ee0e6fa3cf08a637111a0b0317cb6f"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "965e411d3bc0bc3a2b9e1a5cc0b7a398",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 134576,
        "upload_time": "2021-11-10T10:48:24",
        "upload_time_iso_8601": "2021-11-10T10:48:24.830726Z",
        "url": "https://files.pythonhosted.org/packages/05/d9/caabf9ae0dbc4526efccc02895429a5e139af4a030859906a112a1722235/keras_cv_attention_models-1.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e5f9a1d804a8dc52f0f1610cfb9164d314f497aeec3a40480c8b309780550734",
          "md5": "b85b85f7daadcea051b82c0d57bea79b",
          "sha256": "85f4a7b77bb06271e1545d9d538ad7601d48c1c9f426995fce466ab75b2aa641"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "b85b85f7daadcea051b82c0d57bea79b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 118225,
        "upload_time": "2021-11-10T10:48:26",
        "upload_time_iso_8601": "2021-11-10T10:48:26.556895Z",
        "url": "https://files.pythonhosted.org/packages/e5/f9/a1d804a8dc52f0f1610cfb9164d314f497aeec3a40480c8b309780550734/keras-cv-attention-models-1.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "00a00e4de495fdec03ac52e5a707b1ca9781b8f85539b52ef93ef47c2c134c7c",
          "md5": "b129c7258bef46c68d70a232d59c7b54",
          "sha256": "bc1ed80bcacc884f63c94589942264aff6ae58d5721d2bfa0fab1ca633176ca1"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "b129c7258bef46c68d70a232d59c7b54",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 134733,
        "upload_time": "2021-11-16T00:46:09",
        "upload_time_iso_8601": "2021-11-16T00:46:09.907112Z",
        "url": "https://files.pythonhosted.org/packages/00/a0/0e4de495fdec03ac52e5a707b1ca9781b8f85539b52ef93ef47c2c134c7c/keras_cv_attention_models-1.1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bbe53b9fb95715233110cc08ea68278353ee6cdcc4943de8a41606b09a5fda1c",
          "md5": "c697ccff94725c1bb34da486b04d4331",
          "sha256": "a9870b382805b3a9162b001b3c4c4836751b496536d30fca02af2a2cfbba17c4"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "c697ccff94725c1bb34da486b04d4331",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 118583,
        "upload_time": "2021-11-16T00:46:11",
        "upload_time_iso_8601": "2021-11-16T00:46:11.255634Z",
        "url": "https://files.pythonhosted.org/packages/bb/e5/3b9fb95715233110cc08ea68278353ee6cdcc4943de8a41606b09a5fda1c/keras-cv-attention-models-1.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.10": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "335e72bb8a6b35dba5cbb40d26f0351ccee4ef6698110923cf77dbad23909e98",
          "md5": "6e042feb353f8a33425ea0975a8146a5",
          "sha256": "4a9e640471f1b0834d29968760584111515984396a17b65e841a93302a0ed9fa"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.1.10-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "6e042feb353f8a33425ea0975a8146a5",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 164094,
        "upload_time": "2021-12-24T07:56:10",
        "upload_time_iso_8601": "2021-12-24T07:56:10.153156Z",
        "url": "https://files.pythonhosted.org/packages/33/5e/72bb8a6b35dba5cbb40d26f0351ccee4ef6698110923cf77dbad23909e98/keras_cv_attention_models-1.1.10-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3988ae17cb7dbea35bccc4f7baf46c4633513c20a8d00e584ee28e021a1ee7fd",
          "md5": "81d703c88fc4274e425d6913c7ec4361",
          "sha256": "253319a1362a2401535808a864436face28b6b9d630c74161ffcd48a679ff2b9"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.1.10.tar.gz",
        "has_sig": false,
        "md5_digest": "81d703c88fc4274e425d6913c7ec4361",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 147326,
        "upload_time": "2021-12-24T07:56:12",
        "upload_time_iso_8601": "2021-12-24T07:56:12.027437Z",
        "url": "https://files.pythonhosted.org/packages/39/88/ae17cb7dbea35bccc4f7baf46c4633513c20a8d00e584ee28e021a1ee7fd/keras-cv-attention-models-1.1.10.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.11": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0d8a241570f1e5846cb261ae6c414e7e6004581a96c1328e8a8713e2642bbe65",
          "md5": "3dc7ef1d05ff58a93be69424e10739f7",
          "sha256": "6a9cd0e40d672ae89f86e266d087181e715958ce781c79fad4d7659250e8f0f1"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.1.11-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "3dc7ef1d05ff58a93be69424e10739f7",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 164034,
        "upload_time": "2021-12-27T11:05:34",
        "upload_time_iso_8601": "2021-12-27T11:05:34.579568Z",
        "url": "https://files.pythonhosted.org/packages/0d/8a/241570f1e5846cb261ae6c414e7e6004581a96c1328e8a8713e2642bbe65/keras_cv_attention_models-1.1.11-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6863a808a67e9581bd284d439ed0df91b0a622daf875a6acdb4ff4506becd848",
          "md5": "a464fa06113e351c75b3554d25af8d8f",
          "sha256": "d7bde014e56aa91ac52dfcffa8fe960d19aa581a10dbc8e4a5898c2a58f857b3"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.1.11.tar.gz",
        "has_sig": false,
        "md5_digest": "a464fa06113e351c75b3554d25af8d8f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 147402,
        "upload_time": "2021-12-27T11:05:36",
        "upload_time_iso_8601": "2021-12-27T11:05:36.427027Z",
        "url": "https://files.pythonhosted.org/packages/68/63/a808a67e9581bd284d439ed0df91b0a622daf875a6acdb4ff4506becd848/keras-cv-attention-models-1.1.11.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.12": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fe67a45444e37b7bcbaec3db5c82e24c363f3e762dc42e50ab9627b17f8f7520",
          "md5": "7783a6c3cde5a3ad6fd55369bc34ce45",
          "sha256": "9927c047a4ed323b42036486b393d25dcf3a425dab0963b1829f18efcd034671"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.1.12-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "7783a6c3cde5a3ad6fd55369bc34ce45",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 162603,
        "upload_time": "2021-12-30T08:09:52",
        "upload_time_iso_8601": "2021-12-30T08:09:52.331701Z",
        "url": "https://files.pythonhosted.org/packages/fe/67/a45444e37b7bcbaec3db5c82e24c363f3e762dc42e50ab9627b17f8f7520/keras_cv_attention_models-1.1.12-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fa2071e5c90a8bdaf22d6df8ce4f822450d39cb39dd0bc7d602564da546b8392",
          "md5": "2ea18832f77b65011bf2f719d4767f02",
          "sha256": "6a58559bd82a3777cd1c378842c09e1b46204815eb823a720dc1acace18d7fd6"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.1.12.tar.gz",
        "has_sig": false,
        "md5_digest": "2ea18832f77b65011bf2f719d4767f02",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 147400,
        "upload_time": "2021-12-30T08:09:54",
        "upload_time_iso_8601": "2021-12-30T08:09:54.556998Z",
        "url": "https://files.pythonhosted.org/packages/fa/20/71e5c90a8bdaf22d6df8ce4f822450d39cb39dd0bc7d602564da546b8392/keras-cv-attention-models-1.1.12.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.13": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1225effeafd40b9b5fc51055e752e96cba2c9eeb452268ecee973b54786ae424",
          "md5": "72f176baaee5444cb968e943007a4afe",
          "sha256": "e9ce00fad10a008396dc5264b58de9aa01649d38c4d05d0e6c1b00659a46f099"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.1.13-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "72f176baaee5444cb968e943007a4afe",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 162840,
        "upload_time": "2022-01-02T08:39:18",
        "upload_time_iso_8601": "2022-01-02T08:39:18.987363Z",
        "url": "https://files.pythonhosted.org/packages/12/25/effeafd40b9b5fc51055e752e96cba2c9eeb452268ecee973b54786ae424/keras_cv_attention_models-1.1.13-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c8dfab07167a96f162d5648268f2f9291fb75cf648902506ef6557c5dfd280d9",
          "md5": "96a0e8be9d0cec8e6433423dbe53d90d",
          "sha256": "30b1abb85b9df8686a9877ed9bbbda9a3e660326d5158477c1653e81fbc27edd"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.1.13.tar.gz",
        "has_sig": false,
        "md5_digest": "96a0e8be9d0cec8e6433423dbe53d90d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 147603,
        "upload_time": "2022-01-02T08:39:20",
        "upload_time_iso_8601": "2022-01-02T08:39:20.790738Z",
        "url": "https://files.pythonhosted.org/packages/c8/df/ab07167a96f162d5648268f2f9291fb75cf648902506ef6557c5dfd280d9/keras-cv-attention-models-1.1.13.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.14": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b4c203ba52442232f393db1fd99dbe0316b288f3290f5a63de6cb937055ab4e5",
          "md5": "38ed740904dbe62fe4a2e6f6587676f1",
          "sha256": "a0ec1f6c23b3bbb804d2e54bf3c687e652d57bc115d5d2f3c14df3a8f143ca43"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.1.14-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "38ed740904dbe62fe4a2e6f6587676f1",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 163176,
        "upload_time": "2022-01-04T11:04:11",
        "upload_time_iso_8601": "2022-01-04T11:04:11.598006Z",
        "url": "https://files.pythonhosted.org/packages/b4/c2/03ba52442232f393db1fd99dbe0316b288f3290f5a63de6cb937055ab4e5/keras_cv_attention_models-1.1.14-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ea60e6d4ce0374080ebf0a9329c21c1916eff2be85760465c5fd1b0c9731584d",
          "md5": "d9946f9cb6a19aa794c1671ae18cf771",
          "sha256": "c24d4d872b008007435f4c17f93ef38666f081f528cc367984d8272e5d3e6fa4"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.1.14.tar.gz",
        "has_sig": false,
        "md5_digest": "d9946f9cb6a19aa794c1671ae18cf771",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 147915,
        "upload_time": "2022-01-04T11:04:13",
        "upload_time_iso_8601": "2022-01-04T11:04:13.440493Z",
        "url": "https://files.pythonhosted.org/packages/ea/60/e6d4ce0374080ebf0a9329c21c1916eff2be85760465c5fd1b0c9731584d/keras-cv-attention-models-1.1.14.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.15": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "011bede253b07c730e20c5477106acb20981b3178266ac50d0c1399520e76e6d",
          "md5": "275439bc5a2f399d49d12930b4547d10",
          "sha256": "ef5e2b091aebbda3e937e3e5f6de72c7e6a43bb1c28426394733b2023bcb1e96"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.1.15-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "275439bc5a2f399d49d12930b4547d10",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 349065,
        "upload_time": "2022-01-05T10:26:11",
        "upload_time_iso_8601": "2022-01-05T10:26:11.799386Z",
        "url": "https://files.pythonhosted.org/packages/01/1b/ede253b07c730e20c5477106acb20981b3178266ac50d0c1399520e76e6d/keras_cv_attention_models-1.1.15-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f148fda4484b247fc4577cfd6172cb5fd803dd87ab751ed83ded509af177912f",
          "md5": "265e5d3d5e2c7eca77d5d3640ec7e5f1",
          "sha256": "2a61bfc78e16f19795865cd5fa96bf82ceca469f13ee5df8776ba838c8da8c4e"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.1.15.tar.gz",
        "has_sig": false,
        "md5_digest": "265e5d3d5e2c7eca77d5d3640ec7e5f1",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 328023,
        "upload_time": "2022-01-05T10:26:13",
        "upload_time_iso_8601": "2022-01-05T10:26:13.856247Z",
        "url": "https://files.pythonhosted.org/packages/f1/48/fda4484b247fc4577cfd6172cb5fd803dd87ab751ed83ded509af177912f/keras-cv-attention-models-1.1.15.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.16": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9d9544c3a63738bf8d777518e0f2b738e2e314e6db7f7d798cc0c59bdffee018",
          "md5": "0767729a09760bb7266b41f121ae3e6c",
          "sha256": "cd43958b410541866a6f13abdd71c250849f6e0bfc6982d5078d92268ca0d2f9"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.1.16-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0767729a09760bb7266b41f121ae3e6c",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 357344,
        "upload_time": "2022-01-08T05:48:19",
        "upload_time_iso_8601": "2022-01-08T05:48:19.719885Z",
        "url": "https://files.pythonhosted.org/packages/9d/95/44c3a63738bf8d777518e0f2b738e2e314e6db7f7d798cc0c59bdffee018/keras_cv_attention_models-1.1.16-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "07050b6354464adaf04f239f0626d19a81f2f45ce603b7a7f585456f245ddb14",
          "md5": "a371a828ae6a0d557bf0454c956cc521",
          "sha256": "19632dae79b5ce53d9f9da13f1c46f77ca2ab3b8012b027b69767188511e9d18"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.1.16.tar.gz",
        "has_sig": false,
        "md5_digest": "a371a828ae6a0d557bf0454c956cc521",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 335910,
        "upload_time": "2022-01-08T05:48:21",
        "upload_time_iso_8601": "2022-01-08T05:48:21.757085Z",
        "url": "https://files.pythonhosted.org/packages/07/05/0b6354464adaf04f239f0626d19a81f2f45ce603b7a7f585456f245ddb14/keras-cv-attention-models-1.1.16.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.17": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "58e0c995becb12c56c96eb13911c6d3c7598ee19c16707ea566920d1e5977df4",
          "md5": "fb70ebca449b972bfe4abbee4cc9363d",
          "sha256": "983a01fbd49887565ec66721d2ec1889d6c2a7c598b74e7adf46259ab7955e96"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.1.17-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "fb70ebca449b972bfe4abbee4cc9363d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 362921,
        "upload_time": "2022-01-12T07:04:46",
        "upload_time_iso_8601": "2022-01-12T07:04:46.673664Z",
        "url": "https://files.pythonhosted.org/packages/58/e0/c995becb12c56c96eb13911c6d3c7598ee19c16707ea566920d1e5977df4/keras_cv_attention_models-1.1.17-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bd3345cbc3b09968508c738d39bbd756ff1729cee4146f087e0614d2538a74f4",
          "md5": "ba4800aa3421b74337f79dcfd40a9143",
          "sha256": "f1ac2a02f9ff58031609517341bc8b74909686add0a5503d404f3a6d2b6999a9"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.1.17.tar.gz",
        "has_sig": false,
        "md5_digest": "ba4800aa3421b74337f79dcfd40a9143",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 339988,
        "upload_time": "2022-01-12T07:04:48",
        "upload_time_iso_8601": "2022-01-12T07:04:48.415854Z",
        "url": "https://files.pythonhosted.org/packages/bd/33/45cbc3b09968508c738d39bbd756ff1729cee4146f087e0614d2538a74f4/keras-cv-attention-models-1.1.17.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.18": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9e1b20cfc16b20e616ea50d998a8e3e3affe890813a41f22e165d5ac9fc1f70e",
          "md5": "99d34a5d1e184e82e39812f96fd00ccb",
          "sha256": "9ba7cc09e45ed0237e64f270df81dc63a40bdd9eb370947f3c813275a8e574a0"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.1.18-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "99d34a5d1e184e82e39812f96fd00ccb",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 363249,
        "upload_time": "2022-01-12T10:09:29",
        "upload_time_iso_8601": "2022-01-12T10:09:29.908296Z",
        "url": "https://files.pythonhosted.org/packages/9e/1b/20cfc16b20e616ea50d998a8e3e3affe890813a41f22e165d5ac9fc1f70e/keras_cv_attention_models-1.1.18-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "11d01cca42dd25c13bf20fb6aabe3e9578097f9ee1b2ab22615bbefe6a30daa1",
          "md5": "f3d76955aa732408341002b10ff83991",
          "sha256": "749f59f9a9a74ab87f5d5904e819132da8f035131ab5a04da8c3962d5c282eed"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.1.18.tar.gz",
        "has_sig": false,
        "md5_digest": "f3d76955aa732408341002b10ff83991",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 340398,
        "upload_time": "2022-01-12T10:09:31",
        "upload_time_iso_8601": "2022-01-12T10:09:31.641172Z",
        "url": "https://files.pythonhosted.org/packages/11/d0/1cca42dd25c13bf20fb6aabe3e9578097f9ee1b2ab22615bbefe6a30daa1/keras-cv-attention-models-1.1.18.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.19": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "667da8ce7be8a0e916bf9364047b1bdd1c2e535b46cf2294690f9eadaf660535",
          "md5": "8eac614c3dcc94af9675d91159a08dd8",
          "sha256": "9e0d21473601a70ff4f5eeb12ea9abfe82d3547d1652cc3feccfc7d2e1b34601"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.1.19-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "8eac614c3dcc94af9675d91159a08dd8",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 363948,
        "upload_time": "2022-01-13T10:20:46",
        "upload_time_iso_8601": "2022-01-13T10:20:46.377648Z",
        "url": "https://files.pythonhosted.org/packages/66/7d/a8ce7be8a0e916bf9364047b1bdd1c2e535b46cf2294690f9eadaf660535/keras_cv_attention_models-1.1.19-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "59736205cbc9cc37a5e64e24d4a31b83f1677aef134a9ab53076b2e7123bdda9",
          "md5": "0281edec1f9b8da46fe00b9d06671667",
          "sha256": "adaf6db0563086895f2349089e92816c370deef4e5e4c756f8a53025a5175c94"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.1.19.tar.gz",
        "has_sig": false,
        "md5_digest": "0281edec1f9b8da46fe00b9d06671667",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 341037,
        "upload_time": "2022-01-13T10:20:48",
        "upload_time_iso_8601": "2022-01-13T10:20:48.028440Z",
        "url": "https://files.pythonhosted.org/packages/59/73/6205cbc9cc37a5e64e24d4a31b83f1677aef134a9ab53076b2e7123bdda9/keras-cv-attention-models-1.1.19.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4e47e9f6a04bbd433e7b434d7c2959a2c4fa4a89dd257584d867fef7810c5ba8",
          "md5": "ce07c2001d610608b70fe1ecdf4aba50",
          "sha256": "673da5c928b9affd0350048c8483c10c119d9e46616e90f215173ed446000781"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.1.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ce07c2001d610608b70fe1ecdf4aba50",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 135125,
        "upload_time": "2021-11-16T07:16:44",
        "upload_time_iso_8601": "2021-11-16T07:16:44.966672Z",
        "url": "https://files.pythonhosted.org/packages/4e/47/e9f6a04bbd433e7b434d7c2959a2c4fa4a89dd257584d867fef7810c5ba8/keras_cv_attention_models-1.1.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f02fae85349a2633e7e7928e1a0ba8c564237c08459840f8244e6b53c7f3fdc9",
          "md5": "b3edd743f36a023707e1c0c94dd85f92",
          "sha256": "b4ed908d72f47386448eaf76e70021e346365b93b8acba65fe5f2789953f5331"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "b3edd743f36a023707e1c0c94dd85f92",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 116117,
        "upload_time": "2021-11-16T07:16:46",
        "upload_time_iso_8601": "2021-11-16T07:16:46.207398Z",
        "url": "https://files.pythonhosted.org/packages/f0/2f/ae85349a2633e7e7928e1a0ba8c564237c08459840f8244e6b53c7f3fdc9/keras-cv-attention-models-1.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.20": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ee47fb591d38bd444004c161d2c9b62eea92c6558a3f2d4bd50e8b09d26fb2d1",
          "md5": "ff5f317b869a65bf91399e8ed90b9932",
          "sha256": "a1c04d5c474926997a269611b47265f5015b62cf7e330b68cba7fc44a53bede4"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.1.20-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ff5f317b869a65bf91399e8ed90b9932",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 364986,
        "upload_time": "2022-01-25T11:15:22",
        "upload_time_iso_8601": "2022-01-25T11:15:22.558412Z",
        "url": "https://files.pythonhosted.org/packages/ee/47/fb591d38bd444004c161d2c9b62eea92c6558a3f2d4bd50e8b09d26fb2d1/keras_cv_attention_models-1.1.20-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ee636cdfb110e1e436a332705ce04fd6a5c06f6086aa0cb3e93fc08026164000",
          "md5": "58ebd670b02af19b4fce96997eddf053",
          "sha256": "5a284e5232fc666ece5ee4d6c1b756de4ee9581e6a4247cedbc102979c7b0ad9"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.1.20.tar.gz",
        "has_sig": false,
        "md5_digest": "58ebd670b02af19b4fce96997eddf053",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 341907,
        "upload_time": "2022-01-25T11:15:25",
        "upload_time_iso_8601": "2022-01-25T11:15:25.171435Z",
        "url": "https://files.pythonhosted.org/packages/ee/63/6cdfb110e1e436a332705ce04fd6a5c06f6086aa0cb3e93fc08026164000/keras-cv-attention-models-1.1.20.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0226dbb4859ef15efd4b8a76b5274556b528b2902be369148f90627b535598ec",
          "md5": "54e0a543e3ef1ed92de1f1802d9873b0",
          "sha256": "d50186ad0ba7a83391001c02c2d2ad7e9a81b64b70051806f7188ca44c16f58e"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.1.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "54e0a543e3ef1ed92de1f1802d9873b0",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 137746,
        "upload_time": "2021-11-29T10:54:17",
        "upload_time_iso_8601": "2021-11-29T10:54:17.437168Z",
        "url": "https://files.pythonhosted.org/packages/02/26/dbb4859ef15efd4b8a76b5274556b528b2902be369148f90627b535598ec/keras_cv_attention_models-1.1.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "26def17fb8d1dd49e236e9e6bac3403cfddb4c0245afa00b68347137f2af5535",
          "md5": "5cbb849f9297dfc3ef38746a78be5257",
          "sha256": "b646e3964418d7760ade3a7adfc13112adf1ae85c6186befd31d58999d56cc16"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.1.3.tar.gz",
        "has_sig": false,
        "md5_digest": "5cbb849f9297dfc3ef38746a78be5257",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 118565,
        "upload_time": "2021-11-29T10:54:18",
        "upload_time_iso_8601": "2021-11-29T10:54:18.608995Z",
        "url": "https://files.pythonhosted.org/packages/26/de/f17fb8d1dd49e236e9e6bac3403cfddb4c0245afa00b68347137f2af5535/keras-cv-attention-models-1.1.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a379ce8a694ad6a97ecc6af84234f495b0166b216ec48debbdcf1f941d2f9c4b",
          "md5": "e2d1acdc1b0d42c0456b9f56234981e9",
          "sha256": "161acc3d7de6182a1256ca2692dae885da17d0f8edb39cc51f3993e9d3447aaf"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.1.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "e2d1acdc1b0d42c0456b9f56234981e9",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 138342,
        "upload_time": "2021-12-07T02:37:02",
        "upload_time_iso_8601": "2021-12-07T02:37:02.271565Z",
        "url": "https://files.pythonhosted.org/packages/a3/79/ce8a694ad6a97ecc6af84234f495b0166b216ec48debbdcf1f941d2f9c4b/keras_cv_attention_models-1.1.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5af32d0642a5734a2b5b5a855814d42a6360b930be7917db9160bba071032f9b",
          "md5": "8f50e0649b0dcfe94cb2453c66688690",
          "sha256": "7dcdc4f09cc5a2ae97b808efc93043ea3048dd0a6c96c3fa473a464a4b95dae2"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.1.4.tar.gz",
        "has_sig": false,
        "md5_digest": "8f50e0649b0dcfe94cb2453c66688690",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 119623,
        "upload_time": "2021-12-07T02:37:03",
        "upload_time_iso_8601": "2021-12-07T02:37:03.787906Z",
        "url": "https://files.pythonhosted.org/packages/5a/f3/2d0642a5734a2b5b5a855814d42a6360b930be7917db9160bba071032f9b/keras-cv-attention-models-1.1.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0fa4ecc49459a57d847def3f0804f344348ddd080f86f15b3d62a0f3581dd7ad",
          "md5": "0ef33c6763617df5a6bb35a0622a4fe3",
          "sha256": "bc4adc7e06b8a68591030e32f69ba1ac3866f5e9f55942f25e1c220bed1e9738"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.1.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0ef33c6763617df5a6bb35a0622a4fe3",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 138565,
        "upload_time": "2021-12-13T03:08:05",
        "upload_time_iso_8601": "2021-12-13T03:08:05.170984Z",
        "url": "https://files.pythonhosted.org/packages/0f/a4/ecc49459a57d847def3f0804f344348ddd080f86f15b3d62a0f3581dd7ad/keras_cv_attention_models-1.1.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "93a368b27fc2a595036814900cc17f4065f09cbb5caa40e2c1c20b56700e08c0",
          "md5": "d42f9b1f0d7f4b191d17f2551ca64474",
          "sha256": "e47bdb383b034179a74b8b9a65e99ea5ea965aa1e7c080257f77eaf5de29720e"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.1.5.tar.gz",
        "has_sig": false,
        "md5_digest": "d42f9b1f0d7f4b191d17f2551ca64474",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 120135,
        "upload_time": "2021-12-13T03:08:06",
        "upload_time_iso_8601": "2021-12-13T03:08:06.617645Z",
        "url": "https://files.pythonhosted.org/packages/93/a3/68b27fc2a595036814900cc17f4065f09cbb5caa40e2c1c20b56700e08c0/keras-cv-attention-models-1.1.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "66913ca41aacdf1f23ae71f3114d5ca262fb829bc402adf0445e2443f0fedb8a",
          "md5": "f328dbd7461c8fe7e367eb261e0b5cfd",
          "sha256": "66772ad4e052e8dd1562c984ffb5e3be20856e0450c855803b21687d144427e7"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.1.6-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f328dbd7461c8fe7e367eb261e0b5cfd",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 139360,
        "upload_time": "2021-12-14T11:26:27",
        "upload_time_iso_8601": "2021-12-14T11:26:27.700488Z",
        "url": "https://files.pythonhosted.org/packages/66/91/3ca41aacdf1f23ae71f3114d5ca262fb829bc402adf0445e2443f0fedb8a/keras_cv_attention_models-1.1.6-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fe8a71c06540abddc17d627853c74fac8fdc866b1143370b03cb0277dbeae831",
          "md5": "5abe9c49303bac39416e9c8534365089",
          "sha256": "70b63ef6f5d62174180b0fc6c75b0c9fb8ed26b4776958874843ef619316f956"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.1.6.tar.gz",
        "has_sig": false,
        "md5_digest": "5abe9c49303bac39416e9c8534365089",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 121479,
        "upload_time": "2021-12-14T11:26:29",
        "upload_time_iso_8601": "2021-12-14T11:26:29.213253Z",
        "url": "https://files.pythonhosted.org/packages/fe/8a/71c06540abddc17d627853c74fac8fdc866b1143370b03cb0277dbeae831/keras-cv-attention-models-1.1.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0accebd9211a4050b5f8d053599f00b6c7f55ecef228d12490e6460a021d104d",
          "md5": "2391abe1a9dd4390278e55674a19e551",
          "sha256": "958af35f3298f81d45c7d6835db1b9540f7854be7d79251da6de5df8101fe2f5"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.1.7-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "2391abe1a9dd4390278e55674a19e551",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 140785,
        "upload_time": "2021-12-22T07:00:27",
        "upload_time_iso_8601": "2021-12-22T07:00:27.279350Z",
        "url": "https://files.pythonhosted.org/packages/0a/cc/ebd9211a4050b5f8d053599f00b6c7f55ecef228d12490e6460a021d104d/keras_cv_attention_models-1.1.7-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "facb0e44ad3821a2b616b68aef840a9f329914a12c4456bed6013e1c44ccc7e1",
          "md5": "4968a0c3f768d61e8c25f441e8f004f2",
          "sha256": "6fb7144c561b2378af5449ba8adb3fd4a72ebf5c634bebc1f8bc36854e5ff4fd"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.1.7.tar.gz",
        "has_sig": false,
        "md5_digest": "4968a0c3f768d61e8c25f441e8f004f2",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 122896,
        "upload_time": "2021-12-22T07:00:28",
        "upload_time_iso_8601": "2021-12-22T07:00:28.945256Z",
        "url": "https://files.pythonhosted.org/packages/fa/cb/0e44ad3821a2b616b68aef840a9f329914a12c4456bed6013e1c44ccc7e1/keras-cv-attention-models-1.1.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "87cf3300064face87c955abbb97943562f0c3b41fb10781a51366d3067a5e5e7",
          "md5": "59d21a81224eab556c21e31993262821",
          "sha256": "2388532bc79b431f0ee86baf347251a65c7cd1ad717067a8dcc017e3c29efde3"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.1.8-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "59d21a81224eab556c21e31993262821",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 142400,
        "upload_time": "2021-12-23T02:16:33",
        "upload_time_iso_8601": "2021-12-23T02:16:33.199784Z",
        "url": "https://files.pythonhosted.org/packages/87/cf/3300064face87c955abbb97943562f0c3b41fb10781a51366d3067a5e5e7/keras_cv_attention_models-1.1.8-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4e2728b0fb6f22d91db6e4920bcde9b4c129cad9463e645fa65686bf6988c673",
          "md5": "b1cd3e49cda5f788aa9c128af67a5219",
          "sha256": "8e4badee91c32fa66e65fc9bf8895680dcd8be742db509b726f9d6172024511c"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.1.8.tar.gz",
        "has_sig": false,
        "md5_digest": "b1cd3e49cda5f788aa9c128af67a5219",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 123727,
        "upload_time": "2021-12-23T02:16:34",
        "upload_time_iso_8601": "2021-12-23T02:16:34.670665Z",
        "url": "https://files.pythonhosted.org/packages/4e/27/28b0fb6f22d91db6e4920bcde9b4c129cad9463e645fa65686bf6988c673/keras-cv-attention-models-1.1.8.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.9": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "99827e1f23e426de33944854d1f2f124f4c998f44031a70aaec6feda6655817d",
          "md5": "b0f311a91a2e8bd58f040ff8e7c6bd60",
          "sha256": "1b7fb2c92aa033871ff83023c5e7764f4d29548240f0bbc9786b781a3c5907ca"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.1.9-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "b0f311a91a2e8bd58f040ff8e7c6bd60",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 144734,
        "upload_time": "2021-12-23T11:18:44",
        "upload_time_iso_8601": "2021-12-23T11:18:44.163447Z",
        "url": "https://files.pythonhosted.org/packages/99/82/7e1f23e426de33944854d1f2f124f4c998f44031a70aaec6feda6655817d/keras_cv_attention_models-1.1.9-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "eea5ff8db31f6888a3e083574ffacfc22306d4d54556323065844ec86639a820",
          "md5": "11cc18e69008af58e1e8ecfe15500b66",
          "sha256": "5aa07b6fd671e7bf698be848e38d99c33f1432d5e0904d528b46f544eafd0f05"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.1.9.tar.gz",
        "has_sig": false,
        "md5_digest": "11cc18e69008af58e1e8ecfe15500b66",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 128434,
        "upload_time": "2021-12-23T11:18:46",
        "upload_time_iso_8601": "2021-12-23T11:18:46.191727Z",
        "url": "https://files.pythonhosted.org/packages/ee/a5/ff8db31f6888a3e083574ffacfc22306d4d54556323065844ec86639a820/keras-cv-attention-models-1.1.9.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "df4d764e252e5b8bd8c2b2c556402aa8fbfabacfdbe1dfc8c475e7bff82e8b2f",
          "md5": "f29795ccf0254e0c7e3f5ba6c289773d",
          "sha256": "48aff0a0dfd47c403c3d50f60d3cdccf7db42bef4683dccc9bef53f7e31d5484"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.2.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f29795ccf0254e0c7e3f5ba6c289773d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 370581,
        "upload_time": "2022-01-26T08:00:21",
        "upload_time_iso_8601": "2022-01-26T08:00:21.886636Z",
        "url": "https://files.pythonhosted.org/packages/df/4d/764e252e5b8bd8c2b2c556402aa8fbfabacfdbe1dfc8c475e7bff82e8b2f/keras_cv_attention_models-1.2.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "191b27fea3628fb33e99131deeca8ab715b88950ff3889457cb5cdad6c823676",
          "md5": "deb012d769f4ce5d683d4f046c297f73",
          "sha256": "6ff4c8b94c8d3b54fa1b59211b51d85201c84034e00eaa8aa3c3b8aaa8a45a52"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "deb012d769f4ce5d683d4f046c297f73",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 346591,
        "upload_time": "2022-01-26T08:00:24",
        "upload_time_iso_8601": "2022-01-26T08:00:24.174976Z",
        "url": "https://files.pythonhosted.org/packages/19/1b/27fea3628fb33e99131deeca8ab715b88950ff3889457cb5cdad6c823676/keras-cv-attention-models-1.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6ec120f5cd73c174aa670815f873b6a7b54cca2df14ca6f7abf72b87a8f0ca67",
          "md5": "3bef813ed755e757c82f576c9ac843f0",
          "sha256": "199a6268f281b15e765deadd66477bd7bb7758713551dfa05ed5dde53f4f2d81"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.2.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "3bef813ed755e757c82f576c9ac843f0",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 378366,
        "upload_time": "2022-01-29T09:27:28",
        "upload_time_iso_8601": "2022-01-29T09:27:28.964867Z",
        "url": "https://files.pythonhosted.org/packages/6e/c1/20f5cd73c174aa670815f873b6a7b54cca2df14ca6f7abf72b87a8f0ca67/keras_cv_attention_models-1.2.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9fbb0a9cad2fd66ec8a49d015fb019f02861dc4d215b5ae69805684ee4c08ae2",
          "md5": "7a7fe77197c67f70037f7a20b233d30c",
          "sha256": "49b3d55deacf8b935029edf87ff5a74286c40d635c127d2fb6f698f145b6fe55"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.2.1.tar.gz",
        "has_sig": false,
        "md5_digest": "7a7fe77197c67f70037f7a20b233d30c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 353349,
        "upload_time": "2022-01-29T09:27:30",
        "upload_time_iso_8601": "2022-01-29T09:27:30.793017Z",
        "url": "https://files.pythonhosted.org/packages/9f/bb/0a9cad2fd66ec8a49d015fb019f02861dc4d215b5ae69805684ee4c08ae2/keras-cv-attention-models-1.2.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.10": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "87d25b5b8e645e7724cfdfed95f44a0c5dba686f42e6789c89027b8bf4419b7a",
          "md5": "dac80580c008f02b87dc5b09299b954a",
          "sha256": "9d6e2a52589c238b2c9a1757acc59aa91dbd2f01686dbd416e25009215a9c4fc"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.2.10-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "dac80580c008f02b87dc5b09299b954a",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 413913,
        "upload_time": "2022-03-18T06:47:22",
        "upload_time_iso_8601": "2022-03-18T06:47:22.763993Z",
        "url": "https://files.pythonhosted.org/packages/87/d2/5b5b8e645e7724cfdfed95f44a0c5dba686f42e6789c89027b8bf4419b7a/keras_cv_attention_models-1.2.10-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "33f01e594db23f1a9f1bde53a64ae55afc09d13d72aad4fd1c884733c91edaa9",
          "md5": "c5d27cf4058b9fa76d7c1d5e43553bdd",
          "sha256": "0c2e9eda829d5207bdfb0ffa2bed2c52c373460bb3d0a78f8ae6ed9c52f0083a"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.2.10.tar.gz",
        "has_sig": false,
        "md5_digest": "c5d27cf4058b9fa76d7c1d5e43553bdd",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 385108,
        "upload_time": "2022-03-18T06:47:24",
        "upload_time_iso_8601": "2022-03-18T06:47:24.784944Z",
        "url": "https://files.pythonhosted.org/packages/33/f0/1e594db23f1a9f1bde53a64ae55afc09d13d72aad4fd1c884733c91edaa9/keras-cv-attention-models-1.2.10.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.11": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ebb4178af940ff6b55ae57eea5a28b5c57f82182e9b138675bf85637117a5786",
          "md5": "0d97d5764eb17d77b2a4055d89c03ce5",
          "sha256": "02692b2655738b9bb12b8e528c3c2ad66f575f77cce978ee1445b4217deb61d9"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.2.11-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0d97d5764eb17d77b2a4055d89c03ce5",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 415378,
        "upload_time": "2022-03-19T09:33:46",
        "upload_time_iso_8601": "2022-03-19T09:33:46.543618Z",
        "url": "https://files.pythonhosted.org/packages/eb/b4/178af940ff6b55ae57eea5a28b5c57f82182e9b138675bf85637117a5786/keras_cv_attention_models-1.2.11-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2341a8a5b5a9f85362e6bad629c5691b8f2a972f281377dc22007793b6a24071",
          "md5": "5eee6f1ef3506da4017ab7814b913329",
          "sha256": "135892544ba5611e8c4dd987e861252444546157191b9d072558100ae68048e2"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.2.11.tar.gz",
        "has_sig": false,
        "md5_digest": "5eee6f1ef3506da4017ab7814b913329",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 386911,
        "upload_time": "2022-03-19T09:33:48",
        "upload_time_iso_8601": "2022-03-19T09:33:48.929974Z",
        "url": "https://files.pythonhosted.org/packages/23/41/a8a5b5a9f85362e6bad629c5691b8f2a972f281377dc22007793b6a24071/keras-cv-attention-models-1.2.11.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.12": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "be290cfafeca3ef78aae440f102e64603b6471af57763f3a1084a5f6248214b7",
          "md5": "6a196071f7da611aa33e6aa5251d36fa",
          "sha256": "baa4ad61e44bef2610fbf24dd22dfad38f44cb432fad51b00982d1743bb1608b"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.2.12-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "6a196071f7da611aa33e6aa5251d36fa",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 415826,
        "upload_time": "2022-03-21T10:51:27",
        "upload_time_iso_8601": "2022-03-21T10:51:27.781952Z",
        "url": "https://files.pythonhosted.org/packages/be/29/0cfafeca3ef78aae440f102e64603b6471af57763f3a1084a5f6248214b7/keras_cv_attention_models-1.2.12-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b45239412ac8b59f8f0834d38de965bd739e9b8d12fd158cbbc095a1ec1808e5",
          "md5": "2493e7cb4b73b6b09eada0f197de1997",
          "sha256": "1d3febfa1ca80592b2013e0b08853c6e390de78b8dc99a183135de96fd64df29"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.2.12.tar.gz",
        "has_sig": false,
        "md5_digest": "2493e7cb4b73b6b09eada0f197de1997",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 387398,
        "upload_time": "2022-03-21T10:51:30",
        "upload_time_iso_8601": "2022-03-21T10:51:30.260415Z",
        "url": "https://files.pythonhosted.org/packages/b4/52/39412ac8b59f8f0834d38de965bd739e9b8d12fd158cbbc095a1ec1808e5/keras-cv-attention-models-1.2.12.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.13": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "77ea08fc92a47bb1b8f6fc4af7c08badd3f135acfe14f231453c524cbc5d041e",
          "md5": "0761efc0fe8f486bcd1652a1690963d0",
          "sha256": "6d7dbf6e2fcfa9ba3f75b8c36a59937cfa56193167627e59bf6c171791fd420a"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.2.13-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0761efc0fe8f486bcd1652a1690963d0",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 421437,
        "upload_time": "2022-03-29T12:07:21",
        "upload_time_iso_8601": "2022-03-29T12:07:21.711669Z",
        "url": "https://files.pythonhosted.org/packages/77/ea/08fc92a47bb1b8f6fc4af7c08badd3f135acfe14f231453c524cbc5d041e/keras_cv_attention_models-1.2.13-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9ec9e55b9d7593e5e404dab8200d91bdcb44a6134f08a19990eb2fd9243cc326",
          "md5": "54adefd18c1fcf01f0bde9324676c3d9",
          "sha256": "e9903ab1038546a949c793e28ba9837179b05d676db0fa4f9e4b601df1b400ca"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.2.13.tar.gz",
        "has_sig": false,
        "md5_digest": "54adefd18c1fcf01f0bde9324676c3d9",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 393607,
        "upload_time": "2022-03-29T12:07:23",
        "upload_time_iso_8601": "2022-03-29T12:07:23.759795Z",
        "url": "https://files.pythonhosted.org/packages/9e/c9/e55b9d7593e5e404dab8200d91bdcb44a6134f08a19990eb2fd9243cc326/keras-cv-attention-models-1.2.13.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.14": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "abf883e9b82c662b4a9ca486188c1441c5a14c151c96271d28b9b448aa917424",
          "md5": "d89852aa73036dcff1276052284f9011",
          "sha256": "11902fdadc2b6c07d9e98d7d27582c39c6ed974312d34e0c2a6851a8738669dd"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.2.14-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d89852aa73036dcff1276052284f9011",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 424345,
        "upload_time": "2022-03-30T12:21:01",
        "upload_time_iso_8601": "2022-03-30T12:21:01.626055Z",
        "url": "https://files.pythonhosted.org/packages/ab/f8/83e9b82c662b4a9ca486188c1441c5a14c151c96271d28b9b448aa917424/keras_cv_attention_models-1.2.14-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3e95331507a743f40eaadbb0227a6d8a8a4b90b0d0f5bd49731addae7a7d8b22",
          "md5": "c7880b9f2a233dbf084da5afa3777aad",
          "sha256": "67ab963b1fd05139f5b32c5ddcea3d53393862c0f8c90e295670fc41e76babf1"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.2.14.tar.gz",
        "has_sig": false,
        "md5_digest": "c7880b9f2a233dbf084da5afa3777aad",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 395965,
        "upload_time": "2022-03-30T12:21:03",
        "upload_time_iso_8601": "2022-03-30T12:21:03.336193Z",
        "url": "https://files.pythonhosted.org/packages/3e/95/331507a743f40eaadbb0227a6d8a8a4b90b0d0f5bd49731addae7a7d8b22/keras-cv-attention-models-1.2.14.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.15": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "403695a6ca5d04111d96e73e286cc80ad64d2cfda1330fd6899daffb86d7fba9",
          "md5": "7ef33d6d316b19d51f0eab658aafff93",
          "sha256": "166bf844e71f6355b11112ef8347bf6e4d3edb8e3793ee5d71c188dd44eb0acd"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.2.15-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "7ef33d6d316b19d51f0eab658aafff93",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 430007,
        "upload_time": "2022-04-02T03:17:49",
        "upload_time_iso_8601": "2022-04-02T03:17:49.296898Z",
        "url": "https://files.pythonhosted.org/packages/40/36/95a6ca5d04111d96e73e286cc80ad64d2cfda1330fd6899daffb86d7fba9/keras_cv_attention_models-1.2.15-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "029cf00d042379f955de2123844e383f2c9113e0999972e221bba6193b8e117e",
          "md5": "467cc7886eae05baf7bbc086c4f5e028",
          "sha256": "ebee9136142e0301d23158485bb9b80359e4e477e5a178c4b4e9079d675b5772"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.2.15.tar.gz",
        "has_sig": false,
        "md5_digest": "467cc7886eae05baf7bbc086c4f5e028",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 401451,
        "upload_time": "2022-04-02T03:17:51",
        "upload_time_iso_8601": "2022-04-02T03:17:51.569484Z",
        "url": "https://files.pythonhosted.org/packages/02/9c/f00d042379f955de2123844e383f2c9113e0999972e221bba6193b8e117e/keras-cv-attention-models-1.2.15.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.16": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a4d030fbff19d2e647fd11701a258df4a31e5efd6d72d407b0304570e50eb4e4",
          "md5": "772275699c10effc0d6722eca3fb81b2",
          "sha256": "42e6c087accf9b9ab0dba7c6fe8e4395a329ef0b8a894a4a2bf5618054151715"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.2.16-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "772275699c10effc0d6722eca3fb81b2",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 438484,
        "upload_time": "2022-04-06T08:02:42",
        "upload_time_iso_8601": "2022-04-06T08:02:42.675039Z",
        "url": "https://files.pythonhosted.org/packages/a4/d0/30fbff19d2e647fd11701a258df4a31e5efd6d72d407b0304570e50eb4e4/keras_cv_attention_models-1.2.16-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7efb4b5f5619c6fb6faed3347b61a17668ac22d5b0fa89d2b9a24cc146d83838",
          "md5": "bde76d97c78d063396590ddb93d85b16",
          "sha256": "8332d07ba425cdac5b9120824aa88a18be6fddecb81ab820da310f531ead129a"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.2.16.tar.gz",
        "has_sig": false,
        "md5_digest": "bde76d97c78d063396590ddb93d85b16",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 409246,
        "upload_time": "2022-04-06T08:02:45",
        "upload_time_iso_8601": "2022-04-06T08:02:45.202514Z",
        "url": "https://files.pythonhosted.org/packages/7e/fb/4b5f5619c6fb6faed3347b61a17668ac22d5b0fa89d2b9a24cc146d83838/keras-cv-attention-models-1.2.16.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.17": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d759a35e3663d90644d24e7b5efe83ba8015b41a1d1780e090c04c4a26ac92ba",
          "md5": "7f7b3e1b585337a35b59a5d08682b965",
          "sha256": "0385e8c36d0583018be1bc4a32535af17b7b65a22fc874372acf4d0764c5ee2c"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.2.17-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "7f7b3e1b585337a35b59a5d08682b965",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 440401,
        "upload_time": "2022-04-11T11:09:13",
        "upload_time_iso_8601": "2022-04-11T11:09:13.655945Z",
        "url": "https://files.pythonhosted.org/packages/d7/59/a35e3663d90644d24e7b5efe83ba8015b41a1d1780e090c04c4a26ac92ba/keras_cv_attention_models-1.2.17-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4461e08dc231a44b29a792d28480b54b4b1d4ae6381291d6f52f1e0fb93997da",
          "md5": "3e4813d9468fb11ff4c05e27c6684b01",
          "sha256": "3643ae0ec74a76241f4d88f453353c250196d307b82eda558df3b55a1dab3878"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.2.17.tar.gz",
        "has_sig": false,
        "md5_digest": "3e4813d9468fb11ff4c05e27c6684b01",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 411483,
        "upload_time": "2022-04-11T11:09:16",
        "upload_time_iso_8601": "2022-04-11T11:09:16.092639Z",
        "url": "https://files.pythonhosted.org/packages/44/61/e08dc231a44b29a792d28480b54b4b1d4ae6381291d6f52f1e0fb93997da/keras-cv-attention-models-1.2.17.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.18": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b761919199c3d18258d127619b856d7d2b624bdb6c56071bc2916c25c5b265bf",
          "md5": "948adaa80372eecc0735f4675fd9a0ba",
          "sha256": "61092e88ede4d928ce0f4aebdce12c193c643c4f166ffbe2cc2494e1ca2801ba"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.2.18-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "948adaa80372eecc0735f4675fd9a0ba",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 449778,
        "upload_time": "2022-04-13T11:30:59",
        "upload_time_iso_8601": "2022-04-13T11:30:59.560063Z",
        "url": "https://files.pythonhosted.org/packages/b7/61/919199c3d18258d127619b856d7d2b624bdb6c56071bc2916c25c5b265bf/keras_cv_attention_models-1.2.18-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "351355e1120fc19910246ae6785d2a03ed374d2ff51156210c102d014c019096",
          "md5": "0f1c338ae7205b877dc6ed5f852dd988",
          "sha256": "387814a902687778baf20e72cabc6ddcea0bccd028e1f8bc1d74214dff7e068a"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.2.18.tar.gz",
        "has_sig": false,
        "md5_digest": "0f1c338ae7205b877dc6ed5f852dd988",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 418133,
        "upload_time": "2022-04-13T11:31:02",
        "upload_time_iso_8601": "2022-04-13T11:31:02.005464Z",
        "url": "https://files.pythonhosted.org/packages/35/13/55e1120fc19910246ae6785d2a03ed374d2ff51156210c102d014c019096/keras-cv-attention-models-1.2.18.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.19": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2edfa1ffe53a83f1046b6fa63051abad13cc58ebe91513405eea04ed15f4af90",
          "md5": "b0f1050aabba11e5f1855af3691a3262",
          "sha256": "6e1e931c9f33ea5f638de144abf676768e19b9929ceedc15ed333870509080f2"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.2.19-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "b0f1050aabba11e5f1855af3691a3262",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 450957,
        "upload_time": "2022-04-15T10:15:18",
        "upload_time_iso_8601": "2022-04-15T10:15:18.757019Z",
        "url": "https://files.pythonhosted.org/packages/2e/df/a1ffe53a83f1046b6fa63051abad13cc58ebe91513405eea04ed15f4af90/keras_cv_attention_models-1.2.19-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1a058c82c5ca7414ec608d6fe397cd7c2b976a6347e0f16a108e3f0ed946c008",
          "md5": "489abcab5e71e11da2e53a7d655d4809",
          "sha256": "2b2a72da9d26488bf3388805f6884478e097924ba34500dd9a93071d51880b25"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.2.19.tar.gz",
        "has_sig": false,
        "md5_digest": "489abcab5e71e11da2e53a7d655d4809",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 419420,
        "upload_time": "2022-04-15T10:15:21",
        "upload_time_iso_8601": "2022-04-15T10:15:21.035169Z",
        "url": "https://files.pythonhosted.org/packages/1a/05/8c82c5ca7414ec608d6fe397cd7c2b976a6347e0f16a108e3f0ed946c008/keras-cv-attention-models-1.2.19.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0a64c3d893506696301e3708fb79f7280b038183b365665c2ffbfd7153a50390",
          "md5": "443d2c315941fd7092bfcc5a939e22a2",
          "sha256": "698357c7cc3911d5c6add470843695bd648d8f4278f14a65fd724941979c9a70"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.2.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "443d2c315941fd7092bfcc5a939e22a2",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 380825,
        "upload_time": "2022-02-10T08:30:28",
        "upload_time_iso_8601": "2022-02-10T08:30:28.126615Z",
        "url": "https://files.pythonhosted.org/packages/0a/64/c3d893506696301e3708fb79f7280b038183b365665c2ffbfd7153a50390/keras_cv_attention_models-1.2.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a02bead45eab4f4f8b1abea28b464380830c616baae2fdce0bdf7e447c5577b2",
          "md5": "b5689bd46cba0a6423062d4c50e7342b",
          "sha256": "e62a196a81b099568fb350cf4900134c70ba03021d4b280f98678e9961cdc786"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.2.2.tar.gz",
        "has_sig": false,
        "md5_digest": "b5689bd46cba0a6423062d4c50e7342b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 355632,
        "upload_time": "2022-02-10T08:30:30",
        "upload_time_iso_8601": "2022-02-10T08:30:30.083229Z",
        "url": "https://files.pythonhosted.org/packages/a0/2b/ead45eab4f4f8b1abea28b464380830c616baae2fdce0bdf7e447c5577b2/keras-cv-attention-models-1.2.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.20": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c0c0777bcd4deef8927ae1bdc9e54f102afb09c3357ad9d3637c6f2464c3a151",
          "md5": "65281055a297192e82a38a8d7c640ce9",
          "sha256": "82ae290166b9b13c04eadfd75fec93e0519af6c4ca9c49ae7de29e91f29322ca"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.2.20-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "65281055a297192e82a38a8d7c640ce9",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 453643,
        "upload_time": "2022-04-18T10:48:59",
        "upload_time_iso_8601": "2022-04-18T10:48:59.897586Z",
        "url": "https://files.pythonhosted.org/packages/c0/c0/777bcd4deef8927ae1bdc9e54f102afb09c3357ad9d3637c6f2464c3a151/keras_cv_attention_models-1.2.20-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "48b53a8386a3f3ab31cfb1cbc2e02cd988a430d7b98ca604643ff46ead408449",
          "md5": "3387fd3bc5be5ecb91d3dc26a9e0b334",
          "sha256": "ab5c5bc2716eba33c6342ba6a5f6121ba7e82c3b28c4d01f0c1fcc6c7a51faa1"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.2.20.tar.gz",
        "has_sig": false,
        "md5_digest": "3387fd3bc5be5ecb91d3dc26a9e0b334",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 425006,
        "upload_time": "2022-04-18T10:49:02",
        "upload_time_iso_8601": "2022-04-18T10:49:02.137107Z",
        "url": "https://files.pythonhosted.org/packages/48/b5/3a8386a3f3ab31cfb1cbc2e02cd988a430d7b98ca604643ff46ead408449/keras-cv-attention-models-1.2.20.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.21": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8f4f9329e4a65f9b16b10f6194028ea2c24693ec076c98277f2d94e63f8b7955",
          "md5": "a6cb9be6312d0fb571fd6ed12c1bdb26",
          "sha256": "3f7b331457613d40b3af72cb2d1c82699746447f3ef86995871acfd58dc1b531"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.2.21-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "a6cb9be6312d0fb571fd6ed12c1bdb26",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 454798,
        "upload_time": "2022-04-22T11:21:40",
        "upload_time_iso_8601": "2022-04-22T11:21:40.235279Z",
        "url": "https://files.pythonhosted.org/packages/8f/4f/9329e4a65f9b16b10f6194028ea2c24693ec076c98277f2d94e63f8b7955/keras_cv_attention_models-1.2.21-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e92cfac4e204d4d6de1aa4150d3688bdd9a4b57ebdfd09c2c25d91ae94ba2ab2",
          "md5": "27144817c5eeea844cdbdb5ade953510",
          "sha256": "a6a2bee218c79b47075f85f0db79c3de4893e2b0f93f4fb957aa0133df8eb9a6"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.2.21.tar.gz",
        "has_sig": false,
        "md5_digest": "27144817c5eeea844cdbdb5ade953510",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 427266,
        "upload_time": "2022-04-22T11:21:42",
        "upload_time_iso_8601": "2022-04-22T11:21:42.708894Z",
        "url": "https://files.pythonhosted.org/packages/e9/2c/fac4e204d4d6de1aa4150d3688bdd9a4b57ebdfd09c2c25d91ae94ba2ab2/keras-cv-attention-models-1.2.21.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.22": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4a24b51374670f78f5f38f3a453631e4a321f66d7992e215e5e9b765e692432e",
          "md5": "cdf064e4928d4f8b52ae35e03a610901",
          "sha256": "f74b907b051d961d3029eddeee2cff75776c01b83f5c51a8795bfcc8fcc02256"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.2.22-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "cdf064e4928d4f8b52ae35e03a610901",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 456359,
        "upload_time": "2022-04-24T09:51:45",
        "upload_time_iso_8601": "2022-04-24T09:51:45.772213Z",
        "url": "https://files.pythonhosted.org/packages/4a/24/b51374670f78f5f38f3a453631e4a321f66d7992e215e5e9b765e692432e/keras_cv_attention_models-1.2.22-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "971d149de24ee58138d2cb1963797d14aa45d9ed4dff0870daaed639949e212a",
          "md5": "fcf4b010be1008255c31bbd59cbe0639",
          "sha256": "34b43a037fc6c61b4e788385d79ba3a821e516540c47792a3cfb0573c09c85ee"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.2.22.tar.gz",
        "has_sig": false,
        "md5_digest": "fcf4b010be1008255c31bbd59cbe0639",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 428834,
        "upload_time": "2022-04-24T09:51:48",
        "upload_time_iso_8601": "2022-04-24T09:51:48.206943Z",
        "url": "https://files.pythonhosted.org/packages/97/1d/149de24ee58138d2cb1963797d14aa45d9ed4dff0870daaed639949e212a/keras-cv-attention-models-1.2.22.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.23": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b725273cf48b8d03fa3b277be7f2869565a23266ebf1c9e32b427885eed37cb2",
          "md5": "51cda71819fa75c6138cb4d041acb3ff",
          "sha256": "a408c27a2070436ee6e4293c521e5fcae959c4c26baef042caf7ddd4cbddbc92"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.2.23-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "51cda71819fa75c6138cb4d041acb3ff",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 461340,
        "upload_time": "2022-04-26T02:07:57",
        "upload_time_iso_8601": "2022-04-26T02:07:57.089593Z",
        "url": "https://files.pythonhosted.org/packages/b7/25/273cf48b8d03fa3b277be7f2869565a23266ebf1c9e32b427885eed37cb2/keras_cv_attention_models-1.2.23-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3fe3d64708a860504358e604e56d22b83b5038396c0dcfdec8650a82113762ce",
          "md5": "5afc30e9f83ce99670891a6264a3295e",
          "sha256": "a58232ff0815caa294908cbb0608fa35fbabde52f6025402616899ebbe90034c"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.2.23.tar.gz",
        "has_sig": false,
        "md5_digest": "5afc30e9f83ce99670891a6264a3295e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 432433,
        "upload_time": "2022-04-26T02:07:59",
        "upload_time_iso_8601": "2022-04-26T02:07:59.206613Z",
        "url": "https://files.pythonhosted.org/packages/3f/e3/d64708a860504358e604e56d22b83b5038396c0dcfdec8650a82113762ce/keras-cv-attention-models-1.2.23.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.24": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5ae1c36b140251f15ef654972379879ce99ef912431577a36288beb13ac56f1b",
          "md5": "28ca4c30a0131f9bd8d17231544f5ea5",
          "sha256": "04ec3df43ef657874c47ec14f2f49e6f2bf6dca28c9de9f05baafc31f6911ee5"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.2.24-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "28ca4c30a0131f9bd8d17231544f5ea5",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 463783,
        "upload_time": "2022-04-28T03:12:27",
        "upload_time_iso_8601": "2022-04-28T03:12:27.673301Z",
        "url": "https://files.pythonhosted.org/packages/5a/e1/c36b140251f15ef654972379879ce99ef912431577a36288beb13ac56f1b/keras_cv_attention_models-1.2.24-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "28e21f36424aecfad594556cb2641690c75d20438acfdebc9e11e87d3314da99",
          "md5": "353c0854e701457d78242c2c4dde3da0",
          "sha256": "3303c4699d47190a5e67463f3490cd025543020ab3df331777e7fdbaf4a5a1fc"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.2.24.tar.gz",
        "has_sig": false,
        "md5_digest": "353c0854e701457d78242c2c4dde3da0",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 435310,
        "upload_time": "2022-04-28T03:12:29",
        "upload_time_iso_8601": "2022-04-28T03:12:29.821581Z",
        "url": "https://files.pythonhosted.org/packages/28/e2/1f36424aecfad594556cb2641690c75d20438acfdebc9e11e87d3314da99/keras-cv-attention-models-1.2.24.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.25": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5c299b0702ea1b2d64781139177fb4f5d3eeaae91958c7eb5b2b9fcb8e011b75",
          "md5": "bd13513a0d4c77c693daabe5978dc9c2",
          "sha256": "6eafc3306d292155d1cac47446f762d78ce6ba0e5c507d8df82a3a9dbc352e51"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.2.25-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "bd13513a0d4c77c693daabe5978dc9c2",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 468661,
        "upload_time": "2022-05-10T05:47:26",
        "upload_time_iso_8601": "2022-05-10T05:47:26.334289Z",
        "url": "https://files.pythonhosted.org/packages/5c/29/9b0702ea1b2d64781139177fb4f5d3eeaae91958c7eb5b2b9fcb8e011b75/keras_cv_attention_models-1.2.25-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2f18375e211e87ccaf49301a0bbae10c44907896eb786a1ca843883f3a53fdaf",
          "md5": "af5e052dada5c5195e8cefb98bf45acd",
          "sha256": "9712b74f69fc69df3f446c21d3cde590621a5337b1b4ea71329ffa3caf9d554d"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.2.25.tar.gz",
        "has_sig": false,
        "md5_digest": "af5e052dada5c5195e8cefb98bf45acd",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 442108,
        "upload_time": "2022-05-10T05:47:28",
        "upload_time_iso_8601": "2022-05-10T05:47:28.824230Z",
        "url": "https://files.pythonhosted.org/packages/2f/18/375e211e87ccaf49301a0bbae10c44907896eb786a1ca843883f3a53fdaf/keras-cv-attention-models-1.2.25.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.26": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "65adc0917cde89040d9b92ab36d080dc859002ec32d278d20467ccb232d0b1f0",
          "md5": "7d354b651939c7a991214557d3c1a359",
          "sha256": "4f0e326a395191121aa450b05bcf22e36e17259567ebb12aa4e7438c8a1a9d2f"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.2.26-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "7d354b651939c7a991214557d3c1a359",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 475958,
        "upload_time": "2022-05-12T03:29:37",
        "upload_time_iso_8601": "2022-05-12T03:29:37.138585Z",
        "url": "https://files.pythonhosted.org/packages/65/ad/c0917cde89040d9b92ab36d080dc859002ec32d278d20467ccb232d0b1f0/keras_cv_attention_models-1.2.26-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "39d563fef00930f605b49a490adf035436e84e06a2f77581ff2e3e31a2e2871d",
          "md5": "75fcf19c06c76cebd064574c2c57a0db",
          "sha256": "11aeef02b7cbef5a7f0c421ed9de22046c60f36d3dd54cbade79fa5689c11d68"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.2.26.tar.gz",
        "has_sig": false,
        "md5_digest": "75fcf19c06c76cebd064574c2c57a0db",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 446855,
        "upload_time": "2022-05-12T03:29:39",
        "upload_time_iso_8601": "2022-05-12T03:29:39.867665Z",
        "url": "https://files.pythonhosted.org/packages/39/d5/63fef00930f605b49a490adf035436e84e06a2f77581ff2e3e31a2e2871d/keras-cv-attention-models-1.2.26.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.27": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c43ed938fa13b9d7dcbedb4fbdaf23bb2de96482a9c8e60de2e419adfa27e9a8",
          "md5": "712d0709c3bb42ce0b3e0c9fe6de0fc9",
          "sha256": "b3233a4f4aaf24663f078069bbe601281b69c0c32f5b8ff1aa7698fc2542b789"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.2.27-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "712d0709c3bb42ce0b3e0c9fe6de0fc9",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 482841,
        "upload_time": "2022-05-18T07:15:06",
        "upload_time_iso_8601": "2022-05-18T07:15:06.248149Z",
        "url": "https://files.pythonhosted.org/packages/c4/3e/d938fa13b9d7dcbedb4fbdaf23bb2de96482a9c8e60de2e419adfa27e9a8/keras_cv_attention_models-1.2.27-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "34e53aa69989c6bdd0d7e777c04d16ca3972221e06f5e8171084b3a83b6ced4e",
          "md5": "f85e2b721e33147266156faa12fb85ad",
          "sha256": "fa9345c57e429ebeb04373785d9e27e63d32ea8960bd12c1286d8374022f4c07"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.2.27.tar.gz",
        "has_sig": false,
        "md5_digest": "f85e2b721e33147266156faa12fb85ad",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 449911,
        "upload_time": "2022-05-18T07:15:09",
        "upload_time_iso_8601": "2022-05-18T07:15:09.124548Z",
        "url": "https://files.pythonhosted.org/packages/34/e5/3aa69989c6bdd0d7e777c04d16ca3972221e06f5e8171084b3a83b6ced4e/keras-cv-attention-models-1.2.27.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.28": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "39c7c64bda0d60867b8a493526a7fb1bc271fc30c672e7771bd0032ddd76e003",
          "md5": "45f185c183724c8ff15e16706228f310",
          "sha256": "1245287cd4a657ba5ffef52b454e234a9645015550bb2e3ce6d921674c7b9429"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.2.28-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "45f185c183724c8ff15e16706228f310",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 490928,
        "upload_time": "2022-07-15T13:59:12",
        "upload_time_iso_8601": "2022-07-15T13:59:12.396823Z",
        "url": "https://files.pythonhosted.org/packages/39/c7/c64bda0d60867b8a493526a7fb1bc271fc30c672e7771bd0032ddd76e003/keras_cv_attention_models-1.2.28-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "42cbfdd98a7d4f96b74a85e5802ff59337192121623f4277cdaf3858ba780375",
          "md5": "612193c3f2e039939f9bdb0e20d6a5d3",
          "sha256": "6bf8669af6e0fb3301cc351d6e76b2d30a6e0fe57b850a0a675cbad960fac267"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.2.28.tar.gz",
        "has_sig": false,
        "md5_digest": "612193c3f2e039939f9bdb0e20d6a5d3",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 456562,
        "upload_time": "2022-07-15T13:59:15",
        "upload_time_iso_8601": "2022-07-15T13:59:15.957904Z",
        "url": "https://files.pythonhosted.org/packages/42/cb/fdd98a7d4f96b74a85e5802ff59337192121623f4277cdaf3858ba780375/keras-cv-attention-models-1.2.28.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.29": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0882c52b49ff937e6ae880e9e389007c653600717965a6787982aadcbea156ab",
          "md5": "e1007551bb67e0022d1b0dc7889cd52b",
          "sha256": "bd42d10b957d81cd5a556b6e02be8a367cdc1290a23303ed73393e38dab7ef78"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.2.29-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "e1007551bb67e0022d1b0dc7889cd52b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 497339,
        "upload_time": "2022-07-19T06:13:44",
        "upload_time_iso_8601": "2022-07-19T06:13:44.058432Z",
        "url": "https://files.pythonhosted.org/packages/08/82/c52b49ff937e6ae880e9e389007c653600717965a6787982aadcbea156ab/keras_cv_attention_models-1.2.29-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0b187425116d2b5c106311c427cb47d2101ef0835a82afe7c6ba03c388b6e196",
          "md5": "bd1faa9611f107b83a1b86110d53b22c",
          "sha256": "e0cb765b3e6ed158da56835783366621c1070ae68b3573f786be419d93234888"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.2.29.tar.gz",
        "has_sig": false,
        "md5_digest": "bd1faa9611f107b83a1b86110d53b22c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 461205,
        "upload_time": "2022-07-19T06:13:46",
        "upload_time_iso_8601": "2022-07-19T06:13:46.384924Z",
        "url": "https://files.pythonhosted.org/packages/0b/18/7425116d2b5c106311c427cb47d2101ef0835a82afe7c6ba03c388b6e196/keras-cv-attention-models-1.2.29.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "38320dfac33c8cf9e0498b8c2083009a9b019dc3e18bdd2e8516304dfab107a3",
          "md5": "a3bd08ccb192a2879c2450e2c47da0df",
          "sha256": "5294fc9f33432b3d7f7d24dfef5d94405bc8f13629b84fb5e24cef1c3cd81b38"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.2.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "a3bd08ccb192a2879c2450e2c47da0df",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 383607,
        "upload_time": "2022-02-15T10:16:15",
        "upload_time_iso_8601": "2022-02-15T10:16:15.246324Z",
        "url": "https://files.pythonhosted.org/packages/38/32/0dfac33c8cf9e0498b8c2083009a9b019dc3e18bdd2e8516304dfab107a3/keras_cv_attention_models-1.2.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cfeb8ebdd19e22e59093f4658330a17cc5dd63d87814d52f6530b67643afd25a",
          "md5": "6dd9d1bc81a385d3b4622697c5802765",
          "sha256": "cf124ef1a64a9c43d4fd62044a193412f46aafc4703400fcb218148106bcb15c"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.2.3.tar.gz",
        "has_sig": false,
        "md5_digest": "6dd9d1bc81a385d3b4622697c5802765",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 359381,
        "upload_time": "2022-02-15T10:16:17",
        "upload_time_iso_8601": "2022-02-15T10:16:17.160258Z",
        "url": "https://files.pythonhosted.org/packages/cf/eb/8ebdd19e22e59093f4658330a17cc5dd63d87814d52f6530b67643afd25a/keras-cv-attention-models-1.2.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.30": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cca396eb7facb886d6fd0488377fd700c3586130ce9c26f0debe551b97d8201c",
          "md5": "c080591645b2ee2dc3cb5acbfa0e2c46",
          "sha256": "3e0c8642caec9a996114cdd8f58e6cca7df1dfa74039cc6308db635328efcec0"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.2.30-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "c080591645b2ee2dc3cb5acbfa0e2c46",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 495558,
        "upload_time": "2022-07-23T08:45:50",
        "upload_time_iso_8601": "2022-07-23T08:45:50.248606Z",
        "url": "https://files.pythonhosted.org/packages/cc/a3/96eb7facb886d6fd0488377fd700c3586130ce9c26f0debe551b97d8201c/keras_cv_attention_models-1.2.30-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "adb954e2bd6873711a7f2750f391a35b4ecead8a24d6fbe9ec5119f3ffb355a9",
          "md5": "75544dada14f538a0fb291e131aa5722",
          "sha256": "b3637c093b3831ede53d8d701d6a9648c6f4fb9552d0f2ab1a589d3fc2d70c0d"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.2.30.tar.gz",
        "has_sig": false,
        "md5_digest": "75544dada14f538a0fb291e131aa5722",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 460302,
        "upload_time": "2022-07-23T08:45:52",
        "upload_time_iso_8601": "2022-07-23T08:45:52.715718Z",
        "url": "https://files.pythonhosted.org/packages/ad/b9/54e2bd6873711a7f2750f391a35b4ecead8a24d6fbe9ec5119f3ffb355a9/keras-cv-attention-models-1.2.30.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "782f78188b60ae40aa40edbd6342a1eb566a3faeb35b0f398cf08680abddea58",
          "md5": "660827e1f014ce58d30d0a8f169b5616",
          "sha256": "cdcfa8a18727835efc0d23dbf9767d910a80f2cad2b7a05dc0a6acb1d3b5a550"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.2.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "660827e1f014ce58d30d0a8f169b5616",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 388317,
        "upload_time": "2022-02-18T12:03:31",
        "upload_time_iso_8601": "2022-02-18T12:03:31.038984Z",
        "url": "https://files.pythonhosted.org/packages/78/2f/78188b60ae40aa40edbd6342a1eb566a3faeb35b0f398cf08680abddea58/keras_cv_attention_models-1.2.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7347bde834d6717b7edbf4a95207fdbc86d0b56af742d0452bd23212307c6640",
          "md5": "64f9ac8c1ed455570e24a19cdc67fb9e",
          "sha256": "dae9fb1a619e83993a6e0874f482ef72953c888f01cc097a25c51170adde0a4a"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.2.4.tar.gz",
        "has_sig": false,
        "md5_digest": "64f9ac8c1ed455570e24a19cdc67fb9e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 363693,
        "upload_time": "2022-02-18T12:03:33",
        "upload_time_iso_8601": "2022-02-18T12:03:33.111046Z",
        "url": "https://files.pythonhosted.org/packages/73/47/bde834d6717b7edbf4a95207fdbc86d0b56af742d0452bd23212307c6640/keras-cv-attention-models-1.2.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "48182d307ac24468e92cd367d82727b838c7172a40cb9c30792a22ea5ac758df",
          "md5": "fa7ce5e31b6edf66503a12020e744d4f",
          "sha256": "a0b67ec9f9b6335e98ccb813bb94c48866d7cc61356d55f552bb4a04ed835a64"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.2.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "fa7ce5e31b6edf66503a12020e744d4f",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 388783,
        "upload_time": "2022-02-22T08:30:26",
        "upload_time_iso_8601": "2022-02-22T08:30:26.139639Z",
        "url": "https://files.pythonhosted.org/packages/48/18/2d307ac24468e92cd367d82727b838c7172a40cb9c30792a22ea5ac758df/keras_cv_attention_models-1.2.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8d8a93851b7e8ebef419fc550844ff5818877bc841d53861efeff31970297bb7",
          "md5": "dffe576664b13172779b66759d60f6b7",
          "sha256": "45de7de6bcdbed58bbd276bbae3b89b035a29748f1a7d98cb04969e6cd74b1a9"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.2.5.tar.gz",
        "has_sig": false,
        "md5_digest": "dffe576664b13172779b66759d60f6b7",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 364311,
        "upload_time": "2022-02-22T08:30:28",
        "upload_time_iso_8601": "2022-02-22T08:30:28.537128Z",
        "url": "https://files.pythonhosted.org/packages/8d/8a/93851b7e8ebef419fc550844ff5818877bc841d53861efeff31970297bb7/keras-cv-attention-models-1.2.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5e6de56d21a9692c30a561853833b57d634d17ed09ab3e1a71a22f2c2e3b3204",
          "md5": "0289821ab545af4ba4e3eb429209138c",
          "sha256": "61d264ecaef5c90a1719e268f512ac765629cf26a93fb9eab792d59b5e13268d"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.2.6-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0289821ab545af4ba4e3eb429209138c",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 397864,
        "upload_time": "2022-03-09T00:53:59",
        "upload_time_iso_8601": "2022-03-09T00:53:59.080094Z",
        "url": "https://files.pythonhosted.org/packages/5e/6d/e56d21a9692c30a561853833b57d634d17ed09ab3e1a71a22f2c2e3b3204/keras_cv_attention_models-1.2.6-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6934fd08756fd7461f2937d3a8607bf5fa5e2b2c0aa673712b8747102e6db2b5",
          "md5": "7ab577a5a766a0c4b3e73f7128b7e306",
          "sha256": "70e1f86e3491bffc027dd4e4f356cbaf8c6cfc1ff753c48dda998a89be537779"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.2.6.tar.gz",
        "has_sig": false,
        "md5_digest": "7ab577a5a766a0c4b3e73f7128b7e306",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 371905,
        "upload_time": "2022-03-09T00:54:01",
        "upload_time_iso_8601": "2022-03-09T00:54:01.026761Z",
        "url": "https://files.pythonhosted.org/packages/69/34/fd08756fd7461f2937d3a8607bf5fa5e2b2c0aa673712b8747102e6db2b5/keras-cv-attention-models-1.2.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "efdeac48a42b61d9a3a824fe09452936e13319bc7dfe02e782250687ef4b3cd3",
          "md5": "712dcf3b538dc50a2f690d46905997f7",
          "sha256": "648daf90a7a6c1bc0c55bd86521dc8e464692484ab1069cee45b47c9760ceb98"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.2.7-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "712dcf3b538dc50a2f690d46905997f7",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 398122,
        "upload_time": "2022-03-09T11:12:08",
        "upload_time_iso_8601": "2022-03-09T11:12:08.589951Z",
        "url": "https://files.pythonhosted.org/packages/ef/de/ac48a42b61d9a3a824fe09452936e13319bc7dfe02e782250687ef4b3cd3/keras_cv_attention_models-1.2.7-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f72c35c9efc28cc9a985afa2bd0ee9158f9578f89a6190ce91e5e4bb831ad1c6",
          "md5": "98ddb259f5eed1186e62d9e01e7ca0fd",
          "sha256": "5384a22878ba1708c445c9d97172917e3c23c69c20d49d55f3ca9727146f6665"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.2.7.tar.gz",
        "has_sig": false,
        "md5_digest": "98ddb259f5eed1186e62d9e01e7ca0fd",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 372138,
        "upload_time": "2022-03-09T11:12:10",
        "upload_time_iso_8601": "2022-03-09T11:12:10.860914Z",
        "url": "https://files.pythonhosted.org/packages/f7/2c/35c9efc28cc9a985afa2bd0ee9158f9578f89a6190ce91e5e4bb831ad1c6/keras-cv-attention-models-1.2.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "35a317c41ac7716e2e3022778e58590489ade66067b5b7459127c87f568f7a18",
          "md5": "15ec67e641bfd416c4857421cb9ebcac",
          "sha256": "3100521a9aef24963a6a7517037643c8345b3f52472688629f7812fac6e5b6a1"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.2.8-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "15ec67e641bfd416c4857421cb9ebcac",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 404803,
        "upload_time": "2022-03-11T06:04:27",
        "upload_time_iso_8601": "2022-03-11T06:04:27.636162Z",
        "url": "https://files.pythonhosted.org/packages/35/a3/17c41ac7716e2e3022778e58590489ade66067b5b7459127c87f568f7a18/keras_cv_attention_models-1.2.8-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bd2e333357162d0b7534a3b124cf228ef539fb8a8c89dcf811249032f70d1a07",
          "md5": "1d2b242a928264c521de3e15016283fd",
          "sha256": "43fd65cf2aed62c811783e008f324d1f2e07f1d492996fab748e443d7295f209"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.2.8.tar.gz",
        "has_sig": false,
        "md5_digest": "1d2b242a928264c521de3e15016283fd",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 378409,
        "upload_time": "2022-03-11T06:04:29",
        "upload_time_iso_8601": "2022-03-11T06:04:29.751931Z",
        "url": "https://files.pythonhosted.org/packages/bd/2e/333357162d0b7534a3b124cf228ef539fb8a8c89dcf811249032f70d1a07/keras-cv-attention-models-1.2.8.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.9": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fa08e3394aa7afa040d8037c403c1ff3856cd0322f81f200dab1ddfe10ce078b",
          "md5": "318ce573aae2f2815e7561ce9a13ef38",
          "sha256": "01246090252f8a5e335a0a37a6eb18171523a5e53ef6891f1e4b3fc90e72ee9b"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.2.9-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "318ce573aae2f2815e7561ce9a13ef38",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 407531,
        "upload_time": "2022-03-13T06:20:19",
        "upload_time_iso_8601": "2022-03-13T06:20:19.864991Z",
        "url": "https://files.pythonhosted.org/packages/fa/08/e3394aa7afa040d8037c403c1ff3856cd0322f81f200dab1ddfe10ce078b/keras_cv_attention_models-1.2.9-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "99fc3277daf231ed92f8371539afb7531781c1e0508a2d606301ccb5b64ed907",
          "md5": "4235f06655f109650aba724ac6b64370",
          "sha256": "59154342fa23b569aeb6fca683d457540239bcbea8bea972c7a8bb75860a8ebc"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.2.9.tar.gz",
        "has_sig": false,
        "md5_digest": "4235f06655f109650aba724ac6b64370",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 381494,
        "upload_time": "2022-03-13T06:20:22",
        "upload_time_iso_8601": "2022-03-13T06:20:22.208686Z",
        "url": "https://files.pythonhosted.org/packages/99/fc/3277daf231ed92f8371539afb7531781c1e0508a2d606301ccb5b64ed907/keras-cv-attention-models-1.2.9.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.3.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2ee936004fb70f7abc4dbff066a5b4e697987340cc371f8745c4d07290b04ee8",
          "md5": "c2103345e98df157916a432d8af690e3",
          "sha256": "d40ced2656781f25ad0c0de454b2dd4f588b3f257ba05e009a7c7d3990f23243"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.3.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "c2103345e98df157916a432d8af690e3",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 502530,
        "upload_time": "2022-07-25T11:00:11",
        "upload_time_iso_8601": "2022-07-25T11:00:11.249647Z",
        "url": "https://files.pythonhosted.org/packages/2e/e9/36004fb70f7abc4dbff066a5b4e697987340cc371f8745c4d07290b04ee8/keras_cv_attention_models-1.3.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "56ffba37886f3e19fd80ee1f7d4d5c30ed1e071be7860cafdea31a86710976a8",
          "md5": "d82d40a28d4c81d5e7cbcd77947777b5",
          "sha256": "a871b81959385f1b0c0247921d2ce4ade7e73ce1056f4af6d20c2ab9ef4e4b15"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.3.0.tar.gz",
        "has_sig": false,
        "md5_digest": "d82d40a28d4c81d5e7cbcd77947777b5",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 465956,
        "upload_time": "2022-07-25T11:00:13",
        "upload_time_iso_8601": "2022-07-25T11:00:13.720044Z",
        "url": "https://files.pythonhosted.org/packages/56/ff/ba37886f3e19fd80ee1f7d4d5c30ed1e071be7860cafdea31a86710976a8/keras-cv-attention-models-1.3.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.3.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "50c688b04d137860bafe86d084a1b67a2c5c32a0abc3bdb9f538cbf7fe28a4b0",
          "md5": "ce948724516d4f3a3689af22a0a107d9",
          "sha256": "b5f811fd93d32ed525fedfc92c8e0e146470ad664456fc899d40036d271601a8"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.3.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ce948724516d4f3a3689af22a0a107d9",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 508956,
        "upload_time": "2022-09-12T06:15:54",
        "upload_time_iso_8601": "2022-09-12T06:15:54.888989Z",
        "url": "https://files.pythonhosted.org/packages/50/c6/88b04d137860bafe86d084a1b67a2c5c32a0abc3bdb9f538cbf7fe28a4b0/keras_cv_attention_models-1.3.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "470be93890d46e14beb9c15baa359b8dcaa81d74b16bbb7650b3e59c6ddfd2fc",
          "md5": "0c6152575a752c636e43539de4db660d",
          "sha256": "747492a5e2fd3c91abe671bee5316466f10de3c80e1331697fdeaa01409e92d2"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.3.1.tar.gz",
        "has_sig": false,
        "md5_digest": "0c6152575a752c636e43539de4db660d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 471670,
        "upload_time": "2022-09-12T06:15:57",
        "upload_time_iso_8601": "2022-09-12T06:15:57.348535Z",
        "url": "https://files.pythonhosted.org/packages/47/0b/e93890d46e14beb9c15baa359b8dcaa81d74b16bbb7650b3e59c6ddfd2fc/keras-cv-attention-models-1.3.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.3.10": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b95283a407e2c7d0f1263654b259723d04582b05bc7aa787fe6499b819b48b59",
          "md5": "fa7541fd57bca5565edd1d95835067bf",
          "sha256": "7fc70e35974460b15b6992bd2153db151fc4b1db9644b995ed846063e22dae70"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.3.10-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "fa7541fd57bca5565edd1d95835067bf",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 593099,
        "upload_time": "2023-03-08T09:18:30",
        "upload_time_iso_8601": "2023-03-08T09:18:30.528808Z",
        "url": "https://files.pythonhosted.org/packages/b9/52/83a407e2c7d0f1263654b259723d04582b05bc7aa787fe6499b819b48b59/keras_cv_attention_models-1.3.10-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b4efa20a8e5dbc4bf6f1251f3478b900add81e543f6d55e23a9d53ee3792e718",
          "md5": "02937055e23fb7035c8e012b45c2d5d0",
          "sha256": "32ae8434ef22d80354112303587dd1559b40442f176295a1dd3ce5383d161505"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.3.10.tar.gz",
        "has_sig": false,
        "md5_digest": "02937055e23fb7035c8e012b45c2d5d0",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 545042,
        "upload_time": "2023-03-08T09:18:35",
        "upload_time_iso_8601": "2023-03-08T09:18:35.679361Z",
        "url": "https://files.pythonhosted.org/packages/b4/ef/a20a8e5dbc4bf6f1251f3478b900add81e543f6d55e23a9d53ee3792e718/keras-cv-attention-models-1.3.10.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.3.11": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ddb9a445ba578f60fd80f86be998a5664f7bfa48674b274067e491f02623de7b",
          "md5": "547347df7d1b12b9e2a8492679b15f9b",
          "sha256": "b299d90a9d915b627f1f133e4759acd0e01a94aa453f799421b50273ff5447ef"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.3.11-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "547347df7d1b12b9e2a8492679b15f9b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 613407,
        "upload_time": "2023-03-08T11:41:03",
        "upload_time_iso_8601": "2023-03-08T11:41:03.331705Z",
        "url": "https://files.pythonhosted.org/packages/dd/b9/a445ba578f60fd80f86be998a5664f7bfa48674b274067e491f02623de7b/keras_cv_attention_models-1.3.11-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6e66390adb389b43b2bab7ba255b6fd8c11ac7adcdd85c10e72c995b0933283a",
          "md5": "f0efbf4cd9a98e6286e6f28c7d3cbdc7",
          "sha256": "cd44ceb846ac063446a96ac21f5d838b7841a28b8a9fbbaa8654ae4f259cfc22"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.3.11.tar.gz",
        "has_sig": false,
        "md5_digest": "f0efbf4cd9a98e6286e6f28c7d3cbdc7",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 563381,
        "upload_time": "2023-03-08T11:41:08",
        "upload_time_iso_8601": "2023-03-08T11:41:08.279631Z",
        "url": "https://files.pythonhosted.org/packages/6e/66/390adb389b43b2bab7ba255b6fd8c11ac7adcdd85c10e72c995b0933283a/keras-cv-attention-models-1.3.11.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.3.12": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a76353bf107cd91cea77e391ac801a62cbfcbe01669fb054a3963e631abd7470",
          "md5": "a56f62e568466d6b478a85dcbdbc4b11",
          "sha256": "78160bfbca338c23f039d2da3cb4e603692043f606f325604918c29b7d8ffe54"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.3.12-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "a56f62e568466d6b478a85dcbdbc4b11",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 617349,
        "upload_time": "2023-03-23T15:13:41",
        "upload_time_iso_8601": "2023-03-23T15:13:41.213402Z",
        "url": "https://files.pythonhosted.org/packages/a7/63/53bf107cd91cea77e391ac801a62cbfcbe01669fb054a3963e631abd7470/keras_cv_attention_models-1.3.12-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2130dfeef3f82106a6773bb72051e07b684d0a941bad193d2320bdb91c24f65c",
          "md5": "e5a00bcba007022129946dcb29e4bf44",
          "sha256": "b1b6a85a0fd20e8d8726216d3b5ec9e14ea5b5e5a619ada9ff9defdecd3bb547"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.3.12.tar.gz",
        "has_sig": false,
        "md5_digest": "e5a00bcba007022129946dcb29e4bf44",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 565949,
        "upload_time": "2023-03-23T15:13:47",
        "upload_time_iso_8601": "2023-03-23T15:13:47.140156Z",
        "url": "https://files.pythonhosted.org/packages/21/30/dfeef3f82106a6773bb72051e07b684d0a941bad193d2320bdb91c24f65c/keras-cv-attention-models-1.3.12.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.3.13": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "982b464dcbac571041e3bf5dcf1425eaa89f23a77ae0fb6e72c5a68a0e9ee0a3",
          "md5": "a7401edb3d1408f1cbd6125034da9230",
          "sha256": "2f816fd6fcf3a34fc5243cc66a85af8c7f61d3fdd42efbf3139500c4340147d7"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.3.13-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "a7401edb3d1408f1cbd6125034da9230",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 618334,
        "upload_time": "2023-04-02T03:55:04",
        "upload_time_iso_8601": "2023-04-02T03:55:04.094236Z",
        "url": "https://files.pythonhosted.org/packages/98/2b/464dcbac571041e3bf5dcf1425eaa89f23a77ae0fb6e72c5a68a0e9ee0a3/keras_cv_attention_models-1.3.13-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "23be527e338ed557071ee26e3445542c8a4d22e7f4c76c9e0a8d56ef638735ea",
          "md5": "f61f8e9286cb686089fe58b64eb55421",
          "sha256": "14ad268d6360be2bb71075c22db31eb0301fd9c3d923d688d076d6a9625b1c0c"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.3.13.tar.gz",
        "has_sig": false,
        "md5_digest": "f61f8e9286cb686089fe58b64eb55421",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 567086,
        "upload_time": "2023-04-02T03:55:08",
        "upload_time_iso_8601": "2023-04-02T03:55:08.903264Z",
        "url": "https://files.pythonhosted.org/packages/23/be/527e338ed557071ee26e3445542c8a4d22e7f4c76c9e0a8d56ef638735ea/keras-cv-attention-models-1.3.13.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.3.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6e32f7834762b41c56fb988e471c09f1fcd8005130a93d87c50a93fb33add68a",
          "md5": "c22bf9546e265dc6348755241b29e011",
          "sha256": "07128d8143bbe4a12f9278ac4445353b3373b5a5fec215fb0bf23e8761767bb8"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.3.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "c22bf9546e265dc6348755241b29e011",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 515937,
        "upload_time": "2022-10-27T10:26:37",
        "upload_time_iso_8601": "2022-10-27T10:26:37.430538Z",
        "url": "https://files.pythonhosted.org/packages/6e/32/f7834762b41c56fb988e471c09f1fcd8005130a93d87c50a93fb33add68a/keras_cv_attention_models-1.3.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "82d1da59f39e4f73679ab2e498d7cb8a0006fdb28b596a13f66868fafea43a13",
          "md5": "0b80a7346b523bec147c15a9adf51b1a",
          "sha256": "dc7043f97cbc4a1c57e4db52a2ed0bb898dfbef4ddaaf6a5463ff6e5528797ef"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.3.2.tar.gz",
        "has_sig": false,
        "md5_digest": "0b80a7346b523bec147c15a9adf51b1a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 477517,
        "upload_time": "2022-10-27T10:26:39",
        "upload_time_iso_8601": "2022-10-27T10:26:39.715112Z",
        "url": "https://files.pythonhosted.org/packages/82/d1/da59f39e4f73679ab2e498d7cb8a0006fdb28b596a13f66868fafea43a13/keras-cv-attention-models-1.3.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.3.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "74c010d81b9053dd4d9e59eb77c063220292d1a5a312bdee5179c2e84568ef2d",
          "md5": "d9a2d3b8b15243ad05253cfb73dfcd52",
          "sha256": "80aca976149912bdf43bbd3b24187cc7bdf22ad8df18166e5ccc609df7d62162"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.3.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d9a2d3b8b15243ad05253cfb73dfcd52",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 517820,
        "upload_time": "2022-11-03T12:57:33",
        "upload_time_iso_8601": "2022-11-03T12:57:33.676713Z",
        "url": "https://files.pythonhosted.org/packages/74/c0/10d81b9053dd4d9e59eb77c063220292d1a5a312bdee5179c2e84568ef2d/keras_cv_attention_models-1.3.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "adabeb1f21ba9b0e79860b71d0141fa77e0f3978781819dd4eb39f727bd22b31",
          "md5": "80e71f1b6419b7106d7ba0f9709b4383",
          "sha256": "02c2dceaa4218f8b3d73645b42e49ae27db28ada2dc1358a5db264ead40457f2"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.3.3.tar.gz",
        "has_sig": false,
        "md5_digest": "80e71f1b6419b7106d7ba0f9709b4383",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 480260,
        "upload_time": "2022-11-03T12:57:35",
        "upload_time_iso_8601": "2022-11-03T12:57:35.692287Z",
        "url": "https://files.pythonhosted.org/packages/ad/ab/eb1f21ba9b0e79860b71d0141fa77e0f3978781819dd4eb39f727bd22b31/keras-cv-attention-models-1.3.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.3.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4bf16f85ec85ac3ce6de6bbac5044cefa6560e0c6a559016d507a81d80f75a2c",
          "md5": "e94d390d2c1da084016e0bcada37a2c8",
          "sha256": "8a56e9205629eac5fc605107f726c1afee08e849589af6755c5c31fb6649cdcf"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.3.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "e94d390d2c1da084016e0bcada37a2c8",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 517849,
        "upload_time": "2022-11-12T09:40:36",
        "upload_time_iso_8601": "2022-11-12T09:40:36.724824Z",
        "url": "https://files.pythonhosted.org/packages/4b/f1/6f85ec85ac3ce6de6bbac5044cefa6560e0c6a559016d507a81d80f75a2c/keras_cv_attention_models-1.3.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3f019d1c0817046aad0ecc4df70ce9317ace654ebc1c87cc67ae0e81d919bd2a",
          "md5": "fe016380db36925465864c09c0a088ba",
          "sha256": "6679b7ebd2290cbf3a50ac65fe801fa66b5578e5172d56b32a40be017f116b03"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.3.4.tar.gz",
        "has_sig": false,
        "md5_digest": "fe016380db36925465864c09c0a088ba",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 480278,
        "upload_time": "2022-11-12T09:40:39",
        "upload_time_iso_8601": "2022-11-12T09:40:39.734391Z",
        "url": "https://files.pythonhosted.org/packages/3f/01/9d1c0817046aad0ecc4df70ce9317ace654ebc1c87cc67ae0e81d919bd2a/keras-cv-attention-models-1.3.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.3.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1de1c4833d30f4da0dc4cc2f99b3451727351febd4085f4527d0601163758bc4",
          "md5": "eb5a0ad64d7738a44512082d92c8bdae",
          "sha256": "b9020cb1ba2c5a85bb1d3f748d7fac0d7ab4c65adc5559f224455440637f867b"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.3.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "eb5a0ad64d7738a44512082d92c8bdae",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 540816,
        "upload_time": "2023-01-09T07:17:44",
        "upload_time_iso_8601": "2023-01-09T07:17:44.705489Z",
        "url": "https://files.pythonhosted.org/packages/1d/e1/c4833d30f4da0dc4cc2f99b3451727351febd4085f4527d0601163758bc4/keras_cv_attention_models-1.3.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a251d5fc471cec7744dd9ca86d4e12e12bf282bf8351c24e2419a39f452bcece",
          "md5": "0a7f94c30d972b9b5dca24b551bcae3d",
          "sha256": "da58d51244d91137aff6fd458381173554a5084c24b31eaaef949d6779439844"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.3.5.tar.gz",
        "has_sig": false,
        "md5_digest": "0a7f94c30d972b9b5dca24b551bcae3d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 497747,
        "upload_time": "2023-01-09T07:17:46",
        "upload_time_iso_8601": "2023-01-09T07:17:46.857670Z",
        "url": "https://files.pythonhosted.org/packages/a2/51/d5fc471cec7744dd9ca86d4e12e12bf282bf8351c24e2419a39f452bcece/keras-cv-attention-models-1.3.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.3.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a7f0e5417a5b3bc18cba2ac62457f13ee9c62f7ba3f421e0604391470594c917",
          "md5": "f978f571704abe821ad24c2e463a7fd5",
          "sha256": "d97ad2df8934acd4a79ca2543f907a1a73959ca9144db4ec391e1e0300f327ea"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.3.6-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f978f571704abe821ad24c2e463a7fd5",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 552527,
        "upload_time": "2023-01-12T15:05:19",
        "upload_time_iso_8601": "2023-01-12T15:05:19.551367Z",
        "url": "https://files.pythonhosted.org/packages/a7/f0/e5417a5b3bc18cba2ac62457f13ee9c62f7ba3f421e0604391470594c917/keras_cv_attention_models-1.3.6-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d88ed5863fd642e1eb253ea306bcf71b5aab0858ee0c921c973141c622d21b19",
          "md5": "5a980f247b49d14135a6f52ef8acc80b",
          "sha256": "6b5212feedfec8200b8c01b3072b5fc681676fb1214d51fd2932a9c9cd7ff6b9"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.3.6.tar.gz",
        "has_sig": false,
        "md5_digest": "5a980f247b49d14135a6f52ef8acc80b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 509015,
        "upload_time": "2023-01-12T15:05:21",
        "upload_time_iso_8601": "2023-01-12T15:05:21.805438Z",
        "url": "https://files.pythonhosted.org/packages/d8/8e/d5863fd642e1eb253ea306bcf71b5aab0858ee0c921c973141c622d21b19/keras-cv-attention-models-1.3.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.3.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ef190bf9acb4aaf67a38144a91e02ec77d4f416925533335e0bf7662a7cb5e4d",
          "md5": "08d6761416fe8c8513c80d05f127b759",
          "sha256": "4e0e1f5d6ee3b6437953b40464e3c02a26e93ab483263e098a1cc57bf6753d02"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.3.7-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "08d6761416fe8c8513c80d05f127b759",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 552511,
        "upload_time": "2023-01-14T12:58:38",
        "upload_time_iso_8601": "2023-01-14T12:58:38.762504Z",
        "url": "https://files.pythonhosted.org/packages/ef/19/0bf9acb4aaf67a38144a91e02ec77d4f416925533335e0bf7662a7cb5e4d/keras_cv_attention_models-1.3.7-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4ed9d2364b05babef53e3f1b25fd8f8ae8751c8ec3c98eddf84cfd0a0b1a914a",
          "md5": "b989007cc2f5dac25ea3b77c964104bd",
          "sha256": "c60e939944edee721731d3a1263c60b3a754d6309bf76dc4dde63027c9b089c0"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.3.7.tar.gz",
        "has_sig": false,
        "md5_digest": "b989007cc2f5dac25ea3b77c964104bd",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 509046,
        "upload_time": "2023-01-14T12:58:40",
        "upload_time_iso_8601": "2023-01-14T12:58:40.876525Z",
        "url": "https://files.pythonhosted.org/packages/4e/d9/d2364b05babef53e3f1b25fd8f8ae8751c8ec3c98eddf84cfd0a0b1a914a/keras-cv-attention-models-1.3.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.3.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6bc8b6471d710984c69e47ea41b6aaeaaf2628f64f85c7ec4e954d7b0211f72d",
          "md5": "8103eeebc4a0492bc14474d98eca841c",
          "sha256": "032ee844bf5a7b43c037cefd5318ed699691c1f77b9f42a6da3538faf5251061"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.3.8-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "8103eeebc4a0492bc14474d98eca841c",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 557723,
        "upload_time": "2023-01-15T05:51:51",
        "upload_time_iso_8601": "2023-01-15T05:51:51.896039Z",
        "url": "https://files.pythonhosted.org/packages/6b/c8/b6471d710984c69e47ea41b6aaeaaf2628f64f85c7ec4e954d7b0211f72d/keras_cv_attention_models-1.3.8-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f47cb6a11f0dda117f09d633a7c8735cb29dbbf978343d137197448a93bd3923",
          "md5": "ddf5961cbe7a341da7b45ce873026fa1",
          "sha256": "498e21865b71b4e8a4335d7f78b83e4c880296821f1de0f5714f46d9e0e70a19"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.3.8.tar.gz",
        "has_sig": false,
        "md5_digest": "ddf5961cbe7a341da7b45ce873026fa1",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 512699,
        "upload_time": "2023-01-15T05:51:54",
        "upload_time_iso_8601": "2023-01-15T05:51:54.053498Z",
        "url": "https://files.pythonhosted.org/packages/f4/7c/b6a11f0dda117f09d633a7c8735cb29dbbf978343d137197448a93bd3923/keras-cv-attention-models-1.3.8.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.3.9": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "394e595f717b61efe6e879e0e06a4fb1cb2c03b1e5ca827c330af74f5d4042fb",
          "md5": "7b509925de95faf91c68d55af0abc281",
          "sha256": "c0524c9d0567b43d8c3aec0b26ca06e9f2e404375141f6dd60de0967d33ffdaa"
        },
        "downloads": -1,
        "filename": "keras_cv_attention_models-1.3.9-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "7b509925de95faf91c68d55af0abc281",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 572456,
        "upload_time": "2023-01-18T09:48:38",
        "upload_time_iso_8601": "2023-01-18T09:48:38.949740Z",
        "url": "https://files.pythonhosted.org/packages/39/4e/595f717b61efe6e879e0e06a4fb1cb2c03b1e5ca827c330af74f5d4042fb/keras_cv_attention_models-1.3.9-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2609ed1d0ee6a598979f95cea42108e8503a6c97409adbfd1ca6a154c7f10432",
          "md5": "48722147dcf86e003d0ff17dff2c1118",
          "sha256": "3f2b434cc6096aff75e87d193f410c07fbc6875c91e3ceef9efd51225da4f195"
        },
        "downloads": -1,
        "filename": "keras-cv-attention-models-1.3.9.tar.gz",
        "has_sig": false,
        "md5_digest": "48722147dcf86e003d0ff17dff2c1118",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 523970,
        "upload_time": "2023-01-18T09:48:41",
        "upload_time_iso_8601": "2023-01-18T09:48:41.342790Z",
        "url": "https://files.pythonhosted.org/packages/26/09/ed1d0ee6a598979f95cea42108e8503a6c97409adbfd1ca6a154c7f10432/keras-cv-attention-models-1.3.9.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "982b464dcbac571041e3bf5dcf1425eaa89f23a77ae0fb6e72c5a68a0e9ee0a3",
        "md5": "a7401edb3d1408f1cbd6125034da9230",
        "sha256": "2f816fd6fcf3a34fc5243cc66a85af8c7f61d3fdd42efbf3139500c4340147d7"
      },
      "downloads": -1,
      "filename": "keras_cv_attention_models-1.3.13-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "a7401edb3d1408f1cbd6125034da9230",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 618334,
      "upload_time": "2023-04-02T03:55:04",
      "upload_time_iso_8601": "2023-04-02T03:55:04.094236Z",
      "url": "https://files.pythonhosted.org/packages/98/2b/464dcbac571041e3bf5dcf1425eaa89f23a77ae0fb6e72c5a68a0e9ee0a3/keras_cv_attention_models-1.3.13-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "23be527e338ed557071ee26e3445542c8a4d22e7f4c76c9e0a8d56ef638735ea",
        "md5": "f61f8e9286cb686089fe58b64eb55421",
        "sha256": "14ad268d6360be2bb71075c22db31eb0301fd9c3d923d688d076d6a9625b1c0c"
      },
      "downloads": -1,
      "filename": "keras-cv-attention-models-1.3.13.tar.gz",
      "has_sig": false,
      "md5_digest": "f61f8e9286cb686089fe58b64eb55421",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 567086,
      "upload_time": "2023-04-02T03:55:08",
      "upload_time_iso_8601": "2023-04-02T03:55:08.903264Z",
      "url": "https://files.pythonhosted.org/packages/23/be/527e338ed557071ee26e3445542c8a4d22e7f4c76c9e0a8d56ef638735ea/keras-cv-attention-models-1.3.13.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}