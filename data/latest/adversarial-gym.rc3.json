{
  "info": {
    "author": "Dawson Horvath",
    "author_email": "Dawson Horvath <horvath.dawson@gmail.com>",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# adversarial-gym\n\nAdversarial gym hosts a range of adversarial turn based games within the OpenAI gym framework. \nThe games currently supported are:\n\n1. Chess\n2. TicTacToe\n\n## Installation\n\nDepending on the use case you can install in developer mode or using pypi. \n\n### Use the package manager [pip](https://pip.pypa.io/en/stable/) to install adversarial_gym\n```bash\npip install adversarial-gym\n```\n\n### Install from Source\nInstallation from source can be used to edit the environments.This is useful when developing or if your use case requires changes to the current API\n```bash\ncd Dir/To/Install/In\ngit clone git@github.com:OperationBeatMeChess/adversarial-gym.git\ncd adversarial-gym\npip install -e .\n```\n\n## Usage\n```python\nimport gym\nimport adversarial_gym\n\n# env = gym.make(\"Chess-v0\", render_mode='human')\nenv = gym.make(\"TicTacToe-v0\", render_mode='human')\nprint('reset')\nenv.reset()\nterminal = False\nwhile not terminal:\n    action = env.action_space.sample()\n    observation, reward, terminal, truncated, info = env.step(action)\nenv.close()\n```\n## Adversarial Environment API\nEach adversarial api follows the structure of the defined base class. This API has a few small additions to the standard OpenAI gym environment to help with the turn based structure of adversarial games. The basic adversarial API follows the below criteria:\n```python\nclass AdversarialEnv(gym.Env):\n    \"\"\"Abstract Adversarial Environment\"\"\"\n\n    @abstractproperty\n    def current_player(self):\n        \"\"\"\n        Returns:\n            current_player: Returns identifier for which player currently has their turn.\n        \"\"\"\n        pass\n\n    @abstractproperty\n    def previous_player(self):\n        \"\"\"\n        Returns:\n            previous_player: Returns identifier for which player previously had their turn.\n        \"\"\"\n        pass\n\n    @abstractproperty\n    def starting_player(self):\n        \"\"\"\n        Returns:\n            starting_player: Returns identifier for which player started the game.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_string_representation(self):\n        \"\"\"\n        Returns:\n            board_string: Returns string representation of current game state.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def set_string_representation(self, board_string):\n        \"\"\"\n        Input:\n            board_string: sets game state to match the string representation of board_string.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def _get_canonical_observation(self):\n        \"\"\"\n        Returns:\n            canonical_state: returns canonical form of board. The canonical form\n                            should be independent of players turn. For e.g. in chess,\n                            the canonical form can be chosen to be from the pov\n                            of white. When the player is white, we can return\n                            board as is. When the player is black, we can invert\n                            the colors and return the board.\n            current_player: returns indentifier of which player is the current player in the canonicial state. \n                            This is used to decode the invariant canonical form.\n        \"\"\"\n        pass  \n\n    @abstractmethod\n    def _game_result(self):\n        \"\"\"\n        Returns:\n            winner: returns None when game is not finished else returns int value \n                    for the winning player or draw.\n            reward: Reward value given the game result. Should not consider the player who won.\n               \n        \"\"\"\n        pass\n\n    @abstractmethod\n    def _do_action(self, action):\n        \"\"\"\n        Input:\n            action: Execute action from current game state.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def _reset_game(self):\n        \"\"\"\n        Reset the state of the game to the initial state. \n        This includes reseting the current player to the starting player.\n        \"\"\"\n\n    @abstractmethod\n    def _get_frame(self):\n        \"\"\"\n        Returns:\n            frame: returns py_game frame for the current state of the game. \n            This will be used by render to render the frame for human visualization\n               \n        \"\"\"\n        pass\n\n    @abstractmethod\n    def _get_img(self):\n        \"\"\"\n        Returns:\n            img: returns rgb_array of the image for the current state of the game. \n               \n        \"\"\"\n        pass\n\n    def game_result(self):\n        return self._game_result()[0]\n\n    def skip_next_human_render(self):\n        \"\"\"\n        Skips the next automatic human render in step or reset. \n        Used for rollouts or similar non visualized moves.\n        \"\"\"\n        self.skip_next_render = True\n\n    def step(self, action):\n        self._do_action(action)\n        observation = self._get_canonical_observation()\n        info = self._get_info()\n        result, reward = self._game_result()\n        terminated = result is not None\n\n        if self.render_mode == \"human\":\n            self.render()\n\n        return observation, reward, terminated, False, info\n\n    def reset(self, seed=None, options=None):\n        super().reset(seed=seed)\n\n        self._reset_game()\n        observation = self._get_canonical_observation()\n        info = self._get_info()\n\n        if self.render_mode == \"human\":\n            self.render()\n        \n        return observation, info\n        \n    def render(self):\n        if self.render_mode == \"human\":\n            \n            if self.clock is None:\n                self.clock = pygame.time.Clock()\n            if self.window is None:\n                pygame.init()\n                pygame.display.init()\n                self.window = pygame.display.set_mode((self.render_size, self.render_size))\n\n            canvas = self._get_frame()\n            # The following line copies our drawings from `canvas` to the visible window\n            self.window.blit(canvas, canvas.get_rect())\n            pygame.display.update()\n            # We need to ensure that human-rendering occurs at the predefined framerate.\n            # The following line will automatically add a delay to keep the framerate stable.\n            self.clock.tick(self.metadata[\"render_fps\"])\n\n        elif self.render_mode == \"rgb_array\":\n            return self._get_img()\n\n\n```\n\nThe major differences between a standard gym environment and the adversarial environment is the adversarial environment keeps track of both the game state and each players state. In other words we must know which player is currently making a move and the state which corresponds with this player. Additionally this must be expressed in the result of the game. \n\nAdditional features which were added for convenience were the ability to hash the environment state with a string representation (useful for representing the game as an action tree where each hashed state can search some position). Also, there are a few private member functions required for step and reset. \n\nFinally, there are two functions used for rendering the pygame window or getting the rgb_array of state. \n\nThis adversarial environment is then also paired with its corresponding adversarial Action_Space. This is required because most games have a subset of the total moves which are legal dependent on the current state of the game. This means it is non trivial to represent the move space with the vanilla gym spaces. To work around this while staying compliant with OpenAI gym API we created the following action space.\n\n```python\nclass AdversarialActionSpace(gym.spaces.Space):\n\n    def sample(self):\n        actions = self.legal_actions\n        return actions[np.random.randint(len(actions))]\n\n    def contains(self, action, is_legal=True):\n        is_contained = action in range(self.action_space_size())\n        and_legal = action in self.legal_actions if is_legal else True\n        return is_contained and and_legal\n\n    @abstractproperty\n    def legal_actions(self):\n        \"\"\"\n        Returns:\n            legal_actions: Returns a list of all the legal moves in the current position.\n        \"\"\"\n        pass\n    \n    @abstractproperty\n    def action_space_size(self):\n        \"\"\"\n        Returns:\n            action_space_size: returns the number of all possible actions.\n        \"\"\"\n        pass\n```\nThe action space is assumed to be a value in the set\n```math\n{1, 2, 3, 4, ..., total_number_actions}\n```\nThis means the action space is linear. however, we will have to decode the action into its corresponding move in which ever game. The legal actions will then just be a mask of which actions in the total set of actions can be played in any position. The action space size is just the `total_number_actions`.\n\n## Contributing\nPull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.\n\nPlease make sure to update tests as appropriate.\n\n## License\n[MIT](https://choosealicense.com/licenses/mit/)\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/OperationBeatMeChess/adversarial-gym",
    "keywords": "",
    "license": "MIT License",
    "maintainer": "",
    "maintainer_email": "",
    "name": "adversarial-gym",
    "package_url": "https://pypi.org/project/adversarial-gym/",
    "platform": null,
    "project_url": "https://pypi.org/project/adversarial-gym/",
    "project_urls": {
      "Bug Tracker": "https://github.com/OperationBeatMeChess/adversarial-gym/issues",
      "Homepage": "https://github.com/OperationBeatMeChess/adversarial-gym"
    },
    "release_url": "https://pypi.org/project/adversarial-gym/0.0.3/",
    "requires_dist": [
      "gym (>=0.26.1)",
      "python-chess",
      "numpy",
      "cairosvg",
      "pillow",
      "pygame"
    ],
    "requires_python": ">=3.7",
    "summary": "OpenAI Gym environments for adversarial games for the operation beat ourselves organisation.",
    "version": "0.0.3",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 15278238,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f05c5836e9328cd6759fe0ac052544a101c409762005f6c78f2e40905c52e7c4",
          "md5": "e502d27c357cf15327ca1bf152e160fb",
          "sha256": "7ce5fa49e3b9a545f646542c0714359f760653120f43f30ef3416fc80c1043ff"
        },
        "downloads": -1,
        "filename": "adversarial_gym-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "e502d27c357cf15327ca1bf152e160fb",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 10572,
        "upload_time": "2022-10-01T23:02:03",
        "upload_time_iso_8601": "2022-10-01T23:02:03.631158Z",
        "url": "https://files.pythonhosted.org/packages/f0/5c/5836e9328cd6759fe0ac052544a101c409762005f6c78f2e40905c52e7c4/adversarial_gym-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "64eab0361dae3b5fb4b104b45c09808d5427fe7e5e79bf366404fe74976748e6",
          "md5": "2a963b4d92a225a9cfddfe08d8112f55",
          "sha256": "4d28d1fbbda7fd50ce0a9dd5f454192a2bcb1e2f12cead82d30266284333ae2b"
        },
        "downloads": -1,
        "filename": "adversarial_gym-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "2a963b4d92a225a9cfddfe08d8112f55",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 11785,
        "upload_time": "2022-10-01T23:02:05",
        "upload_time_iso_8601": "2022-10-01T23:02:05.457426Z",
        "url": "https://files.pythonhosted.org/packages/64/ea/b0361dae3b5fb4b104b45c09808d5427fe7e5e79bf366404fe74976748e6/adversarial_gym-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a5151ec8935b85a146011ab9ded224ea496a6e5165fc7adc5490533bd362cdd6",
          "md5": "6131ca6d06493cecd2960de977240a83",
          "sha256": "f363d892eb44cc4835ab43a7ecc5069e03a76bad21c28ed55e3b331c295970ff"
        },
        "downloads": -1,
        "filename": "adversarial_gym-0.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "6131ca6d06493cecd2960de977240a83",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 10593,
        "upload_time": "2022-10-01T23:27:01",
        "upload_time_iso_8601": "2022-10-01T23:27:01.773358Z",
        "url": "https://files.pythonhosted.org/packages/a5/15/1ec8935b85a146011ab9ded224ea496a6e5165fc7adc5490533bd362cdd6/adversarial_gym-0.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8809186d69255a95f1ddca349a30f5b15b80f66bf58a04787ebbed08f57ec772",
          "md5": "1c038c882afb3cf84f8f0a210a8f9d42",
          "sha256": "42eea9ea4122bb52286e65d75f1991549bda3c16c0e81a6349b395ab3dd6fa43"
        },
        "downloads": -1,
        "filename": "adversarial_gym-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "1c038c882afb3cf84f8f0a210a8f9d42",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 11820,
        "upload_time": "2022-10-01T23:27:03",
        "upload_time_iso_8601": "2022-10-01T23:27:03.703163Z",
        "url": "https://files.pythonhosted.org/packages/88/09/186d69255a95f1ddca349a30f5b15b80f66bf58a04787ebbed08f57ec772/adversarial_gym-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "abd764ed2a525dccfdee8c6a6807f7f16ff18426c01ad2bb125447d7c230af37",
          "md5": "1fc07ed5fef6409088e396f575d35214",
          "sha256": "7103b0bf31265312fc4e7330577077a4b186af89affaf7bb50ec6be9f265c711"
        },
        "downloads": -1,
        "filename": "adversarial_gym-0.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "1fc07ed5fef6409088e396f575d35214",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 10608,
        "upload_time": "2022-10-01T23:37:41",
        "upload_time_iso_8601": "2022-10-01T23:37:41.544008Z",
        "url": "https://files.pythonhosted.org/packages/ab/d7/64ed2a525dccfdee8c6a6807f7f16ff18426c01ad2bb125447d7c230af37/adversarial_gym-0.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "69497b65205e83b99c04681e31a1bcac3fd808f20351f7cdf5e0354df9e7a91b",
          "md5": "12e86989cdc21cf84da479dc1ca14463",
          "sha256": "02949763ba4c70c56a46eea26cb981a3758e5088e021669ba041653b98d1c972"
        },
        "downloads": -1,
        "filename": "adversarial_gym-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "12e86989cdc21cf84da479dc1ca14463",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 11821,
        "upload_time": "2022-10-01T23:37:43",
        "upload_time_iso_8601": "2022-10-01T23:37:43.182882Z",
        "url": "https://files.pythonhosted.org/packages/69/49/7b65205e83b99c04681e31a1bcac3fd808f20351f7cdf5e0354df9e7a91b/adversarial_gym-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "abd764ed2a525dccfdee8c6a6807f7f16ff18426c01ad2bb125447d7c230af37",
        "md5": "1fc07ed5fef6409088e396f575d35214",
        "sha256": "7103b0bf31265312fc4e7330577077a4b186af89affaf7bb50ec6be9f265c711"
      },
      "downloads": -1,
      "filename": "adversarial_gym-0.0.3-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "1fc07ed5fef6409088e396f575d35214",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 10608,
      "upload_time": "2022-10-01T23:37:41",
      "upload_time_iso_8601": "2022-10-01T23:37:41.544008Z",
      "url": "https://files.pythonhosted.org/packages/ab/d7/64ed2a525dccfdee8c6a6807f7f16ff18426c01ad2bb125447d7c230af37/adversarial_gym-0.0.3-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "69497b65205e83b99c04681e31a1bcac3fd808f20351f7cdf5e0354df9e7a91b",
        "md5": "12e86989cdc21cf84da479dc1ca14463",
        "sha256": "02949763ba4c70c56a46eea26cb981a3758e5088e021669ba041653b98d1c972"
      },
      "downloads": -1,
      "filename": "adversarial_gym-0.0.3.tar.gz",
      "has_sig": false,
      "md5_digest": "12e86989cdc21cf84da479dc1ca14463",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 11821,
      "upload_time": "2022-10-01T23:37:43",
      "upload_time_iso_8601": "2022-10-01T23:37:43.182882Z",
      "url": "https://files.pythonhosted.org/packages/69/49/7b65205e83b99c04681e31a1bcac3fd808f20351f7cdf5e0354df9e7a91b/adversarial_gym-0.0.3.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}