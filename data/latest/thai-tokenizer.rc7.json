{
  "info": {
    "author": "Kirill Orlov",
    "author_email": "IDDT@users.noreply.github.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 2 - Pre-Alpha",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Natural Language :: Thai",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Topic :: Text Processing :: Linguistic"
    ],
    "description": "# Thai Tokenizer\nFast and accurate Thai tokenization library using supervised [BPE](https://en.wikipedia.org/wiki/Byte_pair_encoding) designed for full-text search applications.\n\n\n\n## Installation\n```bash\npip3 install thai_tokenizer\n```\n\n\n\n## Usage\nDefault set of pairs is optimized for short Thai-English product descriptions.\n```python\nfrom thai_tokenizer import Tokenizer\ntokenizer = Tokenizer()\ntokenizer('iPad Mini 256GB เครื่องไทย') #> 'iPad Mini 256GB เครื่อง ไทย'\ntokenizer.split('เครื่องไทย') #> ['เครื่อง', 'ไทย']\n```\n\n\n\n## Training\nSee [Training](TRAINING.md) for guidelines to train your own pairs.\n\n\n\n## Contributing\nPull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.\n\n\n\n## License\n[MIT](https://choosealicense.com/licenses/mit/)\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/IDDT/thai-tokenizer",
    "keywords": "thai,tokenizer",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "thai-tokenizer",
    "package_url": "https://pypi.org/project/thai-tokenizer/",
    "platform": "",
    "project_url": "https://pypi.org/project/thai-tokenizer/",
    "project_urls": {
      "Homepage": "https://github.com/IDDT/thai-tokenizer"
    },
    "release_url": "https://pypi.org/project/thai-tokenizer/0.2.5/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "Fast and accurate Thai tokenization library.",
    "version": "0.2.5",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 9993634,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "77b67e6b96e5134ebb3ba4c8f3eb8c19baede987a0cfa4a3c5b3ecf43e9955b6",
          "md5": "0828d4d4855c4a40a2ebe272a73d1aa3",
          "sha256": "c64a93cedf934b5d852acb56a40fd24eb5bbc52e8bdbf8f4151e30cee7a46b3c"
        },
        "downloads": -1,
        "filename": "thai_tokenizer-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0828d4d4855c4a40a2ebe272a73d1aa3",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 28460,
        "upload_time": "2021-01-21T14:20:51",
        "upload_time_iso_8601": "2021-01-21T14:20:51.788447Z",
        "url": "https://files.pythonhosted.org/packages/77/b6/7e6b96e5134ebb3ba4c8f3eb8c19baede987a0cfa4a3c5b3ecf43e9955b6/thai_tokenizer-0.1.0-py3-none-any.whl",
        "yanked": true,
        "yanked_reason": "Obsolete"
      }
    ],
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "949375b46a2a200c79c951bcf045ead66b6d7439dacea8e68ffe373188f4f0cf",
          "md5": "f0e53a7686755480fc9ee5345920e2cf",
          "sha256": "fb0b78695284bb7f429bbffbf460fd2a974c0fef06f2f1ee5a2c639ccdd01716"
        },
        "downloads": -1,
        "filename": "thai_tokenizer-0.2.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f0e53a7686755480fc9ee5345920e2cf",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 28679,
        "upload_time": "2021-03-01T07:11:14",
        "upload_time_iso_8601": "2021-03-01T07:11:14.063007Z",
        "url": "https://files.pythonhosted.org/packages/94/93/75b46a2a200c79c951bcf045ead66b6d7439dacea8e68ffe373188f4f0cf/thai_tokenizer-0.2.0-py3-none-any.whl",
        "yanked": true,
        "yanked_reason": "Obsolete"
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8eddef6ead448a823b0d9112a46804338c5c820a69c316fb3dc81e7b017096aa",
          "md5": "08c45713c031de1b6ec6da5d2952ef4c",
          "sha256": "5050a7981302aebacf7ad9565ffc63e73fca1ebce14e7afa14f823fca3204a59"
        },
        "downloads": -1,
        "filename": "thai_tokenizer-0.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "08c45713c031de1b6ec6da5d2952ef4c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 5226,
        "upload_time": "2021-03-01T07:11:14",
        "upload_time_iso_8601": "2021-03-01T07:11:14.798076Z",
        "url": "https://files.pythonhosted.org/packages/8e/dd/ef6ead448a823b0d9112a46804338c5c820a69c316fb3dc81e7b017096aa/thai_tokenizer-0.2.0.tar.gz",
        "yanked": true,
        "yanked_reason": "Obsolete"
      }
    ],
    "0.2.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b4162f3d66a8434d5e948a5f03711875742b0a4f0bacf51e93c6d3a808ed49ee",
          "md5": "6b39c75f5db39efcccec0df04a38f9ef",
          "sha256": "96223f695877d048b1541714072f38153d53fa14479cea1a3910e204ae4df31d"
        },
        "downloads": -1,
        "filename": "thai_tokenizer-0.2.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "6b39c75f5db39efcccec0df04a38f9ef",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 28112,
        "upload_time": "2021-03-03T08:56:29",
        "upload_time_iso_8601": "2021-03-03T08:56:29.397407Z",
        "url": "https://files.pythonhosted.org/packages/b4/16/2f3d66a8434d5e948a5f03711875742b0a4f0bacf51e93c6d3a808ed49ee/thai_tokenizer-0.2.1-py3-none-any.whl",
        "yanked": true,
        "yanked_reason": "Obsolete"
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a09551788174223aa29c5a9c096ce1ff15fde0fe6c619067eaf2b3fa42bf74d0",
          "md5": "b10db0e8889921ae294ebe7b0b422272",
          "sha256": "9283310691e633a44901f42aacdbb690721acafdb80672d4eda6d5252ce39d0a"
        },
        "downloads": -1,
        "filename": "thai_tokenizer-0.2.1.tar.gz",
        "has_sig": false,
        "md5_digest": "b10db0e8889921ae294ebe7b0b422272",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 5319,
        "upload_time": "2021-03-03T08:56:30",
        "upload_time_iso_8601": "2021-03-03T08:56:30.178636Z",
        "url": "https://files.pythonhosted.org/packages/a0/95/51788174223aa29c5a9c096ce1ff15fde0fe6c619067eaf2b3fa42bf74d0/thai_tokenizer-0.2.1.tar.gz",
        "yanked": true,
        "yanked_reason": "Obsolete"
      }
    ],
    "0.2.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "191a3cd58d609b1d08343a47e00bf3e44dd1e6d15c063691d323879773f2fcea",
          "md5": "ce69b0e0b27515f2ce4d4873a75a9c92",
          "sha256": "e8aadc7ed216a82d40ae917963150ca395ee007d86be3e2f81cfde3b507a2d15"
        },
        "downloads": -1,
        "filename": "thai_tokenizer-0.2.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ce69b0e0b27515f2ce4d4873a75a9c92",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 54390,
        "upload_time": "2021-03-11T03:56:25",
        "upload_time_iso_8601": "2021-03-11T03:56:25.757681Z",
        "url": "https://files.pythonhosted.org/packages/19/1a/3cd58d609b1d08343a47e00bf3e44dd1e6d15c063691d323879773f2fcea/thai_tokenizer-0.2.2-py3-none-any.whl",
        "yanked": true,
        "yanked_reason": "Obsolete"
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c878153c4cb084fe2d0ece40aa2cdf91b37a8635b605d304bc60f394007c45ba",
          "md5": "2547885fe55bcf7ddf4f39e353551c2f",
          "sha256": "ca8790b96c48a5095d922a5323c0dad810ea4757d11062e72640367e983e225e"
        },
        "downloads": -1,
        "filename": "thai_tokenizer-0.2.2.tar.gz",
        "has_sig": false,
        "md5_digest": "2547885fe55bcf7ddf4f39e353551c2f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 5842,
        "upload_time": "2021-03-11T03:56:26",
        "upload_time_iso_8601": "2021-03-11T03:56:26.485025Z",
        "url": "https://files.pythonhosted.org/packages/c8/78/153c4cb084fe2d0ece40aa2cdf91b37a8635b605d304bc60f394007c45ba/thai_tokenizer-0.2.2.tar.gz",
        "yanked": true,
        "yanked_reason": "Obsolete"
      }
    ],
    "0.2.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "133e59d8e1a0b4f95b9dea894304a424f0f906cf1e86423ce7f2da285deec1d0",
          "md5": "6f3a3016228b1394cc65b2af5ff9d6d8",
          "sha256": "c00b3f5b21f9006779abd0849fc680160a9c68df820124b2ead7b3c3cd210a18"
        },
        "downloads": -1,
        "filename": "thai_tokenizer-0.2.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "6f3a3016228b1394cc65b2af5ff9d6d8",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 52968,
        "upload_time": "2021-03-13T15:04:40",
        "upload_time_iso_8601": "2021-03-13T15:04:40.173858Z",
        "url": "https://files.pythonhosted.org/packages/13/3e/59d8e1a0b4f95b9dea894304a424f0f906cf1e86423ce7f2da285deec1d0/thai_tokenizer-0.2.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "15ef5c878c5e13a48dd8a68d5114d9a099a85e557c33cc0a8b9f334b34b95deb",
          "md5": "abefb11f5fb59ad45f6127d95c51dc89",
          "sha256": "291616e294e4cd529a81fbc319462fefbf802b852374c5a11f1f8628fb75ec6b"
        },
        "downloads": -1,
        "filename": "thai_tokenizer-0.2.3.tar.gz",
        "has_sig": false,
        "md5_digest": "abefb11f5fb59ad45f6127d95c51dc89",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 5837,
        "upload_time": "2021-03-13T15:04:41",
        "upload_time_iso_8601": "2021-03-13T15:04:41.039752Z",
        "url": "https://files.pythonhosted.org/packages/15/ef/5c878c5e13a48dd8a68d5114d9a099a85e557c33cc0a8b9f334b34b95deb/thai_tokenizer-0.2.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4b3b6b0e49389e3fafde158eea7f90f330ff3a95ec62599959a97c85f5414c11",
          "md5": "c3b8c24211d6aa8c8d3d72932ccdc87b",
          "sha256": "a98b3f8a777f70f7208ab08148492e0335b0887642663b3cc2805c45493ca5ca"
        },
        "downloads": -1,
        "filename": "thai_tokenizer-0.2.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "c3b8c24211d6aa8c8d3d72932ccdc87b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 52948,
        "upload_time": "2021-03-17T08:09:11",
        "upload_time_iso_8601": "2021-03-17T08:09:11.189171Z",
        "url": "https://files.pythonhosted.org/packages/4b/3b/6b0e49389e3fafde158eea7f90f330ff3a95ec62599959a97c85f5414c11/thai_tokenizer-0.2.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "33c1f753d994a4b9aa13b6f072bb51b11d1e32b2d35c4fe9983bd3fd811e4238",
          "md5": "e1a336e97ebb9691d010dd8c2060e6a9",
          "sha256": "c1d2603b8a07855ad5bc95225ebd25bfbebc22b42f986cac8057b490ff56e515"
        },
        "downloads": -1,
        "filename": "thai_tokenizer-0.2.4.tar.gz",
        "has_sig": false,
        "md5_digest": "e1a336e97ebb9691d010dd8c2060e6a9",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 6550,
        "upload_time": "2021-03-17T08:09:12",
        "upload_time_iso_8601": "2021-03-17T08:09:12.220364Z",
        "url": "https://files.pythonhosted.org/packages/33/c1/f753d994a4b9aa13b6f072bb51b11d1e32b2d35c4fe9983bd3fd811e4238/thai_tokenizer-0.2.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "812dbb92afb743d152b6ce7c8ea99b232ca615a860130eab2959aedb2ceb4b33",
          "md5": "371751f74f634246cff4298333e05700",
          "sha256": "af7ba74a25e4d444205fc159a2413ca300824d7b3378d7cd6bc26074acb666e4"
        },
        "downloads": -1,
        "filename": "thai_tokenizer-0.2.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "371751f74f634246cff4298333e05700",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 52467,
        "upload_time": "2021-04-07T04:24:02",
        "upload_time_iso_8601": "2021-04-07T04:24:02.944482Z",
        "url": "https://files.pythonhosted.org/packages/81/2d/bb92afb743d152b6ce7c8ea99b232ca615a860130eab2959aedb2ceb4b33/thai_tokenizer-0.2.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "80efaf243b5948557d76b51c32588bde7d6f910243241491a85c58a2ea732803",
          "md5": "3b60fe455d3db0e1aa1bda6417cb4c8b",
          "sha256": "7909d1005a90ce918aa14eb30db47d3b39c9da1106115ccadf3afece53887f24"
        },
        "downloads": -1,
        "filename": "thai_tokenizer-0.2.5.tar.gz",
        "has_sig": false,
        "md5_digest": "3b60fe455d3db0e1aa1bda6417cb4c8b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 6532,
        "upload_time": "2021-04-07T04:24:03",
        "upload_time_iso_8601": "2021-04-07T04:24:03.840452Z",
        "url": "https://files.pythonhosted.org/packages/80/ef/af243b5948557d76b51c32588bde7d6f910243241491a85c58a2ea732803/thai_tokenizer-0.2.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "812dbb92afb743d152b6ce7c8ea99b232ca615a860130eab2959aedb2ceb4b33",
        "md5": "371751f74f634246cff4298333e05700",
        "sha256": "af7ba74a25e4d444205fc159a2413ca300824d7b3378d7cd6bc26074acb666e4"
      },
      "downloads": -1,
      "filename": "thai_tokenizer-0.2.5-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "371751f74f634246cff4298333e05700",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 52467,
      "upload_time": "2021-04-07T04:24:02",
      "upload_time_iso_8601": "2021-04-07T04:24:02.944482Z",
      "url": "https://files.pythonhosted.org/packages/81/2d/bb92afb743d152b6ce7c8ea99b232ca615a860130eab2959aedb2ceb4b33/thai_tokenizer-0.2.5-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "80efaf243b5948557d76b51c32588bde7d6f910243241491a85c58a2ea732803",
        "md5": "3b60fe455d3db0e1aa1bda6417cb4c8b",
        "sha256": "7909d1005a90ce918aa14eb30db47d3b39c9da1106115ccadf3afece53887f24"
      },
      "downloads": -1,
      "filename": "thai_tokenizer-0.2.5.tar.gz",
      "has_sig": false,
      "md5_digest": "3b60fe455d3db0e1aa1bda6417cb4c8b",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 6532,
      "upload_time": "2021-04-07T04:24:03",
      "upload_time_iso_8601": "2021-04-07T04:24:03.840452Z",
      "url": "https://files.pythonhosted.org/packages/80/ef/af243b5948557d76b51c32588bde7d6f910243241491a85c58a2ea732803/thai_tokenizer-0.2.5.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}