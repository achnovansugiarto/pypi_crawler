{
  "info": {
    "author": "Gregor Lichtner",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: GNU General Public License v3 (GPLv3)",
      "Operating System :: MacOS",
      "Operating System :: POSIX",
      "Operating System :: Unix",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9"
    ],
    "description": "PypeRunner - Pure Python ETL Pipeline\n#####################################\n.. start-badges\n\n.. image:: https://readthedocs.org/projects/pyperunner/badge/?version=latest\n    :target: https://pyperunner.readthedocs.io/en/latest/?badge=latest\n    :alt: Documentation Status\n\n.. image:: https://badge.fury.io/py/pyperunner.svg\n    :alt: PyPI Package latest release\n    :target: https://pypi.org/project/pyperunner\n\n.. image:: https://img.shields.io/pypi/pyversions/pyperunner.svg\n    :alt: Supported Python Versions\n    :target: https://pypi.org/project/pyperunner/\n\n.. image:: https://pepy.tech/badge/pyperunner\n    :alt: Downloads\n    :target: https://pepy.tech/project/pyperunner/\n\n.. end-badges\n\nPypeRunner is an easy to use yet powerful workflow pipeline tool written in pure python, with parallel processing of tasks, smart\ncaching of results and reproducible runs.\nPypeRunner allows for the creation of complex workflows with branching and merging of several concurrent execution flows.\n\nFeatures\n========\n\n- Easy to use extract, transform load (ETL) pipeline tool\n- Reproducible pipeline runs for data science / machine learning tasks\n- Easy creation of pipelines using functional API chaining (see below)\n- Parallel processing of steps\n- Caching of previously run steps to speed up processing\n- Re-run of steps (and all subsequent steps) when parameters are changed\n- Save & read pipelines to/from yaml\n- Graphical output of pipeline run\n\nInstallation\n============\n\nInstall from conda forge via\n\n.. code-block:: bash\n\n    conda install pyperunner -c conda-forge\n\n\nInstall from pip via\n\n.. code-block:: bash\n\n    pip install pyperunner\n\nOr from source via\n\n.. code-block:: bash\n\n    git clone https://github.com/glichtner/pyperunner.git\n    cd pyperunner\n    python setup.py install\n\n\nQuickstart\n==========\n\nPyperunner has three basic components:\n\n* **Task**: Definition of the work to do (Python classes or functions)\n* **Pipeline**: A collection of tasks that are connected in a directed fashion\n* **Runner**: The executor of a pipeline\n\nHello world example\n-------------------\n\n.. code-block:: python\n\n    from pyperunner import Runner, Pipeline, task\n\n\n    @task(\"Hello\", receives_input=False)\n    def hello():\n        print(\"in hello()\")\n        return \"Hello\"\n\n\n    @task(\"World\")\n    def world(data):\n        hello = data[\"Hello()\"]\n        print(\"in world()\")\n        return f\"{hello} world\"\n\n\n    # instantiate and connect tasks\n    hello = hello()\n    world = world()(hello)\n\n    # create pipeline and set root element\n    pipeline = Pipeline(\"hello-world-example\", [hello])\n\n    # print a summary of the pipeline\n    pipeline.summary()\n\n    # run pipeline\n    runner = Runner(data_path=\"data/\", log_path=\"log/\")\n    runner.run(pipeline)\n\n    # get pipeline results object from the pipeline that was just run\n    results = runner.results()\n\n    # show the results\n    for task_name in results:\n        print(f\"Output of task '{task_name}' was '{results[task_name]}'\")\n\n\n\nRunning this script outputs the following:\n\n.. code-block:: console\n\n    ~/pyperunner/examples$ python hello-world-func.py\n\n    +---------+\n    | Hello() |\n    +---------+\n          *\n          *\n          *\n    +---------+\n    | World() |\n    +---------+\n\n    2021-01-03 20:55:47 INFO     MainProcess  root       Storing pipeline parameters in examples/log/hello-world-example_210103T205547/pipeline.yaml\n    2021-01-03 20:55:47 INFO     MainProcess  root       Storing pipeline data in examples/data\n    2021-01-03 20:55:47 INFO     Process-1    Hello()    Starting\n    2021-01-03 20:55:47 INFO     Process-1    Hello()    in hello()\n    2021-01-03 20:55:47 INFO     Process-1    Hello()    Finished: Status.SUCCESS\n    2021-01-03 20:55:47 INFO     Process-2    World()    Starting\n    2021-01-03 20:55:47 INFO     Process-2    World()    in world()\n    2021-01-03 20:55:47 INFO     Process-2    World()    Finished: Status.SUCCESS\n    2021-01-03 20:55:47 INFO     MainProcess  root       Pipeline run finished\n\n    Output of task 'Hello()' was 'Hello'\n    Output of task 'World()' was 'Hello world'\n\n\nNote that if you re-run the script, pyperunner will detect that the current configuration has already run and\nwill skip the execution of these tasks:\n\n.. code-block:: console\n\n    ~/pyperunner/examples$ python hello-world.py\n\n    2021-01-03 20:56:36 INFO     MainProcess  root       No need to execute task \"Hello()\", skipping it\n    2021-01-03 20:56:36 INFO     MainProcess  root       No need to execute task \"World()\", skipping it\n    2021-01-03 20:56:36 INFO     MainProcess  root       Pipeline run finished\n\nIf you need to reprocess outputs, just add the `force_reload=True` parameter to the pipeline run:\n\n.. code-block:: python\n\n    runner.run(pipeline, force_reload=True)\n\nOr to run just a specific task again, use the `reload=True` parameter when initializing the task:\n\n.. code-block:: python\n\n    # instantiate and connect tasks\n    hello = hello()\n    world = world(reload=True)(hello)\n\nNote that pyperunner detects which tasks it must re-execute: All depending tasks of a reloaded task are automatically\nre-executed, and only those tasks are fully skipped from execution from which the output is not required in a successor\ntask. Also, if a task has been previously executed and its output is required, it is read from disk.\n\n.. code-block:: console\n\n    ~/pyperunner/examples$ python hello-world.py\n\n    2021-01-03 20:57:26 INFO     Process-1    Hello()    Starting\n    2021-01-03 20:57:26 INFO     Process-1    Hello()    Loading output from disk, skipping processing\n    2021-01-03 20:57:26 INFO     Process-1    Hello()    Finished: Status.SUCCESS\n    2021-01-03 20:57:26 INFO     Process-2    World()    Starting\n    2021-01-03 20:57:26 INFO     Process-2    World()    in world()\n    2021-01-03 20:57:26 INFO     Process-2    World()    Finished: Status.SUCCESS\n    2021-01-03 20:57:26 INFO     MainProcess  root       Pipeline run finished\n\n\nAt each run, the pipeline is automatically stored in a yaml file in the log path to ensure reproducibility:\n\n.. code-block:: yaml\n\n    pipeline:\n      name: hello-world-example\n    tasks:\n      Hello():\n        hash: 22179f3afd85ab64dd32c63bc21a9eb4\n        module: __main__\n        name: Hello\n        params: {}\n        parents: []\n        tag: ''\n      World():\n        hash: f7d904856f2aa4fda20e05521298397f\n        module: __main__\n        name: World\n        params: {}\n        parents:\n        - Hello()\n        tag: ''\n\nAdditionally, a graphical representation of the run is saved in the log path:\n\n.. image:: examples/hello-world-status.png\n   :width: 20%\n   :alt: Hello World pipeline status\n   :align: center\n\nDocumentation\n=============\n\nThe `API Reference <http://pyperunner.readthedocs.io>`_ provides API-level documentation.\n\nExamples\n========\n\nLook in the examples/ directory for some example scripts.\n\nMultiple paths pipeline\n-----------------------\n.. code-block:: python\n\n   # Create pipeline\n    pipeline = Pipeline(\"my-pipeline\")\n\n    # Create first stream of tasks: LoadData(csv) --> ProcessData(normalize-l2)\n    load_db = LoadData(\n        \"database\",\n        database={\"host\": \"localhost\", \"username\": \"user\", \"password\": \"password\"},\n        wait=10,\n    )\n    norm_l2 = ProcessData(\"normalize-l2\", norm=\"l2\", axis=0, wait=1)(load_db)\n\n    # Create second stream of tasks:\n    #  LoadData(csv) --> ProcessData(normalize-l1) --> AugmentData(augment)\n    load_csv = LoadData(\"csv\", filename=\"data.csv\", wait=1)\n    norm_l1 = ProcessData(\"normalize-l1\", norm=\"l1\", wait=1)(load_csv)\n    augment = AugmentData(\"augment\", types=[\"rotate\", \"noise\"], wait=1)(norm_l1)\n\n    # Combine outputs of both streams (ProcessData(normalize-l2)\n    # and AugmentData(augment)), additionally add output from ProcessData(normalize-l1)\n    evaluate = Evaluate(\"both\", wait=1)([norm_l1, norm_l2, augment])\n\n    # Add the roots of both streams to the pipeline\n    pipeline.add(load_db)\n    pipeline.add(load_csv)\n\n    # print a summary of the pipeline\n    pipeline.summary()\n\n    # Run pipeline\n    runner = Runner(data_path=\"data/\", log_path=\"log/\")\n    runner.run(pipeline, force_reload=False)\n\n`pipeline.summary()` prints the following ascii summary:\n\n.. code-block:: raw\n\n                                                                          +---------------+\n                                                                          | LoadData(csv) |\n                                                                          +---------------+\n                                                                                  *\n                                                                                  *\n                                                                                  *\n        +--------------------+                                      +---------------------------+\n        | LoadData(database) |                                      | ProcessData(normalize-l1) |\n        +--------------------+                                      +---------------------------+\n                  *                                                    ***                  ***\n                  *                                                ****                        ***\n                  *                                              **                               ****\n    +---------------------------+                 +----------------------+                          ****\n    | ProcessData(normalize-l2) |                 | AugmentData(augment) |                   *******\n    +---------------------------+****             +----------------------+            *******\n                                     *******                  *                *******\n                                            *******          *          *******\n                                                   ****      *      ****\n                                                    +----------------+\n                                                    | Evaluate(both) |\n                                                    +----------------+\n\nNotice how multiple tasks run simultaneously:\n\n.. code-block:: shell\n\n    2021-01-03 19:09:05 INFO     Process-1    LoadData(csv)                  Starting\n    2021-01-03 19:09:05 INFO     Process-2    LoadData(database)             Starting\n    2021-01-03 19:09:06 INFO     Process-1    LoadData(csv)                  Finished: Status.SUCCESS\n    2021-01-03 19:09:06 INFO     Process-3    ProcessData(normalize-l1)      Starting\n    2021-01-03 19:09:07 INFO     Process-3    ProcessData(normalize-l1)      Finished: Status.SUCCESS\n    2021-01-03 19:09:07 INFO     Process-4    AugmentData(augment)           Starting\n    2021-01-03 19:09:08 INFO     Process-4    AugmentData(augment)           Finished: Status.SUCCESS\n    2021-01-03 19:09:15 INFO     Process-2    LoadData(database)             Finished: Status.SUCCESS\n    2021-01-03 19:09:15 INFO     Process-5    ProcessData(normalize-l2)      Starting\n    2021-01-03 19:09:16 INFO     Process-5    ProcessData(normalize-l2)      Finished: Status.SUCCESS\n    2021-01-03 19:09:16 INFO     Process-6    Evaluate(both)                 Starting\n    2021-01-03 19:09:17 INFO     Process-6    Evaluate(both)                 Finished: Status.SUCCESS\n\n.. image:: examples/multi-path-status.png\n   :width: 20%\n   :alt: Multi path pipeline status\n   :align: center\n\n\n.. _change-log-label:\n\nChange Log\n==========\n\nVersion History\n---------------\n\n0.1.1\n    * Added LICENSE to source dist\n\n0.1.1\n    * Fixed setup.py for conda installation\n\n0.1.0\n    * PypeRunner's first release",
    "description_content_type": "",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/glichtner/pyperunner/",
    "keywords": "pyperunner",
    "license": "GNU General Public License v3",
    "maintainer": "Gregor Lichtner",
    "maintainer_email": "",
    "name": "pyperunner",
    "package_url": "https://pypi.org/project/pyperunner/",
    "platform": "",
    "project_url": "https://pypi.org/project/pyperunner/",
    "project_urls": {
      "Homepage": "https://github.com/glichtner/pyperunner/"
    },
    "release_url": "https://pypi.org/project/pyperunner/0.1.2/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "Yet another ETL pipeline runner for python, using multiprocessing and directed acyclic graphs.",
    "version": "0.1.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 9217274,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d1674334d28a0c341b849a418f98f70ceb515d7abd0c71f40aded986497815c6",
          "md5": "848e4b0fe29dde874803be47130a2d70",
          "sha256": "b99bf80c25bdcd26350feb9d59a5c158c74019d1f967d82f2f75ab9448378190"
        },
        "downloads": -1,
        "filename": "pyperunner-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "848e4b0fe29dde874803be47130a2d70",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 129707,
        "upload_time": "2021-01-23T18:11:38",
        "upload_time_iso_8601": "2021-01-23T18:11:38.829383Z",
        "url": "https://files.pythonhosted.org/packages/d1/67/4334d28a0c341b849a418f98f70ceb515d7abd0c71f40aded986497815c6/pyperunner-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.0rc1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a429aa38043201be2faec166563636ecb409df377982a83f560a61ef81241091",
          "md5": "b577d365be815d188acdb1d44cc94307",
          "sha256": "8fc45535b8f0bfdb242c38a6d904f246b30211d309a82fdd36845a7a3b102cdb"
        },
        "downloads": -1,
        "filename": "pyperunner-0.1.0rc1-py3.8.egg",
        "has_sig": false,
        "md5_digest": "b577d365be815d188acdb1d44cc94307",
        "packagetype": "bdist_egg",
        "python_version": "3.8",
        "requires_python": null,
        "size": 19968,
        "upload_time": "2021-01-03T18:26:50",
        "upload_time_iso_8601": "2021-01-03T18:26:50.387624Z",
        "url": "https://files.pythonhosted.org/packages/a4/29/aa38043201be2faec166563636ecb409df377982a83f560a61ef81241091/pyperunner-0.1.0rc1-py3.8.egg",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2b958cfa0d27b6591d7290e7a82249add460663e8423938d9a5f59eb032d7212",
          "md5": "f86ae7a41b3ab0277ae88d1af3bdd80c",
          "sha256": "e3c4d2bc49bb397ba4c52a33041d791e5b7832c8484d5c3b80a8ad72f1d04ff2"
        },
        "downloads": -1,
        "filename": "pyperunner-0.1.0rc1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f86ae7a41b3ab0277ae88d1af3bdd80c",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 32965,
        "upload_time": "2021-01-03T18:26:48",
        "upload_time_iso_8601": "2021-01-03T18:26:48.595990Z",
        "url": "https://files.pythonhosted.org/packages/2b/95/8cfa0d27b6591d7290e7a82249add460663e8423938d9a5f59eb032d7212/pyperunner-0.1.0rc1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f07b9550aea7800e2d8a93513634f9fedf629a8cacd366bdff78cbf4e705b394",
          "md5": "a05d7a4d381960edfed450db20616228",
          "sha256": "2e11545e470b7f3f755ec67948469ddde5e77c4d38791c1ad6e8c237017b519e"
        },
        "downloads": -1,
        "filename": "pyperunner-0.1.0rc1.tar.gz",
        "has_sig": false,
        "md5_digest": "a05d7a4d381960edfed450db20616228",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 17993,
        "upload_time": "2021-01-03T18:26:51",
        "upload_time_iso_8601": "2021-01-03T18:26:51.899526Z",
        "url": "https://files.pythonhosted.org/packages/f0/7b/9550aea7800e2d8a93513634f9fedf629a8cacd366bdff78cbf4e705b394/pyperunner-0.1.0rc1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6f72a239111551e9a04ca2d404c51c26dfdacd0dde77fe7fc414da658e652f21",
          "md5": "8ecd39c3bfc322ba5110b436576fc08d",
          "sha256": "0c60100a21af863f8315e120a777448b4051748017e922c5818bb636812c9e37"
        },
        "downloads": -1,
        "filename": "pyperunner-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "8ecd39c3bfc322ba5110b436576fc08d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 130173,
        "upload_time": "2021-01-24T18:05:41",
        "upload_time_iso_8601": "2021-01-24T18:05:41.374975Z",
        "url": "https://files.pythonhosted.org/packages/6f/72/a239111551e9a04ca2d404c51c26dfdacd0dde77fe7fc414da658e652f21/pyperunner-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cf77529295472902ae0907caeeaaa68c0142cd9a9c679c43958aab3ed370c2f2",
          "md5": "0cc08ca021f2da254c95f55b57dcb24a",
          "sha256": "beb73a64290beb5553cbc3bd1b128191658d8e94d7913fcf4e1e3edff88dfb03"
        },
        "downloads": -1,
        "filename": "pyperunner-0.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "0cc08ca021f2da254c95f55b57dcb24a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 142035,
        "upload_time": "2021-01-24T18:29:45",
        "upload_time_iso_8601": "2021-01-24T18:29:45.452746Z",
        "url": "https://files.pythonhosted.org/packages/cf/77/529295472902ae0907caeeaaa68c0142cd9a9c679c43958aab3ed370c2f2/pyperunner-0.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "cf77529295472902ae0907caeeaaa68c0142cd9a9c679c43958aab3ed370c2f2",
        "md5": "0cc08ca021f2da254c95f55b57dcb24a",
        "sha256": "beb73a64290beb5553cbc3bd1b128191658d8e94d7913fcf4e1e3edff88dfb03"
      },
      "downloads": -1,
      "filename": "pyperunner-0.1.2.tar.gz",
      "has_sig": false,
      "md5_digest": "0cc08ca021f2da254c95f55b57dcb24a",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 142035,
      "upload_time": "2021-01-24T18:29:45",
      "upload_time_iso_8601": "2021-01-24T18:29:45.452746Z",
      "url": "https://files.pythonhosted.org/packages/cf/77/529295472902ae0907caeeaaa68c0142cd9a9c679c43958aab3ed370c2f2/pyperunner-0.1.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}