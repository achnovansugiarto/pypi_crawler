{
  "info": {
    "author": "Kiran R",
    "author_email": "kiranr8k@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Developers",
      "License :: OSI Approved :: Apache Software License",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Topic :: Scientific/Engineering :: Artificial Intelligence"
    ],
    "description": "![fastt5 icon](https://raw.githubusercontent.com/Ki6an/fastT5/master/data/fastT5.png)\n\n<h1 style=\"text-align:center; font-weight:bold;\nfont-size:1.875rem\">Reduce T5 model size by 3X and increase the inference speed up to 5X.\n</h1>\n\n<p align=\"center\">\n    <a href=\"https://github.com/Ki6an/fastT5/blob/master/LICENSE\">\n        <img alt=\"GitHub\" src=\"https://img.shields.io/github/license/ki6an/fastt5?color=blue\">\n    </a>\n    <a href=\"https://github.com/Ki6an/fastT5/actions/workflows/ci-workflow.yml\">\n        <img alt=\"Workflow\" src=\"https://github.com/ki6an/fastT5/actions/workflows/ci-workflow.yml/badge.svg\">\n    </a>\n    <a href=\"https://github.com/Ki6an/fastT5/releases\" >\n        <img alt=\"PYPI release\" src=\"https://img.shields.io/pypi/v/fastt5\">\n    </a>\n    <a href=\"https://github.com/Ki6an/fastT5\" >\n        <img alt=\"Workflow\" src=\"https://img.shields.io/pypi/dm/fastt5\">\n    </a>\n </p>\n\n</br>\n\n- [Install](#install)\n- [Usage](#usage)\n- [Details](#details)\n- [Functionalities](#functionalities)\n- [Benchmarks](#benchmarks)\n  - [Onnx model](#onnx-model)\n  - [Quantized onnx model](#quantized-onnx-model)\n- [Quantized model scores](#quantized-model-scores)\n- [further improvements](#further-improvements)\n- [License](#license)\n- [Get Help](#get-help)\n- [Acknowledgements](#acknowledgements)\n\nT5 models can be used for several NLP tasks such as summarization, QA, QG, translation, text generation, and more. Sequential text generation is naturally slow, and for larger T5 models it gets even slower. **fastT5** makes the T5 models inference faster by running it on onnxruntime. and it also decreases the model size by quantizing it.\n\nfastT5 library allows you to convert a pretrained T5 model to onnx, quantizes it, and gives the model as output which is running on an onnxruntime in a single line of code. You can also customize this whole process.\n\n---\n\n## Install\n\nYou can install fastT5 from PyPI:\n\n```python\n pip install fastt5\n```\n\nIf you want to build from source:\n\n```python\ngit clone https://github.com/Ki6an/fastT5\ncd fastT5\npip3 install -e .\n```\n\n## Usage\n\nThe `export_and_get_onnx_model()` method exports the given pretrained T5 model to onnx, quantizes it and runs it on the onnxruntime with default settings. The returned model from this method supports the `generate()` method of huggingface.\n\n> If you don't wish to quantize the model then use `quantized=False` in the method.\n\n```python\nfrom fastT5 import export_and_get_onnx_model\nfrom transformers import AutoTokenizer\n\nmodel_name = 't5-small'\nmodel = export_and_get_onnx_model(model_name)\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nt_input = \"translate English to French: The universe is a dark forest.\"\ntoken = tokenizer(t_input, return_tensors='pt')\n\ntokens = model.generate(input_ids=token['input_ids'],\n               attention_mask=token['attention_mask'],\n               num_beams=2)\n\noutput = tokenizer.decode(tokens.squeeze(), skip_special_tokens=True)\nprint(output)\n```\n\n> to run the already exported model use `get_onnx_model()`\n\nyou can customize the whole pipeline as shown in the below code example:\n\n```python\nfrom fastT5 import (OnnxT5, get_onnx_runtime_sessions,\n                    generate_onnx_representation, quantize)\nfrom transformers import AutoTokenizer\n\nmodel_or_model_path = 't5-small'\n\n# Step 1. convert huggingfaces t5 model to onnx\nonnx_model_paths = generate_onnx_representation(model_or_model_path)\n\n# Step 2. (recommended) quantize the converted model for fast inference and to reduce model size.\nquant_model_paths = quantize(onnx_model_paths)\n\n# step 3. setup onnx runtime\nmodel_sessions = get_onnx_runtime_sessions(quant_model_paths)\n\n# step 4. get the onnx model\nmodel = OnnxT5(model_or_model_path, model_sessions)\n\n                      ...\n```\n##### custom output paths \nBy default, fastT5 creates a `models` folder in the current directory and stores all the models. You can provide a custom path for a folder to store the exported models. And to run already `exported models` that are stored in a custom folder path: use `get_onnx_model(onnx_models_path=\"/path/to/custom/folder/\")`\n\n```python\nfrom fastT5 import export_and_get_onnx_model, get_onnx_model\n\nmodel_name = \"t5-small\"\ncustom_output_path = \"/path/to/custom/folder/\"\n\n# 1. stores models to custom_output_path\nmodel = export_and_get_onnx_model(model_name, custom_output_path)\n\n# 2. run already exported models that are stored in custom path\n# model = get_onnx_model(model_name, custom_output_path)\n\n```\n\n## Details\n\nT5 is a `seq2seq` model (Encoder-Decoder), as it uses decoder repeatedly for inference, we can't directly export the whole model to onnx. We need to export the encoder and decoder separately.\n\n> `past_key_values` contain pre-computed hidden-states (key and values in the self-attention blocks and cross-attention blocks) that can be used to speed up sequential decoding.\n\nmodels can only be exported with a constant number of inputs. Contrary to this, the decoder of the first step does not take `past_key_values` and the rest of the steps decoders do. To get around this issue, we can create two decoders: one for the first step that does not take `past_key_values` and another for the rest of the steps that utilize the `past_key_values`.\n\nNext, we'll export all three models (encoder, decoder, init_decoder). And then quantize them, quantizing `32bit` to `8bit` should give the 4x memory reduction. Since there is an extra decoder the model size reduces by 3x.\n\nFinally, we'll run the quantized model on onnx runtime.\n\n> The inference is simple as the model supports the [`generate()`](https://huggingface.co/transformers/main_classes/model.html?highlight=generate#transformers.generation_utils.GenerationMixin.generate) method of huggingface.\n\n## Functionalities\n\n- Export any pretrained T5 model to ONNX easily (with `past_key_values`).\n- The exported model supports beam search and greedy search and more via `generate()` method.\n- Reduce the model size by `3X` using quantization.\n- Up to `5X` speedup compared to PyTorch execution for greedy search and `3-4X` for beam search.\n\n## Benchmarks\n\nThe benchmarks are the result of the T5-base model tested on English to French translation.\n\n### Onnx model\n\nThe following graph shows the latency of the quantized onnx model vs the PyTorch model for beam numbers varying from 1 to 9. The latencies shown here are for the mean of sequence lengths up to 130.\n\n![t5-base](https://raw.githubusercontent.com/Ki6an/fastT5/master/data/t5-base.png)\n\nThe following heat map shows the X times faster which the ratio of latency of PyTorch to onnx model.\nThe onnx model outperforms most cases. however, the speed of the model drops for a longer sequence length.\n\n![t5-base-hist](https://raw.githubusercontent.com/Ki6an/fastT5/master/data/t5_base_h.png)\n\n### Quantized onnx model\n\nQuantized models are lightweight models as mentioned earlier, these models have almost the same accuracy as the original model (quantized model scores are mentioned in the next section). Quantized onnx models have the lowest latency compared to both Onnx & PyTorch models.\n\n![t5-base-quant](https://raw.githubusercontent.com/Ki6an/fastT5/master/data/t5-base-quant.png)\n\nThe model outperforms the PyTorch model by 5.7X for greedy search on average and 3-4X for beam search.\n\n![t5-base-quant-hist](https://raw.githubusercontent.com/Ki6an/fastT5/master/data/t5_base_quant_h.png)\n\n> Note : The results were generated on `AMD EPYC 7B12`, these results may vary from device to device. The Onnx models usually perform well on high-end CPUs with more cores.\n\n## Quantized model scores\n\nThe results were tested for English to French translation with beam search number of 3.\n\n|                    | Bleu_4   | METEOR   | ROUGE_L  |\n| ------------------ | -------- | -------- | -------- |\n| t5-small (quant)   | 0.240769 | 0.282342 | 0.468817 |\n| t5-small (pytorch) | 0.254601 | 0.295172 | 0.492749 |\n| t5-base (quant)    | 0.267606 | 0.306019 | 0.499188 |\n| t5-base (pytorch)  | 0.268346 | 0.304969 | 0.503306 |\n| t5-large (quant)   | 0.286726 | 0.316845 | 0.503585 |\n| t5-large (pytorch) | 0.294015 | 0.315774 | 0.508677 |\n\n## Private HuggingFace Model Hub Models\n\nThe [HuggingFace model hub](https://huggingface.co/models) supports private models. To use a private, pre-trained version of T5 with fastT5 you first must have authenticated into HuggingFace ecosystem with `$ transformers-cli login`. Then, when using fastT5, there is an extra import and call:\n\n```python\nfrom fastT5 import (\n    OnnxT5,\n    get_onnx_runtime_sessions,\n    generate_onnx_representation,\n    quantize,\n    set_auth_token)\nfrom transformers import AutoTokenizer\n\nset_auth_token(True)\n# the rest of the code is the same as using a public model\n```\n\nIf you are unable to call `$ transformers-cli login` or prefer to use your API Key, found at https://huggingface.co/settings/token (or https://huggingface.co/organizations/ORG_NAME/settings/token for organizations), you can pass that as a string to `set_auth_token`. Avoid hard-coding your API key into code by setting the environment variable `HF_API_KEY=<redacted>`, and then in code:\n\n```python\nimport os\n\nfrom fastT5 import (\n    OnnxT5,\n    get_onnx_runtime_sessions,\n    generate_onnx_representation,\n    quantize,\n    set_auth_token)\nfrom transformers import AutoTokenizer\n\nauth_token = os.environ.get(\"HF_API_KEY\")\nset_auth_token(auth_token)\n\n# code proceeds as normal\n```\n\n## further improvements\n\n- currently the fastT5 library supports only the cpu version of onnxruntime, gpu implementation still needs to be done.\n- graph optimization of the onnx model will further reduce the latency.\n\n## Get Help\n\n- Contact me at kiranr8k@gmail.com\n- If appropriate, [open an issue](https://github.com/Ki6an/fastT5/issues/new/choose) on GitHub\n\n## Acknowledgements\n\n- [original T5 paper](https://arxiv.org/pdf/1910.10683.pdf)\n- [transformers](https://github.com/huggingface/transformers) by huggingface\n- [onnx](https://github.com/onnx/onnx)\n- [onnxruntime](https://github.com/microsoft/onnxruntime) by microsoft\n- [onnxt5](https://github.com/abelriboulot/onnxt5)\n\n```python\n@article{2019t5,\n  author = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},\n  title = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},\n  journal = {arXiv e-prints},\n  year = {2019},\n  archivePrefix = {arXiv},\n  eprint = {1910.10683},\n}\n```",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/Ki6an/fastT5",
    "keywords": "T5,ONNX,onnxruntime,NLP,transformer,quantization,generate text,summarization,translation,q&a,qg,machine learning,inference,fast inference",
    "license": "apache-2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "fastt5",
    "package_url": "https://pypi.org/project/fastt5/",
    "platform": null,
    "project_url": "https://pypi.org/project/fastt5/",
    "project_urls": {
      "Bug Tracker": "https://github.com/Ki6an/fastT5/issues",
      "Homepage": "https://github.com/Ki6an/fastT5",
      "Repo": "https://github.com/Ki6an/fastT5"
    },
    "release_url": "https://pypi.org/project/fastt5/0.1.4/",
    "requires_dist": null,
    "requires_python": ">=3.5",
    "summary": "boost inference speed of T5 models by 5x & reduce the model size by 3x using fastT5.",
    "version": "0.1.4",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 13410184,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d2c5bf54635c8f3cbc46ed5b854614e08b56ed62de8a7596754e3b6bbfaa44b7",
          "md5": "0065d9e9ff2aacf6af4c57754bad5ec6",
          "sha256": "664c33ac1573b4c2da19e075aed47e7fe8c52645be2d8a0b1e0e01630b17e0d7"
        },
        "downloads": -1,
        "filename": "fastt5-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0065d9e9ff2aacf6af4c57754bad5ec6",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.5",
        "size": 18559,
        "upload_time": "2021-03-11T07:12:21",
        "upload_time_iso_8601": "2021-03-11T07:12:21.306398Z",
        "url": "https://files.pythonhosted.org/packages/d2/c5/bf54635c8f3cbc46ed5b854614e08b56ed62de8a7596754e3b6bbfaa44b7/fastt5-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b91eb7afae32f18d0131b1d45ec0f01791762d631d1834477f5e2da7e9b3ba6c",
          "md5": "87a0194b5aae5428c81860d65d760a26",
          "sha256": "4204b9efdf5019951db8026195e35c0228d247acb8410918e370657a6f1f17cb"
        },
        "downloads": -1,
        "filename": "fastt5-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "87a0194b5aae5428c81860d65d760a26",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 15531,
        "upload_time": "2021-03-11T07:12:23",
        "upload_time_iso_8601": "2021-03-11T07:12:23.264257Z",
        "url": "https://files.pythonhosted.org/packages/b9/1e/b7afae32f18d0131b1d45ec0f01791762d631d1834477f5e2da7e9b3ba6c/fastt5-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "52630730fb2a04387d3b780a2eb353364e70d34a9662df756de19bca38885355",
          "md5": "259259632306f465c44ee9b029a3e577",
          "sha256": "a46a56e0a3439818017a25839dc9c2329267d81e9e67cd28c2a7ff239fa571d1"
        },
        "downloads": -1,
        "filename": "fastt5-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "259259632306f465c44ee9b029a3e577",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 15481,
        "upload_time": "2021-03-11T08:22:10",
        "upload_time_iso_8601": "2021-03-11T08:22:10.535929Z",
        "url": "https://files.pythonhosted.org/packages/52/63/0730fb2a04387d3b780a2eb353364e70d34a9662df756de19bca38885355/fastt5-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ba1f157d111af0d4d78c9c6bb52738c7fe8c20b3c4f6b4940b2cab4f0b6e42c4",
          "md5": "91650ab94308f363286b7ddaf30a4f82",
          "sha256": "7812f40e798216549d8439ed67ae37f6360a27cfe548caa57f688df9d0f8d430"
        },
        "downloads": -1,
        "filename": "fastt5-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "91650ab94308f363286b7ddaf30a4f82",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 15532,
        "upload_time": "2021-03-11T09:03:45",
        "upload_time_iso_8601": "2021-03-11T09:03:45.760650Z",
        "url": "https://files.pythonhosted.org/packages/ba/1f/157d111af0d4d78c9c6bb52738c7fe8c20b3c4f6b4940b2cab4f0b6e42c4/fastt5-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "86c6e9d4423e74dc66d61d703ef24f148ba424e2a71949592f9ded0b4f333c7d",
          "md5": "6771a611816d5d8fabd2c0d0c0a1ff47",
          "sha256": "53e14dbc33c351b71efde4b7629992add2989cc8fa88b6e1be6044eba5b67976"
        },
        "downloads": -1,
        "filename": "fastt5-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "6771a611816d5d8fabd2c0d0c0a1ff47",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 15527,
        "upload_time": "2021-03-18T12:45:38",
        "upload_time_iso_8601": "2021-03-18T12:45:38.161060Z",
        "url": "https://files.pythonhosted.org/packages/86/c6/e9d4423e74dc66d61d703ef24f148ba424e2a71949592f9ded0b4f333c7d/fastt5-0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d00f85e973a62085b3562ea12745b64d235408eb06c6adbcdde6d9c99c9efc9d",
          "md5": "7bed4c91781023d493095f19efceab66",
          "sha256": "9236cfcde584bb9220a99a6bf6281ef021d8a4a932b0487cc479bf73d9a9e294"
        },
        "downloads": -1,
        "filename": "fastt5-0.0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "7bed4c91781023d493095f19efceab66",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 15752,
        "upload_time": "2021-04-09T16:14:11",
        "upload_time_iso_8601": "2021-04-09T16:14:11.458501Z",
        "url": "https://files.pythonhosted.org/packages/d0/0f/85e973a62085b3562ea12745b64d235408eb06c6adbcdde6d9c99c9efc9d/fastt5-0.0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "dac96845af1a4e5e7825fb7d3d32d9a4abbac4953de0e27b0d2d49ad76b818ee",
          "md5": "a1084823b7af17fce990a1312e88781b",
          "sha256": "411def8a8b32cf4dd143cd15acb93eef90fdc9d0aa85871321ce020b0d35f910"
        },
        "downloads": -1,
        "filename": "fastt5-0.0.6.tar.gz",
        "has_sig": false,
        "md5_digest": "a1084823b7af17fce990a1312e88781b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 16013,
        "upload_time": "2021-07-15T09:51:05",
        "upload_time_iso_8601": "2021-07-15T09:51:05.905152Z",
        "url": "https://files.pythonhosted.org/packages/da/c9/6845af1a4e5e7825fb7d3d32d9a4abbac4953de0e27b0d2d49ad76b818ee/fastt5-0.0.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6a4efe57cbd93b0320f502d40707f15adb8f76be4b12c8779a45ea79d9c98ff1",
          "md5": "d51961585d1a66937b0373f6471bef9f",
          "sha256": "2829bee0b9c80bccdf84e5c430a0b880a8f5dbf5b8894a1e739151e280597f6e"
        },
        "downloads": -1,
        "filename": "fastt5-0.0.7.tar.gz",
        "has_sig": false,
        "md5_digest": "d51961585d1a66937b0373f6471bef9f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 17292,
        "upload_time": "2021-09-02T06:35:26",
        "upload_time_iso_8601": "2021-09-02T06:35:26.233319Z",
        "url": "https://files.pythonhosted.org/packages/6a/4e/fe57cbd93b0320f502d40707f15adb8f76be4b12c8779a45ea79d9c98ff1/fastt5-0.0.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "035a3b5b9e3dd54b0b1f124a645e0e1e4202b558c5069f11081381a593b9b043",
          "md5": "319476e2fab2122df3b8e6f10a916271",
          "sha256": "a0ecb3a88d8d9a760c35ee3165052bef6b84a2417b5f5c6a593a9c960f0d9a4a"
        },
        "downloads": -1,
        "filename": "fastt5-0.0.8.tar.gz",
        "has_sig": false,
        "md5_digest": "319476e2fab2122df3b8e6f10a916271",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 17338,
        "upload_time": "2021-12-03T03:11:27",
        "upload_time_iso_8601": "2021-12-03T03:11:27.466206Z",
        "url": "https://files.pythonhosted.org/packages/03/5a/3b5b9e3dd54b0b1f124a645e0e1e4202b558c5069f11081381a593b9b043/fastt5-0.0.8.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.9": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5938aad9fab62b5fc906260085f8a2031c0b6c73d3a0801b3203cb287ad934d3",
          "md5": "b666a5a69d7d8de129a60061cd923c8b",
          "sha256": "7b67043958261d56c343ba8a812fcd17ceb5eb4486552a5c937f390e31b920c2"
        },
        "downloads": -1,
        "filename": "fastt5-0.0.9.tar.gz",
        "has_sig": false,
        "md5_digest": "b666a5a69d7d8de129a60061cd923c8b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 17646,
        "upload_time": "2021-12-08T04:10:20",
        "upload_time_iso_8601": "2021-12-08T04:10:20.449274Z",
        "url": "https://files.pythonhosted.org/packages/59/38/aad9fab62b5fc906260085f8a2031c0b6c73d3a0801b3203cb287ad934d3/fastt5-0.0.9.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6edb58e3d2f0982597e8bdcdb5d771c963598492675630a7f35862f5fa831eed",
          "md5": "1df810226458acdbb1fe7c07f7ad3f38",
          "sha256": "b359b11b7b885c6f2c171de4dcce4311b6850eb996b461f98a40ab4bfc8b23ab"
        },
        "downloads": -1,
        "filename": "fastt5-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "1df810226458acdbb1fe7c07f7ad3f38",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 17790,
        "upload_time": "2021-12-23T16:29:01",
        "upload_time_iso_8601": "2021-12-23T16:29:01.776941Z",
        "url": "https://files.pythonhosted.org/packages/6e/db/58e3d2f0982597e8bdcdb5d771c963598492675630a7f35862f5fa831eed/fastt5-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "461c955a0f12e593248f6bc5598215b3c7e3b28752d321b9060d4bdf33b60011",
          "md5": "46cc2ff02743afb65ed0cb9a0247f6f3",
          "sha256": "219ee0cb4976d48b20066eee2188d3afb4a84c92eab06f7f400d7be6fb134481"
        },
        "downloads": -1,
        "filename": "fastt5-0.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "46cc2ff02743afb65ed0cb9a0247f6f3",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 18282,
        "upload_time": "2022-01-06T19:43:48",
        "upload_time_iso_8601": "2022-01-06T19:43:48.642765Z",
        "url": "https://files.pythonhosted.org/packages/46/1c/955a0f12e593248f6bc5598215b3c7e3b28752d321b9060d4bdf33b60011/fastt5-0.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "653bc1857f193c3a0523f336c5dac6dacc3664090bf25e01d33617d039206352",
          "md5": "c53600204a3b35ee3ff59697a4788f6e",
          "sha256": "35b084679ad02da29665cee396dd2966245a0663fe321e8d0b697b7278d82622"
        },
        "downloads": -1,
        "filename": "fastt5-0.1.3.tar.gz",
        "has_sig": false,
        "md5_digest": "c53600204a3b35ee3ff59697a4788f6e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 18304,
        "upload_time": "2022-03-29T14:01:00",
        "upload_time_iso_8601": "2022-03-29T14:01:00.554599Z",
        "url": "https://files.pythonhosted.org/packages/65/3b/c1857f193c3a0523f336c5dac6dacc3664090bf25e01d33617d039206352/fastt5-0.1.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8f2ded6b9fe2a17039d5cda05579d36c244963c7e8a60733a87a805ef60ba1b4",
          "md5": "4466a0d71de36bea5bf31e85605fa836",
          "sha256": "dc49e3669a788e12673c4de37eceae048f1daa72c302bf7aa891369e5ff064ff"
        },
        "downloads": -1,
        "filename": "fastt5-0.1.4.tar.gz",
        "has_sig": false,
        "md5_digest": "4466a0d71de36bea5bf31e85605fa836",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 18305,
        "upload_time": "2022-04-05T03:23:12",
        "upload_time_iso_8601": "2022-04-05T03:23:12.876672Z",
        "url": "https://files.pythonhosted.org/packages/8f/2d/ed6b9fe2a17039d5cda05579d36c244963c7e8a60733a87a805ef60ba1b4/fastt5-0.1.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "8f2ded6b9fe2a17039d5cda05579d36c244963c7e8a60733a87a805ef60ba1b4",
        "md5": "4466a0d71de36bea5bf31e85605fa836",
        "sha256": "dc49e3669a788e12673c4de37eceae048f1daa72c302bf7aa891369e5ff064ff"
      },
      "downloads": -1,
      "filename": "fastt5-0.1.4.tar.gz",
      "has_sig": false,
      "md5_digest": "4466a0d71de36bea5bf31e85605fa836",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.5",
      "size": 18305,
      "upload_time": "2022-04-05T03:23:12",
      "upload_time_iso_8601": "2022-04-05T03:23:12.876672Z",
      "url": "https://files.pythonhosted.org/packages/8f/2d/ed6b9fe2a17039d5cda05579d36c244963c7e8a60733a87a805ef60ba1b4/fastt5-0.1.4.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}