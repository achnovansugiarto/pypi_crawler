{
  "info": {
    "author": "Mingjian He",
    "author_email": "mh105@mit.edu",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Intended Audience :: Developers",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: BSD License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3 :: Only",
      "Topic :: Scientific/Engineering :: Information Analysis",
      "Topic :: Scientific/Engineering :: Mathematics",
      "Topic :: Utilities"
    ],
    "description": "# somata\n\nGithub: https://github.com/mh105/somata\n\n**State-space Oscillator Modeling And Time-series Analysis (SOMATA)** is a Python library for state-space neural signal\nprocessing algorithms developed in the [Purdon Lab](https://purdonlab.mgh.harvard.edu).\nBasic state-space models are introduced as class objects for flexible manipulations.\nClassical exact and approximate inference algorithms are implemented and interfaced as class methods.\nAdvanced neural oscillator modeling techniques are brought together to work synergistically.\n\n[![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](https://github.com/mh105/pot/commits/master)\n[![made-with-python](https://img.shields.io/badge/Made%20with-Python-1f425f.svg)](https://www.python.org/)\n[![License: BSD 3-Clause Clear](https://img.shields.io/badge/License-BSD%203--Clause%20Clear-lightgrey.svg)](https://spdx.org/licenses/BSD-3-Clause-Clear.html)\n[![DOI](https://zenodo.org/badge/556083594.svg)](https://zenodo.org/badge/latestdoi/556083594)\n\n---\n\n## Table of Contents\n* [Requirements](#requirements)\n* [Install](#install)\n* [Basic state-space models](#basic-state-space-models)\n    * [StateSpaceModel](#class-statespacemodel)\n    * [OscillatorModel](#class-oscillatormodelstatespacemodel)\n    * [AutoRegModel](#class-autoregmodelstatespacemodel)\n    * [GeneralSSModel](#class-generalssmodelstatespacemodel)\n* [Advanced neural oscillator methods](#advanced-neural-oscillator-methods)\n* [Authors](#authors)\n* [Citation](#citation)\n* [License](#license)\n\n---\n\n## Requirements\nsomata is built on `numpy` arrays for computations. `joblib` is used for multithreading. Additional dependencies include\n`matplotlib`, `scipy`, `tqdm`, `codetiming`, and `sorcery`. Full requirements for each release version will be updated\nunder `install_requires` in the `setup.cfg` file. If the `environment.yml` file is used to create a new conda\nenvironment, all and only the required packages will be installed.\n\n## Install\n\n```\npip install somata\n```\n\n### (For development only)\n\n- ### Fork this repo to personal git\n    [How to: GitHub fork](https://docs.github.com/en/get-started/quickstart/fork-a-repo)    \n\n- ### Clone forked copy to local computer\n    ``` git clone <forked copy ssh url> ```\n\n- ### Install conda\n    [Recommended conda distribution: miniconda](https://docs.conda.io/en/latest/miniconda.html)\n\n    _Apple silicon Mac: choose conda native to the ARM64 architecture instead of Intel x86_\n\n- ### Create a new conda environment\n    ``` conda install mamba -n base -c conda-forge ```\\\n    ``` cd <repo root directory with environment.yml> ```\\\n    ``` mamba env create -f environment.yml ```\\\n    ``` conda activate somata ```\\\n    _You may also install somata in an existing environment by skipping this step._\n\n- ### Install somata as a package in editable mode\n    ``` cd <repo root directory with setup.py> ```\\\n    ``` pip install -e . ```\n\n- ### Configure IDEs to use the conda environment\n    [How to: Configure an existing conda environment](https://www.jetbrains.com/help/pycharm/conda-support-creating-conda-virtual-environment.html)\n\n---\n\n## Basic state-space models\nSomata, much like a neuron body supported by dendrites, is built on a set of basic state-space models introduced as class objects.\n\nThe motivations are to:\n- develop a standardized format to store model parameters of state-space equations\n- override Python dunder methods so `__repr__` and `__str__` return something useful\n- define arithmetic-like operations such as `A + B` and `A * B`\n- emulate `numpy.array()` operations including `.append()`\n- implement inference algorithms like Kalman filtering and parameter update (m-step) equations as callable class methods\n\nAt present, and in the near future, somata will be focused on **time-invariant Gaussian linear dynamical systems**.\nThis limit on models we consider simplifies basic models to avoid embedded classes such as `transition_model` and\n`observation_model`, at the cost of restricting somata to classical algorithms with only some extensions to\nBayesian inference and learning. This is a deliberate choice to allow easier, faster, and cleaner applications of\nsomata on neural data analysis, instead of to provide a full-fledged statistical inference package.\n\n---\n\n### _class_ StateSpaceModel\n```python\nsomata.StateSpaceModel(components=None, F=None, Q=None, mu0=None, Q0=None, G=None, R=None, y=None, Fs=None)\n```\n`StateSpaceModel` is the parent class of basic state-space models. The corresponding Gaussian linear dynamical system is:\n\n$$\n\\mathbf{x}_ {t} = \\mathbf{F}\\mathbf{x}_{t-1} + \\boldsymbol{\\eta}_t, \\boldsymbol{\\eta}_t \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{Q})\n$$\n\n$$\n\\mathbf{y}_ {t} = \\mathbf{G}\\mathbf{x}_{t} + \\boldsymbol{\\epsilon}_t, \\boldsymbol{\\epsilon}_t \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{R})\n$$\n\n$$\n\\mathbf{x}_0 \\sim \\mathcal{N}(\\mathbf{\\mu}_0, \\mathbf{Q}_0)\n$$\n\nMost of the constructor input arguments correspond to these model parameters, which are stored as instance attributes.\nThere are two additional arguments: `Fs` and `components`.\n\n`Fs` is the sampling frequency of observed data `y`.\n\n`components` is a list of independent components underlying the hidden states $\\mathbf{x}$. The independent components are\nassumed to appear in block-diagonal form in the state equation. For example, $\\mathbf{x}_t$ might have two independent autoregressive\nmodels (AR) of order 1, and the observation matrix is simply $[1, 1]$ that sums these two components. In this case, `components`\nwould be a list of two AR1 models. Note that each element of the `components` list should be an instance of one of basic model\nclass objects. To break the recursion, often the `components` attribute of a component is set to `None`, i.e.,\n`components[0].components = None`.\n\n1. `StateSpaceModel.__repr__()`\n\nThe double-under method `__repr__()` is overwritten to provide some unique identification info:\n\n```python\n>>> s1 = StateSpaceModel()\n>>> s1\nSsm(0)<f4c0>\n```\nwhere the number inside parenthesis indicates **the number of components** (the `ncomp` attribute) in the model, and the four-digits in `<>` are the last four digits of the memory address of the object instance.\n\n2. `StateSpaceModel.__str__()`\n\nThe double-under method `__str__()` is overwritten so `print()` returns useful info:\n```python\n>>> print(s1)\n<Ssm object at 0x102a8f4c0>\n nstate   = 0     ncomp    = 0\n nchannel = 0     ntime    = 0\n nmodel   = 1\n components = None\n F  .shape = None       Q  .shape = None\n mu0.shape = None       Q0 .shape = None\n G  .shape = None       R  .shape = None\n y  .shape = None       Fs = None\n```\n\n3. Model _stacking_ in `StateSpaceModel`\n\nIn many applications, there are several possible parameter values for a given state-space model structure. Instead of duplicating\nthe same values in multiple instances, somata uses _stacking_ to store multiple model values in the same object instance. Stackable\nmodel parameters are `F, Q, mu0, Q0, G, R`. For example:\n\n```python\n>>> s1 = StateSpaceModel(F=1, Q=2)\n>>> s2 = StateSpaceModel(F=2, Q=2)\n>>> print(s1)\n<Ssm object at 0x11fd7bfa0>\n nstate   = 1     ncomp    = 0\n nchannel = 0     ntime    = 0\n nmodel   = 1\n components = None\n F  .shape = (1, 1)     Q  .shape = (1, 1)\n mu0.shape = None       Q0 .shape = None\n G  .shape = None       R  .shape = None\n y  .shape = None       Fs = None\n\n>>> print(s2)\n<Ssm object at 0x102acc130>\n nstate   = 1     ncomp    = 0\n nchannel = 0     ntime    = 0\n nmodel   = 1\n components = None\n F  .shape = (1, 1)     Q  .shape = (1, 1)\n mu0.shape = None       Q0 .shape = None\n G  .shape = None       R  .shape = None\n y  .shape = None       Fs = None\n\n>>> s3 = s1+s2\n>>> print(s3)\n<Ssm object at 0x102acc280>\n nstate   = 1     ncomp    = 0\n nchannel = 0     ntime    = 0\n nmodel   = 2\n components = None\n F  .shape = (1, 1, 2)  Q  .shape = (1, 1)\n mu0.shape = None       Q0 .shape = None\n G  .shape = None       R  .shape = None\n y  .shape = None       Fs = None\n```\nInvoking the arithmetic operator `+` stacks the two instances `s1` and `s2` into a new instance, where the third dimension of the\n`F` attribute is now `2`, with the two values from `s1` and `s2`. The `nmodel` attribute is also updated to `2`.\n```python\n>>> s3.F\narray([[[1., 2.]]])\n```\nNotice how the third dimension of the `Q` attribute is still `None`. This is because the `+` operator has a built-in duplication check\nsuch that the identical model parameters will not be stacked. This behavior of `__add__` and `__radd__` generalizes to all model parameters, and it is convenient when bootstrapping or testing different parameter values during neural data analysis. Manual stacking of a particular\nmodel parameter is also possible with `.stack_attr()`.\n\n4. Model _expanding_ in `StateSpaceModel`\n\nSimilar to _stacking_, there is a related concept called _expanding_. Expanding a model is useful when we want to permutate multiple model\nparameters each with several possible values. For example:\n\n```python\n>>> s1 = StateSpaceModel(F=1, Q=3, R=5)\n>>> s2 = StateSpaceModel(F=2, Q=4, R=5)\n>>> print(s1+s2)\n<Ssm object at 0x1059626b0>\n nstate   = 1     ncomp    = 0\n nchannel = 1     ntime    = 0\n nmodel   = 2\n components = None\n F  .shape = (1, 1, 2)  Q  .shape = (1, 1, 2)\n mu0.shape = None       Q0 .shape = None\n G  .shape = None       R  .shape = (1, 1)\n y  .shape = None       Fs = None\n\n>>> s3 = s1*s2\n>>> print(s3)\n<Ssm object at 0x1059626b0>\n nstate   = 1     ncomp    = 0\n nchannel = 1     ntime    = 0\n nmodel   = 4\n components = None\n F  .shape = (1, 1, 4)  Q  .shape = (1, 1, 4)\n mu0.shape = None       Q0 .shape = None\n G  .shape = None       R  .shape = (1, 1)\n y  .shape = None       Fs = None\n\n>>> s3.F\narray([[[1., 1., 2., 2.]]])\n>>> s3.Q\narray([[[3., 4., 3., 4.]]])\n```\nMultiplying two `StateSpaceModel` instances with more than one differing model parameters results in expanding these parameters into all possible combinations while keeping other identical attributes intact.\n\n5. Arrays of `StateSpaceModel`\n\nBuilding on _stacking_ and _expanding_, we can easily form an array of `StateSpaceModel` instances using `.stack_to_array()`:\n\n```python\n>>> s_array = s3.stack_to_array()\n>>> s_array\narray([Ssm(0)<4460>, Ssm(0)<4430>, Ssm(0)<4520>, Ssm(0)<4580>],\n      dtype=object)\n```\n\nNote that a `StateSpaceModel` array is duck-typing with a Python `list`, which means one can also form a valid array with `[s1, s2]`.\n\n6. `StateSpaceModel.__len__()`\n\nInvoking `len()` returns the number of stacked models:\n\n```python\n>>> len(s2)\n1\n>>> len(s3)\n4\n```\n\n7. `StateSpaceModel.append()`\n\nAnother useful class method on `StateSpaceModel` is `.append()`. As one would expect, appending a model to another results in\ncombining them in block-diagonal form in the state equation. Compatibility checks happen in the background to make sure no conflict\nexists on the respective observation equations and observed data, if any.\n\n```python\n>>> s1 = StateSpaceModel(F=1, Q=3, R=5)\n>>> s2 = StateSpaceModel(F=2, Q=4, R=5)\n>>> s1.append(s2)\n>>> print(s1)\n<Ssm object at 0x1057cb4c0>\n nstate   = 2     ncomp    = 0\n nchannel = 1     ntime    = 0\n nmodel   = 1\n components = None\n F  .shape = (2, 2)     Q  .shape = (2, 2)\n mu0.shape = None       Q0 .shape = None\n G  .shape = None       R  .shape = (1, 1)\n y  .shape = None       Fs = None\n\n>>> s1.F\narray([[1., 0.],\n       [0., 2.]])\n>>> s1.Q\narray([[3., 0.],\n       [0., 4.]])\n```\n\nNotice that the `nstate` attribute is now updated to `2`, which is different from the `+` operator that updates the `nmodel` attribute to `2`.\n\n8. Inference and learning with `StateSpaceModel`\n\nTwo different implementations of Kalman filtering and fixed-interval smoothing are callable class methods:\n\n```python\n.kalman_filt_smooth(y=None, R_weights=None, return_dict=False, EM=False, skip_interp=True, seterr=None)\n\n.dejong_filt_smooth(y=None, R_weights=None, return_dict=False, EM=False, skip_interp=True, seterr=None)\n```\n\nWith an array of `StateSpaceModel`, one can easily run Kalman filtering and smoothing on all array elements with multithreading using the **static** method `.par_kalman()`:\n\n```python\n.par_kalman(ssm_array, y=None, method='kalman', R_weights=None, skip_interp=True, return_dict=False)\n```\n\nM-step updates are organized using `m_estimate()` that will recurse into each element of the `components` list and use\nthe appropriate m-step update methods associated with different types of state-space models.\n\n**Below we explain three kinds of basic state-space models currently supported in somata.**\n\n---\n### _class_ OscillatorModel(StateSpaceModel)\n```python\nsomata.OscillatorModel(a=None, freq=None, w=None, sigma2=None, add_dc=False,\n                       components='Osc', F=None, Q=None, mu0=None, Q0=None, G=None, R=None, y=None, Fs=None)\n```\n`OscillatorModel` is a child class of `StateSpaceModel`, which means it inherits all the class methods explained above. It has a particular form of the state-space model:\n\n$$\n\\begin{bmatrix}x_{t, 1}\\newline x_{t, 2}\\end{bmatrix} = \\mathbf{F}\\begin{bmatrix}x_{t-1, 1}\\newline x_{t-1, 2}\\end{bmatrix} + \\mathbf{\\eta}_t, \\mathbf{\\eta}_t \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{Q})\n$$\n\n$$\n\\mathbf{y}_ {t} = \\mathbf{G}\\begin{bmatrix}x_{t, 1}\\newline x_{t, 2}\\end{bmatrix} + \\mathbf{\\epsilon}_t, \\mathbf{\\epsilon}_t \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{R})\n$$\n\n$$\n\\begin{bmatrix}x_{0, 1}\\newline x_{0, 2}\\end{bmatrix} \\sim \\mathcal{N}(\\mathbf{\\mu}_0, \\mathbf{Q}_0)\n$$\n\n$$\n\\mathbf{F} = a\\begin{bmatrix}\\cos\\omega & -\\sin\\omega\\newline \\sin\\omega & \\cos\\omega\\end{bmatrix}, \\mathbf{Q} = \\begin{bmatrix}\\sigma^2 & 0\\newline 0 & \\sigma^2\\end{bmatrix}, \\mathbf{G} = \\begin{bmatrix}1 & 0 \\end{bmatrix}\n$$\n\nTo create a simple oscillator model with rotation frequency $15$ Hz (under $100$ Hz sampling frequency) and damping factor $0.9$:\n\n```python\n>>> o1 = OscillatorModel(a=0.9, freq=15, Fs=100)\n>>> o1\nOsc(1)<81f0>\n>>> print(o1)\n<Osc object at 0x1058081f0>\n nstate   = 2     ncomp    = 1\n nchannel = 0     ntime    = 0\n nmodel   = 1\n components = [Osc(0)<4b50>]\n F  .shape = (2, 2)     Q  .shape = (2, 2)\n mu0.shape = (2, 1)     Q0 .shape = (2, 2)\n G  .shape = (1, 2)     R  .shape = None\n y  .shape = None       Fs = 100.0 Hz\n damping a = [0.9]\n freq Hz   = [15.]\n sigma2    = [3.]\n obs noise R = None\n dc index  = None\n```\n\nNotice the `components` attribute auto-populates with a spaceholder `OscillatorModel` instance, which is different from the `o1` instance\nas can be recognized by different memory addresses. State noise variance $\\sigma^2$ defaults to $3$ when not specified and can be changed\nwith the `sigma2` argument to the constructor method.\n\n### _class_ AutoRegModel(StateSpaceModel)\n```python\nsomata.AutoRegModel(coeff=None, sigma2=None,\n                    components='Arn', F=None, Q=None, mu0=None, Q0=None, G=None, R=None, y=None, Fs=None)\n```\n`AutoRegModel` is a child class of `StateSpaceModel`, which means it inherits all the class methods explained above. It has a particular form of the state-space model. For example, an auto-regressive model of order 3 can be expressed as:\n\n$$\n\\begin{bmatrix}x_{t}\\newline x_{t-1}\\newline x_{t-2}\\end{bmatrix} = \\mathbf{F}\\begin{bmatrix}x_{t-1}\\newline x_{t-2}\\newline x_{t-3}\\end{bmatrix} + \\mathbf{\\eta}_t, \\mathbf{\\eta}_t \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{Q})\n$$\n\n$$\n\\mathbf{y}_ {t} = \\mathbf{G}\\begin{bmatrix}x_{t}\\newline x_{t-1}\\newline x_{t-2}\\end{bmatrix} + \\mathbf{\\epsilon}_t, \\mathbf{\\epsilon}_t \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{R})\n$$\n\n$$\n\\begin{bmatrix}x_{0}\\newline x_{-1}\\newline x_{-2}\\end{bmatrix} \\sim \\mathcal{N}(\\mathbf{\\mu}_0, \\mathbf{Q}_0)\n$$\n\n$$\n\\mathbf{F} = \\begin{bmatrix} a_1 & a_2 & a_3 \\newline 1 & 0 & 0 \\newline 0 & 1 & 0 \\end{bmatrix}, \\mathbf{Q} = \\begin{bmatrix}\\sigma^2 & 0 & 0\\newline 0 & 0 & 0\\newline 0 & 0 & 0\\end{bmatrix}, \\mathbf{G} = \\begin{bmatrix}1 & 0 & 0\\end{bmatrix}\n$$\n\nTo create an AR3 model with parameters $a_1=0.5, a_2=0.3, a_3=0.1$ and $\\sigma^2=1$:\n\n```python\n>>> a1 = AutoRegModel(coeff=[0.5,0.3,0.1], sigma2=1)\n>>> a1\nArn=3<24d0>\n>>> print(a1)\n<Arn object at 0x1035524d0>\n nstate   = 3     ncomp    = 1\n nchannel = 0     ntime    = 0\n nmodel   = 1\n components = [Arn=3<2680>]\n F  .shape = (3, 3)     Q  .shape = (3, 3)\n mu0.shape = (3, 1)     Q0 .shape = (3, 3)\n G  .shape = (1, 3)     R  .shape = None\n y  .shape = None       Fs = None\n AR order  = [3]\n AR coeff  = ([0.5 0.3 0.1])\n sigma2    = [1.]\n```\n\nNote that `__repr__()` is slightly different for `AutoRegModel`, since the key information is not how many components but rather the AR order. We display the order of the auto-regressive model with an `=` sign as shown above instead of showing the number of components in\n`()` as for `OscillatorModel` and `StateSpaceModel`.\n\n### _class_ GeneralSSModel(StateSpaceModel)\n```python\nsomata.GeneralSSModel(components='Gen', F=None, Q=None, mu0=None, Q0=None, G=None, R=None, y=None, Fs=None)\n```\n`GeneralSSModel` is a child class of `StateSpaceModel`, which means it inherits all the class methods explained above. The same general Gaussian linear dynamic system as before is followed:\n\n$$\n\\mathbf{x}_ t = \\mathbf{F}\\mathbf{x}_{t-1} + \\boldsymbol{\\eta}_t, \\boldsymbol{\\eta}_t \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{Q})\n$$\n\n$$\n\\mathbf{y}_ {t} = \\mathbf{G}\\mathbf{x}_{t} + \\boldsymbol{\\epsilon}_t, \\boldsymbol{\\epsilon}_t \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{R})\n$$\n\n$$\n\\mathbf{x}_0 \\sim \\mathcal{N}(\\mathbf{\\mu}_0, \\mathbf{Q}_0)\n$$\n\n`GeneralSSModel` is added to somata so that one can perform the most general Gaussian updates for a state-space model without special structures as specified in `OscillatorModel` and `AutoRegModel`. In other words, with non-sparse structures in the model parameters\n`F, Q, Q0, G, R`. To create a simple general state-space model:\n\n```python\n>>> g1 = GeneralSSModel(F=[[1,2],[3,4]])\n>>> g1\nGen(1)<2440>\n>>> print(g1)\n<Gen object at 0x103552440>\n nstate   = 2     ncomp    = 1\n nchannel = 0     ntime    = 0\n nmodel   = 1\n components = [Gen(0)<2710>]\n F  .shape = (2, 2)     Q  .shape = None\n mu0.shape = None       Q0 .shape = None\n G  .shape = None       R  .shape = None\n y  .shape = None       Fs = None\n```\n\n### For more in-depth working examples with the basic models in somata\nLook at the demo script [basic_models_demo_01102022.py](examples/basic_models_demo_01102022.py) and execute the code line by line to get familiar with class objects and methods of somata basic models.\n\n---\n\n## Advanced neural oscillator methods\n1. [Oscillator Model Learning](#osc)\n2. [Iterative Oscillator Algorithm](#ioa)\n\n---\n1. ### Oscillator Model Learning <a name=\"osc\"></a> [<img src=\"https://img.shields.io/badge/Status-Functional-success.svg?logo=Python\">](#osc)\n---\n2. ### Iterative Oscillator Algorithm <a name=\"ioa\"></a> [<img src=\"https://img.shields.io/badge/Status-Functional-success.svg?logo=Python\">](#ioa)\n\n**N.B.:** We recommend downsampling to 120 Hz or less, depending on the oscillations present in your data. Highly oversampled data will make it more difficult to identify oscillatory components, increase the computational time, and could also introduce high frequency noise.\n\nOne major goal of this method was to produce an algorithm that required minimal user intervention, if any. We recommend starting with the algorithm as is, but in the case of poor fitting, we suggest the following alterations:\n1. If the pole initialized from the one-step prediction is between two oscillations, causing poor fitting of this oscillation as it attempts to explain multiple oscillations, we recommend increasing the order of the AR model used to approximate the OSPE. Increase in increments of two, which will allow additional pairs of complex poles.\n\n2. Conversely to point 1, if the order of the AR model is too high then multiple pairs of roots will be attributed to the same oscillation, diluting the strength needed for each of them and possibly leading to none of them being selected as the strongest root in the iterative process to initialize the next oscillation, even though together they describe the strongest oscillation. This can be identified using the innovations plot with all of the AR roots plotted. In this case we recommend decreasing the AR order in increments of 2, to decrease the number of pairs of complex poles.\n\n3. If the initialization of the additional oscillations describes a single oscillation well, but the fitting of this oscillation attempts to explain multiple oscillations and causes poor fitting, we recommend increasing the concentration hyperparameter in the Von Mises prior. This will increase the weight on the initial frequency and stop the oscillation from shifting to explain other oscillations.\n\n4. If the model does not choose the correct number of oscillations, we recommend looking at all fitted models and selecting the best fitting model based on other selection criteria or using your best judgement. You can also choose a subset of well-fitted oscillations and run the kalman filter to estimate oscillations using those fitted parameters.\n\n5. Note that this algorithm assumes a stationary signal, and therefore stationary parameters. Although the Kalman filtering allows some flexibility in this requirement, enabling the model to work on some time-varying signal, the success of the method depends on the strength and duration of the signal components. The weaker and more brief the time-varying component is, the more poorly the model will capture it, if it does at all. We recommend decreasing the length of your window until you have a more stationary signal.\n\nThis algorithm is designed to fit well automatically in most situations, but there will still be some data sets where it does not fit well without intervention.\n\nWhen using this module, please cite the following [paper](https://www.biorxiv.org/content/10.1101/2022.10.30.514422.abstract):\n\nBeck, A. M., He, M., Gutierrez, R. G., & Purdon, P. L. (2022). An iterative search algorithm to identify oscillatory dynamics in neurophysiological time series. bioRxiv.\n\n---\n\n## Authors\nMingjian He, Proloy Das, Amanda Beck, Patrick Purdon\n\n## Citation\nUse different citation styles at: https://doi.org/10.5281/zenodo.7242130\n\n## License\nSOMATA is licensed under the [BSD 3-Clause Clear license](https://spdx.org/licenses/BSD-3-Clause-Clear.html). \\\nCopyright © 2022. All rights reserved.\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/mh105/somata",
    "keywords": "state-space oscillator time-series",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "somata",
    "package_url": "https://pypi.org/project/somata/",
    "platform": null,
    "project_url": "https://pypi.org/project/somata/",
    "project_urls": {
      "Homepage": "https://github.com/mh105/somata"
    },
    "release_url": "https://pypi.org/project/somata/0.2.1/",
    "requires_dist": [
      "joblib",
      "kneed",
      "librosa",
      "matplotlib",
      "numpy (>=1.22)",
      "scipy",
      "tqdm",
      "spectrum",
      "codetiming",
      "sorcery (>=0.2.2)"
    ],
    "requires_python": ">=3.8",
    "summary": "State-space Oscillator Modeling And Time-series Analysis",
    "version": "0.2.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 15847323,
  "releases": {
    "0.2.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4b3319a3bc525173af46c19ca89b41a3a1c262cba5ff97c2f70a86e9554b9021",
          "md5": "41fb7ceb2f34514740c17a6cd0436088",
          "sha256": "efa05d1c73aad945c46ae9763deb0e330ef481900a35759ef59a314405a32d52"
        },
        "downloads": -1,
        "filename": "somata-0.2.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "41fb7ceb2f34514740c17a6cd0436088",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 60556,
        "upload_time": "2022-11-22T00:21:41",
        "upload_time_iso_8601": "2022-11-22T00:21:41.358811Z",
        "url": "https://files.pythonhosted.org/packages/4b/33/19a3bc525173af46c19ca89b41a3a1c262cba5ff97c2f70a86e9554b9021/somata-0.2.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "68332dafbe54cc9e40ef913938a2a4e35755082b402e8f619cded101412ed612",
          "md5": "93b97633696aac5a75b8f109bcce2a54",
          "sha256": "8397422df84a66ea1c3add4ceb493ff1bc6d3edc8c63e81100e8fcf5affc369f"
        },
        "downloads": -1,
        "filename": "somata-0.2.1.tar.gz",
        "has_sig": false,
        "md5_digest": "93b97633696aac5a75b8f109bcce2a54",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 60765,
        "upload_time": "2022-11-22T00:21:43",
        "upload_time_iso_8601": "2022-11-22T00:21:43.419619Z",
        "url": "https://files.pythonhosted.org/packages/68/33/2dafbe54cc9e40ef913938a2a4e35755082b402e8f619cded101412ed612/somata-0.2.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "4b3319a3bc525173af46c19ca89b41a3a1c262cba5ff97c2f70a86e9554b9021",
        "md5": "41fb7ceb2f34514740c17a6cd0436088",
        "sha256": "efa05d1c73aad945c46ae9763deb0e330ef481900a35759ef59a314405a32d52"
      },
      "downloads": -1,
      "filename": "somata-0.2.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "41fb7ceb2f34514740c17a6cd0436088",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.8",
      "size": 60556,
      "upload_time": "2022-11-22T00:21:41",
      "upload_time_iso_8601": "2022-11-22T00:21:41.358811Z",
      "url": "https://files.pythonhosted.org/packages/4b/33/19a3bc525173af46c19ca89b41a3a1c262cba5ff97c2f70a86e9554b9021/somata-0.2.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "68332dafbe54cc9e40ef913938a2a4e35755082b402e8f619cded101412ed612",
        "md5": "93b97633696aac5a75b8f109bcce2a54",
        "sha256": "8397422df84a66ea1c3add4ceb493ff1bc6d3edc8c63e81100e8fcf5affc369f"
      },
      "downloads": -1,
      "filename": "somata-0.2.1.tar.gz",
      "has_sig": false,
      "md5_digest": "93b97633696aac5a75b8f109bcce2a54",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.8",
      "size": 60765,
      "upload_time": "2022-11-22T00:21:43",
      "upload_time_iso_8601": "2022-11-22T00:21:43.419619Z",
      "url": "https://files.pythonhosted.org/packages/68/33/2dafbe54cc9e40ef913938a2a4e35755082b402e8f619cded101412ed612/somata-0.2.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}