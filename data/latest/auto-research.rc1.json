{
  "info": {
    "author": "Sidharth Pal",
    "author_email": "sidharth.pal1992@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Environment :: Console",
      "Environment :: GPU",
      "Environment :: GPU :: NVIDIA CUDA",
      "Environment :: Other Environment",
      "Intended Audience :: Developers",
      "Intended Audience :: Education",
      "Intended Audience :: Other Audience",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: GNU General Public License (GPL)",
      "License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)",
      "License :: OSI Approved :: GNU Lesser General Public License v3 or later (LGPLv3+)",
      "License :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)",
      "Natural Language :: English",
      "Operating System :: MacOS :: MacOS X",
      "Operating System :: POSIX :: Linux",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3 :: Only",
      "Programming Language :: Python :: 3.6",
      "Topic :: Education",
      "Topic :: Education :: Computer Aided Instruction (CAI)",
      "Topic :: Scientific/Engineering",
      "Topic :: Scientific/Engineering :: Artificial Intelligence",
      "Topic :: Scientific/Engineering :: Information Analysis",
      "Topic :: Scientific/Engineering :: Medical Science Apps.",
      "Topic :: Scientific/Engineering :: Physics"
    ],
    "description": "# Auto-Research\n##### A no-code utility to generate a detailed well-cited survey with topic clustered sections (draft paper format) and other interesting artifacts from a single research query.\n\nRequires:\n - python 3.7 or above\n - poppler-utils\n - list of requirements in requirements.txt\n - 8GB disk space \n - 13GB CUDA(GPU) memory - for a survey of 100 searched papers(max_search) and 25 selected papers(num_papers)\n\n\n#### Steps to run (pip coming soon):\n```\napt install -y poppler-utils libpoppler-cpp-dev\ngit clone https://github.com/sidphbot/Auto-Research.git\n\ncd Auto-Research/\npip install -r requirements.txt\npython Surveyor.py [options] <your_research_query>\n```\n\n#### Artifacts generated (zipped):\n- Detailed survey draft paper as txt file\n- A curated list of top 25+ papers as pdfs and txts\n- Images extracted from above papers as jpegs, bmps etc\n- Heading/Section wise highlights extracted from above papers as a re-usable pure python joblib dump\n- Tables extracted from papers(optional)\n- Corpus of metadata highlights/text of top 100 papers as a re-usable pure python joblib dump\n\n## Example run #1 - python utility\n\n```\npython src/Surveyor.py 'multi-task representation learning'\n```\n\n## Example run #2 - python class\n\n```\nfrom Surveyor import Surveyor\nmysurveyor = Surveyor()\nmysurveyor.survey('quantum entanglement')\n```\n\n## Access/Modify defaults:\n\n- inside code \n```\nfrom Surveyor import DEFAULTS\nfrom pprint import pprint\n\npprint(DEFAULTS)\n```\nor,\n\n- Modify static config file - `defaults.py`\n\nor,\n\n- At runtime (utility)\n\n```\npython src/Surveyor.py --help\n```\n```\nusage: Surveyor.py [-h] [--max_search max_metadata_papers]\n                   [--num_papers max_num_papers] [--pdf_dir pdf_dir]\n                   [--txt_dir txt_dir] [--img_dir img_dir] [--tab_dir tab_dir]\n                   [--dump_dir dump_dir] [--models_dir save_models_dir]\n                   [--title_model_name title_model_name]\n                   [--ex_summ_model_name extractive_summ_model_name]\n                   [--ledmodel_name ledmodel_name]\n                   [--embedder_name sentence_embedder_name]\n                   [--nlp_name spacy_model_name]\n                   [--similarity_nlp_name similarity_nlp_name]\n                   [--kw_model_name kw_model_name]\n                   [--refresh_models refresh_models] [--high_gpu high_gpu]\n                   query_string\n\nGenerate a survey just from a query !!\n\npositional arguments:\n  query_string          your research query/keywords\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --max_search max_metadata_papers\n                        maximium number of papers to gaze at - defaults to 100\n  --num_papers max_num_papers\n                        maximium number of papers to download and analyse -\n                        defaults to 25\n  --pdf_dir pdf_dir     pdf paper storage directory - defaults to\n                        arxiv_data/tarpdfs/\n  --txt_dir txt_dir     text-converted paper storage directory - defaults to\n                        arxiv_data/fulltext/\n  --img_dir img_dir     image storage directory - defaults to\n                        arxiv_data/images/\n  --tab_dir tab_dir     tables storage directory - defaults to\n                        arxiv_data/tables/\n  --dump_dir dump_dir   all_output_dir - defaults to arxiv_dumps/\n  --models_dir save_models_dir\n                        directory to save models (> 5GB) - defaults to\n                        saved_models/\n  --title_model_name title_model_name\n                        title model name/tag in hugging-face, defaults to\n                        'Callidior/bert2bert-base-arxiv-titlegen'\n  --ex_summ_model_name extractive_summ_model_name\n                        extractive summary model name/tag in hugging-face,\n                        defaults to 'allenai/scibert_scivocab_uncased'\n  --ledmodel_name ledmodel_name\n                        led model(for abstractive summary) name/tag in\n                        hugging-face, defaults to 'allenai/led-\n                        large-16384-arxiv'\n  --embedder_name sentence_embedder_name\n                        sentence embedder name/tag in hugging-face, defaults\n                        to 'paraphrase-MiniLM-L6-v2'\n  --nlp_name spacy_model_name\n                        spacy model name/tag in hugging-face (if changed -\n                        needs to be spacy-installed prior), defaults to\n                        'en_core_sci_scibert'\n  --similarity_nlp_name similarity_nlp_name\n                        spacy downstream model(for similarity) name/tag in\n                        hugging-face (if changed - needs to be spacy-installed\n                        prior), defaults to 'en_core_sci_lg'\n  --kw_model_name kw_model_name\n                        keyword extraction model name/tag in hugging-face,\n                        defaults to 'distilbert-base-nli-mean-tokens'\n  --refresh_models refresh_models\n                        Refresh model downloads with given names (needs\n                        atleast one model name param above), defaults to False\n  --high_gpu high_gpu   High GPU usage permitted, defaults to False\n\n```\n\n- At runtime (code)\n\n    > during surveyor object initialization with `surveyor_obj = Surveyor()`\n    - `pdf_dir`: String, pdf paper storage directory - defaults to `arxiv_data/tarpdfs/`\n    - `txt_dir`: String, text-converted paper storage directory - defaults to `arxiv_data/fulltext/`\n    - `img_dir`: String, image image storage directory - defaults to `arxiv_data/images/`\n    - `tab_dir`: String, tables storage directory - defaults to `arxiv_data/tables/`\n    - `dump_dir`: String, all_output_dir - defaults to `arxiv_dumps/`\n    - `models_dir`: String, directory to save to huge models, defaults to `saved_models/`\n    - `title_model_name`: String, title model name/tag in hugging-face, defaults to `Callidior/bert2bert-base-arxiv-titlegen`\n    - `ex_summ_model_name`: String, extractive summary model name/tag in hugging-face, defaults to `allenai/scibert_scivocab_uncased`\n    - `ledmodel_name`: String, led model(for abstractive summary) name/tag in hugging-face, defaults to `allenai/led-large-16384-arxiv`\n    - `embedder_name`: String, sentence embedder name/tag in hugging-face, defaults to `paraphrase-MiniLM-L6-v2`\n    - `nlp_name`: String, spacy model name/tag in hugging-face (if changed - needs to be spacy-installed prior), defaults to `en_core_sci_scibert`\n    - `similarity_nlp_name`: String, spacy downstream trained model(for similarity) name/tag in hugging-face (if changed - needs to be spacy-installed prior), defaults to `en_core_sci_lg`\n    - `kw_model_name`: String, keyword extraction model name/tag in hugging-face, defaults to `distilbert-base-nli-mean-tokens`\n    - `high_gpu`: Bool, High GPU usage permitted, defaults to `False`\n    - `refresh_models`: Bool, Refresh model downloads with given names (needs atleast one model name param above), defaults to False\n    \n    > during survey generation with `surveyor_obj.survey(query=\"my_research_query\")`\n    - `max_search`: int maximium number of papers to gaze at - defaults to `100`\n    - `num_papers`: int maximium number of papers to download and analyse - defaults to `25`\n    \n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/sidphbot/Auto-Research",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "Auto-Research",
    "package_url": "https://pypi.org/project/Auto-Research/",
    "platform": "",
    "project_url": "https://pypi.org/project/Auto-Research/",
    "project_urls": {
      "Bug Tracker": "https://github.com/sidphbot/Auto-Research/issues",
      "Demo": "https://www.kaggle.com/sidharthpal/auto-research-generate-survey-from-query",
      "Docs": "https://github.com/example/example/README.md",
      "Homepage": "https://github.com/sidphbot/Auto-Research"
    },
    "release_url": "https://pypi.org/project/Auto-Research/1.0/",
    "requires_dist": [
      "pip",
      "boto3 (==1.9.118)",
      "requests (==2.20.0)",
      "unicodedata2 (==11.0.0)",
      "pdfminer",
      "sentence-transformers",
      "pdftotext",
      "arxiv",
      "arxiv2bib",
      "scholarly",
      "PyMuPDF (==1.18.14)",
      "Pillow",
      "tabula-py",
      "sentencepiece",
      "keybert",
      "spacy[all]",
      "scispacy",
      "amrlib",
      "transformers",
      "neuralcoref",
      "en-core-sci-scibert",
      "en-core-sci-lg",
      "bert-extractive-summarizer"
    ],
    "requires_python": ">=3.7",
    "summary": "Geberate scientific survey with just a query",
    "version": "1.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 10878535,
  "releases": {
    "1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b90c9e0832051981e0735d84874bc0cfd7f7df9ae75cf45a41b9a70418d5b4e2",
          "md5": "fd13c276d9a7f8dd11de048e471f8d65",
          "sha256": "f52ffe851cfbd5e37fc58d57457064786853868600ff32128462f98e5ca7927e"
        },
        "downloads": -1,
        "filename": "Auto_Research-1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "fd13c276d9a7f8dd11de048e471f8d65",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 50716,
        "upload_time": "2021-07-11T13:26:45",
        "upload_time_iso_8601": "2021-07-11T13:26:45.741634Z",
        "url": "https://files.pythonhosted.org/packages/b9/0c/9e0832051981e0735d84874bc0cfd7f7df9ae75cf45a41b9a70418d5b4e2/Auto_Research-1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d318f8af98eca66236b03896c4cb55ca8a2eebb4bc81cc26c024ef4f0188b4a2",
          "md5": "4370e9e71bad2d11e79817dd617a707f",
          "sha256": "e72ac3167a8b1c38bad7b3389204da396efb13ee7ed15927aef0941fddfbd72d"
        },
        "downloads": -1,
        "filename": "Auto-Research-1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "4370e9e71bad2d11e79817dd617a707f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 45983,
        "upload_time": "2021-07-11T13:26:47",
        "upload_time_iso_8601": "2021-07-11T13:26:47.277171Z",
        "url": "https://files.pythonhosted.org/packages/d3/18/f8af98eca66236b03896c4cb55ca8a2eebb4bc81cc26c024ef4f0188b4a2/Auto-Research-1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "b90c9e0832051981e0735d84874bc0cfd7f7df9ae75cf45a41b9a70418d5b4e2",
        "md5": "fd13c276d9a7f8dd11de048e471f8d65",
        "sha256": "f52ffe851cfbd5e37fc58d57457064786853868600ff32128462f98e5ca7927e"
      },
      "downloads": -1,
      "filename": "Auto_Research-1.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "fd13c276d9a7f8dd11de048e471f8d65",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 50716,
      "upload_time": "2021-07-11T13:26:45",
      "upload_time_iso_8601": "2021-07-11T13:26:45.741634Z",
      "url": "https://files.pythonhosted.org/packages/b9/0c/9e0832051981e0735d84874bc0cfd7f7df9ae75cf45a41b9a70418d5b4e2/Auto_Research-1.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "d318f8af98eca66236b03896c4cb55ca8a2eebb4bc81cc26c024ef4f0188b4a2",
        "md5": "4370e9e71bad2d11e79817dd617a707f",
        "sha256": "e72ac3167a8b1c38bad7b3389204da396efb13ee7ed15927aef0941fddfbd72d"
      },
      "downloads": -1,
      "filename": "Auto-Research-1.0.tar.gz",
      "has_sig": false,
      "md5_digest": "4370e9e71bad2d11e79817dd617a707f",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 45983,
      "upload_time": "2021-07-11T13:26:47",
      "upload_time_iso_8601": "2021-07-11T13:26:47.277171Z",
      "url": "https://files.pythonhosted.org/packages/d3/18/f8af98eca66236b03896c4cb55ca8a2eebb4bc81cc26c024ef4f0188b4a2/Auto-Research-1.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}