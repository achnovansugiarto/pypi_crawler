{
  "info": {
    "author": "Livia Rodrigues",
    "author_email": "l180545@dac.unicamp.br",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# HypAST - Hypothalamus Automatic Segmentation Tool\n\nOn this package you will find a trained model for hypothalamus segmentation on T1 MRI images and a trainable class, in case you wish to use your own data.\n\nThis tool is not suitable for clinical purposes.\n\n**HypAST** requires **Python 3.7** and **PyTorch 1.9** \n\nTo install PyTorch:\n\n        # CUDA 10.2\n        conda install pytorch==1.9.0 torchvision==0.10.0 torchaudio==0.9.0 cudatoolkit=10.2 -c pytorch\n        # CUDA 11.3\n        install pytorch==1.9.0 torchvision==0.10.0 torchaudio==0.9.0 cudatoolkit=11.3 -c pytorch -c conda-forge\n        # CPU Only\n        conda install pytorch==1.9.0 torchvision==0.10.0 torchaudio==0.9.0 cpuonly -c pytorch\n\n## GETTING STARTED\n\n**HypAST** works on .nii or .nii.gz input files for images and .nii, .nii.gz or .npy for annotations. \nUsing **HypAST** you will be able to predict hypothalamus segmentation using our model or to train with your own data.\n\nSee more bellow:\n\n#### Trainer\n\nWith **Trainer** you can train the model using your own data. \n\nExample:\n\n        import hypast as hyp\n        train = hyp.Trainer(train_path, chkp_path, val_path, maxep=200, accum=16, weight=[1,4], lr=5e-3, bs=8)\n        train.trainer()\n\n- Input:\n\n    - train_path: path to h5py train set\n    - chkp_path: checkpoint path\n    - val_path: path to h5py val set\n    - maxep: Maximum # of epochs in training (defaul = 200)\n    - accum: Batch accumulation (defaul = 16)\n    - weight: Cross Entropy Weight (defaul = [1,4])\n    - lr: Learning Rate (defaul = 5e-3)\n    - bs: Batch Size (defaul = 8)\n\n- Output:\n    - Checkpoint file on defined path\n\n\n#### CreateHDF5\n\n\nTo facilitate training using **HypAST**, CreateHDF5 will adjust your data for you.\n\nExample:\n\n        import hypast as hyp\n        hyp.CreateHDF5(list_data, list_labels, out_path)\n        create.create_links() \n\n- Input:\n\n    - list_data: List containing paths of .nii or .nii.gz images\n    - list_labels: List containing paths of labels (.nii, .nii.gz or .npy)\n    - out_path: Path were .hdf5 files will be saved\n\n- Output:\n\n    - Return train.hdf5 and val.hdf5 on defined path \n\n#### Predictor\n\nWith **HypAST** you can also generate hypothalamus segmentation using our trained model.\n\nExample:\n\n        import hypast as hyp\n        pred = hyp.Predictor(list_data, out)\n        pred.predictor()\n\n- Input:\n\n    - list_data: List containing paths of .nii or .nii.gz files to be segmented\n    - out: Path were segmentation will be saved\n\n- Output:\n\n    - Segmentation files on defined path\n\n## CONTACT\n\nFor more information or suggestions, please contact liviamarodrigues@gmail.com\n\nSee more on https://github.com/MICLab-Unicamp/HypAST\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/MICLab-Unicamp/HypAST",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "hypast",
    "package_url": "https://pypi.org/project/hypast/",
    "platform": "",
    "project_url": "https://pypi.org/project/hypast/",
    "project_urls": {
      "Homepage": "https://github.com/MICLab-Unicamp/HypAST"
    },
    "release_url": "https://pypi.org/project/hypast/0.0.7/",
    "requires_dist": [
      "numpy (==1.18.1)",
      "pytorch-lightning (==1.4.7)",
      "h5py (==2.10.0)",
      "scikit-image (==0.17.2)",
      "nibabel (==3.1.1)",
      "connected-components-3d",
      "albumentations (==0.4.6)",
      "scikit-learn (==0.22.2.post1)",
      "efficientnet-pytorch"
    ],
    "requires_python": ">3.7",
    "summary": "Hypothalamus Automatic Segmentation Tool",
    "version": "0.0.7",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12319212,
  "releases": {
    "0.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "957e2f9bc89e2b71650ad7097190b21af61b461478e79881b749b9173be2ca9b",
          "md5": "0fd4a9e8e20bc0ea361d74d0f978b9b3",
          "sha256": "1f3d32fcb99778ce1924c7b52f4d06e7bb7c3b3632a441f7b1a7ff2c6922b4c4"
        },
        "downloads": -1,
        "filename": "hypast-0.0.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0fd4a9e8e20bc0ea361d74d0f978b9b3",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">3.7",
        "size": 12694,
        "upload_time": "2021-12-16T02:57:27",
        "upload_time_iso_8601": "2021-12-16T02:57:27.023913Z",
        "url": "https://files.pythonhosted.org/packages/95/7e/2f9bc89e2b71650ad7097190b21af61b461478e79881b749b9173be2ca9b/hypast-0.0.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bf93e786e04ef7f5f7f30316874831050610b8708358fc5aee90b1fb12a4c68f",
          "md5": "3fbf7420aebe8896545854786aee4b67",
          "sha256": "0b692a92f87f9d0d00394f2e94c25e69c61a5d815a6cda47dcb396b34406e1f2"
        },
        "downloads": -1,
        "filename": "hypast-0.0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "3fbf7420aebe8896545854786aee4b67",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">3.7",
        "size": 8398,
        "upload_time": "2021-12-16T02:57:28",
        "upload_time_iso_8601": "2021-12-16T02:57:28.848097Z",
        "url": "https://files.pythonhosted.org/packages/bf/93/e786e04ef7f5f7f30316874831050610b8708358fc5aee90b1fb12a4c68f/hypast-0.0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "dd7ffd98e3ff1369c922c9922dc4aa2b4c3a847945f028a26b604e5f1478c335",
          "md5": "5722aff91198f5d2dad51e965fe67352",
          "sha256": "acd3664a3867cba976e3df69cbe8f5849dd38d7a9f747783aad9faac75ea7936"
        },
        "downloads": -1,
        "filename": "hypast-0.0.7-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "5722aff91198f5d2dad51e965fe67352",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">3.7",
        "size": 12669,
        "upload_time": "2021-12-16T03:03:26",
        "upload_time_iso_8601": "2021-12-16T03:03:26.768416Z",
        "url": "https://files.pythonhosted.org/packages/dd/7f/fd98e3ff1369c922c9922dc4aa2b4c3a847945f028a26b604e5f1478c335/hypast-0.0.7-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c5cd506f2078af8e59775878dab2f6b2df5365026a6e004d47f57d1ce30cb0ac",
          "md5": "530101420534a5221f1c9d0dbbc90a39",
          "sha256": "162ff19a2ac8f1cffb1b61c34090e83dca970494e9a6a04a7eb6e4700529fa25"
        },
        "downloads": -1,
        "filename": "hypast-0.0.7.tar.gz",
        "has_sig": false,
        "md5_digest": "530101420534a5221f1c9d0dbbc90a39",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">3.7",
        "size": 8362,
        "upload_time": "2021-12-16T03:03:28",
        "upload_time_iso_8601": "2021-12-16T03:03:28.475143Z",
        "url": "https://files.pythonhosted.org/packages/c5/cd/506f2078af8e59775878dab2f6b2df5365026a6e004d47f57d1ce30cb0ac/hypast-0.0.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "dd7ffd98e3ff1369c922c9922dc4aa2b4c3a847945f028a26b604e5f1478c335",
        "md5": "5722aff91198f5d2dad51e965fe67352",
        "sha256": "acd3664a3867cba976e3df69cbe8f5849dd38d7a9f747783aad9faac75ea7936"
      },
      "downloads": -1,
      "filename": "hypast-0.0.7-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "5722aff91198f5d2dad51e965fe67352",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">3.7",
      "size": 12669,
      "upload_time": "2021-12-16T03:03:26",
      "upload_time_iso_8601": "2021-12-16T03:03:26.768416Z",
      "url": "https://files.pythonhosted.org/packages/dd/7f/fd98e3ff1369c922c9922dc4aa2b4c3a847945f028a26b604e5f1478c335/hypast-0.0.7-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "c5cd506f2078af8e59775878dab2f6b2df5365026a6e004d47f57d1ce30cb0ac",
        "md5": "530101420534a5221f1c9d0dbbc90a39",
        "sha256": "162ff19a2ac8f1cffb1b61c34090e83dca970494e9a6a04a7eb6e4700529fa25"
      },
      "downloads": -1,
      "filename": "hypast-0.0.7.tar.gz",
      "has_sig": false,
      "md5_digest": "530101420534a5221f1c9d0dbbc90a39",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">3.7",
      "size": 8362,
      "upload_time": "2021-12-16T03:03:28",
      "upload_time_iso_8601": "2021-12-16T03:03:28.475143Z",
      "url": "https://files.pythonhosted.org/packages/c5/cd/506f2078af8e59775878dab2f6b2df5365026a6e004d47f57d1ce30cb0ac/hypast-0.0.7.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}