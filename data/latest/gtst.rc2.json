{
  "info": {
    "author": "Gareth W. Peters",
    "author_email": "\"Ragnar L. Gudmundarson\" <ragnarlevigud@gmail.com>",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# MMDGraph\n\n## What is this package for?\n\nThis package contains code to perform kernel two-sample hypothesis testing on samples of graphs. The code additionally allows for estimation of graphs from a real data matrix.\n\n\n## How to install\n\n<code> pip install MMDGraph </code>\n\n## Usage\n\nWe will go thorugh multiple scenariros: The case when the user has it own networkx graphs, when they are estimated from data matricies, using different kernels and using different MMD estimators.\n\n\n```python\nimport numpy as np\nimport networkx as nx\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport MMDGraph as mg\n```\n\n### Fit when H1 true, different edge probability\n\nIn this example, we simulate binomial graphs assuming that samples two have different edge probabilties. There will be 50 graphs in each sample and the number of nodes is 30 for all graphs. Sample 1 has edge probabilty 0.3 and sample 2 has edge probability 0.4. We will label each node with its corresponding degree so that graph kernels that assume labels can be used.\n\nStart by creating sample graphs\n\n\n```python\n\nn1 = n2 = 50  # sample sizes\n# generate two samples\ng1 = [nx.fast_gnp_random_graph(30,0.3) for _ in range(n1)]\ng2 = [nx.fast_gnp_random_graph(30,0.4) for _ in range(n2)]\n\n# Set node labels as the degree\nfor j in range(len(g1)):\n    nx.set_node_attributes(g1[j],  {key: str(value) for key, value in dict(g1[j].degree).items()} , 'label')\nfor j in range(len(g2)):\n    nx.set_node_attributes(g2[j], {key: str(value) for key, value in dict(g2[j].degree).items()}, 'label')\n\n```\n\nPerform MMD test using various kernels. Note that the unbiases MMD estimator is used\n\n\n```python\n# Random Walk, r is number of eigen-pairs, c is the discount constant\nMMD_out = mg.MMD()\nMMD_out.fit(G1 = g1, G2 = g2, kernel = 'RW_ARKU_plus', mmd_estimators = 'MMD_u', r = 6, c = 0.001)  \nprint(f\" RW_ARKU_plus {MMD_out.p_values}\")\n```\n\n     RW_ARKU_plus {'MMD_u': 0.0}\n    \n\n\n```python\n# RW kernel with labels, Note that we input the label list (all node labels encountered in both graph samples)\nMMD_out = mg.MMD()\nMMD_out.fit(G1 = g1, G2 = g2, kernel = 'RW_ARKL', mmd_estimators = 'MMD_u', r = 4, c = 1e-3,node_label = 'label',\n                                    unique_node_labels= set(np.concatenate([list(nx.get_node_attributes(g, 'label').values())for g in g1+g2])))\nprint(f\" RW_ARKL {MMD_out.p_values}\")\n\n```\n\n    Using label as node labels\n     RW_ARKL {'MMD_u': 0.0}\n    \n\n\n```python\n# GNTK kernel,\n# num_layers is number of layers in neural network,\n# num_mlp_layers is number of multi-layer perceptron layeres\n# jk indicate whether to add jumping knowledge\n# scale how to aggregate neighbours uniform or degree.\nMMD_out = mg.MMD()\nMMD_out.fit(G1 = g1, G2 = g2, kernel = 'GNTK', mmd_estimators = 'MMD_u', num_layers = 2, num_mlp_lauers = 2, jk = True, scale = 'uniform')\nprint(f\" GNTK {MMD_out.p_values}\")\n```\n\n    100%|██████████| 5050/5050.0 [00:11<00:00, 439.45it/s]\n    \n\n     GNTK {'MMD_u': 0.0}\n    \n\n\n```python\n# WWL kernel\n# discount is discount\n# h is number of WL iterations\n# node_label is name of node labels\nMMD_out = mg.MMD()\nMMD_out.fit(G1 = g1, G2 = g2, kernel = 'WWL', mmd_estimators = 'MMD_u', discount = 0.1, h = 2, node_label = 'label')\nprint(f\" WWL {MMD_out.p_values}\")\n```\n\n    Using label as node labels\n     WWL {'MMD_u': 0.0}\n    \n\n\n```python\n# Deep Kernel without the deepness\n# type is wl= wl closeness or sp: shortest path closeness\n# wl_it is number of wl iterations, only applicable for wl.\n# no deepness in this case only a frequency similarity\nMMD_out = mg.MMD()\nMMD_out.fit(G1 = g1, G2 = g2, kernel = 'DK', mmd_estimators = 'MMD_u', type = 'wl', wl_it = 4, node_label = 'label')\nprint(f\" ML DK {MMD_out.p_values}\")\n```\n\n    Using label as node labels\n     ML DK {'MMD_u': 0.0}\n    \n\n\n```python\n\n# Deep kernel with deepness, user has to install gensim, this might take some time, can try to increase number of workers\nMMD_out = mg.MMD()\nMMD_out.fit(G1 = g1, G2 = g2, kernel = 'DK', mmd_estimators = 'MMD_u', type = 'wl', wl_it = 4, opt_type = 'word2vec', node_label = 'label', workers = 10)\nprint(f\" Deep DK {MMD_out.p_values}\")\n```\n\n    Using label as node labels\n     Deep DK {'MMD_u': 0.0}\n    \n\n\n```python\n# It is also possible to use the Grakel library\nkernel = [{\"name\": \"weisfeiler_lehman\", \"n_iter\": 1}, {\"name\": \"vertex_histogram\"}]\nMMD_out = mg.MMD()\nMMD_out.fit(G1 = g1, G2 = g2, kernel = kernel, mmd_estimators = 'MMD_u', node_label = 'label')\nprint(f\" WL {MMD_out.p_values}\")\n```\n\n    Using label as node labels\n    label\n     WL {'MMD_u': 0.0}\n    \n\n\n```python\n# Grakel propagation\nkernel = [ {\"name\":\"propagation\", 't_max':5, 'w':0.1, 'M':\"TV\"}]\nMMD_out = mg.MMD()\nMMD_out.fit(G1 = g1, G2 = g2, kernel = kernel, mmd_estimators = 'MMD_u', node_label = 'label')\nprint(f\" propagation {MMD_out.p_values}\")\n\n```\n\n    Using label as node labels\n    label\n     propagation {'MMD_u': 0.0}\n    \n\n### Using different MMD estimators\n\nIt is also pssobile to use other MMD estimators such as the biases, linear and robust.\n\n\n```python\n# Q is the number of partitions in the MONK estimator\n\nMMD_out = mg.MMD()\nMMD_out.fit(G1 = g1, G2 = g2, kernel = 'RW_ARKU_plus', mmd_estimators = ['MMD_u', 'MMD_b', 'MMD_l', 'MONK_EST'], r = 2, c = 0.001, Q = 5)\nprint(f\" RW_ARKU_plus {MMD_out.p_values}\")\n```\n\n    \n\n     RW_ARKU_plus {'MMD_u': 0.0, 'MMD_b': 0.0, 'MMD_l': 0.0, 'MONK_EST': 0.0}\n    \n\n### H1 true, Graphs with different weights\n\nIt is possible to test graphs which are topologically the same but have different edge weights. Here there are 50 graphs in each sample and the number of nodes is 30 for all graphs. The edge probabilty is 0.3. We will label each node with its corresponding degree so that graph kernels that assume labels can be used.\n\n\n```python\nn1 = n2 = 100\ng1_weights = [nx.fast_gnp_random_graph(30,0.3) for _ in range(n1)]  # sample 1\ng2_weights = [nx.fast_gnp_random_graph(30,0.3) for _ in range(n2)]  # sample 2\n\n# For loops to label each node accoriding to its degree for the two samples.\nfor j in range(len(g1_weights)):\n    nx.set_node_attributes(g1_weights[j],  {key: str(value) for key, value in dict(g1_weights[j].degree).items()} , 'label')\nfor j in range(len(g2_weights)):\n    nx.set_node_attributes(g2_weights[j], {key: str(value) for key, value in dict(g2_weights[j].degree).items()}, 'label')\n\n\n# For loops for the two samples and functions to generate random weights with uniform distribution\ndef edge_dist(loc, scale ):\n    from scipy.stats import uniform\n    return np.random.normal(loc = loc, scale = scale)# uniform.rvs(size=1,  loc = loc , scale = scale)[0]\ndef add_weight(G, loc, scale ):\n    edge_w = dict()\n    for e in G.edges():\n        edge_w[e] = edge_dist(loc, scale)\n    return edge_w\n\n\nfor G in g1_weights:\n    nx.set_edge_attributes(G, add_weight(G, loc = 0.5, scale = 1), \"weight\")\nfor G in g2_weights:\n    nx.set_edge_attributes(G, add_weight(G, loc = 0.5, scale = 2), \"weight\")\n\n```\n\n\n```python\n# Random Walk\nMMD_out = mg.MMD()\nMMD_out.fit(G1 = g1_weights, G2 = g2_weights, kernel = 'RW_ARKU_plus', mmd_estimators = 'MMD_u', r = 2, c = 0.001, edge_attr = 'weight')\nprint(f\" RW_ARKU_plus {MMD_out.p_values}\")\n```\n\n    Using weight as edge attributes\n     RW_ARKU_plus {'MMD_u': 0.0}\n    \n\nNote that if we use a graph kernel that does not take edge weights into account, the test will not be rejected\n\n\n```python\n# Random Walk weights ignored, should not reject\nMMD_out = mg.MMD()\nMMD_out.fit(G1 = g1_weights, G2 = g2_weights, kernel = 'RW_ARKU_plus', mmd_estimators = 'MMD_u', r = 2, c = 0.001)\nprint(f\" RW_ARKU_plus no labels {MMD_out.p_values}\")\n```\n\n     RW_ARKU_plus no labels {'MMD_u': 0.462}\n    \n\n\n```python\n# Grakel pyramid match kernel\nkernel = [{\"name\": \"pyramid_match\", \"L\": 6, \"d\":6, 'with_labels':False}]\nMMD_out = mg.MMD()\nMMD_out.fit(G1 = g1_weights, G2 = g2_weights, kernel = kernel, mmd_estimators = 'MMD_u', edge_attr = 'weight')\nprint(f\" pyramid_match {MMD_out.p_values}\")\n```\n\n    Using weight as edge attributes\n    None\n     pyramid_match {'MMD_u': 0.0}\n    \n\n\n```python\n# propagation, needs node attribute or label \nkernel = [ {\"name\":\"propagation\", 't_max':5, 'w':0.05, 'M':\"TV\"}]\nMMD_out = mg.MMD()\nMMD_out.fit(G1 = g1_weights, G2 = g2_weights, kernel = kernel, mmd_estimators = 'MMD_u', edge_attr = 'weight', node_label = 'label')\nprint(f\" propagation {MMD_out.p_values}\")\n```\n\n    Using weight as edge attributes\n    Using label as node labels\n    label\n     propagation {'MMD_u': 0.0}\n    \n\n ### H1 true different attributes\n\nSome kernels can be used to compare graph with node attributes\n\n\n```python\n\nn1 = n2 = 50\ng1_attr = [nx.fast_gnp_random_graph(30,0.2) for _ in range(n1)]  # sample 1\ng2_attr = [nx.fast_gnp_random_graph(30,0.2) for _ in range(n2)]  # sample 2\n# For loop for the two samples to add node attributes for each graph which have different normal distributions\nfor j in range(len(g1_attr)):\n    nx.set_node_attributes(g1_attr[j], dict( ( (i, np.random.normal(loc = 0, scale = 0.1, size = (1,))) for i in range(len(g1_attr[j])) ) ), 'attr')\nfor j in range(len(g2_attr)):\n    nx.set_node_attributes(g2_attr[j], dict( ( (i, np.random.normal(loc = 0.1, scale = 0.1, size = (1,))) for i in range(len(g2_attr[j])) ) ), 'attr')\n\n```\n\n\n```python\n# Random Walk with weights and node attributes\nMMD_out = mg.MMD()\nMMD_out.fit(G1 = g1_attr, G2 = g2_attr, kernel = 'RW_ARKU_plus', mmd_estimators = 'MMD_u', r = 4, c = 0.01, node_attr = 'attr')\nprint(f\" RW_ARKU_plus {MMD_out.p_values}\")\n```\n\n    Using attr as node attributes\n    \n    \n\n     RW_ARKU_plus {'MMD_u': 0.0}\n    \n\n\n```python\n# GNTK with node attributes\nMMD_out = mg.MMD()\nMMD_out.fit(G1 = g1_attr, G2 = g2_attr, kernel = 'GNTK', mmd_estimators = 'MMD_u', num_layers = 2, num_mlp_lauers = 2, jk = True, scale = 'uniform', node_attr = 'attr')\nprint(f\" GNTK {MMD_out.p_values}\")\n```\n\n    Using attr as node attributes\n    \n\n    100%|██████████| 5050/5050.0 [00:04<00:00, 1246.33it/s]\n    \n\n     GNTK {'MMD_u': 0.0}\n    \n\n\n```python\n# Grakel propagation\nkernel = [ {\"name\":\"propagation\", 't_max':5, 'w':0.1, 'M':\"L1\",'with_attributes':True}]\nMMD_out = mg.MMD()\nMMD_out.fit(G1 = g1_attr, G2 = g2_attr, kernel = kernel, mmd_estimators = 'MMD_u', discount = 0.1, h = 2, node_attr = 'attr')\nprint(f\" Propagation {MMD_out.p_values}\")\n```\n\n    Using attr as node attributes\n    attr\n    \n    \n\n     Propagation {'MMD_u': 0.0}\n    \n\n### Different edge labels\n\nThe RW kernel can take different edge labels\n\n\n```python\nn1 = n2 = 50\ng1_edge = [nx.fast_gnp_random_graph(30,0.3) for _ in range(n1)]  # sample 1\ng2_edge = [nx.fast_gnp_random_graph(30,0.3) for _ in range(n2)]  # sample 2\n\n# For loop to label each edge either 'a' or 'b' the labelling probabilities are different for the two samples\nfor j in range(len(g1_edge)):\n    nx.set_edge_attributes(g1_edge[j], {(i,k):np.random.choice(['a','b'], p = [0.6,0.4]) for i,k in g1_edge[j].edges }, 'edge_label')\nfor j in range(len(g2_edge)):\n    nx.set_edge_attributes(g2_edge[j], {(i,k):np.random.choice(['a','b'], p = [0.7,0.3]) for i,k in g2_edge[j].edges }, 'edge_label')\n\n\n\n```\n\n\n```python\nMMD_out = mg.MMD()\nMMD_out.fit(G1 = g1_edge, G2 = g2_edge, kernel = 'RW_ARKU_edge', mmd_estimators = 'MMD_u', r = 6, c = 0.0001,edge_label = 'edge_label',unique_edge_labels= ['a', 'b'])\nprint(f\" RW_ARKU_edge {MMD_out.p_values}\")\n\n```\n\n    Using edge_label as edge labels\n     RW_ARKU_edge {'MMD_u': 0.0}\n    \n\n# Directed Graphs\n\nThe RW kernel can take directed graphs\n\n\n\n\n```python\nn1 = n2 = 50\ng1_di = [nx.fast_gnp_random_graph(30,0.2) for _ in range(n1)]  # sample 1\ng2_di = [nx.fast_gnp_random_graph(30,0.2) for _ in range(n2)]  # sample 2\n\n# for loop for both samples to convert the networkx graph to a networkx directed graph object\nfor j in range(len(g1_di)):\n    g1_di[j] = nx.DiGraph(g1_di[j])\nfor j in range(len(g2_di)):\n    g2_di[j] = nx.DiGraph(g2_di[j])\n\n# for loop for both samples that removes edges with different removal probabilties between the two samples\nfor j in range(len(g1_di)):\n    edges= list(g1_di[j].edges())\n    for e,u in edges:\n        if np.random.uniform() <0.3:\n            g1_di[j].remove_edge(e,u)\nfor j in range(len(g2_di)):\n    edges= list(g2_di[j].edges())\n    for e,u in edges:\n        if np.random.uniform() <0.5:\n            g2_di[j].remove_edge(e,u)\n\n\n\n\n\n```\n\n\n```python\nMMD_out = mg.MMD()\nMMD_out.fit(G1 = g1_di, G2 = g2_di, kernel = 'RW_ARKU', mmd_estimators = 'MMD_u', r = 4, c = 1e-3)\nprint(f\" RW_ARKU_edge {MMD_out.p_values}\")\n\n```\n\n     RW_ARKU_edge {'MMD_u': 0.0}\n    \n\n### Two data matrices different structure\nIt is possible to estimate graphs from data matrices\n\n\n```python\nG = nx.fast_gnp_random_graph(11, 0.25, seed=42)  # generate a random graph\nassert nx.is_connected(G)\n\n#  Add random weights to the graphs, either positive or negative\nfor e in G.edges():\n    if np.random.uniform() <0.1:\n        w = np.random.uniform(low = 0.1, high = 0.3)\n        G.edges[e[0], e[1]]['weight'] = -w\n    else:\n        w = np.random.uniform(low = 0.1, high = 0.3)\n        G.edges[e[0], e[1]]['weight'] = w\n\n# Extract adjacency matrix and fill the diagonal so that the resulting matrix will be positive definite.\nA = np.array(nx.adjacency_matrix(G).todense())\nnp.fill_diagonal(A, np.sum(np.abs(A), axis = 1)+0.1)\n\n# Copy the adjacency matrix, and remove some edges for that graph,  note the seed is assume to be 45 when G was constructed\nA_s = A.copy()\nA_s[7,4] = 0\nA_s[4,7] = 0\nA_s[5,2] = 0\nA_s[2,5] = 0\n\n\n# Simulate random variables one has A as its precision and one has A_s (the sparse copy of A) as its precision matrix.\n# Note the precision matrix is the inverse covariance.\nX1 = np.random.multivariate_normal(np.zeros(11),np.linalg.inv(A), size = 10000)\nX2 = np.random.multivariate_normal(np.zeros(11),np.linalg.inv(A_s), size = 10000)\n```\n\n    \n\nInput the two samples X1 and X2 to the class method estimate_graphs. Which estimates graphs according to a window size. The best estimation is selected via the EBIC criterion.\n\n\n```python\n# window size = 200 so 10000/200 = 50 graphs in each sample. (200 observations used to estimate each graph.)\n# Nonparanormal, should the nonparanormal transformation be performed on the data matrices.\n# Scale should the data be scaled.\n# Random Walk\nMMD_out = mg.MMD()\nMMD_out.estimate_graphs(X1,X2,window_size=200, alpha = np.exp(np.linspace(-5,-2,100)),beta = 0.5, nonparanormal=False,scale = False)\nMMD_out.fit( kernel = 'RW_ARKU_plus', mmd_estimators = 'MMD_u', r = 5, c = 0.1, edge_attr = 'weight')\nprint(MMD_out.p_values)\n\n\n```\n\n    Using weight as edge attributes\n    \n    \n\n    {'MMD_u': 0.001}\n    \n\n\n```python\n# We can set node labels as degree (or define our own labelling, see below)\nMMD_out = mg.MMD()\nkernel = [{\"name\": \"weisfeiler_lehman\", \"n_iter\": 4}, {\"name\": \"vertex_histogram\"}]\nMMD_out.estimate_graphs(X1,X2,window_size=200, alpha = np.exp(np.linspace(-5,-2,100)),beta = 0.5, nonparanormal=False,scale = False, set_labels=\"degree\")\nMMD_out.fit( kernel = kernel, mmd_estimators = 'MMD_u',  edge_attr = 'weight')\nprint(MMD_out.p_values)\n```\n\n    Using weight as edge attributes\n    Using label as node labels\n    label\n    {'MMD_u': 0.002}\n    \n\nPlot estimated estimated graphs and compare to the true.\n\n\n```python\nnp.fill_diagonal(A_s,0)\nfig, ax = plt.subplots(2,2,figsize = (10,10))\npos = nx.kamada_kawai_layout(G, weight = None)\nnx.draw(G, pos = pos, ax = ax[0,0])\nnx.draw(nx.from_numpy_array(A_s), pos = pos, ax = ax[0,1])\nnx.draw(MMD_out.G1[3], pos = pos, ax = ax[1,0])  # select graph number 3 in sample 1\nnx.draw(MMD_out.G2[3], pos = pos, ax = ax[1,1])  # select graph number 3 in sample 2\nax[0,0].set_title(\"Sample 1 true precision structure\")\nax[0,1].set_title(\"Sample 2 true precision structure\")\nax[1,0].set_title(\"One estimated precision structure from sample 1\")\nax[1,1].set_title(\"One estimated precision structure from sample 2\")\n```\n\n\n\n\n    Text(0.5, 1.0, 'One estimated precision structure from sample 2')\n\n\n\n\n    \n![png](README_files/README_46_1.png)\n    \n\n\n### Two data matrices same structure different attributes\nIt is possible to estimate the graphs beforehand and apply a function to get node attributes\n\n\n```python\n# Generate random samples that have the same underlying precision matrix/graph, but the node have different mean.\n\nG = nx.fast_gnp_random_graph(11, 0.25, seed = 42)\nassert nx.is_connected(G)\n\nfor e in G.edges():\n    if np.random.uniform() <0.1:\n        w = np.random.uniform(low = 0.1, high = 0.3)\n        G.edges[e[0], e[1]]['weight'] = -w\n    else:\n        w = np.random.uniform(low = 0.1, high = 0.3)\n        G.edges[e[0], e[1]]['weight'] = w\n\nA = np.array(nx.adjacency_matrix(G).todense())\nnp.fill_diagonal(A, np.sum(np.abs(A), axis = 1)+0.1)\n\n\nX1 = np.random.multivariate_normal(np.zeros(11),np.linalg.inv(A), size = 10000)\nX2 = np.random.multivariate_normal(np.ones(11),np.linalg.inv(A), size = 10000)\n```\n    \n\n\n```python\n# Random Walk, with attributes, should reject. , the class will use the node label name 'attr'\n# Define attribute function that sets the mean as the node attribute. \n# Note the window size is 400 so there will be 400 observations that are used to estimate each graph/node attribute.\ndef attr_function(X):\n    return np.expand_dims(np.mean(X,axis = 0),axis=1)\n\nMMD_out = mg.MMD()\nMMD_out.estimate_graphs(X1,X2,window_size=400, alpha = np.exp(np.linspace(-5,-2,100)),beta = 0.5, nonparanormal=False,scale = False, set_attributes = attr_function)\nMMD_out.fit( kernel = 'RW_ARKU_plus', mmd_estimators = 'MMD_u', r = 5, c = 0.1, edge_attr = 'weight', node_attr = 'attr')\nprint(MMD_out.p_values)\n```\n\n    Using weight as edge attributes\n    Using attr as node attributes\n    \n\n    {'MMD_u': 0.0}\n    \n\n\n```python\n# If we do not give attributes, the test should not be rejected reject as underlying the precision matrices are the same\nMMD_out_no_attr = mg.MMD()\nMMD_out_no_attr.fit(G1= MMD_out.G1, G2 = MMD_out.G2, kernel = 'RW_ARKU_plus', mmd_estimators = 'MMD_u', r = 5, c = 0.1, edge_attr = 'weight')\nprint(MMD_out_no_attr.p_values)\n```\n\n    Using weight as edge attributes\n    {'MMD_u': 0.993}\n    \n\n\n```python\n# We can also try to make a label function, has to be a dictionary, the class will use the node label name 'label'\n# Note we label the nodes with the rounded mean\ndef label_function(X):\n    m = np.mean(X,axis = 0)\n    return {i:str(np.round(m[i],1)) for i in range(len(m))}\n\nkernel = [{\"name\": \"weisfeiler_lehman\", \"n_iter\": 2}, {\"name\": \"vertex_histogram\"}]\nMMD_out = mg.MMD()\nMMD_out.estimate_graphs(X1,X2,window_size=400, alpha = np.exp(np.linspace(-5,-2,100)),beta = 0.5, nonparanormal=False,scale = False, set_labels= label_function)\nMMD_out.fit(kernel = kernel, mmd_estimators = 'MMD_u', node_label = 'label')\nprint(MMD_out.p_values)\n```\n\n    Using label as node labels\n    label\n    {'MMD_u': 0.0}\n    \n\n\n```python\n# We can also define labels using a dict\n# '1' for sample 1, '2' for sample 2. Graph nr. j gets the list ['a']*6 + ['b']*5\n# meaning the first 6 nodes will be labelled 'a' and the last 5 nodes will be labelled 'b' for sample 1 but\n# the first 4 nodes will be labelled 'a' and the last 7 nodes will be labelled 'b' for sample 2\nlabel_dict = {'1':{j:i for j,i in enumerate(['a']*6 + ['b']*5)}, \n              '2':{j:i for j,i in enumerate(['a']*4 + ['b']*7)}}\nkernel = [{\"name\": \"weisfeiler_lehman\", \"n_iter\": 2}, {\"name\": \"vertex_histogram\"}]\nMMD_out = mg.MMD()\nMMD_out.estimate_graphs(X1,X2,window_size=400, alpha = np.exp(np.linspace(-5,-2,100)),beta = 0.5, nonparanormal=False,scale = False, set_labels= label_dict)\nMMD_out.fit(kernel = kernel, mmd_estimators = 'MMD_u', node_label = 'label')\nprint(MMD_out.p_values)\n```\n\n    Using label as node labels\n    label\n    {'MMD_u': 0.0}\n    \n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "GTST",
    "package_url": "https://pypi.org/project/GTST/",
    "platform": null,
    "project_url": "https://pypi.org/project/GTST/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/GTST/0.0.3/",
    "requires_dist": [
      "networkx>=2.7.1",
      "numpy~=1.21.0",
      "scikit-learn>=1.0.2",
      "scipy>=1.8.0",
      "tqdm>=4.63.1"
    ],
    "requires_python": ">=3.7",
    "summary": "A package for comparing two-sample of graphs",
    "version": "0.0.3",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17119136,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a2a903a5bc1e9cadd644dc40bcc98dd00f8be4d8fc941276bfc08642c1f3abe1",
          "md5": "082aafb9a2eba5aa3ce1ab3b63ab519b",
          "sha256": "f78c20a104902ef383c28002059ec68ede06e9577bed5af0cee25d6d15eb6c0c"
        },
        "downloads": -1,
        "filename": "gtst-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "082aafb9a2eba5aa3ce1ab3b63ab519b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 29353,
        "upload_time": "2023-03-01T23:35:23",
        "upload_time_iso_8601": "2023-03-01T23:35:23.677156Z",
        "url": "https://files.pythonhosted.org/packages/a2/a9/03a5bc1e9cadd644dc40bcc98dd00f8be4d8fc941276bfc08642c1f3abe1/gtst-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fdfbc23c8142d9a4bedaa9f4e50db5e0acebaecc1cbe1ba539b2fbfb532352c4",
          "md5": "d33c507de85361cc59660f24350669f7",
          "sha256": "0ac9376f50058450f578914afc67b4bbd3988389103aac8b9eeeb6d3dff0a662"
        },
        "downloads": -1,
        "filename": "gtst-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "d33c507de85361cc59660f24350669f7",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 534932,
        "upload_time": "2023-03-01T23:35:26",
        "upload_time_iso_8601": "2023-03-01T23:35:26.463206Z",
        "url": "https://files.pythonhosted.org/packages/fd/fb/c23c8142d9a4bedaa9f4e50db5e0acebaecc1cbe1ba539b2fbfb532352c4/gtst-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f231126aad2a7a41feeea530c043249656071d562e2b13d7625798c64ce367c3",
          "md5": "3872a99cef83dfc77099e3642114a525",
          "sha256": "1bd7d11f7ce1b6c64c98efdf1305401f377bb2fb5b60cab506321ea77719ec21"
        },
        "downloads": -1,
        "filename": "gtst-0.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "3872a99cef83dfc77099e3642114a525",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 29381,
        "upload_time": "2023-03-01T23:50:39",
        "upload_time_iso_8601": "2023-03-01T23:50:39.835994Z",
        "url": "https://files.pythonhosted.org/packages/f2/31/126aad2a7a41feeea530c043249656071d562e2b13d7625798c64ce367c3/gtst-0.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "46d9bc5da8187e0ce7af39c712c473a4b1bcd2e826e0ec40e7eb10be6289943f",
          "md5": "a57f0aac889a870d0b71d973ea9fc728",
          "sha256": "409c48e9a2cb2a7fdda5e511c81c74e434c39faaf58bebbf458472b5230aff75"
        },
        "downloads": -1,
        "filename": "gtst-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "a57f0aac889a870d0b71d973ea9fc728",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 535475,
        "upload_time": "2023-03-01T23:50:41",
        "upload_time_iso_8601": "2023-03-01T23:50:41.851463Z",
        "url": "https://files.pythonhosted.org/packages/46/d9/bc5da8187e0ce7af39c712c473a4b1bcd2e826e0ec40e7eb10be6289943f/gtst-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "f231126aad2a7a41feeea530c043249656071d562e2b13d7625798c64ce367c3",
        "md5": "3872a99cef83dfc77099e3642114a525",
        "sha256": "1bd7d11f7ce1b6c64c98efdf1305401f377bb2fb5b60cab506321ea77719ec21"
      },
      "downloads": -1,
      "filename": "gtst-0.0.3-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "3872a99cef83dfc77099e3642114a525",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 29381,
      "upload_time": "2023-03-01T23:50:39",
      "upload_time_iso_8601": "2023-03-01T23:50:39.835994Z",
      "url": "https://files.pythonhosted.org/packages/f2/31/126aad2a7a41feeea530c043249656071d562e2b13d7625798c64ce367c3/gtst-0.0.3-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "46d9bc5da8187e0ce7af39c712c473a4b1bcd2e826e0ec40e7eb10be6289943f",
        "md5": "a57f0aac889a870d0b71d973ea9fc728",
        "sha256": "409c48e9a2cb2a7fdda5e511c81c74e434c39faaf58bebbf458472b5230aff75"
      },
      "downloads": -1,
      "filename": "gtst-0.0.3.tar.gz",
      "has_sig": false,
      "md5_digest": "a57f0aac889a870d0b71d973ea9fc728",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 535475,
      "upload_time": "2023-03-01T23:50:41",
      "upload_time_iso_8601": "2023-03-01T23:50:41.851463Z",
      "url": "https://files.pythonhosted.org/packages/46/d9/bc5da8187e0ce7af39c712c473a4b1bcd2e826e0ec40e7eb10be6289943f/gtst-0.0.3.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}