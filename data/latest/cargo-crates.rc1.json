{
  "info": {
    "author": "Damon P. Cortesi",
    "author_email": "cargocrates@dcortesi.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Cargo Crates\n\nAn easy way to build data extractors in Docker.\n\nGet it ... it's data containers ... cargo crates. \n\nAnyway.\n\n## Usage\n\nConvention over configuration(?).\n\nCargo crates share a common set of patterns that make them easy to use.\n\n- Each crate is associated with a specific API.\n- Authentication is provided via environment variables.\n- Parameters are provided to the container at runtime.\n\nFor example, to extract sleep data from the Oura API you would run a container like this:\n\n```shell\n docker run -e OURA_PAT=<TOKEN> ghcr.io/dacort/crates-oura\n```\n\nYou can be more specific or select different APIs, too:\n\n```shell\n# Returns data beginning 2021-01-01\ndocker run -e OURA_PAT=<TOKEN> -e start=2021-01-01 ghcr.io/dacort/crates-oura\n```\n\n```shell\n# Returns activity data instead of sleep data (the default)\ndocker run -e OURA_PAT=<TOKEN> ghcr.io/dacort/crates-oura activity\n```\n\nOther APIs might need more flexibility - for example, with Twitter there are numerous endpoints.\n\nIn this case, the `.env` file contains the environment variables needed for Twitter authentication.\n\n```shell\n# Extract current user info\ndocker run --env-file .env ghcr.io/dacort/crates-twitter users/show dacort\n\n# Or fetch a user's followers\ndocker run --env-file .env ghcr.io/dacort/crates-twitter followers dacort\n```\n\nThe idea is that the Docker container provides an abstraction on top of the underlying APIs and can be implemented however you want. \n\nPerhaps someday down the road there could be a set of base images that provide a nice set of abstractions for generic authentication and error handling. But for now, it's just a bunch of python.\n\n## Caveats\n\nRight now I'm building this for my own purposes. So the set of supported APIs or endpoints is rather limited.\n\n## Supported Services\n\n### GitHub\n\nSupported Commands:\n- `traffic` - returns results from GitHub traffic stats including clones, popular/paths, popular/referrers, and views. Each type of traffic stat is a subcommand.\n- `releases` - returns information about releases for a specific GitHub repo.\n\nEnvironment Variables:\n- `GITHUB_PAT` - Your GitHub [Personal Access Token](https://github.com/settings/tokens)\n\nExamples:\n- Return all traffic stats for `dacort/cargo-crates`\n    ```shell\n    docker run -e GITHUB_PAT \\\n        ghcr.io/dacort/crates-github \\\n        traffic dacort/cargo-crates \n    ```\n    ```json\n    {\"repo\": \"dacort/cargo-crates\", \"path\": \"clones\", \"stats\": {\"count\": 77, \"uniques\": 8, \"clones\": [{\"timestamp\": \"2021-03-18T00:00:00Z\", \"count\": 77, \"uniques\": 8}]}}\n    {\"repo\": \"dacort/cargo-crates\", \"path\": \"popular/paths\", \"stats\": [{\"path\": \"/dacort/cargo-crates/actions\", \"title\": \"Actions \\u00b7 dacort/cargo-crates\", \"count\": 33, \"uniques\": 1}, {\"path\": \"/dacort/cargo-crates\", \"title\": \"dacort/cargo-crates\", \"count\": 11, \"uniques\": 2}, {\"path\": \"/dacort/cargo-crates/actions/workflows/crates.yaml\", \"title\": \"Actions \\u00b7 dacort/cargo-crates\", \"count\": 7, \"uniques\": 1}, {\"path\": \"/dacort/cargo-crates/actions/runs/666130915\", \"title\": \"Remove useless job0 \\u00b7 dacort/cargo-crates@6b54337\", \"count\": 4, \"uniques\": 1}, {\"path\": \"/dacort/cargo-crates/actions/runs/666151009\", \"title\": \"Trying something else \\u00b7 dacort/cargo-crates@ed3d226\", \"count\": 3, \"uniques\": 1}, {\"path\": \"/dacort/cargo-crates/actions/runs/666165537\", \"title\": \"Hmm \\u00b7 dacort/cargo-crates@64c59e7\", \"count\": 3, \"uniques\": 1}, {\"path\": \"/dacort/cargo-crates/actions/runs/666215936\", \"title\": \"Add requirements \\u00b7 dacort/cargo-crates@6161093\", \"count\": 3, \"uniques\": 1}, {\"path\": \"/dacort/cargo-crates/actions/runs/666227882\", \"title\": \"Does this actually work now?? \\u00b7 dacort/cargo-crates@37d31ea\", \"count\": 3, \"uniques\": 1}, {\"path\": \"/dacort/cargo-crates/pulls\", \"title\": \"Pull requests \\u00b7 dacort/cargo-crates\", \"count\": 3, \"uniques\": 1}, {\"path\": \"/dacort/cargo-crates/actions/workflows/test_matrix.yaml\", \"title\": \"Actions \\u00b7 dacort/cargo-crates\", \"count\": 2, \"uniques\": 1}]}\n    {\"repo\": \"dacort/cargo-crates\", \"path\": \"popular/referrers\", \"stats\": [{\"referrer\": \"github.com\", \"count\": 3, \"uniques\": 2}]}\n    {\"repo\": \"dacort/cargo-crates\", \"path\": \"views\", \"stats\": {\"count\": 108, \"uniques\": 2, \"views\": [{\"timestamp\": \"2021-03-18T00:00:00Z\", \"count\": 108, \"uniques\": 2}]}}\n    ```\n- Return only views for `dacort/cargo-crates`\n    ```shell\n    docker run -e GITHUB_PAT ghcr.io/dacort/crates-github traffic dacort/cargo-crates views\n    ```\n    ```json\n    {\"repo\": \"dacort/cargo-crates\", \"path\": \"views\", \"stats\": {\"count\": 108, \"uniques\": 2, \"views\": [{\"timestamp\": \"2021-03-18T00:00:00Z\", \"count\": 108, \"uniques\": 2}]}}\n    ```\n\n### YouTube\n\nSupported Commands:\n- `videos` - return video stats for up to 50 video IDs.\n- `channel_videos` - return video stats for 50 videos on the provided channel ID.\n\nEnvironment Variables:\n- `YOUTUBE_API_KEY` - An API key for the [YouTube Data API](https://developers.google.com/youtube/v3/docs)\n\nExamples:\n- Return video stats for [Intro to EMR Studio](https://www.youtube.com/watch?v=rZ3zeJ6WKPY)\n    ```shell\n    docker run -e YOUTUBE_API_KEY \\\n        ghcr.io/dacort/crates-youtube \\\n        videos rZ3zeJ6WKPY \n    ```\n    <details>\n        <summary>Click to view JSON</summary>\n    ```json\n    {\n        \"kind\": \"youtube#video\",\n        \"etag\": \"tbhtHqbvEMe3jNGfFGK36HpowJk\",\n        \"id\": \"rZ3zeJ6WKPY\",\n        \"snippet\": {\n            \"publishedAt\": \"2021-04-21T22:43:26Z\",\n            \"channelId\": \"UCd6MoB9NC6uYN2grvUNT-Zg\",\n            \"title\": \"Intro to Amazon EMR Studio\",\n            \"description\": \"Introduction to Amazon EMR Studio. In this video, we show how to:\\n- Create a new workspace\\n- Utilize cluster templates for EMR clusters\\n- Connect EMR Studio to a GitHub repository\\n- Execute parameterized notebooks\\n\\nLearn more about Amazon EMR Studio - https://amzn.to/3xhbuEj\\n\\nSubscribe: \\nMore AWS videos - http://bit.ly/2O3zS75 \\nMore AWS events videos - http://bit.ly/316g9t4\\n\\n#AWS #AWSDemo #AmazonEMRStudio\",\n            \"thumbnails\": {\n                \"default\": {\n                    \"url\": \"https://i.ytimg.com/vi/rZ3zeJ6WKPY/default.jpg\",\n                    \"width\": 120,\n                    \"height\": 90\n                },\n                \"medium\": {\n                    \"url\": \"https://i.ytimg.com/vi/rZ3zeJ6WKPY/mqdefault.jpg\",\n                    \"width\": 320,\n                    \"height\": 180\n                },\n                \"high\": {\n                    \"url\": \"https://i.ytimg.com/vi/rZ3zeJ6WKPY/hqdefault.jpg\",\n                    \"width\": 480,\n                    \"height\": 360\n                },\n                \"standard\": {\n                    \"url\": \"https://i.ytimg.com/vi/rZ3zeJ6WKPY/sddefault.jpg\",\n                    \"width\": 640,\n                    \"height\": 480\n                },\n                \"maxres\": {\n                    \"url\": \"https://i.ytimg.com/vi/rZ3zeJ6WKPY/maxresdefault.jpg\",\n                    \"width\": 1280,\n                    \"height\": 720\n                }\n            },\n            \"channelTitle\": \"Amazon Web Services\",\n            \"tags\": [\n                \"AWS\",\n                \"Amazon Web Services\",\n                \"Cloud\",\n                \"AWS Cloud\",\n                \"Cloud Computing\",\n                \"Amazon AWS\",\n                \"Amazon EMR\",\n                \"Amazon EMR Studio\",\n                \"Jupyter\"\n            ],\n            \"categoryId\": \"28\",\n            \"liveBroadcastContent\": \"none\",\n            \"localized\": {\n                \"title\": \"Intro to Amazon EMR Studio\",\n                \"description\": \"Introduction to Amazon EMR Studio. In this video, we show how to:\\n- Create a new workspace\\n- Utilize cluster templates for EMR clusters\\n- Connect EMR Studio to a GitHub repository\\n- Execute parameterized notebooks\\n\\nLearn more about Amazon EMR Studio - https://amzn.to/3xhbuEj\\n\\nSubscribe: \\nMore AWS videos - http://bit.ly/2O3zS75 \\nMore AWS events videos - http://bit.ly/316g9t4\\n\\n#AWS #AWSDemo #AmazonEMRStudio\"\n            },\n            \"defaultAudioLanguage\": \"en\"\n        },\n        \"contentDetails\": {\n            \"duration\": \"PT12M34S\",\n            \"dimension\": \"2d\",\n            \"definition\": \"hd\",\n            \"caption\": \"false\",\n            \"licensedContent\": false,\n            \"contentRating\": {},\n            \"projection\": \"rectangular\"\n        },\n        \"statistics\": {\n            \"viewCount\": \"537\",\n            \"likeCount\": \"9\",\n            \"dislikeCount\": \"0\",\n            \"favoriteCount\": \"0\",\n            \"commentCount\": \"0\"\n        }\n    }\n    ```\n    </details>\n\n### Oura\n\nRetrieve one of three different [daily summaries](https://cloud.ouraring.com/docs/daily-summaries) from the Oura Ring API.\n\nSupported Commands:\n- `sleep` - return [sleep periods](https://cloud.ouraring.com/docs/sleep)\n- `activity` - return [activity summary](https://cloud.ouraring.com/docs/activity)\n- `readiness` - return [readiness data](https://cloud.ouraring.com/docs/readiness)\n\nEnvironment Variables:\n- `OURA_PAT` - Your Oura [personal access token](https://cloud.ouraring.com/personal-access-tokens#)\n\nExamples:\n- Return sleep data for the past 7 days\n    ```shell\n    docker run -e OURA_PAT \\\n        ghcr.io/dacort/crates-oura \\\n        sleep | head -n 1\n    ```\n    <details>\n        <summary>Click to view JSON</summary>\n    ```json\n    {\n        \"awake\": 2010,\n        \"bedtime_end\": \"2021-04-20T06:55:43-07:00\",\n        \"bedtime_end_delta\": 24943,\n        \"bedtime_start\": \"2021-04-19T23:24:43-07:00\",\n        \"bedtime_start_delta\": -2117,\n        \"breath_average\": 16.25,\n        \"deep\": 4290,\n        \"duration\": 27060,\n        \"efficiency\": 93,\n        \"hr_5min\": [\n            63,\n            63,\n            64,\n            65,\n            66,\n            66,\n            66,\n            67,\n            66,\n            66,\n            67,\n            70,\n            71,\n            70,\n            69,\n            69,\n            70,\n            69,\n            68,\n            68,\n            68,\n            67,\n            67,\n            66,\n            66,\n            66,\n            66,\n            66,\n            62,\n            64,\n            70,\n            68,\n            67,\n            66,\n            66,\n            67,\n            66,\n            66,\n            65,\n            66,\n            66,\n            67,\n            67,\n            67,\n            67,\n            70,\n            69,\n            71,\n            71,\n            69,\n            68,\n            66,\n            63,\n            65,\n            67,\n            66,\n            65,\n            64,\n            63,\n            62,\n            63,\n            65,\n            66,\n            65,\n            69,\n            72,\n            74,\n            72,\n            68,\n            68,\n            69,\n            68,\n            66,\n            62,\n            63,\n            62,\n            61,\n            60,\n            60,\n            58,\n            60,\n            57,\n            58,\n            57,\n            57,\n            58,\n            61,\n            64,\n            66,\n            61,\n            0\n        ],\n        \"hr_average\": 65.68,\n        \"hr_lowest\": 57,\n        \"hypnogram_5min\": \"4221111111222322221111222122223332222222223344333332222212222112333334233332222242222222444\",\n        \"is_longest\": 1,\n        \"light\": 14730,\n        \"midpoint_at_delta\": 11083,\n        \"midpoint_time\": 13200,\n        \"onset_latency\": 270,\n        \"period_id\": 0,\n        \"rem\": 6030,\n        \"restless\": 29,\n        \"rmssd\": 27,\n        \"rmssd_5min\": [\n            33,\n            27,\n            20,\n            19,\n            17,\n            17,\n            17,\n            17,\n            19,\n            22,\n            31,\n            28,\n            18,\n            19,\n            20,\n            19,\n            14,\n            15,\n            17,\n            14,\n            14,\n            15,\n            15,\n            18,\n            17,\n            17,\n            16,\n            40,\n            44,\n            32,\n            21,\n            26,\n            30,\n            27,\n            20,\n            20,\n            17,\n            27,\n            19,\n            16,\n            18,\n            22,\n            23,\n            24,\n            33,\n            23,\n            27,\n            19,\n            19,\n            19,\n            36,\n            29,\n            38,\n            29,\n            27,\n            27,\n            36,\n            31,\n            29,\n            34,\n            29,\n            28,\n            24,\n            36,\n            26,\n            23,\n            19,\n            17,\n            31,\n            30,\n            29,\n            30,\n            32,\n            47,\n            39,\n            30,\n            44,\n            53,\n            48,\n            41,\n            42,\n            65,\n            47,\n            62,\n            48,\n            39,\n            36,\n            22,\n            26,\n            36,\n            0\n        ],\n        \"score\": 83,\n        \"score_alignment\": 97,\n        \"score_deep\": 88,\n        \"score_disturbances\": 77,\n        \"score_efficiency\": 98,\n        \"score_latency\": 72,\n        \"score_rem\": 91,\n        \"score_total\": 77,\n        \"summary_date\": \"2021-04-19\",\n        \"temperature_delta\": 0.06,\n        \"temperature_deviation\": 0.06,\n        \"temperature_trend_deviation\": 0.29,\n        \"timezone\": -420,\n        \"total\": 25050,\n        \"activity_type\": \"sleep\"\n    }\n    ```\n    </details>\n\n### Reddit API\n\nI wanted to get my saved posts out of the [Reddit API](https://www.reddit.com/dev/api). It's a little tough to understand, and the saved posts aren't actually documented there...but after [some hunting](https://www.reddit.com/r/redditdev/comments/91g3ek/api_403_while_trying_to_get_my_saved_posts/), I found that they can be accessed at `/user/dacort/saved.json`.\n\nThis functionality just fetches the most recent 100 saved posts every time. I considered adding a `start_date` filter, but don't need it right now. 😁\n\nSupported Commands:\n- saved <username> - list saved posts for `<username>`\n- search [subreddit] <search_term> - search all of Reddit or a specific subreddit (`r/subreddit_name`) for a search term\n    - Note that terms in quotes need to be surrounded in single quotes, e.g. `'\"cargo crates\"'`\n\nEnvironment Variables:\n- CLIENT_ID - Client ID of a [\"script\"](https://www.reddit.com/prefs/apps) type app\n- CLIENT_SECRET - App secret\n- USERNAME - Your Reddit username\n- PASSWORD - Your Reddit password\n\n### Slack Web API\n\nThe [Slack Web API](https://api.slack.com/web) is intended for use with ad-hoc queries and I use it to query basic info about some of the channels I'm in.\n\nSupported Commands:\n- `channels` - [list all channels](https://api.slack.com/methods/conversations.list) in a Slack team\n- `search` - [search for a keyword](https://api.slack.com/methods/search.messages) in your Slack team\n\nEnvironment Variables:\n- `SLACK_TOKEN` - Some sort of Slack token that starts with `xox...`\n\nExamples:\n\n1. Get a list of channels for the workspace the token is associated with\n\n```shell\ndocker run -e SLACK_TOKEN \\\n    ghcr.io/dacort/crates-slack channels\n```\n\n2. Perform a search in the workspace the token is associated with\n\n```shell\ndocker run -e SLACK_TOKEN \\\n    ghcr.io/dacort/crates-slack search dacort\n```\n\n### Twitter\n\nOnly a couple Twitter endpoints are defined at this point.\n\nSupported Commands:\n- `followers` - return list of followers for a given screen name\n- `users/show` - return user profile data for a given screen name\n\nEnvironment Variables - create a Twitter app and define the 4 different variables.\n- `CONSUMER_KEY`\n- `CONSUMER_SECRET`\n- `ACCESS_TOKEN_KEY`\n- `ACCESS_TOKEN_SECRET`\n\nYou can store all these environment variables in a file and reference that file with Docker.\n\nExamples:\n- Return [@dacort's](https://twitter.com/dacort) profile\n    ```shell\n    docker run --env-file .env \\\n        ghcr.io/dacort/crates-twitter \\\n        users/show dacort\n    ```\n    ```json\n    {\"id\": \"99723\", \"name\": \"Damon Cortesi\", \"username\": \"dacort\"}\n    ```\n\n## Writing output to Amazon S3\n\nThe original idea behind this repo was that I could run these containers and easily output the resulting data to templated paths on S3. \n\nSo I built another tool, called [Forklift](https://github.com/dacort/forklift), that comes bundled with each Cargo Crate.\n\nIf you run the container normally, the output gets printed to stdout. However, if you provide a `FORKLIFT_URI` environment variable,\nthe data will get written to the S3 path provided. You can templatize parts of the path with JSON keys or a couple helper functions.\n\nFor example, the command below will upload my profile info to `s3://<BUCKET>/forklift/twitter/dt=2021-05-15/dacort.json`\n\n```shell\ndocker run \\\n    -e FORKLIFT_URI='s3://<BUCKET>/forklift/twitter/dt={{ today }}/{{json \"username\"}}.json' \\\n    -e AWS_ACCESS_KEY_ID \\\n    -e AWS_SECRET_ACCESS_KEY \\\n    --env-file .env \\\n    ghcr.io/dacort/crates-twitter users/show dacort\n```\n \nNote that we passed AWS credentials as environment variables. You will either need to do that or run the container in AWS using [instance profiles](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html). \n\n## Some higher level thoughts after a few implementations\n\n- The data is intended to be streamed\n    - Output is always a JSON stream\n- Each implementation is intended to be completely independent\n    - They're all Python...they could be anything else!\n- Each implementation is intended to be as lightweight as possible\n    - Don't force unnecessary requirements into a crate\n\n## Next steps\n\n- Formalize the executor API and base class\n    - I want a way to be able to register commands, their parameters, and required environment variables\n- Formalize the output API and stdout/S3 classes\n    - Right now it's pretty hardcoded into the GitHub crate\n\n## Maybe someday\n\n- A generic \"auth\" command for crates\n\n## Resources\n\n- [Python project structure](https://dev.to/codemouse92/dead-simple-python-project-structure-and-imports-38c6)\n- [Minimal Docker containers for Python](https://blog.realkinetic.com/building-minimal-docker-containers-for-python-applications-37d0272c52f3)\n- (ended up not using, but) [IO Streams with Python](https://medium.com/dev-bits/ultimate-guide-for-working-with-i-o-streams-and-zip-archives-in-python-3-6f3cf96dca50)\n- [For building matrix builds](https://stackoverflow.com/questions/59977364/github-actions-how-use-strategy-matrix-with-script)\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/dacort/cargo-crates",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "cargo-crates",
    "package_url": "https://pypi.org/project/cargo-crates/",
    "platform": "",
    "project_url": "https://pypi.org/project/cargo-crates/",
    "project_urls": {
      "Bug Tracker": "https://github.com/dacort/cargo-crates/issues",
      "Homepage": "https://github.com/dacort/cargo-crates"
    },
    "release_url": "https://pypi.org/project/cargo-crates/0.0.1/",
    "requires_dist": [
      "TwitterAPI (==2.6.6)",
      "requests (==2.25.1)"
    ],
    "requires_python": ">=3.8",
    "summary": "An easy way to build data extractors in Docker.",
    "version": "0.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 11410282,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d826a8b423c88b06255e9c5f5bf9946dca3c50c5b3012ef0fa6958f6b93a39ee",
          "md5": "e7a6b34f1125f69c5acfd25b6c803b02",
          "sha256": "6723a2453adf366c298292c27c9b6f5f519613f4828f6df244b25165db434a65"
        },
        "downloads": -1,
        "filename": "cargo_crates-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "e7a6b34f1125f69c5acfd25b6c803b02",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 16693,
        "upload_time": "2021-09-09T20:57:25",
        "upload_time_iso_8601": "2021-09-09T20:57:25.601938Z",
        "url": "https://files.pythonhosted.org/packages/d8/26/a8b423c88b06255e9c5f5bf9946dca3c50c5b3012ef0fa6958f6b93a39ee/cargo_crates-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4026db8d930260f0ec878bbc65d318af030b8a2de4ea0ccd193d784137cb4e0d",
          "md5": "a77b44f9faae369644111c510c6f9685",
          "sha256": "23f44a59dea8ea1001303159eae55c1f8a9d58e9653b43ad8cf16c4efb6d15b5"
        },
        "downloads": -1,
        "filename": "cargo-crates-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "a77b44f9faae369644111c510c6f9685",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 13481,
        "upload_time": "2021-09-09T20:57:26",
        "upload_time_iso_8601": "2021-09-09T20:57:26.981476Z",
        "url": "https://files.pythonhosted.org/packages/40/26/db8d930260f0ec878bbc65d318af030b8a2de4ea0ccd193d784137cb4e0d/cargo-crates-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "d826a8b423c88b06255e9c5f5bf9946dca3c50c5b3012ef0fa6958f6b93a39ee",
        "md5": "e7a6b34f1125f69c5acfd25b6c803b02",
        "sha256": "6723a2453adf366c298292c27c9b6f5f519613f4828f6df244b25165db434a65"
      },
      "downloads": -1,
      "filename": "cargo_crates-0.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "e7a6b34f1125f69c5acfd25b6c803b02",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.8",
      "size": 16693,
      "upload_time": "2021-09-09T20:57:25",
      "upload_time_iso_8601": "2021-09-09T20:57:25.601938Z",
      "url": "https://files.pythonhosted.org/packages/d8/26/a8b423c88b06255e9c5f5bf9946dca3c50c5b3012ef0fa6958f6b93a39ee/cargo_crates-0.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "4026db8d930260f0ec878bbc65d318af030b8a2de4ea0ccd193d784137cb4e0d",
        "md5": "a77b44f9faae369644111c510c6f9685",
        "sha256": "23f44a59dea8ea1001303159eae55c1f8a9d58e9653b43ad8cf16c4efb6d15b5"
      },
      "downloads": -1,
      "filename": "cargo-crates-0.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "a77b44f9faae369644111c510c6f9685",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.8",
      "size": 13481,
      "upload_time": "2021-09-09T20:57:26",
      "upload_time_iso_8601": "2021-09-09T20:57:26.981476Z",
      "url": "https://files.pythonhosted.org/packages/40/26/db8d930260f0ec878bbc65d318af030b8a2de4ea0ccd193d784137cb4e0d/cargo-crates-0.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}