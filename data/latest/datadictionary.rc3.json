{
  "info": {
    "author": "Jason Atwood",
    "author_email": "jason@thedatatoldme.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "License :: OSI Approved :: GNU General Public License v3 (GPLv3)",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# DataDictionary Overview\nIn any data environment, the introduction of new data brings questions about the contents. Discovery and documentation is critical and a lot can be learned of a new data set through basic data profiling. This Python package reads data from a file, directory of files, or a Pandas dataframe and creates a standardized output (Excel workbook) that provides insights on each file's contents. The output can provide any data architect, data engineer, business analyst or data analyst with the information they need to make effective and efficient early decisions about the value of and potential issues in a new data set.\n\nThe file processor is able to read any text or Excel file that can be opened with Pandas. Any argument that can be passed to pandas.read_csv() or pandas.read_excel() is valid and used to direct the file processor.\n\n[DataDictionary Class and Methods](#datadictionary)\n\n## Get Started\n\n[Install DataDictionary](#installation) \n\n[Sample Code](#using-datadictionary)\n\n## Components of the Output File\nThe output is an XLSX Microsoft Excel workbook with information spread across mutliple worksheets. Each bullet corresponds to a worksheet in the output file.\n\n- [Data Types](#data-types)\n- [Text Value Distribution](#text-value-distribution)\n- [Numeric Value Distribution](#numeric-value-distribution)\n- [Potential Primary Keys](#potential-primary-keys)\n- [Sample Data](#sample-data)\n\n### Data Types\nThis worksheet is a great starting point for a data catalogue or data dictionary. At a glance, this report provides:\n\n- The original field name\n  - Presented as the name appears in the sample file\n- A 'clean' version of the field name\n  - These values are optimized for legibility and compatibility with RDBMS standards (See [Column Name Cleanup](#column-name-cleanup))\n- The presumed data type\n  - Data types are simplified into text, integer, decimal, or N/A (See [Data Type Detection](#data-type-detection))\n- The minimum and maximum lengths for text fields\n- The minimum and maximum values for integer fields\n- The precision and scale for decimal fields\n- Potential ID flag\n  - Based on the contents of the field name, make a guess to whether or not it's an ID field\n- Potential PII flag\n  - First, look at the contents of the field name, make a guess to whether or not it contains PII\n  - Second, look at the values in the field and make a guess to whether or not the contents contain PII\n    - If even a single value in a field is presumed to be PII, the entire field is flagged \n- Nullable flag\n  - If one or more values are found to be NULL, set to 1 or True\n\n#### Column Name Cleanup\nThe cleansing process uses two steps:\n1. Remove unwanted characters\n2. Replace unwanted characters\n\nWhen processing a dataframe, file, or directory of files, the output of both steps can be controlled through parameters.\n- colname_chars_remove\n  - Full customization\n- colname_chars_replace_custom\n  - Partial customization (see Table 1) \n\nTarget Character(s) | Replacement Character(s) | Affected by Custom Parameter \n--------------------|--------------------------|------------------------------\n\\\\/()[]{},.!?:;\\-^~`\\\\s+ | _ | Yes, characters can be added\n\\# | num | Yes, replacement can be changed\n$ | usd | Yes, replacement can be changed\n% | pct | Yes, replacement can be changed\n& | and | Yes, replacement can be changed\n\\| | or | Yes, replacement can be changed\n@ | at | Yes, replacement can be changed\n\\+ | plus | Yes, replacement can be changed\n\\* | times | Yes, replacement can be changed\n= | equals | Yes, replacement can be changed\n\\< | lt | Yes, replacement can be changed\n\\> | gt | Yes, replacement can be changed\nCustom | Custom | Yes, target and replacement characters can be added\n\nTable 1\n\n#### Data Type Detection\nThe best source of information for data types from a data source is a physical data model or the DDL used to create the source table. More often than not, that information is either not available or takes a prohibitively long amount of time to obtain from the data owner. This feature is meant to be a helpful suggestion based on the observed records in the sample data. Data types are simplified to avoid prescriptive output (see Table 2).\n\nData Types in Output |\n---------------------|\ndate/datetime |\ndecimal |\ninteger |\ndecimal or integer** |\ntext |\nN/A* |\n\nTable 2\n\n\\* N/A is assigned to fields that contain only NULL values, no data type can be suggested\\\n\\*\\* 'decimal or integer' is assigned to fields that may contain integer values in the source file but while processing that file NULL values were detected which Pandas converts to the float data type. Therefore with ambiguous data a loose suggestion is made.\n\n### Text Value Distribution\nFor each text field, a distribution is appended to this worksheet with the count of NULL values appearing at the top.\n\n### Numeric Value Distribution\nThe output on this worksheet is from the Pandas DataFrame.describe() method. It shows the distribution of numeric fields and **excludes** potential ID fields.\n\n### Potential Primary Keys\nThis is one of the less developed features, however can be useful to highlight fields with heterogenous data that may indicate they may be the natural key or part of the natural key for the given sample data.\n\n### Sample Data\nThis optional sheet takes a number of records from a file and writes them to Sample_Data.\n\n## Get Started\n### Installation\n```python\npip install datadictionary\n```\n\n### Using DataDictionary\n```python\nimport datadictionary\nprofiler = datadictionary.ProfileData()\n\n# profile a single file\nprofiler.process_file('./tests/test1.csv', dest_dir='./tests/', colname_chars_remove=r'aeiou')\n\n# profile a directory of files\nprofiler.process_directory('./tests/', dest_dir='./tests/', contain='test1', not_contain='test2')\n\n# profile a Pandas DataFrame\nprofiler.process_dataframe(dest_dir='./tests/', dataframe=sample_df, dataframe_name='sample_df')\n```\n## DataDictionary\nclass datadictionary.**ProfileData**()\\\n**process_file**(file_path=*filepath*, dest_dir=*filepath*, **kwargs)\\\nfile_path: path to the file to be profiled\\\ndest_dir: directory for profile to be written\\\n**kwargs includes:\n- colname_chars_replace_underscore: string of invalid characters to be replaced with an underscore\n- colname_chars_replace_custom: dict of characters and their replacement value\n- colname_chars_remove: string of characters to be removed\n- sample_data: None or integer > 0, default 500; number of records to include in a sample_data sheet in output file. If None is passed, the sheet is omitted from the output file.\n- parameter: interpret_date_timestamp - boolean default False, attempt to convert string fields to date or timestamp \n- parameter: interpret_date_timestamp_errors - text default \"raise\", options are \"raise\", \"ignore\", \"coerce\". \"raise\" will raise errors on values that cannot be converted, \"ignore\" will not raise errors and returns the input data, \"coerce\" will return NaT values when they cannot be converted.\n- pandas.read_csv() or pandas.read_excel() arguments\n\n**process_directory**(source_dir=*filepath*, dest_dir=*filepath*, **kwargs)\\\nsource_dir: path to the file to be profiled\\\ndest_dir: directory for profile to be written\\\n**kwargs includes:\n- colname_chars_replace_underscore: string of invalid characters to be replaced with an underscore\n- colname_chars_replace_custom: dict of characters and their replacement value\n- colname_chars_remove: string of characters to be removed\n- sample_data: None or integer > 0, default 500; number of records to include in a sample_data sheet in output file. If None is passed, the sheet is omitted from the output file.\n- parameter: interpret_date_timestamp - boolean default False, attempt to convert string fields to date or timestamp \n- parameter: interpret_date_timestamp_errors - text default \"raise\", options are \"raise\", \"ignore\", \"coerce\". \"raise\" will raise errors on values that cannot be converted, \"ignore\" will not raise errors and returns the input data, \"coerce\" will return NaT values when they cannot be converted.\n- pandas.read_csv() or pandas.read_excel() arguments\n\n**process_dataframe**(dest_dir=*filepath*, dataframe=*pandas DataFrame*, dataframe_name=*string*, **kwargs)\\\ndest_dir: directory for profile to be written\\\n**kwargs includes:\n- colname_chars_replace_underscore: string of invalid characters to be replaced with an underscore\n- colname_chars_replace_custom: dict of characters and their replacement value\n- colname_chars_remove: string of characters to be removed\n- sample_data: None or integer > 0, default 500; number of records to include in a sample_data sheet in output file. If None is passed, the sheet is omitted from the output file.\n- parameter: interpret_date_timestamp - boolean default False, attempt to convert string fields to date or timestamp \n- parameter: interpret_date_timestamp_errors - text default \"raise\", options are \"raise\", \"ignore\", \"coerce\". \"raise\" will raise errors on values that cannot be converted, \"ignore\" will not raise errors and returns the input data, \"coerce\" will return NaT values when they cannot be converted.\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/jasonatwood/DataDictionary",
    "keywords": "data dictionary,data profile,data profiler,data,profile,profiler,dictionary",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "datadictionary",
    "package_url": "https://pypi.org/project/datadictionary/",
    "platform": "",
    "project_url": "https://pypi.org/project/datadictionary/",
    "project_urls": {
      "Bug Tracker": "https://github.com/jasonatwood/DataDictionary/issues",
      "Homepage": "https://github.com/jasonatwood/DataDictionary"
    },
    "release_url": "https://pypi.org/project/datadictionary/0.0.2/",
    "requires_dist": [
      "pandas (>=1.0.0)",
      "openpyxl"
    ],
    "requires_python": ">=3.6",
    "summary": "A package for profiling data and creating data dictionaries.",
    "version": "0.0.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12931043,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "46145d74b60c769048a5dbc8be395bb3ad00130d56c5fdc8e3a4c569d19b8a31",
          "md5": "aa36c3e28b16416effb49c445393b3d6",
          "sha256": "8b2d1e488fe06f02498bc61db824a1d8661afab52ff1bf5039c14dccde4693ad"
        },
        "downloads": -1,
        "filename": "datadictionary-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "aa36c3e28b16416effb49c445393b3d6",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 23266,
        "upload_time": "2022-02-13T03:03:10",
        "upload_time_iso_8601": "2022-02-13T03:03:10.620933Z",
        "url": "https://files.pythonhosted.org/packages/46/14/5d74b60c769048a5dbc8be395bb3ad00130d56c5fdc8e3a4c569d19b8a31/datadictionary-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "67b10068a65de3a730f9219cf334d6d3c4f38f89b46338b0a1fcdbffeb330835",
          "md5": "5e26a158213e773adcf252dd9baf119f",
          "sha256": "91417c21990d8e84447b20f7a1b79771b34cf8ad9da9da7cf89cc25c9aadcbe3"
        },
        "downloads": -1,
        "filename": "datadictionary-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "5e26a158213e773adcf252dd9baf119f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 22165,
        "upload_time": "2022-02-13T03:03:11",
        "upload_time_iso_8601": "2022-02-13T03:03:11.726965Z",
        "url": "https://files.pythonhosted.org/packages/67/b1/0068a65de3a730f9219cf334d6d3c4f38f89b46338b0a1fcdbffeb330835/datadictionary-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.1.post1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c6927d362e453b158790a5e02cfa4bfca8d0c4fb9dd97cbae3b56c9511637773",
          "md5": "c0249e2d37b6f08ccf0b49a7d26b60d1",
          "sha256": "e7955d9106afc6e33b2d92780a1c4b958a0eb95a620e356a042fb300cabf86d1"
        },
        "downloads": -1,
        "filename": "datadictionary-0.0.1.post1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "c0249e2d37b6f08ccf0b49a7d26b60d1",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 23367,
        "upload_time": "2022-02-16T01:35:18",
        "upload_time_iso_8601": "2022-02-16T01:35:18.248894Z",
        "url": "https://files.pythonhosted.org/packages/c6/92/7d362e453b158790a5e02cfa4bfca8d0c4fb9dd97cbae3b56c9511637773/datadictionary-0.0.1.post1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f856d39b279003d842fe6083ec874765c4c186c85e2179049815b1a41cd6b733",
          "md5": "80efca38dc230a464c8653427da7f1a8",
          "sha256": "c7af0df48fba86e2af4876faeaea4c13b778217c0913fe4e7c69f53ae5accbd2"
        },
        "downloads": -1,
        "filename": "datadictionary-0.0.1.post1.tar.gz",
        "has_sig": false,
        "md5_digest": "80efca38dc230a464c8653427da7f1a8",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 22239,
        "upload_time": "2022-02-16T01:35:19",
        "upload_time_iso_8601": "2022-02-16T01:35:19.317324Z",
        "url": "https://files.pythonhosted.org/packages/f8/56/d39b279003d842fe6083ec874765c4c186c85e2179049815b1a41cd6b733/datadictionary-0.0.1.post1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "47d2f5b6c343a7ff03ecb3602133b44661776bc42277fc65a40b72c14d8a4e5d",
          "md5": "82fb5cc8e33f4444ad4ea116deb71a76",
          "sha256": "a0fa8c5e83164269864701ee2846c09e1ccc459b074a3be84ec498087a1375ea"
        },
        "downloads": -1,
        "filename": "datadictionary-0.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "82fb5cc8e33f4444ad4ea116deb71a76",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 24190,
        "upload_time": "2022-02-18T06:42:08",
        "upload_time_iso_8601": "2022-02-18T06:42:08.417365Z",
        "url": "https://files.pythonhosted.org/packages/47/d2/f5b6c343a7ff03ecb3602133b44661776bc42277fc65a40b72c14d8a4e5d/datadictionary-0.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "287446cce042f87b40b3fa5add4a3dcc55f833fae770ecfbae02e371051ea49c",
          "md5": "74ed49b068e4bf378e3e7779f3a3f29c",
          "sha256": "abb67387f41421090e522822414335d75c58f2216d98a4eba95a5a51235d8881"
        },
        "downloads": -1,
        "filename": "datadictionary-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "74ed49b068e4bf378e3e7779f3a3f29c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 22839,
        "upload_time": "2022-02-18T06:42:10",
        "upload_time_iso_8601": "2022-02-18T06:42:10.532884Z",
        "url": "https://files.pythonhosted.org/packages/28/74/46cce042f87b40b3fa5add4a3dcc55f833fae770ecfbae02e371051ea49c/datadictionary-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "47d2f5b6c343a7ff03ecb3602133b44661776bc42277fc65a40b72c14d8a4e5d",
        "md5": "82fb5cc8e33f4444ad4ea116deb71a76",
        "sha256": "a0fa8c5e83164269864701ee2846c09e1ccc459b074a3be84ec498087a1375ea"
      },
      "downloads": -1,
      "filename": "datadictionary-0.0.2-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "82fb5cc8e33f4444ad4ea116deb71a76",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 24190,
      "upload_time": "2022-02-18T06:42:08",
      "upload_time_iso_8601": "2022-02-18T06:42:08.417365Z",
      "url": "https://files.pythonhosted.org/packages/47/d2/f5b6c343a7ff03ecb3602133b44661776bc42277fc65a40b72c14d8a4e5d/datadictionary-0.0.2-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "287446cce042f87b40b3fa5add4a3dcc55f833fae770ecfbae02e371051ea49c",
        "md5": "74ed49b068e4bf378e3e7779f3a3f29c",
        "sha256": "abb67387f41421090e522822414335d75c58f2216d98a4eba95a5a51235d8881"
      },
      "downloads": -1,
      "filename": "datadictionary-0.0.2.tar.gz",
      "has_sig": false,
      "md5_digest": "74ed49b068e4bf378e3e7779f3a3f29c",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 22839,
      "upload_time": "2022-02-18T06:42:10",
      "upload_time_iso_8601": "2022-02-18T06:42:10.532884Z",
      "url": "https://files.pythonhosted.org/packages/28/74/46cce042f87b40b3fa5add4a3dcc55f833fae770ecfbae02e371051ea49c/datadictionary-0.0.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}