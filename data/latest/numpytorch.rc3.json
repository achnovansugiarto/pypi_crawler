{
  "info": {
    "author": "kiui",
    "author_email": "ashawkey1999@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Science/Research",
      "Programming Language :: Python :: 3"
    ],
    "description": "# numpytorch\n\n\n\nMonkey-patched `numpy` with `pytorch` syntax.\n\nIf you are also tired of `dim, axis, keepdim, keepdims, cat, concatenate` , or wasted enough time debugging `repeat(), meshgrid()`, this package provides a dirty solution:\n\n```python\n# Just replace the import\n\n#import numpy as np\nimport numpytorch as np\n\n# use the torch syntax:\nx = np.randn(2, 3)\nx = x.permute(1, 0).unsqueeze(-1)\nx = x.add(1).abs().sin()\n\n# while it won't break the original numpy syntax:\nx = np.random.rand(2, 3)\nx = np.expand_dims(x.transpose(1, 0), -1)\nx = np.sin(np.abs(x + 1))\n```\n\n\n\n### Features\n\n* fully compatible with pure `numpy` code.\n\n* patched most `pytorch` functions and `Tensor` methods into `numpy` and `ndarray`.\n\n\n\n### Install\n\nOnly `Cpython` is supported since we use [`forbiddenfruit`](https://github.com/clarete/forbiddenfruit)  to extend the built-in `np.ndarray`.\n\n```bash\npip install numpytorch\n```\n\n\n### Documentations\n\nSince there are conflicted names in `numpy` and `pytorch`, such as `np.stack() & torch.stack()`, `ndarray.view() & Tensor.view()`, two modes are provided to handle these conflicts: `compatible` or `override`.\n\nIn the default `compatible` mode, all of the names in `numpy` are kept unchanged:\n\n* If the name is conflicted, we add `torch_{name}` to distinguish from the original `numpy` method. \n\n  ```python\n  np.torch_stack()\n  arr.torch_view()\n  np.stack() # original numpy stack()\n  arr.view() # original numpy.ndarray view()\n  ```\n\n* If the name is not conflicted, we add both `torch_{name}` and `{name}`.\n\n  ```python\n  np.torch_randn()\n  arr.torch_permute()\n  np.randn() # alias of torch_randn()\n  arr.permute() # alias of torch_permute()\n  ```\n\nIn the `override` mode, we instead keep the `torch` functions unchanged and rename `numpy` functions. `{name} & torch_{name}` are always added (except some special functions like `view(), size`), and the conflicted `numpy` versions are renamed to `numpy_{name}`. However, this is only experimental and may lead to unexpected bugs since it may break some `numpy` functions. Use at your own risk!\n\n```python\n# 'compatible' mode is invoked by default at import\nimport numpytorch as np\n\n# invoke override mode \nnp.set_patch_mode('override')\n\n# invoke compatible mode\nnp.set_patch_mode('compatible')\n\n# remove all patches\nnp.set_patch_mode('none')\n\n# list current patches\nnp.list_patches()\n```\n\nAll of the patched functions and methods are listed below. Unless specifically mentioned, they should behave similarly as the `torch` counterparts.\n\n#### ============== np.* ==============\n**torch_cat** `(tensors: Sequence[numpy.ndarray], dim: int = 0, out: Union[numpy.ndarray, NoneType] = None)`\n\n**cat** `(tensors: Sequence[numpy.ndarray], dim: int = 0, out: Union[numpy.ndarray, NoneType] = None)`\n\n**torch_chunk** `(input: numpy.ndarray, chunks: int, dim: int = 0)`\n\n**chunk** `(input: numpy.ndarray, chunks: int, dim: int = 0)`\n\n**torch_gather** `(input: numpy.ndarray, dim: int, index: numpy.ndarray, out: Union[numpy.ndarray, NoneType] = None)`\n\n**gather** `(input: numpy.ndarray, dim: int, index: numpy.ndarray, out: Union[numpy.ndarray, NoneType] = None)`\n\n**torch_index_select** `(input: numpy.ndarray, dim: int, index: numpy.ndarray, out: Union[numpy.ndarray, NoneType] = None)`\n\n**index_select** `(input: numpy.ndarray, dim: int, index: numpy.ndarray, out: Union[numpy.ndarray, NoneType] = None)`\n\n**torch_masked_select** `(input: numpy.ndarray, mask: numpy.ndarray, out: Union[numpy.ndarray, NoneType] = None)`\n\n**masked_select** `(input: numpy.ndarray, mask: numpy.ndarray, out: Union[numpy.ndarray, NoneType] = None)`\n\n**torch_movedim** `(input: numpy.ndarray, source: Union[int, Tuple[int]], destination: Union[int, Tuple[int]])`\n\n**movedim** `(input: numpy.ndarray, source: Union[int, Tuple[int]], destination: Union[int, Tuple[int]])`\n\n**torch_swapdims** `(input: numpy.ndarray, dim0: int, dim1: int)`\n\n**swapdims** `(input: numpy.ndarray, dim0: int, dim1: int)`\n\n**torch_narrow** `(input: numpy.ndarray, dim: int, start: int, length: int)`\n\n**narrow** `(input: numpy.ndarray, dim: int, start: int, length: int)`\n\n**torch_nonzero** `(input: numpy.ndarray, as_tuple: bool = False)`\n\n**torch_scatter** `(input: numpy.ndarray, dim: int, index: numpy.ndarray, src: numpy.ndarray, reduce: Union[str, NoneType] = None)`\n\n**scatter** `(input: numpy.ndarray, dim: int, index: numpy.ndarray, src: numpy.ndarray, reduce: Union[str, NoneType] = None)`\n\n**torch_scatter_add** `(input: numpy.ndarray, dim: int, index: numpy.ndarray, src: numpy.ndarray)`\n\n**scatter_add** `(input: numpy.ndarray, dim: int, index: numpy.ndarray, src: numpy.ndarray)`\n\n**torch_split** `(input: numpy.ndarray, split_size_or_sections: Union[int, Sequence[int]], dim: int = 0)`\n\n**torch_squeeze** `(input: numpy.ndarray, dim: Union[int, NoneType] = None)`\n\n**torch_stack** `(input: Sequence[numpy.ndarray], dim: int = 0, out: Union[numpy.ndarray, NoneType] = None)`\n\n**torch_unsqueeze** `(input: numpy.ndarray, dim: int)`\n\n**unsqueeze** `(input: numpy.ndarray, dim: int)`\n\n**torch_unbind** `(input: numpy.ndarray, dim: int = 0)`\n\n**unbind** `(input: numpy.ndarray, dim: int = 0)`\n\n**torch_meshgrid** `(*xi: numpy.ndarray)`\n\n**torch_clone** `(input: numpy.ndarray)`\n\n**clone** `(input: numpy.ndarray)`\n\n**torch_is_contiguous** `(input: numpy.ndarray)`\n\n**is_contiguous** `(input: numpy.ndarray)`\n\n**torch_contiguous** `(input: numpy.ndarray)`\n\n**contiguous** `(input: numpy.ndarray)`\n\n**torch_repeat** `(input: numpy.ndarray, *sizes: int)`\n\n**torch_repeat_interleave** `(input: numpy.ndarray, repeats: Union[int, numpy.ndarray], dim: Union[int, NoneType] = None)`\n\n**repeat_interleave** `(input: numpy.ndarray, repeats: Union[int, numpy.ndarray], dim: Union[int, NoneType] = None)`\n\n**torch_permute** `(input: numpy.ndarray, *axes: int)`\n\n**permute** `(input: numpy.ndarray, *axes: int)`\n\n**torch_view** `(input: numpy.ndarray, *sizes: int)`\n\n**view** `(input: numpy.ndarray, *sizes: int)`\n\n**torch_view_as** `(input: numpy.ndarray, other: numpy.ndarray)`\n\n**view_as** `(input: numpy.ndarray, other: numpy.ndarray)`\n\n**torch_expand** `(input: numpy.ndarray, *sizes: int)`\n\nNote: the output is read-only since we use `np.broadcast_to` to return a view of the input, which different from the original behavior of `torch.expand()`.\n\n**expand** `(input: numpy.ndarray, *sizes: int)`\n\n**torch_expand_as** `(input: numpy.ndarray, other: numpy.ndarray)`\n\nNote: the output is read-only.\n\n**expand_as** `(input: numpy.ndarray, other: numpy.ndarray)`\n\n**torch_t** `(input: numpy.ndarray)`\n\n**t** `(input: numpy.ndarray)`\n\n**torch_seed** `()`\n\n**seed** `()`\n\n**torch_manual_seed** `(seed: int)`\n\n**manual_seed** `(seed: int)`\n\n**torch_rand** `(*size: int, out: Union[numpy.ndarray, NoneType] = None)`\n\n**rand** `(*size: int, out: Union[numpy.ndarray, NoneType] = None)`\n\n**torch_rand_like** `(input: numpy.ndarray)`\n\n**rand_like** `(input: numpy.ndarray)`\n\n**torch_randint** `(low: int, high: Union[int, NoneType] = None, size: Union[Sequence[int], NoneType] = None, out: Union[numpy.ndarray, NoneType] = None)`\n\n**randint** `(low: int, high: Union[int, NoneType] = None, size: Union[Sequence[int], NoneType] = None, out: Union[numpy.ndarray, NoneType] = None)`\n\n**torch_randint_like** `(input: numpy.ndarray, low: int, high: Union[int, NoneType] = None)`\n\n**randint_like** `(input: numpy.ndarray, low: int, high: Union[int, NoneType] = None)`\n\n**torch_randn** `(*size: int, out: Union[numpy.ndarray, NoneType] = None)`\n\n**randn** `(*size: int, out: Union[numpy.ndarray, NoneType] = None)`\n\n**torch_randn_like** `(input: numpy.ndarray)`\n\n**randn_like** `(input: numpy.ndarray)`\n\n**torch_randperm** `(n: int, out: Union[numpy.ndarray, NoneType] = None)`\n\n**randperm** `(n: int, out: Union[numpy.ndarray, NoneType] = None)`\n\n**torch_clamp** `(input: numpy.ndarray, min: Union[numbers.Number, numpy.ndarray, NoneType] = None, max: Union[numbers.Number, numpy.ndarray, NoneType] = None)`\n\n**clamp** `(input: numpy.ndarray, min: Union[numbers.Number, numpy.ndarray, NoneType] = None, max: Union[numbers.Number, numpy.ndarray, NoneType] = None)`\n\n**torch_max** `(input: numpy.ndarray, dim: Union[int, numpy.ndarray, NoneType] = None, keepdim: bool = False, out: Union[numpy.ndarray, NoneType] = None)`\n\n**max** `(input: numpy.ndarray, dim: Union[int, numpy.ndarray, NoneType] = None, keepdim: bool = False, out: Union[numpy.ndarray, NoneType] = None)`\n\n**torch_min** `(input: numpy.ndarray, dim: Union[int, numpy.ndarray, NoneType] = None, keepdim: bool = False, out: Union[numpy.ndarray, NoneType] = None)`\n\n**min** `(input: numpy.ndarray, dim: Union[int, numpy.ndarray, NoneType] = None, keepdim: bool = False, out: Union[numpy.ndarray, NoneType] = None)`\n\n**torch_flatten** `(input: numpy.ndarray, start_dim: int = 0, end_dim: int = -1)`\n\n**flatten** `(input: numpy.ndarray, start_dim: int = 0, end_dim: int = -1)`\n\n#### ========== np.ndarray.* ==========\n**torch_dim** `attribute`\n**dim** `attribute`\n**torch_numel** `(self)`\n\n**numel** `(self)`\n\n**torch_index_select** `(input: numpy.ndarray, dim: int, index: numpy.ndarray, out: Union[numpy.ndarray, NoneType] = None)`\n\n**index_select** `(input: numpy.ndarray, dim: int, index: numpy.ndarray, out: Union[numpy.ndarray, NoneType] = None)`\n\n**torch_squeeze_** `(input: numpy.ndarray, dim: Union[int, NoneType] = None)`\n\n**squeeze_** `(input: numpy.ndarray, dim: Union[int, NoneType] = None)`\n\n**torch_unsqueeze** `(input: numpy.ndarray, dim: int)`\n\n**unsqueeze** `(input: numpy.ndarray, dim: int)`\n\n**torch_unsqueeze_** `(input: numpy.ndarray, dim: int)`\n\n**unsqueeze_** `(input: numpy.ndarray, dim: int)`\n\n**torch_is_contiguous** `(input: numpy.ndarray)`\n\n**is_contiguous** `(input: numpy.ndarray)`\n\n**torch_contiguous** `(input: numpy.ndarray)`\n\n**contiguous** `(input: numpy.ndarray)`\n\n**torch_clone** `(input: numpy.ndarray)`\n\n**clone** `(input: numpy.ndarray)`\n\n**torch_repeat** `(input: numpy.ndarray, *sizes: int)`\n\n**torch_repeat_interleave** `(input: numpy.ndarray, repeats: Union[int, numpy.ndarray], dim: Union[int, NoneType] = None)`\n\n**repeat_interleave** `(input: numpy.ndarray, repeats: Union[int, numpy.ndarray], dim: Union[int, NoneType] = None)`\n\n**torch_view** `(input: numpy.ndarray, *sizes: int)`\n\n**torch_permute** `(input: numpy.ndarray, *axes: int)`\n\n**permute** `(input: numpy.ndarray, *axes: int)`\n\n**torch_expand** `(input: numpy.ndarray, *sizes: int)`\n\n**expand** `(input: numpy.ndarray, *sizes: int)`\n\n**torch_expand_as** `(input: numpy.ndarray, other: numpy.ndarray)`\n\n**expand_as** `(input: numpy.ndarray, other: numpy.ndarray)`\n\n**torch_uniform_** `(input: numpy.ndarray, fro: int = 0, to: int = 1)`\n\n**uniform_** `(input: numpy.ndarray, fro: int = 0, to: int = 1)`\n\n**torch_normal_** `(input: numpy.ndarray, mean: int = 0, std: int = 1)`\n\n**normal_** `(input: numpy.ndarray, mean: int = 0, std: int = 1)`\n\n**torch_zero_** `(input: numpy.ndarray)`\n\n**zero_** `(input: numpy.ndarray)`\n\n**torch_clamp** `(input: numpy.ndarray, min: Union[numbers.Number, numpy.ndarray, NoneType] = None, max: Union[numbers.Number, numpy.ndarray, NoneType] = None)`\n\n**clamp** `(input: numpy.ndarray, min: Union[numbers.Number, numpy.ndarray, NoneType] = None, max: Union[numbers.Number, numpy.ndarray, NoneType] = None)`\n\n**torch_clamp_** `(input: numpy.ndarray, min: Union[numbers.Number, numpy.ndarray, NoneType] = None, max: Union[numbers.Number, numpy.ndarray, NoneType] = None)`\n\n**clamp_** `(input: numpy.ndarray, min: Union[numbers.Number, numpy.ndarray, NoneType] = None, max: Union[numbers.Number, numpy.ndarray, NoneType] = None)`\n\n**torch_clip_** `(input: numpy.ndarray, min: Union[numbers.Number, numpy.ndarray, NoneType] = None, max: Union[numbers.Number, numpy.ndarray, NoneType] = None)`\n\n**clip_** `(input: numpy.ndarray, min: Union[numbers.Number, numpy.ndarray, NoneType] = None, max: Union[numbers.Number, numpy.ndarray, NoneType] = None)`\n\n**torch_flatten** `(input: numpy.ndarray, start_dim: int = 0, end_dim: int = -1)`\n\n**torch_max** `(input: numpy.ndarray, dim: Union[int, numpy.ndarray, NoneType] = None, keepdim: bool = False, out: Union[numpy.ndarray, NoneType] = None)`\n\n**torch_min** `(input: numpy.ndarray, dim: Union[int, numpy.ndarray, NoneType] = None, keepdim: bool = False, out: Union[numpy.ndarray, NoneType] = None)`\n\n**torch_amax** `(a, axis=None, out=None, keepdims=<no value>, initial=<no value>, where=<no value>)`\n\n**amax** `(a, axis=None, out=None, keepdims=<no value>, initial=<no value>, where=<no value>)`\n\n**torch_amin** `(a, axis=None, out=None, keepdims=<no value>, initial=<no value>, where=<no value>)`\n\n**amin** `(a, axis=None, out=None, keepdims=<no value>, initial=<no value>, where=<no value>)`\n\n**torch_half** `(self)`\n\n**half** `(self)`\n\n**torch_float** `(self)`\n\n**float** `(self)`\n\n**torch_double** `(self)`\n\n**double** `(self)`\n\n**torch_short** `(self)`\n\n**short** `(self)`\n\n**torch_int** `(self)`\n\n**int** `(self)`\n\n**torch_long** `(self)`\n\n**long** `(self)`\n\n**torch_bool** `(self)`\n\n**bool** `(self)`\n\n**torch_add** `(self, other)`\n\n**add** `(self, other)`\n\n**torch_add_** `(self, other)`\n\n**add_** `(self, other)`\n\n**torch_subtract** `(self, other)`\n\n**subtract** `(self, other)`\n\n**torch_subtract_** `(self, other)`\n\n**subtract_** `(self, other)`\n\n**torch_multiply** `(self, other)`\n\n**multiply** `(self, other)`\n\n**torch_multiply_** `(self, other)`\n\n**multiply_** `(self, other)`\n\n**torch_matmul** `(self, other)`\n\n**matmul** `(self, other)`\n\n**torch_matmul_** `(self, other)`\n\n**matmul_** `(self, other)`\n\n**torch_divide** `(self, other)`\n\n**divide** `(self, other)`\n\n**torch_divide_** `(self, other)`\n\n**divide_** `(self, other)`\n\n**torch_true_divide** `(self, other)`\n\n**true_divide** `(self, other)`\n\n**torch_true_divide_** `(self, other)`\n\n**true_divide_** `(self, other)`\n\n**torch_floor_divide** `(self, other)`\n\n**floor_divide** `(self, other)`\n\n**torch_floor_divide_** `(self, other)`\n\n**floor_divide_** `(self, other)`\n\n**torch_negative** `(self)`\n\n**negative** `(self)`\n\n**torch_negative_** `(self)`\n\n**negative_** `(self)`\n\n**torch_positive** `(self)`\n\n**positive** `(self)`\n\n**torch_positive_** `(self)`\n\n**positive_** `(self)`\n\n**torch_power** `(self, other)`\n\n**power** `(self, other)`\n\n**torch_power_** `(self, other)`\n\n**power_** `(self, other)`\n\n**torch_float_power** `(self, other)`\n\n**float_power** `(self, other)`\n\n**torch_float_power_** `(self, other)`\n\n**float_power_** `(self, other)`\n\n**torch_remainder** `(self, other)`\n\n**remainder** `(self, other)`\n\n**torch_remainder_** `(self, other)`\n\n**remainder_** `(self, other)`\n\n**torch_mod** `(self, other)`\n\n**mod** `(self, other)`\n\n**torch_mod_** `(self, other)`\n\n**mod_** `(self, other)`\n\n**torch_fmod** `(self, other)`\n\n**fmod** `(self, other)`\n\n**torch_fmod_** `(self, other)`\n\n**fmod_** `(self, other)`\n\n**torch_divmod** `(self, other)`\n\n**divmod** `(self, other)`\n\n**torch_divmod_** `(self, other)`\n\n**divmod_** `(self, other)`\n\n**torch_absolute** `(self)`\n\n**absolute** `(self)`\n\n**torch_absolute_** `(self)`\n\n**absolute_** `(self)`\n\n**torch_abs** `(self)`\n\n**abs** `(self)`\n\n**torch_abs_** `(self)`\n\n**abs_** `(self)`\n\n**torch_fabs** `(self)`\n\n**fabs** `(self)`\n\n**torch_fabs_** `(self)`\n\n**fabs_** `(self)`\n\n**torch_sign** `(self)`\n\n**sign** `(self)`\n\n**torch_sign_** `(self)`\n\n**sign_** `(self)`\n\n**torch_rint** `(self)`\n\n**rint** `(self)`\n\n**torch_rint_** `(self)`\n\n**rint_** `(self)`\n\n**torch_conj** `(self)`\n\n**torch_conj_** `(self)`\n\n**conj_** `(self)`\n\n**torch_exp** `(self)`\n\n**exp** `(self)`\n\n**torch_exp_** `(self)`\n\n**exp_** `(self)`\n\n**torch_exp2** `(self)`\n\n**exp2** `(self)`\n\n**torch_exp2_** `(self)`\n\n**exp2_** `(self)`\n\n**torch_log** `(self)`\n\n**log** `(self)`\n\n**torch_log_** `(self)`\n\n**log_** `(self)`\n\n**torch_log2** `(self)`\n\n**log2** `(self)`\n\n**torch_log2_** `(self)`\n\n**log2_** `(self)`\n\n**torch_log10** `(self)`\n\n**log10** `(self)`\n\n**torch_log10_** `(self)`\n\n**log10_** `(self)`\n\n**torch_sqrt** `(self)`\n\n**sqrt** `(self)`\n\n**torch_sqrt_** `(self)`\n\n**sqrt_** `(self)`\n\n**torch_square** `(self)`\n\n**square** `(self)`\n\n**torch_square_** `(self)`\n\n**square_** `(self)`\n\n**torch_cbrt** `(self)`\n\n**cbrt** `(self)`\n\n**torch_cbrt_** `(self)`\n\n**cbrt_** `(self)`\n\n**torch_reciprocal** `(self)`\n\n**reciprocal** `(self)`\n\n**torch_reciprocal_** `(self)`\n\n**reciprocal_** `(self)`\n\n**torch_gcd** `(self, other)`\n\n**gcd** `(self, other)`\n\n**torch_gcd_** `(self, other)`\n\n**gcd_** `(self, other)`\n\n**torch_lcm** `(self, other)`\n\n**lcm** `(self, other)`\n\n**torch_lcm_** `(self, other)`\n\n**lcm_** `(self, other)`\n\n**torch_expm1** `(self)`\n\n**expm1** `(self)`\n\n**torch_expm1_** `(self)`\n\n**expm1_** `(self)`\n\n**torch_log1p** `(self)`\n\n**log1p** `(self)`\n\n**torch_log1p_** `(self)`\n\n**log1p_** `(self)`\n\n**torch_sin** `(self)`\n\n**sin** `(self)`\n\n**torch_sin_** `(self)`\n\n**sin_** `(self)`\n\n**torch_cos** `(self)`\n\n**cos** `(self)`\n\n**torch_cos_** `(self)`\n\n**cos_** `(self)`\n\n**torch_tan** `(self)`\n\n**tan** `(self)`\n\n**torch_tan_** `(self)`\n\n**tan_** `(self)`\n\n**torch_arcsin** `(self)`\n\n**arcsin** `(self)`\n\n**torch_arcsin_** `(self)`\n\n**arcsin_** `(self)`\n\n**torch_arccos** `(self)`\n\n**arccos** `(self)`\n\n**torch_arccos_** `(self)`\n\n**arccos_** `(self)`\n\n**torch_arctan** `(self)`\n\n**arctan** `(self)`\n\n**torch_arctan_** `(self)`\n\n**arctan_** `(self)`\n\n**torch_arctan2** `(self, other)`\n\n**arctan2** `(self, other)`\n\n**torch_arctan2_** `(self, other)`\n\n**arctan2_** `(self, other)`\n\n**torch_sinh** `(self)`\n\n**sinh** `(self)`\n\n**torch_sinh_** `(self)`\n\n**sinh_** `(self)`\n\n**torch_cosh** `(self)`\n\n**cosh** `(self)`\n\n**torch_cosh_** `(self)`\n\n**cosh_** `(self)`\n\n**torch_tanh** `(self)`\n\n**tanh** `(self)`\n\n**torch_tanh_** `(self)`\n\n**tanh_** `(self)`\n\n**torch_arcsinh** `(self)`\n\n**arcsinh** `(self)`\n\n**torch_arcsinh_** `(self)`\n\n**arcsinh_** `(self)`\n\n**torch_arccosh** `(self)`\n\n**arccosh** `(self)`\n\n**torch_arccosh_** `(self)`\n\n**arccosh_** `(self)`\n\n**torch_arctanh** `(self)`\n\n**arctanh** `(self)`\n\n**torch_arctanh_** `(self)`\n\n**arctanh_** `(self)`\n\n**torch_degrees** `(self)`\n\n**degrees** `(self)`\n\n**torch_degrees_** `(self)`\n\n**degrees_** `(self)`\n\n**torch_radians** `(self)`\n\n**radians** `(self)`\n\n**torch_radians_** `(self)`\n\n**radians_** `(self)`\n\n**torch_deg2rad** `(self)`\n\n**deg2rad** `(self)`\n\n**torch_deg2rad_** `(self)`\n\n**deg2rad_** `(self)`\n\n**torch_rad2deg** `(self)`\n\n**rad2deg** `(self)`\n\n**torch_rad2deg_** `(self)`\n\n**rad2deg_** `(self)`\n\n**torch_bitwise_and** `(self, other)`\n\n**bitwise_and** `(self, other)`\n\n**torch_bitwise_and_** `(self, other)`\n\n**bitwise_and_** `(self, other)`\n\n**torch_bitwise_or** `(self, other)`\n\n**bitwise_or** `(self, other)`\n\n**torch_bitwise_or_** `(self, other)`\n\n**bitwise_or_** `(self, other)`\n\n**torch_bitwise_xor** `(self, other)`\n\n**bitwise_xor** `(self, other)`\n\n**torch_bitwise_xor_** `(self, other)`\n\n**bitwise_xor_** `(self, other)`\n\n**torch_invert** `(self)`\n\n**invert** `(self)`\n\n**torch_invert_** `(self)`\n\n**invert_** `(self)`\n\n**torch_left_shift** `(self, other)`\n\n**left_shift** `(self, other)`\n\n**torch_left_shift_** `(self, other)`\n\n**left_shift_** `(self, other)`\n\n**torch_right_shift** `(self, other)`\n\n**right_shift** `(self, other)`\n\n**torch_right_shift_** `(self, other)`\n\n**right_shift_** `(self, other)`\n\n**torch_greater** `(self, other)`\n\n**greater** `(self, other)`\n\n**torch_greater_** `(self, other)`\n\n**greater_** `(self, other)`\n\n**torch_greater_equal** `(self, other)`\n\n**greater_equal** `(self, other)`\n\n**torch_greater_equal_** `(self, other)`\n\n**greater_equal_** `(self, other)`\n\n**torch_less** `(self, other)`\n\n**less** `(self, other)`\n\n**torch_less_** `(self, other)`\n\n**less_** `(self, other)`\n\n**torch_less_equal** `(self, other)`\n\n**less_equal** `(self, other)`\n\n**torch_less_equal_** `(self, other)`\n\n**less_equal_** `(self, other)`\n\n**torch_equal** `(self, other)`\n\n**equal** `(self, other)`\n\n**torch_equal_** `(self, other)`\n\n**equal_** `(self, other)`\n\n**torch_not_equal** `(self, other)`\n\n**not_equal** `(self, other)`\n\n**torch_not_equal_** `(self, other)`\n\n**not_equal_** `(self, other)`\n\n**torch_logical_and** `(self, other)`\n\n**logical_and** `(self, other)`\n\n**torch_logical_and_** `(self, other)`\n\n**logical_and_** `(self, other)`\n\n**torch_logical_or** `(self, other)`\n\n**logical_or** `(self, other)`\n\n**torch_logical_or_** `(self, other)`\n\n**logical_or_** `(self, other)`\n\n**torch_logical_not** `(self)`\n\n**logical_not** `(self)`\n\n**torch_logical_not_** `(self)`\n\n**logical_not_** `(self)`\n\n**torch_logical_xor** `(self, other)`\n\n**logical_xor** `(self, other)`\n\n**torch_logical_xor_** `(self, other)`\n\n**logical_xor_** `(self, other)`\n\n**torch_maximum** `(self, other)`\n\n**maximum** `(self, other)`\n\n**torch_maximum_** `(self, other)`\n\n**maximum_** `(self, other)`\n\n**torch_minimum** `(self, other)`\n\n**minimum** `(self, other)`\n\n**torch_minimum_** `(self, other)`\n\n**minimum_** `(self, other)`\n\n**torch_fmax** `(self, other)`\n\n**fmax** `(self, other)`\n\n**torch_fmax_** `(self, other)`\n\n**fmax_** `(self, other)`\n\n**torch_fmin** `(self, other)`\n\n**fmin** `(self, other)`\n\n**torch_fmin_** `(self, other)`\n\n**fmin_** `(self, other)`\n\n**torch_nextafter** `(self, other)`\n\n**nextafter** `(self, other)`\n\n**torch_nextafter_** `(self, other)`\n\n**nextafter_** `(self, other)`\n\n**torch_spacing** `(self)`\n\n**spacing** `(self)`\n\n**torch_spacing_** `(self)`\n\n**spacing_** `(self)`\n\n**torch_modf** `(self)`\n\n**modf** `(self)`\n\n**torch_modf_** `(self)`\n\n**modf_** `(self)`\n\n**torch_ldexp** `(self, other)`\n\n**ldexp** `(self, other)`\n\n**torch_ldexp_** `(self, other)`\n\n**ldexp_** `(self, other)`\n\n**torch_frexp** `(self)`\n\n**frexp** `(self)`\n\n**torch_frexp_** `(self)`\n\n**frexp_** `(self)`\n\n**torch_isfinite** `(self)`\n\n**isfinite** `(self)`\n\n**torch_isfinite_** `(self)`\n\n**isfinite_** `(self)`\n\n**torch_isinf** `(self)`\n\n**isinf** `(self)`\n\n**torch_isinf_** `(self)`\n\n**isinf_** `(self)`\n\n**torch_isnan** `(self)`\n\n**isnan** `(self)`\n\n**torch_isnan_** `(self)`\n\n**isnan_** `(self)`\n\n**torch_isnat** `(self)`\n\n**isnat** `(self)`\n\n**torch_isnat_** `(self)`\n\n**isnat_** `(self)`\n\n**torch_signbit** `(self)`\n\n**signbit** `(self)`\n\n**torch_signbit_** `(self)`\n\n**signbit_** `(self)`\n\n**torch_copysign** `(self, other)`\n\n**copysign** `(self, other)`\n\n**torch_copysign_** `(self, other)`\n\n**copysign_** `(self, other)`\n\n**torch_floor** `(self)`\n\n**floor** `(self)`\n\n**torch_floor_** `(self)`\n\n**floor_** `(self)`\n\n**torch_ceil** `(self)`\n\n**ceil** `(self)`\n\n**torch_ceil_** `(self)`\n\n**ceil_** `(self)`\n\n**torch_trunc** `(self)`\n\n**trunc** `(self)`\n\n**torch_trunc_** `(self)`\n\n**trunc_** `(self)`\n\n**torch_atan** `(self)`\n\n**atan** `(self)`\n\n**torch_atan_** `(self)`\n\n**atan_** `(self)`\n\n**torch_asin** `(self)`\n\n**asin** `(self)`\n\n**torch_asin_** `(self)`\n\n**asin_** `(self)`\n\n**torch_acos** `(self)`\n\n**acos** `(self)`\n\n**torch_acos_** `(self)`\n\n**acos_** `(self)`\n\n**torch_atan2** `(self, other)`\n\n**atan2** `(self, other)`\n\n**torch_atan2_** `(self, other)`\n\n**atan2_** `(self, other)`\n\n**torch_ge** `(self, other)`\n\n**ge** `(self, other)`\n\n**torch_ge_** `(self, other)`\n\n**ge_** `(self, other)`\n\n**torch_gt** `(self, other)`\n\n**gt** `(self, other)`\n\n**torch_gt_** `(self, other)`\n\n**gt_** `(self, other)`\n\n**torch_le** `(self, other)`\n\n**le** `(self, other)`\n\n**torch_le_** `(self, other)`\n\n**le_** `(self, other)`\n\n**torch_lt** `(self, other)`\n\n**lt** `(self, other)`\n\n**torch_lt_** `(self, other)`\n\n**lt_** `(self, other)`",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/ashawkey/numpytorch",
    "keywords": "deep learning,tensor manipulation,machine learning,scientific computations",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "numpytorch",
    "package_url": "https://pypi.org/project/numpytorch/",
    "platform": "",
    "project_url": "https://pypi.org/project/numpytorch/",
    "project_urls": {
      "Homepage": "https://github.com/ashawkey/numpytorch"
    },
    "release_url": "https://pypi.org/project/numpytorch/0.1.2/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "Monkey-patched numpy with pytorch syntax",
    "version": "0.1.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 11546342,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4ea92d922b333ded4aa7457ac6c4fd6769cf1b29c98a9aa26482388286d8cc43",
          "md5": "3fae0122a513fbddc99641440bda25c8",
          "sha256": "b789db521ce0f2348cbcfcc94a331960728977d06e7017a1b946541ebc7c18c1"
        },
        "downloads": -1,
        "filename": "numpytorch-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "3fae0122a513fbddc99641440bda25c8",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 14680,
        "upload_time": "2021-09-25T09:31:04",
        "upload_time_iso_8601": "2021-09-25T09:31:04.751816Z",
        "url": "https://files.pythonhosted.org/packages/4e/a9/2d922b333ded4aa7457ac6c4fd6769cf1b29c98a9aa26482388286d8cc43/numpytorch-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "65287718e9370dd501a47133eef9e1816bce0e82d0f9f081d6e1337ec9e97453",
          "md5": "2c5a94e5bd12dfc9c9502a924906362d",
          "sha256": "7154d2dacf06fffa7b8bcff53c06f9c0df4e10da9284b1ea67f5e013d90a506e"
        },
        "downloads": -1,
        "filename": "numpytorch-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "2c5a94e5bd12dfc9c9502a924906362d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 15935,
        "upload_time": "2021-09-25T09:44:42",
        "upload_time_iso_8601": "2021-09-25T09:44:42.344816Z",
        "url": "https://files.pythonhosted.org/packages/65/28/7718e9370dd501a47133eef9e1816bce0e82d0f9f081d6e1337ec9e97453/numpytorch-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6472af8742629ace27dfe9834007c83f4b3d7634ae24adb3501ccb0bf69335e8",
          "md5": "d694c9ea8205480532ad98418a080228",
          "sha256": "5dea482beb9a23d53738aff479cc9862eff5cc68d483342036d49f48ad57b388"
        },
        "downloads": -1,
        "filename": "numpytorch-0.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "d694c9ea8205480532ad98418a080228",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 15928,
        "upload_time": "2021-09-25T09:51:18",
        "upload_time_iso_8601": "2021-09-25T09:51:18.617839Z",
        "url": "https://files.pythonhosted.org/packages/64/72/af8742629ace27dfe9834007c83f4b3d7634ae24adb3501ccb0bf69335e8/numpytorch-0.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "6472af8742629ace27dfe9834007c83f4b3d7634ae24adb3501ccb0bf69335e8",
        "md5": "d694c9ea8205480532ad98418a080228",
        "sha256": "5dea482beb9a23d53738aff479cc9862eff5cc68d483342036d49f48ad57b388"
      },
      "downloads": -1,
      "filename": "numpytorch-0.1.2.tar.gz",
      "has_sig": false,
      "md5_digest": "d694c9ea8205480532ad98418a080228",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 15928,
      "upload_time": "2021-09-25T09:51:18",
      "upload_time_iso_8601": "2021-09-25T09:51:18.617839Z",
      "url": "https://files.pythonhosted.org/packages/64/72/af8742629ace27dfe9834007c83f4b3d7634ae24adb3501ccb0bf69335e8/numpytorch-0.1.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}