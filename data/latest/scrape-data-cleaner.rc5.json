{
  "info": {
    "author": "Alexander Njogu",
    "author_email": "Alexander@chekiprice.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Scrape Data Cleaner\n\nClean scraped data fields to recieve your disired text without unicodes,spaces and other unessesary quirks.\n\n# Installation\n\n`pip install scrape-data-cleaner`\n\n# Basic Usage\n```python\nfrom cleaner import string_cleaner,price_cleaner,remove_char\nprint(string_cleaner('Iphone 8   plus \\  '))\nprint(price_cleaner(remove_char('USD 100')))\n```\n\n# Modules\n\n### **string_cleaner** :\n\nCleans strings strings encode and re-encode them in ASCII\n\n### **string_cleaner_array :**\n\nTakes an array of strings encode and re-encode them in ASCII then return an array.\n\n### **string_cleaner_array_wine:**\n\nTakes an array of strings encode and re-encode them in ASCII then return an array however during cleaning does not force removing of spaces and tabs.\n\n### **price_cleaner:**\n\nPerforms string cleaning from `string_cleaner` then converts the response to `Integer`.\n\n### **get_price:**\n\nExtracts price from a rouge string then converts the response to `Integer`.\n\ni.e **string=\"\\a \\t rr$12.5\"** outputs `12`\n\n### **remove_special_char :**\n\nRemoves special characters from string i.e.` * - &` e.t.c.\n\n### **remove_char:**\n\nRemoves all characters and leaves out only integers.\n\n### **remove_char_special:**\n\nRemoves all characters and leaves out only integers but first checks for `.00 `and replaces that with nothing to avoid getting price with extra 00.\n\n### **cleanhtml:**\n\nExtracts text from HTML and returns a string.\n\n### **cleanhtml_array:**\n\nExtracts text from an array of HTML and returns an array of strings.\n\n### **cleanhtml_array2:**\n\nExtracts text from an array of HTML and returns an array of strings however does `string_cleaner` for each string.\n\n### **nbsp_replacer:**\n\nReplaces unicode `\\u00a0` with a space.\n\n### **ratings_extractor:**\n\nExtracts ratings from style for stars. Takes style of this format `width:80% `and converts that to a rating of 1 to 5.\n\n### **specs_table_gen:**\n\nTakes two arrays and combine them with **:** return one array.\n\n### **space_tabs_remover:**\n\nRemoves spaces and tabs i.e if there is `\\u,\\r ,\\n .` This is more aggressive.\n\n### **extract_list:**\n\nExtracts text in HTML list`li`from a HTML block. Takes raw HTML and returns an array of strings.\n\n### **gen_link2:**\n\nReceives two strings name of store and the link then creates a custom url \n\ni.e \n\n`gen_link2('amazon','https://amazon/product/iphone-7.html')`\n\n**Results:**` /amazon/iphone-7`\n\n### **simple_split:**\n\nReceives two strings name of store and the link then creates a custom url \n\ni.e \n\n`simple_split('amazon','/iphone-7/product')`\n\n**Results:**` /amazon/iphone-7__product`\n\n### **extract_from_ldjson:**\n\nExtract a value from ld/json. i.e` extract_from_ldjson(ld_json,'name')` will extract the name value in the ld/json.\n\n### **table_shaker:**\n\nOnly works if your using scrapy. Takes the HTML block with the table and an array of the types of data in table. i.e` table_shaker(response.css('table'),['td','td'])`.\n\n **Note:** Array can be `['th','td']`,`['th','th'] `depending on the table.\n\n### **get_description :**\n\nExtracts description from HTML and returns an array with dictionaries with keys of either text or title. Takes Raw HTML.\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "scrape-data-cleaner",
    "package_url": "https://pypi.org/project/scrape-data-cleaner/",
    "platform": null,
    "project_url": "https://pypi.org/project/scrape-data-cleaner/",
    "project_urls": {
      "Bug Tracker": "https://gitlab.com:xaander1/scraped-data-cleaner.git"
    },
    "release_url": "https://pypi.org/project/scrape-data-cleaner/0.0.23/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "A package for cleaning forms of scraped data and convert them to normal text.",
    "version": "0.0.23",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14322258,
  "releases": {
    "0.0.19": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "36f8c9e72cb5162e097cc12820bcc4fce7dd294926ccf1f7c9373600d07e7cf3",
          "md5": "42ab157690b433aa4262deb17e858497",
          "sha256": "9e84b312d71ed928a78d62ac59d5e5ad432e6b4c550de2664724fd4d9d0b5deb"
        },
        "downloads": -1,
        "filename": "scrape_data_cleaner-0.0.19-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "42ab157690b433aa4262deb17e858497",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 5183,
        "upload_time": "2021-08-22T12:39:39",
        "upload_time_iso_8601": "2021-08-22T12:39:39.177134Z",
        "url": "https://files.pythonhosted.org/packages/36/f8/c9e72cb5162e097cc12820bcc4fce7dd294926ccf1f7c9373600d07e7cf3/scrape_data_cleaner-0.0.19-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a15615a94122c5f705f30d867f4b83d60798d85a9a7043c2d59b854e7c4cc8d9",
          "md5": "75e7871d7ce2fac18604d4bbfc5ca412",
          "sha256": "f494fe6163e0dc66f83124c479fbff006341064c26fefa92c47bef5ddb29e5f0"
        },
        "downloads": -1,
        "filename": "scrape-data-cleaner-0.0.19.tar.gz",
        "has_sig": false,
        "md5_digest": "75e7871d7ce2fac18604d4bbfc5ca412",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 4693,
        "upload_time": "2021-08-22T12:39:40",
        "upload_time_iso_8601": "2021-08-22T12:39:40.071784Z",
        "url": "https://files.pythonhosted.org/packages/a1/56/15a94122c5f705f30d867f4b83d60798d85a9a7043c2d59b854e7c4cc8d9/scrape-data-cleaner-0.0.19.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.20": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9c746602f93b9c16502ed896512f7936770c159fb78ba869d2e6f8400aa80d68",
          "md5": "797d8b145fc695b21e6bcb1e5cab494c",
          "sha256": "e683b819afb816c0521738bfca36decdf8f79e6f60f5e2553ea65a0f37700d46"
        },
        "downloads": -1,
        "filename": "scrape_data_cleaner-0.0.20-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "797d8b145fc695b21e6bcb1e5cab494c",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 5279,
        "upload_time": "2021-08-22T15:25:41",
        "upload_time_iso_8601": "2021-08-22T15:25:41.411943Z",
        "url": "https://files.pythonhosted.org/packages/9c/74/6602f93b9c16502ed896512f7936770c159fb78ba869d2e6f8400aa80d68/scrape_data_cleaner-0.0.20-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fc2a1687b19ad214b7d6f1374696ace78573cc63eda0acde502b8b43473718fb",
          "md5": "9c4fdee7dfb0b72bc2264040d421e341",
          "sha256": "d642bf633be5f5339a935f046f3305689adb119c1b83f0bdb8fc02bc3a3f9741"
        },
        "downloads": -1,
        "filename": "scrape-data-cleaner-0.0.20.tar.gz",
        "has_sig": false,
        "md5_digest": "9c4fdee7dfb0b72bc2264040d421e341",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 4787,
        "upload_time": "2021-08-22T15:25:42",
        "upload_time_iso_8601": "2021-08-22T15:25:42.207575Z",
        "url": "https://files.pythonhosted.org/packages/fc/2a/1687b19ad214b7d6f1374696ace78573cc63eda0acde502b8b43473718fb/scrape-data-cleaner-0.0.20.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.21": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f240502565970b6574025423b820de07d4d2edff42f6c7c591007ad945fd7603",
          "md5": "0b5f96f12f5a8b481c116f1999129f3c",
          "sha256": "b893aced4260990551a5cbaa4b36d8724e04be16e0005819e16dcc531d514f37"
        },
        "downloads": -1,
        "filename": "scrape_data_cleaner-0.0.21-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0b5f96f12f5a8b481c116f1999129f3c",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 6171,
        "upload_time": "2021-08-22T17:54:14",
        "upload_time_iso_8601": "2021-08-22T17:54:14.120441Z",
        "url": "https://files.pythonhosted.org/packages/f2/40/502565970b6574025423b820de07d4d2edff42f6c7c591007ad945fd7603/scrape_data_cleaner-0.0.21-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6c0e43e31e97a5e7faa0e7da47443bab25ea12c75d9baaac1e3a363c9cab03ca",
          "md5": "693f11d58bce717ee0c3745ce7fda58d",
          "sha256": "95d90de07af7bad13dd1828e153f681d45f7c519770d25683dc4f9d105f981ea"
        },
        "downloads": -1,
        "filename": "scrape-data-cleaner-0.0.21.tar.gz",
        "has_sig": false,
        "md5_digest": "693f11d58bce717ee0c3745ce7fda58d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 5684,
        "upload_time": "2021-08-22T17:54:15",
        "upload_time_iso_8601": "2021-08-22T17:54:15.381949Z",
        "url": "https://files.pythonhosted.org/packages/6c/0e/43e31e97a5e7faa0e7da47443bab25ea12c75d9baaac1e3a363c9cab03ca/scrape-data-cleaner-0.0.21.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.22": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ffb8e4e8366c839c2b3f9e1e98888e85c2c2231d080cafa7b6b9c3e6987ef074",
          "md5": "1304a81b709fa51a4bc39c4bdba71167",
          "sha256": "64464d37fa45325ada31ef8e2d37c92ff0d61720e30bc2de9b458d877a2183bb"
        },
        "downloads": -1,
        "filename": "scrape_data_cleaner-0.0.22-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "1304a81b709fa51a4bc39c4bdba71167",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 6274,
        "upload_time": "2021-10-09T08:13:35",
        "upload_time_iso_8601": "2021-10-09T08:13:35.008947Z",
        "url": "https://files.pythonhosted.org/packages/ff/b8/e4e8366c839c2b3f9e1e98888e85c2c2231d080cafa7b6b9c3e6987ef074/scrape_data_cleaner-0.0.22-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b0ad5678cc75a393628c6ff25e0b0204bae7d751a93246754369191a9651ffe0",
          "md5": "46cd80903c14c04cd3774cbe44059bcb",
          "sha256": "fe8251627518e41eecfb068f872c2aa1c45ec54043c6da2e7ab78093f90ceca5"
        },
        "downloads": -1,
        "filename": "scrape-data-cleaner-0.0.22.tar.gz",
        "has_sig": false,
        "md5_digest": "46cd80903c14c04cd3774cbe44059bcb",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 5772,
        "upload_time": "2021-10-09T08:13:36",
        "upload_time_iso_8601": "2021-10-09T08:13:36.308098Z",
        "url": "https://files.pythonhosted.org/packages/b0/ad/5678cc75a393628c6ff25e0b0204bae7d751a93246754369191a9651ffe0/scrape-data-cleaner-0.0.22.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.23": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2607989451e5c3e635b13d7cd05aada5726d0e33ef3af299195df1d32982e737",
          "md5": "43703c5d9dc0d839f4d4c22d10cf23f1",
          "sha256": "7cba6f4ae51da4f774cc35ef33f63bf315d3df0ec390e59d1125f433be2b318a"
        },
        "downloads": -1,
        "filename": "scrape_data_cleaner-0.0.23-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "43703c5d9dc0d839f4d4c22d10cf23f1",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 6310,
        "upload_time": "2022-07-03T13:53:45",
        "upload_time_iso_8601": "2022-07-03T13:53:45.151766Z",
        "url": "https://files.pythonhosted.org/packages/26/07/989451e5c3e635b13d7cd05aada5726d0e33ef3af299195df1d32982e737/scrape_data_cleaner-0.0.23-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "db98d5af4e5675a312c1da33d12b0f6b7e8332e99344258a2fe6e42000803a28",
          "md5": "cd63fd5df17d2579a52fc34d9de8a1da",
          "sha256": "160e8a4ebeee876622adfbae19ea4cf14ab213f3e8cd0dd112041db4171505d8"
        },
        "downloads": -1,
        "filename": "scrape-data-cleaner-0.0.23.tar.gz",
        "has_sig": false,
        "md5_digest": "cd63fd5df17d2579a52fc34d9de8a1da",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 5797,
        "upload_time": "2022-07-03T13:53:46",
        "upload_time_iso_8601": "2022-07-03T13:53:46.819634Z",
        "url": "https://files.pythonhosted.org/packages/db/98/d5af4e5675a312c1da33d12b0f6b7e8332e99344258a2fe6e42000803a28/scrape-data-cleaner-0.0.23.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "2607989451e5c3e635b13d7cd05aada5726d0e33ef3af299195df1d32982e737",
        "md5": "43703c5d9dc0d839f4d4c22d10cf23f1",
        "sha256": "7cba6f4ae51da4f774cc35ef33f63bf315d3df0ec390e59d1125f433be2b318a"
      },
      "downloads": -1,
      "filename": "scrape_data_cleaner-0.0.23-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "43703c5d9dc0d839f4d4c22d10cf23f1",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 6310,
      "upload_time": "2022-07-03T13:53:45",
      "upload_time_iso_8601": "2022-07-03T13:53:45.151766Z",
      "url": "https://files.pythonhosted.org/packages/26/07/989451e5c3e635b13d7cd05aada5726d0e33ef3af299195df1d32982e737/scrape_data_cleaner-0.0.23-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "db98d5af4e5675a312c1da33d12b0f6b7e8332e99344258a2fe6e42000803a28",
        "md5": "cd63fd5df17d2579a52fc34d9de8a1da",
        "sha256": "160e8a4ebeee876622adfbae19ea4cf14ab213f3e8cd0dd112041db4171505d8"
      },
      "downloads": -1,
      "filename": "scrape-data-cleaner-0.0.23.tar.gz",
      "has_sig": false,
      "md5_digest": "cd63fd5df17d2579a52fc34d9de8a1da",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 5797,
      "upload_time": "2022-07-03T13:53:46",
      "upload_time_iso_8601": "2022-07-03T13:53:46.819634Z",
      "url": "https://files.pythonhosted.org/packages/db/98/d5af4e5675a312c1da33d12b0f6b7e8332e99344258a2fe6e42000803a28/scrape-data-cleaner-0.0.23.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}