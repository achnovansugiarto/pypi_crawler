{
  "info": {
    "author": "Porthos",
    "author_email": "etdds@protonmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Reddit Quote Bot\n\nReads all comments in selected subreddits and compares their comments to famous quotes. On a close match, replies with the full quote, crediting the original author.\n\n![Comment Demo](images/comment_demo.png?raw=true \"Example reply\")\n\nI'm live! Check out what I've been up to on [Reddit](https://www.reddit.com/user/redditQuoteBot/comments/).\n\n## Overview\n\nThe bot periodically requests comments from selected subreddits, sorted by newest submissions. Each comment, is compared for similarity to a dataset of [quotes](https://www.kaggle.com/datasets/abireltaief/english-quotes) using [spacy](https://spacy.io/). If a high similarity is detected, a reply is generated and posted as a response to the original comment.\n\n\n## Running a bot instance\n\n### Using Python\n\nThe package is available on [pypi](https://pypi.org/project/redditquotebot/), it can be installed with:\n\n```bash\npip install redditquotebot\n```\n\nA Spacy language model is also needed for natural language processing. Testing is conducted with `en-core-web-md`:\n```bash\npip install https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.4.1/en_core_web_md-3.4.1-py3-none-any.whl\n```\n\nGenerate the configuration and credential templates in the current directory (see reference below):\n```bash\nreddit_quote_bot.py -g\n```\n\nStart up the bot:\n```bash\nreddit_quote_bot.py\n```\n\n### Using Docker\n\nCurrently, the only option is to build the container from source. Eventually, this will be pushed to [Docker Hub](https://hub.docker.com/).\n\nClone this repository:\n\n```bash\ngit clone https://github.com/etdds/redditQuoteBot.git\ncd redditQuoteBot\n```\n\nBuild the docker container:\n```\nmake build-image\n# or\ndocker build -t etdds/reddit-quote-bot:latest .\n```\n\nStart up the bot. The configuration and credential templates are generated on the first run. Populate these files then restart the container.\n```\n# Initial run to generate configuration\ndocker run -v $(pwd):/home/app_user/run etdds/reddit-quote-bot\n\n# Run the container, detached, restarting unless stopped.\ndocker run --restart unless-stopped -d -v $(pwd):/home/app_user/run etdds/reddit-quote-bot\n```\n\nThe mounted directory is used to store the configuration files, credentials, comment and reply records and state.\n\n## Runtime file descriptions\n\nThe bot uses four files during runtime, these are created and stored in the directory from where the bot is started.\n\n### Configuration\n\nThe configuration file `configuration.json` is created the first time is run, and read once on startup. \n\n```json\n{\n  \"reddit\": {\n    \"subreddits\": [\n      \"test\"\n    ],\n    \"new_submissions_per_request\": 10,\n    \"max_comments_per_request\": 100,\n    \"minimum_comment_length\": 15\n  },\n  \"bot\": {\n    \"reply_to_comments\": true,\n    \"reply_threshold\": 0.99,\n    \"matched_quotes_to_log\": 3,\n    \"remove_own_comments\": true,\n    \"remove_comment_threshold\": -1\n  },\n  \"nlp\": {\n    \"match_store_threshold\": 0.97,\n    \"quote_comment_length_delta\": 0.7,\n    \"minimum_comment_sentence_word_length\": 5,\n    \"quote_length_bonus_coefficient\": 0.0008,\n    \"quote_length_bonus_start\": 6,\n    \"quote_length_bonus_end\": 10,\n    \"matched_sentence_coefficient\": 0.5,\n    \"discard_comments_with_author\": true\n  },\n  \"records\": {\n    \"maximum_comment_count\": 0,\n    \"maximum_match_count\": 100,\n    \"maximum_reply_count\": null\n  }\n}\n```\n| Section       | Subsection                            |    Description                                                                                            |\n| ------------- | -------------                         | -------------                                                                                             |\n|reddit         | subreddit                             |  List of subreddits from which comments are taken    |\n|               | new_submissions_per_request           |  The maximum number of submissions (posts) which are taken    |\n|               | max_comments_per_request              |  The maximum number comments which are queried per request.   |\n|               | minimum_comment_length                |  The minimum length of a comment which is stored. Shorter comments are discarded. |\n|bot            | reply_to_comments                     |  If set to true, replies are posted to reddit. If false, they are only logged in `records.json` |\n|               | reply_threshold                       |  The NLP score needed in order for a reply to be sent. Ranging between 0-1 |\n|               | matched_quotes_to_log                 |  The number of matches above `match_store_threshold` to log. |\n|               | remove_own_comments                   |  Toggle the bot's ability to remove it's own comments |\n|               | remove_comment_threshold              |  Toggle the comment score at which a comment is removed. Comments which score equal or below this value are removed. |\n|nlp            | match_store_threshold                 |  The NLP score threshold for comments which are stored, under `matches` in `records.json` |\n|               | quote_comment_length_delta            |  The maximum difference ratio between the length of a comments sentence and quote sentence to be compared. Quote / comment sentence ratios outside this range are discarded. |\n|               | minimum_comment_sentence_word_length  |  The minimum word length a comment needs to be in order to be compared with a quote. |\n|               | quote_length_bonus_coefficient        |  The coefficient applied per word to the NLP score for comment quote sentences matches when they longer than `quote_length_bonus_start` |\n|               | quote_length_bonus_start              |  The starting quote sentence length needed for the NLP score bonus to be applied. |\n|               | quote_length_bonus_end                |  The maximum quote sentence length to which a bonus NLP score is applied. |\n|               | discard_comments_with_author          |  Define if comments should be matched to quotes when the body of the comment contains the author of the quote |\n|records        | maximum_comment_count                 |  Specify the maximum number of comments to be logged in `records.json` . 0 = None, null = No limit |\n|               | maximum_match_count                   |  Specify the maximum number of matches to be logged in `records.json`. 0 = None, null = No limit |\n|               | maximum_reply_count                   |  Specify the maximum number of replies to be logged in `records.json`. 0 = None, null = No limit |\n|               | maximum_removed_comment_count         |  Specify the maximum number of removed comments to be logged in `records.json`. 0 = None, null = No limit |\n\n### Credentials\n\nThe credentials file `credentials.json` is created the first time is run, and read once on startup. Currently, this means the credentials are stored in plain text. This should be changed.\n\nThe fields for the `reddit` object are identically named, and passed directly to [Praw](https://praw.readthedocs.io/en/stable/index.html). See Praw's documentation [here](https://praw.readthedocs.io/en/stable/getting_started/authentication.html).\n\n```json\n{\n  \"reddit\": {\n    \"user_agent\": \"\",\n    \"client_id\": \"\",\n    \"client_secret\": \"\",\n    \"username\": \"\",\n    \"password\": \"\"\n  }\n}\n```\n\n### Records \n\nThe record file, `records.json` is automatically generated and updated during the bots runtime. A minimum example would look like:\n\n#### Comments Section\n\nContains a log of all comments fetched which meet the minimum length criteria, have not been edited, and are not part of the author blacklist.\n\n#### Matches Section\n\nContains a log of all comments and quotes which matched with a score above the `match_store_threshold` score.\n\n#### Replies Section\n\nContains a log of all replies which have been sent (or just logged if `reply_to_comments` is set to false). These are generally matches with a score above `reply_threshold`.\n\n#### Removed Section\n\nContains a log of all self-posted comments that the bot has removed.\n\n#### Banned Subreddit Section\n\nContains a list of subreddits which the bot thinks it is banned from. This is determined by receiving a forbidden exception when trying to post a reply.\n\n```json\n{\n    \"records\": {\n      \"comments\": [\n        {\n          \"body\": \"Eight billion people, it is a momentous milestone for humanity\\n\\nYet, I realise this moment might not be celebrated by all.\\n\\nInstead of the fear of overpopulation, we should focus on the overconsumption of the planet\\u2019s resources by the wealthiest among us.\",\n          \"utc\": 1667800195.0,\n          \"author\": \"cop3213\",\n          \"url\": \"https://reddit.com/r/worldnews/comments/yodyyg/planet_earth_8_billion_people_and_dwindling/ivdteb8/\",\n          \"subreddit\": \"r/worldnews\",\n          \"edited\": false,\n          \"uid\": \"ivdteb8\"\n        },\n      ],\n      \"matches\": [\n        {\n          \"comment\": {\n            \"body\": \"The question feels very cryptic. What are you trying to do?\",\n            \"utc\": 1667805202.0,\n            \"author\": \"dbug89\",\n            \"url\": \"https://reddit.com/r/AusFinance/comments/yofkj7/salary_sacrificing_super/ivdzyjj/\",\n            \"subreddit\": \"r/AusFinance\",\n            \"edited\": false,\n            \"uid\": \"ivdzyjj\"\n          },\n          \"quote\": {\n            \"body\": \"Always do what you are afraid to do.\",\n            \"author\": \"Ralph Waldo Emerson\",\n            \"category\": [\n              \"'inspirational'\"\n            ]\n          },\n          \"score\": 0.9728559309059505\n        }\n      ],\n      \"replies\": [\n        {\n          \"quote\": {\n            \"body\": \"Just because you're paranoid doesn't mean they aren't after you.\",\n            \"author\": \"Joseph Heller,\",\n            \"category\": [\n              \"'misattributed-kurt-cobain'\"\n            ]\n          },\n          \"comment\": {\n            \"body\": \"*just because you're not paranoid doesn't mean they're not after you*\",\n            \"utc\": 1667874409.0,\n            \"author\": \"peter-doubt\",\n            \"url\": \"https://reddit.com/r/worldnews/comments/yp7yux/afp_says_it_does_not_believe_china_has_an_active/ivhyeqv/\",\n            \"subreddit\": \"r/worldnews\",\n            \"edited\": false,\n            \"uid\": \"ivhyeqv\"\n          },\n          \"body\": \"Hi peter-doubt,\\n\\nIt looks like your comment closely matches the famous quote:\\n\\n\\\"Just because you're paranoid doesn't mean they aren't after you.\\\"\\n\\nJoseph Heller,\\n\\nI'm a bot and this action was automatic. [project source](https://www.google.com)\\n        \"\n        }\n      ],\n      \"removed\": [\n        {\n          \"body\": \"Hi Mikey2bz,\\n\\nIt looks like your comment closely matches the famous quote:\\n\\n\\\"It hurts to let go. Sometimes it seems the harder you try to hold on to something or someone the more it wants to get away. You feel like some kind of criminal for having felt, for having wanted. For having wanted to be wanted. It confuses you, because you think that your feelings were wrong and it makes you feel so small because it's so hard to keep it inside when you let it out and it doesn't coma back. You're left so alone that you can't explain. Damn, there's nothing like that, is there? I've been there and you have too. You're nodding your head.\\\" - Henry Rollins,\\n\\n*I'm a bot and this action was automatic [Project source](https://github.com/etdds/redditQuoteBot).*\",\n          \"utc\": 1669551675.0,\n          \"author\": \"redditQuoteBot\",\n          \"url\": \"https://reddit.com/r/Futurology/comments/z5mtb3/we_tasted_the_worlds_first_cultivated_steak_no/ixyo0nc/\",\n          \"subreddit\": \"r/Futurology\",\n          \"edited\": false,\n          \"uid\": \"ixyo0nc\",\n          \"score\": -2\n        },\n      ],\n      \"banned_subreddits\": [\n        \"test\"\n      ]\n    }\n  }\n```\n\n### Bot State\n\nThe current state of the bot is stored in an autogenerated file `scrape_state.json`. Currently, this only keeps a log of the latest comment timestamp in UTC for each subreddit queried.\n\n```json\n{\n  \"latest_comments\": {\n    \"worldnews\": 1667877818.0,\n    \"science\": 1667877772.0,\n    \"AusFinance\": 1667877814.0,\n    \"news\": 1667877770.0,\n    \"ShowerThoughts\": 1667877860.0,\n    \"askscience\": 1667875135.0,\n    \"nottheonion\": 1667877792.0,\n    \"space\": 1667877875.0,\n    \"books\": 1667877515.0,\n    \"UpliftingNews\": 1667877390.0,\n    \"test\": 1667856381.0\n    }\n}\n```\n\n## Development\n\nThe repository is setup to use VSCode with the remote development plugin. Everything should be self-contained within this environment.\n\nContributions and suggestions welcome. Open and an issue or formulate a pull request.\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "redditquotebot",
    "package_url": "https://pypi.org/project/redditquotebot/",
    "platform": null,
    "project_url": "https://pypi.org/project/redditquotebot/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/redditquotebot/0.4.0/",
    "requires_dist": [
      "praw (==7.6.0)",
      "spacy (==3.4.2)"
    ],
    "requires_python": ">=3.6",
    "summary": "Reddit bot for detecting and replying to famous quotes",
    "version": "0.4.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16218765,
  "releases": {
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "24bfeb40f7e6e72988ad21de008a02dffb1b1b93bdc04e3fd3d1db2ac63a4527",
          "md5": "b77f5e2a0ecefd793b3fb5c1e3168a96",
          "sha256": "b9717a8b996eb85a545ffc85f1ca90552390df6df3488f2c58219cd0f2bf2605"
        },
        "downloads": -1,
        "filename": "redditquotebot-0.2.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "b77f5e2a0ecefd793b3fb5c1e3168a96",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 277319,
        "upload_time": "2022-11-14T05:41:27",
        "upload_time_iso_8601": "2022-11-14T05:41:27.631414Z",
        "url": "https://files.pythonhosted.org/packages/24/bf/eb40f7e6e72988ad21de008a02dffb1b1b93bdc04e3fd3d1db2ac63a4527/redditquotebot-0.2.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "084d446d212ccaab9a3ffe435a0222571f570c6690c4caa0eced342b24f4db25",
          "md5": "ac984ce793a1769ac39f6a4e9bde2c47",
          "sha256": "543a2f1e99caa1aa56d71cdb62c33ec6049b991e8bb6283d99699476bd93153b"
        },
        "downloads": -1,
        "filename": "redditquotebot-0.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "ac984ce793a1769ac39f6a4e9bde2c47",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 328517,
        "upload_time": "2022-11-14T05:41:30",
        "upload_time_iso_8601": "2022-11-14T05:41:30.638627Z",
        "url": "https://files.pythonhosted.org/packages/08/4d/446d212ccaab9a3ffe435a0222571f570c6690c4caa0eced342b24f4db25/redditquotebot-0.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4e31ed63c81755afa9052bf8618e43b7b29c36e8908bc0faeb937699471e8a45",
          "md5": "2b4b063c0af7e81a518d153d8416e2d7",
          "sha256": "cbcee3f73d3908295447d0aee744a3b973488a00c94dceb2e876e3b6d0fd8e50"
        },
        "downloads": -1,
        "filename": "redditquotebot-0.3.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "2b4b063c0af7e81a518d153d8416e2d7",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 277298,
        "upload_time": "2022-12-10T05:39:56",
        "upload_time_iso_8601": "2022-12-10T05:39:56.503572Z",
        "url": "https://files.pythonhosted.org/packages/4e/31/ed63c81755afa9052bf8618e43b7b29c36e8908bc0faeb937699471e8a45/redditquotebot-0.3.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9f544f0974bf4d06a13dd78ccd4d37fc20c57dda8aadd42e13b2496e8a7ade66",
          "md5": "0e0c1db77629e60be849d1742474b794",
          "sha256": "62acf44b87abdbf0eb24cbc465f22c6e86fc39ee711da47235d09c9ca13113b9"
        },
        "downloads": -1,
        "filename": "redditquotebot-0.3.0.tar.gz",
        "has_sig": false,
        "md5_digest": "0e0c1db77629e60be849d1742474b794",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 328952,
        "upload_time": "2022-12-10T05:39:59",
        "upload_time_iso_8601": "2022-12-10T05:39:59.637320Z",
        "url": "https://files.pythonhosted.org/packages/9f/54/4f0974bf4d06a13dd78ccd4d37fc20c57dda8aadd42e13b2496e8a7ade66/redditquotebot-0.3.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7411ba89267d626ba72661e95f9d5b3fbbc7cb82b77dcc56c667ce9ae68e48c8",
          "md5": "b25e0c76fc64615499fc0c8aa49aae4d",
          "sha256": "ad0a18c33829ff4dae519faff19efab4ae7727cbc67215da55f4ca2b88aa901d"
        },
        "downloads": -1,
        "filename": "redditquotebot-0.4.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "b25e0c76fc64615499fc0c8aa49aae4d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 279109,
        "upload_time": "2022-12-26T23:14:14",
        "upload_time_iso_8601": "2022-12-26T23:14:14.670265Z",
        "url": "https://files.pythonhosted.org/packages/74/11/ba89267d626ba72661e95f9d5b3fbbc7cb82b77dcc56c667ce9ae68e48c8/redditquotebot-0.4.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "985fd44ce843d273a08a99e13ba6a4276c7b72d595d68da1233b3d7e52298a73",
          "md5": "8b757a3e04edfcf44318a81600907ea3",
          "sha256": "b6b78ddd2734f2902fbd3713a0d977846c9585cc3284178abb59cff82884f43e"
        },
        "downloads": -1,
        "filename": "redditquotebot-0.4.0.tar.gz",
        "has_sig": false,
        "md5_digest": "8b757a3e04edfcf44318a81600907ea3",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 331410,
        "upload_time": "2022-12-26T23:14:18",
        "upload_time_iso_8601": "2022-12-26T23:14:18.375083Z",
        "url": "https://files.pythonhosted.org/packages/98/5f/d44ce843d273a08a99e13ba6a4276c7b72d595d68da1233b3d7e52298a73/redditquotebot-0.4.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "7411ba89267d626ba72661e95f9d5b3fbbc7cb82b77dcc56c667ce9ae68e48c8",
        "md5": "b25e0c76fc64615499fc0c8aa49aae4d",
        "sha256": "ad0a18c33829ff4dae519faff19efab4ae7727cbc67215da55f4ca2b88aa901d"
      },
      "downloads": -1,
      "filename": "redditquotebot-0.4.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "b25e0c76fc64615499fc0c8aa49aae4d",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 279109,
      "upload_time": "2022-12-26T23:14:14",
      "upload_time_iso_8601": "2022-12-26T23:14:14.670265Z",
      "url": "https://files.pythonhosted.org/packages/74/11/ba89267d626ba72661e95f9d5b3fbbc7cb82b77dcc56c667ce9ae68e48c8/redditquotebot-0.4.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "985fd44ce843d273a08a99e13ba6a4276c7b72d595d68da1233b3d7e52298a73",
        "md5": "8b757a3e04edfcf44318a81600907ea3",
        "sha256": "b6b78ddd2734f2902fbd3713a0d977846c9585cc3284178abb59cff82884f43e"
      },
      "downloads": -1,
      "filename": "redditquotebot-0.4.0.tar.gz",
      "has_sig": false,
      "md5_digest": "8b757a3e04edfcf44318a81600907ea3",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 331410,
      "upload_time": "2022-12-26T23:14:18",
      "upload_time_iso_8601": "2022-12-26T23:14:18.375083Z",
      "url": "https://files.pythonhosted.org/packages/98/5f/d44ce843d273a08a99e13ba6a4276c7b72d595d68da1233b3d7e52298a73/redditquotebot-0.4.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}