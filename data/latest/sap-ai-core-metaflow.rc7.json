{
  "info": {
    "author": "SAP SE",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Environment :: Plugins",
      "Intended Audience :: Developers",
      "Intended Audience :: Other Audience",
      "Intended Audience :: Science/Research",
      "License :: Other/Proprietary License",
      "Natural Language :: English",
      "Operating System :: MacOS :: MacOS X",
      "Operating System :: POSIX :: Linux",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Topic :: Scientific/Engineering :: Artificial Intelligence"
    ],
    "description": "# Metaflow library for SAP AI Core\n\nThe `sap-ai-core-metaflow` package is a [Metaflow plugin](https://metaflow.org) that generates [Argo Workflows](https://argoproj.github.io/argo-workflows).\n\nIt adds Argo Workflows capabilities using Metaflow's `@kubernetes` decorator.\n\n## Table of Contents\n\n* [Plugin Installation](#plugin-installation)\n* [Install and configure Argo Workflows](#install-and-configure-argo-workflows)\n* [Configure Metaflow](#configure-metaflow)\n* [Run the Argo WorkflowTemplate](#run-the-argo-workflowtemplate)\n* [Metaflow-Argo Decorators](#metaflow-argo-decorators)\n* [Command-line Parameters and Environment Variables](#command-line-parameters-and-environment-variables)\n* [Other Supported Features](#other-supported-features)\n* [Use with SAP AICore](#use-with-sap-aicore)\n\n## Plugin Installation\n\n```sh\npip install sap-ai-core-metaflow\n```\n\n## Install and configure Argo Workflows\n\nWith the Metaflow-Argo plugin you can execute flows in a K8S cluster.\n> Note: you can also install a local K8S cluster using docker desktop (Mac, Windows) or K3D, minikube (Linux).\n\n* Install [Argo Workflows](https://argoproj.github.io/argo-workflows/installation/) in the K8S cluster.\n* Optionally expose [argo-server](https://argoproj.github.io/argo-workflows/argo-server/) to access ArgoWorkflows UI.\n\n## Configure Metaflow\n\nFor a quick-start follow the steps below.\\\n(Find complete documentation here: [Configuring Metaflow](https://outerbounds.com/docs/configure-metaflow).)\n\n## The Metaflow _config_ File\n\nAn S3 bucket can be configured to store training data and Metaflow code packages.\n\n* Create the config file: `~/.metaflowconfig/config.json` containing your S3 _bucket_ and _prefix_:\n\n``` json\n{\n    \"METAFLOW_DEFAULT_DATASTORE\": \"s3\",\n    \"METAFLOW_DATASTORE_SYSROOT_S3\": \"s3://<bucket>/<prefix>\"\n}\n```\n\nIn addition, your local [aws cli](https://aws.amazon.com/cli/) has to be configured for the same bucket.\n\n## Create the K8S Secret\n\nThis secret allows an Argo Workflow to access the S3 bucket when running in the cluster:\n\n```bash\n    kubectl create secret generic default-object-store-secret --from-literal=AWS_ACCESS_KEY_ID=XXX --from-literal=AWS_SECRET_ACCESS_KEY=YYY\n```\n\n## Run the Argo WorkflowTemplate\n\nHere we use [helloworld.py](https://github.com/Netflix/metaflow/blob/master/metaflow/tutorials/00-helloworld/helloworld.py) from the [Metaflow Tutorials](https://docs.metaflow.org/getting-started/tutorials).\n\n### Deploy the Argo WorkflowTemplate\n\n```bash\n    python helloworld.py --with kubernetes:secrets=default-object-store-secret argo create\n```\n\nYou should see the following output:\n\n```bash\n    Metaflow 2.5.0 executing HelloFlow for user:<xyz>\n    Validating your flow...\n        The graph looks good!\n    Running pylint...\n        Pylint is happy!\n    Deploying helloflow to Argo Workflow Templates...\n    WorkflowTemplate helloflow is pushed to Argo Workflows successfully.\n```\n\n### Trigger the Execution of the WorkflowTemplate\n\n```bash\n    python helloworld.py argo trigger\n```\n\nYou should see a `run-id` after a successful start of a workflow:\n\n```bash\n    Metaflow 2.5.0 executing HelloFlow for user:<xyz>\n    Validating your flow...\n        The graph looks good!\n    Running pylint...\n        Pylint is happy!\n    Workflow helloflow is triggered on Argo Workflows (run-id helloflow-92vbn).\n```\n\n### Check the Execution Status\n\n```bash\n    python helloworld.py argo list-runs\n```\n\nThe flow will display the state `Running` for some time and finally the flow shows\n`Succeeded`:\n\n```bash\n    Metaflow 2.5.0 executing HelloFlow for user:<xyz>\n    Validating your flow...\n        The graph looks good!\n    Running pylint...\n        Pylint is happy!\n    helloflow-92vbn startedAt:'2022-06-15T14:00:27Z' Succeeded\n```\n\n## Metaflow-Argo Decorators\n\nIn addition to general Metaflow decorators, i.e. `@kubernetes`,\n`@resources`, `@environment`, etc. the Metaflow-Argo plugin supports\nadditional Argo-specific customization for steps which support\ninput_artifacts ,output_artifacts, labels and shared_memory.\n\n## The `@argo` Decorator on Step Level\n\nA Metaflow _step_ can override the default values specified on the\nflow level or add extra configurations.\n\n### Labels\n\nLabels are attached as metadata to the pod executing a _step_:\n\n``` python\n...\n\n    @argo(labels = {'plan': 'basic'})\n    @step\n    def training():\n        ...\n```\n\nThe _step_ labels override the flow labels.\n\n### Input Artifacts\n\nThe artifacts configuration is inserted into the generated\nWorkflowTemplate as-is.\n\n``` python\n@argo(input_artifacts=[{\n        'name': 'input_dataset',\n        'path': '/tmp/train.csv',\n        's3': {\n            'endpoint': 's3.amazonaws.com',\n            'bucket': 'my-bucket-name',\n            'key': 'path/in/bucket',\n            'accessKeySecret': {\n                'name': 'my-s3-credentials',\n                'key': 'accessKey'\n            },\n            'secretKeySecret': {\n                'name': 'my-s3-credentials',\n                'key': 'secretKey'\n            }\n        }}])\n@step\ndef start(self):\n    ds = pd.read_csv('/tmp/train.csv')\n```\n\nIf the [Default Artifact Repository](https://argoproj.github.io/argo-workflows/key-only-artifacts) is configured, the credentials can be ommited:\n\n``` python\n@argo(input_artifacts=[{\n        'name': 'input_dataset',\n        'path': '/tmp/spam.csv',\n        's3': {\n            'key': 'path/in/bucket'\n          }\n        }])\n```\n\n### Output Artifacts\n\n> Prerequisite: The [Default Artifact Repository](https://argoproj.github.io/argo-workflows/configure-artifact-repository/#configure-the-default-artifact-repository) is configured\n\nIf the configuration below is added to a _step_, Argo will upload the output artifact to the specified S3 bucket.\n\n``` python\n@argo(output_artifacts=[{\n    'name': 'model',\n    'globalName': 'model',\n    'path': '/tmp/model',\n    'archive': {\n        'none': {}\n    }}])\n@step\ndef train_model(self):\n    ...\n    with open('/tmp/model', 'wb') as f:\n        pickle.dump(self.model, f)\n```\n\n### Configure additional Disk Space using Persistent Volume Claim (PVC)\n\nIf the pod's disk space is not sufficient, one can mount extra storage using a [Persistent Volume Claim](https://kubernetes.io/docs/concepts/storage/persistent-volumes/).\n\nThe example below creates a pvc in WorkflowTemplate with a default size of 50GiB:\n\n``` python\n@argo(mount_pvc=\"/mnt/data\")\n@step\ndef start(self):\n    # use /mnt/data for huge files\n```\n\nTo set the size for the `PVC`, add a value for the command-line parameter `volumen-claim` in MiB:\n\n```bash\n    python helloflow.py argo create --volume-claim=100000\n```\n\n### Shared Memory Allocation\n\nFor adding more `shared memory` in MiB use the following configuration:\n\n``` python\n@argo(shared_memory=100)\n@step\ndef train_model(self):\n    ...\n```\n\n## Command-line Parameters and Environment Variables\n\nThe Metaflow-Argo plugin allows overriding default `flow` values. This done through environment variables or command-line parameters. Command-line parameters naturally have precedence over `envvars`.\n\n## Command-line Parameters\n\n### List Command-line Parameters\n\n```bash\nUsage: helloworld.py argo create [OPTIONS]\n\n  Deploy a new version of this workflow to Argo Workflow Templates.\n\nOptions:\n  --image-pull-secret TEXT    Docker image pull secret.\n  --label TEXT                Label to attach to the workflow template.\n  --annotation TEXT           Annotation to attach to the workflow template.\n  --volume-claim INTEGER      Size of the volumeClaim in MiB\n  --k8s-namespace TEXT        Deploy into the specified kubernetes namespace.\n  --embedded                  Don't download code package into step\n                              containers.Docker images should have a flow and\n                              all dependencies embedded.\n\n  --max-workers INTEGER       Maximum number of parallel pods.  [default: 100]\n  --workflow-timeout INTEGER  Workflow timeout in seconds.\n  --only-json                 Only print out JSON sent to Argo. Do not deploy\n                              anything.\n\n  --help                      Show this message and exit.    \n```\n\n### Set the Flow Name\n\nThe Argo WorkflowTemplate name is taken by default from class name of the the Metaflow script. If you want to change the flow name, use:\n\n```bash\n    python helloworld.py argo --name=hello create\n```\n\n### `@kubernetes` Decorator Command Line Parameter\n\nThe Metaflow command-line parameter `--with=kubernetes` allows for setting configurations when using a kubernetes cluster:\n\n* `secrets` to access object store, multiple secrets can be passed separated by `,`\n\n``` python\n    python helloworld.py --with=kubernetes:secrets=default-object-store-secret,s3-secret argo create\n```\n\n* `image` to specify a docker image\n\n``` python\n    python helloworld.py --with=kubernetes:secrets=default-object-store-secret,image=demisto/sklearn:1.0.0.29944 argo create\n```\n\n* `disk` is used to reserve ephemeral storage in MiB for the node.\n\n``` python\n    python helloworld.py --with=kubernetes:secrets=default-object-store-secret,disk=1024 argo create\n```\n\n### Embedded code package\n\nThe flag `--embedded` generates steps' commands without a code package download; expects a code\tpackage\tto be already *embedded*\ninto a docker image.\n\n## Environment Variables\n\n### Prefix for the Flow Name\n\nTo add a prefix to the flow name set the environment variable `ARGO_WORKFLOW_PREFIX`.\n\n### Default K8S Namespace\n\nThe kubernetes namespace to store templates and execute workflows can be\nset with envvar `METAFLOW_KUBERNETES_NAMESPACE`.\n\n### Default Environment Variables for Command-line Parameters\n\nMetaflow provides envvars for the correspondent command-line parameters by setting this prefix: `METAFLOW_ARGO_CREATE_` e.g.:\n\n```bash\n    export METAFLOW_ARGO_CREATE_MAX_WORKERS=4\n```\n\n## Other Supported Features\n\nThe Metaflow-Argo plugin supports also many Metaflow features.\n\n## `@kubernetes` Decorator\n\nThe Metaflow-Argo plugin makes use of the specifications defined in\n`@kubernetes` decorator to configure container resources.\n\n``` python\n\n    @kubernetes(image='tensorflow/tensorflow:2.6.0', cpu=8, memory=60000)\n    @step\n    def training():\n        ...\n```\n\n## `@resources` Decorator\n\nFull support for [Requesting resources with \\@resources\ndecorator](https://docs.metaflow.org/metaflow/scaling#requesting-resources-with-resources-decorator).\nIf similar resources are specified in both `@kubernetes` and\n`@resources`, the maximum is taken.\n\n``` python\n\n    @kubernetes(image='tensorflow/tensorflow:2.4.2-gpu',\n                node_selector='gpu=nvidia-tesla-k80')\n    @resources(memory=60000, cpu=2)\n    @step\n    def training():\n        ...\n```\n\n## `@environment` Decorator\n\nIn addition to `env` and `envFrom` envvars can be specified in the decorator:\n\n``` python\n@environment(vars={'var':os.getenv('var_1')})\n@step\ndef start(self):\n    print(os.getenv('var'))\n```\n\n## Display Logs for a Step\n\nMetaflow stores stdout and stderr of every step/task and provides a\nconvenient way to access them, passing run-id and step-name:\n\n```bash\n    python 00-helloworld/helloworld.py logs helloflow-bdmmw/start\n```\n\nOptionally specify a task-id, useful when have many instances of the\nsame step, e.g. when use foreach:\n\n```bash\n    python 00-helloworld/helloworld.py logs helloflow-bdmmw/hello/helloflow-bdmmw-3938807173\n```\n\n## Resume flows\n\nSee [How to debug failed\nflows](https://docs.metaflow.org/metaflow/debugging#how-to-debug-failed-flows)\nfor details.\n\n```bash\n    python 00-helloworld/helloworld.py resume --origin-run-id=helloflow-bdmmw\n```\n\n## Schedule flows\n\nMetaflow\\'s\n[\\@schedule](https://docs.metaflow.org/going-to-production-with-metaflow/scheduling-metaflow-flows#scheduling-a-flow)\ndecorator is fully supported. E.g. a workflow template with the\n`@schedule(hourly=True)` will automatically trigger workflow execution\non every hour start.\n\n## Automatically rerun failed steps\n\n`@retry` decorator helps to deal with transient failures. See [Retrying\nTasks with the retry\nDecorator](https://docs.metaflow.org/metaflow/failures#retrying-tasks-with-the-retry-decorator).\n\n## Handle failures programmatically\n\nWhat if a default behavior to stop a whole flow if a particular step\nfails is too limiting? With a help of `@catch` decorator, it\\'s possible\nto handle step\\'s failure in a next step. [Catching Exceptions with the\ncatch\nDecorator](https://docs.metaflow.org/metaflow/failures#catching-exceptions-with-the-catch-decorator).\n\n## Limit the Step Execution Time\n\nUse `@timeout` decorator to guard yourself from accidental resources\nconsumption. Read [Timing out with the timeout\nDecorator](https://docs.metaflow.org/metaflow/failures#timing-out-with-the-timeout-decorator)\nfor more details.\n\n## Use with SAP AICore\n\nSAP AI Core does not allow access to its K8s cluster or argo-server. Workflow Templates are generated in json/yaml format and synced to K8s via the registered Git repo. The Workflows can then be triggered via `SAP AI API`.\n\nThe mandatory information for SAP AI Core is provided through labels and annotations.\n\n```bash\npython helloworld.py --with=kubernetes:secrets=default-object-store-secret,image=docker.io/<my-repo>/helloworld argo create\n  --image-pull-secret=<docker-secret>\n  --label=\"scenarios.ai.sap.com/id:ml_usecase_name\"\n  --label=\"ai.sap.com/version:0.1.0\"\n  --annotation=\"scenarios.ai.sap.com/name:Hello-World\"\n  --annotation=\"\"executables.ai.sap.com/name\":\"helloworld\"\n  --only-json > hello-world.json\n```\n\n[Here](https://blogs.sap.com/2022/04/20/train-your-model-in-sap-ai-core-using-the-metaflow-argo-plugin/) you can find a step-by-step example for SAP AI Core.\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://www.sap.com/",
    "keywords": "SAP AI Core Metaflow Argo Kubernetes",
    "license": "SAP DEVELOPER LICENSE AGREEMENT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "sap-ai-core-metaflow",
    "package_url": "https://pypi.org/project/sap-ai-core-metaflow/",
    "platform": "Linux",
    "project_url": "https://pypi.org/project/sap-ai-core-metaflow/",
    "project_urls": {
      "Documentation": "https://blogs.sap.com/2022/04/20/train-your-model-in-sap-ai-core-using-the-metaflow-argo-plugin/",
      "Homepage": "https://www.sap.com/"
    },
    "release_url": "https://pypi.org/project/sap-ai-core-metaflow/1.1.14/",
    "requires_dist": [
      "metaflow (<=2.8.0,>=2.7.19)",
      "kubernetes (>=23.3.0)",
      "pytest (>=7.1) ; extra == 'test'",
      "pytest-cov[all] ; extra == 'test'"
    ],
    "requires_python": ">=3.7",
    "summary": "A Metaflow plugin to execute flows on Argo Workflows",
    "version": "1.1.14",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17493781,
  "releases": {
    "1.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "157d768ea1abdec4b85aa94ddc043bb0012102f39f20100597b3e6a92cff82a6",
          "md5": "278da6fa71a6576869d0909bb8058b96",
          "sha256": "197a9e9dfac41713152a05bd0ce88ce8931d737258471429fe810d63ede07e3e"
        },
        "downloads": -1,
        "filename": "sap_ai_core_metaflow-1.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "278da6fa71a6576869d0909bb8058b96",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 19435,
        "upload_time": "2022-03-08T07:01:32",
        "upload_time_iso_8601": "2022-03-08T07:01:32.447573Z",
        "url": "https://files.pythonhosted.org/packages/15/7d/768ea1abdec4b85aa94ddc043bb0012102f39f20100597b3e6a92cff82a6/sap_ai_core_metaflow-1.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "362231dde608e2354a1771cb7f9ed5c52211283433b9aaf0fc159da530476df2",
          "md5": "6511c1ae86925dfb34fa24b436eca4db",
          "sha256": "9f8057fd7671d00b1440ac964b90094832cf2a9c119ab87ff778054744b75f46"
        },
        "downloads": -1,
        "filename": "sap_ai_core_metaflow-1.1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "6511c1ae86925dfb34fa24b436eca4db",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 19741,
        "upload_time": "2022-05-09T13:51:08",
        "upload_time_iso_8601": "2022-05-09T13:51:08.726790Z",
        "url": "https://files.pythonhosted.org/packages/36/22/31dde608e2354a1771cb7f9ed5c52211283433b9aaf0fc159da530476df2/sap_ai_core_metaflow-1.1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.11": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f29a9fc61cc0ffc99a1634a302002938dd42f5b838e7cd313dab727d642dd6be",
          "md5": "818344c1479aa6b9c56d6de9d9dfe0ba",
          "sha256": "94701e0174db07b6392d19e4b687860faff8bc33e1c2b5ba4284d6b0a161356d"
        },
        "downloads": -1,
        "filename": "sap_ai_core_metaflow-1.1.11-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "818344c1479aa6b9c56d6de9d9dfe0ba",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 23953,
        "upload_time": "2022-07-21T13:02:20",
        "upload_time_iso_8601": "2022-07-21T13:02:20.084371Z",
        "url": "https://files.pythonhosted.org/packages/f2/9a/9fc61cc0ffc99a1634a302002938dd42f5b838e7cd313dab727d642dd6be/sap_ai_core_metaflow-1.1.11-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.12": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4343ebfc63a06e5898683056114eee1c9761d94158e35e20923d170516bfbcb9",
          "md5": "d36d1e7596b76c5fe8f79cef584d01e2",
          "sha256": "f039c3ec81b1aa81191783b9d5ceae97c019cd393149517ee33c326c4ea3e417"
        },
        "downloads": -1,
        "filename": "sap_ai_core_metaflow-1.1.12-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d36d1e7596b76c5fe8f79cef584d01e2",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 23953,
        "upload_time": "2022-11-29T13:42:55",
        "upload_time_iso_8601": "2022-11-29T13:42:55.569083Z",
        "url": "https://files.pythonhosted.org/packages/43/43/ebfc63a06e5898683056114eee1c9761d94158e35e20923d170516bfbcb9/sap_ai_core_metaflow-1.1.12-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.14": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bf993308f863a72e4400389e543cb169e07be685109e7bf245c4af6fe44ad569",
          "md5": "833614a279c78bb5f9f3b16f89240330",
          "sha256": "c1807a55b268c70ab61830a893d8400bdd3fd94139cbdaa11b6d2c267e793507"
        },
        "downloads": -1,
        "filename": "sap_ai_core_metaflow-1.1.14-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "833614a279c78bb5f9f3b16f89240330",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 23837,
        "upload_time": "2023-03-29T12:51:12",
        "upload_time_iso_8601": "2023-03-29T12:51:12.021805Z",
        "url": "https://files.pythonhosted.org/packages/bf/99/3308f863a72e4400389e543cb169e07be685109e7bf245c4af6fe44ad569/sap_ai_core_metaflow-1.1.14-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "83bf80bc87432480a370b44f4de3140df510f3a12e8291ef4554c976e32c75b0",
          "md5": "6a76c833c60a039dc48c27931bdd3cdc",
          "sha256": "3c84f0e9534dbef29730335b528228585052678f2a04cdcecfd6f0e7749f00de"
        },
        "downloads": -1,
        "filename": "sap_ai_core_metaflow-1.1.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "6a76c833c60a039dc48c27931bdd3cdc",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 20033,
        "upload_time": "2022-05-17T14:15:17",
        "upload_time_iso_8601": "2022-05-17T14:15:17.518015Z",
        "url": "https://files.pythonhosted.org/packages/83/bf/80bc87432480a370b44f4de3140df510f3a12e8291ef4554c976e32c75b0/sap_ai_core_metaflow-1.1.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.9": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2a6a4f8c36dfdb2944c991eaaaa492de320b721c2973c7cb0432c27e9dc788d1",
          "md5": "db9c8107228d37d018a27f9f3db39c7b",
          "sha256": "f3f7d39b1b839049cad9115955e7b001df4b6a3def739f540647d0b0a7dbe104"
        },
        "downloads": -1,
        "filename": "sap_ai_core_metaflow-1.1.9-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "db9c8107228d37d018a27f9f3db39c7b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 23943,
        "upload_time": "2022-06-30T13:07:41",
        "upload_time_iso_8601": "2022-06-30T13:07:41.512668Z",
        "url": "https://files.pythonhosted.org/packages/2a/6a/4f8c36dfdb2944c991eaaaa492de320b721c2973c7cb0432c27e9dc788d1/sap_ai_core_metaflow-1.1.9-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "bf993308f863a72e4400389e543cb169e07be685109e7bf245c4af6fe44ad569",
        "md5": "833614a279c78bb5f9f3b16f89240330",
        "sha256": "c1807a55b268c70ab61830a893d8400bdd3fd94139cbdaa11b6d2c267e793507"
      },
      "downloads": -1,
      "filename": "sap_ai_core_metaflow-1.1.14-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "833614a279c78bb5f9f3b16f89240330",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 23837,
      "upload_time": "2023-03-29T12:51:12",
      "upload_time_iso_8601": "2023-03-29T12:51:12.021805Z",
      "url": "https://files.pythonhosted.org/packages/bf/99/3308f863a72e4400389e543cb169e07be685109e7bf245c4af6fe44ad569/sap_ai_core_metaflow-1.1.14-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}