{
  "info": {
    "author": "The DNADNA Developers",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Environment :: Console",
      "Environment :: GPU :: NVIDIA CUDA",
      "Intended Audience :: Science/Research",
      "License :: CeCILL-C Free Software License Agreement (CECILL-C)",
      "License :: OSI Approved :: GNU Lesser General Public License v3 or later (LGPLv3+)",
      "Programming Language :: Python :: 3.7",
      "Topic :: Scientific/Engineering :: Bio-Informatics"
    ],
    "description": "# DNADNA\n\n [![documentation](https://img.shields.io/badge/documentation-latest-success)](https://mlgenetics.gitlab.io/dnadna/) [![pipeline status](https://gitlab.com/mlgenetics/dnadna/badges/master/pipeline.svg)](https://gitlab.com/mlgenetics/dnadna/pipelines/master/latest) [![coverage report](https://gitlab.com/mlgenetics/dnadna/badges/master/coverage.svg?job=test:cuda)](https://mlgenetics.gitlab.io/dnadna/coverage/cuda/)\n\nDeep Neural Architecture for DNA.\n\nThe goal of this package is to provide utility functions to improve\ndevelopment of neural networks for population genetics.\n\n`dnadna` should allow researchers to focus on their research project, be it the\nanalysis of population genetic data or building new methods, without the need to\nfocus on proper development methodology (unit test, continuous integration,\ndocumentation, etc.). Results will thus be more easily reproduced and shared.\nHaving a common interface will also decrease the risk of bugs.\n\n\n# Installation\n\n## Using conda/mamba\n\nBecause DNADNA has some non-trivial dependencies (most notably\n[PyTorch](https://pytorch.org/)) the easiest way to install it is in a conda\nenvironment.\nWe will show how to install it with `mamba` (which is a faster\nimplementation of `conda`). **Note that all following commands will work with**\n`conda` **instead of** `mamba`**, unless otherwise specified.**\n\nIf you don't have `conda` yet, follow the [official\ninstructions](https://docs.conda.io/projects/conda/en/latest/user-guide/install/index.html)\nto install either the full\n[Anaconda](https://docs.conda.io/projects/conda/en/latest/glossary.html#anaconda-glossary)\ndistribution or, advisably, the smaller\n[Miniconda](https://docs.conda.io/projects/conda/en/latest/glossary.html#miniconda-glossary)\ndistribution.\nOnce you've installed `conda`, you can follow the\n[Mamba](https://github.com/mamba-org/mamba#installation) installation.\n\nYou can install DNADNA in an existing conda environment, but the easiest way\nis to install it with `mamba` in a new environment.  Start by creating a new\nenvironment:\n\n```console\n$ mamba create -n dnadna\n```\n\nwhere the name of the environment (`-n`) is `dnadna` (it won't install\nDNADNA yet).\n\nActivate the environment with `mamba activate dnadna`.\n\nThen DNADNA can be installed and updated by running:\n\n```console\n$ mamba install -c mlgenetics -c pytorch -c bioconda -c conda-forge dnadna\n```\n\nEach `-c` flag specifies a conda \"channel\" that needs to be searched for\nsome of the dependencies.  If you want to add the \"mlgenetics\" channel and\nthose of its dependencies to your list of default conda channels, you can\nrun:\n\n```console\n$ conda config --add channels mlgenetics \\\n               --add channels pytorch \\\n               --add channels conda-forge \\\n               --add channels bioconda\n```\n\nNote: The previous command works only with `conda`, not with `mamba` (yet)\n\n\nOne can make sure `dnadna` is properly installed by running `dnadna -h`.\n\n### Optional dependencies\n\nDNADNA supports logging losses (and eventually other statistics) during\ntraining in the [TensorBoard](https://www.tensorflow.org/tensorboard) format\nfor better [loss\nvisualization](https://mlgenetics.gitlab.io/dnadna/training.html#visualize-losses).\n\nTo ensure TensorBoard support is enabled, you can install it in your active\nconda environment with:\n\n```console\n$ mamba install -c conda-forge tensorboard\n```\n\nDNADNA can be used inside Jupyter notebooks. If you are using conda/mamba environments, you need to install jupyterlab in the same environement as DNADNA:\n\n```console\n$ mamba activate dnadna\n$ mamba install -c conda-forge jupyterlab\n```\n\n\n## Using PyPI\n\nIf you prefer not to use conda, and to get DNADNA and its dependencies\ndirectly using PyPI+pip you can run:\n\n```console\n$ pip install dnadna\n```\n\nNote: We still advise to install it within a conda environment.\n\n## Development\n\nAlternatively, you may *clone* the DNADNA git repository and install from\nthere:\n\n```console\n$ git clone https://gitlab.com/mlgenetics/dnadna.git\n$ cd dnadna\n$ mamba env create\n$ mamba activate dnadna\n$ pip install .\n```\n\nOr using the lighter CPU-only environment:\n\n```console\n$ git clone https://gitlab.com/mlgenetics/dnadna.git\n$ cd dnadna\n$ mamba env create --file environment-cpu.yml\n$ mamba activate dnadna-cpu\n$ pip install .\n```\n\nIf you plan to do **development** on the package, it is advisable to choose\nthe `git clone` solution and install in \"editable\" mode by running instead:\n```console\n$ pip install -e .\n```\n\n## Updating\n\nIf installed with conda/mamba, DNADNA can be updated by running:\n\n```console\n$ mamba update -c mlgenetics -c pytorch -c conda-forge dnadna\n```\n\nOr, if you already added the release channels to your default channels,\nwith simply:\n\n```console\n$ mamba update dnadna\n```\n\n## Note for internal users/developers\n\nUsers of the private repository on https://gitlab.inria.fr should see\n[the development\ndocumentation](https://mlgenetics.gitlab.io/dnadna/development.html) for\nnotes on how to access the private repository.\n\n\n## Docker\n\nA\n[Dockerfile](https://gitlab.com/mlgenetics/dnadna/-/blob/master/Dockerfile)\nis also included for building a Docker image containing DNADNA (it is based\non conda, so it essentially recreates the installation environment explained\nabove, including GPU support.  To build the image run:\n\n```console\n$ docker build --tag dnadna .\n```\n\nMake sure to run this from the root of the repository, as the entire\nrepository needs to be passed to the Docker build context.\n\nIf run without specifying any further commands, it will open a shell with\nthe `dnadna` conda environment enabled:\n\n```console\n$ docker run -ti dnadna\n```\n\nHowever, you can also run it non-interactively, e.g. by specifying the\n`dnadna` command.  Here it is also likely a good idea to mount the data\ndirectory for your simulation/training files.  For example:\n\n```console\n$ docker run -t -v /path/to/my/data:/data --workdir /data dnadna dnadna init\n```\n\nAdditional notes on the Docker image:\n\n* By default it logs in as a non-root user named \"dnadna\" with UID 1001\n  and GID also of 1001.  If you start the container with the `--user` flag\n  and your own UID it will change the UID and GID of the \"dnadna\" user.\n  Make sure to specify both a UID and a GID, otherwise the group of all\n  files owned by \"dnadna\" will be changed to \"root\".  E.g., run:\n  `docker run -u $(id -u):$(id -g)`.\n\n* The default workdir is `/home/dnadna/dnadna` which contains the `dnadna`\n  package source code.\n\n* If you want to install your own conda packages (e.g. to use this container\n  for development), after starting the container it is best to create a new\n  conda environment cloned from the base environment, then re-install\n  dnadna:\n\n  ```console\n  $ conda create -n dnadna --clone base\n  $ conda activate dnadna\n  $ pip install -e .\n  ```\n\n  This is not done by default by the image because it would require\n  additional start-up time in the non-development case.  However, as\n  a short-cut for the above steps you can run the container with\n  `docker run -e DEV=1`.\n\n  Afterwards, you can create a snapshot of this container in another\n  terminal, e.g. by running `docker commit <my-container> dnadna-dev`.\n\n\n# Dependencies\n\n- python >= 3.6\n- pytorch\n- pandas\n- numpy\n- matplotlib\n- msprime\n- jsonschema\n- pyyaml\n- tqdm\n\n(For a complete list, see `setup.cfg`, or `requirements.txt`.)\n\n\n# Quickstart Tutorial\n\nAfter successful installation you should have a command-line utility called\n`dnadna` installed:\n\n```console\n$ dnadna --help\nusage: dnadna [-h] [COMMAND]\n\ndnadna version ... top-level command.\n\nSee dnadna <sub-command> --help for help on individual sub-commands.\n\noptional arguments:\n  -h, --help       show this help message and exit\n  --plugin PLUGIN  load a plugin module; the plugin may be specified either as the file path to a Python module, or the name of a module importable on the current Python module path (i.e. sys.path); plugins are just Python modules which may load arbitrary code (new simulators, loss functions, etc.) during DNADNA startup); --plugin may be passed multiple times to load multiple plugins\n  --trace-plugins  enable tracing of plugin loading; for most commands this is enabled by default, but for other commands is disabled to reduce noise; this forces it to be enabled\n  -V, --version    show the dnadna version and exit\n\nsub-commands:\n  init          Initialize a new model training configuration and directory\n                structure.\n  preprocess    Prepare a training run from an existing model training\n                configuration.\n  train         Train a model on a simulation using a specified pre-processed\n                training config.\n  predict       Make parameter predictions on existing SNP data using an already\n                trained model.\n  simulation    Run a registered simulation.\n```\n\nThis implements a number of different sub-commands for different training\nand simulation steps.  The `dnadna` command can be used either starting with\nan existing simulation dataset (which may need to be first be converted to\nthe [DNADNA Dataset\nFormat](https://mlgenetics.gitlab.io/dnadna/datasets.html#the-dnadna-dataset-format),\nor you may use `dnadna`'s simulator interface to create a new simulation\ndataset.\n\nHere we step through the complete process from configuring and generating a\nsimulation, to running data pre-processing on the simulation, and training a\nnetwork based off that simulation.\n\nIf you already have simulation data in the [DNADNA Data\nFormat](#data-format) you can skip straight to the\n[initialization](#model-initialization) step.\n\n\n## Simulation initialization and configuration\n\nTo initialize a simulation, we must first generate a config file and output\nfolder for it, using the `dnadna simulation init` command:\n\n```console\n$ dnadna simulation init my_dataset one_event\nWriting sample simulation config to my_dataset/my_dataset_simulation_config.yml ...\nEdit the config file as needed, then run this simulation with the command:\n\n    dnadna simulation run my_dataset/my_dataset_simulation_config.yml\n```\n\nThis will create a directory in the current directory, named `my_dataset/`,\nand initialize it with a config file pre-populated with sample parameters\nfor the built-in [one_event example\nsimulator](https://mlgenetics.gitlab.io/dnadna/_autosummary/_autosummary/dnadna.examples.one_event.html).\n\nBefore running the simulation we may want to adjust some of the parameters.\nOpen `my_dataset/my_dataset_simulation_config.yml` in your favorite text\neditor.  By default we see that `n_scenarios` is `100` with `n_replicates`\nof 3 per scenario (in the one_event example `n_replicates` is the number of independently simulated genomic regions). You can change it to `20` scenarios with `2` replicates, i.e. 100 simulations total, which is good for this quick demo but too low for training a real model. For a real training with enough computing resources, we would recommend changing these numbers to higher values such as `20000` and `100` (2 million simulations which take a very long time). You may\nalso set the `seed` option to seed the random number generator for\nreproducible results.  The resulting file (with none of the other settings\nchanged) should look like:\n\n```yaml\n# my_dataset/my_dataset_simulation_config.yml\ndata_root: .\nn_scenarios: 20\nn_replicates: 2\nseed: 2\n...\n```\n\n## Running the simulation\n\nNow to run the simulation we configured, we run `dnadna simulation run`,\npassing it the path to the config file we just edited.  If you run this in a\nterminal it will also display a progress bar:\n\n```console\n$ dnadna simulation run my_dataset/my_dataset_simulation_config.yml\n... INFO;  Running one_event simulator with n_scenarios=20 and n_replicates=2\n... INFO;  Simulation complete!\n... INFO;  Initialize model training with the command:\n... INFO;\n... INFO;      dnadna init --simulation-config=my_dataset/my_dataset_simulation_config.yml <model-name>\n```\n\n## Model initialization\n\nThe main command for initialize DNADNA is `dnadna init`, which assumes we\nalready have a simulation (such as the one we just generated) in the\nstandard [DNADNA Data Format](#data-format).  Although this command can be\nrun without any arguments (producing a default config file), if we pass it\nthe path to our simulation config file it will output a config file\nappropriate for use with that simulation:\n\n```console\n$ dnadna init --simulation-config=my_dataset/my_dataset_simulation_config.yml my_model\nWriting sample preprocessing config to my_model/my_model_preprocessing_config.yml ...\nEdit the dataset and/or preprocessing config files as needed, then run preprocessing with the command:\n\n    dnadna preprocess my_model/my_model_preprocessing_config.yml\n```\n\nAfter running `dnadna init`, it is expected that the user will manually edit\nthe sample config file that it outputs, in order to exactly specify how they\nwant to train their model, and on which parameters.  In fact, the default\ntemplate is going to be good enough for our demo simulation, except for one\nbit that will give us trouble.\n\nThe option `dataset_splits:` has a default value meaning 70% of our\nscenarios will be used for training, and only 30% for validation.  Since,\nfor this quick demo, we only have 20 scenarios, the validation set will be\ntoo small.  Open the file `my_model/my_model_preprocessing_config.yml` in your\neditor and change this so that our dataset is split 50/50 between training\nand validation:\n\n```yaml\n# my_model/my_model_preprocessing_config.yml\n# ...\ndataset_splits:\n    training: 0.5\n    validation: 0.5\n```\n\nUnder normal use you would set these ratios however you prefer.  You can\nalso include a `test` set of scenarios to be set aside for testing your\nmodel.\n\n\n## Pre-processing\n\nBefore training a model, some data pre-processing must be performed on the\ndata set; the output of this pre-processing can depend on the settings in\nthe preprocessing config file that was output by `dnadna init`.  To do this,\nsimply run:\n\n```console\n$ dnadna preprocess my_model/my_model_preprocessing_config.yml\n... INFO;  Removing scenarios with:\n... INFO;   - Missing replicates\n... INFO;   - Fewer than 500 SNPs\n... INFO;  ...\n... INFO;  Using ... CPU for checking scenarios\n... INFO;  20 scenarios out of 20 have been kept, representing 40 simulations\n... INFO;  Splitting scenarios between training and validation set\n... INFO;  Standardizing continuous parameters\n... INFO;  Writing preprocessed scenario parameters to: .../my_model/my_model_preprocessed_params.csv\n... INFO;  Writing sample training config to: .../my_model/my_model_training_config.yml\n... INFO;  Edit the training config file as needed, then start the training run with the command:\n... INFO;\n... INFO;      dnadna train .../my_model/my_model_training_config.yml\n```\n\nThis will produce a `<model_name>_training_config.yml` file containing the\nconfig file prepared for training your model.\n\n\n## Training\n\nTo run a model training, after pre-processing use `dnadna train`, giving it\nthe path to the pre-processed training config file as output by the last\nstep.\n\nIn order to make the training run a little faster (just for this example)\nlet's also edit the training config file to limit it to one epoch:\n\n```yaml\n# my_model/my_model_training_config.yml\n# ...\n# name and parameters of the neural net model to train\nnetwork:\n    name: CustomCNN\n\n# number of epochs over which to repeat the training process\nn_epochs: 1\n...\n```\n\nThen run `dnadna train` on the training config file:\n\n```console\n$ dnadna train my_model/my_model_training_config.yml\n... INFO;  Preparing training run\n... INFO;  20 samples in the validation set and 20 in the training set\n... INFO;  Start training\n... INFO;  Networks states are saved after each validation step\n... INFO;  Starting Epoch #1\n... INFO;  Validation at epoch: 1 and batch: 1\n... INFO;  Compute all outputs for validation dataset...\n... INFO;  Done\n... INFO;  training loss = 1.0222865343093872 // validation loss = 1.2975229024887085\n... INFO;  Better loss found on validation set: None --> 1.2975229024887085\n... INFO;  Saving model to \".../my_model/run_000/my_model_run_000_best_net.pth\" ...\n... INFO;  Compute all outputs for validation dataset...\n... INFO;  Done\n... INFO;  --- 3.185938596725464 seconds ---\n... INFO;  --- Best loss: 3.892427444458008\n... INFO;  Saving model to \".../my_model/run_000/my_model_run_000_last_epoch_net.pth\" ...\n... INFO;  You can test the model's predictions on a test dataset by running the command:\n... INFO;\n... INFO;      dnadna predict .../my_model/run_000/my_model_run_000_last_epoch_net.pth <dataset config file or paths to .npz files>\n```\n\nBy default this will output a directory for your training run under\n`model_name/run_NNN` where `NNN` is an integer run ID.  The run ID starts at\n0, and by default the next unused run ID is used.  However, you may also\npass the `--run-id` argument to give a custom run ID, which may be either an\ninteger, or an arbitrary string.\n\nFollowing a successful training run will output a\n`<model_name>_run_<run_id>_last_epoch_net.pth` file in the run directory,\ncontaining the final trained model in a pickled format, which can be loaded\nby the\n[torch.load](https://pytorch.org/docs/stable/torch.html?highlight=torch%20load#torch.load)\nfunction.\n\nUnder the run directory this will also produce a\n`<model_name>_<run_id>_training_config.yml` file containing the final config\nfile prepared for this training run.  This contains a complete copy of the\n\"base\" training config use used to run `dnadna train` as well as a\ncomplete copy of the simulation config.  This information is copied in full\nfor the purpose of provenance and reproducibility of a training run.\n\nThe expectation is that between multiple training runs, you may modify\nthe \"base\" config to tune the training, either by modifying the original\nconfig file directly, or by copying it and editing the copy.  In any case,\nthe final configuration used to perform the training run is saved in the run\ndirectory and should not be modified.\n\nYou can keep track of all training and validation losses with TensorBoard\n\n\n## Prediction\n\nGiven the trained network, we can now use it to make (or confirm)\npredictions on new datasets.  To demonstrate we'll run the `dnadna predict`\nmodel over part of the existing dataset we just used to train the model,\nthough in practice it could be run on any data that conforms (e.g. in\ndimensions) to the dataset the model was trained on.  The output is a CSV\nfile containing the parameter predictions for each input:\n\n```console\n$ dnadna predict my_model/run_000/my_model_run_000_last_epoch_net.pth \\\n                 my_dataset/scenario_04/*.npz\npath,event_time,recent_size,event_size\n.../my_dataset/scenario_04/my_dataset_04_0.npz,-0.06392800807952881,-0.11097482591867447,-0.12720556557178497\n.../my_dataset/scenario_04/my_dataset_04_1.npz,-0.06392764300107956,-0.11097370833158493,-0.12720371782779694\n```\n\n\n# Data format\n\nDNADNA has a prescribed filesystem layout and file format for the datasets\nits works on.  Some of the details of this layout can be modified in the\nconfiguration files, and in a future version will be further customizable by\nplugins.\n\nBut the default format assumes that SNP data (SNP matrices and associated\nSNP position arrays) are stored in NumPy's\n[NPZ](https://numpy.org/devdocs/reference/generated/numpy.savez.html#numpy.savez)\nformat with one file per SNP.  They are organized on disk by scenario like:\n\n```\n\\_ my_simulation/\n    \\_ my_simulation_params.csv  # the scenario parameters table\n    |_ my_simulation_dataset_config.yml  # the simulation config file\n    |_ scenario_000/\n        \\_ my_simulation_000_00.npz  # scenario 0 replicate 0\n        ...\n        |_ my_simulation_000_NN.npz\n    |_ scenario_001/\n        \\_ my_simulation_001_00.npz  # scenario 1 replicate 0\n        ...\n        |_ my_simulation_001_NN.npz\n    ...\n    |_ scenario_NNN/\n        \\_ my_simulation_NNN_00.npz\n        ...\n        |_ my_simulation_NNN_NN.npz\n```\n\nThe file `my_simulation_params.csv` contains the known target values for\neach parameter of the simulation, on a per-scenario basis.  It is currently\na plain CSV file which must contain at a minimum 3 columns:\n\n* A `scenario_idx` column giving the scenario number.\n* An `n_replicates` column which specifies the number of replicates in that\n  scenario.\n* One or more additional columns containing arbitrary parameter names, and\n  their values each scenario in the dataset.\n\nFor example:\n\n```csv\nscenario_idx,mutation_rate,recombination_rate,event_time,n_replicates\n0,1e-08,1e-08,0.3865300203456797,-0.497464473948751,100\n1,1e-08,1e-08,0.19344551118300793,0.16419897912977574,100\n...\n```\n\nAn associated config file here named `my_simulation_dataset_config.yml`\nprovides further details about how to load the dataset to the DNADNA\nsoftware.  An example dataset config can be generated by running `dnadna\ninit`.\n\nSee [The DNADNA Dataset\nFormat](https://mlgenetics.gitlab.io/dnadna/simulation.html#the-dnadna-dataset-format)\nfor more details.\n\n# Development\n\nSee [the development\ndocumentation](https://mlgenetics.gitlab.io/dnadna/development.html)\nfor full details on how to set up and use a development environment and\ncontribute to DNADNA.\n\n\n# Detailed usage\n\nFor the full usage manual see the [DNADNA\nDocumentation](https://mlgenetics.gitlab.io/dnadna/overview.html).\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://gitlab.com/mlgenetics/dnadna",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "embray@lri.fr",
    "name": "dnadna",
    "package_url": "https://pypi.org/project/dnadna/",
    "platform": null,
    "project_url": "https://pypi.org/project/dnadna/",
    "project_urls": {
      "Homepage": "https://gitlab.com/mlgenetics/dnadna"
    },
    "release_url": "https://pypi.org/project/dnadna/1.0.0rc1/",
    "requires_dist": [
      "jsonschema (>=3.0.0)",
      "jsonschema-pyref (>=0.1.0b1)",
      "matplotlib (>=3.1.0)",
      "msprime (>=0.7.0)",
      "numpy (>=1.19.0)",
      "pandas (>=0.25.0)",
      "pyyaml (>=5.1.0)",
      "scikit-allel (>=1.2.0)",
      "torch (>=1.2.0)",
      "tqdm (>=4.40.0)",
      "mistune (<2.0) ; extra == 'docs'",
      "m2r ; extra == 'docs'",
      "pygments-csv-lexer ; extra == 'docs'",
      "sphinx (>=2.4.0) ; extra == 'docs'",
      "sphinx-rtd-theme ; extra == 'docs'",
      "sphinxcontrib-napoleon ; extra == 'docs'",
      "sphinxcontrib-spelling ; extra == 'docs'",
      "filelock (>=3.0.12) ; extra == 'tests'",
      "mistletoe ; extra == 'tests'",
      "pytest (>=5.3.1) ; extra == 'tests'",
      "pytest-cov (>=2.8.1) ; extra == 'tests'",
      "pytest-doctestplus ; extra == 'tests'",
      "pytest-xdist (>=1.31.0) ; extra == 'tests'"
    ],
    "requires_python": ">=3.7",
    "summary": "Deep Neural Architecture for DNA",
    "version": "1.0.0rc1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 13832626,
  "releases": {
    "1.0.0rc0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f40a7f517298657ad3e88881b6cc88748f55e9d69c903ef858324b844f1e1fbf",
          "md5": "1981faaa85961e0500d5eaa810466917",
          "sha256": "639a770a787e98b3dd1e690c09f3a757fae35eefb9c7ecc7089957157d6bbe29"
        },
        "downloads": -1,
        "filename": "dnadna-1.0.0rc0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "1981faaa85961e0500d5eaa810466917",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 198357,
        "upload_time": "2021-07-30T15:31:44",
        "upload_time_iso_8601": "2021-07-30T15:31:44.688740Z",
        "url": "https://files.pythonhosted.org/packages/f4/0a/7f517298657ad3e88881b6cc88748f55e9d69c903ef858324b844f1e1fbf/dnadna-1.0.0rc0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4e05f6fcb60952348202199bcc86ac834d3ed9414d11c16caef62af11849a967",
          "md5": "7d64f1e0577ffef116e56880f89ff52a",
          "sha256": "5b6db902bbcecd298e97cb69f9c78a84d7789d27663ffa1d92a9e1c489023c64"
        },
        "downloads": -1,
        "filename": "dnadna-1.0.0rc0.tar.gz",
        "has_sig": false,
        "md5_digest": "7d64f1e0577ffef116e56880f89ff52a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 261103,
        "upload_time": "2021-07-30T15:31:47",
        "upload_time_iso_8601": "2021-07-30T15:31:47.022784Z",
        "url": "https://files.pythonhosted.org/packages/4e/05/f6fcb60952348202199bcc86ac834d3ed9414d11c16caef62af11849a967/dnadna-1.0.0rc0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.0rc1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "06ae844b5a3c51d20ee5857164dcb421ac348f8f30db7679aca56c4943aae248",
          "md5": "78670f57d5fc3eda7965cbd116f06f3d",
          "sha256": "57e33bd78dcbc986d1e3c5fc910c1e474946e0c1a2e5b848408c70163be4d0c6"
        },
        "downloads": -1,
        "filename": "dnadna-1.0.0rc1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "78670f57d5fc3eda7965cbd116f06f3d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 199944,
        "upload_time": "2022-05-16T17:57:50",
        "upload_time_iso_8601": "2022-05-16T17:57:50.807334Z",
        "url": "https://files.pythonhosted.org/packages/06/ae/844b5a3c51d20ee5857164dcb421ac348f8f30db7679aca56c4943aae248/dnadna-1.0.0rc1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c4b231b60332b474c3303a37f69c16895a9ff283b2baf5874948612a4f32c622",
          "md5": "0681c5410c028838a7e419e8876d2b94",
          "sha256": "a66434ab371cfd66e0b400617d725176942d6be261ad6c016dd006aba5411e99"
        },
        "downloads": -1,
        "filename": "dnadna-1.0.0rc1.tar.gz",
        "has_sig": false,
        "md5_digest": "0681c5410c028838a7e419e8876d2b94",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 1151185,
        "upload_time": "2022-05-16T17:57:53",
        "upload_time_iso_8601": "2022-05-16T17:57:53.549814Z",
        "url": "https://files.pythonhosted.org/packages/c4/b2/31b60332b474c3303a37f69c16895a9ff283b2baf5874948612a4f32c622/dnadna-1.0.0rc1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "06ae844b5a3c51d20ee5857164dcb421ac348f8f30db7679aca56c4943aae248",
        "md5": "78670f57d5fc3eda7965cbd116f06f3d",
        "sha256": "57e33bd78dcbc986d1e3c5fc910c1e474946e0c1a2e5b848408c70163be4d0c6"
      },
      "downloads": -1,
      "filename": "dnadna-1.0.0rc1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "78670f57d5fc3eda7965cbd116f06f3d",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 199944,
      "upload_time": "2022-05-16T17:57:50",
      "upload_time_iso_8601": "2022-05-16T17:57:50.807334Z",
      "url": "https://files.pythonhosted.org/packages/06/ae/844b5a3c51d20ee5857164dcb421ac348f8f30db7679aca56c4943aae248/dnadna-1.0.0rc1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "c4b231b60332b474c3303a37f69c16895a9ff283b2baf5874948612a4f32c622",
        "md5": "0681c5410c028838a7e419e8876d2b94",
        "sha256": "a66434ab371cfd66e0b400617d725176942d6be261ad6c016dd006aba5411e99"
      },
      "downloads": -1,
      "filename": "dnadna-1.0.0rc1.tar.gz",
      "has_sig": false,
      "md5_digest": "0681c5410c028838a7e419e8876d2b94",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 1151185,
      "upload_time": "2022-05-16T17:57:53",
      "upload_time_iso_8601": "2022-05-16T17:57:53.549814Z",
      "url": "https://files.pythonhosted.org/packages/c4/b2/31b60332b474c3303a37f69c16895a9ff283b2baf5874948612a4f32c622/dnadna-1.0.0rc1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}