{
  "info": {
    "author": "Phan Viet Hoang",
    "author_email": "phanviethoang1512@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Developers",
      "Natural Language :: English",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "<div align=\"center\">\n\n# üèÖQuantitative Summarization ‚Äì Key Point AnalysisüèÖ\n\n[![CircleCI](https://circleci.com/gh/VietHoang1512/KPA.svg?style=svg&circle-token=a196c015fd323b139ee617a2ebd36b9055dee3a2)](https://circleci.com/gh/VietHoang1512/KPA/tree/main)\n[![pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&logoColor=white)](https://github.com/pre-commit/pre-commit)\n[![code style](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1RNZsW30ulRs5Avkwe8Jqfc8zRbhpmUbD?usp=sharing)\n[![Codacy Badge](https://app.codacy.com/project/badge/Grade/776410d9c5ea4290b0301d5f70bec9b5)](https://www.codacy.com/gh/VietHoang1512/KPA/dashboard?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=VietHoang1512/KPA&amp;utm_campaign=Badge_Grade)\n[![CodeFactor](https://www.codefactor.io/repository/github/viethoang1512/kpa/badge?s=805044f88408096519ce8ab36564bb8b98e8e9ba)](https://www.codefactor.io/repository/github/viethoang1512/kpa)\n\n</div>\n\n## Keypoint Analysis \n\nThis library is based on the Transformers library by HuggingFace. **Keypoint Analysis** quickly embeds the statements with the provided supported topic and the stances toward that topic. It is a part of our approach in the [Quantitative Summarization ‚Äì Key Point Analysis](https://competitions.codalab.org/competitions/31166) shared task by **IBM**. We use the ArgKP dataset ([Bar-Haim et al., ACL-2020](https://www.aclweb.org/anthology/2020.acl-main.371.pdf)), which contains ~24K argument/key-point pairs, for 28 controversial topics in our training and evaluation.\n\n### What's New\n\n#### July 1, 2021\n\n- First release of [qs-kpa](https://pypi.org/project/qs-kpa/) python package\n\n#### July 4, 2021\n\n- Our method achieved the 4th position in track I of the shared task [[paper]](https://github.com/VietHoang1512/KPA/paper/ArgMining_EMNLP_submission.pdf)\n\n### Installation\n\n#### Install with pip (stable version)\n\n```bash\npip install qs-kpa\n```\n\n#### Install from sources (latest version)\n\n```bash\ngit clone https://github.com/VietHoang1512/KPA\npip install -e .\n```\n\n### Quick example\n\nCurrently, a pretrained KPA encoder with [RoBERTa](https://arxiv.org/abs/1907.11692) backbone is available, which can be automatically downloaded from Google Drive when initializing the `KeyPointAnalysis` instance. We used the 4 last hidden state representations of the [CLS] token as the whole sentence embedding and trained it with *TupletMarginLoss* and *IntraPairVarianceLoss* on the ArgKP dataset. For the code, see [main.py](scripts/main.py).\n\n```python\n# Import needed libraries\nfrom qs_kpa import KeyPointAnalysis\n\n# Create a KeyPointAnalysis model\n# Set from_pretrained=True in order to download the pretrained model\nencoder = KeyPointAnalysis(from_pretrained=True) \n\n# Model configuration\nprint(encoder)\n\n# Preparing data (a tuple of (topic, statement, stance) or a list of tuples)\ninputs = [\n    (\n        \"Assisted suicide should be a criminal offence\",\n        \"a cure or treatment may be discovered shortly after having ended someone's life unnecessarily.\",\n        1,\n    ),\n    (\n        \"Assisted suicide should be a criminal offence\",\n        \"Assisted suicide should not be allowed because many times people can still get better\",\n        1,\n    ),\n    (\"Assisted suicide should be a criminal offence\", \"Assisted suicide is akin to killing someone\", 1),\n]\n\n# Go and embedd everything\noutput = encoder.encode(inputs, convert_to_numpy=True)\n```\n\nIn a [comparison](scripts/compare.py) with the baseline model-which directly uses sentence embedding from RoBERTa model, in a subset of ArgKP dataset (for avoiding target leakage), our model strongly outperforms and exhibits rich representation learning capacity. Evaluation metrics (relaxed and strict mean Average Precision) are retained from the [KPA_2021_shared_task](IBM/KPA_2021_shared_task).\n\n```abc\nModel using roBERTa directly: mAP strict = 0.4633403767342183 ; mAP relaxed = 0.5991767005443296\nOur pretrained model: mAP strict = 0.9170783671441644 ; mAP relaxed = 0.9722347939653511\n```\n\n### Detailed training\n\nGiven a pair of key point and argument (along with their supported topic & stance) and the matching score. Similar pairs with label 1 are pulled together, or pushed away otherwise.\n\n#### Model\n\n| Model               | BERT/ConvBERT               |  BORT           |  LUKE          |DistilBERT         | ALBERT             | XLNet            | RoBERTa                | ELECTRA            | BART            |MPNet            |\n| ------------------ | ------------------ | ------------------ | ------------------ | ------------------ | ------------------ | ------------------ | ------------------ | ------------------ | ------------------ | ------------------ |\n| Siamese Baseline            | ‚úîÔ∏è | ‚úîÔ∏è | ‚úîÔ∏è | ‚úîÔ∏è | ‚úîÔ∏è | ‚úîÔ∏è | ‚úîÔ∏è | ‚úîÔ∏è | ‚úîÔ∏è | ‚úîÔ∏è |\n| Siamese Question Answering-like              | ‚úîÔ∏è | ‚úîÔ∏è | ‚úîÔ∏è |‚úîÔ∏è| ‚úîÔ∏è | ‚úîÔ∏è | ‚úîÔ∏è | ‚úîÔ∏è | ‚úîÔ∏è | ‚úîÔ∏è |\n| Custom loss Baseline             | ‚úîÔ∏è | ‚úîÔ∏è | ‚úîÔ∏è | ‚úîÔ∏è | ‚úîÔ∏è | ‚úîÔ∏è | ‚úîÔ∏è | ‚úîÔ∏è | ‚úîÔ∏è | ‚úîÔ∏è |\n\n#### Loss\n\n- Constrastive\n- Online Constrastive\n- Triplet\n- Online Triplet (Hard negative/positive mining)\n\n#### Distance\n\n- Euclidean\n- Cosine\n- Manhattan\n\n#### Utils\n\n- K-folds\n- Full-flow\n\n### Pseudo-label\n\nGroup the arguments by their key point and consider the order of that key point within the topic as their labels (see [pseudo_label](qs_kpa/pseudo_label)). We can now utilize available Pytorch metrics learning distance, losses, miners or reducers from this great [open-source](https://github.com/KevinMusgrave/pytorch-metric-learning) in the main training workflow. For training, we use a key point and some of its positive/negative arguments as a batch. The goal is to minimize the distance between the keypoint and positive arguments as well as the arguments themselves. This is also our best approach (single-model) so far.\n\n![Model architecture](https://user-images.githubusercontent.com/52401767/129384453-514b8c80-f64c-4e52-80f5-6efb9a62985b.png)\n\n#### Training example\n\nAn example script for training RoBERTa on the ArgKP dataset. It runs in about 15 minutes each fold on a single Google Colab Tesla P100.\n\n```bash\nOUTPUT_DIR=outputs/pseudo_label/roberta-base/\n\necho \"OUTPUT DIRECTORY $OUTPUT_DIR\"\n\nmkdir -p $OUTPUT_DIR\n\ncp qs_kpa/pseudo_label/models.py  $OUTPUT_DIR\n\nfor fold_id in 1 2 3 4 5 6 7\ndo\n        echo \"TRAINING ON FOLD $fold_id\"\n        python scripts/main.py \\\n                --experiment \"pseudolabel\" \\\n                --output_dir \"$OUTPUT_DIR/fold_$fold_id\" \\\n                --model_name_or_path roberta-base \\\n                --tokenizer roberta-base \\\n                --distance \"cosine\" \\\n                --directory \"kpm_k_folds/fold_$fold_id\" \\\n                --test_directory \"kpm_k_folds/test/\" \\\n                --logging_dir \"$OUTPUT_DIR/fold_$fold_id\" \\\n                --logging_steps 20 \\\n                --max_pos 30 \\\n                --max_neg 90\\\n                --max_unknown 15 \\\n                --overwrite_output_dir \\\n                --num_train_epochs 5 \\\n                --early_stop 10 \\\n                --train_batch_size 1 \\\n                --val_batch_size 128 \\\n                --do_train \\\n                --evaluate_during_training \\\n                --warmup_steps 0 \\\n                --gradient_accumulation_steps 1 \\\n                --learning_rate 0.00003 \\\n                --margin 0.3 \\\n                --drop_rate 0.2 \\\n                --n_hiddens 4 \\\n                --max_len 30 \\\n                --statement_max_len 50 \\\n                --stance_dim 32 \\\n                --text_dim 256 \\\n                --num_workers 4 \\\n                --seed 0 \n\n\ndone\n```\n\nTraining with the previously defined hyper-parameters yields above mentioned mAP score. Other approaches could be found in [bin](bin).\n\n### Contributors\n\n- Phan Viet Hoang\n- Nguyen Duc Long\n\n### BibTeX\n\n```bibtex\n@misc{hoang2021qskpa,\n  author = {Phan, V.H. & Nguyen, D.L.},\n  title = {Keypoint Analysis},\n  year = {2021},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {\\url{https://github.com/VietHoang1512/KPA}}\n}\n```\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/VietHoang1512/KPA",
    "keywords": "",
    "license": "Apache License 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "qs-kpa",
    "package_url": "https://pypi.org/project/qs-kpa/",
    "platform": "",
    "project_url": "https://pypi.org/project/qs-kpa/",
    "project_urls": {
      "Homepage": "https://github.com/VietHoang1512/KPA"
    },
    "release_url": "https://pypi.org/project/qs-kpa/0.0.1/",
    "requires_dist": [
      "transformers (<5.0.0,>=4.1.0)",
      "tqdm",
      "torch (>=1.6.0)",
      "numpy",
      "sklearn",
      "scipy",
      "pandas",
      "gdown",
      "pytorch-metric-learning"
    ],
    "requires_python": ">=3.7",
    "summary": "Quantitative Summarization ‚Äì Key Point Analysis",
    "version": "0.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 11546250,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6c97709c5e97d9aeae290b13d6caa2557142125774fe8a0dafabc01cc9815351",
          "md5": "6e61baf28b7e296d942f05f834025185",
          "sha256": "d4d37a78355631ae26b776c44123cb1c2204c5cff00d39878f531e479e96ccbf"
        },
        "downloads": -1,
        "filename": "qs_kpa-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "6e61baf28b7e296d942f05f834025185",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 41322,
        "upload_time": "2021-09-25T09:27:01",
        "upload_time_iso_8601": "2021-09-25T09:27:01.949999Z",
        "url": "https://files.pythonhosted.org/packages/6c/97/709c5e97d9aeae290b13d6caa2557142125774fe8a0dafabc01cc9815351/qs_kpa-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a6354641a82e590e165e945b02fc002104c4a48495a1e1153b88c89e61e976c6",
          "md5": "b235c73a95362cb8f5f25dd78a978114",
          "sha256": "6bc0247f4dbfbc836d4b41fca080fe3c5c524087a34916179f1ac8150682e2fb"
        },
        "downloads": -1,
        "filename": "qs-kpa-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "b235c73a95362cb8f5f25dd78a978114",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 31363,
        "upload_time": "2021-09-25T09:27:03",
        "upload_time_iso_8601": "2021-09-25T09:27:03.662781Z",
        "url": "https://files.pythonhosted.org/packages/a6/35/4641a82e590e165e945b02fc002104c4a48495a1e1153b88c89e61e976c6/qs-kpa-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "6c97709c5e97d9aeae290b13d6caa2557142125774fe8a0dafabc01cc9815351",
        "md5": "6e61baf28b7e296d942f05f834025185",
        "sha256": "d4d37a78355631ae26b776c44123cb1c2204c5cff00d39878f531e479e96ccbf"
      },
      "downloads": -1,
      "filename": "qs_kpa-0.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "6e61baf28b7e296d942f05f834025185",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 41322,
      "upload_time": "2021-09-25T09:27:01",
      "upload_time_iso_8601": "2021-09-25T09:27:01.949999Z",
      "url": "https://files.pythonhosted.org/packages/6c/97/709c5e97d9aeae290b13d6caa2557142125774fe8a0dafabc01cc9815351/qs_kpa-0.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "a6354641a82e590e165e945b02fc002104c4a48495a1e1153b88c89e61e976c6",
        "md5": "b235c73a95362cb8f5f25dd78a978114",
        "sha256": "6bc0247f4dbfbc836d4b41fca080fe3c5c524087a34916179f1ac8150682e2fb"
      },
      "downloads": -1,
      "filename": "qs-kpa-0.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "b235c73a95362cb8f5f25dd78a978114",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 31363,
      "upload_time": "2021-09-25T09:27:03",
      "upload_time_iso_8601": "2021-09-25T09:27:03.662781Z",
      "url": "https://files.pythonhosted.org/packages/a6/35/4641a82e590e165e945b02fc002104c4a48495a1e1153b88c89e61e976c6/qs-kpa-0.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}