{
  "info": {
    "author": "Andrew Moore",
    "author_email": "andrew.p.moore94@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: Apache Software License",
      "Natural Language :: English",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8"
    ],
    "description": "# Science Parse Python API\n> A Python API for the <a href='https://github.com/allenai/science-parse'>Science Parse server</a>.\n\n\n<p align=\"center\">\n    <a href=\"https://github.com/UCREL/science_parse_py_api/actions/workflows/main.yml\"> <img alt=\"CI\" src=\"https://github.com/UCREL/science_parse_py_api/actions/workflows/main.yml/badge.svg?branch=master&event=push\"></a>    \n    <a href=\"https://codecov.io/gh/UCREL/science_parse_py_api\"> <img alt=\"Codecov\" src=\"https://codecov.io/gh/UCREL/science_parse_py_api/branch/master/graph/badge.svg\"></a>\n    <a href=\"https://github.com/UCREL/science_parse_py_api/blob/master/LICENSE\"> <img alt=\"License\" src=\"https://img.shields.io/github/license/UCREL/science_parse_py_api\"></a>\n</p>\n\n<p align=\"center\">\n    <a href=\"https://pypi.org/project/science_parse_api/\"> <img alt=\"PyPi\" src=\"https://img.shields.io/pypi/v/science_parse_api\"> </a>\n    <a href=\"https://pypi.org/project/science_parse_api/\"> <img alt=\"Supported Python Versions\" src=\"https://img.shields.io/pypi/pyversions/science_parse_api\"> </a>\n</p>\n\n## Install\n\n`pip install science_parse_api`\n\n## Requirements\n\nThis also requires that you have a science parse server running. This can be done through docker:\n\n```\ndocker run -p 127.0.0.1:8080:8080 --rm --init ucrel/ucrel-science-parse:3.0.1\n```\n\nFor versions of Science Parse < 3.0.1 see the [AllenAI docker hub](https://hub.docker.com/r/allenai/scienceparse).\n\nIf you would like to run the docker image with less memory (default is 8GB) then the following command will run it with a limit of 6GB:\n\n```\ndocker run -p 127.0.0.1:8080:8080 --rm --init --memory=6g --memory-swap=6g --env JAVA_MEMORY=5 ucrel/ucrel-science-parse:3.0.1\n```\n\nFor more details on this docker image see the [UCREL docker hub page](https://hub.docker.com/r/ucrel/ucrel-science-parse).\n\n**Note** from the [science parse GitHub](https://github.com/allenai/science-parse/tree/master/cli#memory) it is recomended to run the science parse server with 6GB of memory for the Java process e.g. `JAVA_MEMORY=6`\n\n## How to use\n\nThe API has only one main function: `parse_pdf`. \n\nIt takes an input the:\n1. **server_address** -- Address to the science parse server e.g. \"http://127.0.0.1\"\n2. **file_path_to_pdf** -- The file path to the PDF you would like to parse.\n3. **port** -- Port of the science parse server e.g. \"8080\" \n\nIt will then return the parsed PDF as a Python dictionary with the following keys:\n\n```python\n['abstractText', 'authors', 'id', 'references', 'sections', 'title', 'year']\n```\n\n**Note** not all of these dictionary keys will always exist if science parse cannot detect the relevant information e.g. if it cannot find any references then there will be no reference key.\n\n## Example\n\nThe example below shows how to use the `pdf_parse` function and the expected output format. In this example we ran the science parse server using docker e.g.:\n\n```\ndocker run -p 127.0.0.1:8080:8080 --rm --init ucrel/ucrel-science-parse:3.0.1\n```\n\n```\nfrom pathlib import Path\nimport tempfile\n\nfrom IPython.display import Image\nimport requests\n\nfrom science_parse_api.test_helper import test_data_dir\n\ntry:\n    # Tries to find the folder `test_data`\n    test_data_directory = test_data_dir()\n    test_pdf_paper = Path(test_data_directory, \n                      'example_for_test.pdf').resolve()\n    image_file_name = str(Path(test_data_directory, \n                               'example_test_pdf_as_png.png'))\nexcept FileNotFoundError:\n    # If it cannot find that folder will get the pdf and \n    # image from Github. This will occur if you are using \n    # Google Colab\n    pdf_url = ('https://github.com/UCREL/science_parse_py_api/'\n               'raw/master/test_data/example_for_test.pdf')\n    temp_test_pdf_paper = tempfile.NamedTemporaryFile('rb+')\n    test_pdf_paper = Path(temp_test_pdf_paper.name)\n    with test_pdf_paper.open('rb+') as test_fp:\n        test_fp.write(requests.get(pdf_url).content)\n\n    image_url = ('https://github.com/UCREL/science_parse_py_api'\n                 '/raw/master/test_data/example_test_pdf_as_png.png')\n    image_file = tempfile.NamedTemporaryFile('rb+', suffix='.png')\n    with Path(image_file.name).open('rb+') as image_fp:\n        image_fp.write(requests.get(image_url).content)\n    image_file_name = image_file.name\n\n\nImage(filename=image_file_name)\n```\n\n\n\n\n![png](docs/images/output_7_0.png)\n\n\n\n```\nimport pprint\nfrom science_parse_api.api import parse_pdf\n\nhost = 'http://127.0.0.1'\nport = '8080'\noutput_dict = parse_pdf(host, test_pdf_paper, port=port)\n\npp = pprint.PrettyPrinter(indent=4)\npp.pprint(output_dict)\n```\n\n    {   'abstractText': 'The abstract which is normally short.',\n        'authors': [{'affiliations': [], 'name': 'Andrew Moore'}],\n        'id': 'SP:1499421a494e54e17ee903b5161ccb31091fb77a',\n        'references': [   {   'authors': [   'Tomas Mikolov',\n                                             'Greg Corrado',\n                                             'Kai Chen',\n                                             'Jeffrey Dean.'],\n                              'title': 'Efficient estimation of word '\n                                       'representations in vector space',\n                              'venue': 'Proceedings of the International '\n                                       'Conference on Learning Representations, '\n                                       'pages 1–12.',\n                              'year': 2013}],\n        'sections': [   {   'text': 'The abstract which is normally short.\\n'\n                                    '1 Introduction\\n'\n                                    'Some introduction text.\\n'\n                                    '2 Section 1\\n'\n                                    'Here is some example text.'},\n                        {   'heading': '2.1 Sub Section 1',\n                            'text': 'Some more text but with a reference (Mikolov '\n                                    'et al., 2013).\\n'\n                                    '3 Section 2\\n'\n                                    'The last section\\n'\n                                    'References\\n'\n                                    'Tomas Mikolov, Greg Corrado, Kai Chen, and '\n                                    'Jeffrey Dean. 2013. Efficient estimation of '\n                                    'word representations in vector space. '\n                                    'Proceedings of the International Conference '\n                                    'on Learning Representations, pages 1–12.'}],\n        'title': 'Example paper for testing',\n        'year': 2021}\n\n\nThe output is not perfect but it is very good! Some of the things it did not pick up on:\n\n1. The `authors` key never seems to get the affiliations of the authors (I have tried a few papers).\n2. The sections are a list of sections and each section is made up of `text` and `heading`. However as this example shows it appears that these keys are not always guaranteed e.g. the first section only contains a `text` key.\n3. The sections in this example does not contain all of the sections.\n4. The last section also contains the References.\n5. The output of the `authors` from `references` contains all of the correct authors. However one small issue is that `Jeffrey Dean` has a full stop at the end e.g. `Jeffrey Dean.`\n\nSome of the really nice features:\n\n1. Creates a unique `id` key based on hashing the request to the Science Parse server thus each request to the server will create a unique `id`.\n2. The `year` key contains a python `int` e.g. `2021` and `2013`. \n\n## Uses of Science Parse\n\nScience Parse has been used in the following academic papers:\n\n1. [S2ORC: The Semantic Scholar Open Research Corpus](https://www.aclweb.org/anthology/2020.acl-main.447.pdf). They used Science Parse to extract title and authors from the PDF of academic papers. They then used [Grobid](https://grobid.readthedocs.io/en/latest/) to extract the rest of the data from the PDFs.\n\n## Development\n\nIf you would like to develop on this library. Clone the repository and then install the regular requirements and the development requirements using:\n\n``` bash\npip install -e .[dev]\n```\n\n[The `-e` is an editable flag](http://codumentary.blogspot.com/2014/11/python-tip-of-year-pip-install-editable.html) meaning that if you change anything in the library locally Python will keep track on those changes.\n\n### Package is created with nbdev\n\n**Note** as it is created with nbdev the code and documentation is generated from the notebooks that are within the [./module_notebooks folder](./module_notebooks).\n\n**Note** need to run the following once: `nbdev_install_git_hooks`: [\"This will set up git hooks which will remove metadata from your notebooks when you commit, greatly reducing the chance you have a conflict.\"](https://nbdev.fast.ai/tutorial.html#Install-git-hooks-to-avoid-and-handle-conflicts)\n\nThe main workflow is the following:\n\n1. Edit the notebook(s) you want within [./module_notebooks folder.](./module_notebooks) **The README is generated from the [./module_notebooks/index.ipynb file.](./module_notebooks/index.ipynb)**\n2. Run `nbdev_build_lib` to convert the notebook(s) into a Python module, which in this case will go into the [./science_parse_api folder](./science_parse_api). **Note** if you created a function in one python module and want to use it in another module then you will need to run `nbdev_build_lib` first, as that python module code needs to be transfered from the [./module_notebooks folder.](./module_notebooks) into the [./science_parse_api folder](./science_parse_api).\n3. Create the documentation using `nbdev_build_docs`.\n4. **Optionally** if you created tests run them using `make test`. When you do add tests in the notebooks you will need to import the function from the module and not rely on the function already expressed in the notebook, this is to ensure that code coverage is calculated correctly.\n5. **Optionally** if you would like to see the documentation locally see the [sub-section below.](#local-documentation)\n6. Git add the relevant notebook(s), python module code, and documentation.\n\n### Local documentation\n\nThe documentation can be ran locally via a docker container. The easiest way to run this container is through the make command:\n\n``` bash\nmake docker_docs_serve\n```\n\n**NOTE** This documentation does not update automatically, so it requires re-running this make command each time you want to see an updated version of the documentation.\n\n### PYPI Package release\n\nTo release an updated version of the package:\n\n1. Change the version number in [./settings.ini](./settings.ini)\n2. Build the library using `nbdev_build_lib`\n3. Then make the package and upload it to PYPI using `make release`\n\n## Acknowledgement\n\nThe work has been funded by the [UCREL research centre at Lancaster University](http://ucrel.lancs.ac.uk/).\n\nWe would like to thank the AllenAI institute for creating the [Science Parse software.](https://github.com/allenai/science-parse)\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/UCREL/science_parse_py_api/tree/master/",
    "keywords": "natural-language-processing nlp",
    "license": "Apache Software License 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "science-parse-api",
    "package_url": "https://pypi.org/project/science-parse-api/",
    "platform": "",
    "project_url": "https://pypi.org/project/science-parse-api/",
    "project_urls": {
      "Homepage": "https://github.com/UCREL/science_parse_py_api/tree/master/"
    },
    "release_url": "https://pypi.org/project/science-parse-api/1.0.1/",
    "requires_dist": [
      "requests",
      "nbdev ; extra == 'dev'",
      "responses ; extra == 'dev'",
      "pytest ; extra == 'dev'",
      "pytest-cov ; extra == 'dev'",
      "twine ; extra == 'dev'"
    ],
    "requires_python": ">=3.6",
    "summary": "Python API for Science Parse",
    "version": "1.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12089849,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "58f0114271f452707375cf9eb46f36320853af860abbc2fce710f962c2643e7d",
          "md5": "8f923ba956ce6306b376fa42183684b5",
          "sha256": "bee2b065a2ac693b07343b9664e41859df984646396b3dcb58014af4156a7b0e"
        },
        "downloads": -1,
        "filename": "science_parse_api-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "8f923ba956ce6306b376fa42183684b5",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 11916,
        "upload_time": "2021-03-09T19:19:40",
        "upload_time_iso_8601": "2021-03-09T19:19:40.950675Z",
        "url": "https://files.pythonhosted.org/packages/58/f0/114271f452707375cf9eb46f36320853af860abbc2fce710f962c2643e7d/science_parse_api-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2450ee332fd52d432b2f3a914ab3b37f485e980d1a75648eb4d961332531c516",
          "md5": "ba1c6e049a4b831776e9742196258ed3",
          "sha256": "bbe559237a0bcb2562ee3db608c38a57af7a88cc3ae931023f2f59773c155109"
        },
        "downloads": -1,
        "filename": "science_parse_api-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "ba1c6e049a4b831776e9742196258ed3",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 12651,
        "upload_time": "2021-03-09T19:19:42",
        "upload_time_iso_8601": "2021-03-09T19:19:42.502535Z",
        "url": "https://files.pythonhosted.org/packages/24/50/ee332fd52d432b2f3a914ab3b37f485e980d1a75648eb4d961332531c516/science_parse_api-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "85161c998630febbab2e99409aba44e9dd96244c45511cdb683b5ad42a6a84a1",
          "md5": "96aa1e0d48696d2294bbfdc4eb0d7751",
          "sha256": "ddcd307db6be66a15212e45be83592b4f5842d59341b9683aeab32593a77b14e"
        },
        "downloads": -1,
        "filename": "science_parse_api-1.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "96aa1e0d48696d2294bbfdc4eb0d7751",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 12010,
        "upload_time": "2021-03-10T09:27:27",
        "upload_time_iso_8601": "2021-03-10T09:27:27.535851Z",
        "url": "https://files.pythonhosted.org/packages/85/16/1c998630febbab2e99409aba44e9dd96244c45511cdb683b5ad42a6a84a1/science_parse_api-1.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a7c3ead0c16fa94b54e7c7a6f910f7c0ffacfc8a959f16c7cc4187e7a490fdc9",
          "md5": "42f31cfd20112cb731c96b828425fa23",
          "sha256": "52cabb4c3dd90dd59f3002ac444cd2dbfb06b336e239701bcd666700cc135320"
        },
        "downloads": -1,
        "filename": "science_parse_api-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "42f31cfd20112cb731c96b828425fa23",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 12779,
        "upload_time": "2021-03-10T09:27:28",
        "upload_time_iso_8601": "2021-03-10T09:27:28.711866Z",
        "url": "https://files.pythonhosted.org/packages/a7/c3/ead0c16fa94b54e7c7a6f910f7c0ffacfc8a959f16c7cc4187e7a490fdc9/science_parse_api-1.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fd05792e7c6a4ae9bfdadead7806456e3d1edf481757655ed43c7f510b36bfa3",
          "md5": "6199a54992752e1b8b2369ed1af6e8d3",
          "sha256": "9d92e53a701b33509d185557fd38aed2aac16ea1874172a92bd3ebcacd63604a"
        },
        "downloads": -1,
        "filename": "science_parse_api-1.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "6199a54992752e1b8b2369ed1af6e8d3",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 12020,
        "upload_time": "2021-03-27T08:42:50",
        "upload_time_iso_8601": "2021-03-27T08:42:50.528744Z",
        "url": "https://files.pythonhosted.org/packages/fd/05/792e7c6a4ae9bfdadead7806456e3d1edf481757655ed43c7f510b36bfa3/science_parse_api-1.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "320c1d31c2b1c3eef71e4f215fddf999a8ff53e7df29ba139fd779d0be32ea99",
          "md5": "05eb2295f12e6d4db1acf2fb8a0a7690",
          "sha256": "0be362480c3154449cdca77e4addd948c97f86e2dd8d22a61e6e4eec4aaa0136"
        },
        "downloads": -1,
        "filename": "science_parse_api-1.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "05eb2295f12e6d4db1acf2fb8a0a7690",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 13683,
        "upload_time": "2021-03-27T08:42:51",
        "upload_time_iso_8601": "2021-03-27T08:42:51.948360Z",
        "url": "https://files.pythonhosted.org/packages/32/0c/1d31c2b1c3eef71e4f215fddf999a8ff53e7df29ba139fd779d0be32ea99/science_parse_api-1.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "fd05792e7c6a4ae9bfdadead7806456e3d1edf481757655ed43c7f510b36bfa3",
        "md5": "6199a54992752e1b8b2369ed1af6e8d3",
        "sha256": "9d92e53a701b33509d185557fd38aed2aac16ea1874172a92bd3ebcacd63604a"
      },
      "downloads": -1,
      "filename": "science_parse_api-1.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "6199a54992752e1b8b2369ed1af6e8d3",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 12020,
      "upload_time": "2021-03-27T08:42:50",
      "upload_time_iso_8601": "2021-03-27T08:42:50.528744Z",
      "url": "https://files.pythonhosted.org/packages/fd/05/792e7c6a4ae9bfdadead7806456e3d1edf481757655ed43c7f510b36bfa3/science_parse_api-1.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "320c1d31c2b1c3eef71e4f215fddf999a8ff53e7df29ba139fd779d0be32ea99",
        "md5": "05eb2295f12e6d4db1acf2fb8a0a7690",
        "sha256": "0be362480c3154449cdca77e4addd948c97f86e2dd8d22a61e6e4eec4aaa0136"
      },
      "downloads": -1,
      "filename": "science_parse_api-1.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "05eb2295f12e6d4db1acf2fb8a0a7690",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 13683,
      "upload_time": "2021-03-27T08:42:51",
      "upload_time_iso_8601": "2021-03-27T08:42:51.948360Z",
      "url": "https://files.pythonhosted.org/packages/32/0c/1d31c2b1c3eef71e4f215fddf999a8ff53e7df29ba139fd779d0be32ea99/science_parse_api-1.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}