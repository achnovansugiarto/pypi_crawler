{
  "info": {
    "author": "big-o",
    "author_email": "big-o@users.noreply.github.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Environment :: Console",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: GNU General Public License v3 (GPLv3)",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Topic :: Scientific/Engineering :: Artificial Intelligence",
      "Topic :: Scientific/Engineering :: Information Analysis",
      "Topic :: Text Processing :: Linguistic"
    ],
    "description": "========\nTransvec\n========\n\nCombine pre-trained word embedding models for different languages to vectorise\nmulti-language documents.\n\nThis package includes a python implementation of the the method outlined in `MLS2013`_,\nwhich allows for word embeddings from one model to be translated to the vector space of\nanother model.\n\nThis allows you to combine word embeddings from different languages, avoiding the\nexpense and complexity of training bilingual models. With ``transvec``, you can simply\nuse pre-trained `Word2Vec <https://radimrehurek.com/gensim/models/word2vec.html>`_\nmodels for different languages to measure the similarity of words in different\nlanguages and produce document vectors for mixed-language text.\n\nInstallation\n------------\n\n.. code-block:: bash\n\n    pip install transvec\n\nExample\n-------\n\nLet's say we want to study a corpus of text that contains a mix of Russian and English.\n``gensim`` has pre-trained models for both languages:\n\n.. code-block:: python\n\n    >>> import gensim.downloader\n    >>> ru_model = gensim.downloader.load(\"word2vec-ruscorpora-300\")\n    >>> en_model = gensim.downloader.load(\"glove-wiki-gigaword-300\")\n\nNow assume you don't have the resources to train a single model that understands both\nlanguages well (and you probably don't). It would be nice to take advantage of the\nknowledge we have in these two pre-trained models instead. Let's use the Russian model\nto compare Russian words and the English model to compare English words:\n\n.. code-block:: python\n\n    >>> en_model.similar_by_word(\"king\", 1)\n    [('queen', 0.6336469054222107)]\n\n    >>> ru_model.similar_by_word(\"царь_NOUN\", 1) # \"king\"\n    [('царица_NOUN', 0.7304918766021729)] # \"queen\"\n\nAs advertised, the models correctly find words with a similar meaning. What if\nwe now wish to compare words from different languages?\n\n.. code-block:: python\n\n    >>> ru_model.similar_by_word(\"king\", 1)\n    Traceback (most recent call last):\n        ...\n    KeyError: \"word 'king' not in vocabulary\"\n\nIt doesn't work, because the Russian model was not trained on English words. We could\nof course convert our word to a vector in the English model, and then look for the most\nsimilar vector in our corpus:\n\n.. code-block:: python\n\n    >>> king_vector = en_model.get_vector(\"king\")\n    >>> ru_model.similar_by_vector(king_vector, 1)\n    [('непроизводительный_ADJ', 0.21217751502990723)]\n\nOur result (which appropriately means `\"unproductive\"`) makes no sense at all. The\nmeaning is nothing like our input word. Why did this happen? Because the \"king\" vector\nis defined by the vector space of the English model, which has nothing to do with the\nvector space of the Russian model. Output from the two models is completely\nuncomparable. To remedy this, we must translate the vector from the `source` space\n(English in the above case) into the `target` space (Russian).\n\nThis is where ``transvec`` can help you. By providing pairs of words in the source\nlanguage along with their translation into the target language, ``transvec`` can train a\nmodel that will translate the vector for a word in the source language to a vector in\nthe target language:\n\n.. code-block:: python\n\n    >>> from transvec.transformers import TranslationWordVectorizer\n\n    >>> train = [\n    ...     (\"king\", \"царь_NOUN\"), (\"tsar\", \"царь_NOUN\"),\n    ...     (\"man\", \"мужчина_NOUN\"), (\"woman\", \"женщина_NOUN\")\n    ... ]\n\n    >>> bilingual_model = TranslationWordVectorizer(en_model, ru_model).fit(train)\n\nFor the convenience of English speakers, we have defined English to be our target\nlanguage in this case. This will create a model that can take inputs in either language,\nbut its output will always be in English.\n\n.. note::\n    The models in our example both produce vectors with the same number of dimensions:\n    this is not required by the TranslationWordVectorizer, and models with different\n    dimensionality may be mixed. The output of the TranslationWordVectorizer will\n    always have the same dimensionality as the target model.\n\nNow we can make comparisons across both languages:\n\n.. code-block:: python\n\n    >>> bilingual_model.similar_by_word(\"царь_NOUN\", 1) # \"tsar\"\n    [('king', 0.8043200969696045)]\n\nIf the provided word does not exist in the source corpus, but does exist in the target\ncorpus, the model will fall back to using the target language's vector:\n\n.. code-block:: python\n\n    >>> bilingual_model.similar_by_word(\"king\", 1)\n    [('queen', 0.6336469054222107)]\n\nWe can also get sensible results for words that aren't in our training set (the\nquality will depend on how comprehensive your training word pairs are):\n\n.. code-block:: python\n\n    >>> bilingual_model.similar_by_word(\"царица_NOUN\", 1) # \"queen\"\n    [('king', 0.7763221263885498)]\n\nNote that you can provide regularisation parameters to the `TranslationWordVectorizer`\nto help improve these results if you need to.\n\n\nExtra features\n--------------\n\nBulk vectorisation\n++++++++++++++++++\n\nFor convenience, ``TranslationWordVectorizer`` also implements the `scikit-learn`\n``Transformer`` API, allowing you to vectorise large sets of data in a pipeline easily.\nIf you provide a 2D matrix of words, it will assume each row represents a single\ndocument and produce a single vector for each row, which is just the mean of all of the\nword vectors in the document (this is a simple, cheap way of approximating document\nvectors when your documents contain multiple languages).\n\nMultilingual models\n+++++++++++++++++++\n\nThe example above converts a single source language into a target language. You can\nhowever train a model that recognises multiple source languages instead. Simply provide\nmore than one source language when you initialise the model. Source languages will be\nprioritised in the order you define them. Note that your training data must now contain\nword tuples rather than word pairs; the order of the languages matching the order of\nyour models.\n\nHow does it work?\n-----------------\n\nThe full details are outlined in `MLS2013`_, but basically it's just Ordinary Least\nSquares. The paper notes that a linear relationship exists between the vector spaces of\nmonolingual models, meaning that a simple translation matrix can be used to convert a\nvector from its native vector space to a similar point in a target vector space, placing\nit close to words in the target language with similar meanings.\n\nUnlike the original paper, ``transvec`` uses ridge regression rather than OLS to derive\nthis translation matrix: this is to help prevent overfitting if you only have a small\nset of training word pairs. If you want to use OLS instead, simply set the\nregularization parameter (``alpha``) to zero in the ``TranslationWordVectorizer``\nconstructor.\n\nReferences\n----------\n\n.. [MLS2013] `Tomas Mikolov, Quoc V Le, Ilya Sutskever. 2013.\n        Exploiting Similarities among Languages for Machine Translation\n        <https://arxiv.org/pdf/1309.4168.pdf>`_\n\n\n",
    "description_content_type": "",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "http://github.com/big-o/transvec",
    "keywords": "Translation,Machine Translation,Bilingual,Multilingual,Singular Value Decomposition,SVD,Latent Semantic Indexing,LSA,LSI,Latent Dirichlet Allocation,LDA,Hierarchical Dirichlet Process,HDP,Random Projections,TFIDF,word2vec,doc2vec",
    "license": "GNU GPLv3",
    "maintainer": "",
    "maintainer_email": "",
    "name": "transvec",
    "package_url": "https://pypi.org/project/transvec/",
    "platform": "",
    "project_url": "https://pypi.org/project/transvec/",
    "project_urls": {
      "Homepage": "http://github.com/big-o/transvec"
    },
    "release_url": "https://pypi.org/project/transvec/0.1.0/",
    "requires_dist": [
      "nltk (>=3.5)",
      "numpy",
      "scikit-learn"
    ],
    "requires_python": ">=3.7",
    "summary": "Multilingual word embeddings.",
    "version": "0.1.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 7983027,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a636ee1b7a40e8ebad25c4892550f57fcc57928769ed7e4d716d269c62943930",
          "md5": "cd48d753b8f389ed7b54dbc4b741743b",
          "sha256": "271b088c054f0097516f0a171a524afc0b8a838890f29e77eb91137d005575f8"
        },
        "downloads": -1,
        "filename": "transvec-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "cd48d753b8f389ed7b54dbc4b741743b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 21217,
        "upload_time": "2020-05-16T10:17:56",
        "upload_time_iso_8601": "2020-05-16T10:17:56.042835Z",
        "url": "https://files.pythonhosted.org/packages/a6/36/ee1b7a40e8ebad25c4892550f57fcc57928769ed7e4d716d269c62943930/transvec-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a4533ef3789d6b47059f03f0853914cb55300b7a6f990bf45b2c50bb1f957738",
          "md5": "dbbbb277a986828e21da4e3e271eb5c9",
          "sha256": "2dccbc57a3062711a722a57635a6dbf105283d022d4e6f435652270e675e1505"
        },
        "downloads": -1,
        "filename": "transvec-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "dbbbb277a986828e21da4e3e271eb5c9",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 11637,
        "upload_time": "2020-05-16T10:17:58",
        "upload_time_iso_8601": "2020-05-16T10:17:58.494368Z",
        "url": "https://files.pythonhosted.org/packages/a4/53/3ef3789d6b47059f03f0853914cb55300b7a6f990bf45b2c50bb1f957738/transvec-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "64e3e2391255b87178ca86aaaeba989407394930729e21355907f2470ada346a",
          "md5": "68f2c92c6e4312680f692d20cdf24f62",
          "sha256": "5a452a6382fe12dd5180d2e03e4a729d54210053c3f8e783f0af93cd81f26bc5"
        },
        "downloads": -1,
        "filename": "transvec-0.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "68f2c92c6e4312680f692d20cdf24f62",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 21372,
        "upload_time": "2020-05-16T10:26:09",
        "upload_time_iso_8601": "2020-05-16T10:26:09.376982Z",
        "url": "https://files.pythonhosted.org/packages/64/e3/e2391255b87178ca86aaaeba989407394930729e21355907f2470ada346a/transvec-0.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3b18884ff1a3da408e71c8c5ff587dc2ba75186284d1f8fdbc7ef27207a0d9d4",
          "md5": "57fb2d3777831da1b16c03cbb654a13a",
          "sha256": "fd92460f2d30d02879f4538738b88537bf91fe4ba44841349dd167f0cc0298c0"
        },
        "downloads": -1,
        "filename": "transvec-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "57fb2d3777831da1b16c03cbb654a13a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 11967,
        "upload_time": "2020-05-16T10:26:10",
        "upload_time_iso_8601": "2020-05-16T10:26:10.916413Z",
        "url": "https://files.pythonhosted.org/packages/3b/18/884ff1a3da408e71c8c5ff587dc2ba75186284d1f8fdbc7ef27207a0d9d4/transvec-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0dac7a9aab6c0940a879acc6691aa580bc0c5ce0fd5613da419baf1eefd3b665",
          "md5": "01e6648d5d2f86846cac952f02f2f19f",
          "sha256": "d9e3e4e57826ba61aba4999308d125b7bfe1afa9c600cabc2b3e33b0a0ef5862"
        },
        "downloads": -1,
        "filename": "transvec-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "01e6648d5d2f86846cac952f02f2f19f",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 21438,
        "upload_time": "2020-08-17T20:59:09",
        "upload_time_iso_8601": "2020-08-17T20:59:09.452767Z",
        "url": "https://files.pythonhosted.org/packages/0d/ac/7a9aab6c0940a879acc6691aa580bc0c5ce0fd5613da419baf1eefd3b665/transvec-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3722ee1688217972e3c387075c448a51389be3074466febc4d60b228c9d02a7a",
          "md5": "bd95b5ec4d2c00ed3d80be266739bac5",
          "sha256": "1a71552ea1943a5ccb8c7de0cdf519b4358c8fec7610f83089d98f88265e0e87"
        },
        "downloads": -1,
        "filename": "transvec-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "bd95b5ec4d2c00ed3d80be266739bac5",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 12126,
        "upload_time": "2020-08-17T20:59:10",
        "upload_time_iso_8601": "2020-08-17T20:59:10.997421Z",
        "url": "https://files.pythonhosted.org/packages/37/22/ee1688217972e3c387075c448a51389be3074466febc4d60b228c9d02a7a/transvec-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "0dac7a9aab6c0940a879acc6691aa580bc0c5ce0fd5613da419baf1eefd3b665",
        "md5": "01e6648d5d2f86846cac952f02f2f19f",
        "sha256": "d9e3e4e57826ba61aba4999308d125b7bfe1afa9c600cabc2b3e33b0a0ef5862"
      },
      "downloads": -1,
      "filename": "transvec-0.1.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "01e6648d5d2f86846cac952f02f2f19f",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 21438,
      "upload_time": "2020-08-17T20:59:09",
      "upload_time_iso_8601": "2020-08-17T20:59:09.452767Z",
      "url": "https://files.pythonhosted.org/packages/0d/ac/7a9aab6c0940a879acc6691aa580bc0c5ce0fd5613da419baf1eefd3b665/transvec-0.1.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "3722ee1688217972e3c387075c448a51389be3074466febc4d60b228c9d02a7a",
        "md5": "bd95b5ec4d2c00ed3d80be266739bac5",
        "sha256": "1a71552ea1943a5ccb8c7de0cdf519b4358c8fec7610f83089d98f88265e0e87"
      },
      "downloads": -1,
      "filename": "transvec-0.1.0.tar.gz",
      "has_sig": false,
      "md5_digest": "bd95b5ec4d2c00ed3d80be266739bac5",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 12126,
      "upload_time": "2020-08-17T20:59:10",
      "upload_time_iso_8601": "2020-08-17T20:59:10.997421Z",
      "url": "https://files.pythonhosted.org/packages/37/22/ee1688217972e3c387075c448a51389be3074466febc4d60b228c9d02a7a/transvec-0.1.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}