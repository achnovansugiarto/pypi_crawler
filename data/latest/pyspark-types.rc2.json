{
  "info": {
    "author": "Dan",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.11"
    ],
    "description": "# PySpark Types\n\n`pyspark_types` is a Python library that provides a simple way to map Python dataclasses to PySpark StructTypes.\n\n## Usage\n\n### Pydantic\nPySparkBaseModel is a base class for PySpark models that provides methods for converting between PySpark Rows and Pydantic models.\n\nHere's an example of a Pydantic model that will be used to create a PySpark DataFrame:\n\n```python\nfrom pyspark_types.auxiliary import BoundDecimal\nfrom pyspark_types.pydantic import PySparkBaseModel\n\n\nclass Person(PySparkBaseModel):\n    name: str\n    age: int\n    addresses: dict[str, str]\n    salary: BoundDecimal\n\n```\n\nTo create a PySpark DataFrame from a list of Person Pydantic models, we can use PySparkBaseModel.create_spark_dataframe() method.\n\n```python\nfrom pyspark.sql import SparkSession\n\nspark = SparkSession.builder.appName(\"MyApp\").getOrCreate()\n\n# create a list of Pydantic models\ndata = [\n    Person(\n        name=\"Alice\",\n        age=25,\n        addresses={\"home\": \"123 Main St\", \"work\": \"456 Pine St\"},\n        salary=BoundDecimal(\"5000.00\", precision=10, scale=2),\n    ),\n    Person(\n        name=\"Bob\",\n        age=30,\n        addresses={\"home\": \"789 Elm St\", \"work\": \"321 Oak St\"},\n        salary=BoundDecimal(\"6000.50\", precision=10, scale=2),\n    ),\n]\n\n# create a PySpark DataFrame from the list of Pydantic models\ndf = Person.create_spark_dataframe(data, spark)\n\n# show the contents of the DataFrame\ndf.show()\n\n```\n\nOutput: \n```bash\n+---+-----+--------------------+------+\n|age| name|           addresses|salary|\n+---+-----+--------------------+------+\n| 25|Alice|[home -> 123 Main...|5000.00|\n| 30|  Bob|[home -> 789 Elm ...|6000.50|\n+---+-----+--------------------+------+\n\n```\n\nThe PySparkBaseModel.create_spark_dataframe() method converts the list of Pydantic models to a list of dictionaries, and then creates a PySpark DataFrame from the list of dictionaries and schema generated from the Pydantic model.\n\nYou can also generate a schema based on a Pydantic model by calling the PySparkBaseModel.schema() method:\n```python\nschema = PySparkBaseModel.schema(Person)\n\n```\n\nThis creates a PySpark schema for the Person Pydantic model.\n\nNote that if you have custom types, such as BoundDecimal, you will need to add support for them in PySparkBaseModel. For example, you can modify the PySparkBaseModel.dict() method to extract BoundDecimal values when mapping to DecimalType.\n### Dataclasses\n\nTo use pyspark_types, you first need to define a Python data class with the fields you want to map to PySpark. For example:\n\n```python\nfrom dataclasses import dataclass\n\n@dataclass\nclass Person:\n    name: str\n    age: int\n    is_student: bool\n\n```\nTo map this data class to a PySpark StructType, you can use the map_dataclass_to_struct() function:\n\n```python\nfrom pyspark_types import map_dataclass_to_struct\n\nperson_struct = map_dataclass_to_struct(Person)\n```\n\nThis will return a PySpark StructType that corresponds to the Person data class.\n\nYou can also use the apply_nullability() function to set the nullable flag for a given PySpark DataType:\n\n```python\nfrom pyspark.sql.types import StringType\nfrom pyspark_types import apply_nullability\n\nnullable_string_type = apply_nullability(StringType(), True)\n```\n\nThis will return a new PySpark StringType with the nullable flag set to True.\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "pyspark-types",
    "package_url": "https://pypi.org/project/pyspark-types/",
    "platform": null,
    "project_url": "https://pypi.org/project/pyspark-types/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/pyspark-types/0.0.2/",
    "requires_dist": [
      "black (>=23.1.0,<24.0.0)",
      "pydantic (>=1.10.5,<2.0.0)",
      "pyspark (>=3.3.2,<4.0.0)",
      "pytest (>=7.2.1,<8.0.0)"
    ],
    "requires_python": ">=3.10,<4.0",
    "summary": "`pyspark_types` is a Python library that provides a simple way to map Python dataclasses to PySpark StructTypes",
    "version": "0.0.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17142490,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fbb190388c0f77d83060a7539cc7593fe4f3d9db7213e1df87968b40598fff08",
          "md5": "d1541a76c6d5a2bd94c70cc929588476",
          "sha256": "382fc93fd46890b49ea8e94e8f2a120e2882521c8fdf6259189446419354b5aa"
        },
        "downloads": -1,
        "filename": "pyspark_types-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d1541a76c6d5a2bd94c70cc929588476",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.10,<4.0",
        "size": 6351,
        "upload_time": "2023-03-03T10:02:51",
        "upload_time_iso_8601": "2023-03-03T10:02:51.658244Z",
        "url": "https://files.pythonhosted.org/packages/fb/b1/90388c0f77d83060a7539cc7593fe4f3d9db7213e1df87968b40598fff08/pyspark_types-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "91cf4e384709bc0a14acab5edcd0d92fce3b93ae323eafbaeaeeb50c7dc0d7e8",
          "md5": "70526e2761f1063d4d7848d7d612580b",
          "sha256": "2ec41e886f4d52accbe6fc6a7c0dc1e042126369cf98cbd389d7640302270a75"
        },
        "downloads": -1,
        "filename": "pyspark_types-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "70526e2761f1063d4d7848d7d612580b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.10,<4.0",
        "size": 4814,
        "upload_time": "2023-03-03T10:02:53",
        "upload_time_iso_8601": "2023-03-03T10:02:53.700475Z",
        "url": "https://files.pythonhosted.org/packages/91/cf/4e384709bc0a14acab5edcd0d92fce3b93ae323eafbaeaeeb50c7dc0d7e8/pyspark_types-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b69b3f598b34b77682e61508deab9c2464ac23a2da4125f4aaebd5df78aeb0cf",
          "md5": "823f93e4cfe3153cc1e60efeddf0381e",
          "sha256": "4aeac0c726b9e1cd8ef8e0c98297dbe5ef4000fa5c91d4fd7a38a4ae1c25ce01"
        },
        "downloads": -1,
        "filename": "pyspark_types-0.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "823f93e4cfe3153cc1e60efeddf0381e",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.10,<4.0",
        "size": 6391,
        "upload_time": "2023-03-03T10:34:50",
        "upload_time_iso_8601": "2023-03-03T10:34:50.457047Z",
        "url": "https://files.pythonhosted.org/packages/b6/9b/3f598b34b77682e61508deab9c2464ac23a2da4125f4aaebd5df78aeb0cf/pyspark_types-0.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "845b803ad6a8a1ed3f028cfb1e0be5800050fee3bfc20eaa14752a9b12ddc42a",
          "md5": "0cba129e3bcc02e2feea76baa334274f",
          "sha256": "62302cfa38cf74c695ba492c4515011b9017333e65843cb6e3195ab651aa76d8"
        },
        "downloads": -1,
        "filename": "pyspark_types-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "0cba129e3bcc02e2feea76baa334274f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.10,<4.0",
        "size": 4864,
        "upload_time": "2023-03-03T10:34:52",
        "upload_time_iso_8601": "2023-03-03T10:34:52.021523Z",
        "url": "https://files.pythonhosted.org/packages/84/5b/803ad6a8a1ed3f028cfb1e0be5800050fee3bfc20eaa14752a9b12ddc42a/pyspark_types-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "b69b3f598b34b77682e61508deab9c2464ac23a2da4125f4aaebd5df78aeb0cf",
        "md5": "823f93e4cfe3153cc1e60efeddf0381e",
        "sha256": "4aeac0c726b9e1cd8ef8e0c98297dbe5ef4000fa5c91d4fd7a38a4ae1c25ce01"
      },
      "downloads": -1,
      "filename": "pyspark_types-0.0.2-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "823f93e4cfe3153cc1e60efeddf0381e",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.10,<4.0",
      "size": 6391,
      "upload_time": "2023-03-03T10:34:50",
      "upload_time_iso_8601": "2023-03-03T10:34:50.457047Z",
      "url": "https://files.pythonhosted.org/packages/b6/9b/3f598b34b77682e61508deab9c2464ac23a2da4125f4aaebd5df78aeb0cf/pyspark_types-0.0.2-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "845b803ad6a8a1ed3f028cfb1e0be5800050fee3bfc20eaa14752a9b12ddc42a",
        "md5": "0cba129e3bcc02e2feea76baa334274f",
        "sha256": "62302cfa38cf74c695ba492c4515011b9017333e65843cb6e3195ab651aa76d8"
      },
      "downloads": -1,
      "filename": "pyspark_types-0.0.2.tar.gz",
      "has_sig": false,
      "md5_digest": "0cba129e3bcc02e2feea76baa334274f",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.10,<4.0",
      "size": 4864,
      "upload_time": "2023-03-03T10:34:52",
      "upload_time_iso_8601": "2023-03-03T10:34:52.021523Z",
      "url": "https://files.pythonhosted.org/packages/84/5b/803ad6a8a1ed3f028cfb1e0be5800050fee3bfc20eaa14752a9b12ddc42a/pyspark_types-0.0.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}