{
  "info": {
    "author": "Xu Jing",
    "author_email": "274762204@qq.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Topic :: Text Processing"
    ],
    "description": "detmetric: Metrics for object detection\n==========================================\n\nXu Jing\n\n\nIntroduction\n---------------\n\nThe motivation of this project is the lack of consensus used by different works and implementations concerning the evaluation metrics of the object detection problem. Although on-line competitions use their own metrics to evaluate the task of object detection, just some of them offer reference code snippets to calculate the accuracy of the detected objects.\n\nResearchers who want to evaluate their work using different datasets than those offered by the competitions, need to implement their own version of the metrics. Sometimes a wrong or different implementation can create different and biased results. Ideally, in order to have trustworthy benchmarking among different approaches, it is necessary to have a flexible implementation that can be used by everyone regardless the dataset used.\n\n**This project provides easy-to-use functions implementing the same metrics used by the the most popular competitions of object detection.** Our implementation does not require modifications of your detection model to complicated input formats, avoiding conversions to XML or JSON files. We simplified the input data (ground truth bounding boxes and detected bounding boxes) and gathered in a single project the main metrics used by the academia and challenges. Our implementation was carefully compared against the official implementations and our results are exactly the same.\n\nIn the topics below you can find an overview of the most popular metrics used in different competitions and works, as well as samples showing how to use our code.\n\nThis package support:\n\n+ PASCAL VOC Challenge metric (P-R Curve, mAP)\n+ COCO Detection Challenge (P-R Curve, AP)\n+ Precision\n+ Recall\n+ F-Score\n+ Confidence Interval and Variance\n\nMore detials can find in demo.\n\nDemo\n---------\n\n::\n\n    #---------------------test detcivar module-----------------------\n    from detcivar import DetStatic\n\n    precision = [0.1, 0.2, 0.3, 0.4, 0.5]\n\n\n    # test mean\n    p_mean = DetStatic().mu(precision)\n    print(p_mean)\n\n    real_mean = sum(precision) / len(precision)\n    print(real_mean)\n\n\n    # test variance\n\n    p_var = DetStatic().variance(precision)\n    print(p_var)\n\n    real_var = float((0.1-real_mean)**2 + (0.2-real_mean)**2  + (0.3-real_mean)**2  + (0.4-real_mean)**2  + (0.5-real_mean)**2) / (len(precision)-1)\n    print(real_var)\n\n    # test confidence\n\n    ci = DetStatic().detcivar(precision,level=0.95)\n\n    import pprint\n    pprint.pprint(ci)\n\n\n    # real\n    # N(0,1) 0.025 quntile like equel -1.9599639845400545\n    import numpy as np\n    lower = 0.3 - np.sqrt(0.025) / np.sqrt(5) * 1.9599639845400545\n    upper = 0.3 + np.sqrt(0.025) / np.sqrt(5) * 1.9599639845400545\n\n    print(lower)\n    print(upper)\n\n\n    # test done!!!\n\n    # 0.3\n    # 0.3\n    # 0.025\n    # 0.025\n    # {'CI': [0.16141, 0.43859], 'Var': 0.025}\n    # 0.16140961756503217\n    # 0.43859038243496784\n\n\n::\n\n    #----------------test detmet module-------------------------------\n\n    from detmet import *\n    from utils import *\n    from BoundingBox import BoundingBox\n    from BoundingBoxes import BoundingBoxes\n\n    import glob\n    import os\n\n    def getBoundingBoxes():\n        \"\"\"\n        Read txt files containing bounding boxes (ground truth and detections).\n        \"\"\"\n        # allBoundingBoxes = BoundingBoxes()\n\n        # --------------------------Read ground truths-----------------------------\n        folderGT = './groundtruths'\n\n        files = os.listdir(folderGT)\n        # files = glob.glob(\"./groundtruths/*.txt\")\n        files.sort()\n\n        # Class representing bounding boxes (ground truths and detections)\n        allBoundingBoxes = BoundingBoxes()\n        # Read GT detections from txt file\n        # Each line of the files in the groundtruths folder represents a ground truth bounding box\n        # (bounding boxes that a detector should detect)\n\n        # Each value of each line is  \"class_id, x, y, width, height\" respectively\n        # Class_id represents the class of the bounding box\n        # x, y represents the most top-left coordinates of the bounding box\n        # x2, y2 represents the most bottom-right coordinates of the bounding box\n\n        for f in files:   # file in GT-folder\n            nameOfImage = f.replace(\".txt\", \"\")\n            fh1 = open(os.path.join(folderGT,f), \"r\")\n            for line in fh1:\n                line = line.replace(\"\\n\", \"\")\n                if line.replace(' ', '') == '':\n                    continue\n                splitLine = line.split(\" \")  # space to sep line\n\n                idClass = splitLine[0]  # class\n                x = float(splitLine[1])  # GT no confidnce\n                y = float(splitLine[2])\n                w = float(splitLine[3])\n                h = float(splitLine[4])\n\n                bb = BoundingBox(\n                    nameOfImage,\n                    idClass,\n                    x,\n                    y,\n                    w,\n                    h,\n                    CoordinatesType.Absolute, None,\n                    BBType.GroundTruth,\n                    format=BBFormat.XYWH)\n                allBoundingBoxes.addBoundingBox(bb)\n            fh1.close()\n\n        # ----------------------------Read detections------------------------------\n        folderDet = './detections' \n        files = os.listdir(folderDet)\n        # files = glob.glob(\"./detections/*.txt\")\n        files.sort()\n        # Read detections from txt file\n        # Each line of the files in the detections folder represents a detected bounding box.\n\n        # Each value of each line is  \"class_id, confidence, x, y, width, height\" respectively\n        # Class_id represents the class of the detected bounding box\n        # Confidence represents confidence (from 0 to 1) that this detection belongs to the class_id.\n        # x, y represents the most top-left coordinates of the bounding box\n        # x2, y2 represents the most bottom-right coordinates of the bounding box\n\n        for f in files:\n            # nameOfImage = f.replace(\"_det.txt\",\"\")\n            nameOfImage = f.replace(\".txt\", \"\")\n            # Read detections from txt file\n            fh1 = open(os.path.join(folderDet,f), \"r\")\n            for line in fh1:\n                line = line.replace(\"\\n\", \"\")\n                if line.replace(' ', '') == '':\n                    continue\n                splitLine = line.split(\" \")\n                idClass = splitLine[0]  # class\n                confidence = float(splitLine[1])  # confidence predict detect\n                x = float(splitLine[2])\n                y = float(splitLine[3])\n                w = float(splitLine[4])\n                h = float(splitLine[5])\n                bb = BoundingBox(\n                    nameOfImage,\n                    idClass,\n                    x,\n                    y,\n                    w,\n                    h,\n                    CoordinatesType.Absolute, None,\n                    BBType.Detected,  # GT or predict\n                    confidence,\n                    format=BBFormat.XYWH)\n                allBoundingBoxes.addBoundingBox(bb)\n            fh1.close()\n        return allBoundingBoxes\n\n\n    def createImages(dictGroundTruth, dictDetected):\n        \"\"\"\n        Create representative images with bounding boxes.\n        \"\"\"\n        import numpy as np\n        import cv2\n        # Define image size\n        width = 200\n        height = 200\n        # Loop through the dictionary with ground truth detections\n        for key in dictGroundTruth:\n            image = np.zeros((height, width, 3), np.uint8)\n            gt_boundingboxes = dictGroundTruth[key]\n            image = gt_boundingboxes.drawAllBoundingBoxes(image)\n            detection_boundingboxes = dictDetected[key]\n            image = detection_boundingboxes.drawAllBoundingBoxes(image)\n            # Show detection and its GT\n            cv2.imshow(key, image)\n            cv2.waitKey()\n\n\n\n\n    # Read txt files containing bounding boxes (ground truth and detections)\n    boundingboxes = getBoundingBoxes()\n    # Uncomment the line below to generate images based on the bounding boxes\n    # createImages(dictGroundTruth, dictDetected)\n    # Create an evaluator object in order to obtain the metrics\n    evaluator = DetMetric()\n\n\n    ##############################################################\n    # VOC PASCAL Metrics\n    ##############################################################\n    # Plot Precision x Recall curve\n    evaluator.PlotPRCurve(\n        boundingboxes,  # Object containing all bounding boxes (ground truths and detections)\n        IOUThreshold=0.3,  # IOU threshold\n        # MethodAveragePrecision.COCOInterpolation: COCO AP, MethodAveragePrecision.ElevenInterpolationElevenPointInterpolation: VOC2008, \n        # MethodAveragePrecision.EveryPointInterpolation: VOC2010\n        method=MethodAveragePrecision.COCOInterpolation,  \n        showAP=True,  # Show Average Precision in the title of the plot\n        savePath=\"P-R-Curve-VOC.png\",\n        showInterpolatedPrecision=False)  # Plot the interpolated precision curve\n\n\n    # Get metrics with PASCAL VOC metrics\n    metricsPerClass,metricsAll = evaluator.GetDetMetrics(\n        boundingboxes,  # Object containing all bounding boxes (ground truths and detections)\n        IOUThreshold=0.3,  # IOU threshold\n        beta = 1,  # F1-score\n        method=MethodAveragePrecision.ElevenPointInterpolation)\n\n    print(\"Average precision values per class:\\n\")\n    # Loop through classes to obtain their metrics\n\n    s = ('%20s' + '%14s' * 6) % ('Class','P', 'R', 'F-Score',  'total TP', 'total FP','VOC AP@.5')\n    print(s)\n    for mc in metricsPerClass:\n        # Get metric values per each class\n        c = mc['class']\n        precision = mc['precision']\n        recall = mc['recall']\n        f_score = mc['f_score']\n        average_precision = mc['AP']\n        tp = mc['total TP']\n        fp = mc['total FP']\n\n        metric_c = ('%20s' + '%14s' * 6) % (c, round(precision[-1],3), round(recall[-1],3), round(f_score,3),  tp, fp, round(average_precision,3))\n       \n        # Print AP per class\n        print(metric_c)\n\n    all_precision = round(metricsAll[\"all_precision\"],3)\n    all_recall = round(metricsAll[\"all_recall\"],3)\n    all_f_score = round(metricsAll[\"all_f_score\"],3)\n    all_ap = round(metricsAll[\"total_map\"],3)\n\n    metric_all = ('%20s' + '%14s' * 6) % (\"all\", all_precision, all_recall, all_f_score,  \"\\\\\", \"\\\\\", \"mAP@50:{}\".format(all_ap))\n\n    # Print voc mAP for all class\n    print(metric_all)\n\n    #########################################################################\n    # COCO Metrics\n    # Precision, Recall, F-Score are same to VOC, so we only compute COCO AP\n    #########################################################################\n    # Plot Precision x Recall curve\n    evaluator.PlotPRCurve(\n        boundingboxes,  # Object containing all bounding boxes (ground truths and detections)\n        IOUThreshold=0.5,  # IOU threshold\n        # MethodAveragePrecision.COCOInterpolation: COCO AP, MethodAveragePrecision.COCOInterpolationElevenPointInterpolation: VOC2008, \n        # MethodAveragePrecision.EveryPointInterpolation: VOC2010\n        method=MethodAveragePrecision.ElevenPointInterpolation, # we do not compute the COCO AP for every class, so we use VOC AP replace,in P-R Curve!\n        showAP=True,  # Show Average Precision in the title of the plot\n        savePath=\"P-R-Curv-COCO.png\",\n        showInterpolatedPrecision=False)  # Plot the interpolated precision curve\n\n\n    # Get metrics with COCO metrics\n\n    coco_ap_dict = {}\n    for viou in np.linspace(0.5, 0.95, num=10):\n\n        metricsPerClass, metricsAll = evaluator.GetDetMetrics(\n            boundingboxes,      # Object containing all bounding boxes (ground truths and detections)\n            IOUThreshold=viou,  # IOU threshold\n            beta = 1,           # F1-score\n            method=MethodAveragePrecision.COCOInterpolation)\n\n        ap_iou = metricsAll[\"total_map\"]\n\n        coco_ap_dict[str(viou)] = ap_iou\n        print(\" Average Precision  (AP)  AP@{}: {}\".format(int(viou*100), round(ap_iou,3)))\n\n\n\n    COCO_AP = np.mean(np.array(list(coco_ap_dict.values())))\n    print(\" Average Precision  (AP)  AP@50:95: {}\".format(COCO_AP))\n\n\n\n\n\nSupports\n-----------\n\nTested on Python 3.x\n\n* pip install detmetric\n* Download: https://github.com/DataXujing/detmetric\n* Documentation: https://github.com/DataXujing/detmetric\n\n\nTODO\n----------\n\nHeatmap of object detectiom. like\n\n.. image:: https://github.com/argusswift/YOLOv4-pytorch/blob/master/data/heatmap.jpg?raw=true\n\n\nReference\n-----------\n\n**Thanks to the open source community, we refer to many open source projects for the implementation of part of our code !**\n\n1. https://github.com/rafaelpadilla/Object-Detection-Metrics\n#. https://github.com/WongKinYiu/PyTorch_YOLOv4\n#. https://github.com/argusswift/YOLOv4-pytorch\n",
    "description_content_type": "",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/DataXujing/detmetric",
    "keywords": "object detection",
    "license": "MIT License",
    "maintainer": "",
    "maintainer_email": "",
    "name": "detmetric",
    "package_url": "https://pypi.org/project/detmetric/",
    "platform": "linux/Windows",
    "project_url": "https://pypi.org/project/detmetric/",
    "project_urls": {
      "Homepage": "https://github.com/DataXujing/detmetric"
    },
    "release_url": "https://pypi.org/project/detmetric/0.2.0/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "Object Detection Metric in Computer Vision",
    "version": "0.2.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8511706,
  "releases": {
    "0.1.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e8a318726ec3e3ee500858aa1fcfb07ed108777eb0a082484169327f10fd2f7d",
          "md5": "c06fba53cf9e13d91af7c8e614dab3fa",
          "sha256": "24f548ed36e22c5a4138e1d87a1b3f00664197e0e37be6a9aaca62c443f02e7e"
        },
        "downloads": -1,
        "filename": "detmetric-0.1.4.tar.gz",
        "has_sig": false,
        "md5_digest": "c06fba53cf9e13d91af7c8e614dab3fa",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 15464,
        "upload_time": "2020-10-21T01:31:23",
        "upload_time_iso_8601": "2020-10-21T01:31:23.774609Z",
        "url": "https://files.pythonhosted.org/packages/e8/a3/18726ec3e3ee500858aa1fcfb07ed108777eb0a082484169327f10fd2f7d/detmetric-0.1.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e57eec5dc4402ed8ad1a61883e51b3bf644aae0dbb43b215cd73a90ed032a8b4",
          "md5": "dd1e0328d63f4bd286ac51a283a70810",
          "sha256": "5e81b4b9bedc2fe4602ca3b3fa9c01200bcb727ad45cf2b7a7d57ec8144efa50"
        },
        "downloads": -1,
        "filename": "detmetric-0.1.5.tar.gz",
        "has_sig": false,
        "md5_digest": "dd1e0328d63f4bd286ac51a283a70810",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 16822,
        "upload_time": "2020-10-21T08:28:43",
        "upload_time_iso_8601": "2020-10-21T08:28:43.255351Z",
        "url": "https://files.pythonhosted.org/packages/e5/7e/ec5dc4402ed8ad1a61883e51b3bf644aae0dbb43b215cd73a90ed032a8b4/detmetric-0.1.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c1a4a26d839113ba829448342bd4ff1d240637022d31e6cb40ebc38fb3d1f5e6",
          "md5": "793573d871b0bf249c4c8e1d41d8b399",
          "sha256": "a028221d402daed8ff56557c3a6526ec527d7e6121738f540dbd097ae202efc3"
        },
        "downloads": -1,
        "filename": "detmetric-0.1.6.tar.gz",
        "has_sig": false,
        "md5_digest": "793573d871b0bf249c4c8e1d41d8b399",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 16983,
        "upload_time": "2020-10-21T10:39:01",
        "upload_time_iso_8601": "2020-10-21T10:39:01.944306Z",
        "url": "https://files.pythonhosted.org/packages/c1/a4/a26d839113ba829448342bd4ff1d240637022d31e6cb40ebc38fb3d1f5e6/detmetric-0.1.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d77571ab99c3187f2aeff817ef9bc8ee2232178f6fbced1fe98ac8b6aed7e855",
          "md5": "f784b31cc145ddfc6c35213c658ac5dd",
          "sha256": "c16b0847b1c5db4a51ebe7904a9c609b8ecd7ff6ec67c92cc8890905feab5da3"
        },
        "downloads": -1,
        "filename": "detmetric-0.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "f784b31cc145ddfc6c35213c658ac5dd",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 346504,
        "upload_time": "2020-10-27T11:19:18",
        "upload_time_iso_8601": "2020-10-27T11:19:18.038876Z",
        "url": "https://files.pythonhosted.org/packages/d7/75/71ab99c3187f2aeff817ef9bc8ee2232178f6fbced1fe98ac8b6aed7e855/detmetric-0.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "d77571ab99c3187f2aeff817ef9bc8ee2232178f6fbced1fe98ac8b6aed7e855",
        "md5": "f784b31cc145ddfc6c35213c658ac5dd",
        "sha256": "c16b0847b1c5db4a51ebe7904a9c609b8ecd7ff6ec67c92cc8890905feab5da3"
      },
      "downloads": -1,
      "filename": "detmetric-0.2.0.tar.gz",
      "has_sig": false,
      "md5_digest": "f784b31cc145ddfc6c35213c658ac5dd",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 346504,
      "upload_time": "2020-10-27T11:19:18",
      "upload_time_iso_8601": "2020-10-27T11:19:18.038876Z",
      "url": "https://files.pythonhosted.org/packages/d7/75/71ab99c3187f2aeff817ef9bc8ee2232178f6fbced1fe98ac8b6aed7e855/detmetric-0.2.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}