{
  "info": {
    "author": "Dennis Ulmer",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Topic :: Scientific/Engineering :: Artificial Intelligence"
    ],
    "description": "# :zap: :card_index: token2index: A lightweight but powerful library for token indexing\n\n[![Build](https://travis-ci.org/Kaleidophon/token2index.svg?branch=master)](https://travis-ci.org/github/Kaleidophon/token2index/builds)\n[![Documentation Status](https://readthedocs.org/projects/token2index/badge/?version=latest)](https://token2index.readthedocs.io/en/latest/?badge=latest)\n[![Coverage Status](https://coveralls.io/repos/github/Kaleidophon/token2index/badge.svg?branch=master)](https://coveralls.io/github/Kaleidophon/token2index?branch=master)\n[![Compatibility](https://img.shields.io/badge/Python-3.5%20%7C%203.6%20%7C%203.7%20%7C%203.8-blue)]()\n[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/python/black)\n\n``token2index`` is a small yet powerful library facilitating the fast and easy creation of a data structure mapping \ntokens to indices, primarily aimed at applications for Natural Language Processing. The library is fully tested, and \ndoes not require any additional requirements. The documentation can be found [here](https://token2index.readthedocs.io/en/latest/), some feature highlights are \nshown below.\n\n**Who / what is this for?**\n\nThis class is written to be used for NLP applications where we want to assign an index to every word in a sequence e.g. to be later used to look up corresponding \nword embeddings. Building an index and indexing batches of sequences for Deep Learning models using frameworks like PyTorch or Tensorflow are common steps but are often written from \nscratch every time. This package provides a ready-made package combining many useful features, like reading vocabulary files, building indices from a corpus or indexing entire batches in one single\nfunction call, all while being fully tested.\n\n### :sparkles: Feature Highlights\n\n* **Building and extending vocab**\n\n    One way to build the index from a corpus is using the build() function:\n\n    ```python\n    >>> from t2i import T2I\n    >>> t2i = T2I.build([\"colorless green ideas dream furiously\", \"the horse raced past the barn fell\"])\n    >>> t2i\n    T2I(Size: 13, unk_token: <unk>, eos_token: <eos>, pad_token: <pad>, {'colorless': 0, 'green': 1, 'ideas': 2, 'dream': 3, 'furiously': 4, 'the': 5, 'horse': 6, 'raced': 7, 'past': 8, 'parn': 9, 'fell': 10, '<unk>': 11, '<eos>': 12, '<pad>': 13})\n    ```\n\n    The index can always be extended again later using `extend()`:\n\n    ```python\n    >>> t2i = t2i.extend(\"completely new words\")\n    T2I(Size: 16, unk_token: <unk>, eos_token: <eos>, pad_token: <pad>, {'colorless': 0, 'green': 1, 'ideas': 2, 'dream': 3, 'furiously': 4, 'the': 5, 'horse': 6, 'raced': 7, 'past': 8, 'barn': 9, 'fell': 10, 'completely': 13, 'new': 14, 'words': 15, '<unk>': 16, '<eos>': 17, '<pad>': 18})\n    ```\n\n    Both methods and index() also work with an already tokenized corpus in the form of \n\n        [[\"colorless\", \"green\", \"ideas\", \"dream\", \"furiously\"], [\"the\", \"horse\", \"raced\", \"past\", \"the\", \"barn\", \"fell\"]]    \n\n* **Easy indexing (of batches)**\n\n    Index multiple sentences at once in a single function call!\n\n    ```python\n    >>> t2i.index([\"the green horse raced <eos>\", \"ideas are a dream <eos>\"])\n    [[5, 1, 6, 7, 12], [2, 11, 11, 3, 12]]\n    ```\n\n    where unknown tokens are always mapped to `unk_token`.\n\n* **Easy conversion back to strings**\n\n    Reverting indices back to strings is equally as easy:\n\n    ```python\n    >>> t2i.unindex([5, 14, 16, 3, 6])\n    'the new <unk> dream horse'\n    ```\n\n* **Automatic padding**\n\n    You are indexing multiple sentences of different length and want to add padding? No problem! `index()` has two\n    options available via the `pad_to` argument. The first is padding to the maximum length of all the sentences:\n\n    ```python\n    >>> padded_sents = t2i.index([\"the green horse raced <eos>\", \"ideas <eos>\"], pad_to=\"max\")\n    >>> padded_sents\n    [[5, 1, 6, 7, 12], [2, 12, 13, 13, 13]]\n    >>> t2i.unindex(padded_sents)\n    [['the green horse raced <eos>', 'ideas <eos> <pad> <pad> <pad>']]\n    ```\n\n    Alternatively, you can also pad to a pre-defined length:\n\n    ```python\n    >>> padded_sents = t2i.index([\"the green horse <eos>\", \"past ideas <eos>\"], pad_to=5)\n    >>> padded_sents\n    [[5, 1, 6, 12, 13], [8, 2, 12, 13, 13]]\n    >>> t2i.unindex(padded_sents)\n    [['the green horse <eos> <pad>', 'past ideas <eos> <pad> <pad>']]\n    ```\n\n* **Vocab from file**\n\n    Using `T2I.from_file()`, the index can be created directly by reading from an existing vocab file. \n    Refer to its documentation [here](https://token2index.readthedocs.io/en/latest/#t2i.T2I.from_file) for more info.\n\n* **Fixed memory size**\n\n    Although the `defaultdict` class from Python's `collections` package also posses the functionality to map unknown \n    keys to a certain value, it grows in size for every new key. `T2I` memory size stays fixed after the index is built.\n\n* **Support for special tokens**\n\n    To enable flexibility in modern NLP applications, `T2I` allows for an arbitrary number of special tokens (like a \n    masking or a padding token) during init! \n\n    ```python\n    >>> t2i = T2I(special_tokens=[\"<mask>\"])\n    >>> t2i\n    T2I(Size: 3, unk_token: <unk>, eos_token: <eos>, pad_token: <pad>, {'<unk>': 0, '<eos>': 1, '<mask>': 2, '<pad>': 3})\n    ```\n\n* **Explicitly supported programmer laziness**\n\n    Too lazy to type? The library saves you a few keystrokes here and there. instead of calling `t2i.index(...)` you can\n    directly call `t2i(...)` to index one or multiple sequences. Furthermore, key functions like `index()`, `unindex()`,\n    `build()` and `extend()` support strings or iterables of strings as arguments alike.\n\n### :electric_plug: Compatibility with other frameworks (Numpy, PyTorch, Tensorflow)\n\nIt is also ensured that `T2I` is easily compatible with frameworks like Numpy, PyTorch and \nTensorflow, without needing them as requirements:\n\n**Numpy**\n\n```python\n>>> import numpy as np\n>>> t = np.array(t2i.index([\"the new words are ideas <eos>\", \"the green horse <eos> <pad> <pad>\"]))\n>>> t\narray([[ 5, 15, 16, 17,  2, 18],\n   [ 5,  1,  6, 18, 19, 19]])\n>>> t2i.unindex(t)\n['the new words <unk> ideas <eos>', 'the green horse <eos> <pad> <pad>']\n```\n\n**PyTorch**\n\n```python\n>>> import torch\n>>> t = torch.LongTensor(t2i.index([\"the new words are ideas <eos>\", \"the green horse <eos> <pad> <pad>\"]))\n>>> t\ntensor([[ 5, 15, 16, 17,  2, 18],\n    [ 5,  1,  6, 18, 19, 19]])\n>>> t2i.unindex(t)\n['the new words <unk> ideas <eos>', 'the green horse <eos> <pad> <pad>']\n```\n\n**Tensorflow**\n\n```python\n>>> import tensorflow as tf\n>>> t = tf.convert_to_tensor(t2i.index([\"the new words are ideas <eos>\", \"the green horse <eos> <pad> <pad>\"]), dtype=tf.int32)\n>>> t\ntensor([[ 5, 15, 16, 17,  2, 18],\n    [ 5,  1,  6, 18, 19, 19]])\n>>> t2i.unindex(t)\n['the new words <unk> ideas <eos>', 'the green horse <eos> <pad> <pad>']\n```\n\n### :inbox_tray: Installation\n\nInstallation can simply be done using ``pip``:\n\n    pip3 install token2index\n\n### :mortar_board: Citing\n\nIf you use ``token2index`` for research purposes, please cite the library using the following citation info:\n\n    @misc{ulmer2020token2index,\n        title={token2index: A lightweight but powerful library for token indexing},\n        author={Ulmer, Dennis},\n        journal={https://github.com/Kaleidophon/token2index},\n        year={2020}\n    }\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/Kaleidophon/token2index",
    "keywords": "indexing,token,nlp,pytorch,tensorflow,numpy,w2i,t2i,stoi,itos,i2t,i2w,deep learning,seq2seq",
    "license": "GPL",
    "maintainer": "",
    "maintainer_email": "",
    "name": "token2index",
    "package_url": "https://pypi.org/project/token2index/",
    "platform": "",
    "project_url": "https://pypi.org/project/token2index/",
    "project_urls": {
      "Homepage": "https://github.com/Kaleidophon/token2index"
    },
    "release_url": "https://pypi.org/project/token2index/1.0.2/",
    "requires_dist": null,
    "requires_python": ">=3.5.3",
    "summary": "A lightweight but powerful library for token indexing.",
    "version": "1.0.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8521636,
  "releases": {
    "0.9.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5f96d0f9101171c89df9bf3e6896bd687af2908615b0de405559d8cfd4bf1005",
          "md5": "089b57d795ea09237a45ca17ad82d407",
          "sha256": "d1a4554a8a2ef377726b69c988f1c0bb04d3f6245ec7b8dc348042d38b473a32"
        },
        "downloads": -1,
        "filename": "token2index-0.9.2.tar.gz",
        "has_sig": false,
        "md5_digest": "089b57d795ea09237a45ca17ad82d407",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5.3",
        "size": 15727,
        "upload_time": "2020-06-30T20:00:38",
        "upload_time_iso_8601": "2020-06-30T20:00:38.937933Z",
        "url": "https://files.pythonhosted.org/packages/5f/96/d0f9101171c89df9bf3e6896bd687af2908615b0de405559d8cfd4bf1005/token2index-0.9.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "27f3085d5d70bcfd6d0f95a710cd430c4deb1ca75275e603fb1cec991fcb5e8f",
          "md5": "f353e1a194556961289d5741ccb5cbc7",
          "sha256": "b86871930c179af2fead5fea93560b3e76041ef34f6d06ba5b36ae6322491ae3"
        },
        "downloads": -1,
        "filename": "token2index-1.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f353e1a194556961289d5741ccb5cbc7",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.5.3",
        "size": 28895,
        "upload_time": "2020-07-07T21:49:16",
        "upload_time_iso_8601": "2020-07-07T21:49:16.268781Z",
        "url": "https://files.pythonhosted.org/packages/27/f3/085d5d70bcfd6d0f95a710cd430c4deb1ca75275e603fb1cec991fcb5e8f/token2index-1.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9aef2ac78631b1ad2b6f72e7f1a868e62c849909688b009f66efd680441d25f8",
          "md5": "74c2c8994205e3dedb2cb644d7a2dbc7",
          "sha256": "ab0d47311d6698d3cfe0a7bc8c8698ac4e8e72a84813f43408c332b662c84513"
        },
        "downloads": -1,
        "filename": "token2index-1.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "74c2c8994205e3dedb2cb644d7a2dbc7",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.5.3",
        "size": 29751,
        "upload_time": "2020-10-28T09:37:07",
        "upload_time_iso_8601": "2020-10-28T09:37:07.643808Z",
        "url": "https://files.pythonhosted.org/packages/9a/ef/2ac78631b1ad2b6f72e7f1a868e62c849909688b009f66efd680441d25f8/token2index-1.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "915f9d9f65aa9f55e9a169c2ee2df7ad99dbb47df90cd5c6884daca36d4bb716",
          "md5": "13d52e50a41215c6be87dae3e3f4c960",
          "sha256": "f918d48cc0e578dc1710e57640fcaa336173998a76abca54a832107e37d03ead"
        },
        "downloads": -1,
        "filename": "token2index-1.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "13d52e50a41215c6be87dae3e3f4c960",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5.3",
        "size": 19379,
        "upload_time": "2020-10-28T09:37:09",
        "upload_time_iso_8601": "2020-10-28T09:37:09.274804Z",
        "url": "https://files.pythonhosted.org/packages/91/5f/9d9f65aa9f55e9a169c2ee2df7ad99dbb47df90cd5c6884daca36d4bb716/token2index-1.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "9aef2ac78631b1ad2b6f72e7f1a868e62c849909688b009f66efd680441d25f8",
        "md5": "74c2c8994205e3dedb2cb644d7a2dbc7",
        "sha256": "ab0d47311d6698d3cfe0a7bc8c8698ac4e8e72a84813f43408c332b662c84513"
      },
      "downloads": -1,
      "filename": "token2index-1.0.2-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "74c2c8994205e3dedb2cb644d7a2dbc7",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.5.3",
      "size": 29751,
      "upload_time": "2020-10-28T09:37:07",
      "upload_time_iso_8601": "2020-10-28T09:37:07.643808Z",
      "url": "https://files.pythonhosted.org/packages/9a/ef/2ac78631b1ad2b6f72e7f1a868e62c849909688b009f66efd680441d25f8/token2index-1.0.2-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "915f9d9f65aa9f55e9a169c2ee2df7ad99dbb47df90cd5c6884daca36d4bb716",
        "md5": "13d52e50a41215c6be87dae3e3f4c960",
        "sha256": "f918d48cc0e578dc1710e57640fcaa336173998a76abca54a832107e37d03ead"
      },
      "downloads": -1,
      "filename": "token2index-1.0.2.tar.gz",
      "has_sig": false,
      "md5_digest": "13d52e50a41215c6be87dae3e3f4c960",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.5.3",
      "size": 19379,
      "upload_time": "2020-10-28T09:37:09",
      "upload_time_iso_8601": "2020-10-28T09:37:09.274804Z",
      "url": "https://files.pythonhosted.org/packages/91/5f/9d9f65aa9f55e9a169c2ee2df7ad99dbb47df90cd5c6884daca36d4bb716/token2index-1.0.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}