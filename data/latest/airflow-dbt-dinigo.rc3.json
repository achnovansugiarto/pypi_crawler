{
  "info": {
    "author": null,
    "author_email": null,
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "License :: OSI Approved :: MIT License",
      "Operating System :: MacOS :: MacOS X",
      "Operating System :: POSIX :: Linux",
      "Programming Language :: Python :: 3.7"
    ],
    "description": "# airflow-dbt\n\nThis is a collection of [Airflow](https://airflow.apache.org/) operators to provide easy integration with [dbt](https://www.getdbt.com).\n\n```py\nfrom airflow import DAG\nfrom airflow_dbt.operators.dbt_operator import (\n    DbtSeedOperator,\n    DbtSnapshotOperator,\n    DbtRunOperator,\n    DbtTestOperator\n)\nfrom airflow.utils.dates import days_ago\n\ndefault_args = {\n  'dir': '/srv/app/dbt',\n  'start_date': days_ago(0)\n}\n\nwith DAG(dag_id='dbt', default_args=default_args, schedule_interval='@daily') as dag:\n\n  dbt_seed = DbtSeedOperator(\n    task_id='dbt_seed',\n  )\n\n  dbt_snapshot = DbtSnapshotOperator(\n    task_id='dbt_snapshot',\n  )\n\n  dbt_run = DbtRunOperator(\n    task_id='dbt_run',\n  )\n\n  dbt_test = DbtTestOperator(\n    task_id='dbt_test',\n    retries=0,  # Failing tests would fail the task, and we don't want Airflow to try again\n  )\n\n  dbt_seed >> dbt_snapshot >> dbt_run >> dbt_test\n```\n\n## Installation\n\nInstall from PyPI:\n\n```sh\npip install airflow-dbt\n```\n\nIt will also need access to the `dbt` CLI, which should either be on your `PATH` or can be set with the `dbt_bin` argument in each operator.\n\n## Usage\n\nThere are five operators currently implemented:\n\n* `DbtDocsGenerateOperator`\n  * Calls [`dbt docs generate`](https://docs.getdbt.com/reference/commands/cmd-docs)\n* `DbtDepsOperator`\n  * Calls [`dbt deps`](https://docs.getdbt.com/docs/deps)\n* `DbtSeedOperator`\n  * Calls [`dbt seed`](https://docs.getdbt.com/docs/seed)\n* `DbtSnapshotOperator`\n  * Calls [`dbt snapshot`](https://docs.getdbt.com/docs/snapshot)\n* `DbtRunOperator`\n  * Calls [`dbt run`](https://docs.getdbt.com/docs/run)\n* `DbtTestOperator`\n  * Calls [`dbt test`](https://docs.getdbt.com/docs/test)\n\n\nEach of the above operators accept the arguments in [here (dbt_command_config)](airflow_dbt/dbt_command_config.py). The main ones being:\n\n* `profiles_dir`\n  * If set, passed as the `--profiles-dir` argument to the `dbt` command\n* `target`\n  * If set, passed as the `--target` argument to the `dbt` command\n* `dir`\n  * The directory to run the `dbt` command in\n* `full_refresh`\n  * If set to `True`, passes `--full-refresh`\n* `vars`\n  * If set, passed as the `--vars` argument to the `dbt` command. Should be set as a Python dictionary, as will be passed to the `dbt` command as YAML\n* `models`\n  * If set, passed as the `--models` argument to the `dbt` command\n* `exclude`\n  * If set, passed as the `--exclude` argument to the `dbt` command\n* `select`\n  * If set, passed as the `--select` argument to the `dbt` command\n* `dbt_bin`\n  * The `dbt` CLI. Defaults to `dbt`, so assumes it's on your `PATH`\n* `verbose`\n  * The operator will log verbosely to the Airflow logs\n* `warn_error`\n  * If set to `True`, passes `--warn-error` argument to `dbt` command and will treat warnings as errors\n\nTypically you will want to use the `DbtRunOperator`, followed by the `DbtTestOperator`, as shown earlier.\n\nYou can also use the hook directly. Typically this can be used for when you need to combine the `dbt` command with another task in the same operators, for example running `dbt docs` and uploading the docs to somewhere they can be served from.\n\n## A more advanced example:\n\nIf want to run your `dbt` project other tan in the airflow worker you can use\nthe `DbtCloudBuildHook` and apply it to the `DbtBaseOperator` or simply use the\nprovided `DbtCloudBuildOperator`:\n\n```python\nfrom airflow_dbt.hooks import DbtCloudBuildHook\nfrom airflow_dbt.operators import DbtBaseOperator, DbtCloudBuildOperator\nDbtBaseOperator(\n    task_id='provide_hook',\n    command='run',\n    use_colors=False,\n    config={\n        'profiles_dir': './jaffle-shop',\n        'project_dir': './jaffle-shop',\n    },\n    dbt_hook=DbtCloudBuildHook(\n        gcs_staging_location='gs://my-bucket/compressed-dbt-project.tar.gz'\n    )\n)\n\nDbtCloudBuildOperator(\n    task_id='default_hook_cloudbuild',\n    gcs_staging_location='gs://my-bucket/compressed-dbt-project.tar.gz',\n    command='run',\n    use_colors=False,\n    config={\n        'profiles_dir': './jaffle-shop',\n        'project_dir': './jaffle-shop',\n    },\n)\n```\n\nYou can either define the dbt params/config/flags in the operator or you can \ngroup them into a `config` param. They both have validation, but only the config\nhas templating. The following two tasks are equivalent:\n\n```python\nfrom airflow_dbt.operators.dbt_operator import DbtBaseOperator\n\nDbtBaseOperator(\n    task_id='config_param',\n    command='run',\n    config={\n        'profiles_dir': './jaffle-shop',\n        'project_dir': './jaffle-shop',\n        'dbt_bin': '/usr/local/airflow/.local/bin/dbt',\n        'use_colors': False\n    }\n)\n\nDbtBaseOperator(\n    task_id='flat_config',\n    command='run',\n    profiles_dir='./jaffle-shop',\n    project_dir='./jaffle-shop',\n    dbt_bin='/usr/local/airflow/.local/bin/dbt',\n    use_colors=False\n)\n```\n\n## Building Locally\n\nTo install from the repository:\nFirst it's recommended to create a virtual environment:\n```bash\npython3 -m venv .venv\n\nsource .venv/bin/activate\n```\n\nInstall using `pip`:\n```bash\npip install .\n```\n\n## Testing\n\nTo run tests locally, first create a virtual environment (see [Building Locally](https://github.com/gocardless/airflow-dbt#building-locally) section)\n\nInstall dependencies:\n```bash\npip install . pytest\n```\n\nRun the tests:\n```bash\npytest tests/\n```\n\n## Code style\nThis project uses [flake8](https://flake8.pycqa.org/en/latest/).\n\nTo check your code, first create a virtual environment (see [Building Locally](https://github.com/gocardless/airflow-dbt#building-locally) section):\n```bash\npip install flake8\nflake8 airflow_dbt/ tests/ setup.py\n```\n\n## Package management\n\nIf you use dbt's package manager you should include all dependencies before deploying your dbt project.\n\nFor Docker users, packages specified in `packages.yml` should be included as part your docker image by calling `dbt deps` in your `Dockerfile`.\n\n## Amazon Managed Workflows for Apache Airflow (MWAA)\n\nIf you use MWAA, you just need to update the `requirements.txt` file and add `airflow-dbt` and `dbt` to it.\n\nThen you can have your dbt code inside a folder `{DBT_FOLDER}` in the dags folder on S3 and configure the dbt task like below:\n\n```python\nfrom airflow_dbt.operators.dbt_operator import DbtRunOperator \n\ndbt_run=DbtRunOperator(\n  task_id='dbt_run',\n  dbt_bin='/usr/local/airflow/.local/bin/dbt',\n  profiles_dir='/usr/local/airflow/dags/{DBT_FOLDER}/',\n  dir='/usr/local/airflow/dags/{DBT_FOLDER}/'\n)\n```\n\n## License & Contributing\n\n* This is available as open source under the terms of the [MIT License](http://opensource.org/licenses/MIT).\n* Bug reports and pull requests are welcome on GitHub at https://github.com/gocardless/airflow-dbt.\n\nGoCardless â™¥ open source. If you do too, come [join us](https://gocardless.com/about/jobs).\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": null,
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": null,
    "keywords": null,
    "license": null,
    "maintainer": null,
    "maintainer_email": null,
    "name": "airflow-dbt-dinigo",
    "package_url": "https://pypi.org/project/airflow-dbt-dinigo/",
    "platform": null,
    "project_url": "https://pypi.org/project/airflow-dbt-dinigo/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/airflow-dbt-dinigo/0.5.10/",
    "requires_dist": [
      "apache-airflow>=1.10.3",
      "apache-airflow-providers-google; extra == 'google'",
      "google-cloud-build; extra == 'google'"
    ],
    "requires_python": null,
    "summary": "Apache Airflow integration for dbt",
    "version": "0.5.10",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 15457460,
  "releases": {
    "0.5.10": [
      {
        "comment_text": null,
        "digests": {
          "blake2b_256": "0ed307b854da4d7369daf54d0e7ea949a380f2c263e78ef00bcc526ed0e0458a",
          "md5": "3fbc46b36807dc5251d7dcf8e1a859a3",
          "sha256": "cbc6837655d4f179e341574b1e9e3e7b49c2b65351cf8799d93fadc3f9babe71"
        },
        "downloads": -1,
        "filename": "airflow_dbt_dinigo-0.5.10-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "3fbc46b36807dc5251d7dcf8e1a859a3",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 15481,
        "upload_time": "2022-10-19T05:21:33",
        "upload_time_iso_8601": "2022-10-19T05:21:33.643265Z",
        "url": "https://files.pythonhosted.org/packages/0e/d3/07b854da4d7369daf54d0e7ea949a380f2c263e78ef00bcc526ed0e0458a/airflow_dbt_dinigo-0.5.10-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": null,
        "digests": {
          "blake2b_256": "33f7926edee4ac80b90ab1236daeac01f3b1cc3860fbce6044216e083cd4cd0a",
          "md5": "6f29802ed2a0055b1115b0d3712011e9",
          "sha256": "07686b3b5ac9a95abec14840487686e54b9afeb324faf23884e633c5fafe1295"
        },
        "downloads": -1,
        "filename": "airflow_dbt_dinigo-0.5.10.tar.gz",
        "has_sig": false,
        "md5_digest": "6f29802ed2a0055b1115b0d3712011e9",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 27335,
        "upload_time": "2022-10-19T05:21:35",
        "upload_time_iso_8601": "2022-10-19T05:21:35.959484Z",
        "url": "https://files.pythonhosted.org/packages/33/f7/926edee4ac80b90ab1236daeac01f3b1cc3860fbce6044216e083cd4cd0a/airflow_dbt_dinigo-0.5.10.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.5.8": [
      {
        "comment_text": null,
        "digests": {
          "blake2b_256": "9de502b475b914ebeccacce44cd5208c0abb1eb86894355e33dd40dc1db2918a",
          "md5": "ed62e063d8483b2081a1a755b316ec1c",
          "sha256": "5e9f4b9d6648cb26bc4ad424fa3474325121256342af9985cb6f2325ec1a39c8"
        },
        "downloads": -1,
        "filename": "airflow_dbt_dinigo-0.5.8-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ed62e063d8483b2081a1a755b316ec1c",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 15437,
        "upload_time": "2022-10-16T21:57:59",
        "upload_time_iso_8601": "2022-10-16T21:57:59.561260Z",
        "url": "https://files.pythonhosted.org/packages/9d/e5/02b475b914ebeccacce44cd5208c0abb1eb86894355e33dd40dc1db2918a/airflow_dbt_dinigo-0.5.8-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": null,
        "digests": {
          "blake2b_256": "81262fc9e5fc00d08ff480d6c272df28b3f04ee1137bb4d4225a49d19d588f37",
          "md5": "0fb6a4670b00bdf3632b867a75605b51",
          "sha256": "881f7f0f9d7462aca9b7b14cd5cbf0f68b3f3a7b1b18aebd62218c3eeedfa358"
        },
        "downloads": -1,
        "filename": "airflow_dbt_dinigo-0.5.8.tar.gz",
        "has_sig": false,
        "md5_digest": "0fb6a4670b00bdf3632b867a75605b51",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 12607,
        "upload_time": "2022-10-16T21:57:56",
        "upload_time_iso_8601": "2022-10-16T21:57:56.674595Z",
        "url": "https://files.pythonhosted.org/packages/81/26/2fc9e5fc00d08ff480d6c272df28b3f04ee1137bb4d4225a49d19d588f37/airflow_dbt_dinigo-0.5.8.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.5.9": [
      {
        "comment_text": null,
        "digests": {
          "blake2b_256": "4ad5a8532fea46b429cba48f92141caaf030cd413ce4f81d52e655b394d63fd9",
          "md5": "6c738f3a44f99c743405c11f0caf2180",
          "sha256": "5c9048858fce4d65182a9f3f6774933a83bffa3876b66263b656aaff46e5d209"
        },
        "downloads": -1,
        "filename": "airflow_dbt_dinigo-0.5.9-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "6c738f3a44f99c743405c11f0caf2180",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 15465,
        "upload_time": "2022-10-19T02:17:31",
        "upload_time_iso_8601": "2022-10-19T02:17:31.528056Z",
        "url": "https://files.pythonhosted.org/packages/4a/d5/a8532fea46b429cba48f92141caaf030cd413ce4f81d52e655b394d63fd9/airflow_dbt_dinigo-0.5.9-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": null,
        "digests": {
          "blake2b_256": "f7e12cd9104e648ab02329d3f654a1987df09042f2b5cda4564cea06ab705987",
          "md5": "db271a9af901888eb5ec0be40116221c",
          "sha256": "d6662433843e090e2ce059a535e00f2d16e8371b152ada645042c983218a4807"
        },
        "downloads": -1,
        "filename": "airflow_dbt_dinigo-0.5.9.tar.gz",
        "has_sig": false,
        "md5_digest": "db271a9af901888eb5ec0be40116221c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 27314,
        "upload_time": "2022-10-19T02:17:33",
        "upload_time_iso_8601": "2022-10-19T02:17:33.801854Z",
        "url": "https://files.pythonhosted.org/packages/f7/e1/2cd9104e648ab02329d3f654a1987df09042f2b5cda4564cea06ab705987/airflow_dbt_dinigo-0.5.9.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": null,
      "digests": {
        "blake2b_256": "0ed307b854da4d7369daf54d0e7ea949a380f2c263e78ef00bcc526ed0e0458a",
        "md5": "3fbc46b36807dc5251d7dcf8e1a859a3",
        "sha256": "cbc6837655d4f179e341574b1e9e3e7b49c2b65351cf8799d93fadc3f9babe71"
      },
      "downloads": -1,
      "filename": "airflow_dbt_dinigo-0.5.10-py2.py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "3fbc46b36807dc5251d7dcf8e1a859a3",
      "packagetype": "bdist_wheel",
      "python_version": "py2.py3",
      "requires_python": null,
      "size": 15481,
      "upload_time": "2022-10-19T05:21:33",
      "upload_time_iso_8601": "2022-10-19T05:21:33.643265Z",
      "url": "https://files.pythonhosted.org/packages/0e/d3/07b854da4d7369daf54d0e7ea949a380f2c263e78ef00bcc526ed0e0458a/airflow_dbt_dinigo-0.5.10-py2.py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": null,
      "digests": {
        "blake2b_256": "33f7926edee4ac80b90ab1236daeac01f3b1cc3860fbce6044216e083cd4cd0a",
        "md5": "6f29802ed2a0055b1115b0d3712011e9",
        "sha256": "07686b3b5ac9a95abec14840487686e54b9afeb324faf23884e633c5fafe1295"
      },
      "downloads": -1,
      "filename": "airflow_dbt_dinigo-0.5.10.tar.gz",
      "has_sig": false,
      "md5_digest": "6f29802ed2a0055b1115b0d3712011e9",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 27335,
      "upload_time": "2022-10-19T05:21:35",
      "upload_time_iso_8601": "2022-10-19T05:21:35.959484Z",
      "url": "https://files.pythonhosted.org/packages/33/f7/926edee4ac80b90ab1236daeac01f3b1cc3860fbce6044216e083cd4cd0a/airflow_dbt_dinigo-0.5.10.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}