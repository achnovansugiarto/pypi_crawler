{
  "info": {
    "author": "EliMor",
    "author_email": "elimor.github@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: Apache Software License",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9"
    ],
    "description": "# Airflow Kubernetes Job Operator\n\n## What is this?\nAn Airflow Operator that manages creation, watching, and deletion of a Kubernetes Job. It assumes the client passes in a path to a yaml file that may have Jinja templated fields. \n\n## Who is it for?\nThis package makes the assumption that you're using Kubernetes somehow. Airflow itself may be deployed in Kubernetes (in_cluster mode) or you may just want it to manage Jobs running remotely on a cluster (give Airflow a kube config).\n\n## Why would I use this?\nIn our use of Airflow we struggled a lot with binding our business logic via many different custom Operators and Plugins directly to Airflow. Instead, we found Airflow to be a great manager of execution of code but not the best tool for writing the ETL/ML code itself. \n\nIdeally this should be one of the only Airflow Operators you need.\n\n## How do I use it?\n\nHere are the parameters.\n\n| Parameter | Description | Type    |\t\n| --------- | ----------- | ------- |\n| yaml_file_name | The name of the yaml file, could be a full path | str |\n| yaml_write_path | If you want the rendered yaml file written, where should it be? | str |\n| yaml_write_filename | If you want the rendered yaml file written, what is the filename? | str |\n| yaml_template_fields | If you have variables in your yaml file you want filled out | dict \n| tail_logs | Whether to output a log tail of the pods to airflow, will only do it at an end state | bool (F) |\n| tail_logs_every | every x seconds to wait to begin a new log dump (nearest 5 sec) | int |\n| tail_logs_line_count | num of lines from end to output | int |\n| log_yaml | Whether to log the rendered yaml | bool (T) |\n| in_cluster | Whether or not Airflow has cluster permissions to create and manage Jobs | bool (F) |\n| config_file | The path to the kube configfile | str |\n| cluster_context | If you are using a kube config file include the cluster context | str |\n| delete_completed_job | Autodelete Jobs that completed without errors | bool (F) |\n\n### Step 1. Install the package\n```sh\npip install airflow-kube-job-operator\n```\n\n#### Step 1.5 (Optional) Add Role to your Airflow deployment\nIf you want the Jobs to get created without having to bundle your kubeconfig file somehow into your Airflow pods, you'll need to deploy Airflow in kubernetes and give Airflow some extra RBAC permissions to handle Jobs within your cluster.\n\n** This is needed if you want to use the option ```in_cluster=True``` **\n\nHere's an example of what you may need\n```yaml\nkind: Role\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: airflow\nrules:\n  - verbs:\n      - create\n      - list\n      - get\n      - watch\n      - delete\n      - update\n      - patch\n    apiGroups:\n      - ''\n      - batch\n    resources:\n      - pods\n      - jobs\n      - jobs/status\n  - verbs:\n      - get\n    apiGroups:\n      - ''\n    resources:\n      - pods/log\n  - verbs:\n      - create\n      - get\n    apiGroups:\n      - ''\n    resources:\n      - pods/exec\n\n```\nIf you want to give Airflow power to run Jobs Cluster-wide modify the ClusterRole instead.\n\nAlternatively, just give Airflow your kube cluster config. (A.ii.)\n\n### Step 2. Create a template folder for your yaml files\nThis template folder can be anywhere. It's up to you. But here's a suggestion.\n\nIf you have...\n\n```\n~/airflow/dags\n```\nthen\n```\n~/airflow/kubernetes/job\n```\nCould be a valid choice. \n\nLets create a very simple job and put it there.\n```yaml\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: countdown\n  namespace: <WRITE YOUR AIRFLOW NAMESPACE HERE>\nspec:\n  template:\n    metadata:\n      name: countdown\n    spec:\n      containers:\n      - name: counter\n        image: centos:7\n        command:\n         - \"bin/bash\"\n         - \"-c\"\n         - \"for i in 9 8 7 6 5 4 3 2 1 ; do echo $i ; done\"\n      restartPolicy: Never\n```\nSave the above at\n```\n~/airflow/kubernetes/job/countdown.yaml\n```\n\n\n### Step 3. Create your Dag\n\nFirst some questions to ask yourself...\n\n    A. How do I want my Dag to have access to kubernetes? \n        i. My Airflow has the above RBAC permissions to make Jobs\n        ii. I rather just use my kube config file. It's accessible somewhere in Airflow already (web, worker, and scheduler)\n\n    B. What does my yaml look like? \n        i. I have a simple yaml file. Just create my Job. (The yaml, 'countdown.yaml' above is like this)\n        ii. I have a single yaml file for my Job but I want some templated fields filled out. \n        iii. I'm hardcore. I have multiple yaml files templated in the Jinja style so I can reuse my templates across tasks and dags. \n\n\n#### **A.i. Using ```in_cluster=True```**\n\n```python\nfrom airflow import DAG\nfrom datetime import datetime, timedelta\nfrom airflow_kjo import KubernetesJobOperator\n\ndefault_args = {\n    'owner': 'airflow',\n    'depends_on_past': False,\n    'email': ['airflow@example.com'],\n    'email_on_failure': False,\n    'email_on_retry': False,\n    'retries': 1, # the number of times the pod will retry, can pass in per-task\n    'retry_delay': timedelta(minutes=5), \n    'start_date': datetime(2021, 2, 24, 12, 0),\n}\nwith DAG(\n    'kubernetes_job_operator',\n    default_args=default_args,\n    description='KJO example DAG',\n    schedule_interval=None,\n    catchup=False\n) as dag:\n    task_1 = KubernetesJobOperator(task_id='example_kubernetes_job_operator',\n                                   yaml_file_name='/path/to/airflow/kubernetes/job/countdown.yaml',\n                                   in_cluster=True)\n```\n\n#### **A.ii. Using ```config_file=/path/to/.kube/config```**\n```python\n    task_1 = KubernetesJobOperator(task_id='example_kubernetes_job_operator',\n                                   yaml_file_name='/path/to/airflow/kubernetes/job/countdown.yaml',\n                                   config_file='/path/to/.kube/config',\n                                   cluster_context='my_kube_config_context')\n```\nWhat is this \"my_kube_config_context\" business? \nRead about it in the kubernetes config documentation [here](https://kubernetes.io/docs/concepts/configuration/organize-cluster-access-kubeconfig/)\n\n\n#### **B.i. Simple yaml file execution**\nIn addition to the above Dag styles you could also make use of Airflow's native ```template_searchpath``` field to clean up the Dag a bit.\n\n```python\nfrom airflow import DAG\nfrom datetime import datetime, timedelta\nfrom airflow_kjo import KubernetesJobOperator\n\ndefault_args = {\n    'owner': 'airflow',\n    'depends_on_past': False,\n    'email': ['airflow@example.com'],\n    'email_on_failure': False,\n    'email_on_retry': False,\n    'retries': 1,\n    'retry_delay': timedelta(minutes=5),\n    'start_date': datetime(2021, 2, 24, 12, 0),\n}\nwith DAG(\n    'kubernetes_job_operator',\n    default_args=default_args,\n    description='KJO example DAG',\n    schedule_interval=None,\n    template_searchpath='/path/to/airflow/kubernetes/job'\n    catchup=False\n) as dag:\n    task_1 = KubernetesJobOperator(task_id='example_kubernetes_job_operator',\n                                   yaml_file_name='countdown.yaml',\n                                   in_cluster=True)\n```\n\n\n#### **B.ii. Simple yaml templating**\nLet's make the yaml a little more interesting.\n```yaml\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: countdown-templated-{{task_num}}\n  namespace: <WRITE YOUR AIRFLOW NAMESPACE HERE>\nspec:\n  template:\n    metadata:\n      name: countdown\n    spec:\n      containers:\n      - name: counter\n        image: centos:7\n        command:\n         - \"bin/bash\"\n         - \"-c\"\n         - \"{{command}}\"\n      restartPolicy: Never\n```\nAnd save this as\n```~/airflow/kubernetes/job/countdown.yaml.tmpl```\n\nWe now have the fields ```command``` and ```task_num``` as variables in our yaml file. \nHere's how our Dag looks now...\n\n```python\nwith DAG(\n    'kubernetes_job_operator',\n    default_args=default_args,\n    description='KJO example DAG',\n    schedule_interval=None,\n    template_searchpath='/path/to/airflow/kubernetes/job'\n    catchup=False\n) as dag:\n    command = 'sleep 60; for i in 5 4 3 2 1 ; do echo $i ; done'\n    task_num = 1\n    task_1 = KubernetesJobOperator(task_id='example_kubernetes_job_operator',\n                                   yaml_file_name='countdown.yaml.tmpl',\n                                   yaml_template_fields={'command': command, 'task_num':task_num},\n                                   in_cluster=True)\n```\n\n\n#### **B.iii. Multiple yaml templates**\nThis is very much up to you how you want your Jinja templates separated, if its valid yaml and valid Jinja, it will render and apply just fine...\n\nHeres an example use case.\n1. Create a 'header' template at ```~/airflow/kubernetes/job/countdown_header.yaml.tmpl```\n   ```yaml\n    apiVersion: batch/v1\n    kind: Job\n    metadata:\n      name: countdown-templated-separated\n      namespace: <WRITE YOUR AIRFLOW NAMESPACE HERE>\n    {% block spec %}{% endblock %}\n   ```\n2. Create a 'body' template at ```~/airflow/kubernetes/job/countdown_body.yaml.tmpl```\n    ```yaml\n    {% extends 'countdown_header.yaml.tmpl' %}\n    {% block spec %}\n    spec:\n    template:\n        metadata:\n        name: countdown\n        spec:\n        containers:\n        - name: counter\n            image: centos:7\n            command:\n            - \"bin/bash\"\n            - \"-c\"\n            - \"{{command}}\"\n        restartPolicy: Never\n    {% endblock %}\n    ```\n\nHere's the Dag changes now\n```python\n    task_1 = KubernetesJobOperator(task_id='example_kubernetes_job_operator',\n                                   yaml_file_name='countdown_body.yaml.tmpl',\n                                   yaml_template_fields={'command': command},\n                                   in_cluster=True)\n```\n\nIn this situation it may be useful to have Airflow write out the rendered yaml file somewhere.\n\n```python\n    task_1 = KubernetesJobOperator(task_id='example_kubernetes_job_operator',\n                                   yaml_file_name='countdown_body.yaml.tmpl',\n                                   yaml_template_fields={'command': command},\n                                   yaml_write_path='/tmp',\n                                   yaml_write_filename='rendered.yaml', # will be on the worker pod\n                                   in_cluster=True)\n```\nIt could be very useful to have an NFS to share the same filestore across pods for writing these rendered yaml files out. \n\n## Logging\n\nIf you're using Kubernetes you should have a logging solution of some sort to aggregate and provide searchability of all your logs. However, here are some use cases for forwarding the logs using the KJO.\n\n    1. I just want a simple tail of the logs, I don't care about extra behavior configuration\n    2. I only want logs tailed out when the pods are in an end state; Completed, Errored\n    3. I want to specify how many lines are tailed out and/or how frequently its tailed out \n\n\n1. Add 'tail_logs' to our task from above.\n```python\n    task_1 = KubernetesJobOperator(task_id='example_kubernetes_job_operator',\n                                   yaml_file_name='countdown_body.yaml.tmpl',\n                                   yaml_template_fields={'command': command},\n                                   in_cluster=True,\n                                   tail_logs=True)\n```\n\nIf any tail_logs* parameter is set, 'tail_logs' does not need to be set.\n\n2. Configure the behavior of the log tail\n```python\n    task_1 = KubernetesJobOperator(task_id='example_kubernetes_job_operator',\n                                   yaml_file_name='countdown_body.yaml.tmpl',\n                                   yaml_template_fields={'command': command},\n                                   in_cluster=True,\n                                   tail_logs_every=60, # seconds\n                                   tail_logs_line_count=100)\n```\n\nThis could get to be quite noisy so be mindful of your particular use case.\n\n## Notes....\n\n-  We need to think about how to add PVC support. If a client's Task relies on a PVC being created, they need a way to add it to their DAG and have it created and deleted as a part of the Job flow. Maybe a KubernetesPVCOperator is better than a parameter solution.\n\n## Contributing\n\n- This is a young project and not yet battle tested. Contributions, suggestions, etc. appreciated. \n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "Apache License 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "airflow-kube-job-operator",
    "package_url": "https://pypi.org/project/airflow-kube-job-operator/",
    "platform": "",
    "project_url": "https://pypi.org/project/airflow-kube-job-operator/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/airflow-kube-job-operator/0.2.5/",
    "requires_dist": [
      "apache-airflow (>=2.0.0)",
      "kubernetes (>=11.0.0)",
      "Jinja2 (>=2.11.3)",
      "pytest ; extra == 'tests'"
    ],
    "requires_python": "",
    "summary": "Kubernetes job operator for Airflow",
    "version": "0.2.5",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12749658,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c6bacaf3f977527bb34fcb096ca8ec634efcfa3add2906f01b2f2b812e451ffa",
          "md5": "d5be864c977612fbebb315b4f39c0a2e",
          "sha256": "959e67dad9c2e9cbee7108f80ce50bc2fa232c10adbce23402a714019be68247"
        },
        "downloads": -1,
        "filename": "airflow_kube_job_operator-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d5be864c977612fbebb315b4f39c0a2e",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 4890,
        "upload_time": "2021-06-08T02:16:32",
        "upload_time_iso_8601": "2021-06-08T02:16:32.990417Z",
        "url": "https://files.pythonhosted.org/packages/c6/ba/caf3f977527bb34fcb096ca8ec634efcfa3add2906f01b2f2b812e451ffa/airflow_kube_job_operator-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "22508698394be37cb2f66a7b612bde807c560ffe40203cba6bafac454f26bed5",
          "md5": "4313b8b2491b83ae7c5006fd5e040edd",
          "sha256": "e187be97fc7d4ac42103e182f6dfa66db21430f8ea968fc365e065be4aa03d9e"
        },
        "downloads": -1,
        "filename": "airflow-kube-job-operator-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "4313b8b2491b83ae7c5006fd5e040edd",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 7405,
        "upload_time": "2021-06-08T02:16:34",
        "upload_time_iso_8601": "2021-06-08T02:16:34.538021Z",
        "url": "https://files.pythonhosted.org/packages/22/50/8698394be37cb2f66a7b612bde807c560ffe40203cba6bafac454f26bed5/airflow-kube-job-operator-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "500b42c2f6f317f1ac70f02388b6d3125c19b9152e55497d1ea2e7aafc978710",
          "md5": "a161a9dabff172785f50f27966d3f88a",
          "sha256": "20350b1aad88f496771a20fd1058bce4d86aa3c4d3d75adaaa78144cad87b57e"
        },
        "downloads": -1,
        "filename": "airflow_kube_job_operator-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "a161a9dabff172785f50f27966d3f88a",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 14444,
        "upload_time": "2021-06-19T18:46:17",
        "upload_time_iso_8601": "2021-06-19T18:46:17.670624Z",
        "url": "https://files.pythonhosted.org/packages/50/0b/42c2f6f317f1ac70f02388b6d3125c19b9152e55497d1ea2e7aafc978710/airflow_kube_job_operator-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f45bb64c0ea1f2525f983a7422796273f9af59d695d05213944978f0e500c81d",
          "md5": "107307b150721846edf61c80bcb5754d",
          "sha256": "eb7e28dcce2d9b091e220b53067b301e3bfdc26837d8b91a759f6762e57540dc"
        },
        "downloads": -1,
        "filename": "airflow-kube-job-operator-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "107307b150721846edf61c80bcb5754d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 14173,
        "upload_time": "2021-06-19T18:46:19",
        "upload_time_iso_8601": "2021-06-19T18:46:19.279605Z",
        "url": "https://files.pythonhosted.org/packages/f4/5b/b64c0ea1f2525f983a7422796273f9af59d695d05213944978f0e500c81d/airflow-kube-job-operator-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "43a7d225e24d5b1192c8b03bbc87b7953e5ed858d4b3e5fd7bfdd3892dcc2674",
          "md5": "7fee42d065907ce47fa48a51ddf8d434",
          "sha256": "7cc5cfad2b13552094c29baebd4f00616cae5c7e9022151d700cce6c4974a621"
        },
        "downloads": -1,
        "filename": "airflow_kube_job_operator-0.2.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "7fee42d065907ce47fa48a51ddf8d434",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 15033,
        "upload_time": "2021-08-23T22:28:33",
        "upload_time_iso_8601": "2021-08-23T22:28:33.003666Z",
        "url": "https://files.pythonhosted.org/packages/43/a7/d225e24d5b1192c8b03bbc87b7953e5ed858d4b3e5fd7bfdd3892dcc2674/airflow_kube_job_operator-0.2.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3134d7945ef0ea9770919c45f2d3f10f19e7ec7b70b877116620e7c099d4edcf",
          "md5": "d61b7dd1f1cb9954bab9d0d7d3c8ebbe",
          "sha256": "4749bf1a30c7872413b3cb3f90030ab7ecb4f32fd9a5f53ab327af8b47e16296"
        },
        "downloads": -1,
        "filename": "airflow-kube-job-operator-0.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "d61b7dd1f1cb9954bab9d0d7d3c8ebbe",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 17820,
        "upload_time": "2021-08-23T22:28:34",
        "upload_time_iso_8601": "2021-08-23T22:28:34.843498Z",
        "url": "https://files.pythonhosted.org/packages/31/34/d7945ef0ea9770919c45f2d3f10f19e7ec7b70b877116620e7c099d4edcf/airflow-kube-job-operator-0.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b53aa467577c6619cf37e162783b509b22e6b8706f13ba68c648f7a206898a05",
          "md5": "50c4061d009529969b5e5cd612cb5078",
          "sha256": "f2797da021c5ed48ce0a4073c219595a6270d3ab1faa60ec7b6e87442255346e"
        },
        "downloads": -1,
        "filename": "airflow_kube_job_operator-0.2.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "50c4061d009529969b5e5cd612cb5078",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 15029,
        "upload_time": "2021-09-27T22:10:17",
        "upload_time_iso_8601": "2021-09-27T22:10:17.481741Z",
        "url": "https://files.pythonhosted.org/packages/b5/3a/a467577c6619cf37e162783b509b22e6b8706f13ba68c648f7a206898a05/airflow_kube_job_operator-0.2.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a345610607480d7828d2938d2d8611065a27823ea0da1363f8803740f25e699b",
          "md5": "7cb039c29e000a6c5a22eb12d459e056",
          "sha256": "098bb6fdfdb7e6e852a4ffcff5dc45271b4a4ec7cdbcd2987cc23801e0708585"
        },
        "downloads": -1,
        "filename": "airflow-kube-job-operator-0.2.1.tar.gz",
        "has_sig": false,
        "md5_digest": "7cb039c29e000a6c5a22eb12d459e056",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 17793,
        "upload_time": "2021-09-27T22:10:18",
        "upload_time_iso_8601": "2021-09-27T22:10:18.912976Z",
        "url": "https://files.pythonhosted.org/packages/a3/45/610607480d7828d2938d2d8611065a27823ea0da1363f8803740f25e699b/airflow-kube-job-operator-0.2.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "975c78b1f7e63ada7dae453bdcbb5257f126060a95a49ebb031341f0a1de9d3c",
          "md5": "3a9ce449d249d18aaa1cbd95407766af",
          "sha256": "4cc236db5f815160830b6b5f216a019ebad129d982604d8f396bfb63618aeedb"
        },
        "downloads": -1,
        "filename": "airflow_kube_job_operator-0.2.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "3a9ce449d249d18aaa1cbd95407766af",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 15013,
        "upload_time": "2021-09-27T22:17:23",
        "upload_time_iso_8601": "2021-09-27T22:17:23.092314Z",
        "url": "https://files.pythonhosted.org/packages/97/5c/78b1f7e63ada7dae453bdcbb5257f126060a95a49ebb031341f0a1de9d3c/airflow_kube_job_operator-0.2.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "63321e3a3c410e73d2cb81b1d2445311463e95b3c811cb94532c121ac9497b0b",
          "md5": "53789e364d97477c376e854b405a6ebc",
          "sha256": "a7b6c2a885ade8b4a3678ea209862fe8e34c51b651764bba9a72bc796aa11e60"
        },
        "downloads": -1,
        "filename": "airflow-kube-job-operator-0.2.2.tar.gz",
        "has_sig": false,
        "md5_digest": "53789e364d97477c376e854b405a6ebc",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 17816,
        "upload_time": "2021-09-27T22:17:24",
        "upload_time_iso_8601": "2021-09-27T22:17:24.742553Z",
        "url": "https://files.pythonhosted.org/packages/63/32/1e3a3c410e73d2cb81b1d2445311463e95b3c811cb94532c121ac9497b0b/airflow-kube-job-operator-0.2.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b009ca041ff6d2956f838b12dc6b53e73c04202b888c1c38bf52ba22e47d33c1",
          "md5": "97f0f4dd91d6847eba2aa9c103cb5b59",
          "sha256": "ac93a32309f27e46b74ba7b3bf9e59600ddfe46f2b7a9c2d88d4972f0fe3f8a9"
        },
        "downloads": -1,
        "filename": "airflow_kube_job_operator-0.2.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "97f0f4dd91d6847eba2aa9c103cb5b59",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 15018,
        "upload_time": "2021-09-27T22:27:15",
        "upload_time_iso_8601": "2021-09-27T22:27:15.434999Z",
        "url": "https://files.pythonhosted.org/packages/b0/09/ca041ff6d2956f838b12dc6b53e73c04202b888c1c38bf52ba22e47d33c1/airflow_kube_job_operator-0.2.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b1412836caaf4f6d2d85aa2a5ad1bc5b9c762b4d76a6b0b92389eca19737c792",
          "md5": "a7bbd59b6371357a58444dbb9746907c",
          "sha256": "0ed86eda0be4e3698eb191416e7c6c4784a42a4be9f6d0303079a2424136643f"
        },
        "downloads": -1,
        "filename": "airflow-kube-job-operator-0.2.3.tar.gz",
        "has_sig": false,
        "md5_digest": "a7bbd59b6371357a58444dbb9746907c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 17797,
        "upload_time": "2021-09-27T22:27:17",
        "upload_time_iso_8601": "2021-09-27T22:27:17.348825Z",
        "url": "https://files.pythonhosted.org/packages/b1/41/2836caaf4f6d2d85aa2a5ad1bc5b9c762b4d76a6b0b92389eca19737c792/airflow-kube-job-operator-0.2.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1b91fb83d63aafe6fabc314eb586380c1b862e5c782f4ff5c0743a13f4c8b664",
          "md5": "685afe7e8f9289ba9bddb0fdf0b4c2c4",
          "sha256": "a3ec8d9c2793912f3ed333376e9eb29cab66d6d2816d1a8f6ba7c87990770fbf"
        },
        "downloads": -1,
        "filename": "airflow_kube_job_operator-0.2.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "685afe7e8f9289ba9bddb0fdf0b4c2c4",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 14390,
        "upload_time": "2022-01-31T21:13:10",
        "upload_time_iso_8601": "2022-01-31T21:13:10.758392Z",
        "url": "https://files.pythonhosted.org/packages/1b/91/fb83d63aafe6fabc314eb586380c1b862e5c782f4ff5c0743a13f4c8b664/airflow_kube_job_operator-0.2.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9af4ae0e83b7d73104715647d175c9fd02e52c715d19ae92bf2f7deb0ebc9399",
          "md5": "180b81aa8c8dd65f2ce9bc9eaf031df4",
          "sha256": "93de59f056885c2ae2a366de806a1d9a5bd57110856b7d65e1a50ecabbfdd0bb"
        },
        "downloads": -1,
        "filename": "airflow-kube-job-operator-0.2.4.tar.gz",
        "has_sig": false,
        "md5_digest": "180b81aa8c8dd65f2ce9bc9eaf031df4",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 16670,
        "upload_time": "2022-01-31T21:13:12",
        "upload_time_iso_8601": "2022-01-31T21:13:12.349155Z",
        "url": "https://files.pythonhosted.org/packages/9a/f4/ae0e83b7d73104715647d175c9fd02e52c715d19ae92bf2f7deb0ebc9399/airflow-kube-job-operator-0.2.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ad3e82e997c421148658b9f333ac1852771690b2a0ff9c63762e705edb245d0a",
          "md5": "f47301c5ed57553656d38d557baa12ad",
          "sha256": "f99e721338f42d5cd7610ebd1f8a7e3e65b082ed46346b39c6160bde4eef5b41"
        },
        "downloads": -1,
        "filename": "airflow_kube_job_operator-0.2.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f47301c5ed57553656d38d557baa12ad",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 14414,
        "upload_time": "2022-01-31T22:21:20",
        "upload_time_iso_8601": "2022-01-31T22:21:20.192105Z",
        "url": "https://files.pythonhosted.org/packages/ad/3e/82e997c421148658b9f333ac1852771690b2a0ff9c63762e705edb245d0a/airflow_kube_job_operator-0.2.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1d78ef745f15a03f9e87059a22b24bd7b18160d63b45cbead0d8e84d07a05605",
          "md5": "ba372ab8780a659ac5238dfc0084fbed",
          "sha256": "3aa84d55c90243682d7e3fbb66221f7cea3004da82ac2638d990bd316f4bede0"
        },
        "downloads": -1,
        "filename": "airflow-kube-job-operator-0.2.5.tar.gz",
        "has_sig": false,
        "md5_digest": "ba372ab8780a659ac5238dfc0084fbed",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 16703,
        "upload_time": "2022-01-31T22:21:21",
        "upload_time_iso_8601": "2022-01-31T22:21:21.966679Z",
        "url": "https://files.pythonhosted.org/packages/1d/78/ef745f15a03f9e87059a22b24bd7b18160d63b45cbead0d8e84d07a05605/airflow-kube-job-operator-0.2.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "ad3e82e997c421148658b9f333ac1852771690b2a0ff9c63762e705edb245d0a",
        "md5": "f47301c5ed57553656d38d557baa12ad",
        "sha256": "f99e721338f42d5cd7610ebd1f8a7e3e65b082ed46346b39c6160bde4eef5b41"
      },
      "downloads": -1,
      "filename": "airflow_kube_job_operator-0.2.5-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "f47301c5ed57553656d38d557baa12ad",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 14414,
      "upload_time": "2022-01-31T22:21:20",
      "upload_time_iso_8601": "2022-01-31T22:21:20.192105Z",
      "url": "https://files.pythonhosted.org/packages/ad/3e/82e997c421148658b9f333ac1852771690b2a0ff9c63762e705edb245d0a/airflow_kube_job_operator-0.2.5-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "1d78ef745f15a03f9e87059a22b24bd7b18160d63b45cbead0d8e84d07a05605",
        "md5": "ba372ab8780a659ac5238dfc0084fbed",
        "sha256": "3aa84d55c90243682d7e3fbb66221f7cea3004da82ac2638d990bd316f4bede0"
      },
      "downloads": -1,
      "filename": "airflow-kube-job-operator-0.2.5.tar.gz",
      "has_sig": false,
      "md5_digest": "ba372ab8780a659ac5238dfc0084fbed",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 16703,
      "upload_time": "2022-01-31T22:21:21",
      "upload_time_iso_8601": "2022-01-31T22:21:21.966679Z",
      "url": "https://files.pythonhosted.org/packages/1d/78/ef745f15a03f9e87059a22b24bd7b18160d63b45cbead0d8e84d07a05605/airflow-kube-job-operator-0.2.5.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}