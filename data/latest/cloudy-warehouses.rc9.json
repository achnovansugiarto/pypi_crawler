{
  "info": {
    "author": "Hashmap, Inc",
    "author_email": "accelerators@hashmapinc.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "<!---\n# Modifications Â© 2020 Hashmap, Inc\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n-->\n# cloudy_warehouses\n\nExtension to pandas to allow for simplified interactions with cloud-based data-platforms.\n\n## Snowflake Support\nThe cloudy_warehouses pandas extension currently supports: \n- reading from a Snowflake table\n- writing to an existing Snowflake table from a pandas dataframe\n- creating a new Snowflake table from a pandas dataframe\n- creating a clone of an existing Snowflake table\n- creating an empty clone of an existing Snowflake table (clones columns, not column data)\n- listing Snowflake tables in a database\n## How To Use cloudy_warehouses\n\n**Installation**\n\n`pip install cloudy-warehouses`\n\n**Configuration** \n\nUpon installation, create an empty `.py` file. Then, configure the python file in the following way:\n```python\nimport pandas as pd \nimport cloudy_warehouses\n\n```\nRun this empty file. After you run the file, a configuration file will be created in your HOME directory.\nThe path to the configuration file is: `$HOME/.cloudy_warehouses/configuration_profiles.yml`\n\nFor Windows user: use $USERPROFILE instead of $HOME variable\n\nThe configuration file is a YAML file with the following format\n```yaml\nprofiles:\n  snowflake:\n    user: <your snowflake username>\n    pass: <your snowflake password>\n    acct: <your snowflake account>\n    role: <your snowflake role>\n    warehouse: <your snowflake warehouse>\n    database: <your snowflake database>\n    schema: <your snowflake schema>\n```\nThe user, pass, acct, database, schema, values all should be filled in with your desired Snowflake credentials and connection details. The variables in this\nfile serve as default arguments when calling a cloudy_warehouses method. Role and warehouse can be filled in as well, but they are optional arguments when connecting to Snowflake.\n\n\n\n## API\nThe intent has been to keep the API as simple as possible by minimally extending the pandas API and supporting, for the most part, the same functionality.\n\n### Optional Arguments\nThere are two methods for passing optional arguments into a method.\n1. The configuration file\n2. Directly pass in the arguments when calling the method\n\nThe variables saved in the configuration file serve as default arguments for the methods to use.\nHowever, you tell the method to use different credentials by passing in arguments directly. The method will use the passed in arguments \ninstead of the default arguments saved in `configuration_profiles.yml`. \n\nFor example, if I had the `database` variable saved in the `configuration_profiles.yml` as `database_1`, but passed in `database = database_2` directly into the method,\nthe method would use `database_2` instead of `database_1`. \n\nHowever, if I choose to not directly pass a `database` argument in, the method will use the \n`database_1` because it is the default. The passed in arguments take priority over the default variables saved in `configuration_profiles.yml`.\n### Reading a from a Snowflake table\n```python\npandas.read_snowflake(table: str, \n                      username: str = None, \n                      password: str = None, \n                      account: str = None,\n                      database: str = None, \n                      schema: str = None, \n                      role: str = None, \n                      warehouse: str = None\n                     )\n```\nThis method reads from a Snowflake table and returns the data in said tables as a pandas DataFrame.\n\n### Listing all tables in a Snowflake database\n```python\npandas.list_snowflake_tables(database: str = None, \n                             username: str = None, \n                             password: str = None, \n                             account: str = None,\n                             role: str = None, \n                             warehouse: str = None\n                            )\n```\nThis method returns all of the tables in a Snowflake database as a pandas DataFrame. \n\n### Writing to a Snowflake table\n```python\npandas.DataFrame.cloudy_warehouses.write_snowflake(table: str,\n                                                   database: str = None, \n                                                   schema: str = None, \n                                                   username: str = None,\n                                                   password: str = None, \n                                                   account: str = None, \n                                                   role: str = None, \n                                                   warehouse: str = None,\n                                                   overwrite: bool = False\n                                                  )\n```\nThis method writes to a Snowflake table and informs you on success. This method works when writing to either an existing Snowflake table or a previously non-existing Snowflake table. \nIf the table that you provide does not exist, this method creates a new Snowflake table and writes to it. If the table already exists, the DataFrame data is \nappended to the existing table by default. If you would like to replace the table with the pandas DataFrame\nset `overwrite = True` when calling the method.\n\n### Creating a clone of an existing Snowflake table\n```python\npandas.clone_snowflake(new_table: str, \n                       source_table: str, \n                       source_schema: str = None, \n                       source_database: str = None,\n                       database: str = None, \n                       schema: str = None, \n                       username: str = None, \n                       password: str = None,\n                       account: str = None, \n                       role: str = None, \n                       warehouse: str = None\n                      )           \n```\nThis method creates a clone of an existing Snowflake table. The `new_table` variable is the new table that will\nbe created after the method is called. The `source_table` variable is the existing Snowflake table that is being cloned.\nThe optional `source_database` and `source_schema` variables are the database and schema in which the `source_table` resides.\nIf you plan to clone an existing table from the schema and database that the `new_table` will reside in, you do not need to \ninclude `source_database` and `source_schema` variables.\n\n### Creating an empty clone of an existing Snowflake table\n```python\npandas.clone_empty_snowflake(new_table: str, \n                             source_table: str,\n                             source_database: str = None, \n                             source_schema: str = None,\n                             database: str = None, \n                             schema: str = None,\n                             username: str = None,\n                             password: str = None, \n                             account: str = None, \n                             role: str = None, \n                             warehouse: str = None\n                            )           \n```\nThis method creates an empty clone of an existing Snowflake table. This means that of the columns from the `source_table`\nare copied into the `new_table`, but the `new_table` does not have any data within its columns. The `new_table` variable is the new table that will\nbe created after the method is called. The `source_table` variable is the existing Snowflake table that is being cloned. \nThe optional `source_database` and `source_schema` variables are the database and schema in which the `source_table` resides.\nIf you plan to clone an existing table from the schema and database that the `new_table` will reside in, you do not need to \ninclude `source_database` and `source_schema` variables.\n\n## Examples\n\n__Reading, Writing, and Listing (using configuration file)__\n```python\nimport pandas as pd \nimport cloudy_warehouses\n\npd.list_snowflake_tables(role='SNOWFLAKE_ROLE')\n\ndf_to_write = pd.DataFrame.from_dict({'a': [1, 2, 3], 'b': [2, 3, 5]})\n\ndf_to_write.cloudy_warehouses.write_snowflake(table='SNOWFLAKE_TABLE', role='SNOWFLAKE_ROLE')\n\ndf_read_from_snowflake = pd.read_snowflake(table='SNOWFLAKE_TABLE', role='SNOWFLAKE_ROLE')\n```\nThe methods called in this example use the `database`, `schema`, `warehouse`, and account credentials stored in `configuration_profiles.yml`.\nHowever, the `role` is directly passed in and therefore overwrites the default `role` saved in the configuraiton file.\n\n__Cloning and Empty Cloning (using configuration file)__\n```python\nimport pandas as pd \nimport cloudy_warehouses\n\ndf = pd.DataFrame.from_dict({'COL_1': ['hello', 'there'], 'COL_2': [10, 20], 'COL_3': [10, 20]})\n\npd.clone_snowflake(\n    new_table='SNOWFLAKE_TABLE',\n    source_table='SNOWFLAKE_TABLE_TO_BE_CLONED',\n    source_schema='SNOWFLAKE_SCHEMA_THAT_HOLDS_THE_SOURCE_TABLE'\n    )\n\npd.clone_empty_snowflake(\n    new_table='SNOWFLAKE_TABLE',\n    source_table='SNOWFLAKE_TABLE_TO_BE_CLONED',\n    source_schema='SNOWFLAKE_SCHEMA_THAT_HOLDS_THE_SOURCE_TABLE',\n    source_database='SNOWFLAKE_DATABASE_THAT_HOLDS_THE_SOURCE_SCHEMA'\n    )\n```\nThe methods called in this example use the `database`, `schema`, `warehouse`, `role` and account credentials stored in `configuration_profiles.yml`.\nThe newly cloned table will be saved in the default `database` and `schema` in the configuration file.\n\n__Reading, Writing, and Listing (using optional Snowflake credentials arguments)__\n\n```python\nimport pandas as pd\nimport cloudy_warehouses\n\npd.list_snowflake_tables(\n    database='SNOWFLAKE_DATABASE',\n    username='my_snowflake_username',\n    password='my_snowflake_password',\n    account='my_snowflake_account',\n    warehouse='my_snowflake_warehouse',\n    role='my_snowflake_role'\n)\n\ndf_to_write = pd.DataFrame.from_dict({'a': [1, 2, 3], 'b': [2, 3, 5]})\n\ndf_to_write.cloudy_warehouses.write_snowflake(\n    database='SNOWFLAKE_DATABASE',\n    schema='SNOWFLAKE_SCHEMA',\n    table='SNOWFLAKE_TABLE',\n    username='my_snowflake_username',\n    password='my_snowflake_password',\n    account='my_snowflake_account',\n    overwrite=True\n)\n\ndf_read_from_snowflake = pd.read_snowflake(\n    schema='SNOWFLAKE_SCHEMA',\n    table='SNOWFLAKE_TABLE',\n    username='my_snowflake_username',\n    password='my_snowflake_password',\n    account='my_snowflake_account',\n    role='my_snowflake_role'\n)\n```\nThe arguments passed in here will be used instead of the default variables saved in the configuration file.\nFor example, in last method called, the schema, username, password, account, and role are all passed in. However, this \nmethod will use the default `database` variable because there is not one directly passed in.\n\nWhen the `write_snowflake` method is called in the above example, `overwrite=True`. This means that the Snowflake table being uploaded to will replace any existing data with the pandas DataFrame data.\n\n__Cloning and Empty Cloning (using optional Snowflake credentials arguments)__\n```python\nimport pandas as pd \nimport cloudy_warehouses\n\ndf = pd.DataFrame.from_dict({'COL_1': ['hello', 'there'], 'COL_2': [10, 20], 'COL_3': [10, 20]})\n\npd.clone_snowflake(\n    database='SNOWFLAKE_DATABASE', \n    schema='SNOWFLAKE_SCHEMA',\n    new_table='SNOWFLAKE_TABLE',\n    source_table='SNOWFLAKE_TABLE_TO_BE_CLONED',\n    source_schema='SNOWFLAKE_SCHEMA_THAT_HOLDS_THE_SOURCE_TABLE',\n    source_database='SNOWFLAKE_DATABASE_THAT_HOLDS_THE_SOURCE_SCHEMA',\n    username='my_snowflake_username', \n    password='my_snowflake_password', \n    account='my_snowflake_account',\n    warehouse='my_snowflake_warehouse',\n    role='my_snowflake_role'\n    )\n\npd.clone_empty_snowflake(\n    database='SNOWFLAKE_DATABASE', \n    schema='SNOWFLAKE_SCHEMA',\n    new_table='SNOWFLAKE_TABLE',\n    source_table='SNOWFLAKE_TABLE_TO_BE_CLONED',\n    username='my_snowflake_username', \n    password='my_snowflake_password', \n    account='my_snowflake_account'\n    )\n```",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/hashmapinc/oss/cloudy_warehouses",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "cloudy-warehouses",
    "package_url": "https://pypi.org/project/cloudy-warehouses/",
    "platform": "",
    "project_url": "https://pypi.org/project/cloudy-warehouses/",
    "project_urls": {
      "Homepage": "https://github.com/hashmapinc/oss/cloudy_warehouses"
    },
    "release_url": "https://pypi.org/project/cloudy-warehouses/0.1.0.1/",
    "requires_dist": null,
    "requires_python": ">=3.7",
    "summary": "Cloudy Warehouses allows for stream-lined interaction between pandas and cloud data platform providers.",
    "version": "0.1.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 9869131,
  "releases": {
    "0.0.3.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7344740b0492eff86735649fccea2426c8f91c91d767dfe28228919a3aee367d",
          "md5": "0a91b3d7cb97e470531e36708edf9b71",
          "sha256": "228f56ef8979e74da10342b7a0975a86cb3bc42d33f67543d3a58360bc731bf1"
        },
        "downloads": -1,
        "filename": "cloudy_warehouses-0.0.3.6.tar.gz",
        "has_sig": false,
        "md5_digest": "0a91b3d7cb97e470531e36708edf9b71",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 9883,
        "upload_time": "2020-12-15T19:44:17",
        "upload_time_iso_8601": "2020-12-15T19:44:17.843485Z",
        "url": "https://files.pythonhosted.org/packages/73/44/740b0492eff86735649fccea2426c8f91c91d767dfe28228919a3aee367d/cloudy_warehouses-0.0.3.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4885b7d2f8fb854d54d18749a86b3ed786c4a87eab48e958d60b7f2f96284764",
          "md5": "70079e71b7a0995de10e63482325bf86",
          "sha256": "035518fcf09995d60b4358a42c002e33d030752ec9f1bfd6103d97165c613b2d"
        },
        "downloads": -1,
        "filename": "cloudy_warehouses-0.0.3.7.tar.gz",
        "has_sig": false,
        "md5_digest": "70079e71b7a0995de10e63482325bf86",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 10011,
        "upload_time": "2020-12-15T21:08:31",
        "upload_time_iso_8601": "2020-12-15T21:08:31.557264Z",
        "url": "https://files.pythonhosted.org/packages/48/85/b7d2f8fb854d54d18749a86b3ed786c4a87eab48e958d60b7f2f96284764/cloudy_warehouses-0.0.3.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "539b610c1948200c64fbae834518ee3c7505cbf7285f035c2284ab4c31935243",
          "md5": "9c695ae66aa8f7222fd7e1f265e6a18c",
          "sha256": "12ccb8163becb2bc381b4d77cb43f2175d3980ea7c41b6accb3fb383bad36cc7"
        },
        "downloads": -1,
        "filename": "cloudy_warehouses-0.0.3.8.tar.gz",
        "has_sig": false,
        "md5_digest": "9c695ae66aa8f7222fd7e1f265e6a18c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 9715,
        "upload_time": "2020-12-16T19:45:52",
        "upload_time_iso_8601": "2020-12-16T19:45:52.134276Z",
        "url": "https://files.pythonhosted.org/packages/53/9b/610c1948200c64fbae834518ee3c7505cbf7285f035c2284ab4c31935243/cloudy_warehouses-0.0.3.8.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3.9": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fe22c824618e8c584975f37fe36ff4b89bb63c902810d7bf3f215270a3a841c5",
          "md5": "de362fe1bc724b894cee042664aaf7d8",
          "sha256": "a2c2e73c1c149b85006dedc8d1d800516914c38e986936f6afe2a8c48c1b7c57"
        },
        "downloads": -1,
        "filename": "cloudy_warehouses-0.0.3.9.tar.gz",
        "has_sig": false,
        "md5_digest": "de362fe1bc724b894cee042664aaf7d8",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 9745,
        "upload_time": "2020-12-16T19:59:45",
        "upload_time_iso_8601": "2020-12-16T19:59:45.552784Z",
        "url": "https://files.pythonhosted.org/packages/fe/22/c824618e8c584975f37fe36ff4b89bb63c902810d7bf3f215270a3a841c5/cloudy_warehouses-0.0.3.9.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b82a17c955d9da69fa68c8090cd9d8b5290a94af0eadfb53e3575e0c379400c1",
          "md5": "a84ebbcaa5268c65f7d6995208cee090",
          "sha256": "ca177bd1b5d853bc49832e89cc2661f728927dfaa996baf1f4535bf2f8b385e1"
        },
        "downloads": -1,
        "filename": "cloudy_warehouses-0.0.4.0.tar.gz",
        "has_sig": false,
        "md5_digest": "a84ebbcaa5268c65f7d6995208cee090",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 9697,
        "upload_time": "2021-01-04T15:27:45",
        "upload_time_iso_8601": "2021-01-04T15:27:45.005688Z",
        "url": "https://files.pythonhosted.org/packages/b8/2a/17c955d9da69fa68c8090cd9d8b5290a94af0eadfb53e3575e0c379400c1/cloudy_warehouses-0.0.4.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1536c0b4c4763647774b2e19386ec7d0f3e70cd30d49c2644151713356b707a1",
          "md5": "d8f91fda0dbfe7020c482ed8bf0b6e4d",
          "sha256": "657d273f5f3065db67827be03c4041a5de36dcd1f0730209990b0562cb8cb164"
        },
        "downloads": -1,
        "filename": "cloudy_warehouses-0.0.4.1.tar.gz",
        "has_sig": false,
        "md5_digest": "d8f91fda0dbfe7020c482ed8bf0b6e4d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 10209,
        "upload_time": "2021-01-05T15:46:42",
        "upload_time_iso_8601": "2021-01-05T15:46:42.039817Z",
        "url": "https://files.pythonhosted.org/packages/15/36/c0b4c4763647774b2e19386ec7d0f3e70cd30d49c2644151713356b707a1/cloudy_warehouses-0.0.4.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cc6395215ab5fa44c27e11f1dfeb74ef40d7b32fb418377b533ba6a343872dbd",
          "md5": "2b36d6b6bc566779d96e9ed2d42e86ec",
          "sha256": "339ab60967d00142474df2e68dc6628aa79cbf6f1804782594568c6a72ddd12c"
        },
        "downloads": -1,
        "filename": "cloudy_warehouses-0.0.4.2.tar.gz",
        "has_sig": false,
        "md5_digest": "2b36d6b6bc566779d96e9ed2d42e86ec",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 11395,
        "upload_time": "2021-01-05T20:46:12",
        "upload_time_iso_8601": "2021-01-05T20:46:12.644745Z",
        "url": "https://files.pythonhosted.org/packages/cc/63/95215ab5fa44c27e11f1dfeb74ef40d7b32fb418377b533ba6a343872dbd/cloudy_warehouses-0.0.4.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9fc4ee45320f4f0b9737b7c58c43c82dfa9a29386e0d36b3bb9877c3c834ee69",
          "md5": "211bbd1332e52b2ef9fe071f3593a6ea",
          "sha256": "628dafadfff1e8b8ce3c368a474764884ef09a96299e359d9ce0082bccf8447f"
        },
        "downloads": -1,
        "filename": "cloudy_warehouses-0.1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "211bbd1332e52b2ef9fe071f3593a6ea",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 11620,
        "upload_time": "2021-01-22T19:41:40",
        "upload_time_iso_8601": "2021-01-22T19:41:40.733729Z",
        "url": "https://files.pythonhosted.org/packages/9f/c4/ee45320f4f0b9737b7c58c43c82dfa9a29386e0d36b3bb9877c3c834ee69/cloudy_warehouses-0.1.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f1376d64b3af852e9890655df5b1aa6e6dbcf647d08a9004dc2516639dbf4adc",
          "md5": "c00b8bb3adb44eac89d7251df84c12b9",
          "sha256": "afd539a42e29db75f4195bdfaa22e8e9e67cc1d12ecf1ba860439eb5328da6a8"
        },
        "downloads": -1,
        "filename": "cloudy_warehouses-0.1.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "c00b8bb3adb44eac89d7251df84c12b9",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 11655,
        "upload_time": "2021-03-24T18:43:51",
        "upload_time_iso_8601": "2021-03-24T18:43:51.926443Z",
        "url": "https://files.pythonhosted.org/packages/f1/37/6d64b3af852e9890655df5b1aa6e6dbcf647d08a9004dc2516639dbf4adc/cloudy_warehouses-0.1.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "f1376d64b3af852e9890655df5b1aa6e6dbcf647d08a9004dc2516639dbf4adc",
        "md5": "c00b8bb3adb44eac89d7251df84c12b9",
        "sha256": "afd539a42e29db75f4195bdfaa22e8e9e67cc1d12ecf1ba860439eb5328da6a8"
      },
      "downloads": -1,
      "filename": "cloudy_warehouses-0.1.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "c00b8bb3adb44eac89d7251df84c12b9",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 11655,
      "upload_time": "2021-03-24T18:43:51",
      "upload_time_iso_8601": "2021-03-24T18:43:51.926443Z",
      "url": "https://files.pythonhosted.org/packages/f1/37/6d64b3af852e9890655df5b1aa6e6dbcf647d08a9004dc2516639dbf4adc/cloudy_warehouses-0.1.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}