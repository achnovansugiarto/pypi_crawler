{
  "info": {
    "author": "BecomeAllan (Allan)",
    "author_email": "<allan.filesia@gmail.com>",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Developers",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: MIT License",
      "Operating System :: MacOS :: MacOS X",
      "Operating System :: Microsoft :: Windows",
      "Operating System :: Unix",
      "Programming Language :: Python :: 3",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "# How to install\n\n```python\npip install S2search\n```\n# S2search\n\nSematic Scholar paper search developed by BecomeAllan (c) 2020 is library that can search papers on [Semantic Scholar page](https://www.semanticscholar.org/) or in the [API](https://api.semanticscholar.org/graph/v1) provided by them.\n\nS2search is an request http library, written in Python, to retrieve papers available in Semantic Scholar.\n\n# Examples\n\nWe have two main classes, that can handle the paper data. To make a query about more than one topic, title, etc... The parameter `search`, have to be a string like:\n\nto add some, use `+`:\n\n+ `search = \"artificial intelligence+Deep Learning\"`\n\nor if you want to exclude some, use the `-` to exclude:\n\n+ `search = \"artificial intelligence-application\"`\n  \n## S2paperAPI()\n\nThe `S2paperAPI()`, consume the API of Semantic Scholar. See the [Link](https://api.semanticscholar.org/graph/v1) to understand more about the API.\n\nThe return in `.all` is a Pandas [DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html).\n\n```python\n   >>> from S2search import S2paperAPI\n   >>> m = S2paperAPI()\n   >>> m.get(\"artificial intelligence\", n=2)\n   >>> m.all.shape\n   (2, 12)\n   >>> m.all['title']\n   0    Explainable Artificial Intelligence (XAI): Con...\n   1    Explanation in Artificial Intelligence: Insigh...\n   Name: title, dtype: object\n```\n\n## S2paperWeb()\n\nThe `S2paperWeb()`, consume the content in the [page](https://www.semanticscholar.org/) in Semantic Scholar.\n\nThe return in `.all` is a dictionary arranged about the pages founded.\n\n```python\n   >>> from S2search import S2paperWeb\n   >>> m = S2paperWeb()\n   >>> m.get(\"artificial intelligence+Deep Learning\", n=3, sort = \"total-citations\", fieldsOfStudy = ['biology'])\n   >>> len(m.all['Results'][0]['Page']['Papers'])\n   3\n   >>> m.all['Results'][0]['Page']['Papers'][0].keys()\n   dict_keys(['authors', 'id', 'socialLinks', 'title', 'paperAbstract', 'year',\n    'venue', 'citationContexts', 'citationStats', 'sources', 'externalContentStats',\n    'journal', 'presentationUrls', 'links', 'primaryPaperLink', 'alternatePaperLinks',\n    'entities', 'entityRelations', 'blogs', 'videos', 'githubReferences',\n    'scorecardStats', 'fieldsOfStudy', 'pubDate', 'pubUpdateDate',\n    'badges', 'tldr'])\n```\n\n# Parameters\n\nThese classes have an optimization with CPU cores that make multiple requests at the same time, which is passed as a parameter like the number of cores pass as parameter `poolCPU`. Because of this fact, the Semantic Scholar server may stop receiving requests for a while, so we have defined a timeout in seconds so that we can continue these requests, the parameter is `sleeptry`.\n\n\n## Example\n\n```python\n   >>> from S2search import S2paperWeb, S2paperAPI\n   >>> m = S2paperWeb(poolCPU = 2, sleeptry = 60)\n   >>> k = S2paperAPI(poolCPU = 4, sleeptry = 5)\n```\n\nTo more specific search, this classes have a main function `.get()` with can hame some parameters that can help.\n\n+ `S2paperAPI().get(search, n = 10, offset = 0, papers = [], save = False, saveName = Data, fields = [\"title\",\"abstract\",\"isOpenAccess\",\"fieldsOfStudy\"])`\n\n    - Parameters:\n      - `search : (str)` |\n          The main query in Semantic Scholar API about the papers.\n      - `n : (int)` |\n          The number of papers to get, the maximum is 10.000.\n      - `offset : (int)` |\n          Where start to return the papers, the default is 0,\n          that is the first paper found.\n      - `papers : list(int)` |\n          A list of positions of the papers (0 is the first one), if pass a list, the parameters (n, offset)\n          have no effect in the main query (search). The default is a empty list [].\n      - `save : (bool)` |\n          If true, will save the data set in a file csv at the current directory. the default is False.\n      - `saveName : (str)` |\n          The name of the file when the save is set True.\n      - `fields : list(str)` |\n          The dataframe columns that the Semantic Scholar API returns, see the documentation in [Semantic Scholar API Doc.](https://api.semanticscholar.org/graph/v1#operation/get_graph_get_paper_search).\n\n\n+ `S2paperWeb().get(search, n = 10, offset = 0, papers = [], save = False, saveName = Data, **kwargs)`\n    - Parameters:\n      - `search : (str)` |\n          The main query in Semantic Scholar API about the papers.\n      - `n : (int)` |\n          The number of papers to get.\n       - `save : (bool)` |\n          If true, will save the data set in a file csv at the current directory. the default is False.\n      - `saveName : (str)` |\n          The name of the file when the save is set True.\n      - `page : (int)` |\n          Where start to return of the papers, the default is 1, that is the first paper found.\n      - `sort : (str)` |\n          The order of the return paper, the options are `(\"total-citations\", \"influence\", \"pub-date\", \"relevance\")`.\n          The default is \"relevance\".\n      - `authors : list(str)` |\n          The filter of authors. The default is `[]`.\n      - `coAuthors : list(str)` |\n          The filter of cothors. The default is `[]`.\n      - `venues : list(str)` |\n          The filter of venues. The options are `[\"PloS one\", \"AAAI\", \"Scientific reports\", \"IEEE Access\", \"ArXiv\",\n          \"Expert Syst. Appl.\"\"ICML\", \"Neurocomputing\", \"Sensors\", \"Remote. Sens.\"]`. The default is `[]`.\n      - `yearFilter : dict({\"min\": int, \"max\": int})` |\n          The filter of year. Ex. `{\"min\": 1999, \"max\": 2021}`. The default is `None`.\n      - `requireViewablePdf : (bool)` |\n          If the paper have pdf.\n      - `publicationTypes : list(str)` |\n          The filter of type publication, the options are `[\"ClinicalTrial\",\"CaseReport\",\"Editorial\",\"Study\",\n          \"Book\",\"News\",\"Review\",\"Conference\",\"LettersAndComments\",\"JournalArticle\"]`. The default is `[]`\n      - `fieldsOfStudy : list(str)` |\n          The filter of fields of study, the options are `[\"biology\",\"art\",\"business\",\n          \"computer-science\",\"chemistry\",\"economics\",\"engineering\",\"environmental-science\",\n          \"geography\",\"geology\",\"history\",\"materials-science\",\"mathematics\",\"medicine\",\"philosophy\",\n          \"physics\",\"political-science\",\"psychology\",\"sociology\"]`. The default is `[]`.\n      - `useFallbackRankerService : (bool)` |\n          Fall back to rank the match papers. The defalt is `False`.\n      - `useFallbackSearchCluster : (bool)` |\n          Fall back to cluster the match papers. The defalt is `False`.\n      - `hydrateWithDdb : (bool)` |\n          The defalt is `True`.\n      - `includeTldrs : (bool)` |\n          AI based summary abstracts of papers. The defalt is `True`.\n      - `\"tldrModelVersion\" : (str)` |\n          The AI version. The default is `\"v2.0.0\"`\n      - `performTitleMatch: (bool)` |\n          Match papers about title. The defalt is `True`.\n      - `includeBadges: (bool)` |\n          Some bagdes about the papers. The defalt is `True`.\n      - `getQuerySuggestions: (bool)` |\n          Some query suggestions. The defalt is `True`.\n      - `papers : list(int)` |\n          A list of positions of the papers (0 is the first one), if pass a list, the parameters (n, offset)\n          have no effect in the main query (search). The default is a empty list [].\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "python,Semantic Scholar,API,Papers,semantic-scholar,papers",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "S2search",
    "package_url": "https://pypi.org/project/S2search/",
    "platform": null,
    "project_url": "https://pypi.org/project/S2search/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/S2search/1.0.4.3/",
    "requires_dist": [
      "requests",
      "pandas"
    ],
    "requires_python": "",
    "summary": "Semantic Scholar paper api consuming",
    "version": "1.0.4.3",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 13700691,
  "releases": {
    "1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c009632cb43ac9f7ceff19f9df872e0161eb0c10c344e3e4f4d026afcade728c",
          "md5": "34bfc7088c6b2d8b6d4166d9b71964f6",
          "sha256": "a6ffbc2417a6183fbdf8d1c61782d1767314357085b75b5ee3864baa032058ec"
        },
        "downloads": -1,
        "filename": "S2search-1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "34bfc7088c6b2d8b6d4166d9b71964f6",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 11461,
        "upload_time": "2022-05-03T16:07:37",
        "upload_time_iso_8601": "2022-05-03T16:07:37.483589Z",
        "url": "https://files.pythonhosted.org/packages/c0/09/632cb43ac9f7ceff19f9df872e0161eb0c10c344e3e4f4d026afcade728c/S2search-1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.4.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "65d243f3fa33513c1b0eee10730cba6e38cc345d71b2ca7988886e97f7ca891f",
          "md5": "07946b0dbd3ae2155adf4955fa0e5ee5",
          "sha256": "c4bcddb31596dc339ce9ee7d100caeb76d289dbb05ab9146a911e6ea808700ec"
        },
        "downloads": -1,
        "filename": "S2search-1.0.4.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "07946b0dbd3ae2155adf4955fa0e5ee5",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 13730,
        "upload_time": "2022-04-06T15:35:20",
        "upload_time_iso_8601": "2022-04-06T15:35:20.149581Z",
        "url": "https://files.pythonhosted.org/packages/65/d2/43f3fa33513c1b0eee10730cba6e38cc345d71b2ca7988886e97f7ca891f/S2search-1.0.4.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d59aa349a30466a5b88b4d5cfb58bd156721c4c46e2093bf890c8c23e607825e",
          "md5": "9065095ec3e2e43284df01523e13c711",
          "sha256": "60591d40cc7ee19c28f99b75f56fc51ac402d9cefc99d018dcbf2d9a1bba7185"
        },
        "downloads": -1,
        "filename": "S2search-1.0.4.3.tar.gz",
        "has_sig": false,
        "md5_digest": "9065095ec3e2e43284df01523e13c711",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 11224,
        "upload_time": "2022-04-06T15:35:21",
        "upload_time_iso_8601": "2022-04-06T15:35:21.294599Z",
        "url": "https://files.pythonhosted.org/packages/d5/9a/a349a30466a5b88b4d5cfb58bd156721c4c46e2093bf890c8c23e607825e/S2search-1.0.4.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "65d243f3fa33513c1b0eee10730cba6e38cc345d71b2ca7988886e97f7ca891f",
        "md5": "07946b0dbd3ae2155adf4955fa0e5ee5",
        "sha256": "c4bcddb31596dc339ce9ee7d100caeb76d289dbb05ab9146a911e6ea808700ec"
      },
      "downloads": -1,
      "filename": "S2search-1.0.4.3-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "07946b0dbd3ae2155adf4955fa0e5ee5",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 13730,
      "upload_time": "2022-04-06T15:35:20",
      "upload_time_iso_8601": "2022-04-06T15:35:20.149581Z",
      "url": "https://files.pythonhosted.org/packages/65/d2/43f3fa33513c1b0eee10730cba6e38cc345d71b2ca7988886e97f7ca891f/S2search-1.0.4.3-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "d59aa349a30466a5b88b4d5cfb58bd156721c4c46e2093bf890c8c23e607825e",
        "md5": "9065095ec3e2e43284df01523e13c711",
        "sha256": "60591d40cc7ee19c28f99b75f56fc51ac402d9cefc99d018dcbf2d9a1bba7185"
      },
      "downloads": -1,
      "filename": "S2search-1.0.4.3.tar.gz",
      "has_sig": false,
      "md5_digest": "9065095ec3e2e43284df01523e13c711",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 11224,
      "upload_time": "2022-04-06T15:35:21",
      "upload_time_iso_8601": "2022-04-06T15:35:21.294599Z",
      "url": "https://files.pythonhosted.org/packages/d5/9a/a349a30466a5b88b4d5cfb58bd156721c4c46e2093bf890c8c23e607825e/S2search-1.0.4.3.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}