{
  "info": {
    "author": "",
    "author_email": "Paul Andrey <paul.andrey@inria.fr>, Nathan Bigaud <nathan.bigaud@inria.fr>",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: Unix",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.11",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Topic :: Scientific/Engineering :: Artificial Intelligence",
      "Topic :: Scientific/Engineering :: Mathematics",
      "Typing :: Typed"
    ],
    "description": "# Declearn: a modular and extensible framework for Federated Learning\n\n- [Introduction](#introduction)\n- [Setup](#setup)\n- [Quickstart](#quickstart)\n- [Usage of the Python API](#usage-of-the-python-api)\n  - [Overview of the Federated Learning process](#overview-of-the-federated-learning-process)\n  - [Overview of the declearn API](#overview-of-the-declearn-api)\n  - [Hands-on usage](#hands-on-usage)\n  - [Overview of local differential-privacy capabilities](#local-differential-privacy)\n- [Developers](#developers)\n- [Copyright](#copyright)\n--------------------\n\n## Introduction\n\n`declearn` is a python package providing with a framework to perform federated\nlearning, i.e. to train machine learning models by distributing computations\nacross a set of data owners that, consequently, only have to share aggregated\ninformation (rather than individual data samples) with an orchestrating server\n(and, by extension, with each other).\n\nThe aim of `declearn` is to provide both real-world end-users and algorithm\nresearchers with a modular and extensible framework that:\n\n- builds on **abstractions** general enough to write backbone algorithmic code\n  agnostic to the actual computation framework, statistical model details\n  or network communications setup\n- designs **modular and combinable** objects, so that algorithmic features, and\n  more generally any specific implementation of a component (the model, network\n  protocol, client or server optimizer...) may easily be plugged into the main\n  federated learning process - enabling users to experiment with configurations\n  that intersect unitary features\n- provides with functioning tools that may be used **out-of-the-box** to set up\n  federated learning tasks using some popular computation frameworks (scikit-\n  learn, tensorflow, pytorch...) and federated learning algorithms (FedAvg,\n  Scaffold, FedYogi...)\n- provides with tools that enable **extending** the support of existing tools\n  and APIs to custom functions and classes without having to hack into the\n  source code, merely adding new features (tensor libraries, model classes,\n  optimization plug-ins, orchestration algorithms, communication protocols...)\n  to the party\n\nAt the moment, `declearn` has been focused on so-called \"centralized\" federated\nlearning that implies a central server orchestrating computations, but it might\nbecome more oriented towards decentralized processes in the future, that remove\nthe use of a central agent.\n\n## Setup\n\n### Requirements\n\n- python >= 3.8\n- pip\n\nThird-party requirements are specified (and automatically installed) as part\nof the installation process, and may be consulted from the `pyproject.toml`\nfile.\n\n### Optional requirements\n\nSome third-party requirements are optional, and may not be installed. These\nare also specified as part of the `pyproject.toml` file, and may be divided\ninto two categories:<br/>\n(a) dependencies of optional, applied declearn components (such as the PyTorch\nand Tensorflow tensor libraries, or the gRPC and websockets network\ncommunication backends) that are not imported with declearn by default<br/>\n(b) dependencies for running tests on the package (mainly pytest and some of\nits plug-ins)\n\nThe second category is more developer-oriented, while the first may or may not\nbe relevant depending on the use case to which you wish to apply `declearn`.\n\nIn the `pyproject.toml` file, the `[project.optional-dependencies]` tables\n`all` and `test` respectively list the first and (first + second) categories,\nwhile additional tables redundantly list dependencies unit by unit.\n\n### Using a virtual environment (optional)\n\nIt is generally advised to use a virtual environment, to avoid any dependency\nconflict between declearn and packages you might use in separate projects. To\ndo so, you may for example use python's built-in\n[venv](https://docs.python.org/3/library/venv.html), or the third-party tool\n[conda](https://docs.conda.io/en/latest/).\n\nVenv instructions (example):\n\n```bash\npython -m venv ~/.venvs/declearn\nsource ~/.venvs/declearn/bin/activate\n```\n\nConda instructions (example):\n\n```bash\nconda create -n declearn python=3.8 pip\nconda activate declearn\n```\n\n_Note: at the moment, conda installation is not recommended, because the\npackage's installation is made slightly harder due to some dependencies being\ninstallable via conda while other are only available via pip/pypi, which caninstall\nlead to dependency-tracking trouble._\n\n### Installation\n\n#### Install from PyPI\n\nStable releases of the package are uploaded to\n[PyPI](https://pypi.org/project/declearn/), enabling one to install with:\n\n```bash\npip install declearn  # optionally with version constraints and/or extras\n```\n\n#### Install from source\n\nAlternatively, to install from source, one may clone the git repository (or\ndownload the source code from a release) and run `pip install .` from its\nroot folder.\n\n```bash\ngit clone git@gitlab.inria.fr:magnet/declearn/declearn.git\ncd declearn\npip install .  # or pip install -e .\n```\n\n#### Install extra dependencies\n\nTo also install optional requirements, add the name of the extras between\nbrackets to the `pip install` command, _e.g._ running one of the following:\n\n```bash\n# Examples of cherry-picked installation instructions.\npip install declearn[grpc]   # install dependencies to use gRPC communications\npip install declearn[torch]  # install `declearn.model.torch` dependencies\npip install declearn[tensorflow,torch]  # install both tensorflow and torch\n\n# Instructions to install bundles of optional components.\npip install declearn[all]    # install all extra dependencies, save for testing\npip install declearn[tests]  # install all extra dependencies plus testing ones\n```\n\n#### Notes\n\n- If you are not using a virtual environment, select carefully the `pip` binary\n  being called (e.g. use `python -m pip`), and/or add a `--user` flag to the\n  pip command.\n- Developers may have better installing the package in editable mode, using\n  `pip install -e .` from the repository's root folder.\n- If you are installing the package within a conda environment, it may be\n  better to run `pip install --no-deps declearn` so as to only install the\n  package, and then to manually install the dependencies listed in the\n  `pyproject.toml` file, using `conda install` rather than `pip install`\n  whenever it is possible.\n\n## Quickstart\n\n### Setting\n\nHere is a quickstart example on how to set up a federated learning process\nto learn a LASSO logistic regression model (using a scikit-learn backend)\nusing pre-processed data, formatted as csv files with a \"label\" column,\nwhere each client has two files: one for training, the other for validation.\n\nHere, the code uses:\n\n- standard FedAvg strategy (SGD for local steps, averaging of updates weighted\n  by clients' training dataset size, no modifications of server-side updates)\n- 10 rounds of training, with 5 local epochs performed at each round and\n  128-samples batch size\n- at least 1 and at most 3 clients, awaited for 180 seconds by the server\n- network communications using gRPC, on host \"example.com\" and port 8888\n\nNote that this example code may easily be adjusted to suit use cases, using\nother types of models, alternative federated learning algorithms and/or\nmodifying the communication, training and validation hyper-parameters.\nPlease refer to the [Hands-on usage](#hands-on-usage) section for a more\ndetailed and general description of how to set up a federated learning\ntask and process with declearn.\n\n### Server-side script\n\n```python\nimport declearn\n\nmodel = declearn.model.sklearn.SklearnSGDModel.from_parameters(\n    kind=\"classifier\", loss=\"log_loss\", penalty=\"l1\"\n)\nnetwk = declearn.communication.NetworkServerConfig(\n    protocol=\"grpc\", host=\"example.com\", port=8888,\n    certificate=\"path/to/certificate.pem\",\n    private_key=\"path/to/private_key.pem\"\n)\noptim = declearn.main.config.FLOptimConfig.from_params(\n    aggregator=\"averaging\",\n    client_opt=0.001,\n)\nserver = declearn.main.FederatedServer(\n    model, netwk, optim, checkpoint=\"outputs\"\n)\nconfig = declearn.main.config.FLRunConfig.from_params(\n    rounds=10,\n    register={\"min_clients\": 1, \"max_clients\": 3, \"timeout\": 180},\n    training={\"n_epoch\": 5, \"batch_size\": 128, \"drop_remainder\": False},\n)\nserver.run(config)\n```\n\n### Client-side script\n\n```python\nimport declearn\n\nnetwk = declearn.communication.NetworkClientConfig(\n    protocol=\"grpc\",\n    server_uri=\"example.com:8888\",\n    name=\"client_name\",\n    certificate=\"path/to/client_cert.pem\"\n)\ntrain = declearn.dataset.InMemoryDataset(\n    \"path/to/train.csv\", target=\"label\",\n    expose_classes=True  # enable sharing of unique target values\n)\nvalid = declearn.dataset.InMemoryDataset(\"path/to/valid.csv\", target=\"label\")\nclient = declearn.main.FederatedClient(netwk, train, valid, checkpoint=\"outputs\")\nclient.run()\n```\n\n### Support for GPU acceleration\n\nTL;DR: GPU acceleration is natively available in `declearn` for model\nframeworks that support it, with one line of code and without changing\nyour original model.\n\nDetails:\n\nMost machine learning frameworks, including Tensorflow and Torch, enable\naccelerating computations by using computational devices other than CPU.\n`declearn` interfaces supported frameworks to be able to set a device policy\nin a single line of code, accross frameworks.\n\n`declearn` internalizes the framework-specific code adaptations to place the\ndata, model weights and computations on such a device. `declearn` provides\nwith a simple API to define a global device policy. This enables using a\nsingle GPU to accelerate computations, or forcing the use of a CPU.\n\nBy default, the policy is set to use the first available GPU, and otherwise\nuse the CPU, with a warning that can safely be ignored.\n\nSetting the device policy to be used can be done in local scripts, either as a\nclient or as a server. Device policy is local and is not synchronized between\nfederated learninng participants.\n\nHere are some examples of the one-liner used:\n```python\ndeclearn.utils.set_device_policy(gpu=False)  # disable GPU use\ndeclearn.utils.set_device_policy(gpu=True)  # use any available GPU\ndeclearn.utils.set_device_policy(gpu=True, idx=2)  # specifically use GPU n°2\n```\n\n### Note on dependency sharing\n\nOne important issue however that is not handled by declearn itself is that\nof ensuring that clients have loaded all dependencies that may be required\nto unpack the Model and Optimizer instances transmitted at initialization.\nAt the moment, it is therefore left to users to agree on the dependencies\nthat need to be imported as part of the client-side launching script.\n\nFor example, if the trained model is an artificial neural network that uses\nPyTorch as implementation backend, clients will need to add the\n`import declearn.model.torch` statement in their code (and, obviously, to\nhave `torch` installed). Similarly, if a custom declearn `OptiModule` was\nwritten to modify the way updates are computed locally by clients, it will\nneed to be shared with clients - either as a package to be imported (like\ntorch previously), or as a bit of source code to add on top of the script.\n\n## Usage of the Python API\n\n### Overview of the Federated Learning process\n\nThis overview describes the way the `declearn.main.FederatedServer`\nand `declearn.main.FederatedClient` pair of classes implement the\nfederated learning process. It is however possible to subclass\nthese and/or implement alternative orchestrating classes to define\nalternative overall algorithmic processes - notably by overriding\nor extending methods that define the sub-components of the process\nexposed here.\n\n#### Overall process orchestrated by the server\n\n- Initially:\n  - have the clients connect and register for training\n  - prepare model and optimizer objects on both sides\n- Iteratively:\n  - perform a training round\n  - perform an evaluation round\n  - decide whether to continue, based on the number of\n    rounds taken or on the evolution of the global loss\n- Finally:\n  - restore the model weights that yielded the lowest global loss\n  - notify clients that training is over, so they can disconnect\n    and run their final routine (e.g. save the \"best\" model)\n  - optionally checkpoint the \"best\" model\n  - close the network server and end the process\n\n#### Detail of the process phases\n\n- **Registration process**:\n  - Server:\n    - open up registration (stop rejecting all received messages)\n    - handle and respond to client-emitted registration requests\n    - await criteria to have been met (exact or min/max number of clients\n      registered, optionally under a given timeout delay)\n    - close registration (reject future requests)\n  - Client:\n    - gather metadata about the local training dataset\n      (_e.g._ dimensions and unique labels)\n    - connect to the server and send a request to join training,\n      including the former information\n    - await the server's response (retry after a timeout if the request\n      came in too soon, i.e. registration is not opened yet)\n  - messaging : (JoinRequest <-> JoinReply)\n\n- **Post-registration initialization**\n  - Server:\n    - validate and aggregate clients-transmitted metadata\n    - finalize the model's initialization using those metadata\n    - send the model, local optimizer and evaluation metrics specs to clients\n  - Client:\n    - instantiate the model, optimizer and metrics based on server instructions\n  - messaging: (InitRequest <-> GenericMessage)\n\n- **(Opt.) Local differential privacy initialization**\n  - This step is optional; a flag in the InitRequest at the previous step\n    indicates to clients that it is to happen, as a secondary substep.\n  - Server:\n    - send hyper-parameters to set up local differential privacy, including\n      dp-specific hyper-parameters and information on the planned training\n  - Client:\n    - adjust the training process to use sample-wise gradient clipping and\n      add gaussian noise to gradients, implementing the DP-SGD algorithm\n    - set up a privacy accountant to monitor the use of the privacy budget\n  - messaging: (PrivacyRequest <-> GenericMessage)\n\n- **Training round**:\n  - Server:\n    - select clients that are to participate\n    - send data-batching and effort constraints parameters\n    - send shared model trainable weights and (opt. client-specific) optimizer\n      auxiliary variables\n  - Client:\n    - update model weights and optimizer auxiliary variables\n    - perform training steps based on effort constraints\n    - step: compute gradients over a batch; compute updates; apply them\n    - finally, send back the local model weights' updates and optimizer\n      auxiliary variables\n  - messaging: (TrainRequest <-> TrainReply)\n  - Server:\n    - unpack and aggregate clients' model weights updates into global updates\n    - unpack and process clients' optimizer auxiliary variables\n    - run global updates through the server's optimizer to modify and finally\n      apply them\n\n- **Evaluation round**:\n  - Server:\n    - select clients that are to participate\n    - send data-batching parameters and shared model trainable weights\n    - (_send effort constraints, unused for now_)\n  - Client:\n    - update model weights\n    - perform evaluation steps based on effort constraints\n    - step: update evaluation metrics, including the model's loss, over a batch\n    - optionally checkpoint the model, local optimizer and evaluation metrics\n    - send results to the server: optionally prevent sharing detailed metrics;\n      always include the scalar validation loss value\n  - messaging: (EvaluateRequest <-> EvaluateReply)\n  - Server:\n    - aggregate local loss values into a global loss metric\n    - aggregate all other evaluation metrics and log their values\n    - optionally checkpoint the model, optimizer, aggregated evaluation\n      metrics and client-wise ones\n\n### Overview of the declearn API\n\n#### Package structure\n\nThe package is organized into the following submodules:\n\n- `aggregator`:<br/>\n  &emsp; Model updates aggregating API and implementations.\n- `communication`:<br/>\n  &emsp; Client-Server network communications API and implementations.\n- `data_info`:<br/>\n  &emsp; Tools to write and extend shareable metadata fields specifications.\n- `dataset`:<br/>\n  &emsp; Data interfacing API and implementations.\n- `main`:<br/>\n  &emsp; Main classes implementing a Federated Learning process.\n- `metrics`:<br/>\n  &emsp; Iterative and federative evaluation metrics computation tools.\n- `model`:<br/>\n  &emsp; Model interfacing API and implementations.\n- `optimizer`:<br/>\n  &emsp; Framework-agnostic optimizer and algorithmic plug-ins API and tools.\n- `typing`:<br/>\n  &emsp; Type hinting utils, defined and exposed for code readability purposes.\n- `utils`:<br/>\n  &emsp; Shared utils used (extensively) across all of declearn.\n\n#### Main abstractions\n\nThis section lists the main abstractions implemented as part of\n`declearn`, exposing their main object and usage, some examples\nof ready-to-use implementations that are part of `declearn`, as\nwell as references on how to extend the support of `declearn`\nbackend (notably, (de)serialization and configuration utils) to\nnew custom concrete implementations inheriting the abstraction.\n\n- `declearn.model.api.Model`:\n  - Object: Interface framework-specific machine learning models.\n  - Usage: Compute gradients, apply updates, compute loss...\n  - Examples:\n    - `declearn.model.sklearn.SklearnSGDModel`\n    - `declearn.model.tensorflow.TensorflowModel`\n    - `declearn.model.torch.TorchModel`\n  - Extend: use `declearn.utils.register_type(group=\"Model\")`\n\n- `declearn.model.api.Vector`:\n  - Object: Interface framework-specific data structures.\n  - Usage: Wrap and operate on model weights, gradients, updates...\n  - Examples:\n    - `declearn.model.sklearn.NumpyVector`\n    - `declearn.model.tensorflow.TensorflowVector`\n    - `declearn.model.torch.TorchVector`\n  - Extend: use `declearn.model.api.register_vector_type`\n\n- `declearn.optimizer.modules.OptiModule`:\n  - Object: Define optimization algorithm bricks.\n  - Usage: Plug into a `declearn.optimizer.Optimizer`.\n  - Examples:\n    - `declearn.optimizer.modules.AdagradModule`\n    - `declearn.optimizer.modules.MomentumModule`\n    - `declearn.optimizer.modules.ScaffoldClientModule`\n    - `declearn.optimizer.modules.ScaffoldServerModule`\n  - Extend:\n    - Simply inherit from `OptiModule` (registration is automated).\n    - To avoid it, use `class MyModule(OptiModule, register=False)`.\n\n- `declearn.optimizer.modules.Regularizer`:\n  - Object: Define loss-regularization terms as gradients modifiers.\n  - Usage: Plug into a `declearn.optimizer.Optimizer`.\n  - Examples:\n    - `declearn.optimizer.regularizer.FedProxRegularizer`\n    - `declearn.optimizer.regularizer.LassoRegularizer`\n    - `declearn.optimizer.regularizer.RidgeRegularizer`\n  - Extend:\n    - Simply inherit from `Regularizer` (registration is automated).\n    - To avoid it, use `class MyRegularizer(Regularizer, register=False)`.\n\n- `declearn.metrics.Metric`:\n  - Object: Define evaluation metrics to compute iteratively and federatively.\n  - Usage: Compute local and federated metrics based on local data streams.\n  - Examples:\n    - `declearn.metric.BinaryRocAuc`\n    - `declearn.metric.MeanSquaredError`\n    - `declearn.metric.MuticlassAccuracyPrecisionRecall`\n  - Extend:\n    - Simply inherit from `Metric` (registration is automated).\n    - To avoid it, use `class MyMetric(Metric, register=False)`\n\n- `declearn.communication.api.NetworkClient`:\n  - Object: Instantiate a network communication client endpoint.\n  - Usage: Register for training, send and receive messages.\n  - Examples:\n    - `declearn.communication.grpc.GrpcClient`\n    - `declearn.communication.websockets.WebsocketsClient`\n  - Extend:\n    - Simply inherit from `NetworkClient` (registration is automated).\n    - To avoid it, use `class MyClient(NetworkClient, register=False)`.\n\n- `declearn.communication.api.NetworkServer`:\n  - Object: Instantiate a network communication server endpoint.\n  - Usage: Receive clients' requests, send and receive messages.\n  - Examples:\n    - `declearn.communication.grpc.GrpcServer`\n    - `declearn.communication.websockets.WebsocketsServer`\n  - Extend:\n    - Simply inherit from `NetworkServer` (registration is automated).\n    - To avoid it, use `class MyServer(NetworkServer, register=False)`.\n\n- `declearn.dataset.Dataset`:\n  - Object: Interface data sources agnostic to their format.\n  - Usage: Yield (inputs, labels, weights) data batches, expose metadata.\n  - Examples:\n    - `declearn.dataset.InMemoryDataset`\n  - Extend: use `declearn.utils.register_type(group=\"Dataset\")`\n\n### Hands-on usage\n\nHere are details on how to set up server-side and client-side programs\nthat will run together to perform a federated learning process. Generic\nremarks from the [Quickstart](#quickstart) section hold here as well, the\nformer section being an overly simple exemplification of the present one.\n\nYou can follow along on a concrete example that uses the UCI heart disease\ndataset, that is stored in the `examples/uci-heart` folder. You may refer\nto the `server.py` and `client.py` example scripts, that comprise comments\nindicating how the code relates to the steps described below. For further\ndetails on this example and on how to run it, please refer to its own\n`readme.md` file.\n\n#### Server setup instructions\n\n1. Define a Model:\n\n   - Set up a machine learning model in a given framework\n       (_e.g._ a `torch.nn.Module`).\n   - Select the appropriate `declearn.model.api.Model` subclass to wrap it up.\n   - Either instantiate the `Model` or provide a JSON-serialized configuration.\n\n2. Define a FLOptimConfig:\n   - Select a `declearn.aggregator.Aggregator` (subclass) instance to define\n     how clients' updates are to be aggregated into global-model updates on\n     the server side.\n   - Parameterize a `declearn.optimizer.Optimizer` (possibly using a selected\n     pipeline of `declearn.optimizer.modules.OptiModule` plug-ins and/or a\n     pipeline of `declearn.optimizer.regularizers.Regularizer` ones) to be\n     used by clients to derive local step-wise updates from model gradients.\n   - Similarly, parameterize an `Optimizer` to be used by the server to\n     (optionally) refine the aggregated model updates before applying them.\n   - Wrap these three objects into a `declearn.main.config.FLOptimConfig`,\n     possibly using its `from_config` method to specify the former three\n     components via configuration dicts rather than actual instances.\n   - Alternatively, write up a TOML configuration file that specifies these\n     components (note that 'aggregator' and 'server_opt' have default values\n     and may therefore be left unspecified).\n\n3. Define a communication server endpoint:\n\n   - Select a communication protocol (_e.g._ \"grpc\" or \"websockets\").\n   - Select the host address and port to use.\n   - Preferably provide paths to PEM files storing SSL-required information.\n   - Wrap this into a config dict or use `declearn.communication.build_server`\n       to instantiate a `declearn.communication.api.NetworkServer` to be used.\n\n4. Instantiate and run a FederatedServer:\n\n   - Instantiate a `declearn.main.FederatedServer`:\n     - Provide the Model, FLOptimConfig and Server objects or configurations.\n     - Optionally provide a MetricSet object or its specs (i.e. a list of\n       Metric instances, identifier names of (name, config) tuples), that\n       defines metrics to be computed by clients on their validation data.\n     - Optionally provide the path to a folder where to write output files\n       (model checkpoints and global loss history).\n   - Instantiate a `declearn.main.config.FLRunConfig` to specify the process:\n     - Maximum number of training and evaluation rounds to run.\n     - Registration parameters: exact or min/max number of clients to have\n       and optional timeout delay spent waiting for said clients to join.\n     - Training parameters: data-batching parameters and effort constraints\n       (number of local epochs and/or steps to take, and optional timeout).\n     - Evaluation parameters: data-batching parameters and effort constraints\n       (optional maximum number of steps (<=1 epoch) and optional timeout).\n     - Early-stopping parameters (optionally): patience, tolerance, etc. as\n       to the global model loss's evolution throughout rounds.\n     - Local Differential-Privacy parameters (optionally): (epsilon, delta)\n       budget, type of accountant, clipping norm threshold, RNG parameters.\n   - Alternatively, write up a TOML configuration file that specifies all of\n     the former hyper-parameters.\n   - Call the server's `run` method, passing it the former config object,\n     the path to the TOML configuration file, or dictionaries of keyword\n     arguments to be parsed into a `FLRunConfig` instance.\n\n\n#### Clients setup instructions\n\n1. Interface training data:\n\n   - Select and parameterize a `declearn.dataset.Dataset` subclass that\n       will interface the local training dataset.\n   - Ensure its `get_data_specs` method exposes the metadata that is to\n       be shared with the server (and nothing else, to prevent data leak).\n\n2. Interface validation data (optional):\n\n   - Optionally set up a second Dataset interfacing a validation dataset,\n       used in evaluation rounds. Otherwise, those rounds will be run using\n       the training dataset - which can be slow and/or lead to overfitting.\n\n3. Define a communication client endpoint:\n\n   - Select the communication protocol used (_e.g._ \"grpc\" or \"websockets\").\n   - Provide the server URI to connect to.\n   - Preferable provide the path to a PEM file storing SSL-required information\n       (matching those used on the Server side).\n   - Wrap this into a config dict or use `declearn.communication.build_client`\n       to instantiate a `declearn.communication.api.NetworkClient` to be used.\n\n4. Run any necessary import statement:\n\n   - If optional or third-party dependencies are known to be required, import\n       them (_e.g._ `import declearn.model.torch`).\n\n5. Instantiate a FederatedClient and run it:\n\n   - Instantiate a `declearn.main.FederatedClient`:\n     - Provide the NetworkClient and Dataset objects or configurations.\n     - Optionally specify `share_metrics=False` to prevent sharing evaluation\n       metrics (apart from the aggregated loss) with the server out of privacy\n       concerns.\n     - Optionally provide the path to a folder where to write output files\n       (model checkpoints and local loss history).\n   - Call the client's `run` method and let the magic happen.\n\n#### Logging\n\nNote that this section and the quickstart example both left apart the option\nto configure logging associated with the federated client and server, and/or\nthe network communication handlers they make use of. One may simply set up\ncustom `logging.Logger` instances and pass them as arguments to the class\nconstructors to replace the default, console-only, loggers.\n\nThe `declearn.utils.get_logger` function may be used to facilitate the setup\nof such logger instances, defining their name, verbosity level, and whether\nmessages should be logged to the console and/or to an output file.\n\n### Local Differential Privacy\n\n#### Basics\n\n`declearn` comes with the possibility to train models using local differential\nprivacy, as described in the centralized case by Abadi et al, 2016,\n[Deep Learning with Differential Privacy](https://arxiv.org/abs/1607.00133).\nThis means that training can provide per-client privacy guarantees with regard\nto the central server.\n\nIn practice, this can be done by simply adding a privacy field to the config\nfile, object or input dict to the `run` method of `FederatedServer`. Taking\nthe Heart UCI example, one simply has one line to add to the server-side\nscript (`examples/heart-uci/server.py`) in order to implement local DP,\nhere using Renyi-DP with epsilon=5, delta=0.00001 and a sample-wise gradient\nclipping parameter that binds their euclidean norm below 3:\n\n```python\n# These are the last statements in the `run_server` function.\nrun_cfg = FLRunConfig.from_params(\n    # The following lines come from the base example:\n    rounds=20,\n    register={\"min_clients\": nb_clients},\n    training={\"batch_size\": 30, \"drop_remainder\": False},\n    evaluate={\"batch_size\": 50, \"drop_remainder\": False},\n    early_stop={\"tolerance\": 0.0, \"patience\": 5, \"relative\": False},\n    # DP-specific instructions (in their absence, do not use local DP):\n    privacy={\"accountant\": \"rdp\", \"budget\": (5, 10e-5), \"sclip_norm\": 3},\n)\nserver.run(run_cfg)  # this is unaltered\n```\n\nThis implementation can breach privacy garantees for some standard model\narchitecture and training processes, see the _Warnings and limits_ section.\n\n#### More details on the backend\n\nImplementing local DP requires to change four key elements, which are\nautomatically handled in declearn based on the provided privacy configuration:\n\n- **Add a privacy accountant**. We use the `Opacus` library, to set up a\nprivacy accountant. The accountant is used in two key ways :\n  - To calculate how much noise to add to the gradient at each trainig step\n  to provide an $`(\\epsilon-\\delta)`$-DP guarantee over the total number of\n  steps planned. This is where the heavily lifting is done, as estimating\n  the tighest bounds on the privacy loss is a non-trivial problem. We default\n  to the Renyi-DP accountant used in the original paper, but Opacus provides\n  an evolving list of options, since this is an active area of research. For\n  more details see the documentation of `declearn.main.utils.PrivacyConfig`.\n  - To keep track of the privacy budget spent as training progresses, in\n  particular in case of early stopping.\n\n- **Implement per-sample gradient clipping**. Clipping bounds the sensitivity\nof samples' contributions to model updates. It is performed using the\n`max_norm` parameter of `Model.compute_batch_gradients`.\n\n- **Implement noise-addition to applied gradients**. A gaussian noise with a\ntailored variance is drawn and added to the batch-averaged gradients based on\nwhich the local model is updated at each and every training step.\n\n- **Use Poisson sampling to draw batches**. This is done at the `Dataset` level\nusing the `poisson` argument of `Dataset.generate_batches`.\n  - As stated in the Opacus documentation, \"Minibatches should be formed by\n  uniform sampling, i.e. on each training step, each sample from the dataset\n  is included with a certain probability p. Note that this is different from\n  standard approach of dataset being shuffled and split into batches: each\n  sample has a non-zero probability of appearing multiple times in a given\n  epoch, or not appearing at all.\"\n  - For more details, see Zhu and Wang, 2019,\n  [Poisson Subsampled Renyi Differential Privacy](http://proceedings.mlr.press/v97/zhu19c/zhu19c.pdf)\n\n#### Warnings and limits\n\nUnder certain model and training specifications, two silent breaches of formal\nprivacy guarantees can occur. Some can be handled automatically if working\nwith `torch`, but need to be manually checked for in other frameworks.\n\n- **Neural net layers that breach DP**. Standard architectures can lead\nto information leaking between batch samples. Know examples include batch\nnormalization layers, LSTM, and multi-headed attention modules. In `torch`,\nchecking a module for DP-compliance can be done using Opacus, by running:\n\n  ```python\n  #given an NN.module to be tested\n  from opacus import PrivacyEngine\n  dp_compatible_module = PrivacyEngine.get_compatible_module(module)\n  ```\n\n- **Gradient accumulation**. This feature is not used in standard declearn\nmodels and training tools, but users that might try to write custom hacks\nto simulate large batches by setting a smaller batch size and executing the\noptimization step every N steps over the accumulated sum of output gradients\nshould be aware that this is not compatible with Poisson sampling.\n\nFinally, note that at this stage the DP implementation in declearn is taken\ndirectly from the centralized training case, and as such does not account for\nnor make use of some specifities of the Federated Learning process, such as\nprivacy amplification by iteration.\n\n## Developers\n\n### Contributions\n\nContributions to `declearn` are welcome, whether to provide fixes, suggest\nnew features (_e.g._ new subclasses of the core abstractions) or even push\nforward framework evolutions and API revisions.\n\nTo contribute directly to the code (beyond posting issues on gitlab), please\ncreate a dedicated branch, and submit a **Merge Request** once you want your\nwork reviewed and further processed to end up integrated into the package.\n\nThe **git branching strategy** is the following:\n\n- The 'develop' branch is the main one and should receive all finalized changes\n  to the source code. Release branches are then created and updated by cherry-\n  picking from that branch. It therefore acts as a nightly stable version.\n- The 'rX.Y' branches are release branches for each and every X.Y versions.\n  For past versions, these branches enable pushing patches towards a subminor\n  version release (hence being version `X.Y.(Z+1)-dev`). For future versions,\n  these branches enable cherry-picking commits from main to build up an alpha,\n  beta, release-candidate and eventually stable `X.Y.0` version to release.\n- Feature branches should be created at will to develop features, enhancements,\n  or even hotfixes that will later be merged into 'main' and eventually into\n  one or multiple release branches.\n- It is legit to write up poc branches, as well as to split the development of\n  a feature into multiple branches that will incrementally be merged into an\n  intermediate feature branch that will eventually be merged into 'main'.\n\nThe **coding rules** are fairly simple:\n\n- Abide by [PEP 8](https://peps.python.org/pep-0008/), in a way that is\n  coherent with the practices already at work in declearn.\n- Abide by [PEP 257](https://peps.python.org/pep-0257/), _i.e._ write\n  docstrings **everywhere** (unless inheriting from a method, the behaviour\n  and signature of which are unmodified), again using formatting that is\n  coherent with the declearn practices.\n- Type-hint the code, abiding by [PEP 484](https://peps.python.org/pep-0484/);\n  note that the use of Any and of \"type: ignore\" comments is authorized, but\n  should be remain sparse.\n- Lint your code with [mypy](http://mypy-lang.org/) (for static type checking)\n  and [pylint](https://pylint.pycqa.org/en/latest/) (for more general linting);\n  do use \"type: ...\" and \"pylint: disable=...\" comments where you think it\n  relevant, preferably with some side explanations.\n  (see dedicated sub-sections below: [pylint](#running-pylint-to-check-the-code)\n  and [mypy](#running-mypy-to-type-check-the-code))\n- Reformat your code using [black](https://github.com/psf/black); do use\n  (sparingly) \"fmt: off/on\" comments when you think it relevant\n  (see dedicated sub-section [below](#running-black-to-format-the-code)).\n- Abide by [semver](https://semver.org/) when implementing new features or\n  changing the existing APIs; try making changes non-breaking, document and\n  warn about deprecations or behavior changes, or make a point for API-breaking\n  changes, which we are happy to consider but might take time to be released.\n\n### Unit tests and code analysis\n\nUnit tests, as well as more-involved functional ones, are implemented under\nthe `test/` folder of the present repository.\nThey are implemented using the [PyTest](https://docs.pytest.org) framework,\nas well as some third-party plug-ins (refer to [Setup][#setup] for details).\n\nAdditionally, code analysis tools are configured through the `pyproject.toml`\nfile, and used to control code quality upon merging to the main branch. These\ntools are [black](https://github.com/psf/black) for code formatting,\n[pylint](https://pylint.pycqa.org/) for overall static code analysis and\n[mypy](https://mypy.readthedocs.io/) for static type-cheking.\n\n#### Running the test suite using tox\n\nThe third-party [tox](https://tox.wiki/en/latest/) tools may be used to run\nthe entire test suite within a dedicated virtual environment. Simply run `tox`\nfrom the commandline with the root repo folder as working directory. You may\noptionally specify the python version(s) with which you want to run tests.\n\n```bash\ntox           # run with default python 3.8\ntox -e py310  # override to use python 3.10\n```\n\nNote that additional parameters for `pytest` may be passed as well, by adding\n`--` followed by any set of options you want at the end of the `tox` command.\nFor example, to use the declearn-specific `--fulltest` option (see the section\nbelow), run:\n\n```bash\ntox [tox options] -- --fulltest\n```\n\n#### Running unit tests using pytest\n\nTo run all the tests, simply use:\n\n```bash\npytest test\n```\n\nTo run the tests under a given module (here, \"model\"):\n\n```bash\npytest test/model\n```\n\nTo run the tests under a given file (here, \"test_main.py\"):\n\n```bash\npytest test/test_main.py\n```\n\nNote that by default, some test scenarios that are considered somewhat\nsuperfluous~redundant will be skipped in order to save time. To avoid\nskipping these, and therefore run a more complete test suite, add the\n`--fulltest` option to pytest:\n\n```bash\npytest --fulltest test  # or any more-specific target you want\n```\n\n#### Running black to format the code\n\nThe [black](https://github.com/psf/black) code formatter is used to enforce\nuniformity of the source code's formatting style. It is configured to have\na maximum line length of 79 (as per [PEP 8](https://peps.python.org/pep-0008/))\nand ignore auto-generated protobuf files, but will otherwise modify files\nin-place when executing the following commands from the repository's root\nfolder:\n\n```bash\nblack declearn  # reformat the package\nblack test      # reformat the tests\n```\n\nNote that it may also be called on individual files or folders.\nOne may \"blindly\" run black, however it is actually advised to have a look\nat the reformatting operated, and act on any readability loss due to it. A\ncouple of advice:\n\n1. Use `#fmt: off` / `#fmt: on` comments sparingly, but use them.\n<br/>It is totally okay to protect some (limited) code blocks from\nreformatting if you already spent some time and effort in achieving a\nreadable code that black would disrupt. Please consider refactoring as\nan alternative (e.g. limiting the nest-depth of a statement).\n\n2. Pre-format functions and methods' signature to ensure style homogeneity.\n<br/>When a signature is short enough, black may attempt to flatten it as a\none-liner, whereas the norm in declearn is to have one line per argument,\nall of which end with a trailing comma (for diff minimization purposes). It\nmay sometimes be necessary to manually write the code in the latter style\nfor black not to reformat it.\n\nFinally, note that the test suite run with tox comprises code-checking by\nblack, and will fail if some code is deemed to require alteration by that\ntool. You may run this check manually:\n\n```bash\nblack --check declearn  # or any specific file or folder\n```\n\n#### Running pylint to check the code\n\nThe [pylint](https://pylint.pycqa.org/) linter is expected to be used for\nstatic code analysis. As a consequence, `# pylint: disable=[some-warning]`\ncomments can be found (and added) to the source code, preferably with some\nindication as to the rationale for silencing the warning (or error).\n\nA minimal amount of non-standard hyper-parameters are configured via the\n`pyproject.toml` file and will automatically be used by pylint when run\nfrom within the repository's folder.\n\nMost code editors enable integrating the linter to analyze the code as it is\nbeing edited. To lint the entire package (or some specific files or folders)\none may simply run `pylint`:\n\n```bash\npylint declearn  # analyze the package\npylint test      # analyze the tests\n```\n\nNote that the test suite run with tox comprises the previous two commands,\nwhich both result in a score associated with the analyzed code. If the score\ndoes not equal 10/10, the test suite will fail - notably preventing acceptance\nof merge requests.\n\n#### Running mypy to type-check the code\n\nThe [mypy](https://mypy.readthedocs.io/) linter is expected to be used for\nstatic type-checking code analysis. As a consequence, `# type: ignore` comments\ncan be found (and added) to the source code, as sparingly as possible (mostly,\nto silence warnings about untyped third-party dependencies, false-positives,\nor locally on closure functions that are obvious enough to read from context).\n\nCode should be type-hinted as much and as precisely as possible - so that mypy\nactually provides help in identifying (potential) errors and mistakes, with\ncode clarity as final purpose, rather than being another linter to silence off.\n\nA minimal amount of parameters are configured via the `pyproject.toml` file,\nand some of the strictest rules are disabled as per their default value (e.g.\nAny expressions are authorized - but should be used sparingly).\n\nMost code editors enable integrating the linter to analyze the code as it is\nbeing edited. To lint the entire package (or some specific files or folders)\none may simply run `mypy`:\n\n```bash\nmypy declearn\n```\n\nNote that the test suite run with tox comprises the previous command. If mypy\nidentifies errors, the test suite will fail - notably preventing acceptance\nof merge requests.\n\n\n## Copyright\n\nDeclearn is an open-source software developed by people from the\n[Magnet](https://team.inria.fr/magnet/) team at [Inria](https://www.inria.fr/).\n\n### Authors\n\nCurrent core developers are listed under the `pyproject.toml` file. A more\ndetailed acknowledgement and history of authors and contributors to declearn\ncan be found in the `AUTHORS` file.\n\n### License\n\nDeclearn distributed under the Apache-2.0 license. All code files should\ntherefore contain the following mention, which also applies to the present\nREADME file:\n```\nCopyright 2023 Inria (Institut National de la Recherche en Informatique\net Automatique)\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n```\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "Apache License Version 2.0, January 2004 http://www.apache.org/licenses/  TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION  1. Definitions.  \"License\" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document.  \"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License.  \"Legal Entity\" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity.  \"You\" (or \"Your\") shall mean an individual or Legal Entity exercising permissions granted by this License.  \"Source\" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files.  \"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types.  \"Work\" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below).  \"Derivative Works\" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof.  \"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\"  \"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work.  2. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form.  3. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed.  4. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions:  (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and  (b) You must cause any modified files to carry prominent notices stating that You changed the files; and  (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and  (d) If the Work includes a \"NOTICE\" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License.  You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License.  5. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions.  6. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file.  7. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License.  8. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages.  9. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability.  END OF TERMS AND CONDITIONS  APPENDIX: How to apply the Apache License to your work.  To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets \"[]\" replaced with your own identifying information. (Don't include the brackets!)  The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same \"printed page\" as the copyright notice for easier identification within third-party archives.  Copyright [yyyy] [name of copyright owner]  Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at  http://www.apache.org/licenses/LICENSE-2.0  Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. ",
    "maintainer": "",
    "maintainer_email": "Paul Andrey <paul.andrey@inria.fr>, Nathan Bigaud <nathan.bigaud@inria.fr>",
    "name": "declearn",
    "package_url": "https://pypi.org/project/declearn/",
    "platform": null,
    "project_url": "https://pypi.org/project/declearn/",
    "project_urls": {
      "homepage": "https://gitlab.inria.fr/magnet/declearn/declearn2",
      "repository": "https://gitlab.inria.fr/magnet/declearn/declearn2.git"
    },
    "release_url": "https://pypi.org/project/declearn/2.1.0/",
    "requires_dist": [
      "cryptography (>=35.0)",
      "pandas (>=1.2)",
      "scikit-learn (>=1.0)",
      "typing-extensions (>=4.0)",
      "tomli (>=2.0) ; python_version < \"3.11\"",
      "functorch ; extra == 'all'",
      "grpcio (>=1.45) ; extra == 'all'",
      "opacus (~=1.1) ; extra == 'all'",
      "protobuf (>=3.19) ; extra == 'all'",
      "tensorflow (~=2.5) ; extra == 'all'",
      "torch (~=1.10) ; extra == 'all'",
      "websockets (~=10.1) ; extra == 'all'",
      "opacus (~=1.1) ; extra == 'dp'",
      "grpcio (>=1.45) ; extra == 'grpc'",
      "protobuf (>=3.19) ; extra == 'grpc'",
      "tensorflow (~=2.5) ; extra == 'tensorflow'",
      "black (~=23.0) ; extra == 'tests'",
      "mypy (~=1.0) ; extra == 'tests'",
      "pylint (>=2.14) ; extra == 'tests'",
      "pytest (>=6.1) ; extra == 'tests'",
      "pytest-asyncio ; extra == 'tests'",
      "functorch ; extra == 'tests'",
      "grpcio (>=1.45) ; extra == 'tests'",
      "opacus (~=1.1) ; extra == 'tests'",
      "protobuf (>=3.19) ; extra == 'tests'",
      "tensorflow (~=2.5) ; extra == 'tests'",
      "torch (~=1.10) ; extra == 'tests'",
      "websockets (~=10.1) ; extra == 'tests'",
      "functorch ; extra == 'torch'",
      "torch (~=1.10) ; extra == 'torch'",
      "websockets (~=10.1) ; extra == 'websockets'"
    ],
    "requires_python": ">=3.8",
    "summary": "Declearn - a python package for private decentralized learning.",
    "version": "2.1.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17124822,
  "releases": {
    "2.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "45ff0b92ab1dbebe46489de9a154af7a2b9786623c015c9e66b7578b39c1266f",
          "md5": "ffc93817b3f5b37c19446c1c6492fefd",
          "sha256": "944292d05b7c3fea04cb96a172dc465e1fe29a8c8259e3fe86153aaefdecbf9d"
        },
        "downloads": -1,
        "filename": "declearn-2.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ffc93817b3f5b37c19446c1c6492fefd",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 229285,
        "upload_time": "2023-02-06T16:31:25",
        "upload_time_iso_8601": "2023-02-06T16:31:25.596375Z",
        "url": "https://files.pythonhosted.org/packages/45/ff/0b92ab1dbebe46489de9a154af7a2b9786623c015c9e66b7578b39c1266f/declearn-2.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "44f89b404d75c4b7c89a23a6bc457aeb28f563b636b280397ad54efbfc5fddab",
          "md5": "e1efb86d8da74d2668feb71fedeb8a45",
          "sha256": "325428af28d35a50ccf69ee4d91deb82d012fb4581fd8916b8e35c66650f803a"
        },
        "downloads": -1,
        "filename": "declearn-2.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "e1efb86d8da74d2668feb71fedeb8a45",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 218965,
        "upload_time": "2023-02-06T16:31:28",
        "upload_time_iso_8601": "2023-02-06T16:31:28.107260Z",
        "url": "https://files.pythonhosted.org/packages/44/f8/9b404d75c4b7c89a23a6bc457aeb28f563b636b280397ad54efbfc5fddab/declearn-2.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "2.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e730f2e0b4060f01c985ed304d04f0226706327f011780b01744172ba5582b8e",
          "md5": "56454b290ccc5302d606136d75ad81ec",
          "sha256": "426e8bd969c3fa60c171d6634c4e01fed598603e1760cdbeed033b20eb6c3d04"
        },
        "downloads": -1,
        "filename": "declearn-2.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "56454b290ccc5302d606136d75ad81ec",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 230543,
        "upload_time": "2023-02-13T09:33:54",
        "upload_time_iso_8601": "2023-02-13T09:33:54.986111Z",
        "url": "https://files.pythonhosted.org/packages/e7/30/f2e0b4060f01c985ed304d04f0226706327f011780b01744172ba5582b8e/declearn-2.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "14af2d263308a317ccfda07487a1d65739a118f0d3adbf22121b4cecad470d57",
          "md5": "a2507cde338a7d2af0fbfcb1732b015a",
          "sha256": "128b2834b73e59b16a21a320d98f3e4f6799742e0de5e3d420806a26ae396616"
        },
        "downloads": -1,
        "filename": "declearn-2.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "a2507cde338a7d2af0fbfcb1732b015a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 220565,
        "upload_time": "2023-02-13T09:33:57",
        "upload_time_iso_8601": "2023-02-13T09:33:57.511156Z",
        "url": "https://files.pythonhosted.org/packages/14/af/2d263308a317ccfda07487a1d65739a118f0d3adbf22121b4cecad470d57/declearn-2.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "2.0.2.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "59b60107a996ffeddb337548a87515f13c1135487136fdd611176077963b2a28",
          "md5": "0aa0bb6e77ed8ba1414dd65b8c692940",
          "sha256": "44094a5652fc497c78acf5e148e612386e14540d6375a51a8c00e50dba9c212f"
        },
        "downloads": -1,
        "filename": "declearn-2.0.2.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0aa0bb6e77ed8ba1414dd65b8c692940",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 231158,
        "upload_time": "2023-03-02T09:33:43",
        "upload_time_iso_8601": "2023-03-02T09:33:43.532848Z",
        "url": "https://files.pythonhosted.org/packages/59/b6/0107a996ffeddb337548a87515f13c1135487136fdd611176077963b2a28/declearn-2.0.2.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b9dc11905a051ca8546b78a63c6b16cf2e67a169c63190d464bd36fab3aeda37",
          "md5": "e2df0a786fdcd01289702614b990a8a6",
          "sha256": "76f559bb230852f1996f16add5d4b5e8a375af8cb1b8e806b9f83eb664ce269d"
        },
        "downloads": -1,
        "filename": "declearn-2.0.2.2.tar.gz",
        "has_sig": false,
        "md5_digest": "e2df0a786fdcd01289702614b990a8a6",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 222444,
        "upload_time": "2023-03-02T09:33:45",
        "upload_time_iso_8601": "2023-03-02T09:33:45.597498Z",
        "url": "https://files.pythonhosted.org/packages/b9/dc/11905a051ca8546b78a63c6b16cf2e67a169c63190d464bd36fab3aeda37/declearn-2.0.2.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "2.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f7f151444e10bb067c6e476b954babadcb3a949c26270957ef5214a0065755b3",
          "md5": "fc99d0b638482663e50cb5d284ed9937",
          "sha256": "e913e77a48cd639ab1a40402e2bef6e31db0cf01d2beddf797de77ecc0eee9d7"
        },
        "downloads": -1,
        "filename": "declearn-2.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "fc99d0b638482663e50cb5d284ed9937",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 260342,
        "upload_time": "2023-03-02T09:06:12",
        "upload_time_iso_8601": "2023-03-02T09:06:12.694398Z",
        "url": "https://files.pythonhosted.org/packages/f7/f1/51444e10bb067c6e476b954babadcb3a949c26270957ef5214a0065755b3/declearn-2.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e991c323cf71bae636f7fc86b502b8d1078b3f455e7727acc71698335610ddc5",
          "md5": "fbb6464dbe22601b7f3dc2f396d26bb0",
          "sha256": "f03c6a4a437eb4362542989135036768ede041baba7125d5395ddb0950ef0336"
        },
        "downloads": -1,
        "filename": "declearn-2.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "fbb6464dbe22601b7f3dc2f396d26bb0",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 253007,
        "upload_time": "2023-03-02T09:06:15",
        "upload_time_iso_8601": "2023-03-02T09:06:15.142162Z",
        "url": "https://files.pythonhosted.org/packages/e9/91/c323cf71bae636f7fc86b502b8d1078b3f455e7727acc71698335610ddc5/declearn-2.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "f7f151444e10bb067c6e476b954babadcb3a949c26270957ef5214a0065755b3",
        "md5": "fc99d0b638482663e50cb5d284ed9937",
        "sha256": "e913e77a48cd639ab1a40402e2bef6e31db0cf01d2beddf797de77ecc0eee9d7"
      },
      "downloads": -1,
      "filename": "declearn-2.1.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "fc99d0b638482663e50cb5d284ed9937",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.8",
      "size": 260342,
      "upload_time": "2023-03-02T09:06:12",
      "upload_time_iso_8601": "2023-03-02T09:06:12.694398Z",
      "url": "https://files.pythonhosted.org/packages/f7/f1/51444e10bb067c6e476b954babadcb3a949c26270957ef5214a0065755b3/declearn-2.1.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "e991c323cf71bae636f7fc86b502b8d1078b3f455e7727acc71698335610ddc5",
        "md5": "fbb6464dbe22601b7f3dc2f396d26bb0",
        "sha256": "f03c6a4a437eb4362542989135036768ede041baba7125d5395ddb0950ef0336"
      },
      "downloads": -1,
      "filename": "declearn-2.1.0.tar.gz",
      "has_sig": false,
      "md5_digest": "fbb6464dbe22601b7f3dc2f396d26bb0",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.8",
      "size": 253007,
      "upload_time": "2023-03-02T09:06:15",
      "upload_time_iso_8601": "2023-03-02T09:06:15.142162Z",
      "url": "https://files.pythonhosted.org/packages/e9/91/c323cf71bae636f7fc86b502b8d1078b3f455e7727acc71698335610ddc5/declearn-2.1.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}