{
  "info": {
    "author": "qianzhihao",
    "author_email": "2018302170027@whu.edu.cn",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# VINN\nVINN is Visual Interpretation of Neural Networks\n\nVINN includes a series of interpretability algorithms, like LIME, Grad CAM, Integrated Gradient, saliency maps and so on.\n\nVINN is a graduation project, and will update to new version if possible.\n\n### Target audience\n\nDevelopers, who are looking to understand what their deep models have learnt, or researchers, who want to test their new algorithms are the potential audiences for VINN.\n\nVINN standardize the algorithm framework, so that you can follow the framework to construct your own algorithm and test it.\n\n### Installation\n\n##### requirements\n\nyou can create a new environment by\n\n```bash\n conda create -f requirements\n```\n\nor make sure your own environments have\n\n- python >= 3.6\n\n- pytorch >= 1.2\n\n##### installing the latest release\n\npip:\n\n``` bash\npip install vinn\n```\n\nconda:\n\n```bash\nconda install vinn\n```\n\nor you can download from GitHub and install in the repository\n\n``` bash\nhttps://github.com/Torato-Taraka/VINN.git\npip install vinn-1.0-py3-none-any.whl\n```\n\n### Getting start\n\n``` python\nimport torch\nimport torchvision.transforms as tfs\nfrom torchvision.models import resnet18\nimport cv2\n\nmodel = resnet18(pretrained=True)\ntransform = tfs.Compose([\n    tfs.ToTensor(),\n    tfs.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\nlast_conv = model.layer4[-1]\n\nimage_path = 'test.jpg'\nimage = cv2.imread(image_path)\nimage = cv2.resize(image, (256, 256))\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    \ngpu = True\n```\n\nTill now, necessary parameters(model, image, transform, gpu) is ready, and you can use VINN to interpret your model\n\n```python\nimport vinn\ngradcam = vinn.GradCAM(model=model,\n                      image=image,\n                      last_conv=last_conv,\n                      transform=transform,\n                      gpu=gpu)\ngradcam.forward()\n```\n\nAfter forward, the algorithm finish processing, and the result is stored in `gradcam.mask`.\n\nYou can visualize the result like the following:\n\n```python\nparams = {\n    \"original image\", gradcam.image,\n    \"GradCAM\", gradcam.mask,\n    \"masked image\", gradcam.masked_image\n}\nvinn.subplot([params])\n```\n\nNote that you should pass a list of dicts, since that you may need to interpret several images at the same time.\n\nAnd you can see how the image masked by calling `gradcam.masked_image`.\n\n**But pay attention that NOT all the algorithms generates mask and original image together**, only GradCAM, GuidedGradCAM, LIME and Sensitivity have masked_image.\n\nOf course you can generate by yourself and maybe the later version will achieve the function.\n\n### Customize models, datasets and algorithms\n\nVINN support customizing your model, datasets and even algorithms\n\n#### models\n\nYou should organize your model like\n\n```python\nfrom vinn.model import Models\n\n@Models(\"yourmodel\")\ndef yourmodel():\n    class yourmodel(nn.Module):\n        def __init__(self):\n        \t...\n    return yourmodel()\n```\n\nThis is for registering your algorithm in order to management\n\n#### datasets\n\nSimilar to customize models\n\n```python\nfrom vinn.datasets import DataSet\n\n@DataSet(\"yourdataset\")\ndef yourdataset():\n    class yourdataset:\n        def __init__(self):\n            ...\n            \n        def __getitem__(self, index):\n            image = self.transform(self.images[index])\n            lable = self.lables[index]\n            return image, lable\n        \n        def __len__(self):\n            return len(self.labels)\n    return yourdataset()\n```\n\n`__getitem__()` and `__len__()` is necessary, you can see the details at [torch.utils.data.Dataset]([torch.utils.data â€” PyTorch 1.10 documentation](https://pytorch.org/docs/stable/data.html?highlight=dataset#torch.utils.data.Dataset))\n\nAnd you can see all the existing dataset by\n\n```python\nfrom vinn import list_dataset\nlist_dataset()\n```\n\n#### train model\n\n```python\nfrom vinn import trainer\nfrom torchvision import transforms as tfs\ntransform = tfs.Compose([\n    ...\n])\ntrainer(\n    model_name='yourmodel',\n    dataset_name='yourdataset',\n    classes=...,\n    transform=transform,\n    train_size=...,\n    test_size=...,\n    lr=...,\n    epochs=...,\n    gpu=True\n)\n```\n\n- `model_name`: the string in the @Models() you define\n- `dataset_name`: the string in the @Dataset() you define\n- `classes`: the classes of your dataset\n- `transform`: you define it\n- `train_size`: the size of a sample from your train data\n- `test_size`: the size of a sample from your test data\n- `lr`: learning rate\n- `epochs`: training times\n- `gpu`: whether use cuda or not\n\n#### algorithms\n\nYou should first organize your algorithm like\n\n```python\nfrom vinn.algorithm import Algorithm \nclass youralgo(Algorithm):\n    def __init__(self, model, image, transform, gpu, ...):\n        super().__init__(model, image, transform, gpu)\n        ...\n        \n    def forward(self):\n        ...\n        self.mask = mask\n```\n\n`Algorithm` is the father class of all algorithms\n\nThe most important thing is that you must pass the result to `self.mask`, so that you can easily visualize your result.\n\nOr you can return your result, but I don't think it good for your following operation.\n\n### References of algorithms\n\n- `IntegratedGradients`: [Axiomatic Attribution for Deep Networks, Mukund Sundararajan et al. 2017](https://arxiv.org/abs/1703.01365)\n\n- `SmoothGrad`: [SmoothGrad: removing noise by adding noise, Daniel Smilkov et al. 2017](https://arxiv.org/abs/1706.03825)\n- `SaliencyMap` : [Deep Inside Convolutional Networks: Visualising\n  Image Classification Models and Saliency Maps, K. Simonyan, et. al. 2014](https://arxiv.org/pdf/1312.6034.pdf)\n- `GradCAM`, `GuidedGradCAM`: [Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization, Ramprasaath R. Selvaraju et al. 2017](https://arxiv.org/abs/1610.02391.pdf)\n- `LIME`:[\"Why Should I Trust You?\": Explaining the Predictions of Any Classifier](https://arxiv.org/abs/1602.04938v3)\n- `GBP(Guided Backpropagation)`:[Striving for Simplicity: The All Convolutional Net, Jost Tobias Springenberg et al. 2015](https://arxiv.org/pdf/1412.6806.pdf)\n- `Sensitivity`:[Interpretable Explanations of Black Boxes by Meaningful Perturbation](https://arxiv.org/abs/1704.03296)\n\n### License\n\nVINN is MIT licensed, as found in LICENSE file.\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/Torato-Taraka/VINN",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "vinn",
    "package_url": "https://pypi.org/project/vinn/",
    "platform": "",
    "project_url": "https://pypi.org/project/vinn/",
    "project_urls": {
      "Homepage": "https://github.com/Torato-Taraka/VINN"
    },
    "release_url": "https://pypi.org/project/vinn/1.1/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "Visual Interpretation of Neural Networks",
    "version": "1.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12949979,
  "releases": {
    "1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4d545dd19dd84844c72b928c7383a1d51f402b6f2e9cb44c98b6338666eda1b5",
          "md5": "d891b57addc2a6abf7ebbde223ab7d05",
          "sha256": "1b1f32c4c14389a5ea088e92e9979544d31c128589595675a69bbd33a5aa7cd9"
        },
        "downloads": -1,
        "filename": "vinn-1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d891b57addc2a6abf7ebbde223ab7d05",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 43799,
        "upload_time": "2022-02-20T10:00:56",
        "upload_time_iso_8601": "2022-02-20T10:00:56.258641Z",
        "url": "https://files.pythonhosted.org/packages/4d/54/5dd19dd84844c72b928c7383a1d51f402b6f2e9cb44c98b6338666eda1b5/vinn-1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b6cf9e412249a8c2c077c16a0236b6df5b1bdd511c927cc0b84c8a03ea6f36ee",
          "md5": "c0ce8c2b095ae0ede85579c0c880c7e5",
          "sha256": "c9e00f7ee35fc5c48798a2dbb311b05f1c509452dd37a6a2a93a6961211d5f93"
        },
        "downloads": -1,
        "filename": "vinn-1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "c0ce8c2b095ae0ede85579c0c880c7e5",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 17197,
        "upload_time": "2022-02-20T10:00:59",
        "upload_time_iso_8601": "2022-02-20T10:00:59.955913Z",
        "url": "https://files.pythonhosted.org/packages/b6/cf/9e412249a8c2c077c16a0236b6df5b1bdd511c927cc0b84c8a03ea6f36ee/vinn-1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "4d545dd19dd84844c72b928c7383a1d51f402b6f2e9cb44c98b6338666eda1b5",
        "md5": "d891b57addc2a6abf7ebbde223ab7d05",
        "sha256": "1b1f32c4c14389a5ea088e92e9979544d31c128589595675a69bbd33a5aa7cd9"
      },
      "downloads": -1,
      "filename": "vinn-1.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "d891b57addc2a6abf7ebbde223ab7d05",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 43799,
      "upload_time": "2022-02-20T10:00:56",
      "upload_time_iso_8601": "2022-02-20T10:00:56.258641Z",
      "url": "https://files.pythonhosted.org/packages/4d/54/5dd19dd84844c72b928c7383a1d51f402b6f2e9cb44c98b6338666eda1b5/vinn-1.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "b6cf9e412249a8c2c077c16a0236b6df5b1bdd511c927cc0b84c8a03ea6f36ee",
        "md5": "c0ce8c2b095ae0ede85579c0c880c7e5",
        "sha256": "c9e00f7ee35fc5c48798a2dbb311b05f1c509452dd37a6a2a93a6961211d5f93"
      },
      "downloads": -1,
      "filename": "vinn-1.1.tar.gz",
      "has_sig": false,
      "md5_digest": "c0ce8c2b095ae0ede85579c0c880c7e5",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 17197,
      "upload_time": "2022-02-20T10:00:59",
      "upload_time_iso_8601": "2022-02-20T10:00:59.955913Z",
      "url": "https://files.pythonhosted.org/packages/b6/cf/9e412249a8c2c077c16a0236b6df5b1bdd511c927cc0b84c8a03ea6f36ee/vinn-1.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}