{
  "info": {
    "author": "BobDu",
    "author_email": "i@bobdu.cc",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Environment :: Console",
      "Framework :: Scrapy",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: BSD License",
      "Operating System :: OS Independent",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.4",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: Implementation :: CPython",
      "Programming Language :: Python :: Implementation :: PyPy",
      "Topic :: Internet :: WWW/HTTP",
      "Topic :: Software Development :: Libraries :: Application Frameworks",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "=======\nScrapy3\n=======\n\n.. image:: https://img.shields.io/pypi/v/Scrapy.svg\n   :target: https://pypi.python.org/pypi/Scrapy\n   :alt: PyPI Version\n\n.. image:: https://img.shields.io/pypi/pyversions/Scrapy.svg\n   :target: https://pypi.python.org/pypi/Scrapy\n   :alt: Supported Python Versions\n\n.. image:: https://img.shields.io/travis/scrapy/scrapy/master.svg\n   :target: https://travis-ci.org/scrapy/scrapy\n   :alt: Build Status\n\n.. image:: https://img.shields.io/badge/wheel-yes-brightgreen.svg\n   :target: https://pypi.python.org/pypi/Scrapy\n   :alt: Wheel Status\n\n.. image:: https://img.shields.io/codecov/c/github/scrapy/scrapy/master.svg\n   :target: https://codecov.io/github/scrapy/scrapy?branch=master\n   :alt: Coverage report\n\n.. image:: https://anaconda.org/conda-forge/scrapy/badges/version.svg\n   :target: https://anaconda.org/conda-forge/scrapy\n   :alt: Conda Version\n\nAbstract\n========\n\nThis is a fork for Scrapy. For apply best in python3\n\nOverview\n========\n\nScrapy is a fast high-level web crawling and web scraping framework, used to\ncrawl websites and extract structured data from their pages. It can be used for\na wide range of purposes, from data mining to monitoring and automated testing.\n\nFor more information including a list of features check the Scrapy homepage at:\nhttps://scrapy.org\n\nRequirements\n============\n\n* Python 3.4+\n* Works on Linux, Windows, Mac OSX, BSD\n\nInstall\n=======\n\nThe quick way::\n\n    pip install scrapy\n\nFor more details see the install section in the documentation:\nhttps://doc.scrapy.org/en/latest/intro/install.html\n\nDocumentation\n=============\n\nDocumentation is available online at https://doc.scrapy.org/ and in the ``docs``\ndirectory.\n\nReleases\n========\n\nYou can find release notes at https://doc.scrapy.org/en/latest/news.html\n\nCommunity (blog, twitter, mail list, IRC)\n=========================================\n\nSee https://scrapy.org/community/\n\nContributing\n============\n\nSee https://doc.scrapy.org/en/master/contributing.html\n\nCode of Conduct\n---------------\n\nPlease note that this project is released with a Contributor Code of Conduct\n(see https://github.com/scrapy/scrapy/blob/master/CODE_OF_CONDUCT.md).\n\nBy participating in this project you agree to abide by its terms.\nPlease report unacceptable behavior to opensource@scrapinghub.com.\n\nCompanies using Scrapy\n======================\n\nSee https://scrapy.org/companies/\n\nCommercial Support\n==================\n\nSee https://scrapy.org/support/\n\n\n",
    "description_content_type": "",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/Bob-Du/scrapy3",
    "keywords": "",
    "license": "BSD",
    "maintainer": "",
    "maintainer_email": "",
    "name": "Scrapy3",
    "package_url": "https://pypi.org/project/Scrapy3/",
    "platform": "",
    "project_url": "https://pypi.org/project/Scrapy3/",
    "project_urls": {
      "Homepage": "https://github.com/Bob-Du/scrapy3"
    },
    "release_url": "https://pypi.org/project/Scrapy3/1.0.1/",
    "requires_dist": [
      "Twisted (>=13.1.0)",
      "w3lib (>=1.17.0)",
      "queuelib",
      "lxml",
      "pyOpenSSL",
      "cssselect (>=0.9)",
      "six (>=1.5.2)",
      "parsel (>=1.4)",
      "PyDispatcher (>=2.0.5)",
      "service-identity",
      "PyPyDispatcher (>=2.1.0); platform_python_implementation == \"PyPy\""
    ],
    "requires_python": ">=3.4",
    "summary": "A high-level Web Crawling and Web Scraping framework",
    "version": "1.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 4203044,
  "releases": {
    "1.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d18c8063b0138fa0d98cf44eec91335e54f359c5079518afc3c191a4553eae8c",
          "md5": "c67318401181c58f70cdd035eca6b31f",
          "sha256": "7da6f2c055682436ef3612dff3d469261e3c72dba72b71707abdbcc95e3356ed"
        },
        "downloads": -1,
        "filename": "Scrapy3-1.0.1-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "c67318401181c58f70cdd035eca6b31f",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": ">=3.4",
        "size": 230725,
        "upload_time": "2018-08-24T09:35:14",
        "upload_time_iso_8601": "2018-08-24T09:35:14.998136Z",
        "url": "https://files.pythonhosted.org/packages/d1/8c/8063b0138fa0d98cf44eec91335e54f359c5079518afc3c191a4553eae8c/Scrapy3-1.0.1-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9afa6a0512089f4b8238e4d56dd9b21d5b07591a1747197796b48898896b3408",
          "md5": "d8d482b7d317620a31ec1bd297a4ce90",
          "sha256": "886c25830514d59bdcfe015bb681e74efc945e0d9032ae30cfbe702116224684"
        },
        "downloads": -1,
        "filename": "Scrapy3-1.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "d8d482b7d317620a31ec1bd297a4ce90",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.4",
        "size": 912681,
        "upload_time": "2018-08-24T09:37:08",
        "upload_time_iso_8601": "2018-08-24T09:37:08.261510Z",
        "url": "https://files.pythonhosted.org/packages/9a/fa/6a0512089f4b8238e4d56dd9b21d5b07591a1747197796b48898896b3408/Scrapy3-1.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "d18c8063b0138fa0d98cf44eec91335e54f359c5079518afc3c191a4553eae8c",
        "md5": "c67318401181c58f70cdd035eca6b31f",
        "sha256": "7da6f2c055682436ef3612dff3d469261e3c72dba72b71707abdbcc95e3356ed"
      },
      "downloads": -1,
      "filename": "Scrapy3-1.0.1-py2.py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "c67318401181c58f70cdd035eca6b31f",
      "packagetype": "bdist_wheel",
      "python_version": "py2.py3",
      "requires_python": ">=3.4",
      "size": 230725,
      "upload_time": "2018-08-24T09:35:14",
      "upload_time_iso_8601": "2018-08-24T09:35:14.998136Z",
      "url": "https://files.pythonhosted.org/packages/d1/8c/8063b0138fa0d98cf44eec91335e54f359c5079518afc3c191a4553eae8c/Scrapy3-1.0.1-py2.py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "9afa6a0512089f4b8238e4d56dd9b21d5b07591a1747197796b48898896b3408",
        "md5": "d8d482b7d317620a31ec1bd297a4ce90",
        "sha256": "886c25830514d59bdcfe015bb681e74efc945e0d9032ae30cfbe702116224684"
      },
      "downloads": -1,
      "filename": "Scrapy3-1.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "d8d482b7d317620a31ec1bd297a4ce90",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.4",
      "size": 912681,
      "upload_time": "2018-08-24T09:37:08",
      "upload_time_iso_8601": "2018-08-24T09:37:08.261510Z",
      "url": "https://files.pythonhosted.org/packages/9a/fa/6a0512089f4b8238e4d56dd9b21d5b07591a1747197796b48898896b3408/Scrapy3-1.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}