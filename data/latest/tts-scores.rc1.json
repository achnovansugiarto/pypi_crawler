{
  "info": {
    "author": "James",
    "author_email": "james@adamant.ai",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# TTS Scores - Better evaluation metrics for text to speech models\n\nTTS quality is a difficult thing to measure. Distance-based metrics are poor measurements because they only measure\nsimilarity to the test set, not the realism of the generated speech. For this reason, most TTS papers rely on Mean\nOpinion Scores to report model quality. Computing MOS involves humans in the loop, meaning it is costly and time\nconsuming. More importantly, it cannot be used while training to evaluate the real-time performance of a model while\ntraining.\n\nThe field of image generation has settled on the usage of the Frechet Inception Distance and Inception Score metrics\nto measure live performance. They are quite successful. I think we should take a page out of their book. But, we can\nmodernize this a little:\n\n## Installation\n\ntts-scores is available on pypi:\n```shell\npip install tts-scores\n```\n\n## Contrastive Language-Voice Pretrained model (CLVP)\n\nTo this end, I trained a CLIP-like architecture with a twist: instead of measuring the similarity of text and images,\nit measures the similarity of text and voice clips. I call this model CLVP. I believe such a model is an exceptional \ncandidate for synthesizing a quality metric for Text->Voice models, much in the way that the Inception model is used for\nFID and IS scores.\n\nThis repo contains the source code for CLVP and scripts that allow you to use it. I have built two metrics:\n\n### CLVP Score\n\nThe CLVP score measures the distance predicted by CVLP between text and an audio clip where that text is spoken. A lower\nscore is better. It can be obtained by:\n\n```python\nfrom tts_scores.clvp import CLVPMetric\ncv_metric = CLVPMetric(device='cuda')\nscore = cv_metric.compute_clvp('<path_to_your_tsv>', 'D:\\\\tmp\\\\tortoise-tts-eval\\\\real')\n```\n\n*Note: the format of the TSV file is described in a later section*\n\n### CLVP Frechet Distance\n\nSimilar to FID, this metric compares the distribution of real spoken text with whatever your TTS model generatets.\nIt is particularly useful if you have a bunch of spoken text that you want to compare against but do not have the \ntranscriptions for that text. For example, this is a good fit for measuring the performance of vocoders.\n\nIt works by computing the frechet distance of the outputs of the last layer of the CLVP model when fed data from\nboth distributions. Similar to FID, a lower score is better. It can be obtained by:\n\n```python\nfrom tts_scores.clvp import CLVPMetric\ncv_metric = CLVPMetric(device='cuda')\nscore = cv_metric.compute_fd('<path_to_your_generated_audio>, '<path_to_your_real_audio>')\n```\n\n## wav2vec2 Intelligibility Score\n\nOne rather obvious way to compute the performance of a TTS system that I have not seen before is to leverage an ASR\nsystem. If the goal is to produce intelligible speech - why not use a speech recognition system to measure that\nintelligibility.\n\nThe intelligibility score packaged in this repo does exactly that. It takes in a list of generated and real audio files\nand their transcriptions, and feeds everything through a pre-trained wav2vec2 model. The raw losses are returned. The\nscore is the difference between the wav2vec2 losses for the fake/generated samples and the real samples.\n\nWhile CLVP scores take things like voice quality, voice diversity and prosody into account, the intelligibility score\nonly considers whether or not the speech your TTS model generates maps coherently to the text you put into it. For some\nuse cases, this will be the most important score. For others, all of the scores are important.\n\n```python\nfrom tts_scores.intelligibility import IntelligibilityMetric\nis_metric = IntelligibilityMetric(device='cuda')\nscore = is_metric.compute_intelligibility('<path_to_your_tsv>', '<path_to_your_real_audio>')\n```\n\n## Scores from common models\n\nA metric is only good if there are benchmarks which can be used as points of comparison. To this end, I computed\nall of the scores in this repo on two high-performance TTS models:\n\n1. Tacotron2+waveglow from [NVIDIA's repo](https://github.com/NVIDIA/tacotron2)\n2. FastSpeech2+hifigan from [ming024's repo](https://github.com/ming024/FastSpeech2)\n\nSee the scores below:\n\n# Citations\n\nPlease cite this repo if you use it in your repo:\n\n```\n@software{TTS-scores,\n  author = {Betker, J ames},\n  month = {4},\n  title = {{TTS-scores}},\n  url = {https://github.com/neonbjb/tts-scores},\n  version = {1.0.0},\n  year = {2022}\n}\n```",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "https://github.com/neonbjb/tts-scores/archive/refs/tags/1.0.0.tar.gz",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/neonbjb/tts-scores",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "tts-scores",
    "package_url": "https://pypi.org/project/tts-scores/",
    "platform": null,
    "project_url": "https://pypi.org/project/tts-scores/",
    "project_urls": {
      "Download": "https://github.com/neonbjb/tts-scores/archive/refs/tags/1.0.0.tar.gz",
      "Homepage": "https://github.com/neonbjb/tts-scores"
    },
    "release_url": "https://pypi.org/project/tts-scores/1.0.0/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "A library for computing performance metrics for text-to-speech systems",
    "version": "1.0.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 13370440,
  "releases": {
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e48d276b518a7850846adf3686790e671f938b5c4a14aaf2e0baf2e2009512de",
          "md5": "5229f2586952d8d77031ffec6bee2186",
          "sha256": "f0d7c8c213965145b9f282e34aa6ea23b8e6ac629a21968e85ddb81edb813a3a"
        },
        "downloads": -1,
        "filename": "tts-scores-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "5229f2586952d8d77031ffec6bee2186",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 13996,
        "upload_time": "2022-04-01T06:42:19",
        "upload_time_iso_8601": "2022-04-01T06:42:19.424567Z",
        "url": "https://files.pythonhosted.org/packages/e4/8d/276b518a7850846adf3686790e671f938b5c4a14aaf2e0baf2e2009512de/tts-scores-1.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "e48d276b518a7850846adf3686790e671f938b5c4a14aaf2e0baf2e2009512de",
        "md5": "5229f2586952d8d77031ffec6bee2186",
        "sha256": "f0d7c8c213965145b9f282e34aa6ea23b8e6ac629a21968e85ddb81edb813a3a"
      },
      "downloads": -1,
      "filename": "tts-scores-1.0.0.tar.gz",
      "has_sig": false,
      "md5_digest": "5229f2586952d8d77031ffec6bee2186",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 13996,
      "upload_time": "2022-04-01T06:42:19",
      "upload_time_iso_8601": "2022-04-01T06:42:19.424567Z",
      "url": "https://files.pythonhosted.org/packages/e4/8d/276b518a7850846adf3686790e671f938b5c4a14aaf2e0baf2e2009512de/tts-scores-1.0.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}