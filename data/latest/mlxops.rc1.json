{
  "info": {
    "author": "Fernando Nieuwveldt",
    "author_email": "fdnieuwveldt@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Automating the ML Training Lifecycle with MLxOPS\n\nWe tend to reinvent the training lifecycle on different projects. Given that most ML training lifecycle consist of similar steps\nwe can automate most of the parts of an ML project. \n\nThis package contains model training life cycle components for automating the training and scoring life cycle of models.\nPandas dataframes are used as the underlying data object. As for the estimators, it can be sklearn type estimators that has \nfit and predict method. Estimators like XGBoost en LightGBM can also be used. \n\nMLxOPS serves as experiment and operations module by also persisting all metadata for each component and any artifacts we need to \nreproduce results.\n\nThe mlxops components module contains Machine Learning life cycle components of each step. The components consists of:\n* DataLoader\n    * Data loading component of the training pipeline. This component also contains any stateless preprocessing steps the user\n      wants to apply on the data.\n* DataFeatureMapper\n    * Feature processing pipeline. Apply Feature mapper for example Normalization for numeric features and OneHotEncoder for\n      categoric features. Mapper here is stateful.\n* DataValidator\n    * Data validation component of the training pipeline. Can use sklearn outlier detectors or use can implement their own. This validator\n      should return a mask where -1 is an outlier and 1 an inlier.\n* ModelTrainer\n    * Model component of the training pipeline. ModelTrainer depends on a runned DataLoader, DataFeatureMapper and DataValidator to fit estimator.\n* ModelEvaluator\n    * Compare metrics between trained model and current model in production. This can be any of the metrics implemented in sklearn\n* ArtifactPusher\n    * Pushes artifacts to PROD directory if current model is an improvement on the current best model\n\n<br />\n\nThe mlxops package also contains high level interfaces for training and scoring using pipeline modules:\n* ModelTrainingPipeline\n    * This is a high level implementation of the training life cycle for all the steps in life cycle\n* ScoringPipeline\n    * This pipeline can be used to score data. The model can be loaded from disk or supplied.\n\n## To install package:\n```bash\npip install mlxops\n```\n\n# Example 1: Using the different pipeline components\n\n\n```python\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import ShuffleSplit\n\n# local imports\nimport mlxops\nfrom mlxops.components import DataLoader, DataFeatureMapper, DataValidator\nfrom mlxops.components import ModelTrainer, ModelEvaluator, ArtifactPusher\n```\n\n## DataLoader component of the life cycle\nLoad data using the DataLoader to load data:\n\n```python\nfile_url = \"http://storage.googleapis.com/download.tensorflow.org/data/heart.csv\"\ndata_loader = DataLoader.from_file(file_url, target='target', splitter=ShuffleSplit)\ndata_loader.run()\n```\nDataLoader splits data into train, test and evaulation sets. These sets can retrieved from the following properties\n```python\ndata_loader.train_set\ndata_loader.test_set\ndata_loader.eval_set\n```\n\n## Feature mapper component of the life cycle\nThis component does for example Normalization, OneHotEncoding etc. If the dtypes are properly set user can use the infered pipeline. For this example we will use the infered feature mapper. The feature mapper's run method takes in a DataLoader object.\n```python\nfeature_mapper = DataFeatureMapper.from_infered_pipeline()\nfeature_mapper.run(data_loader=data_loader)\n```\nExample to apply the feature mapper:\n```python\nmapped_train_features = feature_mapper.transform(data_loader.train_set[0])\n```\n\n## Validator component of the life cycle\nThis component step is optional and it takes in a sklearn validator or outlier detector as input. This validator needs to implement a predict method that returns 1 for inlier and -1 for outlier. The validator component gets applied on feature mapped data from the feature_mapper step. The run method takes in a runned DataLoader and DataValidator as input. \n\n```python\ndata_validator = DataValidator(\n    validator=IsolationForest(contamination=0.001)\n)\ndata_validator.run(data_loader=data_loader, feature_mapper=feature_mapper)\n```\nThe mask for the train data can be retrieved from a property method. This mask can be used in conjunction with the DataLoader component to select only relevant samples. For example\n```python\ntrain_data, train_targets = data_loader.train_set\nvalid_train_data, valid_train_targets = train_data[data_validator.trainset_valid],\\\n                                        train_targets[data_validator.trainset_valid]\n```\n\n## ModelTrainer Component of the Machine Learning experiment life cycle\nThe ModelTrainer takes in a sklearn type estimator that implements fit and predict. The ModelTrainer's run method takes components DataLoader, DataFeatureMapper and DataValidator component as inputs. We will set this as our base model.\n\n```python\nbase_trainer = ModelTrainer(\n    estimator=LogisticRegression()\n)\nbase_trainer.run(data_loader, feature_mapper, data_validator)\n```\nLet save this base model and build a new model. We will compare the new model against the base model later.\n```python\nmlxops.saved_model.save(base_trainer, \"lr_base_model\")\n```\n\nLet build a second challenger model using a random forest classifier\n```python\nnew_trainer = ModelTrainer(\n    estimator=RandomForestClassifier(n_estimators=50)\n)\nnew_trainer.run(data_loader, feature_mapper, data_validator)\n```\n\n## ModelEvaluator component step in the Machine Learning life cycle\nThe ModelEvaluator component compares two models based on the supplied metrics. he ModelEvaluator's run method takes components DataLoader, DataFeatureMapper and DataValidator component as inputs as well as a new trained model. The base model is an instance atrributes of the class.\n\n```python\nevaluator = ModelEvaluator(base_model=\"lr_base_model\",\n                           metrics=[accuracy_score])\nevaluator.run(\n    data_loader, feature_mapper, data_validator, new_trainer\n)\n```\nTo check if this model should be pushed:\n```python\nevaluator.push_model\n```\nCheck the models compare with the supplied metrics:\n```python\nevaluator.evaluation_metrics\n```\n\n# Pipeline example\nFor a more high level interface. We can build a pipeline. Here we demonstrate a ModelTrainingPipeline. Similar to the example above.\n\n```python\nfrom mlxops.pipeline import ModelTrainingPipeline\n```\n\nSetup Pipeline\n```python\n\nfile_url = \"http://storage.googleapis.com/download.tensorflow.org/data/heart.csv\"\n\ntrain_pipeline_arguments = {\n    'data_loader': DataLoader.from_file(\n        file_name=file_url, target='target', splitter=ShuffleSplit\n    ),\n    'data_validator': DataValidator(\n        validator=IsolationForest(contamination=0.01)\n    ),\n    'feature_mapper': DataFeatureMapper.from_infered_pipeline(),\n    'trainer': ModelTrainer(\n        estimator=RandomForestClassifier(n_estimators=100, max_depth=3)\n    ),\n    'evaluator': ModelEvaluator(\n        base_model='lr_base_model',\n        metrics=[accuracy_score]\n    ),\n    'pusher': ArtifactPusher(model_serving_dir='testfolder'),\n    \"run_id\": \"0.0.0.1\"\n}\n```\nExecute Pipeline:\n```python\ntrain_pipeline = ModelTrainingPipeline(\n    **train_pipeline_arguments\n)\ntrain_pipeline.run()\nmlxops.saved_model.save(train_pipeline, \"base_model\")\n```\n\nThe ```saved_model``` module saves all component artifacts used in the pipeline along with other metadata. Lets load the saved pipeline\n```python\ndel train_pipeline\n\nloaded_pipeline = mlxops.saved_model.load(\"base_model\")\n```\nEach component can be access through ```loaded_pipeline.component``` where component can be any of:\n```\n* data_loader\n* data_validator\n* evaluator\n* feature_mapper\n* trainer\n* pusher\n```\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/fernandonieuwveldt/mlxops_pipelines",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "mlxops",
    "package_url": "https://pypi.org/project/mlxops/",
    "platform": "",
    "project_url": "https://pypi.org/project/mlxops/",
    "project_urls": {
      "Homepage": "https://github.com/fernandonieuwveldt/mlxops_pipelines"
    },
    "release_url": "https://pypi.org/project/mlxops/0.1.0/",
    "requires_dist": [
      "pandas (==1.0.0)",
      "scikit-learn (==0.24.2)"
    ],
    "requires_python": ">=3.6.0",
    "summary": "Automating the ML Training Lifecycle with MLxOPS",
    "version": "0.1.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12802508,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c477dca2d818adc2df1afff48022a461c90ae2f82f6d1c719926b871db951aff",
          "md5": "8d2b7d633e2ce64a8252e3de48eecedf",
          "sha256": "41f20a0ff4293fe378ff8f7df38fe0c9e5e894b7943cc96d1362b2a1ff119d07"
        },
        "downloads": -1,
        "filename": "mlxops-0.1.0-py3.6.egg",
        "has_sig": false,
        "md5_digest": "8d2b7d633e2ce64a8252e3de48eecedf",
        "packagetype": "bdist_egg",
        "python_version": "0.1.0",
        "requires_python": ">=3.6.0",
        "size": 34152,
        "upload_time": "2022-02-06T12:39:28",
        "upload_time_iso_8601": "2022-02-06T12:39:28.875097Z",
        "url": "https://files.pythonhosted.org/packages/c4/77/dca2d818adc2df1afff48022a461c90ae2f82f6d1c719926b871db951aff/mlxops-0.1.0-py3.6.egg",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4cfa82e7d32787d32a439c0abc003bd73e0ed42a05bd69d0fc047b513f6e0321",
          "md5": "562f0273f399368b40da2cdbc137253e",
          "sha256": "52de4b3cbdaaeda248a5210dbbf2ad9a4cb8e236c4ece6159664c754c934723c"
        },
        "downloads": -1,
        "filename": "mlxops-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "562f0273f399368b40da2cdbc137253e",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6.0",
        "size": 16844,
        "upload_time": "2022-02-06T12:39:27",
        "upload_time_iso_8601": "2022-02-06T12:39:27.337138Z",
        "url": "https://files.pythonhosted.org/packages/4c/fa/82e7d32787d32a439c0abc003bd73e0ed42a05bd69d0fc047b513f6e0321/mlxops-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bdf3042f9c97ef5fa8e7fc23fa5bb2f822be8f77cb42c9fea9a1c68ba3067d9e",
          "md5": "8e7e53e804b5dcc46781879f123ddaa9",
          "sha256": "d8f6a0fc5dd97f180a40ba0b5b54d748d5e9a18addb4d6b815f046c8ecd72d78"
        },
        "downloads": -1,
        "filename": "mlxops-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "8e7e53e804b5dcc46781879f123ddaa9",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6.0",
        "size": 12392,
        "upload_time": "2022-02-06T12:39:31",
        "upload_time_iso_8601": "2022-02-06T12:39:31.145917Z",
        "url": "https://files.pythonhosted.org/packages/bd/f3/042f9c97ef5fa8e7fc23fa5bb2f822be8f77cb42c9fea9a1c68ba3067d9e/mlxops-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "c477dca2d818adc2df1afff48022a461c90ae2f82f6d1c719926b871db951aff",
        "md5": "8d2b7d633e2ce64a8252e3de48eecedf",
        "sha256": "41f20a0ff4293fe378ff8f7df38fe0c9e5e894b7943cc96d1362b2a1ff119d07"
      },
      "downloads": -1,
      "filename": "mlxops-0.1.0-py3.6.egg",
      "has_sig": false,
      "md5_digest": "8d2b7d633e2ce64a8252e3de48eecedf",
      "packagetype": "bdist_egg",
      "python_version": "0.1.0",
      "requires_python": ">=3.6.0",
      "size": 34152,
      "upload_time": "2022-02-06T12:39:28",
      "upload_time_iso_8601": "2022-02-06T12:39:28.875097Z",
      "url": "https://files.pythonhosted.org/packages/c4/77/dca2d818adc2df1afff48022a461c90ae2f82f6d1c719926b871db951aff/mlxops-0.1.0-py3.6.egg",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "4cfa82e7d32787d32a439c0abc003bd73e0ed42a05bd69d0fc047b513f6e0321",
        "md5": "562f0273f399368b40da2cdbc137253e",
        "sha256": "52de4b3cbdaaeda248a5210dbbf2ad9a4cb8e236c4ece6159664c754c934723c"
      },
      "downloads": -1,
      "filename": "mlxops-0.1.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "562f0273f399368b40da2cdbc137253e",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6.0",
      "size": 16844,
      "upload_time": "2022-02-06T12:39:27",
      "upload_time_iso_8601": "2022-02-06T12:39:27.337138Z",
      "url": "https://files.pythonhosted.org/packages/4c/fa/82e7d32787d32a439c0abc003bd73e0ed42a05bd69d0fc047b513f6e0321/mlxops-0.1.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "bdf3042f9c97ef5fa8e7fc23fa5bb2f822be8f77cb42c9fea9a1c68ba3067d9e",
        "md5": "8e7e53e804b5dcc46781879f123ddaa9",
        "sha256": "d8f6a0fc5dd97f180a40ba0b5b54d748d5e9a18addb4d6b815f046c8ecd72d78"
      },
      "downloads": -1,
      "filename": "mlxops-0.1.0.tar.gz",
      "has_sig": false,
      "md5_digest": "8e7e53e804b5dcc46781879f123ddaa9",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6.0",
      "size": 12392,
      "upload_time": "2022-02-06T12:39:31",
      "upload_time_iso_8601": "2022-02-06T12:39:31.145917Z",
      "url": "https://files.pythonhosted.org/packages/bd/f3/042f9c97ef5fa8e7fc23fa5bb2f822be8f77cb42c9fea9a1c68ba3067d9e/mlxops-0.1.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}