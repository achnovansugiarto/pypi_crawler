{
  "info": {
    "author": "ionite",
    "author_email": "dev@ionite.io",
    "bugtrack_url": null,
    "classifiers": [
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3 :: Only",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9"
    ],
    "description": "# Aquila Resolve - Grapheme-to-Phoneme Converter\n\n[![Build](https://github.com/ionite34/Aquila-Resolve/actions/workflows/push-main.yml/badge.svg)](https://github.com/ionite34/Aquila-Resolve/actions/workflows/push-main.yml)\n[![CodeQL](https://github.com/ionite34/Aquila-Resolve/actions/workflows/codeql-analysis.yml/badge.svg)](https://github.com/ionite34/Aquila-Resolve/actions/workflows/codeql-analysis.yml)\n[![codecov](https://codecov.io/gh/ionite34/Aquila-Resolve/branch/main/graph/badge.svg?token=Y9DDMJ0C9A)](https://codecov.io/gh/ionite34/Aquila-Resolve)\n[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Fionite34%2FAquila-Resolve.svg?type=shield)](https://app.fossa.com/projects/git%2Bgithub.com%2Fionite34%2FAquila-Resolve?ref=badge_shield)\n\n![PyPI - Python Version](https://img.shields.io/pypi/pyversions/Aquila-Resolve)\n[![PyPI version](https://badge.fury.io/py/Aquila-Resolve.svg)](https://pypi.org/project/Aquila-Resolve/)\n\n### Augmented Recurrent Neural G2P with Inflectional Orthography\n\nAquila Resolve presents a new approach for accurate and efficient English to \n[ARPAbet](https://wikipedia.org/wiki/ARPABET) G2P resolution.\nThe pipeline employs a context layer, multiple transformer and n-gram morpho-orthographical search layers, \nand an autoregressive recurrent neural transformer base. The current implementation offers state-of-the-art accuracy for out-of-vocabulary (OOV) words, as well as contextual\nanalysis for correct inferencing of [English Heteronyms](https://en.wikipedia.org/wiki/Heteronym_(linguistics)).\n\nThe package is offered in a pre-trained state that is ready for [usage](#Usage) as a dependency or in\nnotebook environments. There are no additional resources needed, other than the model checkpoint which is\nautomatically downloaded on the first usage. See [Installation](#Installation) for more information.\n\n### 1. Dynamic Word Mappings based on context:\n\n```pycon\ng2p.convert('I read the book, did you read it?')\n# >> '{AY1} {R EH1 D} {DH AH0} {B UH1 K}, {D IH1 D} {Y UW1} {R IY1 D} {IH1 T}?'\n```\n```pycon\ng2p.convert('The researcher was to subject the subject to a test.')\n# >> '{DH AH0} {R IY1 S ER0 CH ER0} {W AA1 Z} {T UW1} {S AH0 B JH EH1 K T} {DH AH0} {S AH1 B JH IH0 K T} {T UW1} {AH0} {T EH1 S T}.'\n```\n\n|                                                                                                                                                              | 'The subject was told to read. Eight records were read in total.'                                      |\n|--------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------|\n| *Ground Truth*                                                                                                                                               | The `S AH1 B JH IH0 K T` was told to `R IY1 D`. Eight `R EH1 K ER0 D Z` were `R EH1 D` in total.       |\n| Aquila Resolve                                                                                                                                               | The `S AH1 B JH IH0 K T` was told to `R IY1 D`. Eight `R EH1 K ER0 D Z` were `R EH1 D` in total.       |\n| [Deep Phonemizer](https://github.com/as-ideas/DeepPhonemizer)<br/>([en_us_cmudict_forward.pt](https://github.com/as-ideas/DeepPhonemizer#pretrained-models)) | The **S AH B JH EH K T** was told to **R EH D**. Eight **R AH K AO R D Z** were `R EH D` in total.     |\n| [CMUSphinx Seq2Seq](https://github.com/cmusphinx/g2p-seq2seq)<br/>([checkpoint](https://github.com/cmusphinx/g2p-seq2seq#running-g2p))                       | The `S AH1 B JH IH0 K T` was told to `R IY1 D`. Eight **R IH0 K AO1 R D Z** were **R IY1 D** in total. |\n| [ESpeakNG](https://github.com/espeak-ng/espeak-ng) <br/> (with [phonecodes](https://github.com/jhasegaw/phonecodes))                                         | The **S AH1 B JH EH K T** was told to `R IY1 D`. Eight `R EH1 K ER0 D Z` were **R IY1 D** in total.    |\n\n### 2. Leading Accuracy for unseen words:\n\n```pycon\ng2p.convert('Did you kalpe the Hevinet?')\n# >> '{AY1} {R EH1 D} {DH AH0} {B UH1 K}, {D IH1 D} {Y UW1} {R IY1 D} {IH1 T}?'\n```\n \n|                                                                                                                                                              | \"tensorflow\"                | \"agglomerative\"                    | \"necrophages\"                    |\n|--------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------|------------------------------------|----------------------------------|\n| Aquila Resolve                                                                                                                                               | `T EH1 N S ER0 F L OW2`     | `AH0 G L AA1 M ER0 EY2 T IH0 V`    | `N EH1 K R OW0 F EY2 JH IH0 Z`   |\n| [Deep Phonemizer](https://github.com/as-ideas/DeepPhonemizer)<br/>([en_us_cmudict_forward.pt](https://github.com/as-ideas/DeepPhonemizer#pretrained-models)) | `T EH N S ER F L OW`        | **AH G L AA M ER AH T IH V**       | `N EH K R OW F EY JH IH Z`       |\n| [CMUSphinx Seq2Seq](https://github.com/cmusphinx/g2p-seq2seq)<br/>([checkpoint](https://github.com/cmusphinx/g2p-seq2seq#running-g2p))                       | **T EH1 N S ER0 L OW0 F**   | **AH0 G L AA1 M ER0 T IH0 V**      | **N AE1 K R AH0 F IH0 JH IH0 Z** |\n| [ESpeakNG](https://github.com/espeak-ng/espeak-ng) <br/> (with [phonecodes](https://github.com/jhasegaw/phonecodes))                                         | **T EH1 N S OW0 R F L OW2** | **AA G L AA1 M ER0 R AH0 T IH2 V** | **N EH1 K R AH0 F IH JH EH0 Z**  |\n\n\n## Installation\n\n```bash\npip install aquila-resolve\n```\n> A pre-trained [model checkpoint](https://huggingface.co/ionite/Aquila-Resolve/blob/main/model.pt) (~106 MB) will be\n> automatically downloaded on the first use of relevant public methods that require inferencing. For example,\n> when [instantiating `G2p`](#Usage). You can also start this download manually by calling `Aquila_Resolve.download()`.\n> \n> If you are in an environment where remote file downloads are not possible, you can also transfer the checkpoint \n> manually, placing `model.pt` within the `Aquila_Resolve.data` module folder.\n\n## Usage\n\n### 1. Module\n\n```python\nfrom Aquila_Resolve import G2p\n\ng2p = G2p()\n\ng2p.convert('The book costs $5, will you read it?')\n# >> '{DH AH0} {B UH1 K} {K AA1 S T S} {F AY1 V} {D AA1 L ER0 Z}, {W IH1 L} {Y UW1} {R IY1 D} {IH1 T}?'\n```\n\n> Optional parameters when defining a `G2p` instance:\n\n| Parameter         | Default | Description                                                                                                                                                              |\n|-------------------|---------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| `device`          | `'cpu'` | Device for Pytorch inference model. GPU is supported using `'cuda'`                                                                                                      |\n\n> Optional parameters when calling `convert`:\n\n| Parameter         | Default | Description                                                                                                                                                              |\n|-------------------|---------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| `process_numbers` | `True`  | Toggles conversion of some numbers and symbols to their spoken pronunciation forms. See [numbers.py](src/Aquila_Resolve/text/numbers.py) for details on what is covered. |\n\n### 2. Command Line\n\nA simple wrapper for text conversion is available through the `aquila-resolve` command\n```\n~\n❯ aquila-resolve\n✔ Aquila Resolve v0.1.4\n? Text to convert: I read the book, did you read it?\n{AY1} {R EH1 D} {DH AH0} {B UH1 K}, {D IH1 D} {Y UW1} {R IY1 D} {IH1 T}?\n```\n\n## Model Architecture\n\nIn evaluation[^1], neural G2P models have traditionally been extremely sensitive to orthographical variations\nin graphemes. Attention-based mapping of contextual recognition has traditionally been poor for languages\nlike English with a low correlative relationship between grapheme and phonemes[^2]. Furthermore, both static\nmethods (i.e. [CMU Dictionary](https://github.com/cmusphinx/cmudict)), and dynamic methods (i.e. \n[G2p-seq2seq](https://github.com/cmusphinx/g2p-seq2seq), \n[Phonetisaurus](https://github.com/AdolfVonKleist/Phonetisaurus), \n[DeepPhonemizer](https://github.com/as-ideas/DeepPhonemizer)) \nincur a loss of sentence context during tokenization for training and inference, and therefore make it impossible \nto accurately resolve words with multiple pronunciations based on grammatical context \n[(Heteronyms)](https://wikipedia.org/wiki/Heteronym_(linguistics)).\n\nThis model attempts to address these issues to optimize inference accuracy and run-time speed. The current architecture\nemploys additional natural language analysis steps, including Part-of-speech (POS) tagging, n-gram segmentation, \nlemmatization searches, and word stem analysis. Some layers are universal for all text, such as POS tagging,\nwhile others are activated when deemed required for the requested word. Layer information is retained with the token\nin vectorized and tensor operations. This allows morphological variations of seen words, such as plurals, possessives,\ncompounds, inflectional stem affixes, and lemma variations to be resolved with near ground-truth level of accuracy.\nThis also improves out-of-vocabulary (OOV) inferencing accuracy, by truncating individual tensor size and\ncharacteristics to be closer to seen data. \n\nThe inferencing layer is built as an autoregressive implementation of the forward\n[DeepPhonemizer](https://github.com/as-ideas/DeepPhonemizer) model, as a 4-layer transformer with 256 hidden units. \nThe [pre-trained checkpoint](https://huggingface.co/ionite/Aquila-Resolve/blob/main/model.pt) for Aquila Resolve \nis trained using the CMU Dict v0.7b corpus, with 126,456 unique words. The validation dataset was split as a \nuniform 5% sample of unique words, sorted by grapheme length. The learning rate was linearly increased during \nthe warmup steps, and step-decreased during fine-tuning.\n\n## Symbol Set\n\n> The 2 letter ARPAbet symbol set is used, with numbered vowel stress markers.\n\n### Vowels\n\n| Phoneme | Example       |     | Phoneme | Example       |     | Phoneme | Example          |     | Phoneme | Example |  \n|---------|---------------|-----|---------|---------------|-----|---------|------------------|-----|---------|---------|\n| AA0     | B***al***m    |     | AW0     | ***Ou***rself |     | EY0     | Mayd***ay***     |     | OY0     |         |\n| AA1     | B***o***t     |     | AW1     | Sh***ou***t   |     | EY1     | M***ay***day     |     | OY1     |         |\n| AA2     | C***o***t     |     | AW2     | ***Ou***tdo   |     | EY2     | airfr***eigh***t |     | OY2     |         |\n| AE0     | B***a***t     |     | AY0     | All***y***    |     | IH0     | Cook***i***ng    |     | UH0     |         |\n| AE1     | F***a***st    |     | AY1     | B***i***as    |     | IH1     | Ex***i***st      |     | UH1     |         |\n| AE2     | Midl***a***nd |     | AY2     | Alib***i***   |     | IH2     | Outf***i***t     |     | UH2     |         |\n| AH0     | Centr***a***l |     | EH0     | ***E***nroll  |     | IY0     | Lad***y***       |     | UW0     |         |\n| AH1     | Ch***u***nk   |     | EH1     | Bl***e***ss   |     | IY1     | B***ea***k       |     | UW1     |         |\n| AH2     | Outc***o***me |     | EH2     | Tel***e***x   |     | IY2     | Turnk***ey***    |     | UW2     |         |\n| AO0     | St***o***ry   |     | ER0     | Chapt***er*** |     | OW0     | Re***o***        |     |         |         |\n| AO1     | Ad***o***re   |     | ER1     | V***er***b    |     | OW1     | S***o***         |     |         |         |\n| AO2     | Bl***o***g    |     | ER2     | Catch***er*** |     | OW2     | Carg***o***      |     |         |         |\n\n\n## License\n\nThe code in this project is released under [Apache License 2.0](LICENSE).\n\n[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Fionite34%2FAquila-Resolve.svg?type=large)](https://app.fossa.com/projects/git%2Bgithub.com%2Fionite34%2FAquila-Resolve?ref=badge_large)\n\n## References\n\n[^1]: [r-G2P: Evaluating and Enhancing Robustness of Grapheme to Phoneme Conversion by Controlled noise introducing \nand Contextual information incorporation](https://arxiv.org/abs/2202.11194)\n\n[^2]: [OTEANN: Estimating the Transparency of Orthographies with an Artificial \nNeural Network](https://arxiv.org/abs/1912.13321)\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/ionite34/Aquila-Resolve",
    "keywords": "",
    "license": "Apache 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "Aquila-Resolve",
    "package_url": "https://pypi.org/project/Aquila-Resolve/",
    "platform": null,
    "project_url": "https://pypi.org/project/Aquila-Resolve/",
    "project_urls": {
      "Homepage": "https://github.com/ionite34/Aquila-Resolve"
    },
    "release_url": "https://pypi.org/project/Aquila-Resolve/0.1.4/",
    "requires_dist": [
      "tqdm (>=4.64.0)",
      "nltk (>=3.2.5)",
      "setuptools (>=57.4.0)",
      "pywordsegment (>=0.2.1)",
      "torch (<1.13,>=1.11)",
      "inflect (>=2.1.0)",
      "requests (>=2.23.0)",
      "numpy (>=1.18.0)",
      "inquirerpy (>=0.3.3)",
      "yaspin (>=2.1.0)",
      "importlib-resources (~=5.7.1) ; python_version < \"3.9\""
    ],
    "requires_python": ">=3.7",
    "summary": "Augmented Neural English G2p converter with Inflectional Orthography.",
    "version": "0.1.4",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 15113082,
  "releases": {
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fc458d4998e5f680f4b0cb4a72129be9ebff653237cfab47c37acd978fed7eb8",
          "md5": "91a6c894859b0c55094617d3291345d4",
          "sha256": "93738a73e7ac954f1f099a842c2cdc899b20116afbe1636b15ce141230b71ca4"
        },
        "downloads": -1,
        "filename": "Aquila_Resolve-0.1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "91a6c894859b0c55094617d3291345d4",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 966168,
        "upload_time": "2022-05-17T03:50:41",
        "upload_time_iso_8601": "2022-05-17T03:50:41.938440Z",
        "url": "https://files.pythonhosted.org/packages/fc/45/8d4998e5f680f4b0cb4a72129be9ebff653237cfab47c37acd978fed7eb8/Aquila_Resolve-0.1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "934ca552873e93e7534118bb54a4be3288e0135b853eafa7dbdaef2225759f14",
          "md5": "860541dbc23ddec5dd7cf0a404c8ea7e",
          "sha256": "d34ab86ca080d7d327d7858ce3e50ade5d245799af063ad4fbab23393c6d0e2d"
        },
        "downloads": -1,
        "filename": "Aquila_Resolve-0.1.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "860541dbc23ddec5dd7cf0a404c8ea7e",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 1002460,
        "upload_time": "2022-05-18T21:33:10",
        "upload_time_iso_8601": "2022-05-18T21:33:10.683199Z",
        "url": "https://files.pythonhosted.org/packages/93/4c/a552873e93e7534118bb54a4be3288e0135b853eafa7dbdaef2225759f14/Aquila_Resolve-0.1.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4ed606104f6d3f50a4a2cea96c7c715d6e1c00bf41dd41424cd8d9bb3cdd65cb",
          "md5": "08882a45708c49921c8b0c76e948d6eb",
          "sha256": "a64185085c16e0e4b151d4324e8b2c525d3319e1335f7226c19263451669e145"
        },
        "downloads": -1,
        "filename": "Aquila_Resolve-0.1.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "08882a45708c49921c8b0c76e948d6eb",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 1003940,
        "upload_time": "2022-05-24T21:28:15",
        "upload_time_iso_8601": "2022-05-24T21:28:15.255498Z",
        "url": "https://files.pythonhosted.org/packages/4e/d6/06104f6d3f50a4a2cea96c7c715d6e1c00bf41dd41424cd8d9bb3cdd65cb/Aquila_Resolve-0.1.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "212d71c39e4092bec2ba80a6efc5cbcd59acc948ce3e3cc81705f1ec4519fdc1",
          "md5": "9453d0f2f9bb6ea26f6892f3341c459f",
          "sha256": "7ebe28b83350afaeef7fc69d6f0a690ccc11461fb904779e49d03418a7358e13"
        },
        "downloads": -1,
        "filename": "Aquila_Resolve-0.1.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "9453d0f2f9bb6ea26f6892f3341c459f",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 1004024,
        "upload_time": "2022-09-16T03:48:57",
        "upload_time_iso_8601": "2022-09-16T03:48:57.275893Z",
        "url": "https://files.pythonhosted.org/packages/21/2d/71c39e4092bec2ba80a6efc5cbcd59acc948ce3e3cc81705f1ec4519fdc1/Aquila_Resolve-0.1.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "212d71c39e4092bec2ba80a6efc5cbcd59acc948ce3e3cc81705f1ec4519fdc1",
        "md5": "9453d0f2f9bb6ea26f6892f3341c459f",
        "sha256": "7ebe28b83350afaeef7fc69d6f0a690ccc11461fb904779e49d03418a7358e13"
      },
      "downloads": -1,
      "filename": "Aquila_Resolve-0.1.4-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "9453d0f2f9bb6ea26f6892f3341c459f",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 1004024,
      "upload_time": "2022-09-16T03:48:57",
      "upload_time_iso_8601": "2022-09-16T03:48:57.275893Z",
      "url": "https://files.pythonhosted.org/packages/21/2d/71c39e4092bec2ba80a6efc5cbcd59acc948ce3e3cc81705f1ec4519fdc1/Aquila_Resolve-0.1.4-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}