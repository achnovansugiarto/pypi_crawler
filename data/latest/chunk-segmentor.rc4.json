{
  "info": {
    "author": "yilei.wang",
    "author_email": "stevewyl@163.com",
    "bugtrack_url": null,
    "classifiers": [
      "Programming Language :: Java",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: Implementation :: CPython",
      "Programming Language :: Python :: Implementation :: PyPy"
    ],
    "description": "# Chunk分词器使用指南\n\n环境依赖：python 3.6 (暂时只支持python3)\n\n## 主要功能\n\n1. 能够输出名词短语\n2. 支持词性输出，名词短语词性为np\n3. 支持名词短语以限定词+中心词的形式输出\n\n>不可分割的名词短语是不存在限定词+中心词的形式的，如“机器学习”，而“经典机器学习算法”可拆解为“经典_机器学习_算法”\n\n## Step 1 安装软件包\n\n推荐新建一个python的虚拟环境（可跳过）\n\n```bash\nconda create --name chunk_seg python=3.6.5\n```\n\n### pip安装\n\n```bash\npip install git+https://www.github.com/keras-team/keras-contrib.git\npip install chunk-segmentor\n```\n\n### 手动安装\n\n```bash\ngit clone https://github.com/stevewyl/chunk_segmentor\ncd chunk_segmentor\npip install -r requirements.txt\npython setup.py install\n```\n\n### 额外安装\n```bash\n# 若你的机器安装有GPU，利用GPU加速预测速度\npip install tensorflow-gpu==1.9.0\n```\n### 安装错误\n1. ImportError: cannot import name 'normalize_data_format'\n```bash\npip install -U keras\n```\n\n## Step 2 如何使用\n\n* 第一次import的时候，会自动下载模型和字典数据  \n* 支持单句和多句文本的输入格式，建议以列表的形式传入分词器\n\n```python\nfrom chunk_segmentor import Chunk_Segmentor\ncutter = Chunk_Segmentor()\ns = '这是一个能够输出名词短语的分词器，欢迎试用！'\nres = [item for item in cutter.cut([s] * 10000)] # 1080ti上耗时12s\n\n# 提供两个版本，accurate为精确版，fast为快速版但召回会降低一些，默认精确版\ncutter = Chunk_Segmentor(mode='accurate')\ncutter = Chunk_Segmentor(mode='fast')\n# 限定词+中心词的形式, 默认开启\ncutter.cut(s, qualifier=False)\n# 是否输出词性， 默认开启\ncutter.cut(s, pos=False)\n\n# 输出格式（词列表，词性列表，chunk集合）\n[\n    (\n        ['这', '是', '一个', '能够', '输出', '名词_短语', '的', '分词器', ',', '欢迎', '试用', '!'],\n        ['rzv', 'vshi', 'mq', 'v', 'vn', 'np', 'ude1', 'np', 'w', 'v', 'v', 'w'],\n        ['分词器', '名词_短语']\n    )\n    ...\n]\n```\n\n## Step 3 后续更新\n\n若存在新的模型和字典数据，会提示你是否需要更新\n\n## To-Do Lists\n\n1. 提升限定词和名词短语的准确性 ---> 新的模型\n2. char模型存在GPU调用内存溢出的问题 ---> 使用cnn提取Nchar信息来代替embedding的方式，缩小模型规模\n3. 自定义字典，支持不同粒度的切分\n4. 多进程模型加载和预测",
    "description_content_type": "",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/stevewyl/chunk_segmentor",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "chunk-segmentor",
    "package_url": "https://pypi.org/project/chunk-segmentor/",
    "platform": "",
    "project_url": "https://pypi.org/project/chunk-segmentor/",
    "project_urls": {
      "Homepage": "https://github.com/stevewyl/chunk_segmentor"
    },
    "release_url": "https://pypi.org/project/chunk-segmentor/1.1.0/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "Segmentor with Noun Pharses",
    "version": "1.1.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 4492131,
  "releases": {
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "64b645e90ba875fffe3b5b4a7456526e220abe5ce0ca4566f7ed7ba1f6176f61",
          "md5": "57163758b305b01a3c7e7cbe737338d3",
          "sha256": "3464ce9116879ae1e78fc85aba64fe06be2575dbeb05b5183a11e14c93c5a7b0"
        },
        "downloads": -1,
        "filename": "chunk_segmentor-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "57163758b305b01a3c7e7cbe737338d3",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 1712897,
        "upload_time": "2018-08-29T12:24:04",
        "upload_time_iso_8601": "2018-08-29T12:24:04.798060Z",
        "url": "https://files.pythonhosted.org/packages/64/b6/45e90ba875fffe3b5b4a7456526e220abe5ce0ca4566f7ed7ba1f6176f61/chunk_segmentor-1.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e411de57602ebec0efa529c82ca7ec3ef1276a15da795fa5348df490178eb579",
          "md5": "1b1d1ec061381a8a8aece8867a498e3a",
          "sha256": "3cfe0cecd19b7c41e884de04a8460592594595d64099987b06b51eb4ce30c549"
        },
        "downloads": -1,
        "filename": "chunk_segmentor-1.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "1b1d1ec061381a8a8aece8867a498e3a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 1713039,
        "upload_time": "2018-11-13T09:26:56",
        "upload_time_iso_8601": "2018-11-13T09:26:56.455850Z",
        "url": "https://files.pythonhosted.org/packages/e4/11/de57602ebec0efa529c82ca7ec3ef1276a15da795fa5348df490178eb579/chunk_segmentor-1.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3d5f2975e7760dcb83bf800e449171bbf6d78badb4d5f87da732b112b179fbcc",
          "md5": "de84849e87ef4d4706fdb23c6fc32f32",
          "sha256": "1d9b12c2b8bdd097430895ca8bd56f2e2ffb4daa085079cd9f9011c8d29e2ad0"
        },
        "downloads": -1,
        "filename": "chunk_segmentor-1.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "de84849e87ef4d4706fdb23c6fc32f32",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 1713027,
        "upload_time": "2018-11-13T11:29:09",
        "upload_time_iso_8601": "2018-11-13T11:29:09.448463Z",
        "url": "https://files.pythonhosted.org/packages/3d/5f/2975e7760dcb83bf800e449171bbf6d78badb4d5f87da732b112b179fbcc/chunk_segmentor-1.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "12fc89a4a78500ccffc03871819492b0eaf1f112f0fdd460f3dfc11f04d56f6d",
          "md5": "785e88b88169438c9326493855e297ee",
          "sha256": "0afe6acd331e441648375d65c83bf517ea01fc938e1a618789a0f61cf3539871"
        },
        "downloads": -1,
        "filename": "chunk_segmentor-1.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "785e88b88169438c9326493855e297ee",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 1713521,
        "upload_time": "2018-11-16T02:36:07",
        "upload_time_iso_8601": "2018-11-16T02:36:07.650930Z",
        "url": "https://files.pythonhosted.org/packages/12/fc/89a4a78500ccffc03871819492b0eaf1f112f0fdd460f3dfc11f04d56f6d/chunk_segmentor-1.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "12fc89a4a78500ccffc03871819492b0eaf1f112f0fdd460f3dfc11f04d56f6d",
        "md5": "785e88b88169438c9326493855e297ee",
        "sha256": "0afe6acd331e441648375d65c83bf517ea01fc938e1a618789a0f61cf3539871"
      },
      "downloads": -1,
      "filename": "chunk_segmentor-1.1.0.tar.gz",
      "has_sig": false,
      "md5_digest": "785e88b88169438c9326493855e297ee",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 1713521,
      "upload_time": "2018-11-16T02:36:07",
      "upload_time_iso_8601": "2018-11-16T02:36:07.650930Z",
      "url": "https://files.pythonhosted.org/packages/12/fc/89a4a78500ccffc03871819492b0eaf1f112f0fdd460f3dfc11f04d56f6d/chunk_segmentor-1.1.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}