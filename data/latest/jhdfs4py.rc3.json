{
  "info": {
    "author": "",
    "author_email": "opensource@verpackungsregister.org",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# JHDFS4PY\nConvenient HDFS access using the Java HDFS client in python.\n\n## Installation\n```sh\npip install jhdfs4py\n```\n\n## Usage\nPlease also see the provided demo notebook at `./docs/demo.ipynb`.\n\nCreate a file `file.txt` with the text content \"Hello World\".\n```python\nfrom pyspark.sql import SparkSession\nfrom jhdfs4py import HdfsFs\n\nspark = SparkSession.builder.appName(\"my-app\").getOrCreate()\nhdfs = HdfsFs.from_spark_session(spark)\n\nhdfs.write_string(\n    path=\"/my/path/file.txt\",\n    data=\"Hello World\",\n)\n```\n\nCreate a file `other_file.blop` with the byte content \"some data\".\n```python\nfrom pyspark.sql import SparkSession\nfrom jhdfs4py import HdfsFs\n\nspark = SparkSession.builder.appName(\"my-app\").getOrCreate()\nhdfs = HdfsFs.from_spark_session(spark)\n\nhdfs.write_bytes(\n    path=\"/my/path/other_file.blop\",\n    data=b\"some data\",\n)\n```\n\n## Contribute\nReport [issues](https://gitlab.com/stiftung-zentrale-stelle-verpackungsregister/jhdfs4py/-/issues), submit [Pull Requests](https://gitlab.com/stiftung-zentrale-stelle-verpackungsregister/jhdfs4py/-/merge_requests), or contact us via mail (opensource@verpackungsregister.org).\n\n## Test Suite\n### Hadoop Windows Setup\nOn Windows, a few extra steps are required, before running the tests:\n1. Clone https://github.com/steveloughran/winutils into a directory of your choice\n2. Define the environment variable `HADOOP_HOME` and set it to `X:\\path\\to\\winutils\\hadoop-3.0.0`\n3. Append `%HADOOP_HOME%\\bin` to the `PATH` environment variable\n\n### General Setup\nThe library comes with an extensive [pytest](https://docs.pytest.org/en/stable/) test suite, that depends on a [PY4J](https://www.py4j.org/) gateway\nrunning locally providing the actual HDFS implementation. The testing gateway is located in the `tests/py4j-test-server` folder and implemented by\nthe `org.zsvr.py4j.test.TestGatewayServer` class. The test suite will try to start the gateway automatically on posix systems unless the `USE_EXTERNAL_GATEWAY_SERVER`\nenvironment variable is set. Use the `SBT_SCRIPT` environment variable, to tell the test suite where your [SBT](https://www.scala-sbt.org/) startup\nscript is located.\n\nTo start the gateway manually (don't forget to set `USE_EXTERNAL_GATEWAY_SERVER=1` in this case), you can either use your favourite IDE, after\nimporting `py4j-test-server` as [SBT](https://www.scala-sbt.org/) project, or you can use [SBT](https://www.scala-sbt.org/) directly from the command\nline by entering `sbt run` after having changed to the `tests/py4j-test-server` directory.\n\nTo finally run the tests, change into the `jhdf4py` base directory (the one containing  this README). Make sure all dependencies are met by typing\n`pip install -r requirements.txt`, and finally launch the test suite by entering `pytest` into the console. All tests are expected to pass.\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://gitlab.com/stiftung-zentrale-stelle-verpackungsregister/jhdfs4py",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "jhdfs4py",
    "package_url": "https://pypi.org/project/jhdfs4py/",
    "platform": null,
    "project_url": "https://pypi.org/project/jhdfs4py/",
    "project_urls": {
      "Homepage": "https://gitlab.com/stiftung-zentrale-stelle-verpackungsregister/jhdfs4py"
    },
    "release_url": "https://pypi.org/project/jhdfs4py/1.4.1/",
    "requires_dist": [
      "pyspark (<3.3,>=2.4)",
      "dataclasses (>=0.7) ; python_version < \"3.7\""
    ],
    "requires_python": ">=3.6",
    "summary": "Convenient HDFS access using the Java HDFS client",
    "version": "1.4.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 13640347,
  "releases": {
    "1.3.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6c6923470173fedbee38c92e990745e5f7c4873c614fc8a5e858349b3a5cf9cb",
          "md5": "7b8d86eba6be814a05f579d847f786da",
          "sha256": "643e48fadef6165a50e569eadaf533afe05080f59b57085e6c01f1aef1064a0f"
        },
        "downloads": -1,
        "filename": "jhdfs4py-1.3.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "7b8d86eba6be814a05f579d847f786da",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 11623,
        "upload_time": "2021-11-02T10:05:06",
        "upload_time_iso_8601": "2021-11-02T10:05:06.814823Z",
        "url": "https://files.pythonhosted.org/packages/6c/69/23470173fedbee38c92e990745e5f7c4873c614fc8a5e858349b3a5cf9cb/jhdfs4py-1.3.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.3.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b88d0d1cfdf2e97eb81de5a222ec937f638148c2e06eb7ee68a57b51e040882a",
          "md5": "06937fe161afb0ae810aa57076475edf",
          "sha256": "4f4d3884b43d44cbc74bcf6c67c5ef52f647e22439a79eae8d5860a43413fd69"
        },
        "downloads": -1,
        "filename": "jhdfs4py-1.3.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "06937fe161afb0ae810aa57076475edf",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 12957,
        "upload_time": "2021-11-17T09:32:24",
        "upload_time_iso_8601": "2021-11-17T09:32:24.794357Z",
        "url": "https://files.pythonhosted.org/packages/b8/8d/0d1cfdf2e97eb81de5a222ec937f638148c2e06eb7ee68a57b51e040882a/jhdfs4py-1.3.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.4.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cdc5b5a8ce025f12a603860f0fb4ebfaec4a49046b9811273fc287af1b0c22e7",
          "md5": "794f07e407f81b3100e35c200170b601",
          "sha256": "28f58d780330e1c6d5226584646a0107691056c2c64c08a6987a7a21df89c41c"
        },
        "downloads": -1,
        "filename": "jhdfs4py-1.4.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "794f07e407f81b3100e35c200170b601",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 12893,
        "upload_time": "2022-04-27T14:42:03",
        "upload_time_iso_8601": "2022-04-27T14:42:03.597645Z",
        "url": "https://files.pythonhosted.org/packages/cd/c5/b5a8ce025f12a603860f0fb4ebfaec4a49046b9811273fc287af1b0c22e7/jhdfs4py-1.4.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "cdc5b5a8ce025f12a603860f0fb4ebfaec4a49046b9811273fc287af1b0c22e7",
        "md5": "794f07e407f81b3100e35c200170b601",
        "sha256": "28f58d780330e1c6d5226584646a0107691056c2c64c08a6987a7a21df89c41c"
      },
      "downloads": -1,
      "filename": "jhdfs4py-1.4.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "794f07e407f81b3100e35c200170b601",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 12893,
      "upload_time": "2022-04-27T14:42:03",
      "upload_time_iso_8601": "2022-04-27T14:42:03.597645Z",
      "url": "https://files.pythonhosted.org/packages/cd/c5/b5a8ce025f12a603860f0fb4ebfaec4a49046b9811273fc287af1b0c22e7/jhdfs4py-1.4.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}