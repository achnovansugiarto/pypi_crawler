{
  "info": {
    "author": "PaddyAlton",
    "author_email": "paddy.alton@apolitical.co",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 2 - Pre-Alpha",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3",
      "Topic :: Scientific/Engineering :: Information Analysis"
    ],
    "description": "cohort-analysis\n===============\n\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/ambv/black)\n\nOutline\n-------\n\nA package for calculating cohort metrics from an activity stream and cohorts data table.\n\nUses [pandas](https://pandas.pydata.org/) DataFrames to hold the two tables and provides a class, `CohortMetrics` to:\n\n- manage the data within these DataFrames\n- filter to analyse different user cohorts\n- calculate a variety of important activity metrics (such as weekly active users, monthly active users)\n- calculate cohort retention metrics\n\nInstallation\n------------\n\nTo install from the command line via [pip](https://pip.pypa.io/en/stable/), do:\n\n`pip install cohort-analysis`\n\nTo upgrade to the latest version via `pip`, do:\n\n`pip install cohort-analysis --upgrade`\n\nTo use via [pipenv](https://docs.pipenv.org/en/latest/) put the following in your Pipfile:\n\n```\n[packages]\ncohort-analysis = \">=0.0.1\"\n```\n\nGetting Started\n---------------\n\nTo start, simply\n\n```python\nimport cohort_analysis\n```\n\nThe principal interface for this library is via `cohort_analysis.metrics` (an instance of `cohort_analysis.cohort_metrics.CohortMetrics`).\n\nWe have used [pandas-flavor](https://pypi.org/project/pandas-flavor/) to add a `.cohorts` accessor to pandas DataFrames; note that the above import statement will apply this to all DataFrames.\n\n### Preparing the interface\n\nYou will need to set up the `clickstream` and `cohorts` tables for this interface. There are two ways:\n\n1. via methods\n  - `cohort_analysis.metrics.set_clickstream(df1)`\n  - `cohort_analysis.metrics.set_cohorts(df2)`\n2. via the DataFrame accessor we set up for convenience\n  - `df1.cohorts.set_as_clickstream(cohort_analysis.metrics)`\n  - `df2.cohorts.set_as_cohorts(cohort_analysis.metrics)`\n\nThe `clickstream` table should have two columns, `user_id` and `timestamp` (other columns will be ignored). Every row should record a 'click' (an event of some kind), indicating the responsible user's ID and the timestamp at which it occurred. If your DataFrame has these columns under different names (`col1`, `col2` in the example below), you can indicate that when setting the `clickstream` as follows:\n\n```python\ncohort_analysis.metrics.set_clickstream(df1, timestamp_col=\"col1\", user_id_col=\"col2\")\n```\n\nThe `cohorts` table has two mandatory columns, `user_id` and `reference_timestamp` and is expected, though not required, to have additional columns that can be used to define user cohorts. If your DataFrame has these columns under different names (`colA`, `colB` in the example below), you can indicate that when setting the `cohorts` as follows:\n\n```python\ncohort_analysis.metrics.set_cohorts(df1, reference_timestamp_col=\"colA\", user_id_col=\"colB\")\n```\n\nThe `user_id` columns in the two tables ought to correspond, i.e. IDs in `clickstream.user_id` should be present in `cohorts.user_id` (any that are not will be ignored).\n\n### Direct interface creation\n\nAlternatively, a new instance of `cohort_analysis.cohort_metrics.CohortMetrics` specifying the tables to use can be created as follows:\n\n```python\nmetrics = cohort_analysis.CohortMetrics(clickstream=df1, cohorts=df2)\n```\n\nThe supplied DataFrames should already have the correct column names as detailed in the previous section.\n\n### Timezone support\n\nThe default behaviour of the interface is to convert/localise all timestamps to UTC.\n\nIf your data is in a different timezone, you should change the `CohortMetrics` instance's timezone as follows:\n\n```python\ncohort_analysis.metrics.change_timezone(\"CET\")\n```\n\nThis should be done **before** setting the clickstream and cohorts table if those contain timezone-naive timestamps that actually belong to a timezone other than UTC.\n\nIf creating the interface directly, pass a `timezone` parameter instead:\n\n```python\nmetrics = cohort_analysis.CohortMetrics(clickstream=df1, cohorts=df2, timezone=\"CET\")\n```\n\n### Changing the current time\n\nAt initialisation, the current time in the chosen timezone is set as a reference point for calculations. Actions in the clickstream at future times and users with reference timestamps in the future will be filtered out.\n\nHowever, the `current_timestamp` property can be changed as follows:\n\n```python\nmetrics.change_current_timestamp(\"now\")\n```\n\nValid inputs are:\n\n- `\"now\"` (change `current_timestamp` property to the current time in the chosen timezone)\n- `\"last\"` (change `current_timestamp` to the latest entry in `clickstream.timestamp` and `cohorts.reference_timestamp`)\n- any `pandas.Timestamp` (will be converted/localised to the instance's timezone)\n- any parseable datetime string (will be set to the instance's timezone)\n\nThis allows the user to view the data as it would have appeared at points in the past, handle batched data that doesn't include the latest information, set up deterministic tests etc.\n\n\n### Inspecting the interface\n\nInstances of `CohortMetrics` have a string representation implemented. If the `clickstream` and `cohorts` tables are both set up, `print(cohort_analysis.metrics)` will display a summary of the two tables derived from the DataFrames' own string representations. This can be used for quick inspection of the data. If one or both tables are not yet set up, the representation will indicate this instead.\n\nBasic Usage\n-----------\n\nOnce the `CohortMetrics` object has been prepared, it can be used to derive a variety of activity and cohort retention metrics from the `clickstream` and `cohorts` tables.\n\nMethods will typically return a pandas DataFrame.\n\n### Filtering by cohort\n\nA copy of the two tables, filtered to remove 'clicks' from users not in the `cohorts` table, or with timestamps before the associated user's `reference_timestamp`, may be returned as follows:\n\n```python\nclickstream, cohorts = cohort_analysis.metrics.filter_by_cohorts()\n```\n\nAdditional filtering may be applied by passing a dictionary to this method. Here are some examples:\n\n1. Filter by a column in the `cohorts` table, selecting activity and user data only for (in this example) users who have the value `\"United Kingdom\"` in the `country` column of the `cohorts` table:\n  ```python\n  cohort_dict = {\"country\": \"United Kingdom\"}\n\n  clickstream, cohorts = cohort_analysis.metrics.filter_by_cohorts(cohort_dict)\n  ```\n2. Filter by a column in the `cohorts` table, selecting activity and user data only for users with one of a number of values in a column (in this example, `\"Brazil\"` **or** `\"Canada\"` in the `country` column of the `cohorts` table):\n  ```python\n  cohort_dict = {\"country\": [\"Brazil\", \"Canada\"]}\n\n  clickstream, cohorts = cohort_analysis.metrics.filter_by_cohorts(cohort_dict)\n  ```\n3. Filter by values in multiple columns of the `cohorts` table, selecting activity and user data only for users who (in this example) have the value `\"India\"` in the `country` column of the `cohorts` table **and** the value `\"Social Media\"` in the `acquisition_channel` column:\n  ```python\n  cohort_dict = {\"country\": \"India\", \"acquisition_channel\": \"Social Media\"}\n\n  clickstream, cohorts = cohort_analysis.metrics.filter_by_cohorts(cohort_dict)\n  ```\n  Lists of values may also be passed, as in the previous example.\n  The logic for combining across columns can be changed - 'AND' logic is used by default, but calling `cohort_analysis.metrics.change_filter_logic(\"OR\")` beforehand will use 'OR' logic instead. 'NOT' logic can also be used to exclude all the values provided via `cohort_dict`.\n\n4. Filter by the `reference_timestamp` column in the `cohorts` table, selecting activity and user data only for users with a reference timestamp during a particular time period (in this example, Q2 2020):\n  ```python\n  cohort_dict = {\"calendar\": \"2020-Q2\"}\n\n  clickstream, cohorts = cohort_analysis.metrics.filter_by_cohorts(cohort_dict)\n  ```\n  This kind of filter can be combined with other filters and may have multiple values passed, just as above. Using the key `\"reference_timestamp\"` instead of `\"calendar\"` will work in the exact same way.\n  Possible time periods include:\n  - years (`\"2020\"`)\n  - quarters (`\"2020-Q1\"`)\n  - months (`\"2020-05\"`)\n  - weeks (`\"2020-W-SUN-5\"` - the fifth week concluding on a Sunday in 2020)\n  - days (`\"2020-05-03\"`)\n\nThis method is used internally by other methods that generate metrics.\n\n### Cohort Activity Metrics\n\nThe `cohort-analysis` library supports two different types of activity metric: activity in calendar intervals and activity in rolling intervals.\n\nThe methods for computing activity in **calendar intervals** are as follows:\n\n- `dau_calendar_day`\n- `wau_calendar_week`\n- `mau_calendar_month`\n- `qau_calendar_quarter`\n- `yau_calendar_year`\n\nThese methods all optionally accept a cohort filter dictionary via the input `cohort=cohort_dict`.\n\nEach of these methods returns a DataFrame with a PeriodIndex covering the full timerange of the `clickstream` table's `timestamp` column and the `cohorts` table's `reference_timestamp` column. It has the following columns:\n\n- `cohort_size`\n- `n_active`\n- `?au` (`dau`, `wau`, `mau`, `qau`, `yau` respectively)\n\nBy default, the cohort size is the number of users with reference timestamps prior to the end of each period in the index. This behaviour can be changed to calculate the number of users with reference timestamps prior to the _start_ of each period in the index by passing `cohort_size_at=\"start\"` to any of the methods.\n\nMethods apart from `dau_calendar_day` and `mau_calendar_month` accept an additional argument, since the other intervals are not uniquely defined (although there are sensible defaults that we implement).\n\n- `wau_calendar_week` accepts the optional argument, `week_commencing`. This accepts any day of the week as a value. The default is `\"Monday\"`.\n- `qau_calendar_quarter` and `yau_calendar_year` both accept the optional argument `year_commencing`. This accepts any month of the year as a value. The default is `\"January\"`.\n\nThe methods for computing activity in **rolling windows** are as follows:\n\n- `rolling_wau`\n- `rolling_mau`\n- `rolling_qau`\n\nThese methods all optionally accept a cohort filter dictionary via the input `cohort=cohort_dict`.\n\nEach of these methods returns a DataFrame with a DateIndex covering the full timerange of the `clickstream` table's `timestamp` column and the `cohorts` table's `reference_timestamp` column. It has the following columns:\n\n- `cohort_size`\n- `n_active`\n- `?au` (`wau`, `mau`, `qau` respectively)\n\nFor each date in the index, these metrics are computed for an N day window whose final day is indicated by the index. For WAU, N=7. For MAU, N=28. For QAU, N=91. The latter two values are chosen due to being multiples of 7 (this eliminates weekly cycles in user activity from the metrics).\n\nBy default, the cohort size is the number of users with reference timestamps prior to the end of each window whose final day is indicated by the index. This behaviour can be changed to calculate the number of users with reference timestamps prior to the _start_ of each window by passing `cohort_size_at=\"start\"` to any of the methods.\n\n### Cohort Retention Rates\n\nA cohort retention rate is the active rate of a user cohort during a specified time-interval since `reference_timestamp`.  The current implementation of `CohortMetrics` has three different type of retentions: _fixed-interval_, _unbounded-interval_ and _wmqy-interval_. The code below shows the usage on a `cohorts` DataFrame with `country` in the column.  \n\n```python\nretention_type = 'unbounded'\nretention_cohorts = [{\"country\": \"Canada\"}, {\"country\": \"Brazil\"}]\ninterval_type = \"week\"\n\nmetrics = cohort_analysis.metrics\nmetrics.cohort_retention(retention_type, retention_cohorts, interval_type)\n# returns a DataFrame indexed by week 0 to latest and columned by given cohorts\n```\n\nHere `retention_cohorts` is a list of cohort filtering dictionaries. This allows the end user to easily compare retention metrics for different cohorts.\n\nDevelopment\n-----------\n\nOnce you've cloned the repository and navigated to it, the best way is to use the `pipenv` virtual environment:\n\n1. Make sure that you have the `pipenv` library: `pip install pipenv --upgrade`.\n2. In the top level directory, `/cohort-analysis`, run `pipenv install --dev` (installs virtual environment with development tools).\n3. Launch `pytest-watch` in the virtual environment using `pipenv run ptw`. Edit code at your leisure; the test suite will run whenever you save your work.\n4. Other quality assurance checks can be run locally:\n    -  use `pipenv run coverage` to run the tests and ensure sufficient test coverage\n    -  use `pipenv run mypy` for static type-checking\n    -  use `pipenv run lint-fix` to format the code\n\nContributors\n------------\n\n- Paddy Alton (paddy.alton@apolitical.co)\n- Charlotte Crabb (charlotte.crabb@apolitical.co)\n- Ashia Ogunlade (ashia.ogunlade@apolitical.co)\n- CY Yang (cy.yang@apolitical.co)\n\n(with thanks to the Apolitical engineering and data teams for assistance and review)\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "https://github.com/apolitical/cohort-analysis/archive/vv0.1.2.tar.gz",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "cohort,activity,retention",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "cohort-analysis",
    "package_url": "https://pypi.org/project/cohort-analysis/",
    "platform": "",
    "project_url": "https://pypi.org/project/cohort-analysis/",
    "project_urls": {
      "Download": "https://github.com/apolitical/cohort-analysis/archive/vv0.1.2.tar.gz"
    },
    "release_url": "https://pypi.org/project/cohort-analysis/0.1.2/",
    "requires_dist": [
      "pandas (<2.0,>=1.0.0)",
      "pandas-flavor (<1.0,>=0.2.0)"
    ],
    "requires_python": "",
    "summary": "A package for calculating cohort metrics from an activity stream and cohorts data table.",
    "version": "0.1.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 10073505,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d7f4f2b1f0d63f7b0a06a11d14762dd676e84a5ed2f66acc0c358ffbd49d19b5",
          "md5": "1402c459f1c323d041751096c4bb5fae",
          "sha256": "3ea97c33e48651de505d756465cc605ca212fac10a771828c47f51535525b8f5"
        },
        "downloads": -1,
        "filename": "cohort_analysis-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "1402c459f1c323d041751096c4bb5fae",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 19838,
        "upload_time": "2020-08-27T11:15:25",
        "upload_time_iso_8601": "2020-08-27T11:15:25.132042Z",
        "url": "https://files.pythonhosted.org/packages/d7/f4/f2b1f0d63f7b0a06a11d14762dd676e84a5ed2f66acc0c358ffbd49d19b5/cohort_analysis-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "442e800d00de2360430863018391c2bc4896cf506c3bfd4da6b3afaf1f28895d",
          "md5": "5f3158bb5332b0678fe0cfdc56ba9200",
          "sha256": "316608391714bb647bac37ede9267b06054150b65dde5728f95760ec7bb2374d"
        },
        "downloads": -1,
        "filename": "cohort-analysis-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "5f3158bb5332b0678fe0cfdc56ba9200",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 18772,
        "upload_time": "2020-08-27T11:15:27",
        "upload_time_iso_8601": "2020-08-27T11:15:27.720257Z",
        "url": "https://files.pythonhosted.org/packages/44/2e/800d00de2360430863018391c2bc4896cf506c3bfd4da6b3afaf1f28895d/cohort-analysis-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8d2c0e9419137138af9505789a0dca7c645505d9b5cea786ce31bb3172870935",
          "md5": "2621b6dc4ea451f64068053495ae1a57",
          "sha256": "fb180303122d12447b90114f575c32742a87d6b261068d3e4e5e9a79030fdad3"
        },
        "downloads": -1,
        "filename": "cohort_analysis-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "2621b6dc4ea451f64068053495ae1a57",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 20628,
        "upload_time": "2020-09-09T13:58:11",
        "upload_time_iso_8601": "2020-09-09T13:58:11.567544Z",
        "url": "https://files.pythonhosted.org/packages/8d/2c/0e9419137138af9505789a0dca7c645505d9b5cea786ce31bb3172870935/cohort_analysis-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "befc337240cf17ba54452c21ca0b2c4fcdfe54eea0a0dfd8656d0d5be0040510",
          "md5": "28b8b831766f85f5f76c037ed1563704",
          "sha256": "fc9d55d2957c0f7d2779a6d9e2f03cbcd02309d73072be3859f91f36f2ead9d5"
        },
        "downloads": -1,
        "filename": "cohort-analysis-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "28b8b831766f85f5f76c037ed1563704",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 20663,
        "upload_time": "2020-09-09T13:58:12",
        "upload_time_iso_8601": "2020-09-09T13:58:12.747664Z",
        "url": "https://files.pythonhosted.org/packages/be/fc/337240cf17ba54452c21ca0b2c4fcdfe54eea0a0dfd8656d0d5be0040510/cohort-analysis-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e59688fb5c1f2052db89e0fb153c830b8d6e730bcdf6b38f24d5e001df7633b9",
          "md5": "bbcfb0ad11462b85e7ba57f00bbea5b8",
          "sha256": "7edf48ba70ca22b5171a2f474a7d05d6db8bebccabd9075f5e8bb240c780865a"
        },
        "downloads": -1,
        "filename": "cohort_analysis-0.1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "bbcfb0ad11462b85e7ba57f00bbea5b8",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 20731,
        "upload_time": "2021-03-29T14:37:14",
        "upload_time_iso_8601": "2021-03-29T14:37:14.652751Z",
        "url": "https://files.pythonhosted.org/packages/e5/96/88fb5c1f2052db89e0fb153c830b8d6e730bcdf6b38f24d5e001df7633b9/cohort_analysis-0.1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "faa87398dcbe22430e5c997b9f6b30e85080cc4e6fe86f0925afeeca64844739",
          "md5": "b0a2a825a64f98f861685b55315a8c93",
          "sha256": "22172cce83ce1d1e061b4cf8b656a6dcc5eed17deec3c7bc686dffc98c729a9a"
        },
        "downloads": -1,
        "filename": "cohort-analysis-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "b0a2a825a64f98f861685b55315a8c93",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 20792,
        "upload_time": "2021-03-29T14:37:15",
        "upload_time_iso_8601": "2021-03-29T14:37:15.509710Z",
        "url": "https://files.pythonhosted.org/packages/fa/a8/7398dcbe22430e5c997b9f6b30e85080cc4e6fe86f0925afeeca64844739/cohort-analysis-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8b5857a67c0bbf733482b984d5cc74cee67f20b2e851e524e67446ca88eb132a",
          "md5": "4f6349a431bf2f60693e4159492d1ee6",
          "sha256": "157a799efa09c29102995865d375237930ab86da2aeeba2f1ea43a036a0475ba"
        },
        "downloads": -1,
        "filename": "cohort_analysis-0.1.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "4f6349a431bf2f60693e4159492d1ee6",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 20742,
        "upload_time": "2021-04-15T12:32:57",
        "upload_time_iso_8601": "2021-04-15T12:32:57.369638Z",
        "url": "https://files.pythonhosted.org/packages/8b/58/57a67c0bbf733482b984d5cc74cee67f20b2e851e524e67446ca88eb132a/cohort_analysis-0.1.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "386eb39400571b7c3cf1efc46828ac2de0804ebf0bc786f8ed21ba7a99efc13c",
          "md5": "47dc9aa8cc5d5e7ad997f585758f0132",
          "sha256": "e19bdbe4f3627e3c8de5a40b53d61df35fc9dc30b86e63463827856f1d78fa3d"
        },
        "downloads": -1,
        "filename": "cohort-analysis-0.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "47dc9aa8cc5d5e7ad997f585758f0132",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 21442,
        "upload_time": "2021-04-15T12:32:58",
        "upload_time_iso_8601": "2021-04-15T12:32:58.446587Z",
        "url": "https://files.pythonhosted.org/packages/38/6e/b39400571b7c3cf1efc46828ac2de0804ebf0bc786f8ed21ba7a99efc13c/cohort-analysis-0.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "8b5857a67c0bbf733482b984d5cc74cee67f20b2e851e524e67446ca88eb132a",
        "md5": "4f6349a431bf2f60693e4159492d1ee6",
        "sha256": "157a799efa09c29102995865d375237930ab86da2aeeba2f1ea43a036a0475ba"
      },
      "downloads": -1,
      "filename": "cohort_analysis-0.1.2-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "4f6349a431bf2f60693e4159492d1ee6",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 20742,
      "upload_time": "2021-04-15T12:32:57",
      "upload_time_iso_8601": "2021-04-15T12:32:57.369638Z",
      "url": "https://files.pythonhosted.org/packages/8b/58/57a67c0bbf733482b984d5cc74cee67f20b2e851e524e67446ca88eb132a/cohort_analysis-0.1.2-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "386eb39400571b7c3cf1efc46828ac2de0804ebf0bc786f8ed21ba7a99efc13c",
        "md5": "47dc9aa8cc5d5e7ad997f585758f0132",
        "sha256": "e19bdbe4f3627e3c8de5a40b53d61df35fc9dc30b86e63463827856f1d78fa3d"
      },
      "downloads": -1,
      "filename": "cohort-analysis-0.1.2.tar.gz",
      "has_sig": false,
      "md5_digest": "47dc9aa8cc5d5e7ad997f585758f0132",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 21442,
      "upload_time": "2021-04-15T12:32:58",
      "upload_time_iso_8601": "2021-04-15T12:32:58.446587Z",
      "url": "https://files.pythonhosted.org/packages/38/6e/b39400571b7c3cf1efc46828ac2de0804ebf0bc786f8ed21ba7a99efc13c/cohort-analysis-0.1.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}