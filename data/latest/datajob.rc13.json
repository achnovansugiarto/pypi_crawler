{
  "info": {
    "author": "Vincent Claes",
    "author_email": "vincent.v.claes@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: Other/Proprietary License",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.11",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9"
    ],
    "description": "[![Awesome](https://awesome.re/badge.svg)](https://github.com/kolomied/awesome-cdk#high-level-frameworks)\n![logo](./assets/logo.png)\n\n<div align=\"center\">\n <b>Build and deploy a serverless data pipeline on AWS with no effort.</b></br>\n <i>Our goal is to let developers think about the business logic, datajob does the rest...</i>\n </br>\n </br>\n </br>\n</div>\n\n </br>\n\n- Deploy code to python shell / pyspark **AWS Glue jobs**.\n- Use **AWS Sagemaker** to create ML Models.\n- Orchestrate the above jobs using **AWS Stepfunctions** as simple as `task1 >> task2`\n- Let us [know](https://github.com/vincentclaes/datajob/discussions) **what you want to see next**.\n\n </br>\n\n<div align=\"center\">\n\n :rocket: :new: :rocket:\n </br>\n</br>\n[Check our new example of an End-to-end Machine Learning Pipeline with Glue, Sagemaker and Stepfunctions](examples/ml_pipeline_end_to_end)\n</br>\n</br>\n:rocket: :new: :rocket:\n\n</br></br>\n\n</div>\n\n </br>\n\n# Installation\n\n Datajob can be installed using pip. <br/>\n Beware that we depend on [aws cdk cli](https://github.com/aws/aws-cdk)!\n\n    pip install datajob\n    npm install -g aws-cdk@1.109.0 # latest version of datajob depends this version\n\n# Quickstart\n\nYou can find the full example in [examples/data_pipeline_simple](./examples/data_pipeline_simple/).\n\nWe have a simple data pipeline composed of [2 glue jobs](./examples/data_pipeline_simple/glue_jobs/) orchestrated sequentially using step functions.\n\n```python\nfrom aws_cdk import core\n\nfrom datajob.datajob_stack import DataJobStack\nfrom datajob.glue.glue_job import GlueJob\nfrom datajob.stepfunctions.stepfunctions_workflow import StepfunctionsWorkflow\n\napp = core.App()\n\n# The datajob_stack is the instance that will result in a cloudformation stack.\n# We inject the datajob_stack object through all the resources that we want to add.\nwith DataJobStack(scope=app, id=\"data-pipeline-simple\") as datajob_stack:\n    # We define 2 glue jobs with the relative path to the source code.\n    task1 = GlueJob(\n        datajob_stack=datajob_stack, name=\"task1\", job_path=\"glue_jobs/task.py\"\n    )\n    task2 = GlueJob(\n        datajob_stack=datajob_stack, name=\"task2\", job_path=\"glue_jobs/task2.py\"\n    )\n\n    # We instantiate a step functions workflow and orchestrate the glue jobs.\n    with StepfunctionsWorkflow(datajob_stack=datajob_stack, name=\"workflow\") as sfn:\n        task1 >> task2\n\napp.synth()\n\n```\n\nWe add the above code in a file called `datajob_stack.py` in the [root of the project](./examples/data_pipeline_with_packaged_project/).\n\n\n### Configure CDK\nFollow the steps [here](https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.html#cli-configure-quickstart-config) to configure your credentials.\n\n```shell script\nexport AWS_PROFILE=default\n# use the aws cli to get your account number\nexport AWS_ACCOUNT=$(aws sts get-caller-identity --query Account --output text --profile $AWS_PROFILE)\nexport AWS_DEFAULT_REGION=eu-west-1\n\n# init cdk\ncdk bootstrap aws://$AWS_ACCOUNT/$AWS_DEFAULT_REGION\n```\n\n### Deploy\n\nDeploy the pipeline using CDK.\n\n```shell\ncd examples/data_pipeline_simple\ncdk deploy --app  \"python datajob_stack.py\" --require-approval never\n```\n\n### Execute\n\n```shell script\ndatajob execute --state-machine data-pipeline-simple-workflow\n```\nThe terminal will show a link to the step functions page to follow up on your pipeline run.\n\n![sfn](./assets/sfn.png)\n\n### Destroy\n\n```shell script\ncdk destroy --app  \"python datajob_stack.py\"\n```\n\n# Examples\n\n- [Data pipeline with parallel steps](./examples/data_pipeline_parallel/)\n- [Data pipeline for processing big data using PySpark](./examples/data_pipeline_pyspark/)\n- [Data pipeline where you package and ship your project as a wheel](./examples/data_pipeline_with_packaged_project/)\n- [Machine Learning pipeline where we combine glue jobs with sagemaker](examples/ml_pipeline_end_to_end)\n\nAll our examples are in [./examples](./examples)\n\n\n# Functionality\n\n<details>\n<summary>Deploy to a stage</summary>\n\nSpecify a stage to deploy an isolated pipeline.\n\nTypical examples would be `dev` , `prod`, ...\n\n```shell\ncdk deploy --app \"python datajob_stack.py\" --context stage=my-stage\n```\n\n</details>\n\n<details>\n\n<summary>Using datajob's S3 data bucket</summary>\n\nDynamically reference the `datajob_stack` data bucket name to the arguments of your GlueJob by calling\n`datajob_stack.context.data_bucket_name`.\n\n```python\nimport pathlib\n\nfrom aws_cdk import core\nfrom datajob.datajob_stack import DataJobStack\nfrom datajob.glue.glue_job import GlueJob\nfrom datajob.stepfunctions.stepfunctions_workflow import StepfunctionsWorkflow\n\ncurrent_dir = str(pathlib.Path(__file__).parent.absolute())\n\napp = core.App()\n\nwith DataJobStack(\n        scope=app, id=\"datajob-python-pyspark\", project_root=current_dir\n) as datajob_stack:\n    pyspark_job = GlueJob(\n        datajob_stack=datajob_stack,\n        name=\"pyspark-job\",\n        job_path=\"glue_job/glue_pyspark_example.py\",\n        job_type=\"glueetl\",\n        glue_version=\"2.0\",  # we only support glue 2.0\n        python_version=\"3\",\n        worker_type=\"Standard\",  # options are Standard / G.1X / G.2X\n        number_of_workers=1,\n        arguments={\n            \"--source\": f\"s3://{datajob_stack.context.data_bucket_name}/raw/iris_dataset.csv\",\n            \"--destination\": f\"s3://{datajob_stack.context.data_bucket_name}/target/pyspark_job/iris_dataset.parquet\",\n        },\n    )\n\n    with StepfunctionsWorkflow(datajob_stack=datajob_stack, name=\"workflow\") as sfn:\n        pyspark_job >> ...\n\n```\n\nyou can find this example [here](./examples/data_pipeline_pyspark/glue_job/glue_pyspark_example.py)\n\n</details>\n\n<details>\n<summary>Deploy files to the datajob's deployment bucket</summary>\n\nSpecify the path to the folder we would like to include in the deployment bucket.\n\n```python\n\nfrom aws_cdk import core\nfrom datajob.datajob_stack import DataJobStack\n\napp = core.App()\n\nwith DataJobStack(\n    scope=app, id=\"some-stack-name\", include_folder=\"path/to/folder/\"\n) as datajob_stack:\n\n    ...\n\n```\n\n</details>\n\n<details>\n<summary>Package your project as a wheel and ship it to AWS</summary>\n\nYou can find the example [here](./examples/data_pipeline_with_packaged_project/)\n\n```python\n# We add the path to the project root in the constructor of DataJobStack.\n# By specifying project_root, datajob will look for a .whl in\n# the dist/ folder in your project_root.\nwith DataJobStack(\n    scope=app, id=\"data-pipeline-pkg\", project_root=current_dir\n) as datajob_stack:\n```\n\nPackage you project using [poetry](https://python-poetry.org/)\n\n```shell\npoetry build\ncdk deploy --app \"python datajob_stack.py\"\n```\n\nPackage you project using [setup.py](./examples/data_pipeline_with_packaged_project)\n\n```shell\npython setup.py bdist_wheel\ncdk deploy --app \"python datajob_stack.py\"\n```\nyou can also use the datajob cli to do the two commands at once:\n```shell\n# for poetry\ndatajob deploy --config datajob_stack.py --package poetry\n\n# for setup.py\ndatajob deploy --config datajob_stack.py --package setuppy\n```\n</details>\n\n<details>\n<summary>Processing big data using a Glue Pyspark job</summary>\n\n```python\nimport pathlib\n\nfrom aws_cdk import core\nfrom datajob.datajob_stack import DataJobStack\nfrom datajob.glue.glue_job import GlueJob\n\ncurrent_dir = str(pathlib.Path(__file__).parent.absolute())\n\napp = core.App()\n\nwith DataJobStack(\n        scope=app, id=\"datajob-python-pyspark\", project_root=current_dir\n) as datajob_stack:\n    pyspark_job = GlueJob(\n        datajob_stack=datajob_stack,\n        name=\"pyspark-job\",\n        job_path=\"glue_job/glue_pyspark_example.py\",\n        job_type=\"glueetl\",\n        glue_version=\"2.0\",  # we only support glue 2.0\n        python_version=\"3\",\n        worker_type=\"Standard\",  # options are Standard / G.1X / G.2X\n        number_of_workers=1,\n        arguments={\n            \"--source\": f\"s3://{datajob_stack.context.data_bucket_name}/raw/iris_dataset.csv\",\n            \"--destination\": f\"s3://{datajob_stack.context.data_bucket_name}/target/pyspark_job/iris_dataset.parquet\",\n        },\n    )\n```\nfull example can be found in [examples/data_pipeline_pyspark](examples/data_pipeline_pyspark]).\n</details>\n\n<details>\n<summary>Orchestrate stepfunctions tasks in parallel</summary>\n\n```python\n# Task2 comes after task1. task4 comes after task3.\n# Task 5 depends on both task2 and task4 to be finished.\n# Therefore task1 and task2 can run in parallel,\n# as well as task3 and task4.\nwith StepfunctionsWorkflow(datajob_stack=datajob_stack, name=\"workflow\") as sfn:\n    task1 >> task2\n    task3 >> task4\n    task2 >> task5\n    task4 >> task5\n\n```\nMore can be found in [examples/data_pipeline_parallel](./examples/data_pipeline_parallel)\n\n</details>\n\n<details>\n<summary>Orchestrate 1 stepfunction task</summary>\n\nUse the [Ellipsis](https://docs.python.org/dev/library/constants.html#Ellipsis) object to be able to orchestrate 1 job via step functions.\n\n```python\nsome_task >> ...\n```\n\n</details>\n\n<details>\n<summary>Notify in case of error/success</summary>\n\nProvide the parameter `notification` in the constructor of a `StepfunctionsWorkflow` object.\nThis will create an SNS Topic which will be triggered in case of failure or success.\nThe email will subscribe to the topic and receive the notification in its inbox.\n\n```python\nwith StepfunctionsWorkflow(datajob_stack=datajob_stack,\n                           name=\"workflow\",\n                           notification=\"email@domain.com\") as sfn:\n    task1 >> task2\n```\n\nYou can provide 1 email or a list of emails `[\"email1@domain.com\", \"email2@domain.com\"]`.\n\n</details>\n\n# Datajob in depth\n\nThe `datajob_stack` is the instance that will result in a cloudformation stack.\nThe path in `project_root` helps `datajob_stack` locate the root of the project where\nthe setup.py/poetry pyproject.toml file can be found, as well as the `dist/` folder with the wheel of your project .\n\n```python\nimport pathlib\nfrom aws_cdk import core\n\nfrom datajob.datajob_stack import DataJobStack\n\ncurrent_dir = pathlib.Path(__file__).parent.absolute()\napp = core.App()\n\nwith DataJobStack(\n    scope=app, id=\"data-pipeline-pkg\", project_root=current_dir\n) as datajob_stack:\n\n    ...\n```\n\nWhen __entering the contextmanager__ of DataJobStack:\n\nA [DataJobContext](./datajob/datajob_stack.py#L48) is initialized\nto deploy and run a data pipeline on AWS.\nThe following resources are created:\n1) \"data bucket\"\n    - an S3 bucket that you can use to dump ingested data, dump intermediate results and the final output.\n    - you can access the data bucket as a [Bucket](https://docs.aws.amazon.com/cdk/api/latest/python/aws_cdk.aws_s3/Bucket.html) object via ```datajob_stack.context.data_bucket```\n    - you can access the data bucket name via ```datajob_stack.context.data_bucket_name```\n2) \"deployment bucket\"\n   - an s3 bucket to deploy code, artifacts, scripts, config, files, ...\n   - you can access the deployment bucket as a [Bucket](https://docs.aws.amazon.com/cdk/api/latest/python/aws_cdk.aws_s3/Bucket.html) object via ```datajob_stack.context.deployment_bucket```\n   - you can access the deployment bucket name via ```datajob_stack.context.deployment_bucket_name```\n\nwhen __exiting the context manager__ all the resources of our DataJobStack object are created.\n\n<details>\n<summary>We can write the above example more explicitly...</summary>\n\n```python\nimport pathlib\nfrom aws_cdk import core\n\nfrom datajob.datajob_stack import DataJobStack\nfrom datajob.glue.glue_job import GlueJob\nfrom datajob.stepfunctions.stepfunctions_workflow import StepfunctionsWorkflow\n\ncurrent_dir = pathlib.Path(__file__).parent.absolute()\n\napp = core.App()\n\ndatajob_stack = DataJobStack(scope=app, id=\"data-pipeline-pkg\", project_root=current_dir)\ndatajob_stack.init_datajob_context()\n\ntask1 = GlueJob(datajob_stack=datajob_stack, name=\"task1\", job_path=\"glue_jobs/task.py\")\ntask2 = GlueJob(datajob_stack=datajob_stack, name=\"task2\", job_path=\"glue_jobs/task2.py\")\n\nwith StepfunctionsWorkflow(datajob_stack=datajob_stack, name=\"workflow\") as step_functions_workflow:\n    task1 >> task2\n\ndatajob_stack.create_resources()\napp.synth()\n```\n</details>\n\n# Ideas\n\nAny suggestions can be shared by starting a [discussion](https://github.com/vincentclaes/datajob/discussions)\n\nThese are the ideas, we find interesting to implement;\n\n- add a time based trigger to the step functions workflow.\n- add an s3 event trigger to the step functions workflow.\n- add a lambda that copies data from one s3 location to another.\n- version your data pipeline.\n- cli command to view the logs / glue jobs / s3 bucket\n- implement sagemaker services\n    - processing jobs\n    - hyperparameter tuning jobs\n    - training jobs\n- implement lambda\n- implement ECS Fargate\n- create a serverless UI that follows up on the different pipelines deployed on possibly different AWS accounts using Datajob\n\n> [Feedback](https://github.com/vincentclaes/datajob/discussions) is much appreciated!\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/vincentclaes/datajob",
    "keywords": "pipelines,machine learning,data pipelines,data science,data engineering",
    "license": "Apache Software License (Apache 2.0)",
    "maintainer": "",
    "maintainer_email": "",
    "name": "datajob",
    "package_url": "https://pypi.org/project/datajob/",
    "platform": null,
    "project_url": "https://pypi.org/project/datajob/",
    "project_urls": {
      "Homepage": "https://github.com/vincentclaes/datajob",
      "Repository": "https://github.com/vincentclaes/datajob"
    },
    "release_url": "https://pypi.org/project/datajob/0.11.0/",
    "requires_dist": [
      "stepfunctions (>=2.1.0,<3.0.0)",
      "contextvars (>=2.4,<3.0)",
      "typer (>=0.3.2,<0.4.0)",
      "aws-cdk.core (>=1.181,<2.0)",
      "aws-cdk.aws-glue (>=1.181,<2.0)",
      "aws-cdk.aws-s3-deployment (>=1.181,<2.0)",
      "aws-cdk.aws-stepfunctions (>=1.181,<2.0)",
      "aws-cdk.aws-sns-subscriptions (>=1.181,<2.0)",
      "rich (>=9.13.0,<10.0.0)",
      "toposort (>=1.6,<2.0)"
    ],
    "requires_python": ">=3.8,<4.0",
    "summary": "Build and deploy a serverless data pipeline with no effort on AWS.",
    "version": "0.11.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 15858276,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fc1addcb25cc84fbe4f19839643830588b924a05bd889af651c1b54d7f59d07e",
          "md5": "6a53dc58f3494b46f03fa6dce39247c6",
          "sha256": "ef6c1b01ad8654444e9b6d8cb159774beaa91b5116b2b2e693d3d3e17b931e8a"
        },
        "downloads": -1,
        "filename": "datajob-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "6a53dc58f3494b46f03fa6dce39247c6",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7,<4.0",
        "size": 14363,
        "upload_time": "2020-12-06T12:23:07",
        "upload_time_iso_8601": "2020-12-06T12:23:07.882355Z",
        "url": "https://files.pythonhosted.org/packages/fc/1a/ddcb25cc84fbe4f19839643830588b924a05bd889af651c1b54d7f59d07e/datajob-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7e936650d20625def29aa12b76e065b2e71372b458ae297385086f5614ccc5f9",
          "md5": "e1fff3eda4f61e8d358c5fc78f91fe65",
          "sha256": "c2467255b65e2be1eb1ce46374efc2b9a0ac0600d9adf35cb1c909fefd6b6555"
        },
        "downloads": -1,
        "filename": "datajob-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "e1fff3eda4f61e8d358c5fc78f91fe65",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7,<4.0",
        "size": 12503,
        "upload_time": "2020-12-06T12:23:09",
        "upload_time_iso_8601": "2020-12-06T12:23:09.270204Z",
        "url": "https://files.pythonhosted.org/packages/7e/93/6650d20625def29aa12b76e065b2e71372b458ae297385086f5614ccc5f9/datajob-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.10.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7dd36b03a0d26b2a63a1f8045c0f98597f5e56784bc289394faac35b0864d6ad",
          "md5": "fd4e849bc1462c8234e98e818942fef3",
          "sha256": "0e821be721081992e742d27881130c5443c0d7561a88ca8eae06277412a495e4"
        },
        "downloads": -1,
        "filename": "datajob-0.10.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "fd4e849bc1462c8234e98e818942fef3",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6.2,<4.0",
        "size": 31488,
        "upload_time": "2021-08-11T14:07:38",
        "upload_time_iso_8601": "2021-08-11T14:07:38.348758Z",
        "url": "https://files.pythonhosted.org/packages/7d/d3/6b03a0d26b2a63a1f8045c0f98597f5e56784bc289394faac35b0864d6ad/datajob-0.10.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d6855bb058e4afc20d14e78de81fce9a00804453f7ef05a06f7d8283e2b8e427",
          "md5": "7cc532a4b8a8019e01d57cbf33f1fdf5",
          "sha256": "e9f08f72cd70d47e1b55a070e6368e4f54b65d6ca000f430a340cd304bbdfa5d"
        },
        "downloads": -1,
        "filename": "datajob-0.10.0.tar.gz",
        "has_sig": false,
        "md5_digest": "7cc532a4b8a8019e01d57cbf33f1fdf5",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6.2,<4.0",
        "size": 44142,
        "upload_time": "2021-08-11T14:07:39",
        "upload_time_iso_8601": "2021-08-11T14:07:39.975153Z",
        "url": "https://files.pythonhosted.org/packages/d6/85/5bb058e4afc20d14e78de81fce9a00804453f7ef05a06f7d8283e2b8e427/datajob-0.10.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.10.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4fa90471a7aa9e5db1a836896b142dd512341c5b146765856f2764471bde8bae",
          "md5": "559e5476424533f732c98cafb414ebc4",
          "sha256": "319b4a96f84cf930aaf5990804cba9c4614a8bc27ba50b11f0524882c3d98dcd"
        },
        "downloads": -1,
        "filename": "datajob-0.10.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "559e5476424533f732c98cafb414ebc4",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6.2,<4.0",
        "size": 30155,
        "upload_time": "2021-08-13T11:25:15",
        "upload_time_iso_8601": "2021-08-13T11:25:15.066776Z",
        "url": "https://files.pythonhosted.org/packages/4f/a9/0471a7aa9e5db1a836896b142dd512341c5b146765856f2764471bde8bae/datajob-0.10.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3c3c033e4aaf0bf6bf1340d1ae45393616deef5bc4c598f9d57fe5c3cd8df790",
          "md5": "177f8465d9705049ebc5c647e0b6eb9e",
          "sha256": "eebd920f3951eecffa82595cad7144021456ed76f09844f4e5ae17267020a8dc"
        },
        "downloads": -1,
        "filename": "datajob-0.10.1.tar.gz",
        "has_sig": false,
        "md5_digest": "177f8465d9705049ebc5c647e0b6eb9e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6.2,<4.0",
        "size": 28951,
        "upload_time": "2021-08-13T11:25:16",
        "upload_time_iso_8601": "2021-08-13T11:25:16.947032Z",
        "url": "https://files.pythonhosted.org/packages/3c/3c/033e4aaf0bf6bf1340d1ae45393616deef5bc4c598f9d57fe5c3cd8df790/datajob-0.10.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.11.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3250014fb5cbaa5ee587b2c0cf50b41c04ba87ee61ff22b1efb58303169c25dd",
          "md5": "116ee067190dc72d63aae5dc2717c59b",
          "sha256": "c4b8e37ae91d643ba6a10ce180b34aaec7ffab570e604ef43288ea2e927cb04e"
        },
        "downloads": -1,
        "filename": "datajob-0.11.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "116ee067190dc72d63aae5dc2717c59b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8,<4.0",
        "size": 30232,
        "upload_time": "2022-11-22T19:09:59",
        "upload_time_iso_8601": "2022-11-22T19:09:59.785577Z",
        "url": "https://files.pythonhosted.org/packages/32/50/014fb5cbaa5ee587b2c0cf50b41c04ba87ee61ff22b1efb58303169c25dd/datajob-0.11.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4994839324af5a348b6b49bb1221e9b6af9749c0eec6843618526ec847338791",
          "md5": "3a2e1d5dbdcf3a2b5c35f7f805b60255",
          "sha256": "329df96e476cdb537ee26b0617a9412f518444b765b9c3f576fc1c6e753f61f7"
        },
        "downloads": -1,
        "filename": "datajob-0.11.0.tar.gz",
        "has_sig": false,
        "md5_digest": "3a2e1d5dbdcf3a2b5c35f7f805b60255",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8,<4.0",
        "size": 28958,
        "upload_time": "2022-11-22T19:10:01",
        "upload_time_iso_8601": "2022-11-22T19:10:01.655248Z",
        "url": "https://files.pythonhosted.org/packages/49/94/839324af5a348b6b49bb1221e9b6af9749c0eec6843618526ec847338791/datajob-0.11.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "153bae73eb31050cfb64f8f4dec37f80535be415aa7a848c2954f910ed108013",
          "md5": "99760700fb2f99e4ff676309b33d3576",
          "sha256": "d2e94539c9cbb4e538d93fd98ece2418fa685fbbbe3ea21705852a90b76e4150"
        },
        "downloads": -1,
        "filename": "datajob-0.2.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "99760700fb2f99e4ff676309b33d3576",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7,<4.0",
        "size": 16141,
        "upload_time": "2020-12-06T12:32:05",
        "upload_time_iso_8601": "2020-12-06T12:32:05.059244Z",
        "url": "https://files.pythonhosted.org/packages/15/3b/ae73eb31050cfb64f8f4dec37f80535be415aa7a848c2954f910ed108013/datajob-0.2.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6f7e827e83fdb58c9b2163e24129babc4b7e518256924975c7020d0db56135a5",
          "md5": "dd3111fab429875d471b52ba859e1417",
          "sha256": "f129f9f367f0e2db21585bb7acf37f03891389adb405804188d9dcfe94c7c785"
        },
        "downloads": -1,
        "filename": "datajob-0.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "dd3111fab429875d471b52ba859e1417",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7,<4.0",
        "size": 18635,
        "upload_time": "2020-12-06T12:32:06",
        "upload_time_iso_8601": "2020-12-06T12:32:06.258061Z",
        "url": "https://files.pythonhosted.org/packages/6f/7e/827e83fdb58c9b2163e24129babc4b7e518256924975c7020d0db56135a5/datajob-0.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "798fbead56ab9a8c23add9f7dbeed416edfc0f3eb9d3060a1849b2a9247a9306",
          "md5": "387e079e5196efd432e6414c78b9b1c2",
          "sha256": "f6cc9220712d6a049a1eac01e5043b9002064e90022b590ad9fe04f7e871ca0f"
        },
        "downloads": -1,
        "filename": "datajob-0.3.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "387e079e5196efd432e6414c78b9b1c2",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7,<4.0",
        "size": 16927,
        "upload_time": "2020-12-13T13:11:43",
        "upload_time_iso_8601": "2020-12-13T13:11:43.762431Z",
        "url": "https://files.pythonhosted.org/packages/79/8f/bead56ab9a8c23add9f7dbeed416edfc0f3eb9d3060a1849b2a9247a9306/datajob-0.3.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c0f6d5eff99eb03f5edb7e7583bf81416e54e3380111f595af11563a0a294a1d",
          "md5": "7b21fc7ad5edeb22d4f63f09dc4e4a71",
          "sha256": "9f10d32a559517b3e91da5f385739a0583f745dd47a62e628f83c64ccaa7627a"
        },
        "downloads": -1,
        "filename": "datajob-0.3.0.tar.gz",
        "has_sig": false,
        "md5_digest": "7b21fc7ad5edeb22d4f63f09dc4e4a71",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7,<4.0",
        "size": 15095,
        "upload_time": "2020-12-13T13:11:45",
        "upload_time_iso_8601": "2020-12-13T13:11:45.202817Z",
        "url": "https://files.pythonhosted.org/packages/c0/f6/d5eff99eb03f5edb7e7583bf81416e54e3380111f595af11563a0a294a1d/datajob-0.3.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "923224d5fbf2276d59e3f3f9088031f9812e37f10a2253faad66da01e2b1d89d",
          "md5": "d32f3803adf8d65400129d11754da622",
          "sha256": "f9afd614796a92d8f6743ff35b9715505cfc40669e080f6bbde917a0f082401f"
        },
        "downloads": -1,
        "filename": "datajob-0.4.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d32f3803adf8d65400129d11754da622",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6.1,<4.0.0",
        "size": 18639,
        "upload_time": "2021-01-07T14:56:23",
        "upload_time_iso_8601": "2021-01-07T14:56:23.391482Z",
        "url": "https://files.pythonhosted.org/packages/92/32/24d5fbf2276d59e3f3f9088031f9812e37f10a2253faad66da01e2b1d89d/datajob-0.4.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8f43dbe02d64fb3a5be02049b623f0e9816319a1b9b512df89244dbda26fcf80",
          "md5": "067385268d945041c35358ec5106bb2d",
          "sha256": "7a5f6d20eb060c84a360357bad93c298cc39689e0ce5f3da95445079d8db4d8d"
        },
        "downloads": -1,
        "filename": "datajob-0.4.0.tar.gz",
        "has_sig": false,
        "md5_digest": "067385268d945041c35358ec5106bb2d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6.1,<4.0.0",
        "size": 17414,
        "upload_time": "2021-01-07T14:56:24",
        "upload_time_iso_8601": "2021-01-07T14:56:24.939113Z",
        "url": "https://files.pythonhosted.org/packages/8f/43/dbe02d64fb3a5be02049b623f0e9816319a1b9b512df89244dbda26fcf80/datajob-0.4.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.5.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3b298ab0e7b1aa6c65d4371ddbe73f2d22c90eb8bc1ef14377ffb93d82de8173",
          "md5": "772b1bd38b0c1f5eb0fe01116863c17d",
          "sha256": "1fe9b9bbc4ed8ec54862f6be5b338256c7e29ebcfc6a9a32cf9b56de852423d8"
        },
        "downloads": -1,
        "filename": "datajob-0.5.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "772b1bd38b0c1f5eb0fe01116863c17d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6.1,<4.0.0",
        "size": 18738,
        "upload_time": "2021-01-29T16:01:58",
        "upload_time_iso_8601": "2021-01-29T16:01:58.119261Z",
        "url": "https://files.pythonhosted.org/packages/3b/29/8ab0e7b1aa6c65d4371ddbe73f2d22c90eb8bc1ef14377ffb93d82de8173/datajob-0.5.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "60a5dc7cdb3e3b0595970be8f18017241bb71c937e8a7ccf9c659d6d966b310a",
          "md5": "63d778f33a1a7b21122b1211ee5b645d",
          "sha256": "e05d507fa125af6ed00cf85511abe874007b9a545d26f76dab90a096703e40a5"
        },
        "downloads": -1,
        "filename": "datajob-0.5.0.tar.gz",
        "has_sig": false,
        "md5_digest": "63d778f33a1a7b21122b1211ee5b645d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6.1,<4.0.0",
        "size": 17329,
        "upload_time": "2021-01-29T16:01:59",
        "upload_time_iso_8601": "2021-01-29T16:01:59.365112Z",
        "url": "https://files.pythonhosted.org/packages/60/a5/dc7cdb3e3b0595970be8f18017241bb71c937e8a7ccf9c659d6d966b310a/datajob-0.5.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.6.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "71f0522ecbcc63edec773761386e30f32069342657d86e5e614ae4df599c1be1",
          "md5": "fcd25b9714b431c1f015afc854977604",
          "sha256": "dadabbc5577564ed85e93d17abd6ddafa938e68c52e894af8459b65e3dd4ad8c"
        },
        "downloads": -1,
        "filename": "datajob-0.6.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "fcd25b9714b431c1f015afc854977604",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6.1,<4.0.0",
        "size": 19191,
        "upload_time": "2021-02-20T12:58:17",
        "upload_time_iso_8601": "2021-02-20T12:58:17.839224Z",
        "url": "https://files.pythonhosted.org/packages/71/f0/522ecbcc63edec773761386e30f32069342657d86e5e614ae4df599c1be1/datajob-0.6.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "08b43e63c6251196b8438682e8ceb2d671df062fa5e72bb095e270621ef977ce",
          "md5": "3fdf1afa0fe12e3b28dd82f1bd56190c",
          "sha256": "a703c18cf342fc044fb6b0ad5cd352af72b95c34f6701dc3d9f156a41f56be86"
        },
        "downloads": -1,
        "filename": "datajob-0.6.0.tar.gz",
        "has_sig": false,
        "md5_digest": "3fdf1afa0fe12e3b28dd82f1bd56190c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6.1,<4.0.0",
        "size": 17687,
        "upload_time": "2021-02-20T12:58:19",
        "upload_time_iso_8601": "2021-02-20T12:58:19.160748Z",
        "url": "https://files.pythonhosted.org/packages/08/b4/3e63c6251196b8438682e8ceb2d671df062fa5e72bb095e270621ef977ce/datajob-0.6.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.6.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0ce924a7289da3c27eccabae9d3fbe8740aa307a1f80ad288d593d52e26739e8",
          "md5": "828c5c2aec744f9d82a62f3800fd56b6",
          "sha256": "faabffe978ee1785618ef76c2878357b3ce8f5f1c89033fe226d908546c4cd8a"
        },
        "downloads": -1,
        "filename": "datajob-0.6.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "828c5c2aec744f9d82a62f3800fd56b6",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6.1,<4.0.0",
        "size": 20577,
        "upload_time": "2021-02-25T09:41:17",
        "upload_time_iso_8601": "2021-02-25T09:41:17.688277Z",
        "url": "https://files.pythonhosted.org/packages/0c/e9/24a7289da3c27eccabae9d3fbe8740aa307a1f80ad288d593d52e26739e8/datajob-0.6.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "68929dbddcf320b72bc64a030ccda80bbdf960e0eee417e4dee5f82e2214d883",
          "md5": "d83233efab94322fd79a4762339a9fc8",
          "sha256": "792d456c4f6235e16def1185ce637af3ee55c8f9255166849c1547dc7717fe8a"
        },
        "downloads": -1,
        "filename": "datajob-0.6.1.tar.gz",
        "has_sig": false,
        "md5_digest": "d83233efab94322fd79a4762339a9fc8",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6.1,<4.0.0",
        "size": 26684,
        "upload_time": "2021-02-25T09:41:19",
        "upload_time_iso_8601": "2021-02-25T09:41:19.365753Z",
        "url": "https://files.pythonhosted.org/packages/68/92/9dbddcf320b72bc64a030ccda80bbdf960e0eee417e4dee5f82e2214d883/datajob-0.6.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.7.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3e30508751ae361705fb45716612a893be95c88c4a5782bc82ff25d8a2f729a4",
          "md5": "78c229a2a19828810b387c3b5827da24",
          "sha256": "dcc60afc8a3c03e8d7b19612be7ab355ba229128f498de778312a7d09ad09859"
        },
        "downloads": -1,
        "filename": "datajob-0.7.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "78c229a2a19828810b387c3b5827da24",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6.1,<4.0.0",
        "size": 22140,
        "upload_time": "2021-04-04T13:22:56",
        "upload_time_iso_8601": "2021-04-04T13:22:56.961092Z",
        "url": "https://files.pythonhosted.org/packages/3e/30/508751ae361705fb45716612a893be95c88c4a5782bc82ff25d8a2f729a4/datajob-0.7.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d4d6c283d50218efc6908d17df78eebbb671815d37ce39191a333db9ad392bf2",
          "md5": "b781b254264b7da736cee84d35aeb0ff",
          "sha256": "7d2798489e6f190e7c05a4686c14fa3ee28e8adfe71c9b3da07b2850dbb2d50f"
        },
        "downloads": -1,
        "filename": "datajob-0.7.0.tar.gz",
        "has_sig": false,
        "md5_digest": "b781b254264b7da736cee84d35aeb0ff",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6.1,<4.0.0",
        "size": 21684,
        "upload_time": "2021-04-04T13:22:58",
        "upload_time_iso_8601": "2021-04-04T13:22:58.512600Z",
        "url": "https://files.pythonhosted.org/packages/d4/d6/c283d50218efc6908d17df78eebbb671815d37ce39191a333db9ad392bf2/datajob-0.7.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.8.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5c715b2c0291ed2f90b390c03bfac7c1316462758e358cb0b64da0ca83a2d9ce",
          "md5": "768670cbdb17b20a8715c6b65e777738",
          "sha256": "8d642faee8bfe6686bcbd404e0bb8ae6a0ada7e599d5345621c9f2da76a0ef46"
        },
        "downloads": -1,
        "filename": "datajob-0.8.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "768670cbdb17b20a8715c6b65e777738",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6.2,<4.0.0",
        "size": 24464,
        "upload_time": "2021-06-21T08:05:21",
        "upload_time_iso_8601": "2021-06-21T08:05:21.625751Z",
        "url": "https://files.pythonhosted.org/packages/5c/71/5b2c0291ed2f90b390c03bfac7c1316462758e358cb0b64da0ca83a2d9ce/datajob-0.8.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1dbf10e5a13c9afd5d395ddf5ccd6e7d9a6a6199189e3dfd61f1750cf41ff2fc",
          "md5": "6907a31eb63c139434c59e883b3f1d7f",
          "sha256": "eb0db699ff1c2486721db2624be7637ab746e0867ea3f3ace17c5d7c8cd8a0d0"
        },
        "downloads": -1,
        "filename": "datajob-0.8.0.tar.gz",
        "has_sig": false,
        "md5_digest": "6907a31eb63c139434c59e883b3f1d7f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6.2,<4.0.0",
        "size": 23869,
        "upload_time": "2021-06-21T08:05:23",
        "upload_time_iso_8601": "2021-06-21T08:05:23.744969Z",
        "url": "https://files.pythonhosted.org/packages/1d/bf/10e5a13c9afd5d395ddf5ccd6e7d9a6a6199189e3dfd61f1750cf41ff2fc/datajob-0.8.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.9.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a6c967c0011b1c67827ddeddd184e3201ad89b40f64783ad074648e7ae4af4e9",
          "md5": "73daa050d698db2081f79eda5b944239",
          "sha256": "221f543ca1afe3868c7b2d4686f33e1567617c83790a42d3948eb9b02f5c3b01"
        },
        "downloads": -1,
        "filename": "datajob-0.9.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "73daa050d698db2081f79eda5b944239",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6.1,<4.0",
        "size": 25735,
        "upload_time": "2021-06-23T06:12:17",
        "upload_time_iso_8601": "2021-06-23T06:12:17.575666Z",
        "url": "https://files.pythonhosted.org/packages/a6/c9/67c0011b1c67827ddeddd184e3201ad89b40f64783ad074648e7ae4af4e9/datajob-0.9.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b36c83b48aab07831aba464bc2ba727d25ec177d5e1ba679c95e2b553af06754",
          "md5": "a2bfd6dfd731a00a198e21f81dba7797",
          "sha256": "1fc0da9fe7628324272db835ee4d77d139675769e211a194213dc11cd23e1a05"
        },
        "downloads": -1,
        "filename": "datajob-0.9.0.tar.gz",
        "has_sig": false,
        "md5_digest": "a2bfd6dfd731a00a198e21f81dba7797",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6.1,<4.0",
        "size": 36495,
        "upload_time": "2021-06-23T06:12:19",
        "upload_time_iso_8601": "2021-06-23T06:12:19.901214Z",
        "url": "https://files.pythonhosted.org/packages/b3/6c/83b48aab07831aba464bc2ba727d25ec177d5e1ba679c95e2b553af06754/datajob-0.9.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "3250014fb5cbaa5ee587b2c0cf50b41c04ba87ee61ff22b1efb58303169c25dd",
        "md5": "116ee067190dc72d63aae5dc2717c59b",
        "sha256": "c4b8e37ae91d643ba6a10ce180b34aaec7ffab570e604ef43288ea2e927cb04e"
      },
      "downloads": -1,
      "filename": "datajob-0.11.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "116ee067190dc72d63aae5dc2717c59b",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.8,<4.0",
      "size": 30232,
      "upload_time": "2022-11-22T19:09:59",
      "upload_time_iso_8601": "2022-11-22T19:09:59.785577Z",
      "url": "https://files.pythonhosted.org/packages/32/50/014fb5cbaa5ee587b2c0cf50b41c04ba87ee61ff22b1efb58303169c25dd/datajob-0.11.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "4994839324af5a348b6b49bb1221e9b6af9749c0eec6843618526ec847338791",
        "md5": "3a2e1d5dbdcf3a2b5c35f7f805b60255",
        "sha256": "329df96e476cdb537ee26b0617a9412f518444b765b9c3f576fc1c6e753f61f7"
      },
      "downloads": -1,
      "filename": "datajob-0.11.0.tar.gz",
      "has_sig": false,
      "md5_digest": "3a2e1d5dbdcf3a2b5c35f7f805b60255",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.8,<4.0",
      "size": 28958,
      "upload_time": "2022-11-22T19:10:01",
      "upload_time_iso_8601": "2022-11-22T19:10:01.655248Z",
      "url": "https://files.pythonhosted.org/packages/49/94/839324af5a348b6b49bb1221e9b6af9749c0eec6843618526ec847338791/datajob-0.11.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}