{
  "info": {
    "author": "Yang Deng, Juncheng Dong, Simiao Ren",
    "author_email": "yang.deng@duke.edu",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Benchmarking AEM problems with various DL structures \n[![PyPi Version 0.0.2](https://img.shields.io/badge/pypi-0.0.2-brightgreen)](https://badge.fury.io/py/pypi)\n[![GitHub license](https://img.shields.io/github/license/Naereen/StrapDown.js.svg)](https://github.com/Naereen/StrapDown.js/blob/master/LICENSE)\n\n\nThis repository stores implemention of paper [Benchmarking Data-driven Surrogate Simulators for Artificial Electromagnetic Materials]() \n\nIt includes a suit of AEM data set benchmarks along with implementation of various ready-to-use deep learning architectures (MLP, Transformer, MLP-Mixer) for scientific computation problem and a handful of utility functions.\n\n## Data Sets\n![geometry_illustration](./images/geometry_illustration.png)\nSchematics of geometry in three physical problems. (a) Infinite array of all-dielectric metasurfaces consists of four elliptical-resonators supercells. (b) A nanophotonic particle consists of four layers. (c) The three-layers color filter design.\n\n## Requirements\n| Package | Version |\n|:---------------------------------------------:|:------------------------------------------------------------------:|\n| Python | \\>=3.7 |\n| Pytorch | \\>= 1.3.1 |\n| Numpy  | \\>=1.17.4 |\n| Pandas | \\>=0.25.3 |\n| Tensorboard | \\>=2.0.0 |\n| Tqdm| \\>=4.42.0 |\n| Sklearn | \\>=0.22.1|\n| Matplotlib | \\>= 3.1.3|\n| einops | \\>= 0.3.0|\n| seaborn | \\>= 0.11.2|\n### Environment\n1. The detailed conda environment is packaged in [.yml file](./demo/environment_droplet.yml).\n2. Add the [Benchmarking folder](./Benchmarking%20Algorithms) as one of the source directory to make utils and Simulated_Dataset folders \nvisible runtime\n\n## Features \n* Access to various ADM data sets \n* **Off-the-shelf implementation** of MLP, Transformer and MLP-Mixer with high individuality\n* Utilities for **data preprocessing and preparation** for downstream deep learning tasks\n* Utilities for **plotting** and easy analysis of results\n\n\n## Usage\n\n### Access to Data Sets\n1. ADM Data Set. Please download and unzip from the [Repository](https://doi.org/10.7924/r4jm2bv29).\n2. Particle Data Set. Please download and unzip from the [Repository](https://doi.org/10.7924/r4jm2bv29).\n3. Color Data Set. Please download and unzip from the [Repository](http://dx.doi.org/10.5258/SOTON/D1686).\n\n### Download Pre-trained Models \n1. MLP: Please download and unzip from the [folder](https://drive.google.com/drive/folders/1Br13vFIqvh-5Kpl7AeHH8CkTbkF2Bufa?usp=sharing).\n2. Transformer: Please download and unzip from the [folder](https://drive.google.com/drive/folders/1Br13vFIqvh-5Kpl7AeHH8CkTbkF2Bufa?usp=sharing).\n3. MLP-Mixer: Please download and unzip from the [folder](https://drive.google.com/drive/folders/1Br13vFIqvh-5Kpl7AeHH8CkTbkF2Bufa?usp=sharing).\n\n### Install Package\n```\npip install AEML\n```\n\n### Loading data and Splitting\n#### Loading benchmark datasets described in Section 4.1 of the paper\n\nADM refers to the All-dielectric metasurface dataset. Particle dataset refers to the Nanophotonic Particle dataset. The Color dataset refers to the Color filter dataset. The specification of each dataset is provided in the table below:\n\n| Dataset                    | D_in | D_out | Sub_area          | Simulations | Simulation CPU time  |\n|----------------------------|------|-------|-------------------|-------------|-----------|\n|  All-dielectric metasurfac | 14   | 2001  | Metamaterials     | 60,000      | 7 months  |\n| Nanophotonic particle      | 8    | 201   | Nanophotonics     | 50,000      | 1.5 hours |\n| Color                      | 3    | 3     | Optical waveguide | 100,000     | -         |\n\n\n#### Loading your own benchmark dataset into the framework\nAlthough we used AEM dataset for benchmarking, this suite is open and easily adaptable to a wide range of applications in the scientific computing community. To test your own custom dataset, simply normalize (or not, your choice, our loader would not normalize your dataset) and put your dataset into the Custom folder with the format: data_x.csv, data_y.csv where each file contains the input and output of the application. The shape should be [#Simulations, Dim_x] and [#Simulations, Dim_y] and separated by comma. Note that there should not be any header in the csv.\n\n```\nimport AEML\nfrom AEML.data import ADM, Particle, Color, load_custom_dataset\n\n# Load our pre-defined dataset\ntrain_loader, test_loader, test_x, test_y =ADM/Particle/Color(normalize=True/False, batch_size=1024)    # Loading the ADM dataset\n\n# Or, load prepare your own dataset here\n# train_loader, test_loader, test_x, test_y = load_custom_dataset()\n```\n\n\n### Loading Models with configurable hyper-paramters and making prediction\n\n#### Architectures of various DL structures implementd\n<p align=\"center\">\n  <img src=\"./images/Arch.png\" width=50% height=50% >\n</p>\n\nAs dscribed in section 5 in the paper, the architectures are modified slightly from the original Mixer and Transformer models to fit our scientific computing background. \n\n#### Model hyper-parameter adjustment\n\n```\nfrom AEML.models.Mixer import DukeMIXER\nfrom AEML.models.MLP import DukeMLP\nfrom AEML.models.Transformer import DukeTransformer\n\n# 1. Defining all the models here (We highly recommend training the models one by one due to GPU RAM constraints\n#MLP:\nmodel = DukeMLP(dim_g=3, dim_s=3, linear=[500, 500, 500, 500, 500, 500], skip_connection=False, skip_head=0, dropout=0, model_name=None)\n\n#Transformer:\nmodel= DukeTransformer(dim_g, dim_s, feature_channel_num=32, nhead_encoder=8, \n                        dim_fc_encoder=64, num_encoder_layer=6, head_linear=None, \n                        tail_linear=None, sequence_length=8, model_name=None, \n                        ckpt_dir=os.path.join(os.path.abspath(''), 'models','Transformer'))\n#Mixer:\nmodel = DukeMIXER(dim_g, dim_s, mlp_dim=500, patch_size=10, mixer_layer_num=6,\n                embed_dim=128, token_dim=128, channel_dim=256, \n                mlp_layer_num_front=3, mlp_layer_num_back=3)\n\n# 2. Model training code\n\n#MLP:\nmodel.train_(train_loader, test_loader, epochs=500, optm='Adam', weight_decay=1e-4,\n            lr=1e-4, lr_scheduler_name='reduce_plateau', lr_decay_rate=0.2, eval_step=10,\n            stop_threshold=1e-7)\n\n#Transformer:\nmodel.train_(train_loader, test_loader, epochs=500, optm='Adam', reg_scale=5e-4, lr=1e-3, \n                        lr_schedueler_name='reduce_plateau',lr_decay_rate=0.3, eval_step=10)\n\n#Mixer:\nmodel.train_(train_loader, test_loader, epochs=500, optm='Adam', weight_decay=1e-4,\n            lr=1e-4, lr_scheduler_name='reduce_plateau', lr_decay_rate=0.2, eval_step=10,\n            stop_threshold=1e-7)\n\n# Loading the model you just trained or hypersweeped or our provided pretrained model if \n# you don't want to train it or just want to reproduce our result, only choose one between these 2\nmodel.load_model(pre_trained_model='Particle'\\'AMD'\\'Color'\\None, \n                model_directory='YOUR_MODEL_DIRECOTRY')\n\n# Model inference code: Give it X, output Y\npred_Y = model(test_X)\n\n# Model evaluation code: Give it test_X, test_Y, output MSE and generate a plot of MSE histogram in \\data\nMSE = model.evaluate(test_x, test_y, save_output=False, save_dir='data/')\n\n```\n\n\n### Performance of various DL structures on benchmark ADM data sets\n<p align=\"center\">\n<img src=\"./images/Main_perf_plot.png\" width=70% height=50%>\n</p>\n\n### Relative size of our pre-trained networks\n<p align=\"center\">\n<img src=\"./images/relative_size_vertical.png\" width=30% height=50%>\n</p>\n\n\n## Support\n\nPlease file an issue [here](https://github.com/ydeng-MLM/ML_MM_Benchmark/issues).\n\n## License\n\nThe project is licensed under the [MIT license](https://github.com/ydeng-MLM/ML_MM_Benchmark/blob/main/LICENSE).\n\nPlease cite this work if some of the code or datasets are helpful in your scientific endeavours. For specific datasets, please also cite the respective original source(s), given in the preprint.\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/ydeng-MLM/ML_MM_Benchmark",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "AEML",
    "package_url": "https://pypi.org/project/AEML/",
    "platform": "",
    "project_url": "https://pypi.org/project/AEML/",
    "project_urls": {
      "Homepage": "https://github.com/ydeng-MLM/ML_MM_Benchmark"
    },
    "release_url": "https://pypi.org/project/AEML/0.0.1/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "Package for benchmarking deep learning models on AEM problems",
    "version": "0.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 11418448,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "595f84cac6a7ebac6eb5183069d0bd6bfb008a2956971fbbeeaaeadde88837d7",
          "md5": "e9f970b8eb6e1f893d788eeea81153d3",
          "sha256": "0dea8e3463d18c5db7d452b0e3190d2a85a3110e3f1438743096d0587e65f3ee"
        },
        "downloads": -1,
        "filename": "AEML-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "e9f970b8eb6e1f893d788eeea81153d3",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 78055,
        "upload_time": "2021-09-10T17:51:09",
        "upload_time_iso_8601": "2021-09-10T17:51:09.397992Z",
        "url": "https://files.pythonhosted.org/packages/59/5f/84cac6a7ebac6eb5183069d0bd6bfb008a2956971fbbeeaaeadde88837d7/AEML-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c6848f9f6c4b571b578fc403516bef491c03cdbd56f813cbf9153369c656578d",
          "md5": "e6f7994d9aaa7900ad93023cb2fbf121",
          "sha256": "6ec9e4273819bee8375d15a41a70b654df12362d4e7f6270a5b94aaef18a3d1b"
        },
        "downloads": -1,
        "filename": "AEML-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "e6f7994d9aaa7900ad93023cb2fbf121",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 64971,
        "upload_time": "2021-09-10T17:51:10",
        "upload_time_iso_8601": "2021-09-10T17:51:10.798570Z",
        "url": "https://files.pythonhosted.org/packages/c6/84/8f9f6c4b571b578fc403516bef491c03cdbd56f813cbf9153369c656578d/AEML-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "595f84cac6a7ebac6eb5183069d0bd6bfb008a2956971fbbeeaaeadde88837d7",
        "md5": "e9f970b8eb6e1f893d788eeea81153d3",
        "sha256": "0dea8e3463d18c5db7d452b0e3190d2a85a3110e3f1438743096d0587e65f3ee"
      },
      "downloads": -1,
      "filename": "AEML-0.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "e9f970b8eb6e1f893d788eeea81153d3",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 78055,
      "upload_time": "2021-09-10T17:51:09",
      "upload_time_iso_8601": "2021-09-10T17:51:09.397992Z",
      "url": "https://files.pythonhosted.org/packages/59/5f/84cac6a7ebac6eb5183069d0bd6bfb008a2956971fbbeeaaeadde88837d7/AEML-0.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "c6848f9f6c4b571b578fc403516bef491c03cdbd56f813cbf9153369c656578d",
        "md5": "e6f7994d9aaa7900ad93023cb2fbf121",
        "sha256": "6ec9e4273819bee8375d15a41a70b654df12362d4e7f6270a5b94aaef18a3d1b"
      },
      "downloads": -1,
      "filename": "AEML-0.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "e6f7994d9aaa7900ad93023cb2fbf121",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 64971,
      "upload_time": "2021-09-10T17:51:10",
      "upload_time_iso_8601": "2021-09-10T17:51:10.798570Z",
      "url": "https://files.pythonhosted.org/packages/c6/84/8f9f6c4b571b578fc403516bef491c03cdbd56f813cbf9153369c656578d/AEML-0.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}