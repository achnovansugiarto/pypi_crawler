{
  "info": {
    "author": "feng",
    "author_email": "709642236@qq.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python"
    ],
    "description": "# fspider\n\n#### 介绍\n\nfspider是一款基于python原生协程asyncio的异步网络爬虫框架，仿照scrapy\n\n#### 要求\n\npython>=3.7\n\n#### 安装\n\n1.```pip install fspider```\n\n2.或者[点击下载](https://gitee.com/imflg) 然后执行```python setup.py install```\n\n#### 教程\n\n##### 创建项目\n\nfspdier startproject 命令有两个参数-项目名称和项目路径\n```fspdier startproject testspider .``` 在当前目录创建testspider项目\n\n```\ncd testspider\npython main.py\n```\n\n执行默认的测试用例\n\n#### command\n\n在命令行窗口使用fspider -h 查看支持的命令及参数\n\n- fspdier startproject -h\n- fspdier shell -h\n\n#### 上下文变量\n\n```\nfrom fspider import context\ncontext.spider.get()\n```\n\n目前支持spider对象的获取，这样就不必将spider一直作为参数来传递。\n<span style=\"color:red\">注意:必须在spider初始化之后，即无法在spider init 里面调用</span>\n\n#### signals\n\n- spdier_opened\n- spider_closed\n\n使用方法:\nspider 默认绑定了这两个signal 你可以覆盖这两个方法\n\n```python\nasync def spider_opened(self):\n    self.logger.info('spider_opened!!!!!!!!!!!')\n\n\nasync def spider_closed(self):\n    self.logger.info('spider_closed ')\n    pass\n```\n\n在其他地方使用(sender参数默认使用```context.spider.get()```)\n\n```python\nfrom fspider import signals\n\n\nasync def spider_opened():\n    pass\n\n\nsignals.connect(receiver=spider_opened, signal=signals.spider_opened)\n```\n\n#### spider middreware\n\nspider middreware 是用来处理spider结果的组件 一个简单的spider middreware 如下所示：\n\n```python\nfrom fspider.http.response import Response\nfrom fspider.spidermiddlewares import SpiderMiddleware\nfrom fspider.utils.type import SpiderRequest\n\n\nclass TestSpiderMiddleware(SpiderMiddleware):\n    async def process_start_requests(self, result: SpiderRequest) -> SpiderRequest:\n        async for r in result:\n            print('process_start_requests', r)\n            yield r\n\n    async def process_spider_output(self, response: Response, result: SpiderRequest) -> SpiderRequest:\n        async for i in result:\n            print('process_spider_output', i)\n            yield i\n```\n\n之后你需要在setting中配置启用：\n\n```python\nSPIDER_MIDDLEWARES = {\n    'test.middlewares.TestSpiderMiddleware': 543,\n}\n```\n\n#### downloader middreware\n\ndownloader middreware 是用来处理request请求，最终得到response的一系列组件， 一个简单的downloader middreware 如下所示\n\n```python\nfrom typing import Union\nfrom fspider.downloadermiddlewares import DownloaderMiddleware\nfrom fspider.http.request import Request\nfrom fspider.http.response import Response\n\n\nclass TestDownloaderMiddleware(DownloaderMiddleware):\n    async def process_request(self, request: Request) -> Union[Request, Response, None]:\n        print('process_request', request)\n        return None\n\n    async def process_response(self, request: Request, response: Response) -> Union[Request, Response]:\n        print('process_response', response)\n        return response\n\n```\n\n之后你需要在setting中配置启用：\n\n```python\nDOWNLOADER_MIDDLEWARES = {\n    'test.middlewares.TestDownloaderMiddleware': 543,\n}\n```\n\n> DOWNLOADER_MIDDLEWARES 会先顺序执行各个middlewares的process_request方法，之后倒叙执行process_response\n\n#### 内置 downloader middreware\n\n##### RobotsTxtMiddleware\n\n##### DownloadTimeoutMiddleware\n\n##### DefaultHeadersMiddleware\n\n```python\nDEFAULT_REQUEST_HEADERS = {\n    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n    'Accept-Language': 'zh-CN,zh-HK;q=0.9,zh;q=0.8,en;q=0.7,la;q=0.6,ja;q=0.5',\n    'accept-encoding': 'gzip, deflate, br',\n}\n```\n\n##### HttpCompressionMiddleware\n\naiohttp 会根据response 自动解压数据，所以不需要实现该中间件 （默认DEFAULT_REQUEST_HEADERS 'accept-encoding': 'gzip, deflate,\nbr'，接受压缩数据，不需要的话可以删除accept-encoding）\n\n##### UserAgentMiddleware\n\n##### CookiesMiddleware\n\n##### DefaultDownloaderMiddleware\n\n#### Item Pipeline\n\n当spider 抓取了item,将会移交到 item pipeline ,按照顺序执行相应的组件 一个自定义的pipeline 如下所示：\n\n```python\nimport logging\nimport typing\nfrom fspider.pipelines import Pipeline\nfrom fspider.utils.type import Item\n\n\nclass FspidertestPipeline(Pipeline):\n    async def process_item(self, item: Item) -> typing.Optional[Item]:\n        logging.info(item)\n        return item\n```\n\n- 你必须实现process_item方法\n    - 每个pipeline都会执行此方法来处理\n    - ```return item``` 将会继续执行后续pipeline ，```return None```将会停止执行后续pipiline\n\n- 然后需要在setting 配置启用：\n\n```python\nITEM_PIPELINES = {\n    'fspidertest.pipelines.FspidertestPipeline': 300,\n}\n```\n\n##### MediaPipeline\n\n这是一个用来并发处理image、video等文件的pipeline，并提供了并发控制、大小限制、下载时间估算、超时等功能 默认配置参数\n\n- meida_key：#item[meida_key] 是将要下载的url列表 默认值：media_urls\n- CONN_LIMIT：最大并发 默认值：5\n- LIMIT_PER_HOST：单个域名最大并发 默认值：2\n- file_dir：保存目录 默认当前目录\n- size_limit: 最大文件限制 默认：1024 * 1024 * 1024 # 1GB\n- time_limit：最大时长 默认：10 * 60 # 10分钟\n\nitem_completed 方法：\n> params  :\n>> ```results: typing.Union[str, Exception]```  返回文件保存路径或者exception <br>\n> > item\n\n> return ```item``` or ```None```\n\nexample:\n \n```python\n\nimport logging\nimport typing\nfrom fspider.pipelines.files import MediaPipeline\nfrom fspider.utils.type import Item\n\n\nclass FspidertestPipeline(MediaPipeline):\n    meida_key = 'images'\n    LIMIT_PER_HOST = 2\n\n    # async def process_item(self, item: Item) -> typing.Optional[Item]:\n    #     item = await super().process_item(item)\n    #     logging.info(item)\n    #     return item\n\n    async def item_completed(self, results: typing.Union[str, Exception], item: Item) -> Item:\n        item['media_path'] = [r for r in results if not isinstance(r, Exception)]\n        return item\n```",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/flagang/fspider",
    "keywords": "async spider",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "fspider",
    "package_url": "https://pypi.org/project/fspider/",
    "platform": "",
    "project_url": "https://pypi.org/project/fspider/",
    "project_urls": {
      "Homepage": "https://github.com/flagang/fspider"
    },
    "release_url": "https://pypi.org/project/fspider/1.1.0/",
    "requires_dist": null,
    "requires_python": ">=3.7",
    "summary": "基于asyncio异步爬虫网络框架，仿scrapy",
    "version": "1.1.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12824500,
  "releases": {
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3960dc2c9e22511b69cf81e652c216515a29637eca999b64b24a503b273a0284",
          "md5": "4802b3211b0cbd4ae1e76231863b636c",
          "sha256": "a7c81ab8a811a088ef1938e09e5205f7abce889f4c7940a6c6c4a295767ce122"
        },
        "downloads": -1,
        "filename": "fspider-1.0.0-py3.8.egg",
        "has_sig": false,
        "md5_digest": "4802b3211b0cbd4ae1e76231863b636c",
        "packagetype": "bdist_egg",
        "python_version": "1.0.0",
        "requires_python": ">=3.7",
        "size": 88183,
        "upload_time": "2022-02-08T07:30:48",
        "upload_time_iso_8601": "2022-02-08T07:30:48.895915Z",
        "url": "https://files.pythonhosted.org/packages/39/60/dc2c9e22511b69cf81e652c216515a29637eca999b64b24a503b273a0284/fspider-1.0.0-py3.8.egg",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0fbb1133739ea86e1e44e215f5fa06061e37ccccc3413d76dda5aa2170de7afd",
          "md5": "f5d99f689873458fed603b7fc7d0b3d9",
          "sha256": "d3b4b37ca71a1b409d3ee018925f74874e2092258b87fa6259a512f0f009dfdf"
        },
        "downloads": -1,
        "filename": "fspider-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "f5d99f689873458fed603b7fc7d0b3d9",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 25831,
        "upload_time": "2021-08-16T11:59:16",
        "upload_time_iso_8601": "2021-08-16T11:59:16.384226Z",
        "url": "https://files.pythonhosted.org/packages/0f/bb/1133739ea86e1e44e215f5fa06061e37ccccc3413d76dda5aa2170de7afd/fspider-1.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5bedc7c65a64c304e97f14d4ca933e408768840fca65cfad21bd8832ea3ec3c4",
          "md5": "0bdb976e5db61d2dd05d1cef339955cc",
          "sha256": "d9360256802d3f161141008771d18edb44b351487d417c4177ef90a91aac8cfe"
        },
        "downloads": -1,
        "filename": "fspider-1.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "0bdb976e5db61d2dd05d1cef339955cc",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 29435,
        "upload_time": "2022-02-08T10:51:43",
        "upload_time_iso_8601": "2022-02-08T10:51:43.512923Z",
        "url": "https://files.pythonhosted.org/packages/5b/ed/c7c65a64c304e97f14d4ca933e408768840fca65cfad21bd8832ea3ec3c4/fspider-1.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "5bedc7c65a64c304e97f14d4ca933e408768840fca65cfad21bd8832ea3ec3c4",
        "md5": "0bdb976e5db61d2dd05d1cef339955cc",
        "sha256": "d9360256802d3f161141008771d18edb44b351487d417c4177ef90a91aac8cfe"
      },
      "downloads": -1,
      "filename": "fspider-1.1.0.tar.gz",
      "has_sig": false,
      "md5_digest": "0bdb976e5db61d2dd05d1cef339955cc",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 29435,
      "upload_time": "2022-02-08T10:51:43",
      "upload_time_iso_8601": "2022-02-08T10:51:43.512923Z",
      "url": "https://files.pythonhosted.org/packages/5b/ed/c7c65a64c304e97f14d4ca933e408768840fca65cfad21bd8832ea3ec3c4/fspider-1.1.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}