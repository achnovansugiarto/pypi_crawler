{
  "info": {
    "author": "Lucas Koensgen",
    "author_email": "l.koensgen@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Information Technology",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: GNU General Public License v3 (GPLv3)",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3.9",
      "Topic :: Internet",
      "Topic :: Scientific/Engineering :: Information Analysis",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "# pcs_scraper\n**v0.1.0**\nA python package to query, organize and prepare pandas dataframes from procyclingstats.com data to facilitate further analysis\n\n## Project Description\n\nThis project was undertaken as a side project while working as a data/race analyst with professional cycling teams. While commonplace for many other major sports, I couldn't find any available packages that provided access to professional cycling datasets. There were, however, already fantastic websites devoted to cataloguing this data and presenting it for free. The most user-friendly website I found was procyclingstats.com (PCS) but they didn't have a publicly available api, so I decided to make this package to interact with their posted data programmatically. \n\n_pcs_scraper_ lets users interact with PCS through three fundamental and distinct classes:\n1. Riders\n2. Teams\n3. Races\n\nIn the next versions of this project I would like to link the statistical data from PCS with rider Strava data.\n\n## Installation\n\n###### Via pip:\npip install pcs-scraper\n\n###### Via conda:\nComing soon\n\n###### Via source code:\nFork/clone this repo and create a conda environment to develop in using:\n```\n# create environment using existing environment file\nconda env create -f environment.yml\n\n# add pcs_scraper to path for environment\ncd .../anaconda3/envs/pcs_env/lib/python3.9/site-packages\nnano packages.pth \n# then in nano type **full path** to main pcs_scraper directory (ie. .../Users/name/Desktop/pcs_scraper)\n# press control+O to save file, press control+X to exit nano\n```\n\n## Usage\n###### Basic\n```\n# for specific rider\n\n# import \nimport pcs_scraper as pcs\n\n# request rider object for tadej pogacar\npogacar = pcs.Rider(name = 'tadej-pogacar')\n\n# get pogacar's entire race history \npogacar_race_hx = pogacar.get_race_history()\n```\n```\n# for specific race\n\n# import\nimport pcs_scraper as pcs\n\n# request race object for tour de france\ntdf = pcs.Race(name = 'tour-de-france', year = 2021)\n\n\t# if unsure about spelling of race name according to PCS you can search using:\n\t# race_options = pcs.race_options_by_year(2021)\n\t# can refine output using race circuit or classification when requesting\n\t# race_options = pcs.race_options_by_year(2021, classification = '2.UWT', circuit = 'UCI World Tour')\n\n# request the GC results\ntdf_final_gc = tdf.get_results()\n```\n```\n# for specific team\n\n# import\nimport pcs_scraper as pcs\n\n# request team object for Ineos \nineos = pcs.Team(name = 'ineos-grenadiers', year = 2021)\n\n\t# if unsure about spelling of team name according to PCS you can search using:\n\t# team_options_2021 = pcs.teams_by_year(year = 2021, gender = 'M')\n\n# get the riders from the team\nineos_2021_riders = ineos.get_riders()\n```\n\n###### Practical Examples\nComing soon\n\n## Documentation\nComing soon\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/lucaskoensgen/pcs_scraper",
    "keywords": "cycling,web-scraping,statistics,procyclingstats,peloton",
    "license": "GPLv3",
    "maintainer": "",
    "maintainer_email": "",
    "name": "pcs-scraper",
    "package_url": "https://pypi.org/project/pcs-scraper/",
    "platform": null,
    "project_url": "https://pypi.org/project/pcs-scraper/",
    "project_urls": {
      "Homepage": "https://github.com/lucaskoensgen/pcs_scraper"
    },
    "release_url": "https://pypi.org/project/pcs-scraper/0.2.0/",
    "requires_dist": [
      "requests (>=2.27.1)",
      "beautifulsoup4 (>=4.10.0)",
      "pandas (>=1.4.1)"
    ],
    "requires_python": ">=3.9",
    "summary": "A python-based api to access procyclingstats data",
    "version": "0.2.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17385436,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cc601d16f9b93761293e765654820174a6c956ed24d6ee17ecac0f05c7170909",
          "md5": "89d9e3782e9211ac12f0aa246e54b9c4",
          "sha256": "8fcac866fcb63946a72adffa4cfcb1e3ba2945ee9c55eade624cd583b1860832"
        },
        "downloads": -1,
        "filename": "pcs_scraper-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "89d9e3782e9211ac12f0aa246e54b9c4",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.9",
        "size": 36698,
        "upload_time": "2022-05-20T18:57:48",
        "upload_time_iso_8601": "2022-05-20T18:57:48.855707Z",
        "url": "https://files.pythonhosted.org/packages/cc/60/1d16f9b93761293e765654820174a6c956ed24d6ee17ecac0f05c7170909/pcs_scraper-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3c6ec198666c2d5602125d4de5202cd27be1e88e5f6ef6881d85432e1c789424",
          "md5": "2dab18ebefe286aeebf3a11b7782c13c",
          "sha256": "5dc5c088bdb6e322ccccc86542c3c94b579d551f9a6dd1549418874d7430c25c"
        },
        "downloads": -1,
        "filename": "pcs-scraper-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "2dab18ebefe286aeebf3a11b7782c13c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.9",
        "size": 34943,
        "upload_time": "2022-05-20T18:57:50",
        "upload_time_iso_8601": "2022-05-20T18:57:50.598540Z",
        "url": "https://files.pythonhosted.org/packages/3c/6e/c198666c2d5602125d4de5202cd27be1e88e5f6ef6881d85432e1c789424/pcs-scraper-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e91fea59c1c5838cd1711a306220a433f7674382aa232d93887c1dabdacefec9",
          "md5": "da59eb6e46d2ba960b653cedd18ceaf1",
          "sha256": "7c0a57636657dd51541dfbca5f027fae2dbe7470c848ea5b7eea35a2963f9ae5"
        },
        "downloads": -1,
        "filename": "pcs_scraper-0.2.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "da59eb6e46d2ba960b653cedd18ceaf1",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.9",
        "size": 36916,
        "upload_time": "2023-03-21T19:34:06",
        "upload_time_iso_8601": "2023-03-21T19:34:06.433882Z",
        "url": "https://files.pythonhosted.org/packages/e9/1f/ea59c1c5838cd1711a306220a433f7674382aa232d93887c1dabdacefec9/pcs_scraper-0.2.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2ae5a82e5deb44162702be2c22a572078afd1aeae2973396828208d03c00892a",
          "md5": "ddace77554553ad9753342aabb73355a",
          "sha256": "b160c2e89a2b07394fb5381b669e199a125fd682159fa3128615a6d98f736fd4"
        },
        "downloads": -1,
        "filename": "pcs-scraper-0.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "ddace77554553ad9753342aabb73355a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.9",
        "size": 35106,
        "upload_time": "2023-03-21T19:34:08",
        "upload_time_iso_8601": "2023-03-21T19:34:08.138598Z",
        "url": "https://files.pythonhosted.org/packages/2a/e5/a82e5deb44162702be2c22a572078afd1aeae2973396828208d03c00892a/pcs-scraper-0.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "e91fea59c1c5838cd1711a306220a433f7674382aa232d93887c1dabdacefec9",
        "md5": "da59eb6e46d2ba960b653cedd18ceaf1",
        "sha256": "7c0a57636657dd51541dfbca5f027fae2dbe7470c848ea5b7eea35a2963f9ae5"
      },
      "downloads": -1,
      "filename": "pcs_scraper-0.2.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "da59eb6e46d2ba960b653cedd18ceaf1",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.9",
      "size": 36916,
      "upload_time": "2023-03-21T19:34:06",
      "upload_time_iso_8601": "2023-03-21T19:34:06.433882Z",
      "url": "https://files.pythonhosted.org/packages/e9/1f/ea59c1c5838cd1711a306220a433f7674382aa232d93887c1dabdacefec9/pcs_scraper-0.2.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "2ae5a82e5deb44162702be2c22a572078afd1aeae2973396828208d03c00892a",
        "md5": "ddace77554553ad9753342aabb73355a",
        "sha256": "b160c2e89a2b07394fb5381b669e199a125fd682159fa3128615a6d98f736fd4"
      },
      "downloads": -1,
      "filename": "pcs-scraper-0.2.0.tar.gz",
      "has_sig": false,
      "md5_digest": "ddace77554553ad9753342aabb73355a",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.9",
      "size": 35106,
      "upload_time": "2023-03-21T19:34:08",
      "upload_time_iso_8601": "2023-03-21T19:34:08.138598Z",
      "url": "https://files.pythonhosted.org/packages/2a/e5/a82e5deb44162702be2c22a572078afd1aeae2973396828208d03c00892a/pcs-scraper-0.2.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}