{
  "info": {
    "author": "",
    "author_email": "Clement Perroud <clement.perroud.pro@gmail.com>",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Crypto-Trading-Env\r\n\r\nAn OpenAI Gym environment for simulating stocks and train Reinforcement Learning trading agents.\r\n\r\nDesigned to be **FAST** and **CUSTOMIZABLE** for an easy RL trading algorythms implementation.\r\n## Install and import\r\n```pip install gym-trading-env```|\r\n\r\nThen import :\r\n\r\n```python\r\nfrom gym_trading_env import TradingEnv\r\n```\r\n\r\n## Environment Properties\r\n\r\n### Actions space : positions\r\n\r\nGithub is full of environments that consider actions such as **BUY**, **SELL**. In my opinion, it is a real mistake to think a RL-agent as a trader. Traders make trade and to do so, they place orders on the market (eg. Buy X of stock Y). But what really matter is the position reached. For example, a trader that sell half of his stocks Y, wants to reduce his risk, but also his potential gains. Now, imagine we labelled each position by a number going with:\r\n- ```1``` : We have bought as much as possible of stock Y (LONG); ideally, we have all of our stock's portfolio converted in the stock Y\r\n- ```0``` : We have sold as much as possible of stock Y (OUT); ideally, we have all of our stock's portfolio converted in our currency\r\nNow, we can imagine half position or others :\r\n- ```0.5``` : 50% in stock Y & 50% in currency\r\n- ```0.1``` : 10% in stock Y & 90% in currency\r\n\r\nIn fact, it is way simpler for a RL-agent to work with positions. This way, it can easily make complex operation with a simple action space.\r\nPlus, this environment supports more complex positions such as:\r\n- ```-1``` : once every stock Y is sold, we bet 100% of the portfolio value on the decline of asset Y. To perform this action, the environment borrows 100% of the portfolio valuation as stock Y to an imaginary person, and immediately sell it. When the agent closes the position (position 0), the environment buys the owed amount of stock Y and repays the imaginary person with it. If the price has fallen during the operation, we buy cheaper than we sold what we need to repay : the difference is our gain. The imaginary person is paid a small rent (parameter : ```borrow_interest_rate```)\r\n- ```+2``` : buy as much stock as possible, then we bet 100% of the portfolio value of the rise of asset Y. We use the same mechanism explained above, but we borrow currency and buy stock Y.\r\n- ```-10``` ? : We can BUT ...  We need to borrow 1000% of the portfolio valuation as asset Y. You need to understand that such a \"leverage\" is very risky. As if the stock price rise by 10%, you need to repay the original 1000% of your portfolio valuation at 1100% (1000%*1.10) portfolio valuation. Well, 100% (1100% - 1000%) of your portfolio is used to repay your debt. **GAME OVER, you have 0$ left**. The leverage is very useful but also risky, as it increases your **gains** AND your **losses**. Always keep in mind that you can lose everything.\r\n\r\n### How to use ?\r\n\r\n**1 - Import and clean your data**. They need to be ordered by ascending date. Index must be a date.\r\n```python\r\ndf = pd.read_csv(\"data/BTC_USD-Hourly.csv\", parse_dates=[\"date\"], index_col= \"date\")\r\ndf.sort_index(inplace= True)\r\ndf.dropna(inplace= True)\r\ndf.drop_duplicates(inplace=True)s\r\n```\r\n**2 - Create your feature**. Your RL-agent will need some good, preprocessed features. It is your job to make sure it has everything it needs.\r\n**The feature column names need to contain the keyword 'feature'. The environment will automatically detect them !**\r\n\r\n```python\r\ndf[\"feature_close\"] = df[\"close\"].pct_change()\r\ndf[\"feature_open\"] = df[\"open\"]/df[\"close\"]\r\ndf[\"feature_high\"] = df[\"high\"]/df[\"close\"]\r\ndf[\"feature_low\"] = df[\"low\"]/df[\"close\"]\r\ndf[\"feature_volume\"] = df[\"Volume USD\"] / df[\"Volume USD\"].rolling(7*24).max()\r\ndf.dropna(inplace= True) # Clean your data !\r\n```\r\n**(Optional)3 - Create your own reward function**. Use the history object described below to create your own !\r\n```python\r\nimport numpy as np\r\ndef reward_function(history):\r\n    return np.log(history[-1][\"portfolio_valuation\"] / history[-2][\"portfolio_valuation\"]) #log (p_t / p_t-1 )\r\n\r\n>>> output : history[t] # data history at step t\r\n{\r\n    \"step\": ...,# Step = t\r\n    \"date\": ...,# Date at step t\r\n    \"reward\": ..., # Reward at step t\r\n    \"position_index\": ..., # Index of the position at step t amoung your position argument\r\n    \"position\" : ..., # Portfolio position at step t\r\n    \"df_info\": { # Gather every data at step t from your DataFrame's columns, that are not features\r\n        \"none_feature_columns1\":...,\r\n        \"none_feature_columns2\":...,\r\n        \"none_feature_columns3\":..., \r\n        .... # For example : open, high, low, close,\r\n    },\r\n    \"portfolio_valuation\": ..., # Valuation of the portfolio at step t\r\n    \"portfolio_distribution\":{\r\n            \"asset\" : ...,\r\n            \"fiat\" : ...,\r\n            \"borrowed_asset\": ...,\r\n            \"borrowed_fiat\": ...,\r\n            \"interest_asset\": ...,\r\n            \"interest_fiat\": ...,\r\n    }\r\n}\r\n```\r\n\r\n**4 - Create the environment**\r\n```python\r\nenv = TradingEnv(\r\n    df = df,\r\n    windows= 5, # Windows, default : None. If None, observation at t are the features at step t. If windows = i (int),  observation at t are the features from steps [t-i+1 :  t]\r\n    positions = [-1, -0.5, 0, 0.5, 1], # Positions, default : [0, 1], that the agent can choose (Explained in \"Actions space : positions\")\r\n    initial_position = 0, #Initial position, default = 0\r\n    trading_fees = 0.01/100, # Trading fee, default : 0. Here, 0.01% per stock buy / sell)\r\n    borrow_interest_rate= 0.0003/100, # Borrow interest rate PER STEP, default : 0. Here we pay 0.0003% per HOUR per asset borrowed\r\n    reward_function = reward_function, # Reward function, default : the one presented above\r\n    portfolio_initial_value = 1000, # Initial value of the portfolio (in FIAT), default : 1000. Here, 1000 USD\r\n)\r\n```\r\n**5 - Run the environment**\r\n```python\r\ntruncated = False\r\nobservation, info = env.reset()\r\nwhile not truncated:\r\n    action = env.action_space.sample()\r\n    observation, reward, done, truncated, info = env.step(action)\r\n```\r\n- ```observation``` returns a dict with items :\r\n    - ```features``` : Contains the features created. If windows is None, it contains the features of the current step (shape = (n_features,)). If windows is i (int), it contains the features the last i steps (shape = (5, n_features)).\r\n    - ```position``` : The last position of the environments. It can be useful to include this to the features, so the agent knows which position he is holding and gains stability and continuity.\r\n- ```reward``` : The step reward following the action taken.\r\n- ```done```: Always False.\r\n- ```truncated``` : Is true if we reached the end of the DataFrame.\r\n- ```info``` : Return the last history step of the object \"history\" presented above (in \"3 - Create your own reward function\")\r\n\r\n\r\n**(Optional) 6 - Render**\r\n\r\nPerformed with Dash Plotly (local app).\r\n```python\r\nenv.render()\r\n```\r\n<img alt=\"Render example\" src =\"https://github.com/ClementPerroud/Gym-Trading-Env/blob/main/readme_images/render.PNG?raw=true\" height = \"600\"/>\r\n\r\nEnjoy :)\r\n\r\n\r\n\r\n\r\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "MIT License  Copyright (c) [year] [fullname]  Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:  The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.",
    "maintainer": "",
    "maintainer_email": "",
    "name": "gym-trading-env",
    "package_url": "https://pypi.org/project/gym-trading-env/",
    "platform": null,
    "project_url": "https://pypi.org/project/gym-trading-env/",
    "project_urls": {
      "Bug Tracker": "https://github.com/ClementPerroud/Gym-Trading-Env/issues",
      "Homepage": "https://github.com/ClementPerroud/Gym-Trading-Env"
    },
    "release_url": "https://pypi.org/project/gym-trading-env/0.0.5/",
    "requires_dist": null,
    "requires_python": ">=3.7",
    "summary": "A simple, easy, customizable Open IA Gym environments for trading.",
    "version": "0.0.5",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17479251,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8a667503fa1df89627663e3a3ecd0720c00efa279bc0d175d5a805a3aa36eb57",
          "md5": "9934120d79032dd6fc9efa0d34d69079",
          "sha256": "14c3d3b009b04c96137e5168020698a1100fe5025238adc9dba3e28b6e480912"
        },
        "downloads": -1,
        "filename": "gym_trading_env-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "9934120d79032dd6fc9efa0d34d69079",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 10061,
        "upload_time": "2023-03-28T12:22:59",
        "upload_time_iso_8601": "2023-03-28T12:22:59.117604Z",
        "url": "https://files.pythonhosted.org/packages/8a/66/7503fa1df89627663e3a3ecd0720c00efa279bc0d175d5a805a3aa36eb57/gym_trading_env-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "87aba9adffc7bd1a997fba47a747fb5b837c910180a4eb07cdf66c40da3659d6",
          "md5": "8e51e38468cf23f10c26af6d79c9c9e2",
          "sha256": "de21ffd7247bf9b91f83dbd4ee3950c6bca1fdefcbe6f8793febf9ba956cb1af"
        },
        "downloads": -1,
        "filename": "gym-trading-env-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "8e51e38468cf23f10c26af6d79c9c9e2",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 12193,
        "upload_time": "2023-03-28T12:23:01",
        "upload_time_iso_8601": "2023-03-28T12:23:01.015982Z",
        "url": "https://files.pythonhosted.org/packages/87/ab/a9adffc7bd1a997fba47a747fb5b837c910180a4eb07cdf66c40da3659d6/gym-trading-env-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c12e82ab49b7d54f64f25efa1a4dbae33c341ab91b92f31a84586e105c197742",
          "md5": "ee4df353b3d91fe214e22fcedfb24de6",
          "sha256": "63b0892ba3ea722af9795bccbbbf8a13259b6b53f7a0e1990b4acec7b185781b"
        },
        "downloads": -1,
        "filename": "gym_trading_env-0.0.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ee4df353b3d91fe214e22fcedfb24de6",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 10136,
        "upload_time": "2023-03-28T14:35:14",
        "upload_time_iso_8601": "2023-03-28T14:35:14.576968Z",
        "url": "https://files.pythonhosted.org/packages/c1/2e/82ab49b7d54f64f25efa1a4dbae33c341ab91b92f31a84586e105c197742/gym_trading_env-0.0.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "281c1ce184e4c86c472b6a108c541e10aff2f9c5f5e5bfb89d4454456999888e",
          "md5": "03ee57745f4f36d9bb1b5798a5ce42f2",
          "sha256": "05a68501f8ca1ac1bd6ade7d64baf79d96abdbeab5e1c8d6c0345d8beefcfa92"
        },
        "downloads": -1,
        "filename": "gym-trading-env-0.0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "03ee57745f4f36d9bb1b5798a5ce42f2",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 12287,
        "upload_time": "2023-03-28T14:35:16",
        "upload_time_iso_8601": "2023-03-28T14:35:16.231388Z",
        "url": "https://files.pythonhosted.org/packages/28/1c/1ce184e4c86c472b6a108c541e10aff2f9c5f5e5bfb89d4454456999888e/gym-trading-env-0.0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "c12e82ab49b7d54f64f25efa1a4dbae33c341ab91b92f31a84586e105c197742",
        "md5": "ee4df353b3d91fe214e22fcedfb24de6",
        "sha256": "63b0892ba3ea722af9795bccbbbf8a13259b6b53f7a0e1990b4acec7b185781b"
      },
      "downloads": -1,
      "filename": "gym_trading_env-0.0.5-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "ee4df353b3d91fe214e22fcedfb24de6",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 10136,
      "upload_time": "2023-03-28T14:35:14",
      "upload_time_iso_8601": "2023-03-28T14:35:14.576968Z",
      "url": "https://files.pythonhosted.org/packages/c1/2e/82ab49b7d54f64f25efa1a4dbae33c341ab91b92f31a84586e105c197742/gym_trading_env-0.0.5-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "281c1ce184e4c86c472b6a108c541e10aff2f9c5f5e5bfb89d4454456999888e",
        "md5": "03ee57745f4f36d9bb1b5798a5ce42f2",
        "sha256": "05a68501f8ca1ac1bd6ade7d64baf79d96abdbeab5e1c8d6c0345d8beefcfa92"
      },
      "downloads": -1,
      "filename": "gym-trading-env-0.0.5.tar.gz",
      "has_sig": false,
      "md5_digest": "03ee57745f4f36d9bb1b5798a5ce42f2",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 12287,
      "upload_time": "2023-03-28T14:35:16",
      "upload_time_iso_8601": "2023-03-28T14:35:16.231388Z",
      "url": "https://files.pythonhosted.org/packages/28/1c/1ce184e4c86c472b6a108c541e10aff2f9c5f5e5bfb89d4454456999888e/gym-trading-env-0.0.5.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}