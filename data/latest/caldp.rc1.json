{
  "info": {
    "author": "STScI",
    "author_email": "helpdesk@stsci.edu",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "Calibration data pipeline for Hubble Space Telescope Observations\n-----------------------------------------------------------------\n\n.. image:: http://img.shields.io/badge/powered%20by-AstroPy-orange.svg?style=flat\n    :target: http://www.astropy.org\n    :alt: Powered by Astropy Badge\n\n\nLicense\n-------\n\nThis project is Copyright (c) STScI and licensed under\nthe terms of the BSD 3-Clause license. This package is based upon\nthe `Astropy package template <https://github.com/astropy/package-template>`_\nwhich is licensed under the BSD 3-clause license. See the licenses folder for\nmore information.\n\n\nContributing\n------------\n\nWe love contributions! caldp is open source,\nbuilt on open source, and we'd love to have you hang out in our community.\n\n**Imposter syndrome disclaimer**: We want your help. No, really.\n\nThere may be a little voice inside your head that is telling you that you're not\nready to be an open source contributor; that your skills aren't nearly good\nenough to contribute. What could you possibly offer a project like this one?\n\nWe assure you - the little voice in your head is wrong. If you can write code at\nall, you can contribute code to open source. Contributing to open source\nprojects is a fantastic way to advance one's coding skills. Writing perfect code\nisn't the measure of a good developer (that would disqualify all of us!); it's\ntrying to create something, making mistakes, and learning from those\nmistakes. That's how we all improve, and we are happy to help others learn.\n\nBeing an open source contributor doesn't just mean writing code, either. You can\nhelp out by writing documentation, tests, or even giving feedback about the\nproject (and yes - that includes giving feedback about the contribution\nprocess). Some of these contributions may be the most valuable to the project as\na whole, because you're coming to the project with fresh eyes, so you can see\nthe errors and assumptions that seasoned contributors have glossed over.\n\nNote: This disclaimer was originally written by\n`Adrienne Lowe <https://github.com/adriennefriend>`_ for a\n`PyCon talk <https://www.youtube.com/watch?v=6Uj746j9Heo>`_, and was adapted by\ncaldp based on its use in the README file for the\n`MetPy project <https://github.com/Unidata/MetPy>`_.\n\n\nOverview of CALDP\n-----------------\n\nCALDP is used to integrate fundamental HST calibration programs (*e.g.* calacs.e)\nwith input data, output data, and calibration reference files (CRDS). Ultimately,\n\nCALDP does end-to-end calibration of HST data in a manner similar to the\narchive pipeline, including the generation of preview images.\n\nCALDP is primarily a Python package with some installable scripts, but also includes\ninfrastructure for building a Docker container with everything needed to fully calibrate\nraw HST data to produce pipeline-like products.\n\nCALDP has two basic ways it can be run:\n\n1. CALDP can be run native in a conda environment.\n2. CALDP can be run inside a Docker container.\n\nA variation of running CALDP inside the Docker container is:\n\n3. Run arbitrary numbers of CALDP containers on AWS compute clusters, pulling inputs\nfrom Astroquery, and writing outputs to AWS S3 storage. This can vastly accelerate\nlarge processing runs.\n\nNative CALDP\n------------\n\nThe core logic of CALDP is implemented in the caldp Python package in the\nprocess and create_preview modules.  CALDP also includes convenience scripts to\nmake it simpler to configure and call these modules.   Since it is primarily\nPython,   nothing precludes running CALDP outside a container provided you\ninstall prerequisites.\n\nNative Install\n==============\n\nThe Everything Install\n++++++++++++++++++++++\n\n**WARNING**: By default this install method will completely replace any installation\nyou already have at $HOME/miniconda3 unlless you supply additional parameters.\n\nThe following commands will install:\n\n1. Miniconda\n2. The `stable` version of HSTCAL\n3. Fitscut\n4. Whichever version of CALDP you clone and/or checkout\n\nParameters specified below in **[ ]** are optional,  but must be specified in order, *i.e.*\nto change the CONDA_DIR you must specify all four parameters explicitly.\n\n.. code-block:: sh\n\n    git clone https://github.com/spacetelescope/caldp.git\n    cd caldp\n    scripts/caldp-install-all   [HSTCAL]  [PY_VER]  [CONDA_ENV]  [CONDA_DIR]\n\n.. csv-table::\n    :header: \"Parameter\",  \"Default\", \"Description\"\n    :widths: 15, 15, 50\n\n    HSTCAL, stable,\"Version of base calibration packages,  nominally *stable* or *latest*.\"\n    PY_VER, 3.6.10,\"Python version for CALDP conda environment.\"\n    CONDA_ENV, caldp_stable, \"Conda environment which will be created\"\n    CONDA_DIR, \"${HOME}/miniconda3\", \"Location of Miniconda Installation.\"\n\n\nInstall Step-by-Step\n++++++++++++++++++++\n\nThis section breaks down the Everything installation into different functional steps\nso that you can omit steps or customize as needed,  *e.g.* if you already have a miniconda3\ninstallation and just want to add to it.\n\n0. Check out the source code\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n.. code-block:: sh\n\n     git clone https://github.com/spacetelescope/caldp.git\n    cd caldp\n\n1. Install base conda environment\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n.. code-block:: sh\n\n    scripts/caldp-install-conda  [CONDA_DIR]\n    source ~/.bashrc\n\n2. Install fundamental CAL code using pipeline package lists\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n.. code-block:: sh\n\n    scripts/caldp-install-cal  [HSTCAL]  [PY_VER]  [CONDA_ENV]  [CONDA_DIR]\n    source $CONDA_DIR/etc/profile.d/conda.sh\n    conda activate [CONDA_ENV]\n\n3. Install fitscut for image previews\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n.. code-block:: sh\n\n    scripts/caldp-install-fitscut   ${CONDA_DIR}/envs/${CONDA_ENV}\n\n4. Install CALDP and direct dependencies\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n.. code-block:: sh\n\n    pip install .[dev,test]\n\nWhile doing CALDP development you can of course just iterate changing, re-installing, and\ntesting CALDP itself.\n\nNative Run\n==========\n\nThe abstract command for running CALDP natively is:\n\n.. code-block:: sh\n\n    caldp-process   <ipppssoot>   [<input_path>]  [<output_path>]   [<config>]\n\n.. csv-table:: **Parameter Definitions**\n    :header: \"Parameter\",  \"Default Value\", \"Description\"\n    :widths: 15, 15, 50\n\n    ipppssoot, N/A, \"HST dataset identifier,  you must always specify this\"\n    input_path, file:., \"can be file:<relative_path> or astroquery: or (probably coming s3://input-bucket/subdirs...)\"\n    output_path, file:., \"can be file:<relative_path> or s3://output-bucket/subdirs...\"\n    config, caldp-config-onsite, \"can be caldp-config-offsite,  caldp-config-onsite,  caldp-config-aws,  <custom>\"\n\nRunning natively, file paths for CALDP work normally with the exception that they're\nspecified using a URI-like notation which begins with **file:**. Absolute paths work here.\n\nExample Native Commands\n+++++++++++++++++++++++\nBelow are some parameter examples for running CALDP natively with different input\nand output modes. caldp-process is configured to run using local files by default.\n\n.. code-block:: sh\n\n    # All file access defaults to current working directory. Inputs must pre-exist.\n    # Inputs: Finds raw files matching j8cb010b0 in current working directory\n    # Outputs: Puts output product trees under current working directory as data and messages subdirectories.\n    # CRDS configuration: VPN configuration, no CRDS server required, /grp/crds/cache must be visible.\n    # Scratch files: Extra processing artifacts appear in the current working directory. Export CALDP_HOME to move them somewhere else.\n\n    caldp-process j8cb010b0\n\n    # ----------------------------------------------------------------------------------------\n    # File access in subdirectories, inputs must pre-exist.\n    # Inputs: Finds raw files matching j8cb010b0 in subdirectory j8cb010b0_inputs.\n    # Outputs: Copies output product tree under subdirectory j8cb010b0_outputs.\n    # CRDS configuration: VPN configuration, no CRDS server required, /grp/crds/cache must be visible.\n    # Scratch files: Extra processing artifacts appear in the current working directory. Export CALDP_HOME to move them somewhere else.\n\n    caldp-process j8cb010b0  file:j8cb010b0_inputs  file:j8cb010b0_outputs\n\n\n    # ----------------------------------------------------------------------------------------\n    # Download inputs from astroquery as neeed\n    # Inputs: Downloads raw files matching j8cb010b0 from astroquery to current working directory / CALDP_HOME.\n    # Outputs: Copies output product tree under subdirectory j8cb010b0_outputs.\n    # CRDS configuration: VPN configuration, no CRDS server required, /grp/crds/cache must be visible.\n    # Scratch files: Extra processing artifacts appear in the current working directory. Export CALDP_HOME to move them somewhere else.\n\n    caldp-process j8cb010b0  astroquery:   file:j8cb010b0_outputs\n\n\n    # ----------------------------------------------------------------------------------------\n    # Download inputs from astroquery, upload outputs to S3, current AWS Batch configuration minus Docker.\n    # Inputs: Downloads raw files matching j8cb010b0 from astroquery to current working directory / CALDP_HOME.\n    # Outputs: Copies output product tree to AWS S3 storage bucket, AWS credentials and permission required.\n    # CRDS configuration: VPN configuration, no CRDS server required, /grp/crds/cache must be visible.\n    # Scratch files: Extra processing artifacts appear in the current working directory. Export CALDP_HOME to move them somewhere else.\n\n    caldp-process j8cb010b0  astroquery:  s3://calcloud-hst-pipeline-outputs\n\n\nDocker CALDP\n------------\nWhile CALDP is a natively installable Python package, its roots are as a Docker container\nused to perform HST calibrations on AWS Batch. CALDP has subsequently been enhanced to run\nusing inputs and outputs from a local file system rather than cloud resources like Astroquery\nand AWS S3 storage. The primary difference from running natively is that some portion\nof your native file system must be mounted inside the container to pass files in and out\nas naturally as possible. By default, your current working directory becomes $HOME\n(/home/developer)\n\nDocker Build\n============\nIf you want to run CALDP as a container then the equivalent of installing it\nis either building or pulling the container (i.e. from an AWS elastic container registry, ECR).\nThis section will cover building your own CALDP image. To complete this section for\npersonal use,  all you need is a local installation of Docker and the supplied scripts\nshould run it for you even more easily than normal. This section doesn't cover using Docker\nin general, or hosting your own images on Docker Hub or AWS Elastic Container Registry (ECR)\nwhere you can make them available to others.\n\n0. Clone this repo to a local directory and CD to it.\n\n1. Edit *scripts/caldp-image-config* to set your Docker repo and default tag. Unless\nyou're ready to push an image, you can use any name for your respository. Leave\nthe default tag set to \"latest\" until you're familiar with the scripts and ready\nto modify or improve them.\n\n.. code-block:: sh\n\n    git clone https://github.com:/spacetelescope/caldp.git\n    cd caldp\n\n2. Configure and build:\n\n    # Edit scripts/caldp-image-config to set the Docker image config variables for\n    # your currrent build.  These will include the repo and image tag your want to\n    # build and/or push.\n    vim scripts/caldp-image-config   # and customize as needed.\n\n    # Install CALDP natively to get convenience scripts and your configuration from (1).\n    pip install .\n\n    # This script executes docker build to create the image with your configuration\n    caldp-image-build\n\nAt this stage you can proceed to running your image if you wish.\n\n3. (optional) When you're ready to share your image with others and have done the corresponding\nDocker Hub or ECR setup, you can log in from your shell and then:\n\n.. code-block:: sh\n\n    caldp-image-push\n\nThis will push your image to the repo and tag your configured above.\n\nDocker Run\n==========\nThe following command configures CALDP to run from a container locally. It has the advantage\nthat the entire HST calibration environment is included within the container so there are no\nother preliminary setup steps other than setting up Docker. The same container can be run\nlocally or on pipeline cluster systems like AWS Batch.\n\n.. code-block:: sh\n\n    caldp-docker-run-pipeline  <ipppssoot>  [<input_path>]  [<output_path>]   [<caldp_process_config>]\n\nThis should look very similar to the caldp-process command shown in the *Native CALDP* section above\nbecause it is. The primary **differences** are that absolute native paths do not work.\n\n**NOTE:**  The config file specified to caldp-docker-run-pipeline is used to configure processing,\nnot to select the image.  caldp-docker-run-pipeline automatically uses caldp-image-config to select\nthe image to run.\n\nExample Docker Commands (Local File System)\n+++++++++++++++++++++++++++++++++++++++++++\nBelow are some parameter examples for running CALDP inside Docker with different input\nand output modes. caldp-process is *still* configured to run using local files by default.\n\n.. code-block:: sh\n\n    # All file access defaults to current working directory. Inputs must pre-exist.\n    # Inputs: Finds raw files matching j8cb010b0 in current working directory\n    # Outputs: Puts output product trees under current working directory as data and messages subdirectories.\n    # CRDS configuration: Remote configuration, server https://hst-crds.stsci.edu must be up, files downloaded to crds_cache.\n    # Scratch files: Extra processing artifacts appear in the current working directory. Export CALDP_HOME to move them somewhere else.\n\n    caldp-docker-run-pipeline j8cb010b0\n\n    # ----------------------------------------------------------------------------------------\n    # File access in subdirectories, inputs must pre-exist.\n    # Inputs: Finds raw files matching j8cb010b0 in subdirectory j8cb010b0_inputs.\n    # Outputs: Copies output product tree under subdirectory j8cb010b0_outputs.\n    # CRDS configuration: Remote configuration, server https://hst-crds.stsci.edu must be up, files downloaded to crds_cache.\n    # Scratch files: Extra processing artifacts appear in the current working directory. Export CALDP_HOME to move them somewhere else.\n\n    caldp-docker-run-pipeline j8cb010b0  file:j8cb010b0_inputs  file:j8cb010b0_outputs\n\n\n    # ----------------------------------------------------------------------------------------\n    # Download inputs from astroquery as neeed\n    # Inputs: Downloads raw files matching j8cb010b0 from astroquery to current working directory / CALDP_HOME.\n    # Outputs: Copies output product tree under subdirectory j8cb010b0_outputs.\n    # CRDS configuration: Remote configuration, server https://hst-crds.stsci.edu must be up, files downloaded to crds_cache.\n    # Scratch files: Extra processing artifacts appear in the current working directory. Export CALDP_HOME to move them somewhere else.\n\n    caldp-docker-run-pipeline j8cb010b0  astroquery:   file:j8cb010b0_outputs\n\n\n    # ----------------------------------------------------------------------------------------\n    # Download inputs from astroquery, upload outputs to S3, current AWS Batch configuration minus Docker.\n    # Inputs: Downloads raw files matching j8cb010b0 from astroquery to current working directory / CALDP_HOME.\n    # CRDS configuration: Remote configuration, server https://hst-crds.stsci.edu must be up, files downloaded to crds_cache.\n    # Scratch files: Extra processing artifacts appear in the current working directory. Export CALDP_HOME to move them somewhere else.\n\n    caldp-docker-run-pipeline j8cb010b0  astroquery:  s3://calcloud-hst-pipeline-outputs/batch-22\n\nAfter configuring Docker, caldp-docker-run-pipeline runs *caldp-process* inside the docker container\nwith the parameters given on the command line. While file: paths are defined relative to your native\nfile system, within the Docker container they will nominally be interpreted relative to */home/developer*.\nSince the CALDP_HOME directory is mounted read/write inside Docker, files needed to process a dataset\nwill be reflected back out of the Docker container to CALDP_HOME, defaulting to your current working\ndirectory.\n\n**NOTE:**  Running the final cloud-like configuration above does not produce results idenitical to AWS Batch processing\nbecause it is only processing a single dataset and skips batch tracking and organization actions normally performed by\nthe batch trigger lambda which operates on a list of datasets.\n\nExample Docker Commands (AWS Batch)\n+++++++++++++++++++++++++++++++++++\nBelow is the calling sequence used to run CALDP on AWS Batch. This command is specified in the\nAWS Batch job definition and used to run all queued jobs. The calling sequence uses more\ncustomized input parameters in the outermost wrapper script specifying only the S3 output\nbucket and dataset name.\n\n.. code-block:: sh\n\n    caldp-process-aws  <s3_output_path>   <ipppssoot>\n\nInternally, *caldp-process-aws* runs *caldp-process* automatically configured to use:\n\n1. astroquery: to obtain raw data.\n2. the specified S3 output path which typically includes a batch \"subdirectory\".\n3. the specified dataset (ipppssoot) to define which data to fetch and process.\n4. a serverless CRDS configuration dependent only on S3 files.\n\nDespite supporting a containerized use case, since AWS Batch (or equivalent) normally runs\nDocker, *caldp-process-aws* is effectively a *native* mode command when run by itself.\nThere is no wrapper script equivalent to *caldp-docker-run-pipeline* to configure and\nrun *caldp-process-aws* inside Docker automatically, but since it really requires no additional\nfile mounts or ports, it is simple to run with Docker.\n\nRunning *caldp-process-aws* does require access to the CRDS and the output bucket on AWS S3 storage,\n*i.e.* appropriate credentials and permissions.\n\nDebugging in the Container\n++++++++++++++++++++++++++\nSometimes you want to execute commands in the container environment rather than *caldp-process*. You\ncan run any command using *caldp-docker-run-container* which is itself wrapped by *caldp-docker-run-pipeline*.\n\n.. code-block:: sh\n\n    # You can run a shell or other alternate program inside the CALDP container like this:\n\n    caldp-docker-run-container  /bin/bash  # interactive shell at /home/developer inside the container, nominally as user *developer*.\n\nAbout CALDP_HOME\n++++++++++++++++\nThe CALDP_HOME environment variable defines which native directory *caldp-docker-run-pipeline* will\nmount inside the running Docker container at $HOME as read/write. If not exported, CALDP_HOME\ndefaults to the directory you run caldp-docker-run-pipeline from. Since *caldp-process*\nruns at $HOME within the Docker container, any scratch files used during processing will appear\nexternally within CALDP_HOME. Note that using caldp-docker-run-pipeline is not a requirement,\nit is just a script used to establish standard Docker configuration for local CALDP execution.\n\nGetting AWS Credentials Inside the Container\n++++++++++++++++++++++++++++++++++++++++++++\nOne technique for enabling AWS access inside the container is to put a *.aws* configuration directory in your\n*CALDP_HOME* directory.\n\nSince caldp-docker-run-pipeline mounts CALDP_HOME inside the container at *$HOME*, AWS will see them where it\nexpects to find them. AWS Batch nominally runs worker nodes which have the necessary permissions attached\nso no .aws directory is needed on AWS Batch.\n\nOutput Structure\n----------------\nCALDP and CALCLOUD output data in a form desgined to help track the state of individual datasets.\n\nAs such, the output directory is organized into two subdirectories:\n\n1. *messages*\n2. *data*\n\nA key difference between CALDP and CALCLOUD is that the former is designed for processing single\ndatasets, while the latter is designed for processing batches of datasets which are run individually\nby CALCLOUD. In this context, normally files downloaded from CALCLOUD's S3 storage to an onsite\ndirectory are placed in a \"batch directory\", and the CALDP equivalent of that batch directory is\nthe output directory. The same messages and data appearing in the CALDP output directory would\nalso appeaar in the sync'ed CALCLOUD batch directory.\n\nMessages Subdirectory\n=====================\nThe *messages* subdirectory is used to record the status of individual datasets\nas they progress through processing, data transfer, and archiving. Each dataset has a\nsimilarly named state file which moves between state directories as it starts or completes\nvarious states. The dataset file can be used to record metadata but its primary use\nis to enable simple indentification dataset state without the use of a database, queues,\netc. Only a local file system is needed to track state using this scheme. A mirror\nof this same scheme is used on the cloud on S3 storage to help guide file downloads from\nAWS.\n\n.. code-block:: sh\n\n    <output_path>/\n        messages/\n            datasets-processed/\n                <ipppssoots...>    # CALDP, normally running on AWS batch, leaves messages here. they're empty.\n            dataset-synced/\n                <ipppssoots...>    # CALCLOUD's downloader leaves messages here, normally containing abspaths of files to archive.\n            dataset-archived/\n                <ipppssoots...>    # The archive can acknowledge archive completion here, file contents should be preserved.\n\nData Subdirectory\n=================\nThe *data* subdirectory parallels but has a different structure than the *messages*\nsubdirectory. For every ipppssoot message, there is a data directory and subdirectories\nwhich contain output files from processsing that ipppssoot. In the current implementation,\nthe ipppssoot message file is empty, it is normally populated by CALCLOUD's downloader\nwith the paths of files to archive when it is output to dataset-synced.\n\n.. code-block:: sh\n\n    <output_path>/\n        data/\n            <instrument>/\n                <ipppssoots...>/    # one dir per ipppssoot\n                    science data files for one ipppssoot...\n                    logs/\n                        log and metrics files for one ipppssoot...\n                    previews/\n                        preview images for one ipppssoot...\n\nConfiguring CALDP (advanced)\n----------------------------\nAs explained previously, each of the 3 CALDP use cases has a different CRDS configuration.\nThis implementation is described here in case it is necessary to write additional configurations\nor add variables to these. At present, unlike *caldp-image-config*, these config scripts\ndon't generally need customization, they are used as-is to support their use cases.\n\nCALDP configuration scripts set environment variables which will be defined within the scope\nof *caldp-process*. These configuration scripts are installed alongside other CALDP scripts so they\ncan be sourced directly without knowing where they are installed. The name of the\nconfiguration script is passed as a 4th generally defaulted parameter to caldp-process:\n\n.. csv-table::\n    :header: \"Top Level Script\",  \"Config Script\", \"Description\"\n    :widths: 15, 15, 50\n\n    caldp-process, caldp-config-onsite, Configures CRDS to operate from Central Store /grp/crds/cache. Should scale.\n    caldp-docker-run-pipeline, caldp-config-offsite, Configures CRDS to download from CRDS server. This may not scale well.\n    caldp-process-aws, caldp-config-aws, Configures CRDS to operate from S3 storage with no server dependency. Should scale.\n\nTesting\n-------\n\nTravis\n======\n\nThe CALDP repo is set up for Travis via github checkins.   Whenever you do a PR to spacetelescope/caldp,\nTravis will automatically run CI tests for CALDP.\n\nNative Testing\n==============\n\nIt's common to do testing on a development machine prior to pushing.   This can basically be\naccomplished by installing caldp,  configuring your environment, and then running pytest\nsimilar to how it will be run by Travis.\n\n.. code-block:: sh\n\n    # FIRST: Setup a conda environment for CALDP as discussed above in native installs.\n    # Don't use the \"everything install\" if you have an existing conda environment you\n    # don't want to wipe out.   Make sure to activate it.\n\n    # THEN:  configure your environment and run pytest as Travis would:\n    source caldp-config-offsite\n    pytest caldp --cov=caldp --cov-fail-under 80  --capture=tee-sys\n\n**NOTE:** Not all CALDP code and capabilities are tested, particularly the wrapper scripts\ncurrently associated with running the Python package inside and outside Docker.\n\nS3 I/O\n======\n\nBecause S3 inputs and outputs require AWS credentials to enable access, and specific object paths\nto use,  testing of S3 modes is controlled by two environment variables which define where to locate\nS3 inputs and outputs:\n\n.. code-block:: sh\n\n    export CALDP_S3_TEST_INPUTS=s3://caldp-hst-test/inputs/test-batch\n    export CALDP_S3_TEST_OUTPUTS=s3://caldp-hst-test/outputs/test-batch\n\nIf either or both of the above variables is defined, pytest will also execute tests which utilize the S3\ninput or output modes.  You must also have AWS credentials for this.  Currently S3 is not tested on Travis.",
    "description_content_type": "text/x-rst",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "http://stsci.edu",
    "keywords": "",
    "license": "BSD 3-Clause",
    "maintainer": "",
    "maintainer_email": "",
    "name": "caldp",
    "package_url": "https://pypi.org/project/caldp/",
    "platform": "",
    "project_url": "https://pypi.org/project/caldp/",
    "project_urls": {
      "Homepage": "http://stsci.edu"
    },
    "release_url": "https://pypi.org/project/caldp/0.1.0/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "Calibration data pipeline for Hubble Space Telescope Observations",
    "version": "0.1.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8098056,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f2cb03a8dc8ecf96e63a1ed3542e17245ac71f87213c15221dd897de6bdc53a0",
          "md5": "1981dd6e8d46ea75123b959a498fdc2a",
          "sha256": "e9af4f054d743998fafbc2b78d0f8a7ccb576d2396186cb91820b859eb1b5c11"
        },
        "downloads": -1,
        "filename": "caldp-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "1981dd6e8d46ea75123b959a498fdc2a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 57768,
        "upload_time": "2020-09-02T21:40:42",
        "upload_time_iso_8601": "2020-09-02T21:40:42.802586Z",
        "url": "https://files.pythonhosted.org/packages/f2/cb/03a8dc8ecf96e63a1ed3542e17245ac71f87213c15221dd897de6bdc53a0/caldp-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "f2cb03a8dc8ecf96e63a1ed3542e17245ac71f87213c15221dd897de6bdc53a0",
        "md5": "1981dd6e8d46ea75123b959a498fdc2a",
        "sha256": "e9af4f054d743998fafbc2b78d0f8a7ccb576d2396186cb91820b859eb1b5c11"
      },
      "downloads": -1,
      "filename": "caldp-0.1.0.tar.gz",
      "has_sig": false,
      "md5_digest": "1981dd6e8d46ea75123b959a498fdc2a",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 57768,
      "upload_time": "2020-09-02T21:40:42",
      "upload_time_iso_8601": "2020-09-02T21:40:42.802586Z",
      "url": "https://files.pythonhosted.org/packages/f2/cb/03a8dc8ecf96e63a1ed3542e17245ac71f87213c15221dd897de6bdc53a0/caldp-0.1.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}