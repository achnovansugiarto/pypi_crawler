{
  "info": {
    "author": "RÃ¼zgar Ersin Kanar",
    "author_email": "ruzgarknr@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: Apache Software License",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.9"
    ],
    "description": "\n\n\n# Perlib\n\nThis repository hosts the development of the Perlib library.\n\n## About Perlib\n\nPerlib is a framework written in Python where you can use deep and machine learning algorithms.\n\n## Perlib is\nFeature to use many deep or machine learning models easily\nFeature to easily generate estimates in a single line with default parameters\nUnderstanding data with simple analyzes with a single line\nFeature to automatically preprocess data in a single line\nFeature to easily create artificial neural networks\nFeature to manually pre-process data, extract analysis or create models with detailed parameters, produce tests and predictions\n\n## Usage\nThe core data structures are layers and models. For quick results with default parameters\nTo set up more detailed operations and structures, you should use the Perflib functional API, which allows you to create arbitrary layers or write models completely from scratch via subclassing.\n\n\n## Install\n```python\npip install perlib\n```\n\n```python\nfrom perlib.forecaster import *\n```\n\nThis is how you can use sample datasets.\n\n```python\nfrom perlib import datasets # or  from perlib.datasets import *\nimport pandas as pd\ndataset = datasets.load_airpassengers()\ndata = pd.DataFrame(dataset)\ndata.index = pd.date_range(start=\"2022-01-01\",periods=len(data),freq=\"d\")\n```\n\nTo read your own dataset;\n```python \nimport perlib\npr = perlib.dataPrepration()\ndata = pr.read_data(\"./datasets/winequality-white.csv\",delimiter=\";\")\n```\n\nThe easiest way to get quick results is with the 'get_result' function.\nYou can choice modelname ;\n\"RNN\", \"LSTM\", \"BILSTM\", \"CONVLSTM\", \"TCN\", \"LSTNET\", \"ARIMA\" ,\"SARIMA\" or all machine learning algorithms\n\n\n```python \nforecast,evaluate = get_result(dataFrame=data,\n                    y=\"Values\",\n                    modelName=\"Lstnet\",\n                    dateColumn=False,\n                    process=False,\n                    forecastNumber=24,\n                    metric=[\"mape\",\"mae\",\"mse\"],\n                    epoch=2,\n                    forecastingStartDate=2022-03-06,\n                    verbose=1\n                    )\n```\n```python \n\nParameters created\nModel: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_1 (InputLayer)           [(None, 24, 1)]      0           []                               \n                                                                                                  \n reshape (Reshape)              (None, 24, 1, 1)     0           ['input_1[0][0]']                \n                                                                                                  \n conv2d (Conv2D)                (None, 19, 1, 100)   700         ['reshape[0][0]']   \n\n dropout (Dropout)              (None, 19, 1, 100)   0           ['conv2d[0][0]']                 \n                                                                                                  \n reshape_1 (Reshape)            (None, 19, 100)      0           ['dropout[0][0]']                \n                                                                                                  \n pre_skip_trans (PreSkipTrans)  (None, 1, 100)       0           ['reshape_1[0][0]']              \n                                                                                                  \n gru (GRU)                      [(None, 100),        60600       ['reshape_1[0][0]']              \n                                 (None, 100)]                                                     \n                                                                                                  \n gru_1 (GRU)                    [(None, 5),          1605        ['pre_skip_trans[0][0]']         \n                                 (None, 5)]                                                       \n                                                                                                  \n dropout_1 (Dropout)            (None, 100)          0           ['gru[0][1]']                    \n                                                                                                  \n post_skip_trans (PostSkipTrans  (None, 95)          0           ['gru_1[0][1]',                  \n )                                                                'input_1[0][0]']                \n                                                                                                  \n pre_ar_trans (PreARTrans)      (None, 24)           0           ['input_1[0][0]']                \n                                                                                                  \n concatenate (Concatenate)      (None, 195)          0           ['dropout_1[0][0]',              \n                                                                  'post_skip_trans[0][0]']        \n                                                                                                  \n flatten_1 (Flatten)            (None, 24)           0           ['pre_ar_trans[0][0]']  \n \n flatten (Flatten)              (None, 195)          0           ['concatenate[0][0]']            \n                                                                                                  \n dense_1 (Dense)                (None, 1)            25          ['flatten_1[0][0]']              \n                                                                                                  \n dense (Dense)                  (None, 1)            196         ['flatten[0][0]']                \n                                                                                                  \n post_ar_trans (PostARTrans)    (None, 1)            0           ['dense_1[0][0]',                \n                                                                  'input_1[0][0]']                \n                                                                                                  \n add (Add)                      (None, 1)            0           ['dense[0][0]',                  \n                                                                  'post_ar_trans[0][0]']          \n                                                                                                  \n==================================================================================================\nTotal params: 63,126\nTrainable params: 63,126\nNon-trainable params: 0\n__________________________________________________________________________________________________\nThe model training process has been started.\nEpoch 1/2\n500/500 [==============================] - 14s 23ms/step - loss: 0.2693 - val_loss: 0.0397\nEpoch 2/2\n500/500 [==============================] - 12s 24ms/step - loss: 0.0500 - val_loss: 0.0092\nModel training process completed\n\nThe model is being saved\n1/1 [==============================] - 0s 240ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 10ms/step\n1/1 [==============================] - 0s 16ms/step\n              Values   Predicts\nDate                            \n2022-03-07         71  79.437263\n2022-03-14         84  84.282906\n2022-03-21         90  88.096298\n2022-03-28         87  82.875603\nMAPE: 3.576822717339706\n\n```\n\n```python \nforecast\n\n            Predicts   Actual\nDate                            \n2022-03-07         71  79.437263\n2022-03-08         84  84.282906\n2022-03-09         90  88.096298\n2022-03-10         87  82.875603\n```\n\n```python \nevaluate\n\n{'mean_absolute_percentage_error': 3.576822717339706,\n 'mean_absolute_error': 14.02137889193878,\n 'mean_squared_error': 3485.26570064559}\n```\n\n\nhe Time Series module helps to create many basic models\nwithout using much code and helps to understand which models \nwork better without any parameter adjustments.\n```python \nfrom perlib.piplines.dpipline import Timeseries\npipline = Timeseries(dataFrame=data,\n                       y=\"Values\",\n                       dateColumn=False,\n                       process=False,\n                       epoch=1,\n                       forecastingStartDate=\"2022-03-06\",\n                       forecastNumber= 24,\n                       models=\"all\",\n                       metrics=[\"mape\",\"mae\",\"mse\"]\n                       )\npredictions = pipline.fit()\n\n            mean_absolute_percentage_error | mean_absolute_error  | mean_squared_error\nLSTNET                              14.05  |                67.70 |  5990.35\nLSTM                                7.03   |                38.28 |  2250.69\nBILSTM                              13.21  |                68.22 |  6661.60\nCONVLSTM                            9.62   |                48.06 |  2773.69\nTCN                                 12.03  |                65.44 |  6423.10\nRNN                                 11.53  |                59.33 |  4793.62\nARIMA                               50.18  |                261.14|  74654.48\nSARIMA                              10.48  |                51.25 |  3238.20\n```\n\n\nWith the 'summarize' function you can see quick and simple analysis results.\n```python \nsummarize(dataFrame=data)\n```\n\n\nWith the 'auto' function under 'preprocess', you can prepare the data using general preprocessing.\n```python \npreprocess.auto(dataFrame=data)\n\n12-2022 15:04:36.22    - DEBUG - Conversion to DATETIME succeeded for feature \"Date\"\n27-12-2022 15:04:36.23 - INFO - Completed conversion of DATETIME features in 0.0097 seconds\n27-12-2022 15:04:36.23 - INFO - Started encoding categorical features... Method: \"AUTO\"\n27-12-2022 15:04:36.23 - DEBUG - Skipped encoding for DATETIME feature \"Date\"\n27-12-2022 15:04:36.23 - INFO - Completed encoding of categorical features in 0.001252 seconds\n27-12-2022 15:04:36.23 - INFO - Started feature type conversion...\n27-12-2022 15:04:36.23 - DEBUG - Conversion to type INT succeeded for feature \"Salecount\"\n27-12-2022 15:04:36.24 - DEBUG - Conversion to type INT succeeded for feature \"Day\"\n27-12-2022 15:04:36.24 - DEBUG - Conversion to type INT succeeded for feature \"Month\"\n27-12-2022 15:04:36.24 - DEBUG - Conversion to type INT succeeded for feature \"Year\"\n27-12-2022 15:04:36.24 - INFO - Completed feature type conversion for 4 feature(s) in 0.00796 seconds\n27-12-2022 15:04:36.24 - INFO - Started validation of input parameters...\n27-12-2022 15:04:36.24 - INFO - Completed validation of input parameters\n27-12-2022 15:04:36.24 - INFO - AutoProcess process completed in 0.034259 seconds\n```\n\n\n\nIf you want to build it yourself;\n```python \nfrom perlib.core.models.dmodels import models\nfrom perlib.core.train import dTrain\nfrom perlib.core.tester import dTester\n```\n You can use many features by calling the 'dataPrepration' function for data preparation operations.\n```python \ndata = dataPrepration.read_data(path=\"./dataset/Veriler/ayakkabÄ±_haftalÄ±k.xlsx\")\n```\n```python \ndata = dataPrepration.trainingFordate_range(dataFrame=data,dt1=\"2013-01-01\",dt2=\"2022-01-01\")\n```\n\nYou can use the 'preprocess' function for data preprocessing.\n```python \ndata = preprocess.missing_num(dataFrame=data)\n```\n```python \ndata = preprocess.find_outliers(dataFrame=data)\n```\n```python \ndata = preprocess.encode_cat(dataFrame=data)\n```\n```python \ndata = preprocess.dublicates(dataFrame=data,mode=\"auto\")\n```\n\nYou should create an architecture like below.\n```python \nlayers = {\"Layer\": {\"unit\":[150,100]\n                  ,\"activation\":[\"tanh\",\"tanh\"],\n                    \"dropout\"  :[0.2,0.2]\n                  }}\n```\n\nYou can set each parameter below it by calling the 'req_info' object.\n```python \nreq_info.layers = layers\nreq_info.modelname = \"lstm\"\nreq_info.epoch  =  2\nreq_info.targetCol = \"Values\"\nreq_info.forecastingStartDate = \"2022-01-06 19:00:00\"\nreq_info.period = \"hourly\"\nreq_info.forecastNumber = 7\nreq_info.scaler = \"standard\"\n```\n\nIt will be prepared after importing it into models.\n```python \ns = models(req_info)\n```\n\n.build() func. You can see your architecture with\n```python \ns.build_model()\n```\n```\nModel: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n lstm (LSTM)                 (None, 24, 150)           91200     \n                                                                 \n dropout_2 (Dropout)         (None, 24, 150)           0         \n                                                                 \n lstm_1 (LSTM)               (None, 24, 100)           100400    \n                                                                 \n dropout_3 (Dropout)         (None, 24, 100)           0         \n                                                                 \n lstm_2 (LSTM)               (None, 50)                30200     \n                                                                 \n dropout_4 (Dropout)         (None, 50)                0         \n                                                                 \n dense_2 (Dense)             (None, 1)                 51        \n                                                                 \n=================================================================\nTotal params: 221,851\nTrainable params: 221,851\nNon-trainable params: 0\n_________________________________________________________________\n```\n\nAfter sending the dataframe and the prepared architecture to the dTrain, you can start the training process by calling the .fit() function.\n```python \ntrain = dTrain(dataFrame=data,object=s)\ntrain.fit()\n```\nAfter the training is completed, you can see the results by giving the dataFrame,object,path,metric parameters to 'dTester'.\n```python \nt = dTester(dataFrame=data,object=s,path=\"Data-Lstm-2022-12-14-19-56-28.h5\",metric=[\"mape\",\"mae\"])\n```\n```python \nt.forecast()\n```\n```\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 21ms/step\n\n```\n\n```python \nt.evaluate()\n\nMAPE: 3.35\n```\n\n```python \nfrom perlib.core.models.smodels import models as armodels\nfrom perlib.core.train import  sTrain\nfrom perlib.core.tester import sTester\n```\n```python \naR_info.modelname = \"sarima\"\naR_info.forcastingStartDate = \"2022-6-10\"\n```\n```python \nar = armodels(aR_info)\n#train = sTrain(dataFrame=data,object=ar)\nres = train.fit()\n```\n```python \nr = sTester(dataFrame=data,object=ar,path=\"Data-sarima-2022-12-30-23-49-03.pkl\")\nr.forecast()\nr.evaluate()\n```\n\n```python \nfrom perlib.core.models.mmodels import models\nfrom perlib.core.train import mTrain\n```\n\n```python \nm_info.testsize = .01\nm_info.y        = \"quality\"\nm_info.modelname= \"SVR\"\nm_info.auto  = False\n```\n\n```python \nm = models(m_info)\ntrain = mTrain(dataFrame=data,object=m)\npreds, evaluate = train.predict()\n```\n\n```python \n# If you want to make any other data predictions you can use the train.tester\n# func after train.predict. You can make predictions with\npredicts = train.tester(path=\"Data-SVR-2023-01-08-09-50-37.pkl\", testData=data.iloc[:,1:][-20:])\n```\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/Ruzzg/perlib",
    "keywords": "perlib,tensorflow,machine learning,deep learning",
    "license": "Apache Software License",
    "maintainer": "",
    "maintainer_email": "",
    "name": "perlib",
    "package_url": "https://pypi.org/project/perlib/",
    "platform": null,
    "project_url": "https://pypi.org/project/perlib/",
    "project_urls": {
      "Homepage": "https://github.com/Ruzzg/perlib"
    },
    "release_url": "https://pypi.org/project/perlib/2.1.2/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "Deep learning, Machine learning and Statistical learning for humans.",
    "version": "2.1.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16588514,
  "releases": {
    "2.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d2e54602ca7bf516ec6b93d8eacd8c94147239a0f75adf8ae8f3910b106a314e",
          "md5": "01d093e5c5b4ac641b0f83a7eadb5075",
          "sha256": "1f62d133c220e7fd4d80313368a42b01af68166067bc44ebcddc4e7b70f07a76"
        },
        "downloads": -1,
        "filename": "perlib-2.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "01d093e5c5b4ac641b0f83a7eadb5075",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 115736,
        "upload_time": "2023-01-20T19:26:30",
        "upload_time_iso_8601": "2023-01-20T19:26:30.937459Z",
        "url": "https://files.pythonhosted.org/packages/d2/e5/4602ca7bf516ec6b93d8eacd8c94147239a0f75adf8ae8f3910b106a314e/perlib-2.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "2.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "134650a09e20583cb750bfb5e0b78c143c2962517c0195a480899903b29ddd5a",
          "md5": "52995cbb2d06a4e0e813c890e3d822cc",
          "sha256": "74d0846e206a0f0f3c6e136a21adc229eaa92e80f277ab24cb532b04bc881af7"
        },
        "downloads": -1,
        "filename": "perlib-2.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "52995cbb2d06a4e0e813c890e3d822cc",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 116146,
        "upload_time": "2023-01-27T11:10:00",
        "upload_time_iso_8601": "2023-01-27T11:10:00.291811Z",
        "url": "https://files.pythonhosted.org/packages/13/46/50a09e20583cb750bfb5e0b78c143c2962517c0195a480899903b29ddd5a/perlib-2.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "134650a09e20583cb750bfb5e0b78c143c2962517c0195a480899903b29ddd5a",
        "md5": "52995cbb2d06a4e0e813c890e3d822cc",
        "sha256": "74d0846e206a0f0f3c6e136a21adc229eaa92e80f277ab24cb532b04bc881af7"
      },
      "downloads": -1,
      "filename": "perlib-2.1.2.tar.gz",
      "has_sig": false,
      "md5_digest": "52995cbb2d06a4e0e813c890e3d822cc",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 116146,
      "upload_time": "2023-01-27T11:10:00",
      "upload_time_iso_8601": "2023-01-27T11:10:00.291811Z",
      "url": "https://files.pythonhosted.org/packages/13/46/50a09e20583cb750bfb5e0b78c143c2962517c0195a480899903b29ddd5a/perlib-2.1.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}