{
  "info": {
    "author": "Minqin Chen",
    "author_email": "minqinchen@deepglint.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Developers",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3 :: Only",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Topic :: Scientific/Engineering :: Artificial Intelligence",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "# nnieqat-pytorch\n\nThis is a quantize aware training package for  Neural Network Inference Engine(NNIE) on pytorch, it uses hisilicon quantization library to quantize module's weight and input data as fake fp32 format. To train model which is more friendly to NNIE, just import nnieqat and replace torch.nn default modules with corresponding one.\n\n## Table of Contents\n\n1. [Installation](#installation)\n2. [Usage](#usage)\n3. [Code Examples](#examples)\n4. [Results](#results)\n5. [Todo](#Todo)\n6. [Reference](#reference)\n\n\n<div id=\"installation\"></div>  \n\n## Installation\n\n* Supported Platforms: Linux\n* Accelerators and GPUs: NVIDIA GPUs via CUDA driver 10.\n* Dependencies:\n  * python >= 3.5, < 4\n  * llvmlite >= 0.31.0\n  * pytorch >= 1.0\n  * numba >= 0.42.0\n  * numpy >= 1.18.1\n* Install nnieqat via pypi:\n  $ pip install nnieqat\n\n<div id=\"usage\"></div>\n\n## Usage\n\n* Replace default module with NNIE quantization optimized one. include:\n  * torch.nn.modules.conv -> nnieqat.modules.conv\n  * torch.nn.modules.linear -> nnieqat.modules.linear\n  * torch.nn.modules.pooling -> nnieqat.modules.pooling\n\n  ```python\n  from nnieqat.modules import convert_layers\n  ...\n  ...\n    model = convert_layers(model)\n    print(model)  # Quantized layers have \"Quantized\" prefix.\n  ...\n  ```\n\n* Freeze bn after a few epochs of training\n\n  ```python\n  from nnieqat.gpu.quantize import freeze_bn\n  ...\n  ...\n      if epoch > 2:\n        net.apply(freeze_bn)\n  ...\n  ```\n\n* Unquantize weight before update it\n\n  ```python\n  from nnieqat.gpu.quantize import unquant_weight\n  ...\n  ...\n      net.apply(unquant_weight)\n      optimizer.step()\n  ...\n  ```\n\n* Dump weight quantized model\n\n  ```python\n  from nnieqat.gpu.quantize import quant_weight, unquant_weight\n  ...\n  ...\n      net.apply(quant_weight)\n      save_checkpoint(...)\n      net.apply(unquant_weight)\n  ...\n  ```\n\n<div id=\"examples\"></div>\n\n## Code Examples\n\n* [Cifar10 quantization aware training example][cifar10_qat]  (add nnieqat into [pytorch_cifar10_tutorial][cifar10_example])\n\n  ```python test/test_cifar10.py```\n\n* [ImageNet quantization finetuning example][imagenet_qat]  (add nnieqat into [pytorh_imagenet_main.py][imagenet_example])\n\n  ```python test/test_imagenet.py  --pretrained  path_to_imagenet_dataset```\n\n<div id=\"results\"></div>\n\n## Results  \n\n* ImageNet\n\n  ```\n  python test/test_imagenet.py /data/imgnet/ --arch squeezenet1_1  --lr 0.001 --pretrained --epoch 10   # nnie_lr_e-3_ft\n  python pytorh_imagenet_main.py /data/imgnet/ --arch squeezenet1_1  --lr 0.0001 --pretrained --epoch 10  # lr_e-4_ft\n  python test/test_imagenet.py /data/imgnet/ --arch squeezenet1_1  --lr 0.0001 --pretrained --epoch 10  # nnie_lr_e-4_ft\n  ```\n\n  finetune result：\n\n    |     | trt_fp32 | trt_int8     | nnie     |\n    | -------- |  -------- | -------- | -------- |\n    | torchvision     | 0.56992  | 0.56424  | 0.56026 |\n    | nnie_lr_e-3_ft | 0.56600   | 0.56328   | 0.56612 |\n    | lr_e-4_ft  | 0.57884   | 0.57502   | 0.57542 |\n    | nnie_lr_e-4_ft | 0.57834   | 0.57524   | 0.57730 |  \n\n\n<div id=\"Todo\"></div>\n\n## Todo\n\n* Multiple GPU training support.\n* Other platforms and accelerators support.\n* Generate quantized model directly.\n\n<div id=\"reference\"></div>  \n\n## Reference\n\nHiSVP 量化库使用指南\n\n[Quantizing deep convolutional networks for efficient inference: A whitepaper][quant_whitepaper]\n\n[8-bit Inference with TensorRT][trt_quant]\n\n[Distilling the Knowledge in a Neural Network][distillingNN]\n\n[cifar10_qat]: https://gitlab.deepglint.com/chenMQ/nnieqat-pytorch/-/blob/master/test/test_cifar10.py\n\n[imagenet_qat]: https://gitlab.deepglint.com/chenMQ/nnieqat-pytorch/-/blob/master/test/test_imagenet.py\n\n[imagenet_example]: https://github.com/pytorch/examples/blob/master/imagenet/main.py\n\n[cifar10_example]: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n\n[quant_whitepaper]: https://arxiv.org/abs/1806.08342\n\n[trt_quant]: https://on-demand.gputechconf.com/gtc/2017/presentation/s7310-8-bit-inference-with-tensorrt.pdf\n\n[distillingNN]: https://arxiv.org/abs/1503.02531\n\n[apprentice]: https://arxiv.org/abs/1711.05852\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/aovoc/nnieqat-pytorch",
    "keywords": "quantization aware training,deep learning,neural network,CNN,machine learning",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "nnieqat",
    "package_url": "https://pypi.org/project/nnieqat/",
    "platform": "",
    "project_url": "https://pypi.org/project/nnieqat/",
    "project_urls": {
      "Homepage": "https://github.com/aovoc/nnieqat-pytorch"
    },
    "release_url": "https://pypi.org/project/nnieqat/0.1.0b0/",
    "requires_dist": [
      "torch (>=1.0)",
      "numba (>=0.42.0)",
      "numpy (>=1.18.1)",
      "torchvision (>=0.4) ; extra == 'test'"
    ],
    "requires_python": ">=3.5, <4",
    "summary": "A nnie quantization aware training tool on pytorch.",
    "version": "0.1.0b0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8083247,
  "releases": {
    "0.1.0b0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "494567489fefc1d9efa5ef5d6de0c7c9eafde86066e72681ed8ea3c5b2c496e0",
          "md5": "bbaa8b7c5491a846cb918e00726118bc",
          "sha256": "024229a8c8de835da2e2d73c6689a16970a732dd21529ed0a7489f4b7a337913"
        },
        "downloads": -1,
        "filename": "nnieqat-0.1.0b0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "bbaa8b7c5491a846cb918e00726118bc",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.5, <4",
        "size": 818430,
        "upload_time": "2020-08-16T13:21:48",
        "upload_time_iso_8601": "2020-08-16T13:21:48.213402Z",
        "url": "https://files.pythonhosted.org/packages/49/45/67489fefc1d9efa5ef5d6de0c7c9eafde86066e72681ed8ea3c5b2c496e0/nnieqat-0.1.0b0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "70f8183569e2141a800f176d287faaf1bc4da31bb64f89874af0e0551d9b6508",
          "md5": "89d1035b2debd377f12d17952b3ad741",
          "sha256": "64eed27eef6fae519e01bea098d308b98864ac63c6c169bb14e271eff24bc0c3"
        },
        "downloads": -1,
        "filename": "nnieqat-0.1.0b0.tar.gz",
        "has_sig": false,
        "md5_digest": "89d1035b2debd377f12d17952b3ad741",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5, <4",
        "size": 812028,
        "upload_time": "2020-08-16T13:21:52",
        "upload_time_iso_8601": "2020-08-16T13:21:52.134840Z",
        "url": "https://files.pythonhosted.org/packages/70/f8/183569e2141a800f176d287faaf1bc4da31bb64f89874af0e0551d9b6508/nnieqat-0.1.0b0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "494567489fefc1d9efa5ef5d6de0c7c9eafde86066e72681ed8ea3c5b2c496e0",
        "md5": "bbaa8b7c5491a846cb918e00726118bc",
        "sha256": "024229a8c8de835da2e2d73c6689a16970a732dd21529ed0a7489f4b7a337913"
      },
      "downloads": -1,
      "filename": "nnieqat-0.1.0b0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "bbaa8b7c5491a846cb918e00726118bc",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.5, <4",
      "size": 818430,
      "upload_time": "2020-08-16T13:21:48",
      "upload_time_iso_8601": "2020-08-16T13:21:48.213402Z",
      "url": "https://files.pythonhosted.org/packages/49/45/67489fefc1d9efa5ef5d6de0c7c9eafde86066e72681ed8ea3c5b2c496e0/nnieqat-0.1.0b0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "70f8183569e2141a800f176d287faaf1bc4da31bb64f89874af0e0551d9b6508",
        "md5": "89d1035b2debd377f12d17952b3ad741",
        "sha256": "64eed27eef6fae519e01bea098d308b98864ac63c6c169bb14e271eff24bc0c3"
      },
      "downloads": -1,
      "filename": "nnieqat-0.1.0b0.tar.gz",
      "has_sig": false,
      "md5_digest": "89d1035b2debd377f12d17952b3ad741",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.5, <4",
      "size": 812028,
      "upload_time": "2020-08-16T13:21:52",
      "upload_time_iso_8601": "2020-08-16T13:21:52.134840Z",
      "url": "https://files.pythonhosted.org/packages/70/f8/183569e2141a800f176d287faaf1bc4da31bb64f89874af0e0551d9b6508/nnieqat-0.1.0b0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}