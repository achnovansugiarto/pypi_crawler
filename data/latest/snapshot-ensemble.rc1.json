{
  "info": {
    "author": "Adam Wu",
    "author_email": "adamwu1@outlook.com",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python",
      "Topic :: Scientific/Engineering :: Artificial Intelligence",
      "Topic :: Scientific/Engineering :: Information Analysis"
    ],
    "description": "[![Build](https://img.shields.io/github/workflow/status/adamvvu/snapshot_ensemble/Unit%20Tests?style=for-the-badge)](https://github.com/adamvvu/snapshot_ensemble/actions/workflows/snapshot_ensemble_tests.yml)\n\n[![PyPi](https://img.shields.io/pypi/v/snapshot_ensemble?style=for-the-badge)](https://pypi.org/project/snapshot_ensemble/)\n\n[![Downloads](https://img.shields.io/pypi/dm/snapshot_ensemble?style=for-the-badge)](https://pypi.org/project/snapshot_ensemble/)\n\n[![License](https://img.shields.io/pypi/l/snapshot_ensemble?style=for-the-badge)](https://github.com/adamvvu/snapshot_ensemble/blob/master/LICENSE)\n\n\n\nTrain TensorFlow Keras models with cosine annealing and save an ensemble of models with no additional computational expense.\n\n\n\n------------------------------------------------------------------------\n\n\n\n## **snapshot_ensemble**\n\n\n\nEnsembles of machine learning models have empirically demonstrated\n\nstate-of-the-art results in many regression and classification tasks.\n\nDeep neural networks are popular models given their flexibility and\n\ntheoretical properties, but ensembling several independent neural networks \n\nis often impractical due to the computational expense.\n\n\n\nHuang et al. (2017) proposes the simple idea of *Snapshot Ensembling*, where\n\na single neural network is trained via cyclic learning rate schedules such as\n\ncosine annealing (Loshchilov and Hutter, 2017). At the end of each annealing cycle,\n\nthe model parameters are saved and thus we obtain an ensemble of trained neural\n\nnetworks at the cost of training a single one.\n\n\n\nConceptually, we may think of this as letting the neural network quickly converge \n\nby using a decaying learning rate, and then saving the model at several \n\nlocal minima of the loss surface. We may then used the saved models as part of\n\nan ensemble for prediction or inference.\n\n\n\nThis simple library is an implementation of their ideas as a TensorFlow 2 Keras Callback\n\nto be used during training.\n\n\n\n[Documentation](https://adamvvu.github.io/snapshot_ensemble/docs/)\n\n\n\n## Getting Started\n\n\n\n### Installation\n\n\n\n`pip install snapshot_ensemble`\n\n\n\n#### Dependencies:\n\n\n\n    # Required\n\n    python >= 3.6\n\n    numpy\n\n    tensorflow >= 2.0\n\n\n\n    # Suggested\n\n    matplotlib\n\n\n\n### Usage\n\n\n\n``` python\n\nfrom snapshot_ensemble import SnapshotEnsembleCallback\n\n\n\nmodel = # Compiled TensorFlow 2 Keras model\n\n\n\n# Train the Keras model with Cosine Annealing + Snapshot Ensembling\n\nsnapshotCB = SnapshotEnsembleCallback()\n\nmodel.fit(*args,\n\n          callbacks = [ snapshotCB ]\n\n        )\n\n\n\n# Snapshotted models are then automatically saved (default: `Ensemble/`)\n\n# and may be loaded in for ensembled predictions or inference\n\n```\n\n\n\n### Dynamic Learning Rate Schedule\n\n\n\nThe learning rate schedule inside `SnapshotEnsembleCallback` takes the following parameters:  \n\n    -`cycle_length` : Initial number of epochs per cycle  \n\n    -`cycle_length_multiplier` : Multiplier on number of epochs per cycle  \n\n    -`lr_init` : Initial maximum learning rate  \n\n    -`lr_min` : Initial minimum learning rate  \n\n    -`lr_multiplier` : Multiplier on learning rate per cycle  \n\n\n\nThe `cycle_length`, `lr_init`, and `lr_min` parameters control the initial length and learning rate bounds of each cycle. \n\nThe `*_multiplier` parameters allow for dynamically adjusting the length and/or learning rate bounds as training\n\nprogresses. It is very likely that the default parameters are suboptimal for your task, so these hyperparameters\n\nwill need to be tuned. There is a helper function `VisualizeLR()` to visualize the learning rate schedule.\n\n\n\n<p align=\"middle\">\n\n    <img src=\"assets/LR0.png\" width=\"32%\" />\n\n    <img src=\"assets/LR1.png\" width=\"32%\" />\n\n    <img src=\"assets/LR2.png\" width=\"32%\" />\n\n</p>\n\n\n\n<p style=\"text-align: center;\">\n\n    <em>\n\n    (Left) Standard Cosine Annealing (Middle) Dynamic length (Right) Dynamic length and learning rate bounds\n\n    </em>\n\n</p>\n\n\n\n### Example\n\n\n\nFor a full example, see this\n\n[notebook](https://adamvvu.github.io/snapshot_ensemble/examples/Example.ipynb).\n\n\n\n## References\n\n\n\nHuang, G., Li, Y., & Pleiss, G. (2017). Snapshot Ensembles: Train 1, Get M for Free. \n\n   International Conference on Learning Representations. https://doi.org/https://doi.org/10.48550/arXiv.1704.00109\n\n\n\nLoshchilov, I., & Hutter, F. (2017). SGDR: Stochastic Gradient Descent with Warm Restarts. \n\n    International Conference on Learning Representations. https://doi.org/https://doi.org/10.48550/arXiv.1608.03983\n\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/adamvvu/snapshot_ensemble",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "snapshot-ensemble",
    "package_url": "https://pypi.org/project/snapshot-ensemble/",
    "platform": null,
    "project_url": "https://pypi.org/project/snapshot-ensemble/",
    "project_urls": {
      "Homepage": "https://github.com/adamvvu/snapshot_ensemble"
    },
    "release_url": "https://pypi.org/project/snapshot-ensemble/1.0.0/",
    "requires_dist": [
      "numpy",
      "tensorflow",
      "matplotlib"
    ],
    "requires_python": ">=3.6",
    "summary": "Train TensorFlow Keras models with Cosine Annealing and save an ensemble of models with no additional computational expense.",
    "version": "1.0.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14795404,
  "releases": {
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0a47e70e47ad83dcffbea0ab9ea93b184d26bce54bba6eaf505489ebbc2dd9d2",
          "md5": "6a582967bb921348ef13124eb6a33beb",
          "sha256": "f5cc57d2f35d38a703e4563d4b11be5c78148c6fd8bb2ddb7763d256bc44b74f"
        },
        "downloads": -1,
        "filename": "snapshot_ensemble-1.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "6a582967bb921348ef13124eb6a33beb",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 7353,
        "upload_time": "2022-08-18T01:12:11",
        "upload_time_iso_8601": "2022-08-18T01:12:11.851370Z",
        "url": "https://files.pythonhosted.org/packages/0a/47/e70e47ad83dcffbea0ab9ea93b184d26bce54bba6eaf505489ebbc2dd9d2/snapshot_ensemble-1.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b89f4aea753cd0633be1c70e0b1370d7032b71693b9913363f1712cab30fc1b5",
          "md5": "c5f21c35eb26ea1fce12bd82456054bf",
          "sha256": "a3e9b28a48760bb255314c5c3b2d259d7bb35ae9b01237046b036fec92889b2d"
        },
        "downloads": -1,
        "filename": "snapshot_ensemble-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "c5f21c35eb26ea1fce12bd82456054bf",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 6572,
        "upload_time": "2022-08-18T01:12:14",
        "upload_time_iso_8601": "2022-08-18T01:12:14.080560Z",
        "url": "https://files.pythonhosted.org/packages/b8/9f/4aea753cd0633be1c70e0b1370d7032b71693b9913363f1712cab30fc1b5/snapshot_ensemble-1.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "0a47e70e47ad83dcffbea0ab9ea93b184d26bce54bba6eaf505489ebbc2dd9d2",
        "md5": "6a582967bb921348ef13124eb6a33beb",
        "sha256": "f5cc57d2f35d38a703e4563d4b11be5c78148c6fd8bb2ddb7763d256bc44b74f"
      },
      "downloads": -1,
      "filename": "snapshot_ensemble-1.0.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "6a582967bb921348ef13124eb6a33beb",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 7353,
      "upload_time": "2022-08-18T01:12:11",
      "upload_time_iso_8601": "2022-08-18T01:12:11.851370Z",
      "url": "https://files.pythonhosted.org/packages/0a/47/e70e47ad83dcffbea0ab9ea93b184d26bce54bba6eaf505489ebbc2dd9d2/snapshot_ensemble-1.0.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "b89f4aea753cd0633be1c70e0b1370d7032b71693b9913363f1712cab30fc1b5",
        "md5": "c5f21c35eb26ea1fce12bd82456054bf",
        "sha256": "a3e9b28a48760bb255314c5c3b2d259d7bb35ae9b01237046b036fec92889b2d"
      },
      "downloads": -1,
      "filename": "snapshot_ensemble-1.0.0.tar.gz",
      "has_sig": false,
      "md5_digest": "c5f21c35eb26ea1fce12bd82456054bf",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 6572,
      "upload_time": "2022-08-18T01:12:14",
      "upload_time_iso_8601": "2022-08-18T01:12:14.080560Z",
      "url": "https://files.pythonhosted.org/packages/b8/9f/4aea753cd0633be1c70e0b1370d7032b71693b9913363f1712cab30fc1b5/snapshot_ensemble-1.0.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}