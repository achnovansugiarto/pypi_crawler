{
  "info": {
    "author": "Jhon Freddy Puentes",
    "author_email": "jfredypuentes@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Intended Audience :: Developers",
      "Intended Audience :: Education",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Topic :: Scientific/Engineering",
      "Topic :: Software Development"
    ],
    "description": "<h1 align=\"center\">spanlp</h1>\n\n<p align=\"center\">\n  <br>\n  <i>spanlp es una librer√≠a escrita en Python para detectar, censurar  y limpiar groser√≠as, <br>\n      vulgaridades, palabras de odio, racismo, xenofobia y bullying en textos escritos en <strong>Espa√±ol</strong>.\n    </i>\n  <br>\n\n  <p align=\"center\">\n    <a href=\"https://test.pypi.org/project/spanlp/\">\n      <img src=\"https://img.shields.io/badge/version-v1.1.0-green\"/>\n    </a>\n    <a href=\"https://test.pypi.org/project/spanlp/\">\n      <img src=\"https://img.shields.io/badge/status-stable-blue\"/>\n    </a>\n  <a href=\"https://test.pypi.org/project/spanlp/\">\n      <img src=\"https://img.shields.io/badge/release-v1.1.0-brightgreen\"/>\n    </a>\n    <a href=\"https://test.pypi.org/project/spanlp/\">\n      <img src=\"https://img.shields.io/badge/test--pypi-v0.0.7-yellow\"/>\n    </a>\n  <a href=\"https://test.pypi.org/project/spanlp/\">\n      <img src=\"https://img.shields.io/badge/license-MIT-brightgreen\"/>\n    </a>\n  </p>\n\n  <p align=\"center\">\n    <img alt=\"GitHub Repo stars\" src=\"https://img.shields.io/github/stars/jfreddypuentes/spanlp?style=social\">\n  </p>\n</p>\n\n<hr>\n\n## Indice\n- [Indice](#indice)\n- [Sobre la librer√≠a](#sobre-la-librer√≠a)\n- [Casos de uso](#casos-de-uso)\n- [Status Desarrollo](#status-desarrollo)\n- [Instalaci√≥n](#instalaci√≥n)\n- [Funcionamiento](#funcionamiento)\n  - [Uso b√°sico](#uso-basico)\n  - [Uso avanzado](#uso-avanzado)\n  - [Pre-procesamiento de datos](#preprocesamiento-de-texto)\n- [Beta Testing](#beta-testing)\n- [Reportar un bug](#reportar-un-bug)\n- [Contribuidorxs](#contribuidorxs)\n- [Contacto](#contacto)\n\n<hr>\n\n## Sobre la librer√≠a\nspanlp es una librer√≠a escrita en Python para detecci√≥n de groser√≠as, vulgaridades, palabras de odio, racismo, xenofobia y bullying en textos escritos en Espa√±ol. Puedes usar la librer√≠a y aplicarla a palabras de cualquiera de los m√°s de **20 paises** de habla hispana.\n\nIncluye:\n1. Argentina üá¶üá∑\n2. Bolivia üáßüá¥\n3. Chile üá®üá±\n4. Colombia üá®üá¥\n5. Costa Rica üá®üá∑\n6. Cuba üá®üá∫\n7. Ecuador üá™üá®\n8. El Salvador üá∏üáª\n9. Espa√±a üá™üá∏\n10. Guatemala üá¨üáπ\n11. Guinea Ecuatorial üá¨üá∂\n12. Honduras üá≠üá≥\n13. M√©xico üá≤üáΩ\n14. Nicaragua üá≥üáÆ\n15. Panam√° üáµüá¶\n16. Paraguay üáµüáæ\n17. Per√∫ üáµüá™\n18. Puerto Rico üáµüá∑\n19. Rep√∫blica Dominicana üá©üá¥\n20. Uruguay üá∫üáæ\n21. Venezuela üáªüá™\n\n## Casos de uso\n* Censurar vulgaridades en un texto.\n* Detectar y censurar vulgaridades en una sala de chat en linea.\n* Encontrar y censurar frases y palabras de odio, racismo, xenofia, bullying. (Se deben incluir como par√°metros)\n* Censurar comentarios groseros o insultos en alg√∫n blog o aplicaci√≥n web o sitio web.\n* Censurar malas palabras en un sistema de recolecci√≥n de opiniones, sugerencias, quejas y reclamos.\n* Limpiar textos antes de ser publicados.\n* Detectar y eliminar vulgaridades en textos que ser√°n leidos y/o vistos por ni√±os.\n* Limpiar una base de datos con mucho texto.\n\n## Status Desarrollo\n\n| Funcionalidad                     | Desarrollo |   Pruebas   | Release  |\n|-----------------------------------|------------|-------------|-----------\n| Soporte de tokens con n√∫meros     |     ‚úì      |      ‚úì      | v0.0.5   |  \n| Estrategias de limpieza de datos  |     ‚úì      |      ‚úì      | v0.0.5   |\n| Completar dataset                 |     ‚úì      |      ‚úì      | v1.0.1   |\n| Hamming                           |     ‚úì      |      ‚úì      | v1.0.2   |\n| Levenstein                        |     ‚úì      |      ‚úì      | v1.1.0   |\n| Bag distance                      |     -      |             |    -     |\n| Sorensen-Dice coefficient         |     -      |             |    -     |\n| Tversky index                     |     -      |             |    -     |\n| Overlap index                     |     -      |             |    -     |\n| Tanimoto distance                 |     -      |             |    -     |\n| Ampliaci√≥n datasets               |  Progreso  |      -      |    -     |\n\n\n## Instalaci√≥n\nPara instalar la √∫ltima versi√≥n use:\n```console\npip install spanlp\n```\n\nPara instalar una versi√≥n espec√≠fica use (por ejemplo):\n```\npip install spanlp==1.1.0\n```\n\n## Funcionamiento\nLos algoritmos y modulos se personalizan de forma din√°mica y muy flexible. Veamos algunos usos.\n\n### Uso b√°sico\n\nValidar si una palabra o frase contiene o no una palabrota:\n```python\nfrom spanlp.palabrota import Palabrota\npalabrota = Palabrota()\nprint(palabrota.contains_palabrota(\"Hola huevon c√≥mo est√°?\"))\n# salida: True\n```\n\n```python\nfrom spanlp.palabrota import Palabrota\npalabrota = Palabrota()\nprint(palabrota.contains_palabrota(\"Hola a todos ¬øc√≥mo est√°n?\"))\n# salida: False\n```\n\nCensurar una frase con los par√°metros por defecto:\n\n```python\nfrom spanlp.palabrota import Palabrota\n\npalabrota = Palabrota()\nprint(palabrota.censor(\"Hola huevon c√≥mo est√°?\"))\n\n# salida: Hola !$%#@! c√≥mo est√°?\n```\n\nCensurar la misma frase, configurando car√°cteres propios\n\n```python\nfrom spanlp.palabrota import Palabrota\n\npalabrota = Palabrota(censor_char=\"*\")\nprint(palabrota.censor(\"Hola huevon como est√°?\"))\n\n# salida: Hola ****** c√≥mo est√°?\n```\n\nCensurar otra frase, configurando car√°cteres propios y pa√≠s\n\n```python\nfrom spanlp.palabrota import Palabrota\nfrom spanlp.domain.countries import Country\n\npalabrota = Palabrota(censor_char=\"@\", countries=[Country.COLOMBIA, Country.VENEZUELA])\nprint(palabrota.censor(\"Hola huevon marico c√≥mo est√°?\"))\n\n# salida: Hola @@@@@@ @@@@@@ c√≥mo est√°?\n```\n\nCensuremos la misma frase pero solo con el pa√≠s de Venezuela\n```python\nfrom spanlp.palabrota import Palabrota\nfrom spanlp.domain.countries import Country\n\npalabrota = Palabrota(censor_char=\"@\", countries=[Country.VENEZUELA])\nprint(palabrota.censor(\"Hola huevon marico c√≥mo est√°?\"))\n\n# salida: Hola huevon @@@@@@ c√≥mo est√°?\n```\n\nCensuremos la misma frase pero incluyendo \"huevon\" al vocabulario de Venezuela\n```python\nfrom spanlp.palabrota import Palabrota\nfrom spanlp.domain.countries import Country\n\npalabrota = Palabrota(censor_char=\"@\", countries=[Country.VENEZUELA], include=[\"huevon\"])\nprint(palabrota.censor(\"Hola huevon marico c√≥mo est√°?\"))\n\n# salida: Hola @@@@@@ @@@@@@ c√≥mo est√°?\n```\n\nCensuremos la misma frase incluyendo \"huevon\" al vocabulario de Venezuela y excluyendo \"marico\"\n```python\nfrom spanlp.palabrota import Palabrota\nfrom spanlp.domain.countries import Country\n\npalabrota = Palabrota(censor_char=\"@\", countries=[Country.VENEZUELA], include=[\"huevon\"], exclude=[\"marico\"])\nprint(palabrota.censor(\"Hola huevon marico c√≥mo est√°?\"))\n\n# salida: Hola huevon marico c√≥mo est√°?\n```\n\nCensuremos la misma frase incluyendo \"\"Hola\" y \"huevon\" al vocabulario de Venezuela y excluyendo \"marico\"\n```python\nfrom spanlp.palabrota import Palabrota\nfrom spanlp.domain.countries import Country\n\npalabrota = Palabrota(censor_char=\"-\", countries=[Country.VENEZUELA], include=[\"huevon\"], exclude=[\"marico\"])\nprint(palabrota.censor(\"Hola huevon marico c√≥mo est√°?\"))\n\n# salida: ---- ---- marico c√≥mo est√°?\n```\n\n### Uso Avanzado\nEl uso avanzado incluye usar metricas de distancia y similitud para encontrar, comparar, censurar palabras.\nEstas son las metricas usadas a la fecha:\n1. [ES-Indice de Jaccard](https://es.wikipedia.org/wiki/%C3%8Dndice_Jaccard) ([EN-Jaccard Index](https://en.wikipedia.org/wiki/Jaccard_index))\n2. [ES-Similitud del coseno](https://es.wikipedia.org/wiki/Similitud_coseno) ([EN-Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity))\n3. [ES-Levenshtein](https://es.wikipedia.org/wiki/Distancia_de_Levenshtein)([EN-Levenshtein](https://en.wikipedia.org/wiki/Levenshtein_distance))\n4. [ES-Damerau-Levenshtein](https://es.wikipedia.org/wiki/Distancia_de_Damerau-Levenshtein)([EN-Damerau-Levenshtein](https://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance))\n\nCensuremos la frase usando Cosine Similarity \n```python\nfrom spanlp.palabrota import Palabrota\nfrom spanlp.domain.countries import Country\nfrom spanlp.domain.strategies import CosineSimilarity\n\npalabrota = Palabrota(censor_char=\"*\", countries=[Country.VENEZUELA], distance_metric=CosineSimilarity())\nprint(palabrota.censor(\"Hola huevo maric c√≥mo est√°?\"))\n\n# salida: Hola huevo ***** c√≥mo est√°?\n```\nA pesar de que \"maric\" no est√° en el dataset, al algoritmo la censur√≥ dado que por la m√©trica de distancia es muy similar. \n\n\nCensuremos la frase usando **Cosine Similarity** manipulando los par√°metros\n```python\nfrom spanlp.palabrota import Palabrota\nfrom spanlp.domain.countries import Country\nfrom spanlp.domain.strategies import CosineSimilarity\n\n# Indicamos que tenga en cuenta palabras similares en al menos 30% y que normalice los datos (poner en minusculas, remover acentos)\ncosine = CosineSimilarity(0.9, normalize=True) \npalabrota = Palabrota(censor_char=\"*\", countries=[Country.VENEZUELA], distance_metric=cosine)\nprint(palabrota.censor(\"Hola huevon MARIC c√≥mo est√°?\"))\n\n# salida: hola huevon ***** **** esta? => Censur√≥ \"como\" porque en el dataset est√° \"cono\" y son similares en m√°s del 90%\n```\n\nCensuremos la frase usando **JaccardIndex** con los par√°metros por defecto\n```python\nfrom spanlp.palabrota import Palabrota\nfrom spanlp.domain.countries import Country\nfrom spanlp.domain.strategies import JaccardIndex\n\npalabrota = Palabrota(censor_char=\"*\", countries=[Country.VENEZUELA], distance_metric=JaccardIndex())\nprint(palabrota.censor(\"Hola huevo maric c√≥mo est√°?\"))\n\n# salida: Hola huevo ***** c√≥mo est√°?\n```\nEl indice de Jaccard usa por defecto los siguientes par√°metros:\n* `threshold=0.8` - Indica que censurar√° palabras con una similitud del 80% o m√°s.\n* `normalize=False` - False indica que no pasar√° el texto a minuscula y no remover√° acentos.\n* `n_gram=2` - Usa 2 subsecuencias de la palabra. (Ver [N-grama](https://es.wikipedia.org/wiki/N-grama))\n\nCensuremos la frase usando **JaccardIndex** y modifiquemos los par√°metros\n```python\nfrom spanlp.palabrota import Palabrota\nfrom spanlp.domain.countries import Country\nfrom spanlp.domain.strategies import JaccardIndex\n\njaccard = JaccardIndex(threshold=0.9, normalize=True, n_gram=1)\npalabrota = Palabrota(censor_char=\"*\", countries=[Country.VENEZUELA], distance_metric=jaccard)\nprint(palabrota.censor(\"Hola huevon marica c√≥mo vamos?\"))\n\n# salida: hola huevon ****** **** vamos?\n```\n\nAhora, sin normalizar los datos\n```python\nfrom spanlp.palabrota import Palabrota\nfrom spanlp.domain.countries import Country\nfrom spanlp.domain.strategies import JaccardIndex\n\njaccard = JaccardIndex(threshold=0.9, normalize=False, n_gram=1)\npalabrota = Palabrota(censor_char=\"*\", countries=[Country.VENEZUELA], distance_metric=jaccard)\nprint(palabrota.censor(\"Hola huevon marica c√≥mo vamos?\"))\n\n# salida: Hola huevon ****** c√≥mo vamos? => \"moco\" y \"c√≥mo\" ahora son muy diferentes.\n```\n\nAhora, bajemos el `threshold` a `0.6`\n```python\nfrom spanlp.palabrota import Palabrota\nfrom spanlp.domain.countries import Country\nfrom spanlp.domain.strategies import JaccardIndex\n\njaccard = JaccardIndex(threshold=0.6, normalize=False, n_gram=1)\npalabrota = Palabrota(censor_char=\"*\", countries=[Country.VENEZUELA], distance_metric=jaccard)\nprint(palabrota.censor(\"Hola huevon marica c√≥mo vamos?\"))\n\n# salida: Hola ****** ****** c√≥mo vamos? => Ha censurado una palabra m√°s.\n```\n\nAumentemos la cantidad de `n_gram` a `3` con el `threshold=0.7` y con `normalize=False`\n```python\nfrom spanlp.palabrota import Palabrota\nfrom spanlp.domain.countries import Country\nfrom spanlp.domain.strategies import JaccardIndex\n\njaccard = JaccardIndex(threshold=0.7, normalize=False, n_gram=3)\npalabrota = Palabrota(censor_char=\"*\", countries=[Country.VENEZUELA], distance_metric=jaccard)\nprint(palabrota.censor(\"Hola huevon marica c√≥mo vamos?\"))\n\n# salida: Hola huevon marica c√≥mo vamos? => No censur√≥ nada.\n```\n\n## Preprocesamiento de texto\nSiempre ser√° necesario limpiar los datos antes de empezar a trabajar. Aqui te presento la clase `Preprocessing` y las 28 estrat√©gias de limpieza de datos.\n\n¬øCuantas estrategias hay y cuales son?\n\nSon 28 algoritmos y son:\n\n1. `TextToLower` **input**: \"HOLA QUE M√ÅS?\" **output:** \"hola que m√°s?\"\n2. `TextToUpper` **input:** \"hola ¬øc√≥mo est√°n?\" **output:** \"HOLA ¬øC√ìMO EST√ÅN?\"\n3. `RemoveUnicodeCharacters` **input:** \"hola √ßcomo ¬™van?\" **output:** \"hola como van\"  ([Unicode characters](https://www.rapidtables.com/code/text/unicode-characters.html))\n4. `NumbersToVowelsInLowerCase` **input:** \"h0l4 qu3 t4l?\" **ouput:** \"hola que tal?\"\n5. `NumbersToVowelsInUpperCase` **input:** \"H0l4 c0m0 v4n?\" **output:** \"HOlA cOmO vAn?\"\n6. `NumbersToConsonantsInLowerCase` **input:** \"C0m0 e574n? 8i3n?\" **output:** \"Como estan? bien?\"\n7. `NumbersToConsonantsInUpperCase` **input:** \"C0m0 e574n? 8i3n?\" **output:** \"COMO ESTAN? BIEN?\"\n8. `RemoveExtraSpaces` **input:** \"Hola   como est√°n?   \" **output:** \"Hola como est√°n?\"\n9. `RemoveUserMentions` **input:** \"Hola @channel como van?\" **output:** \"CHola como van?\"\n10. `RemoveUrls`  **input:** \"Revisen este recurso https://github.com/jfreddypuentes/spanlp\" **output:** \"Revisen este recurso \"\n11. `RemoveHashtags` **input:** \"Hola #equipo bienvenidos\" **output:** \"Hola  bienvenidos\"\n12. `RemoveTicks` **input:** \"Hola, que' m√°s'\" **output:** \"Hola, que m√°s\"\n13. `RemoveBackTicks` **input:** \"Hola, que` m√°s`\" **output:** \"Hola, que m√°s\"\n14. `RemovePunctuation`  **input:** \"Mensaje...,con, puntos\" **output:** \"Mensaje con puntos\"\n15. `RemoveNumbers` **input:** \"Hay 12 patacones  y 20 yucas\" **output:** \"Hay patacones y yucas\"\n16. `RemoveAccents` **input:** \"La canci√≥n es una sensaci√≥n\" **output:** \"La cancion es una sensacion\"\n17. `RemoveStopWords` **input:** \"La canci√≥n y la letra es buena\" **output:** \"canci√≥n letra buena\"\n18. `RemoveArticles` **input:** \"La canci√≥n y la letra es buena\" **output:** \"canci√≥n y letra es buena\"\n19. `RemoveEmoticons` **input:** \"Hola ;) como est√°s? XD\" **output:** \"Hola como est√°s?\"\n20. `RemovePronouns` **input:** \"Yo pienso que ella deber√≠a ser como √©l\" **output:** \"pienso que deber√≠a ser como\"\n21. `RemoveAdverbs` **input:** \"muchos a√±os despues frente al peloton de fusilamiento lentamente recordaba...\" **output:** \"muchos a√±os frente al peloton de fusilamiento recordaba...\"\n22. `RemoveConjunctions` **input:** \"y entonces estaba programando aunque con sue√±o pero concentrado creando esta libreria\" **output:** \"entonces estaba programando con sue√±o concentrado creando esta libreria\"\n23. `RemovePrepositions` **input:** \"ante todo es mejor cuidar a la naturaleza mediante buenas acciones. entre todos podemos.\" **output:** \"todo es mejor cuidar la naturaleza buenas acciones. todos podemos.\"\n24. `RemoveAdjectives` **input:** \"la voz era tenebrosa y la noche estaba fria y oscura hasta que de pronto algo luminoso apareci√≥ y\" **output:** \"la voz era y la noche estaba y hasta que de pronto algo apareci√≥ y\"\n25. `RemoveHtmlTags` **input:** \"Hola <strong>USUARIO</strong> que tal?\" **output:** \"Hola USUARIO que tal?\"\n26. `RemoveEmailAddress` **input:** \"Hola Pepito, el correo es contacto@domain.com\" **output:** \"Hola Pepito, el correo es \"\n27. `ExpandAbbreviations` **input:** \"pero xq tengo es3 si yo estaba bn en clase, ahora me duelen to2 los musculos\" **output:** \"pero por que tengo estres si yo estaba bien en clase, ahora me duelen todos los musculos\"\n28. `RemoveAbbreviations` **input:** \"xfa pongase el tapabocas pq me da es3 verlo sin eso. to2 debemos cuidarnos. chas gracias. salu2\" **output:** \"pongase el tapabocas me da verlo sin eso. debemos cuidarnos. gracias.\"\n\n\nLa nueva clase `Preprocessing` implementa de manera flexible y din√°mica cualquier estrategia de limpieza de una manera muy simple. Se puede aplicar dentro de una metrica de distancia como `JaccardIndex` o `CosineSimilarity` para darle m√°s poder a la busqueda, dismunir el riesgo de no encontrar las palabras a censurar y aumentar la posibilidad de censurar las palabras que son por el hecho de estar limpias.\n\n\nVeamos algunos ejemplos:\n\n```python\nfrom spanlp.domain.strategies import Preprocessing, TextToLower\n\nstrategies = [TextToLower()] # Defino mis estrategias de limpieza o pre-procesamiento\ndata = \"ESTARE EN MINUSCULA\" # Tengo mis datos\nresult = Preprocessing(data=data, clean_strategies=strategies).clean() # Invoco a Preprocessing\nprint(result)\n\n# salida: estare en minuscula\n```\n\nTambien se puede as√≠:\n```python\nfrom spanlp.domain.strategies import Preprocessing, TextToLower\n\nstrategies = [TextToLower()]\ndata = \"ESTARE EN MINUSCULA\" \nresult = Preprocessing().clean(data=data, clean_strategies=strategies) # Envio los datos y las estragias al clean()\nprint(result)\n\n# salida: estare en minuscula\n```\n\nY tambien as√≠:\n```python\nfrom spanlp.domain.strategies import Preprocessing, TextToLower\n\nstrategies = [TextToLower()]\ndata = \"ESTARE EN MINUSCULA\"\npreprocessor = Preprocessing(data=data, clean_strategies=strategies)\nresult = preprocessor.clean()\nprint(result)\n\n# salida: estare en minuscula\n```\n\nY as√≠:\n```python\nfrom spanlp.domain.strategies import Preprocessing, TextToLower\n\nresult = Preprocessing(data=\"ESTARE EN MINUSCULA\", clean_strategies=[TextToLower()]).clean()\nprint(result)\n\n# salida: estare en minuscula\n```\n\n**¬øC√≥mo aplico una estrategia para que pre-preprocese mis datos dentro de la m√©trica de distancia?**\n\n\nAplicar la metrica de distancia con una estrategia de pre-procesado:\n```python\nfrom spanlp.domain.strategies import JaccardIndex, TextToLower\n\nstrategies = [TextToLower()]\njaccard_index = JaccardIndex(normalize=True, clean_strategies=strategies)\nresult = jaccard_index.calculate(\"HOLA\", \"hola\")\n\nprint(result)\n\n# salida: 1\n```\n\nUsar la m√©trica como interface para ejecutar la estrategia:\n\n```python\nfrom spanlp.domain.strategies import JaccardIndex, TextToLower\n\nstrategies = [TextToLower()]\njaccard_index = JaccardIndex(normalize=True, clean_strategies=strategies)\nresult = jaccard_index.normalize(\"HOLA ME VOY A NORMALIZAR A MINUSCULA\")\n\nprint(result)\n\n# salida: hola me voy a normalizar a minuscula\n```\n\n**Usar varias estrategias de limpieza de datos**\nNota: Las estrategias se ejecutan en el orden enviado en la lista. Recomiendo analizar primero como desea que funcione: Si primero elimina espacios extras y despues elimina signos de puntuaci√≥n y luego stop words etc.. esto depender√° de su necesidad concreta; Por lo que se pueden obtener diferentes resultados si cambia el orden de las estrategias.\n\nEnviando varias estrategias para limpiar mis datos:\n\n```python\nfrom spanlp.domain.strategies import Preprocessing, TextToLower, RemoveUserMentions, RemovePunctuation\n\nstrategies = [RemoveUserMentions(), TextToLower(), RemovePunctuation()]\ntweet = \"Hola @jhon, si viste que @freddy va a lanzar una nueva libreria Python para NLP?\"\ncleaned = Preprocessing().clean(data=tweet, clean_strategies=strategies)\n\nprint(cleaned)\n\n#salida: hola  si viste que  va a lanzar una nueva libreria python para nlp\n```\n\n**Limpiemos emoticones, pronombres y pasemos a minuscula**\n\n```python\nfrom spanlp.domain.strategies import Preprocessing, RemoveEmoticons, TextToLower, RemovePronouns\n\nstrategies = [RemoveEmoticons(), TextToLower(), RemovePronouns()]\nmessage = \"Segun ella Los emoticones <3 :) :D ;) son muy usados y esta rosa tambien @}->--\"\ncleaned = Preprocessing().clean(data=message, clean_strategies=strategies)\n\nprint(cleaned)\n\n# salida: segun los emoticones son muy usados y esta rosa tambien\n```\n\n\n## Testing\n¬øEres tester? ¬øquieres automatizar pruebas? o ¬øsimplemente aprender del open source y de las pruebas? Aventurate ya y ayudame a mejorar este proyecto!\nA continuaci√≥n encontrar√°s algunas pautas para implementar pruebas exitosas que permitar√°n encontrar posibles errores y mejoras.\n\n### 1. ¬øPor donde empezar?\n* Instalar python.\n* Instalar la librer√≠a. Esto lo logras ejecutando en la terminal el comando: `pip install -i https://test.pypi.org/simple/ spanlp`\n* Abre un nuevo script de python, importa la librer√≠a y empieza a experimentar.\n\n### 2. ¬øQu√© tipos de pruebas puedo realizar?\nExcelente pregunta! no hay limite para la creatividad; As√≠ que haz todas las pruebas que quieras e imagines. Sin embargo, aqu√≠ te dejo algunas pautas:\n\n* **Pruebas de caja negra** => Una vez instales la librer√≠a y hayas leido la documentaci√≥n; Trata de usarla sin preocuparte como funciona o como obtuvo el resultado (Las pruebas no se hacen en base al c√≥digo, sino a la interfaz); Eso si, valida que la salida o el resultado sea el que esperas. Te puedes guiar (pero no mucho) de las pruebas unitarias que est√°n en: `/spanlp/tests/test_palabrota.py`\n\n* **Pruebas de caja blanca** => Si quieres vez como funciona la libreria, estas pruebas son las tuyas. Intenta entender la estructura, los algoritmos y flujos. Una vez los comprendas, \"a dar palo\", trata de quebar o romper la l√≥gica, observa y encuentra si hay posibles formas de hacer que falle, prueba diferentes parametros, flujos, tipos de datos. Haz que falle, haz que se ponga lento! y me cuentas. ;)\n\n* **Pruebas de carga y stress** => Si lo tuyo son las pruebas de requisitos no funcionales, te invito a que sigas estos pasos para estresar la libreria y medir que tan escalable es frente a procesos de alta carga, mide la velocidad y que tan bien se comparta con miles o millones de hilos usandola al tiempo.\n\nSigue estos pasos:\n\n1. Crear una API Rest s√∫per simple. Crea el siguiente script y ll√°malo `server.py` \n\n```console\npip install flask\n```\n\n```python\nfrom flask_cors import CORS, cross_origin\nfrom flask import request\nfrom flask import json\n\nfrom spanlp.palabrota import Palabrota\n\napp = Flask(__name__)\ncors = CORS(app)\n\n@app.route('/api/v1/nlp/text/censor', methods = ['POST'])\n@cross_origin()\ndef censor():\n    try:\n        body = request.json     \n        in_message = body['message']\n\n        if in_message and len(str(in_message).strip()):\n            palabrota = Palabrota()\n            censored = palabrota.censor(in_message)\n            response = {\n                \"success\": True,\n                \"message\": \"OK\",\n                \"error_code\": 0,\n                \"data\": {\n                    'message': in_message,\n                    'censored': censored\n                }\n            }\n            return response\n        else:\n            return {\n                \"success\": False,\n                \"message\": \"Bad Request - message is required\",\n                \"error_code\": 400,\n                \"data\": {}\n            }\n    except Exception as e:\n        return {\n            \"success\": False,\n            \"message\": \"Internal Server Error - \"+str(e),\n            \"error_code\": 500,\n            \"data\": {}\n        }\n\n\nif __name__ == '__main__':\n    app.run(host='127.0.0.1', port=8080, debug=True)\n```\n\n\n```\npython server.py\n```\n\ny listo!! \n\n\n2. Consume la API desde alg√∫n cliente http como [Postman](https://www.postman.com/), [Insomnia](https://insomnia.rest/download/) y/o [SOAP UI](https://www.soapui.org/). Tambien puedes usar alguna herramienta como [Apache JMeter](https://jmeter.apache.org/); o tambien puedes crear un script python con muchos hilos que consuma la API.\n\n\n### 3. ¬øquieres escibrir unit tests y ejecutarlo de forma autom√°tica?\nClona el repositorio en tu m√°quina, abre el proyecto en tu editor favorito, ve al archivo `/spanlp/tests/test_palabrota.py` y empieza a escribir tus propios tests unitarios. Escribe cuantos quieras.\nUna vez tengas los tests listos, ejecuta el siguiente comando en la raiz del proyecto (`/spanlp/`):\n\n```console\npytest -ra\n```\n\no tambien el comando:\n\n```\npython -m pytest\n```\n\nEsto ejecutar√° de forma autom√°tica todas las pruebas programadas e indicar√° si alg√∫n test fall√≥.\n\n\n## Reportar un bug\nSi encuentras alg√∫n problema (por muy m√≠nimo que sea) reportalo [aqu√≠](https://github.com/jfreddypuentes/spanlp/issues/new). Solo necesitar√°s poner t√≠tulo y describir la falla y aportar√° un mont√≥n a que este proyecto mejore su calidad.\n\n\n## Contacto\n¬øAlguna duda? escribeme por email:  [jfredypuentes@gmail.com](mailto:jfredypuentes@gmail.com)\n\nCuentame en ([@jfreddypuentes](https://twitter.com/jfreddypuentes)) ¬øqu√© te parece est√° librer√≠a? ¬øc√≥mo la est√°s usando? ¬øQu√© le mejorar√≠as?\n\n<br>\n\n## Contribuidorxs\n* [@vivianamarquez](https://github.com/vivianamarquez) en Github, [@vivmarquez](https://twitter.com/vivmarquez) en Twitter (Data Scientist) - Contribuci√≥n al dise√±o y funcionalidades de la librer√≠a.\n* [@normacalamartinez](https://github.com/normacalamartinez) en Github (BI Developer) - Contribuci√≥n al dataset de vulgaridades por pa√≠s de habla hispana.\n\n<br>\n\n\n**Hecho con ‚ù§Ô∏èÔ∏è de Colombia para el mundo.**\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/jfreddypuentes/spanlp",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "spanlp",
    "package_url": "https://pypi.org/project/spanlp/",
    "platform": "",
    "project_url": "https://pypi.org/project/spanlp/",
    "project_urls": {
      "Homepage": "https://github.com/jfreddypuentes/spanlp"
    },
    "release_url": "https://pypi.org/project/spanlp/1.1.0/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "A fast, robust Python library to check for profanity or offensive language in Spanish strings.It contains all the rude words of Spanish-speaking countries (Argentina, Bolivia, Chile, Colombia, Costa Rica, Cuba, Ecuador, El Salvador, Espa√±a, Guatemala, Guinea Ecuatorial, Honduras, Mexico, Nicaragua, Panama, Paraguay, Peru, Puerto Rico, Dominicana, Uruguay, Venezuela)",
    "version": "1.1.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 10261377,
  "releases": {
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "023a4f76daf1ffe12c71adefd008b9c91229a582dc62ebe3b6841c9d510ea449",
          "md5": "b151a264689cdf8b40d0467fb0931992",
          "sha256": "4d344181b9eaf9563896f5bad98a95562868b4d8a4edaf8425a127f24ab36453"
        },
        "downloads": -1,
        "filename": "spanlp-1.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "b151a264689cdf8b40d0467fb0931992",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 38909,
        "upload_time": "2021-02-18T02:29:35",
        "upload_time_iso_8601": "2021-02-18T02:29:35.785944Z",
        "url": "https://files.pythonhosted.org/packages/02/3a/4f76daf1ffe12c71adefd008b9c91229a582dc62ebe3b6841c9d510ea449/spanlp-1.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "98448a654ddba936c70dba99734828819f74368b5c5b255d9700f197c2eeb3b9",
          "md5": "3b007c0c69465ba90274ff5e26ff8656",
          "sha256": "6cf77034a917f6e11014760ba79fb72bf31efd82460f5591bf26b5a73c27b23e"
        },
        "downloads": -1,
        "filename": "spanlp-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "3b007c0c69465ba90274ff5e26ff8656",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 34809,
        "upload_time": "2021-02-18T02:29:37",
        "upload_time_iso_8601": "2021-02-18T02:29:37.977583Z",
        "url": "https://files.pythonhosted.org/packages/98/44/8a654ddba936c70dba99734828819f74368b5c5b255d9700f197c2eeb3b9/spanlp-1.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "19880da0c74c575ad04e84663578c3ac72633e7326f110c7362360110bd1f9b7",
          "md5": "3ce53f56db05810947eb2febadaa6721",
          "sha256": "1407c5b983082d9ae5dc5b4c77c7733490983c9aa7395be4f5cd1fd7bed92bfc"
        },
        "downloads": -1,
        "filename": "spanlp-1.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "3ce53f56db05810947eb2febadaa6721",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 38829,
        "upload_time": "2021-02-18T02:40:14",
        "upload_time_iso_8601": "2021-02-18T02:40:14.799910Z",
        "url": "https://files.pythonhosted.org/packages/19/88/0da0c74c575ad04e84663578c3ac72633e7326f110c7362360110bd1f9b7/spanlp-1.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3f95a17ab1317bc8f125cde0e5565fbeaca1b96f2e921b28d51babd723ca77b0",
          "md5": "7b5ea0a5d739d5caf29a8e9f6e418506",
          "sha256": "3041a27c640b3a1dcaae62ba20de295447aa5a684cb87894adf95d057522f6d4"
        },
        "downloads": -1,
        "filename": "spanlp-1.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "7b5ea0a5d739d5caf29a8e9f6e418506",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 34668,
        "upload_time": "2021-02-18T02:40:18",
        "upload_time_iso_8601": "2021-02-18T02:40:18.186231Z",
        "url": "https://files.pythonhosted.org/packages/3f/95/a17ab1317bc8f125cde0e5565fbeaca1b96f2e921b28d51babd723ca77b0/spanlp-1.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "646029d9f8c2fc2cbb221238c76e62dc14d25bdfaa0fe62ead0d7c60a5541984",
          "md5": "382b61e4c13d16fd6978a0eb50300db8",
          "sha256": "253c1c45ab5befb5e9ca4f165af34b5b315799d694c65f98120ff42dc7ed2741"
        },
        "downloads": -1,
        "filename": "spanlp-1.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "382b61e4c13d16fd6978a0eb50300db8",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 40517,
        "upload_time": "2021-05-05T03:32:27",
        "upload_time_iso_8601": "2021-05-05T03:32:27.066301Z",
        "url": "https://files.pythonhosted.org/packages/64/60/29d9f8c2fc2cbb221238c76e62dc14d25bdfaa0fe62ead0d7c60a5541984/spanlp-1.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4e053b46a448579e4f0fd21f3c7d6627048b919b03fe0721a0f3f7e6ea1f4321",
          "md5": "5c427ee7c3992cf16a0fb2f9f11c5121",
          "sha256": "7d566a5110024df60b320782c72776826d51971099e7d3fc750d00d2550a503b"
        },
        "downloads": -1,
        "filename": "spanlp-1.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "5c427ee7c3992cf16a0fb2f9f11c5121",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 37156,
        "upload_time": "2021-05-05T03:32:31",
        "upload_time_iso_8601": "2021-05-05T03:32:31.056256Z",
        "url": "https://files.pythonhosted.org/packages/4e/05/3b46a448579e4f0fd21f3c7d6627048b919b03fe0721a0f3f7e6ea1f4321/spanlp-1.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "646029d9f8c2fc2cbb221238c76e62dc14d25bdfaa0fe62ead0d7c60a5541984",
        "md5": "382b61e4c13d16fd6978a0eb50300db8",
        "sha256": "253c1c45ab5befb5e9ca4f165af34b5b315799d694c65f98120ff42dc7ed2741"
      },
      "downloads": -1,
      "filename": "spanlp-1.1.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "382b61e4c13d16fd6978a0eb50300db8",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 40517,
      "upload_time": "2021-05-05T03:32:27",
      "upload_time_iso_8601": "2021-05-05T03:32:27.066301Z",
      "url": "https://files.pythonhosted.org/packages/64/60/29d9f8c2fc2cbb221238c76e62dc14d25bdfaa0fe62ead0d7c60a5541984/spanlp-1.1.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "4e053b46a448579e4f0fd21f3c7d6627048b919b03fe0721a0f3f7e6ea1f4321",
        "md5": "5c427ee7c3992cf16a0fb2f9f11c5121",
        "sha256": "7d566a5110024df60b320782c72776826d51971099e7d3fc750d00d2550a503b"
      },
      "downloads": -1,
      "filename": "spanlp-1.1.0.tar.gz",
      "has_sig": false,
      "md5_digest": "5c427ee7c3992cf16a0fb2f9f11c5121",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 37156,
      "upload_time": "2021-05-05T03:32:31",
      "upload_time_iso_8601": "2021-05-05T03:32:31.056256Z",
      "url": "https://files.pythonhosted.org/packages/4e/05/3b46a448579e4f0fd21f3c7d6627048b919b03fe0721a0f3f7e6ea1f4321/spanlp-1.1.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}