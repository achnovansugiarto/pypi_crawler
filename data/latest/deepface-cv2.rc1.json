{
  "info": {
    "author": "Lin Xiao Hui",
    "author_email": "llinxiaohui@126.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# deepface_cv2\n\n[deepface](https://github.com/serengil/deepface) with opencv, no need for tensorflow.\n\n## Why such a project\n   1. The original project need tensorflow installed, which is cumbersome?\n   2. The time cost on predict when using tensorflow is higher.\n   3. A package without depending tensorflow, is convenient.\n\n\nAll credits to the [original author](https://github.com/serengil/)\n\n# deepface\n\n<div align=\"center\">\n\n[![PyPI Downloads](https://static.pepy.tech/personalized-badge/deepface?period=total&units=international_system&left_color=grey&right_color=blue&left_text=pypi%20downloads)](https://pepy.tech/project/deepface)\n[![Conda Downloads](https://img.shields.io/conda/dn/conda-forge/deepface?color=green&label=conda%20downloads)](https://anaconda.org/conda-forge/deepface)\n[![Stars](https://img.shields.io/github/stars/serengil/deepface?color=yellow&style=flat)](https://github.com/serengil/deepface/stargazers)\n[![License](http://img.shields.io/:license-MIT-green.svg?style=flat)](https://github.com/serengil/deepface/blob/master/LICENSE)\n[![Support me on Patreon](https://img.shields.io/endpoint.svg?url=https%3A%2F%2Fshieldsio-patreon.vercel.app%2Fapi%3Fusername%3Dserengil%26type%3Dpatrons&style=flat)](https://www.patreon.com/serengil?repo=deepface)\n[![Twitter](https://img.shields.io/twitter/follow/serengil?color=blue&logo=twitter&style=flat)](https://twitter.com/serengil)\n\n[![DOI](http://img.shields.io/:DOI-10.1109/ASYU50717.2020.9259802-blue.svg?style=flat)](https://doi.org/10.1109/ASYU50717.2020.9259802)\n[![DOI](http://img.shields.io/:DOI-10.1109/ICEET53442.2021.9659697-blue.svg?style=flat)](https://doi.org/10.1109/ICEET53442.2021.9659697)\n\n</div>\n\n<p align=\"center\"><img src=\"https://raw.githubusercontent.com/serengil/deepface/master/icon/deepface-icon-labeled.png\" width=\"200\" height=\"240\"></p>\n\nDeepface is a lightweight [face recognition](https://sefiks.com/2018/08/06/deep-face-recognition-with-keras/) and facial attribute analysis ([age](https://sefiks.com/2019/02/13/apparent-age-and-gender-prediction-in-keras/), [gender](https://sefiks.com/2019/02/13/apparent-age-and-gender-prediction-in-keras/), [emotion](https://sefiks.com/2018/01/01/facial-expression-recognition-with-keras/) and [race](https://sefiks.com/2019/11/11/race-and-ethnicity-prediction-in-keras/)) framework for python. It is a hybrid face recognition framework wrapping **state-of-the-art** models: [`VGG-Face`](https://sefiks.com/2018/08/06/deep-face-recognition-with-keras/), [`Google FaceNet`](https://sefiks.com/2018/09/03/face-recognition-with-facenet-in-keras/), [`OpenFace`](https://sefiks.com/2019/07/21/face-recognition-with-openface-in-keras/), [`Facebook DeepFace`](https://sefiks.com/2020/02/17/face-recognition-with-facebook-deepface-in-keras/), [`DeepID`](https://sefiks.com/2020/06/16/face-recognition-with-deepid-in-keras/), [`ArcFace`](https://sefiks.com/2020/12/14/deep-face-recognition-with-arcface-in-keras-and-python/), [`Dlib`](https://sefiks.com/2020/07/11/face-recognition-with-dlib-in-python/) and `SFace`.\n\nExperiments show that human beings have 97.53% accuracy on facial recognition tasks whereas those models already reached and passed that accuracy level.\n\n## Installation [![PyPI](https://img.shields.io/pypi/v/deepface.svg)](https://pypi.org/project/deepface/) [![Conda](https://img.shields.io/conda/vn/conda-forge/deepface.svg)](https://anaconda.org/conda-forge/deepface)\n\nThe easiest way to install deepface is to download it from [`PyPI`](https://pypi.org/project/deepface/). It's going to install the library itself and its prerequisites as well.\n\n```shell\n$ pip install deepface\n```\n\nDeepFace is also available at [`Conda`](https://anaconda.org/conda-forge/deepface). You can alternatively install the package via conda.\n\n```shell\n$ conda install -c conda-forge deepface\n```\n\nThen you will be able to import the library and use its functionalities.\n\n```python\nfrom deepface import DeepFace\n```\n\n**Facial Recognition** - [`Demo`](https://youtu.be/WnUVYQP4h44)\n\nA modern [**face recognition pipeline**](https://sefiks.com/2020/05/01/a-gentle-introduction-to-face-recognition-in-deep-learning/) consists of 5 common stages: [detect](https://sefiks.com/2020/08/25/deep-face-detection-with-opencv-in-python/), [align](https://sefiks.com/2020/02/23/face-alignment-for-face-recognition-in-python-within-opencv/), [normalize](https://sefiks.com/2020/11/20/facial-landmarks-for-face-recognition-with-dlib/), [represent](https://sefiks.com/2018/08/06/deep-face-recognition-with-keras/) and [verify](https://sefiks.com/2020/05/22/fine-tuning-the-threshold-in-face-recognition/). While Deepface handles all these common stages in the background, you don’t need to acquire in-depth knowledge about all the processes behind it. You can just call its verification, find or analysis function with a single line of code.\n\n**Face Verification** - [`Demo`](https://youtu.be/KRCvkNCOphE)\n\nThis function verifies face pairs as same person or different persons. It expects exact image paths as inputs. Passing numpy or based64 encoded images is also welcome. Then, it is going to return a dictionary and you should check just its verified key.\n\n```python\nresult = DeepFace.verify(img1_path = \"img1.jpg\", img2_path = \"img2.jpg\")\n```\n\n<p align=\"center\"><img src=\"https://raw.githubusercontent.com/serengil/deepface/master/icon/stock-1.jpg\" width=\"95%\" height=\"95%\"></p>\n\n**Face recognition** - [`Demo`](https://youtu.be/Hrjp-EStM_s)\n\n[Face recognition](https://sefiks.com/2020/05/25/large-scale-face-recognition-for-deep-learning/) requires applying face verification many times. Herein, deepface has an out-of-the-box find function to handle this action. It's going to look for the identity of input image in the database path and it will return pandas data frame as output.\n\n```python\ndf = DeepFace.find(img_path = \"img1.jpg\", db_path = \"C:/workspace/my_db\")\n```\n\n<p align=\"center\"><img src=\"https://raw.githubusercontent.com/serengil/deepface/master/icon/stock-6-v2.jpg\" width=\"95%\" height=\"95%\"></p>\n\n**Embeddings**\n\nFace recognition models basically represent facial images as multi-dimensional vectors. Sometimes, you need those embedding vectors directly. DeepFace comes with a dedicated representation function.\n\n```python\nembedding = DeepFace.represent(img_path = \"img.jpg\")\n```\n\nThis function returns an array as output. The size of the output array would be different based on the model name. For instance, VGG-Face is the default model for deepface and it represents facial images as 2622 dimensional vectors. Here, embedding is also plotted with 2622 slots horizontally. Each slot is corresponding to a dimension value in the embedding vector and dimension value is explained in the colorbar on the right.\n\n<p align=\"center\"><img src=\"https://raw.githubusercontent.com/serengil/deepface/master/icon/embedding.jpg\" width=\"95%\" height=\"95%\"></p>\n\n**Face recognition models** - [`Demo`](https://youtu.be/i_MOwvhbLdI)\n\nDeepface is a **hybrid** face recognition package. It currently wraps many **state-of-the-art** face recognition models: [`VGG-Face`](https://sefiks.com/2018/08/06/deep-face-recognition-with-keras/) , [`Google FaceNet`](https://sefiks.com/2018/09/03/face-recognition-with-facenet-in-keras/), [`OpenFace`](https://sefiks.com/2019/07/21/face-recognition-with-openface-in-keras/), [`Facebook DeepFace`](https://sefiks.com/2020/02/17/face-recognition-with-facebook-deepface-in-keras/), [`DeepID`](https://sefiks.com/2020/06/16/face-recognition-with-deepid-in-keras/), [`ArcFace`](https://sefiks.com/2020/12/14/deep-face-recognition-with-arcface-in-keras-and-python/), [`Dlib`](https://sefiks.com/2020/07/11/face-recognition-with-dlib-in-python/) and `SFace`. The default configuration uses VGG-Face model.\n\n```python\nmodels = [\"VGG-Face\", \"Facenet\", \"Facenet512\", \"OpenFace\", \"DeepFace\", \"DeepID\", \"ArcFace\", \"Dlib\", \"SFace\"]\n\n#face verification\nresult = DeepFace.verify(img1_path = \"img1.jpg\", img2_path = \"img2.jpg\", model_name = models[1])\n\n#face recognition\ndf = DeepFace.find(img_path = \"img1.jpg\", db_path = \"C:/workspace/my_db\", model_name = models[1])\n\n#embeddings\nembedding = DeepFace.represent(img_path = \"img.jpg\", model_name = models[1])\n```\n\n<p align=\"center\"><img src=\"https://raw.githubusercontent.com/serengil/deepface/master/icon/model-portfolio-v8.jpg\" width=\"95%\" height=\"95%\"></p>\n\nFaceNet, VGG-Face, ArcFace and Dlib are [overperforming](https://youtu.be/i_MOwvhbLdI) ones based on experiments. You can find out the scores of those models below on both [Labeled Faces in the Wild](https://sefiks.com/2020/08/27/labeled-faces-in-the-wild-for-face-recognition/) and YouTube Faces in the Wild data sets declared by its creators.\n\n| Model | LFW Score | YTF Score |\n| ---   | --- | --- |\n| Facenet512 | 99.65% | - |\n| SFace | 99.60% | - |\n| ArcFace | 99.41% | - |\n| Dlib | 99.38 % | - |\n| Facenet | 99.20% | - |\n| VGG-Face | 98.78% | 97.40% |\n| *Human-beings* | *97.53%* | - |\n| OpenFace | 93.80% | - |\n| DeepID | - | 97.05% |\n\n**Similarity**\n\nFace recognition models are regular [convolutional neural networks](https://sefiks.com/2018/03/23/convolutional-autoencoder-clustering-images-with-neural-networks/) and they are responsible to represent faces as vectors. We expect that a face pair of same person should be [more similar](https://sefiks.com/2020/05/22/fine-tuning-the-threshold-in-face-recognition/) than a face pair of different persons.\n\nSimilarity could be calculated by different metrics such as [Cosine Similarity](https://sefiks.com/2018/08/13/cosine-similarity-in-machine-learning/), Euclidean Distance and L2 form. The default configuration uses cosine similarity.\n\n```python\nmetrics = [\"cosine\", \"euclidean\", \"euclidean_l2\"]\n\n#face verification\nresult = DeepFace.verify(img1_path = \"img1.jpg\", img2_path = \"img2.jpg\", distance_metric = metrics[1])\n\n#face recognition\ndf = DeepFace.find(img_path = \"img1.jpg\", db_path = \"C:/workspace/my_db\", distance_metric = metrics[1])\n```\n\nEuclidean L2 form [seems](https://youtu.be/i_MOwvhbLdI) to be more stable than cosine and regular Euclidean distance based on experiments.\n\n**Facial Attribute Analysis** - [`Demo`](https://youtu.be/GT2UeN85BdA)\n\nDeepface also comes with a strong facial attribute analysis module including [`age`](https://sefiks.com/2019/02/13/apparent-age-and-gender-prediction-in-keras/), [`gender`](https://sefiks.com/2019/02/13/apparent-age-and-gender-prediction-in-keras/), [`facial expression`](https://sefiks.com/2018/01/01/facial-expression-recognition-with-keras/) (including angry, fear, neutral, sad, disgust, happy and surprise) and [`race`](https://sefiks.com/2019/11/11/race-and-ethnicity-prediction-in-keras/) (including asian, white, middle eastern, indian, latino and black) predictions.\n\n```python\nobj = DeepFace.analyze(img_path = \"img4.jpg\", actions = ['age', 'gender', 'race', 'emotion'])\n```\n\n<p align=\"center\"><img src=\"https://raw.githubusercontent.com/serengil/deepface/master/icon/stock-2.jpg\" width=\"95%\" height=\"95%\"></p>\n\nAge model got ± 4.65 MAE; gender model got 97.44% accuracy, 96.29% precision and 95.05% recall as mentioned in its [tutorial](https://sefiks.com/2019/02/13/apparent-age-and-gender-prediction-in-keras/).\n\n\n**Face Detectors** - [`Demo`](https://youtu.be/GZ2p2hj2H5k)\n\nFace detection and alignment are important early stages of a modern face recognition pipeline. Experiments show that just alignment increases the face recognition accuracy almost 1%. [`OpenCV`](https://sefiks.com/2020/02/23/face-alignment-for-face-recognition-in-python-within-opencv/), [`SSD`](https://sefiks.com/2020/08/25/deep-face-detection-with-opencv-in-python/), [`Dlib`](https://sefiks.com/2020/07/11/face-recognition-with-dlib-in-python/),  [`MTCNN`](https://sefiks.com/2020/09/09/deep-face-detection-with-mtcnn-in-python/), [`RetinaFace`](https://sefiks.com/2021/04/27/deep-face-detection-with-retinaface-in-python/) and [`MediaPipe`](https://sefiks.com/2022/01/14/deep-face-detection-with-mediapipe/) detectors are wrapped in deepface.\n\n<p align=\"center\"><img src=\"https://raw.githubusercontent.com/serengil/deepface/master/icon/detector-portfolio-v3.jpg\" width=\"95%\" height=\"95%\"></p>\n\nAll deepface functions accept an optional detector backend input argument. You can switch among those detectors with this argument. OpenCV is the default detector.\n\n```python\nbackends = ['opencv', 'ssd', 'dlib', 'mtcnn', 'retinaface', 'mediapipe']\n\n#face verification\nobj = DeepFace.verify(img1_path = \"img1.jpg\", img2_path = \"img2.jpg\", detector_backend = backends[4])\n\n#face recognition\ndf = DeepFace.find(img_path = \"img.jpg\", db_path = \"my_db\", detector_backend = backends[4])\n\n#embeddings\nembedding = DeepFace.represent(img_path = \"img.jpg\", detector_backend = backends[4])\n\n#facial analysis\ndemography = DeepFace.analyze(img_path = \"img4.jpg\", detector_backend = backends[4])\n\n#face detection and alignment\nface = DeepFace.detectFace(img_path = \"img.jpg\", target_size = (224, 224), detector_backend = backends[4])\n```\n\nFace recognition models are actually CNN models and they expect standard sized inputs. So, resizing is required before representation. To avoid deformation, deepface adds black padding pixels according to the target size argument after detection and alignment.\n\n<p align=\"center\"><img src=\"https://raw.githubusercontent.com/serengil/deepface/master/icon/deepface-detectors-v2.jpg\" width=\"90%\" height=\"90%\"></p>\n\n[RetinaFace](https://sefiks.com/2021/04/27/deep-face-detection-with-retinaface-in-python/) and [MTCNN](https://sefiks.com/2020/09/09/deep-face-detection-with-mtcnn-in-python/) seem to overperform in detection and alignment stages but they are much slower. If the speed of your pipeline is more important, then you should use opencv or ssd. On the other hand, if you consider the accuracy, then you should use retinaface or mtcnn.\n\nThe performance of RetinaFace is very satisfactory even in the crowd as seen in the following illustration. Besides, it comes with an incredible facial landmark detection performance. Highlighted red points show some facial landmarks such as eyes, nose and mouth. That's why, alignment score of RetinaFace is high as well.\n\n<p align=\"center\"><img src=\"https://raw.githubusercontent.com/serengil/deepface/master/icon/retinaface-results.jpeg\" width=\"90%\" height=\"90%\"></p>\n\nYou can find out more about RetinaFace on this [repo](https://github.com/serengil/retinaface).\n\n**Real Time Analysis** - [`Demo`](https://youtu.be/-c9sSJcx6wI)\n\nYou can run deepface for real time videos as well. Stream function will access your webcam and apply both face recognition and facial attribute analysis. The function starts to analyze a frame if it can focus a face sequantially 5 frames. Then, it shows results 5 seconds.\n\n```python\nDeepFace.stream(db_path = \"C:/User/Sefik/Desktop/database\")\n```\n\n<p align=\"center\"><img src=\"https://raw.githubusercontent.com/serengil/deepface/master/icon/stock-3.jpg\" width=\"90%\" height=\"90%\"></p>\n\nEven though face recognition is based on one-shot learning, you can use multiple face pictures of a person as well. You should rearrange your directory structure as illustrated below.\n\n```bash\nuser\n├── database\n│   ├── Alice\n│   │   ├── Alice1.jpg\n│   │   ├── Alice2.jpg\n│   ├── Bob\n│   │   ├── Bob.jpg\n```\n\n**API** - [`Demo`](https://youtu.be/HeKCQ6U9XmI)\n\nDeepface serves an API as well. You can clone [`/api/api.py`](https://github.com/serengil/deepface/tree/master/api/api.py) and pass it to python command as an argument. This will get a rest service up. In this way, you can call deepface from an external system such as mobile app or web.\n\n```\npython api.py\n```\n\n<p align=\"center\"><img src=\"https://raw.githubusercontent.com/serengil/deepface/master/icon/deepface-api.jpg\" width=\"90%\" height=\"90%\"></p>\n\nFace recognition, facial attribute analysis and vector representation functions are covered in the API. You are expected to call these functions as http post methods. Service endpoints will be `http://127.0.0.1:5000/verify` for face recognition, `http://127.0.0.1:5000/analyze` for facial attribute analysis, and `http://127.0.0.1:5000/represent` for vector representation. You should pass input images as base64 encoded string in this case. [Here](https://github.com/serengil/deepface/tree/master/api), you can find a postman project.\n\n**Command Line Interface**\n\nDeepFace comes with a command line interface as well. You are able to access its functions in command line as shown below. The command deepface expects the function name as 1st argument and function arguments thereafter.\n\n```shell\n#face verification\n$ deepface verify -img1_path tests/dataset/img1.jpg -img2_path tests/dataset/img2.jpg\n\n#facial analysis\n$ deepface analyze -img_path tests/dataset/img1.jpg\n```\n\n**Tech Stack** - [`Vlog`](https://youtu.be/R8fHsL7u3eE), [`Tutorial`](https://sefiks.com/2021/03/31/tech-stack-recommendations-for-face-recognition/)\n\nFace recognition models represent facial images as vector embeddings. The idea behind facial recognition is that vectors should be more similar for same person than different persons. The question is that where and how to store facial embeddings in a large scale system. Tech stack is vast to store vector embeddings. To determine the right tool, you should consider your task such as face verification or face recognition, priority such as speed or confidence, and also data size.\n\n<p align=\"center\"><img src=\"https://raw.githubusercontent.com/serengil/deepface/master/icon/tech-stack-v2.jpg\" width=\"90%\" height=\"90%\"></p>\n\n## Contribution [![Tests](https://github.com/serengil/deepface/actions/workflows/tests.yml/badge.svg)](https://github.com/serengil/deepface/actions/workflows/tests.yml)\n\nPull requests are welcome! You should run the unit tests locally by running [`test/unit_tests.py`](https://github.com/serengil/deepface/blob/master/tests/unit_tests.py). Once a PR sent, GitHub test workflow will be run automatically and unit test results will be available in [GitHub actions](https://github.com/serengil/deepface/actions) before approval.\n\n## Support\n\nThere are many ways to support a project - starring⭐️ the GitHub repo is just one 🙏\n\nYou can also support this work on [Patreon](https://www.patreon.com/serengil?repo=deepface)\n\n<a href=\"https://www.patreon.com/serengil?repo=deepface\">\n<img src=\"https://raw.githubusercontent.com/serengil/deepface/master/icon/patreon.png\" width=\"30%\" height=\"30%\">\n</a>\n\n## Citation\n\nPlease cite deepface in your publications if it helps your research. Here are BibTeX entries:\n\n```BibTeX\n@inproceedings{serengil2020lightface,\n  title        = {LightFace: A Hybrid Deep Face Recognition Framework},\n  author       = {Serengil, Sefik Ilkin and Ozpinar, Alper},\n  booktitle    = {2020 Innovations in Intelligent Systems and Applications Conference (ASYU)},\n  pages        = {23-27},\n  year         = {2020},\n  doi          = {10.1109/ASYU50717.2020.9259802},\n  url          = {https://doi.org/10.1109/ASYU50717.2020.9259802},\n  organization = {IEEE}\n}\n```\n\n```BibTeX\n@inproceedings{serengil2021lightface,\n  title        = {HyperExtended LightFace: A Facial Attribute Analysis Framework},\n  author       = {Serengil, Sefik Ilkin and Ozpinar, Alper},\n  booktitle    = {2021 International Conference on Engineering and Emerging Technologies (ICEET)},\n  pages        = {1-4},\n  year         = {2021},\n  doi          = {10.1109/ICEET53442.2021.9659697},\n  url          = {https://doi.org/10.1109/ICEET53442.2021.9659697},\n  organization = {IEEE}\n}\n```\n\nAlso, if you use deepface in your GitHub projects, please add deepface in the `requirements.txt`.\n\n## Licence\n\nDeepface is licensed under the MIT License - see [`LICENSE`](https://github.com/serengil/deepface/blob/master/LICENSE) for more details. However, the library wraps some external face recognition models: [VGG-Face](http://www.robots.ox.ac.uk/~vgg/software/vgg_face/), [Facenet](https://github.com/davidsandberg/facenet/blob/master/LICENSE.md), [OpenFace](https://github.com/iwantooxxoox/Keras-OpenFace/blob/master/LICENSE), [DeepFace](https://github.com/swghosh/DeepFace), [DeepID](https://github.com/Ruoyiran/DeepID/blob/master/LICENSE.md), [ArcFace](https://github.com/leondgarse/Keras_insightface/blob/master/LICENSE), [Dlib](https://github.com/davisking/dlib/blob/master/dlib/LICENSE.txt), and [SFace](https://github.com/opencv/opencv_zoo/blob/master/models/face_recognition_sface/LICENSE). Besides, age, gender and race / ethnicity models are based on VGG-Face. Licence types will be inherited if you are going to use those models. Please check the license types of those models for production purposes.\n\nDeepface [logo](https://thenounproject.com/term/face-recognition/2965879/) is created by [Adrien Coquet](https://thenounproject.com/coquet_adrien/) and it is licensed under [Creative Commons: By Attribution 3.0 License](https://creativecommons.org/licenses/by/3.0/).\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/linxiaohui/deepface_cv2",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "deepface-cv2",
    "package_url": "https://pypi.org/project/deepface-cv2/",
    "platform": null,
    "project_url": "https://pypi.org/project/deepface-cv2/",
    "project_urls": {
      "Homepage": "https://github.com/linxiaohui/deepface_cv2"
    },
    "release_url": "https://pypi.org/project/deepface-cv2/0.0.0/",
    "requires_dist": [
      "opecv-python"
    ],
    "requires_python": ">=3.6",
    "summary": "deepface with opencv, no need for tensorflow/keras",
    "version": "0.0.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14491813,
  "releases": {
    "0.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3452de78d0dfaca54df8c252500ac4aecb48e9901e3916e4b6b7245d18594ad5",
          "md5": "1697a48bc6c0b38ceb88190c06cb76d5",
          "sha256": "ff39e8ede2fe9a8dbc448fec1e628e1c0b6721cdc87caed8678c75d5a5b74ad6"
        },
        "downloads": -1,
        "filename": "deepface_cv2-0.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "1697a48bc6c0b38ceb88190c06cb76d5",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 20008,
        "upload_time": "2022-07-20T09:15:54",
        "upload_time_iso_8601": "2022-07-20T09:15:54.974110Z",
        "url": "https://files.pythonhosted.org/packages/34/52/de78d0dfaca54df8c252500ac4aecb48e9901e3916e4b6b7245d18594ad5/deepface_cv2-0.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "3452de78d0dfaca54df8c252500ac4aecb48e9901e3916e4b6b7245d18594ad5",
        "md5": "1697a48bc6c0b38ceb88190c06cb76d5",
        "sha256": "ff39e8ede2fe9a8dbc448fec1e628e1c0b6721cdc87caed8678c75d5a5b74ad6"
      },
      "downloads": -1,
      "filename": "deepface_cv2-0.0.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "1697a48bc6c0b38ceb88190c06cb76d5",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 20008,
      "upload_time": "2022-07-20T09:15:54",
      "upload_time_iso_8601": "2022-07-20T09:15:54.974110Z",
      "url": "https://files.pythonhosted.org/packages/34/52/de78d0dfaca54df8c252500ac4aecb48e9901e3916e4b6b7245d18594ad5/deepface_cv2-0.0.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}