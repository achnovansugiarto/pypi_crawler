{
  "info": {
    "author": "Michael Pidgeon",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.8"
    ],
    "description": "# Explainability robustness toolbox (exrt)\n\nThis package provides two metrics that can be used to measure the robustness of explanations of machine learning models - **infidelity** and **sensitivity**.\n\nThe metrics are based on those defined by Yeh et al. in their paper [On the (In)fidelity and Sensitivity of Explanations](https://papers.nips.cc/paper/2019/file/a7471fdc77b3435276507cc8f2dc2569-Paper.pdf). The implementation is a little different, and allows for nominal data to be used, as well as any arbitary:\n\n- Model, provided it has a `predict()` method that takes an array-like instance. \n- Explanation, provided it is an array-like set of numerical feature importances. \n\nMethods to assist in assembling the required metadata are also provided.\n\nThis work was part of an MSc project, full code for which (including analysis of the results on real datasets) can be found here: https://github.com/pidg3/hw-dissertation\n\n## Infidelity\n\n**Intuition**: if we know what features are most salient for a given model/instance combination, adjusting the values of these features should result in a large change in model output. If it does not, it implies the explanation is not faithful to the model, and therefore will return a larger infidelity value. \n\n**Usage**:\n```\ndef calculate_infidelity(\n    explanation, model, instance, metadata, num_baselined_features=2\n):\n    \"\"\"\n    calculate_infidelity calculates a single numeric value for an explanation's infidelity with respect to some model\n\n    Values are bounded from zero (huge change in model output) to +inf (zero change in model output)\n\n    :param explanation: an array of numbers representing feature importances\n    :param model: a model that provides a predict() function to generate an output prediction\n    :param instance: an array of numbers representing the input instance\n    :param metadata: metadata dictionary in standard format\n    :param num_baselined_features: how many features to set to their baseline value before measuring model output\n    \"\"\"\n```\n\n### Known issues\n\nFeatures are adjusted to their baseline values. If the instance is close to these baseline values for the most salient features, this can result in an artificially low infidelity value. One possible future improvement could be taking the absolute value of `perturbation (dot) explanation - prediction_difference`, rather than the its square (as done by Yeh et al.).\n\n## Sensitivity\n\n**Intuition**: an explanation should not change substantially given a small perturbation to the instance being explained. If it does, it implies the explanation is lacking robustness. \n\n**Usage**:\n```\ndef calculate_sensitivity(\n    explainer,\n    original_explanation,\n    instance,\n    metadata,\n    numeric_displacement=0.1,\n    proportion_features_perturbed=0.1,\n    skip_zero_saliency_features=False,\n):\n    \"\"\"\n    calculate_sensitivity calculates a single numeric value for an explanation's sensitivity, without respect to the underlying model\n\n    :param explainer: function that provides an explanation for a specific instance (in numpy format)\n    :param original_explanation: array of numbers representing the original explanation\n    :param instance: an array of numbers representing the input instance\n    :param metadata: metadata dictionary in standard format\n    :param numeric_displacement: how much (in percentage terms) to perturb numeric features by\n    :param proportion_features_perturbed: how many features (in percentage terms, rounded up) to perturb\n    :param skip_zero_saliency_features: whether to skip perturbing features with zero saliency value (i.e. we assume\n      not important to the calculation)\n    \"\"\"\n```\n\n### Known issues\n\nSpeed - the algorithm is currently rather naive and works through every possible combination of perturbations, calculating a new explanation for each. This can be improved slightly by reducing the `proportion_features_perturbed`, and setting `skip_zero_saliency_features=False` (particularly for datasets with large number of features).\n\nThere is an implicit assumption in this metric the underlying model is fully robust. If the model output itself changes significantly in response to a small perturbation, it is reasonable to also expect the explanation to change. \n\n## Metadata\n\nBoth metrics require a metadata object to be provided. This is a list of dictionaries, with the format below:\n\n```\n[\n  {\n    \"name\":\"age\",\n    \"type\":\"numerical\",\n    \"used\":true,\n    \"min\":18,\n    \"max\": 75,\n    \"index\": 0,\n    \"baseline\": 28\n  },\n  {\n    \"name\":\"job\",\n    \"type\":\"nominal\",\n    \"values\":[\n      \"juggler\",\n      \"lion-tamer\",\n      \"human-cannonball\",\n    ],\n    \"used\":true,\n    \"index\": 1,\n    \"baseline\": \"juggler\"\n  },\n  {\n    \"name\":\"day\",\n    \"type\":\"ordinal\",\n    \"values\":[\n      \"mon\",\n      \"tues\",\n      \"wed\",\n      \"thurs\",\n      \"fri\"\n    ],\n    \"used\":true,\n    \"index\": 2,\n    \"baseline\": \"wed\"\n  }\n]\n```\n\nFeatures should be divided into one of three types:\n* `numerical` - can be integers or floats. Note that:\n  * `min/max` values can optionally be provided. These will improve the accuracy of the sensitivity calculation.\n  * `baseline` - should be the mean value.\n* `nominal` - unordered strings. Note that:\n  * `baseline` - should be the mode value (most frequently occuring).\n* `ordinal` - ordered strings. Note that:\n  * `baseline` - should be the median value.\n\nHelper methods are provided to make this a litte easier: \n\n* `metadata.append_indices(metadata)` - returns a metadata object with `index` fields appended. \n* `metadata.append_baselines(metadata, dataframe)` - returns a metadata object with `baseline` fields appended, assuming the column headers of the dataframe match the feature names in the metadata object. \n\nMethods are also provided to help get useful data from the metadata object.\n\n* `metadata.get_feature_names(metadata)` - returns a list of names.\n* `metadata.get_feature_names_of_type(type, metadata)` - returns a list of names for numerical/nominal/ordinal features only.\n\n## Full example\n\nTODO: perhaps worth changing this to a binary classification for simplicity? \n\nLet's say want to use sklearn to train an MLP model on the simple Iris dataset. We would then like to use [SHAP](https://github.com/slundberg/shap) to obtain explanations for that model, and use this package to analyse the robustness of those explanations. \n\nConveniently, SHAP has a number of built-in datasets, including Iris. Get this data and split into the usual test/train datasets: \n\n```\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neural_network import MLPClassifier\nimport numpy as np\nfrom exrt.infidelity import calculate_infidelity\nfrom exrt.sensitivity import calculate_sensitivity\n\nX_train,X_test,Y_train,Y_test = train_test_split(*shap.datasets.iris(), test_size=0.2, random_state=0)\n```\n\nWe need to define our metadata. This is simple for Iris as all features are numerical. Use the metadata helper methods to make this a bit easier: \n\n```\niris_metadata = [\n    {\n        'name': 'sepal length (cm)',\n        'type': 'numerical',\n        'used': True\n    },\n    {\n        'name': 'sepal width (cm)',\n        'type': 'numerical',\n        'used': True\n    },\n    {\n        'name': 'petal length (cm)',\n        'type': 'numerical',\n        'used': True\n    },\n    {\n        'name': 'petal width (cm)',\n        'type': 'numerical',\n        'used': True\n    }\n]\n\niris_metadata = append_indices(iris_metadata)\niris_metadata = append_baselines(iris_metadata, X_train)\n\n# Result:\n# iris_metadata = [\n#    {\n#        'name': 'sepal length (cm)',\n#        'type': 'numerical',\n#        'used': True,\n#        'baseline': 5.880833333333333,\n#        'index': 0\n#    },\n# ...\n\n```\n\nTrain the classifier, noting this provides us with a `predict()` method as required by the metrics:\n\n```\nnn = MLPClassifier(solver='lbfgs', alpha=1e-1, hidden_layer_sizes=(5, 2), random_state=0)\nnn.fit(X_train, Y_train)\nprint(nn.predict)\n```\n\nUse SHAP to obtain an explanation of the first test instance. As Iris is a multi-class classification problem, SHAP returns three different explanations for the three different classes. We need to write a small helper to get the explantion for the predicted class. \n\n```\ndef get_predicted_class(instance, model):\n  predictions = model.predict_proba(instance)\n  highest_prediction = max(predictions[0])\n  return np.where(predictions[0] == highest_prediction)[0][0]\n\ninstance = X_test.iloc[0,:][0]\npredicted_class = get_predicted_class(instance)\niris_explainer = shap.KernelExplainer(nn.predict_proba, X_train)\niris_shap_values = iris_explainer.shap_values(X_test.iloc[0,:].to_numpy())[predicted_class]\n\nprint(iris_shap_values)\n```\n\nWe can now calculate the metrics. We need to define a 'highest_explainer' function that gives the explanation for our predicted class (again, a complication that arises due to the multi-class problem):\n\n```\ndef highest_explainer(instance, explainer, predicted_class):\n  return explainer.shap_values(instance)[predicted_class]\n\nsensitivity = calculate_sensitivity(highest_explainer, iris_shap_values, instance, iris_metadata)\n\nclass FidelityModel():\n\n    def __init__(self, prediction):\n        self.prediction = prediction\n\n    def predict(self, instance):\n        return nn.predict_proba([instance])[0][self.prediction]\npredict_wrapper = FidelityModel(predicted_class)\n\ninfidelity = calculate_infidelity(iris_shap_values, predict_wrapper, instance, iris_metadata)\n```\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/pidg3/hw-dissertation",
    "keywords": "",
    "license": "GPL",
    "maintainer": "",
    "maintainer_email": "",
    "name": "exrt",
    "package_url": "https://pypi.org/project/exrt/",
    "platform": "",
    "project_url": "https://pypi.org/project/exrt/",
    "project_urls": {
      "Homepage": "https://github.com/pidg3/hw-dissertation"
    },
    "release_url": "https://pypi.org/project/exrt/0.1.0/",
    "requires_dist": [
      "numpy"
    ],
    "requires_python": "",
    "summary": "Measure robustness of machine learning explanations",
    "version": "0.1.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 11140122,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6d22c861579326e39bd7689cc401d57ee23deb6a9d17106ecfb710b77bc8b1cb",
          "md5": "60b3f02aa9f442a938d0429df6d2c3f1",
          "sha256": "b428aebfc2da5293ac9da2781e17f8a3a084b751a780e54daa966f188bc4e660"
        },
        "downloads": -1,
        "filename": "exrt-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "60b3f02aa9f442a938d0429df6d2c3f1",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 9994,
        "upload_time": "2021-08-10T13:38:31",
        "upload_time_iso_8601": "2021-08-10T13:38:31.781744Z",
        "url": "https://files.pythonhosted.org/packages/6d/22/c861579326e39bd7689cc401d57ee23deb6a9d17106ecfb710b77bc8b1cb/exrt-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c24966ed6c4e859aa7555a18b1ddfd391726c61c2e36713b98e2c9199b0f930f",
          "md5": "4db9d4334a5e06f98392d19e37e3b9e7",
          "sha256": "df703d1a67d824661a66e4a30b9d7fbb04c4beb05ef2b57f353c12c097848958"
        },
        "downloads": -1,
        "filename": "exrt-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "4db9d4334a5e06f98392d19e37e3b9e7",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 11786,
        "upload_time": "2021-08-10T13:38:33",
        "upload_time_iso_8601": "2021-08-10T13:38:33.564925Z",
        "url": "https://files.pythonhosted.org/packages/c2/49/66ed6c4e859aa7555a18b1ddfd391726c61c2e36713b98e2c9199b0f930f/exrt-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "6d22c861579326e39bd7689cc401d57ee23deb6a9d17106ecfb710b77bc8b1cb",
        "md5": "60b3f02aa9f442a938d0429df6d2c3f1",
        "sha256": "b428aebfc2da5293ac9da2781e17f8a3a084b751a780e54daa966f188bc4e660"
      },
      "downloads": -1,
      "filename": "exrt-0.1.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "60b3f02aa9f442a938d0429df6d2c3f1",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 9994,
      "upload_time": "2021-08-10T13:38:31",
      "upload_time_iso_8601": "2021-08-10T13:38:31.781744Z",
      "url": "https://files.pythonhosted.org/packages/6d/22/c861579326e39bd7689cc401d57ee23deb6a9d17106ecfb710b77bc8b1cb/exrt-0.1.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "c24966ed6c4e859aa7555a18b1ddfd391726c61c2e36713b98e2c9199b0f930f",
        "md5": "4db9d4334a5e06f98392d19e37e3b9e7",
        "sha256": "df703d1a67d824661a66e4a30b9d7fbb04c4beb05ef2b57f353c12c097848958"
      },
      "downloads": -1,
      "filename": "exrt-0.1.0.tar.gz",
      "has_sig": false,
      "md5_digest": "4db9d4334a5e06f98392d19e37e3b9e7",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 11786,
      "upload_time": "2021-08-10T13:38:33",
      "upload_time_iso_8601": "2021-08-10T13:38:33.564925Z",
      "url": "https://files.pythonhosted.org/packages/c2/49/66ed6c4e859aa7555a18b1ddfd391726c61c2e36713b98e2c9199b0f930f/exrt-0.1.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}