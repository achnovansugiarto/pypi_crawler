{
  "info": {
    "author": "Amazon AppFlow",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# Amazon AppFlow Custom Connector SDK Development Guide\n\nAmazon AppFlow is a fully managed integration service that enables you to securely transfer data between Software-as-a-Service (SaaS) applications like Salesforce, SAP, Zendesk, Slack, and ServiceNow, and AWS services like Amazon S3 and Amazon Redshift, in just a few clicks. With AppFlow, you can run data flows at enterprise scale at the frequency you choose - on a schedule, in response to a business event, or on demand. You can configure data transformation capabilities like filtering and validation to generate rich, ready-to-use data as part of the flow itself, without additional steps. AppFlow automatically encrypts data in motion, and it allows users to restrict data from flowing over the public internet for SaaS applications that are integrated with AWS PrivateLink, reducing exposure to security threats. For more details about AppFlow, see https://aws.amazon.com/appflow/.\n\nThe AppFlow Custom Connector SDK enables customers and third party developers to build custom source and/or destination connectors for the AppFlow service. With the SDK, you can connect to private APIs, on-premise proprietary systems, and other cloud services by adding to AppFlow's library of connectors (https://aws.amazon.com/appflow/integrations/).   \n\nThe Amazon AppFlow Custom Connector SDK simplifies connector development through the use of a normalized interface and data model. It provides authentication, pagination, throttling, error handling, deployment scripts, and a test framework. Connectors developed with the SDK can be used privately, shared within your organization or partners, or published on AWS Marketplace (https://aws.amazon.com/marketplace).\n\nThis document is a guide for developing AppFlow custom connectors.  The SDK includes a complete working example of a sample connector in Python/Java.\n\n\n## What is an AppFlow 'Connector'?\nA connector translates the normalized AppFlow requests (read and write calls) to the requests compatible for the underlying application. The translation includes protocol, API format, query format, data model etc. Connectors support queries, partial queries (paginated) and write calls (insert, update, upsert and delete operations).\n\nAppFlow transfers data between source and destination connectors using an incremental query model. It constructs a query based on the Flow configuration and uses that to pull a configurable number of records from the source connector. For subsequent runs, AppFlow pulls only the records that have changed or were created since the last run. For structured data, the queries are based on entities (e.g. Accounts, Orders, Contact, Benefit, Report etc) as declared by a given connector.\n\n## Connector Configuration\n\nAppFlow manages authentication information for each connector, and it makes those credentials available to the connectors with the request for data reads and writes. AppFlow depends on the connector to provide the authentication scheme(s) the connectors support and the corresponding configuration parameters. It then gives an option to the AppFlow user to pick the desired authentication scheme from the list of supported schemes for that connector. Apart from authentication configuration, connector can also declare the implementation specific runtime settings. For these settings, input from AppFlow users is required during the ConnectorProfile creation or Flow creation. AppFlow stores the user credentials in user’s security manager. The authentication credentials ARN and the runtime settings are stored along with the ConnectorProfile state, and they are passed along with every request to the connector.\n\n## Entity Metadata\n\nAppFlow support dynamic discovery of schema and depends on the connectors to provide the required metadata. Therefore, \nAppFlow depends on two metadata queries from the connectors: \n1. `listEntities`. This API is recursive in nature and provides a hierarchical entity listing based on entityPath. If the \n`listEntities` response has `hasChildren=true`, that that indicates that there are more entities in the next level.\n2. `describeEntity`. This API provides field-level details of a given entity.\nAfter retrieving the metadata from the connector, AppFlow caches the metadata as per the ttl value returned by the connector \nalong with the metadata response in the CacheControl structure. If no ttl value is specified, AppFlow defaults to \n1 hour.\n    \nThese APIs should be implemented in the MetadataHandler and should return metadata about the entities that are supported by the underlying application. An Entity is a standalone object that can be queried by the Public API.\n\nAppFlow expects the MetadataResponse to contain information about the structure of any given Entity, called the EntityDefinition. At a minimum, the EntityDefinition should contain the  following fields:\n\n1. **Entity:** Contains information about the actual entity such as EntityIdentifier, Label, Description, whether the entity is writable or has nested entities.\n2. **Fields:** List of FieldDefinitions which contains information about the fields supported by this entity.\n\n\n###Entity\n* **entityIdentifier** - The unique id which is used to identify the entity in requests made to the service. This could be entityId/ entityName / entityPath+name / entityUrl etc...\n\n* **hasNestedEntities** - A boolean indicating whether the entity has nested or child entities associated with it. AppFlow uses this parameter to determine whether child entities exist and should be displayed to the user for selection during flow creation.\n\n* **isWriteable** - A boolean indicating whether the entity is writeable. This field helps AppFlow determine whether an entity supports WRITE operations. Entities that don't support WRITE operations are excluded when the given connector is used as a \"destination\" connector in the AppFlow Flow\n\n* **label** - An optional string field indicating the label of the entity. If no value is provided, the identifier is displayed to the customers.\n\n* **description** - An optional string field indicating the description of the entity. You can provide a description to give customers information about the entity.\n\n###FieldDefinition\n* **fieldName** - The unique identifier for the field. Used to identify the field in requests made to the service.\n\n* **dataType** - The data type of this field. AppFlow supports the following data types and you must select one of these types:\n```python\nclass FieldDataType(Enum):\n    # String data type used for storing a sequence of characters. Ex. \"CustomConnectorDataType\".\n    String = auto()\n    # 32-bit signed 2's compliment integer. Range from -2^31 -> 2^31 - 1.\n    Integer = auto()\n    # 32-bit floating point. Holds up to 7 decimal digits.\n    Float = auto()\n    # 64-bit floating point number. Holds up to 16 decimal digits. Use when needing more precision than the Float.\n    Double = auto()\n    # 64-bit signed 2's compliment integer. Use when Integer is not large enough to hold the value.\n    Long = auto()\n    # 16-bit signed 2's compliment integer. Use when large values are not expected and you want to minimize payload size.\n    Short = auto()\n    # Used for storing very large integers that are outside the limit of Integer and Long data types.\n    BigInteger = auto()\n    # Used for storing very large floating point numbers that are outside the limit of Float and Double.\n    BigDecimal = auto()\n    # Array of bytes (8-bit signed integer). Used for storing arbitrary data in binary format.\n    ByteArray = auto()\n    # Boolean data type used for storing logical values (true or false).\n    Boolean = auto()\n    # Date format used to store dates. Use for fields that contain dates (usually formatted as ISO-8601). Ex \"yyyy-MM-dd\".\n    # Only Date and DateTime fields can be selected for incremental pull configurations.\n    Date = auto()\n    # Date format used to store date with time commponent. Use for fields that contain date time (usually formatted as ISO-8601). Ex \"yyyy-MM-dd'T'HH:mm:ss.SSS\".\n    # Only Date and DateTime fields can be selected for incremental pull configurations.\n    DateTime = auto()\n    # Arbitrary JSON structured data type. Use when the field value consists of structured data.\n    Struct = auto()\n    # Structure containing (key, value) pairs. Both keys and values must be primitive data types (otherwise use Struct).\n    Map = auto()\n    # List structure containing elements. Elements must be primitives.\n    List = auto()\n}\n```\n\n* **dataTypeLabel** - If the underlying service uses a different label (than the above listed types) for the data type of this field, you may use this to override the label that is shown to the customer. This ensures the customer will always see the data type that is used by the underlying service. For example, a service may use Array as a data type which is the same as the List data type supported by AppFlow.\n\n* **label** - An optional string indicating the label of the field. If no value is provided, the identifier is displayed to the customers.\n\n* **description** - An optional string field indicating the description for the field. You can provide a description to give customers information about the field.\n\n* **defaultValue** - Specify the default value for a field that should be used in-case no value is specified in the record.\n\n* **constraints** - Optional parameter to specify the constraints for this field such as length, min/max values, etc... Refer to the FieldConstraints class to determine how to construct these constraints: https://github.com/awslabs/aws-appflow-custom-connector-java/blob/main/custom-connector-sdk/src/main/java/com/amazonaws/appflow/custom/connector/model/metadata/FieldConstraints.java\n\n* **readProperties** - Defines properties that are applied to the field when the connector is used as a SOURCE:\n  * **isRetrievable** - Boolean indicating if the field can be used in a search result or when retrieving objects. This is similar to the ability to SELECT fields to display in SQL queries. If false, the field cannot be retrieved when using this connector as a SOURCE.\n  * **isNullable** - Boolean indicating if the field can have a null value. If false and AppFlow encounters a null value during flow execution, the flow will fail because we don’t expect the source to have null.\n  * **isQueryable** - Boolean indicating if the field can be used in filter queries. This is similar to the ability to specify filters in the WHERE clause of SQL queries. Some services will not allow requests to contain certain fields as queryable and in such cases, this should be set to false.\n  * **isTimestampFieldForIncrementalQueries** - Boolean indicating if this field can be used for scheduled flows to pull incremental data from last successful execution time. This property indicates that the field contains timestamp values (either as Date or DateTime) which can be used by AppFlow to configure incremental data pulls. If no such field exists then scheduled flows cannot be configured to pull incremental data (all executions will result in a full data pull).\n\n\n* **writeProperties** - Defines properties that are applied to the field when the connector is used as a DESTINATION:\n  * **isCreateable, isUpdateable, isUpsertable** - Boolean properties indicating whether the field can be created or updated in the destination when doing WRITE operations like CREATE/UPDATE/UPSERT.\n  * **isDefaultedOnCreate** - Boolean indicating if the field should use the default value while creating the record if not provided. Otherwise, null will be used if field is nullable.\n  * **isNullable** - Boolean indicating if the field can have a null value when doing write operations. If false and the record being written contains null, then the flow will fail because the field value cannot be set to null.\n  * **supportedWriteOperations** - List of write operations (CREATE/UPDATE/UPSERT) supported by this field. This field can only be used as a destination field when the flow destination is configured for a supported write operation.\n\n\n* **customProperties** - Key, Value map that contains extra properties of the field that are not listed above.\n\n* **[filterOperators](https://github.com/awslabs/aws-appflow-custom-connector-java/blob/main/custom-connector-sdk/src/main/java/com/amazonaws/appflow/custom/connector/model/metadata/FieldDefinition.java#L128)** - This method by default provides the filter operators that are possible for this field depending on the datatype. This is used by AppFlow to determine whether a field can be used to filter and which types of filtering is supported. The connector developer may also override this method if some dataTypes need to be allowed/disallowed for certain filter operations. \nFor example, override this method if you don’t want to support CONTAINS filter operation on List dataTypes. AppFlow will then NOT send filter expression with CONTAINS for this field to your connector.\n\n\n## SDK Interfaces\n\n| Interfaces           | Description                                                                  |\n|----------------------|------------------------------------------------------------------------------|\n| ConfigurationHandler | Defines the functionality to be implemented for configurations, credentials related operations  |\n| MetadataHandler      | Defines the functionality to be implemented for metadata operations |\n| RecordHandler        | Defines the functionality to be implemented for record related CRUD operations|\n\nIn the next section, we take a closer look at these interfaces. AppFlow uses these interfaces to interact with connectors \nfor fetching data from the source connector or pushing data into the destination connector. It also uses these interfaces\nfor the connector registration using the configuration returned by the connector and also to retrieve \nmetadata dynamically. Therefore, along with the data interfaces, the connector developers are required to implement \nthe interface to declare supported authentication types, configuration, and also the metadata interface \nwhich helps the connector declare the supported entities and their shape.\n\nThe connector developers therefore are essentially writing the wiring code to translate to/from from vendor’s API to \nthe generic AppFlow custom connector interface. The connector code needs to handle the following:\n- Necessary protocol and data model transformations.\n- Normalization to standard error-codes.\n- If the token was found to be expired, the connector can propagate the exception. Then AppFlow can handle\nthe exception and refresh the token and reissue the request.\n- Pagination support.\n- Vendors specific versioning differences.\n\n## ConfigurationHandler Details\n\nAllows the connector to declare connector runtime settings and authentication config etc using the \ndescribeConnectorConfiguration method. \n\nIt also includes the implementation for the following callbacks:\n1. validateConnectorRuntimeSettings: to validate user input for connector runtime settings.\n2. validateCredentials: to validate user credentials entered by the AppFlow user.      \n```python\nclass ConfigurationHandler(metaclass=abc.ABCMeta):\n    \"\"\"This abstract base class defines the functionality to be implemented by custom connectors for configurations,\n    credentials related operations.\n    \"\"\"\n    @abc.abstractmethod\n    def describe_connector_configuration(self, request: requests.DescribeConnectorConfigurationRequest) -> \\\n            responses.DescribeConnectorConfigurationResponse:\n        \"\"\"Describes the Connector Configuration supported by the connector.\n\n        Parameters:\n        request (DescribeConnectorConfigurationRequest)\n\n        Return:\n        DescribeConnectorConfigurationResponse\n        \"\"\"\n        pass\n    \n    @abc.abstractmethod\n    def validate_connector_runtime_settings(self, request: requests.ValidateConnectorRuntimeSettingsRequest) -> \\\n            responses.ValidateConnectorRuntimeSettingsResponse:\n        \"\"\"Validates the user inputs corresponding to the connector settings for a given ConnectorRuntimeSettingScope\n\n        Parameters:\n        request (ValidateConnectorRuntimeSettingsRequest)\n\n        Return:\n        ValidateConnectorRuntimeSettingsResponse\n        \"\"\"\n        pass\n\n    @abc.abstractmethod\n    def validate_credentials(self, request: requests.ValidateCredentialsRequest) -> \\\n            responses.ValidateCredentialsResponse:\n        \"\"\"Validates the user provided credentials.\n\n        Parameters:\n        request (ValidateCredentialsRequest)\n\n        Return:\n        ValidateCredentialsResponse\n        \"\"\"\n        pass\n\n```\n\n## MetadataHandler Details\n\nAllows the connector to declare the entity metadata for the underlying application\n- listEntities\n- describeEntity\n```python\nclass MetadataHandler(metaclass=abc.ABCMeta):\n    \"\"\"This abstract base class defines the functionality to be implemented by custom connectors for metadata\n    operations.\n    \"\"\"\n    @abc.abstractmethod\n    def list_entities(self, request: requests.ListEntitiesRequest) -> responses.ListEntitiesResponse:\n        \"\"\"Lists all the entities available in a paginated fashion. This API is recursive in nature\n        and provides a heretical entity listing based on entityPath. If the ListEntitiesResponse\n        returns has_children=true, that indicates that there are more entities in the next level.\n\n        Parameters:\n        request (ListEntitiesRequest)\n\n        Return:\n        ListEntitiesResponse\n        \"\"\"\n        pass\n\n    @abc.abstractmethod\n    def describe_entity(self, request: requests.DescribeEntityRequest) -> responses.DescribeEntityResponse:\n        \"\"\"Describes the entity definition with its field level metadata.\n        \n        Parameters:\n        request (DescribeEntityRequest)\n\n        Return:\n        DescribeEntityResponse\n        \"\"\"\n        pass\n\n```\n\n## RecordHandler Details\n\nThis is where the main functionality of data exchange is implemented:\n- retrieveData: lookup records against a batch of ids\n- queryData: queries the underlying application by translating the incoming filterExpress that follows a specific\nAppFlow DSL (SDK contains a parser to help parse the filterExpression)\n- writeData: writes a batch of records to the underlying application\n```python\nclass RecordHandler(metaclass=abc.ABCMeta):\n    \"\"\"This abstract base class defines the functionality to be implemented by custom connectors for record related\n    operations.\n    \"\"\"\n    @abc.abstractmethod\n    def retrieve_data(self, request: requests.RetrieveDataRequest) -> responses.RetrieveDataResponse:\n        \"\"\"Retrieves the batch of records against a set of identifiers from the source application.\n\n        Parameters:\n        request (RetrieveDataRequest)\n\n        Return:\n        RetrieveDataResponse\n        \"\"\"\n        pass\n\n    @abc.abstractmethod\n    def query_data(self, request: requests.QueryDataRequest) -> responses.QueryDataResponse:\n        \"\"\"Writes batch of records to the destination application.\n\n        Parameters:\n        request (QueryDataResponse)\n\n        Return:\n        WriteDataResponse\n        \"\"\"\n        pass\n\n    @abc.abstractmethod\n    def write_data(self, request: requests.WriteDataRequest) -> responses.WriteDataResponse:\n        \"\"\"Writes batch of records to the destination application.\n\n        Parameters:\n        request (WriteDataRequest)\n\n        Return:\n        WriteDataResponse\n        \"\"\"\n        pass\n\n```\n\n## Filter Expression DSL and Parser\n\nAppFlow uses an incremental query model to fetch data from the source. The initial pull queries records modified/created in \nthe past 30 days (configurable). In the next flow execution onwards, it runs incremental queries to pull data modified/created since the \nlast execution. The AppFlow query engine takes the user input for filtering from the flow definition and translates it to \na normalized DSL and passes it on to connectors. Connectors then take that normalized expression and translate it to \napplication-specific format. The domain specific language (DSL) that defines the filter expressions grammar is AppFlow \nspecific. For example: “price > 100 and accountName contains 'Alexa'\". The query expression DSL is a normalized DSL \nand not specific to DSLs used by specific underlying applications. The connector's job is to provide the necessary \ntranslation from AppFlow DSL to application-specific DSL or other syntax the underlying application requires. In order \nto simplify the work needed to parse the filter expression the parser has been included. Please see the README.md under\nthe `custom_connector_queryfilter` module for the details.\n\n## AppFlow Custom Connector – End-to-End Flow\n\nThe following is a sample end-to-end processing flow to help understand how AppFlow interacts with the custom connectors using\nthe above interfaces:\n\n- Step 1: Connector implementation declares the supported authentication types using the ConfigurationHandler class.\nAppFlow uses `describeConnectorConfiguration` function to retrieve the connector configuration. The\n`DescribeConnectorConfigurationResponse` includes `AuthenticationConfig` and `ConnectorRuntimeSettings` data structures.\nAuthenticationConfig defines the auth scheme supported by the connector (OAuth2/BASIC etc) and\nConnectorRuntimeSettings represents the setting that the connector needs at runtime, input for which are provided by\nthe AppFlow user.(e.g. timeout values or any other implementation dependent inputs)\n\n- Step 2: AppFlow customer deploys this connector Lambda stack into their account and registers a `Connector` against the\nLambda using the `register_connector` AppFlow public API.\n\n- Step 3: AppFlow customer creates a new `ConnectorProfile` against this newly registered connector and picks an\nauthentication type (for this example, let’s assume they picked OAuth2)\n\n- Step 4: AppFlow Console presents them with the corresponding authentication flow and AppFlow takes user inputs and\ninvokes `validateCredentials` function on the connector. If that succeeds, the console presents the screen to take user input for\nthe \"connector runtime settings\" declared by the connector. When user inputs the values corresponding to the settings (example: \nvar1=10, var2=“Foo”). AppFlow invokes `validateConnectorRuntimeSettings` function on the connector so that it can validate the\nuser input. Upon successful validation the credentials and connector runtime settings are stored along with the newly created\n`ConnectorProfile`.\n\n- Step 5: AppFlow user then uses that `ConnectorProfile` to create `Flow` definitions. During the flow creation AppFlow\ninvokes `listEntity` and `describeEntity` functions on the connector to retrieve the list of supported entities and the entity\ndetail of the specific entity AppFlow user selected on the console / API.\n\n- Step 6: When the flow is started AppFlow invokes the connector to execute the query constructed using the user input\nduring the AppFlow definition using the `queryData` function.\n\n- Step 7: For incremental flows AppFlow adds the timestamp based filter on the query and passes it on the connector to\ninvoke it again for incremental data pulls using the query_data function. \n\n- Step 8: If the destination connector is also a custom connector, AppFlow processes the incoming records as per the\ntask definitions and prepares the payload as per the entity shape of the destination connector and hands it over to the\ndestination connector by invoking the `writeData` function.\n\n\n## Connector Developer Experience\n\n- Clone the `custom-connector-example` module and modify the implementation to fit the underlying application you are \nwriting the connector for.\n- Edit the implementations for the three lambda handlers: `ConfigurationHandler`, `MetadataHandler` and `RecordHandler`.\n- Add unit tests.\n- This SDK productivity scripts under the `custom-connector-tools` module, to help build and export the package into \nS3 using AWS CloudFormation template and then deploy the Lambda stack into your account.\n- Login into the AppFlow console and register a `Connector` against the new Lambda.\n- Create a `ConnectorProfile` against the newly registered `Connector`.\n- Create a flow using the new `Connector` and `ConnectorProfile`.\n- Execute the flow.\n\n\n## Getting Started Guide\n\n### Documentation\n\nThe Amazon AppFlow documentation is located here: https://docs.aws.amazon.com/appflow/index.html. The API reference guide can be found here: https://docs.aws.amazon.com/appflow/1.0/APIReference/API_Operations.html.\n\n### Downloading the SDK\n\n\nThe Amazon AppFlow Custom Connector SDK is available for both Java and Python on github at the following link: https://github.com/orgs/awslabs/repositories?q=aws-appflow-custom-connector-\n\n* Java SDK - You can find the Java SDK in [AppFlowJavaSdk](https://github.com/awslabs/aws-appflow-custom-connector-java)/\n* Python SDK - You can find the Python SDK .whl file in [AppFlowPythonSDK/](https://github.com/awslabs/aws-appflow-custom-connector-python)\n\n### Using the SDK\n\n#### For Java SDK Users:\n\nOnce you have the jar, create the Amazon AppFlow client instance and invoke the AppFlow APIs.\n\n```\nAmazonAppflow appflowClient = AmazonAppflowClientBuilder.standard()\n       .withRegion(region)\n        .build();\n```\n\n#### For Python Users:\n\nOnce you have the python whl file, install the whl files using pip3 install. Create the AppFlow client using the boto3 and call the AppFlow APIs.\n\n**Commands to install the Python SDK:**\n\n```\npython3 -m pip install botocore-1.21.25-py3-none-any.whl\npython3 -m pip install boto3-1.18.25-py3-none-any.whl\n```\n\n```\nimport boto3\n\nappflowClient = boto3.client('appflow')\n```\n\n### Lambda Permissions and Resource Policy Must be Manually Updated\n\nIn order for AppFlow to invoke the custom connector Lambda function while executing customer flows, the following permissions need to be added manually (or by simply using the `deploy.sh` script provided in the custom-connector-tools package):\n\n```\n{\n    \"Version\": \"*2012-10-17*\",\n    \"Id\": \"default\",\n    \"Statement\": [{\n        \"Sid\": \"*appflow-example-01*\",\n        \"Effect\": \"Allow\",\n        \"Principal\": {\n            \"Service\": \"appflow.amazonaws.com\"\n        },\n        \"Action\": \"lambda:InvokeFunction\",\n        \"Resource\": \"arn:aws:lambda:*us-east-1*:123456789012:function:*my-function*\",\n        \"Condition\": {\n            \"StringEquals\": {\n                \"AWS:SourceAccount\": \"*123456789012*\"\n            },\n            \"ArnLike\": {\n                \"AWS:SourceArn\": \"arn:aws:appflow:*us-east-1*:*123456789012*:*\"\n            }\n        }\n    }]\n}\n```\n\n* source account: the customers account \n* source arn: all of the Amazon AppFlow resources present in the customers account\n\nThe Source Account and the Source ARN condition helps to prevent the “confused deputy” security vulnerability. The allow-listed service principal allows all of the AWS accounts under the “appflow” service principal to access the customer Lambda.\n\n### Registering your Custom Connector\n\n#### For Console Users:\n\ni) Go to the Amazon AppFlow console and select “Connectors” on the left-side menu. \n\n![AppFlow console home page](https://github.com/awslabs/aws-appflow-custom-connector-python/blob/main/images/appflow-console-home.png?raw=True) \n\nii) Click on the “Register New Connector” button on the console.\n\n![Register new connector button](https://github.com/awslabs/aws-appflow-custom-connector-python/blob/main/images/appflow-console-connectors-page.png?raw=True) \n\niii) Your custom connector Lambda function will be available on this webpage. If not, ensure that the appropriate Lambda permissions are set, as described in the section “Updating Lambda Permissions and Resource Policy Required.\"\n\n![Choose Lambda function](https://github.com/awslabs/aws-appflow-custom-connector-python/blob/main/images/appflow-console-lambda-function.png?raw=True)\n\niv) Provide the label for your connector. The label must be unique per account per region. Click on the “Register” button. \n\n![Provide connector label](https://github.com/awslabs/aws-appflow-custom-connector-python/blob/main/images/appflow-console-connector-label.png?raw=True)\n\nv) Once registered, you’ll see the connector in the list of custom connectors.\n\n![List of custom connectors](https://github.com/awslabs/aws-appflow-custom-connector-python/blob/main/images/appflow-console-test-connector.png?raw=True)\n\n#### For API  Users:\n\nInvoke the `registerConnector` public API endpoint with the following request payload:\n\n```\n{\n   \"connectorLabel\":\"TestCustomConnector\", [The unique Label]\n   \"connectorProvisioningType\":\"LAMBDA\",   [The provisioning type of the connector.\n    Currently only supported value is LAMBDA]\n   \"connectorProvisioningConfig\":{\n      \"lambda\":{\n         \"lambdaArn\":\"arn:aws:lambda:us-west-2:364320160620:function: \n         banvipulCustomConnectorBugBash\" [The arn of the deployed lambda]\n      }\n   }\n}\n```\n\n\n\n### Creating the Connector Profile\n\n#### For Console Users:\n\ni) Go to the “Connections” link from the left menu and select the registered connector from the list.\n\n![Select registered connector](https://github.com/awslabs/aws-appflow-custom-connector-python/blob/main/images/appflow-console-registered-connector.png?raw=True)\n\nii) Once selected click on the ‘Create Connection’ button.\n\n![Create connection button](https://github.com/awslabs/aws-appflow-custom-connector-python/blob/main/images/appflow-console-create-connection.png?raw=True)\n\niii) A pop-up appears asking for the required details to create a connection. Please fill in the details and scroll down to click on the ‘Continue’ button. \n\n![Custom connection details](https://github.com/awslabs/aws-appflow-custom-connector-python/blob/main/images/appflow-console-connection-details.png?raw=True)\n\niv) Your connection now appears in the list.\n\n#### For API Users:\n\nFor custom connectors, a new parameter has been added in the request object for this API. \n\n```\n{\n   .............................\n   .............................\n   .............................\n   \"connectorLabel\":\"TestCustomConnector\", [The Label provided while registering the \n   connector]\n   .............................\n   .............................\n   .............................\n}\n```\n\nPlease follow the sample API request here https://docs.aws.amazon.com/appflow/1.0/APIReference/API_CreateConnectorProfile.html \n\n### Creating Flows\n\n#### For Console Users:\n\ni) Click on the Flow tab in the left menu, select Create Flow, then follow the standard AppFlow flow configuration steps.  \n\n![Create flow button](https://github.com/awslabs/aws-appflow-custom-connector-python/blob/main/images/appflow-console-create-flow.png?raw=True)\n\n#### For API Users:\n\nFollow the sample API request here:\nhttps://docs.aws.amazon.com/appflow/1.0/APIReference/API_CreateFlow.html\n\nIn addition to this, for the custom connectors we have added the following parameters in the request object for this API:\n\n### Finding and Listing Custom Connectors\n\n#### For Console Users:\n\nGo the Amazon AppFlow console and click on “Connectors” on the left menu. Select “Custom connectors” in the drop down list.\n\n![Custom connectors drop-down menu](https://github.com/awslabs/aws-appflow-custom-connector-python/blob/main/images/appflow-console-custom-connectors-dropdown.png?raw=True)\n\n#### For API Users:\n\nCall the listConnectors API with the following request format, this will list all the custom connectors registered in your account:\n\n```\n{\n  \"maxResults\" : 100 // default is 20 and accepted values are between 1 to 100.\n}\n```\n\n### Obtaining Details about the Registered Connector\n\n#### For Console Users:\n\nGo the Amazon AppFlow console, click on “Connectors” on the left menu, then click “View details” on the connector of interest. \n\n![View custom connector details](https://github.com/awslabs/aws-appflow-custom-connector-python/blob/main/images/appflow-console-custom-connectors-view-details.png?raw=True)\n\n#### For API Users:\n\nPlease call describeConnector API. Please follow the sample API request here:\n\n```\n{\n  \"connectorType\" : `\"CustomConnector\",\n  \"connectorLabel\": <YourConnectorLabel>`\n}\n```\n\n## Testing the connector\n\n### Using AWS Lambda console\n\n* After your connector is deployed, you can access the connector through the AWS Lambda console.\n* You can go to the test tab, and define the payloads as per the request format and then invoke the Lambda to test this.\n* To the request payload, you can build the request using the Request model defined as SDK and then convert it to JSON string and then use that on console.\n* You can also use our Testing Tools in `custom-connector-tests` and `custom-connector-integ-test` to test your connector.\n\n## Additional details:\n\nPlease refer to the below READMEs to learn more about the SDK:\n- You can find QueryFilter README in `custom-connector-queryfilter`\n- You can find Example README in `custom-connector-example`\n- You can find Deployment Tools README in `custom-connector-tools`\n- You can find Testing Tools README in `custom-connector-tests` and `custom-connector-integ-test`\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/awslabs/aws-appflow-custom-connector-python",
    "keywords": "",
    "license": "Apache License 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "custom-connector-sdk",
    "package_url": "https://pypi.org/project/custom-connector-sdk/",
    "platform": null,
    "project_url": "https://pypi.org/project/custom-connector-sdk/",
    "project_urls": {
      "Homepage": "https://github.com/awslabs/aws-appflow-custom-connector-python"
    },
    "release_url": "https://pypi.org/project/custom-connector-sdk/1.0.5/",
    "requires_dist": null,
    "requires_python": ">= 3.6",
    "summary": "Amazon AppFlow Custom Connector SDK",
    "version": "1.0.5",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17135409,
  "releases": {
    "1.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b0272318036a532a0d94f68a55d43d600abed7d44a5375117fda20a572a425cc",
          "md5": "98df76bfde10d9c07380d8d3a8170249",
          "sha256": "dc8ccfa576efcad7c4bed5a8a984af44715fea2d35a82c81ddaff59c292f5c11"
        },
        "downloads": -1,
        "filename": "custom_connector_sdk-1.0.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "98df76bfde10d9c07380d8d3a8170249",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">= 3.6",
        "size": 161681,
        "upload_time": "2023-03-02T22:31:59",
        "upload_time_iso_8601": "2023-03-02T22:31:59.345939Z",
        "url": "https://files.pythonhosted.org/packages/b0/27/2318036a532a0d94f68a55d43d600abed7d44a5375117fda20a572a425cc/custom_connector_sdk-1.0.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0a7d9ffd545294045982879bcec42845325f8ae857fb042a44092162f93e8309",
          "md5": "60960455e2feac6e1586dc7ce86c85dd",
          "sha256": "90179e8e94eb17d729d6c5b8b2f30b4523b84a5560e23df947c91fd103829ac4"
        },
        "downloads": -1,
        "filename": "custom_connector_sdk-1.0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "60960455e2feac6e1586dc7ce86c85dd",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">= 3.6",
        "size": 982905,
        "upload_time": "2023-03-02T22:32:01",
        "upload_time_iso_8601": "2023-03-02T22:32:01.551689Z",
        "url": "https://files.pythonhosted.org/packages/0a/7d/9ffd545294045982879bcec42845325f8ae857fb042a44092162f93e8309/custom_connector_sdk-1.0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "b0272318036a532a0d94f68a55d43d600abed7d44a5375117fda20a572a425cc",
        "md5": "98df76bfde10d9c07380d8d3a8170249",
        "sha256": "dc8ccfa576efcad7c4bed5a8a984af44715fea2d35a82c81ddaff59c292f5c11"
      },
      "downloads": -1,
      "filename": "custom_connector_sdk-1.0.5-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "98df76bfde10d9c07380d8d3a8170249",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">= 3.6",
      "size": 161681,
      "upload_time": "2023-03-02T22:31:59",
      "upload_time_iso_8601": "2023-03-02T22:31:59.345939Z",
      "url": "https://files.pythonhosted.org/packages/b0/27/2318036a532a0d94f68a55d43d600abed7d44a5375117fda20a572a425cc/custom_connector_sdk-1.0.5-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "0a7d9ffd545294045982879bcec42845325f8ae857fb042a44092162f93e8309",
        "md5": "60960455e2feac6e1586dc7ce86c85dd",
        "sha256": "90179e8e94eb17d729d6c5b8b2f30b4523b84a5560e23df947c91fd103829ac4"
      },
      "downloads": -1,
      "filename": "custom_connector_sdk-1.0.5.tar.gz",
      "has_sig": false,
      "md5_digest": "60960455e2feac6e1586dc7ce86c85dd",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">= 3.6",
      "size": 982905,
      "upload_time": "2023-03-02T22:32:01",
      "upload_time_iso_8601": "2023-03-02T22:32:01.551689Z",
      "url": "https://files.pythonhosted.org/packages/0a/7d/9ffd545294045982879bcec42845325f8ae857fb042a44092162f93e8309/custom_connector_sdk-1.0.5.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}