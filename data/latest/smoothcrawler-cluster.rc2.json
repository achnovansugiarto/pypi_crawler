{
  "info": {
    "author": "Liu, Bryant",
    "author_email": "chi10211201@cycu.org.tw",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.11",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "<h1 align=\"center\">\n  SmoothCrawler-Cluster\n</h1>\n\n<p align=\"center\">\n  <a href=\"https://pypi.org/project/SmoothCrawler-Cluster\">\n    <img src=\"https://img.shields.io/pypi/pyversions/SmoothCrawler-Cluster.svg?logo=python&logoColor=FBE072\" alt=\"PyPI support versions\">\n  </a>\n  <a href=\"https://pypi.org/project/SmoothCrawler-Cluster\">\n    <img src=\"https://img.shields.io/pypi/v/SmoothCrawler-Cluster?color=%23099cec&amp;label=PyPI&amp;logo=pypi&amp;logoColor=white\" alt=\"PyPI package version\">\n  </a>\n  <a href=\"https://github.com/Chisanan232/SmoothCrawler-Cluster/releases\">\n    <img src=\"https://img.shields.io/github/release/Chisanan232/SmoothCrawler-Cluster.svg?label=Release&amp;logo=github&color=orange\" alt=\"GitHub release version\">\n  </a>\n  <a href=\"https://opensource.org/licenses/Apache-2.0\">\n    <img src=\"https://img.shields.io/badge/License-Apache%202.0-blue.svg?logo=apache\" alt=\"Software license\">\n  </a>\n  <a href=\"https://github.com/Chisanan232/SmoothCrawler-Cluster/actions/workflows/ci-cd.yml\">\n    <img src=\"https://github.com/Chisanan232/SmoothCrawler-Cluster/actions/workflows/ci-cd.yml/badge.svg\" alt=\"CI/CD status\">\n  </a>\n  <a href=\"https://codecov.io/gh/Chisanan232/SmoothCrawler-Cluster\">\n    <img src=\"https://codecov.io/gh/Chisanan232/SmoothCrawler-Cluster/branch/master/graph/badge.svg?token=H34TPZQXYL\" alt=\"Test coverage\">\n  </a>\n  <a href=\"https://github.com/psf/black\">\n    <img src=\"https://img.shields.io/badge/code%20style-black-000000.svg\" alt=\"Coding style reformat tool\">\n  </a>\n  <a href=\"https://github.com/PyCQA/pylint\">\n    <img src=\"https://img.shields.io/badge/linting-pylint-yellowgreen\" alt=\"Coding style checking tool\">\n  </a>\n  <a href=\"https://results.pre-commit.ci/latest/github/Chisanan232/SmoothCrawler-Cluster/master\">\n    <img src=\"https://results.pre-commit.ci/badge/github/Chisanan232/SmoothCrawler-Cluster/master.svg\" alt=\"Pre-Commit building state\">\n  </a>\n  <a href=\"https://www.codacy.com/gh/Chisanan232/SmoothCrawler-Cluster/dashboard?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=Chisanan232/SmoothCrawler-Cluster&amp;utm_campaign=Badge_Grade\">\n    <img src=\"https://app.codacy.com/project/badge/Grade/171272bee2594687964f1f4473628a0f\" alt=\"Code quality level\">\n  </a>\n  <a href='https://smoothcrawler-cluster.readthedocs.io/en/latest/?badge=latest'>\n      <img src='https://readthedocs.org/projects/smoothcrawler-cluster/badge/?version=latest' alt='Documentation Status' />\n  </a>\n\n</p>\n\n<p align=\"center\">\n  <em>SmoothCrawler-Cluster</em> is a Python framework which is encapsulation of building cluster or decentralized crawler system\n  humanly with <a href=\"https://github.com/Chisanan232/smoothcrawler\"><em>SmoothCrawler</em></a>.\n</p>\n\n[Overview](#overview) | [Quickly Demo](#quickly-demo) | [Documentation](#documentation)\n<hr>\n\n\n## Overview\n\n*SmoothCrawler* helps you build crawler with multiple components as combining LEGO. *SmoothCrawler-Cluster* helps you build\na cluster or decentralized system with the LEGO. It's same as the reason why *SmoothCrawler* exist: SoC (Separation of Concerns).\nDevelopers could focus on how to handle everything of HTTP request and HTTP response, how to parse the content of HTTP response, etc.\nIn addiction to the crawler features, it also has the cluster or decentralized system feature.\n\n## Quickly Demo\n\nFor the demonstration, it divides to 2 parts:\n\n* [_General crawler feature_](#general-crawler-feature)\n\n    Demonstrate a general crawling feature, but doesn't have any features are relative with cluster or decentralized system.\n\n* [_Cluster feature_](#cluster-feature)\n\n    Here would let developers be aware of how it runs as a cluster system which is high reliability.\n\n### _General crawler feature_\n\nCurrently, it only supports cluster feature with third party application [**_Zookeeper_**](https://zookeeper.apache.org/documentation.html).\nSo let's start to demonstrate with object **ZookeeperCrawler**:\n\n```python\nfrom smoothcrawler_cluster.crawler import ZookeeperCrawler\n\nzk_crawler = ZookeeperCrawler(runner=1,    # How many crawler to run task\n                              backup=1,    # How many crawler is backup of runner\n                              ensure_initial=True,    # Run the initial process first\n                              zk_hosts=\"localhost:2181\")    # Zookeeper hosts\nzk_crawler.register_factory(http_req_sender=RequestsHTTPRequest(),\n                            http_resp_parser=RequestsExampleHTTPResponseParser(),\n                            data_process=ExampleDataHandler())\nzk_crawler.run()\n```\n\nIt would run as an unlimited loop after calling *run*. If it wants to trigger the crawler instance to run crawling task,\nplease assigning task via setting value to Zookeeper node.\n\n> **Note**\n> Please run the above Python code as 2 different processes, e.g., open 2 terminate tabs or windows and run above Python\n> code in each one.\n\n```python\nfrom kazoo.client import KazooClient\nfrom smoothcrawler_cluster.model import Initial\nimport json\n\n# Initial task data\ntask = Initial.task(running_content=[{\n    \"task_id\": 0,\n    \"url\": \"https://www.example.com\",\n    \"method\": \"GET\",\n    \"parameters\": {},\n    \"header\": {},\n    \"body\": {}\n}])\n\n# Set the task value\nzk_client = KazooClient(hosts=\"localhost:2181\")\nzk_client.start()\nzk_client.set(path=\"/smoothcrawler/node/sc-crawler_1/task\", value=bytes(json.dumps(task.to_readable_object()), \"utf-8\"))\n```\n\nAfter assigning task to crawler instance, it would run the task and save the result back to Zookeeper.\n\n```shell\n[zk: localhost:2181(CONNECTED) 19] get /smoothcrawler/node/sc-crawler_1/task\n{\"running_content\": [], \"cookie\": {}, \"authorization\": {}, \"in_progressing_id\": \"-1\", \"running_result\": {\"success_count\": 1,\n\"fail_count\": 0}, \"running_status\": \"done\", \"result_detail\": [{\"task_id\": 0, \"state\": \"done\", \"status_code\": 200, \"response\":\n\"Example Domain\", \"error_msg\": null}]}\n```\n\nFrom above info, we could get the running result detail in column *result_detail*:\n\n```json\n[\n  {\n    \"task_id\": 0,\n    \"state\": \"done\",\n    \"status_code\": 200,\n    \"response\": \"Example Domain\",\n    \"error_msg\": null\n  }\n]\n```\n\nAbove data means the task which *task_id* is 0 it has done, and the HTTP status code it got is 200. Also it got the parsing\nresult: Example Domain.\n\n### _Cluster feature_\n\nNow we understand how to use it as web spider, but what does it mean below?\n\n> ... how it runs as a cluster system which is high reliability.\n\nDo you remember we run 2 crawler instances, right? Let's check the info about **GroupState** of these crawler instances:\n\n```shell\n[zk: localhost:2181(CONNECTED) 10] get /smoothcrawler/group/sc-crawler-cluster/state\n{\"total_crawler\": 2, \"total_runner\": 1, \"total_backup\": 1, \"standby_id\": \"2\", \"current_crawler\": [\"sc-crawler_1\", \"sc-crawler_2\"],\n\"current_runner\": [\"sc-crawler_1\"], \"current_backup\": [\"sc-crawler_2\"], \"fail_crawler\": [], \"fail_runner\": [], \"fail_backup\": []}\n```\n\nIt shows that it only one instance is **Runner** and would receive tasks to run right now. So let's try to stop or kill the\nRunner one and observe the crawler instances behavior.\n\n> **Note**\n> If you opened 2 terminate tabs or windows to run, please select the first one you run and run control + C.\n\nYou would observe that the **Backup** one would activate by itself to be **Runner** and the original **Runner** one would\nbe recorded at column *fail_crawler* and *fail_runner*.\n\n```shell\n[zk: localhost:2181(CONNECTED) 11] get /smoothcrawler/group/sc-crawler-cluster/state\n{\"total_crawler\": 2, \"total_runner\": 1, \"total_backup\": 0, \"standby_id\": \"3\", \"current_crawler\": [\"sc-crawler_2\"], \"current_runner\":\n[\"sc-crawler_2\"], \"current_backup\": [], \"fail_crawler\": [\"sc-crawler_1\"], \"fail_runner\": [\"sc-crawler_1\"], \"fail_backup\": []}\n```\n\nThe crawler instance *sc-crawler_2* would be the new **Runner** one to wait for task and run. And you also could test its\ncrawling feature as [_General crawler feature_](#general-crawler-feature).\n\nSo far, it demonstrates it besides helps developers to build web crawler as a clean software architecture, it also has cluster\nfeature to let it be a high reliability crawler.\n\n\n## Documentation\n\nThe [documentation](https://smoothcrawler-cluster.readthedocs.io) contains more details, and demonstrations.\n\n* [Quickly Start](https://smoothcrawler-cluster.readthedocs.io/en/master/quickly_start.html) to build your own crawler cluster with *SmoothCrawler-Cluster*\n* Detail *SmoothCrawler-Cluster* usage information of functions, classes and methods in [API References](https://smoothcrawler-cluster.readthedocs.io/en/master/index.html#api-reference)\n* I'm clear what I need and want to [customize something](https://smoothcrawler-cluster.readthedocs.io/en/master/advanced_usage/index.html) of *SmoothCrawler-Cluster*\n* Not sure how to use *SmoothCrawler-Cluster* and design your crawler cluster? [Usage Guides](https://smoothcrawler-cluster.readthedocs.io/en/master/index.html#usage-guides) could be a good guide for you\n* Be curious about the details of *SmoothCrawler-Cluster* development? [Development Documentation](https://smoothcrawler-cluster.readthedocs.io/en/master/index.html#development-documentation) would be helpful to you\n* The [Release Notes](https://smoothcrawler-cluster.readthedocs.io/en/master/index.html#change-logs) of *SmoothCrawler-Cluster*\n\n\n## Download\n\n*SmoothCrawler* still a young open source which keep growing. Here's its download state:\n\n[![Downloads](https://pepy.tech/badge/smoothcrawler-cluster)](https://pepy.tech/project/smoothcrawler-cluster)\n[![Downloads](https://pepy.tech/badge/smoothcrawler-cluster/month)](https://pepy.tech/project/smoothcrawler-cluster)\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://smoothcrawler-cluster.readthedocs.io",
    "keywords": "",
    "license": "Apache License 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "SmoothCrawler-Cluster",
    "package_url": "https://pypi.org/project/SmoothCrawler-Cluster/",
    "platform": null,
    "project_url": "https://pypi.org/project/SmoothCrawler-Cluster/",
    "project_urls": {
      "Documentation": "https://smoothcrawler-cluster.readthedocs.io",
      "Homepage": "https://smoothcrawler-cluster.readthedocs.io",
      "Source": "https://github.com/Chisanan232/SmoothCrawler-Cluster"
    },
    "release_url": "https://pypi.org/project/SmoothCrawler-Cluster/0.2.0/",
    "requires_dist": [
      "smoothcrawler (>=0.2.0)",
      "kazoo (>=2.7.0)"
    ],
    "requires_python": ">=3.6",
    "summary": "Develop and build web spider cluster humanly.",
    "version": "0.2.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16987449,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "abbfbc90b5ad3d79e4a5b6a304d31235c4ae49158848b5e6bd731b5281eab165",
          "md5": "0b78e13b2e0c47813d6a789dfc468167",
          "sha256": "af1ae9d02be4107878a817eb118e66d983bb44d0f89ae0c5569ca3e7eaf2fb55"
        },
        "downloads": -1,
        "filename": "SmoothCrawler_Cluster-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0b78e13b2e0c47813d6a789dfc468167",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 73492,
        "upload_time": "2023-01-23T03:05:26",
        "upload_time_iso_8601": "2023-01-23T03:05:26.631691Z",
        "url": "https://files.pythonhosted.org/packages/ab/bf/bc90b5ad3d79e4a5b6a304d31235c4ae49158848b5e6bd731b5281eab165/SmoothCrawler_Cluster-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5fba427cb70ca570e423e826653377a0fde493e6d6319f70f9078b72b525c9cb",
          "md5": "b680077ad40e8a870c313cae5c34d96e",
          "sha256": "6922b714aaa0cdb635d048e79670a5a4982217da1b462a8e03dc5c480013fd4d"
        },
        "downloads": -1,
        "filename": "SmoothCrawler-Cluster-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "b680077ad40e8a870c313cae5c34d96e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 62141,
        "upload_time": "2023-01-23T03:05:28",
        "upload_time_iso_8601": "2023-01-23T03:05:28.018677Z",
        "url": "https://files.pythonhosted.org/packages/5f/ba/427cb70ca570e423e826653377a0fde493e6d6319f70f9078b72b525c9cb/SmoothCrawler-Cluster-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "25ddaee3870f612d0299668f05825b912bd7554863b5b55a84b8ac12922947df",
          "md5": "4c5f126df921141049ae26842caab337",
          "sha256": "a7acb90151c23d5449bcf7ccc947cf88f0d17718da3beae846c17cf7bb730e99"
        },
        "downloads": -1,
        "filename": "SmoothCrawler_Cluster-0.2.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "4c5f126df921141049ae26842caab337",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 109037,
        "upload_time": "2023-02-23T01:58:46",
        "upload_time_iso_8601": "2023-02-23T01:58:46.407866Z",
        "url": "https://files.pythonhosted.org/packages/25/dd/aee3870f612d0299668f05825b912bd7554863b5b55a84b8ac12922947df/SmoothCrawler_Cluster-0.2.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fc00fa98291a0d90e0c062314b0bfb615bafef26657a0d1c6a675e1d0439986b",
          "md5": "be7b7c606becdf4f38bc78c8c0afc72a",
          "sha256": "9436ddb0753fc1df53525e30fc5069371edda599e7dfe8059ea492a01edcb658"
        },
        "downloads": -1,
        "filename": "SmoothCrawler-Cluster-0.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "be7b7c606becdf4f38bc78c8c0afc72a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 87501,
        "upload_time": "2023-02-23T01:58:48",
        "upload_time_iso_8601": "2023-02-23T01:58:48.157659Z",
        "url": "https://files.pythonhosted.org/packages/fc/00/fa98291a0d90e0c062314b0bfb615bafef26657a0d1c6a675e1d0439986b/SmoothCrawler-Cluster-0.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "25ddaee3870f612d0299668f05825b912bd7554863b5b55a84b8ac12922947df",
        "md5": "4c5f126df921141049ae26842caab337",
        "sha256": "a7acb90151c23d5449bcf7ccc947cf88f0d17718da3beae846c17cf7bb730e99"
      },
      "downloads": -1,
      "filename": "SmoothCrawler_Cluster-0.2.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "4c5f126df921141049ae26842caab337",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 109037,
      "upload_time": "2023-02-23T01:58:46",
      "upload_time_iso_8601": "2023-02-23T01:58:46.407866Z",
      "url": "https://files.pythonhosted.org/packages/25/dd/aee3870f612d0299668f05825b912bd7554863b5b55a84b8ac12922947df/SmoothCrawler_Cluster-0.2.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "fc00fa98291a0d90e0c062314b0bfb615bafef26657a0d1c6a675e1d0439986b",
        "md5": "be7b7c606becdf4f38bc78c8c0afc72a",
        "sha256": "9436ddb0753fc1df53525e30fc5069371edda599e7dfe8059ea492a01edcb658"
      },
      "downloads": -1,
      "filename": "SmoothCrawler-Cluster-0.2.0.tar.gz",
      "has_sig": false,
      "md5_digest": "be7b7c606becdf4f38bc78c8c0afc72a",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 87501,
      "upload_time": "2023-02-23T01:58:48",
      "upload_time_iso_8601": "2023-02-23T01:58:48.157659Z",
      "url": "https://files.pythonhosted.org/packages/fc/00/fa98291a0d90e0c062314b0bfb615bafef26657a0d1c6a675e1d0439986b/SmoothCrawler-Cluster-0.2.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}