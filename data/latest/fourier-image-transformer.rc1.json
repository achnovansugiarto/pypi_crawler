{
  "info": {
    "author": "Tim-Oliver Buchholz, Florian Jug",
    "author_email": "tibuch@mpi-cbg.de, florian.jug@fht.org",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: BSD License",
      "Programming Language :: Python :: 3.7",
      "Topic :: Scientific/Engineering"
    ],
    "description": "# Fourier Image Transformer\n\nTim-Oliver Buchholz<sup>1</sup> and Florian Jug<sup>2</sup></br>\n<sup>1</sup>tibuch@mpi-cbg.de, <sup>2</sup>florian.jug@fht.org\n\nTransformer architectures show spectacular performance on NLP tasks and have recently also been used for tasks such as\nimage completion or image classification. Here we propose to use a sequential image representation, where each prefix of\nthe complete sequence describes the whole image at reduced resolution. Using such Fourier Domain Encodings (FDEs), an\nauto-regressive image completion task is equivalent to predicting a higher resolution output given a low-resolution\ninput. Additionally, we show that an encoder-decoder setup can be used to query arbitrary Fourier coefficients given a\nset of Fourier domain observations. We demonstrate the practicality of this approach in the context of computed\ntomography (CT) image reconstruction. In summary, we show that Fourier Image Transformer (FIT) can be used to solve\nrelevant image analysis tasks in Fourier space, a domain inherently inaccessible to convolutional architectures.\n\nPreprint: [arXiv](arXiv)\n\n## FIT for Super-Resolution\n\n![SRes](figs/SRes.png)\n\n__FIT for super-resolution.__ Low-resolution input images are first transformed into Fourier space and then unrolled\ninto an FDE sequence, as described in Section 3.1 of the paper. This FDE sequence can now be fed to a FIT, that,\nconditioned on this input, extends the FDE sequence to represent a higher resolution image. This setup is trained using\nan FC-Loss that enforces consistency between predicted and ground truth Fourier coefficients. During inference, the FIT\nis conditioned on the first 39 entries of the FDE, corresponding to (a,d) 3x Fourier binned input images. Panels (b,e)\nshow the inverse Fourier transform of the predicted output, and panels (c,f) depict the corresponding ground truth.\n\n## FIT for Tomography\n\n![TRec](figs/TRec.png)\n\n__FIT for computed tomography.__ We propose an encoder-decoder based Fourier Image Transformer setup for tomographic\nreconstruction. In 2D computed tomography, 1D projections of an imaged sample (i.e. the columns of a sinogram) are\nback-transformed into a 2D image. A common method for this transformationis the filtered backprojection (FBP). Since\neach projection maps to a line of coefficients in 2D Fourier space, a limited number of projections in a sinogram leads\nto visible streaking artefacts due to missing/unobserved Fourier coefficients. The idea of our FIT setup is to encode\nall information of a given sinogram and use the decoder to predict missing Fourier coefficients. The reconstructed image\nis then computed via an inverse Fourier transform (iFFT) of these predictions. In order to reduce high frequency\nfluctuations in this result, we introduce a shallow conv-block after the iFFT (shown in black). We train this setup\ncombining the FC-Loss, see Section 3.2 in the paper, and a conventional MSE-loss between prediction and ground truth.\n\n## Installation\n\nWe use [fast-transformers](https://github.com/idiap/fast-transformers) as underlying transformer implementation. In our super-resolution experiments we use their\n`causal-linear` implementation, which uses custom CUDA code (prediction works without this custom code). This code is\ncompiled during the installation of fast-transformers and it is necessary that CUDA and NVIDIA driver versions match.\nFor our experiments we used CUDA 10.2 and NVIDIA driver 440.118.02.\n\nWe recommend to install Fast Image Transformer into a new [conda](https://docs.conda.io/en/latest/miniconda.html)\nenvironment:\n\n`conda create -n fit python=3.7`\n\nNext activate the new environment.:\n\n`conda activate fit`\n\nThen we install PyTorch for CUDA 10.2:\n\n`conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch`\n\nFollowed by installing fast-transformers:\n\n`pip install --user pytorch-fast-transformers`\n\nNow we have to install the `astra-toolbox`:\n\n`conda install -c astra-toolbox/label/dev astra-toolbox`\n\nAnd finally we install Fourier Image Transformer:\n\n`pip install fourier-image-transformer`\n\nStart the jupyter server:\n\n`jupyter notebook`\n\n\n## Cite\n```\n@{}\n```\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/juglab/FourierImageTransformer/",
    "keywords": "",
    "license": "BSD 3-Clause License",
    "maintainer": "",
    "maintainer_email": "",
    "name": "fourier-image-transformer",
    "package_url": "https://pypi.org/project/fourier-image-transformer/",
    "platform": "",
    "project_url": "https://pypi.org/project/fourier-image-transformer/",
    "project_urls": {
      "Homepage": "https://github.com/juglab/FourierImageTransformer/",
      "Repository": "https://github.com/juglab/FourierImageTransformer/"
    },
    "release_url": "https://pypi.org/project/fourier-image-transformer/0.2.0/",
    "requires_dist": [
      "numpy",
      "scipy",
      "matplotlib",
      "torch (>=1.7.0)",
      "torchvision",
      "tifffile",
      "tqdm",
      "pytorch-fast-transformers",
      "dival (<0.6.0)",
      "pytorch-lightning",
      "jupyter",
      "wget"
    ],
    "requires_python": "",
    "summary": "Fourier Image Transformer",
    "version": "0.2.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 9987624,
  "releases": {
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c69263a8035571e74de39725ecf4eda13517b3a8aec8d0dbfb524fa1187bda62",
          "md5": "ff35bb8ed3c78d5ac2ed52d99e2a336e",
          "sha256": "26e16fa1d9940fd74e497e14b7bd64e350e565e162a8c913ae67ad3e5fbb8503"
        },
        "downloads": -1,
        "filename": "fourier_image_transformer-0.2.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ff35bb8ed3c78d5ac2ed52d99e2a336e",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 31947,
        "upload_time": "2021-04-06T15:41:25",
        "upload_time_iso_8601": "2021-04-06T15:41:25.263389Z",
        "url": "https://files.pythonhosted.org/packages/c6/92/63a8035571e74de39725ecf4eda13517b3a8aec8d0dbfb524fa1187bda62/fourier_image_transformer-0.2.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "c69263a8035571e74de39725ecf4eda13517b3a8aec8d0dbfb524fa1187bda62",
        "md5": "ff35bb8ed3c78d5ac2ed52d99e2a336e",
        "sha256": "26e16fa1d9940fd74e497e14b7bd64e350e565e162a8c913ae67ad3e5fbb8503"
      },
      "downloads": -1,
      "filename": "fourier_image_transformer-0.2.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "ff35bb8ed3c78d5ac2ed52d99e2a336e",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 31947,
      "upload_time": "2021-04-06T15:41:25",
      "upload_time_iso_8601": "2021-04-06T15:41:25.263389Z",
      "url": "https://files.pythonhosted.org/packages/c6/92/63a8035571e74de39725ecf4eda13517b3a8aec8d0dbfb524fa1187bda62/fourier_image_transformer-0.2.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}