{
  "info": {
    "author": "Ketan Goyal",
    "author_email": "ketangoyal1988@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Developers",
      "License :: OSI Approved :: Apache Software License",
      "Natural Language :: English",
      "Operating System :: OS Independent",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Topic :: Internet",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "# Nameko-Kafka\n\n[![Build Status](https://travis-ci.com/ketgo/nameko-kafka.svg?branch=master)](https://travis-ci.com/ketgo/nameko-kafka)\n[![codecov.io](https://codecov.io/gh/ketgo/nameko-kafka/coverage.svg?branch=master)](https://codecov.io/gh/ketgo/nameko-kafka/coverage.svg?branch=master)\n[![MIT licensed](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)\n---\n\nKafka extension for [Nameko](https://www.nameko.io/) microservice framework. \n\n## Introduction\n\nThis is a Nameko microservice framework [extension](https://nameko.readthedocs.io/en/stable/key_concepts.html) to support \nKafka entrypoint and dependency. The motivation behind the project is issue [569](https://github.com/nameko/nameko/issues/569). \n_Nameko-kafka_ provide a simple implementation of the entrypoint based on the approach by [calumpeterwebb](https://medium.com/@calumpeterwebb/nameko-tutorial-creating-a-kafka-consuming-microservice-c4a7adb804d0).\nIt also includes a dependency provider for publishing Kafka messages from within a Nameko service.\n\n## Installation\n\nThe package is supports Python >= 3.5\n```bash\n$ pip install nameko-kafka\n```\n\n## Usage\n\nThe extension can be used for both, a service dependency and entrypoint. Example usage for both cases are shown in the\nfollowing sections.\n\n## Dependency\n\nThis is basically a [python-kafka](https://github.com/dpkp/kafka-python) producer in the form of Nameko dependency. \nNameko uses dependency injection to instantiate the producer. You just need to declare it in your service class as shown:\n\n```python\nfrom nameko.rpc import rpc\nfrom nameko_kafka import KafkaProducer\n\n\nclass MyService:\n    \"\"\"\n        My microservice\n    \"\"\"\n    name = \"my-service\"\n    # Kafak dependency\n    producer = KafkaProducer(bootstrap_servers='localhost:1234')\n    \n    @rpc\n    def method(self):\n        # Publish message using dependency\n        self.producer.send(\"kafka-topic\", value=b\"my-message\", key=b\"my-key\")\n```\n\nHere `KafkaProducer` accepts all options valid for `python-kafka`'s [KafkaProducer](https://kafka-python.readthedocs.io/en/master/apidoc/KafkaProducer.html).\n\n### Entrypoint\n\nYou can use the `nameko_kafka.consume` decorator in your services to process Kafka messages:\n\n```python\nfrom nameko_kafka import consume\n\n\nclass MyService:\n    \"\"\"\n        My microservice \n    \"\"\"\n    name = \"my-service\"\n\n    @consume(\"kafka-topic\", group_id=\"my-group\", bootstrap_servers='localhost:1234')\n    def method(self, message):\n        # Your message handler\n        handle_message(message) \n```\n\nThe `consume` decorator accepts all the options valid for `python-kafka`'s [KafkaConsumer](https://kafka-python.readthedocs.io/en/master/apidoc/KafkaConsumer.html). \n\nOn top of the default `python-kafka`'s autocommit feature, the entrypoint also comes with support for three different \ntypes of offset commit strategies: _at least once_, _at most once_ and _exactly once_. The three strategies correspond \nto the different message delivery semantics achievable in Kafka. Examples for each are shown in the following subsections.\n\n#### At Least Once\n\n```python\nfrom nameko_kafka import consume, Semantic\n\n\nclass MyService:\n    \"\"\"\n        My microservice \n    \"\"\"\n    name = \"my-service\"\n    \n    # At least once semantic consumer\n    @consume(\"kafka-topic\", group_id=\"my-group\", bootstrap_servers='localhost:1234', semantic=Semantic.AT_LEAST_ONCE)\n    def method(self, message):\n        # Your message handler\n        handle_message(message) \n```\n\n#### At Most Once\n\n```python\nfrom nameko_kafka import consume, Semantic\n\n\nclass MyService:\n    \"\"\"\n        My microservice \n    \"\"\"\n    name = \"my-service\"\n    \n    # At most once semantic consumer\n    @consume(\"kafka-topic\", group_id=\"my-group\", bootstrap_servers='localhost:1234', semantic=Semantic.AT_MOST_ONCE)\n    def method(self, message):\n        # Your message handler\n        handle_message(message) \n```\n\n#### Exactly Once\n\nThe exactly once semantic requires a persistent storage to save message offsets. Such a persistent store can be \nimplemented using the `OffsetStorage` interface provided by Nameko-kafka. There can be various backend implementations \nlike RDBMS, NoSQL databases, etc. Support for some comes out of the box:\n\n##### MongoDB Storage \n\n```python\nfrom nameko_kafka import consume, Semantic\nfrom nameko_kafka.storage import MongoStorage\n\nfrom pymongo import MongoClient\n\n\nclass MyService:\n    \"\"\"\n        My microservice \n    \"\"\"\n    name = \"my-service\"\n    \n    # At most once semantic consumer\n    @consume(\n        \"kafka-topic\", \n        group_id=\"my-group\", \n        bootstrap_servers='localhost:1234', \n        semantic=Semantic.EXACTLY_ONCE,\n        storage=MongoStorage(\n            # MongoDB backend client\n            client=MongoClient('localhost', 27017),\n            # Database to use for storage\n            db_name=\"database-name\",\n            # Collection to use for storage\n            collection=\"collection-name\"\n        )       \n    )\n    def method(self, message):\n        # Your message handler\n        handle_message(message) \n```\n\nNote: If the `db_name` and `collection` arguments are not specified, the default value of `\"nameko_kafka_offsets\"` and \n`\"offsets\"` will be used by the storage respectively.\n\n##### SQL Storage\n\nPart of v0.2.1\n\n##### S3 Storage\n\nPart of v0.2.2\n\n##### Azure Block Storage\n\nPart of v0.2.3\n\n##### Create Custom Storage\n\nYou can create your own offset storage by implementing the `OffsetStorage` interface. It exposes the following methods:\n\n```python\nfrom nameko_kafka.storage.base import OffsetStorage\n\nclass MyStorage(OffsetStorage):\n    \"\"\"\n        My custom offset storage.\n    \"\"\"\n\n    def setup(self):\n        \"\"\"\n            Method for setup of the storage.\n        \"\"\"\n\n    def stop(self):\n        \"\"\"\n            Method to teardown the storage.\n        \"\"\"\n\n    def read(self, topic, partition):\n        \"\"\"\n            Read last stored offset from storage for \n            given topic and partition.\n\n            :param topic: message topic\n            :param partition: partition number of the topic\n            :returns: last committed offset value\n        \"\"\"\n\n    def write(self, offsets):\n        \"\"\"\n            Write offsets to storage.\n\n            :param offsets: mapping between topic-partition\n                tuples and corresponding latest offset value, \n                e.g.\n                {\n                    (\"topic-1\", 0): 1,\n                    (\"topic-1\", 1): 3,\n                    (\"topic-2\", 1): 10,\n                    ...\n                }\n        \"\"\"\n```\n\n\n## Configurations\n\nThe extension configurations can be set in a nameko [config.yaml]((https://docs.nameko.io/en/stable/cli.html)) file, or \nby environment variables.\n\n### Config File\n\n```yaml\n# Config for entrypoint\nKAFKA_CONSUMER:\n  bootstrap_servers: 'localhost:1234'\n  retry_backoff_ms: 100\n  ...\n\n# Config for dependency\nKAFKA_PRODUCER:\n  bootstrap_servers: 'localhost:1234'\n  retries: 3\n  ...\n```\n\n### Environment Variables\n\n```.env\n# Config for entrypoint\nKAFKA_CONSUMER='{\"bootstrap_servers\": \"localhost:1234\", \"retry_backoff_ms\": 100}'\n\n# Config for dependency\nKAFKA_PRODUCER='{\"bootstrap_servers\": \"localhost:1234\", \"retries\": 3}'\n```\n\n## Milestones\n\n- [x] Kafka Entrypoint\n- [x] Kafka Dependency\n- [x] Commit strategies: \n    - _ALMOST_ONCE_DELIVERY_\n    - _AT_LEAST_ONCE_DELIVERY_ \n    - _EXACTLY_ONCE_DELIVERY_\n- [x] Commit storage for _EXACT_ONCE_DELIVERY_ strategy\n\n## Developers\n\nFor development a kafka broker is required. You can spawn one using the [docker-compose.yml](https://github.com/ketgo/nameko-kafka/blob/master/tests/conftest.py) \nfile in the `tests` folder:\n```bash\n$ cd tests\n$ docker-compose up -d \n```\n\nTo install all package dependencies:\n```bash\n$ pip install -r .[dev]\nor\n$ make deps\n```\n\nOther useful commands:\n```bash\n$ pytest --cov=nameko_kafka tests/\t\t\t# to get coverage report\nor\n$ make coverage\n\n$ pylint nameko_kafka       # to check code quality with PyLint\nor\n$ make lint\n```\n\n## Contributions\n\nIssue reports and Pull requests are always welcomed. Thanks!",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/ketgo/nameko-kafka",
    "keywords": "nameko,kafka,microservice",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "nameko-kafka",
    "package_url": "https://pypi.org/project/nameko-kafka/",
    "platform": "",
    "project_url": "https://pypi.org/project/nameko-kafka/",
    "project_urls": {
      "Homepage": "https://github.com/ketgo/nameko-kafka"
    },
    "release_url": "https://pypi.org/project/nameko-kafka/0.2.0/",
    "requires_dist": null,
    "requires_python": ">=3.4",
    "summary": "Kafka extension for Nameko microservice framework",
    "version": "0.2.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 7786171,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1af5a72b90390bceb1646d0168731137fbcaacefc272f9351d7b6f8b996483d9",
          "md5": "58fb14903982bf9ed454671668587953",
          "sha256": "d8de18aabf1bf85adb02e9a2b222a1f2177053fe0a868ded4504219befc9e9b7"
        },
        "downloads": -1,
        "filename": "nameko_kafka-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "58fb14903982bf9ed454671668587953",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.4",
        "size": 4706,
        "upload_time": "2020-03-28T06:18:01",
        "upload_time_iso_8601": "2020-03-28T06:18:01.142857Z",
        "url": "https://files.pythonhosted.org/packages/1a/f5/a72b90390bceb1646d0168731137fbcaacefc272f9351d7b6f8b996483d9/nameko_kafka-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6d590ba5f8cc389662909d8d723018d46823cd425e0303ac00609a163d6d52ed",
          "md5": "4e0bc757c8de53066f1c903b6b8256c4",
          "sha256": "8be995bb1ebe450a0ef485ba51e5e88a4078dcb0c14870d734e0c5c0b3423c2d"
        },
        "downloads": -1,
        "filename": "nameko_kafka-0.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "4e0bc757c8de53066f1c903b6b8256c4",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.4",
        "size": 13069,
        "upload_time": "2020-07-25T19:06:47",
        "upload_time_iso_8601": "2020-07-25T19:06:47.263071Z",
        "url": "https://files.pythonhosted.org/packages/6d/59/0ba5f8cc389662909d8d723018d46823cd425e0303ac00609a163d6d52ed/nameko_kafka-0.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "6d590ba5f8cc389662909d8d723018d46823cd425e0303ac00609a163d6d52ed",
        "md5": "4e0bc757c8de53066f1c903b6b8256c4",
        "sha256": "8be995bb1ebe450a0ef485ba51e5e88a4078dcb0c14870d734e0c5c0b3423c2d"
      },
      "downloads": -1,
      "filename": "nameko_kafka-0.2.0.tar.gz",
      "has_sig": false,
      "md5_digest": "4e0bc757c8de53066f1c903b6b8256c4",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.4",
      "size": 13069,
      "upload_time": "2020-07-25T19:06:47",
      "upload_time_iso_8601": "2020-07-25T19:06:47.263071Z",
      "url": "https://files.pythonhosted.org/packages/6d/59/0ba5f8cc389662909d8d723018d46823cd425e0303ac00609a163d6d52ed/nameko_kafka-0.2.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}