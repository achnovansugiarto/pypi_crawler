{
  "info": {
    "author": "Zihang Jiang",
    "author_email": "jzh0103@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: Apache Software License",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Topic :: Scientific/Engineering :: Artificial Intelligence"
    ],
    "description": "# All Tokens Matter: Token Labeling for Training Better Vision Transformers ([arxiv](https://arxiv.org/abs/2104.10858))\n\nThis is a Pytorch implementation of our paper. \n\n![Compare](figures/Compare.png)\n\nComparison between the proposed LV-ViT and other recent works based on transformers. Note that we only show models whose model sizes are under 100M.\n\nOur codes are based on the [pytorch-image-models](https://github.com/rwightman/pytorch-image-models) by [Ross Wightman](https://github.com/rwightman).\n\n### Update\n**2021.7: Add script to generate label data.**\n\n**2021.6: Support `pip install tlt` to use our Token Labeling Toolbox for image models.**\n\n**2021.6: Release training code and segmentation model.**\n\n**2021.4: Release LV-ViT models.**\n\n#### LV-ViT Models\n\n| Model                           | layer | dim  | Image resolution |  Param  | Top 1 |Download |\n| :------------------------------ | :---- | :--- | :--------------: |-------: | ----: |   ----: |\n| LV-ViT-S                        | 16    | 384  |       224        |  26.15M |  83.3 |[link](https://github.com/zihangJiang/TokenLabeling/releases/download/1.0/lvvit_s-26M-224-83.3.pth.tar) |\n| LV-ViT-S                        | 16    | 384  |       384        |  26.30M |  84.4 |[link](https://github.com/zihangJiang/TokenLabeling/releases/download/1.0/lvvit_s-26M-384-84.4.pth.tar) |\n| LV-ViT-M                        | 20    | 512  |       224        |  55.83M |  84.0 |[link](https://github.com/zihangJiang/TokenLabeling/releases/download/1.0/lvvit_m-56M-224-84.0.pth.tar) |\n| LV-ViT-M                        | 20    | 512  |       384        |  56.03M |  85.4 |[link](https://github.com/zihangJiang/TokenLabeling/releases/download/1.0/lvvit_m-56M-384-85.4.pth.tar) |\n| LV-ViT-M                        | 20    | 512  |       448        |  56.13M |  85.5 |[link](https://github.com/zihangJiang/TokenLabeling/releases/download/1.1/lvvit_m-56M-448-85.5.pth.tar) |\n| LV-ViT-L                        | 24    | 768  |       448        | 150.47M |  86.2 |[link](https://github.com/zihangJiang/TokenLabeling/releases/download/1.0/lvvit_l-150M-448-86.2.pth.tar) |\n| LV-ViT-L                        | 24    | 768  |       512        | 150.66M |  86.4 |[link](https://github.com/zihangJiang/TokenLabeling/releases/download/1.0/lvvit_l-150M-512-86.4.pth.tar) |\n\n#### Requirements\n\ntorch>=1.4.0\ntorchvision>=0.5.0\npyyaml\nscipy\ntimm==0.4.5\n\ndata prepare: ImageNet with the following folder structure, you can extract imagenet by this [script](https://gist.github.com/BIGBALLON/8a71d225eff18d88e469e6ea9b39cef4).\n\n```\n│imagenet/\n├──train/\n│  ├── n01440764\n│  │   ├── n01440764_10026.JPEG\n│  │   ├── n01440764_10027.JPEG\n│  │   ├── ......\n│  ├── ......\n├──val/\n│  ├── n01440764\n│  │   ├── ILSVRC2012_val_00000293.JPEG\n│  │   ├── ILSVRC2012_val_00002138.JPEG\n│  │   ├── ......\n│  ├── ......\n```\n\n#### Validation\nReplace DATA_DIR with your imagenet validation set path and MODEL_DIR with the checkpoint path\n```\nCUDA_VISIBLE_DEVICES=0 bash eval.sh /path/to/imagenet/val /path/to/checkpoint\n```\n\n#### Label data\n\nWe provide NFNet-F6 generated dense label map in [Google Drive](https://drive.google.com/file/d/1Cat8HQPSRVJFPnBLlfzVE0Exe65a_4zh/view?usp=sharing) and [BaiDu Yun](https://pan.baidu.com/s/1YBqiNN9dAzhEXtPl61bZJw) (password: y6j2). As NFNet-F6 are based on pure ImageNet data, no extra training data is involved.\n\n\n#### Training\n\nTrain the LV-ViT-S: \n\nIf only 4 GPUs are available,\n\n```\nCUDA_VISIBLE_DEVICES=0,1,2,3 ./distributed_train.sh 4 /path/to/imagenet --model lvvit_s -b 256 --apex-amp --img-size 224 --drop-path 0.1 --token-label --token-label-data /path/to/label_data --token-label-size 14 --model-ema\n```\n\nIf 8 GPUs are available: \n```\nCUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 ./distributed_train.sh 8 /path/to/imagenet --model lvvit_s -b 128 --apex-amp --img-size 224 --drop-path 0.1 --token-label --token-label-data /path/to/label_data --token-label-size 14 --model-ema\n```\n\n\nTrain the LV-ViT-M and LV-ViT-L (run on 8 GPUs):\n\n\n```\nCUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 ./distributed_train.sh 8 /path/to/imagenet --model lvvit_m -b 128 --apex-amp --img-size 224 --drop-path 0.2 --token-label --token-label-data /path/to/label_data --token-label-size 14 --model-ema\n```\n```\nCUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 ./distributed_train.sh 8 /path/to/imagenet --model lvvit_l -b 128 --lr 1.e-3 --aa rand-n3-m9-mstd0.5-inc1 --apex-amp --img-size 224 --drop-path 0.3 --token-label --token-label-data /path/to/label_data --token-label-size 14 --model-ema\n```\nIf you want to train our LV-ViT on images with 384x384 resolution, please use `--img-size 384 --token-label-size 24`.\n\n#### Fine-tuning\n\nTo Fine-tune the pre-trained LV-ViT-S on images with 384x384 resolution:\n```\nCUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 ./distributed_train.sh 8 /path/to/imagenet --model lvvit_s -b 64 --apex-amp --img-size 384 --drop-path 0.1 --token-label --token-label-data /path/to/label_data --token-label-size 24 --lr 5.e-6 --min-lr 5.e-6 --weight-decay 1.e-8 --finetune /path/to/checkpoint\n```\n\nTo Fine-tune the pre-trained LV-ViT-S on other datasets without token labeling:\n```\nCUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 ./distributed_train.sh 8 /path/to/dataset --model lvvit_s -b 64 --apex-amp --img-size 224 --drop-path 0.1 --token-label --token-label-size 14 --dense-weight 0.0 --num-classes $NUM_CLASSES --finetune /path/to/checkpoint\n```\n\n### Segmentation\n\nOur Segmentation model are fully based upon the [MMSegmentation](https://github.com/open-mmlab/mmsegmentation) Toolkit. The model and config files are under `seg/` folder which follow the same folder structure. You can simply drop in these file to get start.\n\n```shell\ngit clone https://github.com/open-mmlab/mmsegmentation # and install\n\ncp seg/mmseg/models/backbones/vit.py mmsegmentation/mmseg/models/backbones/\ncp -r seg/configs/lvvit mmsegmentation/configs/\n\n# test upernet+lvvit_s (add --aug-test to test on multi scale)\ncd mmsegmentation\n./tools/dist_test.sh configs/lvvit/upernet_lvvit_s_512x512_160k_ade20k.py /path/to/checkpoint 8 --eval mIoU [--aug-test]\n```\n\n| Backbone                        | Method  | Crop size | Lr Schd |  mIoU   |  mIoU(ms) | Pixel Acc.| Param |Download |\n| :------------------------------ | :------ | :-------- | :------ |:------- |:--------- | :-------- | :---- | :------ |\n| LV-ViT-S                        | UperNet |  512x512  |   160k  |  47.9   |    48.6   |   83.1    |  44M  |[link](https://github.com/zihangJiang/TokenLabeling/releases/download/v1.1-seg/upernet_lvvit_s.pth) |\n| LV-ViT-M                        | UperNet |  512x512  |   160k  |  49.4   |    50.6   |   83.5    |  77M  |[link](https://github.com/zihangJiang/TokenLabeling/releases/download/v1.1-seg/upernet_lvvit_m.pth) |\n| LV-ViT-L                        | UperNet |  512x512  |   160k  |  50.9   |    51.8   |   84.1    |  209M |[link](https://github.com/zihangJiang/TokenLabeling/releases/download/v1.1-seg/upernet_lvvit_l.pth) |\n\n\n### Visualization\n\nWe apply the visualization method in this [repo](https://github.com/hila-chefer/Transformer-Explainability) to visualize the parts of the image that led to a certain classification for DeiT-Base and our LV-ViT-S. The parts of the image that used by the network to make the decision are highlighted in red.\n\n![Compare](figures/Top1.jpg)\n\n### Label generation\nTo generate token label data for training:\n```bash\npython3 generate_label.py /path/to/imagenet/train /path/to/save/label_top5_train_nfnet --model dm_nfnet_f6 --pretrained --img-size 576 -b 32 --crop-pct 1.0\n```\n\n#### Reference\nIf you use this repo or find it useful, please consider citing:\n```\n@article{jiang2021all,\n  title={All Tokens Matter: Token Labeling for Training Better Vision Transformers},\n  author={Jiang, Zihang and Hou, Qibin and Yuan, Li and Zhou, Daquan and Shi, Yujun and Jin, Xiaojie and Wang, Anran and Feng, Jiashi},\n  journal={arXiv preprint arXiv:2104.10858},\n  year={2021}\n}\n```\n\n#### Related projects\n[T2T-ViT](https://github.com/yitu-opensource/T2T-ViT/), [Re-labeling ImageNet](https://github.com/naver-ai/relabel_imagenet), [MMSegmentation](https://github.com/open-mmlab/mmsegmentation), [Transformer Explainability](https://github.com/hila-chefer/Transformer-Explainability).\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/zihangJiang/TokenLabeling",
    "keywords": "imagenet,attention mechanism,transformer,image classification,token labeling",
    "license": "Apache License 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "tlt",
    "package_url": "https://pypi.org/project/tlt/",
    "platform": "",
    "project_url": "https://pypi.org/project/tlt/",
    "project_urls": {
      "Homepage": "https://github.com/zihangJiang/TokenLabeling"
    },
    "release_url": "https://pypi.org/project/tlt/0.2.0/",
    "requires_dist": [
      "timm (>=0.4.5)",
      "torch (>=1.5)",
      "torchvision",
      "scipy"
    ],
    "requires_python": "",
    "summary": "Token Labeling Toolbox for training image models",
    "version": "0.2.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 10963945,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0da6803faddd1f2f468105d3f967ac9868c27a68bf754d09e25e58ab28462d54",
          "md5": "1206d2c50216fb7bb5d93e81493d1c18",
          "sha256": "44bf1175cea6b0a452e39119ce921ebcf2c114486c58bf8b62165fb6dbe31831"
        },
        "downloads": -1,
        "filename": "tlt-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "1206d2c50216fb7bb5d93e81493d1c18",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 31015,
        "upload_time": "2021-06-16T07:56:14",
        "upload_time_iso_8601": "2021-06-16T07:56:14.412516Z",
        "url": "https://files.pythonhosted.org/packages/0d/a6/803faddd1f2f468105d3f967ac9868c27a68bf754d09e25e58ab28462d54/tlt-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3a1f14216d043ab6cb71586b8b0a98864db2aeec523f4f1f0b6ca834d6d3753f",
          "md5": "b9a8ba107c3a76565fedc6557501bd54",
          "sha256": "acdb041ca39d256bc8249228dc9eda4632ff8beb3d3e4d58553c1333fce65202"
        },
        "downloads": -1,
        "filename": "tlt-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "b9a8ba107c3a76565fedc6557501bd54",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 29840,
        "upload_time": "2021-06-16T07:56:15",
        "upload_time_iso_8601": "2021-06-16T07:56:15.522083Z",
        "url": "https://files.pythonhosted.org/packages/3a/1f/14216d043ab6cb71586b8b0a98864db2aeec523f4f1f0b6ca834d6d3753f/tlt-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fabcca153cf4796c6668091c6ca5c679ef8228f7db5d690fb3f2b2824e88b619",
          "md5": "9f0b961919652e08d722fa94d46f3ab6",
          "sha256": "722097c8af2fc5c45fc7eb0a363da2fac5b6c7cacfa92b982a96db5b4ec97b42"
        },
        "downloads": -1,
        "filename": "tlt-0.2.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "9f0b961919652e08d722fa94d46f3ab6",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 33765,
        "upload_time": "2021-07-21T06:41:10",
        "upload_time_iso_8601": "2021-07-21T06:41:10.003251Z",
        "url": "https://files.pythonhosted.org/packages/fa/bc/ca153cf4796c6668091c6ca5c679ef8228f7db5d690fb3f2b2824e88b619/tlt-0.2.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5688576c55000f2c5eaf6e5f48340776e8373e63dd57d88d513d395832556413",
          "md5": "2b3bd0a63b1ef9be30e571211c3fd9aa",
          "sha256": "9cdaec3b07af206e6a3f2872cb883736e3f358994b077c248b71f711d1f18433"
        },
        "downloads": -1,
        "filename": "tlt-0.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "2b3bd0a63b1ef9be30e571211c3fd9aa",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 33341,
        "upload_time": "2021-07-21T06:41:11",
        "upload_time_iso_8601": "2021-07-21T06:41:11.267018Z",
        "url": "https://files.pythonhosted.org/packages/56/88/576c55000f2c5eaf6e5f48340776e8373e63dd57d88d513d395832556413/tlt-0.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "fabcca153cf4796c6668091c6ca5c679ef8228f7db5d690fb3f2b2824e88b619",
        "md5": "9f0b961919652e08d722fa94d46f3ab6",
        "sha256": "722097c8af2fc5c45fc7eb0a363da2fac5b6c7cacfa92b982a96db5b4ec97b42"
      },
      "downloads": -1,
      "filename": "tlt-0.2.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "9f0b961919652e08d722fa94d46f3ab6",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 33765,
      "upload_time": "2021-07-21T06:41:10",
      "upload_time_iso_8601": "2021-07-21T06:41:10.003251Z",
      "url": "https://files.pythonhosted.org/packages/fa/bc/ca153cf4796c6668091c6ca5c679ef8228f7db5d690fb3f2b2824e88b619/tlt-0.2.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "5688576c55000f2c5eaf6e5f48340776e8373e63dd57d88d513d395832556413",
        "md5": "2b3bd0a63b1ef9be30e571211c3fd9aa",
        "sha256": "9cdaec3b07af206e6a3f2872cb883736e3f358994b077c248b71f711d1f18433"
      },
      "downloads": -1,
      "filename": "tlt-0.2.0.tar.gz",
      "has_sig": false,
      "md5_digest": "2b3bd0a63b1ef9be30e571211c3fd9aa",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 33341,
      "upload_time": "2021-07-21T06:41:11",
      "upload_time_iso_8601": "2021-07-21T06:41:11.267018Z",
      "url": "https://files.pythonhosted.org/packages/56/88/576c55000f2c5eaf6e5f48340776e8373e63dd57d88d513d395832556413/tlt-0.2.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}