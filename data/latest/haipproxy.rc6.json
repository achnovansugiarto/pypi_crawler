{
  "info": {
    "author": "Resolvewang",
    "author_email": "resolvewang@foxmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Natural Language :: English",
      "Programming Language :: Python :: 3.4",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6"
    ],
    "description": "# HAipproxy\n[README](README_EN.md)　｜　[中文文档](README.md)\n\n本项目所采集的IP资源都来自互联网，愿景是为大型爬虫项目提供一个**高可用低延迟的高匿IP代理池**。\n\n# Features\n- 快速抓取代理IP\n- IP抓取和提取精准\n- IP来源丰富\n- 优良的IP校验器，并且容易根据自身需要扩展\n- 支持分布式部署\n- 架构设计灵活\n- MIT授权协议\n\n# Quick start\n\n注意，代码请在[release](https://github.com/SpiderClub/haipproxy/releases)列表中下载，**master**分支的代码不保证能稳定运行\n\n## 单机部署\n\n### 服务端\n- 安装Python3和Redis。有问题可以阅读[这篇文章](https://github.com/SpiderClub/weibospider/wiki/%E5%88%86%E5%B8%83%E5%BC%8F%E7%88%AC%E8%99%AB%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE)的相关部分。\n- 根据Redis的实际配置修改项目配置文件[config/settings.py](config/settings.py)中的`REDIS_HOST`、`REDIS_PASSWORD`等参数。\n- 安装[scrapy-splash](https://github.com/scrapy-plugins/scrapy-splash)，并修改配置文件[config/settings.py](config/settings.py)中的`SPLASH_URL`\n- 安装项目相关依赖\n  > pip install -r requirements.txt\n- 启动*scrapy worker*，包括代理IP采集器和校验器\n  > python crawler_booter.py --usage crawler\n\n  > python crawler_booter.py --usage validator\n- 启动*调度器*，包括代理IP定时调度和校验\n  > python scheduler_booter.py --usage crawler\n\n  > python scheduler_booter.py --usage validator\n\n### 客户端\n近日不断有同学问，如何获取该项目中可用的代理IP列表。`haipproxy`提供代理的方式并不是通过`api api`来提供，而是通过具体的客户端来提供。\n目前支持的是[Python客户端](client/py_cli.py)和语言无关的[squid二级代理](client/squid.py)\n\n#### python客户端调用示例 \n```python3\nfrom client.py_cli import ProxyFetcher\nargs = dict(host='127.0.0.1', port=6379, password='123456', db=0)\n＃　这里`zhihu`的意思是，去和`zhihu`相关的代理ip校验队列中获取ip\n＃　这么做的原因是同一个代理IP对不同网站代理效果不同\nfetcher = ProxyFetcher('zhihu', strategy='greedy', redis_args=args)\n# 获取一个可用代理\nprint(fetcher.get_proxy())\n# 获取可用代理列表\nprint(fetcher.get_proxies()) # or print(fetcher.pool)\n```\n\n更具体的示例见[examples/zhihu](examples/zhihu/zhihu_spider.py)\n\n#### squid作为二级代理\n- 安装squid，备份squid的配置文件并且启动squid，以ubuntu为例\n  > sudo apt-get install squid\n\n  > sudo sed -i 's/http_access deny all/http_access allow all/g' /etc/squid/squid.conf\n\n  > sudo cp /etc/squid/squid.conf /etc/squid/squid.conf.backup\n\n  > sudo service squid start\n- 根据操作系统修改项目配置文件[config/settings.py](config/settings.py)中的`SQUID_BIN_PATH`、`SQUID_CONF_PATH`、`SQUID_TEMPLATE_PATH`等参数\n- 启动`squid conf`的定时更新程序\n  > sudo python squid_update.py\n- 使用squid作为代理中间层请求目标网站,默认代理URL为'http://squid_host:3128',用Python请求示例如下\n  ```python3\n  import requests\n  proxies = {'https': 'http://127.0.0.1:3128'}\n  resp = requests.get('https://httpbin.org/ip', proxies=proxies)\n  print(resp.text)\n  ```\n   \n## Docker部署\n- 安装Docker\n\n- 安装*docker-compose*\n  > pip install -U docker-compose\n\n- 修改[settings.py](config/settings.py)中的`SPLASH_URL`和`REDIS_HOST`参数\n  ```python3\n  SPLASH_URL = 'http://splash:8050'\n  REDIS_HOST = 'redis'\n  ```\n- 使用*docker-compose*启动各个应用组件\n  > docker-compose up\n\n这种方式会一同部署`squid`，您可以通过`squid`调用代理IP池，也可以使用客户端调用，和单机部署调用方式一样\n\n# 注意事项\n- 本项目高度依赖Redis，除了消息通信和数据存储之外，IP校验和任务定时工具也使用了Redis中的多种数据结构。\n如果需要替换Redis，请自行度量\n- 由于*GFW*的原因，某些网站需要通过科学上网才能进行访问和采集，如果用户无法访问墙外的网站，请将[rules.py](config/rules.py)\n`task_queue`为` SPIDER_GFW_TASK`和`SPIDER_AJAX_GFW_TASK`的任务`enable`属性设置为0或者启动爬虫的时候指定爬虫类型为`common`和\n`ajax`\n  > python crawler_booter.py --usage crawler common ajax\n- 相同代理IP，对于不同网站的代理效果可能大不相同。如果通用代理无法满足您的需求，您可以[为特定网站编写代理IP校验器](https://github.com/SpiderClub/haipproxy/blob/master/docs/%E9%92%88%E5%AF%B9%E7%89%B9%E5%AE%9A%E7%AB%99%E7%82%B9%E6%B7%BB%E5%8A%A0%E6%A0%A1%E9%AA%8C%E5%99%A8.md)\n\n# 工作流程\n![](static/workflow.png)\n\n# 开发者文档\n为了方便用户针对自身需求进行定制化，`haipproxy`提供了丰富的文档支持。所有文档详见[项目wiki](https://github.com/SpiderClub/haipproxy/wiki)\n\n# 效果测试\n以单机模式部署`haipproxy`和[测试代码](examples/zhihu/zhihu_spider.py)，以知乎为目标请求站点，\n每一万条成功请求为统计结果，实测抓取效果如下\n\n|请求量|时间|耗时|IP负载策略|客户端|\n|-----|----|---|---------|-----|\n|0|2018/03/03 22:03|0|greedy|[py_cli](client/py_cli.py)|\n|10000|2018/03/03 11:03|1 hour|greedy|[py_cli](client/py_cli.py)|\n|20000|2018/03/04 00:08|2 hours|greedy|[py_cli](client/py_cli.py)|\n|30000|2018/03/04 01:02|3 hours|greedy|[py_cli](client/py_cli.py)|\n|40000|2018/03/04 02:15|4 hours|greedy|[py_cli](client/py_cli.py)|\n|50000|2018/03/04 03:03|5 hours|greedy|[py_cli](client/py_cli.py)|\n|60000|2018/03/04 05:18|7 hours|greedy|[py_cli](client/py_cli.py)|\n|70000|2018/03/04 07:11|9 hours|greedy|[py_cli](client/py_cli.py)|\n|80000|2018/03/04 08:43|11 hours|greedy|[py_cli](client/py_cli.py)|\n\n\n可见`haipporxy`的代理效果还算不错，在开始的时候可以达到`1w/hour`的请求量，几个小时候请求量请求量\n降为了`5k/hour`。降低的结果可能有三个: (1)随着数据量的增大,Redis的性能受到了一定的影响(2)知乎校验\n器在把`Init Queue`中的代理消费完之后，由于是定时任务，所以导致某段时间内新鲜的IP空缺。而免费IP大多\n数都是短效的，所以这段时间出现了IP的空缺;(3)由于我们采用的是`greedy`模式调用IP，它的调用策略是: 高\n质量代理IP会一直被调用直至该代理IP不能用或者被封，而低应速度IP会轮询调用。这也可能导致高质量IP的空缺。\n\n由此可见IP校验和调用策略还有很大的优化空间。希望能有志同道合的朋友加入进来一起优化。\n\n测试代码见[examples/zhihu](examples/zhihu/zhihu_spider.py)\n\n# 如何贡献\n- 欢迎给项目提新feature\n- 如果发现项目某些环节有问题，欢迎提issue或者PR\n- 代理IP校验和筛选的策略仍有优化的空间，欢迎大家交流探讨\n- 如果你发现了比较好的代理网站，欢迎分享\n\n# 同类项目参考\n本项目参考了Github上开源的各个爬虫代理的实现，感谢他们的付出，下面是笔者参考的所有项目，排名不分先后。\n\n[dungproxy](https://github.com/virjar/dungproxy)\n\n[proxyspider](https://github.com/zhangchenchen/proxyspider)\n\n[ProxyPool](https://github.com/henson/ProxyPool)\n\n[proxy_pool](https://github.com/jhao104/proxy_pool)\n\n[ProxyPool](https://github.com/WiseDoge/ProxyPool)\n\n[IPProxyTool](https://github.com/awolfly9/IPProxyTool)\n\n[IPProxyPool](https://github.com/qiyeboy/IPProxyPool)\n\n[proxy_list](https://github.com/gavin66/proxy_list)\n\n[proxy_pool](https://github.com/lujqme/proxy_pool)",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/SpiderClub/haipproxy",
    "keywords": "proxy,client,haipproxy",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "haipproxy",
    "package_url": "https://pypi.org/project/haipproxy/",
    "platform": "",
    "project_url": "https://pypi.org/project/haipproxy/",
    "project_urls": {
      "Homepage": "https://github.com/SpiderClub/haipproxy"
    },
    "release_url": "https://pypi.org/project/haipproxy/0.11.6/",
    "requires_dist": null,
    "requires_python": ">=3.4.0",
    "summary": "High aviariable proxy pool client for crawlers.",
    "version": "0.11.6",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 3972244,
  "releases": {
    "0.11": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5a10074939fb20ecfc780e669329056492087cadd6912974a148380ddaa585e0",
          "md5": "137e61e224120d4ae001ccffbac63fef",
          "sha256": "ba4cbb7c23702ece8f33f55f9cbd845e4ae19ca2bd70f1373de6cb54ac375cd2"
        },
        "downloads": -1,
        "filename": "haipproxy-0.11.tar.gz",
        "has_sig": false,
        "md5_digest": "137e61e224120d4ae001ccffbac63fef",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 11186,
        "upload_time": "2018-06-17T06:03:16",
        "upload_time_iso_8601": "2018-06-17T06:03:16.645582Z",
        "url": "https://files.pythonhosted.org/packages/5a/10/074939fb20ecfc780e669329056492087cadd6912974a148380ddaa585e0/haipproxy-0.11.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.11.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cdb7243ec61277c34d6efb605d61c66deea548056a47789bb6bbd239e2d20c38",
          "md5": "e0446a07b280f0d7c2548a9db824865a",
          "sha256": "0f218606a2548630f5f2f0c63f452a72cbf90f00a452e920482661d1af7f210a"
        },
        "downloads": -1,
        "filename": "haipproxy-0.11.1.tar.gz",
        "has_sig": false,
        "md5_digest": "e0446a07b280f0d7c2548a9db824865a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 11195,
        "upload_time": "2018-06-17T06:06:35",
        "upload_time_iso_8601": "2018-06-17T06:06:35.911221Z",
        "url": "https://files.pythonhosted.org/packages/cd/b7/243ec61277c34d6efb605d61c66deea548056a47789bb6bbd239e2d20c38/haipproxy-0.11.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.11.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "250d2c86219ae543e26953c0fb71c67e1ac4b49adb92d7d735bebae664d0d03c",
          "md5": "8bb2e19da2d482a96938ef30eef4b26d",
          "sha256": "81a0d17921dc84154f609d3bd52269535ac8c358081cefa95aa508019220ebd0"
        },
        "downloads": -1,
        "filename": "haipproxy-0.11.3.tar.gz",
        "has_sig": false,
        "md5_digest": "8bb2e19da2d482a96938ef30eef4b26d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.4.0",
        "size": 23808,
        "upload_time": "2018-06-17T06:33:25",
        "upload_time_iso_8601": "2018-06-17T06:33:25.311272Z",
        "url": "https://files.pythonhosted.org/packages/25/0d/2c86219ae543e26953c0fb71c67e1ac4b49adb92d7d735bebae664d0d03c/haipproxy-0.11.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.11.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a8b568b876731950ebd502c9eadbf4a3850e7c124b5708b796c852a399793d23",
          "md5": "148dcf5e91c7958576137da947f49483",
          "sha256": "2c8d0e5d840ace4590c02507379b103c9271e4468e8acb783d847be0a8b8b702"
        },
        "downloads": -1,
        "filename": "haipproxy-0.11.4.tar.gz",
        "has_sig": false,
        "md5_digest": "148dcf5e91c7958576137da947f49483",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.4.0",
        "size": 23857,
        "upload_time": "2018-06-17T06:39:49",
        "upload_time_iso_8601": "2018-06-17T06:39:49.437644Z",
        "url": "https://files.pythonhosted.org/packages/a8/b5/68b876731950ebd502c9eadbf4a3850e7c124b5708b796c852a399793d23/haipproxy-0.11.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.11.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "85855e4bf920c980bdb1fd51468bde834bd28a59943ab3acc7bedea2f2859022",
          "md5": "26541d5e13b66fee2dcf8f109660e3b1",
          "sha256": "c00367754b4e145f80b08243d13ce2f6bc053a7f959a7275f00698e5c82a3bb2"
        },
        "downloads": -1,
        "filename": "haipproxy-0.11.5.tar.gz",
        "has_sig": false,
        "md5_digest": "26541d5e13b66fee2dcf8f109660e3b1",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.4.0",
        "size": 25861,
        "upload_time": "2018-06-17T14:13:46",
        "upload_time_iso_8601": "2018-06-17T14:13:46.073049Z",
        "url": "https://files.pythonhosted.org/packages/85/85/5e4bf920c980bdb1fd51468bde834bd28a59943ab3acc7bedea2f2859022/haipproxy-0.11.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.11.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c45dfab8aaecd798415d13addb65146ced18e2618e213c09244f0bf0d3d376af",
          "md5": "8df858547d252afabd55d9ca6bd30d24",
          "sha256": "85d15c028102ae10032ec517343c957424a5735b6dfbe0012668f9f0eb920dbd"
        },
        "downloads": -1,
        "filename": "haipproxy-0.11.6.tar.gz",
        "has_sig": false,
        "md5_digest": "8df858547d252afabd55d9ca6bd30d24",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.4.0",
        "size": 16428,
        "upload_time": "2018-06-18T02:34:00",
        "upload_time_iso_8601": "2018-06-18T02:34:00.778456Z",
        "url": "https://files.pythonhosted.org/packages/c4/5d/fab8aaecd798415d13addb65146ced18e2618e213c09244f0bf0d3d376af/haipproxy-0.11.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "c45dfab8aaecd798415d13addb65146ced18e2618e213c09244f0bf0d3d376af",
        "md5": "8df858547d252afabd55d9ca6bd30d24",
        "sha256": "85d15c028102ae10032ec517343c957424a5735b6dfbe0012668f9f0eb920dbd"
      },
      "downloads": -1,
      "filename": "haipproxy-0.11.6.tar.gz",
      "has_sig": false,
      "md5_digest": "8df858547d252afabd55d9ca6bd30d24",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.4.0",
      "size": 16428,
      "upload_time": "2018-06-18T02:34:00",
      "upload_time_iso_8601": "2018-06-18T02:34:00.778456Z",
      "url": "https://files.pythonhosted.org/packages/c4/5d/fab8aaecd798415d13addb65146ced18e2618e213c09244f0bf0d3d376af/haipproxy-0.11.6.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}