{
  "info": {
    "author": "UesleiDev",
    "author_email": "uesleibros@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Intended Audience :: Education",
      "License :: OSI Approved :: MIT License",
      "Operating System :: Microsoft :: Windows :: Windows 10",
      "Programming Language :: Python :: 3"
    ],
    "description": "The Tokenizer package provides an easy-to-use and efficient way to tokenize text data. The Tokenizer package is built with performance in mind, making it a fast and reliable choice for tokenizing text data at scale.",
    "description_content_type": "",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "tokenizer, token,basic-tokenizer,basic,easy-and-useful",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "basictokenizer",
    "package_url": "https://pypi.org/project/basictokenizer/",
    "platform": null,
    "project_url": "https://pypi.org/project/basictokenizer/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/basictokenizer/0.0.4/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "A basic and useful tokenizer.",
    "version": "0.0.4",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16718374,
  "releases": {
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b6fed12d3e372d721df9658e6bb292eba91364953b10abf1ab6c25caf148b084",
          "md5": "1c4754041fb68b2d729fb12ab094972d",
          "sha256": "86150f53d271937991f1cb1b1492fd72f8bddb71be9104af92743200f24671e7"
        },
        "downloads": -1,
        "filename": "basictokenizer-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "1c4754041fb68b2d729fb12ab094972d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 2085,
        "upload_time": "2023-02-06T23:03:33",
        "upload_time_iso_8601": "2023-02-06T23:03:33.130967Z",
        "url": "https://files.pythonhosted.org/packages/b6/fe/d12d3e372d721df9658e6bb292eba91364953b10abf1ab6c25caf148b084/basictokenizer-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "438b680dc8102176b52bf89734ccc038ff030592b3b42974c872e0652338c91a",
          "md5": "fe455531bb2a4269b57e81a36b2d5854",
          "sha256": "2d90e03a90dd8de344ea2aeb0209b24af897eb312754df1370bee6bb899a32c9"
        },
        "downloads": -1,
        "filename": "basictokenizer-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "fe455531bb2a4269b57e81a36b2d5854",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 2019,
        "upload_time": "2023-02-06T23:05:35",
        "upload_time_iso_8601": "2023-02-06T23:05:35.921312Z",
        "url": "https://files.pythonhosted.org/packages/43/8b/680dc8102176b52bf89734ccc038ff030592b3b42974c872e0652338c91a/basictokenizer-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3aed76ca2bb72c59cd1b924b0446a5337a8c976d82e8cc050ad9037cd9530ad7",
          "md5": "44d30e6fcb7a555289b58ff34a8f7d3a",
          "sha256": "bc86d245127ecff3fcb065a2e1bcf7dbaf9c1c1754f3b671cf2804c391726089"
        },
        "downloads": -1,
        "filename": "basictokenizer-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "44d30e6fcb7a555289b58ff34a8f7d3a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 2106,
        "upload_time": "2023-02-06T23:07:12",
        "upload_time_iso_8601": "2023-02-06T23:07:12.010483Z",
        "url": "https://files.pythonhosted.org/packages/3a/ed/76ca2bb72c59cd1b924b0446a5337a8c976d82e8cc050ad9037cd9530ad7/basictokenizer-0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "3aed76ca2bb72c59cd1b924b0446a5337a8c976d82e8cc050ad9037cd9530ad7",
        "md5": "44d30e6fcb7a555289b58ff34a8f7d3a",
        "sha256": "bc86d245127ecff3fcb065a2e1bcf7dbaf9c1c1754f3b671cf2804c391726089"
      },
      "downloads": -1,
      "filename": "basictokenizer-0.0.4.tar.gz",
      "has_sig": false,
      "md5_digest": "44d30e6fcb7a555289b58ff34a8f7d3a",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 2106,
      "upload_time": "2023-02-06T23:07:12",
      "upload_time_iso_8601": "2023-02-06T23:07:12.010483Z",
      "url": "https://files.pythonhosted.org/packages/3a/ed/76ca2bb72c59cd1b924b0446a5337a8c976d82e8cc050ad9037cd9530ad7/basictokenizer-0.0.4.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}