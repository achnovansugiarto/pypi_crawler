{
  "info": {
    "author": "Peter Baumgartner",
    "author_email": "5107405+pmbaumgartner@users.noreply.github.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9"
    ],
    "description": "# HTML-friendly spaCy Tokenizer\n\nIt's not an [HTML tokenizer](https://www.w3.org/TR/2011/WD-html5-20110113/tokenization.html#tokenization), but a tokenizer that works with text that happens to be embedded in HTML. \n\n**Install**\n\n```\npip install spacy-html-tokenizer\n```\n\n## How it works\n\nUnder the hood we use [`selectolax`](https://github.com/rushter/selectolax) to parse HTML. From there, common elements used for styling within traditional text elements (e.g. `<b>` or `<span>` inside of a `<p>`) are [unwrapped](https://selectolax.readthedocs.io/en/latest/parser.html#selectolax.parser.HTMLParser.unwrap_tags), meaning the text contained within those elements becomes nested inside their parent elements. You can change this with the `unwrapped_tags` argument to the constructor. Tags used for non-text content, such as `<script>` and `<style>` are removed. Then the text is extracted from each remaining terminal node that contains text. These texts are then tokenized with the standard tokenizer defaults and then combined into a single `Doc`. The end result is a `Doc`, but each element's text from the original document is also a [sentence](https://spacy.io/api/doc#sents), so you can iterate through each element's text with `doc.sents`.\n\n## Example\n\n```python\nimport spacy\nfrom spacy_html_tokenizer import create_html_tokenizer\n\nnlp = spacy.blank(\"en\")\nnlp.tokenizer = create_html_tokenizer()(nlp)\n\nhtml = \"\"\"<h2>An Ordered HTML List</h2>\n<ol>\n    <li><b>Good</b> coffee. There's another sentence here</li>\n    <li>Tea and honey</li>\n    <li>Milk</li>\n</ol>\"\"\"\n\ndoc = nlp(html)\nfor sent in doc.sents:\n    print(sent.text, \"-- N Tokens:\", len(sent))\n\n# An Ordered HTML List -- N Tokens: 4\n# Good coffee. There's another sentence here -- N Tokens: 8\n# Tea and honey -- N Tokens: 3\n# Milk -- N Tokens: 1\n```\n\nIn the prior example, we didn't have any other sentence boundary detection components. However, this will also work with downstream sentence boundary detection components -- e.g.\n\n```python\nnlp = spacy.load(\"en_core_web_sm\")  # has parser for sentence boundary detection\nnlp.tokenizer = create_html_tokenizer()(nlp)\n\ndoc = nlp(html)\nfor sent in doc.sents:\n    print(sent.text, \"-- N Tokens:\", len(sent))\n\n# An Ordered HTML List -- N Tokens: 4\n# Good coffee. -- N Tokens: 3\n# There's another sentence here -- N Tokens: 5\n# Tea and honey -- N Tokens: 3\n# Milk -- N Tokens: 1\n```\n\n### Comparison\n\nWe'll compare parsing [Explosion's About page](https://explosion.ai/about) with and without the HTML tokenizer.\n\n```python\nimport requests\nimport spacy\nfrom spacy_html_tokenizer import create_html_tokenizer\nfrom selectolax.parser import HTMLParser\n\nabout_page_html = requests.get(\"https://explosion.ai/about\").text\n\nnlp_default = spacy.load(\"en_core_web_lg\")\nnlp_html = spacy.load(\"en_core_web_lg\")\nnlp_html.tokenizer = create_html_tokenizer()(nlp_html)\n\n# text from HTML - used for non-HTML default tokenizer\nabout_page_text = HTMLParser(about_page_html).text()\n\ndoc_default = nlp_default(about_page_text)\ndoc_html = nlp_html(about_page_html)\n```\n\n#### View first sentences of each\n\nWith standard tokenizer on text extracted from HTML\n\n```python\nlist(sent.text for sent in doc_default.sents)[:5]\n```\n\n```python\n['AboutSoftware & DemosCustom SolutionsBlog & NewsAbout usExplosion is a software company specializing in developer tools for Artificial\\nIntelligence and Natural Language Processing.',\n'We’re the makers of\\nspaCy, one of the leading open-source libraries for advanced\\nNLP and Prodigy, an annotation tool for radically efficient\\nmachine teaching.',\n'\\n\\n',\n'Ines Montani CEO, FounderInes is a co-founder of Explosion and a core developer of the spaCy NLP library and the Prodigy annotation tool.',\n'She has helped set a new standard for user experience in developer tools for AI engineers and researchers.']\n```\n\nWith HTML Tokenizer on HTML\n\n```python\nlist(sent.text for sent in doc_html.sents)[:10]\n```\n\n```python\n['About us · Explosion',\n 'About',\n 'Software',\n '&',\n 'Demos',\n 'Custom Solutions',\n 'Blog & News',\n 'About us',\n 'Explosion is a software company specializing in developer tools for Artificial Intelligence and Natural Language Processing.',\n 'We’re the makers of spaCy, one of the leading open-source libraries for advanced NLP and Prodigy, an annotation tool for radically efficient machine teaching.']\n```\n\nWhat about the last sentence?\n\n```python\nlist(sent.text for sent in doc_default.sents)[-1]\n\n# We’re the makers of spaCy, one of the leading open-source libraries for advanced NLP.NavigationHomeAbout usSoftware & DemosCustom SolutionsBlog & NewsOur SoftwarespaCy · Industrial-strength NLPProdigy · Radically efficient annotationThinc · Functional deep learning© 2016-2022 Explosion · Legal & Imprint/*<![CDATA[*/window.pagePath=\"/about\";/*]]>*//*<![CDATA[*/window.___chunkMapping={\"app\":[\"/app-ac229f07fa81f29e0f2d.js\"],\"component---node-modules-gatsby-plugin-offline-app-shell-js\":[\"/component---node-modules-gatsby-plugin-offline-app-shell-js-461e7bc49c6ae8260783.js\"],\"component---src-components-post-js\":[\"/component---src-components-post-js-cf4a6bf898db64083052.js\"],\"component---src-pages-404-js\":[\"/component---src-pages-404-js-b7a6fa1d9d8ca6c40071.js\"],\"component---src-pages-blog-js\":[\"/component---src-pages-blog-js-1e313ce0b28a893d3966.js\"],\"component---src-pages-index-js\":[\"/component---src-pages-index-js-175434c68a53f68a253a.js\"],\"component---src-pages-spacy-tailored-pipelines-js\":[\"/component---src-pages-spacy-tailored-pipelines-js-028d0c6c19584ef0935f.js\"]};/*]]>*/\n```\n\nYikes. How about HTML Tokenizer?\n\n```python\nlist(sent.text for sent in doc_html.sents)[-1]\n\n# '© 2016-2022 Explosion · Legal & Imprint'\n```\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/pmbaumgartner/spacy-html-tokenizer",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "spacy-html-tokenizer",
    "package_url": "https://pypi.org/project/spacy-html-tokenizer/",
    "platform": null,
    "project_url": "https://pypi.org/project/spacy-html-tokenizer/",
    "project_urls": {
      "Homepage": "https://github.com/pmbaumgartner/spacy-html-tokenizer",
      "Repository": "https://github.com/pmbaumgartner/spacy-html-tokenizer"
    },
    "release_url": "https://pypi.org/project/spacy-html-tokenizer/0.1.3/",
    "requires_dist": [
      "spacy (>=3.2.2,<4.0.0)",
      "selectolax (>=0.3.6,<0.4.0)"
    ],
    "requires_python": ">=3.7,<4.0",
    "summary": "An HTML-friendly spaCy tokenizer",
    "version": "0.1.3",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 13205233,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6619c25f5c8ed70c2005704b7cd16fdf3059bb3e6d2a5219290aa16e6336f314",
          "md5": "bdd521480b12970407f5872714995aa2",
          "sha256": "82602a371e1b30161da8395beaa65b90e7e3c1ef2bbec1c2a68fbb92a79c6ca5"
        },
        "downloads": -1,
        "filename": "spacy_html_tokenizer-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "bdd521480b12970407f5872714995aa2",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8,<4.0",
        "size": 5408,
        "upload_time": "2022-02-25T13:52:36",
        "upload_time_iso_8601": "2022-02-25T13:52:36.269070Z",
        "url": "https://files.pythonhosted.org/packages/66/19/c25f5c8ed70c2005704b7cd16fdf3059bb3e6d2a5219290aa16e6336f314/spacy_html_tokenizer-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e561012445e4f82d185542a936e306e7dcfea0a227789813ca722c25f4332d4e",
          "md5": "3996c9dd60960c726412b07487a997d8",
          "sha256": "3cb63df12b36880bd8f9a28dcfc4f73dcd87a8b8e27a3687cc189af4b9439abf"
        },
        "downloads": -1,
        "filename": "spacy-html-tokenizer-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "3996c9dd60960c726412b07487a997d8",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8,<4.0",
        "size": 5289,
        "upload_time": "2022-02-25T13:52:34",
        "upload_time_iso_8601": "2022-02-25T13:52:34.902844Z",
        "url": "https://files.pythonhosted.org/packages/e5/61/012445e4f82d185542a936e306e7dcfea0a227789813ca722c25f4332d4e/spacy-html-tokenizer-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "27d351d1e7ab18dd90313188ee1e500a41fc8a0f4c738fa9f119af0e6b8d65b6",
          "md5": "194d738dc52a4e119371043170b82605",
          "sha256": "986d0481bd554ea7821e9afed61e101c3a9fa19686300ed651d10774eea1c7b0"
        },
        "downloads": -1,
        "filename": "spacy_html_tokenizer-0.1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "194d738dc52a4e119371043170b82605",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8,<4.0",
        "size": 5447,
        "upload_time": "2022-02-25T15:25:22",
        "upload_time_iso_8601": "2022-02-25T15:25:22.402341Z",
        "url": "https://files.pythonhosted.org/packages/27/d3/51d1e7ab18dd90313188ee1e500a41fc8a0f4c738fa9f119af0e6b8d65b6/spacy_html_tokenizer-0.1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bb488a3ac975561ec810f86fc43475566d7492cdb5173a677981deb469c1b450",
          "md5": "cd021d250ce25a08c655dc5bc784b73f",
          "sha256": "9c1e1f070536b52104f096b4ab045eebaf9c444196768c1be3de467716eedfc4"
        },
        "downloads": -1,
        "filename": "spacy-html-tokenizer-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "cd021d250ce25a08c655dc5bc784b73f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8,<4.0",
        "size": 5345,
        "upload_time": "2022-02-25T15:25:20",
        "upload_time_iso_8601": "2022-02-25T15:25:20.646764Z",
        "url": "https://files.pythonhosted.org/packages/bb/48/8a3ac975561ec810f86fc43475566d7492cdb5173a677981deb469c1b450/spacy-html-tokenizer-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d650f6cc1668f5c5ea1a5e0ed31a63d09a5694841826e8b1a0a586d66d42dc17",
          "md5": "a5e0a1fd3530aa5b26997032788baf1f",
          "sha256": "5cc96777a31561d2accb8b000e2028ed8ddc80cbea95724f6d7ac5b473631c1a"
        },
        "downloads": -1,
        "filename": "spacy_html_tokenizer-0.1.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "a5e0a1fd3530aa5b26997032788baf1f",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7,<4.0",
        "size": 5474,
        "upload_time": "2022-03-17T13:26:01",
        "upload_time_iso_8601": "2022-03-17T13:26:01.412201Z",
        "url": "https://files.pythonhosted.org/packages/d6/50/f6cc1668f5c5ea1a5e0ed31a63d09a5694841826e8b1a0a586d66d42dc17/spacy_html_tokenizer-0.1.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "99fe122a2577bb6934b1d69605b557a41da2bb706afd0f1e514aba721605846b",
          "md5": "4eea3d60c51b22a7857b4b947a90fc84",
          "sha256": "ad1dd427e2c8a29e2e477812d96f327a728535e29cfbc4180babfa5ecfee8e55"
        },
        "downloads": -1,
        "filename": "spacy-html-tokenizer-0.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "4eea3d60c51b22a7857b4b947a90fc84",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7,<4.0",
        "size": 5381,
        "upload_time": "2022-03-17T13:25:59",
        "upload_time_iso_8601": "2022-03-17T13:25:59.568512Z",
        "url": "https://files.pythonhosted.org/packages/99/fe/122a2577bb6934b1d69605b557a41da2bb706afd0f1e514aba721605846b/spacy-html-tokenizer-0.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d17705a027d05130f524002c796a201078c69a78005ce73a7c82acfb24708256",
          "md5": "e0d505891e011bc9bb6d348ee6f350ed",
          "sha256": "f15cd3b1967949d0730eb41701afc5eebe672224ff82af3d54317063caeba3ac"
        },
        "downloads": -1,
        "filename": "spacy_html_tokenizer-0.1.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "e0d505891e011bc9bb6d348ee6f350ed",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7,<4.0",
        "size": 5452,
        "upload_time": "2022-03-17T13:47:30",
        "upload_time_iso_8601": "2022-03-17T13:47:30.896519Z",
        "url": "https://files.pythonhosted.org/packages/d1/77/05a027d05130f524002c796a201078c69a78005ce73a7c82acfb24708256/spacy_html_tokenizer-0.1.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8fdb68f112d9b206f1162d383fd0f464fa9052a8912180950789c9bdeb945b53",
          "md5": "a8919d81c28adc264e87beca601f045e",
          "sha256": "dbdb74ef5b2da4579985f43c6a63c389936371b10b5bc2e6526f42c2af47d633"
        },
        "downloads": -1,
        "filename": "spacy-html-tokenizer-0.1.3.tar.gz",
        "has_sig": false,
        "md5_digest": "a8919d81c28adc264e87beca601f045e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7,<4.0",
        "size": 5362,
        "upload_time": "2022-03-17T13:47:29",
        "upload_time_iso_8601": "2022-03-17T13:47:29.792042Z",
        "url": "https://files.pythonhosted.org/packages/8f/db/68f112d9b206f1162d383fd0f464fa9052a8912180950789c9bdeb945b53/spacy-html-tokenizer-0.1.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "d17705a027d05130f524002c796a201078c69a78005ce73a7c82acfb24708256",
        "md5": "e0d505891e011bc9bb6d348ee6f350ed",
        "sha256": "f15cd3b1967949d0730eb41701afc5eebe672224ff82af3d54317063caeba3ac"
      },
      "downloads": -1,
      "filename": "spacy_html_tokenizer-0.1.3-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "e0d505891e011bc9bb6d348ee6f350ed",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7,<4.0",
      "size": 5452,
      "upload_time": "2022-03-17T13:47:30",
      "upload_time_iso_8601": "2022-03-17T13:47:30.896519Z",
      "url": "https://files.pythonhosted.org/packages/d1/77/05a027d05130f524002c796a201078c69a78005ce73a7c82acfb24708256/spacy_html_tokenizer-0.1.3-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "8fdb68f112d9b206f1162d383fd0f464fa9052a8912180950789c9bdeb945b53",
        "md5": "a8919d81c28adc264e87beca601f045e",
        "sha256": "dbdb74ef5b2da4579985f43c6a63c389936371b10b5bc2e6526f42c2af47d633"
      },
      "downloads": -1,
      "filename": "spacy-html-tokenizer-0.1.3.tar.gz",
      "has_sig": false,
      "md5_digest": "a8919d81c28adc264e87beca601f045e",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7,<4.0",
      "size": 5362,
      "upload_time": "2022-03-17T13:47:29",
      "upload_time_iso_8601": "2022-03-17T13:47:29.792042Z",
      "url": "https://files.pythonhosted.org/packages/8f/db/68f112d9b206f1162d383fd0f464fa9052a8912180950789c9bdeb945b53/spacy-html-tokenizer-0.1.3.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}