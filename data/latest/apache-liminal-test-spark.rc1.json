{
  "info": {
    "author": "dev@liminal.apache.org",
    "author_email": "dev@liminal.apache.org",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "<!--\nLicensed to the Apache Software Foundation (ASF) under one\nor more contributor license agreements.  See the NOTICE file\ndistributed with this work for additional information\nregarding copyright ownership.  The ASF licenses this file\nto you under the Apache License, Version 2.0 (the\n\"License\"); you may not use this file except in compliance\nwith the License.  You may obtain a copy of the License at\n\n  http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing,\nsoftware distributed under the License is distributed on an\n\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\nKIND, either express or implied.  See the License for the\nspecific language governing permissions and limitations\nunder the License.\n-->\n\n# Apache Liminal\n\nApache Liminal is an end-to-end platform for data engineers & scientists, allowing them to build,\ntrain and deploy machine learning models in a robust and agile way.\n\nThe platform provides the abstractions and declarative capabilities for\ndata extraction & feature engineering followed by model training and serving.\nLiminal's goal is to operationalize the machine learning process, allowing data scientists to\nquickly transition from a successful experiment to an automated pipeline of model training,\nvalidation, deployment and inference in production, freeing them from engineering and\nnon-functional tasks, and allowing them to focus on machine learning code and artifacts.\n\n# Basics\n\nUsing simple YAML configuration, create your own schedule data pipelines (a sequence of tasks to\nperform), application servers,  and more.\n\n## Getting Started\nA simple getting stated guide for Liminal can be found [here](docs/getting_started.md)\n\n## Apache Liminal Documentation\nFull documentation of Apache Liminal can be found [here](docs/liminal)\n\n## High Level Architecture\nHigh level architecture documentation can be found [here](docs/architecture.md)\n\n## Example YAML config file\n```yaml\n---\nname: MyLiminalStack\nowner: Bosco Albert Baracus\nvolumes:\n  - volume: myvol1\n    local:\n      path: /Users/me/myvol1\npipelines:\n  - pipeline: my_pipeline\n    start_date: 1970-01-01\n    timeout_minutes: 45\n    schedule: 0 * 1 * *\n    metrics:\n      namespace: TestNamespace\n      backends: [ 'cloudwatch' ]\n    tasks:\n      - task: my_python_task\n        type: python\n        description: static input task\n        image: my_python_task_img\n        source: write_inputs\n        env_vars:\n          NUM_FILES: 10\n          NUM_SPLITS: 3\n        mounts:\n          - mount: mymount\n            volume: myvol1\n            path: /mnt/vol1\n        cmd: python -u write_inputs.py\n      - task: my_parallelized_python_task\n        type: python\n        description: parallelized python task\n        image: my_parallelized_python_task_img\n        source: write_outputs\n        env_vars:\n          FOO: BAR\n        executors: 3\n        mounts:\n          - mount: mymount\n            volume: myvol1\n            path: /mnt/vol1\n        cmd: python -u write_inputs.py\nservices:\n  - service:\n    name: my_python_server\n    type: python_server\n    description: my python server\n    image: my_server_image\n    source: myserver\n    endpoints:\n      - endpoint: /myendpoint1\n        module: my_server\n        function: myendpoint1func\n```\n\n\n# Installation\n1. Install this repository (HEAD)\n```bash\n   pip install git+https://github.com/apache/incubator-liminal.git\n```\n2. Optional: set LIMINAL_HOME to path of your choice (if not set, will default to ~/liminal_home)\n```bash\necho 'export LIMINAL_HOME=</path/to/some/folder>' >> ~/.bash_profile && source ~/.bash_profile\n```\n\n# Authoring pipelines\n\nThis involves at minimum creating a single file called liminal.yml as in the example above.\n\nIf your pipeline requires custom python code to implement tasks, they should be organized \n[like this](https://github.com/apache/incubator-liminal/tree/master/tests/runners/airflow/liminal)\n\nIf your pipeline  introduces imports of external packages which are not already a part \nof the liminal framework (i.e. you had to pip install them yourself), you need to also provide \na requirements.txt in the root of your project.\n\n# Testing the pipeline locally\n\nWhen your pipeline code is ready, you can test it by running it locally on your machine.\n\n1. Ensure you have The Docker engine running locally, and enable a local Kubernetes cluster:\n![Kubernetes configured](https://raw.githubusercontent.com/apache/incubator-liminal/master/images/k8s_running.png)\n\nAnd allocate it at least 3 CPUs (under \"Resources\" in the Docker preference UI).\n\nIf you want to execute your pipeline on a remote kubernetes cluster, make sure the cluster is configured\nusing :\n```bash\nkubectl config set-context <your remote kubernetes cluster>\n``` \n2. Build the docker images used by your pipeline.\n\nIn the example pipeline above, you can see that tasks and services have an \"image\" field - such as \n\"my_static_input_task_image\". This means that the task is executed inside a docker container, and the docker container \nis created from a docker image where various code and libraries are installed.\n\nYou can take a look at what the build process looks like, e.g. \n[here](https://github.com/apache/incubator-liminal/tree/master/liminal/build/image/python)\n\nIn order for the images to be available for your pipeline, you'll need to build them locally:\n\n```bash\ncd </path/to/your/liminal/code>\nliminal build\n```\n\nYou'll see that a number of outputs indicating various docker images built.\n\n3. Create a kubernetes local volume \\\nIn case your Yaml includes working with [volumes](https://github.com/apache/incubator-liminal/blob/6253f8b2c9dc244af032979ec6d462dc3e07e170/docs/getting_started.md#mounted-volumes)\nplease first run the following command:\n```bash\ncd </path/to/your/liminal/code> \nliminal create\n```\n\n4. Deploy the pipeline:\n```bash\ncd </path/to/your/liminal/code> \nliminal deploy\n```\nNote: after upgrading liminal, it's recommended to issue the command \n```bash\nliminal deploy --clean\n``` \n\nThis will rebuild the airlfow docker containers from scratch with a fresh version of liminal, ensuring consistency.\n\n5. Start the server\n```bash\nliminal start\n```\n\n6. Stop the server\n```bash\nliminal stop\n```\n\n7. Display the server logs\n```bash\nliminal logs --follow/--tail\n\nNumber of lines to show from the end of the log:\nliminal logs --tail=10\n\nFollow log output:\nliminal logs --follow\n```\n\n8. Navigate to [http://localhost:8080/admin](http://localhost:8080/admin)\n\n9. You should see your ![pipeline](https://raw.githubusercontent.com/apache/incubator-liminal/master/images/airflow.png)\nThe pipeline is scheduled to run according to the ```json schedule: 0 * 1 * *``` field in the .yml file you provided.\n\n10. To manually activate your pipeline:\nClick your pipeline and then click \"trigger DAG\"\nClick \"Graph view\"\nYou should see the steps in your pipeline getting executed in \"real time\" by clicking \"Refresh\" periodically.\n\n![Pipeline activation](https://raw.githubusercontent.com/apache/incubator-liminal/master/images/airflow_trigger.png)\n\n# Contributing\n\nMore information on contributing can be found [here](CONTRIBUTING.md)\n\n## Running Tests (for contributors)\nWhen doing local development and running Liminal unit-tests, make sure to set LIMINAL_STAND_ALONE_MODE=True\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/apache/incubator-liminal",
    "keywords": "",
    "license": "Apache License, Version 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "apache-liminal-test-spark",
    "package_url": "https://pypi.org/project/apache-liminal-test-spark/",
    "platform": "",
    "project_url": "https://pypi.org/project/apache-liminal-test-spark/",
    "project_urls": {
      "Homepage": "https://github.com/apache/incubator-liminal"
    },
    "release_url": "https://pypi.org/project/apache-liminal-test-spark/0.0.0/",
    "requires_dist": [
      "docker (==4.2.0)",
      "apache-airflow (==1.10.12)",
      "click (==7.1.1)",
      "Flask (==1.1.1)",
      "pyyaml (==5.3.1)",
      "boto3 (==1.12.10)",
      "botocore (==1.15.21)",
      "kubernetes (==12.0.1)",
      "wheel (==0.36.2)",
      "termcolor (~=1.1.0)",
      "docker-pycreds (==0.4.0)",
      "typing (==3.7.4.1)",
      "GitPython (==3.1.11)",
      "moto (==1.3.14)",
      "diskcache (==3.1.1)",
      "croniter (==0.3.31)",
      "pytz (==2020.5)",
      "pytzdata (==2020.1)",
      "freezegun (==1.1.0)",
      "statsd (<4.0,>=3.3.0)",
      "sqlalchemy (~=1.3.15)",
      "flatdict (==3.4.0)",
      "jinja2 (<2.11.0,>=2.10.1)",
      "python-json-logger (==2.0.1)"
    ],
    "requires_python": ">=3.6",
    "summary": "A package for authoring and deploying machine learning workflows",
    "version": "0.0.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 10943408,
  "releases": {
    "0.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "49bfe84539c1d5d196ebcc166efb44149d8d1d5af0cd2aacf1957b7c64e63a36",
          "md5": "d59d94b095d4a24f195450949ad68dfd",
          "sha256": "90884398f7c30125144072fbe52c04178aa43d4da6ab8136285e110c85ec11cb"
        },
        "downloads": -1,
        "filename": "apache_liminal_test_spark-0.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d59d94b095d4a24f195450949ad68dfd",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 176684,
        "upload_time": "2021-07-19T06:09:15",
        "upload_time_iso_8601": "2021-07-19T06:09:15.585335Z",
        "url": "https://files.pythonhosted.org/packages/49/bf/e84539c1d5d196ebcc166efb44149d8d1d5af0cd2aacf1957b7c64e63a36/apache_liminal_test_spark-0.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1576a116c7d3e8ab73bfc9eab8967058b9a416da32a2661b66302bc31a9ad1e1",
          "md5": "74955f281dc2807fd4045db1fb57ffea",
          "sha256": "9cb974ec420703f20a62ae83b3b81baed2d02463aa225d546ddb195f59c3dc18"
        },
        "downloads": -1,
        "filename": "apache-liminal-test-spark-0.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "74955f281dc2807fd4045db1fb57ffea",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 57968,
        "upload_time": "2021-07-19T06:09:17",
        "upload_time_iso_8601": "2021-07-19T06:09:17.713232Z",
        "url": "https://files.pythonhosted.org/packages/15/76/a116c7d3e8ab73bfc9eab8967058b9a416da32a2661b66302bc31a9ad1e1/apache-liminal-test-spark-0.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "49bfe84539c1d5d196ebcc166efb44149d8d1d5af0cd2aacf1957b7c64e63a36",
        "md5": "d59d94b095d4a24f195450949ad68dfd",
        "sha256": "90884398f7c30125144072fbe52c04178aa43d4da6ab8136285e110c85ec11cb"
      },
      "downloads": -1,
      "filename": "apache_liminal_test_spark-0.0.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "d59d94b095d4a24f195450949ad68dfd",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 176684,
      "upload_time": "2021-07-19T06:09:15",
      "upload_time_iso_8601": "2021-07-19T06:09:15.585335Z",
      "url": "https://files.pythonhosted.org/packages/49/bf/e84539c1d5d196ebcc166efb44149d8d1d5af0cd2aacf1957b7c64e63a36/apache_liminal_test_spark-0.0.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "1576a116c7d3e8ab73bfc9eab8967058b9a416da32a2661b66302bc31a9ad1e1",
        "md5": "74955f281dc2807fd4045db1fb57ffea",
        "sha256": "9cb974ec420703f20a62ae83b3b81baed2d02463aa225d546ddb195f59c3dc18"
      },
      "downloads": -1,
      "filename": "apache-liminal-test-spark-0.0.0.tar.gz",
      "has_sig": false,
      "md5_digest": "74955f281dc2807fd4045db1fb57ffea",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 57968,
      "upload_time": "2021-07-19T06:09:17",
      "upload_time_iso_8601": "2021-07-19T06:09:17.713232Z",
      "url": "https://files.pythonhosted.org/packages/15/76/a116c7d3e8ab73bfc9eab8967058b9a416da32a2661b66302bc31a9ad1e1/apache-liminal-test-spark-0.0.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}