{
  "info": {
    "author": "Jyotika Singh",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: GNU General Public License v3 (GPLv3)",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# pyYouTubeAnalysis\nInteraction with the YouTube API to pull data and run analysis using statistics and Natural Language Processing (NLP). Contains NLP implementations of text cleaning specific to social media data noise, key-phrase extraction using NLTK and Named-entity Recognition (NER) on a list of strings. Contains automatic plots, word clouds, and analysis report pdf generation.\n\n# Setup\n\n1. Use pip\n\n```\npip install pyYouTubeAnalysis\n```\nand run \n```\npython -m spacy download en_core_web_sm\n```\n\nOr,\n2. Clone the project from github and run the following for setup.\n\n```\ngit clone git@github.com:jsingh811/pyYouTubeAnalysis.git\ncd pyYouTubeAnalysis\npip install -e .\npython -m spacy download en_core_web_sm\n```\n\n# Demos\n\nTo see YouTube data extraction examples, see the section [YouTube Data Fetching](https://github.com/jsingh811/pyYouTubeAnalysis#youtube-data-fetching).\n\nTo see NER extraction examples, see the section [Extracting Locations](https://github.com/jsingh811/pyYouTubeAnalysis#extracting-locations).\n\nTo see Key-phrase extraction examples, see the section [Extracting Keyphrases from Text](https://github.com/jsingh811/pyYouTubeAnalysis#extracting-keyphrases-from-text).\n\nTo see data cleaning examples for removing emojis and URLs from text, see the section [Removing Emojis and URLs from Text](https://github.com/jsingh811/pyYouTubeAnalysis#removing-emojis-and-urls-from-text).\n\nTo see report generation with statistical and NLP analysis, see the section [Report Generation](https://github.com/jsingh811/pyYouTubeAnalysis#report-generation).\n\n\n# YouTube Data Fetching\n\n## Command Line Usage\n\n```\npython run_crawl.py -t \"<YouTube API key (39 chars long)>\" -k \"travel vlog\" -sd \"2020-01-01T00:00:00Z\" -ed \"2020-01-02T00:00:00Z\" -climit 5 -path \"/Users/abc/Documents\"\n```\n\n## Input Arguments\n\npath (-path): Path to the directory you want to save the data in  \nkeyword (-k): Keyword to search videos for  \nstart-date (-sd): Starting publish date of video to search. Format YYYY-MM-DDThh:mm:ssZ  \nend-date (-ed): Ending publish date of video to search. Format YYYY-MM-DDThh:mm:ssZ  \ntoken (-t): YouTube API access token  \ncomments (-c): Whether you want to fetch comment text for the videos  \ncomment-limit (-climit): Per video comment limit to fetch  \n\n\n## Import and Use\n\n```\nimport json\nfrom pyYouTubeAnalysis import (run_crawl, crawler)\n\nkeyword = \"travel\"\nstart_date = \"2020-01-01T00:00:00Z\"\nend_date = \"2020-01-02T00:00:00Z\"\ncomment_limit = 5\napi_token = \"<YouTube API key (39 chars long)>\"\npath = \"/Users/abc/Documents\"\napi = crawler.YouTubeCrawler(key=api_token)\n\n# Fetch data from the api\n[videos, comments] = run_crawl.get_videos_and_comments(\n     api,\n     keyword=keyword,\n     start_date=start_date,\n     end_date=end_date,\n     comment_limit=comment_limit\n)\n\n# Save the fetched data on disk\nwith open(\"/\".join([\n    path,\n    \"_\".join([\n        keyword,\n        start_date.replace(\":\", \"\"),\n        end_date.replace(\":\", \"\"),\n        \"video_details.json\"\n    ])\n]), \"w\") as f:\n      json.dump(videos, f, indent=2)\nwith open(\"/\".join([\n    path,\n    \"_\".join([\n        keyword,\n        start_date.replace(\":\", \"\"),\n        end_date.replace(\":\", \"\"),\n        \"comment_details.json\"\n    ])\n]), \"w\") as f:\n      json.dump(comments, f, indent=2)\n```\n## Sample output  \n\nThe data inside `...video_details.json` file that generates is a list of dictionaries, of the following format as shown in [this file](https://github.com/jsingh811/pyYouTubeAnalysis/blob/master/samples/travel%20vlog_2020-01-01T000000Z_2020-01-02T000000Z_video_details.json).  \n\nThe data inside `...comment_details.json` file that generates is a list of dictionaries, of the following format as shown in [this file](https://github.com/jsingh811/pyYouTubeAnalysis/blob/master/samples/travel%20vlog_2020-01-01T000000Z_2020-01-02T000000Z_comment_details.json).\n\n# Extracting Locations\n\nThe following contains examples for extracting location from comments file generated above.\n\n## Command Line Usage\n\nAssuming you are in the parent folder `pyYouTubeAnalysis` after cloning and setting up the project, the following sample command can be used. Please alter -filepath accordingly.\n\n```\npython extract_locations.py -filepath \"/Users/abc/Documents/travel_comment_details.json\"\n```  \n\n## Import and Use\n\n```\nfrom pyYouTubeAnalysis import extract_locations\n\nfilepath = \"/Users/abc/Documents/travel_comment_details.json\"\n\ncomments = extract_locations.read_comment_text(filepath)\nlocations = extract_locations.extract_locations(comments)\n```\n\n## Sample output  \n\nThe data inside `locations_....json` file that generates using the [command line usage](https://github.com/jsingh811/pyYouTubeAnalysis#command-line-usage-1) example, or the variable `locations` in the [import and use](https://github.com/jsingh811/pyYouTubeAnalysis#import-and-use-1) example is a dictionary of location names as keys and their occurrence counts as values of the format as shown in [this file](https://github.com/jsingh811/pyYouTubeAnalysis/blob/master/samples/locations_travel%20vlog_2020-01-01T000000Z_2020-01-02T000000Z_comment_details.json).\n\n\n# Extracting Keyphrases from Text\n\n## Import and Use\n\n```\nfrom pyYouTubeAnalysis.phrases import KeyPhraseGenerator\n\ndocuments = [\n            \"\"\"Did you know about this conference in Miami? It is about Natural\n            Language Processing techniques as applied to messy data.\"\"\",\n            \"I really enjoyed the chocolate cheesecake yesterday!\"\n]\n\nkp = KeyPhraseGenerator()\n\nphrases =  kp.extract_keyphrases(documents)\n\n```\n\n# Removing Emojis and URLs from Text\n\n## Import and Use\n\n```\nfrom pyYouTubeAnalysis import cleaner\n\ndocument = \" emoji was here -> ðŸ˜ƒ , and url was here -> https://github.com\"\n\n# remove emoji\nemoji_removed = cleaner.remove_emojis(document)\n\n# removing url \nurl_removed = cleaner.remove_urls(document)\n\n```\n\n# Report Generation\n\nThis functionality allows the user to crawl YouTube and gather stats related plots, wordclouds and location analysis in one pdf. The files generated as a part of this can be found in [this folder](https://github.com/jsingh811/pyYouTubeAnalysis/blob/master/samples/report).\n\n## Command Line Usage\n\nAssuming you are in the parent folder `pyYouTubeAnalysis` after cloning and setting up the project, the following sample command can be used. Please alter -path accordingly.\n\n```\npython report.py -path \"/Users/abc/Documents\" -k \"travel vlog\" -sd \"2020-01-01T00:00:00Z\" -ed \"2021-03-31T00:00:00Z\" -analysis \"monthly,yearly\"  -t \"<YouTube API key (39 chars long)>\"```  \n```\n\n## Import and Use\n\n```\nfrom pyYouTubeAnalysis.report import ReportGenerator\nfrom pyYouTubeAnalysis import run_crawl, crawler\n\nkeyword = \"travel vlog\"\nstart_date =  \"2020-01-01T00:00:00Z\"\nend_date = \"2021-03-31T00:00:00Z\"\nanalysis_type = [\"yearly\", \"monthly\"] \napi_token = \"<YouTube API key (39 chars long)>\"\npath = \"/Users/abc/Documents\"\n\nrgen = ReportGenerator(path, keyword, start_date, end_date, analysis_type)\n\napi = crawler.YouTubeCrawler(key=api_token)\n# Fetch data from the api\n[videos, comments] = run_crawl.get_videos_and_comments(\n    api, keyword=keyword, start_date=start_date, end_date=end_date, comment_limit=10\n)\nprint(\"\\nFetched data\\n\")\nrgen.get_and_plot_stats(videos)\nrgen.plot_trending_tags(videos)\nrgen.plot_comment_locations(comments)\nprint(\"\\nFetched plots\\n\")\noutput_path = rgen.export_to_pdf()\nprint(\"\\nGenerated pdf here {}\\n\".format(output_path))\n\n```\n\n# Citation \n\nPlease cite this software as below\n\n## APA\n\n```\nSingh, J. (2021). jsingh811/pyYouTubeAnalysis: YouTube Data Requests and Natural Language Processing on Text (v1.1) [Computer software]. Zenodo. https://doi.org/10.5281/ZENODO.5044556\n```\n\n## BibTex \n\n```\n@software{https://doi.org/10.5281/zenodo.5044556,\n  doi = {10.5281/ZENODO.5044556},\n  url = {https://zenodo.org/record/5044556},\n  author = {Singh,  Jyotika},\n  title = {jsingh811/pyYouTubeAnalysis: YouTube Data Requests and Natural Language Processing on Text},\n  publisher = {Zenodo},\n  year = {2021},\n  copyright = {Open Access}\n}\n```\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/jsingh811/pyYouTubeAnalysis",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "pyYouTubeAnalysis",
    "package_url": "https://pypi.org/project/pyYouTubeAnalysis/",
    "platform": "",
    "project_url": "https://pypi.org/project/pyYouTubeAnalysis/",
    "project_urls": {
      "Homepage": "https://github.com/jsingh811/pyYouTubeAnalysis"
    },
    "release_url": "https://pypi.org/project/pyYouTubeAnalysis/1.1/",
    "requires_dist": [
      "google-api-python-client (==1.7.5)",
      "pytest (==3.9.2)",
      "spacy (==3.0.6)",
      "nltk (==3.6.2)",
      "wordcloud (==1.8.1)",
      "matplotlib (==3.3.4)",
      "fpdf (==1.7.2)"
    ],
    "requires_python": ">=3.6, <4",
    "summary": "Interacting with YouTube Data API and running analysis using NLP",
    "version": "1.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 10871158,
  "releases": {
    "1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "77fe1f7d4d04735eb6c31d42cf3c56e1f7ef17a843fa54652a2d374c38f0bb1e",
          "md5": "6845c9de0c5f5953b083dc9777ebf6e6",
          "sha256": "a761d9950db78857b480a7cce4b9744e236abbfa12f8ad2b452a91e7ed745bff"
        },
        "downloads": -1,
        "filename": "pyYouTubeAnalysis-1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "6845c9de0c5f5953b083dc9777ebf6e6",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6, <4",
        "size": 25246,
        "upload_time": "2021-07-10T00:53:20",
        "upload_time_iso_8601": "2021-07-10T00:53:20.573766Z",
        "url": "https://files.pythonhosted.org/packages/77/fe/1f7d4d04735eb6c31d42cf3c56e1f7ef17a843fa54652a2d374c38f0bb1e/pyYouTubeAnalysis-1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7514d2d9090fb983aa4c6a46f18639e34c215ab057a9bd23e5c430fa9740c523",
          "md5": "0f9c69903699bb5f64349f74d989ba61",
          "sha256": "29935630e39eb5e995cdc89e81826dec8ea69c36dcc0f952d1a92d989d131a48"
        },
        "downloads": -1,
        "filename": "pyYouTubeAnalysis-1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "0f9c69903699bb5f64349f74d989ba61",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6, <4",
        "size": 24060,
        "upload_time": "2021-07-10T00:53:22",
        "upload_time_iso_8601": "2021-07-10T00:53:22.198633Z",
        "url": "https://files.pythonhosted.org/packages/75/14/d2d9090fb983aa4c6a46f18639e34c215ab057a9bd23e5c430fa9740c523/pyYouTubeAnalysis-1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "77fe1f7d4d04735eb6c31d42cf3c56e1f7ef17a843fa54652a2d374c38f0bb1e",
        "md5": "6845c9de0c5f5953b083dc9777ebf6e6",
        "sha256": "a761d9950db78857b480a7cce4b9744e236abbfa12f8ad2b452a91e7ed745bff"
      },
      "downloads": -1,
      "filename": "pyYouTubeAnalysis-1.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "6845c9de0c5f5953b083dc9777ebf6e6",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6, <4",
      "size": 25246,
      "upload_time": "2021-07-10T00:53:20",
      "upload_time_iso_8601": "2021-07-10T00:53:20.573766Z",
      "url": "https://files.pythonhosted.org/packages/77/fe/1f7d4d04735eb6c31d42cf3c56e1f7ef17a843fa54652a2d374c38f0bb1e/pyYouTubeAnalysis-1.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "7514d2d9090fb983aa4c6a46f18639e34c215ab057a9bd23e5c430fa9740c523",
        "md5": "0f9c69903699bb5f64349f74d989ba61",
        "sha256": "29935630e39eb5e995cdc89e81826dec8ea69c36dcc0f952d1a92d989d131a48"
      },
      "downloads": -1,
      "filename": "pyYouTubeAnalysis-1.1.tar.gz",
      "has_sig": false,
      "md5_digest": "0f9c69903699bb5f64349f74d989ba61",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6, <4",
      "size": 24060,
      "upload_time": "2021-07-10T00:53:22",
      "upload_time_iso_8601": "2021-07-10T00:53:22.198633Z",
      "url": "https://files.pythonhosted.org/packages/75/14/d2d9090fb983aa4c6a46f18639e34c215ab057a9bd23e5c430fa9740c523/pyYouTubeAnalysis-1.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}