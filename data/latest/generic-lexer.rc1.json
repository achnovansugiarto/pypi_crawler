{
  "info": {
    "author": "Eli Bendersky",
    "author_email": "eliben@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: The Unlicense (Unlicense)",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3 :: Only",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Programming Language :: Python :: Implementation :: CPython",
      "Programming Language :: Python :: Implementation :: PyPy",
      "Topic :: Software Development",
      "Topic :: Software Development :: Interpreters",
      "Topic :: Text Processing"
    ],
    "description": "# Generic Lexer\n[![image](https://img.shields.io/badge/license-Unlicense-blue.svg)](http://unlicense.org/)\n[![image](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n[![image](https://img.shields.io/github/workflow/status/cerberus1746/generic_lexer/Tox%20Testing%20Suite)](https://github.com/Cerberus1746/generic_lexer/actions?query=workflow%3A%22Tox+Testing+Suite%22)\n[![image](https://img.shields.io/codeclimate/coverage/Cerberus1746/generic_lexer)](https://codeclimate.com/github/Cerberus1746/generic_lexer/code)\n[![image](https://img.shields.io/codeclimate/coverage-letter/Cerberus1746/generic_lexer)](https://codeclimate.com/github/Cerberus1746/generic_lexer)\n\nA generic pattern-based Lexer/tokenizer tool.\n\nThe minimum python version is 3.6\n\n<dl>\n    <dt>Original Author</dt>\n    <dd>\n        <a href=\"mailto:eliben@gmail.com\">Eli Bendersky</a> with\n        <a href=\"https://gist.github.com/eliben/5797351\">this gist</a> last modified on 2010/08</dd>\n    <dt>Maintainer</dt>\n    <dd>\n        <a href=\"mailto:cerberus1746@gmail.com\">Leandro Benedet Garcia</a> last modified on 2020/11\n    </dd>\n    <dt>Version</dt>\n    <dd>1.1.0</dd>\n    <dt>License</dt>\n    <dd>The Unlicense</dd>\n    <dt>Documentation</dt>\n    <dd>\n        The documentation can be <a href=\"https://cerberus1746.github.io/generic_lexer/\">\n            found here\n        </a>\n    </dd>\n</dl>\n\n## Example\nIf we try to execute the following code:\n\n```python\nfrom generic_lexer import Lexer\n\n\nrules = {\n    \"VARIABLE\": r\"(?P<var_name>[a-z_]+): (?P<var_type>[A-Z]\\w+)\",\n    \"EQUALS\": r\"=\",\n    \"SPACE\": r\" \",\n    \"STRING\": r\"\\\".*\\\"\",\n}\n\ndata = \"first_word: String = \\\"Hello\\\"\"\ndata = data.strip()\n\nfor curr_token in Lexer(rules, False, data):\n    print(curr_token)\n```\n\nWill give us the following output:\n\n```python\nVARIABLE({'var_name': 'first_word', 'var_type': 'String'}) at 0\nSPACE( ) at 18\nEQUALS(=) at 19\nSPACE( ) at 20\nSTRING(\"Hello\") at 21\n```\n\nAs you can see differently from the original gist, we are capable of specifying multiple groups per token.\nYou cannot use the same group twice,\neither per token or not because all the regex patterns are merged together to generate the tokens later on.\n\nYou may get the values of the tokens this way:\n\n```python\n>>> from generic_lexer import Lexer\n>>> rules = {\n...     \"VARIABLE\": r\"(?P<var_name>[a-z_]+): (?P<var_type>[A-Z]\\w+)\",\n...     \"EQUALS\": r\"=\",\n...     \"STRING\": r\"\\\".*\\\"\",\n... }\n>>> data = \"first_word: String = \\\"Hello\\\"\"\n>>> variable, equals, string = tuple(Lexer(rules, True, data))\n\n>>> variable\nVARIABLE({'var_name': 'first_word', 'var_type': 'String'}) at 0\n\n>>> variable.val\n{'var_name': 'first_word', 'var_type': 'String'}\n>>> variable[\"var_name\"]\n'first_word'\n>>> variable[\"var_type\"]\n'String'\n\n>>> equals\nEQUALS(=) at 19\n\n>>> equals.val\n'='\n\n>>> string\nSTRING(\"Hello\") at 21\n\n>>> string.val\n'\"Hello\"'\n```\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/Cerberus1746/generic_lexer/",
    "keywords": "parser,lexer,tokenizer",
    "license": "The Unlicense",
    "maintainer": "Leandro Benedet Garcia",
    "maintainer_email": "cerberus1746@gmail.com",
    "name": "generic-lexer",
    "package_url": "https://pypi.org/project/generic-lexer/",
    "platform": "",
    "project_url": "https://pypi.org/project/generic-lexer/",
    "project_urls": {
      "Bug Tracker": "https://github.com/Cerberus1746/generic_lexer/issues",
      "Documentation": "https://cerberus1746.github.io/generic_lexer/",
      "Homepage": "https://github.com/Cerberus1746/generic_lexer/",
      "Repository": "https://github.com/Cerberus1746/generic_lexer"
    },
    "release_url": "https://pypi.org/project/generic-lexer/1.1.1/",
    "requires_dist": [
      "sphinx-autodoc-typehints ; extra == 'docs'",
      "sphinx-autodoc-typehints ; extra == 'tests'",
      "tox ; extra == 'tests'"
    ],
    "requires_python": ">=3.5",
    "summary": "A generic pattern-based Lexer/tokenizer tool.",
    "version": "1.1.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8749622,
  "releases": {
    "1.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "528b07a438b8b31b46f016f6473a1900927008e62057c7a6b7d87dcfb63c7714",
          "md5": "24649decdedaa3eca66e9e7ac0c9f171",
          "sha256": "10c9331e365d0c4d01529dbc699e62cd0281ef618e145f2e54e15b4e69d8bcbd"
        },
        "downloads": -1,
        "filename": "generic_lexer-1.1.1-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "24649decdedaa3eca66e9e7ac0c9f171",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": ">=3.5",
        "size": 7516,
        "upload_time": "2020-11-25T20:56:08",
        "upload_time_iso_8601": "2020-11-25T20:56:08.187348Z",
        "url": "https://files.pythonhosted.org/packages/52/8b/07a438b8b31b46f016f6473a1900927008e62057c7a6b7d87dcfb63c7714/generic_lexer-1.1.1-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1b711b3bcf6a314f64614ccc7a17a82e063ba82cd7924bcbce546d8b95df2c7a",
          "md5": "1d3cdfaf844b06aca235d88aa3c915ef",
          "sha256": "afaf5701b446a98d2c186301b0e7d39ea8ec4da16afdca03ca698f9f4b741a4b"
        },
        "downloads": -1,
        "filename": "generic_lexer-1.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "1d3cdfaf844b06aca235d88aa3c915ef",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 7551,
        "upload_time": "2020-11-25T20:56:09",
        "upload_time_iso_8601": "2020-11-25T20:56:09.155661Z",
        "url": "https://files.pythonhosted.org/packages/1b/71/1b3bcf6a314f64614ccc7a17a82e063ba82cd7924bcbce546d8b95df2c7a/generic_lexer-1.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "528b07a438b8b31b46f016f6473a1900927008e62057c7a6b7d87dcfb63c7714",
        "md5": "24649decdedaa3eca66e9e7ac0c9f171",
        "sha256": "10c9331e365d0c4d01529dbc699e62cd0281ef618e145f2e54e15b4e69d8bcbd"
      },
      "downloads": -1,
      "filename": "generic_lexer-1.1.1-py2.py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "24649decdedaa3eca66e9e7ac0c9f171",
      "packagetype": "bdist_wheel",
      "python_version": "py2.py3",
      "requires_python": ">=3.5",
      "size": 7516,
      "upload_time": "2020-11-25T20:56:08",
      "upload_time_iso_8601": "2020-11-25T20:56:08.187348Z",
      "url": "https://files.pythonhosted.org/packages/52/8b/07a438b8b31b46f016f6473a1900927008e62057c7a6b7d87dcfb63c7714/generic_lexer-1.1.1-py2.py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "1b711b3bcf6a314f64614ccc7a17a82e063ba82cd7924bcbce546d8b95df2c7a",
        "md5": "1d3cdfaf844b06aca235d88aa3c915ef",
        "sha256": "afaf5701b446a98d2c186301b0e7d39ea8ec4da16afdca03ca698f9f4b741a4b"
      },
      "downloads": -1,
      "filename": "generic_lexer-1.1.1.tar.gz",
      "has_sig": false,
      "md5_digest": "1d3cdfaf844b06aca235d88aa3c915ef",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.5",
      "size": 7551,
      "upload_time": "2020-11-25T20:56:09",
      "upload_time_iso_8601": "2020-11-25T20:56:09.155661Z",
      "url": "https://files.pythonhosted.org/packages/1b/71/1b3bcf6a314f64614ccc7a17a82e063ba82cd7924bcbce546d8b95df2c7a/generic_lexer-1.1.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}