{
  "info": {
    "author": "Ahmed Rafik",
    "author_email": "djerahahmedrafik@mail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Environment :: Console",
      "Environment :: No Input/Output (Daemon)",
      "Framework :: Scrapy",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: BSD License",
      "Operating System :: OS Independent",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.7",
      "Topic :: Internet :: WWW/HTTP"
    ],
    "description": "\n=========\nScrapy Do\n=========\n\n.. image:: https://api.travis-ci.org/ljanyst/scrapy-do.svg?branch=master\n   :target: https://travis-ci.org/ljanyst/scrapy-do\n\n.. image:: https://coveralls.io/repos/github/ljanyst/scrapy-do/badge.svg?branch=master\n   :target: https://coveralls.io/github/ljanyst/scrapy-do?branch=master\n\n.. image:: https://img.shields.io/pypi/v/scrapy-do.svg\n   :target: https://pypi.python.org/pypi/scrapy-do\n   :alt: PyPI Version\n\n\nScrapy Do is a daemon that provides a convenient way to run `Scrapy\n<https://scrapy.org/>`_ spiders. It can either do it once - immediately; or it\ncan run them periodically, at specified time intervals. It's been inspired by\n`scrapyd <https://github.com/scrapy/scrapyd>`_ but written from scratch. It\ncomes with a REST API, a command line client, and an interactive web interface.\n\n * Homepage: `https://jany.st/scrapy-do.html <https://jany.st/scrapy-do.html>`_\n * Documentation: `https://scrapy-do.readthedocs.io/en/latest/ <https://scrapy-do.readthedocs.io/en/latest/>`_\n\n-----------\nQuick Start\n-----------\n\n* Install ``scrapy-do`` using ``pip``:\n\n  .. code-block:: console\n\n       $ pip install scrapy-do\n\n* Start the daemon in the foreground:\n\n  .. code-block:: console\n\n       $ scrapy-do -n scrapy-do\n\n* Open another terminal window, download the Scrapy's Quotesbot example, and\n  push the code to the server:\n\n  .. code-block:: console\n\n       $ git clone https://github.com/scrapy/quotesbot.git\n       $ cd quotesbot\n       $ scrapy-do-cl push-project\n       +----------------+\n       | quotesbot      |\n       |----------------|\n       | toscrape-css   |\n       | toscrape-xpath |\n       +----------------+\n\n* Schedule some jobs:\n\n  .. code-block:: console\n\n       $ scrapy-do-cl schedule-job --project quotesbot \\\n           --spider toscrape-css --when 'every 5 to 15 minutes'\n       +--------------------------------------+\n       | identifier                           |\n       |--------------------------------------|\n       | 0a3db618-d8e1-48dc-a557-4e8d705d599c |\n       +--------------------------------------+\n\n       $ scrapy-do-cl schedule-job --project quotesbot --spider toscrape-css\n       +--------------------------------------+\n       | identifier                           |\n       |--------------------------------------|\n       | b3a61347-92ef-4095-bb68-0702270a52b8 |\n       +--------------------------------------+\n\n* See what's going on:\n\n  .. figure:: https://github.com/ljanyst/scrapy-do/raw/master/docs/_static/jobs-active.png\n     :scale: 50 %\n     :alt: Active Jobs\n\n     The web interface is available at http://localhost:7654 by default.\n\n--------------------\nBuilding from source\n--------------------\n\nBoth of the steps below require `nodejs` to be installed.\n\n* Check if things work fine:\n\n  .. code-block:: console\n\n       $ pip install -rrequirements-dev.txt\n       $ tox\n\n* Build the wheel:\n\n  .. code-block:: console\n\n       $ python setup.py bdist_wheel\n\n---------\nChangeLog\n---------\n\nVersion 0.4.0\n-------------\n\n* Migration to the Bootstrap 4 UI\n* Make it possible to add a short description to jobs\n* Make it possible to specify user-defined payload in each job that is passed\n  on as a parameter to the python crawler\n* UI updates to support the above\n* New log viewers in the web UI\n\n\n",
    "description_content_type": "",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "BSD License",
    "maintainer": "",
    "maintainer_email": "",
    "name": "scrapy-do-heroku",
    "package_url": "https://pypi.org/project/scrapy-do-heroku/",
    "platform": "",
    "project_url": "https://pypi.org/project/scrapy-do-heroku/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/scrapy-do-heroku/0.4.1/",
    "requires_dist": [
      "autobahn",
      "pem",
      "psutil",
      "pyOpenSSL",
      "python-dateutil",
      "requests",
      "schedule",
      "scrapy",
      "tabulate",
      "twisted",
      "tzlocal"
    ],
    "requires_python": "",
    "summary": "A daemon for scheduling Scrapy spiders",
    "version": "0.4.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 7124412,
  "releases": {
    "0.4.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ba4a56e782bfa76dacaf906367d1a42744da3c0dba22e17c6c754a14de674a91",
          "md5": "757e537a363c68580327e717202c3ea6",
          "sha256": "56c829eb9d0cfcf580cd4c453e3f8779de136991215ad0debcbd9366cbaaa2ee"
        },
        "downloads": -1,
        "filename": "scrapy_do_heroku-0.4.1-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "757e537a363c68580327e717202c3ea6",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 2075480,
        "upload_time": "2020-04-28T23:51:19",
        "upload_time_iso_8601": "2020-04-28T23:51:19.585777Z",
        "url": "https://files.pythonhosted.org/packages/ba/4a/56e782bfa76dacaf906367d1a42744da3c0dba22e17c6c754a14de674a91/scrapy_do_heroku-0.4.1-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fa6e8e1cd199b457d3eef5f5577bd07ccb8f40167bc664d3a8130fd289b6eddb",
          "md5": "2402bddabd858ce1fa39de9fcf4bac2c",
          "sha256": "52c121b45c8e3b080d30308e41575efc1c06227a27f992d9d9277d0920fa7a2a"
        },
        "downloads": -1,
        "filename": "scrapy-do-heroku-0.4.1.tar.gz",
        "has_sig": false,
        "md5_digest": "2402bddabd858ce1fa39de9fcf4bac2c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 61983,
        "upload_time": "2020-04-28T23:51:22",
        "upload_time_iso_8601": "2020-04-28T23:51:22.004481Z",
        "url": "https://files.pythonhosted.org/packages/fa/6e/8e1cd199b457d3eef5f5577bd07ccb8f40167bc664d3a8130fd289b6eddb/scrapy-do-heroku-0.4.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "ba4a56e782bfa76dacaf906367d1a42744da3c0dba22e17c6c754a14de674a91",
        "md5": "757e537a363c68580327e717202c3ea6",
        "sha256": "56c829eb9d0cfcf580cd4c453e3f8779de136991215ad0debcbd9366cbaaa2ee"
      },
      "downloads": -1,
      "filename": "scrapy_do_heroku-0.4.1-py2.py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "757e537a363c68580327e717202c3ea6",
      "packagetype": "bdist_wheel",
      "python_version": "py2.py3",
      "requires_python": null,
      "size": 2075480,
      "upload_time": "2020-04-28T23:51:19",
      "upload_time_iso_8601": "2020-04-28T23:51:19.585777Z",
      "url": "https://files.pythonhosted.org/packages/ba/4a/56e782bfa76dacaf906367d1a42744da3c0dba22e17c6c754a14de674a91/scrapy_do_heroku-0.4.1-py2.py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "fa6e8e1cd199b457d3eef5f5577bd07ccb8f40167bc664d3a8130fd289b6eddb",
        "md5": "2402bddabd858ce1fa39de9fcf4bac2c",
        "sha256": "52c121b45c8e3b080d30308e41575efc1c06227a27f992d9d9277d0920fa7a2a"
      },
      "downloads": -1,
      "filename": "scrapy-do-heroku-0.4.1.tar.gz",
      "has_sig": false,
      "md5_digest": "2402bddabd858ce1fa39de9fcf4bac2c",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 61983,
      "upload_time": "2020-04-28T23:51:22",
      "upload_time_iso_8601": "2020-04-28T23:51:22.004481Z",
      "url": "https://files.pythonhosted.org/packages/fa/6e/8e1cd199b457d3eef5f5577bd07ccb8f40167bc664d3a8130fd289b6eddb/scrapy-do-heroku-0.4.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}