{
  "info": {
    "author": "Ahmed Khaled",
    "author_email": "ahmedkhaled11119999@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License"
    ],
    "description": "# PyEZNet\n# Contents\n - [**Install our package**](#Install_our_package)\n - [**Potential Output**](#Example)\n - [**Modules**](#Modules)\n     - [Layers](#Layers)\n       - [`FullyConnected`](#FCD)\n       - [`Conv2D`](#Conv2D)\n       - [`MaxPooling`](#POOL)\n       - [`AvgPooling`](#POOL)\n       - [`Flatten`](#FLATTEN)\n     - [Loss Functions](#Loss_functions)\n       - [`CrossEntropy`](#CE_Loss)\n       - `MeanSquareError`\n       - `Hinge Loss`\n     - [Activation Functions](#Activation_functions)\n       - `ReLU`\n       - `Leaky ReLU`\n       - `Sigmoid`\n       - `Softmax`\n       - `Tanh`\n       - `Hard Tanh`\n       - `Linear`\n   - [DataLoader](#DataLoader)\n      - [`LoadingData`](#Loading_data)\n      - [`Preprocessing Data`](#Preprocessing_data)\n   - [Net](#Net)\n   - [Evaluation](#Evaluation)\n\n\n# Install our package<a name=\"Install_our_package\"></a>\n```python\npip install PyEZNet\n```\n-----\n# Potential Output <a name=\"Example\"></a>\n\nThis is an example for the output of a LeNet trained on a MNIST data set.\n\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/EslamAsfour/PyEZNet/blob/main/(Final)LeNet_Training.ipynb)\n\n\n<p align=\"center\">\n  <img src=\"https://github.com/EslamAsfour/PyEZNet/blob/main/Diagrams-Docs/expected_output.gif\" />\n  </p>\n\n-----\n\n\n# Modules <a name=\"Modules\"></a>\n\n-----\n\n\n# `Layers` <a name=\"Layers\"></a>\n## 1. Fully Connected :<a name=\"FCD\"></a>\n\nFully Connected layer is used to take the output of convolution/pooling and predicts the best label to describe the image\n\n<p align=\"center\">\n  <img src=\"https://github.com/EslamAsfour/PyEZNet/blob/main/Diagrams-Docs/fullyconnected.jpeg\" />\n  </p>\n\n<br>\n\n1.\tWe get the output from convolution/pooling and initialize our weights vector with the same dimension\n\n\n```python\n\n   def _init_Weights(self,input_dim,output_dim):\n        scale = 1/ sqrt(input_dim)\n                 self.weights['W'] = scale *np.random.randn(input_dim,output_dim)\n                 self.weights['b'] = scale *np.random.randn(1,output_dim)\n\n```\n\n\n\n\n\n2.\tForward function take X 'vector of numpy array' where it's size is (no_of_batch,input_dim)and it's output is Y = (WX+b)\n\n\n```python\n  def forward(self,X):         output=np.dot(X,self.weights['W']) + self.weights['b']\n            self.cache['X']=X\n        self.cache['output']=output\n        return output\n```\n\n\n\n3.\tOur goal with backpropagation is to update each of the weights in the network, so that they cause the actual output to be closer the target output using 'Chain Rule'\n\n\n\n```python\n\n def backward(self,dY):\n\n            dX=dY.dot(self.grad['X'].T)\n            X=self.cache['X']\n            dw=self.grad['W'].T.dot(dY)\n            db=np.sum(dY,axis=0,keepdims=True)          \t\t  \tself.weights_Update={'W': dw,'b': db}\n        return dX\n```\n\n\n\n-----\n\n## 2. Conv2D :<a name=\"Conv2D\"></a>\n### &nbsp;&nbsp;&nbsp;&nbsp;[1. Inputs , Outputs](#IO)\n### &nbsp;&nbsp;&nbsp;&nbsp;[2. Forward Path Theoretically](#FPT)\n### &nbsp;&nbsp;&nbsp;&nbsp;[3. Forward Path in Code](#FPIC)\n### &nbsp;&nbsp;&nbsp;&nbsp;[4. Backward Path Theoretically](#BPT)\n### &nbsp;&nbsp;&nbsp;&nbsp;[5. Backward Path in Code](#BPIC)\n\n### 1. Inputs , Outputs<a name=\"IO\"></a>\n\n\n  ### Inputs for the layer :\n   1.  in_Channels\n   2.  out_Channels (Number of Filter in the Conv Layer)\n   3.  Padding\n   4.  Stride\n   5.  Kernal Size (Size of the Filter ex: 3x3 filter)\n  ### Conv2D Takes input img (Channel , Width , Height)  with N imgs -> (N , Ch , H , W) and Kernal Size \n  ### And we calculate the output size(H,W) by the formula :\n  <p align=\"center\">\n  <img src=\"https://github.com/EslamAsfour/PyEZNet/blob/Conv2D-in-Dev/Diagrams-Docs/shape.png\" />\n  </p>\n\n\n\n###  2. Forward Path Theoretically<a name=\"FPT\"></a>\n  ![alt text](https://github.com/EslamAsfour/PyEZNet/blob/Conv2D-in-Dev/Diagrams-Docs/Forward.gif)\n\n\n\n###  3. Forward Path in Code<a name=\"FPIC\"></a>\n  ```python\n    #loop over every Img\n          for n in range(N):\n              #Loop over every filter\n              for C_out in range(self.Num_Filters):\n                  #Loop over H & W\n                  for h , w in product(range(W_out) , range(H_out)):\n                      # Calc Starting index for every step based on the Stride\n                      H_offset , W_offset = h*self.Stride , w*self.Stride\n                      # Subset from X for the filter size\n                      # Select [ one img (n)  , All the Ch , Offset+ Filter_h , Offset+Filter_W ]\n                      Sub_X = X[n , : , H_offset: (H_offset + Filter_H) , W_offset: (W_offset + Filter_W)  ]\n                      Y[n , C_out , h , w ] = np.sum(self.weights['W'][C_out] * Sub_X) + self.weights['b'][C_out]\n  ```\n\n\n###  4. Backward Path Theoretically<a name=\"BPT\"></a>\n   ### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In the Backward we need to Calculate :\n   ###   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1. Grad X wrt L(Loss Func)\n   ###   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2. Grad W wrt L(Loss Func)\n![alt text](https://github.com/EslamAsfour/PyEZNet/blob/Conv2D-in-Dev/Diagrams-Docs/Backward.gif)\n ### <div align=\"center\">This GIF demonstrate the Calculation of Grad W </div>\n\n\n\n\n###  5. Backward Path in Code<a name=\"BPIC\"></a>\n\n\n  ```python\n    # Calc dX\n        #Loop Over every img\n        for n in range(N):\n            # Loop over filters\n            for C_out in range(self.Num_Filters):\n                # Loop over h,w\n                for h,w in product(range(dY.shape[2]),range(dY.shape[3])):\n                    H_offset , W_offset = h*self.Stride , w*self.Stride\n                    #                                                                                          filter index\n                    dX[n,: , H_offset:H_offset + Filter_H , W_offset:W_offset + Filter_W ] += self.weights['W'][C_out] * dY[n,C_out,h,w]\n\n\n        # Calc dW\n        dW = np.zeros_like(self.weights['W'])\n\n        # Loop over filters\n        for c_w in range(self.Num_Filters):\n            for c_i in range(self.in_Channels):\n                for h,w in product(range(Filter_H),range(Filter_W)):\n                    Sub_X = X[: , c_i , h:H-Filter_H+h+1:self.Stride  , w: W-Filter_W+w+1:self.Stride ]\n                    dY_rec_field = dY[:, c_w]\n                    dW[c_w, c_i, h ,w] = np.sum(Sub_X*dY_rec_field)\n   ```\n\n-----\n\n## 3. Max Pooling & Average Pooling :<a name=\"POOL\"></a>\n### Why do we perform pooling? \nTo reduce variance, reduce computation complexity (as 2*2 max pooling/average pooling reduces 75% data) and extract low level features from neighbourhood.\n\nIn this project we built:\n- [x] Max pooling\n- [x] Average Pooling \n\nMax pooling extracts the most important features like edges whereas, average pooling extracts features so smoothly. For image data, you can see the difference.\nAlthough both are used for same reason, but max pooling is better for extracting the extreme features. Average pooling sometimes can’t extract good features because it takes all into count and results an average value which may/may not be important for object detection type tasks.\n\n<p align=\"center\">\n  <img src=\"https://github.com/EslamAsfour/PyEZNet/blob/main/Diagrams-Docs/mpool.jfif\" />\n  </p>\n\n-----\n\n## `Loss Functions` <a name=\"Loss_functions\"></a>\n### Cross Entropy Loss: <a name=\"CE_Loss\"></a>\n\nCross Entropy is used for multi-class classification, it takes three inputs:\n1. X:The output of the fully connected layers, which corresponds to the prediction.\n2. Y:The true output, which is zeros for all values except for the true label equals one.\n3. The way of collecting total loss, either summing, or mean or average, the default is Mean.\n\n**The Forward Function:**\nstarts by using softmax to generate probabilities for the input prediction array.\nThen uses loss eqaution to calculate loss for every image which is: -sigma(log(X[i]*Y[i]) where i is used in for loop among the labels of each image.\nAfter that it calculates total loss.\nThe function stores probabilities in the cache to be used in backward probagation.\n\n\n**The Backward Function:**\nFunction returns The gradient values from the cache that was calculated by Calc_grad function.\n\n\n**Calc_grad Function:**\nit calculates grad using the euqation: q[i]−y[i] where q is the probabilities from softmax, y[i]=1 if i is the true label only and equal zero if otherwise.\nthen it stores gradient values in the cache to be used in backward probagation.\n\n\n<p align=\"center\">\n  <img src=\"https://github.com/EslamAsfour/PyEZNet/blob/main/Diagrams-Docs/crossentropy.png\" />\n </p>\n\n\n-----\n## `Activation Functions`<a name=\"Activation_functions\"></a>\n\nIn this module we implement our Activation Functions and their derivatives:\nWe implement a class for each activation function. Each class contains three functions (forward function, backward functions and local_grad function). All of them inherit from Activation_Function class.<br>\n\nForward Function: we calculate the activation function itself.<br>\n\nBackward Function: we use the gradient (derivative) in back propagation through layers.<br>\n\nLocal Gradient Function: we calculate the derivative of each function.<br>\n\nHard Tanh                        |Leaky ReLU                      |ReLU\n:-------------------------:|:-------------------------:|:-------------------------:\n![](https://github.com/EslamAsfour/PyEZNet/blob/main/Diagrams-Docs/Hard_Tanh.jfif) |![](https://github.com/EslamAsfour/PyEZNet/blob/main/Diagrams-Docs/Leaky%20ReLU.jfif) |![](https://github.com/EslamAsfour/PyEZNet/blob/main/Diagrams-Docs/ReLU.jfif) |\nSoftmax                       |Tanh                      |Sigmoid\n![](https://github.com/EslamAsfour/PyEZNet/blob/main/Diagrams-Docs/Softmax.jfif) |![](https://github.com/EslamAsfour/PyEZNet/blob/main/Diagrams-Docs/Tanh.jfif) |![](https://github.com/EslamAsfour/PyEZNet/blob/main/Diagrams-Docs/sigmoid.jfif) |\n\n-----\n## `DataLoader` <a name=\"DataLoader\"></a>\n### **1. Loading Data:**<a name=\"Loading_data\"></a>\n\nIn this Dataloader script we download our dataset from \"http://yann.lecun.com/exdb/mnist/\".\n\nTodo list:\n\n1. we use \"download_and_parse_mnist_file\" function to download our files which is in .rar format in data directory and uncompress our files inside this function\n2. it calls \"parse_idx\" function inside it to check that there is no error in it.\n3. start print download progress\n```python\ndef print_download_progress(count, block_size, total_size):\n    pct_complete = int(count * block_size * 100 / total_size)\n    pct_complete = min(pct_complete, 100)\n    msg = \"\\r- Download progress: %d\" % (pct_complete) + \"%\"\n    sys.stdout.write(msg)\n    sys.stdout.flush()\n```\n4. putting Training_Data , Tarining_labels , Testing_Data,Testing_lables in four seperated functions to get the from our files\n```python\ndef train_images():\n    return download_and_parse_mnist_file('train-images-idx3-ubyte.gz')\n\n\ndef test_images():\n    return download_and_parse_mnist_file('t10k-images-idx3-ubyte.gz')\n\n\ndef train_labels():\n    return download_and_parse_mnist_file('train-labels-idx1-ubyte.gz')\n\n\ndef test_labels():\n    return download_and_parse_mnist_file('t10k-labels-idx1-ubyte.gz')\n\n```\n### **2. Preprocessing Data:** <a name=\"Preprocessing_data\"></a>\nIn this script we just :\n\n1. Import our DataLoader script and use it to get our training and testing data with their labels.\n\n2. Prepare our dataset by normalizing ,reshape and make them 2-D array \n\n```python\ndef GetData():\n    print('Loadind data......')\n    num_classes = 10\n    train_images = DataLoader.train_images() #[60000, 28, 28]\n    train_images= np.array(train_images,dtype=np.float32)\n    train_labels = DataLoader.train_labels()\n    test_images = DataLoader.test_images()\n    test_images= np.array(test_images,dtype=np.float32)\n    test_labels = DataLoader.test_labels()\n\n    print('Preparing data......')\n```\n  3. Reshaping and normalization training dataset and its labels\n```python\n    training_data = train_images.reshape(60000, 1, 28, 28)\n    training_data=training_data/255\n    training_labels= train_labels.reshape (-1,1)\n\n```\n 4. Reshaping and normalization testing dataset and its labels\n```python\n    testing_data = test_images.reshape(10000, 1, 28, 28)\n    testing_data=testing_data/255\n    testing_labels=test_labels .reshape (-1,1)\n\n    return training_data,training_labels,testing_data,testing_labels\n\n```\n-----\n\n## `Net` <a name=\"Net\"></a>\nThis script was used to test our CNN accuracy it consists of one class \"Net\"\n\n1. We check that both of loss_fn and layer that will be the input to our CNN is one of our loss functions and layers \n\"Conv_2D,MaxPooling,FC\"\n\n```python\ndef __init__(self,layers,loss):\n        assert isinstance(loss,Loss) #the loss function must be as instance of nn.losses.Loss\n        for layer in layers:\n            assert isinstance(layer,Diff_Func)\n            #layer must be instance of nn.layers.Layer or nn.layers.Function\n\n        self.layers=layers\n        self.loss_function=loss\n```\n\n\n\n2. Using Forward Path to go through the input layers one by one respectively.\n\n```python\n def forward(self,x):\n        '''\n        :param x: numpy input array to our net\n        :return:  numpy output array\n        '''\n\n        for layer in self.layers:\n            x= layer(x)\n        return x\n```\n\n3. Calculating our loss through the forward path \n\n```python\ndef loss(self,x,y):\n        '''\n        :param x: numpy array output of forward pass\n        :param y: numpy array which is true values\n        :return: numpy float loss value\n        '''\n        loss = self.loss_function(x,y)\n        return loss\n```\n\n4. calculating backward path in order to decrease our loss and helping the model train\n\n\n```python\n def backward(self):\n        '''\n        calculate backward pass for net which must be calculated after calculate forwad pass and loss\n        :return: numpy array of shape matching the input during forward pass\n        '''\n        back=self.loss_function.backward()\n        for layer in reversed(self.layers):\n            back=layer.backward(back)\n        return back\n\n```\n**(save_weights)** :\n\n<br>\n\nSaving the current weights in a pickle file ”.pkl” using the epoch and batch in the file name.\n We loop over the layers of the Net and save the weights calculated in each layer in that file.\n\n<br>\n\n**(load_weights)**:\n\n<br>\n\nLoading the weights that have been saved before in a “.pkl” file so we could use it again.\nWe loop over the layers of the Net and load the saved weights into the current weights of each layer in the net. \n\n<br>\n\n-----\n\n## `Evaluation` <a name=\"Evaluation\"></a>\n\n### The function's input:\n- [ ] Number of classes (categories)\n- [ ] True label\n- [ ] Predicted label\n\n### Then the function computes:\n- [ ] The confusion matrix (TP, TN, FP, FN)\n- [ ] Accuracy\n- [ ] Precision\n- [ ] Recall\n- [ ] Average Precision\n- [ ] Average Recall\n\n### How we calculate the output?\n\n1. TP (True Positive): The True Positives is the number of predictions where data labelled to belong to a particular class was correctly classified as the said class.\n\n```python \n    for i in range(No_of_classes):\n        TP[i] = confussion_matrix[i][i]\n  ```\n\n2. TN (True Negatives): The True Negative for a particular class is calculated by taking the sum of the values in every row and column except the row and column of the class we're trying to find the True Negatives for.\n\nFor example, calculating the True Negatives for the Greyhound class (assuming we have 3 classes: Greyhound, Mastiff, Samoyed):\n\n<p align=\"center\">\n  <img src=\"https://github.com/EslamAsfour/PyEZNet/blob/main/Diagrams-Docs/tn1.jfif\" />\n  </p>\n\n\n```python \n    for i in range(No_of_classes):\n        TN[i]= Matrix_sum-(raw_sum[i]+column_sum[i])+confussion_matrix[i][i]\n```\n\n3. FP (False Positive): The False Positives for a particular class can be calculated by taking the sum of all the values in the column corresponding to that class except the True Positives value.\n\nFor example, calculating the False Positives for the Greyhound class (assuming we have 3 classes: Greyhound, Mastiff, Samoyed):\n\n<p align=\"center\">\n  <img src=\"https://github.com/EslamAsfour/PyEZNet/blob/main/Diagrams-Docs/fp1.jfif\" />\n  </p>\n\n```python\n    for i in range(No_of_classes):\n        FP[i]= column_sum[i]-confussion_matrix[i][i]\n```\n\n4. FN (False NEgative): The False Negatives for a particular class can be calculated by taking the sum of all the values in the row corresponding to that class except the True Positive values.\n\nFor example, calculating the False Negatives for the Greyhound class (assuming we have 3 classes: Greyhound, Mastiff, Samoyed):\n\n<p align=\"center\">\n  <img src=\"https://github.com/EslamAsfour/PyEZNet/blob/main/Diagrams-Docs/fn1.jfif\" />\n  </p>\n\n```python\n    for i in range(No_of_classes):\n        FN[i]=raw_sum[i]-confussion_matrix[i][i]\n```\n\n5. Accuracy =  TP / confusion matrix \n\n```python\n    accurecy =  np.sum(TP)/Matrix_sum\n```\n\n6. Precision(class) = TP / (TP + FN)\n\n```python\n    for i in range(No_of_classes):\n        Precision[i]=TP[i]/(TP[i]+FN[i])\n```\n\n7. Recall(class) = TP / (TP + TN)\n\n ```python\n   for i in range(No_of_classes):\n        Recall[i] = TP[i]/(TP[i]+TN[i])\n```\n\n -----\n\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/EslamAsfour/PyNNN",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "PyEZNet",
    "package_url": "https://pypi.org/project/PyEZNet/",
    "platform": "",
    "project_url": "https://pypi.org/project/PyEZNet/",
    "project_urls": {
      "Homepage": "https://github.com/EslamAsfour/PyNNN"
    },
    "release_url": "https://pypi.org/project/PyEZNet/0.0.1/",
    "requires_dist": [
      "numpy"
    ],
    "requires_python": ">=3.6",
    "summary": "A neural network framework based on numpy only",
    "version": "0.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 9217112,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "15e48b2265fe42c029721e9005ca4b77b4bb064b357eea19111d9f254c8ae0bc",
          "md5": "86d0087685823e535c97be16c6d46539",
          "sha256": "6fc85ed5dc921a90e8ff6a5570be3af624d6784eb2de3ab54bd2adb5654da9e7"
        },
        "downloads": -1,
        "filename": "PyEZNet-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "86d0087685823e535c97be16c6d46539",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 27092,
        "upload_time": "2021-01-24T17:44:08",
        "upload_time_iso_8601": "2021-01-24T17:44:08.178455Z",
        "url": "https://files.pythonhosted.org/packages/15/e4/8b2265fe42c029721e9005ca4b77b4bb064b357eea19111d9f254c8ae0bc/PyEZNet-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4d814d822a81a04a2c6c3da7db4b8462d5e62b292cf6d1eb68100798955be742",
          "md5": "d45b1ec3ac5d83f90db469ef91221c53",
          "sha256": "b9a50c76e4fde745f0e00dcf26c76ce3874749e542911382a3d193cf2f051cb9"
        },
        "downloads": -1,
        "filename": "PyEZNet-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "d45b1ec3ac5d83f90db469ef91221c53",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 20226,
        "upload_time": "2021-01-24T17:44:10",
        "upload_time_iso_8601": "2021-01-24T17:44:10.032386Z",
        "url": "https://files.pythonhosted.org/packages/4d/81/4d822a81a04a2c6c3da7db4b8462d5e62b292cf6d1eb68100798955be742/PyEZNet-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "15e48b2265fe42c029721e9005ca4b77b4bb064b357eea19111d9f254c8ae0bc",
        "md5": "86d0087685823e535c97be16c6d46539",
        "sha256": "6fc85ed5dc921a90e8ff6a5570be3af624d6784eb2de3ab54bd2adb5654da9e7"
      },
      "downloads": -1,
      "filename": "PyEZNet-0.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "86d0087685823e535c97be16c6d46539",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 27092,
      "upload_time": "2021-01-24T17:44:08",
      "upload_time_iso_8601": "2021-01-24T17:44:08.178455Z",
      "url": "https://files.pythonhosted.org/packages/15/e4/8b2265fe42c029721e9005ca4b77b4bb064b357eea19111d9f254c8ae0bc/PyEZNet-0.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "4d814d822a81a04a2c6c3da7db4b8462d5e62b292cf6d1eb68100798955be742",
        "md5": "d45b1ec3ac5d83f90db469ef91221c53",
        "sha256": "b9a50c76e4fde745f0e00dcf26c76ce3874749e542911382a3d193cf2f051cb9"
      },
      "downloads": -1,
      "filename": "PyEZNet-0.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "d45b1ec3ac5d83f90db469ef91221c53",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 20226,
      "upload_time": "2021-01-24T17:44:10",
      "upload_time_iso_8601": "2021-01-24T17:44:10.032386Z",
      "url": "https://files.pythonhosted.org/packages/4d/81/4d822a81a04a2c6c3da7db4b8462d5e62b292cf6d1eb68100798955be742/PyEZNet-0.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}