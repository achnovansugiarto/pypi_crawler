{
  "info": {
    "author": "Denis Veselov",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Developers",
      "Intended Audience :: Education",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: MIT License",
      "Natural Language :: English",
      "Operating System :: MacOS",
      "Operating System :: POSIX",
      "Operating System :: Unix",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Topic :: Scientific/Engineering",
      "Topic :: Software Development :: Libraries",
      "Topic :: Text Processing :: Linguistic"
    ],
    "description": "# Text Dataset Cleaner\n\nНастраиваемый пайплайн для очистки текстовых датасетов от мусора (некорректный язык, бранная речь, HTML-теги и т.д.).\nСписок обработчиков для очистки можно комбинировать и настраивать на свой вкус с помощью конфигурационного файла в YAML формате.\n\n## Запуск\n\nИспользовалось на Ubuntu 18.04 с Python 3.7.\n\nДля запуска нужно установить этот пакет, чтобы получить cli-команду, с помощью которой можно творить чудеса:\n\n```bash\ntdc -c путь_к_вашему_конфигу.yml -i input_file.txt -o output_file.txt\n```\n\n### Docker\n\nЗапустить обработку файлов можно внутри Docker контейнера.\n\nПредоставляются следующие volumes:\n- `/tdc/input/` - директория, все файлы которой (нерекурсивно) будут обработаны\n- `/tdc/output/` - директория, в которую будут сложены результаты обработки\n- `/tdc/config.yml` - конфигурационный файл tdc; в образе уже присутствует конфигурация по умолчанию\n\nПримеры использования\n\n```bash\n# Скачиваем Docker образ из registry\ndocker pull textdatasetcleaner/tdc:latest\n\n# Обработать все файлы из директории input\ndocker run --rm \\\n    -v $(pwd)/input/:/tdc/input/ \\\n    -v $(pwd)/output/:/tdc/output/ \\\n    textdatasetcleaner/tdc\n\n# Обработать все файлы из директории input с собственной конфигурацией\ndocker run --rm \\\n    -v $(pwd)/input/:/tdc/input/ \\\n    -v $(pwd)/output/:/tdc/output/ \\\n    -v $(pwd)/custom-config.yml:/tdc/config.yml \\\n    textdatasetcleaner/tdc\n\n# Обработать один файл file.txt в директории input\ndocker run --rm \\\n    -v $(pwd)/input/:/tdc/input/ \\\n    -v $(pwd)/output/:/tdc/output/ \\\n    textdatasetcleaner/tdc \\\n    tdc -c /tdc/config.yml -i /tdc/input/file.txt -o /tdc/output/file.txt\n```\n\n## Стадии обработки\n\nВ данном инструменте предусмотрено 3 стадии обработки:\n\n1. **PRE_PROCESSING** - запуск предварительной обработки, например: удаление дубликатов.\nВ ней могут запускаться только \"файловые\" обработчики.\n2. **PROCESSING** - запуск основной обработки. В ней могут запускаться только \"построчные\" обработчики.\n3. **POST_PROCESSING** - запуск постобработки, например: перемешивание строк (полезно, если ваша сеть может запомнить порядок\nклассов на выборке в момент обучения). В ней могут запускаться только \"файловые\" обработчики.\n\n## Список обработчиков\n\nВсе обработчики (processors) делятся на 2 типа:\n\n- **Файловые** – обрабатывают весь файл целиком.\n- **Построчные** – обрабатывают каждую строку в файле последовательно.\n\nУ любого из них могут быть обязательные и опциональные параметры, которые задаются в конфигурационном файле.\n\n### add_postfix\n\nПострочный обработчик для добавления текста в _конец_ каждой строки.\n\nПараметр | Обязательный? | Тип данных | Значение по-умолчанию | Описание\n---------|---------------|------------|-----------------------|----------\ntext | Да | `str` | - | Текст для добавления в конец строки.\n\n### add_prefix\n\nПострочный обработчик для добавления текста в _начало_ каждой строки.\n\nПараметр | Обязательный? | Тип данных | Значение по-умолчанию | Описание\n---------|---------------|------------|-----------------------|----------\ntext | Да | `str` | - | Текст для добавления в начало строки.\n\n### clean_html\n\nПострочный обработчик для очистки HTML-тегов. По умолчанию включается только если в строке есть оба символа: `<` и `>`.\n\nПараметр | Обязательный? | Тип данных | Значение по-умолчанию | Описание\n---------|---------------|------------|-----------------------|----------\nor_condition | Нет | `bool` | `False` | `True` - обрабатывать есть ли есть хотя бы один из символов: `<` и `>`. `False` - когда обязательно есть оба.\n\n### clean_symbols\n\nПострочный обработчик для очистки различных utf-8 и непечатных символов и замены их на ASCII-эквиваленты.\n\nОбрабатывает следующие виды символов:\n\n- исправляет двойные кавычки\n- исправляет одинарные кавычки\n- исправляет тире\n- исправляет пробелы\n- исправляет восклицательный знак\n- исправляет вопросительный знак\n- исправляет дублирующиеся тире\n- исправляет пробелы перед точкой\n- удаляет непечатные символы\n\n### detect_language\n\nПострочный обработчик для определения языка текста через библиотеку fastText, с использованием их предобученной или собственной модели.\nЕсли строка имеет язык отличный от заданого, то она пропускается (выкидывается) и не будет участвовать в других обработчиках.\n\nПараметр | Обязательный? | Тип данных | Значение по-умолчанию | Описание\n---------|---------------|------------|-----------------------|----------\nlanguage_code | Да | `str` | - | Ожидаемый код языка (`ru`, `en` и т.д.). [Список поддерживаемых языков](https://fasttext.cc/docs/en/language-identification.html)\nthreshold | Нет | `float` | `0.9` | Пороговое значение, _ниже которого_ считается что язык определён некорректно.\nmodel_path | Нет | `str` | `` | Путь на диске к модели (если не указано, то скачается официальная).\nmodel_url | Нет | `str` | `` | URL кастомной модели (если указано, то скачается за место официальной).\ndelimiter | Нет | `str` | `` | Разделитель в тексте. Если у вас TSV и нужно определить язык только выбранного столбца.\ndelimited_position | Нет | `int` | `-1` | Позиция столбца после разделения строки с помощью `.split`. По дефолту - последний.\n\n### filter_currency_symbols\n\nПострочный обработчик для замены или удаления строк, которые имеют один из символов валюты.\n\nПараметр | Обязательный? | Тип данных | Значение по-умолчанию | Описание\n---------|---------------|------------|-----------------------|----------\nmode | Нет | `str` | `remove_line` | Что делать со строкой: `remove_line` - удалить (выбросить), `replace` - заменить найденные совпадения.\nreplace_with | Нет | `str` | `[пробел]` | На что заменять, если выбран режим `replace`.\n\n### filter_email\n\nПострочный обработчик для замены или удаления строк, содержащих email-адрес.\n\nПараметр | Обязательный? | Тип данных | Значение по-умолчанию | Описание\n---------|---------------|------------|-----------------------|----------\nmode | Нет | `str` | `remove_line` | Что делать со строкой: `remove_line` - удалить (выбросить), `replace` - заменить найденные совпадения.\nreplace_with | Нет | `str` | `[пробел]` | На что заменять, если выбран режим `replace`.\n\n### filter_emoji\n\nПострочный обработчик для замены или удаления строк, содержащих emoji.\n\nПараметр | Обязательный? | Тип данных | Значение по-умолчанию | Описание\n---------|---------------|------------|-----------------------|----------\nmode | Нет | `str` | `remove_line` | Что делать со строкой: `remove_line` - удалить (выбросить), `replace` - заменить найденные совпадения.\nreplace_with | Нет | `str` | `[пробел]` | На что заменять, если выбран режим `replace`.\n\n### filter_hashtags\n\nПострочный обработчик для замены или удаления строк, содержащих `#хэштеги`.\n\nПараметр | Обязательный? | Тип данных | Значение по-умолчанию | Описание\n---------|---------------|------------|-----------------------|----------\nmode | Нет | `str` | `remove_line` | Что делать со строкой: `remove_line` - удалить (выбросить), `replace` - заменить найденные совпадения.\nreplace_with | Нет | `str` | `[пробел]` | На что заменять, если выбран режим `replace`.\n\n### filter_max_length\n\nПострочный обработчик для удаления строк, которые **длиннее** заданного порога.\n\nПараметр | Обязательный? | Тип данных | Значение по-умолчанию | Описание\n---------|---------------|------------|-----------------------|----------\nthreshold | Да | `int` | `` | Пороговое значение, _выше которого_ все строки выбрасываются.\ndelimiter | Нет | `str` | `` | Разделитель в тексте. Если у вас TSV и нужно определить язык только выбранного столбца.\ndelimited_position | Нет | `int` | `-1` | Позиция столбца после разделения строки с помощью `.split`. По дефолту - последний.\n\n### filter_min_length\n\nПострочный обработчик для удаления строк, которые **короче** заданного порога.\n\nПараметр | Обязательный? | Тип данных | Значение по-умолчанию | Описание\n---------|---------------|------------|-----------------------|----------\nthreshold | Да | `int` | `` | Пороговое значение, _ниже которого_ все строки выбрасываются.\ndelimiter | Нет | `str` | `` | Разделитель в тексте. Если у вас TSV и нужно определить язык только выбранного столбца.\ndelimited_position | Нет | `int` | `-1` | Позиция столбца после разделения строки с помощью `.split`. По дефолту - последний.\n\n### filter_numbers\n\nПострочный обработчик для замены или удаления строк, содержащих числа вне контекста слов.\n\nПараметр | Обязательный? | Тип данных | Значение по-умолчанию | Описание\n---------|---------------|------------|-----------------------|----------\nmode | Нет | `str` | `remove_line` | Что делать со строкой: `remove_line` - удалить (выбросить), `replace` - заменить найденные совпадения.\nreplace_with | Нет | `str` | `[пробел]` | На что заменять, если выбран режим `replace`.\n\n### filter_phone_number\n\nПострочный обработчик для замены или удаления строк, содержащих телефонные номера.\n\nПараметр | Обязательный? | Тип данных | Значение по-умолчанию | Описание\n---------|---------------|------------|-----------------------|----------\nmode | Нет | `str` | `remove_line` | Что делать со строкой: `remove_line` - удалить (выбросить), `replace` - заменить найденные совпадения.\nreplace_with | Нет | `str` | `[пробел]` | На что заменять, если выбран режим `replace`.\n\n### filter_stop_words\n\nПострочный обработчик для замены или удаления строк, содержащих стоп-слова (список языков и слов см. ниже).\n\nПараметр | Обязательный? | Тип данных | Значение по-умолчанию | Описание\n---------|---------------|------------|-----------------------|----------\nlanguage_code | Да | `str` | - | Ожидаемый код языка (`ru`, `en` и т.д.). [Список поддерживаемых языков](https://github.com/6/stopwords-json/tree/master/dist).\nmode | Нет | `str` | `remove_line` | Что делать со строкой: `remove_line` - удалить (выбросить), `replace` - заменить найденные совпадения.\nreplace_with | Нет | `str` | `[пробел]` | На что заменять, если выбран режим `replace`.\n\n### filter_url\n\nПострочный обработчик для замены или удаления строк, содержащих URL-адреса.\n\nПараметр | Обязательный? | Тип данных | Значение по-умолчанию | Описание\n---------|---------------|------------|-----------------------|----------\nmode | Нет | `str` | `remove_line` | Что делать со строкой: `remove_line` - удалить (выбросить), `replace` - заменить найденные совпадения.\nreplace_with | Нет | `str` | `[пробел]` | На что заменять, если выбран режим `replace`.\n\n### filter_user_handle\n\nПострочный обработчик для замены или удаления строк, содержащих `@юзернеймы`.\n\nПараметр | Обязательный? | Тип данных | Значение по-умолчанию | Описание\n---------|---------------|------------|-----------------------|----------\nmode | Нет | `str` | `remove_line` | Что делать со строкой: `remove_line` - удалить (выбросить), `replace` - заменить найденные совпадения.\nreplace_with | Нет | `str` | `[пробел]` | На что заменять, если выбран режим `replace`.\n\n### line_convert_case\n\nПострочный обработчик для смены регистра.\n\nПараметр | Обязательный? | Тип данных | Значение по-умолчанию | Описание\n---------|---------------|------------|-----------------------|----------\nmode | Да | `str` | - | Варианты: `title` - делает первую букву во всех словах заглавной; `lower` - понижает регистр; `upper` - повышает регистр.\n\n### line_strip\n\nПострочный обработчик для удаления стартовых и конечных пробельных символов.\n\n### normalize_hyphenated_words\n\nПострочный обработчик для исправления слов в тексте, которые были разделены дефисом для переноса слов по слогам в конце строки.\nОбъединяет кусочки слов воедино, убирая дефис и пробелы.\n\n### normalize_quotation_marks\n\nПострочный обработчик для исправления одинарных и двойных кавычек, а также апострофов до их ASCII-эквивалентов.\n\n### normalize_repeating_chars\n\nПострочный обработчик для удаления повторяющихся пунктуационных символов.\nОбрабатывает следующий список символов: `!\"#$%&\\'()*+,-/:;<=>?@[\\\\]^_``{|}~`, а также исправляет многоточие в строках\n(превращает `..` в `...` и если есть 4 подряд повторяющихся точки, то заменяет их в многоточие).\n\n### normalize_unicode\n\nПострочный обработчик для исправления юникодных символов в тексте в их канонический вид.\n\nПараметр | Обязательный? | Тип данных | Значение по-умолчанию | Описание\n---------|---------------|------------|-----------------------|----------\nform | Да | `str` | `NFKC` | Формы преобразования: `NFC`, `NFKC`, `NFD`, `NFKD`. [Подробнее о формах](https://docs.python.org/3/library/unicodedata.html#unicodedata.normalize).\n\n### normalize_whitespace\n\nПострочный обработчик для исправления:\nсмежных пробелов нулевой ширины на пустую строку;\nперевода каретки в Windows-стиле (`\\r\\n`) и перевода каретки с вертикальной табуляцией (`\\n\\v`) на простой перевод каретки `\\n`;\nпробельных символов без переноса каретки на одинарный пробел;\nи удаления стартовых/конечных пробелов в строке.\n\n### remove_accents\n\nПострочный обработчик для транслитерации юникодных символов в ASCII-эквиваленты.\n\n### remove_profanity\n\nПострочный обработчик для удаления строк с матерной речью на _английском языке_.\n\nПараметр | Обязательный? | Тип данных | Значение по-умолчанию | Описание\n---------|---------------|------------|-----------------------|----------\nthreshold | Нет | `float` | `0.9` | Пороговое значение, _выше которого_ считается что в строке есть бранная речь.\n\n### shuffle\n\nФайловый обработчик для перемешивания строк. Используется системная реалзация GNU `shuf`.\n\n### unique\n\nФайловый обработчик для удаления повторов в строках. Используются системные реализации BSD `sort` и `uniq`.\n\n## TODO\n\nК существующим скриптам препроцессинга хочется допилить:\n\n- [ ] Сделать документацию на rtfd.\n- [ ] Перевести всё на английский язык.\n- [ ] Поддержка других входных/выходных форматов файлов (jsonl/стрим из hdfs).\n- [ ] Провести бенчмарки для того чтоб понимать сколько вообще оно работает (можно сделать отдельный бенч-тул и запускать в GHA).\n- [ ] Проверку и исправление орфографии через standalone-версию [LanguageTool](https://github.com/languagetool-org/languagetool)\n- [ ] Исправление знаков пунктуации в строках\n- [ ] Сделать анализ тональности и удалять негативные строки\n- [ ] Попробовать прикрутить классификацию тематики текста\n- [ ] Удаление знаков препинания\n- [x] Понижение регистра (если вдруг кому-то это нужно)\n- [ ] Сделать удаление нечётких дубликатов через шинглы (лучше через какое-то готовое решение)\n- [x] Удаление всех строк, которые содержат стоп-слова из заданного словаря\n- [ ] Проверка метрик читаемости текста (через [pattern.metrics](https://www.clips.uantwerpen.be/pages/pattern-metrics) или [ruTS](https://github.com/SergeyShk/ruTS))\n- [ ] Оценка натуральности/логичности текста через [BERT (режим №2)](https://colab.research.google.com/github/blade1780/bert/blob/master/BERT.ipynb)\n- [ ] Использование готовых API для проверки орфографии через Google/Bing\n- [ ] Прикрутить использование RAMDisk для ускорения обработки\n- [ ] Загрузка процессоров из других директорий (чтобы не форкать реп, если нужно прикрутить свой)\n- [x] Удаление emoji\n- [ ] Добавить [смену версии пакета](https://pypi.org/project/bump2version/) в момент релиза из github (когда проставляется git tag - брать эту версию и заменять в setup.py или `src/__version__.py`)\n\n## Contributors\n\nСписок людей, которые делают этот мир и данный инструмент – лучше :)\n\n- [ameyuuno](https://github.com/ameyuuno)\n\nБольшое спасибо за вклад в развитие TextDatasetCleaner!\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/TextDatasetCleaner/TextDatasetCleaner",
    "keywords": "nlp,preprocessing,text analytics,normalization,natural language processing,linguistics,text processing,text mining",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "textdatasetcleaner",
    "package_url": "https://pypi.org/project/textdatasetcleaner/",
    "platform": "",
    "project_url": "https://pypi.org/project/textdatasetcleaner/",
    "project_urls": {
      "Bug Tracker": "https://github.com/TextDatasetCleaner/TextDatasetCleaner/issues",
      "Documentation": "https://github.com/TextDatasetCleaner/TextDatasetCleaner",
      "Homepage": "https://github.com/TextDatasetCleaner/TextDatasetCleaner",
      "Source Code": "https://github.com/TextDatasetCleaner/TextDatasetCleaner"
    },
    "release_url": "https://pypi.org/project/textdatasetcleaner/0.0.6/",
    "requires_dist": [
      "srsly (==1.0.2)",
      "tqdm (>=4.49.0<5.0.0)",
      "scikit-learn (<=0.20.2)",
      "profanity-check (==1.0.3)",
      "selectolax (<0.3.0,>=0.2.7)",
      "requests (<3.0.0,>=2.24.0)",
      "click (<8.0.0,>=7.1.2)",
      "PyYAML (<6.0.0,>=5.3.1)",
      "textacy (>=0.10.1<1.0.0)",
      "fasttext (==0.9.2)"
    ],
    "requires_python": ">=3.6",
    "summary": "Pipeline for cleaning (preprocessing/normalizing) text datasets",
    "version": "0.0.6",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 9344472,
  "releases": {
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5d0656aceab95ef48ba44aa4a0777e9ba284f3b726da89f92c44cda969902a55",
          "md5": "6a48147e0f7fe12f8f282b02f7fb4b8f",
          "sha256": "08d4c4e68368d0b5309eadcb9691722ac9dd8156e23a68fb51795ea389a21501"
        },
        "downloads": -1,
        "filename": "textdatasetcleaner-0.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "6a48147e0f7fe12f8f282b02f7fb4b8f",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 27276,
        "upload_time": "2020-10-03T20:33:00",
        "upload_time_iso_8601": "2020-10-03T20:33:00.226594Z",
        "url": "https://files.pythonhosted.org/packages/5d/06/56aceab95ef48ba44aa4a0777e9ba284f3b726da89f92c44cda969902a55/textdatasetcleaner-0.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "42b9fac095da7d245b5118f4832f7feb0cdb06d0f0d0809039de6dec741933da",
          "md5": "b0354be0b15e2719d484014631fe8b32",
          "sha256": "d5e182ed72b2e23793276fbffa11dc0ba753cd1e5680ea9bba381ed3e7dbc12d"
        },
        "downloads": -1,
        "filename": "textdatasetcleaner-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "b0354be0b15e2719d484014631fe8b32",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 19469,
        "upload_time": "2020-10-03T20:33:02",
        "upload_time_iso_8601": "2020-10-03T20:33:02.754782Z",
        "url": "https://files.pythonhosted.org/packages/42/b9/fac095da7d245b5118f4832f7feb0cdb06d0f0d0809039de6dec741933da/textdatasetcleaner-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2d88fed3062ce7d037528ed23e780aa8eb1d8946b0598973bd74d27ad91bd580",
          "md5": "23b5d8e27f766a40364e850779b0998e",
          "sha256": "54438eaa3129ef37d769f9ecfc8ee08703286209de500c82c476f26659b3772e"
        },
        "downloads": -1,
        "filename": "textdatasetcleaner-0.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "23b5d8e27f766a40364e850779b0998e",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 29253,
        "upload_time": "2020-10-04T22:47:18",
        "upload_time_iso_8601": "2020-10-04T22:47:18.194535Z",
        "url": "https://files.pythonhosted.org/packages/2d/88/fed3062ce7d037528ed23e780aa8eb1d8946b0598973bd74d27ad91bd580/textdatasetcleaner-0.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "97e2f49aa9738bd9a13c7307400a546c5d30e6994fff7d21c9a21ca84ecf47f4",
          "md5": "4be6b00b2566e451b246d9e934b45c8b",
          "sha256": "6f396e9f6ead17015d6c137a78c634a55a024c3901fecea0550686d2a9003d6c"
        },
        "downloads": -1,
        "filename": "textdatasetcleaner-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "4be6b00b2566e451b246d9e934b45c8b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 22436,
        "upload_time": "2020-10-04T22:47:19",
        "upload_time_iso_8601": "2020-10-04T22:47:19.634071Z",
        "url": "https://files.pythonhosted.org/packages/97/e2/f49aa9738bd9a13c7307400a546c5d30e6994fff7d21c9a21ca84ecf47f4/textdatasetcleaner-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2a05bc026176b4e6bf6dbf0e3ed7fa4fc0079aeeaeffab79ad9a7a59211a4b8f",
          "md5": "355c39a555b86a7a4796939158c68197",
          "sha256": "6286598c3e0cee4defee5217c71e9c8ff696d2786cce52ad60ebef4e80947662"
        },
        "downloads": -1,
        "filename": "textdatasetcleaner-0.0.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "355c39a555b86a7a4796939158c68197",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 30652,
        "upload_time": "2020-11-07T19:14:08",
        "upload_time_iso_8601": "2020-11-07T19:14:08.766866Z",
        "url": "https://files.pythonhosted.org/packages/2a/05/bc026176b4e6bf6dbf0e3ed7fa4fc0079aeeaeffab79ad9a7a59211a4b8f/textdatasetcleaner-0.0.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "623e004b382e85ffe97386c23421a0e004f3227e4d86bbe318eaf5508a9b2d33",
          "md5": "6fd9d97672178860fca98dc180cc23ca",
          "sha256": "e845f784403093ae77b17832dfb6b11836acbd9041ff2aedafc1d3ec5c72d813"
        },
        "downloads": -1,
        "filename": "textdatasetcleaner-0.0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "6fd9d97672178860fca98dc180cc23ca",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 23726,
        "upload_time": "2020-11-07T19:14:11",
        "upload_time_iso_8601": "2020-11-07T19:14:11.010778Z",
        "url": "https://files.pythonhosted.org/packages/62/3e/004b382e85ffe97386c23421a0e004f3227e4d86bbe318eaf5508a9b2d33/textdatasetcleaner-0.0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7f747d9b98c0103896f9772aae12db09ef5068a04c23d01fcda138c28369bac4",
          "md5": "75e60261bb4624dbb8a610b4857a9b43",
          "sha256": "4e8af8791e44d152bc68e8792371bedfb0bc4c5bc524e2431228ffd1d0524ab0"
        },
        "downloads": -1,
        "filename": "textdatasetcleaner-0.0.6-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "75e60261bb4624dbb8a610b4857a9b43",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 31871,
        "upload_time": "2021-02-07T18:58:53",
        "upload_time_iso_8601": "2021-02-07T18:58:53.729356Z",
        "url": "https://files.pythonhosted.org/packages/7f/74/7d9b98c0103896f9772aae12db09ef5068a04c23d01fcda138c28369bac4/textdatasetcleaner-0.0.6-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e931e70ac2d18f12995e16ebd5ab8013b8b9d798c2cbc6f312e10acb08b266e4",
          "md5": "8b373c844192287370e20832e1ee7a57",
          "sha256": "df548728e1304af0a983a40d2df9a841181093829c237677710c8803c0bfa8e0"
        },
        "downloads": -1,
        "filename": "textdatasetcleaner-0.0.6.tar.gz",
        "has_sig": false,
        "md5_digest": "8b373c844192287370e20832e1ee7a57",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 24095,
        "upload_time": "2021-02-07T18:58:55",
        "upload_time_iso_8601": "2021-02-07T18:58:55.132016Z",
        "url": "https://files.pythonhosted.org/packages/e9/31/e70ac2d18f12995e16ebd5ab8013b8b9d798c2cbc6f312e10acb08b266e4/textdatasetcleaner-0.0.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "7f747d9b98c0103896f9772aae12db09ef5068a04c23d01fcda138c28369bac4",
        "md5": "75e60261bb4624dbb8a610b4857a9b43",
        "sha256": "4e8af8791e44d152bc68e8792371bedfb0bc4c5bc524e2431228ffd1d0524ab0"
      },
      "downloads": -1,
      "filename": "textdatasetcleaner-0.0.6-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "75e60261bb4624dbb8a610b4857a9b43",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 31871,
      "upload_time": "2021-02-07T18:58:53",
      "upload_time_iso_8601": "2021-02-07T18:58:53.729356Z",
      "url": "https://files.pythonhosted.org/packages/7f/74/7d9b98c0103896f9772aae12db09ef5068a04c23d01fcda138c28369bac4/textdatasetcleaner-0.0.6-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "e931e70ac2d18f12995e16ebd5ab8013b8b9d798c2cbc6f312e10acb08b266e4",
        "md5": "8b373c844192287370e20832e1ee7a57",
        "sha256": "df548728e1304af0a983a40d2df9a841181093829c237677710c8803c0bfa8e0"
      },
      "downloads": -1,
      "filename": "textdatasetcleaner-0.0.6.tar.gz",
      "has_sig": false,
      "md5_digest": "8b373c844192287370e20832e1ee7a57",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 24095,
      "upload_time": "2021-02-07T18:58:55",
      "upload_time_iso_8601": "2021-02-07T18:58:55.132016Z",
      "url": "https://files.pythonhosted.org/packages/e9/31/e70ac2d18f12995e16ebd5ab8013b8b9d798c2cbc6f312e10acb08b266e4/textdatasetcleaner-0.0.6.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}