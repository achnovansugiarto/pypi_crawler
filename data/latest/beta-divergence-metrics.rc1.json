{
  "info": {
    "author": "Billy Carson",
    "author_email": "williamcarsoniv@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Beta-Divergence Loss Implementations\n\nThis repository contains code for Python implementations of the beta-divergence loss, including implementations compatible [NumPy](https://numpy.org/) and [PyTorch](https://pytorch.org/).\n\n\n## Dependencies\n\nThis library is written in Python, and requires Python (with recommended version >= 3.9) to run. In addition to a working PyTorch installation, this library relies on the following libraries and recommended version numbers:\n\n* [Python](https://www.python.org/) >= 3.9\n* [NumPy](https://numpy.org/) >= 1.22.0\n* [SciPy](https://www.scipy.org/) >= 1.7.3\n\n\n## Installation\n\nTo install the latest stable release, use [pip](https://pip.pypa.io/en/stable/). Use the following command to install:\n\n    $ pip install beta-divergence-metrics\n\n\n## Usage\n\nThe [`numpybd.loss`](https://github.com/wecarsoniv/beta-divergence-metrics/blob/main/src/numpybd/loss.py) module contains two beta-divergence function implementations compatible with NumPy and NumPy arrays: one general beta-divergence between two arrays, and a beta-divergence implementation specific to non-negative matrix factorization (NMF). Similarly [`torchbd.loss`](https://github.com/wecarsoniv/beta-divergence-metrics/blob/main/src/torchbd/loss.py) module contains two beta-divergence class implementations compatible with PyTorch and [PyTorch tensors](https://pytorch.org/tutorials/beginner/introyt/tensors_deeper_tutorial.html). Beta-divergence implementations can be imported as follows:\n\n```python\n# Import beta-divergence loss implementations\nfrom numpybd.loss import *\nfrom torchbd.loss import *\n\n```\n\n\n\n### Beta-divergence between two NumPy arrays\n\nTo calculate the beta-divergence between a NumPy array `a` and a target or reference array `b`, use the `beta_div` loss function. The `beta_div` loss function can be used as follows:\n\n```python\n# Calculate beta-divergence loss between array a and target array b\nloss_val = beta_div(beta=0, reduction='mean')\n\n```\n\n\n### Beta-divergence between two PyTorch tensors\n\nTo calculate the beta-divergence between tensor `a` and a target or reference tensor `b`, use the `BetaDivLoss` loss function. The `BetaDivLoss` loss function can be instantiated and used as follows:\n\n```python\n# Instantiate beta-divergence loss object\nloss_func = BetaDivLoss(beta=0, reduction='mean')\n\n# Calculate beta-divergence loss between tensor a and target tensor b\nloss_val = loss_func(input=a, target=b)\n\n```\n\n\n### NMF beta-divergence between NumPy array of data and data reconstruction\n\nTo calculate the NMF-specific beta-divergence between a NumPy array of data matrix `X` and the product of a scores matrix `H` and a components matrix `W`, use the `nmf_beta_div` loss function. The `nmf_beta_div` loss function can beused as follows:\n\n```python\n# Calculate beta-divergence loss between data matrix X (target or\n# reference matrix) and matrix product of H and W\nloss_val = nmf_beta_div(X=X, H=H, W=W, beta=0, reduction='mean')\n\n```\n\n\n### NMF beta-divergence between PyTorch tensor of data and data reconstruction\n\nTo calculate the NMF-specific beta-divergence between a PyTorch tensor of data matrix `X` and the matrix product of a scores matrix `H` and a components matrix `W`, use the `NMFBetaDivLoss` loss class function. The `NMFBetaDivLoss` loss function can be instantiated and used as follows:\n\n```python\n# Instantiate NMF beta-divergence loss object\nloss_func = NMFBetaDivLoss(beta=0, reduction='mean')\n\n# Calculate beta-divergence loss between data matrix X (target or\n# reference matrix) and matrix product of H and W\nloss_val = loss_func(X=X, H=H, W=W)\n\n```\n\n\n### Choosing beta value\n\nWhen instantiating beta-divergence loss objects, the value of beta should be chosen depending on data type and application. For NMF applications, a beta value of 0 (Itakura-Saito divergence) is recommemded. Integer values of beta correspond to the following divergences and loss functions:\n\n* beta = 0: [Itakura-Saito divergence](https://en.wikipedia.org/wiki/Itakura-Saito_distance)\n* beta = 1: [Kullback-Leibler divergence](https://en.wikipedia.org/wiki/Kullback-Leibler_divergence)\n* beta = 2: [mean-squared error](https://en.wikipedia.org/wiki/Mean_squared_error)\n\n\n## Issue Tracking and Reports\n\nPlease use the [GitHub issue tracker](https://github.com/wecarsoniv/beta-divergence-metrics/issues) associated with this repository for issue tracking, filing bug reports, and asking general questions about the package or project.\n\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/wecarsoniv/beta-divergence-metrics",
    "keywords": "numpybd,torchbd,numpy,pytorch,beta-divergence,beta divergence,beta,divergence,beta-loss,beta loss,loss,beta-distance,beta distance,distance,itakura-saito divergence,itakura saito divergence,is-divergence,is divergence,itakura-saito,itakura saito,itakura,saito,kullback-leibler divergence,kullback leibler divergence,kl divergence,kl,kullback-leibler,kullback,leibler",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "beta-divergence-metrics",
    "package_url": "https://pypi.org/project/beta-divergence-metrics/",
    "platform": "",
    "project_url": "https://pypi.org/project/beta-divergence-metrics/",
    "project_urls": {
      "Homepage": "https://github.com/wecarsoniv/beta-divergence-metrics",
      "Issue Tracker": "https://github.com/wecarsoniv/beta-divergence-metrics/issues"
    },
    "release_url": "https://pypi.org/project/beta-divergence-metrics/0.0.2/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "NumPy and PyTorch implementations of the beta-divergence loss.",
    "version": "0.0.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12738952,
  "releases": {
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a967e7a724d8e4878ab0f0db2d334c6c9b7af744ddd7cc6cef438a2f627b61c6",
          "md5": "58dd38d79d19f83515957611f13180a3",
          "sha256": "cdbbef9acba366a7e6710ebfde955bc614738eadd78fe30d0a4100cf9b66c5f0"
        },
        "downloads": -1,
        "filename": "beta_divergence_metrics-0.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "58dd38d79d19f83515957611f13180a3",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 13418,
        "upload_time": "2022-01-30T19:36:55",
        "upload_time_iso_8601": "2022-01-30T19:36:55.380949Z",
        "url": "https://files.pythonhosted.org/packages/a9/67/e7a724d8e4878ab0f0db2d334c6c9b7af744ddd7cc6cef438a2f627b61c6/beta_divergence_metrics-0.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "15976e1127ebde70414eadc34ca3670cb9202aa9330f4638049dfe2e312a4f5d",
          "md5": "3ed28d92ffea21f13532efa672f34435",
          "sha256": "90f443fe9a7b53c49c90cadd4b9f9963bf595243cdaa98aaa1bf84da4d947ac6"
        },
        "downloads": -1,
        "filename": "beta-divergence-metrics-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "3ed28d92ffea21f13532efa672f34435",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 7848,
        "upload_time": "2022-01-30T19:36:56",
        "upload_time_iso_8601": "2022-01-30T19:36:56.902720Z",
        "url": "https://files.pythonhosted.org/packages/15/97/6e1127ebde70414eadc34ca3670cb9202aa9330f4638049dfe2e312a4f5d/beta-divergence-metrics-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "a967e7a724d8e4878ab0f0db2d334c6c9b7af744ddd7cc6cef438a2f627b61c6",
        "md5": "58dd38d79d19f83515957611f13180a3",
        "sha256": "cdbbef9acba366a7e6710ebfde955bc614738eadd78fe30d0a4100cf9b66c5f0"
      },
      "downloads": -1,
      "filename": "beta_divergence_metrics-0.0.2-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "58dd38d79d19f83515957611f13180a3",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 13418,
      "upload_time": "2022-01-30T19:36:55",
      "upload_time_iso_8601": "2022-01-30T19:36:55.380949Z",
      "url": "https://files.pythonhosted.org/packages/a9/67/e7a724d8e4878ab0f0db2d334c6c9b7af744ddd7cc6cef438a2f627b61c6/beta_divergence_metrics-0.0.2-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "15976e1127ebde70414eadc34ca3670cb9202aa9330f4638049dfe2e312a4f5d",
        "md5": "3ed28d92ffea21f13532efa672f34435",
        "sha256": "90f443fe9a7b53c49c90cadd4b9f9963bf595243cdaa98aaa1bf84da4d947ac6"
      },
      "downloads": -1,
      "filename": "beta-divergence-metrics-0.0.2.tar.gz",
      "has_sig": false,
      "md5_digest": "3ed28d92ffea21f13532efa672f34435",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 7848,
      "upload_time": "2022-01-30T19:36:56",
      "upload_time_iso_8601": "2022-01-30T19:36:56.902720Z",
      "url": "https://files.pythonhosted.org/packages/15/97/6e1127ebde70414eadc34ca3670cb9202aa9330f4638049dfe2e312a4f5d/beta-divergence-metrics-0.0.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}