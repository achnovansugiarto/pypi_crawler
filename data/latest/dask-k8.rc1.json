{
  "info": {
    "author": "Benoit Seguin",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8"
    ],
    "description": "# dask_k8\n\nCreate Dask clusters in Kubernetes easily.\n\nThe aim of this package is to be able to start a Dask client from _outside_ of a Kubernetes cluster\nconnecting to a Dask scheduler/workers running _inside_ of a Kubernetes cluster.\n\nThe dashboard of the dask scheduler running inside Kubernetes is accessible, the corresponding url is printed after the cluster creation.\n\nFirst ensure you have proper Kubernetes access, try running `kubectl get pods` for instance.\n\n### Installation\n\n```\npip install dask_k8\n```\n\n### Example usage\n\n```python\nfrom dask_k8 import DaskCluster\n\n# Use a kubernetes namespace where you have the proper rights, the cluster_id is to distinguish between possible different clusters\ncluster = DaskCluster(namespace=\"dhlab\", cluster_id=\"seguin-0\")\n\n# Initialize cluster\ncluster.create()\n# Get a dask.distributed.Client\ndask_client = cluster.make_dask_client()\n# Increase/decrease the number of workers\ncluster.scale(40, blocking=True)  # Will block until all the workers are effectively connected to the scheduler\n\n# Do the computation\ndask_client.compute(...)\n\n# IMPORTANT: Release the kubernetes resources, it is not done automatically\ncluster.close()\n```\n\nIn order not to forget to release the resources, the following can be done:\n```python\nfrom dask_k8 import DaskCluster\nfrom dask.diagnostics import progress\nfrom dask.distributed import wait\n\ncluster = DaskCluster(namespace=\"dhlab\", cluster_id=\"seguin-0\")\n\nwith cluster:\n    dask_client = cluster.make_dask_client()  # Waits for the scheduler to be started\n    cluster.scale(40)  # Waits for the workers to be started\n    # Compute\n    dask_client.compute(..., sync=True)\n    # Or\n    future = dask_client.compute(...)\n    progress(future)\n    wait(future)\n```\n\nThe corresponding output is:\n```\nScheduler: tcp://10.90.47.7:31791\nDashboard: http://10.90.47.7:7062\nCould not connect to scheduler, retrying...\nCould not connect to scheduler, retrying...\nCurrently 0 workers out of the 40 required, waiting...\nCurrently 13 workers out of the 40 required, waiting...\nCurrently 21 workers out of the 40 required, waiting...\nCurrently 32 workers out of the 40 required, waiting...\nCurrently 33 workers out of the 40 required, waiting...\nCurrently 33 workers out of the 40 required, waiting...\nCurrently 34 workers out of the 40 required, waiting...\nReached the desired 40 workers!\n```\n\n### Specifying the workers/scheduler specifications\n\nArbitrary pod specification can be given both for the scheduler and the worker.\n```python\nfrom dask_k8 import DaskCluster\n\ncluster = DaskCluster(namespace=\"dhlab\", cluster_id=\"seguin-0\", worker_pod_spec=\"\"\"\n  containers:\n    - image: daskdev/dask:latest\n      args: [dask-worker, $(DASK_SCHEDULER_ADDRESS), --nthreads, '1', --no-bokeh, --memory-limit, 4GB, --death-timeout, '60']\n      imagePullPolicy: Always\n      name: dask-worker\n      env:\n        - name: POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: EXTRA_PIP_PACKAGES\n          value: s3fs\n        - name: EXTRA_CONDA_PACKAGES\n          value:\n      resources:\n        requests:\n          cpu: 1\n          memory: \"4G\"\n        limits:\n          cpu: 1\n          memory: \"4G\"\n\"\"\")\n```\n\n### How does it work?\n\n- Kubernetes services are started to connect the dask scheduler and its dashboard to the outside of the Kubernetes cluster. They can be seen\nwith `kubectl get svc` when `DaskCluster` is running (after calling `.create()`).\n- Two Kubernetes deployments are created, one for the scheduler and one for the workers. They can be seen with `kubectl get deployments`.\n- The corresponding pods are automatically managed by Kubernetes and their states can be seen with `kubectl get pods`.\n\n## Project\n\nThe 'impresso - Media Monitoring of the Past' project is funded by the Swiss National Science Foundation (SNSF) under grant number [CRSII5_173719](http://p3.snf.ch/project-173719) (Sinergia program). The project aims at developing tools to process and explore large-scale collections of historical newspapers, and at studying the impact of this new tooling on historical research practices. More information at https://impresso-project.ch.\n\n## License\n\nCopyright (C) 2020  The *impresso* team. Contributors to this program include: [Benoit Seguin](https://github.com/SeguinBe).\n\nThis program is free software: you can redistribute it and/or modify it under the terms of the GNU Affero General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.\nThis program is distributed in the hope that it will be useful, but without any warranty; without even the implied warranty of merchantability or fitness for a particular purpose. See the [GNU Affero General Public License](https://github.com/impresso/dask_k8/blob/master/LICENSE) for more details.",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/impresso/dask_k8",
    "keywords": "",
    "license": "GPL",
    "maintainer": "",
    "maintainer_email": "",
    "name": "dask-k8",
    "package_url": "https://pypi.org/project/dask-k8/",
    "platform": "",
    "project_url": "https://pypi.org/project/dask-k8/",
    "project_urls": {
      "Homepage": "https://github.com/impresso/dask_k8"
    },
    "release_url": "https://pypi.org/project/dask-k8/0.1.1/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "Simple library to start a Dask cluster on Kubernetes",
    "version": "0.1.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8501303,
  "releases": {
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a9afee9ff6f6969534a33c3c0b567c03cdfe44ede0fd3cfa3a03edef381fc3af",
          "md5": "d2fe9aa844e34ee70c9c795ecb7777a7",
          "sha256": "530db86a4ff238234121c455f58abf0b272d905e40746bbd83d696dda38748d4"
        },
        "downloads": -1,
        "filename": "dask-k8-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "d2fe9aa844e34ee70c9c795ecb7777a7",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 5816,
        "upload_time": "2020-10-26T10:38:31",
        "upload_time_iso_8601": "2020-10-26T10:38:31.582083Z",
        "url": "https://files.pythonhosted.org/packages/a9/af/ee9ff6f6969534a33c3c0b567c03cdfe44ede0fd3cfa3a03edef381fc3af/dask-k8-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "a9afee9ff6f6969534a33c3c0b567c03cdfe44ede0fd3cfa3a03edef381fc3af",
        "md5": "d2fe9aa844e34ee70c9c795ecb7777a7",
        "sha256": "530db86a4ff238234121c455f58abf0b272d905e40746bbd83d696dda38748d4"
      },
      "downloads": -1,
      "filename": "dask-k8-0.1.1.tar.gz",
      "has_sig": false,
      "md5_digest": "d2fe9aa844e34ee70c9c795ecb7777a7",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 5816,
      "upload_time": "2020-10-26T10:38:31",
      "upload_time_iso_8601": "2020-10-26T10:38:31.582083Z",
      "url": "https://files.pythonhosted.org/packages/a9/af/ee9ff6f6969534a33c3c0b567c03cdfe44ede0fd3cfa3a03edef381fc3af/dask-k8-0.1.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}