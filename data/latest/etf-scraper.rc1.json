{
  "info": {
    "author": "",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3"
    ],
    "description": "# ETF-Scraper\n\n![IShares](https://github.com/nikulpatel3141/ETF-Scraper/actions/workflows/check_ishares.yml/badge.svg)\n![SSGA](https://github.com/nikulpatel3141/ETF-Scraper/actions/workflows/check_ssga.yml/badge.svg)\n![Vanguard](https://github.com/nikulpatel3141/ETF-Scraper/actions/workflows/check_vanguard.yml/badge.svg)\n![Invesco](https://github.com/nikulpatel3141/ETF-Scraper/actions/workflows/check_invesco.yml/badge.svg)\n\nScrape public ETF and Mutual Fund holdings information, currently from iShares, SSGA, Vanguard and Invesco.\n\nThe aim of this library is to provide a simple, consistent interface for scraping ETF/MF holdings data across multiple providers and asset classes wherever this data is available.\n\nThis is still a work in progress and may not work for _every_ listed fund. In particular, I've focused on making this work for equity ETFs, although with some more work it can be extended to work for mutual funds and credit funds (pull requests are welcome).\n\n## Installation\n\n```bash\ngit clone https://github.com/nikulpatel3141/ETF-Scraper\ncd ETF-Scraper/\npip install .\n```\n\n## Usage\n\n### Python\n\n```python\nfrom etf_scraper import ETFScraper\n\nfund_ticker = \"IVV\" # IShares Core S&P 500 ETF\nholdings_date =  \"2022-12-30\" # or None to query the latest holdings\n\netf_scraper = ETFScraper()\n\nholdings_df = etf_scraper.query_holdings(fund_ticker, holdings_date)\n```\n\n### Command Line\n\nThe script `scripts/scrape_hist.py` allows you to scrape historical/latest fund holdings. See the parameters and examples below:\n\n#### Scrape Monthly Historical ETF holdings\n\nScrape for IVV (iShares S&P500 ETF) and IVW (iShares Russell 3000 ETF) month end holdings from 2010 and save to `/tmp/out` as csv files.\n\n```bash\nmkdir -p /tmp/out # make sure the directory exists\n\npython3 scripts/scrape_hist.py \\\n  --start_date 2019-01-01 --end_date 2023-01-23 \\\n  --tickers IVV IVW \\\n  --save_dir /tmp/out \\\n  --format csv \\\n  --month_ends \\\n  --trading_days \\\n  --exchange NYSE # this is the default anyway\n\nls /tmp/out # IVW_2022_12_30.csv IVW_2022_11_30.csv ...\n\n```\n\nNote: here we need to query for trading day month ends since iShares doesn't report holdings on non-trading days. This is different for Vanguard which report holdings using calendar end dates.\n\n#### Scrape Daily Historical ETF holdings\n\nThe script will scrape daily dates in the given range by default, so remove the `--month_ends` flag (or pass `--no_month_ends`).\n\nAs of writing this is only available for iShares ETFs.\n\n#### Scrape Latest ETF holdings\n\nScrape for latest SPY (SSGA S&P500 ETF) and XLF (Financial Select Sector SPDR Fund) holdings save to `/tmp/out` as parquet files.\n\n```bash\nmkdir -p /tmp/out\n\npython3 scripts/scrape_hist.py \\\n  --tickers SPY XLF \\\n  --save_dir /tmp/out \\\n  --format parquet\n\nls /tmp/out # SPY_2023_01_20.parquet XLF_2023_01_20.parquet\n```\n\nNote: here we don't pass start/end dates or an exchange since we are retrieving the latest holdings.\n\n#### Parameters\n\n```\nusage: scrape_hist.py [-h] --save_dir SAVE_DIR [--start_date START_DATE] [--end_date END_DATE] [--format {csv,parquet,pickle}] --tickers TICKERS [TICKERS ...] [--overwrite | --no-overwrite] [--month_ends | --no-month_ends] [--trading_days | --no-trading_days] [--exchange EXCHANGE] [--num_threads NUM_THREADS] [--log_file LOG_FILE]\n\nScript to query for historical/latest holdings for an input set of tickers\n\noptions:\n  -h, --help            show this help message and exit\n  --save_dir SAVE_DIR   Local directory/cloud bucket to store files\n  --start_date START_DATE\n                        YYYY-MM-DD start date for historical scraping. Leave blank to query latest holdings.\n  --end_date END_DATE   See --start_date. If blank and --start_date given, then defaults to start_date. If --start_date is blank then --end_date must be blank too.\n  --format {csv,parquet,pickle}\n                        Format to save as\n  --tickers TICKERS [TICKERS ...]\n                        Tickers to parse\n  --overwrite, --no-overwrite\n                        If set then query all data requested, otherwise only query files missing from save_dir. Cannot be used with start + end dates (we don't know the latest holdings dates without querying).\n  --month_ends, --no-month_ends\n                        If set then only query for month end dates\n  --trading_days, --no-trading_days\n                        If set then only query for trading days. If --month_ends is also passed, then query only for trading month ends\n  --exchange EXCHANGE   Trading calendar schedule to use if --trading_days is set\n  --num_threads NUM_THREADS\n                        Number of threads to use for parallelising queries\n  --log_file LOG_FILE   Optional path to output error logs\n```\n\n### Data Availability\n\nThis library queries ETF provider websites for holdings data.\n\nWe are therefore limited by what they publish, in particular:\n\n- iShares:\n  - long history available for month end data (eg IVV returns month end data from 2010)\n  - recent daily history is also available\n- SSGA: only latest holdings\n- Invesco: only latest holdings\n- Vanguard: only recent month end holdings\n\nAlso there are other ETF providers which I haven't implemented. Any pull requests to implement others are welcome!\n\n### Available ETFs\n\nThis library can also scrape current ETF listings data from each provider:\n\n```python\nfrom etf_scraper import query_listings, Provider, ETFScraper\n\nproviders = [Provider.IShares] # or [] to scrape all listings\ncurrent_listings = query_listings(providers)\n\netf_scraper = ETFScraper(current_listings)\n```\n\nI'd expect this list to remain relatively static, so a copy is stored in the package itself in [`src/etf_scraper/data/listings.csv`](https://github.com/nikulpatel3141/ETF-Scraper/blob/5116a28697588f566693ca880605c4f68dac14c0/src/etf_scraper/data/listings.csv).\n\nThis copy is loaded by default in `ETFScraper.__init__` using `etf_scraper.load_listings`\n\n## Status Badges\n\nThe status badges at the top of the page are from worklows running daily to query latest holdings from all currently implemented providers for their respectively most popular ETFs.\n\n## Testing\n\nThere are some tests implemented in `src/test` to see if we correctly parse providers responses for holdings. This is definitely an area of improvement, however I'm currently not sure how often providers will change their APIs for retrieving data. Every time they do that we'll likely have to rewrite the tests.\n\n## Related Projects\n\nFor scraping iShares ETFs + AWS integration: https://github.com/talsan/ishares\n\n## Disclaimer\n\nI do not take any responsibility for any (mis)use of this library and do not intend to infringe any fund provider's terms and conditions.\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "etf-scraper",
    "package_url": "https://pypi.org/project/etf-scraper/",
    "platform": null,
    "project_url": "https://pypi.org/project/etf-scraper/",
    "project_urls": {
      "Home": "https://github.com/nikulpatel3141/ETF-Scraper"
    },
    "release_url": "https://pypi.org/project/etf-scraper/0.0.0/",
    "requires_dist": [
      "requests",
      "tenacity",
      "pandas (>=1.5)",
      "numpy",
      "pandas-market-calendars",
      "openpyxl",
      "gcsfs ; extra == 'cloud'",
      "fastparquet (<=2023.01) ; extra == 'cloud'",
      "google-cloud-bigquery ; extra == 'cloud'",
      "pytest ; extra == 'tests'"
    ],
    "requires_python": ">=3.8",
    "summary": "Scrape ETF and Mutual Fund holdings from major providers",
    "version": "0.0.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16861053,
  "releases": {
    "0.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "43a52fe68dd4ed1b0f7596a764983480b75d29770c08f55620a71f235a3ddab7",
          "md5": "610fb5fcfc0bc006656eb080130715af",
          "sha256": "aa7f9ae966ec9b4c5d64ee810227f91cec935c50695ecb3788c09dfe5ffe7d99"
        },
        "downloads": -1,
        "filename": "etf_scraper-0.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "610fb5fcfc0bc006656eb080130715af",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 69035,
        "upload_time": "2023-02-14T20:51:46",
        "upload_time_iso_8601": "2023-02-14T20:51:46.389311Z",
        "url": "https://files.pythonhosted.org/packages/43/a5/2fe68dd4ed1b0f7596a764983480b75d29770c08f55620a71f235a3ddab7/etf_scraper-0.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b35aa1153dc1f61b8b798a87ae5b602cdc10363bcedfd50b15884301bc9f82d9",
          "md5": "ca263f88ed9d82de9659c2bde8450760",
          "sha256": "fa55a672467fc1501ddada3275efbfe7eebd2a226d65360cf358e8c9138e9726"
        },
        "downloads": -1,
        "filename": "etf_scraper-0.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "ca263f88ed9d82de9659c2bde8450760",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 71228,
        "upload_time": "2023-02-14T20:51:48",
        "upload_time_iso_8601": "2023-02-14T20:51:48.084332Z",
        "url": "https://files.pythonhosted.org/packages/b3/5a/a1153dc1f61b8b798a87ae5b602cdc10363bcedfd50b15884301bc9f82d9/etf_scraper-0.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "43a52fe68dd4ed1b0f7596a764983480b75d29770c08f55620a71f235a3ddab7",
        "md5": "610fb5fcfc0bc006656eb080130715af",
        "sha256": "aa7f9ae966ec9b4c5d64ee810227f91cec935c50695ecb3788c09dfe5ffe7d99"
      },
      "downloads": -1,
      "filename": "etf_scraper-0.0.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "610fb5fcfc0bc006656eb080130715af",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.8",
      "size": 69035,
      "upload_time": "2023-02-14T20:51:46",
      "upload_time_iso_8601": "2023-02-14T20:51:46.389311Z",
      "url": "https://files.pythonhosted.org/packages/43/a5/2fe68dd4ed1b0f7596a764983480b75d29770c08f55620a71f235a3ddab7/etf_scraper-0.0.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "b35aa1153dc1f61b8b798a87ae5b602cdc10363bcedfd50b15884301bc9f82d9",
        "md5": "ca263f88ed9d82de9659c2bde8450760",
        "sha256": "fa55a672467fc1501ddada3275efbfe7eebd2a226d65360cf358e8c9138e9726"
      },
      "downloads": -1,
      "filename": "etf_scraper-0.0.0.tar.gz",
      "has_sig": false,
      "md5_digest": "ca263f88ed9d82de9659c2bde8450760",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.8",
      "size": 71228,
      "upload_time": "2023-02-14T20:51:48",
      "upload_time_iso_8601": "2023-02-14T20:51:48.084332Z",
      "url": "https://files.pythonhosted.org/packages/b3/5a/a1153dc1f61b8b798a87ae5b602cdc10363bcedfd50b15884301bc9f82d9/etf_scraper-0.0.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}