{
  "info": {
    "author": "dooboolab",
    "author_email": "support@dooboolab.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "\n# Text Similarity Recommendation System\nThis is a repository for Item RecSys models in Python. You can get the similar Items based on text similarity as follows.\n\n- [Data Description](#data-description)\n- [Process](#process)\n- [Installation](#installation)\n- [Prerequisites](#prerequisites)\n- [Quick Start](#quick-start)\n  * [Example notebooks](#example-notebooks)\n    + [Data Description](#data-description)\n    + [Parameter Description](#parameter-description)\n    + [Pipeline](#pipeline)\n  * [Command Prompt](#command-prompt)\n    + [Precautions <br>](#precautions--br-)\n      - [1. yaml file](#1-yaml-file)\n      - [2. json file](#2-json-file)\n    + [Execute the file](#execute-the-file)\n      - [To predict with newly-trained model](#to-predict-with-newly-trained-model)\n      - [To predict with Pre-trained model](#to-predict-with-pre-trained-model)\n\n---\n\n# Data Description\n#### Input\nThis model recommends items that are highly related to each item in `Items`, which means the source of the recommended items is also `Items`. If you add some text data related to the corresponding `Items` to `related_to_Items`(e.g., Items description, category, etc.), it helps to increase the model accuracy. \n\n\n```python\nItems = [\n          'Netflix movie',\n          'Netflix party',\n          'Netflix top',\n          'Netflix ratings',\n          'rotten tomatoes ratings',\n          'IMDb Top 250 Movie ratings'\n          ]\n          \nrelated_to_Items = [\n          [\"movie top\", \"Netflix\"],\n          [\"party pricing\", \"Netflix\"],\n          [\"top TV shows',\",\"Netflix\"],\n          [\"ratings\"],\n          ['tomatoes'],\n          ['ratings']\n          ]\n```\n\n#### Output\n\n```markdown\nNetflix movie\n1: rotten tomatoes ratings\n2: IMDb Top 250 Movie ratings\n3: Netflix top\n\nNetflix top\n1: IMDb Top 250 Movie ratings\n2: Netflix movie\n3: Netflix ratings\n\nIMDb Top 250 Movie ratings\n1: Netflix ratings\n2: Netflix top\n3: Netflix movie\n```\n\n# Process\n\n![video-TextSimila drawio](https://user-images.githubusercontent.com/48239962/171642236-46d3cbfc-92ca-47e5-9c14-93c9a9a86463.png)\n\n\n**Tokenization**\n\nextract nouns from each sentence\n\n```{python}\n# Example\n['Netflix movie', 'Netflix party']\n```\n```\n[['Netflix', 'movie'], ['Netflix', 'party']]\n```\n\n**Embedding**\n\nget embedding vector from each sentence\n\n```{python}\n# Example\n[['Netflix', 'movie'], ['Netflix', 'party']]\n```\n```\n[[0.94, 0.13], [0.94, 0.741]]\n```\n\nAfter training tokenization and embedding models, the models are saved automatically. You can either train models with your own corpus or use the pre-trained models.\n\n**Calculate cosine similarity**\n\ncalculate the similarity between item embedding vectors using cosine similarity.\n\n$$\nemb_A : \\text{embedding vector of item A}\\\\\nemb_B : \\text{embedding vector of item B}\\\\\ncos(emb_A,emb_B) = \\frac{emb_A\\cdot emb_B}{\n\\|emb_A\\| \\|emb_B\\|}\n$$\n\n\n# Installation\n\n```\npip install TextSimila\n```\n\n# Prerequisites\npython version should be greater than 3.7.x \n\n```\npip install -r requirements.txt\n```\n\n# Quick Start\n\n## Example notebooks\nRefer to [`sample_code.ipynb`](https://github.com/dooboolab/TextSimila/blob/main/example/sample_code.ipynb) if you want to run code in a jupyter environment\n\n\n\n### Parameter Description\nThe tables below describe the parameters of the class `text_sim_reco`\n\n```\nclass text_sim_reco(\n            Items,\n            related_to_Items: list =  None,\n            saved: Boolean = False,\n            lang = Literal[\"en\",\"ko\"],\n            reco_Item_number: int = 3,\n            ratio: float = 0.3,\n\n            # tokenize\n            pretrain_tok: Boolean = False,\n            stopwords: list = None,\n            extranouns: list = None,\n            verbose: Boolean = False,\n            min_noun_frequency: int = 1,\n            max_noun_frequency: int = 80,\n            max_frequency_for_char: int = 20,\n            min_noun_score: float = 0.1,\n            extract_compound: Boolean = False,\n            model_name_tok: str = None,\n            \n            # embedding\n            pretrain_emb: Boolean = False,\n            vector_size: int = 15,\n            window: int = 3,\n            min_count: int = 1,\n            workers: int = 4,\n            sg: Literal[1, 0] = 1,\n            model_name_emb: str = None)\n```\n\n\n\n| Parameters                                                   | Attributes |\n| ------------------------------------------------------------ | :--------- |\n| **Items** : List[str] (required) |     A list of text data to recommend     |\n  **related to Items** : List[List] (optional) |       A list of text data related to `Items` that helps to recommend  |\n  **saved**: Boolean, default = False (optional) |    Whether to save the model       |\n| **lang**: Literal[\"en\",\"ko\"], default = \"en\" |The configure model language<br />- 'ko': Your Items are in Koran <br />- 'en': Your Items are in English|\n  **reco_Item_number** : int, default = 3 |The number of recommendations for each Item|\n  **ratio**: float, default = 0.2 |    The minimum percentage that determines whether to create a corpus         \n\n\n<br />\n  \n| Parameters for tokenization with Korean custom dataset                         | Attributes |\n| ------------------------------------------------------------ | :--------- |\n| **pretrain_tok**: Boolean, default = False  |      Whether to use Pre-trained model     |\n  **min_noun_score** = float, default = 0.1   | The minimum noun score. It decides whether to combine single nouns and compounds |\n  **min_noun_frequency** : int, default = 1   | The minimum frequency of words that occur in a corpus. It decides whether to be a noun while training(noun extracting) |\n  **extract_compound** = boolean, default = False   |  Whether to extract compounds components <br />'compounds components': Information on single nouns that make up compound nouns\n  **verbose**: boolean, default = False  | Whether to print out the current vectorizing |\n  **stopwords** : List, default = None   | (Post-preprocessing option) A List of high-frequency of words to be filtered out   |\n  **extranouns**: List, default = None   | (Post-preprocessing option) A List of nouns to be added  |\n  **max_noun_frequency**: int, default = 80   | (Post-preprocessing option) The maximum frequency of words that occur in a corpus. It decides whether to be a noun after training |\n  **max_frequency_for_char**: int, default = 20  | (Post-preprocessing option) `max_noun_frequency` option for words with length one  |\n  **model_name_tok**: str = None   |      Pre-trained model name  |\n\n\n<br />\n\n| Parameters for embedding                                     | Attributes |\n| ------------------------------------------------------------ | :--------- |\n| **pretrain_emb**: Boolean, default = False |      Whether to use Pre-trained model     |\n  **vector_size** : int, default = 15 |      Dimensionality of the word vectors     |\n  **window**: int, default = 3 |     The maximum distance between the current and predicted word within a sentence     |\n  **min_count**: int, default = 3 |      The model ignores all words with total frequency lower than this     |\n  **workers**: int, default = 3 |      The number of worker threads to train     |\n  **sg**: Literal[1, 0], default = 1 |     Training algorithm: skip-gram if sg=1, otherwise CBOW     |\n  **model_name_emb**: str, default = None |      Pre-trained model name  |\n\n\n---\n\n\n## Command Prompt\nBy running `exe.py`, you can perform all the processes in `sample_code.ipynb` at once. Note that it **saves** the model and the predictions in the following format at every run\n\n```\n# Top3_prediction.json\n{\n  \"Item_1\": [\n    \"recommendation_1\",\n    \"recommendation_2\",\n    \"recommendation_3\"\n  ],\n\n  ...\n\n  \"Item_10\": [\n    \"recommendation_1\",\n    \"recommendation_2\",\n    \"recommendation_3\"\n  ]\n}\n```\n\n\n### Precautions <br>\n**Make sure that the following two files exist in the two folders below before executing `exe.py`**\n\n1. yaml file in `config` folder\n2. json file in `data` folder\n\n#### 1. yaml file\nIf you want to adjust the hyperparameters, modify existing `model.yaml`. \n\nYou can also create your own yaml file, but you must follow the existing `model.yaml` form and save it in `config` folder.\n\n\n#### 2. json file\nIf you want to use your custom data, you must process and save it according to the format below. \n\n```\n[\n  {\n      \"Items\": \"Item_1\",\n      \"related_to_Items\": [\"related_Items\", \"Item_1_discription\"]\n  },\n  \n  ...\n\n  {\n      \"Items\": \"Item_10\",\n      \"related_to_Items\": [\"Item_10_channel\"]\n  }\n\n]\n```\n\n\n### Execute the file\n\n#### To predict with newly-trained model\n\n```\n$ python exe.py [yaml_name] [file_name] --saved [saved]\n```\n\n#### To predict with Pre-trained model\nâ€» If you want to use English custom dataset\n```\n$ python exe.py [yaml_name] [file_name] --pretrain_tok [pretrain_tok] --pretrain_emb [pretrain_emb]\n```\n\nTo make it simpler, \n\n```\n$ python exe.py [yaml_name] [file_name] -tok [pretrain_tok] -emb [pretrain_emb]\n```\n\nFor example, \n\n#### Train ver.\n```\n# If you want to train the model without saving\n$ python exe.py model.yaml sample_eng\n\n# If you want to train the model and then save them\n$ python exe.py model.yaml sample_eng --saved True\n```\n\n#### Pre-trained ver.\n```\n# If you want to use Pre-trained model for tokenization and embedding\n$ python exe.py model.yaml sample_eng -tok True -emb True\n```\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/dooboolab/TextSimila",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "TextSimila",
    "package_url": "https://pypi.org/project/TextSimila/",
    "platform": null,
    "project_url": "https://pypi.org/project/TextSimila/",
    "project_urls": {
      "Homepage": "https://github.com/dooboolab/TextSimila"
    },
    "release_url": "https://pypi.org/project/TextSimila/0.0.6/",
    "requires_dist": [
      "ipykernel",
      "gensim (==4.2.0)",
      "soynlp",
      "nltk",
      "torch",
      "jupyter",
      "pyyaml",
      "argparse"
    ],
    "requires_python": "",
    "summary": "Text Similarity Recommendation System",
    "version": "0.0.6",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14175084,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "62e5907d135b7d71c55da7860f15ab925da7a9cd30ee5b096bc1257f23217012",
          "md5": "fba8e6ef0cb66add45953736d297522b",
          "sha256": "85bb4410458928fafe198af96969f9f3257320bf632252bb049905735011c7e6"
        },
        "downloads": -1,
        "filename": "TextSimila-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "fba8e6ef0cb66add45953736d297522b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 13675,
        "upload_time": "2022-05-24T12:16:41",
        "upload_time_iso_8601": "2022-05-24T12:16:41.586279Z",
        "url": "https://files.pythonhosted.org/packages/62/e5/907d135b7d71c55da7860f15ab925da7a9cd30ee5b096bc1257f23217012/TextSimila-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6db201acc18e048736405892f7cd2caa68e9a4237b794cf7e01bc58390de09bb",
          "md5": "7dda50672b1f5ee316a3d4337cee355d",
          "sha256": "18bf15585dd8eb09553dc8f349826224ffa487a4ee56b251b3320981245e9720"
        },
        "downloads": -1,
        "filename": "TextSimila-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "7dda50672b1f5ee316a3d4337cee355d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 16233,
        "upload_time": "2022-05-24T12:16:43",
        "upload_time_iso_8601": "2022-05-24T12:16:43.548255Z",
        "url": "https://files.pythonhosted.org/packages/6d/b2/01acc18e048736405892f7cd2caa68e9a4237b794cf7e01bc58390de09bb/TextSimila-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ccb8291047be861193a65022f4201cd2a1ff29c4f47b94046e7c5836c2dbe48b",
          "md5": "3f6bf4da5a818de16b698bb8c9117afd",
          "sha256": "8ad7f0e637f2a739ddc91cd06352fa17a60ba97a3cd09cb0afc73a623cc1e527"
        },
        "downloads": -1,
        "filename": "TextSimila-0.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "3f6bf4da5a818de16b698bb8c9117afd",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 19552,
        "upload_time": "2022-05-24T12:22:50",
        "upload_time_iso_8601": "2022-05-24T12:22:50.552432Z",
        "url": "https://files.pythonhosted.org/packages/cc/b8/291047be861193a65022f4201cd2a1ff29c4f47b94046e7c5836c2dbe48b/TextSimila-0.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0267d2a406fc2a4ce8e2da9ea66ce39d0cf5c99d1d0b00c0d8068e87b6c33781",
          "md5": "4eab3537e0bbcfce28c6fd979527db68",
          "sha256": "0a2964c85b6c18e4889b7cfd1a3f66563501f79bec80de16282de0125cf7e007"
        },
        "downloads": -1,
        "filename": "TextSimila-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "4eab3537e0bbcfce28c6fd979527db68",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 20855,
        "upload_time": "2022-05-24T12:22:52",
        "upload_time_iso_8601": "2022-05-24T12:22:52.300499Z",
        "url": "https://files.pythonhosted.org/packages/02/67/d2a406fc2a4ce8e2da9ea66ce39d0cf5c99d1d0b00c0d8068e87b6c33781/TextSimila-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5c0ca1fe9e91a488dce5c1781d1c73279cd951a1758b5004a41aedbc96c60fc3",
          "md5": "ae23358feaccc5a623acd415e4f73741",
          "sha256": "1c529bedb78c08554c3d08579613d6239fab296e85ae891b54d10f1066aa8c85"
        },
        "downloads": -1,
        "filename": "TextSimila-0.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ae23358feaccc5a623acd415e4f73741",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 19550,
        "upload_time": "2022-05-24T12:28:54",
        "upload_time_iso_8601": "2022-05-24T12:28:54.478324Z",
        "url": "https://files.pythonhosted.org/packages/5c/0c/a1fe9e91a488dce5c1781d1c73279cd951a1758b5004a41aedbc96c60fc3/TextSimila-0.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4f922c8f00d2503534dce76b4f988079460905ababc823c8b40113387a2bbd2d",
          "md5": "aa9b2cb2cabebd647a51e01329ee05dd",
          "sha256": "a1f389056d968e53ecdc5cb06f9f128fe9f3a623353ffd85147f109f3d00c909"
        },
        "downloads": -1,
        "filename": "TextSimila-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "aa9b2cb2cabebd647a51e01329ee05dd",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 20838,
        "upload_time": "2022-05-24T12:28:56",
        "upload_time_iso_8601": "2022-05-24T12:28:56.484886Z",
        "url": "https://files.pythonhosted.org/packages/4f/92/2c8f00d2503534dce76b4f988079460905ababc823c8b40113387a2bbd2d/TextSimila-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e70ee4e7d6453378bf257609cc78097518c881f82c060d02a0dd0913be16b760",
          "md5": "0abb63bbdafe30cb7390b19308266653",
          "sha256": "05ea129da870204f061ff9d28ce639f62016bf56c455b1c2d0d9014cadafe2d2"
        },
        "downloads": -1,
        "filename": "TextSimila-0.0.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0abb63bbdafe30cb7390b19308266653",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 19616,
        "upload_time": "2022-05-26T13:08:01",
        "upload_time_iso_8601": "2022-05-26T13:08:01.051974Z",
        "url": "https://files.pythonhosted.org/packages/e7/0e/e4e7d6453378bf257609cc78097518c881f82c060d02a0dd0913be16b760/TextSimila-0.0.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ea640819b46bcb280faad8708ce4ba3a0ca2e97bda188a165c6f7664ad4a2264",
          "md5": "139959a3fd448d1d904ce1106d259109",
          "sha256": "c5fc9cd6fdf61ab37e319e94c3da35a90c09899c5b91b5ebd8de1d5ee1193d46"
        },
        "downloads": -1,
        "filename": "TextSimila-0.0.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "139959a3fd448d1d904ce1106d259109",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 22583,
        "upload_time": "2022-05-28T06:25:14",
        "upload_time_iso_8601": "2022-05-28T06:25:14.331345Z",
        "url": "https://files.pythonhosted.org/packages/ea/64/0819b46bcb280faad8708ce4ba3a0ca2e97bda188a165c6f7664ad4a2264/TextSimila-0.0.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "52417aa627c576a8e764e700807548db46942728f81255a6a1fdafc59e1bc4c6",
          "md5": "5fad54420aab38b5f310170c218c1cbb",
          "sha256": "80a4c1b0136b53def1054e2c66491afc4717829a9091d3efae5428936bfbc6db"
        },
        "downloads": -1,
        "filename": "TextSimila-0.0.6-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "5fad54420aab38b5f310170c218c1cbb",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 22613,
        "upload_time": "2022-06-19T05:08:27",
        "upload_time_iso_8601": "2022-06-19T05:08:27.202747Z",
        "url": "https://files.pythonhosted.org/packages/52/41/7aa627c576a8e764e700807548db46942728f81255a6a1fdafc59e1bc4c6/TextSimila-0.0.6-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "52417aa627c576a8e764e700807548db46942728f81255a6a1fdafc59e1bc4c6",
        "md5": "5fad54420aab38b5f310170c218c1cbb",
        "sha256": "80a4c1b0136b53def1054e2c66491afc4717829a9091d3efae5428936bfbc6db"
      },
      "downloads": -1,
      "filename": "TextSimila-0.0.6-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "5fad54420aab38b5f310170c218c1cbb",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 22613,
      "upload_time": "2022-06-19T05:08:27",
      "upload_time_iso_8601": "2022-06-19T05:08:27.202747Z",
      "url": "https://files.pythonhosted.org/packages/52/41/7aa627c576a8e764e700807548db46942728f81255a6a1fdafc59e1bc4c6/TextSimila-0.0.6-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}