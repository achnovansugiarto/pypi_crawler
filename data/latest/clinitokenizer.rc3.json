{
  "info": {
    "author": "Sam Rawal",
    "author_email": "scrawal2@illinois.edu",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# clinitokenizer\n\n`clinitokenizer` is a sentence tokenizer for clinical text to split unstructured text from clinical text (such as Electronic Medical Records) into individual sentences. \n\nGeneral English sentence tokenizers are often unable to correctly parse medical abbreviations, jargon, and other conventions often used in medical records (see \"Motivating Examples\" section below). clinitokenizer is specifically trained on medical record data and can perform better in these situations (conversely, for non-domain specific use, using more general sentence tokenizers may yield better results). \n\nThe model has been trained on multiple datasets provided by [i2b2 (now n2c2)](https://n2c2.dbmi.hms.harvard.edu). Please visit the n2c2 site to request access to the dataset.\n\n## Installation\n```bash\npip install clinitokenizer\n```\n\n## Quickstart\n\n```python\nfrom clinitokenizer.tokenize import clini_tokenize\n\ntext = \"He was asked if he was taking any medications. Patient is currently taking 5 m.g. Tylenol.\"\nsents = clini_tokenize(text)\n# sents = ['He was asked if he was taking any medications.',\n#         'Patient is currently taking 5 m.g. Tylenol.']\n```\n\nYou can use clinitokenizer as a drop-in replacement for [nltk's](https://www.nltk.org/api/nltk.tokenize.html) `sent_tokenize` function:\n\n```python\n# to swap in clinitokenizer, replace the nltk import...\nfrom nltk.tokenize import sent_tokenize\n\n# ... with the following clinitokenizer import:\nfrom clinitokenizer.tokenize import clini_tokenize as sent_tokenize\n\n# and tokenizing should work in the same manner!\ntokenized_sents = sent_tokenize(text)\n```\n\n## Technical Details\n\nclinitokenizer uses a `bert-large` Transformer model fine-tuned on sentences from Electronic Medical Records provided from the [i2b2/n2c2 dataset](https://n2c2.dbmi.hms.harvard.edu). The model has been fine-tuned and is inferenced using the [Simple Transformers library](http://simpletransformers.ai), and the model is hosted on [HuggingFace ](https://huggingface.co).\n\nThe model can be run on GPU or CPU, and will automatically switch depending on availability of GPU.\n\n## Tradeoffs and Considerations\n\n`clinitokenizer` uses a large neural network (about 1.2 GB) which will be downloaded and cached on-device on first run. This initial setup may take a few minutes, but should only happen once.\n\nCompared to other off-the-shelf sentence tokenizers (i.e. `nltk`), `clinitokenizer` will run slower and consume more memory when running on CPU, so if near-instant tokenization is the goal, using a GPU-based machine or another tokenizer may be better. On a machine with GPU, the time difference is negligable.\n\n`clinitokenizer` is optimized for natural-language text in the clinical domain. Therefore, when tokenizing more general English sentences or for tasks in a different domain, other generalized tokenizers may perform better.\n\n## Additional Configuration\nSee the [CliniTokenize class](https://github.com/clinisift/clinitokenizer/blob/main/src/clinitokenizer/tokenize.py) for more configuration options (more documentation coming soon).\n\n## Motivating Examples\nBelow are some examples of clinical text comparing `clinitokenizer` to `nltk.tokenize.sent_tokenize`:\n\n\n### \"He was asked if he was taking any medications. Patient is currently taking 5 m.g. Tylenol.\"\n**notes:** Challenge here is not mistaking m.g. for end-of-sentence.\n\n**nltk output:** \n\n```\nHe was asked if he was taking any medications.\nPatient is currently taking 5 m.g.\nTylenol.\n```\n\n\n**clinitokenizer output:**\n\n```\nHe was asked if he was taking any medications. \nPatient is currently taking 5 m.g. Tylenol.\n```\n\n---\n\n### \"Pt. has hx of alcohol use disorder He is recovering.\"\n**notes:** Challenge here is there is a typo after 'disorder', missing a period. Can tokenizer semantically identify new sentence?\n\n**nltk output:**\n\n```\nPt.\nhas hx of alcohol use disorder He is recovering.\n```\n\n**clinitokenizer output:**\n```\nPt. has hx of alcohol use disorder \nHe is recovering.\n```\n\n---\n\n### \"Pt. has hx of alcohol use disorder but He is recovering.\"\n**notes:** Opposite as previous example -- here, there is an accidental capitalization. Can tokenizer semantically identify it is NOT a new sentence?\n\n**nltk output:**\n\n```\nPt.\nhas hx of alcohol use disorder but He is recovering.\n```\n\n**clinitokenizer output:**\n\n```\nPt. has hx of alcohol use disorder but He is recovering.\n```\n\n---\n\n### \"Past Medical History: Patient has PMH of COPD.\"\n**notes:** \"Past Medical History\" is a sentence header. Even though it is technically a single sentence according to English grammar, when extracting section headers it may be important to identify them as distinct from all sentences under that header.\n\n**nltk output:**\n\n```\nPast Medical History: Patient has PMH of COPD.\n```\n\n**clinitokenizer output:**\n\n```\nPast Medical History: \nPatient has PMH of COPD.\n```\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/clinisift/clinitokenizer",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "clinitokenizer",
    "package_url": "https://pypi.org/project/clinitokenizer/",
    "platform": null,
    "project_url": "https://pypi.org/project/clinitokenizer/",
    "project_urls": {
      "Bug Tracker": "https://github.com/clinisift/clinitokenizer/issues",
      "Homepage": "https://github.com/clinisift/clinitokenizer"
    },
    "release_url": "https://pypi.org/project/clinitokenizer/0.0.5/",
    "requires_dist": [
      "setuptools (>=42)",
      "torch",
      "tqdm (>=4.62.3)",
      "simpletransformers (==0.63.6)",
      "transformers (==4.14.1)",
      "spacy (==3.1.3)"
    ],
    "requires_python": ">=3.6",
    "summary": "Sentence tokenizer for text from clinical notes.",
    "version": "0.0.5",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14977551,
  "releases": {
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "28703d25c72557fc6aaeaa67716f69f35647c6e65b8fd22cae4b0c342b480a1f",
          "md5": "0b067dcbf2e4202442427c82b5aebab6",
          "sha256": "bb8fb133638aae04906b1d0d5e8541d7542200097f3459b8b10e31bacfc65909"
        },
        "downloads": -1,
        "filename": "clinitokenizer-0.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0b067dcbf2e4202442427c82b5aebab6",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 8016,
        "upload_time": "2022-05-27T21:39:42",
        "upload_time_iso_8601": "2022-05-27T21:39:42.235453Z",
        "url": "https://files.pythonhosted.org/packages/28/70/3d25c72557fc6aaeaa67716f69f35647c6e65b8fd22cae4b0c342b480a1f/clinitokenizer-0.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1411cd4b0be2e1f62f43958d7ca3539e8e1617fe419c90974557e3fc8bff90d6",
          "md5": "42aff544c2743d1c9a9854fc50eea946",
          "sha256": "634d6e5d4685ae0b47c4c375decd69f310b776bcead62c829d111b692f3c4c4c"
        },
        "downloads": -1,
        "filename": "clinitokenizer-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "42aff544c2743d1c9a9854fc50eea946",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 7731,
        "upload_time": "2022-05-27T21:39:44",
        "upload_time_iso_8601": "2022-05-27T21:39:44.167404Z",
        "url": "https://files.pythonhosted.org/packages/14/11/cd4b0be2e1f62f43958d7ca3539e8e1617fe419c90974557e3fc8bff90d6/clinitokenizer-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f8606fe9bf711a01206b1bcc87944d8e498c4bb7cac0c84f64eea13000d2d528",
          "md5": "225bc0286d4b98371e7f4053716c0d68",
          "sha256": "44c8d5039ef13575ab04afb2960c54d9e604dde7c03fc9841602cebbdbb69d8a"
        },
        "downloads": -1,
        "filename": "clinitokenizer-0.0.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "225bc0286d4b98371e7f4053716c0d68",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 8477,
        "upload_time": "2022-05-27T22:21:08",
        "upload_time_iso_8601": "2022-05-27T22:21:08.223008Z",
        "url": "https://files.pythonhosted.org/packages/f8/60/6fe9bf711a01206b1bcc87944d8e498c4bb7cac0c84f64eea13000d2d528/clinitokenizer-0.0.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "734c087f835bb01f5f311fe6c5bcba36986eddc82e55bc4e3e77c4db16e25d40",
          "md5": "efa14e5d5d775a1fd4e02f021396df78",
          "sha256": "f5de51eae697d8e34d066e6c02e4fbddd9e2b155c0a4c5b9d9fd97d58106c186"
        },
        "downloads": -1,
        "filename": "clinitokenizer-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "efa14e5d5d775a1fd4e02f021396df78",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 8256,
        "upload_time": "2022-05-27T22:21:09",
        "upload_time_iso_8601": "2022-05-27T22:21:09.950638Z",
        "url": "https://files.pythonhosted.org/packages/73/4c/087f835bb01f5f311fe6c5bcba36986eddc82e55bc4e3e77c4db16e25d40/clinitokenizer-0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3e1b4821ad9e7b7dd281fc991a45b7dca21cda64e12fee806c8eb8e097dfeade",
          "md5": "f64a722baed303f62b97e81ba741dbde",
          "sha256": "8d68d9b6195266b2e20edadbb4530d81815706bacc68cb5ef80f2676b2ce5c1a"
        },
        "downloads": -1,
        "filename": "clinitokenizer-0.0.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f64a722baed303f62b97e81ba741dbde",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 8719,
        "upload_time": "2022-09-02T19:04:57",
        "upload_time_iso_8601": "2022-09-02T19:04:57.429073Z",
        "url": "https://files.pythonhosted.org/packages/3e/1b/4821ad9e7b7dd281fc991a45b7dca21cda64e12fee806c8eb8e097dfeade/clinitokenizer-0.0.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1a6df10cd8d05ad1b8e8d178512c87444791a945087faa0e7c54746cb5cca1e4",
          "md5": "95c6e9d6c6df286a51f5527eed01d1ff",
          "sha256": "aeda8ab8d6fa68e4e2ec3de62e3796e2fcaa97c35371665d39f0a11cfc639e87"
        },
        "downloads": -1,
        "filename": "clinitokenizer-0.0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "95c6e9d6c6df286a51f5527eed01d1ff",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 8646,
        "upload_time": "2022-09-02T19:04:59",
        "upload_time_iso_8601": "2022-09-02T19:04:59.034141Z",
        "url": "https://files.pythonhosted.org/packages/1a/6d/f10cd8d05ad1b8e8d178512c87444791a945087faa0e7c54746cb5cca1e4/clinitokenizer-0.0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "3e1b4821ad9e7b7dd281fc991a45b7dca21cda64e12fee806c8eb8e097dfeade",
        "md5": "f64a722baed303f62b97e81ba741dbde",
        "sha256": "8d68d9b6195266b2e20edadbb4530d81815706bacc68cb5ef80f2676b2ce5c1a"
      },
      "downloads": -1,
      "filename": "clinitokenizer-0.0.5-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "f64a722baed303f62b97e81ba741dbde",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 8719,
      "upload_time": "2022-09-02T19:04:57",
      "upload_time_iso_8601": "2022-09-02T19:04:57.429073Z",
      "url": "https://files.pythonhosted.org/packages/3e/1b/4821ad9e7b7dd281fc991a45b7dca21cda64e12fee806c8eb8e097dfeade/clinitokenizer-0.0.5-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "1a6df10cd8d05ad1b8e8d178512c87444791a945087faa0e7c54746cb5cca1e4",
        "md5": "95c6e9d6c6df286a51f5527eed01d1ff",
        "sha256": "aeda8ab8d6fa68e4e2ec3de62e3796e2fcaa97c35371665d39f0a11cfc639e87"
      },
      "downloads": -1,
      "filename": "clinitokenizer-0.0.5.tar.gz",
      "has_sig": false,
      "md5_digest": "95c6e9d6c6df286a51f5527eed01d1ff",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 8646,
      "upload_time": "2022-09-02T19:04:59",
      "upload_time_iso_8601": "2022-09-02T19:04:59.034141Z",
      "url": "https://files.pythonhosted.org/packages/1a/6d/f10cd8d05ad1b8e8d178512c87444791a945087faa0e7c54746cb5cca1e4/clinitokenizer-0.0.5.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}