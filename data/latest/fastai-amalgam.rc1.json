{
  "info": {
    "author": "Rahul Somani",
    "author_email": "rsomani95@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: Apache Software License",
      "Natural Language :: English",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8"
    ],
    "description": "# FastAI2 Extensions\n> This library is a collection of utility functions for a variety of purposes that fit right into the `fastai2` ecosystem. It's broadly divided into 3 modules -- _interpret_ , _augment_ , and _inference_ . \n\n\n## Install\n\n`pip install fastai2_extensions`\n\n## Interpretation\n\n##### `ClassificationInterpretationEx`\n\nExtends fastai's [`ClassificationInterpretation`](https://github.com/fastai/fastai2/blob/master/fastai2/interpret.py#L48) to plot model confidence and per-label accuracy bar graphs. It also adds some convenience to grab filenames based on these confidence levels.\n\nThis part of the library is currently suitable for Softmax classifiers only. Multilabel support will be added soon.\n\n```python\nfrom fastai2.vision.all import *\nfrom fastai2_extensions.interpret.all import *\n```\n\n```python\nlearn = load_learner('/Users/rahulsomani/Desktop/shot-lighting-cast/fastai2-110-epoch-model.pkl')\n```\n\n```python\ninterp = ClassificationInterpretationEx.from_learner(learn)\n```\n\n\n\n\n\n```python\nplt.style.use('ggplot')\ninterp.plot_accuracy()\n```\n\n\n![png](docs/images/output_7_0.png)\n\n\n```python\ninterp.plot_label_confidence()\n```\n\n\n![png](docs/images/output_8_0.png)\n\n\n##### `GradCam`\n\nThe `GradCam` object takes in 3 args:\n* `learn`: a fastai `Learner`\n* `fname`: path to the image file to draw the heatcam over\n* `labels`: list of labels to draw the heatmap for. If `None`, draws for the highest predicted class\n\nThere's quite a few plotting options. For more options, see the docs.\n\n```python\nimport PIL\nfname = '../assets/imgs/alice-in-wonderland.jpg'\nPIL.Image.open(fname).resize((550,270))\n```\n\n\n\n\n![png](docs/images/output_10_0.png)\n\n\n\n```python\ngcam = GradCam(learn, fname, None)\ngcam.plot(full_size=True, plot_original=True, figsize=(12,6))\n```\n\n\n\n\n\n\n![png](docs/images/output_11_1.png)\n\n\n```python\ngcam = GradCam(learn, fname, ['shot_lighting_cast_hard', 'shot_lighting_cast_soft'])\ngcam.plot(full_size=False, plot_original=False, figsize=(12,4))\n```\n\n\n![png](docs/images/output_12_0.png)\n\n\n##### Comparing Multiple Models\n\n`compare_venn` lets you compares 2 or models trained evaluated on the same dataset to inspect model agreement. If you only input 2 or 3 models, then you can also see Venn Diagrams for the same.\n\nFor simplicity, I'm using the same model here with smaller versions of the validation set to display this functionality.\n\n```python\ninterp1 = ClassificationInterpretationEx.from_learner(learn1)\ninterp2 = ClassificationInterpretationEx.from_learner(learn2)\ninterp3 = ClassificationInterpretationEx.from_learner(learn3)\ninterp1.compute_label_confidence()\ninterp2.compute_label_confidence()\ninterp3.compute_label_confidence()\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n```python\n%%capture\nfig,common_labels = compare_venn(\n    conf_level=(0,99),  interps=[interp1,interp2],\n    mode='accurate',\n    return_common=True, return_fig=True,\n    set_color='tomato'\n)\n```\n\n```python\nfig\n```\n\n\n\n\n![png](docs/images/output_16_0.png)\n\n\n\n```python\n%%capture\nfig,common_labels = compare_venn(\n    conf_level=(0,99),  interps=[interp1,interp2,interp3],\n    mode='accurate',\n    return_common=True, return_fig=True,\n    set_color='tomato'\n)\n```\n\n```python\nfig\n```\n\n\n\n\n![png](docs/images/output_18_0.png)\n\n\n\n## Augmentation\n\n`ApplyPILFilter`, not surprisingly, lets you apply one or more `PIL.ImageFilter`s as a data augmentation.\n\nThere's also a convenience function `read_lut` which lets you read in a LUT file (commonly found with `.cube` extensions), and construct a `PIL.ImageFilter.Color3dLUT` to apply as a transform.\n\nThe idea place for this in a fastai2 pipeline is as an `item_tfms` as it's a lossless transform and can be done right after reading the image from disk. A full example is shown in the docs.\n\n```python\nfrom fastai2_extensions.augment.pil_filters import *\n```\n\n```python\nlut   = read_lut('../assets/luts/2strip.cube')\nfname = '../assets/imgs/office-standoff.png'\n\nimg_raw  = PILImage.create(fname)\nimg_filt = ApplyPILFilter(lut,p=1.0)(fname, split_idx=0)\n```\n\n```python\n%%capture\nfig,ax = plt.subplots(nrows=1, ncols=2, figsize=(16,6))\nshow_tensor = lambda x,ax: ToTensor()(x).show(ctx=ax)\n\nshow_tensor(img_raw,ax[0])\nshow_tensor(img_filt,ax[1])\n\nax[0].set_title('Original')\nax[1].set_title('LUT Transformed')\n```\n\n```python\nfig\n```\n\n\n\n\n![png](docs/images/output_24_0.png)\n\n\n\n## Export\n\nConvenience wrappers to export to `ONNX`. <br>\nOther frameworks will be added soon.\n\n##### ONNX\n\n```python\n#hide_output\nfrom fastai2_extensions.inference.export import *\n```\n\n```python\ntorch_to_onnx(learn.model,\n              activation   = nn.Softmax(-1),\n              save_path    = Path.home()/'Desktop',\n              model_fname  = 'onnx-model',\n              input_shape  = (1,3,224,224),\n              input_name   = 'input_image',\n              output_names = 'output')\n```\n\n    Loading, polishing, and optimising exported model from /Users/rahulsomani/Desktop/onnx-model.onnx\n    Exported successfully\n\n\n```python\npath_onnx_model = '/Users/rahulsomani/Desktop/onnx-model.onnx'\nfname = '../assets/imgs/odyssey-ape.png'\n```\n\n```python\nfrom onnxruntime import InferenceSession\n\nsession = InferenceSession(path_onnx_model)\nx = {session.get_inputs()[0].name:\n     torch_to_numpy(preprocess_one(fname))} # preprocessing - varies based on your training\nsession.run(None, x)\n```\n\n\n\n\n    [array([[0.6942669 , 0.30573303]], dtype=float32)]\n\n\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/Synopsis/fastai_amalgam/tree/master/",
    "keywords": "fastai,deep learning,visualisation,interpretation",
    "license": "Apache Software License 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "fastai-amalgam",
    "package_url": "https://pypi.org/project/fastai-amalgam/",
    "platform": "",
    "project_url": "https://pypi.org/project/fastai-amalgam/",
    "project_urls": {
      "Homepage": "https://github.com/Synopsis/fastai_amalgam/tree/master/"
    },
    "release_url": "https://pypi.org/project/fastai-amalgam/0.0.26/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "A collection of various CV focused utilities for the fastai library. Includes interpretation, data augmentation, gradcam, loss-functions, model conversion utils, etc",
    "version": "0.0.26",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8996741,
  "releases": {
    "0.0.26": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "465f072541bf3df6f9452fbd54a567fce4e8f0e76b5209037e7113f8c52e98f7",
          "md5": "c14d5f20823017643bf7988c31698f97",
          "sha256": "4a0c6203f160129ddaca2e854b5864825ecf29987697c31802999bdd3796265d"
        },
        "downloads": -1,
        "filename": "fastai_amalgam-0.0.26-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "c14d5f20823017643bf7988c31698f97",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 29649,
        "upload_time": "2020-12-28T08:26:24",
        "upload_time_iso_8601": "2020-12-28T08:26:24.672813Z",
        "url": "https://files.pythonhosted.org/packages/46/5f/072541bf3df6f9452fbd54a567fce4e8f0e76b5209037e7113f8c52e98f7/fastai_amalgam-0.0.26-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4676288304e4152e9b8a040a8ec469552f1f33fed722391139eb2a16d35c3a16",
          "md5": "384995a1f495619c874382fb04991243",
          "sha256": "382b522ecb192ffd85b24b6d73576bd9b497451f2b4ac61602a5d66812f2bcec"
        },
        "downloads": -1,
        "filename": "fastai_amalgam-0.0.26.tar.gz",
        "has_sig": false,
        "md5_digest": "384995a1f495619c874382fb04991243",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 26657,
        "upload_time": "2020-12-28T08:26:27",
        "upload_time_iso_8601": "2020-12-28T08:26:27.046999Z",
        "url": "https://files.pythonhosted.org/packages/46/76/288304e4152e9b8a040a8ec469552f1f33fed722391139eb2a16d35c3a16/fastai_amalgam-0.0.26.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "465f072541bf3df6f9452fbd54a567fce4e8f0e76b5209037e7113f8c52e98f7",
        "md5": "c14d5f20823017643bf7988c31698f97",
        "sha256": "4a0c6203f160129ddaca2e854b5864825ecf29987697c31802999bdd3796265d"
      },
      "downloads": -1,
      "filename": "fastai_amalgam-0.0.26-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "c14d5f20823017643bf7988c31698f97",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 29649,
      "upload_time": "2020-12-28T08:26:24",
      "upload_time_iso_8601": "2020-12-28T08:26:24.672813Z",
      "url": "https://files.pythonhosted.org/packages/46/5f/072541bf3df6f9452fbd54a567fce4e8f0e76b5209037e7113f8c52e98f7/fastai_amalgam-0.0.26-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "4676288304e4152e9b8a040a8ec469552f1f33fed722391139eb2a16d35c3a16",
        "md5": "384995a1f495619c874382fb04991243",
        "sha256": "382b522ecb192ffd85b24b6d73576bd9b497451f2b4ac61602a5d66812f2bcec"
      },
      "downloads": -1,
      "filename": "fastai_amalgam-0.0.26.tar.gz",
      "has_sig": false,
      "md5_digest": "384995a1f495619c874382fb04991243",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 26657,
      "upload_time": "2020-12-28T08:26:27",
      "upload_time_iso_8601": "2020-12-28T08:26:27.046999Z",
      "url": "https://files.pythonhosted.org/packages/46/76/288304e4152e9b8a040a8ec469552f1f33fed722391139eb2a16d35c3a16/fastai_amalgam-0.0.26.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}