{
  "info": {
    "author": "Sevan Brodjian",
    "author_email": "sevanbro7@gmail.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# S3Synchrony\r\n\r\n_Created by Sevan Brodjian for Ameren at the Innovation Center @ UIUC_\r\n\r\nThis package provides a service for synchronizing file creations, deletions, and modifications across users on an AWS S3 prefix. Support also exists for easily expanding to other database systems.\r\n\r\n## Installation\r\n\r\nUse the package manager [pip](https://pip.pypa.io/en/stable/) to install s3synchrony.\r\n\r\n```bash\r\npip install s3synchrony\r\n```\r\n\r\n## Requirements\r\n\r\nS3Synchrony relies on Python 3 and the following packages to operate:\r\n\r\n- hashlib\r\n- datetime\r\n- pandas\r\n- boto3\r\n- botocore\r\n- pyperclip\r\n\r\n## Usage\r\n\r\nS3Synchrony comes with three primary functions, which can be called as follows:\r\n\r\n```python\r\nimport s3synchrony as s3s\r\n\r\n# returns a list of data platforms currently supported\r\ns3s.get_supported_platforms()\r\n\r\n# prompts user to synchronize all detected changes in the local and remote repositories\r\ns3s.smart_sync(platform=\"S3\", aws_bkt=\"bucket_name\", aws_prfx=\"prfx_path\")\r\n\r\n# prompts user to remove all synchronization support on the local and remote repositories\r\ns3s.reset_all(platform=\"S3\", aws_bkt=\"bucket_name\", aws_prfx=\"prfx_path\")\r\n```\r\n\r\n## The Data Folder\r\n\r\nWhen using S3Synchrony, you are synchronizing all of the data stored in a local directory with the data stored in an S3 directory. The S3 directory is referenced through both an AWS bucket, an AWS prefix, and the necessary credentials to access said prefix. The local directory to be used can be a relative or full path, and by default will be a subdirectory named \"Data\" stored in the same working directory.\r\n\r\n- Project Folder\r\n  - Data\r\n  - code, etc.\r\n\r\n## smart_sync\r\n\r\n```python\r\ndef smart_sync(platform=\"S3\", **kwargs):\r\n    \"\"\"Perform all necessary steps to synchronize a local repository   with a remote repo.\r\n\r\n    Notes:\r\n    Keyword arguments are dependent on platform selection.\r\n    \"\"\"\r\n\r\n\r\n    if(platform in _supported_platforms):\r\n        connection = _supported_platforms[platform](**kwargs)\r\n    else:\r\n        connection = baseconn.DataPlatformConnection(**kwargs)\r\n\r\n    connection.intro_message()\r\n    connection.establish_connection()\r\n    connection.synchronize()\r\n    connection.close_message()\r\n```\r\n\r\nThe smart_sync function is the premier work of this package, and will perform all of the data synchronization for you. This function will check the passed platform name, and reference a self-contained list of supported platforms to instantiate the proper class. This list of supported platforms can be accessed via a call to get_supported_platforms().\r\n\r\nEach connection type will require a different set of keyword arguments. For S3, the minimum arguments are \"aws_bkt\" and \"aws_prfx\". Please check the class docstrings for each connection type for more information.\r\n\r\nAll platform classes should be children of the DataPlatformConnection class which is an interface will all necessary public functions. For S3, a folder named .S3 will be created within your data folder. This .S3 folder will contain CSVs used for monitoring data changes and text files for storing small bits of information.\r\n\r\n- **versions.csv:** Contains the state of data stored on s3\r\n- **versionsLocal.csv:** Contains the state of data stored locally\r\n- **deletedS3.csv:** Contains all files deleted from S3\r\n- **deletedLocal.csv:** Contains all files deleted locally\r\n- **ignores3.txt:** Contains a list of file paths to be ignored entirely\r\n- **user_name.txt:** Contains the name attached to your file modifications\r\n- **aws.txt:** Contains credentials used to access the AWS prefix\r\n\r\nUsing these CSVs, S3Synchrony can determine what files you have newly created, deleted, and modified. It will then prompt you to upload these changes to S3. Once you have done so, it will upload new CSVs as needed. After downloading these new CSVs, your collaborative peers will be prompted to download your own changes as well as upload their own.\r\n\r\nIn addition, a tmp folder will be utilised within the .S3 folder. This tmp folder contains downloaded files from S3 that are used to compute certain CSVs.\r\n\r\n## Deletions\r\n\r\nWhen deleting files, the user will be prompted to confirm their deletions. Files that are deleted locally will simply be removed. Files deleted from S3, however, will simply be moved into a \"deleted\" subfolder of the .S3 folder on S3.\r\n\r\n## Logs\r\n\r\nWhen there are any issues with a file being uploaded or downloaded, an error message will be printed and that file will be skipped. A log will then be created a saved locally inside of the \"logs\" subfolder of the local .S3 folder.\r\n\r\n## reset_all\r\n\r\n```python\r\ndef reset_all(platform=\"S3\", **kwargs):\r\n    \"\"\"Reset local and remote directories to original state.\r\n\r\n    Notes:\r\n    Keyword arguments are dependent on platform selection.\r\n    \"\"\"\r\n\r\n    if(platform in _supported_platforms):\r\n        connection = _supported_platforms[platform](**kwargs)\r\n    else:\r\n        connection = baseconn.DataPlatformConnection(**kwargs)\r\n\r\n    connection.intro_message()\r\n    connection.establish_connection()\r\n    if connection.reset_confirm():\r\n        connection.reset_local()\r\n        connection.reset_remote()\r\n    connection.close_message()\r\n```\r\n\r\nResetting all S3Synchrony services is as simple as deleting the .S3 folders contained locally and on S3. Once these are deleted, synchronization cannot occur until they are recreated, which can be done by simply making a new call to S3Synchrony.\r\n\r\nBefore resetting, however, a call to reset_confirm **must** occur. The user will then be prompted to confirm that they would like their .S3 folders removed.\r\n\r\n## License\r\n\r\n[GNU GPLv3](https://www.gnu.org/licenses/)\r\n\r\n\r\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/SevanBrodjian/s3synchrony",
    "keywords": "",
    "license": "LICENSE.md",
    "maintainer": "",
    "maintainer_email": "",
    "name": "s3synchrony",
    "package_url": "https://pypi.org/project/s3synchrony/",
    "platform": "",
    "project_url": "https://pypi.org/project/s3synchrony/",
    "project_urls": {
      "Homepage": "https://github.com/SevanBrodjian/s3synchrony"
    },
    "release_url": "https://pypi.org/project/s3synchrony/0.1.1/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "This package provides a service for synchronizing file creations, deletions, and modifications across users on an AWS S3 prefix.",
    "version": "0.1.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12610475,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ef4adfcee640a523748e66a364e0884ef8c477cb69627560aa6f6f06804ccece",
          "md5": "dbe7f8044b4b9c876455b26d8cc913ec",
          "sha256": "3557eb2342929ac8be9577cca22b84a142e52286c6e7573cd2450e0f31f5c9ee"
        },
        "downloads": -1,
        "filename": "s3synchrony-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "dbe7f8044b4b9c876455b26d8cc913ec",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 917,
        "upload_time": "2022-01-13T17:58:29",
        "upload_time_iso_8601": "2022-01-13T17:58:29.696457Z",
        "url": "https://files.pythonhosted.org/packages/ef/4a/dfcee640a523748e66a364e0884ef8c477cb69627560aa6f6f06804ccece/s3synchrony-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "37b641aae913fd1114687b6b363633b3bf9c6744d153a5c6e21911bd66eed7b3",
          "md5": "5ea2c4aa1fce5ea24c22f6dc9e34b305",
          "sha256": "ab6c3af2b6d8671b4fc57c105912256809071c64c0bfc732c864ff93fd4e2a70"
        },
        "downloads": -1,
        "filename": "s3synchrony-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "5ea2c4aa1fce5ea24c22f6dc9e34b305",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 37488,
        "upload_time": "2022-01-18T18:17:59",
        "upload_time_iso_8601": "2022-01-18T18:17:59.762324Z",
        "url": "https://files.pythonhosted.org/packages/37/b6/41aae913fd1114687b6b363633b3bf9c6744d153a5c6e21911bd66eed7b3/s3synchrony-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "37b641aae913fd1114687b6b363633b3bf9c6744d153a5c6e21911bd66eed7b3",
        "md5": "5ea2c4aa1fce5ea24c22f6dc9e34b305",
        "sha256": "ab6c3af2b6d8671b4fc57c105912256809071c64c0bfc732c864ff93fd4e2a70"
      },
      "downloads": -1,
      "filename": "s3synchrony-0.1.1.tar.gz",
      "has_sig": false,
      "md5_digest": "5ea2c4aa1fce5ea24c22f6dc9e34b305",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 37488,
      "upload_time": "2022-01-18T18:17:59",
      "upload_time_iso_8601": "2022-01-18T18:17:59.762324Z",
      "url": "https://files.pythonhosted.org/packages/37/b6/41aae913fd1114687b6b363633b3bf9c6744d153a5c6e21911bd66eed7b3/s3synchrony-0.1.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}