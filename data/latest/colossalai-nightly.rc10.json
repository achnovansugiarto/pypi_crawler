{
  "info": {
    "author": "",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "Environment :: GPU :: NVIDIA CUDA",
      "License :: OSI Approved :: Apache Software License",
      "Programming Language :: Python :: 3",
      "Topic :: Scientific/Engineering :: Artificial Intelligence",
      "Topic :: System :: Distributed Computing"
    ],
    "description": "# Colossal-AI\n<div id=\"top\" align=\"center\">\n\n   [![logo](https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/colossal-ai_logo_vertical.png)](https://www.colossalai.org/)\n\n   Colossal-AI: Making large AI models cheaper, faster and more accessible\n\n   <h3> <a href=\"https://arxiv.org/abs/2110.14883\"> Paper </a> |\n   <a href=\"https://www.colossalai.org/\"> Documentation </a> |\n   <a href=\"https://github.com/hpcaitech/ColossalAI/tree/main/examples\"> Examples </a> |\n   <a href=\"https://github.com/hpcaitech/ColossalAI/discussions\"> Forum </a> |\n   <a href=\"https://medium.com/@hpcaitech\"> Blog </a></h3>\n\n   [![GitHub Repo stars](https://img.shields.io/github/stars/hpcaitech/ColossalAI?style=social)](https://github.com/hpcaitech/ColossalAI/stargazers)\n   [![Build](https://github.com/hpcaitech/ColossalAI/actions/workflows/build_on_schedule.yml/badge.svg)](https://github.com/hpcaitech/ColossalAI/actions/workflows/build_on_schedule.yml)\n   [![Documentation](https://readthedocs.org/projects/colossalai/badge/?version=latest)](https://colossalai.readthedocs.io/en/latest/?badge=latest)\n   [![CodeFactor](https://www.codefactor.io/repository/github/hpcaitech/colossalai/badge)](https://www.codefactor.io/repository/github/hpcaitech/colossalai)\n   [![HuggingFace badge](https://img.shields.io/badge/%F0%9F%A4%97HuggingFace-Join-yellow)](https://huggingface.co/hpcai-tech)\n   [![slack badge](https://img.shields.io/badge/Slack-join-blueviolet?logo=slack&amp)](https://join.slack.com/t/colossalaiworkspace/shared_invite/zt-z7b26eeb-CBp7jouvu~r0~lcFzX832w)\n   [![WeChat badge](https://img.shields.io/badge/微信-加入-green?logo=wechat&amp)](https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/WeChat.png)\n\n\n   | [English](README.md) | [中文](docs/README-zh-Hans.md) |\n\n</div>\n\n## Latest News\n* [2023/03] [AWS and Google Fund Colossal-AI with Startup Cloud Programs](https://www.hpc-ai.tech/blog/aws-and-google-fund-colossal-ai-with-startup-cloud-programs)\n* [2023/02] [Open source solution replicates ChatGPT training process! Ready to go with only 1.6GB GPU memory](https://www.hpc-ai.tech/blog/colossal-ai-chatgpt)\n* [2023/01] [Hardware Savings Up to 46 Times for AIGC and  Automatic Parallelism](https://medium.com/pytorch/latest-colossal-ai-boasts-novel-automatic-parallelism-and-offers-savings-up-to-46x-for-stable-1453b48f3f02)\n* [2022/11] [Diffusion Pretraining and Hardware Fine-Tuning Can Be Almost 7X Cheaper](https://www.hpc-ai.tech/blog/diffusion-pretraining-and-hardware-fine-tuning-can-be-almost-7x-cheaper)\n* [2022/10] [Use a Laptop to Analyze 90% of Proteins, With a Single-GPU Inference Sequence Exceeding 10,000](https://www.hpc-ai.tech/blog/use-a-laptop-to-analyze-90-of-proteins-with-a-single-gpu-inference-sequence-exceeding)\n* [2022/09] [HPC-AI Tech Completes $6 Million Seed and Angel Round Fundraising](https://www.hpc-ai.tech/blog/hpc-ai-tech-completes-6-million-seed-and-angel-round-fundraising-led-by-bluerun-ventures-in-the)\n\n## Table of Contents\n<ul>\n <li><a href=\"#Why-Colossal-AI\">Why Colossal-AI</a> </li>\n <li><a href=\"#Features\">Features</a> </li>\n <li>\n   <a href=\"#Parallel-Training-Demo\">Parallel Training Demo</a>\n   <ul>\n     <li><a href=\"#GPT-3\">GPT-3</a></li>\n     <li><a href=\"#GPT-2\">GPT-2</a></li>\n     <li><a href=\"#BERT\">BERT</a></li>\n     <li><a href=\"#PaLM\">PaLM</a></li>\n     <li><a href=\"#OPT\">OPT</a></li>\n     <li><a href=\"#ViT\">ViT</a></li>\n     <li><a href=\"#Recommendation-System-Models\">Recommendation System Models</a></li>\n   </ul>\n </li>\n <li>\n   <a href=\"#Single-GPU-Training-Demo\">Single GPU Training Demo</a>\n   <ul>\n     <li><a href=\"#GPT-2-Single\">GPT-2</a></li>\n     <li><a href=\"#PaLM-Single\">PaLM</a></li>\n   </ul>\n </li>\n <li>\n   <a href=\"#Inference-Energon-AI-Demo\">Inference (Energon-AI) Demo</a>\n   <ul>\n     <li><a href=\"#GPT-3-Inference\">GPT-3</a></li>\n     <li><a href=\"#OPT-Serving\">OPT-175B Online Serving for Text Generation</a></li>\n     <li><a href=\"#BLOOM-Inference\">176B BLOOM</a></li>\n   </ul>\n </li>\n   <li>\n   <a href=\"#Colossal-AI-in-the-Real-World\">Colossal-AI for Real World Applications</a>\n   <ul>\n     <li><a href=\"#ChatGPT\">ChatGPT: Low-cost ChatGPT Equivalent Implementation Process</a></li>\n     <li><a href=\"#AIGC\">AIGC: Acceleration of Stable Diffusion</a></li>\n     <li><a href=\"#Biomedicine\">Biomedicine: Acceleration of AlphaFold Protein Structure</a></li>\n   </ul>\n </li>\n <li>\n   <a href=\"#Installation\">Installation</a>\n   <ul>\n     <li><a href=\"#PyPI\">PyPI</a></li>\n     <li><a href=\"#Install-From-Source\">Install From Source</a></li>\n   </ul>\n </li>\n <li><a href=\"#Use-Docker\">Use Docker</a></li>\n <li><a href=\"#Community\">Community</a></li>\n <li><a href=\"#Contributing\">Contributing</a></li>\n <li><a href=\"#Cite-Us\">Cite Us</a></li>\n</ul>\n\n## Why Colossal-AI\n<div align=\"center\">\n   <a href=\"https://youtu.be/KnXSfjqkKN0\">\n   <img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/JamesDemmel_Colossal-AI.png\" width=\"600\" />\n   </a>\n\n   Prof. James Demmel (UC Berkeley): Colossal-AI makes training AI models efficient, easy, and scalable.\n</div>\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n\n## Features\n\nColossal-AI provides a collection of parallel components for you. We aim to support you to write your\ndistributed deep learning models just like how you write your model on your laptop. We provide user-friendly tools to kickstart\ndistributed training and inference in a few lines.\n\n- Parallelism strategies\n  - Data Parallelism\n  - Pipeline Parallelism\n  - 1D, [2D](https://arxiv.org/abs/2104.05343), [2.5D](https://arxiv.org/abs/2105.14500), [3D](https://arxiv.org/abs/2105.14450) Tensor Parallelism\n  - [Sequence Parallelism](https://arxiv.org/abs/2105.13120)\n  - [Zero Redundancy Optimizer (ZeRO)](https://arxiv.org/abs/1910.02054)\n  - [Auto-Parallelism](https://arxiv.org/abs/2302.02599)\n\n- Heterogeneous Memory Management\n  - [PatrickStar](https://arxiv.org/abs/2108.05818)\n\n- Friendly Usage\n  - Parallelism based on configuration file\n\n- Inference\n  - [Energon-AI](https://github.com/hpcaitech/EnergonAI)\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n\n## Parallel Training Demo\n\n### GPT-3\n<p align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/GPT3-v5.png\" width=700/>\n</p>\n\n- Save 50% GPU resources, and 10.7% acceleration\n\n### GPT-2\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/GPT2.png\" width=800/>\n\n- 11x lower GPU memory consumption, and superlinear scaling efficiency with Tensor Parallelism\n\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/(updated)GPT-2.png\" width=800>\n\n- 24x larger model size on the same hardware\n- over 3x acceleration\n### BERT\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/BERT.png\" width=800/>\n\n- 2x faster training, or 50% longer sequence length\n\n### PaLM\n- [PaLM-colossalai](https://github.com/hpcaitech/PaLM-colossalai): Scalable implementation of Google's Pathways Language Model ([PaLM](https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html)).\n\n### OPT\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/OPT_update.png\" width=800/>\n\n- [Open Pretrained Transformer (OPT)](https://github.com/facebookresearch/metaseq), a 175-Billion parameter AI language model released by Meta, which stimulates AI programmers to perform various downstream tasks and application deployments because public pretrained model weights.\n- 45% speedup fine-tuning OPT at low cost in lines. [[Example]](https://github.com/hpcaitech/ColossalAI/tree/main/examples/language/opt) [[Online Serving]](https://colossalai.org/docs/advanced_tutorials/opt_service)\n\nPlease visit our [documentation](https://www.colossalai.org/) and [examples](https://github.com/hpcaitech/ColossalAI/tree/main/examples) for more details.\n\n### ViT\n<p align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/ViT.png\" width=\"450\" />\n</p>\n\n- 14x larger batch size, and 5x faster training for Tensor Parallelism = 64\n\n### Recommendation System Models\n- [Cached Embedding](https://github.com/hpcaitech/CachedEmbedding), utilize software cache to train larger embedding tables with a smaller GPU memory budget.\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n\n## Single GPU Training Demo\n\n### GPT-2\n<p id=\"GPT-2-Single\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/GPT2-GPU1.png\" width=450/>\n</p>\n\n- 20x larger model size on the same hardware\n\n<p id=\"GPT-2-NVME\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/GPT2-NVME.png\" width=800/>\n</p>\n\n- 120x larger model size on the same hardware (RTX 3080)\n\n### PaLM\n<p id=\"PaLM-Single\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/PaLM-GPU1.png\" width=450/>\n</p>\n\n- 34x larger model size on the same hardware\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n\n\n## Inference (Energon-AI) Demo\n\n<p id=\"GPT-3-Inference\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/inference_GPT-3.jpg\" width=800/>\n</p>\n\n- [Energon-AI](https://github.com/hpcaitech/EnergonAI): 50% inference acceleration on the same hardware\n\n<p id=\"OPT-Serving\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/BLOOM%20serving.png\" width=600/>\n</p>\n\n- [OPT Serving](https://colossalai.org/docs/advanced_tutorials/opt_service): Try 175-billion-parameter OPT online services\n\n<p id=\"BLOOM-Inference\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/BLOOM%20Inference.PNG\" width=800/>\n</p>\n\n- [BLOOM](https://github.com/hpcaitech/EnergonAI/tree/main/examples/bloom): Reduce hardware deployment costs of 176-billion-parameter BLOOM by more than 10 times.\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n\n## Colossal-AI in the Real World\n### ChatGPT\nA low-cost [ChatGPT](https://openai.com/blog/chatgpt/) equivalent implementation process. [[code]](https://github.com/hpcaitech/ColossalAI/tree/main/applications/ChatGPT) [[blog]](https://www.hpc-ai.tech/blog/colossal-ai-chatgpt)\n<p id=\"ChatGPT_scaling\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/applications/chatgpt/ChatGPT%20scaling.png\" width=800/>\n</p>\n\n- Up to 7.73 times faster for single server training and 1.42 times faster for single-GPU inference\n\n<p id=\"ChatGPT-1GPU\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/applications/chatgpt/ChatGPT-1GPU.jpg\" width=450/>\n</p>\n\n- Up to 10.3x growth in model capacity on one GPU\n- A mini demo training process requires only 1.62GB of GPU memory (any consumer-grade GPU)\n\n<p id=\"inference\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/applications/chatgpt/LoRA%20data.jpg\" width=600/>\n</p>\n\n- Increase the capacity of the fine-tuning model by up to 3.7 times on a single GPU\n- Keep in a sufficiently high running speed\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n\n\n### AIGC\nAcceleration of AIGC (AI-Generated Content) models such as [Stable Diffusion v1](https://github.com/CompVis/stable-diffusion) and [Stable Diffusion v2](https://github.com/Stability-AI/stablediffusion).\n<p id=\"diffusion_train\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/Stable%20Diffusion%20v2.png\" width=800/>\n</p>\n\n- [Training](https://github.com/hpcaitech/ColossalAI/tree/main/examples/images/diffusion): Reduce Stable Diffusion memory consumption by up to 5.6x and hardware cost by up to 46x (from A100 to RTX3060).\n\n<p id=\"diffusion_demo\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/DreamBooth.png\" width=800/>\n</p>\n\n- [DreamBooth Fine-tuning](https://github.com/hpcaitech/ColossalAI/tree/main/examples/images/dreambooth): Personalize your model using just 3-5 images of the desired subject.\n\n<p id=\"inference\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/Stable%20Diffusion%20Inference.jpg\" width=800/>\n</p>\n\n- [Inference](https://github.com/hpcaitech/ColossalAI/tree/main/examples/images/diffusion): Reduce inference GPU memory consumption by 2.5x.\n\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n\n### Biomedicine\nAcceleration of [AlphaFold Protein Structure](https://alphafold.ebi.ac.uk/)\n\n<p id=\"FastFold\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/FastFold.jpg\" width=800/>\n</p>\n\n- [FastFold](https://github.com/hpcaitech/FastFold): Accelerating training and inference on GPU Clusters, faster data processing, inference sequence containing more than 10000 residues.\n\n<p id=\"FastFold-Intel\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/data%20preprocessing%20with%20Intel.jpg\" width=600/>\n</p>\n\n- [FastFold with Intel](https://github.com/hpcaitech/FastFold): 3x inference acceleration and 39% cost reduce.\n\n<p id=\"xTrimoMultimer\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/xTrimoMultimer_Table.jpg\" width=800/>\n</p>\n\n- [xTrimoMultimer](https://github.com/biomap-research/xTrimoMultimer): accelerating structure prediction of protein monomers and multimer by 11x.\n\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n\n## Installation\n\nRequirements:\n- PyTorch >= 1.11 (PyTorch 2.x in progress)\n- Python >= 3.7\n- CUDA >= 11.0\n\nIf you encounter any problem about installation, you may want to raise an [issue](https://github.com/hpcaitech/ColossalAI/issues/new/choose) in this repository.\n\n### Install from PyPI\n\nYou can easily install Colossal-AI with the following command. **By default, we do not build PyTorch extensions during installation.**\n\n```bash\npip install colossalai\n```\n\n**Note: only Linux is supported for now.**\n\nHowever, if you want to build the PyTorch extensions during installation, you can set `CUDA_EXT=1`.\n\n```bash\nCUDA_EXT=1 pip install colossalai\n```\n\n**Otherwise, CUDA kernels will be built during runtime when you actually need it.**\n\nWe also keep release the nightly version to PyPI on a weekly basis. This allows you to access the unreleased features and bug fixes in the main branch.\nInstallation can be made via\n\n```bash\npip install colossalai-nightly\n```\n\n### Download From Source\n\n> The version of Colossal-AI will be in line with the main branch of the repository. Feel free to raise an issue if you encounter any problem. :)\n\n```shell\ngit clone https://github.com/hpcaitech/ColossalAI.git\ncd ColossalAI\n\n# install colossalai\npip install .\n```\n\nBy default, we do not compile CUDA/C++ kernels. ColossalAI will build them during runtime.\nIf you want to install and enable CUDA kernel fusion (compulsory installation when using fused optimizer):\n\n```shell\nCUDA_EXT=1 pip install .\n```\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n\n## Use Docker\n\n### Pull from DockerHub\n\nYou can directly pull the docker image from our [DockerHub page](https://hub.docker.com/r/hpcaitech/colossalai). The image is automatically uploaded upon release.\n\n\n### Build On Your Own\n\nRun the following command to build a docker image from Dockerfile provided.\n\n> Building Colossal-AI from scratch requires GPU support, you need to use Nvidia Docker Runtime as the default when doing `docker build`. More details can be found [here](https://stackoverflow.com/questions/59691207/docker-build-with-nvidia-runtime).\n> We recommend you install Colossal-AI from our [project page](https://www.colossalai.org) directly.\n\n\n```bash\ncd ColossalAI\ndocker build -t colossalai ./docker\n```\n\nRun the following command to start the docker container in interactive mode.\n\n```bash\ndocker run -ti --gpus all --rm --ipc=host colossalai bash\n```\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n\n## Community\n\nJoin the Colossal-AI community on [Forum](https://github.com/hpcaitech/ColossalAI/discussions),\n[Slack](https://join.slack.com/t/colossalaiworkspace/shared_invite/zt-z7b26eeb-CBp7jouvu~r0~lcFzX832w),\nand [WeChat(微信)](https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/WeChat.png \"qrcode\") to share your suggestions, feedback, and questions with our engineering team.\n\n## Contributing\nReferring to the successful attempts of [BLOOM](https://bigscience.huggingface.co/) and [Stable Diffusion](https://en.wikipedia.org/wiki/Stable_Diffusion), any and all developers and partners with computing powers, datasets, models are welcome to join and build the Colossal-AI community, making efforts towards the era of big AI models!\n\nYou may contact us or participate in the following ways:\n1. [Leaving a Star ⭐](https://github.com/hpcaitech/ColossalAI/stargazers) to show your like and support. Thanks!\n2. Posting an [issue](https://github.com/hpcaitech/ColossalAI/issues/new/choose), or submitting a PR on GitHub follow the guideline in [Contributing](https://github.com/hpcaitech/ColossalAI/blob/main/CONTRIBUTING.md)\n3. Send your official proposal to email contact@hpcaitech.com\n\nThanks so much to all of our amazing contributors!\n\n<a href=\"https://github.com/hpcaitech/ColossalAI/graphs/contributors\"><img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/contributor_avatar.png\" width=\"800px\"></a>\n\n*The order of contributor avatars is randomly shuffled.*\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n\n\n## CI/CD\n\nWe leverage the power of [GitHub Actions](https://github.com/features/actions) to automate our development, release and deployment workflows. Please check out this [documentation](.github/workflows/README.md) on how the automated workflows are operated.\n\n\n## Cite Us\n\nThis project is inspired by some related projects (some by our team and some by other organizations). We would like to credit these amazing projects as listed in the [Reference List](./docs/REFERENCE.md).\n\nTo cite this project, you can use the following BibTeX citation.\n\n```\n@article{bian2021colossal,\n  title={Colossal-AI: A Unified Deep Learning System For Large-Scale Parallel Training},\n  author={Bian, Zhengda and Liu, Hongxin and Wang, Boxiang and Huang, Haichen and Li, Yongbin and Wang, Chuanrui and Cui, Fan and You, Yang},\n  journal={arXiv preprint arXiv:2110.14883},\n  year={2021}\n}\n```\n\nColossal-AI has been accepted as official tutorials by top conference [SC](https://sc22.supercomputing.org/), [AAAI](https://aaai.org/Conferences/AAAI-23/), [PPoPP](https://ppopp23.sigplan.org/), [CVPR](https://cvpr2023.thecvf.com/), [ISC](https://www.isc-hpc.com/), etc.\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://www.colossalai.org",
    "keywords": "",
    "license": "Apache Software License 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "colossalai-nightly",
    "package_url": "https://pypi.org/project/colossalai-nightly/",
    "platform": null,
    "project_url": "https://pypi.org/project/colossalai-nightly/",
    "project_urls": {
      "Bug Tracker": "https://github.com/hpcaitech/ColossalAI/issues",
      "Documentation": "http://colossalai.readthedocs.io",
      "Examples": "https://github.com/hpcaitech/ColossalAI-Examples",
      "Forum": "https://github.com/hpcaitech/ColossalAI/discussions",
      "Github": "https://github.com/hpcaitech/ColossalAI",
      "Homepage": "https://www.colossalai.org"
    },
    "release_url": "https://pypi.org/project/colossalai-nightly/2023.3.25/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "An integrated large-scale model training system with efficient parallelization techniques",
    "version": "2023.3.25",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17437107,
  "releases": {
    "2023.1.14": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "edd115915cfbcbe44ddfd44192c4741389773344a0dbbf453ffb53e61f3eea05",
          "md5": "f70b69f3de37716f621cebd3f91f1ee0",
          "sha256": "b09138da6187fd5a6afcf6d3ff59223a1fec5602530ba96e198564780fa7964b"
        },
        "downloads": -1,
        "filename": "colossalai-nightly-2023.1.14.tar.gz",
        "has_sig": false,
        "md5_digest": "f70b69f3de37716f621cebd3f91f1ee0",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 702415,
        "upload_time": "2023-01-14T00:10:28",
        "upload_time_iso_8601": "2023-01-14T00:10:28.052646Z",
        "url": "https://files.pythonhosted.org/packages/ed/d1/15915cfbcbe44ddfd44192c4741389773344a0dbbf453ffb53e61f3eea05/colossalai-nightly-2023.1.14.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "2023.1.21": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c169c9bd30dcd6d272c687dd8d5ec7b04ba8a1bef7164560b008dade53715646",
          "md5": "c1a3ee8054cd2015cbd9a7ae72395208",
          "sha256": "cb41496381cb6c7e9090a7789eb24c01a87d8c1b0ffac2bc3e19430e184d0e90"
        },
        "downloads": -1,
        "filename": "colossalai-nightly-2023.1.21.tar.gz",
        "has_sig": false,
        "md5_digest": "c1a3ee8054cd2015cbd9a7ae72395208",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 707169,
        "upload_time": "2023-01-21T00:11:33",
        "upload_time_iso_8601": "2023-01-21T00:11:33.474273Z",
        "url": "https://files.pythonhosted.org/packages/c1/69/c9bd30dcd6d272c687dd8d5ec7b04ba8a1bef7164560b008dade53715646/colossalai-nightly-2023.1.21.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "2023.1.28": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b9d14fe509cbd801af25cdf7730172f6f1130e5c0bee78fad79b02d335186f23",
          "md5": "d9cf0b98152f6415dd1df14fb67421a2",
          "sha256": "1733c85791e973d2012cd8aa73478b189fcde5e77fdc2900039bd008b56407f8"
        },
        "downloads": -1,
        "filename": "colossalai-nightly-2023.1.28.tar.gz",
        "has_sig": false,
        "md5_digest": "d9cf0b98152f6415dd1df14fb67421a2",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 707023,
        "upload_time": "2023-01-28T00:10:28",
        "upload_time_iso_8601": "2023-01-28T00:10:28.525139Z",
        "url": "https://files.pythonhosted.org/packages/b9/d1/4fe509cbd801af25cdf7730172f6f1130e5c0bee78fad79b02d335186f23/colossalai-nightly-2023.1.28.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "2023.1.9": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "36a10f6791309d797467cb6c6a51cdaa7a03a27ae9ed63ed9a09a593cb7d1070",
          "md5": "3519d9de481929b1bfc9d354808fcee4",
          "sha256": "91846c0956da5a0cf81de8f0af1e109c5f43e32c628720a9a83aa113b15240dc"
        },
        "downloads": -1,
        "filename": "colossalai-nightly-2023.1.9.tar.gz",
        "has_sig": false,
        "md5_digest": "3519d9de481929b1bfc9d354808fcee4",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 698796,
        "upload_time": "2023-01-09T08:47:13",
        "upload_time_iso_8601": "2023-01-09T08:47:13.303049Z",
        "url": "https://files.pythonhosted.org/packages/36/a1/0f6791309d797467cb6c6a51cdaa7a03a27ae9ed63ed9a09a593cb7d1070/colossalai-nightly-2023.1.9.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "2023.2.25": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "86af6e1bbe7ae3e7b80f36996a277763e737cb9592c5ad22f9f743c9210d9360",
          "md5": "9553847855e7f23c6dd961c3c006f5cd",
          "sha256": "a95b44f6125ea29ebe0dd1e460f7ff103181bcb7220f01d516cdcb1cdc34f714"
        },
        "downloads": -1,
        "filename": "colossalai-nightly-2023.2.25.tar.gz",
        "has_sig": false,
        "md5_digest": "9553847855e7f23c6dd961c3c006f5cd",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 679888,
        "upload_time": "2023-02-25T00:16:31",
        "upload_time_iso_8601": "2023-02-25T00:16:31.664101Z",
        "url": "https://files.pythonhosted.org/packages/86/af/6e1bbe7ae3e7b80f36996a277763e737cb9592c5ad22f9f743c9210d9360/colossalai-nightly-2023.2.25.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "2023.2.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5d10019734e1c1374b720b4624efe7b179cf1844341d796c93aab4f8e96f765d",
          "md5": "4f8341b3ff699f58a796c3123ad389b0",
          "sha256": "a88845ceafe8c79371c3239d84b3bce60d3187aa8c0d1134a8cca9ce3a57b689"
        },
        "downloads": -1,
        "filename": "colossalai-nightly-2023.2.4.tar.gz",
        "has_sig": false,
        "md5_digest": "4f8341b3ff699f58a796c3123ad389b0",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 709845,
        "upload_time": "2023-02-04T00:10:53",
        "upload_time_iso_8601": "2023-02-04T00:10:53.599397Z",
        "url": "https://files.pythonhosted.org/packages/5d/10/019734e1c1374b720b4624efe7b179cf1844341d796c93aab4f8e96f765d/colossalai-nightly-2023.2.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "2023.3.11": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8d1f790fb3ebb04b0e1859b9f1f674042872e3e4958b52fd6039d67cd49933f4",
          "md5": "e9407a81e95d92c382425d6b324c20ec",
          "sha256": "07fa4b7052b036de67700868209693d9b423bb05d71ed5d907c0d2c3585bd88d"
        },
        "downloads": -1,
        "filename": "colossalai-nightly-2023.3.11.tar.gz",
        "has_sig": false,
        "md5_digest": "e9407a81e95d92c382425d6b324c20ec",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 687204,
        "upload_time": "2023-03-11T00:14:31",
        "upload_time_iso_8601": "2023-03-11T00:14:31.155809Z",
        "url": "https://files.pythonhosted.org/packages/8d/1f/790fb3ebb04b0e1859b9f1f674042872e3e4958b52fd6039d67cd49933f4/colossalai-nightly-2023.3.11.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "2023.3.18": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5bdfbe899ad0eb9f533db1beaf919d31958c722b2802d7cabcf5081016bbec1a",
          "md5": "3387f46c052168c759adfad6c6f1c360",
          "sha256": "81704d2aa75a5f50f01fc25dd6c56733a0a1e432a63d2a50dc398f082588ce71"
        },
        "downloads": -1,
        "filename": "colossalai-nightly-2023.3.18.tar.gz",
        "has_sig": false,
        "md5_digest": "3387f46c052168c759adfad6c6f1c360",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 698797,
        "upload_time": "2023-03-18T00:15:04",
        "upload_time_iso_8601": "2023-03-18T00:15:04.125785Z",
        "url": "https://files.pythonhosted.org/packages/5b/df/be899ad0eb9f533db1beaf919d31958c722b2802d7cabcf5081016bbec1a/colossalai-nightly-2023.3.18.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "2023.3.25": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7fff3aeffabce4eb59362f61411740d71e11f049bc867d2fe95dd81fa8a7b2ea",
          "md5": "81145700aa94bb0284a94af67318e8eb",
          "sha256": "429f7e18ceaaedc1d30c2eb6f0e916fab11fbed020aa9aa59fe08e4447e3c43f"
        },
        "downloads": -1,
        "filename": "colossalai-nightly-2023.3.25.tar.gz",
        "has_sig": false,
        "md5_digest": "81145700aa94bb0284a94af67318e8eb",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 726208,
        "upload_time": "2023-03-25T00:14:07",
        "upload_time_iso_8601": "2023-03-25T00:14:07.582877Z",
        "url": "https://files.pythonhosted.org/packages/7f/ff/3aeffabce4eb59362f61411740d71e11f049bc867d2fe95dd81fa8a7b2ea/colossalai-nightly-2023.3.25.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "2023.3.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d27ddd337098cd4ae49fb25393a2f4c021b024ecf21e3a955f42dd27c1317a3d",
          "md5": "02851d4d04f8449e75725a907c5a6637",
          "sha256": "326e5884e475ef537f07dfcca869fd7268ede5f640bbce8afe9a8369cd9b55e9"
        },
        "downloads": -1,
        "filename": "colossalai-nightly-2023.3.4.tar.gz",
        "has_sig": false,
        "md5_digest": "02851d4d04f8449e75725a907c5a6637",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 685101,
        "upload_time": "2023-03-04T00:15:04",
        "upload_time_iso_8601": "2023-03-04T00:15:04.839141Z",
        "url": "https://files.pythonhosted.org/packages/d2/7d/dd337098cd4ae49fb25393a2f4c021b024ecf21e3a955f42dd27c1317a3d/colossalai-nightly-2023.3.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "7fff3aeffabce4eb59362f61411740d71e11f049bc867d2fe95dd81fa8a7b2ea",
        "md5": "81145700aa94bb0284a94af67318e8eb",
        "sha256": "429f7e18ceaaedc1d30c2eb6f0e916fab11fbed020aa9aa59fe08e4447e3c43f"
      },
      "downloads": -1,
      "filename": "colossalai-nightly-2023.3.25.tar.gz",
      "has_sig": false,
      "md5_digest": "81145700aa94bb0284a94af67318e8eb",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 726208,
      "upload_time": "2023-03-25T00:14:07",
      "upload_time_iso_8601": "2023-03-25T00:14:07.582877Z",
      "url": "https://files.pythonhosted.org/packages/7f/ff/3aeffabce4eb59362f61411740d71e11f049bc867d2fe95dd81fa8a7b2ea/colossalai-nightly-2023.3.25.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}