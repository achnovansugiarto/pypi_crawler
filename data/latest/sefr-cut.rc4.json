{
  "info": {
    "author": "mrpeerat",
    "author_email": "peerat.l_s19@vistec.ac.th",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "License :: OSI Approved :: MIT License",
      "Natural Language :: Thai",
      "Topic :: Text Processing :: Linguistic"
    ],
    "description": "# SEFR CUT (Stacked Ensemble Filter and Refine for Word Segmentation) \nDomain Adaptation of Thai Word Segmentation Models using Stacked Ensemble (EMNLP 2020) <br>\nCRF as Stacked Model and DeepCut as Baseline model<br>\n\n## Read more:\n- Paper: [Domain Adaptation of Thai Word Segmentation Models using Stacked Ensemble]()\n- Blog: [Domain Adaptation กับตัวตัดคำ มันดีย์จริงๆ](https://medium.com/@pingloaf)\n\n## Install\n> pip install sefr_cut\n\n## How To use\n### Requirements\n- python >= 3.6\n- python-crfsuite >= 0.9.7\n- pyahocorasick == 1.4.0\n\n## Example\n- Example files are on [SEFR Example notebook](https://github.com/mrpeerat/SEFR_CUT/blob/master/Notebooks/1.SEFR_CUT%20example.ipynb)\n- [Try it on Colab](https://colab.research.google.com/drive/1xA2rzYVnVWwxy6oFkISiG63x-5u1gwa1?usp=sharing)\n### Load Engine & Engine Mode\n- ws1000, tnhc\n  - ws1000: Model trained on Wisesight-1000 and test on Wisesight-160\n  - tnhc: Model trained on TNHC (80:20 train&test split with random seed 42)\n  - BEST: Trained on BEST-2010 Corpus (NECTEC)\n  ```\n  sefr_cut.load_model(engine='ws1000')\n  # OR\n  sefr_cut.load_model(engine='tnhc')\n  # OR\n  sefr_cut.load_model(engine='best')\n  ```\n- tl-deepcut-XXXX\n  - We also provide transfer learning of deepcut on 'Wisesight' as tl-deepcut-ws1000 and 'TNHC' as tl-deepcut-tnhc\n  ```\n  sefr_cut.load_model(engine='tl-deepcut-ws1000')\n  # OR\n  sefr_cut.load_model(engine='tl-deepcut-tnhc')\n  ```\n- deepcut\n  - We also provide the original deepcut\n  ```\n  sefr_cut.load_model(engine='deepcut')\n  ```\n### Segment Example\n- Segment with default k\n  ```\n  sefr_cut.load_model(engine='ws1000')\n  print(sefr_cut.tokenize(['สวัสดีประเทศไทย','ลุงตู่สู้ๆ']))\n  print(sefr_cut.tokenize(['สวัสดีประเทศไทย']))\n  print(sefr_cut.tokenize('สวัสดีประเทศไทย'))\n\n  [['สวัสดี', 'ประเทศ', 'ไทย'], ['ลุง', 'ตู่', 'สู้', 'ๆ']]\n  [['สวัสดี', 'ประเทศ', 'ไทย']]\n  [['สวัสดี', 'ประเทศ', 'ไทย']]\n  ```\n- Segment with different k\n  ```\n  sefr_cut.load_model(engine='ws1000')\n  print(sefr_cut.tokenize(['สวัสดีประเทศไทย','ลุงตู่สู้ๆ'],k=5)) # refine only 5% of character number\n  print(sefr_cut.tokenize(['สวัสดีประเทศไทย','ลุงตู่สู้ๆ'],k=100)) # refine 100% of character number\n\n  [['สวัสดี', 'ประเทศไทย'], ['ลุงตู่', 'สู้', 'ๆ']]\n  [['สวัสดี', 'ประเทศ', 'ไทย'], ['ลุง', 'ตู่', 'สู้', 'ๆ']]\n  ```\n\n## Evaluation\n- Character & Word Evaluation is provided by call fuction ```evaluation()``` \n  - For example\n  ```\n  answer = 'สวัสดี|ประเทศไทย'\n  pred = 'สวัสดี|ประเทศ|ไทย'\n  char_score,word_score = sefr_cut.evaluation(answer,pred)\n  print(f'Word Score: {word_score} Char Score: {char_score}')\n\n  Word Score: 0.4 Char Score: 0.8\n\n  answer = ['สวัสดี|ประเทศไทย']\n  pred = ['สวัสดี|ประเทศ|ไทย']\n  char_score,word_score = sefr_cut.evaluation(answer,pred)\n  print(f'Word Score: {word_score} Char Score: {char_score}')\n\n  Word Score: 0.4 Char Score: 0.8\n\n\n  answer = [['สวัสดี|'],['ประเทศไทย']]\n  pred = [['สวัสดี|'],['ประเทศ|ไทย']]\n  char_score,word_score = sefr_cut.evaluation(answer,pred)\n  print(f'Word Score: {word_score} Char Score: {char_score}')\n\n  Word Score: 0.4 Char Score: 0.8\n  ```\n\n## Performance\n<img src=\"https://user-images.githubusercontent.com/21156980/94525454-4d2e6680-025e-11eb-929f-7bcbb76e92fd.PNG\" width=\"600\" height=\"386\" />\n<img src=\"https://user-images.githubusercontent.com/21156980/94525459-4e5f9380-025e-11eb-9ce6-fd1598b902eb.PNG\" width=\"600\" height=\"386\" />\n<img src=\"https://user-images.githubusercontent.com/21156980/94525741-b9a96580-025e-11eb-81f1-1016e59e25cf.PNG\" width=\"600\" height=\"306\" />\n\n## How to re-train?\n- You can re-train model in folder [Notebooks](https://github.com/mrpeerat/SEFR_CUT/tree/master/Notebooks) We provided everything for you!!\n  ### Re-train Model\n  - You can run the notebook file #2, the corpus inside 'Notebooks/corpus/' is Wisesight-1000, you can try with BEST, TNHC, and LST20 !\n  - Rename variable name ```CRF_model_name``` \n  - Link:[HERE](https://github.com/mrpeerat/SEFR_CUT/blob/master/Notebooks/2.Train_DS_model.ipynb)\n  ### Filter and Refine Example\n  - Set variable name ```CRF_model_name``` same as File#2 \n  - If you want to know why we use filter-and-refine you can try to uncomment 3 lines in ```score_()``` function\n  ```\n  #answer = scoring_function(y_true,cp.deepcopy(y_pred),entropy_index_og)\n  #f1_hypothesis.append(eval_function(y_true,answer))\n  #ax.plot(range(start,K_num,step),f1_hypothesis,c=\"r\",marker='o',label='Best case')\n  ```\n  - Link:[HERE](https://github.com/mrpeerat/SEFR_CUT/blob/master/Notebooks/3.Stacked%20Model%20Example.ipynb)\n  ### Use your own model?\n  - Just move your model inside 'Notebooks/model/' to 'seft_cut/model/' and call model in one line.\n  ```\n  SEFR_CUT.load_model(engine='my_model')\n  ```\n\n## Citation\n- Wait our paper shown in ACL Anthology\n\nThank you many code from\n\n- [Deepcut](https://github.com/rkcosmos/deepcut) (Baseline Model) : We used some of code from Deepcut to perform transfer learning \n- [@bact](https://github.com/bact) (CRF training code) : We used some from https://github.com/bact/nlp-thai in training CRF Model\n\n\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/mrpeerat/SEFR_CUT",
    "keywords": "thai word segmentation,word segmentation,thainlp",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "SEFR-CUT",
    "package_url": "https://pypi.org/project/SEFR-CUT/",
    "platform": "",
    "project_url": "https://pypi.org/project/SEFR-CUT/",
    "project_urls": {
      "Homepage": "https://github.com/mrpeerat/SEFR_CUT"
    },
    "release_url": "https://pypi.org/project/SEFR-CUT/1.1/",
    "requires_dist": [
      "tensorflow (>=2.0.0)",
      "pandas",
      "scipy",
      "numpy",
      "scikit-learn",
      "python-crfsuite",
      "pyahocorasick"
    ],
    "requires_python": "",
    "summary": "Domain Adaptation of Thai Word Segmentation Models using Stacked Ensemble (EMNLP2020)",
    "version": "1.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8342672,
  "releases": {
    "0.1.dev0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8963c48e894593367cc388868ba42308ed308f33ba6e6d4ae72ac96741f2eee3",
          "md5": "004fa7f641de638b606672985c457606",
          "sha256": "a2269277686b6922192db7095c9bbd6aa54838e7dd271f81931e2522d945ae6c"
        },
        "downloads": -1,
        "filename": "SEFR_CUT-0.1.dev0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "004fa7f641de638b606672985c457606",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 8708843,
        "upload_time": "2020-09-28T12:43:25",
        "upload_time_iso_8601": "2020-09-28T12:43:25.915530Z",
        "url": "https://files.pythonhosted.org/packages/89/63/c48e894593367cc388868ba42308ed308f33ba6e6d4ae72ac96741f2eee3/SEFR_CUT-0.1.dev0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7cc77e18c40c25e555f4a6d413727322c5c932fd12c0134931e24a2425754296",
          "md5": "cb4c53c674033f130a93162754dcf1d9",
          "sha256": "3a2b30bfbe0dc07714fb75383e940ae9b0ad70c58a2fd798a083910088aa7e8e"
        },
        "downloads": -1,
        "filename": "SEFR_CUT-0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "cb4c53c674033f130a93162754dcf1d9",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 8709322,
        "upload_time": "2020-09-29T10:38:38",
        "upload_time_iso_8601": "2020-09-29T10:38:38.091415Z",
        "url": "https://files.pythonhosted.org/packages/7c/c7/7e18c40c25e555f4a6d413727322c5c932fd12c0134931e24a2425754296/SEFR_CUT-0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "19e83e2ac21631b063b7fc7f94013e09e64c6a2e6aa20681c8041349e318fb5c",
          "md5": "20322a22e94b96ef63d2a9cde8e6ea20",
          "sha256": "dd66622c7fe3f0056e61cdacc73624edc8ef4607bbd31b820998bfb2195e42fc"
        },
        "downloads": -1,
        "filename": "SEFR_CUT-1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "20322a22e94b96ef63d2a9cde8e6ea20",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 8709403,
        "upload_time": "2020-09-30T08:09:33",
        "upload_time_iso_8601": "2020-09-30T08:09:33.334786Z",
        "url": "https://files.pythonhosted.org/packages/19/e8/3e2ac21631b063b7fc7f94013e09e64c6a2e6aa20681c8041349e318fb5c/SEFR_CUT-1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7b349d8e8e917baebabe350f387b84d1658ac16af19b284bda347373739a3726",
          "md5": "ee6649e5970c1d3c08c07ed607511b3d",
          "sha256": "e811482d5607ab008d71f06c38b1e2a5fe1bceba8b6cf6ea8d7cf6be74864c86"
        },
        "downloads": -1,
        "filename": "SEFR_CUT-1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ee6649e5970c1d3c08c07ed607511b3d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 8709439,
        "upload_time": "2020-10-05T14:56:12",
        "upload_time_iso_8601": "2020-10-05T14:56:12.532416Z",
        "url": "https://files.pythonhosted.org/packages/7b/34/9d8e8e917baebabe350f387b84d1658ac16af19b284bda347373739a3726/SEFR_CUT-1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "7b349d8e8e917baebabe350f387b84d1658ac16af19b284bda347373739a3726",
        "md5": "ee6649e5970c1d3c08c07ed607511b3d",
        "sha256": "e811482d5607ab008d71f06c38b1e2a5fe1bceba8b6cf6ea8d7cf6be74864c86"
      },
      "downloads": -1,
      "filename": "SEFR_CUT-1.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "ee6649e5970c1d3c08c07ed607511b3d",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 8709439,
      "upload_time": "2020-10-05T14:56:12",
      "upload_time_iso_8601": "2020-10-05T14:56:12.532416Z",
      "url": "https://files.pythonhosted.org/packages/7b/34/9d8e8e917baebabe350f387b84d1658ac16af19b284bda347373739a3726/SEFR_CUT-1.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}