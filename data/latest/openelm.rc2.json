{
  "info": {
    "author": "CarperAI",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Environment :: Console",
      "Intended Audience :: Developers",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: MIT License",
      "Natural Language :: English",
      "Operating System :: Unix",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3 :: Only",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.9",
      "Programming Language :: Python :: Implementation :: CPython",
      "Topic :: Scientific/Engineering :: Artificial Intelligence",
      "Typing :: Typed"
    ],
    "description": "[![DOI](https://zenodo.org/badge/532259603.svg)](https://zenodo.org/badge/latestdoi/532259603)\n# OpenELM\n\nThis repository is a replication of [Evolution Through Large Models](https://arxiv.org/abs/2206.08896), a recent paper from OpenAI exploring the links between large language models (LLMs) and evolutionary computing, particularly focused on code generation.\n\nLLMs trained on datasets of code, such as OpenAI’s Codex, have shown good results in automated code generation. However, in cases where we are interested in a class of programs which are rarely found in the training distribution,\nevolutionary algorithms provide a way to generate code by making mutations to known, or \"seed\" programs. The ELM approach shows that an LLM trained on code can suggest intelligent mutations for genetic programming (GP) algorithms. Genetic algorithms explore the search space with random perturbations, but typically need to be highly customised with domain knowledge to allow them to make desirable changes — LLMs provide a way of encoding this domain knowledge and guiding the genetic algorithm towards intelligent exploration of the search space.\n\nThis project aims to replicate the ELM paper in the original [Sodarace](https://doi.org/10.1162/ARTL_a_00185) environment, before applying the technique to more complex code generation problems.\n\nFor more details, see our full research proposal at https://carperai.notion.site/ELM-e8f37b2649944259b1abf9ccaa4edae2. The release blog post: https://carper.ai/openelm-release.\n\n# Architecture\nRoughly, ELM consists of a pipeline of different components:\n```html\n+-------------+                     +-------------+\n|  MapElites  | <-----------------> | Environment |\n+------+------+                     +------+------+\n       |                                   ^\n       | collect samples                   |\n       v                                   v\n+------+---------+     finetune    +-------+--------+    mutate and execute   +----------------+\n| Conditional RL | --------------> | Language model | <---------------------> | Sandbox server |\n+----------------+                 +----------------+                         +----------------+\n```\nThe basic workflow consists of generate -> evaluate -> finetune. We currently have implemented everything except the conditional RL part.\n\n# Running ELM\nCurrently, we can run the MAP-Elites algorithm on [a few environments](https://github.com/CarperAI/OpenELM/blob/main/src/openelm/environments/environments.py), apply [prompt mutations](https://github.com/CarperAI/OpenELM/blob/main/src/openelm/diff_model.py), and connect with an optional [sandbox server](https://github.com/CarperAI/OpenELM/blob/main/src/openelm/sandbox).\n\n## Sandbox\nTo use the code execution sandbox, see the [sandboxing readme](https://github.com/CarperAI/OpenELM/blob/main/src/openelm/sandbox/README.md) for instructions to set it up in a docker container. But for quick testing purpose, one may try the following:\n```bash\ncd elm/sandbox/server\nexport FLASK_APP=index.py\nflask run\n```\n## Running MAP-Elites\nWe have a few toy environments implemented as well as the Sodarace environment in the ELM paper. The `run_elm.py` file gives an example of how to run an ELM loop with MAP-Elites using the Sodarace environment.\n\n## Triton\nWe also have code to run models in Nvidia's Triton Inference Server. See the [Triton Readme](https://github.com/CarperAI/OpenELM/blob/main/src/openelm/codegen/triton_utils/readme.md) to get started\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "OpenELM",
    "package_url": "https://pypi.org/project/OpenELM/",
    "platform": null,
    "project_url": "https://pypi.org/project/OpenELM/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/OpenELM/0.2.1/",
    "requires_dist": [
      "hydra-core (>=1.2.0)",
      "wandb (>=0.13)",
      "numpy",
      "torch (>=1.10)",
      "transformers (>=4.22.0)",
      "tokenizers",
      "swig (>=4.1.0)",
      "box2d-py (==2.3.8)",
      "requests",
      "Flask",
      "pygraphviz ; extra == 'benchmarks'",
      "graphviz ; extra == 'benchmarks'",
      "openai ; extra == 'benchmarks'",
      "black ; extra == 'dev'",
      "isort ; extra == 'dev'",
      "flake8 ; extra == 'dev'",
      "flake8-pyproject ; extra == 'dev'",
      "pydocstyle ; extra == 'dev'",
      "mypy ; extra == 'dev'",
      "pre-commit ; extra == 'dev'",
      "pytest ; extra == 'dev'",
      "pytest-cov ; extra == 'dev'",
      "sphinx (==5.3.0) ; extra == 'docs'",
      "sphinx-rtd-theme ; extra == 'docs'",
      "sphinx-autodoc-typehints ; extra == 'docs'",
      "ipython ; extra == 'notebook'",
      "tritonclient[all] ; extra == 'triton'",
      "instruct-goose ; extra == 'trlx'"
    ],
    "requires_python": ">=3.9",
    "summary": "Evolution Through Large Models",
    "version": "0.2.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17200542,
  "releases": {
    "0.1.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "93faa8910f444f1630118d009ecc0a88fd15e1f70d08c43b9a2167e24f2287ed",
          "md5": "a5e79c69354f93558fbd74715c406d70",
          "sha256": "924daa660ef40c5d7eb8abeac995509ff58efa52449062393c1c90e39ccec4be"
        },
        "downloads": -1,
        "filename": "OpenELM-0.1.7-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "a5e79c69354f93558fbd74715c406d70",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.9",
        "size": 95242,
        "upload_time": "2022-12-25T22:07:27",
        "upload_time_iso_8601": "2022-12-25T22:07:27.968627Z",
        "url": "https://files.pythonhosted.org/packages/93/fa/a8910f444f1630118d009ecc0a88fd15e1f70d08c43b9a2167e24f2287ed/OpenELM-0.1.7-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8490f10b34c912986227b2df8b71207bcae978afe3a95c7c9e7d3e8b5a02f290",
          "md5": "530e11f2d55fa30c62cef23d5bf93747",
          "sha256": "e43283aa22e4d067845012ca8548678d3aa40cad9e76424fe8a11533caab3bf7"
        },
        "downloads": -1,
        "filename": "OpenELM-0.1.7.tar.gz",
        "has_sig": false,
        "md5_digest": "530e11f2d55fa30c62cef23d5bf93747",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.9",
        "size": 106426,
        "upload_time": "2022-12-25T22:07:30",
        "upload_time_iso_8601": "2022-12-25T22:07:30.107563Z",
        "url": "https://files.pythonhosted.org/packages/84/90/f10b34c912986227b2df8b71207bcae978afe3a95c7c9e7d3e8b5a02f290/OpenELM-0.1.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "78f9d6a47bcbb9efda6c9f7113f54713198fed1825355b80c466a2a493119449",
          "md5": "38a4bfa8ea726f4867adcc1cd4fdf2b5",
          "sha256": "2637b91e738c5034b24cd1d30d555ce8a7f12fc3be9cfe683485f4d6c278eb69"
        },
        "downloads": -1,
        "filename": "OpenELM-0.2.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "38a4bfa8ea726f4867adcc1cd4fdf2b5",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.9",
        "size": 105104,
        "upload_time": "2023-03-08T01:49:57",
        "upload_time_iso_8601": "2023-03-08T01:49:57.822088Z",
        "url": "https://files.pythonhosted.org/packages/78/f9/d6a47bcbb9efda6c9f7113f54713198fed1825355b80c466a2a493119449/OpenELM-0.2.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "84ecde59e27e3dc61226b816d6246769ffbf02812abe4ebcdfecce8c43f601fc",
          "md5": "7f1709b949b6c5a7a1f7bbf44c543690",
          "sha256": "91eeec6d6ecf34a1d8074202cc6fe4ad8286c60621059a1579d6a214b7639c55"
        },
        "downloads": -1,
        "filename": "OpenELM-0.2.1.tar.gz",
        "has_sig": false,
        "md5_digest": "7f1709b949b6c5a7a1f7bbf44c543690",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.9",
        "size": 117044,
        "upload_time": "2023-03-08T01:49:59",
        "upload_time_iso_8601": "2023-03-08T01:49:59.620646Z",
        "url": "https://files.pythonhosted.org/packages/84/ec/de59e27e3dc61226b816d6246769ffbf02812abe4ebcdfecce8c43f601fc/OpenELM-0.2.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "78f9d6a47bcbb9efda6c9f7113f54713198fed1825355b80c466a2a493119449",
        "md5": "38a4bfa8ea726f4867adcc1cd4fdf2b5",
        "sha256": "2637b91e738c5034b24cd1d30d555ce8a7f12fc3be9cfe683485f4d6c278eb69"
      },
      "downloads": -1,
      "filename": "OpenELM-0.2.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "38a4bfa8ea726f4867adcc1cd4fdf2b5",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.9",
      "size": 105104,
      "upload_time": "2023-03-08T01:49:57",
      "upload_time_iso_8601": "2023-03-08T01:49:57.822088Z",
      "url": "https://files.pythonhosted.org/packages/78/f9/d6a47bcbb9efda6c9f7113f54713198fed1825355b80c466a2a493119449/OpenELM-0.2.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "84ecde59e27e3dc61226b816d6246769ffbf02812abe4ebcdfecce8c43f601fc",
        "md5": "7f1709b949b6c5a7a1f7bbf44c543690",
        "sha256": "91eeec6d6ecf34a1d8074202cc6fe4ad8286c60621059a1579d6a214b7639c55"
      },
      "downloads": -1,
      "filename": "OpenELM-0.2.1.tar.gz",
      "has_sig": false,
      "md5_digest": "7f1709b949b6c5a7a1f7bbf44c543690",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.9",
      "size": 117044,
      "upload_time": "2023-03-08T01:49:59",
      "upload_time_iso_8601": "2023-03-08T01:49:59.620646Z",
      "url": "https://files.pythonhosted.org/packages/84/ec/de59e27e3dc61226b816d6246769ffbf02812abe4ebcdfecce8c43f601fc/OpenELM-0.2.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}