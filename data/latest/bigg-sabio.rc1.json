{
  "info": {
    "author": "Andrew Freiburger, Ethan Chan",
    "author_email": "andrewfreiburger@gmail.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "Acquire SABIO-RK Kinetics Data for an arbitrary BiGG model\n-------------------------------------------------------------------------\n\n|License|\n\n.. |PyPI version| image:: https://img.shields.io/pypi/v/bigg_sabio.svg?logo=PyPI&logoColor=brightgreen\n   :target: https://pypi.org/project/bigg_sabio/\n   :alt: PyPI version\n\n.. |Actions Status| image:: https://github.com/freiburgermsu/bigg_sabio/workflows/Test%20bigg_sabio/badge.svg\n   :target: https://github.com/freiburgermsu/bigg_sabio/actions\n   :alt: Actions Status\n\n.. |License| image:: https://img.shields.io/badge/License-MIT-blue.svg\n   :target: https://opensource.org/licenses/MIT\n   :alt: License\n\n.. |Downloads| image:: https://pepy.tech/badge/bigg_sabio\n   :target: https://pepy.tech/project/bigg_sabio\n   :alt: Downloads\n\n\nReaction kinetics data is a pillar of biochemical research, and particularly computational biology. Sources of this data, however, are infrequently accessible to programmatic workflows, such as Dynamic Flux Balance Analysis (dFBA), which hinders research progress. The ``BiGG_SABIO`` library attempts to bridge this gab by scraping `SABIO-RK <http://sabio.h-its.org/>`_ kinetics data from any BiGG model-formatted JSON file, which is a powerful ability metabolic and dFBA researchers. SABIO-RK supports this use of this website in its `statement of webservices <http://sabio.h-its.org/layouts/content/webservices.gsp>`_. Examples Notebook are available in the examples directory of the `BiGG_SABIO GitHub repository <https://github.com/freiburgermsu/BiGG_SABIO/examples>`_. Please submit errors, inquiries, or suggestions as `GitHub issues <https://github.com/freiburgermsu/BiGG_SABIO/issues>`_ where they can be addressed.\n\n\n____________\n\n\n----------------------\nInstallation\n----------------------\n\n``BiGG_SABIO`` is installed in a command prompt, Powershell, Terminal, or Anaconda Command Prompt via ``pip``::\n\n pip install bigg_sabio\n\n---------------\n__init__()\n---------------\n\nThe scraping is initiated through four arguments:\n\n.. code-block:: python\n\n import bigg_sabio\n bgsb = bigg_sabio.SABIO_scraping(bigg_model_path, bigg_model_name = None, export_model_content = False, verbose = False)\n\n- *bigg_model_path* ``str``: specifies the path to the JSON file of the BiGG model that will be parsed.\n- *bigg_model_name* ``str``: specifies the name of the BiGG model, which will be used to identify the model and name the output folder directory, where ``None`` defaults the name of the file from the ``bigg_model_path`` parameter.\n- *export_model_content* ``bool``: specifies where parsed information about the BiGG model will be  of the SBML file for the `BiGG model <http://bigg.ucsd.edu/>`_ that will be simulated. \n- *verbose* & *printing* ``bool``: specifies whether simulation details (which is valuable for trobuleshooting) and results, respectively, will be printed. \n\n-------------------\ncomplete()\n-------------------\n\nThe complete scraping process is concisely conducted through a single function, which references the object variables that are defined through the ``__init__()`` function:\n\n.. code-block:: python\n\n import bigg_sabio\n bgsb = bigg_sabio.SABIO_scraping(bigg_model_path, bigg_model_name = None, export_model_content = False, verbose = False)\n bgsb.complete()\n\n\n____________\n\nIndividual functions\n-------------------------------------------------------------------------\nThe steps of acquiring and processing SABIO data into input files of kinetic data for dFBA simulations can be individual executed on demand. These steps and functions are detailed in the following sections.\n\n\n-------------------\nscrape_bigg_xls()\n-------------------\n\nThis function is the first step in BiGG_SABIO workflow, where a Selenium WebDriver is directed through the advanced search options of SABIO and proceeds to download all of the search results that match annotations from the BiGG model. These numerous XLS files, at the end of the scraping process, are concatenated into a spreadsheet with the duplicate rows are removed to yield a complete CSV file of the SABIO kinetics data for the respective BiGG model. The identities and values for each parameter are subsequently scraped, and assembled and downloaded as a separate JSON file.\n\n \n-------------------\nto_fba()\n-------------------\n\nThis is the final step in BiGG_SABIO workflow, where the complete assemblage of SABIO kinetics data is refined into a structure that is amenable with the `dFBAy <https://github.com/freiburgermsu/dFBApy>`_ module. \n\n\n--------------------------------------\nExecuting the individual functions\n--------------------------------------\nThe individual functions can be executed through the following sequence:\n\n.. code-block:: python\n\n import bigg_sabio\n bgsb = bigg_sabio.SABIO_scraping(bigg_model_path, bigg_model_name = None, export_model_content = False, verbose = False)\n bgsb.scrape_bigg_xls()\n bgsb.to_fba()\n\n\n____________\n\n\nAccessible content\n______________________\n\nA multitude of values are stored within the ``SABIO_scraping`` object that can be subsequently referenced and used in a workflow. The complete list of content within the ``SABIO_scraping`` object can be printed through the built-in ``dir()`` function:\n\n.. code-block:: python\n\n # Scrape data for a BiGG model\n from bigg_sabio import SABIO_scraping\n bgsb = SABIO_scraping(bigg_model_path, bigg_model_name = None, export_model_content = False, verbose = False) \n print(dir(bgsb))\n\nThe following list highlights stored content in the ``SABIO_scraping`` object after a simulation:\n\n- *model* & *model_contents* ``dict``: The loaded BiGG model and a parsed form of the model, respectively, that are interpreted and guide the scraping of reaction enzymes.\n- *sabio_df* ``Pandas.DataFrame``: A concatenated DataFrame that embodies all of the downloaded XLS files from the model enzymes.\n- *paths*, *parameters*, & *variables* ``dict``: Dictionaries of 1) the essential paths from the scraping, which may be useful to locate and programmatically access each file; 2) important parameters that were parameterized; and 3) the variable values or files that derived from the scraping, respectively.\n- *bigg_to_sabio_metabolites*, *sabio_to_bigg_metabolites*, & *bigg_reactions* ``dict``: Comprehensive dictionaries for the ID codes of BiGG metabolites and reactions, respectively. The ``bigg_to_sabio_metabolites`` dictionary is indexed with keys of BiGG ID and values of metabolite names that are recognized by SABIO and BiGG, whereas the ``bigg_to_sabio_metabolites`` dictionary is indexed with keys of SABIO metabolite names and values of the corresponding BiGG IDs.\n- *driver* & *fp* ``Selenium.Webdriver``: The Firefox browser driver and profile, respectively, that are used programmatically by `Selenium functions <https://selenium-python.readthedocs.io/api.html>`_ to access and navigate the SABIO-RK database website.\n- *step_number* ``int``: An indication of the progression within the scraping workflow, which is enumerated in the ``main()`` function of the script.",
    "description_content_type": "",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/freiburgermsu/BiGG_SABIO",
    "keywords": "dFBA,FBA,BiGG,biochemistry,scraping,metabolism,SABIO,SABIO-RK,kinetics,bioinformatics",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "BiGG-SABIO",
    "package_url": "https://pypi.org/project/BiGG-SABIO/",
    "platform": "",
    "project_url": "https://pypi.org/project/BiGG-SABIO/",
    "project_urls": {
      "Homepage": "https://github.com/freiburgermsu/BiGG_SABIO"
    },
    "release_url": "https://pypi.org/project/BiGG-SABIO/0.0.1/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "Scrapes SABIO-RK for enzyme kinetics data for given BiGG Model for dFBA simulation.",
    "version": "0.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12978359,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7a5f84840aaab9759899a218a3f1df9667b4a6aff02906878725ea1c3cd5da48",
          "md5": "f551f427b949040efc142d19f908b1fd",
          "sha256": "3722f9178d05cb534b665bbc4b18e38715d9e39aa67020a8e35402fde895b2ae"
        },
        "downloads": -1,
        "filename": "BiGG_SABIO-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "f551f427b949040efc142d19f908b1fd",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 2453077,
        "upload_time": "2022-02-23T02:17:15",
        "upload_time_iso_8601": "2022-02-23T02:17:15.930761Z",
        "url": "https://files.pythonhosted.org/packages/7a/5f/84840aaab9759899a218a3f1df9667b4a6aff02906878725ea1c3cd5da48/BiGG_SABIO-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "7a5f84840aaab9759899a218a3f1df9667b4a6aff02906878725ea1c3cd5da48",
        "md5": "f551f427b949040efc142d19f908b1fd",
        "sha256": "3722f9178d05cb534b665bbc4b18e38715d9e39aa67020a8e35402fde895b2ae"
      },
      "downloads": -1,
      "filename": "BiGG_SABIO-0.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "f551f427b949040efc142d19f908b1fd",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 2453077,
      "upload_time": "2022-02-23T02:17:15",
      "upload_time_iso_8601": "2022-02-23T02:17:15.930761Z",
      "url": "https://files.pythonhosted.org/packages/7a/5f/84840aaab9759899a218a3f1df9667b4a6aff02906878725ea1c3cd5da48/BiGG_SABIO-0.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}