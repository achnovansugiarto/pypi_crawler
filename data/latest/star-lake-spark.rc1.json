{
  "info": {
    "author": "EnginePlus Team",
    "author_email": "kehan.cao@mobvista.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "[CN Doc](README-CN.md)\n\n# Star Lake\nStar Lake is a data lake storage solution built on top of the Apache Spark engine by the EnginePlus team, that supports scalable metadata management, ACID transactions, efficient and flexible upsert operation, schema evolution, and streaming & batch unification.\n\nStar Lake specializes in row and column level incremental upserts, high concurrent write, and bulk scan for data on cloud storage. The cloud native computing and storage separation architecture makes deployment very simple, while supporting huge amounts of data at lower cost.  \nTo be specific, Star Lake has the following characteristics:\n  - Elastic framework: The computing and storage is completely separated. Without the need for fixed nodes and disks, the computing and storage has its own elastic capacity, and a lot of optimization for the cloud storage has done, like concurrency consistency in the object storage, incremental update and etc. With Star Lake, there is no need to maintain fixed storage nodes, and the cost of object storage on cloud is only 1/10 of local disk, which greatly reduces storage and operation costs.\n  - Efficient and scalable metadata management: Star Lake uses Cassandra to manage metadata, which can efficiently handle modification on metadata and support multiple concurrent writes. It solves the problem of slow metadata parsing after long running in data Lake systems such as Delta Lake which use files to maintain metadata, and can only be written at a single point.\n  - ACID transactions: Undo and Redo mechanism ensures that the committing are transactional and users will never see inconsistent data. \n  - Multi-level partitioning and efficient upsert: Star Lake supports range and hash partitioning, and a flexible upsert operation at row and column level. The upsert data are stored as delta files, which greatly improves the efficiency and concurrency of writing data, and the optimized merge scan provides efficient MergeOnRead performance.\n  - Streaming and batch unification: Streaming Sink is supported in Star Lake, which can handle streaming data ingesting, historical data filling in batch, interactive query and other scenarios simultaneously.\n  - Schema evolution: Users can add new fields at any time and quickly populate the new fields with historical data.\n\n\nScenario of Star Lake:\n  - Incremental data need to be written efficiently in large batches in real time, as well as concurrent updates at the row or column level.\n  - Detailed query and update on a large time range with huge amount historical data, while hoping to maintain a low cost\n  - The query is not fixed, and the resource consumption changes greatly, which is expected that the computing resources can be flexible and scalable independently\n  - High concurrent writes are required, and metadata is too large for Delta Lake to meet performance requirements.\n  - For data updates to primary keys, Hudi's MergeOnRead does not meet update performance requirements.\n\n\n\n# Comparison of Data Lake Solutions\n|   | Delta Lake | Hudi | Iceberg | Star Lake |\n| ----- | :----- | :----- | :----- | :----- | \n| Table Mode | CopyOnWrite | CopyOnWrite and MergeOnRead | only delete supports MergeOnRead | **CopyOnWrite and MergeOnRead** |\n| Metadata Store | meta files on table path | meta files on table path | meta files on table path | **Cassandra** |\n| Metadata Scalability | low | low | low | **high** |\n| Read | partition pruning by meta files | partition pruning by meta files | metadata is richer and supports fine-grained pruning at file level | **partition pruning by meta data** |\n| Concurrent Write | support | only support one writer, optimistic concurrency is still in the experimental stage | support | **support, the unique upsert mechanism turns updates into append, greatly improved concurrent write performance** |\n| Streaming and Batch Unification | support | don't support concurrent write | support | **support** |\n| Row Level Upsert | overwrite row-related files | support MergeOnRead, will be compacted at next snapshot | overwrite row-related files | **support MergeOnRead, only write the data to be updated** |\n| Column Level upsert | overwrite all files in partition | support MergeOnRead, will overwrite all files in the partition at next snapshot | overwrite all files in partition | **support MergeOnRead, can last any time until user executes compaction, and optimized merge scan provides efficient read performance** |\n| Bucket Join | nonsupport | nonsupport | nonsupport, bucket rules can be specified in partitioning spec, but there is no implementation yet | **support** |\n\n\n# Performance Comparison Between Star Lake and Iceberg\nIn above data Lake solutions, Delta Lake open source version exists to feed commercial version, and the community is inactive. Hudi focuses on the streaming scenario, and does not support concurrent write, as a data lake solution, its application scenario is too narrow. Iceberg, with its elegant abstract design and active community, as well as more and more new features as the version is updated, is one of the best data lake solution at present, so we choose Iceberg to compare performance.\n\n![performance comparison](doc/performance_comparison.png)\n\n# Maven\nStar Lake is only available with Scala version 2.12.\n\n```xml\n<dependency>\n    <groupId>com.engineplus</groupId>\n    <artifactId>star-lake</artifactId>\n    <version>1.0.0</version>\n</dependency>\n```\n\n# Usage\n\n## 1. Create and Write StarTable\n\n### 1.1 Table Name\n\nThe table name in Star Lake is a path, and the path where the data is stored is the table name.\n\nWhen Dataframe.write(or writeStream) is called to write data to StarTable, a new table will automatically created using the storage path if the table does not exist.\n\n\n### 1.2 Metadata Management\nStar Lake manages metadata through cassandra, so it can process metadata efficiently, and the meta cluster can be easily scaled up in the cloud.\n\nYou need to specify the cassandra cluster address when you use Star Lake, which can be configured in spark environment or can be specified when submitting job.\n\n\n### 1.3 Partition\nStarTable can be partitioned in two ways, range and hash, and they can be used at the same time.\n  - Range partition is a common time-based table partition. Data files of different partitions are stored in different partition paths.\n  - To use a hash partition, you must specify both the hash primary key fields and the hash bucket num. The hash bucket num is used to hash the hash primary key fields.\n  - If you specify both range partition and hash partition, each range partition will have the same hash key written to file with the same bucket id.\n  - When partitioning is specified, data written to StarTable must contain partitioning fields.\n\nDepending on the specific scenario, you can choose to use a range partition, a hash partition, or both. When a hash partition is specified, the data in StarTable will be unique by the primary key, which is the hash partition field + range partition field (if any).\n\nWhen a hash partition is specified, StarTable supports upsert operations, where writing to data in APPEND mode is disabled, and the `starTable.upsert()` method can be used instead.\n\n### 1.4 Code Examples\n```scala\nimport org.apache.spark.sql._\nval spark = SparkSession.builder.master(\"local\")\n  //cassandra host\n  .config(\"spark.engineplus.star.meta.host\", \"cassandra_host\")\n  .config(\"spark.sql.extensions\", \"com.engineplus.star.sql.StarSparkSessionExtension\")\n  .getOrCreate()\nimport spark.implicits._\n\nval df = Seq((\"2021-01-01\",1,\"rice\"),(\"2021-01-01\",2,\"bread\")).toDF(\"date\",\"id\",\"name\")\nval tablePath = \"s3a://bucket-name/table/path/is/also/table/name\"\n\n//create table\n//spark batch\ndf.write\n  .mode(\"append\")\n  .format(\"star\")\n  .option(\"rangePartitions\",\"date\")\n  .option(\"hashPartitions\",\"id\")\n  .option(\"hashBucketNum\",\"2\")\n  .save(tablePath)\n//spark streaming\nimport org.apache.spark.sql.streaming.Trigger\nval readStream = spark.readStream.parquet(\"inputPath\")\nval writeStream = readStream.writeStream\n  .outputMode(\"append\")\n  .trigger(Trigger.ProcessingTime(\"1 minutes\"))\n  .format(\"star\")\n  .option(\"rangePartitions\",\"date\")\n  .option(\"hashPartitions\",\"id\")\n  .option(\"hashBucketNum\", \"2\")\n  .option(\"checkpointLocation\", \"s3a://bucket-name/checkpoint/path\")\n  .start(tablePath)\nwriteStream.awaitTermination()\n\n//for existing table, it no longer need to specify partition information when writing data\n//equivalent to INSERT OVERWRITE PARTITION, if you do not specify option replaceWhere, the entire table will be overwritten\ndf.write\n  .mode(\"overwrite\")\n  .format(\"star\")\n  .option(\"replaceWhere\",\"date='2021-01-01'\")\n  .save(tablePath)\n\n```\n\n## 2. Read StarTable\nYou can read data by Spark API or building StarTable, Spark SQL is also supported, see [8. Operate StarTable by Spark SQL](#8-operate-startable-by-spark-sql)\n\n### 2.1 Code Examples\n```scala\nimport org.apache.spark.sql._\nval spark = SparkSession.builder.master(\"local\")\n  .config(\"spark.engineplus.star.meta.host\", \"cassandra_host\")\n  .config(\"spark.sql.extensions\", \"com.engineplus.star.sql.StarSparkSessionExtension\")\n  .getOrCreate()\nval tablePath = \"s3a://bucket-name/table/path/is/also/table/name\"\n\n//by spark api\nval df1 = spark.read.format(\"star\").load(tablePath)\n\n//by StarTable\nimport com.engineplus.star.tables.StarTable\nval df2 = StarTable.forPath(tablePath).toDF\n\n```\n\n## 3. Upsert StarTable\n\n### 3.1 Batch\nUpsert is supported when hash partitioning has been specified.\n\nMergeOnRead is used by default, upsert data is written as delta files. Star Lake provides efficient upsert and merge scan performance.\n\nParameter `spark.engineplus.star.deltaFile.enabled` can be set to `false` to use CopyOnWrite mode, eventually merged data will be generated after upsert, but this mode is not recommended, because it has poor performance and low concurrent.\n\n#### 3.1.1 Code Examples\n```scala\nimport com.engineplus.star.tables.StarTable\nimport org.apache.spark.sql._\nval spark = SparkSession.builder.master(\"local\")\n  .config(\"spark.engineplus.star.meta.host\", \"cassandra_host\")\n  .config(\"spark.sql.extensions\", \"com.engineplus.star.sql.StarSparkSessionExtension\")\n  .getOrCreate()\nimport spark.implicits._\n\nval tablePath = \"s3a://bucket-name/table/path/is/also/table/name\"\n\nval starTable = StarTable.forPath(tablePath)\nval extraDF = Seq((\"2021-01-01\",3,\"chicken\")).toDF(\"date\",\"id\",\"name\")\n\nstarTable.upsert(extraDF)\n```\n\n### 3.2 Streaming Support\nIn streaming, when outputMode is complete, each write will overwrite all previous data.\n  \nWhen outputMode is append or update, if hash partition is specified, each write is treated as an upsert, if data with the same primary key exists at read time, the latest value of the same key overrides the previous one. Update mode is available only if hash partition is specified.  \nDuplicate data is allowed if no hash partitioning is used. \n\n## 4. Update StarTable\nStar Lake supports update operations, which are performed by specifying the condition and the field Expression that needs to be updated. There are several ways to perform update, see annotations in `com.engineplus.star.tables.StarTable`.\n\n### 4.1 Code Examples\n```scala\nimport com.engineplus.star.tables.StarTable\nimport org.apache.spark.sql._\nval spark = SparkSession.builder.master(\"local\")\n  .config(\"spark.engineplus.star.meta.host\", \"cassandra_host\")\n  .config(\"spark.sql.extensions\", \"com.engineplus.star.sql.StarSparkSessionExtension\")\n  .getOrCreate()\n\nval tablePath = \"s3a://bucket-name/table/path/is/also/table/name\"\nval starTable = StarTable.forPath(tablePath)\nimport org.apache.spark.sql.functions._\n\n//update(condition, set)\nstarTable.update(col(\"date\") > \"2021-01-01\", Map(\"data\" -> lit(\"2021-01-02\")))\n\n```\n\n## 5. Delete Data\nStar Lake supports delete operation to delete data that meet the conditions. Conditions can be any field, and if no condition is specified, all data in table will be deleted.\n\n### 5.1 Code Examples\n```scala\nimport com.engineplus.star.tables.StarTable\nimport org.apache.spark.sql._\nval spark = SparkSession.builder.master(\"local\")\n  .config(\"spark.engineplus.star.meta.host\", \"cassandra_host\")\n  .config(\"spark.sql.extensions\", \"com.engineplus.star.sql.StarSparkSessionExtension\")\n  .getOrCreate()\n\nval tablePath = \"s3a://bucket-name/table/path/is/also/table/name\"\nval starTable = StarTable.forPath(tablePath)\n\n//delete data that meet the condition\nstarTable.delete(\"date='2021-01-01'\")\n//delete full table data\nstarTable.delete()\n```\n\n## 6. Compaction\nUpsert will generates delta files, which can affect read efficiency when delta files num become too large, in this time, compaction can be performed to merge files.\n\nWhen compaction is performed to the full table, you can set conditions for compaction, only range partitions that meet the conditions will perform compaction.\n\nConditions to trigger compaction:\n1. The last modification time for a range partition is before `spark.engineplus.star.compaction.interval` (ms), default is 12 hours\n2. Delta file num exceeds `spark.engineplus.star.deltaFile.max.num`, default is 5\n\n### 6.1 Code Examples\n```scala\nimport com.engineplus.star.tables.StarTable\nimport org.apache.spark.sql._\nval spark = SparkSession.builder.master(\"local\")\n  .config(\"spark.engineplus.star.meta.host\", \"cassandra_host\")\n  .config(\"spark.sql.extensions\", \"com.engineplus.star.sql.StarSparkSessionExtension\")\n  .getOrCreate()\n\nval tablePath = \"s3a://bucket-name/table/path/is/also/table/name\"\nval starTable = StarTable.forPath(tablePath)\n\n//compaction on the specified partition\nstarTable.compaction(\"date='2021-01-01'\")\n//compAction on all partitions of the table\nstarTable.compaction()\n//compaction on all partitions, but only partitions meet the conditions will be performed\nstarTable.compaction(false)\n\n```\n\n## 7. Cleanup\nCleanup operation is used to clean useless data files and meta information in StarTable.\n\nOperations like update, delete, upsert, compaction are not actually delete the data files on the storage, if you want to cleanup the useless data, you can perform a Cleanup operation.\n\nBy default, Cleanup operation will clean up the data which last modified time before 5 hours, you can set `spark.engineplus.star.cleanup.interval` to modify it.\n\nParameter `spark.engineplus.star.cleanup.parallelism` is used to control the parallelism when listing files, default value is 50. If the table has to much partitions and files, you can appropriate adjust it.\n\n### 7.1 Code Examples\n```scala\nimport com.engineplus.star.tables.StarTable\nimport org.apache.spark.sql._\nval spark = SparkSession.builder.master(\"local\")\n  .config(\"spark.engineplus.star.meta.host\", \"cassandra_host\")\n  .config(\"spark.sql.extensions\", \"com.engineplus.star.sql.StarSparkSessionExtension\")\n  .getOrCreate()\n\nval tablePath = \"s3a://bucket-name/table/path/is/also/table/name\"\nval starTable = StarTable.forPath(tablePath)\n\nstarTable.cleanup()\n```\n\n## 8. Operate StarTable by Spark SQL \nSpark SQL is supported to read and write StarTable. To use it, you need to set `spark.sql.catalog.spark_catalog` to `org.apache.spark.sql.star.catalog.StarLakeCatalog`.\n\nNote:\n  - Insert into statement turns `autoMerge` on by default\n  - Spark SQL does not support to set hash partition while creating a StarTable\n  - Cannot perform INSERT INTO on a hash partitioned table, use `starTable.upsert()` instead\n  - Some Spark SQL statements are not supported, see `org.apache.spark.sql.star.rules.StarLakeUnsupportedOperationsCheck`\n\n### 8.1 Code Examples\n```scala\nimport com.engineplus.star.tables.StarTable\nimport org.apache.spark.sql._\nval spark = SparkSession.builder.master(\"local\")\n  .config(\"spark.engineplus.star.meta.host\", \"cassandra_host\")\n  .config(\"spark.sql.extensions\", \"com.engineplus.star.sql.StarSparkSessionExtension\")\n  .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.star.catalog.StarLakeCatalog\")\n  .getOrCreate()\n\nval tablePath = \"s3a://bucket-name/table/path/is/also/table/name\"\nspark.range(10).createOrReplaceTempView(\"tmpView\")\n\n//write\nspark.sql(s\"insert overwrite table star.`$tablePath` partition (date='2021-01-01') select id from tmpView\") \n//INSERT INTO cannot be used on a hash partitioned table, use `starTable.upsert()` instead\nspark.sql(s\"insert into star.`$tablePath` select * from tmpView\")\n\n//read\nspark.sql(s\"select * from star.`$tablePath`\").show()\n\n```\n\n## 9. Operator on Hash Primary Keys\nWhen hash partition is specified, the data in each range partition is partitioned according to the hash primary key and the partitioned data is ordered. Therefore, there is no need to do shuffle and sort when some operators perform on hash primary key.\n\nStar Lake currently supports optimization of join, intersect, and except, and more operators will be supported in the future.\n\n### 9.1 Join on Hash Keys\nScenarios:\n  - Shuffle and sort are not required when data from different partitions of the same table is joined on the hash keys\n  - If two different tables have the same hash field type and number of fields, and the same hash bucket num, there is no need to shuffle and sort when they are joined  on the hash keys\n\nThe test result shows that the efficiency of optimized join is 2.5 times that of Iceberg.\n\n### 9.2 Intersect/Except on Hash Keys\nScenarios:\n  - Intersect/Except on hash keys for different partitions of the same table does not require shuffle, sort, and distinct\n  - Intersect/Except on hash keys for different tables that have the same type and number of hash keys, and the same hash bucket num, there is no need to shuffle, sort, and distinct \n\nIn a range partition, the hash primary keys are unique, so the results of intersect or except are not repeated, so the subsequent operations do not need to deduplicate again. For example, you can directly `count` the number of data, without the need for `count distinc`.\n\nThe test result shows that the efficiency of optimized intersect and except is 3.9 times and 3.6 times that of Iceberg respectively.\n\n### 9.3 Code Examples\n```scala\nimport org.apache.spark.sql._\nval spark = SparkSession.builder.master(\"local\")\n  .config(\"spark.engineplus.star.meta.host\", \"cassandra_host\")\n  .config(\"spark.sql.extensions\", \"com.engineplus.star.sql.StarSparkSessionExtension\")\n  .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.star.catalog.StarLakeCatalog\")\n  .getOrCreate()\nimport spark.implicits._\n\n\nval df1 = Seq((\"2021-01-01\",1,1,\"rice\"),(\"2021-01-02\",2,2,\"bread\")).toDF(\"date\",\"id1\",\"id2\",\"name\")\nval df2 = Seq((\"2021-01-01\",1,1,2.7),(\"2021-01-02\",2,2,1.3)).toDF(\"date\",\"id3\",\"id4\",\"price\")\n\nval tablePath1 = \"s3a://bucket-name/table/path/is/also/table/name/1\"\nval tablePath2 = \"s3a://bucket-name/table/path/is/also/table/name/2\"\n\ndf1.write\n  .mode(\"append\")\n  .format(\"star\")\n  .option(\"rangePartitions\",\"date\")\n  .option(\"hashPartitions\",\"id1,id2\")\n  .option(\"hashBucketNum\",\"2\")\n  .save(tablePath1)\ndf2.write\n  .mode(\"append\")\n  .format(\"star\")\n  .option(\"rangePartitions\",\"date\")\n  .option(\"hashPartitions\",\"id3,id4\")\n  .option(\"hashBucketNum\",\"2\")\n  .save(tablePath2)\n\n\n//join on hash keys without shuffle and sort\n//different range partitions for the same table\nspark.sql(\n  s\"\"\"\n    |select t1.*,t2.* from\n    | (select * from star.`$tablePath1` where date='2021-01-01') t1\n    | join \n    | (select * from star.`$tablePath1` where date='2021-01-02') t2\n    | on t1.id1=t2.id1 and t1.id2=t2.id2\n  \"\"\".stripMargin)\n    .show()\n//different tables with the same hash setting\nspark.sql(\n  s\"\"\"\n    |select t1.*,t2.* from\n    | (select * from star.`$tablePath1` where date='2021-01-01') t1\n    | join \n    | (select * from star.`$tablePath2` where date='2021-01-01') t2\n    | on t1.id1=t2.id3 and t1.id2=t2.id4\n  \"\"\".stripMargin)\n  .show()\n\n//intersect/except on hash keys without shuffle,sort and distinct\n//different range partitions for the same table\nspark.sql(\n  s\"\"\"\n    |select count(1) from \n    | (select id1,id2 from star.`$tablePath1` where date='2021-01-01'\n    |  intersect\n    | select id1,id2 from star.`$tablePath1` where date='2021-01-02') t\n  \"\"\".stripMargin)\n  .show()\n//different tables with the same hash setting\nspark.sql(\n  s\"\"\"\n    |select count(1) from \n    | (select id1,id2 from star.`$tablePath1` where date='2021-01-01'\n    |  intersect\n    | select id3,id4 from star.`$tablePath2` where date='2021-01-01') t\n  \"\"\".stripMargin)\n  .show()\n\n```\n\n## 10. Schema Evolution\nStar Lake supports Schema Evolution, new columns allowed to be added (partitioning fields cannot be modified). When a new column is added and the existing data is read, the new column will be NULL. You can fill the new columns by upsert operation.\n\n### 10.1 Merge Schema\nSpecify `mergeSchema` to `true` or enable `autoMerge` to merge the schema when writing data. The new schema is the union of table schema and the current written data schema.\n\n### 10.2 Code Examples\n```scala\ndf.write\n  .mode(\"append\")\n  .format(\"star\")\n  .option(\"rangePartitions\",\"date\")\n  .option(\"hashPartitions\",\"id\")\n  .option(\"hashBucketNum\",\"2\")\n  //first way\n  .option(\"mergeSchema\",\"true\")\n  .save(tablePath)\n  \nval spark = SparkSession.builder.master(\"local\")\n  .config(\"spark.engineplus.star.meta.host\", \"cassandra_host\")\n  .config(\"spark.sql.extensions\", \"com.engineplus.star.sql.StarSparkSessionExtension\")\n  //second way\n  .config(\"spark.engineplus.star.schema.autoMerge.enabled\", \"true\")\n  .getOrCreate()\n```\n\n## 11. Drop Partition\nDrop a partition, also known as drop range partition, does not actually delete the data files. You can use the Cleanup operation to cleanup stale data.\n\n### 11.1 Code Examples\n```scala\nimport com.engineplus.star.tables.StarTable\nimport org.apache.spark.sql._\nval spark = SparkSession.builder.master(\"local\")\n  .config(\"spark.engineplus.star.meta.host\", \"cassandra_host\")\n  .config(\"spark.sql.extensions\", \"com.engineplus.star.sql.StarSparkSessionExtension\")\n  .getOrCreate()\n\nval tablePath = \"s3a://bucket-name/table/path/is/also/table/name\"\nval starTable = StarTable.forPath(tablePath)\n\n//drop the specified range partition\nstarTable.dropPartition(\"date='2021-01-01'\")\n\n```\n\n## 12. Drop Table\nDrop table will directly deletes all the metadata and files.\n\n### 12.1 Code Examples\n```scala\nimport com.engineplus.star.tables.StarTable\nimport org.apache.spark.sql._\nval spark = SparkSession.builder.master(\"local\")\n  .config(\"spark.engineplus.star.meta.host\", \"cassandra_host\")\n  .config(\"spark.sql.extensions\", \"com.engineplus.star.sql.StarSparkSessionExtension\")\n  .getOrCreate()\n\nval tablePath = \"s3a://bucket-name/table/path/is/also/table/name\"\nval starTable = StarTable.forPath(tablePath)\n\n//drop table\nstarTable.dropTable()\n\n```",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/engine-plus/StarLake",
    "keywords": "star-lake",
    "license": "Apache-2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "star-lake-spark",
    "package_url": "https://pypi.org/project/star-lake-spark/",
    "platform": "",
    "project_url": "https://pypi.org/project/star-lake-spark/",
    "project_urls": {
      "Homepage": "https://github.com/engine-plus/StarLake"
    },
    "release_url": "https://pypi.org/project/star-lake-spark/1.0.0/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "Python APIs for using Star Lake with Apache Spark",
    "version": "1.0.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 10944621,
  "releases": {
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "418c1888a9f2330fe35fb0ae02debde4d5238c2b39c4e260cb8754609e752d98",
          "md5": "957f4251c47f700f23660b13d1d8e0e9",
          "sha256": "91de0a14576f93d997f153c3040585a5750da4cb7f2657227674229664fbe199"
        },
        "downloads": -1,
        "filename": "star-lake-spark-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "957f4251c47f700f23660b13d1d8e0e9",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 17847,
        "upload_time": "2021-07-19T09:34:33",
        "upload_time_iso_8601": "2021-07-19T09:34:33.666332Z",
        "url": "https://files.pythonhosted.org/packages/41/8c/1888a9f2330fe35fb0ae02debde4d5238c2b39c4e260cb8754609e752d98/star-lake-spark-1.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "418c1888a9f2330fe35fb0ae02debde4d5238c2b39c4e260cb8754609e752d98",
        "md5": "957f4251c47f700f23660b13d1d8e0e9",
        "sha256": "91de0a14576f93d997f153c3040585a5750da4cb7f2657227674229664fbe199"
      },
      "downloads": -1,
      "filename": "star-lake-spark-1.0.0.tar.gz",
      "has_sig": false,
      "md5_digest": "957f4251c47f700f23660b13d1d8e0e9",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 17847,
      "upload_time": "2021-07-19T09:34:33",
      "upload_time_iso_8601": "2021-07-19T09:34:33.666332Z",
      "url": "https://files.pythonhosted.org/packages/41/8c/1888a9f2330fe35fb0ae02debde4d5238c2b39c4e260cb8754609e752d98/star-lake-spark-1.0.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}