{
  "info": {
    "author": "",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# neroRL\n\nneroRL is a PyTorch based research framework for Deep Reinforcement Learning specializing on Recurrent Proximal Policy Optimization.\nIts focus is set on environments that are procedurally generated, while providing some usefull tools for experimenting and analyzing a trained behavior.\n\n# Features\n- Environments:\n  - [Obstacle Tower](https://github.com/Unity-Technologies/obstacle-tower-env)\n  - [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents)\n  - [Procgen](https://github.com/openai/procgen)\n  - [Gym-Minigrid](https://github.com/maximecb/gym-minigrid) (Vector (one-hot) or Visual Observations (84x84x3))\n  - [Gym CartPole](https://github.com/openai/gym) using masked velocity\n  - [DM Ballet](https://github.com/deepmind/deepmind-research/tree/master/hierarchical_transformer_memory/pycolab_ballet)\n- Proximal Policy Optimization (PPO)\n  - Discrete and Multi-Discrete Action Spaces\n  - Vector and Visual Observation Spaces (either alone or simultaneously)\n  - [Recurrent Policies using Truncated Backpropagation Through Time](https://github.com/MarcoMeter/recurrent-ppo-truncated-bptt)\n  - Shared and None-Shared Parameters across the Policy and the Value Function\n- Decoupled Proximal Policy Optimization\n  - Same features as PPO, but the parameters, as well as the gradients, are decoupled\n  - Decoupled Advantage Actor-Critic (DAAC, [Raileanu & Fergus, 2021](https://arxiv.org/abs/2102.10330))\n    - The actor network estimates the policy and the advantage function\n\n# Obstacle Tower Challenge\nOriginally, this work started out by achieving the 7th place during the [Obstacle Tower Challenge](https://blogs.unity3d.com/2019/08/07/announcing-the-obstacle-tower-challenge-winners-and-open-source-release/) by using a relatively simple FFCNN. This [video](https://www.youtube.com/watch?v=P2rBDHBHxcM) presents some footage of the approach and the trained behavior:\n\n<p align=\"center\"><a href=\"http://www.youtube.com/watch?feature=player_embedded&v=P2rBDHBHxcM\n\" target=\"_blank\"><img src=\"http://img.youtube.com/vi/P2rBDHBHxcM/0.jpg\" \nalt=\"Rising to the Obstacle Tower Challenge\" width=\"240\" height=\"180\" border=\"10\" /></a></p>\n\nRecently we published a [paper](https://arxiv.org/abs/2004.00567) at CoG 2020 (best paper candidate) that analyzes the taken approach. Additionally the model was trained on 3 level designs and was evaluated on the two left out ones. The results can be reproduced using the [obstacle-tower-challenge](https://github.com/MarcoMeter/neroRL/tree/obstacle-tower-challenge) branch.\n\n# Getting Started\n\nTo get started check out the [docs](/docs/)!\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/MarcoMeter/neroRL",
    "keywords": "Deep Reinforcement Learning,PyTorch,Proximal Policy Optimization,PPO,Recurrent,Recurrence,LSTM,GRU",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "neroRL",
    "package_url": "https://pypi.org/project/neroRL/",
    "platform": null,
    "project_url": "https://pypi.org/project/neroRL/",
    "project_urls": {
      "Bug Tracker": "https://github.com/MarcoMeter/neroRL/issues",
      "Github": "https://github.com/MarcoMeter/neroRL",
      "Homepage": "https://github.com/MarcoMeter/neroRL"
    },
    "release_url": "https://pypi.org/project/neroRL/0.0.4/",
    "requires_dist": [
      "dm-env (==1.5)",
      "docopt",
      "gym",
      "gym-minigrid (==1.0.2)",
      "jinja2",
      "matplotlib",
      "opencv-python",
      "pandas",
      "procgen",
      "pycolab (==1.2)",
      "pygame",
      "pyglet",
      "ruamel.yaml",
      "scipy",
      "windows-curses ; sys_platform == \"win32\""
    ],
    "requires_python": ">=3.6",
    "summary": "A library for Deep Reinforcement Learning (PPO) in PyTorch",
    "version": "0.0.4",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 13370307,
  "releases": {
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "63a7c1b9654bb5ed0e1b1a88feba80284d1179a3e29f5cc23801305c8f4c8faa",
          "md5": "fd5eaa0270876716fa5d3cf7e3a2861d",
          "sha256": "a4267da15723c4df526e9a3170ac4fa4f4a68149be10f181d5330ab3c8d63dc8"
        },
        "downloads": -1,
        "filename": "neroRL-0.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "fd5eaa0270876716fa5d3cf7e3a2861d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 109227,
        "upload_time": "2022-04-01T06:02:15",
        "upload_time_iso_8601": "2022-04-01T06:02:15.656873Z",
        "url": "https://files.pythonhosted.org/packages/63/a7/c1b9654bb5ed0e1b1a88feba80284d1179a3e29f5cc23801305c8f4c8faa/neroRL-0.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b593cbe7831d14e8ac16bc6f70a683425cb1a596238f007de4ca83980cf94269",
          "md5": "f7bb68ba373af23ebcb690e0667cc12f",
          "sha256": "7efd9b4316d8d2a271a41d5a5fb328e3d4a809c3b2d2882cabfb642f8ad3f83b"
        },
        "downloads": -1,
        "filename": "neroRL-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "f7bb68ba373af23ebcb690e0667cc12f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 74653,
        "upload_time": "2022-04-01T06:02:17",
        "upload_time_iso_8601": "2022-04-01T06:02:17.573440Z",
        "url": "https://files.pythonhosted.org/packages/b5/93/cbe7831d14e8ac16bc6f70a683425cb1a596238f007de4ca83980cf94269/neroRL-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "197f0e0f7e7c0cc2cad47655db2b5ac31aeb7f18355fc3f22d37a77f055e789a",
          "md5": "96e4ad384528ab9f405ec3da2d339413",
          "sha256": "b6f788ebc77f5744f20aea915d560427d6c880af1a1868e965e4b278a55d6fd1"
        },
        "downloads": -1,
        "filename": "neroRL-0.0.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "96e4ad384528ab9f405ec3da2d339413",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 109213,
        "upload_time": "2022-04-01T06:11:19",
        "upload_time_iso_8601": "2022-04-01T06:11:19.838128Z",
        "url": "https://files.pythonhosted.org/packages/19/7f/0e0f7e7c0cc2cad47655db2b5ac31aeb7f18355fc3f22d37a77f055e789a/neroRL-0.0.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ad6980ae858331c045c38a6360c414952d618b3fcaaa52efead400fed593b417",
          "md5": "ccba2de5198b0dbc69abc6063f42ffa8",
          "sha256": "7a71e1f08f5b910669e6dc5f24e9918f69ffa26b105080fea7cc022934849516"
        },
        "downloads": -1,
        "filename": "neroRL-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "ccba2de5198b0dbc69abc6063f42ffa8",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 74640,
        "upload_time": "2022-04-01T06:11:21",
        "upload_time_iso_8601": "2022-04-01T06:11:21.321446Z",
        "url": "https://files.pythonhosted.org/packages/ad/69/80ae858331c045c38a6360c414952d618b3fcaaa52efead400fed593b417/neroRL-0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "197f0e0f7e7c0cc2cad47655db2b5ac31aeb7f18355fc3f22d37a77f055e789a",
        "md5": "96e4ad384528ab9f405ec3da2d339413",
        "sha256": "b6f788ebc77f5744f20aea915d560427d6c880af1a1868e965e4b278a55d6fd1"
      },
      "downloads": -1,
      "filename": "neroRL-0.0.4-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "96e4ad384528ab9f405ec3da2d339413",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 109213,
      "upload_time": "2022-04-01T06:11:19",
      "upload_time_iso_8601": "2022-04-01T06:11:19.838128Z",
      "url": "https://files.pythonhosted.org/packages/19/7f/0e0f7e7c0cc2cad47655db2b5ac31aeb7f18355fc3f22d37a77f055e789a/neroRL-0.0.4-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "ad6980ae858331c045c38a6360c414952d618b3fcaaa52efead400fed593b417",
        "md5": "ccba2de5198b0dbc69abc6063f42ffa8",
        "sha256": "7a71e1f08f5b910669e6dc5f24e9918f69ffa26b105080fea7cc022934849516"
      },
      "downloads": -1,
      "filename": "neroRL-0.0.4.tar.gz",
      "has_sig": false,
      "md5_digest": "ccba2de5198b0dbc69abc6063f42ffa8",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 74640,
      "upload_time": "2022-04-01T06:11:21",
      "upload_time_iso_8601": "2022-04-01T06:11:21.321446Z",
      "url": "https://files.pythonhosted.org/packages/ad/69/80ae858331c045c38a6360c414952d618b3fcaaa52efead400fed593b417/neroRL-0.0.4.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}