{
  "info": {
    "author": "Butch Landingin",
    "author_email": "butchland@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: Apache Software License",
      "Natural Language :: English",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8"
    ],
    "description": "# FastAI XLA Extensions Library\n> The FastAI XLA Extensions library package allows your fastai/Pytorch models to run on TPUs using the Pytorch-XLA library.\n\n\n<a href=\"https://colab.research.google.com/github/butchland/fastai_xla_extensions/blob/master/nbs/index.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n\n## Documentation Site\n\nYou can view the documentation here: https://butchland.github.io/fastai_xla_extensions \n\n## Install\n\n`pip install fastai_xla_extensions`\n\n## How to use\n\n### Configure TPU Environment Access\n\nThe Pytorch XLA package requires an environment supporting TPUs (Kaggle kernels, GCP or Colab environments required). \n\nNominally, Pytorch XLA also supports  GPUs so please see the [Pytorch XLA site for more instructions](https://pytorch.org/xla/release/1.7/index.html).\n\nIf running on Colab, make sure the Runtime Type is set to TPU.\n\n\n### Install pytorch 1.7.1\n\nUse pytorch 1.7.1 as this is latest version of pytorch supported by the fastai package\n\n```python\n#hide_output\n#colab\n# install pytorch 1.7.1 b/c fastai doesn't support pytorch 1.8 just yet\n!pip install -Uqq --no-cache-dir torch==1.7.1+cu101 torchvision==0.8.2+cu101 torchtext==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html\n\n```\n\n### Install fastai\n\nUse the latest fastai and fastcore versions (_note: due to a compatibility issue, we are using fastai==2.3.0 for now_)\n\n```python\n#hide_output\n#colab\n!pip install -Uqq fastcore --upgrade\n!pip install -Uqq fastai==2.3.0 \n```\n\n### Install Pytorch XLA\n\n\nThis is the official way to install Pytorch-XLA 1.7 as per the [instructions here](https://colab.research.google.com/github/pytorch/xla/blob/master/contrib/colab/getting-started.ipynb#scrollTo=CHzziBW5AoZH)\n\n```python\n#hide_output\n#colab\n!pip install -Uqq cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.7-cp37-cp37m-linux_x86_64.whl\n```\n\n### Check if XLA is available\n\n```python\n#colab\nimport warnings\ntry:\n    import torch_xla\nexcept ImportError as e:\n    if DEBUG: warnings.warn('TPU environment not available')\n\n```\n\n    WARNING:root:Waiting for TPU to be start up with version pytorch-1.7...\n    WARNING:root:Waiting for TPU to be start up with version pytorch-1.7...\n    WARNING:root:TPU has started up successfully with version pytorch-1.7\n\n\n### Import the libraries\nImport the fastai and fastai_xla_extensions libraries\n\n```python\nfrom fastai.vision.all import *\n```\n\n```python\n#colab\n#hide_output\nfrom fastai_xla_extensions.all import *\n```\n\n\n## Single and Multi Core TPU Modes\n\nThe `fastai_xla_extensions` package allows you to train your models using either a single TPU core or multiple TPU cores. \n\nUsing multi TPU cores is usually faster than single TPU core, but due to some limitations, not all fastai features are supported in multi TPU core mode.\n\n* **Multi Core TPU mode**\n\n    In order to run in multi TPU core mode, the `fastai_xla_extensions` package patched some additional methods to the `Learner` class.\n\n    These additional methods are all prefixed by `xla`. For example, to run the `Learner.fit` method in multi core tpu mode, you can invoke the equivalent `Learner.xla_fit` method, with almost the same parameters.\n\n\n   Note that in multi core TPU mode, when calling normal learner or data loader methods (not prefixed by `xla`), the process does not use the multi core TPUs, but instead runs them using the CPU.\n\n  * **List of `xla` prefixed methods**\n\n    * xla_fit\n    * xla_fine_tune\n    * xla_fit_one_cycle\n    * xla_fit_sgdr\n    * xla_fit_flat_cos\n    * xla_lr_find\n    * xla_get_preds\n\n\n  * **Additional `xla` Parameters (for Multi Core TPU mode)**\n\n    All `xla` prefixed methods support the following additional parameters:\n\n    * num_cores: this is defaulted to 8 (representing the number of TPU cores per TPU device) - valid values are `8` or `1` on Google Colab. For running GCP TPUs, other values maybe possible. See the [Pytorch XLA page](https://pytorch.org/xla/release/1.7/index.html) for more details.\n\n    * start_method: this is defaulted to `fork` which the only value supported on Google Colab. On GCP, other values supported include `spawn`. Again, see the [Pytorch XLA page](https://pytorch.org/xla/release/1.7/index.html) for more details.\n\n    * master_cbs: these are callbacks that are run only on the master ordinal process (rank = 0). This allows the addition of callbacks that may interfere with each other if run simultaneously on more than one process by restricting them to run on only one process - the master ordinal process.\n\n\n* **Single Core TPU mode**\n\n    In order to run in single TPU core mode, the `fastai_xla_extensions` package added a method `to_xla` to the `Learner` class.\n\n    After invoking this method, the learner will now use an associated TPU core device to the learner process which will be used when training the model.\n\n    This means we can use the same `fit` methods in `Learner` that we normally use to train the model when using a GPU or a CPU.\n\n    Also note that the single TPU core mode is incompatible with the Multi TPU Core mode, and that the kernel will have to restarted once the single TPU core mode is set. This is because once a TPU core is associated with the main process, it cannot be unset without restarting the kernel.\n\n\n\n\n### Multi TPU Core Example\nBuild a MNIST classifier -- adapted from fastai course [Lesson 4 notebook](https://github.com/fastai/course-v4/blob/master/nbs/04_mnist_basics.ipynb)\n\nLoad MNIST dataset \n\n```python\npath = untar_data(URLs.MNIST_TINY)\n```\n\n\n\n\n\nCreate Fastai DataBlock\n\n\n\n```python\ndatablock = DataBlock(\n    blocks=(ImageBlock,CategoryBlock),\n    get_items=get_image_files,\n    splitter=GrandparentSplitter(),\n    get_y=parent_label,\n    item_tfms=Resize(28),\n    # batch transforms run on the CPU and are slow, so only using the Normalize batch transform\n    batch_tfms=[Normalize.from_stats(*imagenet_stats)]\n)\n```\n\n```python\n#colab\ndatablock.summary(path)\n```\n\n    Setting-up type transforms pipelines\n    Collecting items from /root/.fastai/data/mnist_tiny\n    Found 1428 items\n    2 datasets of sizes 709,699\n    Setting up Pipeline: PILBase.create\n    Setting up Pipeline: parent_label -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n\n    Building one sample\n      Pipeline: PILBase.create\n        starting from\n          /root/.fastai/data/mnist_tiny/train/7/8791.png\n        applying PILBase.create gives\n          PILImage mode=RGB size=28x28\n      Pipeline: parent_label -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n        starting from\n          /root/.fastai/data/mnist_tiny/train/7/8791.png\n        applying parent_label gives\n          7\n        applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n          TensorCategory(1)\n\n    Final sample: (PILImage mode=RGB size=28x28, TensorCategory(1))\n\n\n    Collecting items from /root/.fastai/data/mnist_tiny\n    Found 1428 items\n    2 datasets of sizes 709,699\n    Setting up Pipeline: PILBase.create\n    Setting up Pipeline: parent_label -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n    Setting up after_item: Pipeline: Resize -- {'size': (28, 28), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n    Setting up before_batch: Pipeline: \n    Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n\n             [[0.4560]],\n\n             [[0.4060]]]]), 'std': tensor([[[[0.2290]],\n\n             [[0.2240]],\n\n             [[0.2250]]]]), 'axes': (0, 2, 3)}\n\n    Building one batch\n    Applying item_tfms to the first sample:\n      Pipeline: Resize -- {'size': (28, 28), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n        starting from\n          (PILImage mode=RGB size=28x28, TensorCategory(1))\n        applying Resize -- {'size': (28, 28), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n          (PILImage mode=RGB size=28x28, TensorCategory(1))\n        applying ToTensor gives\n          (TensorImage of size 3x28x28, TensorCategory(1))\n\n    Adding the next 3 samples\n\n    No before_batch transform to apply\n\n    Collating items in a batch\n\n    Applying batch_tfms to the batch built\n      Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n\n             [[0.4560]],\n\n             [[0.4060]]]]), 'std': tensor([[[[0.2290]],\n\n             [[0.2240]],\n\n             [[0.2250]]]]), 'axes': (0, 2, 3)}\n        starting from\n          (TensorImage of size 4x3x28x28, TensorCategory([1, 1, 1, 1]))\n        applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n          (TensorImage of size 4x3x28x28, TensorCategory([1, 1, 1, 1]))\n        applying Normalize -- {'mean': tensor([[[[0.4850]],\n\n             [[0.4560]],\n\n             [[0.4060]]]]), 'std': tensor([[[[0.2290]],\n\n             [[0.2240]],\n\n             [[0.2250]]]]), 'axes': (0, 2, 3)} gives\n          (TensorImage of size 4x3x28x28, TensorCategory([1, 1, 1, 1]))\n\n\nCreate the dataloader\n\n```python\ndls = datablock.dataloaders(path, bs=8) # use a small batch size as mnist_tiny dataset is very small\n```\n\n```python\n#colab\ndls.show_batch()\n```\n\n\n![png](docs/images/output_27_0.png)\n\n\nCreate a Fastai CNN Learner\n\n\n```python\nlearner = cnn_learner(dls, resnet18, metrics=accuracy, concat_pool=False) # fastai AdaptivePooling causes a lowering which slows down the training so using nn.AvgPool2D\n\n```\n\n    Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n\n\n\n\n\n```python\n#colab\nlearner.summary()\n```\n\nUsing the `lr_find` works \n\n```python\n#colab\nlearner.xla_lr_find()\n```\n\n    start fit\n\n\n\n\n\n\n\n\n\n    SuggestedLRs(lr_min=7.585775847473997e-08, lr_steep=6.309573450380412e-07)\n\n\n\n\n![png](docs/images/output_32_3.png)\n\n\nRun one cycle training.\n\n\n```python\n#colab\nlearner.xla_fit_one_cycle(5,lr_max=slice(1e-4,0.02))\n```\n\n    start fit\n\n\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.190064</td>\n      <td>0.391755</td>\n      <td>0.848011</td>\n      <td>00:17</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.273210</td>\n      <td>0.288629</td>\n      <td>0.882102</td>\n      <td>00:06</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.322163</td>\n      <td>0.430995</td>\n      <td>0.875000</td>\n      <td>00:06</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.354422</td>\n      <td>0.534526</td>\n      <td>0.830966</td>\n      <td>00:06</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.372328</td>\n      <td>0.517053</td>\n      <td>0.833807</td>\n      <td>00:06</td>\n    </tr>\n  </tbody>\n</table>\n\n\nFurther fine-tuning\n\n```python\n#colab\nlearner.xla_fit_one_cycle(5,lr_max=slice(7e-4, 1e-3))\n```\n\n    start fit\n\n\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.046700</td>\n      <td>0.451159</td>\n      <td>0.867898</td>\n      <td>00:14</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.056459</td>\n      <td>0.340751</td>\n      <td>0.896307</td>\n      <td>00:07</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.061811</td>\n      <td>0.376011</td>\n      <td>0.892045</td>\n      <td>00:06</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.071214</td>\n      <td>0.394541</td>\n      <td>0.879261</td>\n      <td>00:06</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.137522</td>\n      <td>0.407396</td>\n      <td>0.899148</td>\n      <td>00:06</td>\n    </tr>\n  </tbody>\n</table>\n\n\nModel params are using CPU (since it is the spawned process models that are moved to TPU)\n\n```python\n#colab\none_param(learner.model).device\n```\n\n\n\n\n    device(type='cpu')\n\n\n\nPlot loss seems to be working fine.\n\n```python\n#colab\nlearner.recorder.plot_loss()\n```\n\n\n![png](docs/images/output_40_0.png)\n\n\n### Single TPU Core Example\nBuild a MNIST classifier -- adapted from fastai course [Lesson 4 notebook](https://github.com/fastai/course-v4/blob/master/nbs/04_mnist_basics.ipynb)\n\nLoad MNIST dataset \n\n```python\npath = untar_data(URLs.MNIST_TINY)\n```\n\nCreate Fastai DataBlock\n\n\n\n```python\ndatablock = DataBlock(\n    blocks=(ImageBlock,CategoryBlock),\n    get_items=get_image_files,\n    splitter=GrandparentSplitter(),\n    get_y=parent_label,\n    item_tfms=Resize(28),\n    # affine transforms are performed on the CPU, other batch transforms are done on the TPU\n    batch_tfms=aug_transforms(do_flip=False,min_scale=0.8)\n)\n```\n\n```python\n#colab\ndatablock.summary(path)\n```\n\n    Setting-up type transforms pipelines\n    Collecting items from /root/.fastai/data/mnist_tiny\n    Found 1428 items\n    2 datasets of sizes 709,699\n    Setting up Pipeline: PILBase.create\n    Setting up Pipeline: parent_label -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n\n    Building one sample\n      Pipeline: PILBase.create\n        starting from\n          /root/.fastai/data/mnist_tiny/train/7/8791.png\n        applying PILBase.create gives\n          PILImage mode=RGB size=28x28\n      Pipeline: parent_label -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n        starting from\n          /root/.fastai/data/mnist_tiny/train/7/8791.png\n        applying parent_label gives\n          7\n        applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n          TensorCategory(1)\n\n    Final sample: (PILImage mode=RGB size=28x28, TensorCategory(1))\n\n\n    Collecting items from /root/.fastai/data/mnist_tiny\n    Found 1428 items\n    2 datasets of sizes 709,699\n    Setting up Pipeline: PILBase.create\n    Setting up Pipeline: parent_label -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n    Setting up after_item: Pipeline: Resize -- {'size': (28, 28), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n    Setting up before_batch: Pipeline: \n    Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Warp -- {'magnitude': 0.2, 'p': 1.0, 'draw_x': None, 'draw_y': None, 'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'batch': False, 'align_corners': True, 'mode_mask': 'nearest'} -> RandomResizedCropGPU -- {'size': None, 'min_scale': 0.8, 'ratio': (1, 1), 'mode': 'bilinear', 'valid_scale': 1.0, 'p': 1.0} -> Brightness -- {'max_lighting': 0.2, 'p': 1.0, 'draw': None, 'batch': False}\n\n    Building one batch\n    Applying item_tfms to the first sample:\n      Pipeline: Resize -- {'size': (28, 28), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} -> ToTensor\n        starting from\n          (PILImage mode=RGB size=28x28, TensorCategory(1))\n        applying Resize -- {'size': (28, 28), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (2, 0), 'p': 1.0} gives\n          (PILImage mode=RGB size=28x28, TensorCategory(1))\n        applying ToTensor gives\n          (TensorImage of size 3x28x28, TensorCategory(1))\n\n    Adding the next 3 samples\n\n    No before_batch transform to apply\n\n    Collating items in a batch\n\n    Applying batch_tfms to the batch built\n      Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Warp -- {'magnitude': 0.2, 'p': 1.0, 'draw_x': None, 'draw_y': None, 'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'batch': False, 'align_corners': True, 'mode_mask': 'nearest'} -> RandomResizedCropGPU -- {'size': None, 'min_scale': 0.8, 'ratio': (1, 1), 'mode': 'bilinear', 'valid_scale': 1.0, 'p': 1.0} -> Brightness -- {'max_lighting': 0.2, 'p': 1.0, 'draw': None, 'batch': False}\n        starting from\n          (TensorImage of size 4x3x28x28, TensorCategory([1, 1, 1, 1]))\n        applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n          (TensorImage of size 4x3x28x28, TensorCategory([1, 1, 1, 1]))\n        applying Warp -- {'magnitude': 0.2, 'p': 1.0, 'draw_x': None, 'draw_y': None, 'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'batch': False, 'align_corners': True, 'mode_mask': 'nearest'} gives\n          (TensorImage of size 4x3x28x28, TensorCategory([1, 1, 1, 1]))\n        applying RandomResizedCropGPU -- {'size': None, 'min_scale': 0.8, 'ratio': (1, 1), 'mode': 'bilinear', 'valid_scale': 1.0, 'p': 1.0} gives\n          (TensorImage of size 4x3x26x26, TensorCategory([1, 1, 1, 1]))\n        applying Brightness -- {'max_lighting': 0.2, 'p': 1.0, 'draw': None, 'batch': False} gives\n          (TensorImage of size 4x3x26x26, TensorCategory([1, 1, 1, 1]))\n\n\nCreate the dataloader\n\n```python\ndls = datablock.dataloaders(path)\n```\n\n```python\n#colab\ndls.show_batch()\n```\n\n\n![png](docs/images/output_49_0.png)\n\n\nCreate a Fastai CNN Learner\n\n\n```python\nlearner = cnn_learner(dls, resnet18, metrics=accuracy)\n\n```\n\n```python\n#colab\nlearner.summary()\n```\n\nSet Learner to XLA mode\nThis will setup the learner to use the XLA Device\n\n```python\n#colab\nlearner.to_xla()\n```\n\n\n\n\n    <fastai.learner.Learner at 0x7fc75a5a8090>\n\n\n\nUsing the `lr_find` works \n\n```python\n#colab\nlearner.lr_find()\n```\n\n\n\n\n\n\n\n\n    SuggestedLRs(lr_min=0.02089296132326126, lr_steep=0.0030199517495930195)\n\n\n\n\n![png](docs/images/output_56_2.png)\n\n\nRun one cycle training.\n\n\n```python\n#colab\nlearner.fit_one_cycle(5,lr_max=slice(1e-4,0.02))\n```\n\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.896238</td>\n      <td>1.876374</td>\n      <td>0.505007</td>\n      <td>00:51</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.725275</td>\n      <td>1.018629</td>\n      <td>0.532189</td>\n      <td>00:13</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.614300</td>\n      <td>3.292356</td>\n      <td>0.513591</td>\n      <td>00:03</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.549166</td>\n      <td>2.262487</td>\n      <td>0.580830</td>\n      <td>00:03</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.535161</td>\n      <td>1.760773</td>\n      <td>0.660944</td>\n      <td>00:03</td>\n    </tr>\n  </tbody>\n</table>\n\n\nFurther fine-tuning\n\n```python\n#colab\nlearner.fit_one_cycle(5,slice(7e-4, 1e-3))\n```\n\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.280359</td>\n      <td>0.992468</td>\n      <td>0.688126</td>\n      <td>00:12</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.315132</td>\n      <td>1.013533</td>\n      <td>0.712446</td>\n      <td>00:03</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.306187</td>\n      <td>0.745202</td>\n      <td>0.711016</td>\n      <td>00:03</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.282278</td>\n      <td>0.701246</td>\n      <td>0.736767</td>\n      <td>00:03</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.288474</td>\n      <td>0.854370</td>\n      <td>0.711016</td>\n      <td>00:03</td>\n    </tr>\n  </tbody>\n</table>\n\n\nModel params are using TPU\n\n```python\n#colab\none_param(learner.model).device\n```\n\n\n\n\n    device(type='xla', index=1)\n\n\n\nDataloader device is set to None (as it is the device mover transform that moves the input to the TPU)\n\n```python\nlearner.dls.device is None\n```\n\n\n\n\n    True\n\n\n\nPlot loss seems to be working fine.\n\n```python\n#colab\nlearner.recorder.plot_loss()\n```\n\n\n![png](docs/images/output_66_0.png)\n\n\n## Performance troubleshooting\n\nTo check if your model is hiting an `aten operation` (an operation that is not handled by accelerator device and returned to CPU for default implementation) you can check it with ands then you can report to pytorch xla team.\n\n```python\n#colab\nfrom fastai_xla_extensions.utils import print_aten_ops\n\nprint_aten_ops()\n```\n\n    needs lowering: Counter: aten::adaptive_max_pool2d\n      Value: 311\n    needs lowering: Counter: aten::adaptive_max_pool2d_backward\n      Value: 201\n\n\n## Samples\n\nOther examples of fastai notebooks using the fastai_xla_extensions package are also available here: \n\n* [Vision (Multiple TPU Core) - CIFAR](https://github.com/butchland/fastai_xla_extensions/blob/master/samples/fastai-multi-core-tpu-training-sample.ipynb) [![](https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/butchland/fastai_xla_extensions/blob/master/samples/fastai-multi-core-tpu-training-sample.ipynb)\n* [Vision (Multiple TPU Core) - Multi Label](https://github.com/butchland/fastai_xla_extensions/blob/master/samples/fastai-multi-core-tpu-training-sample2.ipynb) [![](https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/butchland/fastai_xla_extensions/blob/master/samples/fastai-multi-core-tpu-training-sample2.ipynb)\n\n* [Vision (Multiple TPU Core) - Pets](https://github.com/butchland/fastai_xla_extensions/blob/master/samples/test_fast_tpu_pets.ipynb) [![](https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/butchland/fastai_xla_extensions/blob/master/samples/test_fast_tpu_pets.ipynb)\n\n* [Vision (Multiple TPU Core) - Plain pytorch training with minimal fastai](https://github.com/butchland/fastai_xla_extensions/blob/master/samples/minimal_fastai_pytorch_tpu_sample.ipynb) [![](https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/butchland/fastai_xla_extensions/blob/master/samples/minimal_fastai_pytorch_tpu_sample.ipynb)\n\n* [Vision (Single Core TPU)](https://github.com/butchland/fastai_xla_extensions/blob/master/samples/MNIST_TPU_demo.ipynb) [![](https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/butchland/fastai_xla_extensions/blob/master/samples/MNIST_TPU_demo.ipynb)\n\n* [Collaborative Filtering (Single Core TPU)](https://github.com/butchland/fastai_xla_extensions/blob/master/samples/MovieLensCollaborativeFilteringTPU.ipynb) [![](https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/butchland/fastai_xla_extensions/blob/master/samples/MovieLensCollaborativeFilteringTPU.ipynb)\n\n* [Tabular (Single Core TPU)](https://github.com/butchland/fastai_xla_extensions/blob/master/samples/TabularTrainingTPUdemo.ipynb) [![](https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/butchland/fastai_xla_extensions/blob/master/samples/TabularTrainingTPUdemo.ipynb)\n\n* [Kaggle Notebook version of Vision (Multiple TPU Core) - Pets](https://www.kaggle.com/butchland/fastai-multi-core-tpu-pets-sample) \n\n* **NEW** ** [Vision (Multi Core) using Pytorch Image Models (timm models) with Albumentations](https://github.com/butchland/fastai_xla_extensions/blob/master/samples/timm-albumentations-fastai-multi-tpu-sample.ipynb) [![](https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/butchland/fastai_xla_extensions/blob/master/samples/timm-albumentations-fastai-multi-tpu-sample.ipynb)\n\n\nMore samples will be added in the future as we fix issues and implement more capabilities.\n\n\n\n## Status\nThe fastai XLA extensions library is still in early development phase but is getting close to a 1.0 release.\n\nThe Multi Core TPU mode has been well tested on vision tasks (Classification) but the other modules (Tabular, Collab Filtering, and Text) have not.\n\nIf you use the package and encounter issues, please file bugs and issues encountered in the project's issue tracker.\n\nFeel free to suggest enhancements or feature requests. (Though they might not necessarily be addressed any time soon).\n\nIf you wish to contribute to the project, fork it and make pull request. \n\nThis project uses [nbdev](https://nbdev.fast.ai/) -- a jupyter notebook first development environment and is being developed on [Colab](https://colab.research.google.com).\n\n\n## Development Setup\n\nsee [this note on how to setup your environment for development](https://butchland.github.io/fastai_xla_extensions/dev_setup)\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/butchland/fastai_xla_extensions/tree/master/",
    "keywords": "fastai pytorch pytorch-xla tpu",
    "license": "Apache Software License 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "fastai-xla-extensions",
    "package_url": "https://pypi.org/project/fastai-xla-extensions/",
    "platform": "",
    "project_url": "https://pypi.org/project/fastai-xla-extensions/",
    "project_urls": {
      "Homepage": "https://github.com/butchland/fastai_xla_extensions/tree/master/"
    },
    "release_url": "https://pypi.org/project/fastai-xla-extensions/0.0.12/",
    "requires_dist": [
      "fastai (==2.3.0)"
    ],
    "requires_python": ">=3.6",
    "summary": "A library to extend fastai to run on TPUs using pytorch-xla",
    "version": "0.0.12",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 10998610,
  "releases": {
    "0.0.10": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "55d7ee3b3205fcaac4085584b25337f28a6fdee5e9803df2d7b17004db83097b",
          "md5": "202b3055783f25de70f323344dd746d8",
          "sha256": "fd684aaddaf730bfa4a643923dad9cd2b4fae25d4a20ca65a291c1f3e7481f71"
        },
        "downloads": -1,
        "filename": "fastai_xla_extensions-0.0.10-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "202b3055783f25de70f323344dd746d8",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 38187,
        "upload_time": "2021-03-12T10:24:10",
        "upload_time_iso_8601": "2021-03-12T10:24:10.490024Z",
        "url": "https://files.pythonhosted.org/packages/55/d7/ee3b3205fcaac4085584b25337f28a6fdee5e9803df2d7b17004db83097b/fastai_xla_extensions-0.0.10-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f20dc516753e1a3a08cf38b89ce94711cdac964252fc1b04cecc04e4eb4bbe91",
          "md5": "3c653ae99658a67d48934eb2df93b543",
          "sha256": "99093015b5f613b477e9227e1bdfc6644b8a3343c529199e699e730af54b7b82"
        },
        "downloads": -1,
        "filename": "fastai_xla_extensions-0.0.10.tar.gz",
        "has_sig": false,
        "md5_digest": "3c653ae99658a67d48934eb2df93b543",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 40130,
        "upload_time": "2021-03-12T10:24:12",
        "upload_time_iso_8601": "2021-03-12T10:24:12.270627Z",
        "url": "https://files.pythonhosted.org/packages/f2/0d/c516753e1a3a08cf38b89ce94711cdac964252fc1b04cecc04e4eb4bbe91/fastai_xla_extensions-0.0.10.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.11": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "85a881a1484dbac6a15eb537578a9d42340698451b063d87af5dfbae8ff37eda",
          "md5": "3567557aab6f90e1e441d8da0e888abb",
          "sha256": "cc0eff8ce061d3f2ec1e267be024f96a034ae3ba73ec386a897729eba78fd9e0"
        },
        "downloads": -1,
        "filename": "fastai_xla_extensions-0.0.11-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "3567557aab6f90e1e441d8da0e888abb",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 38111,
        "upload_time": "2021-03-12T10:51:00",
        "upload_time_iso_8601": "2021-03-12T10:51:00.098925Z",
        "url": "https://files.pythonhosted.org/packages/85/a8/81a1484dbac6a15eb537578a9d42340698451b063d87af5dfbae8ff37eda/fastai_xla_extensions-0.0.11-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9e2968c9c1c64603ba0ad0a26d78f391e568f46854ef0496902bd0ab17921484",
          "md5": "09e1138391e8d5a43dd4e23448e3cc3c",
          "sha256": "9789e290a2e416e8ef9f48bed7372c4edd3da6b1c35260ac28c08aaca4619276"
        },
        "downloads": -1,
        "filename": "fastai_xla_extensions-0.0.11.tar.gz",
        "has_sig": false,
        "md5_digest": "09e1138391e8d5a43dd4e23448e3cc3c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 40031,
        "upload_time": "2021-03-12T10:51:01",
        "upload_time_iso_8601": "2021-03-12T10:51:01.690159Z",
        "url": "https://files.pythonhosted.org/packages/9e/29/68c9c1c64603ba0ad0a26d78f391e568f46854ef0496902bd0ab17921484/fastai_xla_extensions-0.0.11.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.12": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3c87399a36832101636343c5474b1e24ef5a9aec5db329d5389589f8ad307650",
          "md5": "72c218ba33d9f53486d12590451c914d",
          "sha256": "0c4babcf89dc07b003c35a587398bf728ba9ebc839e95cf0b159aabc24c6ed11"
        },
        "downloads": -1,
        "filename": "fastai_xla_extensions-0.0.12-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "72c218ba33d9f53486d12590451c914d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 38289,
        "upload_time": "2021-07-25T12:51:43",
        "upload_time_iso_8601": "2021-07-25T12:51:43.419764Z",
        "url": "https://files.pythonhosted.org/packages/3c/87/399a36832101636343c5474b1e24ef5a9aec5db329d5389589f8ad307650/fastai_xla_extensions-0.0.12-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b88943c5fb08f0264a1f4fc18a8574bdd38dad3933251ab73cc2dddb09e3e103",
          "md5": "85cb1eafbd714bdb1beae8f2c496c1df",
          "sha256": "f86f74bb2cddb554cd04bb4d5ef9a78f427d51b8f3728bc69f52d72ca7853bf5"
        },
        "downloads": -1,
        "filename": "fastai_xla_extensions-0.0.12.tar.gz",
        "has_sig": false,
        "md5_digest": "85cb1eafbd714bdb1beae8f2c496c1df",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 43080,
        "upload_time": "2021-07-25T12:51:45",
        "upload_time_iso_8601": "2021-07-25T12:51:45.296137Z",
        "url": "https://files.pythonhosted.org/packages/b8/89/43c5fb08f0264a1f4fc18a8574bdd38dad3933251ab73cc2dddb09e3e103/fastai_xla_extensions-0.0.12.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2f520acdd57836678dbbe1a1d1df39a2522ac210e1b262cafb014a47f08a44e3",
          "md5": "595f1df4fa61db4d1da0f0a06f12bec2",
          "sha256": "616a3f15b571202e899fe12658f8c2ec561f7c17aada0f4538dc83e6ae27322c"
        },
        "downloads": -1,
        "filename": "fastai_xla_extensions-0.0.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "595f1df4fa61db4d1da0f0a06f12bec2",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 13091,
        "upload_time": "2020-12-20T06:13:52",
        "upload_time_iso_8601": "2020-12-20T06:13:52.690963Z",
        "url": "https://files.pythonhosted.org/packages/2f/52/0acdd57836678dbbe1a1d1df39a2522ac210e1b262cafb014a47f08a44e3/fastai_xla_extensions-0.0.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "00435ec99e16d856ad639ebfcfab05dee421d26dafb22e8ef1b3915824df080a",
          "md5": "c3bbe7cd7e05a6dc656680d7ce30cee4",
          "sha256": "f5e66b45e47aa9c9e16e689d5cbc8988b5ce1c70328df64357727608f9c48a81"
        },
        "downloads": -1,
        "filename": "fastai_xla_extensions-0.0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "c3bbe7cd7e05a6dc656680d7ce30cee4",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 18507,
        "upload_time": "2020-12-20T06:13:54",
        "upload_time_iso_8601": "2020-12-20T06:13:54.490447Z",
        "url": "https://files.pythonhosted.org/packages/00/43/5ec99e16d856ad639ebfcfab05dee421d26dafb22e8ef1b3915824df080a/fastai_xla_extensions-0.0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "92892b887eedd16141840280be6c47b06b8ffa2d3cfc289321b694536c9ef9d1",
          "md5": "24f874cadc509c8b30abd205333a6bd1",
          "sha256": "c764bdee765f9350b2c63581b1b5fa7110a7f9142c53fa9e920e77b026284dda"
        },
        "downloads": -1,
        "filename": "fastai_xla_extensions-0.0.6-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "24f874cadc509c8b30abd205333a6bd1",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 13128,
        "upload_time": "2020-12-20T07:29:51",
        "upload_time_iso_8601": "2020-12-20T07:29:51.977691Z",
        "url": "https://files.pythonhosted.org/packages/92/89/2b887eedd16141840280be6c47b06b8ffa2d3cfc289321b694536c9ef9d1/fastai_xla_extensions-0.0.6-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8f9720b472edd6226d7d7c91c4490a8cb021004a6051e49f94448b793f44d506",
          "md5": "0acd1a579cdd121d90d399f1f5b0fd27",
          "sha256": "5d18ee23ae30bf535b965b04605de1b9fef75078fc127c6ec79019419cb1a97d"
        },
        "downloads": -1,
        "filename": "fastai_xla_extensions-0.0.6.tar.gz",
        "has_sig": false,
        "md5_digest": "0acd1a579cdd121d90d399f1f5b0fd27",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 18590,
        "upload_time": "2020-12-20T07:29:53",
        "upload_time_iso_8601": "2020-12-20T07:29:53.651491Z",
        "url": "https://files.pythonhosted.org/packages/8f/97/20b472edd6226d7d7c91c4490a8cb021004a6051e49f94448b793f44d506/fastai_xla_extensions-0.0.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "26619eec53cc264618b87540a28c10654a7b33a2e18001621e81eee319e44846",
          "md5": "1278f67f2c46e2d6e76a21a4bdfcedb8",
          "sha256": "b5f1a611a14ac0728e3a6fa4aee347c4af3c67921fd3a563c15228123789fba3"
        },
        "downloads": -1,
        "filename": "fastai_xla_extensions-0.0.8-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "1278f67f2c46e2d6e76a21a4bdfcedb8",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 38121,
        "upload_time": "2021-03-11T16:20:56",
        "upload_time_iso_8601": "2021-03-11T16:20:56.082808Z",
        "url": "https://files.pythonhosted.org/packages/26/61/9eec53cc264618b87540a28c10654a7b33a2e18001621e81eee319e44846/fastai_xla_extensions-0.0.8-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "87b26b76c6175bcbaec4816119f7929afe3eb5d3dbe929bc921568c6824667a0",
          "md5": "7aad2b4f0f02b6b142465b4750f6453b",
          "sha256": "3b391a5de8736e0b126e54d1d6eb29d6e89a91bae8e923b4ee278b03eecb4239"
        },
        "downloads": -1,
        "filename": "fastai_xla_extensions-0.0.8.tar.gz",
        "has_sig": false,
        "md5_digest": "7aad2b4f0f02b6b142465b4750f6453b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 40073,
        "upload_time": "2021-03-11T16:20:57",
        "upload_time_iso_8601": "2021-03-11T16:20:57.822373Z",
        "url": "https://files.pythonhosted.org/packages/87/b2/6b76c6175bcbaec4816119f7929afe3eb5d3dbe929bc921568c6824667a0/fastai_xla_extensions-0.0.8.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.9": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c7c1ba37e67757502390ff63346969d4911073fba4c2d1bde4a1314bfb935232",
          "md5": "93bbce30ad1523c93c46b964d55d1f48",
          "sha256": "cabb4cc49ae4e74c493d8dd2a916766db8301af9e983380b8ea007de06041e57"
        },
        "downloads": -1,
        "filename": "fastai_xla_extensions-0.0.9-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "93bbce30ad1523c93c46b964d55d1f48",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 38170,
        "upload_time": "2021-03-12T10:08:09",
        "upload_time_iso_8601": "2021-03-12T10:08:09.352184Z",
        "url": "https://files.pythonhosted.org/packages/c7/c1/ba37e67757502390ff63346969d4911073fba4c2d1bde4a1314bfb935232/fastai_xla_extensions-0.0.9-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "70a37ba548a1b5acaacc9bdb85f193e89e5fb7bd984e35a207d317d404666e71",
          "md5": "55159304521d07e297e71943bf908774",
          "sha256": "f06c495686f89c1e7e4b6aee82270a37054be95d8f5075d0989acc1d180cb872"
        },
        "downloads": -1,
        "filename": "fastai_xla_extensions-0.0.9.tar.gz",
        "has_sig": false,
        "md5_digest": "55159304521d07e297e71943bf908774",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 40118,
        "upload_time": "2021-03-12T10:08:11",
        "upload_time_iso_8601": "2021-03-12T10:08:11.299308Z",
        "url": "https://files.pythonhosted.org/packages/70/a3/7ba548a1b5acaacc9bdb85f193e89e5fb7bd984e35a207d317d404666e71/fastai_xla_extensions-0.0.9.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "3c87399a36832101636343c5474b1e24ef5a9aec5db329d5389589f8ad307650",
        "md5": "72c218ba33d9f53486d12590451c914d",
        "sha256": "0c4babcf89dc07b003c35a587398bf728ba9ebc839e95cf0b159aabc24c6ed11"
      },
      "downloads": -1,
      "filename": "fastai_xla_extensions-0.0.12-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "72c218ba33d9f53486d12590451c914d",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 38289,
      "upload_time": "2021-07-25T12:51:43",
      "upload_time_iso_8601": "2021-07-25T12:51:43.419764Z",
      "url": "https://files.pythonhosted.org/packages/3c/87/399a36832101636343c5474b1e24ef5a9aec5db329d5389589f8ad307650/fastai_xla_extensions-0.0.12-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "b88943c5fb08f0264a1f4fc18a8574bdd38dad3933251ab73cc2dddb09e3e103",
        "md5": "85cb1eafbd714bdb1beae8f2c496c1df",
        "sha256": "f86f74bb2cddb554cd04bb4d5ef9a78f427d51b8f3728bc69f52d72ca7853bf5"
      },
      "downloads": -1,
      "filename": "fastai_xla_extensions-0.0.12.tar.gz",
      "has_sig": false,
      "md5_digest": "85cb1eafbd714bdb1beae8f2c496c1df",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 43080,
      "upload_time": "2021-07-25T12:51:45",
      "upload_time_iso_8601": "2021-07-25T12:51:45.296137Z",
      "url": "https://files.pythonhosted.org/packages/b8/89/43c5fb08f0264a1f4fc18a8574bdd38dad3933251ab73cc2dddb09e3e103/fastai_xla_extensions-0.0.12.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}