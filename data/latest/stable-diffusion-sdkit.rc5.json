{
  "info": {
    "author": "",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "Wrapper for the official [Stable Diffusion](https://github.com/Stability-AI/stablediffusion) repository, to allow installing via `pip`. Please see the installation section below for more details.\n\n# Stable Diffusion Version 2\n![t2i](https://github.com/Stability-AI/stablediffusion/raw/main/assets/stable-samples/txt2img/768/merged-0006.png)\n![t2i](https://github.com/Stability-AI/stablediffusion/raw/main/assets/stable-samples/txt2img/768/merged-0002.png)\n![t2i](https://github.com/Stability-AI/stablediffusion/raw/main/assets/stable-samples/txt2img/768/merged-0005.png)\n\nThis repository contains [Stable Diffusion](https://github.com/CompVis/stable-diffusion) models trained from scratch and will be continuously updated with\nnew checkpoints. The following list provides an overview of all currently available models. More coming soon.\n\n# Installation\n1. On Windows and Linux only: `pip install torch torchvision --extra-index-url https://download.pytorch.org/whl/cu116`\n2. Run `pip install stable-diffusion-sdkit`\n\nStep 1 is not necessary on Mac.\n\nThis will install the `ldm` package, which contains the stable diffusion code.\n\n## News\n\n**December 7, 2022**\n\n*Version 2.1*\n\n- New stable diffusion model (_Stable Diffusion 2.1-v_, [HuggingFace](https://huggingface.co/stabilityai/stable-diffusion-2-1)) at 768x768 resolution and (_Stable Diffusion 2.1-base_, [HuggingFace](https://huggingface.co/stabilityai/stable-diffusion-2-1-base)) at 512x512 resolution, both based on the same number of parameters and architecture as 2.0 and fine-tuned on 2.0, on a less restrictive NSFW filtering of the [LAION-5B](https://laion.ai/blog/laion-5b/) dataset.\nPer default, the attention operation of the model is evaluated at full precision when `xformers` is not installed. To enable fp16 (which can cause numerical instabilities with the vanilla attention module on the v2.1 model) , run your script with `ATTN_PRECISION=fp16 python <thescript.py>`\n\n**November 24, 2022**\n\n*Version 2.0*\n\n- New stable diffusion model (_Stable Diffusion 2.0-v_) at 768x768 resolution. Same number of parameters in the U-Net as 1.5, but uses [OpenCLIP-ViT/H](https://github.com/mlfoundations/open_clip) as the text encoder and is trained from scratch. _SD 2.0-v_ is a so-called [v-prediction](https://arxiv.org/abs/2202.00512) model. \n- The above model is finetuned from _SD 2.0-base_, which was trained as a standard noise-prediction model on 512x512 images and is also made available.\n- Added a [x4 upscaling latent text-guided diffusion model](#image-upscaling-with-stable-diffusion).\n- New [depth-guided stable diffusion model](#depth-conditional-stable-diffusion), finetuned from _SD 2.0-base_. The model is conditioned on monocular depth estimates inferred via [MiDaS](https://github.com/isl-org/MiDaS) and can be used for structure-preserving img2img and shape-conditional synthesis.\n\n  ![d2i](https://github.com/Stability-AI/stablediffusion/raw/main/assets/stable-samples/depth2img/depth2img01.png)\n- A [text-guided inpainting model](#image-inpainting-with-stable-diffusion), finetuned from SD _2.0-base_.\n\nWe follow the [original repository](https://github.com/CompVis/stable-diffusion) and provide basic inference scripts to sample from the models.\n\n________________\n*The original Stable Diffusion model was created in a collaboration with [CompVis](https://arxiv.org/abs/2202.00512) and [RunwayML](https://runwayml.com/) and builds upon the work:*\n\n[**High-Resolution Image Synthesis with Latent Diffusion Models**](https://ommer-lab.com/research/latent-diffusion-models/)<br/>\n[Robin Rombach](https://github.com/rromb)\\*,\n[Andreas Blattmann](https://github.com/ablattmann)\\*,\n[Dominik Lorenz](https://github.com/qp-qp)\\,\n[Patrick Esser](https://github.com/pesser),\n[Björn Ommer](https://hci.iwr.uni-heidelberg.de/Staff/bommer)<br/>\n_[CVPR '22 Oral](https://openaccess.thecvf.com/content/CVPR2022/html/Rombach_High-Resolution_Image_Synthesis_With_Latent_Diffusion_Models_CVPR_2022_paper.html) |\n[GitHub](https://github.com/CompVis/latent-diffusion) | [arXiv](https://arxiv.org/abs/2112.10752) | [Project page](https://ommer-lab.com/research/latent-diffusion-models/)_\n\nand [many others](#shout-outs).\n\nStable Diffusion is a latent text-to-image diffusion model.\n________________________________\n  \n## Requirements\n\nYou can update an existing [latent diffusion](https://github.com/CompVis/latent-diffusion) environment by running\n\n```\nconda install pytorch==1.12.1 torchvision==0.13.1 -c pytorch\npip install transformers==4.19.2 diffusers invisible-watermark\npip install -e .\n``` \n#### xformers efficient attention\nFor more efficiency and speed on GPUs, \nwe highly recommended installing the [xformers](https://github.com/facebookresearch/xformers)\nlibrary.\n\nTested on A100 with CUDA 11.4.\nInstallation needs a somewhat recent version of nvcc and gcc/g++, obtain those, e.g., via \n```commandline\nexport CUDA_HOME=/usr/local/cuda-11.4\nconda install -c nvidia/label/cuda-11.4.0 cuda-nvcc\nconda install -c conda-forge gcc\nconda install -c conda-forge gxx_linux-64==9.5.0\n```\n\nThen, run the following (compiling takes up to 30 min).\n\n```commandline\ncd ..\ngit clone https://github.com/facebookresearch/xformers.git\ncd xformers\ngit submodule update --init --recursive\npip install -r requirements.txt\npip install -e .\ncd ../stablediffusion\n```\nUpon successful installation, the code will automatically default to [memory efficient attention](https://github.com/facebookresearch/xformers)\nfor the self- and cross-attention layers in the U-Net and autoencoder.\n\n## General Disclaimer\nStable Diffusion models are general text-to-image diffusion models and therefore mirror biases and (mis-)conceptions that are present\nin their training data. Although efforts were made to reduce the inclusion of explicit pornographic material, **we do not recommend using the provided weights for services or products without additional safety mechanisms and considerations.\nThe weights are research artifacts and should be treated as such.**\nDetails on the training procedure and data, as well as the intended use of the model can be found in the corresponding [model card](https://huggingface.co/stabilityai/stable-diffusion-2).\nThe weights are available via [the StabilityAI organization at Hugging Face](https://huggingface.co/StabilityAI) under the [CreativeML Open RAIL++-M License](LICENSE-MODEL). \n\n\n\n## Stable Diffusion v2\n\nStable Diffusion v2 refers to a specific configuration of the model\narchitecture that uses a downsampling-factor 8 autoencoder with an 865M UNet\nand OpenCLIP ViT-H/14 text encoder for the diffusion model. The _SD 2-v_ model produces 768x768 px outputs. \n\nEvaluations with different classifier-free guidance scales (1.5, 2.0, 3.0, 4.0,\n5.0, 6.0, 7.0, 8.0) and 50 DDIM sampling steps show the relative improvements of the checkpoints:\n\n![sd evaluation results](https://github.com/Stability-AI/stablediffusion/raw/main/assets/model-variants.jpg)\n\n\n\n### Text-to-Image\n![txt2img-stable2](https://github.com/Stability-AI/stablediffusion/raw/main/assets/stable-samples/txt2img/merged-0003.png)\n![txt2img-stable2](https://github.com/Stability-AI/stablediffusion/raw/main/assets/stable-samples/txt2img/merged-0001.png)\n\nStable Diffusion 2 is a latent diffusion model conditioned on the penultimate text embeddings of a CLIP ViT-H/14 text encoder.\nWe provide a [reference script for sampling](#reference-sampling-script).\n#### Reference Sampling Script\n\nThis script incorporates an [invisible watermarking](https://github.com/ShieldMnt/invisible-watermark) of the outputs, to help viewers [identify the images as machine-generated](scripts/tests/test_watermark.py).\nWe provide the configs for the _SD2-v_ (768px) and _SD2-base_ (512px) model.\n\nFirst, download the weights for [_SD2.1-v_](https://huggingface.co/stabilityai/stable-diffusion-2-1) and [_SD2.1-base_](https://huggingface.co/stabilityai/stable-diffusion-2-1-base). \n\nTo sample from the _SD2.1-v_ model, run the following:\n\n```\npython scripts/txt2img.py --prompt \"a professional photograph of an astronaut riding a horse\" --ckpt <path/to/768model.ckpt/> --config configs/stable-diffusion/v2-inference-v.yaml --H 768 --W 768  \n```\nor try out the Web Demo: [![Hugging Face Spaces](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue)](https://huggingface.co/spaces/stabilityai/stable-diffusion).\n\nTo sample from the base model, use\n```\npython scripts/txt2img.py --prompt \"a professional photograph of an astronaut riding a horse\" --ckpt <path/to/model.ckpt/> --config <path/to/config.yaml/>  \n```\n\nBy default, this uses the [DDIM sampler](https://arxiv.org/abs/2010.02502), and renders images of size 768x768 (which it was trained on) in 50 steps. \nEmpirically, the v-models can be sampled with higher guidance scales.\n\nNote: The inference config for all model versions is designed to be used with EMA-only checkpoints. \nFor this reason `use_ema=False` is set in the configuration, otherwise the code will try to switch from\nnon-EMA to EMA weights. \n\n### Image Modification with Stable Diffusion\n\n![depth2img-stable2](https://github.com/Stability-AI/stablediffusion/raw/main/assets/stable-samples/depth2img/merged-0000.png)\n#### Depth-Conditional Stable Diffusion\n\nTo augment the well-established [img2img](https://github.com/CompVis/stable-diffusion#image-modification-with-stable-diffusion) functionality of Stable Diffusion, we provide a _shape-preserving_ stable diffusion model.\n\n\nNote that the original method for image modification introduces significant semantic changes w.r.t. the initial image.\nIf that is not desired, download our [depth-conditional stable diffusion](https://huggingface.co/stabilityai/stable-diffusion-2-depth) model and the `dpt_hybrid` MiDaS [model weights](https://github.com/intel-isl/DPT/releases/download/1_0/dpt_hybrid-midas-501f0c75.pt), place the latter in a folder `midas_models` and sample via \n```\npython scripts/gradio/depth2img.py configs/stable-diffusion/v2-midas-inference.yaml <path-to-ckpt>\n```\n\nor\n\n```\nstreamlit run scripts/streamlit/depth2img.py configs/stable-diffusion/v2-midas-inference.yaml <path-to-ckpt>\n```\n\nThis method can be used on the samples of the base model itself.\nFor example, take [this sample](https://github.com/Stability-AI/stablediffusion/raw/main/assets/stable-samples/depth2img/old_man.png) generated by an anonymous discord user.\nUsing the [gradio](https://gradio.app) or [streamlit](https://streamlit.io/) script `depth2img.py`, the MiDaS model first infers a monocular depth estimate given this input, \nand the diffusion model is then conditioned on the (relative) depth output.\n\n<p align=\"center\">\n<b> depth2image </b><br/>\n<img src=https://github.com/Stability-AI/stablediffusion/raw/main/assets/stable-samples/depth2img/d2i.gif>\n</p>\n\nThis model is particularly useful for a photorealistic style; see the [examples](https://github.com/Stability-AI/stablediffusion/raw/main/assets/stable-samples/depth2img).\nFor a maximum strength of 1.0, the model removes all pixel-based information and only relies on the text prompt and the inferred monocular depth estimate.\n\n![depth2img-stable3](https://github.com/Stability-AI/stablediffusion/raw/main/assets/stable-samples/depth2img/merged-0005.png)\n\n#### Classic Img2Img\n\nFor running the \"classic\" img2img, use\n```\npython scripts/img2img.py --prompt \"A fantasy landscape, trending on artstation\" --init-img <path-to-img.jpg> --strength 0.8 --ckpt <path/to/model.ckpt>\n```\nand adapt the checkpoint and config paths accordingly.\n\n### Image Upscaling with Stable Diffusion\n![upscaling-x4](https://github.com/Stability-AI/stablediffusion/raw/main/assets/stable-samples/upscaling/merged-dog.png)\nAfter [downloading the weights](https://huggingface.co/stabilityai/stable-diffusion-x4-upscaler), run\n```\npython scripts/gradio/superresolution.py configs/stable-diffusion/x4-upscaling.yaml <path-to-checkpoint>\n```\n\nor\n\n```\nstreamlit run scripts/streamlit/superresolution.py -- configs/stable-diffusion/x4-upscaling.yaml <path-to-checkpoint>\n```\n\nfor a Gradio or Streamlit demo of the text-guided x4 superresolution model.  \nThis model can be used both on real inputs and on synthesized examples. For the latter, we recommend setting a higher \n`noise_level`, e.g. `noise_level=100`.\n\n### Image Inpainting with Stable Diffusion\n\n![inpainting-stable2](https://github.com/Stability-AI/stablediffusion/raw/main/assets/stable-inpainting/merged-leopards.png)\n\n[Download the SD 2.0-inpainting checkpoint](https://huggingface.co/stabilityai/stable-diffusion-2-inpainting) and run\n\n```\npython scripts/gradio/inpainting.py configs/stable-diffusion/v2-inpainting-inference.yaml <path-to-checkpoint>\n```\n\nor\n\n```\nstreamlit run scripts/streamlit/inpainting.py -- configs/stable-diffusion/v2-inpainting-inference.yaml <path-to-checkpoint>\n```\n\nfor a Gradio or Streamlit demo of the inpainting model. \nThis scripts adds invisible watermarking to the demo in the [RunwayML](https://github.com/runwayml/stable-diffusion/blob/main/scripts/inpaint_st.py) repository, but both should work interchangeably with the checkpoints/configs.  \n\n\n\n## Shout-Outs\n- Thanks to [Hugging Face](https://huggingface.co/) and in particular [Apolinário](https://github.com/apolinario)  for support with our model releases!\n- Stable Diffusion would not be possible without [LAION](https://laion.ai/) and their efforts to create open, large-scale datasets.\n- The [DeepFloyd team](https://twitter.com/deepfloydai) at Stability AI, for creating the subset of [LAION-5B](https://laion.ai/blog/laion-5b/) dataset used to train the model.\n- Stable Diffusion 2.0 uses [OpenCLIP](https://laion.ai/blog/large-openclip/), trained by [Romain Beaumont](https://github.com/rom1504).  \n- Our codebase for the diffusion models builds heavily on [OpenAI's ADM codebase](https://github.com/openai/guided-diffusion)\nand [https://github.com/lucidrains/denoising-diffusion-pytorch](https://github.com/lucidrains/denoising-diffusion-pytorch). \nThanks for open-sourcing!\n- [CompVis](https://github.com/CompVis/stable-diffusion) initial stable diffusion release\n- [Patrick](https://github.com/pesser)'s [implementation](https://github.com/runwayml/stable-diffusion/blob/main/scripts/inpaint_st.py) of the streamlit demo for inpainting.\n- `img2img` is an application of [SDEdit](https://arxiv.org/abs/2108.01073) by [Chenlin Meng](https://cs.stanford.edu/~chenlin/) from the [Stanford AI Lab](https://cs.stanford.edu/~ermon/website/). \n- [Kat's implementation]((https://github.com/CompVis/latent-diffusion/pull/51)) of the [PLMS](https://arxiv.org/abs/2202.09778) sampler, and [more](https://github.com/crowsonkb/k-diffusion).\n- [DPMSolver](https://arxiv.org/abs/2206.00927) [integration](https://github.com/CompVis/stable-diffusion/pull/440) by [Cheng Lu](https://github.com/LuChengTHU).\n- Facebook's [xformers](https://github.com/facebookresearch/xformers) for efficient attention computation.\n- [MiDaS](https://github.com/isl-org/MiDaS) for monocular depth estimation.\n\n\n## License\n\nThe code in this repository is released under the MIT License.\n\nThe weights are available via [the StabilityAI organization at Hugging Face](https://huggingface.co/StabilityAI), and released under the [CreativeML Open RAIL++-M License](LICENSE-MODEL) License.\n\n## BibTeX\n\n```\n@misc{rombach2021highresolution,\n      title={High-Resolution Image Synthesis with Latent Diffusion Models}, \n      author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Björn Ommer},\n      year={2021},\n      eprint={2112.10752},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV}\n}\n```\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "stable-diffusion-sdkit",
    "package_url": "https://pypi.org/project/stable-diffusion-sdkit/",
    "platform": null,
    "project_url": "https://pypi.org/project/stable-diffusion-sdkit/",
    "project_urls": {
      "Bug Tracker": "https://github.com/Stability-AI/stablediffusion/issues",
      "Homepage": "https://github.com/Stability-AI/stablediffusion"
    },
    "release_url": "https://pypi.org/project/stable-diffusion-sdkit/2.1.4/",
    "requires_dist": [
      "albumentations (==1.3.0)",
      "opencv-python (==4.6.0.66)",
      "pytorch-lightning (==1.4.2)",
      "omegaconf (==2.1.1)",
      "test-tube (>=0.7.5)",
      "einops (==0.3.0)",
      "transformers (==4.26.1)",
      "kornia (==0.6)",
      "open-clip-torch (==2.0.2)",
      "torchmetrics (==0.6.0)",
      "tqdm",
      "huggingface-hub (>=0.10.0)"
    ],
    "requires_python": ">=3.8",
    "summary": "High-Resolution Image Synthesis with Latent Diffusion Models. This is a wrapper around the original repo, to allow installing via pip.",
    "version": "2.1.4",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17328877,
  "releases": {
    "2.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "adaaf7d84b099128763abe165f087e74b61d8f0da64d9528877bc4c7bda0fd5e",
          "md5": "70e939e7072afc8efe8e6df796b68ebc",
          "sha256": "700945299e1dcf478d6ad8f0a0149ec1e632501e3ae7c3a34d1184f51699cc33"
        },
        "downloads": -1,
        "filename": "stable_diffusion_sdkit-2.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "70e939e7072afc8efe8e6df796b68ebc",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 116532,
        "upload_time": "2022-12-23T17:05:45",
        "upload_time_iso_8601": "2022-12-23T17:05:45.143259Z",
        "url": "https://files.pythonhosted.org/packages/ad/aa/f7d84b099128763abe165f087e74b61d8f0da64d9528877bc4c7bda0fd5e/stable_diffusion_sdkit-2.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "74ca71d26e12d8d3aecdbf336a2b837595511317c1ee2d7d1a3171c8c3e8bdbc",
          "md5": "b52ce0541abdfe952fe6cd65288fd830",
          "sha256": "2e6c4d9be268cf887f1f9346e97e6fb6c470de0ae750d079c7f043df54be0bbc"
        },
        "downloads": -1,
        "filename": "stable-diffusion-sdkit-2.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "b52ce0541abdfe952fe6cd65288fd830",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 102458,
        "upload_time": "2022-12-23T17:05:47",
        "upload_time_iso_8601": "2022-12-23T17:05:47.787670Z",
        "url": "https://files.pythonhosted.org/packages/74/ca/71d26e12d8d3aecdbf336a2b837595511317c1ee2d7d1a3171c8c3e8bdbc/stable-diffusion-sdkit-2.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "2.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f210df45915b9e44a59f86676ae19325e1c8a378756e30b92077bf7705db70d5",
          "md5": "35d52039759452336e337ca2a0af62af",
          "sha256": "b00cd1b371dee7277b83a0652037150df0b4643c4c32c11e6c1bc411c0f78808"
        },
        "downloads": -1,
        "filename": "stable_diffusion_sdkit-2.1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "35d52039759452336e337ca2a0af62af",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 116543,
        "upload_time": "2022-12-28T11:20:41",
        "upload_time_iso_8601": "2022-12-28T11:20:41.188469Z",
        "url": "https://files.pythonhosted.org/packages/f2/10/df45915b9e44a59f86676ae19325e1c8a378756e30b92077bf7705db70d5/stable_diffusion_sdkit-2.1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d3e80f4a04d75d925670460441379cedc27d885f75b3c4bbae48378031a801a0",
          "md5": "a61cfe463636610211d7049d53983136",
          "sha256": "63c78671ec77f5646fc2c3397cbbe0a821bdbdc38bbf7971f508f99f7fc71902"
        },
        "downloads": -1,
        "filename": "stable-diffusion-sdkit-2.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "a61cfe463636610211d7049d53983136",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 102471,
        "upload_time": "2022-12-28T11:20:43",
        "upload_time_iso_8601": "2022-12-28T11:20:43.555533Z",
        "url": "https://files.pythonhosted.org/packages/d3/e8/0f4a04d75d925670460441379cedc27d885f75b3c4bbae48378031a801a0/stable-diffusion-sdkit-2.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "2.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8f44accc2133d2ab4459cab684b0553a7500e4cdd30381662c74ba9c466fc540",
          "md5": "3ac1f831ba98101d0731bf88a7838f74",
          "sha256": "c9a6b3e2417746f67aedb5328bc53c7b7acd27cfdafd08f3f43e3472f77c918c"
        },
        "downloads": -1,
        "filename": "stable_diffusion_sdkit-2.1.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "3ac1f831ba98101d0731bf88a7838f74",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 116544,
        "upload_time": "2023-02-18T08:53:37",
        "upload_time_iso_8601": "2023-02-18T08:53:37.976714Z",
        "url": "https://files.pythonhosted.org/packages/8f/44/accc2133d2ab4459cab684b0553a7500e4cdd30381662c74ba9c466fc540/stable_diffusion_sdkit-2.1.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "13373071b3b954215cf3c6c0be93c2589fbe5ea17d640b7d36c2bd5a86bd2fb3",
          "md5": "e57b1e662ae9782ecb4dbd08beacf5a2",
          "sha256": "a40230378c8e90160cbd3710eb1370cbc460ef432931ffa2c2c03c581607a9a6"
        },
        "downloads": -1,
        "filename": "stable-diffusion-sdkit-2.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "e57b1e662ae9782ecb4dbd08beacf5a2",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 102548,
        "upload_time": "2023-02-18T08:53:40",
        "upload_time_iso_8601": "2023-02-18T08:53:40.133272Z",
        "url": "https://files.pythonhosted.org/packages/13/37/3071b3b954215cf3c6c0be93c2589fbe5ea17d640b7d36c2bd5a86bd2fb3/stable-diffusion-sdkit-2.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "2.1.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a99de2fdbb0433e78c2b6ed25ea021b83b875c92290b11185dac378efd3a0627",
          "md5": "3e7819daa07ee7daf7af6624062395a3",
          "sha256": "017acfc3ee4fbf5b2819efa7f37d52cac87dd03c4767c03d23eb239bfcb87215"
        },
        "downloads": -1,
        "filename": "stable_diffusion_sdkit-2.1.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "3e7819daa07ee7daf7af6624062395a3",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 116549,
        "upload_time": "2023-02-18T08:58:16",
        "upload_time_iso_8601": "2023-02-18T08:58:16.135467Z",
        "url": "https://files.pythonhosted.org/packages/a9/9d/e2fdbb0433e78c2b6ed25ea021b83b875c92290b11185dac378efd3a0627/stable_diffusion_sdkit-2.1.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3e0dfd9027c9fe992655dc5dac3dc2ca4f76899210c29a9273a8e1259a902fdf",
          "md5": "9b3c286b8de179b00e8c0e8c86741149",
          "sha256": "9613295b80c515a966ccda12fb4420881f06f0e30f614ae73c0e0111baf464f1"
        },
        "downloads": -1,
        "filename": "stable-diffusion-sdkit-2.1.3.tar.gz",
        "has_sig": false,
        "md5_digest": "9b3c286b8de179b00e8c0e8c86741149",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 102536,
        "upload_time": "2023-02-18T08:58:18",
        "upload_time_iso_8601": "2023-02-18T08:58:18.985584Z",
        "url": "https://files.pythonhosted.org/packages/3e/0d/fd9027c9fe992655dc5dac3dc2ca4f76899210c29a9273a8e1259a902fdf/stable-diffusion-sdkit-2.1.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "2.1.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b66fcf2d5b332e51a397972093f1c495fc5c23ef47752383d5874082067a818d",
          "md5": "8f1e8c693fd037b87e82fd290e2d3f07",
          "sha256": "f47469508e99d92098cb5f7f7daedfb3fe03e4f2359b479cc0cff44794795d51"
        },
        "downloads": -1,
        "filename": "stable_diffusion_sdkit-2.1.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "8f1e8c693fd037b87e82fd290e2d3f07",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 116548,
        "upload_time": "2023-03-17T04:29:36",
        "upload_time_iso_8601": "2023-03-17T04:29:36.403071Z",
        "url": "https://files.pythonhosted.org/packages/b6/6f/cf2d5b332e51a397972093f1c495fc5c23ef47752383d5874082067a818d/stable_diffusion_sdkit-2.1.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a06106d6465767c7ff59c55b5cb7e856706791c6573bbe6b86406f777517bec2",
          "md5": "9c0b3087359a71e4023c7758bd9c30d7",
          "sha256": "37eea0788edbb16bd4319da8d0a49de7521d1595433b8a94a8f1eb5792faeb7c"
        },
        "downloads": -1,
        "filename": "stable-diffusion-sdkit-2.1.4.tar.gz",
        "has_sig": false,
        "md5_digest": "9c0b3087359a71e4023c7758bd9c30d7",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 102570,
        "upload_time": "2023-03-17T04:29:39",
        "upload_time_iso_8601": "2023-03-17T04:29:39.402026Z",
        "url": "https://files.pythonhosted.org/packages/a0/61/06d6465767c7ff59c55b5cb7e856706791c6573bbe6b86406f777517bec2/stable-diffusion-sdkit-2.1.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "b66fcf2d5b332e51a397972093f1c495fc5c23ef47752383d5874082067a818d",
        "md5": "8f1e8c693fd037b87e82fd290e2d3f07",
        "sha256": "f47469508e99d92098cb5f7f7daedfb3fe03e4f2359b479cc0cff44794795d51"
      },
      "downloads": -1,
      "filename": "stable_diffusion_sdkit-2.1.4-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "8f1e8c693fd037b87e82fd290e2d3f07",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.8",
      "size": 116548,
      "upload_time": "2023-03-17T04:29:36",
      "upload_time_iso_8601": "2023-03-17T04:29:36.403071Z",
      "url": "https://files.pythonhosted.org/packages/b6/6f/cf2d5b332e51a397972093f1c495fc5c23ef47752383d5874082067a818d/stable_diffusion_sdkit-2.1.4-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "a06106d6465767c7ff59c55b5cb7e856706791c6573bbe6b86406f777517bec2",
        "md5": "9c0b3087359a71e4023c7758bd9c30d7",
        "sha256": "37eea0788edbb16bd4319da8d0a49de7521d1595433b8a94a8f1eb5792faeb7c"
      },
      "downloads": -1,
      "filename": "stable-diffusion-sdkit-2.1.4.tar.gz",
      "has_sig": false,
      "md5_digest": "9c0b3087359a71e4023c7758bd9c30d7",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.8",
      "size": 102570,
      "upload_time": "2023-03-17T04:29:39",
      "upload_time_iso_8601": "2023-03-17T04:29:39.402026Z",
      "url": "https://files.pythonhosted.org/packages/a0/61/06d6465767c7ff59c55b5cb7e856706791c6573bbe6b86406f777517bec2/stable-diffusion-sdkit-2.1.4.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}