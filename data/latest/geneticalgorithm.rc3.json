{
  "info": {
    "author": "Ryan (Mohammad) Solgi",
    "author_email": "ryan.solgi@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "\n# geneticalgorithm\n\ngeneticalgorithm is a Python library distributed on [Pypi](https://pypi.org) for implementing standard and elitist \n[genetic-algorithm](https://towardsdatascience.com/introduction-to-optimization-with-genetic-algorithm-2f5001d9964b) (GA).\nThis package solves continuous, [combinatorial](https://en.wikipedia.org/wiki/Combinatorial_optimization)\n and mixed [optimization](https://en.wikipedia.org/wiki/Optimization_problem) problems \nwith continuous, discrete, and mixed variables.\nIt provides an easy implementation of genetic-algorithm (GA) in Python.   \n\n## Installation\n\nUse the package manager [pip](https://pip.pypa.io/en/stable/) to install geneticalgorithm in Python.\n\n```python\npip install geneticalgorithm\n```\n## version 1.0.2 updates\n\n@param convergence_curve <True/False> - Plot the convergence curve or not. Default is True.\n@param progress_bar <True/False> - Show progress bar or not. Default is True.\n\n\n## A simple example \nAssume we want to find a set of X=(x1,x2,x3) that minimizes function f(X)=x1+x2+x3 where X can be any real number in \\[0,10\\].  \nThis is a trivial problem and we already know that the answer is X=(0,0,0) where f(X)=0.  \nWe just use this simple example to see how to implement geneticalgorithm:\n\n\nFirst we import geneticalgorithm and [numpy](https://numpy.org). Next, we define \nfunction f which we want to minimize and the boundaries of the decision variables;\nThen simply geneticalgorithm is called to solve the defined optimization problem as follows:\n```python\nimport numpy as np\nfrom geneticalgorithm import geneticalgorithm as ga\n\ndef f(X):\n    return np.sum(X)\n\n\nvarbound=np.array([[0,10]]*3)\n\nmodel=ga(function=f,dimension=3,variable_type='real',variable_boundaries=varbound)\n\nmodel.run()\n\n```\nNotice that we define the function f so that its output is the \nobjective function we want to minimize where the input is the set of X (decision variables).\nThe boundaries for variables must be defined as a numpy array and for each \nvariable we need a separate boundary. Here I have three variables and all of \nthem have the same boundaries (For the case the boundaries are different see the example with mixed variables). \n\n\n\ngeneticalgorithm has some arguments:   \nObviously the first argument is the function f we already defined (for more details about the argument and output see [Function](#1111-id)).  \nOur problem has three variables so we set dimension equal three.   \nVariables are real (continuous) so we use string 'real' to notify the type of \nvariables (geneticalgorithm accepts other types including Boolean, Integers and \nMixed; see other examples).  \nFinally, we input varbound which includes the boundaries of the variables. \nNote that the length of variable_boundaries must be equal to dimension.\n\nIf you run the code, you should see a progress bar that shows the progress of the \ngenetic algorithm (GA) and then the solution, objective function value and the convergence curve as follows:\n\n\n![](https://github.com/rmsolgi/geneticalgorithm/blob/master/genetic_algorithm_convergence.gif)\n\nAlso we can access to the best answer of the defined optimization problem found by geneticalgorithm as a dictionary and a report of the progress of the genetic algorithm. \nTo do so we complete the code as follows:\n```python\nconvergence=model.report\nsolution=model.ouput_dict\n```\n\noutput_dict is a dictionary including the best set of variables found and the value of the given function associated to it ({'variable': , 'function': }). \nreport is a list including the convergence of the algorithm over iterations\n\n## The simple example with integer variables\n\nConsidering the problem given in the simple example above.\nNow assume all variables are integers. So x1, x2, x3 can be any integers in \\[0,10\\].\nIn this case the code is as the following:\n\n```python\nimport numpy as np\nfrom geneticalgorithm import geneticalgorithm as ga\n\ndef f(X):\n    return np.sum(X)\n\n\nvarbound=np.array([[0,10]]*3)\n\nmodel=ga(function=f,dimension=3,variable_type='int',variable_boundaries=varbound)\n\nmodel.run()\n\n\n```\nSo, as it is seen the only difference is that for variable_type we use string 'int'. \n\n## The simple example with Boolean variables\n\nConsidering the problem given in the simple example above.\nNow assume all variables are Boolean instead of real or integer. So X can be either zero or one. Also instead of three let's have 30 variables.\nIn this case the code is as the following:\n\n```python\nimport numpy as np\nfrom geneticalgorithm import geneticalgorithm as ga\n\ndef f(X):\n    return np.sum(X)\n\n\nmodel=ga(function=f,dimension=30,variable_type='bool')\n\nmodel.run()\n\n\n```\n\nNote for variable_type we use string 'bool' when all variables are Boolean.  \nNote that when variable_type equal 'bool' there is no need for variable_boundaries to be defined.\n\n## The simple example with mixed variables\n\nConsidering the problem given in the the simple example above where we want to minimize f(X)=x1+x2+x3. \nNow assume x1 is a real (continuous) variable in \\[0.5,1.5\\], x2 is an integer variable in \\[1,100\\], and x3 is a Boolean variable that can be either zero or one.\nWe already know that the answer is X=(0.5,1,0) where f(X)=1.5\nWe implement geneticalgorithm as the following:\n\n```python\nimport numpy as np\nfrom geneticalgorithm import geneticalgorithm as ga\n\ndef f(X):\n    return np.sum(X)\n\nvarbound=np.array([[0.5,1.5],[1,100],[0,1]])\nvartype=np.array([['real'],['int'],['int']])\nmodel=ga(function=f,dimension=3,variable_type_mixed=vartype,variable_boundaries=varbound)\n\nmodel.run()\n\n```\n\nNote that for mixed variables we need to define boundaries also we need to make a numpy array of variable types as above (vartype). Obviously the order of variables in both arrays must match. Also notice that in such a case for Boolean variables we use string 'int' and boundary \\[0,1\\].  \nNotice that we use argument variable_type_mixed to input a numpy array of variable types for functions with mixed variables.\n\n## Maximization problems\n\ngeneticalgorithm is designed to minimize the given function. A simple trick to \nsolve maximization problems is to multiply the objective function by a negative sign. Then the absolute value of the output is the maximum of the function.\nConsider the above simple example. Now lets find the maximum of f(X)=x1+x2+x3 where X is a set of real variables in \\[0,10\\]. \nWe already know that the answer is X=(10,10,10) where f(X)=30.\n```python\nimport numpy as np\nfrom geneticalgorithm import geneticalgorithm as ga\n\ndef f(X):\n    return -np.sum(X)\n\nvarbound=np.array([[0,10]]*3)\n\nmodel=ga(function=f,dimension=3,variable_type='real',variable_boundaries=varbound)\n\nmodel.run()\n\n```\nAs seen above np.sum(X) is mulitplied by a negative sign. \n\n## Optimization problems with constraints\nIn all above examples, the optimization problem was unconstrained. Now consider that we want to minimize f(X)=x1+x2+x3 where X is a set of real variables in \\[0,10\\]. Also we have an extra constraint so that sum of x1 and x2 is equal or greater than 2. The minimum of f(X) is 2.\nIn such a case, a trick is to define penalty function. Hence we use the code below:\n\n```python\nimport numpy as np\nfrom geneticalgorithm import geneticalgorithm as ga\n\ndef f(X):\n    pen=0\n    if X[0]+X[1]<2:\n        pen=500+1000*(2-X[0]-X[1])\n    return np.sum(X)+pen\n\nvarbound=np.array([[0,10]]*3)\n\nmodel=ga(function=f,dimension=3,variable_type='real',variable_boundaries=varbound)\n\nmodel.run()\n\n```\nAs seen above we add a penalty to the objective function whenever the constraint is not met.  \n\nSome hints about how to define a penalty function:  \n1- Usually you may use a constant greater than the maximum possible value of \nthe objective function if the maximum is known or if we have a guess of that. Here the highest possible value of our function is 300 \n(i.e. if all variables were 10, f(X)=300). So I chose a constant of 500. So, if a trial solution is not in the feasible region even though its objective function may be small, the penalized objective function (fitness function) is worse than any feasible solution.\n2- Use a coefficient big enough and multiply that by the amount of violation. \nThis helps the algorithm learn how to approach feasible domain.\n3- How to define penalty function usually influences the convergence rate of \nan evolutionary algorithm. \nIn my [book on metaheuristics and evolutionary algorithms](https://www.wiley.com/en-us/Meta+heuristic+and+Evolutionary+Algorithms+for+Engineering+Optimization-p-9781119386995) you can learn more about that. \n4- Finally after you solved the problem test the solution to see if boundaries are met. If the solution does not meet \nconstraints, it shows that a bigger penalty is required. However, in problems where \noptimum is exactly on the boundary of the feasible region (or very close to the constraints) which is common in some kinds of problems, a very strict and big penalty may prevent the genetic algorithm\n to approach the optimal region. In such a case designing an appropriate penalty \n function might be more challenging. Actually what we have to do is to design \n a penalty function that let the algorithm searches unfeasible domain while finally \n converge to a feasible solution. Hence you may need more sophisticated penalty \n functions. But in most cases the above formulation work fairly well.\n\n## Genetic algorithm's parameters\n\nEvery evolutionary algorithm (metaheuristic) has some parameters to be adjusted. \n[Genetic algorithm](https://pathmind.com/wiki/evolutionary-genetic-algorithm) \nalso has some parameters. The parameters of geneticalgorithm is defined as a dictionary:\n\n```python\n\nalgorithm_param = {'max_num_iteration': None,\\\n                   'population_size':100,\\\n                   'mutation_probability':0.1,\\\n                   'elit_ratio': 0.01,\\\n                   'crossover_probability': 0.5,\\\n                   'parents_portion': 0.3,\\\n                   'crossover_type':'uniform',\\\n                   'max_iteration_without_improv':None}\n\n```\nThe above dictionary refers to the default values that has been set already. \nOne may simply copy this code from here and change the values and use the modified dictionary as the argument of geneticalgorithm. \nAnother way of accessing this dictionary is using the command below:\n\n```python\nimport numpy as np\nfrom geneticalgorithm import geneticalgorithm as ga\n\ndef f(X):\n    return np.sum(X)\n\n\nmodel=ga(function=f,dimension=3,variable_type='bool')\n\nprint(model.param)\n\n```\n\nAn example of setting a new set of parameters for genetic algorithm and running geneticalgorithm for our first simple example again:\n\n```python\nimport numpy as np\nfrom geneticalgorithm import geneticalgorithm as ga\n\ndef f(X):\n    return np.sum(X)\n\n\nvarbound=np.array([[0,10]]*3)\n\nalgorithm_param = {'max_num_iteration': 3000,\\\n                   'population_size':100,\\\n                   'mutation_probability':0.1,\\\n                   'elit_ratio': 0.01,\\\n                   'crossover_probability': 0.5,\\\n                   'parents_portion': 0.3,\\\n                   'crossover_type':'uniform',\\\n                   'max_iteration_without_improv':None}\n\nmodel=ga(function=f,\\\n            dimension=3,\\\n            variable_type='real',\\\n            variable_boundaries=varbound,\\\n            algorithm_parameters=algorithm_param)\n\nmodel.run()\n\n\n```\n\nNotice that max_num_iteration has been changed to 3000 (it was already None). \nIn the above gif we saw that the algorithm run for 1500 iterations. \nSince we did not define parameters geneticalgorithm applied the default values. \nHowever if you run this code geneticalgroithm executes 3000 iterations this time.  \nTo change other parameters one may simply replace the values according to \n[Arguments](#1112-id). \n\n@ max_num_iteration: The termination criterion of geneticalgorithm. \nIf this parameter's value is None the algorithm sets maximum number of iterations\nautomatically as a function of the dimension, boundaries, and population size. The user may enter\nany number of iterations that they want. It is highly recommended that the user themselves determines the max_num_iterations and not to use None.\n\n@ population_size: determines the number of trial solutions in each iteration.\nThe default value is 100.\n\n@ mutation_probability: determines the chance of each gene in each individual solution\nto be replaced by a random value. The default is 0.1 (i.e. 10 percent). \n\n@ elit_ration: determines the number of elites in the population. The default value is \n0.01 (i.e. 1 percent). For example when population size is 100 and elit_ratio is \n0.01 then there is one elite in the population. If this parameter is set to be zero then\ngeneticalgorithm implements a standard genetic algorithm instead of elitist GA. \n\n@ crossover_probability: determines the chance of an existed solution to pass its \ngenome (aka characteristics) to new trial solutions (aka offspring); the default value is 0.5 (i.e. 50 percent)\n\n@ parents_portion: the portion of population filled by the members of the previous generation (aka parents); \ndefault is 0.3 (i.e. 30 percent of population)\n\n@ crossover_type: there are three options including one_point; two_point, and uniform crossover functions; \ndefault is uniform crossover\n\n@ max_iteration_without_improv: if the algorithms does not improve the objective function\nover the number of successive iterations determined by this parameter, then geneticalgorithm\nstops and report the best found solution before the max_num_iterations to be met. The default value is None. \n\n## <a name=\"1111-id\"></a>Function \nThe given function to be optimized must only accept one argument and return a scalar. \nThe argument of the given function is a numpy array which is entered by geneticalgorithm.\nFor any reason if you do not want to work with numpy in your function you may \n[turn the numpy array to a list](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.ndarray.tolist.html).\n\n## <a name=\"1112-id\"></a>Arguments\n\n@param function <Callable> - the given objective function to be minimized  \nNOTE: This implementation minimizes the given objective function. (For maximization \nmultiply function by a negative sign: the absolute value of the output would be \nthe actual objective function)\n\n@param dimension <integer> - the number of decision variables\n\n@param variable_type <string> - 'bool' if all variables are Boolean; 'int' if all \nvariables are integer; and 'real' if all variables are real value or continuous \n(for mixed type see @param variable_type_mixed). \n\n@param variable_boundaries <numpy array/None> - Default None; leave it None if \nvariable_type is 'bool'; otherwise provide an array of tuples of length two as \nboundaries for each variable; the length of the array must be equal dimension. \nFor example, np.array(\\[0,100\\],\\[0,200\\]) determines lower boundary 0 and upper boundary 100 \nfor first and upper boundary 200 for second variable where dimension is 2.\n\n@param variable_type_mixed <numpy array/None> - Default None; leave it None if all variables have the same type; otherwise this can be used to specify the type of each variable separately. For example if the first \nvariable is integer but the second one is real the input is: \nnp.array(\\['int'\\],\\['real'\\]). NOTE: it does not accept 'bool'. If variable\ntype is Boolean use 'int' and provide a boundary as \\[0,1\\] \nin variable_boundaries. Also if variable_type_mixed is applied, \nvariable_boundaries has to be defined.\n\n@param function_timeout <float> - if the given function does not provide \noutput before function_timeout (unit is seconds) the algorithm raise error.\nFor example, when there is an infinite loop in the given function. \n\n@param algorithm_parameters:  \n@ max_num_iteration <int/None> - stoping criteria of the genetic algorithm (GA)  \n@ population_size <int>   \n@ mutation_probability <float in \\[0,1\\]>  \n@ elit_ration <float in \\[0,1\\]>  \n@ crossover_probability <float in \\[0,1\\]>  \n@ parents_portion <float in \\[0,1\\]>  \n@ crossover_type <string> - Default is 'uniform'; 'one_point' or 'two_point' \nare other options\n@ max_iteration_without_improv <int/None> - maximum number of \nsuccessive iterations without improvement. If None it is ineffective\n\n\n## Methods and Outputs:\n\nmethods:    \nrun(): implements the genetic algorithm (GA)  \n\nparam: a dictionary of parameters of the genetic algorithm (GA)\n\noutput:  \n\noutput_dict: is a dictionary including the best set of variables\nfound and the value of the given function associated to it.\n{'variable': , 'function': }\n\nreport: is a record of the progress of the\nalgorithm over iterations\n\n\n## Function timeout\n\ngeneticalgorithm is designed such that if the given function does not provide\nany output before timeout (the default value is 10 seconds), the algorithm\nwould be terminated and raise the appropriate error. In such a case make sure the given function\nworks correctly (i.e. there is no infinite loop in the given function). Also if the given function takes more than 10 seconds to complete the work\nmake sure to increase function_timeout in arguments.\n\n## Standard GA vs. Elitist GA\n\nThe convergence curve of an elitist genetic algorithm is always non-increasing. So,\nthe best ever found solution is equal to the best solution of the last iteration. However,\nthe convergence curve of a standard genetic algorithm is different. If elit_ratio is zero\ngeneticalgroithm implements a standard GA. The output of geneticalgorithm for standard GA is the best\never found solution not the solution of the last iteration. The difference \nbetween the convergence curve of standard GA and elitist GA is shown below:\n\n![](https://github.com/rmsolgi/geneticalgorithm/blob/master/genetic_algorithm_convergence_curve.gif)\n\n## Hints on how to adjust genetic algorithm's parameters\n\nIn general the performance of a genetic algorithm or any evolutionary algorithm\ndepends on its parameters. Parameter setting of an evolutionary algorithm is important. Usually these parameters are adjusted based on experience and by conducting a sensitivity analysis.\nIt is impossible to provide a general guideline to parameter setting but the suggestions provided below may help:  \n\nNumber of iterations: Select a max_num_iterations sufficienlty large; otherwise the reported solution may not be satisfactory. On the other hand \nselecting a very large number of iterations increases the run time significantly. So this is actually a compromise between\nthe accuracy you want and the time and computational cost you spend. \n\nPopulation size: Given a constant number of functional evaluations (max_num_iterations times population_size) I would \nselect smaller population size and greater iterations. However, a very small choice of \npopulation size is also deteriorative. For most problems I would select a population size of 100 unless the dimension of the problem is very large that needs a bigger population size.\n\nelit_ratio: Although having few elites is usually a good idea and may increase the rate of \nconvergence in some problems, having too many elites in the population may cause the algorithm to easily trap in a local optima. I would usually select only one elite in most cases. Elitism is not always necessary and in some problems may even be deteriorative.\n\nmutation_probability: This is a parameter you may need to adjust more than the other ones. Its appropriate value heavily depends on the problem. Sometimes we may select\nmutation_probability as small as 0.01 (i.e. 1 percent) and sometimes even as large as 0.5 (i.e. 50 percent) or even larger. In general if the genetic algorithm trapped \nin a local optimum increasing the mutation probability may help. On the other hand if the algorithm suffers from stagnation reducing the mutation probability may be effective. However, this rule of thumb is not always true.\n\nparents_portion: If parents_portion set zero, it means that the whole of the population is filled with the newly generated solutions. \nOn the other hand having this parameter equals 1 (i.e. 100 percent) means no new solution\nis generated and the algorithm would just repeat the previous values without any change which is not meaningful and effective obviously. Anything between these two may work. The exact value depends on the problem.\n\n\ncrossover_type: Depends on the problem. I would usually use uniform crossover. But testing the other ones in your problem is recommended.\n\nmax_iteration_without_improv: This is a parameter that I recommend being used cautiously. \nIf this parameter is too small then the algorithm may stop while it trapped in a local optimum.\nSo make sure you select a sufficiently large criteria to provide enough time for the algorithm to progress and to avoid immature convergence. \n\nFinally to make sure that the parameter setting is fine, we usually should run the \nalgorithm for several times and if connvergence curves of all runs converged to the same objective function value we may accept that solution as the optimum. The number of runs\ndepends but usually five or ten runs is prevalent. Notice that in some problems\nseveral possible set of variables produces the same objective function value. \nWhen we study the convergence of a genetic algorithm we compare the objective function values not the decision variables.\n\n## Optimization test functions\n\nImplementation of geneticalgorithm for some benchmark problems:\n\n## [Rastrigin](https://en.wikipedia.org/wiki/Rastrigin_function)\n\n![](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8b/Rastrigin_function.png/600px-Rastrigin_function.png)\n\n\n```python\n\nimport numpy as np\nimport math\nfrom geneticalgorithm import geneticalgorithm as ga\n\ndef f(X):\n\n    dim=len(X)         \n\n    OF=0\n    for i in range (0,dim):\n        OF+=(X[i]**2)-10*math.cos(2*math.pi*X[i])+10\n\n    return OF\n\n\nvarbound=np.array([[-5.12,5.12]]*2)\n\nmodel=ga(function=f,dimension=2,variable_type='real',variable_boundaries=varbound)\n\nmodel.run()\n\n```\n\n![](https://github.com/rmsolgi/geneticalgorithm/blob/master/genetic_algorithm_Rastrigin.gif)\n\n\n## [Ackley](https://en.wikipedia.org/wiki/Ackley_function)\n![](https://upload.wikimedia.org/wikipedia/commons/thumb/9/98/Ackley%27s_function.pdf/page1-600px-Ackley%27s_function.pdf.jpg)\n\n```python\n\nimport numpy as np\nimport math\nfrom geneticalgorithm import geneticalgorithm as ga\n\ndef f(X):\n\n    dim=len(X)\n\n    t1=0\n    t2=0\n    for i in range (0,dim):\n        t1+=X[i]**2\n        t2+=math.cos(2*math.pi*X[i])     \n\n    OF=20+math.e-20*math.exp((t1/dim)*-0.2)-math.exp(t2/dim)\n\n    return OF\n\nvarbound=np.array([[-32.768,32.768]]*2)\n\nmodel=ga(function=f,dimension=2,variable_type='real',variable_boundaries=varbound)\n\nmodel.run()\n\n```\n\n![](https://github.com/rmsolgi/geneticalgorithm/blob/master/genetic_algorithm_Ackley.gif)\n\n## [Weierstrass](http://infinity77.net/global_optimization/test_functions_nd_W.html)\n![](http://infinity77.net/global_optimization/_images/Weierstrass.png)\n\n\n```python\n\nimport numpy as np\nimport math\nfrom geneticalgorithm import geneticalgorithm as ga\n\ndef f(X):\n\n    dim=len(X) \n\n    a=0.5\n    b=3\n    OF=0\n    for i in range (0,dim):\n        t1=0\n        for k in range (0,21):\n            t1+=(a**k)*math.cos((2*math.pi*(b**k))*(X[i]+0.5))\n        OF+=t1\n    t2=0    \n    for k in range (0,21):\n        t2+=(a**k)*math.cos(math.pi*(b**k))\n    OF-=dim*t2\n\n    return OF\n\n\nvarbound=np.array([[-0.5,0.5]]*2)\n\nalgorithm_param = {'max_num_iteration': 1000,\\\n                   'population_size':100,\\\n                   'mutation_probability':0.1,\\\n                   'elit_ratio': 0.01,\\\n                   'crossover_probability': 0.5,\\\n                   'parents_portion': 0.3,\\\n                   'crossover_type':'uniform',\\\n                   'max_iteration_without_improv':None}\n\nmodel=ga(function=f,dimension=2,\\\n         variable_type='real',\\\n             variable_boundaries=varbound,\n             algorithm_parameters=algorithm_param)\n\nmodel.run()\n\n```\n![](https://github.com/rmsolgi/geneticalgorithm/blob/master/genetic_algorithm_Weierstrass.gif)\n## License\n\nCopyright 2020 Ryan (Mohammad) Solgi\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of \nthis software and associated documentation files (the \"Software\"), to deal in \nthe Software without restriction, including without limitation the rights to use, \ncopy, modify, merge, publish, distribute, sublicense, and/or sell copies of the \nSoftware, and to permit persons to whom the Software is furnished to do so, \nsubject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR \nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, \nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL \nTHE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER \nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, \nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE \nSOFTWARE.\n\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/rmsolgi/geneticalgorithm",
    "keywords": "solve,optimization,problem,genetic,algorithm,GA,easy,fast,genetic-algorithm,combinatorial,mixed,evolutionary",
    "license": "",
    "maintainer": "Ryan (Mohammad) Solgi",
    "maintainer_email": "",
    "name": "geneticalgorithm",
    "package_url": "https://pypi.org/project/geneticalgorithm/",
    "platform": "",
    "project_url": "https://pypi.org/project/geneticalgorithm/",
    "project_urls": {
      "Homepage": "https://github.com/rmsolgi/geneticalgorithm"
    },
    "release_url": "https://pypi.org/project/geneticalgorithm/1.0.2/",
    "requires_dist": [
      "func-timeout",
      "numpy"
    ],
    "requires_python": "",
    "summary": "An easy implementation of genetic-algorithm (GA) to solve continuous and combinatorial optimization problems with real, integer, and mixed variables in Python",
    "version": "1.0.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8994309,
  "releases": {
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b3f3d168e46d453cf46604fa4ee8b1e3f2a1ff45b319fbe881c5d140b468dcb3",
          "md5": "f2619e14b065c09926daeffd39b1e6af",
          "sha256": "b9a4e5a3f5ce7ba1b8bb763eec715ff59d157ffced9486557a862fe18b2d4c4f"
        },
        "downloads": -1,
        "filename": "geneticalgorithm-1.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f2619e14b065c09926daeffd39b1e6af",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 15825,
        "upload_time": "2020-05-04T04:27:29",
        "upload_time_iso_8601": "2020-05-04T04:27:29.696501Z",
        "url": "https://files.pythonhosted.org/packages/b3/f3/d168e46d453cf46604fa4ee8b1e3f2a1ff45b319fbe881c5d140b468dcb3/geneticalgorithm-1.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7da2fd586bc7210d7d2551ab1907565e6bbad0adf53d8171c08411f8b8961756",
          "md5": "9acbca643d038b807000bab7300f240c",
          "sha256": "982881ef2ca95b864f67f2f244aaf59be4ccb3ef7afca23d6554869e28d3bee5"
        },
        "downloads": -1,
        "filename": "geneticalgorithm-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "9acbca643d038b807000bab7300f240c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 21472,
        "upload_time": "2020-05-04T04:27:32",
        "upload_time_iso_8601": "2020-05-04T04:27:32.213025Z",
        "url": "https://files.pythonhosted.org/packages/7d/a2/fd586bc7210d7d2551ab1907565e6bbad0adf53d8171c08411f8b8961756/geneticalgorithm-1.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d3abe62b94f9baa4b27bb45b1cc9ae315ecaee53ca96c16da5c4ad18e00dd45b",
          "md5": "a685e919e657c8b0bf5625ae140cab26",
          "sha256": "04e383d42648c18a7a51ea8036afa25934e3bd6e22bb708b86af49681b1b2974"
        },
        "downloads": -1,
        "filename": "geneticalgorithm-1.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "a685e919e657c8b0bf5625ae140cab26",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 15846,
        "upload_time": "2020-05-04T05:11:57",
        "upload_time_iso_8601": "2020-05-04T05:11:57.333269Z",
        "url": "https://files.pythonhosted.org/packages/d3/ab/e62b94f9baa4b27bb45b1cc9ae315ecaee53ca96c16da5c4ad18e00dd45b/geneticalgorithm-1.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c46d9b92691ae850286df0de8081f5a64277eda63f719265240707d62f67f444",
          "md5": "91d02a2fd90861cf57d54f9cc1512532",
          "sha256": "c37651fd6f1877aab16e4131f524344879dd00267a986e38f22544262933eefa"
        },
        "downloads": -1,
        "filename": "geneticalgorithm-1.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "91d02a2fd90861cf57d54f9cc1512532",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 21592,
        "upload_time": "2020-05-04T05:11:58",
        "upload_time_iso_8601": "2020-05-04T05:11:58.722562Z",
        "url": "https://files.pythonhosted.org/packages/c4/6d/9b92691ae850286df0de8081f5a64277eda63f719265240707d62f67f444/geneticalgorithm-1.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "acd2fb9061239eaeee5c0373844f27f43514f33201bc08aea54d65b437402966",
          "md5": "a4e2608661ce440548da9643454c06d3",
          "sha256": "24b73642396256d9393ae86902143c14ffdb43ef9345da9d3e888a5e69bc16ae"
        },
        "downloads": -1,
        "filename": "geneticalgorithm-1.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "a4e2608661ce440548da9643454c06d3",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 16074,
        "upload_time": "2020-12-27T22:50:01",
        "upload_time_iso_8601": "2020-12-27T22:50:01.303167Z",
        "url": "https://files.pythonhosted.org/packages/ac/d2/fb9061239eaeee5c0373844f27f43514f33201bc08aea54d65b437402966/geneticalgorithm-1.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "acd2fb9061239eaeee5c0373844f27f43514f33201bc08aea54d65b437402966",
        "md5": "a4e2608661ce440548da9643454c06d3",
        "sha256": "24b73642396256d9393ae86902143c14ffdb43ef9345da9d3e888a5e69bc16ae"
      },
      "downloads": -1,
      "filename": "geneticalgorithm-1.0.2-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "a4e2608661ce440548da9643454c06d3",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 16074,
      "upload_time": "2020-12-27T22:50:01",
      "upload_time_iso_8601": "2020-12-27T22:50:01.303167Z",
      "url": "https://files.pythonhosted.org/packages/ac/d2/fb9061239eaeee5c0373844f27f43514f33201bc08aea54d65b437402966/geneticalgorithm-1.0.2-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}