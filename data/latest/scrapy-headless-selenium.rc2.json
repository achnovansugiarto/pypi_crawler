{
  "info": {
    "author": "",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# Scrapy with Headless Selenium\n\nScrapy middleware to handle dynamic web pages, using Selenium and running in headless mode by default:\n\n1. Running in headless mode by default\n2. Running by default with ad blocking browser plugin, for faster scraping (only for FireFox, see [this issue](https://bugs.chromium.org/p/chromium/issues/detail?id=706008#c5))\n3. Dynamic responses, to allow interaction with the web page being scraped\n\n## Installation\n```\n$ pip install scrapy-headless-selenium\n```\nYou should use **python>=3.6**.\nYou will also need one of the Selenium compatible browsers and drivers (FireFox & geckodriver or Chrome & chromium-driver).\n\n## Configuration\n1. Add the browser to use, the path to the driver executable, and the arguments to pass to the executable to the scrapy settings:\n    ```python\n    from shutil import which\n\n    SELENIUM_DRIVER_NAME = 'firefox'\n    SELENIUM_DRIVER_EXECUTABLE_PATH = which('geckodriver')\n    SELENIUM_DRIVER_ARGUMENTS = ['-headless']  # '--headless' if using chrome instead of firefox\n    ```\n\nOptionally, set the path to the browser executable:\n    ```python\n    SELENIUM_BROWSER_EXECUTABLE_PATH = which('firefox')\n    ```\n\n2. Add the `SeleniumMiddleware` to the downloader middlewares and to the spider middlewares:\n    ```python\n    DOWNLOADER_MIDDLEWARES = {\n        'scrapy_headless.SeleniumMiddleware': 800\n    }\n    SPIDER_MIDDLEWARES = {\n        'scrapy_headless.SeleniumMiddleware': 800\n    }\n    ```\n## Usage\nUse the `scrapy_headless.SeleniumRequest` instead of the scrapy built-in `Request` like below:\n```python\nfrom scrapy_headless import SeleniumRequest\n\nyield SeleniumRequest(url, self.parse_result)\n```\nThe request will be handled by selenium, and the request will have an additional `meta` key, named `driver` containing the selenium driver with the request processed.\n```python\ndef parse_result(self, response):\n    print(response.request.meta['driver'].title)\n```\nFor more information about the available driver methods and attributes, refer to the [selenium python documentation](http://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.remote.webdriver)\n\nThe `selector` response attribute work as usual (but contains the html processed by the selenium driver).\n```python\ndef parse_result(self, response):\n    print(response.selector.xpath('//title/@text'))\n```\n\nThe Selenium WebDriver is also exposed through the `response.interact` property, to allow interaction with the browser.\nThe response also implements a `click` method which excepts a CSS / XPATH selector, to click on an element and return a new response with the new body:\n```python\ndef parse_result(self, response):\n    response = response.click('#id')  # equivalent to response.click('//[@id=\"id\"]')\n    print(response.selector.xpath('//title/@text'))  # searches the reloaded response body\n```\n\n### Additional arguments\nThe `scrapy_headless.SeleniumRequest` accept 4 additional arguments:\n\n#### `wait_time` / `wait_until`\n\nWhen used, selenium will perform an [Explicit wait](http://selenium-python.readthedocs.io/waits.html#explicit-waits) before returning the response to the spider.\n```python\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support import expected_conditions as EC\n\nyield SeleniumRequest(\n    url=url,\n    callback=self.parse_result,\n    wait_time=10,\n    wait_until=EC.element_to_be_clickable((By.ID, 'someid'))\n)\n```\n\n#### `screenshot`\nWhen used, selenium will take a screenshot of the page and the binary data of the .png captured will be added to the response `meta`:\n```python\nyield SeleniumRequest(\n    url=url,\n    callback=self.parse_result,\n    screenshot=True\n)\n\ndef parse_result(self, response):\n    with open('image.png', 'wb') as image_file:\n        image_file.write(response.meta['screenshot'])\n```\n\n#### `script`\nWhen used, selenium will execute custom JavaScript code.\n```python\nyield SeleniumRequest(\n    url,\n    self.parse_result,\n    script='window.scrollTo(0, document.body.scrollHeight);',\n)\n```\n\n## Thanks\nSpecial thanks to @clemfromspace which wrote [scrapy-selenium](https://github.com/clemfromspace/scrapy-selenium), which is the original fork for this project.",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/OryJonay/scrapy-headless",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "scrapy-headless-selenium",
    "package_url": "https://pypi.org/project/scrapy-headless-selenium/",
    "platform": "",
    "project_url": "https://pypi.org/project/scrapy-headless-selenium/",
    "project_urls": {
      "Homepage": "https://github.com/OryJonay/scrapy-headless"
    },
    "release_url": "https://pypi.org/project/scrapy-headless-selenium/0.1.2/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "Scrapy with Headless Selenium",
    "version": "0.1.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 9042162,
  "releases": {
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5d8d3beeceed6c619e785082f119b9dd79f688c9bde8a9536408d60a2eb0b95d",
          "md5": "de9c55f6267476af9d8b323b01568a6b",
          "sha256": "39d84f33a9189de13c2a4c6be4de629f651c3dc240b83b7598a7cbfa7a29bc33"
        },
        "downloads": -1,
        "filename": "scrapy-headless-selenium-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "de9c55f6267476af9d8b323b01568a6b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 5311,
        "upload_time": "2020-12-25T14:40:11",
        "upload_time_iso_8601": "2020-12-25T14:40:11.970060Z",
        "url": "https://files.pythonhosted.org/packages/5d/8d/3beeceed6c619e785082f119b9dd79f688c9bde8a9536408d60a2eb0b95d/scrapy-headless-selenium-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "be2ce8f345bdd2358a688c81176dcf0a964c5d5e6f3a65858c9f632f1cd7b937",
          "md5": "b7752e4250458f49b7173fb5a10aa91c",
          "sha256": "42e08217d4e56965990ccee77b5815d0139e02839930bc6f68e628c4028ffe58"
        },
        "downloads": -1,
        "filename": "scrapy-headless-selenium-0.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "b7752e4250458f49b7173fb5a10aa91c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 2564870,
        "upload_time": "2021-01-03T13:34:00",
        "upload_time_iso_8601": "2021-01-03T13:34:00.682414Z",
        "url": "https://files.pythonhosted.org/packages/be/2c/e8f345bdd2358a688c81176dcf0a964c5d5e6f3a65858c9f632f1cd7b937/scrapy-headless-selenium-0.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "be2ce8f345bdd2358a688c81176dcf0a964c5d5e6f3a65858c9f632f1cd7b937",
        "md5": "b7752e4250458f49b7173fb5a10aa91c",
        "sha256": "42e08217d4e56965990ccee77b5815d0139e02839930bc6f68e628c4028ffe58"
      },
      "downloads": -1,
      "filename": "scrapy-headless-selenium-0.1.2.tar.gz",
      "has_sig": false,
      "md5_digest": "b7752e4250458f49b7173fb5a10aa91c",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 2564870,
      "upload_time": "2021-01-03T13:34:00",
      "upload_time_iso_8601": "2021-01-03T13:34:00.682414Z",
      "url": "https://files.pythonhosted.org/packages/be/2c/e8f345bdd2358a688c81176dcf0a964c5d5e6f3a65858c9f632f1cd7b937/scrapy-headless-selenium-0.1.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}