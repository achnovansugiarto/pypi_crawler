{
  "info": {
    "author": "Dillon Mabry",
    "author_email": "rapid.dev.solutions@gmail.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# Reddit Comments Analyzer\n[![Build Status](https://travis-ci.org/dillonmabry/youtube-sentiment-helper.svg?branch=master)](https://travis-ci.org/dillonmabry/reddit-comments-tool)\n[![Python 3.4](https://img.shields.io/badge/python-3.4-blue.svg)](https://www.python.org/downloads/release/python-340/)\n[![Python 3.5](https://img.shields.io/badge/python-3.5-blue.svg)](https://www.python.org/downloads/release/python-350/)\n[![Python 3.6](https://img.shields.io/badge/python-3.6-blue.svg)](https://www.python.org/downloads/release/python-360/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\nGeneral package for reddit comments analysis, data manipulation, and other areas\n\n## Install Instructions\n```\npip install .\n```\nor for released version:\n```\npip install reddit-extract\n```\n\n## How to Use\nRequired:\n- Reddit Client ID\n- Reddit Client Secret\n- Reddit User Agent\n- Subreddit\n- List of Thread IDs for bulk extract of multiple Reddit threads\n- Dictionary (Should match your regex search pattern, otherwise your headers will not match the data retrieved, for example: a defined copy/paste form for a reddit thread that users reply to, aka \"Megathreads\")\n- Regex Pattern (for csv)\n\nExtracting all comments for list of threads to csv with defined headers and search pattern:\n```\nimport reddit_extract\nreddit_extract.extract_comments_csv_bulk(<Reddit ClientID>, <Reddit ClientSecret>, <Reddit User Agent>, <Subreddit>, <Thread IDs>, <Dictionary Headers>)\n```\n\nExtracting all comments for list of threads to txt:\n```\nimport reddit_extract\nreddit_extract.extract_comments_txt_bulk(<Reddit ClientID>, <Reddit ClientSecret>, <Reddit User Agent>, <Subreddit>, <Thread IDs>)\n```\n\nExample:\n```\nimport reddit_extract\nthreads = ['aw79c5', 'b7x7n1', 'am5uk7', 'bji681', 'abv2gl', '9klf8e']\nsearch_pattern = r'Form: (.*)\\n*Entity: (.*)\\n*Pending: (.*)\\n*Approved: (.*)\\n*Standardized wait: (.*)\\n*STATE: (.*)'\nheaders = {'Form': 'Form', 'Entity': 'Entity', 'Pending': 'Pending', 'Approved': 'Approved', 'Standardized Wait': 'Standardized Wait', 'STATE': 'STATE'}\nreddit_extract.extract_comments_csv_bulk(<client_id>, <client_secret>, <user_agent>, 'nfa', threads, headers, search_pattern)\n```\n\n## Tests\n```\npython setup.py test\n```",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/dillonmabry/reddit-comments-tool",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "reddit-extract",
    "package_url": "https://pypi.org/project/reddit-extract/",
    "platform": "",
    "project_url": "https://pypi.org/project/reddit-extract/",
    "project_urls": {
      "Homepage": "https://github.com/dillonmabry/reddit-comments-tool"
    },
    "release_url": "https://pypi.org/project/reddit-extract/0.2.0/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "Tool for extracting reddit comments",
    "version": "0.2.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 5347279,
  "releases": {
    "0.1.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "311a044441f695d2222843ee63a743e17d9391b7c4495f6a5730d176b2762401",
          "md5": "d887f08373912d1d5a2c93b86970f05a",
          "sha256": "da299dc594bb85e10a1caa33a6deb4cfbbfa99bdd304bec2903b6a2d61e441b6"
        },
        "downloads": -1,
        "filename": "reddit_extract-0.1.5.tar.gz",
        "has_sig": false,
        "md5_digest": "d887f08373912d1d5a2c93b86970f05a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 5203,
        "upload_time": "2019-05-04T01:20:25",
        "upload_time_iso_8601": "2019-05-04T01:20:25.323729Z",
        "url": "https://files.pythonhosted.org/packages/31/1a/044441f695d2222843ee63a743e17d9391b7c4495f6a5730d176b2762401/reddit_extract-0.1.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "225e56fa37b092a6e1c0ee2099081f9890d941f5d0c3396e7cf20afc48679fb7",
          "md5": "35fbac3df18b2bbb941582c997da1057",
          "sha256": "7a0eaa749632223bfecaed7a772c43d3566e9687de8945adf4d0b427826cef9b"
        },
        "downloads": -1,
        "filename": "reddit_extract-0.1.6.tar.gz",
        "has_sig": false,
        "md5_digest": "35fbac3df18b2bbb941582c997da1057",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 5247,
        "upload_time": "2019-05-04T01:25:41",
        "upload_time_iso_8601": "2019-05-04T01:25:41.651468Z",
        "url": "https://files.pythonhosted.org/packages/22/5e/56fa37b092a6e1c0ee2099081f9890d941f5d0c3396e7cf20afc48679fb7/reddit_extract-0.1.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b5d2a960b687ce52c887a9c6349255a411b90902578c64a5245b9501442ee63f",
          "md5": "116677c8d1962c34e1fa8fa3df1f9760",
          "sha256": "0abf19cfac08d2ad4552a4ce085b60e83ea01c7ffc9a25a4878e63e63fa3364c"
        },
        "downloads": -1,
        "filename": "reddit_extract-0.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "116677c8d1962c34e1fa8fa3df1f9760",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 6191,
        "upload_time": "2019-06-01T20:37:53",
        "upload_time_iso_8601": "2019-06-01T20:37:53.738831Z",
        "url": "https://files.pythonhosted.org/packages/b5/d2/a960b687ce52c887a9c6349255a411b90902578c64a5245b9501442ee63f/reddit_extract-0.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "b5d2a960b687ce52c887a9c6349255a411b90902578c64a5245b9501442ee63f",
        "md5": "116677c8d1962c34e1fa8fa3df1f9760",
        "sha256": "0abf19cfac08d2ad4552a4ce085b60e83ea01c7ffc9a25a4878e63e63fa3364c"
      },
      "downloads": -1,
      "filename": "reddit_extract-0.2.0.tar.gz",
      "has_sig": false,
      "md5_digest": "116677c8d1962c34e1fa8fa3df1f9760",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 6191,
      "upload_time": "2019-06-01T20:37:53",
      "upload_time_iso_8601": "2019-06-01T20:37:53.738831Z",
      "url": "https://files.pythonhosted.org/packages/b5/d2/a960b687ce52c887a9c6349255a411b90902578c64a5245b9501442ee63f/reddit_extract-0.2.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}