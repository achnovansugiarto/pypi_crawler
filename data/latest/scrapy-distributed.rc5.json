{
  "info": {
    "author": "Insutanto",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: BSD License",
      "Operating System :: OS Independent",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: Implementation :: CPython",
      "Programming Language :: Python :: Implementation :: PyPy",
      "Topic :: Internet :: WWW/HTTP",
      "Topic :: Software Development :: Libraries :: Application Frameworks",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "# **Scrapy-Distributed**\n\n`Scrapy-Distributed` is a series of components for you to develop a distributed crawler base on `Scrapy` in an easy way.\n\nNow! `Scrapy-Distributed` has supported `RabbitMQ Scheduler`, `Kafka Scheduler` and `RedisBloom DupeFilter`. You can use either of those in your Scrapy's project very easily.\n\n## **Features**\n\n- RabbitMQ Scheduler\n    - Support custom declare a RabbitMQ's Queue. Such as `passive`, `durable`, `exclusive`, `auto_delete`, and all other options.\n- RabbitMQ Pipeline\n    - Support custom declare a RabbitMQ's Queue for the items of spider. Such as `passive`, `durable`, `exclusive`, `auto_delete`, and all other options.\n- Kafaka Scheduler\n    - Support custom declare a Kafka's Topic. Such as `num_partitions`, `replication_factor` and will support other options.\n- RedisBloom DupeFilter\n    - Support custom the `key`, `errorRate`, `capacity`, `expansion` and auto-scaling(`noScale`) of a bloom filter.\n\n## **Requirements**\n\n- Python >= 3.6\n- Scrapy >= 1.8.0\n- Pika >= 1.0.0\n- RedisBloom >= 0.2.0\n- Redis >= 3.0.1\n- kafka-python >= 1.4.7\n\n## **TODO**\n\n- ~~RabbitMQ Item Pipeline~~\n- Support Delayed Message in RabbitMQ Scheduler\n- Support Scheduler Serializer\n- Custom Interface for DupeFilter\n- RocketMQ Scheduler\n- RocketMQ Item Pipeline\n- SQLAlchemy Item Pipeline\n- Mongodb Item Pipeline\n- ~~Kafka Scheduler~~\n- ~~Kafka Item Pipeline~~\n\n## **Usage**\n\n### **Step 0:**\n\n```\npip install scrapy-distributed\n```\n\nOR\n\n```\ngit clone https://github.com/Insutanto/scrapy-distributed.git && cd scrapy-distributed\n&& python setup.py install\n```\n\nThere is a simple demo in [`examples/simple_example`]((examples/)). Here is the fast way to use `Scrapy-Distributed`.\n\n### [Examples of RabbitMQ](examples/rabbitmq_example)\n\n```bash\n# pull and run a RabbitMQ container.\ndocker run -d --name rabbitmq -p 0.0.0.0:15672:15672 -p 0.0.0.0:5672:5672 rabbitmq:3\n# enable rabbitmq_management\ndocker exec -it <rabbitmq-container-id> /bin/bash\ncd /etc/rabbitmq/\nrabbitmq-plugins enable rabbitmq_management\n\n# pull and run a RedisBloom container.\ndocker run -d --name redis-redisbloom -p 6379:6379 redislabs/rebloom:latest\n\ncd examples/rabbitmq_example\npython run_simple_example.py\n\n```\n\n### [Examples of Kafka](examples/kafka_example)\n\n```bash\n# make sure you have a Kafka running on localhost:9092\n# pull and run a RedisBloom container.\ndocker run -d --name redis-redisbloom -p 6379:6379 redislabs/rebloom:latest\n\ncd examples/kafka_example\npython run_simple_example.py\n\n```\n\n## RabbitMQ Support\n\nIf you don't have the required environment for tests:\n\n```bash\n# pull and run a RabbitMQ container.\ndocker run -d --name rabbitmq -p 0.0.0.0:15672:15672 -p 0.0.0.0:5672:5672 rabbitmq:3\n# enable rabbitmq_management\ndocker exec -it <rabbitmq-container-id> /bin/bash\ncd /etc/rabbitmq/\nrabbitmq-plugins enable rabbitmq_management\n# pull and run a RedisBloom container.\ndocker run -d --name redis-redisbloom -p 6379:6379 redislabs/rebloom:latest\n```\n\n### **Step 1:**\n\nOnly by change `SCHEDULER`, `DUPEFILTER_CLASS` and add some configs, you can get a distributed crawler in a moment.\n\n```\nSCHEDULER = \"scrapy_distributed.schedulers.DistributedScheduler\"\nSCHEDULER_QUEUE_CLASS = \"scrapy_distributed.queues.amqp.RabbitQueue\"\nRABBITMQ_CONNECTION_PARAMETERS = \"amqp://guest:guest@localhost:5672/example/?heartbeat=0\"\nDUPEFILTER_CLASS = \"scrapy_distributed.dupefilters.redis_bloom.RedisBloomDupeFilter\"\nBLOOM_DUPEFILTER_REDIS_URL = \"redis://:@localhost:6379/0\"\nBLOOM_DUPEFILTER_REDIS_HOST = \"localhost\"\nBLOOM_DUPEFILTER_REDIS_PORT = 6379\nREDIS_BLOOM_PARAMS = {\n    \"redis_cls\": \"redisbloom.client.Client\"\n}\nBLOOM_DUPEFILTER_ERROR_RATE = 0.001\nBLOOM_DUPEFILTER_CAPACITY = 100_0000\n\n# disable the RedirectMiddleware, because the RabbitMiddleware can handle those redirect request.\nDOWNLOADER_MIDDLEWARES = {\n    ...\n    \"scrapy.downloadermiddlewares.redirect.RedirectMiddleware\": None,\n    \"scrapy_distributed.middlewares.amqp.RabbitMiddleware\": 542\n}\n\n# add RabbitPipeline, it will push your items to rabbitmq's queue. \nITEM_PIPELINES = {\n    ...\n   'scrapy_distributed.pipelines.amqp.RabbitPipeline': 301,\n}\n\n\n```\n\n### **Step 2:**\n\n```\nscrapy crawl <your_spider>\n```\n\n## Kafka Support\n\n### **Step 1:**\n```\nSCHEDULER = \"scrapy_distributed.schedulers.DistributedScheduler\"\nSCHEDULER_QUEUE_CLASS = \"scrapy_distributed.queues.kafka.KafkaQueue\"\nKAFKA_CONNECTION_PARAMETERS = \"localhost:9092\"\nDUPEFILTER_CLASS = \"scrapy_distributed.dupefilters.redis_bloom.RedisBloomDupeFilter\"\nBLOOM_DUPEFILTER_REDIS_URL = \"redis://:@localhost:6379/0\"\nBLOOM_DUPEFILTER_REDIS_HOST = \"localhost\"\nBLOOM_DUPEFILTER_REDIS_PORT = 6379\nREDIS_BLOOM_PARAMS = {\n    \"redis_cls\": \"redisbloom.client.Client\"\n}\nBLOOM_DUPEFILTER_ERROR_RATE = 0.001\nBLOOM_DUPEFILTER_CAPACITY = 100_0000\n\nDOWNLOADER_MIDDLEWARES = {\n    ...\n   \"scrapy_distributed.middlewares.kafka.KafkaMiddleware\": 542\n}\n\n```\n\n### **Step 2:**\n\n```\nscrapy crawl <your_spider>\n```\n\n## **Reference Project**\n\n`scrapy-rabbitmq-link`([scrapy-rabbitmq-link](https://github.com/mbriliauskas/scrapy-rabbitmq-link))\n\n`scrapy-redis`([scrapy-redis](https://github.com/rmax/scrapy-redis))\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/Insutanto/scrapy-distributed",
    "keywords": "",
    "license": "BSD",
    "maintainer": "Insutanto",
    "maintainer_email": "insutantow@gmail.com",
    "name": "Scrapy-Distributed",
    "package_url": "https://pypi.org/project/Scrapy-Distributed/",
    "platform": "",
    "project_url": "https://pypi.org/project/Scrapy-Distributed/",
    "project_urls": {
      "Documentation": "https://github.com/Insutanto/scrapy-distributed",
      "Homepage": "https://github.com/Insutanto/scrapy-distributed",
      "Source": "https://github.com/Insutanto/scrapy-distributed",
      "Tracker": "https://github.com/Insutanto/scrapy-distributed/issues"
    },
    "release_url": "https://pypi.org/project/Scrapy-Distributed/2020.12.1/",
    "requires_dist": [
      "scrapy (>=1.8.0)",
      "pika (>=1.0.0)",
      "redisbloom (>=0.2.0)",
      "redis (>=3.0.1)",
      "kafka-python (>=1.4.7)"
    ],
    "requires_python": ">=3.6",
    "summary": "A series distributed components for Scrapy framework",
    "version": "2020.12.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 9475843,
  "releases": {
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fd141236eb617b9be2fcb0877af9246dd1d2675aac79f4ffdf1ade4dbf354b4f",
          "md5": "9b81261600fb0606b713991949fb2def",
          "sha256": "5d35aa517e3b19077f3f42d13a8856adb3ef2098870791fd162097961242f2a4"
        },
        "downloads": -1,
        "filename": "Scrapy-Distributed-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "9b81261600fb0606b713991949fb2def",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 11260,
        "upload_time": "2020-08-27T05:31:29",
        "upload_time_iso_8601": "2020-08-27T05:31:29.907832Z",
        "url": "https://files.pythonhosted.org/packages/fd/14/1236eb617b9be2fcb0877af9246dd1d2675aac79f4ffdf1ade4dbf354b4f/Scrapy-Distributed-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "2020.11.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7b282ed5bb58d97b1ce70bb0278688c2b752c2f4a898e130a6b281adf4cc99bc",
          "md5": "b51d571b3cd8944782595b04e1b431ef",
          "sha256": "d8f87265b059357af6e3831f2995795379ba83fe728fe6317a2ef3c84fade5e8"
        },
        "downloads": -1,
        "filename": "Scrapy_Distributed-2020.11.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "b51d571b3cd8944782595b04e1b431ef",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 20637,
        "upload_time": "2020-11-18T16:18:26",
        "upload_time_iso_8601": "2020-11-18T16:18:26.925048Z",
        "url": "https://files.pythonhosted.org/packages/7b/28/2ed5bb58d97b1ce70bb0278688c2b752c2f4a898e130a6b281adf4cc99bc/Scrapy_Distributed-2020.11.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0686dac4f191c8aa3cd823c0d3f0382ca29a9c288d3bc2916633c3350bccdb8f",
          "md5": "bf7aa6acc4026d89fd25899fd3c17ecc",
          "sha256": "46f0c6201f25b8e5f85004a9e4e42d41d14c2262415aa58bc98f30be67f5c10e"
        },
        "downloads": -1,
        "filename": "Scrapy-Distributed-2020.11.0.tar.gz",
        "has_sig": false,
        "md5_digest": "bf7aa6acc4026d89fd25899fd3c17ecc",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 13563,
        "upload_time": "2020-11-18T16:18:29",
        "upload_time_iso_8601": "2020-11-18T16:18:29.003482Z",
        "url": "https://files.pythonhosted.org/packages/06/86/dac4f191c8aa3cd823c0d3f0382ca29a9c288d3bc2916633c3350bccdb8f/Scrapy-Distributed-2020.11.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "2020.11.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d33a415bbdfdd682dfef682f2e3ed09c485f2da6528a405fa5d880f90270eb10",
          "md5": "f76baa9f1afce8536aa10cabdee0197f",
          "sha256": "d0885b3c2f56dc31cabdd666ac5e08df151ce97b9da46ca7bf1d3c99427967a0"
        },
        "downloads": -1,
        "filename": "Scrapy_Distributed-2020.11.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f76baa9f1afce8536aa10cabdee0197f",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 20888,
        "upload_time": "2020-11-22T15:40:48",
        "upload_time_iso_8601": "2020-11-22T15:40:48.662295Z",
        "url": "https://files.pythonhosted.org/packages/d3/3a/415bbdfdd682dfef682f2e3ed09c485f2da6528a405fa5d880f90270eb10/Scrapy_Distributed-2020.11.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "25064517cbe8d9e351550a17fbd97db8bd3e9c1e59a95e7c32d3e5f606e96663",
          "md5": "e644538056dc302425e91450fe735ba0",
          "sha256": "c847a3eb36b363d71b8788bcd96f3a5c0475c6d811ac447755c96a0611366e1b"
        },
        "downloads": -1,
        "filename": "Scrapy-Distributed-2020.11.2.tar.gz",
        "has_sig": false,
        "md5_digest": "e644538056dc302425e91450fe735ba0",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 13849,
        "upload_time": "2020-11-22T15:40:50",
        "upload_time_iso_8601": "2020-11-22T15:40:50.671281Z",
        "url": "https://files.pythonhosted.org/packages/25/06/4517cbe8d9e351550a17fbd97db8bd3e9c1e59a95e7c32d3e5f606e96663/Scrapy-Distributed-2020.11.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "2020.11.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f3bf9045d911e9459e02e737c569e1103b760cb1b0e1cf7bc1cc187e42644c2f",
          "md5": "e3fba1643c5bfce3c6dcb22e1ac5af7e",
          "sha256": "05cc57634ffb78a3324bd6feeda894f9a9ddea0dd9974a7838529b9bcf191739"
        },
        "downloads": -1,
        "filename": "Scrapy_Distributed-2020.11.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "e3fba1643c5bfce3c6dcb22e1ac5af7e",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 23809,
        "upload_time": "2020-12-10T14:34:09",
        "upload_time_iso_8601": "2020-12-10T14:34:09.629098Z",
        "url": "https://files.pythonhosted.org/packages/f3/bf/9045d911e9459e02e737c569e1103b760cb1b0e1cf7bc1cc187e42644c2f/Scrapy_Distributed-2020.11.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "47a803bb3ffa495d2691a55a72a3a716e5ad5f681945cfd64abe16896866adb6",
          "md5": "170d098b1148b4bad0d64df5f3e8f72e",
          "sha256": "34323c99ccd2a076ff33417318e6b4d2ba37cbbd33f4a43315e27e526fd6118f"
        },
        "downloads": -1,
        "filename": "Scrapy-Distributed-2020.11.3.tar.gz",
        "has_sig": false,
        "md5_digest": "170d098b1148b4bad0d64df5f3e8f72e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 15056,
        "upload_time": "2020-12-10T14:34:10",
        "upload_time_iso_8601": "2020-12-10T14:34:10.953497Z",
        "url": "https://files.pythonhosted.org/packages/47/a8/03bb3ffa495d2691a55a72a3a716e5ad5f681945cfd64abe16896866adb6/Scrapy-Distributed-2020.11.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "2020.12.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9ab0d4c3ee8fcfaad190b0c946c4ca54d2f8fcf988ef7198fda21fcf939571ff",
          "md5": "ffc843adf58bad3c6bc94cf223980cfb",
          "sha256": "9e2819ccfcd1090af1ab56335be9f6b5caf5d9ef99f16df0b4122ea010abebbe"
        },
        "downloads": -1,
        "filename": "Scrapy_Distributed-2020.12.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ffc843adf58bad3c6bc94cf223980cfb",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 24669,
        "upload_time": "2021-02-20T14:04:31",
        "upload_time_iso_8601": "2021-02-20T14:04:31.930692Z",
        "url": "https://files.pythonhosted.org/packages/9a/b0/d4c3ee8fcfaad190b0c946c4ca54d2f8fcf988ef7198fda21fcf939571ff/Scrapy_Distributed-2020.12.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b4145da63637aa9a0112d2c45dfd60aedc38726a73528ba2cf254028b4186274",
          "md5": "ff23773ff0ff81472babf80deda09538",
          "sha256": "f0f3451581f586d36d77408815295ca63ff7b93753e2cc3e99491f53e4447fed"
        },
        "downloads": -1,
        "filename": "Scrapy-Distributed-2020.12.1.tar.gz",
        "has_sig": false,
        "md5_digest": "ff23773ff0ff81472babf80deda09538",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 15491,
        "upload_time": "2021-02-20T14:04:33",
        "upload_time_iso_8601": "2021-02-20T14:04:33.142557Z",
        "url": "https://files.pythonhosted.org/packages/b4/14/5da63637aa9a0112d2c45dfd60aedc38726a73528ba2cf254028b4186274/Scrapy-Distributed-2020.12.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "9ab0d4c3ee8fcfaad190b0c946c4ca54d2f8fcf988ef7198fda21fcf939571ff",
        "md5": "ffc843adf58bad3c6bc94cf223980cfb",
        "sha256": "9e2819ccfcd1090af1ab56335be9f6b5caf5d9ef99f16df0b4122ea010abebbe"
      },
      "downloads": -1,
      "filename": "Scrapy_Distributed-2020.12.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "ffc843adf58bad3c6bc94cf223980cfb",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 24669,
      "upload_time": "2021-02-20T14:04:31",
      "upload_time_iso_8601": "2021-02-20T14:04:31.930692Z",
      "url": "https://files.pythonhosted.org/packages/9a/b0/d4c3ee8fcfaad190b0c946c4ca54d2f8fcf988ef7198fda21fcf939571ff/Scrapy_Distributed-2020.12.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "b4145da63637aa9a0112d2c45dfd60aedc38726a73528ba2cf254028b4186274",
        "md5": "ff23773ff0ff81472babf80deda09538",
        "sha256": "f0f3451581f586d36d77408815295ca63ff7b93753e2cc3e99491f53e4447fed"
      },
      "downloads": -1,
      "filename": "Scrapy-Distributed-2020.12.1.tar.gz",
      "has_sig": false,
      "md5_digest": "ff23773ff0ff81472babf80deda09538",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 15491,
      "upload_time": "2021-02-20T14:04:33",
      "upload_time_iso_8601": "2021-02-20T14:04:33.142557Z",
      "url": "https://files.pythonhosted.org/packages/b4/14/5da63637aa9a0112d2c45dfd60aedc38726a73528ba2cf254028b4186274/Scrapy-Distributed-2020.12.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}