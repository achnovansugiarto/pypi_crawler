{
  "info": {
    "author": "Kerun Mi",
    "author_email": "ryunxiaomi@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Developers",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: MacOS",
      "Operating System :: Microsoft :: Windows",
      "Operating System :: OS Independent",
      "Operating System :: POSIX :: Linux",
      "Operating System :: Unix",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.11",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Topic :: Scientific/Engineering :: Artificial Intelligence"
    ],
    "description": "=============\nNCG-optimizer\n=============\n.. image:: https://github.com/RyunMi/NCG-optimizer/workflows/CI/badge.svg\n    :target: https://github.com/RyunMi/NCG-optimizer/actions?query=workflow%3ACI\n    :alt: GitHub Actions status for master branch\n.. image:: https://img.shields.io/pypi/pyversions/ncg-optimizer.svg\n    :target: https://pypi.org/project/ncg-optimizer\n.. image:: https://img.shields.io/pypi/v/ncg-optimizer.svg\n    :target: https://pypi.python.org/pypi/ncg-optimizer\n.. image:: https://pepy.tech/badge/ncg-optimizer\n    :target: https://pepy.tech/project/ncg-optimizer\n.. image:: https://img.shields.io/badge/License-Apache_2.0-blue.svg\n    :target: https://opensource.org/licenses/Apache-2.0\n\n**NCG-optimizer** is a set of optimizer about *nonlinear conjugate gradient* in Pytorch.\n\nInspired by `jettify <https://github.com/jettify/pytorch-optimizer>`__ and `kozistr <https://github.com/kozistr/pytorch_optimizer>`__.\n\nInstall\n=======\n\n::\n\n    $ pip install ncg_optimizer\n\nSupported Optimizers\n====================\n\nBasic Methods\n-------------\n\nThe theoretical analysis and implementation of all basic methods is based on the \"Nonlinear Conjugate Gradient Method\" [#NCGM]_ , \"Numerical Optimization\" ([#NO1]_ [#NO2]_) and \"Conjugate gradient algorithms in nonconvex optimization\"[#CGNO]_.\n\nLinear Conjugate Gradient\n^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe Linear Conjugate Gradient(**LCG**) method is only applicable to linear equation solving problems. It converts linear equations into quadratic functions, so that the problem can be solved iteratively without inverting the coefficient matrix.\n\n.. image:: https://raw.githubusercontent.com/RyunMi/NCG-optimizer/master/docs/LCG.png\n        :width: 800px\n\n.. code-block:: python\n\n        import ncg_optimizer as optim\n        \n        # model = Your Model\n        \n        optimizer = optim.LCG(model.parameters(), eps=1e-5)\n        def closure():\n            optimizer.zero_grad()\n            loss(model(input), target).backward()\n            return loss\n        optimizer.step(closure)\n\nNonlinear Conjugate Gradient\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n.. image:: https://raw.githubusercontent.com/RyunMi/NCG-optimizer/master/docs/NCG.png\n        :width: 800px\n\nFletcher-Reeves Method\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\nThe Fletcher-Reeves conjugate gradient( **FR** ) method  is the earliest nonlinear conjugate gradient method. \nIt was obtained by Fletcher and Reeves in 1964 by extending the conjugate gradient method for solving linear equations to solve optimization problems. \n\nThe scalar parameter update formula of the FR method is as follows:\n\n$$ \\\\beta_k^{F R}=\\\\frac{g_{k+1}^T g_{k+1}}{g_k^T g_k}$$\n\nThe convergence analysis of FR method is often closely related to its selected line search. \nThe FR method of exact line search is used to converge the general nonconvex function. \nThe FR method of strong Wolfe inexact line search method $c_2 \\\\leq 0.5$ is adopted to globally converge to the general nonconvex function. \nThe generalized Wolfe or Armijo inexact line search FR method is globally convergent for general nonconvex functions.\n\n.. code-block:: python\n\n        \n        optimizer = optim.BASIC(\n            model.parameters(), method = 'FR',\n            line_search = 'Strong_Wolfe', c1 = 1e-4, \n            c2 = 0.5, lr = 0.2, max_ls = 25)\n        def closure():\n            optimizer.zero_grad()\n            loss(model(input), target).backward()\n            return loss\n        optimizer.step(closure)\n\nPolak-Ribiere-Polyak Method\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\nThe  Polak-Ribiere-Polyak(**PRP**) method is a nonlinear conjugate gradient method proposed independently by Polak, Ribiere and Polyak in 1969. \nThe PRP method is one of the conjugate gradient methods with the best numerical performance. \nWhen the algorithm produces a small step, the search direction $d_k$ defined by the PRP method automatically approaches the negative gradient direction, \nthus effectively avoiding the disadvantage that the FR method may continuously produce small steps.\n\nThe scalar parameter update formula of the PRP method is as follows:\n\n$$ \\\\beta_k^{PRP}=\\\\frac{g_{k}^{T}(g_{k}-g_{k-1})}{\\\\lVert g_{k-1}\\\\rVert^2}$$\n\nThe convergence analysis of the PRP method is often closely related to the selected line search. When the step size $s_k = x_{k+1} - x_{k} \\\\to 0$ is regarded as a measure of global convergence, \nthe PRP method of exact line search is used to converge the uniformly convex function under this benchmark. \nThe PRP method using Armijo-type inexact line search method converges globally for general nonconvex functions. \nThe PRP $^+$ method using the strong Wolfe( $0 < c_2 < \\\\frac{1}{4}$ ) inexact line search method converges globally for general nonconvex functions. \nThe PRP method with some constant step size factor ( involving Lipschitz constant ) inexact line search method converges globally for general nonconvex functions.\n\n.. code-block:: python\n\n\n        optimizer = optim.BASIC(\n            model.parameters(), method = 'PRP',\n            line_search = 'Armijo', c1 = 1e-4, \n            c2 = 0.9, lr = 1, rho = 0.5,)\n        def closure():\n            optimizer.zero_grad()\n            loss(model(input), target).backward()\n            return loss\n        optimizer.step(closure)\n\nHestenes-Stiefel Method\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\nAnother famous conjugate gradient method Hestenes-Stiefel( **HS** ) method was proposed by Hestenes and Stiefel.\nThe scalar parameter update formula of the HS method is as follows:\n\n$$ \\\\beta_{k}^{HS}=\\\\frac{g_{k}^{T}(g_{k}-g_{k-1})}{(g_{k}-g_{k-1})^Td_{k-1}} $$\n\nCompared with the PRP method, an important property of the HS method is that the conjugate relation \n$d_k^T(g_{k}-g_{k-1}) = 0$ always holds regardless of the exact of the line search. \nHowever, the theoretical properties and computational performance of the HS method are similar to those of the PRP method.\n\nThe convergence analysis of the HS method is often closely related to the selected line search. \nIf the $f(x)$ level set is bounded, its derivative is Lipschitz continuous and satisfies the sufficient descent condition, \nthen the HS method with Wolfe inexact line search method is globally convergent. \nThe HS $^+$ method with the strong Wolfe ( $0 < c_2 < \\\\frac{1}{3}$ ) inexact line search method converges globally for general nonconvex functions.\n\n.. code-block:: python\n\n\n        optimizer = optim.BASIC(\n            model.parameters(), method = 'HS',\n            line_search = 'Strong_Wolfe', c1 = 1e-4, \n            c2 = 0.4, lr = 0.2, max_ls = 25,)\n        def closure():\n            optimizer.zero_grad()\n            loss(model(input), target).backward()\n            return loss\n        optimizer.step(closure)\n\nConjugate Descent Method\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\nConjugate Descent ( **CD** ) was first introduced by Fletcherl in 1987. \nIt can avoid the phenomenon that a rising search direction may occur in each iteration \nsuch as the PRP method and the FR method under certain conditions.\n\nThe scalar parameter update formula of the CD method is as follows:\n\n$$ \\\\beta_{k}^{CD}=\\\\frac{g_{k}^T g_{k}}{-(g_{k-1})^T d_{k-1}} $$\n\nThe convergence analysis of the CD method is often closely related to the selected line search. \nThe CD method using the strong Wolfe ( $c_2 < 1$ ) inexact line search method converges globally for general nonconvex functions, \nbut the convergence accuracy cannot be guaranteed. \nThe CD method using Armijo inexact line search method converges globally for general nonconvex functions.\n\n.. code-block:: python\n\n\n        optimizer = optim.BASIC(\n            model.parameters(), method = 'CD',\n            line_search = 'Armijo', c1 = 1e-4, \n            c2 = 0.9, lr = 1, rho = 0.5,)\n        def closure():\n            optimizer.zero_grad()\n            loss(model(input), target).backward()\n            return loss\n        optimizer.step(closure)\n\nLiu-Storey Method\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\nLiu-Storey ( **LS** ) conjugate gradient method is a nonlinear conjugate gradient method \nproposed by Liu and Storey in 1991, which has good numerical performance.\n\nThe scalar parameter update formula of the LS method is as follows:\n\n$$ \\\\beta_{k}^{LS}=\\\\frac{g_{k}^T (g_{k} - g_{k-1})}{ - g_{k-1}^T d_{k-1}} $$\n\nThe convergence analysis of the LS method is often closely related to the selected line search. \nThe LS method with strong Wolfe inexact line search method has global convergence property ( under Lipschitz condition ). \nThe LS method using Armijo-type inexact line search method converges globally for general nonconvex functions.\n\n.. code-block:: python\n\n\n        optimizer = optim.BASIC(\n            model.parameters(), method = 'LS',\n            line_search = 'Armijo', c1 = 1e-4, \n            c2 = 0.9, lr = 1, rho = 0.5,)\n        def closure():\n            optimizer.zero_grad()\n            loss(model(input), target).backward()\n            return loss\n        optimizer.step(closure)\n\n\n\nDai-Yuan Method\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\nThe Dai-Yuan method ( **DY** ) was first proposed by Yuhong Dai and Yaxiang Yuan in 1995, which always produces a descent search direction under weaker line search conditions and is globally convergent. \nIn addition, good convergence results can be obtained without using strong Wolfe inexact line search but only using Wolfe inexact line search.\n\nThe scalar parameter update formula of the DY method is as follows:\n\n$$ \\\\beta_{k}^{DY}=\\\\frac{g_{k}^T g_{k}}{(g_{k} - g_{k-1})^T d_{k-1}} $$\n\nThe convergence analysis of the DY method is often closely related to the selected line search. \nThe DY method using the strong Wolfe inexact line search method can guarantee sufficient descent and global convergence for general nonconvex functions. \nThe DY method using the Wolfe inexact line search method converges globally for general nonconvex functions.\n\n.. code-block:: python\n\n\n        optimizer = optim.BASIC(\n            model.parameters(), method = 'DY',\n            line_search = 'Strong_Wolfe', c1 = 1e-4, \n            c2 = 0.9, lr = 0.2, max_ls = 25,)\n        def closure():\n            optimizer.zero_grad()\n            loss(model(input), target).backward()\n            return loss\n        optimizer.step(closure)\n\nHager-Zhang Method [#HZ]_\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\nThe Hager-Zhang ( **HZ** ) method is a new nonlinear conjugate gradient method proposed by Hager and Zhang in 2005. \nIt satisfies the sufficient descent condition and has global convergence for strongly convex functions, \nand the search direction approaches the direction of the memoryless BFGS quasi-Newton method.\n\nThe scalar parameter update formula of the HZ method is as follows:\n\n$$\n\\\\beta_k^{HZ}=\\\\frac{1}{d_{k-1}^T (g_{k} - g_{k-1})}((g_{k} - g_{k-1})-2 d_{k-1} \\\\frac{\\\\|(g_{k} - g_{k-1}) \\\\|^2}{d_{k-1}^T (g_{k} - g_{k-1})})^T{g}_{k}\n$$\n\nThe convergence analysis of the HZ method is often closely related to the selected line search. \nThe HZ method with ( strong ) Wolfe inexact line search method converges globally for general nonconvex functions. \nThe HZ $^+$ method using Armijo inexact line search method converges globally for general nonconvex functions.\n\n.. code-block:: python\n\n\n        optimizer = optim.BASIC(\n            model.parameters(), method = 'HZ',\n            line_search = 'Strong_Wolfe', c1 = 1e-4, \n            c2 = 0.9, lr = 0.2, max_ls = 25,)\n        def closure():\n            optimizer.zero_grad()\n            loss(model(input), target).backward()\n            return loss\n        optimizer.step(closure)\n\n\nHybrid HS-DY Method\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\nDai and Yuan studied the **HS-DY** hybrid conjugate gradient method of. \nCompared with other hybrid conjugate gradient methods ( such as FR + PRP hybrid conjugate gradient method ), \nthe advantage of this hybrid method is that it does not require the line search to satisfy the strong Wolfe condition, but only the Wolfe condition. \nTheir numerical experiments show that the HS-DY hybrid conjugate gradient method performs very well on difficult problems.\n\nThe scalar parameter update formula of the HS-DY method is as follows:\n\n$$\n\\\\beta_k^{HS-DY}=\\\\max (0, \\\\min (\\\\beta_k^{HS}, \\\\beta_k^{DY})))\n$$\n\nRegarding the convergence analysis of the HS-DY method, \nthe HS-DY method using the Wolfe inexact line search method is globally convergent for general non-convex functions, \nand the performance effect is also better than the PRP method.\n\n.. code-block:: python\n\n\n        optimizer = optim.BASIC(\n            model.parameters(), method = 'HS-DY',\n            line_search = 'Armijo', c1 = 1e-4, \n            c2 = 0.9 lr = 1, rho = 0.5,)\n        def closure():\n            optimizer.zero_grad()\n            loss(model(input), target).backward()\n            return loss\n        optimizer.step(closure)\n\nLine Search\n^^^^^^^^^^^\nArmijo Line Search\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\nIn order to satisfy the condition that the decrease of the function is at least proportional to the decrease of the tangent, \nthere are:\n\n$$\nf\\\\left(x_k+\\\\alpha_k d_k\\\\right) \\\\leqslant f\\\\left(x_k\\\\right)+c_1 \\\\alpha_k d_k^T g_k\n$$\n\nAmong them, $c_1\\\\in (0,1)$ is generally taken as $c_1 = 10^{-4}$.\n\n.. image:: https://raw.githubusercontent.com/RyunMi/NCG-optimizer/master/docs/ArmijoLS.png\n        :width: 800px\n\nWolfe Line Search(Coming Soon...)\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\nIn the following two formulas, the first inequality is a overwrite of the Armijo criterion.\nIn addition, in order to prevent the step size from being too small and ensure that the objective function decreases sufficiently, \nthe second inequality is introduced, so there is:\n\n$$\nf\\\\left(x_k+\\\\alpha_k d_k\\\\right) \\\\leqslant f\\\\left(x_k\\\\right)+c_1 \\\\alpha_k d_k^T g_k\n$$\n\n$$\n\\\\nabla f\\\\left(x_k+\\\\alpha d_k\\\\right)^T d_k \\\\geq c_2 \\\\nabla f_k^T d_k  \n$$\n\nwhere the $c_2 \\\\in (c_1, 1)$.\n\nStrong Wolfe Line Search [#NO1]_ [#MF]_\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\nThe Strong Wolfe criterion reduces the constraint to less than 0 on the basis of the original Wolfe criterion to ensure the true approximation of the exact line search :\n\n$$\nf\\\\left(x_k+\\\\alpha_k d_k\\\\right) \\\\leqslant f\\\\left(x_k\\\\right)+c_1 \\\\alpha_k d_k^T g_k\n$$\n\n$$\n\\|\\\\nabla f\\\\left(x_k+\\\\alpha d_k\\\\right)^T d_k\\| \\\\leq -c_2 \\\\nabla f_k^T d_k  \n$$\n\n.. image:: https://raw.githubusercontent.com/RyunMi/NCG-optimizer/master/docs/Strong_Wolfe.png\n        :width: 800px\n\n.. image:: https://raw.githubusercontent.com/RyunMi/NCG-optimizer/master/docs/Zoom.png\n        :width: 800px\n\nCitation\n========\nPlease cite original authors of optimization algorithms. If you like this software:\n\n::\n\n    @software{Mi_ncgoptimizer,\n    \ttitle        = {{ncg-optimizer -- a set of optimizer about nonlinear conjugate gradient in Pytorch.}},\n    \tauthor       = {Kerun Mi},\n    \tyear         = 2023,\n    \tmonth        = 2,\n    \tversion      = {0.1.0}}\n\nOr you can get from \"cite this repository\" button.\n\n\nReferences\n==========\n\n.. [#NCGM] Y.H. Dai and Y. Yuan (2000), Nonlinear Conjugate Gradient Methods, Shanghai Scientific and Technical Publishers, Shanghai. (in Chinese)\n.. [#NO1] Nocedal J, Wright S J. Line search methods[J]. Numerical optimization, 2006: 30-65.\n.. [#NO2] Nocedal J, Wright S J. Conjugate gradient methods[J]. Numerical optimization, 2006: 101-134. \n.. [#CGNO] Pytlak R. Conjugate gradient algorithms in nonconvex optimization[M]. Springer Science & Business Media, 2008.\n.. [#HZ] Hager W W, Zhang H. A new conjugate gradient method with guaranteed descent and an efficient line search[J]. SIAM Journal on optimization, 2005, 16(1): 170-192.\n.. [#MF] Schmidt M. minFunc: unconstrained differentiable multivariate optimization in Matlab[J]. Software available at https://www.cs.ubc.ca/~schmidtm/Software/minFunc.html, 2005.\n\nChanges\n-------\n\n0.1.0 (2023-02-05)\n------------------\n* Initial release.\n* Added support for Linear Conjugate Gradient(LCG), Basic Nonlinear Conjugate Gradient(FR, PRP, HS, CD, DY, LS, HZ, HS-DY) methods and two line search function(Armijo & Strong Wolfe).\n",
    "description_content_type": "text/x-rst",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/RyunMi/NCG-optimizer",
    "keywords": "ncg-optimizer,pytorch,LCG,FR,PRP,HS,CD,DY,LS,HZ,HS-DY,Armijo,Strong Wolfe",
    "license": "Apache 2",
    "maintainer": "",
    "maintainer_email": "",
    "name": "ncg-optimizer",
    "package_url": "https://pypi.org/project/ncg-optimizer/",
    "platform": null,
    "project_url": "https://pypi.org/project/ncg-optimizer/",
    "project_urls": {
      "Homepage": "https://github.com/RyunMi/NCG-optimizer"
    },
    "release_url": "https://pypi.org/project/ncg-optimizer/0.1.0/",
    "requires_dist": [
      "torch (>=1.7.1)"
    ],
    "requires_python": "",
    "summary": "Pytorch optimizer based on nonlinear conjugate gradient method",
    "version": "0.1.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16904326,
  "releases": {
    "0.0.1a0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e6f7c2e196bb651e02a0e9965af14512ccc35610d6c7b0641fa258038c11d456",
          "md5": "ba5928d0549ca8d322d0be23c365eb57",
          "sha256": "3d5812e2667f8beda3603b26eac95e65957d18589d44d38f5393c80dd711ea6a"
        },
        "downloads": -1,
        "filename": "ncg_optimizer-0.0.1a0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ba5928d0549ca8d322d0be23c365eb57",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 8006,
        "upload_time": "2023-01-25T14:36:55",
        "upload_time_iso_8601": "2023-01-25T14:36:55.155032Z",
        "url": "https://files.pythonhosted.org/packages/e6/f7/c2e196bb651e02a0e9965af14512ccc35610d6c7b0641fa258038c11d456/ncg_optimizer-0.0.1a0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8a723f0c2cdf553eb592208e8f094602db04a70264b059e328f91852337b63a4",
          "md5": "d57ac64f3f04720ea361803d2ebd5ab7",
          "sha256": "faf406e0a4ba6c382fa2603f85709900c11a456ea3738e8e187d2bf3db2abdc8"
        },
        "downloads": -1,
        "filename": "ncg-optimizer-0.0.1a0.tar.gz",
        "has_sig": false,
        "md5_digest": "d57ac64f3f04720ea361803d2ebd5ab7",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 7473,
        "upload_time": "2023-01-25T14:36:56",
        "upload_time_iso_8601": "2023-01-25T14:36:56.676214Z",
        "url": "https://files.pythonhosted.org/packages/8a/72/3f0c2cdf553eb592208e8f094602db04a70264b059e328f91852337b63a4/ncg-optimizer-0.0.1a0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.1b0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c7582a28d19d3555cc0c14ae61594e720979482ea93eec54cc20c170fa4987e8",
          "md5": "340904c31af23bdf685d3c3ca4a88fa4",
          "sha256": "cecdb0615ef315d44b7eee6e47274e0d63e43255b81c98ebe614f59ac2843e10"
        },
        "downloads": -1,
        "filename": "ncg_optimizer-0.0.1b0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "340904c31af23bdf685d3c3ca4a88fa4",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 8108,
        "upload_time": "2023-01-26T10:54:51",
        "upload_time_iso_8601": "2023-01-26T10:54:51.583141Z",
        "url": "https://files.pythonhosted.org/packages/c7/58/2a28d19d3555cc0c14ae61594e720979482ea93eec54cc20c170fa4987e8/ncg_optimizer-0.0.1b0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ee667f36f5c5c6fa10653f3cae62bb6f86fb52253906a69c41d38d3082a182ec",
          "md5": "547e114ae0f2079be66ad5aa8833f4bd",
          "sha256": "6b1199d7df45324b8812ddbaec690ce7560e379fa0ab8a8b0f41842409db618f"
        },
        "downloads": -1,
        "filename": "ncg-optimizer-0.0.1b0.tar.gz",
        "has_sig": false,
        "md5_digest": "547e114ae0f2079be66ad5aa8833f4bd",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 7567,
        "upload_time": "2023-01-26T10:54:53",
        "upload_time_iso_8601": "2023-01-26T10:54:53.150846Z",
        "url": "https://files.pythonhosted.org/packages/ee/66/7f36f5c5c6fa10653f3cae62bb6f86fb52253906a69c41d38d3082a182ec/ncg-optimizer-0.0.1b0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.1b1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "94ccfdf051dd86cc5b7c7e74bb10c12c083e7a31ddc4403cf6a4f2959a124656",
          "md5": "66a434fb51d966c09918217d7a070a5b",
          "sha256": "af67e152991100bbde2e89725f32984c9ac398dbe6e4381d6c32890543a614f3"
        },
        "downloads": -1,
        "filename": "ncg_optimizer-0.0.1b1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "66a434fb51d966c09918217d7a070a5b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 8103,
        "upload_time": "2023-01-26T11:10:39",
        "upload_time_iso_8601": "2023-01-26T11:10:39.168380Z",
        "url": "https://files.pythonhosted.org/packages/94/cc/fdf051dd86cc5b7c7e74bb10c12c083e7a31ddc4403cf6a4f2959a124656/ncg_optimizer-0.0.1b1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "02de973980c28641672b5a6268a42aad49369cb548b2aaaaf91f1de6d6eea92e",
          "md5": "2dc5d52851382c17d62b06c25efd39b9",
          "sha256": "05f6c98b17f1e6a1d5dc862c681064db704d2df36b01fe5fa874761ac57b2e6e"
        },
        "downloads": -1,
        "filename": "ncg-optimizer-0.0.1b1.tar.gz",
        "has_sig": false,
        "md5_digest": "2dc5d52851382c17d62b06c25efd39b9",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 7558,
        "upload_time": "2023-01-26T11:10:40",
        "upload_time_iso_8601": "2023-01-26T11:10:40.762527Z",
        "url": "https://files.pythonhosted.org/packages/02/de/973980c28641672b5a6268a42aad49369cb548b2aaaaf91f1de6d6eea92e/ncg-optimizer-0.0.1b1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2b0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0fbb963e6c6191dca5862d87c3e2dcab9d59b90b0038e395829842f9e7d18aa3",
          "md5": "d4f84283bf62471621eb62494c62eeee",
          "sha256": "c59e1859b3a0483bd6e5d7af00087bf8593702130ea48d5586bea94e18256df8"
        },
        "downloads": -1,
        "filename": "ncg_optimizer-0.0.2b0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d4f84283bf62471621eb62494c62eeee",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 11668,
        "upload_time": "2023-02-03T17:28:31",
        "upload_time_iso_8601": "2023-02-03T17:28:31.601471Z",
        "url": "https://files.pythonhosted.org/packages/0f/bb/963e6c6191dca5862d87c3e2dcab9d59b90b0038e395829842f9e7d18aa3/ncg_optimizer-0.0.2b0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3e3e8d4ba4623f4550fc71be99ee1cc33962084d36972a82290642f1d9bbdc65",
          "md5": "f9db47815da53a1fc2ea11c3678e1150",
          "sha256": "a5d3526b10cfa4a2b7b80e9003db03c41de8216ca7eff0eded20e68a76c02257"
        },
        "downloads": -1,
        "filename": "ncg-optimizer-0.0.2b0.tar.gz",
        "has_sig": false,
        "md5_digest": "f9db47815da53a1fc2ea11c3678e1150",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 9668,
        "upload_time": "2023-02-03T17:28:33",
        "upload_time_iso_8601": "2023-02-03T17:28:33.129408Z",
        "url": "https://files.pythonhosted.org/packages/3e/3e/8d4ba4623f4550fc71be99ee1cc33962084d36972a82290642f1d9bbdc65/ncg-optimizer-0.0.2b0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "605e2114d35d83882f583857853bb865bbe650a7037db844d5470e7b6d04b2d8",
          "md5": "ee3f86b762b20015fdec99a1485a54f7",
          "sha256": "3f77b1cc3bcd88f690f3bb4bdfbc66a94ff0218cbea3d867cf531c7385f1c938"
        },
        "downloads": -1,
        "filename": "ncg_optimizer-0.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ee3f86b762b20015fdec99a1485a54f7",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 27056,
        "upload_time": "2023-02-04T15:15:24",
        "upload_time_iso_8601": "2023-02-04T15:15:24.031850Z",
        "url": "https://files.pythonhosted.org/packages/60/5e/2114d35d83882f583857853bb865bbe650a7037db844d5470e7b6d04b2d8/ncg_optimizer-0.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "84bfd52d02213ba5ad5b2eafe98a4d254ab8480c245be5b27838c2d5f3030597",
          "md5": "c10049ef7e433fa1a8e39e7eb6c8e69b",
          "sha256": "051b9726a22921fffa9269effed33ba2c7f94bb9d81ada2e53baea47c9166355"
        },
        "downloads": -1,
        "filename": "ncg-optimizer-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "c10049ef7e433fa1a8e39e7eb6c8e69b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 12180,
        "upload_time": "2023-02-04T15:15:25",
        "upload_time_iso_8601": "2023-02-04T15:15:25.717695Z",
        "url": "https://files.pythonhosted.org/packages/84/bf/d52d02213ba5ad5b2eafe98a4d254ab8480c245be5b27838c2d5f3030597/ncg-optimizer-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f7da6f2c58e749f676ed9506eba0d7fb6abd1a208726b0be2e42205ab1fa68fd",
          "md5": "44db10c1373adad6888ed59bc9a12727",
          "sha256": "13d4ee0382c5ccb0d92b296d6935129492d50538669fc133966e85d2b9da4a74"
        },
        "downloads": -1,
        "filename": "ncg_optimizer-0.0.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "44db10c1373adad6888ed59bc9a12727",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 27263,
        "upload_time": "2023-02-05T16:34:34",
        "upload_time_iso_8601": "2023-02-05T16:34:34.175698Z",
        "url": "https://files.pythonhosted.org/packages/f7/da/6f2c58e749f676ed9506eba0d7fb6abd1a208726b0be2e42205ab1fa68fd/ncg_optimizer-0.0.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e157b1a746475079e398ac9181d9e77acf1976ebd6138300230c73b8bda75947",
          "md5": "4d96326173eed9634414b816de6d3b25",
          "sha256": "6e4d9071c587396ca59225b8ffe11a7ecfaa502b30b03188c43df66f86a779a8"
        },
        "downloads": -1,
        "filename": "ncg-optimizer-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "4d96326173eed9634414b816de6d3b25",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 12850,
        "upload_time": "2023-02-05T16:34:35",
        "upload_time_iso_8601": "2023-02-05T16:34:35.409624Z",
        "url": "https://files.pythonhosted.org/packages/e1/57/b1a746475079e398ac9181d9e77acf1976ebd6138300230c73b8bda75947/ncg-optimizer-0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bdcdf73c61c0ab2f43e0d43e208531aaabb43d04600b57206cfd0971ddc209d2",
          "md5": "5e7eeac34acebf23659ff35cafa47abd",
          "sha256": "ceb29bf7b177fefcf718e67b8bd652b36a1d449ed39ef3f0ebad1caafa302735"
        },
        "downloads": -1,
        "filename": "ncg_optimizer-0.0.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "5e7eeac34acebf23659ff35cafa47abd",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 29461,
        "upload_time": "2023-02-06T15:01:27",
        "upload_time_iso_8601": "2023-02-06T15:01:27.954500Z",
        "url": "https://files.pythonhosted.org/packages/bd/cd/f73c61c0ab2f43e0d43e208531aaabb43d04600b57206cfd0971ddc209d2/ncg_optimizer-0.0.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1f2dd5a1638481117629c9c7f3087a6d0e570f036f01b5f5dc694e711e36e489",
          "md5": "06c0a3b2961e160ce89099eb88aa9b56",
          "sha256": "22ffcd7397e3438b8ee7b405cefede03673e4e96a5d846ec361dd8d9e85785ab"
        },
        "downloads": -1,
        "filename": "ncg-optimizer-0.0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "06c0a3b2961e160ce89099eb88aa9b56",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 17334,
        "upload_time": "2023-02-06T15:01:30",
        "upload_time_iso_8601": "2023-02-06T15:01:30.008701Z",
        "url": "https://files.pythonhosted.org/packages/1f/2d/d5a1638481117629c9c7f3087a6d0e570f036f01b5f5dc694e711e36e489/ncg-optimizer-0.0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d0ba9111b62830e84f5fafbd54e88023a94e18919732ed815a45a3163f34b2a9",
          "md5": "582a3567c5a81459427e37f63d656b7b",
          "sha256": "fc75ccb102489fa7fbef67bad3fb4a856e8509348e014067d332f118b5ce47a3"
        },
        "downloads": -1,
        "filename": "ncg_optimizer-0.0.6-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "582a3567c5a81459427e37f63d656b7b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 14814,
        "upload_time": "2023-02-07T16:07:47",
        "upload_time_iso_8601": "2023-02-07T16:07:47.976701Z",
        "url": "https://files.pythonhosted.org/packages/d0/ba/9111b62830e84f5fafbd54e88023a94e18919732ed815a45a3163f34b2a9/ncg_optimizer-0.0.6-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "04985bd209634e0a1a635a74c5ea146f74a46a794384711a7e527c9612bc23a0",
          "md5": "3ab17e5035a82a80e34c0de688d3f9a9",
          "sha256": "dcc01b039d34a7d65e94ef5e65211fc811d15941ecce693f4f8a33fa49b37301"
        },
        "downloads": -1,
        "filename": "ncg-optimizer-0.0.6.tar.gz",
        "has_sig": false,
        "md5_digest": "3ab17e5035a82a80e34c0de688d3f9a9",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 17169,
        "upload_time": "2023-02-07T16:07:49",
        "upload_time_iso_8601": "2023-02-07T16:07:49.375445Z",
        "url": "https://files.pythonhosted.org/packages/04/98/5bd209634e0a1a635a74c5ea146f74a46a794384711a7e527c9612bc23a0/ncg-optimizer-0.0.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6ac3d486e30465bb9446975c2dea319b7ff325f95ad187a941b06b33a5384a77",
          "md5": "da7ee9b15342421a2198d132044df575",
          "sha256": "ce2db06546266f6f0e03b038e7257a020fae31d88cdef70d15380e8035771026"
        },
        "downloads": -1,
        "filename": "ncg_optimizer-0.0.7-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "da7ee9b15342421a2198d132044df575",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 16201,
        "upload_time": "2023-02-08T15:16:10",
        "upload_time_iso_8601": "2023-02-08T15:16:10.982409Z",
        "url": "https://files.pythonhosted.org/packages/6a/c3/d486e30465bb9446975c2dea319b7ff325f95ad187a941b06b33a5384a77/ncg_optimizer-0.0.7-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "eff3b12a50b5cd2203b082154de8db53381608b21babf530bbab9aad7eddc8f4",
          "md5": "3a596d8392e5777035c0b9e35d299df9",
          "sha256": "729d911bd19da1902ee1325f7f1b300b6d2bb2b2c7b01c5f12a34b8432219917"
        },
        "downloads": -1,
        "filename": "ncg-optimizer-0.0.7.tar.gz",
        "has_sig": false,
        "md5_digest": "3a596d8392e5777035c0b9e35d299df9",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 19306,
        "upload_time": "2023-02-08T15:16:12",
        "upload_time_iso_8601": "2023-02-08T15:16:12.317768Z",
        "url": "https://files.pythonhosted.org/packages/ef/f3/b12a50b5cd2203b082154de8db53381608b21babf530bbab9aad7eddc8f4/ncg-optimizer-0.0.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c601c0eb750de87f48f7152770968c38feaff29bccb40c1d7f6c2be6ab4f1d6f",
          "md5": "39009bf6c0dc88a742888364f4dbbac1",
          "sha256": "a65b59541de08be58d8cf7a8c3fe7bf5f5c2ce19bb1d2435e617089b8ffbdf2c"
        },
        "downloads": -1,
        "filename": "ncg_optimizer-0.0.8-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "39009bf6c0dc88a742888364f4dbbac1",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 16594,
        "upload_time": "2023-02-09T14:55:21",
        "upload_time_iso_8601": "2023-02-09T14:55:21.762707Z",
        "url": "https://files.pythonhosted.org/packages/c6/01/c0eb750de87f48f7152770968c38feaff29bccb40c1d7f6c2be6ab4f1d6f/ncg_optimizer-0.0.8-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a0faeb7e12456913b1d69258f4c0db637bd8a7cbc98b15d7b608d44f18edb448",
          "md5": "6355860c0be114bc2285abb6cde98ab3",
          "sha256": "24325238c6b2e3c78b00999c6eb18f52d115b73375ff9826324e098b7511634d"
        },
        "downloads": -1,
        "filename": "ncg-optimizer-0.0.8.tar.gz",
        "has_sig": false,
        "md5_digest": "6355860c0be114bc2285abb6cde98ab3",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 20229,
        "upload_time": "2023-02-09T14:55:23",
        "upload_time_iso_8601": "2023-02-09T14:55:23.501535Z",
        "url": "https://files.pythonhosted.org/packages/a0/fa/eb7e12456913b1d69258f4c0db637bd8a7cbc98b15d7b608d44f18edb448/ncg-optimizer-0.0.8.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.9": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3d449a06575bc0b868cb8a727650e7b93debe487abbb2f699add1687bca7bbf7",
          "md5": "9839dba499ef2334cc998d9b31dabd9d",
          "sha256": "fd81b9a89db6cec9386d09d5fbef4fb460e5ca6d6860551404335199d83962ad"
        },
        "downloads": -1,
        "filename": "ncg_optimizer-0.0.9-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "9839dba499ef2334cc998d9b31dabd9d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 16566,
        "upload_time": "2023-02-10T07:13:46",
        "upload_time_iso_8601": "2023-02-10T07:13:46.193844Z",
        "url": "https://files.pythonhosted.org/packages/3d/44/9a06575bc0b868cb8a727650e7b93debe487abbb2f699add1687bca7bbf7/ncg_optimizer-0.0.9-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7fc12e1e689b09513d170b2c7c587cd4b2aa2209689bada1339a2913642fa99f",
          "md5": "19003fdb3c67aa159f5e4405c4804435",
          "sha256": "a152b0eb9b5df46a1ff1884aad458ff2e844ba8c41767be747dd6d3b857e20a4"
        },
        "downloads": -1,
        "filename": "ncg-optimizer-0.0.9.tar.gz",
        "has_sig": false,
        "md5_digest": "19003fdb3c67aa159f5e4405c4804435",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 20194,
        "upload_time": "2023-02-10T07:13:47",
        "upload_time_iso_8601": "2023-02-10T07:13:47.956314Z",
        "url": "https://files.pythonhosted.org/packages/7f/c1/2e1e689b09513d170b2c7c587cd4b2aa2209689bada1339a2913642fa99f/ncg-optimizer-0.0.9.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f06df86c4bc5587cdfe65603d225b7bd55503d08216c688f1481f699e25628f1",
          "md5": "01f1002c0e8e265fcf8b589e3bb0386a",
          "sha256": "2e5646eb450be7333757006ff0e92f9b5a25e8db555b2890f94f057f89c2af89"
        },
        "downloads": -1,
        "filename": "ncg_optimizer-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "01f1002c0e8e265fcf8b589e3bb0386a",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 16497,
        "upload_time": "2023-02-17T15:33:03",
        "upload_time_iso_8601": "2023-02-17T15:33:03.234724Z",
        "url": "https://files.pythonhosted.org/packages/f0/6d/f86c4bc5587cdfe65603d225b7bd55503d08216c688f1481f699e25628f1/ncg_optimizer-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "15b434e188491c99d056000c014f48f0d73fa9d6fb987cd4b3b07b569906fccb",
          "md5": "9a875055373476c6910abc5f56027cfa",
          "sha256": "90d64a48db041acb3937927958ff61e7bbd81941d04e1cf92927912ff934f39f"
        },
        "downloads": -1,
        "filename": "ncg-optimizer-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "9a875055373476c6910abc5f56027cfa",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 20156,
        "upload_time": "2023-02-17T15:33:04",
        "upload_time_iso_8601": "2023-02-17T15:33:04.664201Z",
        "url": "https://files.pythonhosted.org/packages/15/b4/34e188491c99d056000c014f48f0d73fa9d6fb987cd4b3b07b569906fccb/ncg-optimizer-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "f06df86c4bc5587cdfe65603d225b7bd55503d08216c688f1481f699e25628f1",
        "md5": "01f1002c0e8e265fcf8b589e3bb0386a",
        "sha256": "2e5646eb450be7333757006ff0e92f9b5a25e8db555b2890f94f057f89c2af89"
      },
      "downloads": -1,
      "filename": "ncg_optimizer-0.1.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "01f1002c0e8e265fcf8b589e3bb0386a",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 16497,
      "upload_time": "2023-02-17T15:33:03",
      "upload_time_iso_8601": "2023-02-17T15:33:03.234724Z",
      "url": "https://files.pythonhosted.org/packages/f0/6d/f86c4bc5587cdfe65603d225b7bd55503d08216c688f1481f699e25628f1/ncg_optimizer-0.1.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "15b434e188491c99d056000c014f48f0d73fa9d6fb987cd4b3b07b569906fccb",
        "md5": "9a875055373476c6910abc5f56027cfa",
        "sha256": "90d64a48db041acb3937927958ff61e7bbd81941d04e1cf92927912ff934f39f"
      },
      "downloads": -1,
      "filename": "ncg-optimizer-0.1.0.tar.gz",
      "has_sig": false,
      "md5_digest": "9a875055373476c6910abc5f56027cfa",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 20156,
      "upload_time": "2023-02-17T15:33:04",
      "upload_time_iso_8601": "2023-02-17T15:33:04.664201Z",
      "url": "https://files.pythonhosted.org/packages/15/b4/34e188491c99d056000c014f48f0d73fa9d6fb987cd4b3b07b569906fccb/ncg-optimizer-0.1.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}