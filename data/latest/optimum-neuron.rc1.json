{
  "info": {
    "author": "HuggingFace Inc. Special Ops Team",
    "author_email": "hardware@huggingface.co",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 2 - Pre-Alpha",
      "Intended Audience :: Developers",
      "Intended Audience :: Education",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Topic :: Scientific/Engineering :: Artificial Intelligence"
    ],
    "description": "<!---\nCopyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n-->\n\n# Optimum Neuron\n\nü§ó Optimum Neuron is the interface between the ü§ó Transformers library and AWS Accelerators¬†including [AWS Trainium](https://aws.amazon.com/machine-learning/trainium/?nc1=h_ls) and [AWS Inferentia](https://aws.amazon.com/machine-learning/inferentia/?nc1=h_ls). \nIt provides a set of tools enabling easy model loading, training and inference on single- and multi-Accelerator settings for different downstream tasks.\nThe list of officially validated models and tasks is available [here](TODO:). Users can try other models and tasks with only few changes.\n\n## Install\nTo install the latest release of this package:\n\n```bash\npip install optimum[neuron]\n```\n\nOptimum Neuron is a fast-moving project, and you may want to install it from source:\n\n```bash\npip install git+https://github.com/huggingface/optimum-neuron.git\n```\n\n> Alternatively, you can install the package without pip as follows:\n> ```bash\n> git clone https://github.com/huggingface/optimum-neuron.git\n> cd optimum-neuron\n> python setup.py install\n> ```\n\nLast but not least, don't forget to install the requirements for every example:\n\n```bash\ncd <example-folder>\npip install -r requirements.txt\n```\n\n\n## How to use it?\n\n### Quick Start\n\nü§ó Optimum Neuron was designed with one goal in mind: **to make training and inference straightforward for any ü§ó Transformers user while leveraging the complete power of AWS Accelerators**.\n\n#### Transformers Interface\n\nThere are two main classes one needs to know:\n- TrainiumArgumentParser: inherits the original [HfArgumentParser](https://huggingface.co/docs/transformers/main/en/internal/trainer_utils#transformers.HfArgumentParser) in Transformers with additional checks on the argument values to make sure that they will work well with AWS Trainium instances.\n- [TrainiumTrainer](https://huggingface.co/docs/optimum/neuron/package_reference/trainer): this version trainer takes care of doing the proper checks and changes to the supported models to make them trainable on AWS Trainium instances.\n\nThe [TrainiumTrainer](https://huggingface.co/docs/optimum/neuron/package_reference/trainer) is very similar to the [ü§ó Transformers Trainer](https://huggingface.co/docs/transformers/main_classes/trainer), and adapting a script using the Trainer to make it work with Trainium will mostly consist in simply swapping the Trainer class for the TrainiumTrainer one.\nThat's how most of the [example scripts](https://github.com/huggingface/optimum-neuron/tree/main/examples) were adapted from their [original counterparts](https://github.com/huggingface/transformers/tree/main/examples/pytorch).\n\n```diff\nfrom transformers import TrainingArguments\n+from optimum.neuron import TrainiumTrainer as Trainer\n\ntraining_args = TrainingArguments(\n  # training arguments...\n)\n\n# A lot of code here\n\n# Initialize our Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,  # Original training arguments.\n    train_dataset=train_dataset if training_args.do_train else None,\n    eval_dataset=eval_dataset if training_args.do_eval else None,\n    compute_metrics=compute_metrics,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n)\n```\n\n### Documentation\n\nCheck out [the documentation of Optimum Neuron](https://huggingface.co/docs/optimum/**neuron**/index) for more advanced usage.\n\n<!---\n\n## Validated Models\n\nThe following model architectures, tasks and device distributions have been validated for ü§ó Optimum Neuron:\n\n<div align=\"center\">\n\n| Architecture     | State | <center>Tasks</center>                                                                                                                                                                                                                                                                                                                                 |\n| ---------------- | ----- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n| BERT             | ‚úÖ     | <li>[text classification](https://github.com/huggingface/optimum-neuron/tree/main/examples/text-classification)</li><li>[question answering](https://github.com/huggingface/optimum-neuron/tree/main/examples/question-answering)</li><li>[language modeling](https://github.com/huggingface/optimum-neuron/tree/main/examples/language-modeling)</li> |\n| RoBERTa          | ‚ùå     | <li>[question answering](https://github.com/huggingface/optimum-neuron/tree/main/examples/question-answering)</li><li>[language modeling](https://github.com/huggingface/optimum-neuron/tree/main/examples/language-modeling)</li>                                                                                                                     |\n| ALBERT           | ‚ùå     | <li>[question answering](https://github.com/huggingface/optimum-neuron/tree/main/examples/question-answering)</li><li>[language modeling](https://github.com/huggingface/optimum-neuron/tree/main/examples/language-modeling)</li>                                                                                                                     |\n| DistilBERT       | ‚ùå     | <li>[question answering](https://github.com/huggingface/optimum-neuron/tree/main/examples/question-answering)</li><li>[language modeling](https://github.com/huggingface/optimum-neuron/tree/main/examples/language-modeling)</li>                                                                                                                     |\n| GPT2             | ‚ùå     | <li>[language modeling](https://github.com/huggingface/optimum-neuron/tree/main/examples/language-modeling)</li>                                                                                                                                                                                                                                       |\n| T5               | ‚ùå     | <li>[summarization](https://github.com/huggingface/optimum-neuron/tree/main/examples/summarization)</li><li>[translation](https://github.com/huggingface/optimum-neuron/tree/main/examples/translation)</li>                                                                                                                                           |\n| ViT              | ‚ùå     | <li>[image classification](https://github.com/huggingface/optimum-neuron/tree/main/examples/image-classification)</li>                                                                                                                                                                                                                                 |\n| Swin             | ‚ùå     | <li>[image classification](https://github.com/huggingface/optimum-neuron/tree/main/examples/image-classification)</li>                                                                                                                                                                                                                                 |\n| Wav2Vec2         | ‚ùå     | <li>[audio classification](https://github.com/huggingface/optimum-neuron/tree/main/examples/audio-classification)</li><li>[speech recognition](https://github.com/huggingface/optimum-neuron/tree/main/examples/speech-recognition)</li>                                                                                                               |\n| Stable Diffusion | ‚ùå     | <li>[text-to-image generation](https://github.com/huggingface/optimum-neuron/tree/main/examples/stable-diffusion)</li>                                                                                                                                                                                                                                 |\n| CLIP             | ‚ùå     | <li>[contrastive image-text training](https://github.com/huggingface/optimum-neuron/tree/main/examples/contrastive-image-text)</li>                                                                                                                                                                                                                    |\n\n</div>\n\nOther models and tasks supported by the ü§ó Transformers library may also work. You can refer to this [section](https://github.com/huggingface/optimum-neuron#how-to-use-it) for using them with ü§ó Optimum Neuron. Besides, [this page](https://github.com/huggingface/optimum-neuron/tree/main/examples) explains how to modify any [example](https://github.com/huggingface/transformers/tree/main/examples/pytorch) from the ü§ó Transformers library to make it work with ü§ó Optimum Neuron.\n\n-->\n\nIf you find any issue while using those, please open an issue or a pull request.\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://huggingface.co/hardware/aws",
    "keywords": "transformers,diffusers,mixed-precision training,fine-tuning,inference,tranium,inferentia,aws",
    "license": "Apache",
    "maintainer": "",
    "maintainer_email": "",
    "name": "optimum-neuron",
    "package_url": "https://pypi.org/project/optimum-neuron/",
    "platform": null,
    "project_url": "https://pypi.org/project/optimum-neuron/",
    "project_urls": {
      "Homepage": "https://huggingface.co/hardware/aws"
    },
    "release_url": "https://pypi.org/project/optimum-neuron/0.0.1/",
    "requires_dist": [
      "transformers (>=4.26.0)",
      "optimum",
      "black ; extra == 'quality'",
      "ruff ; extra == 'quality'",
      "hf-doc-builder ; extra == 'quality'",
      "pytest ; extra == 'tests'",
      "psutil ; extra == 'tests'",
      "parameterized ; extra == 'tests'",
      "GitPython ; extra == 'tests'",
      "sentencepiece ; extra == 'tests'",
      "datasets ; extra == 'tests'"
    ],
    "requires_python": "",
    "summary": "Optimum Neuron is the interface between the Hugging Face Transformers and Diffusers libraries and AWS Tranium and Inferentia accelerators. It provides a set of tools enabling easy model loading, training and inference on single and multiple neuron core settings for different downstream tasks.",
    "version": "0.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17272012,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "239b5fa48f06601bd7f256b63b0f48b63902ac9bac350157bf0e029ecdf588e4",
          "md5": "7770c35e60257896e5bc2a663b11d6be",
          "sha256": "e0ca8aef3fe8d47129e6c142f8df9f1f32bb39d0ca36bd79a899a0f2b48de471"
        },
        "downloads": -1,
        "filename": "optimum_neuron-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "7770c35e60257896e5bc2a663b11d6be",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 17244,
        "upload_time": "2023-03-13T14:09:41",
        "upload_time_iso_8601": "2023-03-13T14:09:41.795097Z",
        "url": "https://files.pythonhosted.org/packages/23/9b/5fa48f06601bd7f256b63b0f48b63902ac9bac350157bf0e029ecdf588e4/optimum_neuron-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "88bbdf362cb2444a9be66b27272ae6c7d5c3aed6b7be94db67d206d1d86f6e7d",
          "md5": "cab61875a0dee0c1b321e9e8a9422aaa",
          "sha256": "6264c35aff7019efe8c951cbdecd6c32bf253898ec05725870a1e024940b5167"
        },
        "downloads": -1,
        "filename": "optimum-neuron-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "cab61875a0dee0c1b321e9e8a9422aaa",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 23135,
        "upload_time": "2023-03-13T14:09:43",
        "upload_time_iso_8601": "2023-03-13T14:09:43.797692Z",
        "url": "https://files.pythonhosted.org/packages/88/bb/df362cb2444a9be66b27272ae6c7d5c3aed6b7be94db67d206d1d86f6e7d/optimum-neuron-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "239b5fa48f06601bd7f256b63b0f48b63902ac9bac350157bf0e029ecdf588e4",
        "md5": "7770c35e60257896e5bc2a663b11d6be",
        "sha256": "e0ca8aef3fe8d47129e6c142f8df9f1f32bb39d0ca36bd79a899a0f2b48de471"
      },
      "downloads": -1,
      "filename": "optimum_neuron-0.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "7770c35e60257896e5bc2a663b11d6be",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 17244,
      "upload_time": "2023-03-13T14:09:41",
      "upload_time_iso_8601": "2023-03-13T14:09:41.795097Z",
      "url": "https://files.pythonhosted.org/packages/23/9b/5fa48f06601bd7f256b63b0f48b63902ac9bac350157bf0e029ecdf588e4/optimum_neuron-0.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "88bbdf362cb2444a9be66b27272ae6c7d5c3aed6b7be94db67d206d1d86f6e7d",
        "md5": "cab61875a0dee0c1b321e9e8a9422aaa",
        "sha256": "6264c35aff7019efe8c951cbdecd6c32bf253898ec05725870a1e024940b5167"
      },
      "downloads": -1,
      "filename": "optimum-neuron-0.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "cab61875a0dee0c1b321e9e8a9422aaa",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 23135,
      "upload_time": "2023-03-13T14:09:43",
      "upload_time_iso_8601": "2023-03-13T14:09:43.797692Z",
      "url": "https://files.pythonhosted.org/packages/88/bb/df362cb2444a9be66b27272ae6c7d5c3aed6b7be94db67d206d1d86f6e7d/optimum-neuron-0.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}