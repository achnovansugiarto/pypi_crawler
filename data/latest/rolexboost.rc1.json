{
  "info": {
    "author": "Vopaaz, MichaelYangg",
    "author_email": "liyifan945@163.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7"
    ],
    "description": "# RolexBoost\n\nUnofficial implementation of D. Yang, H. Lee and D. Lim, \"RolexBoost: A Rotation-Based Boosting Algorithm With Adaptive Loss Functions,\" in IEEE Access, vol. 8, pp. 41037-41044, 2020, doi: 10.1109/ACCESS.2020.2976822.\n\nThis is the course project of Fundamentals of Machine Learning, Tsinghua University, 2020 Autumn.\n\n## Installation\n\n```bash\npip install rolexboost\n```\n\n## API reference\n\nWe provided scikit-learn-like API for the RolexBoost algorithm proposed in the paper,\ntogether with the RotationForest and FlexBoost, which are the source of RolexBoost's idea.\n\nNote that\n1. Only classifiers are provided. We did not implemented the regressors because they are not mentioned in the paper, while this project is intended as a reproduction.\n2. We only ensures that the `fit` and `predict` API works well. Some others, such as `score`, may be functional thanks to the scikit-learn `BaseEstimator` and `ClassifierMixin` base classes, but still others, such as `fit_predict` or `predict_proba`, are currently unavailable.\n\nWe might implement those two in the future if someone is interested in this project.\n\n### Basic Example\n\n```python\n>>> import pandas as pd\n>>> import numpy as np\n>>> from rolexboost import RolexBoostClassifier, FlexBoostClassifier, RotationForestClassifier\n\n>>> clf = RolexBoostClassifier() # Or the other two classifiers\n\n>>> df = pd.DataFrame({\"A\": [2,6,5,7,1,8], \"B\":[8,5,2,3,4,6], \"C\": [3,9,5,4,6,1], \"Label\": [0,1,1,0,0,1]})\n>>> df\n   A  B  C  Label\n0  2  8  3      0\n1  6  5  9      1\n2  5  2  5      1\n3  7  3  4      0\n4  1  4  6      0\n5  8  6  1      1\n\n>>> X = df[[\"A\", \"B\", \"C\"]]\n>>> y = df[\"Label\"]\n\n>>> clf.fit(X, y)\nRolexBoostClassifier()\n>>> clf.predict(X)\narray([0, 1, 1, 0, 0, 1], dtype=int64)\n\n>>> test_X = np.array([\n...     [3,1,2],\n...     [2,5,1],\n...     [5,1,7]\n... ])\n\n>>> clf.predict(test_X)\narray([1, 0, 1], dtype=int64)\n```\n\n### API References\n\n#### Rotation Forest\n\n```python\nRotationForestClassifier(\n    n_estimators=100,\n    n_features_per_subset=3,\n    bootstrap_rate=0.75,\n    criterion=\"gini\",\n    splitter=\"best\",\n    max_depth=None,\n    min_samples_split=2,\n    min_samples_leaf=1,\n    min_weight_fraction_leaf=0.0,\n    max_features=None,\n    random_state=None,\n    max_leaf_nodes=None,\n    min_impurity_decrease=0.0,\n    min_impurity_split=None,\n    class_weight=None,\n    presort=\"deprecated\",\n    ccp_alpha=0.0,\n)\n```\n\n- `n_estimators`: number of base estimators\n- `n_features_per_subset`: number of features in each subset\n- `bootstrap_rate`: ratio of samples bootstrapped in the original dataset\n\nAll other parameters are passed to the `DecisionTreeClassifier` of scikit-learn. Please refer to [their documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier) for details.\n\n\nNote:\n\nIn the algorithm description, a parameter controls the number of subsets, and the number of features is derived from it.\nHowever, the validation part of the paper says that \"the number of features in each subset was set to three\".\nIn our framework, the parameter `n_samples_per_subset` is thus formulated in this way to make the benchmark evaluation easier.\n\n\n#### FlexBoost\n\n```python\nFlexBoostClassifier(\n    n_estimators=100,\n    K=0.5,\n    criterion=\"gini\",\n    splitter=\"best\",\n    max_depth=1,\n    min_samples_split=2,\n    min_samples_leaf=1,\n    min_weight_fraction_leaf=0.0,\n    max_features=None,\n    random_state=None,\n    max_leaf_nodes=None,\n    min_impurity_decrease=0.0,\n    min_impurity_split=None,\n    class_weight=None,\n    presort=\"deprecated\",\n    ccp_alpha=0.0,\n)\n```\n\n- `n_estimators`: number of base estimators\n- `K`: the parameter to control the \"aggressiveness\" and \"conservativeness\" in the adaptive loss function choosing process. It should be a number between 0 and 1.\n\nAll other parameters are passed to the `DecisionTreeClassifier` of scikit-learn. Please refer to [their documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier) for details.\n\nThe default parameter for `max_depth` is 1, because FlexBoost is a modification of AdaBoost, and they should converge to the same result when `K=1`.\nIn [scikit-learn implementation of AdaBoost](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier), the default `max_depth` for the DecisionTreeClassifier is 1.\n\n\n\n#### RolexBoost\n\n```python\nRolexBoostClassifier(\n    n_estimators=100,\n    n_features_per_subset=3,\n    bootstrap_rate=0.75,\n    K=0.5,\n    criterion=\"gini\",\n    splitter=\"best\",\n    max_depth=1,\n    min_samples_split=2,\n    min_samples_leaf=1,\n    min_weight_fraction_leaf=0.0,\n    max_features=None,\n    random_state=None,\n    max_leaf_nodes=None,\n    min_impurity_decrease=0.0,\n    min_impurity_split=None,\n    class_weight=None,\n    presort=\"deprecated\",\n    ccp_alpha=0.0\n)\n```\n\n- `n_estimators`: number of base estimators\n- `n_features_per_subset`: number of features in each subset\n- `bootstrap_rate`: ratio of samples bootstrapped in the original dataset\n- `K`: the parameter to control the \"aggressiveness\" and \"conservativeness\" in the adaptive loss function choosing process. It should be a number between 0 and 1.\n\n\nAll other parameters are passed to the `DecisionTreeClassifier` of scikit-learn. Please refer to [their documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier) for details.\n\n\nNote:\n\nIn the algorithm description, a parameter controls the number of subsets, and the number of features is derived from it.\nHowever, the validation part of the paper says that \"the number of features in each subset was set to three\".\nIn our framework, the parameter `n_samples_per_subset` is thus formulated in this way to make the benchmark evaluation easier.\n\nThe default parameter for `max_depth` is 1, because RolexBoost integrates the idea of FlexBoost. Please refer to the last section about why FlexBoost has a default `max_depth` of 1.\n\n\n## Performance Benchmarks\n\nWe have tested the three algorithms on 13 datasets mentioned in the paper.\n\nHere is the result:\n\n| algorithm      | accuracy | benchmark | ratio  |\n| -------------- | -------- | --------- | ------ |\n| RotationForest | 0.7898   | 0.7947    | 0.9938 |\n| FlexBoost      | 0.7976   | 0.8095    | 0.9853 |\n| RolexBoost     | 0.7775   | 0.8167    | 0.9520 |\n\n- `accuracy` refers to the average accuracy of our implementation\n- `benchmark` refers to the average accuracy reported in the paper\n- `ratio` is accuracy/benchmark\n\nFor the detail of each algorithm on each dataset, please run the tests/accuracy-test.py.\nThe test may take ~1 hour to finish.\n\nSome datasets reported in the paper are not involved in the benchmark testing for the following two reasons:\n1. We cannot find the corresponding dataset in the UCI Machine Learning Repository\n2. The 3-class problems are each divided into three 2-class problems. We are not sure about how such division is done.\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/Vopaaz/RolexBoost",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "rolexboost",
    "package_url": "https://pypi.org/project/rolexboost/",
    "platform": "",
    "project_url": "https://pypi.org/project/rolexboost/",
    "project_urls": {
      "Homepage": "https://github.com/Vopaaz/RolexBoost"
    },
    "release_url": "https://pypi.org/project/rolexboost/0.0.1/",
    "requires_dist": [
      "scikit-learn (>=0.22.0)",
      "numpy (>=1.18.0)",
      "scipy (>=1.4.0)"
    ],
    "requires_python": "",
    "summary": "Unofficial implementation of RolexBoost: A Rotation-Based Boosting Algorithm With Adaptive Loss Functions",
    "version": "0.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8227005,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d021bef1ef5afce77962e6eed8128395b14988ae7972aabd8361eb79ab0fbbe9",
          "md5": "0beb36740ebdbaf7a7715ff81e06be9b",
          "sha256": "5cd2d26e0d1bba56f7a47b3d9e2452ac040425dff15844ef9521076b50fa9bb6"
        },
        "downloads": -1,
        "filename": "rolexboost-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0beb36740ebdbaf7a7715ff81e06be9b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 9623,
        "upload_time": "2020-09-20T07:18:11",
        "upload_time_iso_8601": "2020-09-20T07:18:11.223208Z",
        "url": "https://files.pythonhosted.org/packages/d0/21/bef1ef5afce77962e6eed8128395b14988ae7972aabd8361eb79ab0fbbe9/rolexboost-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d3a70827c258f8292dfeb42fff7879050a6dddd798f115aaab9e14f47d4598b2",
          "md5": "1b82ad922bd46dc5322822df1dd97891",
          "sha256": "69210edd0ee9c10709beff78ad0417ee9a0e5a1805d9a979dcca75e1f918e1bc"
        },
        "downloads": -1,
        "filename": "rolexboost-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "1b82ad922bd46dc5322822df1dd97891",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 8408,
        "upload_time": "2020-09-20T07:18:13",
        "upload_time_iso_8601": "2020-09-20T07:18:13.854784Z",
        "url": "https://files.pythonhosted.org/packages/d3/a7/0827c258f8292dfeb42fff7879050a6dddd798f115aaab9e14f47d4598b2/rolexboost-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "d021bef1ef5afce77962e6eed8128395b14988ae7972aabd8361eb79ab0fbbe9",
        "md5": "0beb36740ebdbaf7a7715ff81e06be9b",
        "sha256": "5cd2d26e0d1bba56f7a47b3d9e2452ac040425dff15844ef9521076b50fa9bb6"
      },
      "downloads": -1,
      "filename": "rolexboost-0.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "0beb36740ebdbaf7a7715ff81e06be9b",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 9623,
      "upload_time": "2020-09-20T07:18:11",
      "upload_time_iso_8601": "2020-09-20T07:18:11.223208Z",
      "url": "https://files.pythonhosted.org/packages/d0/21/bef1ef5afce77962e6eed8128395b14988ae7972aabd8361eb79ab0fbbe9/rolexboost-0.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "d3a70827c258f8292dfeb42fff7879050a6dddd798f115aaab9e14f47d4598b2",
        "md5": "1b82ad922bd46dc5322822df1dd97891",
        "sha256": "69210edd0ee9c10709beff78ad0417ee9a0e5a1805d9a979dcca75e1f918e1bc"
      },
      "downloads": -1,
      "filename": "rolexboost-0.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "1b82ad922bd46dc5322822df1dd97891",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 8408,
      "upload_time": "2020-09-20T07:18:13",
      "upload_time_iso_8601": "2020-09-20T07:18:13.854784Z",
      "url": "https://files.pythonhosted.org/packages/d3/a7/0827c258f8292dfeb42fff7879050a6dddd798f115aaab9e14f47d4598b2/rolexboost-0.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}