{
  "info": {
    "author": "Robel Equbasilassie",
    "author_email": "robiki4life@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Ethiopian Natural Language Toolkit (etnltk)\n\n- The Ethiopian Natural Language Toolkit (etnltk) project aimed to develop a suite of open source Natural Language Processing modules for the Ethiopian languages.\n- The Ethiopian Natural Language Toolkit (etnltk) is built using python language and takes inspiration from `spacy` and `nltk` libraries.\n\n## Installation\n\n### pip\n\n- **etnltk** supports Python 3.6 or later. We recommend that you install etnltk via `pip`, the Python package manager. To install, simply run:\n\n  ```python\n    pip install etnltk\n  ```\n\n### From Source\n\n- Alternatively, you can also install from source via `etnltk` git repository, which will give you more flexibility in developing on top of etltk. For this option, run\n\n  ```python\n    git clone https://github.com/robikieq/etnltk.git\n    \n    cd etnltk\n    \n    pip install -e .\n  ```\n\n## Documentation\n\n<https://etnltk.netlify.app/>\n\n## Usage\n\n1. Amharic text preprocessing with Amharic document\n    - Preprocessing amharic text is very simple: you can simply pass the text to the `Amharic` document and access all annotations from the returned Amharic document object:\n\n    ```python\n      from etnltk import Amharic\n\n      sample_text = \"\"\"\n        рѕџрІФрІЮрІФ 14рЇБ 2014 рІЊ.рѕЮ ­ЪцЌ рЅаріарїѕрѕГ рІ░рѕерїЃ рІерѕ░рІЇ рѕ░рѕФрѕй ріарѕхрЅ░рІЇрѕјрЅх /Artificial Intelligence/ ріарѕЂріЋ ріФрѕѕрЅарЅх рІЮрЅЁрЅ░ріЏ рІ░рѕерїЃ рІѕрІ░ рѕІрЅђ рІ░рѕерїЃ рѕѕрѕЏрІхрѕерѕхрЇБ рѕЃрїѕрѕГріЏ рЅІріЋрЅІрІјрЅйріЋ рѕѕрІЊрѕѕрѕЮ рЅ░рІ░рѕФрѕй рѕѕрѕЏрІхрѕерїЇрЇБ ріарїѕрѕФрІі ріарЅЁрѕЮріЋ рѕѕрѕЏрѕ│рІ░рїЇ ріЦріЊ рЅ░рїарЅЃрѕџ рѕѕрѕўрѕєріЋ рЅарїІрѕФ ріарЅЦрѕ« рѕўрѕхрѕФрЅ▒ ріЦрїЁрїЇ рїарЅЃрѕџ ріљрІЇрЇАрЇА\n\n        рЅарѕЏрѕйріЋ рІЊрѕхрЅ░рѕЮрѕ« (Machine Learning) ріарѕЏріФріЮріљрЅх рІерїйрѕЂрЇЇ ріЊрѕЎріЊрІјрЅй рЅаріарѕГрЅ▓рЇірѕ╗рѕЇ рібріЋрЅ░рѕѕрїђріЋрѕх рѕЦрѕГрІЊрЅх рѕѕрѕЏрѕ░рѕЇрїаріЋрЇБ рІерїйрѕЂрЇЇ рІ│рЅ│ріЋ рѕўрѕ░рЅЦрѕ░рЅЦ ріЦріЊ рѕЏрІ░рѕФрїђрЅхрЇц рІеріЊрЅ╣рѕФрѕЇ рѕІріЋрїЅрІїрїЁ рЇЋрѕ«рѕ░рѕ▓ріЋрїЇ рЅ▒рѕјрЅйріЋ /Natural Language Processing Tools/ рЅарѕўрїарЅђрѕЮ рІерїйрѕЂрЇЇ рІ│рЅ│ріЋ рЇЋрѕ«рѕ░рѕх рѕЏрІхрѕерїЇ рЅ░рЅђрІ│рѕџ ріЦріЊ рѕўрѕ░рѕерЅ│рІі рїЅрІ│рІГ ріљрІЇрЇб\n      \"\"\"\n  \n      # Annotating Amharic document\n      doc = Amharic(sample_text)\n\n      # print the `clean` text:\n      print(doc)\n      \n      # output: Amharic(\"рѕџрІФрІЮрІФ рІЊрѕўрЅ░ рѕЮрѕЁрѕерЅх рЅаріарїѕрѕГ рІ░рѕерїЃ рІерѕ░рІЇ рѕ░рѕФрѕй ріарѕхрЅ░рІЇрѕјрЅх ріарѕЂріЋ ріФрѕѕрЅарЅх рІЮрЅЁрЅ░ріЏ рІ░рѕерїЃ рІѕрІ░ рѕІрЅђ рІ░рѕерїЃ рѕѕрѕЏрІхрѕерѕх рѕђрїѕрѕГріЏ рЅІріЋрЅІрІјрЅйріЋ рѕѕріарѕѕрѕЮ рЅ░рІ░рѕФрѕй рѕѕрѕЏрІхрѕерїЇ ріарїѕрѕФрІі ріарЅЁрѕЮріЋ рѕѕрѕЏрѕ│рІ░рїЇ ріЦріЊ рЅ░рїарЅЃрѕџ рѕѕрѕўрѕєріЋ рЅарїІрѕФ ріарЅЦрѕ« рѕўрѕхрѕФрЅ▒ ріЦрїЁрїЇ рїарЅЃрѕџ ріљрІЇ рЅарѕЏрѕйріЋ ріарѕхрЅ░рѕЮрѕ« ріарѕЏріФріЮріљрЅх рІерЇЁрѕЂрЇЇ ріЊрѕЎріЊрІјрЅй рЅаріарѕГрЅ▓рЇірѕ╗рѕЇ рібріЋрЅ░рѕѕрїђріЋрѕх рѕхрѕГріарЅх рѕѕрѕЏрѕ░рѕЇрїаріЋ рІерЇЁрѕЂрЇЇ рІ│рЅ│ріЋ рѕўрѕ░рЅЦрѕ░рЅЦ ріЦріЊ рѕЏрІ░рѕФрїђрЅх рІеріЊрЅ╣рѕФрѕЇ рѕІріЋрїЅрІїрїЁ рЇЋрѕ«рѕ░рѕ▓ріЋрїЇ рЅ▒рѕјрЅйріЋ рЅарѕўрїарЅђрѕЮ рІерЇЁрѕЂрЇЇ рІ│рЅ│ріЋ рЇЋрѕ«рѕ░рѕх рѕЏрІхрѕерїЇ рЅ░рЅђрІ│рѕџ ріЦріЊ рѕўрѕ░рѕерЅ│рІі рїЅрІ│рІГ ріљрІЇ\")\n    ```\n\n     - Here is a another example of performing text cleaning on a piece of plaintext using `clean_amharic` function:\n\n    ```python\n    from etnltk.lang.am import (\n      preprocessing,\n      clean_amharic\n    )\n\n    sample_text = \"\"\"\n      рѕџрІФрІЮрІФ 14рЇБ 2014 рІЊ.рѕЮ ­ЪцЌ рЅаріарїѕрѕГ рІ░рѕерїЃ рІерѕ░рІЇ рѕ░рѕФрѕй ріарѕхрЅ░рІЇрѕјрЅх /Artificial Intelligence/ ріарѕЂріЋ ріФрѕѕрЅарЅх рІЮрЅЁрЅ░ріЏ рІ░рѕерїЃ рІѕрІ░ рѕІрЅђ рІ░рѕерїЃ рѕѕрѕЏрІхрѕерѕхрЇБ рѕЃрїѕрѕГріЏ рЅІріЋрЅІрІјрЅйріЋ рѕѕрІЊрѕѕрѕЮ рЅ░рІ░рѕФрѕй рѕѕрѕЏрІхрѕерїЇрЇБ ріарїѕрѕФрІі ріарЅЁрѕЮріЋ рѕѕрѕЏрѕ│рІ░рїЇ ріЦріЊ рЅ░рїарЅЃрѕџ рѕѕрѕўрѕєріЋ рЅарїІрѕФ ріарЅЦрѕ« рѕўрѕхрѕФрЅ▒ ріЦрїЁрїЇ рїарЅЃрѕџ ріљрІЇрЇАрЇА\n\n      рЅарѕЏрѕйріЋ рІЊрѕхрЅ░рѕЮрѕ« (Machine Learning) ріарѕЏріФріЮріљрЅх рІерїйрѕЂрЇЇ ріЊрѕЎріЊрІјрЅй рЅаріарѕГрЅ▓рЇірѕ╗рѕЇ рібріЋрЅ░рѕѕрїђріЋрѕх рѕЦрѕГрІЊрЅх рѕѕрѕЏрѕ░рѕЇрїаріЋрЇБ рІерїйрѕЂрЇЇ рІ│рЅ│ріЋ рѕўрѕ░рЅЦрѕ░рЅЦ ріЦріЊ рѕЏрІ░рѕФрїђрЅхрЇц рІеріЊрЅ╣рѕФрѕЇ рѕІріЋрїЅрІїрїЁ рЇЋрѕ«рѕ░рѕ▓ріЋрїЇ рЅ▒рѕјрЅйріЋ /Natural Language Processing Tools/ рЅарѕўрїарЅђрѕЮ рІерїйрѕЂрЇЇ рІ│рЅ│ріЋ рЇЋрѕ«рѕ░рѕх рѕЏрІхрѕерїЇ рЅ░рЅђрІ│рѕџ ріЦріЊ рѕўрѕ░рѕерЅ│рІі рїЅрІ│рІГ ріљрІЇрЇб\n    \"\"\"\n\n    # Define a custom preprocessor pipeline\n    custom_pipeline = [\n      preprocessing.remove_emojis, \n      preprocessing.remove_digits,\n      preprocessing.remove_ethiopic_punct,\n      preprocessing.remove_english_chars, \n      preprocessing.remove_punct\n    ]\n    \n    # `clean_amharic` function takes a custom pipeline, if not uses the default pipeline\n    cleaned = clean_amharic(input_text, abbrev=False, pipeline=custom_pipeline)\n\n    # print the `clean` text:\n    print(cleaned)\n    # output: рѕџрІФрІЮрІФ рІЊрѕўрЅ░ рѕЮрѕЁрѕерЅх рЅаріарїѕрѕГ рІ░рѕерїЃ рІерѕ░рІЇ рѕ░рѕФрѕй ріарѕхрЅ░рІЇрѕјрЅх ріарѕЂріЋ ріФрѕѕрЅарЅх рІЮрЅЁрЅ░ріЏ рІ░рѕерїЃ рІѕрІ░ рѕІрЅђ рІ░рѕерїЃ рѕѕрѕЏрІхрѕерѕх рѕђрїѕрѕГріЏ рЅІріЋрЅІрІјрЅйріЋ рѕѕріарѕѕрѕЮ рЅ░рІ░рѕФрѕй рѕѕрѕЏрІхрѕерїЇ ріарїѕрѕФрІі ріарЅЁрѕЮріЋ рѕѕрѕЏрѕ│рІ░рїЇ ріЦріЊ рЅ░рїарЅЃрѕџ рѕѕрѕўрѕєріЋ рЅарїІрѕФ ріарЅЦрѕ« рѕўрѕхрѕФрЅ▒ ріЦрїЁрїЇ рїарЅЃрѕџ ріљрІЇ рЅарѕЏрѕйріЋ ріарѕхрЅ░рѕЮрѕ« ріарѕЏріФріЮріљрЅх рІерЇЁрѕЂрЇЇ ріЊрѕЎріЊрІјрЅй рЅаріарѕГрЅ▓рЇірѕ╗рѕЇ рібріЋрЅ░рѕѕрїђріЋрѕх рѕхрѕГріарЅх рѕѕрѕЏрѕ░рѕЇрїаріЋ рІерЇЁрѕЂрЇЇ рІ│рЅ│ріЋ рѕўрѕ░рЅЦрѕ░рЅЦ ріЦріЊ рѕЏрІ░рѕФрїђрЅх рІеріЊрЅ╣рѕФрѕЇ рѕІріЋрїЅрІїрїЁ рЇЋрѕ«рѕ░рѕ▓ріЋрїЇ рЅ▒рѕјрЅйріЋ рЅарѕўрїарЅђрѕЮ рІерЇЁрѕЂрЇЇ рІ│рЅ│ріЋ рЇЋрѕ«рѕ░рѕх рѕЏрІхрѕерїЇ рЅ░рЅђрІ│рѕџ ріЦріЊ рѕўрѕ░рѕерЅ│рІі рїЅрІ│рІГ ріљрІЇ\n    ```\n\n2. Tokenization - Sentence\n    - Here is a simple example of performing sentence tokenization on a piece of plaintext using Amharic document:\n    - Within Amharic document, annotations are further stored in `Sentences`\n\n    ```python\n    from etnltk import Amharic\n\n    sample_text = \"\"\"\n      рІерѕЏрѕйріЋ рѕѕрѕГріњріЋрїЇ рѕхрѕЇрЅ░-рЅђрѕўрѕ«рЅй  (Algorithms) рЅарѕўрїарЅђрѕЮ рЅІріЋрЅІрІјрЅйріЋ рѕўрѕѕрІерЅх ріЦріЊ рѕўрѕерІ│рЅхрЇБ рІерїйрѕЂрЇЇ рІГрІўрЅХрЅйріЋ рѕўрѕѕрІерЅхрЇБ рІерЅІріЋрЅІріЋ рѕўрІІрЅЁрѕГ рѕўрЅ░ріЋрЅ░ріЋ рІерѕџрІФрѕхрЅйрѕЅ рІерѕЃрїѕрѕфріЏ ріЊрЅ╣рѕФрѕЇ рѕІріЋрїЅрІїрїЁ рЇЋрѕ«рѕ░рѕ▓ріЋрїЇ рЅ▒рѕјрЅй (NLP tools) рЇБ рѕхрѕЇрЅ░-рЅђрѕўрѕ«рЅй ріЦріЊ рѕърІ┤рѕјрЅйріЋ рѕЏрІўрїІрїђрЅх рЅ░рїѕрЅб ріљрІЇрЇб рЅарІџрѕЁрѕЮ рѕўрѕ░рѕерЅх ріарѕЏрѕГріЏрЇБ ріарЇІріЋ рідрѕ«рѕърЇБ рѕХрѕЏрѕіріЏ ріЦріЊ рЅхрїЇрѕГріЏ рЅІріЋрЅІрІјрЅйріЋ рѕѕрѕЏрѕйріЋ рІерѕЏрѕхрЅ░рѕЏрѕГ рѕѓрІ░рЅхріЋ рЅђрѕІрѕЇріЊ рІерЅ░рЅђрѕІрЅ░рЇЇ ріЦріЋрІ▓рѕєріЋ рІФрѕхрЅйрѕІрѕЇрЇАрЇА\n    \"\"\"\n\n    # Annotating Amharic Text\n    doc = Amharic(sample_text)\n\n    # print all list of `Sentence` in a document:\n    print(doc.sentences)\n    # output: [Sentence(\"рІерѕЏрѕйріЋ рѕѕрѕГріњріЋрїЇ рѕхрѕЇрЅ░рЅђрѕўрѕ«рЅй рЅарѕўрїарЅђрѕЮ рЅІріЋрЅІрІјрЅйріЋ рѕўрѕѕрІерЅх ріЦріЊ рѕўрѕерІ│рЅх рІерЇЁрѕЂрЇЇ рІГрІўрЅХрЅйріЋ рѕўрѕѕрІерЅх рІерЅІріЋрЅІріЋ рѕўрІІрЅЁрѕГ рѕўрЅ░ріЋрЅ░ріЋ рІерѕџрІФрѕхрЅйрѕЅ рІерѕђрїѕрѕфріЏ ріЊрЅ╣рѕФрѕЇ рѕІріЋрїЅрІїрїЁ рЇЋрѕ«рѕ░рѕ▓ріЋрїЇ рЅ▒рѕјрЅй рѕхрѕЇрЅ░рЅђрѕўрѕ«рЅй ріЦріЊ рѕърІ┤рѕјрЅйріЋ рѕЏрІўрїІрїђрЅх рЅ░рїѕрЅб ріљрІЇ\"), Sentence(\"рЅарІџрѕЁрѕЮ рѕўрѕ░рѕерЅх ріарѕЏрѕГріЏ ріарЇІріЋ рідрѕ«рѕъ рѕХрѕЏрѕіріЏ ріЦріЊ рЅхрїЇрѕГріЏ рЅІріЋрЅІрІјрЅйріЋ рѕѕрѕЏрѕйріЋ рІерѕЏрѕхрЅ░рѕЏрѕГ рѕѓрІ░рЅхріЋ рЅђрѕІрѕЇріЊ рІерЅ░рЅђрѕІрЅ░рЇЇ ріЦріЋрІ▓рѕєріЋ рІФрѕхрЅйрѕІрѕЇ\")]\n    ```\n\n    - Here is another example of performing sentence tokenization on a piece of plaintext using `sentence_tokenize` function:\n\n    ```python\n    from etnltk.tokenize.am import sent_tokenize\n\n    sample_text = \"\"\"\n      рІерѕЏрѕйріЋ рѕѕрѕГріњріЋрїЇ рѕхрѕЇрЅ░-рЅђрѕўрѕ«рЅй  (Algorithms) рЅарѕўрїарЅђрѕЮ рЅІріЋрЅІрІјрЅйріЋ рѕўрѕѕрІерЅх ріЦріЊ рѕўрѕерІ│рЅхрЇБ рІерїйрѕЂрЇЇ рІГрІўрЅХрЅйріЋ рѕўрѕѕрІерЅхрЇБ рІерЅІріЋрЅІріЋ рѕўрІІрЅЁрѕГ рѕўрЅ░ріЋрЅ░ріЋ рІерѕџрІФрѕхрЅйрѕЅ рІерѕЃрїѕрѕфріЏ ріЊрЅ╣рѕФрѕЇ рѕІріЋрїЅрІїрїЁ рЇЋрѕ«рѕ░рѕ▓ріЋрїЇ рЅ▒рѕјрЅй (NLP tools) рЇБ рѕхрѕЇрЅ░-рЅђрѕўрѕ«рЅй ріЦріЊ рѕърІ┤рѕјрЅйріЋ рѕЏрІўрїІрїђрЅх рЅ░рїѕрЅб ріљрІЇрЇб рЅарІџрѕЁрѕЮ рѕўрѕ░рѕерЅх ріарѕЏрѕГріЏрЇБ ріарЇІріЋ рідрѕ«рѕърЇБ рѕХрѕЏрѕіріЏ ріЦріЊ рЅхрїЇрѕГріЏ рЅІріЋрЅІрІјрЅйріЋ рѕѕрѕЏрѕйріЋ рІерѕЏрѕхрЅ░рѕЏрѕГ рѕѓрІ░рЅхріЋ рЅђрѕІрѕЇріЊ рІерЅ░рЅђрѕІрЅ░рЇЇ ріЦріЋрІ▓рѕєріЋ рІФрѕхрЅйрѕІрѕЇрЇАрЇА\n    \"\"\"\n\n    # Annotating a Document\n    sentences = sent_tokenize(sample_text)\n\n    # print all list of sentence:\n    print(sentences)\n    # output: ['рІерѕЏрѕйріЋ рѕѕрѕГріњріЋрїЇ рѕхрѕЇрЅ░рЅђрѕўрѕ«рЅй рЅарѕўрїарЅђрѕЮ рЅІріЋрЅІрІјрЅйріЋ рѕўрѕѕрІерЅх ріЦріЊ рѕўрѕерІ│рЅх рІерЇЁрѕЂрЇЇ рІГрІўрЅХрЅйріЋ рѕўрѕѕрІерЅх рІерЅІріЋрЅІріЋ рѕўрІІрЅЁрѕГ рѕўрЅ░ріЋрЅ░ріЋ рІерѕџрІФрѕхрЅйрѕЅ рІерѕђрїѕрѕфріЏ ріЊрЅ╣рѕФрѕЇ рѕІріЋрїЅрІїрїЁ рЇЋрѕ«рѕ░рѕ▓ріЋрїЇ рЅ▒рѕјрЅй рѕхрѕЇрЅ░рЅђрѕўрѕ«рЅй ріЦріЊ рѕърІ┤рѕјрЅйріЋ рѕЏрІўрїІрїђрЅх рЅ░рїѕрЅб ріљрІЇ', 'рЅарІџрѕЁрѕЮ рѕўрѕ░рѕерЅх ріарѕЏрѕГріЏ ріарЇІріЋ рідрѕ«рѕъ рѕХрѕЏрѕіріЏ ріЦріЊ рЅхрїЇрѕГріЏ рЅІріЋрЅІрІјрЅйріЋ рѕѕрѕЏрѕйріЋ рІерѕЏрѕхрЅ░рѕЏрѕГ рѕѓрІ░рЅхріЋ рЅђрѕІрѕЇріЊ рІерЅ░рЅђрѕІрЅ░рЇЇ ріЦріЋрІ▓рѕєріЋ рІФрѕхрЅйрѕІрѕЇ']\n\n3. Tokenization - Word\n    - Here is a simple example of performing word tokenization on a piece of plaintext using AmharicDocument:\n    - Within Amharic focument, annotations are further stored in `Words`.\n\n    ```python\n    from etnltk import AmharicDocument\n\n    sample_text = \"\"\"\n      РђюрЅ░рѕеріЏрЇБ рЅ░рѕеріЏ!РђЮ ріарѕѕ ріљрѕГрѕ▒рЇб рІѕрІГрІўрѕ«\n      рЅ│рѕфрі│рЇБ РђюріарЅцрЅх!РђЮ рЅЦрѕѕрІЇ рІерѕЂрѕѕрЅх\n      рІЊрѕўрЅх рѕЇрїЃрЅИрІЇріЋ рІГрІўрІЇ рїѕрЅАрЇб\n      РђюрѕЮріЉріЋ ріљрІЇ рІФрѕўрѕўрІЇ?РђЮ рІХріГрЅ░рѕ»\n      рїарІерЅЂрЇб РђюріарІФрІЕрЅхрѕЮ! рЇђрїЅрѕЕ рѕ│рѕхрЅирѕЇрЇц\n      рѕєрІ▒ рЅ░ріљрЇЇрЅирѕЇрЇц рІхрІ▒рѕЮ рІГрІ░рѕЏрѕЇРђЮ\n      ріарѕЅ рІѕрІГрІўрѕ« рЅ│рѕфрі│рЇб рІХріГрЅ░рѕ»рѕЮрЇБ\n      РђюрЅарїБрѕЮ рІФрѕ│рІЮріЊрѕЇрЇц ріЦріЋрІ░рІџрѕЁ\n      рІФрІ░рѕерїѕрІЇ рІерЅ░рѕўрїБрїаріљ рѕЮрїЇрЅЦ ріарѕѕрѕЏрїЇріўрЅ▒ ріљрІЇрЇб ріарѕЂріЋрѕЮ рІѕрЅ░рЅхрЇБ\n      ріЦріЋрЅЂрѕІрѕЇрЇБ рѕЏрѕГрЇБ ріарЅхріГрѕЇрЅхріЊ рЇЇрѕФрЇЇрѕг рІГрѕўрїЇрЅАрЅхрЇц рЅХрѕј рІГрѕ╗рѕѕрІІрѕЇрЇц\n      рѕѕріарѕЂріЉ рїЇріЋ рѕўрІхріЃріњрЅх ріарІЮрѕѕрЅ│рѕѕрѕЂРђЮ рЅарѕЏрѕѕрЅх ріарѕхрѕерІирЅИрІЇрЇб рІѕрІГрІўрѕ«\n      рЅ│рѕфрі│рѕЮ РђюрІѕрІГ ріарѕѕрѕЏрІѕрЅЁ! рѕЇрїёріЋ рЅарѕЮрїЇрЅЦ ріЦрїЦрѕерЅх рїѕрІхрІгрІЇ ріљрЅарѕГ\"\n      рЅарѕЏрѕѕрЅх ріарѕѕрЅђрѕ▒рЇб\n\n      \"\"\"\n    \n    # Annotating Amharic Text\n    doc = Amharic(sample_text)\n\n    # print all list of `AmharicWord` in a document:\n    print(doc.words)\n    # output: ['рЅ░рѕеріЏ', 'рЅ░рѕеріЏ', 'ріарѕѕ', 'ріљрѕГрѕ▒', 'рІѕрІГрІўрѕ«', 'рЅ│рѕфрі│', 'ріарЅцрЅх', 'рЅЦрѕѕрІЇ', 'рІерѕЂрѕѕрЅх', 'ріарѕўрЅх', 'рѕЇрїЃрЅИрІЇріЋ', 'рІГрІўрІЇ', 'рїѕрЅА', 'рѕЮріЉріЋ', 'ріљрІЇ', 'рІФрѕўрѕўрІЇ', 'рІХріГрЅ░рѕ»', 'рїарІерЅЂ', 'ріарІФрІЕрЅхрѕЮ', 'рЇђрїЅрѕЕ', 'рѕ│рѕхрЅирѕЇ', 'рѕєрІ▒', 'рЅ░ріљрЇЇрЅирѕЇ', 'рІхрІ▒рѕЮ', 'рІГрІ░рѕЏрѕЇ', 'ріарѕЅ', 'рІѕрІГрІўрѕ«', 'рЅ│рѕфрі│', 'рІХріГрЅ░рѕ»рѕЮ', 'рЅарїБрѕЮ', 'рІФрѕ│рІЮріЊрѕЇ', 'ріЦріЋрІ░рІџрѕЁ', 'рІФрІ░рѕерїѕрІЇ', 'рІерЅ░рѕўрїБрїаріљ', 'рѕЮрїЇрЅЦ', 'ріарѕѕрѕЏрїЇріўрЅ▒', 'ріљрІЇ', 'ріарѕЂріЋрѕЮ', 'рІѕрЅ░рЅх', 'ріЦріЋрЅЂрѕІрѕЇ', 'рѕЏрѕГ', 'ріарЅхріГрѕЇрЅхріЊ', 'рЇЇрѕФрЇЇрѕг', 'рІГрѕўрїЇрЅАрЅх', 'рЅХрѕј', 'рІГрѕ╗рѕѕрІІрѕЇ', 'рѕѕріарѕЂріЉ', 'рїЇріЋ', 'рѕўрІхрѕђріњрЅх', 'ріарІЮрѕѕрЅ│рѕѕрѕЂ', 'рЅарѕЏрѕѕрЅх', 'ріарѕхрѕерІирЅИрІЇ', 'рІѕрІГрІўрѕ«', 'рЅ│рѕфрі│рѕЮ', 'рІѕрІГ', 'ріарѕѕрѕЏрІѕрЅЁ', 'рѕЇрїёріЋ', 'рЅарѕЮрїЇрЅЦ', 'ріЦрїЦрѕерЅх', 'рїѕрІхрІгрІЇ', 'ріљрЅарѕГ', 'рЅарѕЏрѕѕрЅх', 'ріарѕѕрЅђрѕ▒']\n    ```\n\n    - Here is another example of performing word tokenization on a piece of plaintext using `word_tokenize` function:\n\n    ```python\n    from etnltk.tokenize.am import word_tokenize\n\n    sample_text = \"\"\"\n      РђюрЅ░рѕеріЏрЇБ рЅ░рѕеріЏ!РђЮ ріарѕѕ ріљрѕГрѕ▒рЇб рІѕрІГрІўрѕ«\n      рЅ│рѕфрі│рЇБ РђюріарЅцрЅх!РђЮ рЅЦрѕѕрІЇ рІерѕЂрѕѕрЅх\n      рІЊрѕўрЅх рѕЇрїЃрЅИрІЇріЋ рІГрІўрІЇ рїѕрЅАрЇб\n      РђюрѕЮріЉріЋ ріљрІЇ рІФрѕўрѕўрІЇ?РђЮ рІХріГрЅ░рѕ»\n      рїарІерЅЂрЇб РђюріарІФрІЕрЅхрѕЮ! рЇђрїЅрѕЕ рѕ│рѕхрЅирѕЇрЇц\n      рѕєрІ▒ рЅ░ріљрЇЇрЅирѕЇрЇц рІхрІ▒рѕЮ рІГрІ░рѕЏрѕЇРђЮ\n      ріарѕЅ рІѕрІГрІўрѕ« рЅ│рѕфрі│рЇб рІХріГрЅ░рѕ»рѕЮрЇБ\n      РђюрЅарїБрѕЮ рІФрѕ│рІЮріЊрѕЇрЇц ріЦріЋрІ░рІџрѕЁ\n      рІФрІ░рѕерїѕрІЇ рІерЅ░рѕўрїБрїаріљ рѕЮрїЇрЅЦ ріарѕѕрѕЏрїЇріўрЅ▒ ріљрІЇрЇб ріарѕЂріЋрѕЮ рІѕрЅ░рЅхрЇБ\n      ріЦріЋрЅЂрѕІрѕЇрЇБ рѕЏрѕГрЇБ ріарЅхріГрѕЇрЅхріЊ рЇЇрѕФрЇЇрѕг рІГрѕўрїЇрЅАрЅхрЇц рЅХрѕј рІГрѕ╗рѕѕрІІрѕЇрЇц\n      рѕѕріарѕЂріЉ рїЇріЋ рѕўрІхріЃріњрЅх ріарІЮрѕѕрЅ│рѕѕрѕЂРђЮ рЅарѕЏрѕѕрЅх ріарѕхрѕерІирЅИрІЇрЇб рІѕрІГрІўрѕ«\n      рЅ│рѕфрі│рѕЮ РђюрІѕрІГ ріарѕѕрѕЏрІѕрЅЁ! рѕЇрїёріЋ рЅарѕЮрїЇрЅЦ ріЦрїЦрѕерЅх рїѕрІхрІгрІЇ ріљрЅарѕГ\"\n      рЅарѕЏрѕѕрЅх ріарѕѕрЅђрѕ▒рЇб\n\n    \"\"\"\n      \n    # word tokenization\n    words = word_tokenize(sample_text)\n\n    # print all list of word:\n    print(words)\n    # output: ['рЅ░рѕеріЏ', 'рЅ░рѕеріЏ', 'ріарѕѕ', 'ріљрѕГрѕ▒', 'рІѕрІГрІўрѕ«', 'рЅ│рѕфрі│', 'ріарЅцрЅх', 'рЅЦрѕѕрІЇ', 'рІерѕЂрѕѕрЅх', 'ріарѕўрЅх', 'рѕЇрїЃрЅИрІЇріЋ', 'рІГрІўрІЇ', 'рїѕрЅА', 'рѕЮріЉріЋ', 'ріљрІЇ', 'рІФрѕўрѕўрІЇ', 'рІХріГрЅ░рѕ»', 'рїарІерЅЂ', 'ріарІФрІЕрЅхрѕЮ', 'рЇђрїЅрѕЕ', 'рѕ│рѕхрЅирѕЇ', 'рѕєрІ▒', 'рЅ░ріљрЇЇрЅирѕЇ', 'рІхрІ▒рѕЮ', 'рІГрІ░рѕЏрѕЇ', 'ріарѕЅ', 'рІѕрІГрІўрѕ«', 'рЅ│рѕфрі│', 'рІХріГрЅ░рѕ»рѕЮ', 'рЅарїБрѕЮ', 'рІФрѕ│рІЮріЊрѕЇ', 'ріЦріЋрІ░рІџрѕЁ', 'рІФрІ░рѕерїѕрІЇ', 'рІерЅ░рѕўрїБрїаріљ', 'рѕЮрїЇрЅЦ', 'ріарѕѕрѕЏрїЇріўрЅ▒', 'ріљрІЇ', 'ріарѕЂріЋрѕЮ', 'рІѕрЅ░рЅх', 'ріЦріЋрЅЂрѕІрѕЇ', 'рѕЏрѕГ', 'ріарЅхріГрѕЇрЅхріЊ', 'рЇЇрѕФрЇЇрѕг', 'рІГрѕўрїЇрЅАрЅх', 'рЅХрѕј', 'рІГрѕ╗рѕѕрІІрѕЇ', 'рѕѕріарѕЂріЉ', 'рїЇріЋ', 'рѕўрІхрѕђріњрЅх', 'ріарІЮрѕѕрЅ│рѕѕрѕЂ', 'рЅарѕЏрѕѕрЅх', 'ріарѕхрѕерІирЅИрІЇ', 'рІѕрІГрІўрѕ«', 'рЅ│рѕфрі│рѕЮ', 'рІѕрІГ', 'ріарѕѕрѕЏрІѕрЅЁ', 'рѕЇрїёріЋ', 'рЅарѕЮрїЇрЅЦ', 'ріЦрїЦрѕерЅх', 'рїѕрІхрІгрІЇ', 'ріљрЅарѕГ', 'рЅарѕЏрѕѕрЅх', 'ріарѕѕрЅђрѕ▒']\n\n4. Normalization\n    1. Character Level Normalization such as \"`рїИ`рѕђрІГ\" and \"`рЇђ`рѕљрІГ\"\n    2. Labialized Character Normalzation such as \"рѕърѕЇ`рЅ▒рІІ`рѕЇ\" to \"рѕърѕЇ`рЅи`рѕЇ\"\n    3. Short Form Expansion such as \"`ріа.ріа`\" to \"`ріарІ▓рѕх ріарЅарЅБ`\"\n    4. Punctuation Normalization such as `::` to `рЇб`\n\n    - Here is a simple example of performing normalization on a piece of plaintext using `normalize` function:\n\n    ```python\n    from etnltk.lang.am import normalize\n\n    sample_text = \"\"\"\n      рѕџрІФрІЮрІФ 14рЇБ 2014 рІЊ.рѕЮ рЅарІЊрїѕрѕГ рІ░рѕерїЃ рІерѕ░рІЇ рѕ░рѕФрѕй ріарѕхрЅ░рІЇрѕјрЅх рІерІЇрІГрІГрЅх рѕўрІхрѕеріГ рѕІрІГ\n      рІерѕЃрїѕрѕГріЏ рЅІріЋрЅІрІјрЅй рЅхрѕГрїЅрѕЮ ріарїѕрѕЇрїЇрѕјрЅхрЇБ \n      рЅ╗рЅхрЅдрЅх (рІерІЇрІГрІГрЅх рѕўрѕѕрІІрІѕрїФ рѕ«рЅдрЅх): \n      рІерЇЁрѕЂрЇЇ рѕ░ріљрІХрЅй рѕѕрѕўрѕѕрІерЅхрЇБ рІерЅЃрѕІрЅх рЅхріГріГрѕѕріЏріљрЅхріЋ рѕѕрѕЏрѕерїІрїѕрїЦрЇБ \n      рЅарЅІріЋрЅІріЋ рѕЋрїЇрїІрЅх рѕўрѕарѕерЅх рїйрѕЉрЇјрЅйріЋ рѕѕрѕЏрІІрЅђрѕГ ріЦріЊ рѕѕрѕўрѕўрѕхрѕерЅхрЇБ \n      рѕерїЁрѕЮ рїйрѕЂрЇјрЅйріЋ рѕѕрѕЏрѕ│рїарѕГрЇБ ріаріЋрі│рѕГ рїЅрІ│рІ«рЅйріЋ рѕўрѕѕрІерЅх рІѕрІГрѕЮ рїЦрЅЁрѕЇ рѕЃрѕ│рЅЦ рѕѕрѕЏрІЇрїБрЅхрЇБ \n      ріЋрїЇрїЇрѕГріЋ рІѕрІ░ рїйрѕЂрЇЇ рѕѕрѕўрЅђрІерѕГ рІерѕџрІФрѕхрЅйрѕЅ рѕўрЅ░рїЇрЅарѕфрІФрІјрЅйріЋ рѕЏрѕЇрѕЏрЅх ріарѕхрѕерѕІрїіріљрЅ▒ рЅ░рїѕрѕЇрї╣рІІрѕЇ::\n    \"\"\"\n\n    # normalization\n    normalized_text = normalize(sample_text)\n\n    # The following example shows how to print all normalized in a document:\n    print(normalized_text)\n    # output: рѕџрІФрІЮрІФ 14рЇБ 2014 ріарѕўрЅ░ рѕЮрѕЁрѕерЅх рЅаріарїѕрѕГ рІ░рѕерїЃ рІерѕ░рІЇ рѕ░рѕФрѕй ріарѕхрЅ░рІЇрѕјрЅх рІерІЇрІГрІГрЅх рѕўрІхрѕеріГ рѕІрІГ\n    # рІерѕђрїѕрѕГріЏ рЅІріЋрЅІрІјрЅй рЅхрѕГрїЅрѕЮ ріарїѕрѕЇрїЇрѕјрЅхрЇБ \n    # рЅ╗рЅхрЅдрЅх (рІерІЇрІГрІГрЅх рѕўрѕѕрІІрІѕрїФ рѕ«рЅдрЅх)рЇА \n    # рІерЇЁрѕЂрЇЇ рѕ░ріљрІХрЅй рѕѕрѕўрѕѕрІерЅхрЇБ рІерЅЃрѕІрЅх рЅхріГріГрѕѕріЏріљрЅхріЋ рѕѕрѕЏрѕерїІрїѕрїЦрЇБ \n    # рЅарЅІріЋрЅІріЋ рѕЁрїЇрїІрЅх рѕўрѕ░рѕерЅх рЇЁрѕЂрЇјрЅйріЋ рѕѕрѕЏрІІрЅђрѕГ ріЦріЊ рѕѕрѕўрѕўрѕхрѕерЅхрЇБ \n    # рѕерїЁрѕЮ рЇЁрѕЂрЇјрЅйріЋ рѕѕрѕЏрѕ│рїарѕГрЇБ ріаріЋрі│рѕГ рїЅрІ│рІ«рЅйріЋ рѕўрѕѕрІерЅх рІѕрІГрѕЮ рїЦрЅЁрѕЇ рѕђрѕ│рЅЦ рѕѕрѕЏрІЇрїБрЅхрЇБ \n    # ріЋрїЇрїЇрѕГріЋ рІѕрІ░ рЇЁрѕЂрЇЇ рѕѕрѕўрЅђрІерѕГ рІерѕџрІФрѕхрЅйрѕЅ рѕўрЅ░рїЇрЅарѕфрІФрІјрЅйріЋ рѕЏрѕЇрѕЏрЅх ріарѕхрѕерѕІрїіріљрЅ▒ рЅ░рїѕрѕЇрї┐рѕЇрЇб \"\"\"\n    ```\n\n    - Here is another example of performing normalization on a piece of plaintext using `normalize_char`, `normalize_punct`, `normalize_labialized`, `normalize_shortened` function:\n\n    ```python\n    from etnltk.lang.am.normalizer import ( \n      normalize_labialized, \n      normalize_shortened,\n      normalize_punct,\n      normalize_char\n    )\n\n    # normalize labialized \n    normalized_text = normalize_labialized(\"ріЋрїЇрїЇрѕГріЋ рІѕрІ░ рїйрѕЂрЇЇ рѕѕрѕўрЅђрІерѕГ рІерѕџрІФрѕхрЅйрѕЅ рѕўрЅ░рїЇрЅарѕфрІФрІјрЅйріЋ рѕЏрѕЇрѕЏрЅх ріарѕхрѕерѕІрїіріљрЅ▒ рЅ░рїѕрѕЇрї╣рІІрѕЇ\")\n    print(normalized_text)\n    # output: ріЋрїЇрїЇрѕГріЋ рІѕрІ░ рЇЁрѕЂрЇЇ рѕѕрѕўрЅђрІерѕГ рІерѕџрІФрѕхрЅйрѕЅ рѕўрЅ░рїЇрЅарѕфрІФрІјрЅйріЋ рѕЏрѕЇрѕЏрЅх ріарѕхрѕерѕІрїіріљрЅ▒ рЅ░рїѕрѕЇрї┐рѕЇ\n\n    # normalize short forms\n    normalized_text = normalize_shortened(\"рѕџрІФрІЮрІФ 14рЇБ 2014 рІЊ.рѕЮ рЅарІЊрїѕрѕГ рІ░рѕерїЃ рІерѕ░рІЇ рѕ░рѕФрѕй ріарѕхрЅ░рІЇрѕјрЅх рІерІЇрІГрІГрЅх рѕўрІхрѕеріГ\")\n    print(normalized_text)\n    # output: рѕџрІФрІЮрІФ 14рЇБ 2014 рІЊрѕўрЅ░ рѕЮрѕЁрѕерЅх рЅаріарїѕрѕГ рІ░рѕерїЃ рІерѕ░рІЇ рѕ░рѕФрѕй ріарѕхрЅ░рІЇрѕјрЅх рІерІЇрІГрІГрЅх рѕўрІхрѕеріГ\n\n    # normalize punctuation\n    normalized_text = normalize_punct(\"рѕўрЅ░рїЇрЅарѕфрІФрІјрЅйріЋ рѕЏрѕЇрѕЏрЅх ріарѕхрѕерѕІрїіріљрЅ▒ рЅ░рїѕрѕЇрї╣рІІрѕЇ::\")\n    print(normalized_text)\n    # output: рѕўрЅ░рїЇрЅарѕфрІФрІјрЅйріЋ рѕЏрѕЇрѕЏрЅх ріарѕхрѕерѕІрїіріљрЅ▒ рЅ░рїѕрѕЇрї┐рѕЇрЇб\n\n    # normalize characters\n    normalized_text = normalize_char(\"рЅарЅІріЋрЅІрІЅ рѕЋрїЇрїІрЅх рѕўрѕарѕерЅх рїйрѕЉрЇјрЅйріЋ рѕЏрІІрЅђрѕГ ріЦріЊ рѕўрѕўрѕЦрѕерЅх\")\n    print(normalized_text)\n    # output: рЅарЅІріЋрЅІрІЅ рѕЁрїЇрїІрЅх рѕўрѕ░рѕерЅх рЇЁрѕЂрЇјрЅйріЋ рѕЏрІІрЅђрѕГ ріЦріЊ рѕўрѕўрѕхрѕерЅх\n\n## Features\n\n- Text preprocessing functions.\n\n    ``` python\n    from etnltk.lang.am import preprocessing\n    ```\n\n    | Function | Description |\n    -----------|-------------|\n    | remove_whitespaces | Remove extra spaces, tabs, and new lines from a text string\n    | remove_links | Remove URLs from a text string\n    | remove_tags | Remove HTML tags from a text string\n    | remove_emojis | Remove emojis from a text string\n    | remove_email | Remove email adresses from a text string\n    | remove_digits | Remove all digits from a text string\n    | remove_english_chars | Remove ascii characters from a text string\n    | remove_arabic_chars | Remove arabic characters and numerals from a text string\n    | remove_chinese_chars | Remove chinese characters from a text string\n    | remove_ethiopic_digits | Remove all ethiopic digits from a text string\n    | remove_ethiopic_punct | Remove ethiopic punctuations from a text string\n    | remove_non_ethiopic | Remove non ethioipc characters from a text string\n    | remove_stopwords | Remove stop words\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/robikieq/etnltk.git",
    "keywords": "['nlp','ethiopic','amharic','tokenization','preprocessing','text-analytics']",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "etnltk",
    "package_url": "https://pypi.org/project/etnltk/",
    "platform": null,
    "project_url": "https://pypi.org/project/etnltk/",
    "project_urls": {
      "Homepage": "https://github.com/robikieq/etnltk.git"
    },
    "release_url": "https://pypi.org/project/etnltk/0.0.22/",
    "requires_dist": [
      "textsearch (>=0.0.21)",
      "emoji (>=1.7.0)"
    ],
    "requires_python": ">=3.6",
    "summary": "Ethiopian Natural Language Toolkit",
    "version": "0.0.22",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 13837594,
  "releases": {
    "0.0.22": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7e75e4080c75afdfc6b435f2ad0fab9d25eebcdaefdbed6d1875ea218c6255fd",
          "md5": "3105d3a4de55b09e09dc9d860e370397",
          "sha256": "c19dbe624e48c91f15bc7b4e4cd343105ef31f34dc03a8e433ee4c152893e788"
        },
        "downloads": -1,
        "filename": "etnltk-0.0.22-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "3105d3a4de55b09e09dc9d860e370397",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 20609,
        "upload_time": "2022-05-17T06:36:15",
        "upload_time_iso_8601": "2022-05-17T06:36:15.933157Z",
        "url": "https://files.pythonhosted.org/packages/7e/75/e4080c75afdfc6b435f2ad0fab9d25eebcdaefdbed6d1875ea218c6255fd/etnltk-0.0.22-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f6f87c58e6525b8764e886ff1b5f2a3e58b7812da0f8af8567010cd30fb721a7",
          "md5": "ac2c018d36f36bca06d4f66e1163f2c9",
          "sha256": "c231a918631cb4c1a5cba76bc3b493d1afc84ba6a5092457c71f3fe8596c4ce9"
        },
        "downloads": -1,
        "filename": "etnltk-0.0.22.tar.gz",
        "has_sig": false,
        "md5_digest": "ac2c018d36f36bca06d4f66e1163f2c9",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 20583,
        "upload_time": "2022-05-17T06:36:18",
        "upload_time_iso_8601": "2022-05-17T06:36:18.190222Z",
        "url": "https://files.pythonhosted.org/packages/f6/f8/7c58e6525b8764e886ff1b5f2a3e58b7812da0f8af8567010cd30fb721a7/etnltk-0.0.22.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "7e75e4080c75afdfc6b435f2ad0fab9d25eebcdaefdbed6d1875ea218c6255fd",
        "md5": "3105d3a4de55b09e09dc9d860e370397",
        "sha256": "c19dbe624e48c91f15bc7b4e4cd343105ef31f34dc03a8e433ee4c152893e788"
      },
      "downloads": -1,
      "filename": "etnltk-0.0.22-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "3105d3a4de55b09e09dc9d860e370397",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 20609,
      "upload_time": "2022-05-17T06:36:15",
      "upload_time_iso_8601": "2022-05-17T06:36:15.933157Z",
      "url": "https://files.pythonhosted.org/packages/7e/75/e4080c75afdfc6b435f2ad0fab9d25eebcdaefdbed6d1875ea218c6255fd/etnltk-0.0.22-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "f6f87c58e6525b8764e886ff1b5f2a3e58b7812da0f8af8567010cd30fb721a7",
        "md5": "ac2c018d36f36bca06d4f66e1163f2c9",
        "sha256": "c231a918631cb4c1a5cba76bc3b493d1afc84ba6a5092457c71f3fe8596c4ce9"
      },
      "downloads": -1,
      "filename": "etnltk-0.0.22.tar.gz",
      "has_sig": false,
      "md5_digest": "ac2c018d36f36bca06d4f66e1163f2c9",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 20583,
      "upload_time": "2022-05-17T06:36:18",
      "upload_time_iso_8601": "2022-05-17T06:36:18.190222Z",
      "url": "https://files.pythonhosted.org/packages/f6/f8/7c58e6525b8764e886ff1b5f2a3e58b7812da0f8af8567010cd30fb721a7/etnltk-0.0.22.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}