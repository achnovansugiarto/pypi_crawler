{
  "info": {
    "author": "Robel Equbasilassie",
    "author_email": "robiki4life@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Ethiopian Natural Language Toolkit (etnltk)\n\n- The Ethiopian Natural Language Toolkit (etnltk) project aimed to develop a suite of open source Natural Language Processing modules for the Ethiopian languages.\n- The Ethiopian Natural Language Toolkit (etnltk) is built using python language and takes inspiration from `spacy` and `nltk` libraries.\n\n## Installation\n\n### pip\n\n- **etnltk** supports Python 3.6 or later. We recommend that you install etnltk via `pip`, the Python package manager. To install, simply run:\n\n  ```python\n    pip install etnltk\n  ```\n\n### From Source\n\n- Alternatively, you can also install from source via `etnltk` git repository, which will give you more flexibility in developing on top of etltk. For this option, run\n\n  ```python\n    git clone https://github.com/robikieq/etnltk.git\n    \n    cd etnltk\n    \n    pip install -e .\n  ```\n\n## Documentation\n\n<https://etnltk.netlify.app/>\n\n## Usage\n\n1. Amharic text preprocessing with Amharic document\n    - Preprocessing amharic text is very simple: you can simply pass the text to the `Amharic` document and access all annotations from the returned Amharic document object:\n\n    ```python\n      from etnltk import Amharic\n\n      sample_text = \"\"\"\n        áˆšá‹«á‹á‹« 14á£ 2014 á‹“.áˆ ðŸ¤— á‰ áŠ áŒˆáˆ­ á‹°áˆ¨áŒƒ á‹¨áˆ°á‹ áˆ°áˆ«áˆ½ áŠ áˆµá‰°á‹áˆŽá‰µ /Artificial Intelligence/ áŠ áˆáŠ• áŠ«áˆˆá‰ á‰µ á‹á‰…á‰°áŠ› á‹°áˆ¨áŒƒ á‹ˆá‹° áˆ‹á‰€ á‹°áˆ¨áŒƒ áˆˆáˆ›á‹µáˆ¨áˆµá£ áˆƒáŒˆáˆ­áŠ› á‰‹áŠ•á‰‹á‹Žá‰½áŠ• áˆˆá‹“áˆˆáˆ á‰°á‹°áˆ«áˆ½ áˆˆáˆ›á‹µáˆ¨áŒá£ áŠ áŒˆáˆ«á‹Š áŠ á‰…áˆáŠ• áˆˆáˆ›áˆ³á‹°áŒ áŠ¥áŠ“ á‰°áŒ á‰ƒáˆš áˆˆáˆ˜áˆ†áŠ• á‰ áŒ‹áˆ« áŠ á‰¥áˆ® áˆ˜áˆµáˆ«á‰± áŠ¥áŒ…áŒ áŒ á‰ƒáˆš áŠá‹á¡á¡\n\n        á‰ áˆ›áˆ½áŠ• á‹“áˆµá‰°áˆáˆ® (Machine Learning) áŠ áˆ›áŠ«áŠáŠá‰µ á‹¨áŒ½áˆá áŠ“áˆ™áŠ“á‹Žá‰½ á‰ áŠ áˆ­á‰²áŠáˆ»áˆ áŠ¢áŠ•á‰°áˆˆáŒ€áŠ•áˆµ áˆ¥áˆ­á‹“á‰µ áˆˆáˆ›áˆ°áˆáŒ áŠ•á£ á‹¨áŒ½áˆá á‹³á‰³áŠ• áˆ˜áˆ°á‰¥áˆ°á‰¥ áŠ¥áŠ“ áˆ›á‹°áˆ«áŒ€á‰µá¤ á‹¨áŠ“á‰¹áˆ«áˆ áˆ‹áŠ•áŒ‰á‹ŒáŒ… á•áˆ®áˆ°áˆ²áŠ•áŒ á‰±áˆŽá‰½áŠ• /Natural Language Processing Tools/ á‰ áˆ˜áŒ á‰€áˆ á‹¨áŒ½áˆá á‹³á‰³áŠ• á•áˆ®áˆ°áˆµ áˆ›á‹µáˆ¨áŒ á‰°á‰€á‹³áˆš áŠ¥áŠ“ áˆ˜áˆ°áˆ¨á‰³á‹Š áŒ‰á‹³á‹­ áŠá‹á¢\n      \"\"\"\n  \n      # Annotating Amharic document\n      doc = Amharic(sample_text)\n\n      # print the `clean` text:\n      print(doc)\n      \n      # output: Amharic(\"áˆšá‹«á‹á‹« á‹“áˆ˜á‰° áˆáˆ…áˆ¨á‰µ á‰ áŠ áŒˆáˆ­ á‹°áˆ¨áŒƒ á‹¨áˆ°á‹ áˆ°áˆ«áˆ½ áŠ áˆµá‰°á‹áˆŽá‰µ áŠ áˆáŠ• áŠ«áˆˆá‰ á‰µ á‹á‰…á‰°áŠ› á‹°áˆ¨áŒƒ á‹ˆá‹° áˆ‹á‰€ á‹°áˆ¨áŒƒ áˆˆáˆ›á‹µáˆ¨áˆµ áˆ€áŒˆáˆ­áŠ› á‰‹áŠ•á‰‹á‹Žá‰½áŠ• áˆˆáŠ áˆˆáˆ á‰°á‹°áˆ«áˆ½ áˆˆáˆ›á‹µáˆ¨áŒ áŠ áŒˆáˆ«á‹Š áŠ á‰…áˆáŠ• áˆˆáˆ›áˆ³á‹°áŒ áŠ¥áŠ“ á‰°áŒ á‰ƒáˆš áˆˆáˆ˜áˆ†áŠ• á‰ áŒ‹áˆ« áŠ á‰¥áˆ® áˆ˜áˆµáˆ«á‰± áŠ¥áŒ…áŒ áŒ á‰ƒáˆš áŠá‹ á‰ áˆ›áˆ½áŠ• áŠ áˆµá‰°áˆáˆ® áŠ áˆ›áŠ«áŠáŠá‰µ á‹¨á…áˆá áŠ“áˆ™áŠ“á‹Žá‰½ á‰ áŠ áˆ­á‰²áŠáˆ»áˆ áŠ¢áŠ•á‰°áˆˆáŒ€áŠ•áˆµ áˆµáˆ­áŠ á‰µ áˆˆáˆ›áˆ°áˆáŒ áŠ• á‹¨á…áˆá á‹³á‰³áŠ• áˆ˜áˆ°á‰¥áˆ°á‰¥ áŠ¥áŠ“ áˆ›á‹°áˆ«áŒ€á‰µ á‹¨áŠ“á‰¹áˆ«áˆ áˆ‹áŠ•áŒ‰á‹ŒáŒ… á•áˆ®áˆ°áˆ²áŠ•áŒ á‰±áˆŽá‰½áŠ• á‰ áˆ˜áŒ á‰€áˆ á‹¨á…áˆá á‹³á‰³áŠ• á•áˆ®áˆ°áˆµ áˆ›á‹µáˆ¨áŒ á‰°á‰€á‹³áˆš áŠ¥áŠ“ áˆ˜áˆ°áˆ¨á‰³á‹Š áŒ‰á‹³á‹­ áŠá‹\")\n    ```\n\n     - Here is a another example of performing text cleaning on a piece of plaintext using `clean_amharic` function:\n\n    ```python\n    from etnltk.lang.am import (\n      preprocessing,\n      clean_amharic\n    )\n\n    sample_text = \"\"\"\n      áˆšá‹«á‹á‹« 14á£ 2014 á‹“.áˆ ðŸ¤— á‰ áŠ áŒˆáˆ­ á‹°áˆ¨áŒƒ á‹¨áˆ°á‹ áˆ°áˆ«áˆ½ áŠ áˆµá‰°á‹áˆŽá‰µ /Artificial Intelligence/ áŠ áˆáŠ• áŠ«áˆˆá‰ á‰µ á‹á‰…á‰°áŠ› á‹°áˆ¨áŒƒ á‹ˆá‹° áˆ‹á‰€ á‹°áˆ¨áŒƒ áˆˆáˆ›á‹µáˆ¨áˆµá£ áˆƒáŒˆáˆ­áŠ› á‰‹áŠ•á‰‹á‹Žá‰½áŠ• áˆˆá‹“áˆˆáˆ á‰°á‹°áˆ«áˆ½ áˆˆáˆ›á‹µáˆ¨áŒá£ áŠ áŒˆáˆ«á‹Š áŠ á‰…áˆáŠ• áˆˆáˆ›áˆ³á‹°áŒ áŠ¥áŠ“ á‰°áŒ á‰ƒáˆš áˆˆáˆ˜áˆ†áŠ• á‰ áŒ‹áˆ« áŠ á‰¥áˆ® áˆ˜áˆµáˆ«á‰± áŠ¥áŒ…áŒ áŒ á‰ƒáˆš áŠá‹á¡á¡\n\n      á‰ áˆ›áˆ½áŠ• á‹“áˆµá‰°áˆáˆ® (Machine Learning) áŠ áˆ›áŠ«áŠáŠá‰µ á‹¨áŒ½áˆá áŠ“áˆ™áŠ“á‹Žá‰½ á‰ áŠ áˆ­á‰²áŠáˆ»áˆ áŠ¢áŠ•á‰°áˆˆáŒ€áŠ•áˆµ áˆ¥áˆ­á‹“á‰µ áˆˆáˆ›áˆ°áˆáŒ áŠ•á£ á‹¨áŒ½áˆá á‹³á‰³áŠ• áˆ˜áˆ°á‰¥áˆ°á‰¥ áŠ¥áŠ“ áˆ›á‹°áˆ«áŒ€á‰µá¤ á‹¨áŠ“á‰¹áˆ«áˆ áˆ‹áŠ•áŒ‰á‹ŒáŒ… á•áˆ®áˆ°áˆ²áŠ•áŒ á‰±áˆŽá‰½áŠ• /Natural Language Processing Tools/ á‰ áˆ˜áŒ á‰€áˆ á‹¨áŒ½áˆá á‹³á‰³áŠ• á•áˆ®áˆ°áˆµ áˆ›á‹µáˆ¨áŒ á‰°á‰€á‹³áˆš áŠ¥áŠ“ áˆ˜áˆ°áˆ¨á‰³á‹Š áŒ‰á‹³á‹­ áŠá‹á¢\n    \"\"\"\n\n    # Define a custom preprocessor pipeline\n    custom_pipeline = [\n      preprocessing.remove_emojis, \n      preprocessing.remove_digits,\n      preprocessing.remove_ethiopic_punct,\n      preprocessing.remove_english_chars, \n      preprocessing.remove_punct\n    ]\n    \n    # `clean_amharic` function takes a custom pipeline, if not uses the default pipeline\n    cleaned = clean_amharic(input_text, abbrev=False, pipeline=custom_pipeline)\n\n    # print the `clean` text:\n    print(cleaned)\n    # output: áˆšá‹«á‹á‹« á‹“áˆ˜á‰° áˆáˆ…áˆ¨á‰µ á‰ áŠ áŒˆáˆ­ á‹°áˆ¨áŒƒ á‹¨áˆ°á‹ áˆ°áˆ«áˆ½ áŠ áˆµá‰°á‹áˆŽá‰µ áŠ áˆáŠ• áŠ«áˆˆá‰ á‰µ á‹á‰…á‰°áŠ› á‹°áˆ¨áŒƒ á‹ˆá‹° áˆ‹á‰€ á‹°áˆ¨áŒƒ áˆˆáˆ›á‹µáˆ¨áˆµ áˆ€áŒˆáˆ­áŠ› á‰‹áŠ•á‰‹á‹Žá‰½áŠ• áˆˆáŠ áˆˆáˆ á‰°á‹°áˆ«áˆ½ áˆˆáˆ›á‹µáˆ¨áŒ áŠ áŒˆáˆ«á‹Š áŠ á‰…áˆáŠ• áˆˆáˆ›áˆ³á‹°áŒ áŠ¥áŠ“ á‰°áŒ á‰ƒáˆš áˆˆáˆ˜áˆ†áŠ• á‰ áŒ‹áˆ« áŠ á‰¥áˆ® áˆ˜áˆµáˆ«á‰± áŠ¥áŒ…áŒ áŒ á‰ƒáˆš áŠá‹ á‰ áˆ›áˆ½áŠ• áŠ áˆµá‰°áˆáˆ® áŠ áˆ›áŠ«áŠáŠá‰µ á‹¨á…áˆá áŠ“áˆ™áŠ“á‹Žá‰½ á‰ áŠ áˆ­á‰²áŠáˆ»áˆ áŠ¢áŠ•á‰°áˆˆáŒ€áŠ•áˆµ áˆµáˆ­áŠ á‰µ áˆˆáˆ›áˆ°áˆáŒ áŠ• á‹¨á…áˆá á‹³á‰³áŠ• áˆ˜áˆ°á‰¥áˆ°á‰¥ áŠ¥áŠ“ áˆ›á‹°áˆ«áŒ€á‰µ á‹¨áŠ“á‰¹áˆ«áˆ áˆ‹áŠ•áŒ‰á‹ŒáŒ… á•áˆ®áˆ°áˆ²áŠ•áŒ á‰±áˆŽá‰½áŠ• á‰ áˆ˜áŒ á‰€áˆ á‹¨á…áˆá á‹³á‰³áŠ• á•áˆ®áˆ°áˆµ áˆ›á‹µáˆ¨áŒ á‰°á‰€á‹³áˆš áŠ¥áŠ“ áˆ˜áˆ°áˆ¨á‰³á‹Š áŒ‰á‹³á‹­ áŠá‹\n    ```\n\n2. Tokenization - Sentence\n    - Here is a simple example of performing sentence tokenization on a piece of plaintext using Amharic document:\n    - Within Amharic document, annotations are further stored in `Sentences`\n\n    ```python\n    from etnltk import Amharic\n\n    sample_text = \"\"\"\n      á‹¨áˆ›áˆ½áŠ• áˆˆáˆ­áŠ’áŠ•áŒ áˆµáˆá‰°-á‰€áˆ˜áˆ®á‰½  (Algorithms) á‰ áˆ˜áŒ á‰€áˆ á‰‹áŠ•á‰‹á‹Žá‰½áŠ• áˆ˜áˆˆá‹¨á‰µ áŠ¥áŠ“ áˆ˜áˆ¨á‹³á‰µá£ á‹¨áŒ½áˆá á‹­á‹˜á‰¶á‰½áŠ• áˆ˜áˆˆá‹¨á‰µá£ á‹¨á‰‹áŠ•á‰‹áŠ• áˆ˜á‹‹á‰…áˆ­ áˆ˜á‰°áŠ•á‰°áŠ• á‹¨áˆšá‹«áˆµá‰½áˆ‰ á‹¨áˆƒáŒˆáˆªáŠ› áŠ“á‰¹áˆ«áˆ áˆ‹áŠ•áŒ‰á‹ŒáŒ… á•áˆ®áˆ°áˆ²áŠ•áŒ á‰±áˆŽá‰½ (NLP tools) á£ áˆµáˆá‰°-á‰€áˆ˜áˆ®á‰½ áŠ¥áŠ“ áˆžá‹´áˆŽá‰½áŠ• áˆ›á‹˜áŒ‹áŒ€á‰µ á‰°áŒˆá‰¢ áŠá‹á¢ á‰ á‹šáˆ…áˆ áˆ˜áˆ°áˆ¨á‰µ áŠ áˆ›áˆ­áŠ›á£ áŠ á‹áŠ• áŠ¦áˆ®áˆžá£ áˆ¶áˆ›áˆŠáŠ› áŠ¥áŠ“ á‰µáŒáˆ­áŠ› á‰‹áŠ•á‰‹á‹Žá‰½áŠ• áˆˆáˆ›áˆ½áŠ• á‹¨áˆ›áˆµá‰°áˆ›áˆ­ áˆ‚á‹°á‰µáŠ• á‰€áˆ‹áˆáŠ“ á‹¨á‰°á‰€áˆ‹á‰°á áŠ¥áŠ•á‹²áˆ†áŠ• á‹«áˆµá‰½áˆ‹áˆá¡á¡\n    \"\"\"\n\n    # Annotating Amharic Text\n    doc = Amharic(sample_text)\n\n    # print all list of `Sentence` in a document:\n    print(doc.sentences)\n    # output: [Sentence(\"á‹¨áˆ›áˆ½áŠ• áˆˆáˆ­áŠ’áŠ•áŒ áˆµáˆá‰°á‰€áˆ˜áˆ®á‰½ á‰ áˆ˜áŒ á‰€áˆ á‰‹áŠ•á‰‹á‹Žá‰½áŠ• áˆ˜áˆˆá‹¨á‰µ áŠ¥áŠ“ áˆ˜áˆ¨á‹³á‰µ á‹¨á…áˆá á‹­á‹˜á‰¶á‰½áŠ• áˆ˜áˆˆá‹¨á‰µ á‹¨á‰‹áŠ•á‰‹áŠ• áˆ˜á‹‹á‰…áˆ­ áˆ˜á‰°áŠ•á‰°áŠ• á‹¨áˆšá‹«áˆµá‰½áˆ‰ á‹¨áˆ€áŒˆáˆªáŠ› áŠ“á‰¹áˆ«áˆ áˆ‹áŠ•áŒ‰á‹ŒáŒ… á•áˆ®áˆ°áˆ²áŠ•áŒ á‰±áˆŽá‰½ áˆµáˆá‰°á‰€áˆ˜áˆ®á‰½ áŠ¥áŠ“ áˆžá‹´áˆŽá‰½áŠ• áˆ›á‹˜áŒ‹áŒ€á‰µ á‰°áŒˆá‰¢ áŠá‹\"), Sentence(\"á‰ á‹šáˆ…áˆ áˆ˜áˆ°áˆ¨á‰µ áŠ áˆ›áˆ­áŠ› áŠ á‹áŠ• áŠ¦áˆ®áˆž áˆ¶áˆ›áˆŠáŠ› áŠ¥áŠ“ á‰µáŒáˆ­áŠ› á‰‹áŠ•á‰‹á‹Žá‰½áŠ• áˆˆáˆ›áˆ½áŠ• á‹¨áˆ›áˆµá‰°áˆ›áˆ­ áˆ‚á‹°á‰µáŠ• á‰€áˆ‹áˆáŠ“ á‹¨á‰°á‰€áˆ‹á‰°á áŠ¥áŠ•á‹²áˆ†áŠ• á‹«áˆµá‰½áˆ‹áˆ\")]\n    ```\n\n    - Here is another example of performing sentence tokenization on a piece of plaintext using `sentence_tokenize` function:\n\n    ```python\n    from etnltk.tokenize.am import sent_tokenize\n\n    sample_text = \"\"\"\n      á‹¨áˆ›áˆ½áŠ• áˆˆáˆ­áŠ’áŠ•áŒ áˆµáˆá‰°-á‰€áˆ˜áˆ®á‰½  (Algorithms) á‰ áˆ˜áŒ á‰€áˆ á‰‹áŠ•á‰‹á‹Žá‰½áŠ• áˆ˜áˆˆá‹¨á‰µ áŠ¥áŠ“ áˆ˜áˆ¨á‹³á‰µá£ á‹¨áŒ½áˆá á‹­á‹˜á‰¶á‰½áŠ• áˆ˜áˆˆá‹¨á‰µá£ á‹¨á‰‹áŠ•á‰‹áŠ• áˆ˜á‹‹á‰…áˆ­ áˆ˜á‰°áŠ•á‰°áŠ• á‹¨áˆšá‹«áˆµá‰½áˆ‰ á‹¨áˆƒáŒˆáˆªáŠ› áŠ“á‰¹áˆ«áˆ áˆ‹áŠ•áŒ‰á‹ŒáŒ… á•áˆ®áˆ°áˆ²áŠ•áŒ á‰±áˆŽá‰½ (NLP tools) á£ áˆµáˆá‰°-á‰€áˆ˜áˆ®á‰½ áŠ¥áŠ“ áˆžá‹´áˆŽá‰½áŠ• áˆ›á‹˜áŒ‹áŒ€á‰µ á‰°áŒˆá‰¢ áŠá‹á¢ á‰ á‹šáˆ…áˆ áˆ˜áˆ°áˆ¨á‰µ áŠ áˆ›áˆ­áŠ›á£ áŠ á‹áŠ• áŠ¦áˆ®áˆžá£ áˆ¶áˆ›áˆŠáŠ› áŠ¥áŠ“ á‰µáŒáˆ­áŠ› á‰‹áŠ•á‰‹á‹Žá‰½áŠ• áˆˆáˆ›áˆ½áŠ• á‹¨áˆ›áˆµá‰°áˆ›áˆ­ áˆ‚á‹°á‰µáŠ• á‰€áˆ‹áˆáŠ“ á‹¨á‰°á‰€áˆ‹á‰°á áŠ¥áŠ•á‹²áˆ†áŠ• á‹«áˆµá‰½áˆ‹áˆá¡á¡\n    \"\"\"\n\n    # Annotating a Document\n    sentences = sent_tokenize(sample_text)\n\n    # print all list of sentence:\n    print(sentences)\n    # output: ['á‹¨áˆ›áˆ½áŠ• áˆˆáˆ­áŠ’áŠ•áŒ áˆµáˆá‰°á‰€áˆ˜áˆ®á‰½ á‰ áˆ˜áŒ á‰€áˆ á‰‹áŠ•á‰‹á‹Žá‰½áŠ• áˆ˜áˆˆá‹¨á‰µ áŠ¥áŠ“ áˆ˜áˆ¨á‹³á‰µ á‹¨á…áˆá á‹­á‹˜á‰¶á‰½áŠ• áˆ˜áˆˆá‹¨á‰µ á‹¨á‰‹áŠ•á‰‹áŠ• áˆ˜á‹‹á‰…áˆ­ áˆ˜á‰°áŠ•á‰°áŠ• á‹¨áˆšá‹«áˆµá‰½áˆ‰ á‹¨áˆ€áŒˆáˆªáŠ› áŠ“á‰¹áˆ«áˆ áˆ‹áŠ•áŒ‰á‹ŒáŒ… á•áˆ®áˆ°áˆ²áŠ•áŒ á‰±áˆŽá‰½ áˆµáˆá‰°á‰€áˆ˜áˆ®á‰½ áŠ¥áŠ“ áˆžá‹´áˆŽá‰½áŠ• áˆ›á‹˜áŒ‹áŒ€á‰µ á‰°áŒˆá‰¢ áŠá‹', 'á‰ á‹šáˆ…áˆ áˆ˜áˆ°áˆ¨á‰µ áŠ áˆ›áˆ­áŠ› áŠ á‹áŠ• áŠ¦áˆ®áˆž áˆ¶áˆ›áˆŠáŠ› áŠ¥áŠ“ á‰µáŒáˆ­áŠ› á‰‹áŠ•á‰‹á‹Žá‰½áŠ• áˆˆáˆ›áˆ½áŠ• á‹¨áˆ›áˆµá‰°áˆ›áˆ­ áˆ‚á‹°á‰µáŠ• á‰€áˆ‹áˆáŠ“ á‹¨á‰°á‰€áˆ‹á‰°á áŠ¥áŠ•á‹²áˆ†áŠ• á‹«áˆµá‰½áˆ‹áˆ']\n\n3. Tokenization - Word\n    - Here is a simple example of performing word tokenization on a piece of plaintext using AmharicDocument:\n    - Within Amharic focument, annotations are further stored in `Words`.\n\n    ```python\n    from etnltk import AmharicDocument\n\n    sample_text = \"\"\"\n      â€œá‰°áˆ¨áŠ›á£ á‰°áˆ¨áŠ›!â€ áŠ áˆˆ áŠáˆ­áˆ±á¢ á‹ˆá‹­á‹˜áˆ®\n      á‰³áˆªáŠ³á£ â€œáŠ á‰¤á‰µ!â€ á‰¥áˆˆá‹ á‹¨áˆáˆˆá‰µ\n      á‹“áˆ˜á‰µ áˆáŒƒá‰¸á‹áŠ• á‹­á‹˜á‹ áŒˆá‰¡á¢\n      â€œáˆáŠ‘áŠ• áŠá‹ á‹«áˆ˜áˆ˜á‹?â€ á‹¶áŠ­á‰°áˆ¯\n      áŒ á‹¨á‰á¢ â€œáŠ á‹«á‹©á‰µáˆ! á€áŒ‰áˆ© áˆ³áˆµá‰·áˆá¤\n      áˆ†á‹± á‰°áŠáá‰·áˆá¤ á‹µá‹±áˆ á‹­á‹°áˆ›áˆâ€\n      áŠ áˆ‰ á‹ˆá‹­á‹˜áˆ® á‰³áˆªáŠ³á¢ á‹¶áŠ­á‰°áˆ¯áˆá£\n      â€œá‰ áŒ£áˆ á‹«áˆ³á‹áŠ“áˆá¤ áŠ¥áŠ•á‹°á‹šáˆ…\n      á‹«á‹°áˆ¨áŒˆá‹ á‹¨á‰°áˆ˜áŒ£áŒ áŠ áˆáŒá‰¥ áŠ áˆˆáˆ›áŒáŠ˜á‰± áŠá‹á¢ áŠ áˆáŠ•áˆ á‹ˆá‰°á‰µá£\n      áŠ¥áŠ•á‰áˆ‹áˆá£ áˆ›áˆ­á£ áŠ á‰µáŠ­áˆá‰µáŠ“ ááˆ«ááˆ¬ á‹­áˆ˜áŒá‰¡á‰µá¤ á‰¶áˆŽ á‹­áˆ»áˆˆá‹‹áˆá¤\n      áˆˆáŠ áˆáŠ‘ áŒáŠ• áˆ˜á‹µáŠƒáŠ’á‰µ áŠ á‹áˆˆá‰³áˆˆáˆâ€ á‰ áˆ›áˆˆá‰µ áŠ áˆµáˆ¨á‹·á‰¸á‹á¢ á‹ˆá‹­á‹˜áˆ®\n      á‰³áˆªáŠ³áˆ â€œá‹ˆá‹­ áŠ áˆˆáˆ›á‹ˆá‰…! áˆáŒ„áŠ• á‰ áˆáŒá‰¥ áŠ¥áŒ¥áˆ¨á‰µ áŒˆá‹µá‹¬á‹ áŠá‰ áˆ­\"\n      á‰ áˆ›áˆˆá‰µ áŠ áˆˆá‰€áˆ±á¢\n\n      \"\"\"\n    \n    # Annotating Amharic Text\n    doc = Amharic(sample_text)\n\n    # print all list of `AmharicWord` in a document:\n    print(doc.words)\n    # output: ['á‰°áˆ¨áŠ›', 'á‰°áˆ¨áŠ›', 'áŠ áˆˆ', 'áŠáˆ­áˆ±', 'á‹ˆá‹­á‹˜áˆ®', 'á‰³áˆªáŠ³', 'áŠ á‰¤á‰µ', 'á‰¥áˆˆá‹', 'á‹¨áˆáˆˆá‰µ', 'áŠ áˆ˜á‰µ', 'áˆáŒƒá‰¸á‹áŠ•', 'á‹­á‹˜á‹', 'áŒˆá‰¡', 'áˆáŠ‘áŠ•', 'áŠá‹', 'á‹«áˆ˜áˆ˜á‹', 'á‹¶áŠ­á‰°áˆ¯', 'áŒ á‹¨á‰', 'áŠ á‹«á‹©á‰µáˆ', 'á€áŒ‰áˆ©', 'áˆ³áˆµá‰·áˆ', 'áˆ†á‹±', 'á‰°áŠáá‰·áˆ', 'á‹µá‹±áˆ', 'á‹­á‹°áˆ›áˆ', 'áŠ áˆ‰', 'á‹ˆá‹­á‹˜áˆ®', 'á‰³áˆªáŠ³', 'á‹¶áŠ­á‰°áˆ¯áˆ', 'á‰ áŒ£áˆ', 'á‹«áˆ³á‹áŠ“áˆ', 'áŠ¥áŠ•á‹°á‹šáˆ…', 'á‹«á‹°áˆ¨áŒˆá‹', 'á‹¨á‰°áˆ˜áŒ£áŒ áŠ', 'áˆáŒá‰¥', 'áŠ áˆˆáˆ›áŒáŠ˜á‰±', 'áŠá‹', 'áŠ áˆáŠ•áˆ', 'á‹ˆá‰°á‰µ', 'áŠ¥áŠ•á‰áˆ‹áˆ', 'áˆ›áˆ­', 'áŠ á‰µáŠ­áˆá‰µáŠ“', 'ááˆ«ááˆ¬', 'á‹­áˆ˜áŒá‰¡á‰µ', 'á‰¶áˆŽ', 'á‹­áˆ»áˆˆá‹‹áˆ', 'áˆˆáŠ áˆáŠ‘', 'áŒáŠ•', 'áˆ˜á‹µáˆ€áŠ’á‰µ', 'áŠ á‹áˆˆá‰³áˆˆáˆ', 'á‰ áˆ›áˆˆá‰µ', 'áŠ áˆµáˆ¨á‹·á‰¸á‹', 'á‹ˆá‹­á‹˜áˆ®', 'á‰³áˆªáŠ³áˆ', 'á‹ˆá‹­', 'áŠ áˆˆáˆ›á‹ˆá‰…', 'áˆáŒ„áŠ•', 'á‰ áˆáŒá‰¥', 'áŠ¥áŒ¥áˆ¨á‰µ', 'áŒˆá‹µá‹¬á‹', 'áŠá‰ áˆ­', 'á‰ áˆ›áˆˆá‰µ', 'áŠ áˆˆá‰€áˆ±']\n    ```\n\n    - Here is another example of performing word tokenization on a piece of plaintext using `word_tokenize` function:\n\n    ```python\n    from etnltk.tokenize.am import word_tokenize\n\n    sample_text = \"\"\"\n      â€œá‰°áˆ¨áŠ›á£ á‰°áˆ¨áŠ›!â€ áŠ áˆˆ áŠáˆ­áˆ±á¢ á‹ˆá‹­á‹˜áˆ®\n      á‰³áˆªáŠ³á£ â€œáŠ á‰¤á‰µ!â€ á‰¥áˆˆá‹ á‹¨áˆáˆˆá‰µ\n      á‹“áˆ˜á‰µ áˆáŒƒá‰¸á‹áŠ• á‹­á‹˜á‹ áŒˆá‰¡á¢\n      â€œáˆáŠ‘áŠ• áŠá‹ á‹«áˆ˜áˆ˜á‹?â€ á‹¶áŠ­á‰°áˆ¯\n      áŒ á‹¨á‰á¢ â€œáŠ á‹«á‹©á‰µáˆ! á€áŒ‰áˆ© áˆ³áˆµá‰·áˆá¤\n      áˆ†á‹± á‰°áŠáá‰·áˆá¤ á‹µá‹±áˆ á‹­á‹°áˆ›áˆâ€\n      áŠ áˆ‰ á‹ˆá‹­á‹˜áˆ® á‰³áˆªáŠ³á¢ á‹¶áŠ­á‰°áˆ¯áˆá£\n      â€œá‰ áŒ£áˆ á‹«áˆ³á‹áŠ“áˆá¤ áŠ¥áŠ•á‹°á‹šáˆ…\n      á‹«á‹°áˆ¨áŒˆá‹ á‹¨á‰°áˆ˜áŒ£áŒ áŠ áˆáŒá‰¥ áŠ áˆˆáˆ›áŒáŠ˜á‰± áŠá‹á¢ áŠ áˆáŠ•áˆ á‹ˆá‰°á‰µá£\n      áŠ¥áŠ•á‰áˆ‹áˆá£ áˆ›áˆ­á£ áŠ á‰µáŠ­áˆá‰µáŠ“ ááˆ«ááˆ¬ á‹­áˆ˜áŒá‰¡á‰µá¤ á‰¶áˆŽ á‹­áˆ»áˆˆá‹‹áˆá¤\n      áˆˆáŠ áˆáŠ‘ áŒáŠ• áˆ˜á‹µáŠƒáŠ’á‰µ áŠ á‹áˆˆá‰³áˆˆáˆâ€ á‰ áˆ›áˆˆá‰µ áŠ áˆµáˆ¨á‹·á‰¸á‹á¢ á‹ˆá‹­á‹˜áˆ®\n      á‰³áˆªáŠ³áˆ â€œá‹ˆá‹­ áŠ áˆˆáˆ›á‹ˆá‰…! áˆáŒ„áŠ• á‰ áˆáŒá‰¥ áŠ¥áŒ¥áˆ¨á‰µ áŒˆá‹µá‹¬á‹ áŠá‰ áˆ­\"\n      á‰ áˆ›áˆˆá‰µ áŠ áˆˆá‰€áˆ±á¢\n\n    \"\"\"\n      \n    # word tokenization\n    words = word_tokenize(sample_text)\n\n    # print all list of word:\n    print(words)\n    # output: ['á‰°áˆ¨áŠ›', 'á‰°áˆ¨áŠ›', 'áŠ áˆˆ', 'áŠáˆ­áˆ±', 'á‹ˆá‹­á‹˜áˆ®', 'á‰³áˆªáŠ³', 'áŠ á‰¤á‰µ', 'á‰¥áˆˆá‹', 'á‹¨áˆáˆˆá‰µ', 'áŠ áˆ˜á‰µ', 'áˆáŒƒá‰¸á‹áŠ•', 'á‹­á‹˜á‹', 'áŒˆá‰¡', 'áˆáŠ‘áŠ•', 'áŠá‹', 'á‹«áˆ˜áˆ˜á‹', 'á‹¶áŠ­á‰°áˆ¯', 'áŒ á‹¨á‰', 'áŠ á‹«á‹©á‰µáˆ', 'á€áŒ‰áˆ©', 'áˆ³áˆµá‰·áˆ', 'áˆ†á‹±', 'á‰°áŠáá‰·áˆ', 'á‹µá‹±áˆ', 'á‹­á‹°áˆ›áˆ', 'áŠ áˆ‰', 'á‹ˆá‹­á‹˜áˆ®', 'á‰³áˆªáŠ³', 'á‹¶áŠ­á‰°áˆ¯áˆ', 'á‰ áŒ£áˆ', 'á‹«áˆ³á‹áŠ“áˆ', 'áŠ¥áŠ•á‹°á‹šáˆ…', 'á‹«á‹°áˆ¨áŒˆá‹', 'á‹¨á‰°áˆ˜áŒ£áŒ áŠ', 'áˆáŒá‰¥', 'áŠ áˆˆáˆ›áŒáŠ˜á‰±', 'áŠá‹', 'áŠ áˆáŠ•áˆ', 'á‹ˆá‰°á‰µ', 'áŠ¥áŠ•á‰áˆ‹áˆ', 'áˆ›áˆ­', 'áŠ á‰µáŠ­áˆá‰µáŠ“', 'ááˆ«ááˆ¬', 'á‹­áˆ˜áŒá‰¡á‰µ', 'á‰¶áˆŽ', 'á‹­áˆ»áˆˆá‹‹áˆ', 'áˆˆáŠ áˆáŠ‘', 'áŒáŠ•', 'áˆ˜á‹µáˆ€áŠ’á‰µ', 'áŠ á‹áˆˆá‰³áˆˆáˆ', 'á‰ áˆ›áˆˆá‰µ', 'áŠ áˆµáˆ¨á‹·á‰¸á‹', 'á‹ˆá‹­á‹˜áˆ®', 'á‰³áˆªáŠ³áˆ', 'á‹ˆá‹­', 'áŠ áˆˆáˆ›á‹ˆá‰…', 'áˆáŒ„áŠ•', 'á‰ áˆáŒá‰¥', 'áŠ¥áŒ¥áˆ¨á‰µ', 'áŒˆá‹µá‹¬á‹', 'áŠá‰ áˆ­', 'á‰ áˆ›áˆˆá‰µ', 'áŠ áˆˆá‰€áˆ±']\n\n4. Normalization\n    1. Character Level Normalization such as \"`áŒ¸`áˆ€á‹­\" and \"`á€`áˆá‹­\"\n    2. Labialized Character Normalzation such as \"áˆžáˆ`á‰±á‹‹`áˆ\" to \"áˆžáˆ`á‰·`áˆ\"\n    3. Short Form Expansion such as \"`áŠ .áŠ `\" to \"`áŠ á‹²áˆµ áŠ á‰ á‰£`\"\n    4. Punctuation Normalization such as `::` to `á¢`\n\n    - Here is a simple example of performing normalization on a piece of plaintext using `normalize` function:\n\n    ```python\n    from etnltk.lang.am import normalize\n\n    sample_text = \"\"\"\n      áˆšá‹«á‹á‹« 14á£ 2014 á‹“.áˆ á‰ á‹“áŒˆáˆ­ á‹°áˆ¨áŒƒ á‹¨áˆ°á‹ áˆ°áˆ«áˆ½ áŠ áˆµá‰°á‹áˆŽá‰µ á‹¨á‹á‹­á‹­á‰µ áˆ˜á‹µáˆ¨áŠ­ áˆ‹á‹­\n      á‹¨áˆƒáŒˆáˆ­áŠ› á‰‹áŠ•á‰‹á‹Žá‰½ á‰µáˆ­áŒ‰áˆ áŠ áŒˆáˆáŒáˆŽá‰µá£ \n      á‰»á‰µá‰¦á‰µ (á‹¨á‹á‹­á‹­á‰µ áˆ˜áˆˆá‹‹á‹ˆáŒ« áˆ®á‰¦á‰µ): \n      á‹¨á…áˆá áˆ°áŠá‹¶á‰½ áˆˆáˆ˜áˆˆá‹¨á‰µá£ á‹¨á‰ƒáˆ‹á‰µ á‰µáŠ­áŠ­áˆˆáŠ›áŠá‰µáŠ• áˆˆáˆ›áˆ¨áŒ‹áŒˆáŒ¥á£ \n      á‰ á‰‹áŠ•á‰‹áŠ• áˆ•áŒáŒ‹á‰µ áˆ˜áˆ áˆ¨á‰µ áŒ½áˆ‘áŽá‰½áŠ• áˆˆáˆ›á‹‹á‰€áˆ­ áŠ¥áŠ“ áˆˆáˆ˜áˆ˜áˆµáˆ¨á‰µá£ \n      áˆ¨áŒ…áˆ áŒ½áˆáŽá‰½áŠ• áˆˆáˆ›áˆ³áŒ áˆ­á£ áŠ áŠ•áŠ³áˆ­ áŒ‰á‹³á‹®á‰½áŠ• áˆ˜áˆˆá‹¨á‰µ á‹ˆá‹­áˆ áŒ¥á‰…áˆ áˆƒáˆ³á‰¥ áˆˆáˆ›á‹áŒ£á‰µá£ \n      áŠ•áŒáŒáˆ­áŠ• á‹ˆá‹° áŒ½áˆá áˆˆáˆ˜á‰€á‹¨áˆ­ á‹¨áˆšá‹«áˆµá‰½áˆ‰ áˆ˜á‰°áŒá‰ áˆªá‹«á‹Žá‰½áŠ• áˆ›áˆáˆ›á‰µ áŠ áˆµáˆ¨áˆ‹áŒŠáŠá‰± á‰°áŒˆáˆáŒ¹á‹‹áˆ::\n    \"\"\"\n\n    # normalization\n    normalized_text = normalize(sample_text)\n\n    # The following example shows how to print all normalized in a document:\n    print(normalized_text)\n    # output: áˆšá‹«á‹á‹« 14á£ 2014 áŠ áˆ˜á‰° áˆáˆ…áˆ¨á‰µ á‰ áŠ áŒˆáˆ­ á‹°áˆ¨áŒƒ á‹¨áˆ°á‹ áˆ°áˆ«áˆ½ áŠ áˆµá‰°á‹áˆŽá‰µ á‹¨á‹á‹­á‹­á‰µ áˆ˜á‹µáˆ¨áŠ­ áˆ‹á‹­\n    # á‹¨áˆ€áŒˆáˆ­áŠ› á‰‹áŠ•á‰‹á‹Žá‰½ á‰µáˆ­áŒ‰áˆ áŠ áŒˆáˆáŒáˆŽá‰µá£ \n    # á‰»á‰µá‰¦á‰µ (á‹¨á‹á‹­á‹­á‰µ áˆ˜áˆˆá‹‹á‹ˆáŒ« áˆ®á‰¦á‰µ)á¡ \n    # á‹¨á…áˆá áˆ°áŠá‹¶á‰½ áˆˆáˆ˜áˆˆá‹¨á‰µá£ á‹¨á‰ƒáˆ‹á‰µ á‰µáŠ­áŠ­áˆˆáŠ›áŠá‰µáŠ• áˆˆáˆ›áˆ¨áŒ‹áŒˆáŒ¥á£ \n    # á‰ á‰‹áŠ•á‰‹áŠ• áˆ…áŒáŒ‹á‰µ áˆ˜áˆ°áˆ¨á‰µ á…áˆáŽá‰½áŠ• áˆˆáˆ›á‹‹á‰€áˆ­ áŠ¥áŠ“ áˆˆáˆ˜áˆ˜áˆµáˆ¨á‰µá£ \n    # áˆ¨áŒ…áˆ á…áˆáŽá‰½áŠ• áˆˆáˆ›áˆ³áŒ áˆ­á£ áŠ áŠ•áŠ³áˆ­ áŒ‰á‹³á‹®á‰½áŠ• áˆ˜áˆˆá‹¨á‰µ á‹ˆá‹­áˆ áŒ¥á‰…áˆ áˆ€áˆ³á‰¥ áˆˆáˆ›á‹áŒ£á‰µá£ \n    # áŠ•áŒáŒáˆ­áŠ• á‹ˆá‹° á…áˆá áˆˆáˆ˜á‰€á‹¨áˆ­ á‹¨áˆšá‹«áˆµá‰½áˆ‰ áˆ˜á‰°áŒá‰ áˆªá‹«á‹Žá‰½áŠ• áˆ›áˆáˆ›á‰µ áŠ áˆµáˆ¨áˆ‹áŒŠáŠá‰± á‰°áŒˆáˆáŒ¿áˆá¢ \"\"\"\n    ```\n\n    - Here is another example of performing normalization on a piece of plaintext using `normalize_char`, `normalize_punct`, `normalize_labialized`, `normalize_shortened` function:\n\n    ```python\n    from etnltk.lang.am.normalizer import ( \n      normalize_labialized, \n      normalize_shortened,\n      normalize_punct,\n      normalize_char\n    )\n\n    # normalize labialized \n    normalized_text = normalize_labialized(\"áŠ•áŒáŒáˆ­áŠ• á‹ˆá‹° áŒ½áˆá áˆˆáˆ˜á‰€á‹¨áˆ­ á‹¨áˆšá‹«áˆµá‰½áˆ‰ áˆ˜á‰°áŒá‰ áˆªá‹«á‹Žá‰½áŠ• áˆ›áˆáˆ›á‰µ áŠ áˆµáˆ¨áˆ‹áŒŠáŠá‰± á‰°áŒˆáˆáŒ¹á‹‹áˆ\")\n    print(normalized_text)\n    # output: áŠ•áŒáŒáˆ­áŠ• á‹ˆá‹° á…áˆá áˆˆáˆ˜á‰€á‹¨áˆ­ á‹¨áˆšá‹«áˆµá‰½áˆ‰ áˆ˜á‰°áŒá‰ áˆªá‹«á‹Žá‰½áŠ• áˆ›áˆáˆ›á‰µ áŠ áˆµáˆ¨áˆ‹áŒŠáŠá‰± á‰°áŒˆáˆáŒ¿áˆ\n\n    # normalize short forms\n    normalized_text = normalize_shortened(\"áˆšá‹«á‹á‹« 14á£ 2014 á‹“.áˆ á‰ á‹“áŒˆáˆ­ á‹°áˆ¨áŒƒ á‹¨áˆ°á‹ áˆ°áˆ«áˆ½ áŠ áˆµá‰°á‹áˆŽá‰µ á‹¨á‹á‹­á‹­á‰µ áˆ˜á‹µáˆ¨áŠ­\")\n    print(normalized_text)\n    # output: áˆšá‹«á‹á‹« 14á£ 2014 á‹“áˆ˜á‰° áˆáˆ…áˆ¨á‰µ á‰ áŠ áŒˆáˆ­ á‹°áˆ¨áŒƒ á‹¨áˆ°á‹ áˆ°áˆ«áˆ½ áŠ áˆµá‰°á‹áˆŽá‰µ á‹¨á‹á‹­á‹­á‰µ áˆ˜á‹µáˆ¨áŠ­\n\n    # normalize punctuation\n    normalized_text = normalize_punct(\"áˆ˜á‰°áŒá‰ áˆªá‹«á‹Žá‰½áŠ• áˆ›áˆáˆ›á‰µ áŠ áˆµáˆ¨áˆ‹áŒŠáŠá‰± á‰°áŒˆáˆáŒ¹á‹‹áˆ::\")\n    print(normalized_text)\n    # output: áˆ˜á‰°áŒá‰ áˆªá‹«á‹Žá‰½áŠ• áˆ›áˆáˆ›á‰µ áŠ áˆµáˆ¨áˆ‹áŒŠáŠá‰± á‰°áŒˆáˆáŒ¿áˆá¢\n\n    # normalize characters\n    normalized_text = normalize_char(\"á‰ á‰‹áŠ•á‰‹á‹‰ áˆ•áŒáŒ‹á‰µ áˆ˜áˆ áˆ¨á‰µ áŒ½áˆ‘áŽá‰½áŠ• áˆ›á‹‹á‰€áˆ­ áŠ¥áŠ“ áˆ˜áˆ˜áˆ¥áˆ¨á‰µ\")\n    print(normalized_text)\n    # output: á‰ á‰‹áŠ•á‰‹á‹‰ áˆ…áŒáŒ‹á‰µ áˆ˜áˆ°áˆ¨á‰µ á…áˆáŽá‰½áŠ• áˆ›á‹‹á‰€áˆ­ áŠ¥áŠ“ áˆ˜áˆ˜áˆµáˆ¨á‰µ\n\n## Features\n\n- Text preprocessing functions.\n\n    ``` python\n    from etnltk.lang.am import preprocessing\n    ```\n\n    | Function | Description |\n    -----------|-------------|\n    | remove_whitespaces | Remove extra spaces, tabs, and new lines from a text string\n    | remove_links | Remove URLs from a text string\n    | remove_tags | Remove HTML tags from a text string\n    | remove_emojis | Remove emojis from a text string\n    | remove_email | Remove email adresses from a text string\n    | remove_digits | Remove all digits from a text string\n    | remove_english_chars | Remove ascii characters from a text string\n    | remove_arabic_chars | Remove arabic characters and numerals from a text string\n    | remove_chinese_chars | Remove chinese characters from a text string\n    | remove_ethiopic_digits | Remove all ethiopic digits from a text string\n    | remove_ethiopic_punct | Remove ethiopic punctuations from a text string\n    | remove_non_ethiopic | Remove non ethioipc characters from a text string\n    | remove_stopwords | Remove stop words\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/robikieq/etnltk.git",
    "keywords": "['nlp','ethiopic','amharic','tokenization','preprocessing','text-analytics']",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "etnltk",
    "package_url": "https://pypi.org/project/etnltk/",
    "platform": null,
    "project_url": "https://pypi.org/project/etnltk/",
    "project_urls": {
      "Homepage": "https://github.com/robikieq/etnltk.git"
    },
    "release_url": "https://pypi.org/project/etnltk/0.0.22/",
    "requires_dist": [
      "textsearch (>=0.0.21)",
      "emoji (>=1.7.0)"
    ],
    "requires_python": ">=3.6",
    "summary": "Ethiopian Natural Language Toolkit",
    "version": "0.0.22",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 13837594,
  "releases": {
    "0.0.22": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7e75e4080c75afdfc6b435f2ad0fab9d25eebcdaefdbed6d1875ea218c6255fd",
          "md5": "3105d3a4de55b09e09dc9d860e370397",
          "sha256": "c19dbe624e48c91f15bc7b4e4cd343105ef31f34dc03a8e433ee4c152893e788"
        },
        "downloads": -1,
        "filename": "etnltk-0.0.22-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "3105d3a4de55b09e09dc9d860e370397",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 20609,
        "upload_time": "2022-05-17T06:36:15",
        "upload_time_iso_8601": "2022-05-17T06:36:15.933157Z",
        "url": "https://files.pythonhosted.org/packages/7e/75/e4080c75afdfc6b435f2ad0fab9d25eebcdaefdbed6d1875ea218c6255fd/etnltk-0.0.22-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f6f87c58e6525b8764e886ff1b5f2a3e58b7812da0f8af8567010cd30fb721a7",
          "md5": "ac2c018d36f36bca06d4f66e1163f2c9",
          "sha256": "c231a918631cb4c1a5cba76bc3b493d1afc84ba6a5092457c71f3fe8596c4ce9"
        },
        "downloads": -1,
        "filename": "etnltk-0.0.22.tar.gz",
        "has_sig": false,
        "md5_digest": "ac2c018d36f36bca06d4f66e1163f2c9",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 20583,
        "upload_time": "2022-05-17T06:36:18",
        "upload_time_iso_8601": "2022-05-17T06:36:18.190222Z",
        "url": "https://files.pythonhosted.org/packages/f6/f8/7c58e6525b8764e886ff1b5f2a3e58b7812da0f8af8567010cd30fb721a7/etnltk-0.0.22.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "7e75e4080c75afdfc6b435f2ad0fab9d25eebcdaefdbed6d1875ea218c6255fd",
        "md5": "3105d3a4de55b09e09dc9d860e370397",
        "sha256": "c19dbe624e48c91f15bc7b4e4cd343105ef31f34dc03a8e433ee4c152893e788"
      },
      "downloads": -1,
      "filename": "etnltk-0.0.22-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "3105d3a4de55b09e09dc9d860e370397",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 20609,
      "upload_time": "2022-05-17T06:36:15",
      "upload_time_iso_8601": "2022-05-17T06:36:15.933157Z",
      "url": "https://files.pythonhosted.org/packages/7e/75/e4080c75afdfc6b435f2ad0fab9d25eebcdaefdbed6d1875ea218c6255fd/etnltk-0.0.22-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "f6f87c58e6525b8764e886ff1b5f2a3e58b7812da0f8af8567010cd30fb721a7",
        "md5": "ac2c018d36f36bca06d4f66e1163f2c9",
        "sha256": "c231a918631cb4c1a5cba76bc3b493d1afc84ba6a5092457c71f3fe8596c4ce9"
      },
      "downloads": -1,
      "filename": "etnltk-0.0.22.tar.gz",
      "has_sig": false,
      "md5_digest": "ac2c018d36f36bca06d4f66e1163f2c9",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 20583,
      "upload_time": "2022-05-17T06:36:18",
      "upload_time_iso_8601": "2022-05-17T06:36:18.190222Z",
      "url": "https://files.pythonhosted.org/packages/f6/f8/7c58e6525b8764e886ff1b5f2a3e58b7812da0f8af8567010cd30fb721a7/etnltk-0.0.22.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}