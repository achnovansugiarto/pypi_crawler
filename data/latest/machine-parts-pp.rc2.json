{
  "info": {
    "author": "Daniel Bakkelund",
    "author_email": "daniel.bakkelund@ifi.uio.no",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "License :: OSI Approved :: GNU Lesser General Public License v3 or later (LGPLv3+)",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# [machine-parts-pp](https://bitbucket.org/Bakkelund/machine-parts-pp/)\n\n# Planted partitions over machine part structures\n\nThis python module offers data and functionality to generate planted partitions over directed acyclic graphs with dissimilarities. The directed acyclic graphs represent machine parts, where the vertices are parts, and the edges are \"part-of\" relations. The planted partitions simulate a copy-paste scenario where a machine (graph) is duplicated, but the parts (vertices) are given new identifiers, and the copy-relation is forgotten. The planted partitions represent the copy-paste links, and the presented problem is to recover the planted partition from the family of graphs and the dissimilarities.\n\nThe machine parts data is extracted from a large database of subsea oil and gas machinery owned by TechnipFMC ([https://www.technipfmc.com/](https://www.technipfmc.com/)), and the dissimilarities are obtained from an in-company data science project using machine learning to develop a similarity measure over the machine parts calculated from metadata.\n\nFor a detailed description of the data and the planted partition generation mechanism, please see the article _Machine part data with part-of relations and part dissimilarities for planted partition generation_.\n\n## Requirements\n* `python 3+`\n* `numpy`\n\n## License\nThe software in this module is licensed under the GNU Lesser General Public License ([https://www.gnu.org/licenses/lgpl-3.0.en.html](https://www.gnu.org/licenses/lgpl-3.0.en.html)).\n\n## Installation\n`python -m pip install machine-parts-pp [--user]`\n\n## How to get hold of the data\n\nThe data can be obtained either as files at [Mendeley Data](https://data.mendeley.com/):\n\n<https://data.mendeley.com/datasets/dhhxzdzm3v/1>\n\nOr they can be obtained through the python API as follows:\n\n```python\nimport machine_parts_pp as pp\n\nparts = pp.get_all_machine_parts()\ndists = pp.get_all_dissimilarities()\n```\n\nIn the above code, `parts` is a `dict` mapping a part id (integer) to a list of part-ids, namely to the list of directly contained parts. That is; `b`is a *part of* `a` if `b in parts[a]`.\nThe object `dists` is a symmetric `N x N` `numpy` array holding the pairwise dissimilarities of all the machine parts.\n\nHowever, if the goal is to use the data to generate clustering problems, the following sections give a description of how the APIs can be used for this.\n\n## Examples involving planted partitions\n\nThe below examples demonstrate how to \n\n1. Obtain a generated problem instance together with a planted partition.\n2. Solve the problem using a library for clustering. We provide two examples, one using [dbscan](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html), and one example using [ophac](https://bitbucket.org/Bakkelund/ophac/wiki/Home).\n3. Evaluate the quality of the solution by computing the adjusted Rand index relative the planted partition. We employ the python library [clusim](https://github.com/Hoosier-Clusters/clusim) for this computation.\n\n### Obtaining a problem instance with a planted partition\n\nWe start by obtaining the problem instance and the planted partition\n\n```python\nimport machine_parts_pp as pp\n\n# number of copy-paste operations\nmult=5\n\n# The base data before copy-pasting\nbase = pp.get_all_machine_parts()\n\n# mean and variance of the noise to be added to the dissimilarity data\nmean = 0.05\nvar  = 0.15\n\n# Generate the problem and obtain the planted partition\ngraph, dissims, planted_partition = pp.planted_partition(base,mult,mean,var)\n```\nWe now have\n\n* `graph` - a dict on the form (`x,[y1,y2,...])` where `x` is an integer and `[y1,...]` are the \"parts of\" `x`, i.e. the descendants of `x` when we consider `graph` to be a directed acyclic graph.\n* `dissims` - An `NxN` `numpy` array with pair-wise dissimilarities of the vertices in graph. All dissimilarities are in the range `[0,1]`.\n* `planted_partition` - A list of lists, each list a cluster, and each cluster a collection of copy-paste pairs. \n\nWe can now use this for testing and benchmarking of algorithms that take `(graph,dissims)` as input and try to use this information to recover `planted_partition`.\n\nThe following two examples continue by first clustering the data, and then evaluate the result by computing the adjusted rand index. \n\n### Using DBSCAN for clustering\n\nThis example requires the python modules `sklern` and `clusim` to be installed.<br/>\nThe full source can be downloaded via this link:\n[example_dbscan.py](https://bitbucket.org/Bakkelund/machine-parts-pp/src/master/python/example/example_dbscan.py)\n\n```python\nfrom sklearn.cluster import DBSCAN\n\n# Use dbscan to cluster, using 3 as the core point threshold (min_samples),\n# and specifying metric='precomputed', since we have pre-computed dissimilarities\ndbscan     = DBSCAN(eps=0.085, min_samples=3, metric='precomputed')\nclustering = dbscan.fit(dissims)\n\n# number of clusters\nnClusters = max(*clustering.labels_)+1\n\n# extracting the physical clusters\nnElts    = len(graph)\nclusters = [[] for _ in range(nClusters)]\nfor elt in range(nElts):\n    clusters[clustering.labels_[elt]].append(elt)\n\n# We can now compare the 'clustering' clusters with the 'planted_partition'\n# clusters to evaluate the degree of precision in recovering the planted\n# partition\n#\n# We have chosen to use the library 'clusim', which requires the clustering to\n# be represented by a dict mapping (eltId,clustId)\n# See the documentaton of clusim for details.\n\nimport clusim.clustering\nimport clusim.sim\n\n# Planted partition clustering representation\npp_cluster_idx = pp.clustering_to_cluster_index_mapping(planted_partition)\npp_dict = {x : [pp_cluster_idx[x]] for x in range(nElts)}\npp_clst = clusim.clustering.Clustering(elm2clu_dict=pp_dict)\n\n# dbscan clustering representation\ndb_dict = {x : [clustering.labels_[x]] for x in range(nElts)}\ndb_clst = clusim.clustering.Clustering(elm2clu_dict=db_dict)\n\n# Since the dbscan clustering is not pre-set to have a fixed number of clusters,\n# we consider the clustering to be \"drawn\" from the family of all clusterings\nari = clusim.sim.adjrand_index(db_clst, pp_clst, 'all1')\n\nprint('Adjusted Rand index:', ari)\n```\n\n### Using ophac for clustering\n\n`ophac` is a library that is tailored especially for clustering of directed acyclic graphs (see [https://bitbucket.org/Bakkelund/ophac/wiki/Home](https://bitbucket.org/Bakkelund/ophac/wiki/Home) for details).<br/>\nThis example requires the python modules `ophac` and `clusim` to be installed.<br/>\nThe full source can be downloaded via this link:\n[example_ophac.py](https://bitbucket.org/Bakkelund/machine-parts-pp/src/master/python/example/example_ophac.py)\n\n```python\n# We now cluster the elements using order preserving clustering through the\n# ophac library. See the documentation of ophac for details.\n\nimport ophac.hierarchy       as hc\nimport ophac.dtypes          as dt\n\n# Formatting the part-of relations as required by ophac\nN = len(graph)\nQ = [sorted(graph[x]) for x in range(N)]\n\n# Formatting the dissimilarity as required by ophac\nD = []\nfor i in range(N):\n    for j in range(i+1,N):\n        D.append(dissims[i,j])\n\n# Run the ophac approximation algorithm\nac = hc.approx_linkage(D,Q,'complete')\n\n# Plotting the merge dissimilarities to find the location of the\n# so called knee. Inspection of the below plot shows that a useful \n# cutoff may be at about 150 merges --> we extract the clustering \n# at this point\nimport matplotlib.pyplot as plt\nnCut = 150\nplt.plot(ac[0].dists, label='merges')\nplt.plot([nCut],[ac[0].dists[nCut]], c='red', marker='o',\n         label=('cut at %d merges' % nCut))\nplt.legend()\nplt.title('Choosing to cut at %d merges based on inspection' % nCut)\nplt.show()\n\n# Using ophac libraries to extract the clustering at nCut merges\ncutoff_partition = dt.merge(dt.Partition(n=N),ac[0].joins[:nCut])\nclusters         = cutoff_partition.data\n\n# We can now compare the 'clusters' with the 'planted_partition'\n# to evaluate the degree of precision in recovering the planted partition.\n#\n# We have chosen to use the library 'clusim', which requires the clustering to\n# be represented by a dict mapping (eltId,clustId)\n# See the documentaton of clusim for details.\n\nimport clusim.clustering\nimport clusim.sim\n\n# Planted partition clusim representation\npp_cluster_idx = pp.clustering_to_cluster_index_mapping(planted_partition)\npp_dict = {x : [pp_cluster_idx[x]] for x in range(N)}\npp_clst = clusim.clustering.Clustering(elm2clu_dict=pp_dict)\n\n# ophac clustering clusim representation\ndb_cluster_idx = pp.clustering_to_cluster_index_mapping(clusters)\ndb_dict = {x : [db_cluster_idx[x]] for x in range(N)}\ndb_clst = clusim.clustering.Clustering(elm2clu_dict=db_dict)\n\n# Since the ophac clustering is not pre-set to have a fixed number of clusters,\n# we consider the clustering to be \"drawn\" from the family of all clusterings\nari = clusim.sim.adjrand_index(db_clst, pp_clst, 'all1')\n\nprint('Adjusted Rand index:', ari)\n```\n\n###Repository\n\nThe source code for this `python` module is available at\n<https://bitbucket.org/Bakkelund/machine-parts-pp/>",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://bitbucket.org/Bakkelund/machine-parts-pp/",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "machine-parts-pp",
    "package_url": "https://pypi.org/project/machine-parts-pp/",
    "platform": "",
    "project_url": "https://pypi.org/project/machine-parts-pp/",
    "project_urls": {
      "Homepage": "https://bitbucket.org/Bakkelund/machine-parts-pp/"
    },
    "release_url": "https://pypi.org/project/machine-parts-pp/0.0.2/",
    "requires_dist": null,
    "requires_python": ">=3.0",
    "summary": "Planted partitions over machine part data with part-of relations",
    "version": "0.0.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12492697,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a262ddf2280df81e90a3b00c76c33783bb22c76ac1082a55922dfe783913bd14",
          "md5": "7100ed3ebfc7ef0814ac5af9087fbbbd",
          "sha256": "00af6821a67c6353e5f5e3aad23c9665421798c63b01b532d0f22866576294d1"
        },
        "downloads": -1,
        "filename": "machine_parts_pp-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "7100ed3ebfc7ef0814ac5af9087fbbbd",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 47947,
        "upload_time": "2021-12-13T18:32:21",
        "upload_time_iso_8601": "2021-12-13T18:32:21.210026Z",
        "url": "https://files.pythonhosted.org/packages/a2/62/ddf2280df81e90a3b00c76c33783bb22c76ac1082a55922dfe783913bd14/machine_parts_pp-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0530b03ab8f4f66d179e98166c8022af9a12601959111de56e671489ed3fc077",
          "md5": "4fea3b8491209216855baf2219e1a48b",
          "sha256": "4b04c196f598af4b812a6373f9a535a5cfbe1d968e30bca039174db7fd76ac0b"
        },
        "downloads": -1,
        "filename": "machine_parts_pp-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "4fea3b8491209216855baf2219e1a48b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.0",
        "size": 48101,
        "upload_time": "2022-01-06T09:39:43",
        "upload_time_iso_8601": "2022-01-06T09:39:43.199972Z",
        "url": "https://files.pythonhosted.org/packages/05/30/b03ab8f4f66d179e98166c8022af9a12601959111de56e671489ed3fc077/machine_parts_pp-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "0530b03ab8f4f66d179e98166c8022af9a12601959111de56e671489ed3fc077",
        "md5": "4fea3b8491209216855baf2219e1a48b",
        "sha256": "4b04c196f598af4b812a6373f9a535a5cfbe1d968e30bca039174db7fd76ac0b"
      },
      "downloads": -1,
      "filename": "machine_parts_pp-0.0.2.tar.gz",
      "has_sig": false,
      "md5_digest": "4fea3b8491209216855baf2219e1a48b",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.0",
      "size": 48101,
      "upload_time": "2022-01-06T09:39:43",
      "upload_time_iso_8601": "2022-01-06T09:39:43.199972Z",
      "url": "https://files.pythonhosted.org/packages/05/30/b03ab8f4f66d179e98166c8022af9a12601959111de56e671489ed3fc077/machine_parts_pp-0.0.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}