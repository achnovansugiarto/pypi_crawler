{
  "info": {
    "author": "Salim I. Amoukou",
    "author_email": "salim.ibrahim-amoukou@universite-paris-saclay.fr",
    "bugtrack_url": null,
    "classifiers": [],
    "description": " # Active Coalition of Variables (ACV):\n\nACV is a python library that aims to explain **any machine learning models** or **data**. \n\n* It gives **local rule-based** explanations for any model or data.\n* It provides **a better estimation of Shapley Values for tree-based model** (more accurate than [path-dependent TreeSHAP](https://github.com/slundberg/shap])). \n It also proposes new Shapley Values that have better local fidelity.\n\nWe can regroup the different explanations in two groups: **Agnostic Explanations** and **Tree-based Explanations**.\n \n### Installation\n\n##### Requirements\nPython 3.6+ \n\n**OSX**: ACV uses Cython extensions that need to be compiled with multi-threading support enabled. \nThe default Apple Clang compiler does not support OpenMP.\nTo solve this issue, obtain the lastest gcc version with Homebrew that has multi-threading enabled: \nsee for example [pysteps installation for OSX.](https://pypi.org/project/pysteps/1.0.0/)\n\n**Windows**: Install MinGW (a Windows distribution of gcc) or Microsoft’s Visual C\n\n\nInstall the acv package:\n```\n$ pip install acv-exp\n```\n\n \n## A. Agnostic explanations\nThe Agnostic approaches explain any data (**X**, **Y**) or model (**X**, **f(X)**) using the following \nexplanation methods:\n\n* Same Decision Probability (SDP) and **Sufficient Explanations**\n* **Sufficient Rules**\n\nSee the paper [Consistent Sufficient Explanations and Minimal Local Rules for explaining regression and classification models]\n for more details.\n\n**I. First, we need to fit our explainer (ACXplainers) to input-output of the data **(X, Y)** or model\n**(X, f(X))** if we want to explain the data or the model respectively.**\n\n```python\nfrom acv_explainers import ACXplainer\n\n# It has the same params as a Random Forest, and it should be tuned to maximize the performance.  \nacv_xplainer = ACXplainer(classifier=True, n_estimators=50, max_depth=5)\nacv_xplainer.fit(X_train, y_train)\n\nroc = roc_auc_score(acv_xplainer.predict(X_test), y_test)\n```\n\n**II. Then, we can load all the explanations in a webApp as follow:**\n\n```python \nimport acv_app\nimport os\n\n# compile the ACXplainer\nacv_app.compile_ACXplainers(acv_xplainer, X_train, y_train, X_test, y_test, path=os.getcwd())\n\n# Launch the webApp\nacv_app.run_webapp(pickle_path=os.getcwd())\n```\n![Capture d’écran de 2021-11-03 19-50-12](https://user-images.githubusercontent.com/40361886/140174581-4c5bf018-05ad-49e0-b005-2a65453626e1.png)\n\n\n\n**III. Or we can compute each explanation separately as follow:**\n\n#### Same Decision Probability (SDP)\nThe main tool of our explanations is the Same Decision Probability (SDP). Given <img src=\"https://latex.codecogs.com/gif.latex?x%20%3D%20%28x_S%2C%20x_%7B%5Cbar%7BS%7D%7D%29\" />, the same decision probability <img src=\"https://latex.codecogs.com/gif.latex?SDP_S%28x%2C%20f%29\" /> of variables <img src=\"https://latex.codecogs.com/gif.latex?x_S\" />  is the probabilty that the prediction remains the same when we fixed variables \n<img src=\"https://latex.codecogs.com/gif.latex?X_S=x_S\" /> or when the variables <img src=\"https://latex.codecogs.com/gif.latex?X_{\\bar{S}}\" /> are missing.\n* **How to compute <img src=\"https://latex.codecogs.com/gif.latex?SDP_S%28x%2C%20f%29\" />  ?**\n\n```python\nsdp = acv_xplainer.compute_sdp_rf(X, S, data_bground) # data_bground is the background dataset that is used for the estimation. It should be the training samples.\n```\n#### Minimal Sufficient Explanations\nThe Sufficient Explanations is the Minimal Subset S such that fixing the values <img src=\"https://latex.codecogs.com/gif.latex?X_S=x_S\" /> \npermit to maintain the prediction with high probability <img src=\"https://latex.codecogs.com/gif.latex?\\pi\" />.\nSee the paper [ref] for more details. \n\n* **How to compute all the Sufficient Explanations  ?**\n\n    Since the Sufficient Explanation is not unique for a given instance, we can compute all of them.\n```python\nsufficient_expl, sdp_expl, sdp_global = acv_xplainer.sufficient_expl_rf(X, y, X_train, y_train, pi_level=0.9)\n```\n\n* **How to compute the Minimal Sufficient Explanation <img src=\"https://latex.codecogs.com/gif.latex?S^\\star\" /> ?**\n    \n    The following code return the Sufficient Explanation with minimal cardinality. \n```python\nsdp_importance, sufficient_expl, size, sdp = acv_xplainer.importance_sdp_rf(X, y, X_train, y_train, pi_level=0.9)\n```\n\n#### Local Explanatory Importance\nFor a given instance, the local explanatory importance of each variable corresponds to the frequency of \napparition of the given variable in the Sufficient Explanations. See the paper [ref] for more details. \n\n* **How to compute the Local Explanatory Importance ?**\n\n```python\nlximp = acv_xplainer.compute_local_sdp(d=X_train.shape[1], sufficient_expl)\n```\n\n#### Local rule-based explanations\nFor a given instance **(x, y)** and its Sufficient Explanation S, we compute a local minimal rule which contains *x* such \nthat every observation **z** that satisfies this rule has <img src=\"https://latex.codecogs.com/gif.latex?SDP_S(\\boldsymbol{x};&space;y)&space;\\geq&space;\\pi\" title=\"SDP_S(\\boldsymbol{x}; y) \\geq \\pi\" />\n\n* **How to compute the local rule explanations ?**\n\n```python\nsdp, rules, _, _, _ = acv_xplainer.compute_sdp_maxrules(X, y, data_bground, y_bground, S) # data_bground is the background dataset that is used for the estimation. It should be the training samples.\n```\n\n## B. Tree-based explanations\nACV gives Shapley Values explanations for XGBoost, LightGBM, CatBoostClassifier, scikit-learn and pyspark tree models. It\nprovides the following  Shapley Values: \n\n* Classic local Shapley Values (The value function is the conditional expectation <img src=\"https://latex.codecogs.com/gif.latex?E[f(x)&space;|&space;\\boldsymbol{X}_S&space;=&space;\\boldsymbol{x}_S]\" title=\"E[f(x) | \\boldsymbol{X}_S = \\boldsymbol{x}_S]\" />)\n* Active Shapley values (Local fidelity and Sparse by design)\n* Swing Shapley Values (The Shapley values are interpretable by design) *(Coming soon)*\n\nIn addition, we use the coalitional version of SV to properly handle categorical variables in the computation of SV.\n\nSee the papers [here](https://github.com/salimamoukou/acv00/blob/main/papers/)\n\nTo explain the tree-based models above, we need to transform our model into ACVTree. \n```python\nfrom acv_explainers import ACVTree\n\nforest = XGBClassifier() # or any Tree Based models\n#...trained the model\n\nacvtree = ACVTree(forest, data_bground) # data_bground is the background dataset that is used for the estimation. It should be the training samples.\n```\n#### Accurate Shapley Values\n\n```python\nsv = acvtree.shap_values(X)\n```\nNote that it provides a better estimation of the [tree-path dependent of TreeSHAP](https://github.com/slundberg/shap]) when the variables are dependent.\n\n#### Accurate Shapley Values with encoded categorical variables\n\nLet assume we have a categorical variable Y with k modalities that we encoded by introducing the dummy variables <img src=\"https://latex.codecogs.com/gif.latex?Y_1%2C%5Cdots%2C%20Y_%7Bk-1%7D\" />. As shown in the paper, we must take the coalition of the dummy variables to correctly compute the Shapley values.\n\n```python\n\n# cat_index := list[list[int]] that contains the column indices of the dummies or one-hot variables grouped \n# together for each variable. For example, if we have only 2 categorical variables Y, Z \n# transformed into [Y_0, Y_1, Y_2] and [Z_0, Z_1, Z_2]\n\ncat_index = [[0, 1, 2], [3, 4, 5]]\nforest_sv = acvtree.shap_values(X, C=cat_index)\n```\nIn addition, we can compute the SV given any coalitions. For example, let assume we have 10 variables \n<img src=\"https://latex.codecogs.com/gif.latex?(X_0, X_1, \\dots , X_{10})\" /> and we want the following coalition <img src=\"https://latex.codecogs.com/gif.latex?C_0%20%3D%20%28X_0%2C%20X_1%2C%20X_2%29%2C%20C_1%3D%28X_3%2C%20X_4%29%2C%20C_2%3D%28X_5%2C%20X_6%29\" />\n\n```python\n\ncoalition = [[0, 1, 2], [3, 4], [5, 6]]\nforest_sv = acvtree.shap_values(X, C=coalition)\n```\n#### **How to compute <img src=\"https://latex.codecogs.com/gif.latex?SDP_S%28x%2C%20f%29\" />  for tree-based classifier ?**\nRecall that the <img src=\"https://latex.codecogs.com/gif.latex?SDP_S%28x%2C%20f%29\" /> is the probability that the prediction remains the same when we fixed variables \n<img src=\"https://latex.codecogs.com/gif.latex?X_S=x_S\" /> given the subset S.\n```python\nsdp = acvtree.compute_sdp_clf(X, S, data_bground) # data_bground is the background dataset that is used for the estimation. It should be the training samples.\n```\n#### **How to compute the Sufficient Coalition <img src=\"https://latex.codecogs.com/gif.latex?S^\\star\" /> and the Global SDP importance for tree-based classifier ?**\nRecall that the Minimal Sufficient Explanations is the Minimal Subset S such that fixing the values <img src=\"https://latex.codecogs.com/gif.latex?X_S=x_S\" /> \npermit to maintain the prediction with high probability <img src=\"https://latex.codecogs.com/gif.latex?\\pi\" />.\n\n```python \nsdp_importance, sdp_index, size, sdp = acvtree.importance_sdp_clf(X, data_bground) # data_bground is the background dataset that is used for the estimation. It should be the training samples.\n```\n\n#### Active Shapley values\n\nThe Active Shapley values is a SV based on a new game defined in the Paper ([Accurate and robust Shapley Values for explaining predictions and focusing on local important variables](https://github.com/salimamoukou/acv00/blob/main/papers/) such that null (non-important) variables has zero SV and the \"payout\" is fairly distribute among active variables.\n\n* **How to compute Active Shapley values ?**\n\n```python\nimport acv_explainers\n\n# First, we need to compute the Active and Null coalition\nsdp_importance, sdp_index, size, sdp = acvtree.importance_sdp_clf(X, data_bground)\nS_star, N_star = acv_explainers.utils.get_active_null_coalition_list(sdp_index, size)\n\n# Then, we used the active coalition found to compute the Active Shapley values.\nforest_asv_adap = acvtree.shap_values_acv_adap(X, C, S_star, N_star, size)\n```\n\n##### Remarks for tree-based explanations: \nIf you don't want to use multi-threaded (due to scaling or memory problem), you have to add \"_nopa\" to each function (e.g. compute_sdp_clf ==> compute_sdp_clf_nopa).\nYou can also compute the different values needed in cache by setting cache=True \nin ACVTree initialization e.g. ACVTree(model, data_bground, cache=True).\n\n## Examples and tutorials (a lot more to come...)\nWe can find a tutorial of the usages of ACV in [demo_acv](https://github.com/salimamoukou/acv00/blob/main/notebooks/demo_acv_explainer) and \nthe notebooks below demonstrate different use cases for ACV. Look inside the notebook directory of the repository if you want to try playing with the original notebooks yourself.\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/salimamoukou/acv00",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "acvt45",
    "package_url": "https://pypi.org/project/acvt45/",
    "platform": "",
    "project_url": "https://pypi.org/project/acvt45/",
    "project_urls": {
      "Homepage": "https://github.com/salimamoukou/acv00"
    },
    "release_url": "https://pypi.org/project/acvt45/1.1.3/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "ACV is a library that provides robust and accurate explanations for machine learning models",
    "version": "1.1.3",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 11919331,
  "releases": {
    "1.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "703bf4d648f6243d348c1d1a0bd6f3a359ef418401d1eb1be98a88d39dec7ea2",
          "md5": "56c8d6c2f6d0a8ba95a009ba234680d1",
          "sha256": "4d6170826a7d598cb80f7c8f937d409fd6dfa4d0f9d2e61c2c0ae0fef2cee3e9"
        },
        "downloads": -1,
        "filename": "acvt45-1.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "56c8d6c2f6d0a8ba95a009ba234680d1",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 1191054,
        "upload_time": "2021-11-03T22:12:40",
        "upload_time_iso_8601": "2021-11-03T22:12:40.460935Z",
        "url": "https://files.pythonhosted.org/packages/70/3b/f4d648f6243d348c1d1a0bd6f3a359ef418401d1eb1be98a88d39dec7ea2/acvt45-1.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b53624892b3dc37c6a31e7d0fac93fb1c5eb9646f9d49f90097739ef9e7b69d1",
          "md5": "c2351065c2e43413099f9de30b825d81",
          "sha256": "0d847ac2ba9c8db4a84eb9181115639d390b63cfaced77d07fbbbd33f7cec2cb"
        },
        "downloads": -1,
        "filename": "acvt45-1.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "c2351065c2e43413099f9de30b825d81",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 1191084,
        "upload_time": "2021-11-03T22:41:23",
        "upload_time_iso_8601": "2021-11-03T22:41:23.307442Z",
        "url": "https://files.pythonhosted.org/packages/b5/36/24892b3dc37c6a31e7d0fac93fb1c5eb9646f9d49f90097739ef9e7b69d1/acvt45-1.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "374f00c1a683bee830d4db186f4143d040d92dcfa580865fcc056f6412d06093",
          "md5": "5173ab6dd5307c61156f349d3e8f823e",
          "sha256": "686b5237d436edf9ec37c98607f905d679920dd703c2de954274a37255815144"
        },
        "downloads": -1,
        "filename": "acvt45-1.1.3.tar.gz",
        "has_sig": false,
        "md5_digest": "5173ab6dd5307c61156f349d3e8f823e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 1190461,
        "upload_time": "2021-11-03T22:53:41",
        "upload_time_iso_8601": "2021-11-03T22:53:41.776259Z",
        "url": "https://files.pythonhosted.org/packages/37/4f/00c1a683bee830d4db186f4143d040d92dcfa580865fcc056f6412d06093/acvt45-1.1.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "374f00c1a683bee830d4db186f4143d040d92dcfa580865fcc056f6412d06093",
        "md5": "5173ab6dd5307c61156f349d3e8f823e",
        "sha256": "686b5237d436edf9ec37c98607f905d679920dd703c2de954274a37255815144"
      },
      "downloads": -1,
      "filename": "acvt45-1.1.3.tar.gz",
      "has_sig": false,
      "md5_digest": "5173ab6dd5307c61156f349d3e8f823e",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 1190461,
      "upload_time": "2021-11-03T22:53:41",
      "upload_time_iso_8601": "2021-11-03T22:53:41.776259Z",
      "url": "https://files.pythonhosted.org/packages/37/4f/00c1a683bee830d4db186f4143d040d92dcfa580865fcc056f6412d06093/acvt45-1.1.3.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}