{
  "info": {
    "author": "Ai Palette",
    "author_email": "ritvik@aipalette.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# aipalette_nlp\n```aipalette_nlp``` python package is a package that contains a list of NLP functions that will be used for future tasks in Ai Palette. Many useful modules and functions will be included in the package. For now, it has a module that consists of tokenizers of different languages, and another module that has several functions for text preprocessing which also includes detecting language.  \n<br>\n\n## How to Use\nInstall this package using pip : `>> pip install aipalette_nlp`, and import it directly in your code.\n<br>\n        \n## Modules \n    \n### *Module1: tokenizer*    \nBelow is an example of how you can use the ```word_tokenize``` function in the tokenizer module, which will automatically detect input language and call its respective tokenizer.\n\n```  \nfrom aipalette_nlp.tokenizer import word_tokenize\n\ntext = \"우아아 제 요리에 날개를 달아주는 아름다운 <키친콤마> 식품들이 도착했어요. 저당질, 저탄수화물로 만들어져 건강과 다이어트 그리고 맛까지 한꺼번에 챙길 수 있는 필수템입니다! 처음 호기심에서 시작한 저탄고지 키토식단을 유지한지 어느덧 2년 가까이 되었어요. 저탄고지는 살을 빼기위해 무작정 탄수화물을 끊는다거나 몸에 무리가 갈 수 있는 저칼로리 / 저염식이 아니에요. 내 몸에서 나타나는 반응에 좀더 귀기울이고 끊임없이 공부하고 좋은 음식을 섭취하려고 노력하는 라이프스타일 입니다.\"  \n\nprint(word_tokenize(text)) \n```\n**Output:**\n\n{'tokenized_text': ['우아아', '제', '요리에', '날개를', '달아주는', '아름다운', '<키친콤마>', '식품들이', '도착했어요', '저당질,', '저탄수화물로', '만들어져', '건강과', '다이어트', '그리고', '맛까지', '한꺼번에', '챙길', '수', '있는', '필수템입니ᄃ', 'ᅡ!', '처음', '호기심에서', '시작 한', '저탄고지', '키토식단을', '유지한지', '어느덧', '2년', '가까이', '되었어요', '저탄고지는', '살을', '빼기위해', '무작정', '탄수화물을', '끊는다거나', '몸에', '무리가', '갈', '수', '있는', '저칼로리', '/', '', '저염식이', '아니에요', '내', '몸에서', '나타나는', '반응에', '좀더', '귀기울이고', '끊임없이', '공부하고', '좋은', '음식을', '섭취하려고', '노력하는', '라이프스타일', '입니다']}\n\n### *Module2: text_cleaning* \nBelow is an example of how you can use the functions in the text_cleaning module.    \n```\nfrom aipalette_nlp.preprocessing import detect_language, clean_text, remove_stopwords\n\ntext = \"\"\"Dinner at @docksidevancouver . Patio season is definitely here!Support your local restaurants.\n\n#foodie #facestuffing #scoutmagazine #vancouvermagazine #dailyhivevancouver #ediblevancouver #eatmagazine #vancouverisawesome #vancouverfoodie #food #foodlover\n#curiocityvancouver #foodporn #foodlover #eat #foodgasm #foodinsta #foodinstagram #instafood #instafoodie #foodlover #foodpics  #foodiesofinstagram #restaurant #homechef #foodphotography #nomnomnom #georgiastraight #docksiderestaurant #granvilleisland #gnocchi #dinner\"\"\"\n\nprint(\"language detected of the given text is : \", detect_language(text))\nprint(remove_stopwords(text))\nprint(clean_text(text))\n\n```  \n   \n**Output:** \n\nlanguage detected of the given text is : en\n\ndinner @docksidevancouver . patio season definitely here!support local restaurants. #foodie #facestuffing #scoutmagazine #vancouvermagazine #dailyhivevancouver #ediblevancouver #eatmagazine #vancouverisawesome #vancouverfoodie #food #foodlover #curiocityvancouver #foodporn #foodlover #eat #foodgasm #foodinsta #foodinstagram #instafood #instafoodie #foodlover #foodpics #foodiesofinstagram #restaurant #homechef #foodphotography #nomnomnom #georgiastraight #docksiderestaurant #granvilleisland #gnocchi #dinner\n\n{'hashtags': ['foodie', 'facestuffing', 'scoutmagazine', 'vancouvermagazine', 'dailyhivevancouver', 'ediblevancouver', 'eatmagazine', 'vancouverisawesome', 'vancouverfoodie', 'food', 'foodlover', 'curiocityvancouver', 'foodporn', 'foodlover', 'eat', 'foodgasm', 'foodinsta', 'foodinstagram', 'instafood', 'instafoodie', 'foodlover', 'foodpics', 'foodiesofinstagram', 'restaurant', 'homechef', 'foodphotography', 'nomnomnom', 'georgiastraight', 'docksiderestaurant', 'granvilleisland', 'gnocchi', 'dinner'], 'cleaned_text': 'dinner username patio season definitely support local restaurants', 'text_length': 65} \n\n<br>\n\n## Complete list of tokenizers supported:\n\n['english', 'french', 'italian', 'portuguese', 'spanish', 'swedish', 'turkish', 'russian', 'mandarin', 'thai', 'japanese', 'korean', 'vietnamese','german', 'arabic']    \n\n<br>\n\n## Text Processing/Cleaning Functions   \nThe ```clean_text``` function from module text_cleaning does the following steps:   \n\n* replace the hashtags (#______) in the main caption with the original form of the word.\n* replace all the mentioned usernames (@_______) with the word “\\<username>”.\n* remove punctuations\n* remove stopwords (use nltk package)\n* detect language\n* replace all links/urls\n\n\n#### Language supported by our language detector :\n`af, am, an, ar, as, az, be, bg, bn, br, bs, ca, cs, cy, da, de, dz, el, en, eo, es, et, eu, fa, fi, fo, fr, ga, gl, gu, he, hi, hr, ht, hu, hy, id, is, it, ja, jv, ka, kk, km, kn, ko, ku, ky, la, lb, lo, lt, lv, mg, mk, ml, mn, mr, ms, mt, nb, ne, nl, nn, no, oc, or, pa, pl, ps, pt, qu, ro, ru, rw, se, si, sk, sl, sq, sr, sv, sw, ta, te, th, tl, tr, ug, uk, ur, vi, vo, wa, xh, zh, zu`\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://bitbucket.org/aipalettepermanent/aipalettenlp-package/src/ritvik-nlp/",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "aipalette-nlp",
    "package_url": "https://pypi.org/project/aipalette-nlp/",
    "platform": null,
    "project_url": "https://pypi.org/project/aipalette-nlp/",
    "project_urls": {
      "Bug Tracker": "https://bitbucket.org/aipalettepermanent/aipalettenlp-package/src/ritvik-nlp/issues",
      "Homepage": "https://bitbucket.org/aipalettepermanent/aipalettenlp-package/src/ritvik-nlp/"
    },
    "release_url": "https://pypi.org/project/aipalette-nlp/0.1.0/",
    "requires_dist": [
      "setuptools (>=42)",
      "wheel",
      "nltk (==3.7)",
      "fastai (==2.7.9)",
      "Janome (==0.4.2)",
      "jieba (==0.42.1)",
      "numpy (==1.24.2)",
      "emoji (==2.0.0)",
      "pythainlp (==3.1.1)",
      "torch (==1.12.1)",
      "SoMaJo (==2.2.3)",
      "pyvi (==0.1.1)",
      "konlpy (==0.6.0)",
      "langcodes (==3.3.0)",
      "langid (==1.1.6)",
      "language-data (==1.1)"
    ],
    "requires_python": ">=3.8",
    "summary": "Ai Palette NLP toolkit",
    "version": "0.1.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16945393,
  "releases": {
    "0.0.9": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "08018c8c462d3104b710076414922d519b6843afe0043cd2648410be1f34aa57",
          "md5": "e54f04c8fa4a62873c46dc5d4ee0d763",
          "sha256": "340647f037cee4c966f6066349e9bdaabe4f989fc75c6331bb4ff6f689476623"
        },
        "downloads": -1,
        "filename": "aipalette_nlp-0.0.9-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "e54f04c8fa4a62873c46dc5d4ee0d763",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 25581,
        "upload_time": "2023-02-20T14:59:16",
        "upload_time_iso_8601": "2023-02-20T14:59:16.581378Z",
        "url": "https://files.pythonhosted.org/packages/08/01/8c8c462d3104b710076414922d519b6843afe0043cd2648410be1f34aa57/aipalette_nlp-0.0.9-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "db232b231e27b27c352402887f2188de42fb9e30d6303ac83e402d9f1adfd066",
          "md5": "70ed2a9780371272a9eac0fe29e0229a",
          "sha256": "fac27686187ae712da28becbb055c7859f74409d51a5bb031df3ea96756fe1c8"
        },
        "downloads": -1,
        "filename": "aipalette_nlp-0.0.9.tar.gz",
        "has_sig": false,
        "md5_digest": "70ed2a9780371272a9eac0fe29e0229a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 24306,
        "upload_time": "2023-02-20T14:59:18",
        "upload_time_iso_8601": "2023-02-20T14:59:18.350424Z",
        "url": "https://files.pythonhosted.org/packages/db/23/2b231e27b27c352402887f2188de42fb9e30d6303ac83e402d9f1adfd066/aipalette_nlp-0.0.9.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a0e93368acd0bf0703fb028a3f32f8e1bbb64bfd013cd19e13011bae748c8f3d",
          "md5": "7bf1d7250d496216509eb4adf15434fc",
          "sha256": "f036efd3a20a29c81912a5108542a3996666ac1e1cf6102f115a971aa2a4e962"
        },
        "downloads": -1,
        "filename": "aipalette_nlp-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "7bf1d7250d496216509eb4adf15434fc",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 25647,
        "upload_time": "2023-02-20T16:03:59",
        "upload_time_iso_8601": "2023-02-20T16:03:59.388356Z",
        "url": "https://files.pythonhosted.org/packages/a0/e9/3368acd0bf0703fb028a3f32f8e1bbb64bfd013cd19e13011bae748c8f3d/aipalette_nlp-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6bcfe05ab033e7a29f5397de99c50cc2f58fb38bc374a0e91f8f1d2f8b9e742f",
          "md5": "0db6365ad7838aa9a4e2765618da9b79",
          "sha256": "0db76860674d5c5b5a9af795db876c4d7404d0e073452b4fb7cf4329c592a424"
        },
        "downloads": -1,
        "filename": "aipalette_nlp-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "0db6365ad7838aa9a4e2765618da9b79",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 24294,
        "upload_time": "2023-02-20T16:04:01",
        "upload_time_iso_8601": "2023-02-20T16:04:01.239221Z",
        "url": "https://files.pythonhosted.org/packages/6b/cf/e05ab033e7a29f5397de99c50cc2f58fb38bc374a0e91f8f1d2f8b9e742f/aipalette_nlp-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "a0e93368acd0bf0703fb028a3f32f8e1bbb64bfd013cd19e13011bae748c8f3d",
        "md5": "7bf1d7250d496216509eb4adf15434fc",
        "sha256": "f036efd3a20a29c81912a5108542a3996666ac1e1cf6102f115a971aa2a4e962"
      },
      "downloads": -1,
      "filename": "aipalette_nlp-0.1.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "7bf1d7250d496216509eb4adf15434fc",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.8",
      "size": 25647,
      "upload_time": "2023-02-20T16:03:59",
      "upload_time_iso_8601": "2023-02-20T16:03:59.388356Z",
      "url": "https://files.pythonhosted.org/packages/a0/e9/3368acd0bf0703fb028a3f32f8e1bbb64bfd013cd19e13011bae748c8f3d/aipalette_nlp-0.1.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "6bcfe05ab033e7a29f5397de99c50cc2f58fb38bc374a0e91f8f1d2f8b9e742f",
        "md5": "0db6365ad7838aa9a4e2765618da9b79",
        "sha256": "0db76860674d5c5b5a9af795db876c4d7404d0e073452b4fb7cf4329c592a424"
      },
      "downloads": -1,
      "filename": "aipalette_nlp-0.1.0.tar.gz",
      "has_sig": false,
      "md5_digest": "0db6365ad7838aa9a4e2765618da9b79",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.8",
      "size": 24294,
      "upload_time": "2023-02-20T16:04:01",
      "upload_time_iso_8601": "2023-02-20T16:04:01.239221Z",
      "url": "https://files.pythonhosted.org/packages/6b/cf/e05ab033e7a29f5397de99c50cc2f58fb38bc374a0e91f8f1d2f8b9e742f/aipalette_nlp-0.1.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}