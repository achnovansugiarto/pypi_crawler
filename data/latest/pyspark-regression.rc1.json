{
  "info": {
    "author": "Forrest Bajbek",
    "author_email": "forrestbajbek@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: MacOS :: MacOS X",
      "Operating System :: POSIX :: Linux",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9"
    ],
    "description": "# pyspark-regression\nA tool for regression testing Spark Dataframes in Python.\n\n`pyspark-regression` is a tool for regression testing Spark Dataframes in Python.\n\nFor install instructions and API documentation, please visit https://forrest-bajbek.github.io/pyspark-regression/\n\n\n## What is a Regression Test?\nA [Regression Test](https://en.wikipedia.org/wiki/Regression_testing) ensures that changes to code only produce expected outcomes, introducing no _new_ bugs. These tests are particularly challenging when working with database tables, as the result can be too large to visually inspect. When updating a SQL transformation, Data Engineers must ensure that no rows or columns were unintentionally altered, even if the table has 300 columns and 400 billion rows.\n\n`pyspark-regression` reduces the complexity of Regression Testing for structured database tables. It standardizes the concepts and jargon associated with this topic, and implements a clean Python API for running regression tests against DataFrames in [Apache Spark](https://spark.apache.org/).\n\n## Example\nConsider the following table:\n\n| id | name | price |\n| - | - | - |\n| 1 | Taco | 3.001 |\n| 2 | Burrito | 6.50 |\n| 3 | flauta | 7.50 |\n\nImagine you are a Data Engineer, and you want to change the underlying ETL so that:\n\n1. The price for Tacos is rounded to 2 decimal places.\n1. The name for Flautas is capitalized.\n\nYou make your changes, and the new table looks like this:\n\n| id | name | price |\n| - | - | - |\n| 1 | Taco | **3.00** |\n| 2 | Burrito | 6.50 |\n| 3 | **Flauta** | 7.50 |\n\nRunning a regression test will help you confirm that the new ETL changed the data how you expected.\n\nLet's create the old and new tables as dataframes so we can run a Regression Test:\n```python\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import *\nfrom pyspark_regression.regression import RegressionTest\n\nspark = SparkSession.builder.getOrCreate()\nspark.conf.set(\"spark.sql.shuffle.partitions\", 1)\n\nschema = StructType(\n    [\n        StructField(\"id\", IntegerType()),\n        StructField(\"name\", StringType()),\n        StructField(\"price\", DoubleType()),\n    ]\n)\n\n# The old data\ndf_old = spark.createDataFrame(\n    [\n        (1, 'Taco', 3.001),\n        (2, 'Burrito', 6.50),\n        (3, 'flauta', 7.50),\n    ],\n    schema=schema\n)\n\n# The new data\ndf_new = spark.createDataFrame(\n    [\n        (1, 'Taco', 3.00),  # Corrected price\n        (2, 'Burrito', 6.50),\n        (3, 'Flauta', 7.50),  # Corrected name\n    ],\n    schema=schema\n)\n\nregression_test = RegressionTest(\n    df_old=df_old,\n    df_new=df_new,\n    pk='id',\n)\n```\n\n\n`RegressionTest()` returns a Python dataclass with lots of methods that help you inspect how the two dataframes are different. Most notably, the `summary` method prints a comprehensive analysis in Markdown. Here's what happens when you run `print(regression_test.summary)`:\n```\n# Regression Test: df\n- run_id: de9bd4eb-5313-4057-badc-7322ee23b83b\n- run_time: 2022-05-25 08:53:50.581283\n\n## Result: **FAILURE**.\nPrinting Regression Report...\n\n### Table stats\n- Count records in old df: 3\n- Count records in new df: 3\n- Count pks in old df: 3\n- Count pks in new df: 3\n\n### Diffs\n- Columns with diffs: {'name', 'price'}\n- Number of records with diffs: 2 (%oT: 66.7%)\n\n Diff Summary:\n| column_name   | data_type   | diff_category        |   count_record | count_record_%oT   |\n|:--------------|:------------|:---------------------|---------------:|:-------------------|\n| name          | string      | capitalization added |              1 | 33.3%              |\n| price         | double      | rounding             |              1 | 33.3%              |\n\n Diff Samples: (5 samples per column_name, per diff_category, per is_duplicate)\n| column_name   | data_type   |   pk | old_value   | new_value   | diff_category        |\n|:--------------|:------------|-----:|:------------|:------------|:---------------------|\n| name          | string      |    3 | 'flauta'    | 'Flauta'    | capitalization added |\n| price         | double      |    1 | 3.001       | 3.0         | rounding             |\n```\n\nThe `RegressionTest` class provides low level access to all the methods used to build the summary:\n```python\n>>> print(regression_test.count_record_old) # count of records in df_old\n3\n\n>>> print(regression_test.count_record_new) # count of records in df_new\n3\n\n>>> print(regression_test.columns_diff) # Columns with diffs\n{'name', 'price'}\n\n>>> regression_test.df_diff.filter(\"column_name = 'price'\").show() # Show all diffs for 'price' column\n+-----------+---------+---+---------+---------+-------------+\n|column_name|data_type| pk|old_value|new_value|diff_category|\n+-----------+---------+---+---------+---------+-------------+\n|      price|   double|  1|    3.001|      3.0|     rounding|\n+-----------+---------+---+---------+---------+-------------+\n```\n\nThis example is accessable from the module:\n```python\nfrom pyspark_regression.example import regression_test\nprint(regression_test.summary)\n```\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://forrest-bajbek.github.io/pyspark-regression/",
    "keywords": "",
    "license": "Apache License 2.0",
    "maintainer": "Forrest Bajbek",
    "maintainer_email": "forrestbajbek@gmail.com",
    "name": "pyspark-regression",
    "package_url": "https://pypi.org/project/pyspark-regression/",
    "platform": null,
    "project_url": "https://pypi.org/project/pyspark-regression/",
    "project_urls": {
      "Documentation": "https://forrest-bajbek.github.io/pyspark-regression/",
      "Homepage": "https://forrest-bajbek.github.io/pyspark-regression/",
      "PyPI": "https://pypi.org/project/pyspark-regression/",
      "Source Code": "https://github.com/forrest-bajbek/pyspark-regression"
    },
    "release_url": "https://pypi.org/project/pyspark-regression/1.1.1/",
    "requires_dist": [
      "pandas",
      "pyspark (>=3)",
      "tabulate",
      "build ; extra == 'dev'",
      "twine ; extra == 'dev'",
      "wheel ; extra == 'dev'",
      "setuptools ; extra == 'dev'",
      "black ; extra == 'dev'",
      "flake8 ; extra == 'dev'",
      "isort ; extra == 'dev'",
      "mkdocs-material ; extra == 'dev'",
      "mkdocstrings-python ; extra == 'dev'",
      "coverage ; extra == 'dev'",
      "pytest ; extra == 'dev'",
      "pytest-cov ; extra == 'dev'",
      "pytest-xdist ; extra == 'dev'"
    ],
    "requires_python": "<3.11,>=3.8",
    "summary": "A tool for regression testing Spark Dataframes in Python",
    "version": "1.1.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16276295,
  "releases": {
    "1.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a0ea8fe9d70e0be70b49a1343d367e49ea9d887462c164c22401b9239495e698",
          "md5": "eb79adfff7ab06519da5f2223b0b7e9d",
          "sha256": "dfeccb9f059d7678c413d058ca33825ca4c87b7d53576ab9b6ef2438beb6ee62"
        },
        "downloads": -1,
        "filename": "pyspark_regression-1.1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "eb79adfff7ab06519da5f2223b0b7e9d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": "<3.11,>=3.8",
        "size": 14081,
        "upload_time": "2023-01-02T04:21:15",
        "upload_time_iso_8601": "2023-01-02T04:21:15.896474Z",
        "url": "https://files.pythonhosted.org/packages/a0/ea/8fe9d70e0be70b49a1343d367e49ea9d887462c164c22401b9239495e698/pyspark_regression-1.1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1418352f3739c5ae4c14b4b6eed28cc8851a2ff9a718a0da42024bc75c87ea73",
          "md5": "bb901dbc19a28d7004ce96bcba1a71ab",
          "sha256": "72b63ff69ab8ccfac7ad8e5a79945c34ffb86eda068a6448e3e7ace3aae33dd1"
        },
        "downloads": -1,
        "filename": "pyspark-regression-1.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "bb901dbc19a28d7004ce96bcba1a71ab",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": "<3.11,>=3.8",
        "size": 15514,
        "upload_time": "2023-01-02T04:21:17",
        "upload_time_iso_8601": "2023-01-02T04:21:17.681330Z",
        "url": "https://files.pythonhosted.org/packages/14/18/352f3739c5ae4c14b4b6eed28cc8851a2ff9a718a0da42024bc75c87ea73/pyspark-regression-1.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "a0ea8fe9d70e0be70b49a1343d367e49ea9d887462c164c22401b9239495e698",
        "md5": "eb79adfff7ab06519da5f2223b0b7e9d",
        "sha256": "dfeccb9f059d7678c413d058ca33825ca4c87b7d53576ab9b6ef2438beb6ee62"
      },
      "downloads": -1,
      "filename": "pyspark_regression-1.1.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "eb79adfff7ab06519da5f2223b0b7e9d",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": "<3.11,>=3.8",
      "size": 14081,
      "upload_time": "2023-01-02T04:21:15",
      "upload_time_iso_8601": "2023-01-02T04:21:15.896474Z",
      "url": "https://files.pythonhosted.org/packages/a0/ea/8fe9d70e0be70b49a1343d367e49ea9d887462c164c22401b9239495e698/pyspark_regression-1.1.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "1418352f3739c5ae4c14b4b6eed28cc8851a2ff9a718a0da42024bc75c87ea73",
        "md5": "bb901dbc19a28d7004ce96bcba1a71ab",
        "sha256": "72b63ff69ab8ccfac7ad8e5a79945c34ffb86eda068a6448e3e7ace3aae33dd1"
      },
      "downloads": -1,
      "filename": "pyspark-regression-1.1.1.tar.gz",
      "has_sig": false,
      "md5_digest": "bb901dbc19a28d7004ce96bcba1a71ab",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": "<3.11,>=3.8",
      "size": 15514,
      "upload_time": "2023-01-02T04:21:17",
      "upload_time_iso_8601": "2023-01-02T04:21:17.681330Z",
      "url": "https://files.pythonhosted.org/packages/14/18/352f3739c5ae4c14b4b6eed28cc8851a2ff9a718a0da42024bc75c87ea73/pyspark-regression-1.1.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}