{
  "info": {
    "author": "Asahi Ushio",
    "author_email": "asahi1992ushio@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Intended Audience :: Developers",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3",
      "Topic :: Scientific/Engineering"
    ],
    "description": "[![license](https://img.shields.io/badge/License-MIT-brightgreen.svg)](https://github.com/asahi417/lmqg/blob/master/LICENSE)\n[![PyPI version](https://badge.fury.io/py/lmqg.svg)](https://badge.fury.io/py/lmqg)\n[![PyPI pyversions](https://img.shields.io/pypi/pyversions/lmqg.svg)](https://pypi.python.org/pypi/lmqg/)\n[![PyPI status](https://img.shields.io/pypi/status/lmqg.svg)](https://pypi.python.org/pypi/lmqg/)\n\n# Generative Language Models for Paragraph-Level Question Generation\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/asahi417/lm-question-generation/master/assets/qg_diagram.png\" width=\"500\">\n</p>\n\nThis is the official repository of the paper\n[\"Generative Language Models for Paragraph-Level Question Generation, EMNLP 2022 main conference\"](https://aclanthology.org/2022.emnlp-main.42/).\nThis repository includes following contents:\n- ***QG-Bench***, the first ever multilingual/multidomain QG benchmark.\n- ***Multilingual/multidomain QG models*** fine-tuned on QG-Bench.\n- A python library ***`lmqg`*** developed for question generation in python as well as QG model fine-tuning/evaluation.\n- ***AutoQG***, a web application hosting QG models where user can test the model output interactively. \n\n### Table of Contents  \n1. **[QG-Bench: multilingual & multidomain QG datasets (+ fine-tuned models)](https://github.com/asahi417/lm-question-generation/blob/master/QG_BENCH.md)**\n2. **[LMQG: python library to fine-tune/evaluate QG model](#lmqg-language-model-for-question-generation-)**\n3. **[AutoQG: web application hosting multilingual QG models](#autoqg)**\n4. **[RestAPI: run model prediction via restAPI](#rest-api-with-huggingface-inference-api)**\n\nPlease cite following paper if you use any resource:\n```\n@inproceedings{ushio-etal-2022-generative,\n    title = \"{G}enerative {L}anguage {M}odels for {P}aragraph-{L}evel {Q}uestion {G}eneration\",\n    author = \"Ushio, Asahi  and\n        Alva-Manchego, Fernando  and\n        Camacho-Collados, Jose\",\n    booktitle = \"Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing\",\n    month = dec,\n    year = \"2022\",\n    address = \"Abu Dhabi, U.A.E.\",\n    publisher = \"Association for Computational Linguistics\",\n}\n```\n\n## LMQG: Language Model for Question Generation ðŸš€\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/13izkdp2l7G2oeh_fwL7xJdR_67HMK_hQ?usp=sharing)\n\nThe `lmqg` is a python library to fine-tune seq2seq language models ([T5](https://arxiv.org/pdf/1910.10683.pdf), [BART](https://arxiv.org/pdf/1910.13461.pdf)) \non the question generation task and provide an API to host the model prediction via [huggingface](https://huggingface.co/).\nLet's install `lmqg` via pip first.\n```shell\npip install lmqg\n```\n\n### Generate Question & Answer\n\n- ***Generate Question on Answers:*** This is a basic usecase of our QG models, where user provides a paragraph and an answer to generate a question that is answerable by the answer given the paragraph.\nSee [MODEL CARD](https://github.com/asahi417/lm-question-generation/blob/master/QG_BENCH.md#qg-models) for the available models.\n\n```python\nfrom lmqg import TransformersQG\n# initialize model\nmodel = TransformersQG(language='en', model='lmqg/t5-large-squad-qg')\n# a list of paragraph\ncontext = [\n    \"William Turner was an English painter who specialised in watercolour landscapes\",\n    \"William Turner was an English painter who specialised in watercolour landscapes\"\n]\n# a list of answer (same size as the context)\nanswer = [\n    \"William Turner\",\n    \"English\"\n]\n# model prediction\nquestion = model.generate_q(list_context=context, list_answer=answer)\nprint(question)\n[\n    'Who was an English painter who specialised in watercolour landscapes?',\n    'What nationality was William Turner?'\n]\n```\n\n- ***Generate Question & Answer Pairs:*** Instead of specifying an answer, user can let QG model to generate an answer on the paragraph, and generate question on it sequentially.\nThis functionality is only available for the QG models fine-tuned with answer extraction see [MODEL CARD](https://github.com/asahi417/lm-question-generation/blob/master/QG_BENCH.md#models-with-answer-extraction) for the full list of models with answer extraction (model alias usually has a suffix of `-qg-ae`).\n  \n```python\nfrom lmqg import TransformersQG\n# initialize model\nmodel = TransformersQG(language='en', model='lmqg/t5-large-squad-qg-ae')\n# paragraph to generate pairs of question and answer\ncontext = \"William Turner was an English painter who specialised in watercolour landscapes. He is often known as William Turner of Oxford or just Turner of Oxford to distinguish him from his contemporary, J. M. W. Turner. Many of Turner's paintings depicted the countryside around Oxford. One of his best known pictures is a view of the city of Oxford from Hinksey Hill.\"\n# model prediction\nquestion_answer = model.generate_qa(context)\n# the output is a list of tuple (question, answer)\nprint(question_answer)\n[\n    ('Who was an English painter who specialised in watercolour landscapes?', 'William Turner'),\n    (\"What was William Turner's nickname?\", 'William Turner of Oxford'),\n    (\"What did many of Turner's paintings depict around Oxford?\", 'countryside'),\n    (\"What is one of William Turner's best known paintings?\", 'a view of the city of Oxford')\n]\n```\n\n\n### Model Evaluation\nThe evaluation tool reports `BLEU4`, `ROUGE-L`, `METEOR`, `BERTScore`, and `MoverScore` following [QG-Bench](https://github.com/asahi417/lm-question-generation/blob/master/QG_BENCH.md).\nFrom command line, run following command \n```shell\nlmqg-eval -m \"lmqg/t5-large-squad-qg\" -e \"./eval_metrics\" -d \"lmqg/qg_squad\" -l \"en\"\n```\nwhere `-m` is a model alias on huggingface or path to local checkpoint, `-e` is the directly to export the metric file, `-d` is the dataset to evaluate, and `-l` is the language of the test set.\nInstead of running model prediction, you can provide a prediction file instead to avoid computing it each time.\n```shell\nlmqg-eval --hyp-test '{your prediction file}' -e \"./eval_metrics\" -d \"lmqg/qg_squad\" -l \"en\"\n```\nThe prediction file should be a text file of model generation in each line in the order of `test` split in the target dataset\n([sample](https://huggingface.co/lmqg/t5-large-squad/raw/main/eval/samples.validation.hyp.paragraph_sentence.question.lmqg_qg_squad.default.txt)).\nCheck `lmqg-eval -h` to display all the options.\n\n### Model Training\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/asahi417/lm-question-generation/master/assets/grid_search.png\" width=\"650\">\n</p>\n\nTo fine-tune QG model, we employ a two-stage hyper-parameter optimization, described as above diagram.\nFollowing command is to run the fine-tuning with parameter optimization.\n```shell\nlmqg-train-search -c \"tmp_ckpt\" -d \"lmqg/qg_squad\" -m \"t5-small\" -b 64 --epoch-partial 5 -e 15 --language \"en\" --n-max-config 1 \\\n  -g 2 4 --lr 1e-04 5e-04 1e-03 --label-smoothing 0 0.15\n```\nCheck `lmqg-train-search -h` to display all the options.\n\nFine-tuning models in python follows below.  \n```python\nfrom lmqg import GridSearcher\ntrainer = GridSearcher(\n    checkpoint_dir='tmp_ckpt',\n    dataset_path='lmqg/qg_squad',\n    model='t5-small',\n    epoch=15,\n    epoch_partial=5,\n    batch=64,\n    n_max_config=5,\n    gradient_accumulation_steps=[2, 4], \n    lr=[1e-04, 5e-04, 1e-03],\n    label_smoothing=[0, 0.15]\n)\ntrainer.run()\n```\n\n\n## AutoQG\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/asahi417/lm-question-generation/master/assets/autoqg.gif\" width=\"500\">\n</p>\n\n***AutoQG ([https://autoqg.net](https://autoqg.net/))*** is a free web application hosting our QG models.\nThe QG models are listed at the [QG-Bench page](https://github.com/asahi417/lm-question-generation/blob/master/QG_BENCH.md).\n\n## Rest API with huggingface inference API\n\nWe provide a rest API which hosts the model inference through huggingface inference API. You need huggingface API token to run your own API and install dependencies as below.\n```shell\npip install lmqg[api]\n```\nSwagger UI is available at [`http://127.0.0.1:8088/docs`](http://127.0.0.1:8088/docs), when you run the app locally (replace the address by your server address).\n\n### Build\n- Build/Run Local (command line):\n```shell\nexport API_TOKEN={Your Huggingface API Token}\nuvicorn app:app --reload --port 8088\nuvicorn app:app --host 0.0.0.0 --port 8088\n```\n\n- Build/Run Local (docker):\n```shell\ndocker build -t lmqg/app:latest . --build-arg api_token={Your Huggingface API Token}\ndocker run -p 8080:8080 lmqg/app:latest\n```\n\n### API Description\nYou must pass the huggingface api token via the environmental variable `API_TOKEN`.\nThe main endpoint is `question_generation`, which has following parameters,\n\n| Parameter        | Description                                                                         |\n| ---------------- | ----------------------------------------------------------------------------------- |\n| **input_text**   | input text, a paragraph or a sentence to generate question |\n| **language**     | language |\n| **qg_model**     | question generation model |\n| **answer_model** | answer extraction model |\n\nand return a list of dictionaries with `question` and `answer`. \n```shell\n{\n  \"qa\": [\n    {\"question\": \"Who founded Nintendo Karuta?\", \"answer\": \"Fusajiro Yamauchi\"},\n    {\"question\": \"When did Nintendo distribute its first video game console, the Color TV-Game?\", \"answer\": \"1977\"}\n  ]\n}\n```\n\n## Misc\nFollowing link is useful if you need to reproduce the results in our paper.\n- [Model Fine-tuning/Evaluation](https://github.com/asahi417/lm-question-generation/tree/master/misc/emnlp_2022/qg_model_training)\n- [QA based Evaluation](https://github.com/asahi417/lm-question-generation/tree/master/misc/emnlp_2022/qa_based_evaluation)\n- [NQG model baseline](https://github.com/asahi417/lm-question-generation/tree/master/misc/emnlp_2022/nqg_baseline)\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "https://github.com/asahi417/lm-question-generation/archive/v0.0.8.tar.gz",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/asahi417/lm-question-generation",
    "keywords": "language model,question-answering,question-generation",
    "license": "MIT License",
    "maintainer": "",
    "maintainer_email": "",
    "name": "lmqg",
    "package_url": "https://pypi.org/project/lmqg/",
    "platform": null,
    "project_url": "https://pypi.org/project/lmqg/",
    "project_urls": {
      "Download": "https://github.com/asahi417/lm-question-generation/archive/v0.0.8.tar.gz",
      "Homepage": "https://github.com/asahi417/lm-question-generation"
    },
    "release_url": "https://pypi.org/project/lmqg/0.0.8/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "Language Model for Question Generation.",
    "version": "0.0.8",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16789860,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c03a574bc675095f343c061ed8b781dfdebbf324cacb008d9b066fd0cf51f59f",
          "md5": "f3a31981a54b3239d49e1fdd7dd948d5",
          "sha256": "8d344f75750e853645823e120eeaa8f9dad7eefa88244e9152fc804996a9e280"
        },
        "downloads": -1,
        "filename": "lmqg-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "f3a31981a54b3239d49e1fdd7dd948d5",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 64816,
        "upload_time": "2022-10-01T16:07:12",
        "upload_time_iso_8601": "2022-10-01T16:07:12.727400Z",
        "url": "https://files.pythonhosted.org/packages/c0/3a/574bc675095f343c061ed8b781dfdebbf324cacb008d9b066fd0cf51f59f/lmqg-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "16d3863b35516febe72f7f9ef6985cf9b3a54422fc9d4ec330ff971257662354",
          "md5": "9eee2c88014a988bbfe0d5ce7ec26e7e",
          "sha256": "c7473163cb19cf6854f31a217bcaac716cb9b9c9a97c735d162642d6f07dca2c"
        },
        "downloads": -1,
        "filename": "lmqg-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "9eee2c88014a988bbfe0d5ce7ec26e7e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 60996,
        "upload_time": "2022-10-01T16:17:36",
        "upload_time_iso_8601": "2022-10-01T16:17:36.209216Z",
        "url": "https://files.pythonhosted.org/packages/16/d3/863b35516febe72f7f9ef6985cf9b3a54422fc9d4ec330ff971257662354/lmqg-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d1cd6ef090be2e17e0d390e5ea562ff52012552627325abd6371c1213c1fa7ba",
          "md5": "1aaa0edfdeffb5852aab99877f325e66",
          "sha256": "24a11d0d28b3060be8c1a207049b1d81025bbdcce71b980b340663d21db99d60"
        },
        "downloads": -1,
        "filename": "lmqg-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "1aaa0edfdeffb5852aab99877f325e66",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 65863,
        "upload_time": "2022-10-06T16:38:13",
        "upload_time_iso_8601": "2022-10-06T16:38:13.967468Z",
        "url": "https://files.pythonhosted.org/packages/d1/cd/6ef090be2e17e0d390e5ea562ff52012552627325abd6371c1213c1fa7ba/lmqg-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "95793a90226b7e3c415159f7a28d94a9b47e75569ee28efec9c912d3ea9fc42c",
          "md5": "e0caaa939c80afb66ea8d5f7d3cb6491",
          "sha256": "3ade44301515b4805cb04f90f652a89616d88e23601462a377fd06667ce35f66"
        },
        "downloads": -1,
        "filename": "lmqg-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "e0caaa939c80afb66ea8d5f7d3cb6491",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 65910,
        "upload_time": "2022-10-07T19:03:32",
        "upload_time_iso_8601": "2022-10-07T19:03:32.620926Z",
        "url": "https://files.pythonhosted.org/packages/95/79/3a90226b7e3c415159f7a28d94a9b47e75569ee28efec9c912d3ea9fc42c/lmqg-0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "76427032dba0d1fb9c25ccf3e0e3cfa241ab603f0a4129083d51b44b6883040d",
          "md5": "952949529f555847ec3f4d0da3c932a1",
          "sha256": "e3928ab80bb8269ab4ab721c70df11245c87ebf542452ce37a238a139f5bd745"
        },
        "downloads": -1,
        "filename": "lmqg-0.0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "952949529f555847ec3f4d0da3c932a1",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 67933,
        "upload_time": "2022-10-07T23:01:21",
        "upload_time_iso_8601": "2022-10-07T23:01:21.869880Z",
        "url": "https://files.pythonhosted.org/packages/76/42/7032dba0d1fb9c25ccf3e0e3cfa241ab603f0a4129083d51b44b6883040d/lmqg-0.0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1adb15ed55f3fded1a4ea8ed6e171e4ba1055f7c01aa627e194e8bbd8f09d29d",
          "md5": "d31d6c5aa6493200cd47e15765d7a90a",
          "sha256": "f21ffbb99b6019efa01f7e12d55a37d40c21bf39c700c1e26b11dc4a52bd147f"
        },
        "downloads": -1,
        "filename": "lmqg-0.0.6.tar.gz",
        "has_sig": false,
        "md5_digest": "d31d6c5aa6493200cd47e15765d7a90a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 98253,
        "upload_time": "2023-02-07T11:39:28",
        "upload_time_iso_8601": "2023-02-07T11:39:28.361162Z",
        "url": "https://files.pythonhosted.org/packages/1a/db/15ed55f3fded1a4ea8ed6e171e4ba1055f7c01aa627e194e8bbd8f09d29d/lmqg-0.0.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "be5bc14a29035fef6250e481c43bd84c6caa264750d78394467a4bdc3ef36149",
          "md5": "d7eebf91682d55eafd6bbd650726fd1b",
          "sha256": "f7f58e178b6accf58002b132277f543a81c0ad2133291f671649345d086bc7a4"
        },
        "downloads": -1,
        "filename": "lmqg-0.0.7.tar.gz",
        "has_sig": false,
        "md5_digest": "d7eebf91682d55eafd6bbd650726fd1b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 96337,
        "upload_time": "2023-02-09T18:45:50",
        "upload_time_iso_8601": "2023-02-09T18:45:50.577774Z",
        "url": "https://files.pythonhosted.org/packages/be/5b/c14a29035fef6250e481c43bd84c6caa264750d78394467a4bdc3ef36149/lmqg-0.0.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "10212cae726b519974f5dab415b3b07b45cd455648a136fef6721c3ca61a081d",
          "md5": "ff97f69646e44cb609d2d177dc3988b0",
          "sha256": "f093494f976dd2c6d2aa9a0cbd8eb74c8bec21c1b97946967303894daf1e01fe"
        },
        "downloads": -1,
        "filename": "lmqg-0.0.8.tar.gz",
        "has_sig": false,
        "md5_digest": "ff97f69646e44cb609d2d177dc3988b0",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 96390,
        "upload_time": "2023-02-10T13:54:16",
        "upload_time_iso_8601": "2023-02-10T13:54:16.750098Z",
        "url": "https://files.pythonhosted.org/packages/10/21/2cae726b519974f5dab415b3b07b45cd455648a136fef6721c3ca61a081d/lmqg-0.0.8.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "10212cae726b519974f5dab415b3b07b45cd455648a136fef6721c3ca61a081d",
        "md5": "ff97f69646e44cb609d2d177dc3988b0",
        "sha256": "f093494f976dd2c6d2aa9a0cbd8eb74c8bec21c1b97946967303894daf1e01fe"
      },
      "downloads": -1,
      "filename": "lmqg-0.0.8.tar.gz",
      "has_sig": false,
      "md5_digest": "ff97f69646e44cb609d2d177dc3988b0",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 96390,
      "upload_time": "2023-02-10T13:54:16",
      "upload_time_iso_8601": "2023-02-10T13:54:16.750098Z",
      "url": "https://files.pythonhosted.org/packages/10/21/2cae726b519974f5dab415b3b07b45cd455648a136fef6721c3ca61a081d/lmqg-0.0.8.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}