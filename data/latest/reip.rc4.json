{
  "info": {
    "author": "Yurii Piadyk, Bea Steers",
    "author_email": "ypiadyk@nyu.edu",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# REIP - data processing pipelines\n\n[![pypi](https://badge.fury.io/py/reip.svg)](https://pypi.python.org/pypi/reip/)\n[![docs](https://readthedocs.org/projects/reip-pipelines/badge/?version=latest)](http://reip-pipelines.readthedocs.io/?badge=latest)\n[![License](https://img.shields.io/pypi/l/reip.svg)](https://github.com/reip-project/reip-pipelines/blob/master/LICENSE)\n<!-- ![tests](https://github.com/beasteers/pathtrees/actions/workflows/ci.yaml/badge.svg) -->\n\n## Install\n\n```bash\npip install reip\n```\n\nMore detailed installation instructions for NVIDIA Jetson platform can be found [here](https://github.com/reip-project/reip-pipelines/blob/master/Installation.md).\n\n## Usage\n\n\n#### Chain Interface\nJavascript-esque method chaining.\n```python\nimport reip\nimport reip.blocks as B\nimport reip.blocks.audio\n\n# record audio and buffer into chunks of 10\naudio = B.audio.Mic(block_duration=1)\naudio10s = (\n    audio.to(B.Debug('Audio'))\n    .to(B.Rebuffer(duration=10)))\n# plot a spectrogram\nspec_img = (\n    audio10s.to(B.audio.Stft())\n    .to(B.Debug('Spec'))\n    .to(B.Specshow('plots/{time}.png')))\n# to wavefile\nwav = (\n    audio10s.to(B.Debug('Audio 222'))\n    .to(B.audio.AudioFile('audio/{time}.wav')))\n\nprint(reip.default_graph())\nreip.run()\n\n```\n\n#### Function Interface\nMimicking a Keras interface.\n```python\nimport reip.blocks as B\n\n# record audio and buffer into chunks of 10\naudio = B.audio.Mic(block_duration=1)\naudio10s = B.Rebuffer(duration=10)(audio)\n\n# to spectrogram\nstft = B.audio.Stft()(audio)\nspecshow = B.Specshow('plots/{time}.png')(spec)\n# to wavefile\nwav10s = B.audio.AudioFile('audio/{time}.wav')(audio10s)\n\nprint(reip.default_graph())\nreip.run()\n\n```\n\n<!-- ## Concepts\n\n### Block\nA block is an isolated piece of computation that takes a variable number of inputs and a metadata dictionary (`(*Xs, meta={})`) and returns a variable number of outputs and a metadata dictionary `([X], {})`.\n\nLike Tensorflow, there is a graph definition stage, and a graph execution stage.\n\nAll blocks exist as separate threads and pass data in between each other using queues.\n\nThese threads can either be run on the current process (the top-level default graph) or on a separate process (a Task).\n\nIf they are run in a separate process, the data is serialized using `pyarrow` and is passed to the other process using a Plasma Object Store.\n\n#### Building your own Blocks\n\n```python\n\nclass Custom(reip.Block):\n    def init(self):\n        '''Initialize the block.\n\n        __init__ is called during graph execution.\n        This function is for initialization that you\n        don't want to have to pickle to send to\n        another task.\n        '''\n\n    def process(self, *Xs, meta=None):\n        '''The main processing code that gets called with\n        every input added to the queue.\n\n        For now, it should return a tuple of a list\n        (data buffers, e.g. numpy arrays or strings)\n        and a dictionary of any metadata you might want\n        to pass to the next block.\n        '''\n        return Xs, meta\n\n    def finish(self):\n        '''Any cleanup that you want to do.'''\n\n``` -->\n\n\n<!-- ### Graph\nA collection of blocks that operate together.\n\nHere's how graph contexts work.\n\n```python\nimport reip\n\n# you always start with a default graph.\ntop_graph = reip.default_graph()\n\nprint(top_graph)\n# [~Graph (0 children) ~]\n\n# create some block, it get's automatically\n# added to the default graph.\nreip.blocks.Debug()\n\n# the block automatically shows up 'o'\nprint(top_graph)\n# [~Graph (1 children)\n#     [Block(4363961616): Debug (1 in, 1 out)]~]\n\n\n# create a nested graph and set as default within\n# the context. New blocks will be added  to this\n# graph.\nwith reip.Graph() as g:\n    reip.blocks.Csv()\n    print(g)\n    # [~Graph (1 children)\n    #     [Block(5007675152): Csv (1 in, 1 out)]~]\n\n# the graph `g` is added to the top graph. ^-^\nprint(top_graph)\n# [~Graph (2 children)\n#     [Block(4363961616): Debug (1 in, 1 out)]\n#     [~Graph (1 children)\n#         [Block(5007675152): Csv (1 in, 1 out)]~]~]\n\n\n# create a separate graph (by setting graph=False).\n# this will not be added to the top graph.\nwith reip.Graph(graph=False) as separate_graph:  \n    reip.blocks.TarGz()\n    print(separate_graph)\n    # [~Graph (1 children)\n    #     [Block(4687358032): TarGz (1 in, 1 out)]~]\n\n# pass separate_graph into a block.\nreip.blocks.Interval(graph=separate_graph)\n\n# it gets added to separate_graph, not the default.\nprint(separate_graph)\n# [~Graph (2 children)\n#     [Block(4432609104): TarGz (1 in, 1 out)]\n#     [Block(4391746128): Interval (0 in, 1 out)]~]\n\n# separate_graph is not here. x.x\nprint(top_graph)\n# [~Graph (2 children)\n#     [Block(4363961616): Debug (1 in, 1 out)]\n#     [~Graph (1 children)\n#         [Block(5007675152): Csv (1 in, 1 out)]~]~]\n```\nAnd you can modify the default without using contexts.\n```python\n# after exiting the `with` context the previous\n# default is set.\nassert reip.default_graph() is top_graph\n\n# but you can change the default like this too\nseparate_graph.as_default()\nassert reip.default_graph() is separate_graph\n\n# and reset it back.\nseparate_graph.restore_previous()\nassert reip.default_graph() is top_graph\n\n```\n\n```python\n\n\n``` -->\n\n\n<!-- ### Task\nA Task is a Graph that executes in a separate process.\n\nAll of the same principles of Graphs apply to Tasks. They can be set as the default and blocks will automatically add themselves to it.\n\n```python\nimport reip\n\ntop_graph = reip.default_graph()\n\nwith reip.Graph() as g:\n    with reip.Task() as t:\n        reip.blocks.Csv()\nprint(top_graph)\n# [~Graph (1 children)\n#     [~Graph (1 children)\n#         [~Task (1 children)\n#             [Block(4997015120): Csv (1 in, 1 out)]~]~]~]\n\n```\n\nCurrently, Tasks will add to the default graph and not other tasks. This was done because I figured nested processes would get messy, but idk. That may change once we test it. -->\n\n\n<!-- ## API - out of date, will update\n\nThe goal of the API is to provide a simple and easily understandable interface to build out ad-hoc data processing pipelines.\n\nThere are two steps to build out a pipeline:\n - graph definition\n - graph execution\n\n```python\nimport reip\nimport reip.blocks as B\n\n# graph definition\n\nclass C:\n    ml_threshold = 0.5\n    ml_classes = 'human voice', 'engine', 'dog'\n\n\n# audio source\naudio = B.audio.source(channels=1, sr=48000, chunk=4800)\n\n# audio processors\nspl = B.audio.spl(n_fft=8192, duration=1)\nml_emb = B.tflite.stft(filename='/path/to/emb_model.tf')\nml_cls = ml_emb | B.tflite(filename='/path/to/cls_model.tf')\n\nml_label = ml_cls | B.f(lambda X, meta:\n    C.ml_classes[np.argmax(X)]\n    if np.any(X > C.ml_threshold)\n    else 'unknown')\n\n# graph execution\n\nreip.run(\n    # feed audio into each processor and print results\n    audio=audio | (\n        spl | B.log(),\n        ml_emb | B.log(),\n        ml_cls | B.log(),\n        ml_label | B.log(),\n    )\n)\n```\n\n**NOTE:** I am open to looking into eager execution definitions as well (which is the current trend with things like tensorflow), but I know that tensorflow had to do some hacky things for eager execution to work properly so doing something like that will probably increase the complexity a fair amount. For the time being, anything people want to use eager execution for, they can just use the function block (`B.f(lambda: ...)`). -->\n\n\n\n\n<!-- ### Block Design\n\n\n\nMost simply, a block is a class with init code (optional), and a data transformation function.\n\nThe transformation function receives:\n - `X` which is the data output of the previous block.\n    - type should be a numpy array or an [xarray](http://xarray.pydata.org/en/stable/) - `xarray` is like a numpy array, but you can also encode column information, so you can assign labels to each numpy array column (`laeq`, `lzeq`, etc.) This will make it really easy to write to things like csv.\n - `meta`, which is the accumulated metadata (`dict`) from this run iteration.\n    ```python\n    {\n        'time': time.time(),\n        ''\n    }\n    ```\n\n```python\nimport json\nfrom reip import Block\n\nclass Inspect(Block):\n    '''A block that prints out info about the data passed to it.'''\n    def __init__(self, message=''):\n        self.message = message\n\n    def call(self, X, meta):\n        '''Apply some transformation to the data, then return it.\n\n        Arguments:\n            X (np.ndarray or xarray.xarray): the data output from\n                the previous block.\n            meta (dict): the accumulated metadata from this run\n                iteration. It should contain keys like:\n\n        Returns:\n            X: transformed input data\n            meta (dict): the accumulated metadata\n        '''\n        print(self.message, f'''\n        shape: {X.shape},      dtype: {X.dtype}\n        mean:  {X.mean():.2f}, std:   {X.std():.2f}\n        min:   {X.min():.2f},  max:   {X.max():.2f}\n        meta: {json.dumps(meta, indent=2, sort_keys=True)}\n        ''')\n        return X, meta\n\n``` -->\n\n<!-- #### Block Concepts\n\nMany pipeline implementations have concepts around block classes like:\n - Source: something that produces data (the start of a pipeline)\n - Processor: something that transforms data (the body of the pipeline)\n - Sink: something that consumes data (the end of a pipeline)\n\nBut personally, I don't think there is a meaningful distinction between a processor and a sink. Take for example, writing out data to a csv file. That would commonly be thought of as a sink, but that block doesn't have a null output. It should output a file which can then be fed into another block (convert to `.tar.gz`, upload, etc.).\n\nSo that leaves us with sources and processors. For the most part they are considered one in the same, however:\n - a processor takes in input and passes on outputs - just think of it as a function that is triggered when new input is passed.\n - a source isn't called in the same way because it doesn't have inputs - it is called once and it controls how often data is sent down the pipeline. -->\n\n<!-- \n## TODO\n\n### Larger Decisions to be Made\n - What do we use for building computational graphs?\n    - can we use existing solutions or will they add too much serialization overhead (e.g. nodered is javascript-based and expects JSON serialization which could be unnecessarily slow for numpy arrays)? We could use our own serialization\n - Does that solution manage job queues?\n    - Yurii has been talking about using distributed computations? Can we utilize existing cluster management tools to spread the load without adding too much data transmission overhead?\n\n### Block Core\n - ~~ input / output regularization/formatting\n - ~~ chaining\n - ~~ clean subclass override implementation\n - jinja formatting\n    - late formatting for values\n    - nested variable scopes\n    - take unused arguments to use as general variables\n - data buffering/chaining\n   - efficient - multiprocessing etc.\n - looping?\n - conditions?\n\n### Audio Blocks\n - ~~ Audio Source\n - ~~ Audio file writer\n - ~~ Audio tflite\n - ~~ SPL\n   - ~~ weighting\n   - ~~ octave bands\n   - what does output look like?\n\n### ML Blocks\n - ~~ Tflite\n   - data windowing\n\n### Misc\n - ~~ Interval Source\n - File/glob source\n  - one at a time\n  - sorting/sampling\n - ~~ Encryption\n - state persistent/tmp\n - CSV\n  - how to do column names\n - Tar - or even general compress/dump\n - upload\n\n### Notes\n - `~~` means in progress / partially done?\n - ~~some task~~ means completed -->\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/reip-project/reip-pipelines",
    "keywords": "iot embedded app pipeline block multiprocessing",
    "license": "BSD 3-Clause Clear License",
    "maintainer": "",
    "maintainer_email": "",
    "name": "reip",
    "package_url": "https://pypi.org/project/reip/",
    "platform": null,
    "project_url": "https://pypi.org/project/reip/",
    "project_urls": {
      "Homepage": "https://github.com/reip-project/reip-pipelines"
    },
    "release_url": "https://pypi.org/project/reip/0.0.4/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "",
    "version": "0.0.4",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 13506333,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9f748dcf7d9a90f2c0f561e60ba4dea55add0477b31667c6f6a19375e3c5e10d",
          "md5": "1d993561798c627c41f06c4008f75cd5",
          "sha256": "a66b56c1633dd251429aab9eff99d5a4061d020afc86f0271e4ba4136af66b32"
        },
        "downloads": -1,
        "filename": "reip-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "1d993561798c627c41f06c4008f75cd5",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 86435,
        "upload_time": "2022-04-11T18:51:43",
        "upload_time_iso_8601": "2022-04-11T18:51:43.323976Z",
        "url": "https://files.pythonhosted.org/packages/9f/74/8dcf7d9a90f2c0f561e60ba4dea55add0477b31667c6f6a19375e3c5e10d/reip-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bff71fb3c99e74f7017dee71f7f92227c1352f7b5847acc687ec9bad6a35a3a8",
          "md5": "8cece984c9a28de0048a004e177652d5",
          "sha256": "70a5498d195ce06503054af929e64de32f24b2e280a6c887ea8da351f4cbc8ec"
        },
        "downloads": -1,
        "filename": "reip-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "8cece984c9a28de0048a004e177652d5",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 86429,
        "upload_time": "2022-04-11T18:52:59",
        "upload_time_iso_8601": "2022-04-11T18:52:59.757107Z",
        "url": "https://files.pythonhosted.org/packages/bf/f7/1fb3c99e74f7017dee71f7f92227c1352f7b5847acc687ec9bad6a35a3a8/reip-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8d588e1dd5897e0159baf0c060dcebbba749c3aef96eed3382792c8cba355bf3",
          "md5": "4ea15a6ba814c2ef7ed0560ac79238d7",
          "sha256": "c2cd6dd243f7eafb54042d6f1acc9b70775147334a2a79963abeceae8fdf498f"
        },
        "downloads": -1,
        "filename": "reip-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "4ea15a6ba814c2ef7ed0560ac79238d7",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 86424,
        "upload_time": "2022-04-11T18:54:32",
        "upload_time_iso_8601": "2022-04-11T18:54:32.105055Z",
        "url": "https://files.pythonhosted.org/packages/8d/58/8e1dd5897e0159baf0c060dcebbba749c3aef96eed3382792c8cba355bf3/reip-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4963a3d5a9a45a5dcf66bf2764716bf419c6030245a6c97b57b33b0e3ed262e8",
          "md5": "23c15e6602cf420a7712eb3ff43e26d0",
          "sha256": "719504e11745d58a648620a8c356961afe2b71313bfa8b2a6653f74af725ed89"
        },
        "downloads": -1,
        "filename": "reip-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "23c15e6602cf420a7712eb3ff43e26d0",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 85965,
        "upload_time": "2022-04-13T20:08:11",
        "upload_time_iso_8601": "2022-04-13T20:08:11.546530Z",
        "url": "https://files.pythonhosted.org/packages/49/63/a3d5a9a45a5dcf66bf2764716bf419c6030245a6c97b57b33b0e3ed262e8/reip-0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "4963a3d5a9a45a5dcf66bf2764716bf419c6030245a6c97b57b33b0e3ed262e8",
        "md5": "23c15e6602cf420a7712eb3ff43e26d0",
        "sha256": "719504e11745d58a648620a8c356961afe2b71313bfa8b2a6653f74af725ed89"
      },
      "downloads": -1,
      "filename": "reip-0.0.4.tar.gz",
      "has_sig": false,
      "md5_digest": "23c15e6602cf420a7712eb3ff43e26d0",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 85965,
      "upload_time": "2022-04-13T20:08:11",
      "upload_time_iso_8601": "2022-04-13T20:08:11.546530Z",
      "url": "https://files.pythonhosted.org/packages/49/63/a3d5a9a45a5dcf66bf2764716bf419c6030245a6c97b57b33b0e3ed262e8/reip-0.0.4.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}