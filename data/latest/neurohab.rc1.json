{
  "info": {
    "author": "Federico Calesella",
    "author_email": "f.calesella@gmail.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# NeuroHab\n Voxelwise brain habituation\n\n## Table of Contents\n1. [Project Overview](#Project_Overview)\n2. [Installation and Data Requirements](#Installation)\n3. [Usage](#Usage)\n   1. [Initialize the ```BrainHabituation``` Class](#Initialize)\n   2. [Find the Needed Files](#Find_files)\n   3. [Estimate Habituation](#Habituation)\n   4. [Save the Results](#Save)\n5. [Example](#Example)\n6. [Notes: Shape and Affine Matrix](#Notes)\n7. [References](#References)\n\n## 1. Project Overview <a name=\"Project_Overview\"></a>\nThe code was conceived to perform voxelwise habituation analysis on functional magnetic resonance imaging (fMRI) data. \\\nTwo measures of habituation were implemented, based on Plichta et al. (2014):\n- First-minus-Last (FmL)\n- Regression (REG)\n\nThe code was made applicable both on blood oxygenation level dependent (BOLD) signal maps and on seed based funcitonal connectivity (FC) maps, as returned by the SPM and CONN toolboxes, respectively. However, it can be used to extract habituation parameters from every kind of NIfTI images. \\\nFurthermore, it handles both block designs with one or multiple conditions and designs with no blocks nor conditions (e.g., resting state).\\\nFinally, it supports both the presence and absence of multiple seeds.\n\n## 2. Installation and Data Requirements <a name=\"Installation\"></a>\nThe installation via pip is supported:\n```\npip install neurohab\n```\n\nThe code assumes the data to be NIfTI images, starting with the string \"BETA\" and organized in:\n- subjects, defined as \"Subject01\"\n- blocks/scans, defined as \"Condition01\"\n- seeds/regions of interest (ROIs), defined as \"Source01\"\n\nAs a consequence an exemplary file name might be \"BETA_Subject01_Condition01_Source01\" for subject one, block/scan one and seed/ROI one. If no condition and/or no source are included in the experimental design, they will just be constant (\"Condition01_Source01\") across subjects. Please note that the number of digits indicating the subjects, conditions, and ROIs must be set according to the global maximum value across the three fields. For instance, if the sample is composed by 50 subjects with no blocks and seeds, then the file names will be \"BETA_Subject01_Condition01_Source01\" ... \"BETA_Subject50_Condition01_Source01\". However, if 100 seeds were present, then the file names will be \"BETA_Subject001_Condition001_Source001\" ... \"BETA_Subject050_Condition001_Source100\".\n\n## 3. Usage <a name=\"Usage\"></a>\n\n### i. Initialize the ```BrainHabituation``` class <a name=\"Initialize\"></a>\nThe ```BrainHabituation``` class requires 3 mandatory and 1 optional parameters to be set as input:\n```python \nBrainHabituation(subjects, conditions, rois, tens=None)\n``` \n*Parameters*:\n- **subjects**: a list containing the numbers of the subjects that will be analyzed \n- **conditions**: a list containing the condition to which each block/scan belongs\n- **rois**: a list containing the number of the seed/ROI to be included\n- **tens** (optional): the number of digits that make up the subject, condition, and source numbers (e.g., if there are 100 subjects, then the subjects' names will be \"BETA_Subject001_Condition001_Source001\", and so tens=3). If no value is provided, tens will be based on the maximum number of digits across the subject numbers, the number of blocks/scans, and the seed/ROI numbers.\n\n### ii. Find the Needed Files <a name=\"Find_files\"></a>\nThe ```find_files``` method allows to create a nested list containing the full path of all the needed NIfTI images. The files are still not loaded for memory saving.\n```python \nfind_files(path)\n``` \n*Parameters*:\n- **path**: a string indicating the full path to the directory which contains the input files.\n\n*Outputs*:\n- **condition_list**: a nested list containing the path of the files on which the analyses will be performed. The list is nested in the following order: conditions, ROIs, and subjects.\n\n### iii. Estimate Habituation <a name=\"Habituation\"></a>\nTwo methods can be used to estimate the voxelwise habituation parameters: ```reg``` and ```fml```.\\\nThe ```reg``` method computes voxelwise habituation using the REG method (i.e., based on regression across blocks/scans).\n```python \nreg(images, nan=False)\n``` \n*Parameters*:\n- **images**: a nested list with the full path of the files that must be loaded, organized following the conditions, ROIs and subjects order.\n- **nan** (optional): boolean defining if NaN values should be replaced with zeros. NaN values happen to be produced when regression of 0 on 0 is computed (in brain images this will be the case for the background).\n\n*Outputs*:\n- **condition_list**: a nested list of numpy.arrays, which will contain the habituation maps for each subject. The list will be organized following the order of the input list (conditions, ROIs, and subjects).\n\nThe ```fml``` method computes voxelwise habituation using the FmL method.\n```python \nfml(images)\n``` \n*Parameters*:\n- **images**: a nested list with the full path of the files that must be loaded, organized following the conditions, ROIs and subjects order.\n\n*Outputs*:\n- **condition_list**: a nested list of numpy.arrays, which will contain the habituation maps for each subject. The list will be organized following the order of the input list (conditions, ROIs, and subjects).\n\n### iv. Save the Results <a name=\"Save\"></a>\nThe habituation maps can be saved in a specified directory using the ```save_images``` method. The output files will start with the \"HAB_\" prefix.\n```python \nsave_images(path, images, shape, affine)\n``` \n*Parameters*:\n- **path**: full path of the directory where to save the files\n- **images**: a nested list of numpy.arrays, containing the habituation maps for each subject. The list must be nested following the order: conditions, ROIs, and subjects.\n- **shape**: the shape of the original images (i.e., the dimension of the arrays of the images - see Section 5). It is assumed that all the images have the same shape. \n- **affine**: the affine matrix (see Section 5) of the original images. It is assumed that all the images have the same affine matrix.\n\n## 4. Example <a name=\"Example\"></a>\nAn example on how to run the code and estimate the habituation parameters is provided in the ```example.py``` file (it can also be used as a run-file). In this file, the following edits are required:\n- line 15: define the full path of the directory where the input files are stored\n- line 17: define the directory where the habituation maps will be saved\n- lines 19-25: the first and last subject\n- line 28: the eventual condition of each block/scan (if no condition exists, create a list of ones with the same length of the blocks/scans number)\n- line 30: the eventual seeds (if no seed exists, the list will contain only a number, matching the \"Source\" field in the file names)\n- line 33: the tens parameter\n- line 35: the shape of the images (see Section 5)\n- line 37: the affine matrix of the images (see Section 5)\n\nIn this case, 106 subjects performed a face-matching task, with shape-matching as a control condition. After preprocessing, each subject resulted with voxelwise BOLD maps in 4 face-matching blocks and 5 shape-matching blocks (i.e., each subject had 9 BOLD maps devided in 2 conditions). Seed based connectivity was also performed with two seeds. Consequently, at lines 19-25 106 subjects were set, at line 28 the conditions were specified for each block (i.e., shape=2; face=1), at line 30 ROIs were defined (only when connectivity maps were used, otherwise only a 1 was inserted), and at line 33 the tens parameter was also defined (even though its specification is optional). Here tens is 3 because we had 9 blocks, 2 rois, and 106 subjects, so the maximum number is 106, which is composed by 3 digits. The shape and the affine matrix were also defined.\n\n## 5. Notes: shape and affine matrix <a name=\"Notes\"></a>\nIn order to assess the shape of the array containing the images and the affine matrx, the NiBabel package can be used. Please refer to the [NiBabel page](https://nipy.org/nibabel/) and its [Getting Started page](https://nipy.org/nibabel/gettingstarted.html). Here an example is provided to assess these parameters with NiBabel. To import the package and load an image, just edit the input string at the second line with a valid full path to a NIfTI image.\n```python \nimport nibabel as nib\nimg = nib.load('example_filename')\n\nprint('Image shape:\\n', img.shape)\nprint('Image affine matrix:\\n', img.affine)\n```\nThe same commands can be run with multpile images in order to assess if the shape and affine matrix are the same across the images.\n\n## References <a name=\"References\"></a>\nPlichta, M. M., Grimm, O., Morgen, K., Mier, D., Sauer, C., Haddad, L., ... & Meyer-Lindenberg, A. (2014). Amygdala habituation: a reliable fMRI phenotype. NeuroImage, 103, 383-390.\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/fcalesella/neurohab",
    "keywords": "",
    "license": "GNU General Public License v3.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "neurohab",
    "package_url": "https://pypi.org/project/neurohab/",
    "platform": "",
    "project_url": "https://pypi.org/project/neurohab/",
    "project_urls": {
      "Homepage": "https://github.com/fcalesella/neurohab"
    },
    "release_url": "https://pypi.org/project/neurohab/0.0.1/",
    "requires_dist": [
      "numpy",
      "nibabel",
      "scipy"
    ],
    "requires_python": "",
    "summary": "Voxelwise brain habituation",
    "version": "0.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 11041090,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a15546af7ea7ea650646ec2f1c289c47a352c188c89fbb8c7075d9790b9ae844",
          "md5": "22f97063dee8a7fb9b973e3447cd7259",
          "sha256": "272f7907f366c938b5986a90c09f00713712fc51772b8db9323619b13fd8ec23"
        },
        "downloads": -1,
        "filename": "neurohab-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "22f97063dee8a7fb9b973e3447cd7259",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 19522,
        "upload_time": "2021-07-29T16:12:13",
        "upload_time_iso_8601": "2021-07-29T16:12:13.878899Z",
        "url": "https://files.pythonhosted.org/packages/a1/55/46af7ea7ea650646ec2f1c289c47a352c188c89fbb8c7075d9790b9ae844/neurohab-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7ecd7982947f3109afc02c2a4d022fbf1f5c897d705683692f2dca7b37bc358b",
          "md5": "1716a41882d589e03a26a3229fa45540",
          "sha256": "15eacba5d8b6fcf953394d81a510dd5d27ed586d47985b66b949ff4724ee1d65"
        },
        "downloads": -1,
        "filename": "neurohab-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "1716a41882d589e03a26a3229fa45540",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 7111,
        "upload_time": "2021-07-29T16:12:15",
        "upload_time_iso_8601": "2021-07-29T16:12:15.478244Z",
        "url": "https://files.pythonhosted.org/packages/7e/cd/7982947f3109afc02c2a4d022fbf1f5c897d705683692f2dca7b37bc358b/neurohab-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "a15546af7ea7ea650646ec2f1c289c47a352c188c89fbb8c7075d9790b9ae844",
        "md5": "22f97063dee8a7fb9b973e3447cd7259",
        "sha256": "272f7907f366c938b5986a90c09f00713712fc51772b8db9323619b13fd8ec23"
      },
      "downloads": -1,
      "filename": "neurohab-0.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "22f97063dee8a7fb9b973e3447cd7259",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 19522,
      "upload_time": "2021-07-29T16:12:13",
      "upload_time_iso_8601": "2021-07-29T16:12:13.878899Z",
      "url": "https://files.pythonhosted.org/packages/a1/55/46af7ea7ea650646ec2f1c289c47a352c188c89fbb8c7075d9790b9ae844/neurohab-0.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "7ecd7982947f3109afc02c2a4d022fbf1f5c897d705683692f2dca7b37bc358b",
        "md5": "1716a41882d589e03a26a3229fa45540",
        "sha256": "15eacba5d8b6fcf953394d81a510dd5d27ed586d47985b66b949ff4724ee1d65"
      },
      "downloads": -1,
      "filename": "neurohab-0.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "1716a41882d589e03a26a3229fa45540",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 7111,
      "upload_time": "2021-07-29T16:12:15",
      "upload_time_iso_8601": "2021-07-29T16:12:15.478244Z",
      "url": "https://files.pythonhosted.org/packages/7e/cd/7982947f3109afc02c2a4d022fbf1f5c897d705683692f2dca7b37bc358b/neurohab-0.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}