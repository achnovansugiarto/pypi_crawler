{
  "info": {
    "author": "Yuchen Eleanor Jiang",
    "author_email": "eleanorjiang630@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3",
      "Topic :: Scientific/Engineering :: Artificial Intelligence"
    ],
    "description": "# [BlonDe and BWB](https://arxiv.org/abs/2103.11878)\n[![Python version](https://img.shields.io/pypi/pyversions/blonde)](https://img.shields.io/pypi/pyversions/blonde)\n[![arxiv](https://img.shields.io/badge/arXiv-2103.11878-b31b1b)](https://arxiv.org/abs/2103.11878)\n[![PyPI version](https://img.shields.io/pypi/v/blonde)](https://img.shields.io/pypi/v/blonde)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT) \n\nBlonDe and BWB are developed for document-level machine translation.\nBlonDe is an automatic evaluation metric that explicitly tracks discourse phenomena.\nBWB is a large-scale bilingual parallel corpus that consists of web novels.\n\nWe hope that they will serve as a guide and inspiration for more work in the area of document level machine translation.\n\n\n## Quick Links\n- ğŸ“ [BlonDe](#-the-blonde-package)\n    - An Automatic Evaluation Metric for Document-Level Machine Translation.\n    - [Package Overview](#package-overview)\n    - [Installation](#-installation)\n    - [Usage](#usage)\n\n\n- ğŸ“™ [BWB: Bilingual Web Book Dataset](#-the-bwb-dataset)\n  - A Large-Scale Bilingual Parallel Corpus for Document-Level Machine Translation.\n  - [Dataset Overview](#dataset-overview)\n  - [Annotation Format](#annotation-format)\n  - [Download](#download)\n  \n#### News:\n<!-- - Features to appear in the next version (currently in the master branch): -->\n- June 2022: Released the BWB dataset.\n- May 2022: Released the BlonDe package.\n- May 2022: Accepted to NAACL2022 ğŸ‰\n\nPlease see [release logs](https://github.com/EleanorJiang/CHANGELOG.md) for older updates.\n\n**If you use the BlonDe package or the BWB dataset for your research, please cite:**\n```bibtex\n@article{jiang-etal-2022-blonde,\n      title={{BlonDe}: An Automatic Evaluation Metric for Document-level Machine Translation}, \n      author={Yuchen Eleanor Jiang and Tianyu Liu and Shuming Ma and Dongdong Zhang and Jian Yang and Haoyang Huang and Rico Sennrich and Ryan Cotterell and Mrinmaya Sachan and Ming Zhou},\n      year={2022},\n      eprint={2103.11878},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}\n```\n\n\n## ğŸ“ The BlonDe Package:\n\n### Package Overview\n\n<img align=\"right\" width=\"300\" src=\"image/blonde_motivation.png\">\n\nStandard automatic metrics, e.g. BLEU, are not reliable for document-level MT evaluation. They can neither distinguish document-level improvements in translation quality from sentence-level ones, nor identify the discourse phenomena that cause context-agnostic translations.\n\nBlonDe is proposed to widen the scope of automatic MT evaluation from sentence to the document level. It takes discourse coherence into consideration by categorizing discourse-related spans and calculating the similarity-based F1 measure of categorized spans. \n\nAs shown in the figure, BlonDe is a lot more selective than BLEU for document-level MT \nand shows a larger quality difference between human and machine translations.\n\nIn the BlonDe package, there are:\n- ``BlonDe``: the main metric, combining ``dBlonDe`` with sentence-level measurement\n- ``dBlonDe``: measures the discourse phonomena (``entity``, ``tense``, ``pronoun``, ``discourse markers``)\n- ``BlonDe+``: takes human annotation (annotated ambiguous/ommitted phrases and manually-annotated NER) into consideration\n\n\n### â³ Installation\n**Python>=3.6 only**\n\nBefore you install ``blonde``, make sure that\nyour `pip`, `setuptools`ï¼Œ`wheel` and `spacy` are up to date, and ``en_core_web_sm`` is downloaded.\n```sh\npip install -U pip setuptools wheel\npip install -U spacy\npython -m spacy download en_core_web_sm\n```\n\nInstall the official Python module from PyPI:\n```sh\npip install blonde\n```\nInstall the latest unstable version from the master branch on Github:\n```\npip install git+https://github.com/EleanorJiang/BlonDe\n```\n\nInstall from the source:\n```sh\ngit clone https://github.com/EleanorJiang/BlonDe\ncd BlonDe\npip install .\n```\nand you may test your installation by:\n```\npython -m unittest discover\n```\n\n### Usage\nWe provide a command line interface (CLI) of BlonDe as well as a python \nmodule. \nWe provide example inputs under `./example`.\n\n### Command-line Usage\nYou can use it as follows for the simplest usage:\n```sh\nblonde -r example/ref.txt -s sys.txt\n```\n\nTo use human-annotated spans for `BlonDe+`, \nadd `-p` and provide the annotation file path with `-an`, as in:\n```sh\nblonde -r example/ref.txt -s sys.txt -p -an example/an.txt\n```\n\nTo use human-annotated named entities (instead of automatic detected ones), \nadd `-p` and provide the named entity file path with `-ner`, as in:\n```sh\nblonde -r example/ref.txt -s sys.txt -p -ner example/ner.txt\n```\n#### The full list of named arguments:\nGeneral arguments:\n```\n  -h, --help            show this help message and exit\n  -r REFERENCE [REFERENCE ...], --reference REFERENCE [REFERENCE ...]\n                        reference file path(s), each line is a sentence\n  -s SYSTEM, --system SYSTEM\n                        system file path, each line is a sentence\n  --version, -V         show program's version number and exit\n```\nBlonDe-related arguments:\n```\n  --categories CATEGORIES [CATEGORIES ...], -c CATEGORIES [CATEGORIES ...]\n                        The categories of BLONDE. \n                        Default: ('tense', 'pronoun', 'entity', 'dm', 'n-gram')\n  --average-method {geometric,arithmetic}, -aver {geometric,arithmetic}\n                        The average method to use, geometric or arithmetic.\n                        Defaults: geometric\n  --smooth-method {none,floor,add-k,exp}, -sm {none,floor,add-k,exp}\n                        Smoothing method: exponential decay, floor (increment zero counts), add-k (increment num/denom by k for n>1), or none.\n                        Default: exp\n  --smooth-value SMOOTH_VALUE, -sv SMOOTH_VALUE\n                        The smoothing value. Only valid for floor and add-k. \n                        Defaults: floor: 0.1, add-k: 1\n  --lowercase LOWERCASE, -lc LOWERCASE\n                        If True, enables case-insensitivity. Default: True\n```\nWeight-related arguments:\n```\n  --override-weights, -w\n                        Whether to customize the weights of BLONDE\n  --reweight, -rw       Whether to reweight the weights of BLONDE to 1\n  --weight-tense WEIGHT_TENSE [WEIGHT_TENSE ...], -wt WEIGHT_TENSE [WEIGHT_TENSE ...]\n                        The weights of TENSE (verb types), should be a tuple of length 7, corresponds to ('VBD', 'VBN', 'VBP',\n                        'VBZ', 'VBG', 'VB', 'MD'). Defaults: (1/7, 1/7, 1/7, 1/7, 1/7, 1/7, 1/7). Only valid when `override_weights`\n                        is used\n  --weight-pronoun WEIGHT_PRONOUN [WEIGHT_PRONOUN ...], -wp WEIGHT_PRONOUN [WEIGHT_PRONOUN ...]\n                        The weights of PRONOUN, should be a tuple of length 4, corresponds to ('masculine', 'feminine', 'neuter',\n                        'epicene'). Defaults: (0.5, 0.5, 0, 0). Only valid when `override_weights` is used\n  --weight-entity WEIGHT_ENTITY [WEIGHT_ENTITY ...], -we WEIGHT_ENTITY [WEIGHT_ENTITY ...]\n                        The weights of PERSON and NONPERSON entities, Defaults: (1/2, 1/2). Only valid when `override_weights` is\n                        used\n  --weight-discourse-marker WEIGHT_DISCOURSE_MARKER [WEIGHT_DISCOURSE_MARKER ...], -wdm WEIGHT_DISCOURSE_MARKER [WEIGHT_DISCOURSE_MARKER ...]\n                        The weights of DISCOURSE MARKER, should be a tuple of length 5, corresponds to ('comparison', 'cause',\n                        'conjunction', 'asynchronous', 'synchronous'). Defaults: (0.5, 0.5, 0, 0). Only valid when\n                        `override_weights` is used\n```\nBlonDe+ related arguments, annotation required:\n```\n  --plus, -p            Whether to add BLONDE PLUS categories. If so, please provide annotation files that are in the required\n                        format.\n  --annotation ANNOTATION, -an ANNOTATION\n                        Annotation file path, each line is the annotation corresponding a sentence. See README for annotation format\n  --ner-refined NER_REFINED, -ner NER_REFINED\n                        Named entity file path, each line is the named entities corresponding a sentence. If provided, the annotated\n                        named entities instead of the automated recognized ones are used in BLONDE. See README for named entity\n                        annotation format\n  --plus-categories PLUS_CATEGORIES [PLUS_CATEGORIES ...], -pc PLUS_CATEGORIES [PLUS_CATEGORIES ...]\n                        The categories that your annotation files contain, Defaults: ('ambiguity', 'ellipsis'). Only valid when\n                        `plus` is used\n  --plus-weights PLUS_WEIGHTS [PLUS_WEIGHTS ...], -pw PLUS_WEIGHTS [PLUS_WEIGHTS ...]\n                        The corresponding weights of plus categories, should be in the same length as `plus_categories`. Defaults:\n                        (1, 1). Only valid when `plus` is used\n```\n\n\n### Using BlonDe from Python\nFollowing [SacreBLEU](https://github.com/mjpost/sacrebleu), we also recommend users to use the object-oriented API, by creating an instance of the `BLONDE` class.\nA detailed example is provided in ``example.py``.\n\n#### Loading Package and creating an ``BLONDE`` object:\n ```python\nfrom blonde import BLONDE\nblonde = BLONDE()\n```\n#### For a single document:\n ```python\nscore = blonde.corpus_score([sys_doc], [[ref_doc_1], [ref_doc_2], ...])\n   ```\nwhere  ``sys_doc``, ``ref_doc_1`` and ``ref_doc_2`` are  ``List[str]``.\n\n#### For a corpus:\n```python\nscore = blonde.corpus_score(sys_corpus, [ref_corpus_1, ref_corpus_2, ...])\n```\nwhere ``sys_corpus``, ``ref_corpus_1`` and ``ref_corpus_2`` are ``List[List[str]]``.\n\n#### For multiple systems & statistical testing:\n ```python\nblonde = BLONDE(references=[ref_corpus]) # for faster recomputation\nscore = blonde.corpus_score(sys_corpus)\n```\n\n#### BlonDe+:\n ```python\nblonde_plus = BLONDE(references=[ref_corpus],\n                     annotation=an_corpus,\n                     ner_refined=ner_corpus\n                 )\nscore = blonde_plus.corpus_score(sys_corpus)\n  ```\n\n#### Adjust parameters:\n ```python\nBLONDE(weights: Weight=WEIGHTS_DEFAULTS,\n       weight_normalize: bool = False,\n       average_method: str = 'geometric',\n       categories: dict = CATEGORIES,\n       plus_categories=None,  # (\"ambiguity\", \"ellipsis\")\n       plus_weights=(1, 1),\n       lowercase: bool = False,\n       smooth_method: str = 'exp',\n       smooth_value: Optional[float] = None,\n       effective_order: bool = False,\n       references: Optional[Sequence[Sequence[Sequence[str]]]] = None,\n       annotation: Sequence[Sequence[str]] = None,\n       ner_refined: Sequence[Sequence[str]] = None)\n```\n| Parameter | Description !\n|-----------|-------------|\n| categories | A dict where the keys are chosen from `('tense', 'pronoun', 'entity', 'n-gram')`, and the keys are the names of features in different categories, Dict[str, Sequence[str]]. If `None`, `('tense', 'pronoun', 'entity', 'n-gram')` are included.\n| weights | The weights of the aerformentioned features, Dict[str, Sequence[float]]. If `None`, uniform weights are adopted. \n| plus_categories | The human annotated categories, e.g. `('ambiguity', 'ellipsis')` (default: None)\n| plus_weights | The weights of the human annotated categories (default: `None`)\n| weight_normalize | Whether to reweight to 1 (default: `False`)\n| lowercase | If `True`, lowercased BLONDE is computed.\n| average_method| The average method to use. Choose from `('geometric', 'arithmetic')`.\n| smooth_method| The smoothing method to use. Choose from `('floor', 'add-k', 'exp' or 'none')`.\n| smooth_value | The smoothing value for `floor` and `add-k` methods. `None` falls back to default value.\n| max_ngram_order| If given, it overrides the maximum n-gram order (default: `4`).\n| effective_order| If `True`, stop including n-gram orders for which score is 0. This should be `True`, if sentence-level BLONDE will be computed.\n| references| A sequence of reference documents with document being defined as a sequence of reference strings. If given, the reference n-grams and lengths will be pre-computed and cached for faster BLONDE computation across many systems.\n\n[comment]: <> (#### Cohesion Score &#40;beta&#41;:)\n\n[comment]: <> ( ```)\n\n[comment]: <> (    cohesion_score = cohesion&#40;sys_doc,word_frequency_file, weight_for_oov=300000, exclu_stop=True, norm=True&#41;)\n\n[comment]: <> ( ```)\n\n[comment]: <> (- ``word_frequency_file``: a ``json`` file containing word frequency table.)\n\n[comment]: <> (- ``weight_for_oov``: the unormalized weight for out of vocabulary.)\n\n[comment]: <> (- ``exclu_stop``: ``True`` when the stop words is excluded.)\n\n[comment]: <> (- ``norm``: ``True`` when normalization is conducted.)\n\n\n\n[comment]: <> (- ``nltk.stopwords``, ``nltk.wordnet``: for cohesion score &#40;beta&#41;)\n\n[comment]: <> (  ```)\n\n[comment]: <> (    pip install nltk)\n\n[comment]: <> (  ```)\n\n[comment]: <> (  then run the Python interpreter:)\n\n[comment]: <> (  ```)\n\n[comment]: <> (    import nltk)\n\n[comment]: <> (    nltk.download&#40;&#41;)\n\n[comment]: <> (  ```)\n\n[comment]: <> (  In the NLTK Downloader window, choose ``wordnet``.)\n\n## ğŸ“™ The BWB Dataset:\n\n### Dataset Overview\n![<img align=\"right\" width=\"400\">](image/bwb_dataset_stats.jpg)\nThe BWB dataset is a large-scale document-level Chinese--English parallel dataset.\nIt consists of Chinese online novels across multiple genres (sci-fi, romance, action, fantasy, comedy, etc.) \nand their corresponding English translations crawled from the Internet.\nThe novels are translated by professional native English speakers, and are corrected by editors.\n\nTo the best of our knowledge, this is the largest document-level translation dataset to date. \n\n#### The Statistics of BWB:\n\n|      |   Train   |  Test  |  Dev  |  Total  |\n|-----------|-------------|-----------|-----------|-----------|\n| #Docs     | 196,304        | 80      | 79      | 196K   |\n| #Sents       | 9,576,566    | 2,632     | 2,618      | 9.58M     |\n| #Words      | 325.4M        | 68.0K      | 67.4K     | 460.8M      |\n\n\n[comment]: <> (### Comparison with other datasets)\n\n[comment]: <> (|   Dataset   |   Domain   | Language |  #Docs  |  #Sents  )\n\n[comment]: <> (|-----------|-------------|-----------|-----------|-----------|)\n\n[comment]: <> (| BWB     | Novels        | ZH-EN      | 196.3K      | 9.58M  |)\n\n[comment]: <> (| WMT News    | News    | DE-EN     | 68.4k      | 3.63M     |)\n\n[comment]: <> (| [OpenSubtitles]&#40;https://opus.nlpl.eu/OpenSubtitles-v2018.php&#41;      | Subtitles        | 29.1k     | 67.4K     | 460.8M      |)\n\n**Note:**\n\n- Each **document** is a chapter. \n- The source document and the target document are aligned at the **sentence**-level.\n- To prevent any train-test leakage, we split the dataset into a training, development and a test set such that chapters from the same book are part of the same split. \n\n\n### Annotation Format\nThe test set of BWB is annotated.\nFor each document, there are:\n- ``chs_re.txt``: the original Chinese document. Each line is a sentence.\n- ``ref_re.txt``: the reference English document. Each line is a sentence.\n- ``ner_re.txt``: the named entities that appear in each sentence and their counts in the sentence.\n- ``an.txt``: the error type, along with the spans that may cause ``ambiguity`` or ``ellipsis``.\n\n**Error Types:**\n\n|  Error Type    |   #id   |  Description  |  With Span Annotation  |  \n|-----------|-------------|-----------|-----------|\n| ``ambiguity``     | 1       | There is(are) some ambiguous term(s) that is(are) correct in the stand-alone sentence but wrong in context.       |:heavy_check_mark:      |\n| ``ellipsis-pronoun``     | 2    | There is(are) error(s) caused by the omission of pronouns.     | :heavy_check_mark:       | \n| ``ellipsis-other``     | 3       | There is(are) error(s) caused by the omission of other phrases.      | :heavy_check_mark:     | \n| ``named entity``      | 4       | There is(are) error(s) due to the mistranslation of named entities.    |    | \n| ``tense``      | 5       | There is(are) error(s) due to tense.     |    | \n| ``sentence-level``| 6 | There is(are) sentence-level error(s). |    | \n\n\nFor better reproducing our results, we also provide:\n- ``mt_re.txt``: the MT output we use in discourse error analysis. Each line is a sentence.\n- ``pe_re.txt``: the human post-editing on provided the MT output by professional translators. \n\n### Example\n``chs_re.txt``:\n```\nä¹”æ‹æ”¥ç´§äº†æ‹³å¤´ï¼Œå‚ä¸‹äº†å¤´ã€‚\nå…¶å®ä»–è¯´å¾—å¯¹ã€‚\nè‡ªå·±å°±æ˜¯ä¸€ä¸ªè ¢è´§ï¼Œç«Ÿç„¶ä¼šç›¸ä¿¡äº†ç½‘ç»œä¸Šçš„çˆ±æƒ…ã€‚\nå¥¹å‹¾èµ·äº†å˜´å”‡ï¼Œæ·±å‘¼å¸ä¸€ä¸‹ï¼Œæ­£æ‰“ç®—å°†æ‰‹æœºæ”¾ä¸‹ï¼Œå¾®ä¿¡ä¸Šå´è¢«ç‚¸å¼€äº†é”…ã€‚\nå¥¹ç‚¹è¿›å»ï¼Œå‘ç°æ˜¯å‡‰ç²‰ç¾¤ï¼Œæ‰€æœ‰äººéƒ½åœ¨@å¥¹ã€‚\nã€ä¹”æ‹ï¼šæ€ä¹ˆäº†ï¼Ÿ\nã€å·æµä¸æ¯ï¼šä¹”æ‹ï¼Œå¿«çœ‹å¾®åšå¤´æ¡ï¼ å¾®åšå¤´æ¡ï¼Ÿ\nå¥¹å¾®å¾®ä¸€æ„£ï¼Œæ‹¿èµ·æ‰‹æœºï¼Œç™»é™†å¾®åšï¼Œåœ¨çœ‹åˆ°å¤´æ¡çš„æ—¶å€™ï¼Œæ•´ä¸ªäººä¸€ä¸‹å­æ„£ä½äº†ï¼\nå‰§ç»„å‘å¸ƒä¼šã€‚ æ²ˆå‡‰å·åº”é‚€å‡ºåœºï¼Œå¯¼æ¼”ç«‹é©¬æ­æ•¬åœ°è¿æ¥è¿‡æ¥ï¼Œå®¢æ°”çš„è·Ÿä»–è¯´è¿™è¯ï¼Œè¡¨è¾¾ç€è‡ªå·±å¯¹ä»–èƒ½å¤Ÿåˆ°æ¥çš„è°¢æ„ã€‚\næ²ˆå‡‰å·æ²¡æœ‰è¯´è¯ï¼Œçœ‹å‘ä¸è¿œå¤„çš„ç‹æ–‡è±ªã€‚\nç‹æ–‡è±ªå‡ºäº‹ä»¥åï¼Œæ‰€æœ‰çš„ä½œå“å…¨éƒ¨ä¸‹æ¶ï¼Œè€Œè¿™ä¸€éƒ¨å‰§è¿˜èƒ½æ’­å‡ºï¼Œæ˜¯å› ä¸ºç‹æ–‡è±ªåœ¨é‡Œé¢å‹æƒ…é¥°æ¼”çš„ç”·ä¸‰å·æˆä»½å¾ˆå°‘ï¼Œå‡ ä¹å¯ä»¥å¿½ç•¥ä¸è®¡ã€‚\nå‰§ç»„æ ¹æœ¬å°±æ²¡æœ‰é‚€è¯·ç‹æ–‡è±ªï¼Œå¯ä»–å´ä¸çŸ¥é“ä»å“ªé‡Œæ‹¿åˆ°äº†é‚€è¯·å‡½ï¼Œè‡ªå·±å ‚è€Œçš‡ä¹‹çš„è¿›æ¥äº†ã€‚ ä»–å½“ç„¶è¦è¿›æ¥äº†ã€‚\nè¿™æ˜¯ä»–æœ€åçš„æœºä¼šäº†ã€‚\nä¸‘é—»é—¹å‡ºæ¥ï¼Œå‡ ä¹æ‰€æœ‰çš„å¹¿å‘Šå•†å’Œå‰§ç»„éƒ½è·Ÿä»–æ¯çº¦ã€‚\nä»–ç°åœ¨å®å¯æ‹ç”·ä¸‰å·ï¼Œä¹Ÿä¸æƒ³å°±æ­¤æ²‰å¯‚ã€‚\nå› ä¸ºä»–çš„äº‹æƒ…ï¼Œæ ¹æœ¬å°±å‹ä¸ä¸‹å»ã€‚\næ‰€ä»¥ç‹æ–‡è±ªåœ¨å‘å¸ƒä¼šä¸Šï¼Œåˆ°å¤„è®¨å¥½åˆ«äººã€‚\næ²ˆå‡‰å·ç©¿ç€ä¸€èº«æ·±ç°è‰²è¥¿è£…ï¼Œé¢è‰²æ¸…å†·ï¼Œæ‰‹é‡Œç«¯ç€ä¸€ä¸ªé«˜è„šé¦™æ§Ÿæ¯ï¼Œç«™åœ¨æ¡Œå­æ—è¾¹ï¼Œæ•´ä¸ªäººæ˜¾å¾—æ ¼å¤–ä¿Šé€¸ï¼Œå´ä¹Ÿæ ¼å¤–çš„æ¸…å†·ï¼Œè®©å‘¨å›´çš„äººéƒ½ä¸æ•¢ä¸Šå‰æ­è®ªã€‚ ä»–ä¸€ä¸ªäººï¼Œå°±æ˜¯ä¸€ä¸ªä¸–ç•Œã€‚\nå¯å¦‚æœèƒ½æ³¨æ„åˆ°ä»–ï¼Œå°±ä¼šå‘ç°ä»–çš„è§†çº¿ï¼Œå´æ€»æ˜¯è‹¥æœ‰ä¼¼æ— çš„é£˜åˆ°ç‹æ–‡è±ªèº«ä¸Šã€‚\nå®‹åŸç«™åœ¨ä»–çš„èº«è¾¹ï¼Œå¯Ÿè§‰åˆ°è¿™ä¸€ç‚¹ä»¥åï¼Œå°±å¿ä¸ä½æ‹½äº†æ‹½ä»–çš„èƒ³è†Šã€‚\næ²ˆå‡‰å·æ·¡æ·¡å›å¤´ï¼Œçœ‹å‘ä»–ï¼Œç›®éœ²è¯¢é—®ã€‚\nâ€œæ²ˆå“¥ï¼Œæ‚¨åˆ°åº•æ˜¯è¦å¹²ä»€ä¹ˆå•Šï¼Ÿ èƒ½ä¸èƒ½å‘Šè¯‰æˆ‘ï¼Œå¥½è®©æˆ‘æœ‰ä¸ªå¿ƒç†å‡†å¤‡ã€‚ æ‚¨è¿™æ ·çªç„¶è·‘è¿‡æ¥å‚åŠ è¿™ä¹ˆä¸€ä¸ªå°å‰§ç»„çš„å‘å¸ƒä¼šï¼Œåˆä»€ä¹ˆéƒ½ä¸è¯´å°±è¿™ä¹ˆæµç€ï¼Œæˆ‘å¿ƒé‡Œç˜†çš„æ…Œã€‚â€\næ²ˆå‡‰å·å¬åˆ°è¿™è¯ï¼ŒæŠ¿äº†ä¸€å£é¦™æ§Ÿï¼Œæ¥ç€ï¼Œå°†é¦™æ§Ÿæ¯æ”¾ä¸‹ã€‚\næ—‹å³ï¼Œä»–è¿ˆå¼€äº†ä¿®é•¿çš„æ­¥ä¼ã€‚\nå®‹åŸçš„å¿ƒéƒ½æäº†èµ·æ¥ï¼Œç´§è·Ÿåœ¨ä»–èº«åã€‚ æ²ˆå‡‰å·ä¸€æ­¥ä¸€æ­¥å¾€å‰ï¼Œèµ°åˆ°äº†å‰æ–¹ã€‚\nç‹æ–‡è±ªæ­£åœ¨è·Ÿåˆ«çš„ä¸‰æµå°æ˜æ˜Ÿå¥—è¿‘ä¹ï¼Œé‚£ä¸ªäººè¯¢é—®ï¼Œâ€œå¬è¯´ä½ æ‰“äº†ä¸€ä¸ªç‹—ä»”ï¼Ÿâ€\nâ€œå¯¹å•Šï¼Œç°åœ¨çš„ç‹—ä»”å°±æ˜¯æƒ¹äººåŒæ¶ï¼Œæˆ‘æ—©å°±æƒ³åŠ¨æ‰‹æ•™è®­ä»–ä»¬äº†ï¼ â€œä½ è¿™æ ·ï¼Œå°±ä¸æ€•è·Ÿä»–ä»¬ç»“ä»‡å•Šï¼Ÿâ€\nâ€œæˆ‘éƒ½è¿™æ ·äº†ï¼Œæˆ‘æ€•ä»€ä¹ˆï¼Ÿ å½“åˆæ²ˆå½±å¸ä»¥æ­£å½“é˜²å«ä¸ºå€Ÿå£ï¼Œå°†ä¸€åç‹—ä»”æ‰“äº†ï¼Œå‘Šåˆ°äº†æ³•åº­ä¸Šå»ä¸ä¹Ÿä¸äº†äº†ä¹‹å—ï¼Ÿ\nç‹æ–‡è±ªè¯´åˆ°è¿™é‡Œï¼Œå˜¿å˜¿ä¸€ç¬‘ã€‚ è¿˜æƒ³è¯´ä»€ä¹ˆï¼Œå¿½ç„¶å¯Ÿè§‰åˆ°èº«åæœ‰äººé è¿‘ã€‚\nä»–å›å¤´ï¼Œå°±çœ‹åˆ°æ²ˆå‡‰å·ï¼Œçœ¼ç³ä¸€ç¼©ï¼Œèˆ”ç€è„¸ç¬‘ï¼Œå´è§æ²ˆå‡‰å·å¾€å‰ä¸€æ­¥ï¼Œä¸€æŠŠæªä½ä»–çš„è¡£é¢†ï¼Œæ¥ç€ä¸€æ‹³å¤´å¯¹ç€ä»–çš„è„¸å°±ç ¸è¿‡æ¥ï¼\n```\n\n``ref_re.txt``:\n```\nQiao Lian clenched her fists and lowered her head.\nActually, he was right.\nShe was indeed an idiot, as only an idiot would believe that they could find true love online.\nShe curled her lips and took a deep breath. Just when she was about to put down her cell phone, a barrage of posts bombarded her WeChat account.\nShe logged into her account and saw that a large number of fans in the Shen Liangchuan fan group had tagged her.\n[Qiao Lian: What happened?]\n[Chuan Forever: Qiao Lian, look at the headlines on Weibo, quickly!]\nShe froze momentarily, then picked up her cell phone and logged into Weibo. When she saw the headlines, her entire body immediately froze over again!\nShen Liangchuan arrived at the scene after accepting the invitation. The director immediately went to greet him in a respectful manner, politely welcoming him and expressing his gratitude for Shen Liangchuanâ€™s presence today.\nShen Liangchuan did not speak. Instead he looked at Wang Wenhao, who was nearby.\nAfter Wang Wenhaoâ€™s scandal broke, every film he starred in had been taken down. Only this show could still be broadcasted, as Wang Wenhao had a supporting role in it and was practically unnoticeable.\nIn fact, the cast and crew hadnâ€™t even invited Wang Wenhao. However, he had obtained a copy of the invitation letter somehow, and strode imposingly into the venue anyway.\nAfter all, this was his final chance.\nAfter his scandals broke, practically every advertiser and filming crew wanted to break their contracts with him.\nHe would rather take a supporting role than fade out into obscurity.\nThat was because the scandals surrounding him would never disappear.\nThus, Wang Wenhao went around trying to curry favor with everybody at this press conference.\nShen Liangchuan was wearing a dark grey suit and he had a cold expression. He was holding a champagne glass and was currently standing beside a table. He looked exceptionally stylish, but also exceptionally icy. As a result, none of the people around him dared to approach him.\nIf anyone had paid attention to him, they would have noticed that his gaze kept drifting over to Wang Wenhao.\nSong Cheng stood at his side. After noticing his behavior, he could not help but pinch his arm.\nShen Liangchuan turned around and looked at him casually, with a questioning face.\nâ€œBrother Shen, what are you planning to do? Can you tell me beforehand so that I can prepare myself mentally. You suddenly decide to come and attend such a small-scale press conference, yet you have been completely silent and are now just standing here and doing nothing? My heart is beating anxiously right now.â€\nAfter Shen Liangchuan heard him speak, he sipped a mouthful of champagne and put the glass down.\nThen, he walked away in long strides.\nSong Cheng was extremely nervous and followed him. Shen Liangchuan walked forward, one step at a time, until he reached the front of the room.\nWang Wenhao was currently ingratiating himself with a C-list celebrity. The celebrity asked, â€œHey, I heard that you beat a paparazzi?â€\nâ€œYeah, the paparazzi nowadays are so disgusting. I have wanted to teach them a lesson myself for some time now!â€ \"Are not you afraid of becoming an enemy of them?\"\nâ€œIâ€™ve already done it, so what should I be scared of? That time Best Actor Shen beat up a reporter, he claimed that it was in self-defence so that he would have an excuse if he got sued, right? At that time, nobody said anythingâ€ \nAs Wang Wenhao spoke, he laughed heartily. Just as he was about to continue speaking, he suddenly felt a presence approaching him from behind.\nHe turned around and saw Shen Liangchuan. His eyes narrowed and attempted to smile at him. However, Shen Liangchuan took a step forward, grabbed his tie and threw a punch at his face!\n```\n\n``ner_re.txt``:\n```\nPERSON: (Qiao Lian: 1; )\tNONPERSON: ()\nPERSON: ()\tNONPERSON: ()\nPERSON: ()\tNONPERSON: ()\nPERSON: ()\tNONPERSON: (WeChat: 1; )\nPERSON: (Shen Liangchuan: 1; )\tNONPERSON: ()\nPERSON: (Qiao Lian: 1; )\tNONPERSON: ()\nPERSON: (Qiao Lian: 1; )\tNONPERSON: (Weibo: 1; )\nPERSON: ()\tNONPERSON: (Weibo: 1; )\nPERSON: (Shen Liangchuan: 1; )\tNONPERSON: (Shen Liangchuanâ€™s: 1; )\nPERSON: (Shen Liangchuan: 1; Wang Wenhao: 1; )\tNONPERSON: ()\nPERSON: (Wang Wenhao: 1; )\tNONPERSON: (Wang Wenhaoâ€™s: 1; )\nPERSON: (Wang Wenhao: 1; )\tNONPERSON: ()\nPERSON: ()\tNONPERSON: ()\nPERSON: ()\tNONPERSON: ()\nPERSON: ()\tNONPERSON: ()\nPERSON: ()\tNONPERSON: ()\nPERSON: (Wang Wenhao: 1; )\tNONPERSON: ()\nPERSON: (Shen Liangchuan: 1; )\tNONPERSON: ()\nPERSON: (Wang Wenhao: 1; )\tNONPERSON: ()\nPERSON: (Song Cheng: 1; )\tNONPERSON: ()\nPERSON: (Shen Liangchuan: 1; )\tNONPERSON: ()\nPERSON: ()\tNONPERSON: ()\nPERSON: (Shen Liangchuan: 1; )\tNONPERSON: ()\nPERSON: ()\tNONPERSON: ()\nPERSON: (Song Cheng: 1; Shen Liangchuan: 1; )\tNONPERSON: ()\nPERSON: (Wang Wenhao: 1; )\tNONPERSON: ()\nPERSON: ()\tNONPERSON: ()\nPERSON: ()\tNONPERSON: ()\nPERSON: (Wang Wenhao: 1; )\tNONPERSON: ()\nPERSON: (Shen Liangchuan: 2; )\tNONPERSON: ()\n```\n\n``an.txt``:\n```\nJoe clenched his fist and bowed his head.\t4,Joe <pos/1,3>\t3,her, his <pos/35,37>\nIn fact, he's right.\t2\t5\nI am a fool, even will believe the love on the Internet.\t2\t5\nShe ticked her lips, took a deep breath, and was about to put her phone down, but weChat was blown open.\t6\t1,bombarded, blown open <pos/94,103>\nShe nodded in and found it was a cold powder group, and everyone was on her.\t1,logged, nodded <pos/5,10>\t4,cold powder group <pos/34,50>\nJoe: What's the matter?\t4,Joe <pos/1,3>\nChuan-flowing: Joe love, quickly look at the micro-blogging headlines! Weibo headlines?\t4,Chuan-flowing <pos/1,13>;Joe love <pos/18,25>;micro-blogging <pos/50,63>\nShe took a slight look, picked up the phone, landed on the micro-blog, when she saw the headlines, the whole person suddenly choked!\t1,logged, landed on <pos/46,54>\t6\nThe show's release. Shen Liangchuan was invited to appear, the director immediately greeted him with respect, politely said this to him, expressed his gratitude for his arrival.\t0\nShen Liangchuan did not speak, look not far from Wang Wenhao.\t6\nAfter Wang Wenhao's accident, all the works were off the shelves, and this play can also be broadcast, because Wang Wenhao in the friendship played by the male no. 3 play is very few, almost negligible.\t1,taken, off the shelves <pos/50,64>\t5\t6\nThe crew did not invite Wang Wenhao, but he did not know where to get the invitation, his own entrance. Of course he's coming in.\t5\nThis is his last chance.\t5\nThe scandal broke, and almost all advertisers and crews broke his contract with him.\t2\t6\nHe would rather shoot the men's number three now than be silent about it.\t1,fade, be silent about <pos/55,69>\t6\nBecause of his affairs, there is no pressure.\t5\t6\nSo Wang Wenhao at the press conference, everywhere to please others.\t6\nShen Liangchuan wearing a dark gray suit, cold-faced, hand with a high-footed champagne glass, standing next to the table, the whole person appears extra or less handsome, but also extraordinarily cold, so that people around are afraid to come forward. He is a man, is a world.\t1,very, extra or less <pos/149,161>;icy, cold <pos/200,203>\t5\nBut if you can notice him, you will find his sight, but always if there is nothing floating to Wang Wenhao body.\t6\t5\t7\nSongcheng stood by his side, aware of this, can not help but pull his arm.\t5\nShen Liangchuan faint lying back, looked at him, blind inquiry.\t6\t7\n\"Shen brother, what the hell are you doing? Can you tell me so that I have a mental preparation. You suddenly ran over to attend the launch of such a small group, and said nothing so, I panicked. \"\t1,press, launch <pos/135,140>\nShen Said, took a sip of champagne, and then put the champagne glass down.\t6\nImmediately, he took a slender step.\t1,long stride,slender step <pos/24,35>\nSongcheng's heart was raised and followed immediately behind him. Shen Liangchuan step by step forward, walked forward.\t1,nervous, raised <pos/23,28>\t6\nWang Wenhao is with other third-rate star-studded sets, the man asked, \"I heard you hit a paparazzi?\" \"\t6\t5\n\"Yeah, the paparazzi are disgusting now, I've wanted to teach them! \"You're not afraid to feud with them, \" he said. \t0\n\"I'm all there, what am I afraid of? At the beginning Shen Shadow Emperor to self-defense as an excuse, a paparazzi hit, to the court to go to the court is not it\"?\t4,Shen Shadow Emperor <pos/56,74>\t5\t7\nWang Wenhao said here, hey hey smile. Want to say something, suddenly realized that someone behind him is close.\t3,He, Want to <pos/39,45>\t6\t1,approaching, close <pos/109,113>\t5\t7\nHe looked back, he saw Shen Liangchuan, eyes shrink, licking his face and smiling, but saw Shen Liangchuan a step forward, a holding his collar, and then a fist to his face hit!\t3,his, eyes <pos/41,44>\t6\t7\n```\n### Download\nDownload the BWB dataset from [this Google Drive link](https://drive.google.com/drive/folders/12K1-DWmpEdqkaR_61aogdywsALDg4z1L?usp=sharing).\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/EleanorJiang/blonde",
    "keywords": "document metric machine translation",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "blonde",
    "package_url": "https://pypi.org/project/blonde/",
    "platform": null,
    "project_url": "https://pypi.org/project/blonde/",
    "project_urls": {
      "Homepage": "https://github.com/EleanorJiang/blonde"
    },
    "release_url": "https://pypi.org/project/blonde/0.1.4/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "PyTorch implementation of BlonDe score",
    "version": "0.1.4",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14214597,
  "releases": {
    "0.1.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e4b4a90d82a69acd388a127ab7becb397bc3baae842a669cd872d709e5c420d8",
          "md5": "5ac39e0c3fc611062e26baf02bad6576",
          "sha256": "3afd969f640cef04b3072430aba5fc1f923b9f555fcd936251b38dee640f84e1"
        },
        "downloads": -1,
        "filename": "blonde-0.1.3.macosx-10.9-x86_64.tar.gz",
        "has_sig": false,
        "md5_digest": "5ac39e0c3fc611062e26baf02bad6576",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 79415,
        "upload_time": "2022-06-22T16:58:43",
        "upload_time_iso_8601": "2022-06-22T16:58:43.470957Z",
        "url": "https://files.pythonhosted.org/packages/e4/b4/a90d82a69acd388a127ab7becb397bc3baae842a669cd872d709e5c420d8/blonde-0.1.3.macosx-10.9-x86_64.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "386743e9d06684646a0bd8dd7faf90b1b83c71ba7a473985c2270dbb7d9f9662",
          "md5": "2551bc8014d460b6aa7a5dee6965fcce",
          "sha256": "21f36532fa992d209191a85e7a5677e981730d7f43b8607053a4131d6b16c7e2"
        },
        "downloads": -1,
        "filename": "blonde-0.1.4.macosx-10.9-x86_64.tar.gz",
        "has_sig": false,
        "md5_digest": "2551bc8014d460b6aa7a5dee6965fcce",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 81178,
        "upload_time": "2022-06-22T18:01:21",
        "upload_time_iso_8601": "2022-06-22T18:01:21.827875Z",
        "url": "https://files.pythonhosted.org/packages/38/67/43e9d06684646a0bd8dd7faf90b1b83c71ba7a473985c2270dbb7d9f9662/blonde-0.1.4.macosx-10.9-x86_64.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "386743e9d06684646a0bd8dd7faf90b1b83c71ba7a473985c2270dbb7d9f9662",
        "md5": "2551bc8014d460b6aa7a5dee6965fcce",
        "sha256": "21f36532fa992d209191a85e7a5677e981730d7f43b8607053a4131d6b16c7e2"
      },
      "downloads": -1,
      "filename": "blonde-0.1.4.macosx-10.9-x86_64.tar.gz",
      "has_sig": false,
      "md5_digest": "2551bc8014d460b6aa7a5dee6965fcce",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 81178,
      "upload_time": "2022-06-22T18:01:21",
      "upload_time_iso_8601": "2022-06-22T18:01:21.827875Z",
      "url": "https://files.pythonhosted.org/packages/38/67/43e9d06684646a0bd8dd7faf90b1b83c71ba7a473985c2270dbb7d9f9662/blonde-0.1.4.macosx-10.9-x86_64.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}