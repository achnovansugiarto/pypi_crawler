{
  "info": {
    "author": "Lotte Weerts",
    "author_email": "lotteweerts@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: BSD License",
      "Natural Language :: English",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Topic :: Scientific/Engineering :: Artificial Intelligence",
      "Topic :: Scientific/Engineering :: Bio-Informatics"
    ],
    "description": "# HumanlikeHearing\n\nA Python package for applying a range of psychometric tests on automatic speech recognition (ASR) systems. For more information on the psychometric tests and the ASR systems this toolbox supports, see our accompanying paper: \n\nThe Psychometrics of Automatic Speech Recognition\nLotte Weerts, Stuart Rosen, Claudia Clopath, Dan F. M. Goodman\nbioRxiv 2021.04.19.440438; doi: https://doi.org/10.1101/2021.04.19.440438\n\n\n## Installation\n\nThe easiest way to install the toolbox is by installing the latest stable release that lives on PyPI:\n\n```\npip install humanlikehearing\n```\n\nTo ensure all dependencies are correctly installed, we recommend using Anaconda to install numpy and scipy beforehand.\n\nTo build the toolbox from source use:\n\n```\npython setup.py build\npython setup.py install\n```\n\nIf your installation went well, you should now be able to execute the demo script `run.py`:\n\n```\npython run.py \\\n  --asr_system_name TestASR \n  --dataset TestDataSet \n  --data_path . \n  --results_folder ../results \n  --sentences_per_condition 1\n```\n\nIMPORTANT: installing the toolbox DOES NOT install any of the automatic speech recognition systems - the sample script will run a dummy ASR system that always prints 'hello world'.\n\n## Prepare ASR systems\n\nBy default, no ASR systems are included in the toolbox. However, the toolbox provides support for specific versions of three freely available ASR systems. If you just want to quickly test out the toolbox, we recommend installing Mozilla DeepSpeech v0.6.1, as it is the easiest to install. \n\nAfter installation, you can start running experiments by setting the --asr_system_name and --model_path accordingly:\n\n```\npython examples/run.py \\\n  --asr_system_name <ASR CLASS NAME> \n  --model_path <PATH TO ASR MODEL FILE>\n  --dataset TestDataSet \n  --data_path . \n  --results_folder ../results \n  --sentences_per_condition 1\n```\n\n### MozillaDeepSpeech (LSTM model)\n\nInstallation instructions can be found on https://deepspeech.readthedocs.io/en/v0.6.1/USING.html\n\nThis code assumes the model follows Mozilla DeepSpeech version 6.1 and may not work for later models! When defining `model_path` refer to the unzipped directory (e.g. `/path/to/downloads/deepspeech-0.6.1-models`). \n\n### Vosk's Kaldi nnet3 model (DNN-HMM model)\n\nInstallation instructions can be found on https://alphacephei.com/vosk/install\n\nThe Vosk model used in the paper is vosk-model-en-us-daanzu-20200905 and can be downloaded here: https://alphacephei.com/vosk/models\n\nNote that to be able to run this model, you also need to  install Kaldi: http://www.kaldi-asr.org/doc/install.html\n\nWhen defining `model_path` refer to the unzipped directory (e.g. `/path/to/downloads/vosk-model-en-us-daanzu-20200905`). \n\n### Fairseq's Wav2vec 2.0 (CNN-Transformer model)\n\nInstallation instructions can be found on: https://github.com/pytorch/fairseq/tree/828960f5dace4787ad81aeadca60043c907adc67/examples/wav2vec\n\nThe Wav2Vec model used in the paper is the Wav2Vec 2.0 Large model trained for 960 hours. \n\nWhen defining `model_path` refer to the `.pt` file of the model (e.g. `/path/to/downloads/wav2vec_big_960h.pt`). Note that it is assumed that in the same folder, a `dict.ltr.txt` file is present. This file can be downloaded here: https://dl.fbaipublicfiles.com/fairseq/wav2vec/dict.ltr.txt\n\n## Prepare DataSets\n\nThe toolbox supports the use of two freely available speech datasets, the ARU speech corpus (which contains recordings of the IEEE sentences) and the LibriSpeech dataset (which contains recordings of audiobooks). We generally recommend the ARU speech corpus for testing as it is most similar to the type of data humans tend to be tested on, and not all experiments are currently compatible with the LibriSpeech dataset (but will be in the future). \n\n### ARU Speech Corpus\nThe ARU dataset can be downloaded here: http://datacat.liverpool.ac.uk/681/\n\nTo run an experiment on the ARU speech corpus: \n\n```\npython examples/run.py \\\n  --dataset ARUDataSet \n  --data_path /your/path/to/ARU_Speech_Corpus_v1_0\n  --results_folder ../results \n  --sentences_per_condition 100\n```\n\n### LibriSpeech Corpus\nThe LibriSpeech test data can be downloaded here: https://www.openslr.org/12\n\nNote: We recommend to only use the \"test-clean.tar.gz\" subset of the LibriSpeech data set, as many freely available ASR systems are trained using LibriSpeech, so testing using the training data will overestimate the ASR performance.\n\nTo run an experiment on the LibriSpeech corpus:\n\n```\npython examples/run.py \\\n  --dataset LibriSpeechDataSet \n  --data_path /your/path/to/test-clean\n  --results_folder ../results \n  --sentences_per_condition 100\n```\n\n## Run an experiment\n\nTo run an experiment, you can either use run.py to load the correct asr system and data set and write the outputs to a results folder. By default, run.py will run all experiments described in the paper:\n\n```\npython examples/run.py \\\n  --asr_system_name <ASR SYSTEM CLASS> \n  --model_path <PATH TO ASR MODEL>\n  --dataset <DATA SET CLASS NAME>  \n  --data_path <PATH TO DATA>\n  --results_folder <RESULTS FOLDER>\n  --sentences_per_condition 100\n```\n\nHere, --asr_system_name, --model_path, --dataset and --data_path can be defined as described above. The --results_folder indicates the folder in which experimental outcomes will be stored as pandas tables. --sentences_per_condition indicates how many sentences are used per condition. For most experiments, in particular the SRT experiments, you want this number to be at least 20, but closer to 100 will give you a better view on the model performance. \n\nIf you only want to run a subset of the experiments or if you want to change any parameters, you can simply edit run.py as desired. \n\n## Analyse your experimental results\n\nTo view the outcomes of your experiments, locate your experiment folder in your results folder, which are organised as `results/test_report_<ASRNAME>_<TIMESTAMP>/<EXPERIMENT CLASS>_<RESULTS TYPE>_<TIMESTAMP>`. Here, `<RESULTS_TYPE>` is usually 'standard', but in some cases may indicate a sub-experiment (e.g. a clipping experiment will have a 'peak' and 'center' results type). \n\nTo load your experimental outcomes, you can use pandas:\n\n```\nimport pandas as pd\nresults = pd.read_pickle('path/to/experiment/results.pk1')\n```\n\nIn most cases, it will be relatively straight forward to analyse the outcomes. However, in the case of speech reception threshold (SRT) experiments, one extra step of analysis is required to obtain the SRTs from the results file. See `examples/srt_analysis.ipynb` for an example of how to obtain SRT results. \n\n# Citing\n\nIf you wish to cite HumanlikeHearing in a scholarly work, please cite the following:\n\nThe Psychometrics of Automatic Speech Recognition\nLotte Weerts, Stuart Rosen, Claudia Clopath, Dan F. M. Goodman\nbioRxiv 2021.04.19.440438; doi: https://doi.org/10.1101/2021.04.19.440438\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/lotteweerts/humanlikehearing",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "humanlikehearing",
    "package_url": "https://pypi.org/project/humanlikehearing/",
    "platform": "",
    "project_url": "https://pypi.org/project/humanlikehearing/",
    "project_urls": {
      "Bug Tracker": "https://github.com/lotteweerts/humanlikehearing/issues",
      "Homepage": "https://github.com/lotteweerts/humanlikehearing"
    },
    "release_url": "https://pypi.org/project/humanlikehearing/0.1.0/",
    "requires_dist": [
      "scipy (>=1.0.0)",
      "numpy (>=1.15.0)",
      "pandas (>=0.13)",
      "absl-py (>=0.10.0)",
      "PyPDF2 (>=1.26.0)",
      "librosa (>=0.7.0)",
      "nltk (>=3.5)",
      "praat-parselmouth (>=0.3.3)",
      "SoundFile (>=0.10.3.post1)",
      "webrtcvad-wheels (>=2.0.10.post2)"
    ],
    "requires_python": ">=3.5",
    "summary": "Psychometric testing on Automatic Speech Recognition systems",
    "version": "0.1.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 10413957,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "de2b1ec8d99aec835e2b111f720cae2f381dfffb7061b49800a2a39b6784e3c9",
          "md5": "67bc214ace8ef098ea71f93b61334f21",
          "sha256": "ca2d12cdde3bcf9f4c08211cee84d40ac4ca11f06a722b40ce2bf5a5a39009d0"
        },
        "downloads": -1,
        "filename": "humanlikehearing-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "67bc214ace8ef098ea71f93b61334f21",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.5",
        "size": 42036,
        "upload_time": "2021-05-19T18:03:06",
        "upload_time_iso_8601": "2021-05-19T18:03:06.398633Z",
        "url": "https://files.pythonhosted.org/packages/de/2b/1ec8d99aec835e2b111f720cae2f381dfffb7061b49800a2a39b6784e3c9/humanlikehearing-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1979c5db4032767979ce568ec45afa74b851a389cf2a7a38b0bc4b9a2c15f00e",
          "md5": "29c84e323b88d200662cfc188538df30",
          "sha256": "3e6afc57d2d8958bdab3399f1c495e7e3e2c9c5f145c80f846a18dc367b85576"
        },
        "downloads": -1,
        "filename": "humanlikehearing-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "29c84e323b88d200662cfc188538df30",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.5",
        "size": 41398,
        "upload_time": "2021-05-19T18:03:07",
        "upload_time_iso_8601": "2021-05-19T18:03:07.997413Z",
        "url": "https://files.pythonhosted.org/packages/19/79/c5db4032767979ce568ec45afa74b851a389cf2a7a38b0bc4b9a2c15f00e/humanlikehearing-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "de2b1ec8d99aec835e2b111f720cae2f381dfffb7061b49800a2a39b6784e3c9",
        "md5": "67bc214ace8ef098ea71f93b61334f21",
        "sha256": "ca2d12cdde3bcf9f4c08211cee84d40ac4ca11f06a722b40ce2bf5a5a39009d0"
      },
      "downloads": -1,
      "filename": "humanlikehearing-0.1.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "67bc214ace8ef098ea71f93b61334f21",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.5",
      "size": 42036,
      "upload_time": "2021-05-19T18:03:06",
      "upload_time_iso_8601": "2021-05-19T18:03:06.398633Z",
      "url": "https://files.pythonhosted.org/packages/de/2b/1ec8d99aec835e2b111f720cae2f381dfffb7061b49800a2a39b6784e3c9/humanlikehearing-0.1.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "1979c5db4032767979ce568ec45afa74b851a389cf2a7a38b0bc4b9a2c15f00e",
        "md5": "29c84e323b88d200662cfc188538df30",
        "sha256": "3e6afc57d2d8958bdab3399f1c495e7e3e2c9c5f145c80f846a18dc367b85576"
      },
      "downloads": -1,
      "filename": "humanlikehearing-0.1.0.tar.gz",
      "has_sig": false,
      "md5_digest": "29c84e323b88d200662cfc188538df30",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.5",
      "size": 41398,
      "upload_time": "2021-05-19T18:03:07",
      "upload_time_iso_8601": "2021-05-19T18:03:07.997413Z",
      "url": "https://files.pythonhosted.org/packages/19/79/c5db4032767979ce568ec45afa74b851a389cf2a7a38b0bc4b9a2c15f00e/humanlikehearing-0.1.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}