{
  "info": {
    "author": "Daniel Whitten",
    "author_email": "danieljwhitten@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# PDFtoCSV\nA script to take multiple PDF files as input and output their text in a CSV file\n\nThe guide below is copied from the Guide.ipynb Jupyter Notebooks file. Some formatting, instructions, and links might therefore not be accurate. For best results, open Guide.ipynb in Jupyter Notebooks\n\nGuide for Installation and Use\nPrerequisites\nAnaconda & Jupyter Notebooks\nWe recommend using this program via the Anaconda Data Science Platform. This includes Jupyter Notebooks, and you likely already have it installed if you are viewing this file.\nThis program can also be run via any Python interpreter, including from the command line, if you have the technical knowledge to do so.\n\nPython 3\nThis program is written using the latest version of Python to date. To ensure you are ready to run it, ensure that the top right corner of your Jupyter Notebook says Python 3. If it does not, try to change it by going to the Kernel menu, choosing Change Kernel, then Python 3. If you do not see this option, you may need to download the latest version of Anaconda here.\n\nWith that, you should be able to follow the steps below and get going within a few minutes!\n\nInstallation\nThe following steps are required before the program is run for the first time. They do not need to be repeated again on the same computer.\n\n1. Install Tesseract\nTesseract is the tool this program uses to read text from pages that do not have machine-readable text. It is is a free, open-source program (sponsored by Google) that performs Optical Character Recognition (OCR). It must be installed first for this program to work properly. More information about Tesseract OCR can be found here.\n\nWindows\nDownload the Tesseract OCR installer here.\nRun the .exe file once it has been downloaded.\nAccept all default options.\n\nMac\nThe easiest way is to install via Homebrew, a handy installer that works to easily install all kinds of usefuly programs, in addition to Tesseract OCR.\n-Open Terminal (Press Command + Space, type \"Terminal\", press Enter)\n-Paste: /usr/bin/ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\"\n-Press Enter\n-Press Enter again\n-Enter your computer password to authorize installation when prompted\n-Homebrew has successfully installed once you see ==> Installation successful!\n-Paste the following: brew install tesseract\n-Press Enter\nFor experienced users, see here for other installation options.\n\nLinux\nIf your distribution uses apt, like Ubuntu, the following should install Tesseract OCR:\nsudo apt install tesseract-ocr\nSee here for more detailed instructions for a wide variety of distributions\n\n2. Prepare Python\nThe cell below installs the Python programs required for this program to run.\nExecute the cell by clicking on it and pressing Shift+Enter.\n\n[-]\n\n\n%run \"installDependencies.py\"\nfrom IPython.core.display import HTML\nHTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")\nIf the output above indicates All packages are installed, you are good to start using the program!\n\nIf not, try opening your command line (Windows: Open the program \"Command Prompt\", Mac: Open the program \"Terminal\") and paste the following, then press Enter: python -m pip install unidecode pytesseract PyMuPDF natsort\n\nHow to Use the Program\n\nPrepare Your PDF Input\n\nLegible Black and White Typed Text\nIt works best with PDF files that have clearly legible typed black text on a white background. The majority of the text should be in the same font and the same size. The program will still try to process files with coloured backgrounds or various non-standard fonts, but the quality of the output may be low.\n\nClearly Labelled Files\nThe output will be one single CSV file (can be opened as a spreadsheet in Microsoft Excel). The text from each page of each document will be included on a separate line. Each line will have: \n-The path of the source file, including preceding folders and the name of the file (Eg. \"path/to/folder/with/PDF/2019/January/1Jan2019.pdf\")\n-The page number, relative to each file\n-The number of words captured from the page\n-The text of the page\nBecause of this format, it is most convenient for you to take the time to name your folders and files descriptively. The program processes the files in the same order that they appear on your computer, when sorted by file name. However, if your folders are randomly or inconsistantly named, it will make it harder to sort and analyze the data\n\nAwareness of Time Required\nThis program extracts text in two different ways. First, it tries to see if any text is already embedded in the PDF (i.e., the PDF is \"machine readable\"). If there is no text embedded, the program then uses Tesseract OCR to read the letters on the page as plain text. It is not crucial to understand how this works, but it will make a different for how long the file(s) will take to process.\n\nMachine readable PDF: ~0.009 seconds/page\nNon-machine readable: ~1 second/100 words on page\nWhile this does not make a large difference if the file has only a few pages, the time difference increases with larger files, and can take days for 20,000+ pages. In order to accurately estimate the time required, open up your PDF files and determine whether they are machine readable or not. The easiest way is to search for a word you know is in the file. If your PDF reader finds the word, it has \"read\" the file, and the file is machine readable. If it does not, it is likely not machine readanble, and will require OCR. Another way of checking is to try to highligh the text with your mouse, if it highlights the lines of text, the page is likely machine readable. If it highlights the entire page as one large box, it is likely not.\nFor larger files, it is common to have some non-machine readable files distributed within machine readable pages. This is common with advertisements in newspapers, for example. The program will process any machine readble file accordingly, and only use OCR on individual pages when necessary, so such file should still be processed relatively quickly.\nIn order to optimize the speed of processing, minimize other tasks being performed by your computer at the same time. Computers have limited processing resources, so watching videos, surfing the internet, or writing in a word processor will all negatively impact the processing time for your files. This is not to say that one cannot multitask while processing files, and the effect is only noticable on large batches of non-machine readable files that are continually processing for hours or days at a time.\n\nRun the Program\nIn Jupyter Notebooks\nIn Jupyter Notebooks, you can either use the cell below (Under \"Ready to Go!\"), or navigate to the folder where you downloaded this program and create a new notebook.\nIn a new cell, paste: %run PDFtoCSV.py \"path/to/folder/with/PDF\"\n\nFrom Command Line\nIf you do not want to run the program via Jupyter Notebooks, it is possible to run via the command line (Command Prompt or Terminal), by running the following command python path/to/download/PDFtoCSV.py /path/to/folder/with/PDFs, replacing the first path with the location of this program and the second with the location of your PDFs.\n\nReady to Go!\nYou are ready to start extracting text from your PDF files!\nThe simplist way is to use the cell below. Simply replace the section in quotation marks with the path to the file or folder you want to convert. For instructions on copying and pasting paths, see below.\n\n%run PDFtoCSV.py \"example/path/to/folder/with/PDFs\"\nJust in case you accidentally erased the command above, here it is again for you to copy and paste:\n%run PDFtoCSV.py \"example/path/to/folder/with/PDFs\"\n\nTroubleshooting Common Issues\nPlease enter a valid file or directory / The folder you have entered does not contain any PDF files\nInclude the full and exact spelling and syntax of the path to your file or folder. The best way to ensure this is to copy it directly, here's how:\nOpen the folder containing the folder or file you want to copy\nOn Windows:\nHold Shift and right click on the folder or file\nLeft click on the menu option \"Copy as Path\"\nOn MacOS\nRight click on the folder or file\nHold the Option button\nLeft click on the menu option \"Copy name as Pathname\"\nPaste in the cell above, replacing \"path/to/folder/with/PDF\"\nBe sure to put a quotation mark before and after the path you have pasted\nPress Shift + Enter to run the program\n\n\"There appears to be an issue with your Tesseract OCR installation\"\nRefer to 1. under the \"Installation\" section of this guide on how to install Tesseract OCR. If you have it installed, try uninstalling and re-installing, being sure to accept all default options on the installation.\n\"I could not find your Tesseract-OCR installation in the default location.\"\nRefer to 1. under the \"Installation section of this guide on how to install Tesseract OCR.\nOpen the file tesseractPath.txt in the same folder as this file, and follow the instructions there to locate your Tesseract program on Linux, or if it was installed in a non-default location on Windows or MacOS.\n\nOther issues\nThis program is still in very early development, and at this point is not fully complete with robust error handling or options for non-standard situations. We attempted to make it as broadly usable as possible. Hopefully further versions will come that include more detailed options for handling unexpected issues.\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/danieljwhitten/datasets-from-pdfs",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "datasets-from-pdfs",
    "package_url": "https://pypi.org/project/datasets-from-pdfs/",
    "platform": "",
    "project_url": "https://pypi.org/project/datasets-from-pdfs/",
    "project_urls": {
      "Homepage": "https://github.com/danieljwhitten/datasets-from-pdfs"
    },
    "release_url": "https://pypi.org/project/datasets-from-pdfs/0.0.7/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "('A tool to convert single or mass PDFs to datasets for', 'language analysis, including a toolbox of text and NLP pre-processing options')",
    "version": "0.0.7",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 9465532,
  "releases": {
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "888b476a8654a905da702c9a6ea1b149f276a180607337f9b076988fe7507023",
          "md5": "e9951edba4ef36396a52533f30a8d6be",
          "sha256": "ffb3f623641dc92749c3da6608cc985a86f7f22dbe86da17c505f507aaaca9bf"
        },
        "downloads": -1,
        "filename": "datasets_from_pdfs-0.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "e9951edba4ef36396a52533f30a8d6be",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 54209,
        "upload_time": "2021-02-18T22:32:50",
        "upload_time_iso_8601": "2021-02-18T22:32:50.141370Z",
        "url": "https://files.pythonhosted.org/packages/88/8b/476a8654a905da702c9a6ea1b149f276a180607337f9b076988fe7507023/datasets_from_pdfs-0.0.2-py3-none-any.whl",
        "yanked": true,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6469dc68b5c910f0269fef3fbe46c8a66ea7fc97a42bd0fdf81db10b009e6ba5",
          "md5": "a3ebeb4f737923b0b99adc594253e50b",
          "sha256": "7d40b70615473c5732f738d65d130d576a3b8e3a202be86abb87bf51262d557b"
        },
        "downloads": -1,
        "filename": "datasets-from-pdfs-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "a3ebeb4f737923b0b99adc594253e50b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 27033,
        "upload_time": "2021-02-18T22:32:51",
        "upload_time_iso_8601": "2021-02-18T22:32:51.775359Z",
        "url": "https://files.pythonhosted.org/packages/64/69/dc68b5c910f0269fef3fbe46c8a66ea7fc97a42bd0fdf81db10b009e6ba5/datasets-from-pdfs-0.0.2.tar.gz",
        "yanked": true,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "915dbdaa81ef6e349e56c3da8e13cb93b5154e5dc750e802317ea31d1f431cc8",
          "md5": "d4cfbcac9c51570e415729111b9c72fd",
          "sha256": "96db58174ab7521bd4a0cb17e7449d3be66c75cb862fe0a57f25390ebc576488"
        },
        "downloads": -1,
        "filename": "datasets_from_pdfs-0.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d4cfbcac9c51570e415729111b9c72fd",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 54201,
        "upload_time": "2021-02-18T22:38:36",
        "upload_time_iso_8601": "2021-02-18T22:38:36.982187Z",
        "url": "https://files.pythonhosted.org/packages/91/5d/bdaa81ef6e349e56c3da8e13cb93b5154e5dc750e802317ea31d1f431cc8/datasets_from_pdfs-0.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "89ca636d0b97d2e0f8766a9011495b6b8e644d85894218e9f64ce6f2d592e822",
          "md5": "ecf5b7575874935ade92a4829bb7ef7a",
          "sha256": "b858cc314b02cd7df4cd9db890058a708292770c223444c626d50556943bb5f1"
        },
        "downloads": -1,
        "filename": "datasets-from-pdfs-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "ecf5b7575874935ade92a4829bb7ef7a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 27012,
        "upload_time": "2021-02-18T22:38:38",
        "upload_time_iso_8601": "2021-02-18T22:38:38.518856Z",
        "url": "https://files.pythonhosted.org/packages/89/ca/636d0b97d2e0f8766a9011495b6b8e644d85894218e9f64ce6f2d592e822/datasets-from-pdfs-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a770fdd6a46013e7e110ee03f5d06dcd080f1170ce78f323175f0c5baa3cb8dc",
          "md5": "674d4aaa1e63bb1bef73ec8b814a215e",
          "sha256": "f10476b3678b48dca482d2a259bb036522f12d747498fb79dd17dbad67f38456"
        },
        "downloads": -1,
        "filename": "datasets_from_pdfs-0.0.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "674d4aaa1e63bb1bef73ec8b814a215e",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 34472,
        "upload_time": "2021-02-18T23:32:00",
        "upload_time_iso_8601": "2021-02-18T23:32:00.140965Z",
        "url": "https://files.pythonhosted.org/packages/a7/70/fdd6a46013e7e110ee03f5d06dcd080f1170ce78f323175f0c5baa3cb8dc/datasets_from_pdfs-0.0.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e9a7fd55619bf6fb6fd6c7f499dca32fa8aa83b3c6be1fbd54c647773f445acc",
          "md5": "c12d9edc34671d563c6715f941394e50",
          "sha256": "0a781cc7c5b6bcb559f00d8aadd720931b17fe79c6da6495b191dea87f7bb6ec"
        },
        "downloads": -1,
        "filename": "datasets-from-pdfs-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "c12d9edc34671d563c6715f941394e50",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 26179,
        "upload_time": "2021-02-18T23:32:01",
        "upload_time_iso_8601": "2021-02-18T23:32:01.622378Z",
        "url": "https://files.pythonhosted.org/packages/e9/a7/fd55619bf6fb6fd6c7f499dca32fa8aa83b3c6be1fbd54c647773f445acc/datasets-from-pdfs-0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "caaf4de0f8578a3197b9cd1bf0e99ed98181b537b0eb88afbafafb515b8ade67",
          "md5": "deb82554240c7c7d2b5063f663048c51",
          "sha256": "332cd7da65b916a6b91061a80cbd09c05fe329fc3a1163faed4377fa8f53063b"
        },
        "downloads": -1,
        "filename": "datasets_from_pdfs-0.0.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "deb82554240c7c7d2b5063f663048c51",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 34498,
        "upload_time": "2021-02-18T23:50:51",
        "upload_time_iso_8601": "2021-02-18T23:50:51.755681Z",
        "url": "https://files.pythonhosted.org/packages/ca/af/4de0f8578a3197b9cd1bf0e99ed98181b537b0eb88afbafafb515b8ade67/datasets_from_pdfs-0.0.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ca2f4f612b0ad8f1dcc1d9162da16a1a5b876a8f58d74268b41ed7d4943b8b1e",
          "md5": "8e08bcbbbc9f0f97515c17a016df9ecc",
          "sha256": "fbea51b019f09306bd5c554b7bf43c737c0814da2db9e9ee0f4a06e2f17a14f7"
        },
        "downloads": -1,
        "filename": "datasets-from-pdfs-0.0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "8e08bcbbbc9f0f97515c17a016df9ecc",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 26272,
        "upload_time": "2021-02-18T23:50:52",
        "upload_time_iso_8601": "2021-02-18T23:50:52.908177Z",
        "url": "https://files.pythonhosted.org/packages/ca/2f/4f612b0ad8f1dcc1d9162da16a1a5b876a8f58d74268b41ed7d4943b8b1e/datasets-from-pdfs-0.0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d3a276464530d7f16ebd5d3994d56bf6db19a50d26a59f548e5e6b3c04c143a2",
          "md5": "5539ba12fe9b45e1848df539d0f4d7ad",
          "sha256": "a21b0984046957c8884f8b8d33e0978a9d857f71e4533db55a1d6dbdfb36ad44"
        },
        "downloads": -1,
        "filename": "datasets_from_pdfs-0.0.6-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "5539ba12fe9b45e1848df539d0f4d7ad",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 34512,
        "upload_time": "2021-02-19T00:08:32",
        "upload_time_iso_8601": "2021-02-19T00:08:32.094405Z",
        "url": "https://files.pythonhosted.org/packages/d3/a2/76464530d7f16ebd5d3994d56bf6db19a50d26a59f548e5e6b3c04c143a2/datasets_from_pdfs-0.0.6-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cd2bbd07e916189f3e45e86c22968d3a85a889ddeac4be4275758819f4657d45",
          "md5": "2e4555f4755b9dd1a08e7875e23957bb",
          "sha256": "638cc1804ba7b71103ac0b0c111215365b61c3ea59499bcb9f8e82de6b4f712c"
        },
        "downloads": -1,
        "filename": "datasets-from-pdfs-0.0.6.tar.gz",
        "has_sig": false,
        "md5_digest": "2e4555f4755b9dd1a08e7875e23957bb",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 26286,
        "upload_time": "2021-02-19T00:08:32",
        "upload_time_iso_8601": "2021-02-19T00:08:32.986563Z",
        "url": "https://files.pythonhosted.org/packages/cd/2b/bd07e916189f3e45e86c22968d3a85a889ddeac4be4275758819f4657d45/datasets-from-pdfs-0.0.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "51771c6ccba18c212dca51414f4cf257df8515a1273a331d05d4f13417f47442",
          "md5": "b92ad517fc1f85db8835835eb67b7ab4",
          "sha256": "a8b9d6738dda484a2f98eccd0d218dc4618250cf97feb6c16873a9ef79a3cb9d"
        },
        "downloads": -1,
        "filename": "datasets_from_pdfs-0.0.7-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "b92ad517fc1f85db8835835eb67b7ab4",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 54547,
        "upload_time": "2021-02-19T12:57:17",
        "upload_time_iso_8601": "2021-02-19T12:57:17.307729Z",
        "url": "https://files.pythonhosted.org/packages/51/77/1c6ccba18c212dca51414f4cf257df8515a1273a331d05d4f13417f47442/datasets_from_pdfs-0.0.7-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8c2a192424bc21fc4f8ce92edf5c234a143fb4aa10506773200fa34e54b7523b",
          "md5": "ca13a1f46b34935bc9e037adc7db65f1",
          "sha256": "44413c34039029612268b7ffbad5a9ae55498395db2777e735bc57d2a6384e75"
        },
        "downloads": -1,
        "filename": "datasets-from-pdfs-0.0.7.tar.gz",
        "has_sig": false,
        "md5_digest": "ca13a1f46b34935bc9e037adc7db65f1",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 27131,
        "upload_time": "2021-02-19T12:57:18",
        "upload_time_iso_8601": "2021-02-19T12:57:18.125876Z",
        "url": "https://files.pythonhosted.org/packages/8c/2a/192424bc21fc4f8ce92edf5c234a143fb4aa10506773200fa34e54b7523b/datasets-from-pdfs-0.0.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "51771c6ccba18c212dca51414f4cf257df8515a1273a331d05d4f13417f47442",
        "md5": "b92ad517fc1f85db8835835eb67b7ab4",
        "sha256": "a8b9d6738dda484a2f98eccd0d218dc4618250cf97feb6c16873a9ef79a3cb9d"
      },
      "downloads": -1,
      "filename": "datasets_from_pdfs-0.0.7-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "b92ad517fc1f85db8835835eb67b7ab4",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 54547,
      "upload_time": "2021-02-19T12:57:17",
      "upload_time_iso_8601": "2021-02-19T12:57:17.307729Z",
      "url": "https://files.pythonhosted.org/packages/51/77/1c6ccba18c212dca51414f4cf257df8515a1273a331d05d4f13417f47442/datasets_from_pdfs-0.0.7-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "8c2a192424bc21fc4f8ce92edf5c234a143fb4aa10506773200fa34e54b7523b",
        "md5": "ca13a1f46b34935bc9e037adc7db65f1",
        "sha256": "44413c34039029612268b7ffbad5a9ae55498395db2777e735bc57d2a6384e75"
      },
      "downloads": -1,
      "filename": "datasets-from-pdfs-0.0.7.tar.gz",
      "has_sig": false,
      "md5_digest": "ca13a1f46b34935bc9e037adc7db65f1",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 27131,
      "upload_time": "2021-02-19T12:57:18",
      "upload_time_iso_8601": "2021-02-19T12:57:18.125876Z",
      "url": "https://files.pythonhosted.org/packages/8c/2a/192424bc21fc4f8ce92edf5c234a143fb4aa10506773200fa34e54b7523b/datasets-from-pdfs-0.0.7.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}