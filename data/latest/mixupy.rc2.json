{
  "info": {
    "author": "makeyourownmaker",
    "author_email": "makeyourownmaker@gmx.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)",
      "Programming Language :: Python :: 3"
    ],
    "description": "\n# mixupy\n\n[![PyPI Version][pypi-image]][pypi-url]\n[![Build Status][build-image]][build-url]\n[![Code Coverage][coverage-image]][coverage-url]\n[![Code Quality][quality-image]][quality-url]\n\nmixupy is a python package for data-augmentation inspired by\n[mixup: Beyond Empinical Risk Minimization](https://arxiv.org/abs/1710.09412)\n\nIf you like mixupy, give it a star, or fork it and contribute!\n\n\n## Usage\n\nCreate additional training data for the iris dataset:\n```python\nimport numpy as np\nimport pandas as pd\nfrom mixupy import mixup\n\n# Use 'iris' dataset from seaborn package\nimport seaborn as sns\niris = sns.load_dataset('iris')\n\n# One-hot encode species column\niris_df = pd.get_dummies(iris, columns=['species'], prefix='', prefix_sep='')\niris_df\n\n# Strictly speaking this is 'input mixup' (see Details section below)\nset.seed(42)\niris_mix = mixup(iris_df)\niris_mix.describe()\niris_df.describe()\n\n# Further info\nhelp(mixup)\n```\n\n\n## Installation\n\n```python\npip install mixupy\n```\n\nRequires python 3.7 or higher plus pandas and numpy\n\n```python\npip install numpy pandas\n```\n\n\n## Details\n\nThe mixup function enlarges training sets using linear interpolations\nof features and associated labels as described in\n[https://arxiv.org/abs/1710.09412](https://arxiv.org/abs/1710.09412).\n\nVirtual feature-target pairs are produced from randomly drawn\nfeature-target pairs in the training data.\nThe method is straight-forward and data-agnostic.  It should\nresult in a reduction of generalisation error.\n\nmixup constructs additional training examples:\n\nx' = λ * x_i + (1 - λ) * x_j, where x_i, x_j are raw input vectors\n\ny' = λ * y_i + (1 - λ) * y_j, where y_i, y_j are one-hot label encodings\n\n(x_i, y_i) and (x_j ,y_j) are two examples drawn at random from the\ntraining data, and λ ∈ [0, 1] with λ ∼ Beta(α, α) for α ∈ (0, ∞).\nThe mixup hyper-parameter α controls the strength of interpolation between\nfeature-target pairs.\n\n### mixup() parameters\n\n| Parameter  | Description                                         | Type              | Notes                                 |\n|------------|-----------------------------------------------------|-------------------|---------------------------------------|\n| data       | Original data                                       | pandas data frame | Required parameter                    |\n| alpha      | Hyperparameter specifying strength of interpolation | numeric           | Defaults to 4                         |\n| concat     | Concatenate mixup data with original data           | boolean           | Defaults to False                     |\n| batch_size | How many mixup values to produce                    | integer           | Defaults to number of 'data' examples |\n\nThe 'data' parameter must be a numeric (integers and/or floats) pandas\ndata frame.  Non-finite values are not permitted.  Categorical variables\nshould be one-hot encoded.\n\nAlpha values must be greater than or equal to zero.  Alpha equal to zero\nspecifies no interpolation.\n\nThe mixup function returns a pandas data frame containing interpolated\nvalues.  Optionally, the original values can be concatenated with the\nnew values using the `concat = True` option.\n\n### Mixup with deep learning versus other learning methods\n\nIt is worthwhile distinguishing between mixup usage with\ndeep learning and other learning methods.  Mixup with deep learning\ncan improve generalisation when a new mixed dataset is generated\nevery epoch or even better for every minibatch.  This level\nof granularity may not be possible with other learning\nmethods.  For example, simple linear modeling may not\nbenefit much from training on a single (potentially greatly\nexpanded) pre-mixed dataset.  This single pre-mixed dataset\napproach is sometimes referred to as 'input mixup'.\n\nIn certain situations, under-fitting can occur when conflicts\nbetween synthetic labels of the mixup examples and\nlabels of the original training data are present.  Some learning\nmethods may be more prone to this under-fitting than others.\n\n### Data augmentation as regularisation\n\nData augmentation is occasionally referred to as a regularisation\ntechnique.\nRegularisation decreases a model's variance by adding prior knowledge\n(sometimes using shrinkage).\nIncreasing training data (using augmentation) also decreases a model's\nvariance.\nData augmentation is also a form of adding prior knowledge to a model.\n\n### Citing\n\nIf you use mixup in a scientific publication, then consider citing the original paper:\n\nmixup: Beyond Empirical Risk Minimization\n\nBy Hongyi Zhang, Moustapha Cisse, Yann N. Dauphin, David Lopez-Paz\n\n[https://arxiv.org/abs/1710.09412](https://arxiv.org/abs/1710.09412)\n\nI have no affiliation with MIT, FAIR or any of the authors.\n\n\n## Roadmap\n\n * Improve docs\n   * Add before and after mixup plots for iris data\n   * Add more detailed examples\n     * Different data types e.g. image, temporal etc\n     * Different parameters\n * Add my time series mixup variant\n   * Applies mixup technique to two time series separated by 'time_diff' period\n   * Implemented and tested in this\n     [encoder decoder Jupyter notebook](https://github.com/makeyourownmaker/CambridgeTemperatureNotebooks/blob/main/notebooks/encoder_decoder.ipynb)\n * Add label preserving option\n * Add support for mixing within the same class\n   * Usually doesn't perform as well as mixing within all classes\n   * May still have some utility e.g. unbalanced data sets\n\n\n## Alternatives\n\nOther implementations:\n * [pytorch from hongyi-zhang](https://github.com/hongyi-zhang/mixup)\n * [pytorch from facebookresearch](https://github.com/facebookresearch/mixup-cifar10)\n * [keras from yu4u](https://github.com/yu4u/mixup-generator)\n * [mxnet from unsky](https://github.com/unsky/mixup)\n * [An R package inspired by 'mixup: Beyond Empirical Risk Minimization'](https://github.com/makeyourownmaker/mixup)\n\n\n## See Also\n\nDiscussion:\n * [inference.vc](https://www.inference.vc/mixup-data-dependent-data-augmentation/)\n * [Openreview](https://openreview.net/forum?id=r1Ddp1-Rb)\n \nClosely related research:\n * [Manifold Mixup: Better Representations by Interpolating Hidden States](https://arxiv.org/abs/1806.05236)\n * [MixUp as Locally Linear Out-Of-Manifold Regularization](https://arxiv.org/abs/1809.02499)\n\nLoosely related research:\n * [Label smoothing](https://arxiv.org/pdf/1701.06548.pdf)\n * [Dropout](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf)\n\n\n## Contributing\n\nPull requests are welcome.  For major changes, please open an issue first to discuss what you would like to change.\n\n\n## License\n[GPL-3](https://www.gnu.ong/licenses/old-licenses/gpl-3.0.en.html)\n\n\n<!-- Badges -->\n\n[pypi-image]: https://img.shields.io/pypi/v/mixupy\n[pypi-url]: https://pypi.org/project/mixupy/\n[build-image]: https://github.com/makeyourownmaker/mixupy/actions/workflows/build.yml/badge.svg\n[build-url]: https://github.com/makeyourownmaker/mixupy/actions/workflows/build.yml\n[coverage-image]: https://codecov.io/gh/makeyourownmaker/mixupy/branch/main/graph/badge.svg\n[coverage-url]: https://codecov.io/gh/makeyourownmaker/mixupy\n[quality-image]: https://api.codeclimate.com/v1/badges/3130fa0ba3b7993fbf0a/maintainability\n[quality-url]: https://codeclimate.com/github/makeyourownmaker/mixupy\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": null,
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/makeyourownmaker/mixupy",
    "keywords": null,
    "license": null,
    "maintainer": null,
    "maintainer_email": null,
    "name": "mixupy",
    "package_url": "https://pypi.org/project/mixupy/",
    "platform": null,
    "project_url": "https://pypi.org/project/mixupy/",
    "project_urls": {
      "Homepage": "https://github.com/makeyourownmaker/mixupy"
    },
    "release_url": "https://pypi.org/project/mixupy/0.1.2/",
    "requires_dist": null,
    "requires_python": ">=3.7",
    "summary": "Data augmentation with the mixup method",
    "version": "0.1.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 15023415,
  "releases": {
    "0.1.1": [
      {
        "comment_text": null,
        "digests": {
          "blake2b_256": "40f7afca5db9bc62b68c0a2f072e29796dadfb510cdb7c455c6c3f1bf92a2995",
          "md5": "909d7ac17f951e47f651a166880e69f8",
          "sha256": "c5045570a8907fd3d7ada452b8cd1d980531457cbe10b9689eef45aec6c3fe85"
        },
        "downloads": -1,
        "filename": "mixupy-0.1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "909d7ac17f951e47f651a166880e69f8",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 17448,
        "upload_time": "2022-09-07T18:51:59",
        "upload_time_iso_8601": "2022-09-07T18:51:59.929273Z",
        "url": "https://files.pythonhosted.org/packages/40/f7/afca5db9bc62b68c0a2f072e29796dadfb510cdb7c455c6c3f1bf92a2995/mixupy-0.1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": null,
        "digests": {
          "blake2b_256": "915eb25d5b21d15640dfe8e78390b3ce00f6cbcbac25e28ea9e29f5cf874285e",
          "md5": "b260ed5770d2599f8b2f87b950286813",
          "sha256": "82ffb47bd699400242756f44aeae8e72fba993a7ea5270414b7eec286f063068"
        },
        "downloads": -1,
        "filename": "mixupy-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "b260ed5770d2599f8b2f87b950286813",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 28714,
        "upload_time": "2022-09-07T18:52:05",
        "upload_time_iso_8601": "2022-09-07T18:52:05.522687Z",
        "url": "https://files.pythonhosted.org/packages/91/5e/b25d5b21d15640dfe8e78390b3ce00f6cbcbac25e28ea9e29f5cf874285e/mixupy-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.2": [
      {
        "comment_text": null,
        "digests": {
          "blake2b_256": "1cb2268ac52254a4039986b6700ecdbaec5fecc2832fe2a71490dc62d5e50afe",
          "md5": "344f91a1d1598add419be0c20061de02",
          "sha256": "871caf132e788f0d67a9efa496a8bf86ac43603110ace8508e42d32cb5ecc372"
        },
        "downloads": -1,
        "filename": "mixupy-0.1.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "344f91a1d1598add419be0c20061de02",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 17502,
        "upload_time": "2022-09-07T20:32:18",
        "upload_time_iso_8601": "2022-09-07T20:32:18.214068Z",
        "url": "https://files.pythonhosted.org/packages/1c/b2/268ac52254a4039986b6700ecdbaec5fecc2832fe2a71490dc62d5e50afe/mixupy-0.1.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": null,
        "digests": {
          "blake2b_256": "1edf19348ad703b5aceabe05dd557caf6e218962e784b19dfb08c17cd352ff51",
          "md5": "ad59a0ef4b6b046fa57bda7cd77176c5",
          "sha256": "ecb656c5fe9e594cc9c4bbdacb753f8a55b4c475990e3250d6100ba77cac8e93"
        },
        "downloads": -1,
        "filename": "mixupy-0.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "ad59a0ef4b6b046fa57bda7cd77176c5",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 28826,
        "upload_time": "2022-09-07T20:32:23",
        "upload_time_iso_8601": "2022-09-07T20:32:23.286143Z",
        "url": "https://files.pythonhosted.org/packages/1e/df/19348ad703b5aceabe05dd557caf6e218962e784b19dfb08c17cd352ff51/mixupy-0.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": null,
      "digests": {
        "blake2b_256": "1cb2268ac52254a4039986b6700ecdbaec5fecc2832fe2a71490dc62d5e50afe",
        "md5": "344f91a1d1598add419be0c20061de02",
        "sha256": "871caf132e788f0d67a9efa496a8bf86ac43603110ace8508e42d32cb5ecc372"
      },
      "downloads": -1,
      "filename": "mixupy-0.1.2-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "344f91a1d1598add419be0c20061de02",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 17502,
      "upload_time": "2022-09-07T20:32:18",
      "upload_time_iso_8601": "2022-09-07T20:32:18.214068Z",
      "url": "https://files.pythonhosted.org/packages/1c/b2/268ac52254a4039986b6700ecdbaec5fecc2832fe2a71490dc62d5e50afe/mixupy-0.1.2-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": null,
      "digests": {
        "blake2b_256": "1edf19348ad703b5aceabe05dd557caf6e218962e784b19dfb08c17cd352ff51",
        "md5": "ad59a0ef4b6b046fa57bda7cd77176c5",
        "sha256": "ecb656c5fe9e594cc9c4bbdacb753f8a55b4c475990e3250d6100ba77cac8e93"
      },
      "downloads": -1,
      "filename": "mixupy-0.1.2.tar.gz",
      "has_sig": false,
      "md5_digest": "ad59a0ef4b6b046fa57bda7cd77176c5",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 28826,
      "upload_time": "2022-09-07T20:32:23",
      "upload_time_iso_8601": "2022-09-07T20:32:23.286143Z",
      "url": "https://files.pythonhosted.org/packages/1e/df/19348ad703b5aceabe05dd557caf6e218962e784b19dfb08c17cd352ff51/mixupy-0.1.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}