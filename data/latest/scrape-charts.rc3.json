{
  "info": {
    "author": "Pranit_P_Shah",
    "author_email": "pranitpshah@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Natural Language :: English",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Scrape Charts\n\nFollow the steps completed in test_scraper.py (located in the tests folder or below). The virtual environment is not necessary, pip will download all required packagesdoes not need to be activited, but the import statements probably appear slightly differently, however comments will rectify your confusion on the correct string to paste.\n\nMain feature: scrape multiple charts from one website or multiple websites, and then turn it into one large list\n\nFeatures include:\n\n* Scraping a chart from a website or multiple websites\n* Choosing what charts you want from a website along with combining multiple websites' charts into one large chart\n* Processing that larger chart into a list\n* Cleaning that list\n* Cleaning the text with regex functions\n* No errors in the python package, eg. works out of the box\n* Converting that cleaned list into a panda dictionary\n* Converting that cleaned list into a dictionary\n* Saving that cleaned list as a json file, etc\n* A very friendly to use class that does everything for you\n* Return statements at every stage so that if one part doesn't work, you can see the data and process it yourself (a contingency, because if you contacted me, I would fix the issue)\n* A maintainer\n* No bugs or issues at the time of writing, (unit testing exists partially)\n* Regex functions that are explained below\n\n```Python\nfrom src.chart_scraper.ChartScraper import Scraper\n# Importing from pip can be done without the src\n\n# This is for educational purposes only, this code is example code, but not for usage\nchartScraper = Scraper(\"https://www.learnthat.org/pages/view/roots.html\", chartNumber=[2])\n# At this stage. chartScraper.combinedCharts hold this one mega list, so you can manually change one or two things, however this isn't necessary, the following code below will still work as if nothing happened\nchartScraper.cleanList(whichToKeep=\"[a-zA-Z0-9 ]+\", whereToSplit=\"\\(|,\", whereToCombine=\"/\", whereToClean=[[\" -\", \":\"],[\";\", \",\"], [\"[^a-zA-Z ,:]+\", \"\"], [\" +\", \" \"]])\nchartScraper.listToDict(includePrintStatement=False)\nchartScraper.getDictKeys(includePrintStatement=False)\n# All lowercase\nchartScraper.findWordComponents(\"philology\")\nchartScraper.createDataFrame()\nchartScraper.saveFiles(fileType=2)\n```\n\n```Python\nchartScraper.cleanList(whichToKeep=\"[a-zA-Z0-9]+\", whereToSplit=\"\\(|,\", whereToCombine=\"/\", whereToClean=[[\" -\", \":\"],[\";\", \",\"], [\"[^a-zA-Z ,:]+\", \"\"], [\" +\", \" \"]])\n# whichToKeep=\"[a-zA-Z0-9 ]+\" removes strings that don't contain either letters (a-z, A-Z) or numbers (0-9, eg. the larger number 123 works)\n# whereToSplit=\"\\(|,\" splits the string whenever there is a parantehsis or comma, the paranthesis is backslashed because regex requires it\n# whereToCombine=\"/\" combines a/b/c into [\"a\", \"ab\", \"ac\"], my niche case required it when I built this package\n# whereToClean=[[\" -\", \":\"],[\";\", \",\"], [\"[^a-zA-Z ,:]+\", \"\"], [\" +\", \" \"]]\n# [\" -\", \":\"] turns any \" -\" into \":\"\n# Likewise, [\";\", \",\"] converts \";\" into \",\"\n# [\"[^a-zA-Z ,:]+\", \"\"] removes characters that aren't letters (a-z, A-z), spaces (\" \"), commas (,), or colons (:)\n# [\" +\", \" \"] rectifies the issue of multiple spaces into one space, eg \"            \" into \" \"\n```\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/Pshah2023/scrape_charts",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "scrape-charts",
    "package_url": "https://pypi.org/project/scrape-charts/",
    "platform": "",
    "project_url": "https://pypi.org/project/scrape-charts/",
    "project_urls": {
      "Bug Tracker": "https://github.com/Pshah2023/scrape_charts/issues",
      "Homepage": "https://github.com/Pshah2023/scrape_charts"
    },
    "release_url": "https://pypi.org/project/scrape-charts/1.2.0/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "Scrape a websites chart into either a list, dict, or pandas dataframe",
    "version": "1.2.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 10983301,
  "releases": {
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "972d2f0ed4589448121255344de1915699bd24be42e45f2acb214de58472b160",
          "md5": "23466cb2caee32bc5c912e155234d561",
          "sha256": "7b2fa493b52fb9edfadba1acb69cc448f9befc36f50320ea6731d93a12513b4f"
        },
        "downloads": -1,
        "filename": "scrape_charts-1.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "23466cb2caee32bc5c912e155234d561",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 16094,
        "upload_time": "2021-07-22T01:19:52",
        "upload_time_iso_8601": "2021-07-22T01:19:52.630783Z",
        "url": "https://files.pythonhosted.org/packages/97/2d/2f0ed4589448121255344de1915699bd24be42e45f2acb214de58472b160/scrape_charts-1.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c39ae192d7fd553f32d4e0afec39e31f24ff278e3732caf775135d248bec7685",
          "md5": "c50902dd35899bbfdbd82d52c088a4cd",
          "sha256": "a3d230b8205f11cf9e22105dde2ee00a5cc66064acd4491b765dc3015dc95bc4"
        },
        "downloads": -1,
        "filename": "scrape_charts-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "c50902dd35899bbfdbd82d52c088a4cd",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 15791,
        "upload_time": "2021-07-22T01:19:55",
        "upload_time_iso_8601": "2021-07-22T01:19:55.142639Z",
        "url": "https://files.pythonhosted.org/packages/c3/9a/e192d7fd553f32d4e0afec39e31f24ff278e3732caf775135d248bec7685/scrape_charts-1.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "80d35b8b1f0a26ebe0ac5c69377fe1d3fef125b92632b147d7c54e4ef1742532",
          "md5": "531c33e8df23651db8e0c17580d1527a",
          "sha256": "e86d579eed4eba06a945864f3d5947201f748acc81cb7c650783e601633d2ce7"
        },
        "downloads": -1,
        "filename": "scrape_charts-1.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "531c33e8df23651db8e0c17580d1527a",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 18108,
        "upload_time": "2021-07-23T04:09:46",
        "upload_time_iso_8601": "2021-07-23T04:09:46.560258Z",
        "url": "https://files.pythonhosted.org/packages/80/d3/5b8b1f0a26ebe0ac5c69377fe1d3fef125b92632b147d7c54e4ef1742532/scrape_charts-1.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "73f040f61810fa3c63df0235b0b8aa34fd01bc3114daaf2743a6105f49ea0f7c",
          "md5": "b17e2d66b8dc9262fafb91b96f18dbcc",
          "sha256": "325baa67a51141be21b271b4bc8c209b067a13e38e9d3294a360fc2eda51ebfd"
        },
        "downloads": -1,
        "filename": "scrape_charts-1.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "b17e2d66b8dc9262fafb91b96f18dbcc",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 17859,
        "upload_time": "2021-07-23T04:09:48",
        "upload_time_iso_8601": "2021-07-23T04:09:48.478273Z",
        "url": "https://files.pythonhosted.org/packages/73/f0/40f61810fa3c63df0235b0b8aa34fd01bc3114daaf2743a6105f49ea0f7c/scrape_charts-1.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0e4b34ab5f4436dac1f8e809e87e37f7c5209c432f6d2480fa0b7c145ee6650a",
          "md5": "3388000c175ba340a914ab3b7a058d6e",
          "sha256": "7a1dc35ba15fecbdc0ce4a3d0d26d6fbd0e57fd223924f2b99978300bd7fc6ef"
        },
        "downloads": -1,
        "filename": "scrape_charts-1.2.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "3388000c175ba340a914ab3b7a058d6e",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 18180,
        "upload_time": "2021-07-23T04:19:16",
        "upload_time_iso_8601": "2021-07-23T04:19:16.445672Z",
        "url": "https://files.pythonhosted.org/packages/0e/4b/34ab5f4436dac1f8e809e87e37f7c5209c432f6d2480fa0b7c145ee6650a/scrape_charts-1.2.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bcc3d77d655649cb29b8456a39cab16a0730ab2d0321c4bc8d1994a1ab14e99a",
          "md5": "ca68b06d63df5544807a64dedab643aa",
          "sha256": "291f5a3d81e99d75afc3d2a05f8c6a5b8d3efca50b3356fd2609f9782490d95b"
        },
        "downloads": -1,
        "filename": "scrape_charts-1.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "ca68b06d63df5544807a64dedab643aa",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 17922,
        "upload_time": "2021-07-23T04:19:18",
        "upload_time_iso_8601": "2021-07-23T04:19:18.476948Z",
        "url": "https://files.pythonhosted.org/packages/bc/c3/d77d655649cb29b8456a39cab16a0730ab2d0321c4bc8d1994a1ab14e99a/scrape_charts-1.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "0e4b34ab5f4436dac1f8e809e87e37f7c5209c432f6d2480fa0b7c145ee6650a",
        "md5": "3388000c175ba340a914ab3b7a058d6e",
        "sha256": "7a1dc35ba15fecbdc0ce4a3d0d26d6fbd0e57fd223924f2b99978300bd7fc6ef"
      },
      "downloads": -1,
      "filename": "scrape_charts-1.2.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "3388000c175ba340a914ab3b7a058d6e",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 18180,
      "upload_time": "2021-07-23T04:19:16",
      "upload_time_iso_8601": "2021-07-23T04:19:16.445672Z",
      "url": "https://files.pythonhosted.org/packages/0e/4b/34ab5f4436dac1f8e809e87e37f7c5209c432f6d2480fa0b7c145ee6650a/scrape_charts-1.2.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "bcc3d77d655649cb29b8456a39cab16a0730ab2d0321c4bc8d1994a1ab14e99a",
        "md5": "ca68b06d63df5544807a64dedab643aa",
        "sha256": "291f5a3d81e99d75afc3d2a05f8c6a5b8d3efca50b3356fd2609f9782490d95b"
      },
      "downloads": -1,
      "filename": "scrape_charts-1.2.0.tar.gz",
      "has_sig": false,
      "md5_digest": "ca68b06d63df5544807a64dedab643aa",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 17922,
      "upload_time": "2021-07-23T04:19:18",
      "upload_time_iso_8601": "2021-07-23T04:19:18.476948Z",
      "url": "https://files.pythonhosted.org/packages/bc/c3/d77d655649cb29b8456a39cab16a0730ab2d0321c4bc8d1994a1ab14e99a/scrape_charts-1.2.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}