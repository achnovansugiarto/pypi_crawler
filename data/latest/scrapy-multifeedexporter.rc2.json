{
  "info": {
    "author": "Gabriel Birke",
    "author_email": "gb@birke-software.de",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Environment :: No Input/Output (Daemon)",
      "Framework :: Scrapy",
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python"
    ],
    "description": "scrapy-multifeedexporter\n========================\n\nThis `Scrapy <http://scrapy.org/>`__ extension exports scraped items of\ndifferent types to multiple feeds. By default each item gets its own\nfeed.\n\nInstallation\n------------\n\n.. code-block:: bash\n\n    $ pip install scrapy-multifeedexporter\n\nConfiguration\n-------------\n\nYou'll have to switch the default ``FeedExporter`` with\n``MultiFeedExporter`` by adding the following lines to the\n``settings.py`` file of your spider:\n\n.. code:: python\n\n    from multifeedexporter import MultiFeedExporter\n\n    EXTENSIONS = {\n        'scrapy.contrib.feedexport.FeedExporter': None,\n        'multifeedexporter.MultiFeedExporter': 500,\n    }\n\n    # Automatically configure available item names from your module\n    MULTIFEEDEXPORTER_ITEMS = MultiFeedExporter.get_bot_items(BOT_NAME)\n\nUsage\n-----\n\nWhen calling ``scrapy crawl`` you need to use the ``%(item_name)s``\nplaceholder in the output file/URI name. The following calls to\n``scrapy crawl`` demonstrate the placeholder:\n\n.. code:: bash\n\n    $ scrapy crawl -o \"spider_name_%(item_name)s.csv\" -t csv spider_name\n    $ scrapy crawl -o \"ftp://foo:bar@example.com/spider_name_%(item_name)s.csv\" -t csv spider_name\n\nIf you omit the placeholder, all items will be placed in one file.\n\nLicense\n-------\n\nscrapy-multifeedexporter is published under MIT license",
    "description_content_type": null,
    "docs_url": null,
    "download_url": null,
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "http://github.com/gbirke/scrapy-multifeedexporter",
    "keywords": "scrapy crawl scraping",
    "license": "The MIT License (MIT)",
    "maintainer": null,
    "maintainer_email": null,
    "name": "scrapy-multifeedexporter",
    "package_url": "https://pypi.org/project/scrapy-multifeedexporter/",
    "platform": "Any",
    "project_url": "https://pypi.org/project/scrapy-multifeedexporter/",
    "project_urls": {
      "Homepage": "http://github.com/gbirke/scrapy-multifeedexporter"
    },
    "release_url": "https://pypi.org/project/scrapy-multifeedexporter/0.1.1/",
    "requires_dist": null,
    "requires_python": null,
    "summary": "Export scraped items of different types to multiple feeds.",
    "version": "0.1.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 1250560,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "aadbd39ff24f9bec5bdc63fc05a87d5106b7d4a0df684045e9129490aa215367",
          "md5": "47f9382d1863b2389159b0479ce9114a",
          "sha256": "fc19904e4e956b5f2ce785a1f85a328aef54f00a3f1f31062a3a7c1843ae2386"
        },
        "downloads": -1,
        "filename": "scrapy-multifeedexporter-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "47f9382d1863b2389159b0479ce9114a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 2655,
        "upload_time": "2014-09-04T11:42:51",
        "upload_time_iso_8601": "2014-09-04T11:42:51.394951Z",
        "url": "https://files.pythonhosted.org/packages/aa/db/d39ff24f9bec5bdc63fc05a87d5106b7d4a0df684045e9129490aa215367/scrapy-multifeedexporter-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "49959956776a86f0c2318a0ab33fa7b3897bb571e0932bad39f79db809b6bdd7",
          "md5": "235617822829e0ae92424e76633aceff",
          "sha256": "6bf3fc7d192b68dbe1b33d823da89298a234af95f7b346cbb2cf3edf9c6378d3"
        },
        "downloads": -1,
        "filename": "scrapy-multifeedexporter-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "235617822829e0ae92424e76633aceff",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 2659,
        "upload_time": "2014-10-07T13:25:51",
        "upload_time_iso_8601": "2014-10-07T13:25:51.300985Z",
        "url": "https://files.pythonhosted.org/packages/49/95/9956776a86f0c2318a0ab33fa7b3897bb571e0932bad39f79db809b6bdd7/scrapy-multifeedexporter-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "49959956776a86f0c2318a0ab33fa7b3897bb571e0932bad39f79db809b6bdd7",
        "md5": "235617822829e0ae92424e76633aceff",
        "sha256": "6bf3fc7d192b68dbe1b33d823da89298a234af95f7b346cbb2cf3edf9c6378d3"
      },
      "downloads": -1,
      "filename": "scrapy-multifeedexporter-0.1.1.tar.gz",
      "has_sig": false,
      "md5_digest": "235617822829e0ae92424e76633aceff",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 2659,
      "upload_time": "2014-10-07T13:25:51",
      "upload_time_iso_8601": "2014-10-07T13:25:51.300985Z",
      "url": "https://files.pythonhosted.org/packages/49/95/9956776a86f0c2318a0ab33fa7b3897bb571e0932bad39f79db809b6bdd7/scrapy-multifeedexporter-0.1.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}