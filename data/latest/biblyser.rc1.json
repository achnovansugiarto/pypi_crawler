{
  "info": {
    "author": "Penelope How",
    "author_email": "pho@geus.dk",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: MIT License",
      "Natural Language :: English",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Topic :: Scientific/Engineering"
    ],
    "description": "# Biblyser\n\n[![Documentation Status](https://readthedocs.org/projects/biblyser/badge/?version=latest)](https://biblyser.readthedocs.io/en/latest/?badge=latest)\n\n**Biblyser** is an object-oriented Python workflow for computing and analysing bibliometrics for an individual or organisation.\n\nThere are four key objects within Biblyser:\n\n+ **Name**, which holds information about an individual author\n+ **Organisation**, which represents a collection of **Name** objects\n+ **Bib**, which hold information about a publication\n+ **BibCollection**, which represents a collection of **Bib** objects\n\n\n## Quick start\nBiblyser can either be installed with pip or clones from the Github repository.\n\n```python\npip install biblyser\n```\n\n```python\ngit clone https://github.com/GEUS-Glaciology-and-Climate/Biblyser \n```\n\nWhen cloning from the Github repository, you will need to create a conda environment with the required package dependencies by installing the Biblyser's dependencies using pip.\n\n```python\npip install pybyliometrics, habanero, scholarly, gender_guesser, pandas, beautifulsoup4\n```\n\nTry running one of the example scripts from the repository to see that it works. To access the Scopus API through the pybliometrics package, you will need to configure your API key.\n\n```python\n# Set up Scopus configuration (only needs to be done once)\nimport pybliometrics\npybliometrics.scopus.utils.create_config()\n```\n\nAn API key or Insttoken is needed to use the Scopus API. An API key can be generated through the Elsevier Developer Portal [here](https://dev.elsevier.com/apikey/manage), which can be used to access all authors and publications within your organisation when in your network or through VPN access. If accessing this from within the network is challenging, then an Insttoken can be requested by contacting Elsevier directly. \n\nAfter this initial set-up, no editing of the example scripts should be needed - the scripts should run as they are. If they don't, there is likely an issue with your python environment.\n\n\n## Name.py\nThe Name object holds attributes about an individual to aid in searching for associated publications. This can be initialised using an individual's full name, with job title and gender as optional inputs, and additional keyword inputs for Orcid ID, Scopus ID, Google Scholar ID, and h-index. \n\n```python\nfrom biblyser.name import Name\n\nn = Name('Jane Emily Doe') \t\t#With fullname string\nn = Name (['Jane','Emily','Doe']) \t#With first, middle and last name as list\n\nn = Name('Jane Emily Doe', \t\n\t 'Forsker',\n\t 'female',\n\t orcid='0000-0001-2345-6789')  #With additional information\n```\n\nVarious name and initial formats are computed from Name object, which maximise the chance of finding all associated publications. The gender of each name can either be provided during initialisatoin, or guessed using `gender_guesser`. The gender definition is used later on to analyse gender distribution in a **BibCollection**.\n\n\n## Organisation.py\nThe Organisation object holds a collection of **Name** objects which represent a group of authors, department, or organisation. The GEUS G&K organisation can be fetched either from the GEUS G&K Pure portal (only retrieves registered authors) or from the staff directory webpage (all G&K members). This information is fed directly into an Organisation object.\n\n```python\nfrom biblyser.organisation import Organisation, fetchWebInfo\nfrom bs4 import BeautifulSoup\n\ndef fetchWebInfo(url, parser, fid, classtype, classid):\n    '''Get all up-to-date information (e.g. names, titles) from a given webpage\n    element id and class'''\n    page = requests.get(url)\n    soup = BeautifulSoup(page.content, parser)\n    results = soup.find(id=fid)\n    elements = results.find_all(classtype, class_=classid)\n    return elements\n\n#Get names and titles from GEUS Pure webpage\nURL = \"https://pub.geus.dk/da/organisations/department-of-glaciology-and-climate/persons/\"\ninfo = fetchWebInfo(URL, 'html.parser', 'main-content', 'div', \n                    'rendering rendering_person rendering_short rendering_person_short')\nnames=[]\ntitles=[]\n[names.append(str(e).split('span')[1].split('<')[0].split('>')[1]) for e in info]\n[titles.append(str(e).split('span')[5].split('<')[0].split('- ')[1]) for e in info]\n\n\n#Get names and titles from GEUS staff webpage\nURL = \"https://www.geus.dk/om-geus/kontakt/telefonbog?departmentId=Glaciologi+og+Klima\"\nnames = fetchWebInfo(URL, 'html.parser', 'gb_ContentPlaceHolderDefault_bottomGrid_ctl03', \n                     'td', 'contact-name')\ntitles = fetchWebInfo(URL, parser, fid, classtype, None)\ntitles = info[:][4]\n\n#Define organisation\norg = Organisation(names, titles)               \n```\n\nThe Organisation object has a checker, which requires user input to manually edit Name objects - this is especially useful in cases of abnormal surname structures and mis-gendered Names. Once satisfied with the information held in the Organisation object, the Organisation object can be populated with missing information from Scopus and Scholar. The final populated object can either be written out of the object as a DataFrame, or carried forward and used to gather bib information as a **BibCollection**.\n\n```python\n#Organisation checker\norg.checkNames()\n\n#Populate author info from Scopus and Scholar                         \norg.populateOrg()\n\n#Write Organisation attributes to DataFrame\ndf = org.asDataFrame()\n```\n\n\n## Bib.py\nA Bib object holds the relevant information associated with a single publication, namely:\n\n+ DOI\n+ Publication title\n+ Authors (held as **Name** objects)\n+ Date of publication\n+ Journal title\n+ Publication type\n+ Gender metrics \n+ Citation count\n+ Altmetric record\n\nA Bib object can either be initiated from a doi string, a title string, or from an author/organisation (as part of a **BibCollection**, see relevant section).\n\n```python\nfrom biblyser.bib import Bib\n\n#Bib object from doi string\npub = Bib(doi='10.5194/tc-11-2691-2017') \t\t\n\n#Bib object from publication title\npub = Bib(title='PyTrx: A Python-Based Monoscopic Terrestrial Photogrammetry Toolset for Glaciology')\n```\n\nBib attributes are populated using the Scopus API provided by [pybliometrics](https://pybliometrics.readthedocs.io/en/stable/), CrossRef API provided by [habanero](https://habanero.readthedocs.io/en/latest/index.html), and/or the Google Scholar API [scholarly](https://scholarly.readthedocs.io/en/stable/quickstart.html).\n\nAuthorship of a publication can be queried within the Bib object, including queries by organisation and (guessed) gender.\n\n\n## BibCollection.py\nA BibCollection object holds a collection of **Bib** objects, i.e. a database of all associated or selected publications. A BibCollection can be initialised from an **Organisation** (for which the BibCollection will search for all publications linked to each name in the organisation), a list of **Bib** objects, or a list of doi strings.\n\n```python\nfrom biblyser.organisation import Organisation\nfrom biblyser.bibCollection import BibCollection\n\n\n#BibCollection from an Organisation\nnames = ['Penelope How', 'Kristin Schild']\ntitles = ['AC-medarbejder', 'Forsker']\norg = Organisation(names, titles)\npubs = BibCollection(org)\n\n#Search for bibs in selected databases\nbibs.getScholarBibs()                           #From Google Scholar\nbibs.getScopusBibs()                            #From Scopus (Pure)\n\n\n#BibCollection from list of Bib objects\ntitles=['PyTrx: A Python-Based Monoscopic Terrestrial Photogrammetry Toolset for Glaciology',\n\t'Glacier calving rates due to subglacial discharge, fjord circulation, and free convection']\nbibs=[]\n[bibs.append(Bib(title=t)) for t in titles]\npubs = BibCollection(bibs)\n\n\n#BibCollection from list of doi strings\ndois = ['10.3389/feart.2020.00021', '10.1029/2017JF004520']\npubs = BibCollection(dois)\n```\n\nConstructing a BibCollection from an **Organisation** can create duplicates due to common authorships, and create false publications due to common names and tags. Duplicates, false matches and unwanted publications (e.g. conference abstracts, discussion papers) can be removed using the filtering functions provided in the BibCollection objects. \n\n```python\n#Remove abstracts and discussion papers\nbibs.removeAbstracts()                          \nbibs.removeDiscussions()                       \n\n#Remove duplicates\nbibs.removeDuplicates()                         \n```\n\nA BibCollection can also be written out of the object as a DataFrame if further inspection is needed\n\n```python\n#Check bibs\nbibs.checkBibs()\n\n#Remove duplicates\nbibs.removeDuplicates()\n\n#Write BibCollection attributes to DataFrame\ndf = bibs.asDataFrame()\n```\n\n## Computing gender metrics\nGenders of each author within the Bib object are firstly guessed, and if the guessed gender is not certian then a gender database is used to check if the author and an associated gender exists. This database is an Organisation object, retaining all information about each author's name and gender. If a name is not found in the database then the user is prompted to manually define the gender, and then retains this new addition. \n\n```python\nimport copy\n\n#Set up gender database using pre-existing organisation\ngdb = copy.copy(org)\n\n#Guess genders for all co-authors in BibCollection\nbibs.getAllGenders(gdb)\n```\n\n## Further development we are working on\n+ Incorporation of other search APIs for publications, such as [Web Of Science](https://pypi.org/project/wos/)\n+ Fetch journal impact factor\n+ Add \"time from PhD\" attribute to Name object\n+ Incorporate abstracts to Bib objects and enable keyword searches\n\nAnd contributions are welcome!\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/GEUS-Glaciology-and-Climate/Biblyser",
    "keywords": "publications citations academia science bibliometrics",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "biblyser",
    "package_url": "https://pypi.org/project/biblyser/",
    "platform": "",
    "project_url": "https://pypi.org/project/biblyser/",
    "project_urls": {
      "Bug Tracker": "https://github.com/GEUS-Glaciology-and-Climate/Biblyser/issues",
      "Homepage": "https://github.com/GEUS-Glaciology-and-Climate/Biblyser"
    },
    "release_url": "https://pypi.org/project/biblyser/0.0.1/",
    "requires_dist": [
      "gender-guesser",
      "habanero",
      "numpy",
      "pandas",
      "pybliometrics",
      "scholarly"
    ],
    "requires_python": ">=3.7",
    "summary": "A bibliometric workflow for evaluating the bib metrics of an individual or group of people",
    "version": "0.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12383192,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e7564ed38f8240bf7e1b9f0a6f6baa668e4cc6dc952af5a27ae24e2dbe54e463",
          "md5": "cc7871e535e6aa463461d61ff2d53d06",
          "sha256": "52bbf19c5288a8e380172f2aa8a3024eeb0c231d4fbc356192f7b93dc04f6d6d"
        },
        "downloads": -1,
        "filename": "biblyser-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "cc7871e535e6aa463461d61ff2d53d06",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 23074,
        "upload_time": "2021-12-22T17:17:13",
        "upload_time_iso_8601": "2021-12-22T17:17:13.999411Z",
        "url": "https://files.pythonhosted.org/packages/e7/56/4ed38f8240bf7e1b9f0a6f6baa668e4cc6dc952af5a27ae24e2dbe54e463/biblyser-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f5c825d057ad055f563659a2d29b0afa1186660b4ab9e57c156aeab0c040f823",
          "md5": "226e6ff809fdba5bbd3b62d8171489fb",
          "sha256": "392cf2d738debaab71a21596df584bddff2518510f962d1c130b916c71578332"
        },
        "downloads": -1,
        "filename": "biblyser-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "226e6ff809fdba5bbd3b62d8171489fb",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 24377,
        "upload_time": "2021-12-22T17:17:15",
        "upload_time_iso_8601": "2021-12-22T17:17:15.639485Z",
        "url": "https://files.pythonhosted.org/packages/f5/c8/25d057ad055f563659a2d29b0afa1186660b4ab9e57c156aeab0c040f823/biblyser-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "e7564ed38f8240bf7e1b9f0a6f6baa668e4cc6dc952af5a27ae24e2dbe54e463",
        "md5": "cc7871e535e6aa463461d61ff2d53d06",
        "sha256": "52bbf19c5288a8e380172f2aa8a3024eeb0c231d4fbc356192f7b93dc04f6d6d"
      },
      "downloads": -1,
      "filename": "biblyser-0.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "cc7871e535e6aa463461d61ff2d53d06",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 23074,
      "upload_time": "2021-12-22T17:17:13",
      "upload_time_iso_8601": "2021-12-22T17:17:13.999411Z",
      "url": "https://files.pythonhosted.org/packages/e7/56/4ed38f8240bf7e1b9f0a6f6baa668e4cc6dc952af5a27ae24e2dbe54e463/biblyser-0.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "f5c825d057ad055f563659a2d29b0afa1186660b4ab9e57c156aeab0c040f823",
        "md5": "226e6ff809fdba5bbd3b62d8171489fb",
        "sha256": "392cf2d738debaab71a21596df584bddff2518510f962d1c130b916c71578332"
      },
      "downloads": -1,
      "filename": "biblyser-0.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "226e6ff809fdba5bbd3b62d8171489fb",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 24377,
      "upload_time": "2021-12-22T17:17:15",
      "upload_time_iso_8601": "2021-12-22T17:17:15.639485Z",
      "url": "https://files.pythonhosted.org/packages/f5/c8/25d057ad055f563659a2d29b0afa1186660b4ab9e57c156aeab0c040f823/biblyser-0.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}