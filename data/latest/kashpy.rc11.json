{
  "info": {
    "author": "Ralph M. Debusmann",
    "author_email": "matthias.debusmann@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: Apache Software License",
      "Programming Language :: Python :: 3.6",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "# kash.py\n\n*kash.py* is a Kafka shell based on Python, or, in other words, a Python-based client library for Kafka based on [confluent-kafka-python](https://github.com/confluentinc/confluent-kafka-python) by Magnus Edenhill, which is itself based on the native Kafka client library [librdkafka](https://github.com/edenhill/librdkafka) by the same author.\n\nThe idea behind *kash.py* is to make it as easy as possible to interact with Kafka using Python, without having to know any of the implementation details of the underlying [confluent-kafka-python](https://github.com/confluentinc/confluent-kafka-python) module. To this end, not only are the functions/methods are simpler to use, but also all classes are converted to simple Python types like tuples and dictionaries. As a result, development chores that took numerous of lines of boilerplate code before can be formulated as one-liners, both in interactive mode using the Python REPL, or within convenient scripts.\n\n*kash.py* has been built for Kafka users of all kinds:\n* For *developers and devops engineers* to view and manipulate Kafka topics using familiar shell syntax (you have *ls*, *touch*, *rm*, *cp*, *cat*, *grep*, *wc* etc.).\n* For *data scientists* to bridge the gap between batch and stream processing, using functions to upload/download files to/from topics, and even functional abstractions a la Databricks/Apache Spark (there are various *foldl*s, *flatmap*s and *map*s for you to explore).\n\n*kash.py* supports *Avro*, *Protobuf* and *JSONSchema*, Confluent Cloud, Redpanda, etc...and it will give you *Kafka superpowers* of a kind you have never experienced before. Honestly :)\n\nCheck out the full [kashpy package documentation](https://github.com/xdgrulez/kash.py/blob/main/docs/_build/markdown/source/kashpy.md) if you are interested in seeing the entire functionality of *kash.py*.\n\n## Installation\n\nJust write...\n```\npip install kashpy\n```\n...and off you go.\n\n## Configuration\n\n*kash.py* makes use of configuration files suffixed `.yaml` which are being searched for in the folder `clusters`, starting 1) from the directory in the `KASHPY_HOME` environment variable, or, if that environment variable is not set, 2) from the current directory.\n\nFor the YAML-based configuration files sporting environment variable interpolation, *kash.py* makes use of the ingenious little library [Piny](https://github.com/pilosus/piny) from Vitaly Samigullin (see also his illustrative [blog](https://blog.pilosus.org/posts/2019/06/07/application-configs-files-or-environment-variables-actually-both/) about the genesis of Piny).\n\nA barebones configuration file looks like this (including Schema Registry):\n\n```\nkafka:\n  bootstrap.servers: localhost:9092\n\nschema_registry:\n  schema.registry.url: http://localhost:8081\n```\n\nYou can also set some of the defaults of *kash.py* in the `kash` section like this:\n\n```\nkash:\n  flush.num.messages: 10000\n  flush.timeout: -1.0\n  retention.ms: -1\n  consume.timeout: 1.0\n  auto.offset.reset: earliest\n  enable.auto.commit: true\n  session.timeout.ms: 10000\n  progress.num.messages: 1000\n  block.num.retries.int: 50\n  block.interval: 0.1\n```\n\nYou can find an in-depth explanation of these settings in the [kashpy package documentation](https://github.com/xdgrulez/kash.py/blob/main/docs/_build/markdown/source/kashpy.md), including example configuration files for connecting to [Confluent Cloud](https://www.confluent.io/confluent-cloud/), [Redpanda](https://redpanda.com/) etc.\n\n## Kafka Made Simple\n\nFor interactive use, e.g. using your local cluster configured in the file `clusters/local.yaml`, just do the following to list the topics:\n```\n$ python3\n>>> from kashpy.kash import *\n>>> c = Cluster(\"local\")\n>>> c.ls()\n['__consumer_offsets', '_schemas']\n>>>\n```\n\nOr, if you'd like to replicate the topic `test` holding 1000 messages from a Kafka cluster `local` on your local machine to a Kafka cluster `ccloud` on Confluent Cloud:\n```\n>>> c_local = Cluster(\"local\")\n>>> c_ccloud = Cluster(\"ccloud\")\n>>> c.cp(c_local, \"test\", c_ccloud, \"test\")\n(1000, 1000)\n>>>\n```\n\nIn the following, we go a bit deeper in two short tutorials; the first demonstrating how *kash.py* helps you to fulfill tasks on a single cluster, and the second how to make use of your newly obtained Kafka superpowers across clusters.\n\n## Tutorial 1 (single cluster)\n\nThis is the first tutorial, showcasing the single cluster capabilities of *kash.py* in interactive mode.\n\nLet's start Python, import kash.py and create a `Cluster` object `c`:\n```\n$ python3\n>>> from kashpy.kash import *\n>>> c = Cluster(\"local\")\n>>>\n```\n\nList the topics on the cluster:\n```\n>>> c.ls()\n['__consumer_offsets', '_schemas']\n>>>\n```\n\nCreate a new topic `snacks`:\n```\n>>> c.touch(\"snacks\")\n'snacks'\n>>> \n```\n\nList the topics on the cluster again:\n```\n>>> c.ls()\n['__consumer_offsets', '_schemas', 'snacks']\n>>>\n```\n\nUpload the following local file `snacks.txt` to the topic `snacks` (examples inspired by the great blog [Kafka with AVRO vs., Kafka with Protobuf vs., Kafka with JSON Schema](https://simon-aubury.medium.com/kafka-with-avro-vs-kafka-with-protobuf-vs-kafka-with-json-schema-667494cbb2af) by Simon Aubury):\n```\n{\"name\": \"cookie\", \"calories\": 500.0, \"colour\": \"brown\"}\n{\"name\": \"cake\", \"calories\": 260.0, \"colour\": \"white\"}\n{\"name\": \"timtam\", \"calories\": 80.0, \"colour\": \"chocolate\"}\n```\n\n```\n>>> c.cp(\"./snacks.txt\", \"snacks\")\n(3, 3)\n>>>\n```\n\nShow the contents of topic `snacks`:\n```\n>>> c.cat(\"snacks\")\n{'headers': None, 'partition': 0, 'offset': 0, 'timestamp': (1, 1678915066323), 'key': None, 'value': '{\"name\": \"cookie\", \"calories\": 500.0, \"colour\": \"brown\"}'}\n{'headers': None, 'partition': 0, 'offset': 1, 'timestamp': (1, 1678915066323), 'key': None, 'value': '{\"name\": \"cake\", \"calories\": 260.0, \"colour\": \"white\"}'}\n{'headers': None, 'partition': 0, 'offset': 2, 'timestamp': (1, 1678915066323), 'key': None, 'value': '{\"name\": \"timtam\", \"calories\": 80.0, \"colour\": \"chocolate\"}'}\n3\n>>> \n```\n\nIf you'd like to see the output of the values of the messages in an indented fashion, you can tell `kash.py` 1) that you'd like to pretty print the messages and 2) that the values have the type `json`:\n```\n>>> c.cat(\"snacks\", foreach_function=ppretty, value_type=\"json\")\n{\n  \"headers\": null,\n  \"partition\": 0,\n  \"offset\": 0,\n  \"timestamp\": [\n    1,\n    1678915066323\n  ],\n  \"key\": null,\n  \"value\": {\n    \"name\": \"cookie\",\n    \"calories\": 500.0,\n    \"colour\": \"brown\"\n  }\n}\n{\n  \"headers\": null,\n  \"partition\": 0,\n  \"offset\": 1,\n  \"timestamp\": [\n    1,\n    1678915066323\n  ],\n  \"key\": null,\n  \"value\": {\n    \"name\": \"cake\",\n    \"calories\": 260.0,\n    \"colour\": \"white\"\n  }\n}\n{\n  \"headers\": null,\n  \"partition\": 0,\n  \"offset\": 2,\n  \"timestamp\": [\n    1,\n    1678915066323\n  ],\n  \"key\": null,\n  \"value\": {\n    \"name\": \"timtam\",\n    \"calories\": 80.0,\n    \"colour\": \"chocolate\"\n  }\n}\n3\n>>> \n```\n\nCount the number of messages, words and bytes of the topic `snacks`:\n```\n>>> c.wc(\"snacks\")\n(3, 18, 169)\n>>>\n```\n\nFind those messages whose values matches the regular expression `.*cake.*`:\n```\n>>> c.grep(\"snacks\", \".*cake.*\")\nFound matching message on partition 0, offset 1.\n([{'headers': None, 'partition': 0, 'offset': 1, 'timestamp': (1, 1664989815680), 'key': None, 'value': '{\"name\": \"cake\", \"calories\": 260.0, \"colour\": \"white\"}'}], 1, 3)\n>>>\n```\n\nFilter the messages to only keep those where the ``colour`` is ``brown``:\n```\n>>> c.filter(\"snacks\", lambda x: x[\"value\"][\"colour\"] == \"brown\", value_type=\"json\")\n([{'headers': None, 'partition': 0, 'offset': 0, 'timestamp': (1, 1666090118747), 'key': None, 'value': {'name': 'cookie', 'calories': 500.0, 'colour': 'brown'}}], 3)\n>>>\n```\n\nCreate a new topic `snacks_protobuf`:\n```\n>>> c.touch(\"snacks_protobuf\")\n'snacks_protobuf'\n>>>\n```\n\nCopy the topic `snacks` onto another topic `snacks_protobuf` using Protobuf (and storing the schema in the Schema Registry):\n\n```\n>>> c.cp(\"snacks\", \"snacks_protobuf\", target_value_type=\"protobuf\", target_value_schema='message Snack { required string name = 1; required float calories = 2; optional string colour = 3; }')\n(3, 3)\n>>>\n```\n\nShow the contents of topic `snacks_protobuf` (showing the values directly as `bytes`):\n\n```\n>>> c.cat(\"snacks_protobuf\", value_type=\"bytes\")\n{'headers': None, 'partition': 0, 'offset': 0, 'timestamp': (1, 1664989815680), 'key': None, 'value': b'\\x00\\x00\\x00\\x00\\x03\\x00\\n\\x06cookie\\x15\\x00\\x00\\xfaC\\x1a\\x05brown'}\n{'headers': None, 'partition': 0, 'offset': 1, 'timestamp': (1, 1664989815680), 'key': None, 'value': b'\\x00\\x00\\x00\\x00\\x03\\x00\\n\\x04cake\\x15\\x00\\x00\\x82C\\x1a\\x05white'}\n{'headers': None, 'partition': 0, 'offset': 2, 'timestamp': (1, 1664989815680), 'key': None, 'value': b'\\x00\\x00\\x00\\x00\\x03\\x00\\n\\x06timtam\\x15\\x00\\x00\\xa0B\\x1a\\tchocolate'}\n>>>\n```\n\nShow the contents of the topic `snacks_protobuf` again (decoding the values using Protobuf and the Schema Registry):\n```\n>>> c.cat(\"snacks_protobuf\", value_type=\"protobuf\")\n{'headers': None, 'partition': 0, 'offset': 0, 'timestamp': (1, 1664989815680), 'key': None, 'value': {'name': 'cookie', 'calories': 500.0, 'colour': 'brown'}}\n{'headers': None, 'partition': 0, 'offset': 1, 'timestamp': (1, 1664989815680), 'key': None, 'value': {'name': 'cake', 'calories': 260.0, 'colour': 'white'}}\n{'headers': None, 'partition': 0, 'offset': 2, 'timestamp': (1, 1664989815680), 'key': None, 'value': {'name': 'timtam', 'calories': 80.0, 'colour': 'chocolate'}}\n3\n>>>\n```\n\nAgain, `kash.py` can give you a prettified indented output:\n```\n>>> c.cat(\"snacks_protobuf\", foreach_function=ppretty, value_type=\"protobuf\")\n{\n  \"headers\": null,\n  \"partition\": 0,\n  \"offset\": 0,\n  \"timestamp\": [\n    1,\n    1678915066323\n  ],\n  \"key\": null,\n  \"value\": {\n    \"name\": \"cookie\",\n    \"calories\": 500.0,\n    \"colour\": \"brown\"\n  }\n}\n{\n  \"headers\": null,\n  \"partition\": 0,\n  \"offset\": 1,\n  \"timestamp\": [\n    1,\n    1678915066323\n  ],\n  \"key\": null,\n  \"value\": {\n    \"name\": \"cake\",\n    \"calories\": 260.0,\n    \"colour\": \"white\"\n  }\n}\n{\n  \"headers\": null,\n  \"partition\": 0,\n  \"offset\": 2,\n  \"timestamp\": [\n    1,\n    1678915066323\n  ],\n  \"key\": null,\n  \"value\": {\n    \"name\": \"timtam\",\n    \"calories\": 80.0,\n    \"colour\": \"chocolate\"\n  }\n}\n3\n>>>\n```\n\nGet a diff of the two topics `snacks` and `snacks_protobuf`, comparing the dictionaries obtained by converting the string payload in `snacks` to Python dictionaries, and the Protobuf payload in `snacks_protobuf` to Python dictionaries as well:\n```\n>>> c.diff(\"snacks\", \"snacks_protobuf\", value_type1=\"json\", value_type2=\"protobuf\")\n([], 3, 3)\n>>>\n```\n\nNow we are getting functional - using a *foldl* operation to sum up the calories of the messages in `snacks`:\n```\n>>> c.foldl(\"snacks\", lambda acc, x: acc + x[\"value\"][\"calories\"], 0, value_type=\"json\")\n(840.0, 3)\n>>>\n```\n\nWe can also use a *flatmap* operation to get a list of all messages in `snacks` where each message is duplicated:\n```\n>>> c.flatmap(\"snacks\", lambda x: [x, x])\n([{'headers': None, 'partition': 0, 'offset': 0, 'timestamp': (1, 1664989815680), 'key': None, 'value': '{\"name\": \"cookie\", \"calories\": 500.0, \"colour\": \"brown\"}'}, {'headers': None, 'partition': 0, 'offset': 0, 'timestamp': (1, 1664989815680), 'key': None, 'value': '{\"name\": \"cookie\", \"calories\": 500.0, \"colour\": \"brown\"}'}, {'headers': None, 'partition': 0, 'offset': 1, 'timestamp': (1, 1664989815680), 'key': None, 'value': '{\"name\": \"cake\", \"calories\": 260.0, \"colour\": \"white\"}'}, {'headers': None, 'partition': 0, 'offset': 1, 'timestamp': (1, 1664989815680), 'key': None, 'value': '{\"name\": \"cake\", \"calories\": 260.0, \"colour\": \"white\"}'}, {'headers': None, 'partition': 0, 'offset': 2, 'timestamp': (1, 1664989815680), 'key': None, 'value': '{\"name\": \"timtam\", \"calories\": 80.0, \"colour\": \"chocolate\"}'}, {'headers': None, 'partition': 0, 'offset': 2, 'timestamp': (1, 1664989815680), 'key': None, 'value': '{\"name\": \"timtam\", \"calories\": 80.0, \"colour\": \"chocolate\"}'}], 3)\n>>>\n```\n\nNext, we use a *map* operation to add the suffix `ish` to all the colours:\n```\n>>> def map_function(x):\n...   x[\"value\"][\"colour\"] += \"ish\"\n...   return x\n... \n>>> c.map(\"snacks\", map_function, value_type=\"json\")\n([{'headers': None, 'partition': 0, 'offset': 0, 'timestamp': (1, 1664989815680), 'key': None, 'value': {'name': 'cookie', 'calories': 500.0, 'colour': 'brownish'}}, {'headers': None, 'partition': 0, 'offset': 1, 'timestamp': (1, 1664989815680), 'key': None, 'value': {'name': 'cake', 'calories': 260.0, 'colour': 'whiteish'}}, {'headers': None, 'partition': 0, 'offset': 2, 'timestamp': (1, 1664989815680), 'key': None, 'value': {'name': 'timtam', 'calories': 80.0, 'colour': 'chocolateish'}}], 3)\n>>>\n```\n\nAnd last, but not least, we copy the topic `snacks` back to a local file `snacks1.txt` while both duplicating the messages and adding the suffix `ish` to all the colours:\n```\n>>> def flatmap_function(x):\n...   x[\"value\"][\"colour\"] += \"ish\"\n...   return [x, x]\n... \n>>> c.flatmap_to_file(\"snacks\", \"./snacks1.txt\", flatmap_function, value_type=\"json\")\n(3, 6)\n>>>\n```\n\nThe resulting file `snacks1.txt` looks like this:\n```\n{\"name\": \"cookie\", \"calories\": 500.0, \"colour\": \"brownish\"}\n{\"name\": \"cookie\", \"calories\": 500.0, \"colour\": \"brownish\"}\n{\"name\": \"cake\", \"calories\": 260.0, \"colour\": \"whiteish\"}\n{\"name\": \"cake\", \"calories\": 260.0, \"colour\": \"whiteish\"}\n{\"name\": \"timtam\", \"calories\": 80.0, \"colour\": \"chocolateish\"}\n{\"name\": \"timtam\", \"calories\": 80.0, \"colour\": \"chocolateish\"}\n```\n\n## Tutorial 2 (cross-cluster)\n\nThis is the second tutorial, showcasing the cross-cluster capabilities of *kash.py* in interactive mode.\n\nFirst, let's start Python, import kash.py and let's see what clusters we have defined in our `clusters` directory:\n```\n$ python3\n>>> from kashpy.kash import *\n>>> clusters()\n['ccloud', 'local', 'redpanda']\n```\n\nNext, we create a `Cluster` object `c1`:\n```\n>>> c1 = Cluster(\"local\")\n>>>\n```\n\nCreate a new topic `snacks1` on cluster c1:\n```\n>>> c1.touch(\"snacks1\")\n'snacks1'\n>>>\n```\n\nUpload the following local file `snacks.txt` to the topic `snacks1` on cluster c1:\n```\n{\"name\": \"cookie\", \"calories\": 500.0, \"colour\": \"brown\"}\n{\"name\": \"cake\", \"calories\": 260.0, \"colour\": \"white\"}\n{\"name\": \"timtam\", \"calories\": 80.0, \"colour\": \"chocolate\"}\n```\n\n```\n>>> c1.cp(\"./snacks.txt\", \"snacks1\")\n(3, 3)\n```\n\nCreate a new `Cluster` object `c2`:\n```\n>>> c2 = Cluster(\"ccloud\")\n>>>\n```\n\nCreate a new topic `snacks2` on `c2`:\n```\n>>> c2.touch(\"snacks2\")\n'snacks2'\n>>>\n```\n\nCopy the topic `snacks1` from cluster `c1` to topic `snacks2` on cluster `c2`:\n```\n>>> cp(c1, \"snacks1\", c2, \"snacks2\")\n(3, 3)\n>>>\n```\n\nGet the diff from topic `snacks1` on cluster `c1` to a topic `snacks2` on cluster `c2`:\n```\n>>> diff(c1, \"snacks1\", c2, \"snacks2\")\n([], 3, 3)\n>>>\n```\n\nNow let's venture into the cross-cluster functional programming domain... let's copy topic `snacks1` on cluster `c1` to a topic  `snacks2_duplicate` on cluster `c2`, while duplicating each message using a *flatmap* operation:\n```\n>>> flatmap(c1, \"snacks1\", c2, \"snacks2_duplicate\", lambda x: [x, x])\n(3, 6)\n>>>\n```\n\nNext, we use a cross-cluster *map* operation to add the suffix `ish` to all the colours and produce the resulting messages to topic `snacks2_ish` on cluster `c2`:\n```\n>>> def map_function(x):\n...   x[\"value\"][\"colour\"] += \"ish\"\n...   return x\n... \n>>> map(c1, \"snacks1\", c2, \"snacks2_ish\", map_function, source_value_type=\"json\")\n(3, 3)\n>>>\n```\n\nNow for the most advanced operation of the tutorials: A *zip* of topic `snacks1` on cluster `c1` and topic `snacks2_ish` on cluster `c2` followed by a *foldl* accumulating pairs of those messages from both topics where the colour of the message from topic `snacks2_ish` ends with `eish`:\n\n```\n>>> def zip_foldl_function(acc, x1, x2):\n...   return acc + [(x1, x2)] if x2[\"value\"][\"colour\"].endswith(\"eish\") else acc\n... \n>>> zip_foldl(c1, \"snacks1\", c2, \"snacks2_ish\", zip_foldl_function, [], value_type2=\"json\")\n([({'headers': None, 'partition': 0, 'offset': 1, 'timestamp': (1, 1664989815680), 'key': None, 'value': b'{\"name\": \"cake\", \"calories\": 260.0, \"colour\": \"white\"}'}, {'headers': None, 'partition': 0, 'offset': 1, 'timestamp': (1, 1664989815680), 'key': None, 'value': {'name': 'cake', 'calories': 260.0, 'colour': 'whiteish'}}), ({'headers': None, 'partition': 0, 'offset': 2, 'timestamp': (1, 1664989815680), 'key': None, 'value': b'{\"name\": \"timtam\", \"calories\": 80.0, \"colour\": \"chocolate\"}'}, {'headers': None, 'partition': 0, 'offset': 2, 'timestamp': (1, 1664989815680), 'key': None, 'value': {'name': 'timtam', 'calories': 80.0, 'colour': 'chocolateish'}})], 3, 3)\n>>>\n```\n\n## kash.py and Functional Programming\n\nAs already hinted at in the tutorials above, the more advanced functionality of *kash.py* rests on a *Functional Programming* (*FP*) backbone. If you intend to use *kash.py* to ease your everyday tasks, you don't have to be aware of that - the bash-like abstractions on top of the functional backbone should already help you out a lot. However, if you are familiar with FP or you would like to become familiar with it, this functional backbone of *kash.py* can actually let you wield even stronger *Kafka superpowers*.\n\n### Single Cluster\n\n#### Kafka Topic to Python Datatype\n\nWe start with functional backbone of those functions which consume a Kafka topic and return a Python datatype. Those functions are based on the `foldl` (\"fold left\") function. `foldl` consumes messages from a topic and then, for each message, calls a function that takes this message and an accumulator of any type, and returns the updated accumulator. `foldl` can be used e.g. to aggregate information from topics, such as the sum of calories of the messages of the topic `snacks` in the following example:\n```\n>>> c.foldl(\"snacks\", lambda acc, x: acc + x[\"value\"][\"calories\"], 0, value_type=\"json\")\n(840.0, 3)\n>>>\n```\n\n`foldl` is the basis for `flatmap` which also consumes messages from a topic, but then calls a simpler function that takes just this message and returns a list of anything (including the empty list). `flatmap` can be used e.g. to duplicate the messages of a topic, as in the following example:\n```\n>>> c.flatmap(\"snacks\", lambda x: [x, x])\n([{'headers': None, 'partition': 0, 'offset': 0, 'timestamp': (1, 1664989815680), 'key': None, 'value': '{\"name\": \"cookie\", \"calories\": 500.0, \"colour\": \"brown\"}'}, {'headers': None, 'partition': 0, 'offset': 0, 'timestamp': (1, 1664989815680), 'key': None, 'value': '{\"name\": \"cookie\", \"calories\": 500.0, \"colour\": \"brown\"}'}, {'headers': None, 'partition': 0, 'offset': 1, 'timestamp': (1, 1664989815680), 'key': None, 'value': '{\"name\": \"cake\", \"calories\": 260.0, \"colour\": \"white\"}'}, {'headers': None, 'partition': 0, 'offset': 1, 'timestamp': (1, 1664989815680), 'key': None, 'value': '{\"name\": \"cake\", \"calories\": 260.0, \"colour\": \"white\"}'}, {'headers': None, 'partition': 0, 'offset': 2, 'timestamp': (1, 1664989815680), 'key': None, 'value': '{\"name\": \"timtam\", \"calories\": 80.0, \"colour\": \"chocolate\"}'}, {'headers': None, 'partition': 0, 'offset': 2, 'timestamp': (1, 1664989815680), 'key': None, 'value': '{\"name\": \"timtam\", \"calories\": 80.0, \"colour\": \"chocolate\"}'}], 3)\n>>>\n```\n\n`flatmap`, in turn, is the basis for `map` which again consumes messages from a topic, but then calls a function that takes just this message and returns anything. `map` can be used e.g. to modify the messages of a topic, as in the following example:\n```\n>>> def map_function(x):\n...   x[\"value\"][\"colour\"] += \"ish\"\n...   return x\n... \n>>> c.map(\"snacks\", map_function, value_type=\"json\")\n([{'headers': None, 'partition': 0, 'offset': 0, 'timestamp': (1, 1664989815680), 'key': None, 'value': {'name': 'cookie', 'calories': 500.0, 'colour': 'brownish'}}, {'headers': None, 'partition': 0, 'offset': 1, 'timestamp': (1, 1664989815680), 'key': None, 'value': {'name': 'cake', 'calories': 260.0, 'colour': 'whiteish'}}, {'headers': None, 'partition': 0, 'offset': 2, 'timestamp': (1, 1664989815680), 'key': None, 'value': {'name': 'timtam', 'calories': 80.0, 'colour': 'chocolateish'}}], 3)\n>>>\n```\n\nFilter the messages to only keep those where the ``colour`` is ``brown``:\n```\n>>> c.filter(\"snacks\", lambda x: x[\"value\"][\"colour\"] == \"brown\", value_type=\"json\")\n([{'headers': None, 'partition': 0, 'offset': 0, 'timestamp': (1, 1666090118747), 'key': None, 'value': {'name': 'cookie', 'calories': 500.0, 'colour': 'brown'}}], 3)\n>>>\n```\n\nHere is an overview of the relations between those functions of *kash.py* which consume messages from Kafka topics and return a Python datatype (or nothing):\n\n* `foldl`\n\n    * `flatmap`, `cat`, `foreach`, `wc`\n\n        * `map`, `filter`, `grep`, `grep_fun`\n\nAs explained above, `foldl` is the basis of it all, `flatmap` is based on `foldl`and `map` is based on `flatmap`. In addition, `cat`, `foreach` and `wc` are also based on `foldl`, and `filter` and `grep` and `grep_fun` are based on `flatmap`.\n\n#### Kafka Topic to Local File\n\nWe turn to those functions consuming messages from a Kafka topic and writing them to a local file, transforming or even removing messages. Here, the basis function is `flatmap_to_file`. Here is an example where the flatmap function is the identity function. Hence, the messages from the topic `snacks` are written to the local file `./snacks.txt`:\n\n```\n>>> c.flatmap_to_file(\"snacks\", \"./snacks.txt\", lambda x: [x])\n(3, 3)\n>>> \n```\n\n`map_to_file` is based on `flatmap_to_file` and can be used to transform each message before it is written to the local file:\n```\n>>> def map_function(x):\n...   x[\"value\"][\"colour\"] += \"ish\"\n...   return x\n... \n>>> c.map_to_file(\"snacks\", \"./snacks.txt\", map_function)\n(3, 3)\n>>> \n```\n\n`filter_to_file` is also based on `flatmap_to_file` and writes only those messages to the local file which fulfil a condition, for example:\n```\n>>> def filter_function(message_dict):\n...   return \"cake\" in message_dict[\"value\"]\n... \n>>> c.filter_to_file(\"snacks\", \"./snacks.txt\", filter_function)\n(3, 1)\n\n```\n\nHere is an overview of the relations between those functions of *kash.py* which consume messages from Kafka topics and write them to a local file:\n\n* `flatmap_to_file`\n\n    * `map_to_file`, `filter_to_file`, `cp/download`\n\nAgain, as explained above, `map_to_file` and `filter_to_file` are based on `flatmap_to_file`, as well as `cp` (with the first not being a file and the second argument being a file marked by it containing a slash `/`) and `download`.\n\n#### Local File to Kafka Topic\n\nThe last set of functional functions are those reading lines/messages from a local file and producing them to a Kafka topic. Here, the basis function is `flatmap_from_file`. Here is an example where the flatmap function is the identity function. Hence, the messages from the local file `./snacks.txt` are produced into the topic `snacks`:\n\n```\n>>> c.flatmap_from_file(\"./snacks.txt\", \"snacks\", lambda x: [x])\n(3, 3)\n>>> \n```\n\n`map_from_file` is based on `flatmap_from_file` and can be used to transform each line/message before it is written to the local file:\n```\n>>> c.map_to_file(\"snacks\", \"./snacks.txt\", lambda x: x)\n(3, 3)\n>>> \n```\n\n`filter_from_file` is also based on `flatmap_from_file` and produces only those messages to the Kafka topic which fulfil a condition. In the example below we produce only those messages which have the string `cake` in their value:\n```\n>>> def filter_function(xy):\n...   x, y = xy\n...   return \"cake\" in y\n... \n>>> c.filter_from_file(\"./snacks.txt\", \"snacks\", filter_function)\n(3, 1)\n>>> \n```\n\nHere is an overview of the relations between those functions of *kash.py* which read lines/messages from a file and produce them to a Kafka topic:\n\n* `flatmap_from_file`\n\n    * `map_from_file`, `filter_from_file`, `cp/download`\n\nAgain, as explained above, `map_from_file` and `filter_from_file` are based on `flatmap_from_file`, as well as `cp` (with the first argument being a file marked by it containing a slash `/` and the second not a file) and `upload`.\n\nThere is also a function `foldl_from_file`. Here is an example where we use it to sum up the calories of the lines/messages from the file `./snacks.txt`:\n```\n>> foldl_from_file(\"./snacks.txt\", lambda acc, x: acc + json.loads(x)[\"calories\"], 0)\n(840.0, 3)\n>>> \n```\n\n### Cross-Cluster\n\n#### Kafka Topic to Kafka Topic\n\n*kash.py* also offers functional functions to use across clusters, based on `flatmap`. In the example below, we use `flatmap` to copy the topic  `snacks1` on cluster `c1` to a topic  `snacks2_duplicate` on cluster `c2`, while duplicating each message using a *flatmap* operation:\n```\n>>> flatmap(c1, \"snacks1\", c2, \"snacks2_duplicate\", lambda x: [x, x])\n(3, 6)\n>>>\n```\n\n`map` is based on `flatmap`. In the following example, we use a cross-cluster `map` to add the suffix `ish` to all the colours and produce the resulting messages to topic `snacks2_ish` on cluster `c2`:\n```\n>>> def map_function(x):\n...   x[\"value\"][\"colour\"] += \"ish\"\n...   return x\n... \n>>> map(c1, \"snacks1\", c2, \"snacks2_ish\", map_function, source_value_type=\"json\")\n(3, 3)\n>>>\n```\n\nThe function `filter` is also based on `flatmap` and, in the example below, is used to only keep those messages where the ``colour`` is ``brown``:\n```\n>>> c.filter(\"snacks\", lambda x: x[\"value\"][\"colour\"] == \"brown\", value_type=\"json\")\n([{'headers': None, 'partition': 0, 'offset': 0, 'timestamp': (1, 1666090118747), 'key': None, 'value': {'name': 'cookie', 'calories': 500.0, 'colour': 'brown'}}], 3)\n>>>\n```\nHere is an overview of the relations between those cross-cluster functions of *kash.py* which consume messages from a topic on one cluster and produce them in another (or equally named) topic on another (or the same) cluster:\n\n* `flatmap`\n\n    * `map`, `filter`, `cp`\n\n#### Consuming Two Topics At the Same Time\n\nThe `diff` and `diff_fun` functions are based on the functional abstraction `zip_foldl`. As an example, \nwe show the *zip* of topic `snacks1` on cluster `c1` and topic `snacks2_ish` on cluster `c2` followed by a *foldl* accumulating pairs of those messages from both topics where the colour of the message from topic `snacks2_ish` ends with `eish`:\n\n```\n>>> def zip_foldl_function(acc, x1, x2):\n...   return acc + [(x1, x2)] if x2[\"value\"][\"colour\"].endswith(\"eish\") else acc\n... \n>>> zip_foldl(c1, \"snacks1\", c2, \"snacks2_ish\", zip_foldl_function, [], value_type2=\"json\")\n([({'headers': None, 'partition': 0, 'offset': 1, 'timestamp': (1, 1664989815680), 'key': None, 'value': b'{\"name\": \"cake\", \"calories\": 260.0, \"colour\": \"white\"}'}, {'headers': None, 'partition': 0, 'offset': 1, 'timestamp': (1, 1664989815680), 'key': None, 'value': {'name': 'cake', 'calories': 260.0, 'colour': 'whiteish'}}), ({'headers': None, 'partition': 0, 'offset': 2, 'timestamp': (1, 1664989815680), 'key': None, 'value': b'{\"name\": \"timtam\", \"calories\": 80.0, \"colour\": \"chocolate\"}'}, {'headers': None, 'partition': 0, 'offset': 2, 'timestamp': (1, 1664989815680), 'key': None, 'value': {'name': 'timtam', 'calories': 80.0, 'colour': 'chocolateish'}})], 3, 3)\n>>>\n```\n\nHere is the overview of the relations between those functions of *kash.py* which consume messages from two topics (on the same cluster or on different clusters):\n\n* `zip_foldl`\n\n    * `diff/diff_fun`\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/xdgrulez/kash.py",
    "keywords": "",
    "license": "Apache License 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "kashpy",
    "package_url": "https://pypi.org/project/kashpy/",
    "platform": null,
    "project_url": "https://pypi.org/project/kashpy/",
    "project_urls": {
      "Homepage": "https://github.com/xdgrulez/kash.py"
    },
    "release_url": "https://pypi.org/project/kashpy/0.0.11/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "A Kafka Shell based on Python",
    "version": "0.0.11",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17309638,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "acd73687c2a7ce7767c95095a30c4eab82d01172c80a330397f7ca310cc81cfe",
          "md5": "cfdc5c5b58c6d995b812fa1fd35ef6cb",
          "sha256": "77ff1a4cbdf704fd9f103bf3fb201df714256371b65d4b999d46950edf88ff37"
        },
        "downloads": -1,
        "filename": "kashpy-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "cfdc5c5b58c6d995b812fa1fd35ef6cb",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 37272,
        "upload_time": "2022-10-07T09:33:02",
        "upload_time_iso_8601": "2022-10-07T09:33:02.108267Z",
        "url": "https://files.pythonhosted.org/packages/ac/d7/3687c2a7ce7767c95095a30c4eab82d01172c80a330397f7ca310cc81cfe/kashpy-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.10": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6a2fbd18c43d6d032791c20e5e73cd547728f814e66c23334a54ef163edb8047",
          "md5": "0163d4d3d08a63641fea54cd302b7059",
          "sha256": "a11a81926183b5399b9262a307de61f1c454a0a804dace590f4f3ad7122cbaea"
        },
        "downloads": -1,
        "filename": "kashpy-0.0.10.tar.gz",
        "has_sig": false,
        "md5_digest": "0163d4d3d08a63641fea54cd302b7059",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 50783,
        "upload_time": "2022-12-13T18:42:03",
        "upload_time_iso_8601": "2022-12-13T18:42:03.782680Z",
        "url": "https://files.pythonhosted.org/packages/6a/2f/bd18c43d6d032791c20e5e73cd547728f814e66c23334a54ef163edb8047/kashpy-0.0.10.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.11": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4fe9e08e4541e7cddf24e066fd5dc86b7facb41813f94932875e1094de6f0717",
          "md5": "0dca6b824033b2ba4753fee0770f877a",
          "sha256": "e21f75bef04ed90086b11792cf5e80c3bc9c4b66a396db61c601a34b83531c32"
        },
        "downloads": -1,
        "filename": "kashpy-0.0.11.tar.gz",
        "has_sig": false,
        "md5_digest": "0dca6b824033b2ba4753fee0770f877a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 53326,
        "upload_time": "2023-03-15T21:34:01",
        "upload_time_iso_8601": "2023-03-15T21:34:01.695728Z",
        "url": "https://files.pythonhosted.org/packages/4f/e9/e08e4541e7cddf24e066fd5dc86b7facb41813f94932875e1094de6f0717/kashpy-0.0.11.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1785d571dd2998f2b76c751fbfdeaab7a4d2e4a8f23046b70896df856417930e",
          "md5": "0d7cdf555e75831c785069258912540f",
          "sha256": "c292821bce1459565daf43cd8c6574c39707e9f6313a4779c1e415efdecaedc2"
        },
        "downloads": -1,
        "filename": "kashpy-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "0d7cdf555e75831c785069258912540f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 40156,
        "upload_time": "2022-10-07T10:20:57",
        "upload_time_iso_8601": "2022-10-07T10:20:57.363861Z",
        "url": "https://files.pythonhosted.org/packages/17/85/d571dd2998f2b76c751fbfdeaab7a4d2e4a8f23046b70896df856417930e/kashpy-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c511b9e4d3d45c9c44dc3ba6e5a94148dae685f72c1614de579ed15c5af169e5",
          "md5": "a98127f9040ecb2b08760e4a710a48ec",
          "sha256": "7807841db737221f392e0037ac8fa7ed908241304009f3aeee723058da78a3b5"
        },
        "downloads": -1,
        "filename": "kashpy-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "a98127f9040ecb2b08760e4a710a48ec",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 41871,
        "upload_time": "2022-10-16T12:34:41",
        "upload_time_iso_8601": "2022-10-16T12:34:41.472193Z",
        "url": "https://files.pythonhosted.org/packages/c5/11/b9e4d3d45c9c44dc3ba6e5a94148dae685f72c1614de579ed15c5af169e5/kashpy-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cd30d171f77489e5b34dd11c5e682260e4531ef79808aec4d5a02c5ce1510293",
          "md5": "2b6c0745a9f7430b478afb340e1b4e86",
          "sha256": "ae957c95129806049cfb3b57bb6101a206e1905be586b6012caefc60988de1a2"
        },
        "downloads": -1,
        "filename": "kashpy-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "2b6c0745a9f7430b478afb340e1b4e86",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 42187,
        "upload_time": "2022-10-16T13:29:49",
        "upload_time_iso_8601": "2022-10-16T13:29:49.804006Z",
        "url": "https://files.pythonhosted.org/packages/cd/30/d171f77489e5b34dd11c5e682260e4531ef79808aec4d5a02c5ce1510293/kashpy-0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cb79159246d9800b578b17aa06e470d45b4004a7852f7fdb83a0372819bfbb6f",
          "md5": "eecd1cb4dc1bff2c9729bebd5564aaf7",
          "sha256": "916ae7770d9014f956c92cfba4dff9d1161fb9f01999cbab717b0aef122df7c5"
        },
        "downloads": -1,
        "filename": "kashpy-0.0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "eecd1cb4dc1bff2c9729bebd5564aaf7",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 48036,
        "upload_time": "2022-10-19T12:31:17",
        "upload_time_iso_8601": "2022-10-19T12:31:17.693052Z",
        "url": "https://files.pythonhosted.org/packages/cb/79/159246d9800b578b17aa06e470d45b4004a7852f7fdb83a0372819bfbb6f/kashpy-0.0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a5423d159568590cdbfd9ddd73d6e1d870d9f1b8d7f013b8de605c45da38a543",
          "md5": "2cc5ddb65b01be1bc7011f0027821569",
          "sha256": "c7b4e2db048d468519cad24999a6e525c09ba7d9e836a21dc8669d131e87df2f"
        },
        "downloads": -1,
        "filename": "kashpy-0.0.6.tar.gz",
        "has_sig": false,
        "md5_digest": "2cc5ddb65b01be1bc7011f0027821569",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 48536,
        "upload_time": "2022-10-24T11:48:23",
        "upload_time_iso_8601": "2022-10-24T11:48:23.600169Z",
        "url": "https://files.pythonhosted.org/packages/a5/42/3d159568590cdbfd9ddd73d6e1d870d9f1b8d7f013b8de605c45da38a543/kashpy-0.0.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ce8c0ca2bd24a5fb50d15e49677688f3dbed7312b7428d0bb18cb9b38fba92eb",
          "md5": "ad20461ce44a918f93198960ba880b98",
          "sha256": "3b2b465b617c9e7fe3b3ccd9094ea7ef56b185604d39678aad0e9c5da83a0692"
        },
        "downloads": -1,
        "filename": "kashpy-0.0.7.tar.gz",
        "has_sig": false,
        "md5_digest": "ad20461ce44a918f93198960ba880b98",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 48645,
        "upload_time": "2022-10-29T23:23:31",
        "upload_time_iso_8601": "2022-10-29T23:23:31.317966Z",
        "url": "https://files.pythonhosted.org/packages/ce/8c/0ca2bd24a5fb50d15e49677688f3dbed7312b7428d0bb18cb9b38fba92eb/kashpy-0.0.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f0ba028ba6527ace67fb463a0e5203086fda9c94955a3350d9a72c6c9f40e5b0",
          "md5": "19913846bc7e4f65e7a1e867918b5e4a",
          "sha256": "77ff2c9ba4ab9584b288d6f44d4c9b26a51366fd79f5461ed848ac51b0457a4b"
        },
        "downloads": -1,
        "filename": "kashpy-0.0.8.tar.gz",
        "has_sig": false,
        "md5_digest": "19913846bc7e4f65e7a1e867918b5e4a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 49009,
        "upload_time": "2022-11-14T17:13:08",
        "upload_time_iso_8601": "2022-11-14T17:13:08.381971Z",
        "url": "https://files.pythonhosted.org/packages/f0/ba/028ba6527ace67fb463a0e5203086fda9c94955a3350d9a72c6c9f40e5b0/kashpy-0.0.8.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.9": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "728dd9f5b8c1715cfe8a11eb425b145f7419c7a2cf25564c97671a818a1ef4c1",
          "md5": "17b8a6a0037bb390390c638ab76715a4",
          "sha256": "cce672bf5b8faea2ea699d5a5ca41e097311d295fc9c51f2e88084237b1d4761"
        },
        "downloads": -1,
        "filename": "kashpy-0.0.9.tar.gz",
        "has_sig": false,
        "md5_digest": "17b8a6a0037bb390390c638ab76715a4",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 49327,
        "upload_time": "2022-11-15T14:13:34",
        "upload_time_iso_8601": "2022-11-15T14:13:34.663202Z",
        "url": "https://files.pythonhosted.org/packages/72/8d/d9f5b8c1715cfe8a11eb425b145f7419c7a2cf25564c97671a818a1ef4c1/kashpy-0.0.9.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "4fe9e08e4541e7cddf24e066fd5dc86b7facb41813f94932875e1094de6f0717",
        "md5": "0dca6b824033b2ba4753fee0770f877a",
        "sha256": "e21f75bef04ed90086b11792cf5e80c3bc9c4b66a396db61c601a34b83531c32"
      },
      "downloads": -1,
      "filename": "kashpy-0.0.11.tar.gz",
      "has_sig": false,
      "md5_digest": "0dca6b824033b2ba4753fee0770f877a",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 53326,
      "upload_time": "2023-03-15T21:34:01",
      "upload_time_iso_8601": "2023-03-15T21:34:01.695728Z",
      "url": "https://files.pythonhosted.org/packages/4f/e9/e08e4541e7cddf24e066fd5dc86b7facb41813f94932875e1094de6f0717/kashpy-0.0.11.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}