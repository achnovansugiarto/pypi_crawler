{
  "info": {
    "author": "Logan Zehm",
    "author_email": "logondz27@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3.10"
    ],
    "description": "# AeroNet\r\n\r\nAeroNet is a simple neural network library. It is written entirely using python, numpy, and scipy. This is an educational neural network library made with the hope of demystifying some of these modern deep learning libraries. Many modern deep learning libraries do not fundamentally differ from AeroNet all that much (minus automatic differentiation). Most of the code in modern libraries is just dedicated to efficiency and optimization of the algorithms used. Feel free to play around with AeroNet and see what deep learning projects you can make.\r\n\r\n## Installing AeroNet\r\n\r\nAeroNet is now hosted on PyPi for your convenience. The only dependencies are numpy, scipy, and dill which are all installed automatically when AeroNet is installed. Python 3.10 is recommended for using AeroNet.\r\n\r\n```bash\r\npip install aeronet-learn\r\n```\r\n\r\n## Running From The Source Code\r\n\r\n### Creating A Virtual Environment\r\n\r\nYou may want to run AeroNet directly from the source code. Or maybe you want to directly run the training examples hosted on github. This can be done by cloning the code from [github](https://github.com/Logon27/AeroNet). You can then create a virtual enviroment with the following code.\r\n\r\n```\r\npython -m venv venvNeuralNetworkLibrary\r\nvenvNeuralNetworkLibrary/scripts/activate.bat\r\npip install -r requirements.txt\r\n```\r\n\r\nYou will then be able to run training examples directly. As seen in the next section.\r\n\r\n### Testing Out A Network\r\n\r\nTest your network against one of these datasets...\r\n```bash\r\n# move into the training examples directory\r\ncd training_examples\r\n# then execute one of the scripts below...\r\n```\r\n\r\n```bash\r\n# Simple xor example with dense layers\r\npython xor.py\r\n\r\n# Mnist with dense layers\r\npython mnist.py\r\n\r\n# Convolutional neural network implementation for mnist\r\npython mnist_conv.py\r\n\r\n# Fully convolutional network implementation for mnist\r\npython mnist_fcn.py\r\n\r\n# Convolutional neural network implementation for mnist with max pooling\r\npython mnist_maxpooling.py\r\n```\r\n---\r\n\r\n## AeroNet Example Usage\r\n\r\n```python\r\n# Import all neural network classes.\r\nfrom nn import *\r\n\r\n# Network layers are initialized as a list of objects\r\nnetwork_layers = [\r\n    Dense(28 * 28, 70),\r\n    Sigmoid(),\r\n    Dense(70, 35),\r\n    Sigmoid(),\r\n    Dense(35, 10),\r\n    Softmax()\r\n]\r\n\r\n# Create a network object\r\nnetwork = Network(\r\n    network_layers,\r\n    TrainingSet(input_train, output_train, input_test, output_test, post_processing),\r\n    loss_function,\r\n    loss_function_prime,\r\n    epochs=10,\r\n    batch_size=1\r\n)\r\n\r\n# Train the network\r\nnetwork.train()\r\n\r\n# Generate a prediction from the network given a single input array\r\nprediction_array = network.predict(input_array)\r\n\r\n# Save the network to a file\r\nsave_network(network, \"network_filename.pkl\")\r\n\r\n# Load the network from a file\r\nnetwork = load_network(\"network_filename.pkl\")\r\n```\r\n\r\n## TrainingSet Explained\r\n\r\nThe TrainingSet object is simply an object that stores your training and validation set data for your network. As well as a post processing function that is applied to your network predictions and training set data before comparisons are made.\r\n\r\n```python\r\nTrainingSet(input_train, output_train, input_test, output_test, post_processing)\r\n```\r\n\r\ninput_train = training set inputs  \r\noutput_train = training set outputs  \r\ninput_test = test / valdation set inputs  \r\noutput_test = test / valdation set outputs  \r\n\r\npost_processing is a function applied to your network prediction and training set data before they are compared. For example with the xor problem your network makes predictions based on floats. So you may want to round to the nearest float before comparing the prediction to the desired output. So you could pass np.rint as the post processing function to round to the nearest int. This allows you to get accurate test accuracy output during training. The same applies to things like mnist. You may have a softmax output with percentage predictions based on 10 indices (0 through 9). You may want your prediction to be the indice with the highest percentage. Therefore, you could pass the np.argmax function as the post processing function. Hopefully you can see why this is useful.\r\n\r\n## Supported Neural Layers\r\n\r\n```python\r\n# Layers\r\nDense(num_input_neurons, num_output_neurons) # For weight manipulation\r\nConvolutional((input_depth, input_height, input_width), kernel_size, num_kernels, stride=(int, int), padding=((int, int), (int, int)))\r\nReshape() # Modifies the shape of the numpy arrays passed between layers\r\nFlatten() # Flattens a numpy array into a 2D matrix with a single column\r\nDropout(probability) # Randomly drops layer outputs based on a probability to prevent overfitting. A probability of 0.25 would drop 25% of connections.\r\nMaxPooling2D((input_depth, input_height, input_width), kernel_size, stride=(int, int), padding=((int, int), (int, int)))\r\n\r\n# Activation Functions\r\nSigmoid()\r\nTanh()\r\nRelu()\r\nLeakyRelu() # Leaky Relu not validated\r\nSoftmax() # For output percentage predictions\r\n```\r\n\r\n## Supported Optimizers\r\n\r\n```python\r\nSGD() # Stochastic Gradient Descent\r\nMomentumSGD() # Stochastic Gradient Descent with Momentum\r\n```\r\n\r\n## Supported Initializers\r\n\r\n```python\r\nUniform(low=-1, high=1)\r\nNormal(mean=0, std=1)\r\nZero() # Zero initialized array for biases\r\nXavier()\r\n```\r\n\r\n## The Network Class\r\n\r\n```\r\nnetwork = Network(\r\n    layers,\r\n    TrainingSet(x_train, y_train, x_test, y_test, post_processing),\r\n    loss=loss_function,\r\n    loss_prime=loss_function_prime,\r\n    epochs=10,\r\n    batch_size=1,\r\n    layer_properties=LayerProperties(learning_rate, weight_initializer, bias_initializer, optimizer),\r\n    data_augmentation=[function1, function2, function3],\r\n    percent_error_threshold=None\r\n    verbose=true\r\n)\r\n```\r\n\r\nThe data_augmentation parameter is a list of pure functions. These functions must take in a single numpy array and return a numpy array. To use functions that take multiple parameters you can pass in a lambda function that calls the multi-parameter function. It can be used for numpy array rotation, scaling, noise, and translation for datasets like mnist (that are uniform and centered). These functions are applied sequentially to every training sample, for every epoch, before they are passed into the network. If no data_augmentation list is supplied then no data_augmentation is performed. You can always choose to augment the dataset before network training begins.\r\n\r\nThe percent_error_threshold parameters on the network class can be used to stop training when the network reaches a certain error percentage. For example, if you passed ```percent_error_threshold = 0.05``` then the network would exit the training loop if the error percentage fell below 5%. This can be used to prevent overtraining or shorten training time if you are only aiming to get below a certain error rate.\r\n\r\n### Network Metadata\r\n\r\nThe network class does track some metadata to help with debugging or generate training statistics.\r\n\r\n- total_training_time (float).  \r\nThe total training time for the network in minutes.\r\n- per_epoch_errors (list of floats)  \r\nA list of the errors per epoch. This is only for the last time the train() method was called.\r\n\r\n## Layer Properties\r\nLearning rates can be set at both a network level (every layer) or at individual layers themselves. This is done through the use of a layer properties class. Each layer with trainable parameters has a default learning rate, weight / bias initializer, and optimizer. So even if you input no layer properties for the layer (or network) it will be populated with some defaults. \r\n\r\n```python\r\n# This example would set these specific layer properties for the first and second dense layer\r\nlayer1_properties = LayerProperties(learning_rate=0.05, weight_initializer=Uniform(), bias_initializer=Uniform(), optimizer=SGD())\r\nlayer2_properties = LayerProperties(learning_rate=0.03, weight_initializer=Uniform(), bias_initializer=Zero(), optimizer=SGD())\r\nnetwork_layers = [\r\n    Dense(28 * 28, 70, layer_properties=layer1_properties),\r\n    Sigmoid(),\r\n    Dense(70, 35, layer_properties=layer2_properties),\r\n    Sigmoid(),\r\n    Dense(35, 10),\r\n    Softmax()\r\n]\r\n\r\n\r\n# Optionally you can set the layer properties for every layer in the network.\r\n# This is done by setting layer properties on the network class itself.\r\nall_layer_properties = LayerProperties(learning_rate=0.05, weight_initializer=Uniform(), bias_initializer=Uniform(), optimizer=SGD())\r\nnetwork = Network(\r\n    network_layers,\r\n    TrainingSet(input_train, output_train, input_test, output_test),\r\n    loss_function,\r\n    loss_function_prime,\r\n    epochs=10,\r\n    batch_size=1,\r\n    layer_properties=all_layer_properties\r\n)\r\n\r\n\r\n# You can also choose to overwrite only some properties at both the network and layer level.\r\n# For example the following would only change the learning rate (for all layers) but leave all other defaults the same.\r\nall_layer_properties = LayerProperties(learning_rate=0.05)\r\nnetwork = Network(\r\n    network_layers,\r\n    TrainingSet(input_train, output_train, input_test, output_test),\r\n    loss_function,\r\n    loss_function_prime,\r\n    epochs=10,\r\n    batch_size=1,\r\n    layer_properties=all_layer_properties\r\n)\r\n```\r\n\r\n## Kernel, Stride, and Padding Notation\r\n> :warning: Striding and Padding were only recently implemented. I cannot confirm that they work in all cases yet. So use at your own risk.\r\n\r\nSometimes you might see notation like **array[x][y]**. However, this is kind of a confusing syntax that people (including myself) write. Do not confuse the arbitrary variable **x** with the width. It does not represent the \"x\" of a coordinate system; in reality it represents the height. If you view the array syntax from a coordinate perspective it is really **array[height][width]**. So when you are inputting parameters for strides and padding it is really with the syntax **(height, width)**.\r\n\r\n### Kernel\r\n\r\nThe kernel supports 3 different syntax listed below. \r\n\r\n```\r\nkernel_size = 3         # Uses 3 for the height and width\r\nkernel_size = (3)       # Uses 3 for the height and width\r\nkernel_size = (3,3)\r\n```\r\n\r\n### Striding\r\n\r\nStriding only has two dimensions, that is striding in the \"height\" dimension and striding in the \"width\" dimension. Striding follows the syntax **(height_stride, width_stride)**. So a stride of (2, 3) would move the kernel 2 positions down and 3 positions to the right. Syntax example listed below.\r\n\r\n```\r\nstride = (3, 3)\r\n```\r\n\r\n### Padding\r\n\r\nThere are four different allowed padding formats.\r\n\r\n**(pad_all_4_sides)**  \r\n```padding = 1```\r\nor...\r\n```padding = (1)```\r\n\r\n**(pad_height, pad_width)**  \r\n```padding = (1, 1)```\r\n\r\n**((pad_top_height,pad_bottom_height), (pad_left_width,pad_right_width))**  \r\nAlternatively you could think of the format as...  \r\n**((top, bottom), (left, right))**  \r\n```padding = ((1,1), (2,2))```\r\n\r\n## CUDA Support\r\n\r\nThis library no longer supports CUDA. It has been removed because it was too hard to maintain with more complex layer implementations.\r\n\r\n## TODO\r\n\r\n- Package And Host The Library\r\n- Implement Avg Pooling\r\n- Implement Adaptive Avg Pooling\r\n- Implement Batch Normalization\r\n- Implement Layer Input Size Calculations\r\n\r\n\r\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/Logon27/AeroNet",
    "keywords": "",
    "license": "LICENSE",
    "maintainer": "",
    "maintainer_email": "",
    "name": "aeronet-learn",
    "package_url": "https://pypi.org/project/aeronet-learn/",
    "platform": null,
    "project_url": "https://pypi.org/project/aeronet-learn/",
    "project_urls": {
      "Homepage": "https://github.com/Logon27/AeroNet"
    },
    "release_url": "https://pypi.org/project/aeronet-learn/1.0.4/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "AeroNet is an educational neural network library. It is written entirely using python, numpy, and scipy.",
    "version": "1.0.4",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16935763,
  "releases": {
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d4d95d2b952d6374c1efebf2f4ca1b7fc40935d186fa2006701ff2fa3a9edf0c",
          "md5": "1c149df617e40b6df981c0d986973cc3",
          "sha256": "8df55e6c344353731bba1db00e520bdb94c4725a6e71b5ef925070eab496cac7"
        },
        "downloads": -1,
        "filename": "aeronet-learn-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "1c149df617e40b6df981c0d986973cc3",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 19416,
        "upload_time": "2023-01-16T20:32:30",
        "upload_time_iso_8601": "2023-01-16T20:32:30.411813Z",
        "url": "https://files.pythonhosted.org/packages/d4/d9/5d2b952d6374c1efebf2f4ca1b7fc40935d186fa2006701ff2fa3a9edf0c/aeronet-learn-1.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f9a9228291dd4068187fcf409aa545850af010226690cb4286313595d4f38308",
          "md5": "54bbf2c209b13114003a615b5fa84625",
          "sha256": "9a905180aacf583a7bbb8e411a3873399921813dd7befcdb0752b2696b804a64"
        },
        "downloads": -1,
        "filename": "aeronet-learn-1.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "54bbf2c209b13114003a615b5fa84625",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 19380,
        "upload_time": "2023-01-18T01:51:46",
        "upload_time_iso_8601": "2023-01-18T01:51:46.825936Z",
        "url": "https://files.pythonhosted.org/packages/f9/a9/228291dd4068187fcf409aa545850af010226690cb4286313595d4f38308/aeronet-learn-1.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "09087fc28feffa575a704539e87eac89f799b48be0d691434c460485d35b0a94",
          "md5": "6cd9c7b70379aa1283e3bc60948dc462",
          "sha256": "769af9a6bbb65ba336572423f5a0c0bd40724a628ad3897cd82540a4163a2e5f"
        },
        "downloads": -1,
        "filename": "aeronet-learn-1.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "6cd9c7b70379aa1283e3bc60948dc462",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 19881,
        "upload_time": "2023-01-20T02:26:40",
        "upload_time_iso_8601": "2023-01-20T02:26:40.414843Z",
        "url": "https://files.pythonhosted.org/packages/09/08/7fc28feffa575a704539e87eac89f799b48be0d691434c460485d35b0a94/aeronet-learn-1.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2c4776c99816249d3ff452b1cd9b9a80f326b0df7ed9e696789ca63d3a25780f",
          "md5": "678da5c744929671c5f87fd4d09c05b0",
          "sha256": "0a0c15bd1c5bfa3d201465dab1776fcc0a31478d2d73eb59cc11946f39db1f72"
        },
        "downloads": -1,
        "filename": "aeronet-learn-1.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "678da5c744929671c5f87fd4d09c05b0",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 19887,
        "upload_time": "2023-02-05T17:12:30",
        "upload_time_iso_8601": "2023-02-05T17:12:30.728760Z",
        "url": "https://files.pythonhosted.org/packages/2c/47/76c99816249d3ff452b1cd9b9a80f326b0df7ed9e696789ca63d3a25780f/aeronet-learn-1.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8a3618dd658559667b2a613a172297007d915ca0e245547eb3dd0b899e968af7",
          "md5": "728ac6e850a22578285527461b281f90",
          "sha256": "56c348f6dca5953817737a04f75a8783c41a693067b59dd71655085bc664a010"
        },
        "downloads": -1,
        "filename": "aeronet-learn-1.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "728ac6e850a22578285527461b281f90",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 20477,
        "upload_time": "2023-02-20T01:10:11",
        "upload_time_iso_8601": "2023-02-20T01:10:11.976064Z",
        "url": "https://files.pythonhosted.org/packages/8a/36/18dd658559667b2a613a172297007d915ca0e245547eb3dd0b899e968af7/aeronet-learn-1.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "8a3618dd658559667b2a613a172297007d915ca0e245547eb3dd0b899e968af7",
        "md5": "728ac6e850a22578285527461b281f90",
        "sha256": "56c348f6dca5953817737a04f75a8783c41a693067b59dd71655085bc664a010"
      },
      "downloads": -1,
      "filename": "aeronet-learn-1.0.4.tar.gz",
      "has_sig": false,
      "md5_digest": "728ac6e850a22578285527461b281f90",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 20477,
      "upload_time": "2023-02-20T01:10:11",
      "upload_time_iso_8601": "2023-02-20T01:10:11.976064Z",
      "url": "https://files.pythonhosted.org/packages/8a/36/18dd658559667b2a613a172297007d915ca0e245547eb3dd0b899e968af7/aeronet-learn-1.0.4.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}