{
  "info": {
    "author": "Trung M. Bui",
    "author_email": "bmtrungvp@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "![license](https://img.shields.io/badge/license-MIT-green) ![PyTorch-1.4.0](https://img.shields.io/badge/PyTorch-1.4.0-blue)\n# AI Picking package\n## System Requirements:\n```sh\n- Ubuntu 16.04 or 18.04\n- CUDA >=10.0, CUDNN>=7\n- Pytorch >=1.4.0\n```\n## Install NVIDIA driver\n```sh\ncheck GPU info: \nsudo lshw -C display or hwinfo --gfxcard --short\nInstall:\nsudo add-apt-repository ppa:graphics-drivers/ppa\nsudo apt update\nreboot\nOpen 'Software and update/ Addtional Drivers' and select proper driver\nreboot\n```\n\n## Install CUDA and CUDNN\n```sh\n- Download *.run file from https://developer.nvidia.com/cuda-toolkit-archive\nsudo sh cuda_XXX.run\n- Follow the command line promts:\n*** Note: Answer 'NO' for question \"Install NVIDIA Accelerated Graphics Driver for Linux-XXX?\"\n- Download CUDNN from https://developer.nvidia.com/rdp/cudnn-archive\n- Extract tar file\nsudo cp /cuda/include/* /usr/loca/cuda-XX/include\nsudo cp /cuda/lib64/* /usr/local/cuda-XX/lib64\n- Set up CUDA path\nsudo gedit ~/.bashrc\nAdd 2 lines to the file:\n    PATH=/usr/local/cuda/bin:$PATH\n    LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH\nsource  ~/.bashrc\n\nsudo gedit /etc/ld.so.conf.d/cuda.conf\nAdd: /usr/local/cuda/lib64\nsudo ldconfig\nreboot\n```\n## Install\n```sh\nsudo apt install python3.6-dev\nsudo apt install python3.6-tk\ncd $ROOT\npip install -e .\n```\n## Download pretrained network and cofigurations file\nhttps://drive.google.com/drive/folders/1hdeJUe0EzIO6be5i-m8ygYpbnDGpHrKy?usp=sharing\n** Place *.cfg files into $ROOT/configs, and trained *.pth to $ROOT/data/model/{grip or suction}_evaluator\n## Demos\n### Suction Detection with RGBD from realsense\n```sh\nfrom ttcv.sensor.realsense_sensor import RSSensor\nimport cv2\n\n# get data from realsene\nsensor = RSSensor()\nsensor.start()\nfor i in range(5): rgb, depth = sensor.get_data()\n# define detector\ndetector = SuctionDetector(cfg_path='configs/suction_net.cfg')\n# set crop area\nbbox = (630, 330, 1000, 670)    # left, top, right, bottom\n# find suction  pose\nSuctions = detector.find_suction_pose_rgb_depth(rgb=rgb, depth=depth, bbox=bbox)\nout = detector.show_suctions_rgb_depth(rgb, depth, Suctions,  bbox=bbox)\n# show\ncv2.imshow('rgb', rgb[:, :, ::-1])\ncv2.imshow('depth', depth)\ncv2.imshow('out', out[:,:,::-1])\n# release realsense\ncv2.waitKey()\nsensor.stop()\n```\n### Suction Detection with GUI\n```sh\nfrom  ttcv.basic.basic_objects import DetGui\nfrom kpick.processing.suction_detection_v2 import SuctionDetector\nclass SuctionGuiDetector(SuctionDetector, DetGui):\n    def gui_process_single(self, rgbd, method_ind=0, filename='unnamed', disp_mode='rgb'):\n        if method_ind == 0: ret = self.show_suctions(\n            rgbd=rgbd, Suctions=self.find_suction_pose_multiscale(rgbd=rgbd), disp_mode=disp_mode)\n        return ret\n\nfrom ttcv.sensor.realsense_sensor import get_realsense_modules\nfrom ttcv.basic.basic_gui import BasGUI, GuiModule\n\ncfg_path = 'configs/suction_net.cfg'\nsuction_detect_module = GuiModule(SuctionGuiDetector, type='suction_detector', name='Suction Detector',\n                                  category='detector', cfg_path=cfg_path, num_mod_method=1)\n\nBasGUI(title='Stefan Pose Maker',\n       modules=[suction_detect_module] + get_realsense_modules(),\n       )\n```\n\n### Suction Detection With TCP/IP connect\n#### Server\n```sh\nfrom ttcv.basic.basic_tcp_connect import ServerThread\nfrom kpick.processing.suction_detection_v2 import SuctionDetector\n\n\nclass SuctionSeverDetector(SuctionDetector, ServerThread):\n    def __init__(self, cfg_path, host='localhost', port=8888):\n        SuctionDetector.__init__(self,cfg_path=cfg_path)\n        print('{} Detector initialized '.format('+'*10))\n        ServerThread.__init__(self,host=host, port=port)\n        print('{} Server initialized '.format('+' * 10))\n\n    def process_received_data(self):\n        Suctions = self.find_suction_pose_rgb_depth(rgb=self.data['rgb'], depth=self.data['depth'],\n                                                    bbox=self.data['bbox'], ws_pts=self.data['ws_pts'])\n\n        det = {'scores': Suctions.scores.tolist(), 'locs': Suctions.get_suction_locs(),\n               'disp_color': Suctions.disp_colors, 'norms': Suctions.norm_vectors(), 'best_ind': Suctions.best_ind}\n        out =  self.show_suctions_rgb_depth(rgb=self.data['rgb'], depth=self.data['depth'],\n                                            Suctions=Suctions, bbox=self.data['bbox'],\n                                            ws_pts=self.data['ws_pts'],  disp_mode=self.data['disp_mode'])\n        return {'im':out, 'det': det}\n\n\nif __name__=='__main__':\n    SuctionSeverDetector(cfg_path='configs/suction_net.cfg').listen()\n\n\n```\n#### Client GUI\n```sh\nfrom ttcv.basic.basic_objects import  DetGuiObj\nfrom ttcv.basic.basic_tcp_connect import ClientThread\nfrom ttcv.utils.proc_utils import CFG\nfrom ttcv.basic.basic_gui import BasGUI, GuiModule\nfrom ttcv.sensor.realsense_sensor import get_realsense_modules\n\n\ndef demo_client_gui(host='localhost',port=8888):\n    class ClientGui(DetGuiObj, ClientThread):\n        def __init__(self, args=None, cfg_path=None):\n            DetGuiObj.__init__(self, args=args, cfg_path=cfg_path)\n            ClientThread.__init__(self, host=self.args.host, port=self.args.port)\n\n        def gui_process_single(self, rgbd, method_ind=0, filename='unnamed', disp_mode='rgb'):\n\n            rets =  self.send_and_get_return({'rgb': rgbd.rgb, 'depth': rgbd.depth,\n                       'bbox': rgbd.workspace.bbox, 'ws_pts': rgbd.workspace.pts, 'disp_mode': disp_mode})\n            print('Return received ...')\n\n            if rets is None:\n                print('None return ...')\n                return rgbd.disp(mode=disp_mode)\n\n            #++++++++++++++++++++++++++++ Robot actiont here\n            det = rets['det']\n            return rets['im']\n\n\n\n    args = CFG()\n    args.host, args.port = host, port\n    client_module = GuiModule(ClientGui, type='client_gui', name='Client GUI', category='detector',\n                              run_thread=True, args=args)\n    BasGUI(title='Client Gui', modules=[client_module,]+get_realsense_modules())\n\nif __name__=='__main__':\n    demo_client_gui()\n```\n#### Client with realsense\n```sh\nfrom ttcv.sensor.realsense_sensor import RSSensor\nimport cv2\nfrom ttcv.basic.basic_tcp_connect import ClientThread\n\n# get data from realsene\nsensor = RSSensor()\nsensor.start()\n# for i in range(5): rgb, depth = sensor.get_data()\n\n# define detector\n# detector = SuctionDetector(cfg_path='configs/suction_net.cfg')\n\n# set crop area\nbbox = None  # (630, 330, 1000, 670)    # left, top, right, bottom\nws_pts = [(177, 48), (1082, 40), (1104, 650), (855, 655), (760, 512), (692, 517), (762, 663), (136, 646)]\n# init client\nclient = ClientThread()\n\nwhile True:\n    rgb, depth = sensor.get_data()\n    cv2.imshow('im', rgb[:, :, ::-1])\n    # find suction  pose\n    # Suctions = detector.find_suction_pose_rgb_depth(rgb=rgb, depth=depth, bbox=bbox)\n    # out = detector.show_suctions_rgb_depth(rgb, depth, Suctions,  bbox=bbox)\n\n    sent_dict = {'rgb': rgb, 'depth': depth, 'bbox': None, 'ws_pts': ws_pts, 'disp_mode': 'rgb'}\n    rets = client.send_and_get_return(sent_dict)\n\n    out, det = rets['im'], rets['det']\n\n    cv2.imshow('out', out[:, :, ::-1])\n    if cv2.waitKey(10) == 27: break\n\n# release realsense\nsensor.stop()\n```\n### Grasp Detection with Realsense\n```sh\nfrom ttcv.sensor.realsense_sensor import RSSensor\nfrom kpick.processing.grip_detection_v6 import GripDetector\nimport cv2\n# get data from realsene\nsensor = RSSensor()\nsensor.start()\nfor i in range(5): rgb, depth = sensor.get_data()\n\n# define detector\ndetector = GripDetector(cfg_path='configs/grip_net.cfg')\n\n# set crop area\nbbox = (630, 330, 1000, 670)  # left, top, right, bottom\n\n# find suction  pose\nGrips = detector.find_grip_pose_rgb_depth(rgb=rgb, depth=depth, bbox=bbox)\nout = detector.show_grips_rgb_depth(rgb, depth, Grips, bbox=bbox)\n\n# show\ncv2.imshow('rgb', rgb[:, :, ::-1])\ncv2.imshow('depth', depth)\ncv2.imshow('out', out[:, :, ::-1])\n\n# release realsense\ncv2.waitKey()\nsensor.stop()\n```\n### Grasp Detection with GUI\n```sh\nclass GripGuiDetector(GripDetector, DetGui):\n    def gui_process_single(self, rgbd, method_ind=0, filename='unnamed', disp_mode='rgb'):\n        if method_ind == 0: ret = self.show_grips(\n            rgbd=rgbd, Grips=self.find_grip_pose_from_edges_v3(rgbd=rgbd), disp_mode=disp_mode)\n        return ret\n\nfrom ttcv.sensor.realsense_sensor import get_realsense_modules\nfrom ttcv.basic.basic_gui import BasGUI, GuiModule\n\ncfg_path = 'configs/grip_net.cfg'\ndetect_module = GuiModule(GripGuiDetector, type='grip_detector', name='Grip Detector',\n                          category='detector', cfg_path=cfg_path, num_mod_method=1)\n\nBasGUI(title='Grip Detection GUI',\n       modules=[detect_module] + get_realsense_modules(),\n       )\n```\n\n### Grasp Detection Server\n```sh\nfrom ttcv.basic.basic_tcp_connect import ServerThread\nfrom kpick.processing.grip_detection_v6 import GripDetector\n\n\nclass GripSeverDetector(GripDetector, ServerThread):\n    def __init__(self, cfg_path, host='localhost', port=8888):\n        GripDetector.__init__(self,cfg_path=cfg_path)\n        print('{} Detector initialized '.format('+'*10))\n        ServerThread.__init__(self,host=host, port=port)\n        print('{} Server initialized '.format('+' * 10))\n\n    def process_received_data(self):\n        Grips = self.find_grip_pose_rgb_depth(rgb=self.data['rgb'], depth=self.data['depth'],\n                                                    bbox=self.data['bbox'], ws_pts=self.data['ws_pts'])\n\n        det = {'scores': Grips.scores, 'locs': Grips.get_grip_centers(),\n               'disp_color': Grips.disp_colors, 'best_ind': Grips.best_ind}\n        out =  self.show_grips_rgb_depth(rgb=self.data['rgb'], depth=self.data['depth'],\n                                            Grips=Grips, bbox=self.data['bbox'],\n                                            ws_pts=self.data['ws_pts'],  disp_mode=self.data['disp_mode'])\n        return {'im':out, 'det': det}\n\n\nif __name__=='__main__':\n    GripSeverDetector(cfg_path='configs/grip_net.cfg').listen()\n\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/mtbui2010",
    "keywords": "AI,VISION,GRASP DETECTION",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "kpick",
    "package_url": "https://pypi.org/project/kpick/",
    "platform": "",
    "project_url": "https://pypi.org/project/kpick/",
    "project_urls": {
      "Homepage": "https://github.com/mtbui2010"
    },
    "release_url": "https://pypi.org/project/kpick/1.0.1/",
    "requires_dist": [
      "numpy"
    ],
    "requires_python": ">=3.6",
    "summary": "An AI picking package",
    "version": "1.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 9111295,
  "releases": {
    "1.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "eed3d79d0920164fb805bda0a47ed0d6a5113dec75bb7889fae0008b51cb6e2f",
          "md5": "ac8373cfcdc9c5b7a890523eb004a66d",
          "sha256": "f8994e520eb18ed39c6d602893c4afb337ea85f585e904f204b3540399262066"
        },
        "downloads": -1,
        "filename": "kpick-1.0.1-cp36-cp36m-manylinux2014_x86_64.whl",
        "has_sig": false,
        "md5_digest": "ac8373cfcdc9c5b7a890523eb004a66d",
        "packagetype": "bdist_wheel",
        "python_version": "cp36",
        "requires_python": ">=3.6",
        "size": 8269897,
        "upload_time": "2021-01-12T04:00:19",
        "upload_time_iso_8601": "2021-01-12T04:00:19.941405Z",
        "url": "https://files.pythonhosted.org/packages/ee/d3/d79d0920164fb805bda0a47ed0d6a5113dec75bb7889fae0008b51cb6e2f/kpick-1.0.1-cp36-cp36m-manylinux2014_x86_64.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "eed3d79d0920164fb805bda0a47ed0d6a5113dec75bb7889fae0008b51cb6e2f",
        "md5": "ac8373cfcdc9c5b7a890523eb004a66d",
        "sha256": "f8994e520eb18ed39c6d602893c4afb337ea85f585e904f204b3540399262066"
      },
      "downloads": -1,
      "filename": "kpick-1.0.1-cp36-cp36m-manylinux2014_x86_64.whl",
      "has_sig": false,
      "md5_digest": "ac8373cfcdc9c5b7a890523eb004a66d",
      "packagetype": "bdist_wheel",
      "python_version": "cp36",
      "requires_python": ">=3.6",
      "size": 8269897,
      "upload_time": "2021-01-12T04:00:19",
      "upload_time_iso_8601": "2021-01-12T04:00:19.941405Z",
      "url": "https://files.pythonhosted.org/packages/ee/d3/d79d0920164fb805bda0a47ed0d6a5113dec75bb7889fae0008b51cb6e2f/kpick-1.0.1-cp36-cp36m-manylinux2014_x86_64.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}