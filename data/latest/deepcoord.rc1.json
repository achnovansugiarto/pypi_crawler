{
  "info": {
    "author": "RealVNF",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "![Python Build](https://github.com/RealVNF/deep-rl-network-service-coordination/workflows/Python%20Build/badge.svg)\n\n# DeepCoord: Self-Learning Multi-Objective Service Coordination Using Deep Reinforcement Learning\n\nUsing deep reinforcement learning (with DDPG), for online service coordinating, including scaling and placement of services and scheduling of rapidly incoming flows. \nServices consist of chained components that need to be instantiated at nodes in the substrate network and that incoming flows need to traverse in a predefined order.\nOur approach learns how to do this by itself just from experience, optimizing individual objectives (e.g., flow success rate) or multiple, \neven competing objectives (e.g., throughput, QoS, energy, costs).\nIt works with realistically available monitoring information, containing partial and delayed observations of the full network state.\n\n<p align=\"center\">\n  <img src=\"docs/realvnf_logo.png\" height=\"150\" hspace=\"30\"/>\n\t<img src=\"docs/upb.png\" width=\"200\" hspace=\"30\"/>\n\t<img src=\"docs/huawei_horizontal.png\" width=\"250\" hspace=\"30\"/>\n</p>\n\n\n## Citation\n\nIf you use this code, please cite our [conference paper](http://dl.ifip.org/db/conf/cnsm/cnsm2020/1570659307.pdf) ([Best Student Paper at IEEE/IFIP CNSM 2020](https://stefanbschneider.github.io/assets/other/best_student_paper_cnsm2020.pdf)) and [journal paper](https://ris.uni-paderborn.de/record/21808):\n\n```\n@inproceedings{schneider2020selfdriving,\n\ttitle={Self-Driving Network and Service Coordination Using Deep Reinforcement Learning},\n\tauthor={Schneider, Stefan and Manzoor, Adnan and Qarawlus, Haydar and Schellenberg, Rafael and Karl, Holger and Khalili, Ramin and Hecker, Artur},\n\tbooktitle={International Conference on Network and Service Management (CNSM)},\n\tyear={2020},\n\tpublisher={IFIP/IEEE}\n}\n\n@article{schneider2021selflearning,\n\ttitle={Self-Learning Multi-Objective Service Coordination Using Deep Reinforcement Learning},\n\tauthor={Schneider, Stefan and Khalili, Ramin and Manzoor, Adnan and Qarawlus, Haydar and Schellenberg, Rafael and Karl, Holger and Hecker, Artur},\n\tjournal={Transactions on Network and Service Management (TNSM)},\n\tvolume={18},\n\tnumber={3},\n\tyear={2021},\n\tpublisher={IEEE}\n}\n```\n\n\n## Setup\n\n_Recommended for development_: Clone and install [`coord-sim`](https://github.com/RealVNF/coord-sim/releases/tag/v2.1.0) and [`common-utils`](https://github.com/RealVNF/common-utils/tree/tnsm2021) \nlocally first in the same venv before running the installation of the RL agent.\n\nYou need to have [Python 3.6 or 3.7](https://www.python.org/downloads/release/) and [venv](https://docs.python.org/3/library/venv.html) module installed.\nThe installation is tested and works on Ubuntu 16.04 and 20.04 with **Python 3.6** and [`coord-sim v2.1.0`](https://github.com/RealVNF/coord-sim/releases/tag/v2.1.0). \nIt does not with Python 3.8 because `tensorboard 1.14.0`, which is a required dependency, is not available for Python 3.8.\n\n\n### Create a venv\n\nOn your local machine:\n\n```bash\n# check version\npython3 --version\n\n# if not 3.6 or 3.7, install python 3.6\nsudo apt update\nsudo add-apt-repository ppa:deadsnakes/ppa\nsudo apt install python3.6 python3.6-dev python3.6-venv\n\n# create venv once\npython3.6 -m venv ./venv\n# activate the venv (always)\nsource venv/bin/activate\n# update setuptools\npip install -U setuptools\n```\n\n### Install dependencies\n\n```bash\n# from within the repo directory\npip install -r requirements.txt\n```\n\nThis also installs the required [`coord-sim`](https://github.com/RealVNF/coord-sim/tree/tnsm2021) and [`common-utils`](https://github.com/RealVNF/common-utils/tree/tnsm2021) package\nif they were not installed manually before.\n\n## Use the RL agent\n\nAll options:\n\n```bash\n$ deepcoord -h\nUsage: deepcoord [OPTIONS] AGENT_CONFIG NETWORK SERVICE SIM_CONFIG STEPS\n\n  deepcoord cli for learning and testing\n\nOptions:\n  --seed INTEGER               Specify the random seed for the environment and\n                               the learning agent.\n  -t, --test TEXT              Name of the training run whose weights should\n                               be used for testing.\n  -w, --weights TEXT           Continue training with the specified weights\n                               (similar to testing)\n  -a, --append-test            Append a test run of the previously trained\n                               agent.\n  -v, --verbose                Set console logger level to debug. (Default is\n                               INFO)\n  -b, --best                   Test the best of the trained agents so far.\n  -e, --test-episodes INTEGER  Set the number of testing episodes\n  -ss, --sim-seed INTEGER      Set the simulator seed\n  -gs, --gen-scenario PATH     Diff. sim config file for additional scenario\n                               test\n  -h, --help                   Show this message and exit.\n```\n\nIgnore potential `tensorflow` warnings.\n\n### Training and testing\n\nExample for short training then testing:\n\n```bash\ndeepcoord res/config/agent/sample_agent.yaml res/networks/sample_network.graphml res/service_functions/abc.yaml res/config/simulator/sample_config.yaml 10 --append-test\n```\n\nResults are stored under `results/` according to the input arguments and the current time stamp.\nThere, you'll find copies of the used inputs, the trained weights, logs, and all result files of any test runs that you performed with these weights.\n\n### Testing\n\nTo run another test run with the trained weights, specify the `<timestamp_seed>` of the training run. For testing, it is recommended to use 200 steps as it is the duration of one episode and use `-e` to specify the number of testing episodes.\nFor example:\n\n```bash\ndeepcoord res/config/agent/sample_agent.yaml res/networks/sample_network.graphml res/service_functions/abc.yaml res/config/simulator/sample_config.yaml 200 -t <timestamp_seed> -e 1\n```\n\n### Testing with a different simulator configuration (Generalization)\n\nTo train an agent and test it on multiple scenarios (simulator configurations), use the `-gs` to specify a different simulator config file to test in combination with `--append-test`.\n\nExample for testing with generalization:\n\n```bash\ndeepcoord res/config/agent/sample_agent.yaml res/networks/sample_network.graphml res/service_functions/abc.yaml res/config/simulator/sample_config.yaml 1000 --append-test -gs res/config/simulator/sample_config.yaml\n```\n\n## Learning Curves using Tensorboard\n\nTo view the learning curve of all agents, i.e., the episode reward over time, use `tensorboard`:\n\n```bash\ntensorboard --logdir==./graph\n```\n\nYou can also filter to only show curves of a specific agent config, network (and service and config) by setting the `--logdir` correspondingly:\n\n```bash\ntensorboard --logdir==./graph/<agent_config>/<network>/<service>/<simulator_config>\n```\n\n## Visualizing/Analyzing Results\n\nTo get a better understanding of what the agent is doing, there is an Juypter notebook `eval_example.ipynb`.\nIt's just an example; you won't be able to run it without all the results (which are too large for the repo).\n\nTo create a similar notebook for evaluation:\n\n```bash\n# first time installation\npip install -r eval_requirements.txt\n# run jupyter server\njupyter lab\n```\n\n_Note:_ If you're running on the server, you should start the Jupyter server in a screen with the following command:\n\n```bash\njupyter notebook --ip 0.0.0.0 --no-browser\n```\n\nYou can then access it over the server's URL at port 8888 at the `/lab` endpoint. For authentication, copy and paste the token that is displayed whed starting the Jupyter server.\n\nAdditionally, the `coord-sim` simulator provides the option to generate animations of the learned policy: \nSee [coord-sim Readme](https://github.com/RealVNF/coord-sim#create-episode-animations).\n\n\n## Training and testing on multiple scenarios\n\nThere is script provided in the `scripts` folder that utilizes the [GNU Parallel](https://www.gnu.org/software/parallel/) utility to run multiple agents at the same time to speed up the training process.\n\n```bash\n./scripts/run_parallel.sh\n```\n\nTo run long training sessions in remote environments without risking to stop the sessions due to possible connectivity issues, it is recommended to run the experiments with the `screen` linux tool.\n\n- For that, start a new `screen` with `screen -S rl-parallel`.\n- Configure the agent and the network, service, config files in the `scripts` directory to match the scenarios that you want to run. Here, the lines of network, service, config are matched by lines (not all permutations), eg, 1. network is matched with 1. service and 1. config. Then all seeds are used for all scenarios.\n- Inside the screen, with the venv activated, run `./scripts/run_parallel.sh` from the project root.\n\n## Acknowledgement\n\nThis project has received funding from German Federal Ministry of Education and Research ([BMBF](https://www.bmbf.de/)) through Software Campus grant 01IS17046 ([RealVNF](https://realvnf.github.io/)).\n\n<p align=\"center\">\n\t<img src=\"docs/software_campus.png\" width=\"200\"/>\n\t<img src=\"docs/BMBF_sponsored_by.jpg\" width=\"250\"/>\n</p>\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/RealVNF/DeepCoord",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "deepcoord",
    "package_url": "https://pypi.org/project/deepcoord/",
    "platform": "",
    "project_url": "https://pypi.org/project/deepcoord/",
    "project_urls": {
      "Homepage": "https://github.com/RealVNF/DeepCoord"
    },
    "release_url": "https://pypi.org/project/deepcoord/1.1.1/",
    "requires_dist": [
      "click (==7.0)",
      "numpy (<1.19,>=1.16.5)",
      "keras (==2.2.5)",
      "keras-rl (==0.4.2)",
      "tensorflow (==1.14.0)",
      "cloudpickle (==1.2)",
      "gym[atari] (==0.14.0)",
      "pandas (==1.0.0)",
      "h5py (==2.10)",
      "flake8",
      "nose2"
    ],
    "requires_python": ">=3.6.*",
    "summary": "DeepCoord: Self-Learning Network and Service Coordination Using Deep Reinforcement Learning",
    "version": "1.1.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12176822,
  "releases": {
    "1.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "593f04a990f115c5b1a19b993a323bd5958f54e638ad379ad456c620443f607b",
          "md5": "8a237ad17cd596503eb4d862249cde29",
          "sha256": "bfeb986aa140b2857310bb207c4971377feabe1f495be26a038f0540ff096318"
        },
        "downloads": -1,
        "filename": "deepcoord-1.1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "8a237ad17cd596503eb4d862249cde29",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6.*",
        "size": 28656,
        "upload_time": "2021-12-01T12:53:10",
        "upload_time_iso_8601": "2021-12-01T12:53:10.783670Z",
        "url": "https://files.pythonhosted.org/packages/59/3f/04a990f115c5b1a19b993a323bd5958f54e638ad379ad456c620443f607b/deepcoord-1.1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e3356618d95be5e3e6a5ef5714ce86692f282eaf05010fef09bdb8884dd48de7",
          "md5": "eb9034bc95b68f1010d2cbf0b3a0dd15",
          "sha256": "d8b30ade09b8eb4c46cbb779336cc54bf34de8769f96fd32fd527caadb0c0b2b"
        },
        "downloads": -1,
        "filename": "deepcoord-1.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "eb9034bc95b68f1010d2cbf0b3a0dd15",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6.*",
        "size": 23885,
        "upload_time": "2021-12-01T12:53:12",
        "upload_time_iso_8601": "2021-12-01T12:53:12.281355Z",
        "url": "https://files.pythonhosted.org/packages/e3/35/6618d95be5e3e6a5ef5714ce86692f282eaf05010fef09bdb8884dd48de7/deepcoord-1.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "593f04a990f115c5b1a19b993a323bd5958f54e638ad379ad456c620443f607b",
        "md5": "8a237ad17cd596503eb4d862249cde29",
        "sha256": "bfeb986aa140b2857310bb207c4971377feabe1f495be26a038f0540ff096318"
      },
      "downloads": -1,
      "filename": "deepcoord-1.1.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "8a237ad17cd596503eb4d862249cde29",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6.*",
      "size": 28656,
      "upload_time": "2021-12-01T12:53:10",
      "upload_time_iso_8601": "2021-12-01T12:53:10.783670Z",
      "url": "https://files.pythonhosted.org/packages/59/3f/04a990f115c5b1a19b993a323bd5958f54e638ad379ad456c620443f607b/deepcoord-1.1.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "e3356618d95be5e3e6a5ef5714ce86692f282eaf05010fef09bdb8884dd48de7",
        "md5": "eb9034bc95b68f1010d2cbf0b3a0dd15",
        "sha256": "d8b30ade09b8eb4c46cbb779336cc54bf34de8769f96fd32fd527caadb0c0b2b"
      },
      "downloads": -1,
      "filename": "deepcoord-1.1.1.tar.gz",
      "has_sig": false,
      "md5_digest": "eb9034bc95b68f1010d2cbf0b3a0dd15",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6.*",
      "size": 23885,
      "upload_time": "2021-12-01T12:53:12",
      "upload_time_iso_8601": "2021-12-01T12:53:12.281355Z",
      "url": "https://files.pythonhosted.org/packages/e3/35/6618d95be5e3e6a5ef5714ce86692f282eaf05010fef09bdb8884dd48de7/deepcoord-1.1.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}