{
  "info": {
    "author": "Lorenzo Adreani",
    "author_email": "adreanilorenzo@outlook.it",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Text Categorization\n\nProgetto per il corso di AI per l'universitÃ  degli studi di Firenze.\n\ntext-categorization Ã¨ un software, che serve per studiare l'andamento predittivo di due diversi modelli: Il Multi-variate Bernolli e il Multinomial.\n\nSi vuole ottenere gli stessi risultati di [(McCallum & Nigam, 1998)](/documents/text-categorization.pdf)\n\nNel multinomial Ã¨ presente anche un diverso approccio per la feature selection, che viene chiamato [KL-Divergence](/documents/kl.pdf).\n\n## Dipendenze\n\nLe seguenti dipendenze sono necessarie per il funzionamento del programma\n- Sklearn\n- Matplotlib\n- PrettyTable\n- Progressbar\n\n```bash\npip install sklearn matplotlib progressbar PrettyTable\n```\n\n## Struttura\n\nLa struttra delle classi Ã¨ la seguente.\n\n![uml](documents/uml/UMLCompleto.jpg)\n\n### Descrizione classi\n\nDataset: Classe principale che gestisce tutta la struttura, si occupa di leggere i gruppi, creare il dizionario pesato e effettua i test.\n\nGroup/Document: Classi che interpretano la gerarchia della directory del dataset. \n\nGroupedWord/DocumentWord: Classi che rappresentano la parola trovata, rispettivamente per le classi Group e Document. (Vedi sotto la modalitÃ  di raggruppamento)\n\nDictionary: Classe che gestisce le parole (GroupedWord/CountedWord) in modo ordinato e utilizza la ricerca binaria per ottenere una ottima efficenza.\n\nWeightedDictionary: Classe astratta che eredita da Dictionary. Ma diversamente da Dictionary le sue parole sono dei WeightedWordVector.\n\nMBMWeightedDictionary, MMWeightedDictionary: Classi che implementano il WeightedDictionary, e calcolano i parametri a seconda del modello predittivo Multi-variate o Multinomial.\n\nWeightedWordVector: Classe astratta che contiene al suo interno un vettore di GroupedWord pari al numero delle classi totali. Si occupa di calcolare i parametri relativi alla parola data la classe.\n\nMBMWeightedWordVector, MMWeightedWordVector: Classi che implementano WeightedWordVector, e creano i pesi a seconda del modello predittivo.\n\nTest: Classe che tiene traccia dei risultati di un particolare test.\n\n### Sequenza train e test\n\nQui viene mostrata la sequenza dei principali processi in train e test.\n\n![flow train test](documents/uml/Flow-train-test.jpg)\n\n### Grouping\n\nQuesta Ã¨ la visualizzazione della modalitÃ  di raggruppamento. In alto la sequenza di raggruppamento in basso la relazione con le classi.\n\n![Grouping](documents/uml/grouping.jpg)\n\n## Comandi\n\nIl software prevede 5 comandi principali, piÃ¹ eventuali argomenti posizionali che possono essere sia opzionali che obbligatori a seconda del comando.\n\n### import-data\n\nQuesto comando serve per importare il dataset nella directory 'data' del progetto. PuÃ² anche essere aggiunta manualmente, semplicemente copiando il dataset nella directory e assicurandosi che i dati siano divisi in 'train' e 'test'.\n\nArgomenti posizionali:\n- -p | --path: Serve per indicare il percorso alla cartella contenente il dataset. (Obbligatorio)\n- -s | --split [ratio]: Indica che il dataset deve essere diviso in 'train' e 'test', puÃ² anche essere indicato il rapporto di suddivisione. Default: 0.2 (80:20)\n- -n | --name [name]: Imposta il nome da dare al dataset \n\n### start-learning\n\nQuesto comando inizia a leggere il dataset, e crea il dizionario con i suoi parametri.\n\nArgomenti posizionali:\n- -n | --name [name]: Il nome del dataset selezionato. (Obbligatorio)\n- -sw | --stop-words [words ...]: Indica quali sono le stop words da rimuovere. Queste parole non verranno aggiunte al dizionario.\n- -he | --headers [headers ...]: Se il dataset ha degli headers, che devono essere rimossi per non comprometere il risultato dei test, vengono indicati qui l'inizi delgli headers. (Esempio in news Ã© stato indicato come headers: \"Newsgroups:\")\n- -fr | --fast-reading: Imposta questo parametro per avere una lettura piÃ¹ veloce del dataset, questo in pratica rimuove la fase di tokenization e le parole saranno divise medianti gli spazi, questo comporta un maggior numero di parole trovate durante la lettura.\n\n### start-testing\n\nEffettua i test per tutti i file della sezione 'test' del dataset scelto.\n\nArgomenti posizionali:\n- -n | --name [name]: Il nome del dataset selezionato. (Obbligatorio)\n- -fl | --feature-lenght [V ...]: Imposta il numero massimo di parole del dizionario per la feature selection, indicare con -1 se si vogliono usare tutte le parole.\n- -kl | --kl-feature: Imposta come feature selection la versione KL al posto della informazione mutuale. Questo avviene solo per il modello multinomiale.\n\n### plot-result\n\nMostra i risultati del test precedente.\n\nArgomenti posizionali:\n- -n | --name [name]: Il nome del dataset selezionato. (Obbligatorio)\n\n### show-datasets\n\nMostra i datasets disponibili.\n\n## Risultati\n\nData la natura casuale della suddivisione dei file in Train e Test, i risultati ottenuti possono variare, anche se in maniera lieve. I risultati qui riportati sono ottenuti tramite i dataset reperibili nella sezione dataset.\n\nSono stati utilizzati i 4 datasets scelti, sono stati messi a confronto i due modelli predittivi ed Ã¨ stato analizato il comportamento delle due varianti di feture selection. \n\n### Newsgroup\n\nIl dataset Ã¨ formato da 19 gruppi e sono stati utilizzati tutti. Come headers Ã¨ stato impostato \"Newsgroups:\".\n\nMulti-variate Bernulli supera il multinomial in dizionari relativamente piÃ¹ piccoli, ma al aumentare delle parole il multinomial ha una performance superiore.\nIn entrambi casi si ha un miglioramento in termini di accuratezza al aumentare del numero di parole considerate. Arrivando fino al 85% di accuratezza per quanto riguarda il multinomial, e 80% per il multi-variate.\n\nIn questo caso il modello multinomiale, con il KL, ottiene un maggior incremento nell'accuratezza rispetto all'informazione mutuale.\n\n#### Mutual information\n\n![News Result](/results/plots/newsIM.png)\n\n#### KL feature-selection\n\n![News Result](/results/plots/newsKL.png)\n\n### Webkb\n\nIl dataset Webkb Ã¨ formato da 7 gruppi, ma ne sono state utilizzati solo 4: student, faculty, staff e course.\n\nQui possiamo notare come il multi-variate giÃ  da subito ha un accuratezza molto elevata, con un massimo a 100 parole, e tiene un andamento costante.\nNel caso multinomiale si ha un accuratezza minore rispetto al multi-variate nel caso dei dizionari piccoli, e va ad aumentare man mano che le parole del dizionario aumentano.\n\nAnche qui con la versione KL si ottengono dei risultati migliori.\n\n#### Mutual information\n\n![Webkb Result](/results/plots/webkbIM.png)\n\n#### KL feature-selection\n\n![Webkb Result](/results/plots/webkbKL.png)\n\n### Sector 48\n\nIl dataset Ã¨ formato da categorie con vari sotto gruppi, sono stati quindi tutti trattati come gruppi diversi, e ne sono risultati in totale 48.\n\nQui il divario con poche parole Ã¨ piÃ¹ ampio, e il multinomial supera il multi-variate quando ha all'incirca 5000 parole nel dizionario.\n\nIn questo caso la versione KL per la feature selection si compora peggio rispetto all'informazione mutuale e non si ottengono performance migliori rispetto al multivariate, fino a quando non vengono usate tutte le parole.\n\n#### Mutual information\n\n![Sector Result](/results/plots/Sector48IM.png)\n\n#### KL feature-selection\n\n![Sector Result](/results/plots/Sector48KL.png)\n\n### Film\n\nIl dataset Ã¨ formato solo da due gruppi positivo e negativo. (nel dataset e presente anche una terza categoria che Ã¨ stata rimossa)\n\nEntrambi qui si comportano bene giÃ  con poche parole e tengono un andamento piÃ¹ o meno costante.\n\nQui abbiamo poca differenza tra il KL e l'informazione mutuale.\n\n#### Mutual information\n\n![Film result](/results/plots/filmIM.png)\n\n#### KL feature-selection\n\n![Film result](/results/plots/filmKL.png)\n\n## Conclusioni\n\nIn generale il Multi-variate Bernulli Model supera il Multinomial, quando vengono selezionate relativamente poche parole dal dizionario, mentre il Multinomial tende ad avere una maggior accuratezza con l'utilizzo completo delle parole nel dizionario.\n\nPer quanto riguarda le due tipologie di feature selection, la versione KL Ã¨ quella che ottiene migliori risultati la maggior parte delle volte, ma non sempre accade come nel caso del dataset 'Sector48'.\n\n## Riferimenti\n\n[Testo assegnato](/documents/Adreani.pdf)\n\n[(McCallum & Nigam, 1998)](/documents/text-categorization.pdf)\n\n[KL-Selection](/documents/kl.pdf)\n\n## Datasets:\n\nNews: http://www.cs.cmu.edu/afs/cs/project/theo-11/www/naive-bayes/20_newsgroups.tar.gz\n\nSector: http://archive.ics.uci.edu/ml/machine-learning-databases/00239/corpus.zip\n\nWebkb: http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/webkb-data.gtar.gz\n\nFilm: http://ai.stanford.edu/~amaas/data/sentiment/ \n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/kinqert/text-categorization",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "tcat",
    "package_url": "https://pypi.org/project/tcat/",
    "platform": "",
    "project_url": "https://pypi.org/project/tcat/",
    "project_urls": {
      "Homepage": "https://github.com/kinqert/text-categorization"
    },
    "release_url": "https://pypi.org/project/tcat/0.1.2/",
    "requires_dist": [
      "Sklearn"
    ],
    "requires_python": ">=3.7",
    "summary": "Package for machine learning with naive bayes classifier",
    "version": "0.1.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12019329,
  "releases": {
    "0.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a07401dcf077a415982fd2474e09df138fb5087628b59e4b917afa54c483fe8e",
          "md5": "059a9135d24e93d953d5bea0aeb2f649",
          "sha256": "03db682dfc8b01cadbbe09bb9b16421eacc4875acf7da87f3ba85066635de4c3"
        },
        "downloads": -1,
        "filename": "tcat-0.1.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "059a9135d24e93d953d5bea0aeb2f649",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 45363,
        "upload_time": "2021-11-14T16:34:03",
        "upload_time_iso_8601": "2021-11-14T16:34:03.353507Z",
        "url": "https://files.pythonhosted.org/packages/a0/74/01dcf077a415982fd2474e09df138fb5087628b59e4b917afa54c483fe8e/tcat-0.1.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "a07401dcf077a415982fd2474e09df138fb5087628b59e4b917afa54c483fe8e",
        "md5": "059a9135d24e93d953d5bea0aeb2f649",
        "sha256": "03db682dfc8b01cadbbe09bb9b16421eacc4875acf7da87f3ba85066635de4c3"
      },
      "downloads": -1,
      "filename": "tcat-0.1.2-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "059a9135d24e93d953d5bea0aeb2f649",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 45363,
      "upload_time": "2021-11-14T16:34:03",
      "upload_time_iso_8601": "2021-11-14T16:34:03.353507Z",
      "url": "https://files.pythonhosted.org/packages/a0/74/01dcf077a415982fd2474e09df138fb5087628b59e4b917afa54c483fe8e/tcat-0.1.2-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}