{
  "info": {
    "author": "Aleksey Korshuk",
    "author_email": "ale-kor02@mail.ru",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Topic :: Scientific/Engineering :: Artificial Intelligence"
    ],
    "description": "# Optimum Transformers\n\n[![Tests](https://github.com/AlekseyKorshuk/optimum-transformers/actions/workflows/python-app.yml/badge.svg)](https://github.com/AlekseyKorshuk/optimum-transformers/actions/workflows/python-app.yml)\n[![License](https://img.shields.io/github/license/AlekseyKorshuk/optimum-transformers.svg?color=blue)](https://github.com/AlekseyKorshuk/optimum-transformers/blob/master/LICENSE)\n[![PyPI](https://img.shields.io/pypi/v/optimum-transformers)](https://pypi.org/project/optimum-transformers/)\n\n<img src=\"https://raw.githubusercontent.com/AlekseyKorshuk/optimum-transformers/master/data/social_preview.png?raw=True\" width=\"1200\">\n\nAccelerated NLP pipelines for fast inference ðŸš€ on CPU and GPU. Built with ðŸ¤—Transformers, Optimum and ONNX runtime.\n\n## Installation:\n\nWith PyPI:\n\n```bash\npip install optimum-transformers\n```\n\nOr directly from GitHub:\n\n```bash\npip install git+https://github.com/AlekseyKorshuk/optimum-transformers\n```\n\n## Usage:\n\nThe pipeline API is similar to transformers [pipeline](https://huggingface.co/transformers/main_classes/pipelines.html)\nwith just a few differences which are explained below.\n\nJust provide the path/url to the model, and it'll download the model if needed from\nthe [hub](https://huggingface.co/models) and automatically create onnx graph and run inference.\n\n```python\nfrom optimum_transformers import pipeline\n\n# Initialize a pipeline by passing the task name and \n# set onnx to True (default value is also True)\nnlp = pipeline(\"sentiment-analysis\", use_onnx=True)\nnlp(\"Transformers and onnx runtime is an awesome combo!\")\n# [{'label': 'POSITIVE', 'score': 0.999721109867096}]  \n```\n\nOr provide a different model using the `model` argument.\n\n```python\nfrom optimum_transformers import pipeline\n\nnlp = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\", use_onnx=True)\nnlp(question=\"What is ONNX Runtime ?\",\n         context=\"ONNX Runtime is a highly performant single inference engine for multiple platforms and hardware\")\n# {'answer': 'highly performant single inference engine for multiple platforms and hardware', 'end': 94,\n# 'score': 0.751201868057251, 'start': 18}\n```\n\n```python\nfrom optimum_transformers import pipeline\n\nnlp = pipeline(\"ner\", model=\"mys/electra-base-turkish-cased-ner\", use_onnx=True, optimize=True,\n                    grouped_entities=True)\nnlp(\"adana kebap Ã¼lkemizin Ã¶nemli lezzetlerinden biridir.\")\n# [{'entity_group': 'B-food', 'score': 0.869149774312973, 'word': 'adana kebap'}]\n```\n\nSet `use_onnx` to `False` for standard torch inference. Set `optimize` to `True` for quantize with ONNX. ( set `use_onnx` to\nTrue)\n\n## Supported pipelines\n\nYou can create `Pipeline` objects for the following down-stream tasks:\n\n- `feature-extraction`: Generates a tensor representation for the input sequence\n- `ner` and `token-classification`: Generates named entity mapping for each word in the input sequence.\n- `sentiment-analysis`: Gives the polarity (positive / negative) of the whole input sequence. Can be used for any text\n  classification model.\n- `question-answering`: Provided some context and a question referring to the context, it will extract the answer to the\n  question in the context.\n- `text-classification`: Classifies sequences according to a given number of classes from training.\n- `zero-shot-classification`: Classifies sequences according to a given number of classes directly in runtime.\n- `fill-mask`: The task of masking tokens in a sequence with a masking token, and prompting the model to fill that mask\n  with an appropriate token.\n- `text-generation`: The task of generating text according to the previous text provided.\n\nCalling the pipeline for the first time loads the model, creates the onnx graph, and caches it for future use. Due to\nthis, the first load will take some time. Subsequent calls to the same model will load the onnx graph automatically from\nthe cache.\n\n## Benchmarks\n\n> Note: For some reason, onnx is slow on colab notebook, so you won't notice any speed-up there. Benchmark it on your own hardware.\n\nCheck our example of benchmarking: [example](./examples/benchmark).\n\nFor detailed benchmarks and other information refer to this blog post and notebook.\n\n- [Accelerate your NLP pipelines using Hugging Face Transformers and ONNX Runtime](https://medium.com/microsoftazure/accelerate-your-nlp-pipelines-using-hugging-face-transformers-and-onnx-runtime-2443578f4333)\n- [Exporting ðŸ¤— transformers model to ONNX](https://github.com/huggingface/transformers/blob/master/notebooks/04-onnx-export.ipynb)\n\n> Note: These results were collected on my local machine. So if you have high performance machine to benchmark, please contact me.\n\n**Benchmark `sentiment-analysis` pipeline**\n\n![](https://raw.githubusercontent.com/AlekseyKorshuk/optimum-transformers/master/data/sentiment_analysis_benchmark.jpg)\n\n**Benchmark `zero-shot-classification` pipeline**\n\n![](https://raw.githubusercontent.com/AlekseyKorshuk/optimum-transformers/master/data/zero_shot_classification_benchmark.jpg)\n\n**Benchmark `token-classification` pipeline**\n\n![](https://raw.githubusercontent.com/AlekseyKorshuk/optimum-transformers/master/data/token_classification_benchmark.jpg)\n\n![](https://raw.githubusercontent.com/AlekseyKorshuk/optimum-transformers/master/data/token_classification_benchmark2.jpg)\n\n**Benchmark `question-answering` pipeline**\n\n![](https://raw.githubusercontent.com/AlekseyKorshuk/optimum-transformers/master/data/question_answering_benchmark.jpg)\n\n**Benchmark `fill-mask` pipeline**\n\n![](https://raw.githubusercontent.com/AlekseyKorshuk/optimum-transformers/master/data/fill_mask_benchmark.jpg)\n\n## About\n\n*Built by Aleksey Korshuk*\n\n[![Follow](https://img.shields.io/github/followers/AlekseyKorshuk?style=social)](https://github.com/AlekseyKorshuk)\n\n[![Follow](https://img.shields.io/twitter/follow/alekseykorshuk?style=social)](https://twitter.com/intent/follow?screen_name=alekseykorshuk)\n\n[![Follow](https://img.shields.io/badge/dynamic/json?color=blue&label=Telegram%20Channel&query=%24.result&url=https%3A%2F%2Fapi.telegram.org%2Fbot1929545866%3AAAFGhV-KKnegEcLiyYJxsc4zV6C-bdPEBtQ%2FgetChatMemberCount%3Fchat_id%3D-1001253621662&style=social&logo=telegram)](https://t.me/joinchat/_CQ04KjcJ-4yZTky)\n\nðŸš€ If you want to contribute to this project OR create something cool together â€” contact\nme: [link](https://github.com/AlekseyKorshuk)\n\nStar this repository:\n\n[![GitHub stars](https://img.shields.io/github/stars/AlekseyKorshuk/optimum-transformers?style=social)](https://github.com/AlekseyKorshuk/optimum-transformers)\n\n## Resources\n\n* Inspired by [Huggingface Infinity](https://huggingface.co/infinity)\n* First step done by [Suraj Patil](https://github.com/patil-suraj/onnx_transformers)\n* [Optimum](https://huggingface.co/docs/optimum/index)\n* [ONNX](https://onnx.ai)\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/AlekseyKorshuk/optimum-transformers",
    "keywords": "ONNX,onnxruntime,NLP,transformer,transformers,inference,fast inference,Optimum,infinity",
    "license": "Apache",
    "maintainer": "",
    "maintainer_email": "",
    "name": "optimum-transformers",
    "package_url": "https://pypi.org/project/optimum-transformers/",
    "platform": null,
    "project_url": "https://pypi.org/project/optimum-transformers/",
    "project_urls": {
      "Documentation": "https://github.com/AlekseyKorshuk/optimum-transformers",
      "Homepage": "https://github.com/AlekseyKorshuk/optimum-transformers",
      "Source": "https://github.com/AlekseyKorshuk/optimum-transformers"
    },
    "release_url": "https://pypi.org/project/optimum-transformers/0.2.1/",
    "requires_dist": [
      "coloredlogs (<16.0,>=15.0)",
      "datasets (<3.0,>=2.0)",
      "matplotlib (<4.0,>=3.5)",
      "onnx (<2.0,>=1.10)",
      "onnxruntime (==1.10)",
      "optimum (==1.0.0)",
      "psutil (<6.0,>=5.9)",
      "seaborn (<1.0,>=0.11)",
      "transformers (<5.0,>=4.15)",
      "tokenizers (<0.12,>=0.11.6)",
      "sentencepiece (<0.2,>=0.1.96)",
      "pytest ; extra == 'dev'",
      "pytest-xdist ; extra == 'dev'",
      "timeout-decorator ; extra == 'dev'",
      "psutil ; extra == 'dev'",
      "black (>=20.8b1) ; extra == 'dev'",
      "isort (>=5) ; extra == 'dev'",
      "flake8 ; extra == 'dev'",
      "black (>=20.8b1) ; extra == 'quality'",
      "isort (>=5) ; extra == 'quality'",
      "flake8 ; extra == 'quality'",
      "pytest ; extra == 'testing'",
      "pytest-xdist ; extra == 'testing'",
      "timeout-decorator ; extra == 'testing'",
      "psutil ; extra == 'testing'"
    ],
    "requires_python": ">=3.6.0",
    "summary": "Accelerated nlp pipelines using Transformers, Optimum and ONNX Runtime",
    "version": "0.2.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 13376931,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6a54954ce30afa279b03bd15b377c329aba2335eb82349990e65aecaa1129f53",
          "md5": "da858e1c1af4329122ca4e6594a7b860",
          "sha256": "a34d129a55ebc5f5515bfedfafc892db50b5d465a97540b7a409e3e8246e3b8a"
        },
        "downloads": -1,
        "filename": "optimum_transformers-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "da858e1c1af4329122ca4e6594a7b860",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6.0",
        "size": 70881,
        "upload_time": "2022-03-24T15:53:42",
        "upload_time_iso_8601": "2022-03-24T15:53:42.832726Z",
        "url": "https://files.pythonhosted.org/packages/6a/54/954ce30afa279b03bd15b377c329aba2335eb82349990e65aecaa1129f53/optimum_transformers-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "332d1e501cf8fd0bebb5da6c607dbc939e3e77a2f512587a1030ba5c1afee2de",
          "md5": "d545e42ee2c0f280b123b5cdeec45a34",
          "sha256": "3c8614164190a2446f6b43a617848efdabb7e1dcbe8024f541dcf854fb74cfe9"
        },
        "downloads": -1,
        "filename": "optimum_transformers-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "d545e42ee2c0f280b123b5cdeec45a34",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6.0",
        "size": 62042,
        "upload_time": "2022-03-24T15:53:44",
        "upload_time_iso_8601": "2022-03-24T15:53:44.692625Z",
        "url": "https://files.pythonhosted.org/packages/33/2d/1e501cf8fd0bebb5da6c607dbc939e3e77a2f512587a1030ba5c1afee2de/optimum_transformers-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0c81ddb960c2f468bb1c47333cbbd58e4027f9761315214b33b708121c5e9992",
          "md5": "6955a4c4aea13e90f92457d885082eab",
          "sha256": "5fe1b01afd377641e004569fbe133b2e6b43556f7a2a201c795cacfe38f99f38"
        },
        "downloads": -1,
        "filename": "optimum_transformers-0.2.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "6955a4c4aea13e90f92457d885082eab",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6.0",
        "size": 59694,
        "upload_time": "2022-03-31T16:57:40",
        "upload_time_iso_8601": "2022-03-31T16:57:40.082983Z",
        "url": "https://files.pythonhosted.org/packages/0c/81/ddb960c2f468bb1c47333cbbd58e4027f9761315214b33b708121c5e9992/optimum_transformers-0.2.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fa243627f80807058e5e67ef018e9736252f49cc50a76418bff55515b7c4e9ba",
          "md5": "b35844c2d6a3a8dd876bbea2818c73b3",
          "sha256": "dd2777a9810431374b99227cfdbaef7f2e8450aea5450f84e25fc6ebf333485d"
        },
        "downloads": -1,
        "filename": "optimum_transformers-0.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "b35844c2d6a3a8dd876bbea2818c73b3",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6.0",
        "size": 55320,
        "upload_time": "2022-03-31T16:57:41",
        "upload_time_iso_8601": "2022-03-31T16:57:41.168813Z",
        "url": "https://files.pythonhosted.org/packages/fa/24/3627f80807058e5e67ef018e9736252f49cc50a76418bff55515b7c4e9ba/optimum_transformers-0.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c3c9e87f5134b3dd6cc7c7216055b3f62d374bb0f8d83dbbc965c4bdedb1b260",
          "md5": "90d70539ccd6528ea1756fc7792df826",
          "sha256": "44615687e8b5110f3090bf9888de25066d4436f14577913f79bc2073ef5c78a9"
        },
        "downloads": -1,
        "filename": "optimum_transformers-0.2.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "90d70539ccd6528ea1756fc7792df826",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6.0",
        "size": 59773,
        "upload_time": "2022-04-01T16:57:52",
        "upload_time_iso_8601": "2022-04-01T16:57:52.727158Z",
        "url": "https://files.pythonhosted.org/packages/c3/c9/e87f5134b3dd6cc7c7216055b3f62d374bb0f8d83dbbc965c4bdedb1b260/optimum_transformers-0.2.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "57ba65cd0927da236db40e5a8b33a006add8c78a0111668f711e10b7def73395",
          "md5": "1c3c476ee5b1a3d7142eb65b45bc29f2",
          "sha256": "e5e194da3c8770f35f9e173d7285f4727b88ec5af65a6e584a56f2b80ff1c224"
        },
        "downloads": -1,
        "filename": "optimum_transformers-0.2.1.tar.gz",
        "has_sig": false,
        "md5_digest": "1c3c476ee5b1a3d7142eb65b45bc29f2",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6.0",
        "size": 55369,
        "upload_time": "2022-04-01T16:57:54",
        "upload_time_iso_8601": "2022-04-01T16:57:54.630503Z",
        "url": "https://files.pythonhosted.org/packages/57/ba/65cd0927da236db40e5a8b33a006add8c78a0111668f711e10b7def73395/optimum_transformers-0.2.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "c3c9e87f5134b3dd6cc7c7216055b3f62d374bb0f8d83dbbc965c4bdedb1b260",
        "md5": "90d70539ccd6528ea1756fc7792df826",
        "sha256": "44615687e8b5110f3090bf9888de25066d4436f14577913f79bc2073ef5c78a9"
      },
      "downloads": -1,
      "filename": "optimum_transformers-0.2.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "90d70539ccd6528ea1756fc7792df826",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6.0",
      "size": 59773,
      "upload_time": "2022-04-01T16:57:52",
      "upload_time_iso_8601": "2022-04-01T16:57:52.727158Z",
      "url": "https://files.pythonhosted.org/packages/c3/c9/e87f5134b3dd6cc7c7216055b3f62d374bb0f8d83dbbc965c4bdedb1b260/optimum_transformers-0.2.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "57ba65cd0927da236db40e5a8b33a006add8c78a0111668f711e10b7def73395",
        "md5": "1c3c476ee5b1a3d7142eb65b45bc29f2",
        "sha256": "e5e194da3c8770f35f9e173d7285f4727b88ec5af65a6e584a56f2b80ff1c224"
      },
      "downloads": -1,
      "filename": "optimum_transformers-0.2.1.tar.gz",
      "has_sig": false,
      "md5_digest": "1c3c476ee5b1a3d7142eb65b45bc29f2",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6.0",
      "size": 55369,
      "upload_time": "2022-04-01T16:57:54",
      "upload_time_iso_8601": "2022-04-01T16:57:54.630503Z",
      "url": "https://files.pythonhosted.org/packages/57/ba/65cd0927da236db40e5a8b33a006add8c78a0111668f711e10b7def73395/optimum_transformers-0.2.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}