{
  "info": {
    "author": "Chris van den Berg",
    "author_email": "fake_email@gmail.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# String Grouper  \n<!-- Some cool decorations -->\n[![pypi](https://badgen.net/pypi/v/string-grouper)](https://pypi.org/project/string-grouper)\n[![license](https://badgen.net/pypi/license/string_grouper)](https://github.com/Bergvca/string_grouper)\n[![lastcommit](https://badgen.net/github/last-commit/Bergvca/string_grouper)](https://github.com/Bergvca/string_grouper)\n[![codecov](https://codecov.io/gh/Bergvca/string_grouper/branch/master/graph/badge.svg?token=AGK441CQDT)](https://codecov.io/gh/Bergvca/string_grouper)\n<!-- [![github](https://shields.io/github/v/release/Bergvca/string_grouper)](https://github.com/Bergvca/string_grouper) -->\n\n<details>\n<summary>Click to see image</summary>\n<br>\n<center><img width=\"100%\" src=\"https://raw.githubusercontent.com/Bergvca/string_grouper/master/tutorials/sec__edgar_company_info_group003c.svg\"></center>\n\nThe image displayed above is a visualization of the graph-structure of one of the groups of strings found by `string_grouper`.  Each circle (node) represents a string, and each connecting arc (edge) represents a match between a pair of strings with a similarity score above a given threshold score (here `0.8`).  \n\nThe ***centroid*** of the group, as determined by `string_grouper` (see [tutorials/group_representatives.md](https://github.com/Bergvca/string_grouper/blob/master/tutorials/group_representatives.md) for an explanation), is the largest node, also with the most edges originating from it.  A thick line in the image denotes a strong similarity between the nodes at its ends, while a faint thin line denotes weak similarity.\n\nThe power of `string_grouper` is discernible from this image: in large datasets, `string_grouper` is often able to resolve indirect associations between strings even when, say, due to memory-resource-limitations, direct matches between those strings cannot be computed using conventional methods with a lower threshold similarity score.    \n\n<div style=\"text-align: center\"> &mdash;&mdash;&mdash;</div>\n\n<sup>This image was designed using the graph-visualization software Gephi 0.9.2 with data generated by `string_grouper` operating on the [sec__edgar_company_info.csv](https://www.kaggle.com/dattapiy/sec-edgar-companies-list/version/1) sample data file.</sup>\n\n---\n</details>\n\n\n**`string_grouper`** is a library that makes finding groups of similar strings within a single, or multiple, lists of strings easy â€” and fast. **`string_grouper`** uses **tf-idf** to calculate [**cosine similarities**](https://towardsdatascience.com/understanding-cosine-similarity-and-its-application-fd42f585296a) within a single list or between two lists of strings. The full process is described in the blog [Super Fast String Matching in Python](https://bergvca.github.io/2017/10/14/super-fast-string-matching.html).\n\n## Installing\n\n`pip install string-grouper`\n\n## Usage\n\n```python\nimport pandas as pd\nfrom string_grouper import match_strings, match_most_similar, \\\n\tgroup_similar_strings, compute_pairwise_similarities, \\\n\tStringGrouper\n```\n\nAs shown above, the library may be used together with `pandas`, and contains four high level functions (`match_strings`, `match_most_similar`, `group_similar_strings`, and `compute_pairwise_similarities`) that can be used directly, and one class (`StringGrouper`) that allows for a more interactive approach. \n\nThe permitted calling patterns of the four functions, and their return types, are:\n\n| Function        | Parameters | `pandas` Return Type |\n| -------------: |:-------------|:-----:|\n| `match_strings`| `(master, **kwargs)`| `DataFrame` |\n| `match_strings`| `(master, duplicates, **kwargs)`| `DataFrame` |\n| `match_strings`| `(master, master_id=id_series, **kwargs)`| `DataFrame` |\n| `match_strings`| `(master, duplicates, master_id, duplicates_id, **kwargs)`| `DataFrame` |\n| `match_most_similar`| `(master, duplicates, **kwargs)`| `Series` (if kwarg `ignore_index=True`) otherwise `DataFrame` (default)|\n| `match_most_similar`| `(master, duplicates, master_id, duplicates_id, **kwargs)`| `DataFrame` |\n| `group_similar_strings`| `(strings_to_group, **kwargs)`| `Series` (if kwarg `ignore_index=True`) otherwise `DataFrame` (default)|\n| `group_similar_strings`| `(strings_to_group, strings_id, **kwargs)`| `DataFrame` |\n| `compute_pairwise_similarities`| `(string_series_1, string_series_2, **kwargs)`| `Series` |\n\nIn the rest of this document the names, `Series` and `DataFrame`, refer to the familiar `pandas` object types.\n#### Parameters:\n\n|Name | Description |\n|:--- | :--- |\n|**`master`** | A `Series` of strings to be matched with themselves (or with those in `duplicates`). |\n|**`duplicates`** | A `Series` of strings to be matched with those of `master`. |\n|**`master_id`** (or `id_series`) | A `Series` of IDs corresponding to the strings in `master`. |\n|**`duplicates_id`** | A `Series` of IDs corresponding to the strings in `duplicates`. |\n|**`strings_to_group`** | A `Series` of strings to be grouped. |\n|**`strings_id`** | A `Series` of IDs corresponding to the strings in `strings_to_group`. |\n|**`string_series_1(_2)`** | A `Series` of strings each of which is to be compared with its corresponding string in `string_series_2(_1)`. |\n|**`**kwargs`** | Keyword arguments (see [below](#kwargs)).|\n\n***New in version 0.6.0***<a name=\"corpus\"></a>: each of the high-level functions listed above also has a `StringGrouper` method counterpart of the same name and parameters.  Calling such a method of any instance of `StringGrouper` will not rebuild the instance's underlying corpus to make string-comparisons but rather use it to perform the string-comparisons.  The input Series to the method (`master`, `duplicates`, and so on) will thus be encoded, or transformed, into tf-idf matrices, using this corpus.  For example:\n```python\n# Build a corpus using strings in the pandas Series master:\nsg = StringGrouper(master)\n# The following method-calls will compare strings first in\n# pandas Series new_master_1 and next in new_master_2\n# using the corpus already built above without rebuilding or\n# changing it in any way:\nmatches1 = sg.match_strings(new_master_1)\nmatches2 = sg.match_strings(new_master_2)\n```\n\n#### Functions:\n\n* #### `match_strings` \n   Returns a `DataFrame` containing similarity-scores of all matching pairs of highly similar strings from `master` (and `duplicates` if given).  Each matching pair in the output appears in its own row/record consisting of\n\n   1. its \"left\" part: a string (with/without its index-label) from `master`, \n   2. its similarity score, and  \n   3. its \"right\" part: a string (with/without its index-label) from `duplicates` (or `master` if `duplicates` is not given), \n\n   in that order.  Thus the column-names of the output are a collection of three groups:\n\n   1. The name of `master` and the name(s) of its index (or index-levels) all prefixed by the string `'left_'`,\n   2. `'similarity'` whose column has the similarity-scores as values, and \n   3. The name of `duplicates` (or `master` if `duplicates` is not given) and the name(s) of its index (or index-levels) prefixed by the string `'right_'`.\n\n   Indexes (or their levels) only appear when the keyword argument `ignore_index=False` (the default). (See [tutorials/ignore_index_and_replace_na.md](https://github.com/Bergvca/string_grouper/blob/master/tutorials/ignore_index_and_replace_na.md) for a demonstration.)\n\n   If either `master` or `duplicates` has no name, it assumes the name `'side'` which is then prefixed as described above.  Similarly, if any of the indexes (or index-levels) has no name it assumes its `pandas` default name (`'index'`, `'level_0'`, and so on) and is then prefixed as described above.\n\n   In other words, if only parameter `master` is given, the function will return pairs of highly similar strings within `master`.  This can be seen as a self-join where both `'left_'` and `'right_'` prefixed columns come from `master`. If both parameters `master` and `duplicates` are given, it will return pairs of highly similar strings between `master` and `duplicates`. This can be seen as an inner-join where `'left_'` and `'right_'` prefixed columns come from `master` and `duplicates` respectively.     \n\n   The function also supports optionally inputting IDs (`master_id` and `duplicates_id`) corresponding to the strings being matched.  In which case, the output includes two additional columns whose names are the names of these optional `Series` prefixed by `'left_'` and `'right_'` accordingly, and containing the IDs corresponding to the strings in the output.  If any of these `Series` has no name, then it assumes the name `'id'` and is then prefixed as described above.\n\n\n* #### `match_most_similar` \n   If `ignore_index=True`, returns a `Series` of strings, where for each string in `duplicates` the most similar string in `master` is returned.  If there are no similar strings in `master` for a given string in `duplicates` (because there is no potential match where the cosine similarity is above the threshold \\[default: 0.8\\]) then the original string in `duplicates` is returned.  The output `Series` thus has the same length and index as `duplicates`.  \n\n   For example, if an input `Series` with the values `\\['foooo', 'bar', 'baz'\\]` is passed as the argument `master`, and `\\['foooob', 'bar', 'new'\\]` as the values of the argument `duplicates`, the function will return a `Series` with values: `\\['foooo', 'bar', 'new'\\]`.\n\n   The name of the output `Series` is the same as that of `master` prefixed with the string `'most_similar_'`.  If `master` has no name, it is assumed to have the name `'master'` before being prefixed.\n\n   If `ignore_index=False` (the default), `match_most_similar` returns a `DataFrame` containing the same `Series` described above as one of its columns.  So it inherits the same index and length as `duplicates`.  The rest of its columns correspond to the index (or index-levels) of `master` and thus contain the index-labels of the most similar strings being output as values.  If there are no similar strings in `master` for a given string in `duplicates` then the value(s) assigned to this index-column(s) for that string is `NaN` by default.  However, if the keyword argument `replace_na=True`, then these `NaN` values are replaced with the index-label(s) of that string in `duplicates`.  Note that such replacements can only occur if the indexes of `master` and `duplicates` have the same number of levels.  (See [tutorials/ignore_index_and_replace_na.md](https://github.com/Bergvca/string_grouper/blob/master/tutorials/ignore_index_and_replace_na.md#MMS) for a demonstration.)\n\n   Each column-name of the output `DataFrame` has the same name as its corresponding column, index, or index-level of `master` prefixed with the string `'most_similar_'`.\n\n   If both parameters `master_id` and `duplicates_id` are also given, then a `DataFrame` is always returned with the same column(s) as described above, but with an additional column containing those IDs from these input `Series` corresponding to the output strings.  This column's name is the same as that of `master_id` prefixed in the same way as described above.  If `master_id` has no name, it is assumed to have the name `'master_id'` before being prefixed.\n\n\n* #### `group_similar_strings` \n  Takes a single `Series` of strings (`strings_to_group`) and groups them by assigning to each string one string from `strings_to_group` chosen as the group-representative for each group of similar strings found. (See [tutorials/group_representatives.md](https://github.com/Bergvca/string_grouper/blob/master/tutorials/group_representatives.md) for details on how the the group-representatives are chosen.)   \n\n  If `ignore_index=True`, the output is a `Series` (with the same name as `strings_to_group` prefixed by the string `'group_rep_'`) of the same length and index as `strings_to_group` containing the group-representative strings.  If `strings_to_group` has no name then the name of the returned `Series` is `'group_rep'`.  \n\n  For example, an input Series with values: `\\['foooo', 'foooob', 'bar'\\]` will return `\\['foooo', 'foooo', 'bar'\\]`.  Here `'foooo'` and `'foooob'` are grouped together into group `'foooo'` because they are found to be similar.  Another example can be found [below](#dedup).\n\n   If `ignore_index=False`, the output is a `DataFrame` containing the above output `Series` as one of its columns with the same name.  The remaining column(s) correspond to the index (or index-levels) of `strings_to_group` and contain the index-labels of the group-representatives as values.  These columns have the same names as their counterparts prefixed by the string `'group_rep_'`. \n\n   If `strings_id` is also given, then the IDs from `strings_id` corresponding to the group-representatives are also returned in an additional column (with the same name as `strings_id` prefixed as described above).  If `strings_id` has no name, it is assumed to have the name `'id'` before being prefixed.\n\n\n* #### `compute_pairwise_similarities`\n   Returns a `Series` of cosine similarity scores the same length and index as `string_series_1`.  Each score is the cosine similarity between the pair of strings in the same position (row) in the two input `Series`, `string_series_1` and `string_series_2`, as the position of the score in the output `Series`.  This can be seen as an element-wise comparison between the two input `Series`.\n\n\nAll functions are built using a class **`StringGrouper`**. This class can be used through pre-defined functions, for example the four high level functions above, as well as using a more interactive approach where matches can be added or removed if needed by calling the **`StringGrouper`** class directly.\n\n\n#### Options:\n\n* #### <a name=\"kwargs\"></a>`kwargs`\n\n   All keyword arguments not mentioned in the function definitions above are used to update the default settings. The following optional arguments can be used:\n\n   * **`ngram_size`**: The amount of characters in each n-gram. Default is `3`.\n   * **`regex`**: The regex string used to clean-up the input string. Default is `r\"[,-./]|\\s\"`.\n   * **`ignore_case`**: Determines whether or not letter case in strings should be ignored. Defaults to `True`.\n   * **`tfidf_matrix_dtype`**: The datatype for the tf-idf values of the matrix components. Allowed values are `numpy.float32` and `numpy.float64`.  Default is `numpy.float32`.  (Note: `numpy.float32` often leads to faster processing and a smaller memory footprint albeit less numerical precision than `numpy.float64`.)\n   * **`max_n_matches`**: The maximum number of matching strings in `master` allowed per string in `duplicates`. Default is the total number of strings in `master`.\n   * **`min_similarity`**: The minimum cosine similarity for two strings to be considered a match.\n    Defaults to `0.8`\n   * **`number_of_processes`**: The number of processes used by the cosine similarity calculation. Defaults to\n    `number of cores on a machine - 1.`\n   * **`ignore_index`**: Determines whether indexes are ignored or not.  If `False` (the default), index-columns will appear in the output, otherwise not.  (See [tutorials/ignore_index_and_replace_na.md](https://github.com/Bergvca/string_grouper/blob/master/tutorials/ignore_index_and_replace_na.md) for a demonstration.)\n   * **`replace_na`**: For function `match_most_similar`, determines whether `NaN` values in index-columns are replaced or not by index-labels from `duplicates`. Defaults to `False`.  (See [tutorials/ignore_index_and_replace_na.md](https://github.com/Bergvca/string_grouper/blob/master/tutorials/ignore_index_and_replace_na.md) for a demonstration.)\n   * **`include_zeroes`**: When `min_similarity` &le; 0, determines whether zero-similarity matches appear in the output.  Defaults to `True`.  (See [tutorials/zero_similarity.md](https://github.com/Bergvca/string_grouper/blob/master/tutorials/zero_similarity.md).)  **Note:** If `include_zeroes` is `True` and the kwarg `max_n_matches` is set then it must be sufficiently high to capture ***all*** nonzero-similarity-matches, otherwise an error is raised and `string_grouper` suggests an alternative value for `max_n_matches`.  To allow `string_grouper` to automatically use the appropriate value for `max_n_matches` then do not set this kwarg at all.\n   * **`group_rep`**: For function `group_similar_strings`, determines how group-representatives are chosen.  Allowed values are `'centroid'` (the default) and `'first'`.  See [tutorials/group_representatives.md](https://github.com/Bergvca/string_grouper/blob/master/tutorials/group_representatives.md) for an explanation.\n   * **`force_symmetries`**: In cases where `duplicates` is `None`, specifies whether corrections should be made to the results to account for symmetry, thus compensating for those losses of numerical significance which violate the symmetries. Defaults to `True`.\n   * **`n_blocks`**: This parameter is a tuple of two `int`s provided to help boost performance, if possible, of processing large DataFrames (see [Subsection Performance](#perf)), by splitting the DataFrames into `n_blocks[0]` blocks for the left operand (of the underlying matrix multiplication) and into `n_blocks[1]` blocks for the right operand before performing the string-comparisons block-wise.  Defaults to `'guess'`, in which case the numbers of blocks are estimated based on previous empirical results.  If `n_blocks = 'auto'`, then splitting is done automatically in the event of an `OverflowError`.\n\n## Examples\n\nIn this section we will cover a few use cases for which string_grouper may be used. We will use the same data set of company names as used in: [Super Fast String Matching in Python](https://bergvca.github.io/2017/10/14/super-fast-string-matching.html).\n\n### Find all matches within a single data set\n\n\n```python\nimport pandas as pd\nimport numpy as np\nfrom string_grouper import match_strings, match_most_similar, \\\n\tgroup_similar_strings, compute_pairwise_similarities, \\\n\tStringGrouper\n```\n\n\n```python\ncompany_names = '/media/chris/data/dev/name_matching/data/sec_edgar_company_info.csv'\n# We only look at the first 50k as an example:\ncompanies = pd.read_csv(company_names)[0:50000]\n# Create all matches:\nmatches = match_strings(companies['Company Name'])\n# Look at only the non-exact matches:\nmatches[matches['left_Company Name'] != matches['right_Company Name']].head()\n```\n\n\n<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>left_index</th>\n      <th>left_Company Name</th>\n      <th>similarity</th>\n      <th>right_Company Name</th>\n      <th>right_index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>15</th>\n      <td>14</td>\n      <td>0210, LLC</td>\n      <td>0.870291</td>\n      <td>90210 LLC</td>\n      <td>4211</td>\n    </tr>\n    <tr>\n      <th>167</th>\n      <td>165</td>\n      <td>1 800 MUTUALS ADVISOR SERIES</td>\n      <td>0.931615</td>\n      <td>1 800 MUTUALS ADVISORS SERIES</td>\n      <td>166</td>\n    </tr>\n    <tr>\n      <th>168</th>\n      <td>166</td>\n      <td>1 800 MUTUALS ADVISORS SERIES</td>\n      <td>0.931615</td>\n      <td>1 800 MUTUALS ADVISOR SERIES</td>\n      <td>165</td>\n    </tr>\n    <tr>\n      <th>172</th>\n      <td>168</td>\n      <td>1 800 RADIATOR FRANCHISE INC</td>\n      <td>1.000000</td>\n      <td>1-800-RADIATOR FRANCHISE INC.</td>\n      <td>201</td>\n    </tr>\n    <tr>\n      <th>178</th>\n      <td>173</td>\n      <td>1 FINANCIAL MARKETPLACE SECURITIES LLC        ...</td>\n      <td>0.949364</td>\n      <td>1 FINANCIAL MARKETPLACE SECURITIES, LLC</td>\n      <td>174</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n### Find all matches in between two data sets. \nThe `match_strings` function finds similar items between two data sets as well. This can be seen as an inner join between two data sets:\n\n\n```python\n# Create a small set of artificial company names:\nduplicates = pd.Series(['S MEDIA GROUP', '012 SMILE.COMMUNICATIONS', 'foo bar', 'B4UTRADE COM CORP'])\n# Create all matches:\nmatches = match_strings(companies['Company Name'], duplicates)\nmatches\n```\n\n\n<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>left_index</th>\n      <th>left_Company Name</th>\n      <th>similarity</th>\n      <th>right_side</th>\n      <th>right_index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>12</td>\n      <td>012 SMILE.COMMUNICATIONS LTD</td>\n      <td>0.944092</td>\n      <td>012 SMILE.COMMUNICATIONS</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>49777</td>\n      <td>B.A.S. MEDIA GROUP</td>\n      <td>0.854383</td>\n      <td>S MEDIA GROUP</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>49855</td>\n      <td>B4UTRADE COM CORP</td>\n      <td>1.000000</td>\n      <td>B4UTRADE COM CORP</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>49856</td>\n      <td>B4UTRADE COM INC</td>\n      <td>0.810217</td>\n      <td>B4UTRADE COM CORP</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>49857</td>\n      <td>B4UTRADE CORP</td>\n      <td>0.878276</td>\n      <td>B4UTRADE COM CORP</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\nOut of the four company names in `duplicates`, three companies are found in the original company data set. One company is found three times.\n\n### Finding duplicates from a (database extract to) DataFrame where IDs for rows are supplied.\n\nA very common scenario is the case where duplicate records for an entity have been entered into a database. That is, there are two or more records where a name field has slightly different spelling. For example, \"A.B. Corporation\" and \"AB Corporation\". Using the optional 'ID' parameter in the `match_strings` function duplicates can be found easily. A [tutorial](https://github.com/Bergvca/string_grouper/blob/master/tutorials/tutorial_1.md) that steps though the process with an example data set is available.\n\n\n### For a second data set, find only the most similar match\n\nIn the example above, it's possible that multiple matches are found for a single string. Sometimes we just want a string to match with a single most similar string. If there are no similar strings found, the original string should be returned:\n\n\n```python\n# Create a small set of artificial company names:\nnew_companies = pd.Series(['S MEDIA GROUP', '012 SMILE.COMMUNICATIONS', 'foo bar', 'B4UTRADE COM CORP'],\\\n                          name='New Company')\n# Create all matches:\nmatches = match_most_similar(companies['Company Name'], new_companies, ignore_index=True)\n# Display the results:\npd.concat([new_companies, matches], axis=1)\n```\n\n\n<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>New Company</th>\n      <th>most_similar_Company Name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>S MEDIA GROUP</td>\n      <td>B.A.S. MEDIA GROUP</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>012 SMILE.COMMUNICATIONS</td>\n      <td>012 SMILE.COMMUNICATIONS LTD</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>foo bar</td>\n      <td>foo bar</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>B4UTRADE COM CORP</td>\n      <td>B4UTRADE COM CORP</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n### <a name=\"dedup\"></a>Deduplicate a single data set and show items with most duplicates\n\nThe `group_similar_strings` function groups strings that are similar using a single linkage clustering algorithm. That is, if item A and item B are similar; and item B and item C are similar; but the similarity between A and C is below the threshold; then all three items are grouped together. \n\n```python\n# Add the grouped strings:\ncompanies['deduplicated_name'] = group_similar_strings(companies['Company Name'],\n                                                       ignore_index=True)\n# Show items with most duplicates:\ncompanies.groupby('deduplicated_name')['Line Number'].count().sort_values(ascending=False).head(10)\n```\n\n\n\n\n    deduplicated_name\n    ADVISORS DISCIPLINED TRUST                                      1824\n    AGL LIFE ASSURANCE CO SEPARATE ACCOUNT                           183\n    ANGELLIST-ART-FUND, A SERIES OF ANGELLIST-FG-FUNDS, LLC          116\n    AMERICREDIT AUTOMOBILE RECEIVABLES TRUST 2001-1                   87\n    ACE SECURITIES CORP. HOME EQUITY LOAN TRUST, SERIES 2006-HE2      57\n    ASSET-BACKED PASS-THROUGH CERTIFICATES SERIES 2004-W1             40\n    ALLSTATE LIFE GLOBAL FUNDING TRUST 2005-3                         39\n    ALLY AUTO RECEIVABLES TRUST 2014-1                                33\n    ANDERSON ROBERT E /                                               28\n    ADVENT INTERNATIONAL GPE VIII LIMITED PARTNERSHIP                 28\n    Name: Line Number, dtype: int64\n\n\nThe `group_similar_strings` function also works with IDs: imagine a `DataFrame` (`customers_df`) with the following content:\n```python\n# Create a small set of artificial customer names:\ncustomers_df = pd.DataFrame(\n   [\n      ('BB016741P', 'Mega Enterprises Corporation'),\n      ('CC082744L', 'Hyper Startup Incorporated'),\n      ('AA098762D', 'Hyper Startup Inc.'),\n      ('BB099931J', 'Hyper-Startup Inc.'),\n      ('HH072982K', 'Hyper Hyper Inc.')\n   ],\n   columns=('Customer ID', 'Customer Name')\n).set_index('Customer ID')\n# Display the data:\ncustomers_df\n```\n\n<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Customer Name</th>\n    </tr>\n    <tr>\n      <th>Customer ID</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>BB016741P</th>\n      <td>Mega Enterprises Corporation</td>\n    </tr>\n    <tr>\n      <th>CC082744L</th>\n      <td>Hyper Startup Incorporated</td>\n    </tr>\n    <tr>\n      <th>AA098762D</th>\n      <td>Hyper Startup Inc.</td>\n    </tr>\n    <tr>\n      <th>BB099931J</th>\n      <td>Hyper-Startup Inc.</td>\n    </tr>\n    <tr>\n      <th>HH072982K</th>\n      <td>Hyper Hyper Inc.</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\nThe output of `group_similar_strings` can be directly used as a mapping table:\n```python\n# Group customers with similar names:\ncustomers_df[[\"group-id\", \"name_deduped\"]]  = \\\n    group_similar_strings(customers_df[\"Customer Name\"])\n# Display the mapping table:\ncustomers_df\n```\n\n<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Customer Name</th>\n      <th>group-id</th>\n      <th>name_deduped</th>\n    </tr>\n    <tr>\n      <th>Customer ID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>BB016741P</th>\n      <td>Mega Enterprises Corporation</td>\n      <td>BB016741P</td>\n      <td>Mega Enterprises Corporation</td>\n    </tr>\n    <tr>\n      <th>CC082744L</th>\n      <td>Hyper Startup Incorporated</td>\n      <td>CC082744L</td>\n      <td>Hyper Startup Incorporated</td>\n    </tr>\n    <tr>\n      <th>AA098762D</th>\n      <td>Hyper Startup Inc.</td>\n      <td>AA098762D</td>\n      <td>Hyper Startup Inc.</td>\n    </tr>\n    <tr>\n      <th>BB099931J</th>\n      <td>Hyper-Startup Inc.</td>\n      <td>AA098762D</td>\n      <td>Hyper Startup Inc.</td>\n    </tr>\n    <tr>\n      <th>HH072982K</th>\n      <td>Hyper Hyper Inc.</td>\n      <td>HH072982K</td>\n      <td>Hyper Hyper Inc.</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\nNote that here `customers_df` initially had only one column \"Customer Name\" (before the `group_similar_strings` function call); and it acquired two more columns \"group-id\" (the index-column) and \"name_deduped\" after the call through a \"[setting with enlargement](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#setting-with-enlargement)\" (a `pandas` feature).\n\n### <a name=\"dot\"></a>Simply compute the cosine similarities of pairs of strings\n\nSometimes we have pairs of strings that have already been matched but whose similarity scores need to be computed.  For this purpose we provide the function `compute_pairwise_similarities`:\n\n```python\n# Create a small DataFrame of pairs of strings:\npair_s = pd.DataFrame(\n    [\n        ('Mega Enterprises Corporation', 'Mega Enterprises Corporation'),\n        ('Hyper Startup Inc.', 'Hyper Startup Incorporated'),\n        ('Hyper Startup Inc.', 'Hyper Startup Inc.'),\n        ('Hyper Startup Inc.', 'Hyper-Startup Inc.'),\n        ('Hyper Hyper Inc.', 'Hyper Hyper Inc.'),\n        ('Mega Enterprises Corporation', 'Mega Enterprises Corp.')\n   ],\n   columns=('left', 'right')\n)\n# Display the data:\npair_s\n```\n\n\n\n\n<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>left</th>\n      <th>right</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Mega Enterprises Corporation</td>\n      <td>Mega Enterprises Corporation</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Hyper Startup Inc.</td>\n      <td>Hyper Startup Incorporated</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Hyper Startup Inc.</td>\n      <td>Hyper Startup Inc.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Hyper Startup Inc.</td>\n      <td>Hyper-Startup Inc.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Hyper Hyper Inc.</td>\n      <td>Hyper Hyper Inc.</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Mega Enterprises Corporation</td>\n      <td>Mega Enterprises Corp.</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n\n```python\n# Compute their cosine similarities and display them:\npair_s['similarity'] = compute_pairwise_similarities(pair_s['left'], pair_s['right'])\npair_s\n```\n\n\n\n\n<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>left</th>\n      <th>right</th>\n      <th>similarity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Mega Enterprises Corporation</td>\n      <td>Mega Enterprises Corporation</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Hyper Startup Inc.</td>\n      <td>Hyper Startup Incorporated</td>\n      <td>0.633620</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Hyper Startup Inc.</td>\n      <td>Hyper Startup Inc.</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Hyper Startup Inc.</td>\n      <td>Hyper-Startup Inc.</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Hyper Hyper Inc.</td>\n      <td>Hyper Hyper Inc.</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Mega Enterprises Corporation</td>\n      <td>Mega Enterprises Corp.</td>\n      <td>0.826463</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n## The StringGrouper class\n\nThe four functions mentioned above all create a `StringGrouper` object behind the scenes and call different functions on it. The `StringGrouper` class keeps track of all tuples of similar strings and creates the groups out of these. Since matches are often not perfect, a common workflow is to:\n\n1. Create matches\n2. Manually inspect the results\n3. Add and remove matches where necessary\n4. Create groups of similar strings\n\nThe `StringGrouper` class allows for this without having to re-calculate the cosine similarity matrix. See below for an example. \n\n\n```python\ncompany_names = '/media/chris/data/dev/name_matching/data/sec_edgar_company_info.csv'\ncompanies = pd.read_csv(company_names)\n```\n\n1. Create matches\n\n\n```python\n# Create a new StringGrouper\nstring_grouper = StringGrouper(companies['Company Name'], ignore_index=True)\n# Check if the ngram function does what we expect:\nstring_grouper.n_grams('McDonalds')\n```\n\n    ['McD', 'cDo', 'Don', 'ona', 'nal', 'ald', 'lds']\n\n\n```python\n# Now fit the StringGrouper - this will take a while since we are calculating cosine similarities on 600k strings\nstring_grouper = string_grouper.fit()\n```\n\n```python\n# Add the grouped strings\ncompanies['deduplicated_name'] = string_grouper.get_groups()\n```\n\nSuppose we know that PWC HOLDING CORP and PRICEWATERHOUSECOOPERS LLP are the same company. StringGrouper will not match these since they are not similar enough. \n\n\n```python\ncompanies[companies.deduplicated_name.str.contains('PRICEWATERHOUSECOOPERS LLP')]\n```\n\n\n<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Line Number</th>\n      <th>Company Name</th>\n      <th>Company CIK Key</th>\n      <th>deduplicated_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>478441</th>\n      <td>478442</td>\n      <td>PRICEWATERHOUSECOOPERS LLP                              /TA</td>\n      <td>1064284</td>\n      <td>PRICEWATERHOUSECOOPERS LLP                              /TA</td>\n    </tr>\n    <tr>\n      <th>478442</th>\n      <td>478443</td>\n      <td>PRICEWATERHOUSECOOPERS LLP</td>\n      <td>1186612</td>\n      <td>PRICEWATERHOUSECOOPERS LLP                              /TA</td>\n    </tr>\n    <tr>\n      <th>478443</th>\n      <td>478444</td>\n      <td>PRICEWATERHOUSECOOPERS SECURITIES LLC</td>\n      <td>1018444</td>\n      <td>PRICEWATERHOUSECOOPERS LLP                              /TA</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n```python\ncompanies[companies.deduplicated_name.str.contains('PWC')]\n```\n\n\n<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Line Number</th>\n      <th>Company Name</th>\n      <th>Company CIK Key</th>\n      <th>deduplicated_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>485535</th>\n      <td>485536</td>\n      <td>PWC CAPITAL INC.</td>\n      <td>1690640</td>\n      <td>PWC CAPITAL INC.</td>\n    </tr>\n    <tr>\n      <th>485536</th>\n      <td>485537</td>\n      <td>PWC HOLDING CORP</td>\n      <td>1456450</td>\n      <td>PWC HOLDING CORP</td>\n    </tr>\n    <tr>\n      <th>485537</th>\n      <td>485538</td>\n      <td>PWC INVESTORS, LLC</td>\n      <td>1480311</td>\n      <td>PWC INVESTORS, LLC</td>\n    </tr>\n    <tr>\n      <th>485538</th>\n      <td>485539</td>\n      <td>PWC REAL ESTATE VALUE FUND I LLC</td>\n      <td>1668928</td>\n      <td>PWC REAL ESTATE VALUE FUND I LLC</td>\n    </tr>\n    <tr>\n      <th>485539</th>\n      <td>485540</td>\n      <td>PWC SECURITIES CORP                                     /BD</td>\n      <td>1023989</td>\n      <td>PWC SECURITIES CORP                                     /BD</td>\n    </tr>\n    <tr>\n      <th>485540</th>\n      <td>485541</td>\n      <td>PWC SECURITIES CORPORATION</td>\n      <td>1023989</td>\n      <td>PWC SECURITIES CORPORATION</td>\n    </tr>\n    <tr>\n      <th>485541</th>\n      <td>485542</td>\n      <td>PWCC LTD</td>\n      <td>1172241</td>\n      <td>PWCC LTD</td>\n    </tr>\n    <tr>\n      <th>485542</th>\n      <td>485543</td>\n      <td>PWCG BROKERAGE, INC.</td>\n      <td>67301</td>\n      <td>PWCG BROKERAGE, INC.</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\nWe can add these with the add function:\n\n\n```python\nstring_grouper = string_grouper.add_match('PRICEWATERHOUSECOOPERS LLP', 'PWC HOLDING CORP')\ncompanies['deduplicated_name'] = string_grouper.get_groups()\n# Now lets check again:\n\ncompanies[companies.deduplicated_name.str.contains('PRICEWATERHOUSECOOPERS LLP')]\n```\n\n\n<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Line Number</th>\n      <th>Company Name</th>\n      <th>Company CIK Key</th>\n      <th>deduplicated_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>478441</th>\n      <td>478442</td>\n      <td>PRICEWATERHOUSECOOPERS LLP                              /TA</td>\n      <td>1064284</td>\n      <td>PRICEWATERHOUSECOOPERS LLP                              /TA</td>\n    </tr>\n    <tr>\n      <th>478442</th>\n      <td>478443</td>\n      <td>PRICEWATERHOUSECOOPERS LLP</td>\n      <td>1186612</td>\n      <td>PRICEWATERHOUSECOOPERS LLP                              /TA</td>\n    </tr>\n    <tr>\n      <th>478443</th>\n      <td>478444</td>\n      <td>PRICEWATERHOUSECOOPERS SECURITIES LLC</td>\n      <td>1018444</td>\n      <td>PRICEWATERHOUSECOOPERS LLP                              /TA</td>\n    </tr>\n    <tr>\n      <th>485536</th>\n      <td>485537</td>\n      <td>PWC HOLDING CORP</td>\n      <td>1456450</td>\n      <td>PRICEWATERHOUSECOOPERS LLP                              /TA</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\nThis can also be used to merge two groups:\n\n\n```python\nstring_grouper = string_grouper.add_match('PRICEWATERHOUSECOOPERS LLP', 'ZUCKER MICHAEL')\ncompanies['deduplicated_name'] = string_grouper.get_groups()\n\n# Now lets check again:\ncompanies[companies.deduplicated_name.str.contains('PRICEWATERHOUSECOOPERS LLP')]\n```\n\n\n<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Line Number</th>\n      <th>Company Name</th>\n      <th>Company CIK Key</th>\n      <th>deduplicated_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>478441</th>\n      <td>478442</td>\n      <td>PRICEWATERHOUSECOOPERS LLP                              /TA</td>\n      <td>1064284</td>\n      <td>PRICEWATERHOUSECOOPERS LLP                              /TA</td>\n    </tr>\n    <tr>\n      <th>478442</th>\n      <td>478443</td>\n      <td>PRICEWATERHOUSECOOPERS LLP</td>\n      <td>1186612</td>\n      <td>PRICEWATERHOUSECOOPERS LLP                              /TA</td>\n    </tr>\n    <tr>\n      <th>478443</th>\n      <td>478444</td>\n      <td>PRICEWATERHOUSECOOPERS SECURITIES LLC</td>\n      <td>1018444</td>\n      <td>PRICEWATERHOUSECOOPERS LLP                              /TA</td>\n    </tr>\n    <tr>\n      <th>485536</th>\n      <td>485537</td>\n      <td>PWC HOLDING CORP</td>\n      <td>1456450</td>\n      <td>PRICEWATERHOUSECOOPERS LLP                              /TA</td>\n    </tr>\n    <tr>\n      <th>662585</th>\n      <td>662586</td>\n      <td>ZUCKER MICHAEL</td>\n      <td>1629018</td>\n      <td>PRICEWATERHOUSECOOPERS LLP                              /TA</td>\n    </tr>\n    <tr>\n      <th>662604</th>\n      <td>662605</td>\n      <td>ZUCKERMAN MICHAEL</td>\n      <td>1303321</td>\n      <td>PRICEWATERHOUSECOOPERS LLP                              /TA</td>\n    </tr>\n    <tr>\n      <th>662605</th>\n      <td>662606</td>\n      <td>ZUCKERMAN MICHAEL</td>\n      <td>1496366</td>\n      <td>PRICEWATERHOUSECOOPERS LLP                              /TA</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\nWe can remove strings from groups in the same way:\n\n\n```python\nstring_grouper = string_grouper.remove_match('PRICEWATERHOUSECOOPERS LLP', 'ZUCKER MICHAEL')\ncompanies['deduplicated_name'] = string_grouper.get_groups()\n\n# Now lets check again:\ncompanies[companies.deduplicated_name.str.contains('PRICEWATERHOUSECOOPERS LLP')]\n```\n\n\n<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Line Number</th>\n      <th>Company Name</th>\n      <th>Company CIK Key</th>\n      <th>deduplicated_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>478441</th>\n      <td>478442</td>\n      <td>PRICEWATERHOUSECOOPERS LLP                              /TA</td>\n      <td>1064284</td>\n      <td>PRICEWATERHOUSECOOPERS LLP                              /TA</td>\n    </tr>\n    <tr>\n      <th>478442</th>\n      <td>478443</td>\n      <td>PRICEWATERHOUSECOOPERS LLP</td>\n      <td>1186612</td>\n      <td>PRICEWATERHOUSECOOPERS LLP                              /TA</td>\n    </tr>\n    <tr>\n      <th>478443</th>\n      <td>478444</td>\n      <td>PRICEWATERHOUSECOOPERS SECURITIES LLC</td>\n      <td>1018444</td>\n      <td>PRICEWATERHOUSECOOPERS LLP                              /TA</td>\n    </tr>\n    <tr>\n      <th>485536</th>\n      <td>485537</td>\n      <td>PWC HOLDING CORP</td>\n      <td>1456450</td>\n      <td>PRICEWATERHOUSECOOPERS LLP                              /TA</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n# Performance<a name=\"perf\"></a>\n\n### <a name=\"Semilogx\"></a>Semilogx plots of run-times of `match_strings()` vs the number of blocks (`n_blocks[1]`) into which the right matrix-operand of the dataset (663 000 strings from sec__edgar_company_info.csv) was split before performing the string comparison.  As shown in the legend, each plot corresponds to the number `n_blocks[0]` of blocks into which the left matrix-operand was split.\n![Semilogx](https://raw.githubusercontent.com/Bergvca/string_grouper/master/images/BlockNumberSpaceExploration1.png)\n\nString comparison, as implemented by `string_grouper`, is essentially matrix \nmultiplication.  A pandas Series of strings is converted (tokenized) into a \nmatrix.  Then that matrix is multiplied by itself (or another) transposed.  \n\nHere is an illustration of multiplication of two matrices ***D*** and ***M***<sup>T</sup>:\n![Block Matrix 1 1](https://raw.githubusercontent.com/Bergvca/string_grouper/master/images/BlockMatrix_1_1.png)\n\nIt turns out that when the matrix (or Series) is very large, the computer \nproceeds quite slowly with the multiplication (apparently due to the RAM being \ntoo full).  Some computers give up with an `OverflowError`.\n\nTo circumvent this issue, `string_grouper` now allows the division of the Series \ninto smaller chunks (or blocks) and multiplies the chunks one pair at a time \ninstead to get the same result:\n\n![Block Matrix 2 2](https://raw.githubusercontent.com/Bergvca/string_grouper/master/images/BlockMatrix_2_2.png)\n\nBut surprise ... the run-time of the process is sometimes drastically reduced \nas a result.  For example, the speed-up of the following call is about 500% \n(here, the Series is divided into 200 blocks on the right operand, that is, \n1 block on the left &times; 200 on the right) compared to the same call with no\nsplitting \\[`n_blocks=(1, 1)`, the default, which is what previous versions \n(0.5.0 and earlier) of `string_grouper` did\\]:\n\n```python\n# A DataFrame of 668 000 records:\ncompanies = pd.read_csv('data/sec__edgar_company_info.csv')\n\n# The following call is more than 6 times faster than earlier versions of \n# match_strings() (that is, when n_blocks=(1, 1))!\nmatch_strings(companies['Company Name')], n_blocks=(1, 200))\n```\n\nFurther exploration of the block number space ([see plot above](#Semilogx)) has revealed that for any fixed \nnumber of right blocks, the run-time gets longer the larger the number of left \nblocks specified.  For this reason, it is recommended *not* to split the left matrix.\n\n![Block Matrix 1 2](https://raw.githubusercontent.com/Bergvca/string_grouper/master/images/BlockMatrix_1_2.png)\n\nIn general,\n\n&nbsp;&nbsp;&nbsp;***total runtime*** = `n_blocks[0]` &times; `n_blocks[1]` &times; ***mean runtime per block-pair***\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; = ***Left Operand Size*** &times; ***Right Operand Size*** &times; \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ***mean runtime per block-pair*** / (***Left Block Size*** &times; ***Right Block Size***)\n\nSo for given left and right operands, minimizing the ***total runtime*** is the same as minimizing the\n\n&nbsp;&nbsp;&nbsp;***runtime per string-pair comparison*** &#8797; <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;***mean runtime per block-pair*** / (***Left Block Size*** &times; ***Right Block Size***)\n\n\n[Below is a log-log-log contour plot](#ContourPlot) of the ***runtime per string-pair comparison*** scaled by its value\nat ***Left Block Size*** = ***Right Block Size*** = 5000.  Here, ***Block Size***\nis the number of strings in that block, and ***mean runtime per block-pair*** is the time taken for the following call to run:\n```python\n# note the parameter order!\nmatch_strings(right_Series, left_Series, n_blocks=(1, 1))\n```\nwhere `left_Series` and `right_Series`, corresponding to ***Left Block*** and ***Right Block*** respectively, are random subsets of the Series `companies['Company Name')]` from the\n[sec__edgar_company_info.csv](https://www.kaggle.com/dattapiy/sec-edgar-companies-list/version/1) sample data file.\n\n<a name=\"ContourPlot\"></a> ![ContourPlot](https://raw.githubusercontent.com/Bergvca/string_grouper/master/images/ScaledRuntimeContourPlot.png)\n\nIt can be seen that when `right_Series` is roughly the size of 80&nbsp;000 (denoted by the \nwhite dashed line in the contour plot above), the runtime per string-pair comparison is at \nits lowest for any fixed `left_Series` size.  Above ***Right Block Size*** = 80&nbsp;000, the \nmatrix-multiplication routine begins to feel the limits of the computer's \navailable memory space and thus its performance deteriorates, as evidenced by the increase \nin runtime per string-pair comparison there (above the white dashed line).  This knowledge \ncould serve as a guide for estimating the optimum block numbers &mdash;\nnamely those that divide the Series into blocks of size roughly equal to \n80&nbsp;000 for the right operand (or `right_Series`).\n\nSo what are the optimum block number values for *any* given Series? That is \nanyone's guess, and may likely depend on the data itself.  Furthermore, as hinted above, \nthe answer may vary from computer to computer.  \n\nWe however encourage the user to make judicious use of the `n_blocks` \nparameter to boost performance of `string_grouper` whenever possible.\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/Bergvca/string_grouper",
    "keywords": "",
    "license": "MIT License",
    "maintainer": "",
    "maintainer_email": "",
    "name": "string-grouper",
    "package_url": "https://pypi.org/project/string-grouper/",
    "platform": "",
    "project_url": "https://pypi.org/project/string-grouper/",
    "project_urls": {
      "Homepage": "https://github.com/Bergvca/string_grouper"
    },
    "release_url": "https://pypi.org/project/string-grouper/0.6.1/",
    "requires_dist": [
      "numpy",
      "pandas (>=0.25.3)",
      "scikit-learn",
      "scipy",
      "sparse-dot-topn-for-blocks (>=0.3.1)",
      "topn (>=0.0.7)"
    ],
    "requires_python": ">3.7",
    "summary": "String grouper contains functions to do string matching using TF-IDF and the cossine similarity. Based on https://bergvca.github.io/2017/10/14/super-fast-string-matching.html",
    "version": "0.6.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 12020369,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "492ec5a209d0a6ede7bcaea26a0d7849009fd0dfa8d89e5b756680d3ddea8288",
          "md5": "8744e9e7f92f907153b94b6693ddaa61",
          "sha256": "619b506d688f12b985e69bd8054164676984a2382427f4af5da0a92b2bf5ab5c"
        },
        "downloads": -1,
        "filename": "string_grouper-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "8744e9e7f92f907153b94b6693ddaa61",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">3.7",
        "size": 11282,
        "upload_time": "2020-01-02T16:02:04",
        "upload_time_iso_8601": "2020-01-02T16:02:04.408137Z",
        "url": "https://files.pythonhosted.org/packages/49/2e/c5a209d0a6ede7bcaea26a0d7849009fd0dfa8d89e5b756680d3ddea8288/string_grouper-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "848f18a7a12b57ac84c979f081dc3351b254e1c2806e2d6c6e4f751e02e0b44d",
          "md5": "6a15129c492648b52eafd63b34cc625b",
          "sha256": "452d398f0dd7b6f88f171dda7a07d71692d61d65b8a0e55155bcfdd42fc5a962"
        },
        "downloads": -1,
        "filename": "string_grouper-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "6a15129c492648b52eafd63b34cc625b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">3.7",
        "size": 14192,
        "upload_time": "2020-01-02T16:02:07",
        "upload_time_iso_8601": "2020-01-02T16:02:07.067875Z",
        "url": "https://files.pythonhosted.org/packages/84/8f/18a7a12b57ac84c979f081dc3351b254e1c2806e2d6c6e4f751e02e0b44d/string_grouper-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5110e6ad81e3de6630b3af9061084a875c80038b6d55c757077a9c54d37cf075",
          "md5": "f66402f832e977e19fae67f7cd677637",
          "sha256": "859b0b5faef5464e5718cefb36b2807e6fbc831a355a12b5af828d91fe43b05c"
        },
        "downloads": -1,
        "filename": "string_grouper-0.1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f66402f832e977e19fae67f7cd677637",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">3.7",
        "size": 11424,
        "upload_time": "2020-07-15T18:41:14",
        "upload_time_iso_8601": "2020-07-15T18:41:14.426813Z",
        "url": "https://files.pythonhosted.org/packages/51/10/e6ad81e3de6630b3af9061084a875c80038b6d55c757077a9c54d37cf075/string_grouper-0.1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "41ee781d8ef706ac04dfa71d0cae078ab85f79ce77c6e0098905a3e3b21fa83a",
          "md5": "6315369df153e8a4cbd24bd0efd6ed6e",
          "sha256": "b5c48d0783f52bd90024b88dc5162d93bc74d346d6229ce82ab39d59e9072dea"
        },
        "downloads": -1,
        "filename": "string_grouper-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "6315369df153e8a4cbd24bd0efd6ed6e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">3.7",
        "size": 14154,
        "upload_time": "2020-07-15T18:41:16",
        "upload_time_iso_8601": "2020-07-15T18:41:16.263305Z",
        "url": "https://files.pythonhosted.org/packages/41/ee/781d8ef706ac04dfa71d0cae078ab85f79ce77c6e0098905a3e3b21fa83a/string_grouper-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "de24bff24947c9f3df49c74099743e037c7ed5bb5d60dae1457372dcdd540459",
          "md5": "bb656cfaaffc7aabc7138fade82caa7d",
          "sha256": "63dc0fccd434c80bc33e041961fdb51111eb9c534390be8b6cb0a9eba785de18"
        },
        "downloads": -1,
        "filename": "string_grouper-0.1.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "bb656cfaaffc7aabc7138fade82caa7d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">3.7",
        "size": 11485,
        "upload_time": "2020-10-12T19:50:57",
        "upload_time_iso_8601": "2020-10-12T19:50:57.823074Z",
        "url": "https://files.pythonhosted.org/packages/de/24/bff24947c9f3df49c74099743e037c7ed5bb5d60dae1457372dcdd540459/string_grouper-0.1.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cd2783d1f15a854ec33d0624a640e3a8d5da93786ab0b799353ee5ca7e8c77b0",
          "md5": "ec05640b99824daa9491efec979ae636",
          "sha256": "4ba81eaa4a02e7abcb8f95fe8863b2af8a9b178bed9d04767a1acca0df6eb758"
        },
        "downloads": -1,
        "filename": "string_grouper-0.2.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ec05640b99824daa9491efec979ae636",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">3.7",
        "size": 11973,
        "upload_time": "2021-02-08T20:56:32",
        "upload_time_iso_8601": "2021-02-08T20:56:32.331945Z",
        "url": "https://files.pythonhosted.org/packages/cd/27/83d1f15a854ec33d0624a640e3a8d5da93786ab0b799353ee5ca7e8c77b0/string_grouper-0.2.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "202841528826bf7a9d89e2c720c489f25887725270d1c5e8164ad6aa3a290dab",
          "md5": "c228854301781f08ddcdf7d6d5d22b35",
          "sha256": "70b6ad543544e0eb068f5ffd1413bd76537f6d18eac4b3f466e1032f140e4695"
        },
        "downloads": -1,
        "filename": "string_grouper-0.3.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "c228854301781f08ddcdf7d6d5d22b35",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">3.7",
        "size": 12550,
        "upload_time": "2021-02-21T20:17:48",
        "upload_time_iso_8601": "2021-02-21T20:17:48.610038Z",
        "url": "https://files.pythonhosted.org/packages/20/28/41528826bf7a9d89e2c720c489f25887725270d1c5e8164ad6aa3a290dab/string_grouper-0.3.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "42c0223573a1081c7d8f98dd36f3c44b0b3e4a14c8fc6fbe25c9e9c3b5b01a34",
          "md5": "51ccab447ac6691faf0e6124ab25de44",
          "sha256": "9f4ac66d21b8140f91491250cb7283bd87a293cc65a5b33a93aa98b3154e137a"
        },
        "downloads": -1,
        "filename": "string_grouper-0.4.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "51ccab447ac6691faf0e6124ab25de44",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">3.7",
        "size": 20162,
        "upload_time": "2021-04-11T19:04:11",
        "upload_time_iso_8601": "2021-04-11T19:04:11.026515Z",
        "url": "https://files.pythonhosted.org/packages/42/c0/223573a1081c7d8f98dd36f3c44b0b3e4a14c8fc6fbe25c9e9c3b5b01a34/string_grouper-0.4.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.5.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "08e3bc4065a12241b11de6be125894f52f01c770306ac37bbfc6517b260495af",
          "md5": "712fef44edd9f4968a7b835d853fb1ae",
          "sha256": "bdfcd8aee6eb20309cd64c76e8d8ce88a04e455878536bb2f6aad4e421ee4207"
        },
        "downloads": -1,
        "filename": "string_grouper-0.5.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "712fef44edd9f4968a7b835d853fb1ae",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">3.7",
        "size": 20279,
        "upload_time": "2021-07-02T13:16:40",
        "upload_time_iso_8601": "2021-07-02T13:16:40.850082Z",
        "url": "https://files.pythonhosted.org/packages/08/e3/bc4065a12241b11de6be125894f52f01c770306ac37bbfc6517b260495af/string_grouper-0.5.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.6.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "674143afd48a2bfc3c2a0d4b2e03f3231b405c5f04306f99b344a12f6b24bdc5",
          "md5": "8101600f75b93273611a412cee54b083",
          "sha256": "377fefb68e8738644f567962a6868d680063ef7b35b230d0b2ca74c28308e17f"
        },
        "downloads": -1,
        "filename": "string_grouper-0.6.0-py3.9.egg",
        "has_sig": false,
        "md5_digest": "8101600f75b93273611a412cee54b083",
        "packagetype": "bdist_egg",
        "python_version": "3.9",
        "requires_python": ">3.7",
        "size": 47769,
        "upload_time": "2021-10-15T18:49:31",
        "upload_time_iso_8601": "2021-10-15T18:49:31.121743Z",
        "url": "https://files.pythonhosted.org/packages/67/41/43afd48a2bfc3c2a0d4b2e03f3231b405c5f04306f99b344a12f6b24bdc5/string_grouper-0.6.0-py3.9.egg",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "431b1af34fe1b19b0cc3b45913b64ea6cdcd74a8286ecd0c00a45183b2b6eafd",
          "md5": "e2276cfc5552ef7f50ca6c8660805651",
          "sha256": "732825181f1ca53c387101bff5b182c1cca33195c2dacab05769f5fe174a4113"
        },
        "downloads": -1,
        "filename": "string_grouper-0.6.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "e2276cfc5552ef7f50ca6c8660805651",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">3.7",
        "size": 28952,
        "upload_time": "2021-10-15T18:49:29",
        "upload_time_iso_8601": "2021-10-15T18:49:29.278424Z",
        "url": "https://files.pythonhosted.org/packages/43/1b/1af34fe1b19b0cc3b45913b64ea6cdcd74a8286ecd0c00a45183b2b6eafd/string_grouper-0.6.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "49d20e715c90d2f3f5a01b88d8f7db7be49b84c0354c132ea08ca63f0dc675c1",
          "md5": "6b2bae0bd0fd48ce9d13ed4efc052e1e",
          "sha256": "948d1d1640a3f752d76130dd23d1a1f4b90649a8088bd0024922d58ec75eb082"
        },
        "downloads": -1,
        "filename": "string_grouper-0.6.0.tar.gz",
        "has_sig": false,
        "md5_digest": "6b2bae0bd0fd48ce9d13ed4efc052e1e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">3.7",
        "size": 49531,
        "upload_time": "2021-10-15T18:49:33",
        "upload_time_iso_8601": "2021-10-15T18:49:33.301887Z",
        "url": "https://files.pythonhosted.org/packages/49/d2/0e715c90d2f3f5a01b88d8f7db7be49b84c0354c132ea08ca63f0dc675c1/string_grouper-0.6.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.6.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4e409b56ca8d29453d0589a50b25184ca9d5c2d3de12af28e57e3efc02188a47",
          "md5": "19f429b4948304d4fd1c3fd2dc15df1a",
          "sha256": "7feb1dc5928c5fcce5a233f00c0828463af723a962510c24234e240e8944d153"
        },
        "downloads": -1,
        "filename": "string_grouper-0.6.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "19f429b4948304d4fd1c3fd2dc15df1a",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">3.7",
        "size": 29405,
        "upload_time": "2021-11-14T20:14:45",
        "upload_time_iso_8601": "2021-11-14T20:14:45.565752Z",
        "url": "https://files.pythonhosted.org/packages/4e/40/9b56ca8d29453d0589a50b25184ca9d5c2d3de12af28e57e3efc02188a47/string_grouper-0.6.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "4e409b56ca8d29453d0589a50b25184ca9d5c2d3de12af28e57e3efc02188a47",
        "md5": "19f429b4948304d4fd1c3fd2dc15df1a",
        "sha256": "7feb1dc5928c5fcce5a233f00c0828463af723a962510c24234e240e8944d153"
      },
      "downloads": -1,
      "filename": "string_grouper-0.6.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "19f429b4948304d4fd1c3fd2dc15df1a",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">3.7",
      "size": 29405,
      "upload_time": "2021-11-14T20:14:45",
      "upload_time_iso_8601": "2021-11-14T20:14:45.565752Z",
      "url": "https://files.pythonhosted.org/packages/4e/40/9b56ca8d29453d0589a50b25184ca9d5c2d3de12af28e57e3efc02188a47/string_grouper-0.6.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}