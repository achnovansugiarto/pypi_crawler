{
  "info": {
    "author": "Peng Tao",
    "author_email": "taopeng543@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3"
    ],
    "description": "## Chaotic Back-propagation (CBP)\ncbpy is a light package for research purpose, which implements the CBP algorithm in the paper \"Brain-inspired Chaotic Back-Propagation\".\n\n### Install\n```bash\npip install cbpy\n```\n\n### Examples\n#### Example1. reveal the principles of Chaotic Back-propagation (CBP) with single-neuron network.\n###### 1. prepare the dataset\n```python\nimport torch\nimport torch.nn as nn\nimport cbpy as cbp\n\ninp = torch.FloatTensor([[1]]) # input sample\ntgt = torch.FloatTensor([[0]]) # target of input\n```\n###### 2. define single-neuron network\n```python\nclass SingleNet(nn.Module):\n    def __init__(self, init_value=0):\n        super().__init__()\n        self.layer = nn.Linear(1, 1)\n        self.act_func = nn.Sigmoid()\n        nn.init.constant_(self.layer.weight, init_value)\n        nn.init.constant_(self.layer.bias, init_value)\n        \n    def forward(self, x):\n        out = self.act_func(self.layer(x))\n        return out\n```\n###### 3. training with BP algorithm\n```python\nnet = SingleNet()\nloss_func = nn.MSELoss() # loss function\noptimizer = torch.optim.SGD(net.parameters(), lr=1)\n\nloss_list = []\nweight_list = []\nbias_list = []\nfor i in range(1000):\n    optimizer.zero_grad()\n    out = net(inp)\n    loss_bp = loss_func(out, tgt)\n    loss_bp.backward()\n    optimizer.step()\n\n    loss_list.append(loss_bp.item())\n    weight_list.append(net.layer.weight.item())\n    bias_list.append(net.layer.bias.item())\n```\n###### 4. plot the learning curve of the weight for BP\n```python\nimport seaborn as sns\nsns.set(context='notebook', style='whitegrid', font_scale=1.2)\n\ncbp.plot_series(weight_list, ylabel='w', title='weight of BP')\n```\n![bp_weight](https://github.com/PengTao-HUST/CBP/blob/master/figures/bp_weight.png?raw=true)\n\n###### 5. training with CBP algorithm\n```python\n# define the chaotic loss function\ndef chaos_loss(out, z, I0=0.65):\n    return -z * (I0 * torch.log(out) + (1 - I0) * torch.log(1 - out))\n\n# training with CBP\nnet = SingleNet()\noptimizer = torch.optim.SGD(net.parameters(), lr=1)\n\nz = 9 # initial chaotic intensity\nbeta = 0.999 # anealing constant\n\nloss_bp_list = []\nloss_cbp_list = []\nweight_list = []\nbias_list = []\nfor i in range(1000):\n    optimizer.zero_grad()\n    out = net(inp)\n    loss_bp = loss_func(out, tgt)\n    loss_chaos = chaos_loss(out, z) # chaotic loss\n    loss_cbp = loss_bp + loss_chaos # loss of CBP\n    loss_cbp.backward()\n    optimizer.step()\n    z *= beta\n    \n    loss_bp_list.append(loss_bp.item())\n    loss_cbp_list.append(loss_cbp.item())\n    weight_list.append(net.layer.weight.item())\n    bias_list.append(net.layer.bias.item())\n``` \n###### 6. plot the learning curve of the weight for CBP\n```python\ncbp.plot_series(weight_list, ylabel='w', title='weight of CBP')\n```\n![cbp_weight](https://github.com/PengTao-HUST/CBP/blob/master/figures/cbp_weight.png?raw=true)\n\n#### Example2. validate the global optimization ability of CBP on the XOR problem\n###### 1. prepare the dataset and parameters\n```python\n# create the XOR dataset\ntrainloader = cbp.create_xor_dataloader()\n\ninp, tgt = next(iter(trainloader))\nprint(inp, '\\n', tgt)\n\n# define params\nloss_func = torch.nn.BCELoss() # loss function\nlr = 0.2 # learning rate\nmax_epoch = 10000 # maximal training epoch\nseed = 32 # random number seed\ninit_mode = 1 # initial weight interval\nlayer_list = [2, 2, 1] # layers for MLP\n```\n\n###### 2. training by BP\n```python\ncbp.set_random_seed(seed)\nmodel = cbp.MLPS(layer_list, init_mode=init_mode, \n                 act_layer=torch.nn.Sigmoid(), active_last=True)\n\nzs = None # chaotic intensity\ncbp_epoch = 0\nbp_l_list, bp_a_list, bp_w_list, bp_o_list = cbp.train_with_chaos(\n    model=model,\n    trainloader=trainloader,\n    testloader=trainloader,\n    loss_func=loss_func,\n    zs=zs,\n    record_weight=True,\n    whole_weight=True,\n    cbp_epoch=cbp_epoch,\n    max_epoch=max_epoch,\n    bp_lr=lr\n)\n```\n\n###### 3. plot the trajectories of the weights for BP (first 2000 epochs)\n```python\ncbp.plot_xor_weight(bp_w_list[:2000])\n```\nWeights of BP\n\n![xor_bp_weight](https://github.com/PengTao-HUST/CBP/blob/master/figures/bp_xor_weight_example.png?raw=true)\n\n###### 4. training by BP from the same initial condition as CBP\n```python\ncbp.set_random_seed(seed)\nmodel = cbp.MLPS(layer_list, init_mode=init_mode, \n                 act_layer=torch.nn.Sigmoid(), active_last=True)\nzs = 12 # chaotic intensity\nbeta = 0.999 # annealing constant\ncbp_epoch = max_epoch\ncbp_l_list, cbp_a_list, cbp_w_list, cbp_o_list = cbp.train_with_chaos(\n    model=model,\n    trainloader=trainloader,\n    testloader=trainloader,\n    loss_func=loss_func,\n    zs=zs,\n    beta=beta,\n    record_weight=True,\n    whole_weight=True,\n    cbp_epoch=cbp_epoch,\n    max_epoch=max_epoch,\n    cbp_lr=lr\n)\n```\n\n###### 5. plot the trajectories of the weights in CBP (first 2000 epochs)\n```\ncbp.plot_xor_weight(cbp_w_list[:2000], suptitle='CBP')\n```\nWeights of CBP\n\n![xor_bp_weight](https://github.com/PengTao-HUST/CBP/blob/master/figures/cbp_xor_weight_example.png?raw=true)\n\n###### 6. compare the loss and accuracy of BP and CBP\n```python\nimport numpy as np\n\nloss_mat = np.array([bp_l_list, cbp_l_list]).T\nacc_mat = np.array([bp_a_list, cbp_a_list]).T\ncbp.plot_mul_loss_acc(loss_mat, acc_mat, alpha=1, ylabels=['loss', 'acc'])\n```\n![compare_loss](https://github.com/PengTao-HUST/CBP/blob/master/figures/comp_bp_cbp_loss_acc.png?raw=true)\n\n#### Example3. choose the parameter z (initial chaotic intensity)\n```python\ncbp.set_random_seed(seed)\nmodel = cbp.MLPS(layer_list, init_mode=init_mode, act_layer=torch.nn.Sigmoid(), active_last=True)\n\nws_lists = cbp.debug_chaos(model, trainloader, loss_func=loss_func)\nle_list = cbp.cal_lyapunov_exponent(ws_lists)\ncbp.plot_lyapunov_exponent_with_z(le_list)\n```\n![Lyapunov_exponent](https://github.com/PengTao-HUST/CBP/blob/master/figures/xor_w1_lyapunov_exponent_with_z.png?raw=true)\n\nIn this example, the Lyapunov exponent around interval [8, 11] is positive, which indicates chaotic dynamics.  \nThen, z = 12 was chosen as the initial chaotic intensity.\n\n### Reproduce the results in the paper\nTo reproduce the results in the paper, check the notebook files in [paper_example](https://github.com/PengTao-HUST/CBP/tree/master/paper_example).\n\n### Components\n- chaos_optim.py: implement the CBP algorithm in the form of optimizer.\n- net.py: contains the neural network class, currently only support MLP.\n- train.py: provide APIs to preform training with the Pytorch style.\n- dataset.py: provide APIs to create the trainloader and testloader.\n- utils.py: several auxiliary functions to analysis the training results.\n- plot.py: several functions to show the training results.\n\n### License\nMIT License",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/PengTao-HUST/CBP",
    "keywords": "",
    "license": "MIT Licence",
    "maintainer": "",
    "maintainer_email": "",
    "name": "cbpy",
    "package_url": "https://pypi.org/project/cbpy/",
    "platform": "",
    "project_url": "https://pypi.org/project/cbpy/",
    "project_urls": {
      "Homepage": "https://github.com/PengTao-HUST/CBP"
    },
    "release_url": "https://pypi.org/project/cbpy/0.0.1/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "Implement Chaotic Backpropagation Algorithm",
    "version": "0.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 10988188,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ce363c499ebeb8965e94e22848e27f09772537281c67294e659f3d52a7a9a759",
          "md5": "5bc2cfbed03d50553e762c33152aa1b0",
          "sha256": "4054e18b8daa4c7ec43581528313f76cbc5aeb2fcd2f5f3a345503c0c3f57320"
        },
        "downloads": -1,
        "filename": "cbpy-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "5bc2cfbed03d50553e762c33152aa1b0",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 17889,
        "upload_time": "2021-07-23T16:57:06",
        "upload_time_iso_8601": "2021-07-23T16:57:06.591896Z",
        "url": "https://files.pythonhosted.org/packages/ce/36/3c499ebeb8965e94e22848e27f09772537281c67294e659f3d52a7a9a759/cbpy-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "ce363c499ebeb8965e94e22848e27f09772537281c67294e659f3d52a7a9a759",
        "md5": "5bc2cfbed03d50553e762c33152aa1b0",
        "sha256": "4054e18b8daa4c7ec43581528313f76cbc5aeb2fcd2f5f3a345503c0c3f57320"
      },
      "downloads": -1,
      "filename": "cbpy-0.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "5bc2cfbed03d50553e762c33152aa1b0",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 17889,
      "upload_time": "2021-07-23T16:57:06",
      "upload_time_iso_8601": "2021-07-23T16:57:06.591896Z",
      "url": "https://files.pythonhosted.org/packages/ce/36/3c499ebeb8965e94e22848e27f09772537281c67294e659f3d52a7a9a759/cbpy-0.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}