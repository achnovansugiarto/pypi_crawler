{
  "info": {
    "author": "Jerry Buaba",
    "author_email": "buabajerry@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.4",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Topic :: Software Development :: Build Tools"
    ],
    "description": "# fastML\n\n--------\nA Python package built with sklearn for running multiple classification algorithms in as little as 4 lines. This package drastically makes the work of Data Scientists, AI and ML engineers very easy and fast by saving them the physical stress of writing close to 200 lines of code as they would if not for this package.\n# Algorithms\n\n------------\n- ### Logistic Regression\n- ### Support Vector Machine\n- ### Decision Tree Classifier\n- ### Random Forest Classifier\n- ### K-Nearest Neighbors\n- ### NeuralNet Classifier\n--------------------------\n# Getting started\n\n-----------------\n\n## Install the package\n```bash\npip install fastML\n```\nNavigate to folder and install requirements: \n```bash\npip install -r requirements.txt\n```\n## Usage\nAssign the variables X and Y to the desired columns and assign the variable size to the desired test_size.  \n```python\nX = < df.features >\nY = < df.target >\nsize = < test_size >\n```\n## Encoding Categorical Data \nEncode target variable if non-numerical:\n```python\nfrom fastML import EncodeCategorical\nY = EncodeCategorical(Y)\n```\n## Using the Neural Net Classifier\n```\nfrom nnclassifier import neuralnet\n```\n## Running fastML\n```python\nfastML(X, Y, size, RandonForestClassifier(), DecisionTreeClassifier(), KNeighborsClassifier(), SVC(),\n        include_special_classifier = True, # to include the neural net classifier\n        special_classifier_epochs=200,\n        special_classifier_nature ='fixed'\n)\n```\nYou may also check the test.py file to see the use case.\n\n## Example output\n```python\nUsing TensorFlow backend.\n\n    \n   __          _   __  __ _      \n  / _|        | | |  \\/  | |     \n | |_ __ _ ___| |_| \\  / | |        \n |  _/ _` / __| __| |\\/| | |     \n | || (_| \\__ \\ |_| |  | | |____ \n |_| \\__,_|___/\\__|_|  |_|______|\n                                 \n                                 \n\n____________________________________________________\n____________________________________________________\nAccuracy Score for SVC is \n0.9811320754716981\n\n\nConfusion Matrix for SVC is \n[[16  0  0]\n [ 0 20  1]\n [ 0  0 16]]\n\n\nClassification Report for SVC is \n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        16\n           1       1.00      0.95      0.98        21\n           2       0.94      1.00      0.97        16\n\n    accuracy                           0.98        53\n   macro avg       0.98      0.98      0.98        53\nweighted avg       0.98      0.98      0.98        53\n\n\n\n____________________________________________________\n____________________________________________________\n____________________________________________________\n____________________________________________________\nAccuracy Score for RandomForestClassifier is \n0.9622641509433962\n\n\nConfusion Matrix for RandomForestClassifier is \n[[16  0  0]\n [ 0 20  1]\n [ 0  1 15]]\n\n\nClassification Report for RandomForestClassifier is \n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        16\n           1       0.95      0.95      0.95        21\n           2       0.94      0.94      0.94        16\n\n    accuracy                           0.96        53\n   macro avg       0.96      0.96      0.96        53\nweighted avg       0.96      0.96      0.96        53\n\n\n\n____________________________________________________\n____________________________________________________\n____________________________________________________\n____________________________________________________\nAccuracy Score for DecisionTreeClassifier is \n0.9622641509433962\n\n\nConfusion Matrix for DecisionTreeClassifier is \n[[16  0  0]\n [ 0 20  1]\n [ 0  1 15]]\n\n\nClassification Report for DecisionTreeClassifier is \n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        16\n           1       0.95      0.95      0.95        21\n           2       0.94      0.94      0.94        16\n\n    accuracy                           0.96        53\n   macro avg       0.96      0.96      0.96        53\nweighted avg       0.96      0.96      0.96        53\n\n\n\n____________________________________________________\n____________________________________________________\n____________________________________________________\n____________________________________________________\nAccuracy Score for KNeighborsClassifier is \n0.9811320754716981\n\n\nConfusion Matrix for KNeighborsClassifier is \n[[16  0  0]\n [ 0 20  1]\n [ 0  0 16]]\n\n\nClassification Report for KNeighborsClassifier is \n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        16\n           1       1.00      0.95      0.98        21\n           2       0.94      1.00      0.97        16\n\n    accuracy                           0.98        53\n   macro avg       0.98      0.98      0.98        53\nweighted avg       0.98      0.98      0.98        53\n\n\n\n____________________________________________________\n____________________________________________________\n____________________________________________________\n____________________________________________________\nAccuracy Score for LogisticRegression is \n0.9811320754716981\n\n\nConfusion Matrix for LogisticRegression is \n[[16  0  0]\n [ 0 20  1]\n [ 0  0 16]]\n\n\nClassification Report for LogisticRegression is \n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        16\n           1       1.00      0.95      0.98        21\n           2       0.94      1.00      0.97        16\n\n    accuracy                           0.98        53\n   macro avg       0.98      0.98      0.98        53\nweighted avg       0.98      0.98      0.98        53\n\n\n\n____________________________________________________\n____________________________________________________\nIncluded special classifier with fixed nature\nModel: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_1 (Dense)              (None, 4)                 20        \n_________________________________________________________________\ndense_2 (Dense)              (None, 16)                80        \n_________________________________________________________________\ndense_3 (Dense)              (None, 3)                 51        \n=================================================================\nTotal params: 151\nTrainable params: 151\nNon-trainable params: 0\n_________________________________________________________________\nTrain on 97 samples, validate on 53 samples\nEpoch 1/200\n97/97 [==============================] - 0s 1ms/step - loss: 1.0995 - accuracy: 0.1443 - val_loss: 1.1011 - val_accuracy: 0.3019\n97/97 [==============================] - 0s 63us/step - loss: 0.5166 - accuracy: 0.7010 - val_loss: 0.5706 - val_accuracy: 0.6038\nEpoch 100/200\n97/97 [==============================] - 0s 88us/step - loss: 0.5128 - accuracy: 0.7010 - val_loss: 0.5675 - val_accuracy: 0.6038\nEpoch 200/200\n97/97 [==============================] - 0s 79us/step - loss: 0.3375 - accuracy: 0.8969 - val_loss: 0.3619 - val_accuracy: 0.9057\n97/97 [==============================] - 0s 36us/step\n____________________________________________________\n____________________________________________________\nAccuracy Score for neuralnet is \n0.8969072103500366\n\n\nConfusion Matrix for neuralnet is \n[[16  0  0]\n [ 0 16  5]\n [ 0  0 16]]\n\n\nClassification Report for neuralnet is \n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        16\n           1       1.00      0.76      0.86        21\n           2       0.76      1.00      0.86        16\n\n    accuracy                           0.91        53\n   macro avg       0.92      0.92      0.91        53\nweighted avg       0.93      0.91      0.91        53\n\n\n\n____________________________________________________\n____________________________________________________\n                    Model            Accuracy\n0                     SVC  0.9811320754716981\n1  RandomForestClassifier  0.9622641509433962\n2  DecisionTreeClassifier  0.9622641509433962\n3    KNeighborsClassifier  0.9811320754716981\n4      LogisticRegression  0.9811320754716981\n5               neuralnet  0.8969072103500366\n\n```\n## Author: [Jerry Buaba](https://linkedin.com/in/jerry-buaba-768351172)\n## Acknowledgements\nThanks to [Vincent Njonge](https://linkedin.com/in/vincent-njonge-528070178), [Emmanuel Amoaku](https://linkedin.com/in/emmanuel-amoaku), [Divine Alorvor](https://www.linkedin.com/in/divine-kofi-alorvor-86775117b), [Philemon Johnson](https://linkedin.com/in/philemon-johnson-b95009171), [William Akuffo](https://linkedin.com/in/william-akuffo-26b430159), [Labaran Mohammed](https://linkedin.com/in/adam-labaran-111358181), [Benjamin Acquaah](https://linkedin.com/in/benjamin-acquaah-9294aa14b), [Silas Bempong](https://www.linkedin.com/in/silas-bempong-604916120) and [Gal Giacomelli](https://linkedin.com/in/gal-giacomelli-221679136) for making this project a success.",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "https://github.com/Team-fastML/fastML/archive/v0.1.tar.gz",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/buabaj",
    "keywords": "Machine Learning,Algorithms,Classification,Neural Net",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "fastML",
    "package_url": "https://pypi.org/project/fastML/",
    "platform": "",
    "project_url": "https://pypi.org/project/fastML/",
    "project_urls": {
      "Download": "https://github.com/Team-fastML/fastML/archive/v0.1.tar.gz",
      "Homepage": "https://github.com/buabaj"
    },
    "release_url": "https://pypi.org/project/fastML/1.0/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "A Python package built with sklearn for running multiple classification algorithms to observe their behaviour in as little as 4 lines. This package drastically makes the work of Data Scientists, AI and ML engineers very easy and fast by saving them the physical stress of writing close to 300 lines of code as they would if not for this package.",
    "version": "1.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8020100,
  "releases": {
    "1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "29919ce4fba377cead426f31a544222b96da0df2539f688fd8a1f6e265a3d754",
          "md5": "51bcbeeb01b03bdbd9bff3a0841a66f5",
          "sha256": "2f3bdd2ea721bb664f1e201e392649495906e27712b3afbbf19bec75ce3eae7c"
        },
        "downloads": -1,
        "filename": "fastML-1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "51bcbeeb01b03bdbd9bff3a0841a66f5",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 7843,
        "upload_time": "2020-06-22T20:37:29",
        "upload_time_iso_8601": "2020-06-22T20:37:29.967189Z",
        "url": "https://files.pythonhosted.org/packages/29/91/9ce4fba377cead426f31a544222b96da0df2539f688fd8a1f6e265a3d754/fastML-1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "29919ce4fba377cead426f31a544222b96da0df2539f688fd8a1f6e265a3d754",
        "md5": "51bcbeeb01b03bdbd9bff3a0841a66f5",
        "sha256": "2f3bdd2ea721bb664f1e201e392649495906e27712b3afbbf19bec75ce3eae7c"
      },
      "downloads": -1,
      "filename": "fastML-1.0.tar.gz",
      "has_sig": false,
      "md5_digest": "51bcbeeb01b03bdbd9bff3a0841a66f5",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 7843,
      "upload_time": "2020-06-22T20:37:29",
      "upload_time_iso_8601": "2020-06-22T20:37:29.967189Z",
      "url": "https://files.pythonhosted.org/packages/29/91/9ce4fba377cead426f31a544222b96da0df2539f688fd8a1f6e265a3d754/fastML-1.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}