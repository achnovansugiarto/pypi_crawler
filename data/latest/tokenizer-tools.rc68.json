{
  "info": {
    "author": "Xiaoquan Kong",
    "author_email": "u1mail2me@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 2 - Pre-Alpha",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Natural Language :: English",
      "Programming Language :: Python :: 2",
      "Programming Language :: Python :: 2.7",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7"
    ],
    "description": "################\nTokenizer Tools\n################\n\n\n.. image:: https://img.shields.io/pypi/v/tokenizer_tools.svg\n        :target: https://pypi.python.org/pypi/tokenizer_tools\n\n.. image:: https://travis-ci.com/howl-anderson/tokenizer_tools.svg?branch=master\n        :target: https://travis-ci.com/howl-anderson/tokenizer_tools\n\n.. image:: https://readthedocs.org/projects/tokenizer-tools/badge/?version=latest\n        :target: https://tokenizer-tools.readthedocs.io/en/latest/?badge=latest\n        :alt: Documentation Status\n\n\n.. image:: https://pyup.io/repos/github/howlandersonn/tokenizer_tools/shield.svg\n     :target: https://pyup.io/repos/github/howlandersonn/tokenizer_tools/\n     :alt: Updates\n\n\n\nTools/Utils for NLP (including dataset reading, tagset encoding & decoding, metrics computing) | NLP 工具集（包含数据集读取、tagset 编码和解码、指标的计算等）\n\n\n* Free software: MIT license\n* Documentation: https://tokenizer-tools.readthedocs.io.\n\n\n*********\nFeatures\n*********\n\n* 常见数据集格式的读取\n* 多种 Tagset 的编码和解码 [`BMES 体系 <tokenizer_tools/tagset/BMES.py>`_, `BILUO 体系 <tokenizer_tools/tagset/NER/BILUO.py>`_, `IOB 体系 <tokenizer_tools/tagset/NER/IOB.py>`_]\n* 指标的计算\n\n*******\n功能\n*******\n\n语料集读写\n============\n\n本软件提供了一种语料存储的磁盘文件格式（暂定名为 conllx）和内存对象格式（暂定名为 offset）。\n\n语料集读取\n------------\n任务：读取 corpus.collx 文件，遍历打印每一条语料。\n\n代码：\n\n.. code-block:: python\n\n    from tokenizer_tools.tagset.offset.corpus import Corpus\n\n    corpus = Corpus.read_from_file(\"corpus.conllx\")\n    for document in corpus:\n        print(document)  # document 就是单条语料对象\n\n语料集写入\n-----------\n任务：将多条语料写入 corpus.conllx 文件\n\n代码：\n\n.. code-block:: python\n\n    from tokenizer_tools.tagset.offset.corpus import Corpus\n\n    corpus_list = [corpus_item_one, corpus_item_two]\n\n    corpus = Corpus(corpus_list)\n    corpus.write_to_file(\"corpus.conllx\")\n\nDocument 属性和方法\n=======================\n\n每一个单条语料都是一个 Document 对象，现在介绍这个对象所拥有的属性和方法\n\n属性\n-----------\n\ntext\n^^^^^^^^^^^\n类型是 list， 代表文本的字段\n\ndomain\n^^^^^^^^^^^\n类型是 string， 代表领域\n\nfunction\n^^^^^^^^^^^^\n类型是 string， 代表功能点\n\nsub_function\n^^^^^^^^^^^^^^^^^^\n类型是 string，代表子功能点\n\nintent\n^^^^^^^^^^^^\n类型是 string， 代表意图\n\nentities\n^^^^^^^^^^^^^^\n类型是 SpanSet， 代表实体，下文有详细介绍\n\n方法\n------------\n\ncompare_entities\n^^^^^^^^^^^^^^^^^^^^^^^^^^^\n比较文本和实体是否匹配\n\nconvert_to_md\n^^^^^^^^^^^^^^^^^^^^^\n将文本和实体转换成 markdown 格式，用于文本化渲染输出\n\n\nSpanSet 属性和方法\n====================\n\n方法\n------\n\n__iter__\n^^^^^^^^^^^^^^^\n可以像列表一样访问，得到的每一个元素都是 Span 对象\n\ncheck_overlap\n^^^^^^^^^^^^^^^^^^^^^^\n检查 span 是否重叠\n\nSpan 属性和方法\n=============================\n\n属性\n-------\n\nstart\n^^^^^^^^^^^\nint, 从 0 开始，包含该位置\n\nend\n^^^^^^^^\nint， 从0开始，不包含该位置\n\nentity\n^^^^^^^^^^^^\nstring， 实体类型\n\nvalue\n^^^^^^^^^^^^^\nstring， 实体的值\n\n******\nTODO\n******\n\n* 改变项目的名字，tokenizer_tools 已经无法正确描述现在项目的功能\n\n*********\nCredits\n*********\n\nThis package was created with Cookiecutter_ and the `audreyr/cookiecutter-pypackage`_ project template.\n\n.. _Cookiecutter: https://github.com/audreyr/cookiecutter\n.. _`audreyr/cookiecutter-pypackage`: https://github.com/audreyr/cookiecutter-pypackage\n\n\n########\nHistory\n########\n\n***********************\n0.1.0 (2018-09-05)\n***********************\n\n* First release on PyPI.\n\n\n",
    "description_content_type": "",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/howlandersonn/tokenizer_tools",
    "keywords": "tokenizer_tools",
    "license": "MIT license",
    "maintainer": "",
    "maintainer_email": "",
    "name": "tokenizer-tools",
    "package_url": "https://pypi.org/project/tokenizer-tools/",
    "platform": "",
    "project_url": "https://pypi.org/project/tokenizer-tools/",
    "project_urls": {
      "Homepage": "https://github.com/howlandersonn/tokenizer_tools"
    },
    "release_url": "https://pypi.org/project/tokenizer-tools/0.46.1/",
    "requires_dist": [
      "Click (>=6.0)",
      "scikit-learn",
      "scipy",
      "pandas",
      "fuzzywuzzy",
      "plotly",
      "mistletoe",
      "tqdm",
      "flask",
      "elasticsearch-dsl",
      "pyahocorasick"
    ],
    "requires_python": "",
    "summary": "Tools for tokenizer develope and evaluation",
    "version": "0.46.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8244101,
  "releases": {
    "0.1.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "60a8e8db5f42aa269427b16e81fe5c50a862d37828f2faf108e87cc6aa15cd76",
          "md5": "76d300e6e46f855f5c32ccd1520ddea8",
          "sha256": "5f90a77c0922b40dc0effd57942b4c8b68f0ad760073561aed1d0216acc48bcf"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.1.5-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "76d300e6e46f855f5c32ccd1520ddea8",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 4362,
        "upload_time": "2018-09-06T08:10:01",
        "upload_time_iso_8601": "2018-09-06T08:10:01.722857Z",
        "url": "https://files.pythonhosted.org/packages/60/a8/e8db5f42aa269427b16e81fe5c50a862d37828f2faf108e87cc6aa15cd76/tokenizer_tools-0.1.5-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5eaed8c7d076ced8997191d43bdf512859389fb3eda8ec488f477ea21bc9d912",
          "md5": "1371545493b9fd2becd0dc9b53d341df",
          "sha256": "8532152a2a833b531638c9048158d0778f15d41296bcd3d3ee441c5d0c8378f4"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.1.5.tar.gz",
        "has_sig": false,
        "md5_digest": "1371545493b9fd2becd0dc9b53d341df",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 9719,
        "upload_time": "2018-09-06T08:10:03",
        "upload_time_iso_8601": "2018-09-06T08:10:03.568834Z",
        "url": "https://files.pythonhosted.org/packages/5e/ae/d8c7d076ced8997191d43bdf512859389fb3eda8ec488f477ea21bc9d912/tokenizer_tools-0.1.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.10.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a7c44cffdf3e4f17614549e50d290516cf5d7c208ef9e3b62f330dcc6873e4b4",
          "md5": "652b4aa587ae56846f2adabf8816d18d",
          "sha256": "d1c01f12f71b766d5806a5df12bc83f78622762ec8de4238a6281734cbf382bc"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.10.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "652b4aa587ae56846f2adabf8816d18d",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 16211,
        "upload_time": "2018-11-21T06:26:14",
        "upload_time_iso_8601": "2018-11-21T06:26:14.020631Z",
        "url": "https://files.pythonhosted.org/packages/a7/c4/4cffdf3e4f17614549e50d290516cf5d7c208ef9e3b62f330dcc6873e4b4/tokenizer_tools-0.10.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d27a604a3fc13c8eaa77b218ef937942ee873ab50a35d2c54c4e571aff423954",
          "md5": "a6abd24a299e3bdd027c7806a06bd2b3",
          "sha256": "4d2cfda0dc059c12e15d74054fc12a129aa19d30bdc2519c2959b8829412d0c2"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.10.0.tar.gz",
        "has_sig": false,
        "md5_digest": "a6abd24a299e3bdd027c7806a06bd2b3",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 16163,
        "upload_time": "2018-11-21T06:26:16",
        "upload_time_iso_8601": "2018-11-21T06:26:16.182744Z",
        "url": "https://files.pythonhosted.org/packages/d2/7a/604a3fc13c8eaa77b218ef937942ee873ab50a35d2c54c4e571aff423954/tokenizer_tools-0.10.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.11.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7ddacca60d8e18ea52f0aaf50efa55e2a6faf217a50706ed1ad787c3a5b6eba2",
          "md5": "17b97d5f0ee50337656382dea18ba5b1",
          "sha256": "0fab9e5962b61c5e0a71f69e0c31bf93164e5d83ea058a576669aaacea7326e3"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.11.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "17b97d5f0ee50337656382dea18ba5b1",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 20675,
        "upload_time": "2019-01-15T08:17:45",
        "upload_time_iso_8601": "2019-01-15T08:17:45.015058Z",
        "url": "https://files.pythonhosted.org/packages/7d/da/cca60d8e18ea52f0aaf50efa55e2a6faf217a50706ed1ad787c3a5b6eba2/tokenizer_tools-0.11.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "00082e267512d9526284ab378173572d6daa41a0b417a7d995bafed1818948ef",
          "md5": "761100c89291c4722cbd4c2f58ee7fc4",
          "sha256": "3ce9aabd41aa392abd96c68e48b1014f030f5fb406cb31f4cb46f7366c4bd0f0"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.11.0.tar.gz",
        "has_sig": false,
        "md5_digest": "761100c89291c4722cbd4c2f58ee7fc4",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 18923,
        "upload_time": "2019-01-15T08:17:47",
        "upload_time_iso_8601": "2019-01-15T08:17:47.184918Z",
        "url": "https://files.pythonhosted.org/packages/00/08/2e267512d9526284ab378173572d6daa41a0b417a7d995bafed1818948ef/tokenizer_tools-0.11.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.12.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3bca0289a65676dccc9e5045ba61098bbc06635a1453faa95a6346535a1d76ab",
          "md5": "d41bb62df32b2f2bf6706e2518b8fb28",
          "sha256": "4be0b5c543fa63ff207d2eab261b8cb7e9485a69d708f7f01d0ac95529238888"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.12.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d41bb62df32b2f2bf6706e2518b8fb28",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 27103,
        "upload_time": "2019-03-11T09:34:02",
        "upload_time_iso_8601": "2019-03-11T09:34:02.760380Z",
        "url": "https://files.pythonhosted.org/packages/3b/ca/0289a65676dccc9e5045ba61098bbc06635a1453faa95a6346535a1d76ab/tokenizer_tools-0.12.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8d9bb46104a0f1c6599a59f92f5b501f805bc584beb0b952dfd45b6e073669ed",
          "md5": "3943b723f20b9b6c80d12630e636865f",
          "sha256": "57ab3d0a012b82a1fc8f2d402fcdc62dadd272a790767f554ce90251e99cf0c7"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.12.0.tar.gz",
        "has_sig": false,
        "md5_digest": "3943b723f20b9b6c80d12630e636865f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 24309,
        "upload_time": "2019-03-11T09:34:04",
        "upload_time_iso_8601": "2019-03-11T09:34:04.637445Z",
        "url": "https://files.pythonhosted.org/packages/8d/9b/b46104a0f1c6599a59f92f5b501f805bc584beb0b952dfd45b6e073669ed/tokenizer_tools-0.12.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.13.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "af7066aa3a10dea7de2d8b13470f503e90919306684e30f7925f37e79712f557",
          "md5": "c5dc289948615c9fe779359f48bb1557",
          "sha256": "8193b2f05f50c6544c3443af67aa3ce3737dd876000eb3451682d516a34dca49"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.13.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "c5dc289948615c9fe779359f48bb1557",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 27172,
        "upload_time": "2019-03-29T08:26:44",
        "upload_time_iso_8601": "2019-03-29T08:26:44.807988Z",
        "url": "https://files.pythonhosted.org/packages/af/70/66aa3a10dea7de2d8b13470f503e90919306684e30f7925f37e79712f557/tokenizer_tools-0.13.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3c9c678fbde3ac26c7f883712acaa19581237b2f30242f523b3aa24eb329f3de",
          "md5": "a6dc568605b019ff984e30c40227cd4b",
          "sha256": "12f85b991edbad88094cd2d842a2df9198e22dfcc89b91425eba324a99eb4951"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.13.0.tar.gz",
        "has_sig": false,
        "md5_digest": "a6dc568605b019ff984e30c40227cd4b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 24366,
        "upload_time": "2019-03-29T08:26:47",
        "upload_time_iso_8601": "2019-03-29T08:26:47.403378Z",
        "url": "https://files.pythonhosted.org/packages/3c/9c/678fbde3ac26c7f883712acaa19581237b2f30242f523b3aa24eb329f3de/tokenizer_tools-0.13.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.13.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b09c8be7c373f8f6f9137a57e835a9e943c72604bcbd43afc537bbb1b2d3246a",
          "md5": "575ce4f1b4583b1f68fb1e2d50ab0b1f",
          "sha256": "b32a11f77efbcb89b9eb414da1a2f5bd5d5c034caeece92f0b20a22e848640ce"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.13.1-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "575ce4f1b4583b1f68fb1e2d50ab0b1f",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 27177,
        "upload_time": "2019-03-29T09:27:37",
        "upload_time_iso_8601": "2019-03-29T09:27:37.921824Z",
        "url": "https://files.pythonhosted.org/packages/b0/9c/8be7c373f8f6f9137a57e835a9e943c72604bcbd43afc537bbb1b2d3246a/tokenizer_tools-0.13.1-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9ea74e00c4afb192d93623ddd3c4395b23a05cb0fdf4eab388179c19f14f624c",
          "md5": "94e412b552b91016e7c98d0249d317b1",
          "sha256": "c5db4528021ef6a8984e3c4906b8e44a50f201108786ee7327504490e1a643c8"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.13.1.tar.gz",
        "has_sig": false,
        "md5_digest": "94e412b552b91016e7c98d0249d317b1",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 24376,
        "upload_time": "2019-03-29T09:27:40",
        "upload_time_iso_8601": "2019-03-29T09:27:40.214361Z",
        "url": "https://files.pythonhosted.org/packages/9e/a7/4e00c4afb192d93623ddd3c4395b23a05cb0fdf4eab388179c19f14f624c/tokenizer_tools-0.13.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.14.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5dca69c0ddc7ec7de321d7f6197fc52087328ef59804d34f7e59eca235799063",
          "md5": "04037cf114cb15d878eab44e9857664b",
          "sha256": "3e15188912dbf67b67b74822ef7352bd4da9ddff024caf2edb0dd618e29a74f1"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.14.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "04037cf114cb15d878eab44e9857664b",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 28560,
        "upload_time": "2019-05-20T06:41:49",
        "upload_time_iso_8601": "2019-05-20T06:41:49.858076Z",
        "url": "https://files.pythonhosted.org/packages/5d/ca/69c0ddc7ec7de321d7f6197fc52087328ef59804d34f7e59eca235799063/tokenizer_tools-0.14.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "865f00b5d902f0e738c281bc78648001be5e7973c22edcf5840b4363391a7452",
          "md5": "beeca8a4d96deb373d8275b8891026fd",
          "sha256": "ccc099bfb7193d5edcb3d85be9a6b432537515de6031aa631b646aa42ddfc064"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.14.0.tar.gz",
        "has_sig": false,
        "md5_digest": "beeca8a4d96deb373d8275b8891026fd",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 25420,
        "upload_time": "2019-05-20T06:41:51",
        "upload_time_iso_8601": "2019-05-20T06:41:51.865259Z",
        "url": "https://files.pythonhosted.org/packages/86/5f/00b5d902f0e738c281bc78648001be5e7973c22edcf5840b4363391a7452/tokenizer_tools-0.14.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.14.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9b725a382955dd59bc34a16dd2708bf7d7f0a0e458240a24830d7c307f8f730f",
          "md5": "319f4ae0b422a864fb6e0464a03d3e64",
          "sha256": "99e66604d82e6fe11d3babafdc0bc800d119d0c346d07f0a410da13aa23045bd"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.14.1-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "319f4ae0b422a864fb6e0464a03d3e64",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 28619,
        "upload_time": "2019-06-28T08:42:25",
        "upload_time_iso_8601": "2019-06-28T08:42:25.138501Z",
        "url": "https://files.pythonhosted.org/packages/9b/72/5a382955dd59bc34a16dd2708bf7d7f0a0e458240a24830d7c307f8f730f/tokenizer_tools-0.14.1-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2a11f108a0ef08df3c5ff77681c3b33d1851c8806c7586523c1a59f62b9c229b",
          "md5": "7dab3666ef11856990bdc71ebbef0f75",
          "sha256": "be73a5aa1f540ea645c04bcbebaf3a395ddfe9ee9c77b55be3317c33137d1393"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.14.1.tar.gz",
        "has_sig": false,
        "md5_digest": "7dab3666ef11856990bdc71ebbef0f75",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 25485,
        "upload_time": "2019-06-28T08:42:26",
        "upload_time_iso_8601": "2019-06-28T08:42:26.797508Z",
        "url": "https://files.pythonhosted.org/packages/2a/11/f108a0ef08df3c5ff77681c3b33d1851c8806c7586523c1a59f62b9c229b/tokenizer_tools-0.14.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.15.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c6289376155259f83f2b071df67351fda91250b090d1707eee06e23ce66b26cc",
          "md5": "4478af6a7784a6d162616c1dfb203750",
          "sha256": "07da41097ea0ba9c6d3382f25605c9e31f9ea9e5a80a5c616c7557bf617b045d"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.15.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "4478af6a7784a6d162616c1dfb203750",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 30868,
        "upload_time": "2019-09-09T03:01:30",
        "upload_time_iso_8601": "2019-09-09T03:01:30.524422Z",
        "url": "https://files.pythonhosted.org/packages/c6/28/9376155259f83f2b071df67351fda91250b090d1707eee06e23ce66b26cc/tokenizer_tools-0.15.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2375b287514a53d33bc6f3d58e062a01ceb3d66e8a73582d5c5ef9a5ca247d51",
          "md5": "b8fb96390c2a09936f02ca4422343a62",
          "sha256": "9e444eb47fa601a5d0089ad91cffcc61be0b1655880df5f9d998f5ebf307bc3a"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.15.0.tar.gz",
        "has_sig": false,
        "md5_digest": "b8fb96390c2a09936f02ca4422343a62",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 24716,
        "upload_time": "2019-09-09T03:01:32",
        "upload_time_iso_8601": "2019-09-09T03:01:32.497721Z",
        "url": "https://files.pythonhosted.org/packages/23/75/b287514a53d33bc6f3d58e062a01ceb3d66e8a73582d5c5ef9a5ca247d51/tokenizer_tools-0.15.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.15.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c301bc65e6d5e59f3472489c3025e23c12dc91977d76930ae2b6b2f1542f21ea",
          "md5": "e359f2fe722921890a47e714eee83172",
          "sha256": "5e838850ee2155c907ae741f45cdf4d87affc4a13d4cfc958fde18bc69ac8179"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.15.2-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "e359f2fe722921890a47e714eee83172",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 30878,
        "upload_time": "2019-09-17T09:10:58",
        "upload_time_iso_8601": "2019-09-17T09:10:58.338567Z",
        "url": "https://files.pythonhosted.org/packages/c3/01/bc65e6d5e59f3472489c3025e23c12dc91977d76930ae2b6b2f1542f21ea/tokenizer_tools-0.15.2-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "eea3524046961efaa52ef23cbeeb2fe1114d20594992c0ccc3bf9544349517c3",
          "md5": "a0e8edd475c1641ffee51ee9151f7237",
          "sha256": "b4e413e3714579beef1195262c7183f3c3d894e952dd09ec4da7602bd17674d7"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.15.2.tar.gz",
        "has_sig": false,
        "md5_digest": "a0e8edd475c1641ffee51ee9151f7237",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 24931,
        "upload_time": "2019-09-17T09:11:00",
        "upload_time_iso_8601": "2019-09-17T09:11:00.619811Z",
        "url": "https://files.pythonhosted.org/packages/ee/a3/524046961efaa52ef23cbeeb2fe1114d20594992c0ccc3bf9544349517c3/tokenizer_tools-0.15.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.15.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "afbe64b1be3703e35c7e10de6f0db2c115ba5e1bb412ab7a2a563474997d937c",
          "md5": "dc5cbfbfc7071b409c24fc4e84e41b81",
          "sha256": "3ab484a7690fca47f35d45ac2865221902735278e021737fc7112102c9916443"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.15.3-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "dc5cbfbfc7071b409c24fc4e84e41b81",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 31127,
        "upload_time": "2019-09-18T06:46:49",
        "upload_time_iso_8601": "2019-09-18T06:46:49.700932Z",
        "url": "https://files.pythonhosted.org/packages/af/be/64b1be3703e35c7e10de6f0db2c115ba5e1bb412ab7a2a563474997d937c/tokenizer_tools-0.15.3-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2fb3bc94fb33053c841a17513e681a10b1e0f0fddb0ada8d03af8ff703727abc",
          "md5": "aa2aa3df90a67241eb2368bab95cce94",
          "sha256": "8bd686e46a4a2127323ac858851f066f8f7735309c7ecae69c0443d7f76f5bc0"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.15.3.tar.gz",
        "has_sig": false,
        "md5_digest": "aa2aa3df90a67241eb2368bab95cce94",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 24987,
        "upload_time": "2019-09-18T06:46:51",
        "upload_time_iso_8601": "2019-09-18T06:46:51.974097Z",
        "url": "https://files.pythonhosted.org/packages/2f/b3/bc94fb33053c841a17513e681a10b1e0f0fddb0ada8d03af8ff703727abc/tokenizer_tools-0.15.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.15.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "22f1896b8ae7776470ba8124dda0f89a082988e39d280231f9e06d22eccbd8a2",
          "md5": "d0d29ec299bf224440d5a27ff18aa2f7",
          "sha256": "be35fc6bcf4a8719a4cb9624cb3ef73772011dfb7da7c167c6c87df9df4e650b"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.15.6-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d0d29ec299bf224440d5a27ff18aa2f7",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 31128,
        "upload_time": "2019-09-29T07:05:30",
        "upload_time_iso_8601": "2019-09-29T07:05:30.852708Z",
        "url": "https://files.pythonhosted.org/packages/22/f1/896b8ae7776470ba8124dda0f89a082988e39d280231f9e06d22eccbd8a2/tokenizer_tools-0.15.6-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b274efba68a3c6713ffbdc9caa372c05f5e50de272a1f6b29c663ac2b8f40a1b",
          "md5": "e6aadc4c832265635fde4b50e238a3c7",
          "sha256": "39b010a91cea78b98bf30e006b7eb9b3f6dd08718ab2eb8e0edf7997090dda11"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.15.6.tar.gz",
        "has_sig": false,
        "md5_digest": "e6aadc4c832265635fde4b50e238a3c7",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 25015,
        "upload_time": "2019-09-29T07:05:32",
        "upload_time_iso_8601": "2019-09-29T07:05:32.614271Z",
        "url": "https://files.pythonhosted.org/packages/b2/74/efba68a3c6713ffbdc9caa372c05f5e50de272a1f6b29c663ac2b8f40a1b/tokenizer_tools-0.15.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.15.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7151760a5110c8d12ed5dc699a615098b2f5d4f96ff01b14480995b7880d2aae",
          "md5": "ad1ca9a3ed46d379d9468cd7f2253489",
          "sha256": "bf197032cd647703681dc8e751f5f6245db8931adbf3e7b13aaab78dcf3af82b"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.15.7-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ad1ca9a3ed46d379d9468cd7f2253489",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 31129,
        "upload_time": "2019-09-29T07:07:33",
        "upload_time_iso_8601": "2019-09-29T07:07:33.573476Z",
        "url": "https://files.pythonhosted.org/packages/71/51/760a5110c8d12ed5dc699a615098b2f5d4f96ff01b14480995b7880d2aae/tokenizer_tools-0.15.7-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3b6662131df40f83005a16ff7154d0d50f8300b6f0eeede681f1d35b2d443e5a",
          "md5": "732e30a8a13dd065a61354be641edfba",
          "sha256": "daa6f994b096bd438ecd9ce9673eab2708c9f5af19b53c892d595339c8b2466e"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.15.7.tar.gz",
        "has_sig": false,
        "md5_digest": "732e30a8a13dd065a61354be641edfba",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 25007,
        "upload_time": "2019-09-29T07:07:35",
        "upload_time_iso_8601": "2019-09-29T07:07:35.586936Z",
        "url": "https://files.pythonhosted.org/packages/3b/66/62131df40f83005a16ff7154d0d50f8300b6f0eeede681f1d35b2d443e5a/tokenizer_tools-0.15.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.16.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4012197f1364a987c0e78e0c1e895c50001558daa61cd4084d7bab020a61fc47",
          "md5": "a0baecc0ad20869816e7eb1bdf2a02c3",
          "sha256": "71d642f0927c47b9976fc5f068c4f3378d7d437ca6b59592e0e6b38472af574c"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.16.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "a0baecc0ad20869816e7eb1bdf2a02c3",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 34999,
        "upload_time": "2019-11-12T09:13:37",
        "upload_time_iso_8601": "2019-11-12T09:13:37.034657Z",
        "url": "https://files.pythonhosted.org/packages/40/12/197f1364a987c0e78e0c1e895c50001558daa61cd4084d7bab020a61fc47/tokenizer_tools-0.16.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "71812c3c816b10315d5dddb99964ee22bdeaec07ec03db9dbb6ea1233b929cfd",
          "md5": "c8f7056940f8b1b65d6a7894aea2619c",
          "sha256": "e9d0dcf166a4b5dd3cdcb8878c3b7a85ca5085996c3309dc6b74915b92e6403c"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.16.0.tar.gz",
        "has_sig": false,
        "md5_digest": "c8f7056940f8b1b65d6a7894aea2619c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 30350,
        "upload_time": "2019-11-12T09:13:39",
        "upload_time_iso_8601": "2019-11-12T09:13:39.114382Z",
        "url": "https://files.pythonhosted.org/packages/71/81/2c3c816b10315d5dddb99964ee22bdeaec07ec03db9dbb6ea1233b929cfd/tokenizer_tools-0.16.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.17.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1a5b3decb187988b8a79d46e2c080714f04c1cafacf19d3fc7cd025fbdad000b",
          "md5": "622f9091c772b9f7b9a8a91b99220259",
          "sha256": "61e693c8e8e4471f66fc66992bc4f392e2ef56adef929f01a73e217c1a830c43"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.17.1-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "622f9091c772b9f7b9a8a91b99220259",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 37433,
        "upload_time": "2019-11-22T08:56:57",
        "upload_time_iso_8601": "2019-11-22T08:56:57.164872Z",
        "url": "https://files.pythonhosted.org/packages/1a/5b/3decb187988b8a79d46e2c080714f04c1cafacf19d3fc7cd025fbdad000b/tokenizer_tools-0.17.1-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4c917203b89ab883cc22e78c9d3e5bb59f3ebdd13bd3d820b29b72abf0363555",
          "md5": "ed9a356ff894581059cc806aee1dd9be",
          "sha256": "8509bf41fae9b1683a0be8ef6f3ad8163b7b61228991708fa151ee412a9b3cbd"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.17.1.tar.gz",
        "has_sig": false,
        "md5_digest": "ed9a356ff894581059cc806aee1dd9be",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 34908,
        "upload_time": "2019-11-22T08:56:59",
        "upload_time_iso_8601": "2019-11-22T08:56:59.593512Z",
        "url": "https://files.pythonhosted.org/packages/4c/91/7203b89ab883cc22e78c9d3e5bb59f3ebdd13bd3d820b29b72abf0363555/tokenizer_tools-0.17.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.18.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bcc304154bd7e8d142b6e13300cf6cec6f301f236a11a0c5639e023abeeb10f2",
          "md5": "8a78ae711cb3174d185f23d48cef5ed1",
          "sha256": "04099a547262adeca5fd4a3ec399c5515f8a1b608748abb77f2829779326b4ce"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.18.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "8a78ae711cb3174d185f23d48cef5ed1",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 37488,
        "upload_time": "2019-12-05T06:56:35",
        "upload_time_iso_8601": "2019-12-05T06:56:35.597159Z",
        "url": "https://files.pythonhosted.org/packages/bc/c3/04154bd7e8d142b6e13300cf6cec6f301f236a11a0c5639e023abeeb10f2/tokenizer_tools-0.18.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "16ad9e0343a75ac2b4b32259a4242aa54b66bb72401dd85995fc094534bff18e",
          "md5": "55e364fd111e45ce0625439f0dbb8366",
          "sha256": "8dda808c35bba2280400ecc2f5f5204c4d1199a3d9d7c530eaa11a06111ce0da"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.18.0.tar.gz",
        "has_sig": false,
        "md5_digest": "55e364fd111e45ce0625439f0dbb8366",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 36374,
        "upload_time": "2019-12-05T06:56:37",
        "upload_time_iso_8601": "2019-12-05T06:56:37.449295Z",
        "url": "https://files.pythonhosted.org/packages/16/ad/9e0343a75ac2b4b32259a4242aa54b66bb72401dd85995fc094534bff18e/tokenizer_tools-0.18.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.19.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b7aae9325af428f0f1cad8bc66725073cf018c9ff4b00ad20516f14878b98c22",
          "md5": "a6ed76a6f525973f5f86f7b8147d377e",
          "sha256": "167c6c3375cb61ac2e4534bccf4de66169f1e11f1743e95a1e496150754a0030"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.19.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "a6ed76a6f525973f5f86f7b8147d377e",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 37710,
        "upload_time": "2019-12-05T08:52:29",
        "upload_time_iso_8601": "2019-12-05T08:52:29.554172Z",
        "url": "https://files.pythonhosted.org/packages/b7/aa/e9325af428f0f1cad8bc66725073cf018c9ff4b00ad20516f14878b98c22/tokenizer_tools-0.19.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "450598c5ca6c4c8d1a0961bd75b8dc4be3aa4daafa1450a2689f18f747e1e69c",
          "md5": "61c43d221a29eb8baef29082ec65a8c9",
          "sha256": "80cd1a1b61ae70d9c009890a3f0d539d7721db16afcf93108d101e919faace0d"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.19.0.tar.gz",
        "has_sig": false,
        "md5_digest": "61c43d221a29eb8baef29082ec65a8c9",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 36969,
        "upload_time": "2019-12-05T08:52:31",
        "upload_time_iso_8601": "2019-12-05T08:52:31.533129Z",
        "url": "https://files.pythonhosted.org/packages/45/05/98c5ca6c4c8d1a0961bd75b8dc4be3aa4daafa1450a2689f18f747e1e69c/tokenizer_tools-0.19.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4ba86912a69ffb9377be44fe5eccf57cc42cefc9e8808979874c2959c6aadef9",
          "md5": "589a11849902a47fb02ff324e0d840cf",
          "sha256": "a76068fa9a431c813bd17bef336576bf260ba0c937cb21054b953c24b6b19fcb"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.2.1-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "589a11849902a47fb02ff324e0d840cf",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 4999,
        "upload_time": "2018-09-06T09:48:21",
        "upload_time_iso_8601": "2018-09-06T09:48:21.412401Z",
        "url": "https://files.pythonhosted.org/packages/4b/a8/6912a69ffb9377be44fe5eccf57cc42cefc9e8808979874c2959c6aadef9/tokenizer_tools-0.2.1-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "65303f141bdde5ce3b6547b47a02b3ef567e15afe5f1ac4c973a928188662c5f",
          "md5": "f19a2bb4445a4e7257890ec923f39580",
          "sha256": "adbe583a00fdcb9bf517c60bdff64ee3a746a3d537b61c33ca7d1602109676d4"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.2.1.tar.gz",
        "has_sig": false,
        "md5_digest": "f19a2bb4445a4e7257890ec923f39580",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 10072,
        "upload_time": "2018-09-06T09:48:23",
        "upload_time_iso_8601": "2018-09-06T09:48:23.132784Z",
        "url": "https://files.pythonhosted.org/packages/65/30/3f141bdde5ce3b6547b47a02b3ef567e15afe5f1ac4c973a928188662c5f/tokenizer_tools-0.2.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "edd080c93e83d634be7483f292ac330cb459ca2d5b3d0963101c3412ce264f7a",
          "md5": "08ee277c1f8241a46b6c3df9046c899e",
          "sha256": "6618c00bad477b0c28e07e1af3346c97b217ae01585db623a646ee8be41474e7"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.2.2-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "08ee277c1f8241a46b6c3df9046c899e",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 5001,
        "upload_time": "2018-09-06T10:15:38",
        "upload_time_iso_8601": "2018-09-06T10:15:38.809471Z",
        "url": "https://files.pythonhosted.org/packages/ed/d0/80c93e83d634be7483f292ac330cb459ca2d5b3d0963101c3412ce264f7a/tokenizer_tools-0.2.2-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "423606e64b8bdb9f67270ca5d998095d5cd52f38944a4772a29c0005b379feec",
          "md5": "c3b490714802b15ac538e67840c718e1",
          "sha256": "dd3e8c15743a9a45858c1faccf046ba5be6de6e7a5782ea2588b2b4fa4dda38f"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.2.2.tar.gz",
        "has_sig": false,
        "md5_digest": "c3b490714802b15ac538e67840c718e1",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 10068,
        "upload_time": "2018-09-06T10:15:40",
        "upload_time_iso_8601": "2018-09-06T10:15:40.630017Z",
        "url": "https://files.pythonhosted.org/packages/42/36/06e64b8bdb9f67270ca5d998095d5cd52f38944a4772a29c0005b379feec/tokenizer_tools-0.2.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.20.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fe24fab5a984957daf24a3d5737dd618b226ab21a031a59b0c211e2ff06583b3",
          "md5": "02e9d8ead5bdd8bc157d3745a99e564a",
          "sha256": "717d434bc1032c563ea06008d2b5ef8574f7483ea5661f67a9dd3242da42935a"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.20.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "02e9d8ead5bdd8bc157d3745a99e564a",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 37845,
        "upload_time": "2019-12-06T04:31:28",
        "upload_time_iso_8601": "2019-12-06T04:31:28.592261Z",
        "url": "https://files.pythonhosted.org/packages/fe/24/fab5a984957daf24a3d5737dd618b226ab21a031a59b0c211e2ff06583b3/tokenizer_tools-0.20.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "62e6d09118fabaef689b479784902eec07dc3baa023a669fd0093de3d5851b1c",
          "md5": "4d4740861ba72ed42ce952e76366303b",
          "sha256": "803ce011a997329c1320da1fd2d443523b867a4ca4aee4860b8991536f614c0d"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.20.0.tar.gz",
        "has_sig": false,
        "md5_digest": "4d4740861ba72ed42ce952e76366303b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 37276,
        "upload_time": "2019-12-06T04:31:31",
        "upload_time_iso_8601": "2019-12-06T04:31:31.469825Z",
        "url": "https://files.pythonhosted.org/packages/62/e6/d09118fabaef689b479784902eec07dc3baa023a669fd0093de3d5851b1c/tokenizer_tools-0.20.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.21.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "30d6be3d9a36a8d160daa7ef06525c1f4f7e9f9db01c5dc89b0da4d227e3319c",
          "md5": "7d62554933109b2a76526ef5bd14f8fb",
          "sha256": "b732e09c25968508d80acddbe5506ed7aef8300f4e084417d7259ad1e9c30a66"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.21.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "7d62554933109b2a76526ef5bd14f8fb",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 39841,
        "upload_time": "2020-01-14T03:18:39",
        "upload_time_iso_8601": "2020-01-14T03:18:39.034833Z",
        "url": "https://files.pythonhosted.org/packages/30/d6/be3d9a36a8d160daa7ef06525c1f4f7e9f9db01c5dc89b0da4d227e3319c/tokenizer_tools-0.21.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7bc7122e9d81c9b8b56057c652fa0230ee5e87c94ee571f42eedc3b6c831d36f",
          "md5": "03915eddb8fb109afa0979deefe6f772",
          "sha256": "aea14271449ff565281a10f30968c519385cc7b398d616dc7010e76ad491cd29"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.21.0.tar.gz",
        "has_sig": false,
        "md5_digest": "03915eddb8fb109afa0979deefe6f772",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 39770,
        "upload_time": "2020-01-14T03:18:41",
        "upload_time_iso_8601": "2020-01-14T03:18:41.119829Z",
        "url": "https://files.pythonhosted.org/packages/7b/c7/122e9d81c9b8b56057c652fa0230ee5e87c94ee571f42eedc3b6c831d36f/tokenizer_tools-0.21.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.21.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "702f56ee0130b653b6a28f5950a82b6cdcd1a271dd1e071bee21c09604246ca1",
          "md5": "d2154a5cd3bcc42a09f89897f83b0def",
          "sha256": "70c128f1a2a738c7c28ca6db53df6d2289c1453ad9bee81a7acc8dbdc3b18da4"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.21.1-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d2154a5cd3bcc42a09f89897f83b0def",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 40021,
        "upload_time": "2020-01-14T05:26:54",
        "upload_time_iso_8601": "2020-01-14T05:26:54.855357Z",
        "url": "https://files.pythonhosted.org/packages/70/2f/56ee0130b653b6a28f5950a82b6cdcd1a271dd1e071bee21c09604246ca1/tokenizer_tools-0.21.1-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "57d748ac171e323f61433ec2e9da54b5fae6905c23bef8553b5839cf958bacad",
          "md5": "f9d96dd22fb01640926fde2cebd69daf",
          "sha256": "aacef7a1e97e6721778c8c879a526ad294465969ae898104d09419ee842c81c6"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.21.1.tar.gz",
        "has_sig": false,
        "md5_digest": "f9d96dd22fb01640926fde2cebd69daf",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 40027,
        "upload_time": "2020-01-14T05:26:56",
        "upload_time_iso_8601": "2020-01-14T05:26:56.983066Z",
        "url": "https://files.pythonhosted.org/packages/57/d7/48ac171e323f61433ec2e9da54b5fae6905c23bef8553b5839cf958bacad/tokenizer_tools-0.21.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.22.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5acad7ba1a9411970ffe17126a33187f1fdee727510ff1d58ff53a5363c60db3",
          "md5": "54edc87117e61f8afbcc7aa036348290",
          "sha256": "579f3824466dd7eaa06677ca23399a019f950036cf1b646acffae6641c289fb7"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.22.1-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "54edc87117e61f8afbcc7aa036348290",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 40925,
        "upload_time": "2020-01-20T08:51:55",
        "upload_time_iso_8601": "2020-01-20T08:51:55.118979Z",
        "url": "https://files.pythonhosted.org/packages/5a/ca/d7ba1a9411970ffe17126a33187f1fdee727510ff1d58ff53a5363c60db3/tokenizer_tools-0.22.1-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ee44cbfd911e84fd2824790f2e6f183b125c366fa22392d472f83eadc758aa22",
          "md5": "064aaac5813f546e747eaa1472587715",
          "sha256": "22a6dfe5f456f0a7dc0292c51c2d73cd483ea843e5815ccf37ad088d1aa05b24"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.22.1.tar.gz",
        "has_sig": false,
        "md5_digest": "064aaac5813f546e747eaa1472587715",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 39226,
        "upload_time": "2020-01-20T08:51:57",
        "upload_time_iso_8601": "2020-01-20T08:51:57.000421Z",
        "url": "https://files.pythonhosted.org/packages/ee/44/cbfd911e84fd2824790f2e6f183b125c366fa22392d472f83eadc758aa22/tokenizer_tools-0.22.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.22.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7c9b3e6f13693e27c479179e0a237d8a454c196e72170dc86b7639706558bab6",
          "md5": "3a6609d7a41a08d8b4d7d13357687b75",
          "sha256": "db0a1063bd0235ca0fbd08fdbbd12b57efd762b3705b72d4747f55f9546f499d"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.22.2-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "3a6609d7a41a08d8b4d7d13357687b75",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 43364,
        "upload_time": "2020-01-20T09:08:16",
        "upload_time_iso_8601": "2020-01-20T09:08:16.967590Z",
        "url": "https://files.pythonhosted.org/packages/7c/9b/3e6f13693e27c479179e0a237d8a454c196e72170dc86b7639706558bab6/tokenizer_tools-0.22.2-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d93d9a392d9fa31e928ef6a8af202fc6559d20c778e087274b2ea2059aecfbc0",
          "md5": "1414161828c0dae5b575ff1a1af18b5c",
          "sha256": "fc26c2e2b85218ead41f68800b2a71b0aa2c1e133cd9071321a73aee6643501a"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.22.2.tar.gz",
        "has_sig": false,
        "md5_digest": "1414161828c0dae5b575ff1a1af18b5c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 40339,
        "upload_time": "2020-01-20T09:08:19",
        "upload_time_iso_8601": "2020-01-20T09:08:19.615093Z",
        "url": "https://files.pythonhosted.org/packages/d9/3d/9a392d9fa31e928ef6a8af202fc6559d20c778e087274b2ea2059aecfbc0/tokenizer_tools-0.22.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.23.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "add7133ad11e002b7b49fada15e14ec18a99556dac34749a38b76d3b9321a0fc",
          "md5": "5a740b7fde429c7723098b7c04833d53",
          "sha256": "4bd646d1c3d8058dc1a06d49f8e3c2b59d642c3ae006c261d6f2d7ff2be71cd3"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.23.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "5a740b7fde429c7723098b7c04833d53",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 44257,
        "upload_time": "2020-01-21T04:40:50",
        "upload_time_iso_8601": "2020-01-21T04:40:50.082350Z",
        "url": "https://files.pythonhosted.org/packages/ad/d7/133ad11e002b7b49fada15e14ec18a99556dac34749a38b76d3b9321a0fc/tokenizer_tools-0.23.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a29460b96582779a78ccaa442f2bcdb4232f959b657a8c1bd4490720c8e2bf22",
          "md5": "065cffeb0308b05d62d4305cf85c517f",
          "sha256": "34c1e701b677b0f4a30594d2d00bd7a864f8f6754e21c82ad4dab46371b80549"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.23.0.tar.gz",
        "has_sig": false,
        "md5_digest": "065cffeb0308b05d62d4305cf85c517f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 41308,
        "upload_time": "2020-01-21T04:40:52",
        "upload_time_iso_8601": "2020-01-21T04:40:52.533859Z",
        "url": "https://files.pythonhosted.org/packages/a2/94/60b96582779a78ccaa442f2bcdb4232f959b657a8c1bd4490720c8e2bf22/tokenizer_tools-0.23.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.24.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a57a94a9b382cabbdf6a52f8836a2201e75a65738e78c22b7c5400fb45ed1e72",
          "md5": "99be0e5540115565b689a4598553a39f",
          "sha256": "42e4319892ece5f3766262e7b04f4a33d09b19d3a65fd28e69261b41b603a1be"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.24.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "99be0e5540115565b689a4598553a39f",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 44388,
        "upload_time": "2020-03-30T07:48:34",
        "upload_time_iso_8601": "2020-03-30T07:48:34.599750Z",
        "url": "https://files.pythonhosted.org/packages/a5/7a/94a9b382cabbdf6a52f8836a2201e75a65738e78c22b7c5400fb45ed1e72/tokenizer_tools-0.24.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "dd048665807f1d11fe11ed2c5a30a4c0d0b84f96aeadfba41149672ab47745a0",
          "md5": "b50a60b730c5356038c4e02c9e77a114",
          "sha256": "67f38b2fe0b721b167e06236ebc97663f2277aeaa926dd0da26bd2970a3fb3e2"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.24.0.tar.gz",
        "has_sig": false,
        "md5_digest": "b50a60b730c5356038c4e02c9e77a114",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 49425,
        "upload_time": "2020-03-30T07:48:36",
        "upload_time_iso_8601": "2020-03-30T07:48:36.784647Z",
        "url": "https://files.pythonhosted.org/packages/dd/04/8665807f1d11fe11ed2c5a30a4c0d0b84f96aeadfba41149672ab47745a0/tokenizer_tools-0.24.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.25.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a5bd77d35c9453e02de070258b9bd9a4492b453d855ae321d4aac636e30221a6",
          "md5": "948d811650e42edb8596337935b1dfbf",
          "sha256": "22626c849632ee6767e23e50d43232e6a47181a818f852547a417c7b5c106b7e"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.25.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "948d811650e42edb8596337935b1dfbf",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 44852,
        "upload_time": "2020-03-31T01:45:20",
        "upload_time_iso_8601": "2020-03-31T01:45:20.753266Z",
        "url": "https://files.pythonhosted.org/packages/a5/bd/77d35c9453e02de070258b9bd9a4492b453d855ae321d4aac636e30221a6/tokenizer_tools-0.25.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bfcd964a21a393894e16057217b1bc4fb426cf1adcb8c94c15f60b58b7110e99",
          "md5": "067a7e7023212d4103784bfeeb3d5436",
          "sha256": "588b01e6877af2e85af34ddb42e471052f9a9780b56d5c893a76d37d882e6adc"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.25.0.tar.gz",
        "has_sig": false,
        "md5_digest": "067a7e7023212d4103784bfeeb3d5436",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 49742,
        "upload_time": "2020-03-31T01:45:23",
        "upload_time_iso_8601": "2020-03-31T01:45:23.172959Z",
        "url": "https://files.pythonhosted.org/packages/bf/cd/964a21a393894e16057217b1bc4fb426cf1adcb8c94c15f60b58b7110e99/tokenizer_tools-0.25.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.26.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9935f60aa7d2086f1d6badb0b881464e6bd5737fde4dc8b048eee062844c51df",
          "md5": "b2c25d21e37c36f2eeeda1ea86bb505c",
          "sha256": "025a75c9d8bd315aa796b36ca69f793def2347483fbfd292e13bc90c02aeb3ab"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.26.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "b2c25d21e37c36f2eeeda1ea86bb505c",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 47118,
        "upload_time": "2020-04-02T04:51:36",
        "upload_time_iso_8601": "2020-04-02T04:51:36.639067Z",
        "url": "https://files.pythonhosted.org/packages/99/35/f60aa7d2086f1d6badb0b881464e6bd5737fde4dc8b048eee062844c51df/tokenizer_tools-0.26.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0cc68870b96fba04c36bc0e4688985275ec3383b6a1d8b924b233ee4d7c084e4",
          "md5": "fe7059edfc5dc3dab9f424f8a036f031",
          "sha256": "bbe23deec307e3cd0126e1e1949be47abfd3ac216c83d3a6ba2118aab750e39a"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.26.0.tar.gz",
        "has_sig": false,
        "md5_digest": "fe7059edfc5dc3dab9f424f8a036f031",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 51973,
        "upload_time": "2020-04-02T04:51:40",
        "upload_time_iso_8601": "2020-04-02T04:51:40.090288Z",
        "url": "https://files.pythonhosted.org/packages/0c/c6/8870b96fba04c36bc0e4688985275ec3383b6a1d8b924b233ee4d7c084e4/tokenizer_tools-0.26.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.27.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fb563b474fe14719d85d837ce0950418d47a6791a23b432f3c4af5451a4a0c96",
          "md5": "b5aa5837885676de8316bfd9622fe723",
          "sha256": "9779199c084ab22ec893222855628a39f6544cd559667bf8ea80b62426e273c4"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.27.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "b5aa5837885676de8316bfd9622fe723",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 46977,
        "upload_time": "2020-04-03T03:59:38",
        "upload_time_iso_8601": "2020-04-03T03:59:38.727683Z",
        "url": "https://files.pythonhosted.org/packages/fb/56/3b474fe14719d85d837ce0950418d47a6791a23b432f3c4af5451a4a0c96/tokenizer_tools-0.27.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d68e3c63e2ed126087ba6bc9c36a515baed8e5c166775eb64e13910aba1240fe",
          "md5": "32d98cd4dd15c84ac77913f806e6cc3e",
          "sha256": "cdba6fc7ff382a63e513c7990685567d4859d4a7ea84739db98826b5c10d91f6"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.27.0.tar.gz",
        "has_sig": false,
        "md5_digest": "32d98cd4dd15c84ac77913f806e6cc3e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 51928,
        "upload_time": "2020-04-03T03:59:40",
        "upload_time_iso_8601": "2020-04-03T03:59:40.433388Z",
        "url": "https://files.pythonhosted.org/packages/d6/8e/3c63e2ed126087ba6bc9c36a515baed8e5c166775eb64e13910aba1240fe/tokenizer_tools-0.27.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.28.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5137512eb34b0bf25f161f5c115c6c0fa7b98e0ca95a545637242c71d2b96020",
          "md5": "f88ed8dadbd012494a29ac28635c840d",
          "sha256": "832fe277245ed9925b914fd6baf3278a58263f324a8f7c97d5aba85b20e5f294"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.28.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f88ed8dadbd012494a29ac28635c840d",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 47163,
        "upload_time": "2020-04-04T17:25:27",
        "upload_time_iso_8601": "2020-04-04T17:25:27.773740Z",
        "url": "https://files.pythonhosted.org/packages/51/37/512eb34b0bf25f161f5c115c6c0fa7b98e0ca95a545637242c71d2b96020/tokenizer_tools-0.28.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c372e7172283c8e4afd5e740ae12b39b8a1e3f3d4b8cdae7397d374f3e0e0fa0",
          "md5": "505ca41e06b2e40be886b70fcd316b95",
          "sha256": "c1b7a300d5c9214c58848dd8d718ee395b9f9538c9e487f21f66c76c0402f282"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.28.0.tar.gz",
        "has_sig": false,
        "md5_digest": "505ca41e06b2e40be886b70fcd316b95",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 52010,
        "upload_time": "2020-04-04T17:25:29",
        "upload_time_iso_8601": "2020-04-04T17:25:29.303883Z",
        "url": "https://files.pythonhosted.org/packages/c3/72/e7172283c8e4afd5e740ae12b39b8a1e3f3d4b8cdae7397d374f3e0e0fa0/tokenizer_tools-0.28.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.29.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "553be0d91cc980f6fe1527d7d6793b04bd5ee33220d7f103f676efef51212be6",
          "md5": "edbc00deae1f7800da2827abf083d581",
          "sha256": "864bf7e925f97b1400f35fb4303d6a4e606df31ad5a5f75a59ff3d6410bf26df"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.29.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "edbc00deae1f7800da2827abf083d581",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 47477,
        "upload_time": "2020-04-07T16:32:50",
        "upload_time_iso_8601": "2020-04-07T16:32:50.778028Z",
        "url": "https://files.pythonhosted.org/packages/55/3b/e0d91cc980f6fe1527d7d6793b04bd5ee33220d7f103f676efef51212be6/tokenizer_tools-0.29.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "086cf2a759525ee3c49d0aa5bba77a7ad18af4b1d00748aea7fc096980d4126c",
          "md5": "e4a7aff58ca21d30b45bf1b4b9a1a097",
          "sha256": "9cf9f100cfb55c3f6d4f6f79a3893e5264dcb9c31a5ac3817226968c7163b15e"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.29.0.tar.gz",
        "has_sig": false,
        "md5_digest": "e4a7aff58ca21d30b45bf1b4b9a1a097",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 52158,
        "upload_time": "2020-04-07T16:32:52",
        "upload_time_iso_8601": "2020-04-07T16:32:52.722892Z",
        "url": "https://files.pythonhosted.org/packages/08/6c/f2a759525ee3c49d0aa5bba77a7ad18af4b1d00748aea7fc096980d4126c/tokenizer_tools-0.29.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "485c6df67cc576427bb97e100640d939015070ca8338c4981cef9b8e91310dbf",
          "md5": "6873862dde28eac2d15bedb7fade530b",
          "sha256": "efb0b7ab6b252863408d8d4ad6cc8278bc890b8cdd1a97e6a1824e2a60267ea5"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.3.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "6873862dde28eac2d15bedb7fade530b",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 4936,
        "upload_time": "2018-09-06T12:46:57",
        "upload_time_iso_8601": "2018-09-06T12:46:57.164613Z",
        "url": "https://files.pythonhosted.org/packages/48/5c/6df67cc576427bb97e100640d939015070ca8338c4981cef9b8e91310dbf/tokenizer_tools-0.3.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0c7b7835b1b54942b48cef6784e500da3d53a567d2a532c1d4aff83f5f9a7f93",
          "md5": "1670c0684ca4e531ed6a29aed36b0569",
          "sha256": "d111964b823e3dd18200c4ce4662bde1f2c10c0d467a1554f8fe9848e1a8b7f7"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.3.0.tar.gz",
        "has_sig": false,
        "md5_digest": "1670c0684ca4e531ed6a29aed36b0569",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 10085,
        "upload_time": "2018-09-06T12:46:58",
        "upload_time_iso_8601": "2018-09-06T12:46:58.744658Z",
        "url": "https://files.pythonhosted.org/packages/0c/7b/7835b1b54942b48cef6784e500da3d53a567d2a532c1d4aff83f5f9a7f93/tokenizer_tools-0.3.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6b71e7a9c6d999a7ef9350a7f0cc2fac4813b0e6d58c4f0aaee18f87cfc566eb",
          "md5": "6423bc0a5d34e2156a49d1b45da6fb36",
          "sha256": "740dc5bd020bf9ce7f5004e284c9723438df430ec5d7bd3ba4cfa85ad5808d16"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.3.1-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "6423bc0a5d34e2156a49d1b45da6fb36",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 8622,
        "upload_time": "2018-09-06T12:54:35",
        "upload_time_iso_8601": "2018-09-06T12:54:35.316519Z",
        "url": "https://files.pythonhosted.org/packages/6b/71/e7a9c6d999a7ef9350a7f0cc2fac4813b0e6d58c4f0aaee18f87cfc566eb/tokenizer_tools-0.3.1-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1e64ee762f0db9afd92df1eee996e5fb92090cfed5c5d2478db4c1bba425470c",
          "md5": "8372f7df183c58a0e38c2aa949d8e11e",
          "sha256": "21db1cc9cba24b00d3036bebcbdfb335f9910fc86df69df9e21e2b723530c91c"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.3.1.tar.gz",
        "has_sig": false,
        "md5_digest": "8372f7df183c58a0e38c2aa949d8e11e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 12100,
        "upload_time": "2018-09-06T12:54:36",
        "upload_time_iso_8601": "2018-09-06T12:54:36.932202Z",
        "url": "https://files.pythonhosted.org/packages/1e/64/ee762f0db9afd92df1eee996e5fb92090cfed5c5d2478db4c1bba425470c/tokenizer_tools-0.3.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bb8e3f3f57fcee53478629cd64db029ea4b82f42ac2d2a54efcf90af438f60c3",
          "md5": "3518499b3374a48d7217727ff2bc4e62",
          "sha256": "1118683650cb6e4975e771834982b535e9c0bb28a7a84973207a6e5a00ee923f"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.3.2-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "3518499b3374a48d7217727ff2bc4e62",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 8829,
        "upload_time": "2018-09-07T03:12:15",
        "upload_time_iso_8601": "2018-09-07T03:12:15.797264Z",
        "url": "https://files.pythonhosted.org/packages/bb/8e/3f3f57fcee53478629cd64db029ea4b82f42ac2d2a54efcf90af438f60c3/tokenizer_tools-0.3.2-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f87f003b5ec7b00c72764628a93d9e8753750e19823082df89755fa14e6139f3",
          "md5": "788390c14b34ebe934282d98c6e2ec50",
          "sha256": "952f51c4c564fe8e1aafa0bd8117359847f8c094b4d2f28b75e26ff684549a4b"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.3.2.tar.gz",
        "has_sig": false,
        "md5_digest": "788390c14b34ebe934282d98c6e2ec50",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 12447,
        "upload_time": "2018-09-07T03:12:17",
        "upload_time_iso_8601": "2018-09-07T03:12:17.524839Z",
        "url": "https://files.pythonhosted.org/packages/f8/7f/003b5ec7b00c72764628a93d9e8753750e19823082df89755fa14e6139f3/tokenizer_tools-0.3.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.30.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "38658201aedbcb90a3e2ddeb249543e6064ae696a9e5cfaa6cce4a17c2923bbf",
          "md5": "99f458ec37efc2dd6b8590782be9fd48",
          "sha256": "cdd7aeacb39cff6ef023b595b7f1861ca3c716860cca9bbf308a1cc28da5a0d4"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.30.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "99f458ec37efc2dd6b8590782be9fd48",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 43633,
        "upload_time": "2020-04-10T03:46:10",
        "upload_time_iso_8601": "2020-04-10T03:46:10.206372Z",
        "url": "https://files.pythonhosted.org/packages/38/65/8201aedbcb90a3e2ddeb249543e6064ae696a9e5cfaa6cce4a17c2923bbf/tokenizer_tools-0.30.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b02bbbc9eacdd10174ef30ca9c1854f1383fa20579b91e6a1432adffb5aa574b",
          "md5": "e205ad6851c7b85f73b2d44822a89f02",
          "sha256": "aee06f487fb399173c00583ebdec018aef90ce0a8010ee5c90ad11740e59233a"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.30.0.tar.gz",
        "has_sig": false,
        "md5_digest": "e205ad6851c7b85f73b2d44822a89f02",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 54001,
        "upload_time": "2020-04-10T03:46:12",
        "upload_time_iso_8601": "2020-04-10T03:46:12.584740Z",
        "url": "https://files.pythonhosted.org/packages/b0/2b/bbc9eacdd10174ef30ca9c1854f1383fa20579b91e6a1432adffb5aa574b/tokenizer_tools-0.30.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.31.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "56db6aad440e3c18d99b65aff551bbc2e294afbc4b7be8c9d4615efee6f60f9e",
          "md5": "0727daae6cae990fcd4f8db06f61a2f4",
          "sha256": "5175fedf95dcd81d065a11f9ebd21c813e4ee71873385065aa227875f4f2fb5d"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.31.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0727daae6cae990fcd4f8db06f61a2f4",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 43906,
        "upload_time": "2020-04-14T10:58:07",
        "upload_time_iso_8601": "2020-04-14T10:58:07.265373Z",
        "url": "https://files.pythonhosted.org/packages/56/db/6aad440e3c18d99b65aff551bbc2e294afbc4b7be8c9d4615efee6f60f9e/tokenizer_tools-0.31.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f62822523754b6f2f20935f9764dd9fe4f6c2c976f5dabf0a6398f097322bc2b",
          "md5": "bbc35eab12db0b706ddbb111d3f4237a",
          "sha256": "cb86477fc3be4081f7b59e156ef319968c7d7320cf1a2df85761cafdc0d12386"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.31.0.tar.gz",
        "has_sig": false,
        "md5_digest": "bbc35eab12db0b706ddbb111d3f4237a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 54229,
        "upload_time": "2020-04-14T10:58:09",
        "upload_time_iso_8601": "2020-04-14T10:58:09.150660Z",
        "url": "https://files.pythonhosted.org/packages/f6/28/22523754b6f2f20935f9764dd9fe4f6c2c976f5dabf0a6398f097322bc2b/tokenizer_tools-0.31.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.32.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5ef57177e9616031d62ff6a3f3f97a7c9c68ed9f2fdbd025821c6d275c7bbfa3",
          "md5": "424d6e7dd1da9f87862bd32a4a5b3535",
          "sha256": "75b3e59b77d03780a6e2e0a298a92ce21a114703d549d04f99222b4fee5c22d4"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.32.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "424d6e7dd1da9f87862bd32a4a5b3535",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 44418,
        "upload_time": "2020-04-16T03:34:16",
        "upload_time_iso_8601": "2020-04-16T03:34:16.639388Z",
        "url": "https://files.pythonhosted.org/packages/5e/f5/7177e9616031d62ff6a3f3f97a7c9c68ed9f2fdbd025821c6d275c7bbfa3/tokenizer_tools-0.32.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b59504f3184b1d98835c000aa4d1f8f3c696f4ac9e0361b368ca4a57d2d2bb7e",
          "md5": "a3254ced781f597a8273eaf2882ae3d6",
          "sha256": "a388e717cb95be6b02bf7c100f34f4d4ea1738f79c816ca052588f9631e01c50"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.32.0.tar.gz",
        "has_sig": false,
        "md5_digest": "a3254ced781f597a8273eaf2882ae3d6",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 56214,
        "upload_time": "2020-04-16T03:34:18",
        "upload_time_iso_8601": "2020-04-16T03:34:18.675235Z",
        "url": "https://files.pythonhosted.org/packages/b5/95/04f3184b1d98835c000aa4d1f8f3c696f4ac9e0361b368ca4a57d2d2bb7e/tokenizer_tools-0.32.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.33.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "aabb72b2e3924fc0fc4987cd48cc0d0dd0a15d7654e07c31381fcdec12dc2bd7",
          "md5": "de2616be2844e31234e5dc656eccb8c2",
          "sha256": "c4de6a865660a377840a7c8b14297391624df34816869440aa8806e8850b8b98"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.33.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "de2616be2844e31234e5dc656eccb8c2",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 44443,
        "upload_time": "2020-04-16T07:17:07",
        "upload_time_iso_8601": "2020-04-16T07:17:07.297873Z",
        "url": "https://files.pythonhosted.org/packages/aa/bb/72b2e3924fc0fc4987cd48cc0d0dd0a15d7654e07c31381fcdec12dc2bd7/tokenizer_tools-0.33.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d37a00e687dc7611b8672d593c3337bfb62740f108c036d34fe03e3bf3dfa04c",
          "md5": "5b9b566319fb28b1fc4b662bab893bb6",
          "sha256": "ac614730ab0906e317106612737838ad63ed2935a4a1f2cccc9fdd47cfe6939c"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.33.0.tar.gz",
        "has_sig": false,
        "md5_digest": "5b9b566319fb28b1fc4b662bab893bb6",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 56226,
        "upload_time": "2020-04-16T07:17:09",
        "upload_time_iso_8601": "2020-04-16T07:17:09.353629Z",
        "url": "https://files.pythonhosted.org/packages/d3/7a/00e687dc7611b8672d593c3337bfb62740f108c036d34fe03e3bf3dfa04c/tokenizer_tools-0.33.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.33.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "21b4123f5107bc5b9a6cb89c69ce6eba91593f67db9803d5525aac89f365e4fa",
          "md5": "608f56e160cc56c89c20c3abd12ee8da",
          "sha256": "e53b47d8135712f3f1d6cd472ebbda0e0897f2d439d79e15a569e74c72fb7cde"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.33.1-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "608f56e160cc56c89c20c3abd12ee8da",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 44445,
        "upload_time": "2020-04-16T07:25:48",
        "upload_time_iso_8601": "2020-04-16T07:25:48.625371Z",
        "url": "https://files.pythonhosted.org/packages/21/b4/123f5107bc5b9a6cb89c69ce6eba91593f67db9803d5525aac89f365e4fa/tokenizer_tools-0.33.1-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "dcce18ca02f9d71246751b1224f5b6bcd35a918a0dea2281319ee54c546ee8bd",
          "md5": "bc95e0d30aac625edea9549976c8e4f1",
          "sha256": "2a187c0e3d76f44b4ce3dbb2257481575a8478246ee199f43169963633973db0"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.33.1.tar.gz",
        "has_sig": false,
        "md5_digest": "bc95e0d30aac625edea9549976c8e4f1",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 56262,
        "upload_time": "2020-04-16T07:25:50",
        "upload_time_iso_8601": "2020-04-16T07:25:50.513735Z",
        "url": "https://files.pythonhosted.org/packages/dc/ce/18ca02f9d71246751b1224f5b6bcd35a918a0dea2281319ee54c546ee8bd/tokenizer_tools-0.33.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.33.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d56361efd9a89bc2a5190898c598f65ecc8631f67269189bf7caffce724c5865",
          "md5": "31ef2db2b21fe7a8a8631d81b43ad5ce",
          "sha256": "693e7ed7aa155f499e323f73665ec32a90d9463e36f6adcda5f30360816138fe"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.33.2-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "31ef2db2b21fe7a8a8631d81b43ad5ce",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 44442,
        "upload_time": "2020-04-16T08:12:17",
        "upload_time_iso_8601": "2020-04-16T08:12:17.498879Z",
        "url": "https://files.pythonhosted.org/packages/d5/63/61efd9a89bc2a5190898c598f65ecc8631f67269189bf7caffce724c5865/tokenizer_tools-0.33.2-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1cf5f6b5dc2ff901659d36cff0ac003a1fe30f47709f5335ab5a522a047376ea",
          "md5": "996a06aa5044a1fe02a963a0e03de4aa",
          "sha256": "6b12637f252bb25c16e662a50da352f67fb104c45a7c15a428166657dcf5d7ec"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.33.2.tar.gz",
        "has_sig": false,
        "md5_digest": "996a06aa5044a1fe02a963a0e03de4aa",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 56231,
        "upload_time": "2020-04-16T08:12:19",
        "upload_time_iso_8601": "2020-04-16T08:12:19.093652Z",
        "url": "https://files.pythonhosted.org/packages/1c/f5/f6b5dc2ff901659d36cff0ac003a1fe30f47709f5335ab5a522a047376ea/tokenizer_tools-0.33.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.34.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "900ddb17b48d7b0faa19a828f176e3cf941b305cdcd29a901374d4875ffcd0c2",
          "md5": "54e8374d5092185a8436161d375c430a",
          "sha256": "57b619ff2d11196bfd0175cc20fbd5b56d52b89bbd47bb340d0bfdb876e68d4b"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.34.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "54e8374d5092185a8436161d375c430a",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 45187,
        "upload_time": "2020-04-27T06:56:55",
        "upload_time_iso_8601": "2020-04-27T06:56:55.930328Z",
        "url": "https://files.pythonhosted.org/packages/90/0d/db17b48d7b0faa19a828f176e3cf941b305cdcd29a901374d4875ffcd0c2/tokenizer_tools-0.34.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "22760677644a35c6462ba65fc0560a4b605c8a2e441064918234423d81265623",
          "md5": "0c7db256acfab63c9ef6773e47e7b289",
          "sha256": "952a40dd075ed8dbb1d8d23cdf793034abfc2847a9c9364968c560610c86b723"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.34.0.tar.gz",
        "has_sig": false,
        "md5_digest": "0c7db256acfab63c9ef6773e47e7b289",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 56764,
        "upload_time": "2020-04-27T06:56:57",
        "upload_time_iso_8601": "2020-04-27T06:56:57.885484Z",
        "url": "https://files.pythonhosted.org/packages/22/76/0677644a35c6462ba65fc0560a4b605c8a2e441064918234423d81265623/tokenizer_tools-0.34.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.35.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "47d7e87c8263524069bf81d4644b94669c72106aa257bf2281765e787c5c8601",
          "md5": "fdeca374fe01485ef7da16bfba1706fc",
          "sha256": "e8baeaad5095868bbc28f602ae50c9e1892172a65c56257b5ee912e83a76d74a"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.35.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "fdeca374fe01485ef7da16bfba1706fc",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 44978,
        "upload_time": "2020-05-04T04:19:17",
        "upload_time_iso_8601": "2020-05-04T04:19:17.294579Z",
        "url": "https://files.pythonhosted.org/packages/47/d7/e87c8263524069bf81d4644b94669c72106aa257bf2281765e787c5c8601/tokenizer_tools-0.35.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "83d2e25d8a4ce9c506657644cc48de98bb6b82e419d31edefe673ea85eaafb54",
          "md5": "33879bbf374b34d18f57e659bbba6060",
          "sha256": "4c6bb23fdc91c2b85fb3e69b2a1fbb73ea79eb476c3182cf771bf9f3958ba0b4"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.35.0.tar.gz",
        "has_sig": false,
        "md5_digest": "33879bbf374b34d18f57e659bbba6060",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 56628,
        "upload_time": "2020-05-04T04:19:19",
        "upload_time_iso_8601": "2020-05-04T04:19:19.198526Z",
        "url": "https://files.pythonhosted.org/packages/83/d2/e25d8a4ce9c506657644cc48de98bb6b82e419d31edefe673ea85eaafb54/tokenizer_tools-0.35.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.36.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d7c9fdc3f7cb37082154fdca17a32a2fb1ab7fd87f79f0dfa696d72a85418722",
          "md5": "871c266377b1b4c7614c0deba3c1a340",
          "sha256": "a405bdbe25e363e44d3f5ead4020c6716f44f223040d1c6e1d80a878d8821f35"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.36.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "871c266377b1b4c7614c0deba3c1a340",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 45138,
        "upload_time": "2020-05-07T11:16:03",
        "upload_time_iso_8601": "2020-05-07T11:16:03.634230Z",
        "url": "https://files.pythonhosted.org/packages/d7/c9/fdc3f7cb37082154fdca17a32a2fb1ab7fd87f79f0dfa696d72a85418722/tokenizer_tools-0.36.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c0b48491e7d3859795a240fe63ff6536edf2e4accf677d2cd968eaa40c92306c",
          "md5": "9c824f55b83297e6341469d7cd6fd160",
          "sha256": "b25c41aafb4cedd71bfb447cfac22c9d9a1d12d27ec6bb7fd5a2c76c6f1e2ca6"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.36.0.tar.gz",
        "has_sig": false,
        "md5_digest": "9c824f55b83297e6341469d7cd6fd160",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 56893,
        "upload_time": "2020-05-07T11:16:05",
        "upload_time_iso_8601": "2020-05-07T11:16:05.639822Z",
        "url": "https://files.pythonhosted.org/packages/c0/b4/8491e7d3859795a240fe63ff6536edf2e4accf677d2cd968eaa40c92306c/tokenizer_tools-0.36.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.36.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6b69097d7e889506b7e2569e43e07ebe13460575950ffb6a1362d7ba8cbe54ea",
          "md5": "5314e43372a41407228652eda567f4f8",
          "sha256": "ce1f2ff98fa3b2cf9597eec7fab604eb8bf3bce2bd1b43eaadfdeed26e43353c"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.36.1-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "5314e43372a41407228652eda567f4f8",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 46379,
        "upload_time": "2020-05-13T06:49:48",
        "upload_time_iso_8601": "2020-05-13T06:49:48.791617Z",
        "url": "https://files.pythonhosted.org/packages/6b/69/097d7e889506b7e2569e43e07ebe13460575950ffb6a1362d7ba8cbe54ea/tokenizer_tools-0.36.1-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "841e30f1f0b472ef6f4bd6260d0657e85eab7aa8d1d5117c78b6936a6d6008ae",
          "md5": "e22ba5a59080d6dacfda7b1e8301b3e9",
          "sha256": "df6a94dc1e3624c762953d8eb3efa1becb306990187b8dac5aa6bf47f64affa2"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.36.1.tar.gz",
        "has_sig": false,
        "md5_digest": "e22ba5a59080d6dacfda7b1e8301b3e9",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 57375,
        "upload_time": "2020-05-13T06:49:51",
        "upload_time_iso_8601": "2020-05-13T06:49:51.083914Z",
        "url": "https://files.pythonhosted.org/packages/84/1e/30f1f0b472ef6f4bd6260d0657e85eab7aa8d1d5117c78b6936a6d6008ae/tokenizer_tools-0.36.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.36.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "285f5c5ef477332ae655764ef4ddbda2d4fb6b4c5c2336dcf8c4501bb6f5f759",
          "md5": "e00a3c144b7a2ef10ace9d16ba4e407c",
          "sha256": "4cf2b59a0a87a7a2278843c2909e25fdd43090425f8614eb794b2723a3f01de9"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.36.2-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "e00a3c144b7a2ef10ace9d16ba4e407c",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 46381,
        "upload_time": "2020-05-13T07:11:16",
        "upload_time_iso_8601": "2020-05-13T07:11:16.393769Z",
        "url": "https://files.pythonhosted.org/packages/28/5f/5c5ef477332ae655764ef4ddbda2d4fb6b4c5c2336dcf8c4501bb6f5f759/tokenizer_tools-0.36.2-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "26373c63a636934919cb5491b1d4949cb77f33ec383c156b79387fc35edd4622",
          "md5": "7fe654088b5ca05cfe3e968100f8ffbe",
          "sha256": "9570f8f8fccb2c3c57348e198d697f619cd5b2553d12d9d584919e0da6996faa"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.36.2.tar.gz",
        "has_sig": false,
        "md5_digest": "7fe654088b5ca05cfe3e968100f8ffbe",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 57396,
        "upload_time": "2020-05-13T07:11:18",
        "upload_time_iso_8601": "2020-05-13T07:11:18.158285Z",
        "url": "https://files.pythonhosted.org/packages/26/37/3c63a636934919cb5491b1d4949cb77f33ec383c156b79387fc35edd4622/tokenizer_tools-0.36.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.37.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f820959088b27967da4049611d9e0d5279ba7b5d187635d523584c700fe43287",
          "md5": "94035f2d169bdb5f4ba2ceba8f7ead6b",
          "sha256": "29b2a47364d9823108e3e126e6197ec2e51fb5a5af5b64503f4f4435d6e3770b"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.37.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "94035f2d169bdb5f4ba2ceba8f7ead6b",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 47513,
        "upload_time": "2020-05-18T03:19:39",
        "upload_time_iso_8601": "2020-05-18T03:19:39.122635Z",
        "url": "https://files.pythonhosted.org/packages/f8/20/959088b27967da4049611d9e0d5279ba7b5d187635d523584c700fe43287/tokenizer_tools-0.37.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a1583a6faa6ebd6a0abdc64aec5d237b00bdc8b8a4b6e5364c78b1328132e5d8",
          "md5": "06491e46de57d08133527a2dd28d9792",
          "sha256": "ec7896096378a9c43da90fe24c5757da15e559927e5babff251ea4d473a7c4f3"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.37.0.tar.gz",
        "has_sig": false,
        "md5_digest": "06491e46de57d08133527a2dd28d9792",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 58418,
        "upload_time": "2020-05-18T03:19:41",
        "upload_time_iso_8601": "2020-05-18T03:19:41.125882Z",
        "url": "https://files.pythonhosted.org/packages/a1/58/3a6faa6ebd6a0abdc64aec5d237b00bdc8b8a4b6e5364c78b1328132e5d8/tokenizer_tools-0.37.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.38.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "07ec46addd45e57388f75dcc42252ae4d19bf6f0128bd10e9fa84fba0df13aa7",
          "md5": "89a0a8fa407be9ec976a3bc8a589f0aa",
          "sha256": "62aad37916a7bc57f19379d3aaa62b23d2270b31de92c54324a5998620297bce"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.38.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "89a0a8fa407be9ec976a3bc8a589f0aa",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 47327,
        "upload_time": "2020-06-22T03:32:21",
        "upload_time_iso_8601": "2020-06-22T03:32:21.166461Z",
        "url": "https://files.pythonhosted.org/packages/07/ec/46addd45e57388f75dcc42252ae4d19bf6f0128bd10e9fa84fba0df13aa7/tokenizer_tools-0.38.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0a5392ccc9572a477516418ca188c39f2a2b582773485acb8e0362a9a5877524",
          "md5": "fcf2eb1d452c6e1c489dbd2858e86ef5",
          "sha256": "68384327227385dc2ec65e2bda1acd4bc6f9cb8a5b9ad1a6ed0e535c83c60fa4"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.38.0.tar.gz",
        "has_sig": false,
        "md5_digest": "fcf2eb1d452c6e1c489dbd2858e86ef5",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 58232,
        "upload_time": "2020-06-22T03:32:22",
        "upload_time_iso_8601": "2020-06-22T03:32:22.865392Z",
        "url": "https://files.pythonhosted.org/packages/0a/53/92ccc9572a477516418ca188c39f2a2b582773485acb8e0362a9a5877524/tokenizer_tools-0.38.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.39.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9b549c489c8d6542eb324bb8bceef4d7bb17071a848fe71196b17acb7af60317",
          "md5": "cebd658b5c78b186d0ddff5bd9275a32",
          "sha256": "e99972a2fb1d0887ebc61ade8fb3b429807db7e9d996f3b465b2a32886eca91e"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.39.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "cebd658b5c78b186d0ddff5bd9275a32",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 50036,
        "upload_time": "2020-07-17T11:31:39",
        "upload_time_iso_8601": "2020-07-17T11:31:39.884860Z",
        "url": "https://files.pythonhosted.org/packages/9b/54/9c489c8d6542eb324bb8bceef4d7bb17071a848fe71196b17acb7af60317/tokenizer_tools-0.39.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0010f50b97a86ef529473d968d0a2a71ff75b42ec3695bf93cb0768ee43cb40b",
          "md5": "df9750a84c011559e23cae7a420e4db3",
          "sha256": "9c212fe59b014273b85109ccaaa9f6c94f43ab5b18dc68db7b8cda076591cff6"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.39.0.tar.gz",
        "has_sig": false,
        "md5_digest": "df9750a84c011559e23cae7a420e4db3",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 61420,
        "upload_time": "2020-07-17T11:31:41",
        "upload_time_iso_8601": "2020-07-17T11:31:41.856957Z",
        "url": "https://files.pythonhosted.org/packages/00/10/f50b97a86ef529473d968d0a2a71ff75b42ec3695bf93cb0768ee43cb40b/tokenizer_tools-0.39.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3ee728057308b5337ca4402af808fc46eaddc611c4397bc66ed86b0dc4edc31a",
          "md5": "fc3808d94f077cce2d3974011380b3b0",
          "sha256": "4bd028c9ca70630ba88a8014b3af24a7aad0a363de3ed3eab8c598973af82977"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.4.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "fc3808d94f077cce2d3974011380b3b0",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 9806,
        "upload_time": "2018-09-10T08:06:58",
        "upload_time_iso_8601": "2018-09-10T08:06:58.195919Z",
        "url": "https://files.pythonhosted.org/packages/3e/e7/28057308b5337ca4402af808fc46eaddc611c4397bc66ed86b0dc4edc31a/tokenizer_tools-0.4.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "46f6c76962beaa03d1070812902a7631523adecb72980e967b977f40a28328fe",
          "md5": "b228b1c21acbe417f1b4678f3571811a",
          "sha256": "b345c3093ae209f37b6df6e652df4aeb2460fe5a9e34de77adf6f12941c0e6e8"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.4.0.tar.gz",
        "has_sig": false,
        "md5_digest": "b228b1c21acbe417f1b4678f3571811a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 12893,
        "upload_time": "2018-09-10T08:07:00",
        "upload_time_iso_8601": "2018-09-10T08:07:00.287375Z",
        "url": "https://files.pythonhosted.org/packages/46/f6/c76962beaa03d1070812902a7631523adecb72980e967b977f40a28328fe/tokenizer_tools-0.4.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3859d9125c06510b853654f116f09fa4254a496274043e9799088e4aecc32cfb",
          "md5": "e1b3769343e10985100424138c27b4a3",
          "sha256": "5a5c3153bc94d6dacd05d46b84c04263024d20abe8da08c806cd71b579b7939b"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.4.1-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "e1b3769343e10985100424138c27b4a3",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 9812,
        "upload_time": "2018-09-10T09:01:58",
        "upload_time_iso_8601": "2018-09-10T09:01:58.778506Z",
        "url": "https://files.pythonhosted.org/packages/38/59/d9125c06510b853654f116f09fa4254a496274043e9799088e4aecc32cfb/tokenizer_tools-0.4.1-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "29f6c38e6322a5193e06a08f59d554476e6c9c1923107bbdbe862b17d8281f46",
          "md5": "bbe55b1e899f6062a29d21eb921953b7",
          "sha256": "e4854f744cdc0ff496202435cc4ab88a0e6897cec4001551eb2b7a92a26beaa0"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.4.1.tar.gz",
        "has_sig": false,
        "md5_digest": "bbe55b1e899f6062a29d21eb921953b7",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 12904,
        "upload_time": "2018-09-10T09:02:00",
        "upload_time_iso_8601": "2018-09-10T09:02:00.682026Z",
        "url": "https://files.pythonhosted.org/packages/29/f6/c38e6322a5193e06a08f59d554476e6c9c1923107bbdbe862b17d8281f46/tokenizer_tools-0.4.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "45a6b42bf7658a95594e8187d3be3334a16dac1b0de19c3e74a19d77b82f7bd5",
          "md5": "7d92c086a37e6154c7eadd4157f73db1",
          "sha256": "068d1d7a36b13a0c4d30295805864a83d9eb6e69c0af5d779db7ae446f045c53"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.4.2-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "7d92c086a37e6154c7eadd4157f73db1",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 9818,
        "upload_time": "2018-09-10T09:40:16",
        "upload_time_iso_8601": "2018-09-10T09:40:16.385873Z",
        "url": "https://files.pythonhosted.org/packages/45/a6/b42bf7658a95594e8187d3be3334a16dac1b0de19c3e74a19d77b82f7bd5/tokenizer_tools-0.4.2-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "01c86c3a65570ba721d00cfbbda7501f9ee68985da70282f6ed1daf55a437a0a",
          "md5": "dd312e46715c098ffa22442dff785214",
          "sha256": "7b89dea46843109eca000af58b3b4a60671dd0afb20e58bbd703d43a78ac5783"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.4.2.tar.gz",
        "has_sig": false,
        "md5_digest": "dd312e46715c098ffa22442dff785214",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 12902,
        "upload_time": "2018-09-10T09:40:18",
        "upload_time_iso_8601": "2018-09-10T09:40:18.553191Z",
        "url": "https://files.pythonhosted.org/packages/01/c8/6c3a65570ba721d00cfbbda7501f9ee68985da70282f6ed1daf55a437a0a/tokenizer_tools-0.4.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.40.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "12c2d46f8fd4cff13a9d238221ae33a0d449618c2291d8a80f3ea9f083b51c8e",
          "md5": "677dfc515a59234b027cf0e33ec87fc0",
          "sha256": "10d81e533abc13460d38882428516042b2f5a61cd8ee1ff7ed1849e211f55e88"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.40.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "677dfc515a59234b027cf0e33ec87fc0",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 50522,
        "upload_time": "2020-07-17T13:56:52",
        "upload_time_iso_8601": "2020-07-17T13:56:52.968339Z",
        "url": "https://files.pythonhosted.org/packages/12/c2/d46f8fd4cff13a9d238221ae33a0d449618c2291d8a80f3ea9f083b51c8e/tokenizer_tools-0.40.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8bcf9e0b388a2c1e47e22e51c03bf0f1ea89fa7911b39c79c8079ba153b3820f",
          "md5": "5137733c025f19e3574414d1ec7686ab",
          "sha256": "dc7502b0d7e0532fa53ca099470ce4f0738462b49468d9d082c8cefd05820235"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.40.0.tar.gz",
        "has_sig": false,
        "md5_digest": "5137733c025f19e3574414d1ec7686ab",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 61978,
        "upload_time": "2020-07-17T13:56:54",
        "upload_time_iso_8601": "2020-07-17T13:56:54.653794Z",
        "url": "https://files.pythonhosted.org/packages/8b/cf/9e0b388a2c1e47e22e51c03bf0f1ea89fa7911b39c79c8079ba153b3820f/tokenizer_tools-0.40.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.41.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d168c17f5ccd03b7c21f8c7a076436fa513a581c6ea052379618250cd67fee7b",
          "md5": "dc4ce61e20712b973d361d73bc5b944b",
          "sha256": "bb3ec6daab73f9a22b72a8a03f2a61d1ae49130fc01799f03888ab7497b8bf3a"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.41.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "dc4ce61e20712b973d361d73bc5b944b",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 53219,
        "upload_time": "2020-07-27T07:16:34",
        "upload_time_iso_8601": "2020-07-27T07:16:34.198778Z",
        "url": "https://files.pythonhosted.org/packages/d1/68/c17f5ccd03b7c21f8c7a076436fa513a581c6ea052379618250cd67fee7b/tokenizer_tools-0.41.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9509aeb73c45c9f97e3079b5d29005cbaff7282490a95b14a263ce8789e3c9db",
          "md5": "ea68eded688d54edbbb80d9114894500",
          "sha256": "772fcac36a63ddf29612be99446dd30f876fcb0f6a4b991ade68b05a9c60dccd"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.41.0.tar.gz",
        "has_sig": false,
        "md5_digest": "ea68eded688d54edbbb80d9114894500",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 62899,
        "upload_time": "2020-07-27T07:16:36",
        "upload_time_iso_8601": "2020-07-27T07:16:36.144077Z",
        "url": "https://files.pythonhosted.org/packages/95/09/aeb73c45c9f97e3079b5d29005cbaff7282490a95b14a263ce8789e3c9db/tokenizer_tools-0.41.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.42.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "58c7b34bb0864656b68f3949ea4f29deeaf117e53da690ecfe28757c5c5c156d",
          "md5": "72b85375d24e9069aea775f4c64476ac",
          "sha256": "28294d5cdf5a90423e76ab3b37836e4375e7a4745e1f62a57b3f6ed9d7a1fd19"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.42.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "72b85375d24e9069aea775f4c64476ac",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 54234,
        "upload_time": "2020-08-07T06:51:58",
        "upload_time_iso_8601": "2020-08-07T06:51:58.469386Z",
        "url": "https://files.pythonhosted.org/packages/58/c7/b34bb0864656b68f3949ea4f29deeaf117e53da690ecfe28757c5c5c156d/tokenizer_tools-0.42.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4ca78182d611ba6b5a74606bab5360757299d2cd6791c1b784b179136f143ebf",
          "md5": "248c1c3f4e10d1a65c15d40faa598aa8",
          "sha256": "75b2f99498661bd96b96ef26b8820570cb0221cee76c78a72816e0b7b706ea76"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.42.0.tar.gz",
        "has_sig": false,
        "md5_digest": "248c1c3f4e10d1a65c15d40faa598aa8",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 63485,
        "upload_time": "2020-08-07T06:52:00",
        "upload_time_iso_8601": "2020-08-07T06:52:00.608372Z",
        "url": "https://files.pythonhosted.org/packages/4c/a7/8182d611ba6b5a74606bab5360757299d2cd6791c1b784b179136f143ebf/tokenizer_tools-0.42.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.43.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c586f0352078bcc9ef0b0dd9e46000faf6aaecc96b1b9cfcb576d324b4a7cf56",
          "md5": "74e53b991dc548ab0cffb9fdf0ad5a57",
          "sha256": "e7f403cfb9664b02de1b65952385e11502e9e61ce9b2fc8b9c51b16f4fcfba22"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.43.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "74e53b991dc548ab0cffb9fdf0ad5a57",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 54720,
        "upload_time": "2020-08-07T13:42:51",
        "upload_time_iso_8601": "2020-08-07T13:42:51.737513Z",
        "url": "https://files.pythonhosted.org/packages/c5/86/f0352078bcc9ef0b0dd9e46000faf6aaecc96b1b9cfcb576d324b4a7cf56/tokenizer_tools-0.43.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "900d8c825f0c48323c8a3cbd9cb745deae82e5f64785b02143498e1d81086c1f",
          "md5": "933c7ed8f610fbf83b9a29eb39ad5f8c",
          "sha256": "3033649f89518aa85eb99bb40d544d447d116791fac0de34c03a9b2f34fdbdff"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.43.0.tar.gz",
        "has_sig": false,
        "md5_digest": "933c7ed8f610fbf83b9a29eb39ad5f8c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 64207,
        "upload_time": "2020-08-07T13:42:53",
        "upload_time_iso_8601": "2020-08-07T13:42:53.591379Z",
        "url": "https://files.pythonhosted.org/packages/90/0d/8c825f0c48323c8a3cbd9cb745deae82e5f64785b02143498e1d81086c1f/tokenizer_tools-0.43.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.44.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c1bd5696e10787fe8d9de643174866cbfd45be32923c56f7b04318667468c7ba",
          "md5": "18275d429e0906cc380cf51defecd3fb",
          "sha256": "0618bd8357c739c90d8cfde343bcc6c73192854eed4eca5e98755aee9693537e"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.44.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "18275d429e0906cc380cf51defecd3fb",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 54530,
        "upload_time": "2020-08-10T01:48:50",
        "upload_time_iso_8601": "2020-08-10T01:48:50.248820Z",
        "url": "https://files.pythonhosted.org/packages/c1/bd/5696e10787fe8d9de643174866cbfd45be32923c56f7b04318667468c7ba/tokenizer_tools-0.44.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a321cc64160b6f1211ba81fa996ff6072950f7dc30104c697bc9334e41173870",
          "md5": "c8fb6e34694a4d042ac5ba1af89cf8e0",
          "sha256": "8f815affbbc5d967416edc02dc2bde55fd7a712c2cdd5714b0764c55437b742a"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.44.0.tar.gz",
        "has_sig": false,
        "md5_digest": "c8fb6e34694a4d042ac5ba1af89cf8e0",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 64402,
        "upload_time": "2020-08-10T01:48:52",
        "upload_time_iso_8601": "2020-08-10T01:48:52.252068Z",
        "url": "https://files.pythonhosted.org/packages/a3/21/cc64160b6f1211ba81fa996ff6072950f7dc30104c697bc9334e41173870/tokenizer_tools-0.44.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.44.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9b88b3181c5c9bddce04160b45e1a9231bce6a2511d424e304e2b8e135ddb685",
          "md5": "448a22b8aef36064b86fc704a22d220e",
          "sha256": "2fa7c1b5f949b8b526df617f817ff32c8b8a31eb2dcd2ad1051570ff69054923"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.44.1-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "448a22b8aef36064b86fc704a22d220e",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 54518,
        "upload_time": "2020-09-22T12:57:57",
        "upload_time_iso_8601": "2020-09-22T12:57:57.402782Z",
        "url": "https://files.pythonhosted.org/packages/9b/88/b3181c5c9bddce04160b45e1a9231bce6a2511d424e304e2b8e135ddb685/tokenizer_tools-0.44.1-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "96ab63d5884db39394d1742bd74ba9869cb6287fec43ed44b1df435da02890de",
          "md5": "e00101b6fb7ba835ce26f17095f6b29e",
          "sha256": "cd1decbc6476dabc39bccc7a1dbc8557f616f961efc459e113456ac0950319fd"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.44.1.tar.gz",
        "has_sig": false,
        "md5_digest": "e00101b6fb7ba835ce26f17095f6b29e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 59479,
        "upload_time": "2020-09-22T12:57:59",
        "upload_time_iso_8601": "2020-09-22T12:57:59.902794Z",
        "url": "https://files.pythonhosted.org/packages/96/ab/63d5884db39394d1742bd74ba9869cb6287fec43ed44b1df435da02890de/tokenizer_tools-0.44.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.45.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "47ce45d9d74d16ad066fd9711f105fec2c95ccd6496eb70098e6db79df5a60c7",
          "md5": "0673dd5330693e5d98a4df9fc5fc26a7",
          "sha256": "d97fa02a948cfb54db5fe5ad8a94c07e810ceb153bf0a8842c5157db5d4da4f7"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.45.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0673dd5330693e5d98a4df9fc5fc26a7",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 65915,
        "upload_time": "2020-09-04T02:50:22",
        "upload_time_iso_8601": "2020-09-04T02:50:22.142788Z",
        "url": "https://files.pythonhosted.org/packages/47/ce/45d9d74d16ad066fd9711f105fec2c95ccd6496eb70098e6db79df5a60c7/tokenizer_tools-0.45.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8143c402bb943993ffe439f153616bf0c8f3463c7491813237dd48d3b4af792f",
          "md5": "3c428952987c026ccfe390a6f1ef8667",
          "sha256": "c7aaa94520c89656cbad90e9ca765fc8693faf272b072d21f25eab0c1c74d398"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.45.0.tar.gz",
        "has_sig": false,
        "md5_digest": "3c428952987c026ccfe390a6f1ef8667",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 72813,
        "upload_time": "2020-09-04T02:50:24",
        "upload_time_iso_8601": "2020-09-04T02:50:24.148210Z",
        "url": "https://files.pythonhosted.org/packages/81/43/c402bb943993ffe439f153616bf0c8f3463c7491813237dd48d3b4af792f/tokenizer_tools-0.45.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.46.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c12411399caefb686dda438a74ebf6cdf654bcf33b1bb0ce47b1dee27d14cfb5",
          "md5": "f68ec9a367c68732e183f682acd8a943",
          "sha256": "e42be339e509572372c6b29d8845dd1273a7ebbfd0e7b79aa08d9a3debf54389"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.46.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f68ec9a367c68732e183f682acd8a943",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 65953,
        "upload_time": "2020-09-04T03:19:06",
        "upload_time_iso_8601": "2020-09-04T03:19:06.782079Z",
        "url": "https://files.pythonhosted.org/packages/c1/24/11399caefb686dda438a74ebf6cdf654bcf33b1bb0ce47b1dee27d14cfb5/tokenizer_tools-0.46.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e21776e88d287617522c7fb411a25df76eb3be7f95f07ee9a1be7209ef33c1e7",
          "md5": "b1e8ee0e0c0e5e9e07dd94fd3e5a54ad",
          "sha256": "04bb4ab2cb884c7a588e798bba3c6771c8da09f5add7a84b4548dd4bcd27dabf"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.46.0.tar.gz",
        "has_sig": false,
        "md5_digest": "b1e8ee0e0c0e5e9e07dd94fd3e5a54ad",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 72938,
        "upload_time": "2020-09-04T03:19:08",
        "upload_time_iso_8601": "2020-09-04T03:19:08.723551Z",
        "url": "https://files.pythonhosted.org/packages/e2/17/76e88d287617522c7fb411a25df76eb3be7f95f07ee9a1be7209ef33c1e7/tokenizer_tools-0.46.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.46.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "93851f5bd5df02cfc4a7d7edd7d4a9b62a29f092e64f6660fbe159337569196f",
          "md5": "0a41f9fbf963caa4bd2c9af3e6986bb7",
          "sha256": "e73d27f575e357202272ab68a9b3e6cbec32bc3aae8268d537ab090bdebf74bb"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.46.1-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0a41f9fbf963caa4bd2c9af3e6986bb7",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 69243,
        "upload_time": "2020-09-22T13:17:46",
        "upload_time_iso_8601": "2020-09-22T13:17:46.294003Z",
        "url": "https://files.pythonhosted.org/packages/93/85/1f5bd5df02cfc4a7d7edd7d4a9b62a29f092e64f6660fbe159337569196f/tokenizer_tools-0.46.1-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a1ec56971a0b4adb6286713ab6dc85792d87dafd544e58367e678f6baaf49f2f",
          "md5": "89877fda9a5612e2a6ed0cc689276361",
          "sha256": "7bdfe8249b3422b77e2fe798d2ef38e05283c229834e79a12bdd8784d759733a"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.46.1.tar.gz",
        "has_sig": false,
        "md5_digest": "89877fda9a5612e2a6ed0cc689276361",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 69810,
        "upload_time": "2020-09-22T13:17:48",
        "upload_time_iso_8601": "2020-09-22T13:17:48.618779Z",
        "url": "https://files.pythonhosted.org/packages/a1/ec/56971a0b4adb6286713ab6dc85792d87dafd544e58367e678f6baaf49f2f/tokenizer_tools-0.46.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.5.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "342661e5f688ccb3924f08b3392efb97d67bdc268f76b1cdb7e8cdf65a623389",
          "md5": "309bfa4887621c7be0d73d1bc8faa205",
          "sha256": "6031802f708f13438f8f36fb18fd5d86df13b5f12b960405a2a84187906e460f"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.5.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "309bfa4887621c7be0d73d1bc8faa205",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 9851,
        "upload_time": "2018-09-11T03:32:00",
        "upload_time_iso_8601": "2018-09-11T03:32:00.346412Z",
        "url": "https://files.pythonhosted.org/packages/34/26/61e5f688ccb3924f08b3392efb97d67bdc268f76b1cdb7e8cdf65a623389/tokenizer_tools-0.5.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a4e5e6d45718b4a2b7edb7a9c6cdce164e3432e73ef1c6c10001ef7d9fd00f4b",
          "md5": "0233756492a325de545f40632dd74c23",
          "sha256": "19afbd7c88ddfd98508aa2c44701197bfb3fd44082ed1dd84b0861c7f512bcdd"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.5.0.tar.gz",
        "has_sig": false,
        "md5_digest": "0233756492a325de545f40632dd74c23",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 12942,
        "upload_time": "2018-09-11T03:32:04",
        "upload_time_iso_8601": "2018-09-11T03:32:04.629690Z",
        "url": "https://files.pythonhosted.org/packages/a4/e5/e6d45718b4a2b7edb7a9c6cdce164e3432e73ef1c6c10001ef7d9fd00f4b/tokenizer_tools-0.5.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.6.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8b9810c32941481690644fb22744786dee03bf6f64f513fd96ef5a5f213a5c1c",
          "md5": "1d547f4efed52504d1d5d897a88beb42",
          "sha256": "3a017ab160cedc5e61bec8e68f4a79397e1e1707c85d7c6e4056cabab46c4692"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.6.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "1d547f4efed52504d1d5d897a88beb42",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 12981,
        "upload_time": "2018-09-13T08:09:39",
        "upload_time_iso_8601": "2018-09-13T08:09:39.012067Z",
        "url": "https://files.pythonhosted.org/packages/8b/98/10c32941481690644fb22744786dee03bf6f64f513fd96ef5a5f213a5c1c/tokenizer_tools-0.6.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a2b7fe38a6e639bd23edc35c9048d22b09d303f3b6dddc92b88174bcb3a9c2cc",
          "md5": "61c2e002a918da1ba13191397929d997",
          "sha256": "3710e50327da1b3c598c870820947fab613945897fd99682141a8ad24f69fa94"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.6.0.tar.gz",
        "has_sig": false,
        "md5_digest": "61c2e002a918da1ba13191397929d997",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 14637,
        "upload_time": "2018-09-13T08:09:41",
        "upload_time_iso_8601": "2018-09-13T08:09:41.078478Z",
        "url": "https://files.pythonhosted.org/packages/a2/b7/fe38a6e639bd23edc35c9048d22b09d303f3b6dddc92b88174bcb3a9c2cc/tokenizer_tools-0.6.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.7.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "733136a4f7dab92cd0411733693af99a493d09e817039d7dc152ceaf6012f97e",
          "md5": "1272adddc6ef5b2ee1eab9dd2db6f8db",
          "sha256": "b861ca55c25aa78ffc09465a868aa5554593ca335d19e05b043555aa1989729f"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.7.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "1272adddc6ef5b2ee1eab9dd2db6f8db",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 13547,
        "upload_time": "2018-09-19T07:11:03",
        "upload_time_iso_8601": "2018-09-19T07:11:03.641684Z",
        "url": "https://files.pythonhosted.org/packages/73/31/36a4f7dab92cd0411733693af99a493d09e817039d7dc152ceaf6012f97e/tokenizer_tools-0.7.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "31c47ea66b5b15bcc43f0b73f363397366ac881b4aba402e7db6f35e258e634d",
          "md5": "b48fd2ede9dc0271fd7cdc94b0de8b37",
          "sha256": "b81725efd7d48095f6ec56e05e7c0ff77c796d96f73d4abb0168ee5733a0c705"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.7.0.tar.gz",
        "has_sig": false,
        "md5_digest": "b48fd2ede9dc0271fd7cdc94b0de8b37",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 14862,
        "upload_time": "2018-09-19T07:11:05",
        "upload_time_iso_8601": "2018-09-19T07:11:05.839052Z",
        "url": "https://files.pythonhosted.org/packages/31/c4/7ea66b5b15bcc43f0b73f363397366ac881b4aba402e7db6f35e258e634d/tokenizer_tools-0.7.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.7.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e7463aa3cb5c846be4c559dfe58ddc4a6cac4960d2847a8ffcabf8c65193fa67",
          "md5": "b4cef43d108403c8560ac9f69cf7e47d",
          "sha256": "b9f809086708212c02669dd20127f780c419a8a4fcf5fa07d96d029cc4b15560"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.7.1-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "b4cef43d108403c8560ac9f69cf7e47d",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 13555,
        "upload_time": "2018-09-19T07:40:57",
        "upload_time_iso_8601": "2018-09-19T07:40:57.998637Z",
        "url": "https://files.pythonhosted.org/packages/e7/46/3aa3cb5c846be4c559dfe58ddc4a6cac4960d2847a8ffcabf8c65193fa67/tokenizer_tools-0.7.1-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "532ec6009775fdf07e0fcf3af5cc79388e71f583f807aa755cf262ef4bcf2cf0",
          "md5": "b0a744307f0e3f05abb846c368b1265a",
          "sha256": "0bc169efbcaa27ab81a4fd60cf3aa834e33f5c63ab7e5b8bda7833da8d9cfb43"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.7.1.tar.gz",
        "has_sig": false,
        "md5_digest": "b0a744307f0e3f05abb846c368b1265a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 14860,
        "upload_time": "2018-09-19T07:40:59",
        "upload_time_iso_8601": "2018-09-19T07:40:59.866791Z",
        "url": "https://files.pythonhosted.org/packages/53/2e/c6009775fdf07e0fcf3af5cc79388e71f583f807aa755cf262ef4bcf2cf0/tokenizer_tools-0.7.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.8.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "770fc1d4f48bc40dc7d03d14426f62b2f8c4467ac7a7f6204c51e8a8026d582f",
          "md5": "78faa96a8bfdefb678c6fd397d008c9e",
          "sha256": "4ad30ce9272a4dc4a11cf08c4a88fc4dc7e172439cebe3348df0b45ecc7cbde6"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.8.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "78faa96a8bfdefb678c6fd397d008c9e",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 13587,
        "upload_time": "2018-10-18T09:50:14",
        "upload_time_iso_8601": "2018-10-18T09:50:14.223348Z",
        "url": "https://files.pythonhosted.org/packages/77/0f/c1d4f48bc40dc7d03d14426f62b2f8c4467ac7a7f6204c51e8a8026d582f/tokenizer_tools-0.8.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0fbae6681de59d358d26931eb89c09c39bac60580f15068d3001d0c15cc82b7e",
          "md5": "853cdda93d310eca96eec48cc1c8f271",
          "sha256": "10ff1d5351407c18004aa462bc2d30a69889d61d8195853b4de3e0ebf177a5f0"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.8.0.tar.gz",
        "has_sig": false,
        "md5_digest": "853cdda93d310eca96eec48cc1c8f271",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 14891,
        "upload_time": "2018-10-18T09:50:16",
        "upload_time_iso_8601": "2018-10-18T09:50:16.726358Z",
        "url": "https://files.pythonhosted.org/packages/0f/ba/e6681de59d358d26931eb89c09c39bac60580f15068d3001d0c15cc82b7e/tokenizer_tools-0.8.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.8.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c574f213935883d26464f8d69b6a4dd2472ead6e74a96899963bbfa215734f0c",
          "md5": "023739b3cc2e3eb2f967e0cfb3adaf31",
          "sha256": "e44189655d3fea76bef4ebaa70c632fd2b29751c6ec281983341bb33912ccdbd"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.8.1-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "023739b3cc2e3eb2f967e0cfb3adaf31",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 13585,
        "upload_time": "2018-10-18T10:24:56",
        "upload_time_iso_8601": "2018-10-18T10:24:56.669633Z",
        "url": "https://files.pythonhosted.org/packages/c5/74/f213935883d26464f8d69b6a4dd2472ead6e74a96899963bbfa215734f0c/tokenizer_tools-0.8.1-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5bed8626cfd1d56e3eabcb18044185837ebc9d18bb1fa0f2e9a2f937b6a1fda6",
          "md5": "654f4f82b53d3f0d74846371824acac2",
          "sha256": "f6dd986f039ded4bbea4381abcfa0dbe55a1423af2e75e4e33bc55861d63270d"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.8.1.tar.gz",
        "has_sig": false,
        "md5_digest": "654f4f82b53d3f0d74846371824acac2",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 14893,
        "upload_time": "2018-10-18T10:24:59",
        "upload_time_iso_8601": "2018-10-18T10:24:59.061053Z",
        "url": "https://files.pythonhosted.org/packages/5b/ed/8626cfd1d56e3eabcb18044185837ebc9d18bb1fa0f2e9a2f937b6a1fda6/tokenizer_tools-0.8.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.8.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0005a94476d3f08128d73fdc9569215caf577071bc4c72c8eca3d2f43d9dbd49",
          "md5": "5bae647a70e112f9a154967a58bdb367",
          "sha256": "2bc867aacccacb8c8f170b0eab99c7c3c4a45d3c3c31752e46d5c55ba4f93193"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.8.2-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "5bae647a70e112f9a154967a58bdb367",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 13607,
        "upload_time": "2018-10-18T10:40:20",
        "upload_time_iso_8601": "2018-10-18T10:40:20.137960Z",
        "url": "https://files.pythonhosted.org/packages/00/05/a94476d3f08128d73fdc9569215caf577071bc4c72c8eca3d2f43d9dbd49/tokenizer_tools-0.8.2-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "043d4bca1088af9d4d98f719d2433751b47b7050cc9cc8b3ab82f0052ae8c8d6",
          "md5": "328b5d9e3b9b1284e6a94d820a71677a",
          "sha256": "a84b4dd646c128f0028fa9d97ad7bdcad14d78c01601c47972a3981ef107e478"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.8.2.tar.gz",
        "has_sig": false,
        "md5_digest": "328b5d9e3b9b1284e6a94d820a71677a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 14911,
        "upload_time": "2018-10-18T10:40:21",
        "upload_time_iso_8601": "2018-10-18T10:40:21.892074Z",
        "url": "https://files.pythonhosted.org/packages/04/3d/4bca1088af9d4d98f719d2433751b47b7050cc9cc8b3ab82f0052ae8c8d6/tokenizer_tools-0.8.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.9.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "87c7fdae6b87195cdb8c899eddf136c35da1995fdc5de1d41abfcf2840590cf4",
          "md5": "7029060b8448686b556a9eda145e7f5e",
          "sha256": "b3acb86eaca6aadaa2ca39398a6aaa5e387a7ed9873944a8abd2e1448c9c5a69"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.9.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "7029060b8448686b556a9eda145e7f5e",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 14900,
        "upload_time": "2018-11-16T09:08:24",
        "upload_time_iso_8601": "2018-11-16T09:08:24.106806Z",
        "url": "https://files.pythonhosted.org/packages/87/c7/fdae6b87195cdb8c899eddf136c35da1995fdc5de1d41abfcf2840590cf4/tokenizer_tools-0.9.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "369209c441533b4e051a0777e4219853221a07e02fc30942326cc3b4ff4e817c",
          "md5": "323e60a747cc41d351b2627a0a0cae43",
          "sha256": "dbabfbf7764f393810b9285749d10a74883e5dcda17f71a0d2b1471e91f1e2ef"
        },
        "downloads": -1,
        "filename": "tokenizer_tools-0.9.0.tar.gz",
        "has_sig": false,
        "md5_digest": "323e60a747cc41d351b2627a0a0cae43",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 15834,
        "upload_time": "2018-11-16T09:08:25",
        "upload_time_iso_8601": "2018-11-16T09:08:25.770430Z",
        "url": "https://files.pythonhosted.org/packages/36/92/09c441533b4e051a0777e4219853221a07e02fc30942326cc3b4ff4e817c/tokenizer_tools-0.9.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "93851f5bd5df02cfc4a7d7edd7d4a9b62a29f092e64f6660fbe159337569196f",
        "md5": "0a41f9fbf963caa4bd2c9af3e6986bb7",
        "sha256": "e73d27f575e357202272ab68a9b3e6cbec32bc3aae8268d537ab090bdebf74bb"
      },
      "downloads": -1,
      "filename": "tokenizer_tools-0.46.1-py2.py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "0a41f9fbf963caa4bd2c9af3e6986bb7",
      "packagetype": "bdist_wheel",
      "python_version": "py2.py3",
      "requires_python": null,
      "size": 69243,
      "upload_time": "2020-09-22T13:17:46",
      "upload_time_iso_8601": "2020-09-22T13:17:46.294003Z",
      "url": "https://files.pythonhosted.org/packages/93/85/1f5bd5df02cfc4a7d7edd7d4a9b62a29f092e64f6660fbe159337569196f/tokenizer_tools-0.46.1-py2.py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "a1ec56971a0b4adb6286713ab6dc85792d87dafd544e58367e678f6baaf49f2f",
        "md5": "89877fda9a5612e2a6ed0cc689276361",
        "sha256": "7bdfe8249b3422b77e2fe798d2ef38e05283c229834e79a12bdd8784d759733a"
      },
      "downloads": -1,
      "filename": "tokenizer_tools-0.46.1.tar.gz",
      "has_sig": false,
      "md5_digest": "89877fda9a5612e2a6ed0cc689276361",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 69810,
      "upload_time": "2020-09-22T13:17:48",
      "upload_time_iso_8601": "2020-09-22T13:17:48.618779Z",
      "url": "https://files.pythonhosted.org/packages/a1/ec/56971a0b4adb6286713ab6dc85792d87dafd544e58367e678f6baaf49f2f/tokenizer_tools-0.46.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}