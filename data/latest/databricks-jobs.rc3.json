{
  "info": {
    "author": "Judah Rand",
    "author_email": "17158624+judahrand@users.noreply.github.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# databricks-jobs\nThe Jobs API allows you to create, edit, and delete jobs.\nYou should never hard code secrets or store them in plain text. Use the [Secrets API](https://docs.microsoft.com/azure/databricks/dev-tools/api/latest/secrets) to manage secrets in the [Databricks CLI](https://docs.microsoft.com/azure/databricks/dev-tools/cli/index). Use the [Secrets utility](https://docs.microsoft.com/azure/databricks/dev-tools/databricks-utils#dbutils-secrets) to reference secrets in notebooks and jobs.\n\nThis Python package is automatically generated by the [OpenAPI Generator](https://openapi-generator.tech) project:\n\n- API version: 2.1\n- Package version: 1.0.0\n- Build package: org.openapitools.codegen.languages.PythonNextgenClientCodegen\n\n## Requirements.\n\nPython 3.7+\n\n## Installation & Usage\n### pip install\n\nIf the python package is hosted on a repository, you can install directly using:\n\n```sh\npip install git+https://github.com/GIT_USER_ID/GIT_REPO_ID.git\n```\n(you may need to run `pip` with root permission: `sudo pip install git+https://github.com/GIT_USER_ID/GIT_REPO_ID.git`)\n\nThen import the package:\n```python\nimport databricks_jobs\n```\n\n### Setuptools\n\nInstall via [Setuptools](http://pypi.python.org/pypi/setuptools).\n\n```sh\npython setup.py install --user\n```\n(or `sudo python setup.py install` to install the package for all users)\n\nThen import the package:\n```python\nimport databricks_jobs\n```\n\n## Getting Started\n\nPlease follow the [installation procedure](#installation--usage) and then run the following:\n\n```python\nfrom __future__ import print_function\n\nimport time\nimport databricks_jobs\nfrom databricks_jobs.rest import ApiException\nfrom pprint import pprint\n\n# Defining the host is optional and defaults to https://<databricks-instance>/api\n# See configuration.py for a list of all supported configuration parameters.\nconfiguration = databricks_jobs.Configuration(\n    host = \"https://<databricks-instance>/api\"\n)\n\n# The client must configure the authentication and authorization parameters\n# in accordance with the API server security policy.\n# Examples for each auth method are provided below, use the example that\n# satisfies your auth use case.\n\n# Configure Bearer authorization (api_token): bearerAuth\nconfiguration = databricks_jobs.Configuration(\n    access_token = os.environ[\"BEARER_TOKEN\"]\n)\n\n\n# Enter a context with an instance of the API client\nwith databricks_jobs.ApiClient(configuration) as api_client:\n    # Create an instance of the API class\n    api_instance = databricks_jobs.DefaultApi(api_client)\n    jobs_create_request = databricks_jobs.JobsCreateRequest() # JobsCreateRequest | \n\n    try:\n        # Create a new job\n        api_response = api_instance.jobs_create(jobs_create_request)\n        print(\"The response of DefaultApi->jobs_create:\\n\")\n        pprint(api_response)\n    except ApiException as e:\n        print(\"Exception when calling DefaultApi->jobs_create: %s\\n\" % e)\n\n```\n\n## Documentation for API Endpoints\n\nAll URIs are relative to *https://<databricks-instance>/api*\n\nClass | Method | HTTP request | Description\n------------ | ------------- | ------------- | -------------\n*DefaultApi* | [**jobs_create**](docs/DefaultApi.md#jobs_create) | **POST** /2.1/jobs/create | Create a new job\n*DefaultApi* | [**jobs_delete**](docs/DefaultApi.md#jobs_delete) | **POST** /2.1/jobs/delete | Delete a job\n*DefaultApi* | [**jobs_get**](docs/DefaultApi.md#jobs_get) | **GET** /2.1/jobs/get | Get a single job\n*DefaultApi* | [**jobs_list**](docs/DefaultApi.md#jobs_list) | **GET** /2.1/jobs/list | List all jobs\n*DefaultApi* | [**jobs_reset**](docs/DefaultApi.md#jobs_reset) | **POST** /2.1/jobs/reset | Overwrites all settings for a job\n*DefaultApi* | [**jobs_run_now**](docs/DefaultApi.md#jobs_run_now) | **POST** /2.1/jobs/run-now | Trigger a new job run\n*DefaultApi* | [**jobs_runs_cancel**](docs/DefaultApi.md#jobs_runs_cancel) | **POST** /2.1/jobs/runs/cancel | Cancel a job run\n*DefaultApi* | [**jobs_runs_cancel_all**](docs/DefaultApi.md#jobs_runs_cancel_all) | **POST** /2.1/jobs/runs/cancel-all | Cancel all runs of a job\n*DefaultApi* | [**jobs_runs_delete**](docs/DefaultApi.md#jobs_runs_delete) | **POST** /2.1/jobs/runs/delete | Delete a job run\n*DefaultApi* | [**jobs_runs_export**](docs/DefaultApi.md#jobs_runs_export) | **GET** /2.0/jobs/runs/export | Export and retrieve a job run\n*DefaultApi* | [**jobs_runs_get**](docs/DefaultApi.md#jobs_runs_get) | **GET** /2.1/jobs/runs/get | Get a single job run\n*DefaultApi* | [**jobs_runs_get_output**](docs/DefaultApi.md#jobs_runs_get_output) | **GET** /2.1/jobs/runs/get-output | Get the output for a single run\n*DefaultApi* | [**jobs_runs_list**](docs/DefaultApi.md#jobs_runs_list) | **GET** /2.1/jobs/runs/list | List runs for a job\n*DefaultApi* | [**jobs_runs_repair**](docs/DefaultApi.md#jobs_runs_repair) | **POST** /2.1/jobs/runs/repair | Repair a job run\n*DefaultApi* | [**jobs_runs_submit**](docs/DefaultApi.md#jobs_runs_submit) | **POST** /2.1/jobs/runs/submit | Create and trigger a one-time run\n*DefaultApi* | [**jobs_update**](docs/DefaultApi.md#jobs_update) | **POST** /2.1/jobs/update | Partially updates a job\n\n\n## Documentation For Models\n\n - [AccessControlList](docs/AccessControlList.md)\n - [AccessControlRequest](docs/AccessControlRequest.md)\n - [AccessControlRequestForGroup](docs/AccessControlRequestForGroup.md)\n - [AccessControlRequestForServicePrincipal](docs/AccessControlRequestForServicePrincipal.md)\n - [AccessControlRequestForUser](docs/AccessControlRequestForUser.md)\n - [Adlsgen2Info](docs/Adlsgen2Info.md)\n - [AutoScale](docs/AutoScale.md)\n - [AwsAttributes](docs/AwsAttributes.md)\n - [AzureAttributes](docs/AzureAttributes.md)\n - [CanManage](docs/CanManage.md)\n - [CanManageRun](docs/CanManageRun.md)\n - [CanView](docs/CanView.md)\n - [ClusterAttributes](docs/ClusterAttributes.md)\n - [ClusterCloudProviderNodeInfo](docs/ClusterCloudProviderNodeInfo.md)\n - [ClusterCloudProviderNodeStatus](docs/ClusterCloudProviderNodeStatus.md)\n - [ClusterEvent](docs/ClusterEvent.md)\n - [ClusterEventType](docs/ClusterEventType.md)\n - [ClusterInfo](docs/ClusterInfo.md)\n - [ClusterInstance](docs/ClusterInstance.md)\n - [ClusterLibraryStatuses](docs/ClusterLibraryStatuses.md)\n - [ClusterLogConf](docs/ClusterLogConf.md)\n - [ClusterSize](docs/ClusterSize.md)\n - [ClusterSource](docs/ClusterSource.md)\n - [ClusterSpec](docs/ClusterSpec.md)\n - [ClusterState](docs/ClusterState.md)\n - [CronSchedule](docs/CronSchedule.md)\n - [DbfsStorageInfo](docs/DbfsStorageInfo.md)\n - [DbtOutput](docs/DbtOutput.md)\n - [DbtTask](docs/DbtTask.md)\n - [DockerBasicAuth](docs/DockerBasicAuth.md)\n - [DockerImage](docs/DockerImage.md)\n - [Error](docs/Error.md)\n - [EventDetails](docs/EventDetails.md)\n - [FileStorageInfo](docs/FileStorageInfo.md)\n - [GcpAttributes](docs/GcpAttributes.md)\n - [GitBranchSource](docs/GitBranchSource.md)\n - [GitCommitSource](docs/GitCommitSource.md)\n - [GitProvider](docs/GitProvider.md)\n - [GitSnapshot](docs/GitSnapshot.md)\n - [GitSource](docs/GitSource.md)\n - [GitTagSource](docs/GitTagSource.md)\n - [InitScriptInfo](docs/InitScriptInfo.md)\n - [IsOwner](docs/IsOwner.md)\n - [Job](docs/Job.md)\n - [JobCluster](docs/JobCluster.md)\n - [JobEmailNotifications](docs/JobEmailNotifications.md)\n - [JobSettings](docs/JobSettings.md)\n - [JobTask](docs/JobTask.md)\n - [JobTaskSettings](docs/JobTaskSettings.md)\n - [JobsCreate200Response](docs/JobsCreate200Response.md)\n - [JobsCreateRequest](docs/JobsCreateRequest.md)\n - [JobsDeleteRequest](docs/JobsDeleteRequest.md)\n - [JobsGet200Response](docs/JobsGet200Response.md)\n - [JobsList200Response](docs/JobsList200Response.md)\n - [JobsResetRequest](docs/JobsResetRequest.md)\n - [JobsRunNow200Response](docs/JobsRunNow200Response.md)\n - [JobsRunNowRequest](docs/JobsRunNowRequest.md)\n - [JobsRunsCancelAllRequest](docs/JobsRunsCancelAllRequest.md)\n - [JobsRunsCancelRequest](docs/JobsRunsCancelRequest.md)\n - [JobsRunsDeleteRequest](docs/JobsRunsDeleteRequest.md)\n - [JobsRunsExport200Response](docs/JobsRunsExport200Response.md)\n - [JobsRunsGet200Response](docs/JobsRunsGet200Response.md)\n - [JobsRunsGetOutput200Response](docs/JobsRunsGetOutput200Response.md)\n - [JobsRunsList200Response](docs/JobsRunsList200Response.md)\n - [JobsRunsRepair200Response](docs/JobsRunsRepair200Response.md)\n - [JobsRunsRepairRequest](docs/JobsRunsRepairRequest.md)\n - [JobsRunsSubmit200Response](docs/JobsRunsSubmit200Response.md)\n - [JobsRunsSubmitRequest](docs/JobsRunsSubmitRequest.md)\n - [JobsUpdateRequest](docs/JobsUpdateRequest.md)\n - [Library](docs/Library.md)\n - [LibraryFullStatus](docs/LibraryFullStatus.md)\n - [LibraryInstallStatus](docs/LibraryInstallStatus.md)\n - [ListOrder](docs/ListOrder.md)\n - [LogSyncStatus](docs/LogSyncStatus.md)\n - [MavenLibrary](docs/MavenLibrary.md)\n - [NewCluster](docs/NewCluster.md)\n - [NewTaskCluster](docs/NewTaskCluster.md)\n - [NodeType](docs/NodeType.md)\n - [NotebookOutput](docs/NotebookOutput.md)\n - [NotebookTask](docs/NotebookTask.md)\n - [PermissionLevel](docs/PermissionLevel.md)\n - [PermissionLevelForGroup](docs/PermissionLevelForGroup.md)\n - [PipelineTask](docs/PipelineTask.md)\n - [PoolClusterTerminationCode](docs/PoolClusterTerminationCode.md)\n - [PythonPyPiLibrary](docs/PythonPyPiLibrary.md)\n - [PythonWheelTask](docs/PythonWheelTask.md)\n - [RCranLibrary](docs/RCranLibrary.md)\n - [RepairHistory](docs/RepairHistory.md)\n - [RepairHistoryItem](docs/RepairHistoryItem.md)\n - [RepairRunInput](docs/RepairRunInput.md)\n - [ResizeCause](docs/ResizeCause.md)\n - [Run](docs/Run.md)\n - [RunLifeCycleState](docs/RunLifeCycleState.md)\n - [RunNowInput](docs/RunNowInput.md)\n - [RunParameters](docs/RunParameters.md)\n - [RunParametersPipelineParams](docs/RunParametersPipelineParams.md)\n - [RunResultState](docs/RunResultState.md)\n - [RunState](docs/RunState.md)\n - [RunSubmitSettings](docs/RunSubmitSettings.md)\n - [RunSubmitTaskSettings](docs/RunSubmitTaskSettings.md)\n - [RunTask](docs/RunTask.md)\n - [RunType](docs/RunType.md)\n - [S3StorageInfo](docs/S3StorageInfo.md)\n - [SparkJarTask](docs/SparkJarTask.md)\n - [SparkNode](docs/SparkNode.md)\n - [SparkNodeAwsAttributes](docs/SparkNodeAwsAttributes.md)\n - [SparkPythonTask](docs/SparkPythonTask.md)\n - [SparkSubmitTask](docs/SparkSubmitTask.md)\n - [SparkVersion](docs/SparkVersion.md)\n - [SqlAlertOutput](docs/SqlAlertOutput.md)\n - [SqlDashboardOutput](docs/SqlDashboardOutput.md)\n - [SqlDashboardWidgetOutput](docs/SqlDashboardWidgetOutput.md)\n - [SqlOutput](docs/SqlOutput.md)\n - [SqlOutputError](docs/SqlOutputError.md)\n - [SqlQueryOutput](docs/SqlQueryOutput.md)\n - [SqlStatementOutput](docs/SqlStatementOutput.md)\n - [SqlTask](docs/SqlTask.md)\n - [SqlTaskAlert](docs/SqlTaskAlert.md)\n - [SqlTaskDashboard](docs/SqlTaskDashboard.md)\n - [SqlTaskQuery](docs/SqlTaskQuery.md)\n - [TaskDependenciesInner](docs/TaskDependenciesInner.md)\n - [TaskSparkSubmitTask](docs/TaskSparkSubmitTask.md)\n - [TerminationCode](docs/TerminationCode.md)\n - [TerminationParameter](docs/TerminationParameter.md)\n - [TerminationReason](docs/TerminationReason.md)\n - [TerminationType](docs/TerminationType.md)\n - [TriggerType](docs/TriggerType.md)\n - [ViewItem](docs/ViewItem.md)\n - [ViewType](docs/ViewType.md)\n - [ViewsToExport](docs/ViewsToExport.md)\n - [WebhookNotifications](docs/WebhookNotifications.md)\n - [WebhookNotificationsOnStartInner](docs/WebhookNotificationsOnStartInner.md)\n\n\n## Documentation For Authorization\n\n\n## bearerAuth\n\n- **Type**: Bearer authentication (api_token)\n\n\n## Author\n\n\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/judahrand/databricks-jobs",
    "keywords": "OpenAPI,OpenAPI-Generator,Databricks,Jobs API 2.1",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "databricks-jobs",
    "package_url": "https://pypi.org/project/databricks-jobs/",
    "platform": null,
    "project_url": "https://pypi.org/project/databricks-jobs/",
    "project_urls": {
      "Homepage": "https://github.com/judahrand/databricks-jobs"
    },
    "release_url": "https://pypi.org/project/databricks-jobs/1.0.3/",
    "requires_dist": [
      "urllib3 (>=1.25.3)",
      "python-dateutil",
      "pydantic",
      "aenum"
    ],
    "requires_python": ">=3.8",
    "summary": "Databricks Jobs API 2.1 Client",
    "version": "1.0.3",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17378502,
  "releases": {
    "1.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "542d4e4dad2dd42ccac533a6076fed18c62f7f485533a4c59c2e6593466cbf81",
          "md5": "1f0165320650fb3a7cc864d77deae98e",
          "sha256": "651b7caa26e521e081874395f6433c64317dfe8c3b2decdd30071d1ef1f5a9ad"
        },
        "downloads": -1,
        "filename": "databricks_jobs-1.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "1f0165320650fb3a7cc864d77deae98e",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 229251,
        "upload_time": "2023-03-17T15:11:20",
        "upload_time_iso_8601": "2023-03-17T15:11:20.537550Z",
        "url": "https://files.pythonhosted.org/packages/54/2d/4e4dad2dd42ccac533a6076fed18c62f7f485533a4c59c2e6593466cbf81/databricks_jobs-1.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b834b9739b8b0deb23906770c4ead8cd92fc793baa120b2a5baa7187b5e82a06",
          "md5": "9fbe15fe2daa9861f5b6398a49f231f1",
          "sha256": "20353f1b27905cc15fc094601b03f0be0be16e8083bb8040ae1676a24f4f92c6"
        },
        "downloads": -1,
        "filename": "databricks-jobs-1.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "9fbe15fe2daa9861f5b6398a49f231f1",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 89135,
        "upload_time": "2023-03-17T15:11:22",
        "upload_time_iso_8601": "2023-03-17T15:11:22.366239Z",
        "url": "https://files.pythonhosted.org/packages/b8/34/b9739b8b0deb23906770c4ead8cd92fc793baa120b2a5baa7187b5e82a06/databricks-jobs-1.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0a09220d55df92dc69d6e5252c9cb8729a2d49a1571b194a54eea60e49dd4506",
          "md5": "3159b487e59fd8253f530921abc85549",
          "sha256": "6ed0a2deec5f0a9c13908f3e199dfbe843fdb53755de5645f5bd9963401be525"
        },
        "downloads": -1,
        "filename": "databricks_jobs-1.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "3159b487e59fd8253f530921abc85549",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 227188,
        "upload_time": "2023-03-20T14:49:33",
        "upload_time_iso_8601": "2023-03-20T14:49:33.722360Z",
        "url": "https://files.pythonhosted.org/packages/0a/09/220d55df92dc69d6e5252c9cb8729a2d49a1571b194a54eea60e49dd4506/databricks_jobs-1.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "724eaf35cbe9e084cbc25cc535bb0cc14b76fcadf37dc8e117133ef0aba51aa7",
          "md5": "4aad6bc3e7aaf0c3f78d47019982c72a",
          "sha256": "f9b4cd7089ce18a6710220383878048d5bd10bd70e98bf5318f5ba619a134b9f"
        },
        "downloads": -1,
        "filename": "databricks-jobs-1.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "4aad6bc3e7aaf0c3f78d47019982c72a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 88261,
        "upload_time": "2023-03-20T14:49:35",
        "upload_time_iso_8601": "2023-03-20T14:49:35.626081Z",
        "url": "https://files.pythonhosted.org/packages/72/4e/af35cbe9e084cbc25cc535bb0cc14b76fcadf37dc8e117133ef0aba51aa7/databricks-jobs-1.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6ee1b946a6089228c0169a8578c6f87abe4c29c13bb54e9d20f9fe1bf50dc73c",
          "md5": "1e4e87bc8598f5d3e1f8687bb95df038",
          "sha256": "3abe4c166e154e91a5e43e5be3f2e246a2920aae8bec52af553a8e80001d4552"
        },
        "downloads": -1,
        "filename": "databricks_jobs-1.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "1e4e87bc8598f5d3e1f8687bb95df038",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 227367,
        "upload_time": "2023-03-21T12:08:29",
        "upload_time_iso_8601": "2023-03-21T12:08:29.073509Z",
        "url": "https://files.pythonhosted.org/packages/6e/e1/b946a6089228c0169a8578c6f87abe4c29c13bb54e9d20f9fe1bf50dc73c/databricks_jobs-1.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d9d4ebba27886ec924d5f726f0adf3ece2cead0cd5e25150c90c2f06a14d3f9d",
          "md5": "a29db7bfdcb2b286cd810d79fbe8160b",
          "sha256": "b148603e369a75d1861a0bcf6dc37b15d4794204ef452a45d09ad6891ed68302"
        },
        "downloads": -1,
        "filename": "databricks-jobs-1.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "a29db7bfdcb2b286cd810d79fbe8160b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 88342,
        "upload_time": "2023-03-21T12:08:30",
        "upload_time_iso_8601": "2023-03-21T12:08:30.648421Z",
        "url": "https://files.pythonhosted.org/packages/d9/d4/ebba27886ec924d5f726f0adf3ece2cead0cd5e25150c90c2f06a14d3f9d/databricks-jobs-1.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "6ee1b946a6089228c0169a8578c6f87abe4c29c13bb54e9d20f9fe1bf50dc73c",
        "md5": "1e4e87bc8598f5d3e1f8687bb95df038",
        "sha256": "3abe4c166e154e91a5e43e5be3f2e246a2920aae8bec52af553a8e80001d4552"
      },
      "downloads": -1,
      "filename": "databricks_jobs-1.0.3-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "1e4e87bc8598f5d3e1f8687bb95df038",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.8",
      "size": 227367,
      "upload_time": "2023-03-21T12:08:29",
      "upload_time_iso_8601": "2023-03-21T12:08:29.073509Z",
      "url": "https://files.pythonhosted.org/packages/6e/e1/b946a6089228c0169a8578c6f87abe4c29c13bb54e9d20f9fe1bf50dc73c/databricks_jobs-1.0.3-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "d9d4ebba27886ec924d5f726f0adf3ece2cead0cd5e25150c90c2f06a14d3f9d",
        "md5": "a29db7bfdcb2b286cd810d79fbe8160b",
        "sha256": "b148603e369a75d1861a0bcf6dc37b15d4794204ef452a45d09ad6891ed68302"
      },
      "downloads": -1,
      "filename": "databricks-jobs-1.0.3.tar.gz",
      "has_sig": false,
      "md5_digest": "a29db7bfdcb2b286cd810d79fbe8160b",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.8",
      "size": 88342,
      "upload_time": "2023-03-21T12:08:30",
      "upload_time_iso_8601": "2023-03-21T12:08:30.648421Z",
      "url": "https://files.pythonhosted.org/packages/d9/d4/ebba27886ec924d5f726f0adf3ece2cead0cd5e25150c90c2f06a14d3f9d/databricks-jobs-1.0.3.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}