{
  "info": {
    "author": "Sriram Kumar Boinpalli",
    "author_email": "srirambsk1996@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Natural Language :: English",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 2",
      "Programming Language :: Python :: 2.7",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.4",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: Implementation :: CPython",
      "Topic :: Software Development :: Libraries :: Python Modules",
      "Topic :: Utilities"
    ],
    "description": "Proxy Scrape\n============\n\nA library for retrieving free proxies (HTTP, HTTPS, SOCKS4, SOCKS5). Supports Python 2.7+ and 3.4+.\n\n*NOTE: This library isn't designed for production use. It's advised to use your own proxies or purchase a service which\nprovides an API. These are merely free ones that are retrieved from sites and should only be used for development\nor testing purposes.*\n\n.. code-block:: python\n\n    import proxyscrape\n\n    collector = proxyscrape.create_collector('default', 'http')  # Create a collector for http resources\n    proxy = collector.get_proxy({'country': 'united states'})  # Retrieve a united states proxy\n\nInstallation\n------------\n\nThe latest version of proxyscrape is available via ``pip``:\n\n.. code-block:: bash\n\n    $ pip install proxyscrape\n\nAlternatively, you can download and install from source:\n\n.. code-block:: bash\n\n    $ python setup.py install\n\nProvided Proxies\n----------------\nCurrent proxies provided are scraped from various sites which offer free HTTP, HTTPS, SOCKS4, and SOCKS5 proxies; and\ndon't require headless browsers or selenium to retrieve. The list of sites proxies retrieved are shown below.\n\n+--------------------+----------------+--------------------------------------------------+\n| resource           | resource type  | url                                              |\n+====================+================+==================================================+\n| anonymous-proxy    | http, https    | https://free-proxy-list.net/anonymous-proxy.html |\n+--------------------+----------------+--------------------------------------------------+\n| free-proxy-list    | http, https    | https://free-proxy-list.net                      |\n+--------------------+----------------+--------------------------------------------------+\n| proxy-daily-http   | http           | http://www.proxy-daily.com                       |\n| proxy-daily-socks4 | socks4         |                                                  |\n| proxy-daily-socks5 | socks5         |                                                  |\n+--------------------+----------------+--------------------------------------------------+\n| socks-proxy        | socks4, socks5 | https://www.socks-proxy.net                      |\n+--------------------+----------------+--------------------------------------------------+\n| ssl-proxy          | https          | https://www.sslproxies.org                       |\n+--------------------+----------------+--------------------------------------------------+\n| uk-proxy           | http, https    | https://free-proxy-list.net/uk-proxy.html        |\n+--------------------+----------------+--------------------------------------------------+\n| us-proxy           | http, https    | https://www.us-proxy.org                         |\n+--------------------+----------------+--------------------------------------------------+\n\nSee `Integration`_ section for additional proxies.\n\nGetting Started\n---------------\n\nProxy Scrape is a library aimed at providing an efficient an easy means of retrieving proxies for web-scraping\npurposes. The proxies retrieved are available from sites providing free proxies. The proxies provided, as shown in the\nabove table, can be of one of the following types (referred to as a `resource type`): http, https, socks4, and socks5.\n\nCollectors\n^^^^^^^^^^\nCollectors serve as the interface to retrieving proxies. They are instantiating at module-level and can be retrieved\nand re-used in different parts of the application (similar to the Python `logging` library). Collectors can be created\nand retrieved via the `create_collector(...)` and `get_collector(...)` functions.\n\n.. code-block:: python\n\n    from proxyscrape import create_collector, get_collector\n\n    collector = create_collector('my-collector', ['socks4', 'socks5'])\n\n    # Some other section of code\n    collector = get_collector('my-collector')\n\nEach collector should have a unique name and be initialized only once. Typically, only a single collector of a given\nresource type should be utilized. Filters can then be applied to the proxies if specific criteria is desired.\n\nWhen given one or more resources, the collector will use those to retrieve proxies. If one or more resource types\nare given, the resources for each of the types will be used to retrieve proxies.\n\nOnce created, proxies can be retrieved via the `get_proxy(...)` or the `get_proxies(...)` function. This optionally takes a `filter_opts`\nparameter which can filter by the following:\n\n- ``code`` (us, ca, ...)\n- ``country`` (united states, canada, ...)\n- ``anonymous`` (True, False)\n- ``type`` (http, https, socks4, socks5, ...)\n\n.. code-block:: python\n\n    from proxyscrape import create_collector\n\n    collector = create_collector('my-collector', 'http')\n\n    # Retrieve any http proxy\n    proxy = collector.get_proxy()\n\n    # Retrieve only 'us' proxies\n    proxy = collector.get_proxy({'code': 'us'})\n\n    # Retrieve only anonymous 'uk' or 'us' proxies\n    proxy = collector.get_proxy({'code': ('us', 'uk'), 'anonymous': True})\n\n    # Retrieve all 'ca' proxies\n    proxies = collector.get_proxies({'code': 'ca'})\n\nFilters can be applied to every proxy retrieval from the collector via `apply_filter(...)`. This is useful when the same\nfilter is expected for any proxy retrieved.\n\n.. code-block:: python\n\n    from proxyscrape import create_collector\n\n    collector = create_collector('my-collector', 'http')\n\n    # Only retrieve 'uk' and 'us' proxies\n    collector.apply_filter({'code': 'us'})\n\n    # Filtered proxies\n    proxy = collector.get_proxy()\n\n    # Clear filter\n    collector.clear_filter()\n\nNote that some filters may instead use specific resources to achieve the same results (i.e. 'us-proxy' or 'uk-proxy' for\n'us' and 'uk' proxies).\n\nBlacklists can be applied to a collector to prevent specific proxies from being retrieved. They accept either one or more Proxy\nobjects, or a host + port number combination and won't allow retrieval of matching proxies. Proxies can be individually removed\nfrom blacklists or the entire blacklist can be cleared.\n\n.. code-block:: python\n\n    from proxyscrape import create_collector\n\n    collector = create_collector('my-collector', 'http')\n\n    # Add proxy to blacklist\n    collector.blacklist_proxy(Proxy('192.168.1.1', '80', None, None, None, 'http', 'my-resource'))\n    collector.blacklist_proxy(host='192.168.1.2', port='8080')\n\n    # Blacklisted proxies won't be included\n    proxy = get_proxy()\n\n    # Remove individual proxies\n    collector.remove_blacklist(host='192.168.1.1', port='80')\n\n    # Clear blacklist\n    collector.clear_blacklist()\n\n\nInstead of permanently blacklisting a particular proxies, a proxy can instead be removed from internal memory. This\nallows it to be re-added to the pool upon a subsequent refresh.\n\n.. code-block:: python\n\n    from proxyscrape import create_collector\n\n    collector = create_collector('my-collector', 'http')\n\n    # Remove proxy from internal pool\n    collector.remove_proxy(Proxy('192.168.1.1', '80', None, None, 'http', 'my-resource'))\n\n\nApart from automatic refreshes when retrieving proxies, they can also be forcefully refreshed via the\n`refresh_proxies(...)` function.\n\n.. code-block:: python\n\n    from proxyscrape import create_collector\n\n    collector = create_collector('my-collector', 'http')\n\n    # Forcefully refresh\n    collector.refresh_proxies(force=True)\n\n    # Refresh only if proxies not refreshed within `refresh_interval`\n    collector.refresh_proxies(force=False)\n\nResources\n^^^^^^^^^\nResources refer to a specific function that retrieves a set of proxies; the currently implemented proxies are all\nretrieves from scraping a particular web site.\n\nAdditional user-defined resources can be added to the pool of proxy retrieval functions via the `add_resource(...)`\nfunction. Resources can belong to multiple resource types.\n\n.. code-block:: python\n\n    from proxyscrape import add_resource\n\n    def func():\n        return {Proxy('192.168.1.1', '80', 'us', 'united states', False, 'http', 'my-resource'), }\n\n    add_resource('my-resource', func, 'http')\n\nAs shown above, a resource doesn't necessarily have to scrape proxies from a web site. It can be return a hard-coded\nlist of proxies, make a call to an api, read from a file, etc.\n\nThe set of library- and user-defined resources can be retrieved via the `get_resources(...)` function.\n\n.. code-block:: python\n\n    from proxyscrape import get_resources\n    resources = get_resources()\n\nResource Types\n^^^^^^^^^^^^^^\nResource types are groupings of resources that can be specified when defining a collector (opposed to giving a\ncollection of resources.\n\nAdditional user-defined resource types can be added via the `add_resource_type(...)` function. Resources can optionally\nbe added to a resource type when defining it.\n\n.. code-block:: python\n\n    from proxyscrape import add_resource_type\n    add_resource_type('my-resource-type')\n    add_resource_type('my-other-resource-type', 'my-resource')  # Define resources for resource type\n\nThe set of library- and user-defined resource types can be retrieved via the `get_resource_types(...)` function.\n\n.. code-block:: python\n\n    from proxyscrape import get_resource_types\n    resources = get_resource_types()\n\n\n.. _Integration:\n\nIntegration\n-----------\n\nIntegrations are proxy implementations that are specific to a particular website or API and have a distinctively\nseparate use case.\n\nProxyScrape\n^^^^^^^^^^^\nThe `ProxyScrape.com API`_ provides a means of accessing thousands of proxies of various types (HTTP, SOCKS4, SOCKS5) in\nan efficient manner. These are vetted and validated with a minimal response time.\n\nThe `get_proxyscrape_resource(...)` function is used to dynamically create a new resource for using the proxyscrape API.\nThe resource name can then be added to a resource type and used like any other library- or user-defined resource. The\nfollowing parameters are used for the API:\n\n- ``proxytype`` (http, socks4, socks5, all)\n- ``timeout`` (milliseconds > 0)\n- ``ssl`` (yes, no, all)\n- ``anonymity`` (elite, anonymous, transparent, all)\n- ``country`` (any Alpha 2 ISO country code, all)\n\n.. code-block:: python\n\n    from proxyscrape import get_proxyscrape_resource\n    resource_name = get_proxyscrape_resource(proxytype='http', timeout=5000, ssl='yes', anonymity='all', country='us')\n\n\n.. _ProxyScrape.com API: https://proxyscrape.com/en/api\n\nContribution\n------------\n\nContributions or suggestions are welcome! Feel free to `open an issue`_ if a bug is found or an enhancement is desired,\nor even a `pull request`_.\n\n.. _open an issue: https://github.com/sriramkumar1996/proxyscrape/issues\n.. _pull request: https://github.com/sriramkumar1996/proxyscrape/compare\n\nChangelog\n---------\n\nAll changes and versioning information can be found in the `CHANGELOG`_.\n\n.. _CHANGELOG: https://github.com/sriramkumar1996/proxyscrape/blob/master/CHANGELOG.rst\n\nLicense\n-------\n\nCopyright (c) 2020 Sriram Kumar. See `LICENSE`_ for details.\n\n.. _LICENSE: https://github.com/sriramkumar1996/proxyscrape/blob/master/LICENSE.txt\n\n\n",
    "description_content_type": "",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/sriramkumar1996/proxyscrape",
    "keywords": "proxyscrape proxy scrape scraper",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "sriram-proxyscrape",
    "package_url": "https://pypi.org/project/sriram-proxyscrape/",
    "platform": "",
    "project_url": "https://pypi.org/project/sriram-proxyscrape/",
    "project_urls": {
      "Homepage": "https://github.com/sriramkumar1996/proxyscrape"
    },
    "release_url": "https://pypi.org/project/sriram-proxyscrape/0.4.0/",
    "requires_dist": [
      "BeautifulSoup4",
      "requests"
    ],
    "requires_python": "",
    "summary": "A library for retrieving free proxies (HTTP, HTTPS, SOCKS4, SOCKS5).",
    "version": "0.4.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 6620713,
  "releases": {
    "0.3.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2ee73fc7dd3237e22940569e73b6c0a6f1f03e6c975e8c968d19b0c5740ec1a1",
          "md5": "dd75b676f077da99c08f4d00824d0348",
          "sha256": "aa495e4a1400ebfc72a0275edc016e832f661de464cc1e101ded2121f4595426"
        },
        "downloads": -1,
        "filename": "sriram_proxyscrape-0.3.1-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "dd75b676f077da99c08f4d00824d0348",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 22968,
        "upload_time": "2020-02-13T01:13:33",
        "upload_time_iso_8601": "2020-02-13T01:13:33.901430Z",
        "url": "https://files.pythonhosted.org/packages/2e/e7/3fc7dd3237e22940569e73b6c0a6f1f03e6c975e8c968d19b0c5740ec1a1/sriram_proxyscrape-0.3.1-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1b84ddc3334d8db13a4e3114253bff11de9c60345d733ce836c8cb95e7cb50f6",
          "md5": "4c02c18c582c022d2c1ce6cbbcb13c45",
          "sha256": "0a13ce3e9052fd369a089863f8cf08a2cd25585d92957ef061b7d0c5b8accb1c"
        },
        "downloads": -1,
        "filename": "sriram-proxyscrape-0.3.1.tar.gz",
        "has_sig": false,
        "md5_digest": "4c02c18c582c022d2c1ce6cbbcb13c45",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 19487,
        "upload_time": "2020-02-13T01:13:36",
        "upload_time_iso_8601": "2020-02-13T01:13:36.987234Z",
        "url": "https://files.pythonhosted.org/packages/1b/84/ddc3334d8db13a4e3114253bff11de9c60345d733ce836c8cb95e7cb50f6/sriram-proxyscrape-0.3.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ddb5b8ea3180580d7f3d927c4af93eee2d7b756d43fe51176b7d033e97349b8e",
          "md5": "4cbb74d47314abbb461f72a5bd4ed532",
          "sha256": "6aeda06abbab27302759bac3d09c68d6ab82d5b7ff06d9ccf707afe6dd216b51"
        },
        "downloads": -1,
        "filename": "sriram_proxyscrape-0.4.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "4cbb74d47314abbb461f72a5bd4ed532",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 22990,
        "upload_time": "2020-02-13T02:56:36",
        "upload_time_iso_8601": "2020-02-13T02:56:36.659847Z",
        "url": "https://files.pythonhosted.org/packages/dd/b5/b8ea3180580d7f3d927c4af93eee2d7b756d43fe51176b7d033e97349b8e/sriram_proxyscrape-0.4.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2ed032fa480f1035a8272c51bc23de884eebf41cc50fb89c021eef8fae6f6f64",
          "md5": "06799baf0f1172c3db1d31d2472c0655",
          "sha256": "8b797387c1967eb2efa4072896b166296ea0bb3f46c7b8604edc744b1e40a321"
        },
        "downloads": -1,
        "filename": "sriram-proxyscrape-0.4.0.tar.gz",
        "has_sig": false,
        "md5_digest": "06799baf0f1172c3db1d31d2472c0655",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 19509,
        "upload_time": "2020-02-13T02:56:38",
        "upload_time_iso_8601": "2020-02-13T02:56:38.711985Z",
        "url": "https://files.pythonhosted.org/packages/2e/d0/32fa480f1035a8272c51bc23de884eebf41cc50fb89c021eef8fae6f6f64/sriram-proxyscrape-0.4.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "ddb5b8ea3180580d7f3d927c4af93eee2d7b756d43fe51176b7d033e97349b8e",
        "md5": "4cbb74d47314abbb461f72a5bd4ed532",
        "sha256": "6aeda06abbab27302759bac3d09c68d6ab82d5b7ff06d9ccf707afe6dd216b51"
      },
      "downloads": -1,
      "filename": "sriram_proxyscrape-0.4.0-py2.py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "4cbb74d47314abbb461f72a5bd4ed532",
      "packagetype": "bdist_wheel",
      "python_version": "py2.py3",
      "requires_python": null,
      "size": 22990,
      "upload_time": "2020-02-13T02:56:36",
      "upload_time_iso_8601": "2020-02-13T02:56:36.659847Z",
      "url": "https://files.pythonhosted.org/packages/dd/b5/b8ea3180580d7f3d927c4af93eee2d7b756d43fe51176b7d033e97349b8e/sriram_proxyscrape-0.4.0-py2.py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "2ed032fa480f1035a8272c51bc23de884eebf41cc50fb89c021eef8fae6f6f64",
        "md5": "06799baf0f1172c3db1d31d2472c0655",
        "sha256": "8b797387c1967eb2efa4072896b166296ea0bb3f46c7b8604edc744b1e40a321"
      },
      "downloads": -1,
      "filename": "sriram-proxyscrape-0.4.0.tar.gz",
      "has_sig": false,
      "md5_digest": "06799baf0f1172c3db1d31d2472c0655",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 19509,
      "upload_time": "2020-02-13T02:56:38",
      "upload_time_iso_8601": "2020-02-13T02:56:38.711985Z",
      "url": "https://files.pythonhosted.org/packages/2e/d0/32fa480f1035a8272c51bc23de884eebf41cc50fb89c021eef8fae6f6f64/sriram-proxyscrape-0.4.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}