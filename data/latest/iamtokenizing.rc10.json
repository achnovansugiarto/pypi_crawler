{
  "info": {
    "author": "IAM CHU Bordeaux France",
    "author_email": "via.issue@only.please",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Information Technology",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: GNU General Public License v3 (GPLv3)",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Topic :: Scientific/Engineering :: Information Analysis",
      "Topic :: Text Processing"
    ],
    "description": "# Tokenization for language processing\n\nThis package contains some basic tools allowing to cut a string in sub-parts (cf. [Wikipedia](https://en.wikipedia.org/wiki/Lexical_analysis#Tokenization)), called `Token`.\n\n`iamtokenizing` classes allow basic tokenization of text, such as\n\n - word splitting, n-gram splitting, (using `NGrams` class) \n - char-gram splitting of arbitrary size (using `CharGrams` class). \n\n`NGrams` also accepts any REGular EXpression (REGEX) to match pattern that will serve as splitting string. The class `RegexDetector` also allows to extract the REGEX pattern as token. In addition, `ContextDetector` allow to split text on some REGEX, and to detect inside these splits an other REGEX, keeping some organisation (called context) of the text between the two detection and splitting scales.\n\n## Installation\n\n - The documentation is available on [https://nlp.frama.io/iamtokenizing/](https://nlp.frama.io/iamtokenizing/)\n - The PyPi package is available on [https://pypi.org/project/iamtokenizing/](https://pypi.org/project/iamtokenizing/)\n - The official repository is on [https://framagit.org/nlp/iamtokenizing](https://framagit.org/nlp/iamtokenizing)\n\n### From Python Package Index (PIP)\n\nSimply run \n\n```bash\npip install iamtokenizing\n```\n\nis sufficient.\n\n### From the repository\n\nThe official repository is on https://framagit.org/nlp/iamtokenizing\n\nOnce the repository has been downloaded (or cloned), one can install this package using `pip` : \n\n```bash\ngit clone https://framagit.org/nlp/iamtokenizing.git\ncd iamtokenizing/\npip install .\n```\n\nOnce installed, one can run some tests using\n\n```bash\ncd tests/\npython3 -m unittest -v\n```\n\n(verbosity `-v` is an option).\n\n## Basic examples\n\nBasic examples can be found in the [documentation](https://nlp.frama.io/iamtokenizing/).\n\n## Versions\n\n - Versions before 0.4 only present the `Token` and `Tokens` classes. They have been splitted after in three classes, named `Span`, `Token` and `Tokens`. Importantly, the methods `Token.append` and `Token.remove` no longer exist in the next version. They have been replaced by `Token.append_range`, `Token.append_ranges`, `Token.remove_range` and `Token.remove_ranges`.\n - Version 0.4 add the class `Span` to `Token` and `Tokens`. `Span` handles the sub-parts splitting of a given string, whereas `Token` and `Tokens` now consumes `Span` objects and handle the attributes of the `Token`. \n - From version 0.5, one has split the basic tools `Span`, `Token` and `Tokens` from the `iamtokenizing` package (see https://pypi.org/project/iamtokenizing/). Only the advanced tokenizer are now present in the package `iamtokenizing`, which depends on the package `tokenspan`. The objects `Span`, `Token` and `Tokens` can be called as before from the newly deployed package `tokenspan`, available on https://pypi.org/project/tokenspan/.\n\n## About us\n\nPackage developped for Natural Language Processing at IAM : Unité d'Informatique et d'Archivistique Médicale, Service d'Informatique Médicale, Pôle de Santé Publique, Centre Hospitalo-Universitaire (CHU) de Bordeaux, France.\n\nYou are kindly encouraged to flag any trouble, and to propose ameliorations and/or suggestions to the authors, via issue or merge requests.\n\nLast version : August 6, 2021\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://framagit.org/nlp/iamtokenizing/",
    "keywords": "",
    "license": "GNU GENERAL PUBLIC LICENSE v.3",
    "maintainer": "",
    "maintainer_email": "",
    "name": "iamtokenizing",
    "package_url": "https://pypi.org/project/iamtokenizing/",
    "platform": null,
    "project_url": "https://pypi.org/project/iamtokenizing/",
    "project_urls": {
      "Homepage": "https://framagit.org/nlp/iamtokenizing/"
    },
    "release_url": "https://pypi.org/project/iamtokenizing/0.7.0/",
    "requires_dist": null,
    "requires_python": ">=3.7",
    "summary": "Simple tokenizers: n-grams and chargrams splitting, white space splitting, or splitting using configurable REGEX expression, or detection into context tokenization. Based on ExtractionString object from the extractionstring package.",
    "version": "0.7.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16304209,
  "releases": {
    "0.3.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8c4763da9abccb50001cf5d1065d6a462d54c3bbbc8dc41a237e395a2b072c09",
          "md5": "86d2891a9c1b160e7a50885a2fc01e65",
          "sha256": "845fed2aa5b9d58c755bfb051eec7ed7651f884e77b33c54f110b52f4692fae9"
        },
        "downloads": -1,
        "filename": "iamtokenizing-0.3.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "86d2891a9c1b160e7a50885a2fc01e65",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 30439,
        "upload_time": "2021-05-28T12:46:54",
        "upload_time_iso_8601": "2021-05-28T12:46:54.647210Z",
        "url": "https://files.pythonhosted.org/packages/8c/47/63da9abccb50001cf5d1065d6a462d54c3bbbc8dc41a237e395a2b072c09/iamtokenizing-0.3.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8e87cd80ade8a663d288e9d9c9a5211d9a7990fe456734d7e05df8e4a7feed83",
          "md5": "6a69a3dd132cf187f1a1d9a299c192af",
          "sha256": "513ef5c0c5a8258ba6ca5de4d93c6f803883badf7ca5317b48b91e324f763803"
        },
        "downloads": -1,
        "filename": "iamtokenizing-0.3.0.tar.gz",
        "has_sig": false,
        "md5_digest": "6a69a3dd132cf187f1a1d9a299c192af",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 28556,
        "upload_time": "2021-05-28T12:46:56",
        "upload_time_iso_8601": "2021-05-28T12:46:56.012859Z",
        "url": "https://files.pythonhosted.org/packages/8e/87/cd80ade8a663d288e9d9c9a5211d9a7990fe456734d7e05df8e4a7feed83/iamtokenizing-0.3.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "80aa046cbf0e2594d1b8401ea0f3af171e1c95c204defa4f131ed062f1bd8005",
          "md5": "3b5d398d762e60cb205846488587d193",
          "sha256": "2f626fd29dce14c641ef5017e605b1a7938aad186c91da23673ef44ac53bb986"
        },
        "downloads": -1,
        "filename": "iamtokenizing-0.3.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "3b5d398d762e60cb205846488587d193",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 30554,
        "upload_time": "2021-05-28T12:55:05",
        "upload_time_iso_8601": "2021-05-28T12:55:05.862165Z",
        "url": "https://files.pythonhosted.org/packages/80/aa/046cbf0e2594d1b8401ea0f3af171e1c95c204defa4f131ed062f1bd8005/iamtokenizing-0.3.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "eb117b257b1799c028815e7a7123e64404ce3967d88477170be2e2c12bf7fcd6",
          "md5": "1b050e58e288a2d3c86f52bc06f9a733",
          "sha256": "68e2e4fc11bdef9ab81ea115d49a4a0382057e7fd9a5d68574e750ddb499ac5a"
        },
        "downloads": -1,
        "filename": "iamtokenizing-0.3.1.tar.gz",
        "has_sig": false,
        "md5_digest": "1b050e58e288a2d3c86f52bc06f9a733",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 28791,
        "upload_time": "2021-05-28T12:55:07",
        "upload_time_iso_8601": "2021-05-28T12:55:07.211666Z",
        "url": "https://files.pythonhosted.org/packages/eb/11/7b257b1799c028815e7a7123e64404ce3967d88477170be2e2c12bf7fcd6/iamtokenizing-0.3.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bd3215cf570eeaf084784d169c351588e9816cf6d9d21cca54878855219f6070",
          "md5": "daee953f0fefc2603911f217160abcc5",
          "sha256": "a2a17785c78dd7e43ca7a0b1ebf31f2bdea727cbec9835912e5e899f18ca2223"
        },
        "downloads": -1,
        "filename": "iamtokenizing-0.4.2.tar.gz",
        "has_sig": false,
        "md5_digest": "daee953f0fefc2603911f217160abcc5",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 18963,
        "upload_time": "2021-08-06T12:53:46",
        "upload_time_iso_8601": "2021-08-06T12:53:46.671506Z",
        "url": "https://files.pythonhosted.org/packages/bd/32/15cf570eeaf084784d169c351588e9816cf6d9d21cca54878855219f6070/iamtokenizing-0.4.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.5.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e94f9db748982a7abbcb45d635f2766f4300a078bb42bd2704c59f09dee911fd",
          "md5": "99b1cf51328fa73a5c69a74e270fdc50",
          "sha256": "8b19678f8b7e401d1862f5784f6f4ae169812816a92f4081778ce912d5c79e82"
        },
        "downloads": -1,
        "filename": "iamtokenizing-0.5.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "99b1cf51328fa73a5c69a74e270fdc50",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 21215,
        "upload_time": "2021-08-06T12:53:45",
        "upload_time_iso_8601": "2021-08-06T12:53:45.366251Z",
        "url": "https://files.pythonhosted.org/packages/e9/4f/9db748982a7abbcb45d635f2766f4300a078bb42bd2704c59f09dee911fd/iamtokenizing-0.5.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "22c7e006cd9d6099673b0f763b02a6d34977c174dcca251b5af22df235750537",
          "md5": "496c98e0cd0da6457a545b845a21cdae",
          "sha256": "c081da19f95560436269bfe4930e8da7b992c8740e03a9dba1042fb2adc18a29"
        },
        "downloads": -1,
        "filename": "iamtokenizing-0.5.0.tar.gz",
        "has_sig": false,
        "md5_digest": "496c98e0cd0da6457a545b845a21cdae",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 18938,
        "upload_time": "2021-08-06T12:53:47",
        "upload_time_iso_8601": "2021-08-06T12:53:47.807135Z",
        "url": "https://files.pythonhosted.org/packages/22/c7/e006cd9d6099673b0f763b02a6d34977c174dcca251b5af22df235750537/iamtokenizing-0.5.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.5.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cb18edfaeffa69419143a9b865ce86ee3f577b9c3bd9affc9bac6ab87f0dbcbe",
          "md5": "5a093deb3b9d60cad93b6ef0dbbcf6f6",
          "sha256": "bd269ad13a3a574dfa152d9c89a3b2b42cf6b0966571febe9d4b4a9f9061d576"
        },
        "downloads": -1,
        "filename": "iamtokenizing-0.5.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "5a093deb3b9d60cad93b6ef0dbbcf6f6",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 20895,
        "upload_time": "2021-08-06T13:01:31",
        "upload_time_iso_8601": "2021-08-06T13:01:31.799156Z",
        "url": "https://files.pythonhosted.org/packages/cb/18/edfaeffa69419143a9b865ce86ee3f577b9c3bd9affc9bac6ab87f0dbcbe/iamtokenizing-0.5.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5e56dd78357db49386a210afc212839f271cf113bdca275a29635a1c3d08fcc4",
          "md5": "0d32d9bfc2774e0c7e89d29444a0de26",
          "sha256": "88b9a06179eb05bf8664792867b79d0dfeb1fc5dfd23f0b129e98d3abd0b1dfa"
        },
        "downloads": -1,
        "filename": "iamtokenizing-0.5.1.tar.gz",
        "has_sig": false,
        "md5_digest": "0d32d9bfc2774e0c7e89d29444a0de26",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 18693,
        "upload_time": "2021-08-06T13:01:35",
        "upload_time_iso_8601": "2021-08-06T13:01:35.006101Z",
        "url": "https://files.pythonhosted.org/packages/5e/56/dd78357db49386a210afc212839f271cf113bdca275a29635a1c3d08fcc4/iamtokenizing-0.5.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.5.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e38a64e436b5331c4125deee4c8ac632980bba8f1c88bba4131261c8f92f1fcc",
          "md5": "1fac62b365c78dd2a7eb78c930329049",
          "sha256": "df5657758bc3ab299219b6ccf247761d05fae6b629d5fab4782d1a6bca137ef9"
        },
        "downloads": -1,
        "filename": "iamtokenizing-0.5.5.linux-x86_64.tar.gz",
        "has_sig": false,
        "md5_digest": "1fac62b365c78dd2a7eb78c930329049",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 12807,
        "upload_time": "2022-01-27T09:45:07",
        "upload_time_iso_8601": "2022-01-27T09:45:07.508855Z",
        "url": "https://files.pythonhosted.org/packages/e3/8a/64e436b5331c4125deee4c8ac632980bba8f1c88bba4131261c8f92f1fcc/iamtokenizing-0.5.5.linux-x86_64.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.5.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8ad120c0566473f1238fba8d1551ca0d24c7d8dc7181864027bdb53d2e59dbc1",
          "md5": "f9d61321c88d9af7921f9131883b659f",
          "sha256": "26e6b6051f59296f585cec518d4a71d3ef94716512912e344a55befb790e7b10"
        },
        "downloads": -1,
        "filename": "iamtokenizing-0.5.6-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f9d61321c88d9af7921f9131883b659f",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 23906,
        "upload_time": "2022-02-17T04:44:01",
        "upload_time_iso_8601": "2022-02-17T04:44:01.614709Z",
        "url": "https://files.pythonhosted.org/packages/8a/d1/20c0566473f1238fba8d1551ca0d24c7d8dc7181864027bdb53d2e59dbc1/iamtokenizing-0.5.6-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3a6403065f157010d60f1e1a05a6633af383d0a1dbcd7edb2ad5646e06705402",
          "md5": "05c8d2bfe5b4b6f29065d169ecdbf61c",
          "sha256": "ab2e81e18d3d51219a177349591a0f296e4eedf31b3ba4a3946315a3b0bd71d7"
        },
        "downloads": -1,
        "filename": "iamtokenizing-0.5.6.tar.gz",
        "has_sig": false,
        "md5_digest": "05c8d2bfe5b4b6f29065d169ecdbf61c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 21601,
        "upload_time": "2022-02-17T04:44:03",
        "upload_time_iso_8601": "2022-02-17T04:44:03.324315Z",
        "url": "https://files.pythonhosted.org/packages/3a/64/03065f157010d60f1e1a05a6633af383d0a1dbcd7edb2ad5646e06705402/iamtokenizing-0.5.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.6.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6f74fb168b3fa06f33c24cf95badbc6a413cfb6804e7ef00d6f898bbd3d5b519",
          "md5": "58e273cb7f68d3b1418f3fc39cbb048d",
          "sha256": "a23a9ebccd8d56084b639d865dc4c503fae4076e6028d00ecbfa0a4f4aa63383"
        },
        "downloads": -1,
        "filename": "iamtokenizing-0.6.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "58e273cb7f68d3b1418f3fc39cbb048d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 23613,
        "upload_time": "2022-02-17T08:35:37",
        "upload_time_iso_8601": "2022-02-17T08:35:37.587457Z",
        "url": "https://files.pythonhosted.org/packages/6f/74/fb168b3fa06f33c24cf95badbc6a413cfb6804e7ef00d6f898bbd3d5b519/iamtokenizing-0.6.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d8db503cee334f8aace419abc8332ce273c65c1c5cc1dec92ae38fed8f603712",
          "md5": "7bc87e54ef461bad97f3d9c938e78271",
          "sha256": "31545a65e9eca45e9105c41a88970a7513ee4aac7383693579d0e4865cb665f8"
        },
        "downloads": -1,
        "filename": "iamtokenizing-0.6.1.tar.gz",
        "has_sig": false,
        "md5_digest": "7bc87e54ef461bad97f3d9c938e78271",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 21628,
        "upload_time": "2022-02-17T08:35:39",
        "upload_time_iso_8601": "2022-02-17T08:35:39.817378Z",
        "url": "https://files.pythonhosted.org/packages/d8/db/503cee334f8aace419abc8332ce273c65c1c5cc1dec92ae38fed8f603712/iamtokenizing-0.6.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.6.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e27eb2fcddcaab3368c35170de307d190f47b6f11ad6e4d08a49e7366571a7a5",
          "md5": "92659e46baef1d503977fb98301debdd",
          "sha256": "472773dea3e2d9a0dc16a294410d283c114723b06db449113ac25887cb0668e5"
        },
        "downloads": -1,
        "filename": "iamtokenizing-0.6.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "92659e46baef1d503977fb98301debdd",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 23620,
        "upload_time": "2022-02-17T08:44:02",
        "upload_time_iso_8601": "2022-02-17T08:44:02.030025Z",
        "url": "https://files.pythonhosted.org/packages/e2/7e/b2fcddcaab3368c35170de307d190f47b6f11ad6e4d08a49e7366571a7a5/iamtokenizing-0.6.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a228aa3f7d737653ca05ad22f1eaad1610d21b10dcb82c9bc0f064d33ea89fb0",
          "md5": "97fd9c7203cc0255f5bae70afdb23be9",
          "sha256": "e4591e7753a458743a5c7f0ae47cbbc5df8cd09e1b739660784fe6920db2470f"
        },
        "downloads": -1,
        "filename": "iamtokenizing-0.6.2.tar.gz",
        "has_sig": false,
        "md5_digest": "97fd9c7203cc0255f5bae70afdb23be9",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 21633,
        "upload_time": "2022-02-17T08:45:07",
        "upload_time_iso_8601": "2022-02-17T08:45:07.753069Z",
        "url": "https://files.pythonhosted.org/packages/a2/28/aa3f7d737653ca05ad22f1eaad1610d21b10dcb82c9bc0f064d33ea89fb0/iamtokenizing-0.6.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.7.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cf030b7f8c76479ad9958a35d6f17067cf42c042362c3c34c3ff960e6c2e7844",
          "md5": "27eec3d19230792d37d5aa4ee6001459",
          "sha256": "b4f5f12ebbb640cc6d9f15d03048528249b7fd99a50d755d3ace665f9a32cebd"
        },
        "downloads": -1,
        "filename": "iamtokenizing-0.7.0.tar.gz",
        "has_sig": false,
        "md5_digest": "27eec3d19230792d37d5aa4ee6001459",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 24358,
        "upload_time": "2023-01-04T16:25:11",
        "upload_time_iso_8601": "2023-01-04T16:25:11.763504Z",
        "url": "https://files.pythonhosted.org/packages/cf/03/0b7f8c76479ad9958a35d6f17067cf42c042362c3c34c3ff960e6c2e7844/iamtokenizing-0.7.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "cf030b7f8c76479ad9958a35d6f17067cf42c042362c3c34c3ff960e6c2e7844",
        "md5": "27eec3d19230792d37d5aa4ee6001459",
        "sha256": "b4f5f12ebbb640cc6d9f15d03048528249b7fd99a50d755d3ace665f9a32cebd"
      },
      "downloads": -1,
      "filename": "iamtokenizing-0.7.0.tar.gz",
      "has_sig": false,
      "md5_digest": "27eec3d19230792d37d5aa4ee6001459",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 24358,
      "upload_time": "2023-01-04T16:25:11",
      "upload_time_iso_8601": "2023-01-04T16:25:11.763504Z",
      "url": "https://files.pythonhosted.org/packages/cf/03/0b7f8c76479ad9958a35d6f17067cf42c042362c3c34c3ff960e6c2e7844/iamtokenizing-0.7.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}