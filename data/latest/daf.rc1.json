{
  "info": {
    "author": "Oren Ben-Kiki",
    "author_email": "oren@ben-kiki.org",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Developers",
      "Intended Audience :: Science/Research",
      "Natural Language :: English",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9",
      "Topic :: Scientific/Engineering :: Bio-Informatics",
      "Topic :: Software Development :: Libraries"
    ],
    "description": "DAF 0.1.0 - Data in Axes in Formats\n=========================================\n\n.. image:: https://readthedocs.org/projects/dafpy/badge/?version=latest\n    :target: https://dafpy.readthedocs.io/en/latest/\n    :alt: Documentation Status\n\nThe daf package provides a uniform generic interface for accessing 1D and 2D data arranged along some set of axes. This\nis a much-needed generalization of the `AnnData <https://pypi.org/project/anndata>`_ functionality. The key features\nare:\n\n* Support both in-memory and persistent data storage of \"any\" format (given an adapter implementation).\n\n* Out of the box, allow storing the data in memory, in ``AnnData`` objects (e.g., using ``h5ad`` files), directly inside\n  `H5FS <https://hdfgroup.org/>`_ files (using `h5py <https://www.h5py.org/>`_), or as a collection of simple\n  memory-mapped files in a directory.\n\n* The data model is based on (1) some axes with named entries, (2) 1-D data indexed by a single axis, (3) 2-D\n  data indexed by a pair of axes, and also (4) 0-D data items (anything not tied to some axis).\n\n* There is explicit control over 2D data layout (row or column major), and support for both dense and sparse matrices,\n  both of which are crucial for performance.\n\n* Allows accessing the data as either plain numpy arrays, scipy csr/csc sparse matrices, or as pandas series/frames.\n\n* Is a pure Python package so should run \"anywhere\" (as long as its dependencies ara available, most notably ``pandas``,\n  ``numpy``, ``scipy`` and ``anndata``).\n\nMotivation\n----------\n\nThe ``daf`` package was created to overcome the limitations of the ``AnnData`` package. Like ``AnnData``, ``daf`` was\ncreated to support code analyzing single-cell RNA sequencing data (\"scRNA-seq\"), but should be useful for other problem\ndomains.\n\nThe main issue we had with ``AnnData`` is that it restricts all the stored data to be described by two axes\n(\"observations\" and \"variables\"). E.g., in single-cell data, every cell would be an \"observation\" and every gene would\nbe a \"variable\". As a secondary annoyance, ``AnnData`` gives one special \"default\" per-observation-per-variable data\nlayer the uninformative name ``X``, and only allows meaningful names for any additional data layers, which use a\ncompletely different access method.\n\nThis works pretty well until one starts to perform higher level operations:\n\n* (Almost) everyone groups cells into \"type\" clusters. This requires storing per-cluster data (e.g. its name and its\n  color).\n\n* Since \"type\" clusters (hopefully) correspond to biological states, which map to gene expression levels, this requires\n  also storing per-cluster-per-gene data.\n\n* Often such clusters form at least a two-level hierarchy, so we need per-sub-cluster data and per-sub-cluster-per-gene\n  data as well.\n\n* We'd like to keep both the UMIs count and the normalized gene fractions (and possibly their log2 values for quick\n  fold factor computations).\n\nSure, it is possible to use a set of ``AnnData`` objects, each with its own distinct set of \"observations\" (for cell,\nclusters, and sub-clusters). We can reduce confusion about what ``X`` is in each data set by always using it for UMIs,\nthough that may not make much sense for some of the data sets. We'll also need to replicate simple per-gene data across\nthe data sets, and keep it in sync, or just store each such data in one of the data sets, and remember in which.\n\nIn short, we'd end up writing some problem-specific code to manage the multiple ``AnnData`` objects for us, which kind\nof defeats the purpose of using ``AnnData`` in the first place. Instead, we have chosen to create ``daf``, which is a\ngeneral-purpose solution that embraces the existence of arbitrary multiple axes in the same data set, and enforces no\nopaque default names, to make it easy for us store explicitly named data per-whatever-we-damn-please all in a single\nplace.\n\nWhen it comes to storage, ``daf`` makes it as easy as possible to write adapters to allow storing the data in your\nfavorite format; in particular, ``daf`` supports ``AnnData`` (or a set of ``AnnData``) as a storage format, which in\nturn allows the data to be stored in various disk file formats such as ``h5ad``. Since ``h5ad`` is restricted by the\n``AnnData`` data model, we also allow directly storing ``daf`` data in an ``h5fs`` file in a more efficient way (that\nis, in ``h5df`` files).\n\nThat said, we find that, for our use cases, the use of complex single-file formats such as ``h5fs`` to be sub-optimal.\nIn effect they function as a file system, but offer only some of its functionality. For example, you need special APIs\nto list the content of the data, copy or delete just parts of it, find out which parts have been changed when, and most\nimplementations do not support memory-mapping the data, which causes a large performance hit for large data sets.\n\nTherefore, as an option, ``daf`` also supports a simple \"files\" storage format where every \"annotation\" is a separate\nfile (in a trivial format) inside a single directory. This allows for efficient memory-mapping of files, using standard\nfile system tools to list, copy and/or delete data, and using tools like ``make`` to automate incremental computations.\nThe main downside is that to send a data set across the network, one has to first collect it into a ``tar`` or ``zip``\narchive. This may actually be more efficient as this allows compressing the data for more efficient transmission or\narchiving. Besides, due to the limitations of ``AnnData``, one has to send multiple files for a complete data set\nanyway.\n\nFinally, ``daf`` also provides a simple in-memory storage format, which is a lightweight container optimized for ``daf``\ndata access (similar to an in-memory ``AnnData`` object).\n\nIt is possible to create views of ``daf`` data (slicing, renaming and hiding axes and/or specific annotations), and to\ncopy ``daf`` data from one data set to another (e.g., from a view of an in-memory data set into an ``AnnData`` data set\nfor exporting it into an ``h5ad`` file).\n\nFinally, the ``daf`` package also provides some convenience functionality out of the box, such as caching derived data\n(different layouts of the same data, sums or other computations along axes, etc.). It is possible to disable such\ncaching (recomputing the derived data every time it is requested), or direct the cache to an arbitrary storage format\n(e.g., keep the derived data cache in-memory on top of a disk-based data set, which is a common usage pattern).\n\nIt is assumed that ``daf`` data will be processed in a single machine, that is, ``daf`` does not try to address the\nissues of a distributed cluster of servers working on a shared data set. Today's servers (as of 2022) can get very big\n(~100 cores and ~1TB of RAM is practical), which means that all/most data sets would fit comfortably in one machine (and\nmemory mapped files are a great help here). In addition, if using the \"files\" storage, it is possible to have different\nservers access the same ``daf`` directory, each computing a different independent additional annotation (e.g., one\nserver searching for doublets while another is searching for gene modules), and as long as only one server writes each\nnew \"annotation\", this should work fine (one can do even better by writing more complex code). This is another example\nof how simple files make it easy to provide functionality which is very difficult to achieve using a complex single-file\nformat such as ``h5fs``.\n\nThe bottom line is that ``daf`` provides a convenient abstraction layer above any \"reasonable\" storage format, allowing\nefficient computation and/or visualization code to naturally access and/or write the data it needs, even for\nhigher-level analysis pipeline, for small to \"very large\" (but not for \"ludicrously large\") data sets.\n\nUsage\n-----\n\n.. code-block:: python\n\n    import daf\n\n    # Open an existing DAF storage in the \"files\" format.\n    data = daf.DafReader(daf.FilesReader(\"...\"))\n\n    # Access arbitrary 0D data.\n    description = data.get_item(\"description\")\n\n    # Get a 1D numpy array by axis and name.\n    metacell_types = data.get_vector(\"metacell;type\")\n\n    # Get a Pandas series by axis and name (index is the type names).\n    type_colors = data.get_series(\"type;color\")\n\n    # Combine these to get a Pandas series of the color of each metacell.\n    metacell_colors = type_colors[metacell_types]\n\n    # Get a 2D matrix by two axes and a name.\n    umis_matrix = data.get_matrix(\"cell,gene;UMIs\")\n\n    if daf.is_dense(umis_matrix):\n        # Umis matrix is dense (2D numpy.ndarray).\n        ...\n    else:\n        assert daf.is_sparse(umis_matrix)\n        # Umis matrix is sparse (scipy.sparse.csr_matrix).\n        ...\n\n    # Get a Pandas data frame with homogeneous elements by two axes and a name.\n    type_marker_genes = data.get_frame(\"gene,type;marker\")\n\n    # Access the mask of marker genes for a specific type as a Pandas series.\n    t_marker_genes = type_marker_genes[\"T\"]\n\n    # Get a Pandas data frame with multiple named (columns) of different types.\n    genes_masks = data.get_columns(\"gene\", [\"forbidden\", \"significant\"])\n\n    # Access the mask of significant genes in the frame as a Pandas series.\n    significant_genes_mask = genes_masks[\"significant\"]\n\n    # Get the total sum of UMIs per cell (and cache it for future requests).\n    cells_umis_sum = data.get_vector(\"cell,gene;UMIs|Sum\")\n\n    #: Slice to include cells with a high number of UMIs and significant genes.\n    strong_data = data.view(\n        axes=dict(cells=cells_umis_sum > 1000, genes=significant_genes_mask)\n    )\n\nSee the `documentation <https://daf.readthedocs.io/en/latest/?badge=latest>`_ for the full API details.\n\nInstallation\n------------\n\nIn short: ``pip install daf``. Note that ``daf`` requires many \"heavy\" dependencies, most notably ``numpy``, ``pandas``,\n``scipy`` and ``anndata``, which ``pip`` should automatically install for you. If you are running inside a ``conda``\nenvironment, you might prefer to use it to first install these dependencies, instead of having ``pip`` install them from\n``PyPI``.\n\nLicense (MIT)\n-------------\n\nCopyright © 2022 Weizmann Institute of Science\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated\ndocumentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the\nrights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit\npersons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the\nSoftware.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE\nWARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\nCOPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\nOTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\nHistory\n=======\n\n0.1.0\n-----\n\n* First published version (alpha).\n\n\n",
    "description_content_type": "text/x-rst",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/tanaylab/daf.git",
    "keywords": "daf",
    "license": "MIT license",
    "maintainer": "",
    "maintainer_email": "",
    "name": "daf",
    "package_url": "https://pypi.org/project/daf/",
    "platform": null,
    "project_url": "https://pypi.org/project/daf/",
    "project_urls": {
      "Homepage": "https://github.com/tanaylab/daf.git"
    },
    "release_url": "https://pypi.org/project/daf/0.1.0/",
    "requires_dist": null,
    "requires_python": ">=3.7",
    "summary": "Data in Axes in Formats",
    "version": "0.1.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14227514,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2393dc26ab9f88a90d08747bed3228ab47d356db9030a37dcb9262800c6c6aee",
          "md5": "60fc7646552dbcd3d6bf6d8a622984ce",
          "sha256": "ac4c0f598299c4c2dd6ca779788a558efe531c4e4f2ece09214cd96ba38c7a1d"
        },
        "downloads": -1,
        "filename": "daf-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "60fc7646552dbcd3d6bf6d8a622984ce",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 116355,
        "upload_time": "2022-06-23T17:05:16",
        "upload_time_iso_8601": "2022-06-23T17:05:16.512887Z",
        "url": "https://files.pythonhosted.org/packages/23/93/dc26ab9f88a90d08747bed3228ab47d356db9030a37dcb9262800c6c6aee/daf-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "2393dc26ab9f88a90d08747bed3228ab47d356db9030a37dcb9262800c6c6aee",
        "md5": "60fc7646552dbcd3d6bf6d8a622984ce",
        "sha256": "ac4c0f598299c4c2dd6ca779788a558efe531c4e4f2ece09214cd96ba38c7a1d"
      },
      "downloads": -1,
      "filename": "daf-0.1.0.tar.gz",
      "has_sig": false,
      "md5_digest": "60fc7646552dbcd3d6bf6d8a622984ce",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 116355,
      "upload_time": "2022-06-23T17:05:16",
      "upload_time_iso_8601": "2022-06-23T17:05:16.512887Z",
      "url": "https://files.pythonhosted.org/packages/23/93/dc26ab9f88a90d08747bed3228ab47d356db9030a37dcb9262800c6c6aee/daf-0.1.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}