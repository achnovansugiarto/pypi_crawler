{
  "info": {
    "author": "Trevor Gokey",
    "author_email": "tgokey@uci.edu",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7"
    ],
    "description": "openff-spellbook\n================\n   <!-- image:: https://img.shields.io/travis/trevorgokey/openff-spellbook.svg -->\n   <!-- :target: https://travis-ci.org/trevorgokey/openff-spellbook -->\n   <!-- image:: https://circleci.com/gh/trevorgokey/openff-spellbook.svg?style=svg -->\n   <!-- :target: https://circleci.com/gh/trevorgokey/openff-spellbook -->\n   <!-- image:: https://codecov.io/gh/trevorgokey/openff-spellbook/branch/master/graph/badge.svg -->\n   <!-- :target: https://codecov.io/gh/trevorgokey/openff-spellbook -->\n\nHandy functionality for working with OpenFF data\n\n# Installation\n\nAvailable on PyPi, so a pip install should work:\n\n``` bash\n\n  $ pip install openff-spellbook\n```\n\nPreferably in a preconfigured virtual environment e.g. conda. Append --user if\nsuch an environment is not being used.\n\nCurrently no dependency checking is performed... depending on the functionality,\nopenforcefield (RDKit), OpenBabel, CMILES, OpenMM, QCElemental, QCPortal, geomeTRIC, and Psi4 are needed.\n\n# Functionality\n\nBottled functionality resides in the `ui` submodule. So far:\n\n<details>\n<summary>The OpenForceField Spellbook TorsionDrive parser and plotter</summary>\n\nThis useful utility is an automated pipeline to save and plot torsiondrive data and figures.\n```\n\n  $ python3 -m offsb.ui.qca.torsiondrive -h\n\n  usage: torsiondrive.py [-h] [--out_file_name OUT_FILE_NAME]\n               [--datasets DATASETS] [--qm-energy]\n               [--mm-energy {None,all,vdw,bonds,angles,dihedrals,outofplanes}]\n               [--openff-name OPENFF_NAME]\n               [--openff-parameter OPENFF_PARAMETER]\n               [--openff-previous OPENFF_PREVIOUS]\n               {torsiondrive_groupby_openff}\n\n  The OpenForceField Spellbook TorsionDrive parser\n\n  positional arguments:\n    {torsiondrive_groupby_openff}\n\n  optional arguments:\n    -h, --help      show this help message and exit\n    --out_file_name OUT_FILE_NAME\n    --datasets DATASETS\n    --qm-energy\n    --mm-energy {None,all,vdw,bonds,angles,dihedrals,outofplanes}\n    --openff-name OPENFF_NAME\n    --openff-parameter OPENFF_PARAMETER\n    --openff-previous OPENFF_PREVIOUS\n```\n</details> \n\n<details>\n<summary>The OpenForceField Spellbook error scanner for QCArchive</summary>\n\n```\n  $ python3 -m offsb.ui.qca.errors -h\n  usage: errors.py [-h] [--save-xyz] [--report-out REPORT_OUT] [--full-report]\n\n  The OpenForceField Spellbook error scanner for QCArchive\n\n  optional arguments:\n    -h, --help      show this help message and exit\n    --save-xyz\n    --report-out REPORT_OUT\n    --full-report\n\n  $ python3 -m offsb.ui.qca.run-optimization\n  usage: run-optimization.py [-h] [-o OUT_JSON] [-i] [-m MEMORY] [-n NTHREADS]\n                 optimization_id molecule_id\n\n  positional arguments:\n    optimization_id   QCA ID of the optimization to run\n    molecule_id     QCA ID of the molecule to use\n\n  optional arguments:\n    -h, --help      show this help message and exit\n    -o OUT_JSON, --out_json OUT_JSON\n              Output json file name\n    -i, --inputs-only   just generate input json; do not run\n    -m MEMORY, --memory MEMORY\n              amount of memory to give to psi4 eg '10GB'\n    -n NTHREADS, --nthreads NTHREADS\n              number of processors to give to psi4\n```\n</details>\n\n<details>\n<summary>The OpenForceField Spellbook energy extractor from QCArchive</summary>\n\n```\n  $ python3 -m offsb.ui.qca.energy-per-molecule\n  usage: energy-per-molecule.py [-h] [--report-out REPORT_OUT]\n\n  The OpenForceField Spellbook energy extractor from QCArchive\n\n  optional arguments:\n    -h, --help      show this help message and exit\n    --report-out REPORT_OUT\n```\n\n</details>\n\n<details>\n<summary>Transform a SMILES string into a QCSchema</summary>\n\n```\n  $ python3 -m offsb.ui.smiles.load -h\n\n  usage: load.py [-h] [-c CUTOFF] [-n MAX_CONFORMERS] [-s LINE_START]\n         [-e LINE_END] [-H HEADER_LINES] [-u] [-i ISOMERS]\n         [-o OUTPUT_FILE] [-f FORMATTED_OUT] [-j] [-m] [--ncpus NCPUS]\n         input\n\n  A tool to transform a SMILES string into a QCSchema. Enumerates stereoisomers\n  if the SMILES is ambiguous, and generates conformers.\n\n  positional arguments:\n    input         Input file containing smiles strings. Assumes that the\n              file is CSV-like, splits on spaces, and the SMILES is\n              the first column\n\n  optional arguments:\n    -h, --help      show this help message and exit\n    -c CUTOFF, --cutoff CUTOFF\n              Prune conformers less than this cutoff using all\n              pairwise RMSD comparisons (in Angstroms)\n    -n MAX_CONFORMERS, --max-conformers MAX_CONFORMERS\n              The number of conformations to attempt generating\n    -s LINE_START, --line-start LINE_START\n              The line in the input file to start processing\n    -e LINE_END, --line-end LINE_END\n              The line in the input file to stop processing (not\n              inclusive)\n    -H HEADER_LINES, --header-lines HEADER_LINES\n              The number of lines at the top of the file to skip\n              before data begins\n    -u, --unique-smiles If stereoisomers are generated, organize molecules by\n              their unambiguous SMILES string\n    -i ISOMERS, --isomers ISOMERS\n              The number of stereoisomers to keep if multiple are\n              found\n    -o OUTPUT_FILE, --output-file OUTPUT_FILE\n              The file to write the output log to\n    -f FORMATTED_OUT, --formatted-out FORMATTED_OUT\n              Write all molecules to a formatted output as qc_schema\n              molecules. Assumes singlets! Choose either --json or\n              --msgpack as the the format\n    -j, --json      Write the formatted output to qc_schema (json) format.\n    -m, --msgpack     Write the formatted output to qc_schema binary message\n              pack (msgpack).\n    --ncpus NCPUS     Number of processes to use.\n```\nAn example output if the SMILES input file is just `C` (methane) would be the following:\n```\n{   \n  \"C\": [\n    {\n      \"schema_name\": \"qcschema_molecule\",\n      \"schema_version\": 2,\n      \"validated\": true,\n      \"symbols\": [\n        \"C\",\n        \"H\",\n        \"H\",\n        \"H\",\n        \"H\"\n      ],\n      \"geometry\": [\n        0.00967296,\n        -0.02006983,\n        0.01136534,\n        1.0387219,\n        1.42757171,\n        -1.12813096,\n        1.41684881,\n        -1.11105294,\n        1.10602765,\n        -1.10880164,\n        -1.23235809,\n        -1.277628,\n        -1.35644204,\n        0.93590916,\n        1.28836596\n      ],\n      \"name\": \"CH4\",\n      \"molecular_charge\": 0.0,\n      \"molecular_multiplicity\": 1,\n      \"connectivity\": [\n        [\n          0,\n          1,\n          1.0\n        ],\n        [\n          0,\n          2,\n          1.0\n        ],\n        [\n          0,\n          3,\n          1.0\n        ],\n        [\n          0,\n          4,\n          1.0\n        ]\n      ],\n      \"fix_com\": false,\n      \"fix_orientation\": false,\n      \"provenance\": {\n        \"creator\": \"QCElemental\",\n        \"version\": \"v0.15.1\",\n        \"routine\": \"qcelemental.molparse.from_schema\"\n      },\n      \"extras\": null\n    }\n  ]\n}\n```\n\n</details>\n\n<details>\n<summary>Submit an Optimization Dataset based on SMILES</summary>\n\nFirst, generate the the JSON for --input-molecules from `python3 -m offsb.ui.smiles.load`. This will\nbe the direct input for `--input-molecules`. Then call the following:\n\n```\n  $ python3 -m offsb.ui.smiles.load -h\n\n  usage: submit-optimizations.py [-h] [--input-molecules INPUT_MOLECULES]\n                   [--metadata METADATA]\n                   [--compute-spec COMPUTE_SPEC]\n                   [--threads THREADS]\n                   [--dataset-name DATASET_NAME] [--server SERVER]\n                   [--priority {low,normal,high}]\n                   [--compute-tag COMPUTE_TAG] [--verbose]\n\n  The OpenFF Spellbook QCArchive Optimization dataset submitter\n\n  optional arguments:\n    -h, --help      show this help message and exit\n    --input-molecules INPUT_MOLECULES\n              A JSON file which contains the QCSchema ready for\n              submission. The json should be a list at the top-\n              level, containing dictionaries with a name as a key,\n              and the value a list of QCMolecules representing the\n              different conformations of the same molecule. Note\n              that entry data, e.g. the CMILES info, should not be\n              specified here as it is generated automatically from\n              this input.\n    --metadata METADATA The JSON file containing the metadata of the dataset.\n    --compute-spec COMPUTE_SPEC\n              A JSON file containing the new compute specification\n              to add to the dataset\n    --threads THREADS   Number of threads to use to communicate with the\n              server\n    --dataset-name DATASET_NAME\n              The name of the dataset. This is needed if the dataset\n              already exists and no metadata is supplied. Useful\n              when e.g. adding computes or molecules to an existing\n              dataset.\n    --server SERVER   The server to connect to. The special value\n              'from_file' will read from the default server\n              connection config file for e.g. authentication\n    --priority {low,normal,high}\n              The priority of the calculations to submit.\n    --compute-tag COMPUTE_TAG\n              The compute tag used to match computations with\n              compute managers. For OpenFF calculations, this should\n              be 'openff'\n    --verbose       Show the progress in the output.\n```\n\nHere, an example `--metadata metadata.json` could be:\n```\n{\n  \"submitter\": \"trevorgokey\",\n  \"creation_date\": \"2020-09-18\",\n  \"collection_type\": \"OptimizationDataset\",\n  \"dataset_name\": \"OpenFF Sandbox CHO PhAlkEthOH v1.0\", \n  \"short_description\": \"A diverse set of CHO molecules\",\n  \"long_description_url\": \"https://github.com/openforcefield/qca-dataset-submission/tree/master/submissions/2020-09-18-OpenFF-Sandbox-CHO-PhAlkEthOH\",\n  \"long_description\": \"This dataset contains an expanded set of the AlkEthOH and PhEthOH datasets, which were used in the original derivation of the frosst specification.\",\n  \"elements\": [\n    \"C\",\n    \"H\",\n    \"O\"\n  ],\n  \"change_log\": [\n    {\"author\": \"trevorgokey\",\n     \"date\": \"2020-09-18\",\n     \"version\": \"1.0\",\n     \"description\": \"A diverse set of CHO molecules. The molecules in this set were generated to include all stereoisomers if chirality was ambiguous from the SMILES input. Conformations were generated which had an RMSD of at least 4 Angstroms from all other conformers\"\n    }\n  ]\n}\n```\n\nAnd if we want to perform both optimizations using B3LYP-D3BJ/DZVP and MM OpenFF 1.0.0, then the JSON file to give to `--compute-spec compute.json` could be the following:\n\n```\n{\"default\":\n  {\"opt_spec\":\n    {\"program\": \"geometric\",\n     \"keywords\":\n      {\"coordsys\": \"tric\",\n       \"enforce\": 0.1,\n       \"reset\": true,\n       \"qccnv\": true,\n       \"epsilon\": 0.0}\n    },\n    \"qc_spec\": {\n      \"driver\": \"gradient\",\n      \"method\": \"b3lyp-d3bj\",\n      \"basis\": \"dzvp\",\n      \"program\": \"psi4\",\n      \"keywords\": {\n        \"maxiter\": 200,\n        \"scf_properties\": [\n          \"dipole\",\n          \"quadrupole\",\n          \"wiberg_lowdin_indices\",\n          \"mayer_indices\"\n        ]\n      }\n    }\n  },\n \"openff-1.0.0\":\n  {\"opt_spec\":\n    {\"program\": \"geometric\",\n     \"keywords\":\n      {\"coordsys\": \"tric\",\n       \"enforce\": 0.1,\n       \"reset\": true,\n       \"qccnv\": true,\n       \"epsilon\": 0.0}\n    },\n    \"qc_spec\": {\n      \"driver\": \"gradient\",\n      \"method\": \"openff-1.0.0\",\n      \"basis\": \"smirnoff\",\n      \"program\": \"openmm\",\n      \"keywords\": { }\n    }\n  }\n}\n```\nNote that the `default` specification is the standard for fitting new versions of the SMIRNOFF OpenForceField.\n\nRunning the command will will produce the following output if `--verbose` is used. First, create the input molecules:\n```\n$ python3 -m offsb.ui.smiles.load methane.smi -n 10 -c 2 -f methane.json -j\n     1 /      1 ENTRY: C\n            ISOMER   1/  1 CONFS: 1 SMILES: C\n            Inputs:      1 Isomers:      1 Conformations:      1\n100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.71it/s]\nTotals:\n  Inputs:   1\n  Isomers:     1\n  Conformations: 1\n```\nNow submit the optimizations (here a private server using `localhost:7777`):\n\n```\n\n$ python3 -m offsb.ui.qca.submit-optimizations --verbose --metadata metadata.json --compute-spec compute.json --server localhost:7777 --priority normal --compute-tag openff --input-molecules methane.json\n\nArguments given:\n{'compute_spec': 'compute.json',\n 'compute_tag': 'openff',\n 'dataset_name': None,\n 'input_molecules': 'methane.json',\n 'metadata': 'metadata.json',\n 'priority': 'normal',\n 'server': 'localhost:7777',\n 'threads': None}\n\nDataset created with the following metadata:\n{'change_log': [{'author': 'trevorgokey',\n         'date': '2020-09-18',\n         'description': 'A diverse set of CHO molecules. The molecules '\n                'in this set were generated to include all '\n                'stereoisomers if chirality was ambiguous from '\n                'the SMILES input. Conformations were '\n                'generated which had an RMSD of at least 4 '\n                'Angstroms from all other conformers',\n         'version': '1.0'}],\n 'collection_type': 'OptimizationDataset',\n 'creation_date': '2020-09-18',\n 'dataset_name': 'OpenFF Sandbox CHO PhAlkEthOH v1.0',\n 'elements': ['C', 'H', 'O'],\n 'long_description': 'This dataset contains an expanded set of the AlkEthOH '\n           'and PhEthOH datasets, which were used in the original '\n           'derivation of the frosst specification.',\n 'long_description_url': 'https://github.com/openforcefield/qca-dataset-submission/tree/master/submissions/2020-09-18-OpenFF-Sandbox-CHO-PhAlkEthOH',\n 'short_description': 'A diverse set of CHO molecules',\n 'submitter': 'trevorgokey'}\n\nSuccessfully added specification default:\n{'opt_spec': {'keywords': {'coordsys': 'tric',\n               'enforce': 0.1,\n               'epsilon': 0.0,\n               'qccnv': True,\n               'reset': True},\n        'program': 'geometric'},\n 'qc_spec': {'basis': 'dzvp',\n       'driver': 'gradient',\n       'keywords': {'maxiter': 200,\n              'scf_properties': ['dipole',\n                       'quadrupole',\n                       'wiberg_lowdin_indices',\n                       'mayer_indices']},\n       'method': 'b3lyp-d3bj',\n       'program': 'psi4'}}\n\nSuccessfully added specification openff-1.0.0:\n{'opt_spec': {'keywords': {'coordsys': 'tric',\n               'enforce': 0.1,\n               'epsilon': 0.0,\n               'qccnv': True,\n               'reset': True},\n        'program': 'geometric'},\n 'qc_spec': {'basis': 'smirnoff',\n       'driver': 'gradient',\n       'keywords': {},\n       'method': 'openff-1.0.0',\n       'program': 'openmm'}}\n\nLoading methane.json into QCArchive...\nNumber of unique molecules: 1\nEntries: 100%|████████████████████████████████████| 1/1 [00:00<00:00, 39.24it/s]\n\nNumber of new entries: 1/1\n\nSubmitting calculations in batches of 20 for specification default\nTasks: 100%|██████████████████████████████████████| 1/1 [00:00<00:00, 16.18it/s]\n\nSubmitting calculations in batches of 20 for specification openff-1.0.0\nTasks: 100%|██████████████████████████████████████| 1/1 [00:00<00:00, 20.08it/s]\n\nNumber of new tasks: 2\n```\n\n</details>\n\nThe format of the file required for `--datasets` in all commands is the following:\n`TYPE NAME WITH SPACES / SPEC1 SPEC2`\nWhere we could specify, using the above dataset submission example, as:\n`OptimizationDataset OpenFF Sandbox CHO PhAlkEthOH v1.0 / default openff-1.0.0`\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/mobleylab/openff-spellbook",
    "keywords": "openff-spellbook",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "openff-spellbook",
    "package_url": "https://pypi.org/project/openff-spellbook/",
    "platform": "",
    "project_url": "https://pypi.org/project/openff-spellbook/",
    "project_urls": {
      "Homepage": "https://github.com/mobleylab/openff-spellbook"
    },
    "release_url": "https://pypi.org/project/openff-spellbook/0.0.8/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "Handy functionality for working with OpenFF data",
    "version": "0.0.8",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 8242603,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "01233e1311150dc2274ffba348ffcaffc3848d46bd79aaa4bc2916e0bd2419a4",
          "md5": "0a88c2033196e7712596fc39e2601d90",
          "sha256": "78896dfc421c8dc977ae1601d8651b36e7c07a24f259592354884a2f64bd92ef"
        },
        "downloads": -1,
        "filename": "openff_spellbook-0.0.1-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0a88c2033196e7712596fc39e2601d90",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": ">=3.6",
        "size": 63992,
        "upload_time": "2020-07-28T23:20:45",
        "upload_time_iso_8601": "2020-07-28T23:20:45.800412Z",
        "url": "https://files.pythonhosted.org/packages/01/23/3e1311150dc2274ffba348ffcaffc3848d46bd79aaa4bc2916e0bd2419a4/openff_spellbook-0.0.1-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5cdd3674a94500d6fb3dd07d9aff8c9993ad140b878a1f98f7e2364ccfe69cf2",
          "md5": "754a56f6516fa5daf23aa34dc7a67d91",
          "sha256": "89aa92cd75b490e4eebd4610a43b5c1c1edd041a8e83e031e9c0b56ee65db2fa"
        },
        "downloads": -1,
        "filename": "openff-spellbook-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "754a56f6516fa5daf23aa34dc7a67d91",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 63200,
        "upload_time": "2020-07-28T23:20:48",
        "upload_time_iso_8601": "2020-07-28T23:20:48.159405Z",
        "url": "https://files.pythonhosted.org/packages/5c/dd/3674a94500d6fb3dd07d9aff8c9993ad140b878a1f98f7e2364ccfe69cf2/openff-spellbook-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f7d770056323901923a71e163659d7f0ff486addc41732dbf5d5373d39fe896b",
          "md5": "9218d21a4c94d2db0135ca645efe7393",
          "sha256": "b2378a7682e4a8c6118fdbf043bf8cfcb7baca60c10a5a32bdd67f7107c0043a"
        },
        "downloads": -1,
        "filename": "openff_spellbook-0.0.2-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "9218d21a4c94d2db0135ca645efe7393",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": ">=3.6",
        "size": 63992,
        "upload_time": "2020-07-29T06:49:05",
        "upload_time_iso_8601": "2020-07-29T06:49:05.952771Z",
        "url": "https://files.pythonhosted.org/packages/f7/d7/70056323901923a71e163659d7f0ff486addc41732dbf5d5373d39fe896b/openff_spellbook-0.0.2-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9f702546eab06484f590333744ead23493a63281025a3c81b53c323904fec019",
          "md5": "6b9295ee250312d1fa3198ca0c6596ea",
          "sha256": "787d39e0f125a854601e02bfef3dcafc9f6b8a89bc90cec0168bb5feef6ba338"
        },
        "downloads": -1,
        "filename": "openff-spellbook-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "6b9295ee250312d1fa3198ca0c6596ea",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 63198,
        "upload_time": "2020-07-29T06:49:07",
        "upload_time_iso_8601": "2020-07-29T06:49:07.766780Z",
        "url": "https://files.pythonhosted.org/packages/9f/70/2546eab06484f590333744ead23493a63281025a3c81b53c323904fec019/openff-spellbook-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3a675d4bb61c9b9d4b2c7a880347dace819011b5a7d1ae39e1f6f57c7cf05ab3",
          "md5": "d62b53d3e4b41f42c08eb899b277cb31",
          "sha256": "57b6b3c3ec4bed5b6affa89238fdddb71fb8df62d6dd01ae2af345a3d44da7d8"
        },
        "downloads": -1,
        "filename": "openff_spellbook-0.0.5-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d62b53d3e4b41f42c08eb899b277cb31",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": ">=3.6",
        "size": 91452,
        "upload_time": "2020-09-21T03:49:28",
        "upload_time_iso_8601": "2020-09-21T03:49:28.983231Z",
        "url": "https://files.pythonhosted.org/packages/3a/67/5d4bb61c9b9d4b2c7a880347dace819011b5a7d1ae39e1f6f57c7cf05ab3/openff_spellbook-0.0.5-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "68c2e1122ac6ac900382ab4a8980cb9e996b169792545f894b6c9016c8808b6b",
          "md5": "a44f091a22e11049bf37331d9dd3e13b",
          "sha256": "127609af80508ecf3dc729dcd38c742fd66918febd4f37f9bb75c0b82b2432de"
        },
        "downloads": -1,
        "filename": "openff-spellbook-0.0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "a44f091a22e11049bf37331d9dd3e13b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 2746095,
        "upload_time": "2020-09-21T03:49:31",
        "upload_time_iso_8601": "2020-09-21T03:49:31.691991Z",
        "url": "https://files.pythonhosted.org/packages/68/c2/e1122ac6ac900382ab4a8980cb9e996b169792545f894b6c9016c8808b6b/openff-spellbook-0.0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e4ea84cab4e4301580b005783713854e8d7182527ea62e24ed1aceb0e0bd811c",
          "md5": "26cd4f1ca5626e13815842689886cb6b",
          "sha256": "46204e39689424e3d21a68916b7289c3aecac4d8e9b5fa6d35a3a798a4370072"
        },
        "downloads": -1,
        "filename": "openff_spellbook-0.0.6-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "26cd4f1ca5626e13815842689886cb6b",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": ">=3.6",
        "size": 106714,
        "upload_time": "2020-09-22T07:23:58",
        "upload_time_iso_8601": "2020-09-22T07:23:58.136682Z",
        "url": "https://files.pythonhosted.org/packages/e4/ea/84cab4e4301580b005783713854e8d7182527ea62e24ed1aceb0e0bd811c/openff_spellbook-0.0.6-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a07c1ead9e1e85b8a859b81272a5a58b8efbcd87b9932b2548d503c4f9286f11",
          "md5": "caf7102d9b5850da60d0f6a3de3bdc0f",
          "sha256": "8846b1211c3a441522929a36c2058dfe2207aeb0e0de2d9125e4c068b236f2d0"
        },
        "downloads": -1,
        "filename": "openff-spellbook-0.0.6.tar.gz",
        "has_sig": false,
        "md5_digest": "caf7102d9b5850da60d0f6a3de3bdc0f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 2746285,
        "upload_time": "2020-09-22T07:24:01",
        "upload_time_iso_8601": "2020-09-22T07:24:01.049174Z",
        "url": "https://files.pythonhosted.org/packages/a0/7c/1ead9e1e85b8a859b81272a5a58b8efbcd87b9932b2548d503c4f9286f11/openff-spellbook-0.0.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5c2d3f7ba893b141d9dc179e6c8d493518287933c4a081fb6619342aef97fa09",
          "md5": "5c532aa9de1b183372b079d65fa75b0b",
          "sha256": "57898faaea691757cd335c60e6bcde8690d1a4730ba5321afaa0d386a841f9d4"
        },
        "downloads": -1,
        "filename": "openff_spellbook-0.0.8-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "5c532aa9de1b183372b079d65fa75b0b",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": ">=3.6",
        "size": 106794,
        "upload_time": "2020-09-22T09:20:38",
        "upload_time_iso_8601": "2020-09-22T09:20:38.966095Z",
        "url": "https://files.pythonhosted.org/packages/5c/2d/3f7ba893b141d9dc179e6c8d493518287933c4a081fb6619342aef97fa09/openff_spellbook-0.0.8-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "45b49d4aeb65e054d51f10c5446b11f3567fa17110da0e03bc46c389d7ea1597",
          "md5": "e471c2f6c168fe6c398652c22f6f2900",
          "sha256": "9aed7eac77f134be1c490d6e93fa90578bb0db46117c316a11f9226ed2001d46"
        },
        "downloads": -1,
        "filename": "openff-spellbook-0.0.8.tar.gz",
        "has_sig": false,
        "md5_digest": "e471c2f6c168fe6c398652c22f6f2900",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 2746381,
        "upload_time": "2020-09-22T09:20:42",
        "upload_time_iso_8601": "2020-09-22T09:20:42.149971Z",
        "url": "https://files.pythonhosted.org/packages/45/b4/9d4aeb65e054d51f10c5446b11f3567fa17110da0e03bc46c389d7ea1597/openff-spellbook-0.0.8.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "5c2d3f7ba893b141d9dc179e6c8d493518287933c4a081fb6619342aef97fa09",
        "md5": "5c532aa9de1b183372b079d65fa75b0b",
        "sha256": "57898faaea691757cd335c60e6bcde8690d1a4730ba5321afaa0d386a841f9d4"
      },
      "downloads": -1,
      "filename": "openff_spellbook-0.0.8-py2.py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "5c532aa9de1b183372b079d65fa75b0b",
      "packagetype": "bdist_wheel",
      "python_version": "py2.py3",
      "requires_python": ">=3.6",
      "size": 106794,
      "upload_time": "2020-09-22T09:20:38",
      "upload_time_iso_8601": "2020-09-22T09:20:38.966095Z",
      "url": "https://files.pythonhosted.org/packages/5c/2d/3f7ba893b141d9dc179e6c8d493518287933c4a081fb6619342aef97fa09/openff_spellbook-0.0.8-py2.py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "45b49d4aeb65e054d51f10c5446b11f3567fa17110da0e03bc46c389d7ea1597",
        "md5": "e471c2f6c168fe6c398652c22f6f2900",
        "sha256": "9aed7eac77f134be1c490d6e93fa90578bb0db46117c316a11f9226ed2001d46"
      },
      "downloads": -1,
      "filename": "openff-spellbook-0.0.8.tar.gz",
      "has_sig": false,
      "md5_digest": "e471c2f6c168fe6c398652c22f6f2900",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 2746381,
      "upload_time": "2020-09-22T09:20:42",
      "upload_time_iso_8601": "2020-09-22T09:20:42.149971Z",
      "url": "https://files.pythonhosted.org/packages/45/b4/9d4aeb65e054d51f10c5446b11f3567fa17110da0e03bc46c389d7ea1597/openff-spellbook-0.0.8.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}