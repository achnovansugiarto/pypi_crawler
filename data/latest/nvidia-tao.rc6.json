{
  "info": {
    "author": "Varun Praveen",
    "author_email": "vpraveen@nvidia.com",
    "bugtrack_url": null,
    "classifiers": [
      "Environment :: Console",
      "Intended Audience :: Developers",
      "License :: Other/Proprietary License",
      "Programming Language :: Python :: 3",
      "Topic :: Scientific/Engineering :: Artificial Intelligence",
      "Topic :: Software Development :: Libraries",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "# TAO Toolkit Quick Start\n\nThe NVIDIA TAO Toolkit, built on TensorFlow and PyTorch, simplifies and accelerates the model training process by abstracting away the complexity of AI models and the deep learning framework. You can use the power of transfer learning to fine-tune NVIDIA pretrained models with your own data and optimize the model for inference throughput â€” all without the need for AI expertise or large training datasets.\n\n[TAO quick start video](https://www.nvidia.com/en-us/on-demand/session/other2022-tao/).\n\n## Requirements\n\n### Minimum Hardware requirements\n\nThe following system configuration is recommended to achieve reasonable training performance with TAO Toolkit and supported models provided:\n\n* 32 GB system RAM\n* 32 GB of GPU RAM\n* 8 core CPU\n* 1 NVIDIA GPU\n* 100 GB of SSD space\n\nTAO Toolkit is supported on discrete GPUs, such as A100, A40, A30, A2, A16, A100x, A30x, V100, T4, Titan-RTX and Quadro-RTX.\n\n> Note: TAO Toolkit is not supported on GPU's before the Pascal generation\n\n### Software requirements\n\n| **Software**                     | **Version** | **Comment** |\n| :--- | :--- | :-- |\n| Ubuntu LTS                       | 20.04       ||\n| python                           | >=3.6.9<3.7 | Not needed if you are using TAO API \\(See #3 below\\) |\n| docker-ce                        | >19.03.5    | Not needed if you are using TAO API \\(See #3 below\\) |\n| docker-API                       | 1.40        | Not needed if you are using TAO API \\(See #3 below\\) |\n| `nvidia-container-toolkit`       | >1.3.0-1    | Not needed if you are using TAO API \\(See #3 below\\) |\n| nvidia-container-runtime         | 3.4.0-1     | Not needed if you are using TAO API \\(See #3 below\\) |\n| nvidia-docker2                   | 2.5.0-1     | Not needed if you are using TAO API \\(See #3 below\\) |\n| nvidia-driver                    | >520        | Not needed if you are using TAO API \\(See #3 below\\) |\n| python-pip                       | >21.06      | Not needed if you are using TAO API \\(See #3 below\\) |\n\n## Package Content\n\nDownload the TAO package which contains startup scripts, Jupyter notebooks and config files. <br>\nTAO is supported on Google Colab; if you want to try on Colab, you can skip this step and directly scroll down to [#4 in the How to run TAO](#colab) section.\n\n    wget --content-disposition https://api.ngc.nvidia.com/v2/resources/nvidia/tao/tao_getting_started/versions/4.0.0/zip -O getting_started_v4.0.0.zip\n    unzip -u getting_started_v4.0.0.zip  -d ./getting_started_v4.0.0 && rm -rf getting_started_v4.0.0.zip && cd ./getting_started_v4.0.0\n\n### File Hierarchy\n\n    setup\n        |--> quickstart_launcher.sh\n        |--> quickstart_api_bare_metal\n        |--> quickstart_api_aws_eks\n    notebooks\n        |--> tao_api_starter_kit\n            |--> api\n                |--> automl\n                |--> end2end\n                |--> dataset_prepare\n            |--> client\n                |--> automl\n                |--> end2end\n                |--> dataset_prepare\n        |--> tao_launcher_starter_kit\n            |--> yolov4_tiny\n            |--> yolov4\n            |--> yolov3\n            |-->  ...\n\n## How to run TAO?\n\nTAO is available as a docker container or as a collection of Python wheels.\n\nThere are 4 ways to run TAO depending on user preference and their setup. See the full list below.\n\n#### 1. Launcher CLI\n\nThe TAO Launcher is a lightweight Python based CLI application to run TAO. The launcher basically acts as a front-end for the multiple TAO Toolkit containers built on both PyTorch and Tensorflow. The multiple containers essentially get launched automatically based on the type of  model you plan to use for your computer vision or conversational AI use-cases.  \n\n<p align=\"center\">\n<img src=\"https://github.com/vpraveen-nv/model_card_images/raw/main/api/tao_launcher.jpg\" width=\"300\"> <br>TAO Launcher<br>\n</p>\n\nTo get started, use the `setup/quickstart_launcher.sh` to validate your setup and install TAO launcher. Jupyter notebooks to train using the Launcher is provided under `notebooks/launcher_starter_kit`.\n\nDetail instructions on installing pre-requisite and setup is provided in [TAO documentation - Launcher](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_quick_start_guide.html)\n\n#### 2. Directly from Container\n\nUsers have option to also run TAO directly using the docker container. To use container directly, user needs to know which container to pull. There are multiple containers under TAO, and depending on the model that you want to train you will need to pull the appropriate container. This is not required when using the Launcher CLI.\n\n    export DOCKER_REGISTRY=\"nvcr.io\"\n    export DOCKER_NAME=\"nvidia/tao/tao-toolkit\"\n    export DOCKER_TAG=\"***\" ## for TensorFlow docker\n    export DOCKER_TAG=\"***\" ## for PyTorch docker\n    export DOCKER_CONTAINER=$DOCKER_REGISTRY/$DOCKER_NAME:$DOCKER_TAG\n\n    docker run -it --rm --gpus all -v /path/in/host:/path/in/docker $DOCKER_CONTAINER \\\n    detectnet_v2 train -e /path/to/experiment/spec.txt -r /path/to/results/dir -k $KEY --gpus 4\n\nMore information about running directly from docker  is provided in [TAO documentation - Container](https://docs.nvidia.com/tao/tao-toolkit/text/working_with_the_containers.html)\n\n#### 3. TAO APIs\n\nTAO Toolkit API is a Kubernetes service that enables building end-to-end AI models using REST APIs. The API service can be installed on a Kubernetes cluster (local / AWS EKS) using a Helm chart along with minimal dependencies. TAO toolkit jobs can be run using GPUs available on the cluster and can scale to a multi-node setting. Users can use a TAO client CLI to interact with TAO services remotely or can integrate it in their own apps and services directly using REST APIs.\n\n<p align=\"center\">\n<img src=\"https://docs.nvidia.com/tao/tao-toolkit/_images/tao_toolkit_api.png\" width=\"500\"> <br>TAO API<br>\n</p>\n\nTo get started, use the provided one-click deploy script to deploy either on bare-metal setup or on managed Kubernetes service like Amazon EKS. Jupyter notebooks to train using the APIs directly or using the client app is provided under `notebooks/api_starter_kit`<br>\n`setup/quickstart_api_bare_metal`<br>\n`setup/quickstart_api_aws_eks`<br>\n\nMore information about setting up the API services and the API is provided in [TAO documentation - API](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_api/api_overview.html)\n\n#### 4. Python Wheel <a class=\"anchor\" name=\"colab\"></a>\n\nUsers can also run TAO directly on bare-metal without docker or K8s. Users can deploy TAO notebooks directly on Google Colab without having to configure infrastructure. The full instructions are provided in the Colab notebook below.\n\n| **CV Task** | **Model Arch** | **One-click Deploy** |\n| :--- | :--- | :-- |\n| Classification | ResNet18 | [Train on Colab](https://colab.research.google.com/github/NVIDIA-AI-IOT/nvidia-tao/blob/main/tensorflow/classification/classification.ipynb) |\n| Multi-task Classification | ResNet18 | [Train on Colab](https://colab.research.google.com/github/NVIDIA-AI-IOT/nvidia-tao/blob/main/tensorflow/multitask_classification/multitask_classification.ipynb) |\n| Object Detection | Deformable-DETR | [Train on Colab](https://colab.research.google.com/github/NVIDIA-AI-IOT/nvidia-tao/blob/main/pytorch/cv_notebooks/deformable_detr/deformable_detr.ipynb) |\n| Object Detection | DSSD | [Train on Colab](https://colab.research.google.com/github/NVIDIA-AI-IOT/nvidia-tao/blob/main/tensorflow/dssd/dssd.ipynb) |\n| Object Detection | EfficientDet | [Train on Colab](https://colab.research.google.com/github/NVIDIA-AI-IOT/nvidia-tao/blob/main/tensorflow/efficientdet/efficientdet.ipynb) |\n| Object Detection | RetinaNet | [Train on Colab](https://colab.research.google.com/github/NVIDIA-AI-IOT/nvidia-tao/blob/main/tensorflow/retinanet/retinanet.ipynb) |\n| Object Detection | SSD | [Train on Colab](https://colab.research.google.com/github/NVIDIA-AI-IOT/nvidia-tao/blob/main/tensorflow/ssd/ssd.ipynb) |\n| Object Detection | YOLOv3 | [Train on Colab](https://colab.research.google.com/github/NVIDIA-AI-IOT/nvidia-tao/blob/main/tensorflow/yolo_v3/yolo_v3.ipynb) |\n| Object Detection | YOLOv4 | [Train on Colab](https://colab.research.google.com/github/NVIDIA-AI-IOT/nvidia-tao/blob/main/tensorflow/yolo_v4/yolo_v4.ipynb) |\n| Object Detection | YoloV4 Tiny | [Train on Colab](https://colab.research.google.com/github/NVIDIA-AI-IOT/nvidia-tao/blob/main/tensorflow/yolo_v4_tiny/yolo_v4_tiny.ipynb) |\n| Action Recognition | ActionRecognition | [Train on Colab](https://colab.research.google.com/github/NVIDIA-AI-IOT/nvidia-tao/blob/main/pytorch/cv_notebooks/action_recognition_net/actionrecognitionnet.ipynb) |\n| OCR | LPRNet | [Train on Colab](https://colab.research.google.com/github/NVIDIA-AI-IOT/nvidia-tao/blob/main/tensorflow/lprnet/lprnet.ipynb) |\n| Pose Action Classification  |  PoseClassificationNet  | [Train on Colab](https://colab.research.google.com/github/NVIDIA-AI-IOT/nvidia-tao/blob/main/pytorch/cv_notebooks/pose_classification_net/poseclassificationnet.ipynb) |\n| 3D Point Cloud | PointPillar | [Train on Colab](https://colab.research.google.com/github/NVIDIA-AI-IOT/nvidia-tao/blob/main/pytorch/cv_notebooks/pointpillars/pointpillars.ipynb) |\n| Emotion Recognition | EmotionNet | [Train on Colab](https://colab.research.google.com/github/NVIDIA-AI-IOT/nvidia-tao/blob/main/tensorflow/emotionnet/emotionnet.ipynb) |\n| Gesture Recognition | GestureNet | [Train on Colab](https://colab.research.google.com/github/NVIDIA-AI-IOT/nvidia-tao/blob/main/tensorflow/gesturenet/gesturenet.ipynb) |\n| Heart Rate Estimation | HeartRateNet | [Train on Colab](https://colab.research.google.com/github/NVIDIA-AI-IOT/nvidia-tao/blob/main/tensorflow/heartratenet/heartratenet.ipynb) |\n<br>\nAfter starting TAO service locally or remotely, start Jupyter notebook\n\n    jupyter notebook --ip 0.0.0.0 --port 8888 --allow-root\n\nOpen an internet browser on localhost and navigate to the following URL: <http://0.0.0.0:8888>\n\nOpen the notebook that you are interested in training and start training.\n\n> Note: All the instructions to train, prune, optimize and download pretrained models are provided in the notebook.\n\n## Jupyter notebooks\n\nAll Notebooks and required spec files are provided in this package. The table below maps which notebook to use for fine-tuning either a purpose-build models like PeopleNet or an open model architecture like YOLO.\n\n|**Purpose-built Model** | **Launcher CLI notebook** |\n|:--|:--|\n| PeopleNet | notebooks/tao_launcher_starter_kit/detectnet_v2/detectnet_v2.ipynb |\n| TrafficCamNet | notebooks/tao_launcher_starter_kit/detectnet_v2/detectnet_v2.ipynb |\n| DashCamNet | notebooks/tao_launcher_starter_kit/detectnet_v2/detectnet_v2.ipynb |\n| FaceDetectIR| notebooks/tao_launcher_starter_kit/detectnet_v2/detectnet_v2.ipynb |\n| VehicleMakeNet | notebooks/tao_launcher_starter_kit/classification/classification.ipynb |\n| VehicleTypeNet | notebooks/tao_launcher_starter_kit/classification/classification.ipynb |\n| PeopleSegNet | notebooks/tao_launcher_starter_kit/mask_rcnn/mask_rcnn.ipynb |\n| PeopleSemSegNet | notebooks/tao_launcher_starter_kit/unet/unet_isbi.ipynb |\n| Bodypose Estimation | notebooks/tao_launcher_starter_kit/bpnet/bpnet.ipynb |\n| License Plate Detection | notebooks/tao_launcher_starter_kit/detectnet_v2/detectnet_v2.ipynb |\n| License Plate Recognition | notebooks/tao_launcher_starter_kit/lprnet/lprnet.ipynb |\n| Gaze Estimation | notebooks/tao_launcher_starter_kit/gazenet/gazenet.ipynb |\n| Facial Landmark | notebooks/tao_launcher_starter_kit/fpenet/fpenet.ipynb |\n| Heart Rate Estimation | notebooks/tao_launcher_starter_kit/heartratenet/heartratenet.ipynb |\n| Gesture Recognition | notebooks/tao_launcher_starter_kit/gesturenet/gesturenet.ipynb |\n| Emotion Recognition | notebooks/tao_launcher_starter_kit/emotionnet/emotionnet.ipynb |\n| FaceDetect | notebooks/tao_launcher_starter_kit/facenet/facenet.ipynb |\n| ActionRecognitionNet | notebooks/tao_launcher_starter_kit/action_recognition_net/actionrecognitionnet.ipynb |\n| PoseClassificationNet | notebooks/tao_launcher_starter_kit/pose_classification_net/pose_classificationnet.ipynb |\n| Pointpillars | notebooks/tao_launcher_starter_kit/pointpillars/pointpillars.ipynb |\n| ReIdentificationNet | notebooks/tao_launcher_starter_kit/re_identification_net/reidentificationnet.ipynb |\n<br>\n\n|**Open model architecture**| **Jupyter notebook** |\n|:--|:--|\n| Deformable-DETR | notebooks/tao_launcher_starter_kit/deformable_detr/deformable_detr.ipynb |\n| SegFormer | notebooks/tao_launcher_starter_kit/segformer/segformer.ipynb |\n| DetectNet_v2 | notebooks/tao_launcher_starter_kit/detectnet_v2/detectnet_v2.ipynb |\n| FasterRCNN | notebooks/tao_launcher_starter_kit/faster_rcnn/faster_rcnn.ipynb |\n| YOLOV3 | notebooks/tao_launcher_starter_kit/yolo_v3/yolo_v3.ipynb |\n| YOLOV4 | notebooks/tao_launcher_starter_kit/yolo_v4/yolo_v4.ipynb |\n| YOLOv4-Tiny | notebooks/tao_launcher_starter_kit/yolo_v4_tiny/yolo_v4_tiny.ipynb |\n| SSD | notebooks/tao_launcher_starter_kit/ssd/ssd.ipynb |\n| DSSD | notebooks/tao_launcher_starter_kit/dssd/dssd.ipynb |\n| RetinaNet | notebooks/tao_launcher_starter_kit/retinanet/retinanet.ipynb |\n| MaskRCNN | notebooks/tao_launcher_starter_kit/mask_rcnn/mask_rcnn.ipynb |\n| UNET | notebooks/tao_launcher_starter_kit/unet/unet_isbi.ipynb |\n| Image Classification | notebooks/tao_launcher_starter_kit/classification/classification.ipynb |\n| EfficientDet | notebooks/tao_launcher_starter_kit/efficientdet/efficientdet.ipynb |\n<br>\n\n**Conversational AI**\n\nFor Conversational AI, all notebooks are available on NGC. Please download the notebook from the appropriate NGC resource as mentioned in the table below.\n\n| **Conversational AI Task**     | **Jupyter Notebooks**                  |\n| :--- | :--- |\n| Speech to Text Citrinet        | [Speech to Text Citrinet Notebook](https://ngc.nvidia.com/catalog/resources/nvidia:tao:speechtotext_citrinet_notebook) |\n| Speech to Text Conformer       | [Speech to Text Conformer Notebook](https://ngc.nvidia.com/catalog/resources/nvidia:tao:speechtotext_citrinet_notebook)   |\n| Question Answering             | [Question Answering Notebook](https://ngc.nvidia.com/catalog/resources/nvidia:tao:questionanswering_notebook)|\n| Text Classification            | [Text Classification Notebook](https://ngc.nvidia.com/catalog/resources/nvidia:tao:textclassification_notebook)        |\n| Token Classification           | [Token Classification Notebook](https://ngc.nvidia.com/catalog/resources/nvidia:tao:tokenclassification_notebook)|\n| Punctuation and Capitalization | [Punctuation Capitalization Notebook](https://ngc.nvidia.com/catalog/resources/nvidia:tao:punctuationcapitalization_notebook) |\n| Intent and Slot Classification | [Intent Slot Classification Notebook](https://ngc.nvidia.com/catalog/resources/nvidia:tao:intentslotclassification_notebook)|\n| NGram Language Model           | [NGram Language Model Notebook](https://ngc.nvidia.com/catalog/resources/nvidia:tao:ngram_lm_notebook)       |\n| Text to Speech                 | [Text to Speech Notebook](https://ngc.nvidia.com/catalog/resources/nvidia:tao:texttospeech_notebook)             |\n\n## Important Links\n\n* [TAO Toolkit Documentation](https://docs.nvidia.com/tao/tao-toolkit/text/overview.html)\n* [TAO for CV (TensorFlow)](https://ngc.nvidia.com/catalog/containers/nvidia:tao:tao-toolkit-tf)\n* [TAO for CV (PyTorch)](https://ngc.nvidia.com/catalog/containers/nvidia:tao:tao-toolkit-pyt)\n* [TAO for Conversational AI](https://ngc.nvidia.com/catalog/containers/nvidia:tao:tao-toolkit-pyt)\n\n## Blogs\n\n[Synthetic Data and TAO](https://developer.nvidia.com/blog/developing-and-deploying-ai-powered-robots-with-nvidia-isaac-sim-and-nvidia-tao/) <br>\n[Action Recognition Blog](https://developer.nvidia.com/blog/developing-and-deploying-your-custom-action-recognition-application-without-any-ai-expertise-using-tao-and-deepstream/) <br>\n[Real-time License Plate Detection](https://developer.nvidia.com/blog/creating-a-real-time-license-plate-detection-and-recognition-app/) <br>\n[2 Pose Estimation: Part 1](https://developer.nvidia.com/blog/training-optimizing-2d-pose-estimation-model-with-tao-toolkit-part-1/) <br>\n[Part 2](https://developer.nvidia.com/blog/training-optimizing-2d-pose-estimation-model-with-tao-toolkit-part-2/) <br>\n[Building ConvAI with TAO Toolkit](https://developer.nvidia.com/blog/building-and-deploying-conversational-ai-models-using-tao-toolkit/) <br>\n\n## License <a class=\"anchor\" name=\"license\"></a>\n\n[TAO Toolkit getting Started](https://docs.nvidia.com/tao/tao-toolkit/text/tao_quick_start_guide.html)\nLicense for TAO containers is included within the container at `workspace/EULA.pdf`. License for the pre-trained models are available with the model files. By pulling and using the Train Adapt Optimize (TAO) Toolkit container to download models, you accept the terms and conditions of these [licenses](https://developer.nvidia.com/tao-toolkit-software-license-agreement).\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "nvidia,tao,launcher",
    "license": "NVIDIA Proprietary Software",
    "maintainer": "",
    "maintainer_email": "",
    "name": "nvidia-tao",
    "package_url": "https://pypi.org/project/nvidia-tao/",
    "platform": null,
    "project_url": "https://pypi.org/project/nvidia-tao/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/nvidia-tao/4.0.1/",
    "requires_dist": [
      "certifi",
      "chardet (==3.0.4)",
      "docker (==4.3.1)",
      "requests",
      "docker-pycreds (==0.4.0)",
      "idna (==2.10)",
      "six (==1.15.0)",
      "tabulate (==0.8.7)",
      "urllib3 (>=1.26.5)",
      "websocket-client (==0.57.0)"
    ],
    "requires_python": ">=3.6.*",
    "summary": "NVIDIA's Launcher for TAO Toolkit.",
    "version": "4.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17177567,
  "releases": {
    "0.1.21": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1418d4919cc3cb4caf111fff934374b124428746a37a6f6a61ae3e1604b9e8ba",
          "md5": "62551d8268cacf6243ab898cc788b8b3",
          "sha256": "d0d60d24805e05625d2dfdc76a342aa33a06aa60df237719b40c12f9ee865706"
        },
        "downloads": -1,
        "filename": "nvidia_tao-0.1.21-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "62551d8268cacf6243ab898cc788b8b3",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6.*",
        "size": 149674,
        "upload_time": "2022-03-18T18:24:32",
        "upload_time_iso_8601": "2022-03-18T18:24:32.850555Z",
        "url": "https://files.pythonhosted.org/packages/14/18/d4919cc3cb4caf111fff934374b124428746a37a6f6a61ae3e1604b9e8ba/nvidia_tao-0.1.21-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.23": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2f525c95380c254d1d1d3376b0d469685e2a95903eb939e934e644ffd7f0fa40",
          "md5": "8748485ffa6ffdd607523d46c897f35f",
          "sha256": "fdc082cbdd6851b514f0c6fffcc886d20b8c2ba50fdc84e953994e50f0a6184a"
        },
        "downloads": -1,
        "filename": "nvidia_tao-0.1.23-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "8748485ffa6ffdd607523d46c897f35f",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6.*",
        "size": 149592,
        "upload_time": "2022-06-01T20:54:58",
        "upload_time_iso_8601": "2022-06-01T20:54:58.870167Z",
        "url": "https://files.pythonhosted.org/packages/2f/52/5c95380c254d1d1d3376b0d469685e2a95903eb939e934e644ffd7f0fa40/nvidia_tao-0.1.23-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.24": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "96a4b4910a2883cc2e3875dd9ac038f35658b1175556eaaa14792507f3d22ff3",
          "md5": "19d3c5a5477934581d08f741f9e5afe7",
          "sha256": "199d9fd171f3f42c4fe00c5de45474378f6888e6f15e7175e34b4be3665ac335"
        },
        "downloads": -1,
        "filename": "nvidia_tao-0.1.24-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "19d3c5a5477934581d08f741f9e5afe7",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6.*",
        "size": 149611,
        "upload_time": "2022-06-15T21:20:27",
        "upload_time_iso_8601": "2022-06-15T21:20:27.573831Z",
        "url": "https://files.pythonhosted.org/packages/96/a4/b4910a2883cc2e3875dd9ac038f35658b1175556eaaa14792507f3d22ff3/nvidia_tao-0.1.24-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "4.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "acbe05a3585c3243c69abd3b6a85978923bdaeea54f1b32f0c030d14c2237718",
          "md5": "f97f5c2d94a07b60fd5cc1cab80f24c8",
          "sha256": "d33ba768d339443a525c2799f69c27c59f98e332fbe42bd2b9943250b2047248"
        },
        "downloads": -1,
        "filename": "nvidia_tao-4.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f97f5c2d94a07b60fd5cc1cab80f24c8",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6.*",
        "size": 155436,
        "upload_time": "2022-12-09T17:57:55",
        "upload_time_iso_8601": "2022-12-09T17:57:55.814431Z",
        "url": "https://files.pythonhosted.org/packages/ac/be/05a3585c3243c69abd3b6a85978923bdaeea54f1b32f0c030d14c2237718/nvidia_tao-4.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "4.0.0.dev0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e1eb6a77c40b2b456cc20bd6bf104860b55bc22cbc955641eb57190101c155ba",
          "md5": "8f9e8ad7dc65ecbfb7366a520ec3e796",
          "sha256": "4186e6aa90ff9065ed7052b1823231989d19dd9ed6bc5a4665b712f80c1c1014"
        },
        "downloads": -1,
        "filename": "nvidia_tao-4.0.0.dev0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "8f9e8ad7dc65ecbfb7366a520ec3e796",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6.*",
        "size": 154385,
        "upload_time": "2022-12-09T17:26:11",
        "upload_time_iso_8601": "2022-12-09T17:26:11.745948Z",
        "url": "https://files.pythonhosted.org/packages/e1/eb/6a77c40b2b456cc20bd6bf104860b55bc22cbc955641eb57190101c155ba/nvidia_tao-4.0.0.dev0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "4.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c0c82f48cb7472fb4019d997558b07d35b74a4c028eed73fc857bb030f42db87",
          "md5": "ddd81bc0faa8b54c6ce083c9c93da137",
          "sha256": "dbbf062da562efc6c626fb96594e7b85cd537f946c21d1e2bf3dc6ff6dfc48b5"
        },
        "downloads": -1,
        "filename": "nvidia_tao-4.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ddd81bc0faa8b54c6ce083c9c93da137",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6.*",
        "size": 155453,
        "upload_time": "2023-03-06T16:19:38",
        "upload_time_iso_8601": "2023-03-06T16:19:38.060548Z",
        "url": "https://files.pythonhosted.org/packages/c0/c8/2f48cb7472fb4019d997558b07d35b74a4c028eed73fc857bb030f42db87/nvidia_tao-4.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "c0c82f48cb7472fb4019d997558b07d35b74a4c028eed73fc857bb030f42db87",
        "md5": "ddd81bc0faa8b54c6ce083c9c93da137",
        "sha256": "dbbf062da562efc6c626fb96594e7b85cd537f946c21d1e2bf3dc6ff6dfc48b5"
      },
      "downloads": -1,
      "filename": "nvidia_tao-4.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "ddd81bc0faa8b54c6ce083c9c93da137",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6.*",
      "size": 155453,
      "upload_time": "2023-03-06T16:19:38",
      "upload_time_iso_8601": "2023-03-06T16:19:38.060548Z",
      "url": "https://files.pythonhosted.org/packages/c0/c8/2f48cb7472fb4019d997558b07d35b74a4c028eed73fc857bb030f42db87/nvidia_tao-4.0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}