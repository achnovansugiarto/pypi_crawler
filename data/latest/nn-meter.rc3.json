{
  "info": {
    "author": "Microsoft nn-Meter Team",
    "author_email": "nn-meter-dev@microsoft.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: MacOS :: MacOS X",
      "Operating System :: Microsoft :: Windows :: Windows 10",
      "Operating System :: POSIX :: Linux",
      "Programming Language :: Python :: 3 :: Only",
      "Topic :: Scientific/Engineering :: Artificial Intelligence"
    ],
    "description": "**nn-Meter** is a novel and efficient system to accurately predict the inference latency of DNN models on diverse edge devices. The key idea is dividing a whole model inference into kernels, i.e., the execution units of fused operators on a device, and conduct kernel-level prediction. We currently evaluate four popular platforms on a large dataset of 26k models. It achieves 99.0% (mobile CPU), 99.1% (mobile Adreno 640 GPU), 99.0% (mobile Adreno 630 GPU), and 83.4% (Intel VPU) prediction accuracy.\n\nThe current supported hardware and inference frameworks:\n\n|       Device       |   Framework   |   Processor   | +-10%  Accuracy |      Hardware name      |\n| :-----------------: | :------------: | :------------: | :-------------: | :----------------------: |\n|       Pixel4       |  TFLite v2.1  | CortexA76 CPU |      99.0%      |  cortexA76cpu_tflite21  |\n|         Mi9         |  TFLite v2.1  | Adreno 640 GPU |      99.1%      |  adreno640gpu_tflite21  |\n|      Pixel3XL      |  TFLite v2.1  | Adreno 630 GPU |      99.0%      |  adreno630gpu_tflite21  |\n| Intel Movidius NCS2 | OpenVINO2019R2 |   Myriad VPU   |      83.4%      | myriadvpu_openvino2019r2 |\n\n*nn-Meter has achieved the **Mobisys 21 Best Paper Award!** For more details, please check out paper:*\n\n[nn-Meter: towards accurate latency prediction of deep-learning model inference on diverse edge devices](https://dl.acm.org/doi/10.1145/3458864.3467882)\n\n## Who should consider using nn-Meter\n\n- Those who want to get the DNN inference latency on mobile and edge devices with **no deployment efforts on real devices**.\n- Those who want to run **hardware-aware NAS with [NNI](https://github.com/microsoft/nni)**.\n- Those who want to **build latency predictors for their own devices** ([Documents](https://github.com/microsoft/nn-Meter/blob/main/docs/builder/overview.md) of nn-Meter builder).\n- Those who want to use the 26k latency [benchmark dataset](https://github.com/microsoft/nn-Meter/releases/download/v1.0-data/datasets.zip).\n\n# Installation\n\nCurrently nn-Meter has been tested on Linux and Windows system. Windows 10, Ubuntu 16.04 and 20.04 with python 3.6.10 are tested and supported. Please first install `python3` before nn-Meter installation. Then nn-Meter could be installed by running:\n\n```Bash\npip install nn-meter\n```\n\nIf you want to try latest code, please install nn-Meter from source code. First git clone nn-Meter package to local:\n\n```Bash\ngit clone git@github.com:microsoft/nn-Meter.git\ncd nn-Meter\n```\n\nThen simply run the following pip install in an environment that has `python >= 3.6`. The command will complete the automatic installation of all necessary dependencies and nn-Meter.\n\n```Bash\npip install .\n```\n\nnn-Meter is a latency predictor of models with type of Tensorflow, PyTorch, Onnx, nn-meter IR graph and [NNI IR graph](https://github.com/microsoft/nni). To use nn-Meter for specific model type, you also need to install corresponding required packages. The well tested versions are listed below:\n\n| Testing Model Type |                                                       Requirements                                                       |\n| :----------------: | :-----------------------------------------------------------------------------------------------------------------------: |\n|     Tensorflow     |                                                  `tensorflow==2.6.0`                                                  |\n|       Torch       | `torch==1.9.0`, `torchvision==0.10.0`, (alternative)[`onnx==1.9.0`, `onnx-simplifier==0.3.6`] or [`nni>=2.4`][1] |\n|        Onnx        |                                                      `onnx==1.9.0`                                                      |\n| nn-Meter IR graph |                                                            ---                                                            |\n|    NNI IR graph    |                                                       `nni>=2.4`                                                       |\n\n[1] Please refer to [nn-Meter Usage](#torch-model-converters) for more information.\n\nPlease also check the versions of `numpy` and `scikit_learn`. The different versions may change the prediction accuracy of kernel predictors.\n\nThe stable version of wheel binary package will be released soon.\n\n# Usage\n\nTo apply for hardware latency prediction, nn-Meter provides two types of interfaces：\n\n- command line `nn-meter` after `nn-meter` [installation](QuickStart.md#Installation).\n- Python binding provided by the module `nn_meter`\n\nHere is a summary of supported inputs of the two methods.\n\n| Testing Model Type |                                       Command Support                                       |                                          Python Binding                                          |\n| :----------------: | :-----------------------------------------------------------------------------------------: | :-----------------------------------------------------------------------------------------------: |\n|     Tensorflow     |             Checkpoint file dumped by `tf.saved_model()` and end with `.pb`             |                 Checkpoint file dumped by `tf.saved_model` and end with `.pb`                 |\n|       Torch       |                              Models in `torchvision.models`                              |                                   Object of `torch.nn.Module`                                   |\n|        Onnx        | Checkpoint file dumped by `torch.onnx.export()` or `onnx.save()` and end with `.onnx` |           Checkpoint file dumped by `onnx.save()` or model loaded by `onnx.load()`           |\n| nn-Meter IR graph |     Json file in the format of [nn-Meter IR Graph](./docs/predictor/input_models.md#nnmeter-ir-graph)     | `dict` object following the format of [nn-Meter IR Graph](./docs/predictor/input_models.md#nnmeter-ir-graph) |\n|    NNI IR graph    |                                              -                                              |                                        NNI IR graph object                                        |\n\nIn both methods, users could appoint predictor name and version to target a specific hardware platform (device). Currently, nn-Meter supports prediction on the following four configs:\n\n| Predictor (device_inferenceframework) | Processor Category | Version |\n| :-----------------------------------: | :----------------: | :-----: |\n|         cortexA76cpu_tflite21         |        CPU        |   1.0   |\n|         adreno640gpu_tflite21         |        GPU        |   1.0   |\n|         adreno630gpu_tflite21         |        GPU        |   1.0   |\n|       myriadvpu_openvino2019r2       |        VPU        |   1.0   |\n\nUsers can get all predefined predictors and versions by running\n\n```bash\n# to list all predefined predictors\nnn-meter --list-predictors \n```\n\n## Predict latency of saved CNN model\n\nAfter installation, a command named `nn-meter` is enabled. To predict the latency for a CNN model with a predefined predictor in command line, users can run the following commands (sample models can be downloaded [here](./material/testmodels))\n\n```bash\n# for Tensorflow (*.pb) file\nnn-meter predict --predictor <hardware> [--predictor-version <version>] --tensorflow <pb-file_or_folder> \n# Example Usage\nnn-meter predict --predictor cortexA76cpu_tflite21 --predictor-version 1.0 --tensorflow mobilenetv3small_0.pb \n\n# for ONNX (*.onnx) file\nnn-meter predict --predictor <hardware> [--predictor-version <version>] --onnx <onnx-file_or_folder>\n#Example Usage\nnn-meter predict --predictor cortexA76cpu_tflite21 --predictor-version 1.0 --onnx mobilenetv3small_0.onnx \n\n# for torch model from torchvision model zoo (str)\nnn-meter predict --predictor <hardware> [--predictor-version <version>] --torchvision <model-name> <model-name>... \n#Example Usage\nnn-meter predict --predictor cortexA76cpu_tflite21 --predictor-version 1.0 --torchvision mobilenet_v2\n\n# for nn-Meter IR (*.json) file\nnn-meter predict --predictor <hardware> [--predictor-version <version>] --nn-meter-ir <json-file_or_folder> \n#Example Usage\nnn-meter predict --predictor cortexA76cpu_tflite21 --predictor-version 1.0 --nn-meter-ir mobilenetv3small_0.json \n```\n\n`--predictor-version <version>` arguments is optional. When the predictor version is not specified by users, nn-meter will use the latest version of the predictor.\n\nnn-Meter can support batch mode prediction. To predict latency for multiple models in the same model type once, user should collect all models in one folder and state the folder after `--[model-type]` liked argument.\n\nIt should also be noted that for PyTorch model, nn-meter can only support existing models in torchvision model zoo. The string followed by `--torchvision` should be exactly one or more string indicating name(s) of some existing torchvision models. To apply latency prediction for torchvision model in command line, `onnx` and `onnx-simplifier` packages are required.\n\n### Convert to nn-Meter IR Graph\n\nFurthermore, users may be interested to convert tensorflow pb-file or onnx file to nn-Meter IR graph. Users could convert nn-Meter IR graph and save to `.json` file be running\n\n```bash\n# for Tensorflow (*.pb) file\nnn-meter get_ir --tensorflow <pb-file> [--output <output-name>]\n\n# for ONNX (*.onnx) file\nnn-meter get_ir --onnx <onnx-file> [--output <output-name>]\n```\n\nOutput name is default to be `/path/to/input/file/<input_file_name>_<model-type>_ir.json` if not specified by users.\n\n## Use nn-Meter in your python code\n\nAfter installation, users can import nn-Meter in python code\n\n```python\nfrom nn_meter import load_latency_predictor\n\npredictor = load_latency_predictor(hardware_name, hardware_predictor_version) # case insensitive in backend\n\n# build your model (e.g., model instance of torch.nn.Module)\nmodel = ... \n\nlat = predictor.predict(model, model_type) # the resulting latency is in unit of ms\n```\n\nBy calling `load_latency_predictor`, user selects the target hardware and loads the corresponding predictor. nn-Meter will try to find the right predictor file in `~/.nn_meter/data`. If the predictor file doesn't exist, it will download from the Github release.\n\nIn `predictor.predict()`, the allowed items of the parameter `model_type` include `[\"pb\", \"torch\", \"onnx\", \"nnmeter-ir\", \"nni-ir\"]`, representing model types of tensorflow, torch, onnx, nn-meter IR graph and NNI IR graph, respectively.\n\n`<span id=\"torch-model-converters\">` For Torch models, the shape of feature maps is unknown merely based on the given network structure, which is, however, significant parameters in latency prediction. Therefore, torch model requires a shape of input tensor for inference as a input of `predictor.predict()`. Based on the given input shape, a random tensor according to the shape will be generated and used. Another thing for Torch model prediction is that users can install the `onnx` and `onnx-simplifier` packages for latency prediction (referred to as Onnx-based latency prediction for torch model), or alternatively install the `nni` package (referred to as NNI-based latency prediction for torch model). Note that the `nni` option does not support command line calls. In addition, if users use `nni` for latency prediction, the PyTorch modules should be defined by the `nn` interface from NNI `import nni.retiarii.nn.pytorch as nn` (view [NNI doc](https://nni.readthedocs.io/en/stable/NAS/QuickStart.html#define-base-model) for more information), and the parameter `apply_nni` should be set as `True` in the function `predictor.predict()`. Here is an example of NNI-based latency prediction for Torch model:\n\n```python\nimport nni.retiarii.nn.pytorch as nn\nfrom nn_meter import load_latency_predictor\n\npredictor = load_latency_predictor(...)\n\n# build your model using nni.retiarii.nn.pytorch as nn\nmodel = nn.Module ...\n\ninput_shape = (1, 3, 224, 224)\nlat = predictor.predict(model, model_type='torch', input_shape=input_shape, apply_nni=True) \n```\n\nThe Onnx-based latency prediction for torch model is stable but slower, while the NNI-based latency prediction for torch model is unstable as it could fail in some case but much faster compared to the Onnx-based model. The Onnx-based model is set as the default one for Torch model latency prediction in nn-Meter. Users could choose which one they preferred to use according to their needs. \n\nUsers could view the information all built-in predictors by `list_latency_predictors` or view the config file in `nn_meter/configs/predictors.yaml`.\n\nUsers could get a nn-Meter IR graph by applying `model_file_to_graph` and `model_to_graph` by calling the model name or model object and specify the model type. The supporting model types of `model_file_to_graph` include \"onnx\", \"pb\", \"torch\", \"nnmeter-ir\" and \"nni-ir\", while the supporting model types of `model_to_graph` include \"onnx\", \"torch\" and \"nni-ir\".\n\n## nn-Meter Builder\n\nnn-Meter builder is an open source tool for users to build latency predictor on their own devices. There are three main parts in nn-Meter builder:\n\n**backend**: the module of connecting backends;\n\n**backend_meta**: the meta tools related to backend. Here we provide the fusion rule tester to detect fusion rules for users' backend;\n\n**kernel_predictor_builder**: the tool to build different kernel latency predictors.\n\nUsers could get access to nn-Meter builder by calling `nn_meter.builder`. For more details to use nn-Meter builder, please check the document of [nn-Meter builder](https://github.com/microsoft/nn-Meter/blob/main/docs/builder/overview.md).\n\n## Hardware-aware NAS by nn-Meter and NNI\n\nTo empower affordable DNN on the edge and mobile devices, hardware-aware NAS searches both high accuracy and low latency models. In particular, the search algorithm only considers the models within the target latency constraints during the search process.\n\nCurrently we provide two examples of hardware-aware NAS, including end-to-end [multi-trial NAS](https://nni.readthedocs.io/en/stable/NAS/multi_trial_nas.html) which is a [random search algorithm](https://arxiv.org/abs/1902.07638) on [SPOS NAS](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123610528.pdf) search space, and the popular [ProxylessNAS](https://nni.readthedocs.io/en/stable/NAS/Proxylessnas.html), which is a one-shot NAS algorithm with hardware-efficient loss function. More examples of other widely-used hardware-aware NAS and model compression algorithms are coming soon.\n\n### Multi-trial SPOS Demo\nTo run multi-trail SPOS demo, NNI should be installed through source code by following [NNI Doc](https://nni.readthedocs.io/en/stable/Tutorial/InstallationLinux.html#installation)\n\n```bash\npython setup.py develop\n```\n\nThen run multi-trail SPOS demo:\n\n```bash\npython ${NNI_ROOT}/examples/nas/oneshot/spos/multi_trial.py\n```\n\n#### How the demo works\n\nRefer to [NNI Doc](https://nni.readthedocs.io/en/stable/nas.html) for how to perform NAS by NNI.\n\nTo support hardware-aware NAS, you first need a `Strategy` that supports filtering the models by latency. We provide such a filter named `LatencyFilter` in NNI and initialize a `Random` strategy with the filter:\n\n```python\nsimple_strategy = strategy.Random(model_filter=LatencyFilter(threshold=100, predictor=base_predictor))\n```\n\n`LatencyFilter` will predict the models' latency by using nn-Meter and filter out the models whose latency with the given predictor are larger than the threshold (i.e., `100` in this example).\nYou can also build your own strategies and filters to support more flexible NAS such as sorting the models according to latency.\n\nThen, pass this strategy to `RetiariiExperiment`:\n\n```python\nexp = RetiariiExperiment(base_model, trainer, strategy=simple_strategy)\n\nexp_config = RetiariiExeConfig('local')\n...\nexp_config.dummy_input = [1, 3, 32, 32]\n\nexp.run(exp_config, port)\n```\n\nIn `exp_config`, `dummy_input` is required for tracing shape info.\n\n### ProxylessNAS Demo\n\nTo run the one-shot ProxylessNAS demo, users can run the NNI ProxylessNAS training demo:\n\n```bash\npython ${NNI_ROOT}/examples/nas/oneshot/proxylessnas/main.py --applied_hardware <hardware> --reference_latency <reference latency (ms)>\n```\n\n#### How the demo works\n\nRefer to [NNI Doc](https://nni.readthedocs.io/en/stable/nas.html) for how to perform NAS by NNI.\n\nProxylessNAS currently builds a lookup table, that stores the measured latency of each candidate building block in the search space. The latency sum of all building blocks in a candidate model will be treated as the model inference latency. With leveraging nn-Meter in NNI, users can apply ProxylessNAS to search efficient DNN models on more types of edge devices. In NNI implementation, a `HardwareLatencyEstimator` predicts expected latency for the mixed operation based on the path weight of `ProxylessLayerChoice`. To call nn-Meter in NNI ProxylessNAS, users can add the arguments of \"`--applied_hardware <hardware> --reference_latency <reference latency (ms)>`\" in the [example](https://github.com/microsoft/nni/blob/master/examples/nas/oneshot/proxylessnas/main.py).\n\n## Benchmark Dataset\n\nTo evaluate the effectiveness of a prediction model on an arbitrary DNN model, we need a representative dataset that covers a large prediction scope. nn-Meter collects and generates 26k CNN models. (Please refer the paper for the dataset generation method.)\n\nWe release the dataset, and provide an interface of `nn_meter.dataset` for users to get access to the dataset. Users can also download the data from the [Download Link](https://github.com/microsoft/nn-Meter/releases/download/v1.0-data/datasets.zip) on their own. \n\n\n\n# Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\n\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n# License\n\nThe entire codebase is under [MIT license](https://github.com/microsoft/nn-Meter/blob/main/LICENSE)\n\nThe dataset is under [Open Use of Data Agreement](https://github.com/Community-Data-License-Agreements/Releases/blob/main/O-UDA-1.0.md)\n\n# Citation\n\nIf you find that nn-Meter helps your research, please consider citing it:\n\n```\n@inproceedings{nnmeter,\n    author = {Zhang, Li Lyna and Han, Shihao and Wei, Jianyu and Zheng, Ningxin and Cao, Ting and Yang, Yuqing and Liu, Yunxin},\n    title = {nn-Meter: Towards Accurate Latency Prediction of Deep-Learning Model Inference on Diverse Edge Devices},\n    year = {2021},\n    publisher = {ACM},\n    address = {New York, NY, USA},\n    url = {https://doi.org/10.1145/3458864.3467882},\n    doi = {10.1145/3458864.3467882},\n    booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},\n    pages = {81–93},\n}\n\n@misc{nnmetercode,\n    author = {Microsoft Research nn-Meter Team},\n    title = {nn-Meter: Towards Accurate Latency Prediction of Deep-Learning Model Inference on Diverse Edge Devices},\n    year = {2021},\n    url = {https://github.com/microsoft/nn-Meter},\n}\n```\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/microsoft/nn-Meter",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "nn-meter",
    "package_url": "https://pypi.org/project/nn-meter/",
    "platform": null,
    "project_url": "https://pypi.org/project/nn-meter/",
    "project_urls": {
      "Data of models": "https://github.com/microsoft/nn-Meter/releases/tag/v1.0-data",
      "Homepage": "https://github.com/microsoft/nn-Meter"
    },
    "release_url": "https://pypi.org/project/nn-meter/2.0/",
    "requires_dist": [
      "numpy",
      "pandas",
      "tqdm",
      "networkx",
      "requests",
      "protobuf",
      "PyYAML",
      "scikit-learn",
      "packaging",
      "jsonlines"
    ],
    "requires_python": "",
    "summary": "nn-Meter is a novel and efficient system to accurately predict the inference latency of DNN models on diverse edge devices.",
    "version": "2.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14257624,
  "releases": {
    "1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0374c0c62bbc74c14d9e8d790d2fc7bd5d1cc3b59e97debd05af0f3cae2e6bfe",
          "md5": "2a54af43c047c5f97ab6c462025a634e",
          "sha256": "ac27a3484a9d0b7aa6130ba8151754e8b049f3d66936143c833363e515bf2e1e"
        },
        "downloads": -1,
        "filename": "nn_meter-1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "2a54af43c047c5f97ab6c462025a634e",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 54080,
        "upload_time": "2021-09-01T07:41:44",
        "upload_time_iso_8601": "2021-09-01T07:41:44.077527Z",
        "url": "https://files.pythonhosted.org/packages/03/74/c0c62bbc74c14d9e8d790d2fc7bd5d1cc3b59e97debd05af0f3cae2e6bfe/nn_meter-1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "33979c7141894e9582535275e05bb67fbd7f5d0fc9d76acafc6fb94562040683",
          "md5": "53602bd0c4816b99ed4dad15c036b225",
          "sha256": "558d0b55e6bf73aed41728eeed18eacf3a2aec0d3cbdfbdabe80287bb340d5df"
        },
        "downloads": -1,
        "filename": "nn-meter-1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "53602bd0c4816b99ed4dad15c036b225",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 37400,
        "upload_time": "2021-09-01T07:41:46",
        "upload_time_iso_8601": "2021-09-01T07:41:46.071829Z",
        "url": "https://files.pythonhosted.org/packages/33/97/9c7141894e9582535275e05bb67fbd7f5d0fc9d76acafc6fb94562040683/nn-meter-1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7345812c0fcb1d0156e3eb2e9ea2b6eb0ee2c42985de5f448a4037ff41bed73e",
          "md5": "64f4495cc82cad89c48dce69253e8bc9",
          "sha256": "3c68e495365dea53d980521b586450d781711736601debe67d5f69e7f3831802"
        },
        "downloads": -1,
        "filename": "nn_meter-1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "64f4495cc82cad89c48dce69253e8bc9",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 59937,
        "upload_time": "2021-11-16T12:23:58",
        "upload_time_iso_8601": "2021-11-16T12:23:58.045734Z",
        "url": "https://files.pythonhosted.org/packages/73/45/812c0fcb1d0156e3eb2e9ea2b6eb0ee2c42985de5f448a4037ff41bed73e/nn_meter-1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1ccef5d9e13504489b42ac4f8eb18da26db636fc40c5446a4db28b9661c538aa",
          "md5": "8333ae8d88994b57dcdc2e45a5f1660a",
          "sha256": "d57dd02ff6a1b383e951e73979fc3a1f04f223524f210e244263cddca1c0b6e9"
        },
        "downloads": -1,
        "filename": "nn-meter-1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "8333ae8d88994b57dcdc2e45a5f1660a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 41619,
        "upload_time": "2021-11-16T12:24:00",
        "upload_time_iso_8601": "2021-11-16T12:24:00.106899Z",
        "url": "https://files.pythonhosted.org/packages/1c/ce/f5d9e13504489b42ac4f8eb18da26db636fc40c5446a4db28b9661c538aa/nn-meter-1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ea28cdff8b98e360a23cdc6d00235fd8c591a35a15c7ac790eb8d88bb6970b45",
          "md5": "80d31ead97d5889e24d6f164959dfbe6",
          "sha256": "bdc7053f7c656fc3ac7df4a935b6547065e4a4a080f2b5a3103263ba207be8c0"
        },
        "downloads": -1,
        "filename": "nn_meter-2.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "80d31ead97d5889e24d6f164959dfbe6",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 132475,
        "upload_time": "2022-06-27T09:21:07",
        "upload_time_iso_8601": "2022-06-27T09:21:07.308921Z",
        "url": "https://files.pythonhosted.org/packages/ea/28/cdff8b98e360a23cdc6d00235fd8c591a35a15c7ac790eb8d88bb6970b45/nn_meter-2.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "af31ba3de0e415cb930532ca02ad4051200464b8da0d7c185ce10afef75b2194",
          "md5": "7952337e8e75fcba2d0ac0358ec8f251",
          "sha256": "7669fdd481d1ba9e8f428ea34dfee12f7b668888d5799f9582e9c484a8d0dd5f"
        },
        "downloads": -1,
        "filename": "nn-meter-2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "7952337e8e75fcba2d0ac0358ec8f251",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 89647,
        "upload_time": "2022-06-27T09:21:22",
        "upload_time_iso_8601": "2022-06-27T09:21:22.731718Z",
        "url": "https://files.pythonhosted.org/packages/af/31/ba3de0e415cb930532ca02ad4051200464b8da0d7c185ce10afef75b2194/nn-meter-2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "ea28cdff8b98e360a23cdc6d00235fd8c591a35a15c7ac790eb8d88bb6970b45",
        "md5": "80d31ead97d5889e24d6f164959dfbe6",
        "sha256": "bdc7053f7c656fc3ac7df4a935b6547065e4a4a080f2b5a3103263ba207be8c0"
      },
      "downloads": -1,
      "filename": "nn_meter-2.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "80d31ead97d5889e24d6f164959dfbe6",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 132475,
      "upload_time": "2022-06-27T09:21:07",
      "upload_time_iso_8601": "2022-06-27T09:21:07.308921Z",
      "url": "https://files.pythonhosted.org/packages/ea/28/cdff8b98e360a23cdc6d00235fd8c591a35a15c7ac790eb8d88bb6970b45/nn_meter-2.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "af31ba3de0e415cb930532ca02ad4051200464b8da0d7c185ce10afef75b2194",
        "md5": "7952337e8e75fcba2d0ac0358ec8f251",
        "sha256": "7669fdd481d1ba9e8f428ea34dfee12f7b668888d5799f9582e9c484a8d0dd5f"
      },
      "downloads": -1,
      "filename": "nn-meter-2.0.tar.gz",
      "has_sig": false,
      "md5_digest": "7952337e8e75fcba2d0ac0358ec8f251",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 89647,
      "upload_time": "2022-06-27T09:21:22",
      "upload_time_iso_8601": "2022-06-27T09:21:22.731718Z",
      "url": "https://files.pythonhosted.org/packages/af/31/ba3de0e415cb930532ca02ad4051200464b8da0d7c185ce10afef75b2194/nn-meter-2.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}