{
  "info": {
    "author": "Alex Lubbock",
    "author_email": "code@alexlubbock.com",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Developers",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python"
    ],
    "description": "# Microbench\n\n![Microbench: Benchmarking and reproducibility metadata capture for Python](https://raw.githubusercontent.com/alubbock/microbench/master/microbench.png)\n\nMicrobench is a small Python package for benchmarking Python functions, and \noptionally capturing extra runtime/environment information. It is most useful in\nclustered/distributed environments, where the same function runs under different\nenvironments, and is designed to be extensible with new\nfunctionality. In addition to benchmarking, this can help reproducibility by\ne.g. logging the versions of key Python packages, or even all packages loaded\ninto the global environment. Other captured metadata can include CPU and RAM\nusage, environment variables, and hardware specifications.\n\n## Requirements\n\nMicrobench by default has no dependencies outside of the Python standard\nlibrary, although [pandas](https://pandas.pydata.org/) is recommended to\nexamine results. However, some mixins (extensions) have specific requirements:\n\n* The [line_profiler](https://github.com/rkern/line_profiler)\n  package needs to be installed for line-by-line code benchmarking.\n* `MBInstalledPackages` requires `setuptools`, which is not a part of the\n  standard library, but is usually available. \n* The CPU cores, total RAM, and telemetry extensions require\n  [psutil](https://pypi.org/project/psutil/).\n* The NVIDIA GPU plugin requires the\n  [nvidia-smi](https://developer.nvidia.com/nvidia-system-management-interface)\n  utility, which usually ships with the NVIDIA graphics card drivers. It needs\n  to be on your `PATH`.\n\n## Installation\n\nTo install using `pip`:\n\n```\npip install microbench\n```\n\n## Usage\n\nMicrobench is designed for benchmarking Python functions. These examples will\nassume you have already defined a Python function `myfunction` that you wish to\nbenchmark:\n\n```python\ndef myfunction(arg1, arg2, ...):\n    ...\n```\n\n### Minimal example\n\nFirst, create a benchmark suite, which specifies the configuration and\ninformation to capture.\n\nHere's a minimal, complete example:\n\n```python\nfrom microbench import MicroBench\n    \nbasic_bench = MicroBench()\n```\n\nTo attach the benchmark to your function, simply use `basic_bench` as a\ndecorator, like this:\n\n```python\n@basic_bench\ndef myfunction(arg1, arg2, ...):\n    ...\n```\n\nThat's it! When `myfunction()` is called, metadata will be captured\ninto a `io.StringIO()` buffer, which can be read as follows\n(using the `pandas` library):\n\n```python\nimport pandas as pd\nresults = pd.read_json(basic_bench.outfile.getvalue(), lines=True)\n```\n\nThe above example captures the fields `start_time`, `finish_time` and\n`function_name`. Microbench can capture many other types of metadata\nfrom the environment, resource usage, and hardware,\nwhich are covered below.\n\n### Extended examples\n\nHere's a more complete example using mixins (the `MB` prefixed class \nnames) to extend functionality. Note that keyword arguments can be supplied\nto the constructor (in this case `some_info=123`) to specify additional\ninformation to capture. This example also specifies the `outfile` option,\nwhich appends metadata to a file on disk.\n\n```python\nfrom microbench import *\nimport numpy, pandas\n\nclass MyBench(MicroBench, MBFunctionCall, MBPythonVersion, MBHostInfo):\n    outfile = '/home/user/my-benchmarks'\n    capture_versions = (numpy, pandas)  # Or use MBGlobalPackages/MBInstalledPackages\n    env_vars = ('SLURM_ARRAY_TASK_ID', )\n    \nbenchmark = MyBench(some_info=123)\n```\n\nThe `env_vars` option from the example above specifies a list of environment\nvariables to capture as `env_<variable name>`. In this example,\nthe [slurm](https://slurm.schedmd.com) array task ID will be stored as\n`env_SLURM_ARRAY_TASK_ID`. Where the environment variable is not set, the\nvalue will be `null`.\n\nTo capture package versions, you can either specify them individually (as\nabove), or you can capture the versions of every package in the global\nenvironment. In the following example, we would capture the versions of\n`microbench`, `numpy`, and `pandas` automatically.\n\n```python\nfrom microbench import *\nimport numpy, pandas\n\nclass Bench2(MicroBench, MBGlobalPackages):\n    outfile = '/home/user/bench2'\n\nbench2 = Bench2()\n```\n\nIf you want to go even further, and capture the version of every package\navailable for import, there's a mixin for that:\n\n```python\nfrom microbench import *\n\nclass Bench3(MicroBench, MBInstalledPackages):\n    pass\n    \nbench3 = Bench3()\n``` \n\n Mixin                 | Fields captured\n-----------------------|----------------\n*(default)*            | `start_time`<br>`finish_time`<br>`function_name`\nMBGlobalPackages       | `package_versions`, with entry for every package in the global environment\nMBInstalledPackages    | `package_versions`, with entry for every package available for import\nMBCondaPackages        | `conda_versions`, with entry for every conda package in the environment\nMBFunctionCall         | `args` (positional arguments)<br>`kwargs` (keyword arguments)\nMBReturnValue          | Wrapped function's return value\nMBPythonVersion        | `python_version` (e.g. 3.6.0) and `python_executable` (e.g. `/usr/bin/python`, which should indicate any active virtual environment)\nMBHostInfo             | `hostname`<br>`operating_system`\nMBHostCpuCores         | `cpu_cores_logical` (number of cores, requires `psutil`)\nMBHostRamTotal         | `ram_total` (total RAM in bytes, requires `psutil`)\nMBNvidiaSmi            | Various NVIDIA GPU fields, detailed in a later section\nMBLineProfiler         | `line_profiler` containing line-by-line profile (see section below)\n\n## Examine results\n\nEach result is a [JSON](https://en.wikipedia.org/wiki/JSON) object. When using\nthe `outfile` option, a JSON object for each `@benchmark` call is stored on a\nseparate line in the file. The output from the minimal example above for a\nsingle run will look similar to the following:\n\n```json\n{\"start_time\": \"2018-08-06T10:28:24.806493\", \"finish_time\": \"2018-08-06T10:28:24.867456\", \"function_name\": \"my_function\"}\n```\n\nThe simplest way to examine results in detail is to load them into a\n[pandas](https://pandas.pydata.org/) dataframe:\n\n```python\nimport pandas\nresults = pandas.read_json('/home/user/my-benchmarks', lines=True)\n```\n\nPandas has powerful data manipulation capabilities. For example, to calculate\nthe average runtime by Python version:\n\n```python\n# Calculate runtime for each run\nresults['runtime'] = results['finish_time'] - results['start_time']\n\n# Average runtime by Python version\nresults.groupby('python_version')['runtime'].mean()\n```\n\nMany more advanced operations are available. The\n[pandas tutorial](https://pandas.pydata.org/pandas-docs/stable/tutorials.html)\nis recommended.\n\n## Line profiler support\n\nMicrobench also has support for [line_profiler](https://github.com/rkern/line_profiler), which shows the execution time\nof each line of Python code. Note that this will slow down your code, so only use it if needed, but it's useful for\ndiscovering bottlenecks within a function. Requires the `line_profiler` package to be installed\n(e.g. `pip install line_profiler`).\n\n```python\nfrom microbench import MicroBench, MBLineProfiler\nimport pandas\n\n# Create our benchmark suite using the MBLineProfiler mixin\nclass LineProfilerBench(MicroBench, MBLineProfiler):\n    pass\n\nlpbench = LineProfilerBench()\n\n# Decorate our function with the benchmark suite\n@lpbench\ndef my_function():\n    \"\"\" Inefficient function for line profiler \"\"\"\n    acc = 0\n    for i in range(1000000):\n        acc += i\n\n    return acc\n\n# Call the function as normal\nmy_function()\n\n# Read the results into a Pandas DataFrame\nresults = pandas.read_json(lpbench.outfile.getvalue(), lines=True)\n\n# Get the line profiler report as an object\nlp = MBLineProfiler.decode_line_profile(results['line_profiler'][0])\n\n# Print the line profiler report\nMBLineProfiler.print_line_profile(results['line_profiler'][0])\n```\n\nThe last line of the previous example will print the line profiler report, showing the execution time of each line of\ncode. Example:\n\n```\nTimer unit: 1e-06 s\n\nTotal time: 0.476723 s\nFile: /home/user/my_test.py\nFunction: my_function at line 12\n\nLine #      Hits         Time  Per Hit   % Time  Line Contents\n==============================================================\n    12                                               @lpbench\n    13                                               def my_function():\n    14                                                   \"\"\" Inefficient function for line profiler \"\"\"\n    15         1          2.0      2.0      0.0          acc = 0\n    16   1000001     217874.0      0.2     45.7          for i in range(1000000):\n    17   1000000     258846.0      0.3     54.3              acc += i\n    18\n    19         1          1.0      1.0      0.0          return acc\n```\n\n## NVIDIA GPU support\n\nAttributes about NVIDIA GPUs can be captured using the `MBNvidiaSmi` plugin.\nThis requires the `nvidia-smi` utility to be available in the current `PATH`.\n\nBy default, the `gpu_name` (model number) and `memory.total` attributes are\ncaptured. Extra attributes can be specified using the class or object-level\nvariable `nvidia_attributes`. To see which attributes are available, run\n`nvidia-smi --help-query-gpu`.\n\nBy default, all installed GPUs will be polled. To limit to a specific GPU,\nspecify the `nvidia_gpus` attribute as a tuple of GPU IDs, which can be\nzero-based GPU indexes (can change between reboots, not recommended),\nGPU UUIDs, or PCI bus IDs. You can find out GPU UUIDs by running\n`nvidia-smi -L`.\n\nHere's an example specifying the optional `nvidia_attributes` and\n`nvidia_gpus` fields:\n\n```python\nfrom microbench import MicroBench, MBNvidiaSmi\n\nclass GpuBench(MicroBench, MBNvidiaSmi):\n    outfile = '/home/user/gpu-benchmarks'\n    nvidia_attributes = ('gpu_name', 'memory.total', 'pcie.link.width.max')\n    nvidia_gpus = (0, )  # Usually better to specify GPU UUIDs here instead\n\ngpu_bench = GpuBench()\n```\n\n## Telemetry support\n\nWe use the term \"telemetry\" to refer to metadata which is captured periodically\nduring the execution of a function by a thread which runs in parallel. For\nexample, this may be useful to see how memory usage changes over time.\n\nTelemetry support requires the `psutil` library.\n\nMicrobench launches and cleans up the monitoring thread automatically.\nThe end user only needs to define a `telemetry` static method, which accepts\na [psutil.Process](https://psutil.readthedocs.io/en/latest/#psutil.Process)\nobject and returns the telemetry data as a dictionary.\n\nThe default telemetry collection interval is every 60 seconds, which can be\ncustomized if needed using the `telemetry_interval` class variable.\n\nA minimal example to capture memory usage every 90 seconds is shown below:\n\n```python\nfrom microbench import MicroBench\n\nclass TelemBench(MicroBench):\n    telemetry_interval = 90\n\n    @staticmethod\n    def telemetry(process):\n        return process.memory_full_info()._asdict()\n\ntelem_bench = TelemBench()\n```\n\n## Extending microbench\n\nMicrobench includes a few mixins for basic functionality as described in the\nextended example, above.\n\nYou can also add functions to your benchmark suite to capture\nextra information at runtime. These functions must be prefixed with `capture_`\nfor them to run automatically before the function starts. They take\na single argument, `bm_data`, a dictionary to be extended with extra data.\nCare should be taken to avoid overwriting existing key names.\n\nHere's an example to capture the machine type (`i386`, `x86_64` etc.):\n\n```python\nfrom microbench import MicroBench\nimport platform\n\nclass Bench(MicroBench):\n    outfile = '/home/user/my-benchmarks'\n\n    def capture_machine_platform(self, bm_data):\n        bm_data['platform'] = platform.machine()\n        \nbenchmark = Bench()\n```\n\n## Extending JSONEncoder\n\nMicrobench encodes data in JSON, but sometimes Microbench will\nencounter data types (like custom objects or classes)\nthat are not encodable as JSON by default (usually meaning they\ndon't have a way to be represented as a string, list, or\ndictionary). For example, when using the `MBFunctionCall` and\n`MBReturnValue`, a warning will be shown if any argument or\nreturn value (respectively) is not encodable as JSON, and the\nvalue will be replaced with a placeholder to allow the metadata\ncapture to continue, and a warning will be shown.\n\nIf you wish to actually capture those values, you will need to\nspecify a way to convert the object to JSON. This is done using\nby extending `microbench.JSONEncoder` with a test for the object\ntype and implementing a conversion to a string, list, or dict.\n\nFor example, to capture a `Graph` object from the `igraph`\npackage using `str(graph)` as the representation, we could\ndo the following (note that we could use any representation\nwe want, e.g. if we wanted to capture the object in a more\nor less detailed way):\n\n```\nimport microbench as mb\nfrom igraph import Graph\n\n# Extend the JSONEncoder to encode Graph objects\nclass CustomJSONEncoder(mb.JSONEncoder):\n    def default(self, o):\n        # Encode igraph.Graph objects as strings\n        if isinstance(o, Graph):\n            return str(o)\n\n        # Add further isinstance(o, ...) cases here\n        # if needed\n\n        # Make sure to call super() to handle\n        # default cases\n        return super().default(o)\n\n# Define your benchmark class as normal\nclass Bench(mb.MicroBench, mb.MBReturnValue):\n    pass\n\n# Create a benchmark suite with the custom JSON\n# encoder from above\nbench = Bench(json_encoder=CustomJSONEncoder)\n\n# Attach the benchmark suite to our function\n@bench\ndef return_a_graph():\n    return Graph(2, ((0, 1), (0, 2)))\n\n# This should now work without warnings or errors\nreturn_a_graph()\n```\n\n## Redis support\n\nBy default, microbench appends output to a file, but output can be directed\nelsewhere, e.g. [redis](https://redis.io) - an in-memory, networked data source.\nThis option is useful when a shared filesystem is not available.\n\nRedis support requires [redis-py](https://github.com/andymccurdy/redis-py).\n\nTo use this feature, inherit from `MicroBenchRedis` instead of `MicroBench`,\nand specify the redis connection and key name as in the following example:\n\n```python\nfrom microbench import MicroBenchRedis\n\nclass RedisBench(MicroBenchRedis):\n    # redis_connection contains arguments for redis.StrictClient()\n    redis_connection = {'host': 'localhost', 'port': 6379}\n    redis_key = 'microbench:mykey'\n\nbenchmark = RedisBench()\n```\n\nTo retrieve results, the `redis` package can be used directly:\n\n```python\nimport redis\nimport pandas\n\n# Establish the connection to redis\nrconn = redis.StrictRedis(host=..., port=...)\n\n# Read the redis data from 'myrediskey' into a list of byte arrays\nredis_data = redis.lrange('myrediskey', 0, -1)\n\n# Convert the list into a single string\njson_data = '\\n'.join(r.decode('utf8') for r in redis_data)\n\n# Read the string into a pandas dataframe\nresults = pandas.read_json(json_data, lines=True)\n```\n\n## Runtime impact considerations\n\nThe runtime impact varies depending on what information is captured and by platform.\nBroadly, capturing environment variables, Python package versions, and timing\ninformation for a function has a negligible impact. Capturing telemetry and\ninvoking external programs (like `nvidia-smi` for GPU information) has a larger impact,\nalthough the latter is a one-off per invocation and typically less than one second.\nTelemetry capture intervals should be kept relatively infrequent (e.g., every minute\nor two, rather than every second) to avoid significant runtime impacts.\n\n## Feedback\n\nPlease note this is a recently created, experimental package. Please let me know\nyour feedback or feature requests in Github issues.\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/alubbock/microbench",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "microbench",
    "package_url": "https://pypi.org/project/microbench/",
    "platform": null,
    "project_url": "https://pypi.org/project/microbench/",
    "project_urls": {
      "Homepage": "https://github.com/alubbock/microbench"
    },
    "release_url": "https://pypi.org/project/microbench/0.8/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "Micro-benchmarking framework. Extensible, with distributed/cluster support.",
    "version": "0.8",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 15737662,
  "releases": {
    "0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f32e432b030d171e69b01caf1df57216ebad5fd9771cb0ab86c6f1afdb4a05c8",
          "md5": "35183c81d2ecdb53aa999fcb72891168",
          "sha256": "462f81aad7e9f94e7f986da07c8042a03ccb39df8aed596e1abf4bd68a437533"
        },
        "downloads": -1,
        "filename": "microbench-0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "35183c81d2ecdb53aa999fcb72891168",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 19282,
        "upload_time": "2018-08-02T22:54:14",
        "upload_time_iso_8601": "2018-08-02T22:54:14.602809Z",
        "url": "https://files.pythonhosted.org/packages/f3/2e/432b030d171e69b01caf1df57216ebad5fd9771cb0ab86c6f1afdb4a05c8/microbench-0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c6aa0ea8fabae331a4c5eeceaffcadae36cc4bdc8b2dc128824a1c67da474e58",
          "md5": "a946bbc9d0d9b20e39295b0956fb164f",
          "sha256": "a968f1951f3257b07e7e6820e571c0c2189eeb648b5832734dc49bb5899ed510"
        },
        "downloads": -1,
        "filename": "microbench-0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "a946bbc9d0d9b20e39295b0956fb164f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 20114,
        "upload_time": "2018-08-03T18:58:58",
        "upload_time_iso_8601": "2018-08-03T18:58:58.063170Z",
        "url": "https://files.pythonhosted.org/packages/c6/aa/0ea8fabae331a4c5eeceaffcadae36cc4bdc8b2dc128824a1c67da474e58/microbench-0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.2.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "881a1137ea6c03ee0a929e9acec0e0b4760590b4914100e5752614fd04e1b20c",
          "md5": "152a559f242634e788b45c9c140f63ff",
          "sha256": "65ebb1c8023008d707b966c8884ee6e9c4845b9561f8e0aa09bc55e236a5ef21"
        },
        "downloads": -1,
        "filename": "microbench-0.2.1.tar.gz",
        "has_sig": false,
        "md5_digest": "152a559f242634e788b45c9c140f63ff",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 23728,
        "upload_time": "2018-08-03T22:41:28",
        "upload_time_iso_8601": "2018-08-03T22:41:28.886195Z",
        "url": "https://files.pythonhosted.org/packages/88/1a/1137ea6c03ee0a929e9acec0e0b4760590b4914100e5752614fd04e1b20c/microbench-0.2.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e1e6cda6d93ba43ab31fec68baa2b209629223601d75c5d216837e5511f9d7fe",
          "md5": "73ef0cd5f78e510c8a7c4792a021a6d2",
          "sha256": "eafcbd3476c73ffa936d39237bb5b06ec55541cb4ed2d91e64318b2b1d627f1d"
        },
        "downloads": -1,
        "filename": "microbench-0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "73ef0cd5f78e510c8a7c4792a021a6d2",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 24320,
        "upload_time": "2018-08-06T15:38:45",
        "upload_time_iso_8601": "2018-08-06T15:38:45.199382Z",
        "url": "https://files.pythonhosted.org/packages/e1/e6/cda6d93ba43ab31fec68baa2b209629223601d75c5d216837e5511f9d7fe/microbench-0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.4.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0195ae9f9cb7f748e47fedae2813332b65eb2201b880524bbbfb141c3b762135",
          "md5": "50f922e4687c7aa12221b1fcfc1fbbfb",
          "sha256": "87a1a6fc8d33e8a91feed051341b54761aca19fcc0503632ad59cbadb545a7b4"
        },
        "downloads": -1,
        "filename": "microbench-0.4.1.tar.gz",
        "has_sig": false,
        "md5_digest": "50f922e4687c7aa12221b1fcfc1fbbfb",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 23768,
        "upload_time": "2019-03-06T00:08:41",
        "upload_time_iso_8601": "2019-03-06T00:08:41.780428Z",
        "url": "https://files.pythonhosted.org/packages/01/95/ae9f9cb7f748e47fedae2813332b65eb2201b880524bbbfb141c3b762135/microbench-0.4.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0fa12a679d7be2be0b8691926b9e6b122e6c386c2f92a1522c71243c1c7e789d",
          "md5": "6674606e04c8be55e3c3b717a2136f9e",
          "sha256": "a4bd186b309f86668733168d69d484acff5a27ca69a8ee40e264701cacb6b299"
        },
        "downloads": -1,
        "filename": "microbench-0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "6674606e04c8be55e3c3b717a2136f9e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 25762,
        "upload_time": "2019-03-14T20:53:29",
        "upload_time_iso_8601": "2019-03-14T20:53:29.542781Z",
        "url": "https://files.pythonhosted.org/packages/0f/a1/2a679d7be2be0b8691926b9e6b122e6c386c2f92a1522c71243c1c7e789d/microbench-0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "db50f86fc468c0bb59fb30685e66839b2961a3cdfc8da86e17d340ee82457d01",
          "md5": "ec9599fbbadb8204d47ec672f3c373a8",
          "sha256": "b8912d2dae202657f7ea78725df6d497b72c77ea4827d13e88ddd3b37bad3d30"
        },
        "downloads": -1,
        "filename": "microbench-0.6.tar.gz",
        "has_sig": false,
        "md5_digest": "ec9599fbbadb8204d47ec672f3c373a8",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 25998,
        "upload_time": "2021-03-02T04:45:01",
        "upload_time_iso_8601": "2021-03-02T04:45:01.120513Z",
        "url": "https://files.pythonhosted.org/packages/db/50/f86fc468c0bb59fb30685e66839b2961a3cdfc8da86e17d340ee82457d01/microbench-0.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7cac8370732695968b2d61e03d325656e9353cc97e75ed5c35ed4058fc95af85",
          "md5": "cdf3dd04dc686d7259171607964ffdb7",
          "sha256": "cb9802f1d64fafd8072641119e10cc6374942449cb8be2c096c4b62595f3f6f2"
        },
        "downloads": -1,
        "filename": "microbench-0.7.tar.gz",
        "has_sig": false,
        "md5_digest": "cdf3dd04dc686d7259171607964ffdb7",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 31659,
        "upload_time": "2021-07-01T01:07:48",
        "upload_time_iso_8601": "2021-07-01T01:07:48.906445Z",
        "url": "https://files.pythonhosted.org/packages/7c/ac/8370732695968b2d61e03d325656e9353cc97e75ed5c35ed4058fc95af85/microbench-0.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1800e592866c23401e148f6e0e64d2cdb81824100662530e59e34e4b040ec65d",
          "md5": "b47e78b995e99018b2e155df76f28e69",
          "sha256": "5a199c1cf50123854eaf8047729dc11b098ec51fbc010d6decd577c52fbc66e4"
        },
        "downloads": -1,
        "filename": "microbench-0.8.tar.gz",
        "has_sig": false,
        "md5_digest": "b47e78b995e99018b2e155df76f28e69",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 34347,
        "upload_time": "2022-11-11T16:50:04",
        "upload_time_iso_8601": "2022-11-11T16:50:04.917557Z",
        "url": "https://files.pythonhosted.org/packages/18/00/e592866c23401e148f6e0e64d2cdb81824100662530e59e34e4b040ec65d/microbench-0.8.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "1800e592866c23401e148f6e0e64d2cdb81824100662530e59e34e4b040ec65d",
        "md5": "b47e78b995e99018b2e155df76f28e69",
        "sha256": "5a199c1cf50123854eaf8047729dc11b098ec51fbc010d6decd577c52fbc66e4"
      },
      "downloads": -1,
      "filename": "microbench-0.8.tar.gz",
      "has_sig": false,
      "md5_digest": "b47e78b995e99018b2e155df76f28e69",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 34347,
      "upload_time": "2022-11-11T16:50:04",
      "upload_time_iso_8601": "2022-11-11T16:50:04.917557Z",
      "url": "https://files.pythonhosted.org/packages/18/00/e592866c23401e148f6e0e64d2cdb81824100662530e59e34e4b040ec65d/microbench-0.8.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}