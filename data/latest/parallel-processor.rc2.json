{
  "info": {
    "author": "lianxiaolei,wangyue",
    "author_email": "lian222@foxmail.com,wangyue29@tal.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# 介绍\n\n我们提供了一个可快速处理大量数据的多进程数据处理模块\n\n此模块可以处理list、numpy、pandas等数据，并且可以以tuple的形式输入，以tuple的形式输出\n\n中间的处理过程可以让用户来决定，只要传入一个自定义函数即可\n\n可设置进程数\n\n----------------------------\n\n# 作者\n\n* 连晓磊 lian222@foxmail.com\n* 王岳   wangyue29@tal.com\n\n----------------------------\n# 样例\n\n引入：\n```python\nfrom parallel_processor import process_data\n\n# 注意在向进程池传入处理函数时，不能使用lambda的方式，否则会报错\nfrom functools import partial\n```\n\n样例1：分词\n```python\ndef seg(x):\n    result = []\n    for i in tqdm_notebook(x):\n        result.append(list(jieba.cut(i)))\n    return result\n\ndata = process_data(data, seg, num_workers=16)\n```\n\n-------------\n\n样例2：text2ids\n```python\ndef convert_example(x, f_token, max_seq_len, return_raw_data=False, mask_rate=0, x1=None, avg_split=False):\n    input_ids_list = []\n    input_mask_list = []\n    segment_ids_list = []\n    input_ids_gt_list = []\n    contents = []\n\n    if x1 is not None:\n        if \"JPY_PARENT_PID\" in os.environ:\n            bar = tqdm_notebook(zip(x, x1))\n        else:\n            bar = tqdm(zip(x, x1))\n    else:\n        if \"JPY_PARENT_PID\" in os.environ:\n            bar = tqdm_notebook(x)\n        else:\n            bar = tqdm(x)\n\n    for line in bar:\n        if x1 is not None:\n            line, line1 = line[0], line[1]\n        else:\n            line1 = ''\n        if mask_rate <= 0:\n            input_ids, input_mask, segment_ids = convert_single_example(max_seq_len, f_token, line, line1,\n                                                                        avg_split=avg_split)\n        else:\n            input_ids, input_mask, segment_ids, input_ids_gt = convert_single_example_with_mlm(\n                max_seq_len, f_token, line, line1, avg_split=avg_split)\n\n        input_ids = np.array(input_ids)\n        input_mask = np.array(input_mask)\n        segment_ids = np.array(segment_ids)\n        input_ids_list.append(input_ids)\n        input_mask_list.append(input_mask)\n        segment_ids_list.append(segment_ids)\n        if mask_rate > 0:\n            input_ids_gt = np.array(input_ids_gt)\n            input_ids_gt_list.append(input_ids_gt)\n\n        if return_raw_data:\n            contents.append(list(line.replace('\\n', '')))\n\n    if mask_rate > 0:\n        if return_raw_data:\n            return np.array(input_ids_list), np.array(input_mask_list), np.array(segment_ids_list), \\\n                   np.array(input_ids_gt_list), np.array(contents)\n        return np.array(input_ids_list), np.array(input_mask_list), np.array(segment_ids_list), \\\n               np.array(input_ids_gt_list)\n    else:\n        if return_raw_data:\n            return np.array(input_ids_list), np.array(input_mask_list), np.array(segment_ids_list), np.array(contents)\n        return np.array(input_ids_list), np.array(input_mask_list), np.array(segment_ids_list)\n\ndef _process(text, **kwargs):\n    f_token = kwargs.get('f_token')\n    max_seq_len = kwargs.get('max_seq_len', 128)\n    return_raw_data = kwargs.get('return_raw_data', False)\n    mask_rate = kwargs.get('mask_rate', 0)\n    avg_split = kwargs.get('avg_split', False)\n    if len(text.shape) > 1:\n        text_a, text_b = text[:, 0], text[:, 1]\n        return convert_example(text_a, f_token, max_seq_len, return_raw_data, mask_rate, text_b, avg_split=avg_split)\n    else:\n        return convert_example(text, f_token, max_seq_len, return_raw_data, mask_rate, avg_split=avg_split)\n\nvocab_file = os.path.join(bert_model_dir, \"vocab.txt\")\nf_token = FullTokenizer(vocab_file)\n\ntext = data[text_cols].values\nfunc_kwargs = {'f_token': f_token, 'max_seq_len': max_seq_len, 'return_raw_data': return_raw_data,\n               'mask_rate': mask_rate, 'avg_split': avg_split}\n\nresult = process_data(text, _process, num_workers=16, is_tuple_data=False, func_kwargs=func_kwargs)\ninput_ids = result[0]\ninput_mask = result[1]\nsegment_ids = result[2]\n```",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/Fakekid/parallel-processor",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "parallel-processor",
    "package_url": "https://pypi.org/project/parallel-processor/",
    "platform": null,
    "project_url": "https://pypi.org/project/parallel-processor/",
    "project_urls": {
      "Homepage": "https://github.com/Fakekid/parallel-processor"
    },
    "release_url": "https://pypi.org/project/parallel-processor/0.1.5/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "Parallelling Data Processor",
    "version": "0.1.5",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 13424273,
  "releases": {
    "0.1.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d75656993681fba6e8fb92abb3efab7cfc490952f13fcfeb673ec81d44242373",
          "md5": "a400f814f62e8e4622345de1b9059a4d",
          "sha256": "a60473844d832d65ab27ea9f9423f03f57d109db1f17cac09aa6b63e3d8f3299"
        },
        "downloads": -1,
        "filename": "parallel_processor-0.1.4.tar.gz",
        "has_sig": false,
        "md5_digest": "a400f814f62e8e4622345de1b9059a4d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 4208,
        "upload_time": "2021-10-11T10:16:36",
        "upload_time_iso_8601": "2021-10-11T10:16:36.917770Z",
        "url": "https://files.pythonhosted.org/packages/d7/56/56993681fba6e8fb92abb3efab7cfc490952f13fcfeb673ec81d44242373/parallel_processor-0.1.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6033a3aeb1b82d556f592cc76743ddd57b6bc86a0581c4c5217932854e2ccf01",
          "md5": "919ce4d45e199038610d51603afa0186",
          "sha256": "50767eb740f2bb89000f9b7d543f1bfdf0a46dd52314e916706aa93f697b12a5"
        },
        "downloads": -1,
        "filename": "parallel_processor-0.1.5.tar.gz",
        "has_sig": false,
        "md5_digest": "919ce4d45e199038610d51603afa0186",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 4163,
        "upload_time": "2022-04-06T02:19:49",
        "upload_time_iso_8601": "2022-04-06T02:19:49.475802Z",
        "url": "https://files.pythonhosted.org/packages/60/33/a3aeb1b82d556f592cc76743ddd57b6bc86a0581c4c5217932854e2ccf01/parallel_processor-0.1.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "6033a3aeb1b82d556f592cc76743ddd57b6bc86a0581c4c5217932854e2ccf01",
        "md5": "919ce4d45e199038610d51603afa0186",
        "sha256": "50767eb740f2bb89000f9b7d543f1bfdf0a46dd52314e916706aa93f697b12a5"
      },
      "downloads": -1,
      "filename": "parallel_processor-0.1.5.tar.gz",
      "has_sig": false,
      "md5_digest": "919ce4d45e199038610d51603afa0186",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 4163,
      "upload_time": "2022-04-06T02:19:49",
      "upload_time_iso_8601": "2022-04-06T02:19:49.475802Z",
      "url": "https://files.pythonhosted.org/packages/60/33/a3aeb1b82d556f592cc76743ddd57b6bc86a0581c4c5217932854e2ccf01/parallel_processor-0.1.5.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}