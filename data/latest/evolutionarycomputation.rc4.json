{
  "info": {
    "author": "Brandon Morgan",
    "author_email": "morganscottbrandon@gmail.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# EvolutionaryComputation\n\n--------------------------------\nEvolutionaryComputation is a Python module containing advanced algorithms in the realm of Evolutionary Computation.\nEvolutionary Computation is a domain of Computational Intelligence, a sub-field Artificial Intelligence,\nwhere the goal is to model biological evolution in terms as an optimization process. See the section,\n`Quick Overview of Evolutionary Algorithms` below for information. \n\n# WORK IN PROGRESS\n\nThis library is still in heavy construction. As of current, the only modules that are fully functional are `NeuroEvolution`,\nminus `NeuroReinforcerImages`, `OptimizationProblems`, lacks examples and readme, `GeneticAlgorithms`, and only \n`CustomAutoMLAlgorithm` from `AutoML`. In addition, documentation is still in progress, please see example notebooks on how\nto use the algorithms, if present in their submodule. \n\n# GitHub Repository\n\nhttps://github.com/OUStudent/EvolutionaryComputation\n\n# Installation\n\n```python\npip install EvolutionaryComputation\n```\n\n--------------------------------\n# Dependencies\n\n- numpy\n- sklearn\n- tensorflow\n- keras\n- matplotlib\n- scipy\n- psutil\n\n--------------------------------\n\n# Algorithms Included\n\n--------------------------------\nAs of current, there are three main types of submodules of algorithms included: Genetic Algorithms for solving \noptimization problems; genetic algorithms specifically created for evolving the weights of neural network for classification, \nregression, auto-encoders, and reinforcement learning; and genetic algorithms specifically created for automated machine\nlearning through hyperparameter optimization. In addition, within the automated machine learning submodule, a framework\nfor evolving the architecture of deep and convolutional neural networks via Keras API has been developed.\n\n## Optimization Problems\n\nAs of current, there exists four classes for solving optimization problems, `GenericUnconstrainedProblem` and \n`HyperParamUnconstrainedProblem` for solving unconstrained problems, `ConstrainedProblem` for solving constrained problems, \nand `ParetoFrontMOP` for solving multi-objective problems by finding the pareto-front.\n\n## NeuroEvolution \n\n### Regression, Classification, and Auto-Encoders\n\nAs of current, there exists three classes for training feed forward neural networks, `NeuroRegressor`, `NeuroClassifier`,\nand `NeuroAutoEncoder`. All three classes use highly specialized genetic algorithms for evolving only the weights\nof a feed forward neural network, keeping the layer and node counts, along with activation functions static. `NeuroRegressor`\nis specialized for regressional analysis, `NeuroClassifier` for classification or labeling, and `NeuroAutoEncoder` for\nencoding and decoding. \n\nNOTE: It must be stated that neuro-evolutionary algorithms for `NeuroRegressor`, `NeuroClassifier`, and `NeuroAutoEncoder`\nare not designed for extremely large models. Genetic algorithms work extremely well when the number of parameters is extremely\nsmall; however, in practice, standard neural networks can have up to millions of trainable parameters. It is suggested that\nif the number of trainable parameters is greater than 10,000 then these neuro-evolutionary algorithms will fail to evolve \nany meaningful networks. It is suggested that this submodule should be purely educational and experimental, or practible\nfor small number of inputs and network sizes. See example notebooks in submodule for realistic examples.\n\n### Reinforcement Learning\n\nAs of current, there exists two classes for reinforcement learning, `NeuroReinforcer` and `NeuroReinforerImages`. Both of \nthese classes work by evolving the weights of a static feed forward neural network. However, they have been adapted to\nevolve activation functions for each layer. `NeuroReinforcer` is designed for handling non-image like numerical input, \nwhile `NeuroReinforerImages` is designed for handling three channel image like input. \n\n## Automated Machine Learning\n\nAs of current, there are two main classes for automated machine learning. The first is a general framework for optimizing \nthe hyper-parameters of a generic machine learning algorithm, `CustomAutoMLAlgorithm`. The second is a framework specifically\ndesigned for evolving both deep and convolutional neural networks through the Keras API, `NetworkArchitectureEvolution`.\nPlease see the notebook examples on how the algorithms are developed and used. \n\n--------------------------------\n# Quick Overview of Evolutionary Algorithms\n\n--------------------------------\n## Introduction\n\nEvolution can be described as a process by which individuals become â€˜fitterâ€™ in different environments through \nadaptation, natural selection, and selective breeding. In evolutionary computation, the goal is to try \nto model these principles to find the best solution to a problem. Each possible solution to a problem is represented as \nan individual in a pool of a population, where one performs adaptation, natural selection, and selective breeding on \nthose possible solutions to find the best solution for the problem.\n\n### Optimization Problems\n\nEvolutionary Computation is commonly used to solve/find the minima or maxima of optimization problems. There are three\nmain types of optimization problems: unconstrained, constrained, and multi-objective. Unconstrained problems can be as \nsimple as minimizing the error rate of a function given some weights or parameters, while constrained problems might involve\nminimizing the cost of a pressure vessel through optimizing the dimensions of the vessel while meeting some safety and \nphysics criterion. Lastly, multi-objective problems are situations where the goal is to solve multiple constrained or unconstrained\noptimization problems simultaneously. The inspiration for using Evolutionary Computation in finding these extrema points\nis that Evolutionary Algorithms are guided random search techniques that do not require knowledge of the derivative of the function,\nwhich is the main component of classical numerical methods. \n\n### Diagram Overview\n\nHere is a basic flow diagram of an evolutionary algorithm:\n\n![Diagram Overview](EvolutionaryComputation.egg-info/img.png)\n\nThe algorithm can be broken down into six main components Initial Population, Selection for Reproduction, Crossover, Mutation,\nSelection for Survival, and Termination:\n\n### Initial Population\n\nThe goal of the initial population is to present the algorithm with a range of diverse solutions. Initial populations where \neach solution is similar will only lead to a local search while initial populations with very distinct solutions will lead \nto a global search. The tradeoff between the two is that a local search will converge much quicker than a global search. \n\n### Selection for Reproduction\n\nThe purpose of selecting individuals for reproduction is to model natural selection in how only the fittest individuals \nare allowed to mate. There are many different ways for selecting individuals for reproduction, but all have a tradeoff \nbetween exploration and exploitation. Exploration refers to how well the algorithm explores the domain space, while exploitation\nrefers to how well the algorithm will converge. If the selection criterion for reproduction is random then good solutions \nmight mate with bad solutions and create worse solutions; however, if the selection criterion for reproduction is to only \ntake the best, then that is equivalent to a local search. After the set of parents have been selected for reproduction, \nthe offspring is created through two main mechanisms: crossover and mutation. \n\n### Crossover Techniques\n\nThe goal of crossover is to combine the informational material of the parents. There are two main types of crossover operators,\naveraging and 'intuitive' crossover. Averaging simply takes the average of the variable values of the parents, while 'intuitive'\ncrossover swaps the variable values of the parents. One of the main problems of crossover is known as the 'permutation' problem,\nwhere two independent solutions can have extremely different variable values but yield similar results, thus averaing or swapping\ntheir variable values can yield poor offspring; however, this normally only occurs when designing extremely complex systems, \nsuch as neural network architectures.  \n\n### Mutation Techniques\n\nThe goal of mutation is to introduce new informational material into the offspring. After the offspring has been crossed \nover, new information can be inserted by simply adding small perturbations to the variables values of the offspring. Another \nproblem with crossover is that it only works with the informational material of the parents, which are based off the informational\nmaterial of the initial population. In this way, for the algorithm to explore new regions it needs new variable values that\nwere not present in the parents. This is achieved through mutation by simply adding small random values to the offspring. \n\n### Selection for Survival\n\nOnce the offspring is created it is time to decide who survives and who does not. Do the offspring always replace the parents?\nAre multiple offspring created per set of parents, and the best set wins? Or are all the parents and offspring pooled together, and\nthe best half are selected for survival? As stated in the Selection for Reproduction section, selection for survival is \ndirectly influential on the exploration and exploitation of the algorithm. If random selection is used for survival then \nthe algorithm has great exploration as it does not converge to any particular solution, but since the selection is random \nthen there is a chance that the best solution can be lost. However, on the other hand, if only the best solutions are kept\nfor survival then the algorithm shows great exploitation as it will never lose the best solutions, but it will show poor \nexploration as the algorithm will be equivalent to performing a local search about the top solutions. \n\n### Termination\n\nThe algorithm repeats the process of selection for reproduction, crossover, mutation, and selection for survival until termination.\nThe most common termination criterion is simply exiting once the number of generations has reached a user defined limit. \n\n\n## Further Resources\n\n--------------------------------\nEvolutionary Computation is a very broad and dense subject that can take up an entire semester at the senior or graduate \nlevel in a Computer Science program. The brief overview given only details the subject matter necessary to understand the \nbasics of Evolutionary Computation. If you are wanting to learn more about the subject, I, the author, have written extensively\nover the subject by providing a full course on Towards Data Science.  \n\nHere is the main page containing all the links to the articles:\n\nhttps://towardsdatascience.com/evolutionary-computation-full-course-overview-f4e421e945d9",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "EvolutionaryComputation",
    "package_url": "https://pypi.org/project/EvolutionaryComputation/",
    "platform": "",
    "project_url": "https://pypi.org/project/EvolutionaryComputation/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/EvolutionaryComputation/0.0.5/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "Python module containing algorithms in the domain of Evolutionary Computation",
    "version": "0.0.5",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 11346921,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ae44d48e4417239f7757015230f0e69a90a9aa88ba10244414d48ad216a7832f",
          "md5": "543fbb9863084a59f9a581fe3fe86b94",
          "sha256": "9b50e0514c3f4848e2be9897acff93dbe5671d96ea34c36aff0e0604c4bcaa2d"
        },
        "downloads": -1,
        "filename": "EvolutionaryComputation-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "543fbb9863084a59f9a581fe3fe86b94",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 4201,
        "upload_time": "2021-08-11T16:29:28",
        "upload_time_iso_8601": "2021-08-11T16:29:28.143446Z",
        "url": "https://files.pythonhosted.org/packages/ae/44/d48e4417239f7757015230f0e69a90a9aa88ba10244414d48ad216a7832f/EvolutionaryComputation-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6caee12a214b76079381bbd2306c3047a0b6cd28b1f399e30294c6a3eb33b5aa",
          "md5": "ca7e86d4debaa9d7ab60140dc023600c",
          "sha256": "b2bd82ecd87f80a95c59e5203ac28604360c67a66e7036afe74ab580ceeb46d7"
        },
        "downloads": -1,
        "filename": "EvolutionaryComputation-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "ca7e86d4debaa9d7ab60140dc023600c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 11874,
        "upload_time": "2021-08-21T19:50:45",
        "upload_time_iso_8601": "2021-08-21T19:50:45.043983Z",
        "url": "https://files.pythonhosted.org/packages/6c/ae/e12a214b76079381bbd2306c3047a0b6cd28b1f399e30294c6a3eb33b5aa/EvolutionaryComputation-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "07cb0c3d7105a0e1acc1864973e4ed4e08295256eae15409b7e8c8e403e56110",
          "md5": "73a87a949d466aeff1eef8f60f50ecd0",
          "sha256": "6568d1d1974507e579504e607e988de472ae3b191fd24b26b480ee9584c35b34"
        },
        "downloads": -1,
        "filename": "EvolutionaryComputation-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "73a87a949d466aeff1eef8f60f50ecd0",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 11857,
        "upload_time": "2021-08-21T19:50:46",
        "upload_time_iso_8601": "2021-08-21T19:50:46.690042Z",
        "url": "https://files.pythonhosted.org/packages/07/cb/0c3d7105a0e1acc1864973e4ed4e08295256eae15409b7e8c8e403e56110/EvolutionaryComputation-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5bd8ba19a37b5ad63905ec906abfe16131dc5c1c5f061b6f67314bcf12c55e26",
          "md5": "ac7319511dc852e0c754596fd68361da",
          "sha256": "b1fb71ff0f5df15ba78796957aa9401651eb1cf760c72021fa3a483702dc4e4d"
        },
        "downloads": -1,
        "filename": "EvolutionaryComputation-0.0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "ac7319511dc852e0c754596fd68361da",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 15545,
        "upload_time": "2021-09-02T13:05:04",
        "upload_time_iso_8601": "2021-09-02T13:05:04.900912Z",
        "url": "https://files.pythonhosted.org/packages/5b/d8/ba19a37b5ad63905ec906abfe16131dc5c1c5f061b6f67314bcf12c55e26/EvolutionaryComputation-0.0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "5bd8ba19a37b5ad63905ec906abfe16131dc5c1c5f061b6f67314bcf12c55e26",
        "md5": "ac7319511dc852e0c754596fd68361da",
        "sha256": "b1fb71ff0f5df15ba78796957aa9401651eb1cf760c72021fa3a483702dc4e4d"
      },
      "downloads": -1,
      "filename": "EvolutionaryComputation-0.0.5.tar.gz",
      "has_sig": false,
      "md5_digest": "ac7319511dc852e0c754596fd68361da",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 15545,
      "upload_time": "2021-09-02T13:05:04",
      "upload_time_iso_8601": "2021-09-02T13:05:04.900912Z",
      "url": "https://files.pythonhosted.org/packages/5b/d8/ba19a37b5ad63905ec906abfe16131dc5c1c5f061b6f67314bcf12c55e26/EvolutionaryComputation-0.0.5.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}