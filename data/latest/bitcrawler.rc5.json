{
  "info": {
    "author": "Austyn Herman",
    "author_email": "austynherman112994@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: Apache Software License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# BitCrawler\n## What is it?\n**Bitcrawler** is a Python package that provides functionality for crawling & scraping the web. The library brings simplicity, speed, and extensibility to any crawling project.\nThe library can be exteded to easily add on additional crawling behavior and functionality for specific use cases.\n\n\n## Installation\n```sh\npip install bitcrawler\n```\n\n## Documentation\n\nSee the documentation at https://bitcrawler.readthedocs.io/en/latest/bitcrawler.html#bitcrawler for more details on usage.\n\n## Example Crawler\n\nCrawling webpages will begin by fetching the original URL supplied. The crawler will traverse links discoverd on the\npages until it reaches the specified crawl depth or runs out of links.\n\nA bitcrawler.webpage.Webpage class instance will be returned for each page fetched. To see more details on\nthe Webpage class see the documetation on the class (https://bitcrawler.readthedocs.io/en/latest/bitcrawler.html#module-bitcrawler.webpage).\n\n### Simple Usage\n\n```py\nfrom bitcrawler.crawler import Crawler\n\ncrawler = Crawler()\n# Returns a list of bitcrawler.webpage.Webpage objects.\n# See the Webpage class for more details on its members.\ncrawled_pages = crawler.crawl('http://test.com')\n\n```\n\n### Advanced Usage\n\nThe below example extends the crawler object and overrides the parse function.\nThe parse function is always called at the end of crawling. It is passed all the pages fetched.\nIn the below example the pages are parsed using beautifulsoup and the title is printed with the URL.\n\n\n```py\nfrom bs4 import BeautifulSoup\nfrom bitcrawler.crawler import Crawler\nfrom bitcrawler import webpage\n\nclass MyCrawler(Crawler):\n    # Parse is always called py the `crawl` method and is provided\n    # a webpage.Webpage class instance for each URL.\n    # See the webpage.Webpage class for details about the object.\n    def parse(self, webpages):\n        for page in webpages:\n            # If page response is not none, response code is in 200s, and document is html.\n            if page.response and \\\n               page.response.ok and \\\n               page.response.headers.get('content-type').startswith('text/html'):\n                soup = BeautifulSoup(page.response.text, \"html.parser\")\n                print(page.url, \"- \", soup.title) \n        return webpages\n\n# Initializes the crawler with the configuration specified by parameters.\ncrawler = MyCrawler(\n    user_agent='python-requests', # The User Agent to use for all requests.\n    crawl_delay=0, # Number of seconds to wait between web requests.\n    crawl_depth=2, # The max depth from following links (Default is 5).\n    cross_site=False, # If true, domains other than the original domain can be crawled.\n    respect_robots=True, # If true, the robots.txt standard will be followed.\n    respect_robots_crawl_delay=True, # If true, the robots.txt crawl delay will be followed.\n    multithreading=True, # If true, parallelizes requests for faster crawling.\n    max_threads=100, # If multithreading is true, this determines the number of threads.\n    webpage_builder=webpage.WebpageBuilder, # Advanced Usage - Allows the WebpageBuilder class to be overridden to allow modificaion.\n    request_kwargs={'timeout': 10}, # Additional keyword arguments that you would like to pass into any request made.\n    reppy_cache_capacity=100, # The number of robots.txt objects to cache. Eliminates the need to fetch robots.txt file many times.\n    reppy_cache_policy=None, # Advanced Usage - See docs for details.\n    reppy_ttl_policy=None, # Advanced Usage - See docs for details.\n    reppy_args=tuple()) # Advanced Usage - See docs for details.\n\n# Crawls pages starting from \"http://test.com\"\n# Returns a list of bitcrawler.webpage.Webpage objects.\n# See the Webpage class for more details on its members.\ncrawled_pages = crawler.crawl(\n    url=\"http://test.com\", # The start URL to crawl from.\n    allowed_domains=[], # A list of allowed domains. `cross_site` must be True. Ex. ['python.org',...]\n    disallowed_domains=[], # A list of disallowed domains. `cross_site` must be True and `allowed_domains` empty.\n    page_timeout=10) # The ammount of time before a page retrieval/build times out.\n\n```\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/austynherman112994/bitcrawler",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "bitcrawler",
    "package_url": "https://pypi.org/project/bitcrawler/",
    "platform": "",
    "project_url": "https://pypi.org/project/bitcrawler/",
    "project_urls": {
      "Homepage": "https://github.com/austynherman112994/bitcrawler"
    },
    "release_url": "https://pypi.org/project/bitcrawler/0.1.0/",
    "requires_dist": [
      "requests",
      "reppy",
      "beautifulsoup4",
      "validators"
    ],
    "requires_python": ">=3.6",
    "summary": "Crawling the web made easy.",
    "version": "0.1.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 9721009,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "645a775352677a7cb6154526b52f3ee3f48a5449898074865b1eea09e34c63a6",
          "md5": "be9ff241dd53d0c38649c49a5975e1a9",
          "sha256": "3a993139416dcbc375bab1e2ce9799a0a81d778961dd631cb351ddccde71766a"
        },
        "downloads": -1,
        "filename": "bitcrawler-0.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "be9ff241dd53d0c38649c49a5975e1a9",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 17403,
        "upload_time": "2021-02-21T05:43:44",
        "upload_time_iso_8601": "2021-02-21T05:43:44.700043Z",
        "url": "https://files.pythonhosted.org/packages/64/5a/775352677a7cb6154526b52f3ee3f48a5449898074865b1eea09e34c63a6/bitcrawler-0.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0e832058309f2e906b04c6c0e3a0fa86c6c48b95bc693f7a89043b86e2a8f41d",
          "md5": "fecc689ea28e29f7e247587d34d590c8",
          "sha256": "5a5fb4e301132544ed2b2a884c79a339caf870798ade06b9eaa57572a956e992"
        },
        "downloads": -1,
        "filename": "bitcrawler-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "fecc689ea28e29f7e247587d34d590c8",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 10955,
        "upload_time": "2021-02-21T05:43:46",
        "upload_time_iso_8601": "2021-02-21T05:43:46.242690Z",
        "url": "https://files.pythonhosted.org/packages/0e/83/2058309f2e906b04c6c0e3a0fa86c6c48b95bc693f7a89043b86e2a8f41d/bitcrawler-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "97e2072512ca18401de28886cffa9e690a16500818888e185b673057c978ab06",
          "md5": "af24f2676e079b5f581ce6d3e0e11f77",
          "sha256": "3eb62c127181c6d690a15b4a6a263c01131b50aeb4e32914f7cdda4ff8ee4551"
        },
        "downloads": -1,
        "filename": "bitcrawler-0.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "af24f2676e079b5f581ce6d3e0e11f77",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 17431,
        "upload_time": "2021-02-21T06:00:10",
        "upload_time_iso_8601": "2021-02-21T06:00:10Z",
        "url": "https://files.pythonhosted.org/packages/97/e2/072512ca18401de28886cffa9e690a16500818888e185b673057c978ab06/bitcrawler-0.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e0fc1a6a590f676b16dfd5c8dedfc9d088748cfcd64ee375515709c045e754ef",
          "md5": "ec32d92b0d5079346101c7d763597187",
          "sha256": "2830f5eaa82dbe92ee19f85bac017ae36e6cdd381f08ab00499e860676519c79"
        },
        "downloads": -1,
        "filename": "bitcrawler-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "ec32d92b0d5079346101c7d763597187",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 11023,
        "upload_time": "2021-02-21T06:00:11",
        "upload_time_iso_8601": "2021-02-21T06:00:11.263157Z",
        "url": "https://files.pythonhosted.org/packages/e0/fc/1a6a590f676b16dfd5c8dedfc9d088748cfcd64ee375515709c045e754ef/bitcrawler-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "49eaea5fc3b0f5ee026925c681d7090e4b49f06f33118d836797885adf67c8ab",
          "md5": "72c0c4846b5fb0223ed7d4064de9aa0c",
          "sha256": "124ba7c859057f9fbb3e891f6e148ffd1e1e2713ab2bbdc0e44ba9d05a916e68"
        },
        "downloads": -1,
        "filename": "bitcrawler-0.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "72c0c4846b5fb0223ed7d4064de9aa0c",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 17390,
        "upload_time": "2021-02-21T21:10:34",
        "upload_time_iso_8601": "2021-02-21T21:10:34.679354Z",
        "url": "https://files.pythonhosted.org/packages/49/ea/ea5fc3b0f5ee026925c681d7090e4b49f06f33118d836797885adf67c8ab/bitcrawler-0.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7caec9f66ce1bfc2747c8c03f9385284ae45169a790d9d60c9e8b810b088fc4b",
          "md5": "88c6b24de10d10ae97236f2e09c3b677",
          "sha256": "448750bb5b583a28b6afa07b13468a14308fe7ebe89111797d19274a41e296fe"
        },
        "downloads": -1,
        "filename": "bitcrawler-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "88c6b24de10d10ae97236f2e09c3b677",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 11062,
        "upload_time": "2021-02-21T21:10:36",
        "upload_time_iso_8601": "2021-02-21T21:10:36.166180Z",
        "url": "https://files.pythonhosted.org/packages/7c/ae/c9f66ce1bfc2747c8c03f9385284ae45169a790d9d60c9e8b810b088fc4b/bitcrawler-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9e1a83b82a3c5f215f01ab78cc0b301775f4ef24c3a0670b3005d8b17e518011",
          "md5": "b495ed877b96d05e0dd535539eebba06",
          "sha256": "78f8a2fb6df3631b9343d6f8243bb734ba301aec9b45008ded301b62b995a253"
        },
        "downloads": -1,
        "filename": "bitcrawler-0.0.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "b495ed877b96d05e0dd535539eebba06",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 18002,
        "upload_time": "2021-02-27T04:18:41",
        "upload_time_iso_8601": "2021-02-27T04:18:41.706933Z",
        "url": "https://files.pythonhosted.org/packages/9e/1a/83b82a3c5f215f01ab78cc0b301775f4ef24c3a0670b3005d8b17e518011/bitcrawler-0.0.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "db9a4fb108ac762e6921ccfcabc866083cac6a3d67f56bda7f0fb3d5f716fc50",
          "md5": "beea20e7a133eb84393aabe4b67470bd",
          "sha256": "d66666b3f1adc85cdf195b7f6de5c530e0e639b9ef5673a22588020e7f649444"
        },
        "downloads": -1,
        "filename": "bitcrawler-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "beea20e7a133eb84393aabe4b67470bd",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 12130,
        "upload_time": "2021-02-27T04:18:43",
        "upload_time_iso_8601": "2021-02-27T04:18:43.227058Z",
        "url": "https://files.pythonhosted.org/packages/db/9a/4fb108ac762e6921ccfcabc866083cac6a3d67f56bda7f0fb3d5f716fc50/bitcrawler-0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "603c879562428435a3a53c9131a53e139cc6ccc8e852eeae9869ef7df313e314",
          "md5": "a5fa31b03b597e51b7fb7c4e66774b95",
          "sha256": "d7cfb319ce8774e6d00fcb399a3db03a540e9e737ca50e7add0a88fcafc00ad7"
        },
        "downloads": -1,
        "filename": "bitcrawler-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "a5fa31b03b597e51b7fb7c4e66774b95",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 18327,
        "upload_time": "2021-03-09T20:57:29",
        "upload_time_iso_8601": "2021-03-09T20:57:29.071778Z",
        "url": "https://files.pythonhosted.org/packages/60/3c/879562428435a3a53c9131a53e139cc6ccc8e852eeae9869ef7df313e314/bitcrawler-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f84cafe26d55ff4946a0423db3c095338af0571ffdad5c3600708f78253d84a0",
          "md5": "ae124499ffbe294493de8b1f8b4965b5",
          "sha256": "facbce097a6b2789bd8365a876cc5d0ead83bdef56f85a82ea2ef0402650709c"
        },
        "downloads": -1,
        "filename": "bitcrawler-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "ae124499ffbe294493de8b1f8b4965b5",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 12634,
        "upload_time": "2021-03-09T20:57:30",
        "upload_time_iso_8601": "2021-03-09T20:57:30.553812Z",
        "url": "https://files.pythonhosted.org/packages/f8/4c/afe26d55ff4946a0423db3c095338af0571ffdad5c3600708f78253d84a0/bitcrawler-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "603c879562428435a3a53c9131a53e139cc6ccc8e852eeae9869ef7df313e314",
        "md5": "a5fa31b03b597e51b7fb7c4e66774b95",
        "sha256": "d7cfb319ce8774e6d00fcb399a3db03a540e9e737ca50e7add0a88fcafc00ad7"
      },
      "downloads": -1,
      "filename": "bitcrawler-0.1.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "a5fa31b03b597e51b7fb7c4e66774b95",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 18327,
      "upload_time": "2021-03-09T20:57:29",
      "upload_time_iso_8601": "2021-03-09T20:57:29.071778Z",
      "url": "https://files.pythonhosted.org/packages/60/3c/879562428435a3a53c9131a53e139cc6ccc8e852eeae9869ef7df313e314/bitcrawler-0.1.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "f84cafe26d55ff4946a0423db3c095338af0571ffdad5c3600708f78253d84a0",
        "md5": "ae124499ffbe294493de8b1f8b4965b5",
        "sha256": "facbce097a6b2789bd8365a876cc5d0ead83bdef56f85a82ea2ef0402650709c"
      },
      "downloads": -1,
      "filename": "bitcrawler-0.1.0.tar.gz",
      "has_sig": false,
      "md5_digest": "ae124499ffbe294493de8b1f8b4965b5",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 12634,
      "upload_time": "2021-03-09T20:57:30",
      "upload_time_iso_8601": "2021-03-09T20:57:30.553812Z",
      "url": "https://files.pythonhosted.org/packages/f8/4c/afe26d55ff4946a0423db3c095338af0571ffdad5c3600708f78253d84a0/bitcrawler-0.1.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}