{
  "info": {
    "author": "Adam Rudd",
    "author_email": "Adam@adamrudd.net",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 2 - Pre-Alpha",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Natural Language :: English",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8"
    ],
    "description": "\nSuper Json Normalize (with Array Ultra)\n=======================================================\n\n<p align=\"center\">\n\n<a href=\"https://pypi.python.org/pypi/super_json_normalize\" alt=\"Pip Logo\">\n        <img src=\"https://img.shields.io/pypi/v/super_json_normalize.svg\" /></a>\n\n<a href=\"https://travis-ci.com/AdamRuddGH/super_json_normalize\" alt=\"Github\">\n        <img src=\"https://img.shields.io/travis/AdamRuddGH/super_json_normalize.svg\" /></a>\n\n<a href=\"https://super-json-normalize.readthedocs.io/en/latest/?version=latest\" alt=\"Documentation Status\">\n        <img src=\"https://readthedocs.org/projects/super-json-normalize/badge/?version=latest\" /></a>\n\n<a href=\"https://pyup.io/repos/github/AdamRuddGH/super_json_normalize/\" alt=\"Updates\">\n        <img src=\"https://pyup.io/repos/github/AdamRuddGH/super_json_normalize/shield.svg\" /></a>\n\nA generic, unlimited level json normalizer which handles arrays at any location. Outputs a normalised set of data which can be imported into a relational table\n</p>\n\n\n\n## Why do I need this?\n\n- This outputs relational data from pretty much and analytics focuse json\n- It'll create new entities for data which should be split out into a new table\n- It'll link those entries by a set list of ID keys you specify\n- All your join keys are yours, so you won't get random breakages if you switch tools etc\n\nIf you're reporting within a relational Database, or have something in the pipeline which doesn't like structured data, this tool will do the heavy lifting to relationalise the json for you.\nThis will save you and your teams time doing the work of unnesting objects and pulling arrays into new tables so you can query them without the weird mappings that forced unnesting offers\n\n* Free software: MIT license\n* Documentation: https://super-json-normalize.readthedocs.io.\n\n## How do i use it for my project?\n\nThis works well as a transform step for your ETL (or even ELT)\n- Extract your data\n- Iterate through each entry\n- Run `super_json_normalize.normalize_record(<your_dict_here>)` on the entry\n- pipe the output arrays of entries to your needed location \n\n\nFeatures\n----------------------\n\n\nTODO:\n- initial dumb unnesting with `id` as the Primary key (DONE)\n- unnesting with configurable Primary Keys\n- multiple Primary keys for parent\n- multi-layerd primary keys (eg entities inside entities)\n\n\n# Design\n\nThis works by pulling out arrays into their own entities. \n\nfor the following example payload `properties` for a house (in directory /samples/property_data/):\n```json\n//for the file property_data.json\n{\n        \"id\": \"ID001\",\n        \"address\": {\n                \"street_address\": \"123 Fake street\",\n                \"suburb\": \"Fakeland\",\n                \"state\": \"VIC\",\n                \"country\": \"Australia\"\n        },\n        \"inspection_times\": [\n                {\"id\": \"IID001\", \"description\":\"First inspection date on Sunday\"},\n                {\"id\": \"IID002\", \"description\":\"Second inspection date on Tuesday\"},\n                {\"id\": \"IID003\", \"description\":\"Final inpection date on Friday\"}\n        ]  \n}\n```\nThe following will occur when we run `super_json_normalize.normalize_record()` on the loaded json data:\n- the `address` object will be unnested\n- a new entitiy called `inspection_times` will be created, and the `inspection_times` array will be removed from the root entity\n- the parent `id` from the root will be pulled into the `inspection_times` entity so we can join the data\n\nthis would end up with:\n```json\n\n\n[\n   {\n    \"name\": \"properties\",                // `properties` entity\n    \"data\": [\n      {\n        \"id\": \"ID001\",                   // primary key\n        \"address_street_address\": \"123 Fake street\",\n        \"address_suburb\": \"Fakeland\",\n        \"address_state\": \"VIC\",\n        \"address_country\": \"Australia\"\n      }\n    ]\n  },\n  {\n    \"name\": \"inspection_times\",          // `inspection_times` entity\n    \"data\": [\n      {\n        \"id\": \"IID001\",         \n        \"description\": \"First inspection date on Sunday\",\n        \"properties_id\": \"ID001\"         // parent key (foreign key) inherited from the root \n      },\n      {\n        \"id\": \"IID002\",\n        \"description\": \"Second inspection date on Tuesday\",\n        \"properties_id\": \"ID001\"         // parent key (foreign key) inherited from the root\n      },\n      {\n        \"id\": \"IID003\",\n        \"description\": \"Final inpection date on Friday\",\n        \"properties_id\": \"ID001\"         // parent key (foreign key) inherited from the root\n      }\n    ]\n  }\n]\n\n```\n\n\nThis is useful for preparing data for a relational db or systems requiring relational data.\n\n\n# usage\n\nExample to dump each entity to json from the sample above from /samples/\nThis one is the `property_data` example:\n\n```python\nimport super_json_normalize\nimport json\n\n#load the data from file\nmy_sample_data = super_json_normalize.load_json(\"./samples/property_data.json\")\n\n#now create the entities in a json file\nmy_output_data = super_json_normalize.normalize_record(my_sample_data, parent_name=\"properties\")\n\n#finally, export the entities in each individual file\nsuper_json_normalize.export_records(my_normalized_data, path=\"./export_data/\", format=\"jsonl\")\n\n###\n# creates files in ./export_data/ directory \n# properties.jsonl\n# inspection_times.jsonl\n\n### properties.jsonl\n# {\"id\": \"ID001\", \"address_street_address\": \"123 Fake street\", \"address_suburb\": \"Fakeland\", \"address_state\": \"VIC\", \"address_country\": \"Australia\"}\n\n### inspection_times.jsonl\n# {\"id\": \"IID001\", \"description\": \"First inspection date on Sunday\", \"properties_id\": \"ID001\"}\n# {\"id\": \"IID002\", \"description\": \"Second inspection date on Tuesday\", \"properties_id\": \"ID001\"}\n# {\"id\": \"IID003\", \"description\": \"Final inpection date on Friday\", \"properties_id\": \"ID001\"}\n\n```\n\n\nCredits\n-------\n\nThis package was created with Cookiecutter_ and the `audreyr/cookiecutter-pypackage`_ project template.\n\n.. _Cookiecutter: https://github.com/audreyr/cookiecutter\n.. _`audreyr/cookiecutter-pypackage`: https://github.com/audreyr/cookiecutter-pypackage\n\n\nHistory\n============\n\n0.1.0 (2021-10-03)\n---------------------------\n\n* First release on PyPI.\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/AdamRuddGH/super_json_normalize",
    "keywords": "super_json_normalize",
    "license": "MIT license",
    "maintainer": "",
    "maintainer_email": "",
    "name": "super-json-normalize",
    "package_url": "https://pypi.org/project/super-json-normalize/",
    "platform": "",
    "project_url": "https://pypi.org/project/super-json-normalize/",
    "project_urls": {
      "Homepage": "https://github.com/AdamRuddGH/super_json_normalize"
    },
    "release_url": "https://pypi.org/project/super-json-normalize/0.1.0/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "A generic, unlimited level json normalizer which unnests and relationalizes arrays at any location. Outputs a normalised set of data which can be imported into a relational table, and pulls in parent keys for joinability",
    "version": "0.1.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 11614921,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6211cbf596065f4f0bf5689781517792c91ac2e3e25610cf614135babd503af9",
          "md5": "28d397e497228a4f939340df7d612802",
          "sha256": "c533e84769dd3c777ca52800ec09e27e17d1a50c64cea1883a1d6a9a038c843f"
        },
        "downloads": -1,
        "filename": "super_json_normalize-0.1.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "28d397e497228a4f939340df7d612802",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": ">=3.6",
        "size": 8196,
        "upload_time": "2021-10-03T04:00:28",
        "upload_time_iso_8601": "2021-10-03T04:00:28.152908Z",
        "url": "https://files.pythonhosted.org/packages/62/11/cbf596065f4f0bf5689781517792c91ac2e3e25610cf614135babd503af9/super_json_normalize-0.1.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9f51b36811aca81ecbf08ab6c8f0b782977829a09f5f1a90e1b6f7e06ccc4d0b",
          "md5": "e3d59da62f0f1cab63f40a34254895c1",
          "sha256": "8aa9442bb2535e28d6b985cb61b85718325675dc04e44e6766eb9f758d9e1044"
        },
        "downloads": -1,
        "filename": "super_json_normalize-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "e3d59da62f0f1cab63f40a34254895c1",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 15558,
        "upload_time": "2021-10-03T04:00:29",
        "upload_time_iso_8601": "2021-10-03T04:00:29.742589Z",
        "url": "https://files.pythonhosted.org/packages/9f/51/b36811aca81ecbf08ab6c8f0b782977829a09f5f1a90e1b6f7e06ccc4d0b/super_json_normalize-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "6211cbf596065f4f0bf5689781517792c91ac2e3e25610cf614135babd503af9",
        "md5": "28d397e497228a4f939340df7d612802",
        "sha256": "c533e84769dd3c777ca52800ec09e27e17d1a50c64cea1883a1d6a9a038c843f"
      },
      "downloads": -1,
      "filename": "super_json_normalize-0.1.0-py2.py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "28d397e497228a4f939340df7d612802",
      "packagetype": "bdist_wheel",
      "python_version": "py2.py3",
      "requires_python": ">=3.6",
      "size": 8196,
      "upload_time": "2021-10-03T04:00:28",
      "upload_time_iso_8601": "2021-10-03T04:00:28.152908Z",
      "url": "https://files.pythonhosted.org/packages/62/11/cbf596065f4f0bf5689781517792c91ac2e3e25610cf614135babd503af9/super_json_normalize-0.1.0-py2.py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "9f51b36811aca81ecbf08ab6c8f0b782977829a09f5f1a90e1b6f7e06ccc4d0b",
        "md5": "e3d59da62f0f1cab63f40a34254895c1",
        "sha256": "8aa9442bb2535e28d6b985cb61b85718325675dc04e44e6766eb9f758d9e1044"
      },
      "downloads": -1,
      "filename": "super_json_normalize-0.1.0.tar.gz",
      "has_sig": false,
      "md5_digest": "e3d59da62f0f1cab63f40a34254895c1",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 15558,
      "upload_time": "2021-10-03T04:00:29",
      "upload_time_iso_8601": "2021-10-03T04:00:29.742589Z",
      "url": "https://files.pythonhosted.org/packages/9f/51/b36811aca81ecbf08ab6c8f0b782977829a09f5f1a90e1b6f7e06ccc4d0b/super_json_normalize-0.1.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}