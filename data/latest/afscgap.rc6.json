{
  "info": {
    "author": "",
    "author_email": "A Samuel Pottinger <sam.pottinger@berkeley.edu>",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Intended Audience :: Developers",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: BSD License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3",
      "Topic :: Scientific/Engineering",
      "Topic :: Software Development :: Libraries"
    ],
    "description": "# AFSC GAP for Python\nPython-based tool chain for working with the public bottom trawl surveys data from the [NOAA AFSC GAP](https://www.fisheries.noaa.gov/contact/groundfish-assessment-program).\n\n| Group | Badges |\n|-------|--------|\n| Status | ![build workflow status](https://github.com/SchmidtDSE/afscgap/actions/workflows/build.yml/badge.svg?branch=main) ![docs workflow status](https://github.com/SchmidtDSE/afscgap/actions/workflows/docs.yml/badge.svg?branch=main) [![Project Status: Active – The project has reached a stable, usable state and is being actively developed.](https://www.repostatus.org/badges/latest/active.svg)](https://www.repostatus.org/#active) |\n| Usage | [![Python 3.7+](https://img.shields.io/badge/python-3.7+-blue.svg)](https://www.python.org/downloads/release/python-370/) [![Pypi Badge](https://img.shields.io/pypi/v/afscgap)](https://pypi.org/project/afscgap/) [![License](https://img.shields.io/badge/License-BSD_3--Clause-blue.svg)](https://opensource.org/licenses/BSD-3-Clause) |\n| Publication | [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/SchmidtDSE/afscgap/main?urlpath=/tree/index.ipynb) |\n\nSee [webpage](https://pyafscgap.org), [project Github](https://github.com/SchmidtDSE/afscgap), and [example notebook](https://mybinder.org/v2/gh/SchmidtDSE/afscgap/main?urlpath=/tree/index.ipynb).\n\n<br>\n<br>\n\n## Quickstart\nYou don't need any local software to get started! To learn about the dataset, explore a visual analytics app at [https://app.pyafscgap.org](https://app.pyafscgap.org) (no code needed!). When ready, learn how to develop with these tools in a free [hosted notebook tutorial](https://mybinder.org/v2/gh/SchmidtDSE/afscgap/main?urlpath=/tree/index.ipynb).\n\n<br>\n<br>\n\n## Installation\nReady to take it to your own machine? Install the open source tools for accessing the AFSC GAP via Pypi / Pip:\n\n```\n$ pip install afscgap\n```\n\nThe library's only dependency is [requests](https://docs.python-requests.org/en/latest/index.html) and [Pandas / numpy are not expected but supported](#pandas).\n\n<br>\n<br>\n\n## Purpose\nUnofficial Python-based tool set for interacting with [bottom trawl surveys](https://www.fisheries.noaa.gov/alaska/commercial-fishing/alaska-groundfish-bottom-trawl-survey-data) from the [Ground Fish Assessment Program (GAP)](https://www.fisheries.noaa.gov/contact/groundfish-assessment-program). It offers:\n\n - Pythonic access to the official [NOAA AFSC GAP API service](https://www.fisheries.noaa.gov/foss/f?p=215%3A28).\n - Tools for inference of the \"negative\" observations not provided by the API service.\n - Visualization tools for quickly exploring and creating comparisons within the datset, including for audiences with limited programming experience.\n\nNote that GAP is an excellent dataset produced by the [Resource Assessment and Conservation Engineering (RACE) Division](https://www.fisheries.noaa.gov/about/resource-assessment-and-conservation-engineering-division) of the [Alaska Fisheries Science Center (AFSC)](https://www.fisheries.noaa.gov/about/alaska-fisheries-science-center) as part of the National Oceanic and Atmospheric Administration's Fisheries organization ([NOAA Fisheries](https://www.fisheries.noaa.gov/)).\n\n<br>\n\n#### Needs\nScientists and developers working on ocean health have an interest in survey data from organizations like [NOAA Fisheries](https://www.fisheries.noaa.gov/). However,\n\n - Using the GAP API from NOAA AFSC in Python can sometimes require a lot of work: understanding a complex schema, determining how to interact with a proprietary REST data service, forming long query URLs, and navigating pagination. \n - The official API service provides presence-only data, complicating some common types of analysis and aggregation.\n - Limited public tooling exists for visualizing within and, especially, creating comparisons between subsets of the AFSC GAP dataset which are useful for some types of investigation.\n\nThese various elements together may increase the barrier for working with these data, limiting their reach within some communities including the Python community.\n\n<br>\n\n#### Goals\nThis tool set aims to provide the following from the start to finish of an investigation:\n\n - **Visual analytics**: Visualization tools for quickly exploring AFSC GAP, helping users start their investigations by finding and comparing subsets of interest within the broader dataset.\n - **API access**: A type-annotated and documented Python interface to the official API service with ability to query with automated pagination, providing results in various formats compatible with different Python usage modalities (Pandas, pure-Python, etc). It adapts the HTTP-based API used by the agency with Python type hints for easy query and interface. \n - **Contextual documentation**: Python docstrings annotate the data structures provided by the API to help users navigate the various fields available, offering contextual documentation when supported by Python IDEs.\n - **Absence inference**: Tools to infer absence or \"zero catch\" data as required for certain analysis and aggregation using a [supplemental hauls flat file dataset](https://pyafscgap.org/community/hauls.csv). Note that this flat file is provided by and hosted for this library's community after being created from [non-API public AFSC GAP data](https://www.fisheries.noaa.gov/foss/f?p=215%3A28). It is updated yearly.\n - **Query generation**: This library converts more common Python standard types to types usable by the API service and emulated in Python when needed, reducing the need to interact directly with [ORDS syntax](https://www.oracle.com/database/technologies/appdev/rest.html).\n - **Accelerate specialized analysis**: Affordances in code and non-code tools for both programmers and non-programmers to continue their investigation easily, including in tools outside this tool set.\n - **Inclusive design**: Users of any skillset should be able to get something from this project.\n\nThough not intended to be general, this project also provides an example for working with [Oracle REST Data Services (ORDS)](https://www.oracle.com/database/technologies/appdev/rest.html) APIs in Python.\n\n<br>\n<br>\n\n## Usage\nThis library provides access to the AFSC GAP data with optional zero catch (\"absence\") record inference.\n\n<br>\n\n#### Visual analytics\nVisualization tools are available to help both programmers and non-programmers start their investigation, providing a UI that stands on the other functionality provided by this project. This is available online at [https://app.pyafscgap.org](https://app.pyafscgap.org). It can generate both CSV (spreadsheet) exports and Python query code to move investigations to their next steps. To self-host or run this tool locally, see the [visualization readme](https://github.com/SchmidtDSE/afscgap/blob/main/afscgapviz/README.md).\n\n<br>\n\n#### Basic queries\nThe `afscgap.query` method is the main entry point into Python-based utilization. Calls can be written manually or generated in the [visual analytics tool](https://app.pyafscgap.org). For example, this requests all records of Pasiphaea pacifica in 2021 from the Gulf of Alaska to get the median bottom temperature when they were observed:\n\n```\nimport statistics\n\nimport afscgap\n\nresults = afscgap.query(\n    year=2021,\n    srvy='GOA',\n    scientific_name='Pasiphaea pacifica'\n)\n\ntemperatures = [record.get_bottom_temperature_c() for record in results]\nprint(statistics.median(temperatures))\n```\n\nNote that `afscgap.query` returns a [Cursor](https://pyafscgap.org/devdocs/afscgap/cursor.html#Cursor). One can iterate over this `Cursor` to access [Record](https://pyafscgap.org/devdocs/afscgap/model.html#Record) objects. You can do this with list comprehensions, maps, etc or with a good old for loop like in this example which gets a histogram of haul temperatures:\n\n```\ncount_by_temperature_c = {}\n\nresults = afscgap.query(\n    year=2021,\n    srvy='GOA',\n    scientific_name='Pasiphaea pacifica'\n)\n\nfor record in results:\n    temp = record.get_bottom_temperature_c()\n    temp_rounded = round(temp)\n    count = count_by_temperature_c.get(temp_rounded, 0) + 1\n    count_by_temperature_c[temp_rounded] = count\n\nprint(count_by_temperature_c)\n```\n\nSee [data structure section](#data-structure). Using an iterator will have the library negotiate pagination behind the scenes so this operation will cause multiple HTTP requests while the iterator runs.\n\n<br>\n\n#### Enable absence data\nOne of the major limitations of the official API is that it only provides presence data. However, this library can optionally infer absence or \"zero catch\" records using a separate static file produced by NOAA AFSC GAP. The [algorithm and details for absence inference](#absence-vs-presence-data) is further discussed below.\n\nAbsence data / \"zero catch\" records inference can be turned on by setting `presence_only` to false in `query`. To demonstrate, this example finds total area swept and total weight for Gadus macrocephalus from the Aleutian Islands in 2021:\n\n```\nimport afscgap\n\nresults = afscgap.query(\n    year=2021,\n    srvy='GOA',\n    scientific_name='Gadus macrocephalus',\n    presence_only=False\n)\n\ntotal_area = 0\ntotal_weight = 0\n\nfor record in results:\n    total_area += record.get_area_swept_ha()\n    total_weight += record.get_weight()\n\ntemplate = '%.2f kg / hectare swept (%.1f kg, %.1f hectares'\nweight_per_area = total_weight / total_area\nmessage = template % (weight_per_area, total_weight, total_area)\n\nprint(message)\n```\n\nFor more [details on the zero catch record feature](#absence-vs-presence-data), please see below.\n\n<br>\n\n#### Serialization\nUsers may request a dictionary representation:\n\n```\nresults = afscgap.query(\n    year=2021,\n    srvy='GOA',\n    scientific_name='Pasiphaea pacifica'\n)\n\n# Get dictionary from individual record\nfor record in results:\n    dict_representation = record.to_dict()\n    print(dict_representation['bottom_temperature_c'])\n\nresults = afscgap.query(\n    year=2021,\n    srvy='GOA',\n    scientific_name='Pasiphaea pacifica'\n)\n\n# Get dictionary for all records\nresults_dicts = results.to_dicts()\n\nfor record in results_dicts:\n    print(record['bottom_temperature_c'])\n```\n\nNote `to_dicts` returns an iterator by default, but it can be realized as a full list using the `list()` command.\n\n<br>\n\n#### Pandas\nThe dictionary form of the data can be used to create a Pandas dataframe:\n\n```\nimport pandas\n\nimport afscgap\n\nresults = afscgap.query(\n    year=2021,\n    srvy='GOA',\n    scientific_name='Pasiphaea pacifica'\n)\n\npandas.DataFrame(results.to_dicts())\n```\n\nNote that Pandas is not required to use this library.\n\n<br>\n\n#### Advanced filtering\nYou can provide range queries which translate to ORDS or Python emulated filters. For example, the following requests before and including 2019:\n\n```\nresults = afscgap.query(\n    year=(None, 2019),\n    srvy='GOA',\n    scientific_name='Pasiphaea pacifica'\n)\n```\n\nThe following requests data after and including 2019:\n\n```\nresults = afscgap.query(\n    year=(2019, None),\n    srvy='GOA',\n    scientific_name='Pasiphaea pacifica'\n)\n```\n\nFinally, the following requests data between 2015 and 2019 (includes 2015 and 2019):\n\n```\nresults = afscgap.query(\n    year=(2015, 2019),\n    srvy='GOA',\n    scientific_name='Pasiphaea pacifica'\n)\n```\n\nFor more advanced filters, please see manual filtering below.\n\n<br>\n\n#### Manual filtering\nUsers may provide advanced queries using Oracle's REST API query parameters. For example, this queries for 2021 records with haul from the Gulf of Alaska in a specific geographic area:\n\n```\nimport afscgap\n\nresults = afscgap.query(\n    year=2021,\n    latitude_dd={'$between': [56, 57]},\n    longitude_dd={'$between': [-161, -160]}\n)\n\ncount_by_common_name = {}\n\nfor record in results:\n    common_name = record.get_common_name()\n    new_count = record.get_count()\n    count = count_by_common_name.get(common_name, 0) + new_count\n    count_by_common_name[common_name] = count\n```\n\nFor more info about the options available, consider the [Oracle docs](https://docs.oracle.com/en/database/oracle/oracle-rest-data-services/19.2/aelig/developing-REST-applications.html#GUID-F0A4D4F9-443B-4EB9-A1D3-1CDE0A8BAFF2) or a helpful unaffiliated [getting started tutorial from Jeff Smith](https://www.thatjeffsmith.com/archive/2019/09/some-query-filtering-examples-in-ords/).\n\n<br>\n\n#### Manual pagination\nBy default, the library will iterate through all results and handle pagination behind the scenes. However, one can also request an individual page:\n\n```\nresults = afscgap.query(\n    year=2021,\n    srvy='GOA',\n    scientific_name='Pasiphaea pacifica'\n)\n\nresults_for_page = results.get_page(offset=20, limit=100)\nprint(len(results_for_page))  # Will print 32 (results contains 52 records)\n```\n\nClient code can also change the pagination behavior used when iterating:\n\n```\nresults = afscgap.query(\n    year=2021,\n    srvy='GOA',\n    scientific_name='Pasiphaea pacifica',\n    start_offset=10,\n    limit=200\n)\n\nfor record in results:\n    print(record.get_bottom_temperature_c())\n```\n\nNote that records are only requested once during iteration and only after the prior page has been returned via the iterator (\"lazy\" loading).\n\n<br>\n<br>\n\n## Data structure\nThe schema drives the getters and filters available on in the library. Note that data structures are defined in the [model submodule](https://pyafscgap.org/devdocs/afscgap/model.html) but client code generally only needs to interact with [Record](https://pyafscgap.org/devdocs/afscgap/model.html#Record) objects.\n\n<br>\n\n#### Schema\n\nA Python-typed description of the fields is provided below.\n\n| **Field**             | **Python Type** | **Description** |\n|-----------------------|-----------------|-----------------|\n| year                  | float           | Year for the survey in which this observation was made. |\n| srvy                  | str             | The name of the survey in which this observation was made. NBS (N Bearing Sea), EBS (SE Bearing Sea), BSS (Bearing Sea Slope), or GOA (Gulf of Alaska) |\n| survey                | str             | Long form description of the survey in which the observation was made. |\n| survey_id             | float           | Unique numeric ID for the survey. |\n| cruise                | float           | An ID uniquely identifying the cruise in which the observation was made. Multiple cruises in a survey. |\n| haul                  | float           | An ID uniquely identifying the haul in which this observation was made. Multiple hauls per cruise. |\n| stratum               | float           | Unique ID for statistical area / survey combination as described in the metadata or 0 if an experimental tow. |\n| station               | str             | Station associated with the survey. |\n| vessel_name           | str             | Unique ID describing the vessel that made this observation. This is left as a string but, in practice, is likely numeric. |\n| vessel_id             | float           | Name of the vessel at the time the observation was made with multiple names potentially associated with a vessel ID. |\n| date_time             | str             | The date and time of the haul which has been attempted to be transformed to an ISO 8601 string without timezone info. If it couldn’t be transformed, the original string is reported. |\n| latitude_dd           | float           | Latitude in decimal degrees associated with the haul. |\n| longitude_dd          | float           | Longitude in decimal degrees associated with the haul. |\n| species_code          | float           | Unique ID associated with the species observed. |\n| common_name           | str             | The “common name” associated with the species observed. Example: Pacific glass shrimp  |\n| scientific_name       | str             | The “scientific name” associated with the species observed. Example: Pasiphaea pacifica  |\n| taxon_confidence      | str             | Confidence flag regarding ability to identify species (High, Moderate, Low). In practice, this can also be Unassessed. |\n| cpue_kgha             | Optional[float] | Catch weight divided by net area (kg / hectares) if available. See metadata. None if could not interpret as a float. |\n| cpue_kgkm2            | Optional[float] | Catch weight divided by net area (kg / km^2) if available. See metadata. None if could not interpret as a float. |\n| cpue_kg1000km2        | Optional[float] | Catch weight divided by net area (kg / km^2 * 1000) if available. See metadata. None if could not interpret as a float. |\n| cpue_noha             | Optional[float] | Catch number divided by net sweep area if available (count / hectares). See metadata. None if could not interpret as a float. |\n| cpue_nokm2            | Optional[float] | Catch number divided by net sweep area if available (count / km^2). See metadata. None if could not interpret as a float. |\n| cpue_no1000km2        | Optional[float] | Catch number divided by net sweep area if available (count / km^2 * 1000). See metadata. None if could not interpret as a float. |\n| weight_kg             | Optional[float] | Taxon weight (kg) if available. See metadata. None if could not interpret as a float. |\n| count                 | Optional[float] | Total number of organism individuals in haul. None if could not interpret as a float. |\n| bottom_temperature_c  | Optional[float] | Bottom temperature associated with observation if available in Celsius. None if not given or could not interpret as a float. |\n| surface_temperature_c | Optional[float] | Surface temperature associated with observation if available in Celsius. None if not given or could not interpret as a float. |\n| depth_m               | float           | Depth of the bottom in meters. |\n| distance_fished_km    | float           | Distance of the net fished as km. |\n| net_width_m           | float           | Distance of the net fished as m. |\n| net_height_m          | float           | Height of the net fished as m. |\n| area_swept_ha         | float           | Area covered by the net while fishing in hectares. |\n| duration_hr           | float           | Duration of the haul as number of hours. |\n| tsn                   | Optional[int]   | Taxonomic information system species code. |\n| ak_survey_id          | int             | AK identifier for the survey. |\n\nFor more information on the schema, see the [metadata](https://github.com/afsc-gap-products/metadata) repository but note that the fields may be slightly different in the Python library per what is actually returned by the API.\n\n<br>\n\n#### Filters and getters\n\nThese fields are available as getters on `afscgap.model.Record` (`result.get_srvy()`) and may be used as optional filters on the query `asfcgagp.query(srvy='GOA')`. Fields which are `Optional` have two getters. First, the \"regular\" getter (`result.get_count()`) will assert that the field is not None before returning a non-optional. The second \"maybe\" getter (`result.get_count_maybe()`) will return None if the value was not provided or could not be parsed.\n\n| **Filter keyword**    | **Regular Getter**                   | **Maybe Getter**                                     |\n|-----------------------|--------------------------------------|------------------------------------------------------|\n| year                  | get_year() -> float                  |                                                      |\n| srvy                  | get_srvy() -> str                    |                                                      |\n| survey                | get_survey() -> str                  |                                                      |\n| survey_id             | get_survey_id() -> float             |                                                      |\n| cruise                | get_cruise() -> float                |                                                      |\n| haul                  | get_haul() -> float                  |                                                      |\n| stratum               | get_stratum() -> float               |                                                      |\n| station               | get_station() -> str                 |                                                      |\n| vessel_name           | get_vessel_name() -> str             |                                                      |\n| vessel_id             | get_vessel_id() -> float             |                                                      |\n| date_time             | get_date_time() -> str               |                                                      |\n| latitude_dd           | get_latitude_dd() -> float           |                                                      |\n| longitude_dd          | get_longitude_dd() -> float          |                                                      |\n| species_code          | get_species_code() -> float          |                                                      |\n| common_name           | get_common_name() -> str             |                                                      |\n| scientific_name       | get_scientific_name() -> str         |                                                      |\n| taxon_confidence      | get_taxon_confidence() -> str        |                                                      |\n| cpue_kgha             | get_cpue_kgha() -> float             | get_cpue_kgha_maybe() -> Optional[float]             |\n| cpue_kgkm2            | get_cpue_kgkm2() -> float            | get_cpue_kgkm2_maybe() -> Optional[float]            |\n| cpue_kg1000km2        | get_cpue_kg1000km2() -> float        | get_cpue_kg1000km2_maybe() -> Optional[float]        |\n| cpue_noha             | get_cpue_noha() -> float             | get_cpue_noha_maybe() -> Optional[float]             |\n| cpue_nokm2            | get_cpue_nokm2() -> float            | get_cpue_nokm2_maybe() -> Optional[float]            |\n| cpue_no1000km2        | get_cpue_no1000km2() -> float        | get_cpue_no1000km2_maybe() -> Optional[float]        |\n| weight_kg             | get_weight_kg() -> float             | get_weight_kg_maybe() -> Optional[float]             |\n| count                 | get_count() -> float                 | get_count_maybe() -> Optional[float]                 |\n| bottom_temperature_c  | get_bottom_temperature_c() -> float  | get_bottom_temperature_c_maybe() -> Optional[float]  |\n| surface_temperature_c | get_surface_temperature_c() -> float | get_surface_temperature_c_maybe() -> Optional[float] |\n| depth_m               | get_depth_m() -> float               |                                                      |\n| distance_fished_km    | get_distance_fished_km() -> float    |                                                      |\n| net_width_m           | get_net_width_m() -> float           | get_net_width_m_maybe() -> Optional[float]           |\n| net_height_m          | get_net_height_m() -> float          | get_net_height_m_maybe() -> Optional[float]          |\n| area_swept_ha         | get_area_swept_ha() -> float         |                                                      |\n| duration_hr           | get_duration_hr() -> float           |                                                      |\n| tsn                   | get_tsn() -> int                     | get_tsn_maybe() -> Optional[int]                     |\n| ak_survey_id          | get_ak_survey_id() -> int            |                                                      |\n\n`Record` objects also have a `is_complete` method which returns true if all the fields with an `Optional` type are non-None and the `date_time` could be parsed and made into an ISO 8601 string.\n\n<br>\n<br>\n\n## Absence vs presence data\nThe API itself provides access to presence only data. This means that records are only given for when a species was found. This can cause issues if trying to aggregate data like, for example, to determine the weight of the species in a region in terms of catch weight per hectare. The AFSC GAP API on its own would not necessarily provide the total nubmer of hecatres surveyed in that region because hauls without the species present would be excluded. That in mind, this library provides a method for inferring absence data.\n\n<br>\n\n#### Example of absence data in aggregation\nHere is a practical memory efficient example using [geolib](https://pypi.org/project/geolib/) and [toolz](https://github.com/pytoolz/toolz) to aggregate catch data by 5 character geohash.\n\n```\nimport afscgap\nimport geolib.geohash\nimport toolz.itertoolz\n\nimport afscgap\n\nresults = afscgap.query(\n    year=2021,\n    srvy='GOA',\n    scientific_name='Gadus macrocephalus',\n    presence_only=False\n)\n\ndef simplify_record(full_record):\n    latitude = full_record.get_latitude_dd()\n    longitude = full_record.get_longitude_dd()\n    geohash = geolib.geohash.encode(latitude, longitude, 5)\n    \n    return {\n        'geohash': geohash,\n        'area': full_record.get_area_swept_ha(),\n        'weight': full_record.get_weight_kg()\n    }\n\ndef combine_record(a, b):\n    assert a['geohash'] == b['geohash']\n    return {\n        'geohash': a['geohash'],\n        'area': a['area'] + b['area'],\n        'weight': a['weight'] + b['weight']\n    }\n\nsimplified_records = map(simplify_record, results)\ntotals_by_geohash = toolz.reduceby(\n    'geohash',\n    combine_record,\n    simplified_records\n)\nweight_by_area_tuples = map(\n    lambda x: (x['geohash'], x['weight'] / x['area']),\n    totals_by_geohash.values()\n)\nweight_by_area_by_geohash = dict(weight_by_area_tuples)\n```\n\nFor more details see the [Python functional programming guide](https://docs.python.org/3/howto/functional.html). All that said, for some queries, the use of Pandas may lead to very heavy memory usage.\n\n<br>\n\n#### Absence inference algorithm\nThough it is not possible to resolve this issue using the AFSC GAP API service alone, this library can infer those missing records using a separate static flat file provided by NOAA and the following algorithm:\n\n\n - Record the set of species observed from API service returned results.\n - Record the set of hauls observed from API service returned results.\n - Return records normally while records remain available from the API service.\n - Upon exhaustion of the API service results, [download the ~10M hauls flat file](https://pyafscgap.org/community/hauls.csv) from this library's community.\n - For each species observed in the API returned results, check if that species had a record for each haul reported in the flat file.\n - For any hauls without the species record, yield an 0 catch record from the iterator for that query.\n\nThis procedure is disabled by default. However, it can be enabled through the `presence_only` keyword in `query` like so: `asfcgap.query(presence_only=False)`.\n\n<br>\n\n#### Memory efficiency of absence inference\nNote that `presence_only=False` will return a lot of records. Indeed, in some queries, this may stretch to many millions. As described in [community guidelines](#community), a goal of this project is provide those data in a memory-efficient way and, specifically, these \"zero catch\" records are generated by the library's iterator as requested but never all held in memory at the same time. It is recommened that client code also take care in memory efficiency. This can be as simple as aggregating via `for` loops which only hold one record in memory at a time. Similarly, consider using `map`, `filter`, `reduce`, [itertools](https://docs.python.org/3/library/itertools.html), etc.\n\n<br>\n\n#### Manual pagination of zero catch records\nThe goal of `Cursor.get_page` is to pull results from a page returned for a query as it appears in the NOAA API service. Note that `get_page` will not return zero catch records even with `presence_only=False` because the \"page\" requested does not technically exist in the API service. In order to use the negative records inference feature, please use the iterator option instead.\n\n<br>\n\n#### Filtering absence data\nNote that the library will emulate filtering in Python so that haul records are filtered just as presence records are filtered by the API service. This works for \"basic\" and \"advanced\" filtering. However, at time of writing, \"manual filtering\" as described below using ORDS syntax is not supported when `presence_data=False`. Also, by default, a warning will be emitted when using this feature to help new users be aware of potential memory issues. This can be suppressed by including `suppress_large_warning=True` in the call to query.\n\n<br>\n\n#### Cached hauls\nIf desired, a cached set of hauls data can be used instead. It must be a list of [Haul objects](https://pyafscgap.org/devdocs/afscgap/model.html#Haul) and can be passed like so:\n\n```\nimport csv\n\nimport afscgap\nimport afscgap.inference\n\nwith open('hauls.csv') as f:\n    rows = csv.DictReader(f)\n    hauls = [afscgap.inference.parse_haul(row) for row in rows]\n\nresults = afscgap.query(\n    year=2021,\n    srvy='GOA',\n    scientific_name='Gadus macrocephalus',\n    presence_only=False,\n    hauls_prefetch=hauls\n)\n```\n\nThis can be helpful when executing a lot of queries and the bandwidth to download the [hauls metadata file](https://pyafscgap.org/community/hauls.csv) multiple times may not be desireable. \n\n<br>\n<br>\n\n## Data quality and completeness\nThere are a few caveats for working with these data that are important for researchers to understand.\n\n<br>\n\n#### Incomplete or invalid records\nMetadata fields such as `year` are always required to make a `Record` whereas others such as catch weight `cpue_kgkm2` are not present on all records returned by the API and are optional. See the [data structure section](#data-structure) for additional details. For fields with optional values:\n\n - A maybe getter (like `get_cpue_kgkm2_maybe`) is provided which will return None without error if the value is not provided or could not be parsed.\n - A regular getter (like `get_cpue_kgkm2`) is provided which asserts the value is not None before it is returned.\n\n`Record` objects also have an `is_complete` method which returns true if both all optional fields on the `Record` are non-None and the `date_time` field on the `Record` is a valid ISO 8601 string. By default, records for which `is_complete` are false are returned when iterating or through `get_page` but this can be overridden by with the `filter_incomplete` keyword argument like so:\n\n```\nresults = afscgap.query(\n    year=2021,\n    srvy='GOA',\n    scientific_name='Pasiphaea pacifica',\n    filter_incomplete=True\n)\n\nfor result in results:\n    assert result.is_complete()\n```\n\nResults returned by the API for which non-Optional fields could not be parsed (like missing `year`) are considered \"invalid\" and always excluded during iteration when those raw unreadable records are kept in a `queue.Queue[dict]` that can be accessed via `get_invalid` like so:\n\n```\nresults = afscgap.query(year=2021, srvy='GOA')\nvalid = list(results)\n\ninvalid_queue = results.get_invalid()\npercent_invalid = invalid_queue.qsize() / len(valid) * 100\nprint('Percent invalid: %%%.2f' % percent_invalid)\n\ncomplete = filter(lambda x: x.is_complete(), valid)\nnum_complete = sum(map(lambda x: 1, complete))\npercent_complete = num_complete / len(valid) * 100\nprint('Percent complete: %%%.2f' % percent_complete)\n```\n\nNote that this queue is filled during iteration (like `for result in results` or `list(results)`) and not `get_page` whose invalid record handling behavior can be specified via the `ignore_invalid` keyword.\n\n<br>\n\n#### Longitude\nThough not officially mentioned by the NOAA API, the authors of this library observe some positive longitudes in returned data where negative longitudes of the same magnitude would be expected. Users of the library should be careful to determine how to handle these records (inferring they should have been the same magnitude of longitude but negative or excluded). Publications should be careful to document their decision.\n\n<br>\n<br>\n\n## License\nWe are happy to make this library available under the BSD 3-Clause license. See LICENSE for more details. (c) 2023 Regents of University of California. See the [Eric and Wendy Schmidt Center for Data Science and the Environment\nat UC Berkeley](https://dse.berkeley.edu).\n\n<br>\n<br>\n\n## Community\nThanks for your support! Pull requests and issues very welcome.\n\n<br>\n\n#### Contribution guidelines\nWe invite contributions via [our project Github](https://github.com/SchmidtDSE/afscgap). Please read the [CONTRIBUTING.md](https://github.com/SchmidtDSE/afscgap/blob/main/CONTRIBUTING.md) file for more information.\n\n<br>\n\n#### Debugging\nWhile participating in the community, you may need to debug URL generation. Therefore, for investigating issues or evaluating the underlying operations, you can also request a full URL for a query:\n\n```\nresults = afscgap.query(\n    year=2021,\n    latitude_dd={'$between': [56, 57]},\n    longitude_dd={'$between': [-161, -160]}\n)\n\nprint(results.get_page_url(limit=10, offset=0))\n```\n\nThe query can be executed by making an HTTP GET request at the provided location.\n\n<br>\n\n#### People\n[Sam Pottinger](https://github.com/sampottinger) is the primary contact with additional development from [Giulia Zarpellon](https://github.com/gizarp). Additionally some acknowledgements:\n\n - Thank you to [Carl Boettiger](https://github.com/cboettig) and [Fernando Perez](https://github.com/fperez) for advice in the Python library.\n - Thanks also to [Maya Weltman-Fahs](https://dse.berkeley.edu/people/maya-weltman-fahs), [Brookie Guzder-Williams](https://github.com/brookisme), and [Magali de Bruyn](https://github.com/magalidebruyn) for advice on the visual analytics tool.\n\nThis is a project of the [The Eric and Wendy Schmidt Center for Data Science and the Environment\nat UC Berkeley](https://dse.berkeley.edu) where [Kevin Koy](https://github.com/kevkoy) is Executive Director. Please contact us via dse@berkeley.edu.\n\n<br>\n<br>\n\n## Open Source\nWe are happy to be part of the open source community.\n\nAt this time, the only open source dependency used by this microlibrary is [Requests](https://docs.python-requests.org/en/latest/index.html) which is available under the [Apache v2 License](https://github.com/psf/requests/blob/main/LICENSE) from [Kenneth Reitz and other contributors](https://github.com/psf/requests/graphs/contributors).\n\nIn addition to Github-provided [Github Actions](https://docs.github.com/en/actions), our build and documentation systems also use the following but are not distributed with or linked to the project itself:\n\n - [mypy](https://github.com/python/mypy) under the [MIT License](https://github.com/python/mypy/blob/master/LICENSE) from Jukka Lehtosalo, Dropbox, and other contributors.\n - [nose2](https://docs.nose2.io/en/latest/index.html) under a [BSD license](https://github.com/nose-devs/nose2/blob/main/license.txt) from Jason Pellerin and other contributors.\n - [pdoc](https://github.com/mitmproxy/pdoc) under the [Unlicense license](https://github.com/mitmproxy/pdoc/blob/main/LICENSE) from [Andrew Gallant](https://github.com/BurntSushi) and [Maximilian Hils](https://github.com/mhils).\n - [pycodestyle](https://pycodestyle.pycqa.org/en/latest/) under the [Expat License](https://github.com/PyCQA/pycodestyle/blob/main/LICENSE) from Johann C. Rocholl, Florent Xicluna, and Ian Lee.\n - [pyflakes](https://github.com/PyCQA/pyflakes) under the [MIT License](https://github.com/PyCQA/pyflakes/blob/main/LICENSE) from Divmod, Florent Xicluna, and other contributors.\n - [sftp-action](https://github.com/Creepios/sftp-action) under the [MIT License](https://github.com/Creepios/sftp-action/blob/master/LICENSE) from Niklas Creepios.\n - [ssh-action](https://github.com/appleboy/ssh-action) under the [MIT License](https://github.com/appleboy/ssh-action/blob/master/LICENSE) from Bo-Yi Wu.\n\nNext, the visualization tool has additional dependencies as documented in the [visualization readme](https://github.com/SchmidtDSE/afscgap/blob/main/afscgapviz/README.md).\n\nFinally, note that the website uses assets from [The Noun Project](thenounproject.com/) under the NounPro plan. If used outside of https://pyafscgap.org, they may be subject to a [different license](https://thenounproject.com/pricing/#icons).\n\nThank you to all of these projects for their contribution.\n\n<br>\n<br>\n\n## Version history\nAnnotated version history:\n\n - `0.0.7`: Visual analytics tools.\n - `0.0.6`: Performance and size improvements.\n - `0.0.5`: Changes to documentation.\n - `0.0.4`: Negative / zero catch inference.\n - `0.0.3`: Minor updates in documentation.\n - `0.0.2`: License under BSD.\n - `0.0.1`: Initial release.\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "afscgap",
    "package_url": "https://pypi.org/project/afscgap/",
    "platform": null,
    "project_url": "https://pypi.org/project/afscgap/",
    "project_urls": {
      "Changelog": "https://github.com/SchmidtDSE/afscgap#version-history",
      "Documentation": "https://pyafscgap.org/devdocs/afscgap.html",
      "Homepage": "https://pyafscgap.org",
      "Issue Tracker": "https://github.com/SchmidtDSE/afscgap/issues",
      "Source": "https://github.com/SchmidtDSE/afscgap"
    },
    "release_url": "https://pypi.org/project/afscgap/0.0.7/",
    "requires_dist": [
      "requests~=2.28.2",
      "build; extra == 'dev'",
      "mypy; extra == 'dev'",
      "nose2; extra == 'dev'",
      "pdoc; extra == 'dev'",
      "pycodestyle; extra == 'dev'",
      "pyflakes; extra == 'dev'",
      "twine; extra == 'dev'",
      "types-requests; extra == 'dev'"
    ],
    "requires_python": ">=3.7",
    "summary": "Tools for interacting with the public bottom trawl surveys data from the NOAA AFSC GAP.",
    "version": "0.0.7",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17339182,
  "releases": {
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "294be718dd745879a9e51a9b557a933689b96af82212da4aea2a25980f4b5272",
          "md5": "5c3975b6c66b5f23aff2c70e99901085",
          "sha256": "aee26e4914b2830a5d4689d623b22354a1c175e0beceb9865613e4d512aacd2a"
        },
        "downloads": -1,
        "filename": "afscgap-0.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "5c3975b6c66b5f23aff2c70e99901085",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 30245,
        "upload_time": "2023-02-24T00:00:35",
        "upload_time_iso_8601": "2023-02-24T00:00:35.278461Z",
        "url": "https://files.pythonhosted.org/packages/29/4b/e718dd745879a9e51a9b557a933689b96af82212da4aea2a25980f4b5272/afscgap-0.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "215679c384d61b8fdfc7586490a4e2f77bc0525ef9c06a94d41c1b3f148041b6",
          "md5": "d704d2a0a9a29cd3d07a5860bb69fecc",
          "sha256": "f42740d155e5abe17555d82145f19935f579ed17e6d1f4e80ab574ec60efa22a"
        },
        "downloads": -1,
        "filename": "afscgap-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "d704d2a0a9a29cd3d07a5860bb69fecc",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 25321,
        "upload_time": "2023-02-24T00:00:37",
        "upload_time_iso_8601": "2023-02-24T00:00:37.111029Z",
        "url": "https://files.pythonhosted.org/packages/21/56/79c384d61b8fdfc7586490a4e2f77bc0525ef9c06a94d41c1b3f148041b6/afscgap-0.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "0a5cbffb79d5ebd7986aa590ad3fe3e3b2429c3f515c8ac61b8d221aaaa11d71",
          "md5": "21551ce14062ab7dd670d9626032ec6e",
          "sha256": "04c3089302570ffae7a0e14be424b95c02b6fa8762d23e5b770adeee7b2c1952"
        },
        "downloads": -1,
        "filename": "afscgap-0.0.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "21551ce14062ab7dd670d9626032ec6e",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 30308,
        "upload_time": "2023-02-24T00:08:21",
        "upload_time_iso_8601": "2023-02-24T00:08:21.074228Z",
        "url": "https://files.pythonhosted.org/packages/0a/5c/bffb79d5ebd7986aa590ad3fe3e3b2429c3f515c8ac61b8d221aaaa11d71/afscgap-0.0.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "51d570252b40b62246688a0513803b5b4034a096e1cdc0d642fb13abcb1b180f",
          "md5": "a6e0a410f05c799ec39edcd6bd8a0008",
          "sha256": "28a186cb37f108f0f203c8c061629957071ff5e68e182002d124a0ae3d806030"
        },
        "downloads": -1,
        "filename": "afscgap-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "a6e0a410f05c799ec39edcd6bd8a0008",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 25377,
        "upload_time": "2023-02-24T00:08:22",
        "upload_time_iso_8601": "2023-02-24T00:08:22.421084Z",
        "url": "https://files.pythonhosted.org/packages/51/d5/70252b40b62246688a0513803b5b4034a096e1cdc0d642fb13abcb1b180f/afscgap-0.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "df3345f61bb46a2e4e3e9e5f26a79fed01d12b5fe9aeb39b027d4afc54b9944a",
          "md5": "458b6a8047218ab05554d8ed2f812b4b",
          "sha256": "b52961ebfce6ee22203de73750bd745c3c6eeea1e1304e1d414eb90060d5539a"
        },
        "downloads": -1,
        "filename": "afscgap-0.0.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "458b6a8047218ab05554d8ed2f812b4b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 39850,
        "upload_time": "2023-03-04T18:07:56",
        "upload_time_iso_8601": "2023-03-04T18:07:56.391540Z",
        "url": "https://files.pythonhosted.org/packages/df/33/45f61bb46a2e4e3e9e5f26a79fed01d12b5fe9aeb39b027d4afc54b9944a/afscgap-0.0.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f4c2fd52e0bebf451b6a5b8919d9436da71dac9ff130a972cd72c860ef1274c8",
          "md5": "946cc49d904f2259cd06cd531dbdf268",
          "sha256": "01c32b1ea8a497db0c7c3c7e82ceafdf5f99c3a277b56fdac3041613edea2507"
        },
        "downloads": -1,
        "filename": "afscgap-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "946cc49d904f2259cd06cd531dbdf268",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 428203,
        "upload_time": "2023-03-04T18:07:57",
        "upload_time_iso_8601": "2023-03-04T18:07:57.718431Z",
        "url": "https://files.pythonhosted.org/packages/f4/c2/fd52e0bebf451b6a5b8919d9436da71dac9ff130a972cd72c860ef1274c8/afscgap-0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b5dc34866c70d1272a19e687d4f47e8cad3d8988b2ec7b4fb6e9b23ca8d88217",
          "md5": "ab0cf2b5eeb18a78aa7d05c22fdec16a",
          "sha256": "272855ea4757899808bd4f53cc3ca620e4f77bfcbad659f2a08e53c9707b9d8d"
        },
        "downloads": -1,
        "filename": "afscgap-0.0.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ab0cf2b5eeb18a78aa7d05c22fdec16a",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 40003,
        "upload_time": "2023-03-05T18:59:45",
        "upload_time_iso_8601": "2023-03-05T18:59:45.210041Z",
        "url": "https://files.pythonhosted.org/packages/b5/dc/34866c70d1272a19e687d4f47e8cad3d8988b2ec7b4fb6e9b23ca8d88217/afscgap-0.0.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4b3e496996a16c90d0288fe8824ea22ea10f597f6c09a6d8c9b8fa146ee980a3",
          "md5": "3fcc7592e25aa9f848c5861c05236332",
          "sha256": "c99720fc991072108e73099c9054bcce780b0c6747408b0df9cb0f596add6b33"
        },
        "downloads": -1,
        "filename": "afscgap-0.0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "3fcc7592e25aa9f848c5861c05236332",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 428989,
        "upload_time": "2023-03-05T18:59:47",
        "upload_time_iso_8601": "2023-03-05T18:59:47.005179Z",
        "url": "https://files.pythonhosted.org/packages/4b/3e/496996a16c90d0288fe8824ea22ea10f597f6c09a6d8c9b8fa146ee980a3/afscgap-0.0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "013eca0d7738f19998e1cf28db69d5f0a41df97e33e37d1eba97f454f450e359",
          "md5": "062a034f78ba4fb95760f7f5a4a84efb",
          "sha256": "4128d956aa6c3ff9eaed451672e638af3aa6b892a726d3f8792f6d867d0636b9"
        },
        "downloads": -1,
        "filename": "afscgap-0.0.6-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "062a034f78ba4fb95760f7f5a4a84efb",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 40528,
        "upload_time": "2023-03-06T16:08:09",
        "upload_time_iso_8601": "2023-03-06T16:08:09.182682Z",
        "url": "https://files.pythonhosted.org/packages/01/3e/ca0d7738f19998e1cf28db69d5f0a41df97e33e37d1eba97f454f450e359/afscgap-0.0.6-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d32bc9b27e6cad61a40210704fa699e6f3fefcae7d2fc35857c9bec919c5c1e6",
          "md5": "d6d65c12baba35f1ae4f058ad8ddbee6",
          "sha256": "e8c4b0d6264fffb82888fdd6c74da28d27dc3fd11e8a5f6306273297574c3440"
        },
        "downloads": -1,
        "filename": "afscgap-0.0.6.tar.gz",
        "has_sig": false,
        "md5_digest": "d6d65c12baba35f1ae4f058ad8ddbee6",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 46440,
        "upload_time": "2023-03-06T16:08:11",
        "upload_time_iso_8601": "2023-03-06T16:08:11.031971Z",
        "url": "https://files.pythonhosted.org/packages/d3/2b/c9b27e6cad61a40210704fa699e6f3fefcae7d2fc35857c9bec919c5c1e6/afscgap-0.0.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fc767a69751bd993972f32883667ac5c345dc2380599253f2c8f4c93d0fde98a",
          "md5": "0568a6611c2f65c12ab06aecfd81e21a",
          "sha256": "aaf29abfa28f97b3ee56c5abe2a2c53d931832f715df23b5884d0cf23b8ac919"
        },
        "downloads": -1,
        "filename": "afscgap-0.0.7-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0568a6611c2f65c12ab06aecfd81e21a",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 41781,
        "upload_time": "2023-03-17T20:39:33",
        "upload_time_iso_8601": "2023-03-17T20:39:33.490546Z",
        "url": "https://files.pythonhosted.org/packages/fc/76/7a69751bd993972f32883667ac5c345dc2380599253f2c8f4c93d0fde98a/afscgap-0.0.7-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d8f3f664f909a1f99c0233c5e497fcc56e6fb01cf025acfe81f9b4164e4983c4",
          "md5": "ee5010a7bafd1aa7af8f3fbae4a4a96e",
          "sha256": "8cfb6140bbf567fef538d3410fcb38d375a77b4f22fb0e42b37cecb433a1e55b"
        },
        "downloads": -1,
        "filename": "afscgap-0.0.7.tar.gz",
        "has_sig": false,
        "md5_digest": "ee5010a7bafd1aa7af8f3fbae4a4a96e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 96431,
        "upload_time": "2023-03-17T20:39:35",
        "upload_time_iso_8601": "2023-03-17T20:39:35.405541Z",
        "url": "https://files.pythonhosted.org/packages/d8/f3/f664f909a1f99c0233c5e497fcc56e6fb01cf025acfe81f9b4164e4983c4/afscgap-0.0.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "fc767a69751bd993972f32883667ac5c345dc2380599253f2c8f4c93d0fde98a",
        "md5": "0568a6611c2f65c12ab06aecfd81e21a",
        "sha256": "aaf29abfa28f97b3ee56c5abe2a2c53d931832f715df23b5884d0cf23b8ac919"
      },
      "downloads": -1,
      "filename": "afscgap-0.0.7-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "0568a6611c2f65c12ab06aecfd81e21a",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 41781,
      "upload_time": "2023-03-17T20:39:33",
      "upload_time_iso_8601": "2023-03-17T20:39:33.490546Z",
      "url": "https://files.pythonhosted.org/packages/fc/76/7a69751bd993972f32883667ac5c345dc2380599253f2c8f4c93d0fde98a/afscgap-0.0.7-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "d8f3f664f909a1f99c0233c5e497fcc56e6fb01cf025acfe81f9b4164e4983c4",
        "md5": "ee5010a7bafd1aa7af8f3fbae4a4a96e",
        "sha256": "8cfb6140bbf567fef538d3410fcb38d375a77b4f22fb0e42b37cecb433a1e55b"
      },
      "downloads": -1,
      "filename": "afscgap-0.0.7.tar.gz",
      "has_sig": false,
      "md5_digest": "ee5010a7bafd1aa7af8f3fbae4a4a96e",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 96431,
      "upload_time": "2023-03-17T20:39:35",
      "upload_time_iso_8601": "2023-03-17T20:39:35.405541Z",
      "url": "https://files.pythonhosted.org/packages/d8/f3/f664f909a1f99c0233c5e497fcc56e6fb01cf025acfe81f9b4164e4983c4/afscgap-0.0.7.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}