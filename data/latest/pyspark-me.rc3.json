{
  "info": {
    "author": "Ivan Georgiev",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# pyspark-me\nDatabricks client SDK for Python with command line interface for Databricks REST APIs.\n\n[TOC]\n\n## Introduction\n\nPysparkme package provides python SDK for Databricks REST API:\n\n* dbfs\n* workspace\n* jobs\n* runs\n\nThe package also comes with a useful CLI which might be very helpful in automation.\n\n## Python Client SDK for Databricks REST APIs\n\n### Create Databricks connection\n\n```python\n# Get Databricks workspace connection\ndbc = pysparkme.databricks.connect(\n        bearer_token='dapixyzabcd09rasdf',\n        url='https://westeurope.azuredatabricks.net')\n```\n\n### DBFS\n\n```python\n# Get list of items at path /FileStore\ndbc.dbfs.ls('/FileStore')\n\n# Check if file or directory exists\ndbc.dbfs.exists('/path/to/heaven')\n\n# Make a directory and it's parents\ndbc.dbfs.mkdirs('/path/to/heaven')\n\n# Delete a directory recusively\ndbc.dbfs.rm('/path', recursive=True)\n\n# Download file block starting 1024 with size 2048\ndbc.dbfs.read('/data/movies.csv', 1024, 2048)\n\n# Download entire file\ndbc.dbfs.read_all('/data/movies.csv')\n```\n\n### Databricks workspace\n\n```python\n# List root workspace directory\ndbc.workspace.ls('/')\n\n# Check if workspace item exists\ndbc.workspace.exists('/explore')\n\n# Check if workspace item is a directory\ndbc.workspace.is_directory('/')\n\n# Export notebook in default (SOURCE) format\ndbc.workspace.export('/my_notebook')\n\n# Export notebook in HTML format\ndbc.workspace.export('/my_notebook', 'HTML')\n```\n\n## Databricks CLI `dbr-me`\n\nYou can call the Databricks CLI using convenient shell command `dbr-me`:\n\n```bash\n$ dbr-me --help\n```\n\n or using python module:\n\n```bash\n$ python -m pysparkme.databricks.cli --help\n```\n\nTo connect to the Databricks cluster, you can supply arguments at the command line:\n\n* `--bearer-token`\n* `--url`\n* `--cluster-id`\n\nAlternatively, you can define environment variables. Command line arguments take precedence.\n\n```bash\nexport DATABRICKS_URL='https://westeurope.azuredatabricks.net/'\nexport DATABRICKS_BEARER_TOKEN='dapixyz89u9ufsdfd0'\nexport DATABRICKS_CLUSTER_ID='1234-456778-abc234'\nexport DATABRICKS_ORG_ID='87287878293983984'\n```\n\n\n\n### Workspace\n\n```bash\n####################\n# List workspace\n# Default path is root - '/'\ndbr-me workspace ls\n# auto-add leading '/'\ndbr-me workspace ls 'Users'\n# Space-indentend json output with number of spaces\ndbr-me workspace --json-indent 4 ls\n# Custom indent string\ndbr-me workspace ls --json-indent='>'\n\n#####################\n# Export workspace items\n# Export everything in source format using defaults: format=SOURCE, path=/\ndbr-me workspace export -o ./.dev/export\n# Export everything in DBC format\ndbr-me workspace export -f DBC -o ./.dev/export.\n# When path is folder, export is recursive\ndbr-me workspace export -o ./.dev/export-utils 'Utils'\n# Export single ITEM\ndbr-me workspace export -o ./.dev/GetML 'Utils/Download MovieLens.py'\n```\n\n\n\n### DBFS\n\n#### List DBFS items\n\n```bash\n# List items on DBFS\ndbr-me dbfs ls --json-indent 3 FileStore/movielens\n```\n\n```bash\n[\n   {\n      \"path\": \"/FileStore/movielens/ml-latest-small\",\n      \"is_dir\": true,\n      \"file_size\": 0,\n      \"is_file\": false,\n      \"human_size\": \"0 B\"\n   }\n]\n```\n\n\n\n```bash\n# Download a file and print to STDOUT\ndbr-me dbfs get ml-latest-small/movies.csv\n```\n\n```bash\n# Download recursively entire directory and store locally\ndbr-me dbfs get -o ml-local ml-latest-small\n```\n\n\n\n### Runs\n\n#### Submit a notebook\n\nImplements: [https://docs.databricks.com/dev-tools/api/latest/jobs.html#runs-submit](https://docs.databricks.com/dev-tools/api/latest/jobs.html#runs-submit)\n\n```bash\n$ dbr-me runs submit \"Utils/Download MovieLens\"\n```\n\n```\n{\"run_id\": 4}\n```\n\nYou can retrieve the job information using `runs get`:\n\n```bash\n$ dbr-me runs get 4 -i 3\n```\n\n#### Get run metadata\n\nImplements: [Databricks REST runs/get](https://docs.databricks.com/dev-tools/api/latest/jobs.html#runs-get) \n\n```bash\n$ dbr-me runs get -i 3 6\n```\n\n```json\n{\n   \"job_id\": 6,\n   \"run_id\": 6,\n   \"creator_user_name\": \"your.name@gmail.com\",\n   \"number_in_job\": 1,\n   \"original_attempt_run_id\": null,\n   \"state\": {\n      \"life_cycle_state\": \"TERMINATED\",\n      \"result_state\": \"SUCCESS\",\n      \"state_message\": \"\"\n   },\n   \"schedule\": null,\n   \"task\": {\n      \"notebook_task\": {\n         \"notebook_path\": \"/Utils/Download MovieLens\"\n      }\n   },\n   \"cluster_spec\": {\n      \"existing_cluster_id\": \"xxxx-yyyyy-zzzzzz\"\n   },\n   \"cluster_instance\": {\n      \"cluster_id\": \"xxxx-yyyyy-zzzzzz\",\n      \"spark_context_id\": \"783487348734873873\"\n   },\n   \"overriding_parameters\": null,\n   \"start_time\": 1592062497162,\n   \"setup_duration\": 0,\n   \"execution_duration\": 11000,\n   \"cleanup_duration\": 0,\n   \"trigger\": null,\n   \"run_name\": \"pyspark-me-1592062494\",\n   \"run_page_url\": \"https://westeurope.azuredatabricks.net/?o=398348734873487#job/6/run/1\",\n   \"run_type\": \"SUBMIT_RUN\"\n}\n```\n\n\n\n#### List Runs\n\nImplements: [Databricks REST runs/list](https://docs.databricks.com/dev-tools/api/latest/jobs.html#runs-list)\n\n```bash\n$ dbr-me runs ls\n```\n\n\n\nTo get only the runs for a particular job:\n\n```bash\n# Get job with job-id=4\n$ dbr-me runs ls 4 -i 3\n```\n\n```json\n{\n   \"runs\": [\n      {\n         \"job_id\": 4,\n         \"run_id\": 4,\n         \"creator_user_name\": \"your.name@gmail.com\",\n         \"number_in_job\": 1,\n         \"original_attempt_run_id\": null,\n         \"state\": {\n            \"life_cycle_state\": \"PENDING\",\n            \"state_message\": \"\"\n         },\n         \"schedule\": null,\n         \"task\": {\n            \"notebook_task\": {\n               \"notebook_path\": \"/Utils/Download MovieLens\"\n            }\n         },\n         \"cluster_spec\": {\n            \"existing_cluster_id\": \"xxxxx-yyyy-zzzzzzz\"\n         },\n         \"cluster_instance\": {\n            \"cluster_id\": \"xxxxx-yyyy-zzzzzzz\"\n         },\n         \"overriding_parameters\": null,\n         \"start_time\": 1592058826123,\n         \"setup_duration\": 0,\n         \"execution_duration\": 0,\n         \"cleanup_duration\": 0,\n         \"trigger\": null,\n         \"run_name\": \"pyspark-me-1592058823\",\n         \"run_page_url\": \"https://westeurope.azuredatabricks.net/?o=abcdefghasdf#job/4/run/1\",\n         \"run_type\": \"SUBMIT_RUN\"\n      }\n   ],\n   \"has_more\": false\n}\n```\n\n\n\n#### Export run \n\nImplements: [Databricks REST runs/export](https://docs.databricks.com/dev-tools/api/latest/jobs.html#runs-export)\n\n```bash\n$ dbr-me runs export --content-only 4 > .dev/run-view.html\n```\n\n\n\n#### Get run output\n\nImplements: [Databricks REST runs/get-output](https://docs.databricks.com/dev-tools/api/latest/jobs.html#runs-get-output)\n\n```bash\n$ dbr-me runs get-output -i 3 6\n```\n\n```json\n{\n   \"notebook_output\": {\n      \"result\": \"Downloaded files: README.txt, links.csv, movies.csv, ratings.csv, tags.csv\",\n      \"truncated\": false\n   },\n   \"error\": null,\n   \"metadata\": {\n      \"job_id\": 5,\n      \"run_id\": 5,\n      \"creator_user_name\": \"your.name@gmail.com\",\n      \"number_in_job\": 1,\n      \"original_attempt_run_id\": null,\n      \"state\": {\n         \"life_cycle_state\": \"TERMINATED\",\n         \"result_state\": \"SUCCESS\",\n         \"state_message\": \"\"\n      },\n      \"schedule\": null,\n      \"task\": {\n         \"notebook_task\": {\n            \"notebook_path\": \"/Utils/Download MovieLens\"\n         }\n      },\n      \"cluster_spec\": {\n         \"existing_cluster_id\": \"xxxx-yyyyy-zzzzzzz\"\n      },\n      \"cluster_instance\": {\n         \"cluster_id\": \"xxxx-yyyyy-zzzzzzz\",\n         \"spark_context_id\": \"8973498743973498\"\n      },\n      \"overriding_parameters\": null,\n      \"start_time\": 1592062147101,\n      \"setup_duration\": 1000,\n      \"execution_duration\": 11000,\n      \"cleanup_duration\": 0,\n      \"trigger\": null,\n      \"run_name\": \"pyspark-me-1592062135\",\n      \"run_page_url\": \"https://westeurope.azuredatabricks.net/?o=89798374987987#job/5/run/1\",\n      \"run_type\": \"SUBMIT_RUN\"\n   }\n}\n```\n\n\n\nTo get only the exit output:\n\n```bash\n$ dbr-me runs get-output -r 6\n```\n\n```\nDownloaded files: README.txt, links.csv, movies.csv, ratings.csv, tags.csv\n```\n\n\n\n## Build and publish\n\n```bash\npython setup.py sdist bdist_wheel\npython -m twine upload dist/*\n```\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/ivangeorgiev/pyspark-me",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "pyspark-me",
    "package_url": "https://pypi.org/project/pyspark-me/",
    "platform": "",
    "project_url": "https://pypi.org/project/pyspark-me/",
    "project_urls": {
      "Homepage": "https://github.com/ivangeorgiev/pyspark-me"
    },
    "release_url": "https://pypi.org/project/pyspark-me/0.0.6/",
    "requires_dist": [
      "click",
      "requests"
    ],
    "requires_python": ">=3.6",
    "summary": "Databricks client SDK with command line client for Databricks REST APIs",
    "version": "0.0.6",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 7468555,
  "releases": {
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "66a505a2d1def183cb985a62d24f1dacbc03cb3e0ba6585c9e5e4f6358687583",
          "md5": "36ddeff0629f770782b2295d075fdfd5",
          "sha256": "0688b7ceebf2c1505d7126595a04a527d01056be9ad0b1ee5f1690d7bbd9f1b1"
        },
        "downloads": -1,
        "filename": "pyspark_me-0.0.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "36ddeff0629f770782b2295d075fdfd5",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 18947,
        "upload_time": "2020-05-07T16:30:12",
        "upload_time_iso_8601": "2020-05-07T16:30:12.769671Z",
        "url": "https://files.pythonhosted.org/packages/66/a5/05a2d1def183cb985a62d24f1dacbc03cb3e0ba6585c9e5e4f6358687583/pyspark_me-0.0.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "613f69a593e45a9ea062f6f8c3efab21c9de3ce86ec50f80b88fbd0ab4abda87",
          "md5": "009b4280452666ba0d9c2a7418f16793",
          "sha256": "c1d51837c07b25d3846db604c5b5d6d2846f42906ebf7fa49d7a0b69beb6e733"
        },
        "downloads": -1,
        "filename": "pyspark-me-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "009b4280452666ba0d9c2a7418f16793",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 7586,
        "upload_time": "2020-05-07T16:30:14",
        "upload_time_iso_8601": "2020-05-07T16:30:14.014622Z",
        "url": "https://files.pythonhosted.org/packages/61/3f/69a593e45a9ea062f6f8c3efab21c9de3ce86ec50f80b88fbd0ab4abda87/pyspark-me-0.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "77c5a1340daf66f8ef1491576445042d9d765546d0d57181ba9873336ab11cd0",
          "md5": "fb36649e95d215288907aaff86bb3a62",
          "sha256": "feb3a0913626c12a5d0a58ac126698fb0e5f28d4b03ed657d27c0f4f9301b272"
        },
        "downloads": -1,
        "filename": "pyspark_me-0.0.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "fb36649e95d215288907aaff86bb3a62",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 19930,
        "upload_time": "2020-05-07T21:27:01",
        "upload_time_iso_8601": "2020-05-07T21:27:01.308132Z",
        "url": "https://files.pythonhosted.org/packages/77/c5/a1340daf66f8ef1491576445042d9d765546d0d57181ba9873336ab11cd0/pyspark_me-0.0.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "de37240c101668eda0967b53586d8653a54cac963d4ca95c90ec6fc62a131e63",
          "md5": "8b0ec5f52f31f0279fe5cf82fb6eca4c",
          "sha256": "d3c2ae5a10654ce2682ddc5ff579285d188ec9605875a5f918384e77f71c9e3e"
        },
        "downloads": -1,
        "filename": "pyspark-me-0.0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "8b0ec5f52f31f0279fe5cf82fb6eca4c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 8565,
        "upload_time": "2020-05-07T21:27:02",
        "upload_time_iso_8601": "2020-05-07T21:27:02.458779Z",
        "url": "https://files.pythonhosted.org/packages/de/37/240c101668eda0967b53586d8653a54cac963d4ca95c90ec6fc62a131e63/pyspark-me-0.0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e1fe5f4d14dc11b6915b19720ccaaadade4e18ced790491a2405f05a087e6e53",
          "md5": "7d4559bcfb124d41f1e0a9955d5888e1",
          "sha256": "48fc48abede5548f7e98100a15d65d8210c9280e81c954e6c19efda4e35d9595"
        },
        "downloads": -1,
        "filename": "pyspark_me-0.0.6-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "7d4559bcfb124d41f1e0a9955d5888e1",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 24262,
        "upload_time": "2020-06-13T16:10:00",
        "upload_time_iso_8601": "2020-06-13T16:10:00.669478Z",
        "url": "https://files.pythonhosted.org/packages/e1/fe/5f4d14dc11b6915b19720ccaaadade4e18ced790491a2405f05a087e6e53/pyspark_me-0.0.6-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c404dd7a47355a1e500ec11fd8cfe6f97360cd6b25266b99d340d92c807156b7",
          "md5": "422dfcff837c2b82f331b54c00a68565",
          "sha256": "fc05a7465f4d57e075a08aa1633d77127f00ff4b8c9712c9ba4de41af82c4f51"
        },
        "downloads": -1,
        "filename": "pyspark-me-0.0.6.tar.gz",
        "has_sig": false,
        "md5_digest": "422dfcff837c2b82f331b54c00a68565",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 13102,
        "upload_time": "2020-06-13T16:10:02",
        "upload_time_iso_8601": "2020-06-13T16:10:02.804574Z",
        "url": "https://files.pythonhosted.org/packages/c4/04/dd7a47355a1e500ec11fd8cfe6f97360cd6b25266b99d340d92c807156b7/pyspark-me-0.0.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "e1fe5f4d14dc11b6915b19720ccaaadade4e18ced790491a2405f05a087e6e53",
        "md5": "7d4559bcfb124d41f1e0a9955d5888e1",
        "sha256": "48fc48abede5548f7e98100a15d65d8210c9280e81c954e6c19efda4e35d9595"
      },
      "downloads": -1,
      "filename": "pyspark_me-0.0.6-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "7d4559bcfb124d41f1e0a9955d5888e1",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 24262,
      "upload_time": "2020-06-13T16:10:00",
      "upload_time_iso_8601": "2020-06-13T16:10:00.669478Z",
      "url": "https://files.pythonhosted.org/packages/e1/fe/5f4d14dc11b6915b19720ccaaadade4e18ced790491a2405f05a087e6e53/pyspark_me-0.0.6-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "c404dd7a47355a1e500ec11fd8cfe6f97360cd6b25266b99d340d92c807156b7",
        "md5": "422dfcff837c2b82f331b54c00a68565",
        "sha256": "fc05a7465f4d57e075a08aa1633d77127f00ff4b8c9712c9ba4de41af82c4f51"
      },
      "downloads": -1,
      "filename": "pyspark-me-0.0.6.tar.gz",
      "has_sig": false,
      "md5_digest": "422dfcff837c2b82f331b54c00a68565",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 13102,
      "upload_time": "2020-06-13T16:10:02",
      "upload_time_iso_8601": "2020-06-13T16:10:02.804574Z",
      "url": "https://files.pythonhosted.org/packages/c4/04/dd7a47355a1e500ec11fd8cfe6f97360cd6b25266b99d340d92c807156b7/pyspark-me-0.0.6.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}