{
  "info": {
    "author": "Shrinivas Vijay Deshmukh",
    "author_email": "shrinivas.deshmukh11@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 2 - Pre-Alpha",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Natural Language :: English",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8"
    ],
    "description": "# avroconvert\n\n[![codecov](https://codecov.io/gh/shrinivdeshmukh/avroconvert/branch/main/graph/badge.svg?token=HKF3Q637NV)](https://codecov.io/gh/shrinivdeshmukh/avroconvert)\n[![docs](https://readthedocs.org/projects/pip/badge/?version=latest&style=flat)](https://avroconvert.readthedocs.io/en/latest/)\n[![docs](https://img.shields.io/pypi/v/avroconvert)](https://pypi.org/project/avroconvert/)\n\nUtility to convert avro files to csv, json and parquet formats\n\n* ## Installation\n\nUsing pypi\n\n```\npip install avroconvert\n```\n\nUsing git:\n\n```\ngit clone https://github.com/shrinivdeshmukh/avroconvert\n```\n```\nmake install\n```\n\n* ## Usage\n\n### Using CLI\n\nCLI can be used to interact with the tool. As the first argument, the source has to be passed. The source can be gs (google cloud storage bucket), s3 (amazon s3 bucket) or fs (local filesystem)\n\n**To read from cloud bucket (google cloud or amazon s3):**\n\ngoogle cloud storage example:\n\n```\navroconvert gs -b <BUCKET_NAME> -f <FORMAT> -o <OUTPUT_FOLDER>\n```\n\namazon s3 example:\n\n```\navroconvert s3 -b <BUCKET_NAME> -f <FORMAT> -o <OUTPUT_FOLDER>\n```\n\nThe tool reads all avro files from the bucket specified by the `-b` parameter, converts them to the format specified by the `-f` parameter, and writes the output format files to the output folder specified by the `-o` parameter with the above command.\n\nThe cli accepts a few additional parameters to authenticate the tool with cloud providers. These parameters are only required if you haven't already been authenticated.\n\nFor google cloud, we have `--auth-file`:\n\n```\navroconvert gs -b <BUCKET_NAME> -f <FORMAT> -o <OUTPUT_FOLDER> --auth-file <SERVICE_ACCOUNT_FILE_PATH>.json (or .p12)\n```\n\nFor amazon s3, we have `--access-key`, `--secret-key`, `--session-token`:\n\n```\navroconvert s3 -b <BUCKET_NAME> -f <FORMAT> -o <OUTPUT_FOLDER> --access-key <AWS_ACCESS_KEY_ID> --secret-key <AWS_SECRET_ACCESS_KEY> --session-token <AWS_SESSION_TOKEN> \n```\n\n**To read from local filesystem**\n\n```\navroconvert fs  -i <INPUT_DATA_FOLDER> -o <OUTPUT_FOLDER> -f <OUTPUT_FORMAT>\n```\n\nThe tool reads all avro files from the input folder specified by the `-i` parameter, converts them to the format specified by the `-f` parameter, and writes the output format files to the output folder specified by the `-o` parameter with the above command.\n\n**Output folder structure**\n\nThe tool replicates the cloud bucket's or local filesystem's directory structure. For example, suppose the output format is parquet and cloud bucket (or local filesystem) has the following structure:\n\n```\nBUCKET\n├── 2021-06-17\n│   └── file1.avro\n│   └── file2.avro\n│ \n├── 2021-06-16\n│   └── data\n│       └── file3.avro\n│       └── file4.avro\n\n```\n\nthe output files will then be saved as:\n\n```\nOUTPUT_FOLDER\n├── 2021-06-17\n│   └── file1.parquet\n│   └── file2.parquet\n│ \n├── 2021-06-16\n│   └── data\n│       └── file3.parquet\n│       └── file4.parquet\n\n```\n\n**Filter files to read**\n\nA parameter called `-p` or `—-prefix` can be passed as well. All three data sources, gs, s3, and fs, share this parameter. Only files with names that begin with the specified prefix will be read; all other files will be filtered out.\n\ngoogle cloud example with `-p`:\n\n```\navroconvert gs -b <BUCKET_NAME> -f <FORMAT> -o <OUTPUT_FOLDER> -p 2021-06-17/file\n```\n\namazon s3 example with `-p`:\n\n```\navroconvert s3 -b <BUCKET_NAME> -f <FORMAT> -o <OUTPUT_FOLDER> -p 2021-06-17/file\n```\n\nlocal filesystem example with `-p`:\n\n```\navroconvert fs  -i <INPUT_DATA_FOLDER> -o <OUTPUT_FOLDER> -f <OUTPUT_FORMAT> -p 2021-06-17/file\n```\n\n### Using the API in code\n\n```\n    from avroconvert import Execute\n\n    # for amazon s3 storage bucket reader\n    output = Execute(source='gs', bucket='<BUCKET_NAME>, dst_format='parquet', auth_file='<SERVICE_ACCOUNT.json>',\n                     outfolder='OUTPUT_FOLDER', access_key='<AWS ACCESS KEY>', secret_key='<AWS SECRET KEY>', \n                     session_token='<AWS SESSION TOKEN>(if any)', bucket='<S3 BUCKET>', prefix='<FILE PREFIX>').run()\n\n    # google storage bucket reader\n    output = Execute(source='gs', bucket='<BUCKET_NAME>, dst_format='parquet', auth_file='<SERVICE_ACCOUNT.json>',\n                     outfolder='OUTPUT_FOLDER').run()\n\n    # Local file system reader\n    output = Execute(source='fs', bucket='<LOCAL_FOLDER NAME> dst_format='parquet', outfolder='OUTPUT_FOLDER').run()\n\n```\n\nFor more details on using the API, please visit [readthedocs](https://avroconvert.readthedocs.io/en/latest/)\n* ## Credits\n\nThis package was created with [Cookiecutter](https://github.com/audreyr/cookiecutter) and the [audreyr/cookiecutter-pypackage](https://github.com/audreyr/cookiecutter-pypackage) project template.\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/shrinivdeshmukh/avroconvert",
    "keywords": "avroconvert",
    "license": "MIT license",
    "maintainer": "",
    "maintainer_email": "",
    "name": "avroconvert",
    "package_url": "https://pypi.org/project/avroconvert/",
    "platform": "",
    "project_url": "https://pypi.org/project/avroconvert/",
    "project_urls": {
      "Homepage": "https://github.com/shrinivdeshmukh/avroconvert"
    },
    "release_url": "https://pypi.org/project/avroconvert/0.1.1/",
    "requires_dist": [
      "boto3 (==1.15.15)",
      "fastavro (==1.0.0.post1)",
      "pandas (==1.2.0)",
      "pyarrow (==4.0.1)",
      "google-api-core (==1.22.4)",
      "google-api-python-client (==1.12.8)",
      "google-auth (==1.22.1)",
      "google-auth-httplib2 (==0.0.4)",
      "google-auth-oauthlib (==0.4.2)",
      "google-cloud-bigquery (==2.0.0)",
      "google-cloud-bigquery-storage (==2.0.0)",
      "google-cloud-core (==1.4.2)",
      "google-cloud-storage (==1.31.2)",
      "google-crc32c (==1.0.0)",
      "google-resumable-media (==1.1.0)",
      "googleapis-common-protos (==1.52.0)",
      "pydata-google-auth (==1.1.0)",
      "python-snappy (==0.6.0)"
    ],
    "requires_python": ">=3.6",
    "summary": "Utility to convert avro files to csv, json and parquet formats",
    "version": "0.1.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 10740973,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6d15d4921677f4c5c7eac0552f238db09f6e721d597213d257c6f6c64b543c2e",
          "md5": "ee469e192e9c55ebabd4487e849a8fd9",
          "sha256": "6e85a8e48cff2c1a8b54dbb059dcd1c733d5f036300a51864b2531a4e83a74a8"
        },
        "downloads": -1,
        "filename": "avroconvert-0.1.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ee469e192e9c55ebabd4487e849a8fd9",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": ">=3.6",
        "size": 16070,
        "upload_time": "2021-06-18T14:04:23",
        "upload_time_iso_8601": "2021-06-18T14:04:23.186791Z",
        "url": "https://files.pythonhosted.org/packages/6d/15/d4921677f4c5c7eac0552f238db09f6e721d597213d257c6f6c64b543c2e/avroconvert-0.1.0-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "97a6456644eee60f8a7dd52d51d5427df51cc14831adc66e6f79382a2caa1df3",
          "md5": "4380c9e5026c30c1233ebb96cc5199a9",
          "sha256": "8b87d740075a9910b8c3b385f1400c6e7cca37f3b9cb28820428998b550634f7"
        },
        "downloads": -1,
        "filename": "avroconvert-0.1.1-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "4380c9e5026c30c1233ebb96cc5199a9",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": ">=3.6",
        "size": 16558,
        "upload_time": "2021-06-25T08:25:45",
        "upload_time_iso_8601": "2021-06-25T08:25:45.688012Z",
        "url": "https://files.pythonhosted.org/packages/97/a6/456644eee60f8a7dd52d51d5427df51cc14831adc66e6f79382a2caa1df3/avroconvert-0.1.1-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "97a6456644eee60f8a7dd52d51d5427df51cc14831adc66e6f79382a2caa1df3",
        "md5": "4380c9e5026c30c1233ebb96cc5199a9",
        "sha256": "8b87d740075a9910b8c3b385f1400c6e7cca37f3b9cb28820428998b550634f7"
      },
      "downloads": -1,
      "filename": "avroconvert-0.1.1-py2.py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "4380c9e5026c30c1233ebb96cc5199a9",
      "packagetype": "bdist_wheel",
      "python_version": "py2.py3",
      "requires_python": ">=3.6",
      "size": 16558,
      "upload_time": "2021-06-25T08:25:45",
      "upload_time_iso_8601": "2021-06-25T08:25:45.688012Z",
      "url": "https://files.pythonhosted.org/packages/97/a6/456644eee60f8a7dd52d51d5427df51cc14831adc66e6f79382a2caa1df3/avroconvert-0.1.1-py2.py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}