{
  "info": {
    "author": "Tomasz Szandala",
    "author_email": "tomasz.szandala@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# PRISM - **Pr**incipal **I**mage **S**ections **M**apping\n\n![TorchPRISM's summary](https://raw.githubusercontent.com/szandala/TorchPRISM/master/TorchPRISM_summary.png)\n\nGraphic Author: [*Natalia Rusin*](https://github.com/Nat3005)\n\nA novel tool that utilizes Principal Component Analysis to display discriminative featues detected by a given convolutional neural network.\nIt complies with virtually all CNNs.\n\n\n# Table of Contents\n* [Usage](#Usage)\n* [`prism` arguments](#`prism`-arguments)\n* [Other arguments](#Other-arguments)\n* [Demo](#Demo)\n* [Results](#Results)\n* [Variance across all Principal Componentes](#Variance-across-all-Principal-Componentes)\n* [Saliency maps integration](#Saliency-maps-integration)\n* [Clustering](#Clustering)\n* [Read more](#Read-more)\n\n## Usage\n\nFor user's convenience we have prepared an argument-feedable excutable `prism`.\nIn order to use it, please prepare virtual env:\n```sh\npython3 -m venv venv\nsource ./venv/bin/activate\npip install --upgrade pip\npip install -r requirements.txt\n./prism\n```\n\n## `prism` arguments\n\n| Argument | Description | Result |\n| :---: | :---: | :---: |\n| none | Default PRISM exection with Gradual Extrapolation applied | ![Vanilla result](https://raw.githubusercontent.com/szandala/TorchPRISM/assets/results/PRISM_vanilla.jpg) |\n| --no-gradual-extrapolation | Skipping Gradual Extrapolation | ![Disabled Gradual Extrapolation](https://raw.githubusercontent.com/szandala/TorchPRISM/assets/results/PRISM_no-ge.jpg) |\n| --inclusive | Quantize colours and show only common for all images in batch | ![Only common features](https://raw.githubusercontent.com/szandala/TorchPRISM/assets/results/PRISM_inclusive.jpg) |\n| --inclusive & --no-gradual-extrapolation | Quantize colours and show only common for all images in batch. **Skip GE!** | ![Inclusive, no GE](https://raw.githubusercontent.com/szandala/TorchPRISM/assets/results/PRISM_no-ge_inclusive.jpg) |\n| --exclusive | Quantize colours and show only unique features for images in batch | ![Only unique features](https://raw.githubusercontent.com/szandala/TorchPRISM/assets/results/PRISM_exclusive.jpg) |\n| --exclusive & --no-gradual-extrapolation | Quantize colours and show only unique features for images in batch. **Skip GE!** | ![Exclusive, no GE](https://raw.githubusercontent.com/szandala/TorchPRISM/assets/results/PRISM_no-ge_exclusive.jpg) |\n| --exclusive & --inclusive | Quantize original PRISM output **Skip GE!** | ![Quantized vanilla result without GE](https://raw.githubusercontent.com/szandala/TorchPRISM/assets/results/PRISM_inclusive_exclusive.jpg) |\n| --split-rgb |Split PRISM output into separate RGB channels. | ![RGB split](https://raw.githubusercontent.com/szandala/TorchPRISM/assets/results/PRISM_RGB.jpg) |\n| --split-rgb & --no-gradual-extrapolation | Also split into RGB, but without Gradual Extrapolation. **Skip GE!** Note it can also go with `--inclusive` or `--exclusive`| ![RGB split, no GE](https://raw.githubusercontent.com/szandala/TorchPRISM/assets/results/PRISM_no-ge_RGB.jpg) |\n\n\n## Other arguments\n\n| Argument | Description | Default |\n| :---: | :---: | :---: |\n| --input=`/path/to/...` | Path from where to take images. Note it is a `glob`, so value `./samples/**/*.jpg` will mean: `jpg` images from ALL subfolders of `samples` | `./samples/*.jpg` |\n| --model=`model-name` | Model to be used with PRISM. Note that Gradual Extrapolation may not behave properly for some models outside *vgg* family. | `vgg16` |\n| --saliency=`model-name` | Makes TorchPRISM perform chosen saliency map generating process and combines it with PRISMâ€™s output. Currently supports:<br>- Contrastive Excitation Backpropagation `exct-backp`<br>- GradCAM `gradcam` | `none` |\n| --cluster | Generates binary file with list of lists - which image contains which features according to PRISM. It can be further used for clustering in script som.py |  |\n| --help | Print help details and exit |  |\n\n## Demo\n\n[Simplest snippet](https://github.com/szandala/TorchPRISM/blob/master/SoftwareX_snippet/snippet.py) of working code.\n\n```python\nimport sys\nsys.path.insert(0, \"../\")\nfrom torchprism import PRISM\nfrom torchvision import models\nfrom utils import load_images, draw_input_n_prism\n\n# load images into batch\ninput_batch = load_images()\n\nmodel = models.vgg11(pretrained=True)\nmodel.eval()\nPRISM.register_hooks(model)\n\nmodel(input_batch)\nprism_maps_batch = PRISM.get_maps()\n\ndrawable_input_batch = input_batch.permute(0, 2, 3, 1).detach().cpu().numpy()\ndrawable_prism_maps_batch = prism_maps_batch.permute(0, 2, 3, 1).detach().cpu().numpy()\n\ndraw_input_n_prism(drawable_input_batch, drawable_prism_maps_batch)\n```\nFirst we have to import PRISM and torch models., as well as functions for preparing input images as simple torch batch and function to draw batches. Next we have to load the model, in this case a pretrained vgg11 has been chosen and then we have to call the first PRISM method to register required hooks in the model.\nWith such a prepared model we can perform the classification and, since the actual output is not needed, we can just ignore it. Model execution is followed by using the second PRISM method to calculate features maps for the processed batch. Finally we have to prepare both input and PRISM output so they can be drawn and as the last step we call a method that displays them using e.g. matplotlib.\n\n## Results\n\nThe results allow us to see the discriminative features found by the model.\nOn the sample images below we can see wolves\n\n![Snippet result](https://raw.githubusercontent.com/szandala/TorchPRISM/master/SoftwareX_snippet/PRISM_result.png)\n\nWe can notice that all wolves have similar colors - features, found on their bodies. Furthermore the coyote also shows almost identical characteristics except the mouth element. wolves have a black stain around their noses, while coyote does not.\n\n## Variance across all Principal Componentes\n\n![Variance for PCs](https://raw.githubusercontent.com/szandala/TorchPRISM/assets/results/PRISM_var_vgg16.jpg)\n\nAlso an image with variance is being plotted.\n\n## Saliency maps integration\n\nSince PRISM can be integrated with all saliency map types it comes with built-in generating tools.\nWe have an example where dog (malamute) is properly recognized by VGG-16 model. However it is alongside mushroom, which despite being correctly identified, has no impact on models classification decision.\nApparently mushroom is not important for the classification, therefore we can generate saliency map for the given example and merge it with PRISM's output.\n![Saliency map combination with PRISM](https://raw.githubusercontent.com/szandala/TorchPRISM/assets/results/PRISM_with_saliency.jpg)\n\n## Clustering\n\nLast but not least a clusterig can be performed using PRISM in order to detect potentially amibgious classes.\nWe have taken 5 canine classes (colour from cluster map in bracket):\n- coyote (orange)\n- grey fox (red)\n- timber wolf (green)\n- samoyed (purple)\n- border collie (blue)\n\n\n![Clustering of PRISM's output](https://raw.githubusercontent.com/szandala/TorchPRISM/assets/results/clustering.png)\n\nFrom the figure we can conclude that coyotes(orange) could be easily confused with timber wolves(green) and grey foxes(red). On the other hand the Samoyed and Border collie specimens (purple and blue respectively) are clearly distinguishable from the rest.\n\n\n\n## Read more\n- **[PRISM comparison with other methods](https://github.com/szandala/TorchPRISM/tree/comparison/comparison_with_others)**\n- [IEEE Access: Gradual Extrapolation](https://ieeexplore.ieee.org/document/9468713)\n- [ICCS-2021: Attention Focus](https://www.iccs-meeting.org/archive/iccs2021/papers/127430415.pdf)\n- [ICCS-2022: PRISM](https://link.springer.com/chapter/10.1007/978-3-031-08751-6_54)\n- [PP RAI'22: Summary](https://docs.google.com/document/d/1_-TKex_0BW2pV3BO4Uwk6gF3Cer2bB5qUdgxWns0e-4/edit?usp=sharing)\n\n**Old LOGO**\n![PRISM old logo](https://raw.githubusercontent.com/szandala/TorchPRISM/master/PRISM_logo.png)\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/szandala/TorchPRISM",
    "keywords": "deep-learning,PCA,visualization,interpretability",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "torchprism",
    "package_url": "https://pypi.org/project/torchprism/",
    "platform": null,
    "project_url": "https://pypi.org/project/torchprism/",
    "project_urls": {
      "Homepage": "https://github.com/szandala/TorchPRISM"
    },
    "release_url": "https://pypi.org/project/torchprism/2.0.0/",
    "requires_dist": [
      "torch (>=1.1)",
      "torchvision (>=0.3.0)"
    ],
    "requires_python": ">=3.6",
    "summary": "Principal Image Sections Mapping for PyTorch",
    "version": "2.0.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 15681350,
  "releases": {
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3c10c963869c19ea2811f624006450ed9a02c83bb18a5460e9af6ce2d46707db",
          "md5": "1a89bae8572393a46683b6e913017cb5",
          "sha256": "fd44334b80dd5c355a680e51058acc4adb05af998e5df5649b6ec0c7f7695b6c"
        },
        "downloads": -1,
        "filename": "torchprism-1.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "1a89bae8572393a46683b6e913017cb5",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 4880,
        "upload_time": "2021-01-28T11:36:19",
        "upload_time_iso_8601": "2021-01-28T11:36:19.602115Z",
        "url": "https://files.pythonhosted.org/packages/3c/10/c963869c19ea2811f624006450ed9a02c83bb18a5460e9af6ce2d46707db/torchprism-1.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d9354eaea4c95ecb0d5a3a97427165eaa8f8cf6fcdcaf372fe203e7568e3af1a",
          "md5": "09791c527c43e186f961a9368c8d7745",
          "sha256": "541c314de6e9d3494e9672234a9ede3618cb8785a99e225f5774646ebedcd810"
        },
        "downloads": -1,
        "filename": "torchprism-1.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "09791c527c43e186f961a9368c8d7745",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 4929,
        "upload_time": "2021-02-03T18:50:30",
        "upload_time_iso_8601": "2021-02-03T18:50:30.281074Z",
        "url": "https://files.pythonhosted.org/packages/d9/35/4eaea4c95ecb0d5a3a97427165eaa8f8cf6fcdcaf372fe203e7568e3af1a/torchprism-1.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "b3456ecd87520ecdb39ea6b0290db58f98657c0116966e30961ddf6e5f4bec25",
          "md5": "8876c5faf4fcae24144dcca58b91acf7",
          "sha256": "c10a5b7e3801ce539a713d8a4629278af67152d3f6c892a0a740807b2508e566"
        },
        "downloads": -1,
        "filename": "torchprism-1.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "8876c5faf4fcae24144dcca58b91acf7",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 4046,
        "upload_time": "2021-02-03T18:50:31",
        "upload_time_iso_8601": "2021-02-03T18:50:31.752329Z",
        "url": "https://files.pythonhosted.org/packages/b3/45/6ecd87520ecdb39ea6b0290db58f98657c0116966e30961ddf6e5f4bec25/torchprism-1.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a1aed3055af5d92de87c1809d3b2f8c4657bf54be5e643b40971b2b2f08a2567",
          "md5": "8c31441ace8e549c6a102d1399eb5c5a",
          "sha256": "b01f56e627f2b205601004e66c3430b00e2abd02b26aef5e5b5f65fd8ec667bf"
        },
        "downloads": -1,
        "filename": "torchprism-1.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "8c31441ace8e549c6a102d1399eb5c5a",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 4837,
        "upload_time": "2021-02-16T18:53:29",
        "upload_time_iso_8601": "2021-02-16T18:53:29.896479Z",
        "url": "https://files.pythonhosted.org/packages/a1/ae/d3055af5d92de87c1809d3b2f8c4657bf54be5e643b40971b2b2f08a2567/torchprism-1.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7811e6d9f25fe2c9aeff8d55c455880b2164a9e3f8bcfdb26ac9f47f3b19eae2",
          "md5": "799c6e621bd29b16f8aee5c5298c9a5e",
          "sha256": "803d3e128291a8d1b3376df8ada662126e7a76f131428881143259a332e107c6"
        },
        "downloads": -1,
        "filename": "torchprism-1.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "799c6e621bd29b16f8aee5c5298c9a5e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 3973,
        "upload_time": "2021-02-16T18:53:31",
        "upload_time_iso_8601": "2021-02-16T18:53:31.019519Z",
        "url": "https://files.pythonhosted.org/packages/78/11/e6d9f25fe2c9aeff8d55c455880b2164a9e3f8bcfdb26ac9f47f3b19eae2/torchprism-1.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "2.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8862cf5f7f835798e0c562fd98e7efa29f789bb7337c069e5ea6e5a535daa63e",
          "md5": "5fb8221a615d372ff23ba310c7a86596",
          "sha256": "cd450a72b48431e19052fe53f96aaf4a91c51d5cd76e853e58eeed27a6a3896d"
        },
        "downloads": -1,
        "filename": "torchprism-2.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "5fb8221a615d372ff23ba310c7a86596",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.6",
        "size": 7104,
        "upload_time": "2022-11-07T07:38:41",
        "upload_time_iso_8601": "2022-11-07T07:38:41.355423Z",
        "url": "https://files.pythonhosted.org/packages/88/62/cf5f7f835798e0c562fd98e7efa29f789bb7337c069e5ea6e5a535daa63e/torchprism-2.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "8862cf5f7f835798e0c562fd98e7efa29f789bb7337c069e5ea6e5a535daa63e",
        "md5": "5fb8221a615d372ff23ba310c7a86596",
        "sha256": "cd450a72b48431e19052fe53f96aaf4a91c51d5cd76e853e58eeed27a6a3896d"
      },
      "downloads": -1,
      "filename": "torchprism-2.0.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "5fb8221a615d372ff23ba310c7a86596",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.6",
      "size": 7104,
      "upload_time": "2022-11-07T07:38:41",
      "upload_time_iso_8601": "2022-11-07T07:38:41.355423Z",
      "url": "https://files.pythonhosted.org/packages/88/62/cf5f7f835798e0c562fd98e7efa29f789bb7337c069e5ea6e5a535daa63e/torchprism-2.0.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}