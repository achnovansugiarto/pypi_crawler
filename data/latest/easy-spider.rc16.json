{
  "info": {
    "author": "lin3x",
    "author_email": "544670411@qq.com",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Easy Spider\n## release note \n1.0.13: 添加自动保存功能\n\n1.1.2: 引入中间件处理，优化 easy_spider.core.Spider 中对请求进行处理的逻辑。\n\n## quick start\n``` python\nfrom easy_spider import async_env, AsyncSpider, Request, HTMLResponse\n    \nclass MySpider(AsyncSpider):\n\n    def init(self):\n        super().__init__()\n        self.start_targets = [\"https://github.blog/\"]\n\n    def handle(self, response: HTMLResponse):\n        titles = response.bs.select(\".post-list__item a\")\n        print([title.text for title in titles])\n\nasync_env.run(MySpider())\n```\n\n这段代码定义了一个`spider`对象，并爬取了[github-blog](https://github.blog/) 中文章的标题。其中主要包含了`init` 以及 `handle` 两个方法。在`init`方法中可以对爬虫的参数进行设置。例如 `self.start_targets = [\"https://github.blog/\"]` 设置了初始爬取目标。而 `handle(self, response: HTMLResponse)`  方法主要用于对服务器返回的内容进行处理。`response.bs` 表示一个由返回的网页构造的 [Beautiful Soup4](https://beautifulsoup.readthedocs.io/zh_CN/v4.4.0/) 对象，你可以用它来提取需要的内容。\n\n## 发现新链接\n\n`handle` 方法除了处理服务器返回的响应对象[Response](https://lin3x.coding.net/p/easy_spider/d/easy_spider/git/tree/function/easy_spider/network/response.py)以外，还有一个重要的功能则是发现新的链接。在 `easy_spider` 中，一个新的链接需要组装成一个请求对象 [Request](https://lin3x.coding.net/p/easy_spider/d/easy_spider/git/tree/function/easy_spider/network/request.py?tab=files) 。请求对象除了包含需要爬取的链接外，还包含爬取这个链接的参数或`Cookies`等内容，这些内容大部分具有默认值。一个跟随链接的示例为:\n\n``` python\nfrom easy_spider import async_env, AsyncSpider, Request, HTMLResponse\n\nclass MySpider(AsyncSpider):\n\n    def init(self):\n        self.start_targets = [\"https://github.blog/\"]\n        \n    def handle(self, response: HTMLResponse):\n        for a in response.bs.select(\"a\"):\n            if \"href\" in a.attrs:\n                yield Request.of(response.url_join(a.attrs[\"href\"]))\n```\n\n`response.url_join` 方法将网页中的相对链接变为绝对链接，例如从 `page/2` 变为 `https://github.blog/2`。`Request.of` 方法利用 `url` 创建具有默认参数的 `Request` 对象。`handle` 方法可以是一个生成器或者也可以直接返回可迭代 `Request` 对象集合。所有 `handle` 产生的新 `Request` 对象都将放入待请求队列中，逐个进行请求。当某个请求完成后，将继续调用 `handle` 方法进行处理。\n\n`easy_spider` 中已经实现了一个简单灵活的发现新链接的方法，你可以直接:\n\n``` python\nfrom easy_spider import async_env, AsyncSpider, Request, HTMLResponse\n\nclass MySpider(AsyncSpider):\n\n    def init(self):\n        self.start_targets = [\"https://github.blog/\"]\n        \n    def handle(self, response: HTMLResponse):\n        yield from super().handle(response)  # 默认发现新连接的方法\n```\n\n发现 `response` 中的所有链接。\n\n## 进阶使用\n\n### 使用过滤器\n\n在默认的情况下，除初始请求外的所有请求都将使用过滤器 [Filter](https://lin3x.coding.net/p/easy_spider/d/easy_spider/git/tree/function/easy_spider/filters/filter.py) 进行过滤。过滤器接收一个参数，并返回布尔值，表示接受或是拒绝这个参数。在定义 `spider` 对象时可以指定 `self.filter`，表示不被该 `filter` 接收的请求都不会放入请求队列中。例如:\n\n```python\nclass MySpider(AsyncSpider):\n\n    def init(self):\n        self.start_targets = [\"https://github.blog/\"]\n        self.filter = URLRegFilter(r\"^https://github\\.blog.+\")\n\n    def handle(self, response: HTMLResponse):\n        for a in response.bs.select(\"a\"):\n            if \"href\" in a.attrs:\n                yield Request.of(response.url_join(a.attrs[\"href\"]))\n```\n\n在 `handle` 方法中虽然提取了所有的 URL，但采用 `URLRegFilter` 对其进行了过滤。只有 `URL` 满足 `r\"^https://github\\.blog.+\"` 的请求会被放入队列，否则将被丢弃。在 `easy_spider` 中主要包含**普通过滤器** 以及**去重过滤器**两种类型的过滤器，普通过滤器有如下几种:\n\n- RegexFilter: 正则表达式过滤器\n- static_filter: 静态文件过滤器(避免爬取到 jpg|css 等类型文件)\n- url_filter: 合法 URL 过滤器\n- html_filter: 响应类型为 html 的 URL 过滤器(通过后缀判定，有一定的误判几率)\n- all_pass_filter: 全部接收过滤器\n- all_reject_filter: 全部拒绝过滤器\n- GenerationFilter: 拒绝深度大于某个值的请求\n\n过滤器支持某些运算符操作，例如 `static_filter` 虽然表示接受静态文件，但在如果 `-static_filter`  则变为拒绝静态文件。这里设有两个过滤器为`f1 f2`，则有:\n\n* `f1` + `f2`: `f1 f2` 同时接收则接受，否则拒绝\n* `f1` -`f2`： `f1` 接受同时 `f2` 拒绝则接受，否则拒绝\n* `f1` | `f2`： `f1` 接受或者 `f2` 拒绝则接受，否则拒绝\n* `-f1`: `f1` 拒绝则接受，否则拒绝\n\n所有的运算符支持多个过滤器级联使用。 `self.filter` 默认为 `html_filter`，实际上 `html_filter = url_filter - static_filter` ， 即提取接受所有具有合法URL[1]且不为静态文件的请求。\n\n`GenerationFilter` 并不对请求的 URL 进行检查，而是检查请求的深度(`Request.generation`)，每一个初始请求的深度为0，初始请求产生的请求深度为1，深度为1的请求产生的请求深度为2。`easy_spider` 爬取的方法为**广度优先**。\n\n去重过滤器还包含了 [BloomFilter](https://lin3x.coding.net/p/easy_spider/d/easy_spider/git/tree/function/easy_spider/filters/history_filter.py) 以及 [HashFilter](https://lin3x.coding.net/p/easy_spider/d/easy_spider/git/tree/function/easy_spider/filters/history_filter.py) 对已完成的请求进行过滤，即 `URL` 去重的功能。`easy_spider` 默认采用 `HashFilter` 进行去重，可以将 `self.crawled_filter` [2] 修改为 `BloomFilter` 以节约内存。\n\n1. 某些时候如  `<a href=\"javascript: callback\">click</a>` 提取的 `URL` 为 `javascript: callback` ，不是合法的URL 。\n2. 这里必须设置 `self.crawled_filter` 而不是使用 `self.filter`。这去重过滤器也无法和普通的过滤器进行运算，否则无法实现去重的功能。\n\n### 请求对象\n\n使用默认参数的 `Request` 对象能满足大部分的需求，但是 `Request` 也支持许多自定义的参数:\n\n```\nmethod: str = 请求方法 GET|POST|PUT|DELETE \ntimeout: int = 超时时间\nheaders: dict = 请求头，默认{}\ncookies: dict = cookies，默认{}\nencoding: str = 编码方式，默认utf-8\nparams: dict = URL参数，默认{}\ndata: dict = 数据，取决于 data_format\ndata_format: str = 数据格式 FORM|JSON，若为 FORM 数据通过 application/x-www-form-urlencoded 格式传递，若为 JSON 则通过 application/json。\nproxy: str = 代理，默认为空\nhandler: str = 处理该 Request 的回调函数\n```\n其中 `handler` 属性用于定义该请求完成时的回调处理函数。默认情况下，将采用 `Spider` 对象中的`handle` 方法。当然你也可以设置任何自己的方法进行处理。\n\n### 响应对象\n\n一个请求对象经由[AsyncClient](https://lin3x.coding.net/p/easy_spider/d/easy_spider/git/tree/function/easy_spider/network/client.py)[1]，发起请求后将返回一个响应对象，即在 handle 方法中处理的对象。`easy_spider` 默认根据 `content_type` 生成三种不同的响应对象，如果 `content_type` 包含`text/html` 则  [HtmlResponse](https://lin3x.coding.net/p/easy_spider/d/easy_spider/git/tree/function/easy_spider/network/response.py)，如果 `content_type` 包含除 `text/html` 以外的 `text/*` 对象，则返回[TextResponse](https://lin3x.coding.net/p/easy_spider/d/easy_spider/git/tree/function/easy_spider/network/response.py)，否则返回[Response](https://lin3x.coding.net/p/easy_spider/d/easy_spider/git/tree/function/easy_spider/network/response.py)。其中不同的响应对象有不同的属性，从 `Response -> TextResponse -> HtmlResponse` 逐渐增多。\n\n`Response` 对象具有的属性:\n\n* headers: HTTP 响应头\n\n* body: HTTP 响应体，为未解码的 bytes 类型\n* url: 响应对象的 `URL`\n* request: 产生该响应对应的请求\n\n`TextResponse` 在 `Response` 基础上增加了:\n\n* text: 解码后的文本内容，`TextResponse` 会自动猜测 `body` 的编码类型进行解码，尽量避免乱码产生\n\n`HtmlResponse`  在 `TextResponse` 基础上增加了:\n\n* bs:  利用 text 属性构建的 [Beautiful Soup4](https://beautifulsoup.readthedocs.io/zh_CN/v4.4.0/) 对象\n\n### 默认请求参数\n\n很多时候需要定义一系列默认参数，而不是在每个请求中都声明，在 `easy_spider` 中所有定义在 `spider` 中与请求对象相同的属性都将复制给每一个新产生的请求，包括初始请求:\n\n```python\nclass MySpider(AsyncSpider):\n\n    def init(self):\n        self.start_targets = [\"https://github.blog/\"]\n        self.cookies = {\"key\": \"value\"}  # 用于设置默认请求参数\n\n    def handle(self, response: HTMLResponse):\n        urls = [response.url_join(a.attrs[\"href\"]) for a in response.bs.select(\"a\")]\n        yield self.from_url(urls)  # 所有请求的 cookies 都将设置与 self.cookies 相同\n```\n\n### 自定义处理方法\n\n可以通过设置请求对象的 `handler` 属性来设置处理该请求返回的响应:\n```python\nfrom easy_spider import async_env, AsyncSpider, Request, HTMLResponse\n\nclass MySpider(AsyncSpider):\n\n    def init(self):\n        self.cookies = {\"key\": \"value\"}  # 用于设置默认请求参数\n        self.start_targets = [\"https://github.blog/\"]\n\n    def handle(self, response: HTMLResponse):\n        urls = [response.url_join(a.attrs[\"href\"]) for a in response.bs.select(\"a\")]\n        for url in urls:\n            if url.endswith(\"xxx\"):\n                yield Request(url, handler=self.handle_other)  # 该请求返回的 response 将由 handle_other 方法处理\n            else:\n                yield Request(url, handler=self.handle)\n\n    def handle_other(self, response):\n        # do something\n        pass\n\nasync_env.run(MySpider())\n```\n\n### 请求中间件\n\n在 `easy_spider` 中，所有的请求都将经过请求中间件的处理。请求中间件是一系列对请求进行变换的类，其都继承于[RequestMiddleware](https://lin3x.coding.net/p/easy_spider/d/easy_spider/git/tree/function/easy_spider/middlewares/build_in.py)，其定义如下:\n\n``` python\nclass RequestMiddleware(ABC):\n\n    @abstractmethod\n    def transform(self, requests: Iterable[Request], response: Optional[Response]) -> Iterable[Request]: pass\n```\n\n其核心方法`transform`接受一个可迭代的请求集合，以及产生这些请求的 `Response` 对象如果为初始请求，则 `Response` 对象为 `None`。`transform`根据这些参数产生新的可迭代的请求集合。\n\n`easy_spider` 许多功能都通过中间件实现，如`过滤器`、`去重过滤器` 以及 `默认参数`。例如`ExtractorFilterMiddleware(self.filter)`  接受 `self.filter `为参数，将所有 `self.filter ` 拒绝的请求从输入的请求集合中除去。 默认采用了以下中间件:\n\n```python\n    def middlewares(self):\n        return ChainMiddleware(GenerationMiddleware(),  # 设置请求为第 n 代，支持GenerationFilter 过滤器\n                               ExtractorFilterMiddleware(self.filter),  # 用于支持过滤器\n                               FilterMiddleware(self.crawled_filter),  # 支持去重过滤器\n                               SetAttrMiddleware(self))  # 用于设置请求默认参数\n```\n\n其中 `ChainMiddleware` 用于将多个中间件合并为一个中间件进行执行[1]。用于可以编写自己的请求中间并重写`spider` 对象的`middlewares` 方法以扩展 `easy_spider` 的功能。例如某些时候需要将初始爬取目标保存在文件中，使用时读取:\n\n```python\nfrom typing import Iterable, Optional\nfrom easy_spider import async_env, AsyncSpider, Request, HTMLResponse, Response\nfrom easy_spider.middlewares.build_in import RequestMiddleware, ChainMiddleware\nfrom easy_spider.tool import get_abs_path\nfrom easy_spider import GenerationFilter\nfrom os.path import join\n\nclass LoadFileMiddleware(RequestMiddleware):\n    def transform(self, requests: Iterable[Request], response: Optional[Response]) -> Iterable[Request]:\n        if not response:  # 如果为初始请求，则从文件中构造请求\n            url = list(requests)[0].url\n            with open(join(get_abs_path(__file__), url), encoding='utf-8') as fd:\n                for line in fd.readlines():\n                    yield Request.of(line.strip(\"\\n\"))\n        else:  # 否则不做任何事情\n            yield from requests\n\nclass MySpider(AsyncSpider):\n\n    def init(self):\n        self.start_targets = [\"urls.txt\"]\n\n    def handle(self, response: HTMLResponse):\n        titles = response.bs.select(\".post-list__item a\")\n        print([title.text for title in titles])\n\n    def middlewares(self):\n        return ChainMiddleware(LoadFileMiddleware()).extend(super().middlewares())\n\nasync_env.run(MySpider())\n```\n\n其中，`middlewares` 中采用 `ChainMiddleware(LoadFileMiddleware()).extend(super().middlewares())`  将新的中间件以及默认的中间件结合在一起[2]，形成新的中间件并返回。\n\n1. `ChainMiddleware` 将所有中间件按照传入的顺序进行执行\n2. 如果你不是十分了解默认中间件执行的功能以及去掉它所产生的影响，建议在自定义中间件时一定要保留默认中间件，并使得自定义中间件在默认中间件前执行。\n\n### 恢复爬虫\n\n`easy_spider` 实现了两种可恢复的爬虫，一种是当用户主动结束爬虫，一种是被意外关闭的爬虫。对于第一种，`easy_spider` 捕获了`ctrl + c`，当你按下`ctrl + c` 时会进行一系列询问，你可以选择是否保存你的爬虫[1]。如果第二次运行该爬虫，如果检测已到保存的记录，会询问你是否继续。对于第二种，`easy_spider`提供了自动保存的功能。\n\n你可以继承[RecoverableSpider](https://lin3x.coding.net/p/easy_spider/d/easy_spider/git/tree/function/easy_spider/core/spider.py)来实现可恢复的爬虫。该爬虫对象与 `AsyncSpider` 使用方法相同，只是多了需要设置的参数:\n\n* name: 爬虫的名称\n* auto_save_frequence: 自动保存频率\n\n`name` 将决定爬虫保存的路径，而 `auto_save_frequence` 将决定爬虫自动保存的频率。`auto_save_frequence = 1000` 表示每进行 `1000` 请求则保存一次爬虫。`auto_save_frequence = 0` 则不进行自动保存。\n\n1.  爬虫保存的内存包括 `已爬取的请求` 以及 `为爬取的请求` 两大部分，其中保存的文件位置为`代码执行目录/.easy_spider/{name}` 其中 `{name}` 爬虫的属性 `self.name`。\n\n### 请求溢出\n\n请求溢出是指当请求达到一定数量时将请求溢出到磁盘中已节约内存，`easy_spider` 默认已经开启了此功能，可以设置 `self.num_of_spill = 0`  来关闭。同样 `self.num_of_spill ` 也指定了溢出的门限值，即若请求达到 `self.num_of_spill * 2` 则将其中的  `self.num_of_spill` 请求溢出到磁盘中。详细的溢出逻辑请参考[SpillRequestQueueProxy](https://lin3x.coding.net/p/easy_spider/d/easy_spider/git/tree/function/easy_spider/core/queue.py)。",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://lin3x.coding.net/p/easy_spider",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "easy-spider",
    "package_url": "https://pypi.org/project/easy-spider/",
    "platform": "",
    "project_url": "https://pypi.org/project/easy-spider/",
    "project_urls": {
      "Homepage": "https://lin3x.coding.net/p/easy_spider"
    },
    "release_url": "https://pypi.org/project/easy-spider/1.1.2/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "A asynchronous spider with aiohttp",
    "version": "1.1.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 6926019,
  "releases": {
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d0b7188cfd43a00d0662228f418d9fa88b4ebf97de229de42b0bb68390e2cf2b",
          "md5": "7d6e774c3e38697777b48036f2e40f0e",
          "sha256": "62dfc81938500a2cb067aa1f0e24b30f55f056ec24ca6d3702b414bb5ca9841d"
        },
        "downloads": -1,
        "filename": "easy-spider-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "7d6e774c3e38697777b48036f2e40f0e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 6511,
        "upload_time": "2020-03-16T14:51:27",
        "upload_time_iso_8601": "2020-03-16T14:51:27.509021Z",
        "url": "https://files.pythonhosted.org/packages/d0/b7/188cfd43a00d0662228f418d9fa88b4ebf97de229de42b0bb68390e2cf2b/easy-spider-1.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "348736fd49c47fb60bec22a05fb73fb909cb05d3602045f857f306aee226901f",
          "md5": "0ef048b347ed00651b8e9b0cdf962c3f",
          "sha256": "0d1f2cc311ab6e3334f669867265031a31dea5c47030775c74126b6069510084"
        },
        "downloads": -1,
        "filename": "easy-spider-1.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "0ef048b347ed00651b8e9b0cdf962c3f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 7078,
        "upload_time": "2020-03-16T15:06:51",
        "upload_time_iso_8601": "2020-03-16T15:06:51.081545Z",
        "url": "https://files.pythonhosted.org/packages/34/87/36fd49c47fb60bec22a05fb73fb909cb05d3602045f857f306aee226901f/easy-spider-1.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.10": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "71f0c4a424b6c7bd5e7dcb6e2f8d58c3f6a4b77c6994b3ebed4cc06ab308ba40",
          "md5": "255375726638f4750d60820081b79e04",
          "sha256": "fd58e8ca008cdc85017d30b34363e5255cd772c3af357593de0b15ca55dbabc7"
        },
        "downloads": -1,
        "filename": "easy-spider-1.0.10.tar.gz",
        "has_sig": false,
        "md5_digest": "255375726638f4750d60820081b79e04",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 15014,
        "upload_time": "2020-03-21T02:06:08",
        "upload_time_iso_8601": "2020-03-21T02:06:08.606523Z",
        "url": "https://files.pythonhosted.org/packages/71/f0/c4a424b6c7bd5e7dcb6e2f8d58c3f6a4b77c6994b3ebed4cc06ab308ba40/easy-spider-1.0.10.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.11": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9b85806d1dbfccf862bfe95300256ad67c66e58581112f1b7481c9c4faa5bbf8",
          "md5": "73f3a26f32786641f6104ceb6943317d",
          "sha256": "dfb2d096a65805975c3c2da6245a7a7719e1cc2842a6eac9e7b4f184ddf486ea"
        },
        "downloads": -1,
        "filename": "easy-spider-1.0.11.tar.gz",
        "has_sig": false,
        "md5_digest": "73f3a26f32786641f6104ceb6943317d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 17805,
        "upload_time": "2020-03-23T01:48:25",
        "upload_time_iso_8601": "2020-03-23T01:48:25.579472Z",
        "url": "https://files.pythonhosted.org/packages/9b/85/806d1dbfccf862bfe95300256ad67c66e58581112f1b7481c9c4faa5bbf8/easy-spider-1.0.11.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.12": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f27a5b94389d5ffe0a4eba2e44454bd5de8367043bca4a5963aca6fd936bc269",
          "md5": "8f2997abd6961de2fa1844ea424085d0",
          "sha256": "0e15def3fb78edee99af41fdf6402015be4f6d20e33c32425295db0a5cb0d113"
        },
        "downloads": -1,
        "filename": "easy-spider-1.0.12.tar.gz",
        "has_sig": false,
        "md5_digest": "8f2997abd6961de2fa1844ea424085d0",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 19447,
        "upload_time": "2020-03-24T12:55:35",
        "upload_time_iso_8601": "2020-03-24T12:55:35.177200Z",
        "url": "https://files.pythonhosted.org/packages/f2/7a/5b94389d5ffe0a4eba2e44454bd5de8367043bca4a5963aca6fd936bc269/easy-spider-1.0.12.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.13": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5ff8f3b7e74d3ae2f1f9541ca468585538efcba891e14758c7db32dd8c026ace",
          "md5": "5020d8edd3bd63d12cb0d988c672a878",
          "sha256": "e04c1004b0b5fb59047049d67d81886ee6b06bf964b394f00870041ef0d377e5"
        },
        "downloads": -1,
        "filename": "easy-spider-1.0.13.tar.gz",
        "has_sig": false,
        "md5_digest": "5020d8edd3bd63d12cb0d988c672a878",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 20507,
        "upload_time": "2020-03-27T06:26:00",
        "upload_time_iso_8601": "2020-03-27T06:26:00.931265Z",
        "url": "https://files.pythonhosted.org/packages/5f/f8/f3b7e74d3ae2f1f9541ca468585538efcba891e14758c7db32dd8c026ace/easy-spider-1.0.13.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.14": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "828c6b4411ee6afc57b7472b04c8b9959e57ad9862dd470f630040d91decbef5",
          "md5": "54867f8b25b984d02ba1258d6bf18f00",
          "sha256": "f5e651f0275f256d5706177493a39ebd0ee623979680523a69ca1497651047e4"
        },
        "downloads": -1,
        "filename": "easy-spider-1.0.14.tar.gz",
        "has_sig": false,
        "md5_digest": "54867f8b25b984d02ba1258d6bf18f00",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 24080,
        "upload_time": "2020-04-01T07:53:28",
        "upload_time_iso_8601": "2020-04-01T07:53:28.240978Z",
        "url": "https://files.pythonhosted.org/packages/82/8c/6b4411ee6afc57b7472b04c8b9959e57ad9862dd470f630040d91decbef5/easy-spider-1.0.14.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9007f4e0ddab3a7b765d8f7a6d9650290bdfad0b063f71a01f1f498faf17ed02",
          "md5": "cf3c7baabb85c1f49a6890705d38b33d",
          "sha256": "1a280ce2a01784d930be8d73a103c1400572bbc06c355d55f10472f8bdf0b689"
        },
        "downloads": -1,
        "filename": "easy-spider-1.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "cf3c7baabb85c1f49a6890705d38b33d",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 12372,
        "upload_time": "2020-03-16T15:18:21",
        "upload_time_iso_8601": "2020-03-16T15:18:21.759086Z",
        "url": "https://files.pythonhosted.org/packages/90/07/f4e0ddab3a7b765d8f7a6d9650290bdfad0b063f71a01f1f498faf17ed02/easy-spider-1.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c6efd08dfb53b6ab7b6d393c290b6f369c6e4847561e4098d024e8f220c69b3e",
          "md5": "b78b686bbbdbe32335410d7d904adf8e",
          "sha256": "b341509de29745cc142600039b939d88022f414660da6576d95fce8619517792"
        },
        "downloads": -1,
        "filename": "easy-spider-1.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "b78b686bbbdbe32335410d7d904adf8e",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 12885,
        "upload_time": "2020-03-17T08:35:55",
        "upload_time_iso_8601": "2020-03-17T08:35:55.167462Z",
        "url": "https://files.pythonhosted.org/packages/c6/ef/d08dfb53b6ab7b6d393c290b6f369c6e4847561e4098d024e8f220c69b3e/easy-spider-1.0.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f2763017b9eaf1dcb4d39ada87cc3f11333ec580609491d74ee2d8a1e5208aa8",
          "md5": "fa8f807fd0ba18f2cf5e1ded720a7b04",
          "sha256": "c8874228a6c930c70f746815b9565f2fba52e2fb57323ffd0cc723a3e0f2f291"
        },
        "downloads": -1,
        "filename": "easy-spider-1.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "fa8f807fd0ba18f2cf5e1ded720a7b04",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 13040,
        "upload_time": "2020-03-17T13:15:20",
        "upload_time_iso_8601": "2020-03-17T13:15:20.114953Z",
        "url": "https://files.pythonhosted.org/packages/f2/76/3017b9eaf1dcb4d39ada87cc3f11333ec580609491d74ee2d8a1e5208aa8/easy-spider-1.0.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "74db100dd711fac9c1b8f392d415050030297d4ff6ee13f1b385657f0d7077a2",
          "md5": "2dac740b2b13e116252137506e21d253",
          "sha256": "56dce71a99b6c83279ede4fb3178f7db2ad1183c673a0087edb6ecbc6c9a6192"
        },
        "downloads": -1,
        "filename": "easy-spider-1.0.5.tar.gz",
        "has_sig": false,
        "md5_digest": "2dac740b2b13e116252137506e21d253",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 13036,
        "upload_time": "2020-03-18T02:41:16",
        "upload_time_iso_8601": "2020-03-18T02:41:16.598735Z",
        "url": "https://files.pythonhosted.org/packages/74/db/100dd711fac9c1b8f392d415050030297d4ff6ee13f1b385657f0d7077a2/easy-spider-1.0.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c87229dac7c64cbdd897fef63dda0e1c3cb7286b0afe1e9a9beb1a5daf69adef",
          "md5": "cbaca0b784428a446b4aeacf9336320f",
          "sha256": "26a8bfb82e21b9718fb16d1dcdfe4afbb35f8d9bb919bc1c246a0b38882c8f7e"
        },
        "downloads": -1,
        "filename": "easy-spider-1.0.6.tar.gz",
        "has_sig": false,
        "md5_digest": "cbaca0b784428a446b4aeacf9336320f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 12721,
        "upload_time": "2020-03-18T06:41:46",
        "upload_time_iso_8601": "2020-03-18T06:41:46.254184Z",
        "url": "https://files.pythonhosted.org/packages/c8/72/29dac7c64cbdd897fef63dda0e1c3cb7286b0afe1e9a9beb1a5daf69adef/easy-spider-1.0.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fb6f98d8df61d87610f28877f73e7aafc291c4e6606f09407c5ca56f35344f84",
          "md5": "f56eff83176349906438525c89404448",
          "sha256": "2b2b76de4391b26aefb753a79af3f9c1710342b1c4a1b7b414b2a73be0db0f6b"
        },
        "downloads": -1,
        "filename": "easy-spider-1.0.7.tar.gz",
        "has_sig": false,
        "md5_digest": "f56eff83176349906438525c89404448",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 13543,
        "upload_time": "2020-03-18T12:58:37",
        "upload_time_iso_8601": "2020-03-18T12:58:37.993534Z",
        "url": "https://files.pythonhosted.org/packages/fb/6f/98d8df61d87610f28877f73e7aafc291c4e6606f09407c5ca56f35344f84/easy-spider-1.0.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d90ea59747b34dbcb30c6cf728e5fa03833aed2dac628e8d32c90492545612c3",
          "md5": "9ca662afd2e002f323f0d829891a791f",
          "sha256": "3ba64e5fcb2074bd5e6513de6df96d6577ee0cda4fb671cc5a6c97feec218157"
        },
        "downloads": -1,
        "filename": "easy-spider-1.0.8.tar.gz",
        "has_sig": false,
        "md5_digest": "9ca662afd2e002f323f0d829891a791f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 13535,
        "upload_time": "2020-03-18T13:14:19",
        "upload_time_iso_8601": "2020-03-18T13:14:19.917488Z",
        "url": "https://files.pythonhosted.org/packages/d9/0e/a59747b34dbcb30c6cf728e5fa03833aed2dac628e8d32c90492545612c3/easy-spider-1.0.8.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.9": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "eabef65c7d96c3da1ec69dbf52fa9bba8361633281fd73435cd68834888cd0f6",
          "md5": "c1d7ea2876598cd82330e3dc5b7ddd55",
          "sha256": "d3083bd6272d7762aff8689fc4e94baef2a43dfb50bbfda1efc947497a955a5a"
        },
        "downloads": -1,
        "filename": "easy-spider-1.0.9.tar.gz",
        "has_sig": false,
        "md5_digest": "c1d7ea2876598cd82330e3dc5b7ddd55",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 13646,
        "upload_time": "2020-03-19T03:17:06",
        "upload_time_iso_8601": "2020-03-19T03:17:06.047355Z",
        "url": "https://files.pythonhosted.org/packages/ea/be/f65c7d96c3da1ec69dbf52fa9bba8361633281fd73435cd68834888cd0f6/easy-spider-1.0.9.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6fa1c2ef28f012d461774a81bf1f850913b2984b771e12088c9d07ba1fc99bf7",
          "md5": "ab04d91625d566c9277bb38e07c94e69",
          "sha256": "a973dfb793445fe4ca4089512b1d27d00f631a3806a9862de12f5da83c734850"
        },
        "downloads": -1,
        "filename": "easy-spider-1.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "ab04d91625d566c9277bb38e07c94e69",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 24091,
        "upload_time": "2020-04-01T08:19:02",
        "upload_time_iso_8601": "2020-04-01T08:19:02.860247Z",
        "url": "https://files.pythonhosted.org/packages/6f/a1/c2ef28f012d461774a81bf1f850913b2984b771e12088c9d07ba1fc99bf7/easy-spider-1.1.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "6fa1c2ef28f012d461774a81bf1f850913b2984b771e12088c9d07ba1fc99bf7",
        "md5": "ab04d91625d566c9277bb38e07c94e69",
        "sha256": "a973dfb793445fe4ca4089512b1d27d00f631a3806a9862de12f5da83c734850"
      },
      "downloads": -1,
      "filename": "easy-spider-1.1.2.tar.gz",
      "has_sig": false,
      "md5_digest": "ab04d91625d566c9277bb38e07c94e69",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 24091,
      "upload_time": "2020-04-01T08:19:02",
      "upload_time_iso_8601": "2020-04-01T08:19:02.860247Z",
      "url": "https://files.pythonhosted.org/packages/6f/a1/c2ef28f012d461774a81bf1f850913b2984b771e12088c9d07ba1fc99bf7/easy-spider-1.1.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}