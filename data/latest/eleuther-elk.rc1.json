{
  "info": {
    "author": "",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "## Introduction\n\n**WIP: This codebase is under active development**\n\nBecause language models are trained to predict the next token in naturally occurring text, they often reproduce common human errors and misconceptions, even when they \"know better\" in some sense. More worryingly, when models are trained to generate text that's rated highly by humans, they may learn to output false statements that human evaluators can't detect. We aim to circumvent this issue by directly [**eliciting latent knowledge**](https://docs.google.com/document/d/1WwsnJQstPq91_Yh-Ch2XRL8H_EpsnjrC1dwZXR37PC8/edit) (ELK) inside the activations of a language model.\n\nSpecifically, we're building on the **Contrast Consistent Search** (CCS) method described in the paper [Discovering Latent Knowledge in Language Models Without Supervision](https://arxiv.org/abs/2212.03827) by Burns et al. (2022). In CCS, we search for features in the hidden states of a language model which satisfy certain logical consistency requirements. It turns out that these features are often useful for question-answering and text classification tasks, even though the features are trained without labels.\n\n### Quick **Start**\n\nOur code is based on [PyTorch](http://pytorch.org) and [Huggingface Transformers](https://huggingface.co/docs/transformers/index). We test the code on Python 3.9 and 3.10.\n\nFirst install the package with `pip install -e .` in the root directory, or `pip install -e .[dev]` if you'd like to contribute to the project (see **Development** section below). This should install all the necessary dependencies.\n\nTo fit reporters for the HuggingFace model `model` and dataset `dataset`, just run:\n\n```bash\nelk elicit microsoft/deberta-v2-xxlarge-mnli imdb\n```\n\nThis will automatically download the model and dataset, run the model and extract the relevant representations if they aren't cached on disk, fit reporters on them, and save the reporter checkpoints to the `elk-reporters` folder in your home directory. It will also evaluate the reporter classification performance on a held out test set and save it to a CSV file in the same folder.\n\n## Caching\n\nThe hidden states resulting from `elk elicit` are cached as a HuggingFace dataset to avoid having to recompute them every time we want to train a probe. The cache is stored in the same place as all other HuggingFace datasets, which is usually `~/.cache/huggingface/datasets`.\n\n## Other commands\n\nTo only extract the hidden states for the model `model` and the dataset `dataset` and save them to `my_output_dir`, without training any reporters, you can run:\n\n```bash\nelk extract microsoft/deberta-v2-xxlarge-mnli imdb -o my_output_dir\n```\n\n## Development\nTo clone the repo and its submodules\n```bash\ngit clone --recurse-submodules https://github.com/EleutherAI/elk.git\n```\nIf you already cloned the repo but are missing the promptsource_module submodule, run\n```bash\ngit submodule update --init --recursive\n```\n\n\nUse `pip install pre-commit && pre-commit install` in the root folder before your first commit.\n\n### Run tests\n```bash\npytest\n```\n### Run type checking\nWe use [pyright](https://github.com/microsoft/pyright), which is built into the VSCode editor. If you'd like to run it as a standalone tool, it requires a [nodejs installation.](https://nodejs.org/en/download/)\n```bash\npyright\n```\n\nIf you work on a new feature / fix or some other code task, make sure to create an issue and assign it to yourself (Maybe, even share it in the elk channel of Eleuther's Discord with a small note). In this way, others know you are working on the issue and people won't do the same thing twice ðŸ‘ Also others can contact you easily.\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "nlp,interpretability,language-models,explainable-ai",
    "license": "MIT License",
    "maintainer": "",
    "maintainer_email": "",
    "name": "eleuther-elk",
    "package_url": "https://pypi.org/project/eleuther-elk/",
    "platform": null,
    "project_url": "https://pypi.org/project/eleuther-elk/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/eleuther-elk/0.1/",
    "requires_dist": [
      "datasets (>=2.5.0)",
      "einops",
      "numpy (>=1.20.0)",
      "prettytable (>=3.5.0)",
      "protobuf (==3.20.*)",
      "pynvml",
      "scikit-learn (>=1.0.0)",
      "sentencepiece (==0.1.97)",
      "simple-parsing (>=0.0.21)",
      "torch (>=1.11.0)",
      "tqdm (>=4.0.0)",
      "transformers (>=4.0.0)",
      "jinja2",
      "hypothesis ; extra == 'dev'",
      "pre-commit ; extra == 'dev'",
      "pytest ; extra == 'dev'",
      "pyright ; extra == 'dev'"
    ],
    "requires_python": ">=3.9",
    "summary": "Keeping language models honest by directly eliciting knowledge encoded in their activations",
    "version": "0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17153323,
  "releases": {
    "0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "83ab44727c8d51751c35bfc02b877048fccfe5890d84da214f5993616eb95235",
          "md5": "9732bb32cd40ac605b9104be25d842f2",
          "sha256": "b7a038579408b573a47cfeb64db6fecd7be1a4f8700be70cc9c9ae342f8b0604"
        },
        "downloads": -1,
        "filename": "eleuther_elk-0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "9732bb32cd40ac605b9104be25d842f2",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.9",
        "size": 28678,
        "upload_time": "2023-03-04T04:55:45",
        "upload_time_iso_8601": "2023-03-04T04:55:45.899573Z",
        "url": "https://files.pythonhosted.org/packages/83/ab/44727c8d51751c35bfc02b877048fccfe5890d84da214f5993616eb95235/eleuther_elk-0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d8a848ff0208c1164705f61cecd41a0e3727e310ae81cb1bd3050eb469e9fd16",
          "md5": "51ab87c1c2932f4cafb2313143734db0",
          "sha256": "640fbd25cbdb1eb7d27fb48adfd762a4f5c89dbe5c32c3c787685443d0429c0b"
        },
        "downloads": -1,
        "filename": "eleuther-elk-0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "51ab87c1c2932f4cafb2313143734db0",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.9",
        "size": 24799,
        "upload_time": "2023-03-04T04:55:47",
        "upload_time_iso_8601": "2023-03-04T04:55:47.646146Z",
        "url": "https://files.pythonhosted.org/packages/d8/a8/48ff0208c1164705f61cecd41a0e3727e310ae81cb1bd3050eb469e9fd16/eleuther-elk-0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "83ab44727c8d51751c35bfc02b877048fccfe5890d84da214f5993616eb95235",
        "md5": "9732bb32cd40ac605b9104be25d842f2",
        "sha256": "b7a038579408b573a47cfeb64db6fecd7be1a4f8700be70cc9c9ae342f8b0604"
      },
      "downloads": -1,
      "filename": "eleuther_elk-0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "9732bb32cd40ac605b9104be25d842f2",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.9",
      "size": 28678,
      "upload_time": "2023-03-04T04:55:45",
      "upload_time_iso_8601": "2023-03-04T04:55:45.899573Z",
      "url": "https://files.pythonhosted.org/packages/83/ab/44727c8d51751c35bfc02b877048fccfe5890d84da214f5993616eb95235/eleuther_elk-0.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "d8a848ff0208c1164705f61cecd41a0e3727e310ae81cb1bd3050eb469e9fd16",
        "md5": "51ab87c1c2932f4cafb2313143734db0",
        "sha256": "640fbd25cbdb1eb7d27fb48adfd762a4f5c89dbe5c32c3c787685443d0429c0b"
      },
      "downloads": -1,
      "filename": "eleuther-elk-0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "51ab87c1c2932f4cafb2313143734db0",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.9",
      "size": 24799,
      "upload_time": "2023-03-04T04:55:47",
      "upload_time_iso_8601": "2023-03-04T04:55:47.646146Z",
      "url": "https://files.pythonhosted.org/packages/d8/a8/48ff0208c1164705f61cecd41a0e3727e310ae81cb1bd3050eb469e9fd16/eleuther-elk-0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}