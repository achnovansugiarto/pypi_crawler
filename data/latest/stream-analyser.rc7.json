{
  "info": {
    "author": "emso-c",
    "author_email": "emsoc192@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Environment :: Console",
      "Intended Audience :: Developers",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: GNU General Public License v3 (GPLv3)",
      "Natural Language :: English",
      "Operating System :: Microsoft :: Windows :: Windows 10",
      "Operating System :: POSIX :: Linux",
      "Programming Language :: Python",
      "Topic :: Scientific/Engineering",
      "Topic :: Scientific/Engineering :: Information Analysis"
    ],
    "description": "# **Stream Analyser**\n\n### Stream Analyser is a configurable data analysis tool that analyses live streams, detects and classifies highlights based on their intensity, finds keywords, and even guesses contexts.\n\n<br>\n\nAlso can be expanded to other live stream platforms such as Twitch if there's enough demand or support.\n\n\n**Currently in Development.**\n\n## Table of contents\n- [Installation](#Installation)\n- [Basic usage](#Usage)\n  - [CLI](#with-CLI)\n- [Key Features](#Key-features)\n- [How does it detect highlights](#About-detecting-highlights)\n- [How does it guess contexts](#About-guessing-contexts)\n- [Performance](#About-performance)\n- [Advanced usage](#Advanced-usage)\n    - [1. Fundamentals](#1.-Fundamentals)\n      - [Initializing](##initializing-the-object)\n      - [analyse() function](#analyse-function)\n    - [2. File handling](#2.-File-handling)\n      - [Caching](#Caching-1)\n      - [Logging](#Logging)\n      - [Exporting](#Exporting)\n      - [CRUD](#CRUD)\n      - [Compressing](#Compressing)\n      - [Integrity checking](#Integrity-checking)\n    - [3. Logging](#3.-Logging-1)\n    - [4. Collecting data](#4.-Collecting-data)\n    - [5. Refining data](#5.-Refining-data)\n    - [6. Analysing data](#6.-Analysing-data)\n    - [7. Output](#7.-Output)\n      - [Direct](#Direct)\n      - [With prebuilt functions](#With-prebuilt-functions)\n    - [8. Custom context](#Custom-context)\n- [Testing](#Testing)\n- [Possible issues](#Possible-issues)\n- [Future goals](#Future-goals)\n- [Support](#Support)\n- [License](#License)\n\n# Installation\n\nUse [pip](https://pip.pypa.io/en/stable/) to install.\n```bash\npip install stream-analyser\n```\n\n# Usage\n\n```python\nfrom streamanalyser import StreamAnalyser\n\nif __name__ == '__main__':\n    with StreamAnalyser(\"gV2HOEE5DfQ\") as analyser:\n        analyser.analyse()\n        analyser.get_highlights(top=10, output_mode=\"detailed\")\n        analyser.get_highlights(top=10, output_mode=\"url\")\n```\n\nConsole output:\n```bash\nHighlights:\n[1:08:33] funny: 草 (806 messages, ultra high intensity, 2.182 diff, 94s duration)\n[0:11:47] funny: 草, yes my, いえちゅ まい だぁぁぁく (360 messages, ultra high intensity, 2.084 diff, 42s duration)\n[0:28:56] funny: 草, en ]:, my horns (322 messages, ultra high intensity, 2.044 diff, 42s duration)\n[0:23:54] None: ymd ymd ymd ymd, bgm is, yes my, love your voice (287 messages, very high intensity, 1.723 diff, 38s duration)\n[0:32:20] funny: 草, the crow is, yes my dark (352 messages, very high intensity, 1.721 diff, 46s duration)\n[0:14:31] cute: かわいい (297 messages, very high intensity, 1.436 diff, 36s duration)\n[0:40:15] None: yes my dark, yagoo my daddy, yes my baby, ill be back (620 messages, very high intensity, 1.427 diff, 82s duration)\n[0:19:47] cute: yes my, ymd, cute yamada (251 messages, very high intensity, 1.376 diff, 31s duration)\n[0:25:10] funny: 草, play apex (378 messages, very high intensity, 1.363 diff, 50s duration)\n[0:13:12] None: カラス, yes my dog (372 messages, very high intensity, 1.320 diff, 46s duration)\n\nLinks:\n1:08:33 -> https://youtu.be/gV2HOEE5DfQ?t=4113\n0:11:47 -> https://youtu.be/gV2HOEE5DfQ?t=707\n0:28:56 -> https://youtu.be/gV2HOEE5DfQ?t=1736\n0:23:54 -> https://youtu.be/gV2HOEE5DfQ?t=1434\n0:32:20 -> https://youtu.be/gV2HOEE5DfQ?t=1940\n0:14:31 -> https://youtu.be/gV2HOEE5DfQ?t=871\n0:40:15 -> https://youtu.be/gV2HOEE5DfQ?t=2415\n0:19:47 -> https://youtu.be/gV2HOEE5DfQ?t=1187\n0:25:10 -> https://youtu.be/gV2HOEE5DfQ?t=1510\n0:13:12 -> https://youtu.be/gV2HOEE5DfQ?t=792\n```\n\n**Important:** Please see [possible issues](#Possible-issues) if you can't see Japanese characters in console.\n\n## with CLI\nYou can also use a simple pre-built CLI \n\n```bash\n> streamanalyser --help\n```\nor\n```python\nfrom streamanalyser.modules import cli\n\nif __name__ == '__main__':\n    cli.main()\n```\n\nSee \"/path/to/package/examples\" for more ways to use the module.\n\n# Key features\n\n- Fetch metadata of the stream\n  - title, channel name, url etc.\n- Fetch live chat of the stream\n- Detect highlights\n- Guess contexts\n- Show and filter highlights\n  - Summary\n  - Detailed\n  - URL\n  - Open in browser\n- Find and filter messages\n- Find and filter authors\n- Find messages made by an author\n- Visualize data\n  - Graph\n  - Word cloud\n- Export data\n\n# About detecting highlights\n\nStream analyser uses live chat reactions to detect highlights and it's accuracy is totally dependant on the participants and the accuracy of the data fetched from YouTube.\n\n# About guessing contexts\n\nDefault contexts are hard-coded into the `path/to/package/data/default_contexts.json` file and can be modified according to requirements, which is explained thoroughly in [custom contexts](#Custom-contexts) section.\n\n# About performance\n\nStream analyser is optimized to be as fast as possible while minimizing required storage space.\n\n## **Caching**\n\nStream analyser uses a disk caching mechanism to store useful data such as messages and metadata which would significantly hinder the performance if not cached.\n\n## **Compressing**\n\nStored messages are compressed right after being fetched and they're only unpacked when needed since they would take up quite a lot of space if not compressed.\n\n## **Exporting**\n\nOther data generated on the run such as graph, word cloud and detected highlights can be exported using `export_data` function.\n\n# **Advanced usage**\n\n# 1. Fundamentals\n\nStream analyser is divided into sub-modules that handles various parts of the job. To briefly explain each one of them:\n\n- `datacollector`: Collects required data.\n- `datarefiner`: Refines collected raw data to be analysed.\n- `chatanalyser`: Analyses the refined data.\n- `keyphrase_finder`: Finds keyphrases using NLP.\n- `filehandler`: Handles almost everything related to files. Including reading, writing, updating and deleting cached files, logs and exports.\n- `structures`: Stores vital data models.\n- `utils`: Includes various functions that does small jobs.\n\n## Initializing the object\n\nThe only required parameter is the id of the stream url. The instance can be initalized as a context manager with the `with` keyword, which is **recommended**:\n```python\nanalyser_object = StreamAnalyser(\"l8Hgi4jF7Zc\")\n```\nor\n```python\nwith StreamAnalyser(\"l8Hgi4jF7Zc\") as sa:\n    ...\n```\n\nThe other parameters provide ways to configure methods of analysing, caching, logging and outputting. Full docs can be found in the module. Some of the important ones are:\n- `storage_path`: Path to store project related files such as logs and caches.\n- `cache_limit`: Max file amount to cache.\n- `cache_deletion_algorithm`: In which order the cached files will be deleted.\n- `msglimit`: Message amount to fetch.\n- `verbose`: Make the output verbose.\n\n## `analyse()` function\nBasically the only function needed to analyse a stream. It's a helper function that calls various parts of the whole module in order to analyse the stream. The implementation is as follows:\n```python\ndef analyse(self):\n    if not self.is_cached:\n        self.collect_data()\n    self.read_data()\n    self.refine_data()\n    self.enforce_integrity()\n    self.fetch_missing_messages()\n    self.analyse_data()\n```\n##### P.S. not confuse it with `analyse_data`! \n\nAs can be seen in the code, it collects, reads, refines and finally analyses the data. All while ensuring the integrity and stability withing the package. Each step will be explained later on.\n\nBefore diving into the core modules (collector, refiner and analyser), the other helper modules will be explained.\n\n# 2. File handling\n\nFile handling is done with the `filehandler` module. It handles everything related to files from caching to interacting with them. These external files are stored in a designated path (Default path is `\"C:\\Stream Analyser\"` as of now)\n\nExample storage folder structure is as follows:\n```\nStream Analyser\n├───Cache\n│   ├───1FXhj4qFOf0\n│   │   ├───messages.json.gz\n│   │   └───metadata.yaml\n│   └───hbNdooO8n_M\n│   │   ├───messages.json.gz\n│   │   └───metadata.yaml\n│   └───jgp1h2yRbBU\n│       ├───messages.json.gz\n│       └───metadata.yaml\n├───Exports\n│   ├───1627487676\n│   └───custom_name\n└───Logs\n    ├───2022-02-W3.log\n    └───2022-02-W2.log\n\n```\n\n- ## Caching\n\n    Everytime a stream is analysed, filehandler caches it's files for a much faster access. The cached files are also compressed with gzip to take up less space and only decompressed when used.\n\n    - ### Location and file structure\n        filehandler caches the fetched data in `\"Stream Analyser/Cache/\"`. Inside the cache folder, all streams are cached seperately using the stream id as the folder name and each folder includes a `\"messages.json.gz\"` and a `\"metadata.yaml\"` file.\n\n    - ### Cache deletion\n        Caches are deleted automatically after hitting the cache limit using a *cache deletion algorithm*. Default behavior is to delete the least recently used cache.\n        \n\n- ## Logging\n\n    filehandler deletes logs that are older than the destined log duration (default is 15).\n\n- ## Exporting\n\n    Default export location is stored in filehandler. \n\n- ## CRUD\n    filehandler performs basic CRUD operations to access and manipulate the stored data.\n\n- ## Compressing\n\n    filehandler can compress and decompress files.\n\n- ## Integrity checking\n    \n    filehandler can check file integrity to detect missing and/or unnecessary files.\n    \n    It also can automatically fix minor mistakes such as compressing files that are unintentionally left decompressed and deleting unnecessary files.\n\n# 3. Logging\n\nLogging is done with `logging` module. All modules share the same log file that changes weekly and all uses `create_logger` function in `loggersetup` module (except `filehandler`) to initialize their own loggers with their own module names. The reason for using seperate loggers is to improve debugging efficiency. \n\nLog files use *YYYY-MM-WX.log* naming convention where WX is the Xth week of the month (including 0). Duration of a log file is 15 days (unless chosen to be kept indefinitely) but can be configured. It can also be disabled.\n\n# 4. Collecting data\n\nData collection is done with the `datacollector` module, which fetches messages of the stream using the `ChatDownloader` module and metadata using the `urllib` module. It also has methods to fetch missing messages and to get thumbnail image url.\n\nOne important part to mention is how `msglimit` (message limit) and `iscomplete` works since knowing if all messages are present or not is a crucial information for the module. `msglimit` basically limits the message amount to fetch and it fetches every message if it's set to `None`, and `iscomplete` stores if **all** messages are fetched or not judging by message limit. This will help us deciding if the stream is fully cached or not later on.\n\nThe fetched data is in it's raw shape and needs to be refined to be actually used.\n\n# 5. Refining data\n\nData refining is done with the `datarefiner` module. It's a bridge between collector and analyser modules that shapes data from one form to another. \n\nThe raw data collected with `datacollector` is in the dictionary form and it's shaped into `Message` dataclass to make the data more consistent and convenient using `refine_raw_messages` function.\n\nIt also gets names of the authors and shapes them into `Author` dataclass too.\n\n# 6. Analysing data\n\nData analysis is done with the `chatanalyser` module by reading the refined chat data.\n\nFirst, it creates frequency table of the message list and calculates moving average of the table. Then it convolves that data to smoothen the moving average even further, so that the spikes of the function becomes clearer to see. Finally, it detects spikes and marks the spike duration as highlight.\n\nAfter finding highlight timestamps, other crucial information is analysed to get more information about each highlight such as:\n- fdelta: Frequency delta. Difference between the frequency at the start and the end.\n- intensity: How tense the highlight was.\n- messages: Messages written during the highlight.\n- keywords: Most used words during the highlight.\n- context: Guessed context by the keywords.\n##### (The explained algorithm will be further improved in the future.)\n\nIt can also draw graph and word cloud of the analysed data on demand.\n\n# 7. Output\n\n- ## Direct\n    Data can be accessed directly using the class attributes\n\n    ```python\n    print(type(analyser.messages))  # list[Message,Superchat,Membership]\n    print(type(analyser.authors))  # list[Author]\n    print(type(analyser.highlights))  # list[Higlight]\n    print(type(analyser.fig))  # plt\n    ```\n- ## With prebuilt functions\n    There are plenty of prebuilt functions to filter and manipulate the returned data. Assuming the object is initialized as follows:\n    \n    ```python\n    with StreamAnalyser(stream_id) as analyser:\n        analyser.analyse()\n    ```\n\n    Data can be accessed and manipulated using these functions:\n\n    - `get_highlights`: Returns highlights that can be filtered and sorted by intensity. Can also pretty print to the console using `ouput_mode` argument. Highlights are color coded by intensity.\n\n      ```python\n      analyser.get_highlights()\n      # No output on console. This usage is the same as `analyser.highlights` and returns a list of highlights.\n\n      analyser.get_highlights(top=10)\n      # Returns top 10 highlights sorted by intensity.\n\n      analyser.get_highlights(output_mode=\"summary\")\n      # Prints the returned highlights on the console.\n\n      analyser.get_highlights(include=[\"funny\", \"cute\"], exclude=[\"scary\"])\n      # Returns highlights that includes \"funny\" and \"cute\" contexts and excludes \"scary\" context. Exclude overrides include. Context names can be found and modified in `/data/default_contexts.json` file.\n\n      analyser.get_highlights(intensity_filters=[\"Very high\"])\n      # Returns highlights that does not have \"Very high\" intensity. Default intenisty names can be found in `chatanalyser.init_intenisty()` function and modified with parameters when initializing the object. \n      \n      ```\n\n    - `most_used_phrase`: Returns most used phrase and its occurance count throughout the stream\n\n      ```python\n      # basic usage\n      phrase, occurance = analyser.most_used_phrase()\n      print(phrase, occurance)\n      # lol 74\n\n      # some phrases can be excluded as well\n      phrase, occurance = analyser.most_used_phrase(exclude=[\"lol\"])\n      print(phrase, occurance)\n      # lmao 64\n\n      # phrases are normalized when finding phrases by default but this behavior can be avoided using `normalize` argument.\n      phrase, occurance = analyser.most_used_phrase(normalize=False)\n      print(phrase, occurance)\n      # lol 68 (notice that occurance count has decreased)\n      ```\n\n    - `find_messages`: Searches for messages. Can be filtered in various ways.\n\n      ```python\n      # basic usage\n      found_messages = analyser.find_messages(\"lol\")\n      [print(message) for message in found_messages]\n      # [0:13:02] Alice: that's funny lol\n      # [0:13:15] Bob: lol\n      # [0:22:25] William: LOL\n\n      # the exact phrase can be searched\n      found_messages = analyser.find_messages(\"lol\", exact=True)\n      [print(message) for message in found_messages]\n      # [0:13:15] Bob: lol\n      # [0:22:25] William: LOL\n\n      # cases are ignored by default, but this behavior can be avoided using `ignore_case` argument. \n      msgs = analyser.find_messages(\"lol\", ignore_case=False)\n      [print(message) for message in msgs]\n      # [0:13:02] Alice: that's funny lol\n      # [0:13:15] Bob: lol\n      ```\n\n    - `find_user_messages`: Returns all messages made by an user. Can use either username or id.\n      ```python\n      found_messages = analyser.find_user_messages(username=\"Tom\")\n      [print(message) for message in found_messages]\n      # [0:01:42] Tom: That's a nice module\n\n      found_messages = analyser.find_user_messages(\n        id=\"UCHkbYFoYuUpfg2R9jcCkTZg\"\n      )\n      [print(message) for message in found_messages]\n      # [1:23:42] Alice: I love cats\n      ```\n    - `generate_wordcloud`: Creates a basic word cloud of the stream.\n      ```python\n      analyser.generate_wordcloud().to_image().show()\n      ```\n    - `show_graph`: Shows a basic graph that contains message frequency and highlights.\n      ```python\n      # both uses are the same\n      analyser.show_graph()\n      analyser.fig.show()\n      ```\n\n    - `export_data`: Exports analysed data to a specified path.\n      ```python\n      # basic usage\n      # exports data to the default export path with the folder name being the current UNIX timestamp\n      analyser.export_data()\n\n      # a custom path and folder name can be used\n      # if the folder name is already used, current UNIX timestamp is added after the folder name\n      analyser.export_data(\n        path=\"./MyExports\", folder_name=\"MyFolderName\"\n      )\n\n      # open the folder in file explorer after exporting \n      analyser.export_data(open_folder=True)\n      ```\n\n# Custom contexts\n\nCustom context files can be integrated using `ContextSourceManager`.\n\n```python\n# examples/custom_context.py\n\nanalyser = sa.StreamAnalyser(\n    \"ShB4Wen_HBg\",\n    verbose=True,\n    not_cache=True,\n    disable_logs=True,\n    msglimit=1000,\n    default_context_path=None # set default context path to None to disable premade default contexts\n)\nwith analyser:\n    # context source paths should be absolute paths\n    analyser.context_source.add(os.path.join(\n        os.path.dirname(os.path.realpath(__file__)), \"contexts_example.json\"\n    ))\n\n    # context sources should be added before the analyse function\n    analyser.analyse()\n\n    analyser.get_highlights(output_mode=\"detailed\")\n\n```\n\nWhile not recommended, you can also modify the default context list using `add_context` and `remove_context` functions or rewrite the `/path/to/package/data/default_contexts.json` file according to your needs.\n\n<hr>\n\n<br>\n\n# Possible issues\n\n### It keeps throwing error when reading cached messages\n\nIt's most likely caused by an interrupted I/O operation and the cache needs to be cleared or fixed by hand. Try these in order:\n\n- Run the program again with `reset` option on (`--reset` for CLI).\n\n```python\n# solution 1\nwith StreamAnalyser('Vl_N4AXspo', reset=True) as analyser:\n  analyser.collect_data()\n\n# solution 2\nwith StreamAnalyser('Vl_N4AXspo') as analyser:\n  analyser.clear_cache()\n  analyser.collect_data()\n```\nor\n```bash\n>streamanalyser [stream-id] --reset\n```\n\n- Open appropriate metadata file and set `is-complete` option to `False`. Then run the program again with `msglimit=None`.\n\n- Delete appropriate message cache by hand.\n\n##### (Default cache path is `\"C:\\Stream Analyser\\Cache\\[stream id]\"`, or you can directly use the `open_cache_folder` function.)\n\nShould the error persists, please open an issue.\n\n### Can't see Japanese characters on console\n\nJust changing the code page to `932` should work.\n\n```bash\nC:\\Your\\Path> chcp 932\nActive code page: 932\n\nC:\\Your\\Path> 今日本語が書ける\n```\n\nLikewise, use `chcp 65001` to go back. Or simply re-open the console.\n\n## Testing\n\n```python\npython -m unittest discover streamanalyser/tests\n```\n\n```python\npython test_coverage.py\n```\n\n## Future goals\n\n- Expand to other stream platforms.\n\n- Automatize context guessing.\n\n- End world hunger.\n\n## Support\nYou can support me to maintain this open-source project by [donating](https://www.paypal.com/donate/?hosted_button_id=UZUYSWDAD9E8N), I'd really appreciate it if you consider it!\n\n## License\n[GPL v3.0](https://choosealicense.com/licenses/gpl-3.0/)\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/emso-c/stream-analyser",
    "keywords": "youtube,live,stream,chat,highlight,analysis",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "stream-analyser",
    "package_url": "https://pypi.org/project/stream-analyser/",
    "platform": null,
    "project_url": "https://pypi.org/project/stream-analyser/",
    "project_urls": {
      "Homepage": "https://github.com/emso-c/stream-analyser"
    },
    "release_url": "https://pypi.org/project/stream-analyser/0.3.8/",
    "requires_dist": [
      "appdirs (>=1.4.4)",
      "black (>=21.7b0)",
      "build (>=0.6.0.post1)",
      "certifi (>=2021.5.30)",
      "charset-normalizer (>=2.0.4)",
      "chat-downloader (>=0.1.8)",
      "click (>=8.0.1)",
      "colorama (>=0.4.4)",
      "colorlog (>=5.0.1)",
      "coverage (>=5.5)",
      "cycler (>=0.10.0)",
      "docstring-parser (>=0.10)",
      "idna (>=3.2)",
      "isodate (>=0.6.0)",
      "joblib (>=1.1.0)",
      "kiwisolver (>=1.3.1)",
      "matplotlib (>=3.4.3)",
      "mypy-extensions (>=0.4.3)",
      "nltk (>=3.6.7)",
      "numpy (>=1.23.3)",
      "packaging (>=21.0)",
      "pathspec (>=0.9.0)",
      "pep517 (>=0.11.0)",
      "Pillow (>=9.0.1)",
      "pyparsing (>=2.4.7)",
      "python-dateutil (>=2.8.2)",
      "PyYAML (>=5.4.1)",
      "regex (>=2021.8.3)",
      "requests (>=2.26.0)",
      "six (>=1.16.0)",
      "tomli (>=1.2.1)",
      "tqdm (>=4.62.3)",
      "urllib3 (>=1.26.6)",
      "websocket-client (>=1.2.1)",
      "wordcloud (>=1.8.1)"
    ],
    "requires_python": ">=3.7",
    "summary": "A tool that analyses live streams",
    "version": "0.3.8",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 15287782,
  "releases": {
    "0.3.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "db16ea98b5666ba6e356601e8193e22970d4f60342011dd340d278d6a7ea1544",
          "md5": "6f0a92e521678ce6ca1a90ea281924fe",
          "sha256": "e8f51858d0d7c625665d8fe4d55bceee2776927ac03146ee9f3eb6cfe34b2646"
        },
        "downloads": -1,
        "filename": "stream_analyser-0.3.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "6f0a92e521678ce6ca1a90ea281924fe",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 648256,
        "upload_time": "2022-02-28T21:44:58",
        "upload_time_iso_8601": "2022-02-28T21:44:58.493529Z",
        "url": "https://files.pythonhosted.org/packages/db/16/ea98b5666ba6e356601e8193e22970d4f60342011dd340d278d6a7ea1544/stream_analyser-0.3.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "067d28bdc8f4343648eabe42bf3abf5e9c8fe76877dc0690aabe218b266fa3b4",
          "md5": "907533715e117fb3d54ba663a09c1e08",
          "sha256": "bebf16ea3eb342c5842325b11ff8a6cf68a6d6d4fa955d547dde61bab209d3cb"
        },
        "downloads": -1,
        "filename": "stream-analyser-0.3.2.tar.gz",
        "has_sig": false,
        "md5_digest": "907533715e117fb3d54ba663a09c1e08",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 646817,
        "upload_time": "2022-02-28T21:45:01",
        "upload_time_iso_8601": "2022-02-28T21:45:01.914314Z",
        "url": "https://files.pythonhosted.org/packages/06/7d/28bdc8f4343648eabe42bf3abf5e9c8fe76877dc0690aabe218b266fa3b4/stream-analyser-0.3.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "19f6708d3c4cf4fb2046be4281756ff9b4eb6e60fb3c7a26e74ecd38e4bdae27",
          "md5": "4c4fed8112639edeeb872e4641844a09",
          "sha256": "7beaaf721f7c3d1d00ae3bc5fd16d04a44dc1beba2069f7417d63421b0aeddcd"
        },
        "downloads": -1,
        "filename": "stream_analyser-0.3.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "4c4fed8112639edeeb872e4641844a09",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 648440,
        "upload_time": "2022-03-01T10:15:44",
        "upload_time_iso_8601": "2022-03-01T10:15:44.864373Z",
        "url": "https://files.pythonhosted.org/packages/19/f6/708d3c4cf4fb2046be4281756ff9b4eb6e60fb3c7a26e74ecd38e4bdae27/stream_analyser-0.3.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3d34a829687b8ace67e92293a3e8b7e46e06662ab143239659e783db29200ef3",
          "md5": "f9f6d21047167bd537125194ae0626de",
          "sha256": "15bdac8f7832f3e4e3b1d93b6b8e84422fe321286e5060d694063cb1b325f88a"
        },
        "downloads": -1,
        "filename": "stream-analyser-0.3.3.tar.gz",
        "has_sig": false,
        "md5_digest": "f9f6d21047167bd537125194ae0626de",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 641754,
        "upload_time": "2022-03-01T10:15:46",
        "upload_time_iso_8601": "2022-03-01T10:15:46.860885Z",
        "url": "https://files.pythonhosted.org/packages/3d/34/a829687b8ace67e92293a3e8b7e46e06662ab143239659e783db29200ef3/stream-analyser-0.3.3.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.4": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f7fac2a5ab2c85699a2cf654d812d0ebc4795e1e12ffc50161b9bb57a57331db",
          "md5": "cb6bb9687a430812367ff9e050438dc0",
          "sha256": "54db87c86b6702819d1136095e0887fa163267d2db3f367b155db5cadb8328a5"
        },
        "downloads": -1,
        "filename": "stream_analyser-0.3.4-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "cb6bb9687a430812367ff9e050438dc0",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 648678,
        "upload_time": "2022-03-06T19:10:46",
        "upload_time_iso_8601": "2022-03-06T19:10:46.210704Z",
        "url": "https://files.pythonhosted.org/packages/f7/fa/c2a5ab2c85699a2cf654d812d0ebc4795e1e12ffc50161b9bb57a57331db/stream_analyser-0.3.4-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "00a398bdbce01443ab62bb508f5c82cf3c737da212cdb9336f42700e814e2219",
          "md5": "34d583bca5dfeb1ef61673c2077a7740",
          "sha256": "d52bacf3f1ca9a9f5eca00d5aaff7fca4819857e650455f567eee94840c32937"
        },
        "downloads": -1,
        "filename": "stream-analyser-0.3.4.tar.gz",
        "has_sig": false,
        "md5_digest": "34d583bca5dfeb1ef61673c2077a7740",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 641950,
        "upload_time": "2022-03-06T19:10:47",
        "upload_time_iso_8601": "2022-03-06T19:10:47.829225Z",
        "url": "https://files.pythonhosted.org/packages/00/a3/98bdbce01443ab62bb508f5c82cf3c737da212cdb9336f42700e814e2219/stream-analyser-0.3.4.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.5": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "f95b147a79d6a97bfe4c83f2ce65bc144d298aa41b90842c945d7989ca1e0ac9",
          "md5": "d29e2b0c963e0860cedf98ee0ccc86a9",
          "sha256": "2d933e200a043ea907b2cdd1eae5c2898ce7f7959edb206866c807fc2f70a2c3"
        },
        "downloads": -1,
        "filename": "stream_analyser-0.3.5-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "d29e2b0c963e0860cedf98ee0ccc86a9",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 648614,
        "upload_time": "2022-03-11T22:03:42",
        "upload_time_iso_8601": "2022-03-11T22:03:42.145342Z",
        "url": "https://files.pythonhosted.org/packages/f9/5b/147a79d6a97bfe4c83f2ce65bc144d298aa41b90842c945d7989ca1e0ac9/stream_analyser-0.3.5-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6b4f1abe59e5d3d5d8996719c83dc662e487b11ee199a7e0a4f4a80ec246955e",
          "md5": "4d25b629554afbd8124284e4c00fb9d5",
          "sha256": "0fa7890d450a9881e2be8de8c420e35559e24bbafd1f3127e274cb7d6fd589d3"
        },
        "downloads": -1,
        "filename": "stream-analyser-0.3.5.tar.gz",
        "has_sig": false,
        "md5_digest": "4d25b629554afbd8124284e4c00fb9d5",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 641885,
        "upload_time": "2022-03-11T22:03:43",
        "upload_time_iso_8601": "2022-03-11T22:03:43.950251Z",
        "url": "https://files.pythonhosted.org/packages/6b/4f/1abe59e5d3d5d8996719c83dc662e487b11ee199a7e0a4f4a80ec246955e/stream-analyser-0.3.5.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.6": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "c1745ff084d928ea6a00807fb72753f52756357b93f85e7d5be12641c8dcd990",
          "md5": "e1a5dbe7abcccecc0b0ff1872a6b2192",
          "sha256": "c75d44afeeca02d181101ae94fca92997909f779b3f37e93f628d4222bfc9c03"
        },
        "downloads": -1,
        "filename": "stream_analyser-0.3.6-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "e1a5dbe7abcccecc0b0ff1872a6b2192",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 648799,
        "upload_time": "2022-03-17T23:27:10",
        "upload_time_iso_8601": "2022-03-17T23:27:10.861768Z",
        "url": "https://files.pythonhosted.org/packages/c1/74/5ff084d928ea6a00807fb72753f52756357b93f85e7d5be12641c8dcd990/stream_analyser-0.3.6-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "bddb4dd872922abf25a9300b69cd82b6bd4aa2bd12dd746fd5d94ed8c254f8eb",
          "md5": "2506ac8d7aa3452bd3cb4b1b9f330f6b",
          "sha256": "2783ef9cc292854e09c111da44e1a295981133914bb456c9125a1e33e106bbd3"
        },
        "downloads": -1,
        "filename": "stream-analyser-0.3.6.tar.gz",
        "has_sig": false,
        "md5_digest": "2506ac8d7aa3452bd3cb4b1b9f330f6b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 642311,
        "upload_time": "2022-03-17T23:27:13",
        "upload_time_iso_8601": "2022-03-17T23:27:13.094082Z",
        "url": "https://files.pythonhosted.org/packages/bd/db/4dd872922abf25a9300b69cd82b6bd4aa2bd12dd746fd5d94ed8c254f8eb/stream-analyser-0.3.6.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.7": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "96c6c437e495046780deb611bcb02ef35e2a7ba5ecde2ebdc82f91edf9ed0e70",
          "md5": "64f3d78ea323a2aaa5f54a4d76e5643d",
          "sha256": "0f5071cadf18dd10a3e4d095fa2c7cf2d0c2a1cdbabd88bff5dc88c065865976"
        },
        "downloads": -1,
        "filename": "stream_analyser-0.3.7-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "64f3d78ea323a2aaa5f54a4d76e5643d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 648712,
        "upload_time": "2022-03-22T21:16:04",
        "upload_time_iso_8601": "2022-03-22T21:16:04.800448Z",
        "url": "https://files.pythonhosted.org/packages/96/c6/c437e495046780deb611bcb02ef35e2a7ba5ecde2ebdc82f91edf9ed0e70/stream_analyser-0.3.7-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "50d6f667e01dbf069315b3a5ad1698d0fae8009f0cef696190afceb02f939228",
          "md5": "73111da6cb9cfe6187a5c155e32fa3fa",
          "sha256": "473a256ec4fd7ac1f9fe452ecf0b78c95acfde7f35f001d908df3c0343b709a5"
        },
        "downloads": -1,
        "filename": "stream-analyser-0.3.7.tar.gz",
        "has_sig": false,
        "md5_digest": "73111da6cb9cfe6187a5c155e32fa3fa",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 642110,
        "upload_time": "2022-03-22T21:16:06",
        "upload_time_iso_8601": "2022-03-22T21:16:06.924031Z",
        "url": "https://files.pythonhosted.org/packages/50/d6/f667e01dbf069315b3a5ad1698d0fae8009f0cef696190afceb02f939228/stream-analyser-0.3.7.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.3.8": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "eede79c1acc12f4773042a6966ac04773e62008b87a8e4ecefb2725a24f2efa9",
          "md5": "69f5dc5cd9e0b71d487e55427da364cf",
          "sha256": "3816c91600d41d5f8e7b22a126874eeaf9b23ebe424e97b9e8c8dd3bed1b2ef9"
        },
        "downloads": -1,
        "filename": "stream_analyser-0.3.8-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "69f5dc5cd9e0b71d487e55427da364cf",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.7",
        "size": 648803,
        "upload_time": "2022-10-03T10:18:11",
        "upload_time_iso_8601": "2022-10-03T10:18:11.760327Z",
        "url": "https://files.pythonhosted.org/packages/ee/de/79c1acc12f4773042a6966ac04773e62008b87a8e4ecefb2725a24f2efa9/stream_analyser-0.3.8-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "48733137983835ec24d566723c83b90272a13a867ee7f337c81970fbdd3a7d01",
          "md5": "25ae0405174294dc07ec1670625d5d0a",
          "sha256": "ae1e60913254de1cead976bd7b7aeecfa592a05c54634737ad4b6b97080fd9c2"
        },
        "downloads": -1,
        "filename": "stream-analyser-0.3.8.tar.gz",
        "has_sig": false,
        "md5_digest": "25ae0405174294dc07ec1670625d5d0a",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.7",
        "size": 642290,
        "upload_time": "2022-10-03T10:18:13",
        "upload_time_iso_8601": "2022-10-03T10:18:13.882081Z",
        "url": "https://files.pythonhosted.org/packages/48/73/3137983835ec24d566723c83b90272a13a867ee7f337c81970fbdd3a7d01/stream-analyser-0.3.8.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "eede79c1acc12f4773042a6966ac04773e62008b87a8e4ecefb2725a24f2efa9",
        "md5": "69f5dc5cd9e0b71d487e55427da364cf",
        "sha256": "3816c91600d41d5f8e7b22a126874eeaf9b23ebe424e97b9e8c8dd3bed1b2ef9"
      },
      "downloads": -1,
      "filename": "stream_analyser-0.3.8-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "69f5dc5cd9e0b71d487e55427da364cf",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.7",
      "size": 648803,
      "upload_time": "2022-10-03T10:18:11",
      "upload_time_iso_8601": "2022-10-03T10:18:11.760327Z",
      "url": "https://files.pythonhosted.org/packages/ee/de/79c1acc12f4773042a6966ac04773e62008b87a8e4ecefb2725a24f2efa9/stream_analyser-0.3.8-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "48733137983835ec24d566723c83b90272a13a867ee7f337c81970fbdd3a7d01",
        "md5": "25ae0405174294dc07ec1670625d5d0a",
        "sha256": "ae1e60913254de1cead976bd7b7aeecfa592a05c54634737ad4b6b97080fd9c2"
      },
      "downloads": -1,
      "filename": "stream-analyser-0.3.8.tar.gz",
      "has_sig": false,
      "md5_digest": "25ae0405174294dc07ec1670625d5d0a",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.7",
      "size": 642290,
      "upload_time": "2022-10-03T10:18:13",
      "upload_time_iso_8601": "2022-10-03T10:18:13.882081Z",
      "url": "https://files.pythonhosted.org/packages/48/73/3137983835ec24d566723c83b90272a13a867ee7f337c81970fbdd3a7d01/stream-analyser-0.3.8.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}