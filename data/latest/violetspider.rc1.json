{
  "info": {
    "author": "violet-drowning",
    "author_email": "459427688@qq.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "# 功能介绍\n\n​\t支持全球疫情数据获取以及对应的国家、省份、城市数据获取\n\n# 具体操作\n\n```python\nimport violetSpider as spider\nfrom violetSpider.core.model import Word, Nation, Province\n\n# 1.获取全球数据\nword: Word = spider.find_word()\nprint(word, type(word))\n# <violetSpider.core.model.World object at 0x0000021DD6FC3AC8> <class 'violetSpider.core.model.World'>\n\n# 2.获取对应数据\n# 获取该对象上所有的存储数据的 Key，drop=True【默认删除值为 None 的 Key】\nkeys = word.keys(drop=True)\nvalues = word.values(drop=True)\nvalue = word.name\nprint(keys, values, value)\n# dict_keys(['name', 'nowConfirm', 'confirm', 'heal', 'dead', 'lastUpdateTime']) \n# dict_values(['地球', 46987153, 217021468, 165524088, 4510227, '2021-10-20 13:43:34'])\n# 地球\n```\n\n## 获取国家数据\n\n```python\n# 根据全球数据获取国家数据\n# 如果不指定具体国家，会获取所有国家\n# 所有数据对象都包含 keys() 和 values()\nnations: list = word.searchNation('美国', '法国', '西班牙')\nnation: Nation = nations[0]\nprint(nations)\nprint(nation.keys(), nation.values())\n\n# [<violetSpider.core.model.Nation object at 0x000002245C37AD30>, \n# <violetSpider.core.model.Nation object at 0x000002245C37ACF8>, \n# <violetSpider.core.model.Nation object at 0x000002245C37AC88>]\n\n# dict_keys(['name', 'continent', 'y', 'date', 'confirmAdd', 'confirmAddCut', 'confirm', 'suspect', 'dead', 'heal', 'nowConfirm', 'confirmCompare', 'nowConfirmCompare', 'healCompare', 'deadCompare']) \n\n# dict_values(['美国', '北美洲', '2021', '08.31', 0, 0, 39668541, 0, 654696, 30826478, 8187367, 0, 0, 0, 0])\n```\n\n## 获取某个国家下的省份数据\n\n```python\n# 先获取具体国家\nnation: Nation = word.searchNation_one('美国')\n\n# 获取指定省份，如果不指定则获取所有\nprovinces = nation.searchProvince()\nfor province in provinces[:3]:\n    print(province.name)\n    \n# 加利福尼亚\n# 德克萨斯\n# 佛罗里达\n```\n\n## 获取省份下面的城市\n\n```python\nnation: Nation = word.searchNation_one('美国')\nprovince: Province = nation.searchProvince_one('德克萨斯')\n\n# 获取指定城市，如果不指定则获取所有\ncitys = province.searchCity()\nfor city in citys[:3]:\n    print(city)\n    \n# 当然，有些省份是没有公布城市数据的\n# violetSpider.core.error.WorldData: 很抱歉, 德克萨斯, 并未开放城市数据\n```\n\n```python\n# 所有你可以这样写\n# 不过别报太大希望，城市一般不会获取到数据\nnation: Nation = word.searchNation_one('美国')\nprovinces = nation.searchProvince()\n\nfor province in provinces:\n    try:\n        c = province.searchCity()[:3]\n        for city in c:\n            print(city.name)\n        print(province.name)\n        break\n    except Exception as e:\n        print(e)\n```\n\n## 保存数据\n\n```python\n# 目前支持 mysql 和 csv 保持\n# 具体 API 如下\nimport violetSpider as spider\n\nspider.save_csv(\n\tpath: str,   # 存储路径，必须\n    data: list,   # 数据，装有 Nation、Province、City 对象的列表 \n    fields=None,  # 存储指定，不指定则全选\n    drop=True     # 是否删除空值字段\n)\n\nspider.save_mysql(\n    username: str,\n    password: str,\n    host: str,\n    port: int,\n    databases: str,\n    data: list,        # 数据，装有 Nation、Province、City 对象的列表 \n    table=None,        # 是否指定表\n    fields=None,       # 指定保存的字段\n    drop=True          # 只要有一个字段的值为空, 那么便不保存这个字段\n)\n```\n## 更新内容\n```python\n1.1.0 -> 基本功能实现\n1.1.3 -> 修复了 china 数据无法获取\n```\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "violetSpider",
    "package_url": "https://pypi.org/project/violetSpider/",
    "platform": "any",
    "project_url": "https://pypi.org/project/violetSpider/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/violetSpider/1.1.3/",
    "requires_dist": [
      "requests"
    ],
    "requires_python": "",
    "summary": "新冠疫情数据爬取",
    "version": "1.1.3",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 16529321,
  "releases": {
    "1.1.3": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "2da54dbb6bb27fe625ae13e6a4f101b575a32660851d8cacf65559c8047deac8",
          "md5": "73715f793de8ddf27afaa2d000516aae",
          "sha256": "7e4f88e3c6c605110ae10b66228835e44e5e830c7fc687beabfa35899cf4306e"
        },
        "downloads": -1,
        "filename": "violetSpider-1.1.3-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "73715f793de8ddf27afaa2d000516aae",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 11284,
        "upload_time": "2023-01-23T08:34:50",
        "upload_time_iso_8601": "2023-01-23T08:34:50.555243Z",
        "url": "https://files.pythonhosted.org/packages/2d/a5/4dbb6bb27fe625ae13e6a4f101b575a32660851d8cacf65559c8047deac8/violetSpider-1.1.3-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "2da54dbb6bb27fe625ae13e6a4f101b575a32660851d8cacf65559c8047deac8",
        "md5": "73715f793de8ddf27afaa2d000516aae",
        "sha256": "7e4f88e3c6c605110ae10b66228835e44e5e830c7fc687beabfa35899cf4306e"
      },
      "downloads": -1,
      "filename": "violetSpider-1.1.3-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "73715f793de8ddf27afaa2d000516aae",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 11284,
      "upload_time": "2023-01-23T08:34:50",
      "upload_time_iso_8601": "2023-01-23T08:34:50.555243Z",
      "url": "https://files.pythonhosted.org/packages/2d/a5/4dbb6bb27fe625ae13e6a4f101b575a32660851d8cacf65559c8047deac8/violetSpider-1.1.3-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}