{
  "info": {
    "author": "Muyang Li",
    "author_email": "muyangli@cs.cmu.edu",
    "bugtrack_url": null,
    "classifiers": [
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Spatially Incremental Generative Engine (SIGE)\n\n### [Paper](https://arxiv.org/abs/2211.02048) | [Project](https://www.cs.cmu.edu/~sige/) | [Slides](www.cs.cmu.edu/~sige/resources/slides.key) | [YouTube](https://youtu.be/rDPotGoPPkQ) | [Bilibili](https://www.bilibili.com/video/BV1WG4y1b76q/?share_source=copy_web&vd_source=28b10c1b7c0a3972f928ee5f17d37771)\n\n**[NEW!]** SIGE  is accepted by NeurIPS 2022! Our code and benchmark datasets are publicly available!\n\n![teaser](https://github.com/lmxyy/sige/raw/main/assets/teaser.png)\n*We introduce Spatially Sparse Inference, a general-purpose method to selectively perform computations at the edited regions for image editing applications. Our method reduces the computation of DDIM by 4~6x and GauGAN by 15x for the above examples while preserving the image quality. When combined with existing compression methods such as GAN Compression, our method further reduces the computation of GauGAN by 47x.*\n\nEfficient Spatially Sparse Inference for Conditional GANs and Diffusion Models</br>\n[Muyang Li](https://lmxyy.me/), [Ji Lin](http://linji.me/), [Chenlin Meng](https://cs.stanford.edu/~chenlin/), [Stefano Ermon](https://cs.stanford.edu/~ermon/), [Song Han](https://songhan.mit.edu/), and [Jun-Yan Zhu](https://www.cs.cmu.edu/~junyanz/)</br>\nCMU, MIT, and Stanford</br>\nIn NeurIPS 2022.\n\n## Overview\n\n![overview](https://github.com/lmxyy/sige/raw/main/assets/method.gif)*Tiling-based sparse convolution overview. For each convolution <i>F<sub>l</sub></i> in the network, we wrap it into SIGE Conv<sub><i>l</i></sub>. The activations of the original image are already pre-computed. When getting the edited image, we first compute a difference mask between the original and edited image and reduce the mask to the active block indices to locate the edited regions. In each SIGE Conv<sub><i>l</i></sub>, we directly gather the active blocks from the edited activation <i>A<sub>l</sub></i><sup>edited</sup> according to the reduced indices, stack the blocks along the batch dimension, and feed them into <i>F<sub>l</sub></i>. The gathered blocks have an overlap of width 2 if <i>F<sub>l</sub></i> is 3Ã—3 convolution. After getting the output blocks from <i>F<sub>l</sub></i>, we scatter them back into <i>F<sub>l</sub></i>(<i>A<sub>l</sub></i><sup>original</sup>) to get the edited output, which approximates <i>F<sub>l</sub></i>(<i>A<sub>l</sub></i><sup>edited</sup>).*\n\n## Performance\n\n### Efficiency\n\n![overview](https://github.com/lmxyy/sige/raw/main/assets/results.png)\n*With 1.2% editing, SIGE could reduce the computation of DDIM, Progressive Distillation and GauGAN by 7-18x, achieve 2-4x speedup on NVIDIA RTX 3090 and 4-14x on Apple M1 Pro CPU. When combined with GAN Compression, it further reduces 50x computation on GauGAN, achieving 38x speedup on Apple M1 Pro CPU. Please check our paper for more details and results.*\n\n### Quality\n\n![overview](https://github.com/lmxyy/sige/raw/main/assets/quality.png)*Qualitative results under different edit sizes. PD is Progressive Distillation. Our method well preserves the visual fidelity of the original model without losing global context.*\n\nReferences:\n\n* Denoising Diffusion Implicit Model (DDIM), Song et al., ICLR 2021\n* Progressive Distillation for Fast Sampling of Diffusion Models, Salimans et al., ICLR 2022\n* Semantic Image Synthesis with Spatially-Adaptive Normalization (GauGAN), Park et al., CVPR 2019\n* GAN Compression: Efficient Architectures for Interactive Conditional GANs, Li et al., CVPR 2020\n\n## Prerequisites\n\n* Python3\n* CPU or NVIDIA GPU + CUDA CuDNN\n* [PyTorch](https://pytorch.org) >= 1.7\n\n## Getting Started\n\n### Installation\n\nAfter installing [PyTorch](https://pytorch.org), you should be able to install SIGE with PyPI\n\n```shell\npip install sige\n```\n\nor via GitHub:\n\n```shell\npip install git+https://github.com/lmxyy/sige.git\n```\n\nor locally for development\n\n```shell\ngit clone git@github.com:lmxyy/sige.git\ncd sige\npip install -e .\n```\n\n### Usage Example\n\nSee [example.py](https://github.com/lmxyy/sige/tree/main/example.py) for the minimal SIGE convolution example. Please first install SIGE with the above instructions and [torchprofile](https://github.com/zhijian-liu/torchprofile) with\n\n```shell\npip install torchprofile\n```\n\nThen you can run it with\n\n```shell\npython example.py [--use_cuda]\n```\n\nWe also have [![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lmxyy/sige/blob/main/example.ipynb) example.\n\n### Benchmark\n\nTo reproduce the results of [DDIM](https://github.com/ermongroup/ddim) and [Progressive Distillation](https://github.com/google-research/google-research/tree/master/diffusion_distillation) or download the LSUN Church editing datasets, please follow the instructions in [diffusion/README.md](https://github.com/lmxyy/sige/tree/main/diffusion/README.md).\n\nTo reproduce the results of [GauGAN](https://github.com/NVlabs/SPADE) and [GAN Compression](https://github.com/mit-han-lab/gan-compression) or download the Cityscapes editing datasets, please follow the instructions in [gaugan/README.md](https://github.com/lmxyy/sige/tree/main/gaugan/README.md).\n\n## Citation\n\nIf you use this code for your research, please cite our paper.\n\n```bibtex\n@inproceedings{li2022efficient,\n  title={Efficient Spatially Sparse Inference for Conditional GANs and Diffusion Models},\n  author={Li, Muyang and Lin, Ji and Meng, Chenlin and Ermon, Stefano and Han, Song and Zhu, Jun-Yan},\n  booktitle={NeurIPS},\n  year={2022}\n}\n```\n\n## Acknowledgments\n\nOur code is developed based on [SDEdit](https://github.com/ermongroup/SDEdit), [ddim](https://github.com/ermongroup/ddim), [diffusion_distillation](https://github.com/google-research/google-research/tree/master/diffusion_distillation) and [gan-compression](https://github.com/mit-han-lab/gan-compression). We refer to [sbnet](https://github.com/uber-research/sbnet) for the tiling-based sparse convolution algorithm implementation. Our work is also inspired by the gather/scatter implementations in [torchsparse](https://github.com/mit-han-lab/torchsparse).\n\nWe also thank [torchprofile](https://github.com/zhijian-liu/torchprofile) for MACs measurement, [clean-fid](https://github.com/GaParmar/clean-fid) for FID computation and [drn](https://github.com/fyu/drn) for Cityscapes mIoU computation.\n\nWe thank Yaoyao Ding, Zihao Ye, Lianmin Zheng, Haotian Tang, and Ligeng Zhu for the helpful comments on the engine design. We also thank George Cazenavette, Kangle Deng, Ruihan Gao, Daohan Lu, Sheng-Yu Wang and Bingliang Zhang for their valuable feedback. The project is partly supported by NSF, MIT-IBM Watson AI Lab, Kwai Inc, and Sony Corporation.\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/lmxyy/sige",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "sige",
    "package_url": "https://pypi.org/project/sige/",
    "platform": null,
    "project_url": "https://pypi.org/project/sige/",
    "project_urls": {
      "Homepage": "https://github.com/lmxyy/sige"
    },
    "release_url": "https://pypi.org/project/sige/0.2.0/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "Spatially Incremental Generative Engine (SIGE)",
    "version": "0.2.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 15671690,
  "releases": {
    "0.2.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5cc2539d25f994cfdc8391f4b85527ddb96f476f0cf1007879588eb4fa78da24",
          "md5": "22cfe8321d15d4ae96b356e678f0470b",
          "sha256": "03ec38fdcb986192ce50d92720ff3b5d9ec291dc8fa9a4be88f99fc619cb9464"
        },
        "downloads": -1,
        "filename": "sige-0.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "22cfe8321d15d4ae96b356e678f0470b",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 17667,
        "upload_time": "2022-11-06T03:01:07",
        "upload_time_iso_8601": "2022-11-06T03:01:07.985018Z",
        "url": "https://files.pythonhosted.org/packages/5c/c2/539d25f994cfdc8391f4b85527ddb96f476f0cf1007879588eb4fa78da24/sige-0.2.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "5cc2539d25f994cfdc8391f4b85527ddb96f476f0cf1007879588eb4fa78da24",
        "md5": "22cfe8321d15d4ae96b356e678f0470b",
        "sha256": "03ec38fdcb986192ce50d92720ff3b5d9ec291dc8fa9a4be88f99fc619cb9464"
      },
      "downloads": -1,
      "filename": "sige-0.2.0.tar.gz",
      "has_sig": false,
      "md5_digest": "22cfe8321d15d4ae96b356e678f0470b",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 17667,
      "upload_time": "2022-11-06T03:01:07",
      "upload_time_iso_8601": "2022-11-06T03:01:07.985018Z",
      "url": "https://files.pythonhosted.org/packages/5c/c2/539d25f994cfdc8391f4b85527ddb96f476f0cf1007879588eb4fa78da24/sige-0.2.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}