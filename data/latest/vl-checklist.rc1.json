{
  "info": {
    "author": "kyusonglee",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "License :: Free for non-commercial use",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# VL-CheckList (Coming Soon)\n\n<img src=\"docs/overview.png\" width=\"800\"> \n\n## Updates\n- 07/04/2022: VL-CheckList paper on arxiv https://arxiv.org/abs/2207.00221\n- 07/12/2022: Updated object, relation, attribute splits/dataset\n- 08/01/2022: Release the initial code and an example model\n\n## Introduction\nThis repository is the official project page for (VL-CheckList). \n**VL-CheckList** is an explainable framework that comprehensively evaluates VLP models and facilitates deeper understanding.The current method to evaluate a VLP model is solely by comparing its fine-tuned downstream tasks performance, which has a number of limitations, such as poor interpretability, incomparable results and bias in data.\n\n\nThe core principle of VL-CheckList are: (1) evaluate a VLP model's fundamental capabilities instead of performance on applications (2) disentangle capabilities into relatively independent variables that are easier to analyze.\n\nVL-CheckList evaluates VLP models from three aspects: Object, Attribute and Relationship. We provide the performance quantitative table and the radar chart based on the three aspects.\n\n## How to Install VL-CheckList\nThere are two options to use VL-CheckList. First, you can install vl_checklist in your project and import vl_checklist and evaluate your models\n```\npip install vl_checklist\n```\nSecond, you can clone the project add your model engine which include 'predict' function. Please find an example engine [Link](./example_models/vilt/engine.py)\n```\ngit clone https://github.com/om-ai-lab/VL-CheckList.git\n```\n\n## How to Evaluate your Model\nWe put the example models in the `example_models/` folder.  \n**1.** Define a config file \ne.g. in [configs/sample.yam](./configs/sample.yaml)\n```\nMAX_NUM: 2000\nMODEL_NAME: \"ViLT\"\nBATCH_SIZE: 4\nTASK: \"itc\"\nDATA:\n  TYPES: [\"Attribute/color\"]\n  TEST_DATA: [\"vg\",\"vaw\"]   \nOUTPUT: \n  DIR: \"output/vilt\"\n```\n**2.** Prepare Evaluation Data\nWe provide the initial curated jsons at `data/` and corresponding yamls at `vl_checklist/corpus`. You can need to download image dataset. You can find the instruction in detail [Link](DATASETS.md)\n\n**3.** Load the model which contain `predict()` and Evaluate class as follows.  \n**4.** Run `start()` as follows\n\nHere is an example code\n```python\nfrom example_models.vilt.engine import ViLT\nfrom vl_checklist.evaluate import Evaluate\n\nif __name__ == '__main__':\n    model = ViLT('vilt_200k_mlm_itm.ckpt')\n    vilt_eval = Evaluate(config=\"configs/sample.yaml\", model=model)\n    vilt_eval.start()\n```    \n\n **5.**  check the results in the OUTDIR DIR you defined the yaml file\n You can check the output format [LINK](OUTPUT.md)\n\n## Download Pretrained Weights\nWe include examples models at `example_models/`. You can download the pretrained weights we used in our papers as follows:\n- [ViLT-B/32](https://github.com/dandelin/ViLT/releases/download/200k/vilt_200k_mlm_itm.ckpt)\n- [ALBEF](https://storage.googleapis.com/sfr-pcl-data-research/ALBEF/ALBEF.pth)\n- [TCL](https://drive.google.com/file/d/1Cb1azBdcdbm0pRMFs-tupKxILTCXlB4O/view)\n- [UNITER](https://github.com/ChenRocks/UNITER)\n- [OSCAR](https://biglmdiag.blob.core.windows.net/vinvl/model_ckpts/image_captioning/pretrained_base.zip)\n- [LXMERT](https://drive.google.com/drive/folders/1Gq1uLUk6NdD0CcJOptXjxE6ssY5XAuat?usp=sharing)\n- [CLIP](https://github.com/openai/CLIP)\n\n## Demo\nWe present the demo in huggingface space, you can try it here: [Demo link](https://huggingface.co/spaces/omlab/VL_checklist_demo)  \nIn this demo, you can change the object and attribute of object in the text prompt. You can also change the size and location of the object.\n\n## References\nIf you use any source codes or datasets included in this toolkit in your work, please cite the following paper. The bibtex are listed below:\n```\n@misc{https://doi.org/10.48550/arxiv.2207.00221,\n  doi = {10.48550/ARXIV.2207.00221}, \n  url = {https://arxiv.org/abs/2207.00221},\n  author = {Zhao, Tiancheng and Zhang, Tianqi and Zhu, Mingwei and Shen, Haozhan and Lee, Kyusong and Lu, Xiaopeng and Yin, Jianwei},\n  keywords = {Computer Vision and Pattern Recognition (cs.CV), Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},\n  title = {VL-CheckList: Evaluating Pre-trained Vision-Language Models with Objects, Attributes and Relations},\n  publisher = {arXiv},\n  year = {2022},\n  copyright = {Creative Commons Attribution 4.0 International}\n}\n```\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/om-ai-lab",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "vl-checklist",
    "package_url": "https://pypi.org/project/vl-checklist/",
    "platform": null,
    "project_url": "https://pypi.org/project/vl-checklist/",
    "project_urls": {
      "Homepage": "https://github.com/om-ai-lab"
    },
    "release_url": "https://pypi.org/project/vl-checklist/0.0.1/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "Checklist for Vision language models",
    "version": "0.0.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 14618482,
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4523a825d2076cbeef0bca162661778595fd7127e9fd2273d29b11bf5f9bb58c",
          "md5": "337ba078674773ad8081981943cc798f",
          "sha256": "95d994591024c67d85b89b0b52ea6b9807968b569d96d144a9bec403a102e193"
        },
        "downloads": -1,
        "filename": "vl_checklist-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "337ba078674773ad8081981943cc798f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 8187453,
        "upload_time": "2022-08-01T23:02:27",
        "upload_time_iso_8601": "2022-08-01T23:02:27.954114Z",
        "url": "https://files.pythonhosted.org/packages/45/23/a825d2076cbeef0bca162661778595fd7127e9fd2273d29b11bf5f9bb58c/vl_checklist-0.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "4523a825d2076cbeef0bca162661778595fd7127e9fd2273d29b11bf5f9bb58c",
        "md5": "337ba078674773ad8081981943cc798f",
        "sha256": "95d994591024c67d85b89b0b52ea6b9807968b569d96d144a9bec403a102e193"
      },
      "downloads": -1,
      "filename": "vl_checklist-0.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "337ba078674773ad8081981943cc798f",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 8187453,
      "upload_time": "2022-08-01T23:02:27",
      "upload_time_iso_8601": "2022-08-01T23:02:27.954114Z",
      "url": "https://files.pythonhosted.org/packages/45/23/a825d2076cbeef0bca162661778595fd7127e9fd2273d29b11bf5f9bb58c/vl_checklist-0.0.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}