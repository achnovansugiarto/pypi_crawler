{
  "info": {
    "author": "Amit Kumar Kushwaha, Subhankar Saha",
    "author_email": "kushwaha.amitkumar@gmail.com, subhankarsaha2410@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Intended Audience :: Developers",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Tweet Scraping\n\n## Prerequisites\n\n1. Internet Connection\n2. Python 3.6+\n3. Must have present credentials (i,e: consumer key, consumer secret, access token, access token secret) by creating an account on Twitter Dev\n4. The code will create the output in the form of a csv file at the location of same code\n5. The dataset created will be unique at tweetid level\n\n## Installing Tweet Scraping\n\n```sh\npip3 install tweetScraping\n```\n\n## Using tweetScraping\n\nJust import tweetScraping and call functions!\n\n## Code Usage:\n\n```sh\nimport tweetScraping\na = tweetScraping.tweetScraping(consumer_key : str ,  consumer_secret :str, access_token : str , access_token_secret : str, query : str , [file_name:str],[no_of_tweets : int])\na.start()\n```\n\n## Code Example:\n## NOTE: These are dummy keys and tokens and are only for representation, please replace these with your credentials\n```sh\nimport tweetScraping\na = tweetScraping.tweetScraping('ghF98tufKbgWpGxHVbBTkx9L5' ,\n                                'EiyUJ9aEdwTEKEe2HLuo8ZhBTJscztgaEpSBY38YZhSUkq1Az4',\n                                '1099325182525661186-9dn78kOA4Z09plZWPHrn9nmgdukg6j',\n                                'dZMfqR9O4eCQLvS0bnWNYr9eivjS4wtwsPY8WnBugR5xJ',\n                                'GOT',\n                                1000)\na.start()\n```\n## This will output a csv file by the name GOT.csv, with 1000 tweets, this 1000 tweets can be increased further\n\n## Description of 33 columns created in the form of structured data from twitter unstructured data\n\n```sh\n1) tweet_id: the tweet id prefized and suffixed by '~' so that no digits are lost\n2) tweet_created_at: When was the tweet posted on Twitter\n3) tweet_created_on_holiday_bool: A boolean to tell if the tweet was posted on a \nnational holiday or not(True:Yes, False: No)\n4) tweet_created_on_weekend_bool: A boolean to tell if the tweet was posted on a \nweekend or not(True:Yes, False: No)\n5) tweet_created_at_noon_bool: A boolean to tell if the tweet was posted during \nnoon hours or not(True:Yes, False: No)\n5) tweet_created_at_eve_bool: A boolean to tell if the tweet was posted during \nevening hours or not(True:Yes, False: No)\n6) user_id: Twitter user account from which the tweet was posted prefixed and \nsuffixed by '~' so that no integer is lost\n7) user_screen_name: Twitter user screen name from which the tweet was posted, \nwill have actual case(If it is camel case it remains as is)\n8) user_screen_name_length: Length of the Twitter user screen name from which \nthe current tweet was posted\n9) user_no_of_tweets: How many tweets have been posted from the screen name \nsince date of creation of account till the date this code getting executed\n10) user_no_of_followers: Number of followers of the Twitter user screen name \nfrom which the current tweet was posted\n11) user_no_of_followings: Number of accounts the Twitter user screen name \nfollow from which the current tweet was posted\n12) user_account_age: How old the Twitter user account on Twitter is from \nwhich the current tweet was posted (current date - account creation date)\n13) user_no_of_favourites: Number of tweets liked by the Twitter \nuser screen name from which the current tweet was posted\n14) user_average_tweets: On a daily basis, how many tweets the Twitter \nuser screen name post from which the current tweet was posted\n15) user_average_favourites: On a daily basis, how many tweets the Twitter \nuser screen name like from which the current tweet was posted\n16) user_account_location: The geographical location(if shared) the Twitter \nuser screen name from which the current tweet was posted\n17) tweet_text: Tweet text post cleaning \n(cleaning done for (@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+), \nand case standardization)\n18) tweet_text_length: Length of the tweet text post cleaning\n19) tweet_text_optimal_length: A boolean to tell if the tweet posted was of \noptimal length or less prior to cleaning(True:Yes, False: No)\n20) tweet_text_no_of_hashtags: How many hashtags were present in the original \ntweet text before cleaning the text\n21) tweet_text_contains_hashtags: A boolean to tell if the tweet posted had a \nhashtag or not prior to cleaning(True:Yes, False: No)\n22) tweet_text_contains_url: A boolean to tell if the tweet posted had any url \nembedded prior to cleaning(True:Yes, False: No)\n23) tweet_text_no_of_user_mentions: How many other screen names were tagged in \nthe tweet text using '@'\n24) tweet_text_contains_user_mentions: A boolean to tell if the tweet posted had\nany user mentions prior to cleaning(True:Yes, False: No)\n25) tweet_text_sentiment: The sentiment of the tweet\n26) tweet_text_contains_media: A boolean to tell if the tweet posted had any \nmultimedia prior to cleaning(True:Yes, False: No)\n27) tweet_text_contains_number: A boolean to tell if the tweet posted had any \nnumbers prior to cleaning(True:Yes, False: No)\n28) tweet_text_contains_upper_words: A boolean to tell if the tweet posted had \nupper case words to emphasize the meaning prior to cleaning(True:Yes, False: No)\n29) tweet_text_contains_lower_words: A boolean to tell if the tweet posted had \nlower case words prior to cleaning(True:Yes, False: No)\n30) tweet_text_contains_excl: A boolean to tell if the tweet posted had \nexclamations prior to cleaning(True:Yes, False: No)\n31) tweet_text_contains_retweet_suggestion: A boolean to tell if the tweet \nposted had 'RT' asking to retweet prior to cleaning(True:Yes, False: No)\n32) retweeted: A boolean to tell if the tweet posted received any r\netweets or not(True:Yes, False: No)\n33) retweets: How many actual number of retweets the current retweet \nreceived at time when you are running this code\n```\n\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "python,tweet scraping,twitter,scraping",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "tweetScraping",
    "package_url": "https://pypi.org/project/tweetScraping/",
    "platform": "",
    "project_url": "https://pypi.org/project/tweetScraping/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/tweetScraping/1.0.2/",
    "requires_dist": [
      "pandas",
      "numpy",
      "tweepy",
      "nltk",
      "holidays",
      "textblob"
    ],
    "requires_python": "",
    "summary": "A Python Package to get tweets with giving only single keyword",
    "version": "1.0.2",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 11097611,
  "releases": {
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "3a12ad04135b9d59d9f6467a5b4fe2e4936b19930e3da0c28a4ef5203c880e2c",
          "md5": "782bff667012064db2ba0eea958ff625",
          "sha256": "ab72892265cc839bb726a95b2c2c03862ed3eeb2537976868ad6aa4ce80287d9"
        },
        "downloads": -1,
        "filename": "tweetScraping-1.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "782bff667012064db2ba0eea958ff625",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 5761,
        "upload_time": "2021-08-01T15:39:42",
        "upload_time_iso_8601": "2021-08-01T15:39:42.993069Z",
        "url": "https://files.pythonhosted.org/packages/3a/12/ad04135b9d59d9f6467a5b4fe2e4936b19930e3da0c28a4ef5203c880e2c/tweetScraping-1.0.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "621f0e8551f625ee6e0b35cba91e0654d6701b3c08b183487d9f25a3f861bc41",
          "md5": "04c64535a6c840e3358b1906478e6960",
          "sha256": "3bcb015df79a723f9dd642451b8368368020030e490aa7c22435cd33f54d8159"
        },
        "downloads": -1,
        "filename": "tweetScraping-1.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "04c64535a6c840e3358b1906478e6960",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 7227,
        "upload_time": "2021-08-02T17:05:56",
        "upload_time_iso_8601": "2021-08-02T17:05:56.025179Z",
        "url": "https://files.pythonhosted.org/packages/62/1f/0e8551f625ee6e0b35cba91e0654d6701b3c08b183487d9f25a3f861bc41/tweetScraping-1.0.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "4e1a62c65c30292499084ed907a5714d7c7764fb05ede6160d34ae12e9c548ea",
          "md5": "b6c98475e3bf3b1705c72909d1cf0d31",
          "sha256": "4cf18572b40d3e8ef87c88abe1e817c1ea394553412eab0c83933a8ac2b3c0eb"
        },
        "downloads": -1,
        "filename": "tweetScraping-1.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "b6c98475e3bf3b1705c72909d1cf0d31",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 8789,
        "upload_time": "2021-08-02T17:05:58",
        "upload_time_iso_8601": "2021-08-02T17:05:58.642664Z",
        "url": "https://files.pythonhosted.org/packages/4e/1a/62c65c30292499084ed907a5714d7c7764fb05ede6160d34ae12e9c548ea/tweetScraping-1.0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.0.2": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8099debef9cf9ca2b1064abc21db35d8b36165b50c61938e1bbb40c396a9e763",
          "md5": "ae40c6542fb159d65c74e4089e3572c7",
          "sha256": "e55a216371ce19d7c97ee96c7f4d5a14970f65f36d0df655c85adafa270cc3ef"
        },
        "downloads": -1,
        "filename": "tweetScraping-1.0.2-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ae40c6542fb159d65c74e4089e3572c7",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 7280,
        "upload_time": "2021-08-05T07:42:49",
        "upload_time_iso_8601": "2021-08-05T07:42:49.820157Z",
        "url": "https://files.pythonhosted.org/packages/80/99/debef9cf9ca2b1064abc21db35d8b36165b50c61938e1bbb40c396a9e763/tweetScraping-1.0.2-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8bd29a4aed72734844788314c3f25ffdf798e8428cfe80e1fb83c6be4c7ac26e",
          "md5": "098588c4c70be3b182ce51230feec71f",
          "sha256": "fa8d87902b3046eeb7708ee85f863755dbd61121b2dd8c0b756b0ae3a11d18ea"
        },
        "downloads": -1,
        "filename": "tweetScraping-1.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "098588c4c70be3b182ce51230feec71f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 9039,
        "upload_time": "2021-08-05T07:42:53",
        "upload_time_iso_8601": "2021-08-05T07:42:53.182666Z",
        "url": "https://files.pythonhosted.org/packages/8b/d2/9a4aed72734844788314c3f25ffdf798e8428cfe80e1fb83c6be4c7ac26e/tweetScraping-1.0.2.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "8099debef9cf9ca2b1064abc21db35d8b36165b50c61938e1bbb40c396a9e763",
        "md5": "ae40c6542fb159d65c74e4089e3572c7",
        "sha256": "e55a216371ce19d7c97ee96c7f4d5a14970f65f36d0df655c85adafa270cc3ef"
      },
      "downloads": -1,
      "filename": "tweetScraping-1.0.2-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "ae40c6542fb159d65c74e4089e3572c7",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 7280,
      "upload_time": "2021-08-05T07:42:49",
      "upload_time_iso_8601": "2021-08-05T07:42:49.820157Z",
      "url": "https://files.pythonhosted.org/packages/80/99/debef9cf9ca2b1064abc21db35d8b36165b50c61938e1bbb40c396a9e763/tweetScraping-1.0.2-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "8bd29a4aed72734844788314c3f25ffdf798e8428cfe80e1fb83c6be4c7ac26e",
        "md5": "098588c4c70be3b182ce51230feec71f",
        "sha256": "fa8d87902b3046eeb7708ee85f863755dbd61121b2dd8c0b756b0ae3a11d18ea"
      },
      "downloads": -1,
      "filename": "tweetScraping-1.0.2.tar.gz",
      "has_sig": false,
      "md5_digest": "098588c4c70be3b182ce51230feec71f",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 9039,
      "upload_time": "2021-08-05T07:42:53",
      "upload_time_iso_8601": "2021-08-05T07:42:53.182666Z",
      "url": "https://files.pythonhosted.org/packages/8b/d2/9a4aed72734844788314c3f25ffdf798e8428cfe80e1fb83c6be4c7ac26e/tweetScraping-1.0.2.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}