{
  "info": {
    "author": "Joe Zuntz",
    "author_email": "joe.zuntz@ed.ac.uk",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: BSD License",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3 :: Only",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8"
    ],
    "description": "Overview\n--------\n\nThis package collects tools which compute weighted statistics on parallel, incremental data, i.e. data being read by multiple processors, a chunk at a time.  \n\nThe tools available are:\n- ``ParallelSum``\n- ``ParallelMean``\n- ``ParallelMeanVariance``\n- ``ParallelHistogram``\n- ``SparseArray``\n\nAll assume that mpi4py is being used among the processes, and are passed a communicator object (often ``mpi4py.MPI.COMM_WORLD``).\n\nInstallation\n------------\n\nFor now you can install this package using:\n\n```\npip install parallel_statistics\n```\n\nDocumentation\n-------------\n\nDocumentation can be found at https://parallel-statistics.readthedocs.io/\n\nExample\n-------\n\nThe three tools ``ParallelSum``, ``ParallelMean``, and ``ParallelMeanVariance`` compute statistics in bins, and you add data to them per bin.\n\nThe usage pattern for them, and ``ParallelHistogram``, is:\n\n- Create a parallel calculator object in each MPI process\n- Have each process read in their own chunks of data and add it using the ``add_data`` methods\n- Once complete, call the ``collect`` method to get the combined results.\n\nHere's an example of splitting up data from an HDF5 file, using an example from the DESC tomographic challenge.  You can run it either on its own, or under MPI with different numbers of processors, and the results should be the same:\n\n```python\nimport mpi4py.MPI\nimport h5py\nimport parallel_statistics\nimport numpy as np\n\n# This data file is available at\n# https://portal.nersc.gov/project/lsst/txpipe/tomo_challenge_data/ugrizy/mini_training.hdf5\nf = h5py.File(\"mini_training.hdf5\", \"r\")\ncomm = mpi4py.MPI.COMM_WORLD\n\n# We must divide up the data between the processes\n# Choose the chunk sizes to use here\nchunk_size = 1000\ntotal_size = f['redshift_true'].size\nnchunk = total_size // chunk_size\nif nchunk * chunk_size < total_size:\n    nchunk += 1\n\n# Choose the binning in which to put values\nnbin = 20\ndz = 0.2\n\n# Make our calculator\ncalc = parallel_statistics.ParallelMeanVariance(size=nbin)\n\n# Loop through the data\nfor i in range(nchunk):\n    # Each process only reads its assigned chunks,\n    # otherwise, skip this chunk\n    if i % comm.size != comm.rank:\n        continue\n    # work out the data range to read\n    start = i * chunk_size\n    end = start + chunk_size\n\n    # read in the input data\n    z = f['redshift_true'][start:end]\n    r = f['r_mag'][start:end]\n\n    # Work out which bins to use for it\n    b = (z / dz).astype(int)\n\n    # add add each one\n    for j in range(z.size):\n        # skip inf, nan, and sentinel values\n        if not r[j] < 30:\n            continue\n        # add each data point\n        calc.add_datum(b[j], r[j])\n\n# Finally, collect the results together\nweight, mean, variance = calc.collect(comm)\n\n# Print out results - only the root process gets the data, unless you pass\n# mode=allreduce to collect.  Will print out NaNs for bins with no objects in.\nif comm.rank == 0:\n    for i in range(nbin):\n        print(f\"z = [{ dz * i :.1f} .. { dz * (i+1) :.1f}]    r = { mean[i] :.2f} Â± { variance[i] :.2f}\")\n```\n\n\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/LSSTDESC/parallel_statistics",
    "keywords": "MPI,statistics",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "parallel-statistics",
    "package_url": "https://pypi.org/project/parallel-statistics/",
    "platform": null,
    "project_url": "https://pypi.org/project/parallel-statistics/",
    "project_urls": {
      "Homepage": "https://github.com/LSSTDESC/parallel_statistics"
    },
    "release_url": "https://pypi.org/project/parallel-statistics/0.13/",
    "requires_dist": null,
    "requires_python": ">=3.6",
    "summary": "Calculating basic statistics in parallel, incrementally",
    "version": "0.13",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17433085,
  "releases": {
    "0.10": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a4290f571177c76dcf597d6db2377b890319368aec3b92df5df89c2472212501",
          "md5": "5a54ca2cf77c5ab5c3ab58a7af16f4e4",
          "sha256": "4655fbd0ad37ad8ca6bbaf0db54e1b14ee679f9cc803e0b47c51e3fd0271ba31"
        },
        "downloads": -1,
        "filename": "parallel_statistics-0.10.tar.gz",
        "has_sig": false,
        "md5_digest": "5a54ca2cf77c5ab5c3ab58a7af16f4e4",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 10384,
        "upload_time": "2020-08-05T14:17:34",
        "upload_time_iso_8601": "2020-08-05T14:17:34.034166Z",
        "url": "https://files.pythonhosted.org/packages/a4/29/0f571177c76dcf597d6db2377b890319368aec3b92df5df89c2472212501/parallel_statistics-0.10.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.11": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d4ac21d210c8e9a2bc9fd61d74c2f3efacee4514463ad7f894da4382d2e676ec",
          "md5": "fc0df52c0265c50ef72caeec0ddb6f3f",
          "sha256": "44d2f1df1450e66828a3a7c8705f8bd402a7a78e8bb997b7720613a83f91b1b6"
        },
        "downloads": -1,
        "filename": "parallel_statistics-0.11.tar.gz",
        "has_sig": false,
        "md5_digest": "fc0df52c0265c50ef72caeec0ddb6f3f",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 10873,
        "upload_time": "2021-02-17T11:14:30",
        "upload_time_iso_8601": "2021-02-17T11:14:30.741179Z",
        "url": "https://files.pythonhosted.org/packages/d4/ac/21d210c8e9a2bc9fd61d74c2f3efacee4514463ad7f894da4382d2e676ec/parallel_statistics-0.11.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.12": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "49aa34741c1b83cc855a68742439f94dc14ec4ec4adb501ed0d8bfa4a9c49ab4",
          "md5": "b48a78324733f59d23654d257f355f25",
          "sha256": "7a7f8166f1475c1ace9341a3b0fce753f29683375e81f5a28c5f1c8951f2a4bf"
        },
        "downloads": -1,
        "filename": "parallel_statistics-0.12.tar.gz",
        "has_sig": false,
        "md5_digest": "b48a78324733f59d23654d257f355f25",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 11504,
        "upload_time": "2021-03-29T15:39:26",
        "upload_time_iso_8601": "2021-03-29T15:39:26.061108Z",
        "url": "https://files.pythonhosted.org/packages/49/aa/34741c1b83cc855a68742439f94dc14ec4ec4adb501ed0d8bfa4a9c49ab4/parallel_statistics-0.12.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.13": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8dc309d1fa59a9e81c89edf6561222860a4d56b383fa40ff35b1a3fa0c087cb1",
          "md5": "1b9045a763df1764d622d45c728f10af",
          "sha256": "8b9ac2f35bdbe773295941221b7981f1a0388cd702e4eab9343bcd9d3098a340"
        },
        "downloads": -1,
        "filename": "parallel_statistics-0.13.tar.gz",
        "has_sig": false,
        "md5_digest": "1b9045a763df1764d622d45c728f10af",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 11945,
        "upload_time": "2023-03-24T15:51:18",
        "upload_time_iso_8601": "2023-03-24T15:51:18.677168Z",
        "url": "https://files.pythonhosted.org/packages/8d/c3/09d1fa59a9e81c89edf6561222860a4d56b383fa40ff35b1a3fa0c087cb1/parallel_statistics-0.13.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.9.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "651e0e9c9badcaf25160336296fcc9b3a5fcda532765dc37e17aa8ff584527b8",
          "md5": "1ff79f31d351758e9bd1141af08b32f3",
          "sha256": "4147016a8bec81b9b5bdaf8a78b15b043f601dc82686a2b73e926ccfbd3829b7"
        },
        "downloads": -1,
        "filename": "parallel_statistics-0.9.0.tar.gz",
        "has_sig": false,
        "md5_digest": "1ff79f31d351758e9bd1141af08b32f3",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 10500,
        "upload_time": "2020-07-29T13:38:20",
        "upload_time_iso_8601": "2020-07-29T13:38:20.714785Z",
        "url": "https://files.pythonhosted.org/packages/65/1e/0e9c9badcaf25160336296fcc9b3a5fcda532765dc37e17aa8ff584527b8/parallel_statistics-0.9.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.9.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1e897a554ef791dfaccc3de64a9aff64fccb6f5f60f09431a21f8fa5feb8017d",
          "md5": "5c5f290722ac405bc7e14274b312f4db",
          "sha256": "31a9f1bf15b3f51b67363a95c1cfb0d6605801a9f7685abecfbcf6a1e37fa779"
        },
        "downloads": -1,
        "filename": "parallel_statistics-0.9.1.tar.gz",
        "has_sig": false,
        "md5_digest": "5c5f290722ac405bc7e14274b312f4db",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.6",
        "size": 10585,
        "upload_time": "2020-07-31T09:41:40",
        "upload_time_iso_8601": "2020-07-31T09:41:40.210780Z",
        "url": "https://files.pythonhosted.org/packages/1e/89/7a554ef791dfaccc3de64a9aff64fccb6f5f60f09431a21f8fa5feb8017d/parallel_statistics-0.9.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "8dc309d1fa59a9e81c89edf6561222860a4d56b383fa40ff35b1a3fa0c087cb1",
        "md5": "1b9045a763df1764d622d45c728f10af",
        "sha256": "8b9ac2f35bdbe773295941221b7981f1a0388cd702e4eab9343bcd9d3098a340"
      },
      "downloads": -1,
      "filename": "parallel_statistics-0.13.tar.gz",
      "has_sig": false,
      "md5_digest": "1b9045a763df1764d622d45c728f10af",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.6",
      "size": 11945,
      "upload_time": "2023-03-24T15:51:18",
      "upload_time_iso_8601": "2023-03-24T15:51:18.677168Z",
      "url": "https://files.pythonhosted.org/packages/8d/c3/09d1fa59a9e81c89edf6561222860a4d56b383fa40ff35b1a3fa0c087cb1/parallel_statistics-0.13.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}