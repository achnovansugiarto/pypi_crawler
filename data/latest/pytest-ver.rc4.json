{
  "info": {
    "author": "JA",
    "author_email": "cppgent0@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Framework :: Pytest",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3.9",
      "Topic :: Software Development :: Testing :: Acceptance"
    ],
    "description": "# pytest-ver\r\n\r\ncurrent state: still under development\r\n\r\nThis module is used to write verification test cases\r\nwithin a Python & pytest environment. FDA compliant reports can\r\nthen be generated.\r\n\r\nThe verification test cases are written in Python which uses\r\nthe pytest module to invoke the test cases. During\r\nexecution, various data is captured. The data is then used by\r\nthe report facility to generate Test Protocol, Test Report\r\nand Trace Matrix documents in docx, pdf and text formats. A\r\nsummary is also generated indicating percentage of requirements\r\nthat are complete, passing/failing etc.\r\n\r\nThis repo is used to develop pytest-ver. See the matching\r\nrepo https://github.com/cppgent0/pytest-ver-tutorial for\r\nfull details of how to use it. There is a User Guide with full\r\ndetails there. That repo tests a simulated IV pump\r\napplication, including a set of requirements and test scripts\r\nthat use pytest-ver. A sample set of reports can be generated\r\nand reviewed.\r\n\r\nThere are also a couple of repos that have used pytest-ver as\r\nproof-of-concept:\r\n\r\n* https://github.com/cppgent0/socket-oneline\r\n* https://github.com/cppgent0/gui-api-tkinter\r\n\r\nCaveat: these are still under development and may have some\r\nissues\r\n\r\n## Usage\r\n\r\n* See repo https://github.com/cppgent0/pytest-ver-tutorial\r\n  for full instructions on how to use pytest-ver\r\n\r\n* User Guide.docx in the pytest-ver-tutorial repo for additional details\r\n\r\n### Quick Guide\r\n\r\n* the file test_sample.py shows various examples of using pytest-ver.\r\n* to invoke all tests use:\r\n\r\n```bash\r\n./doit\r\n```\r\n\r\nor invoke one test case:\r\n\r\n```bash\r\n# the \"-k\" switch is part of pytest\r\n./doit -k test_0\r\n```\r\n\r\n### invoking the test_sample script\r\n\r\nThe test is run in doit by:\r\n\r\n```bash\r\nfunction run_verification()\r\n```\r\n\r\nThe report is run in doit by:\r\n\r\n```bash\r\nfunction run_report()\r\n```\r\n\r\nsee out/ver directory for pdf or docx reports\r\n\r\n## Installation\r\n\r\nThe doc/installation_*.md files contain additional information\r\nfor installing pytest-ver\r\nfor various supported platforms:\r\n\r\n* installation_macos.md : MAC OS\r\n* installation_msys2.md : MSYS2 on Windows\r\n* installation_ubu.md   : Ubuntu\r\n\r\n## Python environment\r\n\r\nNote that the set_env.sh script sets the python environment for\r\nvarious platforms\r\nand sets variables\r\n\r\n* $pyexe - the python executable\r\n* $pybin - the location of the environment bin directory\r\n\r\n```bash\r\nsource set_env.sh\r\nsource \"${pybin}/activate\"\r\n# ... skip ...\r\n$pyexe helpers/ver_report.py\r\n````\r\n\r\n## Report Output\r\n\r\n* the output files are in the out/ver directory\r\n\r\n```bash\r\nls out/ver\r\npytest_ver.log   # the log output\r\npytest_ver.txt   # output from doit script\r\n*_protocol.json  # data generated during the test case run\r\nsummary.docx     # docx version of summary document\r\nsummary.pdf      # pdf version of summary document\r\nsummary.txt      # text version of summary document\r\ntest_protocol.*  # test protocol document in various formats\r\ntest_report.*    # test report document in various formats\r\ntrace.*          # trace matrix document in various formats \r\n```\r\n\r\n## Check conftest.py\r\n\r\nIf you want to use the pytest-ver command line switches from pytest,\r\nensure you call the cli_addoption() and cli_configure() functions in conftest.py\r\n\r\n```python\r\nfrom pytest_ver import pth\r\n\r\n\r\n# -------------------\r\ndef pytest_addoption(parser):\r\n    pth.cfg.cli_addoption(parser)\r\n\r\n\r\n# -------------------\r\ndef pytest_configure(config):\r\n    pth.cfg.cli_configure(config)\r\n```\r\n\r\n## Writing a test case\r\n\r\n* import unittest and pytest as normal. Then import pytest_ver:\r\n\r\n```python\r\nimport unittest\r\nimport pytest\r\nfrom pytest_ver import pth\r\n```\r\n\r\nNote: 'pth' is a global that holds a reference to PytestHarness.\r\nThe harness holds references to all classes needed during a test run.\r\n\r\n* next create a normal unit test for pytest/unitest\r\n\r\n```python\r\n# -------------------\r\nclass TestSample(unittest.TestCase):\r\n    # --------------------\r\n    @classmethod\r\n    def setUpClass(cls):\r\n        pth.init()\r\n\r\n    # -------------------\r\n    def setUp(self):\r\n        pass\r\n\r\n    # -------------------\r\n    def tearDown(self):\r\n        pass\r\n\r\n    # --------------------\r\n    @classmethod\r\n    def tearDownClass(self):\r\n        pth.term()\r\n```\r\n\r\n* To create a protocol use pth.proto.protocol() with a protocol\r\n  id and description\r\n* To create steps within that protocol, use pth.proto.step()\r\n\r\n```python\r\n# --------------------\r\ndef test_0(self):\r\n    # declare a new protcol id and it's description\r\n    pth.proto.protocol('tp-000', 'basic pass/fail tests')\r\n    pth.proto.set_dut_serialno('sn-0123')\r\n\r\n    pth.proto.step('try checks with 1 failure')\r\n    pth.ver.verify_equal(1, 2, reqids='SRS-001')\r\n    pth.ver.verify_equal(1, 1, reqids='SRS-002')\r\n    pth.ver.verify_equal(1, 1, reqids='SRS-003')\r\n    pth.proto.comment('should be 1 failure and 2 passes')\r\n```\r\n\r\nat this point, there is one protocol TP-000 that has 1 step.\r\n\r\nUse doit to run it:\r\n\r\n```bash\r\n./doit -k test_0\r\n```\r\n\r\n### Output\r\n\r\nCheck the stdout or the out/ver/pytest_ver.txt file:\r\n\r\n* indicates that a failure occured\r\n* the return code from the script is non-zero\r\n\r\n### Report documents\r\n\r\nCheck the generated documents in the out/ver/ dirctory.\r\n\r\n* summary.pdf should indicate:\r\n    * there are a total of 7 requirements (see srs_sample.json)\r\n    * there are 2 passing requirements wghich is 28.8% of all\r\n      requirements\r\n    * there is 1 failing requirement which is 14.3% of all\r\n      requirements\r\n    * there are 4 requirements that were not tested which is\r\n      57.1% of all requirements\r\n\r\n* test_report.pdf and/or test_protocol.pdf should indicate:\r\n* the test run type is \"dev\" so this was not a formal run\r\n* the test run id is \"dev-001\". This can be set in cfg.json to\r\n  track individual test runs\r\n* the date time the document was generated\r\n\r\n* There should be one protocol TP-000\r\n* The location of the protocol is test_sample.py(line number)\r\n* The protocol had only 1 step which tested requirement SRS-001\r\n* The report document shows the expected and actual values and\r\n  that result was a FAIL,\r\n  and the location of the failing verify() function\r\n* The report document shows a comment\r\n* There is table after the protocol showing the requirement\r\n  SRS-001 and it's description\r\n* Note the header and footer information comes from the cfg.json\r\n  file\r\n\r\n### Pytest markers\r\n\r\n* you can use pytest markers as normal\r\n\r\n```python\r\n# --------------------\r\n# @pytest.mark.skip(reason='skip')\r\n@pytest.mark.smoketest1\r\ndef test_init2(self):\r\n    pth.proto.protocol('tp-002', 'test the init2')\r\n\r\n    pth.proto.step('verify1 everything is equal')\r\n    pth.ver.verify(1 == 1, reqid='SRS-001')\r\n    # note: this is the second time this requirment is verified\r\n\r\n\r\n# --------------------\r\n# @pytest.mark.skip(reason='skip')\r\ndef test_init3(self):\r\n    pth.proto.protocol('tp-003', 'test the init3')\r\n\r\n    pth.proto.step('verify1 everything is equal')\r\n    pth.ver.verify(1 == 1, reqid='SRS-004')\r\n```\r\n\r\n## Verification Functions\r\n\r\n* To create verification tests use pth.ver.verify()\r\n\r\n```python\r\n# note: you can use normal pytest and unitest functions\r\n# but their results won't show up in the report\r\nself.assertEqual(x, y)\r\n\r\n# do a verification against a requirement\r\npth.ver.verify_equal(x, y, reqid='SRS-001')\r\npth.ver.verify_equal(x, 1, reqid='SRS-001')\r\n# since all verifys passed, this step's result is PASS\r\n\r\npth.proto.step('verify2')\r\npth.ver.verify(False, reqid='SRS-002')\r\npth.ver.verify(True, reqid='SRS-002')\r\npth.ver.verify(True, reqid='SRS-002')\r\n# since one verify failed, this step's result is FAIL\r\n\r\npth.proto.step('verify3')\r\npth.ver.verify(True, reqid='SRS-003')\r\npth.ver.verify(True, reqid='SRS-003')\r\npth.ver.verify(False, reqid='SRS-003')\r\n# since one verify failed, this step's result is FAIL\r\n```\r\n\r\n* See doc/User Guide.docx for a full list of verification\r\n  functions\r\n\r\n```python\r\nverify(actual)  # verify actual is true\r\nverify_true(actual)  # verify actual is true\r\nverify_false(actual)  # verify actual is false\r\nverify_equal(expected, actual)  # verify actual == expected\r\nverify_not_equal(expected, actual)  # verify actual != expected\r\nverify_none(actual)  # verify actual is None\r\nverify_is_none(actual)  # verify actual is None\r\nverify_not_none(actual)  # verify actual is not None\r\nverify_in(actual, exp_list)  # verify actual is in the expected list\r\nverify_not_in(actual, exp_list)  # verify actual is not in the expected list\r\nverify_lt(left, right)  # verify left < right\r\nverify_le(left, right)  # verify left <= right\r\nverify_gt(left, right)  # verify left > right\r\nverify_ge(left, right)  # verify left >= right\r\nverify_reqex(actual, regex)  # verify actual matches the regex\r\nverify_not_reqex(actual, regex)  # verify actual does not matche the regex\r\nverify_delta(expected, actual, abs_tolerance)  # verify actual == expected within +/- tolerance\r\nverify_not_delta(expected, actual, abs_tolerance)  # verify actual outside +/- tolerance\r\nverify_delta_pct(expected, actual, pct_tolerance)  # verify actual == expected within +/- percent\r\nverify_not_delta_pct(expected, actual, pct_tolerance)  # verify actual outside +/- percent\r\n```\r\n\r\n* A pass does not generate any stdout\r\n* A fail reports various information\r\n    * the location of the failure\r\n    * the expected value (and it's python type)\r\n    * the actual value (and it's python type)\r\n    * a traceback at the time of the failures\r\n\r\n```bash\r\nFAILURE: at test_sample.py(37)\r\n   Expected (int)     : 1\r\n   Actual   (int)     : 2\r\ntest_sample.py:37 in test_0() -> pth.ver.verify_equal(1, 2, reqids='SRS-001')\r\npytest_ver/lib/verifier.py:98 in verify_equal() -> self._handle_fail(rs)\r\npytest_ver/lib/verifier.py:412 in _handle_fail() -> raise AssertionError(f'at {rs.location}{msg}')\r\n```\r\n\r\n* The test_report.txt document shows some additional information:\r\n    * the protocol id and description and its location\r\n    * which step failed\r\n    * the date time stamp (dts) when the failure occurred\r\n    * the requirement id\r\n\r\n```bash\r\n==== protocol: TP-000 basic pass/fail tests\r\n     location: test_sample.py(33)\r\n     Step 1  : try checks with 1 failure\r\n       > dts          : 2022-12-11 06:00:52\r\n       > result       : FAIL\r\n       > actual       : 2\r\n       > actual raw   : 2\r\n       > expected     : 1\r\n       > expected raw : 1\r\n       > reqids       : {'SRS-001': 1}\r\n       > location     : test_sample.py(37)\r\n```\r\n\r\n## Generate Report\r\n\r\n* to generate a report use: pth.report()\r\n\r\n* see helpers/ver_report.py\r\n\r\n```python\r\nimport os\r\nimport sys\r\n\r\nsys.path.insert(1, os.path.join('.'))\r\n\r\nfrom pytest_ver import *  # noqa\r\n\r\n# generate the report\r\npth.cfg.cli_parse()\r\n# force iuvmode to be\r\npth.cfg.cli_set('iuvmode', False)\r\n\r\npth.init(report_mode=True)\r\npth.report()\r\npth.term()\r\n```\r\n\r\nto invoke it:\r\n\r\n```bash\r\n$pyexe helpers/ver_report.py\r\n```\r\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "https://bitbucket.org/arrizza-public/pytest-ver/get/master.zip",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://bitbucket.org/arrizza-public/pytest-ver/src/master",
    "keywords": "verification,pytest",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "pytest-ver",
    "package_url": "https://pypi.org/project/pytest-ver/",
    "platform": null,
    "project_url": "https://pypi.org/project/pytest-ver/",
    "project_urls": {
      "Download": "https://bitbucket.org/arrizza-public/pytest-ver/get/master.zip",
      "Homepage": "https://bitbucket.org/arrizza-public/pytest-ver/src/master"
    },
    "release_url": "https://pypi.org/project/pytest-ver/0.0.44/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "Pytest module with Verification Protocol, Verification Report and Trace Matrix",
    "version": "0.0.44",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17390807,
  "releases": {
    "0.0.41": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "6e9a79076a8915a71364b384cd7013cb3c3ada0cc3ae0652a41be00738371d62",
          "md5": "2b284cbcdd1ee4984cab02d13b0f21ed",
          "sha256": "25a52c92155d5ce1d82af1ce808218d553fb57e55bfa2409b0db53844161b364"
        },
        "downloads": -1,
        "filename": "pytest-ver-0.0.41.tar.gz",
        "has_sig": false,
        "md5_digest": "2b284cbcdd1ee4984cab02d13b0f21ed",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 49095,
        "upload_time": "2023-03-04T22:22:09",
        "upload_time_iso_8601": "2023-03-04T22:22:09.550984Z",
        "url": "https://files.pythonhosted.org/packages/6e/9a/79076a8915a71364b384cd7013cb3c3ada0cc3ae0652a41be00738371d62/pytest-ver-0.0.41.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.42": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "51d1c4a7f1b4dc7a224535025e09253e81911df662ac3a62396512059f3dd98e",
          "md5": "f7178457d3f6cb088ae8736eef2d1222",
          "sha256": "270abb6ceeb7aaf844fd542ae41a82d0bd054cc48b8ceb47c6568939a629e141"
        },
        "downloads": -1,
        "filename": "pytest-ver-0.0.42.tar.gz",
        "has_sig": false,
        "md5_digest": "f7178457d3f6cb088ae8736eef2d1222",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 49254,
        "upload_time": "2023-03-05T05:04:34",
        "upload_time_iso_8601": "2023-03-05T05:04:34.282626Z",
        "url": "https://files.pythonhosted.org/packages/51/d1/c4a7f1b4dc7a224535025e09253e81911df662ac3a62396512059f3dd98e/pytest-ver-0.0.42.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.43": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "8a6af217b47a26fa1cb1afc42d5afad3e240cfb927c01fdea0436d9c6230c447",
          "md5": "3fdea9df1f22d901e71f564422691a1c",
          "sha256": "7844085516097044ae0795e7c8f98d041f3ea875dcb24c8824c3b34af45716cd"
        },
        "downloads": -1,
        "filename": "pytest-ver-0.0.43.tar.gz",
        "has_sig": false,
        "md5_digest": "3fdea9df1f22d901e71f564422691a1c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 49246,
        "upload_time": "2023-03-21T03:20:59",
        "upload_time_iso_8601": "2023-03-21T03:20:59.428872Z",
        "url": "https://files.pythonhosted.org/packages/8a/6a/f217b47a26fa1cb1afc42d5afad3e240cfb927c01fdea0436d9c6230c447/pytest-ver-0.0.43.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.0.44": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "ce8785042f955de415dda87961dec7ed4e2a533c9bf8e64872b7976d929587d1",
          "md5": "549f1832e8ef6910e3be479db7ba3c68",
          "sha256": "ca753d5bec479a95168ac2dfdad7d86cf493d5c4d74ff69bfbc0105a9f3d6d05"
        },
        "downloads": -1,
        "filename": "pytest-ver-0.0.44.tar.gz",
        "has_sig": false,
        "md5_digest": "549f1832e8ef6910e3be479db7ba3c68",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 49212,
        "upload_time": "2023-03-22T00:38:33",
        "upload_time_iso_8601": "2023-03-22T00:38:33.065652Z",
        "url": "https://files.pythonhosted.org/packages/ce/87/85042f955de415dda87961dec7ed4e2a533c9bf8e64872b7976d929587d1/pytest-ver-0.0.44.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "ce8785042f955de415dda87961dec7ed4e2a533c9bf8e64872b7976d929587d1",
        "md5": "549f1832e8ef6910e3be479db7ba3c68",
        "sha256": "ca753d5bec479a95168ac2dfdad7d86cf493d5c4d74ff69bfbc0105a9f3d6d05"
      },
      "downloads": -1,
      "filename": "pytest-ver-0.0.44.tar.gz",
      "has_sig": false,
      "md5_digest": "549f1832e8ef6910e3be479db7ba3c68",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 49212,
      "upload_time": "2023-03-22T00:38:33",
      "upload_time_iso_8601": "2023-03-22T00:38:33.065652Z",
      "url": "https://files.pythonhosted.org/packages/ce/87/85042f955de415dda87961dec7ed4e2a533c9bf8e64872b7976d929587d1/pytest-ver-0.0.44.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}