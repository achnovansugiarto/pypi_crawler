{
  "info": {
    "author": "earlsuke",
    "author_email": "ryosuke.mitani@gmail.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "## lexpp : 同義語辞書による日本語テキストへの前処理ツール\n\n**このモジュールは開発中です**\n\n### このモジュールについて\n\nこのモジュールはトークナイズされた辞書登録単位への同義語関連の処理を提供します．\n日本語における同義語が収められたデフォルト辞書として[SudachiDict](https://github.com/WorksApplications/SudachiDict)の[synonym辞書](https://github.com/WorksApplications/SudachiDict/blob/develop/docs/synonyms.md)\nを利用しています．\n\n### インストール方法\n\n```pip install lexpp```\n\n### 使い方\n\n```python\nimport lexpp as lp\npp = lp.Lexpp()\n```\n\n現在のバージョンでは，下記の機能を提供しています．\n\n1. 文字列を辞書引きして，辞書に登録されている情報(Entry)を呼び出す．  lookup(surface: str) -> Tuple(Entry)\n```python\nTESTCASE = \"マンガ喫茶\"\nresult = pp.lookup(TESTCASE)\n```\n\n2. Entryをキーとして，同じグループに登録されている文字列集合を得る．  get_synset(e: Entry) -> Tuple(str)\n```python\nentry = result[0]\nsynonyms = pp.get_synset(entry)\n# synonyms = [\"漫画喫茶\", \"まんが喫茶\", \"マンガ喫茶\", \"漫喫\", \"まん喫\", \"マン喫\"]\n```\n\n3. Entryをキーとして，代表表記として登録されている文字列を得る．      get_representive_form(e: Entry) -> str\n```python\nrepr_form = pp.get_representive_form(entry)\n# repr_form = \"漫画喫茶\"\n```\n\n4. 複数の文字列をクエリとして，共通して登録されているグループIDの集合を得ます．共通して登録されているグループが存在しない場合は，空の集合が返されます． get_common_category_id_set(surfaces: List[str]) -> Set[int]\n```python\nTESTCASE_LIST = [\"漫画喫茶\", \"まんが喫茶\", \"マンガ喫茶\", \"漫喫\", \"まん喫\", \"マン喫\"]\ngid_set = pp.get_common_category_id_set(TESTCASE_LIST)\n# gid_set = {27}\n```\n\nサンプルコードを下記に示します．\n\n[samples/sample.py](samples/sample.py)\n\n### 独自辞書の作り方\n\n```python -m lexpp.dict_builder --input {your dictioanry} --output {output filename}```\n\n注意点: 入力ファイルは[synonym辞書](https://github.com/WorksApplications/SudachiDict/blob/develop/docs/synonyms.md)と同じフォーマットであることを想定しています．\n\nビルド後，Lexppクラスのインスタンスのパラメータとしてファイル名を指定してください．\n\n```python\npp = Lexpp(external_dict_path = {your dictionary})\n```\n\n### ライセンス\n\n[Apache 2.0ライセンス](http://www.apache.org/licenses/LICENSE-2.0)の条件下にて，利用していただけます．\nこのソフトウェアには, [Apache 2.0ライセンス](http://www.apache.org/licenses/LICENSE-2.0)で配布されている製作物が含まれています.\n\n### 参考文献\n\n* 有用なデータセットの公開に感謝します．[SudachiDict](https://github.com/WorksApplications/SudachiDict)\n\n------------------------------------\n\n## lexpp: lexical pre-processing module for Japanese text\n\n***THIS MODULE IS UNDER DEVELOPING***\n\n### What this module is\n\n  This module provides you to pre-process Japanese text by using lexical knowledge. The default dictionary is built based on [Sudachi synonym dict](https://github.com/WorksApplications/SudachiDict/blob/develop/docs/synonyms.md).\n\n\n### How to install\n```pip install lexpp```\n\n### How to use\n\n```python\nimport lexpp as lp\npp = lp.Lexpp()\n```\n\nThe current version of the software provides the following utilities.\n\n1. Lookup a key string from the dictionary to get lexical entities.    lookup(surface: str) -> Tuple(Entry)\n```python\nTESTCASE = \"マンガ喫茶\"\nresult = pp.lookup(TESTCASE)\n```\n2. Lookup a key entry to obtain a synset(a set of synonyms).  get_synset(e: Entry) -> Tuple(str)\n```python\nentry = result[0]\nsynonyms = pp.get_synset(entry)\n# synonyms = [\"漫画喫茶\", \"まんが喫茶\", \"マンガ喫茶\", \"漫喫\", \"まん喫\", \"マン喫\"]\n```\n3. Transform a key entry into a string of representive form.  get_representive_form(e: Entry) -> str\n```python\nrepr_form = pp.get_representive_form(entry)\n# repr_form = \"漫画喫茶\"\n```\n4. Lookup a set of group id which is commonly registered among the input surface list. If no groups existed , an empty set will be returned.  get_common_category_id_set(surfaces: List[str]) -> Set[int]\n```python\nTESTCASE_LIST = [\"漫画喫茶\", \"まんが喫茶\", \"マンガ喫茶\", \"漫喫\", \"まん喫\", \"マン喫\"]\ngid_set = pp.get_common_category_id_set(TESTCASE_LIST)\n# gid_set = {27}\n```\n\nFor more details, See [samples/sample.py](samples/sample.py)\n\n### How to build your dictionary\n\n```python -m lexpp.dict_builder --input {your dictioanry} --output {output filename}```\n\nNOTE: The input file must be formatted by [the Sudachi synonym dict format]((https://github.com/WorksApplications/SudachiDict/blob/develop/docs/synonyms.md).\n\nWhen instantiating Lexpp class, specify to your dictionary as a parameter.\n\n```pp = Lexpp(external_dict_path = {your dictionary})```\n\n### License\n\nThis software is licensed under [Apache 2.0](http://www.apache.org/licenses/LICENSE-2.0).\n\nThis software contains the derivative from the product developed under [Apache 2.0](http://www.apache.org/licenses/LICENSE-2.0).\n\n### References\n* Thanks to [SudachiDict](https://github.com/WorksApplications/SudachiDict) for releasing useful resources.\n\n\n",
    "description_content_type": "",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "https://github.com/earlsuke",
    "keywords": "",
    "license": "Apache-2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "lexpp",
    "package_url": "https://pypi.org/project/lexpp/",
    "platform": "",
    "project_url": "https://pypi.org/project/lexpp/",
    "project_urls": {
      "Homepage": "https://github.com/earlsuke"
    },
    "release_url": "https://pypi.org/project/lexpp/1.1.0/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "A lexical pre-processing module for Japanese text",
    "version": "1.1.0",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 6376064,
  "releases": {
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "cf78ebfb3bc7c70875b991e7315abf5aadc4a1d92e56988a2c79a380b7d9f76a",
          "md5": "f9f59b039f7ae45e0cec34267a435f7c",
          "sha256": "d2938369932269187d4d398b289f66d468427fe543065742ad396f174549da1c"
        },
        "downloads": -1,
        "filename": "lexpp-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "f9f59b039f7ae45e0cec34267a435f7c",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 1549609,
        "upload_time": "2019-11-23T09:36:26",
        "upload_time_iso_8601": "2019-11-23T09:36:26.053412Z",
        "url": "https://files.pythonhosted.org/packages/cf/78/ebfb3bc7c70875b991e7315abf5aadc4a1d92e56988a2c79a380b7d9f76a/lexpp-1.0.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "1.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "9069c7a9cdd2cc32dc4ec675eb78fc76b88cca8369bd3474a9d965b66a9b22e4",
          "md5": "e2d057a09ce5ac939e294a5876f4a16e",
          "sha256": "9c74c4a783849cf904f885d553eb4d187e15dae62123d9b24ddb77b2d92fee1b"
        },
        "downloads": -1,
        "filename": "lexpp-1.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "e2d057a09ce5ac939e294a5876f4a16e",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": null,
        "size": 1554726,
        "upload_time": "2019-12-30T17:14:48",
        "upload_time_iso_8601": "2019-12-30T17:14:48.425197Z",
        "url": "https://files.pythonhosted.org/packages/90/69/c7a9cdd2cc32dc4ec675eb78fc76b88cca8369bd3474a9d965b66a9b22e4/lexpp-1.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "df9a225374070d4f7d6fc11bb4a25cd76abc26c1a52d7fb531c5cb24da052134",
          "md5": "81ec135bf72946be372feecbb458ecea",
          "sha256": "b206b0c5b3fc176abb11ddadaccf2dee2783566b7ade350775ca156c246cfb29"
        },
        "downloads": -1,
        "filename": "lexpp-1.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "81ec135bf72946be372feecbb458ecea",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 1550925,
        "upload_time": "2019-12-30T17:14:51",
        "upload_time_iso_8601": "2019-12-30T17:14:51.550764Z",
        "url": "https://files.pythonhosted.org/packages/df/9a/225374070d4f7d6fc11bb4a25cd76abc26c1a52d7fb531c5cb24da052134/lexpp-1.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "9069c7a9cdd2cc32dc4ec675eb78fc76b88cca8369bd3474a9d965b66a9b22e4",
        "md5": "e2d057a09ce5ac939e294a5876f4a16e",
        "sha256": "9c74c4a783849cf904f885d553eb4d187e15dae62123d9b24ddb77b2d92fee1b"
      },
      "downloads": -1,
      "filename": "lexpp-1.1.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "e2d057a09ce5ac939e294a5876f4a16e",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": null,
      "size": 1554726,
      "upload_time": "2019-12-30T17:14:48",
      "upload_time_iso_8601": "2019-12-30T17:14:48.425197Z",
      "url": "https://files.pythonhosted.org/packages/90/69/c7a9cdd2cc32dc4ec675eb78fc76b88cca8369bd3474a9d965b66a9b22e4/lexpp-1.1.0-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "df9a225374070d4f7d6fc11bb4a25cd76abc26c1a52d7fb531c5cb24da052134",
        "md5": "81ec135bf72946be372feecbb458ecea",
        "sha256": "b206b0c5b3fc176abb11ddadaccf2dee2783566b7ade350775ca156c246cfb29"
      },
      "downloads": -1,
      "filename": "lexpp-1.1.0.tar.gz",
      "has_sig": false,
      "md5_digest": "81ec135bf72946be372feecbb458ecea",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 1550925,
      "upload_time": "2019-12-30T17:14:51",
      "upload_time_iso_8601": "2019-12-30T17:14:51.550764Z",
      "url": "https://files.pythonhosted.org/packages/df/9a/225374070d4f7d6fc11bb4a25cd76abc26c1a52d7fb531c5cb24da052134/lexpp-1.1.0.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}