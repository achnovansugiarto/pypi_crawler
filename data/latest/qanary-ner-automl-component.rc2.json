{
  "info": {
    "author": "",
    "author_email": "Annemarie Wittig <wittiganmarie@gmail.com>",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python :: 3"
    ],
    "description": "# Automation Service \n\nThe Automation Service offers the possibility to have an automatically\ngenerated model based on its given data and endpoints to interact with\nit. In this file, the examples given will follow a NER concerning names,\ns.t., it tries to identify *Firstnames*, *Middlenames*, and *Lastnames*.\nHowever, you may define any entities to recognize that you want. A demo\nof the service can be accessed at <http://demos.swe.htwk-leipzig.de>.\n\nThe service can be run as standalone or within a [Qanary-driven Question\nAnswering system](https://github.com/WDAqua/Qanary).\n\nStarting Conditions\n===================\n\nThere are two options (requirements) for starting the service:\n\n-   option 1: a pre-trained model, or\n\n-   option 2: there must be either compatible datasets for training and\n    testing.\n\nOption 1\n--------\n\nIf a pre-trained model is intended to be provided, it must be available\nin the folder\n[AutomationService/AutomationServiceBackend/data/model](./AutomationService/AutomationServiceBackend/data/model)\n(default configuration). The service works only with\n[spaCy](https://spacy.io) models. Hence, your model needs to follow the\nspaCy standards (or should be trained using spaCy). In a netconsole,\njust copy the contents of a trained model (usually in the folder\n`model-best` or `model-last`) into the mentioned folder.\n\nOption 2\n--------\n\nIf no pre-trained model is provided, training and testing data must be\nprovided to the system. Otherwise, the web service will not start. Both\nfiles must be provided in the folder\n[AutomationService/AutomationServiceBackend/data/trainingdata](./AutomationService/AutomationServiceBackend/data/trainingdata).\nAdditionally, the file names must be defined in the\n[.env](./AutomationService/.env) file. Both datasets must always be in\nCSV file format and meet the following requirements:\n\n-   Each file contains columns for the input-text (first column) and\n    each entity the model should be able to identify.\n\n-   Then, each data-text is written into the text-column and\n    additionally, the values for each entity inside the text are defined\n    separately in the respective column.\n\n-   If a text does not contain a value for a defined entity, the\n    corresponding cell must be empty.\n\nAn example for an [exemplary CSV-formatted dataset for recognizing names\nof people](./AutomationService/ExampleBodies/name) would be something\nlike this:\n\n<table>\n<colgroup>\n<col style=\"width: 25%\" />\n<col style=\"width: 25%\" />\n<col style=\"width: 25%\" />\n<col style=\"width: 25%\" />\n</colgroup>\n<thead>\n<tr class=\"header\">\n<th>Name</th>\n<th>First_Name</th>\n<th>Middle_Name</th>\n<th>Last_Name</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td><p>I am Ms Walters</p></td>\n<td></td>\n<td></td>\n<td><p>Walters</p></td>\n</tr>\n<tr class=\"even\">\n<td><p>Do you think Silke will come?</p></td>\n<td><p>Silke</p></td>\n<td></td>\n<td><p>startquestionansweringwithtextquestion</p></td>\n</tr>\n<tr class=\"odd\">\n<td><p>I do have a middlename, it’s Heinz-Wilhelm</p></td>\n<td></td>\n<td><p>Heinz-Wilhelm</p></td>\n<td></td>\n</tr>\n<tr class=\"even\">\n<td><p>You can send the data to Ingetraut Renz</p></td>\n<td><p>Ingetraut</p></td>\n<td></td>\n<td><p>Renz</p></td>\n</tr>\n</tbody>\n</table>\n\nTraining and testing data must follow the same basic structure (i.e.,\nthey must have the same column name).\n\nThere are two example environments files given for initial training with\n[name](./.env.template-name-training) or\n[address](./.env.template-address-training) data.\n\nStarting the Service\n====================\n\nTo start the service, docker-compose files are provided. Therefore, you\nneed to have docker and docker-compose installed. Additionally, if you\nwant to use a GPU to train the models, you might need additional\nrequirements based on your drivers / hardware, if not you need to remove\nthe lines from the docker-compose. Refer to the documentation needed for\nthese. Nothing else is needed.\n\nStarting as a standalone Service\n--------------------------------\n\nIf you want to run the service as a standalone, in the root directory\nbuild the images. Please note that if the service runs as a standalone,\nit will be running on the port *8002* per default as opposed to 8080 and\n8081.\n\n    docker-compose -f docker-compose_standalone.yml build\n\nYou can then run the service via:\n\n    docker-compose -f docker-compose_standalone.yml up\n\nAdd `-d` to the call to have it run in the background and not be bound\nby the running console.\n\nStarting a Qanary Environment\n-----------------------------\n\n### Starting a complete Qanary environment\n\nIf you want to run the service as a Qanary component, in the root\ndirectory build the images for it. The setup in the docker-compose\nautomatically creates a Qanary instance as well as a Stardog server to\ninteract with.\n\n    docker-compose -f docker-compose_QanaryComponent.yml build\n\nYou can then run it via:\n\n    docker-compose -f docker-compose_QanaryComponent.yml up\n\nAdd `-d` to the call to have it run in the background and not be bound\nby the running console.\n\nUsing the file `docker-compose-full-example.yml` will connect the\npipeline automatically to the HTWK Stardog server.\n\n### How to start the service and connect it to an existing Qanary Question Answering System\n\nIf you already have a Qanary pipeline, you might just want to add the\ncomponent to it. In this case, you can build and start only the required\ncomponent. To do this, the following commaned is used:\n\n    docker-compose -f docker-compose_QanaryComponent.yml build automation_component\n\nYou can then run it via:\n\n    docker-compose -f docker-compose_QanaryComponent.yml up automation_component\n\nAdd `-d` to the call to have it run in the background and not be bound\nby the running console.\n\nHowever, in that case additional configurations are needed to be done.\nTo connect the service to an existing Qanary pipeline, the following\nsteps must be taken:\n\n-   In the highest [.env](./AutomationService/.env) file, the following\n    values have to be adjusted:\n\n    -   `SPRING_BOOT_ADMIN_URL`\n\n    -   `SPRING_BOOT_ADMIN_USERNAME`\n\n    -   `SPRING_BOOT_ADMIN_PASSWORD`\n\n-   In the same file, the component connection settings have to be\n    adjusted:\n\n    -   `SERVICE_HOST`\n\n    -   `SERVICE_PORT`\n\n-   You can also find the component name and description in this file\n\nTo connect the service with an already existing ML Flow Logger, the\nfollowing steps must be taken:\n\n-   In the [.env](./AutomationService/AutomationServiceBackend/app/.env)\n    file of the component, the following values have to be adjusted:\n\n    -   `MLFLOW_URI`\n\n-   In the same file, if SFTP is used, the following values have to be\n    adjusted:\n\n    -   `USE_SFTP = True`\n\n    -   `MLFLOW_HOST`\n\n    -   `MLFLOW_PORT`\n\n-   In the highest [.env](./AutomationService/.env) file, the ML FLOW\n    Logger values are only relevant for the complete system and do not\n    need to be paid attention to for the standalone component\n\nPossible errors\n---------------\n\n### `Additional properties are not allowed ('devices' was unexpected)`\n\nThe full error message might look like this:\n\n    ERROR: The Compose file './docker-compose_QanaryComponent.yml' is invalid because: services.automation_component.deploy.resources.reservations value Additional properties are not allowed ('devices' was unexpected)\n\nReason: The prepared docker-compose file is integrating GPU\ncapabilities. Following the [Docker\ndocumentation](https://docs.docker.com/compose/gpu-support/#enabling-gpu-access-to-service-containers),\nto take advantage of this functionality you need at least docker-compose\nversion v1.28.0+ (check by running the command:\n`docker-compose --version`).\n\nYou might install the most recent version using pip:\n\n    pip install docker-compose --upgrade\n\n### `Parameters not supported in API versions < X`\n\nThe full error message might look like this:\n\n    ERROR: for automation_component  device_requests param is not supported in API versions < 1.40\n\nReason: the docker-compose version used is too outdated. In building\nthis service, the lowest used version was `2.12.2` which worked fine. IF\nthe error occurs, you might install the newest docker-compose version\nusing your preferred installation method.\n\nOn Arch Linux, the call to install / update docker compose would be:\n\n    sudo pacman -S docker-compose\n\nFor Ubuntu and Debain you can run:\n\n    sudo apt-get install docker-compose-plugin\n\nInteraction with the Service\n============================\n\nOnce a Qanary service is started, you may interact with it through a\nhandful of endpoints offered as APIs that will either provide access to\nsome way of information extraction from the given data or enable you to\nretrain (i.e., exchange) the model on runtime.\n\nQanary endpoint\n---------------\n\nTo interact with the Qanary interface, you can access it using the\nfollowing webpage:\n\n    http://demos.swe.htwk-leipzig.de:40111/startquestionansweringwithtextquestion\n\nIt allows you to ask questions and the recognized entities will be saved\nin the Stardog server. The page also allows you to interact with\nStardog.\n\nIf you enter a question such as \"My name is Annemarie Wittig.\" with the\ndefault model, there will be two annotations created, one for the first-\nand one for the last name. The generated query will be something like\nthis:\n\n    PREFIX dbr: <http://dbpedia.org/resource/\n    PREFIX dbo: <http://dbpedia.org/ontology/\n    PREFIX qa: <http://www.wdaqua.eu/qa#\n    PREFIX oa: <http://www.w3.org/ns/openannotation/core/\n    PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#\n    PREFIX xsd: <http://www.w3.org/2001/XMLSchema#\n    INSERT {\n    GRAPH <urn:graph:6ddac4c3-fbc1-4016-a107-d9126b806b65  {\n        ?entityAnnotation0 a qa:AnnotationOfInstance .\n        ?entityAnnotation0 oa:hasTarget [\n            a   oa:SpecificResource;\n                oa:hasSource    <http://localhost:8080/question/stored-question__text_dc03e843-a2bf-4de0-aec0-280fc8d4adb1  ;\n                oa:hasSelector  [\n                    a oa:TextPositionSelector ;\n                    oa:start \"11\"^^xsd:nonNegativeInteger ;\n                    oa:end  \"20\"^^xsd:nonNegativeInteger\n                ]\n            ] .\n        ?entityAnnotation0 oa:hasBody \"FIRST_NAME\"^^xsd:string ;\n            oa:annotatedBy <urn:qanary:AutomationServiceComponent  ;\n            oa:annotatedAt ?time ;\n            qa:score \"0.5\"^^xsd:decimal .\n\n        ?entityAnnotation1 a qa:AnnotationOfInstance .\n        ?entityAnnotation1 oa:hasTarget [\n            a   oa:SpecificResource;\n                oa:hasSource    <http://localhost:8080/question/stored-question__text_dc03e843-a2bf-4de0-aec0-280fc8d4adb1  ;\n                oa:hasSelector  [\n                    a oa:TextPositionSelector ;\n                    oa:start \"21\"^^xsd:nonNegativeInteger ;\n                    oa:end  \"27\"^^xsd:nonNegativeInteger\n                ]\n            ] .\n        ?entityAnnotation1 oa:hasBody \"MIDDLE_NAME\"^^xsd:string ;\n            oa:annotatedBy <urn:qanary:AutomationServiceComponent  ;\n            oa:annotatedAt ?time ;\n            qa:score \"0.5\"^^xsd:decimal .\n        }\n    }\n    WHERE {\n        BIND (IRI(str(RAND())) AS ?entityAnnotation0) .\n        BIND (IRI(str(RAND())) AS ?entityAnnotation1) .\n        BIND (now() as ?time)\n    }\n\nQuerying data from the Qanary triplestore with a query like the\nfollowing, will return the NER parts of the annotation:\n\n    PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#\n    PREFIX oa: <http://www.w3.org/ns/openannotation/core/\n    PREFIX qa: <http://www.wdaqua.eu/qa#\n    SELECT *\n    FROM <urn:graph:6ddac4c3-fbc1-4016-a107-d9126b806b65\n    WHERE {\n        ?annotationId rdf:type ?type.\n        ?annotationId oa:hasBody ?body.\n        ?annotationId oa:hasTarget ?target.\n        ?target oa:hasSelector ?selector .\n        ?selector oa:start ?start .\n        ?selector oa:end ?end .\n    }\n\nThe result then looks like this:\n\n![Example\nResult](https://user-images.githubusercontent.com/59013332/197013196-6cce4c8b-07d9-4426-aaa7-53fe753905c6.png)\n\nAlternatively, you can curl against the pipeline directly using a curl\ncommand such as:\n\n    curl --location --request POST 'http://demos.swe.htwk-leipzig.de:8081/questionanswering?textquestion=Who is Barack Obama?&language=en&componentlist%5B%5D=AutomationServiceComponent'\n\nNER Endpoint\n------------\n\n### /api\n\nThe /api endpoint offers two interfaces for interaction.\n\n#### GET\n\nThe GET interface offers the possibility to retrieve the NER of a single\ntext by your model. This is only an endpoint for quick result checks and\ndoes not allow mlflow logging. You can interact with it by using a call\nlike:\n\n    curl -X 'GET' 'http://demos.swe.htwk-leipzig.de:8081/api?text=TEXT'\n\nRemember to replace spaces with *%*. The result will be the original\ntext, recognized entities with their labels and content:\n\n    {\n        \"text\": \"text\",\n        \"Entity-Label1\": \"value1\",\n        \"Entity-Label2\": \"value2\"\n    }\n\n#### POST\n\nThe POST interface offers a NER for multiple input possibilities:\n\n1.  upload a CSV file,\n\n2.  upload a JSON file, or\n\n3.  upload raw JSON data within the body of your request.\n\nIn all cases the matching\n[\"accept\"-header](https://developer.mozilla.org/docs/Web/HTTP/Headers/Accept)\nmust be set within the HTTP request. It will define whether the output\nis of the type `application/json` or `text/csv`. If another or an\ninvalid \"accept\"-header is given, the service will either use the\n[\"Content-Type\"-header](https://developer.mozilla.org/docs/Web/HTTP/Headers/Content-Type)\nof the uploaded file or, if no file was uploaded, it will use it from\nthe request. If none of these are valid, the request will fail. Hence,\nif you consider problems, then add or check the headers that are defined\nin your Web service request.\n\nYou can also send the parameter `use_ml_logger` with the value `True`\nwith these request to activate logging using mlflow. This is\n*recommended* while using the component in a real Question Answering\nsystem to establish a tracking of the component’s behavior (i.e., the\nquality).\n\n====== CSV Upload\n\nYou can upload a CSV file, containing texts that are supposed to be run\nthrough NER in the first column, to the Web service. There can be any\nother columns added if required. For example, the expected entities\ncould be added to compare expected and actual results. The service will\nthen annotate the CSV file with columns for all its recognizable\nentities and fill these up with the entities contained in each row. The\n`curl` command would be:\n\n    curl -X POST -H 'accept: application/json' -F \"file_to_identify=@{YOUR CSV FILE PATH};type=text/csv\" http://demos.swe.htwk-leipzig.de:8081/api\n\nThe service will answer with the annotated CSV file. Additionally, the\nresponse file will also be saved locally in the container in the folder\n`/code/app/spacy_model/intermediate/results/`.\n\nAs an example, if you want to upload a file such as:\n\n<table style=\"width:100%;\">\n<colgroup>\n<col style=\"width: 51%\" />\n<col style=\"width: 16%\" />\n<col style=\"width: 16%\" />\n<col style=\"width: 16%\" />\n</colgroup>\n<thead>\n<tr class=\"header\">\n<th>Text</th>\n<th>First_Name</th>\n<th>Middle_Name</th>\n<th>Last_Name</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td><p>People call me Ida Clayton Henderson</p></td>\n<td><p>Ida</p></td>\n<td><p>Clayton</p></td>\n<td><p>Henderson</p></td>\n</tr>\n<tr class=\"even\">\n<td><p>I am happy to meet you, too. You can call me Kira.</p></td>\n<td><p>Kira</p></td>\n<td></td>\n<td></td>\n</tr>\n<tr class=\"odd\">\n<td><p>You can send the data to Eberhard Rump</p></td>\n<td><p>Eberhard</p></td>\n<td></td>\n<td><p>Rump</p></td>\n</tr>\n<tr class=\"even\">\n<td><p>Please send all business inquiries to Jessie Edwin Fowler</p></td>\n<td><p>Jessie</p></td>\n<td><p>Edwin</p></td>\n<td><p>Fowler</p></td>\n</tr>\n<tr class=\"odd\">\n<td><p>Oh, I actually go by Lioba Alexandra.</p></td>\n<td><p>Lioba</p></td>\n<td><p>Alexandra</p></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n\nwith `text/csv` as an \"accept\"-header, it would result in something\nlike:\n\n<table style=\"width:100%;\">\n<colgroup>\n<col style=\"width: 33%\" />\n<col style=\"width: 11%\" />\n<col style=\"width: 11%\" />\n<col style=\"width: 11%\" />\n<col style=\"width: 11%\" />\n<col style=\"width: 11%\" />\n<col style=\"width: 11%\" />\n</colgroup>\n<thead>\n<tr class=\"header\">\n<th>Text</th>\n<th>First_Name</th>\n<th>Middle_Name</th>\n<th>Last_Name</th>\n<th>FIRST_NAME</th>\n<th>LAST_NAME</th>\n<th>MIDDLE_NAME</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td><p>People call me Ida Clayton Henderson</p></td>\n<td><p>Ida</p></td>\n<td><p>Clayton</p></td>\n<td><p>Henderson</p></td>\n<td><p>Ida</p></td>\n<td><p>Henderson</p></td>\n<td><p>Clayton</p></td>\n</tr>\n<tr class=\"even\">\n<td><p>I am happy to meet you, too. You can call me Kira.</p></td>\n<td><p>Kira</p></td>\n<td></td>\n<td></td>\n<td><p>Kira</p></td>\n<td></td>\n<td></td>\n</tr>\n<tr class=\"odd\">\n<td><p>You can send the data to Eberhard Rump</p></td>\n<td><p>Eberhard</p></td>\n<td></td>\n<td><p>Rump</p></td>\n<td><p>Eberhard</p></td>\n<td><p>Rump</p></td>\n<td></td>\n</tr>\n<tr class=\"even\">\n<td><p>Please send all business inquiries to Jessie Edwin Fowler</p></td>\n<td><p>Jessie</p></td>\n<td><p>Edwin</p></td>\n<td><p>Fowler</p></td>\n<td><p>Jessie</p></td>\n<td><p>Fowler</p></td>\n<td><p>Edwin</p></td>\n</tr>\n<tr class=\"odd\">\n<td><p>Oh, I actually go by Lioba Alexandra.</p></td>\n<td><p>Lioba</p></td>\n<td><p>Alexandra</p></td>\n<td></td>\n<td><p>Lioba</p></td>\n<td></td>\n<td><p>Alexandra</p></td>\n</tr>\n</tbody>\n</table>\n\nHowever, having defined the `accept`-header as `application/json`. The\nresponse of the Web service would be:\n\n    [\n        {\n            \"Text\": \"People call me Ida Clayton Henderson\",\n            \"First_Name\": \"Ida\",\n            \"Middle_Name\": \"Clayton\",\n            \"Last_Name\": \"Henderson\",\n            \"FIRST_NAME\": \"Ida\",\n            \"LAST_NAME\": \"Henderson\",\n            \"MIDDLE_NAME\": \"Clayton\"\n        },\n        {\n            \"Text\": \"I am happy to meet you, too. You can call me Kira.\",\n            \"First_Name\": \"Kira\",\n            \"Middle_Name\": null,\n            \"Last_Name\": \"         \",\n            \"FIRST_NAME\": \"Kira\",\n            \"LAST_NAME\": \"\",\n            \"MIDDLE_NAME\": \"\"\n        },\n        ...\n    ]\n\n====== JSON File Upload\n\nAdditionally, the endpoint allows applying NER to all texts given in a\nJSON file much like the [CSV Upload](#csv-upload). The JSON file must\nfollow this structure:\n\n    [\n        {\n            \"text\": \"{TEXT TO CLASSIFY}\",\n            \"language\": \"{LANGUAGE}\",\n            \"entities\": {\n                \"{ENTITY1}\": \"{VALUE1}\",\n                \"{ENTITY2}\": \"{VALUE2}\",\n                ...\n            }\n        }\n    ]\n\nHowever, both the language and the entity tags can be left out (they\ndefault to null), if wanted. The NER via uploading a JSON file, much\nlike the CSV file upload, allows the freedom to add any additional\ninformation that is wanted, as long as each object has the \"attribute\ntext\". Hence, request data of sending two element might look like:\n\n    [\n        {\n            \"text\": \"{TEXT TO CLASSIFY}\"\n        },\n        {\n            \"text\": \"{TEXT TO CLASSIFY}\"\n        }\n    ]\n\nExample files to upload are the texts.json files found in the folder\n[./AutomationService/ExampleBodies/name](./AutomationService/ExampleBodies/name)\nand\n[./AutomationService/ExampleBodies/address](./AutomationService/ExampleBodies/address)\ndirectories.\n\nA corresponding `curl` call would be:\n\n    curl -X POST -H 'accept: application/json' -F \"file_to_identify=@{YOUR JSON FILE PATH};type=application/json\" http://demos.swe.htwk-leipzig.de:8081/api\n\nThe response will be the annotated JSON, but it will also be stored\nlocally in the container. It can be found as\n`/code/app/spacy_model/intermediate/results/`. The NER results can be\nfound in the `results` array. An example response object looks like\nthis:\n\n    [\n        {\n            \"text\": \"I am called Marilyn Monroe.\",\n            \"language\": \"en\",\n            \"entities\": [\n                {\n                    \"First_Name\": \"Marilyn\",\n                    \"Last_Name\": \"Monroe\"\n                }\n            ],\n            \"results\": [\n                {\n                    \"FIRST_NAME\": \"Marilyn\",\n                    \"LAST_NAME\": \"Monroe\"\n                }\n            ]\n        }\n    ]\n\nIf this was entered with `text/csv` as `accept`-header, the result would\nbe:\n\n<table>\n<colgroup>\n<col style=\"width: 38%\" />\n<col style=\"width: 12%\" />\n<col style=\"width: 12%\" />\n<col style=\"width: 12%\" />\n<col style=\"width: 12%\" />\n<col style=\"width: 12%\" />\n</colgroup>\n<thead>\n<tr class=\"header\">\n<th>text</th>\n<th>language</th>\n<th>entities_First_Name</th>\n<th>entities_Last_Name</th>\n<th>results_FIRST_NAME</th>\n<th>results_LAST_NAME</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td><p>I am called Marilyn Monroe.</p></td>\n<td><p>en</p></td>\n<td><p>Marilyn</p></td>\n<td><p>Monroe</p></td>\n<td><p>Marilyn</p></td>\n<td><p>Monroe</p></td>\n</tr>\n</tbody>\n</table>\n\n====== Raw JSON Upload\n\nThe direct upload works exactly as the [JSON File\nUpload](#json-file-upload) with the difference, that the request body is\nnot a file but the JSON data as a string. It has the same structure and\nresponse as in the JSON File Upload and all additional information can\nbe referenced there. The only difference is the `curl` command, which\nwill look something like this:\n\n    curl -X POST -H 'accept: application/json' -H \"Content-Type: application/json\" -d '{{YOUR JSON}}' http://demos.swe.htwk-leipzig.de:8081/api\n\nOr an example of a `curl` with content:\n\n    curl -X 'POST' \\\n      'http://demos.swe.htwk-leipzig.de:8081/api' \\\n      -H 'accept: application/json' \\\n      -H 'Content-Type: application/json' \\\n      -d '[\n      {\n        \"text\": \"I am called Marilyn Monroe.\",\n        \"language\": \"en\",\n        \"entities\": {\n          \"First_Name\": \"Marilyn\",\n          \"Last_Name\": \"Monroe\"\n        }\n      }\n    ]'\n\nAlternatively, the `accept`-header can be set to CSV, too.\n\nRetrain Endpoint\n----------------\n\nThe retraining endpoint uses the data you provided to train a new NER\nmodel which will if all is successful, replace the original model. All\nfollowing interactions will then be with the new model. **The original\nmodel will be deleted.** \"accept\"-headers will not be relevant, as the\nonly return value is a success message in JSON format.\n\nThe retraining will, after formatting the input if needed, go through\nthe [data\npreparation](https://github.com/AnnemarieWittig/RecognitionService/blob/main/Documentation/SpaCyTrainingProcess.md)\nas it is described in the documentation, save the created intermediate\nfiles within the container and will then use the created docbins to\ntrain a new model. All of this happens in a folder located in the\ncontainer as `/code/app/spacy_model/intermediate/`. Once the training\nconcludes successfully, the files are moved into the system and\noverwrite other existing files, either of the original model or the\noriginal intermediate files. Both, the (formatted) training- and\ntestingdata as well as the generated docbins will be saved in the\ncontainer (until overwritten again). The used model will always be the\n`model-best` generated by SpaCy.\n\nAfter the training, you can find your files here: \\* Trainingdata is\nsaved as `train.csv` in `/code/app/spacy_model/corpus/trainingdata/` \\*\nTestingdata is saved as `test.csv` in\n`/code/app/spacy_model/corpus/trainingdata/` \\* The generated docbins\nare saved as `train.spacy` and `test.spacy` in\n`/code/app/spacy_model/corpus/spacy-docbins/` \\* The model (only the\ncontents of the model-best) will be found in\n`/code/app/spacy_model/output/model-best/`\n\nEverything else such as the other trained model will be deleted.\n\nPlease note that the process of retraining can, and will, take some time\nto finish. The classification APIs can still be used with the original\nmodel while the training runs.\n\nYou can also send the parameter `use_ml_logger` with the value `True`\nwith these request to activate logging using mlflow. This is recommended\nwhen you use Qanary.\n\n### CSV Upload\n\nThe endpoint allows to upload two CSV files, the `trainingdata` and the\n`testingdata`, as CSV files. You can name them however you like, as long\nas the files have the exact structure as the ones needed in the\n[Starting Conditions](#starting-conditions).\n\nThe corresponding `curl` call would be:\n\n    curl -X POST -F 'trainingdata=@{YOUR TRAININGDATA CSV};type=text/csv' -F 'testingdata=@{YOUR VALIDATION CSV};type=text/csv' http://demos.swe.htwk-leipzig.de:8081/retrain\n\n### JSON File Upload\n\nThe endpoint allows the upload of trainingfiles in JSON format. There\nare three files needed in total. The training data is structured like\nthis:\n\n    {\n        \"trainingdata\": [\n            {\n                \"text\": \"{TRAININGTEXT}\",\n                \"language\": \"{LANGUAGETEXT (not relevant for training and can be ignored, language is set in the model config)}\",\n                \"entities\": {\n                    \"{ENTITY1}\": \"{VALUE1}\",\n                    \"{ENTITY2}\": \"{VALUE2}\",\n                    ...\n                }\n            }\n        ]\n    }\n\nThe data for tests follows the same structure. But, inside the file, the\ninitial key is named `testingdata` (instead of `trainingsdata`).\n\nFor the JSON upload, a third file is needed. It is called options and\ncontains a list of all possible `entities` the NER is supposed to\nrecognize as well as the model `language` and `modeltype`. It has the\nfollowing structure:\n\n    {\n        \"entities\": [\"{ENTITY1}\", \"{ENTITY2}\", ...],\n        \"language\": \"en\",\n        \"modeltype\": \"spacy\"\n    }\n\nExample files for `curl` commands can be found in the\n[ExampleBodies/name](./AutomationService/ExampleBodies/name) and\n[ExampleBodies/address](./AutomationService/ExampleBodies/address)\ndirectories.\n\nWarning: Please note that those are minimal examples and will not\ngenerate a well-working NER model.\n\nThe following `curl` command would start the retraining of the\ncomponent’s model:\n\n    curl -X POST -F 'trainingdata=@{YOUR TRAININGDATA JSON};type=application/json' -F 'testingdata=@{YOUR VALIDATION JSON};type=application/json' -F 'options=@{YOUR OPTIONS JSON};type=application/json' http://demos.swe.htwk-leipzig.de:8081/retrain\n\n### JSON Raw Upload\n\nThe `json/upload-direct` endpoint allows the data needed to be retrained\nraw within the body of the request. The data itself is structured as is\nfor the [JSON File Upload](#json-file-upload-1), but all put in one file\nlike the following:\n\n    {\n        \"trainingdata\": [\n            {\n                \"text\": \"{TRAININGTEXT}\",\n                \"language\": \"{LANGUAGETEXT (not relevant for training and can be ignored, language is set in the model config)}\",\n                \"entities\": {\n                    \"{ENTITY1}\": \"{VALUE1}\",\n                    \"{ENTITY2}\": \"{VALUE2}\",\n                    ...\n                }\n            }\n        ],\n        \"testingdata\": [\n            {\n                \"text\": \"{TRAININGTEXT}\",\n                \"language\": \"{LANGUAGETEXT (not relevant for training and can be ignored, language is set in the model config)}\",\n                \"entities\": {\n                    \"{ENTITY1}\": \"{VALUE1}\",\n                    \"{ENTITY2}\": \"{VALUE2}\",\n                    ...\n                }\n            }\n        ],\n        \"entities\": [\"{ENTITY1}\", \"{ENTITY2}\", ...],\n        \"language\": \"en\",\n        \"modeltype\": \"spacy\"\n    }\n\nIt is generally not recommended using this endpoint for `curl` commands,\nas it easily gets chaotic and is fairly long, but the general `curl`\ncommand would be:\n\n    curl -X POST -H \"Content-Type: application/json\" -d '{YOUR JSON OBJECT}' http://demos.swe.htwk-leipzig.de:8081/retrain\n\nand a working example is:\n\n    curl -X 'POST' \\\n      'http://demos.swe.htwk-leipzig.de:8081/retrain' \\\n      -H 'Content-Type: application/json' \\\n      -d '{\n      \"testingdata\": [\n        {\n          \"text\": \"I am called Marilyn Monroe.\",\n          \"language\": \"en\",\n          \"entities\": {\n            \"First_Name\": \"Marilyn\",\n            \"Last_Name\": \"Monroe\"\n          }\n        }\n      ],\n      \"trainingdata\": [\n        {\n          \"text\": \"I am called Marilyn Monroe.\",\n          \"language\": \"en\",\n          \"entities\": {\n            \"First_Name\": \"Marilyn\",\n            \"Last_Name\": \"Monroe\"\n          }\n        }\n      ],\n      \"entities\": [\n        \"First_Name\",\n        \"Middle_Name\",\n        \"Last_Name\"\n      ],\n      \"language\": \"en\",\n      \"modeltype\": \"spacy\"\n    }'\n\n### Health endpoint\n\nTo check if the service is active, just run:\n<http://demos.swe.htwk-leipzig.de8081/health>\n\nML Flow Logging\n---------------\n\nYou can use ML Flow Logging with this service. For information on the\nsetup and usage of an ML Flow Server, please refer to its\n[Documentation](https://www.mlflow.org/docs/latest/tracking.html). ML\nFlow Logging is always activated for interactions with the service from\nthe Qanary interface, triggering the ([NER Logging](#ner-logging)). It\nmight as well be used for interactions with the\n[/retrain](#retrain-endpoint) ([Training Logging](#training-logging))\nand the [/api](#api-endpoint) ([NER Logging](#ner-logging)) endpoint by\nsetting the parameter `MLFLOW_ACTIVATED` to `True`. The parameter is\nfound in the [inner .env\nfile](./AutomationService/AutomationServiceBackend/app/.env).\n\n### Training Logging\n\nWhen starting a training process via the `\\retrain`-endpoint with the\n`use_ml_logger` parameter set to `True`, the training will be logged\nonce its concluded. The logs can be found in the `AutoML Model Training`\ntab. The logged data contains the attributes:\n\n-   `component_name`: The name of the component that triggered this log\n\n-   `component_type`: The type of the component, in this case always NER\n\n-   `entities`: The entities this trained model could recognize\n\n-   `hardware`: The hardware the model was trained on\n\n-   `language`: The language of the model, specified by the user\n\n-   `model`: The model that was used. SpaCy returns multiple models (the\n    last and the best), but the component always takes \"model-best\",\n    which was the best performing.\n\n-   `model_uuid`: The UUID that’s assigned to this training run.\n\n-   `modeltype`: The model type entered with the training options\n\n-   `time`: The time needed to conclude the training\n\nWithin the \"Artifacts\", there are some files logged:\n\n-   `Datasets`: In this directory, text files are stored that contain\n    the training and testing data given\n\n-   `config.json`: The configuration used to train the model\n\n-   `model_metrics.json`: This file is the meta.json of the model, it\n    contains all kinds of information such as the performance while\n    training.\n\nWhen the training is concluded, the testdata is used to trigger the NER\nprocess and log the results for each given input. This logging happens\nwithin the [NER Logging](#ner-logging) and the UUID will be the same for\nthe training-logs as well as the NER logs.\n\n### NER Logging\n\nWhen a POST request is sent to the `/api` endpoint (found in the\n`AutoML Model Testing` tab), with the `use_ml_logger` parameter set to\n`True`, the NER results will be logged for each of the given input\ntexts. Files will not be logged as one but each input line by itself.\nThe logged values are:\n\n-   `input`: The given input text\n\n-   `model_uuid`: The UUID of this call; It will be the same for all\n    input texts of the same file and if the process is triggered through\n    the training, it will be the same as the training process, too.\n\n-   `runtime`: The time needed for the result for this text.\n\nWithin the `Artifacts`, there are two files logged:\n\n-   `predicted_target.json`: The result of the NER\n\n-   `true_target.json`: The expected result, if provided with the input\n\n### Annotation Logging\n\nWhen a text is entered in the Qanary interface (found in the\n`AutoML Component Annotations` tab), the created annotations are logged,\ntoo. There are no additional parameters to be set as this is a\nrequirement. The logged data is:\n\n-   `input`: The given input text\n\n-   `model_uuid`: The UUID of this call\n\n-   `predicted_target`: The result of the NER, containing the recognized\n    entities and their positions within the input\n\n-   `qanary_graph_id`: The graph the annotations was saved to\n\nPlease note that the process of logging NER uploads can take up some\ntime if bigger datasets are provided.\n\nReady to go Docker Images\n=========================\n\nThere are Docker images available that have pre-trained models for name\nand address recognition - one using a spacy model as a base and one\nusing no base at all. They can be found in the [Qanary\nDockerhub](https://hub.docker.com/u/qanary), named\n`qanary/qanary-component-ner-automl-pretrained-{the model you want}`.\n\n-   [The image with a spacy based model for name (first, middle and last\n    name) recognition in\n    GER](https://hub.docker.com/r/qanary/qanary-component-ner-automl-pretrained-name-spacy-de)\n\n-   [The image with a spacy based model for name (first, middle and last\n    name) recognition in\n    EN](https://hub.docker.com/r/qanary/qanary-component-ner-automl-pretrained-name-spacy-en)\n\n-   [The image without a base model for name (first, middle and last\n    name) recognition in\n    GER](https://hub.docker.com/r/qanary/qanary-component-ner-automl-pretrained-name-nobase-de)\n\n-   [The image without a base model for name (first, middle and last\n    name) recognition in\n    EN](https://hub.docker.com/r/qanary/qanary-component-ner-automl-pretrained-name-nobase-en)\n\n-   [The image with a spacy based model for address (street, house\n    number, postal code and city) recognition in\n    GER](https://hub.docker.com/r/qanary/qanary-component-ner-automl-pretrained-address-spacy-de)\n\n-   [The image with a spacy based model for address (street, house\n    number, postal code and city) recognition in\n    EN](https://hub.docker.com/r/qanary/qanary-component-ner-automl-pretrained-address-spacy-en)\n\n-   [The image without a base model for address (street, house number,\n    postal code and city) recognition in\n    GER](https://hub.docker.com/r/qanary/qanary-component-ner-automl-pretrained-address-nobase-de)\n\n-   [The image without a base model for address (street, house number,\n    postal code and city) recognition in\n    EN](https://hub.docker.com/r/qanary/qanary-component-ner-automl-pretrained-address-nobase-en)\n\n-   Bert models TBD\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "Qanary-NER-AutoML-component",
    "package_url": "https://pypi.org/project/Qanary-NER-AutoML-component/",
    "platform": null,
    "project_url": "https://pypi.org/project/Qanary-NER-AutoML-component/",
    "project_urls": {
      "Bug Tracker": "https://github.com/WSE-research/Qanary-NER-automl-component/issues",
      "Homepage": "https://github.com/WSE-research/Qanary-NER-automl-component",
      "README": "https://github.com/WSE-research/Qanary-NER-automl-component#readme"
    },
    "release_url": "https://pypi.org/project/Qanary-NER-AutoML-component/0.1.1/",
    "requires_dist": null,
    "requires_python": ">=3.8",
    "summary": "A python project allowing to run a fastapi server that can train and identify NER models in runtime and can be included in a qanary environment if wished.",
    "version": "0.1.1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 17376818,
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "d8549acc8d5fd7a1966f5342d4009b6e8918f48757ec1f642c9611c7ea218714",
          "md5": "067c13dbad1b8c2c75d3dcf2f26766b4",
          "sha256": "ca284f6b21af37f8e6622985aec875ed8be0f8daea11c68aeab2ee42cddd5318"
        },
        "downloads": -1,
        "filename": "qanary_ner_automl_component-0.1.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "067c13dbad1b8c2c75d3dcf2f26766b4",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 32582,
        "upload_time": "2023-02-08T15:43:09",
        "upload_time_iso_8601": "2023-02-08T15:43:09.875342Z",
        "url": "https://files.pythonhosted.org/packages/d8/54/9acc8d5fd7a1966f5342d4009b6e8918f48757ec1f642c9611c7ea218714/qanary_ner_automl_component-0.1.0-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "fe64776f9b887ca78e64e86e5b41a624808c9311c2ff89178e4cbe75edb33d36",
          "md5": "dcd094c364f945230dd34f034be5e222",
          "sha256": "6c88db1c788edff004d475c507a39f7b1e6153f2dc221cae1ef68ae733dc8945"
        },
        "downloads": -1,
        "filename": "qanary_ner_automl_component-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "dcd094c364f945230dd34f034be5e222",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 10758999,
        "upload_time": "2023-02-08T15:43:14",
        "upload_time_iso_8601": "2023-02-08T15:43:14.916068Z",
        "url": "https://files.pythonhosted.org/packages/fe/64/776f9b887ca78e64e86e5b41a624808c9311c2ff89178e4cbe75edb33d36/qanary_ner_automl_component-0.1.0.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "424b452151820d4b976da8ecd686e7ff61a482c0d1ec008a905fba6f95ae76d0",
          "md5": "ae6b617f7c21a908273ee394b40c2735",
          "sha256": "cca4f3c1a5e22a001630271e3d2292bc7187d16297d6b1c0e5d088cbc70f8b0b"
        },
        "downloads": -1,
        "filename": "qanary_ner_automl_component-0.1.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "ae6b617f7c21a908273ee394b40c2735",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "requires_python": ">=3.8",
        "size": 36658,
        "upload_time": "2023-03-21T09:30:10",
        "upload_time_iso_8601": "2023-03-21T09:30:10.504994Z",
        "url": "https://files.pythonhosted.org/packages/42/4b/452151820d4b976da8ecd686e7ff61a482c0d1ec008a905fba6f95ae76d0/qanary_ner_automl_component-0.1.1-py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "a485d83422dd88ba012190889ae8b9b917679febfd36c59a600c330b348a7c59",
          "md5": "5f56cf3db83eca0ee37d684cd1966cd0",
          "sha256": "0e45fcf17ff04801a6dc2a26415ba367f5b5efb1febbb1c8576e4dcd9f55c2b9"
        },
        "downloads": -1,
        "filename": "qanary_ner_automl_component-0.1.1.tar.gz",
        "has_sig": false,
        "md5_digest": "5f56cf3db83eca0ee37d684cd1966cd0",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": ">=3.8",
        "size": 69676223,
        "upload_time": "2023-03-21T09:30:28",
        "upload_time_iso_8601": "2023-03-21T09:30:28.341036Z",
        "url": "https://files.pythonhosted.org/packages/a4/85/d83422dd88ba012190889ae8b9b917679febfd36c59a600c330b348a7c59/qanary_ner_automl_component-0.1.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "424b452151820d4b976da8ecd686e7ff61a482c0d1ec008a905fba6f95ae76d0",
        "md5": "ae6b617f7c21a908273ee394b40c2735",
        "sha256": "cca4f3c1a5e22a001630271e3d2292bc7187d16297d6b1c0e5d088cbc70f8b0b"
      },
      "downloads": -1,
      "filename": "qanary_ner_automl_component-0.1.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "ae6b617f7c21a908273ee394b40c2735",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "requires_python": ">=3.8",
      "size": 36658,
      "upload_time": "2023-03-21T09:30:10",
      "upload_time_iso_8601": "2023-03-21T09:30:10.504994Z",
      "url": "https://files.pythonhosted.org/packages/42/4b/452151820d4b976da8ecd686e7ff61a482c0d1ec008a905fba6f95ae76d0/qanary_ner_automl_component-0.1.1-py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "a485d83422dd88ba012190889ae8b9b917679febfd36c59a600c330b348a7c59",
        "md5": "5f56cf3db83eca0ee37d684cd1966cd0",
        "sha256": "0e45fcf17ff04801a6dc2a26415ba367f5b5efb1febbb1c8576e4dcd9f55c2b9"
      },
      "downloads": -1,
      "filename": "qanary_ner_automl_component-0.1.1.tar.gz",
      "has_sig": false,
      "md5_digest": "5f56cf3db83eca0ee37d684cd1966cd0",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": ">=3.8",
      "size": 69676223,
      "upload_time": "2023-03-21T09:30:28",
      "upload_time_iso_8601": "2023-03-21T09:30:28.341036Z",
      "url": "https://files.pythonhosted.org/packages/a4/85/d83422dd88ba012190889ae8b9b917679febfd36c59a600c330b348a7c59/qanary_ner_automl_component-0.1.1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}